{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "epoch:0 step:5[D loss: 0.999917] [G loss: 1.000168]\n",
      "epoch:0 step:10[D loss: 0.999925] [G loss: 1.000164]\n",
      "epoch:0 step:15[D loss: 0.999925] [G loss: 1.000167]\n",
      "epoch:0 step:20[D loss: 0.999928] [G loss: 1.000163]\n",
      "epoch:0 step:25[D loss: 0.999926] [G loss: 1.000165]\n",
      "epoch:0 step:30[D loss: 0.999927] [G loss: 1.000165]\n",
      "epoch:0 step:35[D loss: 0.999931] [G loss: 1.000168]\n",
      "epoch:0 step:40[D loss: 0.999928] [G loss: 1.000171]\n",
      "epoch:0 step:45[D loss: 0.999923] [G loss: 1.000167]\n",
      "epoch:0 step:50[D loss: 0.999927] [G loss: 1.000160]\n",
      "epoch:0 step:55[D loss: 0.999931] [G loss: 1.000155]\n",
      "epoch:0 step:60[D loss: 0.999927] [G loss: 1.000156]\n",
      "epoch:0 step:65[D loss: 0.999929] [G loss: 1.000149]\n",
      "epoch:0 step:70[D loss: 0.999931] [G loss: 1.000139]\n",
      "epoch:0 step:75[D loss: 0.999935] [G loss: 1.000136]\n",
      "epoch:0 step:80[D loss: 0.999941] [G loss: 1.000130]\n",
      "epoch:0 step:85[D loss: 0.999941] [G loss: 1.000126]\n",
      "epoch:0 step:90[D loss: 0.999943] [G loss: 1.000123]\n",
      "epoch:0 step:95[D loss: 0.999944] [G loss: 1.000122]\n",
      "epoch:0 step:100[D loss: 0.999946] [G loss: 1.000120]\n",
      "epoch:0 step:105[D loss: 0.999948] [G loss: 1.000115]\n",
      "epoch:0 step:110[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:0 step:115[D loss: 0.999952] [G loss: 1.000111]\n",
      "epoch:0 step:120[D loss: 0.999953] [G loss: 1.000102]\n",
      "epoch:0 step:125[D loss: 0.999954] [G loss: 1.000105]\n",
      "epoch:0 step:130[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:0 step:135[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:0 step:140[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:0 step:145[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:0 step:150[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:0 step:155[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:0 step:160[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:0 step:165[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:0 step:170[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:0 step:175[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:0 step:180[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:0 step:185[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:0 step:190[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:195[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:200[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:205[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:210[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:215[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:220[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:225[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:230[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:235[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:240[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:245[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:250[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:0 step:255[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:260[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:265[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:0 step:270[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:275[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:280[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:0 step:285[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:0 step:290[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:295[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:0 step:300[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:0 step:305[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:0 step:310[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:0 step:315[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:0 step:320[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:0 step:325[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:0 step:330[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:0 step:335[D loss: 0.999980] [G loss: 1.000095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:340[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:0 step:345[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:0 step:350[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:0 step:355[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:0 step:360[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:0 step:365[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:0 step:370[D loss: 0.999976] [G loss: 1.000099]\n",
      "epoch:0 step:375[D loss: 0.999978] [G loss: 1.000108]\n",
      "epoch:0 step:380[D loss: 0.999969] [G loss: 1.000114]\n",
      "epoch:0 step:385[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:0 step:390[D loss: 0.999974] [G loss: 1.000112]\n",
      "epoch:0 step:395[D loss: 0.999977] [G loss: 1.000102]\n",
      "epoch:0 step:400[D loss: 0.999970] [G loss: 1.000115]\n",
      "epoch:0 step:405[D loss: 0.999974] [G loss: 1.000111]\n",
      "epoch:0 step:410[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:0 step:415[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:0 step:420[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:0 step:425[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:0 step:430[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:0 step:435[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:0 step:440[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:0 step:445[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:0 step:450[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:0 step:455[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:0 step:460[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:0 step:465[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:0 step:470[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:0 step:475[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:0 step:480[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:0 step:485[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:0 step:490[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:0 step:495[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:0 step:500[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:0 step:505[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:0 step:510[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:0 step:515[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:0 step:520[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:525[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:530[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:0 step:535[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:540[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:545[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:550[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:555[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:0 step:560[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:0 step:565[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:570[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:575[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:580[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:0 step:585[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:0 step:590[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:595[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:600[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:605[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:0 step:610[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:615[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:620[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:625[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:630[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:635[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:640[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:645[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:650[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:655[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:660[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:665[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:670[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:675[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:680[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:685[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:690[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:695[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:700[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:705[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:710[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:715[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:720[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:725[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:730[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:735[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:740[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:745[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:750[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:755[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:760[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:765[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:770[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:775[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:780[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:785[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:790[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:795[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:800[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:805[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:810[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:815[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:820[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:825[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:830[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:835[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:840[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:845[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:850[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:855[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:0 step:860[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:865[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:870[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:875[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:880[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:885[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:890[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:895[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:0 step:900[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:905[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:910[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:915[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:920[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:925[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:0 step:930[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:935[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:940[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:945[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:950[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:955[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:960[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:965[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:970[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:0 step:975[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:980[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:985[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:990[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:995[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:1000[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:0 step:1005[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1010[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:1015[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1020[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:1025[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1030[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:0 step:1035[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:0 step:1040[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:1045[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:1050[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:0 step:1055[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:0 step:1060[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:1065[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:1070[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:0 step:1075[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:1080[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1085[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:0 step:1090[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:0 step:1095[D loss: 0.999966] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1100[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:1105[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:1110[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1115[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:1120[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:0 step:1125[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1130[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:1135[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1140[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:1145[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:1150[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:0 step:1155[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1160[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1165[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:1170[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1175[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:0 step:1180[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1185[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:1190[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:1195[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1200[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:0 step:1205[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:1210[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:1215[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:1220[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1225[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:1230[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:1235[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:1240[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:0 step:1245[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:1250[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1255[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:1260[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:0 step:1265[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:1270[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:0 step:1275[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:1280[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:1285[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1290[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1295[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1300[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:1305[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:1310[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:0 step:1315[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:0 step:1320[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:0 step:1325[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1330[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1335[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:0 step:1340[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1345[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:0 step:1350[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1355[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:1360[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:1365[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:1370[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1375[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1380[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1385[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1390[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:0 step:1395[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:0 step:1400[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:0 step:1405[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1410[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:0 step:1415[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:1420[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1425[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:1430[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:0 step:1435[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:0 step:1440[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1445[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:1450[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:1455[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:1460[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:1465[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:1470[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:0 step:1475[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:1480[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1485[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:0 step:1490[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:1495[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:0 step:1500[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:0 step:1505[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:0 step:1510[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1515[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1520[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:1525[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:0 step:1530[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:0 step:1535[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1540[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:1545[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1550[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:1555[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:0 step:1560[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:1565[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:1570[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:1575[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:0 step:1580[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:0 step:1585[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1590[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1595[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:0 step:1600[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1605[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:1610[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:1615[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:1620[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:1625[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:1630[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:1635[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:1640[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:0 step:1645[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:0 step:1650[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:1655[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1660[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1665[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:1670[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:1675[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1680[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:0 step:1685[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:0 step:1690[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:0 step:1695[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:1700[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:1705[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:1710[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:0 step:1715[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1720[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1725[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:1730[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:1735[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:1740[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:1745[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:1750[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:1755[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:1760[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:1765[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1770[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:1775[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:1780[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:1785[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1790[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:1795[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:1800[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:1805[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:0 step:1810[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:0 step:1815[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1820[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:0 step:1825[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:0 step:1830[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:1835[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:1840[D loss: 0.999977] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1845[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:1850[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:0 step:1855[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:1860[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:1865[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:1870[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:0 step:1875[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:1880[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:0 step:1885[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:0 step:1890[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:0 step:1895[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:1900[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:0 step:1905[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:1910[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:0 step:1915[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:0 step:1920[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:1925[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:0 step:1930[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:1935[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:1940[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:1945[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:1950[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:0 step:1955[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:0 step:1960[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:1965[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:1970[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:1975[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:1980[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:1985[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:0 step:1990[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:0 step:1995[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:2000[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2005[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:2010[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:0 step:2015[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:0 step:2020[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2025[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:0 step:2030[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:0 step:2035[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:0 step:2040[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2045[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:0 step:2050[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:0 step:2055[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:0 step:2060[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2065[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2070[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:2075[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:0 step:2080[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:0 step:2085[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:2090[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2095[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:0 step:2100[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:2105[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:0 step:2110[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:2115[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:2120[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2125[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:0 step:2130[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:2135[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:0 step:2140[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:0 step:2145[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2150[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:2155[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:0 step:2160[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:2165[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:0 step:2170[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:2175[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:0 step:2180[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2185[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:2190[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:2195[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:0 step:2200[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2205[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2210[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:0 step:2215[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:2220[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:2225[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:0 step:2230[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:0 step:2235[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:0 step:2240[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:0 step:2245[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:0 step:2250[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:2255[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:2260[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:0 step:2265[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2270[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2275[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:0 step:2280[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2285[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:0 step:2290[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2295[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:2300[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:0 step:2305[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:2310[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:2315[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:0 step:2320[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:2325[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:2330[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:0 step:2335[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:2340[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:2345[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:0 step:2350[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:0 step:2355[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:0 step:2360[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:2365[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:2370[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2375[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:0 step:2380[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2385[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:2390[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:2395[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:0 step:2400[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:0 step:2405[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2410[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:0 step:2415[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2420[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:2425[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:0 step:2430[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:2435[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:2440[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:0 step:2445[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:0 step:2450[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:2455[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:2460[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2465[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:2470[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2475[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:2480[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:2485[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:2490[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2495[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2500[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:0 step:2505[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:2510[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:2515[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:2520[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2525[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:0 step:2530[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:0 step:2535[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:2540[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2545[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:0 step:2550[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:0 step:2555[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:0 step:2560[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2565[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:2570[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2575[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2580[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:0 step:2585[D loss: 0.999974] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:2590[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2595[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:2600[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2605[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:2610[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:2615[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2620[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:2625[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:0 step:2630[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:2635[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:0 step:2640[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2645[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:2650[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:2655[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:0 step:2660[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2665[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:2670[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:2675[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:2680[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:0 step:2685[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:2690[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:0 step:2695[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:0 step:2700[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:2705[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:2710[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:2715[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:2720[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:2725[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:0 step:2730[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:2735[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:0 step:2740[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:2745[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:0 step:2750[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:0 step:2755[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:2760[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2765[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:0 step:2770[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:0 step:2775[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:2780[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2785[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:0 step:2790[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:0 step:2795[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:0 step:2800[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:0 step:2805[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:0 step:2810[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:0 step:2815[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:0 step:2820[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:0 step:2825[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:2830[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:2835[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:2840[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:0 step:2845[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:0 step:2850[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:2855[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:0 step:2860[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:2865[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:2870[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:0 step:2875[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:0 step:2880[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:2885[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:0 step:2890[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:0 step:2895[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:0 step:2900[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2905[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:2910[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:0 step:2915[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:2920[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:2925[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:2930[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:2935[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:2940[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:2945[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:2950[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:2955[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:0 step:2960[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:0 step:2965[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:0 step:2970[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:2975[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:2980[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:2985[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:0 step:2990[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:0 step:2995[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:0 step:3000[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:0 step:3005[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:0 step:3010[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:0 step:3015[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:3020[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:0 step:3025[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:3030[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:3035[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:0 step:3040[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:0 step:3045[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:3050[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:3055[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:0 step:3060[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:3065[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:0 step:3070[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:0 step:3075[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:0 step:3080[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:3085[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:0 step:3090[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:3095[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:0 step:3100[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:3105[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:0 step:3110[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:0 step:3115[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:0 step:3120[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:3125[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:0 step:3130[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:0 step:3135[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:0 step:3140[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:0 step:3145[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:0 step:3150[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:0 step:3155[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:3160[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:3165[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:3170[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:0 step:3175[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:0 step:3180[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:3185[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:0 step:3190[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:3195[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:0 step:3200[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:0 step:3205[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:0 step:3210[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:0 step:3215[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:3220[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:0 step:3225[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:3230[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:0 step:3235[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:3240[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:3245[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:0 step:3250[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:0 step:3255[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:0 step:3260[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:0 step:3265[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:3270[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:0 step:3275[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:0 step:3280[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:0 step:3285[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:0 step:3290[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:0 step:3295[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:3300[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:3305[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:0 step:3310[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:0 step:3315[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:3320[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:0 step:3325[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:0 step:3330[D loss: 0.999972] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:3335[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:0 step:3340[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:0 step:3345[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:0 step:3350[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:3355[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:0 step:3360[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:3365[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:0 step:3370[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:3375[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:3380[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:0 step:3385[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:3390[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:3395[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:3400[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:0 step:3405[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:0 step:3410[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:0 step:3415[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:0 step:3420[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:0 step:3425[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:0 step:3430[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:3435[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:0 step:3440[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:3445[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:3450[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:3455[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:0 step:3460[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:0 step:3465[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:0 step:3470[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:0 step:3475[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:0 step:3480[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:0 step:3485[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:0 step:3490[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:0 step:3495[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:0 step:3500[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:0 step:3505[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:3510[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:0 step:3515[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:0 step:3520[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:3525[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:0 step:3530[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:0 step:3535[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:3540[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:0 step:3545[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:3550[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:0 step:3555[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:3560[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3565[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:0 step:3570[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:0 step:3575[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:0 step:3580[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:0 step:3585[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:3590[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:0 step:3595[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:3600[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:0 step:3605[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:0 step:3610[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:0 step:3615[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:0 step:3620[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:0 step:3625[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:3630[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:0 step:3635[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:0 step:3640[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:0 step:3645[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:0 step:3650[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:0 step:3655[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:0 step:3660[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:0 step:3665[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:0 step:3670[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:0 step:3675[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:0 step:3680[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:3685[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:0 step:3690[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:0 step:3695[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:0 step:3700[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:0 step:3705[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:0 step:3710[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:0 step:3715[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:0 step:3720[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:0 step:3725[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:0 step:3730[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:0 step:3735[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:0 step:3740[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:3745[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:0 step:3750[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:0 step:3755[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:0 step:3760[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:0 step:3765[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:0 step:3770[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:0 step:3775[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:0 step:3780[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:0 step:3785[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:0 step:3790[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:0 step:3795[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:0 step:3800[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:0 step:3805[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:0 step:3810[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:0 step:3815[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:3820[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:0 step:3825[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:0 step:3830[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:0 step:3835[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:0 step:3840[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:0 step:3845[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:0 step:3850[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:0 step:3855[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:3860[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:0 step:3865[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:0 step:3870[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:0 step:3875[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:0 step:3880[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:0 step:3885[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:3890[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:0 step:3895[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:0 step:3900[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:0 step:3905[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:0 step:3910[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:0 step:3915[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:3920[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:0 step:3925[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:0 step:3930[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:0 step:3935[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:3940[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:3945[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:0 step:3950[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:0 step:3955[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:3960[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:0 step:3965[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:0 step:3970[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:0 step:3975[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:0 step:3980[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:0 step:3985[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:0 step:3990[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:0 step:3995[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:0 step:4000[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:0 step:4005[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:0 step:4010[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:0 step:4015[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:0 step:4020[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:4025[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:0 step:4030[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:0 step:4035[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:0 step:4040[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4045[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:0 step:4050[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4055[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:0 step:4060[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:0 step:4065[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:0 step:4070[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:0 step:4075[D loss: 0.999975] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:4080[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:0 step:4085[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:0 step:4090[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:0 step:4095[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:0 step:4100[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:0 step:4105[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:4110[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:0 step:4115[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:0 step:4120[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:0 step:4125[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:0 step:4130[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:0 step:4135[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:0 step:4140[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:0 step:4145[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:0 step:4150[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:0 step:4155[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:0 step:4160[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4165[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:0 step:4170[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:0 step:4175[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:0 step:4180[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:0 step:4185[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:0 step:4190[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:0 step:4195[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:0 step:4200[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:0 step:4205[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:0 step:4210[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:0 step:4215[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:0 step:4220[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:0 step:4225[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:0 step:4230[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:0 step:4235[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:0 step:4240[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:0 step:4245[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:0 step:4250[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:4255[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:0 step:4260[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:0 step:4265[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:0 step:4270[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:0 step:4275[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:0 step:4280[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:0 step:4285[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:0 step:4290[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:4295[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:0 step:4300[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:4305[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:0 step:4310[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:0 step:4315[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:0 step:4320[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:0 step:4325[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:0 step:4330[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:0 step:4335[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:0 step:4340[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:0 step:4345[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:0 step:4350[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:0 step:4355[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:0 step:4360[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:0 step:4365[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:0 step:4370[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:0 step:4375[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:0 step:4380[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:0 step:4385[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:0 step:4390[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:0 step:4395[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:0 step:4400[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:0 step:4405[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:0 step:4410[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:0 step:4415[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:0 step:4420[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:0 step:4425[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:0 step:4430[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:0 step:4435[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:4440[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:0 step:4445[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:0 step:4450[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:0 step:4455[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:4460[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:0 step:4465[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:0 step:4470[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:4475[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:0 step:4480[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:4485[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:0 step:4490[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:0 step:4495[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:0 step:4500[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:0 step:4505[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:0 step:4510[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:0 step:4515[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:0 step:4520[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:0 step:4525[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:0 step:4530[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:0 step:4535[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:0 step:4540[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:0 step:4545[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:0 step:4550[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:0 step:4555[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:0 step:4560[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:0 step:4565[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:0 step:4570[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:0 step:4575[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:0 step:4580[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:0 step:4585[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:0 step:4590[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:0 step:4595[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:0 step:4600[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:0 step:4605[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:0 step:4610[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:0 step:4615[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:0 step:4620[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:0 step:4625[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:0 step:4630[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:0 step:4635[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:0 step:4640[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:0 step:4645[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:0 step:4650[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:0 step:4655[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:0 step:4660[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:0 step:4665[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:0 step:4670[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:0 step:4675[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:0 step:4680[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:0 step:4685[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:1 step:4690[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:1 step:4695[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:1 step:4700[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:1 step:4705[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:1 step:4710[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:4715[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:4720[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:1 step:4725[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:1 step:4730[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:4735[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:1 step:4740[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:4745[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:1 step:4750[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:1 step:4755[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:1 step:4760[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:1 step:4765[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:1 step:4770[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:4775[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:1 step:4780[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:4785[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:4790[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:1 step:4795[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:1 step:4800[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:1 step:4805[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:4810[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:1 step:4815[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:1 step:4820[D loss: 0.999988] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:4825[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:1 step:4830[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:1 step:4835[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:4840[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:1 step:4845[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:1 step:4850[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:1 step:4855[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:1 step:4860[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:4865[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:1 step:4870[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:4875[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:1 step:4880[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:4885[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:1 step:4890[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:1 step:4895[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:4900[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:1 step:4905[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:1 step:4910[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:1 step:4915[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:1 step:4920[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:4925[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:1 step:4930[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:4935[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:1 step:4940[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:1 step:4945[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:1 step:4950[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:4955[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:1 step:4960[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:1 step:4965[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:1 step:4970[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:1 step:4975[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:1 step:4980[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:1 step:4985[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:4990[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:4995[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:5000[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:1 step:5005[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:1 step:5010[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:5015[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:5020[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:1 step:5025[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:1 step:5030[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:1 step:5035[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:5040[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:1 step:5045[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:5050[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:1 step:5055[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:1 step:5060[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:1 step:5065[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:1 step:5070[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:5075[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:5080[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:5085[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:1 step:5090[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:5095[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:5100[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:5105[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:1 step:5110[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:1 step:5115[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:1 step:5120[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:1 step:5125[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:1 step:5130[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:1 step:5135[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:1 step:5140[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:1 step:5145[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:5150[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:5155[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:1 step:5160[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:1 step:5165[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:1 step:5170[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:1 step:5175[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:1 step:5180[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:1 step:5185[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:5190[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:5195[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:5200[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:1 step:5205[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:1 step:5210[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:1 step:5215[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:5220[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:1 step:5225[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:1 step:5230[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:1 step:5235[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:1 step:5240[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:5245[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:1 step:5250[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:5255[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:5260[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:5265[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:1 step:5270[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:1 step:5275[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:1 step:5280[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:1 step:5285[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:1 step:5290[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:5295[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:1 step:5300[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:5305[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:5310[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:1 step:5315[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:1 step:5320[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:1 step:5325[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:5330[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:1 step:5335[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:1 step:5340[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:5345[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:1 step:5350[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:1 step:5355[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:5360[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:1 step:5365[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:5370[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:1 step:5375[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:1 step:5380[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:1 step:5385[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:1 step:5390[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:1 step:5395[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:1 step:5400[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:5405[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:1 step:5410[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:1 step:5415[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:1 step:5420[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:1 step:5425[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:1 step:5430[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:1 step:5435[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:5440[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:1 step:5445[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:1 step:5450[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:1 step:5455[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:5460[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:1 step:5465[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:1 step:5470[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:1 step:5475[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:5480[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:1 step:5485[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:1 step:5490[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:1 step:5495[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:1 step:5500[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:1 step:5505[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:1 step:5510[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:1 step:5515[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:1 step:5520[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:1 step:5525[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:1 step:5530[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:1 step:5535[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:5540[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:1 step:5545[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:5550[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:1 step:5555[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:1 step:5560[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:5565[D loss: 0.999977] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:5570[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:1 step:5575[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:1 step:5580[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:5585[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:1 step:5590[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:1 step:5595[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:1 step:5600[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:5605[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:5610[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:1 step:5615[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:5620[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:5625[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:1 step:5630[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:1 step:5635[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:5640[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:5645[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:5650[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:1 step:5655[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:1 step:5660[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:1 step:5665[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:1 step:5670[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:1 step:5675[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:1 step:5680[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:1 step:5685[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:1 step:5690[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:1 step:5695[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:1 step:5700[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:5705[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:5710[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:1 step:5715[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:5720[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:1 step:5725[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:5730[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:1 step:5735[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:1 step:5740[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:1 step:5745[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:1 step:5750[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:1 step:5755[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:1 step:5760[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:1 step:5765[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:1 step:5770[D loss: 0.999990] [G loss: 1.000080]\n",
      "epoch:1 step:5775[D loss: 0.999971] [G loss: 1.000104]\n",
      "epoch:1 step:5780[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:1 step:5785[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:1 step:5790[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:1 step:5795[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:1 step:5800[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:5805[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:1 step:5810[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:1 step:5815[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:1 step:5820[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:5825[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:1 step:5830[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:1 step:5835[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:1 step:5840[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:5845[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:1 step:5850[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:5855[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:5860[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:1 step:5865[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:1 step:5870[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:1 step:5875[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:1 step:5880[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:1 step:5885[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:5890[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:1 step:5895[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:5900[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:1 step:5905[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:1 step:5910[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:5915[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:5920[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:1 step:5925[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:1 step:5930[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:1 step:5935[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:5940[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:1 step:5945[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:5950[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:1 step:5955[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:1 step:5960[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:1 step:5965[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:5970[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:1 step:5975[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:5980[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:1 step:5985[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:1 step:5990[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:1 step:5995[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:6000[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:1 step:6005[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:1 step:6010[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:1 step:6015[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:6020[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:1 step:6025[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:1 step:6030[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:6035[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:1 step:6040[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:1 step:6045[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:1 step:6050[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:1 step:6055[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:1 step:6060[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:1 step:6065[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:6070[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:6075[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:1 step:6080[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:6085[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:1 step:6090[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:1 step:6095[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:6100[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:1 step:6105[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:6110[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:1 step:6115[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:6120[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:1 step:6125[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:1 step:6130[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:6135[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:1 step:6140[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:1 step:6145[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:1 step:6150[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:1 step:6155[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:1 step:6160[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:1 step:6165[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:1 step:6170[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:1 step:6175[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:1 step:6180[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:6185[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:1 step:6190[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:1 step:6195[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:6200[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:1 step:6205[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:6210[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:1 step:6215[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:1 step:6220[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:6225[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:1 step:6230[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:1 step:6235[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:6240[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:6245[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:6250[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:1 step:6255[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:6260[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:1 step:6265[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:6270[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:6275[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:6280[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:6285[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:1 step:6290[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:1 step:6295[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:6300[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:1 step:6305[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:6310[D loss: 0.999974] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:6315[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:6320[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:1 step:6325[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:1 step:6330[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:6335[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:1 step:6340[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:1 step:6345[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:1 step:6350[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:1 step:6355[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:1 step:6360[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:1 step:6365[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:1 step:6370[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:1 step:6375[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:1 step:6380[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:1 step:6385[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:6390[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:1 step:6395[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:1 step:6400[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:1 step:6405[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:6410[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:6415[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:1 step:6420[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:1 step:6425[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:1 step:6430[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:6435[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:6440[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:1 step:6445[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:1 step:6450[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:6455[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:6460[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:1 step:6465[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:1 step:6470[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:1 step:6475[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:1 step:6480[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:6485[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:6490[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:1 step:6495[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:1 step:6500[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:1 step:6505[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:1 step:6510[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:6515[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:1 step:6520[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:1 step:6525[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:6530[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:6535[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:6540[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:1 step:6545[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:1 step:6550[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:1 step:6555[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:1 step:6560[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:1 step:6565[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:1 step:6570[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:1 step:6575[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:1 step:6580[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:1 step:6585[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:1 step:6590[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:1 step:6595[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:1 step:6600[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:1 step:6605[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:1 step:6610[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:1 step:6615[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:1 step:6620[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:1 step:6625[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:1 step:6630[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:1 step:6635[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:6640[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:1 step:6645[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:1 step:6650[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:1 step:6655[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:1 step:6660[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:6665[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:6670[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:1 step:6675[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:1 step:6680[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:1 step:6685[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:1 step:6690[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:1 step:6695[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:1 step:6700[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:1 step:6705[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:1 step:6710[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:1 step:6715[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:6720[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:1 step:6725[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:1 step:6730[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:1 step:6735[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:1 step:6740[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:6745[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:1 step:6750[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:1 step:6755[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:1 step:6760[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:1 step:6765[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:6770[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:1 step:6775[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:1 step:6780[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:1 step:6785[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:6790[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:1 step:6795[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:6800[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:1 step:6805[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:1 step:6810[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:1 step:6815[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:6820[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:6825[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:6830[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:1 step:6835[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:1 step:6840[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:1 step:6845[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:1 step:6850[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:6855[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:1 step:6860[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:1 step:6865[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:1 step:6870[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:6875[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:1 step:6880[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:1 step:6885[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:1 step:6890[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:1 step:6895[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:6900[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:6905[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:6910[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:1 step:6915[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:6920[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:1 step:6925[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:6930[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:1 step:6935[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:1 step:6940[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:1 step:6945[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:1 step:6950[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:6955[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:6960[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:1 step:6965[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:1 step:6970[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:6975[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:1 step:6980[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:1 step:6985[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:1 step:6990[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:6995[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:1 step:7000[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:1 step:7005[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:1 step:7010[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:1 step:7015[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:1 step:7020[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:7025[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:1 step:7030[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:7035[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:1 step:7040[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:1 step:7045[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:1 step:7050[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:1 step:7055[D loss: 0.999976] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7060[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:1 step:7065[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7070[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:1 step:7075[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:1 step:7080[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:1 step:7085[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:7090[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:1 step:7095[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:7100[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:7105[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:1 step:7110[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:1 step:7115[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:7120[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:7125[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:1 step:7130[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:7135[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:7140[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:1 step:7145[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:7150[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:1 step:7155[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:1 step:7160[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:1 step:7165[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:1 step:7170[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:7175[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:1 step:7180[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:7185[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:1 step:7190[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:1 step:7195[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:1 step:7200[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:1 step:7205[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:1 step:7210[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:1 step:7215[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:7220[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:1 step:7225[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:1 step:7230[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:1 step:7235[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:1 step:7240[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:1 step:7245[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:7250[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:1 step:7255[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:1 step:7260[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:1 step:7265[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:1 step:7270[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:7275[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:7280[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:1 step:7285[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:1 step:7290[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:7295[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:1 step:7300[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:1 step:7305[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:1 step:7310[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:1 step:7315[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:1 step:7320[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:7325[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:7330[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:7335[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:1 step:7340[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:7345[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:1 step:7350[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:1 step:7355[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:7360[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:7365[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:1 step:7370[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:1 step:7375[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:1 step:7380[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:7385[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:1 step:7390[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:1 step:7395[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:7400[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:1 step:7405[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:1 step:7410[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:1 step:7415[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:1 step:7420[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:1 step:7425[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:1 step:7430[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:1 step:7435[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:1 step:7440[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:1 step:7445[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:1 step:7450[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:7455[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:1 step:7460[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:7465[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:1 step:7470[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:1 step:7475[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:1 step:7480[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:1 step:7485[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:1 step:7490[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:1 step:7495[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:7500[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:1 step:7505[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:1 step:7510[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:1 step:7515[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:1 step:7520[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:7525[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:1 step:7530[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:7535[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:1 step:7540[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:1 step:7545[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:1 step:7550[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:1 step:7555[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:1 step:7560[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:7565[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:1 step:7570[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:1 step:7575[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:1 step:7580[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:1 step:7585[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:7590[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:1 step:7595[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:1 step:7600[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:7605[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:1 step:7610[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:7615[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:7620[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:1 step:7625[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:1 step:7630[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:1 step:7635[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:1 step:7640[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:7645[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:1 step:7650[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:1 step:7655[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:1 step:7660[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:1 step:7665[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:1 step:7670[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:1 step:7675[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:1 step:7680[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:1 step:7685[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:1 step:7690[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:1 step:7695[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:1 step:7700[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:1 step:7705[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:1 step:7710[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:7715[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:1 step:7720[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:1 step:7725[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:7730[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:1 step:7735[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:1 step:7740[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:1 step:7745[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:1 step:7750[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:7755[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:1 step:7760[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:1 step:7765[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:1 step:7770[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:1 step:7775[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:1 step:7780[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:1 step:7785[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:1 step:7790[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:1 step:7795[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:1 step:7800[D loss: 0.999982] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:7805[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:1 step:7810[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:1 step:7815[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:1 step:7820[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:1 step:7825[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:1 step:7830[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:7835[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:1 step:7840[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:7845[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:1 step:7850[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:7855[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:1 step:7860[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:7865[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:1 step:7870[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:7875[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:1 step:7880[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:1 step:7885[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:1 step:7890[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:1 step:7895[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:1 step:7900[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:1 step:7905[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:1 step:7910[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:7915[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:1 step:7920[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:1 step:7925[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:7930[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:1 step:7935[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:1 step:7940[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:1 step:7945[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:1 step:7950[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:7955[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:1 step:7960[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:7965[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:7970[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:1 step:7975[D loss: 0.999995] [G loss: 1.000064]\n",
      "epoch:1 step:7980[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:1 step:7985[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:1 step:7990[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:1 step:7995[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:1 step:8000[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:8005[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:1 step:8010[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:8015[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:1 step:8020[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:8025[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:1 step:8030[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:1 step:8035[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:1 step:8040[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:1 step:8045[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:1 step:8050[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:8055[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:1 step:8060[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:1 step:8065[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:1 step:8070[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:8075[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:1 step:8080[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:1 step:8085[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:1 step:8090[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:1 step:8095[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:1 step:8100[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:8105[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:1 step:8110[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:1 step:8115[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:1 step:8120[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:1 step:8125[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:8130[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:1 step:8135[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:8140[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:1 step:8145[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:1 step:8150[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:1 step:8155[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:8160[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:1 step:8165[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:1 step:8170[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:1 step:8175[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:1 step:8180[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:1 step:8185[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:1 step:8190[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:1 step:8195[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:8200[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:8205[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:1 step:8210[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:1 step:8215[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:8220[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:8225[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:1 step:8230[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:1 step:8235[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:1 step:8240[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:8245[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:1 step:8250[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:1 step:8255[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:1 step:8260[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:8265[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:8270[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:8275[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:1 step:8280[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:1 step:8285[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:1 step:8290[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:1 step:8295[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:1 step:8300[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:1 step:8305[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:1 step:8310[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:1 step:8315[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:1 step:8320[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:1 step:8325[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:8330[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:8335[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:1 step:8340[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:1 step:8345[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:1 step:8350[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:1 step:8355[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:8360[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:8365[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:1 step:8370[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:1 step:8375[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:1 step:8380[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:8385[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:1 step:8390[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:1 step:8395[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:1 step:8400[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:1 step:8405[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:1 step:8410[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:8415[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:1 step:8420[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:1 step:8425[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:1 step:8430[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:1 step:8435[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:1 step:8440[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:1 step:8445[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:8450[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:1 step:8455[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:1 step:8460[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:8465[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:1 step:8470[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:1 step:8475[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:1 step:8480[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:1 step:8485[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:1 step:8490[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:1 step:8495[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:1 step:8500[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:1 step:8505[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:1 step:8510[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:1 step:8515[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:1 step:8520[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:8525[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:1 step:8530[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:1 step:8535[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:8540[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:8545[D loss: 0.999985] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:8550[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:1 step:8555[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:1 step:8560[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:1 step:8565[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:1 step:8570[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:1 step:8575[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:1 step:8580[D loss: 0.999980] [G loss: 1.000100]\n",
      "epoch:1 step:8585[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:1 step:8590[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:1 step:8595[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:8600[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:1 step:8605[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:8610[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:1 step:8615[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:1 step:8620[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:1 step:8625[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:1 step:8630[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:8635[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:1 step:8640[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:1 step:8645[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:8650[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:1 step:8655[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:1 step:8660[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:1 step:8665[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:1 step:8670[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:1 step:8675[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:1 step:8680[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:1 step:8685[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:1 step:8690[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:1 step:8695[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:1 step:8700[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:8705[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:1 step:8710[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:1 step:8715[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:1 step:8720[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:1 step:8725[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:1 step:8730[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:1 step:8735[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:1 step:8740[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:1 step:8745[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:1 step:8750[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:8755[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:8760[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:1 step:8765[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:1 step:8770[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:1 step:8775[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:1 step:8780[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:1 step:8785[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:1 step:8790[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:1 step:8795[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:1 step:8800[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:8805[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:1 step:8810[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:1 step:8815[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:1 step:8820[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:1 step:8825[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:1 step:8830[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:1 step:8835[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:1 step:8840[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:1 step:8845[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:1 step:8850[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:1 step:8855[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:1 step:8860[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:1 step:8865[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:1 step:8870[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:8875[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:1 step:8880[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:1 step:8885[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:1 step:8890[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:8895[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:1 step:8900[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:8905[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:1 step:8910[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:1 step:8915[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:1 step:8920[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:1 step:8925[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:1 step:8930[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:1 step:8935[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:8940[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:8945[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:1 step:8950[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:1 step:8955[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:1 step:8960[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:1 step:8965[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:1 step:8970[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:1 step:8975[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:1 step:8980[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:1 step:8985[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:1 step:8990[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:1 step:8995[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:1 step:9000[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:9005[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:1 step:9010[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:9015[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:1 step:9020[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:1 step:9025[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:1 step:9030[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:1 step:9035[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:1 step:9040[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:1 step:9045[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:1 step:9050[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:1 step:9055[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:1 step:9060[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:1 step:9065[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:1 step:9070[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:1 step:9075[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:1 step:9080[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:1 step:9085[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:1 step:9090[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:1 step:9095[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:1 step:9100[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:1 step:9105[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:1 step:9110[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:1 step:9115[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:1 step:9120[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:1 step:9125[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:1 step:9130[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:1 step:9135[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:9140[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:1 step:9145[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:1 step:9150[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:1 step:9155[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:1 step:9160[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:1 step:9165[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:1 step:9170[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:1 step:9175[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:9180[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:1 step:9185[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:1 step:9190[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:1 step:9195[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:1 step:9200[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:1 step:9205[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:1 step:9210[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:1 step:9215[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:1 step:9220[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:1 step:9225[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:1 step:9230[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:1 step:9235[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:1 step:9240[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:1 step:9245[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:1 step:9250[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:1 step:9255[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:1 step:9260[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:9265[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:1 step:9270[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:1 step:9275[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:1 step:9280[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:1 step:9285[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:1 step:9290[D loss: 0.999979] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:9295[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:1 step:9300[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:1 step:9305[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:1 step:9310[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:1 step:9315[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:1 step:9320[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:1 step:9325[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:1 step:9330[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:1 step:9335[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:1 step:9340[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:1 step:9345[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:1 step:9350[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:1 step:9355[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:1 step:9360[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:1 step:9365[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:1 step:9370[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:9375[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:2 step:9380[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:2 step:9385[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:2 step:9390[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:2 step:9395[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:2 step:9400[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:9405[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:2 step:9410[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:2 step:9415[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:2 step:9420[D loss: 0.999977] [G loss: 1.000098]\n",
      "epoch:2 step:9425[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:2 step:9430[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:2 step:9435[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:2 step:9440[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:2 step:9445[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:2 step:9450[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:2 step:9455[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:2 step:9460[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:2 step:9465[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:9470[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:2 step:9475[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:2 step:9480[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:9485[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:9490[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:2 step:9495[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:2 step:9500[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:2 step:9505[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:2 step:9510[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:2 step:9515[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:2 step:9520[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:2 step:9525[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:2 step:9530[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:9535[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:2 step:9540[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:9545[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:2 step:9550[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:9555[D loss: 1.000007] [G loss: 1.000031]\n",
      "epoch:2 step:9560[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:2 step:9565[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:2 step:9570[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:2 step:9575[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:2 step:9580[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:2 step:9585[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:2 step:9590[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:2 step:9595[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:9600[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:2 step:9605[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:2 step:9610[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:9615[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:2 step:9620[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:2 step:9625[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:2 step:9630[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:2 step:9635[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:2 step:9640[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:2 step:9645[D loss: 0.999991] [G loss: 1.000079]\n",
      "epoch:2 step:9650[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:2 step:9655[D loss: 0.999980] [G loss: 1.000108]\n",
      "epoch:2 step:9660[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:2 step:9665[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:2 step:9670[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:2 step:9675[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:2 step:9680[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:2 step:9685[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:2 step:9690[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:2 step:9695[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:2 step:9700[D loss: 1.000004] [G loss: 1.000042]\n",
      "epoch:2 step:9705[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:2 step:9710[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:2 step:9715[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:2 step:9720[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:2 step:9725[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:2 step:9730[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:9735[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:2 step:9740[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:2 step:9745[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:2 step:9750[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:2 step:9755[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:2 step:9760[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:2 step:9765[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:2 step:9770[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:2 step:9775[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:2 step:9780[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:2 step:9785[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:2 step:9790[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:2 step:9795[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:2 step:9800[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:2 step:9805[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:2 step:9810[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:2 step:9815[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:2 step:9820[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:2 step:9825[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:2 step:9830[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:2 step:9835[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:2 step:9840[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:9845[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:2 step:9850[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:2 step:9855[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:2 step:9860[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:2 step:9865[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:2 step:9870[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:2 step:9875[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:2 step:9880[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:2 step:9885[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:9890[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:2 step:9895[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:2 step:9900[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:2 step:9905[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:2 step:9910[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:2 step:9915[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:2 step:9920[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:9925[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:2 step:9930[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:9935[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:2 step:9940[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:2 step:9945[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:2 step:9950[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:2 step:9955[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:2 step:9960[D loss: 1.000008] [G loss: 1.000048]\n",
      "epoch:2 step:9965[D loss: 0.999981] [G loss: 1.000100]\n",
      "epoch:2 step:9970[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:9975[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:2 step:9980[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:2 step:9985[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:2 step:9990[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:2 step:9995[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:2 step:10000[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:2 step:10005[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:2 step:10010[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:2 step:10015[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:2 step:10020[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:10025[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:2 step:10030[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:10035[D loss: 0.999983] [G loss: 1.000053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10040[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:2 step:10045[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:2 step:10050[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:10055[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:2 step:10060[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:10065[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:2 step:10070[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:2 step:10075[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:2 step:10080[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:10085[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:10090[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:10095[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:10100[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:10105[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:2 step:10110[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:2 step:10115[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:2 step:10120[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:2 step:10125[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:2 step:10130[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:2 step:10135[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:2 step:10140[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:2 step:10145[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:10150[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:2 step:10155[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:2 step:10160[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:2 step:10165[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:2 step:10170[D loss: 0.999994] [G loss: 1.000056]\n",
      "epoch:2 step:10175[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:2 step:10180[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:2 step:10185[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:2 step:10190[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:2 step:10195[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:2 step:10200[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:2 step:10205[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:2 step:10210[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:2 step:10215[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:2 step:10220[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:10225[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:2 step:10230[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:2 step:10235[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:10240[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:10245[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:2 step:10250[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:2 step:10255[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:2 step:10260[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:2 step:10265[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:2 step:10270[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:2 step:10275[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:2 step:10280[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:2 step:10285[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:2 step:10290[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:2 step:10295[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:2 step:10300[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:2 step:10305[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:2 step:10310[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:2 step:10315[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:2 step:10320[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:2 step:10325[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:2 step:10330[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:10335[D loss: 1.000000] [G loss: 1.000055]\n",
      "epoch:2 step:10340[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:2 step:10345[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:2 step:10350[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:2 step:10355[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:2 step:10360[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:2 step:10365[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:2 step:10370[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:2 step:10375[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:2 step:10380[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:2 step:10385[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:2 step:10390[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:2 step:10395[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:10400[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:2 step:10405[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:2 step:10410[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:2 step:10415[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:2 step:10420[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:2 step:10425[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:2 step:10430[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:10435[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:2 step:10440[D loss: 1.000000] [G loss: 1.000082]\n",
      "epoch:2 step:10445[D loss: 0.999991] [G loss: 1.000069]\n",
      "epoch:2 step:10450[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:2 step:10455[D loss: 0.999997] [G loss: 1.000093]\n",
      "epoch:2 step:10460[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:2 step:10465[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:2 step:10470[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:2 step:10475[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:2 step:10480[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:2 step:10485[D loss: 0.999971] [G loss: 1.000107]\n",
      "epoch:2 step:10490[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:2 step:10495[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:2 step:10500[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:2 step:10505[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:2 step:10510[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:10515[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:2 step:10520[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:2 step:10525[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:2 step:10530[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:2 step:10535[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:2 step:10540[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:2 step:10545[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:2 step:10550[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:2 step:10555[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:2 step:10560[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:2 step:10565[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:2 step:10570[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:2 step:10575[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:2 step:10580[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:2 step:10585[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:2 step:10590[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:2 step:10595[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:2 step:10600[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:2 step:10605[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:2 step:10610[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:2 step:10615[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:2 step:10620[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:2 step:10625[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:2 step:10630[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:2 step:10635[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:2 step:10640[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:2 step:10645[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:2 step:10650[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:2 step:10655[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:2 step:10660[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:2 step:10665[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:2 step:10670[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:2 step:10675[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:2 step:10680[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:2 step:10685[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:2 step:10690[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:2 step:10695[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:2 step:10700[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:2 step:10705[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:2 step:10710[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:2 step:10715[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:2 step:10720[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:2 step:10725[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:2 step:10730[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:2 step:10735[D loss: 1.000008] [G loss: 1.000007]\n",
      "epoch:2 step:10740[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:2 step:10745[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:2 step:10750[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:2 step:10755[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:2 step:10760[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:2 step:10765[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:2 step:10770[D loss: 0.999971] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:10775[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:10780[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:2 step:10785[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:2 step:10790[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:2 step:10795[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:2 step:10800[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:2 step:10805[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:2 step:10810[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:2 step:10815[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:10820[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:2 step:10825[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:2 step:10830[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:2 step:10835[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:2 step:10840[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:10845[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:2 step:10850[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:10855[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:2 step:10860[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:2 step:10865[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:10870[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:10875[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:2 step:10880[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:2 step:10885[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:2 step:10890[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:2 step:10895[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:2 step:10900[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:2 step:10905[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:10910[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:2 step:10915[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:2 step:10920[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:2 step:10925[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:2 step:10930[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:2 step:10935[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:2 step:10940[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:2 step:10945[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:2 step:10950[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:2 step:10955[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:2 step:10960[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:2 step:10965[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:10970[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:10975[D loss: 0.999991] [G loss: 1.000101]\n",
      "epoch:2 step:10980[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:2 step:10985[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:2 step:10990[D loss: 0.999968] [G loss: 1.000093]\n",
      "epoch:2 step:10995[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:2 step:11000[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:2 step:11005[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:2 step:11010[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:11015[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:2 step:11020[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:2 step:11025[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:2 step:11030[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:11035[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:2 step:11040[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:2 step:11045[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:2 step:11050[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:2 step:11055[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:2 step:11060[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:2 step:11065[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:2 step:11070[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:2 step:11075[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:2 step:11080[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:2 step:11085[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:2 step:11090[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:2 step:11095[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:11100[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:2 step:11105[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:2 step:11110[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:2 step:11115[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:11120[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:2 step:11125[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:2 step:11130[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:2 step:11135[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:2 step:11140[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:2 step:11145[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:2 step:11150[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:2 step:11155[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:2 step:11160[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:2 step:11165[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:2 step:11170[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:2 step:11175[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:2 step:11180[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:2 step:11185[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:2 step:11190[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:2 step:11195[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:11200[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:2 step:11205[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:2 step:11210[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:2 step:11215[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:2 step:11220[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:2 step:11225[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:2 step:11230[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:2 step:11235[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:2 step:11240[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:2 step:11245[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:2 step:11250[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:2 step:11255[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:2 step:11260[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:2 step:11265[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:2 step:11270[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:2 step:11275[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:2 step:11280[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:2 step:11285[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:11290[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:2 step:11295[D loss: 0.999996] [G loss: 1.000085]\n",
      "epoch:2 step:11300[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:2 step:11305[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:2 step:11310[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:2 step:11315[D loss: 1.000008] [G loss: 1.000057]\n",
      "epoch:2 step:11320[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:2 step:11325[D loss: 1.000005] [G loss: 1.000025]\n",
      "epoch:2 step:11330[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:2 step:11335[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:2 step:11340[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:2 step:11345[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:2 step:11350[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:2 step:11355[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:2 step:11360[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:2 step:11365[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:2 step:11370[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:2 step:11375[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:2 step:11380[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:2 step:11385[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:2 step:11390[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:2 step:11395[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:2 step:11400[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:2 step:11405[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:2 step:11410[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:2 step:11415[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:11420[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:2 step:11425[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:2 step:11430[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:2 step:11435[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:2 step:11440[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:2 step:11445[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:2 step:11450[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:2 step:11455[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:2 step:11460[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:11465[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:2 step:11470[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:2 step:11475[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:2 step:11480[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:2 step:11485[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:2 step:11490[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:2 step:11495[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:2 step:11500[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:2 step:11505[D loss: 0.999993] [G loss: 1.000051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:11510[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:2 step:11515[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:2 step:11520[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:2 step:11525[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:2 step:11530[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:2 step:11535[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:2 step:11540[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:2 step:11545[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:2 step:11550[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:2 step:11555[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:2 step:11560[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:2 step:11565[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:2 step:11570[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:2 step:11575[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:2 step:11580[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:2 step:11585[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:11590[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:2 step:11595[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:2 step:11600[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:11605[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:2 step:11610[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:2 step:11615[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:2 step:11620[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:2 step:11625[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:2 step:11630[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:2 step:11635[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:2 step:11640[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:11645[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:2 step:11650[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:2 step:11655[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:2 step:11660[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:2 step:11665[D loss: 1.000009] [G loss: 1.000055]\n",
      "epoch:2 step:11670[D loss: 0.999979] [G loss: 1.000093]\n",
      "epoch:2 step:11675[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:2 step:11680[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:2 step:11685[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:2 step:11690[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:2 step:11695[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:2 step:11700[D loss: 0.999985] [G loss: 1.000096]\n",
      "epoch:2 step:11705[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:2 step:11710[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:2 step:11715[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:2 step:11720[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:2 step:11725[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:2 step:11730[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:2 step:11735[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:2 step:11740[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:2 step:11745[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:2 step:11750[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:2 step:11755[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:2 step:11760[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:2 step:11765[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:2 step:11770[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:2 step:11775[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:2 step:11780[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:2 step:11785[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:2 step:11790[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:2 step:11795[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:2 step:11800[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:2 step:11805[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:2 step:11810[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:2 step:11815[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:2 step:11820[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:2 step:11825[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:2 step:11830[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:2 step:11835[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:2 step:11840[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:2 step:11845[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:2 step:11850[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:2 step:11855[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:2 step:11860[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:11865[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:2 step:11870[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:2 step:11875[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:2 step:11880[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:2 step:11885[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:2 step:11890[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:2 step:11895[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:2 step:11900[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:2 step:11905[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:11910[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:2 step:11915[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:2 step:11920[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:2 step:11925[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:2 step:11930[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:2 step:11935[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:2 step:11940[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:2 step:11945[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:2 step:11950[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:2 step:11955[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:2 step:11960[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:11965[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:2 step:11970[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:2 step:11975[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:2 step:11980[D loss: 0.999995] [G loss: 1.000080]\n",
      "epoch:2 step:11985[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:2 step:11990[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:2 step:11995[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:2 step:12000[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:2 step:12005[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:2 step:12010[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:2 step:12015[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:2 step:12020[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:2 step:12025[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:2 step:12030[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:2 step:12035[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:2 step:12040[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:2 step:12045[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:2 step:12050[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:2 step:12055[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:2 step:12060[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:2 step:12065[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:2 step:12070[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:2 step:12075[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:12080[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:2 step:12085[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:2 step:12090[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:2 step:12095[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:2 step:12100[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:2 step:12105[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:2 step:12110[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:2 step:12115[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:2 step:12120[D loss: 0.999989] [G loss: 1.000081]\n",
      "epoch:2 step:12125[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:2 step:12130[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:2 step:12135[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:2 step:12140[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:2 step:12145[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:2 step:12150[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:2 step:12155[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:2 step:12160[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:2 step:12165[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:2 step:12170[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:2 step:12175[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:12180[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:2 step:12185[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:2 step:12190[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:2 step:12195[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:2 step:12200[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:2 step:12205[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:2 step:12210[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:2 step:12215[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:2 step:12220[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:2 step:12225[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:2 step:12230[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:2 step:12235[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:2 step:12240[D loss: 0.999973] [G loss: 1.000079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:12245[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:2 step:12250[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:12255[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:2 step:12260[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:2 step:12265[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:2 step:12270[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:2 step:12275[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:2 step:12280[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:2 step:12285[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:2 step:12290[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:2 step:12295[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:12300[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:2 step:12305[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:2 step:12310[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:2 step:12315[D loss: 1.000002] [G loss: 1.000077]\n",
      "epoch:2 step:12320[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:2 step:12325[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:2 step:12330[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:2 step:12335[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:2 step:12340[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:2 step:12345[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:2 step:12350[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:2 step:12355[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:2 step:12360[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:2 step:12365[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:2 step:12370[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:2 step:12375[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:2 step:12380[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:2 step:12385[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:2 step:12390[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:2 step:12395[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:2 step:12400[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:2 step:12405[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:2 step:12410[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:2 step:12415[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:2 step:12420[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:2 step:12425[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:2 step:12430[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:2 step:12435[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:2 step:12440[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:2 step:12445[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:2 step:12450[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:2 step:12455[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:2 step:12460[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:2 step:12465[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:2 step:12470[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:2 step:12475[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:12480[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:2 step:12485[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:2 step:12490[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:2 step:12495[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:2 step:12500[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:2 step:12505[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:2 step:12510[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:2 step:12515[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:2 step:12520[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:2 step:12525[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:2 step:12530[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:2 step:12535[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:2 step:12540[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:2 step:12545[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:2 step:12550[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:2 step:12555[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:2 step:12560[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:2 step:12565[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:2 step:12570[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:2 step:12575[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:2 step:12580[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:2 step:12585[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:2 step:12590[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:2 step:12595[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:2 step:12600[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:2 step:12605[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:2 step:12610[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:2 step:12615[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:12620[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:2 step:12625[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:2 step:12630[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:2 step:12635[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:2 step:12640[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:2 step:12645[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:2 step:12650[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:2 step:12655[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:2 step:12660[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:2 step:12665[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:2 step:12670[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:2 step:12675[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:2 step:12680[D loss: 0.999970] [G loss: 1.000107]\n",
      "epoch:2 step:12685[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:2 step:12690[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:2 step:12695[D loss: 0.999995] [G loss: 1.000014]\n",
      "epoch:2 step:12700[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:2 step:12705[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:2 step:12710[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:2 step:12715[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:2 step:12720[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:2 step:12725[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:2 step:12730[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:2 step:12735[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:2 step:12740[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:2 step:12745[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:2 step:12750[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:12755[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:2 step:12760[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:2 step:12765[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:2 step:12770[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:2 step:12775[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:2 step:12780[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:2 step:12785[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:2 step:12790[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:2 step:12795[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:2 step:12800[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:2 step:12805[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:2 step:12810[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:2 step:12815[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:2 step:12820[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:2 step:12825[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:12830[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:2 step:12835[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:2 step:12840[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:2 step:12845[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:2 step:12850[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:2 step:12855[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:2 step:12860[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:2 step:12865[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:2 step:12870[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:2 step:12875[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:2 step:12880[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:2 step:12885[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:2 step:12890[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:2 step:12895[D loss: 0.999959] [G loss: 1.000103]\n",
      "epoch:2 step:12900[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:2 step:12905[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:2 step:12910[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:2 step:12915[D loss: 1.000022] [G loss: 1.000022]\n",
      "epoch:2 step:12920[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:2 step:12925[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:2 step:12930[D loss: 0.999996] [G loss: 1.000063]\n",
      "epoch:2 step:12935[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:2 step:12940[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:2 step:12945[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:2 step:12950[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:2 step:12955[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:2 step:12960[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:12965[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:2 step:12970[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:2 step:12975[D loss: 0.999982] [G loss: 1.000094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:12980[D loss: 0.999991] [G loss: 1.000100]\n",
      "epoch:2 step:12985[D loss: 0.999973] [G loss: 1.000111]\n",
      "epoch:2 step:12990[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:2 step:12995[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:2 step:13000[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:2 step:13005[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:2 step:13010[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:2 step:13015[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:2 step:13020[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:2 step:13025[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:2 step:13030[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:2 step:13035[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:2 step:13040[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:2 step:13045[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:2 step:13050[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:2 step:13055[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:2 step:13060[D loss: 0.999985] [G loss: 1.000094]\n",
      "epoch:2 step:13065[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:2 step:13070[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:2 step:13075[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:2 step:13080[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:2 step:13085[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:13090[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:2 step:13095[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:2 step:13100[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:2 step:13105[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:2 step:13110[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:2 step:13115[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:13120[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:2 step:13125[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:2 step:13130[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:2 step:13135[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:2 step:13140[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:2 step:13145[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:2 step:13150[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:2 step:13155[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:2 step:13160[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:2 step:13165[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:2 step:13170[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:2 step:13175[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:2 step:13180[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:2 step:13185[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:2 step:13190[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:2 step:13195[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:2 step:13200[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:2 step:13205[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:2 step:13210[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:2 step:13215[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:2 step:13220[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:2 step:13225[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:2 step:13230[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:2 step:13235[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:2 step:13240[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:2 step:13245[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:2 step:13250[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:2 step:13255[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:2 step:13260[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:2 step:13265[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:2 step:13270[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:2 step:13275[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:2 step:13280[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:2 step:13285[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:2 step:13290[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:2 step:13295[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:2 step:13300[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:2 step:13305[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:2 step:13310[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:2 step:13315[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:2 step:13320[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:2 step:13325[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:2 step:13330[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:2 step:13335[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:2 step:13340[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:2 step:13345[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:2 step:13350[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:2 step:13355[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:2 step:13360[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:2 step:13365[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:2 step:13370[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:2 step:13375[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:2 step:13380[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:2 step:13385[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:2 step:13390[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:2 step:13395[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:2 step:13400[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:2 step:13405[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:2 step:13410[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:2 step:13415[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:13420[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:2 step:13425[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:2 step:13430[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:2 step:13435[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:2 step:13440[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:2 step:13445[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:2 step:13450[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:2 step:13455[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:2 step:13460[D loss: 0.999974] [G loss: 1.000113]\n",
      "epoch:2 step:13465[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:2 step:13470[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:2 step:13475[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:2 step:13480[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:2 step:13485[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:2 step:13490[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:2 step:13495[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:2 step:13500[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:2 step:13505[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:2 step:13510[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:2 step:13515[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:2 step:13520[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:2 step:13525[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:2 step:13530[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:2 step:13535[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:2 step:13540[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:2 step:13545[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:2 step:13550[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:2 step:13555[D loss: 0.999975] [G loss: 1.000111]\n",
      "epoch:2 step:13560[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:2 step:13565[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:2 step:13570[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:2 step:13575[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:2 step:13580[D loss: 0.999996] [G loss: 1.000060]\n",
      "epoch:2 step:13585[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:2 step:13590[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:2 step:13595[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:2 step:13600[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:2 step:13605[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:2 step:13610[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:2 step:13615[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:13620[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:2 step:13625[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:2 step:13630[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:2 step:13635[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:2 step:13640[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:2 step:13645[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:2 step:13650[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:2 step:13655[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:2 step:13660[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:2 step:13665[D loss: 0.999979] [G loss: 1.000105]\n",
      "epoch:2 step:13670[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:2 step:13675[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:2 step:13680[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:2 step:13685[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:2 step:13690[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:2 step:13695[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:2 step:13700[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:2 step:13705[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:2 step:13710[D loss: 0.999980] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:13715[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:2 step:13720[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:2 step:13725[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:2 step:13730[D loss: 0.999999] [G loss: 1.000018]\n",
      "epoch:2 step:13735[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:2 step:13740[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:2 step:13745[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:2 step:13750[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:2 step:13755[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:2 step:13760[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:2 step:13765[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:2 step:13770[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:2 step:13775[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:2 step:13780[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:2 step:13785[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:2 step:13790[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:2 step:13795[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:2 step:13800[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:2 step:13805[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:2 step:13810[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:2 step:13815[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:2 step:13820[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:2 step:13825[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:2 step:13830[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:2 step:13835[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:2 step:13840[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:2 step:13845[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:2 step:13850[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:2 step:13855[D loss: 0.999979] [G loss: 1.000102]\n",
      "epoch:2 step:13860[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:2 step:13865[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:2 step:13870[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:2 step:13875[D loss: 0.999980] [G loss: 1.000095]\n",
      "epoch:2 step:13880[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:2 step:13885[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:2 step:13890[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:2 step:13895[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:2 step:13900[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:2 step:13905[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:2 step:13910[D loss: 1.000003] [G loss: 1.000050]\n",
      "epoch:2 step:13915[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:2 step:13920[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:2 step:13925[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:2 step:13930[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:2 step:13935[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:2 step:13940[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:2 step:13945[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:2 step:13950[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:2 step:13955[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:2 step:13960[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:2 step:13965[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:2 step:13970[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:2 step:13975[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:2 step:13980[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:2 step:13985[D loss: 0.999989] [G loss: 1.000085]\n",
      "epoch:2 step:13990[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:2 step:13995[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:2 step:14000[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:2 step:14005[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:2 step:14010[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:2 step:14015[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:2 step:14020[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:2 step:14025[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:2 step:14030[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:2 step:14035[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:2 step:14040[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:2 step:14045[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:2 step:14050[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:2 step:14055[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:3 step:14060[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:3 step:14065[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:3 step:14070[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:3 step:14075[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:3 step:14080[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:3 step:14085[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:3 step:14090[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:3 step:14095[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:3 step:14100[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:3 step:14105[D loss: 1.000000] [G loss: 1.000090]\n",
      "epoch:3 step:14110[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:3 step:14115[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:3 step:14120[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:3 step:14125[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:3 step:14130[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:3 step:14135[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:3 step:14140[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:3 step:14145[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:3 step:14150[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:3 step:14155[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:3 step:14160[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:3 step:14165[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:3 step:14170[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:3 step:14175[D loss: 0.999981] [G loss: 1.000103]\n",
      "epoch:3 step:14180[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:3 step:14185[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:3 step:14190[D loss: 0.999982] [G loss: 1.000084]\n",
      "epoch:3 step:14195[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:3 step:14200[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:3 step:14205[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:3 step:14210[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:3 step:14215[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:3 step:14220[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:3 step:14225[D loss: 0.999982] [G loss: 1.000103]\n",
      "epoch:3 step:14230[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:3 step:14235[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:3 step:14240[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:3 step:14245[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:14250[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:3 step:14255[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:3 step:14260[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:3 step:14265[D loss: 0.999992] [G loss: 1.000083]\n",
      "epoch:3 step:14270[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:3 step:14275[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:14280[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:3 step:14285[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:3 step:14290[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:3 step:14295[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:3 step:14300[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:3 step:14305[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:3 step:14310[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:14315[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:3 step:14320[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:3 step:14325[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:3 step:14330[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:3 step:14335[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:3 step:14340[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:3 step:14345[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:3 step:14350[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:3 step:14355[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:3 step:14360[D loss: 0.999983] [G loss: 1.000106]\n",
      "epoch:3 step:14365[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:3 step:14370[D loss: 0.999997] [G loss: 1.000067]\n",
      "epoch:3 step:14375[D loss: 1.000011] [G loss: 1.000036]\n",
      "epoch:3 step:14380[D loss: 0.999940] [G loss: 1.000110]\n",
      "epoch:3 step:14385[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:3 step:14390[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:3 step:14395[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:3 step:14400[D loss: 1.000027] [G loss: 1.000026]\n",
      "epoch:3 step:14405[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:3 step:14410[D loss: 0.999953] [G loss: 1.000133]\n",
      "epoch:3 step:14415[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:3 step:14420[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:3 step:14425[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:3 step:14430[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:3 step:14435[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:3 step:14440[D loss: 0.999954] [G loss: 1.000112]\n",
      "epoch:3 step:14445[D loss: 0.999975] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:14450[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:3 step:14455[D loss: 0.999979] [G loss: 1.000101]\n",
      "epoch:3 step:14460[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:3 step:14465[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:3 step:14470[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:3 step:14475[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:3 step:14480[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:3 step:14485[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:3 step:14490[D loss: 0.999964] [G loss: 1.000102]\n",
      "epoch:3 step:14495[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:3 step:14500[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:3 step:14505[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:3 step:14510[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:3 step:14515[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:3 step:14520[D loss: 0.999983] [G loss: 1.000091]\n",
      "epoch:3 step:14525[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:3 step:14530[D loss: 0.999988] [G loss: 1.000107]\n",
      "epoch:3 step:14535[D loss: 0.999977] [G loss: 1.000102]\n",
      "epoch:3 step:14540[D loss: 0.999981] [G loss: 1.000109]\n",
      "epoch:3 step:14545[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:14550[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:3 step:14555[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:3 step:14560[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:3 step:14565[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:3 step:14570[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:3 step:14575[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:3 step:14580[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:3 step:14585[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:3 step:14590[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:3 step:14595[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:3 step:14600[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:3 step:14605[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:3 step:14610[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:3 step:14615[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:3 step:14620[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:3 step:14625[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:3 step:14630[D loss: 0.999991] [G loss: 1.000074]\n",
      "epoch:3 step:14635[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:3 step:14640[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:3 step:14645[D loss: 1.000005] [G loss: 1.000055]\n",
      "epoch:3 step:14650[D loss: 0.999963] [G loss: 1.000120]\n",
      "epoch:3 step:14655[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:3 step:14660[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:3 step:14665[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:3 step:14670[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:3 step:14675[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:3 step:14680[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:3 step:14685[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:3 step:14690[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:3 step:14695[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:14700[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:3 step:14705[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:3 step:14710[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:3 step:14715[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:3 step:14720[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:3 step:14725[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:3 step:14730[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:3 step:14735[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:3 step:14740[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:3 step:14745[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:3 step:14750[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:14755[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:3 step:14760[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:3 step:14765[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:3 step:14770[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:3 step:14775[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:3 step:14780[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:3 step:14785[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:3 step:14790[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:3 step:14795[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:3 step:14800[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:3 step:14805[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:3 step:14810[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:3 step:14815[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:3 step:14820[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:3 step:14825[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:3 step:14830[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:3 step:14835[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:3 step:14840[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:3 step:14845[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:14850[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:3 step:14855[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:3 step:14860[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:3 step:14865[D loss: 0.999990] [G loss: 1.000101]\n",
      "epoch:3 step:14870[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:3 step:14875[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:3 step:14880[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:3 step:14885[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:3 step:14890[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:3 step:14895[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:3 step:14900[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:3 step:14905[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:3 step:14910[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:3 step:14915[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:3 step:14920[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:3 step:14925[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:3 step:14930[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:14935[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:3 step:14940[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:14945[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:3 step:14950[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:3 step:14955[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:3 step:14960[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:3 step:14965[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:3 step:14970[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:3 step:14975[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:3 step:14980[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:3 step:14985[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:3 step:14990[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:3 step:14995[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:3 step:15000[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:3 step:15005[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:3 step:15010[D loss: 0.999989] [G loss: 1.000088]\n",
      "epoch:3 step:15015[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:3 step:15020[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:3 step:15025[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:3 step:15030[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:3 step:15035[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:3 step:15040[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:3 step:15045[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:3 step:15050[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:3 step:15055[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:3 step:15060[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:3 step:15065[D loss: 0.999967] [G loss: 1.000105]\n",
      "epoch:3 step:15070[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:3 step:15075[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:3 step:15080[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:3 step:15085[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:3 step:15090[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:3 step:15095[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:3 step:15100[D loss: 0.999971] [G loss: 1.000102]\n",
      "epoch:3 step:15105[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:3 step:15110[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:3 step:15115[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:3 step:15120[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:3 step:15125[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:3 step:15130[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:3 step:15135[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:3 step:15140[D loss: 0.999993] [G loss: 1.000104]\n",
      "epoch:3 step:15145[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:3 step:15150[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:3 step:15155[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:3 step:15160[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:3 step:15165[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:3 step:15170[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:3 step:15175[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:3 step:15180[D loss: 0.999983] [G loss: 1.000072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15185[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:3 step:15190[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:3 step:15195[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:3 step:15200[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:3 step:15205[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:3 step:15210[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:3 step:15215[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:3 step:15220[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:3 step:15225[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:3 step:15230[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:3 step:15235[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:3 step:15240[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:15245[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:3 step:15250[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:15255[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:3 step:15260[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:3 step:15265[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:3 step:15270[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:3 step:15275[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:3 step:15280[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:3 step:15285[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:3 step:15290[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:3 step:15295[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:3 step:15300[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:3 step:15305[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:3 step:15310[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:15315[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:15320[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:3 step:15325[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:3 step:15330[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:3 step:15335[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:3 step:15340[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:3 step:15345[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:3 step:15350[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:3 step:15355[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:3 step:15360[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:3 step:15365[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:3 step:15370[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:3 step:15375[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:3 step:15380[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:3 step:15385[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:15390[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:15395[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:15400[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:3 step:15405[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:3 step:15410[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:3 step:15415[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:3 step:15420[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:3 step:15425[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:3 step:15430[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:3 step:15435[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:3 step:15440[D loss: 0.999976] [G loss: 1.000099]\n",
      "epoch:3 step:15445[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:15450[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:3 step:15455[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:3 step:15460[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:3 step:15465[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:15470[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:3 step:15475[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:3 step:15480[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:3 step:15485[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:3 step:15490[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:3 step:15495[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:3 step:15500[D loss: 0.999984] [G loss: 1.000093]\n",
      "epoch:3 step:15505[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:3 step:15510[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:3 step:15515[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:3 step:15520[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:3 step:15525[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:15530[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:3 step:15535[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:3 step:15540[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:3 step:15545[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:3 step:15550[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:3 step:15555[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:3 step:15560[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:3 step:15565[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:3 step:15570[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:3 step:15575[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:3 step:15580[D loss: 1.000006] [G loss: 1.000009]\n",
      "epoch:3 step:15585[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:3 step:15590[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:15595[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:3 step:15600[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:3 step:15605[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:3 step:15610[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:3 step:15615[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:3 step:15620[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:3 step:15625[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:3 step:15630[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:3 step:15635[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:3 step:15640[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:3 step:15645[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:3 step:15650[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:3 step:15655[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:3 step:15660[D loss: 1.000036] [G loss: 1.000033]\n",
      "epoch:3 step:15665[D loss: 0.999997] [G loss: 1.000042]\n",
      "epoch:3 step:15670[D loss: 1.000006] [G loss: 1.000016]\n",
      "epoch:3 step:15675[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:3 step:15680[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:3 step:15685[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:3 step:15690[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:3 step:15695[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:3 step:15700[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:3 step:15705[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:3 step:15710[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:15715[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:3 step:15720[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:3 step:15725[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:3 step:15730[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:3 step:15735[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:3 step:15740[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:3 step:15745[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:15750[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:3 step:15755[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:15760[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:3 step:15765[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:3 step:15770[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:3 step:15775[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:3 step:15780[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:3 step:15785[D loss: 0.999988] [G loss: 1.000091]\n",
      "epoch:3 step:15790[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:3 step:15795[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:3 step:15800[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:3 step:15805[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:3 step:15810[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:3 step:15815[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:3 step:15820[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:15825[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:3 step:15830[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:15835[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:3 step:15840[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:3 step:15845[D loss: 0.999992] [G loss: 1.000088]\n",
      "epoch:3 step:15850[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:3 step:15855[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:3 step:15860[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:3 step:15865[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:3 step:15870[D loss: 0.999989] [G loss: 1.000097]\n",
      "epoch:3 step:15875[D loss: 0.999987] [G loss: 1.000111]\n",
      "epoch:3 step:15880[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:3 step:15885[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:3 step:15890[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:3 step:15895[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:3 step:15900[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:3 step:15905[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:3 step:15910[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:15915[D loss: 0.999968] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:15920[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:3 step:15925[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:3 step:15930[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:3 step:15935[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:3 step:15940[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:3 step:15945[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:3 step:15950[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:3 step:15955[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:3 step:15960[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:3 step:15965[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:3 step:15970[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:3 step:15975[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:3 step:15980[D loss: 0.999965] [G loss: 1.000111]\n",
      "epoch:3 step:15985[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:3 step:15990[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:3 step:15995[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:3 step:16000[D loss: 1.000007] [G loss: 1.000056]\n",
      "epoch:3 step:16005[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:3 step:16010[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:3 step:16015[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:3 step:16020[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:3 step:16025[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:3 step:16030[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:3 step:16035[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:3 step:16040[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:3 step:16045[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:3 step:16050[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:3 step:16055[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:3 step:16060[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:3 step:16065[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:3 step:16070[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:3 step:16075[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:16080[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:3 step:16085[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:3 step:16090[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:3 step:16095[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:3 step:16100[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:16105[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:3 step:16110[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:3 step:16115[D loss: 1.000031] [G loss: 1.000008]\n",
      "epoch:3 step:16120[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:3 step:16125[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:3 step:16130[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:3 step:16135[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:3 step:16140[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:3 step:16145[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:3 step:16150[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:3 step:16155[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:3 step:16160[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:3 step:16165[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:16170[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:3 step:16175[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:3 step:16180[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:16185[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:3 step:16190[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:16195[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:3 step:16200[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:3 step:16205[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:3 step:16210[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:3 step:16215[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:3 step:16220[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:3 step:16225[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:3 step:16230[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:3 step:16235[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:3 step:16240[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:3 step:16245[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:3 step:16250[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:16255[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:3 step:16260[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:3 step:16265[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:3 step:16270[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:3 step:16275[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:3 step:16280[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:16285[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:3 step:16290[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:3 step:16295[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:3 step:16300[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:3 step:16305[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:3 step:16310[D loss: 1.000003] [G loss: 1.000054]\n",
      "epoch:3 step:16315[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:3 step:16320[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:3 step:16325[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:3 step:16330[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:3 step:16335[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:3 step:16340[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:3 step:16345[D loss: 0.999978] [G loss: 1.000104]\n",
      "epoch:3 step:16350[D loss: 1.000027] [G loss: 1.000039]\n",
      "epoch:3 step:16355[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:3 step:16360[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:3 step:16365[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:3 step:16370[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:3 step:16375[D loss: 0.999989] [G loss: 1.000088]\n",
      "epoch:3 step:16380[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:3 step:16385[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:3 step:16390[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:3 step:16395[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:3 step:16400[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:3 step:16405[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:3 step:16410[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:3 step:16415[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:3 step:16420[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:16425[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:3 step:16430[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:16435[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:3 step:16440[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:3 step:16445[D loss: 0.999982] [G loss: 1.000089]\n",
      "epoch:3 step:16450[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:3 step:16455[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:3 step:16460[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:3 step:16465[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:3 step:16470[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:16475[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:3 step:16480[D loss: 1.000001] [G loss: 1.000066]\n",
      "epoch:3 step:16485[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:3 step:16490[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:3 step:16495[D loss: 0.999983] [G loss: 1.000094]\n",
      "epoch:3 step:16500[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:3 step:16505[D loss: 0.999982] [G loss: 1.000092]\n",
      "epoch:3 step:16510[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:3 step:16515[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:3 step:16520[D loss: 1.000007] [G loss: 1.000065]\n",
      "epoch:3 step:16525[D loss: 0.999962] [G loss: 1.000121]\n",
      "epoch:3 step:16530[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:3 step:16535[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:3 step:16540[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:3 step:16545[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:3 step:16550[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:3 step:16555[D loss: 0.999978] [G loss: 1.000098]\n",
      "epoch:3 step:16560[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:3 step:16565[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:3 step:16570[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:3 step:16575[D loss: 0.999987] [G loss: 1.000098]\n",
      "epoch:3 step:16580[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:3 step:16585[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:3 step:16590[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:3 step:16595[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:3 step:16600[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:3 step:16605[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:3 step:16610[D loss: 1.000004] [G loss: 1.000060]\n",
      "epoch:3 step:16615[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:3 step:16620[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:3 step:16625[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:3 step:16630[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:3 step:16635[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:3 step:16640[D loss: 1.000010] [G loss: 1.000039]\n",
      "epoch:3 step:16645[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:3 step:16650[D loss: 0.999970] [G loss: 1.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:16655[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:3 step:16660[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:16665[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:3 step:16670[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:3 step:16675[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:3 step:16680[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:3 step:16685[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:3 step:16690[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:3 step:16695[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:3 step:16700[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:3 step:16705[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:3 step:16710[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:3 step:16715[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:3 step:16720[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:3 step:16725[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:3 step:16730[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:3 step:16735[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:3 step:16740[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:3 step:16745[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:3 step:16750[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:3 step:16755[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:3 step:16760[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:3 step:16765[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:3 step:16770[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:3 step:16775[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:3 step:16780[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:3 step:16785[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:3 step:16790[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:3 step:16795[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:3 step:16800[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:3 step:16805[D loss: 1.000003] [G loss: 1.000067]\n",
      "epoch:3 step:16810[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:3 step:16815[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:3 step:16820[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:3 step:16825[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:3 step:16830[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:3 step:16835[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:3 step:16840[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:3 step:16845[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:3 step:16850[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:3 step:16855[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:3 step:16860[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:3 step:16865[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:3 step:16870[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:3 step:16875[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:3 step:16880[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:3 step:16885[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:3 step:16890[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:3 step:16895[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:3 step:16900[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:3 step:16905[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:3 step:16910[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:3 step:16915[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:3 step:16920[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:3 step:16925[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:3 step:16930[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:3 step:16935[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:3 step:16940[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:3 step:16945[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:3 step:16950[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:3 step:16955[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:3 step:16960[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:3 step:16965[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:3 step:16970[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:3 step:16975[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:3 step:16980[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:16985[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:3 step:16990[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:3 step:16995[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:3 step:17000[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:3 step:17005[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:3 step:17010[D loss: 0.999971] [G loss: 1.000102]\n",
      "epoch:3 step:17015[D loss: 0.999981] [G loss: 1.000108]\n",
      "epoch:3 step:17020[D loss: 0.999973] [G loss: 1.000113]\n",
      "epoch:3 step:17025[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:3 step:17030[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:3 step:17035[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:3 step:17040[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:3 step:17045[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:3 step:17050[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:3 step:17055[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:3 step:17060[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:3 step:17065[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:3 step:17070[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:3 step:17075[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:3 step:17080[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:3 step:17085[D loss: 0.999964] [G loss: 1.000113]\n",
      "epoch:3 step:17090[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:3 step:17095[D loss: 0.999957] [G loss: 1.000119]\n",
      "epoch:3 step:17100[D loss: 0.999966] [G loss: 1.000121]\n",
      "epoch:3 step:17105[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:3 step:17110[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:3 step:17115[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:3 step:17120[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:3 step:17125[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:3 step:17130[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:3 step:17135[D loss: 0.999979] [G loss: 1.000096]\n",
      "epoch:3 step:17140[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:3 step:17145[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:3 step:17150[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:3 step:17155[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:3 step:17160[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:3 step:17165[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:3 step:17170[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:3 step:17175[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:17180[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:3 step:17185[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:3 step:17190[D loss: 0.999985] [G loss: 1.000094]\n",
      "epoch:3 step:17195[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:3 step:17200[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:17205[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:3 step:17210[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:17215[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:3 step:17220[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:3 step:17225[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:17230[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:3 step:17235[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:3 step:17240[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:3 step:17245[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:3 step:17250[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:3 step:17255[D loss: 0.999990] [G loss: 1.000085]\n",
      "epoch:3 step:17260[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:3 step:17265[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:3 step:17270[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:3 step:17275[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:3 step:17280[D loss: 0.999999] [G loss: 1.000067]\n",
      "epoch:3 step:17285[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:3 step:17290[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:3 step:17295[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:3 step:17300[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:3 step:17305[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:3 step:17310[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:3 step:17315[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:3 step:17320[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:3 step:17325[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:3 step:17330[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:3 step:17335[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:3 step:17340[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:3 step:17345[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:3 step:17350[D loss: 0.999998] [G loss: 1.000070]\n",
      "epoch:3 step:17355[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:3 step:17360[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:17365[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:3 step:17370[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:3 step:17375[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:3 step:17380[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:3 step:17385[D loss: 0.999977] [G loss: 1.000090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:17390[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:3 step:17395[D loss: 0.999983] [G loss: 1.000111]\n",
      "epoch:3 step:17400[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:3 step:17405[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:3 step:17410[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:3 step:17415[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:3 step:17420[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:3 step:17425[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:3 step:17430[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:3 step:17435[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:3 step:17440[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:3 step:17445[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:3 step:17450[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:3 step:17455[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:3 step:17460[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:3 step:17465[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:3 step:17470[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:3 step:17475[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:3 step:17480[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:3 step:17485[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:3 step:17490[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:3 step:17495[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:17500[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:3 step:17505[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:17510[D loss: 1.000011] [G loss: 1.000041]\n",
      "epoch:3 step:17515[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:3 step:17520[D loss: 0.999991] [G loss: 1.000092]\n",
      "epoch:3 step:17525[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:3 step:17530[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:3 step:17535[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:3 step:17540[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:3 step:17545[D loss: 0.999983] [G loss: 1.000097]\n",
      "epoch:3 step:17550[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:3 step:17555[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:3 step:17560[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:3 step:17565[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:3 step:17570[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:3 step:17575[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:3 step:17580[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:17585[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:17590[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:17595[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:3 step:17600[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:3 step:17605[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:3 step:17610[D loss: 1.000009] [G loss: 1.000012]\n",
      "epoch:3 step:17615[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:3 step:17620[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:3 step:17625[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:3 step:17630[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:3 step:17635[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:3 step:17640[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:3 step:17645[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:3 step:17650[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:3 step:17655[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:3 step:17660[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:3 step:17665[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:3 step:17670[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:3 step:17675[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:3 step:17680[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:3 step:17685[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:3 step:17690[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:3 step:17695[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:3 step:17700[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:3 step:17705[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:3 step:17710[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:3 step:17715[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:3 step:17720[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:3 step:17725[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:3 step:17730[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:3 step:17735[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:3 step:17740[D loss: 0.999989] [G loss: 1.000093]\n",
      "epoch:3 step:17745[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:3 step:17750[D loss: 0.999951] [G loss: 1.000135]\n",
      "epoch:3 step:17755[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:3 step:17760[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:3 step:17765[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:3 step:17770[D loss: 0.999970] [G loss: 1.000035]\n",
      "epoch:3 step:17775[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:3 step:17780[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:3 step:17785[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:3 step:17790[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:3 step:17795[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:3 step:17800[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:3 step:17805[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:3 step:17810[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:3 step:17815[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:3 step:17820[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:3 step:17825[D loss: 0.999999] [G loss: 1.000029]\n",
      "epoch:3 step:17830[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:3 step:17835[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:3 step:17840[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:3 step:17845[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:3 step:17850[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:3 step:17855[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:3 step:17860[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:3 step:17865[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:3 step:17870[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:3 step:17875[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:3 step:17880[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:3 step:17885[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:3 step:17890[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:3 step:17895[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:3 step:17900[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:3 step:17905[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:3 step:17910[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:3 step:17915[D loss: 1.000009] [G loss: 1.000029]\n",
      "epoch:3 step:17920[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:3 step:17925[D loss: 0.999992] [G loss: 1.000083]\n",
      "epoch:3 step:17930[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:3 step:17935[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:3 step:17940[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:3 step:17945[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:3 step:17950[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:3 step:17955[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:3 step:17960[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:3 step:17965[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:3 step:17970[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:3 step:17975[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:17980[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:3 step:17985[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:3 step:17990[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:3 step:17995[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:3 step:18000[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:3 step:18005[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:3 step:18010[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:3 step:18015[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:3 step:18020[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:3 step:18025[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:3 step:18030[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:3 step:18035[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:3 step:18040[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:3 step:18045[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:3 step:18050[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:3 step:18055[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:3 step:18060[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:3 step:18065[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:3 step:18070[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:3 step:18075[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:3 step:18080[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:3 step:18085[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:3 step:18090[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:3 step:18095[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:3 step:18100[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:3 step:18105[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:3 step:18110[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:3 step:18115[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:3 step:18120[D loss: 0.999983] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:18125[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:3 step:18130[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:3 step:18135[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:18140[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:3 step:18145[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:3 step:18150[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:3 step:18155[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:3 step:18160[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:3 step:18165[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:3 step:18170[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:3 step:18175[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:3 step:18180[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:3 step:18185[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:3 step:18190[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:3 step:18195[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:3 step:18200[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:3 step:18205[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:3 step:18210[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:3 step:18215[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:3 step:18220[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:3 step:18225[D loss: 1.000006] [G loss: 1.000064]\n",
      "epoch:3 step:18230[D loss: 0.999995] [G loss: 1.000073]\n",
      "epoch:3 step:18235[D loss: 0.999973] [G loss: 1.000101]\n",
      "epoch:3 step:18240[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:3 step:18245[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:3 step:18250[D loss: 0.999982] [G loss: 1.000102]\n",
      "epoch:3 step:18255[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:3 step:18260[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:3 step:18265[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:3 step:18270[D loss: 0.999959] [G loss: 1.000113]\n",
      "epoch:3 step:18275[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:3 step:18280[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:3 step:18285[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:3 step:18290[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:3 step:18295[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:3 step:18300[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:3 step:18305[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:3 step:18310[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:3 step:18315[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:3 step:18320[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:3 step:18325[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:3 step:18330[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:3 step:18335[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:3 step:18340[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:3 step:18345[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:3 step:18350[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:3 step:18355[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:3 step:18360[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:3 step:18365[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:3 step:18370[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:3 step:18375[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:3 step:18380[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:3 step:18385[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:3 step:18390[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:3 step:18395[D loss: 0.999975] [G loss: 1.000104]\n",
      "epoch:3 step:18400[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:3 step:18405[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:3 step:18410[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:3 step:18415[D loss: 1.000001] [G loss: 1.000056]\n",
      "epoch:3 step:18420[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:3 step:18425[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:3 step:18430[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:3 step:18435[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:3 step:18440[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:3 step:18445[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:3 step:18450[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:3 step:18455[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:3 step:18460[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:3 step:18465[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:3 step:18470[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:3 step:18475[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:3 step:18480[D loss: 0.999961] [G loss: 1.000109]\n",
      "epoch:3 step:18485[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:3 step:18490[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:3 step:18495[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:3 step:18500[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:3 step:18505[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:3 step:18510[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:3 step:18515[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:3 step:18520[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:3 step:18525[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:3 step:18530[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:3 step:18535[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:3 step:18540[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:3 step:18545[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:3 step:18550[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:3 step:18555[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:3 step:18560[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:3 step:18565[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:3 step:18570[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:3 step:18575[D loss: 0.999986] [G loss: 1.000082]\n",
      "epoch:3 step:18580[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:3 step:18585[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:3 step:18590[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:3 step:18595[D loss: 1.000001] [G loss: 1.000052]\n",
      "epoch:3 step:18600[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:3 step:18605[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:3 step:18610[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:3 step:18615[D loss: 0.999975] [G loss: 1.000095]\n",
      "epoch:3 step:18620[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:3 step:18625[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:3 step:18630[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:3 step:18635[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:3 step:18640[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:3 step:18645[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:3 step:18650[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:3 step:18655[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:3 step:18660[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:3 step:18665[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:3 step:18670[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:3 step:18675[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:3 step:18680[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:3 step:18685[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:3 step:18690[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:3 step:18695[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:3 step:18700[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:3 step:18705[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:3 step:18710[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:3 step:18715[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:3 step:18720[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:3 step:18725[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:3 step:18730[D loss: 1.000008] [G loss: 1.000040]\n",
      "epoch:3 step:18735[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:3 step:18740[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:4 step:18745[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:4 step:18750[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:4 step:18755[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:4 step:18760[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:4 step:18765[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:4 step:18770[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:4 step:18775[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:4 step:18780[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:4 step:18785[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:4 step:18790[D loss: 1.000006] [G loss: 1.000039]\n",
      "epoch:4 step:18795[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:4 step:18800[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:4 step:18805[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:4 step:18810[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:4 step:18815[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:18820[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:4 step:18825[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:4 step:18830[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:4 step:18835[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:4 step:18840[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:4 step:18845[D loss: 0.999999] [G loss: 1.000029]\n",
      "epoch:4 step:18850[D loss: 1.000015] [G loss: 1.000022]\n",
      "epoch:4 step:18855[D loss: 0.999983] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:18860[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:4 step:18865[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:4 step:18870[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:4 step:18875[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:4 step:18880[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:4 step:18885[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:4 step:18890[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:4 step:18895[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:4 step:18900[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:4 step:18905[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:4 step:18910[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:4 step:18915[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:4 step:18920[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:4 step:18925[D loss: 0.999990] [G loss: 1.000092]\n",
      "epoch:4 step:18930[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:4 step:18935[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:4 step:18940[D loss: 1.000002] [G loss: 1.000063]\n",
      "epoch:4 step:18945[D loss: 1.000002] [G loss: 1.000067]\n",
      "epoch:4 step:18950[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:4 step:18955[D loss: 0.999954] [G loss: 1.000113]\n",
      "epoch:4 step:18960[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:4 step:18965[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:4 step:18970[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:4 step:18975[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:4 step:18980[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:4 step:18985[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:4 step:18990[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:4 step:18995[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:4 step:19000[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:4 step:19005[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:4 step:19010[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:4 step:19015[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:4 step:19020[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:4 step:19025[D loss: 0.999978] [G loss: 1.000099]\n",
      "epoch:4 step:19030[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:4 step:19035[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:4 step:19040[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:4 step:19045[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:4 step:19050[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:4 step:19055[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:4 step:19060[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:4 step:19065[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:4 step:19070[D loss: 0.999984] [G loss: 1.000095]\n",
      "epoch:4 step:19075[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:4 step:19080[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:4 step:19085[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:4 step:19090[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:4 step:19095[D loss: 1.000010] [G loss: 1.000028]\n",
      "epoch:4 step:19100[D loss: 0.999953] [G loss: 1.000138]\n",
      "epoch:4 step:19105[D loss: 0.999940] [G loss: 1.000138]\n",
      "epoch:4 step:19110[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:4 step:19115[D loss: 1.000014] [G loss: 1.000045]\n",
      "epoch:4 step:19120[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:4 step:19125[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:4 step:19130[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:4 step:19135[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:4 step:19140[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:4 step:19145[D loss: 0.999991] [G loss: 1.000091]\n",
      "epoch:4 step:19150[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:4 step:19155[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:4 step:19160[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:4 step:19165[D loss: 1.000008] [G loss: 1.000006]\n",
      "epoch:4 step:19170[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:4 step:19175[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:4 step:19180[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:4 step:19185[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:4 step:19190[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:4 step:19195[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:4 step:19200[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:4 step:19205[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:19210[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:4 step:19215[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:4 step:19220[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:4 step:19225[D loss: 0.999967] [G loss: 1.000129]\n",
      "epoch:4 step:19230[D loss: 0.999973] [G loss: 1.000107]\n",
      "epoch:4 step:19235[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:4 step:19240[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:4 step:19245[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:4 step:19250[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:4 step:19255[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:4 step:19260[D loss: 1.000008] [G loss: 1.000038]\n",
      "epoch:4 step:19265[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:4 step:19270[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:4 step:19275[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:4 step:19280[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:4 step:19285[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:4 step:19290[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:4 step:19295[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:4 step:19300[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:4 step:19305[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:4 step:19310[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:4 step:19315[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:4 step:19320[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:4 step:19325[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:4 step:19330[D loss: 1.000015] [G loss: 1.000005]\n",
      "epoch:4 step:19335[D loss: 1.000020] [G loss: 1.000044]\n",
      "epoch:4 step:19340[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:4 step:19345[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:4 step:19350[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:4 step:19355[D loss: 1.000008] [G loss: 1.000036]\n",
      "epoch:4 step:19360[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:4 step:19365[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:4 step:19370[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:4 step:19375[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:4 step:19380[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:4 step:19385[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:4 step:19390[D loss: 1.000007] [G loss: 1.000049]\n",
      "epoch:4 step:19395[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:4 step:19400[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:4 step:19405[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:4 step:19410[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:4 step:19415[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:4 step:19420[D loss: 0.999986] [G loss: 1.000082]\n",
      "epoch:4 step:19425[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:4 step:19430[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:4 step:19435[D loss: 0.999990] [G loss: 1.000093]\n",
      "epoch:4 step:19440[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:4 step:19445[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:4 step:19450[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:4 step:19455[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:4 step:19460[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:4 step:19465[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:4 step:19470[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:4 step:19475[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:4 step:19480[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:4 step:19485[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:4 step:19490[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:4 step:19495[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:4 step:19500[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:4 step:19505[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:4 step:19510[D loss: 1.000016] [G loss: 1.000019]\n",
      "epoch:4 step:19515[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:4 step:19520[D loss: 0.999980] [G loss: 1.000106]\n",
      "epoch:4 step:19525[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:4 step:19530[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:4 step:19535[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:4 step:19540[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:4 step:19545[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:4 step:19550[D loss: 1.000005] [G loss: 1.000073]\n",
      "epoch:4 step:19555[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:4 step:19560[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:4 step:19565[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:4 step:19570[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:4 step:19575[D loss: 0.999964] [G loss: 1.000104]\n",
      "epoch:4 step:19580[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:4 step:19585[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:4 step:19590[D loss: 0.999948] [G loss: 1.000132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:19595[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:4 step:19600[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:4 step:19605[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:4 step:19610[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:4 step:19615[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:4 step:19620[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:4 step:19625[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:4 step:19630[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:4 step:19635[D loss: 0.999980] [G loss: 1.000108]\n",
      "epoch:4 step:19640[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:4 step:19645[D loss: 0.999971] [G loss: 1.000101]\n",
      "epoch:4 step:19650[D loss: 0.999992] [G loss: 1.000057]\n",
      "epoch:4 step:19655[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:4 step:19660[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:4 step:19665[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:4 step:19670[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:4 step:19675[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:4 step:19680[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:4 step:19685[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:4 step:19690[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:4 step:19695[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:4 step:19700[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:4 step:19705[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:4 step:19710[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:4 step:19715[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:4 step:19720[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:4 step:19725[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:4 step:19730[D loss: 1.000006] [G loss: 1.000065]\n",
      "epoch:4 step:19735[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:4 step:19740[D loss: 0.999984] [G loss: 1.000103]\n",
      "epoch:4 step:19745[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:4 step:19750[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:4 step:19755[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:4 step:19760[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:4 step:19765[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:4 step:19770[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:4 step:19775[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:4 step:19780[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:4 step:19785[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:4 step:19790[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:4 step:19795[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:4 step:19800[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:4 step:19805[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:4 step:19810[D loss: 1.000006] [G loss: 1.000060]\n",
      "epoch:4 step:19815[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:4 step:19820[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:4 step:19825[D loss: 1.000021] [G loss: 1.000054]\n",
      "epoch:4 step:19830[D loss: 0.999964] [G loss: 1.000108]\n",
      "epoch:4 step:19835[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:4 step:19840[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:4 step:19845[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:4 step:19850[D loss: 1.000009] [G loss: 1.000035]\n",
      "epoch:4 step:19855[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:4 step:19860[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:4 step:19865[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:4 step:19870[D loss: 0.999986] [G loss: 1.000104]\n",
      "epoch:4 step:19875[D loss: 1.000000] [G loss: 1.000089]\n",
      "epoch:4 step:19880[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:4 step:19885[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:4 step:19890[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:4 step:19895[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:4 step:19900[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:4 step:19905[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:4 step:19910[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:4 step:19915[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:4 step:19920[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:4 step:19925[D loss: 0.999997] [G loss: 1.000072]\n",
      "epoch:4 step:19930[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:4 step:19935[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:4 step:19940[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:4 step:19945[D loss: 1.000011] [G loss: 1.000057]\n",
      "epoch:4 step:19950[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:4 step:19955[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:4 step:19960[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:4 step:19965[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:4 step:19970[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:4 step:19975[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:4 step:19980[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:4 step:19985[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:4 step:19990[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:4 step:19995[D loss: 0.999964] [G loss: 1.000125]\n",
      "epoch:4 step:20000[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:4 step:20005[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:4 step:20010[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:4 step:20015[D loss: 0.999990] [G loss: 1.000086]\n",
      "epoch:4 step:20020[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:4 step:20025[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:4 step:20030[D loss: 1.000000] [G loss: 1.000068]\n",
      "epoch:4 step:20035[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:4 step:20040[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:4 step:20045[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:4 step:20050[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:4 step:20055[D loss: 0.999998] [G loss: 1.000097]\n",
      "epoch:4 step:20060[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:4 step:20065[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:4 step:20070[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:4 step:20075[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:4 step:20080[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:4 step:20085[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:4 step:20090[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:4 step:20095[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:4 step:20100[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:4 step:20105[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:4 step:20110[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:4 step:20115[D loss: 1.000001] [G loss: 1.000050]\n",
      "epoch:4 step:20120[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:4 step:20125[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:4 step:20130[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:4 step:20135[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:4 step:20140[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:4 step:20145[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:4 step:20150[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:4 step:20155[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:4 step:20160[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:4 step:20165[D loss: 1.000003] [G loss: 1.000046]\n",
      "epoch:4 step:20170[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:4 step:20175[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:4 step:20180[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:4 step:20185[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:4 step:20190[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:4 step:20195[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:4 step:20200[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:4 step:20205[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:4 step:20210[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:4 step:20215[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:4 step:20220[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:4 step:20225[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:4 step:20230[D loss: 1.000011] [G loss: 1.000031]\n",
      "epoch:4 step:20235[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:4 step:20240[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:4 step:20245[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:4 step:20250[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:4 step:20255[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:4 step:20260[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:4 step:20265[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:4 step:20270[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:4 step:20275[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:4 step:20280[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:4 step:20285[D loss: 1.000018] [G loss: 1.000024]\n",
      "epoch:4 step:20290[D loss: 1.000002] [G loss: 1.000038]\n",
      "epoch:4 step:20295[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:4 step:20300[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:4 step:20305[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:4 step:20310[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:4 step:20315[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:4 step:20320[D loss: 0.999985] [G loss: 1.000095]\n",
      "epoch:4 step:20325[D loss: 0.999966] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:20330[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:4 step:20335[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:4 step:20340[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:4 step:20345[D loss: 1.000047] [G loss: 0.999989]\n",
      "epoch:4 step:20350[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:4 step:20355[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:20360[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:4 step:20365[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:4 step:20370[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:4 step:20375[D loss: 1.000017] [G loss: 1.000012]\n",
      "epoch:4 step:20380[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:4 step:20385[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:4 step:20390[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:4 step:20395[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:4 step:20400[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:4 step:20405[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:4 step:20410[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:4 step:20415[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:4 step:20420[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:4 step:20425[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:4 step:20430[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:4 step:20435[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:4 step:20440[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:4 step:20445[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:4 step:20450[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:4 step:20455[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:4 step:20460[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:4 step:20465[D loss: 0.999972] [G loss: 1.000106]\n",
      "epoch:4 step:20470[D loss: 0.999990] [G loss: 1.000081]\n",
      "epoch:4 step:20475[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:4 step:20480[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:4 step:20485[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:4 step:20490[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:4 step:20495[D loss: 0.999984] [G loss: 1.000092]\n",
      "epoch:4 step:20500[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:4 step:20505[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:4 step:20510[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:4 step:20515[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:4 step:20520[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:4 step:20525[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:4 step:20530[D loss: 0.999991] [G loss: 1.000104]\n",
      "epoch:4 step:20535[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:4 step:20540[D loss: 0.999982] [G loss: 1.000095]\n",
      "epoch:4 step:20545[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:4 step:20550[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:4 step:20555[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:4 step:20560[D loss: 1.000054] [G loss: 0.999981]\n",
      "epoch:4 step:20565[D loss: 0.999940] [G loss: 1.000125]\n",
      "epoch:4 step:20570[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:4 step:20575[D loss: 0.999972] [G loss: 1.000143]\n",
      "epoch:4 step:20580[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:4 step:20585[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:4 step:20590[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:4 step:20595[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:4 step:20600[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:4 step:20605[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:4 step:20610[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:4 step:20615[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:4 step:20620[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:4 step:20625[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:4 step:20630[D loss: 1.000001] [G loss: 1.000088]\n",
      "epoch:4 step:20635[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:4 step:20640[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:4 step:20645[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:4 step:20650[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:4 step:20655[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:4 step:20660[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:4 step:20665[D loss: 0.999977] [G loss: 1.000100]\n",
      "epoch:4 step:20670[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:4 step:20675[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:4 step:20680[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:4 step:20685[D loss: 1.000001] [G loss: 1.000080]\n",
      "epoch:4 step:20690[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:4 step:20695[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:4 step:20700[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:4 step:20705[D loss: 0.999961] [G loss: 1.000097]\n",
      "epoch:4 step:20710[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:4 step:20715[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:4 step:20720[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:4 step:20725[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:4 step:20730[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:4 step:20735[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:4 step:20740[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:4 step:20745[D loss: 0.999956] [G loss: 1.000122]\n",
      "epoch:4 step:20750[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:4 step:20755[D loss: 0.999988] [G loss: 1.000082]\n",
      "epoch:4 step:20760[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:4 step:20765[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:4 step:20770[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:4 step:20775[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:4 step:20780[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:4 step:20785[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:4 step:20790[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:4 step:20795[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:4 step:20800[D loss: 1.000019] [G loss: 1.000024]\n",
      "epoch:4 step:20805[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:4 step:20810[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:4 step:20815[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:4 step:20820[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:4 step:20825[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:4 step:20830[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:4 step:20835[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:4 step:20840[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:4 step:20845[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:4 step:20850[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:4 step:20855[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:4 step:20860[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:4 step:20865[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:4 step:20870[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:4 step:20875[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:4 step:20880[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:4 step:20885[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:4 step:20890[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:4 step:20895[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:4 step:20900[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:4 step:20905[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:4 step:20910[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:4 step:20915[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:4 step:20920[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:4 step:20925[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:4 step:20930[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:4 step:20935[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:4 step:20940[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:4 step:20945[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:4 step:20950[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:4 step:20955[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:4 step:20960[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:4 step:20965[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:4 step:20970[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:4 step:20975[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:4 step:20980[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:4 step:20985[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:4 step:20990[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:4 step:20995[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:4 step:21000[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:4 step:21005[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:4 step:21010[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:4 step:21015[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:4 step:21020[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:4 step:21025[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:4 step:21030[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:4 step:21035[D loss: 1.000007] [G loss: 1.000064]\n",
      "epoch:4 step:21040[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:4 step:21045[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:4 step:21050[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:4 step:21055[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:4 step:21060[D loss: 0.999990] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:21065[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:4 step:21070[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:4 step:21075[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:4 step:21080[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:4 step:21085[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:4 step:21090[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:4 step:21095[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:4 step:21100[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:4 step:21105[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:4 step:21110[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:4 step:21115[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:4 step:21120[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:4 step:21125[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:4 step:21130[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:4 step:21135[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:4 step:21140[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:4 step:21145[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:4 step:21150[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:4 step:21155[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:4 step:21160[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:4 step:21165[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:4 step:21170[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:4 step:21175[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:4 step:21180[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:4 step:21185[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:4 step:21190[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:4 step:21195[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:4 step:21200[D loss: 0.999980] [G loss: 1.000103]\n",
      "epoch:4 step:21205[D loss: 1.000017] [G loss: 1.000014]\n",
      "epoch:4 step:21210[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:4 step:21215[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:4 step:21220[D loss: 1.000030] [G loss: 1.000043]\n",
      "epoch:4 step:21225[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:4 step:21230[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:4 step:21235[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:4 step:21240[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:4 step:21245[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:4 step:21250[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:4 step:21255[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:4 step:21260[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:4 step:21265[D loss: 1.000002] [G loss: 1.000058]\n",
      "epoch:4 step:21270[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:4 step:21275[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:4 step:21280[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:4 step:21285[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:4 step:21290[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:4 step:21295[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:4 step:21300[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:4 step:21305[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:4 step:21310[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:4 step:21315[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:4 step:21320[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:4 step:21325[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:4 step:21330[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:4 step:21335[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:4 step:21340[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:4 step:21345[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:4 step:21350[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:4 step:21355[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:4 step:21360[D loss: 0.999958] [G loss: 1.000113]\n",
      "epoch:4 step:21365[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:4 step:21370[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:4 step:21375[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:4 step:21380[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:4 step:21385[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:4 step:21390[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:4 step:21395[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:4 step:21400[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:4 step:21405[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:4 step:21410[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:4 step:21415[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:4 step:21420[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:4 step:21425[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:4 step:21430[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:4 step:21435[D loss: 0.999968] [G loss: 1.000110]\n",
      "epoch:4 step:21440[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:4 step:21445[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:4 step:21450[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:4 step:21455[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:4 step:21460[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:4 step:21465[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:4 step:21470[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:21475[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:4 step:21480[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:4 step:21485[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:4 step:21490[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:4 step:21495[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:4 step:21500[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:4 step:21505[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:4 step:21510[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:4 step:21515[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:4 step:21520[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:4 step:21525[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:4 step:21530[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:4 step:21535[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:4 step:21540[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:4 step:21545[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:4 step:21550[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:4 step:21555[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:4 step:21560[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:4 step:21565[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:4 step:21570[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:4 step:21575[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:4 step:21580[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:4 step:21585[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:4 step:21590[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:4 step:21595[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:4 step:21600[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:4 step:21605[D loss: 1.000000] [G loss: 1.000079]\n",
      "epoch:4 step:21610[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:4 step:21615[D loss: 1.000014] [G loss: 1.000048]\n",
      "epoch:4 step:21620[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:4 step:21625[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:4 step:21630[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:4 step:21635[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:4 step:21640[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:4 step:21645[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:4 step:21650[D loss: 1.000025] [G loss: 1.000027]\n",
      "epoch:4 step:21655[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:4 step:21660[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:4 step:21665[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:4 step:21670[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:4 step:21675[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:4 step:21680[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:4 step:21685[D loss: 0.999995] [G loss: 1.000065]\n",
      "epoch:4 step:21690[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:21695[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:4 step:21700[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:4 step:21705[D loss: 0.999993] [G loss: 1.000079]\n",
      "epoch:4 step:21710[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:4 step:21715[D loss: 0.999986] [G loss: 1.000096]\n",
      "epoch:4 step:21720[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:4 step:21725[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:4 step:21730[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:4 step:21735[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:4 step:21740[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:4 step:21745[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:21750[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:4 step:21755[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:4 step:21760[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:4 step:21765[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:4 step:21770[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:4 step:21775[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:4 step:21780[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:4 step:21785[D loss: 1.000010] [G loss: 1.000046]\n",
      "epoch:4 step:21790[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:4 step:21795[D loss: 0.999978] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:21800[D loss: 0.999997] [G loss: 1.000064]\n",
      "epoch:4 step:21805[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:4 step:21810[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:4 step:21815[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:4 step:21820[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:4 step:21825[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:4 step:21830[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:4 step:21835[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:4 step:21840[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:4 step:21845[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:4 step:21850[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:4 step:21855[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:4 step:21860[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:4 step:21865[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:4 step:21870[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:4 step:21875[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:4 step:21880[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:4 step:21885[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:4 step:21890[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:4 step:21895[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:4 step:21900[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:4 step:21905[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:4 step:21910[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:4 step:21915[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:4 step:21920[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:4 step:21925[D loss: 0.999972] [G loss: 1.000110]\n",
      "epoch:4 step:21930[D loss: 0.999997] [G loss: 1.000080]\n",
      "epoch:4 step:21935[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:4 step:21940[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:4 step:21945[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:4 step:21950[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:4 step:21955[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:4 step:21960[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:4 step:21965[D loss: 0.999971] [G loss: 1.000107]\n",
      "epoch:4 step:21970[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:4 step:21975[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:4 step:21980[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:4 step:21985[D loss: 0.999989] [G loss: 1.000076]\n",
      "epoch:4 step:21990[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:4 step:21995[D loss: 1.000008] [G loss: 1.000065]\n",
      "epoch:4 step:22000[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:4 step:22005[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:4 step:22010[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:4 step:22015[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:4 step:22020[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:4 step:22025[D loss: 0.999975] [G loss: 1.000111]\n",
      "epoch:4 step:22030[D loss: 0.999978] [G loss: 1.000091]\n",
      "epoch:4 step:22035[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:4 step:22040[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:4 step:22045[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:4 step:22050[D loss: 0.999986] [G loss: 1.000102]\n",
      "epoch:4 step:22055[D loss: 1.000004] [G loss: 1.000076]\n",
      "epoch:4 step:22060[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:4 step:22065[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:4 step:22070[D loss: 1.000030] [G loss: 1.000010]\n",
      "epoch:4 step:22075[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:4 step:22080[D loss: 0.999974] [G loss: 1.000103]\n",
      "epoch:4 step:22085[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:4 step:22090[D loss: 0.999945] [G loss: 1.000099]\n",
      "epoch:4 step:22095[D loss: 0.999960] [G loss: 1.000054]\n",
      "epoch:4 step:22100[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:4 step:22105[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:4 step:22110[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:4 step:22115[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:4 step:22120[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:4 step:22125[D loss: 0.999973] [G loss: 1.000101]\n",
      "epoch:4 step:22130[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:4 step:22135[D loss: 0.999977] [G loss: 1.000094]\n",
      "epoch:4 step:22140[D loss: 0.999991] [G loss: 1.000069]\n",
      "epoch:4 step:22145[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:4 step:22150[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:4 step:22155[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:4 step:22160[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:4 step:22165[D loss: 0.999986] [G loss: 1.000094]\n",
      "epoch:4 step:22170[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:4 step:22175[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:4 step:22180[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:4 step:22185[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:4 step:22190[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:4 step:22195[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:4 step:22200[D loss: 0.999946] [G loss: 1.000109]\n",
      "epoch:4 step:22205[D loss: 0.999996] [G loss: 1.000064]\n",
      "epoch:4 step:22210[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:4 step:22215[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:4 step:22220[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:4 step:22225[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:4 step:22230[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:4 step:22235[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:4 step:22240[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:4 step:22245[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:4 step:22250[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:4 step:22255[D loss: 1.000004] [G loss: 1.000031]\n",
      "epoch:4 step:22260[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:4 step:22265[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:4 step:22270[D loss: 0.999967] [G loss: 1.000108]\n",
      "epoch:4 step:22275[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:4 step:22280[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:4 step:22285[D loss: 0.999988] [G loss: 1.000069]\n",
      "epoch:4 step:22290[D loss: 0.999992] [G loss: 1.000079]\n",
      "epoch:4 step:22295[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:4 step:22300[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:4 step:22305[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:4 step:22310[D loss: 0.999976] [G loss: 1.000111]\n",
      "epoch:4 step:22315[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:4 step:22320[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:4 step:22325[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:4 step:22330[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:4 step:22335[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:4 step:22340[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:4 step:22345[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:4 step:22350[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:4 step:22355[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:4 step:22360[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:4 step:22365[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:4 step:22370[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:4 step:22375[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:4 step:22380[D loss: 1.000011] [G loss: 1.000042]\n",
      "epoch:4 step:22385[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:4 step:22390[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:4 step:22395[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:4 step:22400[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:4 step:22405[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:4 step:22410[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:4 step:22415[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:4 step:22420[D loss: 1.000006] [G loss: 1.000044]\n",
      "epoch:4 step:22425[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:4 step:22430[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:4 step:22435[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:4 step:22440[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:4 step:22445[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:4 step:22450[D loss: 1.000029] [G loss: 0.999988]\n",
      "epoch:4 step:22455[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:4 step:22460[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:4 step:22465[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:4 step:22470[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:4 step:22475[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:4 step:22480[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:4 step:22485[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:4 step:22490[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:4 step:22495[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:4 step:22500[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:4 step:22505[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:4 step:22510[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:4 step:22515[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:4 step:22520[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:4 step:22525[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:4 step:22530[D loss: 0.999978] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:22535[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:4 step:22540[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:4 step:22545[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:4 step:22550[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:4 step:22555[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:4 step:22560[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:4 step:22565[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:4 step:22570[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:4 step:22575[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:4 step:22580[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:4 step:22585[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:4 step:22590[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:4 step:22595[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:4 step:22600[D loss: 0.999989] [G loss: 1.000089]\n",
      "epoch:4 step:22605[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:4 step:22610[D loss: 0.999955] [G loss: 1.000147]\n",
      "epoch:4 step:22615[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:4 step:22620[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:4 step:22625[D loss: 1.000000] [G loss: 1.000056]\n",
      "epoch:4 step:22630[D loss: 1.000034] [G loss: 0.999985]\n",
      "epoch:4 step:22635[D loss: 0.999974] [G loss: 1.000099]\n",
      "epoch:4 step:22640[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:4 step:22645[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:4 step:22650[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:4 step:22655[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:4 step:22660[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:4 step:22665[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:4 step:22670[D loss: 1.000017] [G loss: 0.999979]\n",
      "epoch:4 step:22675[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:4 step:22680[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:4 step:22685[D loss: 1.000010] [G loss: 1.000054]\n",
      "epoch:4 step:22690[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:4 step:22695[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:4 step:22700[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:4 step:22705[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:4 step:22710[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:4 step:22715[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:4 step:22720[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:4 step:22725[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:4 step:22730[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:4 step:22735[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:4 step:22740[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:4 step:22745[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:4 step:22750[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:4 step:22755[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:4 step:22760[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:4 step:22765[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:4 step:22770[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:4 step:22775[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:4 step:22780[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:4 step:22785[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:4 step:22790[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:4 step:22795[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:4 step:22800[D loss: 0.999976] [G loss: 1.000103]\n",
      "epoch:4 step:22805[D loss: 0.999999] [G loss: 1.000054]\n",
      "epoch:4 step:22810[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:4 step:22815[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:4 step:22820[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:4 step:22825[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:4 step:22830[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:4 step:22835[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:4 step:22840[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:4 step:22845[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:4 step:22850[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:4 step:22855[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:4 step:22860[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:4 step:22865[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:4 step:22870[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:4 step:22875[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:4 step:22880[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:4 step:22885[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:4 step:22890[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:4 step:22895[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:4 step:22900[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:4 step:22905[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:4 step:22910[D loss: 0.999977] [G loss: 1.000100]\n",
      "epoch:4 step:22915[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:4 step:22920[D loss: 1.000002] [G loss: 1.000080]\n",
      "epoch:4 step:22925[D loss: 1.000002] [G loss: 1.000084]\n",
      "epoch:4 step:22930[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:4 step:22935[D loss: 0.999960] [G loss: 1.000153]\n",
      "epoch:4 step:22940[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:4 step:22945[D loss: 1.000012] [G loss: 1.000041]\n",
      "epoch:4 step:22950[D loss: 1.000020] [G loss: 0.999994]\n",
      "epoch:4 step:22955[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:4 step:22960[D loss: 0.999963] [G loss: 1.000121]\n",
      "epoch:4 step:22965[D loss: 0.999957] [G loss: 1.000101]\n",
      "epoch:4 step:22970[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:4 step:22975[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:4 step:22980[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:4 step:22985[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:4 step:22990[D loss: 0.999990] [G loss: 1.000083]\n",
      "epoch:4 step:22995[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:4 step:23000[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:4 step:23005[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:4 step:23010[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:4 step:23015[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:4 step:23020[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:4 step:23025[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:4 step:23030[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:4 step:23035[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:4 step:23040[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:4 step:23045[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:4 step:23050[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:4 step:23055[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:4 step:23060[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:4 step:23065[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:4 step:23070[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:4 step:23075[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:4 step:23080[D loss: 0.999969] [G loss: 1.000100]\n",
      "epoch:4 step:23085[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:4 step:23090[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:4 step:23095[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:4 step:23100[D loss: 0.999997] [G loss: 1.000031]\n",
      "epoch:4 step:23105[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:4 step:23110[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:4 step:23115[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:4 step:23120[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:4 step:23125[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:4 step:23130[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:4 step:23135[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:4 step:23140[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:4 step:23145[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:4 step:23150[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:4 step:23155[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:4 step:23160[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:4 step:23165[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:4 step:23170[D loss: 1.000004] [G loss: 1.000020]\n",
      "epoch:4 step:23175[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:4 step:23180[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:4 step:23185[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:4 step:23190[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:4 step:23195[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:4 step:23200[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:4 step:23205[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:4 step:23210[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:4 step:23215[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:4 step:23220[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:4 step:23225[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:4 step:23230[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:4 step:23235[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:4 step:23240[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:4 step:23245[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:4 step:23250[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:4 step:23255[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:4 step:23260[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:4 step:23265[D loss: 0.999989] [G loss: 1.000039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:23270[D loss: 0.999984] [G loss: 1.000089]\n",
      "epoch:4 step:23275[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:4 step:23280[D loss: 1.000005] [G loss: 1.000031]\n",
      "epoch:4 step:23285[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:4 step:23290[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:4 step:23295[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:4 step:23300[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:4 step:23305[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:4 step:23310[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:4 step:23315[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:4 step:23320[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:4 step:23325[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:4 step:23330[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:4 step:23335[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:4 step:23340[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:4 step:23345[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:4 step:23350[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:4 step:23355[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:4 step:23360[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:4 step:23365[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:4 step:23370[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:4 step:23375[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:4 step:23380[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:4 step:23385[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:4 step:23390[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:4 step:23395[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:4 step:23400[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:4 step:23405[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:4 step:23410[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:4 step:23415[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:4 step:23420[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:4 step:23425[D loss: 0.999993] [G loss: 1.000069]\n",
      "epoch:5 step:23430[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:5 step:23435[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:5 step:23440[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:5 step:23445[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:5 step:23450[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:5 step:23455[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:5 step:23460[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:5 step:23465[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:5 step:23470[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:5 step:23475[D loss: 0.999995] [G loss: 1.000125]\n",
      "epoch:5 step:23480[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:5 step:23485[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:5 step:23490[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:5 step:23495[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:5 step:23500[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:5 step:23505[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:5 step:23510[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:23515[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:5 step:23520[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:5 step:23525[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:5 step:23530[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:5 step:23535[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:5 step:23540[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:5 step:23545[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:5 step:23550[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:5 step:23555[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:5 step:23560[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:5 step:23565[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:5 step:23570[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:5 step:23575[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:5 step:23580[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:5 step:23585[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:5 step:23590[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:5 step:23595[D loss: 0.999993] [G loss: 1.000086]\n",
      "epoch:5 step:23600[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:5 step:23605[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:5 step:23610[D loss: 0.999972] [G loss: 1.000111]\n",
      "epoch:5 step:23615[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:5 step:23620[D loss: 0.999997] [G loss: 1.000020]\n",
      "epoch:5 step:23625[D loss: 1.000000] [G loss: 1.000085]\n",
      "epoch:5 step:23630[D loss: 1.000026] [G loss: 0.999979]\n",
      "epoch:5 step:23635[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:5 step:23640[D loss: 0.999993] [G loss: 1.000086]\n",
      "epoch:5 step:23645[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:5 step:23650[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:5 step:23655[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:5 step:23660[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:5 step:23665[D loss: 0.999986] [G loss: 1.000026]\n",
      "epoch:5 step:23670[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:5 step:23675[D loss: 0.999969] [G loss: 1.000109]\n",
      "epoch:5 step:23680[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:5 step:23685[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:5 step:23690[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:5 step:23695[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:5 step:23700[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:5 step:23705[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:5 step:23710[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:5 step:23715[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:5 step:23720[D loss: 0.999963] [G loss: 1.000097]\n",
      "epoch:5 step:23725[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:5 step:23730[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:5 step:23735[D loss: 0.999982] [G loss: 1.000095]\n",
      "epoch:5 step:23740[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:5 step:23745[D loss: 1.000008] [G loss: 1.000077]\n",
      "epoch:5 step:23750[D loss: 0.999985] [G loss: 1.000090]\n",
      "epoch:5 step:23755[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:5 step:23760[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:5 step:23765[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:5 step:23770[D loss: 1.000022] [G loss: 1.000024]\n",
      "epoch:5 step:23775[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:5 step:23780[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:5 step:23785[D loss: 0.999998] [G loss: 1.000070]\n",
      "epoch:5 step:23790[D loss: 0.999967] [G loss: 1.000119]\n",
      "epoch:5 step:23795[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:5 step:23800[D loss: 1.000020] [G loss: 0.999999]\n",
      "epoch:5 step:23805[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:5 step:23810[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:5 step:23815[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:5 step:23820[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:5 step:23825[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:5 step:23830[D loss: 0.999991] [G loss: 1.000061]\n",
      "epoch:5 step:23835[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:5 step:23840[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:5 step:23845[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:5 step:23850[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:5 step:23855[D loss: 1.000005] [G loss: 1.000000]\n",
      "epoch:5 step:23860[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:5 step:23865[D loss: 0.999950] [G loss: 1.000090]\n",
      "epoch:5 step:23870[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:5 step:23875[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:5 step:23880[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:5 step:23885[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:5 step:23890[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:5 step:23895[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:5 step:23900[D loss: 1.000006] [G loss: 1.000047]\n",
      "epoch:5 step:23905[D loss: 1.000001] [G loss: 1.000069]\n",
      "epoch:5 step:23910[D loss: 0.999959] [G loss: 1.000119]\n",
      "epoch:5 step:23915[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:5 step:23920[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:5 step:23925[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:5 step:23930[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:5 step:23935[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:5 step:23940[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:5 step:23945[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:5 step:23950[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:23955[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:5 step:23960[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:5 step:23965[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:5 step:23970[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:5 step:23975[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:23980[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:5 step:23985[D loss: 0.999995] [G loss: 1.000000]\n",
      "epoch:5 step:23990[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:5 step:23995[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:5 step:24000[D loss: 0.999980] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:24005[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:5 step:24010[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:5 step:24015[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:5 step:24020[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:5 step:24025[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:5 step:24030[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:5 step:24035[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:5 step:24040[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:5 step:24045[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:5 step:24050[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:5 step:24055[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:5 step:24060[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:5 step:24065[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:5 step:24070[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:5 step:24075[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:5 step:24080[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:5 step:24085[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:5 step:24090[D loss: 1.000017] [G loss: 1.000003]\n",
      "epoch:5 step:24095[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:5 step:24100[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:5 step:24105[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:5 step:24110[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:5 step:24115[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:5 step:24120[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:5 step:24125[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:5 step:24130[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:5 step:24135[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:5 step:24140[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:5 step:24145[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:5 step:24150[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:5 step:24155[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:5 step:24160[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:5 step:24165[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:5 step:24170[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:5 step:24175[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:5 step:24180[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:5 step:24185[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:5 step:24190[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:5 step:24195[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:5 step:24200[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:5 step:24205[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:24210[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:5 step:24215[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:5 step:24220[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:5 step:24225[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:5 step:24230[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:5 step:24235[D loss: 0.999989] [G loss: 1.000111]\n",
      "epoch:5 step:24240[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:5 step:24245[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:24250[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:5 step:24255[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:5 step:24260[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:5 step:24265[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:5 step:24270[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:5 step:24275[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:5 step:24280[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:5 step:24285[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:5 step:24290[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:5 step:24295[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:24300[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:5 step:24305[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:5 step:24310[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:5 step:24315[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:5 step:24320[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:5 step:24325[D loss: 0.999974] [G loss: 1.000095]\n",
      "epoch:5 step:24330[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:5 step:24335[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:5 step:24340[D loss: 0.999986] [G loss: 1.000030]\n",
      "epoch:5 step:24345[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:5 step:24350[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:5 step:24355[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:5 step:24360[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:5 step:24365[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:5 step:24370[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:5 step:24375[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:5 step:24380[D loss: 1.000002] [G loss: 1.000007]\n",
      "epoch:5 step:24385[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:5 step:24390[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:5 step:24395[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:24400[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:5 step:24405[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:5 step:24410[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:5 step:24415[D loss: 0.999975] [G loss: 1.000103]\n",
      "epoch:5 step:24420[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:5 step:24425[D loss: 1.000004] [G loss: 1.000085]\n",
      "epoch:5 step:24430[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:5 step:24435[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:5 step:24440[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:5 step:24445[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:5 step:24450[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:5 step:24455[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:5 step:24460[D loss: 0.999955] [G loss: 1.000133]\n",
      "epoch:5 step:24465[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:5 step:24470[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:5 step:24475[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:5 step:24480[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:5 step:24485[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:5 step:24490[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:5 step:24495[D loss: 0.999979] [G loss: 1.000117]\n",
      "epoch:5 step:24500[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:5 step:24505[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:5 step:24510[D loss: 1.000034] [G loss: 1.000020]\n",
      "epoch:5 step:24515[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:5 step:24520[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:5 step:24525[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:5 step:24530[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:5 step:24535[D loss: 1.000027] [G loss: 0.999994]\n",
      "epoch:5 step:24540[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:5 step:24545[D loss: 0.999948] [G loss: 1.000070]\n",
      "epoch:5 step:24550[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:5 step:24555[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:5 step:24560[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:5 step:24565[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:5 step:24570[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:5 step:24575[D loss: 0.999994] [G loss: 1.000048]\n",
      "epoch:5 step:24580[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:5 step:24585[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:5 step:24590[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:5 step:24595[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:5 step:24600[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:5 step:24605[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:5 step:24610[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:5 step:24615[D loss: 0.999996] [G loss: 1.000045]\n",
      "epoch:5 step:24620[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:5 step:24625[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:24630[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:5 step:24635[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:5 step:24640[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:5 step:24645[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:24650[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:5 step:24655[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:5 step:24660[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:5 step:24665[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:5 step:24670[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:5 step:24675[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:5 step:24680[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:5 step:24685[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:5 step:24690[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:5 step:24695[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:5 step:24700[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:5 step:24705[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:5 step:24710[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:5 step:24715[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:5 step:24720[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:5 step:24725[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:5 step:24730[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:5 step:24735[D loss: 0.999986] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:24740[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:5 step:24745[D loss: 0.999950] [G loss: 1.000072]\n",
      "epoch:5 step:24750[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:5 step:24755[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:5 step:24760[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:5 step:24765[D loss: 0.999992] [G loss: 1.000006]\n",
      "epoch:5 step:24770[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:5 step:24775[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:5 step:24780[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:5 step:24785[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:5 step:24790[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:5 step:24795[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:5 step:24800[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:5 step:24805[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:5 step:24810[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:5 step:24815[D loss: 1.000006] [G loss: 1.000017]\n",
      "epoch:5 step:24820[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:5 step:24825[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:5 step:24830[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:5 step:24835[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:5 step:24840[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:5 step:24845[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:5 step:24850[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:5 step:24855[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:5 step:24860[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:5 step:24865[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:5 step:24870[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:5 step:24875[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:5 step:24880[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:5 step:24885[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:5 step:24890[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:5 step:24895[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:5 step:24900[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:5 step:24905[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:5 step:24910[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:24915[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:5 step:24920[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:5 step:24925[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:5 step:24930[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:5 step:24935[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:5 step:24940[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:5 step:24945[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:5 step:24950[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:5 step:24955[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:5 step:24960[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:5 step:24965[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:5 step:24970[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:5 step:24975[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:5 step:24980[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:5 step:24985[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:5 step:24990[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:5 step:24995[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:5 step:25000[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:5 step:25005[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:5 step:25010[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:5 step:25015[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:5 step:25020[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:5 step:25025[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:5 step:25030[D loss: 1.000047] [G loss: 1.000021]\n",
      "epoch:5 step:25035[D loss: 1.000007] [G loss: 1.000035]\n",
      "epoch:5 step:25040[D loss: 0.999956] [G loss: 1.000135]\n",
      "epoch:5 step:25045[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:5 step:25050[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:5 step:25055[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:5 step:25060[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:5 step:25065[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:5 step:25070[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:5 step:25075[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:5 step:25080[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:5 step:25085[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:5 step:25090[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:5 step:25095[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:5 step:25100[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:5 step:25105[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:5 step:25110[D loss: 0.999985] [G loss: 1.000024]\n",
      "epoch:5 step:25115[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:5 step:25120[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:5 step:25125[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:5 step:25130[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:5 step:25135[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:5 step:25140[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:5 step:25145[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:5 step:25150[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:5 step:25155[D loss: 0.999994] [G loss: 1.000075]\n",
      "epoch:5 step:25160[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:5 step:25165[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:5 step:25170[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:5 step:25175[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:5 step:25180[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:5 step:25185[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:5 step:25190[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:5 step:25195[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:5 step:25200[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:5 step:25205[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:5 step:25210[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:5 step:25215[D loss: 0.999986] [G loss: 1.000096]\n",
      "epoch:5 step:25220[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:5 step:25225[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:5 step:25230[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:5 step:25235[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:5 step:25240[D loss: 0.999980] [G loss: 1.000118]\n",
      "epoch:5 step:25245[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:5 step:25250[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:5 step:25255[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:5 step:25260[D loss: 0.999968] [G loss: 1.000118]\n",
      "epoch:5 step:25265[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:5 step:25270[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:5 step:25275[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:5 step:25280[D loss: 0.999996] [G loss: 1.000021]\n",
      "epoch:5 step:25285[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:5 step:25290[D loss: 1.000002] [G loss: 1.000005]\n",
      "epoch:5 step:25295[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:5 step:25300[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:5 step:25305[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:5 step:25310[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:5 step:25315[D loss: 0.999984] [G loss: 1.000116]\n",
      "epoch:5 step:25320[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:5 step:25325[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:5 step:25330[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:5 step:25335[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:5 step:25340[D loss: 1.000010] [G loss: 1.000054]\n",
      "epoch:5 step:25345[D loss: 0.999972] [G loss: 1.000100]\n",
      "epoch:5 step:25350[D loss: 0.999955] [G loss: 1.000139]\n",
      "epoch:5 step:25355[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:5 step:25360[D loss: 0.999991] [G loss: 1.000118]\n",
      "epoch:5 step:25365[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:5 step:25370[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:5 step:25375[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:5 step:25380[D loss: 1.000007] [G loss: 1.000031]\n",
      "epoch:5 step:25385[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:5 step:25390[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:5 step:25395[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:5 step:25400[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:5 step:25405[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:5 step:25410[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:5 step:25415[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:5 step:25420[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:5 step:25425[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:5 step:25430[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:5 step:25435[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:5 step:25440[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:5 step:25445[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:5 step:25450[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:5 step:25455[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:5 step:25460[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:5 step:25465[D loss: 0.999961] [G loss: 1.000056]\n",
      "epoch:5 step:25470[D loss: 0.999983] [G loss: 1.000063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:25475[D loss: 1.000004] [G loss: 1.000059]\n",
      "epoch:5 step:25480[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:5 step:25485[D loss: 1.000009] [G loss: 1.000051]\n",
      "epoch:5 step:25490[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:5 step:25495[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:5 step:25500[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:5 step:25505[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:5 step:25510[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:5 step:25515[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:5 step:25520[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:5 step:25525[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:5 step:25530[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:5 step:25535[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:5 step:25540[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:5 step:25545[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:5 step:25550[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:5 step:25555[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:5 step:25560[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:5 step:25565[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:5 step:25570[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:5 step:25575[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:5 step:25580[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:5 step:25585[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:5 step:25590[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:5 step:25595[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:5 step:25600[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:5 step:25605[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:5 step:25610[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:5 step:25615[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:5 step:25620[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:25625[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:5 step:25630[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:5 step:25635[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:5 step:25640[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:5 step:25645[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:5 step:25650[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:5 step:25655[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:5 step:25660[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:5 step:25665[D loss: 1.000021] [G loss: 1.000010]\n",
      "epoch:5 step:25670[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:5 step:25675[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:5 step:25680[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:5 step:25685[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:5 step:25690[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:5 step:25695[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:5 step:25700[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:5 step:25705[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:5 step:25710[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:5 step:25715[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:5 step:25720[D loss: 1.000009] [G loss: 1.000084]\n",
      "epoch:5 step:25725[D loss: 0.999962] [G loss: 1.000108]\n",
      "epoch:5 step:25730[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:25735[D loss: 1.000013] [G loss: 0.999984]\n",
      "epoch:5 step:25740[D loss: 0.999993] [G loss: 1.000007]\n",
      "epoch:5 step:25745[D loss: 1.000013] [G loss: 1.000034]\n",
      "epoch:5 step:25750[D loss: 1.000002] [G loss: 1.000026]\n",
      "epoch:5 step:25755[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:5 step:25760[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:5 step:25765[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:5 step:25770[D loss: 0.999995] [G loss: 1.000065]\n",
      "epoch:5 step:25775[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:5 step:25780[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:5 step:25785[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:25790[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:5 step:25795[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:5 step:25800[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:5 step:25805[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:5 step:25810[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:5 step:25815[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:5 step:25820[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:5 step:25825[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:5 step:25830[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:5 step:25835[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:5 step:25840[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:5 step:25845[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:5 step:25850[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:5 step:25855[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:5 step:25860[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:5 step:25865[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:5 step:25870[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:5 step:25875[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:5 step:25880[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:25885[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:5 step:25890[D loss: 1.000003] [G loss: 1.000034]\n",
      "epoch:5 step:25895[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:5 step:25900[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:5 step:25905[D loss: 1.000006] [G loss: 1.000072]\n",
      "epoch:5 step:25910[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:5 step:25915[D loss: 1.000004] [G loss: 1.000034]\n",
      "epoch:5 step:25920[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:5 step:25925[D loss: 0.999979] [G loss: 1.000098]\n",
      "epoch:5 step:25930[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:5 step:25935[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:5 step:25940[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:5 step:25945[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:5 step:25950[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:5 step:25955[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:5 step:25960[D loss: 0.999993] [G loss: 1.000091]\n",
      "epoch:5 step:25965[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:5 step:25970[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:5 step:25975[D loss: 1.000018] [G loss: 1.000042]\n",
      "epoch:5 step:25980[D loss: 0.999990] [G loss: 1.000052]\n",
      "epoch:5 step:25985[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:5 step:25990[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:5 step:25995[D loss: 1.000026] [G loss: 0.999960]\n",
      "epoch:5 step:26000[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:5 step:26005[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:5 step:26010[D loss: 1.000005] [G loss: 1.000065]\n",
      "epoch:5 step:26015[D loss: 0.999954] [G loss: 1.000103]\n",
      "epoch:5 step:26020[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:26025[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:5 step:26030[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:5 step:26035[D loss: 1.000005] [G loss: 1.000035]\n",
      "epoch:5 step:26040[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:5 step:26045[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:5 step:26050[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:5 step:26055[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:5 step:26060[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:5 step:26065[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:5 step:26070[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:5 step:26075[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:5 step:26080[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:5 step:26085[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:5 step:26090[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:5 step:26095[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:5 step:26100[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:5 step:26105[D loss: 1.000013] [G loss: 1.000043]\n",
      "epoch:5 step:26110[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:5 step:26115[D loss: 0.999960] [G loss: 1.000127]\n",
      "epoch:5 step:26120[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:5 step:26125[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:5 step:26130[D loss: 0.999976] [G loss: 1.000020]\n",
      "epoch:5 step:26135[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:5 step:26140[D loss: 1.000026] [G loss: 0.999993]\n",
      "epoch:5 step:26145[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:5 step:26150[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:5 step:26155[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:5 step:26160[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:5 step:26165[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:5 step:26170[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:5 step:26175[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:5 step:26180[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:5 step:26185[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:5 step:26190[D loss: 0.999982] [G loss: 1.000097]\n",
      "epoch:5 step:26195[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:5 step:26200[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:5 step:26205[D loss: 0.999970] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:26210[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:5 step:26215[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:5 step:26220[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:5 step:26225[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:5 step:26230[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:5 step:26235[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:5 step:26240[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:5 step:26245[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:5 step:26250[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:5 step:26255[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:5 step:26260[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:5 step:26265[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:5 step:26270[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:5 step:26275[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:5 step:26280[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:5 step:26285[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:5 step:26290[D loss: 1.000010] [G loss: 1.000022]\n",
      "epoch:5 step:26295[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:5 step:26300[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:5 step:26305[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:5 step:26310[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:5 step:26315[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:5 step:26320[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:5 step:26325[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:5 step:26330[D loss: 1.000006] [G loss: 1.000054]\n",
      "epoch:5 step:26335[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:5 step:26340[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:5 step:26345[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:5 step:26350[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:5 step:26355[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:5 step:26360[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:5 step:26365[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:5 step:26370[D loss: 1.000010] [G loss: 1.000067]\n",
      "epoch:5 step:26375[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:5 step:26380[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:5 step:26385[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:5 step:26390[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:5 step:26395[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:5 step:26400[D loss: 1.000044] [G loss: 0.999958]\n",
      "epoch:5 step:26405[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:5 step:26410[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:5 step:26415[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:5 step:26420[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:5 step:26425[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:5 step:26430[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:5 step:26435[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:5 step:26440[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:5 step:26445[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:5 step:26450[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:5 step:26455[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:5 step:26460[D loss: 1.000006] [G loss: 1.000051]\n",
      "epoch:5 step:26465[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:5 step:26470[D loss: 0.999994] [G loss: 1.000084]\n",
      "epoch:5 step:26475[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:5 step:26480[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:5 step:26485[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:5 step:26490[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:5 step:26495[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:5 step:26500[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:5 step:26505[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:5 step:26510[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:5 step:26515[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:5 step:26520[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:5 step:26525[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:5 step:26530[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:5 step:26535[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:5 step:26540[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:5 step:26545[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:5 step:26550[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:5 step:26555[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:5 step:26560[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:5 step:26565[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:5 step:26570[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:5 step:26575[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:5 step:26580[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:5 step:26585[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:5 step:26590[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:5 step:26595[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:5 step:26600[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:5 step:26605[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:5 step:26610[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:5 step:26615[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:5 step:26620[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:5 step:26625[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:5 step:26630[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:5 step:26635[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:5 step:26640[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:5 step:26645[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:5 step:26650[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:5 step:26655[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:5 step:26660[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:5 step:26665[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:5 step:26670[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:5 step:26675[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:5 step:26680[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:5 step:26685[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:5 step:26690[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:5 step:26695[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:5 step:26700[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:5 step:26705[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:5 step:26710[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:5 step:26715[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:5 step:26720[D loss: 1.000013] [G loss: 1.000017]\n",
      "epoch:5 step:26725[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:5 step:26730[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:5 step:26735[D loss: 0.999964] [G loss: 1.000133]\n",
      "epoch:5 step:26740[D loss: 1.000012] [G loss: 1.000017]\n",
      "epoch:5 step:26745[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:5 step:26750[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:26755[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:5 step:26760[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:5 step:26765[D loss: 0.999978] [G loss: 1.000097]\n",
      "epoch:5 step:26770[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:5 step:26775[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:5 step:26780[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:5 step:26785[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:5 step:26790[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:5 step:26795[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:5 step:26800[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:5 step:26805[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:5 step:26810[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:5 step:26815[D loss: 0.999982] [G loss: 1.000089]\n",
      "epoch:5 step:26820[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:5 step:26825[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:5 step:26830[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:5 step:26835[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:5 step:26840[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:5 step:26845[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:5 step:26850[D loss: 1.000015] [G loss: 1.000022]\n",
      "epoch:5 step:26855[D loss: 0.999957] [G loss: 1.000136]\n",
      "epoch:5 step:26860[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:5 step:26865[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:5 step:26870[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:5 step:26875[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:5 step:26880[D loss: 0.999953] [G loss: 1.000117]\n",
      "epoch:5 step:26885[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:5 step:26890[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:5 step:26895[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:5 step:26900[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:5 step:26905[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:5 step:26910[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:5 step:26915[D loss: 0.999985] [G loss: 1.000095]\n",
      "epoch:5 step:26920[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:5 step:26925[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:5 step:26930[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:5 step:26935[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:5 step:26940[D loss: 0.999992] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:26945[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:5 step:26950[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:5 step:26955[D loss: 1.000004] [G loss: 1.000045]\n",
      "epoch:5 step:26960[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:5 step:26965[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:5 step:26970[D loss: 1.000004] [G loss: 1.000033]\n",
      "epoch:5 step:26975[D loss: 1.000031] [G loss: 1.000024]\n",
      "epoch:5 step:26980[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:5 step:26985[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:5 step:26990[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:5 step:26995[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:5 step:27000[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:5 step:27005[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:5 step:27010[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:5 step:27015[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:5 step:27020[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:5 step:27025[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:5 step:27030[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:5 step:27035[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:5 step:27040[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:5 step:27045[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:5 step:27050[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:5 step:27055[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:5 step:27060[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:5 step:27065[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:5 step:27070[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:5 step:27075[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:5 step:27080[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:5 step:27085[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:5 step:27090[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:5 step:27095[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:5 step:27100[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:5 step:27105[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:5 step:27110[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:5 step:27115[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:5 step:27120[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:5 step:27125[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:5 step:27130[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:5 step:27135[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:5 step:27140[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:5 step:27145[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:5 step:27150[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:5 step:27155[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:5 step:27160[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:5 step:27165[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:5 step:27170[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:5 step:27175[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:5 step:27180[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:5 step:27185[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:5 step:27190[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:27195[D loss: 0.999977] [G loss: 1.000131]\n",
      "epoch:5 step:27200[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:5 step:27205[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:5 step:27210[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:5 step:27215[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:5 step:27220[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:5 step:27225[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:5 step:27230[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:5 step:27235[D loss: 0.999988] [G loss: 1.000093]\n",
      "epoch:5 step:27240[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:5 step:27245[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:5 step:27250[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:5 step:27255[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:5 step:27260[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:5 step:27265[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:5 step:27270[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:5 step:27275[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:5 step:27280[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:5 step:27285[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:5 step:27290[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:5 step:27295[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:5 step:27300[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:5 step:27305[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:5 step:27310[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:5 step:27315[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:5 step:27320[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:5 step:27325[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:27330[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:5 step:27335[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:5 step:27340[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:5 step:27345[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:5 step:27350[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:5 step:27355[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:5 step:27360[D loss: 0.999971] [G loss: 1.000021]\n",
      "epoch:5 step:27365[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:5 step:27370[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:5 step:27375[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:5 step:27380[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:5 step:27385[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:5 step:27390[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:5 step:27395[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:5 step:27400[D loss: 1.000020] [G loss: 0.999985]\n",
      "epoch:5 step:27405[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:5 step:27410[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:5 step:27415[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:5 step:27420[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:5 step:27425[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:5 step:27430[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:5 step:27435[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:5 step:27440[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:5 step:27445[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:5 step:27450[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:5 step:27455[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:5 step:27460[D loss: 1.000000] [G loss: 1.000062]\n",
      "epoch:5 step:27465[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:5 step:27470[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:5 step:27475[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:5 step:27480[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:5 step:27485[D loss: 0.999978] [G loss: 1.000025]\n",
      "epoch:5 step:27490[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:5 step:27495[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:5 step:27500[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:5 step:27505[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:5 step:27510[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:5 step:27515[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:5 step:27520[D loss: 0.999970] [G loss: 1.000036]\n",
      "epoch:5 step:27525[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:5 step:27530[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:5 step:27535[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:5 step:27540[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:5 step:27545[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:5 step:27550[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:5 step:27555[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:5 step:27560[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:5 step:27565[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:5 step:27570[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:5 step:27575[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:5 step:27580[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:5 step:27585[D loss: 1.000008] [G loss: 0.999996]\n",
      "epoch:5 step:27590[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:5 step:27595[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:5 step:27600[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:5 step:27605[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:5 step:27610[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:5 step:27615[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:5 step:27620[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:5 step:27625[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:5 step:27630[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:5 step:27635[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:5 step:27640[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:5 step:27645[D loss: 0.999978] [G loss: 1.000106]\n",
      "epoch:5 step:27650[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:5 step:27655[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:5 step:27660[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:5 step:27665[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:5 step:27670[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:5 step:27675[D loss: 0.999971] [G loss: 1.000066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:27680[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:5 step:27685[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:5 step:27690[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:5 step:27695[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:5 step:27700[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:5 step:27705[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:5 step:27710[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:5 step:27715[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:5 step:27720[D loss: 1.000001] [G loss: 1.000052]\n",
      "epoch:5 step:27725[D loss: 0.999947] [G loss: 1.000117]\n",
      "epoch:5 step:27730[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:5 step:27735[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:5 step:27740[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:5 step:27745[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:5 step:27750[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:5 step:27755[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:5 step:27760[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:5 step:27765[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:5 step:27770[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:5 step:27775[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:5 step:27780[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:5 step:27785[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:5 step:27790[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:5 step:27795[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:5 step:27800[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:5 step:27805[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:5 step:27810[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:5 step:27815[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:5 step:27820[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:5 step:27825[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:5 step:27830[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:5 step:27835[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:5 step:27840[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:5 step:27845[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:5 step:27850[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:5 step:27855[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:5 step:27860[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:5 step:27865[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:5 step:27870[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:5 step:27875[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:5 step:27880[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:5 step:27885[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:5 step:27890[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:5 step:27895[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:5 step:27900[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:5 step:27905[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:5 step:27910[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:5 step:27915[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:5 step:27920[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:5 step:27925[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:5 step:27930[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:5 step:27935[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:5 step:27940[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:5 step:27945[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:5 step:27950[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:5 step:27955[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:5 step:27960[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:5 step:27965[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:5 step:27970[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:5 step:27975[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:5 step:27980[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:5 step:27985[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:5 step:27990[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:5 step:27995[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:5 step:28000[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:5 step:28005[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:5 step:28010[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:5 step:28015[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:5 step:28020[D loss: 0.999996] [G loss: 1.000071]\n",
      "epoch:5 step:28025[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:5 step:28030[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:5 step:28035[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:5 step:28040[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:5 step:28045[D loss: 0.999945] [G loss: 1.000116]\n",
      "epoch:5 step:28050[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:5 step:28055[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:5 step:28060[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:5 step:28065[D loss: 0.999972] [G loss: 1.000041]\n",
      "epoch:5 step:28070[D loss: 1.000000] [G loss: 1.000044]\n",
      "epoch:5 step:28075[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:5 step:28080[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:5 step:28085[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:5 step:28090[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:5 step:28095[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:5 step:28100[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:5 step:28105[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:5 step:28110[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:28115[D loss: 0.999990] [G loss: 1.000079]\n",
      "epoch:6 step:28120[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:6 step:28125[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:6 step:28130[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:6 step:28135[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:6 step:28140[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:6 step:28145[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:6 step:28150[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:28155[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:6 step:28160[D loss: 1.000044] [G loss: 1.000027]\n",
      "epoch:6 step:28165[D loss: 1.000010] [G loss: 1.000035]\n",
      "epoch:6 step:28170[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:6 step:28175[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:6 step:28180[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:6 step:28185[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:6 step:28190[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:6 step:28195[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:6 step:28200[D loss: 0.999998] [G loss: 0.999995]\n",
      "epoch:6 step:28205[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:6 step:28210[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:6 step:28215[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:6 step:28220[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:6 step:28225[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:6 step:28230[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:6 step:28235[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:6 step:28240[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:6 step:28245[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:6 step:28250[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:6 step:28255[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:6 step:28260[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:6 step:28265[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:6 step:28270[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:6 step:28275[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:6 step:28280[D loss: 0.999977] [G loss: 1.000136]\n",
      "epoch:6 step:28285[D loss: 0.999956] [G loss: 1.000107]\n",
      "epoch:6 step:28290[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:6 step:28295[D loss: 0.999985] [G loss: 1.000091]\n",
      "epoch:6 step:28300[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:6 step:28305[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:6 step:28310[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:6 step:28315[D loss: 1.000039] [G loss: 0.999957]\n",
      "epoch:6 step:28320[D loss: 0.999987] [G loss: 1.000013]\n",
      "epoch:6 step:28325[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:6 step:28330[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:6 step:28335[D loss: 0.999964] [G loss: 1.000114]\n",
      "epoch:6 step:28340[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:6 step:28345[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:6 step:28350[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:6 step:28355[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:6 step:28360[D loss: 0.999977] [G loss: 1.000011]\n",
      "epoch:6 step:28365[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:6 step:28370[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:6 step:28375[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:6 step:28380[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:6 step:28385[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:6 step:28390[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:6 step:28395[D loss: 0.999986] [G loss: 1.000127]\n",
      "epoch:6 step:28400[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:28405[D loss: 0.999960] [G loss: 1.000116]\n",
      "epoch:6 step:28410[D loss: 0.999980] [G loss: 1.000085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:28415[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:6 step:28420[D loss: 1.000018] [G loss: 0.999992]\n",
      "epoch:6 step:28425[D loss: 0.999993] [G loss: 1.000085]\n",
      "epoch:6 step:28430[D loss: 1.000023] [G loss: 1.000031]\n",
      "epoch:6 step:28435[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:6 step:28440[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:6 step:28445[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:6 step:28450[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:6 step:28455[D loss: 1.000020] [G loss: 1.000034]\n",
      "epoch:6 step:28460[D loss: 0.999972] [G loss: 1.000127]\n",
      "epoch:6 step:28465[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:6 step:28470[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:6 step:28475[D loss: 0.999991] [G loss: 1.000009]\n",
      "epoch:6 step:28480[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:6 step:28485[D loss: 1.000008] [G loss: 1.000031]\n",
      "epoch:6 step:28490[D loss: 0.999993] [G loss: 1.000004]\n",
      "epoch:6 step:28495[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:6 step:28500[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:6 step:28505[D loss: 0.999949] [G loss: 1.000115]\n",
      "epoch:6 step:28510[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:6 step:28515[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:6 step:28520[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:6 step:28525[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:6 step:28530[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:6 step:28535[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:6 step:28540[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:6 step:28545[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:6 step:28550[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:6 step:28555[D loss: 1.000004] [G loss: 1.000031]\n",
      "epoch:6 step:28560[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:6 step:28565[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:6 step:28570[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:6 step:28575[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:6 step:28580[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:6 step:28585[D loss: 1.000020] [G loss: 1.000049]\n",
      "epoch:6 step:28590[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:6 step:28595[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:6 step:28600[D loss: 0.999982] [G loss: 1.000112]\n",
      "epoch:6 step:28605[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:6 step:28610[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:6 step:28615[D loss: 1.000002] [G loss: 1.000042]\n",
      "epoch:6 step:28620[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:6 step:28625[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:6 step:28630[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:6 step:28635[D loss: 0.999961] [G loss: 1.000100]\n",
      "epoch:6 step:28640[D loss: 0.999984] [G loss: 1.000021]\n",
      "epoch:6 step:28645[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:6 step:28650[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:6 step:28655[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:6 step:28660[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:6 step:28665[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:6 step:28670[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:6 step:28675[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:6 step:28680[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:6 step:28685[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:6 step:28690[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:6 step:28695[D loss: 0.999998] [G loss: 1.000080]\n",
      "epoch:6 step:28700[D loss: 0.999973] [G loss: 1.000106]\n",
      "epoch:6 step:28705[D loss: 1.000019] [G loss: 0.999997]\n",
      "epoch:6 step:28710[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:6 step:28715[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:6 step:28720[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:6 step:28725[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:6 step:28730[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:6 step:28735[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:6 step:28740[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:6 step:28745[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:6 step:28750[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:6 step:28755[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:6 step:28760[D loss: 0.999996] [G loss: 1.000077]\n",
      "epoch:6 step:28765[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:6 step:28770[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:6 step:28775[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:6 step:28780[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:6 step:28785[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:6 step:28790[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:6 step:28795[D loss: 1.000000] [G loss: 1.000018]\n",
      "epoch:6 step:28800[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:6 step:28805[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:6 step:28810[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:6 step:28815[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:6 step:28820[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:28825[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:6 step:28830[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:6 step:28835[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:6 step:28840[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:6 step:28845[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:6 step:28850[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:6 step:28855[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:6 step:28860[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:6 step:28865[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:6 step:28870[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:6 step:28875[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:6 step:28880[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:6 step:28885[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:6 step:28890[D loss: 0.999978] [G loss: 1.000095]\n",
      "epoch:6 step:28895[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:6 step:28900[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:6 step:28905[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:6 step:28910[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:6 step:28915[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:6 step:28920[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:6 step:28925[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:6 step:28930[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:6 step:28935[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:6 step:28940[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:6 step:28945[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:28950[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:6 step:28955[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:6 step:28960[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:6 step:28965[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:6 step:28970[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:6 step:28975[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:6 step:28980[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:6 step:28985[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:6 step:28990[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:6 step:28995[D loss: 0.999954] [G loss: 1.000108]\n",
      "epoch:6 step:29000[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:6 step:29005[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:6 step:29010[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:6 step:29015[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:6 step:29020[D loss: 1.000005] [G loss: 1.000006]\n",
      "epoch:6 step:29025[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:6 step:29030[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:6 step:29035[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:6 step:29040[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:6 step:29045[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:6 step:29050[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:6 step:29055[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:6 step:29060[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:6 step:29065[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:6 step:29070[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:6 step:29075[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:6 step:29080[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:29085[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:6 step:29090[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:6 step:29095[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:6 step:29100[D loss: 0.999989] [G loss: 1.000097]\n",
      "epoch:6 step:29105[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:6 step:29110[D loss: 1.000004] [G loss: 1.000110]\n",
      "epoch:6 step:29115[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:6 step:29120[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:6 step:29125[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:6 step:29130[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:6 step:29135[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:6 step:29140[D loss: 1.000005] [G loss: 1.000066]\n",
      "epoch:6 step:29145[D loss: 0.999998] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:29150[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:6 step:29155[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:6 step:29160[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:6 step:29165[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:6 step:29170[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:6 step:29175[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:6 step:29180[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:6 step:29185[D loss: 0.999981] [G loss: 1.000108]\n",
      "epoch:6 step:29190[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:6 step:29195[D loss: 1.000001] [G loss: 1.000104]\n",
      "epoch:6 step:29200[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:6 step:29205[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:6 step:29210[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:6 step:29215[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:6 step:29220[D loss: 1.000027] [G loss: 0.999968]\n",
      "epoch:6 step:29225[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:6 step:29230[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:6 step:29235[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:6 step:29240[D loss: 0.999973] [G loss: 1.000114]\n",
      "epoch:6 step:29245[D loss: 1.000005] [G loss: 1.000070]\n",
      "epoch:6 step:29250[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:6 step:29255[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:6 step:29260[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:6 step:29265[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:6 step:29270[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:6 step:29275[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:6 step:29280[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:6 step:29285[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:6 step:29290[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:6 step:29295[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:6 step:29300[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:6 step:29305[D loss: 0.999981] [G loss: 1.000085]\n",
      "epoch:6 step:29310[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:6 step:29315[D loss: 0.999991] [G loss: 1.000084]\n",
      "epoch:6 step:29320[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:6 step:29325[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:6 step:29330[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:6 step:29335[D loss: 0.999953] [G loss: 1.000116]\n",
      "epoch:6 step:29340[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:6 step:29345[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:6 step:29350[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:6 step:29355[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:6 step:29360[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:6 step:29365[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:6 step:29370[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:6 step:29375[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:6 step:29380[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:6 step:29385[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:6 step:29390[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:6 step:29395[D loss: 0.999952] [G loss: 1.000071]\n",
      "epoch:6 step:29400[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:6 step:29405[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:6 step:29410[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:6 step:29415[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:6 step:29420[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:6 step:29425[D loss: 1.000042] [G loss: 1.000005]\n",
      "epoch:6 step:29430[D loss: 0.999918] [G loss: 1.000140]\n",
      "epoch:6 step:29435[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:6 step:29440[D loss: 1.000000] [G loss: 1.000085]\n",
      "epoch:6 step:29445[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:6 step:29450[D loss: 1.000009] [G loss: 1.000005]\n",
      "epoch:6 step:29455[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:6 step:29460[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:6 step:29465[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:6 step:29470[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:6 step:29475[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:6 step:29480[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:6 step:29485[D loss: 1.000023] [G loss: 1.000002]\n",
      "epoch:6 step:29490[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:6 step:29495[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:6 step:29500[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:6 step:29505[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:6 step:29510[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:6 step:29515[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:6 step:29520[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:6 step:29525[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:6 step:29530[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:6 step:29535[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:6 step:29540[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:6 step:29545[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:6 step:29550[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:6 step:29555[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:6 step:29560[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:6 step:29565[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:6 step:29570[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:6 step:29575[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:29580[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:6 step:29585[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:6 step:29590[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:6 step:29595[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:6 step:29600[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:6 step:29605[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:6 step:29610[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:6 step:29615[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:6 step:29620[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:6 step:29625[D loss: 1.000009] [G loss: 1.000026]\n",
      "epoch:6 step:29630[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:6 step:29635[D loss: 1.000009] [G loss: 1.000008]\n",
      "epoch:6 step:29640[D loss: 1.000007] [G loss: 1.000005]\n",
      "epoch:6 step:29645[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:6 step:29650[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:29655[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:6 step:29660[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:6 step:29665[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:6 step:29670[D loss: 0.999911] [G loss: 1.000139]\n",
      "epoch:6 step:29675[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:6 step:29680[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:6 step:29685[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:6 step:29690[D loss: 0.999990] [G loss: 1.000112]\n",
      "epoch:6 step:29695[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:6 step:29700[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:6 step:29705[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:6 step:29710[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:6 step:29715[D loss: 1.000034] [G loss: 1.000036]\n",
      "epoch:6 step:29720[D loss: 1.000019] [G loss: 1.000016]\n",
      "epoch:6 step:29725[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:6 step:29730[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:6 step:29735[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:6 step:29740[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:6 step:29745[D loss: 1.000012] [G loss: 1.000010]\n",
      "epoch:6 step:29750[D loss: 0.999934] [G loss: 1.000088]\n",
      "epoch:6 step:29755[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:6 step:29760[D loss: 1.000003] [G loss: 1.000041]\n",
      "epoch:6 step:29765[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:6 step:29770[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:6 step:29775[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:6 step:29780[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:6 step:29785[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:6 step:29790[D loss: 0.999992] [G loss: 1.000061]\n",
      "epoch:6 step:29795[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:6 step:29800[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:6 step:29805[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:6 step:29810[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:6 step:29815[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:6 step:29820[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:6 step:29825[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:6 step:29830[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:6 step:29835[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:6 step:29840[D loss: 1.000019] [G loss: 1.000027]\n",
      "epoch:6 step:29845[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:6 step:29850[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:6 step:29855[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:6 step:29860[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:6 step:29865[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:6 step:29870[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:6 step:29875[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:6 step:29880[D loss: 0.999974] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:29885[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:6 step:29890[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:6 step:29895[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:6 step:29900[D loss: 0.999980] [G loss: 1.000117]\n",
      "epoch:6 step:29905[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:6 step:29910[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:6 step:29915[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:6 step:29920[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:6 step:29925[D loss: 1.000045] [G loss: 0.999985]\n",
      "epoch:6 step:29930[D loss: 1.000073] [G loss: 0.999948]\n",
      "epoch:6 step:29935[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:6 step:29940[D loss: 0.999946] [G loss: 1.000124]\n",
      "epoch:6 step:29945[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:6 step:29950[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:6 step:29955[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:6 step:29960[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:6 step:29965[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:6 step:29970[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:6 step:29975[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:6 step:29980[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:6 step:29985[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:6 step:29990[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:6 step:29995[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:6 step:30000[D loss: 1.000059] [G loss: 0.999998]\n",
      "epoch:6 step:30005[D loss: 0.999934] [G loss: 1.000097]\n",
      "epoch:6 step:30010[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:6 step:30015[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:6 step:30020[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:6 step:30025[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:6 step:30030[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:6 step:30035[D loss: 1.000033] [G loss: 1.000001]\n",
      "epoch:6 step:30040[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:6 step:30045[D loss: 1.000033] [G loss: 1.000021]\n",
      "epoch:6 step:30050[D loss: 0.999953] [G loss: 1.000117]\n",
      "epoch:6 step:30055[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:6 step:30060[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:6 step:30065[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:6 step:30070[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:6 step:30075[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:6 step:30080[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:6 step:30085[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:6 step:30090[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:6 step:30095[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:6 step:30100[D loss: 1.000013] [G loss: 1.000035]\n",
      "epoch:6 step:30105[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:6 step:30110[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:6 step:30115[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:6 step:30120[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:6 step:30125[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:6 step:30130[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:6 step:30135[D loss: 1.000026] [G loss: 1.000003]\n",
      "epoch:6 step:30140[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:6 step:30145[D loss: 1.000003] [G loss: 1.000042]\n",
      "epoch:6 step:30150[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:6 step:30155[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:6 step:30160[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:6 step:30165[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:6 step:30170[D loss: 0.999991] [G loss: 1.000096]\n",
      "epoch:6 step:30175[D loss: 0.999956] [G loss: 1.000106]\n",
      "epoch:6 step:30180[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:6 step:30185[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:6 step:30190[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:6 step:30195[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:6 step:30200[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:6 step:30205[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:6 step:30210[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:6 step:30215[D loss: 1.000000] [G loss: 1.000072]\n",
      "epoch:6 step:30220[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:6 step:30225[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:6 step:30230[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:6 step:30235[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:6 step:30240[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:6 step:30245[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:6 step:30250[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:6 step:30255[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:6 step:30260[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:6 step:30265[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:6 step:30270[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:6 step:30275[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:6 step:30280[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:6 step:30285[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:6 step:30290[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:6 step:30295[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:6 step:30300[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:6 step:30305[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:6 step:30310[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:6 step:30315[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:6 step:30320[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:30325[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:6 step:30330[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:6 step:30335[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:6 step:30340[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:6 step:30345[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:6 step:30350[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:6 step:30355[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:6 step:30360[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:6 step:30365[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:6 step:30370[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:30375[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:6 step:30380[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:6 step:30385[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:6 step:30390[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:6 step:30395[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:6 step:30400[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:6 step:30405[D loss: 1.000031] [G loss: 1.000003]\n",
      "epoch:6 step:30410[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:6 step:30415[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:6 step:30420[D loss: 1.000006] [G loss: 0.999999]\n",
      "epoch:6 step:30425[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:6 step:30430[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:6 step:30435[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:6 step:30440[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:6 step:30445[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:6 step:30450[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:6 step:30455[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:6 step:30460[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:6 step:30465[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:6 step:30470[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:6 step:30475[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:6 step:30480[D loss: 1.000018] [G loss: 1.000002]\n",
      "epoch:6 step:30485[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:6 step:30490[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:6 step:30495[D loss: 0.999941] [G loss: 1.000096]\n",
      "epoch:6 step:30500[D loss: 1.000030] [G loss: 1.000004]\n",
      "epoch:6 step:30505[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:6 step:30510[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:6 step:30515[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:6 step:30520[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:6 step:30525[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:30530[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:6 step:30535[D loss: 0.999996] [G loss: 1.000063]\n",
      "epoch:6 step:30540[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:6 step:30545[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:6 step:30550[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:6 step:30555[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:6 step:30560[D loss: 0.999997] [G loss: 1.000046]\n",
      "epoch:6 step:30565[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:6 step:30570[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:6 step:30575[D loss: 0.999991] [G loss: 1.000103]\n",
      "epoch:6 step:30580[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:6 step:30585[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:6 step:30590[D loss: 0.999982] [G loss: 1.000112]\n",
      "epoch:6 step:30595[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:6 step:30600[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:6 step:30605[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:6 step:30610[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:6 step:30615[D loss: 0.999982] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:30620[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:6 step:30625[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:6 step:30630[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:6 step:30635[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:6 step:30640[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:6 step:30645[D loss: 1.000018] [G loss: 1.000015]\n",
      "epoch:6 step:30650[D loss: 0.999962] [G loss: 1.000113]\n",
      "epoch:6 step:30655[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:6 step:30660[D loss: 1.000031] [G loss: 1.000065]\n",
      "epoch:6 step:30665[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:30670[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:6 step:30675[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:6 step:30680[D loss: 0.999988] [G loss: 1.000004]\n",
      "epoch:6 step:30685[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:6 step:30690[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:6 step:30695[D loss: 1.000017] [G loss: 1.000044]\n",
      "epoch:6 step:30700[D loss: 0.999925] [G loss: 1.000118]\n",
      "epoch:6 step:30705[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:6 step:30710[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:6 step:30715[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:6 step:30720[D loss: 1.000020] [G loss: 1.000020]\n",
      "epoch:6 step:30725[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:6 step:30730[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:6 step:30735[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:6 step:30740[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:6 step:30745[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:6 step:30750[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:6 step:30755[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:6 step:30760[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:6 step:30765[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:6 step:30770[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:6 step:30775[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:6 step:30780[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:6 step:30785[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:6 step:30790[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:6 step:30795[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:6 step:30800[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:6 step:30805[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:6 step:30810[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:6 step:30815[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:6 step:30820[D loss: 0.999939] [G loss: 1.000113]\n",
      "epoch:6 step:30825[D loss: 0.999998] [G loss: 1.000060]\n",
      "epoch:6 step:30830[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:6 step:30835[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:6 step:30840[D loss: 0.999981] [G loss: 1.000127]\n",
      "epoch:6 step:30845[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:6 step:30850[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:6 step:30855[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:6 step:30860[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:6 step:30865[D loss: 1.000000] [G loss: 1.000073]\n",
      "epoch:6 step:30870[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:6 step:30875[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:6 step:30880[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:6 step:30885[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:6 step:30890[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:6 step:30895[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:6 step:30900[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:6 step:30905[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:6 step:30910[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:6 step:30915[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:6 step:30920[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:6 step:30925[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:6 step:30930[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:30935[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:6 step:30940[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:6 step:30945[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:6 step:30950[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:6 step:30955[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:6 step:30960[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:6 step:30965[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:6 step:30970[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:6 step:30975[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:6 step:30980[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:6 step:30985[D loss: 1.000005] [G loss: 0.999985]\n",
      "epoch:6 step:30990[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:6 step:30995[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:6 step:31000[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:6 step:31005[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:6 step:31010[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:6 step:31015[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:6 step:31020[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:6 step:31025[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:6 step:31030[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:6 step:31035[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:6 step:31040[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:6 step:31045[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:6 step:31050[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:6 step:31055[D loss: 0.999991] [G loss: 1.000100]\n",
      "epoch:6 step:31060[D loss: 0.999947] [G loss: 1.000125]\n",
      "epoch:6 step:31065[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:6 step:31070[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:6 step:31075[D loss: 1.000015] [G loss: 1.000025]\n",
      "epoch:6 step:31080[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:6 step:31085[D loss: 1.000009] [G loss: 1.000111]\n",
      "epoch:6 step:31090[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:6 step:31095[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:6 step:31100[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:6 step:31105[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:6 step:31110[D loss: 0.999990] [G loss: 1.000018]\n",
      "epoch:6 step:31115[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:6 step:31120[D loss: 0.999996] [G loss: 1.000006]\n",
      "epoch:6 step:31125[D loss: 0.999951] [G loss: 1.000068]\n",
      "epoch:6 step:31130[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:6 step:31135[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:6 step:31140[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:6 step:31145[D loss: 1.000007] [G loss: 1.000043]\n",
      "epoch:6 step:31150[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:6 step:31155[D loss: 0.999979] [G loss: 1.000129]\n",
      "epoch:6 step:31160[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:6 step:31165[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:6 step:31170[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:6 step:31175[D loss: 0.999973] [G loss: 1.000025]\n",
      "epoch:6 step:31180[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:6 step:31185[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:6 step:31190[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:6 step:31195[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:6 step:31200[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:6 step:31205[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:6 step:31210[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:6 step:31215[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:6 step:31220[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:6 step:31225[D loss: 0.999988] [G loss: 1.000023]\n",
      "epoch:6 step:31230[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:6 step:31235[D loss: 1.000004] [G loss: 1.000059]\n",
      "epoch:6 step:31240[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:6 step:31245[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:6 step:31250[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:6 step:31255[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:6 step:31260[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:6 step:31265[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:6 step:31270[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:6 step:31275[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:6 step:31280[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:6 step:31285[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:6 step:31290[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:6 step:31295[D loss: 1.000004] [G loss: 1.000058]\n",
      "epoch:6 step:31300[D loss: 0.999954] [G loss: 1.000086]\n",
      "epoch:6 step:31305[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:6 step:31310[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:6 step:31315[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:6 step:31320[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:6 step:31325[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:6 step:31330[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:6 step:31335[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:6 step:31340[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:6 step:31345[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:6 step:31350[D loss: 0.999969] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:31355[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:6 step:31360[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:6 step:31365[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:6 step:31370[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:6 step:31375[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:6 step:31380[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:6 step:31385[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:6 step:31390[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:6 step:31395[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:6 step:31400[D loss: 0.999992] [G loss: 1.000076]\n",
      "epoch:6 step:31405[D loss: 0.999965] [G loss: 1.000111]\n",
      "epoch:6 step:31410[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:6 step:31415[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:6 step:31420[D loss: 1.000008] [G loss: 1.000034]\n",
      "epoch:6 step:31425[D loss: 0.999960] [G loss: 1.000124]\n",
      "epoch:6 step:31430[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:6 step:31435[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:6 step:31440[D loss: 1.000007] [G loss: 1.000044]\n",
      "epoch:6 step:31445[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:6 step:31450[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:6 step:31455[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:6 step:31460[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:6 step:31465[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:6 step:31470[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:6 step:31475[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:6 step:31480[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:6 step:31485[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:6 step:31490[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:6 step:31495[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:6 step:31500[D loss: 0.999950] [G loss: 1.000121]\n",
      "epoch:6 step:31505[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:6 step:31510[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:6 step:31515[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:6 step:31520[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:6 step:31525[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:6 step:31530[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:6 step:31535[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:6 step:31540[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:6 step:31545[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:6 step:31550[D loss: 0.999956] [G loss: 1.000108]\n",
      "epoch:6 step:31555[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:6 step:31560[D loss: 0.999996] [G loss: 0.999998]\n",
      "epoch:6 step:31565[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:6 step:31570[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:6 step:31575[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:6 step:31580[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:6 step:31585[D loss: 0.999960] [G loss: 1.000052]\n",
      "epoch:6 step:31590[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:6 step:31595[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:31600[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:6 step:31605[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:6 step:31610[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:6 step:31615[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:6 step:31620[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:6 step:31625[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:6 step:31630[D loss: 0.999998] [G loss: 1.000008]\n",
      "epoch:6 step:31635[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:6 step:31640[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:6 step:31645[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:6 step:31650[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:6 step:31655[D loss: 1.000026] [G loss: 1.000019]\n",
      "epoch:6 step:31660[D loss: 1.000026] [G loss: 1.000019]\n",
      "epoch:6 step:31665[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:6 step:31670[D loss: 0.999945] [G loss: 1.000112]\n",
      "epoch:6 step:31675[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:6 step:31680[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:6 step:31685[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:6 step:31690[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:6 step:31695[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:6 step:31700[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:6 step:31705[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:6 step:31710[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:6 step:31715[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:6 step:31720[D loss: 1.000002] [G loss: 1.000041]\n",
      "epoch:6 step:31725[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:6 step:31730[D loss: 1.000011] [G loss: 1.000012]\n",
      "epoch:6 step:31735[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:31740[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:6 step:31745[D loss: 1.000009] [G loss: 1.000023]\n",
      "epoch:6 step:31750[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:6 step:31755[D loss: 0.999995] [G loss: 1.000035]\n",
      "epoch:6 step:31760[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:6 step:31765[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:6 step:31770[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:6 step:31775[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:6 step:31780[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:6 step:31785[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:6 step:31790[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:6 step:31795[D loss: 1.000009] [G loss: 1.000026]\n",
      "epoch:6 step:31800[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:6 step:31805[D loss: 1.000009] [G loss: 1.000049]\n",
      "epoch:6 step:31810[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:6 step:31815[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:6 step:31820[D loss: 1.000021] [G loss: 0.999995]\n",
      "epoch:6 step:31825[D loss: 0.999956] [G loss: 1.000058]\n",
      "epoch:6 step:31830[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:6 step:31835[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:6 step:31840[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:6 step:31845[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:6 step:31850[D loss: 1.000000] [G loss: 1.000004]\n",
      "epoch:6 step:31855[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:6 step:31860[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:6 step:31865[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:6 step:31870[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:6 step:31875[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:6 step:31880[D loss: 1.000012] [G loss: 1.000024]\n",
      "epoch:6 step:31885[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:6 step:31890[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:6 step:31895[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:6 step:31900[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:6 step:31905[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:6 step:31910[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:6 step:31915[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:6 step:31920[D loss: 0.999989] [G loss: 1.000084]\n",
      "epoch:6 step:31925[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:6 step:31930[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:6 step:31935[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:6 step:31940[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:6 step:31945[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:6 step:31950[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:6 step:31955[D loss: 0.999987] [G loss: 1.000012]\n",
      "epoch:6 step:31960[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:6 step:31965[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:6 step:31970[D loss: 1.000017] [G loss: 1.000021]\n",
      "epoch:6 step:31975[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:6 step:31980[D loss: 0.999973] [G loss: 1.000110]\n",
      "epoch:6 step:31985[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:6 step:31990[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:6 step:31995[D loss: 1.000003] [G loss: 1.000032]\n",
      "epoch:6 step:32000[D loss: 1.000020] [G loss: 1.000026]\n",
      "epoch:6 step:32005[D loss: 0.999932] [G loss: 1.000152]\n",
      "epoch:6 step:32010[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:6 step:32015[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:6 step:32020[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:6 step:32025[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:6 step:32030[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:6 step:32035[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:6 step:32040[D loss: 1.000001] [G loss: 1.000025]\n",
      "epoch:6 step:32045[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:6 step:32050[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:6 step:32055[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:6 step:32060[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:6 step:32065[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:6 step:32070[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:6 step:32075[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:6 step:32080[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:6 step:32085[D loss: 0.999992] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:32090[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:6 step:32095[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:6 step:32100[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:6 step:32105[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:6 step:32110[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:6 step:32115[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:6 step:32120[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:6 step:32125[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:6 step:32130[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:6 step:32135[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:6 step:32140[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:6 step:32145[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:6 step:32150[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:6 step:32155[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:6 step:32160[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:6 step:32165[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:6 step:32170[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:6 step:32175[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:6 step:32180[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:6 step:32185[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:6 step:32190[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:6 step:32195[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:6 step:32200[D loss: 0.999997] [G loss: 1.000043]\n",
      "epoch:6 step:32205[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:6 step:32210[D loss: 0.999992] [G loss: 1.000045]\n",
      "epoch:6 step:32215[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:6 step:32220[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:6 step:32225[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:6 step:32230[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:6 step:32235[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:6 step:32240[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:6 step:32245[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:6 step:32250[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:6 step:32255[D loss: 1.000013] [G loss: 1.000043]\n",
      "epoch:6 step:32260[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:6 step:32265[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:6 step:32270[D loss: 1.000021] [G loss: 1.000036]\n",
      "epoch:6 step:32275[D loss: 0.999949] [G loss: 1.000067]\n",
      "epoch:6 step:32280[D loss: 1.000018] [G loss: 1.000033]\n",
      "epoch:6 step:32285[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:6 step:32290[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:6 step:32295[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:6 step:32300[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:6 step:32305[D loss: 0.999992] [G loss: 1.000089]\n",
      "epoch:6 step:32310[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:6 step:32315[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:6 step:32320[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:6 step:32325[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:6 step:32330[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:6 step:32335[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:6 step:32340[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:6 step:32345[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:6 step:32350[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:6 step:32355[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:6 step:32360[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:32365[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:6 step:32370[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:6 step:32375[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:6 step:32380[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:6 step:32385[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:6 step:32390[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:6 step:32395[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:6 step:32400[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:6 step:32405[D loss: 0.999993] [G loss: 1.000084]\n",
      "epoch:6 step:32410[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:6 step:32415[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:6 step:32420[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:6 step:32425[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:6 step:32430[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:6 step:32435[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:6 step:32440[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:6 step:32445[D loss: 1.000027] [G loss: 0.999989]\n",
      "epoch:6 step:32450[D loss: 0.999951] [G loss: 1.000112]\n",
      "epoch:6 step:32455[D loss: 0.999982] [G loss: 1.000087]\n",
      "epoch:6 step:32460[D loss: 1.000001] [G loss: 1.000079]\n",
      "epoch:6 step:32465[D loss: 0.999965] [G loss: 1.000034]\n",
      "epoch:6 step:32470[D loss: 1.000000] [G loss: 1.000019]\n",
      "epoch:6 step:32475[D loss: 0.999973] [G loss: 1.000034]\n",
      "epoch:6 step:32480[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:6 step:32485[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:6 step:32490[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:6 step:32495[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:6 step:32500[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:6 step:32505[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:6 step:32510[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:6 step:32515[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:6 step:32520[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:6 step:32525[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:6 step:32530[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:6 step:32535[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:6 step:32540[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:6 step:32545[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:6 step:32550[D loss: 0.999997] [G loss: 1.000009]\n",
      "epoch:6 step:32555[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:6 step:32560[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:6 step:32565[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:6 step:32570[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:6 step:32575[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:6 step:32580[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:6 step:32585[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:6 step:32590[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:6 step:32595[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:6 step:32600[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:6 step:32605[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:6 step:32610[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:6 step:32615[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:6 step:32620[D loss: 0.999987] [G loss: 1.000073]\n",
      "epoch:6 step:32625[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:6 step:32630[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:6 step:32635[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:6 step:32640[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:6 step:32645[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:6 step:32650[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:6 step:32655[D loss: 0.999999] [G loss: 1.000025]\n",
      "epoch:6 step:32660[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:6 step:32665[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:6 step:32670[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:6 step:32675[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:6 step:32680[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:6 step:32685[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:6 step:32690[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:6 step:32695[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:6 step:32700[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:6 step:32705[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:6 step:32710[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:6 step:32715[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:6 step:32720[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:6 step:32725[D loss: 1.000005] [G loss: 1.000023]\n",
      "epoch:6 step:32730[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:6 step:32735[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:6 step:32740[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:6 step:32745[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:6 step:32750[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:6 step:32755[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:6 step:32760[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:6 step:32765[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:6 step:32770[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:6 step:32775[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:6 step:32780[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:6 step:32785[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:6 step:32790[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:6 step:32795[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:7 step:32800[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:7 step:32805[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:7 step:32810[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:7 step:32815[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:7 step:32820[D loss: 0.999982] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:32825[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:7 step:32830[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:7 step:32835[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:32840[D loss: 0.999989] [G loss: 1.000071]\n",
      "epoch:7 step:32845[D loss: 1.000029] [G loss: 1.000011]\n",
      "epoch:7 step:32850[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:7 step:32855[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:7 step:32860[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:7 step:32865[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:7 step:32870[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:7 step:32875[D loss: 0.999957] [G loss: 1.000102]\n",
      "epoch:7 step:32880[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:7 step:32885[D loss: 0.999996] [G loss: 0.999980]\n",
      "epoch:7 step:32890[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:7 step:32895[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:7 step:32900[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:7 step:32905[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:7 step:32910[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:7 step:32915[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:7 step:32920[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:7 step:32925[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:7 step:32930[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:7 step:32935[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:32940[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:7 step:32945[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:7 step:32950[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:7 step:32955[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:7 step:32960[D loss: 0.999995] [G loss: 1.000040]\n",
      "epoch:7 step:32965[D loss: 1.000034] [G loss: 1.000008]\n",
      "epoch:7 step:32970[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:7 step:32975[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:7 step:32980[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:7 step:32985[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:7 step:32990[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:7 step:32995[D loss: 1.000036] [G loss: 0.999983]\n",
      "epoch:7 step:33000[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:7 step:33005[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:7 step:33010[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:7 step:33015[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:7 step:33020[D loss: 0.999982] [G loss: 1.000101]\n",
      "epoch:7 step:33025[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:7 step:33030[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:7 step:33035[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:33040[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:33045[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:7 step:33050[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:7 step:33055[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:7 step:33060[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:7 step:33065[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:7 step:33070[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:7 step:33075[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:7 step:33080[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:7 step:33085[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:7 step:33090[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:7 step:33095[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:7 step:33100[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:7 step:33105[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:7 step:33110[D loss: 1.000053] [G loss: 0.999951]\n",
      "epoch:7 step:33115[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:7 step:33120[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:7 step:33125[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:7 step:33130[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:7 step:33135[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:7 step:33140[D loss: 1.000004] [G loss: 1.000081]\n",
      "epoch:7 step:33145[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:7 step:33150[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:7 step:33155[D loss: 0.999986] [G loss: 1.000100]\n",
      "epoch:7 step:33160[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:7 step:33165[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:7 step:33170[D loss: 0.999999] [G loss: 1.000076]\n",
      "epoch:7 step:33175[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:7 step:33180[D loss: 0.999954] [G loss: 1.000108]\n",
      "epoch:7 step:33185[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:7 step:33190[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:7 step:33195[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:7 step:33200[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:7 step:33205[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:7 step:33210[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:7 step:33215[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:7 step:33220[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:7 step:33225[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:7 step:33230[D loss: 0.999972] [G loss: 1.000088]\n",
      "epoch:7 step:33235[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:7 step:33240[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:7 step:33245[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:7 step:33250[D loss: 1.000008] [G loss: 1.000004]\n",
      "epoch:7 step:33255[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:7 step:33260[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:7 step:33265[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:7 step:33270[D loss: 0.999987] [G loss: 1.000097]\n",
      "epoch:7 step:33275[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:7 step:33280[D loss: 0.999967] [G loss: 1.000109]\n",
      "epoch:7 step:33285[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:7 step:33290[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:7 step:33295[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:7 step:33300[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:7 step:33305[D loss: 0.999995] [G loss: 1.000067]\n",
      "epoch:7 step:33310[D loss: 0.999970] [G loss: 1.000112]\n",
      "epoch:7 step:33315[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:7 step:33320[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:7 step:33325[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:7 step:33330[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:7 step:33335[D loss: 0.999944] [G loss: 1.000107]\n",
      "epoch:7 step:33340[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:7 step:33345[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:7 step:33350[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:7 step:33355[D loss: 0.999994] [G loss: 1.000056]\n",
      "epoch:7 step:33360[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:7 step:33365[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:7 step:33370[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:7 step:33375[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:7 step:33380[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:7 step:33385[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:7 step:33390[D loss: 0.999969] [G loss: 1.000145]\n",
      "epoch:7 step:33395[D loss: 0.999911] [G loss: 1.000147]\n",
      "epoch:7 step:33400[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:7 step:33405[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:7 step:33410[D loss: 0.999987] [G loss: 1.000075]\n",
      "epoch:7 step:33415[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:7 step:33420[D loss: 1.000039] [G loss: 0.999994]\n",
      "epoch:7 step:33425[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:7 step:33430[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:7 step:33435[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:7 step:33440[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:7 step:33445[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:7 step:33450[D loss: 1.000001] [G loss: 1.000056]\n",
      "epoch:7 step:33455[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:7 step:33460[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:7 step:33465[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:7 step:33470[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:7 step:33475[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:7 step:33480[D loss: 1.000000] [G loss: 0.999976]\n",
      "epoch:7 step:33485[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:7 step:33490[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:7 step:33495[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:7 step:33500[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:7 step:33505[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:7 step:33510[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:7 step:33515[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:33520[D loss: 1.000015] [G loss: 0.999976]\n",
      "epoch:7 step:33525[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:7 step:33530[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:7 step:33535[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:7 step:33540[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:7 step:33545[D loss: 1.000004] [G loss: 0.999984]\n",
      "epoch:7 step:33550[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:7 step:33555[D loss: 0.999974] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:33560[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:7 step:33565[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:7 step:33570[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:7 step:33575[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:7 step:33580[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:7 step:33585[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:7 step:33590[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:7 step:33595[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:7 step:33600[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:7 step:33605[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:7 step:33610[D loss: 0.999934] [G loss: 1.000094]\n",
      "epoch:7 step:33615[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:7 step:33620[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:7 step:33625[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:7 step:33630[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:7 step:33635[D loss: 0.999999] [G loss: 1.000005]\n",
      "epoch:7 step:33640[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:7 step:33645[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:7 step:33650[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:7 step:33655[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:7 step:33660[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:7 step:33665[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:7 step:33670[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:7 step:33675[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:33680[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:7 step:33685[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:7 step:33690[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:7 step:33695[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:7 step:33700[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:7 step:33705[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:7 step:33710[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:7 step:33715[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:7 step:33720[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:7 step:33725[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:33730[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:7 step:33735[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:7 step:33740[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:7 step:33745[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:7 step:33750[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:7 step:33755[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:7 step:33760[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:7 step:33765[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:7 step:33770[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:7 step:33775[D loss: 1.000000] [G loss: 1.000022]\n",
      "epoch:7 step:33780[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:7 step:33785[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:7 step:33790[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:7 step:33795[D loss: 1.000033] [G loss: 1.000021]\n",
      "epoch:7 step:33800[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:7 step:33805[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:7 step:33810[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:7 step:33815[D loss: 0.999974] [G loss: 1.000096]\n",
      "epoch:7 step:33820[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:7 step:33825[D loss: 1.000017] [G loss: 0.999995]\n",
      "epoch:7 step:33830[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:7 step:33835[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:33840[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:7 step:33845[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:7 step:33850[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:7 step:33855[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:7 step:33860[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:7 step:33865[D loss: 1.000003] [G loss: 1.000050]\n",
      "epoch:7 step:33870[D loss: 0.999957] [G loss: 1.000114]\n",
      "epoch:7 step:33875[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:7 step:33880[D loss: 1.000007] [G loss: 1.000104]\n",
      "epoch:7 step:33885[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:7 step:33890[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:7 step:33895[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:7 step:33900[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:7 step:33905[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:7 step:33910[D loss: 1.000016] [G loss: 1.000000]\n",
      "epoch:7 step:33915[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:7 step:33920[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:7 step:33925[D loss: 1.000048] [G loss: 0.999976]\n",
      "epoch:7 step:33930[D loss: 0.999962] [G loss: 1.000150]\n",
      "epoch:7 step:33935[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:7 step:33940[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:7 step:33945[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:7 step:33950[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:7 step:33955[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:7 step:33960[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:7 step:33965[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:7 step:33970[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:7 step:33975[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:7 step:33980[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:7 step:33985[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:7 step:33990[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:7 step:33995[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:34000[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:7 step:34005[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:7 step:34010[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:7 step:34015[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:7 step:34020[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:7 step:34025[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:7 step:34030[D loss: 1.000009] [G loss: 0.999987]\n",
      "epoch:7 step:34035[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:7 step:34040[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:7 step:34045[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:7 step:34050[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:7 step:34055[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:7 step:34060[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:7 step:34065[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:7 step:34070[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:7 step:34075[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:7 step:34080[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:7 step:34085[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:7 step:34090[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:7 step:34095[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:7 step:34100[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:7 step:34105[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:7 step:34110[D loss: 1.000032] [G loss: 1.000035]\n",
      "epoch:7 step:34115[D loss: 0.999940] [G loss: 1.000078]\n",
      "epoch:7 step:34120[D loss: 0.999939] [G loss: 1.000097]\n",
      "epoch:7 step:34125[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:7 step:34130[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:7 step:34135[D loss: 0.999989] [G loss: 1.000006]\n",
      "epoch:7 step:34140[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:7 step:34145[D loss: 1.000044] [G loss: 0.999937]\n",
      "epoch:7 step:34150[D loss: 0.999934] [G loss: 1.000098]\n",
      "epoch:7 step:34155[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:7 step:34160[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:7 step:34165[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:7 step:34170[D loss: 1.000013] [G loss: 1.000015]\n",
      "epoch:7 step:34175[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:7 step:34180[D loss: 0.999961] [G loss: 1.000047]\n",
      "epoch:7 step:34185[D loss: 0.999973] [G loss: 1.000112]\n",
      "epoch:7 step:34190[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:7 step:34195[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:7 step:34200[D loss: 0.999998] [G loss: 1.000015]\n",
      "epoch:7 step:34205[D loss: 0.999948] [G loss: 1.000103]\n",
      "epoch:7 step:34210[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:7 step:34215[D loss: 0.999995] [G loss: 1.000070]\n",
      "epoch:7 step:34220[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:7 step:34225[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:7 step:34230[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:7 step:34235[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:7 step:34240[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:7 step:34245[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:7 step:34250[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:7 step:34255[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:7 step:34260[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:7 step:34265[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:34270[D loss: 1.000009] [G loss: 1.000040]\n",
      "epoch:7 step:34275[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:7 step:34280[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:7 step:34285[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:7 step:34290[D loss: 0.999977] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:34295[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:7 step:34300[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:7 step:34305[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:7 step:34310[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:7 step:34315[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:7 step:34320[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:7 step:34325[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:7 step:34330[D loss: 0.999954] [G loss: 1.000076]\n",
      "epoch:7 step:34335[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:7 step:34340[D loss: 1.000023] [G loss: 1.000003]\n",
      "epoch:7 step:34345[D loss: 1.000011] [G loss: 0.999999]\n",
      "epoch:7 step:34350[D loss: 1.000024] [G loss: 1.000000]\n",
      "epoch:7 step:34355[D loss: 0.999949] [G loss: 1.000092]\n",
      "epoch:7 step:34360[D loss: 0.999923] [G loss: 1.000116]\n",
      "epoch:7 step:34365[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:7 step:34370[D loss: 0.999968] [G loss: 1.000113]\n",
      "epoch:7 step:34375[D loss: 1.000043] [G loss: 1.000048]\n",
      "epoch:7 step:34380[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:7 step:34385[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:7 step:34390[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:7 step:34395[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:7 step:34400[D loss: 1.000074] [G loss: 0.999991]\n",
      "epoch:7 step:34405[D loss: 1.000020] [G loss: 1.000028]\n",
      "epoch:7 step:34410[D loss: 1.000022] [G loss: 1.000038]\n",
      "epoch:7 step:34415[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:7 step:34420[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:7 step:34425[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:7 step:34430[D loss: 1.000032] [G loss: 1.000020]\n",
      "epoch:7 step:34435[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:7 step:34440[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:7 step:34445[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:7 step:34450[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:7 step:34455[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:7 step:34460[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:7 step:34465[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:7 step:34470[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:7 step:34475[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:7 step:34480[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:7 step:34485[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:7 step:34490[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:7 step:34495[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:7 step:34500[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:7 step:34505[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:7 step:34510[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:7 step:34515[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:7 step:34520[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:7 step:34525[D loss: 1.000015] [G loss: 1.000032]\n",
      "epoch:7 step:34530[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:7 step:34535[D loss: 1.000020] [G loss: 1.000020]\n",
      "epoch:7 step:34540[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:7 step:34545[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:7 step:34550[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:7 step:34555[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:7 step:34560[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:7 step:34565[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:7 step:34570[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:7 step:34575[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:7 step:34580[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:7 step:34585[D loss: 1.000013] [G loss: 1.000071]\n",
      "epoch:7 step:34590[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:7 step:34595[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:7 step:34600[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:7 step:34605[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:7 step:34610[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:7 step:34615[D loss: 1.000013] [G loss: 1.000054]\n",
      "epoch:7 step:34620[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:7 step:34625[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:7 step:34630[D loss: 0.999964] [G loss: 1.000114]\n",
      "epoch:7 step:34635[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:7 step:34640[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:7 step:34645[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:7 step:34650[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:7 step:34655[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:7 step:34660[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:7 step:34665[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:7 step:34670[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:7 step:34675[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:7 step:34680[D loss: 1.000023] [G loss: 0.999997]\n",
      "epoch:7 step:34685[D loss: 1.000012] [G loss: 1.000082]\n",
      "epoch:7 step:34690[D loss: 0.999938] [G loss: 1.000111]\n",
      "epoch:7 step:34695[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:7 step:34700[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:7 step:34705[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:7 step:34710[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:7 step:34715[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:7 step:34720[D loss: 1.000034] [G loss: 1.000008]\n",
      "epoch:7 step:34725[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:7 step:34730[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:7 step:34735[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:7 step:34740[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:7 step:34745[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:7 step:34750[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:7 step:34755[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:7 step:34760[D loss: 0.999998] [G loss: 1.000030]\n",
      "epoch:7 step:34765[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:7 step:34770[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:7 step:34775[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:7 step:34780[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:7 step:34785[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:7 step:34790[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:7 step:34795[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:7 step:34800[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:7 step:34805[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:7 step:34810[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:7 step:34815[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:7 step:34820[D loss: 0.999972] [G loss: 1.000097]\n",
      "epoch:7 step:34825[D loss: 1.000010] [G loss: 0.999937]\n",
      "epoch:7 step:34830[D loss: 1.000052] [G loss: 0.999999]\n",
      "epoch:7 step:34835[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:7 step:34840[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:7 step:34845[D loss: 0.999969] [G loss: 1.000131]\n",
      "epoch:7 step:34850[D loss: 0.999944] [G loss: 1.000077]\n",
      "epoch:7 step:34855[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:7 step:34860[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:7 step:34865[D loss: 1.000007] [G loss: 1.000004]\n",
      "epoch:7 step:34870[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:7 step:34875[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:7 step:34880[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:7 step:34885[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:7 step:34890[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:7 step:34895[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:7 step:34900[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:7 step:34905[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:7 step:34910[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:7 step:34915[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:7 step:34920[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:7 step:34925[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:7 step:34930[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:7 step:34935[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:7 step:34940[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:7 step:34945[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:7 step:34950[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:7 step:34955[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:7 step:34960[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:7 step:34965[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:7 step:34970[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:7 step:34975[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:7 step:34980[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:7 step:34985[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:7 step:34990[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:7 step:34995[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:7 step:35000[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:7 step:35005[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:7 step:35010[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:7 step:35015[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:7 step:35020[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:7 step:35025[D loss: 1.000003] [G loss: 0.999984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:35030[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:7 step:35035[D loss: 1.000030] [G loss: 1.000016]\n",
      "epoch:7 step:35040[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:7 step:35045[D loss: 0.999971] [G loss: 1.000113]\n",
      "epoch:7 step:35050[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:7 step:35055[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:7 step:35060[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:7 step:35065[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:7 step:35070[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:7 step:35075[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:7 step:35080[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:7 step:35085[D loss: 0.999951] [G loss: 1.000131]\n",
      "epoch:7 step:35090[D loss: 1.000073] [G loss: 1.000028]\n",
      "epoch:7 step:35095[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:7 step:35100[D loss: 0.999954] [G loss: 1.000062]\n",
      "epoch:7 step:35105[D loss: 1.000011] [G loss: 0.999998]\n",
      "epoch:7 step:35110[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:7 step:35115[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:7 step:35120[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:7 step:35125[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:7 step:35130[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:7 step:35135[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:7 step:35140[D loss: 0.999986] [G loss: 1.000102]\n",
      "epoch:7 step:35145[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:7 step:35150[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:7 step:35155[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:7 step:35160[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:7 step:35165[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:7 step:35170[D loss: 0.999938] [G loss: 1.000105]\n",
      "epoch:7 step:35175[D loss: 0.999949] [G loss: 1.000068]\n",
      "epoch:7 step:35180[D loss: 0.999960] [G loss: 1.000042]\n",
      "epoch:7 step:35185[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:7 step:35190[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:7 step:35195[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:7 step:35200[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:7 step:35205[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:7 step:35210[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:7 step:35215[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:7 step:35220[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:7 step:35225[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:7 step:35230[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:7 step:35235[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:7 step:35240[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:7 step:35245[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:7 step:35250[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:7 step:35255[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:7 step:35260[D loss: 1.000013] [G loss: 1.000050]\n",
      "epoch:7 step:35265[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:7 step:35270[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:7 step:35275[D loss: 1.000023] [G loss: 1.000043]\n",
      "epoch:7 step:35280[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:7 step:35285[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:7 step:35290[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:7 step:35295[D loss: 1.000017] [G loss: 1.000004]\n",
      "epoch:7 step:35300[D loss: 0.999986] [G loss: 1.000006]\n",
      "epoch:7 step:35305[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:7 step:35310[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:7 step:35315[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:7 step:35320[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:7 step:35325[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:7 step:35330[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:7 step:35335[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:7 step:35340[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:7 step:35345[D loss: 1.000001] [G loss: 1.000074]\n",
      "epoch:7 step:35350[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:7 step:35355[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:7 step:35360[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:7 step:35365[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:7 step:35370[D loss: 0.999938] [G loss: 1.000088]\n",
      "epoch:7 step:35375[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:7 step:35380[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:7 step:35385[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:7 step:35390[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:7 step:35395[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:7 step:35400[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:7 step:35405[D loss: 1.000003] [G loss: 1.000031]\n",
      "epoch:7 step:35410[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:7 step:35415[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:35420[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:7 step:35425[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:7 step:35430[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:7 step:35435[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:7 step:35440[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:7 step:35445[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:7 step:35450[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:7 step:35455[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:7 step:35460[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:7 step:35465[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:7 step:35470[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:7 step:35475[D loss: 0.999999] [G loss: 1.000067]\n",
      "epoch:7 step:35480[D loss: 0.999994] [G loss: 1.000082]\n",
      "epoch:7 step:35485[D loss: 1.000015] [G loss: 1.000014]\n",
      "epoch:7 step:35490[D loss: 0.999981] [G loss: 1.000109]\n",
      "epoch:7 step:35495[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:7 step:35500[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:7 step:35505[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:7 step:35510[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:7 step:35515[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:7 step:35520[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:7 step:35525[D loss: 0.999998] [G loss: 1.000070]\n",
      "epoch:7 step:35530[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:7 step:35535[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:7 step:35540[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:7 step:35545[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:7 step:35550[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:7 step:35555[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:7 step:35560[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:7 step:35565[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:7 step:35570[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:7 step:35575[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:7 step:35580[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:7 step:35585[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:7 step:35590[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:7 step:35595[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:7 step:35600[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:7 step:35605[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:7 step:35610[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:7 step:35615[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:7 step:35620[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:7 step:35625[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:7 step:35630[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:7 step:35635[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:7 step:35640[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:7 step:35645[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:7 step:35650[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:7 step:35655[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:7 step:35660[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:7 step:35665[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:7 step:35670[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:7 step:35675[D loss: 0.999950] [G loss: 1.000118]\n",
      "epoch:7 step:35680[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:7 step:35685[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:7 step:35690[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:7 step:35695[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:7 step:35700[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:7 step:35705[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:7 step:35710[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:7 step:35715[D loss: 0.999961] [G loss: 1.000040]\n",
      "epoch:7 step:35720[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:7 step:35725[D loss: 0.999995] [G loss: 1.000002]\n",
      "epoch:7 step:35730[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:7 step:35735[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:7 step:35740[D loss: 1.000017] [G loss: 1.000017]\n",
      "epoch:7 step:35745[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:7 step:35750[D loss: 0.999974] [G loss: 1.000042]\n",
      "epoch:7 step:35755[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:7 step:35760[D loss: 0.999994] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:35765[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:7 step:35770[D loss: 0.999994] [G loss: 1.000068]\n",
      "epoch:7 step:35775[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:7 step:35780[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:7 step:35785[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:7 step:35790[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:7 step:35795[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:7 step:35800[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:7 step:35805[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:7 step:35810[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:7 step:35815[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:7 step:35820[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:7 step:35825[D loss: 1.000020] [G loss: 1.000013]\n",
      "epoch:7 step:35830[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:7 step:35835[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:7 step:35840[D loss: 0.999985] [G loss: 1.000136]\n",
      "epoch:7 step:35845[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:7 step:35850[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:7 step:35855[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:7 step:35860[D loss: 1.000000] [G loss: 1.000011]\n",
      "epoch:7 step:35865[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:7 step:35870[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:7 step:35875[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:7 step:35880[D loss: 1.000027] [G loss: 0.999996]\n",
      "epoch:7 step:35885[D loss: 0.999957] [G loss: 1.000141]\n",
      "epoch:7 step:35890[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:7 step:35895[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:7 step:35900[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:7 step:35905[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:35910[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:7 step:35915[D loss: 0.999991] [G loss: 1.000021]\n",
      "epoch:7 step:35920[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:7 step:35925[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:7 step:35930[D loss: 1.000026] [G loss: 1.000046]\n",
      "epoch:7 step:35935[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:7 step:35940[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:7 step:35945[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:7 step:35950[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:7 step:35955[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:7 step:35960[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:7 step:35965[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:7 step:35970[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:7 step:35975[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:7 step:35980[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:7 step:35985[D loss: 0.999954] [G loss: 1.000064]\n",
      "epoch:7 step:35990[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:7 step:35995[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:7 step:36000[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:7 step:36005[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:7 step:36010[D loss: 0.999993] [G loss: 1.000043]\n",
      "epoch:7 step:36015[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:7 step:36020[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:7 step:36025[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:7 step:36030[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:7 step:36035[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:7 step:36040[D loss: 0.999990] [G loss: 1.000081]\n",
      "epoch:7 step:36045[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:7 step:36050[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:7 step:36055[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:7 step:36060[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:7 step:36065[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:7 step:36070[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:36075[D loss: 0.999951] [G loss: 1.000090]\n",
      "epoch:7 step:36080[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:7 step:36085[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:7 step:36090[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:7 step:36095[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:7 step:36100[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:7 step:36105[D loss: 1.000000] [G loss: 1.000102]\n",
      "epoch:7 step:36110[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:7 step:36115[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:7 step:36120[D loss: 1.000013] [G loss: 0.999999]\n",
      "epoch:7 step:36125[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:7 step:36130[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:7 step:36135[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:7 step:36140[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:7 step:36145[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:36150[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:7 step:36155[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:7 step:36160[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:7 step:36165[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:7 step:36170[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:7 step:36175[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:7 step:36180[D loss: 0.999942] [G loss: 1.000108]\n",
      "epoch:7 step:36185[D loss: 0.999999] [G loss: 1.000039]\n",
      "epoch:7 step:36190[D loss: 0.999948] [G loss: 1.000117]\n",
      "epoch:7 step:36195[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:7 step:36200[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:7 step:36205[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:7 step:36210[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:7 step:36215[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:7 step:36220[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:7 step:36225[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:7 step:36230[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:7 step:36235[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:7 step:36240[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:7 step:36245[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:7 step:36250[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:7 step:36255[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:7 step:36260[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:7 step:36265[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:36270[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:7 step:36275[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:7 step:36280[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:7 step:36285[D loss: 0.999997] [G loss: 1.000064]\n",
      "epoch:7 step:36290[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:7 step:36295[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:7 step:36300[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:7 step:36305[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:7 step:36310[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:7 step:36315[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:7 step:36320[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:7 step:36325[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:7 step:36330[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:7 step:36335[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:7 step:36340[D loss: 1.000008] [G loss: 1.000047]\n",
      "epoch:7 step:36345[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:7 step:36350[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:7 step:36355[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:7 step:36360[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:7 step:36365[D loss: 1.000023] [G loss: 1.000044]\n",
      "epoch:7 step:36370[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:7 step:36375[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:7 step:36380[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:7 step:36385[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:7 step:36390[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:7 step:36395[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:7 step:36400[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:7 step:36405[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:7 step:36410[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:7 step:36415[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:7 step:36420[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:7 step:36425[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:7 step:36430[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:7 step:36435[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:7 step:36440[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:7 step:36445[D loss: 1.000019] [G loss: 1.000011]\n",
      "epoch:7 step:36450[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:7 step:36455[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:7 step:36460[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:7 step:36465[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:7 step:36470[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:7 step:36475[D loss: 0.999997] [G loss: 1.000038]\n",
      "epoch:7 step:36480[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:7 step:36485[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:7 step:36490[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:7 step:36495[D loss: 0.999961] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:36500[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:7 step:36505[D loss: 1.000059] [G loss: 0.999980]\n",
      "epoch:7 step:36510[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:7 step:36515[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:7 step:36520[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:7 step:36525[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:7 step:36530[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:7 step:36535[D loss: 0.999949] [G loss: 1.000122]\n",
      "epoch:7 step:36540[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:7 step:36545[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:7 step:36550[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:7 step:36555[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:7 step:36560[D loss: 0.999999] [G loss: 1.000021]\n",
      "epoch:7 step:36565[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:7 step:36570[D loss: 0.999944] [G loss: 1.000093]\n",
      "epoch:7 step:36575[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:7 step:36580[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:7 step:36585[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:7 step:36590[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:7 step:36595[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:7 step:36600[D loss: 0.999945] [G loss: 1.000106]\n",
      "epoch:7 step:36605[D loss: 0.999963] [G loss: 1.000112]\n",
      "epoch:7 step:36610[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:7 step:36615[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:7 step:36620[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:7 step:36625[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:7 step:36630[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:7 step:36635[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:7 step:36640[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:7 step:36645[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:7 step:36650[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:7 step:36655[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:7 step:36660[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:7 step:36665[D loss: 1.000002] [G loss: 1.000015]\n",
      "epoch:7 step:36670[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:7 step:36675[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:7 step:36680[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:7 step:36685[D loss: 1.000037] [G loss: 0.999957]\n",
      "epoch:7 step:36690[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:7 step:36695[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:7 step:36700[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:7 step:36705[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:7 step:36710[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:7 step:36715[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:7 step:36720[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:7 step:36725[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:7 step:36730[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:7 step:36735[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:7 step:36740[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:7 step:36745[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:7 step:36750[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:7 step:36755[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:7 step:36760[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:7 step:36765[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:7 step:36770[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:7 step:36775[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:7 step:36780[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:7 step:36785[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:7 step:36790[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:7 step:36795[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:7 step:36800[D loss: 1.000010] [G loss: 1.000042]\n",
      "epoch:7 step:36805[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:7 step:36810[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:7 step:36815[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:7 step:36820[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:7 step:36825[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:7 step:36830[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:7 step:36835[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:7 step:36840[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:7 step:36845[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:7 step:36850[D loss: 0.999993] [G loss: 1.000014]\n",
      "epoch:7 step:36855[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:7 step:36860[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:7 step:36865[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:7 step:36870[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:7 step:36875[D loss: 1.000001] [G loss: 1.000021]\n",
      "epoch:7 step:36880[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:7 step:36885[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:7 step:36890[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:7 step:36895[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:7 step:36900[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:7 step:36905[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:7 step:36910[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:7 step:36915[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:7 step:36920[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:7 step:36925[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:7 step:36930[D loss: 0.999981] [G loss: 1.000010]\n",
      "epoch:7 step:36935[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:7 step:36940[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:7 step:36945[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:7 step:36950[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:7 step:36955[D loss: 1.000046] [G loss: 0.999957]\n",
      "epoch:7 step:36960[D loss: 0.999994] [G loss: 0.999987]\n",
      "epoch:7 step:36965[D loss: 1.000026] [G loss: 1.000018]\n",
      "epoch:7 step:36970[D loss: 1.000000] [G loss: 1.000012]\n",
      "epoch:7 step:36975[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:7 step:36980[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:7 step:36985[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:7 step:36990[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:7 step:36995[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:7 step:37000[D loss: 1.000050] [G loss: 0.999949]\n",
      "epoch:7 step:37005[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:7 step:37010[D loss: 0.999966] [G loss: 1.000042]\n",
      "epoch:7 step:37015[D loss: 1.000014] [G loss: 1.000012]\n",
      "epoch:7 step:37020[D loss: 0.999951] [G loss: 1.000102]\n",
      "epoch:7 step:37025[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:7 step:37030[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:7 step:37035[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:7 step:37040[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:7 step:37045[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:7 step:37050[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:7 step:37055[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:7 step:37060[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:7 step:37065[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:7 step:37070[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:7 step:37075[D loss: 1.000009] [G loss: 1.000025]\n",
      "epoch:7 step:37080[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:7 step:37085[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:7 step:37090[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:7 step:37095[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:7 step:37100[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:7 step:37105[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:7 step:37110[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:7 step:37115[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:7 step:37120[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:7 step:37125[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:7 step:37130[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:7 step:37135[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:7 step:37140[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:7 step:37145[D loss: 1.000016] [G loss: 1.000033]\n",
      "epoch:7 step:37150[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:7 step:37155[D loss: 1.000028] [G loss: 0.999937]\n",
      "epoch:7 step:37160[D loss: 0.999957] [G loss: 1.000046]\n",
      "epoch:7 step:37165[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:7 step:37170[D loss: 1.000028] [G loss: 0.999958]\n",
      "epoch:7 step:37175[D loss: 0.999981] [G loss: 1.000015]\n",
      "epoch:7 step:37180[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:7 step:37185[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:7 step:37190[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:7 step:37195[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:7 step:37200[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:7 step:37205[D loss: 0.999992] [G loss: 1.000008]\n",
      "epoch:7 step:37210[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:7 step:37215[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:7 step:37220[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:7 step:37225[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:7 step:37230[D loss: 0.999970] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:37235[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:7 step:37240[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:7 step:37245[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:7 step:37250[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:7 step:37255[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:7 step:37260[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:7 step:37265[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:7 step:37270[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:7 step:37275[D loss: 1.000025] [G loss: 1.000026]\n",
      "epoch:7 step:37280[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:7 step:37285[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:7 step:37290[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:7 step:37295[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:7 step:37300[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:7 step:37305[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:7 step:37310[D loss: 0.999986] [G loss: 1.000095]\n",
      "epoch:7 step:37315[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:7 step:37320[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:7 step:37325[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:7 step:37330[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:7 step:37335[D loss: 1.000065] [G loss: 0.999902]\n",
      "epoch:7 step:37340[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:7 step:37345[D loss: 0.999967] [G loss: 1.000022]\n",
      "epoch:7 step:37350[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:7 step:37355[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:7 step:37360[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:7 step:37365[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:7 step:37370[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:7 step:37375[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:7 step:37380[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:7 step:37385[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:7 step:37390[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:7 step:37395[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:7 step:37400[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:7 step:37405[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:7 step:37410[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:7 step:37415[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:7 step:37420[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:7 step:37425[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:37430[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:7 step:37435[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:7 step:37440[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:7 step:37445[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:7 step:37450[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:7 step:37455[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:7 step:37460[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:7 step:37465[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:7 step:37470[D loss: 1.000016] [G loss: 1.000021]\n",
      "epoch:7 step:37475[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:7 step:37480[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:8 step:37485[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:8 step:37490[D loss: 1.000002] [G loss: 1.000008]\n",
      "epoch:8 step:37495[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:8 step:37500[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:8 step:37505[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:8 step:37510[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:8 step:37515[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:8 step:37520[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:8 step:37525[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:8 step:37530[D loss: 1.000047] [G loss: 0.999993]\n",
      "epoch:8 step:37535[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:8 step:37540[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:8 step:37545[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:8 step:37550[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:8 step:37555[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:8 step:37560[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:8 step:37565[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:8 step:37570[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:8 step:37575[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:8 step:37580[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:8 step:37585[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:8 step:37590[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:8 step:37595[D loss: 0.999946] [G loss: 1.000116]\n",
      "epoch:8 step:37600[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:8 step:37605[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:8 step:37610[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:8 step:37615[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:8 step:37620[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:8 step:37625[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:8 step:37630[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:8 step:37635[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:8 step:37640[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:8 step:37645[D loss: 0.999951] [G loss: 1.000105]\n",
      "epoch:8 step:37650[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:8 step:37655[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:8 step:37660[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:8 step:37665[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:8 step:37670[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:8 step:37675[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:8 step:37680[D loss: 0.999996] [G loss: 1.000072]\n",
      "epoch:8 step:37685[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:8 step:37690[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:8 step:37695[D loss: 0.999949] [G loss: 1.000109]\n",
      "epoch:8 step:37700[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:8 step:37705[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:8 step:37710[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:8 step:37715[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:8 step:37720[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:8 step:37725[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:8 step:37730[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:8 step:37735[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:8 step:37740[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:8 step:37745[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:8 step:37750[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:8 step:37755[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:8 step:37760[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:8 step:37765[D loss: 0.999998] [G loss: 1.000066]\n",
      "epoch:8 step:37770[D loss: 0.999991] [G loss: 1.000088]\n",
      "epoch:8 step:37775[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:8 step:37780[D loss: 0.999965] [G loss: 1.000109]\n",
      "epoch:8 step:37785[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:8 step:37790[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:8 step:37795[D loss: 1.000032] [G loss: 0.999975]\n",
      "epoch:8 step:37800[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:8 step:37805[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:8 step:37810[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:8 step:37815[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:8 step:37820[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:8 step:37825[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:8 step:37830[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:8 step:37835[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:8 step:37840[D loss: 1.000005] [G loss: 1.000069]\n",
      "epoch:8 step:37845[D loss: 0.999946] [G loss: 1.000149]\n",
      "epoch:8 step:37850[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:8 step:37855[D loss: 1.000023] [G loss: 1.000003]\n",
      "epoch:8 step:37860[D loss: 0.999951] [G loss: 1.000062]\n",
      "epoch:8 step:37865[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:37870[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:8 step:37875[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:8 step:37880[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:8 step:37885[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:8 step:37890[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:8 step:37895[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:8 step:37900[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:8 step:37905[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:8 step:37910[D loss: 1.000008] [G loss: 1.000003]\n",
      "epoch:8 step:37915[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:8 step:37920[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:8 step:37925[D loss: 1.000003] [G loss: 1.000074]\n",
      "epoch:8 step:37930[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:8 step:37935[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:8 step:37940[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:8 step:37945[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:8 step:37950[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:8 step:37955[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:8 step:37960[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:8 step:37965[D loss: 0.999972] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:37970[D loss: 0.999923] [G loss: 1.000137]\n",
      "epoch:8 step:37975[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:8 step:37980[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:8 step:37985[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:8 step:37990[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:8 step:37995[D loss: 0.999969] [G loss: 1.000100]\n",
      "epoch:8 step:38000[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:8 step:38005[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:8 step:38010[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:8 step:38015[D loss: 0.999980] [G loss: 1.000106]\n",
      "epoch:8 step:38020[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:8 step:38025[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:8 step:38030[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:8 step:38035[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:8 step:38040[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:8 step:38045[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:8 step:38050[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:8 step:38055[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:8 step:38060[D loss: 0.999992] [G loss: 1.000016]\n",
      "epoch:8 step:38065[D loss: 0.999977] [G loss: 1.000131]\n",
      "epoch:8 step:38070[D loss: 0.999948] [G loss: 1.000135]\n",
      "epoch:8 step:38075[D loss: 0.999998] [G loss: 1.000066]\n",
      "epoch:8 step:38080[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:8 step:38085[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:8 step:38090[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:8 step:38095[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:8 step:38100[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:8 step:38105[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:8 step:38110[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:8 step:38115[D loss: 0.999992] [G loss: 1.000071]\n",
      "epoch:8 step:38120[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:8 step:38125[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:8 step:38130[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:8 step:38135[D loss: 1.000006] [G loss: 1.000028]\n",
      "epoch:8 step:38140[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:8 step:38145[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:8 step:38150[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:38155[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:8 step:38160[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:8 step:38165[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:8 step:38170[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:8 step:38175[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:8 step:38180[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:8 step:38185[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:8 step:38190[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:8 step:38195[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:8 step:38200[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:8 step:38205[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:8 step:38210[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:8 step:38215[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:8 step:38220[D loss: 0.999987] [G loss: 1.000091]\n",
      "epoch:8 step:38225[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:8 step:38230[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:8 step:38235[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:8 step:38240[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:8 step:38245[D loss: 0.999992] [G loss: 1.000057]\n",
      "epoch:8 step:38250[D loss: 0.999990] [G loss: 1.000025]\n",
      "epoch:8 step:38255[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:38260[D loss: 0.999961] [G loss: 1.000124]\n",
      "epoch:8 step:38265[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:8 step:38270[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:8 step:38275[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:8 step:38280[D loss: 0.999965] [G loss: 1.000100]\n",
      "epoch:8 step:38285[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:8 step:38290[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:8 step:38295[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:8 step:38300[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:8 step:38305[D loss: 0.999993] [G loss: 1.000061]\n",
      "epoch:8 step:38310[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:8 step:38315[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:8 step:38320[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:8 step:38325[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:8 step:38330[D loss: 0.999960] [G loss: 1.000110]\n",
      "epoch:8 step:38335[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:8 step:38340[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:8 step:38345[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:8 step:38350[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:8 step:38355[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:8 step:38360[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:8 step:38365[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:8 step:38370[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:8 step:38375[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:8 step:38380[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:8 step:38385[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:8 step:38390[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:8 step:38395[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:8 step:38400[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:8 step:38405[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:8 step:38410[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:8 step:38415[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:8 step:38420[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:8 step:38425[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:8 step:38430[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:8 step:38435[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:8 step:38440[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:8 step:38445[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:8 step:38450[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:8 step:38455[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:8 step:38460[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:8 step:38465[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:8 step:38470[D loss: 0.999991] [G loss: 1.000107]\n",
      "epoch:8 step:38475[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:8 step:38480[D loss: 1.000025] [G loss: 1.000022]\n",
      "epoch:8 step:38485[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:8 step:38490[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:8 step:38495[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:8 step:38500[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:8 step:38505[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:8 step:38510[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:8 step:38515[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:8 step:38520[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:8 step:38525[D loss: 1.000010] [G loss: 1.000066]\n",
      "epoch:8 step:38530[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:8 step:38535[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:8 step:38540[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:8 step:38545[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:8 step:38550[D loss: 0.999993] [G loss: 1.000090]\n",
      "epoch:8 step:38555[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:8 step:38560[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:8 step:38565[D loss: 1.000006] [G loss: 1.000093]\n",
      "epoch:8 step:38570[D loss: 0.999960] [G loss: 1.000104]\n",
      "epoch:8 step:38575[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:8 step:38580[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:8 step:38585[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:8 step:38590[D loss: 1.000000] [G loss: 1.000029]\n",
      "epoch:8 step:38595[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:8 step:38600[D loss: 0.999953] [G loss: 1.000063]\n",
      "epoch:8 step:38605[D loss: 0.999970] [G loss: 1.000102]\n",
      "epoch:8 step:38610[D loss: 0.999972] [G loss: 1.000128]\n",
      "epoch:8 step:38615[D loss: 1.000041] [G loss: 1.000002]\n",
      "epoch:8 step:38620[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:8 step:38625[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:8 step:38630[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:8 step:38635[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:8 step:38640[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:8 step:38645[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:8 step:38650[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:8 step:38655[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:8 step:38660[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:8 step:38665[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:8 step:38670[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:8 step:38675[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:8 step:38680[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:8 step:38685[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:8 step:38690[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:8 step:38695[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:8 step:38700[D loss: 0.999972] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:38705[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:8 step:38710[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:8 step:38715[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:8 step:38720[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:8 step:38725[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:8 step:38730[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:8 step:38735[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:8 step:38740[D loss: 0.999986] [G loss: 1.000038]\n",
      "epoch:8 step:38745[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:8 step:38750[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:8 step:38755[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:8 step:38760[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:8 step:38765[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:8 step:38770[D loss: 1.000039] [G loss: 0.999961]\n",
      "epoch:8 step:38775[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:8 step:38780[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:8 step:38785[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:8 step:38790[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:8 step:38795[D loss: 1.000000] [G loss: 1.000081]\n",
      "epoch:8 step:38800[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:8 step:38805[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:8 step:38810[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:8 step:38815[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:8 step:38820[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:8 step:38825[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:8 step:38830[D loss: 0.999949] [G loss: 1.000109]\n",
      "epoch:8 step:38835[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:8 step:38840[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:8 step:38845[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:8 step:38850[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:8 step:38855[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:8 step:38860[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:8 step:38865[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:8 step:38870[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:8 step:38875[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:8 step:38880[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:8 step:38885[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:8 step:38890[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:8 step:38895[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:8 step:38900[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:8 step:38905[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:8 step:38910[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:8 step:38915[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:8 step:38920[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:8 step:38925[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:8 step:38930[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:8 step:38935[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:8 step:38940[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:8 step:38945[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:8 step:38950[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:8 step:38955[D loss: 0.999948] [G loss: 1.000137]\n",
      "epoch:8 step:38960[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:8 step:38965[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:8 step:38970[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:8 step:38975[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:8 step:38980[D loss: 1.000027] [G loss: 0.999987]\n",
      "epoch:8 step:38985[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:8 step:38990[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:8 step:38995[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:8 step:39000[D loss: 1.000020] [G loss: 1.000019]\n",
      "epoch:8 step:39005[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:8 step:39010[D loss: 0.999990] [G loss: 1.000081]\n",
      "epoch:8 step:39015[D loss: 0.999943] [G loss: 1.000068]\n",
      "epoch:8 step:39020[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:8 step:39025[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:8 step:39030[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:8 step:39035[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:8 step:39040[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:8 step:39045[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:8 step:39050[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:8 step:39055[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:8 step:39060[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:8 step:39065[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:8 step:39070[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:8 step:39075[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:8 step:39080[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:8 step:39085[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:8 step:39090[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:8 step:39095[D loss: 0.999964] [G loss: 1.000136]\n",
      "epoch:8 step:39100[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:8 step:39105[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:8 step:39110[D loss: 1.000006] [G loss: 1.000039]\n",
      "epoch:8 step:39115[D loss: 1.000050] [G loss: 0.999969]\n",
      "epoch:8 step:39120[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:8 step:39125[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:8 step:39130[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:8 step:39135[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:8 step:39140[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:8 step:39145[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:8 step:39150[D loss: 1.000010] [G loss: 1.000019]\n",
      "epoch:8 step:39155[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:8 step:39160[D loss: 0.999995] [G loss: 1.000015]\n",
      "epoch:8 step:39165[D loss: 0.999952] [G loss: 1.000126]\n",
      "epoch:8 step:39170[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:8 step:39175[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:8 step:39180[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:8 step:39185[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:8 step:39190[D loss: 0.999997] [G loss: 1.000018]\n",
      "epoch:8 step:39195[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:8 step:39200[D loss: 0.999962] [G loss: 1.000135]\n",
      "epoch:8 step:39205[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:8 step:39210[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:8 step:39215[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:8 step:39220[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:8 step:39225[D loss: 1.000000] [G loss: 1.000043]\n",
      "epoch:8 step:39230[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:8 step:39235[D loss: 0.999950] [G loss: 1.000116]\n",
      "epoch:8 step:39240[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:8 step:39245[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:8 step:39250[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:8 step:39255[D loss: 0.999970] [G loss: 1.000102]\n",
      "epoch:8 step:39260[D loss: 1.000000] [G loss: 1.000062]\n",
      "epoch:8 step:39265[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:8 step:39270[D loss: 1.000013] [G loss: 1.000044]\n",
      "epoch:8 step:39275[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:8 step:39280[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:8 step:39285[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:8 step:39290[D loss: 1.000017] [G loss: 1.000019]\n",
      "epoch:8 step:39295[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:8 step:39300[D loss: 1.000015] [G loss: 1.000039]\n",
      "epoch:8 step:39305[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:8 step:39310[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:8 step:39315[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:8 step:39320[D loss: 0.999936] [G loss: 1.000124]\n",
      "epoch:8 step:39325[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:8 step:39330[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:8 step:39335[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:8 step:39340[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:8 step:39345[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:8 step:39350[D loss: 0.999998] [G loss: 1.000062]\n",
      "epoch:8 step:39355[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:8 step:39360[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:8 step:39365[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:8 step:39370[D loss: 1.000028] [G loss: 1.000071]\n",
      "epoch:8 step:39375[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:8 step:39380[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:8 step:39385[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:8 step:39390[D loss: 0.999956] [G loss: 1.000049]\n",
      "epoch:8 step:39395[D loss: 1.000033] [G loss: 0.999978]\n",
      "epoch:8 step:39400[D loss: 0.999945] [G loss: 1.000111]\n",
      "epoch:8 step:39405[D loss: 1.000021] [G loss: 1.000046]\n",
      "epoch:8 step:39410[D loss: 0.999948] [G loss: 1.000086]\n",
      "epoch:8 step:39415[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:8 step:39420[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:8 step:39425[D loss: 0.999975] [G loss: 1.000098]\n",
      "epoch:8 step:39430[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:8 step:39435[D loss: 1.000001] [G loss: 0.999987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:39440[D loss: 0.999967] [G loss: 1.000036]\n",
      "epoch:8 step:39445[D loss: 0.999971] [G loss: 1.000039]\n",
      "epoch:8 step:39450[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:8 step:39455[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:8 step:39460[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:8 step:39465[D loss: 1.000011] [G loss: 0.999957]\n",
      "epoch:8 step:39470[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:8 step:39475[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:8 step:39480[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:8 step:39485[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:8 step:39490[D loss: 0.999997] [G loss: 1.000042]\n",
      "epoch:8 step:39495[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:8 step:39500[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:8 step:39505[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:8 step:39510[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:8 step:39515[D loss: 1.000014] [G loss: 1.000028]\n",
      "epoch:8 step:39520[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:8 step:39525[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:8 step:39530[D loss: 1.000011] [G loss: 1.000060]\n",
      "epoch:8 step:39535[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:8 step:39540[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:8 step:39545[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:8 step:39550[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:8 step:39555[D loss: 0.999946] [G loss: 1.000073]\n",
      "epoch:8 step:39560[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:8 step:39565[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:8 step:39570[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:8 step:39575[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:8 step:39580[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:8 step:39585[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:8 step:39590[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:8 step:39595[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:8 step:39600[D loss: 1.000014] [G loss: 0.999993]\n",
      "epoch:8 step:39605[D loss: 0.999940] [G loss: 1.000118]\n",
      "epoch:8 step:39610[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:8 step:39615[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:8 step:39620[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:8 step:39625[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:8 step:39630[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:8 step:39635[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:8 step:39640[D loss: 1.000015] [G loss: 1.000006]\n",
      "epoch:8 step:39645[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:8 step:39650[D loss: 1.000038] [G loss: 0.999986]\n",
      "epoch:8 step:39655[D loss: 0.999954] [G loss: 1.000108]\n",
      "epoch:8 step:39660[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:8 step:39665[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:8 step:39670[D loss: 1.000010] [G loss: 1.000003]\n",
      "epoch:8 step:39675[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:8 step:39680[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:8 step:39685[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:8 step:39690[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:8 step:39695[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:8 step:39700[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:8 step:39705[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:8 step:39710[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:8 step:39715[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:8 step:39720[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:8 step:39725[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:8 step:39730[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:8 step:39735[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:8 step:39740[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:8 step:39745[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:8 step:39750[D loss: 1.000030] [G loss: 0.999973]\n",
      "epoch:8 step:39755[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:8 step:39760[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:8 step:39765[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:8 step:39770[D loss: 1.000008] [G loss: 1.000033]\n",
      "epoch:8 step:39775[D loss: 1.000029] [G loss: 1.000079]\n",
      "epoch:8 step:39780[D loss: 0.999945] [G loss: 1.000108]\n",
      "epoch:8 step:39785[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:8 step:39790[D loss: 1.000016] [G loss: 0.999959]\n",
      "epoch:8 step:39795[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:8 step:39800[D loss: 1.000018] [G loss: 1.000008]\n",
      "epoch:8 step:39805[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:8 step:39810[D loss: 0.999937] [G loss: 1.000095]\n",
      "epoch:8 step:39815[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:8 step:39820[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:8 step:39825[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:8 step:39830[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:8 step:39835[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:8 step:39840[D loss: 1.000001] [G loss: 1.000063]\n",
      "epoch:8 step:39845[D loss: 0.999969] [G loss: 1.000042]\n",
      "epoch:8 step:39850[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:8 step:39855[D loss: 1.000025] [G loss: 0.999920]\n",
      "epoch:8 step:39860[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:8 step:39865[D loss: 0.999980] [G loss: 1.000003]\n",
      "epoch:8 step:39870[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:8 step:39875[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:8 step:39880[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:8 step:39885[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:8 step:39890[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:8 step:39895[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:8 step:39900[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:8 step:39905[D loss: 1.000025] [G loss: 0.999983]\n",
      "epoch:8 step:39910[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:8 step:39915[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:8 step:39920[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:8 step:39925[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:8 step:39930[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:8 step:39935[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:8 step:39940[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:8 step:39945[D loss: 0.999981] [G loss: 1.000104]\n",
      "epoch:8 step:39950[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:8 step:39955[D loss: 0.999972] [G loss: 1.000032]\n",
      "epoch:8 step:39960[D loss: 1.000032] [G loss: 1.000057]\n",
      "epoch:8 step:39965[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:8 step:39970[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:8 step:39975[D loss: 1.000062] [G loss: 0.999879]\n",
      "epoch:8 step:39980[D loss: 1.000041] [G loss: 1.000000]\n",
      "epoch:8 step:39985[D loss: 0.999953] [G loss: 1.000054]\n",
      "epoch:8 step:39990[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:8 step:39995[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:8 step:40000[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:8 step:40005[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:8 step:40010[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:8 step:40015[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:8 step:40020[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:8 step:40025[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:8 step:40030[D loss: 0.999996] [G loss: 1.000096]\n",
      "epoch:8 step:40035[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:8 step:40040[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:8 step:40045[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:8 step:40050[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:8 step:40055[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:8 step:40060[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:8 step:40065[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:8 step:40070[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:8 step:40075[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:8 step:40080[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:8 step:40085[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:8 step:40090[D loss: 1.000022] [G loss: 1.000000]\n",
      "epoch:8 step:40095[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:8 step:40100[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:8 step:40105[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:8 step:40110[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:8 step:40115[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:8 step:40120[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:8 step:40125[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:8 step:40130[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:8 step:40135[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:8 step:40140[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:8 step:40145[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:8 step:40150[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:8 step:40155[D loss: 1.000004] [G loss: 1.000031]\n",
      "epoch:8 step:40160[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:8 step:40165[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:8 step:40170[D loss: 0.999972] [G loss: 1.000099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:40175[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:8 step:40180[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:8 step:40185[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:8 step:40190[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:8 step:40195[D loss: 1.000010] [G loss: 1.000002]\n",
      "epoch:8 step:40200[D loss: 1.000035] [G loss: 0.999989]\n",
      "epoch:8 step:40205[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:8 step:40210[D loss: 0.999963] [G loss: 1.000117]\n",
      "epoch:8 step:40215[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:8 step:40220[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:8 step:40225[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:8 step:40230[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:8 step:40235[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:8 step:40240[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:8 step:40245[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:8 step:40250[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:8 step:40255[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:8 step:40260[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:8 step:40265[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:8 step:40270[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:8 step:40275[D loss: 0.999964] [G loss: 1.000102]\n",
      "epoch:8 step:40280[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:8 step:40285[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:8 step:40290[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:8 step:40295[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:8 step:40300[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:8 step:40305[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:8 step:40310[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:8 step:40315[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:8 step:40320[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:8 step:40325[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:8 step:40330[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:8 step:40335[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:8 step:40340[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:8 step:40345[D loss: 1.000032] [G loss: 0.999993]\n",
      "epoch:8 step:40350[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:8 step:40355[D loss: 1.000045] [G loss: 1.000001]\n",
      "epoch:8 step:40360[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:8 step:40365[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:8 step:40370[D loss: 0.999987] [G loss: 1.000090]\n",
      "epoch:8 step:40375[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:8 step:40380[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:8 step:40385[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:8 step:40390[D loss: 1.000024] [G loss: 0.999980]\n",
      "epoch:8 step:40395[D loss: 0.999943] [G loss: 1.000115]\n",
      "epoch:8 step:40400[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:8 step:40405[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:8 step:40410[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:8 step:40415[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:8 step:40420[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:8 step:40425[D loss: 1.000021] [G loss: 1.000037]\n",
      "epoch:8 step:40430[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:8 step:40435[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:8 step:40440[D loss: 1.000029] [G loss: 1.000015]\n",
      "epoch:8 step:40445[D loss: 1.000046] [G loss: 1.000065]\n",
      "epoch:8 step:40450[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:8 step:40455[D loss: 0.999990] [G loss: 1.000140]\n",
      "epoch:8 step:40460[D loss: 0.999941] [G loss: 1.000110]\n",
      "epoch:8 step:40465[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:8 step:40470[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:40475[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:8 step:40480[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:8 step:40485[D loss: 1.000010] [G loss: 1.000011]\n",
      "epoch:8 step:40490[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:8 step:40495[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:8 step:40500[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:8 step:40505[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:8 step:40510[D loss: 0.999972] [G loss: 1.000110]\n",
      "epoch:8 step:40515[D loss: 1.000027] [G loss: 1.000004]\n",
      "epoch:8 step:40520[D loss: 0.999939] [G loss: 1.000150]\n",
      "epoch:8 step:40525[D loss: 1.000000] [G loss: 1.000158]\n",
      "epoch:8 step:40530[D loss: 0.999940] [G loss: 1.000103]\n",
      "epoch:8 step:40535[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:8 step:40540[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:8 step:40545[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:8 step:40550[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:40555[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:8 step:40560[D loss: 0.999986] [G loss: 0.999980]\n",
      "epoch:8 step:40565[D loss: 0.999997] [G loss: 1.000097]\n",
      "epoch:8 step:40570[D loss: 1.000008] [G loss: 0.999970]\n",
      "epoch:8 step:40575[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:8 step:40580[D loss: 0.999976] [G loss: 1.000137]\n",
      "epoch:8 step:40585[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:8 step:40590[D loss: 0.999999] [G loss: 1.000077]\n",
      "epoch:8 step:40595[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:8 step:40600[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:8 step:40605[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:8 step:40610[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:8 step:40615[D loss: 1.000021] [G loss: 1.000010]\n",
      "epoch:8 step:40620[D loss: 1.000002] [G loss: 0.999993]\n",
      "epoch:8 step:40625[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:8 step:40630[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:8 step:40635[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:8 step:40640[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:8 step:40645[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:8 step:40650[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:8 step:40655[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:8 step:40660[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:8 step:40665[D loss: 1.000001] [G loss: 1.000030]\n",
      "epoch:8 step:40670[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:8 step:40675[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:8 step:40680[D loss: 1.000037] [G loss: 0.999972]\n",
      "epoch:8 step:40685[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:8 step:40690[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:8 step:40695[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:8 step:40700[D loss: 0.999997] [G loss: 0.999993]\n",
      "epoch:8 step:40705[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:8 step:40710[D loss: 1.000038] [G loss: 0.999996]\n",
      "epoch:8 step:40715[D loss: 0.999936] [G loss: 1.000071]\n",
      "epoch:8 step:40720[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:8 step:40725[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:8 step:40730[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:8 step:40735[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:8 step:40740[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:8 step:40745[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:8 step:40750[D loss: 1.000006] [G loss: 0.999981]\n",
      "epoch:8 step:40755[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:8 step:40760[D loss: 1.000033] [G loss: 0.999938]\n",
      "epoch:8 step:40765[D loss: 0.999999] [G loss: 1.000046]\n",
      "epoch:8 step:40770[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:8 step:40775[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:8 step:40780[D loss: 1.000001] [G loss: 1.000032]\n",
      "epoch:8 step:40785[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:8 step:40790[D loss: 1.000016] [G loss: 1.000033]\n",
      "epoch:8 step:40795[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:8 step:40800[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:8 step:40805[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:8 step:40810[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:8 step:40815[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:8 step:40820[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:8 step:40825[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:8 step:40830[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:8 step:40835[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:8 step:40840[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:8 step:40845[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:8 step:40850[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:8 step:40855[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:8 step:40860[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:8 step:40865[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:8 step:40870[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:8 step:40875[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:8 step:40880[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:8 step:40885[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:8 step:40890[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:8 step:40895[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:8 step:40900[D loss: 0.999997] [G loss: 1.000010]\n",
      "epoch:8 step:40905[D loss: 0.999978] [G loss: 1.000089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:40910[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:8 step:40915[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:8 step:40920[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:8 step:40925[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:8 step:40930[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:8 step:40935[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:8 step:40940[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:8 step:40945[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:8 step:40950[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:8 step:40955[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:8 step:40960[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:8 step:40965[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:8 step:40970[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:8 step:40975[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:8 step:40980[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:8 step:40985[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:8 step:40990[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:8 step:40995[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:8 step:41000[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:8 step:41005[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:8 step:41010[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:8 step:41015[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:8 step:41020[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:8 step:41025[D loss: 1.000030] [G loss: 1.000021]\n",
      "epoch:8 step:41030[D loss: 1.000026] [G loss: 1.000016]\n",
      "epoch:8 step:41035[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:8 step:41040[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:8 step:41045[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:8 step:41050[D loss: 1.000008] [G loss: 1.000040]\n",
      "epoch:8 step:41055[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:8 step:41060[D loss: 1.000009] [G loss: 1.000021]\n",
      "epoch:8 step:41065[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:8 step:41070[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:8 step:41075[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:8 step:41080[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:8 step:41085[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:8 step:41090[D loss: 0.999995] [G loss: 1.000108]\n",
      "epoch:8 step:41095[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:8 step:41100[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:8 step:41105[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:8 step:41110[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:8 step:41115[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:8 step:41120[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:8 step:41125[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:8 step:41130[D loss: 0.999972] [G loss: 1.000116]\n",
      "epoch:8 step:41135[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:8 step:41140[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:8 step:41145[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:8 step:41150[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:8 step:41155[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:8 step:41160[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:8 step:41165[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:8 step:41170[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:8 step:41175[D loss: 0.999995] [G loss: 1.000088]\n",
      "epoch:8 step:41180[D loss: 0.999999] [G loss: 1.000016]\n",
      "epoch:8 step:41185[D loss: 0.999963] [G loss: 1.000091]\n",
      "epoch:8 step:41190[D loss: 1.000045] [G loss: 0.999984]\n",
      "epoch:8 step:41195[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:8 step:41200[D loss: 0.999986] [G loss: 1.000017]\n",
      "epoch:8 step:41205[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:8 step:41210[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:8 step:41215[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:8 step:41220[D loss: 1.000027] [G loss: 0.999986]\n",
      "epoch:8 step:41225[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:8 step:41230[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:8 step:41235[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:8 step:41240[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:8 step:41245[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:8 step:41250[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:8 step:41255[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:8 step:41260[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:8 step:41265[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:8 step:41270[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:8 step:41275[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:8 step:41280[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:8 step:41285[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:8 step:41290[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:8 step:41295[D loss: 1.000004] [G loss: 1.000027]\n",
      "epoch:8 step:41300[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:8 step:41305[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:8 step:41310[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:41315[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:8 step:41320[D loss: 0.999991] [G loss: 0.999993]\n",
      "epoch:8 step:41325[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:8 step:41330[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:8 step:41335[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:8 step:41340[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:8 step:41345[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:8 step:41350[D loss: 0.999935] [G loss: 1.000167]\n",
      "epoch:8 step:41355[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:8 step:41360[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:8 step:41365[D loss: 1.000022] [G loss: 0.999978]\n",
      "epoch:8 step:41370[D loss: 0.999986] [G loss: 1.000078]\n",
      "epoch:8 step:41375[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:8 step:41380[D loss: 1.000013] [G loss: 0.999982]\n",
      "epoch:8 step:41385[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:8 step:41390[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:8 step:41395[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:8 step:41400[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:8 step:41405[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:8 step:41410[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:8 step:41415[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:8 step:41420[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:8 step:41425[D loss: 1.000010] [G loss: 1.000021]\n",
      "epoch:8 step:41430[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:8 step:41435[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:8 step:41440[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:8 step:41445[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:8 step:41450[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:8 step:41455[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:8 step:41460[D loss: 0.999989] [G loss: 1.000030]\n",
      "epoch:8 step:41465[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:8 step:41470[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:8 step:41475[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:41480[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:8 step:41485[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:8 step:41490[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:8 step:41495[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:8 step:41500[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:8 step:41505[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:8 step:41510[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:8 step:41515[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:8 step:41520[D loss: 0.999957] [G loss: 1.000133]\n",
      "epoch:8 step:41525[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:8 step:41530[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:8 step:41535[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:8 step:41540[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:8 step:41545[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:8 step:41550[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:8 step:41555[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:8 step:41560[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:8 step:41565[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:8 step:41570[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:8 step:41575[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:8 step:41580[D loss: 0.999983] [G loss: 1.000021]\n",
      "epoch:8 step:41585[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:8 step:41590[D loss: 1.000004] [G loss: 1.000014]\n",
      "epoch:8 step:41595[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:8 step:41600[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:8 step:41605[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:8 step:41610[D loss: 1.000007] [G loss: 1.000050]\n",
      "epoch:8 step:41615[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:8 step:41620[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:8 step:41625[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:8 step:41630[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:8 step:41635[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:8 step:41640[D loss: 0.999994] [G loss: 1.000045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:41645[D loss: 0.999944] [G loss: 1.000065]\n",
      "epoch:8 step:41650[D loss: 0.999978] [G loss: 1.000141]\n",
      "epoch:8 step:41655[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:8 step:41660[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:8 step:41665[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:8 step:41670[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:8 step:41675[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:8 step:41680[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:8 step:41685[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:8 step:41690[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:8 step:41695[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:8 step:41700[D loss: 1.000011] [G loss: 1.000023]\n",
      "epoch:8 step:41705[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:8 step:41710[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:8 step:41715[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:8 step:41720[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:8 step:41725[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:8 step:41730[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:8 step:41735[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:8 step:41740[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:8 step:41745[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:8 step:41750[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:8 step:41755[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:8 step:41760[D loss: 1.000010] [G loss: 1.000010]\n",
      "epoch:8 step:41765[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:8 step:41770[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:8 step:41775[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:8 step:41780[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:8 step:41785[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:8 step:41790[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:8 step:41795[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:8 step:41800[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:41805[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:8 step:41810[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:8 step:41815[D loss: 1.000003] [G loss: 0.999987]\n",
      "epoch:8 step:41820[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:8 step:41825[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:8 step:41830[D loss: 1.000040] [G loss: 0.999998]\n",
      "epoch:8 step:41835[D loss: 0.999967] [G loss: 1.000029]\n",
      "epoch:8 step:41840[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:8 step:41845[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:8 step:41850[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:8 step:41855[D loss: 1.000014] [G loss: 1.000015]\n",
      "epoch:8 step:41860[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:8 step:41865[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:8 step:41870[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:8 step:41875[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:8 step:41880[D loss: 0.999992] [G loss: 1.000016]\n",
      "epoch:8 step:41885[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:8 step:41890[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:8 step:41895[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:8 step:41900[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:8 step:41905[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:8 step:41910[D loss: 0.999998] [G loss: 1.000030]\n",
      "epoch:8 step:41915[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:8 step:41920[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:8 step:41925[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:8 step:41930[D loss: 0.999995] [G loss: 1.000011]\n",
      "epoch:8 step:41935[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:8 step:41940[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:8 step:41945[D loss: 0.999986] [G loss: 1.000018]\n",
      "epoch:8 step:41950[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:8 step:41955[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:8 step:41960[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:8 step:41965[D loss: 1.000007] [G loss: 0.999984]\n",
      "epoch:8 step:41970[D loss: 0.999961] [G loss: 1.000053]\n",
      "epoch:8 step:41975[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:8 step:41980[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:8 step:41985[D loss: 0.999969] [G loss: 1.000111]\n",
      "epoch:8 step:41990[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:8 step:41995[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:8 step:42000[D loss: 0.999995] [G loss: 1.000097]\n",
      "epoch:8 step:42005[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:8 step:42010[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:8 step:42015[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:8 step:42020[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:8 step:42025[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:8 step:42030[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:8 step:42035[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:8 step:42040[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:8 step:42045[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:8 step:42050[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:8 step:42055[D loss: 1.000011] [G loss: 1.000031]\n",
      "epoch:8 step:42060[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:8 step:42065[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:8 step:42070[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:8 step:42075[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:8 step:42080[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:8 step:42085[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:8 step:42090[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:8 step:42095[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:8 step:42100[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:8 step:42105[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:8 step:42110[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:8 step:42115[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:8 step:42120[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:8 step:42125[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:8 step:42130[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:8 step:42135[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:8 step:42140[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:8 step:42145[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:8 step:42150[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:8 step:42155[D loss: 1.000001] [G loss: 1.000009]\n",
      "epoch:8 step:42160[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:8 step:42165[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:9 step:42170[D loss: 1.000015] [G loss: 1.000004]\n",
      "epoch:9 step:42175[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:9 step:42180[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:9 step:42185[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:9 step:42190[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:9 step:42195[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:9 step:42200[D loss: 1.000003] [G loss: 1.000000]\n",
      "epoch:9 step:42205[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:9 step:42210[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:9 step:42215[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:9 step:42220[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:9 step:42225[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:9 step:42230[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:9 step:42235[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:9 step:42240[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:9 step:42245[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:9 step:42250[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:9 step:42255[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:9 step:42260[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:9 step:42265[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:9 step:42270[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:9 step:42275[D loss: 1.000017] [G loss: 1.000038]\n",
      "epoch:9 step:42280[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:9 step:42285[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:9 step:42290[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:9 step:42295[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:9 step:42300[D loss: 0.999997] [G loss: 1.000054]\n",
      "epoch:9 step:42305[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:9 step:42310[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:9 step:42315[D loss: 1.000018] [G loss: 1.000016]\n",
      "epoch:9 step:42320[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:9 step:42325[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:9 step:42330[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:9 step:42335[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:9 step:42340[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:9 step:42345[D loss: 1.000014] [G loss: 1.000056]\n",
      "epoch:9 step:42350[D loss: 1.000012] [G loss: 1.000019]\n",
      "epoch:9 step:42355[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:9 step:42360[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:9 step:42365[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:9 step:42370[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:9 step:42375[D loss: 0.999958] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:42380[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:9 step:42385[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:9 step:42390[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:9 step:42395[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:9 step:42400[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:9 step:42405[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:9 step:42410[D loss: 0.999979] [G loss: 1.000022]\n",
      "epoch:9 step:42415[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:9 step:42420[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:9 step:42425[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:9 step:42430[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:9 step:42435[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:9 step:42440[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:9 step:42445[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:9 step:42450[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:9 step:42455[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:9 step:42460[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:9 step:42465[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:9 step:42470[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:9 step:42475[D loss: 1.000022] [G loss: 1.000015]\n",
      "epoch:9 step:42480[D loss: 1.000027] [G loss: 1.000007]\n",
      "epoch:9 step:42485[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:9 step:42490[D loss: 1.000006] [G loss: 1.000059]\n",
      "epoch:9 step:42495[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:9 step:42500[D loss: 0.999962] [G loss: 1.000045]\n",
      "epoch:9 step:42505[D loss: 1.000003] [G loss: 0.999999]\n",
      "epoch:9 step:42510[D loss: 1.000002] [G loss: 1.000088]\n",
      "epoch:9 step:42515[D loss: 1.000005] [G loss: 1.000096]\n",
      "epoch:9 step:42520[D loss: 1.000015] [G loss: 1.000059]\n",
      "epoch:9 step:42525[D loss: 0.999989] [G loss: 1.000076]\n",
      "epoch:9 step:42530[D loss: 0.999955] [G loss: 1.000144]\n",
      "epoch:9 step:42535[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:9 step:42540[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:9 step:42545[D loss: 0.999951] [G loss: 1.000083]\n",
      "epoch:9 step:42550[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:9 step:42555[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:9 step:42560[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:9 step:42565[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:9 step:42570[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:9 step:42575[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:9 step:42580[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:9 step:42585[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:9 step:42590[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:9 step:42595[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:9 step:42600[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:9 step:42605[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:9 step:42610[D loss: 1.000032] [G loss: 1.000027]\n",
      "epoch:9 step:42615[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:9 step:42620[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:9 step:42625[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:9 step:42630[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:9 step:42635[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:9 step:42640[D loss: 1.000006] [G loss: 1.000003]\n",
      "epoch:9 step:42645[D loss: 0.999971] [G loss: 1.000090]\n",
      "epoch:9 step:42650[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:9 step:42655[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:9 step:42660[D loss: 1.000003] [G loss: 1.000047]\n",
      "epoch:9 step:42665[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:9 step:42670[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:9 step:42675[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:9 step:42680[D loss: 1.000033] [G loss: 0.999985]\n",
      "epoch:9 step:42685[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:9 step:42690[D loss: 0.999950] [G loss: 1.000134]\n",
      "epoch:9 step:42695[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:9 step:42700[D loss: 0.999982] [G loss: 1.000102]\n",
      "epoch:9 step:42705[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:9 step:42710[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:9 step:42715[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:9 step:42720[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:9 step:42725[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:9 step:42730[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:9 step:42735[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:9 step:42740[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:9 step:42745[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:9 step:42750[D loss: 0.999977] [G loss: 1.000111]\n",
      "epoch:9 step:42755[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:9 step:42760[D loss: 1.000011] [G loss: 1.000066]\n",
      "epoch:9 step:42765[D loss: 0.999973] [G loss: 1.000103]\n",
      "epoch:9 step:42770[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:9 step:42775[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:9 step:42780[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:9 step:42785[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:9 step:42790[D loss: 1.000007] [G loss: 1.000038]\n",
      "epoch:9 step:42795[D loss: 0.999965] [G loss: 1.000041]\n",
      "epoch:9 step:42800[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:9 step:42805[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:9 step:42810[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:9 step:42815[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:9 step:42820[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:9 step:42825[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:9 step:42830[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:9 step:42835[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:9 step:42840[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:9 step:42845[D loss: 1.000001] [G loss: 1.000017]\n",
      "epoch:9 step:42850[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:9 step:42855[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:9 step:42860[D loss: 1.000001] [G loss: 1.000042]\n",
      "epoch:9 step:42865[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:9 step:42870[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:9 step:42875[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:9 step:42880[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:9 step:42885[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:9 step:42890[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:9 step:42895[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:9 step:42900[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:9 step:42905[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:9 step:42910[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:9 step:42915[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:9 step:42920[D loss: 0.999947] [G loss: 1.000064]\n",
      "epoch:9 step:42925[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:9 step:42930[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:9 step:42935[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:9 step:42940[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:9 step:42945[D loss: 0.999969] [G loss: 1.000107]\n",
      "epoch:9 step:42950[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:9 step:42955[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:9 step:42960[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:9 step:42965[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:9 step:42970[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:9 step:42975[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:9 step:42980[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:9 step:42985[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:9 step:42990[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:9 step:42995[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:9 step:43000[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:9 step:43005[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:9 step:43010[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:9 step:43015[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:9 step:43020[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:9 step:43025[D loss: 1.000036] [G loss: 0.999984]\n",
      "epoch:9 step:43030[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:9 step:43035[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:9 step:43040[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:9 step:43045[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:9 step:43050[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:9 step:43055[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:9 step:43060[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:9 step:43065[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:9 step:43070[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:9 step:43075[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:9 step:43080[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:9 step:43085[D loss: 1.000003] [G loss: 1.000030]\n",
      "epoch:9 step:43090[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:9 step:43095[D loss: 0.999991] [G loss: 1.000011]\n",
      "epoch:9 step:43100[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:9 step:43105[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:9 step:43110[D loss: 0.999968] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:43115[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:9 step:43120[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:9 step:43125[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:9 step:43130[D loss: 0.999978] [G loss: 1.000114]\n",
      "epoch:9 step:43135[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:9 step:43140[D loss: 1.000000] [G loss: 1.000031]\n",
      "epoch:9 step:43145[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:9 step:43150[D loss: 1.000017] [G loss: 1.000025]\n",
      "epoch:9 step:43155[D loss: 0.999975] [G loss: 1.000103]\n",
      "epoch:9 step:43160[D loss: 0.999946] [G loss: 1.000076]\n",
      "epoch:9 step:43165[D loss: 1.000011] [G loss: 1.000064]\n",
      "epoch:9 step:43170[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:9 step:43175[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:9 step:43180[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:9 step:43185[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:9 step:43190[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:9 step:43195[D loss: 1.000017] [G loss: 0.999997]\n",
      "epoch:9 step:43200[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:9 step:43205[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:9 step:43210[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:9 step:43215[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:9 step:43220[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:9 step:43225[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:9 step:43230[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:9 step:43235[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:9 step:43240[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:9 step:43245[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:9 step:43250[D loss: 0.999981] [G loss: 1.000162]\n",
      "epoch:9 step:43255[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:9 step:43260[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:9 step:43265[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:9 step:43270[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:9 step:43275[D loss: 1.000013] [G loss: 1.000010]\n",
      "epoch:9 step:43280[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:9 step:43285[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:9 step:43290[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:9 step:43295[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:9 step:43300[D loss: 0.999955] [G loss: 1.000128]\n",
      "epoch:9 step:43305[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:9 step:43310[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:9 step:43315[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:9 step:43320[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:9 step:43325[D loss: 1.000004] [G loss: 0.999996]\n",
      "epoch:9 step:43330[D loss: 0.999960] [G loss: 1.000047]\n",
      "epoch:9 step:43335[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:9 step:43340[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:9 step:43345[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:9 step:43350[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:9 step:43355[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:9 step:43360[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:9 step:43365[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:9 step:43370[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:9 step:43375[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:9 step:43380[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:9 step:43385[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:9 step:43390[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:9 step:43395[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:9 step:43400[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:9 step:43405[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:9 step:43410[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:9 step:43415[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:9 step:43420[D loss: 1.000007] [G loss: 1.000025]\n",
      "epoch:9 step:43425[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:9 step:43430[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:9 step:43435[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:9 step:43440[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:9 step:43445[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:9 step:43450[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:9 step:43455[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:9 step:43460[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:9 step:43465[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:9 step:43470[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:9 step:43475[D loss: 1.000010] [G loss: 1.000057]\n",
      "epoch:9 step:43480[D loss: 1.000022] [G loss: 1.000046]\n",
      "epoch:9 step:43485[D loss: 0.999937] [G loss: 1.000096]\n",
      "epoch:9 step:43490[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:9 step:43495[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:9 step:43500[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:9 step:43505[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:9 step:43510[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:9 step:43515[D loss: 0.999944] [G loss: 1.000103]\n",
      "epoch:9 step:43520[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:9 step:43525[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:9 step:43530[D loss: 0.999999] [G loss: 0.999974]\n",
      "epoch:9 step:43535[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:9 step:43540[D loss: 1.000008] [G loss: 1.000009]\n",
      "epoch:9 step:43545[D loss: 0.999986] [G loss: 1.000020]\n",
      "epoch:9 step:43550[D loss: 0.999973] [G loss: 1.000036]\n",
      "epoch:9 step:43555[D loss: 1.000012] [G loss: 1.000045]\n",
      "epoch:9 step:43560[D loss: 0.999950] [G loss: 1.000114]\n",
      "epoch:9 step:43565[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:9 step:43570[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:9 step:43575[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:9 step:43580[D loss: 0.999948] [G loss: 1.000087]\n",
      "epoch:9 step:43585[D loss: 1.000024] [G loss: 1.000023]\n",
      "epoch:9 step:43590[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:9 step:43595[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:9 step:43600[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:9 step:43605[D loss: 1.000002] [G loss: 1.000041]\n",
      "epoch:9 step:43610[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:9 step:43615[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:9 step:43620[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:9 step:43625[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:9 step:43630[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:9 step:43635[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:9 step:43640[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:9 step:43645[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:9 step:43650[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:9 step:43655[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:9 step:43660[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:9 step:43665[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:9 step:43670[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:9 step:43675[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:9 step:43680[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:9 step:43685[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:9 step:43690[D loss: 1.000016] [G loss: 0.999997]\n",
      "epoch:9 step:43695[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:9 step:43700[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:9 step:43705[D loss: 0.999987] [G loss: 1.000009]\n",
      "epoch:9 step:43710[D loss: 1.000022] [G loss: 1.000016]\n",
      "epoch:9 step:43715[D loss: 1.000023] [G loss: 0.999959]\n",
      "epoch:9 step:43720[D loss: 1.000022] [G loss: 1.000020]\n",
      "epoch:9 step:43725[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:9 step:43730[D loss: 0.999980] [G loss: 1.000006]\n",
      "epoch:9 step:43735[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:9 step:43740[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:9 step:43745[D loss: 1.000005] [G loss: 1.000055]\n",
      "epoch:9 step:43750[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:9 step:43755[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:9 step:43760[D loss: 0.999969] [G loss: 1.000023]\n",
      "epoch:9 step:43765[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:9 step:43770[D loss: 1.000102] [G loss: 0.999897]\n",
      "epoch:9 step:43775[D loss: 1.000009] [G loss: 1.000029]\n",
      "epoch:9 step:43780[D loss: 1.000023] [G loss: 0.999969]\n",
      "epoch:9 step:43785[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:9 step:43790[D loss: 0.999942] [G loss: 1.000068]\n",
      "epoch:9 step:43795[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:9 step:43800[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:9 step:43805[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:9 step:43810[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:9 step:43815[D loss: 1.000008] [G loss: 1.000005]\n",
      "epoch:9 step:43820[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:9 step:43825[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:9 step:43830[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:9 step:43835[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:9 step:43840[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:9 step:43845[D loss: 0.999989] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:43850[D loss: 0.999988] [G loss: 1.000025]\n",
      "epoch:9 step:43855[D loss: 0.999943] [G loss: 1.000089]\n",
      "epoch:9 step:43860[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:9 step:43865[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:9 step:43870[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:9 step:43875[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:9 step:43880[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:9 step:43885[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:9 step:43890[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:9 step:43895[D loss: 1.000052] [G loss: 1.000001]\n",
      "epoch:9 step:43900[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:9 step:43905[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:9 step:43910[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:9 step:43915[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:9 step:43920[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:9 step:43925[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:9 step:43930[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:9 step:43935[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:9 step:43940[D loss: 1.000010] [G loss: 1.000016]\n",
      "epoch:9 step:43945[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:9 step:43950[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:9 step:43955[D loss: 1.000019] [G loss: 1.000038]\n",
      "epoch:9 step:43960[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:9 step:43965[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:9 step:43970[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:9 step:43975[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:9 step:43980[D loss: 1.000021] [G loss: 1.000047]\n",
      "epoch:9 step:43985[D loss: 0.999943] [G loss: 1.000219]\n",
      "epoch:9 step:43990[D loss: 1.000048] [G loss: 0.999920]\n",
      "epoch:9 step:43995[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:9 step:44000[D loss: 1.000009] [G loss: 1.000036]\n",
      "epoch:9 step:44005[D loss: 1.000002] [G loss: 1.000037]\n",
      "epoch:9 step:44010[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:9 step:44015[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:9 step:44020[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:9 step:44025[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:9 step:44030[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:9 step:44035[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:9 step:44040[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:9 step:44045[D loss: 0.999927] [G loss: 1.000136]\n",
      "epoch:9 step:44050[D loss: 1.000021] [G loss: 1.000024]\n",
      "epoch:9 step:44055[D loss: 0.999975] [G loss: 1.000151]\n",
      "epoch:9 step:44060[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:9 step:44065[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:9 step:44070[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:9 step:44075[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:9 step:44080[D loss: 0.999954] [G loss: 1.000121]\n",
      "epoch:9 step:44085[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:9 step:44090[D loss: 0.999995] [G loss: 1.000095]\n",
      "epoch:9 step:44095[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:9 step:44100[D loss: 0.999992] [G loss: 1.000105]\n",
      "epoch:9 step:44105[D loss: 0.999937] [G loss: 1.000152]\n",
      "epoch:9 step:44110[D loss: 1.000024] [G loss: 0.999985]\n",
      "epoch:9 step:44115[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:9 step:44120[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:9 step:44125[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:9 step:44130[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:9 step:44135[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:9 step:44140[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:9 step:44145[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:9 step:44150[D loss: 0.999986] [G loss: 0.999991]\n",
      "epoch:9 step:44155[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:9 step:44160[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:9 step:44165[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:9 step:44170[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:9 step:44175[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:9 step:44180[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:9 step:44185[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:9 step:44190[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:9 step:44195[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:9 step:44200[D loss: 1.000010] [G loss: 1.000058]\n",
      "epoch:9 step:44205[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:9 step:44210[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:9 step:44215[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:9 step:44220[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:9 step:44225[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:9 step:44230[D loss: 0.999946] [G loss: 1.000108]\n",
      "epoch:9 step:44235[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:9 step:44240[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:9 step:44245[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:9 step:44250[D loss: 0.999986] [G loss: 1.000029]\n",
      "epoch:9 step:44255[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:9 step:44260[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:9 step:44265[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:9 step:44270[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:9 step:44275[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:9 step:44280[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:9 step:44285[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:9 step:44290[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:9 step:44295[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:9 step:44300[D loss: 0.999995] [G loss: 1.000003]\n",
      "epoch:9 step:44305[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:9 step:44310[D loss: 1.000002] [G loss: 1.000006]\n",
      "epoch:9 step:44315[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:9 step:44320[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:9 step:44325[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:9 step:44330[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:9 step:44335[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:9 step:44340[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:9 step:44345[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:9 step:44350[D loss: 1.000031] [G loss: 0.999985]\n",
      "epoch:9 step:44355[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:9 step:44360[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:9 step:44365[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:9 step:44370[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:9 step:44375[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:9 step:44380[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:9 step:44385[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:9 step:44390[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:9 step:44395[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:9 step:44400[D loss: 1.000006] [G loss: 1.000050]\n",
      "epoch:9 step:44405[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:9 step:44410[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:9 step:44415[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:9 step:44420[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:9 step:44425[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:9 step:44430[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:9 step:44435[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:9 step:44440[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:9 step:44445[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:9 step:44450[D loss: 1.000005] [G loss: 0.999921]\n",
      "epoch:9 step:44455[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:9 step:44460[D loss: 1.000048] [G loss: 1.000054]\n",
      "epoch:9 step:44465[D loss: 0.999925] [G loss: 1.000130]\n",
      "epoch:9 step:44470[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:9 step:44475[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:9 step:44480[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:9 step:44485[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:9 step:44490[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:9 step:44495[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:9 step:44500[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:9 step:44505[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:9 step:44510[D loss: 0.999949] [G loss: 1.000153]\n",
      "epoch:9 step:44515[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:9 step:44520[D loss: 0.999970] [G loss: 1.000103]\n",
      "epoch:9 step:44525[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:9 step:44530[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:9 step:44535[D loss: 1.000015] [G loss: 0.999994]\n",
      "epoch:9 step:44540[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:9 step:44545[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:9 step:44550[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:9 step:44555[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:9 step:44560[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:9 step:44565[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:9 step:44570[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:9 step:44575[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:9 step:44580[D loss: 0.999977] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:44585[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:9 step:44590[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:9 step:44595[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:9 step:44600[D loss: 0.999977] [G loss: 1.000020]\n",
      "epoch:9 step:44605[D loss: 0.999953] [G loss: 1.000067]\n",
      "epoch:9 step:44610[D loss: 0.999969] [G loss: 1.000100]\n",
      "epoch:9 step:44615[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:9 step:44620[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:9 step:44625[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:9 step:44630[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:9 step:44635[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:9 step:44640[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:9 step:44645[D loss: 0.999985] [G loss: 1.000123]\n",
      "epoch:9 step:44650[D loss: 1.000027] [G loss: 0.999985]\n",
      "epoch:9 step:44655[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:9 step:44660[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:9 step:44665[D loss: 1.000029] [G loss: 1.000023]\n",
      "epoch:9 step:44670[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:9 step:44675[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:9 step:44680[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:9 step:44685[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:9 step:44690[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:9 step:44695[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:9 step:44700[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:9 step:44705[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:9 step:44710[D loss: 0.999958] [G loss: 1.000059]\n",
      "epoch:9 step:44715[D loss: 0.999985] [G loss: 1.000125]\n",
      "epoch:9 step:44720[D loss: 0.999919] [G loss: 1.000145]\n",
      "epoch:9 step:44725[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:9 step:44730[D loss: 0.999994] [G loss: 1.000026]\n",
      "epoch:9 step:44735[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:9 step:44740[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:9 step:44745[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:9 step:44750[D loss: 1.000041] [G loss: 0.999992]\n",
      "epoch:9 step:44755[D loss: 0.999979] [G loss: 1.000001]\n",
      "epoch:9 step:44760[D loss: 1.000011] [G loss: 0.999999]\n",
      "epoch:9 step:44765[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:9 step:44770[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:9 step:44775[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:9 step:44780[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:9 step:44785[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:9 step:44790[D loss: 1.000001] [G loss: 1.000020]\n",
      "epoch:9 step:44795[D loss: 1.000025] [G loss: 0.999986]\n",
      "epoch:9 step:44800[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:9 step:44805[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:9 step:44810[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:9 step:44815[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:9 step:44820[D loss: 0.999947] [G loss: 1.000102]\n",
      "epoch:9 step:44825[D loss: 0.999961] [G loss: 1.000070]\n",
      "epoch:9 step:44830[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:9 step:44835[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:9 step:44840[D loss: 0.999969] [G loss: 1.000086]\n",
      "epoch:9 step:44845[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:9 step:44850[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:9 step:44855[D loss: 1.000012] [G loss: 1.000013]\n",
      "epoch:9 step:44860[D loss: 1.000030] [G loss: 0.999974]\n",
      "epoch:9 step:44865[D loss: 0.999974] [G loss: 1.000012]\n",
      "epoch:9 step:44870[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:9 step:44875[D loss: 0.999993] [G loss: 1.000009]\n",
      "epoch:9 step:44880[D loss: 1.000005] [G loss: 1.000030]\n",
      "epoch:9 step:44885[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:9 step:44890[D loss: 1.000032] [G loss: 1.000015]\n",
      "epoch:9 step:44895[D loss: 1.000016] [G loss: 1.000029]\n",
      "epoch:9 step:44900[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:9 step:44905[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:9 step:44910[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:9 step:44915[D loss: 1.000006] [G loss: 1.000048]\n",
      "epoch:9 step:44920[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:9 step:44925[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:9 step:44930[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:9 step:44935[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:9 step:44940[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:9 step:44945[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:9 step:44950[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:9 step:44955[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:9 step:44960[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:9 step:44965[D loss: 0.999978] [G loss: 1.000116]\n",
      "epoch:9 step:44970[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:9 step:44975[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:9 step:44980[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:9 step:44985[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:9 step:44990[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:9 step:44995[D loss: 0.999990] [G loss: 1.000080]\n",
      "epoch:9 step:45000[D loss: 0.999961] [G loss: 1.000066]\n",
      "epoch:9 step:45005[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:9 step:45010[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:9 step:45015[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:9 step:45020[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:9 step:45025[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:9 step:45030[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:9 step:45035[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:9 step:45040[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:9 step:45045[D loss: 1.000005] [G loss: 1.000029]\n",
      "epoch:9 step:45050[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:9 step:45055[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:9 step:45060[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:9 step:45065[D loss: 0.999988] [G loss: 1.000093]\n",
      "epoch:9 step:45070[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:9 step:45075[D loss: 1.000072] [G loss: 0.999892]\n",
      "epoch:9 step:45080[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:9 step:45085[D loss: 0.999925] [G loss: 1.000092]\n",
      "epoch:9 step:45090[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:9 step:45095[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:9 step:45100[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:9 step:45105[D loss: 0.999993] [G loss: 1.000085]\n",
      "epoch:9 step:45110[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:9 step:45115[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:9 step:45120[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:9 step:45125[D loss: 1.000020] [G loss: 1.000055]\n",
      "epoch:9 step:45130[D loss: 0.999987] [G loss: 1.000129]\n",
      "epoch:9 step:45135[D loss: 0.999994] [G loss: 1.000090]\n",
      "epoch:9 step:45140[D loss: 1.000047] [G loss: 1.000041]\n",
      "epoch:9 step:45145[D loss: 0.999960] [G loss: 1.000109]\n",
      "epoch:9 step:45150[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:9 step:45155[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:9 step:45160[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:9 step:45165[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:9 step:45170[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:9 step:45175[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:9 step:45180[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:9 step:45185[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:9 step:45190[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:9 step:45195[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:9 step:45200[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:9 step:45205[D loss: 1.000032] [G loss: 0.999963]\n",
      "epoch:9 step:45210[D loss: 0.999996] [G loss: 1.000081]\n",
      "epoch:9 step:45215[D loss: 0.999943] [G loss: 1.000095]\n",
      "epoch:9 step:45220[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:9 step:45225[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:9 step:45230[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:9 step:45235[D loss: 0.999963] [G loss: 1.000011]\n",
      "epoch:9 step:45240[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:9 step:45245[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:9 step:45250[D loss: 1.000028] [G loss: 1.000011]\n",
      "epoch:9 step:45255[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:9 step:45260[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:9 step:45265[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:9 step:45270[D loss: 0.999965] [G loss: 1.000035]\n",
      "epoch:9 step:45275[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:9 step:45280[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:9 step:45285[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:9 step:45290[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:9 step:45295[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:9 step:45300[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:9 step:45305[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:9 step:45310[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:9 step:45315[D loss: 0.999984] [G loss: 1.000094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:45320[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:9 step:45325[D loss: 0.999979] [G loss: 1.000107]\n",
      "epoch:9 step:45330[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:9 step:45335[D loss: 1.000006] [G loss: 1.000008]\n",
      "epoch:9 step:45340[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:9 step:45345[D loss: 1.000005] [G loss: 0.999995]\n",
      "epoch:9 step:45350[D loss: 1.000031] [G loss: 1.000006]\n",
      "epoch:9 step:45355[D loss: 0.999932] [G loss: 1.000086]\n",
      "epoch:9 step:45360[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:9 step:45365[D loss: 0.999945] [G loss: 1.000136]\n",
      "epoch:9 step:45370[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:9 step:45375[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:9 step:45380[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:9 step:45385[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:9 step:45390[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:9 step:45395[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:9 step:45400[D loss: 0.999978] [G loss: 0.999995]\n",
      "epoch:9 step:45405[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:9 step:45410[D loss: 0.999957] [G loss: 1.000113]\n",
      "epoch:9 step:45415[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:9 step:45420[D loss: 0.999994] [G loss: 1.000067]\n",
      "epoch:9 step:45425[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:9 step:45430[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:9 step:45435[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:9 step:45440[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:9 step:45445[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:9 step:45450[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:9 step:45455[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:9 step:45460[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:9 step:45465[D loss: 0.999993] [G loss: 1.000086]\n",
      "epoch:9 step:45470[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:9 step:45475[D loss: 0.999988] [G loss: 1.000089]\n",
      "epoch:9 step:45480[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:9 step:45485[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:9 step:45490[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:9 step:45495[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:9 step:45500[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:9 step:45505[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:9 step:45510[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:9 step:45515[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:9 step:45520[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:9 step:45525[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:9 step:45530[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:9 step:45535[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:9 step:45540[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:9 step:45545[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:9 step:45550[D loss: 0.999999] [G loss: 0.999995]\n",
      "epoch:9 step:45555[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:9 step:45560[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:9 step:45565[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:9 step:45570[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:9 step:45575[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:9 step:45580[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:9 step:45585[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:9 step:45590[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:9 step:45595[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:9 step:45600[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:9 step:45605[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:9 step:45610[D loss: 0.999978] [G loss: 1.000109]\n",
      "epoch:9 step:45615[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:9 step:45620[D loss: 0.999997] [G loss: 0.999964]\n",
      "epoch:9 step:45625[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:9 step:45630[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:9 step:45635[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:9 step:45640[D loss: 0.999986] [G loss: 1.000081]\n",
      "epoch:9 step:45645[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:9 step:45650[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:9 step:45655[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:9 step:45660[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:9 step:45665[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:9 step:45670[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:9 step:45675[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:9 step:45680[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:9 step:45685[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:9 step:45690[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:9 step:45695[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:9 step:45700[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:9 step:45705[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:9 step:45710[D loss: 1.000022] [G loss: 1.000047]\n",
      "epoch:9 step:45715[D loss: 1.000011] [G loss: 1.000038]\n",
      "epoch:9 step:45720[D loss: 0.999999] [G loss: 1.000011]\n",
      "epoch:9 step:45725[D loss: 0.999933] [G loss: 1.000114]\n",
      "epoch:9 step:45730[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:9 step:45735[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:9 step:45740[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:9 step:45745[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:9 step:45750[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:9 step:45755[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:9 step:45760[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:9 step:45765[D loss: 0.999959] [G loss: 1.000109]\n",
      "epoch:9 step:45770[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:9 step:45775[D loss: 0.999978] [G loss: 1.000117]\n",
      "epoch:9 step:45780[D loss: 0.999999] [G loss: 1.000063]\n",
      "epoch:9 step:45785[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:9 step:45790[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:9 step:45795[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:9 step:45800[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:9 step:45805[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:9 step:45810[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:9 step:45815[D loss: 0.999992] [G loss: 1.000072]\n",
      "epoch:9 step:45820[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:9 step:45825[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:9 step:45830[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:9 step:45835[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:9 step:45840[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:9 step:45845[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:9 step:45850[D loss: 0.999998] [G loss: 1.000074]\n",
      "epoch:9 step:45855[D loss: 1.000022] [G loss: 0.999964]\n",
      "epoch:9 step:45860[D loss: 0.999996] [G loss: 1.000122]\n",
      "epoch:9 step:45865[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:9 step:45870[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:9 step:45875[D loss: 1.000086] [G loss: 0.999957]\n",
      "epoch:9 step:45880[D loss: 0.999907] [G loss: 1.000044]\n",
      "epoch:9 step:45885[D loss: 1.000005] [G loss: 0.999971]\n",
      "epoch:9 step:45890[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:9 step:45895[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:9 step:45900[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:9 step:45905[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:9 step:45910[D loss: 0.999939] [G loss: 1.000101]\n",
      "epoch:9 step:45915[D loss: 0.999959] [G loss: 1.000055]\n",
      "epoch:9 step:45920[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:9 step:45925[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:9 step:45930[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:9 step:45935[D loss: 1.000040] [G loss: 1.000004]\n",
      "epoch:9 step:45940[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:9 step:45945[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:9 step:45950[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:9 step:45955[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:9 step:45960[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:9 step:45965[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:9 step:45970[D loss: 1.000010] [G loss: 0.999993]\n",
      "epoch:9 step:45975[D loss: 1.000039] [G loss: 0.999989]\n",
      "epoch:9 step:45980[D loss: 0.999983] [G loss: 1.000040]\n",
      "epoch:9 step:45985[D loss: 0.999960] [G loss: 1.000101]\n",
      "epoch:9 step:45990[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:9 step:45995[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:9 step:46000[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:9 step:46005[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:9 step:46010[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:9 step:46015[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:9 step:46020[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:9 step:46025[D loss: 1.000047] [G loss: 0.999974]\n",
      "epoch:9 step:46030[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:9 step:46035[D loss: 1.000088] [G loss: 0.999943]\n",
      "epoch:9 step:46040[D loss: 0.999886] [G loss: 1.000125]\n",
      "epoch:9 step:46045[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:9 step:46050[D loss: 0.999972] [G loss: 1.000029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:46055[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:9 step:46060[D loss: 1.000011] [G loss: 1.000016]\n",
      "epoch:9 step:46065[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:9 step:46070[D loss: 0.999968] [G loss: 1.000035]\n",
      "epoch:9 step:46075[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:9 step:46080[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:9 step:46085[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:9 step:46090[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:9 step:46095[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:9 step:46100[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:9 step:46105[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:9 step:46110[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:9 step:46115[D loss: 1.000009] [G loss: 1.000039]\n",
      "epoch:9 step:46120[D loss: 1.000009] [G loss: 0.999982]\n",
      "epoch:9 step:46125[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:9 step:46130[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:9 step:46135[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:9 step:46140[D loss: 0.999993] [G loss: 1.000037]\n",
      "epoch:9 step:46145[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:9 step:46150[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:9 step:46155[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:9 step:46160[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:9 step:46165[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:9 step:46170[D loss: 1.000014] [G loss: 1.000036]\n",
      "epoch:9 step:46175[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:9 step:46180[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:9 step:46185[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:9 step:46190[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:9 step:46195[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:9 step:46200[D loss: 0.999997] [G loss: 1.000062]\n",
      "epoch:9 step:46205[D loss: 1.000022] [G loss: 1.000035]\n",
      "epoch:9 step:46210[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:9 step:46215[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:9 step:46220[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:9 step:46225[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:9 step:46230[D loss: 0.999967] [G loss: 1.000041]\n",
      "epoch:9 step:46235[D loss: 1.000001] [G loss: 1.000056]\n",
      "epoch:9 step:46240[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:9 step:46245[D loss: 0.999996] [G loss: 1.000098]\n",
      "epoch:9 step:46250[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:9 step:46255[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:9 step:46260[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:9 step:46265[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:9 step:46270[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:9 step:46275[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:9 step:46280[D loss: 0.999924] [G loss: 1.000117]\n",
      "epoch:9 step:46285[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:9 step:46290[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:9 step:46295[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:9 step:46300[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:9 step:46305[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:9 step:46310[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:9 step:46315[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:9 step:46320[D loss: 0.999961] [G loss: 1.000103]\n",
      "epoch:9 step:46325[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:9 step:46330[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:9 step:46335[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:9 step:46340[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:9 step:46345[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:9 step:46350[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:9 step:46355[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:9 step:46360[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:9 step:46365[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:9 step:46370[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:9 step:46375[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:9 step:46380[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:9 step:46385[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:9 step:46390[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:9 step:46395[D loss: 1.000001] [G loss: 1.000067]\n",
      "epoch:9 step:46400[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:9 step:46405[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:9 step:46410[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:9 step:46415[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:9 step:46420[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:9 step:46425[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:9 step:46430[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:9 step:46435[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:9 step:46440[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:9 step:46445[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:9 step:46450[D loss: 0.999998] [G loss: 1.000072]\n",
      "epoch:9 step:46455[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:9 step:46460[D loss: 0.999994] [G loss: 1.000082]\n",
      "epoch:9 step:46465[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:9 step:46470[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:9 step:46475[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:9 step:46480[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:9 step:46485[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:9 step:46490[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:9 step:46495[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:9 step:46500[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:9 step:46505[D loss: 1.000017] [G loss: 0.999986]\n",
      "epoch:9 step:46510[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:9 step:46515[D loss: 0.999997] [G loss: 1.000089]\n",
      "epoch:9 step:46520[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:9 step:46525[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:9 step:46530[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:9 step:46535[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:9 step:46540[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:9 step:46545[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:9 step:46550[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:9 step:46555[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:9 step:46560[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:9 step:46565[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:9 step:46570[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:9 step:46575[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:9 step:46580[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:9 step:46585[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:9 step:46590[D loss: 1.000004] [G loss: 1.000057]\n",
      "epoch:9 step:46595[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:9 step:46600[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:9 step:46605[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:9 step:46610[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:9 step:46615[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:9 step:46620[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:9 step:46625[D loss: 0.999967] [G loss: 1.000026]\n",
      "epoch:9 step:46630[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:9 step:46635[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:9 step:46640[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:9 step:46645[D loss: 1.000008] [G loss: 1.000046]\n",
      "epoch:9 step:46650[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:9 step:46655[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:9 step:46660[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:9 step:46665[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:9 step:46670[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:9 step:46675[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:9 step:46680[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:9 step:46685[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:9 step:46690[D loss: 1.000007] [G loss: 1.000003]\n",
      "epoch:9 step:46695[D loss: 0.999933] [G loss: 1.000141]\n",
      "epoch:9 step:46700[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:9 step:46705[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:9 step:46710[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:9 step:46715[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:9 step:46720[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:9 step:46725[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:9 step:46730[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:9 step:46735[D loss: 1.000008] [G loss: 1.000017]\n",
      "epoch:9 step:46740[D loss: 1.000010] [G loss: 0.999999]\n",
      "epoch:9 step:46745[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:9 step:46750[D loss: 1.000006] [G loss: 1.000068]\n",
      "epoch:9 step:46755[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:9 step:46760[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:9 step:46765[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:9 step:46770[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:9 step:46775[D loss: 0.999961] [G loss: 1.000102]\n",
      "epoch:9 step:46780[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:9 step:46785[D loss: 0.999971] [G loss: 1.000065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:46790[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:9 step:46795[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:9 step:46800[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:9 step:46805[D loss: 1.000005] [G loss: 1.000033]\n",
      "epoch:9 step:46810[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:9 step:46815[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:9 step:46820[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:9 step:46825[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:9 step:46830[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:9 step:46835[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:9 step:46840[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:9 step:46845[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:9 step:46850[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:10 step:46855[D loss: 1.000033] [G loss: 1.000028]\n",
      "epoch:10 step:46860[D loss: 1.000006] [G loss: 1.000011]\n",
      "epoch:10 step:46865[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:10 step:46870[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:10 step:46875[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:10 step:46880[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:10 step:46885[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:10 step:46890[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:10 step:46895[D loss: 1.000017] [G loss: 1.000010]\n",
      "epoch:10 step:46900[D loss: 1.000038] [G loss: 1.000004]\n",
      "epoch:10 step:46905[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:10 step:46910[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:10 step:46915[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:10 step:46920[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:10 step:46925[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:10 step:46930[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:10 step:46935[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:10 step:46940[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:10 step:46945[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:10 step:46950[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:10 step:46955[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:10 step:46960[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:10 step:46965[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:10 step:46970[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:10 step:46975[D loss: 1.000003] [G loss: 0.999995]\n",
      "epoch:10 step:46980[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:10 step:46985[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:10 step:46990[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:10 step:46995[D loss: 0.999949] [G loss: 1.000107]\n",
      "epoch:10 step:47000[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:10 step:47005[D loss: 0.999991] [G loss: 1.000021]\n",
      "epoch:10 step:47010[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:10 step:47015[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:10 step:47020[D loss: 1.000029] [G loss: 0.999984]\n",
      "epoch:10 step:47025[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:10 step:47030[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:10 step:47035[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:10 step:47040[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:10 step:47045[D loss: 1.000034] [G loss: 0.999945]\n",
      "epoch:10 step:47050[D loss: 1.000057] [G loss: 0.999971]\n",
      "epoch:10 step:47055[D loss: 0.999968] [G loss: 1.000120]\n",
      "epoch:10 step:47060[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:10 step:47065[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:10 step:47070[D loss: 0.999993] [G loss: 1.000079]\n",
      "epoch:10 step:47075[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:10 step:47080[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:10 step:47085[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:10 step:47090[D loss: 1.000029] [G loss: 0.999963]\n",
      "epoch:10 step:47095[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:10 step:47100[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:10 step:47105[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:10 step:47110[D loss: 0.999998] [G loss: 1.000009]\n",
      "epoch:10 step:47115[D loss: 0.999989] [G loss: 1.000088]\n",
      "epoch:10 step:47120[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:10 step:47125[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:10 step:47130[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:10 step:47135[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:10 step:47140[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:10 step:47145[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:10 step:47150[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:10 step:47155[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:10 step:47160[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:10 step:47165[D loss: 1.000056] [G loss: 0.999973]\n",
      "epoch:10 step:47170[D loss: 0.999982] [G loss: 1.000105]\n",
      "epoch:10 step:47175[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:10 step:47180[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:10 step:47185[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:10 step:47190[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:10 step:47195[D loss: 1.000017] [G loss: 1.000073]\n",
      "epoch:10 step:47200[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:10 step:47205[D loss: 1.000011] [G loss: 1.000016]\n",
      "epoch:10 step:47210[D loss: 0.999999] [G loss: 1.000085]\n",
      "epoch:10 step:47215[D loss: 0.999999] [G loss: 1.000067]\n",
      "epoch:10 step:47220[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:10 step:47225[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:10 step:47230[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:10 step:47235[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:10 step:47240[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:10 step:47245[D loss: 1.000006] [G loss: 1.000037]\n",
      "epoch:10 step:47250[D loss: 0.999998] [G loss: 1.000029]\n",
      "epoch:10 step:47255[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:10 step:47260[D loss: 0.999989] [G loss: 0.999999]\n",
      "epoch:10 step:47265[D loss: 0.999998] [G loss: 0.999999]\n",
      "epoch:10 step:47270[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:10 step:47275[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:10 step:47280[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:10 step:47285[D loss: 1.000005] [G loss: 1.000037]\n",
      "epoch:10 step:47290[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:10 step:47295[D loss: 1.000033] [G loss: 1.000043]\n",
      "epoch:10 step:47300[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:10 step:47305[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:10 step:47310[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:10 step:47315[D loss: 1.000004] [G loss: 1.000040]\n",
      "epoch:10 step:47320[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:10 step:47325[D loss: 1.000027] [G loss: 1.000010]\n",
      "epoch:10 step:47330[D loss: 0.999979] [G loss: 1.000111]\n",
      "epoch:10 step:47335[D loss: 0.999994] [G loss: 1.000081]\n",
      "epoch:10 step:47340[D loss: 0.999957] [G loss: 1.000128]\n",
      "epoch:10 step:47345[D loss: 0.999941] [G loss: 1.000106]\n",
      "epoch:10 step:47350[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:10 step:47355[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:10 step:47360[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:10 step:47365[D loss: 1.000016] [G loss: 0.999997]\n",
      "epoch:10 step:47370[D loss: 1.000011] [G loss: 1.000039]\n",
      "epoch:10 step:47375[D loss: 1.000027] [G loss: 1.000041]\n",
      "epoch:10 step:47380[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:10 step:47385[D loss: 1.000008] [G loss: 1.000016]\n",
      "epoch:10 step:47390[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:10 step:47395[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:10 step:47400[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:10 step:47405[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:10 step:47410[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:10 step:47415[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:10 step:47420[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:10 step:47425[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:10 step:47430[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:10 step:47435[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:10 step:47440[D loss: 0.999999] [G loss: 1.000083]\n",
      "epoch:10 step:47445[D loss: 1.000014] [G loss: 1.000090]\n",
      "epoch:10 step:47450[D loss: 0.999914] [G loss: 1.000135]\n",
      "epoch:10 step:47455[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:10 step:47460[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:10 step:47465[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:10 step:47470[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:10 step:47475[D loss: 1.000012] [G loss: 1.000024]\n",
      "epoch:10 step:47480[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:10 step:47485[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:10 step:47490[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:10 step:47495[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:10 step:47500[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:10 step:47505[D loss: 0.999988] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:47510[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:10 step:47515[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:10 step:47520[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:10 step:47525[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:10 step:47530[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:10 step:47535[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:10 step:47540[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:10 step:47545[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:10 step:47550[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:10 step:47555[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:10 step:47560[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:10 step:47565[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:10 step:47570[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:10 step:47575[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:10 step:47580[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:10 step:47585[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:10 step:47590[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:10 step:47595[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:10 step:47600[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:10 step:47605[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:10 step:47610[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:10 step:47615[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:10 step:47620[D loss: 0.999937] [G loss: 1.000114]\n",
      "epoch:10 step:47625[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:10 step:47630[D loss: 1.000014] [G loss: 1.000041]\n",
      "epoch:10 step:47635[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:10 step:47640[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:10 step:47645[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:10 step:47650[D loss: 1.000020] [G loss: 1.000016]\n",
      "epoch:10 step:47655[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:10 step:47660[D loss: 0.999945] [G loss: 1.000175]\n",
      "epoch:10 step:47665[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:10 step:47670[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:10 step:47675[D loss: 1.000017] [G loss: 1.000010]\n",
      "epoch:10 step:47680[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:10 step:47685[D loss: 0.999968] [G loss: 1.000032]\n",
      "epoch:10 step:47690[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:10 step:47695[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:10 step:47700[D loss: 0.999998] [G loss: 1.000075]\n",
      "epoch:10 step:47705[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:10 step:47710[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:10 step:47715[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:10 step:47720[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:10 step:47725[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:10 step:47730[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:10 step:47735[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:10 step:47740[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:10 step:47745[D loss: 0.999970] [G loss: 1.000105]\n",
      "epoch:10 step:47750[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:10 step:47755[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:10 step:47760[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:10 step:47765[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:10 step:47770[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:10 step:47775[D loss: 1.000011] [G loss: 1.000009]\n",
      "epoch:10 step:47780[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:10 step:47785[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:10 step:47790[D loss: 1.000007] [G loss: 1.000040]\n",
      "epoch:10 step:47795[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:10 step:47800[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:10 step:47805[D loss: 0.999958] [G loss: 1.000058]\n",
      "epoch:10 step:47810[D loss: 0.999973] [G loss: 1.000037]\n",
      "epoch:10 step:47815[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:10 step:47820[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:10 step:47825[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:10 step:47830[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:10 step:47835[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:10 step:47840[D loss: 1.000058] [G loss: 1.000034]\n",
      "epoch:10 step:47845[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:10 step:47850[D loss: 0.999996] [G loss: 1.000097]\n",
      "epoch:10 step:47855[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:10 step:47860[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:10 step:47865[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:10 step:47870[D loss: 1.000016] [G loss: 1.000046]\n",
      "epoch:10 step:47875[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:10 step:47880[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:10 step:47885[D loss: 0.999999] [G loss: 1.000080]\n",
      "epoch:10 step:47890[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:10 step:47895[D loss: 0.999995] [G loss: 1.000077]\n",
      "epoch:10 step:47900[D loss: 0.999968] [G loss: 1.000107]\n",
      "epoch:10 step:47905[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:10 step:47910[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:10 step:47915[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:10 step:47920[D loss: 1.000006] [G loss: 1.000028]\n",
      "epoch:10 step:47925[D loss: 0.999987] [G loss: 1.000095]\n",
      "epoch:10 step:47930[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:10 step:47935[D loss: 1.000075] [G loss: 1.000041]\n",
      "epoch:10 step:47940[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:10 step:47945[D loss: 0.999950] [G loss: 1.000096]\n",
      "epoch:10 step:47950[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:10 step:47955[D loss: 0.999999] [G loss: 1.000045]\n",
      "epoch:10 step:47960[D loss: 1.000016] [G loss: 0.999991]\n",
      "epoch:10 step:47965[D loss: 1.000033] [G loss: 0.999969]\n",
      "epoch:10 step:47970[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:10 step:47975[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:10 step:47980[D loss: 0.999975] [G loss: 1.000113]\n",
      "epoch:10 step:47985[D loss: 1.000009] [G loss: 1.000107]\n",
      "epoch:10 step:47990[D loss: 0.999914] [G loss: 1.000098]\n",
      "epoch:10 step:47995[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:10 step:48000[D loss: 1.000037] [G loss: 0.999995]\n",
      "epoch:10 step:48005[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:10 step:48010[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:10 step:48015[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:10 step:48020[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:10 step:48025[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:10 step:48030[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:10 step:48035[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:10 step:48040[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:10 step:48045[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:10 step:48050[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:10 step:48055[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:10 step:48060[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:10 step:48065[D loss: 0.999983] [G loss: 1.000020]\n",
      "epoch:10 step:48070[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:10 step:48075[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:10 step:48080[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:10 step:48085[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:10 step:48090[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:10 step:48095[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:10 step:48100[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:10 step:48105[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:10 step:48110[D loss: 0.999961] [G loss: 1.000061]\n",
      "epoch:10 step:48115[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:10 step:48120[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:10 step:48125[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:10 step:48130[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:10 step:48135[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:10 step:48140[D loss: 0.999994] [G loss: 1.000060]\n",
      "epoch:10 step:48145[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:10 step:48150[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:10 step:48155[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:10 step:48160[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:10 step:48165[D loss: 0.999973] [G loss: 1.000099]\n",
      "epoch:10 step:48170[D loss: 0.999950] [G loss: 1.000065]\n",
      "epoch:10 step:48175[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:10 step:48180[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:10 step:48185[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:10 step:48190[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:10 step:48195[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:10 step:48200[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:10 step:48205[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:10 step:48210[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:10 step:48215[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:10 step:48220[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:10 step:48225[D loss: 0.999979] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:48230[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:10 step:48235[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:10 step:48240[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:10 step:48245[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:10 step:48250[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:10 step:48255[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:10 step:48260[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:10 step:48265[D loss: 0.999947] [G loss: 1.000074]\n",
      "epoch:10 step:48270[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:10 step:48275[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:10 step:48280[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:10 step:48285[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:10 step:48290[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:10 step:48295[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:10 step:48300[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:10 step:48305[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:10 step:48310[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:10 step:48315[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:10 step:48320[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:10 step:48325[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:10 step:48330[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:10 step:48335[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:10 step:48340[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:10 step:48345[D loss: 0.999979] [G loss: 1.000019]\n",
      "epoch:10 step:48350[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:10 step:48355[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:10 step:48360[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:10 step:48365[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:10 step:48370[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:10 step:48375[D loss: 1.000017] [G loss: 1.000025]\n",
      "epoch:10 step:48380[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:10 step:48385[D loss: 0.999962] [G loss: 1.000037]\n",
      "epoch:10 step:48390[D loss: 0.999992] [G loss: 1.000031]\n",
      "epoch:10 step:48395[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:10 step:48400[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:10 step:48405[D loss: 1.000060] [G loss: 0.999928]\n",
      "epoch:10 step:48410[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:10 step:48415[D loss: 0.999936] [G loss: 1.000099]\n",
      "epoch:10 step:48420[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:10 step:48425[D loss: 1.000023] [G loss: 1.000029]\n",
      "epoch:10 step:48430[D loss: 1.000029] [G loss: 1.000075]\n",
      "epoch:10 step:48435[D loss: 0.999960] [G loss: 1.000038]\n",
      "epoch:10 step:48440[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:10 step:48445[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:10 step:48450[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:10 step:48455[D loss: 0.999985] [G loss: 1.000114]\n",
      "epoch:10 step:48460[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:10 step:48465[D loss: 1.000036] [G loss: 0.999943]\n",
      "epoch:10 step:48470[D loss: 0.999974] [G loss: 1.000016]\n",
      "epoch:10 step:48475[D loss: 0.999924] [G loss: 1.000100]\n",
      "epoch:10 step:48480[D loss: 0.999971] [G loss: 1.000037]\n",
      "epoch:10 step:48485[D loss: 1.000009] [G loss: 1.000015]\n",
      "epoch:10 step:48490[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:10 step:48495[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:10 step:48500[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:10 step:48505[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:10 step:48510[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:10 step:48515[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:10 step:48520[D loss: 1.000013] [G loss: 1.000041]\n",
      "epoch:10 step:48525[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:10 step:48530[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:10 step:48535[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:10 step:48540[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:10 step:48545[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:10 step:48550[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:10 step:48555[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:10 step:48560[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:10 step:48565[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:10 step:48570[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:10 step:48575[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:10 step:48580[D loss: 0.999991] [G loss: 1.000100]\n",
      "epoch:10 step:48585[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:10 step:48590[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:10 step:48595[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:10 step:48600[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:10 step:48605[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:10 step:48610[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:10 step:48615[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:10 step:48620[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:10 step:48625[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:10 step:48630[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:10 step:48635[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:10 step:48640[D loss: 1.000011] [G loss: 1.000054]\n",
      "epoch:10 step:48645[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:10 step:48650[D loss: 1.000012] [G loss: 1.000021]\n",
      "epoch:10 step:48655[D loss: 0.999980] [G loss: 1.000022]\n",
      "epoch:10 step:48660[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:10 step:48665[D loss: 0.999959] [G loss: 1.000133]\n",
      "epoch:10 step:48670[D loss: 1.000039] [G loss: 1.000012]\n",
      "epoch:10 step:48675[D loss: 0.999957] [G loss: 1.000135]\n",
      "epoch:10 step:48680[D loss: 0.999942] [G loss: 1.000102]\n",
      "epoch:10 step:48685[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:10 step:48690[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:10 step:48695[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:10 step:48700[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:10 step:48705[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:10 step:48710[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:10 step:48715[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:10 step:48720[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:10 step:48725[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:10 step:48730[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:10 step:48735[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:10 step:48740[D loss: 0.999939] [G loss: 1.000240]\n",
      "epoch:10 step:48745[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:10 step:48750[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:10 step:48755[D loss: 0.999994] [G loss: 1.000048]\n",
      "epoch:10 step:48760[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:10 step:48765[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:10 step:48770[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:10 step:48775[D loss: 1.000022] [G loss: 1.000023]\n",
      "epoch:10 step:48780[D loss: 0.999928] [G loss: 1.000079]\n",
      "epoch:10 step:48785[D loss: 1.000020] [G loss: 1.000034]\n",
      "epoch:10 step:48790[D loss: 0.999980] [G loss: 1.000109]\n",
      "epoch:10 step:48795[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:10 step:48800[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:10 step:48805[D loss: 1.000030] [G loss: 0.999977]\n",
      "epoch:10 step:48810[D loss: 0.999946] [G loss: 1.000042]\n",
      "epoch:10 step:48815[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:10 step:48820[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:10 step:48825[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:10 step:48830[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:10 step:48835[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:10 step:48840[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:10 step:48845[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:10 step:48850[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:10 step:48855[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:10 step:48860[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:10 step:48865[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:10 step:48870[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:10 step:48875[D loss: 1.000017] [G loss: 1.000067]\n",
      "epoch:10 step:48880[D loss: 1.000006] [G loss: 0.999957]\n",
      "epoch:10 step:48885[D loss: 1.000014] [G loss: 1.000002]\n",
      "epoch:10 step:48890[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:10 step:48895[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:10 step:48900[D loss: 1.000018] [G loss: 1.000069]\n",
      "epoch:10 step:48905[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:10 step:48910[D loss: 1.000068] [G loss: 0.999928]\n",
      "epoch:10 step:48915[D loss: 0.999996] [G loss: 0.999994]\n",
      "epoch:10 step:48920[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:10 step:48925[D loss: 0.999963] [G loss: 0.999995]\n",
      "epoch:10 step:48930[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:10 step:48935[D loss: 1.000017] [G loss: 1.000006]\n",
      "epoch:10 step:48940[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:10 step:48945[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:10 step:48950[D loss: 0.999981] [G loss: 1.000032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:48955[D loss: 1.000013] [G loss: 1.000033]\n",
      "epoch:10 step:48960[D loss: 0.999973] [G loss: 1.000121]\n",
      "epoch:10 step:48965[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:10 step:48970[D loss: 0.999967] [G loss: 1.000115]\n",
      "epoch:10 step:48975[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:10 step:48980[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:10 step:48985[D loss: 0.999986] [G loss: 0.999991]\n",
      "epoch:10 step:48990[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:10 step:48995[D loss: 1.000013] [G loss: 0.999981]\n",
      "epoch:10 step:49000[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:10 step:49005[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:10 step:49010[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:10 step:49015[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:10 step:49020[D loss: 1.000023] [G loss: 1.000002]\n",
      "epoch:10 step:49025[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:10 step:49030[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:10 step:49035[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:10 step:49040[D loss: 1.000021] [G loss: 1.000008]\n",
      "epoch:10 step:49045[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:10 step:49050[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:10 step:49055[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:10 step:49060[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:10 step:49065[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:10 step:49070[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:10 step:49075[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:10 step:49080[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:10 step:49085[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:10 step:49090[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:10 step:49095[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:10 step:49100[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:10 step:49105[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:10 step:49110[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:10 step:49115[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:10 step:49120[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:10 step:49125[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:10 step:49130[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:10 step:49135[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:10 step:49140[D loss: 1.000020] [G loss: 1.000021]\n",
      "epoch:10 step:49145[D loss: 1.000033] [G loss: 1.000087]\n",
      "epoch:10 step:49150[D loss: 1.000010] [G loss: 0.999974]\n",
      "epoch:10 step:49155[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:10 step:49160[D loss: 1.000020] [G loss: 0.999990]\n",
      "epoch:10 step:49165[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:10 step:49170[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:10 step:49175[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:10 step:49180[D loss: 0.999967] [G loss: 1.000031]\n",
      "epoch:10 step:49185[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:10 step:49190[D loss: 1.000019] [G loss: 1.000043]\n",
      "epoch:10 step:49195[D loss: 0.999976] [G loss: 1.000135]\n",
      "epoch:10 step:49200[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:10 step:49205[D loss: 0.999990] [G loss: 1.000113]\n",
      "epoch:10 step:49210[D loss: 0.999949] [G loss: 1.000125]\n",
      "epoch:10 step:49215[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:10 step:49220[D loss: 1.000015] [G loss: 1.000008]\n",
      "epoch:10 step:49225[D loss: 0.999996] [G loss: 1.000008]\n",
      "epoch:10 step:49230[D loss: 0.999989] [G loss: 0.999998]\n",
      "epoch:10 step:49235[D loss: 0.999964] [G loss: 1.000025]\n",
      "epoch:10 step:49240[D loss: 1.000033] [G loss: 0.999996]\n",
      "epoch:10 step:49245[D loss: 0.999953] [G loss: 1.000027]\n",
      "epoch:10 step:49250[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:10 step:49255[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:10 step:49260[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:10 step:49265[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:10 step:49270[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:10 step:49275[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:10 step:49280[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:10 step:49285[D loss: 1.000008] [G loss: 1.000065]\n",
      "epoch:10 step:49290[D loss: 1.000013] [G loss: 1.000066]\n",
      "epoch:10 step:49295[D loss: 1.000005] [G loss: 1.000102]\n",
      "epoch:10 step:49300[D loss: 0.999984] [G loss: 1.000146]\n",
      "epoch:10 step:49305[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:10 step:49310[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:10 step:49315[D loss: 1.000034] [G loss: 1.000081]\n",
      "epoch:10 step:49320[D loss: 1.000007] [G loss: 1.000044]\n",
      "epoch:10 step:49325[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:10 step:49330[D loss: 0.999998] [G loss: 1.000106]\n",
      "epoch:10 step:49335[D loss: 1.000008] [G loss: 1.000067]\n",
      "epoch:10 step:49340[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:10 step:49345[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:10 step:49350[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:10 step:49355[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:10 step:49360[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:10 step:49365[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:10 step:49370[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:10 step:49375[D loss: 1.000007] [G loss: 1.000021]\n",
      "epoch:10 step:49380[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:10 step:49385[D loss: 1.000012] [G loss: 1.000052]\n",
      "epoch:10 step:49390[D loss: 1.000038] [G loss: 0.999980]\n",
      "epoch:10 step:49395[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:10 step:49400[D loss: 0.999977] [G loss: 1.000191]\n",
      "epoch:10 step:49405[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:10 step:49410[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:10 step:49415[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:10 step:49420[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:10 step:49425[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:10 step:49430[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:10 step:49435[D loss: 1.000107] [G loss: 0.999979]\n",
      "epoch:10 step:49440[D loss: 0.999909] [G loss: 1.000181]\n",
      "epoch:10 step:49445[D loss: 0.999929] [G loss: 1.000167]\n",
      "epoch:10 step:49450[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:10 step:49455[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:10 step:49460[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:10 step:49465[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:10 step:49470[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:10 step:49475[D loss: 1.000015] [G loss: 1.000024]\n",
      "epoch:10 step:49480[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:10 step:49485[D loss: 0.999935] [G loss: 1.000145]\n",
      "epoch:10 step:49490[D loss: 0.999903] [G loss: 1.000182]\n",
      "epoch:10 step:49495[D loss: 0.999965] [G loss: 1.000099]\n",
      "epoch:10 step:49500[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:10 step:49505[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:10 step:49510[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:10 step:49515[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:10 step:49520[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:10 step:49525[D loss: 0.999935] [G loss: 1.000092]\n",
      "epoch:10 step:49530[D loss: 0.999982] [G loss: 1.000120]\n",
      "epoch:10 step:49535[D loss: 1.000017] [G loss: 1.000100]\n",
      "epoch:10 step:49540[D loss: 0.999930] [G loss: 1.000192]\n",
      "epoch:10 step:49545[D loss: 0.999960] [G loss: 1.000152]\n",
      "epoch:10 step:49550[D loss: 0.999940] [G loss: 1.000139]\n",
      "epoch:10 step:49555[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:10 step:49560[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:10 step:49565[D loss: 1.000064] [G loss: 0.999909]\n",
      "epoch:10 step:49570[D loss: 1.000012] [G loss: 0.999998]\n",
      "epoch:10 step:49575[D loss: 0.999955] [G loss: 1.000133]\n",
      "epoch:10 step:49580[D loss: 0.999993] [G loss: 1.000081]\n",
      "epoch:10 step:49585[D loss: 0.999948] [G loss: 1.000062]\n",
      "epoch:10 step:49590[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:10 step:49595[D loss: 0.999959] [G loss: 1.000117]\n",
      "epoch:10 step:49600[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:10 step:49605[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:10 step:49610[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:10 step:49615[D loss: 1.000015] [G loss: 1.000005]\n",
      "epoch:10 step:49620[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:10 step:49625[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:10 step:49630[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:10 step:49635[D loss: 0.999993] [G loss: 1.000072]\n",
      "epoch:10 step:49640[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:10 step:49645[D loss: 0.999993] [G loss: 1.000090]\n",
      "epoch:10 step:49650[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:10 step:49655[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:10 step:49660[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:10 step:49665[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:10 step:49670[D loss: 0.999988] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:49675[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:10 step:49680[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:10 step:49685[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:10 step:49690[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:10 step:49695[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:10 step:49700[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:10 step:49705[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:10 step:49710[D loss: 1.000013] [G loss: 0.999996]\n",
      "epoch:10 step:49715[D loss: 1.000008] [G loss: 1.000046]\n",
      "epoch:10 step:49720[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:10 step:49725[D loss: 1.000050] [G loss: 0.999976]\n",
      "epoch:10 step:49730[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:10 step:49735[D loss: 0.999960] [G loss: 1.000052]\n",
      "epoch:10 step:49740[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:10 step:49745[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:10 step:49750[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:10 step:49755[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:10 step:49760[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:10 step:49765[D loss: 0.999967] [G loss: 1.000113]\n",
      "epoch:10 step:49770[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:10 step:49775[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:10 step:49780[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:10 step:49785[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:10 step:49790[D loss: 0.999994] [G loss: 1.000086]\n",
      "epoch:10 step:49795[D loss: 1.000044] [G loss: 0.999993]\n",
      "epoch:10 step:49800[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:10 step:49805[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:10 step:49810[D loss: 1.000005] [G loss: 1.000002]\n",
      "epoch:10 step:49815[D loss: 1.000029] [G loss: 1.000023]\n",
      "epoch:10 step:49820[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:10 step:49825[D loss: 0.999988] [G loss: 1.000109]\n",
      "epoch:10 step:49830[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:10 step:49835[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:10 step:49840[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:10 step:49845[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:10 step:49850[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:10 step:49855[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:10 step:49860[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:10 step:49865[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:10 step:49870[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:10 step:49875[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:10 step:49880[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:10 step:49885[D loss: 1.000009] [G loss: 1.000029]\n",
      "epoch:10 step:49890[D loss: 0.999934] [G loss: 1.000166]\n",
      "epoch:10 step:49895[D loss: 0.999992] [G loss: 1.000141]\n",
      "epoch:10 step:49900[D loss: 0.999953] [G loss: 1.000038]\n",
      "epoch:10 step:49905[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:10 step:49910[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:10 step:49915[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:10 step:49920[D loss: 0.999978] [G loss: 1.000024]\n",
      "epoch:10 step:49925[D loss: 0.999971] [G loss: 1.000029]\n",
      "epoch:10 step:49930[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:10 step:49935[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:10 step:49940[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:10 step:49945[D loss: 0.999949] [G loss: 1.000061]\n",
      "epoch:10 step:49950[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:10 step:49955[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:10 step:49960[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:10 step:49965[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:10 step:49970[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:10 step:49975[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:10 step:49980[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:10 step:49985[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:10 step:49990[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:10 step:49995[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:10 step:50000[D loss: 0.999950] [G loss: 1.000092]\n",
      "epoch:10 step:50005[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:10 step:50010[D loss: 0.999977] [G loss: 1.000094]\n",
      "epoch:10 step:50015[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:10 step:50020[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:10 step:50025[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:10 step:50030[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:10 step:50035[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:10 step:50040[D loss: 0.999948] [G loss: 1.000068]\n",
      "epoch:10 step:50045[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:10 step:50050[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:10 step:50055[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:10 step:50060[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:10 step:50065[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:10 step:50070[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:10 step:50075[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:10 step:50080[D loss: 0.999954] [G loss: 1.000118]\n",
      "epoch:10 step:50085[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:10 step:50090[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:10 step:50095[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:10 step:50100[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:10 step:50105[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:10 step:50110[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:10 step:50115[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:10 step:50120[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:10 step:50125[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:10 step:50130[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:10 step:50135[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:10 step:50140[D loss: 0.999995] [G loss: 1.000106]\n",
      "epoch:10 step:50145[D loss: 0.999974] [G loss: 1.000133]\n",
      "epoch:10 step:50150[D loss: 1.000001] [G loss: 1.000012]\n",
      "epoch:10 step:50155[D loss: 0.999951] [G loss: 1.000128]\n",
      "epoch:10 step:50160[D loss: 0.999956] [G loss: 1.000196]\n",
      "epoch:10 step:50165[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:10 step:50170[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:10 step:50175[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:10 step:50180[D loss: 1.000016] [G loss: 1.000005]\n",
      "epoch:10 step:50185[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:10 step:50190[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:10 step:50195[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:10 step:50200[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:10 step:50205[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:10 step:50210[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:10 step:50215[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:10 step:50220[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:10 step:50225[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:10 step:50230[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:10 step:50235[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:10 step:50240[D loss: 0.999961] [G loss: 1.000143]\n",
      "epoch:10 step:50245[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:10 step:50250[D loss: 0.999943] [G loss: 1.000079]\n",
      "epoch:10 step:50255[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:10 step:50260[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:10 step:50265[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:10 step:50270[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:10 step:50275[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:10 step:50280[D loss: 0.999962] [G loss: 1.000099]\n",
      "epoch:10 step:50285[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:10 step:50290[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:10 step:50295[D loss: 1.000007] [G loss: 1.000068]\n",
      "epoch:10 step:50300[D loss: 0.999938] [G loss: 1.000097]\n",
      "epoch:10 step:50305[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:10 step:50310[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:10 step:50315[D loss: 0.999992] [G loss: 1.000066]\n",
      "epoch:10 step:50320[D loss: 0.999942] [G loss: 1.000134]\n",
      "epoch:10 step:50325[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:10 step:50330[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:10 step:50335[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:10 step:50340[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:10 step:50345[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:10 step:50350[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:10 step:50355[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:10 step:50360[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:10 step:50365[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:10 step:50370[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:10 step:50375[D loss: 0.999949] [G loss: 1.000123]\n",
      "epoch:10 step:50380[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:10 step:50385[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:10 step:50390[D loss: 0.999978] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:50395[D loss: 1.000091] [G loss: 0.999949]\n",
      "epoch:10 step:50400[D loss: 1.000030] [G loss: 1.000055]\n",
      "epoch:10 step:50405[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:10 step:50410[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:10 step:50415[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:10 step:50420[D loss: 1.000015] [G loss: 1.000027]\n",
      "epoch:10 step:50425[D loss: 1.000016] [G loss: 1.000008]\n",
      "epoch:10 step:50430[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:10 step:50435[D loss: 0.999961] [G loss: 1.000048]\n",
      "epoch:10 step:50440[D loss: 0.999987] [G loss: 1.000104]\n",
      "epoch:10 step:50445[D loss: 0.999994] [G loss: 1.000069]\n",
      "epoch:10 step:50450[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:10 step:50455[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:10 step:50460[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:10 step:50465[D loss: 1.000003] [G loss: 1.000139]\n",
      "epoch:10 step:50470[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:10 step:50475[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:10 step:50480[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:10 step:50485[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:10 step:50490[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:10 step:50495[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:10 step:50500[D loss: 0.999991] [G loss: 1.000102]\n",
      "epoch:10 step:50505[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:10 step:50510[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:10 step:50515[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:10 step:50520[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:10 step:50525[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:10 step:50530[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:10 step:50535[D loss: 1.000013] [G loss: 1.000000]\n",
      "epoch:10 step:50540[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:10 step:50545[D loss: 0.999995] [G loss: 1.000095]\n",
      "epoch:10 step:50550[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:10 step:50555[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:10 step:50560[D loss: 1.000069] [G loss: 0.999960]\n",
      "epoch:10 step:50565[D loss: 0.999947] [G loss: 1.000055]\n",
      "epoch:10 step:50570[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:10 step:50575[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:10 step:50580[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:10 step:50585[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:10 step:50590[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:10 step:50595[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:10 step:50600[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:10 step:50605[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:10 step:50610[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:10 step:50615[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:10 step:50620[D loss: 1.000002] [G loss: 1.000069]\n",
      "epoch:10 step:50625[D loss: 1.000017] [G loss: 0.999987]\n",
      "epoch:10 step:50630[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:10 step:50635[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:10 step:50640[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:10 step:50645[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:10 step:50650[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:10 step:50655[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:10 step:50660[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:10 step:50665[D loss: 0.999941] [G loss: 1.000096]\n",
      "epoch:10 step:50670[D loss: 0.999941] [G loss: 1.000089]\n",
      "epoch:10 step:50675[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:10 step:50680[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:10 step:50685[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:10 step:50690[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:10 step:50695[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:10 step:50700[D loss: 0.999998] [G loss: 1.000005]\n",
      "epoch:10 step:50705[D loss: 1.000018] [G loss: 1.000037]\n",
      "epoch:10 step:50710[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:10 step:50715[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:10 step:50720[D loss: 1.000021] [G loss: 1.000032]\n",
      "epoch:10 step:50725[D loss: 0.999940] [G loss: 1.000066]\n",
      "epoch:10 step:50730[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:10 step:50735[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:10 step:50740[D loss: 1.000040] [G loss: 0.999973]\n",
      "epoch:10 step:50745[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:10 step:50750[D loss: 1.000010] [G loss: 1.000010]\n",
      "epoch:10 step:50755[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:10 step:50760[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:10 step:50765[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:10 step:50770[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:10 step:50775[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:10 step:50780[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:10 step:50785[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:10 step:50790[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:10 step:50795[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:10 step:50800[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:10 step:50805[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:10 step:50810[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:10 step:50815[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:10 step:50820[D loss: 1.000007] [G loss: 1.000038]\n",
      "epoch:10 step:50825[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:10 step:50830[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:10 step:50835[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:10 step:50840[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:10 step:50845[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:10 step:50850[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:10 step:50855[D loss: 1.000019] [G loss: 0.999977]\n",
      "epoch:10 step:50860[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:10 step:50865[D loss: 1.000008] [G loss: 1.000034]\n",
      "epoch:10 step:50870[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:10 step:50875[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:10 step:50880[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:10 step:50885[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:10 step:50890[D loss: 1.000003] [G loss: 1.000036]\n",
      "epoch:10 step:50895[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:10 step:50900[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:10 step:50905[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:10 step:50910[D loss: 1.000008] [G loss: 0.999983]\n",
      "epoch:10 step:50915[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:10 step:50920[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:10 step:50925[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:10 step:50930[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:10 step:50935[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:10 step:50940[D loss: 1.000007] [G loss: 1.000057]\n",
      "epoch:10 step:50945[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:10 step:50950[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:10 step:50955[D loss: 0.999988] [G loss: 1.000047]\n",
      "epoch:10 step:50960[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:10 step:50965[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:10 step:50970[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:10 step:50975[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:10 step:50980[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:10 step:50985[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:10 step:50990[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:10 step:50995[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:10 step:51000[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:10 step:51005[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:10 step:51010[D loss: 1.000051] [G loss: 1.000001]\n",
      "epoch:10 step:51015[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:10 step:51020[D loss: 1.000012] [G loss: 1.000053]\n",
      "epoch:10 step:51025[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:10 step:51030[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:10 step:51035[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:10 step:51040[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:10 step:51045[D loss: 0.999973] [G loss: 1.000116]\n",
      "epoch:10 step:51050[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:10 step:51055[D loss: 1.000002] [G loss: 1.000029]\n",
      "epoch:10 step:51060[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:10 step:51065[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:10 step:51070[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:10 step:51075[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:10 step:51080[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:10 step:51085[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:10 step:51090[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:10 step:51095[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:10 step:51100[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:10 step:51105[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:10 step:51110[D loss: 0.999978] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:51115[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:10 step:51120[D loss: 0.999963] [G loss: 1.000099]\n",
      "epoch:10 step:51125[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:10 step:51130[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:10 step:51135[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:10 step:51140[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:10 step:51145[D loss: 1.000023] [G loss: 1.000076]\n",
      "epoch:10 step:51150[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:10 step:51155[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:10 step:51160[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:10 step:51165[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:10 step:51170[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:10 step:51175[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:10 step:51180[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:10 step:51185[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:10 step:51190[D loss: 1.000000] [G loss: 1.000003]\n",
      "epoch:10 step:51195[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:10 step:51200[D loss: 1.000055] [G loss: 0.999956]\n",
      "epoch:10 step:51205[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:10 step:51210[D loss: 1.000004] [G loss: 1.000009]\n",
      "epoch:10 step:51215[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:10 step:51220[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:10 step:51225[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:10 step:51230[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:10 step:51235[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:10 step:51240[D loss: 0.999965] [G loss: 1.000100]\n",
      "epoch:10 step:51245[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:10 step:51250[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:10 step:51255[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:10 step:51260[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:10 step:51265[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:10 step:51270[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:10 step:51275[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:10 step:51280[D loss: 1.000005] [G loss: 1.000033]\n",
      "epoch:10 step:51285[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:10 step:51290[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:10 step:51295[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:10 step:51300[D loss: 0.999998] [G loss: 1.000011]\n",
      "epoch:10 step:51305[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:10 step:51310[D loss: 0.999983] [G loss: 1.000021]\n",
      "epoch:10 step:51315[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:10 step:51320[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:10 step:51325[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:10 step:51330[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:10 step:51335[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:10 step:51340[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:10 step:51345[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:10 step:51350[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:10 step:51355[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:10 step:51360[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:10 step:51365[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:10 step:51370[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:10 step:51375[D loss: 1.000015] [G loss: 0.999979]\n",
      "epoch:10 step:51380[D loss: 1.000052] [G loss: 0.999984]\n",
      "epoch:10 step:51385[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:10 step:51390[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:10 step:51395[D loss: 0.999974] [G loss: 1.000016]\n",
      "epoch:10 step:51400[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:10 step:51405[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:10 step:51410[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:10 step:51415[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:10 step:51420[D loss: 1.000018] [G loss: 0.999957]\n",
      "epoch:10 step:51425[D loss: 1.000042] [G loss: 0.999968]\n",
      "epoch:10 step:51430[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:10 step:51435[D loss: 1.000017] [G loss: 1.000058]\n",
      "epoch:10 step:51440[D loss: 0.999947] [G loss: 1.000063]\n",
      "epoch:10 step:51445[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:10 step:51450[D loss: 0.999994] [G loss: 1.000033]\n",
      "epoch:10 step:51455[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:10 step:51460[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:10 step:51465[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:10 step:51470[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:10 step:51475[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:10 step:51480[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:10 step:51485[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:10 step:51490[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:10 step:51495[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:10 step:51500[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:10 step:51505[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:10 step:51510[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:10 step:51515[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:10 step:51520[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:10 step:51525[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:10 step:51530[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:10 step:51535[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:11 step:51540[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:11 step:51545[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:11 step:51550[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:11 step:51555[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:11 step:51560[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:11 step:51565[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:11 step:51570[D loss: 1.000013] [G loss: 1.000029]\n",
      "epoch:11 step:51575[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:11 step:51580[D loss: 1.000012] [G loss: 1.000022]\n",
      "epoch:11 step:51585[D loss: 1.000001] [G loss: 1.000078]\n",
      "epoch:11 step:51590[D loss: 1.000009] [G loss: 1.000037]\n",
      "epoch:11 step:51595[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:11 step:51600[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:11 step:51605[D loss: 1.000012] [G loss: 0.999978]\n",
      "epoch:11 step:51610[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:11 step:51615[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:11 step:51620[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:11 step:51625[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:11 step:51630[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:11 step:51635[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:11 step:51640[D loss: 0.999987] [G loss: 1.000040]\n",
      "epoch:11 step:51645[D loss: 0.999999] [G loss: 1.000047]\n",
      "epoch:11 step:51650[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:11 step:51655[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:11 step:51660[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:11 step:51665[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:11 step:51670[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:11 step:51675[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:11 step:51680[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:11 step:51685[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:11 step:51690[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:11 step:51695[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:11 step:51700[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:11 step:51705[D loss: 1.000019] [G loss: 1.000025]\n",
      "epoch:11 step:51710[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:11 step:51715[D loss: 1.000019] [G loss: 1.000035]\n",
      "epoch:11 step:51720[D loss: 0.999948] [G loss: 1.000131]\n",
      "epoch:11 step:51725[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:11 step:51730[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:11 step:51735[D loss: 1.000018] [G loss: 1.000010]\n",
      "epoch:11 step:51740[D loss: 1.000028] [G loss: 0.999965]\n",
      "epoch:11 step:51745[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:11 step:51750[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:11 step:51755[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:11 step:51760[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:11 step:51765[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:11 step:51770[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:11 step:51775[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:11 step:51780[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:11 step:51785[D loss: 0.999958] [G loss: 1.000056]\n",
      "epoch:11 step:51790[D loss: 0.999968] [G loss: 1.000089]\n",
      "epoch:11 step:51795[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:11 step:51800[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:11 step:51805[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:11 step:51810[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:11 step:51815[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:11 step:51820[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:11 step:51825[D loss: 0.999975] [G loss: 1.000106]\n",
      "epoch:11 step:51830[D loss: 0.999968] [G loss: 1.000119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:51835[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:11 step:51840[D loss: 0.999981] [G loss: 1.000084]\n",
      "epoch:11 step:51845[D loss: 1.000052] [G loss: 0.999971]\n",
      "epoch:11 step:51850[D loss: 1.000029] [G loss: 1.000058]\n",
      "epoch:11 step:51855[D loss: 1.000028] [G loss: 1.000037]\n",
      "epoch:11 step:51860[D loss: 0.999944] [G loss: 1.000083]\n",
      "epoch:11 step:51865[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:11 step:51870[D loss: 0.999964] [G loss: 1.000087]\n",
      "epoch:11 step:51875[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:11 step:51880[D loss: 1.000037] [G loss: 0.999984]\n",
      "epoch:11 step:51885[D loss: 1.000009] [G loss: 1.000021]\n",
      "epoch:11 step:51890[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:11 step:51895[D loss: 0.999984] [G loss: 1.000103]\n",
      "epoch:11 step:51900[D loss: 0.999942] [G loss: 1.000162]\n",
      "epoch:11 step:51905[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:11 step:51910[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:11 step:51915[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:11 step:51920[D loss: 1.000000] [G loss: 1.000044]\n",
      "epoch:11 step:51925[D loss: 0.999970] [G loss: 1.000107]\n",
      "epoch:11 step:51930[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:11 step:51935[D loss: 0.999999] [G loss: 1.000019]\n",
      "epoch:11 step:51940[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:11 step:51945[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:11 step:51950[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:11 step:51955[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:11 step:51960[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:11 step:51965[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:11 step:51970[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:11 step:51975[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:11 step:51980[D loss: 0.999964] [G loss: 1.000115]\n",
      "epoch:11 step:51985[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:11 step:51990[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:11 step:51995[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:11 step:52000[D loss: 1.000007] [G loss: 1.000047]\n",
      "epoch:11 step:52005[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:11 step:52010[D loss: 1.000029] [G loss: 1.000025]\n",
      "epoch:11 step:52015[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:11 step:52020[D loss: 0.999919] [G loss: 1.000210]\n",
      "epoch:11 step:52025[D loss: 0.999981] [G loss: 1.000091]\n",
      "epoch:11 step:52030[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:11 step:52035[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:11 step:52040[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:11 step:52045[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:11 step:52050[D loss: 1.000024] [G loss: 0.999983]\n",
      "epoch:11 step:52055[D loss: 1.000045] [G loss: 0.999962]\n",
      "epoch:11 step:52060[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:11 step:52065[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:11 step:52070[D loss: 1.000007] [G loss: 0.999995]\n",
      "epoch:11 step:52075[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:11 step:52080[D loss: 0.999926] [G loss: 1.000106]\n",
      "epoch:11 step:52085[D loss: 1.000023] [G loss: 1.000063]\n",
      "epoch:11 step:52090[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:11 step:52095[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:11 step:52100[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:11 step:52105[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:11 step:52110[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:11 step:52115[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:11 step:52120[D loss: 1.000008] [G loss: 1.000076]\n",
      "epoch:11 step:52125[D loss: 0.999974] [G loss: 1.000121]\n",
      "epoch:11 step:52130[D loss: 0.999999] [G loss: 1.000141]\n",
      "epoch:11 step:52135[D loss: 0.999893] [G loss: 1.000184]\n",
      "epoch:11 step:52140[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:11 step:52145[D loss: 0.999959] [G loss: 1.000120]\n",
      "epoch:11 step:52150[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:11 step:52155[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:11 step:52160[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:11 step:52165[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:11 step:52170[D loss: 1.000001] [G loss: 1.000056]\n",
      "epoch:11 step:52175[D loss: 0.999996] [G loss: 1.000063]\n",
      "epoch:11 step:52180[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:11 step:52185[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:11 step:52190[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:11 step:52195[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:11 step:52200[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:11 step:52205[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:11 step:52210[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:11 step:52215[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:11 step:52220[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:11 step:52225[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:11 step:52230[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:11 step:52235[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:11 step:52240[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:11 step:52245[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:11 step:52250[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:11 step:52255[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:11 step:52260[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:11 step:52265[D loss: 0.999938] [G loss: 1.000101]\n",
      "epoch:11 step:52270[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:11 step:52275[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:11 step:52280[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:11 step:52285[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:11 step:52290[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:11 step:52295[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:11 step:52300[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:11 step:52305[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:11 step:52310[D loss: 0.999989] [G loss: 1.000062]\n",
      "epoch:11 step:52315[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:11 step:52320[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:11 step:52325[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:11 step:52330[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:11 step:52335[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:11 step:52340[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:11 step:52345[D loss: 0.999986] [G loss: 1.000101]\n",
      "epoch:11 step:52350[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:11 step:52355[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:11 step:52360[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:11 step:52365[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:11 step:52370[D loss: 0.999981] [G loss: 1.000016]\n",
      "epoch:11 step:52375[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:11 step:52380[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:11 step:52385[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:11 step:52390[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:11 step:52395[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:11 step:52400[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:11 step:52405[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:11 step:52410[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:11 step:52415[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:11 step:52420[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:11 step:52425[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:11 step:52430[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:11 step:52435[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:11 step:52440[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:11 step:52445[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:11 step:52450[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:11 step:52455[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:11 step:52460[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:11 step:52465[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:11 step:52470[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:11 step:52475[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:11 step:52480[D loss: 0.999947] [G loss: 1.000080]\n",
      "epoch:11 step:52485[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:52490[D loss: 0.999997] [G loss: 1.000027]\n",
      "epoch:11 step:52495[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:11 step:52500[D loss: 1.000003] [G loss: 1.000054]\n",
      "epoch:11 step:52505[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:11 step:52510[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:11 step:52515[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:11 step:52520[D loss: 1.000015] [G loss: 1.000033]\n",
      "epoch:11 step:52525[D loss: 1.000040] [G loss: 1.000036]\n",
      "epoch:11 step:52530[D loss: 0.999927] [G loss: 1.000123]\n",
      "epoch:11 step:52535[D loss: 1.000055] [G loss: 0.999986]\n",
      "epoch:11 step:52540[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:11 step:52545[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:11 step:52550[D loss: 0.999972] [G loss: 1.000052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:52555[D loss: 1.000001] [G loss: 1.000030]\n",
      "epoch:11 step:52560[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:11 step:52565[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:11 step:52570[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:11 step:52575[D loss: 0.999925] [G loss: 1.000068]\n",
      "epoch:11 step:52580[D loss: 1.000019] [G loss: 1.000057]\n",
      "epoch:11 step:52585[D loss: 0.999900] [G loss: 1.000149]\n",
      "epoch:11 step:52590[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:11 step:52595[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:11 step:52600[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:11 step:52605[D loss: 0.999974] [G loss: 1.000111]\n",
      "epoch:11 step:52610[D loss: 0.999999] [G loss: 1.000070]\n",
      "epoch:11 step:52615[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:11 step:52620[D loss: 1.000039] [G loss: 1.000067]\n",
      "epoch:11 step:52625[D loss: 1.000019] [G loss: 1.000023]\n",
      "epoch:11 step:52630[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:11 step:52635[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:11 step:52640[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:11 step:52645[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:11 step:52650[D loss: 1.000011] [G loss: 0.999992]\n",
      "epoch:11 step:52655[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:11 step:52660[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:11 step:52665[D loss: 1.000027] [G loss: 1.000023]\n",
      "epoch:11 step:52670[D loss: 1.000058] [G loss: 0.999957]\n",
      "epoch:11 step:52675[D loss: 0.999967] [G loss: 1.000025]\n",
      "epoch:11 step:52680[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:11 step:52685[D loss: 1.000011] [G loss: 1.000036]\n",
      "epoch:11 step:52690[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:11 step:52695[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:11 step:52700[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:11 step:52705[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:11 step:52710[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:11 step:52715[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:11 step:52720[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:11 step:52725[D loss: 0.999994] [G loss: 0.999998]\n",
      "epoch:11 step:52730[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:11 step:52735[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:11 step:52740[D loss: 0.999960] [G loss: 1.000104]\n",
      "epoch:11 step:52745[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:11 step:52750[D loss: 0.999951] [G loss: 1.000081]\n",
      "epoch:11 step:52755[D loss: 0.999954] [G loss: 1.000103]\n",
      "epoch:11 step:52760[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:11 step:52765[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:11 step:52770[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:11 step:52775[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:11 step:52780[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:11 step:52785[D loss: 0.999974] [G loss: 1.000036]\n",
      "epoch:11 step:52790[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:11 step:52795[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:11 step:52800[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:11 step:52805[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:11 step:52810[D loss: 1.000030] [G loss: 0.999985]\n",
      "epoch:11 step:52815[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:11 step:52820[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:11 step:52825[D loss: 1.000039] [G loss: 1.000000]\n",
      "epoch:11 step:52830[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:11 step:52835[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:11 step:52840[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:11 step:52845[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:11 step:52850[D loss: 1.000025] [G loss: 1.000028]\n",
      "epoch:11 step:52855[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:11 step:52860[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:11 step:52865[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:11 step:52870[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:11 step:52875[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:11 step:52880[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:11 step:52885[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:11 step:52890[D loss: 0.999945] [G loss: 1.000077]\n",
      "epoch:11 step:52895[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:11 step:52900[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:11 step:52905[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:11 step:52910[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:11 step:52915[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:11 step:52920[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:11 step:52925[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:11 step:52930[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:11 step:52935[D loss: 0.999921] [G loss: 1.000118]\n",
      "epoch:11 step:52940[D loss: 1.000012] [G loss: 1.000008]\n",
      "epoch:11 step:52945[D loss: 1.000024] [G loss: 0.999960]\n",
      "epoch:11 step:52950[D loss: 0.999944] [G loss: 1.000103]\n",
      "epoch:11 step:52955[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:11 step:52960[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:11 step:52965[D loss: 0.999949] [G loss: 1.000062]\n",
      "epoch:11 step:52970[D loss: 0.999962] [G loss: 1.000040]\n",
      "epoch:11 step:52975[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:11 step:52980[D loss: 1.000001] [G loss: 1.000061]\n",
      "epoch:11 step:52985[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:11 step:52990[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:11 step:52995[D loss: 0.999984] [G loss: 1.000025]\n",
      "epoch:11 step:53000[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:11 step:53005[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:11 step:53010[D loss: 0.999941] [G loss: 1.000133]\n",
      "epoch:11 step:53015[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:11 step:53020[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:11 step:53025[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:11 step:53030[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:11 step:53035[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:11 step:53040[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:11 step:53045[D loss: 0.999992] [G loss: 1.000009]\n",
      "epoch:11 step:53050[D loss: 1.000006] [G loss: 1.000058]\n",
      "epoch:11 step:53055[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:11 step:53060[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:11 step:53065[D loss: 1.000004] [G loss: 1.000071]\n",
      "epoch:11 step:53070[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:11 step:53075[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:11 step:53080[D loss: 1.000003] [G loss: 1.000029]\n",
      "epoch:11 step:53085[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:11 step:53090[D loss: 1.000033] [G loss: 0.999994]\n",
      "epoch:11 step:53095[D loss: 0.999976] [G loss: 1.000005]\n",
      "epoch:11 step:53100[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:11 step:53105[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:11 step:53110[D loss: 0.999985] [G loss: 1.000120]\n",
      "epoch:11 step:53115[D loss: 1.000014] [G loss: 1.000101]\n",
      "epoch:11 step:53120[D loss: 0.999953] [G loss: 1.000026]\n",
      "epoch:11 step:53125[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:11 step:53130[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:11 step:53135[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:11 step:53140[D loss: 1.000040] [G loss: 1.000023]\n",
      "epoch:11 step:53145[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:11 step:53150[D loss: 1.000010] [G loss: 1.000053]\n",
      "epoch:11 step:53155[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:11 step:53160[D loss: 0.999971] [G loss: 1.000040]\n",
      "epoch:11 step:53165[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:11 step:53170[D loss: 0.999996] [G loss: 1.000016]\n",
      "epoch:11 step:53175[D loss: 0.999973] [G loss: 1.000026]\n",
      "epoch:11 step:53180[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:11 step:53185[D loss: 1.000036] [G loss: 0.999992]\n",
      "epoch:11 step:53190[D loss: 0.999946] [G loss: 1.000066]\n",
      "epoch:11 step:53195[D loss: 0.999929] [G loss: 1.000102]\n",
      "epoch:11 step:53200[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:11 step:53205[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:11 step:53210[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:11 step:53215[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:11 step:53220[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:11 step:53225[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:11 step:53230[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:11 step:53235[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:11 step:53240[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:11 step:53245[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:11 step:53250[D loss: 0.999999] [G loss: 1.000001]\n",
      "epoch:11 step:53255[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:11 step:53260[D loss: 0.999952] [G loss: 1.000074]\n",
      "epoch:11 step:53265[D loss: 0.999983] [G loss: 1.000113]\n",
      "epoch:11 step:53270[D loss: 0.999965] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:53275[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:11 step:53280[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:11 step:53285[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:11 step:53290[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:11 step:53295[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:11 step:53300[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:11 step:53305[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:11 step:53310[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:11 step:53315[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:11 step:53320[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:11 step:53325[D loss: 1.000021] [G loss: 1.000043]\n",
      "epoch:11 step:53330[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:11 step:53335[D loss: 0.999983] [G loss: 1.000089]\n",
      "epoch:11 step:53340[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:11 step:53345[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:11 step:53350[D loss: 1.000016] [G loss: 1.000049]\n",
      "epoch:11 step:53355[D loss: 1.000016] [G loss: 1.000105]\n",
      "epoch:11 step:53360[D loss: 0.999929] [G loss: 1.000150]\n",
      "epoch:11 step:53365[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:11 step:53370[D loss: 0.999973] [G loss: 1.000131]\n",
      "epoch:11 step:53375[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:11 step:53380[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:11 step:53385[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:11 step:53390[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:11 step:53395[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:11 step:53400[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:11 step:53405[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:11 step:53410[D loss: 1.000001] [G loss: 1.000069]\n",
      "epoch:11 step:53415[D loss: 0.999967] [G loss: 1.000038]\n",
      "epoch:11 step:53420[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:11 step:53425[D loss: 1.000008] [G loss: 1.000130]\n",
      "epoch:11 step:53430[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:11 step:53435[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:11 step:53440[D loss: 1.000001] [G loss: 1.000010]\n",
      "epoch:11 step:53445[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:11 step:53450[D loss: 1.000000] [G loss: 1.000089]\n",
      "epoch:11 step:53455[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:11 step:53460[D loss: 1.000037] [G loss: 1.000038]\n",
      "epoch:11 step:53465[D loss: 0.999947] [G loss: 1.000085]\n",
      "epoch:11 step:53470[D loss: 0.999974] [G loss: 1.000104]\n",
      "epoch:11 step:53475[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:11 step:53480[D loss: 1.000003] [G loss: 1.000050]\n",
      "epoch:11 step:53485[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:11 step:53490[D loss: 1.000013] [G loss: 1.000001]\n",
      "epoch:11 step:53495[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:11 step:53500[D loss: 0.999964] [G loss: 1.000042]\n",
      "epoch:11 step:53505[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:11 step:53510[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:11 step:53515[D loss: 1.000002] [G loss: 1.000061]\n",
      "epoch:11 step:53520[D loss: 0.999977] [G loss: 1.000039]\n",
      "epoch:11 step:53525[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:11 step:53530[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:11 step:53535[D loss: 0.999943] [G loss: 1.000113]\n",
      "epoch:11 step:53540[D loss: 0.999996] [G loss: 1.000066]\n",
      "epoch:11 step:53545[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:11 step:53550[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:11 step:53555[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:11 step:53560[D loss: 0.999982] [G loss: 1.000101]\n",
      "epoch:11 step:53565[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:11 step:53570[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:11 step:53575[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:11 step:53580[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:11 step:53585[D loss: 0.999979] [G loss: 1.000117]\n",
      "epoch:11 step:53590[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:11 step:53595[D loss: 1.000022] [G loss: 1.000056]\n",
      "epoch:11 step:53600[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:11 step:53605[D loss: 0.999941] [G loss: 1.000118]\n",
      "epoch:11 step:53610[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:11 step:53615[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:11 step:53620[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:11 step:53625[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:11 step:53630[D loss: 0.999956] [G loss: 1.000075]\n",
      "epoch:11 step:53635[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:11 step:53640[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:11 step:53645[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:11 step:53650[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:11 step:53655[D loss: 1.000000] [G loss: 1.000032]\n",
      "epoch:11 step:53660[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:11 step:53665[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:11 step:53670[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:11 step:53675[D loss: 0.999991] [G loss: 1.000008]\n",
      "epoch:11 step:53680[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:11 step:53685[D loss: 0.999999] [G loss: 1.000053]\n",
      "epoch:11 step:53690[D loss: 0.999943] [G loss: 1.000099]\n",
      "epoch:11 step:53695[D loss: 1.000036] [G loss: 0.999968]\n",
      "epoch:11 step:53700[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:11 step:53705[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:11 step:53710[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:11 step:53715[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:11 step:53720[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:11 step:53725[D loss: 0.999979] [G loss: 1.000083]\n",
      "epoch:11 step:53730[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:11 step:53735[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:11 step:53740[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:11 step:53745[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:11 step:53750[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:11 step:53755[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:11 step:53760[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:11 step:53765[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:11 step:53770[D loss: 1.000021] [G loss: 0.999985]\n",
      "epoch:11 step:53775[D loss: 1.000053] [G loss: 0.999944]\n",
      "epoch:11 step:53780[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:11 step:53785[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:11 step:53790[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:11 step:53795[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:11 step:53800[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:11 step:53805[D loss: 1.000008] [G loss: 1.000024]\n",
      "epoch:11 step:53810[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:11 step:53815[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:11 step:53820[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:11 step:53825[D loss: 1.000008] [G loss: 1.000083]\n",
      "epoch:11 step:53830[D loss: 1.000046] [G loss: 1.000134]\n",
      "epoch:11 step:53835[D loss: 0.999917] [G loss: 1.000154]\n",
      "epoch:11 step:53840[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:11 step:53845[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:11 step:53850[D loss: 0.999992] [G loss: 1.000006]\n",
      "epoch:11 step:53855[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:11 step:53860[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:11 step:53865[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:11 step:53870[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:11 step:53875[D loss: 1.000039] [G loss: 0.999991]\n",
      "epoch:11 step:53880[D loss: 0.999952] [G loss: 1.000153]\n",
      "epoch:11 step:53885[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:11 step:53890[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:11 step:53895[D loss: 1.000008] [G loss: 0.999994]\n",
      "epoch:11 step:53900[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:11 step:53905[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:11 step:53910[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:11 step:53915[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:11 step:53920[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:11 step:53925[D loss: 1.000018] [G loss: 1.000048]\n",
      "epoch:11 step:53930[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:11 step:53935[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:11 step:53940[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:11 step:53945[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:11 step:53950[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:11 step:53955[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:11 step:53960[D loss: 1.000029] [G loss: 1.000040]\n",
      "epoch:11 step:53965[D loss: 0.999942] [G loss: 1.000110]\n",
      "epoch:11 step:53970[D loss: 0.999954] [G loss: 1.000133]\n",
      "epoch:11 step:53975[D loss: 0.999996] [G loss: 1.000099]\n",
      "epoch:11 step:53980[D loss: 0.999990] [G loss: 1.000095]\n",
      "epoch:11 step:53985[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:11 step:53990[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:11 step:53995[D loss: 0.999978] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:54000[D loss: 0.999980] [G loss: 1.000116]\n",
      "epoch:11 step:54005[D loss: 0.999998] [G loss: 1.000059]\n",
      "epoch:11 step:54010[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:11 step:54015[D loss: 1.000022] [G loss: 1.000116]\n",
      "epoch:11 step:54020[D loss: 0.999989] [G loss: 1.000099]\n",
      "epoch:11 step:54025[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:11 step:54030[D loss: 0.999999] [G loss: 0.999990]\n",
      "epoch:11 step:54035[D loss: 1.000013] [G loss: 1.000048]\n",
      "epoch:11 step:54040[D loss: 0.999942] [G loss: 1.000079]\n",
      "epoch:11 step:54045[D loss: 0.999984] [G loss: 1.000016]\n",
      "epoch:11 step:54050[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:11 step:54055[D loss: 1.000008] [G loss: 1.000017]\n",
      "epoch:11 step:54060[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:11 step:54065[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:11 step:54070[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:11 step:54075[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:11 step:54080[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:11 step:54085[D loss: 1.000021] [G loss: 1.000051]\n",
      "epoch:11 step:54090[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:11 step:54095[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:11 step:54100[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:11 step:54105[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:11 step:54110[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:11 step:54115[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:11 step:54120[D loss: 1.000050] [G loss: 0.999975]\n",
      "epoch:11 step:54125[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:11 step:54130[D loss: 0.999982] [G loss: 1.000092]\n",
      "epoch:11 step:54135[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:11 step:54140[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:11 step:54145[D loss: 1.000013] [G loss: 1.000011]\n",
      "epoch:11 step:54150[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:54155[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:11 step:54160[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:11 step:54165[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:11 step:54170[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:11 step:54175[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:11 step:54180[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:11 step:54185[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:11 step:54190[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:11 step:54195[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:11 step:54200[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:11 step:54205[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:11 step:54210[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:11 step:54215[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:11 step:54220[D loss: 1.000014] [G loss: 1.000024]\n",
      "epoch:11 step:54225[D loss: 0.999944] [G loss: 1.000128]\n",
      "epoch:11 step:54230[D loss: 1.000029] [G loss: 0.999964]\n",
      "epoch:11 step:54235[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:11 step:54240[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:11 step:54245[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:11 step:54250[D loss: 1.000051] [G loss: 0.999955]\n",
      "epoch:11 step:54255[D loss: 0.999968] [G loss: 1.000123]\n",
      "epoch:11 step:54260[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:11 step:54265[D loss: 0.999963] [G loss: 1.000118]\n",
      "epoch:11 step:54270[D loss: 0.999937] [G loss: 1.000082]\n",
      "epoch:11 step:54275[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:11 step:54280[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:54285[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:11 step:54290[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:11 step:54295[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:11 step:54300[D loss: 1.000022] [G loss: 1.000064]\n",
      "epoch:11 step:54305[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:11 step:54310[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:11 step:54315[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:11 step:54320[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:11 step:54325[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:11 step:54330[D loss: 0.999985] [G loss: 1.000093]\n",
      "epoch:11 step:54335[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:11 step:54340[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:11 step:54345[D loss: 0.999981] [G loss: 0.999994]\n",
      "epoch:11 step:54350[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:11 step:54355[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:11 step:54360[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:11 step:54365[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:11 step:54370[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:11 step:54375[D loss: 1.000019] [G loss: 1.000000]\n",
      "epoch:11 step:54380[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:11 step:54385[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:11 step:54390[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:11 step:54395[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:11 step:54400[D loss: 1.000042] [G loss: 0.999982]\n",
      "epoch:11 step:54405[D loss: 0.999938] [G loss: 1.000108]\n",
      "epoch:11 step:54410[D loss: 0.999993] [G loss: 1.000114]\n",
      "epoch:11 step:54415[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:11 step:54420[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:11 step:54425[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:11 step:54430[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:11 step:54435[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:11 step:54440[D loss: 0.999996] [G loss: 1.000055]\n",
      "epoch:11 step:54445[D loss: 1.000005] [G loss: 1.000021]\n",
      "epoch:11 step:54450[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:11 step:54455[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:11 step:54460[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:11 step:54465[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:11 step:54470[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:11 step:54475[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:11 step:54480[D loss: 1.000027] [G loss: 1.000067]\n",
      "epoch:11 step:54485[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:11 step:54490[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:11 step:54495[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:11 step:54500[D loss: 1.000040] [G loss: 1.000038]\n",
      "epoch:11 step:54505[D loss: 1.000014] [G loss: 1.000044]\n",
      "epoch:11 step:54510[D loss: 0.999982] [G loss: 1.000181]\n",
      "epoch:11 step:54515[D loss: 0.999895] [G loss: 1.000177]\n",
      "epoch:11 step:54520[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:11 step:54525[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:11 step:54530[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:11 step:54535[D loss: 1.000003] [G loss: 1.000053]\n",
      "epoch:11 step:54540[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:11 step:54545[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:11 step:54550[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:11 step:54555[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:11 step:54560[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:11 step:54565[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:11 step:54570[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:11 step:54575[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:11 step:54580[D loss: 1.000034] [G loss: 1.000059]\n",
      "epoch:11 step:54585[D loss: 0.999955] [G loss: 1.000049]\n",
      "epoch:11 step:54590[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:11 step:54595[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:54600[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:11 step:54605[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:11 step:54610[D loss: 0.999969] [G loss: 1.000042]\n",
      "epoch:11 step:54615[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:11 step:54620[D loss: 1.000004] [G loss: 1.000064]\n",
      "epoch:11 step:54625[D loss: 0.999962] [G loss: 1.000121]\n",
      "epoch:11 step:54630[D loss: 0.999974] [G loss: 1.000029]\n",
      "epoch:11 step:54635[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:11 step:54640[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:11 step:54645[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:11 step:54650[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:11 step:54655[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:11 step:54660[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:11 step:54665[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:11 step:54670[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:11 step:54675[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:11 step:54680[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:11 step:54685[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:11 step:54690[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:11 step:54695[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:11 step:54700[D loss: 0.999993] [G loss: 1.000043]\n",
      "epoch:11 step:54705[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:11 step:54710[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:11 step:54715[D loss: 0.999969] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:54720[D loss: 1.000029] [G loss: 0.999989]\n",
      "epoch:11 step:54725[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:11 step:54730[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:11 step:54735[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:11 step:54740[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:11 step:54745[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:11 step:54750[D loss: 0.999998] [G loss: 1.000006]\n",
      "epoch:11 step:54755[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:11 step:54760[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:11 step:54765[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:11 step:54770[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:11 step:54775[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:11 step:54780[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:11 step:54785[D loss: 0.999946] [G loss: 1.000089]\n",
      "epoch:11 step:54790[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:11 step:54795[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:11 step:54800[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:11 step:54805[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:11 step:54810[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:11 step:54815[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:11 step:54820[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:11 step:54825[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:11 step:54830[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:11 step:54835[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:11 step:54840[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:11 step:54845[D loss: 1.000001] [G loss: 1.000102]\n",
      "epoch:11 step:54850[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:11 step:54855[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:11 step:54860[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:11 step:54865[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:11 step:54870[D loss: 0.999979] [G loss: 0.999990]\n",
      "epoch:11 step:54875[D loss: 0.999994] [G loss: 1.000056]\n",
      "epoch:11 step:54880[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:11 step:54885[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:11 step:54890[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:11 step:54895[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:11 step:54900[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:11 step:54905[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:11 step:54910[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:11 step:54915[D loss: 1.000001] [G loss: 1.000009]\n",
      "epoch:11 step:54920[D loss: 0.999997] [G loss: 1.000035]\n",
      "epoch:11 step:54925[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:11 step:54930[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:11 step:54935[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:11 step:54940[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:11 step:54945[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:11 step:54950[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:11 step:54955[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:11 step:54960[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:11 step:54965[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:11 step:54970[D loss: 0.999964] [G loss: 1.000051]\n",
      "epoch:11 step:54975[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:11 step:54980[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:11 step:54985[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:11 step:54990[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:11 step:54995[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:55000[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:11 step:55005[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:11 step:55010[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:11 step:55015[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:11 step:55020[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:11 step:55025[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:11 step:55030[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:11 step:55035[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:11 step:55040[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:11 step:55045[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:11 step:55050[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:11 step:55055[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:11 step:55060[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:11 step:55065[D loss: 0.999963] [G loss: 1.000115]\n",
      "epoch:11 step:55070[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:11 step:55075[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:11 step:55080[D loss: 1.000034] [G loss: 1.000031]\n",
      "epoch:11 step:55085[D loss: 1.000012] [G loss: 1.000053]\n",
      "epoch:11 step:55090[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:11 step:55095[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:11 step:55100[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:11 step:55105[D loss: 0.999971] [G loss: 1.000149]\n",
      "epoch:11 step:55110[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:11 step:55115[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:11 step:55120[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:11 step:55125[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:11 step:55130[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:11 step:55135[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:11 step:55140[D loss: 0.999978] [G loss: 1.000102]\n",
      "epoch:11 step:55145[D loss: 0.999972] [G loss: 1.000139]\n",
      "epoch:11 step:55150[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:11 step:55155[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:11 step:55160[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:11 step:55165[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:11 step:55170[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:11 step:55175[D loss: 1.000011] [G loss: 1.000048]\n",
      "epoch:11 step:55180[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:11 step:55185[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:11 step:55190[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:11 step:55195[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:11 step:55200[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:11 step:55205[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:11 step:55210[D loss: 0.999993] [G loss: 1.000076]\n",
      "epoch:11 step:55215[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:11 step:55220[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:11 step:55225[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:11 step:55230[D loss: 0.999978] [G loss: 1.000095]\n",
      "epoch:11 step:55235[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:11 step:55240[D loss: 0.999962] [G loss: 1.000114]\n",
      "epoch:11 step:55245[D loss: 1.000073] [G loss: 0.999986]\n",
      "epoch:11 step:55250[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:11 step:55255[D loss: 0.999968] [G loss: 1.000032]\n",
      "epoch:11 step:55260[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:11 step:55265[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:11 step:55270[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:11 step:55275[D loss: 0.999987] [G loss: 1.000076]\n",
      "epoch:11 step:55280[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:11 step:55285[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:11 step:55290[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:11 step:55295[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:11 step:55300[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:11 step:55305[D loss: 1.000006] [G loss: 1.000071]\n",
      "epoch:11 step:55310[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:11 step:55315[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:11 step:55320[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:11 step:55325[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:11 step:55330[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:11 step:55335[D loss: 0.999997] [G loss: 1.000018]\n",
      "epoch:11 step:55340[D loss: 0.999976] [G loss: 1.000091]\n",
      "epoch:11 step:55345[D loss: 0.999968] [G loss: 1.000130]\n",
      "epoch:11 step:55350[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:11 step:55355[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:11 step:55360[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:11 step:55365[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:11 step:55370[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:11 step:55375[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:11 step:55380[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:11 step:55385[D loss: 0.999998] [G loss: 1.000013]\n",
      "epoch:11 step:55390[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:11 step:55395[D loss: 1.000023] [G loss: 0.999990]\n",
      "epoch:11 step:55400[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:11 step:55405[D loss: 0.999975] [G loss: 1.000106]\n",
      "epoch:11 step:55410[D loss: 0.999963] [G loss: 1.000042]\n",
      "epoch:11 step:55415[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:11 step:55420[D loss: 1.000006] [G loss: 1.000009]\n",
      "epoch:11 step:55425[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:11 step:55430[D loss: 1.000029] [G loss: 1.000025]\n",
      "epoch:11 step:55435[D loss: 0.999993] [G loss: 1.000051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:55440[D loss: 0.999950] [G loss: 1.000047]\n",
      "epoch:11 step:55445[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:55450[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:11 step:55455[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:11 step:55460[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:11 step:55465[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:11 step:55470[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:11 step:55475[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:11 step:55480[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:11 step:55485[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:11 step:55490[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:11 step:55495[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:11 step:55500[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:55505[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:11 step:55510[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:11 step:55515[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:11 step:55520[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:11 step:55525[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:11 step:55530[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:11 step:55535[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:11 step:55540[D loss: 1.000031] [G loss: 0.999976]\n",
      "epoch:11 step:55545[D loss: 1.000008] [G loss: 0.999982]\n",
      "epoch:11 step:55550[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:11 step:55555[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:11 step:55560[D loss: 0.999975] [G loss: 1.000106]\n",
      "epoch:11 step:55565[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:11 step:55570[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:11 step:55575[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:11 step:55580[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:11 step:55585[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:11 step:55590[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:11 step:55595[D loss: 1.000002] [G loss: 0.999988]\n",
      "epoch:11 step:55600[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:11 step:55605[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:11 step:55610[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:11 step:55615[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:11 step:55620[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:11 step:55625[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:11 step:55630[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:11 step:55635[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:11 step:55640[D loss: 1.000004] [G loss: 1.000005]\n",
      "epoch:11 step:55645[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:11 step:55650[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:11 step:55655[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:11 step:55660[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:11 step:55665[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:11 step:55670[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:11 step:55675[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:11 step:55680[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:11 step:55685[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:11 step:55690[D loss: 0.999996] [G loss: 0.999999]\n",
      "epoch:11 step:55695[D loss: 1.000027] [G loss: 1.000024]\n",
      "epoch:11 step:55700[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:11 step:55705[D loss: 0.999997] [G loss: 1.000073]\n",
      "epoch:11 step:55710[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:11 step:55715[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:11 step:55720[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:11 step:55725[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:11 step:55730[D loss: 0.999984] [G loss: 1.000104]\n",
      "epoch:11 step:55735[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:11 step:55740[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:11 step:55745[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:11 step:55750[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:11 step:55755[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:11 step:55760[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:11 step:55765[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:11 step:55770[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:11 step:55775[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:11 step:55780[D loss: 1.000002] [G loss: 1.000038]\n",
      "epoch:11 step:55785[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:11 step:55790[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:11 step:55795[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:11 step:55800[D loss: 1.000001] [G loss: 1.000023]\n",
      "epoch:11 step:55805[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:11 step:55810[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:11 step:55815[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:11 step:55820[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:11 step:55825[D loss: 0.999977] [G loss: 1.000042]\n",
      "epoch:11 step:55830[D loss: 1.000064] [G loss: 0.999954]\n",
      "epoch:11 step:55835[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:11 step:55840[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:11 step:55845[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:11 step:55850[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:11 step:55855[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:11 step:55860[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:11 step:55865[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:11 step:55870[D loss: 0.999999] [G loss: 1.000023]\n",
      "epoch:11 step:55875[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:11 step:55880[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:11 step:55885[D loss: 1.000050] [G loss: 0.999992]\n",
      "epoch:11 step:55890[D loss: 0.999916] [G loss: 1.000098]\n",
      "epoch:11 step:55895[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:11 step:55900[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:11 step:55905[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:11 step:55910[D loss: 1.000019] [G loss: 0.999976]\n",
      "epoch:11 step:55915[D loss: 0.999951] [G loss: 1.000116]\n",
      "epoch:11 step:55920[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:11 step:55925[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:11 step:55930[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:11 step:55935[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:11 step:55940[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:11 step:55945[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:11 step:55950[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:11 step:55955[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:11 step:55960[D loss: 1.000040] [G loss: 1.000028]\n",
      "epoch:11 step:55965[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:11 step:55970[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:11 step:55975[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:11 step:55980[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:11 step:55985[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:11 step:55990[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:11 step:55995[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:11 step:56000[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:11 step:56005[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:11 step:56010[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:11 step:56015[D loss: 1.000063] [G loss: 0.999945]\n",
      "epoch:11 step:56020[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:11 step:56025[D loss: 0.999974] [G loss: 1.000025]\n",
      "epoch:11 step:56030[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:11 step:56035[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:11 step:56040[D loss: 0.999976] [G loss: 1.000111]\n",
      "epoch:11 step:56045[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:11 step:56050[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:11 step:56055[D loss: 1.000022] [G loss: 1.000075]\n",
      "epoch:11 step:56060[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:11 step:56065[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:11 step:56070[D loss: 0.999969] [G loss: 1.000024]\n",
      "epoch:11 step:56075[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:11 step:56080[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:11 step:56085[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:11 step:56090[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:11 step:56095[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:11 step:56100[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:11 step:56105[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:11 step:56110[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:11 step:56115[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:11 step:56120[D loss: 0.999952] [G loss: 1.000137]\n",
      "epoch:11 step:56125[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:11 step:56130[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:11 step:56135[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:11 step:56140[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:11 step:56145[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:11 step:56150[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:11 step:56155[D loss: 0.999987] [G loss: 1.000035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:56160[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:11 step:56165[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:11 step:56170[D loss: 0.999980] [G loss: 1.000041]\n",
      "epoch:11 step:56175[D loss: 0.999997] [G loss: 1.000017]\n",
      "epoch:11 step:56180[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:11 step:56185[D loss: 0.999961] [G loss: 1.000068]\n",
      "epoch:11 step:56190[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:11 step:56195[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:11 step:56200[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:11 step:56205[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:11 step:56210[D loss: 0.999994] [G loss: 1.000061]\n",
      "epoch:11 step:56215[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:11 step:56220[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:12 step:56225[D loss: 1.000026] [G loss: 1.000009]\n",
      "epoch:12 step:56230[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:12 step:56235[D loss: 1.000015] [G loss: 0.999988]\n",
      "epoch:12 step:56240[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:12 step:56245[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:12 step:56250[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:12 step:56255[D loss: 1.000010] [G loss: 1.000036]\n",
      "epoch:12 step:56260[D loss: 0.999989] [G loss: 1.000059]\n",
      "epoch:12 step:56265[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:12 step:56270[D loss: 0.999999] [G loss: 1.000103]\n",
      "epoch:12 step:56275[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:12 step:56280[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:12 step:56285[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:12 step:56290[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:12 step:56295[D loss: 1.000002] [G loss: 1.000018]\n",
      "epoch:12 step:56300[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:12 step:56305[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:12 step:56310[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:12 step:56315[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:12 step:56320[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:12 step:56325[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:12 step:56330[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:12 step:56335[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:12 step:56340[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:12 step:56345[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:12 step:56350[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:12 step:56355[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:12 step:56360[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:12 step:56365[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:12 step:56370[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:12 step:56375[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:12 step:56380[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:12 step:56385[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:12 step:56390[D loss: 0.999966] [G loss: 1.000108]\n",
      "epoch:12 step:56395[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:12 step:56400[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:12 step:56405[D loss: 0.999925] [G loss: 1.000215]\n",
      "epoch:12 step:56410[D loss: 0.999951] [G loss: 1.000102]\n",
      "epoch:12 step:56415[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:12 step:56420[D loss: 1.000047] [G loss: 0.999938]\n",
      "epoch:12 step:56425[D loss: 1.000036] [G loss: 0.999961]\n",
      "epoch:12 step:56430[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:12 step:56435[D loss: 0.999921] [G loss: 1.000178]\n",
      "epoch:12 step:56440[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:12 step:56445[D loss: 0.999943] [G loss: 1.000126]\n",
      "epoch:12 step:56450[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:12 step:56455[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:12 step:56460[D loss: 0.999986] [G loss: 1.000004]\n",
      "epoch:12 step:56465[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:12 step:56470[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:12 step:56475[D loss: 1.000007] [G loss: 1.000033]\n",
      "epoch:12 step:56480[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:12 step:56485[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:12 step:56490[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:12 step:56495[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:12 step:56500[D loss: 0.999955] [G loss: 1.000103]\n",
      "epoch:12 step:56505[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:12 step:56510[D loss: 0.999984] [G loss: 1.000114]\n",
      "epoch:12 step:56515[D loss: 0.999964] [G loss: 1.000121]\n",
      "epoch:12 step:56520[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:12 step:56525[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:12 step:56530[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:12 step:56535[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:12 step:56540[D loss: 1.000049] [G loss: 0.999996]\n",
      "epoch:12 step:56545[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:12 step:56550[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:12 step:56555[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:12 step:56560[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:12 step:56565[D loss: 1.000020] [G loss: 1.000074]\n",
      "epoch:12 step:56570[D loss: 1.000002] [G loss: 1.000013]\n",
      "epoch:12 step:56575[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:12 step:56580[D loss: 1.000006] [G loss: 1.000049]\n",
      "epoch:12 step:56585[D loss: 1.000010] [G loss: 1.000045]\n",
      "epoch:12 step:56590[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:12 step:56595[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:12 step:56600[D loss: 0.999973] [G loss: 1.000028]\n",
      "epoch:12 step:56605[D loss: 0.999958] [G loss: 1.000111]\n",
      "epoch:12 step:56610[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:12 step:56615[D loss: 1.000013] [G loss: 1.000017]\n",
      "epoch:12 step:56620[D loss: 0.999982] [G loss: 1.000008]\n",
      "epoch:12 step:56625[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:12 step:56630[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:12 step:56635[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:12 step:56640[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:12 step:56645[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:12 step:56650[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:12 step:56655[D loss: 1.000007] [G loss: 1.000000]\n",
      "epoch:12 step:56660[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:12 step:56665[D loss: 1.000023] [G loss: 1.000047]\n",
      "epoch:12 step:56670[D loss: 0.999995] [G loss: 0.999989]\n",
      "epoch:12 step:56675[D loss: 0.999939] [G loss: 1.000084]\n",
      "epoch:12 step:56680[D loss: 0.999951] [G loss: 1.000079]\n",
      "epoch:12 step:56685[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:12 step:56690[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:12 step:56695[D loss: 1.000037] [G loss: 0.999960]\n",
      "epoch:12 step:56700[D loss: 1.000014] [G loss: 1.000049]\n",
      "epoch:12 step:56705[D loss: 0.999932] [G loss: 1.000152]\n",
      "epoch:12 step:56710[D loss: 0.999969] [G loss: 1.000128]\n",
      "epoch:12 step:56715[D loss: 0.999944] [G loss: 1.000103]\n",
      "epoch:12 step:56720[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:12 step:56725[D loss: 0.999991] [G loss: 1.000004]\n",
      "epoch:12 step:56730[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:12 step:56735[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:12 step:56740[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:12 step:56745[D loss: 1.000017] [G loss: 1.000003]\n",
      "epoch:12 step:56750[D loss: 0.999933] [G loss: 1.000120]\n",
      "epoch:12 step:56755[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:12 step:56760[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:12 step:56765[D loss: 0.999955] [G loss: 1.000063]\n",
      "epoch:12 step:56770[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:12 step:56775[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:12 step:56780[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:12 step:56785[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:12 step:56790[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:12 step:56795[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:12 step:56800[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:12 step:56805[D loss: 0.999973] [G loss: 1.000173]\n",
      "epoch:12 step:56810[D loss: 0.999978] [G loss: 1.000119]\n",
      "epoch:12 step:56815[D loss: 1.000020] [G loss: 1.000014]\n",
      "epoch:12 step:56820[D loss: 0.999937] [G loss: 1.000106]\n",
      "epoch:12 step:56825[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:12 step:56830[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:12 step:56835[D loss: 0.999983] [G loss: 1.000026]\n",
      "epoch:12 step:56840[D loss: 1.000006] [G loss: 1.000021]\n",
      "epoch:12 step:56845[D loss: 1.000030] [G loss: 1.000001]\n",
      "epoch:12 step:56850[D loss: 0.999959] [G loss: 1.000043]\n",
      "epoch:12 step:56855[D loss: 1.000021] [G loss: 1.000004]\n",
      "epoch:12 step:56860[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:12 step:56865[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:12 step:56870[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:12 step:56875[D loss: 0.999990] [G loss: 1.000033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:56880[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:12 step:56885[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:12 step:56890[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:12 step:56895[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:12 step:56900[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:12 step:56905[D loss: 1.000003] [G loss: 1.000022]\n",
      "epoch:12 step:56910[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:12 step:56915[D loss: 1.000002] [G loss: 1.000037]\n",
      "epoch:12 step:56920[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:12 step:56925[D loss: 0.999944] [G loss: 1.000098]\n",
      "epoch:12 step:56930[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:12 step:56935[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:12 step:56940[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:12 step:56945[D loss: 1.000041] [G loss: 0.999970]\n",
      "epoch:12 step:56950[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:12 step:56955[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:12 step:56960[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:12 step:56965[D loss: 1.000009] [G loss: 0.999997]\n",
      "epoch:12 step:56970[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:12 step:56975[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:12 step:56980[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:12 step:56985[D loss: 0.999937] [G loss: 1.000148]\n",
      "epoch:12 step:56990[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:12 step:56995[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:12 step:57000[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:12 step:57005[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:12 step:57010[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:12 step:57015[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:12 step:57020[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:12 step:57025[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:12 step:57030[D loss: 0.999976] [G loss: 1.000089]\n",
      "epoch:12 step:57035[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:12 step:57040[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:12 step:57045[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:12 step:57050[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:12 step:57055[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:12 step:57060[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:12 step:57065[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:12 step:57070[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:12 step:57075[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:12 step:57080[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:12 step:57085[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:12 step:57090[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:12 step:57095[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:12 step:57100[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:12 step:57105[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:12 step:57110[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:12 step:57115[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:12 step:57120[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:12 step:57125[D loss: 0.999975] [G loss: 1.000098]\n",
      "epoch:12 step:57130[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:12 step:57135[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:12 step:57140[D loss: 0.999977] [G loss: 1.000020]\n",
      "epoch:12 step:57145[D loss: 1.000011] [G loss: 1.000014]\n",
      "epoch:12 step:57150[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:57155[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:12 step:57160[D loss: 1.000006] [G loss: 1.000069]\n",
      "epoch:12 step:57165[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:12 step:57170[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:12 step:57175[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:12 step:57180[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:57185[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:12 step:57190[D loss: 1.000008] [G loss: 1.000029]\n",
      "epoch:12 step:57195[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:12 step:57200[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:12 step:57205[D loss: 1.000028] [G loss: 1.000010]\n",
      "epoch:12 step:57210[D loss: 1.000024] [G loss: 1.000092]\n",
      "epoch:12 step:57215[D loss: 0.999978] [G loss: 1.000089]\n",
      "epoch:12 step:57220[D loss: 0.999989] [G loss: 1.000137]\n",
      "epoch:12 step:57225[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:12 step:57230[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:12 step:57235[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:12 step:57240[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:12 step:57245[D loss: 0.999967] [G loss: 1.000036]\n",
      "epoch:12 step:57250[D loss: 0.999999] [G loss: 1.000018]\n",
      "epoch:12 step:57255[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:12 step:57260[D loss: 0.999962] [G loss: 1.000018]\n",
      "epoch:12 step:57265[D loss: 1.000018] [G loss: 1.000055]\n",
      "epoch:12 step:57270[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:12 step:57275[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:12 step:57280[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:12 step:57285[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:12 step:57290[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:12 step:57295[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:12 step:57300[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:12 step:57305[D loss: 0.999972] [G loss: 1.000166]\n",
      "epoch:12 step:57310[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:12 step:57315[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:12 step:57320[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:12 step:57325[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:12 step:57330[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:12 step:57335[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:12 step:57340[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:12 step:57345[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:12 step:57350[D loss: 0.999981] [G loss: 1.000116]\n",
      "epoch:12 step:57355[D loss: 0.999981] [G loss: 1.000123]\n",
      "epoch:12 step:57360[D loss: 0.999944] [G loss: 1.000082]\n",
      "epoch:12 step:57365[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:12 step:57370[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:12 step:57375[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:12 step:57380[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:12 step:57385[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:12 step:57390[D loss: 1.000013] [G loss: 1.000019]\n",
      "epoch:12 step:57395[D loss: 1.000032] [G loss: 1.000007]\n",
      "epoch:12 step:57400[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:12 step:57405[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:12 step:57410[D loss: 1.000013] [G loss: 1.000008]\n",
      "epoch:12 step:57415[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:12 step:57420[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:12 step:57425[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:12 step:57430[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:12 step:57435[D loss: 0.999945] [G loss: 1.000086]\n",
      "epoch:12 step:57440[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:12 step:57445[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:12 step:57450[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:12 step:57455[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:12 step:57460[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:12 step:57465[D loss: 0.999994] [G loss: 1.000059]\n",
      "epoch:12 step:57470[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:12 step:57475[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:12 step:57480[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:12 step:57485[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:12 step:57490[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:12 step:57495[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:12 step:57500[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:12 step:57505[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:12 step:57510[D loss: 0.999986] [G loss: 1.000099]\n",
      "epoch:12 step:57515[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:12 step:57520[D loss: 0.999996] [G loss: 1.000069]\n",
      "epoch:12 step:57525[D loss: 0.999965] [G loss: 1.000041]\n",
      "epoch:12 step:57530[D loss: 1.000011] [G loss: 0.999998]\n",
      "epoch:12 step:57535[D loss: 1.000065] [G loss: 0.999909]\n",
      "epoch:12 step:57540[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:12 step:57545[D loss: 0.999988] [G loss: 1.000025]\n",
      "epoch:12 step:57550[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:12 step:57555[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:12 step:57560[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:12 step:57565[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:12 step:57570[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:12 step:57575[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:12 step:57580[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:12 step:57585[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:12 step:57590[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:12 step:57595[D loss: 1.000000] [G loss: 1.000037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:57600[D loss: 0.999995] [G loss: 1.000035]\n",
      "epoch:12 step:57605[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:12 step:57610[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:12 step:57615[D loss: 0.999949] [G loss: 1.000108]\n",
      "epoch:12 step:57620[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:12 step:57625[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:12 step:57630[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:12 step:57635[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:12 step:57640[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:12 step:57645[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:12 step:57650[D loss: 0.999997] [G loss: 1.000031]\n",
      "epoch:12 step:57655[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:12 step:57660[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:12 step:57665[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:12 step:57670[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:12 step:57675[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:12 step:57680[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:12 step:57685[D loss: 0.999967] [G loss: 1.000037]\n",
      "epoch:12 step:57690[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:12 step:57695[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:12 step:57700[D loss: 0.999992] [G loss: 1.000011]\n",
      "epoch:12 step:57705[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:12 step:57710[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:12 step:57715[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:12 step:57720[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:57725[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:12 step:57730[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:12 step:57735[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:12 step:57740[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:12 step:57745[D loss: 0.999994] [G loss: 1.000006]\n",
      "epoch:12 step:57750[D loss: 0.999998] [G loss: 1.000051]\n",
      "epoch:12 step:57755[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:12 step:57760[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:12 step:57765[D loss: 1.000050] [G loss: 0.999957]\n",
      "epoch:12 step:57770[D loss: 1.000024] [G loss: 1.000038]\n",
      "epoch:12 step:57775[D loss: 0.999961] [G loss: 1.000164]\n",
      "epoch:12 step:57780[D loss: 0.999952] [G loss: 1.000063]\n",
      "epoch:12 step:57785[D loss: 0.999925] [G loss: 1.000158]\n",
      "epoch:12 step:57790[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:12 step:57795[D loss: 0.999970] [G loss: 1.000139]\n",
      "epoch:12 step:57800[D loss: 0.999966] [G loss: 1.000168]\n",
      "epoch:12 step:57805[D loss: 0.999971] [G loss: 1.000023]\n",
      "epoch:12 step:57810[D loss: 0.999994] [G loss: 0.999992]\n",
      "epoch:12 step:57815[D loss: 1.000010] [G loss: 0.999991]\n",
      "epoch:12 step:57820[D loss: 0.999969] [G loss: 1.000016]\n",
      "epoch:12 step:57825[D loss: 1.000070] [G loss: 0.999918]\n",
      "epoch:12 step:57830[D loss: 1.000045] [G loss: 0.999929]\n",
      "epoch:12 step:57835[D loss: 0.999950] [G loss: 1.000177]\n",
      "epoch:12 step:57840[D loss: 0.999949] [G loss: 1.000071]\n",
      "epoch:12 step:57845[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:12 step:57850[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:12 step:57855[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:12 step:57860[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:12 step:57865[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:12 step:57870[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:12 step:57875[D loss: 0.999991] [G loss: 1.000009]\n",
      "epoch:12 step:57880[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:12 step:57885[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:12 step:57890[D loss: 1.000018] [G loss: 0.999985]\n",
      "epoch:12 step:57895[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:12 step:57900[D loss: 0.999943] [G loss: 1.000118]\n",
      "epoch:12 step:57905[D loss: 0.999990] [G loss: 1.000076]\n",
      "epoch:12 step:57910[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:12 step:57915[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:12 step:57920[D loss: 0.999983] [G loss: 1.000039]\n",
      "epoch:12 step:57925[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:12 step:57930[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:12 step:57935[D loss: 1.000011] [G loss: 0.999975]\n",
      "epoch:12 step:57940[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:12 step:57945[D loss: 0.999976] [G loss: 1.000013]\n",
      "epoch:12 step:57950[D loss: 1.000078] [G loss: 0.999964]\n",
      "epoch:12 step:57955[D loss: 0.999946] [G loss: 1.000078]\n",
      "epoch:12 step:57960[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:12 step:57965[D loss: 1.000013] [G loss: 1.000054]\n",
      "epoch:12 step:57970[D loss: 0.999966] [G loss: 1.000096]\n",
      "epoch:12 step:57975[D loss: 0.999989] [G loss: 1.000086]\n",
      "epoch:12 step:57980[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:12 step:57985[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:12 step:57990[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:12 step:57995[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:12 step:58000[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:12 step:58005[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:12 step:58010[D loss: 1.000053] [G loss: 0.999961]\n",
      "epoch:12 step:58015[D loss: 0.999964] [G loss: 1.000055]\n",
      "epoch:12 step:58020[D loss: 1.000016] [G loss: 1.000063]\n",
      "epoch:12 step:58025[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:12 step:58030[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:12 step:58035[D loss: 1.000009] [G loss: 1.000034]\n",
      "epoch:12 step:58040[D loss: 1.000022] [G loss: 1.000085]\n",
      "epoch:12 step:58045[D loss: 1.000007] [G loss: 0.999962]\n",
      "epoch:12 step:58050[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:12 step:58055[D loss: 1.000033] [G loss: 1.000014]\n",
      "epoch:12 step:58060[D loss: 0.999977] [G loss: 1.000019]\n",
      "epoch:12 step:58065[D loss: 0.999998] [G loss: 1.000052]\n",
      "epoch:12 step:58070[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:12 step:58075[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:12 step:58080[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:12 step:58085[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:12 step:58090[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:12 step:58095[D loss: 1.000042] [G loss: 0.999994]\n",
      "epoch:12 step:58100[D loss: 1.000005] [G loss: 1.000017]\n",
      "epoch:12 step:58105[D loss: 0.999976] [G loss: 1.000114]\n",
      "epoch:12 step:58110[D loss: 1.000031] [G loss: 1.000056]\n",
      "epoch:12 step:58115[D loss: 0.999903] [G loss: 1.000182]\n",
      "epoch:12 step:58120[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:12 step:58125[D loss: 1.000001] [G loss: 1.000039]\n",
      "epoch:12 step:58130[D loss: 0.999969] [G loss: 1.000030]\n",
      "epoch:12 step:58135[D loss: 1.000055] [G loss: 0.999929]\n",
      "epoch:12 step:58140[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:12 step:58145[D loss: 1.000010] [G loss: 1.000092]\n",
      "epoch:12 step:58150[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:12 step:58155[D loss: 0.999961] [G loss: 1.000129]\n",
      "epoch:12 step:58160[D loss: 1.000010] [G loss: 1.000037]\n",
      "epoch:12 step:58165[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:12 step:58170[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:12 step:58175[D loss: 1.000029] [G loss: 0.999949]\n",
      "epoch:12 step:58180[D loss: 0.999955] [G loss: 1.000034]\n",
      "epoch:12 step:58185[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:12 step:58190[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:12 step:58195[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:12 step:58200[D loss: 1.000008] [G loss: 1.000007]\n",
      "epoch:12 step:58205[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:12 step:58210[D loss: 0.999934] [G loss: 1.000076]\n",
      "epoch:12 step:58215[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:12 step:58220[D loss: 0.999998] [G loss: 1.000004]\n",
      "epoch:12 step:58225[D loss: 0.999984] [G loss: 1.000076]\n",
      "epoch:12 step:58230[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:12 step:58235[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:12 step:58240[D loss: 1.000009] [G loss: 1.000011]\n",
      "epoch:12 step:58245[D loss: 1.000011] [G loss: 1.000052]\n",
      "epoch:12 step:58250[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:12 step:58255[D loss: 1.000035] [G loss: 1.000028]\n",
      "epoch:12 step:58260[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:12 step:58265[D loss: 1.000033] [G loss: 0.999940]\n",
      "epoch:12 step:58270[D loss: 0.999991] [G loss: 1.000104]\n",
      "epoch:12 step:58275[D loss: 0.999940] [G loss: 1.000092]\n",
      "epoch:12 step:58280[D loss: 1.000019] [G loss: 1.000025]\n",
      "epoch:12 step:58285[D loss: 1.000012] [G loss: 0.999959]\n",
      "epoch:12 step:58290[D loss: 1.000014] [G loss: 1.000000]\n",
      "epoch:12 step:58295[D loss: 0.999917] [G loss: 1.000080]\n",
      "epoch:12 step:58300[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:12 step:58305[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:12 step:58310[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:12 step:58315[D loss: 0.999971] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:58320[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:12 step:58325[D loss: 1.000004] [G loss: 1.000056]\n",
      "epoch:12 step:58330[D loss: 1.000019] [G loss: 1.000002]\n",
      "epoch:12 step:58335[D loss: 0.999929] [G loss: 1.000138]\n",
      "epoch:12 step:58340[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:12 step:58345[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:12 step:58350[D loss: 1.000014] [G loss: 1.000004]\n",
      "epoch:12 step:58355[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:12 step:58360[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:12 step:58365[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:12 step:58370[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:12 step:58375[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:12 step:58380[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:12 step:58385[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:12 step:58390[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:12 step:58395[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:12 step:58400[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:12 step:58405[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:12 step:58410[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:12 step:58415[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:12 step:58420[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:12 step:58425[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:12 step:58430[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:12 step:58435[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:12 step:58440[D loss: 0.999959] [G loss: 1.000105]\n",
      "epoch:12 step:58445[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:12 step:58450[D loss: 1.000016] [G loss: 1.000005]\n",
      "epoch:12 step:58455[D loss: 1.000007] [G loss: 1.000045]\n",
      "epoch:12 step:58460[D loss: 0.999976] [G loss: 1.000124]\n",
      "epoch:12 step:58465[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:12 step:58470[D loss: 0.999924] [G loss: 1.000142]\n",
      "epoch:12 step:58475[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:12 step:58480[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:12 step:58485[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:12 step:58490[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:12 step:58495[D loss: 1.000001] [G loss: 1.000004]\n",
      "epoch:12 step:58500[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:12 step:58505[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:12 step:58510[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:12 step:58515[D loss: 1.000070] [G loss: 1.000061]\n",
      "epoch:12 step:58520[D loss: 0.999930] [G loss: 1.000153]\n",
      "epoch:12 step:58525[D loss: 0.999940] [G loss: 1.000109]\n",
      "epoch:12 step:58530[D loss: 1.000017] [G loss: 0.999958]\n",
      "epoch:12 step:58535[D loss: 0.999988] [G loss: 0.999988]\n",
      "epoch:12 step:58540[D loss: 1.000045] [G loss: 0.999962]\n",
      "epoch:12 step:58545[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:12 step:58550[D loss: 0.999998] [G loss: 0.999999]\n",
      "epoch:12 step:58555[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:12 step:58560[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:12 step:58565[D loss: 1.000018] [G loss: 1.000029]\n",
      "epoch:12 step:58570[D loss: 0.999944] [G loss: 1.000117]\n",
      "epoch:12 step:58575[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:12 step:58580[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:12 step:58585[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:12 step:58590[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:12 step:58595[D loss: 0.999996] [G loss: 1.000030]\n",
      "epoch:12 step:58600[D loss: 0.999969] [G loss: 1.000046]\n",
      "epoch:12 step:58605[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:12 step:58610[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:12 step:58615[D loss: 0.999973] [G loss: 1.000028]\n",
      "epoch:12 step:58620[D loss: 0.999945] [G loss: 1.000108]\n",
      "epoch:12 step:58625[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:12 step:58630[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:12 step:58635[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:12 step:58640[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:12 step:58645[D loss: 1.000035] [G loss: 1.000010]\n",
      "epoch:12 step:58650[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:12 step:58655[D loss: 0.999981] [G loss: 1.000092]\n",
      "epoch:12 step:58660[D loss: 0.999998] [G loss: 1.000052]\n",
      "epoch:12 step:58665[D loss: 0.999943] [G loss: 1.000139]\n",
      "epoch:12 step:58670[D loss: 1.000031] [G loss: 1.000016]\n",
      "epoch:12 step:58675[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:12 step:58680[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:12 step:58685[D loss: 0.999987] [G loss: 1.000133]\n",
      "epoch:12 step:58690[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:12 step:58695[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:12 step:58700[D loss: 1.000002] [G loss: 1.000097]\n",
      "epoch:12 step:58705[D loss: 0.999945] [G loss: 1.000111]\n",
      "epoch:12 step:58710[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:12 step:58715[D loss: 1.000026] [G loss: 0.999981]\n",
      "epoch:12 step:58720[D loss: 0.999994] [G loss: 1.000087]\n",
      "epoch:12 step:58725[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:12 step:58730[D loss: 0.999997] [G loss: 0.999985]\n",
      "epoch:12 step:58735[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:12 step:58740[D loss: 0.999962] [G loss: 1.000123]\n",
      "epoch:12 step:58745[D loss: 1.000008] [G loss: 1.000058]\n",
      "epoch:12 step:58750[D loss: 0.999954] [G loss: 1.000067]\n",
      "epoch:12 step:58755[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:12 step:58760[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:12 step:58765[D loss: 0.999938] [G loss: 1.000102]\n",
      "epoch:12 step:58770[D loss: 1.000018] [G loss: 1.000122]\n",
      "epoch:12 step:58775[D loss: 0.999923] [G loss: 1.000134]\n",
      "epoch:12 step:58780[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:12 step:58785[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:12 step:58790[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:12 step:58795[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:12 step:58800[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:12 step:58805[D loss: 1.000006] [G loss: 1.000091]\n",
      "epoch:12 step:58810[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:12 step:58815[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:12 step:58820[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:12 step:58825[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:12 step:58830[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:12 step:58835[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:12 step:58840[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:12 step:58845[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:12 step:58850[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:12 step:58855[D loss: 0.999940] [G loss: 1.000080]\n",
      "epoch:12 step:58860[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:12 step:58865[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:12 step:58870[D loss: 0.999971] [G loss: 1.000098]\n",
      "epoch:12 step:58875[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:12 step:58880[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:12 step:58885[D loss: 0.999993] [G loss: 1.000070]\n",
      "epoch:12 step:58890[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:12 step:58895[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:12 step:58900[D loss: 0.999974] [G loss: 1.000123]\n",
      "epoch:12 step:58905[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:12 step:58910[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:12 step:58915[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:12 step:58920[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:12 step:58925[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:12 step:58930[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:12 step:58935[D loss: 1.000002] [G loss: 1.000072]\n",
      "epoch:12 step:58940[D loss: 0.999958] [G loss: 1.000126]\n",
      "epoch:12 step:58945[D loss: 1.000024] [G loss: 1.000011]\n",
      "epoch:12 step:58950[D loss: 1.000006] [G loss: 0.999989]\n",
      "epoch:12 step:58955[D loss: 0.999949] [G loss: 1.000050]\n",
      "epoch:12 step:58960[D loss: 0.999934] [G loss: 1.000133]\n",
      "epoch:12 step:58965[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:12 step:58970[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:12 step:58975[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:12 step:58980[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:12 step:58985[D loss: 1.000012] [G loss: 1.000057]\n",
      "epoch:12 step:58990[D loss: 0.999969] [G loss: 1.000000]\n",
      "epoch:12 step:58995[D loss: 0.999973] [G loss: 1.000031]\n",
      "epoch:12 step:59000[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:12 step:59005[D loss: 0.999958] [G loss: 1.000106]\n",
      "epoch:12 step:59010[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:12 step:59015[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:12 step:59020[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:12 step:59025[D loss: 1.000001] [G loss: 1.000059]\n",
      "epoch:12 step:59030[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:12 step:59035[D loss: 0.999973] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:59040[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:12 step:59045[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:12 step:59050[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:12 step:59055[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:12 step:59060[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:12 step:59065[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:12 step:59070[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:12 step:59075[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:12 step:59080[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:12 step:59085[D loss: 1.000002] [G loss: 1.000087]\n",
      "epoch:12 step:59090[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:12 step:59095[D loss: 0.999968] [G loss: 1.000164]\n",
      "epoch:12 step:59100[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:12 step:59105[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:12 step:59110[D loss: 1.000004] [G loss: 1.000075]\n",
      "epoch:12 step:59115[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:12 step:59120[D loss: 0.999985] [G loss: 1.000110]\n",
      "epoch:12 step:59125[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:12 step:59130[D loss: 1.000019] [G loss: 1.000022]\n",
      "epoch:12 step:59135[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:12 step:59140[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:12 step:59145[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:12 step:59150[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:12 step:59155[D loss: 1.000002] [G loss: 0.999993]\n",
      "epoch:12 step:59160[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:12 step:59165[D loss: 1.000048] [G loss: 1.000005]\n",
      "epoch:12 step:59170[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:12 step:59175[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:12 step:59180[D loss: 1.000012] [G loss: 1.000038]\n",
      "epoch:12 step:59185[D loss: 1.000090] [G loss: 0.999922]\n",
      "epoch:12 step:59190[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:12 step:59195[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:12 step:59200[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:12 step:59205[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:12 step:59210[D loss: 0.999945] [G loss: 1.000125]\n",
      "epoch:12 step:59215[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:12 step:59220[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:12 step:59225[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:12 step:59230[D loss: 0.999999] [G loss: 0.999997]\n",
      "epoch:12 step:59235[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:12 step:59240[D loss: 0.999994] [G loss: 1.000000]\n",
      "epoch:12 step:59245[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:12 step:59250[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:12 step:59255[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:12 step:59260[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:12 step:59265[D loss: 0.999987] [G loss: 1.000157]\n",
      "epoch:12 step:59270[D loss: 0.999990] [G loss: 0.999988]\n",
      "epoch:12 step:59275[D loss: 0.999950] [G loss: 1.000108]\n",
      "epoch:12 step:59280[D loss: 0.999997] [G loss: 1.000087]\n",
      "epoch:12 step:59285[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:12 step:59290[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:12 step:59295[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:12 step:59300[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:12 step:59305[D loss: 1.000059] [G loss: 1.000029]\n",
      "epoch:12 step:59310[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:12 step:59315[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:12 step:59320[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:12 step:59325[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:12 step:59330[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:12 step:59335[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:12 step:59340[D loss: 0.999956] [G loss: 1.000050]\n",
      "epoch:12 step:59345[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:12 step:59350[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:12 step:59355[D loss: 1.000000] [G loss: 1.000021]\n",
      "epoch:12 step:59360[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:12 step:59365[D loss: 0.999967] [G loss: 1.000056]\n",
      "epoch:12 step:59370[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:12 step:59375[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:12 step:59380[D loss: 0.999951] [G loss: 1.000106]\n",
      "epoch:12 step:59385[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:12 step:59390[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:12 step:59395[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:12 step:59400[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:12 step:59405[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:12 step:59410[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:12 step:59415[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:12 step:59420[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:12 step:59425[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:12 step:59430[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:12 step:59435[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:12 step:59440[D loss: 1.000022] [G loss: 0.999950]\n",
      "epoch:12 step:59445[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:12 step:59450[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:12 step:59455[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:12 step:59460[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:12 step:59465[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:12 step:59470[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:12 step:59475[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:12 step:59480[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:12 step:59485[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:12 step:59490[D loss: 0.999991] [G loss: 1.000024]\n",
      "epoch:12 step:59495[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:12 step:59500[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:12 step:59505[D loss: 0.999985] [G loss: 1.000027]\n",
      "epoch:12 step:59510[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:12 step:59515[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:12 step:59520[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:12 step:59525[D loss: 0.999997] [G loss: 1.000076]\n",
      "epoch:12 step:59530[D loss: 1.000018] [G loss: 1.000056]\n",
      "epoch:12 step:59535[D loss: 1.000039] [G loss: 0.999970]\n",
      "epoch:12 step:59540[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:12 step:59545[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:12 step:59550[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:12 step:59555[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:12 step:59560[D loss: 0.999983] [G loss: 1.000060]\n",
      "epoch:12 step:59565[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:12 step:59570[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:12 step:59575[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:12 step:59580[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:12 step:59585[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:12 step:59590[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:12 step:59595[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:12 step:59600[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:12 step:59605[D loss: 1.000032] [G loss: 0.999929]\n",
      "epoch:12 step:59610[D loss: 1.000033] [G loss: 0.999979]\n",
      "epoch:12 step:59615[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:12 step:59620[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:12 step:59625[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:12 step:59630[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:12 step:59635[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:12 step:59640[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:12 step:59645[D loss: 1.000049] [G loss: 0.999951]\n",
      "epoch:12 step:59650[D loss: 0.999958] [G loss: 1.000059]\n",
      "epoch:12 step:59655[D loss: 0.999952] [G loss: 1.000059]\n",
      "epoch:12 step:59660[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:12 step:59665[D loss: 0.999989] [G loss: 1.000103]\n",
      "epoch:12 step:59670[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:12 step:59675[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:12 step:59680[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:12 step:59685[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:12 step:59690[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:12 step:59695[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:12 step:59700[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:12 step:59705[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:12 step:59710[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:12 step:59715[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:12 step:59720[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:12 step:59725[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:12 step:59730[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:12 step:59735[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:12 step:59740[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:12 step:59745[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:12 step:59750[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:12 step:59755[D loss: 0.999973] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:59760[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:12 step:59765[D loss: 0.999976] [G loss: 1.000099]\n",
      "epoch:12 step:59770[D loss: 1.000015] [G loss: 1.000001]\n",
      "epoch:12 step:59775[D loss: 1.000014] [G loss: 0.999984]\n",
      "epoch:12 step:59780[D loss: 0.999943] [G loss: 1.000122]\n",
      "epoch:12 step:59785[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:59790[D loss: 1.000058] [G loss: 1.000020]\n",
      "epoch:12 step:59795[D loss: 0.999941] [G loss: 1.000145]\n",
      "epoch:12 step:59800[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:12 step:59805[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:12 step:59810[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:12 step:59815[D loss: 1.000017] [G loss: 0.999999]\n",
      "epoch:12 step:59820[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:12 step:59825[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:12 step:59830[D loss: 0.999958] [G loss: 1.000117]\n",
      "epoch:12 step:59835[D loss: 0.999959] [G loss: 1.000119]\n",
      "epoch:12 step:59840[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:12 step:59845[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:12 step:59850[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:12 step:59855[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:12 step:59860[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:12 step:59865[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:12 step:59870[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:12 step:59875[D loss: 1.000000] [G loss: 1.000060]\n",
      "epoch:12 step:59880[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:12 step:59885[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:12 step:59890[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:12 step:59895[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:12 step:59900[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:12 step:59905[D loss: 0.999988] [G loss: 1.000160]\n",
      "epoch:12 step:59910[D loss: 0.999930] [G loss: 1.000145]\n",
      "epoch:12 step:59915[D loss: 1.000052] [G loss: 0.999975]\n",
      "epoch:12 step:59920[D loss: 1.000016] [G loss: 1.000026]\n",
      "epoch:12 step:59925[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:12 step:59930[D loss: 1.000091] [G loss: 0.999931]\n",
      "epoch:12 step:59935[D loss: 0.999906] [G loss: 1.000073]\n",
      "epoch:12 step:59940[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:12 step:59945[D loss: 0.999990] [G loss: 1.000001]\n",
      "epoch:12 step:59950[D loss: 0.999989] [G loss: 1.000005]\n",
      "epoch:12 step:59955[D loss: 0.999948] [G loss: 1.000084]\n",
      "epoch:12 step:59960[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:12 step:59965[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:12 step:59970[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:12 step:59975[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:12 step:59980[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:12 step:59985[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:12 step:59990[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:12 step:59995[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:12 step:60000[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:12 step:60005[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:12 step:60010[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:12 step:60015[D loss: 0.999952] [G loss: 1.000083]\n",
      "epoch:12 step:60020[D loss: 1.000007] [G loss: 1.000027]\n",
      "epoch:12 step:60025[D loss: 0.999933] [G loss: 1.000142]\n",
      "epoch:12 step:60030[D loss: 1.000061] [G loss: 0.999987]\n",
      "epoch:12 step:60035[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:12 step:60040[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:12 step:60045[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:12 step:60050[D loss: 1.000022] [G loss: 0.999974]\n",
      "epoch:12 step:60055[D loss: 0.999941] [G loss: 1.000107]\n",
      "epoch:12 step:60060[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:12 step:60065[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:12 step:60070[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:12 step:60075[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:12 step:60080[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:12 step:60085[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:12 step:60090[D loss: 0.999991] [G loss: 1.000098]\n",
      "epoch:12 step:60095[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:12 step:60100[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:12 step:60105[D loss: 1.000007] [G loss: 1.000031]\n",
      "epoch:12 step:60110[D loss: 1.000011] [G loss: 1.000028]\n",
      "epoch:12 step:60115[D loss: 1.000013] [G loss: 1.000049]\n",
      "epoch:12 step:60120[D loss: 0.999937] [G loss: 1.000121]\n",
      "epoch:12 step:60125[D loss: 0.999944] [G loss: 1.000059]\n",
      "epoch:12 step:60130[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:12 step:60135[D loss: 0.999953] [G loss: 1.000072]\n",
      "epoch:12 step:60140[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:12 step:60145[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:12 step:60150[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:12 step:60155[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:12 step:60160[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:12 step:60165[D loss: 0.999959] [G loss: 1.000126]\n",
      "epoch:12 step:60170[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:12 step:60175[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:12 step:60180[D loss: 1.000008] [G loss: 0.999996]\n",
      "epoch:12 step:60185[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:12 step:60190[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:12 step:60195[D loss: 1.000006] [G loss: 1.000059]\n",
      "epoch:12 step:60200[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:12 step:60205[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:12 step:60210[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:12 step:60215[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:12 step:60220[D loss: 1.000004] [G loss: 1.000021]\n",
      "epoch:12 step:60225[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:12 step:60230[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:12 step:60235[D loss: 0.999969] [G loss: 1.000098]\n",
      "epoch:12 step:60240[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:12 step:60245[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:12 step:60250[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:12 step:60255[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:12 step:60260[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:12 step:60265[D loss: 0.999972] [G loss: 1.000029]\n",
      "epoch:12 step:60270[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:12 step:60275[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:12 step:60280[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:12 step:60285[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:12 step:60290[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:12 step:60295[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:12 step:60300[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:12 step:60305[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:12 step:60310[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:12 step:60315[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:12 step:60320[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:12 step:60325[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:12 step:60330[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:12 step:60335[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:12 step:60340[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:12 step:60345[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:12 step:60350[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:12 step:60355[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:12 step:60360[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:12 step:60365[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:12 step:60370[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:12 step:60375[D loss: 0.999952] [G loss: 1.000098]\n",
      "epoch:12 step:60380[D loss: 1.000030] [G loss: 1.000008]\n",
      "epoch:12 step:60385[D loss: 0.999963] [G loss: 1.000042]\n",
      "epoch:12 step:60390[D loss: 0.999978] [G loss: 1.000137]\n",
      "epoch:12 step:60395[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:12 step:60400[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:12 step:60405[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:12 step:60410[D loss: 1.000018] [G loss: 1.000059]\n",
      "epoch:12 step:60415[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:12 step:60420[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:12 step:60425[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:12 step:60430[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:12 step:60435[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:12 step:60440[D loss: 1.000012] [G loss: 1.000033]\n",
      "epoch:12 step:60445[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:12 step:60450[D loss: 0.999976] [G loss: 1.000018]\n",
      "epoch:12 step:60455[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:12 step:60460[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:12 step:60465[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:12 step:60470[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:12 step:60475[D loss: 0.999987] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:60480[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:12 step:60485[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:12 step:60490[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:12 step:60495[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:12 step:60500[D loss: 1.000032] [G loss: 0.999953]\n",
      "epoch:12 step:60505[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:12 step:60510[D loss: 0.999924] [G loss: 1.000131]\n",
      "epoch:12 step:60515[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:12 step:60520[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:12 step:60525[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:12 step:60530[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:12 step:60535[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:12 step:60540[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:12 step:60545[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:12 step:60550[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:12 step:60555[D loss: 1.000004] [G loss: 1.000063]\n",
      "epoch:12 step:60560[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:12 step:60565[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:12 step:60570[D loss: 1.000012] [G loss: 1.000067]\n",
      "epoch:12 step:60575[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:12 step:60580[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:12 step:60585[D loss: 0.999956] [G loss: 1.000105]\n",
      "epoch:12 step:60590[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:12 step:60595[D loss: 1.000003] [G loss: 1.000026]\n",
      "epoch:12 step:60600[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:12 step:60605[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:12 step:60610[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:12 step:60615[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:12 step:60620[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:12 step:60625[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:12 step:60630[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:12 step:60635[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:12 step:60640[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:12 step:60645[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:12 step:60650[D loss: 1.000031] [G loss: 0.999975]\n",
      "epoch:12 step:60655[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:12 step:60660[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:12 step:60665[D loss: 1.000010] [G loss: 1.000032]\n",
      "epoch:12 step:60670[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:12 step:60675[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:12 step:60680[D loss: 0.999997] [G loss: 0.999985]\n",
      "epoch:12 step:60685[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:12 step:60690[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:12 step:60695[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:12 step:60700[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:12 step:60705[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:12 step:60710[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:12 step:60715[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:12 step:60720[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:12 step:60725[D loss: 1.000008] [G loss: 1.000014]\n",
      "epoch:12 step:60730[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:12 step:60735[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:12 step:60740[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:12 step:60745[D loss: 0.999922] [G loss: 1.000126]\n",
      "epoch:12 step:60750[D loss: 0.999961] [G loss: 1.000107]\n",
      "epoch:12 step:60755[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:12 step:60760[D loss: 1.000064] [G loss: 0.999919]\n",
      "epoch:12 step:60765[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:12 step:60770[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:12 step:60775[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:12 step:60780[D loss: 0.999946] [G loss: 1.000071]\n",
      "epoch:12 step:60785[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:12 step:60790[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:12 step:60795[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:12 step:60800[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:12 step:60805[D loss: 0.999971] [G loss: 1.000127]\n",
      "epoch:12 step:60810[D loss: 1.000010] [G loss: 0.999982]\n",
      "epoch:12 step:60815[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:12 step:60820[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:12 step:60825[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:12 step:60830[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:12 step:60835[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:12 step:60840[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:12 step:60845[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:12 step:60850[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:12 step:60855[D loss: 0.999978] [G loss: 1.000016]\n",
      "epoch:12 step:60860[D loss: 1.000026] [G loss: 0.999987]\n",
      "epoch:12 step:60865[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:12 step:60870[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:12 step:60875[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:12 step:60880[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:12 step:60885[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:12 step:60890[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:12 step:60895[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:12 step:60900[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:12 step:60905[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:13 step:60910[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:13 step:60915[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:13 step:60920[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:13 step:60925[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:13 step:60930[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:13 step:60935[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:13 step:60940[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:13 step:60945[D loss: 0.999997] [G loss: 1.000011]\n",
      "epoch:13 step:60950[D loss: 0.999975] [G loss: 1.000083]\n",
      "epoch:13 step:60955[D loss: 1.000015] [G loss: 1.000073]\n",
      "epoch:13 step:60960[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:13 step:60965[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:13 step:60970[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:13 step:60975[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:13 step:60980[D loss: 0.999996] [G loss: 1.000008]\n",
      "epoch:13 step:60985[D loss: 0.999955] [G loss: 1.000089]\n",
      "epoch:13 step:60990[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:13 step:60995[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:13 step:61000[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:13 step:61005[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:13 step:61010[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:13 step:61015[D loss: 1.000010] [G loss: 1.000044]\n",
      "epoch:13 step:61020[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:13 step:61025[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:13 step:61030[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:13 step:61035[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:13 step:61040[D loss: 0.999972] [G loss: 1.000117]\n",
      "epoch:13 step:61045[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:13 step:61050[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:13 step:61055[D loss: 1.000014] [G loss: 0.999962]\n",
      "epoch:13 step:61060[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:13 step:61065[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:13 step:61070[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:13 step:61075[D loss: 1.000018] [G loss: 1.000039]\n",
      "epoch:13 step:61080[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:13 step:61085[D loss: 1.000034] [G loss: 0.999983]\n",
      "epoch:13 step:61090[D loss: 0.999970] [G loss: 1.000137]\n",
      "epoch:13 step:61095[D loss: 0.999958] [G loss: 1.000039]\n",
      "epoch:13 step:61100[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:13 step:61105[D loss: 1.000074] [G loss: 0.999942]\n",
      "epoch:13 step:61110[D loss: 1.000063] [G loss: 0.999910]\n",
      "epoch:13 step:61115[D loss: 0.999949] [G loss: 1.000085]\n",
      "epoch:13 step:61120[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:13 step:61125[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:13 step:61130[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:13 step:61135[D loss: 0.999937] [G loss: 1.000106]\n",
      "epoch:13 step:61140[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:13 step:61145[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:13 step:61150[D loss: 1.000004] [G loss: 0.999998]\n",
      "epoch:13 step:61155[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:13 step:61160[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:13 step:61165[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:13 step:61170[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:13 step:61175[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:13 step:61180[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:13 step:61185[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:13 step:61190[D loss: 0.999962] [G loss: 1.000130]\n",
      "epoch:13 step:61195[D loss: 1.000001] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:61200[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:13 step:61205[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:13 step:61210[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:13 step:61215[D loss: 1.000001] [G loss: 1.000025]\n",
      "epoch:13 step:61220[D loss: 1.000019] [G loss: 1.000031]\n",
      "epoch:13 step:61225[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:13 step:61230[D loss: 1.000033] [G loss: 0.999987]\n",
      "epoch:13 step:61235[D loss: 0.999968] [G loss: 1.000034]\n",
      "epoch:13 step:61240[D loss: 0.999953] [G loss: 1.000103]\n",
      "epoch:13 step:61245[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:13 step:61250[D loss: 1.000018] [G loss: 1.000036]\n",
      "epoch:13 step:61255[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:13 step:61260[D loss: 0.999981] [G loss: 1.000095]\n",
      "epoch:13 step:61265[D loss: 1.000009] [G loss: 1.000033]\n",
      "epoch:13 step:61270[D loss: 0.999950] [G loss: 1.000115]\n",
      "epoch:13 step:61275[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:13 step:61280[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:13 step:61285[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:13 step:61290[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:13 step:61295[D loss: 1.000011] [G loss: 1.000004]\n",
      "epoch:13 step:61300[D loss: 0.999997] [G loss: 0.999988]\n",
      "epoch:13 step:61305[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:13 step:61310[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:13 step:61315[D loss: 0.999999] [G loss: 1.000021]\n",
      "epoch:13 step:61320[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:13 step:61325[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:13 step:61330[D loss: 1.000015] [G loss: 1.000007]\n",
      "epoch:13 step:61335[D loss: 0.999973] [G loss: 1.000018]\n",
      "epoch:13 step:61340[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:13 step:61345[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:13 step:61350[D loss: 1.000027] [G loss: 1.000032]\n",
      "epoch:13 step:61355[D loss: 0.999950] [G loss: 1.000116]\n",
      "epoch:13 step:61360[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:13 step:61365[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:13 step:61370[D loss: 1.000008] [G loss: 0.999985]\n",
      "epoch:13 step:61375[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:13 step:61380[D loss: 1.000045] [G loss: 1.000009]\n",
      "epoch:13 step:61385[D loss: 0.999938] [G loss: 1.000174]\n",
      "epoch:13 step:61390[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:13 step:61395[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:13 step:61400[D loss: 0.999954] [G loss: 1.000096]\n",
      "epoch:13 step:61405[D loss: 0.999972] [G loss: 0.999996]\n",
      "epoch:13 step:61410[D loss: 1.000035] [G loss: 0.999966]\n",
      "epoch:13 step:61415[D loss: 0.999967] [G loss: 1.000035]\n",
      "epoch:13 step:61420[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:13 step:61425[D loss: 0.999962] [G loss: 1.000124]\n",
      "epoch:13 step:61430[D loss: 0.999953] [G loss: 1.000131]\n",
      "epoch:13 step:61435[D loss: 0.999932] [G loss: 1.000122]\n",
      "epoch:13 step:61440[D loss: 1.000006] [G loss: 1.000082]\n",
      "epoch:13 step:61445[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:13 step:61450[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:13 step:61455[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:13 step:61460[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:13 step:61465[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:13 step:61470[D loss: 0.999973] [G loss: 1.000132]\n",
      "epoch:13 step:61475[D loss: 0.999947] [G loss: 1.000112]\n",
      "epoch:13 step:61480[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:13 step:61485[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:13 step:61490[D loss: 1.000038] [G loss: 0.999985]\n",
      "epoch:13 step:61495[D loss: 1.000025] [G loss: 1.000057]\n",
      "epoch:13 step:61500[D loss: 1.000025] [G loss: 1.000064]\n",
      "epoch:13 step:61505[D loss: 0.999934] [G loss: 1.000119]\n",
      "epoch:13 step:61510[D loss: 0.999943] [G loss: 1.000119]\n",
      "epoch:13 step:61515[D loss: 0.999980] [G loss: 1.000115]\n",
      "epoch:13 step:61520[D loss: 0.999943] [G loss: 1.000102]\n",
      "epoch:13 step:61525[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:13 step:61530[D loss: 1.000030] [G loss: 1.000018]\n",
      "epoch:13 step:61535[D loss: 0.999954] [G loss: 1.000047]\n",
      "epoch:13 step:61540[D loss: 1.000046] [G loss: 0.999946]\n",
      "epoch:13 step:61545[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:13 step:61550[D loss: 1.000012] [G loss: 1.000002]\n",
      "epoch:13 step:61555[D loss: 0.999933] [G loss: 1.000068]\n",
      "epoch:13 step:61560[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:13 step:61565[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:13 step:61570[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:13 step:61575[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:13 step:61580[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:13 step:61585[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:13 step:61590[D loss: 1.000019] [G loss: 1.000049]\n",
      "epoch:13 step:61595[D loss: 0.999999] [G loss: 0.999996]\n",
      "epoch:13 step:61600[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:13 step:61605[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:13 step:61610[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:13 step:61615[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:13 step:61620[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:13 step:61625[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:13 step:61630[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:13 step:61635[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:13 step:61640[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:13 step:61645[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:13 step:61650[D loss: 0.999956] [G loss: 1.000119]\n",
      "epoch:13 step:61655[D loss: 1.000004] [G loss: 1.000007]\n",
      "epoch:13 step:61660[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:13 step:61665[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:13 step:61670[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:13 step:61675[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:13 step:61680[D loss: 1.000008] [G loss: 1.000018]\n",
      "epoch:13 step:61685[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:13 step:61690[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:13 step:61695[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:13 step:61700[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:13 step:61705[D loss: 0.999984] [G loss: 1.000066]\n",
      "epoch:13 step:61710[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:13 step:61715[D loss: 0.999953] [G loss: 1.000133]\n",
      "epoch:13 step:61720[D loss: 0.999920] [G loss: 1.000109]\n",
      "epoch:13 step:61725[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:13 step:61730[D loss: 0.999973] [G loss: 1.000107]\n",
      "epoch:13 step:61735[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:13 step:61740[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:13 step:61745[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:13 step:61750[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:13 step:61755[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:13 step:61760[D loss: 0.999936] [G loss: 1.000128]\n",
      "epoch:13 step:61765[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:13 step:61770[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:13 step:61775[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:13 step:61780[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:13 step:61785[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:13 step:61790[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:13 step:61795[D loss: 1.000018] [G loss: 1.000022]\n",
      "epoch:13 step:61800[D loss: 0.999947] [G loss: 1.000109]\n",
      "epoch:13 step:61805[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:13 step:61810[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:13 step:61815[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:13 step:61820[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:13 step:61825[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:13 step:61830[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:13 step:61835[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:13 step:61840[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:13 step:61845[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:13 step:61850[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:13 step:61855[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:13 step:61860[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:13 step:61865[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:13 step:61870[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:13 step:61875[D loss: 1.000011] [G loss: 1.000040]\n",
      "epoch:13 step:61880[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:13 step:61885[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:13 step:61890[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:13 step:61895[D loss: 1.000014] [G loss: 1.000115]\n",
      "epoch:13 step:61900[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:13 step:61905[D loss: 0.999984] [G loss: 1.000125]\n",
      "epoch:13 step:61910[D loss: 0.999935] [G loss: 1.000133]\n",
      "epoch:13 step:61915[D loss: 0.999983] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:61920[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:13 step:61925[D loss: 0.999990] [G loss: 0.999993]\n",
      "epoch:13 step:61930[D loss: 1.000005] [G loss: 1.000006]\n",
      "epoch:13 step:61935[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:13 step:61940[D loss: 1.000082] [G loss: 0.999847]\n",
      "epoch:13 step:61945[D loss: 0.999954] [G loss: 1.000040]\n",
      "epoch:13 step:61950[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:13 step:61955[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:13 step:61960[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:13 step:61965[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:13 step:61970[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:13 step:61975[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:13 step:61980[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:13 step:61985[D loss: 0.999963] [G loss: 1.000102]\n",
      "epoch:13 step:61990[D loss: 0.999991] [G loss: 1.000238]\n",
      "epoch:13 step:61995[D loss: 0.999930] [G loss: 1.000130]\n",
      "epoch:13 step:62000[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:13 step:62005[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:13 step:62010[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:13 step:62015[D loss: 1.000023] [G loss: 1.000012]\n",
      "epoch:13 step:62020[D loss: 0.999992] [G loss: 1.000025]\n",
      "epoch:13 step:62025[D loss: 0.999966] [G loss: 1.000040]\n",
      "epoch:13 step:62030[D loss: 0.999959] [G loss: 1.000123]\n",
      "epoch:13 step:62035[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:13 step:62040[D loss: 1.000044] [G loss: 0.999998]\n",
      "epoch:13 step:62045[D loss: 0.999905] [G loss: 1.000151]\n",
      "epoch:13 step:62050[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:13 step:62055[D loss: 0.999941] [G loss: 1.000142]\n",
      "epoch:13 step:62060[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:13 step:62065[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:13 step:62070[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:13 step:62075[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:13 step:62080[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:13 step:62085[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:13 step:62090[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:13 step:62095[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:13 step:62100[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:13 step:62105[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:13 step:62110[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:13 step:62115[D loss: 1.000002] [G loss: 1.000026]\n",
      "epoch:13 step:62120[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:13 step:62125[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:13 step:62130[D loss: 1.000028] [G loss: 1.000025]\n",
      "epoch:13 step:62135[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:13 step:62140[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:13 step:62145[D loss: 0.999998] [G loss: 1.000074]\n",
      "epoch:13 step:62150[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:13 step:62155[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:13 step:62160[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:13 step:62165[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:13 step:62170[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:13 step:62175[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:13 step:62180[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:13 step:62185[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:13 step:62190[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:13 step:62195[D loss: 1.000003] [G loss: 1.000085]\n",
      "epoch:13 step:62200[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:13 step:62205[D loss: 0.999944] [G loss: 1.000103]\n",
      "epoch:13 step:62210[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:13 step:62215[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:13 step:62220[D loss: 1.000017] [G loss: 1.000066]\n",
      "epoch:13 step:62225[D loss: 0.999971] [G loss: 1.000080]\n",
      "epoch:13 step:62230[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:13 step:62235[D loss: 1.000020] [G loss: 1.000060]\n",
      "epoch:13 step:62240[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:13 step:62245[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:13 step:62250[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:13 step:62255[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:13 step:62260[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:13 step:62265[D loss: 0.999947] [G loss: 1.000070]\n",
      "epoch:13 step:62270[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:13 step:62275[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:13 step:62280[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:13 step:62285[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:13 step:62290[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:13 step:62295[D loss: 1.000003] [G loss: 1.000030]\n",
      "epoch:13 step:62300[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:13 step:62305[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:13 step:62310[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:13 step:62315[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:13 step:62320[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:13 step:62325[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:13 step:62330[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:13 step:62335[D loss: 1.000007] [G loss: 0.999993]\n",
      "epoch:13 step:62340[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:13 step:62345[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:13 step:62350[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:13 step:62355[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:13 step:62360[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:13 step:62365[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:13 step:62370[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:13 step:62375[D loss: 0.999950] [G loss: 1.000082]\n",
      "epoch:13 step:62380[D loss: 1.000002] [G loss: 1.000056]\n",
      "epoch:13 step:62385[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:13 step:62390[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:13 step:62395[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:13 step:62400[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:13 step:62405[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:13 step:62410[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:13 step:62415[D loss: 1.000005] [G loss: 0.999999]\n",
      "epoch:13 step:62420[D loss: 0.999986] [G loss: 1.000094]\n",
      "epoch:13 step:62425[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:13 step:62430[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:13 step:62435[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:13 step:62440[D loss: 0.999960] [G loss: 1.000063]\n",
      "epoch:13 step:62445[D loss: 0.999992] [G loss: 1.000015]\n",
      "epoch:13 step:62450[D loss: 1.000049] [G loss: 0.999956]\n",
      "epoch:13 step:62455[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:13 step:62460[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:13 step:62465[D loss: 0.999940] [G loss: 1.000074]\n",
      "epoch:13 step:62470[D loss: 0.999996] [G loss: 0.999989]\n",
      "epoch:13 step:62475[D loss: 0.999935] [G loss: 1.000108]\n",
      "epoch:13 step:62480[D loss: 0.999975] [G loss: 1.000110]\n",
      "epoch:13 step:62485[D loss: 1.000030] [G loss: 1.000029]\n",
      "epoch:13 step:62490[D loss: 0.999977] [G loss: 0.999965]\n",
      "epoch:13 step:62495[D loss: 1.000027] [G loss: 0.999974]\n",
      "epoch:13 step:62500[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:13 step:62505[D loss: 0.999957] [G loss: 1.000034]\n",
      "epoch:13 step:62510[D loss: 1.000112] [G loss: 0.999894]\n",
      "epoch:13 step:62515[D loss: 1.000020] [G loss: 1.000004]\n",
      "epoch:13 step:62520[D loss: 1.000053] [G loss: 0.999891]\n",
      "epoch:13 step:62525[D loss: 0.999957] [G loss: 1.000038]\n",
      "epoch:13 step:62530[D loss: 0.999955] [G loss: 1.000064]\n",
      "epoch:13 step:62535[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:13 step:62540[D loss: 0.999984] [G loss: 1.000070]\n",
      "epoch:13 step:62545[D loss: 0.999970] [G loss: 1.000032]\n",
      "epoch:13 step:62550[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:13 step:62555[D loss: 0.999998] [G loss: 1.000003]\n",
      "epoch:13 step:62560[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:13 step:62565[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:13 step:62570[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:13 step:62575[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:13 step:62580[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:13 step:62585[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:13 step:62590[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:13 step:62595[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:13 step:62600[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:13 step:62605[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:13 step:62610[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:13 step:62615[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:13 step:62620[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:13 step:62625[D loss: 1.000003] [G loss: 1.000034]\n",
      "epoch:13 step:62630[D loss: 0.999944] [G loss: 1.000064]\n",
      "epoch:13 step:62635[D loss: 1.000024] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:62640[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:13 step:62645[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:13 step:62650[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:13 step:62655[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:13 step:62660[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:13 step:62665[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:13 step:62670[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:13 step:62675[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:13 step:62680[D loss: 0.999989] [G loss: 1.000072]\n",
      "epoch:13 step:62685[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:13 step:62690[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:13 step:62695[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:13 step:62700[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:13 step:62705[D loss: 0.999961] [G loss: 1.000135]\n",
      "epoch:13 step:62710[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:13 step:62715[D loss: 1.000009] [G loss: 1.000020]\n",
      "epoch:13 step:62720[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:13 step:62725[D loss: 1.000064] [G loss: 0.999994]\n",
      "epoch:13 step:62730[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:13 step:62735[D loss: 0.999916] [G loss: 1.000141]\n",
      "epoch:13 step:62740[D loss: 1.000044] [G loss: 1.000048]\n",
      "epoch:13 step:62745[D loss: 1.000001] [G loss: 1.000031]\n",
      "epoch:13 step:62750[D loss: 0.999998] [G loss: 1.000084]\n",
      "epoch:13 step:62755[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:13 step:62760[D loss: 0.999973] [G loss: 1.000011]\n",
      "epoch:13 step:62765[D loss: 1.000001] [G loss: 0.999975]\n",
      "epoch:13 step:62770[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:13 step:62775[D loss: 0.999997] [G loss: 0.999990]\n",
      "epoch:13 step:62780[D loss: 1.000010] [G loss: 0.999995]\n",
      "epoch:13 step:62785[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:13 step:62790[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:13 step:62795[D loss: 1.000028] [G loss: 1.000107]\n",
      "epoch:13 step:62800[D loss: 0.999967] [G loss: 0.999988]\n",
      "epoch:13 step:62805[D loss: 0.999862] [G loss: 1.000165]\n",
      "epoch:13 step:62810[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:13 step:62815[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:13 step:62820[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:13 step:62825[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:13 step:62830[D loss: 1.000012] [G loss: 1.000091]\n",
      "epoch:13 step:62835[D loss: 0.999914] [G loss: 1.000091]\n",
      "epoch:13 step:62840[D loss: 0.999987] [G loss: 1.000088]\n",
      "epoch:13 step:62845[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:13 step:62850[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:13 step:62855[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:13 step:62860[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:13 step:62865[D loss: 1.000012] [G loss: 1.000104]\n",
      "epoch:13 step:62870[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:13 step:62875[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:13 step:62880[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:13 step:62885[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:13 step:62890[D loss: 1.000013] [G loss: 0.999977]\n",
      "epoch:13 step:62895[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:13 step:62900[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:13 step:62905[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:13 step:62910[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:13 step:62915[D loss: 1.000000] [G loss: 1.000057]\n",
      "epoch:13 step:62920[D loss: 0.999914] [G loss: 1.000199]\n",
      "epoch:13 step:62925[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:13 step:62930[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:13 step:62935[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:13 step:62940[D loss: 0.999997] [G loss: 1.000001]\n",
      "epoch:13 step:62945[D loss: 0.999973] [G loss: 1.000011]\n",
      "epoch:13 step:62950[D loss: 0.999995] [G loss: 1.000007]\n",
      "epoch:13 step:62955[D loss: 0.999986] [G loss: 1.000121]\n",
      "epoch:13 step:62960[D loss: 0.999986] [G loss: 1.000018]\n",
      "epoch:13 step:62965[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:13 step:62970[D loss: 0.999962] [G loss: 1.000046]\n",
      "epoch:13 step:62975[D loss: 0.999997] [G loss: 1.000014]\n",
      "epoch:13 step:62980[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:13 step:62985[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:13 step:62990[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:13 step:62995[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:13 step:63000[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:13 step:63005[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:13 step:63010[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:13 step:63015[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:13 step:63020[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:13 step:63025[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:13 step:63030[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:13 step:63035[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:13 step:63040[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:13 step:63045[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:13 step:63050[D loss: 0.999943] [G loss: 1.000101]\n",
      "epoch:13 step:63055[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:13 step:63060[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:13 step:63065[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:13 step:63070[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:13 step:63075[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:13 step:63080[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:13 step:63085[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:13 step:63090[D loss: 0.999997] [G loss: 1.000028]\n",
      "epoch:13 step:63095[D loss: 1.000023] [G loss: 1.000000]\n",
      "epoch:13 step:63100[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:13 step:63105[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:13 step:63110[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:13 step:63115[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:13 step:63120[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:13 step:63125[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:13 step:63130[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:13 step:63135[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:13 step:63140[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:13 step:63145[D loss: 0.999967] [G loss: 1.000074]\n",
      "epoch:13 step:63150[D loss: 0.999985] [G loss: 1.000013]\n",
      "epoch:13 step:63155[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:13 step:63160[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:13 step:63165[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:13 step:63170[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:13 step:63175[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:13 step:63180[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:13 step:63185[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:13 step:63190[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:13 step:63195[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:13 step:63200[D loss: 1.000107] [G loss: 0.999927]\n",
      "epoch:13 step:63205[D loss: 0.999938] [G loss: 1.000136]\n",
      "epoch:13 step:63210[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:13 step:63215[D loss: 1.000020] [G loss: 1.000019]\n",
      "epoch:13 step:63220[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:13 step:63225[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:13 step:63230[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:13 step:63235[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:13 step:63240[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:13 step:63245[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:13 step:63250[D loss: 0.999928] [G loss: 1.000181]\n",
      "epoch:13 step:63255[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:13 step:63260[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:13 step:63265[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:13 step:63270[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:13 step:63275[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:13 step:63280[D loss: 0.999998] [G loss: 0.999997]\n",
      "epoch:13 step:63285[D loss: 0.999981] [G loss: 1.000015]\n",
      "epoch:13 step:63290[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:13 step:63295[D loss: 0.999997] [G loss: 1.000039]\n",
      "epoch:13 step:63300[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:13 step:63305[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:13 step:63310[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:13 step:63315[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:13 step:63320[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:13 step:63325[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:13 step:63330[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:13 step:63335[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:13 step:63340[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:13 step:63345[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:13 step:63350[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:13 step:63355[D loss: 0.999949] [G loss: 1.000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:63360[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:13 step:63365[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:13 step:63370[D loss: 1.000028] [G loss: 0.999979]\n",
      "epoch:13 step:63375[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:13 step:63380[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:13 step:63385[D loss: 1.000016] [G loss: 1.000132]\n",
      "epoch:13 step:63390[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:13 step:63395[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:13 step:63400[D loss: 1.000028] [G loss: 1.000008]\n",
      "epoch:13 step:63405[D loss: 1.000015] [G loss: 1.000042]\n",
      "epoch:13 step:63410[D loss: 0.999928] [G loss: 1.000069]\n",
      "epoch:13 step:63415[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:13 step:63420[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:13 step:63425[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:13 step:63430[D loss: 1.000000] [G loss: 1.000070]\n",
      "epoch:13 step:63435[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:13 step:63440[D loss: 1.000009] [G loss: 1.000047]\n",
      "epoch:13 step:63445[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:13 step:63450[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:13 step:63455[D loss: 1.000003] [G loss: 1.000191]\n",
      "epoch:13 step:63460[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:13 step:63465[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:13 step:63470[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:13 step:63475[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:13 step:63480[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:13 step:63485[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:13 step:63490[D loss: 1.000041] [G loss: 0.999990]\n",
      "epoch:13 step:63495[D loss: 0.999923] [G loss: 1.000127]\n",
      "epoch:13 step:63500[D loss: 1.000052] [G loss: 0.999923]\n",
      "epoch:13 step:63505[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:13 step:63510[D loss: 0.999942] [G loss: 1.000139]\n",
      "epoch:13 step:63515[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:13 step:63520[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:13 step:63525[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:13 step:63530[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:13 step:63535[D loss: 1.000014] [G loss: 1.000027]\n",
      "epoch:13 step:63540[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:13 step:63545[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:13 step:63550[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:13 step:63555[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:13 step:63560[D loss: 0.999954] [G loss: 1.000091]\n",
      "epoch:13 step:63565[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:13 step:63570[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:13 step:63575[D loss: 1.000006] [G loss: 1.000033]\n",
      "epoch:13 step:63580[D loss: 0.999954] [G loss: 1.000076]\n",
      "epoch:13 step:63585[D loss: 0.999989] [G loss: 1.000115]\n",
      "epoch:13 step:63590[D loss: 1.000026] [G loss: 1.000037]\n",
      "epoch:13 step:63595[D loss: 1.000011] [G loss: 1.000053]\n",
      "epoch:13 step:63600[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:13 step:63605[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:13 step:63610[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:13 step:63615[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:13 step:63620[D loss: 1.000033] [G loss: 1.000024]\n",
      "epoch:13 step:63625[D loss: 1.000007] [G loss: 1.000073]\n",
      "epoch:13 step:63630[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:13 step:63635[D loss: 0.999986] [G loss: 1.000077]\n",
      "epoch:13 step:63640[D loss: 0.999921] [G loss: 1.000123]\n",
      "epoch:13 step:63645[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:13 step:63650[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:13 step:63655[D loss: 1.000003] [G loss: 1.000060]\n",
      "epoch:13 step:63660[D loss: 0.999996] [G loss: 1.000073]\n",
      "epoch:13 step:63665[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:13 step:63670[D loss: 1.000052] [G loss: 0.999988]\n",
      "epoch:13 step:63675[D loss: 0.999920] [G loss: 1.000030]\n",
      "epoch:13 step:63680[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:13 step:63685[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:13 step:63690[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:13 step:63695[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:13 step:63700[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:13 step:63705[D loss: 1.000011] [G loss: 1.000000]\n",
      "epoch:13 step:63710[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:13 step:63715[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:13 step:63720[D loss: 0.999986] [G loss: 1.000094]\n",
      "epoch:13 step:63725[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:13 step:63730[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:13 step:63735[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:13 step:63740[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:13 step:63745[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:13 step:63750[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:13 step:63755[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:13 step:63760[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:13 step:63765[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:13 step:63770[D loss: 1.000003] [G loss: 1.000063]\n",
      "epoch:13 step:63775[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:13 step:63780[D loss: 1.000003] [G loss: 1.000083]\n",
      "epoch:13 step:63785[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:13 step:63790[D loss: 1.000043] [G loss: 0.999947]\n",
      "epoch:13 step:63795[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:13 step:63800[D loss: 1.000012] [G loss: 1.000017]\n",
      "epoch:13 step:63805[D loss: 1.000007] [G loss: 1.000006]\n",
      "epoch:13 step:63810[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:13 step:63815[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:13 step:63820[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:13 step:63825[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:13 step:63830[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:13 step:63835[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:13 step:63840[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:13 step:63845[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:13 step:63850[D loss: 1.000021] [G loss: 1.000081]\n",
      "epoch:13 step:63855[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:13 step:63860[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:13 step:63865[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:13 step:63870[D loss: 1.000017] [G loss: 1.000040]\n",
      "epoch:13 step:63875[D loss: 1.000036] [G loss: 1.000033]\n",
      "epoch:13 step:63880[D loss: 1.000023] [G loss: 1.000072]\n",
      "epoch:13 step:63885[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:13 step:63890[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:13 step:63895[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:13 step:63900[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:13 step:63905[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:13 step:63910[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:13 step:63915[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:13 step:63920[D loss: 0.999929] [G loss: 1.000093]\n",
      "epoch:13 step:63925[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:13 step:63930[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:13 step:63935[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:13 step:63940[D loss: 0.999981] [G loss: 1.000100]\n",
      "epoch:13 step:63945[D loss: 1.000031] [G loss: 0.999961]\n",
      "epoch:13 step:63950[D loss: 1.000026] [G loss: 1.000096]\n",
      "epoch:13 step:63955[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:13 step:63960[D loss: 1.000001] [G loss: 1.000048]\n",
      "epoch:13 step:63965[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:13 step:63970[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:13 step:63975[D loss: 0.999989] [G loss: 1.000010]\n",
      "epoch:13 step:63980[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:13 step:63985[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:13 step:63990[D loss: 1.000018] [G loss: 1.000055]\n",
      "epoch:13 step:63995[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:13 step:64000[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:13 step:64005[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:13 step:64010[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:13 step:64015[D loss: 0.999965] [G loss: 1.000112]\n",
      "epoch:13 step:64020[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:13 step:64025[D loss: 1.000006] [G loss: 1.000027]\n",
      "epoch:13 step:64030[D loss: 0.999992] [G loss: 1.000018]\n",
      "epoch:13 step:64035[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:13 step:64040[D loss: 1.000025] [G loss: 0.999994]\n",
      "epoch:13 step:64045[D loss: 0.999924] [G loss: 1.000135]\n",
      "epoch:13 step:64050[D loss: 1.000005] [G loss: 0.999981]\n",
      "epoch:13 step:64055[D loss: 0.999950] [G loss: 1.000139]\n",
      "epoch:13 step:64060[D loss: 0.999943] [G loss: 1.000100]\n",
      "epoch:13 step:64065[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:13 step:64070[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:13 step:64075[D loss: 0.999982] [G loss: 1.000039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:64080[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:13 step:64085[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:13 step:64090[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:13 step:64095[D loss: 0.999993] [G loss: 0.999989]\n",
      "epoch:13 step:64100[D loss: 0.999942] [G loss: 1.000082]\n",
      "epoch:13 step:64105[D loss: 1.000032] [G loss: 1.000031]\n",
      "epoch:13 step:64110[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:13 step:64115[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:13 step:64120[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:13 step:64125[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:13 step:64130[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:13 step:64135[D loss: 1.000035] [G loss: 1.000002]\n",
      "epoch:13 step:64140[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:13 step:64145[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:13 step:64150[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:13 step:64155[D loss: 0.999992] [G loss: 1.000011]\n",
      "epoch:13 step:64160[D loss: 1.000034] [G loss: 1.000009]\n",
      "epoch:13 step:64165[D loss: 0.999984] [G loss: 1.000027]\n",
      "epoch:13 step:64170[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:13 step:64175[D loss: 0.999984] [G loss: 1.000039]\n",
      "epoch:13 step:64180[D loss: 0.999987] [G loss: 0.999992]\n",
      "epoch:13 step:64185[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:13 step:64190[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:13 step:64195[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:13 step:64200[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:13 step:64205[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:13 step:64210[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:13 step:64215[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:13 step:64220[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:13 step:64225[D loss: 0.999958] [G loss: 1.000063]\n",
      "epoch:13 step:64230[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:13 step:64235[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:13 step:64240[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:13 step:64245[D loss: 0.999979] [G loss: 1.000055]\n",
      "epoch:13 step:64250[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:13 step:64255[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:13 step:64260[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:13 step:64265[D loss: 0.999969] [G loss: 1.000044]\n",
      "epoch:13 step:64270[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:13 step:64275[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:13 step:64280[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:13 step:64285[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:13 step:64290[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:13 step:64295[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:13 step:64300[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:13 step:64305[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:13 step:64310[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:13 step:64315[D loss: 0.999995] [G loss: 1.000016]\n",
      "epoch:13 step:64320[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:13 step:64325[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:13 step:64330[D loss: 1.000037] [G loss: 0.999995]\n",
      "epoch:13 step:64335[D loss: 0.999962] [G loss: 1.000127]\n",
      "epoch:13 step:64340[D loss: 0.999942] [G loss: 1.000096]\n",
      "epoch:13 step:64345[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:13 step:64350[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:13 step:64355[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:13 step:64360[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:13 step:64365[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:13 step:64370[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:13 step:64375[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:13 step:64380[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:13 step:64385[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:13 step:64390[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:13 step:64395[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:13 step:64400[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:13 step:64405[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:13 step:64410[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:13 step:64415[D loss: 0.999966] [G loss: 1.000111]\n",
      "epoch:13 step:64420[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:13 step:64425[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:13 step:64430[D loss: 0.999984] [G loss: 1.000081]\n",
      "epoch:13 step:64435[D loss: 0.999935] [G loss: 1.000148]\n",
      "epoch:13 step:64440[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:13 step:64445[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:13 step:64450[D loss: 1.000026] [G loss: 1.000021]\n",
      "epoch:13 step:64455[D loss: 0.999998] [G loss: 1.000101]\n",
      "epoch:13 step:64460[D loss: 1.000020] [G loss: 0.999943]\n",
      "epoch:13 step:64465[D loss: 0.999952] [G loss: 1.000122]\n",
      "epoch:13 step:64470[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:13 step:64475[D loss: 1.000025] [G loss: 1.000110]\n",
      "epoch:13 step:64480[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:13 step:64485[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:13 step:64490[D loss: 0.999996] [G loss: 1.000003]\n",
      "epoch:13 step:64495[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:13 step:64500[D loss: 1.000006] [G loss: 1.000041]\n",
      "epoch:13 step:64505[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:13 step:64510[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:13 step:64515[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:13 step:64520[D loss: 0.999981] [G loss: 1.000087]\n",
      "epoch:13 step:64525[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:13 step:64530[D loss: 0.999950] [G loss: 1.000083]\n",
      "epoch:13 step:64535[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:13 step:64540[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:13 step:64545[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:13 step:64550[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:13 step:64555[D loss: 0.999996] [G loss: 1.000026]\n",
      "epoch:13 step:64560[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:13 step:64565[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:13 step:64570[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:13 step:64575[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:13 step:64580[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:13 step:64585[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:13 step:64590[D loss: 1.000011] [G loss: 1.000049]\n",
      "epoch:13 step:64595[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:13 step:64600[D loss: 1.000020] [G loss: 1.000014]\n",
      "epoch:13 step:64605[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:13 step:64610[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:13 step:64615[D loss: 1.000016] [G loss: 1.000054]\n",
      "epoch:13 step:64620[D loss: 0.999943] [G loss: 1.000048]\n",
      "epoch:13 step:64625[D loss: 0.999992] [G loss: 0.999995]\n",
      "epoch:13 step:64630[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:13 step:64635[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:13 step:64640[D loss: 0.999954] [G loss: 1.000094]\n",
      "epoch:13 step:64645[D loss: 0.999992] [G loss: 1.000071]\n",
      "epoch:13 step:64650[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:13 step:64655[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:13 step:64660[D loss: 1.000025] [G loss: 0.999984]\n",
      "epoch:13 step:64665[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:13 step:64670[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:13 step:64675[D loss: 0.999961] [G loss: 1.000157]\n",
      "epoch:13 step:64680[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:13 step:64685[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:13 step:64690[D loss: 0.999949] [G loss: 1.000074]\n",
      "epoch:13 step:64695[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:13 step:64700[D loss: 0.999987] [G loss: 1.000008]\n",
      "epoch:13 step:64705[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:13 step:64710[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:13 step:64715[D loss: 0.999983] [G loss: 1.000122]\n",
      "epoch:13 step:64720[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:13 step:64725[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:13 step:64730[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:13 step:64735[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:13 step:64740[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:13 step:64745[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:13 step:64750[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:13 step:64755[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:13 step:64760[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:13 step:64765[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:13 step:64770[D loss: 0.999956] [G loss: 1.000114]\n",
      "epoch:13 step:64775[D loss: 1.000072] [G loss: 0.999970]\n",
      "epoch:13 step:64780[D loss: 0.999944] [G loss: 1.000091]\n",
      "epoch:13 step:64785[D loss: 0.999969] [G loss: 1.000110]\n",
      "epoch:13 step:64790[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:13 step:64795[D loss: 0.999991] [G loss: 1.000041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:64800[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:13 step:64805[D loss: 0.999962] [G loss: 1.000114]\n",
      "epoch:13 step:64810[D loss: 0.999989] [G loss: 1.000038]\n",
      "epoch:13 step:64815[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:13 step:64820[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:13 step:64825[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:13 step:64830[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:13 step:64835[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:13 step:64840[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:13 step:64845[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:13 step:64850[D loss: 0.999981] [G loss: 1.000121]\n",
      "epoch:13 step:64855[D loss: 0.999938] [G loss: 1.000060]\n",
      "epoch:13 step:64860[D loss: 0.999967] [G loss: 1.000007]\n",
      "epoch:13 step:64865[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:13 step:64870[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:13 step:64875[D loss: 0.999985] [G loss: 1.000007]\n",
      "epoch:13 step:64880[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:13 step:64885[D loss: 1.000017] [G loss: 0.999997]\n",
      "epoch:13 step:64890[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:13 step:64895[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:13 step:64900[D loss: 0.999953] [G loss: 1.000059]\n",
      "epoch:13 step:64905[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:13 step:64910[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:13 step:64915[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:13 step:64920[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:13 step:64925[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:13 step:64930[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:13 step:64935[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:13 step:64940[D loss: 0.999981] [G loss: 1.000100]\n",
      "epoch:13 step:64945[D loss: 1.000029] [G loss: 1.000098]\n",
      "epoch:13 step:64950[D loss: 0.999943] [G loss: 1.000082]\n",
      "epoch:13 step:64955[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:13 step:64960[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:13 step:64965[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:13 step:64970[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:13 step:64975[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:13 step:64980[D loss: 0.999978] [G loss: 1.000027]\n",
      "epoch:13 step:64985[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:13 step:64990[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:13 step:64995[D loss: 1.000017] [G loss: 0.999988]\n",
      "epoch:13 step:65000[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:13 step:65005[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:13 step:65010[D loss: 0.999993] [G loss: 1.000045]\n",
      "epoch:13 step:65015[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:13 step:65020[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:13 step:65025[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:13 step:65030[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:13 step:65035[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:13 step:65040[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:13 step:65045[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:13 step:65050[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:13 step:65055[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:13 step:65060[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:13 step:65065[D loss: 1.000037] [G loss: 1.000008]\n",
      "epoch:13 step:65070[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:13 step:65075[D loss: 0.999998] [G loss: 1.000087]\n",
      "epoch:13 step:65080[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:13 step:65085[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:13 step:65090[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:13 step:65095[D loss: 0.999968] [G loss: 1.000035]\n",
      "epoch:13 step:65100[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:13 step:65105[D loss: 0.999929] [G loss: 1.000092]\n",
      "epoch:13 step:65110[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:13 step:65115[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:13 step:65120[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:13 step:65125[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:13 step:65130[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:13 step:65135[D loss: 0.999981] [G loss: 1.000045]\n",
      "epoch:13 step:65140[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:13 step:65145[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:13 step:65150[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:13 step:65155[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:13 step:65160[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:13 step:65165[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:13 step:65170[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:13 step:65175[D loss: 0.999994] [G loss: 1.000014]\n",
      "epoch:13 step:65180[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:13 step:65185[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:13 step:65190[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:13 step:65195[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:13 step:65200[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:13 step:65205[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:13 step:65210[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:13 step:65215[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:13 step:65220[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:13 step:65225[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:13 step:65230[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:13 step:65235[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:13 step:65240[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:13 step:65245[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:13 step:65250[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:13 step:65255[D loss: 0.999987] [G loss: 1.000096]\n",
      "epoch:13 step:65260[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:13 step:65265[D loss: 1.000027] [G loss: 0.999934]\n",
      "epoch:13 step:65270[D loss: 0.999947] [G loss: 1.000053]\n",
      "epoch:13 step:65275[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:13 step:65280[D loss: 1.000048] [G loss: 0.999901]\n",
      "epoch:13 step:65285[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:13 step:65290[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:13 step:65295[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:13 step:65300[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:13 step:65305[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:13 step:65310[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:13 step:65315[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:13 step:65320[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:13 step:65325[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:13 step:65330[D loss: 0.999999] [G loss: 1.000040]\n",
      "epoch:13 step:65335[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:13 step:65340[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:13 step:65345[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:13 step:65350[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:13 step:65355[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:13 step:65360[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:13 step:65365[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:13 step:65370[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:13 step:65375[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:13 step:65380[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:13 step:65385[D loss: 1.000009] [G loss: 1.000001]\n",
      "epoch:13 step:65390[D loss: 0.999950] [G loss: 1.000114]\n",
      "epoch:13 step:65395[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:13 step:65400[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:13 step:65405[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:13 step:65410[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:13 step:65415[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:13 step:65420[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:13 step:65425[D loss: 1.000018] [G loss: 1.000035]\n",
      "epoch:13 step:65430[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:13 step:65435[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:13 step:65440[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:13 step:65445[D loss: 1.000039] [G loss: 0.999971]\n",
      "epoch:13 step:65450[D loss: 0.999947] [G loss: 1.000046]\n",
      "epoch:13 step:65455[D loss: 0.999942] [G loss: 1.000091]\n",
      "epoch:13 step:65460[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:13 step:65465[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:13 step:65470[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:13 step:65475[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:13 step:65480[D loss: 0.999998] [G loss: 1.000025]\n",
      "epoch:13 step:65485[D loss: 0.999952] [G loss: 1.000072]\n",
      "epoch:13 step:65490[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:13 step:65495[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:13 step:65500[D loss: 1.000008] [G loss: 1.000010]\n",
      "epoch:13 step:65505[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:13 step:65510[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:13 step:65515[D loss: 0.999966] [G loss: 1.000029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:65520[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:13 step:65525[D loss: 0.999934] [G loss: 1.000140]\n",
      "epoch:13 step:65530[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:13 step:65535[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:13 step:65540[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:13 step:65545[D loss: 1.000002] [G loss: 1.000001]\n",
      "epoch:13 step:65550[D loss: 0.999954] [G loss: 1.000086]\n",
      "epoch:13 step:65555[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:13 step:65560[D loss: 1.000021] [G loss: 1.000013]\n",
      "epoch:13 step:65565[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:13 step:65570[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:13 step:65575[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:13 step:65580[D loss: 0.999994] [G loss: 1.000054]\n",
      "epoch:13 step:65585[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:13 step:65590[D loss: 0.999959] [G loss: 1.000063]\n",
      "epoch:14 step:65595[D loss: 1.000030] [G loss: 0.999967]\n",
      "epoch:14 step:65600[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:14 step:65605[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:14 step:65610[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:14 step:65615[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:14 step:65620[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:14 step:65625[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:14 step:65630[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:14 step:65635[D loss: 1.000007] [G loss: 1.000040]\n",
      "epoch:14 step:65640[D loss: 1.000025] [G loss: 1.000072]\n",
      "epoch:14 step:65645[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:14 step:65650[D loss: 0.999952] [G loss: 1.000065]\n",
      "epoch:14 step:65655[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:14 step:65660[D loss: 0.999978] [G loss: 1.000063]\n",
      "epoch:14 step:65665[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:14 step:65670[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:14 step:65675[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:14 step:65680[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:14 step:65685[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:14 step:65690[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:14 step:65695[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:14 step:65700[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:14 step:65705[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:14 step:65710[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:14 step:65715[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:14 step:65720[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:14 step:65725[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:14 step:65730[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:14 step:65735[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:14 step:65740[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:14 step:65745[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:14 step:65750[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:14 step:65755[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:14 step:65760[D loss: 1.000032] [G loss: 0.999988]\n",
      "epoch:14 step:65765[D loss: 0.999949] [G loss: 1.000092]\n",
      "epoch:14 step:65770[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:14 step:65775[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:14 step:65780[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:14 step:65785[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:14 step:65790[D loss: 1.000035] [G loss: 1.000027]\n",
      "epoch:14 step:65795[D loss: 1.000019] [G loss: 1.000021]\n",
      "epoch:14 step:65800[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:14 step:65805[D loss: 0.999985] [G loss: 1.000101]\n",
      "epoch:14 step:65810[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:14 step:65815[D loss: 0.999957] [G loss: 1.000116]\n",
      "epoch:14 step:65820[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:14 step:65825[D loss: 1.000008] [G loss: 1.000006]\n",
      "epoch:14 step:65830[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:14 step:65835[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:14 step:65840[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:14 step:65845[D loss: 1.000014] [G loss: 1.000031]\n",
      "epoch:14 step:65850[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:14 step:65855[D loss: 1.000036] [G loss: 1.000042]\n",
      "epoch:14 step:65860[D loss: 0.999948] [G loss: 1.000154]\n",
      "epoch:14 step:65865[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:14 step:65870[D loss: 0.999948] [G loss: 1.000107]\n",
      "epoch:14 step:65875[D loss: 1.000023] [G loss: 1.000014]\n",
      "epoch:14 step:65880[D loss: 1.000008] [G loss: 1.000103]\n",
      "epoch:14 step:65885[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:14 step:65890[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:14 step:65895[D loss: 0.999946] [G loss: 1.000095]\n",
      "epoch:14 step:65900[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:14 step:65905[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:14 step:65910[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:14 step:65915[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:14 step:65920[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:14 step:65925[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:14 step:65930[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:14 step:65935[D loss: 1.000027] [G loss: 1.000060]\n",
      "epoch:14 step:65940[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:14 step:65945[D loss: 0.999952] [G loss: 1.000121]\n",
      "epoch:14 step:65950[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:14 step:65955[D loss: 0.999999] [G loss: 1.000110]\n",
      "epoch:14 step:65960[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:14 step:65965[D loss: 1.000024] [G loss: 0.999989]\n",
      "epoch:14 step:65970[D loss: 0.999992] [G loss: 1.000016]\n",
      "epoch:14 step:65975[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:14 step:65980[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:14 step:65985[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:14 step:65990[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:14 step:65995[D loss: 0.999971] [G loss: 1.000102]\n",
      "epoch:14 step:66000[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:14 step:66005[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:14 step:66010[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:14 step:66015[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:14 step:66020[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:14 step:66025[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:14 step:66030[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:14 step:66035[D loss: 1.000033] [G loss: 0.999976]\n",
      "epoch:14 step:66040[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:14 step:66045[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:14 step:66050[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:14 step:66055[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:14 step:66060[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:14 step:66065[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:14 step:66070[D loss: 0.999986] [G loss: 1.000088]\n",
      "epoch:14 step:66075[D loss: 1.000001] [G loss: 1.000081]\n",
      "epoch:14 step:66080[D loss: 0.999970] [G loss: 1.000107]\n",
      "epoch:14 step:66085[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:14 step:66090[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:14 step:66095[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:14 step:66100[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:14 step:66105[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:14 step:66110[D loss: 0.999961] [G loss: 1.000127]\n",
      "epoch:14 step:66115[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:14 step:66120[D loss: 0.999999] [G loss: 0.999987]\n",
      "epoch:14 step:66125[D loss: 0.999978] [G loss: 1.000115]\n",
      "epoch:14 step:66130[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:14 step:66135[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:14 step:66140[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:14 step:66145[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:14 step:66150[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:14 step:66155[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:14 step:66160[D loss: 1.000007] [G loss: 1.000044]\n",
      "epoch:14 step:66165[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:14 step:66170[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:14 step:66175[D loss: 0.999989] [G loss: 1.000096]\n",
      "epoch:14 step:66180[D loss: 1.000065] [G loss: 0.999989]\n",
      "epoch:14 step:66185[D loss: 1.000005] [G loss: 1.000090]\n",
      "epoch:14 step:66190[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:14 step:66195[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:14 step:66200[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:14 step:66205[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:14 step:66210[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:14 step:66215[D loss: 1.000000] [G loss: 1.000072]\n",
      "epoch:14 step:66220[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:14 step:66225[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:14 step:66230[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:14 step:66235[D loss: 0.999993] [G loss: 1.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:66240[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:14 step:66245[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:14 step:66250[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:14 step:66255[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:14 step:66260[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:14 step:66265[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:14 step:66270[D loss: 0.999970] [G loss: 1.000039]\n",
      "epoch:14 step:66275[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:14 step:66280[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:14 step:66285[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:14 step:66290[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:14 step:66295[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:14 step:66300[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:14 step:66305[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:14 step:66310[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:14 step:66315[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:14 step:66320[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:14 step:66325[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:14 step:66330[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:14 step:66335[D loss: 0.999948] [G loss: 1.000114]\n",
      "epoch:14 step:66340[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:14 step:66345[D loss: 1.000002] [G loss: 1.000008]\n",
      "epoch:14 step:66350[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:14 step:66355[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:14 step:66360[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:14 step:66365[D loss: 0.999958] [G loss: 1.000133]\n",
      "epoch:14 step:66370[D loss: 0.999953] [G loss: 1.000143]\n",
      "epoch:14 step:66375[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:14 step:66380[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:14 step:66385[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:14 step:66390[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:14 step:66395[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:14 step:66400[D loss: 1.000011] [G loss: 1.000008]\n",
      "epoch:14 step:66405[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:14 step:66410[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:14 step:66415[D loss: 1.000008] [G loss: 1.000036]\n",
      "epoch:14 step:66420[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:14 step:66425[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:14 step:66430[D loss: 0.999984] [G loss: 1.000101]\n",
      "epoch:14 step:66435[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:14 step:66440[D loss: 0.999995] [G loss: 1.000022]\n",
      "epoch:14 step:66445[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:14 step:66450[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:14 step:66455[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:14 step:66460[D loss: 0.999973] [G loss: 1.000052]\n",
      "epoch:14 step:66465[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:14 step:66470[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:14 step:66475[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:14 step:66480[D loss: 1.000057] [G loss: 1.000016]\n",
      "epoch:14 step:66485[D loss: 1.000001] [G loss: 1.000101]\n",
      "epoch:14 step:66490[D loss: 0.999943] [G loss: 1.000086]\n",
      "epoch:14 step:66495[D loss: 0.999923] [G loss: 1.000187]\n",
      "epoch:14 step:66500[D loss: 0.999927] [G loss: 1.000157]\n",
      "epoch:14 step:66505[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:14 step:66510[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:14 step:66515[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:14 step:66520[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:14 step:66525[D loss: 1.000024] [G loss: 0.999971]\n",
      "epoch:14 step:66530[D loss: 1.000022] [G loss: 0.999995]\n",
      "epoch:14 step:66535[D loss: 0.999977] [G loss: 1.000015]\n",
      "epoch:14 step:66540[D loss: 0.999943] [G loss: 1.000114]\n",
      "epoch:14 step:66545[D loss: 1.000002] [G loss: 0.999980]\n",
      "epoch:14 step:66550[D loss: 0.999941] [G loss: 1.000101]\n",
      "epoch:14 step:66555[D loss: 0.999983] [G loss: 1.000117]\n",
      "epoch:14 step:66560[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:14 step:66565[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:14 step:66570[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:14 step:66575[D loss: 1.000009] [G loss: 1.000049]\n",
      "epoch:14 step:66580[D loss: 0.999999] [G loss: 1.000077]\n",
      "epoch:14 step:66585[D loss: 1.000028] [G loss: 1.000007]\n",
      "epoch:14 step:66590[D loss: 1.000052] [G loss: 1.000082]\n",
      "epoch:14 step:66595[D loss: 0.999938] [G loss: 1.000141]\n",
      "epoch:14 step:66600[D loss: 0.999942] [G loss: 1.000128]\n",
      "epoch:14 step:66605[D loss: 0.999927] [G loss: 1.000125]\n",
      "epoch:14 step:66610[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:14 step:66615[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:14 step:66620[D loss: 1.000000] [G loss: 1.000015]\n",
      "epoch:14 step:66625[D loss: 1.000002] [G loss: 1.000077]\n",
      "epoch:14 step:66630[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:14 step:66635[D loss: 1.000043] [G loss: 0.999979]\n",
      "epoch:14 step:66640[D loss: 1.000020] [G loss: 0.999980]\n",
      "epoch:14 step:66645[D loss: 0.999932] [G loss: 1.000110]\n",
      "epoch:14 step:66650[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:14 step:66655[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:14 step:66660[D loss: 1.000066] [G loss: 0.999940]\n",
      "epoch:14 step:66665[D loss: 0.999963] [G loss: 1.000137]\n",
      "epoch:14 step:66670[D loss: 0.999965] [G loss: 1.000128]\n",
      "epoch:14 step:66675[D loss: 1.000021] [G loss: 1.000188]\n",
      "epoch:14 step:66680[D loss: 0.999928] [G loss: 1.000154]\n",
      "epoch:14 step:66685[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:14 step:66690[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:14 step:66695[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:14 step:66700[D loss: 1.000015] [G loss: 0.999978]\n",
      "epoch:14 step:66705[D loss: 1.000038] [G loss: 0.999954]\n",
      "epoch:14 step:66710[D loss: 1.000020] [G loss: 0.999892]\n",
      "epoch:14 step:66715[D loss: 0.999970] [G loss: 1.000108]\n",
      "epoch:14 step:66720[D loss: 0.999961] [G loss: 1.000198]\n",
      "epoch:14 step:66725[D loss: 1.000002] [G loss: 1.000155]\n",
      "epoch:14 step:66730[D loss: 0.999924] [G loss: 1.000127]\n",
      "epoch:14 step:66735[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:14 step:66740[D loss: 1.000037] [G loss: 1.000028]\n",
      "epoch:14 step:66745[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:14 step:66750[D loss: 0.999940] [G loss: 1.000100]\n",
      "epoch:14 step:66755[D loss: 0.999959] [G loss: 1.000105]\n",
      "epoch:14 step:66760[D loss: 1.000009] [G loss: 1.000072]\n",
      "epoch:14 step:66765[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:14 step:66770[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:14 step:66775[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:14 step:66780[D loss: 1.000001] [G loss: 1.000013]\n",
      "epoch:14 step:66785[D loss: 0.999954] [G loss: 1.000045]\n",
      "epoch:14 step:66790[D loss: 0.999965] [G loss: 1.000021]\n",
      "epoch:14 step:66795[D loss: 1.000080] [G loss: 0.999925]\n",
      "epoch:14 step:66800[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:14 step:66805[D loss: 1.000020] [G loss: 0.999993]\n",
      "epoch:14 step:66810[D loss: 0.999944] [G loss: 1.000184]\n",
      "epoch:14 step:66815[D loss: 0.999936] [G loss: 1.000112]\n",
      "epoch:14 step:66820[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:14 step:66825[D loss: 0.999946] [G loss: 1.000062]\n",
      "epoch:14 step:66830[D loss: 1.000036] [G loss: 1.000030]\n",
      "epoch:14 step:66835[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:14 step:66840[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:14 step:66845[D loss: 1.000001] [G loss: 0.999995]\n",
      "epoch:14 step:66850[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:14 step:66855[D loss: 1.000030] [G loss: 0.999998]\n",
      "epoch:14 step:66860[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:14 step:66865[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:14 step:66870[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:14 step:66875[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:14 step:66880[D loss: 1.000017] [G loss: 1.000102]\n",
      "epoch:14 step:66885[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:14 step:66890[D loss: 1.000001] [G loss: 1.000045]\n",
      "epoch:14 step:66895[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:14 step:66900[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:14 step:66905[D loss: 1.000129] [G loss: 0.999879]\n",
      "epoch:14 step:66910[D loss: 0.999917] [G loss: 1.000107]\n",
      "epoch:14 step:66915[D loss: 0.999988] [G loss: 1.000003]\n",
      "epoch:14 step:66920[D loss: 1.000031] [G loss: 1.000065]\n",
      "epoch:14 step:66925[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:14 step:66930[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:14 step:66935[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:14 step:66940[D loss: 1.000014] [G loss: 0.999997]\n",
      "epoch:14 step:66945[D loss: 0.999953] [G loss: 1.000052]\n",
      "epoch:14 step:66950[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:14 step:66955[D loss: 0.999976] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:66960[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:14 step:66965[D loss: 1.000018] [G loss: 0.999987]\n",
      "epoch:14 step:66970[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:14 step:66975[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:14 step:66980[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:14 step:66985[D loss: 0.999963] [G loss: 1.000098]\n",
      "epoch:14 step:66990[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:14 step:66995[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:14 step:67000[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:14 step:67005[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:14 step:67010[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:14 step:67015[D loss: 0.999954] [G loss: 1.000058]\n",
      "epoch:14 step:67020[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:14 step:67025[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:14 step:67030[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:14 step:67035[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:14 step:67040[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:14 step:67045[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:14 step:67050[D loss: 1.000005] [G loss: 1.000017]\n",
      "epoch:14 step:67055[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:14 step:67060[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:14 step:67065[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:14 step:67070[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:14 step:67075[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:14 step:67080[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:14 step:67085[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:14 step:67090[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:14 step:67095[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:14 step:67100[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:14 step:67105[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:14 step:67110[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:14 step:67115[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:14 step:67120[D loss: 1.000023] [G loss: 1.000013]\n",
      "epoch:14 step:67125[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:14 step:67130[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:14 step:67135[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:14 step:67140[D loss: 1.000010] [G loss: 1.000010]\n",
      "epoch:14 step:67145[D loss: 1.000055] [G loss: 0.999996]\n",
      "epoch:14 step:67150[D loss: 0.999958] [G loss: 1.000038]\n",
      "epoch:14 step:67155[D loss: 0.999933] [G loss: 1.000119]\n",
      "epoch:14 step:67160[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:14 step:67165[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:14 step:67170[D loss: 1.000028] [G loss: 1.000034]\n",
      "epoch:14 step:67175[D loss: 1.000009] [G loss: 1.000014]\n",
      "epoch:14 step:67180[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:14 step:67185[D loss: 1.000009] [G loss: 1.000036]\n",
      "epoch:14 step:67190[D loss: 0.999927] [G loss: 1.000096]\n",
      "epoch:14 step:67195[D loss: 1.000040] [G loss: 1.000027]\n",
      "epoch:14 step:67200[D loss: 0.999993] [G loss: 1.000100]\n",
      "epoch:14 step:67205[D loss: 1.000007] [G loss: 1.000086]\n",
      "epoch:14 step:67210[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:14 step:67215[D loss: 0.999955] [G loss: 1.000056]\n",
      "epoch:14 step:67220[D loss: 0.999970] [G loss: 1.000036]\n",
      "epoch:14 step:67225[D loss: 1.000032] [G loss: 0.999993]\n",
      "epoch:14 step:67230[D loss: 0.999965] [G loss: 1.000008]\n",
      "epoch:14 step:67235[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:14 step:67240[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:14 step:67245[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:14 step:67250[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:14 step:67255[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:14 step:67260[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:14 step:67265[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:14 step:67270[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:14 step:67275[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:14 step:67280[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:14 step:67285[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:14 step:67290[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:14 step:67295[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:14 step:67300[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:14 step:67305[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:14 step:67310[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:14 step:67315[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:14 step:67320[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:14 step:67325[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:14 step:67330[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:14 step:67335[D loss: 1.000023] [G loss: 0.999995]\n",
      "epoch:14 step:67340[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:14 step:67345[D loss: 0.999954] [G loss: 1.000114]\n",
      "epoch:14 step:67350[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:14 step:67355[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:14 step:67360[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:14 step:67365[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:14 step:67370[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:14 step:67375[D loss: 0.999938] [G loss: 1.000109]\n",
      "epoch:14 step:67380[D loss: 1.000092] [G loss: 0.999920]\n",
      "epoch:14 step:67385[D loss: 0.999927] [G loss: 1.000109]\n",
      "epoch:14 step:67390[D loss: 0.999996] [G loss: 1.000119]\n",
      "epoch:14 step:67395[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:14 step:67400[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:14 step:67405[D loss: 1.000020] [G loss: 1.000054]\n",
      "epoch:14 step:67410[D loss: 0.999962] [G loss: 1.000242]\n",
      "epoch:14 step:67415[D loss: 1.000015] [G loss: 0.999988]\n",
      "epoch:14 step:67420[D loss: 1.000074] [G loss: 0.999958]\n",
      "epoch:14 step:67425[D loss: 0.999994] [G loss: 1.000157]\n",
      "epoch:14 step:67430[D loss: 0.999910] [G loss: 1.000195]\n",
      "epoch:14 step:67435[D loss: 1.000016] [G loss: 1.000061]\n",
      "epoch:14 step:67440[D loss: 0.999907] [G loss: 1.000153]\n",
      "epoch:14 step:67445[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:14 step:67450[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:14 step:67455[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:14 step:67460[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:14 step:67465[D loss: 1.000012] [G loss: 0.999993]\n",
      "epoch:14 step:67470[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:14 step:67475[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:14 step:67480[D loss: 1.000025] [G loss: 1.000141]\n",
      "epoch:14 step:67485[D loss: 0.999970] [G loss: 1.000035]\n",
      "epoch:14 step:67490[D loss: 0.999974] [G loss: 1.000017]\n",
      "epoch:14 step:67495[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:14 step:67500[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:14 step:67505[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:14 step:67510[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:14 step:67515[D loss: 1.000083] [G loss: 0.999980]\n",
      "epoch:14 step:67520[D loss: 0.999966] [G loss: 0.999953]\n",
      "epoch:14 step:67525[D loss: 1.000028] [G loss: 0.999987]\n",
      "epoch:14 step:67530[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:14 step:67535[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:14 step:67540[D loss: 0.999962] [G loss: 1.000141]\n",
      "epoch:14 step:67545[D loss: 0.999928] [G loss: 1.000094]\n",
      "epoch:14 step:67550[D loss: 0.999989] [G loss: 1.000094]\n",
      "epoch:14 step:67555[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:14 step:67560[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:14 step:67565[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:14 step:67570[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:14 step:67575[D loss: 1.000029] [G loss: 0.999987]\n",
      "epoch:14 step:67580[D loss: 0.999999] [G loss: 1.000002]\n",
      "epoch:14 step:67585[D loss: 0.999937] [G loss: 1.000131]\n",
      "epoch:14 step:67590[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:14 step:67595[D loss: 1.000023] [G loss: 0.999973]\n",
      "epoch:14 step:67600[D loss: 0.999941] [G loss: 1.000137]\n",
      "epoch:14 step:67605[D loss: 0.999936] [G loss: 1.000132]\n",
      "epoch:14 step:67610[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:14 step:67615[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:14 step:67620[D loss: 1.000002] [G loss: 0.999978]\n",
      "epoch:14 step:67625[D loss: 1.000073] [G loss: 0.999921]\n",
      "epoch:14 step:67630[D loss: 0.999920] [G loss: 1.000083]\n",
      "epoch:14 step:67635[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:14 step:67640[D loss: 1.000016] [G loss: 1.000097]\n",
      "epoch:14 step:67645[D loss: 0.999926] [G loss: 1.000125]\n",
      "epoch:14 step:67650[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:14 step:67655[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:14 step:67660[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:14 step:67665[D loss: 0.999962] [G loss: 1.000022]\n",
      "epoch:14 step:67670[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:14 step:67675[D loss: 0.999988] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:67680[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:14 step:67685[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:14 step:67690[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:14 step:67695[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:14 step:67700[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:14 step:67705[D loss: 0.999928] [G loss: 1.000151]\n",
      "epoch:14 step:67710[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:14 step:67715[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:14 step:67720[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:14 step:67725[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:14 step:67730[D loss: 1.000010] [G loss: 1.000012]\n",
      "epoch:14 step:67735[D loss: 1.000025] [G loss: 0.999983]\n",
      "epoch:14 step:67740[D loss: 0.999986] [G loss: 1.000028]\n",
      "epoch:14 step:67745[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:14 step:67750[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:14 step:67755[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:14 step:67760[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:14 step:67765[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:14 step:67770[D loss: 1.000014] [G loss: 1.000053]\n",
      "epoch:14 step:67775[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:14 step:67780[D loss: 1.000009] [G loss: 0.999997]\n",
      "epoch:14 step:67785[D loss: 0.999965] [G loss: 1.000028]\n",
      "epoch:14 step:67790[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:14 step:67795[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:14 step:67800[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:14 step:67805[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:14 step:67810[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:14 step:67815[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:14 step:67820[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:14 step:67825[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:14 step:67830[D loss: 0.999990] [G loss: 1.000093]\n",
      "epoch:14 step:67835[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:14 step:67840[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:14 step:67845[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:14 step:67850[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:14 step:67855[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:14 step:67860[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:14 step:67865[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:14 step:67870[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:14 step:67875[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:14 step:67880[D loss: 1.000003] [G loss: 1.000061]\n",
      "epoch:14 step:67885[D loss: 1.000055] [G loss: 1.000064]\n",
      "epoch:14 step:67890[D loss: 0.999937] [G loss: 1.000133]\n",
      "epoch:14 step:67895[D loss: 0.999937] [G loss: 1.000116]\n",
      "epoch:14 step:67900[D loss: 0.999997] [G loss: 1.000002]\n",
      "epoch:14 step:67905[D loss: 0.999960] [G loss: 1.000054]\n",
      "epoch:14 step:67910[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:14 step:67915[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:14 step:67920[D loss: 0.999997] [G loss: 0.999993]\n",
      "epoch:14 step:67925[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:14 step:67930[D loss: 1.000031] [G loss: 1.000101]\n",
      "epoch:14 step:67935[D loss: 1.000032] [G loss: 1.000082]\n",
      "epoch:14 step:67940[D loss: 0.999944] [G loss: 1.000085]\n",
      "epoch:14 step:67945[D loss: 0.999929] [G loss: 1.000144]\n",
      "epoch:14 step:67950[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:14 step:67955[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:14 step:67960[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:14 step:67965[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:14 step:67970[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:14 step:67975[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:14 step:67980[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:14 step:67985[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:14 step:67990[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:14 step:67995[D loss: 0.999953] [G loss: 1.000102]\n",
      "epoch:14 step:68000[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:14 step:68005[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:14 step:68010[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:14 step:68015[D loss: 1.000024] [G loss: 1.000048]\n",
      "epoch:14 step:68020[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:14 step:68025[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:14 step:68030[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:14 step:68035[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:14 step:68040[D loss: 0.999959] [G loss: 1.000118]\n",
      "epoch:14 step:68045[D loss: 0.999968] [G loss: 1.000097]\n",
      "epoch:14 step:68050[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:14 step:68055[D loss: 0.999995] [G loss: 1.000079]\n",
      "epoch:14 step:68060[D loss: 1.000002] [G loss: 1.000085]\n",
      "epoch:14 step:68065[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:14 step:68070[D loss: 1.000053] [G loss: 1.000039]\n",
      "epoch:14 step:68075[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:14 step:68080[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:14 step:68085[D loss: 1.000006] [G loss: 1.000036]\n",
      "epoch:14 step:68090[D loss: 0.999968] [G loss: 1.000117]\n",
      "epoch:14 step:68095[D loss: 0.999934] [G loss: 1.000086]\n",
      "epoch:14 step:68100[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:14 step:68105[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:14 step:68110[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:14 step:68115[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:14 step:68120[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:14 step:68125[D loss: 0.999957] [G loss: 1.000123]\n",
      "epoch:14 step:68130[D loss: 0.999983] [G loss: 1.000089]\n",
      "epoch:14 step:68135[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:14 step:68140[D loss: 1.000065] [G loss: 1.000073]\n",
      "epoch:14 step:68145[D loss: 0.999967] [G loss: 1.000105]\n",
      "epoch:14 step:68150[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:14 step:68155[D loss: 0.999994] [G loss: 1.000041]\n",
      "epoch:14 step:68160[D loss: 1.000019] [G loss: 0.999940]\n",
      "epoch:14 step:68165[D loss: 0.999950] [G loss: 1.000063]\n",
      "epoch:14 step:68170[D loss: 0.999997] [G loss: 1.000016]\n",
      "epoch:14 step:68175[D loss: 1.000043] [G loss: 1.000028]\n",
      "epoch:14 step:68180[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:14 step:68185[D loss: 0.999977] [G loss: 1.000114]\n",
      "epoch:14 step:68190[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:14 step:68195[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:14 step:68200[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:14 step:68205[D loss: 0.999971] [G loss: 1.000033]\n",
      "epoch:14 step:68210[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:14 step:68215[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:14 step:68220[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:14 step:68225[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:14 step:68230[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:14 step:68235[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:14 step:68240[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:14 step:68245[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:14 step:68250[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:14 step:68255[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:14 step:68260[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:14 step:68265[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:14 step:68270[D loss: 1.000019] [G loss: 0.999978]\n",
      "epoch:14 step:68275[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:14 step:68280[D loss: 0.999988] [G loss: 1.000091]\n",
      "epoch:14 step:68285[D loss: 1.000012] [G loss: 1.000019]\n",
      "epoch:14 step:68290[D loss: 0.999984] [G loss: 1.000015]\n",
      "epoch:14 step:68295[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:14 step:68300[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:14 step:68305[D loss: 1.000031] [G loss: 0.999994]\n",
      "epoch:14 step:68310[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:14 step:68315[D loss: 0.999937] [G loss: 1.000158]\n",
      "epoch:14 step:68320[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:14 step:68325[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:14 step:68330[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:14 step:68335[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:14 step:68340[D loss: 1.000036] [G loss: 1.000020]\n",
      "epoch:14 step:68345[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:14 step:68350[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:14 step:68355[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:14 step:68360[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:14 step:68365[D loss: 0.999967] [G loss: 1.000031]\n",
      "epoch:14 step:68370[D loss: 0.999995] [G loss: 1.000012]\n",
      "epoch:14 step:68375[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:14 step:68380[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:14 step:68385[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:14 step:68390[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:14 step:68395[D loss: 0.999963] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:68400[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:14 step:68405[D loss: 1.000008] [G loss: 1.000008]\n",
      "epoch:14 step:68410[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:14 step:68415[D loss: 1.000026] [G loss: 0.999952]\n",
      "epoch:14 step:68420[D loss: 0.999975] [G loss: 1.000029]\n",
      "epoch:14 step:68425[D loss: 0.999952] [G loss: 1.000046]\n",
      "epoch:14 step:68430[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:14 step:68435[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:14 step:68440[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:14 step:68445[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:14 step:68450[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:14 step:68455[D loss: 1.000032] [G loss: 1.000050]\n",
      "epoch:14 step:68460[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:14 step:68465[D loss: 0.999986] [G loss: 1.000108]\n",
      "epoch:14 step:68470[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:14 step:68475[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:14 step:68480[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:14 step:68485[D loss: 1.000010] [G loss: 0.999998]\n",
      "epoch:14 step:68490[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:14 step:68495[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:14 step:68500[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:14 step:68505[D loss: 1.000014] [G loss: 1.000018]\n",
      "epoch:14 step:68510[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:14 step:68515[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:14 step:68520[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:14 step:68525[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:14 step:68530[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:14 step:68535[D loss: 1.000001] [G loss: 1.000046]\n",
      "epoch:14 step:68540[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:14 step:68545[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:14 step:68550[D loss: 0.999971] [G loss: 1.000133]\n",
      "epoch:14 step:68555[D loss: 1.000063] [G loss: 1.000016]\n",
      "epoch:14 step:68560[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:14 step:68565[D loss: 1.000019] [G loss: 1.000097]\n",
      "epoch:14 step:68570[D loss: 0.999936] [G loss: 1.000143]\n",
      "epoch:14 step:68575[D loss: 0.999934] [G loss: 1.000117]\n",
      "epoch:14 step:68580[D loss: 0.999978] [G loss: 1.000043]\n",
      "epoch:14 step:68585[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:14 step:68590[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:14 step:68595[D loss: 1.000069] [G loss: 0.999900]\n",
      "epoch:14 step:68600[D loss: 1.000025] [G loss: 0.999987]\n",
      "epoch:14 step:68605[D loss: 0.999981] [G loss: 0.999962]\n",
      "epoch:14 step:68610[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:14 step:68615[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:14 step:68620[D loss: 1.000005] [G loss: 1.000022]\n",
      "epoch:14 step:68625[D loss: 1.000012] [G loss: 1.000017]\n",
      "epoch:14 step:68630[D loss: 1.000008] [G loss: 0.999994]\n",
      "epoch:14 step:68635[D loss: 1.000022] [G loss: 1.000071]\n",
      "epoch:14 step:68640[D loss: 0.999956] [G loss: 1.000050]\n",
      "epoch:14 step:68645[D loss: 0.999938] [G loss: 1.000140]\n",
      "epoch:14 step:68650[D loss: 1.000045] [G loss: 0.999988]\n",
      "epoch:14 step:68655[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:14 step:68660[D loss: 0.999956] [G loss: 1.000041]\n",
      "epoch:14 step:68665[D loss: 1.000011] [G loss: 1.000025]\n",
      "epoch:14 step:68670[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:14 step:68675[D loss: 1.000062] [G loss: 0.999979]\n",
      "epoch:14 step:68680[D loss: 0.999951] [G loss: 1.000131]\n",
      "epoch:14 step:68685[D loss: 0.999928] [G loss: 1.000064]\n",
      "epoch:14 step:68690[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:14 step:68695[D loss: 0.999945] [G loss: 1.000107]\n",
      "epoch:14 step:68700[D loss: 1.000014] [G loss: 1.000032]\n",
      "epoch:14 step:68705[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:14 step:68710[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:14 step:68715[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:14 step:68720[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:14 step:68725[D loss: 1.000031] [G loss: 0.999994]\n",
      "epoch:14 step:68730[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:14 step:68735[D loss: 1.000010] [G loss: 0.999988]\n",
      "epoch:14 step:68740[D loss: 0.999962] [G loss: 1.000110]\n",
      "epoch:14 step:68745[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:14 step:68750[D loss: 1.000001] [G loss: 1.000058]\n",
      "epoch:14 step:68755[D loss: 0.999941] [G loss: 1.000120]\n",
      "epoch:14 step:68760[D loss: 0.999953] [G loss: 1.000036]\n",
      "epoch:14 step:68765[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:14 step:68770[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:14 step:68775[D loss: 0.999960] [G loss: 1.000112]\n",
      "epoch:14 step:68780[D loss: 0.999948] [G loss: 1.000054]\n",
      "epoch:14 step:68785[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:14 step:68790[D loss: 0.999977] [G loss: 1.000043]\n",
      "epoch:14 step:68795[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:14 step:68800[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:14 step:68805[D loss: 1.000000] [G loss: 0.999994]\n",
      "epoch:14 step:68810[D loss: 0.999998] [G loss: 1.000013]\n",
      "epoch:14 step:68815[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:14 step:68820[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:14 step:68825[D loss: 0.999946] [G loss: 1.000061]\n",
      "epoch:14 step:68830[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:14 step:68835[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:14 step:68840[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:14 step:68845[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:14 step:68850[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:14 step:68855[D loss: 0.999964] [G loss: 1.000095]\n",
      "epoch:14 step:68860[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:14 step:68865[D loss: 0.999993] [G loss: 1.000013]\n",
      "epoch:14 step:68870[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:14 step:68875[D loss: 1.000023] [G loss: 0.999977]\n",
      "epoch:14 step:68880[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:14 step:68885[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:14 step:68890[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:14 step:68895[D loss: 1.000020] [G loss: 1.000001]\n",
      "epoch:14 step:68900[D loss: 1.000031] [G loss: 1.000027]\n",
      "epoch:14 step:68905[D loss: 0.999907] [G loss: 1.000179]\n",
      "epoch:14 step:68910[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:14 step:68915[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:14 step:68920[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:14 step:68925[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:14 step:68930[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:14 step:68935[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:14 step:68940[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:14 step:68945[D loss: 0.999979] [G loss: 1.000025]\n",
      "epoch:14 step:68950[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:14 step:68955[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:14 step:68960[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:14 step:68965[D loss: 0.999986] [G loss: 1.000050]\n",
      "epoch:14 step:68970[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:14 step:68975[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:14 step:68980[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:14 step:68985[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:14 step:68990[D loss: 1.000008] [G loss: 0.999966]\n",
      "epoch:14 step:68995[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:14 step:69000[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:14 step:69005[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:14 step:69010[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:14 step:69015[D loss: 1.000063] [G loss: 0.999898]\n",
      "epoch:14 step:69020[D loss: 1.000009] [G loss: 1.000017]\n",
      "epoch:14 step:69025[D loss: 0.999994] [G loss: 0.999967]\n",
      "epoch:14 step:69030[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:14 step:69035[D loss: 0.999954] [G loss: 1.000147]\n",
      "epoch:14 step:69040[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:14 step:69045[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:14 step:69050[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:14 step:69055[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:14 step:69060[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:14 step:69065[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:14 step:69070[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:14 step:69075[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:14 step:69080[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:14 step:69085[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:14 step:69090[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:14 step:69095[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:14 step:69100[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:14 step:69105[D loss: 0.999990] [G loss: 1.000076]\n",
      "epoch:14 step:69110[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:14 step:69115[D loss: 0.999985] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:69120[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:14 step:69125[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:14 step:69130[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:14 step:69135[D loss: 1.000070] [G loss: 0.999953]\n",
      "epoch:14 step:69140[D loss: 1.000052] [G loss: 1.000017]\n",
      "epoch:14 step:69145[D loss: 0.999919] [G loss: 1.000171]\n",
      "epoch:14 step:69150[D loss: 1.000029] [G loss: 0.999967]\n",
      "epoch:14 step:69155[D loss: 0.999994] [G loss: 1.000033]\n",
      "epoch:14 step:69160[D loss: 1.000043] [G loss: 1.000028]\n",
      "epoch:14 step:69165[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:14 step:69170[D loss: 0.999995] [G loss: 1.000023]\n",
      "epoch:14 step:69175[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:14 step:69180[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:14 step:69185[D loss: 1.000018] [G loss: 1.000027]\n",
      "epoch:14 step:69190[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:14 step:69195[D loss: 0.999965] [G loss: 1.000110]\n",
      "epoch:14 step:69200[D loss: 0.999927] [G loss: 1.000215]\n",
      "epoch:14 step:69205[D loss: 0.999986] [G loss: 1.000058]\n",
      "epoch:14 step:69210[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:14 step:69215[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:14 step:69220[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:14 step:69225[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:14 step:69230[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:14 step:69235[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:14 step:69240[D loss: 1.000056] [G loss: 0.999935]\n",
      "epoch:14 step:69245[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:14 step:69250[D loss: 1.000023] [G loss: 1.000010]\n",
      "epoch:14 step:69255[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:14 step:69260[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:14 step:69265[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:14 step:69270[D loss: 1.000022] [G loss: 1.000033]\n",
      "epoch:14 step:69275[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:14 step:69280[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:14 step:69285[D loss: 1.000003] [G loss: 1.000070]\n",
      "epoch:14 step:69290[D loss: 0.999939] [G loss: 1.000105]\n",
      "epoch:14 step:69295[D loss: 0.999992] [G loss: 1.000087]\n",
      "epoch:14 step:69300[D loss: 1.000123] [G loss: 0.999945]\n",
      "epoch:14 step:69305[D loss: 0.999922] [G loss: 1.000088]\n",
      "epoch:14 step:69310[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:14 step:69315[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:14 step:69320[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:14 step:69325[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:14 step:69330[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:14 step:69335[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:14 step:69340[D loss: 0.999990] [G loss: 1.000080]\n",
      "epoch:14 step:69345[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:14 step:69350[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:14 step:69355[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:14 step:69360[D loss: 0.999963] [G loss: 1.000173]\n",
      "epoch:14 step:69365[D loss: 0.999948] [G loss: 1.000106]\n",
      "epoch:14 step:69370[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:14 step:69375[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:14 step:69380[D loss: 1.000005] [G loss: 0.999985]\n",
      "epoch:14 step:69385[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:14 step:69390[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:14 step:69395[D loss: 0.999955] [G loss: 1.000113]\n",
      "epoch:14 step:69400[D loss: 1.000038] [G loss: 1.000053]\n",
      "epoch:14 step:69405[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:14 step:69410[D loss: 0.999957] [G loss: 1.000112]\n",
      "epoch:14 step:69415[D loss: 0.999921] [G loss: 1.000143]\n",
      "epoch:14 step:69420[D loss: 0.999975] [G loss: 1.000092]\n",
      "epoch:14 step:69425[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:14 step:69430[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:14 step:69435[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:14 step:69440[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:14 step:69445[D loss: 1.000035] [G loss: 0.999994]\n",
      "epoch:14 step:69450[D loss: 0.999990] [G loss: 1.000086]\n",
      "epoch:14 step:69455[D loss: 0.999994] [G loss: 1.000071]\n",
      "epoch:14 step:69460[D loss: 0.999995] [G loss: 1.000096]\n",
      "epoch:14 step:69465[D loss: 0.999904] [G loss: 1.000122]\n",
      "epoch:14 step:69470[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:14 step:69475[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:14 step:69480[D loss: 1.000017] [G loss: 1.000006]\n",
      "epoch:14 step:69485[D loss: 1.000066] [G loss: 0.999917]\n",
      "epoch:14 step:69490[D loss: 1.000004] [G loss: 1.000045]\n",
      "epoch:14 step:69495[D loss: 0.999952] [G loss: 0.999992]\n",
      "epoch:14 step:69500[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:14 step:69505[D loss: 0.999976] [G loss: 1.000112]\n",
      "epoch:14 step:69510[D loss: 0.999938] [G loss: 1.000188]\n",
      "epoch:14 step:69515[D loss: 0.999942] [G loss: 1.000118]\n",
      "epoch:14 step:69520[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:14 step:69525[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:14 step:69530[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:14 step:69535[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:14 step:69540[D loss: 1.000014] [G loss: 1.000032]\n",
      "epoch:14 step:69545[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:14 step:69550[D loss: 0.999984] [G loss: 1.000031]\n",
      "epoch:14 step:69555[D loss: 0.999992] [G loss: 1.000039]\n",
      "epoch:14 step:69560[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:14 step:69565[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:14 step:69570[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:14 step:69575[D loss: 0.999947] [G loss: 1.000102]\n",
      "epoch:14 step:69580[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:14 step:69585[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:14 step:69590[D loss: 1.000005] [G loss: 1.000025]\n",
      "epoch:14 step:69595[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:14 step:69600[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:14 step:69605[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:14 step:69610[D loss: 1.000013] [G loss: 1.000014]\n",
      "epoch:14 step:69615[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:14 step:69620[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:14 step:69625[D loss: 1.000000] [G loss: 1.000077]\n",
      "epoch:14 step:69630[D loss: 1.000003] [G loss: 1.000132]\n",
      "epoch:14 step:69635[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:14 step:69640[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:14 step:69645[D loss: 1.000004] [G loss: 1.000005]\n",
      "epoch:14 step:69650[D loss: 1.000011] [G loss: 0.999962]\n",
      "epoch:14 step:69655[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:14 step:69660[D loss: 1.000004] [G loss: 0.999997]\n",
      "epoch:14 step:69665[D loss: 0.999971] [G loss: 1.000026]\n",
      "epoch:14 step:69670[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:14 step:69675[D loss: 0.999939] [G loss: 1.000098]\n",
      "epoch:14 step:69680[D loss: 1.000007] [G loss: 1.000020]\n",
      "epoch:14 step:69685[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:14 step:69690[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:14 step:69695[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:14 step:69700[D loss: 0.999962] [G loss: 1.000099]\n",
      "epoch:14 step:69705[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:14 step:69710[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:14 step:69715[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:14 step:69720[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:14 step:69725[D loss: 0.999952] [G loss: 1.000087]\n",
      "epoch:14 step:69730[D loss: 0.999963] [G loss: 1.000087]\n",
      "epoch:14 step:69735[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:14 step:69740[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:14 step:69745[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:14 step:69750[D loss: 1.000000] [G loss: 1.000041]\n",
      "epoch:14 step:69755[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:14 step:69760[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:14 step:69765[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:14 step:69770[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:14 step:69775[D loss: 0.999992] [G loss: 1.000067]\n",
      "epoch:14 step:69780[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:14 step:69785[D loss: 1.000020] [G loss: 1.000058]\n",
      "epoch:14 step:69790[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:14 step:69795[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:14 step:69800[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:14 step:69805[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:14 step:69810[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:14 step:69815[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:14 step:69820[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:14 step:69825[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:14 step:69830[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:14 step:69835[D loss: 0.999996] [G loss: 1.000037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:69840[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:14 step:69845[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:14 step:69850[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:14 step:69855[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:14 step:69860[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:14 step:69865[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:14 step:69870[D loss: 0.999998] [G loss: 1.000050]\n",
      "epoch:14 step:69875[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:14 step:69880[D loss: 0.999986] [G loss: 1.000026]\n",
      "epoch:14 step:69885[D loss: 0.999998] [G loss: 1.000072]\n",
      "epoch:14 step:69890[D loss: 0.999971] [G loss: 1.000021]\n",
      "epoch:14 step:69895[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:14 step:69900[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:14 step:69905[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:14 step:69910[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:14 step:69915[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:14 step:69920[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:14 step:69925[D loss: 1.000040] [G loss: 0.999974]\n",
      "epoch:14 step:69930[D loss: 0.999998] [G loss: 1.000003]\n",
      "epoch:14 step:69935[D loss: 1.000015] [G loss: 0.999996]\n",
      "epoch:14 step:69940[D loss: 1.000047] [G loss: 0.999998]\n",
      "epoch:14 step:69945[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:14 step:69950[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:14 step:69955[D loss: 0.999945] [G loss: 1.000084]\n",
      "epoch:14 step:69960[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:14 step:69965[D loss: 1.000019] [G loss: 0.999996]\n",
      "epoch:14 step:69970[D loss: 0.999949] [G loss: 1.000124]\n",
      "epoch:14 step:69975[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:14 step:69980[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:14 step:69985[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:14 step:69990[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:14 step:69995[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:14 step:70000[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:14 step:70005[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:14 step:70010[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:14 step:70015[D loss: 1.000004] [G loss: 1.000051]\n",
      "epoch:14 step:70020[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:14 step:70025[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:14 step:70030[D loss: 0.999999] [G loss: 1.000004]\n",
      "epoch:14 step:70035[D loss: 1.000021] [G loss: 1.000013]\n",
      "epoch:14 step:70040[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:14 step:70045[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:14 step:70050[D loss: 0.999988] [G loss: 1.000004]\n",
      "epoch:14 step:70055[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:14 step:70060[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:14 step:70065[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:14 step:70070[D loss: 1.000051] [G loss: 1.000019]\n",
      "epoch:14 step:70075[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:14 step:70080[D loss: 0.999969] [G loss: 1.000030]\n",
      "epoch:14 step:70085[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:14 step:70090[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:14 step:70095[D loss: 1.000027] [G loss: 1.000044]\n",
      "epoch:14 step:70100[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:14 step:70105[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:14 step:70110[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:14 step:70115[D loss: 0.999992] [G loss: 0.999993]\n",
      "epoch:14 step:70120[D loss: 0.999988] [G loss: 1.000097]\n",
      "epoch:14 step:70125[D loss: 0.999951] [G loss: 1.000058]\n",
      "epoch:14 step:70130[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:14 step:70135[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:14 step:70140[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:14 step:70145[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:14 step:70150[D loss: 0.999999] [G loss: 1.000011]\n",
      "epoch:14 step:70155[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:14 step:70160[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:14 step:70165[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:14 step:70170[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:14 step:70175[D loss: 0.999973] [G loss: 1.000153]\n",
      "epoch:14 step:70180[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:14 step:70185[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:14 step:70190[D loss: 0.999959] [G loss: 1.000089]\n",
      "epoch:14 step:70195[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:14 step:70200[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:14 step:70205[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:14 step:70210[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:14 step:70215[D loss: 0.999998] [G loss: 0.999961]\n",
      "epoch:14 step:70220[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:14 step:70225[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:14 step:70230[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:14 step:70235[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:14 step:70240[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:14 step:70245[D loss: 0.999981] [G loss: 1.000073]\n",
      "epoch:14 step:70250[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:14 step:70255[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:14 step:70260[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:14 step:70265[D loss: 1.000015] [G loss: 1.000033]\n",
      "epoch:14 step:70270[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:14 step:70275[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:15 step:70280[D loss: 1.000004] [G loss: 1.000040]\n",
      "epoch:15 step:70285[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:15 step:70290[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:15 step:70295[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:15 step:70300[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:15 step:70305[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:15 step:70310[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:15 step:70315[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:15 step:70320[D loss: 1.000018] [G loss: 1.000016]\n",
      "epoch:15 step:70325[D loss: 1.000052] [G loss: 0.999987]\n",
      "epoch:15 step:70330[D loss: 1.000016] [G loss: 0.999996]\n",
      "epoch:15 step:70335[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:15 step:70340[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:15 step:70345[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:15 step:70350[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:15 step:70355[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:15 step:70360[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:15 step:70365[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:15 step:70370[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:15 step:70375[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:15 step:70380[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:15 step:70385[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:15 step:70390[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:15 step:70395[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:15 step:70400[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:15 step:70405[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:15 step:70410[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:15 step:70415[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:15 step:70420[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:15 step:70425[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:15 step:70430[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:15 step:70435[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:15 step:70440[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:15 step:70445[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:15 step:70450[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:15 step:70455[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:15 step:70460[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:15 step:70465[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:15 step:70470[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:15 step:70475[D loss: 1.000014] [G loss: 1.000022]\n",
      "epoch:15 step:70480[D loss: 1.000002] [G loss: 0.999982]\n",
      "epoch:15 step:70485[D loss: 1.000001] [G loss: 0.999962]\n",
      "epoch:15 step:70490[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:15 step:70495[D loss: 0.999993] [G loss: 0.999998]\n",
      "epoch:15 step:70500[D loss: 0.999987] [G loss: 1.000077]\n",
      "epoch:15 step:70505[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:15 step:70510[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:15 step:70515[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:15 step:70520[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:15 step:70525[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:15 step:70530[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:15 step:70535[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:15 step:70540[D loss: 1.000001] [G loss: 1.000062]\n",
      "epoch:15 step:70545[D loss: 1.000016] [G loss: 0.999985]\n",
      "epoch:15 step:70550[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:15 step:70555[D loss: 0.999947] [G loss: 1.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:70560[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:15 step:70565[D loss: 0.999971] [G loss: 1.000101]\n",
      "epoch:15 step:70570[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:15 step:70575[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:15 step:70580[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:15 step:70585[D loss: 1.000006] [G loss: 1.000032]\n",
      "epoch:15 step:70590[D loss: 1.000022] [G loss: 1.000039]\n",
      "epoch:15 step:70595[D loss: 1.000052] [G loss: 0.999935]\n",
      "epoch:15 step:70600[D loss: 0.999937] [G loss: 1.000130]\n",
      "epoch:15 step:70605[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:15 step:70610[D loss: 0.999954] [G loss: 1.000060]\n",
      "epoch:15 step:70615[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:15 step:70620[D loss: 1.000024] [G loss: 1.000092]\n",
      "epoch:15 step:70625[D loss: 1.000077] [G loss: 0.999935]\n",
      "epoch:15 step:70630[D loss: 1.000031] [G loss: 0.999963]\n",
      "epoch:15 step:70635[D loss: 1.000006] [G loss: 1.000095]\n",
      "epoch:15 step:70640[D loss: 0.999908] [G loss: 1.000188]\n",
      "epoch:15 step:70645[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:15 step:70650[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:15 step:70655[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:15 step:70660[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:15 step:70665[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:15 step:70670[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:15 step:70675[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:15 step:70680[D loss: 1.000029] [G loss: 1.000000]\n",
      "epoch:15 step:70685[D loss: 0.999918] [G loss: 1.000127]\n",
      "epoch:15 step:70690[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:15 step:70695[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:15 step:70700[D loss: 0.999997] [G loss: 1.000007]\n",
      "epoch:15 step:70705[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:15 step:70710[D loss: 0.999985] [G loss: 1.000019]\n",
      "epoch:15 step:70715[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:15 step:70720[D loss: 1.000037] [G loss: 1.000071]\n",
      "epoch:15 step:70725[D loss: 0.999930] [G loss: 1.000103]\n",
      "epoch:15 step:70730[D loss: 0.999961] [G loss: 1.000038]\n",
      "epoch:15 step:70735[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:15 step:70740[D loss: 1.000030] [G loss: 0.999978]\n",
      "epoch:15 step:70745[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:15 step:70750[D loss: 1.000112] [G loss: 0.999957]\n",
      "epoch:15 step:70755[D loss: 0.999963] [G loss: 1.000148]\n",
      "epoch:15 step:70760[D loss: 0.999967] [G loss: 1.000168]\n",
      "epoch:15 step:70765[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:15 step:70770[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:15 step:70775[D loss: 0.999936] [G loss: 1.000123]\n",
      "epoch:15 step:70780[D loss: 0.999986] [G loss: 1.000066]\n",
      "epoch:15 step:70785[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:15 step:70790[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:15 step:70795[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:15 step:70800[D loss: 1.000017] [G loss: 1.000000]\n",
      "epoch:15 step:70805[D loss: 0.999982] [G loss: 1.000016]\n",
      "epoch:15 step:70810[D loss: 1.000022] [G loss: 1.000011]\n",
      "epoch:15 step:70815[D loss: 0.999954] [G loss: 1.000149]\n",
      "epoch:15 step:70820[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:15 step:70825[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:15 step:70830[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:15 step:70835[D loss: 0.999962] [G loss: 1.000107]\n",
      "epoch:15 step:70840[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:15 step:70845[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:15 step:70850[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:15 step:70855[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:15 step:70860[D loss: 1.000055] [G loss: 0.999963]\n",
      "epoch:15 step:70865[D loss: 1.000051] [G loss: 0.999997]\n",
      "epoch:15 step:70870[D loss: 1.000094] [G loss: 0.999952]\n",
      "epoch:15 step:70875[D loss: 0.999912] [G loss: 1.000176]\n",
      "epoch:15 step:70880[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:15 step:70885[D loss: 0.999987] [G loss: 1.000098]\n",
      "epoch:15 step:70890[D loss: 0.999958] [G loss: 1.000114]\n",
      "epoch:15 step:70895[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:15 step:70900[D loss: 1.000011] [G loss: 1.000007]\n",
      "epoch:15 step:70905[D loss: 0.999990] [G loss: 0.999965]\n",
      "epoch:15 step:70910[D loss: 1.000004] [G loss: 1.000111]\n",
      "epoch:15 step:70915[D loss: 1.000017] [G loss: 0.999958]\n",
      "epoch:15 step:70920[D loss: 1.000042] [G loss: 0.999974]\n",
      "epoch:15 step:70925[D loss: 0.999948] [G loss: 1.000057]\n",
      "epoch:15 step:70930[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:15 step:70935[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:15 step:70940[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:15 step:70945[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:15 step:70950[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:15 step:70955[D loss: 1.000033] [G loss: 0.999997]\n",
      "epoch:15 step:70960[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:15 step:70965[D loss: 0.999932] [G loss: 1.000132]\n",
      "epoch:15 step:70970[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:15 step:70975[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:15 step:70980[D loss: 0.999950] [G loss: 1.000161]\n",
      "epoch:15 step:70985[D loss: 1.000012] [G loss: 1.000031]\n",
      "epoch:15 step:70990[D loss: 0.999942] [G loss: 1.000112]\n",
      "epoch:15 step:70995[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:15 step:71000[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:15 step:71005[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:15 step:71010[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:15 step:71015[D loss: 0.999994] [G loss: 1.000081]\n",
      "epoch:15 step:71020[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:15 step:71025[D loss: 0.999953] [G loss: 1.000110]\n",
      "epoch:15 step:71030[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:15 step:71035[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:15 step:71040[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:15 step:71045[D loss: 0.999984] [G loss: 1.000091]\n",
      "epoch:15 step:71050[D loss: 0.999987] [G loss: 1.000116]\n",
      "epoch:15 step:71055[D loss: 0.999946] [G loss: 1.000204]\n",
      "epoch:15 step:71060[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:15 step:71065[D loss: 1.000011] [G loss: 1.000002]\n",
      "epoch:15 step:71070[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:15 step:71075[D loss: 1.000032] [G loss: 1.000019]\n",
      "epoch:15 step:71080[D loss: 1.000032] [G loss: 1.000010]\n",
      "epoch:15 step:71085[D loss: 1.000007] [G loss: 1.000064]\n",
      "epoch:15 step:71090[D loss: 0.999950] [G loss: 1.000096]\n",
      "epoch:15 step:71095[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:15 step:71100[D loss: 0.999946] [G loss: 1.000082]\n",
      "epoch:15 step:71105[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:15 step:71110[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:15 step:71115[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:15 step:71120[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:15 step:71125[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:15 step:71130[D loss: 0.999945] [G loss: 1.000116]\n",
      "epoch:15 step:71135[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:15 step:71140[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:15 step:71145[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:15 step:71150[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:15 step:71155[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:15 step:71160[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:15 step:71165[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:15 step:71170[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:15 step:71175[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:15 step:71180[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:15 step:71185[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:15 step:71190[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:15 step:71195[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:15 step:71200[D loss: 1.000045] [G loss: 0.999949]\n",
      "epoch:15 step:71205[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:15 step:71210[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:15 step:71215[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:15 step:71220[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:15 step:71225[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:15 step:71230[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:15 step:71235[D loss: 0.999965] [G loss: 1.000043]\n",
      "epoch:15 step:71240[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:15 step:71245[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:15 step:71250[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:15 step:71255[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:15 step:71260[D loss: 1.000016] [G loss: 1.000064]\n",
      "epoch:15 step:71265[D loss: 1.000035] [G loss: 1.000057]\n",
      "epoch:15 step:71270[D loss: 0.999859] [G loss: 1.000212]\n",
      "epoch:15 step:71275[D loss: 1.000025] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:71280[D loss: 0.999927] [G loss: 1.000134]\n",
      "epoch:15 step:71285[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:15 step:71290[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:15 step:71295[D loss: 1.000002] [G loss: 1.000060]\n",
      "epoch:15 step:71300[D loss: 1.000006] [G loss: 1.000029]\n",
      "epoch:15 step:71305[D loss: 1.000026] [G loss: 0.999925]\n",
      "epoch:15 step:71310[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:15 step:71315[D loss: 0.999922] [G loss: 1.000111]\n",
      "epoch:15 step:71320[D loss: 0.999963] [G loss: 1.000137]\n",
      "epoch:15 step:71325[D loss: 1.000009] [G loss: 1.000062]\n",
      "epoch:15 step:71330[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:15 step:71335[D loss: 0.999940] [G loss: 1.000147]\n",
      "epoch:15 step:71340[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:15 step:71345[D loss: 1.000003] [G loss: 1.000089]\n",
      "epoch:15 step:71350[D loss: 0.999995] [G loss: 1.000090]\n",
      "epoch:15 step:71355[D loss: 1.000003] [G loss: 1.000080]\n",
      "epoch:15 step:71360[D loss: 1.000054] [G loss: 1.000169]\n",
      "epoch:15 step:71365[D loss: 1.000007] [G loss: 1.000017]\n",
      "epoch:15 step:71370[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:15 step:71375[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:15 step:71380[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:15 step:71385[D loss: 1.000057] [G loss: 0.999944]\n",
      "epoch:15 step:71390[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:15 step:71395[D loss: 0.999943] [G loss: 1.000098]\n",
      "epoch:15 step:71400[D loss: 0.999993] [G loss: 1.000110]\n",
      "epoch:15 step:71405[D loss: 1.000113] [G loss: 0.999923]\n",
      "epoch:15 step:71410[D loss: 1.000039] [G loss: 1.000082]\n",
      "epoch:15 step:71415[D loss: 1.000056] [G loss: 0.999836]\n",
      "epoch:15 step:71420[D loss: 0.999910] [G loss: 1.000120]\n",
      "epoch:15 step:71425[D loss: 0.999995] [G loss: 1.000145]\n",
      "epoch:15 step:71430[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:15 step:71435[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:15 step:71440[D loss: 0.999969] [G loss: 1.000146]\n",
      "epoch:15 step:71445[D loss: 1.000001] [G loss: 1.000086]\n",
      "epoch:15 step:71450[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:15 step:71455[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:15 step:71460[D loss: 0.999997] [G loss: 1.000048]\n",
      "epoch:15 step:71465[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:15 step:71470[D loss: 0.999998] [G loss: 0.999998]\n",
      "epoch:15 step:71475[D loss: 1.000029] [G loss: 0.999932]\n",
      "epoch:15 step:71480[D loss: 1.000024] [G loss: 1.000045]\n",
      "epoch:15 step:71485[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:15 step:71490[D loss: 1.000034] [G loss: 1.000003]\n",
      "epoch:15 step:71495[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:15 step:71500[D loss: 0.999974] [G loss: 1.000151]\n",
      "epoch:15 step:71505[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:15 step:71510[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:15 step:71515[D loss: 1.000006] [G loss: 1.000102]\n",
      "epoch:15 step:71520[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:15 step:71525[D loss: 0.999959] [G loss: 1.000074]\n",
      "epoch:15 step:71530[D loss: 1.000001] [G loss: 0.999997]\n",
      "epoch:15 step:71535[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:15 step:71540[D loss: 1.000013] [G loss: 1.000021]\n",
      "epoch:15 step:71545[D loss: 0.999952] [G loss: 1.000018]\n",
      "epoch:15 step:71550[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:15 step:71555[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:15 step:71560[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:15 step:71565[D loss: 0.999982] [G loss: 1.000150]\n",
      "epoch:15 step:71570[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:15 step:71575[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:15 step:71580[D loss: 0.999942] [G loss: 1.000098]\n",
      "epoch:15 step:71585[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:15 step:71590[D loss: 1.000006] [G loss: 1.000089]\n",
      "epoch:15 step:71595[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:15 step:71600[D loss: 0.999964] [G loss: 1.000040]\n",
      "epoch:15 step:71605[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:15 step:71610[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:15 step:71615[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:15 step:71620[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:15 step:71625[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:15 step:71630[D loss: 0.999946] [G loss: 1.000075]\n",
      "epoch:15 step:71635[D loss: 1.000001] [G loss: 1.000100]\n",
      "epoch:15 step:71640[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:15 step:71645[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:15 step:71650[D loss: 1.000004] [G loss: 1.000007]\n",
      "epoch:15 step:71655[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:15 step:71660[D loss: 0.999952] [G loss: 1.000037]\n",
      "epoch:15 step:71665[D loss: 0.999942] [G loss: 1.000148]\n",
      "epoch:15 step:71670[D loss: 0.999995] [G loss: 1.000002]\n",
      "epoch:15 step:71675[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:15 step:71680[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:15 step:71685[D loss: 1.000007] [G loss: 1.000010]\n",
      "epoch:15 step:71690[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:15 step:71695[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:15 step:71700[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:15 step:71705[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:15 step:71710[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:15 step:71715[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:15 step:71720[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:15 step:71725[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:15 step:71730[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:15 step:71735[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:15 step:71740[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:15 step:71745[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:15 step:71750[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:15 step:71755[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:15 step:71760[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:15 step:71765[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:15 step:71770[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:15 step:71775[D loss: 1.000000] [G loss: 1.000022]\n",
      "epoch:15 step:71780[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:15 step:71785[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:15 step:71790[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:15 step:71795[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:15 step:71800[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:15 step:71805[D loss: 1.000022] [G loss: 0.999999]\n",
      "epoch:15 step:71810[D loss: 0.999948] [G loss: 1.000072]\n",
      "epoch:15 step:71815[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:15 step:71820[D loss: 1.000013] [G loss: 1.000006]\n",
      "epoch:15 step:71825[D loss: 1.000007] [G loss: 0.999986]\n",
      "epoch:15 step:71830[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:15 step:71835[D loss: 0.999994] [G loss: 0.999999]\n",
      "epoch:15 step:71840[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:15 step:71845[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:15 step:71850[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:15 step:71855[D loss: 1.000016] [G loss: 1.000046]\n",
      "epoch:15 step:71860[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:15 step:71865[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:15 step:71870[D loss: 1.000029] [G loss: 1.000017]\n",
      "epoch:15 step:71875[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:15 step:71880[D loss: 1.000047] [G loss: 1.000041]\n",
      "epoch:15 step:71885[D loss: 1.000135] [G loss: 0.999762]\n",
      "epoch:15 step:71890[D loss: 1.000020] [G loss: 1.000026]\n",
      "epoch:15 step:71895[D loss: 0.999930] [G loss: 1.000118]\n",
      "epoch:15 step:71900[D loss: 0.999949] [G loss: 0.999999]\n",
      "epoch:15 step:71905[D loss: 0.999952] [G loss: 1.000052]\n",
      "epoch:15 step:71910[D loss: 1.000028] [G loss: 1.000014]\n",
      "epoch:15 step:71915[D loss: 0.999931] [G loss: 1.000084]\n",
      "epoch:15 step:71920[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:15 step:71925[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:15 step:71930[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:15 step:71935[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:15 step:71940[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:15 step:71945[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:15 step:71950[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:15 step:71955[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:15 step:71960[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:15 step:71965[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:15 step:71970[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:15 step:71975[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:15 step:71980[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:15 step:71985[D loss: 0.999980] [G loss: 1.000015]\n",
      "epoch:15 step:71990[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:15 step:71995[D loss: 0.999992] [G loss: 1.000034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:72000[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:15 step:72005[D loss: 1.000021] [G loss: 1.000067]\n",
      "epoch:15 step:72010[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:15 step:72015[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:15 step:72020[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:15 step:72025[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:15 step:72030[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:15 step:72035[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:15 step:72040[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:15 step:72045[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:15 step:72050[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:15 step:72055[D loss: 0.999990] [G loss: 1.000016]\n",
      "epoch:15 step:72060[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:15 step:72065[D loss: 1.000064] [G loss: 0.999962]\n",
      "epoch:15 step:72070[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:15 step:72075[D loss: 1.000001] [G loss: 1.000082]\n",
      "epoch:15 step:72080[D loss: 0.999936] [G loss: 1.000118]\n",
      "epoch:15 step:72085[D loss: 0.999990] [G loss: 0.999987]\n",
      "epoch:15 step:72090[D loss: 1.000073] [G loss: 0.999909]\n",
      "epoch:15 step:72095[D loss: 1.000074] [G loss: 0.999966]\n",
      "epoch:15 step:72100[D loss: 1.000007] [G loss: 1.000045]\n",
      "epoch:15 step:72105[D loss: 0.999994] [G loss: 1.000072]\n",
      "epoch:15 step:72110[D loss: 1.000036] [G loss: 1.000051]\n",
      "epoch:15 step:72115[D loss: 1.000023] [G loss: 0.999982]\n",
      "epoch:15 step:72120[D loss: 0.999946] [G loss: 1.000135]\n",
      "epoch:15 step:72125[D loss: 0.999947] [G loss: 1.000111]\n",
      "epoch:15 step:72130[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:15 step:72135[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:15 step:72140[D loss: 0.999993] [G loss: 1.000016]\n",
      "epoch:15 step:72145[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:15 step:72150[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:15 step:72155[D loss: 1.000014] [G loss: 1.000004]\n",
      "epoch:15 step:72160[D loss: 1.000005] [G loss: 1.000042]\n",
      "epoch:15 step:72165[D loss: 1.000010] [G loss: 1.000157]\n",
      "epoch:15 step:72170[D loss: 0.999893] [G loss: 1.000135]\n",
      "epoch:15 step:72175[D loss: 0.999941] [G loss: 1.000047]\n",
      "epoch:15 step:72180[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:15 step:72185[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:15 step:72190[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:15 step:72195[D loss: 0.999968] [G loss: 1.000025]\n",
      "epoch:15 step:72200[D loss: 1.000028] [G loss: 0.999971]\n",
      "epoch:15 step:72205[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:15 step:72210[D loss: 1.000006] [G loss: 1.000080]\n",
      "epoch:15 step:72215[D loss: 0.999955] [G loss: 1.000138]\n",
      "epoch:15 step:72220[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:15 step:72225[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:15 step:72230[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:15 step:72235[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:15 step:72240[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:15 step:72245[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:15 step:72250[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:15 step:72255[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:15 step:72260[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:15 step:72265[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:15 step:72270[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:15 step:72275[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:15 step:72280[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:15 step:72285[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:15 step:72290[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:15 step:72295[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:15 step:72300[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:15 step:72305[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:15 step:72310[D loss: 1.000019] [G loss: 1.000006]\n",
      "epoch:15 step:72315[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:15 step:72320[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:15 step:72325[D loss: 1.000001] [G loss: 1.000069]\n",
      "epoch:15 step:72330[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:15 step:72335[D loss: 1.000029] [G loss: 1.000033]\n",
      "epoch:15 step:72340[D loss: 0.999994] [G loss: 1.000001]\n",
      "epoch:15 step:72345[D loss: 1.000058] [G loss: 0.999926]\n",
      "epoch:15 step:72350[D loss: 0.999946] [G loss: 1.000079]\n",
      "epoch:15 step:72355[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:15 step:72360[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:15 step:72365[D loss: 0.999942] [G loss: 1.000114]\n",
      "epoch:15 step:72370[D loss: 0.999927] [G loss: 1.000117]\n",
      "epoch:15 step:72375[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:15 step:72380[D loss: 1.000010] [G loss: 1.000061]\n",
      "epoch:15 step:72385[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:15 step:72390[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:15 step:72395[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:15 step:72400[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:15 step:72405[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:15 step:72410[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:15 step:72415[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:15 step:72420[D loss: 0.999947] [G loss: 1.000114]\n",
      "epoch:15 step:72425[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:15 step:72430[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:15 step:72435[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:15 step:72440[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:15 step:72445[D loss: 1.000008] [G loss: 1.000043]\n",
      "epoch:15 step:72450[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:15 step:72455[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:15 step:72460[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:15 step:72465[D loss: 1.000017] [G loss: 0.999997]\n",
      "epoch:15 step:72470[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:15 step:72475[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:15 step:72480[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:15 step:72485[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:15 step:72490[D loss: 0.999983] [G loss: 1.000043]\n",
      "epoch:15 step:72495[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:15 step:72500[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:15 step:72505[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:15 step:72510[D loss: 1.000002] [G loss: 1.000038]\n",
      "epoch:15 step:72515[D loss: 0.999981] [G loss: 1.000055]\n",
      "epoch:15 step:72520[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:15 step:72525[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:15 step:72530[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:15 step:72535[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:15 step:72540[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:15 step:72545[D loss: 0.999995] [G loss: 1.000091]\n",
      "epoch:15 step:72550[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:15 step:72555[D loss: 0.999925] [G loss: 1.000120]\n",
      "epoch:15 step:72560[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:15 step:72565[D loss: 0.999992] [G loss: 1.000087]\n",
      "epoch:15 step:72570[D loss: 1.000080] [G loss: 1.000088]\n",
      "epoch:15 step:72575[D loss: 0.999935] [G loss: 1.000103]\n",
      "epoch:15 step:72580[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:15 step:72585[D loss: 1.000067] [G loss: 0.999898]\n",
      "epoch:15 step:72590[D loss: 0.999995] [G loss: 0.999978]\n",
      "epoch:15 step:72595[D loss: 0.999998] [G loss: 1.000090]\n",
      "epoch:15 step:72600[D loss: 1.000005] [G loss: 1.000010]\n",
      "epoch:15 step:72605[D loss: 0.999910] [G loss: 1.000130]\n",
      "epoch:15 step:72610[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:15 step:72615[D loss: 0.999979] [G loss: 1.000075]\n",
      "epoch:15 step:72620[D loss: 0.999990] [G loss: 1.000113]\n",
      "epoch:15 step:72625[D loss: 0.999971] [G loss: 1.000132]\n",
      "epoch:15 step:72630[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:15 step:72635[D loss: 0.999938] [G loss: 1.000136]\n",
      "epoch:15 step:72640[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:15 step:72645[D loss: 1.000021] [G loss: 0.999993]\n",
      "epoch:15 step:72650[D loss: 1.000005] [G loss: 0.999994]\n",
      "epoch:15 step:72655[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:15 step:72660[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:15 step:72665[D loss: 1.000013] [G loss: 1.000058]\n",
      "epoch:15 step:72670[D loss: 0.999933] [G loss: 1.000080]\n",
      "epoch:15 step:72675[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:15 step:72680[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:15 step:72685[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:15 step:72690[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:15 step:72695[D loss: 1.000037] [G loss: 0.999949]\n",
      "epoch:15 step:72700[D loss: 1.000163] [G loss: 0.999797]\n",
      "epoch:15 step:72705[D loss: 0.999922] [G loss: 1.000132]\n",
      "epoch:15 step:72710[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:15 step:72715[D loss: 0.999976] [G loss: 1.000144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:72720[D loss: 0.999954] [G loss: 1.000148]\n",
      "epoch:15 step:72725[D loss: 0.999940] [G loss: 1.000210]\n",
      "epoch:15 step:72730[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:15 step:72735[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:15 step:72740[D loss: 1.000032] [G loss: 1.000059]\n",
      "epoch:15 step:72745[D loss: 0.999962] [G loss: 1.000179]\n",
      "epoch:15 step:72750[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:15 step:72755[D loss: 1.000021] [G loss: 1.000104]\n",
      "epoch:15 step:72760[D loss: 1.000015] [G loss: 1.000037]\n",
      "epoch:15 step:72765[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:15 step:72770[D loss: 1.000034] [G loss: 0.999978]\n",
      "epoch:15 step:72775[D loss: 1.000007] [G loss: 1.000095]\n",
      "epoch:15 step:72780[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:15 step:72785[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:15 step:72790[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:15 step:72795[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:15 step:72800[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:15 step:72805[D loss: 0.999975] [G loss: 1.000078]\n",
      "epoch:15 step:72810[D loss: 0.999997] [G loss: 1.000083]\n",
      "epoch:15 step:72815[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:15 step:72820[D loss: 1.000013] [G loss: 0.999993]\n",
      "epoch:15 step:72825[D loss: 1.000016] [G loss: 1.000220]\n",
      "epoch:15 step:72830[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:15 step:72835[D loss: 0.999940] [G loss: 1.000112]\n",
      "epoch:15 step:72840[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:15 step:72845[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:15 step:72850[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:15 step:72855[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:15 step:72860[D loss: 1.000047] [G loss: 0.999977]\n",
      "epoch:15 step:72865[D loss: 0.999984] [G loss: 0.999998]\n",
      "epoch:15 step:72870[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:15 step:72875[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:15 step:72880[D loss: 0.999954] [G loss: 1.000091]\n",
      "epoch:15 step:72885[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:15 step:72890[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:15 step:72895[D loss: 0.999984] [G loss: 1.000098]\n",
      "epoch:15 step:72900[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:15 step:72905[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:15 step:72910[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:15 step:72915[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:15 step:72920[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:15 step:72925[D loss: 1.000024] [G loss: 1.000026]\n",
      "epoch:15 step:72930[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:15 step:72935[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:15 step:72940[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:15 step:72945[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:15 step:72950[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:15 step:72955[D loss: 0.999940] [G loss: 1.000184]\n",
      "epoch:15 step:72960[D loss: 0.999972] [G loss: 1.000151]\n",
      "epoch:15 step:72965[D loss: 0.999973] [G loss: 1.000112]\n",
      "epoch:15 step:72970[D loss: 1.000039] [G loss: 0.999981]\n",
      "epoch:15 step:72975[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:15 step:72980[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:15 step:72985[D loss: 1.000001] [G loss: 0.999998]\n",
      "epoch:15 step:72990[D loss: 1.000000] [G loss: 1.000071]\n",
      "epoch:15 step:72995[D loss: 1.000020] [G loss: 0.999993]\n",
      "epoch:15 step:73000[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:15 step:73005[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:15 step:73010[D loss: 0.999980] [G loss: 0.999997]\n",
      "epoch:15 step:73015[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:15 step:73020[D loss: 0.999988] [G loss: 1.000028]\n",
      "epoch:15 step:73025[D loss: 1.000018] [G loss: 1.000015]\n",
      "epoch:15 step:73030[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:15 step:73035[D loss: 0.999945] [G loss: 1.000023]\n",
      "epoch:15 step:73040[D loss: 1.000052] [G loss: 1.000006]\n",
      "epoch:15 step:73045[D loss: 0.999941] [G loss: 1.000059]\n",
      "epoch:15 step:73050[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:15 step:73055[D loss: 0.999991] [G loss: 1.000024]\n",
      "epoch:15 step:73060[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:15 step:73065[D loss: 0.999991] [G loss: 1.000094]\n",
      "epoch:15 step:73070[D loss: 0.999968] [G loss: 1.000115]\n",
      "epoch:15 step:73075[D loss: 0.999988] [G loss: 1.000101]\n",
      "epoch:15 step:73080[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:15 step:73085[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:15 step:73090[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:15 step:73095[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:15 step:73100[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:15 step:73105[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:15 step:73110[D loss: 0.999993] [G loss: 0.999981]\n",
      "epoch:15 step:73115[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:15 step:73120[D loss: 0.999936] [G loss: 1.000080]\n",
      "epoch:15 step:73125[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:15 step:73130[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:15 step:73135[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:15 step:73140[D loss: 1.000032] [G loss: 1.000025]\n",
      "epoch:15 step:73145[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:15 step:73150[D loss: 1.000044] [G loss: 1.000055]\n",
      "epoch:15 step:73155[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:15 step:73160[D loss: 0.999961] [G loss: 1.000048]\n",
      "epoch:15 step:73165[D loss: 1.000034] [G loss: 1.000040]\n",
      "epoch:15 step:73170[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:15 step:73175[D loss: 0.999978] [G loss: 1.000107]\n",
      "epoch:15 step:73180[D loss: 0.999957] [G loss: 1.000128]\n",
      "epoch:15 step:73185[D loss: 0.999999] [G loss: 1.000073]\n",
      "epoch:15 step:73190[D loss: 0.999957] [G loss: 1.000113]\n",
      "epoch:15 step:73195[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:15 step:73200[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:15 step:73205[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:15 step:73210[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:15 step:73215[D loss: 1.000077] [G loss: 1.000014]\n",
      "epoch:15 step:73220[D loss: 1.000032] [G loss: 1.000000]\n",
      "epoch:15 step:73225[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:15 step:73230[D loss: 0.999933] [G loss: 1.000117]\n",
      "epoch:15 step:73235[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:15 step:73240[D loss: 1.000050] [G loss: 1.000043]\n",
      "epoch:15 step:73245[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:15 step:73250[D loss: 1.000025] [G loss: 1.000018]\n",
      "epoch:15 step:73255[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:15 step:73260[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:15 step:73265[D loss: 0.999926] [G loss: 1.000122]\n",
      "epoch:15 step:73270[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:15 step:73275[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:15 step:73280[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:15 step:73285[D loss: 1.000008] [G loss: 0.999979]\n",
      "epoch:15 step:73290[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:15 step:73295[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:15 step:73300[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:15 step:73305[D loss: 1.000000] [G loss: 1.000004]\n",
      "epoch:15 step:73310[D loss: 1.000045] [G loss: 0.999968]\n",
      "epoch:15 step:73315[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:15 step:73320[D loss: 1.000044] [G loss: 1.000075]\n",
      "epoch:15 step:73325[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:15 step:73330[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:15 step:73335[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:15 step:73340[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:15 step:73345[D loss: 0.999992] [G loss: 1.000043]\n",
      "epoch:15 step:73350[D loss: 1.000015] [G loss: 1.000041]\n",
      "epoch:15 step:73355[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:15 step:73360[D loss: 0.999996] [G loss: 1.000100]\n",
      "epoch:15 step:73365[D loss: 0.999966] [G loss: 1.000111]\n",
      "epoch:15 step:73370[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:15 step:73375[D loss: 1.000002] [G loss: 1.000066]\n",
      "epoch:15 step:73380[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:15 step:73385[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:15 step:73390[D loss: 1.000000] [G loss: 1.000021]\n",
      "epoch:15 step:73395[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:15 step:73400[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:15 step:73405[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:15 step:73410[D loss: 1.000017] [G loss: 0.999996]\n",
      "epoch:15 step:73415[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:15 step:73420[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:15 step:73425[D loss: 0.999959] [G loss: 1.000128]\n",
      "epoch:15 step:73430[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:15 step:73435[D loss: 0.999984] [G loss: 1.000113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:73440[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:15 step:73445[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:15 step:73450[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:15 step:73455[D loss: 0.999998] [G loss: 1.000038]\n",
      "epoch:15 step:73460[D loss: 0.999992] [G loss: 1.000097]\n",
      "epoch:15 step:73465[D loss: 0.999929] [G loss: 1.000071]\n",
      "epoch:15 step:73470[D loss: 0.999944] [G loss: 1.000062]\n",
      "epoch:15 step:73475[D loss: 1.000048] [G loss: 0.999971]\n",
      "epoch:15 step:73480[D loss: 0.999963] [G loss: 1.000137]\n",
      "epoch:15 step:73485[D loss: 0.999916] [G loss: 1.000097]\n",
      "epoch:15 step:73490[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:15 step:73495[D loss: 1.000017] [G loss: 0.999992]\n",
      "epoch:15 step:73500[D loss: 0.999985] [G loss: 0.999991]\n",
      "epoch:15 step:73505[D loss: 1.000002] [G loss: 1.000074]\n",
      "epoch:15 step:73510[D loss: 0.999967] [G loss: 1.000009]\n",
      "epoch:15 step:73515[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:15 step:73520[D loss: 0.999969] [G loss: 1.000118]\n",
      "epoch:15 step:73525[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:15 step:73530[D loss: 0.999946] [G loss: 1.000116]\n",
      "epoch:15 step:73535[D loss: 0.999960] [G loss: 1.000105]\n",
      "epoch:15 step:73540[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:15 step:73545[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:15 step:73550[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:15 step:73555[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:15 step:73560[D loss: 0.999978] [G loss: 1.000092]\n",
      "epoch:15 step:73565[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:15 step:73570[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:15 step:73575[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:15 step:73580[D loss: 1.000003] [G loss: 0.999977]\n",
      "epoch:15 step:73585[D loss: 0.999942] [G loss: 1.000158]\n",
      "epoch:15 step:73590[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:15 step:73595[D loss: 0.999941] [G loss: 1.000096]\n",
      "epoch:15 step:73600[D loss: 1.000013] [G loss: 1.000002]\n",
      "epoch:15 step:73605[D loss: 1.000021] [G loss: 0.999982]\n",
      "epoch:15 step:73610[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:15 step:73615[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:15 step:73620[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:15 step:73625[D loss: 0.999997] [G loss: 0.999969]\n",
      "epoch:15 step:73630[D loss: 0.999935] [G loss: 1.000090]\n",
      "epoch:15 step:73635[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:15 step:73640[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:15 step:73645[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:15 step:73650[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:15 step:73655[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:15 step:73660[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:15 step:73665[D loss: 1.000005] [G loss: 1.000009]\n",
      "epoch:15 step:73670[D loss: 1.000030] [G loss: 0.999943]\n",
      "epoch:15 step:73675[D loss: 1.000012] [G loss: 1.000048]\n",
      "epoch:15 step:73680[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:15 step:73685[D loss: 0.999964] [G loss: 1.000127]\n",
      "epoch:15 step:73690[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:15 step:73695[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:15 step:73700[D loss: 1.000037] [G loss: 1.000006]\n",
      "epoch:15 step:73705[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:15 step:73710[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:15 step:73715[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:15 step:73720[D loss: 1.000015] [G loss: 1.000057]\n",
      "epoch:15 step:73725[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:15 step:73730[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:15 step:73735[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:15 step:73740[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:15 step:73745[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:15 step:73750[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:15 step:73755[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:15 step:73760[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:15 step:73765[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:15 step:73770[D loss: 1.000004] [G loss: 1.000058]\n",
      "epoch:15 step:73775[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:15 step:73780[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:15 step:73785[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:15 step:73790[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:15 step:73795[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:15 step:73800[D loss: 1.000015] [G loss: 1.000005]\n",
      "epoch:15 step:73805[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:15 step:73810[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:15 step:73815[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:15 step:73820[D loss: 1.000052] [G loss: 1.000024]\n",
      "epoch:15 step:73825[D loss: 1.000023] [G loss: 1.000073]\n",
      "epoch:15 step:73830[D loss: 0.999956] [G loss: 1.000109]\n",
      "epoch:15 step:73835[D loss: 1.000027] [G loss: 0.999927]\n",
      "epoch:15 step:73840[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:15 step:73845[D loss: 0.999987] [G loss: 1.000123]\n",
      "epoch:15 step:73850[D loss: 1.000005] [G loss: 1.000003]\n",
      "epoch:15 step:73855[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:15 step:73860[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:15 step:73865[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:15 step:73870[D loss: 1.000013] [G loss: 1.000039]\n",
      "epoch:15 step:73875[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:15 step:73880[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:15 step:73885[D loss: 1.000039] [G loss: 1.000004]\n",
      "epoch:15 step:73890[D loss: 1.000011] [G loss: 1.000034]\n",
      "epoch:15 step:73895[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:15 step:73900[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:15 step:73905[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:15 step:73910[D loss: 0.999993] [G loss: 1.000094]\n",
      "epoch:15 step:73915[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:15 step:73920[D loss: 0.999949] [G loss: 1.000060]\n",
      "epoch:15 step:73925[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:15 step:73930[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:15 step:73935[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:15 step:73940[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:15 step:73945[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:15 step:73950[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:15 step:73955[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:15 step:73960[D loss: 1.000031] [G loss: 1.000046]\n",
      "epoch:15 step:73965[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:15 step:73970[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:15 step:73975[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:15 step:73980[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:15 step:73985[D loss: 1.000067] [G loss: 0.999982]\n",
      "epoch:15 step:73990[D loss: 0.999955] [G loss: 1.000047]\n",
      "epoch:15 step:73995[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:15 step:74000[D loss: 0.999972] [G loss: 1.000049]\n",
      "epoch:15 step:74005[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:15 step:74010[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:15 step:74015[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:15 step:74020[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:15 step:74025[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:15 step:74030[D loss: 0.999978] [G loss: 1.000044]\n",
      "epoch:15 step:74035[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:15 step:74040[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:15 step:74045[D loss: 1.000024] [G loss: 1.000070]\n",
      "epoch:15 step:74050[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:15 step:74055[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:15 step:74060[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:15 step:74065[D loss: 0.999932] [G loss: 1.000095]\n",
      "epoch:15 step:74070[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:15 step:74075[D loss: 0.999962] [G loss: 1.000110]\n",
      "epoch:15 step:74080[D loss: 0.999954] [G loss: 1.000139]\n",
      "epoch:15 step:74085[D loss: 1.000071] [G loss: 0.999936]\n",
      "epoch:15 step:74090[D loss: 0.999925] [G loss: 1.000145]\n",
      "epoch:15 step:74095[D loss: 0.999949] [G loss: 1.000082]\n",
      "epoch:15 step:74100[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:15 step:74105[D loss: 0.999956] [G loss: 1.000079]\n",
      "epoch:15 step:74110[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:15 step:74115[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:15 step:74120[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:15 step:74125[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:15 step:74130[D loss: 1.000011] [G loss: 1.000018]\n",
      "epoch:15 step:74135[D loss: 0.999919] [G loss: 1.000170]\n",
      "epoch:15 step:74140[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:15 step:74145[D loss: 1.000019] [G loss: 1.000065]\n",
      "epoch:15 step:74150[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:15 step:74155[D loss: 0.999970] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:74160[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:15 step:74165[D loss: 0.999997] [G loss: 1.000072]\n",
      "epoch:15 step:74170[D loss: 1.000019] [G loss: 1.000018]\n",
      "epoch:15 step:74175[D loss: 0.999843] [G loss: 1.000223]\n",
      "epoch:15 step:74180[D loss: 0.999931] [G loss: 1.000000]\n",
      "epoch:15 step:74185[D loss: 0.999937] [G loss: 1.000104]\n",
      "epoch:15 step:74190[D loss: 1.000020] [G loss: 1.000015]\n",
      "epoch:15 step:74195[D loss: 0.999936] [G loss: 1.000090]\n",
      "epoch:15 step:74200[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:15 step:74205[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:15 step:74210[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:15 step:74215[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:15 step:74220[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:15 step:74225[D loss: 1.000022] [G loss: 1.000012]\n",
      "epoch:15 step:74230[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:15 step:74235[D loss: 0.999943] [G loss: 1.000081]\n",
      "epoch:15 step:74240[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:15 step:74245[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:15 step:74250[D loss: 0.999918] [G loss: 1.000163]\n",
      "epoch:15 step:74255[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:15 step:74260[D loss: 0.999945] [G loss: 1.000131]\n",
      "epoch:15 step:74265[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:15 step:74270[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:15 step:74275[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:15 step:74280[D loss: 0.999993] [G loss: 0.999982]\n",
      "epoch:15 step:74285[D loss: 1.000006] [G loss: 1.000007]\n",
      "epoch:15 step:74290[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:15 step:74295[D loss: 0.999950] [G loss: 1.000134]\n",
      "epoch:15 step:74300[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:15 step:74305[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:15 step:74310[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:15 step:74315[D loss: 0.999996] [G loss: 1.000105]\n",
      "epoch:15 step:74320[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:15 step:74325[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:15 step:74330[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:15 step:74335[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:15 step:74340[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:15 step:74345[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:15 step:74350[D loss: 0.999979] [G loss: 1.000044]\n",
      "epoch:15 step:74355[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:15 step:74360[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:15 step:74365[D loss: 0.999992] [G loss: 1.000084]\n",
      "epoch:15 step:74370[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:15 step:74375[D loss: 0.999995] [G loss: 1.000053]\n",
      "epoch:15 step:74380[D loss: 1.000038] [G loss: 0.999969]\n",
      "epoch:15 step:74385[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:15 step:74390[D loss: 0.999949] [G loss: 1.000095]\n",
      "epoch:15 step:74395[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:15 step:74400[D loss: 0.999924] [G loss: 1.000134]\n",
      "epoch:15 step:74405[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:15 step:74410[D loss: 0.999971] [G loss: 1.000097]\n",
      "epoch:15 step:74415[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:15 step:74420[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:15 step:74425[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:15 step:74430[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:15 step:74435[D loss: 1.000014] [G loss: 1.000047]\n",
      "epoch:15 step:74440[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:15 step:74445[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:15 step:74450[D loss: 0.999944] [G loss: 1.000090]\n",
      "epoch:15 step:74455[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:15 step:74460[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:15 step:74465[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:15 step:74470[D loss: 1.000021] [G loss: 1.000060]\n",
      "epoch:15 step:74475[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:15 step:74480[D loss: 1.000034] [G loss: 0.999951]\n",
      "epoch:15 step:74485[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:15 step:74490[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:15 step:74495[D loss: 1.000056] [G loss: 0.999973]\n",
      "epoch:15 step:74500[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:15 step:74505[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:15 step:74510[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:15 step:74515[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:15 step:74520[D loss: 0.999978] [G loss: 1.000081]\n",
      "epoch:15 step:74525[D loss: 0.999995] [G loss: 1.000015]\n",
      "epoch:15 step:74530[D loss: 1.000001] [G loss: 1.000002]\n",
      "epoch:15 step:74535[D loss: 1.000005] [G loss: 1.000005]\n",
      "epoch:15 step:74540[D loss: 1.000048] [G loss: 1.000013]\n",
      "epoch:15 step:74545[D loss: 1.000008] [G loss: 0.999985]\n",
      "epoch:15 step:74550[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:15 step:74555[D loss: 1.000051] [G loss: 0.999997]\n",
      "epoch:15 step:74560[D loss: 0.999966] [G loss: 1.000113]\n",
      "epoch:15 step:74565[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:15 step:74570[D loss: 1.000022] [G loss: 0.999965]\n",
      "epoch:15 step:74575[D loss: 0.999958] [G loss: 1.000024]\n",
      "epoch:15 step:74580[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:15 step:74585[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:15 step:74590[D loss: 1.000013] [G loss: 1.000030]\n",
      "epoch:15 step:74595[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:15 step:74600[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:15 step:74605[D loss: 0.999978] [G loss: 1.000024]\n",
      "epoch:15 step:74610[D loss: 1.000032] [G loss: 0.999977]\n",
      "epoch:15 step:74615[D loss: 0.999984] [G loss: 1.000025]\n",
      "epoch:15 step:74620[D loss: 0.999945] [G loss: 1.000114]\n",
      "epoch:15 step:74625[D loss: 0.999999] [G loss: 1.000085]\n",
      "epoch:15 step:74630[D loss: 0.999922] [G loss: 1.000064]\n",
      "epoch:15 step:74635[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:15 step:74640[D loss: 0.999953] [G loss: 1.000043]\n",
      "epoch:15 step:74645[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:15 step:74650[D loss: 1.000041] [G loss: 0.999912]\n",
      "epoch:15 step:74655[D loss: 0.999997] [G loss: 1.000031]\n",
      "epoch:15 step:74660[D loss: 0.999928] [G loss: 1.000076]\n",
      "epoch:15 step:74665[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:15 step:74670[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:15 step:74675[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:15 step:74680[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:15 step:74685[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:15 step:74690[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:15 step:74695[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:15 step:74700[D loss: 0.999992] [G loss: 1.000058]\n",
      "epoch:15 step:74705[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:15 step:74710[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:15 step:74715[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:15 step:74720[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:15 step:74725[D loss: 0.999964] [G loss: 1.000036]\n",
      "epoch:15 step:74730[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:15 step:74735[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:15 step:74740[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:15 step:74745[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:15 step:74750[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:15 step:74755[D loss: 0.999990] [G loss: 1.000073]\n",
      "epoch:15 step:74760[D loss: 0.999999] [G loss: 1.000017]\n",
      "epoch:15 step:74765[D loss: 0.999957] [G loss: 1.000034]\n",
      "epoch:15 step:74770[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:15 step:74775[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:15 step:74780[D loss: 0.999979] [G loss: 1.000107]\n",
      "epoch:15 step:74785[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:15 step:74790[D loss: 1.000002] [G loss: 1.000058]\n",
      "epoch:15 step:74795[D loss: 1.000021] [G loss: 1.000044]\n",
      "epoch:15 step:74800[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:15 step:74805[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:15 step:74810[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:15 step:74815[D loss: 1.000039] [G loss: 0.999968]\n",
      "epoch:15 step:74820[D loss: 0.999953] [G loss: 1.000058]\n",
      "epoch:15 step:74825[D loss: 0.999934] [G loss: 1.000076]\n",
      "epoch:15 step:74830[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:15 step:74835[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:15 step:74840[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:15 step:74845[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:15 step:74850[D loss: 1.000007] [G loss: 1.000010]\n",
      "epoch:15 step:74855[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:15 step:74860[D loss: 0.999962] [G loss: 1.000122]\n",
      "epoch:15 step:74865[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:15 step:74870[D loss: 0.999995] [G loss: 1.000004]\n",
      "epoch:15 step:74875[D loss: 1.000039] [G loss: 0.999989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:74880[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:15 step:74885[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:15 step:74890[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:15 step:74895[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:15 step:74900[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:15 step:74905[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:15 step:74910[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:15 step:74915[D loss: 1.000017] [G loss: 1.000028]\n",
      "epoch:15 step:74920[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:15 step:74925[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:15 step:74930[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:15 step:74935[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:15 step:74940[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:15 step:74945[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:15 step:74950[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:15 step:74955[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:15 step:74960[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:16 step:74965[D loss: 1.000013] [G loss: 1.000044]\n",
      "epoch:16 step:74970[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:16 step:74975[D loss: 0.999987] [G loss: 1.000074]\n",
      "epoch:16 step:74980[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:16 step:74985[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:16 step:74990[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:16 step:74995[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:16 step:75000[D loss: 0.999958] [G loss: 1.000115]\n",
      "epoch:16 step:75005[D loss: 1.000040] [G loss: 0.999966]\n",
      "epoch:16 step:75010[D loss: 0.999981] [G loss: 1.000173]\n",
      "epoch:16 step:75015[D loss: 0.999981] [G loss: 1.000133]\n",
      "epoch:16 step:75020[D loss: 0.999938] [G loss: 1.000101]\n",
      "epoch:16 step:75025[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:16 step:75030[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:16 step:75035[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:16 step:75040[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:16 step:75045[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:16 step:75050[D loss: 1.000010] [G loss: 1.000007]\n",
      "epoch:16 step:75055[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:16 step:75060[D loss: 0.999975] [G loss: 1.000029]\n",
      "epoch:16 step:75065[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:16 step:75070[D loss: 0.999978] [G loss: 1.000100]\n",
      "epoch:16 step:75075[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:16 step:75080[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:16 step:75085[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:16 step:75090[D loss: 0.999989] [G loss: 1.000070]\n",
      "epoch:16 step:75095[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:16 step:75100[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:16 step:75105[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:16 step:75110[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:16 step:75115[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:16 step:75120[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:16 step:75125[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:16 step:75130[D loss: 1.000038] [G loss: 1.000017]\n",
      "epoch:16 step:75135[D loss: 0.999968] [G loss: 1.000112]\n",
      "epoch:16 step:75140[D loss: 1.000017] [G loss: 1.000042]\n",
      "epoch:16 step:75145[D loss: 0.999985] [G loss: 1.000120]\n",
      "epoch:16 step:75150[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:16 step:75155[D loss: 0.999991] [G loss: 1.000079]\n",
      "epoch:16 step:75160[D loss: 1.000103] [G loss: 0.999903]\n",
      "epoch:16 step:75165[D loss: 0.999922] [G loss: 1.000190]\n",
      "epoch:16 step:75170[D loss: 0.999957] [G loss: 1.000053]\n",
      "epoch:16 step:75175[D loss: 0.999942] [G loss: 1.000134]\n",
      "epoch:16 step:75180[D loss: 1.000002] [G loss: 0.999969]\n",
      "epoch:16 step:75185[D loss: 0.999999] [G loss: 1.000047]\n",
      "epoch:16 step:75190[D loss: 0.999902] [G loss: 1.000182]\n",
      "epoch:16 step:75195[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:16 step:75200[D loss: 0.999957] [G loss: 1.000053]\n",
      "epoch:16 step:75205[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:16 step:75210[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:16 step:75215[D loss: 1.000005] [G loss: 1.000053]\n",
      "epoch:16 step:75220[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:16 step:75225[D loss: 1.000004] [G loss: 1.000005]\n",
      "epoch:16 step:75230[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:16 step:75235[D loss: 1.000014] [G loss: 1.000017]\n",
      "epoch:16 step:75240[D loss: 0.999952] [G loss: 1.000122]\n",
      "epoch:16 step:75245[D loss: 0.999980] [G loss: 1.000117]\n",
      "epoch:16 step:75250[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:16 step:75255[D loss: 0.999970] [G loss: 1.000131]\n",
      "epoch:16 step:75260[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:16 step:75265[D loss: 0.999970] [G loss: 1.000105]\n",
      "epoch:16 step:75270[D loss: 1.000023] [G loss: 1.000002]\n",
      "epoch:16 step:75275[D loss: 0.999961] [G loss: 1.000133]\n",
      "epoch:16 step:75280[D loss: 1.000057] [G loss: 0.999958]\n",
      "epoch:16 step:75285[D loss: 1.000010] [G loss: 1.000023]\n",
      "epoch:16 step:75290[D loss: 1.000012] [G loss: 0.999965]\n",
      "epoch:16 step:75295[D loss: 0.999986] [G loss: 1.000007]\n",
      "epoch:16 step:75300[D loss: 0.999956] [G loss: 1.000116]\n",
      "epoch:16 step:75305[D loss: 0.999999] [G loss: 1.000102]\n",
      "epoch:16 step:75310[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:16 step:75315[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:16 step:75320[D loss: 1.000040] [G loss: 0.999986]\n",
      "epoch:16 step:75325[D loss: 0.999939] [G loss: 1.000145]\n",
      "epoch:16 step:75330[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:16 step:75335[D loss: 1.000025] [G loss: 0.999993]\n",
      "epoch:16 step:75340[D loss: 0.999948] [G loss: 1.000088]\n",
      "epoch:16 step:75345[D loss: 1.000009] [G loss: 0.999998]\n",
      "epoch:16 step:75350[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:16 step:75355[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:16 step:75360[D loss: 0.999941] [G loss: 1.000114]\n",
      "epoch:16 step:75365[D loss: 1.000023] [G loss: 0.999999]\n",
      "epoch:16 step:75370[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:16 step:75375[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:16 step:75380[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:16 step:75385[D loss: 0.999994] [G loss: 1.000012]\n",
      "epoch:16 step:75390[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:16 step:75395[D loss: 1.000014] [G loss: 0.999991]\n",
      "epoch:16 step:75400[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:16 step:75405[D loss: 1.000062] [G loss: 0.999975]\n",
      "epoch:16 step:75410[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:16 step:75415[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:16 step:75420[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:16 step:75425[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:16 step:75430[D loss: 0.999978] [G loss: 1.000011]\n",
      "epoch:16 step:75435[D loss: 1.000011] [G loss: 1.000068]\n",
      "epoch:16 step:75440[D loss: 1.000014] [G loss: 1.000052]\n",
      "epoch:16 step:75445[D loss: 1.000015] [G loss: 1.000042]\n",
      "epoch:16 step:75450[D loss: 1.000061] [G loss: 0.999979]\n",
      "epoch:16 step:75455[D loss: 1.000003] [G loss: 1.000031]\n",
      "epoch:16 step:75460[D loss: 0.999941] [G loss: 1.000113]\n",
      "epoch:16 step:75465[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:16 step:75470[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:16 step:75475[D loss: 1.000027] [G loss: 0.999963]\n",
      "epoch:16 step:75480[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:16 step:75485[D loss: 1.000014] [G loss: 0.999989]\n",
      "epoch:16 step:75490[D loss: 0.999945] [G loss: 1.000050]\n",
      "epoch:16 step:75495[D loss: 1.000005] [G loss: 1.000060]\n",
      "epoch:16 step:75500[D loss: 0.999947] [G loss: 1.000126]\n",
      "epoch:16 step:75505[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:16 step:75510[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:16 step:75515[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:16 step:75520[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:16 step:75525[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:16 step:75530[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:16 step:75535[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:16 step:75540[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:16 step:75545[D loss: 1.000024] [G loss: 1.000013]\n",
      "epoch:16 step:75550[D loss: 0.999959] [G loss: 1.000160]\n",
      "epoch:16 step:75555[D loss: 1.000058] [G loss: 1.000025]\n",
      "epoch:16 step:75560[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:16 step:75565[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:16 step:75570[D loss: 0.999948] [G loss: 1.000147]\n",
      "epoch:16 step:75575[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:16 step:75580[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:16 step:75585[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:16 step:75590[D loss: 0.999960] [G loss: 1.000036]\n",
      "epoch:16 step:75595[D loss: 0.999985] [G loss: 1.000042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:75600[D loss: 0.999998] [G loss: 1.000007]\n",
      "epoch:16 step:75605[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:16 step:75610[D loss: 0.999921] [G loss: 1.000106]\n",
      "epoch:16 step:75615[D loss: 0.999999] [G loss: 1.000015]\n",
      "epoch:16 step:75620[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:16 step:75625[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:16 step:75630[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:16 step:75635[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:16 step:75640[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:16 step:75645[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:16 step:75650[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:16 step:75655[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:16 step:75660[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:16 step:75665[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:16 step:75670[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:16 step:75675[D loss: 0.999976] [G loss: 1.000029]\n",
      "epoch:16 step:75680[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:16 step:75685[D loss: 0.999995] [G loss: 1.000064]\n",
      "epoch:16 step:75690[D loss: 0.999974] [G loss: 1.000087]\n",
      "epoch:16 step:75695[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:16 step:75700[D loss: 1.000008] [G loss: 1.000038]\n",
      "epoch:16 step:75705[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:16 step:75710[D loss: 0.999993] [G loss: 1.000018]\n",
      "epoch:16 step:75715[D loss: 0.999937] [G loss: 1.000085]\n",
      "epoch:16 step:75720[D loss: 0.999915] [G loss: 1.000155]\n",
      "epoch:16 step:75725[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:16 step:75730[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:16 step:75735[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:16 step:75740[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:16 step:75745[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:16 step:75750[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:16 step:75755[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:16 step:75760[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:16 step:75765[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:16 step:75770[D loss: 1.000031] [G loss: 0.999981]\n",
      "epoch:16 step:75775[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:16 step:75780[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:16 step:75785[D loss: 1.000007] [G loss: 1.000049]\n",
      "epoch:16 step:75790[D loss: 1.000018] [G loss: 0.999983]\n",
      "epoch:16 step:75795[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:16 step:75800[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:16 step:75805[D loss: 1.000014] [G loss: 0.999978]\n",
      "epoch:16 step:75810[D loss: 1.000007] [G loss: 0.999999]\n",
      "epoch:16 step:75815[D loss: 0.999924] [G loss: 1.000151]\n",
      "epoch:16 step:75820[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:16 step:75825[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:16 step:75830[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:16 step:75835[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:16 step:75840[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:16 step:75845[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:16 step:75850[D loss: 0.999983] [G loss: 1.000085]\n",
      "epoch:16 step:75855[D loss: 1.000006] [G loss: 1.000010]\n",
      "epoch:16 step:75860[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:16 step:75865[D loss: 0.999979] [G loss: 1.000101]\n",
      "epoch:16 step:75870[D loss: 0.999978] [G loss: 1.000103]\n",
      "epoch:16 step:75875[D loss: 0.999975] [G loss: 1.000099]\n",
      "epoch:16 step:75880[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:16 step:75885[D loss: 1.000000] [G loss: 1.000005]\n",
      "epoch:16 step:75890[D loss: 0.999967] [G loss: 1.000020]\n",
      "epoch:16 step:75895[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:16 step:75900[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:16 step:75905[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:16 step:75910[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:16 step:75915[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:16 step:75920[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:16 step:75925[D loss: 1.000021] [G loss: 1.000023]\n",
      "epoch:16 step:75930[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:16 step:75935[D loss: 1.000011] [G loss: 0.999997]\n",
      "epoch:16 step:75940[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:16 step:75945[D loss: 0.999981] [G loss: 1.000037]\n",
      "epoch:16 step:75950[D loss: 1.000035] [G loss: 1.000108]\n",
      "epoch:16 step:75955[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:16 step:75960[D loss: 1.000057] [G loss: 1.000060]\n",
      "epoch:16 step:75965[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:16 step:75970[D loss: 0.999949] [G loss: 1.000132]\n",
      "epoch:16 step:75975[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:16 step:75980[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:16 step:75985[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:16 step:75990[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:16 step:75995[D loss: 0.999997] [G loss: 1.000057]\n",
      "epoch:16 step:76000[D loss: 0.999949] [G loss: 1.000046]\n",
      "epoch:16 step:76005[D loss: 1.000018] [G loss: 1.000054]\n",
      "epoch:16 step:76010[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:16 step:76015[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:16 step:76020[D loss: 0.999995] [G loss: 1.000013]\n",
      "epoch:16 step:76025[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:16 step:76030[D loss: 1.000007] [G loss: 1.000058]\n",
      "epoch:16 step:76035[D loss: 0.999932] [G loss: 1.000159]\n",
      "epoch:16 step:76040[D loss: 0.999938] [G loss: 1.000161]\n",
      "epoch:16 step:76045[D loss: 1.000080] [G loss: 1.000079]\n",
      "epoch:16 step:76050[D loss: 0.999920] [G loss: 1.000153]\n",
      "epoch:16 step:76055[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:16 step:76060[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:16 step:76065[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:16 step:76070[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:16 step:76075[D loss: 0.999946] [G loss: 1.000123]\n",
      "epoch:16 step:76080[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:16 step:76085[D loss: 0.999985] [G loss: 1.000120]\n",
      "epoch:16 step:76090[D loss: 1.000008] [G loss: 1.000114]\n",
      "epoch:16 step:76095[D loss: 1.000090] [G loss: 0.999959]\n",
      "epoch:16 step:76100[D loss: 0.999906] [G loss: 1.000123]\n",
      "epoch:16 step:76105[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:16 step:76110[D loss: 1.000018] [G loss: 1.000034]\n",
      "epoch:16 step:76115[D loss: 0.999945] [G loss: 1.000107]\n",
      "epoch:16 step:76120[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:16 step:76125[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:16 step:76130[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:16 step:76135[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:16 step:76140[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:16 step:76145[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:16 step:76150[D loss: 0.999991] [G loss: 1.000001]\n",
      "epoch:16 step:76155[D loss: 0.999966] [G loss: 1.000094]\n",
      "epoch:16 step:76160[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:16 step:76165[D loss: 1.000030] [G loss: 1.000042]\n",
      "epoch:16 step:76170[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:16 step:76175[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:16 step:76180[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:16 step:76185[D loss: 0.999956] [G loss: 1.000108]\n",
      "epoch:16 step:76190[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:16 step:76195[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:16 step:76200[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:16 step:76205[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:16 step:76210[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:16 step:76215[D loss: 1.000002] [G loss: 1.000073]\n",
      "epoch:16 step:76220[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:16 step:76225[D loss: 0.999972] [G loss: 1.000145]\n",
      "epoch:16 step:76230[D loss: 0.999951] [G loss: 1.000128]\n",
      "epoch:16 step:76235[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:16 step:76240[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:16 step:76245[D loss: 0.999943] [G loss: 1.000104]\n",
      "epoch:16 step:76250[D loss: 0.999988] [G loss: 1.000084]\n",
      "epoch:16 step:76255[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:16 step:76260[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:16 step:76265[D loss: 1.000020] [G loss: 0.999970]\n",
      "epoch:16 step:76270[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:16 step:76275[D loss: 1.000060] [G loss: 1.000024]\n",
      "epoch:16 step:76280[D loss: 1.000033] [G loss: 0.999931]\n",
      "epoch:16 step:76285[D loss: 0.999945] [G loss: 1.000078]\n",
      "epoch:16 step:76290[D loss: 0.999952] [G loss: 1.000120]\n",
      "epoch:16 step:76295[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:16 step:76300[D loss: 1.000006] [G loss: 1.000010]\n",
      "epoch:16 step:76305[D loss: 1.000032] [G loss: 0.999925]\n",
      "epoch:16 step:76310[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:16 step:76315[D loss: 0.999972] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:76320[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:16 step:76325[D loss: 0.999954] [G loss: 1.000041]\n",
      "epoch:16 step:76330[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:16 step:76335[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:16 step:76340[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:16 step:76345[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:16 step:76350[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:16 step:76355[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:16 step:76360[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:16 step:76365[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:16 step:76370[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:16 step:76375[D loss: 0.999956] [G loss: 1.000048]\n",
      "epoch:16 step:76380[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:16 step:76385[D loss: 0.999950] [G loss: 1.000107]\n",
      "epoch:16 step:76390[D loss: 1.000020] [G loss: 1.000003]\n",
      "epoch:16 step:76395[D loss: 0.999947] [G loss: 1.000054]\n",
      "epoch:16 step:76400[D loss: 0.999944] [G loss: 1.000119]\n",
      "epoch:16 step:76405[D loss: 1.000017] [G loss: 1.000054]\n",
      "epoch:16 step:76410[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:16 step:76415[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:16 step:76420[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:16 step:76425[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:16 step:76430[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:16 step:76435[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:16 step:76440[D loss: 0.999995] [G loss: 1.000021]\n",
      "epoch:16 step:76445[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:16 step:76450[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:16 step:76455[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:16 step:76460[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:16 step:76465[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:16 step:76470[D loss: 0.999996] [G loss: 1.000011]\n",
      "epoch:16 step:76475[D loss: 1.000005] [G loss: 0.999988]\n",
      "epoch:16 step:76480[D loss: 1.000004] [G loss: 0.999988]\n",
      "epoch:16 step:76485[D loss: 0.999988] [G loss: 1.000087]\n",
      "epoch:16 step:76490[D loss: 1.000006] [G loss: 1.000066]\n",
      "epoch:16 step:76495[D loss: 0.999938] [G loss: 1.000077]\n",
      "epoch:16 step:76500[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:16 step:76505[D loss: 1.000039] [G loss: 1.000021]\n",
      "epoch:16 step:76510[D loss: 1.000045] [G loss: 0.999980]\n",
      "epoch:16 step:76515[D loss: 0.999980] [G loss: 1.000126]\n",
      "epoch:16 step:76520[D loss: 0.999997] [G loss: 1.000000]\n",
      "epoch:16 step:76525[D loss: 0.999932] [G loss: 1.000081]\n",
      "epoch:16 step:76530[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:16 step:76535[D loss: 0.999968] [G loss: 1.000099]\n",
      "epoch:16 step:76540[D loss: 1.000039] [G loss: 1.000029]\n",
      "epoch:16 step:76545[D loss: 0.999949] [G loss: 1.000049]\n",
      "epoch:16 step:76550[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:16 step:76555[D loss: 0.999941] [G loss: 1.000085]\n",
      "epoch:16 step:76560[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:16 step:76565[D loss: 1.000069] [G loss: 0.999936]\n",
      "epoch:16 step:76570[D loss: 1.000064] [G loss: 0.999938]\n",
      "epoch:16 step:76575[D loss: 1.000077] [G loss: 0.999909]\n",
      "epoch:16 step:76580[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:16 step:76585[D loss: 0.999919] [G loss: 1.000083]\n",
      "epoch:16 step:76590[D loss: 0.999967] [G loss: 1.000017]\n",
      "epoch:16 step:76595[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:16 step:76600[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:16 step:76605[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:16 step:76610[D loss: 1.000050] [G loss: 1.000000]\n",
      "epoch:16 step:76615[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:16 step:76620[D loss: 0.999959] [G loss: 1.000037]\n",
      "epoch:16 step:76625[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:16 step:76630[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:16 step:76635[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:16 step:76640[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:16 step:76645[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:16 step:76650[D loss: 0.999965] [G loss: 1.000041]\n",
      "epoch:16 step:76655[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:16 step:76660[D loss: 0.999955] [G loss: 1.000066]\n",
      "epoch:16 step:76665[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:16 step:76670[D loss: 0.999992] [G loss: 0.999993]\n",
      "epoch:16 step:76675[D loss: 0.999944] [G loss: 1.000089]\n",
      "epoch:16 step:76680[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:16 step:76685[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:16 step:76690[D loss: 1.000005] [G loss: 1.000104]\n",
      "epoch:16 step:76695[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:16 step:76700[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:16 step:76705[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:16 step:76710[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:16 step:76715[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:16 step:76720[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:16 step:76725[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:16 step:76730[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:16 step:76735[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:16 step:76740[D loss: 0.999995] [G loss: 1.000007]\n",
      "epoch:16 step:76745[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:16 step:76750[D loss: 1.000026] [G loss: 1.000072]\n",
      "epoch:16 step:76755[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:16 step:76760[D loss: 0.999916] [G loss: 1.000219]\n",
      "epoch:16 step:76765[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:16 step:76770[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:16 step:76775[D loss: 1.000039] [G loss: 0.999974]\n",
      "epoch:16 step:76780[D loss: 0.999992] [G loss: 1.000125]\n",
      "epoch:16 step:76785[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:16 step:76790[D loss: 0.999996] [G loss: 1.000067]\n",
      "epoch:16 step:76795[D loss: 0.999979] [G loss: 1.000141]\n",
      "epoch:16 step:76800[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:16 step:76805[D loss: 0.999944] [G loss: 1.000102]\n",
      "epoch:16 step:76810[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:16 step:76815[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:16 step:76820[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:16 step:76825[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:16 step:76830[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:16 step:76835[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:16 step:76840[D loss: 0.999970] [G loss: 1.000108]\n",
      "epoch:16 step:76845[D loss: 1.000005] [G loss: 1.000053]\n",
      "epoch:16 step:76850[D loss: 1.000133] [G loss: 0.999911]\n",
      "epoch:16 step:76855[D loss: 0.999957] [G loss: 1.000155]\n",
      "epoch:16 step:76860[D loss: 0.999924] [G loss: 1.000092]\n",
      "epoch:16 step:76865[D loss: 0.999937] [G loss: 1.000097]\n",
      "epoch:16 step:76870[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:16 step:76875[D loss: 0.999995] [G loss: 0.999992]\n",
      "epoch:16 step:76880[D loss: 0.999991] [G loss: 1.000050]\n",
      "epoch:16 step:76885[D loss: 1.000057] [G loss: 0.999991]\n",
      "epoch:16 step:76890[D loss: 0.999940] [G loss: 1.000025]\n",
      "epoch:16 step:76895[D loss: 1.000006] [G loss: 1.000086]\n",
      "epoch:16 step:76900[D loss: 1.000018] [G loss: 0.999944]\n",
      "epoch:16 step:76905[D loss: 0.999909] [G loss: 1.000110]\n",
      "epoch:16 step:76910[D loss: 1.000026] [G loss: 1.000095]\n",
      "epoch:16 step:76915[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:16 step:76920[D loss: 0.999994] [G loss: 1.000146]\n",
      "epoch:16 step:76925[D loss: 0.999937] [G loss: 1.000144]\n",
      "epoch:16 step:76930[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:16 step:76935[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:16 step:76940[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:16 step:76945[D loss: 1.000031] [G loss: 0.999960]\n",
      "epoch:16 step:76950[D loss: 1.000013] [G loss: 0.999969]\n",
      "epoch:16 step:76955[D loss: 1.000031] [G loss: 1.000002]\n",
      "epoch:16 step:76960[D loss: 0.999959] [G loss: 1.000103]\n",
      "epoch:16 step:76965[D loss: 1.000028] [G loss: 1.000036]\n",
      "epoch:16 step:76970[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:16 step:76975[D loss: 0.999918] [G loss: 1.000176]\n",
      "epoch:16 step:76980[D loss: 0.999917] [G loss: 1.000120]\n",
      "epoch:16 step:76985[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:16 step:76990[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:16 step:76995[D loss: 1.000015] [G loss: 1.000044]\n",
      "epoch:16 step:77000[D loss: 0.999960] [G loss: 1.000037]\n",
      "epoch:16 step:77005[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:16 step:77010[D loss: 1.000025] [G loss: 1.000071]\n",
      "epoch:16 step:77015[D loss: 0.999953] [G loss: 1.000073]\n",
      "epoch:16 step:77020[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:16 step:77025[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:16 step:77030[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:16 step:77035[D loss: 0.999975] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:77040[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:16 step:77045[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:16 step:77050[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:16 step:77055[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:16 step:77060[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:16 step:77065[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:16 step:77070[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:16 step:77075[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:16 step:77080[D loss: 1.000003] [G loss: 0.999991]\n",
      "epoch:16 step:77085[D loss: 0.999969] [G loss: 1.000118]\n",
      "epoch:16 step:77090[D loss: 0.999899] [G loss: 1.000145]\n",
      "epoch:16 step:77095[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:16 step:77100[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:16 step:77105[D loss: 0.999992] [G loss: 1.000048]\n",
      "epoch:16 step:77110[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:16 step:77115[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:16 step:77120[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:16 step:77125[D loss: 0.999997] [G loss: 1.000024]\n",
      "epoch:16 step:77130[D loss: 0.999976] [G loss: 1.000119]\n",
      "epoch:16 step:77135[D loss: 1.000016] [G loss: 1.000007]\n",
      "epoch:16 step:77140[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:16 step:77145[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:16 step:77150[D loss: 1.000014] [G loss: 1.000006]\n",
      "epoch:16 step:77155[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:16 step:77160[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:16 step:77165[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:16 step:77170[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:16 step:77175[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:16 step:77180[D loss: 0.999934] [G loss: 1.000093]\n",
      "epoch:16 step:77185[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:16 step:77190[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:16 step:77195[D loss: 1.000048] [G loss: 1.000027]\n",
      "epoch:16 step:77200[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:16 step:77205[D loss: 0.999958] [G loss: 1.000109]\n",
      "epoch:16 step:77210[D loss: 0.999975] [G loss: 1.000099]\n",
      "epoch:16 step:77215[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:16 step:77220[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:16 step:77225[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:16 step:77230[D loss: 0.999933] [G loss: 1.000136]\n",
      "epoch:16 step:77235[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:16 step:77240[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:16 step:77245[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:16 step:77250[D loss: 1.000095] [G loss: 0.999927]\n",
      "epoch:16 step:77255[D loss: 1.000085] [G loss: 1.000118]\n",
      "epoch:16 step:77260[D loss: 0.999921] [G loss: 1.000156]\n",
      "epoch:16 step:77265[D loss: 0.999928] [G loss: 1.000122]\n",
      "epoch:16 step:77270[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:16 step:77275[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:16 step:77280[D loss: 1.000000] [G loss: 1.000008]\n",
      "epoch:16 step:77285[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:16 step:77290[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:16 step:77295[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:16 step:77300[D loss: 1.000047] [G loss: 1.000062]\n",
      "epoch:16 step:77305[D loss: 1.000053] [G loss: 1.000087]\n",
      "epoch:16 step:77310[D loss: 0.999924] [G loss: 1.000081]\n",
      "epoch:16 step:77315[D loss: 0.999990] [G loss: 1.000105]\n",
      "epoch:16 step:77320[D loss: 0.999965] [G loss: 1.000170]\n",
      "epoch:16 step:77325[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:16 step:77330[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:16 step:77335[D loss: 0.999978] [G loss: 1.000016]\n",
      "epoch:16 step:77340[D loss: 0.999992] [G loss: 1.000011]\n",
      "epoch:16 step:77345[D loss: 1.000023] [G loss: 0.999991]\n",
      "epoch:16 step:77350[D loss: 0.999996] [G loss: 1.000045]\n",
      "epoch:16 step:77355[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:16 step:77360[D loss: 0.999968] [G loss: 1.000033]\n",
      "epoch:16 step:77365[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:16 step:77370[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:16 step:77375[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:16 step:77380[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:16 step:77385[D loss: 1.000017] [G loss: 1.000066]\n",
      "epoch:16 step:77390[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:16 step:77395[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:16 step:77400[D loss: 1.000002] [G loss: 1.000074]\n",
      "epoch:16 step:77405[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:16 step:77410[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:16 step:77415[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:16 step:77420[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:16 step:77425[D loss: 1.000015] [G loss: 1.000079]\n",
      "epoch:16 step:77430[D loss: 0.999996] [G loss: 1.000089]\n",
      "epoch:16 step:77435[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:16 step:77440[D loss: 0.999998] [G loss: 1.000151]\n",
      "epoch:16 step:77445[D loss: 1.000012] [G loss: 1.000038]\n",
      "epoch:16 step:77450[D loss: 0.999971] [G loss: 1.000034]\n",
      "epoch:16 step:77455[D loss: 1.000076] [G loss: 0.999866]\n",
      "epoch:16 step:77460[D loss: 1.000040] [G loss: 1.000030]\n",
      "epoch:16 step:77465[D loss: 0.999921] [G loss: 1.000057]\n",
      "epoch:16 step:77470[D loss: 0.999956] [G loss: 1.000062]\n",
      "epoch:16 step:77475[D loss: 0.999992] [G loss: 1.000001]\n",
      "epoch:16 step:77480[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:16 step:77485[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:16 step:77490[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:16 step:77495[D loss: 1.000002] [G loss: 1.000081]\n",
      "epoch:16 step:77500[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:16 step:77505[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:16 step:77510[D loss: 1.000055] [G loss: 1.000067]\n",
      "epoch:16 step:77515[D loss: 0.999949] [G loss: 1.000134]\n",
      "epoch:16 step:77520[D loss: 0.999998] [G loss: 0.999981]\n",
      "epoch:16 step:77525[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:16 step:77530[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:16 step:77535[D loss: 0.999941] [G loss: 1.000078]\n",
      "epoch:16 step:77540[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:16 step:77545[D loss: 1.000148] [G loss: 0.999887]\n",
      "epoch:16 step:77550[D loss: 0.999855] [G loss: 1.000247]\n",
      "epoch:16 step:77555[D loss: 0.999920] [G loss: 1.000218]\n",
      "epoch:16 step:77560[D loss: 0.999996] [G loss: 1.000076]\n",
      "epoch:16 step:77565[D loss: 0.999971] [G loss: 1.000147]\n",
      "epoch:16 step:77570[D loss: 0.999999] [G loss: 0.999990]\n",
      "epoch:16 step:77575[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:16 step:77580[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:16 step:77585[D loss: 0.999932] [G loss: 1.000123]\n",
      "epoch:16 step:77590[D loss: 1.000009] [G loss: 1.000042]\n",
      "epoch:16 step:77595[D loss: 0.999964] [G loss: 1.000018]\n",
      "epoch:16 step:77600[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:16 step:77605[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:16 step:77610[D loss: 0.999966] [G loss: 1.000040]\n",
      "epoch:16 step:77615[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:16 step:77620[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:16 step:77625[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:16 step:77630[D loss: 0.999961] [G loss: 1.000114]\n",
      "epoch:16 step:77635[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:16 step:77640[D loss: 0.999985] [G loss: 1.000126]\n",
      "epoch:16 step:77645[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:16 step:77650[D loss: 1.000035] [G loss: 0.999991]\n",
      "epoch:16 step:77655[D loss: 0.999903] [G loss: 1.000210]\n",
      "epoch:16 step:77660[D loss: 0.999939] [G loss: 1.000107]\n",
      "epoch:16 step:77665[D loss: 0.999931] [G loss: 1.000088]\n",
      "epoch:16 step:77670[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:16 step:77675[D loss: 1.000049] [G loss: 0.999991]\n",
      "epoch:16 step:77680[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:16 step:77685[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:16 step:77690[D loss: 0.999947] [G loss: 1.000131]\n",
      "epoch:16 step:77695[D loss: 0.999940] [G loss: 1.000083]\n",
      "epoch:16 step:77700[D loss: 0.999928] [G loss: 1.000126]\n",
      "epoch:16 step:77705[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:16 step:77710[D loss: 1.000053] [G loss: 0.999999]\n",
      "epoch:16 step:77715[D loss: 0.999984] [G loss: 1.000034]\n",
      "epoch:16 step:77720[D loss: 0.999914] [G loss: 1.000127]\n",
      "epoch:16 step:77725[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:16 step:77730[D loss: 0.999960] [G loss: 1.000051]\n",
      "epoch:16 step:77735[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:16 step:77740[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:16 step:77745[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:16 step:77750[D loss: 1.000005] [G loss: 1.000069]\n",
      "epoch:16 step:77755[D loss: 0.999950] [G loss: 1.000098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:77760[D loss: 1.000007] [G loss: 1.000041]\n",
      "epoch:16 step:77765[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:16 step:77770[D loss: 0.999975] [G loss: 1.000006]\n",
      "epoch:16 step:77775[D loss: 1.000061] [G loss: 0.999921]\n",
      "epoch:16 step:77780[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:16 step:77785[D loss: 0.999940] [G loss: 1.000114]\n",
      "epoch:16 step:77790[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:16 step:77795[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:16 step:77800[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:16 step:77805[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:16 step:77810[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:16 step:77815[D loss: 0.999962] [G loss: 1.000041]\n",
      "epoch:16 step:77820[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:16 step:77825[D loss: 1.000024] [G loss: 1.000016]\n",
      "epoch:16 step:77830[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:16 step:77835[D loss: 1.000020] [G loss: 1.000076]\n",
      "epoch:16 step:77840[D loss: 1.000025] [G loss: 1.000022]\n",
      "epoch:16 step:77845[D loss: 0.999966] [G loss: 1.000027]\n",
      "epoch:16 step:77850[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:16 step:77855[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:16 step:77860[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:16 step:77865[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:16 step:77870[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:16 step:77875[D loss: 1.000015] [G loss: 0.999989]\n",
      "epoch:16 step:77880[D loss: 0.999946] [G loss: 1.000071]\n",
      "epoch:16 step:77885[D loss: 1.000017] [G loss: 0.999991]\n",
      "epoch:16 step:77890[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:16 step:77895[D loss: 0.999954] [G loss: 1.000101]\n",
      "epoch:16 step:77900[D loss: 1.000008] [G loss: 1.000063]\n",
      "epoch:16 step:77905[D loss: 1.000015] [G loss: 1.000063]\n",
      "epoch:16 step:77910[D loss: 0.999944] [G loss: 1.000080]\n",
      "epoch:16 step:77915[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:16 step:77920[D loss: 1.000047] [G loss: 1.000044]\n",
      "epoch:16 step:77925[D loss: 1.000086] [G loss: 0.999929]\n",
      "epoch:16 step:77930[D loss: 0.999943] [G loss: 1.000092]\n",
      "epoch:16 step:77935[D loss: 0.999950] [G loss: 1.000175]\n",
      "epoch:16 step:77940[D loss: 0.999947] [G loss: 1.000195]\n",
      "epoch:16 step:77945[D loss: 0.999960] [G loss: 1.000112]\n",
      "epoch:16 step:77950[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:16 step:77955[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:16 step:77960[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:16 step:77965[D loss: 1.000056] [G loss: 0.999977]\n",
      "epoch:16 step:77970[D loss: 1.000077] [G loss: 0.999905]\n",
      "epoch:16 step:77975[D loss: 0.999948] [G loss: 1.000037]\n",
      "epoch:16 step:77980[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:16 step:77985[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:16 step:77990[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:16 step:77995[D loss: 1.000011] [G loss: 0.999983]\n",
      "epoch:16 step:78000[D loss: 0.999940] [G loss: 1.000124]\n",
      "epoch:16 step:78005[D loss: 1.000075] [G loss: 0.999984]\n",
      "epoch:16 step:78010[D loss: 0.999908] [G loss: 1.000111]\n",
      "epoch:16 step:78015[D loss: 1.000012] [G loss: 1.000013]\n",
      "epoch:16 step:78020[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:16 step:78025[D loss: 0.999975] [G loss: 1.000023]\n",
      "epoch:16 step:78030[D loss: 0.999965] [G loss: 1.000042]\n",
      "epoch:16 step:78035[D loss: 1.000011] [G loss: 0.999971]\n",
      "epoch:16 step:78040[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:16 step:78045[D loss: 1.000059] [G loss: 0.999981]\n",
      "epoch:16 step:78050[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:16 step:78055[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:16 step:78060[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:16 step:78065[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:16 step:78070[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:16 step:78075[D loss: 0.999963] [G loss: 1.000039]\n",
      "epoch:16 step:78080[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:16 step:78085[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:16 step:78090[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:16 step:78095[D loss: 1.000038] [G loss: 0.999989]\n",
      "epoch:16 step:78100[D loss: 1.000012] [G loss: 0.999940]\n",
      "epoch:16 step:78105[D loss: 0.999962] [G loss: 1.000041]\n",
      "epoch:16 step:78110[D loss: 1.000017] [G loss: 1.000046]\n",
      "epoch:16 step:78115[D loss: 0.999944] [G loss: 1.000097]\n",
      "epoch:16 step:78120[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:16 step:78125[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:16 step:78130[D loss: 0.999996] [G loss: 1.000012]\n",
      "epoch:16 step:78135[D loss: 1.000017] [G loss: 0.999942]\n",
      "epoch:16 step:78140[D loss: 0.999961] [G loss: 1.000115]\n",
      "epoch:16 step:78145[D loss: 0.999958] [G loss: 1.000137]\n",
      "epoch:16 step:78150[D loss: 0.999958] [G loss: 1.000048]\n",
      "epoch:16 step:78155[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:16 step:78160[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:16 step:78165[D loss: 0.999950] [G loss: 1.000095]\n",
      "epoch:16 step:78170[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:16 step:78175[D loss: 0.999948] [G loss: 1.000057]\n",
      "epoch:16 step:78180[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:16 step:78185[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:16 step:78190[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:16 step:78195[D loss: 0.999957] [G loss: 1.000052]\n",
      "epoch:16 step:78200[D loss: 1.000008] [G loss: 0.999988]\n",
      "epoch:16 step:78205[D loss: 1.000019] [G loss: 1.000029]\n",
      "epoch:16 step:78210[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:16 step:78215[D loss: 0.999934] [G loss: 1.000176]\n",
      "epoch:16 step:78220[D loss: 0.999946] [G loss: 1.000093]\n",
      "epoch:16 step:78225[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:16 step:78230[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:16 step:78235[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:16 step:78240[D loss: 0.999997] [G loss: 1.000015]\n",
      "epoch:16 step:78245[D loss: 0.999950] [G loss: 1.000114]\n",
      "epoch:16 step:78250[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:16 step:78255[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:16 step:78260[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:16 step:78265[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:16 step:78270[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:16 step:78275[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:16 step:78280[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:16 step:78285[D loss: 1.000010] [G loss: 1.000044]\n",
      "epoch:16 step:78290[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:16 step:78295[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:16 step:78300[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:16 step:78305[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:16 step:78310[D loss: 0.999998] [G loss: 1.000009]\n",
      "epoch:16 step:78315[D loss: 0.999935] [G loss: 1.000147]\n",
      "epoch:16 step:78320[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:16 step:78325[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:16 step:78330[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:16 step:78335[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:16 step:78340[D loss: 0.999973] [G loss: 0.999999]\n",
      "epoch:16 step:78345[D loss: 0.999991] [G loss: 1.000046]\n",
      "epoch:16 step:78350[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:16 step:78355[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:16 step:78360[D loss: 0.999918] [G loss: 1.000134]\n",
      "epoch:16 step:78365[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:16 step:78370[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:16 step:78375[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:16 step:78380[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:16 step:78385[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:16 step:78390[D loss: 1.000020] [G loss: 0.999981]\n",
      "epoch:16 step:78395[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:16 step:78400[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:16 step:78405[D loss: 0.999982] [G loss: 1.000167]\n",
      "epoch:16 step:78410[D loss: 0.999931] [G loss: 1.000104]\n",
      "epoch:16 step:78415[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:16 step:78420[D loss: 0.999936] [G loss: 1.000107]\n",
      "epoch:16 step:78425[D loss: 0.999954] [G loss: 1.000072]\n",
      "epoch:16 step:78430[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:16 step:78435[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:16 step:78440[D loss: 0.999941] [G loss: 1.000110]\n",
      "epoch:16 step:78445[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:16 step:78450[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:16 step:78455[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:16 step:78460[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:16 step:78465[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:16 step:78470[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:16 step:78475[D loss: 0.999962] [G loss: 1.000091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:78480[D loss: 0.999951] [G loss: 1.000126]\n",
      "epoch:16 step:78485[D loss: 0.999961] [G loss: 1.000122]\n",
      "epoch:16 step:78490[D loss: 0.999989] [G loss: 1.000085]\n",
      "epoch:16 step:78495[D loss: 0.999931] [G loss: 1.000110]\n",
      "epoch:16 step:78500[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:16 step:78505[D loss: 1.000026] [G loss: 1.000005]\n",
      "epoch:16 step:78510[D loss: 1.000015] [G loss: 1.000038]\n",
      "epoch:16 step:78515[D loss: 1.000019] [G loss: 0.999972]\n",
      "epoch:16 step:78520[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:16 step:78525[D loss: 0.999918] [G loss: 1.000131]\n",
      "epoch:16 step:78530[D loss: 0.999988] [G loss: 1.000128]\n",
      "epoch:16 step:78535[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:16 step:78540[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:16 step:78545[D loss: 0.999974] [G loss: 1.000023]\n",
      "epoch:16 step:78550[D loss: 1.000016] [G loss: 1.000032]\n",
      "epoch:16 step:78555[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:16 step:78560[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:16 step:78565[D loss: 0.999985] [G loss: 1.000092]\n",
      "epoch:16 step:78570[D loss: 1.000001] [G loss: 1.000116]\n",
      "epoch:16 step:78575[D loss: 0.999964] [G loss: 1.000147]\n",
      "epoch:16 step:78580[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:16 step:78585[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:16 step:78590[D loss: 1.000017] [G loss: 1.000024]\n",
      "epoch:16 step:78595[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:16 step:78600[D loss: 0.999965] [G loss: 1.000134]\n",
      "epoch:16 step:78605[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:16 step:78610[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:16 step:78615[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:16 step:78620[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:16 step:78625[D loss: 0.999941] [G loss: 1.000089]\n",
      "epoch:16 step:78630[D loss: 0.999964] [G loss: 1.000115]\n",
      "epoch:16 step:78635[D loss: 0.999938] [G loss: 1.000134]\n",
      "epoch:16 step:78640[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:16 step:78645[D loss: 1.000016] [G loss: 1.000079]\n",
      "epoch:16 step:78650[D loss: 0.999975] [G loss: 1.000080]\n",
      "epoch:16 step:78655[D loss: 0.999993] [G loss: 1.000099]\n",
      "epoch:16 step:78660[D loss: 0.999938] [G loss: 1.000130]\n",
      "epoch:16 step:78665[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:16 step:78670[D loss: 1.000075] [G loss: 0.999959]\n",
      "epoch:16 step:78675[D loss: 0.999920] [G loss: 1.000047]\n",
      "epoch:16 step:78680[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:16 step:78685[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:16 step:78690[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:16 step:78695[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:16 step:78700[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:16 step:78705[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:16 step:78710[D loss: 1.000003] [G loss: 1.000009]\n",
      "epoch:16 step:78715[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:16 step:78720[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:16 step:78725[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:16 step:78730[D loss: 1.000001] [G loss: 1.000070]\n",
      "epoch:16 step:78735[D loss: 0.999958] [G loss: 1.000140]\n",
      "epoch:16 step:78740[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:16 step:78745[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:16 step:78750[D loss: 1.000020] [G loss: 1.000053]\n",
      "epoch:16 step:78755[D loss: 0.999951] [G loss: 1.000110]\n",
      "epoch:16 step:78760[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:16 step:78765[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:16 step:78770[D loss: 1.000038] [G loss: 1.000000]\n",
      "epoch:16 step:78775[D loss: 0.999954] [G loss: 1.000094]\n",
      "epoch:16 step:78780[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:16 step:78785[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:16 step:78790[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:16 step:78795[D loss: 0.999967] [G loss: 1.000109]\n",
      "epoch:16 step:78800[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:16 step:78805[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:16 step:78810[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:16 step:78815[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:16 step:78820[D loss: 1.000030] [G loss: 0.999945]\n",
      "epoch:16 step:78825[D loss: 0.999997] [G loss: 0.999967]\n",
      "epoch:16 step:78830[D loss: 1.000057] [G loss: 1.000033]\n",
      "epoch:16 step:78835[D loss: 0.999904] [G loss: 1.000092]\n",
      "epoch:16 step:78840[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:16 step:78845[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:16 step:78850[D loss: 0.999992] [G loss: 1.000002]\n",
      "epoch:16 step:78855[D loss: 1.000000] [G loss: 0.999997]\n",
      "epoch:16 step:78860[D loss: 0.999888] [G loss: 1.000183]\n",
      "epoch:16 step:78865[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:16 step:78870[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:16 step:78875[D loss: 1.000023] [G loss: 1.000028]\n",
      "epoch:16 step:78880[D loss: 0.999986] [G loss: 1.000086]\n",
      "epoch:16 step:78885[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:16 step:78890[D loss: 0.999969] [G loss: 1.000135]\n",
      "epoch:16 step:78895[D loss: 0.999950] [G loss: 1.000106]\n",
      "epoch:16 step:78900[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:16 step:78905[D loss: 1.000000] [G loss: 1.000116]\n",
      "epoch:16 step:78910[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:16 step:78915[D loss: 1.000110] [G loss: 0.999718]\n",
      "epoch:16 step:78920[D loss: 0.999945] [G loss: 1.000060]\n",
      "epoch:16 step:78925[D loss: 0.999940] [G loss: 1.000028]\n",
      "epoch:16 step:78930[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:16 step:78935[D loss: 1.000022] [G loss: 0.999975]\n",
      "epoch:16 step:78940[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:16 step:78945[D loss: 0.999942] [G loss: 1.000101]\n",
      "epoch:16 step:78950[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:16 step:78955[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:16 step:78960[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:16 step:78965[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:16 step:78970[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:16 step:78975[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:16 step:78980[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:16 step:78985[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:16 step:78990[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:16 step:78995[D loss: 0.999958] [G loss: 1.000102]\n",
      "epoch:16 step:79000[D loss: 1.000037] [G loss: 1.000009]\n",
      "epoch:16 step:79005[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:16 step:79010[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:16 step:79015[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:16 step:79020[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:16 step:79025[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:16 step:79030[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:16 step:79035[D loss: 0.999977] [G loss: 1.000038]\n",
      "epoch:16 step:79040[D loss: 1.000012] [G loss: 1.000021]\n",
      "epoch:16 step:79045[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:16 step:79050[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:16 step:79055[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:16 step:79060[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:16 step:79065[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:16 step:79070[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:16 step:79075[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:16 step:79080[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:16 step:79085[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:16 step:79090[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:16 step:79095[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:16 step:79100[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:16 step:79105[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:16 step:79110[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:16 step:79115[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:16 step:79120[D loss: 1.000067] [G loss: 0.999910]\n",
      "epoch:16 step:79125[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:16 step:79130[D loss: 1.000024] [G loss: 1.000075]\n",
      "epoch:16 step:79135[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:16 step:79140[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:16 step:79145[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:16 step:79150[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:16 step:79155[D loss: 1.000012] [G loss: 1.000029]\n",
      "epoch:16 step:79160[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:16 step:79165[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:16 step:79170[D loss: 0.999947] [G loss: 1.000113]\n",
      "epoch:16 step:79175[D loss: 0.999958] [G loss: 1.000102]\n",
      "epoch:16 step:79180[D loss: 1.000047] [G loss: 0.999999]\n",
      "epoch:16 step:79185[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:16 step:79190[D loss: 0.999970] [G loss: 1.000022]\n",
      "epoch:16 step:79195[D loss: 0.999966] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:79200[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:16 step:79205[D loss: 0.999950] [G loss: 1.000123]\n",
      "epoch:16 step:79210[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:16 step:79215[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:16 step:79220[D loss: 1.000025] [G loss: 0.999984]\n",
      "epoch:16 step:79225[D loss: 1.000012] [G loss: 1.000030]\n",
      "epoch:16 step:79230[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:16 step:79235[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:16 step:79240[D loss: 1.000018] [G loss: 1.000070]\n",
      "epoch:16 step:79245[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:16 step:79250[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:16 step:79255[D loss: 1.000012] [G loss: 1.000047]\n",
      "epoch:16 step:79260[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:16 step:79265[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:16 step:79270[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:16 step:79275[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:16 step:79280[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:16 step:79285[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:16 step:79290[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:16 step:79295[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:16 step:79300[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:16 step:79305[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:16 step:79310[D loss: 1.000093] [G loss: 0.999944]\n",
      "epoch:16 step:79315[D loss: 0.999972] [G loss: 1.000021]\n",
      "epoch:16 step:79320[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:16 step:79325[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:16 step:79330[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:16 step:79335[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:16 step:79340[D loss: 1.000034] [G loss: 0.999914]\n",
      "epoch:16 step:79345[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:16 step:79350[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:16 step:79355[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:16 step:79360[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:16 step:79365[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:16 step:79370[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:16 step:79375[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:16 step:79380[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:16 step:79385[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:16 step:79390[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:16 step:79395[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:16 step:79400[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:16 step:79405[D loss: 1.000042] [G loss: 0.999950]\n",
      "epoch:16 step:79410[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:16 step:79415[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:16 step:79420[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:16 step:79425[D loss: 1.000009] [G loss: 1.000049]\n",
      "epoch:16 step:79430[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:16 step:79435[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:16 step:79440[D loss: 1.000034] [G loss: 1.000002]\n",
      "epoch:16 step:79445[D loss: 1.000046] [G loss: 0.999887]\n",
      "epoch:16 step:79450[D loss: 0.999911] [G loss: 1.000082]\n",
      "epoch:16 step:79455[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:16 step:79460[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:16 step:79465[D loss: 1.000038] [G loss: 1.000063]\n",
      "epoch:16 step:79470[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:16 step:79475[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:16 step:79480[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:16 step:79485[D loss: 1.000025] [G loss: 0.999943]\n",
      "epoch:16 step:79490[D loss: 1.000043] [G loss: 1.000029]\n",
      "epoch:16 step:79495[D loss: 0.999900] [G loss: 1.000096]\n",
      "epoch:16 step:79500[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:16 step:79505[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:16 step:79510[D loss: 0.999935] [G loss: 1.000103]\n",
      "epoch:16 step:79515[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:16 step:79520[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:16 step:79525[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:16 step:79530[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:16 step:79535[D loss: 1.000015] [G loss: 0.999990]\n",
      "epoch:16 step:79540[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:16 step:79545[D loss: 0.999975] [G loss: 1.000103]\n",
      "epoch:16 step:79550[D loss: 0.999949] [G loss: 1.000040]\n",
      "epoch:16 step:79555[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:16 step:79560[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:16 step:79565[D loss: 1.000015] [G loss: 1.000019]\n",
      "epoch:16 step:79570[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:16 step:79575[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:16 step:79580[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:16 step:79585[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:16 step:79590[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:16 step:79595[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:16 step:79600[D loss: 0.999997] [G loss: 1.000004]\n",
      "epoch:16 step:79605[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:16 step:79610[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:16 step:79615[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:16 step:79620[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:16 step:79625[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:16 step:79630[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:16 step:79635[D loss: 0.999992] [G loss: 1.000094]\n",
      "epoch:16 step:79640[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:16 step:79645[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:17 step:79650[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:17 step:79655[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:17 step:79660[D loss: 0.999957] [G loss: 1.000061]\n",
      "epoch:17 step:79665[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:17 step:79670[D loss: 0.999942] [G loss: 1.000100]\n",
      "epoch:17 step:79675[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:17 step:79680[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:17 step:79685[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:17 step:79690[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:17 step:79695[D loss: 1.000010] [G loss: 1.000088]\n",
      "epoch:17 step:79700[D loss: 1.000009] [G loss: 1.000005]\n",
      "epoch:17 step:79705[D loss: 0.999938] [G loss: 1.000060]\n",
      "epoch:17 step:79710[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:17 step:79715[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:17 step:79720[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:17 step:79725[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:17 step:79730[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:17 step:79735[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:17 step:79740[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:17 step:79745[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:17 step:79750[D loss: 1.000018] [G loss: 0.999992]\n",
      "epoch:17 step:79755[D loss: 1.000008] [G loss: 1.000053]\n",
      "epoch:17 step:79760[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:17 step:79765[D loss: 0.999977] [G loss: 1.000100]\n",
      "epoch:17 step:79770[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:17 step:79775[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:17 step:79780[D loss: 1.000005] [G loss: 1.000047]\n",
      "epoch:17 step:79785[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:17 step:79790[D loss: 0.999977] [G loss: 1.000056]\n",
      "epoch:17 step:79795[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:17 step:79800[D loss: 0.999954] [G loss: 1.000050]\n",
      "epoch:17 step:79805[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:17 step:79810[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:17 step:79815[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:17 step:79820[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:17 step:79825[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:17 step:79830[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:17 step:79835[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:17 step:79840[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:17 step:79845[D loss: 1.000066] [G loss: 0.999900]\n",
      "epoch:17 step:79850[D loss: 0.999940] [G loss: 1.000111]\n",
      "epoch:17 step:79855[D loss: 0.999965] [G loss: 1.000028]\n",
      "epoch:17 step:79860[D loss: 0.999975] [G loss: 1.000023]\n",
      "epoch:17 step:79865[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:17 step:79870[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:17 step:79875[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:17 step:79880[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:17 step:79885[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:17 step:79890[D loss: 0.999957] [G loss: 1.000117]\n",
      "epoch:17 step:79895[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:17 step:79900[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:17 step:79905[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:17 step:79910[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:17 step:79915[D loss: 0.999989] [G loss: 1.000054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:79920[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:17 step:79925[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:17 step:79930[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:17 step:79935[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:17 step:79940[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:17 step:79945[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:17 step:79950[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:17 step:79955[D loss: 1.000030] [G loss: 0.999987]\n",
      "epoch:17 step:79960[D loss: 0.999977] [G loss: 1.000149]\n",
      "epoch:17 step:79965[D loss: 1.000014] [G loss: 1.000057]\n",
      "epoch:17 step:79970[D loss: 0.999935] [G loss: 1.000115]\n",
      "epoch:17 step:79975[D loss: 1.000026] [G loss: 0.999993]\n",
      "epoch:17 step:79980[D loss: 0.999943] [G loss: 1.000054]\n",
      "epoch:17 step:79985[D loss: 1.000023] [G loss: 1.000008]\n",
      "epoch:17 step:79990[D loss: 1.000091] [G loss: 0.999928]\n",
      "epoch:17 step:79995[D loss: 1.000014] [G loss: 1.000048]\n",
      "epoch:17 step:80000[D loss: 1.000038] [G loss: 1.000027]\n",
      "epoch:17 step:80005[D loss: 0.999996] [G loss: 1.000081]\n",
      "epoch:17 step:80010[D loss: 0.999971] [G loss: 1.000148]\n",
      "epoch:17 step:80015[D loss: 0.999947] [G loss: 1.000055]\n",
      "epoch:17 step:80020[D loss: 1.000004] [G loss: 1.000043]\n",
      "epoch:17 step:80025[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:17 step:80030[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:17 step:80035[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:17 step:80040[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:17 step:80045[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:17 step:80050[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:17 step:80055[D loss: 1.000019] [G loss: 0.999947]\n",
      "epoch:17 step:80060[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:17 step:80065[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:17 step:80070[D loss: 0.999961] [G loss: 1.000053]\n",
      "epoch:17 step:80075[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:17 step:80080[D loss: 0.999991] [G loss: 0.999986]\n",
      "epoch:17 step:80085[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:17 step:80090[D loss: 1.000037] [G loss: 1.000012]\n",
      "epoch:17 step:80095[D loss: 0.999962] [G loss: 1.000046]\n",
      "epoch:17 step:80100[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:17 step:80105[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:17 step:80110[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:17 step:80115[D loss: 0.999985] [G loss: 0.999968]\n",
      "epoch:17 step:80120[D loss: 1.000029] [G loss: 1.000012]\n",
      "epoch:17 step:80125[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:17 step:80130[D loss: 0.999982] [G loss: 1.000122]\n",
      "epoch:17 step:80135[D loss: 1.000039] [G loss: 0.999960]\n",
      "epoch:17 step:80140[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:17 step:80145[D loss: 0.999929] [G loss: 1.000126]\n",
      "epoch:17 step:80150[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:17 step:80155[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:17 step:80160[D loss: 1.000006] [G loss: 1.000022]\n",
      "epoch:17 step:80165[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:17 step:80170[D loss: 1.000059] [G loss: 0.999921]\n",
      "epoch:17 step:80175[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:17 step:80180[D loss: 1.000026] [G loss: 1.000018]\n",
      "epoch:17 step:80185[D loss: 0.999918] [G loss: 1.000176]\n",
      "epoch:17 step:80190[D loss: 0.999928] [G loss: 1.000096]\n",
      "epoch:17 step:80195[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:17 step:80200[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:17 step:80205[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:17 step:80210[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:17 step:80215[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:17 step:80220[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:17 step:80225[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:17 step:80230[D loss: 1.000030] [G loss: 1.000033]\n",
      "epoch:17 step:80235[D loss: 1.000034] [G loss: 1.000007]\n",
      "epoch:17 step:80240[D loss: 1.000048] [G loss: 0.999971]\n",
      "epoch:17 step:80245[D loss: 0.999913] [G loss: 1.000151]\n",
      "epoch:17 step:80250[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:17 step:80255[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:17 step:80260[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:17 step:80265[D loss: 0.999995] [G loss: 0.999991]\n",
      "epoch:17 step:80270[D loss: 1.000048] [G loss: 0.999952]\n",
      "epoch:17 step:80275[D loss: 0.999965] [G loss: 1.000031]\n",
      "epoch:17 step:80280[D loss: 1.000005] [G loss: 1.000010]\n",
      "epoch:17 step:80285[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:17 step:80290[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:17 step:80295[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:17 step:80300[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:17 step:80305[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:17 step:80310[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:17 step:80315[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:17 step:80320[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:17 step:80325[D loss: 0.999961] [G loss: 1.000039]\n",
      "epoch:17 step:80330[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:17 step:80335[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:17 step:80340[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:17 step:80345[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:17 step:80350[D loss: 1.000002] [G loss: 0.999986]\n",
      "epoch:17 step:80355[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:17 step:80360[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:17 step:80365[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:17 step:80370[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:17 step:80375[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:17 step:80380[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:17 step:80385[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:17 step:80390[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:17 step:80395[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:17 step:80400[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:17 step:80405[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:17 step:80410[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:17 step:80415[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:17 step:80420[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:17 step:80425[D loss: 1.000042] [G loss: 1.000014]\n",
      "epoch:17 step:80430[D loss: 0.999925] [G loss: 1.000101]\n",
      "epoch:17 step:80435[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:17 step:80440[D loss: 0.999992] [G loss: 1.000006]\n",
      "epoch:17 step:80445[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:17 step:80450[D loss: 1.000027] [G loss: 1.000017]\n",
      "epoch:17 step:80455[D loss: 1.000017] [G loss: 1.000052]\n",
      "epoch:17 step:80460[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:17 step:80465[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:17 step:80470[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:17 step:80475[D loss: 0.999930] [G loss: 1.000109]\n",
      "epoch:17 step:80480[D loss: 0.999919] [G loss: 1.000100]\n",
      "epoch:17 step:80485[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:17 step:80490[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:17 step:80495[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:17 step:80500[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:17 step:80505[D loss: 0.999983] [G loss: 1.000034]\n",
      "epoch:17 step:80510[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:17 step:80515[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:17 step:80520[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:17 step:80525[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:17 step:80530[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:17 step:80535[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:17 step:80540[D loss: 0.999957] [G loss: 1.000127]\n",
      "epoch:17 step:80545[D loss: 0.999946] [G loss: 1.000084]\n",
      "epoch:17 step:80550[D loss: 0.999954] [G loss: 1.000085]\n",
      "epoch:17 step:80555[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:17 step:80560[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:17 step:80565[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:17 step:80570[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:17 step:80575[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:17 step:80580[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:17 step:80585[D loss: 1.000012] [G loss: 1.000042]\n",
      "epoch:17 step:80590[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:17 step:80595[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:17 step:80600[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:17 step:80605[D loss: 0.999975] [G loss: 1.000036]\n",
      "epoch:17 step:80610[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:17 step:80615[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:17 step:80620[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:17 step:80625[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:17 step:80630[D loss: 0.999952] [G loss: 1.000153]\n",
      "epoch:17 step:80635[D loss: 1.000020] [G loss: 1.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:80640[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:17 step:80645[D loss: 1.000039] [G loss: 1.000125]\n",
      "epoch:17 step:80650[D loss: 0.999932] [G loss: 1.000129]\n",
      "epoch:17 step:80655[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:17 step:80660[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:17 step:80665[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:17 step:80670[D loss: 1.000012] [G loss: 0.999995]\n",
      "epoch:17 step:80675[D loss: 1.000059] [G loss: 0.999903]\n",
      "epoch:17 step:80680[D loss: 1.000029] [G loss: 0.999992]\n",
      "epoch:17 step:80685[D loss: 0.999938] [G loss: 1.000021]\n",
      "epoch:17 step:80690[D loss: 1.000015] [G loss: 1.000029]\n",
      "epoch:17 step:80695[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:17 step:80700[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:17 step:80705[D loss: 0.999942] [G loss: 1.000131]\n",
      "epoch:17 step:80710[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:17 step:80715[D loss: 1.000028] [G loss: 1.000006]\n",
      "epoch:17 step:80720[D loss: 0.999957] [G loss: 1.000137]\n",
      "epoch:17 step:80725[D loss: 0.999997] [G loss: 1.000082]\n",
      "epoch:17 step:80730[D loss: 0.999976] [G loss: 1.000226]\n",
      "epoch:17 step:80735[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:17 step:80740[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:17 step:80745[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:17 step:80750[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:17 step:80755[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:17 step:80760[D loss: 1.000062] [G loss: 0.999979]\n",
      "epoch:17 step:80765[D loss: 0.999969] [G loss: 0.999997]\n",
      "epoch:17 step:80770[D loss: 0.999970] [G loss: 1.000171]\n",
      "epoch:17 step:80775[D loss: 1.000081] [G loss: 1.000058]\n",
      "epoch:17 step:80780[D loss: 1.000020] [G loss: 1.000101]\n",
      "epoch:17 step:80785[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:17 step:80790[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:17 step:80795[D loss: 1.000049] [G loss: 0.999983]\n",
      "epoch:17 step:80800[D loss: 0.999919] [G loss: 1.000122]\n",
      "epoch:17 step:80805[D loss: 0.999952] [G loss: 1.000064]\n",
      "epoch:17 step:80810[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:17 step:80815[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:17 step:80820[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:17 step:80825[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:17 step:80830[D loss: 1.000006] [G loss: 1.000071]\n",
      "epoch:17 step:80835[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:17 step:80840[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:17 step:80845[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:17 step:80850[D loss: 1.000017] [G loss: 1.000066]\n",
      "epoch:17 step:80855[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:17 step:80860[D loss: 0.999946] [G loss: 1.000121]\n",
      "epoch:17 step:80865[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:17 step:80870[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:17 step:80875[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:17 step:80880[D loss: 1.000008] [G loss: 0.999978]\n",
      "epoch:17 step:80885[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:17 step:80890[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:17 step:80895[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:17 step:80900[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:17 step:80905[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:17 step:80910[D loss: 1.000010] [G loss: 1.000003]\n",
      "epoch:17 step:80915[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:17 step:80920[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:17 step:80925[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:17 step:80930[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:17 step:80935[D loss: 1.000007] [G loss: 1.000028]\n",
      "epoch:17 step:80940[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:17 step:80945[D loss: 1.000007] [G loss: 1.000034]\n",
      "epoch:17 step:80950[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:17 step:80955[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:17 step:80960[D loss: 1.000023] [G loss: 1.000044]\n",
      "epoch:17 step:80965[D loss: 0.999955] [G loss: 1.000061]\n",
      "epoch:17 step:80970[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:17 step:80975[D loss: 1.000009] [G loss: 1.000037]\n",
      "epoch:17 step:80980[D loss: 0.999913] [G loss: 1.000125]\n",
      "epoch:17 step:80985[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:17 step:80990[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:17 step:80995[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:17 step:81000[D loss: 0.999967] [G loss: 1.000039]\n",
      "epoch:17 step:81005[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:17 step:81010[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:17 step:81015[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:17 step:81020[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:17 step:81025[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:17 step:81030[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:17 step:81035[D loss: 1.000025] [G loss: 1.000000]\n",
      "epoch:17 step:81040[D loss: 0.999950] [G loss: 1.000115]\n",
      "epoch:17 step:81045[D loss: 0.999906] [G loss: 1.000123]\n",
      "epoch:17 step:81050[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:17 step:81055[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:17 step:81060[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:17 step:81065[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:17 step:81070[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:17 step:81075[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:17 step:81080[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:17 step:81085[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:17 step:81090[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:17 step:81095[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:17 step:81100[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:17 step:81105[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:17 step:81110[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:17 step:81115[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:17 step:81120[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:17 step:81125[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:17 step:81130[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:17 step:81135[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:17 step:81140[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:17 step:81145[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:17 step:81150[D loss: 0.999945] [G loss: 1.000090]\n",
      "epoch:17 step:81155[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:17 step:81160[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:17 step:81165[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:17 step:81170[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:17 step:81175[D loss: 1.000027] [G loss: 1.000009]\n",
      "epoch:17 step:81180[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:17 step:81185[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:17 step:81190[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:17 step:81195[D loss: 1.000028] [G loss: 0.999986]\n",
      "epoch:17 step:81200[D loss: 1.000048] [G loss: 1.000007]\n",
      "epoch:17 step:81205[D loss: 0.999977] [G loss: 0.999986]\n",
      "epoch:17 step:81210[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:17 step:81215[D loss: 0.999957] [G loss: 1.000105]\n",
      "epoch:17 step:81220[D loss: 0.999950] [G loss: 1.000151]\n",
      "epoch:17 step:81225[D loss: 1.000017] [G loss: 1.000125]\n",
      "epoch:17 step:81230[D loss: 0.999960] [G loss: 1.000047]\n",
      "epoch:17 step:81235[D loss: 0.999994] [G loss: 0.999997]\n",
      "epoch:17 step:81240[D loss: 1.000003] [G loss: 0.999992]\n",
      "epoch:17 step:81245[D loss: 0.999967] [G loss: 1.000012]\n",
      "epoch:17 step:81250[D loss: 1.000015] [G loss: 0.999992]\n",
      "epoch:17 step:81255[D loss: 1.000013] [G loss: 1.000008]\n",
      "epoch:17 step:81260[D loss: 1.000030] [G loss: 1.000006]\n",
      "epoch:17 step:81265[D loss: 0.999967] [G loss: 1.000020]\n",
      "epoch:17 step:81270[D loss: 0.999979] [G loss: 1.000016]\n",
      "epoch:17 step:81275[D loss: 0.999951] [G loss: 1.000055]\n",
      "epoch:17 step:81280[D loss: 1.000016] [G loss: 0.999989]\n",
      "epoch:17 step:81285[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:17 step:81290[D loss: 0.999959] [G loss: 1.000043]\n",
      "epoch:17 step:81295[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:17 step:81300[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:17 step:81305[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:17 step:81310[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:17 step:81315[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:17 step:81320[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:17 step:81325[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:17 step:81330[D loss: 0.999997] [G loss: 1.000005]\n",
      "epoch:17 step:81335[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:17 step:81340[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:17 step:81345[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:17 step:81350[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:17 step:81355[D loss: 0.999975] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:81360[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:17 step:81365[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:17 step:81370[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:17 step:81375[D loss: 0.999993] [G loss: 1.000091]\n",
      "epoch:17 step:81380[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:17 step:81385[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:17 step:81390[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:17 step:81395[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:17 step:81400[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:17 step:81405[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:17 step:81410[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:17 step:81415[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:17 step:81420[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:17 step:81425[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:17 step:81430[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:17 step:81435[D loss: 1.000046] [G loss: 0.999951]\n",
      "epoch:17 step:81440[D loss: 0.999950] [G loss: 1.000071]\n",
      "epoch:17 step:81445[D loss: 0.999984] [G loss: 1.000090]\n",
      "epoch:17 step:81450[D loss: 0.999946] [G loss: 1.000083]\n",
      "epoch:17 step:81455[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:17 step:81460[D loss: 0.999993] [G loss: 1.000108]\n",
      "epoch:17 step:81465[D loss: 1.000031] [G loss: 1.000094]\n",
      "epoch:17 step:81470[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:17 step:81475[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:17 step:81480[D loss: 0.999957] [G loss: 1.000160]\n",
      "epoch:17 step:81485[D loss: 0.999928] [G loss: 1.000200]\n",
      "epoch:17 step:81490[D loss: 1.000008] [G loss: 1.000034]\n",
      "epoch:17 step:81495[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:17 step:81500[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:17 step:81505[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:17 step:81510[D loss: 0.999998] [G loss: 1.000000]\n",
      "epoch:17 step:81515[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:17 step:81520[D loss: 1.000012] [G loss: 0.999989]\n",
      "epoch:17 step:81525[D loss: 0.999999] [G loss: 1.000072]\n",
      "epoch:17 step:81530[D loss: 0.999964] [G loss: 1.000129]\n",
      "epoch:17 step:81535[D loss: 1.000006] [G loss: 1.000133]\n",
      "epoch:17 step:81540[D loss: 0.999902] [G loss: 1.000139]\n",
      "epoch:17 step:81545[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:17 step:81550[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:17 step:81555[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:17 step:81560[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:17 step:81565[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:17 step:81570[D loss: 1.000031] [G loss: 1.000048]\n",
      "epoch:17 step:81575[D loss: 0.999926] [G loss: 1.000109]\n",
      "epoch:17 step:81580[D loss: 0.999979] [G loss: 1.000189]\n",
      "epoch:17 step:81585[D loss: 0.999950] [G loss: 1.000160]\n",
      "epoch:17 step:81590[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:17 step:81595[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:17 step:81600[D loss: 1.000051] [G loss: 0.999959]\n",
      "epoch:17 step:81605[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:17 step:81610[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:17 step:81615[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:17 step:81620[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:17 step:81625[D loss: 0.999956] [G loss: 1.000109]\n",
      "epoch:17 step:81630[D loss: 1.000017] [G loss: 0.999993]\n",
      "epoch:17 step:81635[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:17 step:81640[D loss: 0.999930] [G loss: 1.000125]\n",
      "epoch:17 step:81645[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:17 step:81650[D loss: 0.999969] [G loss: 1.000125]\n",
      "epoch:17 step:81655[D loss: 0.999947] [G loss: 1.000110]\n",
      "epoch:17 step:81660[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:17 step:81665[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:17 step:81670[D loss: 1.000004] [G loss: 1.000053]\n",
      "epoch:17 step:81675[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:17 step:81680[D loss: 1.000045] [G loss: 1.000003]\n",
      "epoch:17 step:81685[D loss: 0.999960] [G loss: 1.000038]\n",
      "epoch:17 step:81690[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:17 step:81695[D loss: 0.999968] [G loss: 1.000169]\n",
      "epoch:17 step:81700[D loss: 0.999914] [G loss: 1.000126]\n",
      "epoch:17 step:81705[D loss: 1.000016] [G loss: 1.000048]\n",
      "epoch:17 step:81710[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:17 step:81715[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:17 step:81720[D loss: 0.999950] [G loss: 1.000029]\n",
      "epoch:17 step:81725[D loss: 0.999952] [G loss: 1.000057]\n",
      "epoch:17 step:81730[D loss: 1.000023] [G loss: 0.999952]\n",
      "epoch:17 step:81735[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:17 step:81740[D loss: 0.999957] [G loss: 1.000054]\n",
      "epoch:17 step:81745[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:17 step:81750[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:17 step:81755[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:17 step:81760[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:17 step:81765[D loss: 1.000005] [G loss: 1.000051]\n",
      "epoch:17 step:81770[D loss: 0.999943] [G loss: 1.000120]\n",
      "epoch:17 step:81775[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:17 step:81780[D loss: 0.999942] [G loss: 1.000096]\n",
      "epoch:17 step:81785[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:17 step:81790[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:17 step:81795[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:17 step:81800[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:17 step:81805[D loss: 1.000017] [G loss: 0.999987]\n",
      "epoch:17 step:81810[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:17 step:81815[D loss: 1.000027] [G loss: 0.999981]\n",
      "epoch:17 step:81820[D loss: 1.000017] [G loss: 0.999984]\n",
      "epoch:17 step:81825[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:17 step:81830[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:17 step:81835[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:17 step:81840[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:17 step:81845[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:17 step:81850[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:17 step:81855[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:17 step:81860[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:17 step:81865[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:17 step:81870[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:17 step:81875[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:17 step:81880[D loss: 1.000021] [G loss: 1.000020]\n",
      "epoch:17 step:81885[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:17 step:81890[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:17 step:81895[D loss: 0.999999] [G loss: 1.000047]\n",
      "epoch:17 step:81900[D loss: 0.999998] [G loss: 1.000002]\n",
      "epoch:17 step:81905[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:17 step:81910[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:17 step:81915[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:17 step:81920[D loss: 0.999953] [G loss: 1.000057]\n",
      "epoch:17 step:81925[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:17 step:81930[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:17 step:81935[D loss: 0.999965] [G loss: 1.000130]\n",
      "epoch:17 step:81940[D loss: 1.000111] [G loss: 1.000020]\n",
      "epoch:17 step:81945[D loss: 0.999924] [G loss: 1.000121]\n",
      "epoch:17 step:81950[D loss: 1.000009] [G loss: 1.000079]\n",
      "epoch:17 step:81955[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:17 step:81960[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:17 step:81965[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:17 step:81970[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:17 step:81975[D loss: 0.999974] [G loss: 1.000003]\n",
      "epoch:17 step:81980[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:17 step:81985[D loss: 1.000073] [G loss: 0.999998]\n",
      "epoch:17 step:81990[D loss: 1.000051] [G loss: 1.000099]\n",
      "epoch:17 step:81995[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:17 step:82000[D loss: 0.999946] [G loss: 1.000171]\n",
      "epoch:17 step:82005[D loss: 0.999936] [G loss: 1.000110]\n",
      "epoch:17 step:82010[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:17 step:82015[D loss: 1.000018] [G loss: 1.000006]\n",
      "epoch:17 step:82020[D loss: 1.000008] [G loss: 0.999970]\n",
      "epoch:17 step:82025[D loss: 0.999955] [G loss: 1.000033]\n",
      "epoch:17 step:82030[D loss: 1.000018] [G loss: 0.999937]\n",
      "epoch:17 step:82035[D loss: 1.000050] [G loss: 1.000001]\n",
      "epoch:17 step:82040[D loss: 0.999941] [G loss: 1.000048]\n",
      "epoch:17 step:82045[D loss: 0.999960] [G loss: 1.000056]\n",
      "epoch:17 step:82050[D loss: 1.000028] [G loss: 0.999953]\n",
      "epoch:17 step:82055[D loss: 0.999945] [G loss: 1.000091]\n",
      "epoch:17 step:82060[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:17 step:82065[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:17 step:82070[D loss: 1.000010] [G loss: 1.000072]\n",
      "epoch:17 step:82075[D loss: 0.999954] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:82080[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:17 step:82085[D loss: 1.000000] [G loss: 1.000093]\n",
      "epoch:17 step:82090[D loss: 1.000014] [G loss: 1.000110]\n",
      "epoch:17 step:82095[D loss: 0.999956] [G loss: 1.000163]\n",
      "epoch:17 step:82100[D loss: 0.999990] [G loss: 1.000077]\n",
      "epoch:17 step:82105[D loss: 0.999976] [G loss: 1.000143]\n",
      "epoch:17 step:82110[D loss: 0.999842] [G loss: 1.000395]\n",
      "epoch:17 step:82115[D loss: 0.999908] [G loss: 1.000252]\n",
      "epoch:17 step:82120[D loss: 0.999972] [G loss: 1.000009]\n",
      "epoch:17 step:82125[D loss: 1.000014] [G loss: 1.000055]\n",
      "epoch:17 step:82130[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:17 step:82135[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:17 step:82140[D loss: 1.000061] [G loss: 0.999986]\n",
      "epoch:17 step:82145[D loss: 1.000045] [G loss: 1.000029]\n",
      "epoch:17 step:82150[D loss: 0.999912] [G loss: 1.000052]\n",
      "epoch:17 step:82155[D loss: 0.999962] [G loss: 1.000033]\n",
      "epoch:17 step:82160[D loss: 0.999925] [G loss: 1.000115]\n",
      "epoch:17 step:82165[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:17 step:82170[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:17 step:82175[D loss: 0.999954] [G loss: 1.000097]\n",
      "epoch:17 step:82180[D loss: 1.000057] [G loss: 0.999964]\n",
      "epoch:17 step:82185[D loss: 1.000000] [G loss: 1.000084]\n",
      "epoch:17 step:82190[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:17 step:82195[D loss: 1.000048] [G loss: 1.000105]\n",
      "epoch:17 step:82200[D loss: 0.999962] [G loss: 1.000098]\n",
      "epoch:17 step:82205[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:17 step:82210[D loss: 0.999999] [G loss: 1.000009]\n",
      "epoch:17 step:82215[D loss: 1.000008] [G loss: 0.999974]\n",
      "epoch:17 step:82220[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:17 step:82225[D loss: 1.000000] [G loss: 0.999992]\n",
      "epoch:17 step:82230[D loss: 0.999999] [G loss: 1.000085]\n",
      "epoch:17 step:82235[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:17 step:82240[D loss: 0.999963] [G loss: 1.000124]\n",
      "epoch:17 step:82245[D loss: 0.999916] [G loss: 1.000154]\n",
      "epoch:17 step:82250[D loss: 0.999973] [G loss: 1.000103]\n",
      "epoch:17 step:82255[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:17 step:82260[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:17 step:82265[D loss: 0.999968] [G loss: 1.000115]\n",
      "epoch:17 step:82270[D loss: 0.999978] [G loss: 1.000024]\n",
      "epoch:17 step:82275[D loss: 1.000002] [G loss: 0.999966]\n",
      "epoch:17 step:82280[D loss: 0.999971] [G loss: 1.000028]\n",
      "epoch:17 step:82285[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:17 step:82290[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:17 step:82295[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:17 step:82300[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:17 step:82305[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:17 step:82310[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:17 step:82315[D loss: 1.000004] [G loss: 1.000002]\n",
      "epoch:17 step:82320[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:17 step:82325[D loss: 1.000012] [G loss: 1.000126]\n",
      "epoch:17 step:82330[D loss: 1.000060] [G loss: 1.000007]\n",
      "epoch:17 step:82335[D loss: 0.999945] [G loss: 1.000132]\n",
      "epoch:17 step:82340[D loss: 0.999970] [G loss: 1.000105]\n",
      "epoch:17 step:82345[D loss: 0.999960] [G loss: 1.000107]\n",
      "epoch:17 step:82350[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:17 step:82355[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:17 step:82360[D loss: 1.000022] [G loss: 1.000045]\n",
      "epoch:17 step:82365[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:17 step:82370[D loss: 1.000023] [G loss: 0.999977]\n",
      "epoch:17 step:82375[D loss: 1.000044] [G loss: 0.999917]\n",
      "epoch:17 step:82380[D loss: 0.999972] [G loss: 0.999992]\n",
      "epoch:17 step:82385[D loss: 0.999954] [G loss: 1.000108]\n",
      "epoch:17 step:82390[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:17 step:82395[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:17 step:82400[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:17 step:82405[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:17 step:82410[D loss: 1.000011] [G loss: 1.000060]\n",
      "epoch:17 step:82415[D loss: 0.999950] [G loss: 1.000082]\n",
      "epoch:17 step:82420[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:17 step:82425[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:17 step:82430[D loss: 0.999999] [G loss: 1.000010]\n",
      "epoch:17 step:82435[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:17 step:82440[D loss: 0.999998] [G loss: 1.000075]\n",
      "epoch:17 step:82445[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:17 step:82450[D loss: 1.000000] [G loss: 1.000010]\n",
      "epoch:17 step:82455[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:17 step:82460[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:17 step:82465[D loss: 0.999992] [G loss: 1.000021]\n",
      "epoch:17 step:82470[D loss: 0.999951] [G loss: 1.000124]\n",
      "epoch:17 step:82475[D loss: 0.999940] [G loss: 1.000095]\n",
      "epoch:17 step:82480[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:17 step:82485[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:17 step:82490[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:17 step:82495[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:17 step:82500[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:17 step:82505[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:17 step:82510[D loss: 1.000012] [G loss: 1.000086]\n",
      "epoch:17 step:82515[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:17 step:82520[D loss: 0.999988] [G loss: 1.000214]\n",
      "epoch:17 step:82525[D loss: 0.999922] [G loss: 1.000182]\n",
      "epoch:17 step:82530[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:17 step:82535[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:17 step:82540[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:17 step:82545[D loss: 1.000000] [G loss: 1.000109]\n",
      "epoch:17 step:82550[D loss: 1.000015] [G loss: 0.999983]\n",
      "epoch:17 step:82555[D loss: 1.000015] [G loss: 1.000010]\n",
      "epoch:17 step:82560[D loss: 1.000048] [G loss: 0.999954]\n",
      "epoch:17 step:82565[D loss: 0.999933] [G loss: 1.000075]\n",
      "epoch:17 step:82570[D loss: 0.999952] [G loss: 1.000102]\n",
      "epoch:17 step:82575[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:17 step:82580[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:17 step:82585[D loss: 1.000003] [G loss: 1.000092]\n",
      "epoch:17 step:82590[D loss: 1.000039] [G loss: 1.000050]\n",
      "epoch:17 step:82595[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:17 step:82600[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:17 step:82605[D loss: 1.000056] [G loss: 0.999998]\n",
      "epoch:17 step:82610[D loss: 1.000065] [G loss: 1.000037]\n",
      "epoch:17 step:82615[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:17 step:82620[D loss: 1.000043] [G loss: 1.000049]\n",
      "epoch:17 step:82625[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:17 step:82630[D loss: 0.999954] [G loss: 1.000136]\n",
      "epoch:17 step:82635[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:17 step:82640[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:17 step:82645[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:17 step:82650[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:17 step:82655[D loss: 0.999958] [G loss: 1.000077]\n",
      "epoch:17 step:82660[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:17 step:82665[D loss: 0.999929] [G loss: 1.000150]\n",
      "epoch:17 step:82670[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:17 step:82675[D loss: 0.999994] [G loss: 1.000057]\n",
      "epoch:17 step:82680[D loss: 0.999954] [G loss: 1.000155]\n",
      "epoch:17 step:82685[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:17 step:82690[D loss: 1.000074] [G loss: 1.000048]\n",
      "epoch:17 step:82695[D loss: 0.999929] [G loss: 1.000089]\n",
      "epoch:17 step:82700[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:17 step:82705[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:17 step:82710[D loss: 0.999955] [G loss: 1.000064]\n",
      "epoch:17 step:82715[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:17 step:82720[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:17 step:82725[D loss: 0.999978] [G loss: 0.999994]\n",
      "epoch:17 step:82730[D loss: 1.000080] [G loss: 0.999984]\n",
      "epoch:17 step:82735[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:17 step:82740[D loss: 0.999945] [G loss: 1.000052]\n",
      "epoch:17 step:82745[D loss: 1.000007] [G loss: 1.000082]\n",
      "epoch:17 step:82750[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:17 step:82755[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:17 step:82760[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:17 step:82765[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:17 step:82770[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:17 step:82775[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:17 step:82780[D loss: 1.000020] [G loss: 0.999990]\n",
      "epoch:17 step:82785[D loss: 0.999965] [G loss: 1.000034]\n",
      "epoch:17 step:82790[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:17 step:82795[D loss: 0.999982] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:82800[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:17 step:82805[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:17 step:82810[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:17 step:82815[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:17 step:82820[D loss: 1.000003] [G loss: 1.000001]\n",
      "epoch:17 step:82825[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:17 step:82830[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:17 step:82835[D loss: 0.999950] [G loss: 1.000054]\n",
      "epoch:17 step:82840[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:17 step:82845[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:17 step:82850[D loss: 1.000003] [G loss: 1.000052]\n",
      "epoch:17 step:82855[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:17 step:82860[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:17 step:82865[D loss: 1.000009] [G loss: 0.999979]\n",
      "epoch:17 step:82870[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:17 step:82875[D loss: 0.999957] [G loss: 1.000109]\n",
      "epoch:17 step:82880[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:17 step:82885[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:17 step:82890[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:17 step:82895[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:17 step:82900[D loss: 0.999974] [G loss: 1.000086]\n",
      "epoch:17 step:82905[D loss: 0.999954] [G loss: 1.000097]\n",
      "epoch:17 step:82910[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:17 step:82915[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:17 step:82920[D loss: 0.999937] [G loss: 1.000094]\n",
      "epoch:17 step:82925[D loss: 1.000021] [G loss: 0.999996]\n",
      "epoch:17 step:82930[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:17 step:82935[D loss: 0.999946] [G loss: 1.000077]\n",
      "epoch:17 step:82940[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:17 step:82945[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:17 step:82950[D loss: 1.000064] [G loss: 0.999894]\n",
      "epoch:17 step:82955[D loss: 1.000035] [G loss: 1.000044]\n",
      "epoch:17 step:82960[D loss: 1.000043] [G loss: 0.999975]\n",
      "epoch:17 step:82965[D loss: 0.999957] [G loss: 1.000042]\n",
      "epoch:17 step:82970[D loss: 0.999946] [G loss: 1.000084]\n",
      "epoch:17 step:82975[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:17 step:82980[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:17 step:82985[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:17 step:82990[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:17 step:82995[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:17 step:83000[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:17 step:83005[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:17 step:83010[D loss: 1.000024] [G loss: 0.999959]\n",
      "epoch:17 step:83015[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:17 step:83020[D loss: 1.000040] [G loss: 0.999923]\n",
      "epoch:17 step:83025[D loss: 0.999951] [G loss: 1.000061]\n",
      "epoch:17 step:83030[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:17 step:83035[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:17 step:83040[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:17 step:83045[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:17 step:83050[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:17 step:83055[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:17 step:83060[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:17 step:83065[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:17 step:83070[D loss: 0.999993] [G loss: 1.000020]\n",
      "epoch:17 step:83075[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:17 step:83080[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:17 step:83085[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:17 step:83090[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:17 step:83095[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:17 step:83100[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:17 step:83105[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:17 step:83110[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:17 step:83115[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:17 step:83120[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:17 step:83125[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:17 step:83130[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:17 step:83135[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:17 step:83140[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:17 step:83145[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:17 step:83150[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:17 step:83155[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:17 step:83160[D loss: 1.000013] [G loss: 0.999982]\n",
      "epoch:17 step:83165[D loss: 0.999938] [G loss: 1.000109]\n",
      "epoch:17 step:83170[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:17 step:83175[D loss: 0.999942] [G loss: 1.000118]\n",
      "epoch:17 step:83180[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:17 step:83185[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:17 step:83190[D loss: 1.000040] [G loss: 1.000043]\n",
      "epoch:17 step:83195[D loss: 0.999934] [G loss: 1.000231]\n",
      "epoch:17 step:83200[D loss: 0.999909] [G loss: 1.000157]\n",
      "epoch:17 step:83205[D loss: 1.000017] [G loss: 0.999945]\n",
      "epoch:17 step:83210[D loss: 0.999958] [G loss: 1.000104]\n",
      "epoch:17 step:83215[D loss: 1.000071] [G loss: 1.000009]\n",
      "epoch:17 step:83220[D loss: 0.999928] [G loss: 1.000158]\n",
      "epoch:17 step:83225[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:17 step:83230[D loss: 0.999985] [G loss: 1.000008]\n",
      "epoch:17 step:83235[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:17 step:83240[D loss: 0.999966] [G loss: 1.000042]\n",
      "epoch:17 step:83245[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:17 step:83250[D loss: 0.999976] [G loss: 1.000118]\n",
      "epoch:17 step:83255[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:17 step:83260[D loss: 1.000010] [G loss: 1.000110]\n",
      "epoch:17 step:83265[D loss: 0.999981] [G loss: 1.000097]\n",
      "epoch:17 step:83270[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:17 step:83275[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:17 step:83280[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:17 step:83285[D loss: 0.999994] [G loss: 1.000087]\n",
      "epoch:17 step:83290[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:17 step:83295[D loss: 1.000009] [G loss: 0.999989]\n",
      "epoch:17 step:83300[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:17 step:83305[D loss: 1.000005] [G loss: 0.999998]\n",
      "epoch:17 step:83310[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:17 step:83315[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:17 step:83320[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:17 step:83325[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:17 step:83330[D loss: 1.000070] [G loss: 0.999980]\n",
      "epoch:17 step:83335[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:17 step:83340[D loss: 0.999974] [G loss: 1.000169]\n",
      "epoch:17 step:83345[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:17 step:83350[D loss: 0.999997] [G loss: 1.000038]\n",
      "epoch:17 step:83355[D loss: 1.000055] [G loss: 1.000010]\n",
      "epoch:17 step:83360[D loss: 0.999941] [G loss: 1.000060]\n",
      "epoch:17 step:83365[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:17 step:83370[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:17 step:83375[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:17 step:83380[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:17 step:83385[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:17 step:83390[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:17 step:83395[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:17 step:83400[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:17 step:83405[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:17 step:83410[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:17 step:83415[D loss: 1.000059] [G loss: 1.000009]\n",
      "epoch:17 step:83420[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:17 step:83425[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:17 step:83430[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:17 step:83435[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:17 step:83440[D loss: 0.999952] [G loss: 1.000104]\n",
      "epoch:17 step:83445[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:17 step:83450[D loss: 0.999974] [G loss: 1.000114]\n",
      "epoch:17 step:83455[D loss: 1.000042] [G loss: 1.000045]\n",
      "epoch:17 step:83460[D loss: 1.000015] [G loss: 0.999966]\n",
      "epoch:17 step:83465[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:17 step:83470[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:17 step:83475[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:17 step:83480[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:17 step:83485[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:17 step:83490[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:17 step:83495[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:17 step:83500[D loss: 0.999950] [G loss: 1.000125]\n",
      "epoch:17 step:83505[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:17 step:83510[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:17 step:83515[D loss: 0.999937] [G loss: 1.000216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:83520[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:17 step:83525[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:17 step:83530[D loss: 0.999994] [G loss: 1.000013]\n",
      "epoch:17 step:83535[D loss: 0.999968] [G loss: 1.000106]\n",
      "epoch:17 step:83540[D loss: 1.000044] [G loss: 0.999977]\n",
      "epoch:17 step:83545[D loss: 0.999977] [G loss: 1.000093]\n",
      "epoch:17 step:83550[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:17 step:83555[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:17 step:83560[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:17 step:83565[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:17 step:83570[D loss: 0.999973] [G loss: 1.000087]\n",
      "epoch:17 step:83575[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:17 step:83580[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:17 step:83585[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:17 step:83590[D loss: 0.999997] [G loss: 1.000080]\n",
      "epoch:17 step:83595[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:17 step:83600[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:17 step:83605[D loss: 0.999951] [G loss: 1.000083]\n",
      "epoch:17 step:83610[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:17 step:83615[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:17 step:83620[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:17 step:83625[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:17 step:83630[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:17 step:83635[D loss: 0.999987] [G loss: 1.000089]\n",
      "epoch:17 step:83640[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:17 step:83645[D loss: 1.000010] [G loss: 1.000005]\n",
      "epoch:17 step:83650[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:17 step:83655[D loss: 0.999939] [G loss: 1.000120]\n",
      "epoch:17 step:83660[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:17 step:83665[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:17 step:83670[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:17 step:83675[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:17 step:83680[D loss: 0.999968] [G loss: 1.000090]\n",
      "epoch:17 step:83685[D loss: 1.000022] [G loss: 1.000041]\n",
      "epoch:17 step:83690[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:17 step:83695[D loss: 0.999998] [G loss: 1.000068]\n",
      "epoch:17 step:83700[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:17 step:83705[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:17 step:83710[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:17 step:83715[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:17 step:83720[D loss: 1.000027] [G loss: 0.999958]\n",
      "epoch:17 step:83725[D loss: 0.999952] [G loss: 1.000025]\n",
      "epoch:17 step:83730[D loss: 0.999934] [G loss: 1.000073]\n",
      "epoch:17 step:83735[D loss: 1.000022] [G loss: 1.000019]\n",
      "epoch:17 step:83740[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:17 step:83745[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:17 step:83750[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:17 step:83755[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:17 step:83760[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:17 step:83765[D loss: 0.999946] [G loss: 1.000107]\n",
      "epoch:17 step:83770[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:17 step:83775[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:17 step:83780[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:17 step:83785[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:17 step:83790[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:17 step:83795[D loss: 0.999975] [G loss: 1.000090]\n",
      "epoch:17 step:83800[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:17 step:83805[D loss: 1.000011] [G loss: 1.000052]\n",
      "epoch:17 step:83810[D loss: 0.999917] [G loss: 1.000084]\n",
      "epoch:17 step:83815[D loss: 1.000020] [G loss: 1.000057]\n",
      "epoch:17 step:83820[D loss: 0.999991] [G loss: 0.999995]\n",
      "epoch:17 step:83825[D loss: 0.999985] [G loss: 1.000071]\n",
      "epoch:17 step:83830[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:17 step:83835[D loss: 1.000024] [G loss: 1.000004]\n",
      "epoch:17 step:83840[D loss: 0.999960] [G loss: 1.000136]\n",
      "epoch:17 step:83845[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:17 step:83850[D loss: 0.999981] [G loss: 1.000033]\n",
      "epoch:17 step:83855[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:17 step:83860[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:17 step:83865[D loss: 0.999977] [G loss: 1.000119]\n",
      "epoch:17 step:83870[D loss: 0.999948] [G loss: 1.000096]\n",
      "epoch:17 step:83875[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:17 step:83880[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:17 step:83885[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:17 step:83890[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:17 step:83895[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:17 step:83900[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:17 step:83905[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:17 step:83910[D loss: 1.000014] [G loss: 1.000009]\n",
      "epoch:17 step:83915[D loss: 0.999982] [G loss: 1.000021]\n",
      "epoch:17 step:83920[D loss: 0.999970] [G loss: 1.000022]\n",
      "epoch:17 step:83925[D loss: 0.999999] [G loss: 1.000058]\n",
      "epoch:17 step:83930[D loss: 1.000001] [G loss: 0.999976]\n",
      "epoch:17 step:83935[D loss: 0.999956] [G loss: 1.000059]\n",
      "epoch:17 step:83940[D loss: 0.999979] [G loss: 1.000078]\n",
      "epoch:17 step:83945[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:17 step:83950[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:17 step:83955[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:17 step:83960[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:17 step:83965[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:17 step:83970[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:17 step:83975[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:17 step:83980[D loss: 1.000045] [G loss: 0.999966]\n",
      "epoch:17 step:83985[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:17 step:83990[D loss: 1.000023] [G loss: 0.999963]\n",
      "epoch:17 step:83995[D loss: 0.999984] [G loss: 1.000122]\n",
      "epoch:17 step:84000[D loss: 0.999957] [G loss: 1.000042]\n",
      "epoch:17 step:84005[D loss: 1.000066] [G loss: 0.999899]\n",
      "epoch:17 step:84010[D loss: 0.999934] [G loss: 1.000041]\n",
      "epoch:17 step:84015[D loss: 0.999989] [G loss: 1.000012]\n",
      "epoch:17 step:84020[D loss: 1.000009] [G loss: 0.999980]\n",
      "epoch:17 step:84025[D loss: 0.999979] [G loss: 1.000125]\n",
      "epoch:17 step:84030[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:17 step:84035[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:17 step:84040[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:17 step:84045[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:17 step:84050[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:17 step:84055[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:17 step:84060[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:17 step:84065[D loss: 0.999968] [G loss: 1.000039]\n",
      "epoch:17 step:84070[D loss: 0.999946] [G loss: 1.000139]\n",
      "epoch:17 step:84075[D loss: 0.999940] [G loss: 1.000117]\n",
      "epoch:17 step:84080[D loss: 0.999942] [G loss: 1.000075]\n",
      "epoch:17 step:84085[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:17 step:84090[D loss: 0.999995] [G loss: 1.000019]\n",
      "epoch:17 step:84095[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:17 step:84100[D loss: 0.999994] [G loss: 1.000021]\n",
      "epoch:17 step:84105[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:17 step:84110[D loss: 1.000012] [G loss: 1.000038]\n",
      "epoch:17 step:84115[D loss: 1.000006] [G loss: 1.000052]\n",
      "epoch:17 step:84120[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:17 step:84125[D loss: 1.000007] [G loss: 0.999989]\n",
      "epoch:17 step:84130[D loss: 0.999933] [G loss: 1.000074]\n",
      "epoch:17 step:84135[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:17 step:84140[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:17 step:84145[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:17 step:84150[D loss: 0.999995] [G loss: 1.000116]\n",
      "epoch:17 step:84155[D loss: 0.999998] [G loss: 0.999985]\n",
      "epoch:17 step:84160[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:17 step:84165[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:17 step:84170[D loss: 1.000004] [G loss: 0.999978]\n",
      "epoch:17 step:84175[D loss: 1.000011] [G loss: 1.000007]\n",
      "epoch:17 step:84180[D loss: 0.999986] [G loss: 1.000026]\n",
      "epoch:17 step:84185[D loss: 0.999987] [G loss: 1.000104]\n",
      "epoch:17 step:84190[D loss: 0.999921] [G loss: 1.000132]\n",
      "epoch:17 step:84195[D loss: 0.999968] [G loss: 1.000035]\n",
      "epoch:17 step:84200[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:17 step:84205[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:17 step:84210[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:17 step:84215[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:17 step:84220[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:17 step:84225[D loss: 0.999954] [G loss: 1.000067]\n",
      "epoch:17 step:84230[D loss: 1.000032] [G loss: 1.000039]\n",
      "epoch:17 step:84235[D loss: 0.999970] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:84240[D loss: 1.000014] [G loss: 0.999960]\n",
      "epoch:17 step:84245[D loss: 0.999989] [G loss: 0.999992]\n",
      "epoch:17 step:84250[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:17 step:84255[D loss: 0.999942] [G loss: 1.000093]\n",
      "epoch:17 step:84260[D loss: 0.999911] [G loss: 1.000124]\n",
      "epoch:17 step:84265[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:17 step:84270[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:17 step:84275[D loss: 0.999981] [G loss: 1.000078]\n",
      "epoch:17 step:84280[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:17 step:84285[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:17 step:84290[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:17 step:84295[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:17 step:84300[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:17 step:84305[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:17 step:84310[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:17 step:84315[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:17 step:84320[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:17 step:84325[D loss: 0.999956] [G loss: 1.000069]\n",
      "epoch:17 step:84330[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:18 step:84335[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:18 step:84340[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:18 step:84345[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:18 step:84350[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:18 step:84355[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:18 step:84360[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:18 step:84365[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:18 step:84370[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:18 step:84375[D loss: 1.000032] [G loss: 0.999960]\n",
      "epoch:18 step:84380[D loss: 1.000123] [G loss: 0.999854]\n",
      "epoch:18 step:84385[D loss: 0.999938] [G loss: 1.000114]\n",
      "epoch:18 step:84390[D loss: 0.999935] [G loss: 1.000086]\n",
      "epoch:18 step:84395[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:18 step:84400[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:18 step:84405[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:18 step:84410[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:18 step:84415[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:18 step:84420[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:18 step:84425[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:18 step:84430[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:18 step:84435[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:18 step:84440[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:18 step:84445[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:18 step:84450[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:18 step:84455[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:18 step:84460[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:18 step:84465[D loss: 1.000008] [G loss: 1.000066]\n",
      "epoch:18 step:84470[D loss: 0.999955] [G loss: 1.000095]\n",
      "epoch:18 step:84475[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:18 step:84480[D loss: 1.000004] [G loss: 1.000027]\n",
      "epoch:18 step:84485[D loss: 0.999940] [G loss: 1.000041]\n",
      "epoch:18 step:84490[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:18 step:84495[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:18 step:84500[D loss: 0.999996] [G loss: 1.000100]\n",
      "epoch:18 step:84505[D loss: 0.999949] [G loss: 1.000107]\n",
      "epoch:18 step:84510[D loss: 1.000030] [G loss: 1.000009]\n",
      "epoch:18 step:84515[D loss: 0.999893] [G loss: 1.000193]\n",
      "epoch:18 step:84520[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:18 step:84525[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:18 step:84530[D loss: 1.000091] [G loss: 0.999880]\n",
      "epoch:18 step:84535[D loss: 1.000032] [G loss: 0.999975]\n",
      "epoch:18 step:84540[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:18 step:84545[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:18 step:84550[D loss: 0.999972] [G loss: 1.000031]\n",
      "epoch:18 step:84555[D loss: 0.999943] [G loss: 1.000120]\n",
      "epoch:18 step:84560[D loss: 0.999991] [G loss: 1.000031]\n",
      "epoch:18 step:84565[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:18 step:84570[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:18 step:84575[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:18 step:84580[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:18 step:84585[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:18 step:84590[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:18 step:84595[D loss: 0.999999] [G loss: 1.000029]\n",
      "epoch:18 step:84600[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:18 step:84605[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:18 step:84610[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:18 step:84615[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:18 step:84620[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:18 step:84625[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:18 step:84630[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:18 step:84635[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:18 step:84640[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:18 step:84645[D loss: 1.000007] [G loss: 1.000057]\n",
      "epoch:18 step:84650[D loss: 1.000030] [G loss: 0.999978]\n",
      "epoch:18 step:84655[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:18 step:84660[D loss: 1.000013] [G loss: 0.999968]\n",
      "epoch:18 step:84665[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:18 step:84670[D loss: 1.000006] [G loss: 1.000005]\n",
      "epoch:18 step:84675[D loss: 1.000028] [G loss: 1.000074]\n",
      "epoch:18 step:84680[D loss: 1.000076] [G loss: 0.999894]\n",
      "epoch:18 step:84685[D loss: 0.999911] [G loss: 1.000196]\n",
      "epoch:18 step:84690[D loss: 0.999943] [G loss: 1.000145]\n",
      "epoch:18 step:84695[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:18 step:84700[D loss: 0.999981] [G loss: 1.000019]\n",
      "epoch:18 step:84705[D loss: 1.000064] [G loss: 0.999950]\n",
      "epoch:18 step:84710[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:18 step:84715[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:18 step:84720[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:18 step:84725[D loss: 1.000003] [G loss: 1.000026]\n",
      "epoch:18 step:84730[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:18 step:84735[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:18 step:84740[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:18 step:84745[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:18 step:84750[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:18 step:84755[D loss: 0.999983] [G loss: 1.000001]\n",
      "epoch:18 step:84760[D loss: 0.999942] [G loss: 1.000111]\n",
      "epoch:18 step:84765[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:18 step:84770[D loss: 0.999979] [G loss: 1.000089]\n",
      "epoch:18 step:84775[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:18 step:84780[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:18 step:84785[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:18 step:84790[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:18 step:84795[D loss: 1.000015] [G loss: 1.000006]\n",
      "epoch:18 step:84800[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:18 step:84805[D loss: 1.000060] [G loss: 1.000018]\n",
      "epoch:18 step:84810[D loss: 0.999967] [G loss: 1.000134]\n",
      "epoch:18 step:84815[D loss: 0.999987] [G loss: 1.000123]\n",
      "epoch:18 step:84820[D loss: 0.999964] [G loss: 1.000122]\n",
      "epoch:18 step:84825[D loss: 0.999853] [G loss: 1.000230]\n",
      "epoch:18 step:84830[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:18 step:84835[D loss: 1.000017] [G loss: 0.999960]\n",
      "epoch:18 step:84840[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:18 step:84845[D loss: 1.000015] [G loss: 0.999983]\n",
      "epoch:18 step:84850[D loss: 0.999993] [G loss: 1.000104]\n",
      "epoch:18 step:84855[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:18 step:84860[D loss: 0.999948] [G loss: 1.000064]\n",
      "epoch:18 step:84865[D loss: 0.999999] [G loss: 1.000065]\n",
      "epoch:18 step:84870[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:18 step:84875[D loss: 0.999940] [G loss: 1.000097]\n",
      "epoch:18 step:84880[D loss: 0.999947] [G loss: 1.000129]\n",
      "epoch:18 step:84885[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:18 step:84890[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:18 step:84895[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:18 step:84900[D loss: 0.999953] [G loss: 1.000066]\n",
      "epoch:18 step:84905[D loss: 0.999999] [G loss: 1.000052]\n",
      "epoch:18 step:84910[D loss: 1.000000] [G loss: 1.000065]\n",
      "epoch:18 step:84915[D loss: 1.000076] [G loss: 0.999963]\n",
      "epoch:18 step:84920[D loss: 1.000038] [G loss: 1.000138]\n",
      "epoch:18 step:84925[D loss: 0.999937] [G loss: 1.000206]\n",
      "epoch:18 step:84930[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:18 step:84935[D loss: 0.999942] [G loss: 1.000151]\n",
      "epoch:18 step:84940[D loss: 0.999973] [G loss: 1.000098]\n",
      "epoch:18 step:84945[D loss: 0.999975] [G loss: 1.000105]\n",
      "epoch:18 step:84950[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:18 step:84955[D loss: 1.000004] [G loss: 1.000016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:84960[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:18 step:84965[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:18 step:84970[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:18 step:84975[D loss: 1.000022] [G loss: 0.999989]\n",
      "epoch:18 step:84980[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:18 step:84985[D loss: 0.999998] [G loss: 1.000001]\n",
      "epoch:18 step:84990[D loss: 0.999992] [G loss: 1.000073]\n",
      "epoch:18 step:84995[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:18 step:85000[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:18 step:85005[D loss: 0.999968] [G loss: 1.000065]\n",
      "epoch:18 step:85010[D loss: 1.000000] [G loss: 1.000005]\n",
      "epoch:18 step:85015[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:18 step:85020[D loss: 0.999939] [G loss: 1.000112]\n",
      "epoch:18 step:85025[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:18 step:85030[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:18 step:85035[D loss: 1.000008] [G loss: 1.000039]\n",
      "epoch:18 step:85040[D loss: 0.999947] [G loss: 1.000121]\n",
      "epoch:18 step:85045[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:18 step:85050[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:18 step:85055[D loss: 0.999955] [G loss: 1.000098]\n",
      "epoch:18 step:85060[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:18 step:85065[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:18 step:85070[D loss: 0.999963] [G loss: 1.000116]\n",
      "epoch:18 step:85075[D loss: 1.000037] [G loss: 0.999957]\n",
      "epoch:18 step:85080[D loss: 0.999935] [G loss: 1.000140]\n",
      "epoch:18 step:85085[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:18 step:85090[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:18 step:85095[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:18 step:85100[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:18 step:85105[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:18 step:85110[D loss: 0.999998] [G loss: 1.000029]\n",
      "epoch:18 step:85115[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:18 step:85120[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:18 step:85125[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:18 step:85130[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:18 step:85135[D loss: 1.000006] [G loss: 1.000071]\n",
      "epoch:18 step:85140[D loss: 1.000052] [G loss: 0.999947]\n",
      "epoch:18 step:85145[D loss: 0.999970] [G loss: 1.000043]\n",
      "epoch:18 step:85150[D loss: 0.999946] [G loss: 1.000085]\n",
      "epoch:18 step:85155[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:18 step:85160[D loss: 1.000009] [G loss: 0.999967]\n",
      "epoch:18 step:85165[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:18 step:85170[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:18 step:85175[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:18 step:85180[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:18 step:85185[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:18 step:85190[D loss: 0.999996] [G loss: 1.000008]\n",
      "epoch:18 step:85195[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:18 step:85200[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:18 step:85205[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:18 step:85210[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:18 step:85215[D loss: 0.999959] [G loss: 1.000097]\n",
      "epoch:18 step:85220[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:18 step:85225[D loss: 1.000025] [G loss: 0.999983]\n",
      "epoch:18 step:85230[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:18 step:85235[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:18 step:85240[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:18 step:85245[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:18 step:85250[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:18 step:85255[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:18 step:85260[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:18 step:85265[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:18 step:85270[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:18 step:85275[D loss: 0.999962] [G loss: 1.000036]\n",
      "epoch:18 step:85280[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:18 step:85285[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:18 step:85290[D loss: 0.999989] [G loss: 1.000002]\n",
      "epoch:18 step:85295[D loss: 0.999988] [G loss: 1.000010]\n",
      "epoch:18 step:85300[D loss: 1.000012] [G loss: 1.000017]\n",
      "epoch:18 step:85305[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:18 step:85310[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:18 step:85315[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:18 step:85320[D loss: 1.000037] [G loss: 1.000043]\n",
      "epoch:18 step:85325[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:18 step:85330[D loss: 0.999948] [G loss: 1.000196]\n",
      "epoch:18 step:85335[D loss: 0.999949] [G loss: 1.000090]\n",
      "epoch:18 step:85340[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:18 step:85345[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:18 step:85350[D loss: 1.000010] [G loss: 0.999994]\n",
      "epoch:18 step:85355[D loss: 0.999978] [G loss: 1.000015]\n",
      "epoch:18 step:85360[D loss: 1.000047] [G loss: 0.999995]\n",
      "epoch:18 step:85365[D loss: 0.999983] [G loss: 1.000108]\n",
      "epoch:18 step:85370[D loss: 0.999956] [G loss: 1.000022]\n",
      "epoch:18 step:85375[D loss: 1.000041] [G loss: 0.999976]\n",
      "epoch:18 step:85380[D loss: 0.999978] [G loss: 1.000097]\n",
      "epoch:18 step:85385[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:18 step:85390[D loss: 1.000005] [G loss: 0.999995]\n",
      "epoch:18 step:85395[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:18 step:85400[D loss: 1.000032] [G loss: 1.000056]\n",
      "epoch:18 step:85405[D loss: 0.999964] [G loss: 1.000129]\n",
      "epoch:18 step:85410[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:18 step:85415[D loss: 0.999959] [G loss: 1.000232]\n",
      "epoch:18 step:85420[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:18 step:85425[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:18 step:85430[D loss: 0.999997] [G loss: 1.000089]\n",
      "epoch:18 step:85435[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:18 step:85440[D loss: 1.000013] [G loss: 1.000026]\n",
      "epoch:18 step:85445[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:18 step:85450[D loss: 0.999964] [G loss: 1.000024]\n",
      "epoch:18 step:85455[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:18 step:85460[D loss: 0.999979] [G loss: 1.000189]\n",
      "epoch:18 step:85465[D loss: 1.000083] [G loss: 1.000038]\n",
      "epoch:18 step:85470[D loss: 0.999852] [G loss: 1.000199]\n",
      "epoch:18 step:85475[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:18 step:85480[D loss: 0.999990] [G loss: 1.000097]\n",
      "epoch:18 step:85485[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:18 step:85490[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:18 step:85495[D loss: 1.000024] [G loss: 1.000044]\n",
      "epoch:18 step:85500[D loss: 1.000010] [G loss: 1.000050]\n",
      "epoch:18 step:85505[D loss: 1.000017] [G loss: 1.000029]\n",
      "epoch:18 step:85510[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:18 step:85515[D loss: 1.000013] [G loss: 1.000019]\n",
      "epoch:18 step:85520[D loss: 1.000000] [G loss: 0.999949]\n",
      "epoch:18 step:85525[D loss: 1.000017] [G loss: 0.999989]\n",
      "epoch:18 step:85530[D loss: 1.000014] [G loss: 0.999974]\n",
      "epoch:18 step:85535[D loss: 1.000067] [G loss: 0.999988]\n",
      "epoch:18 step:85540[D loss: 1.000039] [G loss: 1.000004]\n",
      "epoch:18 step:85545[D loss: 0.999950] [G loss: 1.000038]\n",
      "epoch:18 step:85550[D loss: 0.999967] [G loss: 1.000179]\n",
      "epoch:18 step:85555[D loss: 1.000015] [G loss: 1.000044]\n",
      "epoch:18 step:85560[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:18 step:85565[D loss: 0.999980] [G loss: 1.000008]\n",
      "epoch:18 step:85570[D loss: 1.000018] [G loss: 1.000011]\n",
      "epoch:18 step:85575[D loss: 0.999944] [G loss: 1.000088]\n",
      "epoch:18 step:85580[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:18 step:85585[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:18 step:85590[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:18 step:85595[D loss: 0.999971] [G loss: 1.000096]\n",
      "epoch:18 step:85600[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:18 step:85605[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:18 step:85610[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:18 step:85615[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:18 step:85620[D loss: 1.000012] [G loss: 1.000122]\n",
      "epoch:18 step:85625[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:18 step:85630[D loss: 0.999922] [G loss: 1.000194]\n",
      "epoch:18 step:85635[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:18 step:85640[D loss: 0.999992] [G loss: 0.999975]\n",
      "epoch:18 step:85645[D loss: 1.000031] [G loss: 1.000031]\n",
      "epoch:18 step:85650[D loss: 0.999990] [G loss: 0.999989]\n",
      "epoch:18 step:85655[D loss: 0.999948] [G loss: 1.000029]\n",
      "epoch:18 step:85660[D loss: 1.000029] [G loss: 1.000066]\n",
      "epoch:18 step:85665[D loss: 0.999927] [G loss: 1.000119]\n",
      "epoch:18 step:85670[D loss: 0.999969] [G loss: 1.000007]\n",
      "epoch:18 step:85675[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:18 step:85680[D loss: 0.999977] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:85685[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:18 step:85690[D loss: 1.000007] [G loss: 1.000102]\n",
      "epoch:18 step:85695[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:18 step:85700[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:18 step:85705[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:18 step:85710[D loss: 1.000010] [G loss: 0.999974]\n",
      "epoch:18 step:85715[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:18 step:85720[D loss: 1.000023] [G loss: 1.000043]\n",
      "epoch:18 step:85725[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:18 step:85730[D loss: 1.000016] [G loss: 1.000007]\n",
      "epoch:18 step:85735[D loss: 0.999940] [G loss: 1.000102]\n",
      "epoch:18 step:85740[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:18 step:85745[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:18 step:85750[D loss: 1.000002] [G loss: 0.999959]\n",
      "epoch:18 step:85755[D loss: 0.999983] [G loss: 1.000020]\n",
      "epoch:18 step:85760[D loss: 0.999958] [G loss: 1.000048]\n",
      "epoch:18 step:85765[D loss: 0.999965] [G loss: 1.000061]\n",
      "epoch:18 step:85770[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:18 step:85775[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:18 step:85780[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:18 step:85785[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:18 step:85790[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:18 step:85795[D loss: 0.999962] [G loss: 1.000111]\n",
      "epoch:18 step:85800[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:18 step:85805[D loss: 1.000010] [G loss: 1.000018]\n",
      "epoch:18 step:85810[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:18 step:85815[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:18 step:85820[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:18 step:85825[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:18 step:85830[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:18 step:85835[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:18 step:85840[D loss: 1.000019] [G loss: 0.999978]\n",
      "epoch:18 step:85845[D loss: 1.000045] [G loss: 1.000022]\n",
      "epoch:18 step:85850[D loss: 1.000023] [G loss: 0.999961]\n",
      "epoch:18 step:85855[D loss: 1.000007] [G loss: 1.000042]\n",
      "epoch:18 step:85860[D loss: 1.000087] [G loss: 0.999895]\n",
      "epoch:18 step:85865[D loss: 0.999941] [G loss: 1.000061]\n",
      "epoch:18 step:85870[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:18 step:85875[D loss: 0.999995] [G loss: 1.000023]\n",
      "epoch:18 step:85880[D loss: 1.000014] [G loss: 0.999979]\n",
      "epoch:18 step:85885[D loss: 1.000028] [G loss: 1.000024]\n",
      "epoch:18 step:85890[D loss: 0.999971] [G loss: 1.000008]\n",
      "epoch:18 step:85895[D loss: 0.999944] [G loss: 1.000072]\n",
      "epoch:18 step:85900[D loss: 0.999934] [G loss: 1.000149]\n",
      "epoch:18 step:85905[D loss: 0.999882] [G loss: 1.000209]\n",
      "epoch:18 step:85910[D loss: 0.999995] [G loss: 1.000164]\n",
      "epoch:18 step:85915[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:18 step:85920[D loss: 0.999992] [G loss: 0.999987]\n",
      "epoch:18 step:85925[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:18 step:85930[D loss: 1.000030] [G loss: 0.999944]\n",
      "epoch:18 step:85935[D loss: 1.000118] [G loss: 0.999887]\n",
      "epoch:18 step:85940[D loss: 0.999982] [G loss: 1.000096]\n",
      "epoch:18 step:85945[D loss: 0.999946] [G loss: 1.000168]\n",
      "epoch:18 step:85950[D loss: 0.999927] [G loss: 1.000032]\n",
      "epoch:18 step:85955[D loss: 0.999973] [G loss: 1.000025]\n",
      "epoch:18 step:85960[D loss: 1.000016] [G loss: 1.000025]\n",
      "epoch:18 step:85965[D loss: 0.999997] [G loss: 1.000093]\n",
      "epoch:18 step:85970[D loss: 0.999985] [G loss: 0.999933]\n",
      "epoch:18 step:85975[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:18 step:85980[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:18 step:85985[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:18 step:85990[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:18 step:85995[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:18 step:86000[D loss: 0.999993] [G loss: 1.000025]\n",
      "epoch:18 step:86005[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:18 step:86010[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:18 step:86015[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:18 step:86020[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:18 step:86025[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:18 step:86030[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:18 step:86035[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:18 step:86040[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:18 step:86045[D loss: 0.999971] [G loss: 1.000069]\n",
      "epoch:18 step:86050[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:18 step:86055[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:18 step:86060[D loss: 1.000019] [G loss: 1.000080]\n",
      "epoch:18 step:86065[D loss: 0.999950] [G loss: 1.000088]\n",
      "epoch:18 step:86070[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:18 step:86075[D loss: 1.000030] [G loss: 1.000053]\n",
      "epoch:18 step:86080[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:18 step:86085[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:18 step:86090[D loss: 1.000004] [G loss: 1.000041]\n",
      "epoch:18 step:86095[D loss: 0.999942] [G loss: 1.000114]\n",
      "epoch:18 step:86100[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:18 step:86105[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:18 step:86110[D loss: 1.000001] [G loss: 1.000011]\n",
      "epoch:18 step:86115[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:18 step:86120[D loss: 1.000123] [G loss: 0.999885]\n",
      "epoch:18 step:86125[D loss: 0.999939] [G loss: 1.000075]\n",
      "epoch:18 step:86130[D loss: 1.000001] [G loss: 1.000109]\n",
      "epoch:18 step:86135[D loss: 0.999903] [G loss: 1.000179]\n",
      "epoch:18 step:86140[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:18 step:86145[D loss: 0.999983] [G loss: 1.000011]\n",
      "epoch:18 step:86150[D loss: 1.000100] [G loss: 0.999906]\n",
      "epoch:18 step:86155[D loss: 1.000062] [G loss: 0.999897]\n",
      "epoch:18 step:86160[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:18 step:86165[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:18 step:86170[D loss: 0.999980] [G loss: 1.000099]\n",
      "epoch:18 step:86175[D loss: 1.000019] [G loss: 1.000091]\n",
      "epoch:18 step:86180[D loss: 0.999955] [G loss: 1.000135]\n",
      "epoch:18 step:86185[D loss: 0.999943] [G loss: 1.000146]\n",
      "epoch:18 step:86190[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:18 step:86195[D loss: 0.999994] [G loss: 1.000009]\n",
      "epoch:18 step:86200[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:18 step:86205[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:18 step:86210[D loss: 1.000027] [G loss: 1.000030]\n",
      "epoch:18 step:86215[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:18 step:86220[D loss: 1.000073] [G loss: 0.999964]\n",
      "epoch:18 step:86225[D loss: 1.000022] [G loss: 1.000012]\n",
      "epoch:18 step:86230[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:18 step:86235[D loss: 0.999945] [G loss: 1.000090]\n",
      "epoch:18 step:86240[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:18 step:86245[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:18 step:86250[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:18 step:86255[D loss: 1.000045] [G loss: 0.999940]\n",
      "epoch:18 step:86260[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:18 step:86265[D loss: 1.000044] [G loss: 1.000000]\n",
      "epoch:18 step:86270[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:18 step:86275[D loss: 0.999947] [G loss: 1.000098]\n",
      "epoch:18 step:86280[D loss: 1.000007] [G loss: 1.000095]\n",
      "epoch:18 step:86285[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:18 step:86290[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:18 step:86295[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:18 step:86300[D loss: 0.999985] [G loss: 1.000067]\n",
      "epoch:18 step:86305[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:18 step:86310[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:18 step:86315[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:18 step:86320[D loss: 1.000011] [G loss: 0.999939]\n",
      "epoch:18 step:86325[D loss: 0.999988] [G loss: 0.999999]\n",
      "epoch:18 step:86330[D loss: 0.999997] [G loss: 0.999978]\n",
      "epoch:18 step:86335[D loss: 1.000062] [G loss: 0.999957]\n",
      "epoch:18 step:86340[D loss: 1.000012] [G loss: 0.999986]\n",
      "epoch:18 step:86345[D loss: 1.000018] [G loss: 1.000051]\n",
      "epoch:18 step:86350[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:18 step:86355[D loss: 0.999939] [G loss: 1.000056]\n",
      "epoch:18 step:86360[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:18 step:86365[D loss: 1.000093] [G loss: 0.999820]\n",
      "epoch:18 step:86370[D loss: 0.999928] [G loss: 1.000079]\n",
      "epoch:18 step:86375[D loss: 0.999978] [G loss: 1.000013]\n",
      "epoch:18 step:86380[D loss: 1.000047] [G loss: 1.000071]\n",
      "epoch:18 step:86385[D loss: 0.999990] [G loss: 0.999994]\n",
      "epoch:18 step:86390[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:18 step:86395[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:18 step:86400[D loss: 1.000001] [G loss: 0.999995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:86405[D loss: 0.999960] [G loss: 1.000047]\n",
      "epoch:18 step:86410[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:18 step:86415[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:18 step:86420[D loss: 0.999962] [G loss: 1.000049]\n",
      "epoch:18 step:86425[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:18 step:86430[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:18 step:86435[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:18 step:86440[D loss: 1.000019] [G loss: 1.000035]\n",
      "epoch:18 step:86445[D loss: 0.999997] [G loss: 0.999991]\n",
      "epoch:18 step:86450[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:18 step:86455[D loss: 0.999953] [G loss: 1.000071]\n",
      "epoch:18 step:86460[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:18 step:86465[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:18 step:86470[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:18 step:86475[D loss: 0.999980] [G loss: 1.000024]\n",
      "epoch:18 step:86480[D loss: 0.999976] [G loss: 1.000014]\n",
      "epoch:18 step:86485[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:18 step:86490[D loss: 1.000028] [G loss: 1.000056]\n",
      "epoch:18 step:86495[D loss: 0.999976] [G loss: 1.000041]\n",
      "epoch:18 step:86500[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:18 step:86505[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:18 step:86510[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:18 step:86515[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:18 step:86520[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:18 step:86525[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:18 step:86530[D loss: 0.999963] [G loss: 1.000042]\n",
      "epoch:18 step:86535[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:18 step:86540[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:18 step:86545[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:18 step:86550[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:18 step:86555[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:18 step:86560[D loss: 1.000000] [G loss: 1.000058]\n",
      "epoch:18 step:86565[D loss: 1.000005] [G loss: 1.000095]\n",
      "epoch:18 step:86570[D loss: 0.999961] [G loss: 1.000138]\n",
      "epoch:18 step:86575[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:18 step:86580[D loss: 1.000014] [G loss: 0.999995]\n",
      "epoch:18 step:86585[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:18 step:86590[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:18 step:86595[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:18 step:86600[D loss: 1.000019] [G loss: 0.999960]\n",
      "epoch:18 step:86605[D loss: 1.000012] [G loss: 1.000015]\n",
      "epoch:18 step:86610[D loss: 0.999988] [G loss: 0.999989]\n",
      "epoch:18 step:86615[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:18 step:86620[D loss: 0.999956] [G loss: 1.000179]\n",
      "epoch:18 step:86625[D loss: 1.000168] [G loss: 0.999941]\n",
      "epoch:18 step:86630[D loss: 0.999908] [G loss: 1.000156]\n",
      "epoch:18 step:86635[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:18 step:86640[D loss: 0.999930] [G loss: 1.000086]\n",
      "epoch:18 step:86645[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:18 step:86650[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:18 step:86655[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:18 step:86660[D loss: 1.000017] [G loss: 0.999951]\n",
      "epoch:18 step:86665[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:18 step:86670[D loss: 1.000056] [G loss: 0.999973]\n",
      "epoch:18 step:86675[D loss: 1.000024] [G loss: 1.000048]\n",
      "epoch:18 step:86680[D loss: 0.999930] [G loss: 1.000099]\n",
      "epoch:18 step:86685[D loss: 0.999939] [G loss: 1.000177]\n",
      "epoch:18 step:86690[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:18 step:86695[D loss: 0.999973] [G loss: 1.000107]\n",
      "epoch:18 step:86700[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:18 step:86705[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:18 step:86710[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:18 step:86715[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:18 step:86720[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:18 step:86725[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:18 step:86730[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:18 step:86735[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:18 step:86740[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:18 step:86745[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:18 step:86750[D loss: 0.999969] [G loss: 1.000040]\n",
      "epoch:18 step:86755[D loss: 1.000010] [G loss: 1.000033]\n",
      "epoch:18 step:86760[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:18 step:86765[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:18 step:86770[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:18 step:86775[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:18 step:86780[D loss: 1.000024] [G loss: 0.999985]\n",
      "epoch:18 step:86785[D loss: 0.999952] [G loss: 1.000083]\n",
      "epoch:18 step:86790[D loss: 1.000001] [G loss: 1.000101]\n",
      "epoch:18 step:86795[D loss: 0.999975] [G loss: 1.000210]\n",
      "epoch:18 step:86800[D loss: 0.999937] [G loss: 1.000169]\n",
      "epoch:18 step:86805[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:18 step:86810[D loss: 1.000071] [G loss: 1.000053]\n",
      "epoch:18 step:86815[D loss: 1.000037] [G loss: 1.000021]\n",
      "epoch:18 step:86820[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:18 step:86825[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:18 step:86830[D loss: 1.000033] [G loss: 1.000004]\n",
      "epoch:18 step:86835[D loss: 0.999983] [G loss: 0.999976]\n",
      "epoch:18 step:86840[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:18 step:86845[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:18 step:86850[D loss: 1.000016] [G loss: 1.000029]\n",
      "epoch:18 step:86855[D loss: 0.999935] [G loss: 1.000128]\n",
      "epoch:18 step:86860[D loss: 0.999951] [G loss: 1.000094]\n",
      "epoch:18 step:86865[D loss: 0.999975] [G loss: 1.000155]\n",
      "epoch:18 step:86870[D loss: 0.999974] [G loss: 1.000115]\n",
      "epoch:18 step:86875[D loss: 0.999948] [G loss: 1.000149]\n",
      "epoch:18 step:86880[D loss: 1.000123] [G loss: 0.999976]\n",
      "epoch:18 step:86885[D loss: 0.999946] [G loss: 1.000143]\n",
      "epoch:18 step:86890[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:18 step:86895[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:18 step:86900[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:18 step:86905[D loss: 0.999937] [G loss: 1.000050]\n",
      "epoch:18 step:86910[D loss: 0.999937] [G loss: 1.000105]\n",
      "epoch:18 step:86915[D loss: 1.000005] [G loss: 1.000159]\n",
      "epoch:18 step:86920[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:18 step:86925[D loss: 0.999984] [G loss: 1.000131]\n",
      "epoch:18 step:86930[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:18 step:86935[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:18 step:86940[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:18 step:86945[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:18 step:86950[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:18 step:86955[D loss: 0.999992] [G loss: 0.999998]\n",
      "epoch:18 step:86960[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:18 step:86965[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:18 step:86970[D loss: 0.999961] [G loss: 1.000109]\n",
      "epoch:18 step:86975[D loss: 0.999948] [G loss: 1.000116]\n",
      "epoch:18 step:86980[D loss: 1.000000] [G loss: 1.000063]\n",
      "epoch:18 step:86985[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:18 step:86990[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:18 step:86995[D loss: 0.999948] [G loss: 1.000092]\n",
      "epoch:18 step:87000[D loss: 1.000054] [G loss: 0.999978]\n",
      "epoch:18 step:87005[D loss: 0.999978] [G loss: 1.000117]\n",
      "epoch:18 step:87010[D loss: 0.999986] [G loss: 1.000158]\n",
      "epoch:18 step:87015[D loss: 1.000050] [G loss: 0.999962]\n",
      "epoch:18 step:87020[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:18 step:87025[D loss: 0.999989] [G loss: 1.000074]\n",
      "epoch:18 step:87030[D loss: 0.999945] [G loss: 1.000098]\n",
      "epoch:18 step:87035[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:18 step:87040[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:18 step:87045[D loss: 1.000010] [G loss: 1.000116]\n",
      "epoch:18 step:87050[D loss: 0.999990] [G loss: 1.000091]\n",
      "epoch:18 step:87055[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:18 step:87060[D loss: 1.000011] [G loss: 1.000083]\n",
      "epoch:18 step:87065[D loss: 0.999946] [G loss: 1.000049]\n",
      "epoch:18 step:87070[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:18 step:87075[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:18 step:87080[D loss: 0.999968] [G loss: 1.000101]\n",
      "epoch:18 step:87085[D loss: 1.000013] [G loss: 1.000034]\n",
      "epoch:18 step:87090[D loss: 1.000000] [G loss: 1.000021]\n",
      "epoch:18 step:87095[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:18 step:87100[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:18 step:87105[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:18 step:87110[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:18 step:87115[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:18 step:87120[D loss: 0.999975] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:87125[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:18 step:87130[D loss: 1.000003] [G loss: 1.000022]\n",
      "epoch:18 step:87135[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:18 step:87140[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:18 step:87145[D loss: 1.000007] [G loss: 1.000065]\n",
      "epoch:18 step:87150[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:18 step:87155[D loss: 0.999984] [G loss: 1.000095]\n",
      "epoch:18 step:87160[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:18 step:87165[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:18 step:87170[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:18 step:87175[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:18 step:87180[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:18 step:87185[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:18 step:87190[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:18 step:87195[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:18 step:87200[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:18 step:87205[D loss: 1.000018] [G loss: 1.000042]\n",
      "epoch:18 step:87210[D loss: 0.999994] [G loss: 1.000087]\n",
      "epoch:18 step:87215[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:18 step:87220[D loss: 0.999964] [G loss: 1.000076]\n",
      "epoch:18 step:87225[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:18 step:87230[D loss: 0.999950] [G loss: 1.000093]\n",
      "epoch:18 step:87235[D loss: 1.000024] [G loss: 1.000018]\n",
      "epoch:18 step:87240[D loss: 0.999966] [G loss: 1.000108]\n",
      "epoch:18 step:87245[D loss: 1.000013] [G loss: 0.999969]\n",
      "epoch:18 step:87250[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:18 step:87255[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:18 step:87260[D loss: 0.999954] [G loss: 1.000096]\n",
      "epoch:18 step:87265[D loss: 0.999984] [G loss: 1.000038]\n",
      "epoch:18 step:87270[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:18 step:87275[D loss: 1.000039] [G loss: 1.000028]\n",
      "epoch:18 step:87280[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:18 step:87285[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:18 step:87290[D loss: 1.000013] [G loss: 1.000065]\n",
      "epoch:18 step:87295[D loss: 1.000116] [G loss: 0.999941]\n",
      "epoch:18 step:87300[D loss: 0.999970] [G loss: 1.000105]\n",
      "epoch:18 step:87305[D loss: 1.000093] [G loss: 1.000051]\n",
      "epoch:18 step:87310[D loss: 0.999861] [G loss: 1.000186]\n",
      "epoch:18 step:87315[D loss: 0.999909] [G loss: 1.000098]\n",
      "epoch:18 step:87320[D loss: 0.999900] [G loss: 1.000153]\n",
      "epoch:18 step:87325[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:18 step:87330[D loss: 0.999980] [G loss: 1.000089]\n",
      "epoch:18 step:87335[D loss: 1.000023] [G loss: 0.999985]\n",
      "epoch:18 step:87340[D loss: 1.000016] [G loss: 0.999938]\n",
      "epoch:18 step:87345[D loss: 0.999985] [G loss: 1.000005]\n",
      "epoch:18 step:87350[D loss: 0.999997] [G loss: 0.999996]\n",
      "epoch:18 step:87355[D loss: 0.999967] [G loss: 1.000041]\n",
      "epoch:18 step:87360[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:18 step:87365[D loss: 1.000010] [G loss: 1.000013]\n",
      "epoch:18 step:87370[D loss: 1.000006] [G loss: 1.000046]\n",
      "epoch:18 step:87375[D loss: 1.000065] [G loss: 1.000034]\n",
      "epoch:18 step:87380[D loss: 0.999915] [G loss: 1.000109]\n",
      "epoch:18 step:87385[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:18 step:87390[D loss: 1.000004] [G loss: 1.000065]\n",
      "epoch:18 step:87395[D loss: 1.000002] [G loss: 1.000001]\n",
      "epoch:18 step:87400[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:18 step:87405[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:18 step:87410[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:18 step:87415[D loss: 1.000022] [G loss: 1.000038]\n",
      "epoch:18 step:87420[D loss: 1.000063] [G loss: 0.999973]\n",
      "epoch:18 step:87425[D loss: 0.999932] [G loss: 1.000066]\n",
      "epoch:18 step:87430[D loss: 1.000029] [G loss: 0.999993]\n",
      "epoch:18 step:87435[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:18 step:87440[D loss: 1.000007] [G loss: 1.000087]\n",
      "epoch:18 step:87445[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:18 step:87450[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:18 step:87455[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:18 step:87460[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:18 step:87465[D loss: 1.000036] [G loss: 0.999966]\n",
      "epoch:18 step:87470[D loss: 1.000001] [G loss: 1.000005]\n",
      "epoch:18 step:87475[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:18 step:87480[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:18 step:87485[D loss: 0.999973] [G loss: 1.000023]\n",
      "epoch:18 step:87490[D loss: 0.999940] [G loss: 1.000169]\n",
      "epoch:18 step:87495[D loss: 0.999939] [G loss: 1.000164]\n",
      "epoch:18 step:87500[D loss: 0.999988] [G loss: 1.000010]\n",
      "epoch:18 step:87505[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:18 step:87510[D loss: 0.999995] [G loss: 1.000012]\n",
      "epoch:18 step:87515[D loss: 1.000074] [G loss: 1.000000]\n",
      "epoch:18 step:87520[D loss: 0.999961] [G loss: 0.999967]\n",
      "epoch:18 step:87525[D loss: 0.999966] [G loss: 1.000018]\n",
      "epoch:18 step:87530[D loss: 1.000010] [G loss: 1.000022]\n",
      "epoch:18 step:87535[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:18 step:87540[D loss: 0.999988] [G loss: 1.000004]\n",
      "epoch:18 step:87545[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:18 step:87550[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:18 step:87555[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:18 step:87560[D loss: 1.000054] [G loss: 0.999932]\n",
      "epoch:18 step:87565[D loss: 0.999930] [G loss: 1.000069]\n",
      "epoch:18 step:87570[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:18 step:87575[D loss: 0.999994] [G loss: 1.000112]\n",
      "epoch:18 step:87580[D loss: 1.000004] [G loss: 1.000051]\n",
      "epoch:18 step:87585[D loss: 0.999999] [G loss: 1.000093]\n",
      "epoch:18 step:87590[D loss: 0.999944] [G loss: 1.000099]\n",
      "epoch:18 step:87595[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:18 step:87600[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:18 step:87605[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:18 step:87610[D loss: 0.999992] [G loss: 1.000011]\n",
      "epoch:18 step:87615[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:18 step:87620[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:18 step:87625[D loss: 0.999985] [G loss: 1.000066]\n",
      "epoch:18 step:87630[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:18 step:87635[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:18 step:87640[D loss: 1.000010] [G loss: 1.000058]\n",
      "epoch:18 step:87645[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:18 step:87650[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:18 step:87655[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:18 step:87660[D loss: 1.000014] [G loss: 1.000010]\n",
      "epoch:18 step:87665[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:18 step:87670[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:18 step:87675[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:18 step:87680[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:18 step:87685[D loss: 0.999976] [G loss: 1.000088]\n",
      "epoch:18 step:87690[D loss: 1.000019] [G loss: 1.000006]\n",
      "epoch:18 step:87695[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:18 step:87700[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:18 step:87705[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:18 step:87710[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:18 step:87715[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:18 step:87720[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:18 step:87725[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:18 step:87730[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:18 step:87735[D loss: 0.999953] [G loss: 1.000060]\n",
      "epoch:18 step:87740[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:18 step:87745[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:18 step:87750[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:18 step:87755[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:18 step:87760[D loss: 0.999949] [G loss: 1.000103]\n",
      "epoch:18 step:87765[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:18 step:87770[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:18 step:87775[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:18 step:87780[D loss: 0.999933] [G loss: 1.000098]\n",
      "epoch:18 step:87785[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:18 step:87790[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:18 step:87795[D loss: 1.000043] [G loss: 1.000021]\n",
      "epoch:18 step:87800[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:18 step:87805[D loss: 0.999987] [G loss: 1.000102]\n",
      "epoch:18 step:87810[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:18 step:87815[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:18 step:87820[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:18 step:87825[D loss: 0.999953] [G loss: 1.000113]\n",
      "epoch:18 step:87830[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:18 step:87835[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:18 step:87840[D loss: 0.999977] [G loss: 1.000055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:87845[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:18 step:87850[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:18 step:87855[D loss: 1.000016] [G loss: 1.000012]\n",
      "epoch:18 step:87860[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:18 step:87865[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:18 step:87870[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:18 step:87875[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:18 step:87880[D loss: 1.000067] [G loss: 0.999969]\n",
      "epoch:18 step:87885[D loss: 1.000041] [G loss: 0.999950]\n",
      "epoch:18 step:87890[D loss: 1.000016] [G loss: 1.000029]\n",
      "epoch:18 step:87895[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:18 step:87900[D loss: 1.000048] [G loss: 1.000105]\n",
      "epoch:18 step:87905[D loss: 0.999944] [G loss: 1.000135]\n",
      "epoch:18 step:87910[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:18 step:87915[D loss: 0.999983] [G loss: 1.000007]\n",
      "epoch:18 step:87920[D loss: 0.999999] [G loss: 1.000020]\n",
      "epoch:18 step:87925[D loss: 1.000006] [G loss: 1.000026]\n",
      "epoch:18 step:87930[D loss: 0.999962] [G loss: 1.000026]\n",
      "epoch:18 step:87935[D loss: 0.999959] [G loss: 1.000128]\n",
      "epoch:18 step:87940[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:18 step:87945[D loss: 0.999996] [G loss: 1.000150]\n",
      "epoch:18 step:87950[D loss: 0.999965] [G loss: 1.000121]\n",
      "epoch:18 step:87955[D loss: 0.999960] [G loss: 1.000116]\n",
      "epoch:18 step:87960[D loss: 0.999993] [G loss: 1.000010]\n",
      "epoch:18 step:87965[D loss: 0.999954] [G loss: 1.000067]\n",
      "epoch:18 step:87970[D loss: 1.000047] [G loss: 0.999996]\n",
      "epoch:18 step:87975[D loss: 0.999933] [G loss: 1.000034]\n",
      "epoch:18 step:87980[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:18 step:87985[D loss: 1.000010] [G loss: 1.000015]\n",
      "epoch:18 step:87990[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:18 step:87995[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:18 step:88000[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:18 step:88005[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:18 step:88010[D loss: 1.000008] [G loss: 1.000039]\n",
      "epoch:18 step:88015[D loss: 1.000022] [G loss: 1.000055]\n",
      "epoch:18 step:88020[D loss: 0.999969] [G loss: 1.000122]\n",
      "epoch:18 step:88025[D loss: 0.999997] [G loss: 1.000078]\n",
      "epoch:18 step:88030[D loss: 0.999977] [G loss: 1.000123]\n",
      "epoch:18 step:88035[D loss: 0.999925] [G loss: 1.000102]\n",
      "epoch:18 step:88040[D loss: 1.000007] [G loss: 1.000047]\n",
      "epoch:18 step:88045[D loss: 0.999990] [G loss: 1.000086]\n",
      "epoch:18 step:88050[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:18 step:88055[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:18 step:88060[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:18 step:88065[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:18 step:88070[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:18 step:88075[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:18 step:88080[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:18 step:88085[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:18 step:88090[D loss: 0.999996] [G loss: 0.999990]\n",
      "epoch:18 step:88095[D loss: 1.000021] [G loss: 0.999997]\n",
      "epoch:18 step:88100[D loss: 1.000019] [G loss: 1.000074]\n",
      "epoch:18 step:88105[D loss: 0.999924] [G loss: 1.000138]\n",
      "epoch:18 step:88110[D loss: 0.999934] [G loss: 1.000056]\n",
      "epoch:18 step:88115[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:18 step:88120[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:18 step:88125[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:18 step:88130[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:18 step:88135[D loss: 1.000022] [G loss: 0.999954]\n",
      "epoch:18 step:88140[D loss: 0.999998] [G loss: 1.000106]\n",
      "epoch:18 step:88145[D loss: 0.999944] [G loss: 1.000085]\n",
      "epoch:18 step:88150[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:18 step:88155[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:18 step:88160[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:18 step:88165[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:18 step:88170[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:18 step:88175[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:18 step:88180[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:18 step:88185[D loss: 1.000004] [G loss: 0.999999]\n",
      "epoch:18 step:88190[D loss: 1.000048] [G loss: 0.999951]\n",
      "epoch:18 step:88195[D loss: 0.999899] [G loss: 1.000178]\n",
      "epoch:18 step:88200[D loss: 0.999965] [G loss: 1.000166]\n",
      "epoch:18 step:88205[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:18 step:88210[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:18 step:88215[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:18 step:88220[D loss: 0.999992] [G loss: 1.000017]\n",
      "epoch:18 step:88225[D loss: 1.000013] [G loss: 1.000015]\n",
      "epoch:18 step:88230[D loss: 1.000010] [G loss: 0.999950]\n",
      "epoch:18 step:88235[D loss: 0.999968] [G loss: 1.000006]\n",
      "epoch:18 step:88240[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:18 step:88245[D loss: 0.999954] [G loss: 1.000051]\n",
      "epoch:18 step:88250[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:18 step:88255[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:18 step:88260[D loss: 0.999993] [G loss: 1.000028]\n",
      "epoch:18 step:88265[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:18 step:88270[D loss: 1.000014] [G loss: 1.000005]\n",
      "epoch:18 step:88275[D loss: 0.999935] [G loss: 1.000177]\n",
      "epoch:18 step:88280[D loss: 0.999936] [G loss: 1.000077]\n",
      "epoch:18 step:88285[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:18 step:88290[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:18 step:88295[D loss: 0.999996] [G loss: 1.000013]\n",
      "epoch:18 step:88300[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:18 step:88305[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:18 step:88310[D loss: 1.000023] [G loss: 0.999955]\n",
      "epoch:18 step:88315[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:18 step:88320[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:18 step:88325[D loss: 0.999943] [G loss: 1.000099]\n",
      "epoch:18 step:88330[D loss: 0.999949] [G loss: 1.000068]\n",
      "epoch:18 step:88335[D loss: 1.000002] [G loss: 1.000002]\n",
      "epoch:18 step:88340[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:18 step:88345[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:18 step:88350[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:18 step:88355[D loss: 1.000067] [G loss: 0.999950]\n",
      "epoch:18 step:88360[D loss: 0.999936] [G loss: 1.000118]\n",
      "epoch:18 step:88365[D loss: 1.000014] [G loss: 1.000114]\n",
      "epoch:18 step:88370[D loss: 1.000044] [G loss: 1.000073]\n",
      "epoch:18 step:88375[D loss: 0.999952] [G loss: 1.000086]\n",
      "epoch:18 step:88380[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:18 step:88385[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:18 step:88390[D loss: 0.999960] [G loss: 1.000115]\n",
      "epoch:18 step:88395[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:18 step:88400[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:18 step:88405[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:18 step:88410[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:18 step:88415[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:18 step:88420[D loss: 1.000037] [G loss: 0.999982]\n",
      "epoch:18 step:88425[D loss: 0.999954] [G loss: 1.000053]\n",
      "epoch:18 step:88430[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:18 step:88435[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:18 step:88440[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:18 step:88445[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:18 step:88450[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:18 step:88455[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:18 step:88460[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:18 step:88465[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:18 step:88470[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:18 step:88475[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:18 step:88480[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:18 step:88485[D loss: 0.999955] [G loss: 1.000093]\n",
      "epoch:18 step:88490[D loss: 1.000073] [G loss: 1.000002]\n",
      "epoch:18 step:88495[D loss: 1.000014] [G loss: 0.999967]\n",
      "epoch:18 step:88500[D loss: 1.000035] [G loss: 1.000054]\n",
      "epoch:18 step:88505[D loss: 0.999968] [G loss: 1.000036]\n",
      "epoch:18 step:88510[D loss: 0.999990] [G loss: 1.000031]\n",
      "epoch:18 step:88515[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:18 step:88520[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:18 step:88525[D loss: 0.999999] [G loss: 1.000013]\n",
      "epoch:18 step:88530[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:18 step:88535[D loss: 1.000026] [G loss: 1.000057]\n",
      "epoch:18 step:88540[D loss: 0.999972] [G loss: 1.000095]\n",
      "epoch:18 step:88545[D loss: 0.999963] [G loss: 1.000121]\n",
      "epoch:18 step:88550[D loss: 1.000044] [G loss: 1.000098]\n",
      "epoch:18 step:88555[D loss: 0.999946] [G loss: 1.000111]\n",
      "epoch:18 step:88560[D loss: 1.000010] [G loss: 0.999982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:88565[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:18 step:88570[D loss: 0.999975] [G loss: 1.000012]\n",
      "epoch:18 step:88575[D loss: 1.000002] [G loss: 1.000050]\n",
      "epoch:18 step:88580[D loss: 0.999949] [G loss: 1.000075]\n",
      "epoch:18 step:88585[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:18 step:88590[D loss: 0.999996] [G loss: 0.999995]\n",
      "epoch:18 step:88595[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:18 step:88600[D loss: 0.999987] [G loss: 1.000006]\n",
      "epoch:18 step:88605[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:18 step:88610[D loss: 1.000011] [G loss: 1.000059]\n",
      "epoch:18 step:88615[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:18 step:88620[D loss: 0.999999] [G loss: 1.000069]\n",
      "epoch:18 step:88625[D loss: 1.000033] [G loss: 1.000049]\n",
      "epoch:18 step:88630[D loss: 0.999927] [G loss: 1.000111]\n",
      "epoch:18 step:88635[D loss: 0.999953] [G loss: 1.000078]\n",
      "epoch:18 step:88640[D loss: 0.999985] [G loss: 1.000064]\n",
      "epoch:18 step:88645[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:18 step:88650[D loss: 1.000016] [G loss: 0.999988]\n",
      "epoch:18 step:88655[D loss: 0.999990] [G loss: 1.000050]\n",
      "epoch:18 step:88660[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:18 step:88665[D loss: 1.000047] [G loss: 1.000001]\n",
      "epoch:18 step:88670[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:18 step:88675[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:18 step:88680[D loss: 1.000029] [G loss: 1.000127]\n",
      "epoch:18 step:88685[D loss: 0.999940] [G loss: 1.000068]\n",
      "epoch:18 step:88690[D loss: 0.999994] [G loss: 1.000003]\n",
      "epoch:18 step:88695[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:18 step:88700[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:18 step:88705[D loss: 0.999984] [G loss: 1.000040]\n",
      "epoch:18 step:88710[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:18 step:88715[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:18 step:88720[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:18 step:88725[D loss: 0.999955] [G loss: 1.000063]\n",
      "epoch:18 step:88730[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:18 step:88735[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:18 step:88740[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:18 step:88745[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:18 step:88750[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:18 step:88755[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:18 step:88760[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:18 step:88765[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:18 step:88770[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:18 step:88775[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:18 step:88780[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:18 step:88785[D loss: 1.000018] [G loss: 0.999984]\n",
      "epoch:18 step:88790[D loss: 0.999942] [G loss: 1.000045]\n",
      "epoch:18 step:88795[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:18 step:88800[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:18 step:88805[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:18 step:88810[D loss: 1.000030] [G loss: 1.000042]\n",
      "epoch:18 step:88815[D loss: 1.000003] [G loss: 0.999990]\n",
      "epoch:18 step:88820[D loss: 0.999970] [G loss: 1.000026]\n",
      "epoch:18 step:88825[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:18 step:88830[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:18 step:88835[D loss: 1.000093] [G loss: 0.999891]\n",
      "epoch:18 step:88840[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:18 step:88845[D loss: 0.999980] [G loss: 1.000014]\n",
      "epoch:18 step:88850[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:18 step:88855[D loss: 1.000042] [G loss: 0.999910]\n",
      "epoch:18 step:88860[D loss: 0.999991] [G loss: 1.000068]\n",
      "epoch:18 step:88865[D loss: 0.999895] [G loss: 1.000106]\n",
      "epoch:18 step:88870[D loss: 0.999996] [G loss: 0.999985]\n",
      "epoch:18 step:88875[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:18 step:88880[D loss: 0.999989] [G loss: 0.999996]\n",
      "epoch:18 step:88885[D loss: 0.999959] [G loss: 1.000047]\n",
      "epoch:18 step:88890[D loss: 0.999953] [G loss: 1.000061]\n",
      "epoch:18 step:88895[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:18 step:88900[D loss: 1.000033] [G loss: 0.999995]\n",
      "epoch:18 step:88905[D loss: 1.000019] [G loss: 0.999997]\n",
      "epoch:18 step:88910[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:18 step:88915[D loss: 1.000087] [G loss: 0.999910]\n",
      "epoch:18 step:88920[D loss: 0.999928] [G loss: 1.000092]\n",
      "epoch:18 step:88925[D loss: 0.999977] [G loss: 1.000005]\n",
      "epoch:18 step:88930[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:18 step:88935[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:18 step:88940[D loss: 1.000000] [G loss: 1.000004]\n",
      "epoch:18 step:88945[D loss: 0.999915] [G loss: 1.000107]\n",
      "epoch:18 step:88950[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:18 step:88955[D loss: 0.999953] [G loss: 1.000059]\n",
      "epoch:18 step:88960[D loss: 0.999949] [G loss: 1.000127]\n",
      "epoch:18 step:88965[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:18 step:88970[D loss: 0.999996] [G loss: 1.000015]\n",
      "epoch:18 step:88975[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:18 step:88980[D loss: 0.999976] [G loss: 1.000033]\n",
      "epoch:18 step:88985[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:18 step:88990[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:18 step:88995[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:18 step:89000[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:18 step:89005[D loss: 1.000055] [G loss: 0.999929]\n",
      "epoch:18 step:89010[D loss: 0.999974] [G loss: 1.000000]\n",
      "epoch:18 step:89015[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:19 step:89020[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:19 step:89025[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:19 step:89030[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:19 step:89035[D loss: 0.999984] [G loss: 1.000022]\n",
      "epoch:19 step:89040[D loss: 1.000024] [G loss: 0.999983]\n",
      "epoch:19 step:89045[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:19 step:89050[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:19 step:89055[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:19 step:89060[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:19 step:89065[D loss: 1.000036] [G loss: 1.000015]\n",
      "epoch:19 step:89070[D loss: 1.000028] [G loss: 0.999969]\n",
      "epoch:19 step:89075[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:19 step:89080[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:19 step:89085[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:19 step:89090[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:19 step:89095[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:19 step:89100[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:19 step:89105[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:19 step:89110[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:19 step:89115[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:19 step:89120[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:19 step:89125[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:19 step:89130[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:19 step:89135[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:19 step:89140[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:19 step:89145[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:19 step:89150[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:19 step:89155[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:19 step:89160[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:19 step:89165[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:19 step:89170[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:19 step:89175[D loss: 1.000015] [G loss: 1.000049]\n",
      "epoch:19 step:89180[D loss: 0.999967] [G loss: 1.000121]\n",
      "epoch:19 step:89185[D loss: 1.000002] [G loss: 1.000115]\n",
      "epoch:19 step:89190[D loss: 0.999918] [G loss: 1.000184]\n",
      "epoch:19 step:89195[D loss: 1.000043] [G loss: 1.000064]\n",
      "epoch:19 step:89200[D loss: 0.999915] [G loss: 1.000182]\n",
      "epoch:19 step:89205[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:19 step:89210[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:19 step:89215[D loss: 1.000109] [G loss: 0.999937]\n",
      "epoch:19 step:89220[D loss: 0.999988] [G loss: 0.999953]\n",
      "epoch:19 step:89225[D loss: 1.000046] [G loss: 0.999794]\n",
      "epoch:19 step:89230[D loss: 0.999926] [G loss: 1.000096]\n",
      "epoch:19 step:89235[D loss: 1.000031] [G loss: 0.999914]\n",
      "epoch:19 step:89240[D loss: 1.000031] [G loss: 1.000018]\n",
      "epoch:19 step:89245[D loss: 0.999891] [G loss: 1.000199]\n",
      "epoch:19 step:89250[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:19 step:89255[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:19 step:89260[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:19 step:89265[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:19 step:89270[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:19 step:89275[D loss: 0.999974] [G loss: 1.000104]\n",
      "epoch:19 step:89280[D loss: 0.999998] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:89285[D loss: 1.000030] [G loss: 0.999943]\n",
      "epoch:19 step:89290[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:19 step:89295[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:19 step:89300[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:19 step:89305[D loss: 1.000004] [G loss: 1.000078]\n",
      "epoch:19 step:89310[D loss: 0.999990] [G loss: 1.000091]\n",
      "epoch:19 step:89315[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:19 step:89320[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:19 step:89325[D loss: 1.000043] [G loss: 0.999996]\n",
      "epoch:19 step:89330[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:19 step:89335[D loss: 0.999956] [G loss: 1.000130]\n",
      "epoch:19 step:89340[D loss: 1.000004] [G loss: 0.999945]\n",
      "epoch:19 step:89345[D loss: 0.999985] [G loss: 1.000008]\n",
      "epoch:19 step:89350[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:19 step:89355[D loss: 0.999995] [G loss: 0.999994]\n",
      "epoch:19 step:89360[D loss: 1.000063] [G loss: 0.999985]\n",
      "epoch:19 step:89365[D loss: 1.000071] [G loss: 0.999941]\n",
      "epoch:19 step:89370[D loss: 0.999988] [G loss: 1.000019]\n",
      "epoch:19 step:89375[D loss: 1.000046] [G loss: 1.000033]\n",
      "epoch:19 step:89380[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:19 step:89385[D loss: 0.999937] [G loss: 1.000101]\n",
      "epoch:19 step:89390[D loss: 0.999974] [G loss: 1.000029]\n",
      "epoch:19 step:89395[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:19 step:89400[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:19 step:89405[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:19 step:89410[D loss: 0.999931] [G loss: 1.000147]\n",
      "epoch:19 step:89415[D loss: 0.999949] [G loss: 1.000099]\n",
      "epoch:19 step:89420[D loss: 0.999970] [G loss: 1.000119]\n",
      "epoch:19 step:89425[D loss: 0.999937] [G loss: 1.000079]\n",
      "epoch:19 step:89430[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:19 step:89435[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:19 step:89440[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:19 step:89445[D loss: 0.999992] [G loss: 1.000012]\n",
      "epoch:19 step:89450[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:19 step:89455[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:19 step:89460[D loss: 1.000036] [G loss: 0.999961]\n",
      "epoch:19 step:89465[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:19 step:89470[D loss: 0.999907] [G loss: 1.000101]\n",
      "epoch:19 step:89475[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:19 step:89480[D loss: 1.000022] [G loss: 0.999952]\n",
      "epoch:19 step:89485[D loss: 1.000017] [G loss: 0.999982]\n",
      "epoch:19 step:89490[D loss: 1.000021] [G loss: 1.000056]\n",
      "epoch:19 step:89495[D loss: 0.999911] [G loss: 1.000189]\n",
      "epoch:19 step:89500[D loss: 0.999952] [G loss: 1.000140]\n",
      "epoch:19 step:89505[D loss: 0.999949] [G loss: 1.000156]\n",
      "epoch:19 step:89510[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:19 step:89515[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:19 step:89520[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:19 step:89525[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:19 step:89530[D loss: 1.000041] [G loss: 0.999964]\n",
      "epoch:19 step:89535[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:19 step:89540[D loss: 0.999935] [G loss: 1.000201]\n",
      "epoch:19 step:89545[D loss: 0.999861] [G loss: 1.000216]\n",
      "epoch:19 step:89550[D loss: 0.999923] [G loss: 1.000198]\n",
      "epoch:19 step:89555[D loss: 0.999957] [G loss: 1.000111]\n",
      "epoch:19 step:89560[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:19 step:89565[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:19 step:89570[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:19 step:89575[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:19 step:89580[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:19 step:89585[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:19 step:89590[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:19 step:89595[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:19 step:89600[D loss: 1.000053] [G loss: 0.999998]\n",
      "epoch:19 step:89605[D loss: 1.000060] [G loss: 1.000046]\n",
      "epoch:19 step:89610[D loss: 0.999928] [G loss: 1.000225]\n",
      "epoch:19 step:89615[D loss: 0.999947] [G loss: 1.000138]\n",
      "epoch:19 step:89620[D loss: 0.999963] [G loss: 1.000117]\n",
      "epoch:19 step:89625[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:19 step:89630[D loss: 0.999976] [G loss: 1.000026]\n",
      "epoch:19 step:89635[D loss: 1.000007] [G loss: 0.999986]\n",
      "epoch:19 step:89640[D loss: 1.000049] [G loss: 0.999993]\n",
      "epoch:19 step:89645[D loss: 0.999968] [G loss: 1.000027]\n",
      "epoch:19 step:89650[D loss: 1.000009] [G loss: 1.000041]\n",
      "epoch:19 step:89655[D loss: 1.000018] [G loss: 1.000014]\n",
      "epoch:19 step:89660[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:19 step:89665[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:19 step:89670[D loss: 1.000010] [G loss: 1.000001]\n",
      "epoch:19 step:89675[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:19 step:89680[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:19 step:89685[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:19 step:89690[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:19 step:89695[D loss: 0.999945] [G loss: 1.000135]\n",
      "epoch:19 step:89700[D loss: 1.000022] [G loss: 1.000078]\n",
      "epoch:19 step:89705[D loss: 0.999953] [G loss: 1.000108]\n",
      "epoch:19 step:89710[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:19 step:89715[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:19 step:89720[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:19 step:89725[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:19 step:89730[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:19 step:89735[D loss: 0.999992] [G loss: 1.000071]\n",
      "epoch:19 step:89740[D loss: 0.999988] [G loss: 1.000008]\n",
      "epoch:19 step:89745[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:19 step:89750[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:19 step:89755[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:19 step:89760[D loss: 1.000033] [G loss: 0.999979]\n",
      "epoch:19 step:89765[D loss: 0.999929] [G loss: 1.000122]\n",
      "epoch:19 step:89770[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:19 step:89775[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:19 step:89780[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:19 step:89785[D loss: 0.999955] [G loss: 1.000122]\n",
      "epoch:19 step:89790[D loss: 1.000001] [G loss: 1.000045]\n",
      "epoch:19 step:89795[D loss: 1.000012] [G loss: 1.000059]\n",
      "epoch:19 step:89800[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:19 step:89805[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:19 step:89810[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:19 step:89815[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:19 step:89820[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:19 step:89825[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:19 step:89830[D loss: 0.999934] [G loss: 1.000089]\n",
      "epoch:19 step:89835[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:19 step:89840[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:19 step:89845[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:19 step:89850[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:19 step:89855[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:19 step:89860[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:19 step:89865[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:19 step:89870[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:19 step:89875[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:19 step:89880[D loss: 0.999951] [G loss: 1.000097]\n",
      "epoch:19 step:89885[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:19 step:89890[D loss: 1.000002] [G loss: 1.000000]\n",
      "epoch:19 step:89895[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:19 step:89900[D loss: 0.999954] [G loss: 1.000092]\n",
      "epoch:19 step:89905[D loss: 0.999996] [G loss: 1.000066]\n",
      "epoch:19 step:89910[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:19 step:89915[D loss: 0.999946] [G loss: 1.000091]\n",
      "epoch:19 step:89920[D loss: 0.999967] [G loss: 1.000113]\n",
      "epoch:19 step:89925[D loss: 0.999928] [G loss: 1.000143]\n",
      "epoch:19 step:89930[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:19 step:89935[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:19 step:89940[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:19 step:89945[D loss: 0.999997] [G loss: 1.000080]\n",
      "epoch:19 step:89950[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:19 step:89955[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:19 step:89960[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:19 step:89965[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:19 step:89970[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:19 step:89975[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:19 step:89980[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:19 step:89985[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:19 step:89990[D loss: 1.000064] [G loss: 0.999948]\n",
      "epoch:19 step:89995[D loss: 0.999956] [G loss: 1.000020]\n",
      "epoch:19 step:90000[D loss: 0.999971] [G loss: 1.000135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:90005[D loss: 1.000033] [G loss: 1.000068]\n",
      "epoch:19 step:90010[D loss: 1.000036] [G loss: 1.000036]\n",
      "epoch:19 step:90015[D loss: 0.999998] [G loss: 1.000111]\n",
      "epoch:19 step:90020[D loss: 0.999898] [G loss: 1.000250]\n",
      "epoch:19 step:90025[D loss: 0.999974] [G loss: 1.000143]\n",
      "epoch:19 step:90030[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:19 step:90035[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:19 step:90040[D loss: 0.999985] [G loss: 1.000012]\n",
      "epoch:19 step:90045[D loss: 0.999999] [G loss: 0.999973]\n",
      "epoch:19 step:90050[D loss: 1.000024] [G loss: 0.999992]\n",
      "epoch:19 step:90055[D loss: 0.999912] [G loss: 1.000048]\n",
      "epoch:19 step:90060[D loss: 1.000053] [G loss: 0.999960]\n",
      "epoch:19 step:90065[D loss: 0.999936] [G loss: 1.000102]\n",
      "epoch:19 step:90070[D loss: 0.999950] [G loss: 1.000070]\n",
      "epoch:19 step:90075[D loss: 1.000033] [G loss: 1.000016]\n",
      "epoch:19 step:90080[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:19 step:90085[D loss: 0.999975] [G loss: 1.000109]\n",
      "epoch:19 step:90090[D loss: 0.999927] [G loss: 1.000140]\n",
      "epoch:19 step:90095[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:19 step:90100[D loss: 0.999967] [G loss: 1.000259]\n",
      "epoch:19 step:90105[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:19 step:90110[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:19 step:90115[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:19 step:90120[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:19 step:90125[D loss: 0.999975] [G loss: 1.000097]\n",
      "epoch:19 step:90130[D loss: 1.000014] [G loss: 1.000056]\n",
      "epoch:19 step:90135[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:19 step:90140[D loss: 0.999978] [G loss: 1.000133]\n",
      "epoch:19 step:90145[D loss: 1.000022] [G loss: 1.000122]\n",
      "epoch:19 step:90150[D loss: 1.000085] [G loss: 0.999998]\n",
      "epoch:19 step:90155[D loss: 0.999866] [G loss: 1.000207]\n",
      "epoch:19 step:90160[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:19 step:90165[D loss: 0.999997] [G loss: 1.000058]\n",
      "epoch:19 step:90170[D loss: 0.999997] [G loss: 1.000021]\n",
      "epoch:19 step:90175[D loss: 0.999961] [G loss: 1.000048]\n",
      "epoch:19 step:90180[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:19 step:90185[D loss: 0.999989] [G loss: 1.000097]\n",
      "epoch:19 step:90190[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:19 step:90195[D loss: 0.999972] [G loss: 1.000046]\n",
      "epoch:19 step:90200[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:19 step:90205[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:19 step:90210[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:19 step:90215[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:19 step:90220[D loss: 1.000082] [G loss: 0.999918]\n",
      "epoch:19 step:90225[D loss: 1.000014] [G loss: 0.999951]\n",
      "epoch:19 step:90230[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:19 step:90235[D loss: 1.000049] [G loss: 0.999986]\n",
      "epoch:19 step:90240[D loss: 0.999944] [G loss: 1.000108]\n",
      "epoch:19 step:90245[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:19 step:90250[D loss: 1.000000] [G loss: 1.000002]\n",
      "epoch:19 step:90255[D loss: 0.999951] [G loss: 1.000058]\n",
      "epoch:19 step:90260[D loss: 0.999945] [G loss: 1.000053]\n",
      "epoch:19 step:90265[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:19 step:90270[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:19 step:90275[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:19 step:90280[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:19 step:90285[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:19 step:90290[D loss: 1.000030] [G loss: 1.000023]\n",
      "epoch:19 step:90295[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:19 step:90300[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:19 step:90305[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:19 step:90310[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:19 step:90315[D loss: 1.000009] [G loss: 0.999985]\n",
      "epoch:19 step:90320[D loss: 0.999954] [G loss: 1.000065]\n",
      "epoch:19 step:90325[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:19 step:90330[D loss: 1.000004] [G loss: 1.000073]\n",
      "epoch:19 step:90335[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:19 step:90340[D loss: 0.999944] [G loss: 1.000093]\n",
      "epoch:19 step:90345[D loss: 0.999999] [G loss: 1.000067]\n",
      "epoch:19 step:90350[D loss: 0.999949] [G loss: 1.000085]\n",
      "epoch:19 step:90355[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:19 step:90360[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:19 step:90365[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:19 step:90370[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:19 step:90375[D loss: 0.999999] [G loss: 0.999994]\n",
      "epoch:19 step:90380[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:19 step:90385[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:19 step:90390[D loss: 1.000022] [G loss: 1.000018]\n",
      "epoch:19 step:90395[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:19 step:90400[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:19 step:90405[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:19 step:90410[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:19 step:90415[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:19 step:90420[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:19 step:90425[D loss: 0.999992] [G loss: 1.000054]\n",
      "epoch:19 step:90430[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:19 step:90435[D loss: 1.000006] [G loss: 1.000070]\n",
      "epoch:19 step:90440[D loss: 0.999988] [G loss: 1.000105]\n",
      "epoch:19 step:90445[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:19 step:90450[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:19 step:90455[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:19 step:90460[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:19 step:90465[D loss: 1.000010] [G loss: 1.000020]\n",
      "epoch:19 step:90470[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:19 step:90475[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:19 step:90480[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:19 step:90485[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:19 step:90490[D loss: 0.999990] [G loss: 1.000103]\n",
      "epoch:19 step:90495[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:19 step:90500[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:19 step:90505[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:19 step:90510[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:19 step:90515[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:19 step:90520[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:19 step:90525[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:19 step:90530[D loss: 0.999959] [G loss: 1.000128]\n",
      "epoch:19 step:90535[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:19 step:90540[D loss: 1.000034] [G loss: 0.999900]\n",
      "epoch:19 step:90545[D loss: 0.999994] [G loss: 1.000040]\n",
      "epoch:19 step:90550[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:19 step:90555[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:19 step:90560[D loss: 1.000001] [G loss: 1.000030]\n",
      "epoch:19 step:90565[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:19 step:90570[D loss: 1.000028] [G loss: 0.999962]\n",
      "epoch:19 step:90575[D loss: 0.999952] [G loss: 1.000051]\n",
      "epoch:19 step:90580[D loss: 0.999931] [G loss: 1.000111]\n",
      "epoch:19 step:90585[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:19 step:90590[D loss: 1.000040] [G loss: 0.999984]\n",
      "epoch:19 step:90595[D loss: 1.000007] [G loss: 1.000144]\n",
      "epoch:19 step:90600[D loss: 0.999949] [G loss: 1.000045]\n",
      "epoch:19 step:90605[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:19 step:90610[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:19 step:90615[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:19 step:90620[D loss: 1.000136] [G loss: 0.999869]\n",
      "epoch:19 step:90625[D loss: 1.000095] [G loss: 0.999885]\n",
      "epoch:19 step:90630[D loss: 1.000069] [G loss: 0.999935]\n",
      "epoch:19 step:90635[D loss: 0.999977] [G loss: 0.999966]\n",
      "epoch:19 step:90640[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:19 step:90645[D loss: 0.999953] [G loss: 0.999986]\n",
      "epoch:19 step:90650[D loss: 0.999948] [G loss: 1.000054]\n",
      "epoch:19 step:90655[D loss: 0.999977] [G loss: 1.000025]\n",
      "epoch:19 step:90660[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:19 step:90665[D loss: 1.000027] [G loss: 0.999970]\n",
      "epoch:19 step:90670[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:19 step:90675[D loss: 1.000012] [G loss: 1.000008]\n",
      "epoch:19 step:90680[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:19 step:90685[D loss: 0.999961] [G loss: 1.000039]\n",
      "epoch:19 step:90690[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:19 step:90695[D loss: 0.999990] [G loss: 1.000029]\n",
      "epoch:19 step:90700[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:19 step:90705[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:19 step:90710[D loss: 0.999978] [G loss: 1.000025]\n",
      "epoch:19 step:90715[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:19 step:90720[D loss: 0.999973] [G loss: 1.000034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:90725[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:19 step:90730[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:19 step:90735[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:19 step:90740[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:19 step:90745[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:19 step:90750[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:19 step:90755[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:19 step:90760[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:19 step:90765[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:19 step:90770[D loss: 1.000016] [G loss: 0.999996]\n",
      "epoch:19 step:90775[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:19 step:90780[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:19 step:90785[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:19 step:90790[D loss: 0.999973] [G loss: 1.000083]\n",
      "epoch:19 step:90795[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:19 step:90800[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:19 step:90805[D loss: 1.000023] [G loss: 1.000026]\n",
      "epoch:19 step:90810[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:19 step:90815[D loss: 0.999977] [G loss: 1.000103]\n",
      "epoch:19 step:90820[D loss: 0.999943] [G loss: 1.000103]\n",
      "epoch:19 step:90825[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:19 step:90830[D loss: 0.999996] [G loss: 1.000077]\n",
      "epoch:19 step:90835[D loss: 1.000048] [G loss: 1.000007]\n",
      "epoch:19 step:90840[D loss: 1.000055] [G loss: 0.999918]\n",
      "epoch:19 step:90845[D loss: 0.999913] [G loss: 1.000153]\n",
      "epoch:19 step:90850[D loss: 1.000028] [G loss: 1.000062]\n",
      "epoch:19 step:90855[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:19 step:90860[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:19 step:90865[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:19 step:90870[D loss: 1.000002] [G loss: 0.999977]\n",
      "epoch:19 step:90875[D loss: 1.000012] [G loss: 0.999968]\n",
      "epoch:19 step:90880[D loss: 0.999961] [G loss: 1.000138]\n",
      "epoch:19 step:90885[D loss: 0.999969] [G loss: 1.000013]\n",
      "epoch:19 step:90890[D loss: 1.000013] [G loss: 1.000025]\n",
      "epoch:19 step:90895[D loss: 1.000001] [G loss: 1.000017]\n",
      "epoch:19 step:90900[D loss: 0.999998] [G loss: 1.000091]\n",
      "epoch:19 step:90905[D loss: 1.000116] [G loss: 0.999962]\n",
      "epoch:19 step:90910[D loss: 0.999898] [G loss: 1.000210]\n",
      "epoch:19 step:90915[D loss: 0.999928] [G loss: 1.000073]\n",
      "epoch:19 step:90920[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:19 step:90925[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:19 step:90930[D loss: 1.000036] [G loss: 0.999979]\n",
      "epoch:19 step:90935[D loss: 0.999982] [G loss: 1.000019]\n",
      "epoch:19 step:90940[D loss: 1.000072] [G loss: 0.999980]\n",
      "epoch:19 step:90945[D loss: 1.000005] [G loss: 0.999956]\n",
      "epoch:19 step:90950[D loss: 1.000022] [G loss: 1.000063]\n",
      "epoch:19 step:90955[D loss: 0.999951] [G loss: 1.000136]\n",
      "epoch:19 step:90960[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:19 step:90965[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:19 step:90970[D loss: 1.000034] [G loss: 0.999979]\n",
      "epoch:19 step:90975[D loss: 0.999954] [G loss: 1.000045]\n",
      "epoch:19 step:90980[D loss: 0.999999] [G loss: 0.999980]\n",
      "epoch:19 step:90985[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:19 step:90990[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:19 step:90995[D loss: 0.999998] [G loss: 0.999983]\n",
      "epoch:19 step:91000[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:19 step:91005[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:19 step:91010[D loss: 0.999959] [G loss: 1.000106]\n",
      "epoch:19 step:91015[D loss: 0.999940] [G loss: 1.000156]\n",
      "epoch:19 step:91020[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:19 step:91025[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:19 step:91030[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:19 step:91035[D loss: 1.000004] [G loss: 1.000051]\n",
      "epoch:19 step:91040[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:19 step:91045[D loss: 0.999962] [G loss: 1.000050]\n",
      "epoch:19 step:91050[D loss: 1.000011] [G loss: 1.000054]\n",
      "epoch:19 step:91055[D loss: 0.999927] [G loss: 1.000085]\n",
      "epoch:19 step:91060[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:19 step:91065[D loss: 1.000044] [G loss: 1.000042]\n",
      "epoch:19 step:91070[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:19 step:91075[D loss: 1.000014] [G loss: 1.000005]\n",
      "epoch:19 step:91080[D loss: 0.999989] [G loss: 0.999982]\n",
      "epoch:19 step:91085[D loss: 0.999952] [G loss: 1.000110]\n",
      "epoch:19 step:91090[D loss: 0.999934] [G loss: 1.000074]\n",
      "epoch:19 step:91095[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:19 step:91100[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:19 step:91105[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:19 step:91110[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:19 step:91115[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:19 step:91120[D loss: 1.000041] [G loss: 1.000040]\n",
      "epoch:19 step:91125[D loss: 0.999960] [G loss: 1.000148]\n",
      "epoch:19 step:91130[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:19 step:91135[D loss: 1.000056] [G loss: 0.999959]\n",
      "epoch:19 step:91140[D loss: 0.999934] [G loss: 1.000152]\n",
      "epoch:19 step:91145[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:19 step:91150[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:19 step:91155[D loss: 0.999983] [G loss: 1.000008]\n",
      "epoch:19 step:91160[D loss: 1.000050] [G loss: 0.999940]\n",
      "epoch:19 step:91165[D loss: 0.999964] [G loss: 1.000110]\n",
      "epoch:19 step:91170[D loss: 0.999943] [G loss: 1.000104]\n",
      "epoch:19 step:91175[D loss: 0.999935] [G loss: 1.000164]\n",
      "epoch:19 step:91180[D loss: 0.999961] [G loss: 1.000046]\n",
      "epoch:19 step:91185[D loss: 0.999974] [G loss: 1.000120]\n",
      "epoch:19 step:91190[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:19 step:91195[D loss: 0.999963] [G loss: 1.000040]\n",
      "epoch:19 step:91200[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:19 step:91205[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:19 step:91210[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:19 step:91215[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:19 step:91220[D loss: 0.999970] [G loss: 1.000043]\n",
      "epoch:19 step:91225[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:19 step:91230[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:19 step:91235[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:19 step:91240[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:19 step:91245[D loss: 0.999998] [G loss: 1.000080]\n",
      "epoch:19 step:91250[D loss: 0.999963] [G loss: 1.000105]\n",
      "epoch:19 step:91255[D loss: 1.000027] [G loss: 1.000024]\n",
      "epoch:19 step:91260[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:19 step:91265[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:19 step:91270[D loss: 1.000006] [G loss: 0.999998]\n",
      "epoch:19 step:91275[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:19 step:91280[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:19 step:91285[D loss: 0.999979] [G loss: 1.000114]\n",
      "epoch:19 step:91290[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:19 step:91295[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:19 step:91300[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:19 step:91305[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:19 step:91310[D loss: 1.000041] [G loss: 1.000166]\n",
      "epoch:19 step:91315[D loss: 0.999909] [G loss: 1.000164]\n",
      "epoch:19 step:91320[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:19 step:91325[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:19 step:91330[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:19 step:91335[D loss: 1.000028] [G loss: 0.999991]\n",
      "epoch:19 step:91340[D loss: 1.000031] [G loss: 0.999974]\n",
      "epoch:19 step:91345[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:19 step:91350[D loss: 0.999992] [G loss: 1.000083]\n",
      "epoch:19 step:91355[D loss: 0.999958] [G loss: 1.000208]\n",
      "epoch:19 step:91360[D loss: 1.000056] [G loss: 1.000085]\n",
      "epoch:19 step:91365[D loss: 0.999934] [G loss: 1.000127]\n",
      "epoch:19 step:91370[D loss: 0.999970] [G loss: 1.000117]\n",
      "epoch:19 step:91375[D loss: 0.999994] [G loss: 1.000006]\n",
      "epoch:19 step:91380[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:19 step:91385[D loss: 1.000010] [G loss: 0.999984]\n",
      "epoch:19 step:91390[D loss: 0.999989] [G loss: 1.000000]\n",
      "epoch:19 step:91395[D loss: 1.000036] [G loss: 0.999960]\n",
      "epoch:19 step:91400[D loss: 0.999912] [G loss: 1.000084]\n",
      "epoch:19 step:91405[D loss: 0.999995] [G loss: 1.000072]\n",
      "epoch:19 step:91410[D loss: 0.999941] [G loss: 1.000067]\n",
      "epoch:19 step:91415[D loss: 0.999944] [G loss: 1.000055]\n",
      "epoch:19 step:91420[D loss: 1.000055] [G loss: 1.000045]\n",
      "epoch:19 step:91425[D loss: 0.999926] [G loss: 1.000092]\n",
      "epoch:19 step:91430[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:19 step:91435[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:19 step:91440[D loss: 1.000011] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:91445[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:19 step:91450[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:19 step:91455[D loss: 1.000082] [G loss: 0.999987]\n",
      "epoch:19 step:91460[D loss: 0.999982] [G loss: 1.000142]\n",
      "epoch:19 step:91465[D loss: 0.999970] [G loss: 1.000157]\n",
      "epoch:19 step:91470[D loss: 0.999965] [G loss: 1.000164]\n",
      "epoch:19 step:91475[D loss: 0.999958] [G loss: 1.000193]\n",
      "epoch:19 step:91480[D loss: 1.000000] [G loss: 1.000175]\n",
      "epoch:19 step:91485[D loss: 0.999910] [G loss: 1.000229]\n",
      "epoch:19 step:91490[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:19 step:91495[D loss: 1.000068] [G loss: 1.000009]\n",
      "epoch:19 step:91500[D loss: 1.000000] [G loss: 1.000059]\n",
      "epoch:19 step:91505[D loss: 0.999955] [G loss: 1.000078]\n",
      "epoch:19 step:91510[D loss: 1.000025] [G loss: 1.000009]\n",
      "epoch:19 step:91515[D loss: 1.000055] [G loss: 1.000007]\n",
      "epoch:19 step:91520[D loss: 0.999940] [G loss: 1.000006]\n",
      "epoch:19 step:91525[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:19 step:91530[D loss: 0.999949] [G loss: 1.000022]\n",
      "epoch:19 step:91535[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:19 step:91540[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:19 step:91545[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:19 step:91550[D loss: 0.999991] [G loss: 1.000120]\n",
      "epoch:19 step:91555[D loss: 0.999919] [G loss: 1.000243]\n",
      "epoch:19 step:91560[D loss: 0.999881] [G loss: 1.000219]\n",
      "epoch:19 step:91565[D loss: 1.000078] [G loss: 1.000078]\n",
      "epoch:19 step:91570[D loss: 0.999934] [G loss: 1.000154]\n",
      "epoch:19 step:91575[D loss: 0.999991] [G loss: 1.000004]\n",
      "epoch:19 step:91580[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:19 step:91585[D loss: 0.999980] [G loss: 1.000044]\n",
      "epoch:19 step:91590[D loss: 0.999928] [G loss: 1.000128]\n",
      "epoch:19 step:91595[D loss: 1.000009] [G loss: 0.999982]\n",
      "epoch:19 step:91600[D loss: 1.000062] [G loss: 1.000044]\n",
      "epoch:19 step:91605[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:19 step:91610[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:19 step:91615[D loss: 0.999997] [G loss: 1.000093]\n",
      "epoch:19 step:91620[D loss: 0.999929] [G loss: 1.000238]\n",
      "epoch:19 step:91625[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:19 step:91630[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:19 step:91635[D loss: 0.999987] [G loss: 1.000086]\n",
      "epoch:19 step:91640[D loss: 1.000007] [G loss: 0.999979]\n",
      "epoch:19 step:91645[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:19 step:91650[D loss: 1.000006] [G loss: 0.999898]\n",
      "epoch:19 step:91655[D loss: 0.999890] [G loss: 1.000173]\n",
      "epoch:19 step:91660[D loss: 1.000006] [G loss: 1.000077]\n",
      "epoch:19 step:91665[D loss: 0.999970] [G loss: 1.000057]\n",
      "epoch:19 step:91670[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:19 step:91675[D loss: 0.999955] [G loss: 1.000095]\n",
      "epoch:19 step:91680[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:19 step:91685[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:19 step:91690[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:19 step:91695[D loss: 1.000002] [G loss: 1.000081]\n",
      "epoch:19 step:91700[D loss: 0.999997] [G loss: 1.000075]\n",
      "epoch:19 step:91705[D loss: 1.000036] [G loss: 1.000028]\n",
      "epoch:19 step:91710[D loss: 1.000022] [G loss: 1.000041]\n",
      "epoch:19 step:91715[D loss: 0.999969] [G loss: 1.000047]\n",
      "epoch:19 step:91720[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:19 step:91725[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:19 step:91730[D loss: 1.000138] [G loss: 0.999854]\n",
      "epoch:19 step:91735[D loss: 0.999954] [G loss: 1.000123]\n",
      "epoch:19 step:91740[D loss: 1.000129] [G loss: 0.999771]\n",
      "epoch:19 step:91745[D loss: 1.000116] [G loss: 0.999805]\n",
      "epoch:19 step:91750[D loss: 0.999899] [G loss: 1.000055]\n",
      "epoch:19 step:91755[D loss: 0.999917] [G loss: 1.000170]\n",
      "epoch:19 step:91760[D loss: 0.999953] [G loss: 1.000104]\n",
      "epoch:19 step:91765[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:19 step:91770[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:19 step:91775[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:19 step:91780[D loss: 1.000048] [G loss: 0.999940]\n",
      "epoch:19 step:91785[D loss: 0.999945] [G loss: 1.000039]\n",
      "epoch:19 step:91790[D loss: 0.999976] [G loss: 1.000017]\n",
      "epoch:19 step:91795[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:19 step:91800[D loss: 0.999971] [G loss: 1.000026]\n",
      "epoch:19 step:91805[D loss: 0.999970] [G loss: 1.000124]\n",
      "epoch:19 step:91810[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:19 step:91815[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:19 step:91820[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:19 step:91825[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:19 step:91830[D loss: 1.000006] [G loss: 1.000058]\n",
      "epoch:19 step:91835[D loss: 0.999955] [G loss: 1.000109]\n",
      "epoch:19 step:91840[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:19 step:91845[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:19 step:91850[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:19 step:91855[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:19 step:91860[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:19 step:91865[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:19 step:91870[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:19 step:91875[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:19 step:91880[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:19 step:91885[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:19 step:91890[D loss: 1.000009] [G loss: 1.000093]\n",
      "epoch:19 step:91895[D loss: 1.000014] [G loss: 0.999994]\n",
      "epoch:19 step:91900[D loss: 0.999936] [G loss: 1.000071]\n",
      "epoch:19 step:91905[D loss: 0.999976] [G loss: 1.000160]\n",
      "epoch:19 step:91910[D loss: 0.999979] [G loss: 1.000102]\n",
      "epoch:19 step:91915[D loss: 1.000012] [G loss: 1.000128]\n",
      "epoch:19 step:91920[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:19 step:91925[D loss: 1.000040] [G loss: 0.999949]\n",
      "epoch:19 step:91930[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:19 step:91935[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:19 step:91940[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:19 step:91945[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:19 step:91950[D loss: 0.999968] [G loss: 1.000042]\n",
      "epoch:19 step:91955[D loss: 1.000053] [G loss: 0.999962]\n",
      "epoch:19 step:91960[D loss: 1.000082] [G loss: 0.999856]\n",
      "epoch:19 step:91965[D loss: 0.999973] [G loss: 1.000008]\n",
      "epoch:19 step:91970[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:19 step:91975[D loss: 0.999961] [G loss: 1.000105]\n",
      "epoch:19 step:91980[D loss: 1.000031] [G loss: 1.000009]\n",
      "epoch:19 step:91985[D loss: 0.999953] [G loss: 1.000018]\n",
      "epoch:19 step:91990[D loss: 1.000094] [G loss: 0.999916]\n",
      "epoch:19 step:91995[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:19 step:92000[D loss: 0.999958] [G loss: 1.000043]\n",
      "epoch:19 step:92005[D loss: 1.000005] [G loss: 1.000040]\n",
      "epoch:19 step:92010[D loss: 0.999952] [G loss: 1.000119]\n",
      "epoch:19 step:92015[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:19 step:92020[D loss: 1.000032] [G loss: 0.999973]\n",
      "epoch:19 step:92025[D loss: 0.999949] [G loss: 1.000142]\n",
      "epoch:19 step:92030[D loss: 0.999942] [G loss: 1.000057]\n",
      "epoch:19 step:92035[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:19 step:92040[D loss: 0.999979] [G loss: 1.000012]\n",
      "epoch:19 step:92045[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:19 step:92050[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:19 step:92055[D loss: 1.000023] [G loss: 0.999949]\n",
      "epoch:19 step:92060[D loss: 1.000072] [G loss: 0.999979]\n",
      "epoch:19 step:92065[D loss: 0.999903] [G loss: 1.000118]\n",
      "epoch:19 step:92070[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:19 step:92075[D loss: 1.000017] [G loss: 0.999995]\n",
      "epoch:19 step:92080[D loss: 0.999942] [G loss: 1.000076]\n",
      "epoch:19 step:92085[D loss: 0.999948] [G loss: 1.000082]\n",
      "epoch:19 step:92090[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:19 step:92095[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:19 step:92100[D loss: 1.000076] [G loss: 0.999868]\n",
      "epoch:19 step:92105[D loss: 0.999941] [G loss: 1.000152]\n",
      "epoch:19 step:92110[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:19 step:92115[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:19 step:92120[D loss: 0.999945] [G loss: 1.000083]\n",
      "epoch:19 step:92125[D loss: 1.000003] [G loss: 1.000084]\n",
      "epoch:19 step:92130[D loss: 0.999921] [G loss: 1.000172]\n",
      "epoch:19 step:92135[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:19 step:92140[D loss: 1.000023] [G loss: 1.000074]\n",
      "epoch:19 step:92145[D loss: 0.999941] [G loss: 1.000072]\n",
      "epoch:19 step:92150[D loss: 1.000027] [G loss: 0.999968]\n",
      "epoch:19 step:92155[D loss: 1.000035] [G loss: 0.999888]\n",
      "epoch:19 step:92160[D loss: 0.999942] [G loss: 1.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:92165[D loss: 1.000012] [G loss: 1.000046]\n",
      "epoch:19 step:92170[D loss: 0.999873] [G loss: 1.000123]\n",
      "epoch:19 step:92175[D loss: 1.000030] [G loss: 1.000039]\n",
      "epoch:19 step:92180[D loss: 0.999949] [G loss: 1.000148]\n",
      "epoch:19 step:92185[D loss: 0.999892] [G loss: 1.000146]\n",
      "epoch:19 step:92190[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:19 step:92195[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:19 step:92200[D loss: 1.000106] [G loss: 0.999958]\n",
      "epoch:19 step:92205[D loss: 0.999928] [G loss: 1.000023]\n",
      "epoch:19 step:92210[D loss: 0.999959] [G loss: 1.000038]\n",
      "epoch:19 step:92215[D loss: 1.000081] [G loss: 0.999980]\n",
      "epoch:19 step:92220[D loss: 0.999908] [G loss: 1.000258]\n",
      "epoch:19 step:92225[D loss: 1.000012] [G loss: 0.999963]\n",
      "epoch:19 step:92230[D loss: 0.999951] [G loss: 1.000050]\n",
      "epoch:19 step:92235[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:19 step:92240[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:19 step:92245[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:19 step:92250[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:19 step:92255[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:19 step:92260[D loss: 0.999981] [G loss: 1.000058]\n",
      "epoch:19 step:92265[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:19 step:92270[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:19 step:92275[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:19 step:92280[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:19 step:92285[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:19 step:92290[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:19 step:92295[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:19 step:92300[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:19 step:92305[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:19 step:92310[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:19 step:92315[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:19 step:92320[D loss: 0.999962] [G loss: 1.000124]\n",
      "epoch:19 step:92325[D loss: 1.000036] [G loss: 1.000050]\n",
      "epoch:19 step:92330[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:19 step:92335[D loss: 0.999990] [G loss: 0.999981]\n",
      "epoch:19 step:92340[D loss: 0.999981] [G loss: 1.000003]\n",
      "epoch:19 step:92345[D loss: 1.000005] [G loss: 0.999956]\n",
      "epoch:19 step:92350[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:19 step:92355[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:19 step:92360[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:19 step:92365[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:19 step:92370[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:19 step:92375[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:19 step:92380[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:19 step:92385[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:19 step:92390[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:19 step:92395[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:19 step:92400[D loss: 0.999942] [G loss: 1.000094]\n",
      "epoch:19 step:92405[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:19 step:92410[D loss: 0.999991] [G loss: 0.999996]\n",
      "epoch:19 step:92415[D loss: 0.999925] [G loss: 1.000138]\n",
      "epoch:19 step:92420[D loss: 1.000000] [G loss: 0.999998]\n",
      "epoch:19 step:92425[D loss: 0.999978] [G loss: 1.000132]\n",
      "epoch:19 step:92430[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:19 step:92435[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:19 step:92440[D loss: 1.000002] [G loss: 1.000017]\n",
      "epoch:19 step:92445[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:19 step:92450[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:19 step:92455[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:19 step:92460[D loss: 0.999960] [G loss: 1.000135]\n",
      "epoch:19 step:92465[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:19 step:92470[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:19 step:92475[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:19 step:92480[D loss: 1.000042] [G loss: 0.999970]\n",
      "epoch:19 step:92485[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:19 step:92490[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:19 step:92495[D loss: 0.999954] [G loss: 1.000061]\n",
      "epoch:19 step:92500[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:19 step:92505[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:19 step:92510[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:19 step:92515[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:19 step:92520[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:19 step:92525[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:19 step:92530[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:19 step:92535[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:19 step:92540[D loss: 1.000063] [G loss: 0.999970]\n",
      "epoch:19 step:92545[D loss: 1.000038] [G loss: 0.999980]\n",
      "epoch:19 step:92550[D loss: 0.999934] [G loss: 1.000132]\n",
      "epoch:19 step:92555[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:19 step:92560[D loss: 1.000009] [G loss: 1.000012]\n",
      "epoch:19 step:92565[D loss: 1.000099] [G loss: 0.999893]\n",
      "epoch:19 step:92570[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:19 step:92575[D loss: 0.999975] [G loss: 1.000012]\n",
      "epoch:19 step:92580[D loss: 0.999938] [G loss: 1.000123]\n",
      "epoch:19 step:92585[D loss: 0.999989] [G loss: 1.000196]\n",
      "epoch:19 step:92590[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:19 step:92595[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:19 step:92600[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:19 step:92605[D loss: 1.000019] [G loss: 0.999984]\n",
      "epoch:19 step:92610[D loss: 1.000047] [G loss: 0.999953]\n",
      "epoch:19 step:92615[D loss: 0.999957] [G loss: 1.000023]\n",
      "epoch:19 step:92620[D loss: 0.999968] [G loss: 1.000028]\n",
      "epoch:19 step:92625[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:19 step:92630[D loss: 0.999986] [G loss: 1.000135]\n",
      "epoch:19 step:92635[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:19 step:92640[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:19 step:92645[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:19 step:92650[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:19 step:92655[D loss: 1.000008] [G loss: 1.000007]\n",
      "epoch:19 step:92660[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:19 step:92665[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:19 step:92670[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:19 step:92675[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:19 step:92680[D loss: 0.999977] [G loss: 1.000012]\n",
      "epoch:19 step:92685[D loss: 0.999986] [G loss: 1.000049]\n",
      "epoch:19 step:92690[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:19 step:92695[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:19 step:92700[D loss: 1.000003] [G loss: 1.000089]\n",
      "epoch:19 step:92705[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:19 step:92710[D loss: 0.999998] [G loss: 1.000115]\n",
      "epoch:19 step:92715[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:19 step:92720[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:19 step:92725[D loss: 1.000056] [G loss: 1.000065]\n",
      "epoch:19 step:92730[D loss: 0.999929] [G loss: 0.999994]\n",
      "epoch:19 step:92735[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:19 step:92740[D loss: 0.999986] [G loss: 0.999983]\n",
      "epoch:19 step:92745[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:19 step:92750[D loss: 0.999953] [G loss: 1.000092]\n",
      "epoch:19 step:92755[D loss: 0.999995] [G loss: 1.000030]\n",
      "epoch:19 step:92760[D loss: 0.999946] [G loss: 1.000092]\n",
      "epoch:19 step:92765[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:19 step:92770[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:19 step:92775[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:19 step:92780[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:19 step:92785[D loss: 1.000019] [G loss: 1.000063]\n",
      "epoch:19 step:92790[D loss: 1.000005] [G loss: 1.000007]\n",
      "epoch:19 step:92795[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:19 step:92800[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:19 step:92805[D loss: 0.999998] [G loss: 1.000080]\n",
      "epoch:19 step:92810[D loss: 0.999938] [G loss: 1.000082]\n",
      "epoch:19 step:92815[D loss: 0.999940] [G loss: 1.000102]\n",
      "epoch:19 step:92820[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:19 step:92825[D loss: 0.999990] [G loss: 1.000100]\n",
      "epoch:19 step:92830[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:19 step:92835[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:19 step:92840[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:19 step:92845[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:19 step:92850[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:19 step:92855[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:19 step:92860[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:19 step:92865[D loss: 0.999994] [G loss: 1.000026]\n",
      "epoch:19 step:92870[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:19 step:92875[D loss: 1.000019] [G loss: 0.999950]\n",
      "epoch:19 step:92880[D loss: 0.999965] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:92885[D loss: 1.000109] [G loss: 0.999878]\n",
      "epoch:19 step:92890[D loss: 0.999972] [G loss: 0.999994]\n",
      "epoch:19 step:92895[D loss: 0.999976] [G loss: 1.000084]\n",
      "epoch:19 step:92900[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:19 step:92905[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:19 step:92910[D loss: 1.000061] [G loss: 0.999945]\n",
      "epoch:19 step:92915[D loss: 0.999955] [G loss: 1.000147]\n",
      "epoch:19 step:92920[D loss: 0.999937] [G loss: 1.000018]\n",
      "epoch:19 step:92925[D loss: 1.000030] [G loss: 0.999938]\n",
      "epoch:19 step:92930[D loss: 0.999997] [G loss: 1.000092]\n",
      "epoch:19 step:92935[D loss: 0.999962] [G loss: 1.000105]\n",
      "epoch:19 step:92940[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:19 step:92945[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:19 step:92950[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:19 step:92955[D loss: 0.999965] [G loss: 1.000038]\n",
      "epoch:19 step:92960[D loss: 0.999962] [G loss: 1.000107]\n",
      "epoch:19 step:92965[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:19 step:92970[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:19 step:92975[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:19 step:92980[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:19 step:92985[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:19 step:92990[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:19 step:92995[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:19 step:93000[D loss: 0.999990] [G loss: 1.000081]\n",
      "epoch:19 step:93005[D loss: 1.000055] [G loss: 1.000004]\n",
      "epoch:19 step:93010[D loss: 0.999952] [G loss: 1.000098]\n",
      "epoch:19 step:93015[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:19 step:93020[D loss: 0.999970] [G loss: 1.000097]\n",
      "epoch:19 step:93025[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:19 step:93030[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:19 step:93035[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:19 step:93040[D loss: 1.000033] [G loss: 1.000006]\n",
      "epoch:19 step:93045[D loss: 0.999915] [G loss: 1.000113]\n",
      "epoch:19 step:93050[D loss: 0.999959] [G loss: 1.000136]\n",
      "epoch:19 step:93055[D loss: 1.000052] [G loss: 1.000015]\n",
      "epoch:19 step:93060[D loss: 0.999970] [G loss: 1.000046]\n",
      "epoch:19 step:93065[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:19 step:93070[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:19 step:93075[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:19 step:93080[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:19 step:93085[D loss: 0.999978] [G loss: 1.000021]\n",
      "epoch:19 step:93090[D loss: 0.999978] [G loss: 0.999994]\n",
      "epoch:19 step:93095[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:19 step:93100[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:19 step:93105[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:19 step:93110[D loss: 0.999996] [G loss: 1.000049]\n",
      "epoch:19 step:93115[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:19 step:93120[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:19 step:93125[D loss: 0.999944] [G loss: 1.000142]\n",
      "epoch:19 step:93130[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:19 step:93135[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:19 step:93140[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:19 step:93145[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:19 step:93150[D loss: 0.999921] [G loss: 1.000128]\n",
      "epoch:19 step:93155[D loss: 0.999955] [G loss: 1.000091]\n",
      "epoch:19 step:93160[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:19 step:93165[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:19 step:93170[D loss: 0.999989] [G loss: 1.000037]\n",
      "epoch:19 step:93175[D loss: 1.000007] [G loss: 1.000083]\n",
      "epoch:19 step:93180[D loss: 0.999944] [G loss: 1.000077]\n",
      "epoch:19 step:93185[D loss: 1.000027] [G loss: 1.000080]\n",
      "epoch:19 step:93190[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:19 step:93195[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:19 step:93200[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:19 step:93205[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:19 step:93210[D loss: 1.000019] [G loss: 1.000042]\n",
      "epoch:19 step:93215[D loss: 0.999947] [G loss: 1.000080]\n",
      "epoch:19 step:93220[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:19 step:93225[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:19 step:93230[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:19 step:93235[D loss: 0.999974] [G loss: 1.000147]\n",
      "epoch:19 step:93240[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:19 step:93245[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:19 step:93250[D loss: 0.999953] [G loss: 1.000113]\n",
      "epoch:19 step:93255[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:19 step:93260[D loss: 0.999988] [G loss: 1.000101]\n",
      "epoch:19 step:93265[D loss: 0.999953] [G loss: 1.000036]\n",
      "epoch:19 step:93270[D loss: 0.999982] [G loss: 1.000027]\n",
      "epoch:19 step:93275[D loss: 0.999999] [G loss: 0.999996]\n",
      "epoch:19 step:93280[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:19 step:93285[D loss: 0.999961] [G loss: 1.000005]\n",
      "epoch:19 step:93290[D loss: 1.000004] [G loss: 1.000062]\n",
      "epoch:19 step:93295[D loss: 1.000061] [G loss: 1.000029]\n",
      "epoch:19 step:93300[D loss: 1.000009] [G loss: 1.000045]\n",
      "epoch:19 step:93305[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:19 step:93310[D loss: 1.000018] [G loss: 1.000007]\n",
      "epoch:19 step:93315[D loss: 0.999956] [G loss: 1.000054]\n",
      "epoch:19 step:93320[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:19 step:93325[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:19 step:93330[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:19 step:93335[D loss: 0.999995] [G loss: 1.000069]\n",
      "epoch:19 step:93340[D loss: 1.000003] [G loss: 1.000082]\n",
      "epoch:19 step:93345[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:19 step:93350[D loss: 1.000032] [G loss: 0.999999]\n",
      "epoch:19 step:93355[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:19 step:93360[D loss: 0.999949] [G loss: 1.000120]\n",
      "epoch:19 step:93365[D loss: 0.999961] [G loss: 1.000179]\n",
      "epoch:19 step:93370[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:19 step:93375[D loss: 1.000007] [G loss: 1.000011]\n",
      "epoch:19 step:93380[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:19 step:93385[D loss: 0.999966] [G loss: 1.000042]\n",
      "epoch:19 step:93390[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:19 step:93395[D loss: 0.999948] [G loss: 1.000089]\n",
      "epoch:19 step:93400[D loss: 0.999904] [G loss: 1.000085]\n",
      "epoch:19 step:93405[D loss: 1.000028] [G loss: 1.000028]\n",
      "epoch:19 step:93410[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:19 step:93415[D loss: 0.999959] [G loss: 1.000142]\n",
      "epoch:19 step:93420[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:19 step:93425[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:19 step:93430[D loss: 0.999992] [G loss: 1.000003]\n",
      "epoch:19 step:93435[D loss: 0.999932] [G loss: 1.000098]\n",
      "epoch:19 step:93440[D loss: 1.000050] [G loss: 1.000039]\n",
      "epoch:19 step:93445[D loss: 0.999934] [G loss: 1.000105]\n",
      "epoch:19 step:93450[D loss: 0.999932] [G loss: 1.000121]\n",
      "epoch:19 step:93455[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:19 step:93460[D loss: 0.999971] [G loss: 1.000103]\n",
      "epoch:19 step:93465[D loss: 0.999990] [G loss: 1.000063]\n",
      "epoch:19 step:93470[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:19 step:93475[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:19 step:93480[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:19 step:93485[D loss: 1.000032] [G loss: 0.999989]\n",
      "epoch:19 step:93490[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:19 step:93495[D loss: 1.000042] [G loss: 0.999952]\n",
      "epoch:19 step:93500[D loss: 1.000009] [G loss: 0.999975]\n",
      "epoch:19 step:93505[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:19 step:93510[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:19 step:93515[D loss: 0.999998] [G loss: 1.000019]\n",
      "epoch:19 step:93520[D loss: 0.999956] [G loss: 1.000171]\n",
      "epoch:19 step:93525[D loss: 0.999956] [G loss: 1.000083]\n",
      "epoch:19 step:93530[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:19 step:93535[D loss: 1.000034] [G loss: 1.000048]\n",
      "epoch:19 step:93540[D loss: 0.999927] [G loss: 1.000095]\n",
      "epoch:19 step:93545[D loss: 1.000079] [G loss: 0.999997]\n",
      "epoch:19 step:93550[D loss: 0.999904] [G loss: 1.000088]\n",
      "epoch:19 step:93555[D loss: 0.999975] [G loss: 1.000009]\n",
      "epoch:19 step:93560[D loss: 0.999950] [G loss: 1.000050]\n",
      "epoch:19 step:93565[D loss: 0.999983] [G loss: 0.999983]\n",
      "epoch:19 step:93570[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:19 step:93575[D loss: 0.999972] [G loss: 1.000040]\n",
      "epoch:19 step:93580[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:19 step:93585[D loss: 0.999979] [G loss: 1.000092]\n",
      "epoch:19 step:93590[D loss: 1.000024] [G loss: 0.999988]\n",
      "epoch:19 step:93595[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:19 step:93600[D loss: 1.000011] [G loss: 1.000089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:93605[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:19 step:93610[D loss: 1.000000] [G loss: 1.000029]\n",
      "epoch:19 step:93615[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:19 step:93620[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:19 step:93625[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:19 step:93630[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:19 step:93635[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:19 step:93640[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:19 step:93645[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:19 step:93650[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:19 step:93655[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:19 step:93660[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:19 step:93665[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:19 step:93670[D loss: 1.000004] [G loss: 1.000056]\n",
      "epoch:19 step:93675[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:19 step:93680[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:19 step:93685[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:19 step:93690[D loss: 1.000032] [G loss: 1.000002]\n",
      "epoch:19 step:93695[D loss: 0.999993] [G loss: 1.000014]\n",
      "epoch:19 step:93700[D loss: 0.999965] [G loss: 1.000043]\n",
      "epoch:20 step:93705[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:20 step:93710[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:20 step:93715[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:20 step:93720[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:20 step:93725[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:20 step:93730[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:20 step:93735[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:20 step:93740[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:20 step:93745[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:20 step:93750[D loss: 1.000050] [G loss: 0.999998]\n",
      "epoch:20 step:93755[D loss: 1.000033] [G loss: 0.999966]\n",
      "epoch:20 step:93760[D loss: 0.999939] [G loss: 1.000074]\n",
      "epoch:20 step:93765[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:20 step:93770[D loss: 0.999953] [G loss: 1.000067]\n",
      "epoch:20 step:93775[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:20 step:93780[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:20 step:93785[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:20 step:93790[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:20 step:93795[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:20 step:93800[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:20 step:93805[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:20 step:93810[D loss: 0.999964] [G loss: 1.000116]\n",
      "epoch:20 step:93815[D loss: 1.000013] [G loss: 1.000010]\n",
      "epoch:20 step:93820[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:20 step:93825[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:20 step:93830[D loss: 1.000005] [G loss: 1.000040]\n",
      "epoch:20 step:93835[D loss: 1.000005] [G loss: 1.000074]\n",
      "epoch:20 step:93840[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:20 step:93845[D loss: 1.000005] [G loss: 1.000024]\n",
      "epoch:20 step:93850[D loss: 1.000013] [G loss: 1.000007]\n",
      "epoch:20 step:93855[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:20 step:93860[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:20 step:93865[D loss: 1.000000] [G loss: 1.000010]\n",
      "epoch:20 step:93870[D loss: 1.000002] [G loss: 1.000124]\n",
      "epoch:20 step:93875[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:20 step:93880[D loss: 1.000029] [G loss: 1.000065]\n",
      "epoch:20 step:93885[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:20 step:93890[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:20 step:93895[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:20 step:93900[D loss: 1.000050] [G loss: 0.999946]\n",
      "epoch:20 step:93905[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:20 step:93910[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:20 step:93915[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:20 step:93920[D loss: 0.999947] [G loss: 1.000101]\n",
      "epoch:20 step:93925[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:20 step:93930[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:20 step:93935[D loss: 0.999990] [G loss: 1.000059]\n",
      "epoch:20 step:93940[D loss: 0.999983] [G loss: 1.000078]\n",
      "epoch:20 step:93945[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:20 step:93950[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:20 step:93955[D loss: 1.000005] [G loss: 1.000044]\n",
      "epoch:20 step:93960[D loss: 0.999941] [G loss: 1.000099]\n",
      "epoch:20 step:93965[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:20 step:93970[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:20 step:93975[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:20 step:93980[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:20 step:93985[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:20 step:93990[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:20 step:93995[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:20 step:94000[D loss: 0.999984] [G loss: 1.000109]\n",
      "epoch:20 step:94005[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:20 step:94010[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:20 step:94015[D loss: 1.000038] [G loss: 0.999991]\n",
      "epoch:20 step:94020[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:20 step:94025[D loss: 0.999965] [G loss: 1.000033]\n",
      "epoch:20 step:94030[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:20 step:94035[D loss: 0.999954] [G loss: 1.000015]\n",
      "epoch:20 step:94040[D loss: 0.999954] [G loss: 1.000046]\n",
      "epoch:20 step:94045[D loss: 1.000048] [G loss: 0.999978]\n",
      "epoch:20 step:94050[D loss: 0.999996] [G loss: 1.000061]\n",
      "epoch:20 step:94055[D loss: 0.999935] [G loss: 1.000184]\n",
      "epoch:20 step:94060[D loss: 0.999982] [G loss: 1.000122]\n",
      "epoch:20 step:94065[D loss: 0.999927] [G loss: 1.000145]\n",
      "epoch:20 step:94070[D loss: 0.999939] [G loss: 1.000084]\n",
      "epoch:20 step:94075[D loss: 0.999987] [G loss: 1.000002]\n",
      "epoch:20 step:94080[D loss: 0.999961] [G loss: 1.000023]\n",
      "epoch:20 step:94085[D loss: 1.000004] [G loss: 0.999988]\n",
      "epoch:20 step:94090[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:20 step:94095[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:20 step:94100[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:20 step:94105[D loss: 1.000085] [G loss: 0.999932]\n",
      "epoch:20 step:94110[D loss: 0.999960] [G loss: 1.000061]\n",
      "epoch:20 step:94115[D loss: 1.000039] [G loss: 1.000062]\n",
      "epoch:20 step:94120[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:20 step:94125[D loss: 0.999975] [G loss: 1.000021]\n",
      "epoch:20 step:94130[D loss: 1.000030] [G loss: 0.999919]\n",
      "epoch:20 step:94135[D loss: 1.000000] [G loss: 1.000046]\n",
      "epoch:20 step:94140[D loss: 0.999954] [G loss: 1.000066]\n",
      "epoch:20 step:94145[D loss: 1.000069] [G loss: 1.000019]\n",
      "epoch:20 step:94150[D loss: 0.999977] [G loss: 1.000010]\n",
      "epoch:20 step:94155[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:20 step:94160[D loss: 0.999940] [G loss: 1.000083]\n",
      "epoch:20 step:94165[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:20 step:94170[D loss: 0.999999] [G loss: 1.000006]\n",
      "epoch:20 step:94175[D loss: 0.999984] [G loss: 1.000110]\n",
      "epoch:20 step:94180[D loss: 1.000125] [G loss: 0.999796]\n",
      "epoch:20 step:94185[D loss: 1.000001] [G loss: 1.000093]\n",
      "epoch:20 step:94190[D loss: 0.999880] [G loss: 1.000268]\n",
      "epoch:20 step:94195[D loss: 0.999885] [G loss: 1.000195]\n",
      "epoch:20 step:94200[D loss: 0.999975] [G loss: 1.000038]\n",
      "epoch:20 step:94205[D loss: 0.999959] [G loss: 1.000049]\n",
      "epoch:20 step:94210[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:20 step:94215[D loss: 1.000002] [G loss: 1.000019]\n",
      "epoch:20 step:94220[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:20 step:94225[D loss: 0.999934] [G loss: 1.000151]\n",
      "epoch:20 step:94230[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:20 step:94235[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:20 step:94240[D loss: 0.999985] [G loss: 1.000109]\n",
      "epoch:20 step:94245[D loss: 0.999947] [G loss: 1.000091]\n",
      "epoch:20 step:94250[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:20 step:94255[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:20 step:94260[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:20 step:94265[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:20 step:94270[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:20 step:94275[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:20 step:94280[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:20 step:94285[D loss: 1.000032] [G loss: 1.000111]\n",
      "epoch:20 step:94290[D loss: 1.000067] [G loss: 1.000045]\n",
      "epoch:20 step:94295[D loss: 1.000041] [G loss: 1.000104]\n",
      "epoch:20 step:94300[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:20 step:94305[D loss: 0.999924] [G loss: 1.000203]\n",
      "epoch:20 step:94310[D loss: 0.999974] [G loss: 1.000142]\n",
      "epoch:20 step:94315[D loss: 0.999961] [G loss: 1.000118]\n",
      "epoch:20 step:94320[D loss: 0.999957] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:94325[D loss: 1.000054] [G loss: 0.999943]\n",
      "epoch:20 step:94330[D loss: 0.999963] [G loss: 0.999991]\n",
      "epoch:20 step:94335[D loss: 0.999999] [G loss: 1.000005]\n",
      "epoch:20 step:94340[D loss: 0.999978] [G loss: 1.000001]\n",
      "epoch:20 step:94345[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:20 step:94350[D loss: 0.999932] [G loss: 1.000103]\n",
      "epoch:20 step:94355[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:20 step:94360[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:20 step:94365[D loss: 0.999999] [G loss: 1.000016]\n",
      "epoch:20 step:94370[D loss: 0.999964] [G loss: 1.000033]\n",
      "epoch:20 step:94375[D loss: 0.999963] [G loss: 1.000099]\n",
      "epoch:20 step:94380[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:20 step:94385[D loss: 1.000002] [G loss: 1.000014]\n",
      "epoch:20 step:94390[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:20 step:94395[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:20 step:94400[D loss: 0.999981] [G loss: 1.000064]\n",
      "epoch:20 step:94405[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:20 step:94410[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:20 step:94415[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:20 step:94420[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:20 step:94425[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:20 step:94430[D loss: 0.999940] [G loss: 1.000099]\n",
      "epoch:20 step:94435[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:20 step:94440[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:20 step:94445[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:20 step:94450[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:20 step:94455[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:20 step:94460[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:20 step:94465[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:20 step:94470[D loss: 0.999953] [G loss: 1.000122]\n",
      "epoch:20 step:94475[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:20 step:94480[D loss: 1.000020] [G loss: 1.000089]\n",
      "epoch:20 step:94485[D loss: 0.999955] [G loss: 1.000084]\n",
      "epoch:20 step:94490[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:20 step:94495[D loss: 1.000019] [G loss: 0.999916]\n",
      "epoch:20 step:94500[D loss: 1.000054] [G loss: 0.999948]\n",
      "epoch:20 step:94505[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:20 step:94510[D loss: 1.000045] [G loss: 0.999959]\n",
      "epoch:20 step:94515[D loss: 1.000031] [G loss: 0.999972]\n",
      "epoch:20 step:94520[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:20 step:94525[D loss: 0.999987] [G loss: 0.999984]\n",
      "epoch:20 step:94530[D loss: 0.999945] [G loss: 1.000106]\n",
      "epoch:20 step:94535[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:20 step:94540[D loss: 0.999930] [G loss: 1.000160]\n",
      "epoch:20 step:94545[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:20 step:94550[D loss: 0.999980] [G loss: 1.000084]\n",
      "epoch:20 step:94555[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:20 step:94560[D loss: 0.999975] [G loss: 1.000025]\n",
      "epoch:20 step:94565[D loss: 0.999970] [G loss: 1.000027]\n",
      "epoch:20 step:94570[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:20 step:94575[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:20 step:94580[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:20 step:94585[D loss: 0.999981] [G loss: 1.000104]\n",
      "epoch:20 step:94590[D loss: 1.000031] [G loss: 1.000028]\n",
      "epoch:20 step:94595[D loss: 0.999960] [G loss: 1.000170]\n",
      "epoch:20 step:94600[D loss: 0.999946] [G loss: 1.000108]\n",
      "epoch:20 step:94605[D loss: 0.999959] [G loss: 1.000112]\n",
      "epoch:20 step:94610[D loss: 0.999971] [G loss: 1.000099]\n",
      "epoch:20 step:94615[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:20 step:94620[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:20 step:94625[D loss: 1.000041] [G loss: 0.999993]\n",
      "epoch:20 step:94630[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:20 step:94635[D loss: 0.999975] [G loss: 1.000064]\n",
      "epoch:20 step:94640[D loss: 0.999997] [G loss: 1.000110]\n",
      "epoch:20 step:94645[D loss: 0.999930] [G loss: 1.000098]\n",
      "epoch:20 step:94650[D loss: 0.999954] [G loss: 1.000109]\n",
      "epoch:20 step:94655[D loss: 0.999955] [G loss: 1.000075]\n",
      "epoch:20 step:94660[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:20 step:94665[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:20 step:94670[D loss: 1.000027] [G loss: 1.000009]\n",
      "epoch:20 step:94675[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:20 step:94680[D loss: 0.999931] [G loss: 1.000154]\n",
      "epoch:20 step:94685[D loss: 0.999998] [G loss: 1.000102]\n",
      "epoch:20 step:94690[D loss: 1.000058] [G loss: 1.000071]\n",
      "epoch:20 step:94695[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:20 step:94700[D loss: 1.000052] [G loss: 1.000112]\n",
      "epoch:20 step:94705[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:20 step:94710[D loss: 0.999997] [G loss: 1.000100]\n",
      "epoch:20 step:94715[D loss: 0.999964] [G loss: 1.000103]\n",
      "epoch:20 step:94720[D loss: 0.999986] [G loss: 1.000043]\n",
      "epoch:20 step:94725[D loss: 1.000012] [G loss: 1.000012]\n",
      "epoch:20 step:94730[D loss: 1.000015] [G loss: 0.999961]\n",
      "epoch:20 step:94735[D loss: 1.000023] [G loss: 0.999914]\n",
      "epoch:20 step:94740[D loss: 0.999885] [G loss: 1.000048]\n",
      "epoch:20 step:94745[D loss: 1.000084] [G loss: 1.000066]\n",
      "epoch:20 step:94750[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:20 step:94755[D loss: 0.999947] [G loss: 1.000142]\n",
      "epoch:20 step:94760[D loss: 0.999968] [G loss: 1.000111]\n",
      "epoch:20 step:94765[D loss: 0.999967] [G loss: 1.000131]\n",
      "epoch:20 step:94770[D loss: 1.000030] [G loss: 0.999991]\n",
      "epoch:20 step:94775[D loss: 0.999889] [G loss: 1.000297]\n",
      "epoch:20 step:94780[D loss: 1.000086] [G loss: 1.000014]\n",
      "epoch:20 step:94785[D loss: 1.000090] [G loss: 1.000076]\n",
      "epoch:20 step:94790[D loss: 0.999950] [G loss: 1.000131]\n",
      "epoch:20 step:94795[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:20 step:94800[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:20 step:94805[D loss: 1.000038] [G loss: 0.999966]\n",
      "epoch:20 step:94810[D loss: 1.000059] [G loss: 0.999971]\n",
      "epoch:20 step:94815[D loss: 1.000075] [G loss: 0.999948]\n",
      "epoch:20 step:94820[D loss: 1.000005] [G loss: 0.999946]\n",
      "epoch:20 step:94825[D loss: 1.000061] [G loss: 0.999992]\n",
      "epoch:20 step:94830[D loss: 1.000091] [G loss: 1.000024]\n",
      "epoch:20 step:94835[D loss: 1.000119] [G loss: 1.000009]\n",
      "epoch:20 step:94840[D loss: 0.999904] [G loss: 1.000205]\n",
      "epoch:20 step:94845[D loss: 0.999967] [G loss: 1.000034]\n",
      "epoch:20 step:94850[D loss: 0.999897] [G loss: 1.000288]\n",
      "epoch:20 step:94855[D loss: 0.999905] [G loss: 1.000230]\n",
      "epoch:20 step:94860[D loss: 0.999892] [G loss: 1.000168]\n",
      "epoch:20 step:94865[D loss: 0.999965] [G loss: 1.000159]\n",
      "epoch:20 step:94870[D loss: 0.999992] [G loss: 1.000129]\n",
      "epoch:20 step:94875[D loss: 0.999880] [G loss: 1.000215]\n",
      "epoch:20 step:94880[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:20 step:94885[D loss: 1.000022] [G loss: 1.000040]\n",
      "epoch:20 step:94890[D loss: 1.000023] [G loss: 1.000010]\n",
      "epoch:20 step:94895[D loss: 1.000027] [G loss: 0.999969]\n",
      "epoch:20 step:94900[D loss: 0.999998] [G loss: 0.999985]\n",
      "epoch:20 step:94905[D loss: 0.999958] [G loss: 1.000141]\n",
      "epoch:20 step:94910[D loss: 1.000020] [G loss: 0.999998]\n",
      "epoch:20 step:94915[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:20 step:94920[D loss: 1.000023] [G loss: 1.000054]\n",
      "epoch:20 step:94925[D loss: 0.999920] [G loss: 1.000130]\n",
      "epoch:20 step:94930[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:20 step:94935[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:20 step:94940[D loss: 0.999994] [G loss: 1.000100]\n",
      "epoch:20 step:94945[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:20 step:94950[D loss: 0.999954] [G loss: 1.000051]\n",
      "epoch:20 step:94955[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:20 step:94960[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:20 step:94965[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:20 step:94970[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:20 step:94975[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:20 step:94980[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:20 step:94985[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:20 step:94990[D loss: 0.999999] [G loss: 1.000082]\n",
      "epoch:20 step:94995[D loss: 0.999924] [G loss: 1.000101]\n",
      "epoch:20 step:95000[D loss: 0.999957] [G loss: 1.000140]\n",
      "epoch:20 step:95005[D loss: 0.999961] [G loss: 1.000044]\n",
      "epoch:20 step:95010[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:20 step:95015[D loss: 1.000035] [G loss: 1.000015]\n",
      "epoch:20 step:95020[D loss: 0.999980] [G loss: 1.000011]\n",
      "epoch:20 step:95025[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:20 step:95030[D loss: 0.999932] [G loss: 1.000157]\n",
      "epoch:20 step:95035[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:20 step:95040[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:20 step:95045[D loss: 0.999984] [G loss: 1.000012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:95050[D loss: 1.000016] [G loss: 1.000004]\n",
      "epoch:20 step:95055[D loss: 0.999949] [G loss: 1.000095]\n",
      "epoch:20 step:95060[D loss: 1.000015] [G loss: 1.000074]\n",
      "epoch:20 step:95065[D loss: 0.999948] [G loss: 1.000138]\n",
      "epoch:20 step:95070[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:20 step:95075[D loss: 1.000026] [G loss: 1.000027]\n",
      "epoch:20 step:95080[D loss: 0.999998] [G loss: 0.999987]\n",
      "epoch:20 step:95085[D loss: 0.999999] [G loss: 0.999989]\n",
      "epoch:20 step:95090[D loss: 0.999977] [G loss: 1.000132]\n",
      "epoch:20 step:95095[D loss: 0.999953] [G loss: 1.000130]\n",
      "epoch:20 step:95100[D loss: 0.999965] [G loss: 1.000104]\n",
      "epoch:20 step:95105[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:20 step:95110[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:20 step:95115[D loss: 0.999972] [G loss: 1.000055]\n",
      "epoch:20 step:95120[D loss: 1.000035] [G loss: 0.999988]\n",
      "epoch:20 step:95125[D loss: 0.999944] [G loss: 1.000140]\n",
      "epoch:20 step:95130[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:20 step:95135[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:20 step:95140[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:20 step:95145[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:20 step:95150[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:20 step:95155[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:20 step:95160[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:20 step:95165[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:20 step:95170[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:20 step:95175[D loss: 0.999990] [G loss: 1.000065]\n",
      "epoch:20 step:95180[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:20 step:95185[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:20 step:95190[D loss: 1.000015] [G loss: 1.000023]\n",
      "epoch:20 step:95195[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:20 step:95200[D loss: 1.000003] [G loss: 1.000029]\n",
      "epoch:20 step:95205[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:20 step:95210[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:20 step:95215[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:20 step:95220[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:20 step:95225[D loss: 1.000001] [G loss: 1.000049]\n",
      "epoch:20 step:95230[D loss: 1.000012] [G loss: 1.000081]\n",
      "epoch:20 step:95235[D loss: 0.999966] [G loss: 1.000054]\n",
      "epoch:20 step:95240[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:20 step:95245[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:20 step:95250[D loss: 1.000075] [G loss: 0.999886]\n",
      "epoch:20 step:95255[D loss: 1.000003] [G loss: 1.000089]\n",
      "epoch:20 step:95260[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:20 step:95265[D loss: 0.999963] [G loss: 1.000018]\n",
      "epoch:20 step:95270[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:20 step:95275[D loss: 0.999991] [G loss: 1.000003]\n",
      "epoch:20 step:95280[D loss: 0.999979] [G loss: 1.000165]\n",
      "epoch:20 step:95285[D loss: 0.999978] [G loss: 1.000026]\n",
      "epoch:20 step:95290[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:20 step:95295[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:20 step:95300[D loss: 0.999980] [G loss: 1.000004]\n",
      "epoch:20 step:95305[D loss: 1.000159] [G loss: 0.999808]\n",
      "epoch:20 step:95310[D loss: 1.000052] [G loss: 0.999961]\n",
      "epoch:20 step:95315[D loss: 1.000106] [G loss: 0.999847]\n",
      "epoch:20 step:95320[D loss: 0.999953] [G loss: 1.000058]\n",
      "epoch:20 step:95325[D loss: 0.999948] [G loss: 1.000061]\n",
      "epoch:20 step:95330[D loss: 1.000018] [G loss: 1.000026]\n",
      "epoch:20 step:95335[D loss: 1.000058] [G loss: 0.999970]\n",
      "epoch:20 step:95340[D loss: 0.999935] [G loss: 1.000003]\n",
      "epoch:20 step:95345[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:20 step:95350[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:20 step:95355[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:20 step:95360[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:20 step:95365[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:20 step:95370[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:20 step:95375[D loss: 0.999971] [G loss: 1.000052]\n",
      "epoch:20 step:95380[D loss: 1.000038] [G loss: 0.999967]\n",
      "epoch:20 step:95385[D loss: 1.000011] [G loss: 1.000034]\n",
      "epoch:20 step:95390[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:20 step:95395[D loss: 0.999971] [G loss: 1.000027]\n",
      "epoch:20 step:95400[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:20 step:95405[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:20 step:95410[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:20 step:95415[D loss: 0.999988] [G loss: 1.000007]\n",
      "epoch:20 step:95420[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:20 step:95425[D loss: 0.999934] [G loss: 1.000082]\n",
      "epoch:20 step:95430[D loss: 1.000122] [G loss: 0.999896]\n",
      "epoch:20 step:95435[D loss: 0.999908] [G loss: 1.000107]\n",
      "epoch:20 step:95440[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:20 step:95445[D loss: 0.999995] [G loss: 1.000119]\n",
      "epoch:20 step:95450[D loss: 0.999929] [G loss: 1.000117]\n",
      "epoch:20 step:95455[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:20 step:95460[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:20 step:95465[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:20 step:95470[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:20 step:95475[D loss: 0.999981] [G loss: 1.000017]\n",
      "epoch:20 step:95480[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:20 step:95485[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:20 step:95490[D loss: 1.000038] [G loss: 0.999994]\n",
      "epoch:20 step:95495[D loss: 0.999944] [G loss: 1.000110]\n",
      "epoch:20 step:95500[D loss: 1.000077] [G loss: 0.999944]\n",
      "epoch:20 step:95505[D loss: 0.999921] [G loss: 1.000147]\n",
      "epoch:20 step:95510[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:20 step:95515[D loss: 1.000012] [G loss: 1.000025]\n",
      "epoch:20 step:95520[D loss: 1.000003] [G loss: 1.000110]\n",
      "epoch:20 step:95525[D loss: 1.000015] [G loss: 0.999936]\n",
      "epoch:20 step:95530[D loss: 1.000017] [G loss: 1.000033]\n",
      "epoch:20 step:95535[D loss: 1.000055] [G loss: 1.000016]\n",
      "epoch:20 step:95540[D loss: 0.999910] [G loss: 1.000237]\n",
      "epoch:20 step:95545[D loss: 1.000012] [G loss: 1.000075]\n",
      "epoch:20 step:95550[D loss: 0.999946] [G loss: 1.000106]\n",
      "epoch:20 step:95555[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:20 step:95560[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:20 step:95565[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:20 step:95570[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:20 step:95575[D loss: 1.000021] [G loss: 1.000011]\n",
      "epoch:20 step:95580[D loss: 1.000032] [G loss: 0.999981]\n",
      "epoch:20 step:95585[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:20 step:95590[D loss: 1.000096] [G loss: 0.999973]\n",
      "epoch:20 step:95595[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:20 step:95600[D loss: 1.000015] [G loss: 0.999926]\n",
      "epoch:20 step:95605[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:20 step:95610[D loss: 0.999951] [G loss: 1.000093]\n",
      "epoch:20 step:95615[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:20 step:95620[D loss: 0.999953] [G loss: 1.000046]\n",
      "epoch:20 step:95625[D loss: 1.000133] [G loss: 0.999959]\n",
      "epoch:20 step:95630[D loss: 0.999900] [G loss: 1.000098]\n",
      "epoch:20 step:95635[D loss: 1.000049] [G loss: 1.000057]\n",
      "epoch:20 step:95640[D loss: 0.999867] [G loss: 1.000246]\n",
      "epoch:20 step:95645[D loss: 0.999934] [G loss: 1.000080]\n",
      "epoch:20 step:95650[D loss: 1.000019] [G loss: 1.000073]\n",
      "epoch:20 step:95655[D loss: 0.999941] [G loss: 1.000051]\n",
      "epoch:20 step:95660[D loss: 0.999973] [G loss: 1.000107]\n",
      "epoch:20 step:95665[D loss: 0.999952] [G loss: 1.000066]\n",
      "epoch:20 step:95670[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:20 step:95675[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:20 step:95680[D loss: 0.999995] [G loss: 1.000040]\n",
      "epoch:20 step:95685[D loss: 1.000004] [G loss: 1.000026]\n",
      "epoch:20 step:95690[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:20 step:95695[D loss: 1.000062] [G loss: 0.999894]\n",
      "epoch:20 step:95700[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:20 step:95705[D loss: 1.000001] [G loss: 1.000158]\n",
      "epoch:20 step:95710[D loss: 0.999965] [G loss: 1.000125]\n",
      "epoch:20 step:95715[D loss: 0.999977] [G loss: 1.000131]\n",
      "epoch:20 step:95720[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:20 step:95725[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:20 step:95730[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:20 step:95735[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:20 step:95740[D loss: 0.999945] [G loss: 1.000030]\n",
      "epoch:20 step:95745[D loss: 1.000015] [G loss: 0.999989]\n",
      "epoch:20 step:95750[D loss: 1.000136] [G loss: 0.999950]\n",
      "epoch:20 step:95755[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:20 step:95760[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:20 step:95765[D loss: 0.999988] [G loss: 1.000027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:95770[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:20 step:95775[D loss: 0.999996] [G loss: 1.000084]\n",
      "epoch:20 step:95780[D loss: 0.999940] [G loss: 1.000130]\n",
      "epoch:20 step:95785[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:20 step:95790[D loss: 0.999956] [G loss: 1.000103]\n",
      "epoch:20 step:95795[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:20 step:95800[D loss: 0.999958] [G loss: 1.000072]\n",
      "epoch:20 step:95805[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:20 step:95810[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:20 step:95815[D loss: 0.999974] [G loss: 1.000032]\n",
      "epoch:20 step:95820[D loss: 0.999950] [G loss: 1.000110]\n",
      "epoch:20 step:95825[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:20 step:95830[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:20 step:95835[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:20 step:95840[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:20 step:95845[D loss: 0.999939] [G loss: 1.000152]\n",
      "epoch:20 step:95850[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:20 step:95855[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:20 step:95860[D loss: 1.000016] [G loss: 1.000020]\n",
      "epoch:20 step:95865[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:20 step:95870[D loss: 0.999973] [G loss: 1.000133]\n",
      "epoch:20 step:95875[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:20 step:95880[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:20 step:95885[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:20 step:95890[D loss: 1.000000] [G loss: 1.000046]\n",
      "epoch:20 step:95895[D loss: 0.999954] [G loss: 1.000053]\n",
      "epoch:20 step:95900[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:20 step:95905[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:20 step:95910[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:20 step:95915[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:20 step:95920[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:20 step:95925[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:20 step:95930[D loss: 0.999956] [G loss: 1.000140]\n",
      "epoch:20 step:95935[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:20 step:95940[D loss: 0.999992] [G loss: 1.000105]\n",
      "epoch:20 step:95945[D loss: 0.999962] [G loss: 1.000092]\n",
      "epoch:20 step:95950[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:20 step:95955[D loss: 1.000007] [G loss: 1.000032]\n",
      "epoch:20 step:95960[D loss: 0.999971] [G loss: 1.000021]\n",
      "epoch:20 step:95965[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:20 step:95970[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:20 step:95975[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:20 step:95980[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:20 step:95985[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:20 step:95990[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:20 step:95995[D loss: 1.000045] [G loss: 1.000094]\n",
      "epoch:20 step:96000[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:20 step:96005[D loss: 0.999923] [G loss: 1.000097]\n",
      "epoch:20 step:96010[D loss: 1.000013] [G loss: 0.999992]\n",
      "epoch:20 step:96015[D loss: 1.000027] [G loss: 0.999954]\n",
      "epoch:20 step:96020[D loss: 0.999980] [G loss: 1.000090]\n",
      "epoch:20 step:96025[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:20 step:96030[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:20 step:96035[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:20 step:96040[D loss: 0.999981] [G loss: 1.000092]\n",
      "epoch:20 step:96045[D loss: 0.999959] [G loss: 1.000120]\n",
      "epoch:20 step:96050[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:20 step:96055[D loss: 0.999965] [G loss: 1.000100]\n",
      "epoch:20 step:96060[D loss: 1.000006] [G loss: 1.000053]\n",
      "epoch:20 step:96065[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:20 step:96070[D loss: 1.000021] [G loss: 1.000052]\n",
      "epoch:20 step:96075[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:20 step:96080[D loss: 0.999951] [G loss: 1.000065]\n",
      "epoch:20 step:96085[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:20 step:96090[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:20 step:96095[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:20 step:96100[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:20 step:96105[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:20 step:96110[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:20 step:96115[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:20 step:96120[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:20 step:96125[D loss: 1.000052] [G loss: 1.000038]\n",
      "epoch:20 step:96130[D loss: 0.999931] [G loss: 1.000107]\n",
      "epoch:20 step:96135[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:20 step:96140[D loss: 0.999991] [G loss: 1.000090]\n",
      "epoch:20 step:96145[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:20 step:96150[D loss: 0.999976] [G loss: 1.000112]\n",
      "epoch:20 step:96155[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:20 step:96160[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:20 step:96165[D loss: 1.000014] [G loss: 1.000073]\n",
      "epoch:20 step:96170[D loss: 0.999987] [G loss: 1.000093]\n",
      "epoch:20 step:96175[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:20 step:96180[D loss: 1.000004] [G loss: 1.000158]\n",
      "epoch:20 step:96185[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:20 step:96190[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:20 step:96195[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:20 step:96200[D loss: 1.000018] [G loss: 1.000050]\n",
      "epoch:20 step:96205[D loss: 0.999960] [G loss: 1.000043]\n",
      "epoch:20 step:96210[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:20 step:96215[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:20 step:96220[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:20 step:96225[D loss: 1.000011] [G loss: 1.000019]\n",
      "epoch:20 step:96230[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:20 step:96235[D loss: 1.000003] [G loss: 1.000077]\n",
      "epoch:20 step:96240[D loss: 0.999991] [G loss: 1.000057]\n",
      "epoch:20 step:96245[D loss: 0.999924] [G loss: 1.000130]\n",
      "epoch:20 step:96250[D loss: 1.000047] [G loss: 1.000141]\n",
      "epoch:20 step:96255[D loss: 0.999944] [G loss: 1.000121]\n",
      "epoch:20 step:96260[D loss: 0.999981] [G loss: 1.000015]\n",
      "epoch:20 step:96265[D loss: 1.000030] [G loss: 0.999992]\n",
      "epoch:20 step:96270[D loss: 1.000059] [G loss: 0.999951]\n",
      "epoch:20 step:96275[D loss: 1.000005] [G loss: 0.999934]\n",
      "epoch:20 step:96280[D loss: 0.999972] [G loss: 1.000028]\n",
      "epoch:20 step:96285[D loss: 1.000021] [G loss: 1.000152]\n",
      "epoch:20 step:96290[D loss: 0.999995] [G loss: 0.999991]\n",
      "epoch:20 step:96295[D loss: 0.999940] [G loss: 1.000124]\n",
      "epoch:20 step:96300[D loss: 0.999921] [G loss: 1.000185]\n",
      "epoch:20 step:96305[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:20 step:96310[D loss: 0.999999] [G loss: 1.000060]\n",
      "epoch:20 step:96315[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:20 step:96320[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:20 step:96325[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:20 step:96330[D loss: 1.000027] [G loss: 0.999991]\n",
      "epoch:20 step:96335[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:20 step:96340[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:20 step:96345[D loss: 1.000010] [G loss: 1.000047]\n",
      "epoch:20 step:96350[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:20 step:96355[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:20 step:96360[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:20 step:96365[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:20 step:96370[D loss: 0.999986] [G loss: 1.000105]\n",
      "epoch:20 step:96375[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:20 step:96380[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:20 step:96385[D loss: 1.000011] [G loss: 1.000068]\n",
      "epoch:20 step:96390[D loss: 0.999911] [G loss: 1.000192]\n",
      "epoch:20 step:96395[D loss: 0.999944] [G loss: 1.000134]\n",
      "epoch:20 step:96400[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:20 step:96405[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:20 step:96410[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:20 step:96415[D loss: 1.000014] [G loss: 1.000059]\n",
      "epoch:20 step:96420[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:20 step:96425[D loss: 1.000019] [G loss: 1.000017]\n",
      "epoch:20 step:96430[D loss: 0.999936] [G loss: 1.000143]\n",
      "epoch:20 step:96435[D loss: 0.999955] [G loss: 1.000043]\n",
      "epoch:20 step:96440[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:20 step:96445[D loss: 1.000043] [G loss: 1.000014]\n",
      "epoch:20 step:96450[D loss: 0.999980] [G loss: 1.000112]\n",
      "epoch:20 step:96455[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:20 step:96460[D loss: 0.999959] [G loss: 1.000046]\n",
      "epoch:20 step:96465[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:20 step:96470[D loss: 0.999920] [G loss: 1.000067]\n",
      "epoch:20 step:96475[D loss: 0.999996] [G loss: 0.999992]\n",
      "epoch:20 step:96480[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:20 step:96485[D loss: 0.999953] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:96490[D loss: 0.999981] [G loss: 1.000123]\n",
      "epoch:20 step:96495[D loss: 1.000017] [G loss: 1.000019]\n",
      "epoch:20 step:96500[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:20 step:96505[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:20 step:96510[D loss: 0.999948] [G loss: 1.000109]\n",
      "epoch:20 step:96515[D loss: 0.999981] [G loss: 1.000125]\n",
      "epoch:20 step:96520[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:20 step:96525[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:20 step:96530[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:20 step:96535[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:20 step:96540[D loss: 1.000040] [G loss: 0.999961]\n",
      "epoch:20 step:96545[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:20 step:96550[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:20 step:96555[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:20 step:96560[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:20 step:96565[D loss: 1.000037] [G loss: 1.000023]\n",
      "epoch:20 step:96570[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:20 step:96575[D loss: 1.000060] [G loss: 0.999983]\n",
      "epoch:20 step:96580[D loss: 0.999933] [G loss: 1.000110]\n",
      "epoch:20 step:96585[D loss: 0.999915] [G loss: 1.000105]\n",
      "epoch:20 step:96590[D loss: 1.000032] [G loss: 1.000040]\n",
      "epoch:20 step:96595[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:20 step:96600[D loss: 0.999970] [G loss: 1.000178]\n",
      "epoch:20 step:96605[D loss: 0.999918] [G loss: 1.000108]\n",
      "epoch:20 step:96610[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:20 step:96615[D loss: 0.999994] [G loss: 0.999981]\n",
      "epoch:20 step:96620[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:20 step:96625[D loss: 1.000016] [G loss: 0.999985]\n",
      "epoch:20 step:96630[D loss: 1.000008] [G loss: 0.999970]\n",
      "epoch:20 step:96635[D loss: 1.000051] [G loss: 0.999919]\n",
      "epoch:20 step:96640[D loss: 1.000134] [G loss: 1.000000]\n",
      "epoch:20 step:96645[D loss: 1.000028] [G loss: 1.000082]\n",
      "epoch:20 step:96650[D loss: 0.999945] [G loss: 1.000085]\n",
      "epoch:20 step:96655[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:20 step:96660[D loss: 0.999996] [G loss: 1.000039]\n",
      "epoch:20 step:96665[D loss: 1.000082] [G loss: 0.999916]\n",
      "epoch:20 step:96670[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:20 step:96675[D loss: 1.000063] [G loss: 0.999986]\n",
      "epoch:20 step:96680[D loss: 0.999908] [G loss: 1.000133]\n",
      "epoch:20 step:96685[D loss: 0.999943] [G loss: 1.000110]\n",
      "epoch:20 step:96690[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:20 step:96695[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:20 step:96700[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:20 step:96705[D loss: 1.000016] [G loss: 0.999949]\n",
      "epoch:20 step:96710[D loss: 1.000040] [G loss: 0.999958]\n",
      "epoch:20 step:96715[D loss: 0.999964] [G loss: 1.000034]\n",
      "epoch:20 step:96720[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:20 step:96725[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:20 step:96730[D loss: 1.000047] [G loss: 0.999928]\n",
      "epoch:20 step:96735[D loss: 1.000052] [G loss: 0.999952]\n",
      "epoch:20 step:96740[D loss: 0.999959] [G loss: 1.000109]\n",
      "epoch:20 step:96745[D loss: 1.000062] [G loss: 1.000035]\n",
      "epoch:20 step:96750[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:20 step:96755[D loss: 1.000029] [G loss: 1.000039]\n",
      "epoch:20 step:96760[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:20 step:96765[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:20 step:96770[D loss: 0.999986] [G loss: 1.000001]\n",
      "epoch:20 step:96775[D loss: 1.000008] [G loss: 1.000002]\n",
      "epoch:20 step:96780[D loss: 0.999959] [G loss: 1.000017]\n",
      "epoch:20 step:96785[D loss: 0.999987] [G loss: 1.000097]\n",
      "epoch:20 step:96790[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:20 step:96795[D loss: 0.999971] [G loss: 1.000030]\n",
      "epoch:20 step:96800[D loss: 1.000024] [G loss: 1.000012]\n",
      "epoch:20 step:96805[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:20 step:96810[D loss: 1.000025] [G loss: 1.000056]\n",
      "epoch:20 step:96815[D loss: 0.999914] [G loss: 1.000139]\n",
      "epoch:20 step:96820[D loss: 0.999943] [G loss: 1.000117]\n",
      "epoch:20 step:96825[D loss: 1.000001] [G loss: 1.000111]\n",
      "epoch:20 step:96830[D loss: 0.999955] [G loss: 1.000100]\n",
      "epoch:20 step:96835[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:20 step:96840[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:20 step:96845[D loss: 1.000010] [G loss: 1.000030]\n",
      "epoch:20 step:96850[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:20 step:96855[D loss: 0.999943] [G loss: 1.000092]\n",
      "epoch:20 step:96860[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:20 step:96865[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:20 step:96870[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:20 step:96875[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:20 step:96880[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:20 step:96885[D loss: 1.000014] [G loss: 1.000005]\n",
      "epoch:20 step:96890[D loss: 0.999952] [G loss: 1.000010]\n",
      "epoch:20 step:96895[D loss: 0.999921] [G loss: 1.000118]\n",
      "epoch:20 step:96900[D loss: 0.999977] [G loss: 1.000136]\n",
      "epoch:20 step:96905[D loss: 1.000024] [G loss: 1.000027]\n",
      "epoch:20 step:96910[D loss: 0.999974] [G loss: 1.000082]\n",
      "epoch:20 step:96915[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:20 step:96920[D loss: 1.000056] [G loss: 0.999836]\n",
      "epoch:20 step:96925[D loss: 1.000013] [G loss: 0.999991]\n",
      "epoch:20 step:96930[D loss: 1.000043] [G loss: 0.999925]\n",
      "epoch:20 step:96935[D loss: 0.999941] [G loss: 0.999986]\n",
      "epoch:20 step:96940[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:20 step:96945[D loss: 0.999969] [G loss: 1.000183]\n",
      "epoch:20 step:96950[D loss: 0.999849] [G loss: 1.000270]\n",
      "epoch:20 step:96955[D loss: 0.999976] [G loss: 1.000178]\n",
      "epoch:20 step:96960[D loss: 1.000011] [G loss: 0.999997]\n",
      "epoch:20 step:96965[D loss: 0.999952] [G loss: 1.000139]\n",
      "epoch:20 step:96970[D loss: 0.999946] [G loss: 1.000105]\n",
      "epoch:20 step:96975[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:20 step:96980[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:20 step:96985[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:20 step:96990[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:20 step:96995[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:20 step:97000[D loss: 1.000009] [G loss: 1.000017]\n",
      "epoch:20 step:97005[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:20 step:97010[D loss: 0.999991] [G loss: 1.000055]\n",
      "epoch:20 step:97015[D loss: 0.999987] [G loss: 1.000054]\n",
      "epoch:20 step:97020[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:20 step:97025[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:20 step:97030[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:20 step:97035[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:20 step:97040[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:20 step:97045[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:20 step:97050[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:20 step:97055[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:20 step:97060[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:20 step:97065[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:20 step:97070[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:20 step:97075[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:20 step:97080[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:20 step:97085[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:20 step:97090[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:20 step:97095[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:20 step:97100[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:20 step:97105[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:20 step:97110[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:20 step:97115[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:20 step:97120[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:20 step:97125[D loss: 0.999964] [G loss: 1.000119]\n",
      "epoch:20 step:97130[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:20 step:97135[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:20 step:97140[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:20 step:97145[D loss: 1.000032] [G loss: 1.000029]\n",
      "epoch:20 step:97150[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:20 step:97155[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:20 step:97160[D loss: 1.000023] [G loss: 0.999973]\n",
      "epoch:20 step:97165[D loss: 0.999945] [G loss: 1.000062]\n",
      "epoch:20 step:97170[D loss: 0.999992] [G loss: 1.000000]\n",
      "epoch:20 step:97175[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:20 step:97180[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:20 step:97185[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:20 step:97190[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:20 step:97195[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:20 step:97200[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:20 step:97205[D loss: 0.999973] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:97210[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:20 step:97215[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:20 step:97220[D loss: 0.999951] [G loss: 1.000086]\n",
      "epoch:20 step:97225[D loss: 1.000002] [G loss: 1.000029]\n",
      "epoch:20 step:97230[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:20 step:97235[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:20 step:97240[D loss: 0.999996] [G loss: 1.000006]\n",
      "epoch:20 step:97245[D loss: 1.000089] [G loss: 0.999935]\n",
      "epoch:20 step:97250[D loss: 1.000092] [G loss: 0.999952]\n",
      "epoch:20 step:97255[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:20 step:97260[D loss: 0.999878] [G loss: 1.000176]\n",
      "epoch:20 step:97265[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:20 step:97270[D loss: 1.000024] [G loss: 1.000166]\n",
      "epoch:20 step:97275[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:20 step:97280[D loss: 1.000024] [G loss: 1.000008]\n",
      "epoch:20 step:97285[D loss: 1.000004] [G loss: 0.999980]\n",
      "epoch:20 step:97290[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:20 step:97295[D loss: 1.000017] [G loss: 0.999968]\n",
      "epoch:20 step:97300[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:20 step:97305[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:20 step:97310[D loss: 1.000027] [G loss: 1.000071]\n",
      "epoch:20 step:97315[D loss: 1.000001] [G loss: 1.000102]\n",
      "epoch:20 step:97320[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:20 step:97325[D loss: 0.999954] [G loss: 1.000076]\n",
      "epoch:20 step:97330[D loss: 1.000019] [G loss: 0.999994]\n",
      "epoch:20 step:97335[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:20 step:97340[D loss: 1.000056] [G loss: 1.000029]\n",
      "epoch:20 step:97345[D loss: 0.999951] [G loss: 1.000017]\n",
      "epoch:20 step:97350[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:20 step:97355[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:20 step:97360[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:20 step:97365[D loss: 0.999948] [G loss: 1.000089]\n",
      "epoch:20 step:97370[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:20 step:97375[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:20 step:97380[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:20 step:97385[D loss: 1.000055] [G loss: 1.000033]\n",
      "epoch:20 step:97390[D loss: 0.999925] [G loss: 1.000137]\n",
      "epoch:20 step:97395[D loss: 1.000001] [G loss: 1.000107]\n",
      "epoch:20 step:97400[D loss: 1.000020] [G loss: 1.000020]\n",
      "epoch:20 step:97405[D loss: 0.999949] [G loss: 1.000055]\n",
      "epoch:20 step:97410[D loss: 1.000034] [G loss: 1.000063]\n",
      "epoch:20 step:97415[D loss: 0.999941] [G loss: 1.000031]\n",
      "epoch:20 step:97420[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:20 step:97425[D loss: 0.999911] [G loss: 1.000113]\n",
      "epoch:20 step:97430[D loss: 0.999976] [G loss: 1.000035]\n",
      "epoch:20 step:97435[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:20 step:97440[D loss: 1.000013] [G loss: 1.000029]\n",
      "epoch:20 step:97445[D loss: 0.999998] [G loss: 1.000034]\n",
      "epoch:20 step:97450[D loss: 1.000020] [G loss: 1.000038]\n",
      "epoch:20 step:97455[D loss: 0.999951] [G loss: 1.000055]\n",
      "epoch:20 step:97460[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:20 step:97465[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:20 step:97470[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:20 step:97475[D loss: 1.000026] [G loss: 0.999983]\n",
      "epoch:20 step:97480[D loss: 0.999957] [G loss: 1.000059]\n",
      "epoch:20 step:97485[D loss: 1.000006] [G loss: 1.000019]\n",
      "epoch:20 step:97490[D loss: 0.999996] [G loss: 1.000066]\n",
      "epoch:20 step:97495[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:20 step:97500[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:20 step:97505[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:20 step:97510[D loss: 1.000005] [G loss: 1.000117]\n",
      "epoch:20 step:97515[D loss: 0.999973] [G loss: 1.000038]\n",
      "epoch:20 step:97520[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:20 step:97525[D loss: 0.999953] [G loss: 1.000059]\n",
      "epoch:20 step:97530[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:20 step:97535[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:20 step:97540[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:20 step:97545[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:20 step:97550[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:20 step:97555[D loss: 0.999995] [G loss: 1.000012]\n",
      "epoch:20 step:97560[D loss: 1.000045] [G loss: 0.999931]\n",
      "epoch:20 step:97565[D loss: 0.999978] [G loss: 1.000109]\n",
      "epoch:20 step:97570[D loss: 1.000015] [G loss: 1.000071]\n",
      "epoch:20 step:97575[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:20 step:97580[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:20 step:97585[D loss: 1.000015] [G loss: 0.999973]\n",
      "epoch:20 step:97590[D loss: 1.000018] [G loss: 1.000002]\n",
      "epoch:20 step:97595[D loss: 0.999982] [G loss: 1.000115]\n",
      "epoch:20 step:97600[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:20 step:97605[D loss: 1.000042] [G loss: 0.999903]\n",
      "epoch:20 step:97610[D loss: 0.999943] [G loss: 1.000070]\n",
      "epoch:20 step:97615[D loss: 0.999962] [G loss: 1.000031]\n",
      "epoch:20 step:97620[D loss: 0.999959] [G loss: 1.000055]\n",
      "epoch:20 step:97625[D loss: 0.999957] [G loss: 1.000068]\n",
      "epoch:20 step:97630[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:20 step:97635[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:20 step:97640[D loss: 0.999999] [G loss: 1.000018]\n",
      "epoch:20 step:97645[D loss: 1.000157] [G loss: 0.999788]\n",
      "epoch:20 step:97650[D loss: 0.999956] [G loss: 1.000052]\n",
      "epoch:20 step:97655[D loss: 0.999949] [G loss: 1.000052]\n",
      "epoch:20 step:97660[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:20 step:97665[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:20 step:97670[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:20 step:97675[D loss: 0.999988] [G loss: 1.000068]\n",
      "epoch:20 step:97680[D loss: 1.000008] [G loss: 0.999974]\n",
      "epoch:20 step:97685[D loss: 1.000025] [G loss: 0.999991]\n",
      "epoch:20 step:97690[D loss: 1.000100] [G loss: 0.999959]\n",
      "epoch:20 step:97695[D loss: 0.999951] [G loss: 1.000063]\n",
      "epoch:20 step:97700[D loss: 0.999939] [G loss: 1.000055]\n",
      "epoch:20 step:97705[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:20 step:97710[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:20 step:97715[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:20 step:97720[D loss: 1.000055] [G loss: 0.999924]\n",
      "epoch:20 step:97725[D loss: 1.000073] [G loss: 0.999917]\n",
      "epoch:20 step:97730[D loss: 0.999938] [G loss: 1.000080]\n",
      "epoch:20 step:97735[D loss: 1.000025] [G loss: 1.000038]\n",
      "epoch:20 step:97740[D loss: 1.000065] [G loss: 0.999999]\n",
      "epoch:20 step:97745[D loss: 0.999935] [G loss: 1.000077]\n",
      "epoch:20 step:97750[D loss: 1.000006] [G loss: 1.000081]\n",
      "epoch:20 step:97755[D loss: 0.999957] [G loss: 1.000157]\n",
      "epoch:20 step:97760[D loss: 0.999962] [G loss: 1.000122]\n",
      "epoch:20 step:97765[D loss: 0.999933] [G loss: 1.000090]\n",
      "epoch:20 step:97770[D loss: 1.000003] [G loss: 0.999971]\n",
      "epoch:20 step:97775[D loss: 0.999986] [G loss: 0.999981]\n",
      "epoch:20 step:97780[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:20 step:97785[D loss: 1.000010] [G loss: 0.999950]\n",
      "epoch:20 step:97790[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:20 step:97795[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:20 step:97800[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:20 step:97805[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:20 step:97810[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:20 step:97815[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:20 step:97820[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:20 step:97825[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:20 step:97830[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:20 step:97835[D loss: 0.999945] [G loss: 1.000091]\n",
      "epoch:20 step:97840[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:20 step:97845[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:20 step:97850[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:20 step:97855[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:20 step:97860[D loss: 1.000085] [G loss: 0.999922]\n",
      "epoch:20 step:97865[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:20 step:97870[D loss: 0.999976] [G loss: 1.000100]\n",
      "epoch:20 step:97875[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:20 step:97880[D loss: 1.000006] [G loss: 1.000021]\n",
      "epoch:20 step:97885[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:20 step:97890[D loss: 1.000032] [G loss: 1.000023]\n",
      "epoch:20 step:97895[D loss: 1.000021] [G loss: 1.000007]\n",
      "epoch:20 step:97900[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:20 step:97905[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:20 step:97910[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:20 step:97915[D loss: 0.999953] [G loss: 1.000118]\n",
      "epoch:20 step:97920[D loss: 1.000020] [G loss: 1.000076]\n",
      "epoch:20 step:97925[D loss: 0.999935] [G loss: 1.000113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:97930[D loss: 0.999937] [G loss: 1.000097]\n",
      "epoch:20 step:97935[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:20 step:97940[D loss: 1.000005] [G loss: 0.999968]\n",
      "epoch:20 step:97945[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:20 step:97950[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:20 step:97955[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:20 step:97960[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:20 step:97965[D loss: 1.000020] [G loss: 1.000014]\n",
      "epoch:20 step:97970[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:20 step:97975[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:20 step:97980[D loss: 1.000022] [G loss: 1.000071]\n",
      "epoch:20 step:97985[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:20 step:97990[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:20 step:97995[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:20 step:98000[D loss: 1.000011] [G loss: 1.000076]\n",
      "epoch:20 step:98005[D loss: 0.999973] [G loss: 1.000057]\n",
      "epoch:20 step:98010[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:20 step:98015[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:20 step:98020[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:20 step:98025[D loss: 0.999960] [G loss: 1.000116]\n",
      "epoch:20 step:98030[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:20 step:98035[D loss: 1.000007] [G loss: 1.000086]\n",
      "epoch:20 step:98040[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:20 step:98045[D loss: 0.999967] [G loss: 1.000155]\n",
      "epoch:20 step:98050[D loss: 1.000016] [G loss: 1.000077]\n",
      "epoch:20 step:98055[D loss: 0.999943] [G loss: 1.000081]\n",
      "epoch:20 step:98060[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:20 step:98065[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:20 step:98070[D loss: 1.000009] [G loss: 0.999960]\n",
      "epoch:20 step:98075[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:20 step:98080[D loss: 0.999914] [G loss: 1.000174]\n",
      "epoch:20 step:98085[D loss: 0.999895] [G loss: 1.000100]\n",
      "epoch:20 step:98090[D loss: 0.999950] [G loss: 1.000064]\n",
      "epoch:20 step:98095[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:20 step:98100[D loss: 0.999985] [G loss: 1.000122]\n",
      "epoch:20 step:98105[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:20 step:98110[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:20 step:98115[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:20 step:98120[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:20 step:98125[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:20 step:98130[D loss: 0.999994] [G loss: 1.000089]\n",
      "epoch:20 step:98135[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:20 step:98140[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:20 step:98145[D loss: 1.000004] [G loss: 1.000103]\n",
      "epoch:20 step:98150[D loss: 0.999952] [G loss: 1.000112]\n",
      "epoch:20 step:98155[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:20 step:98160[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:20 step:98165[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:20 step:98170[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:20 step:98175[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:20 step:98180[D loss: 1.000092] [G loss: 0.999957]\n",
      "epoch:20 step:98185[D loss: 0.999913] [G loss: 1.000099]\n",
      "epoch:20 step:98190[D loss: 0.999978] [G loss: 0.999998]\n",
      "epoch:20 step:98195[D loss: 0.999983] [G loss: 1.000029]\n",
      "epoch:20 step:98200[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:20 step:98205[D loss: 1.000087] [G loss: 0.999928]\n",
      "epoch:20 step:98210[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:20 step:98215[D loss: 1.000002] [G loss: 1.000021]\n",
      "epoch:20 step:98220[D loss: 1.000004] [G loss: 1.000069]\n",
      "epoch:20 step:98225[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:20 step:98230[D loss: 1.000052] [G loss: 0.999972]\n",
      "epoch:20 step:98235[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:20 step:98240[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:20 step:98245[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:20 step:98250[D loss: 0.999957] [G loss: 1.000039]\n",
      "epoch:20 step:98255[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:20 step:98260[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:20 step:98265[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:20 step:98270[D loss: 0.999983] [G loss: 1.000095]\n",
      "epoch:20 step:98275[D loss: 1.000038] [G loss: 0.999964]\n",
      "epoch:20 step:98280[D loss: 0.999929] [G loss: 1.000073]\n",
      "epoch:20 step:98285[D loss: 0.999985] [G loss: 1.000130]\n",
      "epoch:20 step:98290[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:20 step:98295[D loss: 1.000026] [G loss: 0.999988]\n",
      "epoch:20 step:98300[D loss: 0.999946] [G loss: 1.000083]\n",
      "epoch:20 step:98305[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:20 step:98310[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:20 step:98315[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:20 step:98320[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:20 step:98325[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:20 step:98330[D loss: 0.999938] [G loss: 1.000123]\n",
      "epoch:20 step:98335[D loss: 1.000022] [G loss: 0.999955]\n",
      "epoch:20 step:98340[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:20 step:98345[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:20 step:98350[D loss: 0.999970] [G loss: 1.000026]\n",
      "epoch:20 step:98355[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:20 step:98360[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:20 step:98365[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:20 step:98370[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:20 step:98375[D loss: 1.000042] [G loss: 1.000011]\n",
      "epoch:20 step:98380[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:20 step:98385[D loss: 0.999994] [G loss: 1.000039]\n",
      "epoch:21 step:98390[D loss: 1.000074] [G loss: 0.999937]\n",
      "epoch:21 step:98395[D loss: 0.999996] [G loss: 0.999984]\n",
      "epoch:21 step:98400[D loss: 0.999917] [G loss: 1.000099]\n",
      "epoch:21 step:98405[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:21 step:98410[D loss: 1.000001] [G loss: 1.000075]\n",
      "epoch:21 step:98415[D loss: 0.999956] [G loss: 1.000074]\n",
      "epoch:21 step:98420[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:21 step:98425[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:21 step:98430[D loss: 1.000031] [G loss: 1.000002]\n",
      "epoch:21 step:98435[D loss: 1.000071] [G loss: 1.000008]\n",
      "epoch:21 step:98440[D loss: 1.000068] [G loss: 0.999902]\n",
      "epoch:21 step:98445[D loss: 0.999837] [G loss: 1.000207]\n",
      "epoch:21 step:98450[D loss: 0.999925] [G loss: 1.000099]\n",
      "epoch:21 step:98455[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:21 step:98460[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:21 step:98465[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:21 step:98470[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:21 step:98475[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:21 step:98480[D loss: 0.999967] [G loss: 1.000055]\n",
      "epoch:21 step:98485[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:21 step:98490[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:21 step:98495[D loss: 0.999989] [G loss: 1.000083]\n",
      "epoch:21 step:98500[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:21 step:98505[D loss: 0.999984] [G loss: 1.000093]\n",
      "epoch:21 step:98510[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:21 step:98515[D loss: 0.999986] [G loss: 1.000067]\n",
      "epoch:21 step:98520[D loss: 1.000004] [G loss: 1.000053]\n",
      "epoch:21 step:98525[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:21 step:98530[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:21 step:98535[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:21 step:98540[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:21 step:98545[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:21 step:98550[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:21 step:98555[D loss: 0.999965] [G loss: 1.000166]\n",
      "epoch:21 step:98560[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:21 step:98565[D loss: 1.000012] [G loss: 1.000046]\n",
      "epoch:21 step:98570[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:21 step:98575[D loss: 0.999947] [G loss: 1.000074]\n",
      "epoch:21 step:98580[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:21 step:98585[D loss: 1.000075] [G loss: 0.999919]\n",
      "epoch:21 step:98590[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:21 step:98595[D loss: 0.999991] [G loss: 0.999982]\n",
      "epoch:21 step:98600[D loss: 0.999933] [G loss: 1.000112]\n",
      "epoch:21 step:98605[D loss: 0.999986] [G loss: 0.999988]\n",
      "epoch:21 step:98610[D loss: 0.999945] [G loss: 1.000141]\n",
      "epoch:21 step:98615[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:21 step:98620[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:21 step:98625[D loss: 0.999963] [G loss: 1.000040]\n",
      "epoch:21 step:98630[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:21 step:98635[D loss: 1.000001] [G loss: 1.000086]\n",
      "epoch:21 step:98640[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:21 step:98645[D loss: 0.999971] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:98650[D loss: 1.000021] [G loss: 1.000036]\n",
      "epoch:21 step:98655[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:21 step:98660[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:21 step:98665[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:21 step:98670[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:21 step:98675[D loss: 0.999953] [G loss: 1.000104]\n",
      "epoch:21 step:98680[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:21 step:98685[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:21 step:98690[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:21 step:98695[D loss: 0.999995] [G loss: 1.000047]\n",
      "epoch:21 step:98700[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:21 step:98705[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:21 step:98710[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:21 step:98715[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:21 step:98720[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:21 step:98725[D loss: 0.999996] [G loss: 0.999986]\n",
      "epoch:21 step:98730[D loss: 1.000044] [G loss: 1.000059]\n",
      "epoch:21 step:98735[D loss: 1.000014] [G loss: 1.000051]\n",
      "epoch:21 step:98740[D loss: 0.999908] [G loss: 1.000207]\n",
      "epoch:21 step:98745[D loss: 0.999941] [G loss: 1.000200]\n",
      "epoch:21 step:98750[D loss: 0.999984] [G loss: 1.000037]\n",
      "epoch:21 step:98755[D loss: 0.999946] [G loss: 1.000031]\n",
      "epoch:21 step:98760[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:21 step:98765[D loss: 0.999986] [G loss: 1.000052]\n",
      "epoch:21 step:98770[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:21 step:98775[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:21 step:98780[D loss: 1.000004] [G loss: 1.000000]\n",
      "epoch:21 step:98785[D loss: 1.000003] [G loss: 1.000002]\n",
      "epoch:21 step:98790[D loss: 1.000042] [G loss: 1.000000]\n",
      "epoch:21 step:98795[D loss: 0.999989] [G loss: 0.999996]\n",
      "epoch:21 step:98800[D loss: 0.999921] [G loss: 1.000122]\n",
      "epoch:21 step:98805[D loss: 0.999971] [G loss: 1.000034]\n",
      "epoch:21 step:98810[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:21 step:98815[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:21 step:98820[D loss: 0.999994] [G loss: 1.000035]\n",
      "epoch:21 step:98825[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:21 step:98830[D loss: 1.000099] [G loss: 0.999906]\n",
      "epoch:21 step:98835[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:21 step:98840[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:21 step:98845[D loss: 0.999970] [G loss: 1.000013]\n",
      "epoch:21 step:98850[D loss: 0.999987] [G loss: 1.000051]\n",
      "epoch:21 step:98855[D loss: 1.000009] [G loss: 1.000011]\n",
      "epoch:21 step:98860[D loss: 0.999997] [G loss: 1.000099]\n",
      "epoch:21 step:98865[D loss: 1.000011] [G loss: 1.000047]\n",
      "epoch:21 step:98870[D loss: 1.000034] [G loss: 1.000042]\n",
      "epoch:21 step:98875[D loss: 1.000023] [G loss: 1.000103]\n",
      "epoch:21 step:98880[D loss: 0.999921] [G loss: 1.000155]\n",
      "epoch:21 step:98885[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:21 step:98890[D loss: 1.000007] [G loss: 1.000013]\n",
      "epoch:21 step:98895[D loss: 1.000006] [G loss: 0.999947]\n",
      "epoch:21 step:98900[D loss: 1.000059] [G loss: 0.999920]\n",
      "epoch:21 step:98905[D loss: 0.999965] [G loss: 1.000113]\n",
      "epoch:21 step:98910[D loss: 1.000065] [G loss: 0.999911]\n",
      "epoch:21 step:98915[D loss: 0.999915] [G loss: 1.000175]\n",
      "epoch:21 step:98920[D loss: 1.000039] [G loss: 1.000050]\n",
      "epoch:21 step:98925[D loss: 0.999982] [G loss: 1.000147]\n",
      "epoch:21 step:98930[D loss: 0.999873] [G loss: 1.000195]\n",
      "epoch:21 step:98935[D loss: 0.999999] [G loss: 1.000095]\n",
      "epoch:21 step:98940[D loss: 0.999941] [G loss: 1.000130]\n",
      "epoch:21 step:98945[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:21 step:98950[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:21 step:98955[D loss: 1.000009] [G loss: 1.000017]\n",
      "epoch:21 step:98960[D loss: 0.999992] [G loss: 1.000062]\n",
      "epoch:21 step:98965[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:21 step:98970[D loss: 1.000078] [G loss: 0.999998]\n",
      "epoch:21 step:98975[D loss: 1.000051] [G loss: 1.000077]\n",
      "epoch:21 step:98980[D loss: 1.000004] [G loss: 1.000185]\n",
      "epoch:21 step:98985[D loss: 0.999900] [G loss: 1.000149]\n",
      "epoch:21 step:98990[D loss: 0.999927] [G loss: 1.000126]\n",
      "epoch:21 step:98995[D loss: 0.999861] [G loss: 1.000256]\n",
      "epoch:21 step:99000[D loss: 0.999941] [G loss: 1.000231]\n",
      "epoch:21 step:99005[D loss: 1.000010] [G loss: 1.000068]\n",
      "epoch:21 step:99010[D loss: 0.999953] [G loss: 1.000049]\n",
      "epoch:21 step:99015[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:21 step:99020[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:21 step:99025[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:21 step:99030[D loss: 0.999970] [G loss: 1.000019]\n",
      "epoch:21 step:99035[D loss: 0.999934] [G loss: 1.000045]\n",
      "epoch:21 step:99040[D loss: 0.999981] [G loss: 1.000000]\n",
      "epoch:21 step:99045[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:21 step:99050[D loss: 1.000019] [G loss: 1.000044]\n",
      "epoch:21 step:99055[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:21 step:99060[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:21 step:99065[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:21 step:99070[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:21 step:99075[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:21 step:99080[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:21 step:99085[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:21 step:99090[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:21 step:99095[D loss: 1.000009] [G loss: 0.999988]\n",
      "epoch:21 step:99100[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:21 step:99105[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:21 step:99110[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:21 step:99115[D loss: 0.999995] [G loss: 1.000022]\n",
      "epoch:21 step:99120[D loss: 0.999989] [G loss: 1.000105]\n",
      "epoch:21 step:99125[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:21 step:99130[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:21 step:99135[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:21 step:99140[D loss: 0.999957] [G loss: 1.000063]\n",
      "epoch:21 step:99145[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:21 step:99150[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:21 step:99155[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:21 step:99160[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:21 step:99165[D loss: 0.999905] [G loss: 1.000197]\n",
      "epoch:21 step:99170[D loss: 0.999958] [G loss: 1.000055]\n",
      "epoch:21 step:99175[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:21 step:99180[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:21 step:99185[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:21 step:99190[D loss: 1.000007] [G loss: 1.000037]\n",
      "epoch:21 step:99195[D loss: 1.000041] [G loss: 0.999963]\n",
      "epoch:21 step:99200[D loss: 0.999964] [G loss: 1.000043]\n",
      "epoch:21 step:99205[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:21 step:99210[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:21 step:99215[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:21 step:99220[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:21 step:99225[D loss: 1.000032] [G loss: 1.000013]\n",
      "epoch:21 step:99230[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:21 step:99235[D loss: 0.999938] [G loss: 1.000139]\n",
      "epoch:21 step:99240[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:21 step:99245[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:21 step:99250[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:21 step:99255[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:21 step:99260[D loss: 1.000003] [G loss: 1.000015]\n",
      "epoch:21 step:99265[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:21 step:99270[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:21 step:99275[D loss: 0.999996] [G loss: 1.000093]\n",
      "epoch:21 step:99280[D loss: 1.000039] [G loss: 0.999953]\n",
      "epoch:21 step:99285[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:21 step:99290[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:21 step:99295[D loss: 0.999956] [G loss: 1.000121]\n",
      "epoch:21 step:99300[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:21 step:99305[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:21 step:99310[D loss: 1.000006] [G loss: 1.000018]\n",
      "epoch:21 step:99315[D loss: 0.999994] [G loss: 1.000045]\n",
      "epoch:21 step:99320[D loss: 0.999983] [G loss: 1.000107]\n",
      "epoch:21 step:99325[D loss: 1.000024] [G loss: 1.000069]\n",
      "epoch:21 step:99330[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:21 step:99335[D loss: 0.999947] [G loss: 1.000109]\n",
      "epoch:21 step:99340[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:21 step:99345[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:21 step:99350[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:21 step:99355[D loss: 1.000010] [G loss: 1.000003]\n",
      "epoch:21 step:99360[D loss: 1.000028] [G loss: 0.999952]\n",
      "epoch:21 step:99365[D loss: 1.000125] [G loss: 0.999916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:99370[D loss: 1.000013] [G loss: 1.000035]\n",
      "epoch:21 step:99375[D loss: 0.999979] [G loss: 1.000184]\n",
      "epoch:21 step:99380[D loss: 0.999982] [G loss: 1.000143]\n",
      "epoch:21 step:99385[D loss: 1.000014] [G loss: 1.000247]\n",
      "epoch:21 step:99390[D loss: 0.999905] [G loss: 1.000208]\n",
      "epoch:21 step:99395[D loss: 0.999929] [G loss: 1.000122]\n",
      "epoch:21 step:99400[D loss: 0.999937] [G loss: 1.000123]\n",
      "epoch:21 step:99405[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:21 step:99410[D loss: 1.000001] [G loss: 0.999964]\n",
      "epoch:21 step:99415[D loss: 1.000055] [G loss: 0.999895]\n",
      "epoch:21 step:99420[D loss: 1.000094] [G loss: 0.999859]\n",
      "epoch:21 step:99425[D loss: 0.999942] [G loss: 0.999942]\n",
      "epoch:21 step:99430[D loss: 1.000021] [G loss: 1.000037]\n",
      "epoch:21 step:99435[D loss: 0.999990] [G loss: 1.000061]\n",
      "epoch:21 step:99440[D loss: 0.999944] [G loss: 1.000109]\n",
      "epoch:21 step:99445[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:21 step:99450[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:21 step:99455[D loss: 0.999984] [G loss: 1.000100]\n",
      "epoch:21 step:99460[D loss: 0.999985] [G loss: 1.000029]\n",
      "epoch:21 step:99465[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:21 step:99470[D loss: 1.000055] [G loss: 1.000099]\n",
      "epoch:21 step:99475[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:21 step:99480[D loss: 0.999975] [G loss: 1.000003]\n",
      "epoch:21 step:99485[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:21 step:99490[D loss: 0.999946] [G loss: 1.000092]\n",
      "epoch:21 step:99495[D loss: 0.999995] [G loss: 1.000080]\n",
      "epoch:21 step:99500[D loss: 1.000018] [G loss: 1.000038]\n",
      "epoch:21 step:99505[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:21 step:99510[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:21 step:99515[D loss: 1.000037] [G loss: 1.000033]\n",
      "epoch:21 step:99520[D loss: 1.000062] [G loss: 0.999993]\n",
      "epoch:21 step:99525[D loss: 0.999955] [G loss: 1.000037]\n",
      "epoch:21 step:99530[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:21 step:99535[D loss: 1.000002] [G loss: 1.000003]\n",
      "epoch:21 step:99540[D loss: 0.999964] [G loss: 1.000027]\n",
      "epoch:21 step:99545[D loss: 0.999971] [G loss: 1.000037]\n",
      "epoch:21 step:99550[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:21 step:99555[D loss: 0.999934] [G loss: 1.000133]\n",
      "epoch:21 step:99560[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:21 step:99565[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:21 step:99570[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:21 step:99575[D loss: 0.999979] [G loss: 0.999987]\n",
      "epoch:21 step:99580[D loss: 0.999960] [G loss: 1.000046]\n",
      "epoch:21 step:99585[D loss: 1.000025] [G loss: 0.999972]\n",
      "epoch:21 step:99590[D loss: 1.000029] [G loss: 1.000016]\n",
      "epoch:21 step:99595[D loss: 1.000020] [G loss: 0.999986]\n",
      "epoch:21 step:99600[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:21 step:99605[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:21 step:99610[D loss: 0.999949] [G loss: 1.000062]\n",
      "epoch:21 step:99615[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:21 step:99620[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:21 step:99625[D loss: 1.000018] [G loss: 1.000045]\n",
      "epoch:21 step:99630[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:21 step:99635[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:21 step:99640[D loss: 0.999986] [G loss: 1.000094]\n",
      "epoch:21 step:99645[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:21 step:99650[D loss: 0.999983] [G loss: 1.000100]\n",
      "epoch:21 step:99655[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:21 step:99660[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:21 step:99665[D loss: 0.999983] [G loss: 1.000028]\n",
      "epoch:21 step:99670[D loss: 0.999944] [G loss: 1.000076]\n",
      "epoch:21 step:99675[D loss: 1.000041] [G loss: 1.000025]\n",
      "epoch:21 step:99680[D loss: 0.999884] [G loss: 1.000155]\n",
      "epoch:21 step:99685[D loss: 1.000015] [G loss: 1.000029]\n",
      "epoch:21 step:99690[D loss: 0.999953] [G loss: 1.000090]\n",
      "epoch:21 step:99695[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:21 step:99700[D loss: 1.000055] [G loss: 0.999965]\n",
      "epoch:21 step:99705[D loss: 0.999947] [G loss: 1.000071]\n",
      "epoch:21 step:99710[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:21 step:99715[D loss: 1.000018] [G loss: 1.000044]\n",
      "epoch:21 step:99720[D loss: 0.999991] [G loss: 1.000018]\n",
      "epoch:21 step:99725[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:21 step:99730[D loss: 0.999988] [G loss: 1.000009]\n",
      "epoch:21 step:99735[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:21 step:99740[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:21 step:99745[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:21 step:99750[D loss: 0.999966] [G loss: 1.000055]\n",
      "epoch:21 step:99755[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:21 step:99760[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:21 step:99765[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:21 step:99770[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:21 step:99775[D loss: 0.999978] [G loss: 1.000115]\n",
      "epoch:21 step:99780[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:21 step:99785[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:21 step:99790[D loss: 1.000047] [G loss: 0.999957]\n",
      "epoch:21 step:99795[D loss: 1.000024] [G loss: 1.000016]\n",
      "epoch:21 step:99800[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:21 step:99805[D loss: 0.999954] [G loss: 1.000159]\n",
      "epoch:21 step:99810[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:21 step:99815[D loss: 0.999958] [G loss: 1.000062]\n",
      "epoch:21 step:99820[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:21 step:99825[D loss: 1.000027] [G loss: 0.999996]\n",
      "epoch:21 step:99830[D loss: 1.000044] [G loss: 0.999881]\n",
      "epoch:21 step:99835[D loss: 0.999965] [G loss: 1.000036]\n",
      "epoch:21 step:99840[D loss: 0.999959] [G loss: 1.000099]\n",
      "epoch:21 step:99845[D loss: 0.999962] [G loss: 1.000095]\n",
      "epoch:21 step:99850[D loss: 0.999988] [G loss: 1.000014]\n",
      "epoch:21 step:99855[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:21 step:99860[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:21 step:99865[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:21 step:99870[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:21 step:99875[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:21 step:99880[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:21 step:99885[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:21 step:99890[D loss: 0.999982] [G loss: 1.000022]\n",
      "epoch:21 step:99895[D loss: 0.999997] [G loss: 1.000003]\n",
      "epoch:21 step:99900[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:21 step:99905[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:21 step:99910[D loss: 1.000072] [G loss: 0.999884]\n",
      "epoch:21 step:99915[D loss: 0.999950] [G loss: 1.000147]\n",
      "epoch:21 step:99920[D loss: 0.999969] [G loss: 1.000013]\n",
      "epoch:21 step:99925[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:21 step:99930[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:21 step:99935[D loss: 1.000021] [G loss: 0.999978]\n",
      "epoch:21 step:99940[D loss: 1.000055] [G loss: 0.999948]\n",
      "epoch:21 step:99945[D loss: 0.999911] [G loss: 1.000142]\n",
      "epoch:21 step:99950[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:21 step:99955[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:21 step:99960[D loss: 0.999967] [G loss: 1.000112]\n",
      "epoch:21 step:99965[D loss: 1.000062] [G loss: 1.000012]\n",
      "epoch:21 step:99970[D loss: 0.999971] [G loss: 0.999999]\n",
      "epoch:21 step:99975[D loss: 1.000025] [G loss: 0.999922]\n",
      "epoch:21 step:99980[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:21 step:99985[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:21 step:99990[D loss: 1.000055] [G loss: 1.000048]\n",
      "epoch:21 step:99995[D loss: 1.000089] [G loss: 0.999965]\n",
      "epoch:21 step:100000[D loss: 1.000013] [G loss: 1.000061]\n",
      "epoch:21 step:100005[D loss: 0.999924] [G loss: 1.000094]\n",
      "epoch:21 step:100010[D loss: 0.999954] [G loss: 1.000032]\n",
      "epoch:21 step:100015[D loss: 0.999985] [G loss: 1.000022]\n",
      "epoch:21 step:100020[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:21 step:100025[D loss: 0.999920] [G loss: 1.000043]\n",
      "epoch:21 step:100030[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:21 step:100035[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:21 step:100040[D loss: 0.999947] [G loss: 1.000061]\n",
      "epoch:21 step:100045[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:21 step:100050[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:21 step:100055[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:21 step:100060[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:21 step:100065[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:21 step:100070[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:21 step:100075[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:21 step:100080[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:21 step:100085[D loss: 0.999960] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:100090[D loss: 0.999951] [G loss: 1.000099]\n",
      "epoch:21 step:100095[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:21 step:100100[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:21 step:100105[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:21 step:100110[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:21 step:100115[D loss: 1.000081] [G loss: 0.999997]\n",
      "epoch:21 step:100120[D loss: 0.999938] [G loss: 1.000081]\n",
      "epoch:21 step:100125[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:21 step:100130[D loss: 0.999985] [G loss: 1.000093]\n",
      "epoch:21 step:100135[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:21 step:100140[D loss: 1.000061] [G loss: 0.999978]\n",
      "epoch:21 step:100145[D loss: 0.999960] [G loss: 1.000137]\n",
      "epoch:21 step:100150[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:21 step:100155[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:21 step:100160[D loss: 0.999973] [G loss: 1.000066]\n",
      "epoch:21 step:100165[D loss: 1.000031] [G loss: 0.999926]\n",
      "epoch:21 step:100170[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:21 step:100175[D loss: 1.000058] [G loss: 1.000050]\n",
      "epoch:21 step:100180[D loss: 1.000035] [G loss: 0.999893]\n",
      "epoch:21 step:100185[D loss: 1.000073] [G loss: 1.000079]\n",
      "epoch:21 step:100190[D loss: 0.999926] [G loss: 1.000194]\n",
      "epoch:21 step:100195[D loss: 0.999936] [G loss: 1.000115]\n",
      "epoch:21 step:100200[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:21 step:100205[D loss: 1.000026] [G loss: 1.000054]\n",
      "epoch:21 step:100210[D loss: 1.000003] [G loss: 0.999985]\n",
      "epoch:21 step:100215[D loss: 0.999955] [G loss: 1.000132]\n",
      "epoch:21 step:100220[D loss: 0.999917] [G loss: 1.000231]\n",
      "epoch:21 step:100225[D loss: 1.000089] [G loss: 0.999843]\n",
      "epoch:21 step:100230[D loss: 0.999923] [G loss: 1.000130]\n",
      "epoch:21 step:100235[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:21 step:100240[D loss: 0.999994] [G loss: 1.000108]\n",
      "epoch:21 step:100245[D loss: 0.999937] [G loss: 1.000122]\n",
      "epoch:21 step:100250[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:21 step:100255[D loss: 0.999971] [G loss: 1.000135]\n",
      "epoch:21 step:100260[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:21 step:100265[D loss: 1.000010] [G loss: 1.000012]\n",
      "epoch:21 step:100270[D loss: 0.999969] [G loss: 1.000097]\n",
      "epoch:21 step:100275[D loss: 1.000127] [G loss: 0.999953]\n",
      "epoch:21 step:100280[D loss: 1.000053] [G loss: 0.999915]\n",
      "epoch:21 step:100285[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:21 step:100290[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:21 step:100295[D loss: 0.999903] [G loss: 1.000160]\n",
      "epoch:21 step:100300[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:21 step:100305[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:21 step:100310[D loss: 0.999985] [G loss: 1.000112]\n",
      "epoch:21 step:100315[D loss: 0.999949] [G loss: 1.000043]\n",
      "epoch:21 step:100320[D loss: 1.000007] [G loss: 1.000069]\n",
      "epoch:21 step:100325[D loss: 1.000029] [G loss: 0.999940]\n",
      "epoch:21 step:100330[D loss: 0.999927] [G loss: 1.000074]\n",
      "epoch:21 step:100335[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:21 step:100340[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:21 step:100345[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:21 step:100350[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:21 step:100355[D loss: 0.999992] [G loss: 1.000086]\n",
      "epoch:21 step:100360[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:21 step:100365[D loss: 1.000004] [G loss: 1.000044]\n",
      "epoch:21 step:100370[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:21 step:100375[D loss: 0.999982] [G loss: 1.000025]\n",
      "epoch:21 step:100380[D loss: 0.999991] [G loss: 0.999999]\n",
      "epoch:21 step:100385[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:21 step:100390[D loss: 1.000016] [G loss: 1.000028]\n",
      "epoch:21 step:100395[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:21 step:100400[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:21 step:100405[D loss: 0.999943] [G loss: 1.000087]\n",
      "epoch:21 step:100410[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:21 step:100415[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:21 step:100420[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:21 step:100425[D loss: 0.999965] [G loss: 1.000018]\n",
      "epoch:21 step:100430[D loss: 0.999956] [G loss: 1.000108]\n",
      "epoch:21 step:100435[D loss: 1.000012] [G loss: 1.000133]\n",
      "epoch:21 step:100440[D loss: 0.999939] [G loss: 1.000097]\n",
      "epoch:21 step:100445[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:21 step:100450[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:21 step:100455[D loss: 1.000022] [G loss: 0.999966]\n",
      "epoch:21 step:100460[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:21 step:100465[D loss: 0.999953] [G loss: 1.000056]\n",
      "epoch:21 step:100470[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:21 step:100475[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:21 step:100480[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:21 step:100485[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:21 step:100490[D loss: 1.000002] [G loss: 1.000095]\n",
      "epoch:21 step:100495[D loss: 0.999998] [G loss: 1.000103]\n",
      "epoch:21 step:100500[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:21 step:100505[D loss: 0.999986] [G loss: 1.000094]\n",
      "epoch:21 step:100510[D loss: 0.999949] [G loss: 1.000093]\n",
      "epoch:21 step:100515[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:21 step:100520[D loss: 0.999987] [G loss: 1.000079]\n",
      "epoch:21 step:100525[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:21 step:100530[D loss: 1.000004] [G loss: 1.000000]\n",
      "epoch:21 step:100535[D loss: 0.999932] [G loss: 1.000118]\n",
      "epoch:21 step:100540[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:21 step:100545[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:21 step:100550[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:21 step:100555[D loss: 1.000002] [G loss: 1.000015]\n",
      "epoch:21 step:100560[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:21 step:100565[D loss: 0.999991] [G loss: 1.000026]\n",
      "epoch:21 step:100570[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:21 step:100575[D loss: 0.999947] [G loss: 1.000101]\n",
      "epoch:21 step:100580[D loss: 1.000059] [G loss: 1.000001]\n",
      "epoch:21 step:100585[D loss: 0.999983] [G loss: 1.000016]\n",
      "epoch:21 step:100590[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:21 step:100595[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:21 step:100600[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:21 step:100605[D loss: 1.000018] [G loss: 0.999961]\n",
      "epoch:21 step:100610[D loss: 0.999960] [G loss: 1.000050]\n",
      "epoch:21 step:100615[D loss: 1.000044] [G loss: 1.000039]\n",
      "epoch:21 step:100620[D loss: 1.000085] [G loss: 1.000064]\n",
      "epoch:21 step:100625[D loss: 1.000036] [G loss: 1.000020]\n",
      "epoch:21 step:100630[D loss: 1.000044] [G loss: 1.000021]\n",
      "epoch:21 step:100635[D loss: 1.000020] [G loss: 1.000037]\n",
      "epoch:21 step:100640[D loss: 0.999918] [G loss: 1.000069]\n",
      "epoch:21 step:100645[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:21 step:100650[D loss: 0.999951] [G loss: 1.000050]\n",
      "epoch:21 step:100655[D loss: 1.000021] [G loss: 1.000002]\n",
      "epoch:21 step:100660[D loss: 0.999988] [G loss: 0.999979]\n",
      "epoch:21 step:100665[D loss: 0.999999] [G loss: 0.999924]\n",
      "epoch:21 step:100670[D loss: 0.999999] [G loss: 1.000091]\n",
      "epoch:21 step:100675[D loss: 1.000015] [G loss: 1.000178]\n",
      "epoch:21 step:100680[D loss: 1.000095] [G loss: 1.000208]\n",
      "epoch:21 step:100685[D loss: 0.999938] [G loss: 1.000096]\n",
      "epoch:21 step:100690[D loss: 0.999931] [G loss: 1.000142]\n",
      "epoch:21 step:100695[D loss: 0.999957] [G loss: 1.000103]\n",
      "epoch:21 step:100700[D loss: 0.999971] [G loss: 1.000043]\n",
      "epoch:21 step:100705[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:21 step:100710[D loss: 0.999978] [G loss: 1.000108]\n",
      "epoch:21 step:100715[D loss: 0.999914] [G loss: 1.000136]\n",
      "epoch:21 step:100720[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:21 step:100725[D loss: 1.000107] [G loss: 0.999928]\n",
      "epoch:21 step:100730[D loss: 1.000001] [G loss: 1.000074]\n",
      "epoch:21 step:100735[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:21 step:100740[D loss: 0.999995] [G loss: 1.000141]\n",
      "epoch:21 step:100745[D loss: 0.999908] [G loss: 1.000155]\n",
      "epoch:21 step:100750[D loss: 0.999940] [G loss: 1.000111]\n",
      "epoch:21 step:100755[D loss: 1.000011] [G loss: 1.000021]\n",
      "epoch:21 step:100760[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:21 step:100765[D loss: 1.000018] [G loss: 1.000007]\n",
      "epoch:21 step:100770[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:21 step:100775[D loss: 1.000026] [G loss: 1.000023]\n",
      "epoch:21 step:100780[D loss: 0.999960] [G loss: 1.000016]\n",
      "epoch:21 step:100785[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:21 step:100790[D loss: 0.999946] [G loss: 1.000038]\n",
      "epoch:21 step:100795[D loss: 0.999948] [G loss: 1.000093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:100800[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:21 step:100805[D loss: 0.999979] [G loss: 1.000031]\n",
      "epoch:21 step:100810[D loss: 1.000048] [G loss: 1.000024]\n",
      "epoch:21 step:100815[D loss: 0.999974] [G loss: 1.000003]\n",
      "epoch:21 step:100820[D loss: 0.999944] [G loss: 1.000096]\n",
      "epoch:21 step:100825[D loss: 0.999966] [G loss: 1.000177]\n",
      "epoch:21 step:100830[D loss: 0.999992] [G loss: 1.000078]\n",
      "epoch:21 step:100835[D loss: 0.999967] [G loss: 1.000111]\n",
      "epoch:21 step:100840[D loss: 0.999954] [G loss: 1.000102]\n",
      "epoch:21 step:100845[D loss: 1.000019] [G loss: 1.000010]\n",
      "epoch:21 step:100850[D loss: 1.000022] [G loss: 1.000097]\n",
      "epoch:21 step:100855[D loss: 0.999929] [G loss: 1.000198]\n",
      "epoch:21 step:100860[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:21 step:100865[D loss: 1.000093] [G loss: 1.000033]\n",
      "epoch:21 step:100870[D loss: 0.999973] [G loss: 1.000101]\n",
      "epoch:21 step:100875[D loss: 0.999996] [G loss: 0.999988]\n",
      "epoch:21 step:100880[D loss: 1.000098] [G loss: 0.999951]\n",
      "epoch:21 step:100885[D loss: 1.000215] [G loss: 0.999804]\n",
      "epoch:21 step:100890[D loss: 0.999992] [G loss: 0.999910]\n",
      "epoch:21 step:100895[D loss: 0.999926] [G loss: 1.000091]\n",
      "epoch:21 step:100900[D loss: 0.999867] [G loss: 1.000189]\n",
      "epoch:21 step:100905[D loss: 0.999968] [G loss: 1.000138]\n",
      "epoch:21 step:100910[D loss: 0.999932] [G loss: 1.000092]\n",
      "epoch:21 step:100915[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:21 step:100920[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:21 step:100925[D loss: 0.999998] [G loss: 1.000089]\n",
      "epoch:21 step:100930[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:21 step:100935[D loss: 1.000040] [G loss: 1.000188]\n",
      "epoch:21 step:100940[D loss: 0.999939] [G loss: 1.000167]\n",
      "epoch:21 step:100945[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:21 step:100950[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:21 step:100955[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:21 step:100960[D loss: 0.999940] [G loss: 1.000104]\n",
      "epoch:21 step:100965[D loss: 0.999984] [G loss: 1.000000]\n",
      "epoch:21 step:100970[D loss: 1.000023] [G loss: 1.000096]\n",
      "epoch:21 step:100975[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:21 step:100980[D loss: 0.999923] [G loss: 1.000171]\n",
      "epoch:21 step:100985[D loss: 1.000066] [G loss: 0.999882]\n",
      "epoch:21 step:100990[D loss: 0.999962] [G loss: 1.000124]\n",
      "epoch:21 step:100995[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:21 step:101000[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:21 step:101005[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:21 step:101010[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:21 step:101015[D loss: 1.000027] [G loss: 0.999962]\n",
      "epoch:21 step:101020[D loss: 0.999985] [G loss: 0.999962]\n",
      "epoch:21 step:101025[D loss: 0.999941] [G loss: 1.000083]\n",
      "epoch:21 step:101030[D loss: 0.999975] [G loss: 1.000009]\n",
      "epoch:21 step:101035[D loss: 0.999966] [G loss: 1.000041]\n",
      "epoch:21 step:101040[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:21 step:101045[D loss: 0.999943] [G loss: 1.000108]\n",
      "epoch:21 step:101050[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:21 step:101055[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:21 step:101060[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:21 step:101065[D loss: 1.000053] [G loss: 1.000038]\n",
      "epoch:21 step:101070[D loss: 1.000066] [G loss: 0.999954]\n",
      "epoch:21 step:101075[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:21 step:101080[D loss: 1.000095] [G loss: 0.999905]\n",
      "epoch:21 step:101085[D loss: 0.999954] [G loss: 1.000064]\n",
      "epoch:21 step:101090[D loss: 0.999926] [G loss: 1.000123]\n",
      "epoch:21 step:101095[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:21 step:101100[D loss: 1.000053] [G loss: 0.999989]\n",
      "epoch:21 step:101105[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:21 step:101110[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:21 step:101115[D loss: 1.000021] [G loss: 0.999998]\n",
      "epoch:21 step:101120[D loss: 0.999933] [G loss: 1.000071]\n",
      "epoch:21 step:101125[D loss: 0.999978] [G loss: 1.000109]\n",
      "epoch:21 step:101130[D loss: 0.999984] [G loss: 1.000071]\n",
      "epoch:21 step:101135[D loss: 1.000015] [G loss: 1.000057]\n",
      "epoch:21 step:101140[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:21 step:101145[D loss: 0.999968] [G loss: 1.000028]\n",
      "epoch:21 step:101150[D loss: 1.000053] [G loss: 0.999972]\n",
      "epoch:21 step:101155[D loss: 0.999890] [G loss: 1.000093]\n",
      "epoch:21 step:101160[D loss: 1.000028] [G loss: 0.999929]\n",
      "epoch:21 step:101165[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:21 step:101170[D loss: 0.999994] [G loss: 0.999999]\n",
      "epoch:21 step:101175[D loss: 1.000022] [G loss: 1.000067]\n",
      "epoch:21 step:101180[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:21 step:101185[D loss: 0.999946] [G loss: 1.000095]\n",
      "epoch:21 step:101190[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:21 step:101195[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:21 step:101200[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:21 step:101205[D loss: 0.999894] [G loss: 1.000151]\n",
      "epoch:21 step:101210[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:21 step:101215[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:21 step:101220[D loss: 0.999949] [G loss: 1.000079]\n",
      "epoch:21 step:101225[D loss: 1.000057] [G loss: 0.999984]\n",
      "epoch:21 step:101230[D loss: 0.999988] [G loss: 1.000088]\n",
      "epoch:21 step:101235[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:21 step:101240[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:21 step:101245[D loss: 0.999963] [G loss: 1.000114]\n",
      "epoch:21 step:101250[D loss: 1.000011] [G loss: 1.000065]\n",
      "epoch:21 step:101255[D loss: 1.000049] [G loss: 0.999867]\n",
      "epoch:21 step:101260[D loss: 1.000045] [G loss: 1.000091]\n",
      "epoch:21 step:101265[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:21 step:101270[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:21 step:101275[D loss: 1.000045] [G loss: 1.000079]\n",
      "epoch:21 step:101280[D loss: 1.000012] [G loss: 1.000060]\n",
      "epoch:21 step:101285[D loss: 1.000100] [G loss: 1.000041]\n",
      "epoch:21 step:101290[D loss: 0.999914] [G loss: 1.000080]\n",
      "epoch:21 step:101295[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:21 step:101300[D loss: 1.000011] [G loss: 1.000004]\n",
      "epoch:21 step:101305[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:21 step:101310[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:21 step:101315[D loss: 0.999977] [G loss: 1.000026]\n",
      "epoch:21 step:101320[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:21 step:101325[D loss: 1.000007] [G loss: 1.000077]\n",
      "epoch:21 step:101330[D loss: 1.000025] [G loss: 1.000134]\n",
      "epoch:21 step:101335[D loss: 0.999944] [G loss: 1.000061]\n",
      "epoch:21 step:101340[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:21 step:101345[D loss: 1.000056] [G loss: 0.999924]\n",
      "epoch:21 step:101350[D loss: 1.000063] [G loss: 0.999926]\n",
      "epoch:21 step:101355[D loss: 0.999932] [G loss: 1.000105]\n",
      "epoch:21 step:101360[D loss: 1.000216] [G loss: 0.999774]\n",
      "epoch:21 step:101365[D loss: 0.999837] [G loss: 1.000154]\n",
      "epoch:21 step:101370[D loss: 1.000006] [G loss: 1.000057]\n",
      "epoch:21 step:101375[D loss: 0.999981] [G loss: 1.000129]\n",
      "epoch:21 step:101380[D loss: 0.999939] [G loss: 1.000133]\n",
      "epoch:21 step:101385[D loss: 1.000031] [G loss: 1.000049]\n",
      "epoch:21 step:101390[D loss: 0.999967] [G loss: 1.000011]\n",
      "epoch:21 step:101395[D loss: 1.000057] [G loss: 0.999949]\n",
      "epoch:21 step:101400[D loss: 0.999962] [G loss: 1.000025]\n",
      "epoch:21 step:101405[D loss: 1.000026] [G loss: 0.999956]\n",
      "epoch:21 step:101410[D loss: 1.000011] [G loss: 0.999939]\n",
      "epoch:21 step:101415[D loss: 0.999947] [G loss: 1.000036]\n",
      "epoch:21 step:101420[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:21 step:101425[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:21 step:101430[D loss: 1.000084] [G loss: 0.999988]\n",
      "epoch:21 step:101435[D loss: 0.999931] [G loss: 1.000074]\n",
      "epoch:21 step:101440[D loss: 1.000011] [G loss: 1.000059]\n",
      "epoch:21 step:101445[D loss: 1.000008] [G loss: 1.000067]\n",
      "epoch:21 step:101450[D loss: 1.000010] [G loss: 1.000017]\n",
      "epoch:21 step:101455[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:21 step:101460[D loss: 0.999991] [G loss: 1.000051]\n",
      "epoch:21 step:101465[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:21 step:101470[D loss: 1.000008] [G loss: 1.000090]\n",
      "epoch:21 step:101475[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:21 step:101480[D loss: 0.999956] [G loss: 1.000117]\n",
      "epoch:21 step:101485[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:21 step:101490[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:21 step:101495[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:21 step:101500[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:21 step:101505[D loss: 0.999955] [G loss: 1.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:101510[D loss: 1.000005] [G loss: 1.000039]\n",
      "epoch:21 step:101515[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:21 step:101520[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:21 step:101525[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:21 step:101530[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:21 step:101535[D loss: 0.999985] [G loss: 1.000097]\n",
      "epoch:21 step:101540[D loss: 0.999934] [G loss: 1.000094]\n",
      "epoch:21 step:101545[D loss: 0.999944] [G loss: 1.000089]\n",
      "epoch:21 step:101550[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:21 step:101555[D loss: 0.999986] [G loss: 1.000040]\n",
      "epoch:21 step:101560[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:21 step:101565[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:21 step:101570[D loss: 1.000037] [G loss: 1.000029]\n",
      "epoch:21 step:101575[D loss: 0.999933] [G loss: 1.000047]\n",
      "epoch:21 step:101580[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:21 step:101585[D loss: 0.999952] [G loss: 1.000146]\n",
      "epoch:21 step:101590[D loss: 1.000002] [G loss: 1.000055]\n",
      "epoch:21 step:101595[D loss: 0.999949] [G loss: 1.000108]\n",
      "epoch:21 step:101600[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:21 step:101605[D loss: 1.000040] [G loss: 0.999988]\n",
      "epoch:21 step:101610[D loss: 0.999987] [G loss: 1.000092]\n",
      "epoch:21 step:101615[D loss: 1.000018] [G loss: 1.000084]\n",
      "epoch:21 step:101620[D loss: 0.999938] [G loss: 1.000084]\n",
      "epoch:21 step:101625[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:21 step:101630[D loss: 0.999938] [G loss: 1.000182]\n",
      "epoch:21 step:101635[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:21 step:101640[D loss: 1.000021] [G loss: 1.000051]\n",
      "epoch:21 step:101645[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:21 step:101650[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:21 step:101655[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:21 step:101660[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:21 step:101665[D loss: 1.000010] [G loss: 0.999979]\n",
      "epoch:21 step:101670[D loss: 1.000002] [G loss: 1.000022]\n",
      "epoch:21 step:101675[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:21 step:101680[D loss: 0.999997] [G loss: 1.000025]\n",
      "epoch:21 step:101685[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:21 step:101690[D loss: 1.000014] [G loss: 0.999999]\n",
      "epoch:21 step:101695[D loss: 1.000054] [G loss: 0.999957]\n",
      "epoch:21 step:101700[D loss: 0.999945] [G loss: 1.000135]\n",
      "epoch:21 step:101705[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:21 step:101710[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:21 step:101715[D loss: 0.999984] [G loss: 1.000027]\n",
      "epoch:21 step:101720[D loss: 0.999946] [G loss: 1.000061]\n",
      "epoch:21 step:101725[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:21 step:101730[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:21 step:101735[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:21 step:101740[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:21 step:101745[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:21 step:101750[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:21 step:101755[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:21 step:101760[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:21 step:101765[D loss: 0.999988] [G loss: 1.000023]\n",
      "epoch:21 step:101770[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:21 step:101775[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:21 step:101780[D loss: 0.999940] [G loss: 1.000102]\n",
      "epoch:21 step:101785[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:21 step:101790[D loss: 1.000008] [G loss: 1.000025]\n",
      "epoch:21 step:101795[D loss: 0.999984] [G loss: 1.000131]\n",
      "epoch:21 step:101800[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:21 step:101805[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:21 step:101810[D loss: 1.000015] [G loss: 1.000008]\n",
      "epoch:21 step:101815[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:21 step:101820[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:21 step:101825[D loss: 0.999997] [G loss: 1.000000]\n",
      "epoch:21 step:101830[D loss: 1.000065] [G loss: 1.000013]\n",
      "epoch:21 step:101835[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:21 step:101840[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:21 step:101845[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:21 step:101850[D loss: 1.000034] [G loss: 1.000048]\n",
      "epoch:21 step:101855[D loss: 0.999957] [G loss: 1.000157]\n",
      "epoch:21 step:101860[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:21 step:101865[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:21 step:101870[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:21 step:101875[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:21 step:101880[D loss: 0.999960] [G loss: 1.000118]\n",
      "epoch:21 step:101885[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:21 step:101890[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:21 step:101895[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:21 step:101900[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:21 step:101905[D loss: 0.999982] [G loss: 1.000064]\n",
      "epoch:21 step:101910[D loss: 1.000009] [G loss: 1.000023]\n",
      "epoch:21 step:101915[D loss: 0.999961] [G loss: 1.000092]\n",
      "epoch:21 step:101920[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:21 step:101925[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:21 step:101930[D loss: 1.000007] [G loss: 1.000075]\n",
      "epoch:21 step:101935[D loss: 1.000054] [G loss: 1.000031]\n",
      "epoch:21 step:101940[D loss: 0.999965] [G loss: 1.000064]\n",
      "epoch:21 step:101945[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:21 step:101950[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:21 step:101955[D loss: 1.000018] [G loss: 1.000088]\n",
      "epoch:21 step:101960[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:21 step:101965[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:21 step:101970[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:21 step:101975[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:21 step:101980[D loss: 1.000002] [G loss: 1.000023]\n",
      "epoch:21 step:101985[D loss: 0.999983] [G loss: 1.000092]\n",
      "epoch:21 step:101990[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:21 step:101995[D loss: 1.000050] [G loss: 1.000030]\n",
      "epoch:21 step:102000[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:21 step:102005[D loss: 0.999938] [G loss: 1.000078]\n",
      "epoch:21 step:102010[D loss: 0.999951] [G loss: 1.000090]\n",
      "epoch:21 step:102015[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:21 step:102020[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:21 step:102025[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:21 step:102030[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:21 step:102035[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:21 step:102040[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:21 step:102045[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:21 step:102050[D loss: 0.999962] [G loss: 1.000038]\n",
      "epoch:21 step:102055[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:21 step:102060[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:21 step:102065[D loss: 1.000006] [G loss: 1.000012]\n",
      "epoch:21 step:102070[D loss: 1.000021] [G loss: 1.000010]\n",
      "epoch:21 step:102075[D loss: 0.999946] [G loss: 1.000066]\n",
      "epoch:21 step:102080[D loss: 1.000040] [G loss: 0.999989]\n",
      "epoch:21 step:102085[D loss: 1.000014] [G loss: 1.000002]\n",
      "epoch:21 step:102090[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:21 step:102095[D loss: 1.000154] [G loss: 0.999911]\n",
      "epoch:21 step:102100[D loss: 0.999916] [G loss: 1.000063]\n",
      "epoch:21 step:102105[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:21 step:102110[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:21 step:102115[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:21 step:102120[D loss: 0.999953] [G loss: 1.000109]\n",
      "epoch:21 step:102125[D loss: 0.999997] [G loss: 1.000068]\n",
      "epoch:21 step:102130[D loss: 0.999991] [G loss: 0.999967]\n",
      "epoch:21 step:102135[D loss: 0.999983] [G loss: 1.000002]\n",
      "epoch:21 step:102140[D loss: 0.999967] [G loss: 1.000017]\n",
      "epoch:21 step:102145[D loss: 0.999959] [G loss: 1.000050]\n",
      "epoch:21 step:102150[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:21 step:102155[D loss: 1.000072] [G loss: 0.999926]\n",
      "epoch:21 step:102160[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:21 step:102165[D loss: 0.999944] [G loss: 1.000068]\n",
      "epoch:21 step:102170[D loss: 0.999947] [G loss: 1.000064]\n",
      "epoch:21 step:102175[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:21 step:102180[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:21 step:102185[D loss: 1.000017] [G loss: 0.999988]\n",
      "epoch:21 step:102190[D loss: 1.000025] [G loss: 0.999998]\n",
      "epoch:21 step:102195[D loss: 1.000004] [G loss: 1.000104]\n",
      "epoch:21 step:102200[D loss: 0.999901] [G loss: 1.000171]\n",
      "epoch:21 step:102205[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:21 step:102210[D loss: 1.000019] [G loss: 0.999984]\n",
      "epoch:21 step:102215[D loss: 0.999978] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:102220[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:21 step:102225[D loss: 0.999969] [G loss: 1.000044]\n",
      "epoch:21 step:102230[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:21 step:102235[D loss: 0.999941] [G loss: 1.000023]\n",
      "epoch:21 step:102240[D loss: 1.000039] [G loss: 0.999994]\n",
      "epoch:21 step:102245[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:21 step:102250[D loss: 1.000083] [G loss: 0.999911]\n",
      "epoch:21 step:102255[D loss: 1.000057] [G loss: 1.000050]\n",
      "epoch:21 step:102260[D loss: 0.999872] [G loss: 1.000168]\n",
      "epoch:21 step:102265[D loss: 1.000030] [G loss: 1.000020]\n",
      "epoch:21 step:102270[D loss: 0.999912] [G loss: 1.000090]\n",
      "epoch:21 step:102275[D loss: 0.999998] [G loss: 0.999972]\n",
      "epoch:21 step:102280[D loss: 1.000027] [G loss: 0.999989]\n",
      "epoch:21 step:102285[D loss: 1.000031] [G loss: 0.999950]\n",
      "epoch:21 step:102290[D loss: 0.999940] [G loss: 1.000007]\n",
      "epoch:21 step:102295[D loss: 0.999996] [G loss: 0.999988]\n",
      "epoch:21 step:102300[D loss: 1.000031] [G loss: 1.000034]\n",
      "epoch:21 step:102305[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:21 step:102310[D loss: 0.999992] [G loss: 1.000151]\n",
      "epoch:21 step:102315[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:21 step:102320[D loss: 0.999948] [G loss: 1.000116]\n",
      "epoch:21 step:102325[D loss: 1.000014] [G loss: 1.000055]\n",
      "epoch:21 step:102330[D loss: 0.999980] [G loss: 1.000156]\n",
      "epoch:21 step:102335[D loss: 0.999925] [G loss: 1.000053]\n",
      "epoch:21 step:102340[D loss: 0.999999] [G loss: 0.999989]\n",
      "epoch:21 step:102345[D loss: 0.999998] [G loss: 0.999954]\n",
      "epoch:21 step:102350[D loss: 0.999950] [G loss: 1.000067]\n",
      "epoch:21 step:102355[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:21 step:102360[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:21 step:102365[D loss: 1.000025] [G loss: 0.999986]\n",
      "epoch:21 step:102370[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:21 step:102375[D loss: 1.000029] [G loss: 1.000054]\n",
      "epoch:21 step:102380[D loss: 0.999944] [G loss: 1.000071]\n",
      "epoch:21 step:102385[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:21 step:102390[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:21 step:102395[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:21 step:102400[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:21 step:102405[D loss: 0.999928] [G loss: 1.000080]\n",
      "epoch:21 step:102410[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:21 step:102415[D loss: 0.999991] [G loss: 1.000070]\n",
      "epoch:21 step:102420[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:21 step:102425[D loss: 1.000054] [G loss: 1.000051]\n",
      "epoch:21 step:102430[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:21 step:102435[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:21 step:102440[D loss: 0.999993] [G loss: 1.000097]\n",
      "epoch:21 step:102445[D loss: 0.999943] [G loss: 1.000094]\n",
      "epoch:21 step:102450[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:21 step:102455[D loss: 0.999996] [G loss: 0.999987]\n",
      "epoch:21 step:102460[D loss: 0.999973] [G loss: 0.999993]\n",
      "epoch:21 step:102465[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:21 step:102470[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:21 step:102475[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:21 step:102480[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:21 step:102485[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:21 step:102490[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:21 step:102495[D loss: 1.000020] [G loss: 0.999992]\n",
      "epoch:21 step:102500[D loss: 0.999910] [G loss: 1.000128]\n",
      "epoch:21 step:102505[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:21 step:102510[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:21 step:102515[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:21 step:102520[D loss: 0.999947] [G loss: 1.000093]\n",
      "epoch:21 step:102525[D loss: 0.999957] [G loss: 1.000099]\n",
      "epoch:21 step:102530[D loss: 1.000008] [G loss: 0.999996]\n",
      "epoch:21 step:102535[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:21 step:102540[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:21 step:102545[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:21 step:102550[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:21 step:102555[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:21 step:102560[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:21 step:102565[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:21 step:102570[D loss: 0.999958] [G loss: 1.000073]\n",
      "epoch:21 step:102575[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:21 step:102580[D loss: 0.999988] [G loss: 1.000065]\n",
      "epoch:21 step:102585[D loss: 0.999942] [G loss: 1.000069]\n",
      "epoch:21 step:102590[D loss: 0.999985] [G loss: 1.000033]\n",
      "epoch:21 step:102595[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:21 step:102600[D loss: 0.999981] [G loss: 1.000019]\n",
      "epoch:21 step:102605[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:21 step:102610[D loss: 0.999911] [G loss: 1.000141]\n",
      "epoch:21 step:102615[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:21 step:102620[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:21 step:102625[D loss: 1.000001] [G loss: 1.000036]\n",
      "epoch:21 step:102630[D loss: 1.000033] [G loss: 1.000090]\n",
      "epoch:21 step:102635[D loss: 0.999939] [G loss: 1.000109]\n",
      "epoch:21 step:102640[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:21 step:102645[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:21 step:102650[D loss: 1.000061] [G loss: 0.999897]\n",
      "epoch:21 step:102655[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:21 step:102660[D loss: 1.000020] [G loss: 1.000037]\n",
      "epoch:21 step:102665[D loss: 0.999946] [G loss: 1.000141]\n",
      "epoch:21 step:102670[D loss: 0.999950] [G loss: 1.000043]\n",
      "epoch:21 step:102675[D loss: 0.999934] [G loss: 1.000140]\n",
      "epoch:21 step:102680[D loss: 1.000008] [G loss: 1.000064]\n",
      "epoch:21 step:102685[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:21 step:102690[D loss: 0.999966] [G loss: 1.000034]\n",
      "epoch:21 step:102695[D loss: 1.000013] [G loss: 0.999992]\n",
      "epoch:21 step:102700[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:21 step:102705[D loss: 1.000052] [G loss: 1.000084]\n",
      "epoch:21 step:102710[D loss: 0.999920] [G loss: 1.000133]\n",
      "epoch:21 step:102715[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:21 step:102720[D loss: 1.000042] [G loss: 0.999968]\n",
      "epoch:21 step:102725[D loss: 0.999956] [G loss: 1.000155]\n",
      "epoch:21 step:102730[D loss: 0.999986] [G loss: 1.000160]\n",
      "epoch:21 step:102735[D loss: 0.999969] [G loss: 1.000187]\n",
      "epoch:21 step:102740[D loss: 0.999925] [G loss: 1.000062]\n",
      "epoch:21 step:102745[D loss: 1.000030] [G loss: 1.000006]\n",
      "epoch:21 step:102750[D loss: 0.999983] [G loss: 0.999998]\n",
      "epoch:21 step:102755[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:21 step:102760[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:21 step:102765[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:21 step:102770[D loss: 0.999927] [G loss: 1.000042]\n",
      "epoch:21 step:102775[D loss: 1.000002] [G loss: 0.999999]\n",
      "epoch:21 step:102780[D loss: 0.999980] [G loss: 1.000027]\n",
      "epoch:21 step:102785[D loss: 0.999995] [G loss: 1.000013]\n",
      "epoch:21 step:102790[D loss: 0.999947] [G loss: 1.000059]\n",
      "epoch:21 step:102795[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:21 step:102800[D loss: 0.999951] [G loss: 1.000070]\n",
      "epoch:21 step:102805[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:21 step:102810[D loss: 1.000018] [G loss: 1.000085]\n",
      "epoch:21 step:102815[D loss: 1.000034] [G loss: 0.999960]\n",
      "epoch:21 step:102820[D loss: 0.999950] [G loss: 1.000096]\n",
      "epoch:21 step:102825[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:21 step:102830[D loss: 0.999962] [G loss: 1.000146]\n",
      "epoch:21 step:102835[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:21 step:102840[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:21 step:102845[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:21 step:102850[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:21 step:102855[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:21 step:102860[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:21 step:102865[D loss: 1.000007] [G loss: 1.000092]\n",
      "epoch:21 step:102870[D loss: 1.000041] [G loss: 0.999950]\n",
      "epoch:21 step:102875[D loss: 0.999946] [G loss: 1.000075]\n",
      "epoch:21 step:102880[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:21 step:102885[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:21 step:102890[D loss: 1.000055] [G loss: 0.999999]\n",
      "epoch:21 step:102895[D loss: 0.999938] [G loss: 1.000101]\n",
      "epoch:21 step:102900[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:21 step:102905[D loss: 1.000023] [G loss: 1.000053]\n",
      "epoch:21 step:102910[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:21 step:102915[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:21 step:102920[D loss: 0.999935] [G loss: 1.000068]\n",
      "epoch:21 step:102925[D loss: 1.000021] [G loss: 1.000036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:102930[D loss: 0.999982] [G loss: 1.000015]\n",
      "epoch:21 step:102935[D loss: 0.999892] [G loss: 1.000130]\n",
      "epoch:21 step:102940[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:21 step:102945[D loss: 1.000001] [G loss: 0.999960]\n",
      "epoch:21 step:102950[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:21 step:102955[D loss: 1.000021] [G loss: 1.000030]\n",
      "epoch:21 step:102960[D loss: 1.000016] [G loss: 1.000001]\n",
      "epoch:21 step:102965[D loss: 0.999971] [G loss: 1.000106]\n",
      "epoch:21 step:102970[D loss: 0.999985] [G loss: 1.000117]\n",
      "epoch:21 step:102975[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:21 step:102980[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:21 step:102985[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:21 step:102990[D loss: 1.000002] [G loss: 1.000032]\n",
      "epoch:21 step:102995[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:21 step:103000[D loss: 0.999959] [G loss: 1.000022]\n",
      "epoch:21 step:103005[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:21 step:103010[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:21 step:103015[D loss: 0.999930] [G loss: 1.000135]\n",
      "epoch:21 step:103020[D loss: 0.999997] [G loss: 1.000051]\n",
      "epoch:21 step:103025[D loss: 0.999978] [G loss: 1.000027]\n",
      "epoch:21 step:103030[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:21 step:103035[D loss: 0.999974] [G loss: 1.000049]\n",
      "epoch:21 step:103040[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:21 step:103045[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:21 step:103050[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:21 step:103055[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:21 step:103060[D loss: 1.000020] [G loss: 1.000068]\n",
      "epoch:21 step:103065[D loss: 1.000001] [G loss: 0.999988]\n",
      "epoch:21 step:103070[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:22 step:103075[D loss: 1.000019] [G loss: 0.999983]\n",
      "epoch:22 step:103080[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:22 step:103085[D loss: 0.999950] [G loss: 1.000083]\n",
      "epoch:22 step:103090[D loss: 1.000036] [G loss: 0.999985]\n",
      "epoch:22 step:103095[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:22 step:103100[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:22 step:103105[D loss: 0.999990] [G loss: 1.000018]\n",
      "epoch:22 step:103110[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:22 step:103115[D loss: 1.000003] [G loss: 1.000045]\n",
      "epoch:22 step:103120[D loss: 1.000050] [G loss: 1.000010]\n",
      "epoch:22 step:103125[D loss: 0.999995] [G loss: 1.000085]\n",
      "epoch:22 step:103130[D loss: 0.999908] [G loss: 1.000127]\n",
      "epoch:22 step:103135[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:22 step:103140[D loss: 0.999974] [G loss: 1.000036]\n",
      "epoch:22 step:103145[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:22 step:103150[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:22 step:103155[D loss: 0.999972] [G loss: 1.000086]\n",
      "epoch:22 step:103160[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:22 step:103165[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:22 step:103170[D loss: 0.999960] [G loss: 1.000062]\n",
      "epoch:22 step:103175[D loss: 1.000048] [G loss: 0.999981]\n",
      "epoch:22 step:103180[D loss: 1.000008] [G loss: 1.000135]\n",
      "epoch:22 step:103185[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:22 step:103190[D loss: 0.999961] [G loss: 1.000113]\n",
      "epoch:22 step:103195[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:22 step:103200[D loss: 0.999987] [G loss: 1.000096]\n",
      "epoch:22 step:103205[D loss: 1.000029] [G loss: 1.000051]\n",
      "epoch:22 step:103210[D loss: 0.999909] [G loss: 1.000132]\n",
      "epoch:22 step:103215[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:22 step:103220[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:22 step:103225[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:22 step:103230[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:22 step:103235[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:22 step:103240[D loss: 0.999942] [G loss: 1.000150]\n",
      "epoch:22 step:103245[D loss: 0.999929] [G loss: 1.000121]\n",
      "epoch:22 step:103250[D loss: 1.000027] [G loss: 1.000041]\n",
      "epoch:22 step:103255[D loss: 1.000054] [G loss: 0.999965]\n",
      "epoch:22 step:103260[D loss: 0.999952] [G loss: 1.000058]\n",
      "epoch:22 step:103265[D loss: 1.000000] [G loss: 1.000026]\n",
      "epoch:22 step:103270[D loss: 1.000070] [G loss: 0.999910]\n",
      "epoch:22 step:103275[D loss: 0.999934] [G loss: 1.000117]\n",
      "epoch:22 step:103280[D loss: 0.999889] [G loss: 1.000126]\n",
      "epoch:22 step:103285[D loss: 0.999989] [G loss: 1.000009]\n",
      "epoch:22 step:103290[D loss: 0.999858] [G loss: 1.000185]\n",
      "epoch:22 step:103295[D loss: 0.999938] [G loss: 1.000127]\n",
      "epoch:22 step:103300[D loss: 0.999924] [G loss: 1.000158]\n",
      "epoch:22 step:103305[D loss: 0.999954] [G loss: 1.000109]\n",
      "epoch:22 step:103310[D loss: 0.999954] [G loss: 1.000109]\n",
      "epoch:22 step:103315[D loss: 0.999948] [G loss: 1.000107]\n",
      "epoch:22 step:103320[D loss: 0.999967] [G loss: 1.000046]\n",
      "epoch:22 step:103325[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:22 step:103330[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:22 step:103335[D loss: 1.000097] [G loss: 0.999915]\n",
      "epoch:22 step:103340[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:22 step:103345[D loss: 1.000019] [G loss: 1.000039]\n",
      "epoch:22 step:103350[D loss: 0.999936] [G loss: 1.000145]\n",
      "epoch:22 step:103355[D loss: 1.000047] [G loss: 1.000037]\n",
      "epoch:22 step:103360[D loss: 0.999960] [G loss: 1.000122]\n",
      "epoch:22 step:103365[D loss: 0.999955] [G loss: 1.000120]\n",
      "epoch:22 step:103370[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:22 step:103375[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:22 step:103380[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:22 step:103385[D loss: 0.999998] [G loss: 1.000098]\n",
      "epoch:22 step:103390[D loss: 1.000016] [G loss: 1.000013]\n",
      "epoch:22 step:103395[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:22 step:103400[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:22 step:103405[D loss: 0.999992] [G loss: 0.999976]\n",
      "epoch:22 step:103410[D loss: 1.000014] [G loss: 0.999981]\n",
      "epoch:22 step:103415[D loss: 1.000230] [G loss: 0.999656]\n",
      "epoch:22 step:103420[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:22 step:103425[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:22 step:103430[D loss: 0.999966] [G loss: 1.000122]\n",
      "epoch:22 step:103435[D loss: 0.999914] [G loss: 1.000149]\n",
      "epoch:22 step:103440[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:22 step:103445[D loss: 1.000081] [G loss: 0.999923]\n",
      "epoch:22 step:103450[D loss: 0.999925] [G loss: 1.000094]\n",
      "epoch:22 step:103455[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:22 step:103460[D loss: 1.000017] [G loss: 1.000056]\n",
      "epoch:22 step:103465[D loss: 1.000003] [G loss: 1.000020]\n",
      "epoch:22 step:103470[D loss: 0.999942] [G loss: 1.000115]\n",
      "epoch:22 step:103475[D loss: 1.000009] [G loss: 1.000119]\n",
      "epoch:22 step:103480[D loss: 0.999990] [G loss: 0.999972]\n",
      "epoch:22 step:103485[D loss: 0.999925] [G loss: 1.000186]\n",
      "epoch:22 step:103490[D loss: 0.999941] [G loss: 1.000073]\n",
      "epoch:22 step:103495[D loss: 1.000050] [G loss: 0.999958]\n",
      "epoch:22 step:103500[D loss: 1.000045] [G loss: 0.999853]\n",
      "epoch:22 step:103505[D loss: 0.999962] [G loss: 1.000025]\n",
      "epoch:22 step:103510[D loss: 1.000105] [G loss: 0.999779]\n",
      "epoch:22 step:103515[D loss: 1.000006] [G loss: 1.000168]\n",
      "epoch:22 step:103520[D loss: 1.000031] [G loss: 0.999922]\n",
      "epoch:22 step:103525[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:22 step:103530[D loss: 0.999972] [G loss: 1.000010]\n",
      "epoch:22 step:103535[D loss: 0.999954] [G loss: 1.000064]\n",
      "epoch:22 step:103540[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:22 step:103545[D loss: 1.000009] [G loss: 1.000072]\n",
      "epoch:22 step:103550[D loss: 1.000047] [G loss: 0.999991]\n",
      "epoch:22 step:103555[D loss: 1.000090] [G loss: 0.999871]\n",
      "epoch:22 step:103560[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:22 step:103565[D loss: 0.999878] [G loss: 1.000213]\n",
      "epoch:22 step:103570[D loss: 0.999934] [G loss: 1.000098]\n",
      "epoch:22 step:103575[D loss: 0.999927] [G loss: 1.000114]\n",
      "epoch:22 step:103580[D loss: 1.000002] [G loss: 1.000128]\n",
      "epoch:22 step:103585[D loss: 0.999972] [G loss: 1.000012]\n",
      "epoch:22 step:103590[D loss: 0.999985] [G loss: 1.000028]\n",
      "epoch:22 step:103595[D loss: 1.000027] [G loss: 0.999962]\n",
      "epoch:22 step:103600[D loss: 0.999957] [G loss: 1.000027]\n",
      "epoch:22 step:103605[D loss: 1.000065] [G loss: 1.000009]\n",
      "epoch:22 step:103610[D loss: 1.000015] [G loss: 1.000012]\n",
      "epoch:22 step:103615[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:22 step:103620[D loss: 0.999909] [G loss: 1.000189]\n",
      "epoch:22 step:103625[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:22 step:103630[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:22 step:103635[D loss: 0.999957] [G loss: 1.000126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:103640[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:22 step:103645[D loss: 0.999959] [G loss: 1.000147]\n",
      "epoch:22 step:103650[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:22 step:103655[D loss: 1.000169] [G loss: 0.999875]\n",
      "epoch:22 step:103660[D loss: 1.000125] [G loss: 0.999903]\n",
      "epoch:22 step:103665[D loss: 1.000045] [G loss: 1.000078]\n",
      "epoch:22 step:103670[D loss: 1.000038] [G loss: 0.999975]\n",
      "epoch:22 step:103675[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:22 step:103680[D loss: 1.000028] [G loss: 1.000027]\n",
      "epoch:22 step:103685[D loss: 0.999897] [G loss: 1.000181]\n",
      "epoch:22 step:103690[D loss: 0.999950] [G loss: 1.000097]\n",
      "epoch:22 step:103695[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:22 step:103700[D loss: 0.999959] [G loss: 1.000024]\n",
      "epoch:22 step:103705[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:22 step:103710[D loss: 1.000004] [G loss: 1.000036]\n",
      "epoch:22 step:103715[D loss: 1.000039] [G loss: 0.999971]\n",
      "epoch:22 step:103720[D loss: 0.999910] [G loss: 1.000121]\n",
      "epoch:22 step:103725[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:22 step:103730[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:22 step:103735[D loss: 0.999937] [G loss: 1.000065]\n",
      "epoch:22 step:103740[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:22 step:103745[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:22 step:103750[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:22 step:103755[D loss: 1.000006] [G loss: 0.999972]\n",
      "epoch:22 step:103760[D loss: 0.999974] [G loss: 1.000033]\n",
      "epoch:22 step:103765[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:22 step:103770[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:22 step:103775[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:22 step:103780[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:22 step:103785[D loss: 0.999946] [G loss: 1.000092]\n",
      "epoch:22 step:103790[D loss: 0.999960] [G loss: 1.000054]\n",
      "epoch:22 step:103795[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:22 step:103800[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:22 step:103805[D loss: 1.000009] [G loss: 1.000069]\n",
      "epoch:22 step:103810[D loss: 1.000006] [G loss: 1.000035]\n",
      "epoch:22 step:103815[D loss: 1.000092] [G loss: 0.999911]\n",
      "epoch:22 step:103820[D loss: 1.000001] [G loss: 0.999985]\n",
      "epoch:22 step:103825[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:22 step:103830[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:22 step:103835[D loss: 0.999977] [G loss: 1.000088]\n",
      "epoch:22 step:103840[D loss: 1.000013] [G loss: 0.999967]\n",
      "epoch:22 step:103845[D loss: 0.999948] [G loss: 1.000153]\n",
      "epoch:22 step:103850[D loss: 1.000003] [G loss: 1.000038]\n",
      "epoch:22 step:103855[D loss: 0.999927] [G loss: 1.000113]\n",
      "epoch:22 step:103860[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:22 step:103865[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:22 step:103870[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:22 step:103875[D loss: 0.999976] [G loss: 1.000056]\n",
      "epoch:22 step:103880[D loss: 0.999942] [G loss: 1.000146]\n",
      "epoch:22 step:103885[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:22 step:103890[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:22 step:103895[D loss: 1.000020] [G loss: 1.000002]\n",
      "epoch:22 step:103900[D loss: 1.000011] [G loss: 0.999995]\n",
      "epoch:22 step:103905[D loss: 0.999974] [G loss: 1.000054]\n",
      "epoch:22 step:103910[D loss: 1.000020] [G loss: 1.000038]\n",
      "epoch:22 step:103915[D loss: 1.000025] [G loss: 0.999979]\n",
      "epoch:22 step:103920[D loss: 0.999964] [G loss: 1.000107]\n",
      "epoch:22 step:103925[D loss: 1.000018] [G loss: 1.000002]\n",
      "epoch:22 step:103930[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:22 step:103935[D loss: 0.999919] [G loss: 1.000094]\n",
      "epoch:22 step:103940[D loss: 0.999959] [G loss: 1.000105]\n",
      "epoch:22 step:103945[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:22 step:103950[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:22 step:103955[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:22 step:103960[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:22 step:103965[D loss: 1.000030] [G loss: 0.999986]\n",
      "epoch:22 step:103970[D loss: 1.000011] [G loss: 0.999977]\n",
      "epoch:22 step:103975[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:22 step:103980[D loss: 1.000042] [G loss: 0.999974]\n",
      "epoch:22 step:103985[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:22 step:103990[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:22 step:103995[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:22 step:104000[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:22 step:104005[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:22 step:104010[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:22 step:104015[D loss: 1.000004] [G loss: 1.000015]\n",
      "epoch:22 step:104020[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:22 step:104025[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:22 step:104030[D loss: 0.999972] [G loss: 1.000052]\n",
      "epoch:22 step:104035[D loss: 0.999948] [G loss: 1.000190]\n",
      "epoch:22 step:104040[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:22 step:104045[D loss: 0.999993] [G loss: 1.000069]\n",
      "epoch:22 step:104050[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:22 step:104055[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:22 step:104060[D loss: 1.000090] [G loss: 1.000035]\n",
      "epoch:22 step:104065[D loss: 1.000110] [G loss: 0.999887]\n",
      "epoch:22 step:104070[D loss: 0.999945] [G loss: 1.000225]\n",
      "epoch:22 step:104075[D loss: 0.999971] [G loss: 1.000180]\n",
      "epoch:22 step:104080[D loss: 0.999919] [G loss: 1.000172]\n",
      "epoch:22 step:104085[D loss: 0.999976] [G loss: 1.000143]\n",
      "epoch:22 step:104090[D loss: 0.999981] [G loss: 1.000079]\n",
      "epoch:22 step:104095[D loss: 0.999994] [G loss: 0.999974]\n",
      "epoch:22 step:104100[D loss: 1.000053] [G loss: 0.999928]\n",
      "epoch:22 step:104105[D loss: 1.000043] [G loss: 1.000002]\n",
      "epoch:22 step:104110[D loss: 0.999966] [G loss: 0.999950]\n",
      "epoch:22 step:104115[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:22 step:104120[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:22 step:104125[D loss: 1.000034] [G loss: 0.999993]\n",
      "epoch:22 step:104130[D loss: 1.000068] [G loss: 0.999910]\n",
      "epoch:22 step:104135[D loss: 0.999959] [G loss: 1.000111]\n",
      "epoch:22 step:104140[D loss: 0.999992] [G loss: 1.000136]\n",
      "epoch:22 step:104145[D loss: 0.999915] [G loss: 1.000235]\n",
      "epoch:22 step:104150[D loss: 1.000030] [G loss: 1.000027]\n",
      "epoch:22 step:104155[D loss: 1.000054] [G loss: 1.000162]\n",
      "epoch:22 step:104160[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:22 step:104165[D loss: 0.999899] [G loss: 1.000166]\n",
      "epoch:22 step:104170[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:22 step:104175[D loss: 1.000016] [G loss: 0.999942]\n",
      "epoch:22 step:104180[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:22 step:104185[D loss: 1.000063] [G loss: 0.999936]\n",
      "epoch:22 step:104190[D loss: 0.999988] [G loss: 0.999841]\n",
      "epoch:22 step:104195[D loss: 1.000016] [G loss: 1.000031]\n",
      "epoch:22 step:104200[D loss: 1.000123] [G loss: 1.000004]\n",
      "epoch:22 step:104205[D loss: 1.000181] [G loss: 0.999987]\n",
      "epoch:22 step:104210[D loss: 0.999937] [G loss: 1.000141]\n",
      "epoch:22 step:104215[D loss: 0.999844] [G loss: 1.000305]\n",
      "epoch:22 step:104220[D loss: 0.999995] [G loss: 1.000250]\n",
      "epoch:22 step:104225[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:22 step:104230[D loss: 0.999815] [G loss: 1.000282]\n",
      "epoch:22 step:104235[D loss: 0.999962] [G loss: 1.000230]\n",
      "epoch:22 step:104240[D loss: 0.999972] [G loss: 1.000195]\n",
      "epoch:22 step:104245[D loss: 0.999976] [G loss: 1.000232]\n",
      "epoch:22 step:104250[D loss: 0.999932] [G loss: 1.000165]\n",
      "epoch:22 step:104255[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:22 step:104260[D loss: 1.000052] [G loss: 0.999930]\n",
      "epoch:22 step:104265[D loss: 1.000064] [G loss: 0.999859]\n",
      "epoch:22 step:104270[D loss: 0.999994] [G loss: 0.999971]\n",
      "epoch:22 step:104275[D loss: 1.000048] [G loss: 1.000003]\n",
      "epoch:22 step:104280[D loss: 0.999955] [G loss: 1.000019]\n",
      "epoch:22 step:104285[D loss: 0.999928] [G loss: 1.000157]\n",
      "epoch:22 step:104290[D loss: 1.000013] [G loss: 1.000104]\n",
      "epoch:22 step:104295[D loss: 1.000014] [G loss: 1.000016]\n",
      "epoch:22 step:104300[D loss: 0.999943] [G loss: 1.000163]\n",
      "epoch:22 step:104305[D loss: 0.999920] [G loss: 1.000119]\n",
      "epoch:22 step:104310[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:22 step:104315[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:22 step:104320[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:22 step:104325[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:22 step:104330[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:22 step:104335[D loss: 0.999990] [G loss: 1.000013]\n",
      "epoch:22 step:104340[D loss: 0.999974] [G loss: 1.000103]\n",
      "epoch:22 step:104345[D loss: 1.000004] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:104350[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:22 step:104355[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:22 step:104360[D loss: 1.000028] [G loss: 1.000004]\n",
      "epoch:22 step:104365[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:22 step:104370[D loss: 0.999995] [G loss: 1.000033]\n",
      "epoch:22 step:104375[D loss: 0.999937] [G loss: 1.000065]\n",
      "epoch:22 step:104380[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:22 step:104385[D loss: 1.000036] [G loss: 1.000001]\n",
      "epoch:22 step:104390[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:22 step:104395[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:22 step:104400[D loss: 1.000046] [G loss: 1.000006]\n",
      "epoch:22 step:104405[D loss: 0.999940] [G loss: 1.000083]\n",
      "epoch:22 step:104410[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:22 step:104415[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:22 step:104420[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:22 step:104425[D loss: 1.000032] [G loss: 0.999968]\n",
      "epoch:22 step:104430[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:22 step:104435[D loss: 0.999985] [G loss: 1.000032]\n",
      "epoch:22 step:104440[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:22 step:104445[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:22 step:104450[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:22 step:104455[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:22 step:104460[D loss: 1.000004] [G loss: 1.000064]\n",
      "epoch:22 step:104465[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:22 step:104470[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:22 step:104475[D loss: 1.000009] [G loss: 1.000004]\n",
      "epoch:22 step:104480[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:22 step:104485[D loss: 0.999940] [G loss: 1.000120]\n",
      "epoch:22 step:104490[D loss: 0.999999] [G loss: 1.000026]\n",
      "epoch:22 step:104495[D loss: 0.999927] [G loss: 1.000152]\n",
      "epoch:22 step:104500[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:22 step:104505[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:22 step:104510[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:22 step:104515[D loss: 0.999948] [G loss: 1.000109]\n",
      "epoch:22 step:104520[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:22 step:104525[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:22 step:104530[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:22 step:104535[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:22 step:104540[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:22 step:104545[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:22 step:104550[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:22 step:104555[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:22 step:104560[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:22 step:104565[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:22 step:104570[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:22 step:104575[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:22 step:104580[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:22 step:104585[D loss: 1.000009] [G loss: 1.000070]\n",
      "epoch:22 step:104590[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:22 step:104595[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:22 step:104600[D loss: 1.000030] [G loss: 0.999950]\n",
      "epoch:22 step:104605[D loss: 0.999950] [G loss: 1.000049]\n",
      "epoch:22 step:104610[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:22 step:104615[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:22 step:104620[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:22 step:104625[D loss: 1.000020] [G loss: 1.000022]\n",
      "epoch:22 step:104630[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:22 step:104635[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:22 step:104640[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:22 step:104645[D loss: 0.999939] [G loss: 1.000095]\n",
      "epoch:22 step:104650[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:22 step:104655[D loss: 0.999966] [G loss: 1.000036]\n",
      "epoch:22 step:104660[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:22 step:104665[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:22 step:104670[D loss: 1.000048] [G loss: 0.999996]\n",
      "epoch:22 step:104675[D loss: 1.000106] [G loss: 0.999896]\n",
      "epoch:22 step:104680[D loss: 1.000010] [G loss: 1.000104]\n",
      "epoch:22 step:104685[D loss: 1.000013] [G loss: 1.000066]\n",
      "epoch:22 step:104690[D loss: 1.000023] [G loss: 0.999946]\n",
      "epoch:22 step:104695[D loss: 0.999970] [G loss: 1.000008]\n",
      "epoch:22 step:104700[D loss: 0.999949] [G loss: 1.000016]\n",
      "epoch:22 step:104705[D loss: 1.000083] [G loss: 0.999912]\n",
      "epoch:22 step:104710[D loss: 0.999938] [G loss: 1.000002]\n",
      "epoch:22 step:104715[D loss: 1.000031] [G loss: 1.000023]\n",
      "epoch:22 step:104720[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:22 step:104725[D loss: 0.999940] [G loss: 1.000106]\n",
      "epoch:22 step:104730[D loss: 0.999944] [G loss: 1.000148]\n",
      "epoch:22 step:104735[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:22 step:104740[D loss: 0.999967] [G loss: 1.000037]\n",
      "epoch:22 step:104745[D loss: 0.999973] [G loss: 1.000056]\n",
      "epoch:22 step:104750[D loss: 0.999990] [G loss: 1.000015]\n",
      "epoch:22 step:104755[D loss: 0.999972] [G loss: 1.000025]\n",
      "epoch:22 step:104760[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:22 step:104765[D loss: 1.000022] [G loss: 0.999979]\n",
      "epoch:22 step:104770[D loss: 0.999967] [G loss: 1.000028]\n",
      "epoch:22 step:104775[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:22 step:104780[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:22 step:104785[D loss: 0.999995] [G loss: 1.000057]\n",
      "epoch:22 step:104790[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:22 step:104795[D loss: 0.999987] [G loss: 1.000070]\n",
      "epoch:22 step:104800[D loss: 1.000044] [G loss: 1.000020]\n",
      "epoch:22 step:104805[D loss: 0.999943] [G loss: 1.000068]\n",
      "epoch:22 step:104810[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:22 step:104815[D loss: 1.000005] [G loss: 1.000049]\n",
      "epoch:22 step:104820[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:22 step:104825[D loss: 1.000005] [G loss: 1.000062]\n",
      "epoch:22 step:104830[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:22 step:104835[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:22 step:104840[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:22 step:104845[D loss: 1.000003] [G loss: 1.000037]\n",
      "epoch:22 step:104850[D loss: 0.999970] [G loss: 1.000036]\n",
      "epoch:22 step:104855[D loss: 0.999978] [G loss: 1.000007]\n",
      "epoch:22 step:104860[D loss: 1.000007] [G loss: 1.000180]\n",
      "epoch:22 step:104865[D loss: 0.999921] [G loss: 1.000111]\n",
      "epoch:22 step:104870[D loss: 1.000062] [G loss: 0.999977]\n",
      "epoch:22 step:104875[D loss: 0.999934] [G loss: 1.000142]\n",
      "epoch:22 step:104880[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:22 step:104885[D loss: 1.000133] [G loss: 0.999809]\n",
      "epoch:22 step:104890[D loss: 1.000115] [G loss: 0.999992]\n",
      "epoch:22 step:104895[D loss: 0.999916] [G loss: 1.000177]\n",
      "epoch:22 step:104900[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:22 step:104905[D loss: 1.000164] [G loss: 0.999921]\n",
      "epoch:22 step:104910[D loss: 0.999897] [G loss: 1.000182]\n",
      "epoch:22 step:104915[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:22 step:104920[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:22 step:104925[D loss: 0.999937] [G loss: 1.000148]\n",
      "epoch:22 step:104930[D loss: 0.999942] [G loss: 1.000146]\n",
      "epoch:22 step:104935[D loss: 0.999981] [G loss: 1.000107]\n",
      "epoch:22 step:104940[D loss: 0.999998] [G loss: 1.000113]\n",
      "epoch:22 step:104945[D loss: 0.999995] [G loss: 1.000030]\n",
      "epoch:22 step:104950[D loss: 1.000015] [G loss: 0.999980]\n",
      "epoch:22 step:104955[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:22 step:104960[D loss: 1.000079] [G loss: 0.999993]\n",
      "epoch:22 step:104965[D loss: 1.000040] [G loss: 0.999943]\n",
      "epoch:22 step:104970[D loss: 0.999867] [G loss: 1.000147]\n",
      "epoch:22 step:104975[D loss: 0.999990] [G loss: 1.000174]\n",
      "epoch:22 step:104980[D loss: 1.000000] [G loss: 1.000074]\n",
      "epoch:22 step:104985[D loss: 0.999950] [G loss: 1.000104]\n",
      "epoch:22 step:104990[D loss: 0.999969] [G loss: 1.000102]\n",
      "epoch:22 step:104995[D loss: 1.000028] [G loss: 0.999980]\n",
      "epoch:22 step:105000[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:22 step:105005[D loss: 1.000149] [G loss: 0.999878]\n",
      "epoch:22 step:105010[D loss: 0.999910] [G loss: 1.000112]\n",
      "epoch:22 step:105015[D loss: 0.999893] [G loss: 1.000057]\n",
      "epoch:22 step:105020[D loss: 1.000069] [G loss: 1.000071]\n",
      "epoch:22 step:105025[D loss: 0.999950] [G loss: 1.000031]\n",
      "epoch:22 step:105030[D loss: 1.000012] [G loss: 1.000126]\n",
      "epoch:22 step:105035[D loss: 0.999929] [G loss: 1.000117]\n",
      "epoch:22 step:105040[D loss: 0.999998] [G loss: 1.000106]\n",
      "epoch:22 step:105045[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:22 step:105050[D loss: 0.999981] [G loss: 1.000093]\n",
      "epoch:22 step:105055[D loss: 0.999975] [G loss: 1.000087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:105060[D loss: 1.000008] [G loss: 1.000006]\n",
      "epoch:22 step:105065[D loss: 1.000023] [G loss: 0.999989]\n",
      "epoch:22 step:105070[D loss: 0.999950] [G loss: 1.000130]\n",
      "epoch:22 step:105075[D loss: 0.999940] [G loss: 1.000127]\n",
      "epoch:22 step:105080[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:22 step:105085[D loss: 0.999994] [G loss: 1.000074]\n",
      "epoch:22 step:105090[D loss: 0.999940] [G loss: 1.000103]\n",
      "epoch:22 step:105095[D loss: 0.999965] [G loss: 1.000055]\n",
      "epoch:22 step:105100[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:22 step:105105[D loss: 1.000063] [G loss: 0.999946]\n",
      "epoch:22 step:105110[D loss: 0.999943] [G loss: 1.000047]\n",
      "epoch:22 step:105115[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:22 step:105120[D loss: 1.000057] [G loss: 1.000009]\n",
      "epoch:22 step:105125[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:22 step:105130[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:22 step:105135[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:22 step:105140[D loss: 0.999988] [G loss: 1.000067]\n",
      "epoch:22 step:105145[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:22 step:105150[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:22 step:105155[D loss: 0.999957] [G loss: 1.000073]\n",
      "epoch:22 step:105160[D loss: 1.000000] [G loss: 0.999999]\n",
      "epoch:22 step:105165[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:22 step:105170[D loss: 0.999975] [G loss: 1.000048]\n",
      "epoch:22 step:105175[D loss: 1.000007] [G loss: 1.000070]\n",
      "epoch:22 step:105180[D loss: 0.999988] [G loss: 1.000102]\n",
      "epoch:22 step:105185[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:22 step:105190[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:22 step:105195[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:22 step:105200[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:22 step:105205[D loss: 1.000068] [G loss: 1.000003]\n",
      "epoch:22 step:105210[D loss: 1.000041] [G loss: 1.000011]\n",
      "epoch:22 step:105215[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:22 step:105220[D loss: 0.999954] [G loss: 1.000027]\n",
      "epoch:22 step:105225[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:22 step:105230[D loss: 1.000021] [G loss: 1.000035]\n",
      "epoch:22 step:105235[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:22 step:105240[D loss: 1.000008] [G loss: 1.000060]\n",
      "epoch:22 step:105245[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:22 step:105250[D loss: 1.000030] [G loss: 1.000012]\n",
      "epoch:22 step:105255[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:22 step:105260[D loss: 0.999984] [G loss: 1.000082]\n",
      "epoch:22 step:105265[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:22 step:105270[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:22 step:105275[D loss: 0.999972] [G loss: 1.000094]\n",
      "epoch:22 step:105280[D loss: 0.999961] [G loss: 1.000091]\n",
      "epoch:22 step:105285[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:22 step:105290[D loss: 1.000040] [G loss: 0.999998]\n",
      "epoch:22 step:105295[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:22 step:105300[D loss: 1.000034] [G loss: 1.000042]\n",
      "epoch:22 step:105305[D loss: 1.000058] [G loss: 1.000036]\n",
      "epoch:22 step:105310[D loss: 0.999871] [G loss: 1.000295]\n",
      "epoch:22 step:105315[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:22 step:105320[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:22 step:105325[D loss: 1.000033] [G loss: 0.999982]\n",
      "epoch:22 step:105330[D loss: 0.999996] [G loss: 0.999927]\n",
      "epoch:22 step:105335[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:22 step:105340[D loss: 0.999999] [G loss: 1.000034]\n",
      "epoch:22 step:105345[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:22 step:105350[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:22 step:105355[D loss: 1.000006] [G loss: 1.000038]\n",
      "epoch:22 step:105360[D loss: 0.999987] [G loss: 1.000115]\n",
      "epoch:22 step:105365[D loss: 1.000153] [G loss: 1.000047]\n",
      "epoch:22 step:105370[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:22 step:105375[D loss: 0.999897] [G loss: 1.000169]\n",
      "epoch:22 step:105380[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:22 step:105385[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:22 step:105390[D loss: 0.999944] [G loss: 1.000137]\n",
      "epoch:22 step:105395[D loss: 1.000021] [G loss: 0.999975]\n",
      "epoch:22 step:105400[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:22 step:105405[D loss: 0.999911] [G loss: 1.000162]\n",
      "epoch:22 step:105410[D loss: 0.999999] [G loss: 1.000080]\n",
      "epoch:22 step:105415[D loss: 1.000044] [G loss: 1.000181]\n",
      "epoch:22 step:105420[D loss: 0.999853] [G loss: 1.000231]\n",
      "epoch:22 step:105425[D loss: 0.999928] [G loss: 1.000189]\n",
      "epoch:22 step:105430[D loss: 0.999949] [G loss: 1.000196]\n",
      "epoch:22 step:105435[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:22 step:105440[D loss: 1.000010] [G loss: 0.999990]\n",
      "epoch:22 step:105445[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:22 step:105450[D loss: 0.999963] [G loss: 1.000038]\n",
      "epoch:22 step:105455[D loss: 0.999977] [G loss: 1.000053]\n",
      "epoch:22 step:105460[D loss: 0.999951] [G loss: 1.000065]\n",
      "epoch:22 step:105465[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:22 step:105470[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:22 step:105475[D loss: 0.999944] [G loss: 1.000091]\n",
      "epoch:22 step:105480[D loss: 0.999945] [G loss: 1.000070]\n",
      "epoch:22 step:105485[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:22 step:105490[D loss: 0.999938] [G loss: 1.000111]\n",
      "epoch:22 step:105495[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:22 step:105500[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:22 step:105505[D loss: 1.000012] [G loss: 1.000061]\n",
      "epoch:22 step:105510[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:22 step:105515[D loss: 0.999980] [G loss: 1.000067]\n",
      "epoch:22 step:105520[D loss: 0.999983] [G loss: 1.000100]\n",
      "epoch:22 step:105525[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:22 step:105530[D loss: 0.999932] [G loss: 1.000175]\n",
      "epoch:22 step:105535[D loss: 1.000039] [G loss: 1.000077]\n",
      "epoch:22 step:105540[D loss: 0.999992] [G loss: 1.000193]\n",
      "epoch:22 step:105545[D loss: 0.999927] [G loss: 1.000121]\n",
      "epoch:22 step:105550[D loss: 1.000058] [G loss: 1.000164]\n",
      "epoch:22 step:105555[D loss: 0.999917] [G loss: 1.000214]\n",
      "epoch:22 step:105560[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:22 step:105565[D loss: 1.000022] [G loss: 0.999946]\n",
      "epoch:22 step:105570[D loss: 1.000119] [G loss: 0.999833]\n",
      "epoch:22 step:105575[D loss: 0.999920] [G loss: 0.999922]\n",
      "epoch:22 step:105580[D loss: 0.999928] [G loss: 1.000082]\n",
      "epoch:22 step:105585[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:22 step:105590[D loss: 0.999905] [G loss: 1.000181]\n",
      "epoch:22 step:105595[D loss: 0.999944] [G loss: 1.000080]\n",
      "epoch:22 step:105600[D loss: 1.000023] [G loss: 0.999999]\n",
      "epoch:22 step:105605[D loss: 1.000120] [G loss: 1.000018]\n",
      "epoch:22 step:105610[D loss: 1.000001] [G loss: 1.000127]\n",
      "epoch:22 step:105615[D loss: 0.999953] [G loss: 1.000174]\n",
      "epoch:22 step:105620[D loss: 1.000047] [G loss: 1.000269]\n",
      "epoch:22 step:105625[D loss: 0.999943] [G loss: 1.000136]\n",
      "epoch:22 step:105630[D loss: 0.999952] [G loss: 1.000069]\n",
      "epoch:22 step:105635[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:22 step:105640[D loss: 0.999989] [G loss: 1.000032]\n",
      "epoch:22 step:105645[D loss: 1.000024] [G loss: 0.999962]\n",
      "epoch:22 step:105650[D loss: 0.999960] [G loss: 1.000025]\n",
      "epoch:22 step:105655[D loss: 1.000047] [G loss: 1.000112]\n",
      "epoch:22 step:105660[D loss: 0.999926] [G loss: 1.000134]\n",
      "epoch:22 step:105665[D loss: 1.000089] [G loss: 0.999901]\n",
      "epoch:22 step:105670[D loss: 0.999912] [G loss: 1.000218]\n",
      "epoch:22 step:105675[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:22 step:105680[D loss: 0.999875] [G loss: 1.000159]\n",
      "epoch:22 step:105685[D loss: 0.999961] [G loss: 1.000149]\n",
      "epoch:22 step:105690[D loss: 1.000005] [G loss: 1.000172]\n",
      "epoch:22 step:105695[D loss: 0.999947] [G loss: 1.000068]\n",
      "epoch:22 step:105700[D loss: 0.999990] [G loss: 1.000018]\n",
      "epoch:22 step:105705[D loss: 0.999928] [G loss: 1.000014]\n",
      "epoch:22 step:105710[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:22 step:105715[D loss: 1.000024] [G loss: 0.999990]\n",
      "epoch:22 step:105720[D loss: 0.999952] [G loss: 1.000051]\n",
      "epoch:22 step:105725[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:22 step:105730[D loss: 0.999948] [G loss: 1.000042]\n",
      "epoch:22 step:105735[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:22 step:105740[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:22 step:105745[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:22 step:105750[D loss: 1.000039] [G loss: 1.000005]\n",
      "epoch:22 step:105755[D loss: 1.000028] [G loss: 1.000002]\n",
      "epoch:22 step:105760[D loss: 1.000020] [G loss: 1.000022]\n",
      "epoch:22 step:105765[D loss: 1.000033] [G loss: 1.000003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:105770[D loss: 0.999938] [G loss: 1.000069]\n",
      "epoch:22 step:105775[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:22 step:105780[D loss: 0.999960] [G loss: 1.000057]\n",
      "epoch:22 step:105785[D loss: 1.000014] [G loss: 1.000063]\n",
      "epoch:22 step:105790[D loss: 0.999998] [G loss: 0.999997]\n",
      "epoch:22 step:105795[D loss: 1.000018] [G loss: 1.000057]\n",
      "epoch:22 step:105800[D loss: 1.000021] [G loss: 1.000014]\n",
      "epoch:22 step:105805[D loss: 0.999957] [G loss: 1.000056]\n",
      "epoch:22 step:105810[D loss: 0.999997] [G loss: 1.000055]\n",
      "epoch:22 step:105815[D loss: 0.999952] [G loss: 1.000075]\n",
      "epoch:22 step:105820[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:22 step:105825[D loss: 1.000006] [G loss: 1.000065]\n",
      "epoch:22 step:105830[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:22 step:105835[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:22 step:105840[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:22 step:105845[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:22 step:105850[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:22 step:105855[D loss: 0.999980] [G loss: 1.000042]\n",
      "epoch:22 step:105860[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:22 step:105865[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:22 step:105870[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:22 step:105875[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:22 step:105880[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:22 step:105885[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:22 step:105890[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:22 step:105895[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:22 step:105900[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:22 step:105905[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:22 step:105910[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:22 step:105915[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:22 step:105920[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:22 step:105925[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:22 step:105930[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:22 step:105935[D loss: 1.000063] [G loss: 1.000004]\n",
      "epoch:22 step:105940[D loss: 0.999909] [G loss: 1.000140]\n",
      "epoch:22 step:105945[D loss: 1.000066] [G loss: 1.000036]\n",
      "epoch:22 step:105950[D loss: 0.999890] [G loss: 1.000271]\n",
      "epoch:22 step:105955[D loss: 0.999969] [G loss: 0.999999]\n",
      "epoch:22 step:105960[D loss: 0.999977] [G loss: 1.000107]\n",
      "epoch:22 step:105965[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:22 step:105970[D loss: 0.999996] [G loss: 1.000086]\n",
      "epoch:22 step:105975[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:22 step:105980[D loss: 1.000046] [G loss: 0.999963]\n",
      "epoch:22 step:105985[D loss: 0.999935] [G loss: 1.000099]\n",
      "epoch:22 step:105990[D loss: 0.999960] [G loss: 1.000021]\n",
      "epoch:22 step:105995[D loss: 1.000008] [G loss: 0.999991]\n",
      "epoch:22 step:106000[D loss: 0.999939] [G loss: 1.000109]\n",
      "epoch:22 step:106005[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:22 step:106010[D loss: 0.999963] [G loss: 1.000125]\n",
      "epoch:22 step:106015[D loss: 1.000081] [G loss: 1.000020]\n",
      "epoch:22 step:106020[D loss: 0.999931] [G loss: 1.000095]\n",
      "epoch:22 step:106025[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:22 step:106030[D loss: 1.000010] [G loss: 0.999969]\n",
      "epoch:22 step:106035[D loss: 1.000127] [G loss: 0.999907]\n",
      "epoch:22 step:106040[D loss: 1.000054] [G loss: 0.999890]\n",
      "epoch:22 step:106045[D loss: 1.000105] [G loss: 0.999868]\n",
      "epoch:22 step:106050[D loss: 0.999921] [G loss: 1.000020]\n",
      "epoch:22 step:106055[D loss: 0.999934] [G loss: 1.000118]\n",
      "epoch:22 step:106060[D loss: 1.000060] [G loss: 0.999978]\n",
      "epoch:22 step:106065[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:22 step:106070[D loss: 0.999891] [G loss: 1.000207]\n",
      "epoch:22 step:106075[D loss: 0.999911] [G loss: 1.000105]\n",
      "epoch:22 step:106080[D loss: 0.999997] [G loss: 0.999997]\n",
      "epoch:22 step:106085[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:22 step:106090[D loss: 1.000026] [G loss: 0.999990]\n",
      "epoch:22 step:106095[D loss: 0.999980] [G loss: 0.999992]\n",
      "epoch:22 step:106100[D loss: 0.999974] [G loss: 1.000028]\n",
      "epoch:22 step:106105[D loss: 1.000022] [G loss: 0.999972]\n",
      "epoch:22 step:106110[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:22 step:106115[D loss: 1.000129] [G loss: 0.999874]\n",
      "epoch:22 step:106120[D loss: 0.999900] [G loss: 1.000114]\n",
      "epoch:22 step:106125[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:22 step:106130[D loss: 0.999999] [G loss: 1.000029]\n",
      "epoch:22 step:106135[D loss: 1.000012] [G loss: 1.000006]\n",
      "epoch:22 step:106140[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:22 step:106145[D loss: 1.000024] [G loss: 1.000008]\n",
      "epoch:22 step:106150[D loss: 0.999920] [G loss: 1.000119]\n",
      "epoch:22 step:106155[D loss: 1.000016] [G loss: 1.000097]\n",
      "epoch:22 step:106160[D loss: 1.000064] [G loss: 0.999922]\n",
      "epoch:22 step:106165[D loss: 0.999946] [G loss: 1.000043]\n",
      "epoch:22 step:106170[D loss: 1.000000] [G loss: 1.000082]\n",
      "epoch:22 step:106175[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:22 step:106180[D loss: 0.999977] [G loss: 1.000110]\n",
      "epoch:22 step:106185[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:22 step:106190[D loss: 0.999994] [G loss: 1.000076]\n",
      "epoch:22 step:106195[D loss: 1.000020] [G loss: 1.000041]\n",
      "epoch:22 step:106200[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:22 step:106205[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:22 step:106210[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:22 step:106215[D loss: 0.999968] [G loss: 1.000071]\n",
      "epoch:22 step:106220[D loss: 1.000131] [G loss: 0.999811]\n",
      "epoch:22 step:106225[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:22 step:106230[D loss: 0.999997] [G loss: 1.000150]\n",
      "epoch:22 step:106235[D loss: 0.999921] [G loss: 1.000241]\n",
      "epoch:22 step:106240[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:22 step:106245[D loss: 0.999990] [G loss: 1.000005]\n",
      "epoch:22 step:106250[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:22 step:106255[D loss: 1.000087] [G loss: 0.999938]\n",
      "epoch:22 step:106260[D loss: 0.999973] [G loss: 0.999898]\n",
      "epoch:22 step:106265[D loss: 0.999972] [G loss: 0.999952]\n",
      "epoch:22 step:106270[D loss: 1.000022] [G loss: 1.000144]\n",
      "epoch:22 step:106275[D loss: 1.000054] [G loss: 1.000082]\n",
      "epoch:22 step:106280[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:22 step:106285[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:22 step:106290[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:22 step:106295[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:22 step:106300[D loss: 1.000044] [G loss: 0.999971]\n",
      "epoch:22 step:106305[D loss: 0.999953] [G loss: 1.000034]\n",
      "epoch:22 step:106310[D loss: 0.999876] [G loss: 1.000191]\n",
      "epoch:22 step:106315[D loss: 0.999973] [G loss: 1.000167]\n",
      "epoch:22 step:106320[D loss: 0.999908] [G loss: 1.000138]\n",
      "epoch:22 step:106325[D loss: 1.000049] [G loss: 1.000115]\n",
      "epoch:22 step:106330[D loss: 0.999902] [G loss: 1.000154]\n",
      "epoch:22 step:106335[D loss: 0.999948] [G loss: 1.000140]\n",
      "epoch:22 step:106340[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:22 step:106345[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:22 step:106350[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:22 step:106355[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:22 step:106360[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:22 step:106365[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:22 step:106370[D loss: 0.999990] [G loss: 1.000010]\n",
      "epoch:22 step:106375[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:22 step:106380[D loss: 1.000000] [G loss: 1.000092]\n",
      "epoch:22 step:106385[D loss: 1.000041] [G loss: 0.999962]\n",
      "epoch:22 step:106390[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:22 step:106395[D loss: 1.000003] [G loss: 1.000002]\n",
      "epoch:22 step:106400[D loss: 1.000018] [G loss: 1.000039]\n",
      "epoch:22 step:106405[D loss: 0.999948] [G loss: 1.000045]\n",
      "epoch:22 step:106410[D loss: 0.999992] [G loss: 0.999988]\n",
      "epoch:22 step:106415[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:22 step:106420[D loss: 0.999978] [G loss: 1.000058]\n",
      "epoch:22 step:106425[D loss: 0.999954] [G loss: 1.000051]\n",
      "epoch:22 step:106430[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:22 step:106435[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:22 step:106440[D loss: 0.999990] [G loss: 1.000019]\n",
      "epoch:22 step:106445[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:22 step:106450[D loss: 0.999989] [G loss: 1.000012]\n",
      "epoch:22 step:106455[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:22 step:106460[D loss: 0.999985] [G loss: 1.000052]\n",
      "epoch:22 step:106465[D loss: 1.000023] [G loss: 0.999946]\n",
      "epoch:22 step:106470[D loss: 1.000001] [G loss: 0.999973]\n",
      "epoch:22 step:106475[D loss: 1.000004] [G loss: 0.999998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:106480[D loss: 1.000137] [G loss: 0.999883]\n",
      "epoch:22 step:106485[D loss: 0.999879] [G loss: 1.000113]\n",
      "epoch:22 step:106490[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:22 step:106495[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:22 step:106500[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:22 step:106505[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:22 step:106510[D loss: 0.999972] [G loss: 1.000021]\n",
      "epoch:22 step:106515[D loss: 1.000053] [G loss: 0.999970]\n",
      "epoch:22 step:106520[D loss: 0.999981] [G loss: 0.999981]\n",
      "epoch:22 step:106525[D loss: 0.999976] [G loss: 1.000000]\n",
      "epoch:22 step:106530[D loss: 0.999920] [G loss: 1.000078]\n",
      "epoch:22 step:106535[D loss: 1.000082] [G loss: 1.000042]\n",
      "epoch:22 step:106540[D loss: 0.999955] [G loss: 1.000161]\n",
      "epoch:22 step:106545[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:22 step:106550[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:22 step:106555[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:22 step:106560[D loss: 0.999946] [G loss: 1.000142]\n",
      "epoch:22 step:106565[D loss: 0.999992] [G loss: 1.000014]\n",
      "epoch:22 step:106570[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:22 step:106575[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:22 step:106580[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:22 step:106585[D loss: 1.000036] [G loss: 0.999937]\n",
      "epoch:22 step:106590[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:22 step:106595[D loss: 0.999965] [G loss: 1.000158]\n",
      "epoch:22 step:106600[D loss: 0.999945] [G loss: 1.000186]\n",
      "epoch:22 step:106605[D loss: 0.999951] [G loss: 1.000092]\n",
      "epoch:22 step:106610[D loss: 0.999929] [G loss: 1.000166]\n",
      "epoch:22 step:106615[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:22 step:106620[D loss: 1.000022] [G loss: 1.000007]\n",
      "epoch:22 step:106625[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:22 step:106630[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:22 step:106635[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:22 step:106640[D loss: 1.000039] [G loss: 1.000156]\n",
      "epoch:22 step:106645[D loss: 1.000075] [G loss: 0.999956]\n",
      "epoch:22 step:106650[D loss: 0.999851] [G loss: 1.000151]\n",
      "epoch:22 step:106655[D loss: 0.999937] [G loss: 1.000120]\n",
      "epoch:22 step:106660[D loss: 0.999960] [G loss: 1.000115]\n",
      "epoch:22 step:106665[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:22 step:106670[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:22 step:106675[D loss: 1.000015] [G loss: 1.000047]\n",
      "epoch:22 step:106680[D loss: 1.000007] [G loss: 1.000086]\n",
      "epoch:22 step:106685[D loss: 1.000047] [G loss: 0.999975]\n",
      "epoch:22 step:106690[D loss: 0.999923] [G loss: 1.000144]\n",
      "epoch:22 step:106695[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:22 step:106700[D loss: 0.999998] [G loss: 1.000022]\n",
      "epoch:22 step:106705[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:22 step:106710[D loss: 1.000010] [G loss: 1.000032]\n",
      "epoch:22 step:106715[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:22 step:106720[D loss: 0.999991] [G loss: 1.000044]\n",
      "epoch:22 step:106725[D loss: 0.999995] [G loss: 1.000013]\n",
      "epoch:22 step:106730[D loss: 0.999959] [G loss: 1.000053]\n",
      "epoch:22 step:106735[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:22 step:106740[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:22 step:106745[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:22 step:106750[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:22 step:106755[D loss: 1.000013] [G loss: 1.000102]\n",
      "epoch:22 step:106760[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:22 step:106765[D loss: 1.000040] [G loss: 1.000020]\n",
      "epoch:22 step:106770[D loss: 0.999979] [G loss: 1.000116]\n",
      "epoch:22 step:106775[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:22 step:106780[D loss: 1.000038] [G loss: 0.999985]\n",
      "epoch:22 step:106785[D loss: 0.999952] [G loss: 1.000031]\n",
      "epoch:22 step:106790[D loss: 0.999969] [G loss: 1.000018]\n",
      "epoch:22 step:106795[D loss: 0.999967] [G loss: 1.000036]\n",
      "epoch:22 step:106800[D loss: 0.999967] [G loss: 1.000059]\n",
      "epoch:22 step:106805[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:22 step:106810[D loss: 1.000008] [G loss: 1.000020]\n",
      "epoch:22 step:106815[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:22 step:106820[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:22 step:106825[D loss: 0.999977] [G loss: 1.000021]\n",
      "epoch:22 step:106830[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:22 step:106835[D loss: 0.999969] [G loss: 1.000106]\n",
      "epoch:22 step:106840[D loss: 1.000071] [G loss: 1.000032]\n",
      "epoch:22 step:106845[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:22 step:106850[D loss: 0.999957] [G loss: 1.000089]\n",
      "epoch:22 step:106855[D loss: 0.999994] [G loss: 0.999930]\n",
      "epoch:22 step:106860[D loss: 1.000020] [G loss: 0.999991]\n",
      "epoch:22 step:106865[D loss: 0.999902] [G loss: 1.000035]\n",
      "epoch:22 step:106870[D loss: 0.999930] [G loss: 1.000109]\n",
      "epoch:22 step:106875[D loss: 1.000065] [G loss: 1.000021]\n",
      "epoch:22 step:106880[D loss: 1.000071] [G loss: 0.999988]\n",
      "epoch:22 step:106885[D loss: 0.999902] [G loss: 1.000154]\n",
      "epoch:22 step:106890[D loss: 1.000075] [G loss: 0.999930]\n",
      "epoch:22 step:106895[D loss: 1.000002] [G loss: 1.000034]\n",
      "epoch:22 step:106900[D loss: 0.999934] [G loss: 1.000149]\n",
      "epoch:22 step:106905[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:22 step:106910[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:22 step:106915[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:22 step:106920[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:22 step:106925[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:22 step:106930[D loss: 1.000004] [G loss: 1.000011]\n",
      "epoch:22 step:106935[D loss: 0.999964] [G loss: 1.000030]\n",
      "epoch:22 step:106940[D loss: 1.000042] [G loss: 1.000044]\n",
      "epoch:22 step:106945[D loss: 0.999948] [G loss: 1.000014]\n",
      "epoch:22 step:106950[D loss: 1.000053] [G loss: 0.999953]\n",
      "epoch:22 step:106955[D loss: 0.999930] [G loss: 1.000087]\n",
      "epoch:22 step:106960[D loss: 0.999934] [G loss: 1.000071]\n",
      "epoch:22 step:106965[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:22 step:106970[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:22 step:106975[D loss: 0.999998] [G loss: 1.000060]\n",
      "epoch:22 step:106980[D loss: 0.999967] [G loss: 1.000051]\n",
      "epoch:22 step:106985[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:22 step:106990[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:22 step:106995[D loss: 0.999950] [G loss: 1.000077]\n",
      "epoch:22 step:107000[D loss: 1.000020] [G loss: 1.000018]\n",
      "epoch:22 step:107005[D loss: 1.000022] [G loss: 0.999960]\n",
      "epoch:22 step:107010[D loss: 0.999928] [G loss: 1.000159]\n",
      "epoch:22 step:107015[D loss: 1.000102] [G loss: 0.999996]\n",
      "epoch:22 step:107020[D loss: 0.999920] [G loss: 1.000091]\n",
      "epoch:22 step:107025[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:22 step:107030[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:22 step:107035[D loss: 0.999984] [G loss: 1.000033]\n",
      "epoch:22 step:107040[D loss: 0.999964] [G loss: 1.000079]\n",
      "epoch:22 step:107045[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:22 step:107050[D loss: 1.000001] [G loss: 0.999946]\n",
      "epoch:22 step:107055[D loss: 1.000015] [G loss: 1.000012]\n",
      "epoch:22 step:107060[D loss: 0.999985] [G loss: 1.000102]\n",
      "epoch:22 step:107065[D loss: 0.999962] [G loss: 1.000046]\n",
      "epoch:22 step:107070[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:22 step:107075[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:22 step:107080[D loss: 0.999947] [G loss: 1.000059]\n",
      "epoch:22 step:107085[D loss: 0.999996] [G loss: 1.000041]\n",
      "epoch:22 step:107090[D loss: 0.999961] [G loss: 1.000042]\n",
      "epoch:22 step:107095[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:22 step:107100[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:22 step:107105[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:22 step:107110[D loss: 0.999999] [G loss: 1.000121]\n",
      "epoch:22 step:107115[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:22 step:107120[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:22 step:107125[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:22 step:107130[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:22 step:107135[D loss: 0.999960] [G loss: 1.000046]\n",
      "epoch:22 step:107140[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:22 step:107145[D loss: 0.999967] [G loss: 0.999999]\n",
      "epoch:22 step:107150[D loss: 1.000006] [G loss: 1.000015]\n",
      "epoch:22 step:107155[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:22 step:107160[D loss: 0.999959] [G loss: 1.000086]\n",
      "epoch:22 step:107165[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:22 step:107170[D loss: 0.999970] [G loss: 1.000048]\n",
      "epoch:22 step:107175[D loss: 1.000002] [G loss: 1.000029]\n",
      "epoch:22 step:107180[D loss: 0.999978] [G loss: 1.000105]\n",
      "epoch:22 step:107185[D loss: 0.999978] [G loss: 1.000018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:107190[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:22 step:107195[D loss: 0.999978] [G loss: 1.000037]\n",
      "epoch:22 step:107200[D loss: 1.000015] [G loss: 1.000008]\n",
      "epoch:22 step:107205[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:22 step:107210[D loss: 0.999986] [G loss: 0.999997]\n",
      "epoch:22 step:107215[D loss: 0.999969] [G loss: 1.000109]\n",
      "epoch:22 step:107220[D loss: 0.999950] [G loss: 1.000063]\n",
      "epoch:22 step:107225[D loss: 0.999963] [G loss: 1.000090]\n",
      "epoch:22 step:107230[D loss: 1.000100] [G loss: 0.999901]\n",
      "epoch:22 step:107235[D loss: 0.999925] [G loss: 1.000018]\n",
      "epoch:22 step:107240[D loss: 1.000044] [G loss: 1.000034]\n",
      "epoch:22 step:107245[D loss: 1.000020] [G loss: 0.999877]\n",
      "epoch:22 step:107250[D loss: 0.999885] [G loss: 1.000139]\n",
      "epoch:22 step:107255[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:22 step:107260[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:22 step:107265[D loss: 0.999990] [G loss: 1.000049]\n",
      "epoch:22 step:107270[D loss: 0.999969] [G loss: 1.000034]\n",
      "epoch:22 step:107275[D loss: 1.000020] [G loss: 1.000002]\n",
      "epoch:22 step:107280[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:22 step:107285[D loss: 1.000026] [G loss: 1.000116]\n",
      "epoch:22 step:107290[D loss: 0.999943] [G loss: 1.000212]\n",
      "epoch:22 step:107295[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:22 step:107300[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:22 step:107305[D loss: 0.999940] [G loss: 1.000121]\n",
      "epoch:22 step:107310[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:22 step:107315[D loss: 1.000035] [G loss: 1.000063]\n",
      "epoch:22 step:107320[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:22 step:107325[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:22 step:107330[D loss: 1.000000] [G loss: 0.999943]\n",
      "epoch:22 step:107335[D loss: 0.999999] [G loss: 0.999995]\n",
      "epoch:22 step:107340[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:22 step:107345[D loss: 0.999898] [G loss: 1.000104]\n",
      "epoch:22 step:107350[D loss: 1.000056] [G loss: 1.000057]\n",
      "epoch:22 step:107355[D loss: 0.999929] [G loss: 1.000102]\n",
      "epoch:22 step:107360[D loss: 1.000018] [G loss: 1.000056]\n",
      "epoch:22 step:107365[D loss: 0.999946] [G loss: 1.000139]\n",
      "epoch:22 step:107370[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:22 step:107375[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:22 step:107380[D loss: 1.000015] [G loss: 1.000009]\n",
      "epoch:22 step:107385[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:22 step:107390[D loss: 1.000042] [G loss: 1.000003]\n",
      "epoch:22 step:107395[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:22 step:107400[D loss: 0.999989] [G loss: 1.000042]\n",
      "epoch:22 step:107405[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:22 step:107410[D loss: 0.999953] [G loss: 1.000121]\n",
      "epoch:22 step:107415[D loss: 0.999997] [G loss: 1.000034]\n",
      "epoch:22 step:107420[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:22 step:107425[D loss: 0.999950] [G loss: 1.000053]\n",
      "epoch:22 step:107430[D loss: 1.000027] [G loss: 0.999980]\n",
      "epoch:22 step:107435[D loss: 1.000012] [G loss: 1.000034]\n",
      "epoch:22 step:107440[D loss: 0.999949] [G loss: 1.000080]\n",
      "epoch:22 step:107445[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:22 step:107450[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:22 step:107455[D loss: 0.999957] [G loss: 1.000044]\n",
      "epoch:22 step:107460[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:22 step:107465[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:22 step:107470[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:22 step:107475[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:22 step:107480[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:22 step:107485[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:22 step:107490[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:22 step:107495[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:22 step:107500[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:22 step:107505[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:22 step:107510[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:22 step:107515[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:22 step:107520[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:22 step:107525[D loss: 0.999988] [G loss: 1.000040]\n",
      "epoch:22 step:107530[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:22 step:107535[D loss: 1.000004] [G loss: 1.000021]\n",
      "epoch:22 step:107540[D loss: 1.000022] [G loss: 0.999969]\n",
      "epoch:22 step:107545[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:22 step:107550[D loss: 0.999984] [G loss: 1.000120]\n",
      "epoch:22 step:107555[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:22 step:107560[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:22 step:107565[D loss: 0.999979] [G loss: 1.000017]\n",
      "epoch:22 step:107570[D loss: 0.999945] [G loss: 1.000075]\n",
      "epoch:22 step:107575[D loss: 1.000041] [G loss: 0.999985]\n",
      "epoch:22 step:107580[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:22 step:107585[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:22 step:107590[D loss: 1.000039] [G loss: 0.999979]\n",
      "epoch:22 step:107595[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:22 step:107600[D loss: 0.999955] [G loss: 1.000122]\n",
      "epoch:22 step:107605[D loss: 0.999964] [G loss: 1.000025]\n",
      "epoch:22 step:107610[D loss: 1.000034] [G loss: 0.999926]\n",
      "epoch:22 step:107615[D loss: 0.999999] [G loss: 1.000006]\n",
      "epoch:22 step:107620[D loss: 1.000005] [G loss: 0.999972]\n",
      "epoch:22 step:107625[D loss: 0.999965] [G loss: 1.000033]\n",
      "epoch:22 step:107630[D loss: 0.999946] [G loss: 1.000060]\n",
      "epoch:22 step:107635[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:22 step:107640[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:22 step:107645[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:22 step:107650[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:22 step:107655[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:22 step:107660[D loss: 0.999943] [G loss: 1.000063]\n",
      "epoch:22 step:107665[D loss: 1.000021] [G loss: 0.999925]\n",
      "epoch:22 step:107670[D loss: 0.999969] [G loss: 1.000035]\n",
      "epoch:22 step:107675[D loss: 0.999996] [G loss: 1.000095]\n",
      "epoch:22 step:107680[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:22 step:107685[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:22 step:107690[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:22 step:107695[D loss: 0.999977] [G loss: 1.000018]\n",
      "epoch:22 step:107700[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:22 step:107705[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:22 step:107710[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:22 step:107715[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:22 step:107720[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:22 step:107725[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:22 step:107730[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:22 step:107735[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:22 step:107740[D loss: 0.999947] [G loss: 1.000109]\n",
      "epoch:22 step:107745[D loss: 1.000000] [G loss: 1.000004]\n",
      "epoch:22 step:107750[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:22 step:107755[D loss: 0.999985] [G loss: 1.000038]\n",
      "epoch:23 step:107760[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:23 step:107765[D loss: 0.999940] [G loss: 1.000128]\n",
      "epoch:23 step:107770[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:23 step:107775[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:23 step:107780[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:23 step:107785[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:23 step:107790[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:23 step:107795[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:23 step:107800[D loss: 1.000024] [G loss: 1.000012]\n",
      "epoch:23 step:107805[D loss: 0.999953] [G loss: 1.000174]\n",
      "epoch:23 step:107810[D loss: 0.999997] [G loss: 1.000124]\n",
      "epoch:23 step:107815[D loss: 0.999937] [G loss: 1.000065]\n",
      "epoch:23 step:107820[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:23 step:107825[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:23 step:107830[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:23 step:107835[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:23 step:107840[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:23 step:107845[D loss: 1.000008] [G loss: 1.000010]\n",
      "epoch:23 step:107850[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:23 step:107855[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:23 step:107860[D loss: 1.000037] [G loss: 1.000026]\n",
      "epoch:23 step:107865[D loss: 0.999972] [G loss: 1.000098]\n",
      "epoch:23 step:107870[D loss: 0.999932] [G loss: 1.000116]\n",
      "epoch:23 step:107875[D loss: 0.999954] [G loss: 1.000134]\n",
      "epoch:23 step:107880[D loss: 0.999980] [G loss: 1.000112]\n",
      "epoch:23 step:107885[D loss: 1.000023] [G loss: 1.000062]\n",
      "epoch:23 step:107890[D loss: 0.999976] [G loss: 1.000134]\n",
      "epoch:23 step:107895[D loss: 0.999950] [G loss: 1.000082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:107900[D loss: 1.000034] [G loss: 0.999967]\n",
      "epoch:23 step:107905[D loss: 1.000032] [G loss: 0.999955]\n",
      "epoch:23 step:107910[D loss: 1.000023] [G loss: 0.999865]\n",
      "epoch:23 step:107915[D loss: 0.999974] [G loss: 0.999998]\n",
      "epoch:23 step:107920[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:23 step:107925[D loss: 1.000033] [G loss: 1.000010]\n",
      "epoch:23 step:107930[D loss: 1.000032] [G loss: 0.999969]\n",
      "epoch:23 step:107935[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:23 step:107940[D loss: 0.999987] [G loss: 1.000145]\n",
      "epoch:23 step:107945[D loss: 0.999962] [G loss: 1.000096]\n",
      "epoch:23 step:107950[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:23 step:107955[D loss: 1.000031] [G loss: 0.999991]\n",
      "epoch:23 step:107960[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:23 step:107965[D loss: 1.000045] [G loss: 0.999902]\n",
      "epoch:23 step:107970[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:23 step:107975[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:23 step:107980[D loss: 0.999960] [G loss: 1.000129]\n",
      "epoch:23 step:107985[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:23 step:107990[D loss: 0.999943] [G loss: 1.000119]\n",
      "epoch:23 step:107995[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:23 step:108000[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:23 step:108005[D loss: 0.999982] [G loss: 1.000117]\n",
      "epoch:23 step:108010[D loss: 1.000004] [G loss: 1.000059]\n",
      "epoch:23 step:108015[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:23 step:108020[D loss: 1.000012] [G loss: 1.000060]\n",
      "epoch:23 step:108025[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:23 step:108030[D loss: 0.999997] [G loss: 1.000072]\n",
      "epoch:23 step:108035[D loss: 0.999994] [G loss: 1.000033]\n",
      "epoch:23 step:108040[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:23 step:108045[D loss: 0.999979] [G loss: 1.000096]\n",
      "epoch:23 step:108050[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:23 step:108055[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:23 step:108060[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:23 step:108065[D loss: 1.000025] [G loss: 1.000046]\n",
      "epoch:23 step:108070[D loss: 0.999945] [G loss: 1.000177]\n",
      "epoch:23 step:108075[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:23 step:108080[D loss: 1.000001] [G loss: 0.999996]\n",
      "epoch:23 step:108085[D loss: 1.000035] [G loss: 0.999952]\n",
      "epoch:23 step:108090[D loss: 1.000022] [G loss: 0.999964]\n",
      "epoch:23 step:108095[D loss: 1.000012] [G loss: 0.999964]\n",
      "epoch:23 step:108100[D loss: 1.000057] [G loss: 1.000060]\n",
      "epoch:23 step:108105[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:23 step:108110[D loss: 1.000098] [G loss: 0.999910]\n",
      "epoch:23 step:108115[D loss: 1.000012] [G loss: 1.000051]\n",
      "epoch:23 step:108120[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:23 step:108125[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:23 step:108130[D loss: 1.000031] [G loss: 0.999965]\n",
      "epoch:23 step:108135[D loss: 0.999956] [G loss: 1.000033]\n",
      "epoch:23 step:108140[D loss: 0.999944] [G loss: 1.000109]\n",
      "epoch:23 step:108145[D loss: 0.999987] [G loss: 1.000096]\n",
      "epoch:23 step:108150[D loss: 1.000000] [G loss: 1.000004]\n",
      "epoch:23 step:108155[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:23 step:108160[D loss: 0.999976] [G loss: 1.000153]\n",
      "epoch:23 step:108165[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:23 step:108170[D loss: 0.999932] [G loss: 1.000064]\n",
      "epoch:23 step:108175[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:23 step:108180[D loss: 1.000015] [G loss: 1.000015]\n",
      "epoch:23 step:108185[D loss: 0.999932] [G loss: 1.000138]\n",
      "epoch:23 step:108190[D loss: 1.000023] [G loss: 1.000051]\n",
      "epoch:23 step:108195[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:23 step:108200[D loss: 1.000049] [G loss: 1.000128]\n",
      "epoch:23 step:108205[D loss: 1.000003] [G loss: 1.000038]\n",
      "epoch:23 step:108210[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:23 step:108215[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:23 step:108220[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:23 step:108225[D loss: 0.999955] [G loss: 1.000040]\n",
      "epoch:23 step:108230[D loss: 1.000005] [G loss: 0.999998]\n",
      "epoch:23 step:108235[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:23 step:108240[D loss: 1.000043] [G loss: 1.000073]\n",
      "epoch:23 step:108245[D loss: 1.000024] [G loss: 1.000098]\n",
      "epoch:23 step:108250[D loss: 0.999898] [G loss: 1.000189]\n",
      "epoch:23 step:108255[D loss: 0.999981] [G loss: 1.000093]\n",
      "epoch:23 step:108260[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:23 step:108265[D loss: 1.000010] [G loss: 1.000068]\n",
      "epoch:23 step:108270[D loss: 0.999946] [G loss: 1.000087]\n",
      "epoch:23 step:108275[D loss: 0.999975] [G loss: 1.000068]\n",
      "epoch:23 step:108280[D loss: 1.000023] [G loss: 0.999961]\n",
      "epoch:23 step:108285[D loss: 1.000026] [G loss: 0.999956]\n",
      "epoch:23 step:108290[D loss: 1.000126] [G loss: 0.999834]\n",
      "epoch:23 step:108295[D loss: 1.000072] [G loss: 0.999894]\n",
      "epoch:23 step:108300[D loss: 0.999985] [G loss: 0.999938]\n",
      "epoch:23 step:108305[D loss: 1.000054] [G loss: 0.999995]\n",
      "epoch:23 step:108310[D loss: 0.999881] [G loss: 1.000171]\n",
      "epoch:23 step:108315[D loss: 1.000003] [G loss: 1.000071]\n",
      "epoch:23 step:108320[D loss: 1.000034] [G loss: 1.000032]\n",
      "epoch:23 step:108325[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:23 step:108330[D loss: 0.999964] [G loss: 1.000142]\n",
      "epoch:23 step:108335[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:23 step:108340[D loss: 1.000081] [G loss: 0.999896]\n",
      "epoch:23 step:108345[D loss: 1.000089] [G loss: 0.999955]\n",
      "epoch:23 step:108350[D loss: 1.000017] [G loss: 1.000045]\n",
      "epoch:23 step:108355[D loss: 0.999911] [G loss: 1.000145]\n",
      "epoch:23 step:108360[D loss: 0.999951] [G loss: 1.000074]\n",
      "epoch:23 step:108365[D loss: 0.999987] [G loss: 1.000198]\n",
      "epoch:23 step:108370[D loss: 0.999893] [G loss: 1.000147]\n",
      "epoch:23 step:108375[D loss: 0.999950] [G loss: 1.000089]\n",
      "epoch:23 step:108380[D loss: 1.000003] [G loss: 1.000022]\n",
      "epoch:23 step:108385[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:23 step:108390[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:23 step:108395[D loss: 0.999997] [G loss: 1.000066]\n",
      "epoch:23 step:108400[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:23 step:108405[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:23 step:108410[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:23 step:108415[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:23 step:108420[D loss: 0.999969] [G loss: 1.000074]\n",
      "epoch:23 step:108425[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:23 step:108430[D loss: 0.999993] [G loss: 1.000008]\n",
      "epoch:23 step:108435[D loss: 0.999953] [G loss: 1.000095]\n",
      "epoch:23 step:108440[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:23 step:108445[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:23 step:108450[D loss: 0.999989] [G loss: 1.000043]\n",
      "epoch:23 step:108455[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:23 step:108460[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:23 step:108465[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:23 step:108470[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:23 step:108475[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:23 step:108480[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:23 step:108485[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:23 step:108490[D loss: 1.000028] [G loss: 0.999992]\n",
      "epoch:23 step:108495[D loss: 0.999938] [G loss: 1.000075]\n",
      "epoch:23 step:108500[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:23 step:108505[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:23 step:108510[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:23 step:108515[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:23 step:108520[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:23 step:108525[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:23 step:108530[D loss: 0.999968] [G loss: 1.000148]\n",
      "epoch:23 step:108535[D loss: 1.000051] [G loss: 0.999998]\n",
      "epoch:23 step:108540[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:23 step:108545[D loss: 1.000039] [G loss: 0.999924]\n",
      "epoch:23 step:108550[D loss: 0.999924] [G loss: 1.000053]\n",
      "epoch:23 step:108555[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:23 step:108560[D loss: 0.999998] [G loss: 1.000130]\n",
      "epoch:23 step:108565[D loss: 0.999934] [G loss: 1.000129]\n",
      "epoch:23 step:108570[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:23 step:108575[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:23 step:108580[D loss: 0.999989] [G loss: 0.999997]\n",
      "epoch:23 step:108585[D loss: 1.000013] [G loss: 0.999982]\n",
      "epoch:23 step:108590[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:23 step:108595[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:23 step:108600[D loss: 1.000000] [G loss: 1.000052]\n",
      "epoch:23 step:108605[D loss: 0.999945] [G loss: 1.000135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:108610[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:23 step:108615[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:23 step:108620[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:23 step:108625[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:23 step:108630[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:23 step:108635[D loss: 0.999964] [G loss: 1.000066]\n",
      "epoch:23 step:108640[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:23 step:108645[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:23 step:108650[D loss: 1.000000] [G loss: 1.000049]\n",
      "epoch:23 step:108655[D loss: 0.999976] [G loss: 1.000027]\n",
      "epoch:23 step:108660[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:23 step:108665[D loss: 1.000017] [G loss: 1.000046]\n",
      "epoch:23 step:108670[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:23 step:108675[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:23 step:108680[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:23 step:108685[D loss: 1.000010] [G loss: 0.999989]\n",
      "epoch:23 step:108690[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:23 step:108695[D loss: 1.000025] [G loss: 1.000033]\n",
      "epoch:23 step:108700[D loss: 0.999898] [G loss: 1.000155]\n",
      "epoch:23 step:108705[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:23 step:108710[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:23 step:108715[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:23 step:108720[D loss: 1.000012] [G loss: 1.000076]\n",
      "epoch:23 step:108725[D loss: 1.000012] [G loss: 1.000042]\n",
      "epoch:23 step:108730[D loss: 0.999958] [G loss: 0.999972]\n",
      "epoch:23 step:108735[D loss: 1.000013] [G loss: 0.999995]\n",
      "epoch:23 step:108740[D loss: 0.999979] [G loss: 1.000180]\n",
      "epoch:23 step:108745[D loss: 1.000038] [G loss: 1.000083]\n",
      "epoch:23 step:108750[D loss: 0.999970] [G loss: 1.000106]\n",
      "epoch:23 step:108755[D loss: 1.000142] [G loss: 0.999999]\n",
      "epoch:23 step:108760[D loss: 0.999917] [G loss: 1.000190]\n",
      "epoch:23 step:108765[D loss: 0.999991] [G loss: 1.000078]\n",
      "epoch:23 step:108770[D loss: 0.999917] [G loss: 1.000183]\n",
      "epoch:23 step:108775[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:23 step:108780[D loss: 0.999994] [G loss: 0.999994]\n",
      "epoch:23 step:108785[D loss: 0.999988] [G loss: 0.999993]\n",
      "epoch:23 step:108790[D loss: 1.000048] [G loss: 1.000001]\n",
      "epoch:23 step:108795[D loss: 0.999946] [G loss: 0.999975]\n",
      "epoch:23 step:108800[D loss: 1.000017] [G loss: 1.000060]\n",
      "epoch:23 step:108805[D loss: 1.000036] [G loss: 0.999929]\n",
      "epoch:23 step:108810[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:23 step:108815[D loss: 0.999971] [G loss: 1.000034]\n",
      "epoch:23 step:108820[D loss: 0.999937] [G loss: 1.000108]\n",
      "epoch:23 step:108825[D loss: 1.000001] [G loss: 1.000083]\n",
      "epoch:23 step:108830[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:23 step:108835[D loss: 0.999905] [G loss: 1.000190]\n",
      "epoch:23 step:108840[D loss: 1.000103] [G loss: 1.000124]\n",
      "epoch:23 step:108845[D loss: 0.999899] [G loss: 1.000129]\n",
      "epoch:23 step:108850[D loss: 0.999928] [G loss: 1.000116]\n",
      "epoch:23 step:108855[D loss: 0.999984] [G loss: 1.000091]\n",
      "epoch:23 step:108860[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:23 step:108865[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:23 step:108870[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:23 step:108875[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:23 step:108880[D loss: 1.000095] [G loss: 1.000001]\n",
      "epoch:23 step:108885[D loss: 1.000073] [G loss: 1.000049]\n",
      "epoch:23 step:108890[D loss: 1.000064] [G loss: 1.000166]\n",
      "epoch:23 step:108895[D loss: 0.999914] [G loss: 1.000169]\n",
      "epoch:23 step:108900[D loss: 0.999879] [G loss: 1.000129]\n",
      "epoch:23 step:108905[D loss: 1.000013] [G loss: 1.000099]\n",
      "epoch:23 step:108910[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:23 step:108915[D loss: 0.999925] [G loss: 1.000156]\n",
      "epoch:23 step:108920[D loss: 0.999971] [G loss: 1.000164]\n",
      "epoch:23 step:108925[D loss: 0.999979] [G loss: 1.000156]\n",
      "epoch:23 step:108930[D loss: 0.999989] [G loss: 1.000144]\n",
      "epoch:23 step:108935[D loss: 0.999981] [G loss: 1.000066]\n",
      "epoch:23 step:108940[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:23 step:108945[D loss: 1.000042] [G loss: 0.999973]\n",
      "epoch:23 step:108950[D loss: 1.000005] [G loss: 1.000008]\n",
      "epoch:23 step:108955[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:23 step:108960[D loss: 1.000018] [G loss: 1.000033]\n",
      "epoch:23 step:108965[D loss: 0.999971] [G loss: 1.000184]\n",
      "epoch:23 step:108970[D loss: 0.999849] [G loss: 1.000246]\n",
      "epoch:23 step:108975[D loss: 1.000042] [G loss: 1.000105]\n",
      "epoch:23 step:108980[D loss: 0.999946] [G loss: 1.000123]\n",
      "epoch:23 step:108985[D loss: 0.999924] [G loss: 1.000167]\n",
      "epoch:23 step:108990[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:23 step:108995[D loss: 0.999998] [G loss: 1.000016]\n",
      "epoch:23 step:109000[D loss: 0.999950] [G loss: 1.000027]\n",
      "epoch:23 step:109005[D loss: 1.000017] [G loss: 0.999998]\n",
      "epoch:23 step:109010[D loss: 1.000067] [G loss: 0.999917]\n",
      "epoch:23 step:109015[D loss: 0.999917] [G loss: 1.000090]\n",
      "epoch:23 step:109020[D loss: 0.999989] [G loss: 1.000106]\n",
      "epoch:23 step:109025[D loss: 0.999952] [G loss: 1.000096]\n",
      "epoch:23 step:109030[D loss: 0.999949] [G loss: 1.000108]\n",
      "epoch:23 step:109035[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:23 step:109040[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:23 step:109045[D loss: 0.999974] [G loss: 1.000115]\n",
      "epoch:23 step:109050[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:23 step:109055[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:23 step:109060[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:23 step:109065[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:23 step:109070[D loss: 1.000010] [G loss: 1.000062]\n",
      "epoch:23 step:109075[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:23 step:109080[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:23 step:109085[D loss: 0.999954] [G loss: 1.000131]\n",
      "epoch:23 step:109090[D loss: 0.999944] [G loss: 1.000109]\n",
      "epoch:23 step:109095[D loss: 0.999996] [G loss: 1.000035]\n",
      "epoch:23 step:109100[D loss: 0.999983] [G loss: 1.000008]\n",
      "epoch:23 step:109105[D loss: 0.999996] [G loss: 1.000077]\n",
      "epoch:23 step:109110[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:23 step:109115[D loss: 1.000009] [G loss: 1.000085]\n",
      "epoch:23 step:109120[D loss: 0.999991] [G loss: 1.000093]\n",
      "epoch:23 step:109125[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:23 step:109130[D loss: 1.000021] [G loss: 0.999992]\n",
      "epoch:23 step:109135[D loss: 1.000059] [G loss: 0.999977]\n",
      "epoch:23 step:109140[D loss: 0.999988] [G loss: 1.000010]\n",
      "epoch:23 step:109145[D loss: 1.000011] [G loss: 1.000062]\n",
      "epoch:23 step:109150[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:23 step:109155[D loss: 0.999947] [G loss: 1.000141]\n",
      "epoch:23 step:109160[D loss: 0.999981] [G loss: 1.000083]\n",
      "epoch:23 step:109165[D loss: 0.999980] [G loss: 1.000077]\n",
      "epoch:23 step:109170[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:23 step:109175[D loss: 0.999960] [G loss: 1.000085]\n",
      "epoch:23 step:109180[D loss: 0.999960] [G loss: 1.000102]\n",
      "epoch:23 step:109185[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:23 step:109190[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:23 step:109195[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:23 step:109200[D loss: 1.000004] [G loss: 1.000002]\n",
      "epoch:23 step:109205[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:23 step:109210[D loss: 0.999979] [G loss: 1.000042]\n",
      "epoch:23 step:109215[D loss: 0.999988] [G loss: 1.000039]\n",
      "epoch:23 step:109220[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:23 step:109225[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:23 step:109230[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:23 step:109235[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:23 step:109240[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:23 step:109245[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:23 step:109250[D loss: 0.999979] [G loss: 1.000085]\n",
      "epoch:23 step:109255[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:23 step:109260[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:23 step:109265[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:23 step:109270[D loss: 1.000013] [G loss: 1.000037]\n",
      "epoch:23 step:109275[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:23 step:109280[D loss: 1.000019] [G loss: 1.000059]\n",
      "epoch:23 step:109285[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:23 step:109290[D loss: 0.999951] [G loss: 1.000079]\n",
      "epoch:23 step:109295[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:23 step:109300[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:23 step:109305[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:23 step:109310[D loss: 1.000013] [G loss: 1.000112]\n",
      "epoch:23 step:109315[D loss: 0.999939] [G loss: 1.000112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:109320[D loss: 0.999953] [G loss: 1.000096]\n",
      "epoch:23 step:109325[D loss: 0.999934] [G loss: 1.000118]\n",
      "epoch:23 step:109330[D loss: 1.000010] [G loss: 1.000071]\n",
      "epoch:23 step:109335[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:23 step:109340[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:23 step:109345[D loss: 1.000011] [G loss: 0.999971]\n",
      "epoch:23 step:109350[D loss: 0.999982] [G loss: 0.999990]\n",
      "epoch:23 step:109355[D loss: 1.000018] [G loss: 0.999979]\n",
      "epoch:23 step:109360[D loss: 1.000007] [G loss: 1.000071]\n",
      "epoch:23 step:109365[D loss: 0.999975] [G loss: 1.000121]\n",
      "epoch:23 step:109370[D loss: 1.000078] [G loss: 0.999971]\n",
      "epoch:23 step:109375[D loss: 0.999955] [G loss: 1.000052]\n",
      "epoch:23 step:109380[D loss: 0.999940] [G loss: 1.000088]\n",
      "epoch:23 step:109385[D loss: 0.999934] [G loss: 1.000040]\n",
      "epoch:23 step:109390[D loss: 1.000037] [G loss: 0.999940]\n",
      "epoch:23 step:109395[D loss: 0.999966] [G loss: 1.000007]\n",
      "epoch:23 step:109400[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:23 step:109405[D loss: 0.999951] [G loss: 1.000052]\n",
      "epoch:23 step:109410[D loss: 0.999944] [G loss: 1.000037]\n",
      "epoch:23 step:109415[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:23 step:109420[D loss: 0.999968] [G loss: 1.000115]\n",
      "epoch:23 step:109425[D loss: 0.999947] [G loss: 1.000080]\n",
      "epoch:23 step:109430[D loss: 0.999937] [G loss: 1.000126]\n",
      "epoch:23 step:109435[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:23 step:109440[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:23 step:109445[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:23 step:109450[D loss: 0.999974] [G loss: 1.000040]\n",
      "epoch:23 step:109455[D loss: 0.999957] [G loss: 1.000021]\n",
      "epoch:23 step:109460[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:23 step:109465[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:23 step:109470[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:23 step:109475[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:23 step:109480[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:23 step:109485[D loss: 1.000060] [G loss: 0.999965]\n",
      "epoch:23 step:109490[D loss: 0.999933] [G loss: 1.000076]\n",
      "epoch:23 step:109495[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:23 step:109500[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:23 step:109505[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:23 step:109510[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:23 step:109515[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:23 step:109520[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:23 step:109525[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:23 step:109530[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:23 step:109535[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:23 step:109540[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:23 step:109545[D loss: 1.000020] [G loss: 1.000019]\n",
      "epoch:23 step:109550[D loss: 0.999950] [G loss: 1.000065]\n",
      "epoch:23 step:109555[D loss: 1.000002] [G loss: 1.000075]\n",
      "epoch:23 step:109560[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:23 step:109565[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:23 step:109570[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:23 step:109575[D loss: 1.000058] [G loss: 0.999968]\n",
      "epoch:23 step:109580[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:23 step:109585[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:23 step:109590[D loss: 0.999968] [G loss: 1.000196]\n",
      "epoch:23 step:109595[D loss: 0.999930] [G loss: 1.000195]\n",
      "epoch:23 step:109600[D loss: 0.999972] [G loss: 1.000111]\n",
      "epoch:23 step:109605[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:23 step:109610[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:23 step:109615[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:23 step:109620[D loss: 1.000022] [G loss: 0.999985]\n",
      "epoch:23 step:109625[D loss: 0.999943] [G loss: 1.000053]\n",
      "epoch:23 step:109630[D loss: 0.999927] [G loss: 1.000153]\n",
      "epoch:23 step:109635[D loss: 1.000012] [G loss: 1.000065]\n",
      "epoch:23 step:109640[D loss: 0.999988] [G loss: 1.000102]\n",
      "epoch:23 step:109645[D loss: 1.000118] [G loss: 0.999959]\n",
      "epoch:23 step:109650[D loss: 0.999857] [G loss: 1.000191]\n",
      "epoch:23 step:109655[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:23 step:109660[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:23 step:109665[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:23 step:109670[D loss: 1.000047] [G loss: 0.999922]\n",
      "epoch:23 step:109675[D loss: 1.000009] [G loss: 0.999924]\n",
      "epoch:23 step:109680[D loss: 1.000113] [G loss: 0.999977]\n",
      "epoch:23 step:109685[D loss: 0.999988] [G loss: 0.999931]\n",
      "epoch:23 step:109690[D loss: 1.000026] [G loss: 1.000117]\n",
      "epoch:23 step:109695[D loss: 0.999990] [G loss: 1.000087]\n",
      "epoch:23 step:109700[D loss: 0.999919] [G loss: 1.000080]\n",
      "epoch:23 step:109705[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:23 step:109710[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:23 step:109715[D loss: 1.000015] [G loss: 1.000020]\n",
      "epoch:23 step:109720[D loss: 1.000007] [G loss: 1.000027]\n",
      "epoch:23 step:109725[D loss: 0.999982] [G loss: 1.000090]\n",
      "epoch:23 step:109730[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:23 step:109735[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:23 step:109740[D loss: 1.000056] [G loss: 0.999922]\n",
      "epoch:23 step:109745[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:23 step:109750[D loss: 0.999977] [G loss: 1.000094]\n",
      "epoch:23 step:109755[D loss: 1.000089] [G loss: 0.999838]\n",
      "epoch:23 step:109760[D loss: 1.000059] [G loss: 1.000010]\n",
      "epoch:23 step:109765[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:23 step:109770[D loss: 0.999881] [G loss: 1.000264]\n",
      "epoch:23 step:109775[D loss: 0.999917] [G loss: 1.000128]\n",
      "epoch:23 step:109780[D loss: 0.999949] [G loss: 1.000066]\n",
      "epoch:23 step:109785[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:23 step:109790[D loss: 0.999997] [G loss: 1.000006]\n",
      "epoch:23 step:109795[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:23 step:109800[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:23 step:109805[D loss: 1.000010] [G loss: 1.000092]\n",
      "epoch:23 step:109810[D loss: 0.999983] [G loss: 1.000010]\n",
      "epoch:23 step:109815[D loss: 0.999963] [G loss: 1.000044]\n",
      "epoch:23 step:109820[D loss: 0.999922] [G loss: 1.000106]\n",
      "epoch:23 step:109825[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:23 step:109830[D loss: 1.000054] [G loss: 0.999977]\n",
      "epoch:23 step:109835[D loss: 1.000013] [G loss: 1.000014]\n",
      "epoch:23 step:109840[D loss: 0.999952] [G loss: 1.000106]\n",
      "epoch:23 step:109845[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:23 step:109850[D loss: 0.999947] [G loss: 1.000087]\n",
      "epoch:23 step:109855[D loss: 0.999970] [G loss: 1.000072]\n",
      "epoch:23 step:109860[D loss: 0.999968] [G loss: 1.000091]\n",
      "epoch:23 step:109865[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:23 step:109870[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:23 step:109875[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:23 step:109880[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:23 step:109885[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:23 step:109890[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:23 step:109895[D loss: 1.000013] [G loss: 1.000076]\n",
      "epoch:23 step:109900[D loss: 1.000046] [G loss: 0.999968]\n",
      "epoch:23 step:109905[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:23 step:109910[D loss: 0.999904] [G loss: 1.000127]\n",
      "epoch:23 step:109915[D loss: 0.999989] [G loss: 1.000127]\n",
      "epoch:23 step:109920[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:23 step:109925[D loss: 1.000004] [G loss: 1.000050]\n",
      "epoch:23 step:109930[D loss: 0.999960] [G loss: 1.000058]\n",
      "epoch:23 step:109935[D loss: 1.000015] [G loss: 1.000040]\n",
      "epoch:23 step:109940[D loss: 0.999993] [G loss: 0.999975]\n",
      "epoch:23 step:109945[D loss: 0.999945] [G loss: 1.000107]\n",
      "epoch:23 step:109950[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:23 step:109955[D loss: 0.999953] [G loss: 1.000140]\n",
      "epoch:23 step:109960[D loss: 0.999936] [G loss: 1.000105]\n",
      "epoch:23 step:109965[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:23 step:109970[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:23 step:109975[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:23 step:109980[D loss: 0.999983] [G loss: 1.000067]\n",
      "epoch:23 step:109985[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:23 step:109990[D loss: 1.000011] [G loss: 1.000046]\n",
      "epoch:23 step:109995[D loss: 0.999970] [G loss: 1.000135]\n",
      "epoch:23 step:110000[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:23 step:110005[D loss: 0.999954] [G loss: 1.000122]\n",
      "epoch:23 step:110010[D loss: 0.999966] [G loss: 1.000056]\n",
      "epoch:23 step:110015[D loss: 0.999986] [G loss: 1.000032]\n",
      "epoch:23 step:110020[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:23 step:110025[D loss: 1.000029] [G loss: 0.999965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:110030[D loss: 0.999952] [G loss: 1.000104]\n",
      "epoch:23 step:110035[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:23 step:110040[D loss: 1.000016] [G loss: 1.000019]\n",
      "epoch:23 step:110045[D loss: 0.999993] [G loss: 1.000138]\n",
      "epoch:23 step:110050[D loss: 1.000125] [G loss: 1.000099]\n",
      "epoch:23 step:110055[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:23 step:110060[D loss: 0.999935] [G loss: 1.000092]\n",
      "epoch:23 step:110065[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:23 step:110070[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:23 step:110075[D loss: 0.999986] [G loss: 1.000037]\n",
      "epoch:23 step:110080[D loss: 1.000013] [G loss: 0.999954]\n",
      "epoch:23 step:110085[D loss: 0.999928] [G loss: 1.000052]\n",
      "epoch:23 step:110090[D loss: 0.999994] [G loss: 1.000020]\n",
      "epoch:23 step:110095[D loss: 1.000038] [G loss: 1.000040]\n",
      "epoch:23 step:110100[D loss: 0.999990] [G loss: 1.000148]\n",
      "epoch:23 step:110105[D loss: 0.999957] [G loss: 1.000125]\n",
      "epoch:23 step:110110[D loss: 0.999934] [G loss: 1.000161]\n",
      "epoch:23 step:110115[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:23 step:110120[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:23 step:110125[D loss: 0.999997] [G loss: 0.999968]\n",
      "epoch:23 step:110130[D loss: 1.000004] [G loss: 0.999913]\n",
      "epoch:23 step:110135[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:23 step:110140[D loss: 0.999905] [G loss: 1.000063]\n",
      "epoch:23 step:110145[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:23 step:110150[D loss: 0.999997] [G loss: 1.000057]\n",
      "epoch:23 step:110155[D loss: 0.999940] [G loss: 1.000092]\n",
      "epoch:23 step:110160[D loss: 1.000024] [G loss: 1.000000]\n",
      "epoch:23 step:110165[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:23 step:110170[D loss: 0.999955] [G loss: 1.000111]\n",
      "epoch:23 step:110175[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:23 step:110180[D loss: 1.000050] [G loss: 0.999961]\n",
      "epoch:23 step:110185[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:23 step:110190[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:23 step:110195[D loss: 1.000007] [G loss: 1.000103]\n",
      "epoch:23 step:110200[D loss: 0.999982] [G loss: 1.000138]\n",
      "epoch:23 step:110205[D loss: 1.000007] [G loss: 1.000122]\n",
      "epoch:23 step:110210[D loss: 0.999916] [G loss: 1.000133]\n",
      "epoch:23 step:110215[D loss: 0.999977] [G loss: 1.000161]\n",
      "epoch:23 step:110220[D loss: 1.000013] [G loss: 1.000178]\n",
      "epoch:23 step:110225[D loss: 0.999984] [G loss: 1.000194]\n",
      "epoch:23 step:110230[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:23 step:110235[D loss: 1.000070] [G loss: 1.000108]\n",
      "epoch:23 step:110240[D loss: 1.000006] [G loss: 1.000083]\n",
      "epoch:23 step:110245[D loss: 1.000014] [G loss: 0.999989]\n",
      "epoch:23 step:110250[D loss: 1.000075] [G loss: 0.999925]\n",
      "epoch:23 step:110255[D loss: 1.000061] [G loss: 0.999903]\n",
      "epoch:23 step:110260[D loss: 0.999882] [G loss: 1.000054]\n",
      "epoch:23 step:110265[D loss: 1.000007] [G loss: 1.000012]\n",
      "epoch:23 step:110270[D loss: 1.000017] [G loss: 1.000045]\n",
      "epoch:23 step:110275[D loss: 1.000006] [G loss: 1.000009]\n",
      "epoch:23 step:110280[D loss: 0.999962] [G loss: 1.000143]\n",
      "epoch:23 step:110285[D loss: 0.999931] [G loss: 1.000123]\n",
      "epoch:23 step:110290[D loss: 1.000056] [G loss: 1.000025]\n",
      "epoch:23 step:110295[D loss: 0.999955] [G loss: 1.000242]\n",
      "epoch:23 step:110300[D loss: 0.999953] [G loss: 1.000183]\n",
      "epoch:23 step:110305[D loss: 1.000100] [G loss: 1.000111]\n",
      "epoch:23 step:110310[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:23 step:110315[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:23 step:110320[D loss: 1.000039] [G loss: 0.999939]\n",
      "epoch:23 step:110325[D loss: 0.999966] [G loss: 1.000010]\n",
      "epoch:23 step:110330[D loss: 0.999994] [G loss: 0.999925]\n",
      "epoch:23 step:110335[D loss: 0.999928] [G loss: 1.000100]\n",
      "epoch:23 step:110340[D loss: 1.000078] [G loss: 1.000114]\n",
      "epoch:23 step:110345[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:23 step:110350[D loss: 0.999939] [G loss: 1.000097]\n",
      "epoch:23 step:110355[D loss: 0.999985] [G loss: 1.000079]\n",
      "epoch:23 step:110360[D loss: 0.999899] [G loss: 1.000194]\n",
      "epoch:23 step:110365[D loss: 0.999983] [G loss: 1.000097]\n",
      "epoch:23 step:110370[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:23 step:110375[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:23 step:110380[D loss: 0.999948] [G loss: 1.000115]\n",
      "epoch:23 step:110385[D loss: 0.999967] [G loss: 1.000099]\n",
      "epoch:23 step:110390[D loss: 0.999913] [G loss: 1.000126]\n",
      "epoch:23 step:110395[D loss: 0.999955] [G loss: 1.000146]\n",
      "epoch:23 step:110400[D loss: 1.000037] [G loss: 0.999928]\n",
      "epoch:23 step:110405[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:23 step:110410[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:23 step:110415[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:23 step:110420[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:23 step:110425[D loss: 1.000006] [G loss: 1.000068]\n",
      "epoch:23 step:110430[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:23 step:110435[D loss: 1.000059] [G loss: 1.000020]\n",
      "epoch:23 step:110440[D loss: 1.000063] [G loss: 1.000005]\n",
      "epoch:23 step:110445[D loss: 1.000035] [G loss: 1.000013]\n",
      "epoch:23 step:110450[D loss: 1.000054] [G loss: 0.999955]\n",
      "epoch:23 step:110455[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:23 step:110460[D loss: 0.999957] [G loss: 1.000149]\n",
      "epoch:23 step:110465[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:23 step:110470[D loss: 0.999998] [G loss: 1.000006]\n",
      "epoch:23 step:110475[D loss: 1.000004] [G loss: 0.999993]\n",
      "epoch:23 step:110480[D loss: 1.000033] [G loss: 0.999958]\n",
      "epoch:23 step:110485[D loss: 1.000079] [G loss: 0.999855]\n",
      "epoch:23 step:110490[D loss: 0.999933] [G loss: 1.000050]\n",
      "epoch:23 step:110495[D loss: 1.000002] [G loss: 1.000026]\n",
      "epoch:23 step:110500[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:23 step:110505[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:23 step:110510[D loss: 0.999895] [G loss: 1.000184]\n",
      "epoch:23 step:110515[D loss: 0.999961] [G loss: 1.000097]\n",
      "epoch:23 step:110520[D loss: 0.999989] [G loss: 1.000035]\n",
      "epoch:23 step:110525[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:23 step:110530[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:23 step:110535[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:23 step:110540[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:23 step:110545[D loss: 1.000016] [G loss: 1.000031]\n",
      "epoch:23 step:110550[D loss: 1.000033] [G loss: 1.000004]\n",
      "epoch:23 step:110555[D loss: 0.999981] [G loss: 1.000040]\n",
      "epoch:23 step:110560[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:23 step:110565[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:23 step:110570[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:23 step:110575[D loss: 0.999920] [G loss: 1.000102]\n",
      "epoch:23 step:110580[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:23 step:110585[D loss: 0.999959] [G loss: 1.000077]\n",
      "epoch:23 step:110590[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:23 step:110595[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:23 step:110600[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:23 step:110605[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:23 step:110610[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:23 step:110615[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:23 step:110620[D loss: 1.000097] [G loss: 0.999906]\n",
      "epoch:23 step:110625[D loss: 0.999992] [G loss: 1.000032]\n",
      "epoch:23 step:110630[D loss: 1.000104] [G loss: 0.999968]\n",
      "epoch:23 step:110635[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:23 step:110640[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:23 step:110645[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:23 step:110650[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:23 step:110655[D loss: 1.000043] [G loss: 1.000007]\n",
      "epoch:23 step:110660[D loss: 0.999966] [G loss: 1.000065]\n",
      "epoch:23 step:110665[D loss: 0.999977] [G loss: 1.000081]\n",
      "epoch:23 step:110670[D loss: 1.000016] [G loss: 0.999980]\n",
      "epoch:23 step:110675[D loss: 0.999978] [G loss: 1.000066]\n",
      "epoch:23 step:110680[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:23 step:110685[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:23 step:110690[D loss: 0.999935] [G loss: 1.000086]\n",
      "epoch:23 step:110695[D loss: 1.000039] [G loss: 1.000058]\n",
      "epoch:23 step:110700[D loss: 1.000056] [G loss: 1.000212]\n",
      "epoch:23 step:110705[D loss: 0.999826] [G loss: 1.000206]\n",
      "epoch:23 step:110710[D loss: 0.999950] [G loss: 1.000102]\n",
      "epoch:23 step:110715[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:23 step:110720[D loss: 1.000046] [G loss: 1.000052]\n",
      "epoch:23 step:110725[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:23 step:110730[D loss: 1.000038] [G loss: 1.000152]\n",
      "epoch:23 step:110735[D loss: 0.999926] [G loss: 1.000203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:110740[D loss: 0.999919] [G loss: 1.000134]\n",
      "epoch:23 step:110745[D loss: 0.999927] [G loss: 1.000121]\n",
      "epoch:23 step:110750[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:23 step:110755[D loss: 0.999969] [G loss: 1.000141]\n",
      "epoch:23 step:110760[D loss: 1.000007] [G loss: 1.000001]\n",
      "epoch:23 step:110765[D loss: 1.000017] [G loss: 1.000020]\n",
      "epoch:23 step:110770[D loss: 0.999930] [G loss: 1.000076]\n",
      "epoch:23 step:110775[D loss: 1.000005] [G loss: 0.999967]\n",
      "epoch:23 step:110780[D loss: 0.999954] [G loss: 0.999995]\n",
      "epoch:23 step:110785[D loss: 0.999944] [G loss: 1.000051]\n",
      "epoch:23 step:110790[D loss: 1.000017] [G loss: 0.999983]\n",
      "epoch:23 step:110795[D loss: 1.000025] [G loss: 0.999982]\n",
      "epoch:23 step:110800[D loss: 1.000094] [G loss: 0.999965]\n",
      "epoch:23 step:110805[D loss: 0.999940] [G loss: 1.000070]\n",
      "epoch:23 step:110810[D loss: 0.999903] [G loss: 1.000112]\n",
      "epoch:23 step:110815[D loss: 0.999985] [G loss: 1.000114]\n",
      "epoch:23 step:110820[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:23 step:110825[D loss: 0.999951] [G loss: 1.000079]\n",
      "epoch:23 step:110830[D loss: 1.000006] [G loss: 1.000013]\n",
      "epoch:23 step:110835[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:23 step:110840[D loss: 1.000032] [G loss: 1.000021]\n",
      "epoch:23 step:110845[D loss: 1.000064] [G loss: 1.000021]\n",
      "epoch:23 step:110850[D loss: 0.999909] [G loss: 1.000103]\n",
      "epoch:23 step:110855[D loss: 1.000001] [G loss: 1.000118]\n",
      "epoch:23 step:110860[D loss: 0.999946] [G loss: 1.000126]\n",
      "epoch:23 step:110865[D loss: 1.000075] [G loss: 0.999888]\n",
      "epoch:23 step:110870[D loss: 0.999945] [G loss: 1.000081]\n",
      "epoch:23 step:110875[D loss: 0.999973] [G loss: 1.000114]\n",
      "epoch:23 step:110880[D loss: 0.999979] [G loss: 1.000130]\n",
      "epoch:23 step:110885[D loss: 0.999946] [G loss: 1.000116]\n",
      "epoch:23 step:110890[D loss: 1.000019] [G loss: 0.999979]\n",
      "epoch:23 step:110895[D loss: 0.999961] [G loss: 1.000034]\n",
      "epoch:23 step:110900[D loss: 0.999928] [G loss: 1.000081]\n",
      "epoch:23 step:110905[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:23 step:110910[D loss: 0.999994] [G loss: 1.000160]\n",
      "epoch:23 step:110915[D loss: 1.000050] [G loss: 1.000095]\n",
      "epoch:23 step:110920[D loss: 0.999899] [G loss: 1.000206]\n",
      "epoch:23 step:110925[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:23 step:110930[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:23 step:110935[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:23 step:110940[D loss: 1.000022] [G loss: 1.000043]\n",
      "epoch:23 step:110945[D loss: 0.999934] [G loss: 1.000016]\n",
      "epoch:23 step:110950[D loss: 0.999953] [G loss: 0.999970]\n",
      "epoch:23 step:110955[D loss: 1.000053] [G loss: 0.999988]\n",
      "epoch:23 step:110960[D loss: 1.000059] [G loss: 1.000002]\n",
      "epoch:23 step:110965[D loss: 0.999982] [G loss: 1.000018]\n",
      "epoch:23 step:110970[D loss: 0.999878] [G loss: 1.000113]\n",
      "epoch:23 step:110975[D loss: 0.999946] [G loss: 1.000054]\n",
      "epoch:23 step:110980[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:23 step:110985[D loss: 1.000011] [G loss: 0.999977]\n",
      "epoch:23 step:110990[D loss: 0.999954] [G loss: 1.000037]\n",
      "epoch:23 step:110995[D loss: 0.999983] [G loss: 1.000023]\n",
      "epoch:23 step:111000[D loss: 1.000042] [G loss: 0.999991]\n",
      "epoch:23 step:111005[D loss: 0.999902] [G loss: 1.000154]\n",
      "epoch:23 step:111010[D loss: 1.000084] [G loss: 1.000006]\n",
      "epoch:23 step:111015[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:23 step:111020[D loss: 0.999950] [G loss: 1.000117]\n",
      "epoch:23 step:111025[D loss: 0.999957] [G loss: 1.000121]\n",
      "epoch:23 step:111030[D loss: 0.999958] [G loss: 1.000121]\n",
      "epoch:23 step:111035[D loss: 0.999960] [G loss: 1.000088]\n",
      "epoch:23 step:111040[D loss: 0.999971] [G loss: 1.000098]\n",
      "epoch:23 step:111045[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:23 step:111050[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:23 step:111055[D loss: 0.999948] [G loss: 1.000088]\n",
      "epoch:23 step:111060[D loss: 0.999952] [G loss: 1.000141]\n",
      "epoch:23 step:111065[D loss: 0.999997] [G loss: 1.000125]\n",
      "epoch:23 step:111070[D loss: 1.000040] [G loss: 1.000009]\n",
      "epoch:23 step:111075[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:23 step:111080[D loss: 1.000013] [G loss: 1.000020]\n",
      "epoch:23 step:111085[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:23 step:111090[D loss: 0.999954] [G loss: 1.000016]\n",
      "epoch:23 step:111095[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:23 step:111100[D loss: 0.999984] [G loss: 1.000020]\n",
      "epoch:23 step:111105[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:23 step:111110[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:23 step:111115[D loss: 1.000004] [G loss: 1.000069]\n",
      "epoch:23 step:111120[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:23 step:111125[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:23 step:111130[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:23 step:111135[D loss: 1.000000] [G loss: 1.000025]\n",
      "epoch:23 step:111140[D loss: 1.000074] [G loss: 0.999881]\n",
      "epoch:23 step:111145[D loss: 1.000004] [G loss: 1.000082]\n",
      "epoch:23 step:111150[D loss: 0.999986] [G loss: 1.000130]\n",
      "epoch:23 step:111155[D loss: 1.000062] [G loss: 0.999984]\n",
      "epoch:23 step:111160[D loss: 0.999902] [G loss: 1.000138]\n",
      "epoch:23 step:111165[D loss: 1.000084] [G loss: 1.000052]\n",
      "epoch:23 step:111170[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:23 step:111175[D loss: 0.999996] [G loss: 0.999980]\n",
      "epoch:23 step:111180[D loss: 1.000123] [G loss: 0.999782]\n",
      "epoch:23 step:111185[D loss: 1.000061] [G loss: 0.999802]\n",
      "epoch:23 step:111190[D loss: 1.000005] [G loss: 0.999944]\n",
      "epoch:23 step:111195[D loss: 0.999964] [G loss: 1.000003]\n",
      "epoch:23 step:111200[D loss: 1.000066] [G loss: 1.000020]\n",
      "epoch:23 step:111205[D loss: 0.999944] [G loss: 1.000070]\n",
      "epoch:23 step:111210[D loss: 0.999931] [G loss: 1.000080]\n",
      "epoch:23 step:111215[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:23 step:111220[D loss: 0.999984] [G loss: 1.000116]\n",
      "epoch:23 step:111225[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:23 step:111230[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:23 step:111235[D loss: 0.999939] [G loss: 1.000101]\n",
      "epoch:23 step:111240[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:23 step:111245[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:23 step:111250[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:23 step:111255[D loss: 0.999989] [G loss: 1.000077]\n",
      "epoch:23 step:111260[D loss: 0.999982] [G loss: 1.000078]\n",
      "epoch:23 step:111265[D loss: 0.999964] [G loss: 1.000109]\n",
      "epoch:23 step:111270[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:23 step:111275[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:23 step:111280[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:23 step:111285[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:23 step:111290[D loss: 0.999984] [G loss: 1.000000]\n",
      "epoch:23 step:111295[D loss: 0.999935] [G loss: 1.000137]\n",
      "epoch:23 step:111300[D loss: 1.000049] [G loss: 1.000031]\n",
      "epoch:23 step:111305[D loss: 1.000061] [G loss: 0.999951]\n",
      "epoch:23 step:111310[D loss: 1.000075] [G loss: 0.999898]\n",
      "epoch:23 step:111315[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:23 step:111320[D loss: 0.999903] [G loss: 1.000154]\n",
      "epoch:23 step:111325[D loss: 0.999992] [G loss: 1.000145]\n",
      "epoch:23 step:111330[D loss: 1.000020] [G loss: 1.000037]\n",
      "epoch:23 step:111335[D loss: 0.999971] [G loss: 1.000032]\n",
      "epoch:23 step:111340[D loss: 1.000000] [G loss: 1.000019]\n",
      "epoch:23 step:111345[D loss: 0.999990] [G loss: 0.999992]\n",
      "epoch:23 step:111350[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:23 step:111355[D loss: 0.999982] [G loss: 1.000094]\n",
      "epoch:23 step:111360[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:23 step:111365[D loss: 1.000029] [G loss: 1.000053]\n",
      "epoch:23 step:111370[D loss: 0.999982] [G loss: 1.000155]\n",
      "epoch:23 step:111375[D loss: 0.999931] [G loss: 1.000151]\n",
      "epoch:23 step:111380[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:23 step:111385[D loss: 0.999987] [G loss: 1.000012]\n",
      "epoch:23 step:111390[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:23 step:111395[D loss: 1.000025] [G loss: 0.999932]\n",
      "epoch:23 step:111400[D loss: 0.999967] [G loss: 0.999980]\n",
      "epoch:23 step:111405[D loss: 0.999959] [G loss: 0.999998]\n",
      "epoch:23 step:111410[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:23 step:111415[D loss: 1.000017] [G loss: 0.999986]\n",
      "epoch:23 step:111420[D loss: 0.999968] [G loss: 1.000030]\n",
      "epoch:23 step:111425[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:23 step:111430[D loss: 0.999935] [G loss: 1.000087]\n",
      "epoch:23 step:111435[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:23 step:111440[D loss: 1.000052] [G loss: 1.000020]\n",
      "epoch:23 step:111445[D loss: 0.999922] [G loss: 1.000161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:111450[D loss: 1.000009] [G loss: 1.000180]\n",
      "epoch:23 step:111455[D loss: 1.000081] [G loss: 1.000036]\n",
      "epoch:23 step:111460[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:23 step:111465[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:23 step:111470[D loss: 0.999946] [G loss: 1.000068]\n",
      "epoch:23 step:111475[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:23 step:111480[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:23 step:111485[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:23 step:111490[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:23 step:111495[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:23 step:111500[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:23 step:111505[D loss: 1.000026] [G loss: 1.000054]\n",
      "epoch:23 step:111510[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:23 step:111515[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:23 step:111520[D loss: 0.999912] [G loss: 1.000163]\n",
      "epoch:23 step:111525[D loss: 1.000069] [G loss: 0.999995]\n",
      "epoch:23 step:111530[D loss: 0.999967] [G loss: 1.000154]\n",
      "epoch:23 step:111535[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:23 step:111540[D loss: 1.000014] [G loss: 0.999985]\n",
      "epoch:23 step:111545[D loss: 1.000040] [G loss: 0.999935]\n",
      "epoch:23 step:111550[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:23 step:111555[D loss: 0.999930] [G loss: 1.000117]\n",
      "epoch:23 step:111560[D loss: 0.999946] [G loss: 1.000162]\n",
      "epoch:23 step:111565[D loss: 1.000020] [G loss: 1.000139]\n",
      "epoch:23 step:111570[D loss: 0.999956] [G loss: 1.000064]\n",
      "epoch:23 step:111575[D loss: 0.999984] [G loss: 1.000112]\n",
      "epoch:23 step:111580[D loss: 0.999898] [G loss: 1.000164]\n",
      "epoch:23 step:111585[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:23 step:111590[D loss: 0.999986] [G loss: 1.000074]\n",
      "epoch:23 step:111595[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:23 step:111600[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:23 step:111605[D loss: 0.999965] [G loss: 1.000062]\n",
      "epoch:23 step:111610[D loss: 1.000052] [G loss: 0.999965]\n",
      "epoch:23 step:111615[D loss: 1.000023] [G loss: 0.999981]\n",
      "epoch:23 step:111620[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:23 step:111625[D loss: 0.999870] [G loss: 1.000339]\n",
      "epoch:23 step:111630[D loss: 0.999946] [G loss: 1.000060]\n",
      "epoch:23 step:111635[D loss: 0.999877] [G loss: 1.000222]\n",
      "epoch:23 step:111640[D loss: 0.999943] [G loss: 1.000066]\n",
      "epoch:23 step:111645[D loss: 1.000015] [G loss: 0.999991]\n",
      "epoch:23 step:111650[D loss: 1.000005] [G loss: 1.000018]\n",
      "epoch:23 step:111655[D loss: 1.000034] [G loss: 0.999932]\n",
      "epoch:23 step:111660[D loss: 0.999939] [G loss: 1.000050]\n",
      "epoch:23 step:111665[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:23 step:111670[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:23 step:111675[D loss: 0.999930] [G loss: 1.000142]\n",
      "epoch:23 step:111680[D loss: 0.999950] [G loss: 1.000106]\n",
      "epoch:23 step:111685[D loss: 1.000012] [G loss: 1.000065]\n",
      "epoch:23 step:111690[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:23 step:111695[D loss: 1.000009] [G loss: 1.000086]\n",
      "epoch:23 step:111700[D loss: 1.000064] [G loss: 0.999983]\n",
      "epoch:23 step:111705[D loss: 0.999959] [G loss: 1.000062]\n",
      "epoch:23 step:111710[D loss: 1.000036] [G loss: 0.999915]\n",
      "epoch:23 step:111715[D loss: 0.999980] [G loss: 1.000010]\n",
      "epoch:23 step:111720[D loss: 0.999961] [G loss: 1.000028]\n",
      "epoch:23 step:111725[D loss: 0.999994] [G loss: 1.000011]\n",
      "epoch:23 step:111730[D loss: 1.000116] [G loss: 0.999918]\n",
      "epoch:23 step:111735[D loss: 0.999989] [G loss: 1.000063]\n",
      "epoch:23 step:111740[D loss: 0.999913] [G loss: 1.000199]\n",
      "epoch:23 step:111745[D loss: 0.999992] [G loss: 1.000143]\n",
      "epoch:23 step:111750[D loss: 0.999966] [G loss: 1.000089]\n",
      "epoch:23 step:111755[D loss: 0.999995] [G loss: 0.999996]\n",
      "epoch:23 step:111760[D loss: 1.000042] [G loss: 1.000002]\n",
      "epoch:23 step:111765[D loss: 1.000068] [G loss: 1.000028]\n",
      "epoch:23 step:111770[D loss: 0.999936] [G loss: 1.000117]\n",
      "epoch:23 step:111775[D loss: 1.000013] [G loss: 1.000033]\n",
      "epoch:23 step:111780[D loss: 0.999951] [G loss: 1.000195]\n",
      "epoch:23 step:111785[D loss: 0.999954] [G loss: 1.000058]\n",
      "epoch:23 step:111790[D loss: 1.000056] [G loss: 0.999980]\n",
      "epoch:23 step:111795[D loss: 1.000007] [G loss: 1.000200]\n",
      "epoch:23 step:111800[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:23 step:111805[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:23 step:111810[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:23 step:111815[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:23 step:111820[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:23 step:111825[D loss: 1.000005] [G loss: 1.000027]\n",
      "epoch:23 step:111830[D loss: 0.999951] [G loss: 1.000098]\n",
      "epoch:23 step:111835[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:23 step:111840[D loss: 0.999942] [G loss: 1.000092]\n",
      "epoch:23 step:111845[D loss: 0.999996] [G loss: 1.000129]\n",
      "epoch:23 step:111850[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:23 step:111855[D loss: 0.999972] [G loss: 1.000034]\n",
      "epoch:23 step:111860[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:23 step:111865[D loss: 1.000029] [G loss: 0.999979]\n",
      "epoch:23 step:111870[D loss: 0.999893] [G loss: 1.000201]\n",
      "epoch:23 step:111875[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:23 step:111880[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:23 step:111885[D loss: 1.000044] [G loss: 1.000042]\n",
      "epoch:23 step:111890[D loss: 0.999956] [G loss: 1.000042]\n",
      "epoch:23 step:111895[D loss: 0.999959] [G loss: 1.000031]\n",
      "epoch:23 step:111900[D loss: 1.000033] [G loss: 1.000008]\n",
      "epoch:23 step:111905[D loss: 0.999941] [G loss: 1.000058]\n",
      "epoch:23 step:111910[D loss: 1.000005] [G loss: 0.999974]\n",
      "epoch:23 step:111915[D loss: 1.000110] [G loss: 0.999937]\n",
      "epoch:23 step:111920[D loss: 0.999904] [G loss: 1.000082]\n",
      "epoch:23 step:111925[D loss: 0.999991] [G loss: 1.000166]\n",
      "epoch:23 step:111930[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:23 step:111935[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:23 step:111940[D loss: 1.000004] [G loss: 1.000006]\n",
      "epoch:23 step:111945[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:23 step:111950[D loss: 1.000021] [G loss: 1.000056]\n",
      "epoch:23 step:111955[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:23 step:111960[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:23 step:111965[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:23 step:111970[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:23 step:111975[D loss: 0.999949] [G loss: 1.000176]\n",
      "epoch:23 step:111980[D loss: 1.000013] [G loss: 0.999986]\n",
      "epoch:23 step:111985[D loss: 0.999944] [G loss: 1.000095]\n",
      "epoch:23 step:111990[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:23 step:111995[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:23 step:112000[D loss: 0.999993] [G loss: 1.000086]\n",
      "epoch:23 step:112005[D loss: 0.999981] [G loss: 1.000070]\n",
      "epoch:23 step:112010[D loss: 0.999997] [G loss: 1.000001]\n",
      "epoch:23 step:112015[D loss: 0.999949] [G loss: 1.000076]\n",
      "epoch:23 step:112020[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:23 step:112025[D loss: 1.000043] [G loss: 0.999939]\n",
      "epoch:23 step:112030[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:23 step:112035[D loss: 1.000020] [G loss: 1.000120]\n",
      "epoch:23 step:112040[D loss: 0.999952] [G loss: 1.000061]\n",
      "epoch:23 step:112045[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:23 step:112050[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:23 step:112055[D loss: 1.000007] [G loss: 0.999981]\n",
      "epoch:23 step:112060[D loss: 0.999991] [G loss: 1.000021]\n",
      "epoch:23 step:112065[D loss: 1.000005] [G loss: 0.999957]\n",
      "epoch:23 step:112070[D loss: 1.000017] [G loss: 1.000029]\n",
      "epoch:23 step:112075[D loss: 1.000052] [G loss: 0.999972]\n",
      "epoch:23 step:112080[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:23 step:112085[D loss: 0.999946] [G loss: 1.000083]\n",
      "epoch:23 step:112090[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:23 step:112095[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:23 step:112100[D loss: 1.000038] [G loss: 0.999961]\n",
      "epoch:23 step:112105[D loss: 0.999956] [G loss: 1.000152]\n",
      "epoch:23 step:112110[D loss: 0.999956] [G loss: 1.000039]\n",
      "epoch:23 step:112115[D loss: 0.999995] [G loss: 1.000079]\n",
      "epoch:23 step:112120[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:23 step:112125[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:23 step:112130[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:23 step:112135[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:23 step:112140[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:23 step:112145[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:23 step:112150[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:23 step:112155[D loss: 0.999943] [G loss: 1.000083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:112160[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:23 step:112165[D loss: 0.999990] [G loss: 1.000067]\n",
      "epoch:23 step:112170[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:23 step:112175[D loss: 1.000008] [G loss: 1.000005]\n",
      "epoch:23 step:112180[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:23 step:112185[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:23 step:112190[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:23 step:112195[D loss: 0.999973] [G loss: 1.000030]\n",
      "epoch:23 step:112200[D loss: 1.000009] [G loss: 1.000026]\n",
      "epoch:23 step:112205[D loss: 0.999988] [G loss: 1.000032]\n",
      "epoch:23 step:112210[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:23 step:112215[D loss: 0.999972] [G loss: 1.000019]\n",
      "epoch:23 step:112220[D loss: 1.000027] [G loss: 0.999984]\n",
      "epoch:23 step:112225[D loss: 0.999990] [G loss: 1.000131]\n",
      "epoch:23 step:112230[D loss: 0.999944] [G loss: 1.000060]\n",
      "epoch:23 step:112235[D loss: 1.000101] [G loss: 0.999925]\n",
      "epoch:23 step:112240[D loss: 1.000046] [G loss: 0.999946]\n",
      "epoch:23 step:112245[D loss: 0.999956] [G loss: 1.000055]\n",
      "epoch:23 step:112250[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:23 step:112255[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:23 step:112260[D loss: 1.000089] [G loss: 0.999984]\n",
      "epoch:23 step:112265[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:23 step:112270[D loss: 0.999961] [G loss: 1.000053]\n",
      "epoch:23 step:112275[D loss: 1.000067] [G loss: 0.999946]\n",
      "epoch:23 step:112280[D loss: 1.000017] [G loss: 0.999913]\n",
      "epoch:23 step:112285[D loss: 1.000016] [G loss: 1.000094]\n",
      "epoch:23 step:112290[D loss: 0.999915] [G loss: 1.000069]\n",
      "epoch:23 step:112295[D loss: 1.000003] [G loss: 1.000013]\n",
      "epoch:23 step:112300[D loss: 0.999976] [G loss: 0.999987]\n",
      "epoch:23 step:112305[D loss: 0.999971] [G loss: 1.000046]\n",
      "epoch:23 step:112310[D loss: 0.999963] [G loss: 1.000108]\n",
      "epoch:23 step:112315[D loss: 1.000009] [G loss: 0.999994]\n",
      "epoch:23 step:112320[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:23 step:112325[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:23 step:112330[D loss: 0.999989] [G loss: 1.000070]\n",
      "epoch:23 step:112335[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:23 step:112340[D loss: 1.000120] [G loss: 0.999889]\n",
      "epoch:23 step:112345[D loss: 0.999919] [G loss: 1.000080]\n",
      "epoch:23 step:112350[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:23 step:112355[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:23 step:112360[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:23 step:112365[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:23 step:112370[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:23 step:112375[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:23 step:112380[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:23 step:112385[D loss: 0.999991] [G loss: 1.000085]\n",
      "epoch:23 step:112390[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:23 step:112395[D loss: 1.000016] [G loss: 0.999946]\n",
      "epoch:23 step:112400[D loss: 1.000005] [G loss: 0.999992]\n",
      "epoch:23 step:112405[D loss: 0.999980] [G loss: 1.000028]\n",
      "epoch:23 step:112410[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:23 step:112415[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:23 step:112420[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:23 step:112425[D loss: 0.999940] [G loss: 1.000084]\n",
      "epoch:23 step:112430[D loss: 1.000025] [G loss: 0.999988]\n",
      "epoch:23 step:112435[D loss: 0.999955] [G loss: 1.000035]\n",
      "epoch:23 step:112440[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:24 step:112445[D loss: 0.999981] [G loss: 1.000096]\n",
      "epoch:24 step:112450[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:24 step:112455[D loss: 0.999976] [G loss: 1.000046]\n",
      "epoch:24 step:112460[D loss: 1.000016] [G loss: 0.999963]\n",
      "epoch:24 step:112465[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:24 step:112470[D loss: 0.999911] [G loss: 1.000144]\n",
      "epoch:24 step:112475[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:24 step:112480[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:24 step:112485[D loss: 1.000104] [G loss: 0.999828]\n",
      "epoch:24 step:112490[D loss: 1.000081] [G loss: 0.999990]\n",
      "epoch:24 step:112495[D loss: 1.000049] [G loss: 0.999996]\n",
      "epoch:24 step:112500[D loss: 0.999947] [G loss: 1.000023]\n",
      "epoch:24 step:112505[D loss: 1.000010] [G loss: 1.000003]\n",
      "epoch:24 step:112510[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:24 step:112515[D loss: 0.999960] [G loss: 1.000141]\n",
      "epoch:24 step:112520[D loss: 1.000010] [G loss: 1.000061]\n",
      "epoch:24 step:112525[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:24 step:112530[D loss: 1.000000] [G loss: 1.000024]\n",
      "epoch:24 step:112535[D loss: 1.000031] [G loss: 0.999955]\n",
      "epoch:24 step:112540[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:24 step:112545[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:24 step:112550[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:24 step:112555[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:24 step:112560[D loss: 1.000028] [G loss: 1.000094]\n",
      "epoch:24 step:112565[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:24 step:112570[D loss: 0.999943] [G loss: 1.000216]\n",
      "epoch:24 step:112575[D loss: 0.999989] [G loss: 1.000208]\n",
      "epoch:24 step:112580[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:24 step:112585[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:24 step:112590[D loss: 1.000004] [G loss: 1.000001]\n",
      "epoch:24 step:112595[D loss: 0.999979] [G loss: 0.999978]\n",
      "epoch:24 step:112600[D loss: 1.000004] [G loss: 0.999953]\n",
      "epoch:24 step:112605[D loss: 0.999967] [G loss: 1.000037]\n",
      "epoch:24 step:112610[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:24 step:112615[D loss: 0.999967] [G loss: 1.000085]\n",
      "epoch:24 step:112620[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:24 step:112625[D loss: 1.000005] [G loss: 1.000041]\n",
      "epoch:24 step:112630[D loss: 0.999961] [G loss: 1.000079]\n",
      "epoch:24 step:112635[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:24 step:112640[D loss: 1.000067] [G loss: 1.000006]\n",
      "epoch:24 step:112645[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:24 step:112650[D loss: 0.999989] [G loss: 0.999999]\n",
      "epoch:24 step:112655[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:24 step:112660[D loss: 0.999965] [G loss: 1.000036]\n",
      "epoch:24 step:112665[D loss: 1.000019] [G loss: 1.000018]\n",
      "epoch:24 step:112670[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:24 step:112675[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:24 step:112680[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:24 step:112685[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:24 step:112690[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:24 step:112695[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:24 step:112700[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:24 step:112705[D loss: 0.999999] [G loss: 1.000089]\n",
      "epoch:24 step:112710[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:24 step:112715[D loss: 0.999946] [G loss: 1.000112]\n",
      "epoch:24 step:112720[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:24 step:112725[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:24 step:112730[D loss: 0.999941] [G loss: 1.000110]\n",
      "epoch:24 step:112735[D loss: 1.000009] [G loss: 0.999977]\n",
      "epoch:24 step:112740[D loss: 0.999999] [G loss: 1.000013]\n",
      "epoch:24 step:112745[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:24 step:112750[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:24 step:112755[D loss: 1.000015] [G loss: 1.000004]\n",
      "epoch:24 step:112760[D loss: 1.000038] [G loss: 1.000075]\n",
      "epoch:24 step:112765[D loss: 1.000002] [G loss: 0.999980]\n",
      "epoch:24 step:112770[D loss: 0.999939] [G loss: 1.000041]\n",
      "epoch:24 step:112775[D loss: 0.999942] [G loss: 1.000101]\n",
      "epoch:24 step:112780[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:24 step:112785[D loss: 1.000055] [G loss: 0.999980]\n",
      "epoch:24 step:112790[D loss: 1.000026] [G loss: 0.999985]\n",
      "epoch:24 step:112795[D loss: 0.999996] [G loss: 1.000025]\n",
      "epoch:24 step:112800[D loss: 1.000020] [G loss: 1.000066]\n",
      "epoch:24 step:112805[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:24 step:112810[D loss: 0.999932] [G loss: 1.000047]\n",
      "epoch:24 step:112815[D loss: 0.999953] [G loss: 1.000029]\n",
      "epoch:24 step:112820[D loss: 0.999969] [G loss: 1.000051]\n",
      "epoch:24 step:112825[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:24 step:112830[D loss: 0.999999] [G loss: 1.000008]\n",
      "epoch:24 step:112835[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:24 step:112840[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:24 step:112845[D loss: 1.000015] [G loss: 0.999985]\n",
      "epoch:24 step:112850[D loss: 0.999983] [G loss: 1.000025]\n",
      "epoch:24 step:112855[D loss: 0.999958] [G loss: 1.000053]\n",
      "epoch:24 step:112860[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:24 step:112865[D loss: 0.999951] [G loss: 1.000068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:112870[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:24 step:112875[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:24 step:112880[D loss: 0.999909] [G loss: 1.000123]\n",
      "epoch:24 step:112885[D loss: 1.000008] [G loss: 1.000010]\n",
      "epoch:24 step:112890[D loss: 0.999986] [G loss: 1.000027]\n",
      "epoch:24 step:112895[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:24 step:112900[D loss: 0.999972] [G loss: 1.000042]\n",
      "epoch:24 step:112905[D loss: 0.999989] [G loss: 1.000054]\n",
      "epoch:24 step:112910[D loss: 0.999955] [G loss: 1.000049]\n",
      "epoch:24 step:112915[D loss: 1.000032] [G loss: 1.000063]\n",
      "epoch:24 step:112920[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:24 step:112925[D loss: 1.000021] [G loss: 1.000097]\n",
      "epoch:24 step:112930[D loss: 0.999969] [G loss: 1.000200]\n",
      "epoch:24 step:112935[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:24 step:112940[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:24 step:112945[D loss: 0.999995] [G loss: 1.000024]\n",
      "epoch:24 step:112950[D loss: 0.999987] [G loss: 0.999999]\n",
      "epoch:24 step:112955[D loss: 1.000012] [G loss: 0.999952]\n",
      "epoch:24 step:112960[D loss: 1.000029] [G loss: 0.999997]\n",
      "epoch:24 step:112965[D loss: 1.000052] [G loss: 0.999874]\n",
      "epoch:24 step:112970[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:24 step:112975[D loss: 0.999982] [G loss: 1.000132]\n",
      "epoch:24 step:112980[D loss: 1.000075] [G loss: 0.999919]\n",
      "epoch:24 step:112985[D loss: 0.999912] [G loss: 1.000143]\n",
      "epoch:24 step:112990[D loss: 1.000010] [G loss: 1.000045]\n",
      "epoch:24 step:112995[D loss: 0.999941] [G loss: 1.000091]\n",
      "epoch:24 step:113000[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:24 step:113005[D loss: 0.999998] [G loss: 1.000072]\n",
      "epoch:24 step:113010[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:24 step:113015[D loss: 1.000025] [G loss: 1.000002]\n",
      "epoch:24 step:113020[D loss: 0.999943] [G loss: 1.000084]\n",
      "epoch:24 step:113025[D loss: 1.000056] [G loss: 0.999958]\n",
      "epoch:24 step:113030[D loss: 1.000074] [G loss: 0.999905]\n",
      "epoch:24 step:113035[D loss: 1.000017] [G loss: 1.000067]\n",
      "epoch:24 step:113040[D loss: 0.999977] [G loss: 0.999924]\n",
      "epoch:24 step:113045[D loss: 0.999946] [G loss: 1.000115]\n",
      "epoch:24 step:113050[D loss: 0.999997] [G loss: 1.000060]\n",
      "epoch:24 step:113055[D loss: 0.999993] [G loss: 1.000055]\n",
      "epoch:24 step:113060[D loss: 1.000022] [G loss: 1.000004]\n",
      "epoch:24 step:113065[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:24 step:113070[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:24 step:113075[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:24 step:113080[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:24 step:113085[D loss: 1.000025] [G loss: 0.999987]\n",
      "epoch:24 step:113090[D loss: 0.999948] [G loss: 1.000067]\n",
      "epoch:24 step:113095[D loss: 1.000003] [G loss: 0.999998]\n",
      "epoch:24 step:113100[D loss: 0.999981] [G loss: 1.000155]\n",
      "epoch:24 step:113105[D loss: 0.999883] [G loss: 1.000152]\n",
      "epoch:24 step:113110[D loss: 0.999936] [G loss: 1.000105]\n",
      "epoch:24 step:113115[D loss: 0.999932] [G loss: 1.000158]\n",
      "epoch:24 step:113120[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:24 step:113125[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:24 step:113130[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:24 step:113135[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:24 step:113140[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:24 step:113145[D loss: 0.999988] [G loss: 1.000107]\n",
      "epoch:24 step:113150[D loss: 0.999960] [G loss: 1.000108]\n",
      "epoch:24 step:113155[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:24 step:113160[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:24 step:113165[D loss: 0.999964] [G loss: 1.000111]\n",
      "epoch:24 step:113170[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:24 step:113175[D loss: 0.999994] [G loss: 1.000105]\n",
      "epoch:24 step:113180[D loss: 0.999935] [G loss: 1.000137]\n",
      "epoch:24 step:113185[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:24 step:113190[D loss: 0.999987] [G loss: 1.000034]\n",
      "epoch:24 step:113195[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:24 step:113200[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:24 step:113205[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:24 step:113210[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:24 step:113215[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:24 step:113220[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:24 step:113225[D loss: 0.999950] [G loss: 1.000066]\n",
      "epoch:24 step:113230[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:24 step:113235[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:24 step:113240[D loss: 0.999974] [G loss: 1.000093]\n",
      "epoch:24 step:113245[D loss: 0.999979] [G loss: 1.000124]\n",
      "epoch:24 step:113250[D loss: 1.000012] [G loss: 1.000058]\n",
      "epoch:24 step:113255[D loss: 0.999940] [G loss: 1.000129]\n",
      "epoch:24 step:113260[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:24 step:113265[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:24 step:113270[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:24 step:113275[D loss: 0.999970] [G loss: 1.000037]\n",
      "epoch:24 step:113280[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:24 step:113285[D loss: 0.999948] [G loss: 1.000096]\n",
      "epoch:24 step:113290[D loss: 0.999982] [G loss: 1.000039]\n",
      "epoch:24 step:113295[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:24 step:113300[D loss: 0.999994] [G loss: 1.000012]\n",
      "epoch:24 step:113305[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:24 step:113310[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:24 step:113315[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:24 step:113320[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:24 step:113325[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:24 step:113330[D loss: 1.000010] [G loss: 1.000094]\n",
      "epoch:24 step:113335[D loss: 0.999908] [G loss: 1.000223]\n",
      "epoch:24 step:113340[D loss: 0.999943] [G loss: 1.000092]\n",
      "epoch:24 step:113345[D loss: 0.999960] [G loss: 1.000100]\n",
      "epoch:24 step:113350[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:24 step:113355[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:24 step:113360[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:24 step:113365[D loss: 1.000027] [G loss: 0.999957]\n",
      "epoch:24 step:113370[D loss: 0.999969] [G loss: 1.000013]\n",
      "epoch:24 step:113375[D loss: 0.999957] [G loss: 1.000139]\n",
      "epoch:24 step:113380[D loss: 1.000007] [G loss: 1.000103]\n",
      "epoch:24 step:113385[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:24 step:113390[D loss: 0.999974] [G loss: 1.000060]\n",
      "epoch:24 step:113395[D loss: 0.999983] [G loss: 1.000045]\n",
      "epoch:24 step:113400[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:24 step:113405[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:24 step:113410[D loss: 1.000052] [G loss: 1.000010]\n",
      "epoch:24 step:113415[D loss: 1.000025] [G loss: 0.999984]\n",
      "epoch:24 step:113420[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:24 step:113425[D loss: 1.000105] [G loss: 0.999898]\n",
      "epoch:24 step:113430[D loss: 1.000108] [G loss: 1.000024]\n",
      "epoch:24 step:113435[D loss: 0.999913] [G loss: 1.000135]\n",
      "epoch:24 step:113440[D loss: 1.000017] [G loss: 1.000145]\n",
      "epoch:24 step:113445[D loss: 0.999879] [G loss: 1.000214]\n",
      "epoch:24 step:113450[D loss: 0.999950] [G loss: 1.000089]\n",
      "epoch:24 step:113455[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:24 step:113460[D loss: 1.000010] [G loss: 0.999999]\n",
      "epoch:24 step:113465[D loss: 0.999999] [G loss: 0.999998]\n",
      "epoch:24 step:113470[D loss: 1.000044] [G loss: 0.999971]\n",
      "epoch:24 step:113475[D loss: 1.000119] [G loss: 0.999840]\n",
      "epoch:24 step:113480[D loss: 0.999980] [G loss: 0.999812]\n",
      "epoch:24 step:113485[D loss: 1.000039] [G loss: 1.000061]\n",
      "epoch:24 step:113490[D loss: 0.999886] [G loss: 1.000203]\n",
      "epoch:24 step:113495[D loss: 0.999878] [G loss: 1.000206]\n",
      "epoch:24 step:113500[D loss: 0.999967] [G loss: 1.000141]\n",
      "epoch:24 step:113505[D loss: 1.000002] [G loss: 1.000074]\n",
      "epoch:24 step:113510[D loss: 0.999987] [G loss: 1.000114]\n",
      "epoch:24 step:113515[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:24 step:113520[D loss: 0.999964] [G loss: 1.000141]\n",
      "epoch:24 step:113525[D loss: 1.000024] [G loss: 1.000230]\n",
      "epoch:24 step:113530[D loss: 1.000018] [G loss: 1.000015]\n",
      "epoch:24 step:113535[D loss: 0.999935] [G loss: 1.000077]\n",
      "epoch:24 step:113540[D loss: 1.000004] [G loss: 1.000056]\n",
      "epoch:24 step:113545[D loss: 1.000005] [G loss: 1.000035]\n",
      "epoch:24 step:113550[D loss: 1.000013] [G loss: 1.000016]\n",
      "epoch:24 step:113555[D loss: 1.000020] [G loss: 1.000026]\n",
      "epoch:24 step:113560[D loss: 1.000006] [G loss: 0.999922]\n",
      "epoch:24 step:113565[D loss: 1.000018] [G loss: 1.000065]\n",
      "epoch:24 step:113570[D loss: 0.999986] [G loss: 1.000139]\n",
      "epoch:24 step:113575[D loss: 0.999988] [G loss: 1.000310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:113580[D loss: 0.999939] [G loss: 1.000021]\n",
      "epoch:24 step:113585[D loss: 0.999940] [G loss: 1.000099]\n",
      "epoch:24 step:113590[D loss: 1.000084] [G loss: 0.999974]\n",
      "epoch:24 step:113595[D loss: 0.999914] [G loss: 1.000151]\n",
      "epoch:24 step:113600[D loss: 0.999907] [G loss: 1.000141]\n",
      "epoch:24 step:113605[D loss: 0.999952] [G loss: 1.000155]\n",
      "epoch:24 step:113610[D loss: 0.999922] [G loss: 1.000225]\n",
      "epoch:24 step:113615[D loss: 0.999950] [G loss: 1.000149]\n",
      "epoch:24 step:113620[D loss: 0.999925] [G loss: 1.000077]\n",
      "epoch:24 step:113625[D loss: 1.000029] [G loss: 1.000007]\n",
      "epoch:24 step:113630[D loss: 1.000064] [G loss: 0.999893]\n",
      "epoch:24 step:113635[D loss: 0.999977] [G loss: 1.000011]\n",
      "epoch:24 step:113640[D loss: 0.999946] [G loss: 1.000103]\n",
      "epoch:24 step:113645[D loss: 1.000032] [G loss: 1.000003]\n",
      "epoch:24 step:113650[D loss: 0.999944] [G loss: 1.000032]\n",
      "epoch:24 step:113655[D loss: 0.999861] [G loss: 1.000201]\n",
      "epoch:24 step:113660[D loss: 1.000084] [G loss: 0.999980]\n",
      "epoch:24 step:113665[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:24 step:113670[D loss: 0.999901] [G loss: 1.000206]\n",
      "epoch:24 step:113675[D loss: 0.999950] [G loss: 1.000076]\n",
      "epoch:24 step:113680[D loss: 1.000051] [G loss: 1.000020]\n",
      "epoch:24 step:113685[D loss: 0.999915] [G loss: 1.000080]\n",
      "epoch:24 step:113690[D loss: 1.000004] [G loss: 1.000014]\n",
      "epoch:24 step:113695[D loss: 1.000042] [G loss: 0.999952]\n",
      "epoch:24 step:113700[D loss: 1.000057] [G loss: 0.999890]\n",
      "epoch:24 step:113705[D loss: 0.999995] [G loss: 1.000034]\n",
      "epoch:24 step:113710[D loss: 1.000003] [G loss: 1.000051]\n",
      "epoch:24 step:113715[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:24 step:113720[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:24 step:113725[D loss: 0.999991] [G loss: 1.000048]\n",
      "epoch:24 step:113730[D loss: 1.000037] [G loss: 0.999997]\n",
      "epoch:24 step:113735[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:24 step:113740[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:24 step:113745[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:24 step:113750[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:24 step:113755[D loss: 1.000076] [G loss: 0.999999]\n",
      "epoch:24 step:113760[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:24 step:113765[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:24 step:113770[D loss: 0.999930] [G loss: 1.000182]\n",
      "epoch:24 step:113775[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:24 step:113780[D loss: 0.999976] [G loss: 1.000016]\n",
      "epoch:24 step:113785[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:24 step:113790[D loss: 1.000006] [G loss: 0.999988]\n",
      "epoch:24 step:113795[D loss: 0.999984] [G loss: 1.000004]\n",
      "epoch:24 step:113800[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:24 step:113805[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:24 step:113810[D loss: 0.999975] [G loss: 1.000098]\n",
      "epoch:24 step:113815[D loss: 1.000056] [G loss: 0.999985]\n",
      "epoch:24 step:113820[D loss: 1.000046] [G loss: 0.999995]\n",
      "epoch:24 step:113825[D loss: 0.999942] [G loss: 1.000117]\n",
      "epoch:24 step:113830[D loss: 0.999979] [G loss: 1.000133]\n",
      "epoch:24 step:113835[D loss: 0.999948] [G loss: 1.000145]\n",
      "epoch:24 step:113840[D loss: 0.999934] [G loss: 1.000132]\n",
      "epoch:24 step:113845[D loss: 0.999982] [G loss: 1.000042]\n",
      "epoch:24 step:113850[D loss: 1.000021] [G loss: 0.999980]\n",
      "epoch:24 step:113855[D loss: 0.999948] [G loss: 1.000052]\n",
      "epoch:24 step:113860[D loss: 1.000108] [G loss: 0.999857]\n",
      "epoch:24 step:113865[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:24 step:113870[D loss: 0.999903] [G loss: 1.000079]\n",
      "epoch:24 step:113875[D loss: 0.999953] [G loss: 1.000086]\n",
      "epoch:24 step:113880[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:24 step:113885[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:24 step:113890[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:24 step:113895[D loss: 0.999943] [G loss: 1.000089]\n",
      "epoch:24 step:113900[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:24 step:113905[D loss: 1.000008] [G loss: 1.000058]\n",
      "epoch:24 step:113910[D loss: 0.999994] [G loss: 0.999986]\n",
      "epoch:24 step:113915[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:24 step:113920[D loss: 0.999921] [G loss: 1.000110]\n",
      "epoch:24 step:113925[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:24 step:113930[D loss: 0.999996] [G loss: 1.000064]\n",
      "epoch:24 step:113935[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:24 step:113940[D loss: 1.000013] [G loss: 0.999975]\n",
      "epoch:24 step:113945[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:24 step:113950[D loss: 1.000006] [G loss: 1.000020]\n",
      "epoch:24 step:113955[D loss: 0.999973] [G loss: 1.000163]\n",
      "epoch:24 step:113960[D loss: 0.999965] [G loss: 1.000034]\n",
      "epoch:24 step:113965[D loss: 1.000001] [G loss: 1.000048]\n",
      "epoch:24 step:113970[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:24 step:113975[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:24 step:113980[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:24 step:113985[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:24 step:113990[D loss: 0.999991] [G loss: 1.000072]\n",
      "epoch:24 step:113995[D loss: 1.000036] [G loss: 1.000027]\n",
      "epoch:24 step:114000[D loss: 0.999909] [G loss: 1.000108]\n",
      "epoch:24 step:114005[D loss: 0.999945] [G loss: 1.000067]\n",
      "epoch:24 step:114010[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:24 step:114015[D loss: 1.000003] [G loss: 1.000074]\n",
      "epoch:24 step:114020[D loss: 1.000041] [G loss: 1.000076]\n",
      "epoch:24 step:114025[D loss: 0.999969] [G loss: 0.999976]\n",
      "epoch:24 step:114030[D loss: 1.000023] [G loss: 1.000025]\n",
      "epoch:24 step:114035[D loss: 0.999949] [G loss: 1.000048]\n",
      "epoch:24 step:114040[D loss: 1.000036] [G loss: 0.999985]\n",
      "epoch:24 step:114045[D loss: 1.000126] [G loss: 1.000016]\n",
      "epoch:24 step:114050[D loss: 1.000063] [G loss: 0.999948]\n",
      "epoch:24 step:114055[D loss: 1.000099] [G loss: 0.999792]\n",
      "epoch:24 step:114060[D loss: 0.999993] [G loss: 0.999996]\n",
      "epoch:24 step:114065[D loss: 0.999965] [G loss: 0.999999]\n",
      "epoch:24 step:114070[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:24 step:114075[D loss: 1.000064] [G loss: 0.999858]\n",
      "epoch:24 step:114080[D loss: 0.999944] [G loss: 1.000070]\n",
      "epoch:24 step:114085[D loss: 0.999915] [G loss: 1.000091]\n",
      "epoch:24 step:114090[D loss: 0.999931] [G loss: 1.000129]\n",
      "epoch:24 step:114095[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:24 step:114100[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:24 step:114105[D loss: 0.999941] [G loss: 1.000087]\n",
      "epoch:24 step:114110[D loss: 1.000035] [G loss: 0.999997]\n",
      "epoch:24 step:114115[D loss: 0.999915] [G loss: 1.000101]\n",
      "epoch:24 step:114120[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:24 step:114125[D loss: 0.999980] [G loss: 1.000066]\n",
      "epoch:24 step:114130[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:24 step:114135[D loss: 1.000002] [G loss: 0.999992]\n",
      "epoch:24 step:114140[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:24 step:114145[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:24 step:114150[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:24 step:114155[D loss: 0.999952] [G loss: 1.000094]\n",
      "epoch:24 step:114160[D loss: 1.000030] [G loss: 0.999981]\n",
      "epoch:24 step:114165[D loss: 0.999951] [G loss: 1.000066]\n",
      "epoch:24 step:114170[D loss: 1.000081] [G loss: 1.000020]\n",
      "epoch:24 step:114175[D loss: 0.999917] [G loss: 1.000101]\n",
      "epoch:24 step:114180[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:24 step:114185[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:24 step:114190[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:24 step:114195[D loss: 0.999976] [G loss: 1.000082]\n",
      "epoch:24 step:114200[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:24 step:114205[D loss: 0.999984] [G loss: 1.000088]\n",
      "epoch:24 step:114210[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:24 step:114215[D loss: 0.999952] [G loss: 1.000093]\n",
      "epoch:24 step:114220[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:24 step:114225[D loss: 0.999970] [G loss: 1.000070]\n",
      "epoch:24 step:114230[D loss: 1.000097] [G loss: 0.999985]\n",
      "epoch:24 step:114235[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:24 step:114240[D loss: 1.000034] [G loss: 1.000029]\n",
      "epoch:24 step:114245[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:24 step:114250[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:24 step:114255[D loss: 1.000035] [G loss: 0.999949]\n",
      "epoch:24 step:114260[D loss: 0.999987] [G loss: 1.000149]\n",
      "epoch:24 step:114265[D loss: 1.000016] [G loss: 1.000004]\n",
      "epoch:24 step:114270[D loss: 0.999954] [G loss: 1.000123]\n",
      "epoch:24 step:114275[D loss: 1.000128] [G loss: 0.999920]\n",
      "epoch:24 step:114280[D loss: 0.999849] [G loss: 1.000369]\n",
      "epoch:24 step:114285[D loss: 1.000038] [G loss: 0.999958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:114290[D loss: 0.999993] [G loss: 1.000097]\n",
      "epoch:24 step:114295[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:24 step:114300[D loss: 0.999962] [G loss: 1.000136]\n",
      "epoch:24 step:114305[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:24 step:114310[D loss: 1.000017] [G loss: 1.000084]\n",
      "epoch:24 step:114315[D loss: 0.999976] [G loss: 1.000019]\n",
      "epoch:24 step:114320[D loss: 1.000038] [G loss: 0.999949]\n",
      "epoch:24 step:114325[D loss: 1.000042] [G loss: 0.999903]\n",
      "epoch:24 step:114330[D loss: 1.000149] [G loss: 0.999866]\n",
      "epoch:24 step:114335[D loss: 1.000132] [G loss: 0.999740]\n",
      "epoch:24 step:114340[D loss: 0.999812] [G loss: 1.000205]\n",
      "epoch:24 step:114345[D loss: 0.999959] [G loss: 1.000102]\n",
      "epoch:24 step:114350[D loss: 1.000021] [G loss: 0.999957]\n",
      "epoch:24 step:114355[D loss: 0.999951] [G loss: 1.000021]\n",
      "epoch:24 step:114360[D loss: 0.999995] [G loss: 1.000066]\n",
      "epoch:24 step:114365[D loss: 1.000036] [G loss: 0.999945]\n",
      "epoch:24 step:114370[D loss: 0.999979] [G loss: 1.000011]\n",
      "epoch:24 step:114375[D loss: 1.000085] [G loss: 0.999915]\n",
      "epoch:24 step:114380[D loss: 1.000079] [G loss: 0.999952]\n",
      "epoch:24 step:114385[D loss: 0.999859] [G loss: 1.000054]\n",
      "epoch:24 step:114390[D loss: 1.000022] [G loss: 1.000086]\n",
      "epoch:24 step:114395[D loss: 0.999934] [G loss: 1.000046]\n",
      "epoch:24 step:114400[D loss: 1.000040] [G loss: 1.000001]\n",
      "epoch:24 step:114405[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:24 step:114410[D loss: 0.999997] [G loss: 1.000143]\n",
      "epoch:24 step:114415[D loss: 0.999936] [G loss: 1.000149]\n",
      "epoch:24 step:114420[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:24 step:114425[D loss: 1.000064] [G loss: 0.999908]\n",
      "epoch:24 step:114430[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:24 step:114435[D loss: 0.999859] [G loss: 1.000169]\n",
      "epoch:24 step:114440[D loss: 0.999969] [G loss: 1.000134]\n",
      "epoch:24 step:114445[D loss: 0.999962] [G loss: 1.000107]\n",
      "epoch:24 step:114450[D loss: 0.999972] [G loss: 1.000112]\n",
      "epoch:24 step:114455[D loss: 1.000089] [G loss: 0.999945]\n",
      "epoch:24 step:114460[D loss: 0.999847] [G loss: 1.000241]\n",
      "epoch:24 step:114465[D loss: 0.999912] [G loss: 1.000050]\n",
      "epoch:24 step:114470[D loss: 0.999941] [G loss: 1.000133]\n",
      "epoch:24 step:114475[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:24 step:114480[D loss: 0.999968] [G loss: 1.000035]\n",
      "epoch:24 step:114485[D loss: 1.000006] [G loss: 0.999969]\n",
      "epoch:24 step:114490[D loss: 1.000146] [G loss: 0.999863]\n",
      "epoch:24 step:114495[D loss: 0.999927] [G loss: 1.000064]\n",
      "epoch:24 step:114500[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:24 step:114505[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:24 step:114510[D loss: 0.999980] [G loss: 1.000095]\n",
      "epoch:24 step:114515[D loss: 1.000017] [G loss: 0.999990]\n",
      "epoch:24 step:114520[D loss: 0.999961] [G loss: 1.000105]\n",
      "epoch:24 step:114525[D loss: 0.999934] [G loss: 1.000103]\n",
      "epoch:24 step:114530[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:24 step:114535[D loss: 0.999974] [G loss: 1.000048]\n",
      "epoch:24 step:114540[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:24 step:114545[D loss: 1.000069] [G loss: 0.999998]\n",
      "epoch:24 step:114550[D loss: 1.000013] [G loss: 1.000040]\n",
      "epoch:24 step:114555[D loss: 0.999965] [G loss: 1.000114]\n",
      "epoch:24 step:114560[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:24 step:114565[D loss: 0.999957] [G loss: 1.000103]\n",
      "epoch:24 step:114570[D loss: 1.000001] [G loss: 1.000055]\n",
      "epoch:24 step:114575[D loss: 0.999973] [G loss: 1.000033]\n",
      "epoch:24 step:114580[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:24 step:114585[D loss: 1.000023] [G loss: 1.000014]\n",
      "epoch:24 step:114590[D loss: 1.000026] [G loss: 0.999913]\n",
      "epoch:24 step:114595[D loss: 0.999951] [G loss: 1.000022]\n",
      "epoch:24 step:114600[D loss: 1.000066] [G loss: 1.000039]\n",
      "epoch:24 step:114605[D loss: 0.999971] [G loss: 1.000002]\n",
      "epoch:24 step:114610[D loss: 0.999983] [G loss: 1.000150]\n",
      "epoch:24 step:114615[D loss: 1.000016] [G loss: 1.000007]\n",
      "epoch:24 step:114620[D loss: 0.999905] [G loss: 1.000113]\n",
      "epoch:24 step:114625[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:24 step:114630[D loss: 0.999952] [G loss: 1.000063]\n",
      "epoch:24 step:114635[D loss: 0.999952] [G loss: 1.000156]\n",
      "epoch:24 step:114640[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:24 step:114645[D loss: 0.999957] [G loss: 1.000036]\n",
      "epoch:24 step:114650[D loss: 1.000015] [G loss: 1.000019]\n",
      "epoch:24 step:114655[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:24 step:114660[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:24 step:114665[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:24 step:114670[D loss: 1.000028] [G loss: 1.000035]\n",
      "epoch:24 step:114675[D loss: 1.000068] [G loss: 0.999976]\n",
      "epoch:24 step:114680[D loss: 1.000155] [G loss: 0.999892]\n",
      "epoch:24 step:114685[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:24 step:114690[D loss: 0.999948] [G loss: 1.000165]\n",
      "epoch:24 step:114695[D loss: 0.999913] [G loss: 1.000149]\n",
      "epoch:24 step:114700[D loss: 0.999985] [G loss: 1.000093]\n",
      "epoch:24 step:114705[D loss: 0.999959] [G loss: 1.000132]\n",
      "epoch:24 step:114710[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:24 step:114715[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:24 step:114720[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:24 step:114725[D loss: 1.000002] [G loss: 1.000039]\n",
      "epoch:24 step:114730[D loss: 1.000076] [G loss: 1.000056]\n",
      "epoch:24 step:114735[D loss: 1.000214] [G loss: 0.999854]\n",
      "epoch:24 step:114740[D loss: 1.000060] [G loss: 0.999871]\n",
      "epoch:24 step:114745[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:24 step:114750[D loss: 0.999930] [G loss: 1.000106]\n",
      "epoch:24 step:114755[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:24 step:114760[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:24 step:114765[D loss: 1.000013] [G loss: 0.999999]\n",
      "epoch:24 step:114770[D loss: 0.999959] [G loss: 0.999990]\n",
      "epoch:24 step:114775[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:24 step:114780[D loss: 0.999990] [G loss: 1.000120]\n",
      "epoch:24 step:114785[D loss: 1.000111] [G loss: 1.000038]\n",
      "epoch:24 step:114790[D loss: 0.999978] [G loss: 1.000161]\n",
      "epoch:24 step:114795[D loss: 0.999874] [G loss: 1.000242]\n",
      "epoch:24 step:114800[D loss: 0.999897] [G loss: 1.000196]\n",
      "epoch:24 step:114805[D loss: 0.999961] [G loss: 1.000141]\n",
      "epoch:24 step:114810[D loss: 1.000040] [G loss: 0.999950]\n",
      "epoch:24 step:114815[D loss: 1.000006] [G loss: 0.999960]\n",
      "epoch:24 step:114820[D loss: 0.999974] [G loss: 0.999998]\n",
      "epoch:24 step:114825[D loss: 0.999951] [G loss: 1.000023]\n",
      "epoch:24 step:114830[D loss: 1.000081] [G loss: 1.000025]\n",
      "epoch:24 step:114835[D loss: 0.999888] [G loss: 1.000026]\n",
      "epoch:24 step:114840[D loss: 0.999945] [G loss: 1.000029]\n",
      "epoch:24 step:114845[D loss: 1.000070] [G loss: 0.999998]\n",
      "epoch:24 step:114850[D loss: 0.999929] [G loss: 1.000028]\n",
      "epoch:24 step:114855[D loss: 0.999992] [G loss: 1.000063]\n",
      "epoch:24 step:114860[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:24 step:114865[D loss: 1.000026] [G loss: 1.000002]\n",
      "epoch:24 step:114870[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:24 step:114875[D loss: 1.000031] [G loss: 1.000028]\n",
      "epoch:24 step:114880[D loss: 1.000034] [G loss: 1.000019]\n",
      "epoch:24 step:114885[D loss: 0.999992] [G loss: 1.000103]\n",
      "epoch:24 step:114890[D loss: 1.000088] [G loss: 0.999947]\n",
      "epoch:24 step:114895[D loss: 0.999915] [G loss: 1.000147]\n",
      "epoch:24 step:114900[D loss: 0.999918] [G loss: 1.000271]\n",
      "epoch:24 step:114905[D loss: 1.000095] [G loss: 1.000096]\n",
      "epoch:24 step:114910[D loss: 0.999899] [G loss: 1.000278]\n",
      "epoch:24 step:114915[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:24 step:114920[D loss: 1.000006] [G loss: 1.000318]\n",
      "epoch:24 step:114925[D loss: 0.999896] [G loss: 1.000263]\n",
      "epoch:24 step:114930[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:24 step:114935[D loss: 1.000008] [G loss: 0.999989]\n",
      "epoch:24 step:114940[D loss: 1.000060] [G loss: 0.999938]\n",
      "epoch:24 step:114945[D loss: 0.999960] [G loss: 0.999938]\n",
      "epoch:24 step:114950[D loss: 0.999995] [G loss: 0.999989]\n",
      "epoch:24 step:114955[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:24 step:114960[D loss: 0.999991] [G loss: 0.999986]\n",
      "epoch:24 step:114965[D loss: 0.999990] [G loss: 1.000106]\n",
      "epoch:24 step:114970[D loss: 0.999956] [G loss: 1.000052]\n",
      "epoch:24 step:114975[D loss: 1.000027] [G loss: 1.000126]\n",
      "epoch:24 step:114980[D loss: 1.000078] [G loss: 0.999998]\n",
      "epoch:24 step:114985[D loss: 0.999847] [G loss: 1.000288]\n",
      "epoch:24 step:114990[D loss: 1.000088] [G loss: 1.000246]\n",
      "epoch:24 step:114995[D loss: 0.999945] [G loss: 1.000109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:115000[D loss: 0.999925] [G loss: 1.000106]\n",
      "epoch:24 step:115005[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:24 step:115010[D loss: 1.000017] [G loss: 1.000011]\n",
      "epoch:24 step:115015[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:24 step:115020[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:24 step:115025[D loss: 1.000093] [G loss: 1.000001]\n",
      "epoch:24 step:115030[D loss: 1.000002] [G loss: 0.999936]\n",
      "epoch:24 step:115035[D loss: 0.999975] [G loss: 1.000142]\n",
      "epoch:24 step:115040[D loss: 0.999949] [G loss: 1.000089]\n",
      "epoch:24 step:115045[D loss: 1.000037] [G loss: 0.999983]\n",
      "epoch:24 step:115050[D loss: 0.999987] [G loss: 0.999999]\n",
      "epoch:24 step:115055[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:24 step:115060[D loss: 0.999940] [G loss: 1.000135]\n",
      "epoch:24 step:115065[D loss: 0.999967] [G loss: 1.000037]\n",
      "epoch:24 step:115070[D loss: 1.000013] [G loss: 0.999948]\n",
      "epoch:24 step:115075[D loss: 0.999945] [G loss: 1.000101]\n",
      "epoch:24 step:115080[D loss: 0.999989] [G loss: 1.000049]\n",
      "epoch:24 step:115085[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:24 step:115090[D loss: 0.999982] [G loss: 1.000077]\n",
      "epoch:24 step:115095[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:24 step:115100[D loss: 0.999983] [G loss: 1.000068]\n",
      "epoch:24 step:115105[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:24 step:115110[D loss: 0.999979] [G loss: 1.000107]\n",
      "epoch:24 step:115115[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:24 step:115120[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:24 step:115125[D loss: 1.000032] [G loss: 1.000014]\n",
      "epoch:24 step:115130[D loss: 0.999920] [G loss: 1.000142]\n",
      "epoch:24 step:115135[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:24 step:115140[D loss: 0.999980] [G loss: 1.000098]\n",
      "epoch:24 step:115145[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:24 step:115150[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:24 step:115155[D loss: 1.000104] [G loss: 0.999894]\n",
      "epoch:24 step:115160[D loss: 1.000019] [G loss: 0.999924]\n",
      "epoch:24 step:115165[D loss: 1.000004] [G loss: 0.999992]\n",
      "epoch:24 step:115170[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:24 step:115175[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:24 step:115180[D loss: 0.999976] [G loss: 1.000062]\n",
      "epoch:24 step:115185[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:24 step:115190[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:24 step:115195[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:24 step:115200[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:24 step:115205[D loss: 1.000091] [G loss: 0.999938]\n",
      "epoch:24 step:115210[D loss: 0.999960] [G loss: 0.999929]\n",
      "epoch:24 step:115215[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:24 step:115220[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:24 step:115225[D loss: 0.999885] [G loss: 1.000158]\n",
      "epoch:24 step:115230[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:24 step:115235[D loss: 0.999977] [G loss: 1.000074]\n",
      "epoch:24 step:115240[D loss: 1.000015] [G loss: 0.999977]\n",
      "epoch:24 step:115245[D loss: 1.000017] [G loss: 0.999912]\n",
      "epoch:24 step:115250[D loss: 0.999933] [G loss: 1.000037]\n",
      "epoch:24 step:115255[D loss: 1.000020] [G loss: 1.000093]\n",
      "epoch:24 step:115260[D loss: 0.999945] [G loss: 1.000067]\n",
      "epoch:24 step:115265[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:24 step:115270[D loss: 0.999953] [G loss: 1.000071]\n",
      "epoch:24 step:115275[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:24 step:115280[D loss: 0.999982] [G loss: 1.000048]\n",
      "epoch:24 step:115285[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:24 step:115290[D loss: 0.999972] [G loss: 1.000066]\n",
      "epoch:24 step:115295[D loss: 0.999977] [G loss: 1.000040]\n",
      "epoch:24 step:115300[D loss: 0.999960] [G loss: 1.000065]\n",
      "epoch:24 step:115305[D loss: 1.000069] [G loss: 0.999939]\n",
      "epoch:24 step:115310[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:24 step:115315[D loss: 1.000060] [G loss: 1.000085]\n",
      "epoch:24 step:115320[D loss: 0.999931] [G loss: 1.000170]\n",
      "epoch:24 step:115325[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:24 step:115330[D loss: 1.000032] [G loss: 1.000025]\n",
      "epoch:24 step:115335[D loss: 0.999865] [G loss: 1.000137]\n",
      "epoch:24 step:115340[D loss: 1.000013] [G loss: 1.000075]\n",
      "epoch:24 step:115345[D loss: 0.999950] [G loss: 1.000049]\n",
      "epoch:24 step:115350[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:24 step:115355[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:24 step:115360[D loss: 0.999952] [G loss: 1.000027]\n",
      "epoch:24 step:115365[D loss: 1.000052] [G loss: 0.999921]\n",
      "epoch:24 step:115370[D loss: 0.999944] [G loss: 1.000130]\n",
      "epoch:24 step:115375[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:24 step:115380[D loss: 0.999943] [G loss: 1.000081]\n",
      "epoch:24 step:115385[D loss: 1.000016] [G loss: 1.000053]\n",
      "epoch:24 step:115390[D loss: 0.999949] [G loss: 1.000092]\n",
      "epoch:24 step:115395[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:24 step:115400[D loss: 1.000081] [G loss: 0.999931]\n",
      "epoch:24 step:115405[D loss: 1.000099] [G loss: 0.999990]\n",
      "epoch:24 step:115410[D loss: 1.000034] [G loss: 1.000011]\n",
      "epoch:24 step:115415[D loss: 1.000175] [G loss: 0.999902]\n",
      "epoch:24 step:115420[D loss: 0.999930] [G loss: 1.000228]\n",
      "epoch:24 step:115425[D loss: 0.999901] [G loss: 1.000155]\n",
      "epoch:24 step:115430[D loss: 0.999942] [G loss: 1.000104]\n",
      "epoch:24 step:115435[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:24 step:115440[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:24 step:115445[D loss: 1.000087] [G loss: 0.999947]\n",
      "epoch:24 step:115450[D loss: 1.000013] [G loss: 1.000047]\n",
      "epoch:24 step:115455[D loss: 0.999965] [G loss: 1.000014]\n",
      "epoch:24 step:115460[D loss: 1.000017] [G loss: 0.999961]\n",
      "epoch:24 step:115465[D loss: 1.000002] [G loss: 0.999984]\n",
      "epoch:24 step:115470[D loss: 0.999954] [G loss: 1.000031]\n",
      "epoch:24 step:115475[D loss: 1.000008] [G loss: 0.999998]\n",
      "epoch:24 step:115480[D loss: 0.999938] [G loss: 1.000113]\n",
      "epoch:24 step:115485[D loss: 1.000167] [G loss: 0.999876]\n",
      "epoch:24 step:115490[D loss: 0.999926] [G loss: 1.000062]\n",
      "epoch:24 step:115495[D loss: 1.000029] [G loss: 1.000017]\n",
      "epoch:24 step:115500[D loss: 0.999925] [G loss: 1.000150]\n",
      "epoch:24 step:115505[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:24 step:115510[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:24 step:115515[D loss: 1.000004] [G loss: 0.999971]\n",
      "epoch:24 step:115520[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:24 step:115525[D loss: 1.000018] [G loss: 1.000121]\n",
      "epoch:24 step:115530[D loss: 1.000129] [G loss: 0.999845]\n",
      "epoch:24 step:115535[D loss: 0.999944] [G loss: 1.000014]\n",
      "epoch:24 step:115540[D loss: 1.000033] [G loss: 1.000059]\n",
      "epoch:24 step:115545[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:24 step:115550[D loss: 0.999960] [G loss: 1.000156]\n",
      "epoch:24 step:115555[D loss: 0.999998] [G loss: 1.000047]\n",
      "epoch:24 step:115560[D loss: 0.999932] [G loss: 1.000170]\n",
      "epoch:24 step:115565[D loss: 0.999967] [G loss: 1.000117]\n",
      "epoch:24 step:115570[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:24 step:115575[D loss: 1.000026] [G loss: 0.999961]\n",
      "epoch:24 step:115580[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:24 step:115585[D loss: 0.999946] [G loss: 1.000037]\n",
      "epoch:24 step:115590[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:24 step:115595[D loss: 0.999878] [G loss: 1.000184]\n",
      "epoch:24 step:115600[D loss: 1.000099] [G loss: 0.999883]\n",
      "epoch:24 step:115605[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:24 step:115610[D loss: 0.999962] [G loss: 1.000032]\n",
      "epoch:24 step:115615[D loss: 0.999987] [G loss: 1.000029]\n",
      "epoch:24 step:115620[D loss: 0.999980] [G loss: 0.999997]\n",
      "epoch:24 step:115625[D loss: 1.000032] [G loss: 1.000044]\n",
      "epoch:24 step:115630[D loss: 0.999888] [G loss: 1.000026]\n",
      "epoch:24 step:115635[D loss: 0.999934] [G loss: 1.000066]\n",
      "epoch:24 step:115640[D loss: 1.000041] [G loss: 1.000016]\n",
      "epoch:24 step:115645[D loss: 0.999943] [G loss: 1.000186]\n",
      "epoch:24 step:115650[D loss: 0.999919] [G loss: 1.000141]\n",
      "epoch:24 step:115655[D loss: 0.999927] [G loss: 1.000080]\n",
      "epoch:24 step:115660[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:24 step:115665[D loss: 0.999980] [G loss: 1.000053]\n",
      "epoch:24 step:115670[D loss: 0.999996] [G loss: 0.999978]\n",
      "epoch:24 step:115675[D loss: 0.999917] [G loss: 1.000067]\n",
      "epoch:24 step:115680[D loss: 0.999975] [G loss: 1.000027]\n",
      "epoch:24 step:115685[D loss: 1.000001] [G loss: 1.000038]\n",
      "epoch:24 step:115690[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:24 step:115695[D loss: 1.000102] [G loss: 0.999999]\n",
      "epoch:24 step:115700[D loss: 0.999907] [G loss: 1.000125]\n",
      "epoch:24 step:115705[D loss: 0.999932] [G loss: 1.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:115710[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:24 step:115715[D loss: 1.000020] [G loss: 1.000010]\n",
      "epoch:24 step:115720[D loss: 0.999945] [G loss: 1.000043]\n",
      "epoch:24 step:115725[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:24 step:115730[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:24 step:115735[D loss: 0.999949] [G loss: 1.000117]\n",
      "epoch:24 step:115740[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:24 step:115745[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:24 step:115750[D loss: 1.000002] [G loss: 1.000083]\n",
      "epoch:24 step:115755[D loss: 1.000001] [G loss: 1.000034]\n",
      "epoch:24 step:115760[D loss: 0.999972] [G loss: 1.000036]\n",
      "epoch:24 step:115765[D loss: 1.000029] [G loss: 0.999988]\n",
      "epoch:24 step:115770[D loss: 1.000027] [G loss: 0.999984]\n",
      "epoch:24 step:115775[D loss: 0.999946] [G loss: 1.000058]\n",
      "epoch:24 step:115780[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:24 step:115785[D loss: 0.999945] [G loss: 1.000064]\n",
      "epoch:24 step:115790[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:24 step:115795[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:24 step:115800[D loss: 0.999992] [G loss: 1.000009]\n",
      "epoch:24 step:115805[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:24 step:115810[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:24 step:115815[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:24 step:115820[D loss: 1.000019] [G loss: 0.999942]\n",
      "epoch:24 step:115825[D loss: 1.000009] [G loss: 1.000016]\n",
      "epoch:24 step:115830[D loss: 1.000022] [G loss: 1.000085]\n",
      "epoch:24 step:115835[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:24 step:115840[D loss: 0.999962] [G loss: 1.000122]\n",
      "epoch:24 step:115845[D loss: 0.999973] [G loss: 1.000027]\n",
      "epoch:24 step:115850[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:24 step:115855[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:24 step:115860[D loss: 0.999973] [G loss: 1.000037]\n",
      "epoch:24 step:115865[D loss: 1.000074] [G loss: 0.999915]\n",
      "epoch:24 step:115870[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:24 step:115875[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:24 step:115880[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:24 step:115885[D loss: 1.000025] [G loss: 1.000019]\n",
      "epoch:24 step:115890[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:24 step:115895[D loss: 0.999946] [G loss: 1.000085]\n",
      "epoch:24 step:115900[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:24 step:115905[D loss: 1.000046] [G loss: 1.000066]\n",
      "epoch:24 step:115910[D loss: 0.999994] [G loss: 1.000080]\n",
      "epoch:24 step:115915[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:24 step:115920[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:24 step:115925[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:24 step:115930[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:24 step:115935[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:24 step:115940[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:24 step:115945[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:24 step:115950[D loss: 0.999962] [G loss: 1.000103]\n",
      "epoch:24 step:115955[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:24 step:115960[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:24 step:115965[D loss: 1.000011] [G loss: 1.000056]\n",
      "epoch:24 step:115970[D loss: 1.000030] [G loss: 0.999992]\n",
      "epoch:24 step:115975[D loss: 0.999976] [G loss: 1.000095]\n",
      "epoch:24 step:115980[D loss: 0.999987] [G loss: 1.000083]\n",
      "epoch:24 step:115985[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:24 step:115990[D loss: 1.000060] [G loss: 0.999911]\n",
      "epoch:24 step:115995[D loss: 1.000094] [G loss: 0.999821]\n",
      "epoch:24 step:116000[D loss: 0.999978] [G loss: 1.000020]\n",
      "epoch:24 step:116005[D loss: 0.999987] [G loss: 0.999997]\n",
      "epoch:24 step:116010[D loss: 1.000105] [G loss: 1.000056]\n",
      "epoch:24 step:116015[D loss: 0.999919] [G loss: 1.000140]\n",
      "epoch:24 step:116020[D loss: 0.999878] [G loss: 1.000144]\n",
      "epoch:24 step:116025[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:24 step:116030[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:24 step:116035[D loss: 1.000019] [G loss: 0.999994]\n",
      "epoch:24 step:116040[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:24 step:116045[D loss: 0.999944] [G loss: 1.000064]\n",
      "epoch:24 step:116050[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:24 step:116055[D loss: 1.000036] [G loss: 1.000063]\n",
      "epoch:24 step:116060[D loss: 1.000027] [G loss: 1.000051]\n",
      "epoch:24 step:116065[D loss: 0.999926] [G loss: 1.000116]\n",
      "epoch:24 step:116070[D loss: 0.999979] [G loss: 1.000015]\n",
      "epoch:24 step:116075[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:24 step:116080[D loss: 1.000138] [G loss: 0.999816]\n",
      "epoch:24 step:116085[D loss: 0.999971] [G loss: 0.999991]\n",
      "epoch:24 step:116090[D loss: 0.999947] [G loss: 1.000038]\n",
      "epoch:24 step:116095[D loss: 1.000003] [G loss: 1.000055]\n",
      "epoch:24 step:116100[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:24 step:116105[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:24 step:116110[D loss: 1.000013] [G loss: 1.000039]\n",
      "epoch:24 step:116115[D loss: 0.999953] [G loss: 1.000093]\n",
      "epoch:24 step:116120[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:24 step:116125[D loss: 1.000043] [G loss: 1.000082]\n",
      "epoch:24 step:116130[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:24 step:116135[D loss: 0.999963] [G loss: 1.000176]\n",
      "epoch:24 step:116140[D loss: 0.999996] [G loss: 1.000051]\n",
      "epoch:24 step:116145[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:24 step:116150[D loss: 1.000011] [G loss: 1.000140]\n",
      "epoch:24 step:116155[D loss: 0.999900] [G loss: 0.999984]\n",
      "epoch:24 step:116160[D loss: 0.999941] [G loss: 1.000090]\n",
      "epoch:24 step:116165[D loss: 0.999973] [G loss: 1.000037]\n",
      "epoch:24 step:116170[D loss: 0.999946] [G loss: 1.000088]\n",
      "epoch:24 step:116175[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:24 step:116180[D loss: 0.999986] [G loss: 1.000060]\n",
      "epoch:24 step:116185[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:24 step:116190[D loss: 1.000071] [G loss: 0.999949]\n",
      "epoch:24 step:116195[D loss: 0.999919] [G loss: 1.000134]\n",
      "epoch:24 step:116200[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:24 step:116205[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:24 step:116210[D loss: 0.999988] [G loss: 1.000120]\n",
      "epoch:24 step:116215[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:24 step:116220[D loss: 0.999955] [G loss: 1.000041]\n",
      "epoch:24 step:116225[D loss: 1.000018] [G loss: 0.999957]\n",
      "epoch:24 step:116230[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:24 step:116235[D loss: 0.999918] [G loss: 1.000110]\n",
      "epoch:24 step:116240[D loss: 0.999988] [G loss: 1.000066]\n",
      "epoch:24 step:116245[D loss: 0.999996] [G loss: 1.000136]\n",
      "epoch:24 step:116250[D loss: 0.999955] [G loss: 1.000207]\n",
      "epoch:24 step:116255[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:24 step:116260[D loss: 0.999915] [G loss: 1.000216]\n",
      "epoch:24 step:116265[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:24 step:116270[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:24 step:116275[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:24 step:116280[D loss: 1.000004] [G loss: 0.999962]\n",
      "epoch:24 step:116285[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:24 step:116290[D loss: 1.000022] [G loss: 1.000052]\n",
      "epoch:24 step:116295[D loss: 1.000028] [G loss: 1.000007]\n",
      "epoch:24 step:116300[D loss: 0.999954] [G loss: 1.000122]\n",
      "epoch:24 step:116305[D loss: 0.999935] [G loss: 1.000090]\n",
      "epoch:24 step:116310[D loss: 0.999975] [G loss: 1.000206]\n",
      "epoch:24 step:116315[D loss: 0.999895] [G loss: 1.000095]\n",
      "epoch:24 step:116320[D loss: 0.999982] [G loss: 1.000116]\n",
      "epoch:24 step:116325[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:24 step:116330[D loss: 0.999990] [G loss: 1.000023]\n",
      "epoch:24 step:116335[D loss: 1.000021] [G loss: 1.000023]\n",
      "epoch:24 step:116340[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:24 step:116345[D loss: 0.999916] [G loss: 1.000065]\n",
      "epoch:24 step:116350[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:24 step:116355[D loss: 0.999939] [G loss: 1.000193]\n",
      "epoch:24 step:116360[D loss: 0.999970] [G loss: 1.000100]\n",
      "epoch:24 step:116365[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:24 step:116370[D loss: 1.000033] [G loss: 0.999975]\n",
      "epoch:24 step:116375[D loss: 0.999998] [G loss: 0.999992]\n",
      "epoch:24 step:116380[D loss: 1.000029] [G loss: 1.000034]\n",
      "epoch:24 step:116385[D loss: 1.000020] [G loss: 1.000186]\n",
      "epoch:24 step:116390[D loss: 0.999928] [G loss: 1.000097]\n",
      "epoch:24 step:116395[D loss: 1.000040] [G loss: 0.999915]\n",
      "epoch:24 step:116400[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:24 step:116405[D loss: 0.999958] [G loss: 1.000048]\n",
      "epoch:24 step:116410[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:24 step:116415[D loss: 1.000038] [G loss: 0.999986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:116420[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:24 step:116425[D loss: 0.999935] [G loss: 1.000132]\n",
      "epoch:24 step:116430[D loss: 0.999950] [G loss: 1.000174]\n",
      "epoch:24 step:116435[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:24 step:116440[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:24 step:116445[D loss: 1.000012] [G loss: 1.000003]\n",
      "epoch:24 step:116450[D loss: 0.999938] [G loss: 1.000057]\n",
      "epoch:24 step:116455[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:24 step:116460[D loss: 0.999977] [G loss: 1.000084]\n",
      "epoch:24 step:116465[D loss: 1.000043] [G loss: 1.000009]\n",
      "epoch:24 step:116470[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:24 step:116475[D loss: 1.000004] [G loss: 1.000087]\n",
      "epoch:24 step:116480[D loss: 0.999991] [G loss: 1.000200]\n",
      "epoch:24 step:116485[D loss: 0.999923] [G loss: 1.000081]\n",
      "epoch:24 step:116490[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:24 step:116495[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:24 step:116500[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:24 step:116505[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:24 step:116510[D loss: 1.000001] [G loss: 1.000052]\n",
      "epoch:24 step:116515[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:24 step:116520[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:24 step:116525[D loss: 0.999977] [G loss: 1.000046]\n",
      "epoch:24 step:116530[D loss: 1.000010] [G loss: 1.000117]\n",
      "epoch:24 step:116535[D loss: 0.999946] [G loss: 1.000076]\n",
      "epoch:24 step:116540[D loss: 0.999915] [G loss: 1.000148]\n",
      "epoch:24 step:116545[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:24 step:116550[D loss: 1.000014] [G loss: 1.000014]\n",
      "epoch:24 step:116555[D loss: 1.000010] [G loss: 0.999964]\n",
      "epoch:24 step:116560[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:24 step:116565[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:24 step:116570[D loss: 1.000000] [G loss: 1.000061]\n",
      "epoch:24 step:116575[D loss: 0.999955] [G loss: 1.000096]\n",
      "epoch:24 step:116580[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:24 step:116585[D loss: 0.999971] [G loss: 1.000121]\n",
      "epoch:24 step:116590[D loss: 0.999958] [G loss: 1.000137]\n",
      "epoch:24 step:116595[D loss: 1.000085] [G loss: 0.999908]\n",
      "epoch:24 step:116600[D loss: 1.000079] [G loss: 1.000054]\n",
      "epoch:24 step:116605[D loss: 0.999935] [G loss: 1.000072]\n",
      "epoch:24 step:116610[D loss: 1.000043] [G loss: 1.000133]\n",
      "epoch:24 step:116615[D loss: 0.999850] [G loss: 1.000185]\n",
      "epoch:24 step:116620[D loss: 0.999935] [G loss: 1.000087]\n",
      "epoch:24 step:116625[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:24 step:116630[D loss: 0.999975] [G loss: 1.000023]\n",
      "epoch:24 step:116635[D loss: 1.000007] [G loss: 1.000048]\n",
      "epoch:24 step:116640[D loss: 1.000013] [G loss: 0.999984]\n",
      "epoch:24 step:116645[D loss: 0.999924] [G loss: 1.000154]\n",
      "epoch:24 step:116650[D loss: 0.999950] [G loss: 1.000075]\n",
      "epoch:24 step:116655[D loss: 1.000005] [G loss: 1.000046]\n",
      "epoch:24 step:116660[D loss: 1.000034] [G loss: 1.000079]\n",
      "epoch:24 step:116665[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:24 step:116670[D loss: 0.999963] [G loss: 1.000031]\n",
      "epoch:24 step:116675[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:24 step:116680[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:24 step:116685[D loss: 0.999962] [G loss: 1.000094]\n",
      "epoch:24 step:116690[D loss: 0.999972] [G loss: 1.000068]\n",
      "epoch:24 step:116695[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:24 step:116700[D loss: 0.999990] [G loss: 1.000037]\n",
      "epoch:24 step:116705[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:24 step:116710[D loss: 1.000002] [G loss: 0.999998]\n",
      "epoch:24 step:116715[D loss: 0.999931] [G loss: 1.000090]\n",
      "epoch:24 step:116720[D loss: 0.999998] [G loss: 1.000162]\n",
      "epoch:24 step:116725[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:24 step:116730[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:24 step:116735[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:24 step:116740[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:24 step:116745[D loss: 0.999955] [G loss: 1.000041]\n",
      "epoch:24 step:116750[D loss: 1.000005] [G loss: 1.000101]\n",
      "epoch:24 step:116755[D loss: 0.999965] [G loss: 1.000035]\n",
      "epoch:24 step:116760[D loss: 1.000048] [G loss: 1.000002]\n",
      "epoch:24 step:116765[D loss: 0.999937] [G loss: 1.000116]\n",
      "epoch:24 step:116770[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:24 step:116775[D loss: 1.000011] [G loss: 1.000035]\n",
      "epoch:24 step:116780[D loss: 1.000025] [G loss: 1.000002]\n",
      "epoch:24 step:116785[D loss: 1.000014] [G loss: 1.000049]\n",
      "epoch:24 step:116790[D loss: 0.999996] [G loss: 1.000142]\n",
      "epoch:24 step:116795[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:24 step:116800[D loss: 1.000008] [G loss: 1.000018]\n",
      "epoch:24 step:116805[D loss: 0.999947] [G loss: 1.000023]\n",
      "epoch:24 step:116810[D loss: 0.999971] [G loss: 1.000019]\n",
      "epoch:24 step:116815[D loss: 1.000046] [G loss: 0.999920]\n",
      "epoch:24 step:116820[D loss: 1.000041] [G loss: 0.999918]\n",
      "epoch:24 step:116825[D loss: 0.999963] [G loss: 0.999979]\n",
      "epoch:24 step:116830[D loss: 0.999968] [G loss: 1.000026]\n",
      "epoch:24 step:116835[D loss: 1.000049] [G loss: 0.999906]\n",
      "epoch:24 step:116840[D loss: 1.000010] [G loss: 1.000066]\n",
      "epoch:24 step:116845[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:24 step:116850[D loss: 0.999970] [G loss: 1.000038]\n",
      "epoch:24 step:116855[D loss: 0.999988] [G loss: 1.000018]\n",
      "epoch:24 step:116860[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:24 step:116865[D loss: 1.000049] [G loss: 1.000042]\n",
      "epoch:24 step:116870[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:24 step:116875[D loss: 0.999957] [G loss: 1.000100]\n",
      "epoch:24 step:116880[D loss: 0.999932] [G loss: 1.000124]\n",
      "epoch:24 step:116885[D loss: 1.000008] [G loss: 1.000039]\n",
      "epoch:24 step:116890[D loss: 0.999934] [G loss: 1.000097]\n",
      "epoch:24 step:116895[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:24 step:116900[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:24 step:116905[D loss: 0.999957] [G loss: 1.000056]\n",
      "epoch:24 step:116910[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:24 step:116915[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:24 step:116920[D loss: 1.000066] [G loss: 0.999943]\n",
      "epoch:24 step:116925[D loss: 1.000028] [G loss: 0.999936]\n",
      "epoch:24 step:116930[D loss: 0.999907] [G loss: 1.000095]\n",
      "epoch:24 step:116935[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:24 step:116940[D loss: 0.999997] [G loss: 1.000032]\n",
      "epoch:24 step:116945[D loss: 1.000045] [G loss: 1.000009]\n",
      "epoch:24 step:116950[D loss: 0.999982] [G loss: 1.000007]\n",
      "epoch:24 step:116955[D loss: 0.999985] [G loss: 1.000018]\n",
      "epoch:24 step:116960[D loss: 1.000034] [G loss: 0.999984]\n",
      "epoch:24 step:116965[D loss: 1.000004] [G loss: 0.999976]\n",
      "epoch:24 step:116970[D loss: 1.000062] [G loss: 1.000025]\n",
      "epoch:24 step:116975[D loss: 0.999938] [G loss: 1.000053]\n",
      "epoch:24 step:116980[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:24 step:116985[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:24 step:116990[D loss: 0.999991] [G loss: 1.000065]\n",
      "epoch:24 step:116995[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:24 step:117000[D loss: 0.999940] [G loss: 1.000067]\n",
      "epoch:24 step:117005[D loss: 0.999966] [G loss: 1.000019]\n",
      "epoch:24 step:117010[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:24 step:117015[D loss: 0.999978] [G loss: 1.000079]\n",
      "epoch:24 step:117020[D loss: 0.999974] [G loss: 0.999996]\n",
      "epoch:24 step:117025[D loss: 1.000082] [G loss: 0.999977]\n",
      "epoch:24 step:117030[D loss: 0.999976] [G loss: 0.999954]\n",
      "epoch:24 step:117035[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:24 step:117040[D loss: 1.000024] [G loss: 0.999988]\n",
      "epoch:24 step:117045[D loss: 0.999982] [G loss: 1.000017]\n",
      "epoch:24 step:117050[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:24 step:117055[D loss: 0.999924] [G loss: 1.000114]\n",
      "epoch:24 step:117060[D loss: 0.999952] [G loss: 1.000048]\n",
      "epoch:24 step:117065[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:24 step:117070[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:24 step:117075[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:24 step:117080[D loss: 1.000031] [G loss: 0.999957]\n",
      "epoch:24 step:117085[D loss: 0.999945] [G loss: 1.000059]\n",
      "epoch:24 step:117090[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:24 step:117095[D loss: 0.999978] [G loss: 1.000060]\n",
      "epoch:24 step:117100[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:24 step:117105[D loss: 1.000024] [G loss: 1.000043]\n",
      "epoch:24 step:117110[D loss: 0.999936] [G loss: 1.000072]\n",
      "epoch:24 step:117115[D loss: 0.999966] [G loss: 1.000106]\n",
      "epoch:24 step:117120[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:24 step:117125[D loss: 0.999998] [G loss: 1.000022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:117130[D loss: 1.000053] [G loss: 0.999972]\n",
      "epoch:25 step:117135[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:25 step:117140[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:25 step:117145[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:25 step:117150[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:25 step:117155[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:25 step:117160[D loss: 1.000028] [G loss: 0.999975]\n",
      "epoch:25 step:117165[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:25 step:117170[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:25 step:117175[D loss: 1.000000] [G loss: 1.000129]\n",
      "epoch:25 step:117180[D loss: 1.000015] [G loss: 0.999979]\n",
      "epoch:25 step:117185[D loss: 0.999902] [G loss: 1.000109]\n",
      "epoch:25 step:117190[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:25 step:117195[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:25 step:117200[D loss: 0.999976] [G loss: 1.000080]\n",
      "epoch:25 step:117205[D loss: 0.999974] [G loss: 1.000046]\n",
      "epoch:25 step:117210[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:25 step:117215[D loss: 0.999973] [G loss: 1.000069]\n",
      "epoch:25 step:117220[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:25 step:117225[D loss: 0.999971] [G loss: 1.000073]\n",
      "epoch:25 step:117230[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:25 step:117235[D loss: 1.000015] [G loss: 0.999996]\n",
      "epoch:25 step:117240[D loss: 0.999913] [G loss: 1.000125]\n",
      "epoch:25 step:117245[D loss: 1.000003] [G loss: 1.000026]\n",
      "epoch:25 step:117250[D loss: 0.999932] [G loss: 1.000097]\n",
      "epoch:25 step:117255[D loss: 0.999958] [G loss: 1.000137]\n",
      "epoch:25 step:117260[D loss: 1.000082] [G loss: 1.000039]\n",
      "epoch:25 step:117265[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:25 step:117270[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:25 step:117275[D loss: 0.999973] [G loss: 1.000034]\n",
      "epoch:25 step:117280[D loss: 1.000006] [G loss: 1.000030]\n",
      "epoch:25 step:117285[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:25 step:117290[D loss: 0.999969] [G loss: 1.000032]\n",
      "epoch:25 step:117295[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:25 step:117300[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:25 step:117305[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:25 step:117310[D loss: 0.999989] [G loss: 1.000052]\n",
      "epoch:25 step:117315[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:25 step:117320[D loss: 0.999990] [G loss: 1.000046]\n",
      "epoch:25 step:117325[D loss: 1.000062] [G loss: 1.000029]\n",
      "epoch:25 step:117330[D loss: 0.999923] [G loss: 1.000134]\n",
      "epoch:25 step:117335[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:25 step:117340[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:25 step:117345[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:25 step:117350[D loss: 0.999946] [G loss: 1.000078]\n",
      "epoch:25 step:117355[D loss: 0.999977] [G loss: 1.000009]\n",
      "epoch:25 step:117360[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:25 step:117365[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:25 step:117370[D loss: 0.999994] [G loss: 1.000030]\n",
      "epoch:25 step:117375[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:25 step:117380[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:25 step:117385[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:25 step:117390[D loss: 1.000023] [G loss: 1.000032]\n",
      "epoch:25 step:117395[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:25 step:117400[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:25 step:117405[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:25 step:117410[D loss: 0.999997] [G loss: 0.999991]\n",
      "epoch:25 step:117415[D loss: 1.000021] [G loss: 1.000049]\n",
      "epoch:25 step:117420[D loss: 0.999977] [G loss: 1.000104]\n",
      "epoch:25 step:117425[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:25 step:117430[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:25 step:117435[D loss: 0.999969] [G loss: 1.000037]\n",
      "epoch:25 step:117440[D loss: 1.000085] [G loss: 0.999866]\n",
      "epoch:25 step:117445[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:25 step:117450[D loss: 0.999987] [G loss: 0.999970]\n",
      "epoch:25 step:117455[D loss: 0.999992] [G loss: 0.999980]\n",
      "epoch:25 step:117460[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:25 step:117465[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:25 step:117470[D loss: 1.000083] [G loss: 0.999937]\n",
      "epoch:25 step:117475[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:25 step:117480[D loss: 1.000043] [G loss: 0.999981]\n",
      "epoch:25 step:117485[D loss: 1.000090] [G loss: 0.999916]\n",
      "epoch:25 step:117490[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:25 step:117495[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:25 step:117500[D loss: 1.000047] [G loss: 0.999976]\n",
      "epoch:25 step:117505[D loss: 0.999975] [G loss: 1.000039]\n",
      "epoch:25 step:117510[D loss: 1.000011] [G loss: 0.999995]\n",
      "epoch:25 step:117515[D loss: 1.000004] [G loss: 1.000023]\n",
      "epoch:25 step:117520[D loss: 0.999929] [G loss: 1.000108]\n",
      "epoch:25 step:117525[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:25 step:117530[D loss: 0.999996] [G loss: 1.000005]\n",
      "epoch:25 step:117535[D loss: 0.999980] [G loss: 1.000026]\n",
      "epoch:25 step:117540[D loss: 0.999937] [G loss: 1.000021]\n",
      "epoch:25 step:117545[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:25 step:117550[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:25 step:117555[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:25 step:117560[D loss: 1.000007] [G loss: 1.000025]\n",
      "epoch:25 step:117565[D loss: 1.000011] [G loss: 1.000036]\n",
      "epoch:25 step:117570[D loss: 1.000022] [G loss: 1.000047]\n",
      "epoch:25 step:117575[D loss: 0.999936] [G loss: 1.000132]\n",
      "epoch:25 step:117580[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:25 step:117585[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:25 step:117590[D loss: 1.000003] [G loss: 0.999960]\n",
      "epoch:25 step:117595[D loss: 1.000005] [G loss: 0.999962]\n",
      "epoch:25 step:117600[D loss: 1.000078] [G loss: 0.999993]\n",
      "epoch:25 step:117605[D loss: 0.999942] [G loss: 1.000125]\n",
      "epoch:25 step:117610[D loss: 1.000021] [G loss: 1.000090]\n",
      "epoch:25 step:117615[D loss: 0.999978] [G loss: 1.000170]\n",
      "epoch:25 step:117620[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:25 step:117625[D loss: 0.999961] [G loss: 1.000102]\n",
      "epoch:25 step:117630[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:25 step:117635[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:25 step:117640[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:25 step:117645[D loss: 0.999995] [G loss: 1.000029]\n",
      "epoch:25 step:117650[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:25 step:117655[D loss: 0.999984] [G loss: 1.000018]\n",
      "epoch:25 step:117660[D loss: 1.000034] [G loss: 1.000000]\n",
      "epoch:25 step:117665[D loss: 0.999899] [G loss: 1.000212]\n",
      "epoch:25 step:117670[D loss: 0.999949] [G loss: 1.000007]\n",
      "epoch:25 step:117675[D loss: 1.000038] [G loss: 1.000026]\n",
      "epoch:25 step:117680[D loss: 0.999950] [G loss: 1.000147]\n",
      "epoch:25 step:117685[D loss: 0.999928] [G loss: 1.000118]\n",
      "epoch:25 step:117690[D loss: 0.999994] [G loss: 1.000172]\n",
      "epoch:25 step:117695[D loss: 0.999935] [G loss: 1.000136]\n",
      "epoch:25 step:117700[D loss: 0.999995] [G loss: 1.000108]\n",
      "epoch:25 step:117705[D loss: 0.999973] [G loss: 1.000009]\n",
      "epoch:25 step:117710[D loss: 1.000138] [G loss: 0.999914]\n",
      "epoch:25 step:117715[D loss: 1.000089] [G loss: 0.999981]\n",
      "epoch:25 step:117720[D loss: 1.000094] [G loss: 1.000047]\n",
      "epoch:25 step:117725[D loss: 0.999995] [G loss: 0.999986]\n",
      "epoch:25 step:117730[D loss: 1.000002] [G loss: 1.000045]\n",
      "epoch:25 step:117735[D loss: 0.999896] [G loss: 1.000214]\n",
      "epoch:25 step:117740[D loss: 0.999935] [G loss: 1.000146]\n",
      "epoch:25 step:117745[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:25 step:117750[D loss: 1.000033] [G loss: 0.999950]\n",
      "epoch:25 step:117755[D loss: 0.999966] [G loss: 0.999978]\n",
      "epoch:25 step:117760[D loss: 0.999983] [G loss: 1.000086]\n",
      "epoch:25 step:117765[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:25 step:117770[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:25 step:117775[D loss: 0.999903] [G loss: 1.000082]\n",
      "epoch:25 step:117780[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:25 step:117785[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:25 step:117790[D loss: 1.000007] [G loss: 1.000014]\n",
      "epoch:25 step:117795[D loss: 0.999982] [G loss: 1.000086]\n",
      "epoch:25 step:117800[D loss: 0.999930] [G loss: 1.000089]\n",
      "epoch:25 step:117805[D loss: 0.999996] [G loss: 1.000020]\n",
      "epoch:25 step:117810[D loss: 0.999995] [G loss: 1.000064]\n",
      "epoch:25 step:117815[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:25 step:117820[D loss: 1.000016] [G loss: 1.000063]\n",
      "epoch:25 step:117825[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:25 step:117830[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:25 step:117835[D loss: 1.000012] [G loss: 0.999993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:117840[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:25 step:117845[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:25 step:117850[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:25 step:117855[D loss: 0.999971] [G loss: 1.000087]\n",
      "epoch:25 step:117860[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:25 step:117865[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:25 step:117870[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:25 step:117875[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:25 step:117880[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:25 step:117885[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:25 step:117890[D loss: 0.999965] [G loss: 1.000097]\n",
      "epoch:25 step:117895[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:25 step:117900[D loss: 1.000035] [G loss: 0.999972]\n",
      "epoch:25 step:117905[D loss: 1.000095] [G loss: 0.999938]\n",
      "epoch:25 step:117910[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:25 step:117915[D loss: 1.000047] [G loss: 0.999924]\n",
      "epoch:25 step:117920[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:25 step:117925[D loss: 1.000029] [G loss: 0.999987]\n",
      "epoch:25 step:117930[D loss: 1.000020] [G loss: 1.000006]\n",
      "epoch:25 step:117935[D loss: 1.000066] [G loss: 0.999943]\n",
      "epoch:25 step:117940[D loss: 0.999805] [G loss: 1.000318]\n",
      "epoch:25 step:117945[D loss: 0.999917] [G loss: 1.000122]\n",
      "epoch:25 step:117950[D loss: 0.999993] [G loss: 1.000042]\n",
      "epoch:25 step:117955[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:25 step:117960[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:25 step:117965[D loss: 1.000024] [G loss: 1.000016]\n",
      "epoch:25 step:117970[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:25 step:117975[D loss: 0.999971] [G loss: 1.000104]\n",
      "epoch:25 step:117980[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:25 step:117985[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:25 step:117990[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:25 step:117995[D loss: 0.999949] [G loss: 1.000090]\n",
      "epoch:25 step:118000[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:25 step:118005[D loss: 0.999951] [G loss: 1.000103]\n",
      "epoch:25 step:118010[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:25 step:118015[D loss: 0.999972] [G loss: 1.000128]\n",
      "epoch:25 step:118020[D loss: 0.999955] [G loss: 1.000186]\n",
      "epoch:25 step:118025[D loss: 0.999933] [G loss: 1.000139]\n",
      "epoch:25 step:118030[D loss: 0.999931] [G loss: 1.000156]\n",
      "epoch:25 step:118035[D loss: 0.999995] [G loss: 1.000067]\n",
      "epoch:25 step:118040[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:25 step:118045[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:25 step:118050[D loss: 1.000034] [G loss: 0.999997]\n",
      "epoch:25 step:118055[D loss: 0.999989] [G loss: 1.000019]\n",
      "epoch:25 step:118060[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:25 step:118065[D loss: 0.999957] [G loss: 1.000069]\n",
      "epoch:25 step:118070[D loss: 0.999997] [G loss: 1.000064]\n",
      "epoch:25 step:118075[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:25 step:118080[D loss: 0.999989] [G loss: 1.000053]\n",
      "epoch:25 step:118085[D loss: 0.999978] [G loss: 1.000020]\n",
      "epoch:25 step:118090[D loss: 1.000048] [G loss: 0.999999]\n",
      "epoch:25 step:118095[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:25 step:118100[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:25 step:118105[D loss: 1.000000] [G loss: 0.999989]\n",
      "epoch:25 step:118110[D loss: 1.000022] [G loss: 1.000048]\n",
      "epoch:25 step:118115[D loss: 1.000036] [G loss: 1.000064]\n",
      "epoch:25 step:118120[D loss: 0.999939] [G loss: 1.000081]\n",
      "epoch:25 step:118125[D loss: 1.000058] [G loss: 1.000091]\n",
      "epoch:25 step:118130[D loss: 0.999947] [G loss: 1.000145]\n",
      "epoch:25 step:118135[D loss: 0.999948] [G loss: 1.000140]\n",
      "epoch:25 step:118140[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:25 step:118145[D loss: 0.999975] [G loss: 1.000053]\n",
      "epoch:25 step:118150[D loss: 1.000003] [G loss: 1.000008]\n",
      "epoch:25 step:118155[D loss: 1.000017] [G loss: 0.999926]\n",
      "epoch:25 step:118160[D loss: 1.000061] [G loss: 1.000008]\n",
      "epoch:25 step:118165[D loss: 0.999871] [G loss: 1.000128]\n",
      "epoch:25 step:118170[D loss: 0.999974] [G loss: 1.000143]\n",
      "epoch:25 step:118175[D loss: 1.000019] [G loss: 1.000009]\n",
      "epoch:25 step:118180[D loss: 1.000006] [G loss: 1.000053]\n",
      "epoch:25 step:118185[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:25 step:118190[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:25 step:118195[D loss: 0.999975] [G loss: 1.000135]\n",
      "epoch:25 step:118200[D loss: 0.999917] [G loss: 1.000165]\n",
      "epoch:25 step:118205[D loss: 0.999986] [G loss: 1.000113]\n",
      "epoch:25 step:118210[D loss: 1.000155] [G loss: 0.999998]\n",
      "epoch:25 step:118215[D loss: 0.999954] [G loss: 1.000140]\n",
      "epoch:25 step:118220[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:25 step:118225[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:25 step:118230[D loss: 1.000046] [G loss: 0.999916]\n",
      "epoch:25 step:118235[D loss: 0.999928] [G loss: 1.000170]\n",
      "epoch:25 step:118240[D loss: 0.999986] [G loss: 1.000119]\n",
      "epoch:25 step:118245[D loss: 0.999917] [G loss: 1.000127]\n",
      "epoch:25 step:118250[D loss: 1.000007] [G loss: 1.000082]\n",
      "epoch:25 step:118255[D loss: 1.000042] [G loss: 1.000110]\n",
      "epoch:25 step:118260[D loss: 1.000054] [G loss: 1.000100]\n",
      "epoch:25 step:118265[D loss: 0.999911] [G loss: 1.000178]\n",
      "epoch:25 step:118270[D loss: 0.999923] [G loss: 1.000125]\n",
      "epoch:25 step:118275[D loss: 1.000026] [G loss: 1.000060]\n",
      "epoch:25 step:118280[D loss: 0.999933] [G loss: 1.000034]\n",
      "epoch:25 step:118285[D loss: 0.999938] [G loss: 1.000034]\n",
      "epoch:25 step:118290[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:25 step:118295[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:25 step:118300[D loss: 0.999980] [G loss: 1.000102]\n",
      "epoch:25 step:118305[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:25 step:118310[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:25 step:118315[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:25 step:118320[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:25 step:118325[D loss: 1.000027] [G loss: 0.999957]\n",
      "epoch:25 step:118330[D loss: 1.000047] [G loss: 0.999988]\n",
      "epoch:25 step:118335[D loss: 0.999943] [G loss: 1.000141]\n",
      "epoch:25 step:118340[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:25 step:118345[D loss: 0.999970] [G loss: 1.000144]\n",
      "epoch:25 step:118350[D loss: 0.999988] [G loss: 1.000055]\n",
      "epoch:25 step:118355[D loss: 0.999954] [G loss: 1.000094]\n",
      "epoch:25 step:118360[D loss: 0.999980] [G loss: 1.000025]\n",
      "epoch:25 step:118365[D loss: 1.000022] [G loss: 1.000070]\n",
      "epoch:25 step:118370[D loss: 0.999930] [G loss: 1.000104]\n",
      "epoch:25 step:118375[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:25 step:118380[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:25 step:118385[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:25 step:118390[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:25 step:118395[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:25 step:118400[D loss: 0.999990] [G loss: 1.000081]\n",
      "epoch:25 step:118405[D loss: 1.000002] [G loss: 1.000012]\n",
      "epoch:25 step:118410[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:25 step:118415[D loss: 1.000029] [G loss: 1.000078]\n",
      "epoch:25 step:118420[D loss: 0.999937] [G loss: 1.000085]\n",
      "epoch:25 step:118425[D loss: 1.000020] [G loss: 0.999963]\n",
      "epoch:25 step:118430[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:25 step:118435[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:25 step:118440[D loss: 1.000015] [G loss: 1.000038]\n",
      "epoch:25 step:118445[D loss: 0.999898] [G loss: 1.000117]\n",
      "epoch:25 step:118450[D loss: 0.999946] [G loss: 1.000075]\n",
      "epoch:25 step:118455[D loss: 1.000012] [G loss: 1.000094]\n",
      "epoch:25 step:118460[D loss: 1.000036] [G loss: 0.999926]\n",
      "epoch:25 step:118465[D loss: 0.999948] [G loss: 1.000065]\n",
      "epoch:25 step:118470[D loss: 0.999964] [G loss: 1.000019]\n",
      "epoch:25 step:118475[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:25 step:118480[D loss: 0.999996] [G loss: 1.000010]\n",
      "epoch:25 step:118485[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:25 step:118490[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:25 step:118495[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:25 step:118500[D loss: 1.000033] [G loss: 0.999953]\n",
      "epoch:25 step:118505[D loss: 0.999988] [G loss: 1.000045]\n",
      "epoch:25 step:118510[D loss: 0.999972] [G loss: 1.000011]\n",
      "epoch:25 step:118515[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:25 step:118520[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:25 step:118525[D loss: 1.000003] [G loss: 1.000000]\n",
      "epoch:25 step:118530[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:25 step:118535[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:25 step:118540[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:25 step:118545[D loss: 0.999985] [G loss: 1.000035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:118550[D loss: 1.000037] [G loss: 0.999982]\n",
      "epoch:25 step:118555[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:25 step:118560[D loss: 1.000001] [G loss: 1.000011]\n",
      "epoch:25 step:118565[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:25 step:118570[D loss: 0.999939] [G loss: 1.000087]\n",
      "epoch:25 step:118575[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:25 step:118580[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:25 step:118585[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:25 step:118590[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:25 step:118595[D loss: 0.999991] [G loss: 1.000005]\n",
      "epoch:25 step:118600[D loss: 1.000012] [G loss: 0.999997]\n",
      "epoch:25 step:118605[D loss: 0.999961] [G loss: 1.000052]\n",
      "epoch:25 step:118610[D loss: 0.999978] [G loss: 1.000049]\n",
      "epoch:25 step:118615[D loss: 1.000002] [G loss: 1.000076]\n",
      "epoch:25 step:118620[D loss: 0.999965] [G loss: 1.000043]\n",
      "epoch:25 step:118625[D loss: 1.000005] [G loss: 1.000039]\n",
      "epoch:25 step:118630[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:25 step:118635[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:25 step:118640[D loss: 1.000033] [G loss: 0.999960]\n",
      "epoch:25 step:118645[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:25 step:118650[D loss: 0.999998] [G loss: 1.000084]\n",
      "epoch:25 step:118655[D loss: 0.999984] [G loss: 1.000052]\n",
      "epoch:25 step:118660[D loss: 0.999979] [G loss: 1.000091]\n",
      "epoch:25 step:118665[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:25 step:118670[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:25 step:118675[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:25 step:118680[D loss: 1.000024] [G loss: 1.000040]\n",
      "epoch:25 step:118685[D loss: 0.999960] [G loss: 1.000046]\n",
      "epoch:25 step:118690[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:25 step:118695[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:25 step:118700[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:25 step:118705[D loss: 1.000009] [G loss: 1.000069]\n",
      "epoch:25 step:118710[D loss: 1.000007] [G loss: 0.999981]\n",
      "epoch:25 step:118715[D loss: 0.999971] [G loss: 1.000017]\n",
      "epoch:25 step:118720[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:25 step:118725[D loss: 0.999942] [G loss: 1.000072]\n",
      "epoch:25 step:118730[D loss: 1.000058] [G loss: 1.000078]\n",
      "epoch:25 step:118735[D loss: 1.000015] [G loss: 1.000036]\n",
      "epoch:25 step:118740[D loss: 0.999921] [G loss: 1.000249]\n",
      "epoch:25 step:118745[D loss: 0.999920] [G loss: 1.000109]\n",
      "epoch:25 step:118750[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:25 step:118755[D loss: 1.000081] [G loss: 0.999961]\n",
      "epoch:25 step:118760[D loss: 1.000003] [G loss: 1.000107]\n",
      "epoch:25 step:118765[D loss: 0.999949] [G loss: 1.000116]\n",
      "epoch:25 step:118770[D loss: 0.999916] [G loss: 1.000125]\n",
      "epoch:25 step:118775[D loss: 1.000014] [G loss: 1.000052]\n",
      "epoch:25 step:118780[D loss: 0.999953] [G loss: 1.000058]\n",
      "epoch:25 step:118785[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:25 step:118790[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:25 step:118795[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:25 step:118800[D loss: 0.999978] [G loss: 1.000029]\n",
      "epoch:25 step:118805[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:25 step:118810[D loss: 1.000019] [G loss: 1.000059]\n",
      "epoch:25 step:118815[D loss: 0.999906] [G loss: 1.000128]\n",
      "epoch:25 step:118820[D loss: 0.999929] [G loss: 1.000134]\n",
      "epoch:25 step:118825[D loss: 0.999948] [G loss: 1.000084]\n",
      "epoch:25 step:118830[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:25 step:118835[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:25 step:118840[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:25 step:118845[D loss: 1.000025] [G loss: 0.999997]\n",
      "epoch:25 step:118850[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:25 step:118855[D loss: 1.000029] [G loss: 1.000098]\n",
      "epoch:25 step:118860[D loss: 0.999935] [G loss: 1.000110]\n",
      "epoch:25 step:118865[D loss: 0.999951] [G loss: 1.000109]\n",
      "epoch:25 step:118870[D loss: 1.000040] [G loss: 1.000072]\n",
      "epoch:25 step:118875[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:25 step:118880[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:25 step:118885[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:25 step:118890[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:25 step:118895[D loss: 0.999977] [G loss: 1.000072]\n",
      "epoch:25 step:118900[D loss: 1.000065] [G loss: 0.999906]\n",
      "epoch:25 step:118905[D loss: 1.000015] [G loss: 0.999924]\n",
      "epoch:25 step:118910[D loss: 0.999990] [G loss: 1.000006]\n",
      "epoch:25 step:118915[D loss: 1.000122] [G loss: 0.999975]\n",
      "epoch:25 step:118920[D loss: 0.999937] [G loss: 1.000069]\n",
      "epoch:25 step:118925[D loss: 1.000051] [G loss: 1.000078]\n",
      "epoch:25 step:118930[D loss: 0.999934] [G loss: 1.000159]\n",
      "epoch:25 step:118935[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:25 step:118940[D loss: 1.000013] [G loss: 1.000012]\n",
      "epoch:25 step:118945[D loss: 1.000044] [G loss: 1.000040]\n",
      "epoch:25 step:118950[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:25 step:118955[D loss: 1.000015] [G loss: 1.000003]\n",
      "epoch:25 step:118960[D loss: 0.999988] [G loss: 1.000201]\n",
      "epoch:25 step:118965[D loss: 1.000028] [G loss: 1.000033]\n",
      "epoch:25 step:118970[D loss: 0.999911] [G loss: 1.000124]\n",
      "epoch:25 step:118975[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:25 step:118980[D loss: 0.999960] [G loss: 1.000116]\n",
      "epoch:25 step:118985[D loss: 0.999985] [G loss: 1.000088]\n",
      "epoch:25 step:118990[D loss: 0.999957] [G loss: 0.999998]\n",
      "epoch:25 step:118995[D loss: 1.000035] [G loss: 1.000028]\n",
      "epoch:25 step:119000[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:25 step:119005[D loss: 1.000019] [G loss: 0.999951]\n",
      "epoch:25 step:119010[D loss: 1.000087] [G loss: 0.999850]\n",
      "epoch:25 step:119015[D loss: 1.000243] [G loss: 0.999762]\n",
      "epoch:25 step:119020[D loss: 0.999918] [G loss: 1.000105]\n",
      "epoch:25 step:119025[D loss: 0.999828] [G loss: 1.000129]\n",
      "epoch:25 step:119030[D loss: 0.999907] [G loss: 1.000126]\n",
      "epoch:25 step:119035[D loss: 0.999990] [G loss: 1.000055]\n",
      "epoch:25 step:119040[D loss: 0.999938] [G loss: 1.000089]\n",
      "epoch:25 step:119045[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:25 step:119050[D loss: 1.000050] [G loss: 0.999984]\n",
      "epoch:25 step:119055[D loss: 0.999962] [G loss: 1.000046]\n",
      "epoch:25 step:119060[D loss: 1.000057] [G loss: 0.999991]\n",
      "epoch:25 step:119065[D loss: 1.000048] [G loss: 0.999909]\n",
      "epoch:25 step:119070[D loss: 0.999902] [G loss: 1.000085]\n",
      "epoch:25 step:119075[D loss: 1.000021] [G loss: 1.000050]\n",
      "epoch:25 step:119080[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:25 step:119085[D loss: 1.000009] [G loss: 1.000062]\n",
      "epoch:25 step:119090[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:25 step:119095[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:25 step:119100[D loss: 0.999942] [G loss: 1.000109]\n",
      "epoch:25 step:119105[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:25 step:119110[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:25 step:119115[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:25 step:119120[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:25 step:119125[D loss: 0.999929] [G loss: 1.000159]\n",
      "epoch:25 step:119130[D loss: 1.000084] [G loss: 0.999878]\n",
      "epoch:25 step:119135[D loss: 0.999952] [G loss: 1.000168]\n",
      "epoch:25 step:119140[D loss: 0.999985] [G loss: 1.000109]\n",
      "epoch:25 step:119145[D loss: 0.999897] [G loss: 1.000168]\n",
      "epoch:25 step:119150[D loss: 0.999976] [G loss: 1.000000]\n",
      "epoch:25 step:119155[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:25 step:119160[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:25 step:119165[D loss: 0.999965] [G loss: 1.000044]\n",
      "epoch:25 step:119170[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:25 step:119175[D loss: 1.000009] [G loss: 1.000127]\n",
      "epoch:25 step:119180[D loss: 0.999939] [G loss: 1.000103]\n",
      "epoch:25 step:119185[D loss: 1.000036] [G loss: 1.000033]\n",
      "epoch:25 step:119190[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:25 step:119195[D loss: 1.000002] [G loss: 1.000010]\n",
      "epoch:25 step:119200[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:25 step:119205[D loss: 0.999996] [G loss: 1.000036]\n",
      "epoch:25 step:119210[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:25 step:119215[D loss: 0.999954] [G loss: 1.000100]\n",
      "epoch:25 step:119220[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:25 step:119225[D loss: 0.999984] [G loss: 1.000074]\n",
      "epoch:25 step:119230[D loss: 1.000058] [G loss: 0.999980]\n",
      "epoch:25 step:119235[D loss: 1.000086] [G loss: 0.999907]\n",
      "epoch:25 step:119240[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:25 step:119245[D loss: 0.999920] [G loss: 1.000144]\n",
      "epoch:25 step:119250[D loss: 0.999940] [G loss: 1.000106]\n",
      "epoch:25 step:119255[D loss: 0.999994] [G loss: 1.000042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:119260[D loss: 1.000001] [G loss: 1.000099]\n",
      "epoch:25 step:119265[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:25 step:119270[D loss: 0.999932] [G loss: 1.000074]\n",
      "epoch:25 step:119275[D loss: 0.999990] [G loss: 1.000085]\n",
      "epoch:25 step:119280[D loss: 0.999915] [G loss: 1.000102]\n",
      "epoch:25 step:119285[D loss: 0.999970] [G loss: 1.000148]\n",
      "epoch:25 step:119290[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:25 step:119295[D loss: 1.000036] [G loss: 1.000029]\n",
      "epoch:25 step:119300[D loss: 0.999928] [G loss: 1.000148]\n",
      "epoch:25 step:119305[D loss: 0.999961] [G loss: 1.000047]\n",
      "epoch:25 step:119310[D loss: 1.000001] [G loss: 1.000014]\n",
      "epoch:25 step:119315[D loss: 1.000002] [G loss: 1.000054]\n",
      "epoch:25 step:119320[D loss: 0.999909] [G loss: 1.000079]\n",
      "epoch:25 step:119325[D loss: 0.999998] [G loss: 1.000012]\n",
      "epoch:25 step:119330[D loss: 0.999994] [G loss: 1.000001]\n",
      "epoch:25 step:119335[D loss: 0.999962] [G loss: 1.000101]\n",
      "epoch:25 step:119340[D loss: 0.999942] [G loss: 1.000089]\n",
      "epoch:25 step:119345[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:25 step:119350[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:25 step:119355[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:25 step:119360[D loss: 1.000030] [G loss: 1.000077]\n",
      "epoch:25 step:119365[D loss: 0.999933] [G loss: 1.000159]\n",
      "epoch:25 step:119370[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:25 step:119375[D loss: 0.999942] [G loss: 1.000118]\n",
      "epoch:25 step:119380[D loss: 0.999991] [G loss: 1.000052]\n",
      "epoch:25 step:119385[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:25 step:119390[D loss: 1.000004] [G loss: 0.999980]\n",
      "epoch:25 step:119395[D loss: 0.999937] [G loss: 1.000155]\n",
      "epoch:25 step:119400[D loss: 0.999896] [G loss: 1.000127]\n",
      "epoch:25 step:119405[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:25 step:119410[D loss: 1.000019] [G loss: 1.000079]\n",
      "epoch:25 step:119415[D loss: 1.000019] [G loss: 1.000082]\n",
      "epoch:25 step:119420[D loss: 0.999991] [G loss: 1.000305]\n",
      "epoch:25 step:119425[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:25 step:119430[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:25 step:119435[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:25 step:119440[D loss: 0.999989] [G loss: 0.999976]\n",
      "epoch:25 step:119445[D loss: 1.000018] [G loss: 1.000019]\n",
      "epoch:25 step:119450[D loss: 1.000126] [G loss: 0.999808]\n",
      "epoch:25 step:119455[D loss: 0.999979] [G loss: 1.000058]\n",
      "epoch:25 step:119460[D loss: 0.999941] [G loss: 1.000080]\n",
      "epoch:25 step:119465[D loss: 1.000060] [G loss: 1.000064]\n",
      "epoch:25 step:119470[D loss: 0.999943] [G loss: 1.000264]\n",
      "epoch:25 step:119475[D loss: 0.999927] [G loss: 1.000165]\n",
      "epoch:25 step:119480[D loss: 0.999961] [G loss: 1.000169]\n",
      "epoch:25 step:119485[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:25 step:119490[D loss: 0.999966] [G loss: 1.000027]\n",
      "epoch:25 step:119495[D loss: 1.000059] [G loss: 0.999951]\n",
      "epoch:25 step:119500[D loss: 1.000003] [G loss: 0.999932]\n",
      "epoch:25 step:119505[D loss: 0.999991] [G loss: 0.999984]\n",
      "epoch:25 step:119510[D loss: 0.999944] [G loss: 1.000044]\n",
      "epoch:25 step:119515[D loss: 1.000028] [G loss: 1.000049]\n",
      "epoch:25 step:119520[D loss: 0.999940] [G loss: 1.000081]\n",
      "epoch:25 step:119525[D loss: 0.999944] [G loss: 1.000062]\n",
      "epoch:25 step:119530[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:25 step:119535[D loss: 0.999971] [G loss: 1.000094]\n",
      "epoch:25 step:119540[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:25 step:119545[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:25 step:119550[D loss: 1.000059] [G loss: 1.000038]\n",
      "epoch:25 step:119555[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:25 step:119560[D loss: 0.999969] [G loss: 1.000113]\n",
      "epoch:25 step:119565[D loss: 0.999996] [G loss: 1.000086]\n",
      "epoch:25 step:119570[D loss: 0.999933] [G loss: 1.000147]\n",
      "epoch:25 step:119575[D loss: 1.000011] [G loss: 1.000059]\n",
      "epoch:25 step:119580[D loss: 0.999919] [G loss: 1.000145]\n",
      "epoch:25 step:119585[D loss: 0.999969] [G loss: 1.000110]\n",
      "epoch:25 step:119590[D loss: 0.999996] [G loss: 1.000145]\n",
      "epoch:25 step:119595[D loss: 0.999992] [G loss: 1.000116]\n",
      "epoch:25 step:119600[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:25 step:119605[D loss: 1.000037] [G loss: 1.000086]\n",
      "epoch:25 step:119610[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:25 step:119615[D loss: 1.000000] [G loss: 1.000048]\n",
      "epoch:25 step:119620[D loss: 1.000041] [G loss: 1.000038]\n",
      "epoch:25 step:119625[D loss: 1.000173] [G loss: 0.999902]\n",
      "epoch:25 step:119630[D loss: 0.999920] [G loss: 0.999995]\n",
      "epoch:25 step:119635[D loss: 0.999989] [G loss: 1.000044]\n",
      "epoch:25 step:119640[D loss: 0.999971] [G loss: 1.000024]\n",
      "epoch:25 step:119645[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:25 step:119650[D loss: 0.999956] [G loss: 1.000102]\n",
      "epoch:25 step:119655[D loss: 0.999889] [G loss: 1.000181]\n",
      "epoch:25 step:119660[D loss: 0.999970] [G loss: 1.000202]\n",
      "epoch:25 step:119665[D loss: 1.000045] [G loss: 1.000000]\n",
      "epoch:25 step:119670[D loss: 0.999871] [G loss: 1.000253]\n",
      "epoch:25 step:119675[D loss: 1.000161] [G loss: 0.999956]\n",
      "epoch:25 step:119680[D loss: 0.999946] [G loss: 1.000163]\n",
      "epoch:25 step:119685[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:25 step:119690[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:25 step:119695[D loss: 1.000060] [G loss: 0.999920]\n",
      "epoch:25 step:119700[D loss: 0.999992] [G loss: 0.999985]\n",
      "epoch:25 step:119705[D loss: 0.999936] [G loss: 1.000113]\n",
      "epoch:25 step:119710[D loss: 1.000111] [G loss: 0.999955]\n",
      "epoch:25 step:119715[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:25 step:119720[D loss: 1.000021] [G loss: 1.000005]\n",
      "epoch:25 step:119725[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:25 step:119730[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:25 step:119735[D loss: 0.999934] [G loss: 1.000083]\n",
      "epoch:25 step:119740[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:25 step:119745[D loss: 0.999934] [G loss: 1.000120]\n",
      "epoch:25 step:119750[D loss: 0.999986] [G loss: 1.000087]\n",
      "epoch:25 step:119755[D loss: 1.000010] [G loss: 1.000013]\n",
      "epoch:25 step:119760[D loss: 1.000029] [G loss: 0.999903]\n",
      "epoch:25 step:119765[D loss: 0.999929] [G loss: 1.000115]\n",
      "epoch:25 step:119770[D loss: 0.999990] [G loss: 1.000060]\n",
      "epoch:25 step:119775[D loss: 0.999994] [G loss: 1.000089]\n",
      "epoch:25 step:119780[D loss: 0.999950] [G loss: 1.000085]\n",
      "epoch:25 step:119785[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:25 step:119790[D loss: 1.000016] [G loss: 0.999975]\n",
      "epoch:25 step:119795[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:25 step:119800[D loss: 1.000005] [G loss: 1.000039]\n",
      "epoch:25 step:119805[D loss: 1.000011] [G loss: 1.000087]\n",
      "epoch:25 step:119810[D loss: 1.000016] [G loss: 1.000045]\n",
      "epoch:25 step:119815[D loss: 1.000094] [G loss: 0.999873]\n",
      "epoch:25 step:119820[D loss: 0.999994] [G loss: 1.000110]\n",
      "epoch:25 step:119825[D loss: 0.999885] [G loss: 1.000158]\n",
      "epoch:25 step:119830[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:25 step:119835[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:25 step:119840[D loss: 1.000132] [G loss: 0.999844]\n",
      "epoch:25 step:119845[D loss: 1.000085] [G loss: 0.999792]\n",
      "epoch:25 step:119850[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:25 step:119855[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:25 step:119860[D loss: 0.999924] [G loss: 1.000103]\n",
      "epoch:25 step:119865[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:25 step:119870[D loss: 0.999984] [G loss: 1.000001]\n",
      "epoch:25 step:119875[D loss: 0.999956] [G loss: 1.000129]\n",
      "epoch:25 step:119880[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:25 step:119885[D loss: 1.000014] [G loss: 0.999978]\n",
      "epoch:25 step:119890[D loss: 1.000005] [G loss: 0.999992]\n",
      "epoch:25 step:119895[D loss: 0.999970] [G loss: 1.000026]\n",
      "epoch:25 step:119900[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:25 step:119905[D loss: 0.999994] [G loss: 0.999990]\n",
      "epoch:25 step:119910[D loss: 0.999988] [G loss: 1.000105]\n",
      "epoch:25 step:119915[D loss: 0.999998] [G loss: 1.000046]\n",
      "epoch:25 step:119920[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:25 step:119925[D loss: 0.999959] [G loss: 1.000054]\n",
      "epoch:25 step:119930[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:25 step:119935[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:25 step:119940[D loss: 0.999996] [G loss: 1.000032]\n",
      "epoch:25 step:119945[D loss: 0.999956] [G loss: 1.000038]\n",
      "epoch:25 step:119950[D loss: 0.999948] [G loss: 1.000084]\n",
      "epoch:25 step:119955[D loss: 1.000019] [G loss: 0.999939]\n",
      "epoch:25 step:119960[D loss: 0.999946] [G loss: 1.000040]\n",
      "epoch:25 step:119965[D loss: 0.999969] [G loss: 1.000070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:119970[D loss: 0.999983] [G loss: 1.000050]\n",
      "epoch:25 step:119975[D loss: 0.999973] [G loss: 1.000045]\n",
      "epoch:25 step:119980[D loss: 0.999967] [G loss: 1.000033]\n",
      "epoch:25 step:119985[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:25 step:119990[D loss: 1.000030] [G loss: 1.000000]\n",
      "epoch:25 step:119995[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:25 step:120000[D loss: 1.000031] [G loss: 1.000061]\n",
      "epoch:25 step:120005[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:25 step:120010[D loss: 1.000002] [G loss: 0.999984]\n",
      "epoch:25 step:120015[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:25 step:120020[D loss: 0.999958] [G loss: 1.000107]\n",
      "epoch:25 step:120025[D loss: 1.000005] [G loss: 1.000055]\n",
      "epoch:25 step:120030[D loss: 1.000011] [G loss: 1.000005]\n",
      "epoch:25 step:120035[D loss: 1.000034] [G loss: 1.000010]\n",
      "epoch:25 step:120040[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:25 step:120045[D loss: 0.999958] [G loss: 1.000047]\n",
      "epoch:25 step:120050[D loss: 0.999964] [G loss: 1.000098]\n",
      "epoch:25 step:120055[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:25 step:120060[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:25 step:120065[D loss: 1.000001] [G loss: 1.000088]\n",
      "epoch:25 step:120070[D loss: 1.000071] [G loss: 0.999985]\n",
      "epoch:25 step:120075[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:25 step:120080[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:25 step:120085[D loss: 0.999969] [G loss: 1.000145]\n",
      "epoch:25 step:120090[D loss: 1.000021] [G loss: 1.000132]\n",
      "epoch:25 step:120095[D loss: 0.999927] [G loss: 1.000198]\n",
      "epoch:25 step:120100[D loss: 0.999995] [G loss: 1.000229]\n",
      "epoch:25 step:120105[D loss: 0.999909] [G loss: 1.000151]\n",
      "epoch:25 step:120110[D loss: 0.999931] [G loss: 1.000081]\n",
      "epoch:25 step:120115[D loss: 0.999976] [G loss: 1.000031]\n",
      "epoch:25 step:120120[D loss: 0.999975] [G loss: 1.000017]\n",
      "epoch:25 step:120125[D loss: 0.999996] [G loss: 0.999982]\n",
      "epoch:25 step:120130[D loss: 1.000011] [G loss: 1.000031]\n",
      "epoch:25 step:120135[D loss: 1.000080] [G loss: 0.999935]\n",
      "epoch:25 step:120140[D loss: 0.999948] [G loss: 1.000050]\n",
      "epoch:25 step:120145[D loss: 1.000007] [G loss: 1.000057]\n",
      "epoch:25 step:120150[D loss: 0.999969] [G loss: 1.000041]\n",
      "epoch:25 step:120155[D loss: 0.999988] [G loss: 1.000090]\n",
      "epoch:25 step:120160[D loss: 0.999996] [G loss: 1.000017]\n",
      "epoch:25 step:120165[D loss: 1.000001] [G loss: 1.000073]\n",
      "epoch:25 step:120170[D loss: 1.000012] [G loss: 1.000190]\n",
      "epoch:25 step:120175[D loss: 0.999964] [G loss: 0.999964]\n",
      "epoch:25 step:120180[D loss: 0.999971] [G loss: 1.000131]\n",
      "epoch:25 step:120185[D loss: 0.999972] [G loss: 1.000165]\n",
      "epoch:25 step:120190[D loss: 0.999958] [G loss: 1.000043]\n",
      "epoch:25 step:120195[D loss: 0.999978] [G loss: 1.000034]\n",
      "epoch:25 step:120200[D loss: 1.000004] [G loss: 0.999927]\n",
      "epoch:25 step:120205[D loss: 0.999987] [G loss: 0.999992]\n",
      "epoch:25 step:120210[D loss: 1.000053] [G loss: 1.000031]\n",
      "epoch:25 step:120215[D loss: 1.000034] [G loss: 1.000002]\n",
      "epoch:25 step:120220[D loss: 0.999946] [G loss: 1.000063]\n",
      "epoch:25 step:120225[D loss: 1.000007] [G loss: 1.000062]\n",
      "epoch:25 step:120230[D loss: 0.999970] [G loss: 1.000045]\n",
      "epoch:25 step:120235[D loss: 0.999931] [G loss: 1.000154]\n",
      "epoch:25 step:120240[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:25 step:120245[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:25 step:120250[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:25 step:120255[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:25 step:120260[D loss: 1.000025] [G loss: 1.000034]\n",
      "epoch:25 step:120265[D loss: 0.999936] [G loss: 1.000143]\n",
      "epoch:25 step:120270[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:25 step:120275[D loss: 0.999923] [G loss: 1.000142]\n",
      "epoch:25 step:120280[D loss: 0.999987] [G loss: 1.000000]\n",
      "epoch:25 step:120285[D loss: 0.999961] [G loss: 1.000098]\n",
      "epoch:25 step:120290[D loss: 0.999977] [G loss: 1.000082]\n",
      "epoch:25 step:120295[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:25 step:120300[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:25 step:120305[D loss: 1.000009] [G loss: 0.999949]\n",
      "epoch:25 step:120310[D loss: 1.000014] [G loss: 1.000068]\n",
      "epoch:25 step:120315[D loss: 0.999926] [G loss: 1.000086]\n",
      "epoch:25 step:120320[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:25 step:120325[D loss: 1.000034] [G loss: 1.000039]\n",
      "epoch:25 step:120330[D loss: 0.999918] [G loss: 1.000178]\n",
      "epoch:25 step:120335[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:25 step:120340[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:25 step:120345[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:25 step:120350[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:25 step:120355[D loss: 0.999990] [G loss: 1.000066]\n",
      "epoch:25 step:120360[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:25 step:120365[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:25 step:120370[D loss: 0.999976] [G loss: 1.000048]\n",
      "epoch:25 step:120375[D loss: 0.999957] [G loss: 1.000055]\n",
      "epoch:25 step:120380[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:25 step:120385[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:25 step:120390[D loss: 0.999962] [G loss: 1.000045]\n",
      "epoch:25 step:120395[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:25 step:120400[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:25 step:120405[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:25 step:120410[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:25 step:120415[D loss: 0.999977] [G loss: 1.000096]\n",
      "epoch:25 step:120420[D loss: 0.999969] [G loss: 1.000090]\n",
      "epoch:25 step:120425[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:25 step:120430[D loss: 0.999950] [G loss: 1.000128]\n",
      "epoch:25 step:120435[D loss: 1.000032] [G loss: 1.000084]\n",
      "epoch:25 step:120440[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:25 step:120445[D loss: 0.999923] [G loss: 1.000092]\n",
      "epoch:25 step:120450[D loss: 0.999989] [G loss: 0.999967]\n",
      "epoch:25 step:120455[D loss: 0.999960] [G loss: 1.000029]\n",
      "epoch:25 step:120460[D loss: 0.999936] [G loss: 1.000048]\n",
      "epoch:25 step:120465[D loss: 1.000041] [G loss: 0.999929]\n",
      "epoch:25 step:120470[D loss: 1.000003] [G loss: 0.999951]\n",
      "epoch:25 step:120475[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:25 step:120480[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:25 step:120485[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:25 step:120490[D loss: 1.000028] [G loss: 0.999960]\n",
      "epoch:25 step:120495[D loss: 0.999993] [G loss: 1.000001]\n",
      "epoch:25 step:120500[D loss: 0.999993] [G loss: 1.000065]\n",
      "epoch:25 step:120505[D loss: 0.999951] [G loss: 1.000066]\n",
      "epoch:25 step:120510[D loss: 1.000032] [G loss: 0.999967]\n",
      "epoch:25 step:120515[D loss: 1.000019] [G loss: 1.000065]\n",
      "epoch:25 step:120520[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:25 step:120525[D loss: 1.000059] [G loss: 0.999915]\n",
      "epoch:25 step:120530[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:25 step:120535[D loss: 1.000004] [G loss: 1.000079]\n",
      "epoch:25 step:120540[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:25 step:120545[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:25 step:120550[D loss: 0.999989] [G loss: 0.999932]\n",
      "epoch:25 step:120555[D loss: 1.000045] [G loss: 0.999858]\n",
      "epoch:25 step:120560[D loss: 0.999987] [G loss: 0.999956]\n",
      "epoch:25 step:120565[D loss: 1.000012] [G loss: 0.999940]\n",
      "epoch:25 step:120570[D loss: 1.000102] [G loss: 0.999900]\n",
      "epoch:25 step:120575[D loss: 0.999902] [G loss: 1.000059]\n",
      "epoch:25 step:120580[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:25 step:120585[D loss: 0.999965] [G loss: 1.000032]\n",
      "epoch:25 step:120590[D loss: 0.999973] [G loss: 1.000145]\n",
      "epoch:25 step:120595[D loss: 0.999919] [G loss: 1.000139]\n",
      "epoch:25 step:120600[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:25 step:120605[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:25 step:120610[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:25 step:120615[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:25 step:120620[D loss: 0.999971] [G loss: 1.000088]\n",
      "epoch:25 step:120625[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:25 step:120630[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:25 step:120635[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:25 step:120640[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:25 step:120645[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:25 step:120650[D loss: 1.000063] [G loss: 0.999942]\n",
      "epoch:25 step:120655[D loss: 1.000027] [G loss: 0.999975]\n",
      "epoch:25 step:120660[D loss: 0.999943] [G loss: 1.000134]\n",
      "epoch:25 step:120665[D loss: 0.999997] [G loss: 1.000060]\n",
      "epoch:25 step:120670[D loss: 0.999999] [G loss: 1.000006]\n",
      "epoch:25 step:120675[D loss: 1.000053] [G loss: 0.999973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:120680[D loss: 1.000021] [G loss: 0.999966]\n",
      "epoch:25 step:120685[D loss: 0.999948] [G loss: 1.000071]\n",
      "epoch:25 step:120690[D loss: 1.000010] [G loss: 0.999966]\n",
      "epoch:25 step:120695[D loss: 1.000134] [G loss: 1.000019]\n",
      "epoch:25 step:120700[D loss: 1.000057] [G loss: 0.999984]\n",
      "epoch:25 step:120705[D loss: 0.999922] [G loss: 1.000077]\n",
      "epoch:25 step:120710[D loss: 0.999991] [G loss: 1.000025]\n",
      "epoch:25 step:120715[D loss: 1.000003] [G loss: 1.000014]\n",
      "epoch:25 step:120720[D loss: 0.999965] [G loss: 1.000027]\n",
      "epoch:25 step:120725[D loss: 1.000007] [G loss: 1.000042]\n",
      "epoch:25 step:120730[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:25 step:120735[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:25 step:120740[D loss: 0.999997] [G loss: 1.000110]\n",
      "epoch:25 step:120745[D loss: 0.999920] [G loss: 1.000135]\n",
      "epoch:25 step:120750[D loss: 0.999959] [G loss: 1.000053]\n",
      "epoch:25 step:120755[D loss: 1.000027] [G loss: 0.999940]\n",
      "epoch:25 step:120760[D loss: 0.999961] [G loss: 1.000047]\n",
      "epoch:25 step:120765[D loss: 1.000039] [G loss: 1.000024]\n",
      "epoch:25 step:120770[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:25 step:120775[D loss: 1.000062] [G loss: 0.999954]\n",
      "epoch:25 step:120780[D loss: 0.999980] [G loss: 1.000025]\n",
      "epoch:25 step:120785[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:25 step:120790[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:25 step:120795[D loss: 0.999941] [G loss: 1.000130]\n",
      "epoch:25 step:120800[D loss: 0.999942] [G loss: 1.000100]\n",
      "epoch:25 step:120805[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:25 step:120810[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:25 step:120815[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:25 step:120820[D loss: 1.000009] [G loss: 1.000026]\n",
      "epoch:25 step:120825[D loss: 0.999941] [G loss: 1.000108]\n",
      "epoch:25 step:120830[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:25 step:120835[D loss: 1.000164] [G loss: 0.999896]\n",
      "epoch:25 step:120840[D loss: 0.999868] [G loss: 1.000052]\n",
      "epoch:25 step:120845[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:25 step:120850[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:25 step:120855[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:25 step:120860[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:25 step:120865[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:25 step:120870[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:25 step:120875[D loss: 1.000043] [G loss: 0.999997]\n",
      "epoch:25 step:120880[D loss: 0.999941] [G loss: 1.000119]\n",
      "epoch:25 step:120885[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:25 step:120890[D loss: 0.999984] [G loss: 1.000054]\n",
      "epoch:25 step:120895[D loss: 1.000004] [G loss: 1.000081]\n",
      "epoch:25 step:120900[D loss: 0.999914] [G loss: 1.000147]\n",
      "epoch:25 step:120905[D loss: 0.999999] [G loss: 1.000030]\n",
      "epoch:25 step:120910[D loss: 1.000033] [G loss: 0.999923]\n",
      "epoch:25 step:120915[D loss: 1.000004] [G loss: 0.999992]\n",
      "epoch:25 step:120920[D loss: 0.999886] [G loss: 1.000129]\n",
      "epoch:25 step:120925[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:25 step:120930[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:25 step:120935[D loss: 1.000025] [G loss: 1.000086]\n",
      "epoch:25 step:120940[D loss: 0.999948] [G loss: 1.000101]\n",
      "epoch:25 step:120945[D loss: 0.999954] [G loss: 1.000090]\n",
      "epoch:25 step:120950[D loss: 0.999994] [G loss: 0.999996]\n",
      "epoch:25 step:120955[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:25 step:120960[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:25 step:120965[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:25 step:120970[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:25 step:120975[D loss: 1.000026] [G loss: 1.000044]\n",
      "epoch:25 step:120980[D loss: 0.999972] [G loss: 1.000112]\n",
      "epoch:25 step:120985[D loss: 1.000038] [G loss: 0.999988]\n",
      "epoch:25 step:120990[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:25 step:120995[D loss: 0.999987] [G loss: 1.000106]\n",
      "epoch:25 step:121000[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:25 step:121005[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:25 step:121010[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:25 step:121015[D loss: 0.999984] [G loss: 1.000094]\n",
      "epoch:25 step:121020[D loss: 0.999988] [G loss: 1.000130]\n",
      "epoch:25 step:121025[D loss: 0.999981] [G loss: 1.000043]\n",
      "epoch:25 step:121030[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:25 step:121035[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:25 step:121040[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:25 step:121045[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:25 step:121050[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:25 step:121055[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:25 step:121060[D loss: 0.999979] [G loss: 1.000066]\n",
      "epoch:25 step:121065[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:25 step:121070[D loss: 1.000031] [G loss: 1.000015]\n",
      "epoch:25 step:121075[D loss: 0.999944] [G loss: 1.000090]\n",
      "epoch:25 step:121080[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:25 step:121085[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:25 step:121090[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:25 step:121095[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:25 step:121100[D loss: 1.000045] [G loss: 0.999985]\n",
      "epoch:25 step:121105[D loss: 1.000012] [G loss: 1.000043]\n",
      "epoch:25 step:121110[D loss: 0.999886] [G loss: 1.000171]\n",
      "epoch:25 step:121115[D loss: 0.999855] [G loss: 1.000275]\n",
      "epoch:25 step:121120[D loss: 0.999969] [G loss: 1.000101]\n",
      "epoch:25 step:121125[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:25 step:121130[D loss: 1.000053] [G loss: 0.999938]\n",
      "epoch:25 step:121135[D loss: 0.999945] [G loss: 1.000092]\n",
      "epoch:25 step:121140[D loss: 0.999974] [G loss: 1.000034]\n",
      "epoch:25 step:121145[D loss: 0.999948] [G loss: 1.000153]\n",
      "epoch:25 step:121150[D loss: 0.999981] [G loss: 1.000132]\n",
      "epoch:25 step:121155[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:25 step:121160[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:25 step:121165[D loss: 1.000085] [G loss: 0.999975]\n",
      "epoch:25 step:121170[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:25 step:121175[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:25 step:121180[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:25 step:121185[D loss: 1.000010] [G loss: 1.000054]\n",
      "epoch:25 step:121190[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:25 step:121195[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:25 step:121200[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:25 step:121205[D loss: 0.999980] [G loss: 1.000078]\n",
      "epoch:25 step:121210[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:25 step:121215[D loss: 1.000031] [G loss: 1.000000]\n",
      "epoch:25 step:121220[D loss: 0.999956] [G loss: 1.000051]\n",
      "epoch:25 step:121225[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:25 step:121230[D loss: 1.000046] [G loss: 0.999966]\n",
      "epoch:25 step:121235[D loss: 0.999996] [G loss: 1.000018]\n",
      "epoch:25 step:121240[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:25 step:121245[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:25 step:121250[D loss: 0.999956] [G loss: 1.000081]\n",
      "epoch:25 step:121255[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:25 step:121260[D loss: 0.999927] [G loss: 1.000125]\n",
      "epoch:25 step:121265[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:25 step:121270[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:25 step:121275[D loss: 1.000052] [G loss: 1.000006]\n",
      "epoch:25 step:121280[D loss: 1.000005] [G loss: 1.000052]\n",
      "epoch:25 step:121285[D loss: 1.000051] [G loss: 1.000060]\n",
      "epoch:25 step:121290[D loss: 0.999967] [G loss: 0.999991]\n",
      "epoch:25 step:121295[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:25 step:121300[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:25 step:121305[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:25 step:121310[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:25 step:121315[D loss: 1.000018] [G loss: 1.000004]\n",
      "epoch:25 step:121320[D loss: 0.999952] [G loss: 1.000045]\n",
      "epoch:25 step:121325[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:25 step:121330[D loss: 0.999995] [G loss: 1.000078]\n",
      "epoch:25 step:121335[D loss: 0.999971] [G loss: 1.000079]\n",
      "epoch:25 step:121340[D loss: 0.999991] [G loss: 1.000108]\n",
      "epoch:25 step:121345[D loss: 1.000012] [G loss: 1.000056]\n",
      "epoch:25 step:121350[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:25 step:121355[D loss: 1.000010] [G loss: 0.999994]\n",
      "epoch:25 step:121360[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:25 step:121365[D loss: 0.999960] [G loss: 1.000025]\n",
      "epoch:25 step:121370[D loss: 0.999966] [G loss: 1.000051]\n",
      "epoch:25 step:121375[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:25 step:121380[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:25 step:121385[D loss: 0.999972] [G loss: 1.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:121390[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:25 step:121395[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:25 step:121400[D loss: 0.999958] [G loss: 1.000057]\n",
      "epoch:25 step:121405[D loss: 1.000034] [G loss: 1.000018]\n",
      "epoch:25 step:121410[D loss: 0.999946] [G loss: 1.000068]\n",
      "epoch:25 step:121415[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:25 step:121420[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:25 step:121425[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:25 step:121430[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:25 step:121435[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:25 step:121440[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:25 step:121445[D loss: 1.000016] [G loss: 1.000009]\n",
      "epoch:25 step:121450[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:25 step:121455[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:25 step:121460[D loss: 1.000026] [G loss: 1.000031]\n",
      "epoch:25 step:121465[D loss: 0.999960] [G loss: 1.000099]\n",
      "epoch:25 step:121470[D loss: 0.999985] [G loss: 1.000078]\n",
      "epoch:25 step:121475[D loss: 0.999999] [G loss: 1.000109]\n",
      "epoch:25 step:121480[D loss: 0.999956] [G loss: 1.000071]\n",
      "epoch:25 step:121485[D loss: 1.000068] [G loss: 0.999932]\n",
      "epoch:25 step:121490[D loss: 0.999950] [G loss: 1.000031]\n",
      "epoch:25 step:121495[D loss: 1.000006] [G loss: 0.999954]\n",
      "epoch:25 step:121500[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:25 step:121505[D loss: 1.000079] [G loss: 0.999983]\n",
      "epoch:25 step:121510[D loss: 0.999953] [G loss: 1.000013]\n",
      "epoch:25 step:121515[D loss: 0.999981] [G loss: 1.000007]\n",
      "epoch:25 step:121520[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:25 step:121525[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:25 step:121530[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:25 step:121535[D loss: 0.999974] [G loss: 1.000041]\n",
      "epoch:25 step:121540[D loss: 1.000015] [G loss: 1.000025]\n",
      "epoch:25 step:121545[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:25 step:121550[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:25 step:121555[D loss: 1.000020] [G loss: 1.000000]\n",
      "epoch:25 step:121560[D loss: 0.999957] [G loss: 1.000077]\n",
      "epoch:25 step:121565[D loss: 0.999959] [G loss: 1.000052]\n",
      "epoch:25 step:121570[D loss: 0.999984] [G loss: 1.000096]\n",
      "epoch:25 step:121575[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:25 step:121580[D loss: 0.999995] [G loss: 1.000071]\n",
      "epoch:25 step:121585[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:25 step:121590[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:25 step:121595[D loss: 0.999984] [G loss: 1.000107]\n",
      "epoch:25 step:121600[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:25 step:121605[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:25 step:121610[D loss: 0.999993] [G loss: 1.000017]\n",
      "epoch:25 step:121615[D loss: 0.999941] [G loss: 1.000068]\n",
      "epoch:25 step:121620[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:25 step:121625[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:25 step:121630[D loss: 1.000016] [G loss: 1.000202]\n",
      "epoch:25 step:121635[D loss: 0.999877] [G loss: 1.000169]\n",
      "epoch:25 step:121640[D loss: 0.999939] [G loss: 1.000089]\n",
      "epoch:25 step:121645[D loss: 1.000012] [G loss: 1.000028]\n",
      "epoch:25 step:121650[D loss: 0.999999] [G loss: 0.999996]\n",
      "epoch:25 step:121655[D loss: 1.000015] [G loss: 1.000074]\n",
      "epoch:25 step:121660[D loss: 0.999983] [G loss: 1.000018]\n",
      "epoch:25 step:121665[D loss: 1.000039] [G loss: 1.000027]\n",
      "epoch:25 step:121670[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:25 step:121675[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:25 step:121680[D loss: 0.999959] [G loss: 1.000061]\n",
      "epoch:25 step:121685[D loss: 1.000003] [G loss: 1.000025]\n",
      "epoch:25 step:121690[D loss: 1.000050] [G loss: 0.999889]\n",
      "epoch:25 step:121695[D loss: 0.999902] [G loss: 1.000096]\n",
      "epoch:25 step:121700[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:25 step:121705[D loss: 1.000028] [G loss: 0.999875]\n",
      "epoch:25 step:121710[D loss: 0.999908] [G loss: 1.000243]\n",
      "epoch:25 step:121715[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:25 step:121720[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:25 step:121725[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:25 step:121730[D loss: 1.000034] [G loss: 1.000005]\n",
      "epoch:25 step:121735[D loss: 0.999936] [G loss: 1.000082]\n",
      "epoch:25 step:121740[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:25 step:121745[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:25 step:121750[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:25 step:121755[D loss: 0.999996] [G loss: 1.000014]\n",
      "epoch:25 step:121760[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:25 step:121765[D loss: 0.999962] [G loss: 1.000059]\n",
      "epoch:25 step:121770[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:25 step:121775[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:25 step:121780[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:25 step:121785[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:25 step:121790[D loss: 1.000019] [G loss: 1.000035]\n",
      "epoch:25 step:121795[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:25 step:121800[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:25 step:121805[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:25 step:121810[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:26 step:121815[D loss: 1.000014] [G loss: 1.000058]\n",
      "epoch:26 step:121820[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:26 step:121825[D loss: 1.000005] [G loss: 1.000014]\n",
      "epoch:26 step:121830[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:26 step:121835[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:26 step:121840[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:26 step:121845[D loss: 0.999992] [G loss: 1.000051]\n",
      "epoch:26 step:121850[D loss: 0.999984] [G loss: 1.000020]\n",
      "epoch:26 step:121855[D loss: 1.000087] [G loss: 0.999972]\n",
      "epoch:26 step:121860[D loss: 1.000000] [G loss: 1.000204]\n",
      "epoch:26 step:121865[D loss: 1.000072] [G loss: 0.999985]\n",
      "epoch:26 step:121870[D loss: 0.999971] [G loss: 1.000019]\n",
      "epoch:26 step:121875[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:26 step:121880[D loss: 0.999947] [G loss: 1.000082]\n",
      "epoch:26 step:121885[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:26 step:121890[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:26 step:121895[D loss: 0.999984] [G loss: 1.000008]\n",
      "epoch:26 step:121900[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:26 step:121905[D loss: 1.000029] [G loss: 0.999914]\n",
      "epoch:26 step:121910[D loss: 0.999996] [G loss: 1.000009]\n",
      "epoch:26 step:121915[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:26 step:121920[D loss: 1.000039] [G loss: 1.000072]\n",
      "epoch:26 step:121925[D loss: 0.999935] [G loss: 1.000091]\n",
      "epoch:26 step:121930[D loss: 0.999987] [G loss: 1.000084]\n",
      "epoch:26 step:121935[D loss: 0.999950] [G loss: 1.000102]\n",
      "epoch:26 step:121940[D loss: 0.999984] [G loss: 1.000087]\n",
      "epoch:26 step:121945[D loss: 0.999963] [G loss: 1.000176]\n",
      "epoch:26 step:121950[D loss: 0.999944] [G loss: 1.000109]\n",
      "epoch:26 step:121955[D loss: 0.999980] [G loss: 1.000062]\n",
      "epoch:26 step:121960[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:26 step:121965[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:26 step:121970[D loss: 0.999974] [G loss: 1.000119]\n",
      "epoch:26 step:121975[D loss: 0.999988] [G loss: 1.000074]\n",
      "epoch:26 step:121980[D loss: 1.000009] [G loss: 1.000073]\n",
      "epoch:26 step:121985[D loss: 0.999958] [G loss: 1.000126]\n",
      "epoch:26 step:121990[D loss: 0.999945] [G loss: 1.000140]\n",
      "epoch:26 step:121995[D loss: 0.999982] [G loss: 1.000099]\n",
      "epoch:26 step:122000[D loss: 0.999979] [G loss: 1.000007]\n",
      "epoch:26 step:122005[D loss: 1.000027] [G loss: 1.000040]\n",
      "epoch:26 step:122010[D loss: 1.000098] [G loss: 0.999978]\n",
      "epoch:26 step:122015[D loss: 1.000047] [G loss: 0.999971]\n",
      "epoch:26 step:122020[D loss: 0.999947] [G loss: 1.000051]\n",
      "epoch:26 step:122025[D loss: 1.000030] [G loss: 0.999989]\n",
      "epoch:26 step:122030[D loss: 0.999971] [G loss: 1.000007]\n",
      "epoch:26 step:122035[D loss: 0.999962] [G loss: 1.000115]\n",
      "epoch:26 step:122040[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:26 step:122045[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:26 step:122050[D loss: 0.999943] [G loss: 1.000111]\n",
      "epoch:26 step:122055[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:26 step:122060[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:26 step:122065[D loss: 0.999969] [G loss: 1.000105]\n",
      "epoch:26 step:122070[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:26 step:122075[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:26 step:122080[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:26 step:122085[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:26 step:122090[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:26 step:122095[D loss: 1.000004] [G loss: 1.000028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:122100[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:26 step:122105[D loss: 0.999983] [G loss: 1.000119]\n",
      "epoch:26 step:122110[D loss: 0.999908] [G loss: 1.000178]\n",
      "epoch:26 step:122115[D loss: 0.999984] [G loss: 1.000079]\n",
      "epoch:26 step:122120[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:26 step:122125[D loss: 1.000032] [G loss: 0.999984]\n",
      "epoch:26 step:122130[D loss: 1.000040] [G loss: 1.000011]\n",
      "epoch:26 step:122135[D loss: 0.999960] [G loss: 1.000003]\n",
      "epoch:26 step:122140[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:26 step:122145[D loss: 0.999954] [G loss: 1.000119]\n",
      "epoch:26 step:122150[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:26 step:122155[D loss: 1.000090] [G loss: 1.000026]\n",
      "epoch:26 step:122160[D loss: 1.000021] [G loss: 0.999999]\n",
      "epoch:26 step:122165[D loss: 0.999928] [G loss: 1.000154]\n",
      "epoch:26 step:122170[D loss: 0.999991] [G loss: 1.000098]\n",
      "epoch:26 step:122175[D loss: 0.999984] [G loss: 1.000045]\n",
      "epoch:26 step:122180[D loss: 1.000023] [G loss: 0.999944]\n",
      "epoch:26 step:122185[D loss: 1.000037] [G loss: 1.000075]\n",
      "epoch:26 step:122190[D loss: 1.000000] [G loss: 1.000029]\n",
      "epoch:26 step:122195[D loss: 0.999894] [G loss: 1.000135]\n",
      "epoch:26 step:122200[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:26 step:122205[D loss: 1.000004] [G loss: 1.000002]\n",
      "epoch:26 step:122210[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:26 step:122215[D loss: 0.999951] [G loss: 1.000135]\n",
      "epoch:26 step:122220[D loss: 1.000008] [G loss: 1.000041]\n",
      "epoch:26 step:122225[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:26 step:122230[D loss: 0.999944] [G loss: 1.000101]\n",
      "epoch:26 step:122235[D loss: 1.000042] [G loss: 1.000002]\n",
      "epoch:26 step:122240[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:26 step:122245[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:26 step:122250[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:26 step:122255[D loss: 1.000027] [G loss: 1.000054]\n",
      "epoch:26 step:122260[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:26 step:122265[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:26 step:122270[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:26 step:122275[D loss: 0.999991] [G loss: 1.000049]\n",
      "epoch:26 step:122280[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:26 step:122285[D loss: 1.000079] [G loss: 1.000015]\n",
      "epoch:26 step:122290[D loss: 0.999897] [G loss: 1.000285]\n",
      "epoch:26 step:122295[D loss: 1.000006] [G loss: 1.000122]\n",
      "epoch:26 step:122300[D loss: 0.999912] [G loss: 1.000231]\n",
      "epoch:26 step:122305[D loss: 0.999908] [G loss: 1.000185]\n",
      "epoch:26 step:122310[D loss: 0.999971] [G loss: 1.000116]\n",
      "epoch:26 step:122315[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:26 step:122320[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:26 step:122325[D loss: 0.999985] [G loss: 1.000011]\n",
      "epoch:26 step:122330[D loss: 1.000021] [G loss: 0.999996]\n",
      "epoch:26 step:122335[D loss: 1.000018] [G loss: 1.000045]\n",
      "epoch:26 step:122340[D loss: 0.999998] [G loss: 1.000008]\n",
      "epoch:26 step:122345[D loss: 1.000054] [G loss: 0.999984]\n",
      "epoch:26 step:122350[D loss: 1.000040] [G loss: 0.999973]\n",
      "epoch:26 step:122355[D loss: 0.999961] [G loss: 1.000041]\n",
      "epoch:26 step:122360[D loss: 0.999972] [G loss: 1.000114]\n",
      "epoch:26 step:122365[D loss: 0.999940] [G loss: 1.000131]\n",
      "epoch:26 step:122370[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:26 step:122375[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:26 step:122380[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:26 step:122385[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:26 step:122390[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:26 step:122395[D loss: 1.000017] [G loss: 1.000093]\n",
      "epoch:26 step:122400[D loss: 1.000220] [G loss: 0.999825]\n",
      "epoch:26 step:122405[D loss: 0.999875] [G loss: 1.000304]\n",
      "epoch:26 step:122410[D loss: 0.999970] [G loss: 1.000004]\n",
      "epoch:26 step:122415[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:26 step:122420[D loss: 0.999954] [G loss: 1.000175]\n",
      "epoch:26 step:122425[D loss: 0.999932] [G loss: 1.000166]\n",
      "epoch:26 step:122430[D loss: 0.999939] [G loss: 1.000153]\n",
      "epoch:26 step:122435[D loss: 1.000029] [G loss: 0.999967]\n",
      "epoch:26 step:122440[D loss: 0.999988] [G loss: 1.000029]\n",
      "epoch:26 step:122445[D loss: 0.999973] [G loss: 1.000013]\n",
      "epoch:26 step:122450[D loss: 1.000000] [G loss: 1.000017]\n",
      "epoch:26 step:122455[D loss: 0.999939] [G loss: 1.000079]\n",
      "epoch:26 step:122460[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:26 step:122465[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:26 step:122470[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:26 step:122475[D loss: 1.000071] [G loss: 0.999996]\n",
      "epoch:26 step:122480[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:26 step:122485[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:26 step:122490[D loss: 0.999931] [G loss: 1.000121]\n",
      "epoch:26 step:122495[D loss: 1.000005] [G loss: 1.000057]\n",
      "epoch:26 step:122500[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:26 step:122505[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:26 step:122510[D loss: 0.999973] [G loss: 1.000082]\n",
      "epoch:26 step:122515[D loss: 0.999989] [G loss: 1.000048]\n",
      "epoch:26 step:122520[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:26 step:122525[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:26 step:122530[D loss: 1.000001] [G loss: 1.000007]\n",
      "epoch:26 step:122535[D loss: 1.000014] [G loss: 1.000072]\n",
      "epoch:26 step:122540[D loss: 0.999988] [G loss: 1.000013]\n",
      "epoch:26 step:122545[D loss: 1.000004] [G loss: 1.000151]\n",
      "epoch:26 step:122550[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:26 step:122555[D loss: 1.000059] [G loss: 0.999912]\n",
      "epoch:26 step:122560[D loss: 1.000022] [G loss: 0.999957]\n",
      "epoch:26 step:122565[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:26 step:122570[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:26 step:122575[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:26 step:122580[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:26 step:122585[D loss: 0.999986] [G loss: 1.000106]\n",
      "epoch:26 step:122590[D loss: 1.000000] [G loss: 1.000098]\n",
      "epoch:26 step:122595[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:26 step:122600[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:26 step:122605[D loss: 0.999988] [G loss: 1.000027]\n",
      "epoch:26 step:122610[D loss: 1.000068] [G loss: 0.999922]\n",
      "epoch:26 step:122615[D loss: 0.999919] [G loss: 1.000148]\n",
      "epoch:26 step:122620[D loss: 1.000004] [G loss: 1.000121]\n",
      "epoch:26 step:122625[D loss: 0.999925] [G loss: 1.000103]\n",
      "epoch:26 step:122630[D loss: 0.999961] [G loss: 1.000049]\n",
      "epoch:26 step:122635[D loss: 1.000031] [G loss: 0.999976]\n",
      "epoch:26 step:122640[D loss: 1.000042] [G loss: 0.999950]\n",
      "epoch:26 step:122645[D loss: 0.999927] [G loss: 1.000082]\n",
      "epoch:26 step:122650[D loss: 0.999943] [G loss: 1.000067]\n",
      "epoch:26 step:122655[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:26 step:122660[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:26 step:122665[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:26 step:122670[D loss: 1.000024] [G loss: 0.999997]\n",
      "epoch:26 step:122675[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:26 step:122680[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:26 step:122685[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:26 step:122690[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:26 step:122695[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:26 step:122700[D loss: 1.000015] [G loss: 1.000040]\n",
      "epoch:26 step:122705[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:26 step:122710[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:26 step:122715[D loss: 1.000021] [G loss: 0.999971]\n",
      "epoch:26 step:122720[D loss: 0.999946] [G loss: 1.000124]\n",
      "epoch:26 step:122725[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:26 step:122730[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:26 step:122735[D loss: 1.000037] [G loss: 0.999968]\n",
      "epoch:26 step:122740[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:26 step:122745[D loss: 0.999996] [G loss: 1.000043]\n",
      "epoch:26 step:122750[D loss: 1.000060] [G loss: 1.000020]\n",
      "epoch:26 step:122755[D loss: 0.999982] [G loss: 1.000011]\n",
      "epoch:26 step:122760[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:26 step:122765[D loss: 0.999985] [G loss: 1.000069]\n",
      "epoch:26 step:122770[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:26 step:122775[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:26 step:122780[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:26 step:122785[D loss: 0.999976] [G loss: 1.000116]\n",
      "epoch:26 step:122790[D loss: 1.000003] [G loss: 1.000003]\n",
      "epoch:26 step:122795[D loss: 1.000018] [G loss: 1.000056]\n",
      "epoch:26 step:122800[D loss: 1.000114] [G loss: 0.999999]\n",
      "epoch:26 step:122805[D loss: 0.999932] [G loss: 1.000206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:122810[D loss: 1.000008] [G loss: 1.000197]\n",
      "epoch:26 step:122815[D loss: 0.999936] [G loss: 1.000201]\n",
      "epoch:26 step:122820[D loss: 0.999931] [G loss: 1.000199]\n",
      "epoch:26 step:122825[D loss: 0.999976] [G loss: 1.000110]\n",
      "epoch:26 step:122830[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:26 step:122835[D loss: 0.999989] [G loss: 1.000041]\n",
      "epoch:26 step:122840[D loss: 1.000057] [G loss: 0.999873]\n",
      "epoch:26 step:122845[D loss: 1.000074] [G loss: 0.999885]\n",
      "epoch:26 step:122850[D loss: 0.999917] [G loss: 1.000027]\n",
      "epoch:26 step:122855[D loss: 1.000072] [G loss: 0.999971]\n",
      "epoch:26 step:122860[D loss: 1.000068] [G loss: 0.999876]\n",
      "epoch:26 step:122865[D loss: 1.000025] [G loss: 0.999969]\n",
      "epoch:26 step:122870[D loss: 0.999957] [G loss: 1.000066]\n",
      "epoch:26 step:122875[D loss: 1.000045] [G loss: 1.000076]\n",
      "epoch:26 step:122880[D loss: 1.000074] [G loss: 0.999962]\n",
      "epoch:26 step:122885[D loss: 0.999938] [G loss: 1.000135]\n",
      "epoch:26 step:122890[D loss: 0.999973] [G loss: 1.000131]\n",
      "epoch:26 step:122895[D loss: 1.000107] [G loss: 1.000108]\n",
      "epoch:26 step:122900[D loss: 0.999922] [G loss: 1.000201]\n",
      "epoch:26 step:122905[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:26 step:122910[D loss: 1.000004] [G loss: 1.000018]\n",
      "epoch:26 step:122915[D loss: 0.999981] [G loss: 1.000050]\n",
      "epoch:26 step:122920[D loss: 1.000032] [G loss: 0.999982]\n",
      "epoch:26 step:122925[D loss: 1.000000] [G loss: 1.000033]\n",
      "epoch:26 step:122930[D loss: 0.999921] [G loss: 1.000093]\n",
      "epoch:26 step:122935[D loss: 1.000002] [G loss: 1.000034]\n",
      "epoch:26 step:122940[D loss: 1.000225] [G loss: 0.999787]\n",
      "epoch:26 step:122945[D loss: 1.000084] [G loss: 1.000065]\n",
      "epoch:26 step:122950[D loss: 0.999828] [G loss: 1.000222]\n",
      "epoch:26 step:122955[D loss: 0.999886] [G loss: 1.000142]\n",
      "epoch:26 step:122960[D loss: 1.000001] [G loss: 1.000131]\n",
      "epoch:26 step:122965[D loss: 0.999972] [G loss: 1.000127]\n",
      "epoch:26 step:122970[D loss: 0.999949] [G loss: 1.000130]\n",
      "epoch:26 step:122975[D loss: 0.999955] [G loss: 1.000172]\n",
      "epoch:26 step:122980[D loss: 0.999986] [G loss: 1.000107]\n",
      "epoch:26 step:122985[D loss: 0.999976] [G loss: 1.000140]\n",
      "epoch:26 step:122990[D loss: 0.999885] [G loss: 1.000203]\n",
      "epoch:26 step:122995[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:26 step:123000[D loss: 0.999989] [G loss: 0.999993]\n",
      "epoch:26 step:123005[D loss: 0.999944] [G loss: 1.000049]\n",
      "epoch:26 step:123010[D loss: 1.000042] [G loss: 0.999946]\n",
      "epoch:26 step:123015[D loss: 1.000042] [G loss: 0.999900]\n",
      "epoch:26 step:123020[D loss: 0.999931] [G loss: 1.000130]\n",
      "epoch:26 step:123025[D loss: 0.999936] [G loss: 1.000102]\n",
      "epoch:26 step:123030[D loss: 1.000082] [G loss: 1.000099]\n",
      "epoch:26 step:123035[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:26 step:123040[D loss: 0.999912] [G loss: 1.000217]\n",
      "epoch:26 step:123045[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:26 step:123050[D loss: 1.000021] [G loss: 1.000071]\n",
      "epoch:26 step:123055[D loss: 0.999945] [G loss: 1.000059]\n",
      "epoch:26 step:123060[D loss: 1.000010] [G loss: 1.000059]\n",
      "epoch:26 step:123065[D loss: 1.000030] [G loss: 1.000055]\n",
      "epoch:26 step:123070[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:26 step:123075[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:26 step:123080[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:26 step:123085[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:26 step:123090[D loss: 0.999957] [G loss: 1.000065]\n",
      "epoch:26 step:123095[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:26 step:123100[D loss: 1.000024] [G loss: 1.000101]\n",
      "epoch:26 step:123105[D loss: 0.999937] [G loss: 1.000143]\n",
      "epoch:26 step:123110[D loss: 1.000022] [G loss: 0.999997]\n",
      "epoch:26 step:123115[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:26 step:123120[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:26 step:123125[D loss: 0.999984] [G loss: 1.000124]\n",
      "epoch:26 step:123130[D loss: 0.999996] [G loss: 0.999969]\n",
      "epoch:26 step:123135[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:26 step:123140[D loss: 1.000036] [G loss: 1.000043]\n",
      "epoch:26 step:123145[D loss: 0.999946] [G loss: 1.000107]\n",
      "epoch:26 step:123150[D loss: 0.999971] [G loss: 1.000047]\n",
      "epoch:26 step:123155[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:26 step:123160[D loss: 1.000005] [G loss: 1.000038]\n",
      "epoch:26 step:123165[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:26 step:123170[D loss: 0.999981] [G loss: 1.000059]\n",
      "epoch:26 step:123175[D loss: 0.999982] [G loss: 1.000070]\n",
      "epoch:26 step:123180[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:26 step:123185[D loss: 1.000001] [G loss: 1.000084]\n",
      "epoch:26 step:123190[D loss: 1.000045] [G loss: 0.999970]\n",
      "epoch:26 step:123195[D loss: 0.999931] [G loss: 1.000112]\n",
      "epoch:26 step:123200[D loss: 1.000003] [G loss: 1.000093]\n",
      "epoch:26 step:123205[D loss: 0.999948] [G loss: 1.000153]\n",
      "epoch:26 step:123210[D loss: 1.000035] [G loss: 0.999988]\n",
      "epoch:26 step:123215[D loss: 0.999914] [G loss: 1.000097]\n",
      "epoch:26 step:123220[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:26 step:123225[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:26 step:123230[D loss: 1.000048] [G loss: 0.999933]\n",
      "epoch:26 step:123235[D loss: 0.999890] [G loss: 1.000173]\n",
      "epoch:26 step:123240[D loss: 0.999947] [G loss: 1.000026]\n",
      "epoch:26 step:123245[D loss: 0.999998] [G loss: 1.000005]\n",
      "epoch:26 step:123250[D loss: 0.999974] [G loss: 1.000020]\n",
      "epoch:26 step:123255[D loss: 0.999955] [G loss: 1.000061]\n",
      "epoch:26 step:123260[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:26 step:123265[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:26 step:123270[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:26 step:123275[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:26 step:123280[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:26 step:123285[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:26 step:123290[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:26 step:123295[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:26 step:123300[D loss: 1.000010] [G loss: 1.000017]\n",
      "epoch:26 step:123305[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:26 step:123310[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:26 step:123315[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:26 step:123320[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:26 step:123325[D loss: 0.999965] [G loss: 1.000102]\n",
      "epoch:26 step:123330[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:26 step:123335[D loss: 0.999988] [G loss: 1.000038]\n",
      "epoch:26 step:123340[D loss: 0.999978] [G loss: 1.000017]\n",
      "epoch:26 step:123345[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:26 step:123350[D loss: 0.999995] [G loss: 0.999974]\n",
      "epoch:26 step:123355[D loss: 1.000039] [G loss: 1.000007]\n",
      "epoch:26 step:123360[D loss: 1.000009] [G loss: 0.999974]\n",
      "epoch:26 step:123365[D loss: 1.000034] [G loss: 1.000019]\n",
      "epoch:26 step:123370[D loss: 1.000027] [G loss: 0.999912]\n",
      "epoch:26 step:123375[D loss: 0.999915] [G loss: 1.000143]\n",
      "epoch:26 step:123380[D loss: 1.000000] [G loss: 0.999994]\n",
      "epoch:26 step:123385[D loss: 1.000025] [G loss: 1.000115]\n",
      "epoch:26 step:123390[D loss: 1.000013] [G loss: 1.000107]\n",
      "epoch:26 step:123395[D loss: 0.999970] [G loss: 0.999955]\n",
      "epoch:26 step:123400[D loss: 0.999991] [G loss: 0.999974]\n",
      "epoch:26 step:123405[D loss: 1.000066] [G loss: 0.999875]\n",
      "epoch:26 step:123410[D loss: 0.999974] [G loss: 1.000010]\n",
      "epoch:26 step:123415[D loss: 1.000144] [G loss: 0.999915]\n",
      "epoch:26 step:123420[D loss: 0.999987] [G loss: 1.000155]\n",
      "epoch:26 step:123425[D loss: 1.000053] [G loss: 0.999987]\n",
      "epoch:26 step:123430[D loss: 0.999968] [G loss: 0.999980]\n",
      "epoch:26 step:123435[D loss: 0.999891] [G loss: 1.000165]\n",
      "epoch:26 step:123440[D loss: 1.000006] [G loss: 0.999980]\n",
      "epoch:26 step:123445[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:26 step:123450[D loss: 0.999963] [G loss: 1.000015]\n",
      "epoch:26 step:123455[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:26 step:123460[D loss: 1.000028] [G loss: 1.000036]\n",
      "epoch:26 step:123465[D loss: 0.999967] [G loss: 1.000043]\n",
      "epoch:26 step:123470[D loss: 0.999939] [G loss: 1.000062]\n",
      "epoch:26 step:123475[D loss: 0.999939] [G loss: 1.000094]\n",
      "epoch:26 step:123480[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:26 step:123485[D loss: 0.999959] [G loss: 1.000051]\n",
      "epoch:26 step:123490[D loss: 0.999976] [G loss: 1.000013]\n",
      "epoch:26 step:123495[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:26 step:123500[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:26 step:123505[D loss: 0.999996] [G loss: 1.000028]\n",
      "epoch:26 step:123510[D loss: 1.000002] [G loss: 0.999997]\n",
      "epoch:26 step:123515[D loss: 0.999961] [G loss: 1.000088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:123520[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:26 step:123525[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:26 step:123530[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:26 step:123535[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:26 step:123540[D loss: 1.000018] [G loss: 1.000051]\n",
      "epoch:26 step:123545[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:26 step:123550[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:26 step:123555[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:26 step:123560[D loss: 0.999956] [G loss: 1.000080]\n",
      "epoch:26 step:123565[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:26 step:123570[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:26 step:123575[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:26 step:123580[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:26 step:123585[D loss: 1.000021] [G loss: 1.000008]\n",
      "epoch:26 step:123590[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:26 step:123595[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:26 step:123600[D loss: 0.999997] [G loss: 1.000079]\n",
      "epoch:26 step:123605[D loss: 0.999954] [G loss: 1.000068]\n",
      "epoch:26 step:123610[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:26 step:123615[D loss: 0.999934] [G loss: 1.000075]\n",
      "epoch:26 step:123620[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:26 step:123625[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:26 step:123630[D loss: 1.000036] [G loss: 1.000051]\n",
      "epoch:26 step:123635[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:26 step:123640[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:26 step:123645[D loss: 1.000044] [G loss: 1.000035]\n",
      "epoch:26 step:123650[D loss: 0.999898] [G loss: 1.000229]\n",
      "epoch:26 step:123655[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:26 step:123660[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:26 step:123665[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:26 step:123670[D loss: 1.000026] [G loss: 0.999924]\n",
      "epoch:26 step:123675[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:26 step:123680[D loss: 0.999955] [G loss: 1.000048]\n",
      "epoch:26 step:123685[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:26 step:123690[D loss: 1.000016] [G loss: 1.000014]\n",
      "epoch:26 step:123695[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:26 step:123700[D loss: 1.000101] [G loss: 1.000063]\n",
      "epoch:26 step:123705[D loss: 0.999989] [G loss: 1.000025]\n",
      "epoch:26 step:123710[D loss: 0.999904] [G loss: 1.000117]\n",
      "epoch:26 step:123715[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:26 step:123720[D loss: 0.999962] [G loss: 1.000046]\n",
      "epoch:26 step:123725[D loss: 1.000047] [G loss: 1.000021]\n",
      "epoch:26 step:123730[D loss: 0.999989] [G loss: 1.000002]\n",
      "epoch:26 step:123735[D loss: 1.000139] [G loss: 0.999962]\n",
      "epoch:26 step:123740[D loss: 0.999851] [G loss: 1.000175]\n",
      "epoch:26 step:123745[D loss: 1.000106] [G loss: 1.000046]\n",
      "epoch:26 step:123750[D loss: 0.999871] [G loss: 1.000172]\n",
      "epoch:26 step:123755[D loss: 0.999906] [G loss: 1.000075]\n",
      "epoch:26 step:123760[D loss: 1.000078] [G loss: 1.000009]\n",
      "epoch:26 step:123765[D loss: 0.999950] [G loss: 1.000030]\n",
      "epoch:26 step:123770[D loss: 1.000023] [G loss: 1.000017]\n",
      "epoch:26 step:123775[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:26 step:123780[D loss: 0.999971] [G loss: 1.000022]\n",
      "epoch:26 step:123785[D loss: 0.999965] [G loss: 1.000049]\n",
      "epoch:26 step:123790[D loss: 1.000015] [G loss: 0.999992]\n",
      "epoch:26 step:123795[D loss: 1.000022] [G loss: 1.000025]\n",
      "epoch:26 step:123800[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:26 step:123805[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:26 step:123810[D loss: 1.000051] [G loss: 0.999964]\n",
      "epoch:26 step:123815[D loss: 1.000054] [G loss: 1.000012]\n",
      "epoch:26 step:123820[D loss: 0.999833] [G loss: 1.000345]\n",
      "epoch:26 step:123825[D loss: 0.999973] [G loss: 1.000182]\n",
      "epoch:26 step:123830[D loss: 0.999919] [G loss: 1.000148]\n",
      "epoch:26 step:123835[D loss: 0.999937] [G loss: 1.000050]\n",
      "epoch:26 step:123840[D loss: 0.999964] [G loss: 1.000059]\n",
      "epoch:26 step:123845[D loss: 1.000050] [G loss: 0.999996]\n",
      "epoch:26 step:123850[D loss: 0.999966] [G loss: 1.000018]\n",
      "epoch:26 step:123855[D loss: 0.999982] [G loss: 1.000012]\n",
      "epoch:26 step:123860[D loss: 1.000122] [G loss: 0.999912]\n",
      "epoch:26 step:123865[D loss: 0.999892] [G loss: 1.000125]\n",
      "epoch:26 step:123870[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:26 step:123875[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:26 step:123880[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:26 step:123885[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:26 step:123890[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:26 step:123895[D loss: 0.999955] [G loss: 1.000076]\n",
      "epoch:26 step:123900[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:26 step:123905[D loss: 1.000007] [G loss: 0.999976]\n",
      "epoch:26 step:123910[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:26 step:123915[D loss: 1.000044] [G loss: 1.000059]\n",
      "epoch:26 step:123920[D loss: 1.000000] [G loss: 1.000068]\n",
      "epoch:26 step:123925[D loss: 0.999949] [G loss: 1.000101]\n",
      "epoch:26 step:123930[D loss: 0.999924] [G loss: 1.000175]\n",
      "epoch:26 step:123935[D loss: 0.999993] [G loss: 1.000063]\n",
      "epoch:26 step:123940[D loss: 0.999963] [G loss: 1.000045]\n",
      "epoch:26 step:123945[D loss: 0.999992] [G loss: 0.999990]\n",
      "epoch:26 step:123950[D loss: 1.000010] [G loss: 0.999949]\n",
      "epoch:26 step:123955[D loss: 0.999901] [G loss: 1.000089]\n",
      "epoch:26 step:123960[D loss: 0.999959] [G loss: 0.999978]\n",
      "epoch:26 step:123965[D loss: 1.000038] [G loss: 0.999927]\n",
      "epoch:26 step:123970[D loss: 1.000053] [G loss: 0.999943]\n",
      "epoch:26 step:123975[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:26 step:123980[D loss: 0.999994] [G loss: 1.000079]\n",
      "epoch:26 step:123985[D loss: 0.999963] [G loss: 1.000117]\n",
      "epoch:26 step:123990[D loss: 0.999974] [G loss: 1.000043]\n",
      "epoch:26 step:123995[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:26 step:124000[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:26 step:124005[D loss: 0.999951] [G loss: 1.000083]\n",
      "epoch:26 step:124010[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:26 step:124015[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:26 step:124020[D loss: 1.000073] [G loss: 0.999860]\n",
      "epoch:26 step:124025[D loss: 1.000052] [G loss: 0.999921]\n",
      "epoch:26 step:124030[D loss: 1.000054] [G loss: 1.000003]\n",
      "epoch:26 step:124035[D loss: 0.999877] [G loss: 1.000125]\n",
      "epoch:26 step:124040[D loss: 1.000015] [G loss: 1.000114]\n",
      "epoch:26 step:124045[D loss: 1.000083] [G loss: 1.000128]\n",
      "epoch:26 step:124050[D loss: 0.999984] [G loss: 1.000107]\n",
      "epoch:26 step:124055[D loss: 0.999940] [G loss: 1.000111]\n",
      "epoch:26 step:124060[D loss: 0.999976] [G loss: 1.000111]\n",
      "epoch:26 step:124065[D loss: 1.000012] [G loss: 0.999947]\n",
      "epoch:26 step:124070[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:26 step:124075[D loss: 0.999926] [G loss: 1.000097]\n",
      "epoch:26 step:124080[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:26 step:124085[D loss: 0.999995] [G loss: 0.999989]\n",
      "epoch:26 step:124090[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:26 step:124095[D loss: 1.000022] [G loss: 1.000038]\n",
      "epoch:26 step:124100[D loss: 1.000080] [G loss: 0.999995]\n",
      "epoch:26 step:124105[D loss: 1.000173] [G loss: 0.999967]\n",
      "epoch:26 step:124110[D loss: 0.999931] [G loss: 1.000080]\n",
      "epoch:26 step:124115[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:26 step:124120[D loss: 0.999928] [G loss: 1.000086]\n",
      "epoch:26 step:124125[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:26 step:124130[D loss: 0.999985] [G loss: 1.000058]\n",
      "epoch:26 step:124135[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:26 step:124140[D loss: 0.999941] [G loss: 1.000104]\n",
      "epoch:26 step:124145[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:26 step:124150[D loss: 1.000077] [G loss: 0.999953]\n",
      "epoch:26 step:124155[D loss: 0.999987] [G loss: 1.000170]\n",
      "epoch:26 step:124160[D loss: 0.999919] [G loss: 1.000175]\n",
      "epoch:26 step:124165[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:26 step:124170[D loss: 0.999912] [G loss: 1.000168]\n",
      "epoch:26 step:124175[D loss: 0.999980] [G loss: 1.000088]\n",
      "epoch:26 step:124180[D loss: 0.999990] [G loss: 1.000003]\n",
      "epoch:26 step:124185[D loss: 0.999919] [G loss: 1.000094]\n",
      "epoch:26 step:124190[D loss: 1.000001] [G loss: 1.000028]\n",
      "epoch:26 step:124195[D loss: 0.999930] [G loss: 1.000058]\n",
      "epoch:26 step:124200[D loss: 1.000092] [G loss: 0.999976]\n",
      "epoch:26 step:124205[D loss: 0.999929] [G loss: 1.000058]\n",
      "epoch:26 step:124210[D loss: 0.999933] [G loss: 1.000078]\n",
      "epoch:26 step:124215[D loss: 1.000036] [G loss: 1.000069]\n",
      "epoch:26 step:124220[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:26 step:124225[D loss: 0.999970] [G loss: 1.000062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:124230[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:26 step:124235[D loss: 1.000064] [G loss: 1.000039]\n",
      "epoch:26 step:124240[D loss: 0.999907] [G loss: 1.000151]\n",
      "epoch:26 step:124245[D loss: 1.000015] [G loss: 1.000064]\n",
      "epoch:26 step:124250[D loss: 0.999992] [G loss: 1.000130]\n",
      "epoch:26 step:124255[D loss: 0.999949] [G loss: 1.000158]\n",
      "epoch:26 step:124260[D loss: 0.999948] [G loss: 1.000160]\n",
      "epoch:26 step:124265[D loss: 0.999955] [G loss: 1.000108]\n",
      "epoch:26 step:124270[D loss: 0.999960] [G loss: 1.000138]\n",
      "epoch:26 step:124275[D loss: 0.999982] [G loss: 1.000162]\n",
      "epoch:26 step:124280[D loss: 0.999914] [G loss: 1.000297]\n",
      "epoch:26 step:124285[D loss: 0.999923] [G loss: 1.000103]\n",
      "epoch:26 step:124290[D loss: 1.000066] [G loss: 1.000090]\n",
      "epoch:26 step:124295[D loss: 1.000048] [G loss: 1.000029]\n",
      "epoch:26 step:124300[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:26 step:124305[D loss: 1.000055] [G loss: 0.999906]\n",
      "epoch:26 step:124310[D loss: 1.000164] [G loss: 0.999839]\n",
      "epoch:26 step:124315[D loss: 0.999830] [G loss: 1.000094]\n",
      "epoch:26 step:124320[D loss: 0.999938] [G loss: 1.000044]\n",
      "epoch:26 step:124325[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:26 step:124330[D loss: 0.999911] [G loss: 1.000211]\n",
      "epoch:26 step:124335[D loss: 0.999929] [G loss: 1.000154]\n",
      "epoch:26 step:124340[D loss: 0.999943] [G loss: 1.000095]\n",
      "epoch:26 step:124345[D loss: 0.999961] [G loss: 1.000222]\n",
      "epoch:26 step:124350[D loss: 0.999986] [G loss: 1.000097]\n",
      "epoch:26 step:124355[D loss: 1.000055] [G loss: 0.999982]\n",
      "epoch:26 step:124360[D loss: 1.000219] [G loss: 1.000018]\n",
      "epoch:26 step:124365[D loss: 0.999898] [G loss: 1.000201]\n",
      "epoch:26 step:124370[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:26 step:124375[D loss: 0.999986] [G loss: 1.000026]\n",
      "epoch:26 step:124380[D loss: 1.000024] [G loss: 0.999941]\n",
      "epoch:26 step:124385[D loss: 1.000000] [G loss: 0.999940]\n",
      "epoch:26 step:124390[D loss: 0.999975] [G loss: 1.000011]\n",
      "epoch:26 step:124395[D loss: 1.000079] [G loss: 1.000037]\n",
      "epoch:26 step:124400[D loss: 1.000054] [G loss: 0.999841]\n",
      "epoch:26 step:124405[D loss: 0.999854] [G loss: 1.000200]\n",
      "epoch:26 step:124410[D loss: 0.999950] [G loss: 1.000141]\n",
      "epoch:26 step:124415[D loss: 1.000024] [G loss: 1.000045]\n",
      "epoch:26 step:124420[D loss: 0.999927] [G loss: 1.000085]\n",
      "epoch:26 step:124425[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:26 step:124430[D loss: 0.999992] [G loss: 1.000171]\n",
      "epoch:26 step:124435[D loss: 0.999952] [G loss: 1.000082]\n",
      "epoch:26 step:124440[D loss: 1.000050] [G loss: 0.999947]\n",
      "epoch:26 step:124445[D loss: 0.999938] [G loss: 0.999994]\n",
      "epoch:26 step:124450[D loss: 0.999951] [G loss: 1.000131]\n",
      "epoch:26 step:124455[D loss: 0.999950] [G loss: 1.000068]\n",
      "epoch:26 step:124460[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:26 step:124465[D loss: 0.999980] [G loss: 1.000049]\n",
      "epoch:26 step:124470[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:26 step:124475[D loss: 0.999989] [G loss: 1.000087]\n",
      "epoch:26 step:124480[D loss: 1.000063] [G loss: 0.999976]\n",
      "epoch:26 step:124485[D loss: 0.999959] [G loss: 1.000044]\n",
      "epoch:26 step:124490[D loss: 1.000017] [G loss: 1.000094]\n",
      "epoch:26 step:124495[D loss: 1.000003] [G loss: 1.000100]\n",
      "epoch:26 step:124500[D loss: 1.000054] [G loss: 0.999993]\n",
      "epoch:26 step:124505[D loss: 1.000052] [G loss: 1.000013]\n",
      "epoch:26 step:124510[D loss: 0.999985] [G loss: 1.000007]\n",
      "epoch:26 step:124515[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:26 step:124520[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:26 step:124525[D loss: 1.000102] [G loss: 0.999829]\n",
      "epoch:26 step:124530[D loss: 0.999972] [G loss: 1.000070]\n",
      "epoch:26 step:124535[D loss: 1.000073] [G loss: 0.999899]\n",
      "epoch:26 step:124540[D loss: 1.000086] [G loss: 0.999829]\n",
      "epoch:26 step:124545[D loss: 0.999896] [G loss: 1.000075]\n",
      "epoch:26 step:124550[D loss: 0.999988] [G loss: 1.000060]\n",
      "epoch:26 step:124555[D loss: 0.999994] [G loss: 1.000063]\n",
      "epoch:26 step:124560[D loss: 1.000059] [G loss: 1.000015]\n",
      "epoch:26 step:124565[D loss: 0.999935] [G loss: 1.000067]\n",
      "epoch:26 step:124570[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:26 step:124575[D loss: 0.999981] [G loss: 1.000001]\n",
      "epoch:26 step:124580[D loss: 1.000013] [G loss: 1.000029]\n",
      "epoch:26 step:124585[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:26 step:124590[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:26 step:124595[D loss: 1.000006] [G loss: 1.000022]\n",
      "epoch:26 step:124600[D loss: 1.000030] [G loss: 1.000000]\n",
      "epoch:26 step:124605[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:26 step:124610[D loss: 0.999946] [G loss: 1.000093]\n",
      "epoch:26 step:124615[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:26 step:124620[D loss: 0.999990] [G loss: 1.000039]\n",
      "epoch:26 step:124625[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:26 step:124630[D loss: 0.999950] [G loss: 1.000100]\n",
      "epoch:26 step:124635[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:26 step:124640[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:26 step:124645[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:26 step:124650[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:26 step:124655[D loss: 0.999994] [G loss: 1.000042]\n",
      "epoch:26 step:124660[D loss: 0.999927] [G loss: 1.000137]\n",
      "epoch:26 step:124665[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:26 step:124670[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:26 step:124675[D loss: 1.000001] [G loss: 1.000017]\n",
      "epoch:26 step:124680[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:26 step:124685[D loss: 1.000078] [G loss: 0.999956]\n",
      "epoch:26 step:124690[D loss: 0.999962] [G loss: 1.000054]\n",
      "epoch:26 step:124695[D loss: 0.999941] [G loss: 1.000064]\n",
      "epoch:26 step:124700[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:26 step:124705[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:26 step:124710[D loss: 1.000043] [G loss: 1.000041]\n",
      "epoch:26 step:124715[D loss: 0.999945] [G loss: 1.000048]\n",
      "epoch:26 step:124720[D loss: 1.000044] [G loss: 0.999956]\n",
      "epoch:26 step:124725[D loss: 0.999917] [G loss: 1.000148]\n",
      "epoch:26 step:124730[D loss: 0.999912] [G loss: 1.000114]\n",
      "epoch:26 step:124735[D loss: 0.999930] [G loss: 1.000129]\n",
      "epoch:26 step:124740[D loss: 0.999995] [G loss: 1.000016]\n",
      "epoch:26 step:124745[D loss: 1.000003] [G loss: 1.000090]\n",
      "epoch:26 step:124750[D loss: 1.000031] [G loss: 1.000087]\n",
      "epoch:26 step:124755[D loss: 1.000053] [G loss: 1.000105]\n",
      "epoch:26 step:124760[D loss: 0.999911] [G loss: 1.000149]\n",
      "epoch:26 step:124765[D loss: 0.999982] [G loss: 1.000050]\n",
      "epoch:26 step:124770[D loss: 1.000002] [G loss: 1.000067]\n",
      "epoch:26 step:124775[D loss: 1.000072] [G loss: 0.999989]\n",
      "epoch:26 step:124780[D loss: 1.000024] [G loss: 0.999873]\n",
      "epoch:26 step:124785[D loss: 1.000021] [G loss: 1.000283]\n",
      "epoch:26 step:124790[D loss: 0.999968] [G loss: 1.000115]\n",
      "epoch:26 step:124795[D loss: 0.999978] [G loss: 0.999944]\n",
      "epoch:26 step:124800[D loss: 0.999966] [G loss: 1.000198]\n",
      "epoch:26 step:124805[D loss: 0.999973] [G loss: 1.000100]\n",
      "epoch:26 step:124810[D loss: 0.999937] [G loss: 1.000158]\n",
      "epoch:26 step:124815[D loss: 1.000002] [G loss: 1.000048]\n",
      "epoch:26 step:124820[D loss: 1.000082] [G loss: 0.999860]\n",
      "epoch:26 step:124825[D loss: 0.999986] [G loss: 0.999912]\n",
      "epoch:26 step:124830[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:26 step:124835[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:26 step:124840[D loss: 1.000009] [G loss: 1.000015]\n",
      "epoch:26 step:124845[D loss: 0.999949] [G loss: 1.000139]\n",
      "epoch:26 step:124850[D loss: 0.999917] [G loss: 1.000160]\n",
      "epoch:26 step:124855[D loss: 1.000164] [G loss: 0.999899]\n",
      "epoch:26 step:124860[D loss: 0.999932] [G loss: 1.000036]\n",
      "epoch:26 step:124865[D loss: 1.000036] [G loss: 1.000082]\n",
      "epoch:26 step:124870[D loss: 0.999978] [G loss: 1.000125]\n",
      "epoch:26 step:124875[D loss: 0.999986] [G loss: 0.999945]\n",
      "epoch:26 step:124880[D loss: 1.000000] [G loss: 0.999913]\n",
      "epoch:26 step:124885[D loss: 0.999948] [G loss: 1.000049]\n",
      "epoch:26 step:124890[D loss: 0.999936] [G loss: 1.000085]\n",
      "epoch:26 step:124895[D loss: 1.000116] [G loss: 0.999911]\n",
      "epoch:26 step:124900[D loss: 1.000030] [G loss: 1.000039]\n",
      "epoch:26 step:124905[D loss: 0.999914] [G loss: 1.000048]\n",
      "epoch:26 step:124910[D loss: 1.000006] [G loss: 1.000163]\n",
      "epoch:26 step:124915[D loss: 0.999952] [G loss: 1.000013]\n",
      "epoch:26 step:124920[D loss: 1.000041] [G loss: 1.000085]\n",
      "epoch:26 step:124925[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:26 step:124930[D loss: 0.999920] [G loss: 1.000106]\n",
      "epoch:26 step:124935[D loss: 1.000015] [G loss: 1.000015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:124940[D loss: 0.999977] [G loss: 1.000064]\n",
      "epoch:26 step:124945[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:26 step:124950[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:26 step:124955[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:26 step:124960[D loss: 1.000011] [G loss: 1.000012]\n",
      "epoch:26 step:124965[D loss: 0.999907] [G loss: 1.000189]\n",
      "epoch:26 step:124970[D loss: 1.000019] [G loss: 1.000068]\n",
      "epoch:26 step:124975[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:26 step:124980[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:26 step:124985[D loss: 1.000015] [G loss: 0.999980]\n",
      "epoch:26 step:124990[D loss: 0.999981] [G loss: 1.000020]\n",
      "epoch:26 step:124995[D loss: 1.000135] [G loss: 0.999858]\n",
      "epoch:26 step:125000[D loss: 0.999880] [G loss: 1.000059]\n",
      "epoch:26 step:125005[D loss: 0.999929] [G loss: 1.000078]\n",
      "epoch:26 step:125010[D loss: 1.000041] [G loss: 1.000132]\n",
      "epoch:26 step:125015[D loss: 0.999926] [G loss: 1.000153]\n",
      "epoch:26 step:125020[D loss: 1.000002] [G loss: 1.000053]\n",
      "epoch:26 step:125025[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:26 step:125030[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:26 step:125035[D loss: 1.000039] [G loss: 0.999983]\n",
      "epoch:26 step:125040[D loss: 1.000043] [G loss: 0.999980]\n",
      "epoch:26 step:125045[D loss: 0.999941] [G loss: 1.000038]\n",
      "epoch:26 step:125050[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:26 step:125055[D loss: 0.999991] [G loss: 1.000087]\n",
      "epoch:26 step:125060[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:26 step:125065[D loss: 1.000007] [G loss: 1.000066]\n",
      "epoch:26 step:125070[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:26 step:125075[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:26 step:125080[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:26 step:125085[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:26 step:125090[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:26 step:125095[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:26 step:125100[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:26 step:125105[D loss: 0.999983] [G loss: 1.000057]\n",
      "epoch:26 step:125110[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:26 step:125115[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:26 step:125120[D loss: 1.000018] [G loss: 1.000067]\n",
      "epoch:26 step:125125[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:26 step:125130[D loss: 0.999965] [G loss: 1.000074]\n",
      "epoch:26 step:125135[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:26 step:125140[D loss: 1.000042] [G loss: 0.999936]\n",
      "epoch:26 step:125145[D loss: 0.999884] [G loss: 1.000098]\n",
      "epoch:26 step:125150[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:26 step:125155[D loss: 0.999993] [G loss: 1.000039]\n",
      "epoch:26 step:125160[D loss: 0.999973] [G loss: 1.000054]\n",
      "epoch:26 step:125165[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:26 step:125170[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:26 step:125175[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:26 step:125180[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:26 step:125185[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:26 step:125190[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:26 step:125195[D loss: 0.999912] [G loss: 1.000175]\n",
      "epoch:26 step:125200[D loss: 1.000090] [G loss: 0.999927]\n",
      "epoch:26 step:125205[D loss: 1.000060] [G loss: 0.999958]\n",
      "epoch:26 step:125210[D loss: 0.999910] [G loss: 1.000184]\n",
      "epoch:26 step:125215[D loss: 0.999916] [G loss: 1.000118]\n",
      "epoch:26 step:125220[D loss: 0.999989] [G loss: 1.000076]\n",
      "epoch:26 step:125225[D loss: 0.999982] [G loss: 1.000023]\n",
      "epoch:26 step:125230[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:26 step:125235[D loss: 1.000014] [G loss: 1.000001]\n",
      "epoch:26 step:125240[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:26 step:125245[D loss: 0.999980] [G loss: 1.000020]\n",
      "epoch:26 step:125250[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:26 step:125255[D loss: 1.000071] [G loss: 0.999927]\n",
      "epoch:26 step:125260[D loss: 0.999912] [G loss: 1.000109]\n",
      "epoch:26 step:125265[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:26 step:125270[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:26 step:125275[D loss: 1.000021] [G loss: 1.000097]\n",
      "epoch:26 step:125280[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:26 step:125285[D loss: 0.999928] [G loss: 1.000092]\n",
      "epoch:26 step:125290[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:26 step:125295[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:26 step:125300[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:26 step:125305[D loss: 1.000012] [G loss: 0.999995]\n",
      "epoch:26 step:125310[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:26 step:125315[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:26 step:125320[D loss: 0.999988] [G loss: 1.000042]\n",
      "epoch:26 step:125325[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:26 step:125330[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:26 step:125335[D loss: 0.999983] [G loss: 1.000105]\n",
      "epoch:26 step:125340[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:26 step:125345[D loss: 0.999948] [G loss: 1.000116]\n",
      "epoch:26 step:125350[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:26 step:125355[D loss: 1.000068] [G loss: 0.999948]\n",
      "epoch:26 step:125360[D loss: 1.000034] [G loss: 1.000046]\n",
      "epoch:26 step:125365[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:26 step:125370[D loss: 0.999884] [G loss: 1.000169]\n",
      "epoch:26 step:125375[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:26 step:125380[D loss: 1.000207] [G loss: 1.000032]\n",
      "epoch:26 step:125385[D loss: 0.999978] [G loss: 1.000077]\n",
      "epoch:26 step:125390[D loss: 0.999948] [G loss: 1.000045]\n",
      "epoch:26 step:125395[D loss: 1.000013] [G loss: 0.999966]\n",
      "epoch:26 step:125400[D loss: 1.000011] [G loss: 0.999932]\n",
      "epoch:26 step:125405[D loss: 1.000107] [G loss: 0.999870]\n",
      "epoch:26 step:125410[D loss: 0.999952] [G loss: 1.000031]\n",
      "epoch:26 step:125415[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:26 step:125420[D loss: 0.999969] [G loss: 1.000092]\n",
      "epoch:26 step:125425[D loss: 1.000036] [G loss: 1.000047]\n",
      "epoch:26 step:125430[D loss: 1.000005] [G loss: 1.000109]\n",
      "epoch:26 step:125435[D loss: 0.999940] [G loss: 1.000095]\n",
      "epoch:26 step:125440[D loss: 0.999933] [G loss: 1.000073]\n",
      "epoch:26 step:125445[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:26 step:125450[D loss: 1.000030] [G loss: 0.999965]\n",
      "epoch:26 step:125455[D loss: 0.999942] [G loss: 1.000048]\n",
      "epoch:26 step:125460[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:26 step:125465[D loss: 0.999986] [G loss: 1.000031]\n",
      "epoch:26 step:125470[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:26 step:125475[D loss: 0.999949] [G loss: 1.000042]\n",
      "epoch:26 step:125480[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:26 step:125485[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:26 step:125490[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:26 step:125495[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:26 step:125500[D loss: 0.999936] [G loss: 1.000104]\n",
      "epoch:26 step:125505[D loss: 0.999946] [G loss: 1.000190]\n",
      "epoch:26 step:125510[D loss: 0.999924] [G loss: 1.000140]\n",
      "epoch:26 step:125515[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:26 step:125520[D loss: 1.000219] [G loss: 0.999761]\n",
      "epoch:26 step:125525[D loss: 0.999904] [G loss: 0.999979]\n",
      "epoch:26 step:125530[D loss: 1.000004] [G loss: 0.999992]\n",
      "epoch:26 step:125535[D loss: 0.999943] [G loss: 1.000076]\n",
      "epoch:26 step:125540[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:26 step:125545[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:26 step:125550[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:26 step:125555[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:26 step:125560[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:26 step:125565[D loss: 0.999999] [G loss: 0.999996]\n",
      "epoch:26 step:125570[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:26 step:125575[D loss: 0.999939] [G loss: 1.000071]\n",
      "epoch:26 step:125580[D loss: 1.000066] [G loss: 1.000030]\n",
      "epoch:26 step:125585[D loss: 0.999994] [G loss: 1.000097]\n",
      "epoch:26 step:125590[D loss: 0.999941] [G loss: 1.000108]\n",
      "epoch:26 step:125595[D loss: 0.999978] [G loss: 1.000059]\n",
      "epoch:26 step:125600[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:26 step:125605[D loss: 0.999928] [G loss: 1.000116]\n",
      "epoch:26 step:125610[D loss: 1.000025] [G loss: 1.000032]\n",
      "epoch:26 step:125615[D loss: 1.000016] [G loss: 1.000047]\n",
      "epoch:26 step:125620[D loss: 1.000161] [G loss: 0.999914]\n",
      "epoch:26 step:125625[D loss: 0.999910] [G loss: 1.000098]\n",
      "epoch:26 step:125630[D loss: 0.999918] [G loss: 1.000191]\n",
      "epoch:26 step:125635[D loss: 0.999922] [G loss: 1.000108]\n",
      "epoch:26 step:125640[D loss: 0.999937] [G loss: 1.000099]\n",
      "epoch:26 step:125645[D loss: 0.999970] [G loss: 1.000120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:125650[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:26 step:125655[D loss: 0.999982] [G loss: 1.000082]\n",
      "epoch:26 step:125660[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:26 step:125665[D loss: 1.000000] [G loss: 0.999967]\n",
      "epoch:26 step:125670[D loss: 1.000039] [G loss: 0.999965]\n",
      "epoch:26 step:125675[D loss: 0.999891] [G loss: 1.000169]\n",
      "epoch:26 step:125680[D loss: 1.000076] [G loss: 1.000003]\n",
      "epoch:26 step:125685[D loss: 0.999914] [G loss: 1.000075]\n",
      "epoch:26 step:125690[D loss: 0.999974] [G loss: 1.000138]\n",
      "epoch:26 step:125695[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:26 step:125700[D loss: 1.000002] [G loss: 1.000070]\n",
      "epoch:26 step:125705[D loss: 1.000045] [G loss: 0.999984]\n",
      "epoch:26 step:125710[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:26 step:125715[D loss: 0.999999] [G loss: 1.000050]\n",
      "epoch:26 step:125720[D loss: 0.999910] [G loss: 1.000137]\n",
      "epoch:26 step:125725[D loss: 0.999974] [G loss: 1.000038]\n",
      "epoch:26 step:125730[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:26 step:125735[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:26 step:125740[D loss: 0.999957] [G loss: 1.000104]\n",
      "epoch:26 step:125745[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:26 step:125750[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:26 step:125755[D loss: 1.000011] [G loss: 1.000077]\n",
      "epoch:26 step:125760[D loss: 0.999885] [G loss: 1.000109]\n",
      "epoch:26 step:125765[D loss: 0.999929] [G loss: 1.000088]\n",
      "epoch:26 step:125770[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:26 step:125775[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:26 step:125780[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:26 step:125785[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:26 step:125790[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:26 step:125795[D loss: 0.999999] [G loss: 1.000010]\n",
      "epoch:26 step:125800[D loss: 1.000028] [G loss: 1.000055]\n",
      "epoch:26 step:125805[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:26 step:125810[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:26 step:125815[D loss: 1.000017] [G loss: 1.000005]\n",
      "epoch:26 step:125820[D loss: 0.999941] [G loss: 1.000095]\n",
      "epoch:26 step:125825[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:26 step:125830[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:26 step:125835[D loss: 0.999990] [G loss: 1.000089]\n",
      "epoch:26 step:125840[D loss: 0.999974] [G loss: 1.000027]\n",
      "epoch:26 step:125845[D loss: 0.999957] [G loss: 1.000107]\n",
      "epoch:26 step:125850[D loss: 1.000022] [G loss: 1.000069]\n",
      "epoch:26 step:125855[D loss: 0.999935] [G loss: 1.000058]\n",
      "epoch:26 step:125860[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:26 step:125865[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:26 step:125870[D loss: 1.000022] [G loss: 1.000087]\n",
      "epoch:26 step:125875[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:26 step:125880[D loss: 1.000019] [G loss: 0.999955]\n",
      "epoch:26 step:125885[D loss: 0.999997] [G loss: 1.000017]\n",
      "epoch:26 step:125890[D loss: 1.000006] [G loss: 0.999984]\n",
      "epoch:26 step:125895[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:26 step:125900[D loss: 0.999965] [G loss: 1.000110]\n",
      "epoch:26 step:125905[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:26 step:125910[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:26 step:125915[D loss: 0.999968] [G loss: 1.000059]\n",
      "epoch:26 step:125920[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:26 step:125925[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:26 step:125930[D loss: 0.999933] [G loss: 1.000083]\n",
      "epoch:26 step:125935[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:26 step:125940[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:26 step:125945[D loss: 0.999959] [G loss: 1.000080]\n",
      "epoch:26 step:125950[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:26 step:125955[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:26 step:125960[D loss: 0.999985] [G loss: 1.000146]\n",
      "epoch:26 step:125965[D loss: 0.999887] [G loss: 1.000202]\n",
      "epoch:26 step:125970[D loss: 1.000016] [G loss: 1.000126]\n",
      "epoch:26 step:125975[D loss: 0.999996] [G loss: 1.000092]\n",
      "epoch:26 step:125980[D loss: 0.999953] [G loss: 1.000244]\n",
      "epoch:26 step:125985[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:26 step:125990[D loss: 0.999991] [G loss: 1.000003]\n",
      "epoch:26 step:125995[D loss: 1.000012] [G loss: 0.999978]\n",
      "epoch:26 step:126000[D loss: 1.000039] [G loss: 0.999938]\n",
      "epoch:26 step:126005[D loss: 0.999940] [G loss: 1.000098]\n",
      "epoch:26 step:126010[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:26 step:126015[D loss: 0.999938] [G loss: 1.000176]\n",
      "epoch:26 step:126020[D loss: 1.000018] [G loss: 0.999964]\n",
      "epoch:26 step:126025[D loss: 0.999985] [G loss: 1.000087]\n",
      "epoch:26 step:126030[D loss: 0.999924] [G loss: 1.000221]\n",
      "epoch:26 step:126035[D loss: 0.999878] [G loss: 1.000195]\n",
      "epoch:26 step:126040[D loss: 0.999938] [G loss: 1.000126]\n",
      "epoch:26 step:126045[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:26 step:126050[D loss: 0.999999] [G loss: 1.000061]\n",
      "epoch:26 step:126055[D loss: 1.000009] [G loss: 1.000104]\n",
      "epoch:26 step:126060[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:26 step:126065[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:26 step:126070[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:26 step:126075[D loss: 1.000038] [G loss: 1.000002]\n",
      "epoch:26 step:126080[D loss: 0.999966] [G loss: 0.999982]\n",
      "epoch:26 step:126085[D loss: 0.999918] [G loss: 1.000097]\n",
      "epoch:26 step:126090[D loss: 1.000087] [G loss: 1.000010]\n",
      "epoch:26 step:126095[D loss: 0.999934] [G loss: 1.000091]\n",
      "epoch:26 step:126100[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:26 step:126105[D loss: 0.999991] [G loss: 1.000121]\n",
      "epoch:26 step:126110[D loss: 0.999990] [G loss: 0.999991]\n",
      "epoch:26 step:126115[D loss: 0.999935] [G loss: 1.000065]\n",
      "epoch:26 step:126120[D loss: 0.999996] [G loss: 1.000002]\n",
      "epoch:26 step:126125[D loss: 0.999994] [G loss: 0.999988]\n",
      "epoch:26 step:126130[D loss: 1.000071] [G loss: 0.999966]\n",
      "epoch:26 step:126135[D loss: 0.999911] [G loss: 1.000123]\n",
      "epoch:26 step:126140[D loss: 0.999810] [G loss: 1.000242]\n",
      "epoch:26 step:126145[D loss: 1.000109] [G loss: 0.999971]\n",
      "epoch:26 step:126150[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:26 step:126155[D loss: 1.000036] [G loss: 1.000033]\n",
      "epoch:26 step:126160[D loss: 1.000152] [G loss: 0.999977]\n",
      "epoch:26 step:126165[D loss: 0.999907] [G loss: 1.000141]\n",
      "epoch:26 step:126170[D loss: 1.000020] [G loss: 0.999925]\n",
      "epoch:26 step:126175[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:26 step:126180[D loss: 0.999994] [G loss: 1.000022]\n",
      "epoch:26 step:126185[D loss: 1.000048] [G loss: 0.999942]\n",
      "epoch:26 step:126190[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:26 step:126195[D loss: 0.999992] [G loss: 0.999968]\n",
      "epoch:26 step:126200[D loss: 1.000001] [G loss: 1.000037]\n",
      "epoch:26 step:126205[D loss: 1.000000] [G loss: 0.999942]\n",
      "epoch:26 step:126210[D loss: 1.000045] [G loss: 1.000003]\n",
      "epoch:26 step:126215[D loss: 0.999918] [G loss: 1.000094]\n",
      "epoch:26 step:126220[D loss: 1.000002] [G loss: 0.999988]\n",
      "epoch:26 step:126225[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:26 step:126230[D loss: 0.999995] [G loss: 1.000026]\n",
      "epoch:26 step:126235[D loss: 1.000078] [G loss: 0.999998]\n",
      "epoch:26 step:126240[D loss: 0.999904] [G loss: 1.000214]\n",
      "epoch:26 step:126245[D loss: 0.999868] [G loss: 1.000170]\n",
      "epoch:26 step:126250[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:26 step:126255[D loss: 1.000005] [G loss: 1.000096]\n",
      "epoch:26 step:126260[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:26 step:126265[D loss: 0.999972] [G loss: 0.999991]\n",
      "epoch:26 step:126270[D loss: 0.999934] [G loss: 1.000087]\n",
      "epoch:26 step:126275[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:26 step:126280[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:26 step:126285[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:26 step:126290[D loss: 1.000072] [G loss: 0.999981]\n",
      "epoch:26 step:126295[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:26 step:126300[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:26 step:126305[D loss: 0.999978] [G loss: 1.000064]\n",
      "epoch:26 step:126310[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:26 step:126315[D loss: 0.999983] [G loss: 1.000160]\n",
      "epoch:26 step:126320[D loss: 0.999944] [G loss: 1.000073]\n",
      "epoch:26 step:126325[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:26 step:126330[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:26 step:126335[D loss: 0.999912] [G loss: 1.000172]\n",
      "epoch:26 step:126340[D loss: 0.999951] [G loss: 1.000166]\n",
      "epoch:26 step:126345[D loss: 0.999967] [G loss: 1.000002]\n",
      "epoch:26 step:126350[D loss: 1.000035] [G loss: 0.999963]\n",
      "epoch:26 step:126355[D loss: 0.999878] [G loss: 1.000136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:126360[D loss: 0.999964] [G loss: 1.000045]\n",
      "epoch:26 step:126365[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:26 step:126370[D loss: 0.999953] [G loss: 1.000064]\n",
      "epoch:26 step:126375[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:26 step:126380[D loss: 0.999997] [G loss: 1.000054]\n",
      "epoch:26 step:126385[D loss: 1.000020] [G loss: 0.999997]\n",
      "epoch:26 step:126390[D loss: 0.999997] [G loss: 0.999977]\n",
      "epoch:26 step:126395[D loss: 1.000079] [G loss: 0.999958]\n",
      "epoch:26 step:126400[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:26 step:126405[D loss: 1.000039] [G loss: 0.999985]\n",
      "epoch:26 step:126410[D loss: 1.000015] [G loss: 0.999953]\n",
      "epoch:26 step:126415[D loss: 0.999913] [G loss: 1.000148]\n",
      "epoch:26 step:126420[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:26 step:126425[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:26 step:126430[D loss: 0.999954] [G loss: 1.000064]\n",
      "epoch:26 step:126435[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:26 step:126440[D loss: 1.000009] [G loss: 0.999982]\n",
      "epoch:26 step:126445[D loss: 0.999947] [G loss: 1.000085]\n",
      "epoch:26 step:126450[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:26 step:126455[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:26 step:126460[D loss: 0.999983] [G loss: 1.000024]\n",
      "epoch:26 step:126465[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:26 step:126470[D loss: 0.999933] [G loss: 1.000094]\n",
      "epoch:26 step:126475[D loss: 0.999973] [G loss: 1.000059]\n",
      "epoch:26 step:126480[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:26 step:126485[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:26 step:126490[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:26 step:126495[D loss: 1.000013] [G loss: 1.000000]\n",
      "epoch:27 step:126500[D loss: 0.999989] [G loss: 1.000127]\n",
      "epoch:27 step:126505[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:27 step:126510[D loss: 0.999961] [G loss: 1.000026]\n",
      "epoch:27 step:126515[D loss: 0.999939] [G loss: 1.000185]\n",
      "epoch:27 step:126520[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:27 step:126525[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:27 step:126530[D loss: 1.000007] [G loss: 1.000023]\n",
      "epoch:27 step:126535[D loss: 0.999940] [G loss: 1.000062]\n",
      "epoch:27 step:126540[D loss: 1.000030] [G loss: 0.999986]\n",
      "epoch:27 step:126545[D loss: 1.000043] [G loss: 1.000082]\n",
      "epoch:27 step:126550[D loss: 0.999950] [G loss: 1.000144]\n",
      "epoch:27 step:126555[D loss: 0.999913] [G loss: 1.000103]\n",
      "epoch:27 step:126560[D loss: 0.999940] [G loss: 1.000100]\n",
      "epoch:27 step:126565[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:27 step:126570[D loss: 0.999962] [G loss: 1.000082]\n",
      "epoch:27 step:126575[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:27 step:126580[D loss: 0.999966] [G loss: 1.000047]\n",
      "epoch:27 step:126585[D loss: 1.000006] [G loss: 1.000000]\n",
      "epoch:27 step:126590[D loss: 0.999998] [G loss: 0.999989]\n",
      "epoch:27 step:126595[D loss: 0.999954] [G loss: 1.000064]\n",
      "epoch:27 step:126600[D loss: 1.000002] [G loss: 1.000068]\n",
      "epoch:27 step:126605[D loss: 1.000030] [G loss: 1.000047]\n",
      "epoch:27 step:126610[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:27 step:126615[D loss: 1.000002] [G loss: 1.000101]\n",
      "epoch:27 step:126620[D loss: 0.999928] [G loss: 1.000133]\n",
      "epoch:27 step:126625[D loss: 0.999963] [G loss: 1.000129]\n",
      "epoch:27 step:126630[D loss: 0.999983] [G loss: 1.000160]\n",
      "epoch:27 step:126635[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:27 step:126640[D loss: 1.000020] [G loss: 1.000006]\n",
      "epoch:27 step:126645[D loss: 1.000015] [G loss: 0.999962]\n",
      "epoch:27 step:126650[D loss: 0.999913] [G loss: 1.000081]\n",
      "epoch:27 step:126655[D loss: 0.999963] [G loss: 1.000057]\n",
      "epoch:27 step:126660[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:27 step:126665[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:27 step:126670[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:27 step:126675[D loss: 1.000011] [G loss: 1.000051]\n",
      "epoch:27 step:126680[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:27 step:126685[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:27 step:126690[D loss: 0.999973] [G loss: 1.000040]\n",
      "epoch:27 step:126695[D loss: 1.000101] [G loss: 0.999976]\n",
      "epoch:27 step:126700[D loss: 1.000087] [G loss: 0.999876]\n",
      "epoch:27 step:126705[D loss: 0.999892] [G loss: 1.000136]\n",
      "epoch:27 step:126710[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:27 step:126715[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:27 step:126720[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:27 step:126725[D loss: 0.999992] [G loss: 1.000007]\n",
      "epoch:27 step:126730[D loss: 0.999922] [G loss: 1.000142]\n",
      "epoch:27 step:126735[D loss: 0.999979] [G loss: 1.000110]\n",
      "epoch:27 step:126740[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:27 step:126745[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:27 step:126750[D loss: 1.000035] [G loss: 0.999991]\n",
      "epoch:27 step:126755[D loss: 1.000037] [G loss: 0.999883]\n",
      "epoch:27 step:126760[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:27 step:126765[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:27 step:126770[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:27 step:126775[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:27 step:126780[D loss: 0.999972] [G loss: 1.000119]\n",
      "epoch:27 step:126785[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:27 step:126790[D loss: 0.999955] [G loss: 1.000086]\n",
      "epoch:27 step:126795[D loss: 0.999967] [G loss: 1.000106]\n",
      "epoch:27 step:126800[D loss: 0.999943] [G loss: 1.000104]\n",
      "epoch:27 step:126805[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:27 step:126810[D loss: 1.000020] [G loss: 1.000033]\n",
      "epoch:27 step:126815[D loss: 1.000025] [G loss: 1.000044]\n",
      "epoch:27 step:126820[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:27 step:126825[D loss: 1.000027] [G loss: 0.999944]\n",
      "epoch:27 step:126830[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:27 step:126835[D loss: 1.000041] [G loss: 0.999964]\n",
      "epoch:27 step:126840[D loss: 1.000070] [G loss: 1.000006]\n",
      "epoch:27 step:126845[D loss: 0.999916] [G loss: 1.000191]\n",
      "epoch:27 step:126850[D loss: 1.000027] [G loss: 1.000007]\n",
      "epoch:27 step:126855[D loss: 0.999999] [G loss: 1.000113]\n",
      "epoch:27 step:126860[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:27 step:126865[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:27 step:126870[D loss: 1.000134] [G loss: 0.999804]\n",
      "epoch:27 step:126875[D loss: 1.000032] [G loss: 0.999893]\n",
      "epoch:27 step:126880[D loss: 0.999985] [G loss: 1.000105]\n",
      "epoch:27 step:126885[D loss: 0.999969] [G loss: 1.000127]\n",
      "epoch:27 step:126890[D loss: 0.999945] [G loss: 1.000071]\n",
      "epoch:27 step:126895[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:27 step:126900[D loss: 0.999988] [G loss: 1.000116]\n",
      "epoch:27 step:126905[D loss: 0.999913] [G loss: 1.000093]\n",
      "epoch:27 step:126910[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:27 step:126915[D loss: 1.000023] [G loss: 1.000008]\n",
      "epoch:27 step:126920[D loss: 1.000026] [G loss: 0.999928]\n",
      "epoch:27 step:126925[D loss: 0.999931] [G loss: 1.000135]\n",
      "epoch:27 step:126930[D loss: 0.999940] [G loss: 1.000095]\n",
      "epoch:27 step:126935[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:27 step:126940[D loss: 1.000098] [G loss: 1.000026]\n",
      "epoch:27 step:126945[D loss: 0.999917] [G loss: 1.000178]\n",
      "epoch:27 step:126950[D loss: 0.999947] [G loss: 1.000092]\n",
      "epoch:27 step:126955[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:27 step:126960[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:27 step:126965[D loss: 1.000020] [G loss: 0.999935]\n",
      "epoch:27 step:126970[D loss: 1.000044] [G loss: 1.000016]\n",
      "epoch:27 step:126975[D loss: 1.000019] [G loss: 0.999985]\n",
      "epoch:27 step:126980[D loss: 1.000093] [G loss: 1.000018]\n",
      "epoch:27 step:126985[D loss: 0.999957] [G loss: 1.000160]\n",
      "epoch:27 step:126990[D loss: 0.999880] [G loss: 1.000201]\n",
      "epoch:27 step:126995[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:27 step:127000[D loss: 1.000014] [G loss: 1.000000]\n",
      "epoch:27 step:127005[D loss: 0.999952] [G loss: 1.000053]\n",
      "epoch:27 step:127010[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:27 step:127015[D loss: 0.999941] [G loss: 1.000090]\n",
      "epoch:27 step:127020[D loss: 1.000022] [G loss: 0.999960]\n",
      "epoch:27 step:127025[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:27 step:127030[D loss: 1.000038] [G loss: 1.000020]\n",
      "epoch:27 step:127035[D loss: 1.000067] [G loss: 0.999938]\n",
      "epoch:27 step:127040[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:27 step:127045[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:27 step:127050[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:27 step:127055[D loss: 0.999966] [G loss: 1.000070]\n",
      "epoch:27 step:127060[D loss: 0.999983] [G loss: 1.000065]\n",
      "epoch:27 step:127065[D loss: 0.999993] [G loss: 1.000054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:127070[D loss: 0.999989] [G loss: 1.000024]\n",
      "epoch:27 step:127075[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:27 step:127080[D loss: 1.000052] [G loss: 0.999975]\n",
      "epoch:27 step:127085[D loss: 1.000037] [G loss: 1.000089]\n",
      "epoch:27 step:127090[D loss: 1.000001] [G loss: 1.000100]\n",
      "epoch:27 step:127095[D loss: 0.999905] [G loss: 1.000153]\n",
      "epoch:27 step:127100[D loss: 0.999894] [G loss: 1.000169]\n",
      "epoch:27 step:127105[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:27 step:127110[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:27 step:127115[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:27 step:127120[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:27 step:127125[D loss: 0.999956] [G loss: 0.999974]\n",
      "epoch:27 step:127130[D loss: 1.000059] [G loss: 0.999893]\n",
      "epoch:27 step:127135[D loss: 1.000017] [G loss: 0.999989]\n",
      "epoch:27 step:127140[D loss: 1.000108] [G loss: 0.999946]\n",
      "epoch:27 step:127145[D loss: 0.999883] [G loss: 1.000043]\n",
      "epoch:27 step:127150[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:27 step:127155[D loss: 1.000004] [G loss: 1.000045]\n",
      "epoch:27 step:127160[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:27 step:127165[D loss: 0.999979] [G loss: 1.000077]\n",
      "epoch:27 step:127170[D loss: 0.999965] [G loss: 1.000008]\n",
      "epoch:27 step:127175[D loss: 1.000038] [G loss: 1.000009]\n",
      "epoch:27 step:127180[D loss: 0.999978] [G loss: 1.000075]\n",
      "epoch:27 step:127185[D loss: 0.999975] [G loss: 1.000044]\n",
      "epoch:27 step:127190[D loss: 0.999949] [G loss: 1.000087]\n",
      "epoch:27 step:127195[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:27 step:127200[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:27 step:127205[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:27 step:127210[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:27 step:127215[D loss: 0.999982] [G loss: 1.000080]\n",
      "epoch:27 step:127220[D loss: 1.000008] [G loss: 1.000031]\n",
      "epoch:27 step:127225[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:27 step:127230[D loss: 0.999918] [G loss: 1.000221]\n",
      "epoch:27 step:127235[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:27 step:127240[D loss: 0.999992] [G loss: 1.000042]\n",
      "epoch:27 step:127245[D loss: 0.999988] [G loss: 0.999988]\n",
      "epoch:27 step:127250[D loss: 0.999967] [G loss: 1.000061]\n",
      "epoch:27 step:127255[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:27 step:127260[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:27 step:127265[D loss: 0.999950] [G loss: 1.000148]\n",
      "epoch:27 step:127270[D loss: 1.000040] [G loss: 0.999984]\n",
      "epoch:27 step:127275[D loss: 1.000032] [G loss: 1.000066]\n",
      "epoch:27 step:127280[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:27 step:127285[D loss: 1.000022] [G loss: 0.999968]\n",
      "epoch:27 step:127290[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:27 step:127295[D loss: 0.999930] [G loss: 1.000147]\n",
      "epoch:27 step:127300[D loss: 0.999951] [G loss: 1.000213]\n",
      "epoch:27 step:127305[D loss: 0.999990] [G loss: 1.000098]\n",
      "epoch:27 step:127310[D loss: 0.999876] [G loss: 1.000182]\n",
      "epoch:27 step:127315[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:27 step:127320[D loss: 0.999982] [G loss: 1.000016]\n",
      "epoch:27 step:127325[D loss: 1.000020] [G loss: 0.999960]\n",
      "epoch:27 step:127330[D loss: 0.999901] [G loss: 1.000133]\n",
      "epoch:27 step:127335[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:27 step:127340[D loss: 1.000011] [G loss: 1.000033]\n",
      "epoch:27 step:127345[D loss: 1.000005] [G loss: 1.000045]\n",
      "epoch:27 step:127350[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:27 step:127355[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:27 step:127360[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:27 step:127365[D loss: 0.999982] [G loss: 1.000040]\n",
      "epoch:27 step:127370[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:27 step:127375[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:27 step:127380[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:27 step:127385[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:27 step:127390[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:27 step:127395[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:27 step:127400[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:27 step:127405[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:27 step:127410[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:27 step:127415[D loss: 0.999945] [G loss: 1.000086]\n",
      "epoch:27 step:127420[D loss: 1.000026] [G loss: 0.999980]\n",
      "epoch:27 step:127425[D loss: 0.999988] [G loss: 1.000071]\n",
      "epoch:27 step:127430[D loss: 0.999952] [G loss: 1.000104]\n",
      "epoch:27 step:127435[D loss: 0.999979] [G loss: 1.000060]\n",
      "epoch:27 step:127440[D loss: 0.999985] [G loss: 1.000070]\n",
      "epoch:27 step:127445[D loss: 0.999978] [G loss: 1.000062]\n",
      "epoch:27 step:127450[D loss: 0.999982] [G loss: 1.000041]\n",
      "epoch:27 step:127455[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:27 step:127460[D loss: 1.000029] [G loss: 1.000022]\n",
      "epoch:27 step:127465[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:27 step:127470[D loss: 0.999971] [G loss: 1.000089]\n",
      "epoch:27 step:127475[D loss: 0.999978] [G loss: 1.000129]\n",
      "epoch:27 step:127480[D loss: 0.999902] [G loss: 1.000195]\n",
      "epoch:27 step:127485[D loss: 1.000109] [G loss: 0.999921]\n",
      "epoch:27 step:127490[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:27 step:127495[D loss: 0.999980] [G loss: 1.000205]\n",
      "epoch:27 step:127500[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:27 step:127505[D loss: 1.000004] [G loss: 1.000083]\n",
      "epoch:27 step:127510[D loss: 0.999949] [G loss: 1.000077]\n",
      "epoch:27 step:127515[D loss: 0.999993] [G loss: 1.000000]\n",
      "epoch:27 step:127520[D loss: 0.999980] [G loss: 1.000037]\n",
      "epoch:27 step:127525[D loss: 1.000074] [G loss: 0.999895]\n",
      "epoch:27 step:127530[D loss: 1.000221] [G loss: 0.999719]\n",
      "epoch:27 step:127535[D loss: 0.999870] [G loss: 1.000029]\n",
      "epoch:27 step:127540[D loss: 0.999926] [G loss: 1.000199]\n",
      "epoch:27 step:127545[D loss: 0.999916] [G loss: 1.000164]\n",
      "epoch:27 step:127550[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:27 step:127555[D loss: 0.999949] [G loss: 1.000107]\n",
      "epoch:27 step:127560[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:27 step:127565[D loss: 1.000025] [G loss: 1.000019]\n",
      "epoch:27 step:127570[D loss: 1.000007] [G loss: 1.000062]\n",
      "epoch:27 step:127575[D loss: 0.999925] [G loss: 1.000148]\n",
      "epoch:27 step:127580[D loss: 1.000022] [G loss: 1.000184]\n",
      "epoch:27 step:127585[D loss: 0.999897] [G loss: 1.000160]\n",
      "epoch:27 step:127590[D loss: 0.999924] [G loss: 1.000118]\n",
      "epoch:27 step:127595[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:27 step:127600[D loss: 0.999961] [G loss: 1.000083]\n",
      "epoch:27 step:127605[D loss: 0.999975] [G loss: 1.000154]\n",
      "epoch:27 step:127610[D loss: 1.000043] [G loss: 1.000021]\n",
      "epoch:27 step:127615[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:27 step:127620[D loss: 1.000023] [G loss: 1.000038]\n",
      "epoch:27 step:127625[D loss: 0.999961] [G loss: 1.000227]\n",
      "epoch:27 step:127630[D loss: 1.000038] [G loss: 1.000071]\n",
      "epoch:27 step:127635[D loss: 0.999953] [G loss: 1.000062]\n",
      "epoch:27 step:127640[D loss: 0.999992] [G loss: 1.000026]\n",
      "epoch:27 step:127645[D loss: 1.000004] [G loss: 1.000081]\n",
      "epoch:27 step:127650[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:27 step:127655[D loss: 0.999931] [G loss: 1.000094]\n",
      "epoch:27 step:127660[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:27 step:127665[D loss: 1.000025] [G loss: 1.000023]\n",
      "epoch:27 step:127670[D loss: 1.000031] [G loss: 0.999999]\n",
      "epoch:27 step:127675[D loss: 0.999905] [G loss: 1.000136]\n",
      "epoch:27 step:127680[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:27 step:127685[D loss: 1.000035] [G loss: 0.999920]\n",
      "epoch:27 step:127690[D loss: 0.999977] [G loss: 1.000025]\n",
      "epoch:27 step:127695[D loss: 1.000072] [G loss: 0.999849]\n",
      "epoch:27 step:127700[D loss: 1.000019] [G loss: 1.000011]\n",
      "epoch:27 step:127705[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:27 step:127710[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:27 step:127715[D loss: 0.999982] [G loss: 1.000199]\n",
      "epoch:27 step:127720[D loss: 0.999928] [G loss: 1.000163]\n",
      "epoch:27 step:127725[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:27 step:127730[D loss: 0.999974] [G loss: 1.000056]\n",
      "epoch:27 step:127735[D loss: 1.000006] [G loss: 1.000027]\n",
      "epoch:27 step:127740[D loss: 0.999929] [G loss: 1.000068]\n",
      "epoch:27 step:127745[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:27 step:127750[D loss: 1.000076] [G loss: 1.000003]\n",
      "epoch:27 step:127755[D loss: 0.999898] [G loss: 1.000154]\n",
      "epoch:27 step:127760[D loss: 0.999988] [G loss: 1.000136]\n",
      "epoch:27 step:127765[D loss: 0.999925] [G loss: 1.000213]\n",
      "epoch:27 step:127770[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:27 step:127775[D loss: 0.999995] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:127780[D loss: 0.999978] [G loss: 1.000028]\n",
      "epoch:27 step:127785[D loss: 1.000017] [G loss: 1.000026]\n",
      "epoch:27 step:127790[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:27 step:127795[D loss: 0.999948] [G loss: 1.000131]\n",
      "epoch:27 step:127800[D loss: 1.000048] [G loss: 0.999897]\n",
      "epoch:27 step:127805[D loss: 1.000027] [G loss: 0.999997]\n",
      "epoch:27 step:127810[D loss: 1.000129] [G loss: 0.999935]\n",
      "epoch:27 step:127815[D loss: 0.999942] [G loss: 1.000031]\n",
      "epoch:27 step:127820[D loss: 0.999980] [G loss: 1.000091]\n",
      "epoch:27 step:127825[D loss: 1.000069] [G loss: 0.999989]\n",
      "epoch:27 step:127830[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:27 step:127835[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:27 step:127840[D loss: 0.999908] [G loss: 1.000136]\n",
      "epoch:27 step:127845[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:27 step:127850[D loss: 1.000050] [G loss: 0.999901]\n",
      "epoch:27 step:127855[D loss: 0.999987] [G loss: 0.999952]\n",
      "epoch:27 step:127860[D loss: 0.999949] [G loss: 1.000070]\n",
      "epoch:27 step:127865[D loss: 0.999958] [G loss: 1.000051]\n",
      "epoch:27 step:127870[D loss: 0.999997] [G loss: 1.000089]\n",
      "epoch:27 step:127875[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:27 step:127880[D loss: 0.999966] [G loss: 1.000072]\n",
      "epoch:27 step:127885[D loss: 0.999980] [G loss: 1.000080]\n",
      "epoch:27 step:127890[D loss: 0.999921] [G loss: 1.000131]\n",
      "epoch:27 step:127895[D loss: 0.999963] [G loss: 1.000094]\n",
      "epoch:27 step:127900[D loss: 0.999969] [G loss: 1.000065]\n",
      "epoch:27 step:127905[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:27 step:127910[D loss: 0.999963] [G loss: 1.000078]\n",
      "epoch:27 step:127915[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:27 step:127920[D loss: 0.999982] [G loss: 1.000110]\n",
      "epoch:27 step:127925[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:27 step:127930[D loss: 0.999984] [G loss: 1.000059]\n",
      "epoch:27 step:127935[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:27 step:127940[D loss: 0.999966] [G loss: 1.000085]\n",
      "epoch:27 step:127945[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:27 step:127950[D loss: 0.999982] [G loss: 1.000035]\n",
      "epoch:27 step:127955[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:27 step:127960[D loss: 0.999977] [G loss: 1.000094]\n",
      "epoch:27 step:127965[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:27 step:127970[D loss: 1.000026] [G loss: 0.999983]\n",
      "epoch:27 step:127975[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:27 step:127980[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:27 step:127985[D loss: 0.999993] [G loss: 1.000059]\n",
      "epoch:27 step:127990[D loss: 0.999937] [G loss: 1.000082]\n",
      "epoch:27 step:127995[D loss: 1.000020] [G loss: 0.999986]\n",
      "epoch:27 step:128000[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:27 step:128005[D loss: 0.999987] [G loss: 1.000055]\n",
      "epoch:27 step:128010[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:27 step:128015[D loss: 1.000017] [G loss: 1.000006]\n",
      "epoch:27 step:128020[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:27 step:128025[D loss: 1.000008] [G loss: 1.000078]\n",
      "epoch:27 step:128030[D loss: 0.999947] [G loss: 1.000077]\n",
      "epoch:27 step:128035[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:27 step:128040[D loss: 1.000003] [G loss: 1.000043]\n",
      "epoch:27 step:128045[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:27 step:128050[D loss: 1.000069] [G loss: 0.999922]\n",
      "epoch:27 step:128055[D loss: 0.999963] [G loss: 1.000036]\n",
      "epoch:27 step:128060[D loss: 0.999967] [G loss: 1.000080]\n",
      "epoch:27 step:128065[D loss: 0.999998] [G loss: 1.000031]\n",
      "epoch:27 step:128070[D loss: 0.999967] [G loss: 1.000141]\n",
      "epoch:27 step:128075[D loss: 1.000061] [G loss: 1.000001]\n",
      "epoch:27 step:128080[D loss: 0.999936] [G loss: 1.000051]\n",
      "epoch:27 step:128085[D loss: 1.000004] [G loss: 0.999969]\n",
      "epoch:27 step:128090[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:27 step:128095[D loss: 1.000042] [G loss: 0.999984]\n",
      "epoch:27 step:128100[D loss: 1.000179] [G loss: 0.999826]\n",
      "epoch:27 step:128105[D loss: 1.000140] [G loss: 0.999828]\n",
      "epoch:27 step:128110[D loss: 1.000037] [G loss: 1.000070]\n",
      "epoch:27 step:128115[D loss: 0.999998] [G loss: 0.999986]\n",
      "epoch:27 step:128120[D loss: 0.999927] [G loss: 1.000067]\n",
      "epoch:27 step:128125[D loss: 0.999972] [G loss: 1.000011]\n",
      "epoch:27 step:128130[D loss: 1.000097] [G loss: 0.999848]\n",
      "epoch:27 step:128135[D loss: 0.999911] [G loss: 1.000027]\n",
      "epoch:27 step:128140[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:27 step:128145[D loss: 0.999979] [G loss: 1.000018]\n",
      "epoch:27 step:128150[D loss: 0.999950] [G loss: 1.000120]\n",
      "epoch:27 step:128155[D loss: 0.999916] [G loss: 1.000130]\n",
      "epoch:27 step:128160[D loss: 0.999954] [G loss: 1.000056]\n",
      "epoch:27 step:128165[D loss: 0.999972] [G loss: 1.000077]\n",
      "epoch:27 step:128170[D loss: 0.999944] [G loss: 1.000068]\n",
      "epoch:27 step:128175[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:27 step:128180[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:27 step:128185[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:27 step:128190[D loss: 0.999995] [G loss: 1.000083]\n",
      "epoch:27 step:128195[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:27 step:128200[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:27 step:128205[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:27 step:128210[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:27 step:128215[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:27 step:128220[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:27 step:128225[D loss: 0.999975] [G loss: 1.000093]\n",
      "epoch:27 step:128230[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:27 step:128235[D loss: 0.999953] [G loss: 1.000119]\n",
      "epoch:27 step:128240[D loss: 1.000003] [G loss: 1.000024]\n",
      "epoch:27 step:128245[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:27 step:128250[D loss: 0.999963] [G loss: 1.000066]\n",
      "epoch:27 step:128255[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:27 step:128260[D loss: 0.999980] [G loss: 1.000004]\n",
      "epoch:27 step:128265[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:27 step:128270[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:27 step:128275[D loss: 0.999992] [G loss: 1.000003]\n",
      "epoch:27 step:128280[D loss: 0.999985] [G loss: 0.999993]\n",
      "epoch:27 step:128285[D loss: 1.000210] [G loss: 0.999812]\n",
      "epoch:27 step:128290[D loss: 0.999955] [G loss: 1.000074]\n",
      "epoch:27 step:128295[D loss: 1.000031] [G loss: 1.000111]\n",
      "epoch:27 step:128300[D loss: 0.999902] [G loss: 1.000158]\n",
      "epoch:27 step:128305[D loss: 0.999951] [G loss: 1.000075]\n",
      "epoch:27 step:128310[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:27 step:128315[D loss: 1.000043] [G loss: 1.000038]\n",
      "epoch:27 step:128320[D loss: 1.000042] [G loss: 0.999884]\n",
      "epoch:27 step:128325[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:27 step:128330[D loss: 1.000089] [G loss: 0.999998]\n",
      "epoch:27 step:128335[D loss: 0.999963] [G loss: 1.000235]\n",
      "epoch:27 step:128340[D loss: 0.999980] [G loss: 1.000107]\n",
      "epoch:27 step:128345[D loss: 0.999894] [G loss: 1.000210]\n",
      "epoch:27 step:128350[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:27 step:128355[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:27 step:128360[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:27 step:128365[D loss: 1.000027] [G loss: 1.000057]\n",
      "epoch:27 step:128370[D loss: 0.999936] [G loss: 1.000058]\n",
      "epoch:27 step:128375[D loss: 1.000002] [G loss: 1.000027]\n",
      "epoch:27 step:128380[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:27 step:128385[D loss: 1.000131] [G loss: 1.000003]\n",
      "epoch:27 step:128390[D loss: 0.999926] [G loss: 1.000065]\n",
      "epoch:27 step:128395[D loss: 0.999978] [G loss: 0.999957]\n",
      "epoch:27 step:128400[D loss: 0.999947] [G loss: 1.000089]\n",
      "epoch:27 step:128405[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:27 step:128410[D loss: 1.000028] [G loss: 0.999986]\n",
      "epoch:27 step:128415[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:27 step:128420[D loss: 1.000039] [G loss: 1.000080]\n",
      "epoch:27 step:128425[D loss: 0.999952] [G loss: 1.000060]\n",
      "epoch:27 step:128430[D loss: 0.999950] [G loss: 1.000177]\n",
      "epoch:27 step:128435[D loss: 0.999987] [G loss: 1.000004]\n",
      "epoch:27 step:128440[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:27 step:128445[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:27 step:128450[D loss: 1.000030] [G loss: 1.000031]\n",
      "epoch:27 step:128455[D loss: 0.999959] [G loss: 1.000004]\n",
      "epoch:27 step:128460[D loss: 0.999972] [G loss: 1.000035]\n",
      "epoch:27 step:128465[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:27 step:128470[D loss: 0.999965] [G loss: 1.000017]\n",
      "epoch:27 step:128475[D loss: 0.999943] [G loss: 1.000104]\n",
      "epoch:27 step:128480[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:27 step:128485[D loss: 1.000012] [G loss: 0.999963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:128490[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:27 step:128495[D loss: 0.999959] [G loss: 1.000070]\n",
      "epoch:27 step:128500[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:27 step:128505[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:27 step:128510[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:27 step:128515[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:27 step:128520[D loss: 1.000088] [G loss: 0.999914]\n",
      "epoch:27 step:128525[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:27 step:128530[D loss: 0.999998] [G loss: 1.000118]\n",
      "epoch:27 step:128535[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:27 step:128540[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:27 step:128545[D loss: 1.000136] [G loss: 0.999893]\n",
      "epoch:27 step:128550[D loss: 0.999941] [G loss: 1.000081]\n",
      "epoch:27 step:128555[D loss: 1.000051] [G loss: 0.999977]\n",
      "epoch:27 step:128560[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:27 step:128565[D loss: 0.999925] [G loss: 1.000135]\n",
      "epoch:27 step:128570[D loss: 0.999948] [G loss: 1.000024]\n",
      "epoch:27 step:128575[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:27 step:128580[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:27 step:128585[D loss: 0.999922] [G loss: 1.000099]\n",
      "epoch:27 step:128590[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:27 step:128595[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:27 step:128600[D loss: 0.999996] [G loss: 1.000102]\n",
      "epoch:27 step:128605[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:27 step:128610[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:27 step:128615[D loss: 0.999976] [G loss: 1.000093]\n",
      "epoch:27 step:128620[D loss: 0.999906] [G loss: 1.000149]\n",
      "epoch:27 step:128625[D loss: 0.999995] [G loss: 1.000055]\n",
      "epoch:27 step:128630[D loss: 0.999949] [G loss: 1.000086]\n",
      "epoch:27 step:128635[D loss: 0.999984] [G loss: 1.000011]\n",
      "epoch:27 step:128640[D loss: 0.999984] [G loss: 1.000026]\n",
      "epoch:27 step:128645[D loss: 1.000007] [G loss: 0.999967]\n",
      "epoch:27 step:128650[D loss: 0.999921] [G loss: 1.000054]\n",
      "epoch:27 step:128655[D loss: 1.000033] [G loss: 1.000061]\n",
      "epoch:27 step:128660[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:27 step:128665[D loss: 0.999980] [G loss: 1.000119]\n",
      "epoch:27 step:128670[D loss: 1.000012] [G loss: 1.000043]\n",
      "epoch:27 step:128675[D loss: 1.000042] [G loss: 1.000000]\n",
      "epoch:27 step:128680[D loss: 0.999984] [G loss: 0.999997]\n",
      "epoch:27 step:128685[D loss: 0.999981] [G loss: 1.000039]\n",
      "epoch:27 step:128690[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:27 step:128695[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:27 step:128700[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:27 step:128705[D loss: 1.000033] [G loss: 0.999980]\n",
      "epoch:27 step:128710[D loss: 0.999971] [G loss: 1.000041]\n",
      "epoch:27 step:128715[D loss: 0.999994] [G loss: 1.000031]\n",
      "epoch:27 step:128720[D loss: 0.999901] [G loss: 1.000124]\n",
      "epoch:27 step:128725[D loss: 1.000027] [G loss: 1.000061]\n",
      "epoch:27 step:128730[D loss: 1.000052] [G loss: 1.000024]\n",
      "epoch:27 step:128735[D loss: 0.999899] [G loss: 1.000290]\n",
      "epoch:27 step:128740[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:27 step:128745[D loss: 0.999960] [G loss: 1.000111]\n",
      "epoch:27 step:128750[D loss: 1.000001] [G loss: 1.000040]\n",
      "epoch:27 step:128755[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:27 step:128760[D loss: 0.999981] [G loss: 1.000029]\n",
      "epoch:27 step:128765[D loss: 1.000046] [G loss: 0.999957]\n",
      "epoch:27 step:128770[D loss: 0.999991] [G loss: 0.999997]\n",
      "epoch:27 step:128775[D loss: 0.999972] [G loss: 1.000045]\n",
      "epoch:27 step:128780[D loss: 0.999970] [G loss: 1.000161]\n",
      "epoch:27 step:128785[D loss: 1.000017] [G loss: 1.000039]\n",
      "epoch:27 step:128790[D loss: 1.000233] [G loss: 0.999974]\n",
      "epoch:27 step:128795[D loss: 0.999915] [G loss: 1.000166]\n",
      "epoch:27 step:128800[D loss: 0.999932] [G loss: 1.000111]\n",
      "epoch:27 step:128805[D loss: 0.999966] [G loss: 1.000059]\n",
      "epoch:27 step:128810[D loss: 0.999963] [G loss: 1.000053]\n",
      "epoch:27 step:128815[D loss: 0.999928] [G loss: 1.000130]\n",
      "epoch:27 step:128820[D loss: 1.000066] [G loss: 0.999854]\n",
      "epoch:27 step:128825[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:27 step:128830[D loss: 0.999934] [G loss: 1.000071]\n",
      "epoch:27 step:128835[D loss: 1.000035] [G loss: 1.000127]\n",
      "epoch:27 step:128840[D loss: 0.999980] [G loss: 1.000229]\n",
      "epoch:27 step:128845[D loss: 0.999919] [G loss: 1.000155]\n",
      "epoch:27 step:128850[D loss: 1.000025] [G loss: 1.000146]\n",
      "epoch:27 step:128855[D loss: 0.999965] [G loss: 1.000108]\n",
      "epoch:27 step:128860[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:27 step:128865[D loss: 1.000017] [G loss: 0.999962]\n",
      "epoch:27 step:128870[D loss: 0.999984] [G loss: 0.999979]\n",
      "epoch:27 step:128875[D loss: 1.000000] [G loss: 0.999997]\n",
      "epoch:27 step:128880[D loss: 0.999992] [G loss: 0.999949]\n",
      "epoch:27 step:128885[D loss: 1.000071] [G loss: 0.999947]\n",
      "epoch:27 step:128890[D loss: 0.999917] [G loss: 0.999986]\n",
      "epoch:27 step:128895[D loss: 0.999953] [G loss: 1.000022]\n",
      "epoch:27 step:128900[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:27 step:128905[D loss: 0.999949] [G loss: 1.000057]\n",
      "epoch:27 step:128910[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:27 step:128915[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:27 step:128920[D loss: 1.000101] [G loss: 0.999954]\n",
      "epoch:27 step:128925[D loss: 0.999891] [G loss: 1.000145]\n",
      "epoch:27 step:128930[D loss: 1.000000] [G loss: 1.000053]\n",
      "epoch:27 step:128935[D loss: 0.999982] [G loss: 1.000117]\n",
      "epoch:27 step:128940[D loss: 0.999946] [G loss: 1.000117]\n",
      "epoch:27 step:128945[D loss: 0.999918] [G loss: 1.000196]\n",
      "epoch:27 step:128950[D loss: 0.999929] [G loss: 1.000054]\n",
      "epoch:27 step:128955[D loss: 0.999960] [G loss: 1.000113]\n",
      "epoch:27 step:128960[D loss: 1.000005] [G loss: 1.000114]\n",
      "epoch:27 step:128965[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:27 step:128970[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:27 step:128975[D loss: 1.000020] [G loss: 1.000134]\n",
      "epoch:27 step:128980[D loss: 0.999949] [G loss: 1.000113]\n",
      "epoch:27 step:128985[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:27 step:128990[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:27 step:128995[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:27 step:129000[D loss: 0.999943] [G loss: 1.000070]\n",
      "epoch:27 step:129005[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:27 step:129010[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:27 step:129015[D loss: 0.999987] [G loss: 1.000048]\n",
      "epoch:27 step:129020[D loss: 0.999951] [G loss: 1.000122]\n",
      "epoch:27 step:129025[D loss: 0.999947] [G loss: 1.000090]\n",
      "epoch:27 step:129030[D loss: 0.999968] [G loss: 1.000164]\n",
      "epoch:27 step:129035[D loss: 1.000083] [G loss: 0.999977]\n",
      "epoch:27 step:129040[D loss: 0.999994] [G loss: 1.000143]\n",
      "epoch:27 step:129045[D loss: 1.000112] [G loss: 1.000254]\n",
      "epoch:27 step:129050[D loss: 0.999936] [G loss: 1.000176]\n",
      "epoch:27 step:129055[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:27 step:129060[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:27 step:129065[D loss: 1.000034] [G loss: 0.999920]\n",
      "epoch:27 step:129070[D loss: 1.000026] [G loss: 0.999914]\n",
      "epoch:27 step:129075[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:27 step:129080[D loss: 1.000228] [G loss: 0.999796]\n",
      "epoch:27 step:129085[D loss: 0.999892] [G loss: 1.000098]\n",
      "epoch:27 step:129090[D loss: 1.000091] [G loss: 0.999816]\n",
      "epoch:27 step:129095[D loss: 0.999980] [G loss: 1.000029]\n",
      "epoch:27 step:129100[D loss: 0.999861] [G loss: 1.000304]\n",
      "epoch:27 step:129105[D loss: 0.999876] [G loss: 1.000129]\n",
      "epoch:27 step:129110[D loss: 0.999882] [G loss: 1.000158]\n",
      "epoch:27 step:129115[D loss: 1.000004] [G loss: 1.000075]\n",
      "epoch:27 step:129120[D loss: 0.999958] [G loss: 1.000112]\n",
      "epoch:27 step:129125[D loss: 0.999946] [G loss: 1.000104]\n",
      "epoch:27 step:129130[D loss: 1.000004] [G loss: 1.000001]\n",
      "epoch:27 step:129135[D loss: 0.999972] [G loss: 1.000029]\n",
      "epoch:27 step:129140[D loss: 1.000019] [G loss: 0.999957]\n",
      "epoch:27 step:129145[D loss: 0.999911] [G loss: 1.000044]\n",
      "epoch:27 step:129150[D loss: 1.000010] [G loss: 1.000030]\n",
      "epoch:27 step:129155[D loss: 0.999883] [G loss: 1.000164]\n",
      "epoch:27 step:129160[D loss: 0.999991] [G loss: 1.000056]\n",
      "epoch:27 step:129165[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:27 step:129170[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:27 step:129175[D loss: 1.000022] [G loss: 0.999983]\n",
      "epoch:27 step:129180[D loss: 1.000030] [G loss: 1.000030]\n",
      "epoch:27 step:129185[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:27 step:129190[D loss: 1.000005] [G loss: 1.000076]\n",
      "epoch:27 step:129195[D loss: 0.999958] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:129200[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:27 step:129205[D loss: 0.999968] [G loss: 1.000027]\n",
      "epoch:27 step:129210[D loss: 0.999982] [G loss: 1.000052]\n",
      "epoch:27 step:129215[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:27 step:129220[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:27 step:129225[D loss: 0.999987] [G loss: 1.000090]\n",
      "epoch:27 step:129230[D loss: 0.999946] [G loss: 1.000121]\n",
      "epoch:27 step:129235[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:27 step:129240[D loss: 1.000005] [G loss: 1.000019]\n",
      "epoch:27 step:129245[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:27 step:129250[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:27 step:129255[D loss: 1.000007] [G loss: 1.000022]\n",
      "epoch:27 step:129260[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:27 step:129265[D loss: 0.999976] [G loss: 1.000032]\n",
      "epoch:27 step:129270[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:27 step:129275[D loss: 0.999967] [G loss: 1.000040]\n",
      "epoch:27 step:129280[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:27 step:129285[D loss: 0.999937] [G loss: 1.000126]\n",
      "epoch:27 step:129290[D loss: 1.000003] [G loss: 1.000022]\n",
      "epoch:27 step:129295[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:27 step:129300[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:27 step:129305[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:27 step:129310[D loss: 1.000022] [G loss: 0.999972]\n",
      "epoch:27 step:129315[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:27 step:129320[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:27 step:129325[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:27 step:129330[D loss: 0.999959] [G loss: 1.000078]\n",
      "epoch:27 step:129335[D loss: 0.999958] [G loss: 1.000074]\n",
      "epoch:27 step:129340[D loss: 0.999985] [G loss: 1.000021]\n",
      "epoch:27 step:129345[D loss: 0.999963] [G loss: 1.000029]\n",
      "epoch:27 step:129350[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:27 step:129355[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:27 step:129360[D loss: 1.000026] [G loss: 0.999975]\n",
      "epoch:27 step:129365[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:27 step:129370[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:27 step:129375[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:27 step:129380[D loss: 0.999934] [G loss: 1.000118]\n",
      "epoch:27 step:129385[D loss: 0.999967] [G loss: 1.000086]\n",
      "epoch:27 step:129390[D loss: 1.000009] [G loss: 1.000025]\n",
      "epoch:27 step:129395[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:27 step:129400[D loss: 1.000003] [G loss: 1.000059]\n",
      "epoch:27 step:129405[D loss: 0.999995] [G loss: 1.000046]\n",
      "epoch:27 step:129410[D loss: 0.999999] [G loss: 1.000043]\n",
      "epoch:27 step:129415[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:27 step:129420[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:27 step:129425[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:27 step:129430[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:27 step:129435[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:27 step:129440[D loss: 1.000007] [G loss: 1.000108]\n",
      "epoch:27 step:129445[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:27 step:129450[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:27 step:129455[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:27 step:129460[D loss: 1.000084] [G loss: 1.000007]\n",
      "epoch:27 step:129465[D loss: 0.999959] [G loss: 1.000072]\n",
      "epoch:27 step:129470[D loss: 1.000156] [G loss: 1.000072]\n",
      "epoch:27 step:129475[D loss: 0.999900] [G loss: 1.000166]\n",
      "epoch:27 step:129480[D loss: 0.999903] [G loss: 1.000140]\n",
      "epoch:27 step:129485[D loss: 0.999948] [G loss: 1.000132]\n",
      "epoch:27 step:129490[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:27 step:129495[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:27 step:129500[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:27 step:129505[D loss: 1.000010] [G loss: 1.000049]\n",
      "epoch:27 step:129510[D loss: 0.999881] [G loss: 1.000120]\n",
      "epoch:27 step:129515[D loss: 0.999983] [G loss: 1.000037]\n",
      "epoch:27 step:129520[D loss: 0.999981] [G loss: 1.000023]\n",
      "epoch:27 step:129525[D loss: 0.999947] [G loss: 1.000075]\n",
      "epoch:27 step:129530[D loss: 1.000001] [G loss: 1.000044]\n",
      "epoch:27 step:129535[D loss: 0.999963] [G loss: 1.000030]\n",
      "epoch:27 step:129540[D loss: 1.000207] [G loss: 0.999830]\n",
      "epoch:27 step:129545[D loss: 0.999884] [G loss: 1.000055]\n",
      "epoch:27 step:129550[D loss: 0.999941] [G loss: 1.000128]\n",
      "epoch:27 step:129555[D loss: 1.000038] [G loss: 0.999945]\n",
      "epoch:27 step:129560[D loss: 0.999985] [G loss: 0.999970]\n",
      "epoch:27 step:129565[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:27 step:129570[D loss: 1.000041] [G loss: 1.000000]\n",
      "epoch:27 step:129575[D loss: 0.999897] [G loss: 1.000092]\n",
      "epoch:27 step:129580[D loss: 1.000029] [G loss: 1.000044]\n",
      "epoch:27 step:129585[D loss: 0.999939] [G loss: 1.000132]\n",
      "epoch:27 step:129590[D loss: 0.999949] [G loss: 1.000043]\n",
      "epoch:27 step:129595[D loss: 1.000008] [G loss: 1.000112]\n",
      "epoch:27 step:129600[D loss: 0.999934] [G loss: 1.000127]\n",
      "epoch:27 step:129605[D loss: 1.000059] [G loss: 0.999962]\n",
      "epoch:27 step:129610[D loss: 0.999915] [G loss: 1.000163]\n",
      "epoch:27 step:129615[D loss: 0.999980] [G loss: 1.000073]\n",
      "epoch:27 step:129620[D loss: 0.999989] [G loss: 1.000133]\n",
      "epoch:27 step:129625[D loss: 0.999962] [G loss: 1.000074]\n",
      "epoch:27 step:129630[D loss: 1.000038] [G loss: 0.999970]\n",
      "epoch:27 step:129635[D loss: 1.000009] [G loss: 1.000031]\n",
      "epoch:27 step:129640[D loss: 1.000075] [G loss: 0.999829]\n",
      "epoch:27 step:129645[D loss: 1.000047] [G loss: 0.999939]\n",
      "epoch:27 step:129650[D loss: 0.999881] [G loss: 1.000155]\n",
      "epoch:27 step:129655[D loss: 1.000047] [G loss: 1.000111]\n",
      "epoch:27 step:129660[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:27 step:129665[D loss: 1.000009] [G loss: 1.000004]\n",
      "epoch:27 step:129670[D loss: 1.000010] [G loss: 1.000034]\n",
      "epoch:27 step:129675[D loss: 1.000037] [G loss: 0.999967]\n",
      "epoch:27 step:129680[D loss: 1.000078] [G loss: 0.999974]\n",
      "epoch:27 step:129685[D loss: 0.999909] [G loss: 1.000091]\n",
      "epoch:27 step:129690[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:27 step:129695[D loss: 1.000014] [G loss: 1.000108]\n",
      "epoch:27 step:129700[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:27 step:129705[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:27 step:129710[D loss: 0.999983] [G loss: 1.000030]\n",
      "epoch:27 step:129715[D loss: 0.999997] [G loss: 1.000047]\n",
      "epoch:27 step:129720[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:27 step:129725[D loss: 0.999929] [G loss: 1.000143]\n",
      "epoch:27 step:129730[D loss: 0.999937] [G loss: 1.000051]\n",
      "epoch:27 step:129735[D loss: 0.999981] [G loss: 1.000054]\n",
      "epoch:27 step:129740[D loss: 1.000018] [G loss: 1.000085]\n",
      "epoch:27 step:129745[D loss: 0.999980] [G loss: 1.000043]\n",
      "epoch:27 step:129750[D loss: 1.000035] [G loss: 1.000053]\n",
      "epoch:27 step:129755[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:27 step:129760[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:27 step:129765[D loss: 1.000029] [G loss: 0.999957]\n",
      "epoch:27 step:129770[D loss: 1.000007] [G loss: 1.000009]\n",
      "epoch:27 step:129775[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:27 step:129780[D loss: 1.000037] [G loss: 0.999961]\n",
      "epoch:27 step:129785[D loss: 0.999940] [G loss: 1.000045]\n",
      "epoch:27 step:129790[D loss: 1.000065] [G loss: 0.999956]\n",
      "epoch:27 step:129795[D loss: 0.999957] [G loss: 1.000041]\n",
      "epoch:27 step:129800[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:27 step:129805[D loss: 0.999989] [G loss: 1.000195]\n",
      "epoch:27 step:129810[D loss: 0.999803] [G loss: 1.000419]\n",
      "epoch:27 step:129815[D loss: 0.999893] [G loss: 1.000160]\n",
      "epoch:27 step:129820[D loss: 0.999952] [G loss: 1.000048]\n",
      "epoch:27 step:129825[D loss: 1.000024] [G loss: 0.999939]\n",
      "epoch:27 step:129830[D loss: 0.999967] [G loss: 1.000027]\n",
      "epoch:27 step:129835[D loss: 0.999991] [G loss: 1.000005]\n",
      "epoch:27 step:129840[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:27 step:129845[D loss: 0.999992] [G loss: 1.000002]\n",
      "epoch:27 step:129850[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:27 step:129855[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:27 step:129860[D loss: 0.999991] [G loss: 1.000039]\n",
      "epoch:27 step:129865[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:27 step:129870[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:27 step:129875[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:27 step:129880[D loss: 0.999949] [G loss: 1.000095]\n",
      "epoch:27 step:129885[D loss: 0.999953] [G loss: 1.000121]\n",
      "epoch:27 step:129890[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:27 step:129895[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:27 step:129900[D loss: 0.999960] [G loss: 1.000053]\n",
      "epoch:27 step:129905[D loss: 1.000009] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:129910[D loss: 0.999958] [G loss: 1.000059]\n",
      "epoch:27 step:129915[D loss: 0.999950] [G loss: 1.000073]\n",
      "epoch:27 step:129920[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:27 step:129925[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:27 step:129930[D loss: 0.999955] [G loss: 1.000035]\n",
      "epoch:27 step:129935[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:27 step:129940[D loss: 1.000081] [G loss: 0.999924]\n",
      "epoch:27 step:129945[D loss: 0.999975] [G loss: 1.000018]\n",
      "epoch:27 step:129950[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:27 step:129955[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:27 step:129960[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:27 step:129965[D loss: 1.000003] [G loss: 1.000028]\n",
      "epoch:27 step:129970[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:27 step:129975[D loss: 0.999995] [G loss: 1.000016]\n",
      "epoch:27 step:129980[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:27 step:129985[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:27 step:129990[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:27 step:129995[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:27 step:130000[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:27 step:130005[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:27 step:130010[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:27 step:130015[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:27 step:130020[D loss: 0.999985] [G loss: 1.000080]\n",
      "epoch:27 step:130025[D loss: 1.000022] [G loss: 1.000000]\n",
      "epoch:27 step:130030[D loss: 0.999858] [G loss: 1.000238]\n",
      "epoch:27 step:130035[D loss: 0.999970] [G loss: 1.000106]\n",
      "epoch:27 step:130040[D loss: 1.000016] [G loss: 1.000003]\n",
      "epoch:27 step:130045[D loss: 1.000064] [G loss: 0.999955]\n",
      "epoch:27 step:130050[D loss: 0.999935] [G loss: 1.000023]\n",
      "epoch:27 step:130055[D loss: 1.000131] [G loss: 0.999674]\n",
      "epoch:27 step:130060[D loss: 0.999960] [G loss: 1.000013]\n",
      "epoch:27 step:130065[D loss: 1.000035] [G loss: 1.000151]\n",
      "epoch:27 step:130070[D loss: 0.999945] [G loss: 1.000142]\n",
      "epoch:27 step:130075[D loss: 0.999894] [G loss: 1.000057]\n",
      "epoch:27 step:130080[D loss: 1.000041] [G loss: 0.999976]\n",
      "epoch:27 step:130085[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:27 step:130090[D loss: 0.999959] [G loss: 1.000030]\n",
      "epoch:27 step:130095[D loss: 1.000011] [G loss: 1.000028]\n",
      "epoch:27 step:130100[D loss: 0.999945] [G loss: 1.000052]\n",
      "epoch:27 step:130105[D loss: 0.999974] [G loss: 1.000147]\n",
      "epoch:27 step:130110[D loss: 0.999978] [G loss: 1.000032]\n",
      "epoch:27 step:130115[D loss: 0.999943] [G loss: 1.000065]\n",
      "epoch:27 step:130120[D loss: 1.000006] [G loss: 0.999927]\n",
      "epoch:27 step:130125[D loss: 0.999960] [G loss: 0.999980]\n",
      "epoch:27 step:130130[D loss: 1.000044] [G loss: 1.000044]\n",
      "epoch:27 step:130135[D loss: 0.999976] [G loss: 0.999990]\n",
      "epoch:27 step:130140[D loss: 0.999867] [G loss: 1.000209]\n",
      "epoch:27 step:130145[D loss: 1.000126] [G loss: 0.999918]\n",
      "epoch:27 step:130150[D loss: 0.999941] [G loss: 1.000085]\n",
      "epoch:27 step:130155[D loss: 1.000026] [G loss: 1.000022]\n",
      "epoch:27 step:130160[D loss: 0.999958] [G loss: 1.000013]\n",
      "epoch:27 step:130165[D loss: 0.999967] [G loss: 1.000002]\n",
      "epoch:27 step:130170[D loss: 0.999990] [G loss: 0.999950]\n",
      "epoch:27 step:130175[D loss: 0.999971] [G loss: 1.000128]\n",
      "epoch:27 step:130180[D loss: 0.999918] [G loss: 1.000058]\n",
      "epoch:27 step:130185[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:27 step:130190[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:27 step:130195[D loss: 0.999954] [G loss: 1.000087]\n",
      "epoch:27 step:130200[D loss: 0.999994] [G loss: 1.000058]\n",
      "epoch:27 step:130205[D loss: 1.000045] [G loss: 1.000029]\n",
      "epoch:27 step:130210[D loss: 0.999943] [G loss: 1.000092]\n",
      "epoch:27 step:130215[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:27 step:130220[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:27 step:130225[D loss: 1.000015] [G loss: 0.999989]\n",
      "epoch:27 step:130230[D loss: 0.999957] [G loss: 1.000123]\n",
      "epoch:27 step:130235[D loss: 0.999999] [G loss: 1.000031]\n",
      "epoch:27 step:130240[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:27 step:130245[D loss: 1.000101] [G loss: 0.999858]\n",
      "epoch:27 step:130250[D loss: 1.000000] [G loss: 0.999891]\n",
      "epoch:27 step:130255[D loss: 0.999950] [G loss: 1.000061]\n",
      "epoch:27 step:130260[D loss: 1.000024] [G loss: 0.999952]\n",
      "epoch:27 step:130265[D loss: 1.000005] [G loss: 1.000136]\n",
      "epoch:27 step:130270[D loss: 0.999959] [G loss: 1.000123]\n",
      "epoch:27 step:130275[D loss: 0.999955] [G loss: 1.000038]\n",
      "epoch:27 step:130280[D loss: 0.999981] [G loss: 1.000031]\n",
      "epoch:27 step:130285[D loss: 0.999999] [G loss: 1.000023]\n",
      "epoch:27 step:130290[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:27 step:130295[D loss: 0.999930] [G loss: 1.000100]\n",
      "epoch:27 step:130300[D loss: 1.000013] [G loss: 0.999982]\n",
      "epoch:27 step:130305[D loss: 1.000016] [G loss: 1.000133]\n",
      "epoch:27 step:130310[D loss: 0.999925] [G loss: 1.000092]\n",
      "epoch:27 step:130315[D loss: 0.999949] [G loss: 1.000121]\n",
      "epoch:27 step:130320[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:27 step:130325[D loss: 0.999944] [G loss: 1.000128]\n",
      "epoch:27 step:130330[D loss: 0.999918] [G loss: 1.000234]\n",
      "epoch:27 step:130335[D loss: 0.999958] [G loss: 1.000039]\n",
      "epoch:27 step:130340[D loss: 0.999956] [G loss: 1.000107]\n",
      "epoch:27 step:130345[D loss: 1.000012] [G loss: 0.999986]\n",
      "epoch:27 step:130350[D loss: 0.999951] [G loss: 1.000055]\n",
      "epoch:27 step:130355[D loss: 1.000100] [G loss: 0.999800]\n",
      "epoch:27 step:130360[D loss: 0.999984] [G loss: 1.000072]\n",
      "epoch:27 step:130365[D loss: 1.000006] [G loss: 1.000087]\n",
      "epoch:27 step:130370[D loss: 0.999841] [G loss: 1.000161]\n",
      "epoch:27 step:130375[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:27 step:130380[D loss: 0.999952] [G loss: 1.000067]\n",
      "epoch:27 step:130385[D loss: 1.000006] [G loss: 0.999988]\n",
      "epoch:27 step:130390[D loss: 1.000083] [G loss: 0.999909]\n",
      "epoch:27 step:130395[D loss: 1.000011] [G loss: 0.999991]\n",
      "epoch:27 step:130400[D loss: 0.999932] [G loss: 1.000025]\n",
      "epoch:27 step:130405[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:27 step:130410[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:27 step:130415[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:27 step:130420[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:27 step:130425[D loss: 0.999957] [G loss: 1.000051]\n",
      "epoch:27 step:130430[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:27 step:130435[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:27 step:130440[D loss: 1.000014] [G loss: 1.000058]\n",
      "epoch:27 step:130445[D loss: 0.999970] [G loss: 1.000059]\n",
      "epoch:27 step:130450[D loss: 1.000021] [G loss: 0.999940]\n",
      "epoch:27 step:130455[D loss: 0.999930] [G loss: 1.000062]\n",
      "epoch:27 step:130460[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:27 step:130465[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:27 step:130470[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:27 step:130475[D loss: 1.000037] [G loss: 0.999992]\n",
      "epoch:27 step:130480[D loss: 1.000004] [G loss: 1.000072]\n",
      "epoch:27 step:130485[D loss: 1.000185] [G loss: 0.999815]\n",
      "epoch:27 step:130490[D loss: 0.999976] [G loss: 1.000063]\n",
      "epoch:27 step:130495[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:27 step:130500[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:27 step:130505[D loss: 0.999993] [G loss: 1.000014]\n",
      "epoch:27 step:130510[D loss: 0.999948] [G loss: 1.000034]\n",
      "epoch:27 step:130515[D loss: 0.999988] [G loss: 1.000061]\n",
      "epoch:27 step:130520[D loss: 1.000158] [G loss: 0.999846]\n",
      "epoch:27 step:130525[D loss: 0.999930] [G loss: 1.000031]\n",
      "epoch:27 step:130530[D loss: 1.000038] [G loss: 1.000120]\n",
      "epoch:27 step:130535[D loss: 0.999893] [G loss: 1.000446]\n",
      "epoch:27 step:130540[D loss: 0.999930] [G loss: 1.000133]\n",
      "epoch:27 step:130545[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:27 step:130550[D loss: 0.999955] [G loss: 1.000054]\n",
      "epoch:27 step:130555[D loss: 0.999995] [G loss: 0.999992]\n",
      "epoch:27 step:130560[D loss: 0.999971] [G loss: 1.000029]\n",
      "epoch:27 step:130565[D loss: 0.999971] [G loss: 1.000028]\n",
      "epoch:27 step:130570[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:27 step:130575[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:27 step:130580[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:27 step:130585[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:27 step:130590[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:27 step:130595[D loss: 0.999986] [G loss: 1.000007]\n",
      "epoch:27 step:130600[D loss: 1.000011] [G loss: 1.000030]\n",
      "epoch:27 step:130605[D loss: 1.000045] [G loss: 0.999975]\n",
      "epoch:27 step:130610[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:27 step:130615[D loss: 0.999973] [G loss: 1.000076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:130620[D loss: 0.999948] [G loss: 1.000074]\n",
      "epoch:27 step:130625[D loss: 1.000058] [G loss: 0.999979]\n",
      "epoch:27 step:130630[D loss: 0.999906] [G loss: 1.000086]\n",
      "epoch:27 step:130635[D loss: 0.999951] [G loss: 1.000129]\n",
      "epoch:27 step:130640[D loss: 1.000020] [G loss: 1.000104]\n",
      "epoch:27 step:130645[D loss: 0.999921] [G loss: 1.000142]\n",
      "epoch:27 step:130650[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:27 step:130655[D loss: 1.000065] [G loss: 0.999957]\n",
      "epoch:27 step:130660[D loss: 0.999921] [G loss: 1.000023]\n",
      "epoch:27 step:130665[D loss: 1.000199] [G loss: 0.999876]\n",
      "epoch:27 step:130670[D loss: 0.999859] [G loss: 1.000095]\n",
      "epoch:27 step:130675[D loss: 1.000005] [G loss: 0.999973]\n",
      "epoch:27 step:130680[D loss: 1.000015] [G loss: 0.999969]\n",
      "epoch:27 step:130685[D loss: 0.999900] [G loss: 1.000148]\n",
      "epoch:27 step:130690[D loss: 1.000024] [G loss: 1.000021]\n",
      "epoch:27 step:130695[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:27 step:130700[D loss: 0.999996] [G loss: 1.000075]\n",
      "epoch:27 step:130705[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:27 step:130710[D loss: 1.000067] [G loss: 0.999958]\n",
      "epoch:27 step:130715[D loss: 1.000131] [G loss: 0.999965]\n",
      "epoch:27 step:130720[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:27 step:130725[D loss: 0.999897] [G loss: 1.000161]\n",
      "epoch:27 step:130730[D loss: 0.999904] [G loss: 1.000174]\n",
      "epoch:27 step:130735[D loss: 0.999950] [G loss: 1.000121]\n",
      "epoch:27 step:130740[D loss: 0.999989] [G loss: 1.000119]\n",
      "epoch:27 step:130745[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:27 step:130750[D loss: 0.999970] [G loss: 1.000029]\n",
      "epoch:27 step:130755[D loss: 0.999959] [G loss: 1.000065]\n",
      "epoch:27 step:130760[D loss: 1.000039] [G loss: 0.999925]\n",
      "epoch:27 step:130765[D loss: 1.000017] [G loss: 0.999872]\n",
      "epoch:27 step:130770[D loss: 0.999918] [G loss: 1.000061]\n",
      "epoch:27 step:130775[D loss: 1.000056] [G loss: 0.999977]\n",
      "epoch:27 step:130780[D loss: 0.999960] [G loss: 1.000004]\n",
      "epoch:27 step:130785[D loss: 0.999966] [G loss: 1.000102]\n",
      "epoch:27 step:130790[D loss: 1.000137] [G loss: 0.999843]\n",
      "epoch:27 step:130795[D loss: 0.999897] [G loss: 1.000146]\n",
      "epoch:27 step:130800[D loss: 0.999957] [G loss: 1.000047]\n",
      "epoch:27 step:130805[D loss: 0.999994] [G loss: 1.000046]\n",
      "epoch:27 step:130810[D loss: 1.000017] [G loss: 1.000001]\n",
      "epoch:27 step:130815[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:27 step:130820[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:27 step:130825[D loss: 0.999910] [G loss: 1.000103]\n",
      "epoch:27 step:130830[D loss: 1.000034] [G loss: 1.000104]\n",
      "epoch:27 step:130835[D loss: 1.000076] [G loss: 0.999851]\n",
      "epoch:27 step:130840[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:27 step:130845[D loss: 0.999982] [G loss: 1.000235]\n",
      "epoch:27 step:130850[D loss: 0.999947] [G loss: 1.000039]\n",
      "epoch:27 step:130855[D loss: 1.000003] [G loss: 0.999973]\n",
      "epoch:27 step:130860[D loss: 0.999941] [G loss: 1.000081]\n",
      "epoch:27 step:130865[D loss: 0.999962] [G loss: 1.000037]\n",
      "epoch:27 step:130870[D loss: 1.000017] [G loss: 0.999966]\n",
      "epoch:27 step:130875[D loss: 1.000046] [G loss: 0.999928]\n",
      "epoch:27 step:130880[D loss: 0.999913] [G loss: 1.000084]\n",
      "epoch:27 step:130885[D loss: 0.999962] [G loss: 1.000109]\n",
      "epoch:27 step:130890[D loss: 0.999920] [G loss: 1.000137]\n",
      "epoch:27 step:130895[D loss: 0.999945] [G loss: 1.000154]\n",
      "epoch:27 step:130900[D loss: 0.999972] [G loss: 1.000007]\n",
      "epoch:27 step:130905[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:27 step:130910[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:27 step:130915[D loss: 0.999907] [G loss: 1.000157]\n",
      "epoch:27 step:130920[D loss: 1.000007] [G loss: 1.000029]\n",
      "epoch:27 step:130925[D loss: 0.999993] [G loss: 1.000036]\n",
      "epoch:27 step:130930[D loss: 0.999983] [G loss: 1.000090]\n",
      "epoch:27 step:130935[D loss: 0.999913] [G loss: 1.000140]\n",
      "epoch:27 step:130940[D loss: 0.999972] [G loss: 1.000137]\n",
      "epoch:27 step:130945[D loss: 0.999981] [G loss: 1.000025]\n",
      "epoch:27 step:130950[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:27 step:130955[D loss: 0.999963] [G loss: 1.000054]\n",
      "epoch:27 step:130960[D loss: 0.999983] [G loss: 1.000062]\n",
      "epoch:27 step:130965[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:27 step:130970[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:27 step:130975[D loss: 1.000024] [G loss: 1.000082]\n",
      "epoch:27 step:130980[D loss: 0.999994] [G loss: 1.000018]\n",
      "epoch:27 step:130985[D loss: 0.999909] [G loss: 1.000107]\n",
      "epoch:27 step:130990[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:27 step:130995[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:27 step:131000[D loss: 1.000000] [G loss: 1.000184]\n",
      "epoch:27 step:131005[D loss: 0.999957] [G loss: 1.000086]\n",
      "epoch:27 step:131010[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:27 step:131015[D loss: 0.999999] [G loss: 1.000058]\n",
      "epoch:27 step:131020[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:27 step:131025[D loss: 1.000040] [G loss: 0.999995]\n",
      "epoch:27 step:131030[D loss: 0.999955] [G loss: 1.000045]\n",
      "epoch:27 step:131035[D loss: 1.000019] [G loss: 1.000008]\n",
      "epoch:27 step:131040[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:27 step:131045[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:27 step:131050[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:27 step:131055[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:27 step:131060[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:27 step:131065[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:27 step:131070[D loss: 1.000001] [G loss: 1.000087]\n",
      "epoch:27 step:131075[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:27 step:131080[D loss: 1.000105] [G loss: 1.000009]\n",
      "epoch:27 step:131085[D loss: 0.999925] [G loss: 1.000085]\n",
      "epoch:27 step:131090[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:27 step:131095[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:27 step:131100[D loss: 1.000012] [G loss: 0.999999]\n",
      "epoch:27 step:131105[D loss: 0.999947] [G loss: 1.000086]\n",
      "epoch:27 step:131110[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:27 step:131115[D loss: 0.999990] [G loss: 1.000000]\n",
      "epoch:27 step:131120[D loss: 0.999957] [G loss: 1.000057]\n",
      "epoch:27 step:131125[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:27 step:131130[D loss: 1.000010] [G loss: 0.999976]\n",
      "epoch:27 step:131135[D loss: 0.999983] [G loss: 1.000031]\n",
      "epoch:27 step:131140[D loss: 1.000012] [G loss: 1.000019]\n",
      "epoch:27 step:131145[D loss: 0.999983] [G loss: 1.000019]\n",
      "epoch:27 step:131150[D loss: 0.999989] [G loss: 1.000092]\n",
      "epoch:27 step:131155[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:27 step:131160[D loss: 0.999976] [G loss: 1.000118]\n",
      "epoch:27 step:131165[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:27 step:131170[D loss: 1.000038] [G loss: 1.000016]\n",
      "epoch:27 step:131175[D loss: 0.999981] [G loss: 0.999949]\n",
      "epoch:27 step:131180[D loss: 0.999936] [G loss: 0.999984]\n",
      "epoch:28 step:131185[D loss: 0.999943] [G loss: 1.000044]\n",
      "epoch:28 step:131190[D loss: 0.999965] [G loss: 1.000037]\n",
      "epoch:28 step:131195[D loss: 0.999945] [G loss: 1.000065]\n",
      "epoch:28 step:131200[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:28 step:131205[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:28 step:131210[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:28 step:131215[D loss: 0.999991] [G loss: 1.000012]\n",
      "epoch:28 step:131220[D loss: 0.999997] [G loss: 0.999997]\n",
      "epoch:28 step:131225[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:28 step:131230[D loss: 0.999982] [G loss: 1.000146]\n",
      "epoch:28 step:131235[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:28 step:131240[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:28 step:131245[D loss: 0.999922] [G loss: 1.000080]\n",
      "epoch:28 step:131250[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:28 step:131255[D loss: 0.999982] [G loss: 1.000051]\n",
      "epoch:28 step:131260[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:28 step:131265[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:28 step:131270[D loss: 0.999993] [G loss: 1.000034]\n",
      "epoch:28 step:131275[D loss: 0.999978] [G loss: 1.000038]\n",
      "epoch:28 step:131280[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:28 step:131285[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:28 step:131290[D loss: 1.000052] [G loss: 0.999987]\n",
      "epoch:28 step:131295[D loss: 0.999929] [G loss: 1.000088]\n",
      "epoch:28 step:131300[D loss: 0.999969] [G loss: 1.000095]\n",
      "epoch:28 step:131305[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:28 step:131310[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:28 step:131315[D loss: 0.999982] [G loss: 1.000113]\n",
      "epoch:28 step:131320[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:28 step:131325[D loss: 0.999962] [G loss: 1.000075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:131330[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:28 step:131335[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:28 step:131340[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:28 step:131345[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:28 step:131350[D loss: 0.999987] [G loss: 1.000099]\n",
      "epoch:28 step:131355[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:28 step:131360[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:28 step:131365[D loss: 0.999982] [G loss: 1.000109]\n",
      "epoch:28 step:131370[D loss: 1.000009] [G loss: 0.999997]\n",
      "epoch:28 step:131375[D loss: 1.000019] [G loss: 1.000065]\n",
      "epoch:28 step:131380[D loss: 1.000085] [G loss: 1.000024]\n",
      "epoch:28 step:131385[D loss: 0.999994] [G loss: 1.000075]\n",
      "epoch:28 step:131390[D loss: 0.999975] [G loss: 1.000017]\n",
      "epoch:28 step:131395[D loss: 0.999944] [G loss: 1.000107]\n",
      "epoch:28 step:131400[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:28 step:131405[D loss: 0.999964] [G loss: 1.000080]\n",
      "epoch:28 step:131410[D loss: 0.999983] [G loss: 1.000083]\n",
      "epoch:28 step:131415[D loss: 0.999964] [G loss: 1.000060]\n",
      "epoch:28 step:131420[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:28 step:131425[D loss: 0.999992] [G loss: 1.000040]\n",
      "epoch:28 step:131430[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:28 step:131435[D loss: 0.999993] [G loss: 1.000067]\n",
      "epoch:28 step:131440[D loss: 0.999967] [G loss: 1.000044]\n",
      "epoch:28 step:131445[D loss: 1.000026] [G loss: 1.000003]\n",
      "epoch:28 step:131450[D loss: 1.000017] [G loss: 1.000014]\n",
      "epoch:28 step:131455[D loss: 0.999960] [G loss: 1.000069]\n",
      "epoch:28 step:131460[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:28 step:131465[D loss: 0.999968] [G loss: 1.000113]\n",
      "epoch:28 step:131470[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:28 step:131475[D loss: 0.999966] [G loss: 1.000117]\n",
      "epoch:28 step:131480[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:28 step:131485[D loss: 0.999954] [G loss: 1.000026]\n",
      "epoch:28 step:131490[D loss: 1.000001] [G loss: 0.999981]\n",
      "epoch:28 step:131495[D loss: 1.000098] [G loss: 0.999882]\n",
      "epoch:28 step:131500[D loss: 1.000073] [G loss: 0.999931]\n",
      "epoch:28 step:131505[D loss: 0.999921] [G loss: 1.000087]\n",
      "epoch:28 step:131510[D loss: 0.999922] [G loss: 1.000073]\n",
      "epoch:28 step:131515[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:28 step:131520[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:28 step:131525[D loss: 1.000069] [G loss: 1.000024]\n",
      "epoch:28 step:131530[D loss: 1.000055] [G loss: 0.999915]\n",
      "epoch:28 step:131535[D loss: 1.000012] [G loss: 1.000044]\n",
      "epoch:28 step:131540[D loss: 1.000006] [G loss: 1.000124]\n",
      "epoch:28 step:131545[D loss: 1.000004] [G loss: 1.000035]\n",
      "epoch:28 step:131550[D loss: 0.999984] [G loss: 1.000029]\n",
      "epoch:28 step:131555[D loss: 0.999938] [G loss: 1.000045]\n",
      "epoch:28 step:131560[D loss: 0.999941] [G loss: 1.000119]\n",
      "epoch:28 step:131565[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:28 step:131570[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:28 step:131575[D loss: 0.999960] [G loss: 1.000035]\n",
      "epoch:28 step:131580[D loss: 0.999923] [G loss: 1.000067]\n",
      "epoch:28 step:131585[D loss: 0.999972] [G loss: 1.000103]\n",
      "epoch:28 step:131590[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:28 step:131595[D loss: 0.999995] [G loss: 1.000003]\n",
      "epoch:28 step:131600[D loss: 0.999999] [G loss: 0.999951]\n",
      "epoch:28 step:131605[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:28 step:131610[D loss: 1.000004] [G loss: 0.999987]\n",
      "epoch:28 step:131615[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:28 step:131620[D loss: 0.999988] [G loss: 1.000008]\n",
      "epoch:28 step:131625[D loss: 1.000025] [G loss: 1.000021]\n",
      "epoch:28 step:131630[D loss: 0.999952] [G loss: 1.000063]\n",
      "epoch:28 step:131635[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:28 step:131640[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:28 step:131645[D loss: 1.000040] [G loss: 0.999992]\n",
      "epoch:28 step:131650[D loss: 1.000002] [G loss: 1.000069]\n",
      "epoch:28 step:131655[D loss: 1.000033] [G loss: 1.000057]\n",
      "epoch:28 step:131660[D loss: 1.000093] [G loss: 0.999934]\n",
      "epoch:28 step:131665[D loss: 0.999968] [G loss: 1.000114]\n",
      "epoch:28 step:131670[D loss: 0.999983] [G loss: 1.000136]\n",
      "epoch:28 step:131675[D loss: 0.999967] [G loss: 1.000147]\n",
      "epoch:28 step:131680[D loss: 0.999983] [G loss: 1.000059]\n",
      "epoch:28 step:131685[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:28 step:131690[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:28 step:131695[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:28 step:131700[D loss: 0.999953] [G loss: 1.000144]\n",
      "epoch:28 step:131705[D loss: 1.000184] [G loss: 0.999850]\n",
      "epoch:28 step:131710[D loss: 0.999870] [G loss: 1.000078]\n",
      "epoch:28 step:131715[D loss: 0.999954] [G loss: 1.000181]\n",
      "epoch:28 step:131720[D loss: 1.000078] [G loss: 0.999906]\n",
      "epoch:28 step:131725[D loss: 0.999922] [G loss: 1.000116]\n",
      "epoch:28 step:131730[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:28 step:131735[D loss: 0.999958] [G loss: 1.000035]\n",
      "epoch:28 step:131740[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:28 step:131745[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:28 step:131750[D loss: 0.999996] [G loss: 0.999997]\n",
      "epoch:28 step:131755[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:28 step:131760[D loss: 1.000061] [G loss: 1.000004]\n",
      "epoch:28 step:131765[D loss: 1.000140] [G loss: 0.999908]\n",
      "epoch:28 step:131770[D loss: 1.000093] [G loss: 1.000022]\n",
      "epoch:28 step:131775[D loss: 0.999928] [G loss: 1.000341]\n",
      "epoch:28 step:131780[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:28 step:131785[D loss: 0.999910] [G loss: 1.000154]\n",
      "epoch:28 step:131790[D loss: 0.999889] [G loss: 1.000173]\n",
      "epoch:28 step:131795[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:28 step:131800[D loss: 1.000003] [G loss: 0.999992]\n",
      "epoch:28 step:131805[D loss: 1.000106] [G loss: 0.999938]\n",
      "epoch:28 step:131810[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:28 step:131815[D loss: 1.000019] [G loss: 1.000015]\n",
      "epoch:28 step:131820[D loss: 0.999944] [G loss: 1.000073]\n",
      "epoch:28 step:131825[D loss: 1.000016] [G loss: 1.000002]\n",
      "epoch:28 step:131830[D loss: 0.999894] [G loss: 1.000099]\n",
      "epoch:28 step:131835[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:28 step:131840[D loss: 0.999988] [G loss: 1.000076]\n",
      "epoch:28 step:131845[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:28 step:131850[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:28 step:131855[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:28 step:131860[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:28 step:131865[D loss: 0.999977] [G loss: 1.000054]\n",
      "epoch:28 step:131870[D loss: 0.999978] [G loss: 1.000065]\n",
      "epoch:28 step:131875[D loss: 0.999981] [G loss: 1.000074]\n",
      "epoch:28 step:131880[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:28 step:131885[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:28 step:131890[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:28 step:131895[D loss: 0.999975] [G loss: 1.000061]\n",
      "epoch:28 step:131900[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:28 step:131905[D loss: 0.999967] [G loss: 1.000128]\n",
      "epoch:28 step:131910[D loss: 0.999944] [G loss: 1.000085]\n",
      "epoch:28 step:131915[D loss: 0.999934] [G loss: 1.000118]\n",
      "epoch:28 step:131920[D loss: 0.999984] [G loss: 1.000050]\n",
      "epoch:28 step:131925[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:28 step:131930[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:28 step:131935[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:28 step:131940[D loss: 1.000005] [G loss: 1.000078]\n",
      "epoch:28 step:131945[D loss: 0.999948] [G loss: 1.000070]\n",
      "epoch:28 step:131950[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:28 step:131955[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:28 step:131960[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:28 step:131965[D loss: 0.999967] [G loss: 1.000120]\n",
      "epoch:28 step:131970[D loss: 0.999994] [G loss: 1.000099]\n",
      "epoch:28 step:131975[D loss: 0.999949] [G loss: 1.000099]\n",
      "epoch:28 step:131980[D loss: 1.000040] [G loss: 0.999998]\n",
      "epoch:28 step:131985[D loss: 1.000026] [G loss: 1.000094]\n",
      "epoch:28 step:131990[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:28 step:131995[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:28 step:132000[D loss: 0.999990] [G loss: 1.000075]\n",
      "epoch:28 step:132005[D loss: 1.000055] [G loss: 1.000020]\n",
      "epoch:28 step:132010[D loss: 1.000006] [G loss: 1.000048]\n",
      "epoch:28 step:132015[D loss: 0.999965] [G loss: 1.000029]\n",
      "epoch:28 step:132020[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:28 step:132025[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:28 step:132030[D loss: 0.999958] [G loss: 1.000086]\n",
      "epoch:28 step:132035[D loss: 0.999980] [G loss: 1.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:132040[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:28 step:132045[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:28 step:132050[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:28 step:132055[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:28 step:132060[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:28 step:132065[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:28 step:132070[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:28 step:132075[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:28 step:132080[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:28 step:132085[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:28 step:132090[D loss: 0.999990] [G loss: 1.000012]\n",
      "epoch:28 step:132095[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:28 step:132100[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:28 step:132105[D loss: 1.000021] [G loss: 0.999998]\n",
      "epoch:28 step:132110[D loss: 0.999955] [G loss: 1.000043]\n",
      "epoch:28 step:132115[D loss: 0.999961] [G loss: 1.000046]\n",
      "epoch:28 step:132120[D loss: 1.000041] [G loss: 1.000044]\n",
      "epoch:28 step:132125[D loss: 0.999975] [G loss: 1.000042]\n",
      "epoch:28 step:132130[D loss: 0.999948] [G loss: 1.000068]\n",
      "epoch:28 step:132135[D loss: 0.999986] [G loss: 1.000033]\n",
      "epoch:28 step:132140[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:28 step:132145[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:28 step:132150[D loss: 1.000036] [G loss: 1.000010]\n",
      "epoch:28 step:132155[D loss: 1.000011] [G loss: 1.000053]\n",
      "epoch:28 step:132160[D loss: 1.000026] [G loss: 1.000020]\n",
      "epoch:28 step:132165[D loss: 0.999966] [G loss: 1.000166]\n",
      "epoch:28 step:132170[D loss: 1.000170] [G loss: 0.999948]\n",
      "epoch:28 step:132175[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:28 step:132180[D loss: 1.000056] [G loss: 1.000136]\n",
      "epoch:28 step:132185[D loss: 0.999975] [G loss: 1.000115]\n",
      "epoch:28 step:132190[D loss: 0.999951] [G loss: 1.000061]\n",
      "epoch:28 step:132195[D loss: 0.999944] [G loss: 1.000090]\n",
      "epoch:28 step:132200[D loss: 1.000006] [G loss: 1.000002]\n",
      "epoch:28 step:132205[D loss: 0.999976] [G loss: 0.999990]\n",
      "epoch:28 step:132210[D loss: 1.000023] [G loss: 0.999958]\n",
      "epoch:28 step:132215[D loss: 1.000032] [G loss: 0.999923]\n",
      "epoch:28 step:132220[D loss: 0.999948] [G loss: 0.999998]\n",
      "epoch:28 step:132225[D loss: 1.000055] [G loss: 0.999960]\n",
      "epoch:28 step:132230[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:28 step:132235[D loss: 0.999993] [G loss: 1.000100]\n",
      "epoch:28 step:132240[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:28 step:132245[D loss: 0.999951] [G loss: 1.000134]\n",
      "epoch:28 step:132250[D loss: 1.000072] [G loss: 0.999958]\n",
      "epoch:28 step:132255[D loss: 0.999963] [G loss: 1.000124]\n",
      "epoch:28 step:132260[D loss: 0.999973] [G loss: 1.000102]\n",
      "epoch:28 step:132265[D loss: 1.000070] [G loss: 1.000162]\n",
      "epoch:28 step:132270[D loss: 0.999948] [G loss: 1.000141]\n",
      "epoch:28 step:132275[D loss: 0.999980] [G loss: 1.000013]\n",
      "epoch:28 step:132280[D loss: 0.999985] [G loss: 1.000042]\n",
      "epoch:28 step:132285[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:28 step:132290[D loss: 1.000014] [G loss: 1.000022]\n",
      "epoch:28 step:132295[D loss: 1.000015] [G loss: 0.999989]\n",
      "epoch:28 step:132300[D loss: 0.999951] [G loss: 1.000048]\n",
      "epoch:28 step:132305[D loss: 1.000036] [G loss: 0.999945]\n",
      "epoch:28 step:132310[D loss: 1.000088] [G loss: 0.999954]\n",
      "epoch:28 step:132315[D loss: 1.000028] [G loss: 1.000130]\n",
      "epoch:28 step:132320[D loss: 0.999991] [G loss: 0.999992]\n",
      "epoch:28 step:132325[D loss: 1.000021] [G loss: 0.999907]\n",
      "epoch:28 step:132330[D loss: 1.000104] [G loss: 0.999963]\n",
      "epoch:28 step:132335[D loss: 0.999979] [G loss: 1.000037]\n",
      "epoch:28 step:132340[D loss: 0.999897] [G loss: 1.000150]\n",
      "epoch:28 step:132345[D loss: 1.000013] [G loss: 1.000082]\n",
      "epoch:28 step:132350[D loss: 0.999931] [G loss: 1.000227]\n",
      "epoch:28 step:132355[D loss: 0.999943] [G loss: 1.000166]\n",
      "epoch:28 step:132360[D loss: 0.999946] [G loss: 1.000092]\n",
      "epoch:28 step:132365[D loss: 0.999986] [G loss: 1.000103]\n",
      "epoch:28 step:132370[D loss: 1.000014] [G loss: 0.999993]\n",
      "epoch:28 step:132375[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:28 step:132380[D loss: 1.000030] [G loss: 1.000101]\n",
      "epoch:28 step:132385[D loss: 0.999980] [G loss: 1.000186]\n",
      "epoch:28 step:132390[D loss: 1.000037] [G loss: 1.000015]\n",
      "epoch:28 step:132395[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:28 step:132400[D loss: 0.999993] [G loss: 1.000117]\n",
      "epoch:28 step:132405[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:28 step:132410[D loss: 0.999980] [G loss: 0.999994]\n",
      "epoch:28 step:132415[D loss: 1.000011] [G loss: 1.000056]\n",
      "epoch:28 step:132420[D loss: 1.000058] [G loss: 1.000023]\n",
      "epoch:28 step:132425[D loss: 0.999925] [G loss: 1.000085]\n",
      "epoch:28 step:132430[D loss: 0.999974] [G loss: 1.000155]\n",
      "epoch:28 step:132435[D loss: 0.999990] [G loss: 1.000119]\n",
      "epoch:28 step:132440[D loss: 0.999920] [G loss: 1.000115]\n",
      "epoch:28 step:132445[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:28 step:132450[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:28 step:132455[D loss: 1.000036] [G loss: 1.000086]\n",
      "epoch:28 step:132460[D loss: 1.000060] [G loss: 0.999925]\n",
      "epoch:28 step:132465[D loss: 0.999958] [G loss: 1.000136]\n",
      "epoch:28 step:132470[D loss: 1.000030] [G loss: 1.000010]\n",
      "epoch:28 step:132475[D loss: 0.999955] [G loss: 1.000057]\n",
      "epoch:28 step:132480[D loss: 0.999965] [G loss: 1.000096]\n",
      "epoch:28 step:132485[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:28 step:132490[D loss: 0.999984] [G loss: 1.000055]\n",
      "epoch:28 step:132495[D loss: 1.000045] [G loss: 0.999961]\n",
      "epoch:28 step:132500[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:28 step:132505[D loss: 0.999986] [G loss: 1.000036]\n",
      "epoch:28 step:132510[D loss: 1.000034] [G loss: 1.000002]\n",
      "epoch:28 step:132515[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:28 step:132520[D loss: 1.000003] [G loss: 1.000040]\n",
      "epoch:28 step:132525[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:28 step:132530[D loss: 0.999977] [G loss: 1.000101]\n",
      "epoch:28 step:132535[D loss: 0.999994] [G loss: 1.000036]\n",
      "epoch:28 step:132540[D loss: 0.999981] [G loss: 1.000048]\n",
      "epoch:28 step:132545[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:28 step:132550[D loss: 0.999967] [G loss: 1.000098]\n",
      "epoch:28 step:132555[D loss: 0.999991] [G loss: 1.000032]\n",
      "epoch:28 step:132560[D loss: 1.000031] [G loss: 0.999957]\n",
      "epoch:28 step:132565[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:28 step:132570[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:28 step:132575[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:28 step:132580[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:28 step:132585[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:28 step:132590[D loss: 0.999994] [G loss: 1.000002]\n",
      "epoch:28 step:132595[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:28 step:132600[D loss: 0.999929] [G loss: 1.000163]\n",
      "epoch:28 step:132605[D loss: 1.000022] [G loss: 0.999953]\n",
      "epoch:28 step:132610[D loss: 0.999958] [G loss: 1.000031]\n",
      "epoch:28 step:132615[D loss: 0.999969] [G loss: 1.000040]\n",
      "epoch:28 step:132620[D loss: 1.000004] [G loss: 1.000021]\n",
      "epoch:28 step:132625[D loss: 0.999954] [G loss: 1.000156]\n",
      "epoch:28 step:132630[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:28 step:132635[D loss: 1.000021] [G loss: 0.999988]\n",
      "epoch:28 step:132640[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:28 step:132645[D loss: 0.999983] [G loss: 1.000033]\n",
      "epoch:28 step:132650[D loss: 0.999968] [G loss: 1.000051]\n",
      "epoch:28 step:132655[D loss: 0.999960] [G loss: 1.000127]\n",
      "epoch:28 step:132660[D loss: 1.000014] [G loss: 1.000011]\n",
      "epoch:28 step:132665[D loss: 0.999948] [G loss: 1.000111]\n",
      "epoch:28 step:132670[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:28 step:132675[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:28 step:132680[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:28 step:132685[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:28 step:132690[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:28 step:132695[D loss: 1.000012] [G loss: 1.000049]\n",
      "epoch:28 step:132700[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:28 step:132705[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:28 step:132710[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:28 step:132715[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:28 step:132720[D loss: 0.999993] [G loss: 1.000029]\n",
      "epoch:28 step:132725[D loss: 1.000053] [G loss: 0.999985]\n",
      "epoch:28 step:132730[D loss: 1.000059] [G loss: 0.999941]\n",
      "epoch:28 step:132735[D loss: 1.000012] [G loss: 1.000057]\n",
      "epoch:28 step:132740[D loss: 0.999943] [G loss: 1.000058]\n",
      "epoch:28 step:132745[D loss: 0.999946] [G loss: 1.000028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:132750[D loss: 0.999945] [G loss: 1.000078]\n",
      "epoch:28 step:132755[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:28 step:132760[D loss: 0.999967] [G loss: 1.000200]\n",
      "epoch:28 step:132765[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:28 step:132770[D loss: 1.000007] [G loss: 1.000026]\n",
      "epoch:28 step:132775[D loss: 0.999930] [G loss: 1.000081]\n",
      "epoch:28 step:132780[D loss: 0.999987] [G loss: 1.000065]\n",
      "epoch:28 step:132785[D loss: 1.000039] [G loss: 1.000117]\n",
      "epoch:28 step:132790[D loss: 0.999965] [G loss: 1.000178]\n",
      "epoch:28 step:132795[D loss: 1.000010] [G loss: 1.000055]\n",
      "epoch:28 step:132800[D loss: 0.999951] [G loss: 1.000119]\n",
      "epoch:28 step:132805[D loss: 0.999989] [G loss: 0.999979]\n",
      "epoch:28 step:132810[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:28 step:132815[D loss: 1.000013] [G loss: 1.000054]\n",
      "epoch:28 step:132820[D loss: 0.999943] [G loss: 1.000033]\n",
      "epoch:28 step:132825[D loss: 0.999984] [G loss: 1.000116]\n",
      "epoch:28 step:132830[D loss: 1.000002] [G loss: 1.000123]\n",
      "epoch:28 step:132835[D loss: 0.999945] [G loss: 1.000134]\n",
      "epoch:28 step:132840[D loss: 0.999971] [G loss: 1.000077]\n",
      "epoch:28 step:132845[D loss: 1.000002] [G loss: 1.000004]\n",
      "epoch:28 step:132850[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:28 step:132855[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:28 step:132860[D loss: 0.999991] [G loss: 1.000034]\n",
      "epoch:28 step:132865[D loss: 0.999971] [G loss: 1.000112]\n",
      "epoch:28 step:132870[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:28 step:132875[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:28 step:132880[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:28 step:132885[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:28 step:132890[D loss: 0.999975] [G loss: 1.000060]\n",
      "epoch:28 step:132895[D loss: 0.999978] [G loss: 0.999999]\n",
      "epoch:28 step:132900[D loss: 0.999983] [G loss: 1.000023]\n",
      "epoch:28 step:132905[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:28 step:132910[D loss: 1.000061] [G loss: 1.000056]\n",
      "epoch:28 step:132915[D loss: 0.999929] [G loss: 1.000049]\n",
      "epoch:28 step:132920[D loss: 0.999962] [G loss: 1.000042]\n",
      "epoch:28 step:132925[D loss: 1.000033] [G loss: 1.000067]\n",
      "epoch:28 step:132930[D loss: 0.999927] [G loss: 1.000120]\n",
      "epoch:28 step:132935[D loss: 1.000015] [G loss: 1.000054]\n",
      "epoch:28 step:132940[D loss: 1.000011] [G loss: 1.000075]\n",
      "epoch:28 step:132945[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:28 step:132950[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:28 step:132955[D loss: 0.999971] [G loss: 1.000042]\n",
      "epoch:28 step:132960[D loss: 0.999972] [G loss: 1.000048]\n",
      "epoch:28 step:132965[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:28 step:132970[D loss: 0.999998] [G loss: 1.000114]\n",
      "epoch:28 step:132975[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:28 step:132980[D loss: 1.000071] [G loss: 0.999966]\n",
      "epoch:28 step:132985[D loss: 0.999869] [G loss: 1.000226]\n",
      "epoch:28 step:132990[D loss: 0.999928] [G loss: 1.000107]\n",
      "epoch:28 step:132995[D loss: 0.999980] [G loss: 1.000070]\n",
      "epoch:28 step:133000[D loss: 1.000015] [G loss: 1.000041]\n",
      "epoch:28 step:133005[D loss: 1.000024] [G loss: 0.999984]\n",
      "epoch:28 step:133010[D loss: 1.000006] [G loss: 1.000045]\n",
      "epoch:28 step:133015[D loss: 1.000054] [G loss: 1.000018]\n",
      "epoch:28 step:133020[D loss: 0.999927] [G loss: 1.000193]\n",
      "epoch:28 step:133025[D loss: 0.999969] [G loss: 1.000076]\n",
      "epoch:28 step:133030[D loss: 0.999950] [G loss: 1.000072]\n",
      "epoch:28 step:133035[D loss: 0.999910] [G loss: 1.000104]\n",
      "epoch:28 step:133040[D loss: 0.999987] [G loss: 1.000024]\n",
      "epoch:28 step:133045[D loss: 0.999975] [G loss: 1.000066]\n",
      "epoch:28 step:133050[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:28 step:133055[D loss: 1.000018] [G loss: 1.000032]\n",
      "epoch:28 step:133060[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:28 step:133065[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:28 step:133070[D loss: 1.000086] [G loss: 1.000030]\n",
      "epoch:28 step:133075[D loss: 0.999977] [G loss: 1.000052]\n",
      "epoch:28 step:133080[D loss: 0.999902] [G loss: 1.000123]\n",
      "epoch:28 step:133085[D loss: 0.999951] [G loss: 1.000088]\n",
      "epoch:28 step:133090[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:28 step:133095[D loss: 1.000078] [G loss: 0.999890]\n",
      "epoch:28 step:133100[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:28 step:133105[D loss: 1.000189] [G loss: 0.999896]\n",
      "epoch:28 step:133110[D loss: 0.999904] [G loss: 1.000067]\n",
      "epoch:28 step:133115[D loss: 1.000123] [G loss: 0.999968]\n",
      "epoch:28 step:133120[D loss: 0.999991] [G loss: 1.000058]\n",
      "epoch:28 step:133125[D loss: 0.999957] [G loss: 1.000045]\n",
      "epoch:28 step:133130[D loss: 0.999994] [G loss: 1.000055]\n",
      "epoch:28 step:133135[D loss: 0.999983] [G loss: 1.000014]\n",
      "epoch:28 step:133140[D loss: 0.999955] [G loss: 1.000102]\n",
      "epoch:28 step:133145[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:28 step:133150[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:28 step:133155[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:28 step:133160[D loss: 0.999999] [G loss: 1.000023]\n",
      "epoch:28 step:133165[D loss: 0.999993] [G loss: 1.000049]\n",
      "epoch:28 step:133170[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:28 step:133175[D loss: 1.000048] [G loss: 0.999917]\n",
      "epoch:28 step:133180[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:28 step:133185[D loss: 0.999999] [G loss: 1.000092]\n",
      "epoch:28 step:133190[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:28 step:133195[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:28 step:133200[D loss: 1.000025] [G loss: 1.000011]\n",
      "epoch:28 step:133205[D loss: 0.999928] [G loss: 1.000057]\n",
      "epoch:28 step:133210[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:28 step:133215[D loss: 1.000042] [G loss: 0.999950]\n",
      "epoch:28 step:133220[D loss: 0.999943] [G loss: 1.000100]\n",
      "epoch:28 step:133225[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:28 step:133230[D loss: 1.000105] [G loss: 0.999891]\n",
      "epoch:28 step:133235[D loss: 0.999929] [G loss: 1.000077]\n",
      "epoch:28 step:133240[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:28 step:133245[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:28 step:133250[D loss: 1.000015] [G loss: 0.999980]\n",
      "epoch:28 step:133255[D loss: 0.999950] [G loss: 1.000063]\n",
      "epoch:28 step:133260[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:28 step:133265[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:28 step:133270[D loss: 1.000038] [G loss: 0.999947]\n",
      "epoch:28 step:133275[D loss: 0.999914] [G loss: 1.000148]\n",
      "epoch:28 step:133280[D loss: 1.000001] [G loss: 1.000068]\n",
      "epoch:28 step:133285[D loss: 1.000082] [G loss: 1.000036]\n",
      "epoch:28 step:133290[D loss: 0.999924] [G loss: 1.000161]\n",
      "epoch:28 step:133295[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:28 step:133300[D loss: 0.999950] [G loss: 1.000085]\n",
      "epoch:28 step:133305[D loss: 0.999965] [G loss: 1.000066]\n",
      "epoch:28 step:133310[D loss: 1.000026] [G loss: 0.999967]\n",
      "epoch:28 step:133315[D loss: 1.000041] [G loss: 0.999999]\n",
      "epoch:28 step:133320[D loss: 1.000100] [G loss: 0.999866]\n",
      "epoch:28 step:133325[D loss: 0.999918] [G loss: 1.000240]\n",
      "epoch:28 step:133330[D loss: 0.999935] [G loss: 1.000220]\n",
      "epoch:28 step:133335[D loss: 0.999918] [G loss: 1.000086]\n",
      "epoch:28 step:133340[D loss: 1.000014] [G loss: 1.000103]\n",
      "epoch:28 step:133345[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:28 step:133350[D loss: 0.999997] [G loss: 1.000056]\n",
      "epoch:28 step:133355[D loss: 1.000008] [G loss: 1.000030]\n",
      "epoch:28 step:133360[D loss: 1.000029] [G loss: 1.000060]\n",
      "epoch:28 step:133365[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:28 step:133370[D loss: 1.000049] [G loss: 0.999914]\n",
      "epoch:28 step:133375[D loss: 0.999940] [G loss: 1.000088]\n",
      "epoch:28 step:133380[D loss: 1.000003] [G loss: 1.000049]\n",
      "epoch:28 step:133385[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:28 step:133390[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:28 step:133395[D loss: 0.999940] [G loss: 1.000071]\n",
      "epoch:28 step:133400[D loss: 0.999982] [G loss: 1.000066]\n",
      "epoch:28 step:133405[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:28 step:133410[D loss: 1.000050] [G loss: 0.999929]\n",
      "epoch:28 step:133415[D loss: 1.000053] [G loss: 1.000099]\n",
      "epoch:28 step:133420[D loss: 1.000023] [G loss: 1.000037]\n",
      "epoch:28 step:133425[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:28 step:133430[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:28 step:133435[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:28 step:133440[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:28 step:133445[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:28 step:133450[D loss: 0.999998] [G loss: 1.000033]\n",
      "epoch:28 step:133455[D loss: 0.999979] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:133460[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:28 step:133465[D loss: 0.999972] [G loss: 1.000105]\n",
      "epoch:28 step:133470[D loss: 1.000025] [G loss: 1.000124]\n",
      "epoch:28 step:133475[D loss: 1.000160] [G loss: 1.000130]\n",
      "epoch:28 step:133480[D loss: 0.999890] [G loss: 1.000180]\n",
      "epoch:28 step:133485[D loss: 0.999905] [G loss: 1.000148]\n",
      "epoch:28 step:133490[D loss: 0.999949] [G loss: 1.000073]\n",
      "epoch:28 step:133495[D loss: 0.999937] [G loss: 1.000075]\n",
      "epoch:28 step:133500[D loss: 0.999962] [G loss: 1.000112]\n",
      "epoch:28 step:133505[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:28 step:133510[D loss: 0.999971] [G loss: 1.000034]\n",
      "epoch:28 step:133515[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:28 step:133520[D loss: 1.000133] [G loss: 0.999942]\n",
      "epoch:28 step:133525[D loss: 1.000065] [G loss: 1.000131]\n",
      "epoch:28 step:133530[D loss: 0.999912] [G loss: 1.000138]\n",
      "epoch:28 step:133535[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:28 step:133540[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:28 step:133545[D loss: 1.000004] [G loss: 0.999992]\n",
      "epoch:28 step:133550[D loss: 1.000044] [G loss: 0.999939]\n",
      "epoch:28 step:133555[D loss: 1.000010] [G loss: 0.999964]\n",
      "epoch:28 step:133560[D loss: 0.999942] [G loss: 1.000079]\n",
      "epoch:28 step:133565[D loss: 0.999970] [G loss: 1.000052]\n",
      "epoch:28 step:133570[D loss: 0.999944] [G loss: 1.000140]\n",
      "epoch:28 step:133575[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:28 step:133580[D loss: 0.999934] [G loss: 1.000134]\n",
      "epoch:28 step:133585[D loss: 0.999959] [G loss: 1.000107]\n",
      "epoch:28 step:133590[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:28 step:133595[D loss: 1.000010] [G loss: 0.999996]\n",
      "epoch:28 step:133600[D loss: 1.000078] [G loss: 0.999931]\n",
      "epoch:28 step:133605[D loss: 1.000121] [G loss: 0.999978]\n",
      "epoch:28 step:133610[D loss: 0.999926] [G loss: 1.000121]\n",
      "epoch:28 step:133615[D loss: 0.999946] [G loss: 1.000191]\n",
      "epoch:28 step:133620[D loss: 0.999999] [G loss: 1.000168]\n",
      "epoch:28 step:133625[D loss: 0.999943] [G loss: 1.000233]\n",
      "epoch:28 step:133630[D loss: 0.999945] [G loss: 1.000306]\n",
      "epoch:28 step:133635[D loss: 0.999930] [G loss: 1.000079]\n",
      "epoch:28 step:133640[D loss: 0.999993] [G loss: 1.000109]\n",
      "epoch:28 step:133645[D loss: 0.999979] [G loss: 1.000163]\n",
      "epoch:28 step:133650[D loss: 0.999972] [G loss: 1.000181]\n",
      "epoch:28 step:133655[D loss: 0.999972] [G loss: 1.000060]\n",
      "epoch:28 step:133660[D loss: 1.000052] [G loss: 1.000107]\n",
      "epoch:28 step:133665[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:28 step:133670[D loss: 0.999990] [G loss: 1.000044]\n",
      "epoch:28 step:133675[D loss: 1.000025] [G loss: 1.000003]\n",
      "epoch:28 step:133680[D loss: 1.000191] [G loss: 0.999769]\n",
      "epoch:28 step:133685[D loss: 0.999821] [G loss: 1.000034]\n",
      "epoch:28 step:133690[D loss: 0.999894] [G loss: 1.000117]\n",
      "epoch:28 step:133695[D loss: 1.000022] [G loss: 0.999967]\n",
      "epoch:28 step:133700[D loss: 0.999997] [G loss: 1.000096]\n",
      "epoch:28 step:133705[D loss: 0.999874] [G loss: 1.000223]\n",
      "epoch:28 step:133710[D loss: 0.999962] [G loss: 1.000010]\n",
      "epoch:28 step:133715[D loss: 0.999971] [G loss: 1.000100]\n",
      "epoch:28 step:133720[D loss: 0.999926] [G loss: 1.000179]\n",
      "epoch:28 step:133725[D loss: 0.999958] [G loss: 1.000118]\n",
      "epoch:28 step:133730[D loss: 0.999981] [G loss: 1.000267]\n",
      "epoch:28 step:133735[D loss: 0.999976] [G loss: 1.000136]\n",
      "epoch:28 step:133740[D loss: 0.999920] [G loss: 1.000132]\n",
      "epoch:28 step:133745[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:28 step:133750[D loss: 1.000014] [G loss: 0.999965]\n",
      "epoch:28 step:133755[D loss: 0.999934] [G loss: 1.000078]\n",
      "epoch:28 step:133760[D loss: 1.000023] [G loss: 0.999963]\n",
      "epoch:28 step:133765[D loss: 1.000072] [G loss: 1.000085]\n",
      "epoch:28 step:133770[D loss: 0.999982] [G loss: 0.999994]\n",
      "epoch:28 step:133775[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:28 step:133780[D loss: 0.999949] [G loss: 1.000202]\n",
      "epoch:28 step:133785[D loss: 0.999866] [G loss: 1.000220]\n",
      "epoch:28 step:133790[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:28 step:133795[D loss: 0.999957] [G loss: 1.000076]\n",
      "epoch:28 step:133800[D loss: 0.999998] [G loss: 1.000136]\n",
      "epoch:28 step:133805[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:28 step:133810[D loss: 1.000031] [G loss: 0.999921]\n",
      "epoch:28 step:133815[D loss: 0.999993] [G loss: 0.999946]\n",
      "epoch:28 step:133820[D loss: 0.999960] [G loss: 1.000015]\n",
      "epoch:28 step:133825[D loss: 0.999907] [G loss: 1.000100]\n",
      "epoch:28 step:133830[D loss: 0.999911] [G loss: 1.000054]\n",
      "epoch:28 step:133835[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:28 step:133840[D loss: 0.999963] [G loss: 1.000029]\n",
      "epoch:28 step:133845[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:28 step:133850[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:28 step:133855[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:28 step:133860[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:28 step:133865[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:28 step:133870[D loss: 1.000016] [G loss: 0.999979]\n",
      "epoch:28 step:133875[D loss: 1.000101] [G loss: 0.999880]\n",
      "epoch:28 step:133880[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:28 step:133885[D loss: 0.999959] [G loss: 1.000076]\n",
      "epoch:28 step:133890[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:28 step:133895[D loss: 1.000113] [G loss: 0.999912]\n",
      "epoch:28 step:133900[D loss: 1.000009] [G loss: 1.000008]\n",
      "epoch:28 step:133905[D loss: 0.999936] [G loss: 1.000149]\n",
      "epoch:28 step:133910[D loss: 0.999995] [G loss: 1.000078]\n",
      "epoch:28 step:133915[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:28 step:133920[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:28 step:133925[D loss: 0.999986] [G loss: 1.000021]\n",
      "epoch:28 step:133930[D loss: 1.000013] [G loss: 1.000042]\n",
      "epoch:28 step:133935[D loss: 1.000003] [G loss: 1.000047]\n",
      "epoch:28 step:133940[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:28 step:133945[D loss: 1.000005] [G loss: 0.999990]\n",
      "epoch:28 step:133950[D loss: 0.999951] [G loss: 1.000030]\n",
      "epoch:28 step:133955[D loss: 0.999977] [G loss: 1.000049]\n",
      "epoch:28 step:133960[D loss: 0.999955] [G loss: 1.000065]\n",
      "epoch:28 step:133965[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:28 step:133970[D loss: 1.000003] [G loss: 1.000023]\n",
      "epoch:28 step:133975[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:28 step:133980[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:28 step:133985[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:28 step:133990[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:28 step:133995[D loss: 1.000018] [G loss: 0.999997]\n",
      "epoch:28 step:134000[D loss: 0.999958] [G loss: 1.000066]\n",
      "epoch:28 step:134005[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:28 step:134010[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:28 step:134015[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:28 step:134020[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:28 step:134025[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:28 step:134030[D loss: 0.999976] [G loss: 1.000028]\n",
      "epoch:28 step:134035[D loss: 0.999995] [G loss: 1.000014]\n",
      "epoch:28 step:134040[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:28 step:134045[D loss: 1.000016] [G loss: 1.000036]\n",
      "epoch:28 step:134050[D loss: 0.999986] [G loss: 1.000007]\n",
      "epoch:28 step:134055[D loss: 1.000067] [G loss: 0.999989]\n",
      "epoch:28 step:134060[D loss: 0.999961] [G loss: 1.000094]\n",
      "epoch:28 step:134065[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:28 step:134070[D loss: 0.999938] [G loss: 1.000056]\n",
      "epoch:28 step:134075[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:28 step:134080[D loss: 0.999984] [G loss: 1.000014]\n",
      "epoch:28 step:134085[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:28 step:134090[D loss: 0.999976] [G loss: 1.000079]\n",
      "epoch:28 step:134095[D loss: 0.999928] [G loss: 1.000138]\n",
      "epoch:28 step:134100[D loss: 0.999955] [G loss: 1.000050]\n",
      "epoch:28 step:134105[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:28 step:134110[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:28 step:134115[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:28 step:134120[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:28 step:134125[D loss: 0.999991] [G loss: 1.000130]\n",
      "epoch:28 step:134130[D loss: 0.999964] [G loss: 1.000047]\n",
      "epoch:28 step:134135[D loss: 0.999987] [G loss: 1.000050]\n",
      "epoch:28 step:134140[D loss: 1.000063] [G loss: 0.999940]\n",
      "epoch:28 step:134145[D loss: 1.000124] [G loss: 0.999915]\n",
      "epoch:28 step:134150[D loss: 0.999979] [G loss: 1.000072]\n",
      "epoch:28 step:134155[D loss: 1.000060] [G loss: 1.000119]\n",
      "epoch:28 step:134160[D loss: 0.999976] [G loss: 1.000135]\n",
      "epoch:28 step:134165[D loss: 0.999959] [G loss: 1.000091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:134170[D loss: 0.999945] [G loss: 1.000081]\n",
      "epoch:28 step:134175[D loss: 0.999950] [G loss: 1.000084]\n",
      "epoch:28 step:134180[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:28 step:134185[D loss: 1.000027] [G loss: 0.999982]\n",
      "epoch:28 step:134190[D loss: 1.000029] [G loss: 0.999947]\n",
      "epoch:28 step:134195[D loss: 0.999970] [G loss: 1.000000]\n",
      "epoch:28 step:134200[D loss: 0.999978] [G loss: 1.000041]\n",
      "epoch:28 step:134205[D loss: 0.999962] [G loss: 1.000051]\n",
      "epoch:28 step:134210[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:28 step:134215[D loss: 1.000144] [G loss: 0.999823]\n",
      "epoch:28 step:134220[D loss: 1.000045] [G loss: 0.999929]\n",
      "epoch:28 step:134225[D loss: 1.000021] [G loss: 1.000168]\n",
      "epoch:28 step:134230[D loss: 0.999901] [G loss: 1.000159]\n",
      "epoch:28 step:134235[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:28 step:134240[D loss: 1.000014] [G loss: 1.000004]\n",
      "epoch:28 step:134245[D loss: 1.000022] [G loss: 0.999963]\n",
      "epoch:28 step:134250[D loss: 1.000010] [G loss: 1.000025]\n",
      "epoch:28 step:134255[D loss: 0.999942] [G loss: 1.000021]\n",
      "epoch:28 step:134260[D loss: 0.999945] [G loss: 1.000059]\n",
      "epoch:28 step:134265[D loss: 1.000115] [G loss: 1.000001]\n",
      "epoch:28 step:134270[D loss: 1.000033] [G loss: 0.999974]\n",
      "epoch:28 step:134275[D loss: 0.999922] [G loss: 1.000009]\n",
      "epoch:28 step:134280[D loss: 1.000014] [G loss: 1.000134]\n",
      "epoch:28 step:134285[D loss: 0.999913] [G loss: 1.000121]\n",
      "epoch:28 step:134290[D loss: 0.999966] [G loss: 1.000127]\n",
      "epoch:28 step:134295[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:28 step:134300[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:28 step:134305[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:28 step:134310[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:28 step:134315[D loss: 1.000050] [G loss: 0.999962]\n",
      "epoch:28 step:134320[D loss: 0.999943] [G loss: 1.000020]\n",
      "epoch:28 step:134325[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:28 step:134330[D loss: 1.000003] [G loss: 1.000128]\n",
      "epoch:28 step:134335[D loss: 0.999865] [G loss: 1.000218]\n",
      "epoch:28 step:134340[D loss: 1.000013] [G loss: 1.000123]\n",
      "epoch:28 step:134345[D loss: 0.999977] [G loss: 1.000121]\n",
      "epoch:28 step:134350[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:28 step:134355[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:28 step:134360[D loss: 1.000041] [G loss: 0.999898]\n",
      "epoch:28 step:134365[D loss: 1.000180] [G loss: 0.999824]\n",
      "epoch:28 step:134370[D loss: 0.999878] [G loss: 1.000019]\n",
      "epoch:28 step:134375[D loss: 0.999930] [G loss: 0.999990]\n",
      "epoch:28 step:134380[D loss: 1.000131] [G loss: 1.000116]\n",
      "epoch:28 step:134385[D loss: 1.000045] [G loss: 1.000017]\n",
      "epoch:28 step:134390[D loss: 0.999815] [G loss: 1.000259]\n",
      "epoch:28 step:134395[D loss: 0.999867] [G loss: 1.000135]\n",
      "epoch:28 step:134400[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:28 step:134405[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:28 step:134410[D loss: 0.999991] [G loss: 1.000067]\n",
      "epoch:28 step:134415[D loss: 1.000007] [G loss: 0.999965]\n",
      "epoch:28 step:134420[D loss: 0.999978] [G loss: 1.000056]\n",
      "epoch:28 step:134425[D loss: 0.999973] [G loss: 1.000159]\n",
      "epoch:28 step:134430[D loss: 0.999923] [G loss: 1.000096]\n",
      "epoch:28 step:134435[D loss: 1.000027] [G loss: 1.000045]\n",
      "epoch:28 step:134440[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:28 step:134445[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:28 step:134450[D loss: 0.999922] [G loss: 1.000121]\n",
      "epoch:28 step:134455[D loss: 0.999970] [G loss: 1.000114]\n",
      "epoch:28 step:134460[D loss: 0.999972] [G loss: 1.000110]\n",
      "epoch:28 step:134465[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:28 step:134470[D loss: 0.999934] [G loss: 1.000109]\n",
      "epoch:28 step:134475[D loss: 0.999947] [G loss: 1.000102]\n",
      "epoch:28 step:134480[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:28 step:134485[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:28 step:134490[D loss: 0.999984] [G loss: 1.000101]\n",
      "epoch:28 step:134495[D loss: 0.999996] [G loss: 1.000050]\n",
      "epoch:28 step:134500[D loss: 0.999971] [G loss: 1.000062]\n",
      "epoch:28 step:134505[D loss: 1.000048] [G loss: 0.999970]\n",
      "epoch:28 step:134510[D loss: 1.000050] [G loss: 1.000045]\n",
      "epoch:28 step:134515[D loss: 0.999942] [G loss: 1.000058]\n",
      "epoch:28 step:134520[D loss: 0.999932] [G loss: 1.000107]\n",
      "epoch:28 step:134525[D loss: 0.999930] [G loss: 1.000099]\n",
      "epoch:28 step:134530[D loss: 0.999965] [G loss: 1.000083]\n",
      "epoch:28 step:134535[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:28 step:134540[D loss: 0.999979] [G loss: 1.000034]\n",
      "epoch:28 step:134545[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:28 step:134550[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:28 step:134555[D loss: 0.999995] [G loss: 1.000044]\n",
      "epoch:28 step:134560[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:28 step:134565[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:28 step:134570[D loss: 1.000034] [G loss: 0.999950]\n",
      "epoch:28 step:134575[D loss: 0.999999] [G loss: 1.000078]\n",
      "epoch:28 step:134580[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:28 step:134585[D loss: 0.999944] [G loss: 1.000098]\n",
      "epoch:28 step:134590[D loss: 1.000006] [G loss: 1.000067]\n",
      "epoch:28 step:134595[D loss: 1.000015] [G loss: 0.999942]\n",
      "epoch:28 step:134600[D loss: 0.999939] [G loss: 1.000082]\n",
      "epoch:28 step:134605[D loss: 1.000049] [G loss: 0.999917]\n",
      "epoch:28 step:134610[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:28 step:134615[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:28 step:134620[D loss: 0.999956] [G loss: 1.000073]\n",
      "epoch:28 step:134625[D loss: 1.000079] [G loss: 0.999897]\n",
      "epoch:28 step:134630[D loss: 0.999920] [G loss: 1.000094]\n",
      "epoch:28 step:134635[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:28 step:134640[D loss: 0.999974] [G loss: 1.000105]\n",
      "epoch:28 step:134645[D loss: 1.000040] [G loss: 1.000056]\n",
      "epoch:28 step:134650[D loss: 1.000049] [G loss: 0.999962]\n",
      "epoch:28 step:134655[D loss: 0.999991] [G loss: 0.999983]\n",
      "epoch:28 step:134660[D loss: 0.999951] [G loss: 1.000094]\n",
      "epoch:28 step:134665[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:28 step:134670[D loss: 0.999958] [G loss: 1.000088]\n",
      "epoch:28 step:134675[D loss: 1.000038] [G loss: 1.000014]\n",
      "epoch:28 step:134680[D loss: 0.999940] [G loss: 1.000098]\n",
      "epoch:28 step:134685[D loss: 0.999989] [G loss: 1.000031]\n",
      "epoch:28 step:134690[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:28 step:134695[D loss: 1.000002] [G loss: 1.000035]\n",
      "epoch:28 step:134700[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:28 step:134705[D loss: 0.999997] [G loss: 1.000114]\n",
      "epoch:28 step:134710[D loss: 0.999894] [G loss: 1.000252]\n",
      "epoch:28 step:134715[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:28 step:134720[D loss: 0.999949] [G loss: 1.000120]\n",
      "epoch:28 step:134725[D loss: 1.000036] [G loss: 0.999973]\n",
      "epoch:28 step:134730[D loss: 1.000058] [G loss: 0.999961]\n",
      "epoch:28 step:134735[D loss: 0.999938] [G loss: 1.000113]\n",
      "epoch:28 step:134740[D loss: 0.999904] [G loss: 1.000139]\n",
      "epoch:28 step:134745[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:28 step:134750[D loss: 1.000127] [G loss: 1.000032]\n",
      "epoch:28 step:134755[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:28 step:134760[D loss: 0.999950] [G loss: 1.000015]\n",
      "epoch:28 step:134765[D loss: 1.000011] [G loss: 1.000029]\n",
      "epoch:28 step:134770[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:28 step:134775[D loss: 1.000047] [G loss: 0.999993]\n",
      "epoch:28 step:134780[D loss: 0.999966] [G loss: 0.999984]\n",
      "epoch:28 step:134785[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:28 step:134790[D loss: 0.999976] [G loss: 1.000136]\n",
      "epoch:28 step:134795[D loss: 1.000084] [G loss: 1.000049]\n",
      "epoch:28 step:134800[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:28 step:134805[D loss: 0.999935] [G loss: 1.000090]\n",
      "epoch:28 step:134810[D loss: 1.000061] [G loss: 0.999947]\n",
      "epoch:28 step:134815[D loss: 0.999946] [G loss: 1.000032]\n",
      "epoch:28 step:134820[D loss: 1.000024] [G loss: 1.000013]\n",
      "epoch:28 step:134825[D loss: 0.999930] [G loss: 1.000051]\n",
      "epoch:28 step:134830[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:28 step:134835[D loss: 1.000023] [G loss: 1.000031]\n",
      "epoch:28 step:134840[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:28 step:134845[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:28 step:134850[D loss: 0.999986] [G loss: 1.000065]\n",
      "epoch:28 step:134855[D loss: 0.999995] [G loss: 0.999980]\n",
      "epoch:28 step:134860[D loss: 0.999946] [G loss: 1.000079]\n",
      "epoch:28 step:134865[D loss: 0.999979] [G loss: 1.000187]\n",
      "epoch:28 step:134870[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:28 step:134875[D loss: 0.999964] [G loss: 1.000146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:134880[D loss: 0.999995] [G loss: 1.000084]\n",
      "epoch:28 step:134885[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:28 step:134890[D loss: 1.000139] [G loss: 0.999888]\n",
      "epoch:28 step:134895[D loss: 0.999861] [G loss: 1.000094]\n",
      "epoch:28 step:134900[D loss: 0.999908] [G loss: 1.000137]\n",
      "epoch:28 step:134905[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:28 step:134910[D loss: 0.999978] [G loss: 1.000097]\n",
      "epoch:28 step:134915[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:28 step:134920[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:28 step:134925[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:28 step:134930[D loss: 1.000023] [G loss: 1.000064]\n",
      "epoch:28 step:134935[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:28 step:134940[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:28 step:134945[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:28 step:134950[D loss: 0.999999] [G loss: 1.000144]\n",
      "epoch:28 step:134955[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:28 step:134960[D loss: 1.000017] [G loss: 0.999966]\n",
      "epoch:28 step:134965[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:28 step:134970[D loss: 0.999989] [G loss: 0.999969]\n",
      "epoch:28 step:134975[D loss: 0.999926] [G loss: 1.000089]\n",
      "epoch:28 step:134980[D loss: 1.000049] [G loss: 1.000001]\n",
      "epoch:28 step:134985[D loss: 1.000034] [G loss: 1.000037]\n",
      "epoch:28 step:134990[D loss: 1.000027] [G loss: 1.000212]\n",
      "epoch:28 step:134995[D loss: 0.999923] [G loss: 1.000145]\n",
      "epoch:28 step:135000[D loss: 0.999924] [G loss: 1.000146]\n",
      "epoch:28 step:135005[D loss: 0.999977] [G loss: 1.000026]\n",
      "epoch:28 step:135010[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:28 step:135015[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:28 step:135020[D loss: 0.999996] [G loss: 1.000019]\n",
      "epoch:28 step:135025[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:28 step:135030[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:28 step:135035[D loss: 1.000006] [G loss: 1.000004]\n",
      "epoch:28 step:135040[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:28 step:135045[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:28 step:135050[D loss: 1.000009] [G loss: 1.000137]\n",
      "epoch:28 step:135055[D loss: 0.999903] [G loss: 1.000083]\n",
      "epoch:28 step:135060[D loss: 0.999982] [G loss: 1.000104]\n",
      "epoch:28 step:135065[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:28 step:135070[D loss: 1.000061] [G loss: 0.999893]\n",
      "epoch:28 step:135075[D loss: 1.000027] [G loss: 1.000038]\n",
      "epoch:28 step:135080[D loss: 0.999973] [G loss: 1.000019]\n",
      "epoch:28 step:135085[D loss: 0.999962] [G loss: 1.000062]\n",
      "epoch:28 step:135090[D loss: 0.999970] [G loss: 1.000030]\n",
      "epoch:28 step:135095[D loss: 0.999933] [G loss: 1.000142]\n",
      "epoch:28 step:135100[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:28 step:135105[D loss: 0.999933] [G loss: 1.000112]\n",
      "epoch:28 step:135110[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:28 step:135115[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:28 step:135120[D loss: 1.000004] [G loss: 1.000040]\n",
      "epoch:28 step:135125[D loss: 0.999941] [G loss: 1.000206]\n",
      "epoch:28 step:135130[D loss: 0.999973] [G loss: 1.000063]\n",
      "epoch:28 step:135135[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:28 step:135140[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:28 step:135145[D loss: 0.999956] [G loss: 1.000113]\n",
      "epoch:28 step:135150[D loss: 1.000004] [G loss: 1.000005]\n",
      "epoch:28 step:135155[D loss: 0.999969] [G loss: 1.000129]\n",
      "epoch:28 step:135160[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:28 step:135165[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:28 step:135170[D loss: 0.999999] [G loss: 1.000070]\n",
      "epoch:28 step:135175[D loss: 1.000043] [G loss: 0.999960]\n",
      "epoch:28 step:135180[D loss: 0.999933] [G loss: 1.000064]\n",
      "epoch:28 step:135185[D loss: 1.000008] [G loss: 1.000000]\n",
      "epoch:28 step:135190[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:28 step:135195[D loss: 1.000033] [G loss: 0.999987]\n",
      "epoch:28 step:135200[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:28 step:135205[D loss: 1.000024] [G loss: 1.000010]\n",
      "epoch:28 step:135210[D loss: 0.999931] [G loss: 1.000091]\n",
      "epoch:28 step:135215[D loss: 0.999989] [G loss: 1.000091]\n",
      "epoch:28 step:135220[D loss: 1.000141] [G loss: 0.999912]\n",
      "epoch:28 step:135225[D loss: 0.999894] [G loss: 1.000139]\n",
      "epoch:28 step:135230[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:28 step:135235[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:28 step:135240[D loss: 0.999932] [G loss: 1.000125]\n",
      "epoch:28 step:135245[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:28 step:135250[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:28 step:135255[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:28 step:135260[D loss: 1.000001] [G loss: 1.000036]\n",
      "epoch:28 step:135265[D loss: 0.999979] [G loss: 1.000065]\n",
      "epoch:28 step:135270[D loss: 1.000019] [G loss: 1.000088]\n",
      "epoch:28 step:135275[D loss: 0.999960] [G loss: 1.000028]\n",
      "epoch:28 step:135280[D loss: 0.999993] [G loss: 1.000058]\n",
      "epoch:28 step:135285[D loss: 1.000033] [G loss: 0.999960]\n",
      "epoch:28 step:135290[D loss: 1.000006] [G loss: 1.000009]\n",
      "epoch:28 step:135295[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:28 step:135300[D loss: 0.999970] [G loss: 1.000044]\n",
      "epoch:28 step:135305[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:28 step:135310[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:28 step:135315[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:28 step:135320[D loss: 0.999983] [G loss: 1.000022]\n",
      "epoch:28 step:135325[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:28 step:135330[D loss: 0.999976] [G loss: 1.000127]\n",
      "epoch:28 step:135335[D loss: 1.000037] [G loss: 0.999967]\n",
      "epoch:28 step:135340[D loss: 1.000130] [G loss: 0.999939]\n",
      "epoch:28 step:135345[D loss: 0.999953] [G loss: 1.000051]\n",
      "epoch:28 step:135350[D loss: 1.000093] [G loss: 1.000002]\n",
      "epoch:28 step:135355[D loss: 0.999921] [G loss: 1.000138]\n",
      "epoch:28 step:135360[D loss: 0.999984] [G loss: 1.000035]\n",
      "epoch:28 step:135365[D loss: 0.999928] [G loss: 1.000126]\n",
      "epoch:28 step:135370[D loss: 0.999992] [G loss: 0.999996]\n",
      "epoch:28 step:135375[D loss: 0.999928] [G loss: 1.000081]\n",
      "epoch:28 step:135380[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:28 step:135385[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:28 step:135390[D loss: 0.999975] [G loss: 1.000098]\n",
      "epoch:28 step:135395[D loss: 0.999954] [G loss: 1.000124]\n",
      "epoch:28 step:135400[D loss: 1.000035] [G loss: 1.000070]\n",
      "epoch:28 step:135405[D loss: 0.999988] [G loss: 1.000035]\n",
      "epoch:28 step:135410[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:28 step:135415[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:28 step:135420[D loss: 0.999978] [G loss: 1.000061]\n",
      "epoch:28 step:135425[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:28 step:135430[D loss: 0.999989] [G loss: 1.000064]\n",
      "epoch:28 step:135435[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:28 step:135440[D loss: 0.999987] [G loss: 1.000033]\n",
      "epoch:28 step:135445[D loss: 1.000007] [G loss: 0.999970]\n",
      "epoch:28 step:135450[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:28 step:135455[D loss: 0.999953] [G loss: 1.000044]\n",
      "epoch:28 step:135460[D loss: 1.000005] [G loss: 1.000098]\n",
      "epoch:28 step:135465[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:28 step:135470[D loss: 0.999960] [G loss: 1.000097]\n",
      "epoch:28 step:135475[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:28 step:135480[D loss: 0.999968] [G loss: 1.000039]\n",
      "epoch:28 step:135485[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:28 step:135490[D loss: 0.999989] [G loss: 1.000014]\n",
      "epoch:28 step:135495[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:28 step:135500[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:28 step:135505[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:28 step:135510[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:28 step:135515[D loss: 0.999967] [G loss: 1.000139]\n",
      "epoch:28 step:135520[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:28 step:135525[D loss: 0.999982] [G loss: 1.000062]\n",
      "epoch:28 step:135530[D loss: 1.000040] [G loss: 1.000060]\n",
      "epoch:28 step:135535[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:28 step:135540[D loss: 1.000011] [G loss: 1.000006]\n",
      "epoch:28 step:135545[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:28 step:135550[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:28 step:135555[D loss: 1.000028] [G loss: 0.999958]\n",
      "epoch:28 step:135560[D loss: 0.999922] [G loss: 1.000166]\n",
      "epoch:28 step:135565[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:28 step:135570[D loss: 0.999980] [G loss: 1.000058]\n",
      "epoch:28 step:135575[D loss: 0.999981] [G loss: 1.000062]\n",
      "epoch:28 step:135580[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:28 step:135585[D loss: 0.999959] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:135590[D loss: 0.999930] [G loss: 1.000107]\n",
      "epoch:28 step:135595[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:28 step:135600[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:28 step:135605[D loss: 1.000035] [G loss: 1.000067]\n",
      "epoch:28 step:135610[D loss: 0.999869] [G loss: 1.000224]\n",
      "epoch:28 step:135615[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:28 step:135620[D loss: 0.999979] [G loss: 1.000061]\n",
      "epoch:28 step:135625[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:28 step:135630[D loss: 1.000000] [G loss: 1.000009]\n",
      "epoch:28 step:135635[D loss: 1.000005] [G loss: 1.000032]\n",
      "epoch:28 step:135640[D loss: 0.999996] [G loss: 0.999971]\n",
      "epoch:28 step:135645[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:28 step:135650[D loss: 0.999994] [G loss: 1.000015]\n",
      "epoch:28 step:135655[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:28 step:135660[D loss: 1.000008] [G loss: 1.000033]\n",
      "epoch:28 step:135665[D loss: 1.000020] [G loss: 0.999975]\n",
      "epoch:28 step:135670[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:28 step:135675[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:28 step:135680[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:28 step:135685[D loss: 1.000010] [G loss: 1.000059]\n",
      "epoch:28 step:135690[D loss: 0.999984] [G loss: 0.999976]\n",
      "epoch:28 step:135695[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:28 step:135700[D loss: 1.000013] [G loss: 1.000083]\n",
      "epoch:28 step:135705[D loss: 1.000082] [G loss: 0.999870]\n",
      "epoch:28 step:135710[D loss: 0.999981] [G loss: 1.000154]\n",
      "epoch:28 step:135715[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:28 step:135720[D loss: 1.000060] [G loss: 0.999958]\n",
      "epoch:28 step:135725[D loss: 0.999994] [G loss: 0.999967]\n",
      "epoch:28 step:135730[D loss: 1.000021] [G loss: 0.999934]\n",
      "epoch:28 step:135735[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:28 step:135740[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:28 step:135745[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:28 step:135750[D loss: 0.999969] [G loss: 1.000064]\n",
      "epoch:28 step:135755[D loss: 0.999992] [G loss: 1.000050]\n",
      "epoch:28 step:135760[D loss: 0.999988] [G loss: 1.000001]\n",
      "epoch:28 step:135765[D loss: 1.000200] [G loss: 0.999781]\n",
      "epoch:28 step:135770[D loss: 0.999855] [G loss: 1.000137]\n",
      "epoch:28 step:135775[D loss: 1.000008] [G loss: 1.000005]\n",
      "epoch:28 step:135780[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:28 step:135785[D loss: 0.999951] [G loss: 1.000155]\n",
      "epoch:28 step:135790[D loss: 0.999978] [G loss: 1.000013]\n",
      "epoch:28 step:135795[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:28 step:135800[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:28 step:135805[D loss: 0.999970] [G loss: 1.000060]\n",
      "epoch:28 step:135810[D loss: 1.000032] [G loss: 0.999990]\n",
      "epoch:28 step:135815[D loss: 0.999943] [G loss: 1.000101]\n",
      "epoch:28 step:135820[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:28 step:135825[D loss: 0.999946] [G loss: 1.000064]\n",
      "epoch:28 step:135830[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:28 step:135835[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:28 step:135840[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:28 step:135845[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:28 step:135850[D loss: 0.999972] [G loss: 1.000050]\n",
      "epoch:28 step:135855[D loss: 1.000075] [G loss: 1.000012]\n",
      "epoch:28 step:135860[D loss: 0.999952] [G loss: 1.000101]\n",
      "epoch:28 step:135865[D loss: 0.999978] [G loss: 1.000055]\n",
      "epoch:29 step:135870[D loss: 1.000048] [G loss: 0.999935]\n",
      "epoch:29 step:135875[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:29 step:135880[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:29 step:135885[D loss: 1.000072] [G loss: 0.999959]\n",
      "epoch:29 step:135890[D loss: 0.999903] [G loss: 1.000145]\n",
      "epoch:29 step:135895[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:29 step:135900[D loss: 1.000011] [G loss: 0.999919]\n",
      "epoch:29 step:135905[D loss: 1.000061] [G loss: 0.999809]\n",
      "epoch:29 step:135910[D loss: 1.000069] [G loss: 0.999959]\n",
      "epoch:29 step:135915[D loss: 0.999986] [G loss: 1.000170]\n",
      "epoch:29 step:135920[D loss: 1.000070] [G loss: 0.999884]\n",
      "epoch:29 step:135925[D loss: 0.999909] [G loss: 1.000111]\n",
      "epoch:29 step:135930[D loss: 0.999939] [G loss: 1.000079]\n",
      "epoch:29 step:135935[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:29 step:135940[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:29 step:135945[D loss: 0.999969] [G loss: 1.000082]\n",
      "epoch:29 step:135950[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:29 step:135955[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:29 step:135960[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:29 step:135965[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:29 step:135970[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:29 step:135975[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:29 step:135980[D loss: 0.999987] [G loss: 1.000060]\n",
      "epoch:29 step:135985[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:29 step:135990[D loss: 0.999974] [G loss: 1.000071]\n",
      "epoch:29 step:135995[D loss: 0.999991] [G loss: 1.000078]\n",
      "epoch:29 step:136000[D loss: 1.000008] [G loss: 1.000091]\n",
      "epoch:29 step:136005[D loss: 0.999958] [G loss: 1.000084]\n",
      "epoch:29 step:136010[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:29 step:136015[D loss: 1.000021] [G loss: 1.000028]\n",
      "epoch:29 step:136020[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:29 step:136025[D loss: 0.999994] [G loss: 1.000023]\n",
      "epoch:29 step:136030[D loss: 0.999977] [G loss: 1.000071]\n",
      "epoch:29 step:136035[D loss: 1.000018] [G loss: 1.000075]\n",
      "epoch:29 step:136040[D loss: 0.999902] [G loss: 1.000131]\n",
      "epoch:29 step:136045[D loss: 1.000004] [G loss: 1.000110]\n",
      "epoch:29 step:136050[D loss: 0.999955] [G loss: 1.000130]\n",
      "epoch:29 step:136055[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:29 step:136060[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:29 step:136065[D loss: 1.000026] [G loss: 0.999922]\n",
      "epoch:29 step:136070[D loss: 1.000029] [G loss: 0.999985]\n",
      "epoch:29 step:136075[D loss: 0.999960] [G loss: 1.000013]\n",
      "epoch:29 step:136080[D loss: 1.000026] [G loss: 0.999931]\n",
      "epoch:29 step:136085[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:29 step:136090[D loss: 1.000032] [G loss: 0.999935]\n",
      "epoch:29 step:136095[D loss: 0.999996] [G loss: 1.000047]\n",
      "epoch:29 step:136100[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:29 step:136105[D loss: 0.999951] [G loss: 1.000127]\n",
      "epoch:29 step:136110[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:29 step:136115[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:29 step:136120[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:29 step:136125[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:29 step:136130[D loss: 1.000033] [G loss: 1.000047]\n",
      "epoch:29 step:136135[D loss: 0.999990] [G loss: 1.000094]\n",
      "epoch:29 step:136140[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:29 step:136145[D loss: 0.999972] [G loss: 1.000093]\n",
      "epoch:29 step:136150[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:29 step:136155[D loss: 0.999960] [G loss: 1.000081]\n",
      "epoch:29 step:136160[D loss: 0.999974] [G loss: 1.000063]\n",
      "epoch:29 step:136165[D loss: 0.999969] [G loss: 1.000069]\n",
      "epoch:29 step:136170[D loss: 0.999971] [G loss: 1.000014]\n",
      "epoch:29 step:136175[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:29 step:136180[D loss: 1.000014] [G loss: 1.000035]\n",
      "epoch:29 step:136185[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:29 step:136190[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:29 step:136195[D loss: 0.999985] [G loss: 1.000135]\n",
      "epoch:29 step:136200[D loss: 0.999948] [G loss: 1.000098]\n",
      "epoch:29 step:136205[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:29 step:136210[D loss: 1.000019] [G loss: 1.000062]\n",
      "epoch:29 step:136215[D loss: 1.000059] [G loss: 0.999924]\n",
      "epoch:29 step:136220[D loss: 1.000015] [G loss: 0.999990]\n",
      "epoch:29 step:136225[D loss: 0.999989] [G loss: 1.000099]\n",
      "epoch:29 step:136230[D loss: 0.999957] [G loss: 1.000062]\n",
      "epoch:29 step:136235[D loss: 1.000033] [G loss: 0.999942]\n",
      "epoch:29 step:136240[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:29 step:136245[D loss: 0.999956] [G loss: 0.999983]\n",
      "epoch:29 step:136250[D loss: 0.999938] [G loss: 1.000110]\n",
      "epoch:29 step:136255[D loss: 0.999958] [G loss: 1.000126]\n",
      "epoch:29 step:136260[D loss: 1.000010] [G loss: 1.000083]\n",
      "epoch:29 step:136265[D loss: 1.000012] [G loss: 0.999985]\n",
      "epoch:29 step:136270[D loss: 0.999970] [G loss: 1.000117]\n",
      "epoch:29 step:136275[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:29 step:136280[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:29 step:136285[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:29 step:136290[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:29 step:136295[D loss: 0.999955] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:136300[D loss: 0.999901] [G loss: 1.000138]\n",
      "epoch:29 step:136305[D loss: 0.999991] [G loss: 1.000010]\n",
      "epoch:29 step:136310[D loss: 1.000029] [G loss: 1.000122]\n",
      "epoch:29 step:136315[D loss: 0.999942] [G loss: 1.000059]\n",
      "epoch:29 step:136320[D loss: 0.999949] [G loss: 1.000082]\n",
      "epoch:29 step:136325[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:29 step:136330[D loss: 1.000002] [G loss: 0.999992]\n",
      "epoch:29 step:136335[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:29 step:136340[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:29 step:136345[D loss: 0.999963] [G loss: 1.000150]\n",
      "epoch:29 step:136350[D loss: 0.999969] [G loss: 1.000199]\n",
      "epoch:29 step:136355[D loss: 1.000053] [G loss: 1.000014]\n",
      "epoch:29 step:136360[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:29 step:136365[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:29 step:136370[D loss: 0.999946] [G loss: 1.000126]\n",
      "epoch:29 step:136375[D loss: 0.999984] [G loss: 0.999930]\n",
      "epoch:29 step:136380[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:29 step:136385[D loss: 1.000089] [G loss: 0.999824]\n",
      "epoch:29 step:136390[D loss: 1.000112] [G loss: 0.999834]\n",
      "epoch:29 step:136395[D loss: 0.999892] [G loss: 1.000175]\n",
      "epoch:29 step:136400[D loss: 0.999955] [G loss: 1.000206]\n",
      "epoch:29 step:136405[D loss: 1.000051] [G loss: 1.000009]\n",
      "epoch:29 step:136410[D loss: 0.999917] [G loss: 1.000118]\n",
      "epoch:29 step:136415[D loss: 0.999945] [G loss: 1.000136]\n",
      "epoch:29 step:136420[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:29 step:136425[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:29 step:136430[D loss: 0.999977] [G loss: 1.000090]\n",
      "epoch:29 step:136435[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:29 step:136440[D loss: 0.999986] [G loss: 1.000069]\n",
      "epoch:29 step:136445[D loss: 0.999987] [G loss: 1.000071]\n",
      "epoch:29 step:136450[D loss: 1.000084] [G loss: 0.999950]\n",
      "epoch:29 step:136455[D loss: 1.000083] [G loss: 0.999981]\n",
      "epoch:29 step:136460[D loss: 1.000066] [G loss: 1.000046]\n",
      "epoch:29 step:136465[D loss: 0.999900] [G loss: 1.000140]\n",
      "epoch:29 step:136470[D loss: 0.999910] [G loss: 1.000159]\n",
      "epoch:29 step:136475[D loss: 0.999917] [G loss: 1.000135]\n",
      "epoch:29 step:136480[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:29 step:136485[D loss: 1.000029] [G loss: 0.999967]\n",
      "epoch:29 step:136490[D loss: 1.000060] [G loss: 0.999921]\n",
      "epoch:29 step:136495[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:29 step:136500[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:29 step:136505[D loss: 0.999980] [G loss: 1.000064]\n",
      "epoch:29 step:136510[D loss: 0.999997] [G loss: 1.000090]\n",
      "epoch:29 step:136515[D loss: 0.999927] [G loss: 1.000095]\n",
      "epoch:29 step:136520[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:29 step:136525[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:29 step:136530[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:29 step:136535[D loss: 0.999967] [G loss: 1.000066]\n",
      "epoch:29 step:136540[D loss: 1.000000] [G loss: 1.000030]\n",
      "epoch:29 step:136545[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:29 step:136550[D loss: 0.999971] [G loss: 1.000005]\n",
      "epoch:29 step:136555[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:29 step:136560[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:29 step:136565[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:29 step:136570[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:29 step:136575[D loss: 1.000008] [G loss: 0.999982]\n",
      "epoch:29 step:136580[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:29 step:136585[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:29 step:136590[D loss: 0.999992] [G loss: 1.000047]\n",
      "epoch:29 step:136595[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:29 step:136600[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:29 step:136605[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:29 step:136610[D loss: 0.999992] [G loss: 1.000029]\n",
      "epoch:29 step:136615[D loss: 0.999994] [G loss: 1.000073]\n",
      "epoch:29 step:136620[D loss: 0.999957] [G loss: 1.000096]\n",
      "epoch:29 step:136625[D loss: 0.999976] [G loss: 1.000034]\n",
      "epoch:29 step:136630[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:29 step:136635[D loss: 1.000000] [G loss: 1.000078]\n",
      "epoch:29 step:136640[D loss: 0.999878] [G loss: 1.000246]\n",
      "epoch:29 step:136645[D loss: 0.999999] [G loss: 1.000078]\n",
      "epoch:29 step:136650[D loss: 1.000016] [G loss: 0.999977]\n",
      "epoch:29 step:136655[D loss: 0.999931] [G loss: 1.000148]\n",
      "epoch:29 step:136660[D loss: 0.999980] [G loss: 1.000051]\n",
      "epoch:29 step:136665[D loss: 0.999997] [G loss: 1.000085]\n",
      "epoch:29 step:136670[D loss: 1.000003] [G loss: 1.000104]\n",
      "epoch:29 step:136675[D loss: 0.999940] [G loss: 1.000188]\n",
      "epoch:29 step:136680[D loss: 0.999925] [G loss: 1.000154]\n",
      "epoch:29 step:136685[D loss: 0.999948] [G loss: 1.000096]\n",
      "epoch:29 step:136690[D loss: 1.000017] [G loss: 0.999993]\n",
      "epoch:29 step:136695[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:29 step:136700[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:29 step:136705[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:29 step:136710[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:29 step:136715[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:29 step:136720[D loss: 0.999951] [G loss: 1.000107]\n",
      "epoch:29 step:136725[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:29 step:136730[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:29 step:136735[D loss: 0.999995] [G loss: 1.000050]\n",
      "epoch:29 step:136740[D loss: 0.999959] [G loss: 1.000104]\n",
      "epoch:29 step:136745[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:29 step:136750[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:29 step:136755[D loss: 1.000012] [G loss: 1.000065]\n",
      "epoch:29 step:136760[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:29 step:136765[D loss: 0.999947] [G loss: 1.000086]\n",
      "epoch:29 step:136770[D loss: 0.999987] [G loss: 1.000106]\n",
      "epoch:29 step:136775[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:29 step:136780[D loss: 0.999968] [G loss: 1.000106]\n",
      "epoch:29 step:136785[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:29 step:136790[D loss: 1.000022] [G loss: 1.000010]\n",
      "epoch:29 step:136795[D loss: 1.000014] [G loss: 0.999937]\n",
      "epoch:29 step:136800[D loss: 0.999916] [G loss: 1.000131]\n",
      "epoch:29 step:136805[D loss: 1.000029] [G loss: 1.000054]\n",
      "epoch:29 step:136810[D loss: 0.999971] [G loss: 1.000083]\n",
      "epoch:29 step:136815[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:29 step:136820[D loss: 0.999999] [G loss: 1.000032]\n",
      "epoch:29 step:136825[D loss: 0.999961] [G loss: 1.000051]\n",
      "epoch:29 step:136830[D loss: 1.000017] [G loss: 1.000037]\n",
      "epoch:29 step:136835[D loss: 1.000056] [G loss: 1.000032]\n",
      "epoch:29 step:136840[D loss: 1.000002] [G loss: 1.000080]\n",
      "epoch:29 step:136845[D loss: 0.999958] [G loss: 1.000110]\n",
      "epoch:29 step:136850[D loss: 1.000031] [G loss: 1.000089]\n",
      "epoch:29 step:136855[D loss: 1.000099] [G loss: 0.999962]\n",
      "epoch:29 step:136860[D loss: 0.999959] [G loss: 1.000181]\n",
      "epoch:29 step:136865[D loss: 1.000058] [G loss: 1.000144]\n",
      "epoch:29 step:136870[D loss: 0.999999] [G loss: 1.000144]\n",
      "epoch:29 step:136875[D loss: 0.999998] [G loss: 1.000120]\n",
      "epoch:29 step:136880[D loss: 0.999977] [G loss: 1.000120]\n",
      "epoch:29 step:136885[D loss: 0.999937] [G loss: 1.000085]\n",
      "epoch:29 step:136890[D loss: 1.000027] [G loss: 0.999981]\n",
      "epoch:29 step:136895[D loss: 1.000056] [G loss: 0.999920]\n",
      "epoch:29 step:136900[D loss: 1.000091] [G loss: 0.999831]\n",
      "epoch:29 step:136905[D loss: 0.999900] [G loss: 1.000063]\n",
      "epoch:29 step:136910[D loss: 1.000055] [G loss: 1.000022]\n",
      "epoch:29 step:136915[D loss: 0.999927] [G loss: 1.000147]\n",
      "epoch:29 step:136920[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:29 step:136925[D loss: 0.999958] [G loss: 1.000069]\n",
      "epoch:29 step:136930[D loss: 0.999962] [G loss: 1.000117]\n",
      "epoch:29 step:136935[D loss: 1.000049] [G loss: 1.000012]\n",
      "epoch:29 step:136940[D loss: 1.000038] [G loss: 0.999996]\n",
      "epoch:29 step:136945[D loss: 1.000139] [G loss: 0.999771]\n",
      "epoch:29 step:136950[D loss: 1.000142] [G loss: 1.000202]\n",
      "epoch:29 step:136955[D loss: 0.999922] [G loss: 1.000127]\n",
      "epoch:29 step:136960[D loss: 0.999858] [G loss: 1.000238]\n",
      "epoch:29 step:136965[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:29 step:136970[D loss: 0.999995] [G loss: 0.999988]\n",
      "epoch:29 step:136975[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:29 step:136980[D loss: 1.000122] [G loss: 0.999907]\n",
      "epoch:29 step:136985[D loss: 0.999919] [G loss: 1.000101]\n",
      "epoch:29 step:136990[D loss: 1.000113] [G loss: 0.999891]\n",
      "epoch:29 step:136995[D loss: 1.000155] [G loss: 0.999965]\n",
      "epoch:29 step:137000[D loss: 0.999966] [G loss: 1.000283]\n",
      "epoch:29 step:137005[D loss: 0.999887] [G loss: 1.000144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:137010[D loss: 0.999903] [G loss: 1.000162]\n",
      "epoch:29 step:137015[D loss: 1.000008] [G loss: 1.000106]\n",
      "epoch:29 step:137020[D loss: 0.999932] [G loss: 1.000065]\n",
      "epoch:29 step:137025[D loss: 0.999950] [G loss: 1.000104]\n",
      "epoch:29 step:137030[D loss: 0.999983] [G loss: 1.000113]\n",
      "epoch:29 step:137035[D loss: 0.999981] [G loss: 1.000174]\n",
      "epoch:29 step:137040[D loss: 0.999959] [G loss: 1.000132]\n",
      "epoch:29 step:137045[D loss: 0.999926] [G loss: 1.000130]\n",
      "epoch:29 step:137050[D loss: 0.999957] [G loss: 1.000139]\n",
      "epoch:29 step:137055[D loss: 1.000009] [G loss: 1.000001]\n",
      "epoch:29 step:137060[D loss: 1.000011] [G loss: 0.999992]\n",
      "epoch:29 step:137065[D loss: 0.999978] [G loss: 1.000023]\n",
      "epoch:29 step:137070[D loss: 1.000196] [G loss: 0.999878]\n",
      "epoch:29 step:137075[D loss: 1.000011] [G loss: 1.000003]\n",
      "epoch:29 step:137080[D loss: 0.999937] [G loss: 1.000071]\n",
      "epoch:29 step:137085[D loss: 1.000024] [G loss: 1.000184]\n",
      "epoch:29 step:137090[D loss: 0.999909] [G loss: 1.000161]\n",
      "epoch:29 step:137095[D loss: 0.999973] [G loss: 1.000104]\n",
      "epoch:29 step:137100[D loss: 1.000015] [G loss: 1.000002]\n",
      "epoch:29 step:137105[D loss: 1.000070] [G loss: 1.000037]\n",
      "epoch:29 step:137110[D loss: 0.999909] [G loss: 1.000148]\n",
      "epoch:29 step:137115[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:29 step:137120[D loss: 1.000001] [G loss: 1.000000]\n",
      "epoch:29 step:137125[D loss: 0.999960] [G loss: 1.000086]\n",
      "epoch:29 step:137130[D loss: 1.000007] [G loss: 1.000038]\n",
      "epoch:29 step:137135[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:29 step:137140[D loss: 0.999976] [G loss: 1.000136]\n",
      "epoch:29 step:137145[D loss: 1.000013] [G loss: 1.000024]\n",
      "epoch:29 step:137150[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:29 step:137155[D loss: 0.999943] [G loss: 1.000075]\n",
      "epoch:29 step:137160[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:29 step:137165[D loss: 1.000012] [G loss: 1.000032]\n",
      "epoch:29 step:137170[D loss: 0.999940] [G loss: 1.000071]\n",
      "epoch:29 step:137175[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:29 step:137180[D loss: 1.000123] [G loss: 0.999908]\n",
      "epoch:29 step:137185[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:29 step:137190[D loss: 0.999976] [G loss: 1.000057]\n",
      "epoch:29 step:137195[D loss: 1.000048] [G loss: 1.000040]\n",
      "epoch:29 step:137200[D loss: 0.999953] [G loss: 1.000075]\n",
      "epoch:29 step:137205[D loss: 0.999988] [G loss: 1.000064]\n",
      "epoch:29 step:137210[D loss: 1.000018] [G loss: 0.999977]\n",
      "epoch:29 step:137215[D loss: 0.999950] [G loss: 1.000203]\n",
      "epoch:29 step:137220[D loss: 1.000046] [G loss: 0.999981]\n",
      "epoch:29 step:137225[D loss: 0.999947] [G loss: 0.999994]\n",
      "epoch:29 step:137230[D loss: 0.999948] [G loss: 1.000091]\n",
      "epoch:29 step:137235[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:29 step:137240[D loss: 0.999986] [G loss: 1.000089]\n",
      "epoch:29 step:137245[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:29 step:137250[D loss: 0.999962] [G loss: 1.000085]\n",
      "epoch:29 step:137255[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:29 step:137260[D loss: 0.999892] [G loss: 1.000162]\n",
      "epoch:29 step:137265[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:29 step:137270[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:29 step:137275[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:29 step:137280[D loss: 0.999943] [G loss: 1.000110]\n",
      "epoch:29 step:137285[D loss: 1.000061] [G loss: 0.999967]\n",
      "epoch:29 step:137290[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:29 step:137295[D loss: 0.999924] [G loss: 1.000091]\n",
      "epoch:29 step:137300[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:29 step:137305[D loss: 0.999997] [G loss: 1.000044]\n",
      "epoch:29 step:137310[D loss: 0.999964] [G loss: 1.000082]\n",
      "epoch:29 step:137315[D loss: 0.999978] [G loss: 1.000022]\n",
      "epoch:29 step:137320[D loss: 0.999976] [G loss: 1.000094]\n",
      "epoch:29 step:137325[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:29 step:137330[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:29 step:137335[D loss: 0.999964] [G loss: 1.000062]\n",
      "epoch:29 step:137340[D loss: 1.000030] [G loss: 0.999971]\n",
      "epoch:29 step:137345[D loss: 0.999992] [G loss: 1.000046]\n",
      "epoch:29 step:137350[D loss: 0.999989] [G loss: 1.000045]\n",
      "epoch:29 step:137355[D loss: 0.999956] [G loss: 1.000086]\n",
      "epoch:29 step:137360[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:29 step:137365[D loss: 1.000018] [G loss: 1.000000]\n",
      "epoch:29 step:137370[D loss: 0.999960] [G loss: 1.000059]\n",
      "epoch:29 step:137375[D loss: 1.000008] [G loss: 1.000028]\n",
      "epoch:29 step:137380[D loss: 1.000001] [G loss: 1.000033]\n",
      "epoch:29 step:137385[D loss: 0.999961] [G loss: 1.000025]\n",
      "epoch:29 step:137390[D loss: 0.999998] [G loss: 1.000055]\n",
      "epoch:29 step:137395[D loss: 1.000020] [G loss: 1.000058]\n",
      "epoch:29 step:137400[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:29 step:137405[D loss: 0.999989] [G loss: 1.000027]\n",
      "epoch:29 step:137410[D loss: 1.000024] [G loss: 1.000006]\n",
      "epoch:29 step:137415[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:29 step:137420[D loss: 1.000000] [G loss: 1.000071]\n",
      "epoch:29 step:137425[D loss: 0.999936] [G loss: 1.000072]\n",
      "epoch:29 step:137430[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:29 step:137435[D loss: 0.999959] [G loss: 1.000041]\n",
      "epoch:29 step:137440[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:29 step:137445[D loss: 1.000024] [G loss: 1.000063]\n",
      "epoch:29 step:137450[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:29 step:137455[D loss: 1.000015] [G loss: 0.999989]\n",
      "epoch:29 step:137460[D loss: 0.999974] [G loss: 0.999949]\n",
      "epoch:29 step:137465[D loss: 1.000052] [G loss: 0.999927]\n",
      "epoch:29 step:137470[D loss: 1.000091] [G loss: 1.000184]\n",
      "epoch:29 step:137475[D loss: 0.999942] [G loss: 1.000250]\n",
      "epoch:29 step:137480[D loss: 0.999981] [G loss: 1.000157]\n",
      "epoch:29 step:137485[D loss: 0.999984] [G loss: 1.000009]\n",
      "epoch:29 step:137490[D loss: 0.999956] [G loss: 1.000003]\n",
      "epoch:29 step:137495[D loss: 1.000009] [G loss: 1.000018]\n",
      "epoch:29 step:137500[D loss: 1.000043] [G loss: 0.999920]\n",
      "epoch:29 step:137505[D loss: 0.999958] [G loss: 0.999933]\n",
      "epoch:29 step:137510[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:29 step:137515[D loss: 0.999970] [G loss: 1.000161]\n",
      "epoch:29 step:137520[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:29 step:137525[D loss: 0.999992] [G loss: 1.000102]\n",
      "epoch:29 step:137530[D loss: 0.999962] [G loss: 1.000124]\n",
      "epoch:29 step:137535[D loss: 0.999957] [G loss: 1.000052]\n",
      "epoch:29 step:137540[D loss: 0.999975] [G loss: 1.000057]\n",
      "epoch:29 step:137545[D loss: 1.000003] [G loss: 1.000050]\n",
      "epoch:29 step:137550[D loss: 0.999974] [G loss: 1.000057]\n",
      "epoch:29 step:137555[D loss: 1.000023] [G loss: 0.999989]\n",
      "epoch:29 step:137560[D loss: 1.000047] [G loss: 0.999982]\n",
      "epoch:29 step:137565[D loss: 0.999923] [G loss: 1.000078]\n",
      "epoch:29 step:137570[D loss: 0.999948] [G loss: 1.000129]\n",
      "epoch:29 step:137575[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:29 step:137580[D loss: 0.999974] [G loss: 1.000083]\n",
      "epoch:29 step:137585[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:29 step:137590[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:29 step:137595[D loss: 1.000076] [G loss: 1.000039]\n",
      "epoch:29 step:137600[D loss: 0.999962] [G loss: 1.000011]\n",
      "epoch:29 step:137605[D loss: 0.999951] [G loss: 1.000063]\n",
      "epoch:29 step:137610[D loss: 1.000125] [G loss: 0.999973]\n",
      "epoch:29 step:137615[D loss: 0.999921] [G loss: 1.000100]\n",
      "epoch:29 step:137620[D loss: 1.000075] [G loss: 1.000057]\n",
      "epoch:29 step:137625[D loss: 0.999936] [G loss: 1.000169]\n",
      "epoch:29 step:137630[D loss: 0.999947] [G loss: 1.000130]\n",
      "epoch:29 step:137635[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:29 step:137640[D loss: 1.000059] [G loss: 0.999871]\n",
      "epoch:29 step:137645[D loss: 0.999979] [G loss: 0.999961]\n",
      "epoch:29 step:137650[D loss: 0.999956] [G loss: 1.000047]\n",
      "epoch:29 step:137655[D loss: 1.000136] [G loss: 1.000022]\n",
      "epoch:29 step:137660[D loss: 0.999911] [G loss: 1.000091]\n",
      "epoch:29 step:137665[D loss: 1.000018] [G loss: 1.000039]\n",
      "epoch:29 step:137670[D loss: 1.000003] [G loss: 1.000015]\n",
      "epoch:29 step:137675[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:29 step:137680[D loss: 1.000045] [G loss: 0.999988]\n",
      "epoch:29 step:137685[D loss: 1.000067] [G loss: 1.000044]\n",
      "epoch:29 step:137690[D loss: 1.000038] [G loss: 0.999929]\n",
      "epoch:29 step:137695[D loss: 0.999960] [G loss: 1.000097]\n",
      "epoch:29 step:137700[D loss: 0.999986] [G loss: 1.000214]\n",
      "epoch:29 step:137705[D loss: 1.000008] [G loss: 1.000063]\n",
      "epoch:29 step:137710[D loss: 1.000072] [G loss: 1.000056]\n",
      "epoch:29 step:137715[D loss: 0.999973] [G loss: 1.000123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:137720[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:29 step:137725[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:29 step:137730[D loss: 0.999979] [G loss: 1.000005]\n",
      "epoch:29 step:137735[D loss: 0.999966] [G loss: 1.000099]\n",
      "epoch:29 step:137740[D loss: 1.000040] [G loss: 0.999942]\n",
      "epoch:29 step:137745[D loss: 1.000017] [G loss: 0.999999]\n",
      "epoch:29 step:137750[D loss: 1.000026] [G loss: 0.999938]\n",
      "epoch:29 step:137755[D loss: 1.000027] [G loss: 1.000155]\n",
      "epoch:29 step:137760[D loss: 0.999918] [G loss: 1.000118]\n",
      "epoch:29 step:137765[D loss: 0.999908] [G loss: 1.000115]\n",
      "epoch:29 step:137770[D loss: 0.999991] [G loss: 1.000007]\n",
      "epoch:29 step:137775[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:29 step:137780[D loss: 0.999957] [G loss: 1.000048]\n",
      "epoch:29 step:137785[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:29 step:137790[D loss: 1.000071] [G loss: 0.999928]\n",
      "epoch:29 step:137795[D loss: 0.999936] [G loss: 1.000047]\n",
      "epoch:29 step:137800[D loss: 1.000150] [G loss: 0.999969]\n",
      "epoch:29 step:137805[D loss: 1.000027] [G loss: 0.999984]\n",
      "epoch:29 step:137810[D loss: 0.999914] [G loss: 1.000083]\n",
      "epoch:29 step:137815[D loss: 0.999936] [G loss: 1.000175]\n",
      "epoch:29 step:137820[D loss: 0.999852] [G loss: 1.000179]\n",
      "epoch:29 step:137825[D loss: 1.000070] [G loss: 1.000048]\n",
      "epoch:29 step:137830[D loss: 1.000004] [G loss: 0.999999]\n",
      "epoch:29 step:137835[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:29 step:137840[D loss: 0.999917] [G loss: 1.000085]\n",
      "epoch:29 step:137845[D loss: 0.999970] [G loss: 1.000083]\n",
      "epoch:29 step:137850[D loss: 1.000013] [G loss: 0.999968]\n",
      "epoch:29 step:137855[D loss: 1.000036] [G loss: 0.999832]\n",
      "epoch:29 step:137860[D loss: 1.000001] [G loss: 1.000021]\n",
      "epoch:29 step:137865[D loss: 1.000001] [G loss: 1.000079]\n",
      "epoch:29 step:137870[D loss: 0.999982] [G loss: 1.000091]\n",
      "epoch:29 step:137875[D loss: 0.999956] [G loss: 1.000173]\n",
      "epoch:29 step:137880[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:29 step:137885[D loss: 1.000004] [G loss: 1.000028]\n",
      "epoch:29 step:137890[D loss: 0.999943] [G loss: 1.000043]\n",
      "epoch:29 step:137895[D loss: 0.999951] [G loss: 1.000060]\n",
      "epoch:29 step:137900[D loss: 1.000118] [G loss: 0.999834]\n",
      "epoch:29 step:137905[D loss: 0.999912] [G loss: 1.000071]\n",
      "epoch:29 step:137910[D loss: 0.999975] [G loss: 1.000025]\n",
      "epoch:29 step:137915[D loss: 1.000113] [G loss: 0.999998]\n",
      "epoch:29 step:137920[D loss: 0.999960] [G loss: 1.000018]\n",
      "epoch:29 step:137925[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:29 step:137930[D loss: 1.000008] [G loss: 0.999996]\n",
      "epoch:29 step:137935[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:29 step:137940[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:29 step:137945[D loss: 0.999990] [G loss: 1.000026]\n",
      "epoch:29 step:137950[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:29 step:137955[D loss: 0.999985] [G loss: 1.000100]\n",
      "epoch:29 step:137960[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:29 step:137965[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:29 step:137970[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:29 step:137975[D loss: 1.000026] [G loss: 1.000021]\n",
      "epoch:29 step:137980[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:29 step:137985[D loss: 0.999915] [G loss: 1.000131]\n",
      "epoch:29 step:137990[D loss: 0.999987] [G loss: 1.000102]\n",
      "epoch:29 step:137995[D loss: 0.999944] [G loss: 1.000107]\n",
      "epoch:29 step:138000[D loss: 0.999960] [G loss: 1.000049]\n",
      "epoch:29 step:138005[D loss: 1.000022] [G loss: 0.999966]\n",
      "epoch:29 step:138010[D loss: 0.999936] [G loss: 1.000080]\n",
      "epoch:29 step:138015[D loss: 0.999982] [G loss: 1.000031]\n",
      "epoch:29 step:138020[D loss: 0.999940] [G loss: 1.000072]\n",
      "epoch:29 step:138025[D loss: 0.999968] [G loss: 1.000079]\n",
      "epoch:29 step:138030[D loss: 1.000001] [G loss: 1.000008]\n",
      "epoch:29 step:138035[D loss: 0.999956] [G loss: 1.000137]\n",
      "epoch:29 step:138040[D loss: 1.000036] [G loss: 1.000015]\n",
      "epoch:29 step:138045[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:29 step:138050[D loss: 0.999975] [G loss: 1.000019]\n",
      "epoch:29 step:138055[D loss: 1.000001] [G loss: 1.000038]\n",
      "epoch:29 step:138060[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:29 step:138065[D loss: 0.999962] [G loss: 1.000071]\n",
      "epoch:29 step:138070[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:29 step:138075[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:29 step:138080[D loss: 0.999977] [G loss: 1.000057]\n",
      "epoch:29 step:138085[D loss: 1.000027] [G loss: 0.999990]\n",
      "epoch:29 step:138090[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:29 step:138095[D loss: 1.000091] [G loss: 1.000044]\n",
      "epoch:29 step:138100[D loss: 0.999973] [G loss: 1.000139]\n",
      "epoch:29 step:138105[D loss: 1.000020] [G loss: 1.000109]\n",
      "epoch:29 step:138110[D loss: 0.999965] [G loss: 1.000098]\n",
      "epoch:29 step:138115[D loss: 0.999999] [G loss: 1.000049]\n",
      "epoch:29 step:138120[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:29 step:138125[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:29 step:138130[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:29 step:138135[D loss: 1.000030] [G loss: 0.999949]\n",
      "epoch:29 step:138140[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:29 step:138145[D loss: 0.999965] [G loss: 1.000048]\n",
      "epoch:29 step:138150[D loss: 1.000072] [G loss: 0.999953]\n",
      "epoch:29 step:138155[D loss: 0.999984] [G loss: 1.000167]\n",
      "epoch:29 step:138160[D loss: 1.000296] [G loss: 0.999845]\n",
      "epoch:29 step:138165[D loss: 0.999788] [G loss: 1.000290]\n",
      "epoch:29 step:138170[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:29 step:138175[D loss: 0.999951] [G loss: 1.000034]\n",
      "epoch:29 step:138180[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:29 step:138185[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:29 step:138190[D loss: 1.000028] [G loss: 0.999959]\n",
      "epoch:29 step:138195[D loss: 0.999955] [G loss: 1.000046]\n",
      "epoch:29 step:138200[D loss: 0.999952] [G loss: 1.000107]\n",
      "epoch:29 step:138205[D loss: 1.000009] [G loss: 1.000072]\n",
      "epoch:29 step:138210[D loss: 1.000029] [G loss: 1.000106]\n",
      "epoch:29 step:138215[D loss: 0.999916] [G loss: 1.000136]\n",
      "epoch:29 step:138220[D loss: 0.999942] [G loss: 1.000105]\n",
      "epoch:29 step:138225[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:29 step:138230[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:29 step:138235[D loss: 1.000026] [G loss: 0.999932]\n",
      "epoch:29 step:138240[D loss: 0.999990] [G loss: 0.999999]\n",
      "epoch:29 step:138245[D loss: 0.999989] [G loss: 1.000047]\n",
      "epoch:29 step:138250[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:29 step:138255[D loss: 1.000092] [G loss: 0.999900]\n",
      "epoch:29 step:138260[D loss: 0.999980] [G loss: 0.999990]\n",
      "epoch:29 step:138265[D loss: 0.999968] [G loss: 1.000035]\n",
      "epoch:29 step:138270[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:29 step:138275[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:29 step:138280[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:29 step:138285[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:29 step:138290[D loss: 1.000113] [G loss: 0.999923]\n",
      "epoch:29 step:138295[D loss: 0.999912] [G loss: 1.000127]\n",
      "epoch:29 step:138300[D loss: 0.999939] [G loss: 1.000142]\n",
      "epoch:29 step:138305[D loss: 0.999956] [G loss: 1.000179]\n",
      "epoch:29 step:138310[D loss: 0.999934] [G loss: 1.000140]\n",
      "epoch:29 step:138315[D loss: 0.999964] [G loss: 1.000197]\n",
      "epoch:29 step:138320[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:29 step:138325[D loss: 1.000004] [G loss: 1.000096]\n",
      "epoch:29 step:138330[D loss: 0.999944] [G loss: 1.000199]\n",
      "epoch:29 step:138335[D loss: 0.999971] [G loss: 1.000127]\n",
      "epoch:29 step:138340[D loss: 1.000019] [G loss: 0.999957]\n",
      "epoch:29 step:138345[D loss: 0.999965] [G loss: 1.000095]\n",
      "epoch:29 step:138350[D loss: 0.999972] [G loss: 1.000041]\n",
      "epoch:29 step:138355[D loss: 1.000041] [G loss: 0.999969]\n",
      "epoch:29 step:138360[D loss: 1.000032] [G loss: 0.999993]\n",
      "epoch:29 step:138365[D loss: 1.000009] [G loss: 1.000172]\n",
      "epoch:29 step:138370[D loss: 0.999826] [G loss: 1.000091]\n",
      "epoch:29 step:138375[D loss: 0.999886] [G loss: 1.000182]\n",
      "epoch:29 step:138380[D loss: 0.999908] [G loss: 1.000151]\n",
      "epoch:29 step:138385[D loss: 0.999973] [G loss: 1.000105]\n",
      "epoch:29 step:138390[D loss: 0.999967] [G loss: 1.000100]\n",
      "epoch:29 step:138395[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:29 step:138400[D loss: 0.999984] [G loss: 1.000110]\n",
      "epoch:29 step:138405[D loss: 1.000084] [G loss: 0.999942]\n",
      "epoch:29 step:138410[D loss: 0.999962] [G loss: 1.000145]\n",
      "epoch:29 step:138415[D loss: 1.000078] [G loss: 1.000175]\n",
      "epoch:29 step:138420[D loss: 0.999917] [G loss: 1.000177]\n",
      "epoch:29 step:138425[D loss: 0.999992] [G loss: 1.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:138430[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:29 step:138435[D loss: 1.000055] [G loss: 0.999923]\n",
      "epoch:29 step:138440[D loss: 0.999913] [G loss: 1.000053]\n",
      "epoch:29 step:138445[D loss: 1.000070] [G loss: 0.999938]\n",
      "epoch:29 step:138450[D loss: 1.000120] [G loss: 1.000135]\n",
      "epoch:29 step:138455[D loss: 0.999944] [G loss: 1.000142]\n",
      "epoch:29 step:138460[D loss: 1.000015] [G loss: 1.000097]\n",
      "epoch:29 step:138465[D loss: 1.000040] [G loss: 1.000080]\n",
      "epoch:29 step:138470[D loss: 0.999980] [G loss: 1.000120]\n",
      "epoch:29 step:138475[D loss: 0.999939] [G loss: 1.000100]\n",
      "epoch:29 step:138480[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:29 step:138485[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:29 step:138490[D loss: 1.000056] [G loss: 0.999967]\n",
      "epoch:29 step:138495[D loss: 0.999953] [G loss: 1.000105]\n",
      "epoch:29 step:138500[D loss: 0.999912] [G loss: 1.000077]\n",
      "epoch:29 step:138505[D loss: 1.000076] [G loss: 0.999867]\n",
      "epoch:29 step:138510[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:29 step:138515[D loss: 0.999944] [G loss: 1.000087]\n",
      "epoch:29 step:138520[D loss: 0.999935] [G loss: 1.000107]\n",
      "epoch:29 step:138525[D loss: 0.999956] [G loss: 1.000075]\n",
      "epoch:29 step:138530[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:29 step:138535[D loss: 1.000031] [G loss: 1.000051]\n",
      "epoch:29 step:138540[D loss: 0.999916] [G loss: 1.000102]\n",
      "epoch:29 step:138545[D loss: 1.000030] [G loss: 1.000152]\n",
      "epoch:29 step:138550[D loss: 0.999979] [G loss: 1.000105]\n",
      "epoch:29 step:138555[D loss: 1.000080] [G loss: 1.000005]\n",
      "epoch:29 step:138560[D loss: 0.999862] [G loss: 1.000407]\n",
      "epoch:29 step:138565[D loss: 0.999956] [G loss: 1.000121]\n",
      "epoch:29 step:138570[D loss: 0.999949] [G loss: 1.000075]\n",
      "epoch:29 step:138575[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:29 step:138580[D loss: 1.000101] [G loss: 0.999901]\n",
      "epoch:29 step:138585[D loss: 0.999927] [G loss: 1.000032]\n",
      "epoch:29 step:138590[D loss: 1.000131] [G loss: 0.999851]\n",
      "epoch:29 step:138595[D loss: 1.000119] [G loss: 0.999808]\n",
      "epoch:29 step:138600[D loss: 0.999856] [G loss: 1.000121]\n",
      "epoch:29 step:138605[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:29 step:138610[D loss: 0.999971] [G loss: 1.000105]\n",
      "epoch:29 step:138615[D loss: 0.999995] [G loss: 1.000090]\n",
      "epoch:29 step:138620[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:29 step:138625[D loss: 0.999985] [G loss: 1.000077]\n",
      "epoch:29 step:138630[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:29 step:138635[D loss: 0.999934] [G loss: 1.000070]\n",
      "epoch:29 step:138640[D loss: 0.999965] [G loss: 1.000046]\n",
      "epoch:29 step:138645[D loss: 0.999989] [G loss: 1.000005]\n",
      "epoch:29 step:138650[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:29 step:138655[D loss: 1.000020] [G loss: 1.000018]\n",
      "epoch:29 step:138660[D loss: 1.000034] [G loss: 1.000045]\n",
      "epoch:29 step:138665[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:29 step:138670[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:29 step:138675[D loss: 0.999988] [G loss: 1.000102]\n",
      "epoch:29 step:138680[D loss: 0.999965] [G loss: 1.000033]\n",
      "epoch:29 step:138685[D loss: 0.999963] [G loss: 1.000059]\n",
      "epoch:29 step:138690[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:29 step:138695[D loss: 1.000006] [G loss: 1.000007]\n",
      "epoch:29 step:138700[D loss: 0.999974] [G loss: 0.999998]\n",
      "epoch:29 step:138705[D loss: 1.000020] [G loss: 1.000013]\n",
      "epoch:29 step:138710[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:29 step:138715[D loss: 1.000022] [G loss: 1.000013]\n",
      "epoch:29 step:138720[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:29 step:138725[D loss: 0.999937] [G loss: 1.000128]\n",
      "epoch:29 step:138730[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:29 step:138735[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:29 step:138740[D loss: 1.000047] [G loss: 1.000028]\n",
      "epoch:29 step:138745[D loss: 0.999962] [G loss: 1.000077]\n",
      "epoch:29 step:138750[D loss: 0.999953] [G loss: 1.000047]\n",
      "epoch:29 step:138755[D loss: 1.000014] [G loss: 0.999994]\n",
      "epoch:29 step:138760[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:29 step:138765[D loss: 1.000010] [G loss: 1.000052]\n",
      "epoch:29 step:138770[D loss: 0.999925] [G loss: 1.000071]\n",
      "epoch:29 step:138775[D loss: 0.999988] [G loss: 1.000023]\n",
      "epoch:29 step:138780[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:29 step:138785[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:29 step:138790[D loss: 0.999966] [G loss: 1.000052]\n",
      "epoch:29 step:138795[D loss: 0.999968] [G loss: 1.000034]\n",
      "epoch:29 step:138800[D loss: 0.999964] [G loss: 1.000091]\n",
      "epoch:29 step:138805[D loss: 0.999962] [G loss: 1.000113]\n",
      "epoch:29 step:138810[D loss: 1.000011] [G loss: 1.000081]\n",
      "epoch:29 step:138815[D loss: 0.999918] [G loss: 1.000115]\n",
      "epoch:29 step:138820[D loss: 1.000003] [G loss: 1.000010]\n",
      "epoch:29 step:138825[D loss: 1.000010] [G loss: 1.000013]\n",
      "epoch:29 step:138830[D loss: 1.000153] [G loss: 0.999825]\n",
      "epoch:29 step:138835[D loss: 0.999953] [G loss: 1.000046]\n",
      "epoch:29 step:138840[D loss: 1.000093] [G loss: 1.000080]\n",
      "epoch:29 step:138845[D loss: 0.999951] [G loss: 1.000160]\n",
      "epoch:29 step:138850[D loss: 0.999932] [G loss: 1.000122]\n",
      "epoch:29 step:138855[D loss: 0.999909] [G loss: 1.000163]\n",
      "epoch:29 step:138860[D loss: 0.999944] [G loss: 1.000041]\n",
      "epoch:29 step:138865[D loss: 0.999972] [G loss: 1.000091]\n",
      "epoch:29 step:138870[D loss: 1.000022] [G loss: 1.000001]\n",
      "epoch:29 step:138875[D loss: 1.000031] [G loss: 0.999926]\n",
      "epoch:29 step:138880[D loss: 0.999944] [G loss: 1.000030]\n",
      "epoch:29 step:138885[D loss: 1.000041] [G loss: 0.999951]\n",
      "epoch:29 step:138890[D loss: 0.999983] [G loss: 1.000032]\n",
      "epoch:29 step:138895[D loss: 0.999950] [G loss: 1.000022]\n",
      "epoch:29 step:138900[D loss: 1.000058] [G loss: 0.999963]\n",
      "epoch:29 step:138905[D loss: 1.000005] [G loss: 1.000029]\n",
      "epoch:29 step:138910[D loss: 1.000026] [G loss: 1.000117]\n",
      "epoch:29 step:138915[D loss: 0.999933] [G loss: 1.000070]\n",
      "epoch:29 step:138920[D loss: 0.999920] [G loss: 1.000204]\n",
      "epoch:29 step:138925[D loss: 0.999998] [G loss: 1.000060]\n",
      "epoch:29 step:138930[D loss: 1.000020] [G loss: 0.999987]\n",
      "epoch:29 step:138935[D loss: 1.000001] [G loss: 0.999984]\n",
      "epoch:29 step:138940[D loss: 1.000029] [G loss: 0.999905]\n",
      "epoch:29 step:138945[D loss: 0.999977] [G loss: 0.999948]\n",
      "epoch:29 step:138950[D loss: 0.999976] [G loss: 1.000156]\n",
      "epoch:29 step:138955[D loss: 1.000018] [G loss: 0.999969]\n",
      "epoch:29 step:138960[D loss: 0.999882] [G loss: 1.000093]\n",
      "epoch:29 step:138965[D loss: 1.000003] [G loss: 1.000086]\n",
      "epoch:29 step:138970[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:29 step:138975[D loss: 1.000003] [G loss: 1.000058]\n",
      "epoch:29 step:138980[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:29 step:138985[D loss: 1.000009] [G loss: 1.000015]\n",
      "epoch:29 step:138990[D loss: 0.999956] [G loss: 1.000178]\n",
      "epoch:29 step:138995[D loss: 0.999925] [G loss: 1.000117]\n",
      "epoch:29 step:139000[D loss: 1.000024] [G loss: 1.000037]\n",
      "epoch:29 step:139005[D loss: 1.000014] [G loss: 0.999948]\n",
      "epoch:29 step:139010[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:29 step:139015[D loss: 0.999960] [G loss: 1.000102]\n",
      "epoch:29 step:139020[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:29 step:139025[D loss: 0.999912] [G loss: 1.000167]\n",
      "epoch:29 step:139030[D loss: 1.000029] [G loss: 1.000012]\n",
      "epoch:29 step:139035[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:29 step:139040[D loss: 0.999996] [G loss: 1.000048]\n",
      "epoch:29 step:139045[D loss: 0.999989] [G loss: 1.000036]\n",
      "epoch:29 step:139050[D loss: 1.000034] [G loss: 1.000125]\n",
      "epoch:29 step:139055[D loss: 0.999907] [G loss: 1.000096]\n",
      "epoch:29 step:139060[D loss: 0.999972] [G loss: 1.000041]\n",
      "epoch:29 step:139065[D loss: 1.000009] [G loss: 1.000099]\n",
      "epoch:29 step:139070[D loss: 0.999967] [G loss: 1.000151]\n",
      "epoch:29 step:139075[D loss: 0.999997] [G loss: 1.000038]\n",
      "epoch:29 step:139080[D loss: 0.999918] [G loss: 1.000089]\n",
      "epoch:29 step:139085[D loss: 1.000012] [G loss: 1.000004]\n",
      "epoch:29 step:139090[D loss: 1.000042] [G loss: 0.999993]\n",
      "epoch:29 step:139095[D loss: 1.000005] [G loss: 0.999977]\n",
      "epoch:29 step:139100[D loss: 0.999962] [G loss: 1.000023]\n",
      "epoch:29 step:139105[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:29 step:139110[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:29 step:139115[D loss: 0.999980] [G loss: 1.000023]\n",
      "epoch:29 step:139120[D loss: 0.999992] [G loss: 1.000071]\n",
      "epoch:29 step:139125[D loss: 0.999985] [G loss: 1.000008]\n",
      "epoch:29 step:139130[D loss: 0.999930] [G loss: 1.000128]\n",
      "epoch:29 step:139135[D loss: 0.999968] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:139140[D loss: 0.999972] [G loss: 1.000075]\n",
      "epoch:29 step:139145[D loss: 1.000019] [G loss: 0.999988]\n",
      "epoch:29 step:139150[D loss: 1.000013] [G loss: 0.999965]\n",
      "epoch:29 step:139155[D loss: 0.999962] [G loss: 1.000073]\n",
      "epoch:29 step:139160[D loss: 1.000021] [G loss: 1.000020]\n",
      "epoch:29 step:139165[D loss: 0.999935] [G loss: 1.000100]\n",
      "epoch:29 step:139170[D loss: 1.000033] [G loss: 1.000029]\n",
      "epoch:29 step:139175[D loss: 1.000048] [G loss: 1.000053]\n",
      "epoch:29 step:139180[D loss: 0.999993] [G loss: 1.000155]\n",
      "epoch:29 step:139185[D loss: 0.999904] [G loss: 1.000118]\n",
      "epoch:29 step:139190[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:29 step:139195[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:29 step:139200[D loss: 0.999913] [G loss: 1.000043]\n",
      "epoch:29 step:139205[D loss: 0.999966] [G loss: 1.000064]\n",
      "epoch:29 step:139210[D loss: 0.999957] [G loss: 1.000044]\n",
      "epoch:29 step:139215[D loss: 0.999993] [G loss: 0.999979]\n",
      "epoch:29 step:139220[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:29 step:139225[D loss: 0.999983] [G loss: 1.000019]\n",
      "epoch:29 step:139230[D loss: 0.999991] [G loss: 1.000089]\n",
      "epoch:29 step:139235[D loss: 0.999957] [G loss: 1.000085]\n",
      "epoch:29 step:139240[D loss: 1.000005] [G loss: 1.000031]\n",
      "epoch:29 step:139245[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:29 step:139250[D loss: 1.000022] [G loss: 1.000010]\n",
      "epoch:29 step:139255[D loss: 1.000021] [G loss: 1.000026]\n",
      "epoch:29 step:139260[D loss: 0.999953] [G loss: 1.000099]\n",
      "epoch:29 step:139265[D loss: 1.000051] [G loss: 0.999969]\n",
      "epoch:29 step:139270[D loss: 0.999938] [G loss: 1.000107]\n",
      "epoch:29 step:139275[D loss: 1.000045] [G loss: 0.999989]\n",
      "epoch:29 step:139280[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:29 step:139285[D loss: 0.999964] [G loss: 1.000030]\n",
      "epoch:29 step:139290[D loss: 0.999990] [G loss: 1.000072]\n",
      "epoch:29 step:139295[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:29 step:139300[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:29 step:139305[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:29 step:139310[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:29 step:139315[D loss: 0.999937] [G loss: 1.000032]\n",
      "epoch:29 step:139320[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:29 step:139325[D loss: 0.999984] [G loss: 1.000084]\n",
      "epoch:29 step:139330[D loss: 1.000047] [G loss: 1.000018]\n",
      "epoch:29 step:139335[D loss: 0.999978] [G loss: 1.000036]\n",
      "epoch:29 step:139340[D loss: 0.999929] [G loss: 1.000066]\n",
      "epoch:29 step:139345[D loss: 1.000001] [G loss: 1.000005]\n",
      "epoch:29 step:139350[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:29 step:139355[D loss: 0.999970] [G loss: 1.000075]\n",
      "epoch:29 step:139360[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:29 step:139365[D loss: 0.999955] [G loss: 1.000062]\n",
      "epoch:29 step:139370[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:29 step:139375[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:29 step:139380[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:29 step:139385[D loss: 1.000001] [G loss: 1.000024]\n",
      "epoch:29 step:139390[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:29 step:139395[D loss: 1.000005] [G loss: 1.000043]\n",
      "epoch:29 step:139400[D loss: 0.999993] [G loss: 1.000046]\n",
      "epoch:29 step:139405[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:29 step:139410[D loss: 0.999989] [G loss: 1.000091]\n",
      "epoch:29 step:139415[D loss: 1.000162] [G loss: 0.999830]\n",
      "epoch:29 step:139420[D loss: 0.999906] [G loss: 1.000164]\n",
      "epoch:29 step:139425[D loss: 1.000041] [G loss: 0.999862]\n",
      "epoch:29 step:139430[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:29 step:139435[D loss: 1.000090] [G loss: 1.000156]\n",
      "epoch:29 step:139440[D loss: 1.000013] [G loss: 1.000055]\n",
      "epoch:29 step:139445[D loss: 0.999898] [G loss: 1.000095]\n",
      "epoch:29 step:139450[D loss: 0.999998] [G loss: 1.000011]\n",
      "epoch:29 step:139455[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:29 step:139460[D loss: 1.000085] [G loss: 0.999914]\n",
      "epoch:29 step:139465[D loss: 0.999910] [G loss: 1.000043]\n",
      "epoch:29 step:139470[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:29 step:139475[D loss: 0.999937] [G loss: 1.000083]\n",
      "epoch:29 step:139480[D loss: 1.000012] [G loss: 1.000066]\n",
      "epoch:29 step:139485[D loss: 0.999999] [G loss: 1.000142]\n",
      "epoch:29 step:139490[D loss: 0.999936] [G loss: 1.000093]\n",
      "epoch:29 step:139495[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:29 step:139500[D loss: 1.000023] [G loss: 1.000022]\n",
      "epoch:29 step:139505[D loss: 1.000043] [G loss: 1.000031]\n",
      "epoch:29 step:139510[D loss: 0.999935] [G loss: 1.000056]\n",
      "epoch:29 step:139515[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:29 step:139520[D loss: 1.000038] [G loss: 1.000006]\n",
      "epoch:29 step:139525[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:29 step:139530[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:29 step:139535[D loss: 0.999993] [G loss: 1.000038]\n",
      "epoch:29 step:139540[D loss: 0.999951] [G loss: 1.000112]\n",
      "epoch:29 step:139545[D loss: 0.999983] [G loss: 1.000047]\n",
      "epoch:29 step:139550[D loss: 0.999998] [G loss: 1.000078]\n",
      "epoch:29 step:139555[D loss: 0.999965] [G loss: 1.000031]\n",
      "epoch:29 step:139560[D loss: 1.000007] [G loss: 1.000052]\n",
      "epoch:29 step:139565[D loss: 1.000034] [G loss: 1.000061]\n",
      "epoch:29 step:139570[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:29 step:139575[D loss: 1.000116] [G loss: 0.999896]\n",
      "epoch:29 step:139580[D loss: 0.999919] [G loss: 0.999997]\n",
      "epoch:29 step:139585[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:29 step:139590[D loss: 0.999946] [G loss: 1.000085]\n",
      "epoch:29 step:139595[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:29 step:139600[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:29 step:139605[D loss: 0.999960] [G loss: 1.000095]\n",
      "epoch:29 step:139610[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:29 step:139615[D loss: 1.000031] [G loss: 0.999997]\n",
      "epoch:29 step:139620[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:29 step:139625[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:29 step:139630[D loss: 0.999987] [G loss: 1.000043]\n",
      "epoch:29 step:139635[D loss: 1.000004] [G loss: 1.000080]\n",
      "epoch:29 step:139640[D loss: 0.999968] [G loss: 1.000080]\n",
      "epoch:29 step:139645[D loss: 1.000075] [G loss: 0.999981]\n",
      "epoch:29 step:139650[D loss: 1.000106] [G loss: 0.999948]\n",
      "epoch:29 step:139655[D loss: 1.000066] [G loss: 0.999929]\n",
      "epoch:29 step:139660[D loss: 0.999882] [G loss: 1.000205]\n",
      "epoch:29 step:139665[D loss: 0.999930] [G loss: 1.000155]\n",
      "epoch:29 step:139670[D loss: 1.000004] [G loss: 1.000060]\n",
      "epoch:29 step:139675[D loss: 1.000073] [G loss: 1.000038]\n",
      "epoch:29 step:139680[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:29 step:139685[D loss: 0.999955] [G loss: 1.000087]\n",
      "epoch:29 step:139690[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:29 step:139695[D loss: 1.000058] [G loss: 0.999792]\n",
      "epoch:29 step:139700[D loss: 0.999974] [G loss: 1.000025]\n",
      "epoch:29 step:139705[D loss: 0.999983] [G loss: 1.000008]\n",
      "epoch:29 step:139710[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:29 step:139715[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:29 step:139720[D loss: 0.999978] [G loss: 1.000047]\n",
      "epoch:29 step:139725[D loss: 0.999988] [G loss: 1.000109]\n",
      "epoch:29 step:139730[D loss: 0.999993] [G loss: 1.000073]\n",
      "epoch:29 step:139735[D loss: 1.000030] [G loss: 1.000065]\n",
      "epoch:29 step:139740[D loss: 0.999923] [G loss: 1.000079]\n",
      "epoch:29 step:139745[D loss: 0.999982] [G loss: 1.000075]\n",
      "epoch:29 step:139750[D loss: 0.999972] [G loss: 1.000062]\n",
      "epoch:29 step:139755[D loss: 0.999926] [G loss: 1.000155]\n",
      "epoch:29 step:139760[D loss: 1.000102] [G loss: 0.999975]\n",
      "epoch:29 step:139765[D loss: 1.000048] [G loss: 0.999900]\n",
      "epoch:29 step:139770[D loss: 0.999817] [G loss: 1.000166]\n",
      "epoch:29 step:139775[D loss: 0.999942] [G loss: 1.000095]\n",
      "epoch:29 step:139780[D loss: 0.999998] [G loss: 1.000044]\n",
      "epoch:29 step:139785[D loss: 0.999933] [G loss: 1.000107]\n",
      "epoch:29 step:139790[D loss: 0.999952] [G loss: 1.000044]\n",
      "epoch:29 step:139795[D loss: 0.999998] [G loss: 1.000057]\n",
      "epoch:29 step:139800[D loss: 0.999977] [G loss: 1.000047]\n",
      "epoch:29 step:139805[D loss: 0.999980] [G loss: 1.000102]\n",
      "epoch:29 step:139810[D loss: 1.000036] [G loss: 1.000098]\n",
      "epoch:29 step:139815[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:29 step:139820[D loss: 0.999991] [G loss: 1.000029]\n",
      "epoch:29 step:139825[D loss: 0.999925] [G loss: 1.000092]\n",
      "epoch:29 step:139830[D loss: 0.999975] [G loss: 1.000033]\n",
      "epoch:29 step:139835[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:29 step:139840[D loss: 1.000017] [G loss: 0.999990]\n",
      "epoch:29 step:139845[D loss: 0.999971] [G loss: 1.000081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:139850[D loss: 0.999940] [G loss: 1.000141]\n",
      "epoch:29 step:139855[D loss: 0.999972] [G loss: 1.000220]\n",
      "epoch:29 step:139860[D loss: 0.999949] [G loss: 1.000091]\n",
      "epoch:29 step:139865[D loss: 0.999974] [G loss: 1.000008]\n",
      "epoch:29 step:139870[D loss: 0.999957] [G loss: 1.000078]\n",
      "epoch:29 step:139875[D loss: 1.000018] [G loss: 1.000020]\n",
      "epoch:29 step:139880[D loss: 0.999932] [G loss: 1.000132]\n",
      "epoch:29 step:139885[D loss: 0.999946] [G loss: 1.000162]\n",
      "epoch:29 step:139890[D loss: 0.999956] [G loss: 1.000089]\n",
      "epoch:29 step:139895[D loss: 0.999939] [G loss: 1.000119]\n",
      "epoch:29 step:139900[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:29 step:139905[D loss: 1.000028] [G loss: 1.000220]\n",
      "epoch:29 step:139910[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:29 step:139915[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:29 step:139920[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:29 step:139925[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:29 step:139930[D loss: 0.999975] [G loss: 1.000047]\n",
      "epoch:29 step:139935[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:29 step:139940[D loss: 0.999962] [G loss: 1.000061]\n",
      "epoch:29 step:139945[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:29 step:139950[D loss: 0.999952] [G loss: 1.000071]\n",
      "epoch:29 step:139955[D loss: 1.000042] [G loss: 1.000036]\n",
      "epoch:29 step:139960[D loss: 0.999899] [G loss: 1.000093]\n",
      "epoch:29 step:139965[D loss: 0.999940] [G loss: 1.000130]\n",
      "epoch:29 step:139970[D loss: 0.999940] [G loss: 1.000093]\n",
      "epoch:29 step:139975[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:29 step:139980[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:29 step:139985[D loss: 0.999966] [G loss: 1.000093]\n",
      "epoch:29 step:139990[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:29 step:139995[D loss: 0.999991] [G loss: 1.000060]\n",
      "epoch:29 step:140000[D loss: 0.999940] [G loss: 1.000091]\n",
      "epoch:29 step:140005[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:29 step:140010[D loss: 1.000033] [G loss: 0.999921]\n",
      "epoch:29 step:140015[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:29 step:140020[D loss: 0.999960] [G loss: 1.000101]\n",
      "epoch:29 step:140025[D loss: 1.000009] [G loss: 1.000041]\n",
      "epoch:29 step:140030[D loss: 0.999980] [G loss: 1.000014]\n",
      "epoch:29 step:140035[D loss: 1.000063] [G loss: 1.000082]\n",
      "epoch:29 step:140040[D loss: 0.999895] [G loss: 1.000124]\n",
      "epoch:29 step:140045[D loss: 0.999923] [G loss: 1.000118]\n",
      "epoch:29 step:140050[D loss: 0.999946] [G loss: 1.000077]\n",
      "epoch:29 step:140055[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:29 step:140060[D loss: 0.999991] [G loss: 1.000113]\n",
      "epoch:29 step:140065[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:29 step:140070[D loss: 0.999993] [G loss: 1.000044]\n",
      "epoch:29 step:140075[D loss: 0.999996] [G loss: 1.000034]\n",
      "epoch:29 step:140080[D loss: 1.000000] [G loss: 1.000037]\n",
      "epoch:29 step:140085[D loss: 1.000039] [G loss: 1.000095]\n",
      "epoch:29 step:140090[D loss: 0.999947] [G loss: 1.000111]\n",
      "epoch:29 step:140095[D loss: 0.999984] [G loss: 1.000024]\n",
      "epoch:29 step:140100[D loss: 1.000025] [G loss: 1.000033]\n",
      "epoch:29 step:140105[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:29 step:140110[D loss: 1.000120] [G loss: 0.999953]\n",
      "epoch:29 step:140115[D loss: 0.999779] [G loss: 1.000289]\n",
      "epoch:29 step:140120[D loss: 0.999949] [G loss: 1.000111]\n",
      "epoch:29 step:140125[D loss: 1.000016] [G loss: 1.000015]\n",
      "epoch:29 step:140130[D loss: 1.000017] [G loss: 0.999996]\n",
      "epoch:29 step:140135[D loss: 0.999935] [G loss: 1.000039]\n",
      "epoch:29 step:140140[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:29 step:140145[D loss: 1.000154] [G loss: 0.999836]\n",
      "epoch:29 step:140150[D loss: 0.999944] [G loss: 1.000043]\n",
      "epoch:29 step:140155[D loss: 0.999970] [G loss: 1.000049]\n",
      "epoch:29 step:140160[D loss: 1.000073] [G loss: 1.000031]\n",
      "epoch:29 step:140165[D loss: 0.999855] [G loss: 1.000189]\n",
      "epoch:29 step:140170[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:29 step:140175[D loss: 1.000008] [G loss: 1.000051]\n",
      "epoch:29 step:140180[D loss: 1.000009] [G loss: 1.000062]\n",
      "epoch:29 step:140185[D loss: 1.000017] [G loss: 1.000002]\n",
      "epoch:29 step:140190[D loss: 0.999968] [G loss: 1.000040]\n",
      "epoch:29 step:140195[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:29 step:140200[D loss: 0.999988] [G loss: 1.000100]\n",
      "epoch:29 step:140205[D loss: 0.999924] [G loss: 1.000183]\n",
      "epoch:29 step:140210[D loss: 0.999965] [G loss: 1.000105]\n",
      "epoch:29 step:140215[D loss: 0.999961] [G loss: 1.000160]\n",
      "epoch:29 step:140220[D loss: 0.999967] [G loss: 1.000023]\n",
      "epoch:29 step:140225[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:29 step:140230[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:29 step:140235[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:29 step:140240[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:29 step:140245[D loss: 0.999922] [G loss: 1.000118]\n",
      "epoch:29 step:140250[D loss: 0.999945] [G loss: 1.000075]\n",
      "epoch:29 step:140255[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:29 step:140260[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:29 step:140265[D loss: 0.999977] [G loss: 1.000095]\n",
      "epoch:29 step:140270[D loss: 0.999994] [G loss: 1.000043]\n",
      "epoch:29 step:140275[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:29 step:140280[D loss: 1.000007] [G loss: 1.000004]\n",
      "epoch:29 step:140285[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:29 step:140290[D loss: 0.999991] [G loss: 1.000147]\n",
      "epoch:29 step:140295[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:29 step:140300[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:29 step:140305[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:29 step:140310[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:29 step:140315[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:29 step:140320[D loss: 0.999961] [G loss: 1.000087]\n",
      "epoch:29 step:140325[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:29 step:140330[D loss: 1.000028] [G loss: 1.000073]\n",
      "epoch:29 step:140335[D loss: 0.999913] [G loss: 1.000157]\n",
      "epoch:29 step:140340[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:29 step:140345[D loss: 1.000033] [G loss: 1.000025]\n",
      "epoch:29 step:140350[D loss: 1.000029] [G loss: 0.999936]\n",
      "epoch:29 step:140355[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:29 step:140360[D loss: 0.999966] [G loss: 1.000082]\n",
      "epoch:29 step:140365[D loss: 0.999986] [G loss: 0.999998]\n",
      "epoch:29 step:140370[D loss: 0.999969] [G loss: 1.000116]\n",
      "epoch:29 step:140375[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:29 step:140380[D loss: 0.999988] [G loss: 1.000078]\n",
      "epoch:29 step:140385[D loss: 0.999972] [G loss: 1.000192]\n",
      "epoch:29 step:140390[D loss: 0.999947] [G loss: 1.000120]\n",
      "epoch:29 step:140395[D loss: 0.999965] [G loss: 1.000107]\n",
      "epoch:29 step:140400[D loss: 1.000001] [G loss: 0.999909]\n",
      "epoch:29 step:140405[D loss: 1.000181] [G loss: 0.999828]\n",
      "epoch:29 step:140410[D loss: 1.000024] [G loss: 0.999816]\n",
      "epoch:29 step:140415[D loss: 0.999998] [G loss: 1.000064]\n",
      "epoch:29 step:140420[D loss: 0.999915] [G loss: 0.999996]\n",
      "epoch:29 step:140425[D loss: 0.999978] [G loss: 1.000030]\n",
      "epoch:29 step:140430[D loss: 0.999938] [G loss: 1.000136]\n",
      "epoch:29 step:140435[D loss: 0.999950] [G loss: 1.000140]\n",
      "epoch:29 step:140440[D loss: 0.999976] [G loss: 1.000127]\n",
      "epoch:29 step:140445[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:29 step:140450[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:29 step:140455[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:29 step:140460[D loss: 1.000019] [G loss: 1.000005]\n",
      "epoch:29 step:140465[D loss: 1.000038] [G loss: 0.999953]\n",
      "epoch:29 step:140470[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:29 step:140475[D loss: 1.000007] [G loss: 1.000025]\n",
      "epoch:29 step:140480[D loss: 0.999965] [G loss: 1.000114]\n",
      "epoch:29 step:140485[D loss: 0.999955] [G loss: 1.000113]\n",
      "epoch:29 step:140490[D loss: 0.999935] [G loss: 1.000101]\n",
      "epoch:29 step:140495[D loss: 0.999940] [G loss: 1.000091]\n",
      "epoch:29 step:140500[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:29 step:140505[D loss: 1.000035] [G loss: 0.999968]\n",
      "epoch:29 step:140510[D loss: 0.999901] [G loss: 1.000108]\n",
      "epoch:29 step:140515[D loss: 0.999985] [G loss: 1.000030]\n",
      "epoch:29 step:140520[D loss: 0.999958] [G loss: 1.000096]\n",
      "epoch:29 step:140525[D loss: 0.999975] [G loss: 1.000072]\n",
      "epoch:29 step:140530[D loss: 0.999999] [G loss: 1.000048]\n",
      "epoch:29 step:140535[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:29 step:140540[D loss: 1.000003] [G loss: 1.000082]\n",
      "epoch:29 step:140545[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:29 step:140550[D loss: 0.999943] [G loss: 1.000118]\n",
      "epoch:30 step:140555[D loss: 1.000010] [G loss: 1.000048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:140560[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:30 step:140565[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:30 step:140570[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:30 step:140575[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:30 step:140580[D loss: 1.000000] [G loss: 1.000033]\n",
      "epoch:30 step:140585[D loss: 0.999945] [G loss: 1.000103]\n",
      "epoch:30 step:140590[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:30 step:140595[D loss: 1.000057] [G loss: 0.999894]\n",
      "epoch:30 step:140600[D loss: 0.999966] [G loss: 1.000152]\n",
      "epoch:30 step:140605[D loss: 0.999900] [G loss: 1.000195]\n",
      "epoch:30 step:140610[D loss: 0.999912] [G loss: 1.000083]\n",
      "epoch:30 step:140615[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:30 step:140620[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:30 step:140625[D loss: 1.000077] [G loss: 0.999938]\n",
      "epoch:30 step:140630[D loss: 0.999929] [G loss: 1.000113]\n",
      "epoch:30 step:140635[D loss: 1.000008] [G loss: 1.000057]\n",
      "epoch:30 step:140640[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:30 step:140645[D loss: 1.000006] [G loss: 0.999985]\n",
      "epoch:30 step:140650[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:30 step:140655[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:30 step:140660[D loss: 1.000039] [G loss: 0.999989]\n",
      "epoch:30 step:140665[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:30 step:140670[D loss: 1.000018] [G loss: 1.000063]\n",
      "epoch:30 step:140675[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:30 step:140680[D loss: 0.999918] [G loss: 1.000168]\n",
      "epoch:30 step:140685[D loss: 1.000098] [G loss: 1.000084]\n",
      "epoch:30 step:140690[D loss: 0.999922] [G loss: 1.000138]\n",
      "epoch:30 step:140695[D loss: 0.999996] [G loss: 1.000058]\n",
      "epoch:30 step:140700[D loss: 1.000053] [G loss: 0.999843]\n",
      "epoch:30 step:140705[D loss: 0.999988] [G loss: 0.999971]\n",
      "epoch:30 step:140710[D loss: 0.999965] [G loss: 1.000039]\n",
      "epoch:30 step:140715[D loss: 0.999964] [G loss: 1.000042]\n",
      "epoch:30 step:140720[D loss: 1.000001] [G loss: 1.000075]\n",
      "epoch:30 step:140725[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:30 step:140730[D loss: 1.000071] [G loss: 0.999968]\n",
      "epoch:30 step:140735[D loss: 0.999988] [G loss: 1.000142]\n",
      "epoch:30 step:140740[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:30 step:140745[D loss: 1.000000] [G loss: 0.999981]\n",
      "epoch:30 step:140750[D loss: 1.000268] [G loss: 0.999678]\n",
      "epoch:30 step:140755[D loss: 0.999935] [G loss: 1.000088]\n",
      "epoch:30 step:140760[D loss: 0.999963] [G loss: 1.000024]\n",
      "epoch:30 step:140765[D loss: 0.999988] [G loss: 1.000059]\n",
      "epoch:30 step:140770[D loss: 0.999954] [G loss: 1.000024]\n",
      "epoch:30 step:140775[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:30 step:140780[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:30 step:140785[D loss: 0.999948] [G loss: 1.000079]\n",
      "epoch:30 step:140790[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:30 step:140795[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:30 step:140800[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:30 step:140805[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:30 step:140810[D loss: 1.000005] [G loss: 1.000033]\n",
      "epoch:30 step:140815[D loss: 0.999989] [G loss: 1.000060]\n",
      "epoch:30 step:140820[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:30 step:140825[D loss: 1.000011] [G loss: 1.000018]\n",
      "epoch:30 step:140830[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:30 step:140835[D loss: 0.999981] [G loss: 1.000089]\n",
      "epoch:30 step:140840[D loss: 0.999934] [G loss: 1.000146]\n",
      "epoch:30 step:140845[D loss: 0.999955] [G loss: 1.000120]\n",
      "epoch:30 step:140850[D loss: 0.999976] [G loss: 1.000008]\n",
      "epoch:30 step:140855[D loss: 0.999937] [G loss: 1.000081]\n",
      "epoch:30 step:140860[D loss: 1.000033] [G loss: 0.999986]\n",
      "epoch:30 step:140865[D loss: 1.000099] [G loss: 0.999938]\n",
      "epoch:30 step:140870[D loss: 1.000021] [G loss: 1.000036]\n",
      "epoch:30 step:140875[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:30 step:140880[D loss: 1.000033] [G loss: 0.999984]\n",
      "epoch:30 step:140885[D loss: 0.999993] [G loss: 0.999990]\n",
      "epoch:30 step:140890[D loss: 0.999938] [G loss: 1.000133]\n",
      "epoch:30 step:140895[D loss: 1.000025] [G loss: 1.000091]\n",
      "epoch:30 step:140900[D loss: 0.999960] [G loss: 1.000124]\n",
      "epoch:30 step:140905[D loss: 1.000024] [G loss: 1.000006]\n",
      "epoch:30 step:140910[D loss: 1.000058] [G loss: 1.000038]\n",
      "epoch:30 step:140915[D loss: 1.000008] [G loss: 1.000022]\n",
      "epoch:30 step:140920[D loss: 1.000051] [G loss: 0.999999]\n",
      "epoch:30 step:140925[D loss: 1.000071] [G loss: 0.999946]\n",
      "epoch:30 step:140930[D loss: 0.999974] [G loss: 1.000114]\n",
      "epoch:30 step:140935[D loss: 0.999939] [G loss: 1.000225]\n",
      "epoch:30 step:140940[D loss: 0.999953] [G loss: 1.000213]\n",
      "epoch:30 step:140945[D loss: 0.999931] [G loss: 1.000166]\n",
      "epoch:30 step:140950[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:30 step:140955[D loss: 1.000016] [G loss: 1.000048]\n",
      "epoch:30 step:140960[D loss: 1.000028] [G loss: 1.000021]\n",
      "epoch:30 step:140965[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:30 step:140970[D loss: 0.999904] [G loss: 1.000152]\n",
      "epoch:30 step:140975[D loss: 0.999954] [G loss: 1.000134]\n",
      "epoch:30 step:140980[D loss: 0.999962] [G loss: 1.000063]\n",
      "epoch:30 step:140985[D loss: 0.999983] [G loss: 1.000058]\n",
      "epoch:30 step:140990[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:30 step:140995[D loss: 1.000007] [G loss: 1.000129]\n",
      "epoch:30 step:141000[D loss: 0.999955] [G loss: 1.000112]\n",
      "epoch:30 step:141005[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:30 step:141010[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:30 step:141015[D loss: 1.000039] [G loss: 0.999995]\n",
      "epoch:30 step:141020[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:30 step:141025[D loss: 0.999986] [G loss: 1.000123]\n",
      "epoch:30 step:141030[D loss: 1.000012] [G loss: 1.000063]\n",
      "epoch:30 step:141035[D loss: 0.999986] [G loss: 1.000190]\n",
      "epoch:30 step:141040[D loss: 1.000024] [G loss: 1.000079]\n",
      "epoch:30 step:141045[D loss: 0.999986] [G loss: 1.000091]\n",
      "epoch:30 step:141050[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:30 step:141055[D loss: 1.000062] [G loss: 0.999941]\n",
      "epoch:30 step:141060[D loss: 0.999951] [G loss: 1.000008]\n",
      "epoch:30 step:141065[D loss: 1.000068] [G loss: 0.999960]\n",
      "epoch:30 step:141070[D loss: 0.999879] [G loss: 1.000214]\n",
      "epoch:30 step:141075[D loss: 0.999984] [G loss: 1.000113]\n",
      "epoch:30 step:141080[D loss: 0.999992] [G loss: 0.999991]\n",
      "epoch:30 step:141085[D loss: 1.000142] [G loss: 0.999919]\n",
      "epoch:30 step:141090[D loss: 0.999971] [G loss: 1.000211]\n",
      "epoch:30 step:141095[D loss: 0.999907] [G loss: 1.000091]\n",
      "epoch:30 step:141100[D loss: 0.999992] [G loss: 1.000081]\n",
      "epoch:30 step:141105[D loss: 0.999972] [G loss: 1.000089]\n",
      "epoch:30 step:141110[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:30 step:141115[D loss: 0.999982] [G loss: 1.000071]\n",
      "epoch:30 step:141120[D loss: 0.999961] [G loss: 1.000064]\n",
      "epoch:30 step:141125[D loss: 0.999980] [G loss: 1.000010]\n",
      "epoch:30 step:141130[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:30 step:141135[D loss: 1.000118] [G loss: 1.000003]\n",
      "epoch:30 step:141140[D loss: 0.999917] [G loss: 1.000412]\n",
      "epoch:30 step:141145[D loss: 1.000056] [G loss: 1.000120]\n",
      "epoch:30 step:141150[D loss: 0.999826] [G loss: 1.000240]\n",
      "epoch:30 step:141155[D loss: 0.999998] [G loss: 1.000117]\n",
      "epoch:30 step:141160[D loss: 0.999958] [G loss: 1.000130]\n",
      "epoch:30 step:141165[D loss: 0.999954] [G loss: 1.000099]\n",
      "epoch:30 step:141170[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:30 step:141175[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:30 step:141180[D loss: 0.999973] [G loss: 0.999987]\n",
      "epoch:30 step:141185[D loss: 1.000039] [G loss: 0.999919]\n",
      "epoch:30 step:141190[D loss: 1.000000] [G loss: 1.000019]\n",
      "epoch:30 step:141195[D loss: 1.000043] [G loss: 0.999917]\n",
      "epoch:30 step:141200[D loss: 0.999876] [G loss: 1.000117]\n",
      "epoch:30 step:141205[D loss: 0.999968] [G loss: 1.000100]\n",
      "epoch:30 step:141210[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:30 step:141215[D loss: 0.999945] [G loss: 1.000108]\n",
      "epoch:30 step:141220[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:30 step:141225[D loss: 0.999993] [G loss: 1.000047]\n",
      "epoch:30 step:141230[D loss: 1.000011] [G loss: 1.000016]\n",
      "epoch:30 step:141235[D loss: 1.000018] [G loss: 1.000028]\n",
      "epoch:30 step:141240[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:30 step:141245[D loss: 0.999958] [G loss: 1.000025]\n",
      "epoch:30 step:141250[D loss: 1.000028] [G loss: 1.000030]\n",
      "epoch:30 step:141255[D loss: 1.000016] [G loss: 1.000117]\n",
      "epoch:30 step:141260[D loss: 0.999839] [G loss: 1.000279]\n",
      "epoch:30 step:141265[D loss: 0.999896] [G loss: 1.000149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:141270[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:30 step:141275[D loss: 0.999924] [G loss: 1.000157]\n",
      "epoch:30 step:141280[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:30 step:141285[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:30 step:141290[D loss: 0.999930] [G loss: 1.000175]\n",
      "epoch:30 step:141295[D loss: 1.000056] [G loss: 1.000039]\n",
      "epoch:30 step:141300[D loss: 1.000001] [G loss: 0.999990]\n",
      "epoch:30 step:141305[D loss: 0.999964] [G loss: 1.000036]\n",
      "epoch:30 step:141310[D loss: 0.999922] [G loss: 1.000125]\n",
      "epoch:30 step:141315[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:30 step:141320[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:30 step:141325[D loss: 0.999985] [G loss: 1.000094]\n",
      "epoch:30 step:141330[D loss: 1.000022] [G loss: 1.000120]\n",
      "epoch:30 step:141335[D loss: 0.999890] [G loss: 1.000101]\n",
      "epoch:30 step:141340[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:30 step:141345[D loss: 0.999980] [G loss: 1.000087]\n",
      "epoch:30 step:141350[D loss: 1.000007] [G loss: 0.999997]\n",
      "epoch:30 step:141355[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:30 step:141360[D loss: 1.000026] [G loss: 1.000024]\n",
      "epoch:30 step:141365[D loss: 0.999964] [G loss: 1.000049]\n",
      "epoch:30 step:141370[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:30 step:141375[D loss: 0.999994] [G loss: 1.000085]\n",
      "epoch:30 step:141380[D loss: 0.999940] [G loss: 1.000120]\n",
      "epoch:30 step:141385[D loss: 0.999941] [G loss: 1.000094]\n",
      "epoch:30 step:141390[D loss: 1.000005] [G loss: 1.000119]\n",
      "epoch:30 step:141395[D loss: 1.000022] [G loss: 0.999970]\n",
      "epoch:30 step:141400[D loss: 1.000043] [G loss: 0.999970]\n",
      "epoch:30 step:141405[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:30 step:141410[D loss: 0.999977] [G loss: 1.000012]\n",
      "epoch:30 step:141415[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:30 step:141420[D loss: 0.999987] [G loss: 1.000026]\n",
      "epoch:30 step:141425[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:30 step:141430[D loss: 0.999968] [G loss: 1.000087]\n",
      "epoch:30 step:141435[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:30 step:141440[D loss: 0.999976] [G loss: 1.000076]\n",
      "epoch:30 step:141445[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:30 step:141450[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:30 step:141455[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:30 step:141460[D loss: 0.999927] [G loss: 1.000148]\n",
      "epoch:30 step:141465[D loss: 1.000006] [G loss: 1.000032]\n",
      "epoch:30 step:141470[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:30 step:141475[D loss: 1.000085] [G loss: 0.999930]\n",
      "epoch:30 step:141480[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:30 step:141485[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:30 step:141490[D loss: 1.000040] [G loss: 0.999991]\n",
      "epoch:30 step:141495[D loss: 0.999983] [G loss: 1.000076]\n",
      "epoch:30 step:141500[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:30 step:141505[D loss: 0.999994] [G loss: 1.000034]\n",
      "epoch:30 step:141510[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:30 step:141515[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:30 step:141520[D loss: 0.999999] [G loss: 1.000073]\n",
      "epoch:30 step:141525[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:30 step:141530[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:30 step:141535[D loss: 1.000018] [G loss: 1.000067]\n",
      "epoch:30 step:141540[D loss: 1.000085] [G loss: 1.000066]\n",
      "epoch:30 step:141545[D loss: 0.999850] [G loss: 1.000302]\n",
      "epoch:30 step:141550[D loss: 0.999989] [G loss: 1.000299]\n",
      "epoch:30 step:141555[D loss: 1.000003] [G loss: 1.000093]\n",
      "epoch:30 step:141560[D loss: 0.999934] [G loss: 1.000138]\n",
      "epoch:30 step:141565[D loss: 0.999988] [G loss: 0.999967]\n",
      "epoch:30 step:141570[D loss: 1.000017] [G loss: 0.999980]\n",
      "epoch:30 step:141575[D loss: 0.999994] [G loss: 0.999881]\n",
      "epoch:30 step:141580[D loss: 1.000083] [G loss: 0.999841]\n",
      "epoch:30 step:141585[D loss: 0.999905] [G loss: 1.000149]\n",
      "epoch:30 step:141590[D loss: 0.999917] [G loss: 1.000033]\n",
      "epoch:30 step:141595[D loss: 1.000122] [G loss: 0.999879]\n",
      "epoch:30 step:141600[D loss: 0.999972] [G loss: 1.000084]\n",
      "epoch:30 step:141605[D loss: 1.000026] [G loss: 0.999974]\n",
      "epoch:30 step:141610[D loss: 0.999950] [G loss: 1.000129]\n",
      "epoch:30 step:141615[D loss: 0.999982] [G loss: 1.000118]\n",
      "epoch:30 step:141620[D loss: 1.000036] [G loss: 1.000044]\n",
      "epoch:30 step:141625[D loss: 0.999965] [G loss: 1.000132]\n",
      "epoch:30 step:141630[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:30 step:141635[D loss: 1.000001] [G loss: 1.000307]\n",
      "epoch:30 step:141640[D loss: 0.999965] [G loss: 1.000136]\n",
      "epoch:30 step:141645[D loss: 0.999919] [G loss: 1.000099]\n",
      "epoch:30 step:141650[D loss: 1.000017] [G loss: 1.000025]\n",
      "epoch:30 step:141655[D loss: 1.000035] [G loss: 0.999942]\n",
      "epoch:30 step:141660[D loss: 1.000010] [G loss: 1.000061]\n",
      "epoch:30 step:141665[D loss: 1.000068] [G loss: 1.000006]\n",
      "epoch:30 step:141670[D loss: 0.999936] [G loss: 1.000042]\n",
      "epoch:30 step:141675[D loss: 1.000042] [G loss: 1.000043]\n",
      "epoch:30 step:141680[D loss: 1.000024] [G loss: 1.000216]\n",
      "epoch:30 step:141685[D loss: 1.000094] [G loss: 1.000022]\n",
      "epoch:30 step:141690[D loss: 0.999941] [G loss: 1.000139]\n",
      "epoch:30 step:141695[D loss: 0.999873] [G loss: 1.000216]\n",
      "epoch:30 step:141700[D loss: 1.000013] [G loss: 1.000131]\n",
      "epoch:30 step:141705[D loss: 0.999896] [G loss: 1.000166]\n",
      "epoch:30 step:141710[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:30 step:141715[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:30 step:141720[D loss: 0.999999] [G loss: 1.000095]\n",
      "epoch:30 step:141725[D loss: 0.999916] [G loss: 1.000243]\n",
      "epoch:30 step:141730[D loss: 0.999955] [G loss: 1.000104]\n",
      "epoch:30 step:141735[D loss: 1.000001] [G loss: 1.000020]\n",
      "epoch:30 step:141740[D loss: 0.999966] [G loss: 1.000030]\n",
      "epoch:30 step:141745[D loss: 1.000018] [G loss: 0.999931]\n",
      "epoch:30 step:141750[D loss: 1.000032] [G loss: 1.000079]\n",
      "epoch:30 step:141755[D loss: 1.000034] [G loss: 1.000028]\n",
      "epoch:30 step:141760[D loss: 0.999883] [G loss: 1.000157]\n",
      "epoch:30 step:141765[D loss: 1.000030] [G loss: 0.999960]\n",
      "epoch:30 step:141770[D loss: 0.999905] [G loss: 1.000276]\n",
      "epoch:30 step:141775[D loss: 0.999938] [G loss: 1.000113]\n",
      "epoch:30 step:141780[D loss: 1.000029] [G loss: 1.000029]\n",
      "epoch:30 step:141785[D loss: 1.000018] [G loss: 1.000009]\n",
      "epoch:30 step:141790[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:30 step:141795[D loss: 0.999951] [G loss: 1.000066]\n",
      "epoch:30 step:141800[D loss: 0.999998] [G loss: 0.999983]\n",
      "epoch:30 step:141805[D loss: 1.000020] [G loss: 1.000036]\n",
      "epoch:30 step:141810[D loss: 0.999970] [G loss: 1.000094]\n",
      "epoch:30 step:141815[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:30 step:141820[D loss: 0.999996] [G loss: 1.000068]\n",
      "epoch:30 step:141825[D loss: 1.000022] [G loss: 1.000075]\n",
      "epoch:30 step:141830[D loss: 1.000008] [G loss: 1.000061]\n",
      "epoch:30 step:141835[D loss: 1.000017] [G loss: 1.000031]\n",
      "epoch:30 step:141840[D loss: 0.999993] [G loss: 1.000081]\n",
      "epoch:30 step:141845[D loss: 0.999981] [G loss: 1.000057]\n",
      "epoch:30 step:141850[D loss: 1.000009] [G loss: 1.000053]\n",
      "epoch:30 step:141855[D loss: 0.999964] [G loss: 1.000064]\n",
      "epoch:30 step:141860[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:30 step:141865[D loss: 1.000035] [G loss: 1.000028]\n",
      "epoch:30 step:141870[D loss: 0.999974] [G loss: 1.000016]\n",
      "epoch:30 step:141875[D loss: 0.999948] [G loss: 1.000096]\n",
      "epoch:30 step:141880[D loss: 1.000047] [G loss: 1.000012]\n",
      "epoch:30 step:141885[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:30 step:141890[D loss: 0.999947] [G loss: 1.000026]\n",
      "epoch:30 step:141895[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:30 step:141900[D loss: 0.999982] [G loss: 1.000083]\n",
      "epoch:30 step:141905[D loss: 0.999948] [G loss: 1.000100]\n",
      "epoch:30 step:141910[D loss: 1.000068] [G loss: 0.999997]\n",
      "epoch:30 step:141915[D loss: 0.999987] [G loss: 1.000107]\n",
      "epoch:30 step:141920[D loss: 0.999988] [G loss: 1.000030]\n",
      "epoch:30 step:141925[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:30 step:141930[D loss: 1.000005] [G loss: 1.000029]\n",
      "epoch:30 step:141935[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:30 step:141940[D loss: 0.999981] [G loss: 1.000112]\n",
      "epoch:30 step:141945[D loss: 0.999938] [G loss: 1.000140]\n",
      "epoch:30 step:141950[D loss: 0.999939] [G loss: 1.000127]\n",
      "epoch:30 step:141955[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:30 step:141960[D loss: 0.999953] [G loss: 1.000106]\n",
      "epoch:30 step:141965[D loss: 0.999938] [G loss: 1.000102]\n",
      "epoch:30 step:141970[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:30 step:141975[D loss: 1.000028] [G loss: 0.999982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:141980[D loss: 0.999963] [G loss: 1.000036]\n",
      "epoch:30 step:141985[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:30 step:141990[D loss: 1.000025] [G loss: 1.000019]\n",
      "epoch:30 step:141995[D loss: 1.000003] [G loss: 1.000019]\n",
      "epoch:30 step:142000[D loss: 0.999972] [G loss: 1.000025]\n",
      "epoch:30 step:142005[D loss: 0.999985] [G loss: 1.000009]\n",
      "epoch:30 step:142010[D loss: 0.999958] [G loss: 1.000054]\n",
      "epoch:30 step:142015[D loss: 1.000018] [G loss: 0.999980]\n",
      "epoch:30 step:142020[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:30 step:142025[D loss: 1.000037] [G loss: 0.999921]\n",
      "epoch:30 step:142030[D loss: 0.999944] [G loss: 1.000091]\n",
      "epoch:30 step:142035[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:30 step:142040[D loss: 0.999974] [G loss: 1.000092]\n",
      "epoch:30 step:142045[D loss: 0.999966] [G loss: 1.000032]\n",
      "epoch:30 step:142050[D loss: 1.000004] [G loss: 0.999956]\n",
      "epoch:30 step:142055[D loss: 0.999947] [G loss: 1.000073]\n",
      "epoch:30 step:142060[D loss: 1.000025] [G loss: 0.999976]\n",
      "epoch:30 step:142065[D loss: 1.000059] [G loss: 0.999976]\n",
      "epoch:30 step:142070[D loss: 0.999886] [G loss: 1.000104]\n",
      "epoch:30 step:142075[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:30 step:142080[D loss: 0.999979] [G loss: 1.000084]\n",
      "epoch:30 step:142085[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:30 step:142090[D loss: 1.000008] [G loss: 1.000001]\n",
      "epoch:30 step:142095[D loss: 1.000032] [G loss: 1.000014]\n",
      "epoch:30 step:142100[D loss: 1.000051] [G loss: 0.999974]\n",
      "epoch:30 step:142105[D loss: 0.999936] [G loss: 1.000147]\n",
      "epoch:30 step:142110[D loss: 0.999934] [G loss: 1.000069]\n",
      "epoch:30 step:142115[D loss: 0.999944] [G loss: 1.000040]\n",
      "epoch:30 step:142120[D loss: 0.999973] [G loss: 1.000025]\n",
      "epoch:30 step:142125[D loss: 0.999963] [G loss: 1.000037]\n",
      "epoch:30 step:142130[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:30 step:142135[D loss: 1.000063] [G loss: 0.999963]\n",
      "epoch:30 step:142140[D loss: 1.000007] [G loss: 0.999949]\n",
      "epoch:30 step:142145[D loss: 0.999941] [G loss: 1.000004]\n",
      "epoch:30 step:142150[D loss: 0.999993] [G loss: 1.000062]\n",
      "epoch:30 step:142155[D loss: 1.000100] [G loss: 0.999965]\n",
      "epoch:30 step:142160[D loss: 1.000098] [G loss: 0.999990]\n",
      "epoch:30 step:142165[D loss: 0.999955] [G loss: 1.000215]\n",
      "epoch:30 step:142170[D loss: 1.000019] [G loss: 0.999998]\n",
      "epoch:30 step:142175[D loss: 1.000028] [G loss: 0.999850]\n",
      "epoch:30 step:142180[D loss: 1.000106] [G loss: 0.999942]\n",
      "epoch:30 step:142185[D loss: 1.000091] [G loss: 0.999929]\n",
      "epoch:30 step:142190[D loss: 0.999827] [G loss: 1.000130]\n",
      "epoch:30 step:142195[D loss: 1.000025] [G loss: 0.999952]\n",
      "epoch:30 step:142200[D loss: 0.999915] [G loss: 1.000086]\n",
      "epoch:30 step:142205[D loss: 0.999929] [G loss: 1.000146]\n",
      "epoch:30 step:142210[D loss: 0.999942] [G loss: 1.000134]\n",
      "epoch:30 step:142215[D loss: 1.000042] [G loss: 1.000005]\n",
      "epoch:30 step:142220[D loss: 0.999973] [G loss: 1.000029]\n",
      "epoch:30 step:142225[D loss: 1.000019] [G loss: 1.000001]\n",
      "epoch:30 step:142230[D loss: 1.000014] [G loss: 1.000024]\n",
      "epoch:30 step:142235[D loss: 1.000051] [G loss: 0.999988]\n",
      "epoch:30 step:142240[D loss: 0.999960] [G loss: 1.000047]\n",
      "epoch:30 step:142245[D loss: 0.999963] [G loss: 1.000052]\n",
      "epoch:30 step:142250[D loss: 0.999923] [G loss: 1.000067]\n",
      "epoch:30 step:142255[D loss: 1.000023] [G loss: 0.999975]\n",
      "epoch:30 step:142260[D loss: 0.999894] [G loss: 1.000163]\n",
      "epoch:30 step:142265[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:30 step:142270[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:30 step:142275[D loss: 1.000063] [G loss: 0.999971]\n",
      "epoch:30 step:142280[D loss: 1.000027] [G loss: 0.999990]\n",
      "epoch:30 step:142285[D loss: 0.999924] [G loss: 1.000088]\n",
      "epoch:30 step:142290[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:30 step:142295[D loss: 1.000058] [G loss: 0.999991]\n",
      "epoch:30 step:142300[D loss: 0.999953] [G loss: 1.000059]\n",
      "epoch:30 step:142305[D loss: 1.000055] [G loss: 1.000037]\n",
      "epoch:30 step:142310[D loss: 1.000088] [G loss: 1.000023]\n",
      "epoch:30 step:142315[D loss: 0.999958] [G loss: 1.000142]\n",
      "epoch:30 step:142320[D loss: 0.999918] [G loss: 1.000155]\n",
      "epoch:30 step:142325[D loss: 1.000017] [G loss: 1.000001]\n",
      "epoch:30 step:142330[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:30 step:142335[D loss: 0.999972] [G loss: 1.000080]\n",
      "epoch:30 step:142340[D loss: 1.000087] [G loss: 0.999941]\n",
      "epoch:30 step:142345[D loss: 0.999957] [G loss: 1.000079]\n",
      "epoch:30 step:142350[D loss: 1.000120] [G loss: 0.999873]\n",
      "epoch:30 step:142355[D loss: 0.999844] [G loss: 1.000188]\n",
      "epoch:30 step:142360[D loss: 0.999954] [G loss: 1.000084]\n",
      "epoch:30 step:142365[D loss: 0.999964] [G loss: 1.000092]\n",
      "epoch:30 step:142370[D loss: 1.000085] [G loss: 0.999977]\n",
      "epoch:30 step:142375[D loss: 1.000031] [G loss: 0.999954]\n",
      "epoch:30 step:142380[D loss: 0.999960] [G loss: 1.000114]\n",
      "epoch:30 step:142385[D loss: 1.000032] [G loss: 1.000080]\n",
      "epoch:30 step:142390[D loss: 1.000016] [G loss: 1.000103]\n",
      "epoch:30 step:142395[D loss: 0.999925] [G loss: 1.000158]\n",
      "epoch:30 step:142400[D loss: 0.999948] [G loss: 1.000088]\n",
      "epoch:30 step:142405[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:30 step:142410[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:30 step:142415[D loss: 0.999971] [G loss: 1.000054]\n",
      "epoch:30 step:142420[D loss: 1.000024] [G loss: 1.000085]\n",
      "epoch:30 step:142425[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:30 step:142430[D loss: 1.000044] [G loss: 0.999920]\n",
      "epoch:30 step:142435[D loss: 1.000023] [G loss: 1.000006]\n",
      "epoch:30 step:142440[D loss: 1.000147] [G loss: 1.000045]\n",
      "epoch:30 step:142445[D loss: 1.000028] [G loss: 0.999918]\n",
      "epoch:30 step:142450[D loss: 0.999875] [G loss: 1.000151]\n",
      "epoch:30 step:142455[D loss: 0.999932] [G loss: 1.000079]\n",
      "epoch:30 step:142460[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:30 step:142465[D loss: 1.000121] [G loss: 0.999766]\n",
      "epoch:30 step:142470[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:30 step:142475[D loss: 1.000062] [G loss: 1.000043]\n",
      "epoch:30 step:142480[D loss: 0.999881] [G loss: 1.000085]\n",
      "epoch:30 step:142485[D loss: 1.000062] [G loss: 1.000081]\n",
      "epoch:30 step:142490[D loss: 0.999837] [G loss: 1.000340]\n",
      "epoch:30 step:142495[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:30 step:142500[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:30 step:142505[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:30 step:142510[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:30 step:142515[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:30 step:142520[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:30 step:142525[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:30 step:142530[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:30 step:142535[D loss: 0.999943] [G loss: 1.000149]\n",
      "epoch:30 step:142540[D loss: 0.999903] [G loss: 1.000184]\n",
      "epoch:30 step:142545[D loss: 1.000116] [G loss: 0.999795]\n",
      "epoch:30 step:142550[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:30 step:142555[D loss: 1.000002] [G loss: 1.000091]\n",
      "epoch:30 step:142560[D loss: 0.999968] [G loss: 1.000072]\n",
      "epoch:30 step:142565[D loss: 0.999970] [G loss: 1.000113]\n",
      "epoch:30 step:142570[D loss: 1.000002] [G loss: 1.000100]\n",
      "epoch:30 step:142575[D loss: 1.000045] [G loss: 1.000008]\n",
      "epoch:30 step:142580[D loss: 0.999964] [G loss: 0.999965]\n",
      "epoch:30 step:142585[D loss: 1.000120] [G loss: 1.000018]\n",
      "epoch:30 step:142590[D loss: 0.999941] [G loss: 1.000047]\n",
      "epoch:30 step:142595[D loss: 0.999943] [G loss: 1.000166]\n",
      "epoch:30 step:142600[D loss: 1.000061] [G loss: 1.000103]\n",
      "epoch:30 step:142605[D loss: 0.999886] [G loss: 1.000140]\n",
      "epoch:30 step:142610[D loss: 1.000105] [G loss: 0.999856]\n",
      "epoch:30 step:142615[D loss: 1.000099] [G loss: 0.999848]\n",
      "epoch:30 step:142620[D loss: 0.999936] [G loss: 1.000101]\n",
      "epoch:30 step:142625[D loss: 0.999893] [G loss: 1.000079]\n",
      "epoch:30 step:142630[D loss: 0.999964] [G loss: 1.000036]\n",
      "epoch:30 step:142635[D loss: 0.999957] [G loss: 1.000081]\n",
      "epoch:30 step:142640[D loss: 0.999985] [G loss: 1.000060]\n",
      "epoch:30 step:142645[D loss: 0.999945] [G loss: 1.000114]\n",
      "epoch:30 step:142650[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:30 step:142655[D loss: 0.999981] [G loss: 1.000108]\n",
      "epoch:30 step:142660[D loss: 1.000001] [G loss: 1.000081]\n",
      "epoch:30 step:142665[D loss: 0.999941] [G loss: 1.000111]\n",
      "epoch:30 step:142670[D loss: 0.999976] [G loss: 1.000151]\n",
      "epoch:30 step:142675[D loss: 0.999926] [G loss: 1.000157]\n",
      "epoch:30 step:142680[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:30 step:142685[D loss: 0.999940] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:142690[D loss: 0.999961] [G loss: 1.000073]\n",
      "epoch:30 step:142695[D loss: 0.999952] [G loss: 1.000040]\n",
      "epoch:30 step:142700[D loss: 0.999926] [G loss: 1.000121]\n",
      "epoch:30 step:142705[D loss: 0.999932] [G loss: 1.000051]\n",
      "epoch:30 step:142710[D loss: 0.999947] [G loss: 1.000126]\n",
      "epoch:30 step:142715[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:30 step:142720[D loss: 1.000007] [G loss: 1.000027]\n",
      "epoch:30 step:142725[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:30 step:142730[D loss: 1.000073] [G loss: 0.999968]\n",
      "epoch:30 step:142735[D loss: 0.999889] [G loss: 1.000152]\n",
      "epoch:30 step:142740[D loss: 0.999897] [G loss: 1.000179]\n",
      "epoch:30 step:142745[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:30 step:142750[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:30 step:142755[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:30 step:142760[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:30 step:142765[D loss: 0.999992] [G loss: 1.000036]\n",
      "epoch:30 step:142770[D loss: 0.999982] [G loss: 1.000055]\n",
      "epoch:30 step:142775[D loss: 0.999952] [G loss: 1.000134]\n",
      "epoch:30 step:142780[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:30 step:142785[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:30 step:142790[D loss: 1.000070] [G loss: 0.999937]\n",
      "epoch:30 step:142795[D loss: 0.999988] [G loss: 1.000021]\n",
      "epoch:30 step:142800[D loss: 0.999970] [G loss: 1.000112]\n",
      "epoch:30 step:142805[D loss: 0.999970] [G loss: 1.000081]\n",
      "epoch:30 step:142810[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:30 step:142815[D loss: 0.999953] [G loss: 1.000109]\n",
      "epoch:30 step:142820[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:30 step:142825[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:30 step:142830[D loss: 0.999938] [G loss: 1.000067]\n",
      "epoch:30 step:142835[D loss: 1.000052] [G loss: 0.999986]\n",
      "epoch:30 step:142840[D loss: 0.999975] [G loss: 1.000119]\n",
      "epoch:30 step:142845[D loss: 1.000086] [G loss: 1.000194]\n",
      "epoch:30 step:142850[D loss: 0.999802] [G loss: 1.000270]\n",
      "epoch:30 step:142855[D loss: 0.999939] [G loss: 1.000089]\n",
      "epoch:30 step:142860[D loss: 0.999985] [G loss: 1.000027]\n",
      "epoch:30 step:142865[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:30 step:142870[D loss: 1.000059] [G loss: 0.999974]\n",
      "epoch:30 step:142875[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:30 step:142880[D loss: 0.999950] [G loss: 1.000051]\n",
      "epoch:30 step:142885[D loss: 0.999957] [G loss: 1.000058]\n",
      "epoch:30 step:142890[D loss: 0.999984] [G loss: 1.000117]\n",
      "epoch:30 step:142895[D loss: 0.999960] [G loss: 1.000165]\n",
      "epoch:30 step:142900[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:30 step:142905[D loss: 0.999973] [G loss: 1.000043]\n",
      "epoch:30 step:142910[D loss: 0.999970] [G loss: 1.000093]\n",
      "epoch:30 step:142915[D loss: 0.999994] [G loss: 1.000010]\n",
      "epoch:30 step:142920[D loss: 1.000044] [G loss: 1.000051]\n",
      "epoch:30 step:142925[D loss: 0.999975] [G loss: 0.999998]\n",
      "epoch:30 step:142930[D loss: 0.999975] [G loss: 1.000032]\n",
      "epoch:30 step:142935[D loss: 0.999963] [G loss: 1.000063]\n",
      "epoch:30 step:142940[D loss: 1.000107] [G loss: 0.999901]\n",
      "epoch:30 step:142945[D loss: 0.999928] [G loss: 1.000084]\n",
      "epoch:30 step:142950[D loss: 0.999975] [G loss: 1.000076]\n",
      "epoch:30 step:142955[D loss: 0.999937] [G loss: 1.000079]\n",
      "epoch:30 step:142960[D loss: 1.000055] [G loss: 0.999846]\n",
      "epoch:30 step:142965[D loss: 1.000001] [G loss: 0.999990]\n",
      "epoch:30 step:142970[D loss: 1.000045] [G loss: 1.000025]\n",
      "epoch:30 step:142975[D loss: 1.000083] [G loss: 1.000045]\n",
      "epoch:30 step:142980[D loss: 0.999888] [G loss: 1.000129]\n",
      "epoch:30 step:142985[D loss: 0.999806] [G loss: 1.000376]\n",
      "epoch:30 step:142990[D loss: 1.000078] [G loss: 1.000140]\n",
      "epoch:30 step:142995[D loss: 0.999998] [G loss: 1.000168]\n",
      "epoch:30 step:143000[D loss: 0.999954] [G loss: 1.000261]\n",
      "epoch:30 step:143005[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:30 step:143010[D loss: 0.999999] [G loss: 1.000111]\n",
      "epoch:30 step:143015[D loss: 1.000022] [G loss: 1.000190]\n",
      "epoch:30 step:143020[D loss: 1.000026] [G loss: 1.000068]\n",
      "epoch:30 step:143025[D loss: 1.000022] [G loss: 0.999993]\n",
      "epoch:30 step:143030[D loss: 0.999964] [G loss: 1.000105]\n",
      "epoch:30 step:143035[D loss: 0.999989] [G loss: 1.000051]\n",
      "epoch:30 step:143040[D loss: 1.000069] [G loss: 0.999953]\n",
      "epoch:30 step:143045[D loss: 1.000086] [G loss: 0.999988]\n",
      "epoch:30 step:143050[D loss: 1.000170] [G loss: 0.999900]\n",
      "epoch:30 step:143055[D loss: 0.999985] [G loss: 0.999897]\n",
      "epoch:30 step:143060[D loss: 0.999841] [G loss: 1.000264]\n",
      "epoch:30 step:143065[D loss: 0.999957] [G loss: 1.000111]\n",
      "epoch:30 step:143070[D loss: 0.999913] [G loss: 1.000202]\n",
      "epoch:30 step:143075[D loss: 0.999942] [G loss: 1.000114]\n",
      "epoch:30 step:143080[D loss: 0.999967] [G loss: 1.000063]\n",
      "epoch:30 step:143085[D loss: 1.000018] [G loss: 1.000111]\n",
      "epoch:30 step:143090[D loss: 0.999946] [G loss: 1.000201]\n",
      "epoch:30 step:143095[D loss: 0.999968] [G loss: 1.000099]\n",
      "epoch:30 step:143100[D loss: 0.999969] [G loss: 1.000397]\n",
      "epoch:30 step:143105[D loss: 0.999948] [G loss: 1.000181]\n",
      "epoch:30 step:143110[D loss: 0.999952] [G loss: 1.000081]\n",
      "epoch:30 step:143115[D loss: 1.000024] [G loss: 0.999998]\n",
      "epoch:30 step:143120[D loss: 1.000027] [G loss: 0.999979]\n",
      "epoch:30 step:143125[D loss: 0.999960] [G loss: 1.000066]\n",
      "epoch:30 step:143130[D loss: 0.999942] [G loss: 1.000089]\n",
      "epoch:30 step:143135[D loss: 1.000107] [G loss: 0.999992]\n",
      "epoch:30 step:143140[D loss: 0.999919] [G loss: 1.000137]\n",
      "epoch:30 step:143145[D loss: 0.999942] [G loss: 1.000141]\n",
      "epoch:30 step:143150[D loss: 0.999928] [G loss: 1.000209]\n",
      "epoch:30 step:143155[D loss: 0.999966] [G loss: 1.000129]\n",
      "epoch:30 step:143160[D loss: 0.999934] [G loss: 1.000069]\n",
      "epoch:30 step:143165[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:30 step:143170[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:30 step:143175[D loss: 1.000003] [G loss: 1.000004]\n",
      "epoch:30 step:143180[D loss: 0.999972] [G loss: 1.000064]\n",
      "epoch:30 step:143185[D loss: 0.999959] [G loss: 1.000056]\n",
      "epoch:30 step:143190[D loss: 1.000009] [G loss: 0.999979]\n",
      "epoch:30 step:143195[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:30 step:143200[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:30 step:143205[D loss: 0.999963] [G loss: 1.000081]\n",
      "epoch:30 step:143210[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:30 step:143215[D loss: 0.999961] [G loss: 1.000074]\n",
      "epoch:30 step:143220[D loss: 0.999971] [G loss: 1.000135]\n",
      "epoch:30 step:143225[D loss: 0.999954] [G loss: 1.000041]\n",
      "epoch:30 step:143230[D loss: 1.000150] [G loss: 0.999894]\n",
      "epoch:30 step:143235[D loss: 0.999952] [G loss: 1.000269]\n",
      "epoch:30 step:143240[D loss: 1.000067] [G loss: 1.000004]\n",
      "epoch:30 step:143245[D loss: 0.999958] [G loss: 1.000139]\n",
      "epoch:30 step:143250[D loss: 0.999899] [G loss: 1.000166]\n",
      "epoch:30 step:143255[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:30 step:143260[D loss: 0.999993] [G loss: 1.000024]\n",
      "epoch:30 step:143265[D loss: 1.000089] [G loss: 0.999908]\n",
      "epoch:30 step:143270[D loss: 0.999978] [G loss: 0.999942]\n",
      "epoch:30 step:143275[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:30 step:143280[D loss: 1.000084] [G loss: 0.999780]\n",
      "epoch:30 step:143285[D loss: 0.999881] [G loss: 1.000076]\n",
      "epoch:30 step:143290[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:30 step:143295[D loss: 0.999944] [G loss: 1.000136]\n",
      "epoch:30 step:143300[D loss: 1.000076] [G loss: 1.000030]\n",
      "epoch:30 step:143305[D loss: 0.999893] [G loss: 1.000158]\n",
      "epoch:30 step:143310[D loss: 0.999963] [G loss: 1.000103]\n",
      "epoch:30 step:143315[D loss: 1.000035] [G loss: 0.999997]\n",
      "epoch:30 step:143320[D loss: 0.999898] [G loss: 1.000075]\n",
      "epoch:30 step:143325[D loss: 1.000003] [G loss: 1.000005]\n",
      "epoch:30 step:143330[D loss: 0.999948] [G loss: 1.000070]\n",
      "epoch:30 step:143335[D loss: 0.999999] [G loss: 0.999985]\n",
      "epoch:30 step:143340[D loss: 0.999944] [G loss: 1.000116]\n",
      "epoch:30 step:143345[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:30 step:143350[D loss: 0.999958] [G loss: 1.000065]\n",
      "epoch:30 step:143355[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:30 step:143360[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:30 step:143365[D loss: 1.000001] [G loss: 1.000038]\n",
      "epoch:30 step:143370[D loss: 0.999937] [G loss: 1.000096]\n",
      "epoch:30 step:143375[D loss: 1.000009] [G loss: 1.000021]\n",
      "epoch:30 step:143380[D loss: 0.999945] [G loss: 1.000100]\n",
      "epoch:30 step:143385[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:30 step:143390[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:30 step:143395[D loss: 0.999987] [G loss: 1.000067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:143400[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:30 step:143405[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:30 step:143410[D loss: 0.999980] [G loss: 1.000061]\n",
      "epoch:30 step:143415[D loss: 1.000007] [G loss: 1.000073]\n",
      "epoch:30 step:143420[D loss: 0.999979] [G loss: 1.000041]\n",
      "epoch:30 step:143425[D loss: 0.999988] [G loss: 1.000132]\n",
      "epoch:30 step:143430[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:30 step:143435[D loss: 1.000015] [G loss: 0.999958]\n",
      "epoch:30 step:143440[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:30 step:143445[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:30 step:143450[D loss: 1.000045] [G loss: 0.999985]\n",
      "epoch:30 step:143455[D loss: 0.999970] [G loss: 1.000030]\n",
      "epoch:30 step:143460[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:30 step:143465[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:30 step:143470[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:30 step:143475[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:30 step:143480[D loss: 0.999995] [G loss: 1.000089]\n",
      "epoch:30 step:143485[D loss: 0.999998] [G loss: 1.000021]\n",
      "epoch:30 step:143490[D loss: 0.999936] [G loss: 1.000106]\n",
      "epoch:30 step:143495[D loss: 1.000050] [G loss: 1.000045]\n",
      "epoch:30 step:143500[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:30 step:143505[D loss: 1.000020] [G loss: 1.000013]\n",
      "epoch:30 step:143510[D loss: 1.000058] [G loss: 1.000039]\n",
      "epoch:30 step:143515[D loss: 1.000180] [G loss: 0.999955]\n",
      "epoch:30 step:143520[D loss: 0.999976] [G loss: 1.000104]\n",
      "epoch:30 step:143525[D loss: 1.000069] [G loss: 1.000127]\n",
      "epoch:30 step:143530[D loss: 0.999969] [G loss: 1.000061]\n",
      "epoch:30 step:143535[D loss: 0.999938] [G loss: 1.000149]\n",
      "epoch:30 step:143540[D loss: 0.999939] [G loss: 1.000087]\n",
      "epoch:30 step:143545[D loss: 0.999994] [G loss: 1.000000]\n",
      "epoch:30 step:143550[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:30 step:143555[D loss: 1.000068] [G loss: 0.999982]\n",
      "epoch:30 step:143560[D loss: 1.000061] [G loss: 0.999849]\n",
      "epoch:30 step:143565[D loss: 0.999993] [G loss: 0.999900]\n",
      "epoch:30 step:143570[D loss: 1.000013] [G loss: 1.000015]\n",
      "epoch:30 step:143575[D loss: 0.999917] [G loss: 1.000019]\n",
      "epoch:30 step:143580[D loss: 0.999905] [G loss: 1.000044]\n",
      "epoch:30 step:143585[D loss: 0.999957] [G loss: 1.000055]\n",
      "epoch:30 step:143590[D loss: 1.000050] [G loss: 0.999908]\n",
      "epoch:30 step:143595[D loss: 1.000256] [G loss: 0.999760]\n",
      "epoch:30 step:143600[D loss: 0.999950] [G loss: 1.000064]\n",
      "epoch:30 step:143605[D loss: 0.999930] [G loss: 1.000122]\n",
      "epoch:30 step:143610[D loss: 0.999922] [G loss: 1.000148]\n",
      "epoch:30 step:143615[D loss: 0.999957] [G loss: 1.000049]\n",
      "epoch:30 step:143620[D loss: 0.999977] [G loss: 1.000023]\n",
      "epoch:30 step:143625[D loss: 0.999989] [G loss: 0.999971]\n",
      "epoch:30 step:143630[D loss: 0.999949] [G loss: 1.000068]\n",
      "epoch:30 step:143635[D loss: 1.000088] [G loss: 1.000015]\n",
      "epoch:30 step:143640[D loss: 0.999908] [G loss: 1.000220]\n",
      "epoch:30 step:143645[D loss: 0.999932] [G loss: 1.000075]\n",
      "epoch:30 step:143650[D loss: 0.999968] [G loss: 1.000149]\n",
      "epoch:30 step:143655[D loss: 0.999977] [G loss: 1.000027]\n",
      "epoch:30 step:143660[D loss: 1.000014] [G loss: 1.000106]\n",
      "epoch:30 step:143665[D loss: 0.999927] [G loss: 1.000182]\n",
      "epoch:30 step:143670[D loss: 0.999943] [G loss: 1.000166]\n",
      "epoch:30 step:143675[D loss: 0.999981] [G loss: 1.000082]\n",
      "epoch:30 step:143680[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:30 step:143685[D loss: 1.000012] [G loss: 1.000044]\n",
      "epoch:30 step:143690[D loss: 1.000001] [G loss: 1.000072]\n",
      "epoch:30 step:143695[D loss: 0.999921] [G loss: 1.000108]\n",
      "epoch:30 step:143700[D loss: 0.999999] [G loss: 1.000066]\n",
      "epoch:30 step:143705[D loss: 0.999985] [G loss: 1.000118]\n",
      "epoch:30 step:143710[D loss: 0.999994] [G loss: 1.000101]\n",
      "epoch:30 step:143715[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:30 step:143720[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:30 step:143725[D loss: 0.999962] [G loss: 1.000057]\n",
      "epoch:30 step:143730[D loss: 0.999927] [G loss: 1.000105]\n",
      "epoch:30 step:143735[D loss: 1.000163] [G loss: 0.999904]\n",
      "epoch:30 step:143740[D loss: 0.999979] [G loss: 0.999968]\n",
      "epoch:30 step:143745[D loss: 0.999861] [G loss: 1.000126]\n",
      "epoch:30 step:143750[D loss: 1.000096] [G loss: 1.000124]\n",
      "epoch:30 step:143755[D loss: 0.999932] [G loss: 1.000304]\n",
      "epoch:30 step:143760[D loss: 0.999899] [G loss: 1.000258]\n",
      "epoch:30 step:143765[D loss: 0.999913] [G loss: 1.000104]\n",
      "epoch:30 step:143770[D loss: 1.000030] [G loss: 0.999949]\n",
      "epoch:30 step:143775[D loss: 1.000010] [G loss: 0.999964]\n",
      "epoch:30 step:143780[D loss: 1.000120] [G loss: 0.999885]\n",
      "epoch:30 step:143785[D loss: 1.000009] [G loss: 0.999931]\n",
      "epoch:30 step:143790[D loss: 0.999957] [G loss: 1.000070]\n",
      "epoch:30 step:143795[D loss: 1.000075] [G loss: 0.999926]\n",
      "epoch:30 step:143800[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:30 step:143805[D loss: 1.000085] [G loss: 1.000036]\n",
      "epoch:30 step:143810[D loss: 0.999925] [G loss: 1.000120]\n",
      "epoch:30 step:143815[D loss: 0.999967] [G loss: 1.000128]\n",
      "epoch:30 step:143820[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:30 step:143825[D loss: 0.999976] [G loss: 1.000097]\n",
      "epoch:30 step:143830[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:30 step:143835[D loss: 1.000024] [G loss: 1.000017]\n",
      "epoch:30 step:143840[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:30 step:143845[D loss: 0.999973] [G loss: 1.000077]\n",
      "epoch:30 step:143850[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:30 step:143855[D loss: 0.999979] [G loss: 1.000047]\n",
      "epoch:30 step:143860[D loss: 1.000029] [G loss: 1.000046]\n",
      "epoch:30 step:143865[D loss: 1.000041] [G loss: 0.999991]\n",
      "epoch:30 step:143870[D loss: 0.999931] [G loss: 1.000082]\n",
      "epoch:30 step:143875[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:30 step:143880[D loss: 0.999967] [G loss: 1.000101]\n",
      "epoch:30 step:143885[D loss: 0.999961] [G loss: 0.999963]\n",
      "epoch:30 step:143890[D loss: 1.000044] [G loss: 1.000014]\n",
      "epoch:30 step:143895[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:30 step:143900[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:30 step:143905[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:30 step:143910[D loss: 0.999943] [G loss: 1.000141]\n",
      "epoch:30 step:143915[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:30 step:143920[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:30 step:143925[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:30 step:143930[D loss: 0.999970] [G loss: 1.000111]\n",
      "epoch:30 step:143935[D loss: 0.999961] [G loss: 1.000125]\n",
      "epoch:30 step:143940[D loss: 1.000047] [G loss: 0.999972]\n",
      "epoch:30 step:143945[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:30 step:143950[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:30 step:143955[D loss: 0.999979] [G loss: 1.000021]\n",
      "epoch:30 step:143960[D loss: 0.999970] [G loss: 1.000080]\n",
      "epoch:30 step:143965[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:30 step:143970[D loss: 0.999972] [G loss: 1.000058]\n",
      "epoch:30 step:143975[D loss: 1.000052] [G loss: 0.999967]\n",
      "epoch:30 step:143980[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:30 step:143985[D loss: 1.000001] [G loss: 1.000018]\n",
      "epoch:30 step:143990[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:30 step:143995[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:30 step:144000[D loss: 0.999963] [G loss: 1.000064]\n",
      "epoch:30 step:144005[D loss: 1.000000] [G loss: 1.000092]\n",
      "epoch:30 step:144010[D loss: 1.000017] [G loss: 1.000075]\n",
      "epoch:30 step:144015[D loss: 1.000003] [G loss: 0.999982]\n",
      "epoch:30 step:144020[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:30 step:144025[D loss: 0.999966] [G loss: 0.999977]\n",
      "epoch:30 step:144030[D loss: 0.999974] [G loss: 1.000097]\n",
      "epoch:30 step:144035[D loss: 1.000005] [G loss: 0.999932]\n",
      "epoch:30 step:144040[D loss: 0.999959] [G loss: 1.000147]\n",
      "epoch:30 step:144045[D loss: 0.999942] [G loss: 1.000046]\n",
      "epoch:30 step:144050[D loss: 0.999952] [G loss: 1.000068]\n",
      "epoch:30 step:144055[D loss: 0.999962] [G loss: 1.000080]\n",
      "epoch:30 step:144060[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:30 step:144065[D loss: 0.999996] [G loss: 1.000042]\n",
      "epoch:30 step:144070[D loss: 0.999968] [G loss: 1.000096]\n",
      "epoch:30 step:144075[D loss: 1.000106] [G loss: 0.999909]\n",
      "epoch:30 step:144080[D loss: 1.000098] [G loss: 0.999919]\n",
      "epoch:30 step:144085[D loss: 1.000057] [G loss: 0.999909]\n",
      "epoch:30 step:144090[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:30 step:144095[D loss: 0.999945] [G loss: 1.000049]\n",
      "epoch:30 step:144100[D loss: 1.000027] [G loss: 1.000023]\n",
      "epoch:30 step:144105[D loss: 1.000015] [G loss: 0.999936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:144110[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:30 step:144115[D loss: 1.000007] [G loss: 1.000056]\n",
      "epoch:30 step:144120[D loss: 1.000271] [G loss: 0.999886]\n",
      "epoch:30 step:144125[D loss: 0.999861] [G loss: 1.000365]\n",
      "epoch:30 step:144130[D loss: 0.999886] [G loss: 1.000117]\n",
      "epoch:30 step:144135[D loss: 1.000007] [G loss: 1.000011]\n",
      "epoch:30 step:144140[D loss: 0.999965] [G loss: 1.000080]\n",
      "epoch:30 step:144145[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:30 step:144150[D loss: 1.000014] [G loss: 1.000040]\n",
      "epoch:30 step:144155[D loss: 0.999967] [G loss: 1.000048]\n",
      "epoch:30 step:144160[D loss: 1.000028] [G loss: 1.000035]\n",
      "epoch:30 step:144165[D loss: 1.000039] [G loss: 1.000052]\n",
      "epoch:30 step:144170[D loss: 0.999905] [G loss: 1.000111]\n",
      "epoch:30 step:144175[D loss: 0.999935] [G loss: 1.000105]\n",
      "epoch:30 step:144180[D loss: 0.999937] [G loss: 1.000104]\n",
      "epoch:30 step:144185[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:30 step:144190[D loss: 0.999957] [G loss: 1.000051]\n",
      "epoch:30 step:144195[D loss: 0.999970] [G loss: 1.000033]\n",
      "epoch:30 step:144200[D loss: 0.999996] [G loss: 1.000016]\n",
      "epoch:30 step:144205[D loss: 1.000040] [G loss: 0.999941]\n",
      "epoch:30 step:144210[D loss: 1.000000] [G loss: 0.999966]\n",
      "epoch:30 step:144215[D loss: 0.999943] [G loss: 1.000090]\n",
      "epoch:30 step:144220[D loss: 0.999940] [G loss: 1.000083]\n",
      "epoch:30 step:144225[D loss: 0.999959] [G loss: 1.000035]\n",
      "epoch:30 step:144230[D loss: 0.999979] [G loss: 1.000126]\n",
      "epoch:30 step:144235[D loss: 1.000032] [G loss: 0.999998]\n",
      "epoch:30 step:144240[D loss: 1.000008] [G loss: 1.000012]\n",
      "epoch:30 step:144245[D loss: 1.000086] [G loss: 0.999952]\n",
      "epoch:30 step:144250[D loss: 0.999887] [G loss: 1.000180]\n",
      "epoch:30 step:144255[D loss: 0.999927] [G loss: 1.000069]\n",
      "epoch:30 step:144260[D loss: 1.000033] [G loss: 1.000027]\n",
      "epoch:30 step:144265[D loss: 0.999940] [G loss: 1.000039]\n",
      "epoch:30 step:144270[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:30 step:144275[D loss: 0.999968] [G loss: 1.000049]\n",
      "epoch:30 step:144280[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:30 step:144285[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:30 step:144290[D loss: 1.000078] [G loss: 0.999881]\n",
      "epoch:30 step:144295[D loss: 0.999937] [G loss: 1.000110]\n",
      "epoch:30 step:144300[D loss: 1.000068] [G loss: 0.999917]\n",
      "epoch:30 step:144305[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:30 step:144310[D loss: 0.999919] [G loss: 1.000148]\n",
      "epoch:30 step:144315[D loss: 0.999899] [G loss: 1.000129]\n",
      "epoch:30 step:144320[D loss: 1.000003] [G loss: 1.000174]\n",
      "epoch:30 step:144325[D loss: 1.000044] [G loss: 1.000000]\n",
      "epoch:30 step:144330[D loss: 0.999951] [G loss: 1.000051]\n",
      "epoch:30 step:144335[D loss: 1.000020] [G loss: 0.999967]\n",
      "epoch:30 step:144340[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:30 step:144345[D loss: 0.999983] [G loss: 1.000036]\n",
      "epoch:30 step:144350[D loss: 0.999934] [G loss: 1.000202]\n",
      "epoch:30 step:144355[D loss: 0.999960] [G loss: 1.000105]\n",
      "epoch:30 step:144360[D loss: 1.000013] [G loss: 1.000133]\n",
      "epoch:30 step:144365[D loss: 0.999967] [G loss: 1.000075]\n",
      "epoch:30 step:144370[D loss: 0.999938] [G loss: 1.000093]\n",
      "epoch:30 step:144375[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:30 step:144380[D loss: 0.999931] [G loss: 1.000144]\n",
      "epoch:30 step:144385[D loss: 0.999951] [G loss: 1.000150]\n",
      "epoch:30 step:144390[D loss: 0.999958] [G loss: 1.000027]\n",
      "epoch:30 step:144395[D loss: 0.999956] [G loss: 1.000091]\n",
      "epoch:30 step:144400[D loss: 0.999982] [G loss: 1.000030]\n",
      "epoch:30 step:144405[D loss: 1.000038] [G loss: 1.000059]\n",
      "epoch:30 step:144410[D loss: 0.999932] [G loss: 1.000162]\n",
      "epoch:30 step:144415[D loss: 0.999985] [G loss: 1.000014]\n",
      "epoch:30 step:144420[D loss: 1.000291] [G loss: 0.999660]\n",
      "epoch:30 step:144425[D loss: 0.999854] [G loss: 1.000104]\n",
      "epoch:30 step:144430[D loss: 0.999928] [G loss: 1.000225]\n",
      "epoch:30 step:144435[D loss: 0.999958] [G loss: 1.000038]\n",
      "epoch:30 step:144440[D loss: 1.000005] [G loss: 1.000000]\n",
      "epoch:30 step:144445[D loss: 0.999981] [G loss: 1.000123]\n",
      "epoch:30 step:144450[D loss: 1.000037] [G loss: 0.999898]\n",
      "epoch:30 step:144455[D loss: 0.999942] [G loss: 1.000064]\n",
      "epoch:30 step:144460[D loss: 0.999948] [G loss: 1.000049]\n",
      "epoch:30 step:144465[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:30 step:144470[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:30 step:144475[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:30 step:144480[D loss: 0.999964] [G loss: 1.000140]\n",
      "epoch:30 step:144485[D loss: 0.999959] [G loss: 1.000085]\n",
      "epoch:30 step:144490[D loss: 1.000039] [G loss: 0.999993]\n",
      "epoch:30 step:144495[D loss: 0.999990] [G loss: 1.000161]\n",
      "epoch:30 step:144500[D loss: 0.999920] [G loss: 1.000078]\n",
      "epoch:30 step:144505[D loss: 0.999994] [G loss: 1.000007]\n",
      "epoch:30 step:144510[D loss: 0.999968] [G loss: 0.999977]\n",
      "epoch:30 step:144515[D loss: 0.999974] [G loss: 1.000011]\n",
      "epoch:30 step:144520[D loss: 1.000055] [G loss: 0.999935]\n",
      "epoch:30 step:144525[D loss: 1.000040] [G loss: 1.000050]\n",
      "epoch:30 step:144530[D loss: 0.999974] [G loss: 1.000195]\n",
      "epoch:30 step:144535[D loss: 0.999904] [G loss: 1.000182]\n",
      "epoch:30 step:144540[D loss: 1.000109] [G loss: 0.999906]\n",
      "epoch:30 step:144545[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:30 step:144550[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:30 step:144555[D loss: 1.000013] [G loss: 1.000029]\n",
      "epoch:30 step:144560[D loss: 0.999979] [G loss: 0.999970]\n",
      "epoch:30 step:144565[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:30 step:144570[D loss: 1.000021] [G loss: 1.000028]\n",
      "epoch:30 step:144575[D loss: 1.000089] [G loss: 0.999904]\n",
      "epoch:30 step:144580[D loss: 0.999960] [G loss: 1.000079]\n",
      "epoch:30 step:144585[D loss: 0.999962] [G loss: 1.000111]\n",
      "epoch:30 step:144590[D loss: 1.000037] [G loss: 1.000105]\n",
      "epoch:30 step:144595[D loss: 0.999950] [G loss: 1.000081]\n",
      "epoch:30 step:144600[D loss: 0.999921] [G loss: 1.000116]\n",
      "epoch:30 step:144605[D loss: 0.999977] [G loss: 1.000036]\n",
      "epoch:30 step:144610[D loss: 1.000021] [G loss: 0.999951]\n",
      "epoch:30 step:144615[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:30 step:144620[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:30 step:144625[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:30 step:144630[D loss: 0.999979] [G loss: 1.000040]\n",
      "epoch:30 step:144635[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:30 step:144640[D loss: 0.999976] [G loss: 1.000077]\n",
      "epoch:30 step:144645[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:30 step:144650[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:30 step:144655[D loss: 0.999985] [G loss: 1.000081]\n",
      "epoch:30 step:144660[D loss: 0.999989] [G loss: 1.000056]\n",
      "epoch:30 step:144665[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:30 step:144670[D loss: 0.999970] [G loss: 1.000091]\n",
      "epoch:30 step:144675[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:30 step:144680[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:30 step:144685[D loss: 0.999928] [G loss: 1.000107]\n",
      "epoch:30 step:144690[D loss: 0.999936] [G loss: 1.000142]\n",
      "epoch:30 step:144695[D loss: 1.000003] [G loss: 1.000064]\n",
      "epoch:30 step:144700[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:30 step:144705[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:30 step:144710[D loss: 1.000020] [G loss: 1.000077]\n",
      "epoch:30 step:144715[D loss: 1.000029] [G loss: 0.999937]\n",
      "epoch:30 step:144720[D loss: 1.000005] [G loss: 1.000166]\n",
      "epoch:30 step:144725[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:30 step:144730[D loss: 0.999931] [G loss: 1.000089]\n",
      "epoch:30 step:144735[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:30 step:144740[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:30 step:144745[D loss: 0.999977] [G loss: 1.000118]\n",
      "epoch:30 step:144750[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:30 step:144755[D loss: 1.000023] [G loss: 1.000000]\n",
      "epoch:30 step:144760[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:30 step:144765[D loss: 0.999965] [G loss: 1.000165]\n",
      "epoch:30 step:144770[D loss: 1.000056] [G loss: 1.000009]\n",
      "epoch:30 step:144775[D loss: 0.999839] [G loss: 1.000307]\n",
      "epoch:30 step:144780[D loss: 0.999961] [G loss: 1.000107]\n",
      "epoch:30 step:144785[D loss: 0.999942] [G loss: 1.000110]\n",
      "epoch:30 step:144790[D loss: 0.999965] [G loss: 1.000090]\n",
      "epoch:30 step:144795[D loss: 1.000031] [G loss: 1.000066]\n",
      "epoch:30 step:144800[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:30 step:144805[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:30 step:144810[D loss: 0.999966] [G loss: 1.000076]\n",
      "epoch:30 step:144815[D loss: 1.000026] [G loss: 0.999966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:144820[D loss: 0.999977] [G loss: 1.000009]\n",
      "epoch:30 step:144825[D loss: 0.999995] [G loss: 0.999956]\n",
      "epoch:30 step:144830[D loss: 1.000091] [G loss: 0.999966]\n",
      "epoch:30 step:144835[D loss: 0.999928] [G loss: 1.000121]\n",
      "epoch:30 step:144840[D loss: 1.000025] [G loss: 0.999994]\n",
      "epoch:30 step:144845[D loss: 0.999943] [G loss: 1.000204]\n",
      "epoch:30 step:144850[D loss: 0.999931] [G loss: 1.000096]\n",
      "epoch:30 step:144855[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:30 step:144860[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:30 step:144865[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:30 step:144870[D loss: 1.000085] [G loss: 0.999905]\n",
      "epoch:30 step:144875[D loss: 0.999932] [G loss: 1.000090]\n",
      "epoch:30 step:144880[D loss: 0.999930] [G loss: 1.000111]\n",
      "epoch:30 step:144885[D loss: 1.000070] [G loss: 1.000011]\n",
      "epoch:30 step:144890[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:30 step:144895[D loss: 0.999974] [G loss: 1.000094]\n",
      "epoch:30 step:144900[D loss: 0.999999] [G loss: 1.000128]\n",
      "epoch:30 step:144905[D loss: 0.999955] [G loss: 1.000035]\n",
      "epoch:30 step:144910[D loss: 1.000001] [G loss: 1.000085]\n",
      "epoch:30 step:144915[D loss: 0.999963] [G loss: 1.000010]\n",
      "epoch:30 step:144920[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:30 step:144925[D loss: 1.000041] [G loss: 0.999962]\n",
      "epoch:30 step:144930[D loss: 0.999905] [G loss: 1.000190]\n",
      "epoch:30 step:144935[D loss: 0.999940] [G loss: 1.000060]\n",
      "epoch:30 step:144940[D loss: 0.999998] [G loss: 1.000071]\n",
      "epoch:30 step:144945[D loss: 0.999968] [G loss: 1.000081]\n",
      "epoch:30 step:144950[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:30 step:144955[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:30 step:144960[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:30 step:144965[D loss: 0.999925] [G loss: 1.000080]\n",
      "epoch:30 step:144970[D loss: 0.999992] [G loss: 1.000019]\n",
      "epoch:30 step:144975[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:30 step:144980[D loss: 1.000048] [G loss: 1.000002]\n",
      "epoch:30 step:144985[D loss: 1.000034] [G loss: 1.000078]\n",
      "epoch:30 step:144990[D loss: 0.999937] [G loss: 1.000094]\n",
      "epoch:30 step:144995[D loss: 0.999973] [G loss: 1.000110]\n",
      "epoch:30 step:145000[D loss: 0.999995] [G loss: 1.000020]\n",
      "epoch:30 step:145005[D loss: 1.000019] [G loss: 0.999992]\n",
      "epoch:30 step:145010[D loss: 0.999953] [G loss: 1.000080]\n",
      "epoch:30 step:145015[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:30 step:145020[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:30 step:145025[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:30 step:145030[D loss: 1.000072] [G loss: 0.999981]\n",
      "epoch:30 step:145035[D loss: 0.999956] [G loss: 1.000059]\n",
      "epoch:30 step:145040[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:30 step:145045[D loss: 0.999997] [G loss: 1.000036]\n",
      "epoch:30 step:145050[D loss: 0.999989] [G loss: 1.000013]\n",
      "epoch:30 step:145055[D loss: 1.000048] [G loss: 1.000025]\n",
      "epoch:30 step:145060[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:30 step:145065[D loss: 0.999980] [G loss: 1.000017]\n",
      "epoch:30 step:145070[D loss: 0.999996] [G loss: 1.000141]\n",
      "epoch:30 step:145075[D loss: 1.000030] [G loss: 0.999995]\n",
      "epoch:30 step:145080[D loss: 1.000056] [G loss: 1.000060]\n",
      "epoch:30 step:145085[D loss: 0.999961] [G loss: 1.000041]\n",
      "epoch:30 step:145090[D loss: 1.000069] [G loss: 0.999919]\n",
      "epoch:30 step:145095[D loss: 1.000037] [G loss: 0.999876]\n",
      "epoch:30 step:145100[D loss: 0.999998] [G loss: 0.999970]\n",
      "epoch:30 step:145105[D loss: 0.999954] [G loss: 0.999995]\n",
      "epoch:30 step:145110[D loss: 0.999909] [G loss: 1.000096]\n",
      "epoch:30 step:145115[D loss: 0.999947] [G loss: 1.000054]\n",
      "epoch:30 step:145120[D loss: 1.000016] [G loss: 1.000055]\n",
      "epoch:30 step:145125[D loss: 1.000072] [G loss: 0.999947]\n",
      "epoch:30 step:145130[D loss: 0.999945] [G loss: 1.000085]\n",
      "epoch:30 step:145135[D loss: 1.000012] [G loss: 1.000107]\n",
      "epoch:30 step:145140[D loss: 0.999932] [G loss: 1.000072]\n",
      "epoch:30 step:145145[D loss: 0.999995] [G loss: 0.999980]\n",
      "epoch:30 step:145150[D loss: 0.999992] [G loss: 1.000035]\n",
      "epoch:30 step:145155[D loss: 1.000020] [G loss: 1.000018]\n",
      "epoch:30 step:145160[D loss: 1.000035] [G loss: 1.000021]\n",
      "epoch:30 step:145165[D loss: 0.999919] [G loss: 1.000101]\n",
      "epoch:30 step:145170[D loss: 0.999954] [G loss: 1.000079]\n",
      "epoch:30 step:145175[D loss: 0.999948] [G loss: 1.000048]\n",
      "epoch:30 step:145180[D loss: 0.999957] [G loss: 1.000051]\n",
      "epoch:30 step:145185[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:30 step:145190[D loss: 1.000061] [G loss: 1.000015]\n",
      "epoch:30 step:145195[D loss: 0.999884] [G loss: 1.000076]\n",
      "epoch:30 step:145200[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:30 step:145205[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:30 step:145210[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:30 step:145215[D loss: 1.000010] [G loss: 1.000025]\n",
      "epoch:30 step:145220[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:30 step:145225[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:30 step:145230[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:30 step:145235[D loss: 0.999986] [G loss: 1.000045]\n",
      "epoch:31 step:145240[D loss: 1.000066] [G loss: 0.999996]\n",
      "epoch:31 step:145245[D loss: 0.999954] [G loss: 1.000065]\n",
      "epoch:31 step:145250[D loss: 0.999974] [G loss: 1.000047]\n",
      "epoch:31 step:145255[D loss: 0.999971] [G loss: 1.000056]\n",
      "epoch:31 step:145260[D loss: 0.999971] [G loss: 1.000065]\n",
      "epoch:31 step:145265[D loss: 0.999992] [G loss: 1.000027]\n",
      "epoch:31 step:145270[D loss: 1.000043] [G loss: 1.000008]\n",
      "epoch:31 step:145275[D loss: 1.000058] [G loss: 1.000004]\n",
      "epoch:31 step:145280[D loss: 1.000009] [G loss: 1.000030]\n",
      "epoch:31 step:145285[D loss: 1.000072] [G loss: 1.000076]\n",
      "epoch:31 step:145290[D loss: 0.999935] [G loss: 1.000183]\n",
      "epoch:31 step:145295[D loss: 0.999942] [G loss: 1.000069]\n",
      "epoch:31 step:145300[D loss: 0.999997] [G loss: 0.999995]\n",
      "epoch:31 step:145305[D loss: 1.000007] [G loss: 0.999981]\n",
      "epoch:31 step:145310[D loss: 0.999902] [G loss: 1.000060]\n",
      "epoch:31 step:145315[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:31 step:145320[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:31 step:145325[D loss: 0.999996] [G loss: 1.000102]\n",
      "epoch:31 step:145330[D loss: 0.999996] [G loss: 1.000011]\n",
      "epoch:31 step:145335[D loss: 0.999933] [G loss: 1.000086]\n",
      "epoch:31 step:145340[D loss: 0.999998] [G loss: 1.000089]\n",
      "epoch:31 step:145345[D loss: 1.000055] [G loss: 1.000015]\n",
      "epoch:31 step:145350[D loss: 0.999992] [G loss: 1.000052]\n",
      "epoch:31 step:145355[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:31 step:145360[D loss: 0.999962] [G loss: 1.000070]\n",
      "epoch:31 step:145365[D loss: 0.999994] [G loss: 1.000064]\n",
      "epoch:31 step:145370[D loss: 1.000064] [G loss: 0.999986]\n",
      "epoch:31 step:145375[D loss: 0.999971] [G loss: 1.000075]\n",
      "epoch:31 step:145380[D loss: 1.000076] [G loss: 0.999945]\n",
      "epoch:31 step:145385[D loss: 1.000012] [G loss: 1.000095]\n",
      "epoch:31 step:145390[D loss: 0.999930] [G loss: 1.000089]\n",
      "epoch:31 step:145395[D loss: 0.999957] [G loss: 1.000084]\n",
      "epoch:31 step:145400[D loss: 0.999932] [G loss: 1.000107]\n",
      "epoch:31 step:145405[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:31 step:145410[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:31 step:145415[D loss: 1.000053] [G loss: 1.000025]\n",
      "epoch:31 step:145420[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:31 step:145425[D loss: 0.999938] [G loss: 1.000100]\n",
      "epoch:31 step:145430[D loss: 0.999957] [G loss: 1.000015]\n",
      "epoch:31 step:145435[D loss: 1.000073] [G loss: 0.999984]\n",
      "epoch:31 step:145440[D loss: 0.999821] [G loss: 1.000300]\n",
      "epoch:31 step:145445[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:31 step:145450[D loss: 0.999958] [G loss: 1.000080]\n",
      "epoch:31 step:145455[D loss: 0.999917] [G loss: 1.000151]\n",
      "epoch:31 step:145460[D loss: 0.999961] [G loss: 1.000096]\n",
      "epoch:31 step:145465[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:31 step:145470[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:31 step:145475[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:31 step:145480[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:31 step:145485[D loss: 0.999976] [G loss: 1.000061]\n",
      "epoch:31 step:145490[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:31 step:145495[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:31 step:145500[D loss: 1.000034] [G loss: 0.999992]\n",
      "epoch:31 step:145505[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:31 step:145510[D loss: 0.999942] [G loss: 1.000105]\n",
      "epoch:31 step:145515[D loss: 0.999989] [G loss: 1.000079]\n",
      "epoch:31 step:145520[D loss: 0.999959] [G loss: 1.000064]\n",
      "epoch:31 step:145525[D loss: 0.999964] [G loss: 1.000078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:145530[D loss: 0.999978] [G loss: 1.000069]\n",
      "epoch:31 step:145535[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:31 step:145540[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:31 step:145545[D loss: 0.999998] [G loss: 1.000063]\n",
      "epoch:31 step:145550[D loss: 1.000030] [G loss: 1.000038]\n",
      "epoch:31 step:145555[D loss: 1.000012] [G loss: 1.000066]\n",
      "epoch:31 step:145560[D loss: 0.999934] [G loss: 1.000082]\n",
      "epoch:31 step:145565[D loss: 1.000074] [G loss: 0.999914]\n",
      "epoch:31 step:145570[D loss: 0.999980] [G loss: 1.000025]\n",
      "epoch:31 step:145575[D loss: 1.000017] [G loss: 1.000026]\n",
      "epoch:31 step:145580[D loss: 1.000121] [G loss: 0.999970]\n",
      "epoch:31 step:145585[D loss: 0.999953] [G loss: 1.000113]\n",
      "epoch:31 step:145590[D loss: 0.999996] [G loss: 1.000077]\n",
      "epoch:31 step:145595[D loss: 1.000034] [G loss: 1.000077]\n",
      "epoch:31 step:145600[D loss: 0.999960] [G loss: 1.000143]\n",
      "epoch:31 step:145605[D loss: 1.000038] [G loss: 0.999975]\n",
      "epoch:31 step:145610[D loss: 1.000115] [G loss: 0.999862]\n",
      "epoch:31 step:145615[D loss: 1.000052] [G loss: 0.999853]\n",
      "epoch:31 step:145620[D loss: 0.999949] [G loss: 1.000123]\n",
      "epoch:31 step:145625[D loss: 1.000001] [G loss: 1.000043]\n",
      "epoch:31 step:145630[D loss: 0.999950] [G loss: 1.000109]\n",
      "epoch:31 step:145635[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:31 step:145640[D loss: 1.000067] [G loss: 0.999991]\n",
      "epoch:31 step:145645[D loss: 1.000011] [G loss: 0.999957]\n",
      "epoch:31 step:145650[D loss: 0.999956] [G loss: 1.000065]\n",
      "epoch:31 step:145655[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:31 step:145660[D loss: 0.999974] [G loss: 1.000022]\n",
      "epoch:31 step:145665[D loss: 0.999969] [G loss: 1.000001]\n",
      "epoch:31 step:145670[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:31 step:145675[D loss: 0.999927] [G loss: 1.000150]\n",
      "epoch:31 step:145680[D loss: 1.000163] [G loss: 0.999905]\n",
      "epoch:31 step:145685[D loss: 1.000048] [G loss: 0.999958]\n",
      "epoch:31 step:145690[D loss: 0.999931] [G loss: 1.000117]\n",
      "epoch:31 step:145695[D loss: 0.999946] [G loss: 1.000076]\n",
      "epoch:31 step:145700[D loss: 1.000021] [G loss: 0.999984]\n",
      "epoch:31 step:145705[D loss: 1.000099] [G loss: 0.999765]\n",
      "epoch:31 step:145710[D loss: 1.000086] [G loss: 0.999978]\n",
      "epoch:31 step:145715[D loss: 1.000103] [G loss: 0.999915]\n",
      "epoch:31 step:145720[D loss: 1.000031] [G loss: 1.000066]\n",
      "epoch:31 step:145725[D loss: 1.000113] [G loss: 0.999964]\n",
      "epoch:31 step:145730[D loss: 0.999891] [G loss: 1.000266]\n",
      "epoch:31 step:145735[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:31 step:145740[D loss: 0.999959] [G loss: 1.000088]\n",
      "epoch:31 step:145745[D loss: 0.999954] [G loss: 1.000062]\n",
      "epoch:31 step:145750[D loss: 0.999994] [G loss: 1.000015]\n",
      "epoch:31 step:145755[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:31 step:145760[D loss: 0.999982] [G loss: 1.000102]\n",
      "epoch:31 step:145765[D loss: 0.999985] [G loss: 1.000010]\n",
      "epoch:31 step:145770[D loss: 1.000077] [G loss: 0.999945]\n",
      "epoch:31 step:145775[D loss: 0.999959] [G loss: 1.000114]\n",
      "epoch:31 step:145780[D loss: 0.999878] [G loss: 1.000116]\n",
      "epoch:31 step:145785[D loss: 1.000059] [G loss: 1.000030]\n",
      "epoch:31 step:145790[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:31 step:145795[D loss: 0.999934] [G loss: 1.000151]\n",
      "epoch:31 step:145800[D loss: 0.999962] [G loss: 1.000130]\n",
      "epoch:31 step:145805[D loss: 0.999957] [G loss: 1.000108]\n",
      "epoch:31 step:145810[D loss: 1.000004] [G loss: 1.000016]\n",
      "epoch:31 step:145815[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:31 step:145820[D loss: 1.000082] [G loss: 0.999977]\n",
      "epoch:31 step:145825[D loss: 1.000136] [G loss: 0.999941]\n",
      "epoch:31 step:145830[D loss: 0.999862] [G loss: 1.000262]\n",
      "epoch:31 step:145835[D loss: 0.999809] [G loss: 1.000275]\n",
      "epoch:31 step:145840[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:31 step:145845[D loss: 0.999914] [G loss: 1.000189]\n",
      "epoch:31 step:145850[D loss: 1.000032] [G loss: 1.000065]\n",
      "epoch:31 step:145855[D loss: 0.999914] [G loss: 1.000175]\n",
      "epoch:31 step:145860[D loss: 0.999874] [G loss: 1.000147]\n",
      "epoch:31 step:145865[D loss: 0.999926] [G loss: 1.000205]\n",
      "epoch:31 step:145870[D loss: 0.999973] [G loss: 1.000037]\n",
      "epoch:31 step:145875[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:31 step:145880[D loss: 1.000015] [G loss: 0.999942]\n",
      "epoch:31 step:145885[D loss: 0.999961] [G loss: 1.000023]\n",
      "epoch:31 step:145890[D loss: 1.000004] [G loss: 0.999925]\n",
      "epoch:31 step:145895[D loss: 1.000115] [G loss: 0.999881]\n",
      "epoch:31 step:145900[D loss: 1.000121] [G loss: 0.999871]\n",
      "epoch:31 step:145905[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:31 step:145910[D loss: 0.999992] [G loss: 1.000030]\n",
      "epoch:31 step:145915[D loss: 0.999837] [G loss: 1.000155]\n",
      "epoch:31 step:145920[D loss: 0.999941] [G loss: 1.000128]\n",
      "epoch:31 step:145925[D loss: 0.999991] [G loss: 1.000028]\n",
      "epoch:31 step:145930[D loss: 0.999985] [G loss: 1.000047]\n",
      "epoch:31 step:145935[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:31 step:145940[D loss: 1.000110] [G loss: 0.999956]\n",
      "epoch:31 step:145945[D loss: 0.999882] [G loss: 1.000233]\n",
      "epoch:31 step:145950[D loss: 0.999922] [G loss: 1.000082]\n",
      "epoch:31 step:145955[D loss: 0.999892] [G loss: 1.000171]\n",
      "epoch:31 step:145960[D loss: 1.000068] [G loss: 1.000019]\n",
      "epoch:31 step:145965[D loss: 0.999854] [G loss: 1.000226]\n",
      "epoch:31 step:145970[D loss: 0.999992] [G loss: 1.000218]\n",
      "epoch:31 step:145975[D loss: 0.999894] [G loss: 1.000142]\n",
      "epoch:31 step:145980[D loss: 0.999918] [G loss: 1.000094]\n",
      "epoch:31 step:145985[D loss: 0.999962] [G loss: 1.000060]\n",
      "epoch:31 step:145990[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:31 step:145995[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:31 step:146000[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:31 step:146005[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:31 step:146010[D loss: 0.999998] [G loss: 1.000028]\n",
      "epoch:31 step:146015[D loss: 1.000034] [G loss: 1.000025]\n",
      "epoch:31 step:146020[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:31 step:146025[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:31 step:146030[D loss: 1.000001] [G loss: 0.999981]\n",
      "epoch:31 step:146035[D loss: 1.000039] [G loss: 0.999937]\n",
      "epoch:31 step:146040[D loss: 1.000157] [G loss: 0.999883]\n",
      "epoch:31 step:146045[D loss: 1.000059] [G loss: 1.000018]\n",
      "epoch:31 step:146050[D loss: 0.999885] [G loss: 1.000177]\n",
      "epoch:31 step:146055[D loss: 0.999831] [G loss: 1.000239]\n",
      "epoch:31 step:146060[D loss: 0.999920] [G loss: 1.000080]\n",
      "epoch:31 step:146065[D loss: 1.000013] [G loss: 0.999991]\n",
      "epoch:31 step:146070[D loss: 0.999977] [G loss: 1.000026]\n",
      "epoch:31 step:146075[D loss: 0.999961] [G loss: 1.000072]\n",
      "epoch:31 step:146080[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:31 step:146085[D loss: 0.999993] [G loss: 1.000033]\n",
      "epoch:31 step:146090[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:31 step:146095[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:31 step:146100[D loss: 0.999986] [G loss: 1.000054]\n",
      "epoch:31 step:146105[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:31 step:146110[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:31 step:146115[D loss: 0.999979] [G loss: 1.000082]\n",
      "epoch:31 step:146120[D loss: 0.999972] [G loss: 1.000057]\n",
      "epoch:31 step:146125[D loss: 1.000030] [G loss: 1.000026]\n",
      "epoch:31 step:146130[D loss: 0.999943] [G loss: 1.000150]\n",
      "epoch:31 step:146135[D loss: 0.999965] [G loss: 1.000056]\n",
      "epoch:31 step:146140[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:31 step:146145[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:31 step:146150[D loss: 0.999949] [G loss: 1.000104]\n",
      "epoch:31 step:146155[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:31 step:146160[D loss: 1.000000] [G loss: 1.000063]\n",
      "epoch:31 step:146165[D loss: 1.000034] [G loss: 0.999998]\n",
      "epoch:31 step:146170[D loss: 0.999917] [G loss: 1.000110]\n",
      "epoch:31 step:146175[D loss: 0.999968] [G loss: 1.000141]\n",
      "epoch:31 step:146180[D loss: 0.999951] [G loss: 1.000132]\n",
      "epoch:31 step:146185[D loss: 0.999943] [G loss: 1.000095]\n",
      "epoch:31 step:146190[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:31 step:146195[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:31 step:146200[D loss: 0.999993] [G loss: 1.000114]\n",
      "epoch:31 step:146205[D loss: 1.000001] [G loss: 1.000019]\n",
      "epoch:31 step:146210[D loss: 1.000027] [G loss: 0.999975]\n",
      "epoch:31 step:146215[D loss: 1.000091] [G loss: 0.999871]\n",
      "epoch:31 step:146220[D loss: 1.000021] [G loss: 1.000015]\n",
      "epoch:31 step:146225[D loss: 1.000117] [G loss: 1.000001]\n",
      "epoch:31 step:146230[D loss: 1.000057] [G loss: 0.999949]\n",
      "epoch:31 step:146235[D loss: 1.000188] [G loss: 1.000069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:146240[D loss: 1.000052] [G loss: 1.000023]\n",
      "epoch:31 step:146245[D loss: 0.999863] [G loss: 1.000181]\n",
      "epoch:31 step:146250[D loss: 0.999924] [G loss: 1.000158]\n",
      "epoch:31 step:146255[D loss: 0.999954] [G loss: 1.000031]\n",
      "epoch:31 step:146260[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:31 step:146265[D loss: 1.000046] [G loss: 0.999898]\n",
      "epoch:31 step:146270[D loss: 1.000055] [G loss: 0.999871]\n",
      "epoch:31 step:146275[D loss: 0.999931] [G loss: 0.999986]\n",
      "epoch:31 step:146280[D loss: 1.000048] [G loss: 0.999972]\n",
      "epoch:31 step:146285[D loss: 1.000023] [G loss: 0.999992]\n",
      "epoch:31 step:146290[D loss: 1.000038] [G loss: 0.999968]\n",
      "epoch:31 step:146295[D loss: 0.999968] [G loss: 1.000032]\n",
      "epoch:31 step:146300[D loss: 0.999962] [G loss: 1.000102]\n",
      "epoch:31 step:146305[D loss: 0.999987] [G loss: 1.000016]\n",
      "epoch:31 step:146310[D loss: 0.999887] [G loss: 1.000247]\n",
      "epoch:31 step:146315[D loss: 1.000025] [G loss: 1.000097]\n",
      "epoch:31 step:146320[D loss: 1.000067] [G loss: 1.000293]\n",
      "epoch:31 step:146325[D loss: 0.999910] [G loss: 1.000200]\n",
      "epoch:31 step:146330[D loss: 0.999890] [G loss: 1.000121]\n",
      "epoch:31 step:146335[D loss: 0.999971] [G loss: 1.000063]\n",
      "epoch:31 step:146340[D loss: 1.000035] [G loss: 0.999953]\n",
      "epoch:31 step:146345[D loss: 1.000127] [G loss: 0.999901]\n",
      "epoch:31 step:146350[D loss: 1.000077] [G loss: 0.999932]\n",
      "epoch:31 step:146355[D loss: 0.999945] [G loss: 1.000034]\n",
      "epoch:31 step:146360[D loss: 0.999951] [G loss: 1.000154]\n",
      "epoch:31 step:146365[D loss: 1.000141] [G loss: 1.000024]\n",
      "epoch:31 step:146370[D loss: 1.000211] [G loss: 0.999913]\n",
      "epoch:31 step:146375[D loss: 0.999787] [G loss: 1.000188]\n",
      "epoch:31 step:146380[D loss: 0.999921] [G loss: 1.000144]\n",
      "epoch:31 step:146385[D loss: 1.000052] [G loss: 1.000109]\n",
      "epoch:31 step:146390[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:31 step:146395[D loss: 0.999950] [G loss: 1.000139]\n",
      "epoch:31 step:146400[D loss: 1.000025] [G loss: 1.000067]\n",
      "epoch:31 step:146405[D loss: 0.999989] [G loss: 1.000143]\n",
      "epoch:31 step:146410[D loss: 0.999966] [G loss: 1.000160]\n",
      "epoch:31 step:146415[D loss: 0.999933] [G loss: 1.000122]\n",
      "epoch:31 step:146420[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:31 step:146425[D loss: 0.999995] [G loss: 0.999936]\n",
      "epoch:31 step:146430[D loss: 0.999984] [G loss: 1.000002]\n",
      "epoch:31 step:146435[D loss: 1.000016] [G loss: 1.000024]\n",
      "epoch:31 step:146440[D loss: 1.000058] [G loss: 1.000059]\n",
      "epoch:31 step:146445[D loss: 1.000084] [G loss: 0.999943]\n",
      "epoch:31 step:146450[D loss: 0.999829] [G loss: 1.000240]\n",
      "epoch:31 step:146455[D loss: 1.000030] [G loss: 1.000137]\n",
      "epoch:31 step:146460[D loss: 0.999948] [G loss: 1.000185]\n",
      "epoch:31 step:146465[D loss: 0.999986] [G loss: 1.000120]\n",
      "epoch:31 step:146470[D loss: 0.999977] [G loss: 1.000062]\n",
      "epoch:31 step:146475[D loss: 1.000046] [G loss: 1.000040]\n",
      "epoch:31 step:146480[D loss: 0.999922] [G loss: 1.000035]\n",
      "epoch:31 step:146485[D loss: 1.000035] [G loss: 1.000019]\n",
      "epoch:31 step:146490[D loss: 0.999998] [G loss: 0.999992]\n",
      "epoch:31 step:146495[D loss: 0.999945] [G loss: 1.000097]\n",
      "epoch:31 step:146500[D loss: 1.000028] [G loss: 1.000048]\n",
      "epoch:31 step:146505[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:31 step:146510[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:31 step:146515[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:31 step:146520[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:31 step:146525[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:31 step:146530[D loss: 0.999956] [G loss: 1.000098]\n",
      "epoch:31 step:146535[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:31 step:146540[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:31 step:146545[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:31 step:146550[D loss: 0.999988] [G loss: 1.000094]\n",
      "epoch:31 step:146555[D loss: 1.000043] [G loss: 0.999927]\n",
      "epoch:31 step:146560[D loss: 0.999876] [G loss: 1.000150]\n",
      "epoch:31 step:146565[D loss: 1.000010] [G loss: 1.000187]\n",
      "epoch:31 step:146570[D loss: 0.999981] [G loss: 1.000130]\n",
      "epoch:31 step:146575[D loss: 0.999953] [G loss: 1.000061]\n",
      "epoch:31 step:146580[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:31 step:146585[D loss: 0.999995] [G loss: 0.999988]\n",
      "epoch:31 step:146590[D loss: 0.999980] [G loss: 1.000065]\n",
      "epoch:31 step:146595[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:31 step:146600[D loss: 1.000002] [G loss: 1.000042]\n",
      "epoch:31 step:146605[D loss: 0.999954] [G loss: 1.000071]\n",
      "epoch:31 step:146610[D loss: 1.000023] [G loss: 1.000020]\n",
      "epoch:31 step:146615[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:31 step:146620[D loss: 1.000014] [G loss: 0.999992]\n",
      "epoch:31 step:146625[D loss: 1.000034] [G loss: 1.000071]\n",
      "epoch:31 step:146630[D loss: 0.999965] [G loss: 1.000079]\n",
      "epoch:31 step:146635[D loss: 0.999952] [G loss: 1.000099]\n",
      "epoch:31 step:146640[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:31 step:146645[D loss: 0.999993] [G loss: 1.000060]\n",
      "epoch:31 step:146650[D loss: 0.999904] [G loss: 1.000105]\n",
      "epoch:31 step:146655[D loss: 1.000163] [G loss: 0.999824]\n",
      "epoch:31 step:146660[D loss: 0.999952] [G loss: 1.000128]\n",
      "epoch:31 step:146665[D loss: 0.999907] [G loss: 1.000092]\n",
      "epoch:31 step:146670[D loss: 0.999995] [G loss: 1.000093]\n",
      "epoch:31 step:146675[D loss: 0.999994] [G loss: 1.000079]\n",
      "epoch:31 step:146680[D loss: 0.999926] [G loss: 1.000115]\n",
      "epoch:31 step:146685[D loss: 0.999952] [G loss: 1.000112]\n",
      "epoch:31 step:146690[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:31 step:146695[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:31 step:146700[D loss: 1.000027] [G loss: 1.000003]\n",
      "epoch:31 step:146705[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:31 step:146710[D loss: 1.000058] [G loss: 0.999988]\n",
      "epoch:31 step:146715[D loss: 1.000011] [G loss: 1.000034]\n",
      "epoch:31 step:146720[D loss: 0.999870] [G loss: 1.000180]\n",
      "epoch:31 step:146725[D loss: 1.000005] [G loss: 0.999971]\n",
      "epoch:31 step:146730[D loss: 0.999946] [G loss: 1.000082]\n",
      "epoch:31 step:146735[D loss: 1.000034] [G loss: 0.999928]\n",
      "epoch:31 step:146740[D loss: 0.999950] [G loss: 1.000085]\n",
      "epoch:31 step:146745[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:31 step:146750[D loss: 0.999969] [G loss: 1.000201]\n",
      "epoch:31 step:146755[D loss: 0.999926] [G loss: 1.000071]\n",
      "epoch:31 step:146760[D loss: 0.999988] [G loss: 1.000043]\n",
      "epoch:31 step:146765[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:31 step:146770[D loss: 0.999987] [G loss: 1.000023]\n",
      "epoch:31 step:146775[D loss: 0.999986] [G loss: 1.000012]\n",
      "epoch:31 step:146780[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:31 step:146785[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:31 step:146790[D loss: 1.000020] [G loss: 0.999979]\n",
      "epoch:31 step:146795[D loss: 0.999961] [G loss: 1.000029]\n",
      "epoch:31 step:146800[D loss: 0.999949] [G loss: 1.000074]\n",
      "epoch:31 step:146805[D loss: 0.999973] [G loss: 1.000020]\n",
      "epoch:31 step:146810[D loss: 0.999970] [G loss: 1.000039]\n",
      "epoch:31 step:146815[D loss: 1.000019] [G loss: 1.000030]\n",
      "epoch:31 step:146820[D loss: 1.000008] [G loss: 0.999994]\n",
      "epoch:31 step:146825[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:31 step:146830[D loss: 0.999940] [G loss: 1.000094]\n",
      "epoch:31 step:146835[D loss: 0.999958] [G loss: 1.000029]\n",
      "epoch:31 step:146840[D loss: 1.000129] [G loss: 0.999865]\n",
      "epoch:31 step:146845[D loss: 1.000027] [G loss: 1.000091]\n",
      "epoch:31 step:146850[D loss: 0.999987] [G loss: 1.000146]\n",
      "epoch:31 step:146855[D loss: 1.000024] [G loss: 0.999958]\n",
      "epoch:31 step:146860[D loss: 0.999949] [G loss: 0.999962]\n",
      "epoch:31 step:146865[D loss: 1.000036] [G loss: 0.999963]\n",
      "epoch:31 step:146870[D loss: 1.000209] [G loss: 0.999750]\n",
      "epoch:31 step:146875[D loss: 0.999916] [G loss: 0.999986]\n",
      "epoch:31 step:146880[D loss: 1.000078] [G loss: 1.000005]\n",
      "epoch:31 step:146885[D loss: 0.999865] [G loss: 1.000123]\n",
      "epoch:31 step:146890[D loss: 0.999976] [G loss: 1.000044]\n",
      "epoch:31 step:146895[D loss: 0.999944] [G loss: 1.000128]\n",
      "epoch:31 step:146900[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:31 step:146905[D loss: 1.000032] [G loss: 0.999963]\n",
      "epoch:31 step:146910[D loss: 1.000016] [G loss: 0.999976]\n",
      "epoch:31 step:146915[D loss: 0.999944] [G loss: 1.000090]\n",
      "epoch:31 step:146920[D loss: 1.000074] [G loss: 0.999888]\n",
      "epoch:31 step:146925[D loss: 0.999914] [G loss: 1.000198]\n",
      "epoch:31 step:146930[D loss: 0.999930] [G loss: 1.000125]\n",
      "epoch:31 step:146935[D loss: 0.999973] [G loss: 1.000047]\n",
      "epoch:31 step:146940[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:31 step:146945[D loss: 0.999957] [G loss: 1.000064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:146950[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:31 step:146955[D loss: 0.999979] [G loss: 1.000035]\n",
      "epoch:31 step:146960[D loss: 0.999960] [G loss: 1.000039]\n",
      "epoch:31 step:146965[D loss: 1.000177] [G loss: 0.999870]\n",
      "epoch:31 step:146970[D loss: 0.999913] [G loss: 1.000091]\n",
      "epoch:31 step:146975[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:31 step:146980[D loss: 1.000015] [G loss: 1.000058]\n",
      "epoch:31 step:146985[D loss: 0.999965] [G loss: 1.000026]\n",
      "epoch:31 step:146990[D loss: 0.999976] [G loss: 1.000122]\n",
      "epoch:31 step:146995[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:31 step:147000[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:31 step:147005[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:31 step:147010[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:31 step:147015[D loss: 0.999919] [G loss: 1.000088]\n",
      "epoch:31 step:147020[D loss: 0.999979] [G loss: 1.000051]\n",
      "epoch:31 step:147025[D loss: 1.000042] [G loss: 1.000106]\n",
      "epoch:31 step:147030[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:31 step:147035[D loss: 1.000140] [G loss: 0.999832]\n",
      "epoch:31 step:147040[D loss: 0.999850] [G loss: 1.000211]\n",
      "epoch:31 step:147045[D loss: 0.999947] [G loss: 1.000086]\n",
      "epoch:31 step:147050[D loss: 1.000103] [G loss: 0.999857]\n",
      "epoch:31 step:147055[D loss: 1.000119] [G loss: 0.999930]\n",
      "epoch:31 step:147060[D loss: 1.000095] [G loss: 0.999929]\n",
      "epoch:31 step:147065[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:31 step:147070[D loss: 1.000102] [G loss: 0.999974]\n",
      "epoch:31 step:147075[D loss: 1.000076] [G loss: 0.999932]\n",
      "epoch:31 step:147080[D loss: 0.999937] [G loss: 1.000132]\n",
      "epoch:31 step:147085[D loss: 0.999990] [G loss: 1.000134]\n",
      "epoch:31 step:147090[D loss: 0.999919] [G loss: 1.000161]\n",
      "epoch:31 step:147095[D loss: 0.999955] [G loss: 1.000122]\n",
      "epoch:31 step:147100[D loss: 0.999991] [G loss: 1.000016]\n",
      "epoch:31 step:147105[D loss: 1.000067] [G loss: 1.000061]\n",
      "epoch:31 step:147110[D loss: 0.999967] [G loss: 1.000040]\n",
      "epoch:31 step:147115[D loss: 0.999962] [G loss: 1.000041]\n",
      "epoch:31 step:147120[D loss: 1.000006] [G loss: 0.999937]\n",
      "epoch:31 step:147125[D loss: 1.000177] [G loss: 0.999825]\n",
      "epoch:31 step:147130[D loss: 0.999972] [G loss: 1.000006]\n",
      "epoch:31 step:147135[D loss: 0.999952] [G loss: 1.000017]\n",
      "epoch:31 step:147140[D loss: 0.999872] [G loss: 1.000138]\n",
      "epoch:31 step:147145[D loss: 1.000019] [G loss: 1.000177]\n",
      "epoch:31 step:147150[D loss: 0.999910] [G loss: 1.000105]\n",
      "epoch:31 step:147155[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:31 step:147160[D loss: 1.000015] [G loss: 0.999990]\n",
      "epoch:31 step:147165[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:31 step:147170[D loss: 1.000021] [G loss: 0.999972]\n",
      "epoch:31 step:147175[D loss: 1.000022] [G loss: 0.999989]\n",
      "epoch:31 step:147180[D loss: 0.999935] [G loss: 1.000091]\n",
      "epoch:31 step:147185[D loss: 0.999950] [G loss: 1.000059]\n",
      "epoch:31 step:147190[D loss: 0.999986] [G loss: 1.000053]\n",
      "epoch:31 step:147195[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:31 step:147200[D loss: 0.999955] [G loss: 1.000068]\n",
      "epoch:31 step:147205[D loss: 0.999991] [G loss: 1.000035]\n",
      "epoch:31 step:147210[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:31 step:147215[D loss: 0.999995] [G loss: 1.000054]\n",
      "epoch:31 step:147220[D loss: 0.999932] [G loss: 1.000085]\n",
      "epoch:31 step:147225[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:31 step:147230[D loss: 1.000053] [G loss: 0.999868]\n",
      "epoch:31 step:147235[D loss: 1.000014] [G loss: 0.999988]\n",
      "epoch:31 step:147240[D loss: 1.000005] [G loss: 1.000052]\n",
      "epoch:31 step:147245[D loss: 0.999899] [G loss: 1.000161]\n",
      "epoch:31 step:147250[D loss: 0.999895] [G loss: 1.000207]\n",
      "epoch:31 step:147255[D loss: 0.999905] [G loss: 1.000139]\n",
      "epoch:31 step:147260[D loss: 0.999962] [G loss: 1.000048]\n",
      "epoch:31 step:147265[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:31 step:147270[D loss: 1.000020] [G loss: 1.000021]\n",
      "epoch:31 step:147275[D loss: 0.999957] [G loss: 1.000018]\n",
      "epoch:31 step:147280[D loss: 1.000029] [G loss: 0.999918]\n",
      "epoch:31 step:147285[D loss: 1.000086] [G loss: 1.000035]\n",
      "epoch:31 step:147290[D loss: 0.999883] [G loss: 1.000143]\n",
      "epoch:31 step:147295[D loss: 0.999953] [G loss: 1.000049]\n",
      "epoch:31 step:147300[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:31 step:147305[D loss: 0.999996] [G loss: 0.999991]\n",
      "epoch:31 step:147310[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:31 step:147315[D loss: 0.999958] [G loss: 1.000091]\n",
      "epoch:31 step:147320[D loss: 0.999965] [G loss: 1.000060]\n",
      "epoch:31 step:147325[D loss: 0.999976] [G loss: 1.000073]\n",
      "epoch:31 step:147330[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:31 step:147335[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:31 step:147340[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:31 step:147345[D loss: 0.999970] [G loss: 1.000103]\n",
      "epoch:31 step:147350[D loss: 1.000015] [G loss: 0.999996]\n",
      "epoch:31 step:147355[D loss: 0.999993] [G loss: 1.000075]\n",
      "epoch:31 step:147360[D loss: 0.999997] [G loss: 1.000052]\n",
      "epoch:31 step:147365[D loss: 0.999932] [G loss: 1.000091]\n",
      "epoch:31 step:147370[D loss: 0.999974] [G loss: 1.000084]\n",
      "epoch:31 step:147375[D loss: 1.000005] [G loss: 1.000004]\n",
      "epoch:31 step:147380[D loss: 0.999961] [G loss: 1.000037]\n",
      "epoch:31 step:147385[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:31 step:147390[D loss: 1.000005] [G loss: 0.999968]\n",
      "epoch:31 step:147395[D loss: 1.000048] [G loss: 1.000042]\n",
      "epoch:31 step:147400[D loss: 0.999935] [G loss: 1.000099]\n",
      "epoch:31 step:147405[D loss: 1.000076] [G loss: 0.999979]\n",
      "epoch:31 step:147410[D loss: 0.999976] [G loss: 1.000107]\n",
      "epoch:31 step:147415[D loss: 1.000042] [G loss: 0.999910]\n",
      "epoch:31 step:147420[D loss: 0.999913] [G loss: 1.000059]\n",
      "epoch:31 step:147425[D loss: 0.999936] [G loss: 1.000075]\n",
      "epoch:31 step:147430[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:31 step:147435[D loss: 1.000015] [G loss: 1.000000]\n",
      "epoch:31 step:147440[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:31 step:147445[D loss: 0.999959] [G loss: 1.000146]\n",
      "epoch:31 step:147450[D loss: 0.999949] [G loss: 1.000114]\n",
      "epoch:31 step:147455[D loss: 1.000008] [G loss: 1.000060]\n",
      "epoch:31 step:147460[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:31 step:147465[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:31 step:147470[D loss: 0.999968] [G loss: 1.000139]\n",
      "epoch:31 step:147475[D loss: 1.000012] [G loss: 1.000031]\n",
      "epoch:31 step:147480[D loss: 1.000003] [G loss: 1.000025]\n",
      "epoch:31 step:147485[D loss: 0.999949] [G loss: 1.000085]\n",
      "epoch:31 step:147490[D loss: 0.999982] [G loss: 1.000010]\n",
      "epoch:31 step:147495[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:31 step:147500[D loss: 0.999970] [G loss: 1.000066]\n",
      "epoch:31 step:147505[D loss: 0.999956] [G loss: 1.000070]\n",
      "epoch:31 step:147510[D loss: 0.999944] [G loss: 1.000077]\n",
      "epoch:31 step:147515[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:31 step:147520[D loss: 0.999953] [G loss: 1.000128]\n",
      "epoch:31 step:147525[D loss: 1.000017] [G loss: 1.000106]\n",
      "epoch:31 step:147530[D loss: 1.000109] [G loss: 1.000076]\n",
      "epoch:31 step:147535[D loss: 0.999954] [G loss: 1.000107]\n",
      "epoch:31 step:147540[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:31 step:147545[D loss: 1.000069] [G loss: 0.999894]\n",
      "epoch:31 step:147550[D loss: 0.999969] [G loss: 1.000039]\n",
      "epoch:31 step:147555[D loss: 0.999953] [G loss: 1.000144]\n",
      "epoch:31 step:147560[D loss: 1.000022] [G loss: 1.000070]\n",
      "epoch:31 step:147565[D loss: 0.999947] [G loss: 1.000078]\n",
      "epoch:31 step:147570[D loss: 0.999985] [G loss: 1.000055]\n",
      "epoch:31 step:147575[D loss: 0.999978] [G loss: 1.000103]\n",
      "epoch:31 step:147580[D loss: 1.000094] [G loss: 0.999958]\n",
      "epoch:31 step:147585[D loss: 0.999923] [G loss: 1.000113]\n",
      "epoch:31 step:147590[D loss: 0.999954] [G loss: 1.000113]\n",
      "epoch:31 step:147595[D loss: 1.000006] [G loss: 1.000017]\n",
      "epoch:31 step:147600[D loss: 0.999992] [G loss: 1.000022]\n",
      "epoch:31 step:147605[D loss: 1.000060] [G loss: 0.999975]\n",
      "epoch:31 step:147610[D loss: 0.999895] [G loss: 1.000145]\n",
      "epoch:31 step:147615[D loss: 0.999979] [G loss: 0.999950]\n",
      "epoch:31 step:147620[D loss: 0.999928] [G loss: 1.000103]\n",
      "epoch:31 step:147625[D loss: 1.000007] [G loss: 1.000071]\n",
      "epoch:31 step:147630[D loss: 0.999941] [G loss: 1.000055]\n",
      "epoch:31 step:147635[D loss: 0.999969] [G loss: 1.000075]\n",
      "epoch:31 step:147640[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:31 step:147645[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:31 step:147650[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:31 step:147655[D loss: 0.999973] [G loss: 1.000071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:147660[D loss: 1.000128] [G loss: 1.000066]\n",
      "epoch:31 step:147665[D loss: 0.999886] [G loss: 1.000091]\n",
      "epoch:31 step:147670[D loss: 1.000004] [G loss: 1.000124]\n",
      "epoch:31 step:147675[D loss: 0.999925] [G loss: 1.000268]\n",
      "epoch:31 step:147680[D loss: 0.999994] [G loss: 1.000134]\n",
      "epoch:31 step:147685[D loss: 0.999878] [G loss: 1.000272]\n",
      "epoch:31 step:147690[D loss: 0.999934] [G loss: 1.000212]\n",
      "epoch:31 step:147695[D loss: 1.000061] [G loss: 1.000104]\n",
      "epoch:31 step:147700[D loss: 1.000102] [G loss: 1.000095]\n",
      "epoch:31 step:147705[D loss: 0.999879] [G loss: 1.000447]\n",
      "epoch:31 step:147710[D loss: 0.999980] [G loss: 1.000027]\n",
      "epoch:31 step:147715[D loss: 0.999969] [G loss: 1.000157]\n",
      "epoch:31 step:147720[D loss: 0.999993] [G loss: 1.000077]\n",
      "epoch:31 step:147725[D loss: 1.000052] [G loss: 0.999923]\n",
      "epoch:31 step:147730[D loss: 1.000110] [G loss: 0.999867]\n",
      "epoch:31 step:147735[D loss: 1.000163] [G loss: 0.999820]\n",
      "epoch:31 step:147740[D loss: 0.999940] [G loss: 1.000040]\n",
      "epoch:31 step:147745[D loss: 0.999882] [G loss: 1.000123]\n",
      "epoch:31 step:147750[D loss: 0.999912] [G loss: 1.000022]\n",
      "epoch:31 step:147755[D loss: 1.000012] [G loss: 1.000095]\n",
      "epoch:31 step:147760[D loss: 1.000084] [G loss: 0.999866]\n",
      "epoch:31 step:147765[D loss: 0.999923] [G loss: 1.000143]\n",
      "epoch:31 step:147770[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:31 step:147775[D loss: 1.000059] [G loss: 1.000019]\n",
      "epoch:31 step:147780[D loss: 1.000025] [G loss: 1.000018]\n",
      "epoch:31 step:147785[D loss: 1.000197] [G loss: 1.000080]\n",
      "epoch:31 step:147790[D loss: 0.999967] [G loss: 1.000109]\n",
      "epoch:31 step:147795[D loss: 0.999956] [G loss: 1.000048]\n",
      "epoch:31 step:147800[D loss: 1.000005] [G loss: 1.000036]\n",
      "epoch:31 step:147805[D loss: 1.000072] [G loss: 0.999979]\n",
      "epoch:31 step:147810[D loss: 0.999991] [G loss: 1.000019]\n",
      "epoch:31 step:147815[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:31 step:147820[D loss: 1.000162] [G loss: 0.999960]\n",
      "epoch:31 step:147825[D loss: 1.000063] [G loss: 0.999830]\n",
      "epoch:31 step:147830[D loss: 0.999915] [G loss: 1.000158]\n",
      "epoch:31 step:147835[D loss: 0.999897] [G loss: 1.000241]\n",
      "epoch:31 step:147840[D loss: 0.999964] [G loss: 1.000127]\n",
      "epoch:31 step:147845[D loss: 0.999996] [G loss: 1.000027]\n",
      "epoch:31 step:147850[D loss: 0.999948] [G loss: 1.000067]\n",
      "epoch:31 step:147855[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:31 step:147860[D loss: 0.999976] [G loss: 1.000037]\n",
      "epoch:31 step:147865[D loss: 1.000018] [G loss: 1.000001]\n",
      "epoch:31 step:147870[D loss: 0.999908] [G loss: 1.000167]\n",
      "epoch:31 step:147875[D loss: 0.999986] [G loss: 1.000010]\n",
      "epoch:31 step:147880[D loss: 0.999967] [G loss: 1.000124]\n",
      "epoch:31 step:147885[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:31 step:147890[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:31 step:147895[D loss: 0.999982] [G loss: 1.000088]\n",
      "epoch:31 step:147900[D loss: 0.999975] [G loss: 1.000067]\n",
      "epoch:31 step:147905[D loss: 0.999991] [G loss: 1.000075]\n",
      "epoch:31 step:147910[D loss: 0.999965] [G loss: 1.000067]\n",
      "epoch:31 step:147915[D loss: 1.000100] [G loss: 0.999956]\n",
      "epoch:31 step:147920[D loss: 1.000080] [G loss: 0.999931]\n",
      "epoch:31 step:147925[D loss: 0.999815] [G loss: 1.000301]\n",
      "epoch:31 step:147930[D loss: 0.999935] [G loss: 1.000200]\n",
      "epoch:31 step:147935[D loss: 0.999918] [G loss: 1.000205]\n",
      "epoch:31 step:147940[D loss: 0.999902] [G loss: 1.000162]\n",
      "epoch:31 step:147945[D loss: 0.999979] [G loss: 1.000024]\n",
      "epoch:31 step:147950[D loss: 1.000102] [G loss: 0.999959]\n",
      "epoch:31 step:147955[D loss: 0.999899] [G loss: 1.000211]\n",
      "epoch:31 step:147960[D loss: 0.999938] [G loss: 1.000123]\n",
      "epoch:31 step:147965[D loss: 1.000024] [G loss: 1.000022]\n",
      "epoch:31 step:147970[D loss: 0.999931] [G loss: 1.000052]\n",
      "epoch:31 step:147975[D loss: 0.999966] [G loss: 1.000097]\n",
      "epoch:31 step:147980[D loss: 0.999987] [G loss: 1.000056]\n",
      "epoch:31 step:147985[D loss: 1.000001] [G loss: 1.000167]\n",
      "epoch:31 step:147990[D loss: 0.999976] [G loss: 1.000010]\n",
      "epoch:31 step:147995[D loss: 0.999970] [G loss: 1.000104]\n",
      "epoch:31 step:148000[D loss: 0.999915] [G loss: 1.000070]\n",
      "epoch:31 step:148005[D loss: 0.999981] [G loss: 1.000109]\n",
      "epoch:31 step:148010[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:31 step:148015[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:31 step:148020[D loss: 0.999983] [G loss: 1.000027]\n",
      "epoch:31 step:148025[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:31 step:148030[D loss: 0.999908] [G loss: 1.000141]\n",
      "epoch:31 step:148035[D loss: 0.999954] [G loss: 1.000077]\n",
      "epoch:31 step:148040[D loss: 1.000009] [G loss: 1.000055]\n",
      "epoch:31 step:148045[D loss: 0.999868] [G loss: 1.000220]\n",
      "epoch:31 step:148050[D loss: 0.999993] [G loss: 1.000083]\n",
      "epoch:31 step:148055[D loss: 0.999995] [G loss: 1.000093]\n",
      "epoch:31 step:148060[D loss: 0.999984] [G loss: 1.000036]\n",
      "epoch:31 step:148065[D loss: 0.999921] [G loss: 1.000108]\n",
      "epoch:31 step:148070[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:31 step:148075[D loss: 0.999971] [G loss: 1.000012]\n",
      "epoch:31 step:148080[D loss: 0.999977] [G loss: 1.000051]\n",
      "epoch:31 step:148085[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:31 step:148090[D loss: 0.999952] [G loss: 1.000090]\n",
      "epoch:31 step:148095[D loss: 1.000006] [G loss: 1.000097]\n",
      "epoch:31 step:148100[D loss: 1.000013] [G loss: 0.999979]\n",
      "epoch:31 step:148105[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:31 step:148110[D loss: 0.999934] [G loss: 1.000197]\n",
      "epoch:31 step:148115[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:31 step:148120[D loss: 0.999953] [G loss: 1.000068]\n",
      "epoch:31 step:148125[D loss: 0.999978] [G loss: 1.000086]\n",
      "epoch:31 step:148130[D loss: 0.999964] [G loss: 1.000056]\n",
      "epoch:31 step:148135[D loss: 0.999992] [G loss: 1.000092]\n",
      "epoch:31 step:148140[D loss: 0.999971] [G loss: 1.000074]\n",
      "epoch:31 step:148145[D loss: 1.000083] [G loss: 0.999854]\n",
      "epoch:31 step:148150[D loss: 0.999972] [G loss: 1.000116]\n",
      "epoch:31 step:148155[D loss: 0.999920] [G loss: 1.000077]\n",
      "epoch:31 step:148160[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:31 step:148165[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:31 step:148170[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:31 step:148175[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:31 step:148180[D loss: 0.999970] [G loss: 1.000142]\n",
      "epoch:31 step:148185[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:31 step:148190[D loss: 0.999983] [G loss: 1.000051]\n",
      "epoch:31 step:148195[D loss: 1.000238] [G loss: 0.999761]\n",
      "epoch:31 step:148200[D loss: 1.000083] [G loss: 1.000058]\n",
      "epoch:31 step:148205[D loss: 0.999965] [G loss: 1.000117]\n",
      "epoch:31 step:148210[D loss: 1.000058] [G loss: 1.000084]\n",
      "epoch:31 step:148215[D loss: 0.999980] [G loss: 1.000036]\n",
      "epoch:31 step:148220[D loss: 0.999893] [G loss: 1.000174]\n",
      "epoch:31 step:148225[D loss: 0.999967] [G loss: 1.000082]\n",
      "epoch:31 step:148230[D loss: 0.999976] [G loss: 1.000030]\n",
      "epoch:31 step:148235[D loss: 0.999978] [G loss: 1.000025]\n",
      "epoch:31 step:148240[D loss: 1.000061] [G loss: 0.999924]\n",
      "epoch:31 step:148245[D loss: 1.000174] [G loss: 0.999784]\n",
      "epoch:31 step:148250[D loss: 0.999943] [G loss: 0.999994]\n",
      "epoch:31 step:148255[D loss: 1.000067] [G loss: 0.999985]\n",
      "epoch:31 step:148260[D loss: 1.000005] [G loss: 0.999909]\n",
      "epoch:31 step:148265[D loss: 0.999926] [G loss: 1.000079]\n",
      "epoch:31 step:148270[D loss: 1.000048] [G loss: 0.999958]\n",
      "epoch:31 step:148275[D loss: 0.999986] [G loss: 1.000022]\n",
      "epoch:31 step:148280[D loss: 1.000111] [G loss: 1.000008]\n",
      "epoch:31 step:148285[D loss: 0.999927] [G loss: 1.000003]\n",
      "epoch:31 step:148290[D loss: 1.000039] [G loss: 1.000150]\n",
      "epoch:31 step:148295[D loss: 0.999896] [G loss: 1.000200]\n",
      "epoch:31 step:148300[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:31 step:148305[D loss: 0.999975] [G loss: 1.000059]\n",
      "epoch:31 step:148310[D loss: 0.999941] [G loss: 1.000031]\n",
      "epoch:31 step:148315[D loss: 0.999946] [G loss: 1.000053]\n",
      "epoch:31 step:148320[D loss: 1.000119] [G loss: 0.999859]\n",
      "epoch:31 step:148325[D loss: 1.000070] [G loss: 0.999841]\n",
      "epoch:31 step:148330[D loss: 0.999920] [G loss: 1.000054]\n",
      "epoch:31 step:148335[D loss: 1.000104] [G loss: 0.999908]\n",
      "epoch:31 step:148340[D loss: 0.999933] [G loss: 1.000088]\n",
      "epoch:31 step:148345[D loss: 1.000027] [G loss: 1.000049]\n",
      "epoch:31 step:148350[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:31 step:148355[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:31 step:148360[D loss: 0.999996] [G loss: 1.000060]\n",
      "epoch:31 step:148365[D loss: 0.999931] [G loss: 1.000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:148370[D loss: 0.999961] [G loss: 1.000081]\n",
      "epoch:31 step:148375[D loss: 0.999993] [G loss: 1.000052]\n",
      "epoch:31 step:148380[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:31 step:148385[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:31 step:148390[D loss: 1.000009] [G loss: 1.000077]\n",
      "epoch:31 step:148395[D loss: 1.000000] [G loss: 1.000065]\n",
      "epoch:31 step:148400[D loss: 1.000015] [G loss: 1.000019]\n",
      "epoch:31 step:148405[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:31 step:148410[D loss: 0.999968] [G loss: 1.000060]\n",
      "epoch:31 step:148415[D loss: 0.999978] [G loss: 1.000045]\n",
      "epoch:31 step:148420[D loss: 1.000028] [G loss: 0.999988]\n",
      "epoch:31 step:148425[D loss: 0.999927] [G loss: 1.000055]\n",
      "epoch:31 step:148430[D loss: 1.000019] [G loss: 0.999977]\n",
      "epoch:31 step:148435[D loss: 0.999983] [G loss: 1.000084]\n",
      "epoch:31 step:148440[D loss: 0.999949] [G loss: 1.000072]\n",
      "epoch:31 step:148445[D loss: 0.999990] [G loss: 1.000032]\n",
      "epoch:31 step:148450[D loss: 0.999994] [G loss: 1.000029]\n",
      "epoch:31 step:148455[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:31 step:148460[D loss: 1.000004] [G loss: 0.999953]\n",
      "epoch:31 step:148465[D loss: 1.000039] [G loss: 1.000030]\n",
      "epoch:31 step:148470[D loss: 0.999899] [G loss: 1.000122]\n",
      "epoch:31 step:148475[D loss: 0.999953] [G loss: 1.000084]\n",
      "epoch:31 step:148480[D loss: 0.999989] [G loss: 1.000034]\n",
      "epoch:31 step:148485[D loss: 0.999981] [G loss: 1.000041]\n",
      "epoch:31 step:148490[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:31 step:148495[D loss: 0.999987] [G loss: 1.000015]\n",
      "epoch:31 step:148500[D loss: 0.999974] [G loss: 1.000069]\n",
      "epoch:31 step:148505[D loss: 0.999985] [G loss: 1.000068]\n",
      "epoch:31 step:148510[D loss: 1.000030] [G loss: 0.999894]\n",
      "epoch:31 step:148515[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:31 step:148520[D loss: 0.999996] [G loss: 1.000038]\n",
      "epoch:31 step:148525[D loss: 0.999964] [G loss: 1.000028]\n",
      "epoch:31 step:148530[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:31 step:148535[D loss: 0.999916] [G loss: 1.000104]\n",
      "epoch:31 step:148540[D loss: 1.000012] [G loss: 1.000145]\n",
      "epoch:31 step:148545[D loss: 0.999984] [G loss: 1.000140]\n",
      "epoch:31 step:148550[D loss: 0.999970] [G loss: 1.000090]\n",
      "epoch:31 step:148555[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:31 step:148560[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:31 step:148565[D loss: 1.000066] [G loss: 0.999949]\n",
      "epoch:31 step:148570[D loss: 0.999926] [G loss: 0.999995]\n",
      "epoch:31 step:148575[D loss: 0.999989] [G loss: 1.000058]\n",
      "epoch:31 step:148580[D loss: 0.999977] [G loss: 1.000055]\n",
      "epoch:31 step:148585[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:31 step:148590[D loss: 1.000001] [G loss: 1.000022]\n",
      "epoch:31 step:148595[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:31 step:148600[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:31 step:148605[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:31 step:148610[D loss: 0.999977] [G loss: 1.000073]\n",
      "epoch:31 step:148615[D loss: 0.999994] [G loss: 1.000051]\n",
      "epoch:31 step:148620[D loss: 0.999988] [G loss: 1.000033]\n",
      "epoch:31 step:148625[D loss: 0.999963] [G loss: 1.000107]\n",
      "epoch:31 step:148630[D loss: 0.999991] [G loss: 1.000118]\n",
      "epoch:31 step:148635[D loss: 0.999992] [G loss: 1.000060]\n",
      "epoch:31 step:148640[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:31 step:148645[D loss: 0.999970] [G loss: 1.000086]\n",
      "epoch:31 step:148650[D loss: 0.999982] [G loss: 1.000005]\n",
      "epoch:31 step:148655[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:31 step:148660[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:31 step:148665[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:31 step:148670[D loss: 0.999994] [G loss: 1.000091]\n",
      "epoch:31 step:148675[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:31 step:148680[D loss: 1.000075] [G loss: 0.999881]\n",
      "epoch:31 step:148685[D loss: 0.999968] [G loss: 1.000011]\n",
      "epoch:31 step:148690[D loss: 0.999931] [G loss: 1.000106]\n",
      "epoch:31 step:148695[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:31 step:148700[D loss: 1.000021] [G loss: 1.000133]\n",
      "epoch:31 step:148705[D loss: 0.999967] [G loss: 1.000126]\n",
      "epoch:31 step:148710[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:31 step:148715[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:31 step:148720[D loss: 1.000000] [G loss: 1.000027]\n",
      "epoch:31 step:148725[D loss: 0.999958] [G loss: 1.000083]\n",
      "epoch:31 step:148730[D loss: 1.000026] [G loss: 1.000001]\n",
      "epoch:31 step:148735[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:31 step:148740[D loss: 1.000001] [G loss: 1.000001]\n",
      "epoch:31 step:148745[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:31 step:148750[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:31 step:148755[D loss: 0.999952] [G loss: 1.000080]\n",
      "epoch:31 step:148760[D loss: 0.999995] [G loss: 1.000056]\n",
      "epoch:31 step:148765[D loss: 1.000031] [G loss: 0.999979]\n",
      "epoch:31 step:148770[D loss: 0.999941] [G loss: 1.000115]\n",
      "epoch:31 step:148775[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:31 step:148780[D loss: 1.000059] [G loss: 0.999949]\n",
      "epoch:31 step:148785[D loss: 1.000062] [G loss: 1.000017]\n",
      "epoch:31 step:148790[D loss: 0.999902] [G loss: 1.000137]\n",
      "epoch:31 step:148795[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:31 step:148800[D loss: 0.999944] [G loss: 1.000110]\n",
      "epoch:31 step:148805[D loss: 1.000020] [G loss: 1.000179]\n",
      "epoch:31 step:148810[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:31 step:148815[D loss: 0.999994] [G loss: 1.000028]\n",
      "epoch:31 step:148820[D loss: 1.000008] [G loss: 0.999989]\n",
      "epoch:31 step:148825[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:31 step:148830[D loss: 1.000032] [G loss: 1.000012]\n",
      "epoch:31 step:148835[D loss: 0.999971] [G loss: 1.000112]\n",
      "epoch:31 step:148840[D loss: 0.999954] [G loss: 1.000123]\n",
      "epoch:31 step:148845[D loss: 1.000061] [G loss: 1.000000]\n",
      "epoch:31 step:148850[D loss: 0.999943] [G loss: 1.000111]\n",
      "epoch:31 step:148855[D loss: 0.999962] [G loss: 1.000065]\n",
      "epoch:31 step:148860[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:31 step:148865[D loss: 0.999997] [G loss: 1.000049]\n",
      "epoch:31 step:148870[D loss: 0.999980] [G loss: 1.000030]\n",
      "epoch:31 step:148875[D loss: 1.000029] [G loss: 1.000034]\n",
      "epoch:31 step:148880[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:31 step:148885[D loss: 0.999956] [G loss: 1.000139]\n",
      "epoch:31 step:148890[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:31 step:148895[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:31 step:148900[D loss: 0.999971] [G loss: 1.000050]\n",
      "epoch:31 step:148905[D loss: 0.999973] [G loss: 1.000090]\n",
      "epoch:31 step:148910[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:31 step:148915[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:31 step:148920[D loss: 1.000039] [G loss: 1.000072]\n",
      "epoch:31 step:148925[D loss: 0.999988] [G loss: 1.000053]\n",
      "epoch:31 step:148930[D loss: 1.000074] [G loss: 0.999991]\n",
      "epoch:31 step:148935[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:31 step:148940[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:31 step:148945[D loss: 1.000260] [G loss: 0.999749]\n",
      "epoch:31 step:148950[D loss: 0.999771] [G loss: 1.000108]\n",
      "epoch:31 step:148955[D loss: 0.999958] [G loss: 1.000070]\n",
      "epoch:31 step:148960[D loss: 0.999976] [G loss: 1.000040]\n",
      "epoch:31 step:148965[D loss: 0.999975] [G loss: 1.000056]\n",
      "epoch:31 step:148970[D loss: 0.999946] [G loss: 1.000053]\n",
      "epoch:31 step:148975[D loss: 0.999973] [G loss: 1.000085]\n",
      "epoch:31 step:148980[D loss: 0.999974] [G loss: 1.000070]\n",
      "epoch:31 step:148985[D loss: 1.000021] [G loss: 1.000052]\n",
      "epoch:31 step:148990[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:31 step:148995[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:31 step:149000[D loss: 0.999982] [G loss: 1.000047]\n",
      "epoch:31 step:149005[D loss: 1.000042] [G loss: 0.999980]\n",
      "epoch:31 step:149010[D loss: 1.000025] [G loss: 1.000003]\n",
      "epoch:31 step:149015[D loss: 0.999996] [G loss: 0.999997]\n",
      "epoch:31 step:149020[D loss: 0.999993] [G loss: 1.000068]\n",
      "epoch:31 step:149025[D loss: 0.999985] [G loss: 1.000034]\n",
      "epoch:31 step:149030[D loss: 0.999913] [G loss: 1.000124]\n",
      "epoch:31 step:149035[D loss: 1.000024] [G loss: 1.000069]\n",
      "epoch:31 step:149040[D loss: 0.999971] [G loss: 1.000108]\n",
      "epoch:31 step:149045[D loss: 1.000058] [G loss: 1.000091]\n",
      "epoch:31 step:149050[D loss: 0.999952] [G loss: 1.000091]\n",
      "epoch:31 step:149055[D loss: 0.999945] [G loss: 1.000073]\n",
      "epoch:31 step:149060[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:31 step:149065[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:31 step:149070[D loss: 0.999925] [G loss: 1.000103]\n",
      "epoch:31 step:149075[D loss: 1.000007] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:149080[D loss: 0.999906] [G loss: 1.000114]\n",
      "epoch:31 step:149085[D loss: 0.999973] [G loss: 1.000067]\n",
      "epoch:31 step:149090[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:31 step:149095[D loss: 1.000019] [G loss: 1.000055]\n",
      "epoch:31 step:149100[D loss: 1.000015] [G loss: 1.000036]\n",
      "epoch:31 step:149105[D loss: 1.000028] [G loss: 1.000040]\n",
      "epoch:31 step:149110[D loss: 0.999967] [G loss: 1.000058]\n",
      "epoch:31 step:149115[D loss: 0.999919] [G loss: 1.000090]\n",
      "epoch:31 step:149120[D loss: 0.999998] [G loss: 1.000004]\n",
      "epoch:31 step:149125[D loss: 0.999931] [G loss: 1.000124]\n",
      "epoch:31 step:149130[D loss: 1.000127] [G loss: 0.999918]\n",
      "epoch:31 step:149135[D loss: 0.999963] [G loss: 1.000135]\n",
      "epoch:31 step:149140[D loss: 0.999955] [G loss: 0.999990]\n",
      "epoch:31 step:149145[D loss: 0.999975] [G loss: 0.999981]\n",
      "epoch:31 step:149150[D loss: 0.999963] [G loss: 1.000006]\n",
      "epoch:31 step:149155[D loss: 0.999947] [G loss: 1.000042]\n",
      "epoch:31 step:149160[D loss: 0.999951] [G loss: 1.000059]\n",
      "epoch:31 step:149165[D loss: 0.999950] [G loss: 1.000085]\n",
      "epoch:31 step:149170[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:31 step:149175[D loss: 1.000037] [G loss: 0.999981]\n",
      "epoch:31 step:149180[D loss: 1.000157] [G loss: 0.999897]\n",
      "epoch:31 step:149185[D loss: 0.999964] [G loss: 0.999989]\n",
      "epoch:31 step:149190[D loss: 0.999963] [G loss: 1.000026]\n",
      "epoch:31 step:149195[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:31 step:149200[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:31 step:149205[D loss: 0.999990] [G loss: 1.000024]\n",
      "epoch:31 step:149210[D loss: 1.000133] [G loss: 0.999843]\n",
      "epoch:31 step:149215[D loss: 0.999960] [G loss: 1.000092]\n",
      "epoch:31 step:149220[D loss: 0.999888] [G loss: 1.000223]\n",
      "epoch:31 step:149225[D loss: 0.999932] [G loss: 1.000281]\n",
      "epoch:31 step:149230[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:31 step:149235[D loss: 0.999920] [G loss: 1.000113]\n",
      "epoch:31 step:149240[D loss: 0.999984] [G loss: 1.000042]\n",
      "epoch:31 step:149245[D loss: 0.999977] [G loss: 1.000028]\n",
      "epoch:31 step:149250[D loss: 0.999951] [G loss: 1.000133]\n",
      "epoch:31 step:149255[D loss: 1.000002] [G loss: 1.000072]\n",
      "epoch:31 step:149260[D loss: 1.000106] [G loss: 0.999854]\n",
      "epoch:31 step:149265[D loss: 0.999870] [G loss: 1.000227]\n",
      "epoch:31 step:149270[D loss: 0.999938] [G loss: 1.000132]\n",
      "epoch:31 step:149275[D loss: 1.000115] [G loss: 1.000045]\n",
      "epoch:31 step:149280[D loss: 0.999940] [G loss: 1.000094]\n",
      "epoch:31 step:149285[D loss: 0.999924] [G loss: 1.000103]\n",
      "epoch:31 step:149290[D loss: 0.999979] [G loss: 1.000103]\n",
      "epoch:31 step:149295[D loss: 0.999970] [G loss: 1.000103]\n",
      "epoch:31 step:149300[D loss: 0.999990] [G loss: 0.999998]\n",
      "epoch:31 step:149305[D loss: 0.999947] [G loss: 1.000079]\n",
      "epoch:31 step:149310[D loss: 0.999957] [G loss: 1.000047]\n",
      "epoch:31 step:149315[D loss: 1.000004] [G loss: 0.999999]\n",
      "epoch:31 step:149320[D loss: 0.999973] [G loss: 1.000061]\n",
      "epoch:31 step:149325[D loss: 1.000077] [G loss: 1.000003]\n",
      "epoch:31 step:149330[D loss: 0.999925] [G loss: 1.000119]\n",
      "epoch:31 step:149335[D loss: 0.999964] [G loss: 1.000086]\n",
      "epoch:31 step:149340[D loss: 1.000030] [G loss: 0.999975]\n",
      "epoch:31 step:149345[D loss: 0.999988] [G loss: 1.000070]\n",
      "epoch:31 step:149350[D loss: 1.000005] [G loss: 0.999966]\n",
      "epoch:31 step:149355[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:31 step:149360[D loss: 0.999987] [G loss: 1.000037]\n",
      "epoch:31 step:149365[D loss: 1.000003] [G loss: 0.999998]\n",
      "epoch:31 step:149370[D loss: 1.000009] [G loss: 1.000044]\n",
      "epoch:31 step:149375[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:31 step:149380[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:31 step:149385[D loss: 1.000000] [G loss: 1.000051]\n",
      "epoch:31 step:149390[D loss: 0.999996] [G loss: 1.000044]\n",
      "epoch:31 step:149395[D loss: 1.000003] [G loss: 1.000108]\n",
      "epoch:31 step:149400[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:31 step:149405[D loss: 1.000052] [G loss: 1.000074]\n",
      "epoch:31 step:149410[D loss: 0.999940] [G loss: 1.000121]\n",
      "epoch:31 step:149415[D loss: 0.999979] [G loss: 1.000068]\n",
      "epoch:31 step:149420[D loss: 0.999983] [G loss: 1.000053]\n",
      "epoch:31 step:149425[D loss: 0.999987] [G loss: 1.000072]\n",
      "epoch:31 step:149430[D loss: 1.000015] [G loss: 1.000069]\n",
      "epoch:31 step:149435[D loss: 0.999984] [G loss: 1.000041]\n",
      "epoch:31 step:149440[D loss: 1.000028] [G loss: 0.999972]\n",
      "epoch:31 step:149445[D loss: 0.999963] [G loss: 1.000071]\n",
      "epoch:31 step:149450[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:31 step:149455[D loss: 1.000040] [G loss: 1.000011]\n",
      "epoch:31 step:149460[D loss: 0.999954] [G loss: 1.000069]\n",
      "epoch:31 step:149465[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:31 step:149470[D loss: 0.999964] [G loss: 1.000073]\n",
      "epoch:31 step:149475[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:31 step:149480[D loss: 0.999949] [G loss: 1.000123]\n",
      "epoch:31 step:149485[D loss: 0.999962] [G loss: 1.000084]\n",
      "epoch:31 step:149490[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:31 step:149495[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:31 step:149500[D loss: 0.999972] [G loss: 1.000033]\n",
      "epoch:31 step:149505[D loss: 1.000010] [G loss: 0.999967]\n",
      "epoch:31 step:149510[D loss: 0.999978] [G loss: 1.000031]\n",
      "epoch:31 step:149515[D loss: 1.000180] [G loss: 0.999903]\n",
      "epoch:31 step:149520[D loss: 1.000045] [G loss: 0.999921]\n",
      "epoch:31 step:149525[D loss: 1.000013] [G loss: 1.000013]\n",
      "epoch:31 step:149530[D loss: 1.000017] [G loss: 1.000088]\n",
      "epoch:31 step:149535[D loss: 0.999951] [G loss: 1.000076]\n",
      "epoch:31 step:149540[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:31 step:149545[D loss: 0.999989] [G loss: 1.000022]\n",
      "epoch:31 step:149550[D loss: 0.999995] [G loss: 1.000028]\n",
      "epoch:31 step:149555[D loss: 1.000035] [G loss: 1.000041]\n",
      "epoch:31 step:149560[D loss: 0.999870] [G loss: 1.000193]\n",
      "epoch:31 step:149565[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:31 step:149570[D loss: 1.000113] [G loss: 0.999935]\n",
      "epoch:31 step:149575[D loss: 1.000073] [G loss: 0.999931]\n",
      "epoch:31 step:149580[D loss: 0.999940] [G loss: 1.000197]\n",
      "epoch:31 step:149585[D loss: 0.999959] [G loss: 1.000241]\n",
      "epoch:31 step:149590[D loss: 0.999985] [G loss: 1.000003]\n",
      "epoch:31 step:149595[D loss: 1.000018] [G loss: 0.999963]\n",
      "epoch:31 step:149600[D loss: 1.000045] [G loss: 0.999996]\n",
      "epoch:31 step:149605[D loss: 0.999985] [G loss: 1.000036]\n",
      "epoch:31 step:149610[D loss: 0.999990] [G loss: 0.999947]\n",
      "epoch:31 step:149615[D loss: 1.000024] [G loss: 1.000063]\n",
      "epoch:31 step:149620[D loss: 0.999863] [G loss: 1.000123]\n",
      "epoch:31 step:149625[D loss: 0.999955] [G loss: 1.000072]\n",
      "epoch:31 step:149630[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:31 step:149635[D loss: 0.999937] [G loss: 1.000124]\n",
      "epoch:31 step:149640[D loss: 0.999940] [G loss: 1.000100]\n",
      "epoch:31 step:149645[D loss: 1.000002] [G loss: 1.000062]\n",
      "epoch:31 step:149650[D loss: 0.999990] [G loss: 1.000038]\n",
      "epoch:31 step:149655[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:31 step:149660[D loss: 1.000028] [G loss: 1.000047]\n",
      "epoch:31 step:149665[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:31 step:149670[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:31 step:149675[D loss: 0.999976] [G loss: 1.000075]\n",
      "epoch:31 step:149680[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:31 step:149685[D loss: 0.999980] [G loss: 1.000059]\n",
      "epoch:31 step:149690[D loss: 0.999990] [G loss: 1.000074]\n",
      "epoch:31 step:149695[D loss: 0.999987] [G loss: 1.000007]\n",
      "epoch:31 step:149700[D loss: 0.999961] [G loss: 1.000108]\n",
      "epoch:31 step:149705[D loss: 0.999968] [G loss: 1.000078]\n",
      "epoch:31 step:149710[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:31 step:149715[D loss: 1.000021] [G loss: 1.000082]\n",
      "epoch:31 step:149720[D loss: 1.000019] [G loss: 0.999982]\n",
      "epoch:31 step:149725[D loss: 0.999999] [G loss: 0.999966]\n",
      "epoch:31 step:149730[D loss: 0.999908] [G loss: 1.000085]\n",
      "epoch:31 step:149735[D loss: 0.999937] [G loss: 1.000099]\n",
      "epoch:31 step:149740[D loss: 1.000025] [G loss: 1.000080]\n",
      "epoch:31 step:149745[D loss: 0.999994] [G loss: 1.000044]\n",
      "epoch:31 step:149750[D loss: 0.999998] [G loss: 1.000066]\n",
      "epoch:31 step:149755[D loss: 1.000016] [G loss: 1.000068]\n",
      "epoch:31 step:149760[D loss: 1.000001] [G loss: 1.000027]\n",
      "epoch:31 step:149765[D loss: 1.000008] [G loss: 1.000142]\n",
      "epoch:31 step:149770[D loss: 0.999985] [G loss: 1.000011]\n",
      "epoch:31 step:149775[D loss: 1.000072] [G loss: 0.999945]\n",
      "epoch:31 step:149780[D loss: 1.000040] [G loss: 0.999849]\n",
      "epoch:31 step:149785[D loss: 0.999973] [G loss: 1.000048]\n",
      "epoch:31 step:149790[D loss: 0.999964] [G loss: 1.000046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:149795[D loss: 0.999938] [G loss: 1.000090]\n",
      "epoch:31 step:149800[D loss: 0.999961] [G loss: 1.000050]\n",
      "epoch:31 step:149805[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:31 step:149810[D loss: 0.999969] [G loss: 1.000122]\n",
      "epoch:31 step:149815[D loss: 0.999985] [G loss: 1.000003]\n",
      "epoch:31 step:149820[D loss: 1.000057] [G loss: 1.000003]\n",
      "epoch:31 step:149825[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:31 step:149830[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:31 step:149835[D loss: 0.999991] [G loss: 1.000071]\n",
      "epoch:31 step:149840[D loss: 0.999977] [G loss: 1.000106]\n",
      "epoch:31 step:149845[D loss: 0.999930] [G loss: 1.000164]\n",
      "epoch:31 step:149850[D loss: 0.999934] [G loss: 1.000110]\n",
      "epoch:31 step:149855[D loss: 0.999964] [G loss: 1.000070]\n",
      "epoch:31 step:149860[D loss: 0.999954] [G loss: 1.000074]\n",
      "epoch:31 step:149865[D loss: 0.999941] [G loss: 1.000093]\n",
      "epoch:31 step:149870[D loss: 0.999991] [G loss: 1.000015]\n",
      "epoch:31 step:149875[D loss: 1.000082] [G loss: 0.999925]\n",
      "epoch:31 step:149880[D loss: 0.999920] [G loss: 1.000065]\n",
      "epoch:31 step:149885[D loss: 0.999973] [G loss: 0.999984]\n",
      "epoch:31 step:149890[D loss: 0.999966] [G loss: 1.000086]\n",
      "epoch:31 step:149895[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:31 step:149900[D loss: 0.999944] [G loss: 1.000102]\n",
      "epoch:31 step:149905[D loss: 0.999961] [G loss: 1.000104]\n",
      "epoch:31 step:149910[D loss: 1.000001] [G loss: 1.000003]\n",
      "epoch:31 step:149915[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:31 step:149920[D loss: 1.000042] [G loss: 0.999981]\n",
      "epoch:32 step:149925[D loss: 1.000089] [G loss: 0.999929]\n",
      "epoch:32 step:149930[D loss: 1.000042] [G loss: 0.999980]\n",
      "epoch:32 step:149935[D loss: 0.999910] [G loss: 1.000121]\n",
      "epoch:32 step:149940[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:32 step:149945[D loss: 0.999953] [G loss: 1.000085]\n",
      "epoch:32 step:149950[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:32 step:149955[D loss: 1.000004] [G loss: 1.000027]\n",
      "epoch:32 step:149960[D loss: 1.000006] [G loss: 1.000005]\n",
      "epoch:32 step:149965[D loss: 1.000121] [G loss: 0.999819]\n",
      "epoch:32 step:149970[D loss: 1.000126] [G loss: 0.999864]\n",
      "epoch:32 step:149975[D loss: 0.999956] [G loss: 1.000103]\n",
      "epoch:32 step:149980[D loss: 0.999855] [G loss: 1.000159]\n",
      "epoch:32 step:149985[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:32 step:149990[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:32 step:149995[D loss: 0.999952] [G loss: 1.000113]\n",
      "epoch:32 step:150000[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:32 step:150005[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:32 step:150010[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:32 step:150015[D loss: 0.999982] [G loss: 1.000034]\n",
      "epoch:32 step:150020[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:32 step:150025[D loss: 0.999993] [G loss: 1.000105]\n",
      "epoch:32 step:150030[D loss: 1.000018] [G loss: 1.000037]\n",
      "epoch:32 step:150035[D loss: 0.999949] [G loss: 1.000088]\n",
      "epoch:32 step:150040[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:32 step:150045[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:32 step:150050[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:32 step:150055[D loss: 1.000053] [G loss: 1.000032]\n",
      "epoch:32 step:150060[D loss: 0.999950] [G loss: 1.000080]\n",
      "epoch:32 step:150065[D loss: 0.999932] [G loss: 1.000096]\n",
      "epoch:32 step:150070[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:32 step:150075[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:32 step:150080[D loss: 0.999944] [G loss: 1.000158]\n",
      "epoch:32 step:150085[D loss: 0.999867] [G loss: 1.000205]\n",
      "epoch:32 step:150090[D loss: 1.000012] [G loss: 1.000107]\n",
      "epoch:32 step:150095[D loss: 0.999998] [G loss: 1.000073]\n",
      "epoch:32 step:150100[D loss: 0.999988] [G loss: 1.000115]\n",
      "epoch:32 step:150105[D loss: 0.999912] [G loss: 1.000198]\n",
      "epoch:32 step:150110[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:32 step:150115[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:32 step:150120[D loss: 1.000174] [G loss: 0.999814]\n",
      "epoch:32 step:150125[D loss: 1.000024] [G loss: 0.999902]\n",
      "epoch:32 step:150130[D loss: 0.999960] [G loss: 1.000060]\n",
      "epoch:32 step:150135[D loss: 1.000024] [G loss: 0.999885]\n",
      "epoch:32 step:150140[D loss: 0.999896] [G loss: 1.000147]\n",
      "epoch:32 step:150145[D loss: 0.999921] [G loss: 1.000234]\n",
      "epoch:32 step:150150[D loss: 0.999908] [G loss: 1.000183]\n",
      "epoch:32 step:150155[D loss: 0.999945] [G loss: 1.000102]\n",
      "epoch:32 step:150160[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:32 step:150165[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:32 step:150170[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:32 step:150175[D loss: 0.999974] [G loss: 1.000101]\n",
      "epoch:32 step:150180[D loss: 0.999985] [G loss: 1.000062]\n",
      "epoch:32 step:150185[D loss: 1.000018] [G loss: 1.000147]\n",
      "epoch:32 step:150190[D loss: 1.000011] [G loss: 1.000060]\n",
      "epoch:32 step:150195[D loss: 0.999857] [G loss: 1.000209]\n",
      "epoch:32 step:150200[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:32 step:150205[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:32 step:150210[D loss: 0.999967] [G loss: 1.000094]\n",
      "epoch:32 step:150215[D loss: 0.999966] [G loss: 1.000114]\n",
      "epoch:32 step:150220[D loss: 1.000007] [G loss: 0.999943]\n",
      "epoch:32 step:150225[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:32 step:150230[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:32 step:150235[D loss: 1.000033] [G loss: 1.000040]\n",
      "epoch:32 step:150240[D loss: 0.999992] [G loss: 1.000104]\n",
      "epoch:32 step:150245[D loss: 0.999914] [G loss: 1.000114]\n",
      "epoch:32 step:150250[D loss: 0.999943] [G loss: 1.000055]\n",
      "epoch:32 step:150255[D loss: 0.999989] [G loss: 0.999990]\n",
      "epoch:32 step:150260[D loss: 1.000021] [G loss: 0.999995]\n",
      "epoch:32 step:150265[D loss: 1.000113] [G loss: 1.000102]\n",
      "epoch:32 step:150270[D loss: 0.999828] [G loss: 1.000272]\n",
      "epoch:32 step:150275[D loss: 0.999978] [G loss: 1.000155]\n",
      "epoch:32 step:150280[D loss: 0.999897] [G loss: 1.000285]\n",
      "epoch:32 step:150285[D loss: 0.999875] [G loss: 1.000207]\n",
      "epoch:32 step:150290[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:32 step:150295[D loss: 1.000026] [G loss: 0.999990]\n",
      "epoch:32 step:150300[D loss: 0.999989] [G loss: 1.000000]\n",
      "epoch:32 step:150305[D loss: 1.000005] [G loss: 1.000015]\n",
      "epoch:32 step:150310[D loss: 0.999947] [G loss: 1.000058]\n",
      "epoch:32 step:150315[D loss: 1.000019] [G loss: 0.999953]\n",
      "epoch:32 step:150320[D loss: 0.999993] [G loss: 1.000054]\n",
      "epoch:32 step:150325[D loss: 1.000056] [G loss: 1.000022]\n",
      "epoch:32 step:150330[D loss: 0.999932] [G loss: 1.000070]\n",
      "epoch:32 step:150335[D loss: 0.999975] [G loss: 1.000086]\n",
      "epoch:32 step:150340[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:32 step:150345[D loss: 0.999927] [G loss: 1.000173]\n",
      "epoch:32 step:150350[D loss: 1.000071] [G loss: 0.999936]\n",
      "epoch:32 step:150355[D loss: 1.000023] [G loss: 0.999959]\n",
      "epoch:32 step:150360[D loss: 0.999968] [G loss: 1.000094]\n",
      "epoch:32 step:150365[D loss: 1.000076] [G loss: 1.000113]\n",
      "epoch:32 step:150370[D loss: 0.999997] [G loss: 1.000084]\n",
      "epoch:32 step:150375[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:32 step:150380[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:32 step:150385[D loss: 0.999991] [G loss: 0.999987]\n",
      "epoch:32 step:150390[D loss: 1.000070] [G loss: 0.999901]\n",
      "epoch:32 step:150395[D loss: 1.000036] [G loss: 1.000042]\n",
      "epoch:32 step:150400[D loss: 0.999999] [G loss: 1.000113]\n",
      "epoch:32 step:150405[D loss: 1.000026] [G loss: 1.000051]\n",
      "epoch:32 step:150410[D loss: 0.999933] [G loss: 1.000199]\n",
      "epoch:32 step:150415[D loss: 0.999928] [G loss: 1.000157]\n",
      "epoch:32 step:150420[D loss: 0.999984] [G loss: 1.000108]\n",
      "epoch:32 step:150425[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:32 step:150430[D loss: 0.999943] [G loss: 1.000047]\n",
      "epoch:32 step:150435[D loss: 0.999954] [G loss: 1.000088]\n",
      "epoch:32 step:150440[D loss: 0.999989] [G loss: 1.000033]\n",
      "epoch:32 step:150445[D loss: 1.000062] [G loss: 0.999928]\n",
      "epoch:32 step:150450[D loss: 0.999983] [G loss: 1.000015]\n",
      "epoch:32 step:150455[D loss: 0.999990] [G loss: 1.000091]\n",
      "epoch:32 step:150460[D loss: 1.000039] [G loss: 1.000038]\n",
      "epoch:32 step:150465[D loss: 0.999904] [G loss: 1.000106]\n",
      "epoch:32 step:150470[D loss: 0.999864] [G loss: 1.000270]\n",
      "epoch:32 step:150475[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:32 step:150480[D loss: 0.999995] [G loss: 1.000115]\n",
      "epoch:32 step:150485[D loss: 1.000032] [G loss: 1.000086]\n",
      "epoch:32 step:150490[D loss: 0.999919] [G loss: 1.000129]\n",
      "epoch:32 step:150495[D loss: 0.999954] [G loss: 1.000134]\n",
      "epoch:32 step:150500[D loss: 1.000022] [G loss: 0.999998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:150505[D loss: 1.000092] [G loss: 0.999914]\n",
      "epoch:32 step:150510[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:32 step:150515[D loss: 1.000076] [G loss: 1.000043]\n",
      "epoch:32 step:150520[D loss: 1.000060] [G loss: 0.999964]\n",
      "epoch:32 step:150525[D loss: 0.999890] [G loss: 1.000150]\n",
      "epoch:32 step:150530[D loss: 1.000030] [G loss: 1.000066]\n",
      "epoch:32 step:150535[D loss: 0.999979] [G loss: 1.000121]\n",
      "epoch:32 step:150540[D loss: 0.999989] [G loss: 1.000069]\n",
      "epoch:32 step:150545[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:32 step:150550[D loss: 1.000102] [G loss: 0.999911]\n",
      "epoch:32 step:150555[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:32 step:150560[D loss: 1.000025] [G loss: 0.999956]\n",
      "epoch:32 step:150565[D loss: 1.000018] [G loss: 0.999980]\n",
      "epoch:32 step:150570[D loss: 0.999930] [G loss: 1.000063]\n",
      "epoch:32 step:150575[D loss: 0.999996] [G loss: 1.000005]\n",
      "epoch:32 step:150580[D loss: 1.000027] [G loss: 1.000019]\n",
      "epoch:32 step:150585[D loss: 1.000025] [G loss: 1.000037]\n",
      "epoch:32 step:150590[D loss: 1.000007] [G loss: 1.000054]\n",
      "epoch:32 step:150595[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:32 step:150600[D loss: 0.999949] [G loss: 1.000080]\n",
      "epoch:32 step:150605[D loss: 1.000027] [G loss: 0.999993]\n",
      "epoch:32 step:150610[D loss: 1.000011] [G loss: 1.000043]\n",
      "epoch:32 step:150615[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:32 step:150620[D loss: 0.999936] [G loss: 1.000127]\n",
      "epoch:32 step:150625[D loss: 1.000078] [G loss: 1.000003]\n",
      "epoch:32 step:150630[D loss: 0.999992] [G loss: 1.000082]\n",
      "epoch:32 step:150635[D loss: 0.999922] [G loss: 1.000147]\n",
      "epoch:32 step:150640[D loss: 0.999974] [G loss: 1.000059]\n",
      "epoch:32 step:150645[D loss: 0.999952] [G loss: 1.000122]\n",
      "epoch:32 step:150650[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:32 step:150655[D loss: 0.999981] [G loss: 1.000047]\n",
      "epoch:32 step:150660[D loss: 1.000013] [G loss: 1.000010]\n",
      "epoch:32 step:150665[D loss: 1.000062] [G loss: 0.999915]\n",
      "epoch:32 step:150670[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:32 step:150675[D loss: 0.999955] [G loss: 1.000017]\n",
      "epoch:32 step:150680[D loss: 0.999952] [G loss: 1.000095]\n",
      "epoch:32 step:150685[D loss: 0.999980] [G loss: 1.000076]\n",
      "epoch:32 step:150690[D loss: 1.000089] [G loss: 0.999975]\n",
      "epoch:32 step:150695[D loss: 1.000101] [G loss: 0.999900]\n",
      "epoch:32 step:150700[D loss: 1.000026] [G loss: 1.000073]\n",
      "epoch:32 step:150705[D loss: 0.999957] [G loss: 1.000042]\n",
      "epoch:32 step:150710[D loss: 1.000009] [G loss: 0.999998]\n",
      "epoch:32 step:150715[D loss: 0.999999] [G loss: 1.000060]\n",
      "epoch:32 step:150720[D loss: 1.000065] [G loss: 0.999953]\n",
      "epoch:32 step:150725[D loss: 0.999989] [G loss: 1.000136]\n",
      "epoch:32 step:150730[D loss: 0.999957] [G loss: 1.000206]\n",
      "epoch:32 step:150735[D loss: 0.999830] [G loss: 1.000186]\n",
      "epoch:32 step:150740[D loss: 0.999939] [G loss: 1.000057]\n",
      "epoch:32 step:150745[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:32 step:150750[D loss: 1.000030] [G loss: 1.000017]\n",
      "epoch:32 step:150755[D loss: 0.999962] [G loss: 1.000008]\n",
      "epoch:32 step:150760[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:32 step:150765[D loss: 0.999982] [G loss: 1.000063]\n",
      "epoch:32 step:150770[D loss: 0.999991] [G loss: 1.000062]\n",
      "epoch:32 step:150775[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:32 step:150780[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:32 step:150785[D loss: 0.999958] [G loss: 1.000113]\n",
      "epoch:32 step:150790[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:32 step:150795[D loss: 0.999972] [G loss: 1.000090]\n",
      "epoch:32 step:150800[D loss: 0.999978] [G loss: 1.000112]\n",
      "epoch:32 step:150805[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:32 step:150810[D loss: 1.000026] [G loss: 1.000046]\n",
      "epoch:32 step:150815[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:32 step:150820[D loss: 0.999932] [G loss: 1.000084]\n",
      "epoch:32 step:150825[D loss: 0.999953] [G loss: 1.000103]\n",
      "epoch:32 step:150830[D loss: 0.999962] [G loss: 1.000091]\n",
      "epoch:32 step:150835[D loss: 0.999994] [G loss: 1.000066]\n",
      "epoch:32 step:150840[D loss: 0.999927] [G loss: 1.000106]\n",
      "epoch:32 step:150845[D loss: 1.000024] [G loss: 0.999946]\n",
      "epoch:32 step:150850[D loss: 0.999975] [G loss: 1.000075]\n",
      "epoch:32 step:150855[D loss: 1.000004] [G loss: 1.000000]\n",
      "epoch:32 step:150860[D loss: 0.999950] [G loss: 1.000175]\n",
      "epoch:32 step:150865[D loss: 0.999991] [G loss: 1.000106]\n",
      "epoch:32 step:150870[D loss: 0.999929] [G loss: 1.000126]\n",
      "epoch:32 step:150875[D loss: 1.000013] [G loss: 1.000009]\n",
      "epoch:32 step:150880[D loss: 0.999975] [G loss: 1.000011]\n",
      "epoch:32 step:150885[D loss: 1.000021] [G loss: 1.000041]\n",
      "epoch:32 step:150890[D loss: 1.000026] [G loss: 0.999996]\n",
      "epoch:32 step:150895[D loss: 1.000028] [G loss: 1.000013]\n",
      "epoch:32 step:150900[D loss: 1.000053] [G loss: 0.999880]\n",
      "epoch:32 step:150905[D loss: 1.000069] [G loss: 0.999994]\n",
      "epoch:32 step:150910[D loss: 1.000107] [G loss: 1.000071]\n",
      "epoch:32 step:150915[D loss: 1.000060] [G loss: 0.999963]\n",
      "epoch:32 step:150920[D loss: 1.000161] [G loss: 0.999979]\n",
      "epoch:32 step:150925[D loss: 0.999934] [G loss: 1.000153]\n",
      "epoch:32 step:150930[D loss: 0.999925] [G loss: 1.000186]\n",
      "epoch:32 step:150935[D loss: 0.999960] [G loss: 1.000123]\n",
      "epoch:32 step:150940[D loss: 0.999974] [G loss: 1.000004]\n",
      "epoch:32 step:150945[D loss: 1.000000] [G loss: 1.000005]\n",
      "epoch:32 step:150950[D loss: 1.000030] [G loss: 0.999967]\n",
      "epoch:32 step:150955[D loss: 1.000204] [G loss: 0.999715]\n",
      "epoch:32 step:150960[D loss: 0.999897] [G loss: 0.999884]\n",
      "epoch:32 step:150965[D loss: 1.000001] [G loss: 0.999999]\n",
      "epoch:32 step:150970[D loss: 1.000117] [G loss: 0.999823]\n",
      "epoch:32 step:150975[D loss: 0.999919] [G loss: 1.000044]\n",
      "epoch:32 step:150980[D loss: 1.000012] [G loss: 1.000092]\n",
      "epoch:32 step:150985[D loss: 1.000080] [G loss: 0.999960]\n",
      "epoch:32 step:150990[D loss: 1.000076] [G loss: 0.999976]\n",
      "epoch:32 step:150995[D loss: 0.999983] [G loss: 1.000075]\n",
      "epoch:32 step:151000[D loss: 0.999875] [G loss: 1.000238]\n",
      "epoch:32 step:151005[D loss: 1.000020] [G loss: 1.000424]\n",
      "epoch:32 step:151010[D loss: 0.999898] [G loss: 1.000202]\n",
      "epoch:32 step:151015[D loss: 0.999905] [G loss: 1.000163]\n",
      "epoch:32 step:151020[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:32 step:151025[D loss: 1.000014] [G loss: 0.999978]\n",
      "epoch:32 step:151030[D loss: 1.000051] [G loss: 0.999934]\n",
      "epoch:32 step:151035[D loss: 1.000096] [G loss: 0.999944]\n",
      "epoch:32 step:151040[D loss: 0.999986] [G loss: 1.000002]\n",
      "epoch:32 step:151045[D loss: 1.000098] [G loss: 0.999956]\n",
      "epoch:32 step:151050[D loss: 1.000096] [G loss: 0.999908]\n",
      "epoch:32 step:151055[D loss: 1.000148] [G loss: 0.999925]\n",
      "epoch:32 step:151060[D loss: 0.999929] [G loss: 0.999992]\n",
      "epoch:32 step:151065[D loss: 0.999905] [G loss: 1.000190]\n",
      "epoch:32 step:151070[D loss: 1.000058] [G loss: 1.000116]\n",
      "epoch:32 step:151075[D loss: 1.000079] [G loss: 0.999986]\n",
      "epoch:32 step:151080[D loss: 0.999909] [G loss: 1.000205]\n",
      "epoch:32 step:151085[D loss: 1.000005] [G loss: 1.000068]\n",
      "epoch:32 step:151090[D loss: 1.000001] [G loss: 1.000118]\n",
      "epoch:32 step:151095[D loss: 0.999964] [G loss: 1.000174]\n",
      "epoch:32 step:151100[D loss: 1.000000] [G loss: 0.999960]\n",
      "epoch:32 step:151105[D loss: 0.999997] [G loss: 1.000069]\n",
      "epoch:32 step:151110[D loss: 1.000011] [G loss: 0.999988]\n",
      "epoch:32 step:151115[D loss: 1.000029] [G loss: 0.999991]\n",
      "epoch:32 step:151120[D loss: 1.000056] [G loss: 1.000036]\n",
      "epoch:32 step:151125[D loss: 1.000123] [G loss: 0.999962]\n",
      "epoch:32 step:151130[D loss: 0.999979] [G loss: 1.000142]\n",
      "epoch:32 step:151135[D loss: 0.999734] [G loss: 1.000276]\n",
      "epoch:32 step:151140[D loss: 1.000064] [G loss: 1.000049]\n",
      "epoch:32 step:151145[D loss: 1.000010] [G loss: 0.999996]\n",
      "epoch:32 step:151150[D loss: 0.999926] [G loss: 1.000200]\n",
      "epoch:32 step:151155[D loss: 0.999862] [G loss: 1.000169]\n",
      "epoch:32 step:151160[D loss: 1.000043] [G loss: 1.000010]\n",
      "epoch:32 step:151165[D loss: 0.999915] [G loss: 1.000132]\n",
      "epoch:32 step:151170[D loss: 1.000008] [G loss: 1.000019]\n",
      "epoch:32 step:151175[D loss: 1.000039] [G loss: 0.999964]\n",
      "epoch:32 step:151180[D loss: 0.999942] [G loss: 1.000039]\n",
      "epoch:32 step:151185[D loss: 1.000078] [G loss: 0.999987]\n",
      "epoch:32 step:151190[D loss: 0.999906] [G loss: 1.000101]\n",
      "epoch:32 step:151195[D loss: 0.999973] [G loss: 1.000111]\n",
      "epoch:32 step:151200[D loss: 0.999955] [G loss: 1.000038]\n",
      "epoch:32 step:151205[D loss: 1.000023] [G loss: 1.000037]\n",
      "epoch:32 step:151210[D loss: 1.000053] [G loss: 1.000136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:151215[D loss: 0.999970] [G loss: 1.000006]\n",
      "epoch:32 step:151220[D loss: 0.999961] [G loss: 1.000155]\n",
      "epoch:32 step:151225[D loss: 0.999943] [G loss: 1.000079]\n",
      "epoch:32 step:151230[D loss: 0.999967] [G loss: 1.000072]\n",
      "epoch:32 step:151235[D loss: 1.000068] [G loss: 0.999986]\n",
      "epoch:32 step:151240[D loss: 0.999974] [G loss: 0.999971]\n",
      "epoch:32 step:151245[D loss: 0.999965] [G loss: 1.000001]\n",
      "epoch:32 step:151250[D loss: 1.000011] [G loss: 1.000168]\n",
      "epoch:32 step:151255[D loss: 0.999974] [G loss: 0.999959]\n",
      "epoch:32 step:151260[D loss: 0.999898] [G loss: 1.000079]\n",
      "epoch:32 step:151265[D loss: 1.000007] [G loss: 1.000023]\n",
      "epoch:32 step:151270[D loss: 0.999982] [G loss: 1.000104]\n",
      "epoch:32 step:151275[D loss: 0.999970] [G loss: 1.000047]\n",
      "epoch:32 step:151280[D loss: 1.000023] [G loss: 1.000054]\n",
      "epoch:32 step:151285[D loss: 0.999956] [G loss: 1.000104]\n",
      "epoch:32 step:151290[D loss: 0.999930] [G loss: 1.000111]\n",
      "epoch:32 step:151295[D loss: 0.999979] [G loss: 1.000046]\n",
      "epoch:32 step:151300[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:32 step:151305[D loss: 0.999998] [G loss: 0.999983]\n",
      "epoch:32 step:151310[D loss: 0.999944] [G loss: 1.000210]\n",
      "epoch:32 step:151315[D loss: 1.000059] [G loss: 0.999934]\n",
      "epoch:32 step:151320[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:32 step:151325[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:32 step:151330[D loss: 0.999964] [G loss: 1.000084]\n",
      "epoch:32 step:151335[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:32 step:151340[D loss: 1.000039] [G loss: 0.999933]\n",
      "epoch:32 step:151345[D loss: 1.000006] [G loss: 1.000014]\n",
      "epoch:32 step:151350[D loss: 0.999955] [G loss: 1.000081]\n",
      "epoch:32 step:151355[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:32 step:151360[D loss: 0.999977] [G loss: 1.000013]\n",
      "epoch:32 step:151365[D loss: 0.999981] [G loss: 1.000053]\n",
      "epoch:32 step:151370[D loss: 0.999931] [G loss: 1.000071]\n",
      "epoch:32 step:151375[D loss: 0.999970] [G loss: 1.000088]\n",
      "epoch:32 step:151380[D loss: 0.999943] [G loss: 1.000121]\n",
      "epoch:32 step:151385[D loss: 0.999965] [G loss: 1.000047]\n",
      "epoch:32 step:151390[D loss: 0.999980] [G loss: 1.000074]\n",
      "epoch:32 step:151395[D loss: 0.999969] [G loss: 1.000054]\n",
      "epoch:32 step:151400[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:32 step:151405[D loss: 0.999916] [G loss: 1.000100]\n",
      "epoch:32 step:151410[D loss: 1.000005] [G loss: 1.000016]\n",
      "epoch:32 step:151415[D loss: 0.999981] [G loss: 1.000065]\n",
      "epoch:32 step:151420[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:32 step:151425[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:32 step:151430[D loss: 0.999978] [G loss: 1.000033]\n",
      "epoch:32 step:151435[D loss: 1.000014] [G loss: 1.000027]\n",
      "epoch:32 step:151440[D loss: 0.999968] [G loss: 1.000037]\n",
      "epoch:32 step:151445[D loss: 1.000000] [G loss: 1.000033]\n",
      "epoch:32 step:151450[D loss: 1.000007] [G loss: 1.000020]\n",
      "epoch:32 step:151455[D loss: 0.999942] [G loss: 1.000105]\n",
      "epoch:32 step:151460[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:32 step:151465[D loss: 1.000044] [G loss: 0.999998]\n",
      "epoch:32 step:151470[D loss: 1.000051] [G loss: 0.999995]\n",
      "epoch:32 step:151475[D loss: 0.999899] [G loss: 1.000241]\n",
      "epoch:32 step:151480[D loss: 0.999986] [G loss: 1.000000]\n",
      "epoch:32 step:151485[D loss: 0.999961] [G loss: 1.000033]\n",
      "epoch:32 step:151490[D loss: 0.999983] [G loss: 1.000017]\n",
      "epoch:32 step:151495[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:32 step:151500[D loss: 0.999976] [G loss: 1.000047]\n",
      "epoch:32 step:151505[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:32 step:151510[D loss: 0.999982] [G loss: 0.999971]\n",
      "epoch:32 step:151515[D loss: 0.999967] [G loss: 1.000013]\n",
      "epoch:32 step:151520[D loss: 1.000042] [G loss: 0.999955]\n",
      "epoch:32 step:151525[D loss: 1.000058] [G loss: 1.000080]\n",
      "epoch:32 step:151530[D loss: 1.000061] [G loss: 1.000107]\n",
      "epoch:32 step:151535[D loss: 0.999933] [G loss: 1.000184]\n",
      "epoch:32 step:151540[D loss: 0.999974] [G loss: 1.000016]\n",
      "epoch:32 step:151545[D loss: 0.999948] [G loss: 1.000073]\n",
      "epoch:32 step:151550[D loss: 1.000019] [G loss: 1.000007]\n",
      "epoch:32 step:151555[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:32 step:151560[D loss: 0.999895] [G loss: 1.000112]\n",
      "epoch:32 step:151565[D loss: 0.999980] [G loss: 1.000033]\n",
      "epoch:32 step:151570[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:32 step:151575[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:32 step:151580[D loss: 0.999969] [G loss: 1.000079]\n",
      "epoch:32 step:151585[D loss: 1.000011] [G loss: 1.000039]\n",
      "epoch:32 step:151590[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:32 step:151595[D loss: 0.999968] [G loss: 0.999992]\n",
      "epoch:32 step:151600[D loss: 0.999996] [G loss: 1.000004]\n",
      "epoch:32 step:151605[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:32 step:151610[D loss: 0.999943] [G loss: 0.999992]\n",
      "epoch:32 step:151615[D loss: 1.000020] [G loss: 0.999981]\n",
      "epoch:32 step:151620[D loss: 0.999972] [G loss: 1.000028]\n",
      "epoch:32 step:151625[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:32 step:151630[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:32 step:151635[D loss: 0.999971] [G loss: 1.000053]\n",
      "epoch:32 step:151640[D loss: 0.999985] [G loss: 1.000045]\n",
      "epoch:32 step:151645[D loss: 0.999965] [G loss: 1.000042]\n",
      "epoch:32 step:151650[D loss: 1.000169] [G loss: 0.999957]\n",
      "epoch:32 step:151655[D loss: 0.999915] [G loss: 1.000081]\n",
      "epoch:32 step:151660[D loss: 0.999975] [G loss: 1.000034]\n",
      "epoch:32 step:151665[D loss: 0.999950] [G loss: 1.000179]\n",
      "epoch:32 step:151670[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:32 step:151675[D loss: 0.999974] [G loss: 1.000151]\n",
      "epoch:32 step:151680[D loss: 0.999952] [G loss: 1.000100]\n",
      "epoch:32 step:151685[D loss: 0.999982] [G loss: 1.000074]\n",
      "epoch:32 step:151690[D loss: 0.999997] [G loss: 0.999992]\n",
      "epoch:32 step:151695[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:32 step:151700[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:32 step:151705[D loss: 0.999995] [G loss: 0.999985]\n",
      "epoch:32 step:151710[D loss: 1.000043] [G loss: 1.000061]\n",
      "epoch:32 step:151715[D loss: 0.999962] [G loss: 1.000000]\n",
      "epoch:32 step:151720[D loss: 1.000000] [G loss: 1.000152]\n",
      "epoch:32 step:151725[D loss: 0.999952] [G loss: 1.000118]\n",
      "epoch:32 step:151730[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:32 step:151735[D loss: 0.999979] [G loss: 1.000056]\n",
      "epoch:32 step:151740[D loss: 1.000051] [G loss: 1.000010]\n",
      "epoch:32 step:151745[D loss: 1.000036] [G loss: 0.999908]\n",
      "epoch:32 step:151750[D loss: 1.000042] [G loss: 0.999967]\n",
      "epoch:32 step:151755[D loss: 1.000137] [G loss: 0.999883]\n",
      "epoch:32 step:151760[D loss: 1.000060] [G loss: 0.999993]\n",
      "epoch:32 step:151765[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:32 step:151770[D loss: 0.999944] [G loss: 1.000143]\n",
      "epoch:32 step:151775[D loss: 0.999927] [G loss: 1.000143]\n",
      "epoch:32 step:151780[D loss: 0.999978] [G loss: 1.000093]\n",
      "epoch:32 step:151785[D loss: 0.999963] [G loss: 1.000069]\n",
      "epoch:32 step:151790[D loss: 1.000004] [G loss: 1.000081]\n",
      "epoch:32 step:151795[D loss: 1.000007] [G loss: 0.999996]\n",
      "epoch:32 step:151800[D loss: 1.000079] [G loss: 0.999839]\n",
      "epoch:32 step:151805[D loss: 1.000129] [G loss: 0.999758]\n",
      "epoch:32 step:151810[D loss: 1.000181] [G loss: 0.999916]\n",
      "epoch:32 step:151815[D loss: 0.999957] [G loss: 1.000036]\n",
      "epoch:32 step:151820[D loss: 1.000000] [G loss: 0.999932]\n",
      "epoch:32 step:151825[D loss: 1.000043] [G loss: 0.999874]\n",
      "epoch:32 step:151830[D loss: 0.999848] [G loss: 1.000287]\n",
      "epoch:32 step:151835[D loss: 0.999926] [G loss: 1.000074]\n",
      "epoch:32 step:151840[D loss: 0.999968] [G loss: 1.000084]\n",
      "epoch:32 step:151845[D loss: 1.000095] [G loss: 0.999942]\n",
      "epoch:32 step:151850[D loss: 0.999984] [G loss: 0.999963]\n",
      "epoch:32 step:151855[D loss: 1.000078] [G loss: 1.000000]\n",
      "epoch:32 step:151860[D loss: 0.999887] [G loss: 1.000120]\n",
      "epoch:32 step:151865[D loss: 0.999877] [G loss: 1.000108]\n",
      "epoch:32 step:151870[D loss: 0.999999] [G loss: 1.000100]\n",
      "epoch:32 step:151875[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:32 step:151880[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:32 step:151885[D loss: 0.999976] [G loss: 1.000049]\n",
      "epoch:32 step:151890[D loss: 0.999984] [G loss: 1.000062]\n",
      "epoch:32 step:151895[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:32 step:151900[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:32 step:151905[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:32 step:151910[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:32 step:151915[D loss: 1.000021] [G loss: 0.999989]\n",
      "epoch:32 step:151920[D loss: 0.999984] [G loss: 1.000024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:151925[D loss: 0.999983] [G loss: 1.000103]\n",
      "epoch:32 step:151930[D loss: 0.999918] [G loss: 1.000169]\n",
      "epoch:32 step:151935[D loss: 1.000074] [G loss: 0.999974]\n",
      "epoch:32 step:151940[D loss: 0.999986] [G loss: 1.000073]\n",
      "epoch:32 step:151945[D loss: 1.000017] [G loss: 1.000006]\n",
      "epoch:32 step:151950[D loss: 0.999981] [G loss: 1.000012]\n",
      "epoch:32 step:151955[D loss: 1.000093] [G loss: 0.999970]\n",
      "epoch:32 step:151960[D loss: 0.999930] [G loss: 0.999999]\n",
      "epoch:32 step:151965[D loss: 1.000038] [G loss: 1.000015]\n",
      "epoch:32 step:151970[D loss: 1.000186] [G loss: 0.999950]\n",
      "epoch:32 step:151975[D loss: 0.999908] [G loss: 1.000110]\n",
      "epoch:32 step:151980[D loss: 0.999942] [G loss: 1.000060]\n",
      "epoch:32 step:151985[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:32 step:151990[D loss: 0.999960] [G loss: 1.000036]\n",
      "epoch:32 step:151995[D loss: 0.999928] [G loss: 1.000048]\n",
      "epoch:32 step:152000[D loss: 0.999996] [G loss: 0.999996]\n",
      "epoch:32 step:152005[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:32 step:152010[D loss: 0.999972] [G loss: 1.000053]\n",
      "epoch:32 step:152015[D loss: 0.999927] [G loss: 1.000097]\n",
      "epoch:32 step:152020[D loss: 0.999935] [G loss: 1.000108]\n",
      "epoch:32 step:152025[D loss: 0.999976] [G loss: 1.000086]\n",
      "epoch:32 step:152030[D loss: 1.000003] [G loss: 1.000047]\n",
      "epoch:32 step:152035[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:32 step:152040[D loss: 1.000009] [G loss: 1.000066]\n",
      "epoch:32 step:152045[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:32 step:152050[D loss: 0.999949] [G loss: 1.000084]\n",
      "epoch:32 step:152055[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:32 step:152060[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:32 step:152065[D loss: 0.999935] [G loss: 1.000089]\n",
      "epoch:32 step:152070[D loss: 0.999997] [G loss: 1.000059]\n",
      "epoch:32 step:152075[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:32 step:152080[D loss: 0.999982] [G loss: 1.000058]\n",
      "epoch:32 step:152085[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:32 step:152090[D loss: 1.000002] [G loss: 1.000043]\n",
      "epoch:32 step:152095[D loss: 0.999971] [G loss: 1.000068]\n",
      "epoch:32 step:152100[D loss: 0.999992] [G loss: 1.000056]\n",
      "epoch:32 step:152105[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:32 step:152110[D loss: 0.999993] [G loss: 1.000070]\n",
      "epoch:32 step:152115[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:32 step:152120[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:32 step:152125[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:32 step:152130[D loss: 0.999959] [G loss: 1.000079]\n",
      "epoch:32 step:152135[D loss: 0.999966] [G loss: 1.000066]\n",
      "epoch:32 step:152140[D loss: 0.999984] [G loss: 1.000075]\n",
      "epoch:32 step:152145[D loss: 0.999964] [G loss: 1.000115]\n",
      "epoch:32 step:152150[D loss: 1.000000] [G loss: 1.000073]\n",
      "epoch:32 step:152155[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:32 step:152160[D loss: 0.999874] [G loss: 1.000182]\n",
      "epoch:32 step:152165[D loss: 0.999970] [G loss: 1.000134]\n",
      "epoch:32 step:152170[D loss: 0.999986] [G loss: 1.000122]\n",
      "epoch:32 step:152175[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:32 step:152180[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:32 step:152185[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:32 step:152190[D loss: 1.000181] [G loss: 0.999679]\n",
      "epoch:32 step:152195[D loss: 0.999946] [G loss: 1.000069]\n",
      "epoch:32 step:152200[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:32 step:152205[D loss: 0.999904] [G loss: 1.000175]\n",
      "epoch:32 step:152210[D loss: 1.000035] [G loss: 1.000076]\n",
      "epoch:32 step:152215[D loss: 1.000101] [G loss: 1.000242]\n",
      "epoch:32 step:152220[D loss: 0.999894] [G loss: 1.000109]\n",
      "epoch:32 step:152225[D loss: 0.999944] [G loss: 1.000135]\n",
      "epoch:32 step:152230[D loss: 0.999972] [G loss: 1.000101]\n",
      "epoch:32 step:152235[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:32 step:152240[D loss: 1.000027] [G loss: 0.999956]\n",
      "epoch:32 step:152245[D loss: 1.000086] [G loss: 0.999902]\n",
      "epoch:32 step:152250[D loss: 0.999947] [G loss: 0.999995]\n",
      "epoch:32 step:152255[D loss: 1.000006] [G loss: 1.000049]\n",
      "epoch:32 step:152260[D loss: 1.000119] [G loss: 0.999987]\n",
      "epoch:32 step:152265[D loss: 1.000126] [G loss: 1.000103]\n",
      "epoch:32 step:152270[D loss: 0.999827] [G loss: 1.000078]\n",
      "epoch:32 step:152275[D loss: 1.000033] [G loss: 1.000093]\n",
      "epoch:32 step:152280[D loss: 0.999901] [G loss: 1.000215]\n",
      "epoch:32 step:152285[D loss: 0.999899] [G loss: 1.000170]\n",
      "epoch:32 step:152290[D loss: 0.999990] [G loss: 0.999992]\n",
      "epoch:32 step:152295[D loss: 0.999989] [G loss: 0.999976]\n",
      "epoch:32 step:152300[D loss: 0.999951] [G loss: 1.000043]\n",
      "epoch:32 step:152305[D loss: 0.999963] [G loss: 1.000047]\n",
      "epoch:32 step:152310[D loss: 1.000014] [G loss: 1.000028]\n",
      "epoch:32 step:152315[D loss: 0.999963] [G loss: 0.999986]\n",
      "epoch:32 step:152320[D loss: 0.999925] [G loss: 1.000069]\n",
      "epoch:32 step:152325[D loss: 1.000073] [G loss: 0.999897]\n",
      "epoch:32 step:152330[D loss: 0.999998] [G loss: 0.999994]\n",
      "epoch:32 step:152335[D loss: 1.000064] [G loss: 0.999956]\n",
      "epoch:32 step:152340[D loss: 0.999833] [G loss: 1.000183]\n",
      "epoch:32 step:152345[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:32 step:152350[D loss: 0.999951] [G loss: 1.000107]\n",
      "epoch:32 step:152355[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:32 step:152360[D loss: 1.000039] [G loss: 0.999945]\n",
      "epoch:32 step:152365[D loss: 1.000105] [G loss: 0.999949]\n",
      "epoch:32 step:152370[D loss: 1.000114] [G loss: 0.999898]\n",
      "epoch:32 step:152375[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:32 step:152380[D loss: 1.000089] [G loss: 0.999904]\n",
      "epoch:32 step:152385[D loss: 1.000095] [G loss: 1.000066]\n",
      "epoch:32 step:152390[D loss: 1.000052] [G loss: 1.000137]\n",
      "epoch:32 step:152395[D loss: 0.999805] [G loss: 1.000218]\n",
      "epoch:32 step:152400[D loss: 1.000118] [G loss: 1.000225]\n",
      "epoch:32 step:152405[D loss: 0.999967] [G loss: 1.000216]\n",
      "epoch:32 step:152410[D loss: 0.999953] [G loss: 1.000077]\n",
      "epoch:32 step:152415[D loss: 1.000075] [G loss: 0.999893]\n",
      "epoch:32 step:152420[D loss: 1.000119] [G loss: 0.999824]\n",
      "epoch:32 step:152425[D loss: 0.999916] [G loss: 1.000034]\n",
      "epoch:32 step:152430[D loss: 0.999935] [G loss: 1.000055]\n",
      "epoch:32 step:152435[D loss: 1.000011] [G loss: 0.999937]\n",
      "epoch:32 step:152440[D loss: 0.999942] [G loss: 1.000143]\n",
      "epoch:32 step:152445[D loss: 0.999942] [G loss: 1.000151]\n",
      "epoch:32 step:152450[D loss: 1.000025] [G loss: 0.999994]\n",
      "epoch:32 step:152455[D loss: 1.000066] [G loss: 1.000027]\n",
      "epoch:32 step:152460[D loss: 1.000028] [G loss: 1.000140]\n",
      "epoch:32 step:152465[D loss: 1.000087] [G loss: 1.000017]\n",
      "epoch:32 step:152470[D loss: 1.000070] [G loss: 1.000322]\n",
      "epoch:32 step:152475[D loss: 0.999870] [G loss: 1.000259]\n",
      "epoch:32 step:152480[D loss: 0.999988] [G loss: 1.000052]\n",
      "epoch:32 step:152485[D loss: 1.000040] [G loss: 0.999967]\n",
      "epoch:32 step:152490[D loss: 1.000061] [G loss: 0.999922]\n",
      "epoch:32 step:152495[D loss: 1.000027] [G loss: 0.999917]\n",
      "epoch:32 step:152500[D loss: 1.000016] [G loss: 0.999986]\n",
      "epoch:32 step:152505[D loss: 1.000122] [G loss: 1.000022]\n",
      "epoch:32 step:152510[D loss: 0.999967] [G loss: 1.000084]\n",
      "epoch:32 step:152515[D loss: 1.000030] [G loss: 1.000116]\n",
      "epoch:32 step:152520[D loss: 1.000005] [G loss: 1.000096]\n",
      "epoch:32 step:152525[D loss: 0.999970] [G loss: 1.000096]\n",
      "epoch:32 step:152530[D loss: 0.999930] [G loss: 1.000109]\n",
      "epoch:32 step:152535[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:32 step:152540[D loss: 0.999964] [G loss: 1.000097]\n",
      "epoch:32 step:152545[D loss: 0.999988] [G loss: 1.000056]\n",
      "epoch:32 step:152550[D loss: 1.000017] [G loss: 1.000072]\n",
      "epoch:32 step:152555[D loss: 0.999910] [G loss: 1.000095]\n",
      "epoch:32 step:152560[D loss: 1.000004] [G loss: 1.000011]\n",
      "epoch:32 step:152565[D loss: 0.999937] [G loss: 1.000163]\n",
      "epoch:32 step:152570[D loss: 0.999900] [G loss: 1.000070]\n",
      "epoch:32 step:152575[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:32 step:152580[D loss: 1.000014] [G loss: 1.000039]\n",
      "epoch:32 step:152585[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:32 step:152590[D loss: 0.999950] [G loss: 1.000116]\n",
      "epoch:32 step:152595[D loss: 0.999950] [G loss: 1.000046]\n",
      "epoch:32 step:152600[D loss: 1.000103] [G loss: 1.000046]\n",
      "epoch:32 step:152605[D loss: 1.000073] [G loss: 1.000020]\n",
      "epoch:32 step:152610[D loss: 0.999918] [G loss: 1.000163]\n",
      "epoch:32 step:152615[D loss: 1.000040] [G loss: 1.000067]\n",
      "epoch:32 step:152620[D loss: 1.000019] [G loss: 1.000014]\n",
      "epoch:32 step:152625[D loss: 0.999943] [G loss: 1.000143]\n",
      "epoch:32 step:152630[D loss: 0.999936] [G loss: 1.000115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:152635[D loss: 1.000119] [G loss: 0.999912]\n",
      "epoch:32 step:152640[D loss: 1.000025] [G loss: 0.999958]\n",
      "epoch:32 step:152645[D loss: 1.000019] [G loss: 0.999954]\n",
      "epoch:32 step:152650[D loss: 0.999970] [G loss: 1.000032]\n",
      "epoch:32 step:152655[D loss: 0.999896] [G loss: 1.000106]\n",
      "epoch:32 step:152660[D loss: 1.000045] [G loss: 0.999877]\n",
      "epoch:32 step:152665[D loss: 0.999934] [G loss: 1.000121]\n",
      "epoch:32 step:152670[D loss: 1.000006] [G loss: 1.000113]\n",
      "epoch:32 step:152675[D loss: 0.999932] [G loss: 1.000088]\n",
      "epoch:32 step:152680[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:32 step:152685[D loss: 1.000021] [G loss: 1.000028]\n",
      "epoch:32 step:152690[D loss: 0.999952] [G loss: 1.000030]\n",
      "epoch:32 step:152695[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:32 step:152700[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:32 step:152705[D loss: 0.999993] [G loss: 1.000032]\n",
      "epoch:32 step:152710[D loss: 0.999945] [G loss: 1.000139]\n",
      "epoch:32 step:152715[D loss: 0.999935] [G loss: 1.000106]\n",
      "epoch:32 step:152720[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:32 step:152725[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:32 step:152730[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:32 step:152735[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:32 step:152740[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:32 step:152745[D loss: 0.999990] [G loss: 1.000085]\n",
      "epoch:32 step:152750[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:32 step:152755[D loss: 0.999957] [G loss: 1.000075]\n",
      "epoch:32 step:152760[D loss: 0.999977] [G loss: 1.000076]\n",
      "epoch:32 step:152765[D loss: 0.999985] [G loss: 1.000049]\n",
      "epoch:32 step:152770[D loss: 0.999985] [G loss: 1.000031]\n",
      "epoch:32 step:152775[D loss: 0.999984] [G loss: 1.000064]\n",
      "epoch:32 step:152780[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:32 step:152785[D loss: 0.999980] [G loss: 1.000117]\n",
      "epoch:32 step:152790[D loss: 0.999963] [G loss: 1.000062]\n",
      "epoch:32 step:152795[D loss: 1.000044] [G loss: 1.000092]\n",
      "epoch:32 step:152800[D loss: 0.999981] [G loss: 1.000098]\n",
      "epoch:32 step:152805[D loss: 0.999975] [G loss: 1.000050]\n",
      "epoch:32 step:152810[D loss: 0.999994] [G loss: 1.000077]\n",
      "epoch:32 step:152815[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:32 step:152820[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:32 step:152825[D loss: 0.999980] [G loss: 1.000050]\n",
      "epoch:32 step:152830[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:32 step:152835[D loss: 1.000009] [G loss: 0.999990]\n",
      "epoch:32 step:152840[D loss: 0.999965] [G loss: 1.000054]\n",
      "epoch:32 step:152845[D loss: 1.000007] [G loss: 1.000010]\n",
      "epoch:32 step:152850[D loss: 0.999899] [G loss: 1.000105]\n",
      "epoch:32 step:152855[D loss: 0.999977] [G loss: 1.000058]\n",
      "epoch:32 step:152860[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:32 step:152865[D loss: 1.000065] [G loss: 1.000077]\n",
      "epoch:32 step:152870[D loss: 0.999931] [G loss: 1.000129]\n",
      "epoch:32 step:152875[D loss: 0.999973] [G loss: 1.000075]\n",
      "epoch:32 step:152880[D loss: 1.000020] [G loss: 1.000086]\n",
      "epoch:32 step:152885[D loss: 1.000086] [G loss: 1.000020]\n",
      "epoch:32 step:152890[D loss: 0.999955] [G loss: 1.000109]\n",
      "epoch:32 step:152895[D loss: 1.000088] [G loss: 1.000057]\n",
      "epoch:32 step:152900[D loss: 0.999921] [G loss: 1.000177]\n",
      "epoch:32 step:152905[D loss: 0.999906] [G loss: 1.000149]\n",
      "epoch:32 step:152910[D loss: 0.999936] [G loss: 1.000141]\n",
      "epoch:32 step:152915[D loss: 0.999979] [G loss: 1.000045]\n",
      "epoch:32 step:152920[D loss: 0.999950] [G loss: 1.000069]\n",
      "epoch:32 step:152925[D loss: 1.000007] [G loss: 1.000020]\n",
      "epoch:32 step:152930[D loss: 1.000064] [G loss: 0.999941]\n",
      "epoch:32 step:152935[D loss: 0.999944] [G loss: 1.000000]\n",
      "epoch:32 step:152940[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:32 step:152945[D loss: 0.999936] [G loss: 1.000095]\n",
      "epoch:32 step:152950[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:32 step:152955[D loss: 1.000080] [G loss: 0.999947]\n",
      "epoch:32 step:152960[D loss: 1.000056] [G loss: 0.999968]\n",
      "epoch:32 step:152965[D loss: 1.000211] [G loss: 0.999861]\n",
      "epoch:32 step:152970[D loss: 0.999936] [G loss: 1.000068]\n",
      "epoch:32 step:152975[D loss: 0.999951] [G loss: 1.000053]\n",
      "epoch:32 step:152980[D loss: 1.000011] [G loss: 1.000072]\n",
      "epoch:32 step:152985[D loss: 0.999980] [G loss: 0.999988]\n",
      "epoch:32 step:152990[D loss: 1.000012] [G loss: 1.000011]\n",
      "epoch:32 step:152995[D loss: 0.999957] [G loss: 1.000004]\n",
      "epoch:32 step:153000[D loss: 0.999944] [G loss: 1.000075]\n",
      "epoch:32 step:153005[D loss: 1.000114] [G loss: 0.999913]\n",
      "epoch:32 step:153010[D loss: 1.000064] [G loss: 0.999903]\n",
      "epoch:32 step:153015[D loss: 0.999935] [G loss: 1.000085]\n",
      "epoch:32 step:153020[D loss: 1.000025] [G loss: 1.000061]\n",
      "epoch:32 step:153025[D loss: 0.999992] [G loss: 1.000037]\n",
      "epoch:32 step:153030[D loss: 0.999958] [G loss: 1.000122]\n",
      "epoch:32 step:153035[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:32 step:153040[D loss: 0.999953] [G loss: 1.000144]\n",
      "epoch:32 step:153045[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:32 step:153050[D loss: 0.999987] [G loss: 1.000004]\n",
      "epoch:32 step:153055[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:32 step:153060[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:32 step:153065[D loss: 0.999955] [G loss: 1.000085]\n",
      "epoch:32 step:153070[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:32 step:153075[D loss: 0.999969] [G loss: 1.000087]\n",
      "epoch:32 step:153080[D loss: 1.000012] [G loss: 1.000042]\n",
      "epoch:32 step:153085[D loss: 0.999966] [G loss: 1.000061]\n",
      "epoch:32 step:153090[D loss: 0.999987] [G loss: 1.000063]\n",
      "epoch:32 step:153095[D loss: 0.999998] [G loss: 1.000040]\n",
      "epoch:32 step:153100[D loss: 0.999996] [G loss: 0.999984]\n",
      "epoch:32 step:153105[D loss: 1.000005] [G loss: 1.000023]\n",
      "epoch:32 step:153110[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:32 step:153115[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:32 step:153120[D loss: 1.000021] [G loss: 1.000001]\n",
      "epoch:32 step:153125[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:32 step:153130[D loss: 0.999993] [G loss: 1.000023]\n",
      "epoch:32 step:153135[D loss: 1.000006] [G loss: 0.999990]\n",
      "epoch:32 step:153140[D loss: 1.000007] [G loss: 1.000018]\n",
      "epoch:32 step:153145[D loss: 0.999970] [G loss: 1.000034]\n",
      "epoch:32 step:153150[D loss: 1.000090] [G loss: 0.999944]\n",
      "epoch:32 step:153155[D loss: 0.999905] [G loss: 1.000098]\n",
      "epoch:32 step:153160[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:32 step:153165[D loss: 1.000050] [G loss: 1.000021]\n",
      "epoch:32 step:153170[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:32 step:153175[D loss: 0.999986] [G loss: 1.000219]\n",
      "epoch:32 step:153180[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:32 step:153185[D loss: 0.999973] [G loss: 1.000032]\n",
      "epoch:32 step:153190[D loss: 0.999997] [G loss: 0.999957]\n",
      "epoch:32 step:153195[D loss: 0.999940] [G loss: 1.000108]\n",
      "epoch:32 step:153200[D loss: 1.000064] [G loss: 0.999976]\n",
      "epoch:32 step:153205[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:32 step:153210[D loss: 0.999917] [G loss: 1.000072]\n",
      "epoch:32 step:153215[D loss: 1.000002] [G loss: 1.000069]\n",
      "epoch:32 step:153220[D loss: 0.999965] [G loss: 1.000058]\n",
      "epoch:32 step:153225[D loss: 1.000039] [G loss: 1.000026]\n",
      "epoch:32 step:153230[D loss: 1.000156] [G loss: 0.999923]\n",
      "epoch:32 step:153235[D loss: 0.999882] [G loss: 1.000236]\n",
      "epoch:32 step:153240[D loss: 0.999980] [G loss: 1.000004]\n",
      "epoch:32 step:153245[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:32 step:153250[D loss: 1.000016] [G loss: 0.999922]\n",
      "epoch:32 step:153255[D loss: 0.999921] [G loss: 1.000026]\n",
      "epoch:32 step:153260[D loss: 0.999986] [G loss: 1.000011]\n",
      "epoch:32 step:153265[D loss: 0.999872] [G loss: 1.000131]\n",
      "epoch:32 step:153270[D loss: 0.999939] [G loss: 1.000073]\n",
      "epoch:32 step:153275[D loss: 0.999958] [G loss: 1.000061]\n",
      "epoch:32 step:153280[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:32 step:153285[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:32 step:153290[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:32 step:153295[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:32 step:153300[D loss: 0.999979] [G loss: 1.000099]\n",
      "epoch:32 step:153305[D loss: 0.999993] [G loss: 1.000041]\n",
      "epoch:32 step:153310[D loss: 0.999931] [G loss: 1.000161]\n",
      "epoch:32 step:153315[D loss: 1.000018] [G loss: 1.000030]\n",
      "epoch:32 step:153320[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:32 step:153325[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:32 step:153330[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:32 step:153335[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:32 step:153340[D loss: 1.000023] [G loss: 0.999966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:153345[D loss: 1.000035] [G loss: 1.000013]\n",
      "epoch:32 step:153350[D loss: 1.000021] [G loss: 0.999917]\n",
      "epoch:32 step:153355[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:32 step:153360[D loss: 0.999944] [G loss: 1.000066]\n",
      "epoch:32 step:153365[D loss: 1.000072] [G loss: 0.999894]\n",
      "epoch:32 step:153370[D loss: 0.999898] [G loss: 1.000140]\n",
      "epoch:32 step:153375[D loss: 1.000020] [G loss: 1.000062]\n",
      "epoch:32 step:153380[D loss: 0.999994] [G loss: 1.000107]\n",
      "epoch:32 step:153385[D loss: 0.999990] [G loss: 1.000109]\n",
      "epoch:32 step:153390[D loss: 0.999920] [G loss: 1.000213]\n",
      "epoch:32 step:153395[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:32 step:153400[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:32 step:153405[D loss: 0.999992] [G loss: 1.000034]\n",
      "epoch:32 step:153410[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:32 step:153415[D loss: 1.000062] [G loss: 0.999919]\n",
      "epoch:32 step:153420[D loss: 0.999990] [G loss: 1.000010]\n",
      "epoch:32 step:153425[D loss: 1.000033] [G loss: 0.999990]\n",
      "epoch:32 step:153430[D loss: 1.000024] [G loss: 0.999968]\n",
      "epoch:32 step:153435[D loss: 0.999959] [G loss: 1.000058]\n",
      "epoch:32 step:153440[D loss: 0.999981] [G loss: 1.000071]\n",
      "epoch:32 step:153445[D loss: 1.000012] [G loss: 1.000007]\n",
      "epoch:32 step:153450[D loss: 1.000031] [G loss: 1.000024]\n",
      "epoch:32 step:153455[D loss: 0.999914] [G loss: 1.000123]\n",
      "epoch:32 step:153460[D loss: 0.999911] [G loss: 1.000110]\n",
      "epoch:32 step:153465[D loss: 1.000097] [G loss: 0.999994]\n",
      "epoch:32 step:153470[D loss: 1.000188] [G loss: 0.999923]\n",
      "epoch:32 step:153475[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:32 step:153480[D loss: 0.999949] [G loss: 1.000042]\n",
      "epoch:32 step:153485[D loss: 0.999906] [G loss: 1.000149]\n",
      "epoch:32 step:153490[D loss: 1.000036] [G loss: 1.000193]\n",
      "epoch:32 step:153495[D loss: 0.999921] [G loss: 1.000143]\n",
      "epoch:32 step:153500[D loss: 0.999964] [G loss: 1.000028]\n",
      "epoch:32 step:153505[D loss: 1.000077] [G loss: 0.999896]\n",
      "epoch:32 step:153510[D loss: 0.999946] [G loss: 0.999960]\n",
      "epoch:32 step:153515[D loss: 1.000120] [G loss: 0.999888]\n",
      "epoch:32 step:153520[D loss: 0.999926] [G loss: 1.000081]\n",
      "epoch:32 step:153525[D loss: 0.999967] [G loss: 1.000071]\n",
      "epoch:32 step:153530[D loss: 1.000005] [G loss: 1.000087]\n",
      "epoch:32 step:153535[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:32 step:153540[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:32 step:153545[D loss: 0.999975] [G loss: 1.000091]\n",
      "epoch:32 step:153550[D loss: 0.999999] [G loss: 1.000004]\n",
      "epoch:32 step:153555[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:32 step:153560[D loss: 1.000099] [G loss: 0.999981]\n",
      "epoch:32 step:153565[D loss: 0.999885] [G loss: 1.000152]\n",
      "epoch:32 step:153570[D loss: 0.999935] [G loss: 1.000049]\n",
      "epoch:32 step:153575[D loss: 0.999991] [G loss: 1.000080]\n",
      "epoch:32 step:153580[D loss: 0.999970] [G loss: 1.000013]\n",
      "epoch:32 step:153585[D loss: 0.999997] [G loss: 1.000082]\n",
      "epoch:32 step:153590[D loss: 0.999923] [G loss: 1.000065]\n",
      "epoch:32 step:153595[D loss: 0.999975] [G loss: 1.000058]\n",
      "epoch:32 step:153600[D loss: 0.999997] [G loss: 1.000063]\n",
      "epoch:32 step:153605[D loss: 1.000084] [G loss: 1.000011]\n",
      "epoch:32 step:153610[D loss: 0.999999] [G loss: 1.000031]\n",
      "epoch:32 step:153615[D loss: 1.000081] [G loss: 1.000072]\n",
      "epoch:32 step:153620[D loss: 1.000085] [G loss: 1.000001]\n",
      "epoch:32 step:153625[D loss: 0.999911] [G loss: 1.000110]\n",
      "epoch:32 step:153630[D loss: 0.999969] [G loss: 1.000063]\n",
      "epoch:32 step:153635[D loss: 0.999942] [G loss: 1.000134]\n",
      "epoch:32 step:153640[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:32 step:153645[D loss: 0.999963] [G loss: 1.000049]\n",
      "epoch:32 step:153650[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:32 step:153655[D loss: 0.999972] [G loss: 1.000083]\n",
      "epoch:32 step:153660[D loss: 0.999959] [G loss: 1.000112]\n",
      "epoch:32 step:153665[D loss: 0.999952] [G loss: 1.000039]\n",
      "epoch:32 step:153670[D loss: 1.000053] [G loss: 0.999993]\n",
      "epoch:32 step:153675[D loss: 1.000036] [G loss: 0.999932]\n",
      "epoch:32 step:153680[D loss: 0.999952] [G loss: 1.000103]\n",
      "epoch:32 step:153685[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:32 step:153690[D loss: 1.000072] [G loss: 1.000085]\n",
      "epoch:32 step:153695[D loss: 0.999987] [G loss: 1.000097]\n",
      "epoch:32 step:153700[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:32 step:153705[D loss: 0.999975] [G loss: 1.000062]\n",
      "epoch:32 step:153710[D loss: 1.000059] [G loss: 1.000007]\n",
      "epoch:32 step:153715[D loss: 0.999987] [G loss: 1.000032]\n",
      "epoch:32 step:153720[D loss: 1.000028] [G loss: 1.000071]\n",
      "epoch:32 step:153725[D loss: 0.999970] [G loss: 1.000126]\n",
      "epoch:32 step:153730[D loss: 1.000115] [G loss: 1.000141]\n",
      "epoch:32 step:153735[D loss: 0.999933] [G loss: 1.000139]\n",
      "epoch:32 step:153740[D loss: 0.999982] [G loss: 1.000079]\n",
      "epoch:32 step:153745[D loss: 0.999957] [G loss: 1.000092]\n",
      "epoch:32 step:153750[D loss: 0.999963] [G loss: 1.000068]\n",
      "epoch:32 step:153755[D loss: 0.999992] [G loss: 1.000017]\n",
      "epoch:32 step:153760[D loss: 0.999991] [G loss: 0.999997]\n",
      "epoch:32 step:153765[D loss: 1.000018] [G loss: 0.999986]\n",
      "epoch:32 step:153770[D loss: 0.999993] [G loss: 1.000011]\n",
      "epoch:32 step:153775[D loss: 0.999962] [G loss: 1.000106]\n",
      "epoch:32 step:153780[D loss: 0.999961] [G loss: 1.000120]\n",
      "epoch:32 step:153785[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:32 step:153790[D loss: 0.999966] [G loss: 1.000182]\n",
      "epoch:32 step:153795[D loss: 0.999948] [G loss: 1.000037]\n",
      "epoch:32 step:153800[D loss: 0.999974] [G loss: 1.000102]\n",
      "epoch:32 step:153805[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:32 step:153810[D loss: 1.000029] [G loss: 1.000035]\n",
      "epoch:32 step:153815[D loss: 1.000066] [G loss: 1.000069]\n",
      "epoch:32 step:153820[D loss: 0.999994] [G loss: 1.000118]\n",
      "epoch:32 step:153825[D loss: 0.999944] [G loss: 1.000046]\n",
      "epoch:32 step:153830[D loss: 0.999972] [G loss: 1.000022]\n",
      "epoch:32 step:153835[D loss: 0.999949] [G loss: 1.000127]\n",
      "epoch:32 step:153840[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:32 step:153845[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:32 step:153850[D loss: 1.000019] [G loss: 1.000001]\n",
      "epoch:32 step:153855[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:32 step:153860[D loss: 0.999943] [G loss: 1.000146]\n",
      "epoch:32 step:153865[D loss: 1.000029] [G loss: 1.000114]\n",
      "epoch:32 step:153870[D loss: 0.999986] [G loss: 1.000075]\n",
      "epoch:32 step:153875[D loss: 1.000085] [G loss: 0.999873]\n",
      "epoch:32 step:153880[D loss: 0.999926] [G loss: 1.000069]\n",
      "epoch:32 step:153885[D loss: 0.999981] [G loss: 1.000026]\n",
      "epoch:32 step:153890[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:32 step:153895[D loss: 1.000045] [G loss: 0.999944]\n",
      "epoch:32 step:153900[D loss: 0.999950] [G loss: 1.000144]\n",
      "epoch:32 step:153905[D loss: 0.999874] [G loss: 1.000235]\n",
      "epoch:32 step:153910[D loss: 0.999971] [G loss: 1.000212]\n",
      "epoch:32 step:153915[D loss: 0.999922] [G loss: 1.000166]\n",
      "epoch:32 step:153920[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:32 step:153925[D loss: 1.000003] [G loss: 0.999996]\n",
      "epoch:32 step:153930[D loss: 0.999931] [G loss: 1.000090]\n",
      "epoch:32 step:153935[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:32 step:153940[D loss: 0.999991] [G loss: 1.000042]\n",
      "epoch:32 step:153945[D loss: 1.000094] [G loss: 0.999988]\n",
      "epoch:32 step:153950[D loss: 0.999952] [G loss: 1.000059]\n",
      "epoch:32 step:153955[D loss: 1.000121] [G loss: 0.999963]\n",
      "epoch:32 step:153960[D loss: 0.999935] [G loss: 1.000363]\n",
      "epoch:32 step:153965[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:32 step:153970[D loss: 0.999915] [G loss: 1.000118]\n",
      "epoch:32 step:153975[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:32 step:153980[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:32 step:153985[D loss: 0.999981] [G loss: 1.000080]\n",
      "epoch:32 step:153990[D loss: 1.000020] [G loss: 0.999999]\n",
      "epoch:32 step:153995[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:32 step:154000[D loss: 0.999962] [G loss: 1.000064]\n",
      "epoch:32 step:154005[D loss: 0.999981] [G loss: 0.999993]\n",
      "epoch:32 step:154010[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:32 step:154015[D loss: 0.999987] [G loss: 1.000066]\n",
      "epoch:32 step:154020[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:32 step:154025[D loss: 1.000020] [G loss: 1.000053]\n",
      "epoch:32 step:154030[D loss: 0.999949] [G loss: 1.000124]\n",
      "epoch:32 step:154035[D loss: 0.999964] [G loss: 1.000067]\n",
      "epoch:32 step:154040[D loss: 1.000041] [G loss: 1.000026]\n",
      "epoch:32 step:154045[D loss: 1.000006] [G loss: 1.000040]\n",
      "epoch:32 step:154050[D loss: 1.000023] [G loss: 1.000042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:154055[D loss: 0.999940] [G loss: 1.000111]\n",
      "epoch:32 step:154060[D loss: 0.999979] [G loss: 1.000114]\n",
      "epoch:32 step:154065[D loss: 0.999984] [G loss: 1.000189]\n",
      "epoch:32 step:154070[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:32 step:154075[D loss: 1.000034] [G loss: 0.999985]\n",
      "epoch:32 step:154080[D loss: 1.000202] [G loss: 0.999948]\n",
      "epoch:32 step:154085[D loss: 0.999935] [G loss: 0.999952]\n",
      "epoch:32 step:154090[D loss: 0.999920] [G loss: 1.000307]\n",
      "epoch:32 step:154095[D loss: 0.999929] [G loss: 1.000128]\n",
      "epoch:32 step:154100[D loss: 0.999847] [G loss: 1.000199]\n",
      "epoch:32 step:154105[D loss: 0.999947] [G loss: 1.000100]\n",
      "epoch:32 step:154110[D loss: 0.999951] [G loss: 1.000152]\n",
      "epoch:32 step:154115[D loss: 0.999930] [G loss: 1.000227]\n",
      "epoch:32 step:154120[D loss: 0.999964] [G loss: 1.000093]\n",
      "epoch:32 step:154125[D loss: 1.000073] [G loss: 0.999937]\n",
      "epoch:32 step:154130[D loss: 1.000141] [G loss: 0.999761]\n",
      "epoch:32 step:154135[D loss: 1.000015] [G loss: 0.999974]\n",
      "epoch:32 step:154140[D loss: 1.000015] [G loss: 1.000178]\n",
      "epoch:32 step:154145[D loss: 0.999932] [G loss: 1.000066]\n",
      "epoch:32 step:154150[D loss: 0.999956] [G loss: 1.000140]\n",
      "epoch:32 step:154155[D loss: 1.000003] [G loss: 1.000193]\n",
      "epoch:32 step:154160[D loss: 0.999956] [G loss: 1.000238]\n",
      "epoch:32 step:154165[D loss: 1.000037] [G loss: 1.000232]\n",
      "epoch:32 step:154170[D loss: 0.999834] [G loss: 1.000305]\n",
      "epoch:32 step:154175[D loss: 0.999949] [G loss: 1.000150]\n",
      "epoch:32 step:154180[D loss: 0.999939] [G loss: 1.000074]\n",
      "epoch:32 step:154185[D loss: 1.000073] [G loss: 0.999823]\n",
      "epoch:32 step:154190[D loss: 1.000022] [G loss: 0.999936]\n",
      "epoch:32 step:154195[D loss: 0.999933] [G loss: 1.000069]\n",
      "epoch:32 step:154200[D loss: 0.999969] [G loss: 1.000018]\n",
      "epoch:32 step:154205[D loss: 0.999987] [G loss: 1.000011]\n",
      "epoch:32 step:154210[D loss: 0.999997] [G loss: 1.000080]\n",
      "epoch:32 step:154215[D loss: 1.000173] [G loss: 0.999806]\n",
      "epoch:32 step:154220[D loss: 0.999982] [G loss: 0.999976]\n",
      "epoch:32 step:154225[D loss: 0.999917] [G loss: 1.000167]\n",
      "epoch:32 step:154230[D loss: 0.999953] [G loss: 1.000100]\n",
      "epoch:32 step:154235[D loss: 0.999962] [G loss: 1.000147]\n",
      "epoch:32 step:154240[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:32 step:154245[D loss: 0.999947] [G loss: 1.000123]\n",
      "epoch:32 step:154250[D loss: 0.999980] [G loss: 1.000086]\n",
      "epoch:32 step:154255[D loss: 1.000025] [G loss: 0.999955]\n",
      "epoch:32 step:154260[D loss: 0.999922] [G loss: 1.000135]\n",
      "epoch:32 step:154265[D loss: 0.999967] [G loss: 1.000116]\n",
      "epoch:32 step:154270[D loss: 1.000075] [G loss: 1.000075]\n",
      "epoch:32 step:154275[D loss: 0.999901] [G loss: 1.000091]\n",
      "epoch:32 step:154280[D loss: 0.999971] [G loss: 1.000001]\n",
      "epoch:32 step:154285[D loss: 1.000008] [G loss: 1.000073]\n",
      "epoch:32 step:154290[D loss: 0.999980] [G loss: 1.000052]\n",
      "epoch:32 step:154295[D loss: 0.999994] [G loss: 1.000024]\n",
      "epoch:32 step:154300[D loss: 1.000044] [G loss: 0.999876]\n",
      "epoch:32 step:154305[D loss: 0.999951] [G loss: 1.000073]\n",
      "epoch:32 step:154310[D loss: 0.999981] [G loss: 1.000036]\n",
      "epoch:32 step:154315[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:32 step:154320[D loss: 1.000034] [G loss: 0.999984]\n",
      "epoch:32 step:154325[D loss: 0.999958] [G loss: 1.000078]\n",
      "epoch:32 step:154330[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:32 step:154335[D loss: 1.000002] [G loss: 1.000057]\n",
      "epoch:32 step:154340[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:32 step:154345[D loss: 0.999987] [G loss: 1.000100]\n",
      "epoch:32 step:154350[D loss: 0.999941] [G loss: 1.000141]\n",
      "epoch:32 step:154355[D loss: 0.999970] [G loss: 1.000119]\n",
      "epoch:32 step:154360[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:32 step:154365[D loss: 0.999973] [G loss: 1.000108]\n",
      "epoch:32 step:154370[D loss: 0.999945] [G loss: 1.000059]\n",
      "epoch:32 step:154375[D loss: 1.000009] [G loss: 1.000028]\n",
      "epoch:32 step:154380[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:32 step:154385[D loss: 0.999948] [G loss: 1.000134]\n",
      "epoch:32 step:154390[D loss: 1.000011] [G loss: 1.000076]\n",
      "epoch:32 step:154395[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:32 step:154400[D loss: 1.000108] [G loss: 0.999986]\n",
      "epoch:32 step:154405[D loss: 1.000073] [G loss: 0.999884]\n",
      "epoch:32 step:154410[D loss: 0.999919] [G loss: 1.000045]\n",
      "epoch:32 step:154415[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:32 step:154420[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:32 step:154425[D loss: 1.000078] [G loss: 1.000011]\n",
      "epoch:32 step:154430[D loss: 0.999962] [G loss: 1.000078]\n",
      "epoch:32 step:154435[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:32 step:154440[D loss: 1.000012] [G loss: 1.000046]\n",
      "epoch:32 step:154445[D loss: 1.000052] [G loss: 0.999852]\n",
      "epoch:32 step:154450[D loss: 1.000072] [G loss: 0.999942]\n",
      "epoch:32 step:154455[D loss: 0.999926] [G loss: 1.000073]\n",
      "epoch:32 step:154460[D loss: 1.000014] [G loss: 1.000009]\n",
      "epoch:32 step:154465[D loss: 0.999934] [G loss: 1.000074]\n",
      "epoch:32 step:154470[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:32 step:154475[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:32 step:154480[D loss: 0.999942] [G loss: 1.000096]\n",
      "epoch:32 step:154485[D loss: 0.999990] [G loss: 1.000045]\n",
      "epoch:32 step:154490[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:32 step:154495[D loss: 0.999993] [G loss: 1.000048]\n",
      "epoch:32 step:154500[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:32 step:154505[D loss: 1.000053] [G loss: 0.999944]\n",
      "epoch:32 step:154510[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:32 step:154515[D loss: 1.000033] [G loss: 0.999985]\n",
      "epoch:32 step:154520[D loss: 0.999948] [G loss: 1.000077]\n",
      "epoch:32 step:154525[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:32 step:154530[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:32 step:154535[D loss: 1.000015] [G loss: 1.000016]\n",
      "epoch:32 step:154540[D loss: 1.000148] [G loss: 0.999746]\n",
      "epoch:32 step:154545[D loss: 0.999939] [G loss: 1.000042]\n",
      "epoch:32 step:154550[D loss: 0.999941] [G loss: 1.000080]\n",
      "epoch:32 step:154555[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:32 step:154560[D loss: 0.999981] [G loss: 1.000077]\n",
      "epoch:32 step:154565[D loss: 1.000023] [G loss: 1.000018]\n",
      "epoch:32 step:154570[D loss: 0.999968] [G loss: 1.000062]\n",
      "epoch:32 step:154575[D loss: 0.999998] [G loss: 1.000058]\n",
      "epoch:32 step:154580[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:32 step:154585[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:32 step:154590[D loss: 0.999961] [G loss: 1.000089]\n",
      "epoch:32 step:154595[D loss: 1.000106] [G loss: 0.999922]\n",
      "epoch:32 step:154600[D loss: 0.999980] [G loss: 1.000134]\n",
      "epoch:32 step:154605[D loss: 0.999956] [G loss: 1.000060]\n",
      "epoch:33 step:154610[D loss: 1.000021] [G loss: 1.000066]\n",
      "epoch:33 step:154615[D loss: 0.999941] [G loss: 1.000083]\n",
      "epoch:33 step:154620[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:33 step:154625[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:33 step:154630[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:33 step:154635[D loss: 0.999967] [G loss: 1.000102]\n",
      "epoch:33 step:154640[D loss: 0.999975] [G loss: 1.000055]\n",
      "epoch:33 step:154645[D loss: 0.999965] [G loss: 1.000089]\n",
      "epoch:33 step:154650[D loss: 1.000006] [G loss: 1.000013]\n",
      "epoch:33 step:154655[D loss: 1.000098] [G loss: 0.999918]\n",
      "epoch:33 step:154660[D loss: 1.000036] [G loss: 0.999977]\n",
      "epoch:33 step:154665[D loss: 0.999897] [G loss: 1.000115]\n",
      "epoch:33 step:154670[D loss: 0.999945] [G loss: 1.000066]\n",
      "epoch:33 step:154675[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:33 step:154680[D loss: 1.000000] [G loss: 1.000090]\n",
      "epoch:33 step:154685[D loss: 0.999990] [G loss: 1.000068]\n",
      "epoch:33 step:154690[D loss: 1.000003] [G loss: 1.000042]\n",
      "epoch:33 step:154695[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:33 step:154700[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:33 step:154705[D loss: 0.999974] [G loss: 1.000072]\n",
      "epoch:33 step:154710[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:33 step:154715[D loss: 1.000027] [G loss: 0.999987]\n",
      "epoch:33 step:154720[D loss: 0.999913] [G loss: 1.000125]\n",
      "epoch:33 step:154725[D loss: 1.000028] [G loss: 1.000119]\n",
      "epoch:33 step:154730[D loss: 0.999918] [G loss: 1.000137]\n",
      "epoch:33 step:154735[D loss: 0.999983] [G loss: 1.000122]\n",
      "epoch:33 step:154740[D loss: 1.000099] [G loss: 1.000012]\n",
      "epoch:33 step:154745[D loss: 0.999918] [G loss: 1.000147]\n",
      "epoch:33 step:154750[D loss: 1.000007] [G loss: 1.000006]\n",
      "epoch:33 step:154755[D loss: 1.000031] [G loss: 0.999983]\n",
      "epoch:33 step:154760[D loss: 0.999941] [G loss: 1.000060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:154765[D loss: 0.999922] [G loss: 1.000060]\n",
      "epoch:33 step:154770[D loss: 0.999961] [G loss: 1.000058]\n",
      "epoch:33 step:154775[D loss: 1.000011] [G loss: 1.000030]\n",
      "epoch:33 step:154780[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:33 step:154785[D loss: 0.999996] [G loss: 1.000073]\n",
      "epoch:33 step:154790[D loss: 0.999986] [G loss: 1.000123]\n",
      "epoch:33 step:154795[D loss: 0.999914] [G loss: 1.000154]\n",
      "epoch:33 step:154800[D loss: 1.000000] [G loss: 1.000038]\n",
      "epoch:33 step:154805[D loss: 1.000026] [G loss: 1.000049]\n",
      "epoch:33 step:154810[D loss: 1.000096] [G loss: 0.999935]\n",
      "epoch:33 step:154815[D loss: 1.000031] [G loss: 0.999930]\n",
      "epoch:33 step:154820[D loss: 0.999976] [G loss: 1.000025]\n",
      "epoch:33 step:154825[D loss: 0.999937] [G loss: 1.000082]\n",
      "epoch:33 step:154830[D loss: 0.999901] [G loss: 1.000181]\n",
      "epoch:33 step:154835[D loss: 0.999985] [G loss: 1.000059]\n",
      "epoch:33 step:154840[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:33 step:154845[D loss: 0.999954] [G loss: 1.000093]\n",
      "epoch:33 step:154850[D loss: 0.999945] [G loss: 1.000100]\n",
      "epoch:33 step:154855[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:33 step:154860[D loss: 0.999986] [G loss: 1.000027]\n",
      "epoch:33 step:154865[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:33 step:154870[D loss: 1.000029] [G loss: 1.000118]\n",
      "epoch:33 step:154875[D loss: 1.000017] [G loss: 1.000063]\n",
      "epoch:33 step:154880[D loss: 0.999948] [G loss: 1.000109]\n",
      "epoch:33 step:154885[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:33 step:154890[D loss: 0.999923] [G loss: 1.000124]\n",
      "epoch:33 step:154895[D loss: 0.999983] [G loss: 1.000049]\n",
      "epoch:33 step:154900[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:33 step:154905[D loss: 0.999969] [G loss: 1.000088]\n",
      "epoch:33 step:154910[D loss: 0.999952] [G loss: 1.000056]\n",
      "epoch:33 step:154915[D loss: 0.999922] [G loss: 1.000117]\n",
      "epoch:33 step:154920[D loss: 0.999974] [G loss: 1.000080]\n",
      "epoch:33 step:154925[D loss: 1.000001] [G loss: 1.000070]\n",
      "epoch:33 step:154930[D loss: 1.000005] [G loss: 1.000043]\n",
      "epoch:33 step:154935[D loss: 1.000040] [G loss: 1.000017]\n",
      "epoch:33 step:154940[D loss: 0.999883] [G loss: 1.000121]\n",
      "epoch:33 step:154945[D loss: 0.999951] [G loss: 1.000119]\n",
      "epoch:33 step:154950[D loss: 0.999958] [G loss: 1.000286]\n",
      "epoch:33 step:154955[D loss: 0.999995] [G loss: 1.000104]\n",
      "epoch:33 step:154960[D loss: 0.999962] [G loss: 1.000191]\n",
      "epoch:33 step:154965[D loss: 1.000031] [G loss: 1.000133]\n",
      "epoch:33 step:154970[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:33 step:154975[D loss: 1.000110] [G loss: 0.999868]\n",
      "epoch:33 step:154980[D loss: 1.000124] [G loss: 0.999793]\n",
      "epoch:33 step:154985[D loss: 0.999922] [G loss: 1.000088]\n",
      "epoch:33 step:154990[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:33 step:154995[D loss: 1.000083] [G loss: 0.999981]\n",
      "epoch:33 step:155000[D loss: 0.999863] [G loss: 1.000219]\n",
      "epoch:33 step:155005[D loss: 0.999908] [G loss: 1.000221]\n",
      "epoch:33 step:155010[D loss: 0.999926] [G loss: 1.000251]\n",
      "epoch:33 step:155015[D loss: 0.999969] [G loss: 1.000045]\n",
      "epoch:33 step:155020[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:33 step:155025[D loss: 0.999967] [G loss: 1.000095]\n",
      "epoch:33 step:155030[D loss: 1.000019] [G loss: 1.000005]\n",
      "epoch:33 step:155035[D loss: 0.999977] [G loss: 0.999996]\n",
      "epoch:33 step:155040[D loss: 0.999957] [G loss: 1.000072]\n",
      "epoch:33 step:155045[D loss: 0.999914] [G loss: 1.000163]\n",
      "epoch:33 step:155050[D loss: 1.000063] [G loss: 1.000010]\n",
      "epoch:33 step:155055[D loss: 0.999931] [G loss: 1.000132]\n",
      "epoch:33 step:155060[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:33 step:155065[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:33 step:155070[D loss: 0.999980] [G loss: 1.000068]\n",
      "epoch:33 step:155075[D loss: 0.999982] [G loss: 1.000076]\n",
      "epoch:33 step:155080[D loss: 0.999998] [G loss: 1.000147]\n",
      "epoch:33 step:155085[D loss: 1.000078] [G loss: 0.999914]\n",
      "epoch:33 step:155090[D loss: 1.000040] [G loss: 1.000214]\n",
      "epoch:33 step:155095[D loss: 1.000023] [G loss: 1.000113]\n",
      "epoch:33 step:155100[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:33 step:155105[D loss: 0.999889] [G loss: 1.000228]\n",
      "epoch:33 step:155110[D loss: 1.000000] [G loss: 0.999968]\n",
      "epoch:33 step:155115[D loss: 0.999961] [G loss: 1.000090]\n",
      "epoch:33 step:155120[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:33 step:155125[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:33 step:155130[D loss: 1.000093] [G loss: 0.999868]\n",
      "epoch:33 step:155135[D loss: 0.999989] [G loss: 0.999973]\n",
      "epoch:33 step:155140[D loss: 1.000027] [G loss: 1.000067]\n",
      "epoch:33 step:155145[D loss: 1.000131] [G loss: 0.999823]\n",
      "epoch:33 step:155150[D loss: 0.999982] [G loss: 0.999883]\n",
      "epoch:33 step:155155[D loss: 0.999949] [G loss: 1.000135]\n",
      "epoch:33 step:155160[D loss: 0.999981] [G loss: 1.000092]\n",
      "epoch:33 step:155165[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:33 step:155170[D loss: 0.999953] [G loss: 1.000148]\n",
      "epoch:33 step:155175[D loss: 0.999991] [G loss: 1.000036]\n",
      "epoch:33 step:155180[D loss: 1.000053] [G loss: 1.000016]\n",
      "epoch:33 step:155185[D loss: 0.999940] [G loss: 1.000090]\n",
      "epoch:33 step:155190[D loss: 1.000057] [G loss: 1.000037]\n",
      "epoch:33 step:155195[D loss: 1.000072] [G loss: 1.000101]\n",
      "epoch:33 step:155200[D loss: 1.000122] [G loss: 0.999983]\n",
      "epoch:33 step:155205[D loss: 0.999983] [G loss: 1.000026]\n",
      "epoch:33 step:155210[D loss: 0.999977] [G loss: 1.000050]\n",
      "epoch:33 step:155215[D loss: 0.999924] [G loss: 1.000249]\n",
      "epoch:33 step:155220[D loss: 0.999949] [G loss: 1.000207]\n",
      "epoch:33 step:155225[D loss: 0.999920] [G loss: 1.000160]\n",
      "epoch:33 step:155230[D loss: 1.000037] [G loss: 0.999975]\n",
      "epoch:33 step:155235[D loss: 1.000006] [G loss: 0.999919]\n",
      "epoch:33 step:155240[D loss: 1.000040] [G loss: 0.999858]\n",
      "epoch:33 step:155245[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:33 step:155250[D loss: 0.999955] [G loss: 1.000128]\n",
      "epoch:33 step:155255[D loss: 0.999810] [G loss: 1.000183]\n",
      "epoch:33 step:155260[D loss: 0.999995] [G loss: 1.000042]\n",
      "epoch:33 step:155265[D loss: 0.999962] [G loss: 1.000121]\n",
      "epoch:33 step:155270[D loss: 0.999930] [G loss: 1.000171]\n",
      "epoch:33 step:155275[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:33 step:155280[D loss: 0.999968] [G loss: 1.000063]\n",
      "epoch:33 step:155285[D loss: 0.999978] [G loss: 1.000082]\n",
      "epoch:33 step:155290[D loss: 1.000029] [G loss: 1.000000]\n",
      "epoch:33 step:155295[D loss: 0.999933] [G loss: 1.000090]\n",
      "epoch:33 step:155300[D loss: 0.999984] [G loss: 1.000067]\n",
      "epoch:33 step:155305[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:33 step:155310[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:33 step:155315[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:33 step:155320[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:33 step:155325[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:33 step:155330[D loss: 0.999960] [G loss: 1.000140]\n",
      "epoch:33 step:155335[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:33 step:155340[D loss: 0.999947] [G loss: 1.000145]\n",
      "epoch:33 step:155345[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:33 step:155350[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:33 step:155355[D loss: 0.999988] [G loss: 1.000008]\n",
      "epoch:33 step:155360[D loss: 0.999974] [G loss: 1.000062]\n",
      "epoch:33 step:155365[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:33 step:155370[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:33 step:155375[D loss: 0.999957] [G loss: 1.000110]\n",
      "epoch:33 step:155380[D loss: 0.999985] [G loss: 1.000083]\n",
      "epoch:33 step:155385[D loss: 1.000144] [G loss: 0.999886]\n",
      "epoch:33 step:155390[D loss: 0.999853] [G loss: 1.000154]\n",
      "epoch:33 step:155395[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:33 step:155400[D loss: 0.999983] [G loss: 1.000054]\n",
      "epoch:33 step:155405[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:33 step:155410[D loss: 1.000005] [G loss: 1.000053]\n",
      "epoch:33 step:155415[D loss: 1.000010] [G loss: 1.000086]\n",
      "epoch:33 step:155420[D loss: 0.999948] [G loss: 1.000029]\n",
      "epoch:33 step:155425[D loss: 0.999935] [G loss: 1.000135]\n",
      "epoch:33 step:155430[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:33 step:155435[D loss: 0.999972] [G loss: 1.000102]\n",
      "epoch:33 step:155440[D loss: 0.999965] [G loss: 1.000069]\n",
      "epoch:33 step:155445[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:33 step:155450[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:33 step:155455[D loss: 0.999988] [G loss: 1.000072]\n",
      "epoch:33 step:155460[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:33 step:155465[D loss: 0.999975] [G loss: 1.000085]\n",
      "epoch:33 step:155470[D loss: 0.999975] [G loss: 1.000050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:155475[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:33 step:155480[D loss: 0.999972] [G loss: 1.000085]\n",
      "epoch:33 step:155485[D loss: 0.999984] [G loss: 1.000058]\n",
      "epoch:33 step:155490[D loss: 0.999960] [G loss: 1.000083]\n",
      "epoch:33 step:155495[D loss: 1.000013] [G loss: 1.000026]\n",
      "epoch:33 step:155500[D loss: 0.999985] [G loss: 1.000116]\n",
      "epoch:33 step:155505[D loss: 0.999984] [G loss: 1.000030]\n",
      "epoch:33 step:155510[D loss: 0.999958] [G loss: 1.000152]\n",
      "epoch:33 step:155515[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:33 step:155520[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:33 step:155525[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:33 step:155530[D loss: 0.999985] [G loss: 1.000117]\n",
      "epoch:33 step:155535[D loss: 1.000021] [G loss: 0.999988]\n",
      "epoch:33 step:155540[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:33 step:155545[D loss: 0.999929] [G loss: 1.000159]\n",
      "epoch:33 step:155550[D loss: 0.999972] [G loss: 1.000100]\n",
      "epoch:33 step:155555[D loss: 0.999978] [G loss: 1.000048]\n",
      "epoch:33 step:155560[D loss: 1.000019] [G loss: 1.000016]\n",
      "epoch:33 step:155565[D loss: 0.999987] [G loss: 1.000035]\n",
      "epoch:33 step:155570[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:33 step:155575[D loss: 1.000021] [G loss: 1.000062]\n",
      "epoch:33 step:155580[D loss: 0.999955] [G loss: 1.000077]\n",
      "epoch:33 step:155585[D loss: 0.999971] [G loss: 1.000096]\n",
      "epoch:33 step:155590[D loss: 1.000041] [G loss: 1.000074]\n",
      "epoch:33 step:155595[D loss: 1.000051] [G loss: 1.000203]\n",
      "epoch:33 step:155600[D loss: 0.999941] [G loss: 1.000154]\n",
      "epoch:33 step:155605[D loss: 0.999861] [G loss: 1.000483]\n",
      "epoch:33 step:155610[D loss: 0.999916] [G loss: 1.000236]\n",
      "epoch:33 step:155615[D loss: 0.999960] [G loss: 1.000111]\n",
      "epoch:33 step:155620[D loss: 0.999984] [G loss: 0.999970]\n",
      "epoch:33 step:155625[D loss: 0.999973] [G loss: 1.000072]\n",
      "epoch:33 step:155630[D loss: 1.000052] [G loss: 0.999943]\n",
      "epoch:33 step:155635[D loss: 0.999985] [G loss: 0.999898]\n",
      "epoch:33 step:155640[D loss: 1.000113] [G loss: 0.999880]\n",
      "epoch:33 step:155645[D loss: 0.999911] [G loss: 0.999994]\n",
      "epoch:33 step:155650[D loss: 1.000151] [G loss: 1.000001]\n",
      "epoch:33 step:155655[D loss: 0.999923] [G loss: 1.000128]\n",
      "epoch:33 step:155660[D loss: 0.999995] [G loss: 1.000096]\n",
      "epoch:33 step:155665[D loss: 0.999936] [G loss: 1.000138]\n",
      "epoch:33 step:155670[D loss: 0.999923] [G loss: 1.000137]\n",
      "epoch:33 step:155675[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:33 step:155680[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:33 step:155685[D loss: 0.999985] [G loss: 1.000085]\n",
      "epoch:33 step:155690[D loss: 1.000160] [G loss: 1.000065]\n",
      "epoch:33 step:155695[D loss: 0.999999] [G loss: 1.000075]\n",
      "epoch:33 step:155700[D loss: 0.999937] [G loss: 1.000109]\n",
      "epoch:33 step:155705[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:33 step:155710[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:33 step:155715[D loss: 1.000107] [G loss: 0.999932]\n",
      "epoch:33 step:155720[D loss: 0.999978] [G loss: 1.000088]\n",
      "epoch:33 step:155725[D loss: 0.999934] [G loss: 1.000084]\n",
      "epoch:33 step:155730[D loss: 1.000099] [G loss: 0.999900]\n",
      "epoch:33 step:155735[D loss: 1.000081] [G loss: 1.000019]\n",
      "epoch:33 step:155740[D loss: 1.000023] [G loss: 1.000291]\n",
      "epoch:33 step:155745[D loss: 0.999911] [G loss: 1.000168]\n",
      "epoch:33 step:155750[D loss: 0.999931] [G loss: 1.000156]\n",
      "epoch:33 step:155755[D loss: 1.000091] [G loss: 1.000029]\n",
      "epoch:33 step:155760[D loss: 0.999899] [G loss: 1.000194]\n",
      "epoch:33 step:155765[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:33 step:155770[D loss: 1.000008] [G loss: 1.000049]\n",
      "epoch:33 step:155775[D loss: 0.999978] [G loss: 1.000129]\n",
      "epoch:33 step:155780[D loss: 0.999904] [G loss: 1.000175]\n",
      "epoch:33 step:155785[D loss: 1.000017] [G loss: 1.000012]\n",
      "epoch:33 step:155790[D loss: 1.000052] [G loss: 0.999977]\n",
      "epoch:33 step:155795[D loss: 1.000117] [G loss: 0.999911]\n",
      "epoch:33 step:155800[D loss: 0.999918] [G loss: 1.000129]\n",
      "epoch:33 step:155805[D loss: 1.000014] [G loss: 1.000020]\n",
      "epoch:33 step:155810[D loss: 1.000034] [G loss: 1.000213]\n",
      "epoch:33 step:155815[D loss: 0.999882] [G loss: 1.000299]\n",
      "epoch:33 step:155820[D loss: 0.999902] [G loss: 1.000216]\n",
      "epoch:33 step:155825[D loss: 1.000090] [G loss: 1.000027]\n",
      "epoch:33 step:155830[D loss: 1.000006] [G loss: 1.000046]\n",
      "epoch:33 step:155835[D loss: 0.999986] [G loss: 1.000071]\n",
      "epoch:33 step:155840[D loss: 0.999963] [G loss: 1.000100]\n",
      "epoch:33 step:155845[D loss: 1.000023] [G loss: 1.000053]\n",
      "epoch:33 step:155850[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:33 step:155855[D loss: 1.000001] [G loss: 1.000051]\n",
      "epoch:33 step:155860[D loss: 0.999985] [G loss: 1.000147]\n",
      "epoch:33 step:155865[D loss: 0.999958] [G loss: 1.000092]\n",
      "epoch:33 step:155870[D loss: 0.999941] [G loss: 1.000166]\n",
      "epoch:33 step:155875[D loss: 0.999964] [G loss: 1.000106]\n",
      "epoch:33 step:155880[D loss: 0.999960] [G loss: 1.000101]\n",
      "epoch:33 step:155885[D loss: 0.999973] [G loss: 1.000088]\n",
      "epoch:33 step:155890[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:33 step:155895[D loss: 0.999992] [G loss: 1.000099]\n",
      "epoch:33 step:155900[D loss: 0.999982] [G loss: 1.000073]\n",
      "epoch:33 step:155905[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:33 step:155910[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:33 step:155915[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:33 step:155920[D loss: 1.000050] [G loss: 1.000017]\n",
      "epoch:33 step:155925[D loss: 1.000034] [G loss: 0.999915]\n",
      "epoch:33 step:155930[D loss: 0.999908] [G loss: 1.000084]\n",
      "epoch:33 step:155935[D loss: 1.000105] [G loss: 0.999980]\n",
      "epoch:33 step:155940[D loss: 0.999902] [G loss: 1.000172]\n",
      "epoch:33 step:155945[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:33 step:155950[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:33 step:155955[D loss: 1.000009] [G loss: 1.000017]\n",
      "epoch:33 step:155960[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:33 step:155965[D loss: 0.999887] [G loss: 1.000131]\n",
      "epoch:33 step:155970[D loss: 0.999948] [G loss: 1.000081]\n",
      "epoch:33 step:155975[D loss: 0.999975] [G loss: 1.000094]\n",
      "epoch:33 step:155980[D loss: 1.000040] [G loss: 1.000032]\n",
      "epoch:33 step:155985[D loss: 0.999994] [G loss: 1.000025]\n",
      "epoch:33 step:155990[D loss: 0.999917] [G loss: 1.000170]\n",
      "epoch:33 step:155995[D loss: 0.999992] [G loss: 1.000077]\n",
      "epoch:33 step:156000[D loss: 0.999908] [G loss: 1.000175]\n",
      "epoch:33 step:156005[D loss: 0.999980] [G loss: 1.000054]\n",
      "epoch:33 step:156010[D loss: 1.000044] [G loss: 0.999991]\n",
      "epoch:33 step:156015[D loss: 1.000054] [G loss: 0.999913]\n",
      "epoch:33 step:156020[D loss: 0.999982] [G loss: 1.000004]\n",
      "epoch:33 step:156025[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:33 step:156030[D loss: 1.000050] [G loss: 0.999988]\n",
      "epoch:33 step:156035[D loss: 0.999930] [G loss: 1.000091]\n",
      "epoch:33 step:156040[D loss: 0.999981] [G loss: 1.000046]\n",
      "epoch:33 step:156045[D loss: 1.000056] [G loss: 1.000096]\n",
      "epoch:33 step:156050[D loss: 0.999974] [G loss: 1.000037]\n",
      "epoch:33 step:156055[D loss: 0.999958] [G loss: 1.000105]\n",
      "epoch:33 step:156060[D loss: 0.999982] [G loss: 1.000107]\n",
      "epoch:33 step:156065[D loss: 0.999969] [G loss: 1.000089]\n",
      "epoch:33 step:156070[D loss: 1.000035] [G loss: 0.999888]\n",
      "epoch:33 step:156075[D loss: 0.999997] [G loss: 1.000000]\n",
      "epoch:33 step:156080[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:33 step:156085[D loss: 0.999916] [G loss: 1.000081]\n",
      "epoch:33 step:156090[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:33 step:156095[D loss: 0.999934] [G loss: 1.000090]\n",
      "epoch:33 step:156100[D loss: 0.999979] [G loss: 1.000029]\n",
      "epoch:33 step:156105[D loss: 0.999978] [G loss: 1.000053]\n",
      "epoch:33 step:156110[D loss: 0.999971] [G loss: 1.000072]\n",
      "epoch:33 step:156115[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:33 step:156120[D loss: 1.000006] [G loss: 1.000104]\n",
      "epoch:33 step:156125[D loss: 0.999923] [G loss: 1.000077]\n",
      "epoch:33 step:156130[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:33 step:156135[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:33 step:156140[D loss: 1.000015] [G loss: 0.999996]\n",
      "epoch:33 step:156145[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:33 step:156150[D loss: 1.000015] [G loss: 1.000003]\n",
      "epoch:33 step:156155[D loss: 1.000053] [G loss: 1.000007]\n",
      "epoch:33 step:156160[D loss: 1.000008] [G loss: 1.000069]\n",
      "epoch:33 step:156165[D loss: 0.999891] [G loss: 1.000124]\n",
      "epoch:33 step:156170[D loss: 0.999957] [G loss: 1.000061]\n",
      "epoch:33 step:156175[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:33 step:156180[D loss: 0.999985] [G loss: 1.000110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:156185[D loss: 0.999964] [G loss: 1.000112]\n",
      "epoch:33 step:156190[D loss: 1.000027] [G loss: 0.999924]\n",
      "epoch:33 step:156195[D loss: 1.000042] [G loss: 0.999889]\n",
      "epoch:33 step:156200[D loss: 1.000069] [G loss: 0.999970]\n",
      "epoch:33 step:156205[D loss: 1.000103] [G loss: 0.999893]\n",
      "epoch:33 step:156210[D loss: 1.000089] [G loss: 1.000048]\n",
      "epoch:33 step:156215[D loss: 1.000203] [G loss: 0.999789]\n",
      "epoch:33 step:156220[D loss: 1.000108] [G loss: 0.999968]\n",
      "epoch:33 step:156225[D loss: 0.999980] [G loss: 1.000106]\n",
      "epoch:33 step:156230[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:33 step:156235[D loss: 1.000024] [G loss: 0.999955]\n",
      "epoch:33 step:156240[D loss: 1.000148] [G loss: 0.999932]\n",
      "epoch:33 step:156245[D loss: 0.999856] [G loss: 1.000047]\n",
      "epoch:33 step:156250[D loss: 0.999955] [G loss: 1.000277]\n",
      "epoch:33 step:156255[D loss: 1.000029] [G loss: 1.000106]\n",
      "epoch:33 step:156260[D loss: 0.999904] [G loss: 1.000126]\n",
      "epoch:33 step:156265[D loss: 0.999936] [G loss: 1.000106]\n",
      "epoch:33 step:156270[D loss: 1.000013] [G loss: 1.000030]\n",
      "epoch:33 step:156275[D loss: 0.999954] [G loss: 1.000063]\n",
      "epoch:33 step:156280[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:33 step:156285[D loss: 0.999980] [G loss: 1.000035]\n",
      "epoch:33 step:156290[D loss: 0.999988] [G loss: 1.000034]\n",
      "epoch:33 step:156295[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:33 step:156300[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:33 step:156305[D loss: 0.999944] [G loss: 1.000107]\n",
      "epoch:33 step:156310[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:33 step:156315[D loss: 0.999976] [G loss: 1.000045]\n",
      "epoch:33 step:156320[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:33 step:156325[D loss: 0.999998] [G loss: 1.000049]\n",
      "epoch:33 step:156330[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:33 step:156335[D loss: 1.000112] [G loss: 0.999930]\n",
      "epoch:33 step:156340[D loss: 0.999987] [G loss: 0.999986]\n",
      "epoch:33 step:156345[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:33 step:156350[D loss: 1.000028] [G loss: 1.000030]\n",
      "epoch:33 step:156355[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:33 step:156360[D loss: 1.000028] [G loss: 1.000027]\n",
      "epoch:33 step:156365[D loss: 0.999991] [G loss: 1.000090]\n",
      "epoch:33 step:156370[D loss: 0.999961] [G loss: 1.000124]\n",
      "epoch:33 step:156375[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:33 step:156380[D loss: 1.000050] [G loss: 0.999970]\n",
      "epoch:33 step:156385[D loss: 0.999911] [G loss: 1.000131]\n",
      "epoch:33 step:156390[D loss: 0.999999] [G loss: 1.000036]\n",
      "epoch:33 step:156395[D loss: 1.000096] [G loss: 1.000007]\n",
      "epoch:33 step:156400[D loss: 0.999898] [G loss: 1.000140]\n",
      "epoch:33 step:156405[D loss: 1.000097] [G loss: 1.000001]\n",
      "epoch:33 step:156410[D loss: 0.999907] [G loss: 1.000146]\n",
      "epoch:33 step:156415[D loss: 0.999990] [G loss: 1.000047]\n",
      "epoch:33 step:156420[D loss: 1.000109] [G loss: 0.999918]\n",
      "epoch:33 step:156425[D loss: 1.000156] [G loss: 0.999922]\n",
      "epoch:33 step:156430[D loss: 1.000019] [G loss: 1.000017]\n",
      "epoch:33 step:156435[D loss: 1.000058] [G loss: 0.999939]\n",
      "epoch:33 step:156440[D loss: 1.000163] [G loss: 1.000004]\n",
      "epoch:33 step:156445[D loss: 1.000069] [G loss: 1.000069]\n",
      "epoch:33 step:156450[D loss: 0.999911] [G loss: 1.000282]\n",
      "epoch:33 step:156455[D loss: 1.000001] [G loss: 1.000077]\n",
      "epoch:33 step:156460[D loss: 0.999952] [G loss: 1.000139]\n",
      "epoch:33 step:156465[D loss: 0.999963] [G loss: 1.000104]\n",
      "epoch:33 step:156470[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:33 step:156475[D loss: 0.999971] [G loss: 1.000092]\n",
      "epoch:33 step:156480[D loss: 1.000080] [G loss: 0.999925]\n",
      "epoch:33 step:156485[D loss: 1.000100] [G loss: 0.999800]\n",
      "epoch:33 step:156490[D loss: 1.000048] [G loss: 1.000010]\n",
      "epoch:33 step:156495[D loss: 1.000238] [G loss: 0.999923]\n",
      "epoch:33 step:156500[D loss: 1.000060] [G loss: 0.999820]\n",
      "epoch:33 step:156505[D loss: 0.999969] [G loss: 0.999905]\n",
      "epoch:33 step:156510[D loss: 0.999794] [G loss: 1.000340]\n",
      "epoch:33 step:156515[D loss: 0.999996] [G loss: 1.000118]\n",
      "epoch:33 step:156520[D loss: 0.999900] [G loss: 1.000107]\n",
      "epoch:33 step:156525[D loss: 0.999967] [G loss: 1.000077]\n",
      "epoch:33 step:156530[D loss: 1.000079] [G loss: 0.999940]\n",
      "epoch:33 step:156535[D loss: 0.999889] [G loss: 1.000036]\n",
      "epoch:33 step:156540[D loss: 1.000132] [G loss: 0.999909]\n",
      "epoch:33 step:156545[D loss: 1.000078] [G loss: 0.999924]\n",
      "epoch:33 step:156550[D loss: 0.999874] [G loss: 1.000024]\n",
      "epoch:33 step:156555[D loss: 1.000132] [G loss: 0.999889]\n",
      "epoch:33 step:156560[D loss: 0.999906] [G loss: 1.000066]\n",
      "epoch:33 step:156565[D loss: 1.000049] [G loss: 1.000097]\n",
      "epoch:33 step:156570[D loss: 0.999947] [G loss: 1.000177]\n",
      "epoch:33 step:156575[D loss: 0.999991] [G loss: 1.000105]\n",
      "epoch:33 step:156580[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:33 step:156585[D loss: 0.999929] [G loss: 1.000094]\n",
      "epoch:33 step:156590[D loss: 1.000094] [G loss: 0.999891]\n",
      "epoch:33 step:156595[D loss: 1.000004] [G loss: 0.999902]\n",
      "epoch:33 step:156600[D loss: 0.999855] [G loss: 1.000247]\n",
      "epoch:33 step:156605[D loss: 1.000028] [G loss: 1.000043]\n",
      "epoch:33 step:156610[D loss: 0.999990] [G loss: 1.000058]\n",
      "epoch:33 step:156615[D loss: 0.999875] [G loss: 1.000247]\n",
      "epoch:33 step:156620[D loss: 1.000002] [G loss: 1.000100]\n",
      "epoch:33 step:156625[D loss: 1.000033] [G loss: 0.999997]\n",
      "epoch:33 step:156630[D loss: 0.999935] [G loss: 1.000074]\n",
      "epoch:33 step:156635[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:33 step:156640[D loss: 1.000058] [G loss: 0.999943]\n",
      "epoch:33 step:156645[D loss: 0.999906] [G loss: 1.000086]\n",
      "epoch:33 step:156650[D loss: 1.000013] [G loss: 0.999995]\n",
      "epoch:33 step:156655[D loss: 1.000124] [G loss: 1.000045]\n",
      "epoch:33 step:156660[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:33 step:156665[D loss: 0.999948] [G loss: 1.000066]\n",
      "epoch:33 step:156670[D loss: 1.000011] [G loss: 1.000024]\n",
      "epoch:33 step:156675[D loss: 1.000001] [G loss: 1.000031]\n",
      "epoch:33 step:156680[D loss: 0.999982] [G loss: 1.000101]\n",
      "epoch:33 step:156685[D loss: 0.999983] [G loss: 1.000082]\n",
      "epoch:33 step:156690[D loss: 0.999961] [G loss: 1.000101]\n",
      "epoch:33 step:156695[D loss: 0.999954] [G loss: 1.000097]\n",
      "epoch:33 step:156700[D loss: 0.999961] [G loss: 1.000088]\n",
      "epoch:33 step:156705[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:33 step:156710[D loss: 1.000053] [G loss: 0.999987]\n",
      "epoch:33 step:156715[D loss: 0.999942] [G loss: 1.000196]\n",
      "epoch:33 step:156720[D loss: 0.999989] [G loss: 1.000065]\n",
      "epoch:33 step:156725[D loss: 1.000011] [G loss: 1.000002]\n",
      "epoch:33 step:156730[D loss: 0.999932] [G loss: 1.000172]\n",
      "epoch:33 step:156735[D loss: 1.000052] [G loss: 0.999939]\n",
      "epoch:33 step:156740[D loss: 0.999989] [G loss: 0.999987]\n",
      "epoch:33 step:156745[D loss: 1.000136] [G loss: 0.999885]\n",
      "epoch:33 step:156750[D loss: 1.000002] [G loss: 1.000051]\n",
      "epoch:33 step:156755[D loss: 0.999890] [G loss: 1.000252]\n",
      "epoch:33 step:156760[D loss: 0.999922] [G loss: 1.000104]\n",
      "epoch:33 step:156765[D loss: 0.999962] [G loss: 1.000139]\n",
      "epoch:33 step:156770[D loss: 0.999953] [G loss: 1.000091]\n",
      "epoch:33 step:156775[D loss: 1.000011] [G loss: 1.000050]\n",
      "epoch:33 step:156780[D loss: 0.999987] [G loss: 1.000053]\n",
      "epoch:33 step:156785[D loss: 1.000076] [G loss: 0.999878]\n",
      "epoch:33 step:156790[D loss: 0.999959] [G loss: 1.000015]\n",
      "epoch:33 step:156795[D loss: 1.000034] [G loss: 1.000120]\n",
      "epoch:33 step:156800[D loss: 0.999935] [G loss: 1.000106]\n",
      "epoch:33 step:156805[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:33 step:156810[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:33 step:156815[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:33 step:156820[D loss: 0.999981] [G loss: 1.000101]\n",
      "epoch:33 step:156825[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:33 step:156830[D loss: 1.000011] [G loss: 1.000043]\n",
      "epoch:33 step:156835[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:33 step:156840[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:33 step:156845[D loss: 1.000026] [G loss: 1.000064]\n",
      "epoch:33 step:156850[D loss: 1.000006] [G loss: 1.000024]\n",
      "epoch:33 step:156855[D loss: 1.000022] [G loss: 1.000041]\n",
      "epoch:33 step:156860[D loss: 0.999923] [G loss: 1.000132]\n",
      "epoch:33 step:156865[D loss: 1.000019] [G loss: 1.000014]\n",
      "epoch:33 step:156870[D loss: 0.999966] [G loss: 1.000092]\n",
      "epoch:33 step:156875[D loss: 0.999977] [G loss: 1.000007]\n",
      "epoch:33 step:156880[D loss: 0.999990] [G loss: 1.000020]\n",
      "epoch:33 step:156885[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:33 step:156890[D loss: 1.000079] [G loss: 0.999884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:156895[D loss: 0.999971] [G loss: 1.000134]\n",
      "epoch:33 step:156900[D loss: 1.000320] [G loss: 0.999962]\n",
      "epoch:33 step:156905[D loss: 0.999787] [G loss: 1.000263]\n",
      "epoch:33 step:156910[D loss: 0.999926] [G loss: 1.000056]\n",
      "epoch:33 step:156915[D loss: 0.999904] [G loss: 1.000115]\n",
      "epoch:33 step:156920[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:33 step:156925[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:33 step:156930[D loss: 0.999994] [G loss: 1.000014]\n",
      "epoch:33 step:156935[D loss: 0.999854] [G loss: 1.000172]\n",
      "epoch:33 step:156940[D loss: 0.999979] [G loss: 1.000028]\n",
      "epoch:33 step:156945[D loss: 1.000075] [G loss: 1.000053]\n",
      "epoch:33 step:156950[D loss: 1.000174] [G loss: 0.999948]\n",
      "epoch:33 step:156955[D loss: 0.999914] [G loss: 1.000159]\n",
      "epoch:33 step:156960[D loss: 0.999946] [G loss: 1.000177]\n",
      "epoch:33 step:156965[D loss: 0.999943] [G loss: 1.000219]\n",
      "epoch:33 step:156970[D loss: 0.999954] [G loss: 1.000141]\n",
      "epoch:33 step:156975[D loss: 1.000023] [G loss: 0.999997]\n",
      "epoch:33 step:156980[D loss: 1.000021] [G loss: 0.999962]\n",
      "epoch:33 step:156985[D loss: 0.999982] [G loss: 0.999981]\n",
      "epoch:33 step:156990[D loss: 0.999949] [G loss: 1.000025]\n",
      "epoch:33 step:156995[D loss: 1.000045] [G loss: 0.999997]\n",
      "epoch:33 step:157000[D loss: 0.999960] [G loss: 0.999943]\n",
      "epoch:33 step:157005[D loss: 0.999939] [G loss: 1.000099]\n",
      "epoch:33 step:157010[D loss: 1.000060] [G loss: 1.000152]\n",
      "epoch:33 step:157015[D loss: 0.999821] [G loss: 1.000231]\n",
      "epoch:33 step:157020[D loss: 0.999997] [G loss: 1.000118]\n",
      "epoch:33 step:157025[D loss: 0.999975] [G loss: 1.000143]\n",
      "epoch:33 step:157030[D loss: 1.000066] [G loss: 0.999971]\n",
      "epoch:33 step:157035[D loss: 0.999998] [G loss: 0.999963]\n",
      "epoch:33 step:157040[D loss: 1.000019] [G loss: 1.000035]\n",
      "epoch:33 step:157045[D loss: 1.000010] [G loss: 1.000123]\n",
      "epoch:33 step:157050[D loss: 1.000028] [G loss: 1.000080]\n",
      "epoch:33 step:157055[D loss: 1.000123] [G loss: 1.000061]\n",
      "epoch:33 step:157060[D loss: 0.999895] [G loss: 1.000199]\n",
      "epoch:33 step:157065[D loss: 0.999972] [G loss: 1.000389]\n",
      "epoch:33 step:157070[D loss: 0.999988] [G loss: 1.000485]\n",
      "epoch:33 step:157075[D loss: 0.999958] [G loss: 1.000298]\n",
      "epoch:33 step:157080[D loss: 0.999700] [G loss: 1.000416]\n",
      "epoch:33 step:157085[D loss: 1.000244] [G loss: 1.000199]\n",
      "epoch:33 step:157090[D loss: 1.000002] [G loss: 1.000352]\n",
      "epoch:33 step:157095[D loss: 0.999948] [G loss: 1.000160]\n",
      "epoch:33 step:157100[D loss: 1.000065] [G loss: 0.999931]\n",
      "epoch:33 step:157105[D loss: 1.000035] [G loss: 0.999943]\n",
      "epoch:33 step:157110[D loss: 0.999928] [G loss: 0.999946]\n",
      "epoch:33 step:157115[D loss: 0.999939] [G loss: 1.000013]\n",
      "epoch:33 step:157120[D loss: 0.999935] [G loss: 1.000046]\n",
      "epoch:33 step:157125[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:33 step:157130[D loss: 1.000027] [G loss: 0.999912]\n",
      "epoch:33 step:157135[D loss: 0.999898] [G loss: 1.000047]\n",
      "epoch:33 step:157140[D loss: 1.000245] [G loss: 0.999892]\n",
      "epoch:33 step:157145[D loss: 1.000163] [G loss: 1.000054]\n",
      "epoch:33 step:157150[D loss: 1.000132] [G loss: 0.999926]\n",
      "epoch:33 step:157155[D loss: 1.000271] [G loss: 1.000132]\n",
      "epoch:33 step:157160[D loss: 1.000036] [G loss: 1.000067]\n",
      "epoch:33 step:157165[D loss: 0.999806] [G loss: 1.000225]\n",
      "epoch:33 step:157170[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:33 step:157175[D loss: 1.000024] [G loss: 0.999937]\n",
      "epoch:33 step:157180[D loss: 1.000010] [G loss: 0.999958]\n",
      "epoch:33 step:157185[D loss: 1.000114] [G loss: 0.999904]\n",
      "epoch:33 step:157190[D loss: 1.000272] [G loss: 0.999838]\n",
      "epoch:33 step:157195[D loss: 0.999976] [G loss: 1.000038]\n",
      "epoch:33 step:157200[D loss: 0.999971] [G loss: 1.000107]\n",
      "epoch:33 step:157205[D loss: 0.999960] [G loss: 1.000168]\n",
      "epoch:33 step:157210[D loss: 0.999905] [G loss: 1.000154]\n",
      "epoch:33 step:157215[D loss: 0.999959] [G loss: 1.000154]\n",
      "epoch:33 step:157220[D loss: 0.999863] [G loss: 1.000194]\n",
      "epoch:33 step:157225[D loss: 0.999959] [G loss: 1.000164]\n",
      "epoch:33 step:157230[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:33 step:157235[D loss: 0.999960] [G loss: 1.000106]\n",
      "epoch:33 step:157240[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:33 step:157245[D loss: 0.999945] [G loss: 1.000025]\n",
      "epoch:33 step:157250[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:33 step:157255[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:33 step:157260[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:33 step:157265[D loss: 0.999975] [G loss: 1.000070]\n",
      "epoch:33 step:157270[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:33 step:157275[D loss: 1.000167] [G loss: 0.999841]\n",
      "epoch:33 step:157280[D loss: 0.999920] [G loss: 1.000144]\n",
      "epoch:33 step:157285[D loss: 1.000239] [G loss: 0.999878]\n",
      "epoch:33 step:157290[D loss: 0.999938] [G loss: 1.000235]\n",
      "epoch:33 step:157295[D loss: 0.999991] [G loss: 1.000146]\n",
      "epoch:33 step:157300[D loss: 0.999920] [G loss: 1.000374]\n",
      "epoch:33 step:157305[D loss: 0.999984] [G loss: 1.000198]\n",
      "epoch:33 step:157310[D loss: 0.999893] [G loss: 1.000209]\n",
      "epoch:33 step:157315[D loss: 0.999982] [G loss: 1.000069]\n",
      "epoch:33 step:157320[D loss: 1.000157] [G loss: 0.999862]\n",
      "epoch:33 step:157325[D loss: 0.999967] [G loss: 0.999980]\n",
      "epoch:33 step:157330[D loss: 1.000037] [G loss: 0.999958]\n",
      "epoch:33 step:157335[D loss: 0.999975] [G loss: 1.000016]\n",
      "epoch:33 step:157340[D loss: 0.999943] [G loss: 1.000025]\n",
      "epoch:33 step:157345[D loss: 1.000045] [G loss: 0.999916]\n",
      "epoch:33 step:157350[D loss: 1.000033] [G loss: 1.000082]\n",
      "epoch:33 step:157355[D loss: 0.999974] [G loss: 1.000215]\n",
      "epoch:33 step:157360[D loss: 0.999949] [G loss: 1.000043]\n",
      "epoch:33 step:157365[D loss: 0.999995] [G loss: 1.000039]\n",
      "epoch:33 step:157370[D loss: 0.999969] [G loss: 1.000049]\n",
      "epoch:33 step:157375[D loss: 0.999965] [G loss: 1.000065]\n",
      "epoch:33 step:157380[D loss: 0.999973] [G loss: 1.000078]\n",
      "epoch:33 step:157385[D loss: 0.999961] [G loss: 1.000067]\n",
      "epoch:33 step:157390[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:33 step:157395[D loss: 1.000021] [G loss: 1.000025]\n",
      "epoch:33 step:157400[D loss: 0.999930] [G loss: 1.000149]\n",
      "epoch:33 step:157405[D loss: 0.999964] [G loss: 1.000069]\n",
      "epoch:33 step:157410[D loss: 1.000001] [G loss: 1.000094]\n",
      "epoch:33 step:157415[D loss: 0.999950] [G loss: 1.000135]\n",
      "epoch:33 step:157420[D loss: 0.999964] [G loss: 1.000096]\n",
      "epoch:33 step:157425[D loss: 0.999973] [G loss: 1.000084]\n",
      "epoch:33 step:157430[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:33 step:157435[D loss: 1.000000] [G loss: 1.000050]\n",
      "epoch:33 step:157440[D loss: 0.999952] [G loss: 1.000078]\n",
      "epoch:33 step:157445[D loss: 1.000010] [G loss: 1.000080]\n",
      "epoch:33 step:157450[D loss: 0.999943] [G loss: 1.000091]\n",
      "epoch:33 step:157455[D loss: 0.999976] [G loss: 1.000090]\n",
      "epoch:33 step:157460[D loss: 0.999960] [G loss: 1.000073]\n",
      "epoch:33 step:157465[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:33 step:157470[D loss: 0.999989] [G loss: 1.000094]\n",
      "epoch:33 step:157475[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:33 step:157480[D loss: 1.000045] [G loss: 1.000014]\n",
      "epoch:33 step:157485[D loss: 0.999970] [G loss: 1.000128]\n",
      "epoch:33 step:157490[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:33 step:157495[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:33 step:157500[D loss: 0.999977] [G loss: 1.000066]\n",
      "epoch:33 step:157505[D loss: 1.000043] [G loss: 1.000058]\n",
      "epoch:33 step:157510[D loss: 0.999961] [G loss: 1.000042]\n",
      "epoch:33 step:157515[D loss: 1.000005] [G loss: 1.000042]\n",
      "epoch:33 step:157520[D loss: 0.999998] [G loss: 1.000027]\n",
      "epoch:33 step:157525[D loss: 0.999956] [G loss: 1.000063]\n",
      "epoch:33 step:157530[D loss: 0.999979] [G loss: 1.000053]\n",
      "epoch:33 step:157535[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:33 step:157540[D loss: 1.000002] [G loss: 1.000007]\n",
      "epoch:33 step:157545[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:33 step:157550[D loss: 1.000064] [G loss: 1.000119]\n",
      "epoch:33 step:157555[D loss: 0.999977] [G loss: 1.000030]\n",
      "epoch:33 step:157560[D loss: 0.999972] [G loss: 1.000039]\n",
      "epoch:33 step:157565[D loss: 1.000055] [G loss: 1.000074]\n",
      "epoch:33 step:157570[D loss: 1.000119] [G loss: 1.000063]\n",
      "epoch:33 step:157575[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:33 step:157580[D loss: 1.000228] [G loss: 0.999986]\n",
      "epoch:33 step:157585[D loss: 1.000013] [G loss: 1.000016]\n",
      "epoch:33 step:157590[D loss: 0.999923] [G loss: 1.000142]\n",
      "epoch:33 step:157595[D loss: 0.999934] [G loss: 1.000194]\n",
      "epoch:33 step:157600[D loss: 0.999964] [G loss: 1.000111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:157605[D loss: 0.999977] [G loss: 1.000098]\n",
      "epoch:33 step:157610[D loss: 1.000050] [G loss: 0.999997]\n",
      "epoch:33 step:157615[D loss: 0.999972] [G loss: 0.999988]\n",
      "epoch:33 step:157620[D loss: 0.999996] [G loss: 0.999889]\n",
      "epoch:33 step:157625[D loss: 0.999930] [G loss: 1.000123]\n",
      "epoch:33 step:157630[D loss: 0.999933] [G loss: 1.000075]\n",
      "epoch:33 step:157635[D loss: 0.999979] [G loss: 1.000057]\n",
      "epoch:33 step:157640[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:33 step:157645[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:33 step:157650[D loss: 1.000066] [G loss: 1.000088]\n",
      "epoch:33 step:157655[D loss: 0.999910] [G loss: 1.000063]\n",
      "epoch:33 step:157660[D loss: 1.000050] [G loss: 1.000096]\n",
      "epoch:33 step:157665[D loss: 0.999980] [G loss: 1.000082]\n",
      "epoch:33 step:157670[D loss: 0.999947] [G loss: 1.000062]\n",
      "epoch:33 step:157675[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:33 step:157680[D loss: 0.999966] [G loss: 1.000037]\n",
      "epoch:33 step:157685[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:33 step:157690[D loss: 1.000208] [G loss: 0.999844]\n",
      "epoch:33 step:157695[D loss: 1.000161] [G loss: 0.999673]\n",
      "epoch:33 step:157700[D loss: 0.999898] [G loss: 1.000036]\n",
      "epoch:33 step:157705[D loss: 1.000118] [G loss: 0.999949]\n",
      "epoch:33 step:157710[D loss: 1.000000] [G loss: 0.999881]\n",
      "epoch:33 step:157715[D loss: 0.999920] [G loss: 1.000269]\n",
      "epoch:33 step:157720[D loss: 1.000001] [G loss: 1.000057]\n",
      "epoch:33 step:157725[D loss: 0.999995] [G loss: 1.000102]\n",
      "epoch:33 step:157730[D loss: 0.999985] [G loss: 1.000122]\n",
      "epoch:33 step:157735[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:33 step:157740[D loss: 1.000132] [G loss: 0.999951]\n",
      "epoch:33 step:157745[D loss: 1.000027] [G loss: 0.999975]\n",
      "epoch:33 step:157750[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:33 step:157755[D loss: 0.999916] [G loss: 1.000211]\n",
      "epoch:33 step:157760[D loss: 1.000038] [G loss: 1.000069]\n",
      "epoch:33 step:157765[D loss: 0.999987] [G loss: 1.000254]\n",
      "epoch:33 step:157770[D loss: 0.999925] [G loss: 1.000246]\n",
      "epoch:33 step:157775[D loss: 0.999992] [G loss: 1.000018]\n",
      "epoch:33 step:157780[D loss: 1.000039] [G loss: 0.999954]\n",
      "epoch:33 step:157785[D loss: 1.000042] [G loss: 0.999963]\n",
      "epoch:33 step:157790[D loss: 1.000129] [G loss: 0.999942]\n",
      "epoch:33 step:157795[D loss: 0.999977] [G loss: 0.999943]\n",
      "epoch:33 step:157800[D loss: 0.999942] [G loss: 1.000011]\n",
      "epoch:33 step:157805[D loss: 1.000056] [G loss: 1.000030]\n",
      "epoch:33 step:157810[D loss: 1.000043] [G loss: 1.000094]\n",
      "epoch:33 step:157815[D loss: 0.999969] [G loss: 1.000099]\n",
      "epoch:33 step:157820[D loss: 0.999940] [G loss: 1.000023]\n",
      "epoch:33 step:157825[D loss: 1.000006] [G loss: 1.000038]\n",
      "epoch:33 step:157830[D loss: 1.000021] [G loss: 1.000001]\n",
      "epoch:33 step:157835[D loss: 1.000047] [G loss: 0.999999]\n",
      "epoch:33 step:157840[D loss: 0.999984] [G loss: 1.000006]\n",
      "epoch:33 step:157845[D loss: 0.999944] [G loss: 1.000080]\n",
      "epoch:33 step:157850[D loss: 0.999979] [G loss: 1.000119]\n",
      "epoch:33 step:157855[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:33 step:157860[D loss: 1.000104] [G loss: 1.000038]\n",
      "epoch:33 step:157865[D loss: 0.999961] [G loss: 1.000121]\n",
      "epoch:33 step:157870[D loss: 0.999958] [G loss: 1.000094]\n",
      "epoch:33 step:157875[D loss: 1.000028] [G loss: 0.999943]\n",
      "epoch:33 step:157880[D loss: 0.999965] [G loss: 1.000049]\n",
      "epoch:33 step:157885[D loss: 0.999959] [G loss: 1.000090]\n",
      "epoch:33 step:157890[D loss: 0.999966] [G loss: 1.000098]\n",
      "epoch:33 step:157895[D loss: 0.999965] [G loss: 1.000078]\n",
      "epoch:33 step:157900[D loss: 0.999962] [G loss: 1.000136]\n",
      "epoch:33 step:157905[D loss: 0.999957] [G loss: 1.000111]\n",
      "epoch:33 step:157910[D loss: 0.999970] [G loss: 1.000143]\n",
      "epoch:33 step:157915[D loss: 0.999990] [G loss: 1.000143]\n",
      "epoch:33 step:157920[D loss: 0.999949] [G loss: 1.000160]\n",
      "epoch:33 step:157925[D loss: 0.999960] [G loss: 1.000077]\n",
      "epoch:33 step:157930[D loss: 1.000010] [G loss: 0.999971]\n",
      "epoch:33 step:157935[D loss: 1.000039] [G loss: 0.999998]\n",
      "epoch:33 step:157940[D loss: 0.999955] [G loss: 1.000031]\n",
      "epoch:33 step:157945[D loss: 0.999941] [G loss: 1.000062]\n",
      "epoch:33 step:157950[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:33 step:157955[D loss: 1.000009] [G loss: 1.000009]\n",
      "epoch:33 step:157960[D loss: 0.999889] [G loss: 1.000141]\n",
      "epoch:33 step:157965[D loss: 0.999975] [G loss: 1.000079]\n",
      "epoch:33 step:157970[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:33 step:157975[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:33 step:157980[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:33 step:157985[D loss: 0.999962] [G loss: 1.000068]\n",
      "epoch:33 step:157990[D loss: 0.999950] [G loss: 1.000130]\n",
      "epoch:33 step:157995[D loss: 0.999945] [G loss: 1.000135]\n",
      "epoch:33 step:158000[D loss: 0.999985] [G loss: 1.000072]\n",
      "epoch:33 step:158005[D loss: 0.999980] [G loss: 1.000040]\n",
      "epoch:33 step:158010[D loss: 0.999946] [G loss: 1.000093]\n",
      "epoch:33 step:158015[D loss: 1.000034] [G loss: 1.000042]\n",
      "epoch:33 step:158020[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:33 step:158025[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:33 step:158030[D loss: 1.000009] [G loss: 1.000036]\n",
      "epoch:33 step:158035[D loss: 1.000035] [G loss: 0.999908]\n",
      "epoch:33 step:158040[D loss: 1.000000] [G loss: 1.000039]\n",
      "epoch:33 step:158045[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:33 step:158050[D loss: 1.000020] [G loss: 1.000106]\n",
      "epoch:33 step:158055[D loss: 0.999943] [G loss: 1.000074]\n",
      "epoch:33 step:158060[D loss: 0.999927] [G loss: 1.000127]\n",
      "epoch:33 step:158065[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:33 step:158070[D loss: 1.000022] [G loss: 1.000180]\n",
      "epoch:33 step:158075[D loss: 0.999996] [G loss: 1.000094]\n",
      "epoch:33 step:158080[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:33 step:158085[D loss: 0.999925] [G loss: 1.000105]\n",
      "epoch:33 step:158090[D loss: 0.999984] [G loss: 1.000077]\n",
      "epoch:33 step:158095[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:33 step:158100[D loss: 1.000078] [G loss: 0.999896]\n",
      "epoch:33 step:158105[D loss: 1.000008] [G loss: 0.999960]\n",
      "epoch:33 step:158110[D loss: 0.999971] [G loss: 1.000044]\n",
      "epoch:33 step:158115[D loss: 0.999996] [G loss: 1.000057]\n",
      "epoch:33 step:158120[D loss: 0.999961] [G loss: 1.000099]\n",
      "epoch:33 step:158125[D loss: 0.999924] [G loss: 1.000146]\n",
      "epoch:33 step:158130[D loss: 1.000077] [G loss: 1.000115]\n",
      "epoch:33 step:158135[D loss: 1.000045] [G loss: 1.000069]\n",
      "epoch:33 step:158140[D loss: 0.999967] [G loss: 1.000136]\n",
      "epoch:33 step:158145[D loss: 0.999898] [G loss: 1.000136]\n",
      "epoch:33 step:158150[D loss: 1.000091] [G loss: 0.999984]\n",
      "epoch:33 step:158155[D loss: 1.000224] [G loss: 0.999868]\n",
      "epoch:33 step:158160[D loss: 1.000019] [G loss: 1.000020]\n",
      "epoch:33 step:158165[D loss: 0.999891] [G loss: 1.000094]\n",
      "epoch:33 step:158170[D loss: 0.999885] [G loss: 1.000160]\n",
      "epoch:33 step:158175[D loss: 1.000117] [G loss: 1.000176]\n",
      "epoch:33 step:158180[D loss: 0.999960] [G loss: 1.000041]\n",
      "epoch:33 step:158185[D loss: 0.999916] [G loss: 1.000078]\n",
      "epoch:33 step:158190[D loss: 0.999976] [G loss: 1.000024]\n",
      "epoch:33 step:158195[D loss: 1.000047] [G loss: 0.999942]\n",
      "epoch:33 step:158200[D loss: 1.000063] [G loss: 0.999947]\n",
      "epoch:33 step:158205[D loss: 0.999911] [G loss: 1.000152]\n",
      "epoch:33 step:158210[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:33 step:158215[D loss: 1.000037] [G loss: 1.000107]\n",
      "epoch:33 step:158220[D loss: 1.000039] [G loss: 1.000121]\n",
      "epoch:33 step:158225[D loss: 0.999900] [G loss: 1.000188]\n",
      "epoch:33 step:158230[D loss: 0.999951] [G loss: 1.000157]\n",
      "epoch:33 step:158235[D loss: 0.999959] [G loss: 1.000073]\n",
      "epoch:33 step:158240[D loss: 0.999947] [G loss: 1.000089]\n",
      "epoch:33 step:158245[D loss: 1.000011] [G loss: 1.000018]\n",
      "epoch:33 step:158250[D loss: 1.000000] [G loss: 0.999984]\n",
      "epoch:33 step:158255[D loss: 0.999960] [G loss: 1.000054]\n",
      "epoch:33 step:158260[D loss: 1.000043] [G loss: 1.000007]\n",
      "epoch:33 step:158265[D loss: 1.000008] [G loss: 1.000033]\n",
      "epoch:33 step:158270[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:33 step:158275[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:33 step:158280[D loss: 0.999950] [G loss: 1.000049]\n",
      "epoch:33 step:158285[D loss: 0.999920] [G loss: 1.000153]\n",
      "epoch:33 step:158290[D loss: 0.999975] [G loss: 1.000041]\n",
      "epoch:33 step:158295[D loss: 0.999955] [G loss: 1.000073]\n",
      "epoch:33 step:158300[D loss: 1.000067] [G loss: 1.000036]\n",
      "epoch:33 step:158305[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:33 step:158310[D loss: 0.999860] [G loss: 1.000136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:158315[D loss: 1.000029] [G loss: 1.000060]\n",
      "epoch:33 step:158320[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:33 step:158325[D loss: 0.999987] [G loss: 1.000049]\n",
      "epoch:33 step:158330[D loss: 0.999954] [G loss: 1.000057]\n",
      "epoch:33 step:158335[D loss: 0.999959] [G loss: 1.000055]\n",
      "epoch:33 step:158340[D loss: 1.000012] [G loss: 0.999992]\n",
      "epoch:33 step:158345[D loss: 0.999977] [G loss: 1.000075]\n",
      "epoch:33 step:158350[D loss: 0.999962] [G loss: 1.000053]\n",
      "epoch:33 step:158355[D loss: 1.000000] [G loss: 1.000090]\n",
      "epoch:33 step:158360[D loss: 0.999942] [G loss: 1.000089]\n",
      "epoch:33 step:158365[D loss: 0.999925] [G loss: 1.000097]\n",
      "epoch:33 step:158370[D loss: 0.999996] [G loss: 1.000084]\n",
      "epoch:33 step:158375[D loss: 0.999991] [G loss: 1.000303]\n",
      "epoch:33 step:158380[D loss: 1.000040] [G loss: 1.000082]\n",
      "epoch:33 step:158385[D loss: 0.999961] [G loss: 1.000054]\n",
      "epoch:33 step:158390[D loss: 1.000080] [G loss: 0.999928]\n",
      "epoch:33 step:158395[D loss: 1.000151] [G loss: 0.999834]\n",
      "epoch:33 step:158400[D loss: 0.999917] [G loss: 1.000062]\n",
      "epoch:33 step:158405[D loss: 1.000045] [G loss: 0.999878]\n",
      "epoch:33 step:158410[D loss: 0.999938] [G loss: 1.000162]\n",
      "epoch:33 step:158415[D loss: 0.999936] [G loss: 1.000318]\n",
      "epoch:33 step:158420[D loss: 0.999900] [G loss: 1.000120]\n",
      "epoch:33 step:158425[D loss: 0.999901] [G loss: 1.000221]\n",
      "epoch:33 step:158430[D loss: 0.999999] [G loss: 1.000099]\n",
      "epoch:33 step:158435[D loss: 0.999926] [G loss: 1.000122]\n",
      "epoch:33 step:158440[D loss: 0.999988] [G loss: 1.000095]\n",
      "epoch:33 step:158445[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:33 step:158450[D loss: 0.999960] [G loss: 1.000093]\n",
      "epoch:33 step:158455[D loss: 0.999991] [G loss: 0.999934]\n",
      "epoch:33 step:158460[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:33 step:158465[D loss: 0.999866] [G loss: 1.000271]\n",
      "epoch:33 step:158470[D loss: 0.999859] [G loss: 1.000224]\n",
      "epoch:33 step:158475[D loss: 1.000121] [G loss: 1.000011]\n",
      "epoch:33 step:158480[D loss: 0.999904] [G loss: 1.000081]\n",
      "epoch:33 step:158485[D loss: 0.999930] [G loss: 1.000142]\n",
      "epoch:33 step:158490[D loss: 1.000002] [G loss: 0.999989]\n",
      "epoch:33 step:158495[D loss: 1.000042] [G loss: 1.000055]\n",
      "epoch:33 step:158500[D loss: 1.000048] [G loss: 1.000075]\n",
      "epoch:33 step:158505[D loss: 0.999997] [G loss: 0.999960]\n",
      "epoch:33 step:158510[D loss: 0.999884] [G loss: 1.000073]\n",
      "epoch:33 step:158515[D loss: 0.999987] [G loss: 1.000062]\n",
      "epoch:33 step:158520[D loss: 0.999998] [G loss: 1.000087]\n",
      "epoch:33 step:158525[D loss: 1.000016] [G loss: 1.000071]\n",
      "epoch:33 step:158530[D loss: 0.999923] [G loss: 1.000162]\n",
      "epoch:33 step:158535[D loss: 1.000009] [G loss: 1.000116]\n",
      "epoch:33 step:158540[D loss: 0.999947] [G loss: 1.000140]\n",
      "epoch:33 step:158545[D loss: 0.999971] [G loss: 1.000098]\n",
      "epoch:33 step:158550[D loss: 0.999996] [G loss: 1.000163]\n",
      "epoch:33 step:158555[D loss: 1.000034] [G loss: 0.999928]\n",
      "epoch:33 step:158560[D loss: 1.000061] [G loss: 0.999893]\n",
      "epoch:33 step:158565[D loss: 0.999986] [G loss: 0.999982]\n",
      "epoch:33 step:158570[D loss: 0.999873] [G loss: 1.000118]\n",
      "epoch:33 step:158575[D loss: 1.000040] [G loss: 1.000016]\n",
      "epoch:33 step:158580[D loss: 1.000008] [G loss: 1.000123]\n",
      "epoch:33 step:158585[D loss: 0.999865] [G loss: 1.000305]\n",
      "epoch:33 step:158590[D loss: 0.999939] [G loss: 1.000125]\n",
      "epoch:33 step:158595[D loss: 1.000007] [G loss: 1.000166]\n",
      "epoch:33 step:158600[D loss: 0.999917] [G loss: 1.000096]\n",
      "epoch:33 step:158605[D loss: 0.999934] [G loss: 1.000062]\n",
      "epoch:33 step:158610[D loss: 0.999987] [G loss: 1.000010]\n",
      "epoch:33 step:158615[D loss: 0.999952] [G loss: 1.000018]\n",
      "epoch:33 step:158620[D loss: 0.999987] [G loss: 0.999946]\n",
      "epoch:33 step:158625[D loss: 0.999920] [G loss: 1.000057]\n",
      "epoch:33 step:158630[D loss: 1.000048] [G loss: 1.000113]\n",
      "epoch:33 step:158635[D loss: 0.999959] [G loss: 1.000042]\n",
      "epoch:33 step:158640[D loss: 0.999928] [G loss: 1.000264]\n",
      "epoch:33 step:158645[D loss: 1.000078] [G loss: 1.000103]\n",
      "epoch:33 step:158650[D loss: 0.999966] [G loss: 1.000060]\n",
      "epoch:33 step:158655[D loss: 0.999933] [G loss: 1.000202]\n",
      "epoch:33 step:158660[D loss: 0.999971] [G loss: 1.000120]\n",
      "epoch:33 step:158665[D loss: 0.999956] [G loss: 1.000113]\n",
      "epoch:33 step:158670[D loss: 0.999933] [G loss: 1.000147]\n",
      "epoch:33 step:158675[D loss: 1.000002] [G loss: 1.000008]\n",
      "epoch:33 step:158680[D loss: 0.999971] [G loss: 1.000124]\n",
      "epoch:33 step:158685[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:33 step:158690[D loss: 0.999945] [G loss: 1.000118]\n",
      "epoch:33 step:158695[D loss: 1.000016] [G loss: 1.000099]\n",
      "epoch:33 step:158700[D loss: 0.999935] [G loss: 1.000068]\n",
      "epoch:33 step:158705[D loss: 0.999956] [G loss: 1.000095]\n",
      "epoch:33 step:158710[D loss: 1.000059] [G loss: 1.000124]\n",
      "epoch:33 step:158715[D loss: 0.999971] [G loss: 0.999987]\n",
      "epoch:33 step:158720[D loss: 0.999923] [G loss: 1.000054]\n",
      "epoch:33 step:158725[D loss: 0.999911] [G loss: 1.000124]\n",
      "epoch:33 step:158730[D loss: 0.999986] [G loss: 1.000107]\n",
      "epoch:33 step:158735[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:33 step:158740[D loss: 0.999974] [G loss: 1.000036]\n",
      "epoch:33 step:158745[D loss: 0.999983] [G loss: 1.000042]\n",
      "epoch:33 step:158750[D loss: 1.000053] [G loss: 0.999984]\n",
      "epoch:33 step:158755[D loss: 0.999976] [G loss: 1.000055]\n",
      "epoch:33 step:158760[D loss: 0.999999] [G loss: 1.000064]\n",
      "epoch:33 step:158765[D loss: 1.000059] [G loss: 1.000039]\n",
      "epoch:33 step:158770[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:33 step:158775[D loss: 1.000023] [G loss: 1.000146]\n",
      "epoch:33 step:158780[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:33 step:158785[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:33 step:158790[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:33 step:158795[D loss: 0.999986] [G loss: 1.000076]\n",
      "epoch:33 step:158800[D loss: 1.000005] [G loss: 1.000079]\n",
      "epoch:33 step:158805[D loss: 0.999971] [G loss: 1.000026]\n",
      "epoch:33 step:158810[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:33 step:158815[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:33 step:158820[D loss: 1.000029] [G loss: 0.999983]\n",
      "epoch:33 step:158825[D loss: 0.999962] [G loss: 1.000141]\n",
      "epoch:33 step:158830[D loss: 0.999998] [G loss: 1.000043]\n",
      "epoch:33 step:158835[D loss: 1.000014] [G loss: 0.999948]\n",
      "epoch:33 step:158840[D loss: 0.999925] [G loss: 1.000099]\n",
      "epoch:33 step:158845[D loss: 0.999965] [G loss: 1.000068]\n",
      "epoch:33 step:158850[D loss: 0.999964] [G loss: 1.000159]\n",
      "epoch:33 step:158855[D loss: 0.999971] [G loss: 1.000071]\n",
      "epoch:33 step:158860[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:33 step:158865[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:33 step:158870[D loss: 1.000023] [G loss: 1.000003]\n",
      "epoch:33 step:158875[D loss: 0.999954] [G loss: 1.000065]\n",
      "epoch:33 step:158880[D loss: 0.999959] [G loss: 1.000059]\n",
      "epoch:33 step:158885[D loss: 1.000129] [G loss: 0.999908]\n",
      "epoch:33 step:158890[D loss: 0.999966] [G loss: 1.000039]\n",
      "epoch:33 step:158895[D loss: 0.999928] [G loss: 1.000146]\n",
      "epoch:33 step:158900[D loss: 1.000043] [G loss: 1.000068]\n",
      "epoch:33 step:158905[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:33 step:158910[D loss: 0.999973] [G loss: 1.000019]\n",
      "epoch:33 step:158915[D loss: 1.000010] [G loss: 1.000039]\n",
      "epoch:33 step:158920[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:33 step:158925[D loss: 1.000016] [G loss: 1.000080]\n",
      "epoch:33 step:158930[D loss: 0.999932] [G loss: 1.000084]\n",
      "epoch:33 step:158935[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:33 step:158940[D loss: 1.000017] [G loss: 1.000020]\n",
      "epoch:33 step:158945[D loss: 1.000022] [G loss: 1.000010]\n",
      "epoch:33 step:158950[D loss: 1.000011] [G loss: 1.000017]\n",
      "epoch:33 step:158955[D loss: 1.000033] [G loss: 1.000004]\n",
      "epoch:33 step:158960[D loss: 1.000017] [G loss: 0.999978]\n",
      "epoch:33 step:158965[D loss: 1.000031] [G loss: 1.000011]\n",
      "epoch:33 step:158970[D loss: 0.999910] [G loss: 1.000088]\n",
      "epoch:33 step:158975[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:33 step:158980[D loss: 1.000001] [G loss: 1.000053]\n",
      "epoch:33 step:158985[D loss: 1.000053] [G loss: 1.000022]\n",
      "epoch:33 step:158990[D loss: 0.999892] [G loss: 1.000097]\n",
      "epoch:33 step:158995[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:33 step:159000[D loss: 0.999964] [G loss: 1.000052]\n",
      "epoch:33 step:159005[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:33 step:159010[D loss: 0.999989] [G loss: 1.000039]\n",
      "epoch:33 step:159015[D loss: 0.999981] [G loss: 1.000042]\n",
      "epoch:33 step:159020[D loss: 0.999984] [G loss: 1.000057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:159025[D loss: 0.999988] [G loss: 1.000020]\n",
      "epoch:33 step:159030[D loss: 0.999950] [G loss: 1.000209]\n",
      "epoch:33 step:159035[D loss: 0.999854] [G loss: 1.000268]\n",
      "epoch:33 step:159040[D loss: 0.999896] [G loss: 1.000157]\n",
      "epoch:33 step:159045[D loss: 0.999899] [G loss: 1.000145]\n",
      "epoch:33 step:159050[D loss: 0.999961] [G loss: 1.000172]\n",
      "epoch:33 step:159055[D loss: 0.999981] [G loss: 1.000044]\n",
      "epoch:33 step:159060[D loss: 1.000011] [G loss: 1.000025]\n",
      "epoch:33 step:159065[D loss: 0.999951] [G loss: 1.000057]\n",
      "epoch:33 step:159070[D loss: 0.999972] [G loss: 1.000074]\n",
      "epoch:33 step:159075[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:33 step:159080[D loss: 0.999971] [G loss: 1.000038]\n",
      "epoch:33 step:159085[D loss: 1.000061] [G loss: 0.999931]\n",
      "epoch:33 step:159090[D loss: 0.999985] [G loss: 1.000005]\n",
      "epoch:33 step:159095[D loss: 0.999979] [G loss: 1.000005]\n",
      "epoch:33 step:159100[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:33 step:159105[D loss: 0.999952] [G loss: 1.000077]\n",
      "epoch:33 step:159110[D loss: 1.000095] [G loss: 0.999975]\n",
      "epoch:33 step:159115[D loss: 0.999996] [G loss: 0.999990]\n",
      "epoch:33 step:159120[D loss: 0.999970] [G loss: 1.000041]\n",
      "epoch:33 step:159125[D loss: 1.000023] [G loss: 1.000051]\n",
      "epoch:33 step:159130[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:33 step:159135[D loss: 1.000116] [G loss: 0.999949]\n",
      "epoch:33 step:159140[D loss: 0.999909] [G loss: 1.000059]\n",
      "epoch:33 step:159145[D loss: 0.999994] [G loss: 0.999995]\n",
      "epoch:33 step:159150[D loss: 0.999998] [G loss: 0.999972]\n",
      "epoch:33 step:159155[D loss: 1.000073] [G loss: 0.999783]\n",
      "epoch:33 step:159160[D loss: 0.999933] [G loss: 1.000037]\n",
      "epoch:33 step:159165[D loss: 0.999960] [G loss: 1.000030]\n",
      "epoch:33 step:159170[D loss: 0.999955] [G loss: 1.000067]\n",
      "epoch:33 step:159175[D loss: 1.000028] [G loss: 1.000011]\n",
      "epoch:33 step:159180[D loss: 1.000030] [G loss: 1.000038]\n",
      "epoch:33 step:159185[D loss: 1.000039] [G loss: 0.999976]\n",
      "epoch:33 step:159190[D loss: 1.000016] [G loss: 1.000168]\n",
      "epoch:33 step:159195[D loss: 0.999922] [G loss: 1.000063]\n",
      "epoch:33 step:159200[D loss: 0.999988] [G loss: 1.000017]\n",
      "epoch:33 step:159205[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:33 step:159210[D loss: 1.000014] [G loss: 1.000011]\n",
      "epoch:33 step:159215[D loss: 0.999993] [G loss: 1.000050]\n",
      "epoch:33 step:159220[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:33 step:159225[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:33 step:159230[D loss: 0.999951] [G loss: 1.000100]\n",
      "epoch:33 step:159235[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:33 step:159240[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:33 step:159245[D loss: 0.999995] [G loss: 1.000031]\n",
      "epoch:33 step:159250[D loss: 0.999975] [G loss: 1.000020]\n",
      "epoch:33 step:159255[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:33 step:159260[D loss: 0.999963] [G loss: 1.000050]\n",
      "epoch:33 step:159265[D loss: 0.999985] [G loss: 1.000018]\n",
      "epoch:33 step:159270[D loss: 0.999960] [G loss: 1.000098]\n",
      "epoch:33 step:159275[D loss: 0.999961] [G loss: 1.000085]\n",
      "epoch:33 step:159280[D loss: 1.000003] [G loss: 1.000069]\n",
      "epoch:33 step:159285[D loss: 0.999931] [G loss: 1.000106]\n",
      "epoch:33 step:159290[D loss: 1.000013] [G loss: 1.000002]\n",
      "epoch:34 step:159295[D loss: 0.999990] [G loss: 1.000078]\n",
      "epoch:34 step:159300[D loss: 0.999998] [G loss: 1.000026]\n",
      "epoch:34 step:159305[D loss: 0.999954] [G loss: 1.000082]\n",
      "epoch:34 step:159310[D loss: 1.000013] [G loss: 0.999989]\n",
      "epoch:34 step:159315[D loss: 0.999944] [G loss: 1.000092]\n",
      "epoch:34 step:159320[D loss: 0.999978] [G loss: 1.000076]\n",
      "epoch:34 step:159325[D loss: 1.000003] [G loss: 1.000018]\n",
      "epoch:34 step:159330[D loss: 1.000010] [G loss: 1.000005]\n",
      "epoch:34 step:159335[D loss: 0.999967] [G loss: 1.000087]\n",
      "epoch:34 step:159340[D loss: 1.000011] [G loss: 1.000072]\n",
      "epoch:34 step:159345[D loss: 1.000083] [G loss: 0.999878]\n",
      "epoch:34 step:159350[D loss: 0.999891] [G loss: 1.000109]\n",
      "epoch:34 step:159355[D loss: 0.999943] [G loss: 1.000088]\n",
      "epoch:34 step:159360[D loss: 0.999971] [G loss: 1.000059]\n",
      "epoch:34 step:159365[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:34 step:159370[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:34 step:159375[D loss: 0.999948] [G loss: 1.000099]\n",
      "epoch:34 step:159380[D loss: 0.999976] [G loss: 1.000039]\n",
      "epoch:34 step:159385[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:34 step:159390[D loss: 0.999968] [G loss: 1.000088]\n",
      "epoch:34 step:159395[D loss: 0.999973] [G loss: 1.000079]\n",
      "epoch:34 step:159400[D loss: 0.999964] [G loss: 1.000134]\n",
      "epoch:34 step:159405[D loss: 0.999896] [G loss: 1.000131]\n",
      "epoch:34 step:159410[D loss: 0.999884] [G loss: 1.000334]\n",
      "epoch:34 step:159415[D loss: 0.999987] [G loss: 1.000078]\n",
      "epoch:34 step:159420[D loss: 0.999978] [G loss: 1.000162]\n",
      "epoch:34 step:159425[D loss: 1.000149] [G loss: 0.999924]\n",
      "epoch:34 step:159430[D loss: 0.999918] [G loss: 1.000111]\n",
      "epoch:34 step:159435[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:34 step:159440[D loss: 1.000079] [G loss: 0.999896]\n",
      "epoch:34 step:159445[D loss: 0.999837] [G loss: 1.000072]\n",
      "epoch:34 step:159450[D loss: 0.999959] [G loss: 1.000046]\n",
      "epoch:34 step:159455[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:34 step:159460[D loss: 1.000005] [G loss: 1.000058]\n",
      "epoch:34 step:159465[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:34 step:159470[D loss: 1.000054] [G loss: 1.000017]\n",
      "epoch:34 step:159475[D loss: 0.999983] [G loss: 1.000109]\n",
      "epoch:34 step:159480[D loss: 0.999951] [G loss: 1.000107]\n",
      "epoch:34 step:159485[D loss: 1.000012] [G loss: 0.999965]\n",
      "epoch:34 step:159490[D loss: 1.000087] [G loss: 0.999881]\n",
      "epoch:34 step:159495[D loss: 1.000049] [G loss: 0.999953]\n",
      "epoch:34 step:159500[D loss: 1.000022] [G loss: 0.999973]\n",
      "epoch:34 step:159505[D loss: 0.999948] [G loss: 1.000133]\n",
      "epoch:34 step:159510[D loss: 0.999956] [G loss: 1.000032]\n",
      "epoch:34 step:159515[D loss: 1.000018] [G loss: 1.000001]\n",
      "epoch:34 step:159520[D loss: 1.000011] [G loss: 0.999961]\n",
      "epoch:34 step:159525[D loss: 0.999924] [G loss: 1.000124]\n",
      "epoch:34 step:159530[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:34 step:159535[D loss: 0.999968] [G loss: 1.000086]\n",
      "epoch:34 step:159540[D loss: 0.999959] [G loss: 1.000095]\n",
      "epoch:34 step:159545[D loss: 0.999995] [G loss: 1.000040]\n",
      "epoch:34 step:159550[D loss: 0.999955] [G loss: 1.000107]\n",
      "epoch:34 step:159555[D loss: 0.999968] [G loss: 1.000064]\n",
      "epoch:34 step:159560[D loss: 1.000008] [G loss: 1.000018]\n",
      "epoch:34 step:159565[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:34 step:159570[D loss: 0.999977] [G loss: 1.000085]\n",
      "epoch:34 step:159575[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:34 step:159580[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:34 step:159585[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:34 step:159590[D loss: 0.999988] [G loss: 1.000057]\n",
      "epoch:34 step:159595[D loss: 0.999936] [G loss: 1.000064]\n",
      "epoch:34 step:159600[D loss: 0.999990] [G loss: 1.000040]\n",
      "epoch:34 step:159605[D loss: 1.000061] [G loss: 0.999927]\n",
      "epoch:34 step:159610[D loss: 1.000053] [G loss: 1.000025]\n",
      "epoch:34 step:159615[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:34 step:159620[D loss: 0.999949] [G loss: 1.000078]\n",
      "epoch:34 step:159625[D loss: 0.999991] [G loss: 1.000037]\n",
      "epoch:34 step:159630[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:34 step:159635[D loss: 1.000070] [G loss: 1.000046]\n",
      "epoch:34 step:159640[D loss: 1.000110] [G loss: 0.999952]\n",
      "epoch:34 step:159645[D loss: 1.000021] [G loss: 1.000116]\n",
      "epoch:34 step:159650[D loss: 0.999942] [G loss: 1.000265]\n",
      "epoch:34 step:159655[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:34 step:159660[D loss: 1.000065] [G loss: 0.999920]\n",
      "epoch:34 step:159665[D loss: 1.000023] [G loss: 1.000004]\n",
      "epoch:34 step:159670[D loss: 0.999972] [G loss: 0.999984]\n",
      "epoch:34 step:159675[D loss: 0.999964] [G loss: 1.000254]\n",
      "epoch:34 step:159680[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:34 step:159685[D loss: 0.999952] [G loss: 1.000170]\n",
      "epoch:34 step:159690[D loss: 0.999967] [G loss: 1.000054]\n",
      "epoch:34 step:159695[D loss: 0.999984] [G loss: 1.000133]\n",
      "epoch:34 step:159700[D loss: 0.999966] [G loss: 1.000046]\n",
      "epoch:34 step:159705[D loss: 0.999998] [G loss: 0.999959]\n",
      "epoch:34 step:159710[D loss: 1.000030] [G loss: 0.999974]\n",
      "epoch:34 step:159715[D loss: 1.000050] [G loss: 0.999965]\n",
      "epoch:34 step:159720[D loss: 0.999862] [G loss: 1.000171]\n",
      "epoch:34 step:159725[D loss: 1.000088] [G loss: 0.999937]\n",
      "epoch:34 step:159730[D loss: 1.000007] [G loss: 1.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:159735[D loss: 1.000022] [G loss: 1.000111]\n",
      "epoch:34 step:159740[D loss: 0.999932] [G loss: 1.000163]\n",
      "epoch:34 step:159745[D loss: 0.999979] [G loss: 1.000064]\n",
      "epoch:34 step:159750[D loss: 1.000020] [G loss: 0.999998]\n",
      "epoch:34 step:159755[D loss: 0.999997] [G loss: 1.000084]\n",
      "epoch:34 step:159760[D loss: 1.000137] [G loss: 0.999851]\n",
      "epoch:34 step:159765[D loss: 1.000185] [G loss: 0.999845]\n",
      "epoch:34 step:159770[D loss: 0.999951] [G loss: 1.000274]\n",
      "epoch:34 step:159775[D loss: 0.999813] [G loss: 1.000395]\n",
      "epoch:34 step:159780[D loss: 0.999989] [G loss: 1.000167]\n",
      "epoch:34 step:159785[D loss: 0.999963] [G loss: 1.000146]\n",
      "epoch:34 step:159790[D loss: 0.999955] [G loss: 1.000131]\n",
      "epoch:34 step:159795[D loss: 0.999981] [G loss: 1.000086]\n",
      "epoch:34 step:159800[D loss: 0.999970] [G loss: 1.000073]\n",
      "epoch:34 step:159805[D loss: 1.000024] [G loss: 0.999944]\n",
      "epoch:34 step:159810[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:34 step:159815[D loss: 1.000085] [G loss: 0.999920]\n",
      "epoch:34 step:159820[D loss: 1.000088] [G loss: 0.999859]\n",
      "epoch:34 step:159825[D loss: 1.000071] [G loss: 1.000013]\n",
      "epoch:34 step:159830[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:34 step:159835[D loss: 0.999681] [G loss: 1.000304]\n",
      "epoch:34 step:159840[D loss: 0.999811] [G loss: 1.000370]\n",
      "epoch:34 step:159845[D loss: 0.999993] [G loss: 1.000051]\n",
      "epoch:34 step:159850[D loss: 0.999922] [G loss: 1.000174]\n",
      "epoch:34 step:159855[D loss: 1.000002] [G loss: 1.000046]\n",
      "epoch:34 step:159860[D loss: 0.999942] [G loss: 1.000143]\n",
      "epoch:34 step:159865[D loss: 0.999925] [G loss: 1.000147]\n",
      "epoch:34 step:159870[D loss: 1.000014] [G loss: 1.000065]\n",
      "epoch:34 step:159875[D loss: 1.000251] [G loss: 0.999862]\n",
      "epoch:34 step:159880[D loss: 1.000140] [G loss: 0.999954]\n",
      "epoch:34 step:159885[D loss: 1.000214] [G loss: 0.999919]\n",
      "epoch:34 step:159890[D loss: 0.999785] [G loss: 1.000188]\n",
      "epoch:34 step:159895[D loss: 1.000000] [G loss: 1.000117]\n",
      "epoch:34 step:159900[D loss: 0.999846] [G loss: 1.000306]\n",
      "epoch:34 step:159905[D loss: 0.999982] [G loss: 1.000238]\n",
      "epoch:34 step:159910[D loss: 0.999944] [G loss: 1.000225]\n",
      "epoch:34 step:159915[D loss: 1.000009] [G loss: 1.000025]\n",
      "epoch:34 step:159920[D loss: 0.999939] [G loss: 1.000033]\n",
      "epoch:34 step:159925[D loss: 0.999997] [G loss: 1.000038]\n",
      "epoch:34 step:159930[D loss: 1.000012] [G loss: 1.000006]\n",
      "epoch:34 step:159935[D loss: 1.000034] [G loss: 1.000078]\n",
      "epoch:34 step:159940[D loss: 0.999932] [G loss: 1.000063]\n",
      "epoch:34 step:159945[D loss: 0.999959] [G loss: 1.000062]\n",
      "epoch:34 step:159950[D loss: 0.999979] [G loss: 1.000086]\n",
      "epoch:34 step:159955[D loss: 1.000059] [G loss: 0.999965]\n",
      "epoch:34 step:159960[D loss: 1.000067] [G loss: 0.999939]\n",
      "epoch:34 step:159965[D loss: 0.999969] [G loss: 1.000100]\n",
      "epoch:34 step:159970[D loss: 0.999933] [G loss: 1.000074]\n",
      "epoch:34 step:159975[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:34 step:159980[D loss: 0.999986] [G loss: 1.000019]\n",
      "epoch:34 step:159985[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:34 step:159990[D loss: 0.999971] [G loss: 1.000045]\n",
      "epoch:34 step:159995[D loss: 1.000038] [G loss: 1.000019]\n",
      "epoch:34 step:160000[D loss: 1.000088] [G loss: 0.999921]\n",
      "epoch:34 step:160005[D loss: 0.999879] [G loss: 1.000161]\n",
      "epoch:34 step:160010[D loss: 0.999914] [G loss: 1.000151]\n",
      "epoch:34 step:160015[D loss: 0.999967] [G loss: 1.000156]\n",
      "epoch:34 step:160020[D loss: 0.999972] [G loss: 1.000043]\n",
      "epoch:34 step:160025[D loss: 0.999991] [G loss: 1.000117]\n",
      "epoch:34 step:160030[D loss: 0.999993] [G loss: 1.000064]\n",
      "epoch:34 step:160035[D loss: 1.000013] [G loss: 0.999966]\n",
      "epoch:34 step:160040[D loss: 1.000006] [G loss: 0.999986]\n",
      "epoch:34 step:160045[D loss: 0.999999] [G loss: 0.999977]\n",
      "epoch:34 step:160050[D loss: 0.999972] [G loss: 1.000056]\n",
      "epoch:34 step:160055[D loss: 0.999981] [G loss: 1.000035]\n",
      "epoch:34 step:160060[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:34 step:160065[D loss: 0.999974] [G loss: 1.000089]\n",
      "epoch:34 step:160070[D loss: 0.999962] [G loss: 1.000107]\n",
      "epoch:34 step:160075[D loss: 0.999960] [G loss: 1.000053]\n",
      "epoch:34 step:160080[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:34 step:160085[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:34 step:160090[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:34 step:160095[D loss: 1.000006] [G loss: 0.999985]\n",
      "epoch:34 step:160100[D loss: 1.000096] [G loss: 0.999940]\n",
      "epoch:34 step:160105[D loss: 0.999876] [G loss: 1.000152]\n",
      "epoch:34 step:160110[D loss: 0.999957] [G loss: 1.000074]\n",
      "epoch:34 step:160115[D loss: 0.999993] [G loss: 1.000074]\n",
      "epoch:34 step:160120[D loss: 1.000031] [G loss: 0.999972]\n",
      "epoch:34 step:160125[D loss: 1.000005] [G loss: 1.000003]\n",
      "epoch:34 step:160130[D loss: 0.999977] [G loss: 1.000048]\n",
      "epoch:34 step:160135[D loss: 0.999968] [G loss: 1.000073]\n",
      "epoch:34 step:160140[D loss: 1.000018] [G loss: 0.999980]\n",
      "epoch:34 step:160145[D loss: 0.999983] [G loss: 1.000052]\n",
      "epoch:34 step:160150[D loss: 0.999970] [G loss: 1.000053]\n",
      "epoch:34 step:160155[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:34 step:160160[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:34 step:160165[D loss: 0.999976] [G loss: 1.000023]\n",
      "epoch:34 step:160170[D loss: 1.000004] [G loss: 1.000017]\n",
      "epoch:34 step:160175[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:34 step:160180[D loss: 1.000043] [G loss: 0.999982]\n",
      "epoch:34 step:160185[D loss: 1.000066] [G loss: 0.999941]\n",
      "epoch:34 step:160190[D loss: 0.999994] [G loss: 1.000000]\n",
      "epoch:34 step:160195[D loss: 0.999993] [G loss: 1.000056]\n",
      "epoch:34 step:160200[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:34 step:160205[D loss: 0.999969] [G loss: 1.000093]\n",
      "epoch:34 step:160210[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:34 step:160215[D loss: 1.000045] [G loss: 0.999976]\n",
      "epoch:34 step:160220[D loss: 0.999992] [G loss: 1.000020]\n",
      "epoch:34 step:160225[D loss: 0.999985] [G loss: 1.000013]\n",
      "epoch:34 step:160230[D loss: 0.999952] [G loss: 1.000124]\n",
      "epoch:34 step:160235[D loss: 0.999985] [G loss: 1.000073]\n",
      "epoch:34 step:160240[D loss: 0.999967] [G loss: 1.000042]\n",
      "epoch:34 step:160245[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:34 step:160250[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:34 step:160255[D loss: 1.000058] [G loss: 0.999963]\n",
      "epoch:34 step:160260[D loss: 1.000049] [G loss: 1.000014]\n",
      "epoch:34 step:160265[D loss: 1.000020] [G loss: 1.000073]\n",
      "epoch:34 step:160270[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:34 step:160275[D loss: 0.999971] [G loss: 1.000138]\n",
      "epoch:34 step:160280[D loss: 1.000177] [G loss: 0.999950]\n",
      "epoch:34 step:160285[D loss: 0.999877] [G loss: 1.000178]\n",
      "epoch:34 step:160290[D loss: 1.000019] [G loss: 1.000283]\n",
      "epoch:34 step:160295[D loss: 0.999864] [G loss: 1.000287]\n",
      "epoch:34 step:160300[D loss: 0.999953] [G loss: 1.000120]\n",
      "epoch:34 step:160305[D loss: 0.999966] [G loss: 1.000050]\n",
      "epoch:34 step:160310[D loss: 1.000037] [G loss: 0.999932]\n",
      "epoch:34 step:160315[D loss: 1.000050] [G loss: 0.999884]\n",
      "epoch:34 step:160320[D loss: 1.000068] [G loss: 1.000009]\n",
      "epoch:34 step:160325[D loss: 0.999920] [G loss: 1.000070]\n",
      "epoch:34 step:160330[D loss: 0.999932] [G loss: 1.000044]\n",
      "epoch:34 step:160335[D loss: 1.000064] [G loss: 1.000021]\n",
      "epoch:34 step:160340[D loss: 0.999965] [G loss: 1.000013]\n",
      "epoch:34 step:160345[D loss: 0.999902] [G loss: 1.000127]\n",
      "epoch:34 step:160350[D loss: 0.999967] [G loss: 1.000135]\n",
      "epoch:34 step:160355[D loss: 1.000064] [G loss: 0.999968]\n",
      "epoch:34 step:160360[D loss: 1.000016] [G loss: 1.000114]\n",
      "epoch:34 step:160365[D loss: 0.999910] [G loss: 1.000181]\n",
      "epoch:34 step:160370[D loss: 0.999948] [G loss: 1.000124]\n",
      "epoch:34 step:160375[D loss: 1.000042] [G loss: 1.000193]\n",
      "epoch:34 step:160380[D loss: 0.999954] [G loss: 1.000117]\n",
      "epoch:34 step:160385[D loss: 0.999973] [G loss: 1.000042]\n",
      "epoch:34 step:160390[D loss: 1.000041] [G loss: 1.000016]\n",
      "epoch:34 step:160395[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:34 step:160400[D loss: 1.000016] [G loss: 1.000023]\n",
      "epoch:34 step:160405[D loss: 1.000131] [G loss: 0.999949]\n",
      "epoch:34 step:160410[D loss: 0.999971] [G loss: 0.999963]\n",
      "epoch:34 step:160415[D loss: 1.000140] [G loss: 0.999938]\n",
      "epoch:34 step:160420[D loss: 0.999946] [G loss: 1.000438]\n",
      "epoch:34 step:160425[D loss: 0.999956] [G loss: 1.000336]\n",
      "epoch:34 step:160430[D loss: 0.999734] [G loss: 1.000360]\n",
      "epoch:34 step:160435[D loss: 0.999935] [G loss: 1.000096]\n",
      "epoch:34 step:160440[D loss: 1.000103] [G loss: 1.000005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:160445[D loss: 0.999941] [G loss: 1.000133]\n",
      "epoch:34 step:160450[D loss: 0.999948] [G loss: 1.000099]\n",
      "epoch:34 step:160455[D loss: 0.999979] [G loss: 1.000100]\n",
      "epoch:34 step:160460[D loss: 1.000031] [G loss: 1.000075]\n",
      "epoch:34 step:160465[D loss: 0.999813] [G loss: 1.000346]\n",
      "epoch:34 step:160470[D loss: 0.999950] [G loss: 1.000150]\n",
      "epoch:34 step:160475[D loss: 0.999960] [G loss: 1.000134]\n",
      "epoch:34 step:160480[D loss: 1.000030] [G loss: 0.999944]\n",
      "epoch:34 step:160485[D loss: 1.000010] [G loss: 1.000084]\n",
      "epoch:34 step:160490[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:34 step:160495[D loss: 1.000134] [G loss: 0.999966]\n",
      "epoch:34 step:160500[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:34 step:160505[D loss: 0.999921] [G loss: 1.000128]\n",
      "epoch:34 step:160510[D loss: 0.999993] [G loss: 1.000171]\n",
      "epoch:34 step:160515[D loss: 0.999946] [G loss: 1.000151]\n",
      "epoch:34 step:160520[D loss: 0.999953] [G loss: 1.000130]\n",
      "epoch:34 step:160525[D loss: 1.000081] [G loss: 0.999963]\n",
      "epoch:34 step:160530[D loss: 1.000016] [G loss: 1.000038]\n",
      "epoch:34 step:160535[D loss: 0.999926] [G loss: 1.000065]\n",
      "epoch:34 step:160540[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:34 step:160545[D loss: 0.999902] [G loss: 1.000167]\n",
      "epoch:34 step:160550[D loss: 0.999948] [G loss: 1.000084]\n",
      "epoch:34 step:160555[D loss: 1.000068] [G loss: 1.000072]\n",
      "epoch:34 step:160560[D loss: 0.999958] [G loss: 1.000230]\n",
      "epoch:34 step:160565[D loss: 0.999994] [G loss: 1.000093]\n",
      "epoch:34 step:160570[D loss: 1.000042] [G loss: 0.999940]\n",
      "epoch:34 step:160575[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:34 step:160580[D loss: 0.999912] [G loss: 1.000051]\n",
      "epoch:34 step:160585[D loss: 1.000010] [G loss: 1.000000]\n",
      "epoch:34 step:160590[D loss: 0.999990] [G loss: 1.000030]\n",
      "epoch:34 step:160595[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:34 step:160600[D loss: 0.999947] [G loss: 1.000115]\n",
      "epoch:34 step:160605[D loss: 0.999960] [G loss: 1.000195]\n",
      "epoch:34 step:160610[D loss: 0.999956] [G loss: 1.000186]\n",
      "epoch:34 step:160615[D loss: 0.999951] [G loss: 1.000072]\n",
      "epoch:34 step:160620[D loss: 0.999993] [G loss: 1.000123]\n",
      "epoch:34 step:160625[D loss: 0.999976] [G loss: 1.000060]\n",
      "epoch:34 step:160630[D loss: 0.999996] [G loss: 1.000023]\n",
      "epoch:34 step:160635[D loss: 1.000043] [G loss: 0.999915]\n",
      "epoch:34 step:160640[D loss: 1.000005] [G loss: 1.000124]\n",
      "epoch:34 step:160645[D loss: 0.999899] [G loss: 1.000297]\n",
      "epoch:34 step:160650[D loss: 0.999967] [G loss: 1.000097]\n",
      "epoch:34 step:160655[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:34 step:160660[D loss: 0.999965] [G loss: 1.000022]\n",
      "epoch:34 step:160665[D loss: 1.000017] [G loss: 1.000037]\n",
      "epoch:34 step:160670[D loss: 0.999968] [G loss: 1.000103]\n",
      "epoch:34 step:160675[D loss: 0.999998] [G loss: 1.000035]\n",
      "epoch:34 step:160680[D loss: 0.999977] [G loss: 1.000110]\n",
      "epoch:34 step:160685[D loss: 0.999942] [G loss: 1.000140]\n",
      "epoch:34 step:160690[D loss: 0.999948] [G loss: 1.000121]\n",
      "epoch:34 step:160695[D loss: 0.999974] [G loss: 1.000100]\n",
      "epoch:34 step:160700[D loss: 0.999999] [G loss: 1.000037]\n",
      "epoch:34 step:160705[D loss: 0.999958] [G loss: 1.000099]\n",
      "epoch:34 step:160710[D loss: 1.000009] [G loss: 1.000114]\n",
      "epoch:34 step:160715[D loss: 1.000063] [G loss: 0.999967]\n",
      "epoch:34 step:160720[D loss: 0.999927] [G loss: 1.000093]\n",
      "epoch:34 step:160725[D loss: 1.000004] [G loss: 1.000032]\n",
      "epoch:34 step:160730[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:34 step:160735[D loss: 0.999977] [G loss: 1.000100]\n",
      "epoch:34 step:160740[D loss: 0.999988] [G loss: 1.000000]\n",
      "epoch:34 step:160745[D loss: 0.999941] [G loss: 1.000142]\n",
      "epoch:34 step:160750[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:34 step:160755[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:34 step:160760[D loss: 0.999879] [G loss: 1.000114]\n",
      "epoch:34 step:160765[D loss: 1.000117] [G loss: 0.999894]\n",
      "epoch:34 step:160770[D loss: 1.000045] [G loss: 0.999955]\n",
      "epoch:34 step:160775[D loss: 0.999868] [G loss: 1.000162]\n",
      "epoch:34 step:160780[D loss: 0.999954] [G loss: 1.000153]\n",
      "epoch:34 step:160785[D loss: 0.999946] [G loss: 1.000124]\n",
      "epoch:34 step:160790[D loss: 0.999997] [G loss: 1.000013]\n",
      "epoch:34 step:160795[D loss: 0.999956] [G loss: 1.000093]\n",
      "epoch:34 step:160800[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:34 step:160805[D loss: 1.000040] [G loss: 0.999974]\n",
      "epoch:34 step:160810[D loss: 0.999896] [G loss: 1.000087]\n",
      "epoch:34 step:160815[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:34 step:160820[D loss: 1.000020] [G loss: 1.000004]\n",
      "epoch:34 step:160825[D loss: 1.000014] [G loss: 1.000081]\n",
      "epoch:34 step:160830[D loss: 0.999975] [G loss: 1.000054]\n",
      "epoch:34 step:160835[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:34 step:160840[D loss: 0.999997] [G loss: 1.000069]\n",
      "epoch:34 step:160845[D loss: 0.999981] [G loss: 1.000139]\n",
      "epoch:34 step:160850[D loss: 0.999973] [G loss: 1.000117]\n",
      "epoch:34 step:160855[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:34 step:160860[D loss: 0.999885] [G loss: 1.000179]\n",
      "epoch:34 step:160865[D loss: 0.999982] [G loss: 1.000188]\n",
      "epoch:34 step:160870[D loss: 1.000073] [G loss: 1.000089]\n",
      "epoch:34 step:160875[D loss: 0.999954] [G loss: 1.000032]\n",
      "epoch:34 step:160880[D loss: 0.999987] [G loss: 1.000080]\n",
      "epoch:34 step:160885[D loss: 1.000030] [G loss: 0.999874]\n",
      "epoch:34 step:160890[D loss: 1.000015] [G loss: 0.999910]\n",
      "epoch:34 step:160895[D loss: 1.000262] [G loss: 0.999722]\n",
      "epoch:34 step:160900[D loss: 1.000090] [G loss: 0.999949]\n",
      "epoch:34 step:160905[D loss: 1.000183] [G loss: 0.999788]\n",
      "epoch:34 step:160910[D loss: 0.999913] [G loss: 0.999986]\n",
      "epoch:34 step:160915[D loss: 0.999899] [G loss: 1.000088]\n",
      "epoch:34 step:160920[D loss: 0.999954] [G loss: 1.000066]\n",
      "epoch:34 step:160925[D loss: 1.000048] [G loss: 1.000006]\n",
      "epoch:34 step:160930[D loss: 0.999902] [G loss: 1.000051]\n",
      "epoch:34 step:160935[D loss: 0.999981] [G loss: 1.000102]\n",
      "epoch:34 step:160940[D loss: 1.000017] [G loss: 1.000128]\n",
      "epoch:34 step:160945[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:34 step:160950[D loss: 0.999983] [G loss: 1.000087]\n",
      "epoch:34 step:160955[D loss: 0.999982] [G loss: 1.000013]\n",
      "epoch:34 step:160960[D loss: 0.999973] [G loss: 1.000073]\n",
      "epoch:34 step:160965[D loss: 0.999927] [G loss: 1.000114]\n",
      "epoch:34 step:160970[D loss: 0.999972] [G loss: 1.000067]\n",
      "epoch:34 step:160975[D loss: 0.999984] [G loss: 1.000016]\n",
      "epoch:34 step:160980[D loss: 1.000019] [G loss: 1.000014]\n",
      "epoch:34 step:160985[D loss: 0.999996] [G loss: 1.000052]\n",
      "epoch:34 step:160990[D loss: 0.999966] [G loss: 1.000043]\n",
      "epoch:34 step:160995[D loss: 1.000003] [G loss: 0.999986]\n",
      "epoch:34 step:161000[D loss: 0.999990] [G loss: 1.000062]\n",
      "epoch:34 step:161005[D loss: 0.999967] [G loss: 1.000092]\n",
      "epoch:34 step:161010[D loss: 1.000054] [G loss: 0.999959]\n",
      "epoch:34 step:161015[D loss: 0.999951] [G loss: 1.000085]\n",
      "epoch:34 step:161020[D loss: 1.000040] [G loss: 1.000068]\n",
      "epoch:34 step:161025[D loss: 0.999941] [G loss: 1.000046]\n",
      "epoch:34 step:161030[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:34 step:161035[D loss: 1.000008] [G loss: 1.000055]\n",
      "epoch:34 step:161040[D loss: 0.999966] [G loss: 1.000057]\n",
      "epoch:34 step:161045[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:34 step:161050[D loss: 0.999935] [G loss: 1.000121]\n",
      "epoch:34 step:161055[D loss: 0.999949] [G loss: 1.000081]\n",
      "epoch:34 step:161060[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:34 step:161065[D loss: 1.000052] [G loss: 0.999944]\n",
      "epoch:34 step:161070[D loss: 0.999930] [G loss: 1.000068]\n",
      "epoch:34 step:161075[D loss: 0.999991] [G loss: 1.000008]\n",
      "epoch:34 step:161080[D loss: 1.000053] [G loss: 1.000086]\n",
      "epoch:34 step:161085[D loss: 0.999894] [G loss: 1.000132]\n",
      "epoch:34 step:161090[D loss: 1.000019] [G loss: 1.000087]\n",
      "epoch:34 step:161095[D loss: 0.999907] [G loss: 1.000124]\n",
      "epoch:34 step:161100[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:34 step:161105[D loss: 1.000089] [G loss: 0.999867]\n",
      "epoch:34 step:161110[D loss: 1.000074] [G loss: 1.000026]\n",
      "epoch:34 step:161115[D loss: 1.000032] [G loss: 1.000068]\n",
      "epoch:34 step:161120[D loss: 1.000033] [G loss: 1.000007]\n",
      "epoch:34 step:161125[D loss: 0.999965] [G loss: 1.000255]\n",
      "epoch:34 step:161130[D loss: 0.999972] [G loss: 1.000216]\n",
      "epoch:34 step:161135[D loss: 0.999933] [G loss: 1.000115]\n",
      "epoch:34 step:161140[D loss: 0.999997] [G loss: 1.000085]\n",
      "epoch:34 step:161145[D loss: 0.999998] [G loss: 1.000045]\n",
      "epoch:34 step:161150[D loss: 0.999969] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:161155[D loss: 1.000008] [G loss: 1.000062]\n",
      "epoch:34 step:161160[D loss: 0.999961] [G loss: 1.000127]\n",
      "epoch:34 step:161165[D loss: 0.999965] [G loss: 1.000072]\n",
      "epoch:34 step:161170[D loss: 1.000025] [G loss: 0.999999]\n",
      "epoch:34 step:161175[D loss: 1.000068] [G loss: 0.999959]\n",
      "epoch:34 step:161180[D loss: 1.000121] [G loss: 1.000046]\n",
      "epoch:34 step:161185[D loss: 0.999991] [G loss: 1.000069]\n",
      "epoch:34 step:161190[D loss: 0.999987] [G loss: 0.999927]\n",
      "epoch:34 step:161195[D loss: 0.999953] [G loss: 1.000065]\n",
      "epoch:34 step:161200[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:34 step:161205[D loss: 0.999974] [G loss: 1.000030]\n",
      "epoch:34 step:161210[D loss: 0.999936] [G loss: 1.000091]\n",
      "epoch:34 step:161215[D loss: 1.000073] [G loss: 1.000053]\n",
      "epoch:34 step:161220[D loss: 0.999926] [G loss: 1.000028]\n",
      "epoch:34 step:161225[D loss: 0.999984] [G loss: 1.000254]\n",
      "epoch:34 step:161230[D loss: 1.000022] [G loss: 1.000070]\n",
      "epoch:34 step:161235[D loss: 1.000008] [G loss: 0.999969]\n",
      "epoch:34 step:161240[D loss: 0.999952] [G loss: 1.000039]\n",
      "epoch:34 step:161245[D loss: 1.000022] [G loss: 0.999983]\n",
      "epoch:34 step:161250[D loss: 0.999964] [G loss: 1.000000]\n",
      "epoch:34 step:161255[D loss: 0.999983] [G loss: 0.999960]\n",
      "epoch:34 step:161260[D loss: 0.999982] [G loss: 1.000014]\n",
      "epoch:34 step:161265[D loss: 0.999993] [G loss: 1.000022]\n",
      "epoch:34 step:161270[D loss: 1.000004] [G loss: 1.000010]\n",
      "epoch:34 step:161275[D loss: 1.000143] [G loss: 0.999790]\n",
      "epoch:34 step:161280[D loss: 0.999873] [G loss: 1.000168]\n",
      "epoch:34 step:161285[D loss: 0.999930] [G loss: 1.000204]\n",
      "epoch:34 step:161290[D loss: 0.999981] [G loss: 1.000016]\n",
      "epoch:34 step:161295[D loss: 0.999983] [G loss: 1.000070]\n",
      "epoch:34 step:161300[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:34 step:161305[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:34 step:161310[D loss: 1.000054] [G loss: 1.000031]\n",
      "epoch:34 step:161315[D loss: 0.999956] [G loss: 1.000158]\n",
      "epoch:34 step:161320[D loss: 1.000078] [G loss: 0.999904]\n",
      "epoch:34 step:161325[D loss: 0.999995] [G loss: 1.000198]\n",
      "epoch:34 step:161330[D loss: 0.999947] [G loss: 1.000090]\n",
      "epoch:34 step:161335[D loss: 0.999958] [G loss: 1.000148]\n",
      "epoch:34 step:161340[D loss: 0.999945] [G loss: 1.000229]\n",
      "epoch:34 step:161345[D loss: 0.999937] [G loss: 1.000130]\n",
      "epoch:34 step:161350[D loss: 0.999984] [G loss: 1.000116]\n",
      "epoch:34 step:161355[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:34 step:161360[D loss: 1.000021] [G loss: 1.000027]\n",
      "epoch:34 step:161365[D loss: 0.999960] [G loss: 0.999927]\n",
      "epoch:34 step:161370[D loss: 0.999884] [G loss: 1.000159]\n",
      "epoch:34 step:161375[D loss: 0.999971] [G loss: 1.000078]\n",
      "epoch:34 step:161380[D loss: 0.999910] [G loss: 1.000103]\n",
      "epoch:34 step:161385[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:34 step:161390[D loss: 0.999989] [G loss: 1.000018]\n",
      "epoch:34 step:161395[D loss: 1.000020] [G loss: 1.000039]\n",
      "epoch:34 step:161400[D loss: 0.999989] [G loss: 1.000086]\n",
      "epoch:34 step:161405[D loss: 0.999970] [G loss: 1.000087]\n",
      "epoch:34 step:161410[D loss: 0.999971] [G loss: 1.000115]\n",
      "epoch:34 step:161415[D loss: 0.999961] [G loss: 1.000172]\n",
      "epoch:34 step:161420[D loss: 0.999960] [G loss: 1.000076]\n",
      "epoch:34 step:161425[D loss: 0.999966] [G loss: 1.000048]\n",
      "epoch:34 step:161430[D loss: 1.000045] [G loss: 0.999913]\n",
      "epoch:34 step:161435[D loss: 1.000055] [G loss: 0.999936]\n",
      "epoch:34 step:161440[D loss: 1.000016] [G loss: 0.999931]\n",
      "epoch:34 step:161445[D loss: 0.999931] [G loss: 1.000059]\n",
      "epoch:34 step:161450[D loss: 0.999950] [G loss: 1.000184]\n",
      "epoch:34 step:161455[D loss: 0.999946] [G loss: 1.000098]\n",
      "epoch:34 step:161460[D loss: 0.999992] [G loss: 1.000093]\n",
      "epoch:34 step:161465[D loss: 1.000024] [G loss: 1.000016]\n",
      "epoch:34 step:161470[D loss: 0.999950] [G loss: 1.000029]\n",
      "epoch:34 step:161475[D loss: 0.999965] [G loss: 1.000002]\n",
      "epoch:34 step:161480[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:34 step:161485[D loss: 1.000013] [G loss: 1.000015]\n",
      "epoch:34 step:161490[D loss: 0.999939] [G loss: 1.000095]\n",
      "epoch:34 step:161495[D loss: 0.999966] [G loss: 1.000081]\n",
      "epoch:34 step:161500[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:34 step:161505[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:34 step:161510[D loss: 0.999951] [G loss: 1.000121]\n",
      "epoch:34 step:161515[D loss: 0.999966] [G loss: 1.000038]\n",
      "epoch:34 step:161520[D loss: 0.999979] [G loss: 1.000119]\n",
      "epoch:34 step:161525[D loss: 1.000016] [G loss: 1.000091]\n",
      "epoch:34 step:161530[D loss: 1.000015] [G loss: 1.000089]\n",
      "epoch:34 step:161535[D loss: 0.999965] [G loss: 1.000101]\n",
      "epoch:34 step:161540[D loss: 0.999944] [G loss: 1.000140]\n",
      "epoch:34 step:161545[D loss: 1.000009] [G loss: 0.999937]\n",
      "epoch:34 step:161550[D loss: 0.999959] [G loss: 1.000066]\n",
      "epoch:34 step:161555[D loss: 0.999988] [G loss: 1.000024]\n",
      "epoch:34 step:161560[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:34 step:161565[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:34 step:161570[D loss: 0.999986] [G loss: 1.000035]\n",
      "epoch:34 step:161575[D loss: 0.999955] [G loss: 1.000094]\n",
      "epoch:34 step:161580[D loss: 1.000051] [G loss: 1.000086]\n",
      "epoch:34 step:161585[D loss: 1.000026] [G loss: 1.000294]\n",
      "epoch:34 step:161590[D loss: 0.999896] [G loss: 1.000192]\n",
      "epoch:34 step:161595[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:34 step:161600[D loss: 1.000052] [G loss: 0.999841]\n",
      "epoch:34 step:161605[D loss: 1.000010] [G loss: 1.000023]\n",
      "epoch:34 step:161610[D loss: 1.000018] [G loss: 0.999998]\n",
      "epoch:34 step:161615[D loss: 1.000013] [G loss: 1.000016]\n",
      "epoch:34 step:161620[D loss: 0.999890] [G loss: 1.000117]\n",
      "epoch:34 step:161625[D loss: 0.999943] [G loss: 1.000101]\n",
      "epoch:34 step:161630[D loss: 0.999956] [G loss: 1.000155]\n",
      "epoch:34 step:161635[D loss: 1.000013] [G loss: 1.000151]\n",
      "epoch:34 step:161640[D loss: 0.999925] [G loss: 1.000111]\n",
      "epoch:34 step:161645[D loss: 0.999997] [G loss: 1.000090]\n",
      "epoch:34 step:161650[D loss: 0.999936] [G loss: 1.000183]\n",
      "epoch:34 step:161655[D loss: 0.999964] [G loss: 1.000083]\n",
      "epoch:34 step:161660[D loss: 0.999995] [G loss: 1.000017]\n",
      "epoch:34 step:161665[D loss: 1.000056] [G loss: 0.999826]\n",
      "epoch:34 step:161670[D loss: 0.999908] [G loss: 1.000061]\n",
      "epoch:34 step:161675[D loss: 0.999973] [G loss: 0.999966]\n",
      "epoch:34 step:161680[D loss: 1.000205] [G loss: 0.999702]\n",
      "epoch:34 step:161685[D loss: 0.999940] [G loss: 0.999955]\n",
      "epoch:34 step:161690[D loss: 0.999932] [G loss: 1.000159]\n",
      "epoch:34 step:161695[D loss: 1.000035] [G loss: 0.999928]\n",
      "epoch:34 step:161700[D loss: 0.999952] [G loss: 1.000019]\n",
      "epoch:34 step:161705[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:34 step:161710[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:34 step:161715[D loss: 1.000077] [G loss: 1.000006]\n",
      "epoch:34 step:161720[D loss: 0.999983] [G loss: 0.999932]\n",
      "epoch:34 step:161725[D loss: 0.999940] [G loss: 1.000135]\n",
      "epoch:34 step:161730[D loss: 1.000031] [G loss: 1.000100]\n",
      "epoch:34 step:161735[D loss: 1.000007] [G loss: 1.000157]\n",
      "epoch:34 step:161740[D loss: 0.999989] [G loss: 1.000139]\n",
      "epoch:34 step:161745[D loss: 0.999926] [G loss: 1.000210]\n",
      "epoch:34 step:161750[D loss: 1.000011] [G loss: 1.000214]\n",
      "epoch:34 step:161755[D loss: 1.000015] [G loss: 1.000133]\n",
      "epoch:34 step:161760[D loss: 0.999932] [G loss: 1.000259]\n",
      "epoch:34 step:161765[D loss: 0.999977] [G loss: 1.000078]\n",
      "epoch:34 step:161770[D loss: 1.000056] [G loss: 1.000108]\n",
      "epoch:34 step:161775[D loss: 0.999983] [G loss: 1.000104]\n",
      "epoch:34 step:161780[D loss: 0.999985] [G loss: 1.000041]\n",
      "epoch:34 step:161785[D loss: 1.000110] [G loss: 0.999934]\n",
      "epoch:34 step:161790[D loss: 1.000159] [G loss: 0.999864]\n",
      "epoch:34 step:161795[D loss: 0.999919] [G loss: 0.999954]\n",
      "epoch:34 step:161800[D loss: 0.999959] [G loss: 0.999906]\n",
      "epoch:34 step:161805[D loss: 0.999840] [G loss: 1.000220]\n",
      "epoch:34 step:161810[D loss: 1.000045] [G loss: 1.000012]\n",
      "epoch:34 step:161815[D loss: 0.999964] [G loss: 1.000148]\n",
      "epoch:34 step:161820[D loss: 0.999890] [G loss: 1.000121]\n",
      "epoch:34 step:161825[D loss: 0.999944] [G loss: 1.000194]\n",
      "epoch:34 step:161830[D loss: 0.999978] [G loss: 1.000090]\n",
      "epoch:34 step:161835[D loss: 0.999968] [G loss: 1.000110]\n",
      "epoch:34 step:161840[D loss: 0.999989] [G loss: 1.000300]\n",
      "epoch:34 step:161845[D loss: 0.999978] [G loss: 1.000102]\n",
      "epoch:34 step:161850[D loss: 1.000006] [G loss: 0.999996]\n",
      "epoch:34 step:161855[D loss: 1.000016] [G loss: 1.000044]\n",
      "epoch:34 step:161860[D loss: 0.999987] [G loss: 1.000074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:161865[D loss: 1.000048] [G loss: 0.999961]\n",
      "epoch:34 step:161870[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:34 step:161875[D loss: 1.000042] [G loss: 1.000089]\n",
      "epoch:34 step:161880[D loss: 0.999927] [G loss: 1.000132]\n",
      "epoch:34 step:161885[D loss: 0.999949] [G loss: 1.000102]\n",
      "epoch:34 step:161890[D loss: 0.999939] [G loss: 1.000104]\n",
      "epoch:34 step:161895[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:34 step:161900[D loss: 1.000041] [G loss: 0.999974]\n",
      "epoch:34 step:161905[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:34 step:161910[D loss: 0.999953] [G loss: 1.000083]\n",
      "epoch:34 step:161915[D loss: 0.999957] [G loss: 1.000082]\n",
      "epoch:34 step:161920[D loss: 0.999978] [G loss: 1.000068]\n",
      "epoch:34 step:161925[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:34 step:161930[D loss: 0.999979] [G loss: 1.000090]\n",
      "epoch:34 step:161935[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:34 step:161940[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:34 step:161945[D loss: 0.999966] [G loss: 1.000084]\n",
      "epoch:34 step:161950[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:34 step:161955[D loss: 0.999918] [G loss: 1.000120]\n",
      "epoch:34 step:161960[D loss: 1.000044] [G loss: 1.000042]\n",
      "epoch:34 step:161965[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:34 step:161970[D loss: 1.000001] [G loss: 1.000089]\n",
      "epoch:34 step:161975[D loss: 0.999997] [G loss: 1.000124]\n",
      "epoch:34 step:161980[D loss: 1.000003] [G loss: 1.000098]\n",
      "epoch:34 step:161985[D loss: 1.000033] [G loss: 1.000048]\n",
      "epoch:34 step:161990[D loss: 0.999923] [G loss: 1.000124]\n",
      "epoch:34 step:161995[D loss: 0.999987] [G loss: 0.999974]\n",
      "epoch:34 step:162000[D loss: 1.000017] [G loss: 0.999987]\n",
      "epoch:34 step:162005[D loss: 1.000147] [G loss: 1.000015]\n",
      "epoch:34 step:162010[D loss: 1.000063] [G loss: 0.999861]\n",
      "epoch:34 step:162015[D loss: 1.000008] [G loss: 1.000032]\n",
      "epoch:34 step:162020[D loss: 0.999912] [G loss: 1.000196]\n",
      "epoch:34 step:162025[D loss: 0.999907] [G loss: 1.000112]\n",
      "epoch:34 step:162030[D loss: 0.999945] [G loss: 1.000090]\n",
      "epoch:34 step:162035[D loss: 0.999993] [G loss: 1.000035]\n",
      "epoch:34 step:162040[D loss: 1.000016] [G loss: 1.000043]\n",
      "epoch:34 step:162045[D loss: 0.999997] [G loss: 1.000062]\n",
      "epoch:34 step:162050[D loss: 0.999962] [G loss: 1.000036]\n",
      "epoch:34 step:162055[D loss: 1.000070] [G loss: 0.999977]\n",
      "epoch:34 step:162060[D loss: 0.999967] [G loss: 1.000053]\n",
      "epoch:34 step:162065[D loss: 0.999983] [G loss: 1.000046]\n",
      "epoch:34 step:162070[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:34 step:162075[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:34 step:162080[D loss: 0.999990] [G loss: 1.000056]\n",
      "epoch:34 step:162085[D loss: 0.999947] [G loss: 1.000044]\n",
      "epoch:34 step:162090[D loss: 0.999977] [G loss: 1.000032]\n",
      "epoch:34 step:162095[D loss: 0.999936] [G loss: 1.000095]\n",
      "epoch:34 step:162100[D loss: 0.999957] [G loss: 1.000080]\n",
      "epoch:34 step:162105[D loss: 1.000026] [G loss: 1.000009]\n",
      "epoch:34 step:162110[D loss: 0.999970] [G loss: 1.000058]\n",
      "epoch:34 step:162115[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:34 step:162120[D loss: 0.999973] [G loss: 1.000041]\n",
      "epoch:34 step:162125[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:34 step:162130[D loss: 0.999983] [G loss: 1.000061]\n",
      "epoch:34 step:162135[D loss: 0.999982] [G loss: 1.000061]\n",
      "epoch:34 step:162140[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:34 step:162145[D loss: 0.999997] [G loss: 1.000041]\n",
      "epoch:34 step:162150[D loss: 0.999963] [G loss: 1.000042]\n",
      "epoch:34 step:162155[D loss: 1.000101] [G loss: 1.000008]\n",
      "epoch:34 step:162160[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:34 step:162165[D loss: 1.000158] [G loss: 1.000015]\n",
      "epoch:34 step:162170[D loss: 0.999996] [G loss: 1.000065]\n",
      "epoch:34 step:162175[D loss: 0.999952] [G loss: 1.000036]\n",
      "epoch:34 step:162180[D loss: 0.999965] [G loss: 1.000053]\n",
      "epoch:34 step:162185[D loss: 0.999964] [G loss: 1.000068]\n",
      "epoch:34 step:162190[D loss: 0.999961] [G loss: 1.000132]\n",
      "epoch:34 step:162195[D loss: 1.000018] [G loss: 1.000014]\n",
      "epoch:34 step:162200[D loss: 1.000049] [G loss: 0.999944]\n",
      "epoch:34 step:162205[D loss: 1.000062] [G loss: 0.999932]\n",
      "epoch:34 step:162210[D loss: 0.999876] [G loss: 1.000072]\n",
      "epoch:34 step:162215[D loss: 0.999971] [G loss: 1.000138]\n",
      "epoch:34 step:162220[D loss: 0.999944] [G loss: 1.000114]\n",
      "epoch:34 step:162225[D loss: 1.000078] [G loss: 0.999930]\n",
      "epoch:34 step:162230[D loss: 1.000030] [G loss: 1.000098]\n",
      "epoch:34 step:162235[D loss: 0.999962] [G loss: 1.000284]\n",
      "epoch:34 step:162240[D loss: 0.999954] [G loss: 1.000105]\n",
      "epoch:34 step:162245[D loss: 1.000014] [G loss: 1.000021]\n",
      "epoch:34 step:162250[D loss: 1.000124] [G loss: 1.000067]\n",
      "epoch:34 step:162255[D loss: 1.000114] [G loss: 1.000051]\n",
      "epoch:34 step:162260[D loss: 1.000041] [G loss: 0.999974]\n",
      "epoch:34 step:162265[D loss: 1.000103] [G loss: 1.000090]\n",
      "epoch:34 step:162270[D loss: 0.999988] [G loss: 1.000031]\n",
      "epoch:34 step:162275[D loss: 0.999980] [G loss: 0.999971]\n",
      "epoch:34 step:162280[D loss: 0.999940] [G loss: 1.000178]\n",
      "epoch:34 step:162285[D loss: 0.999930] [G loss: 1.000131]\n",
      "epoch:34 step:162290[D loss: 0.999949] [G loss: 1.000131]\n",
      "epoch:34 step:162295[D loss: 1.000096] [G loss: 0.999911]\n",
      "epoch:34 step:162300[D loss: 0.999994] [G loss: 0.999891]\n",
      "epoch:34 step:162305[D loss: 0.999978] [G loss: 0.999861]\n",
      "epoch:34 step:162310[D loss: 0.999987] [G loss: 1.000022]\n",
      "epoch:34 step:162315[D loss: 0.999990] [G loss: 0.999940]\n",
      "epoch:34 step:162320[D loss: 0.999926] [G loss: 1.000055]\n",
      "epoch:34 step:162325[D loss: 0.999963] [G loss: 1.000016]\n",
      "epoch:34 step:162330[D loss: 0.999967] [G loss: 1.000060]\n",
      "epoch:34 step:162335[D loss: 1.000026] [G loss: 1.000063]\n",
      "epoch:34 step:162340[D loss: 0.999926] [G loss: 1.000104]\n",
      "epoch:34 step:162345[D loss: 1.000030] [G loss: 1.000017]\n",
      "epoch:34 step:162350[D loss: 0.999981] [G loss: 1.000027]\n",
      "epoch:34 step:162355[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:34 step:162360[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:34 step:162365[D loss: 0.999975] [G loss: 1.000071]\n",
      "epoch:34 step:162370[D loss: 0.999968] [G loss: 1.000145]\n",
      "epoch:34 step:162375[D loss: 1.000009] [G loss: 1.000038]\n",
      "epoch:34 step:162380[D loss: 1.000037] [G loss: 0.999999]\n",
      "epoch:34 step:162385[D loss: 0.999912] [G loss: 1.000083]\n",
      "epoch:34 step:162390[D loss: 1.000133] [G loss: 0.999932]\n",
      "epoch:34 step:162395[D loss: 0.999986] [G loss: 1.000059]\n",
      "epoch:34 step:162400[D loss: 1.000055] [G loss: 1.000070]\n",
      "epoch:34 step:162405[D loss: 0.999989] [G loss: 1.000111]\n",
      "epoch:34 step:162410[D loss: 0.999968] [G loss: 1.000102]\n",
      "epoch:34 step:162415[D loss: 0.999969] [G loss: 1.000096]\n",
      "epoch:34 step:162420[D loss: 0.999991] [G loss: 1.000041]\n",
      "epoch:34 step:162425[D loss: 1.000141] [G loss: 0.999926]\n",
      "epoch:34 step:162430[D loss: 0.999993] [G loss: 1.000066]\n",
      "epoch:34 step:162435[D loss: 0.999979] [G loss: 1.000122]\n",
      "epoch:34 step:162440[D loss: 1.000018] [G loss: 1.000079]\n",
      "epoch:34 step:162445[D loss: 0.999923] [G loss: 1.000113]\n",
      "epoch:34 step:162450[D loss: 0.999990] [G loss: 1.000131]\n",
      "epoch:34 step:162455[D loss: 0.999976] [G loss: 1.000098]\n",
      "epoch:34 step:162460[D loss: 1.000029] [G loss: 1.000022]\n",
      "epoch:34 step:162465[D loss: 1.000088] [G loss: 0.999928]\n",
      "epoch:34 step:162470[D loss: 0.999962] [G loss: 1.000104]\n",
      "epoch:34 step:162475[D loss: 1.000192] [G loss: 0.999917]\n",
      "epoch:34 step:162480[D loss: 0.999893] [G loss: 1.000083]\n",
      "epoch:34 step:162485[D loss: 0.999886] [G loss: 1.000131]\n",
      "epoch:34 step:162490[D loss: 0.999997] [G loss: 1.000183]\n",
      "epoch:34 step:162495[D loss: 1.000013] [G loss: 1.000179]\n",
      "epoch:34 step:162500[D loss: 0.999908] [G loss: 1.000158]\n",
      "epoch:34 step:162505[D loss: 0.999953] [G loss: 1.000076]\n",
      "epoch:34 step:162510[D loss: 0.999989] [G loss: 1.000004]\n",
      "epoch:34 step:162515[D loss: 1.000013] [G loss: 1.000002]\n",
      "epoch:34 step:162520[D loss: 1.000177] [G loss: 0.999810]\n",
      "epoch:34 step:162525[D loss: 0.999991] [G loss: 0.999931]\n",
      "epoch:34 step:162530[D loss: 0.999915] [G loss: 1.000115]\n",
      "epoch:34 step:162535[D loss: 1.000245] [G loss: 0.999833]\n",
      "epoch:34 step:162540[D loss: 0.999914] [G loss: 1.000173]\n",
      "epoch:34 step:162545[D loss: 0.999988] [G loss: 1.000171]\n",
      "epoch:34 step:162550[D loss: 0.999929] [G loss: 1.000154]\n",
      "epoch:34 step:162555[D loss: 0.999986] [G loss: 1.000128]\n",
      "epoch:34 step:162560[D loss: 0.999984] [G loss: 1.000013]\n",
      "epoch:34 step:162565[D loss: 0.999947] [G loss: 1.000091]\n",
      "epoch:34 step:162570[D loss: 1.000022] [G loss: 0.999959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:162575[D loss: 0.999951] [G loss: 1.000123]\n",
      "epoch:34 step:162580[D loss: 0.999929] [G loss: 0.999974]\n",
      "epoch:34 step:162585[D loss: 0.999929] [G loss: 1.000077]\n",
      "epoch:34 step:162590[D loss: 1.000072] [G loss: 0.999928]\n",
      "epoch:34 step:162595[D loss: 0.999923] [G loss: 1.000097]\n",
      "epoch:34 step:162600[D loss: 1.000054] [G loss: 0.999959]\n",
      "epoch:34 step:162605[D loss: 1.000040] [G loss: 0.999992]\n",
      "epoch:34 step:162610[D loss: 0.999959] [G loss: 1.000000]\n",
      "epoch:34 step:162615[D loss: 0.999976] [G loss: 1.000081]\n",
      "epoch:34 step:162620[D loss: 0.999951] [G loss: 1.000071]\n",
      "epoch:34 step:162625[D loss: 1.000010] [G loss: 1.000043]\n",
      "epoch:34 step:162630[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:34 step:162635[D loss: 0.999973] [G loss: 1.000058]\n",
      "epoch:34 step:162640[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:34 step:162645[D loss: 0.999940] [G loss: 1.000089]\n",
      "epoch:34 step:162650[D loss: 1.000023] [G loss: 0.999992]\n",
      "epoch:34 step:162655[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:34 step:162660[D loss: 0.999967] [G loss: 1.000088]\n",
      "epoch:34 step:162665[D loss: 0.999995] [G loss: 1.000038]\n",
      "epoch:34 step:162670[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:34 step:162675[D loss: 0.999969] [G loss: 1.000073]\n",
      "epoch:34 step:162680[D loss: 1.000018] [G loss: 1.000010]\n",
      "epoch:34 step:162685[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:34 step:162690[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:34 step:162695[D loss: 0.999990] [G loss: 1.000053]\n",
      "epoch:34 step:162700[D loss: 0.999976] [G loss: 1.000066]\n",
      "epoch:34 step:162705[D loss: 0.999976] [G loss: 1.000065]\n",
      "epoch:34 step:162710[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:34 step:162715[D loss: 1.000000] [G loss: 1.000091]\n",
      "epoch:34 step:162720[D loss: 0.999987] [G loss: 1.000064]\n",
      "epoch:34 step:162725[D loss: 1.000014] [G loss: 0.999992]\n",
      "epoch:34 step:162730[D loss: 1.000012] [G loss: 1.000066]\n",
      "epoch:34 step:162735[D loss: 0.999950] [G loss: 1.000101]\n",
      "epoch:34 step:162740[D loss: 0.999976] [G loss: 1.000109]\n",
      "epoch:34 step:162745[D loss: 1.000042] [G loss: 1.000154]\n",
      "epoch:34 step:162750[D loss: 0.999936] [G loss: 1.000126]\n",
      "epoch:34 step:162755[D loss: 1.000088] [G loss: 1.000058]\n",
      "epoch:34 step:162760[D loss: 0.999958] [G loss: 1.000109]\n",
      "epoch:34 step:162765[D loss: 0.999997] [G loss: 0.999941]\n",
      "epoch:34 step:162770[D loss: 0.999909] [G loss: 1.000137]\n",
      "epoch:34 step:162775[D loss: 0.999917] [G loss: 1.000111]\n",
      "epoch:34 step:162780[D loss: 0.999977] [G loss: 1.000122]\n",
      "epoch:34 step:162785[D loss: 0.999973] [G loss: 1.000055]\n",
      "epoch:34 step:162790[D loss: 0.999962] [G loss: 1.000036]\n",
      "epoch:34 step:162795[D loss: 0.999989] [G loss: 1.000073]\n",
      "epoch:34 step:162800[D loss: 0.999999] [G loss: 1.000090]\n",
      "epoch:34 step:162805[D loss: 0.999986] [G loss: 1.000090]\n",
      "epoch:34 step:162810[D loss: 1.000002] [G loss: 1.000072]\n",
      "epoch:34 step:162815[D loss: 1.000067] [G loss: 1.000097]\n",
      "epoch:34 step:162820[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:34 step:162825[D loss: 0.999823] [G loss: 1.000340]\n",
      "epoch:34 step:162830[D loss: 0.999975] [G loss: 1.000192]\n",
      "epoch:34 step:162835[D loss: 0.999894] [G loss: 1.000149]\n",
      "epoch:34 step:162840[D loss: 1.000048] [G loss: 0.999963]\n",
      "epoch:34 step:162845[D loss: 0.999928] [G loss: 1.000079]\n",
      "epoch:34 step:162850[D loss: 0.999976] [G loss: 1.000043]\n",
      "epoch:34 step:162855[D loss: 1.000073] [G loss: 0.999906]\n",
      "epoch:34 step:162860[D loss: 0.999969] [G loss: 1.000293]\n",
      "epoch:34 step:162865[D loss: 0.999956] [G loss: 1.000164]\n",
      "epoch:34 step:162870[D loss: 1.000000] [G loss: 1.000003]\n",
      "epoch:34 step:162875[D loss: 0.999901] [G loss: 1.000173]\n",
      "epoch:34 step:162880[D loss: 1.000055] [G loss: 0.999971]\n",
      "epoch:34 step:162885[D loss: 0.999994] [G loss: 1.000019]\n",
      "epoch:34 step:162890[D loss: 1.000016] [G loss: 1.000023]\n",
      "epoch:34 step:162895[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:34 step:162900[D loss: 1.000003] [G loss: 1.000125]\n",
      "epoch:34 step:162905[D loss: 1.000013] [G loss: 1.000110]\n",
      "epoch:34 step:162910[D loss: 1.000033] [G loss: 1.000041]\n",
      "epoch:34 step:162915[D loss: 0.999993] [G loss: 0.999970]\n",
      "epoch:34 step:162920[D loss: 0.999957] [G loss: 1.000064]\n",
      "epoch:34 step:162925[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:34 step:162930[D loss: 1.000114] [G loss: 0.999936]\n",
      "epoch:34 step:162935[D loss: 0.999956] [G loss: 0.999981]\n",
      "epoch:34 step:162940[D loss: 1.000006] [G loss: 1.000001]\n",
      "epoch:34 step:162945[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:34 step:162950[D loss: 1.000042] [G loss: 1.000007]\n",
      "epoch:34 step:162955[D loss: 0.999970] [G loss: 1.000079]\n",
      "epoch:34 step:162960[D loss: 0.999991] [G loss: 0.999948]\n",
      "epoch:34 step:162965[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:34 step:162970[D loss: 0.999981] [G loss: 1.000060]\n",
      "epoch:34 step:162975[D loss: 1.000126] [G loss: 0.999999]\n",
      "epoch:34 step:162980[D loss: 0.999908] [G loss: 1.000132]\n",
      "epoch:34 step:162985[D loss: 1.000084] [G loss: 1.000061]\n",
      "epoch:34 step:162990[D loss: 0.999947] [G loss: 1.000179]\n",
      "epoch:34 step:162995[D loss: 0.999978] [G loss: 1.000111]\n",
      "epoch:34 step:163000[D loss: 1.000044] [G loss: 1.000064]\n",
      "epoch:34 step:163005[D loss: 0.999934] [G loss: 1.000017]\n",
      "epoch:34 step:163010[D loss: 0.999996] [G loss: 1.000007]\n",
      "epoch:34 step:163015[D loss: 0.999946] [G loss: 1.000105]\n",
      "epoch:34 step:163020[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:34 step:163025[D loss: 0.999986] [G loss: 1.000042]\n",
      "epoch:34 step:163030[D loss: 0.999951] [G loss: 1.000090]\n",
      "epoch:34 step:163035[D loss: 0.999969] [G loss: 1.000081]\n",
      "epoch:34 step:163040[D loss: 1.000066] [G loss: 1.000066]\n",
      "epoch:34 step:163045[D loss: 0.999886] [G loss: 1.000204]\n",
      "epoch:34 step:163050[D loss: 0.999945] [G loss: 1.000131]\n",
      "epoch:34 step:163055[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:34 step:163060[D loss: 1.000063] [G loss: 1.000195]\n",
      "epoch:34 step:163065[D loss: 0.999944] [G loss: 1.000184]\n",
      "epoch:34 step:163070[D loss: 1.000003] [G loss: 1.000011]\n",
      "epoch:34 step:163075[D loss: 1.000033] [G loss: 0.999969]\n",
      "epoch:34 step:163080[D loss: 1.000077] [G loss: 1.000022]\n",
      "epoch:34 step:163085[D loss: 0.999987] [G loss: 1.000038]\n",
      "epoch:34 step:163090[D loss: 0.999997] [G loss: 1.000000]\n",
      "epoch:34 step:163095[D loss: 0.999982] [G loss: 1.000145]\n",
      "epoch:34 step:163100[D loss: 1.000031] [G loss: 1.000092]\n",
      "epoch:34 step:163105[D loss: 0.999870] [G loss: 1.000211]\n",
      "epoch:34 step:163110[D loss: 0.999928] [G loss: 1.000146]\n",
      "epoch:34 step:163115[D loss: 0.999986] [G loss: 1.000064]\n",
      "epoch:34 step:163120[D loss: 0.999948] [G loss: 1.000085]\n",
      "epoch:34 step:163125[D loss: 0.999956] [G loss: 1.000153]\n",
      "epoch:34 step:163130[D loss: 0.999992] [G loss: 0.999968]\n",
      "epoch:34 step:163135[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:34 step:163140[D loss: 0.999957] [G loss: 1.000091]\n",
      "epoch:34 step:163145[D loss: 0.999989] [G loss: 1.000067]\n",
      "epoch:34 step:163150[D loss: 0.999938] [G loss: 1.000137]\n",
      "epoch:34 step:163155[D loss: 0.999987] [G loss: 1.000047]\n",
      "epoch:34 step:163160[D loss: 1.000065] [G loss: 1.000142]\n",
      "epoch:34 step:163165[D loss: 0.999855] [G loss: 1.000129]\n",
      "epoch:34 step:163170[D loss: 0.999974] [G loss: 1.000088]\n",
      "epoch:34 step:163175[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:34 step:163180[D loss: 1.000014] [G loss: 1.000011]\n",
      "epoch:34 step:163185[D loss: 1.000075] [G loss: 0.999950]\n",
      "epoch:34 step:163190[D loss: 0.999987] [G loss: 0.999991]\n",
      "epoch:34 step:163195[D loss: 0.999959] [G loss: 1.000087]\n",
      "epoch:34 step:163200[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:34 step:163205[D loss: 0.999998] [G loss: 1.000036]\n",
      "epoch:34 step:163210[D loss: 0.999942] [G loss: 1.000102]\n",
      "epoch:34 step:163215[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:34 step:163220[D loss: 0.999969] [G loss: 1.000103]\n",
      "epoch:34 step:163225[D loss: 0.999942] [G loss: 1.000097]\n",
      "epoch:34 step:163230[D loss: 0.999891] [G loss: 1.000196]\n",
      "epoch:34 step:163235[D loss: 0.999991] [G loss: 1.000146]\n",
      "epoch:34 step:163240[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:34 step:163245[D loss: 1.000003] [G loss: 1.000102]\n",
      "epoch:34 step:163250[D loss: 0.999977] [G loss: 1.000011]\n",
      "epoch:34 step:163255[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:34 step:163260[D loss: 1.000011] [G loss: 1.000022]\n",
      "epoch:34 step:163265[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:34 step:163270[D loss: 0.999948] [G loss: 1.000153]\n",
      "epoch:34 step:163275[D loss: 0.999935] [G loss: 1.000130]\n",
      "epoch:34 step:163280[D loss: 1.000057] [G loss: 1.000013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:163285[D loss: 0.999904] [G loss: 1.000180]\n",
      "epoch:34 step:163290[D loss: 1.000009] [G loss: 0.999984]\n",
      "epoch:34 step:163295[D loss: 1.000079] [G loss: 0.999949]\n",
      "epoch:34 step:163300[D loss: 0.999933] [G loss: 1.000127]\n",
      "epoch:34 step:163305[D loss: 0.999948] [G loss: 1.000083]\n",
      "epoch:34 step:163310[D loss: 0.999901] [G loss: 1.000197]\n",
      "epoch:34 step:163315[D loss: 1.000124] [G loss: 0.999965]\n",
      "epoch:34 step:163320[D loss: 0.999935] [G loss: 1.000120]\n",
      "epoch:34 step:163325[D loss: 1.000040] [G loss: 0.999990]\n",
      "epoch:34 step:163330[D loss: 1.000086] [G loss: 1.000049]\n",
      "epoch:34 step:163335[D loss: 0.999929] [G loss: 1.000140]\n",
      "epoch:34 step:163340[D loss: 0.999961] [G loss: 1.000057]\n",
      "epoch:34 step:163345[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:34 step:163350[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:34 step:163355[D loss: 0.999950] [G loss: 1.000070]\n",
      "epoch:34 step:163360[D loss: 1.000013] [G loss: 0.999980]\n",
      "epoch:34 step:163365[D loss: 0.999988] [G loss: 1.000089]\n",
      "epoch:34 step:163370[D loss: 0.999988] [G loss: 1.000044]\n",
      "epoch:34 step:163375[D loss: 0.999968] [G loss: 1.000048]\n",
      "epoch:34 step:163380[D loss: 0.999962] [G loss: 1.000156]\n",
      "epoch:34 step:163385[D loss: 0.999934] [G loss: 1.000108]\n",
      "epoch:34 step:163390[D loss: 0.999955] [G loss: 1.000111]\n",
      "epoch:34 step:163395[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:34 step:163400[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:34 step:163405[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:34 step:163410[D loss: 0.999923] [G loss: 1.000112]\n",
      "epoch:34 step:163415[D loss: 0.999956] [G loss: 1.000110]\n",
      "epoch:34 step:163420[D loss: 0.999957] [G loss: 1.000087]\n",
      "epoch:34 step:163425[D loss: 0.999979] [G loss: 1.000079]\n",
      "epoch:34 step:163430[D loss: 1.000000] [G loss: 1.000066]\n",
      "epoch:34 step:163435[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:34 step:163440[D loss: 0.999985] [G loss: 1.000084]\n",
      "epoch:34 step:163445[D loss: 1.000005] [G loss: 1.000066]\n",
      "epoch:34 step:163450[D loss: 1.000020] [G loss: 1.000086]\n",
      "epoch:34 step:163455[D loss: 0.999956] [G loss: 1.000068]\n",
      "epoch:34 step:163460[D loss: 1.000057] [G loss: 1.000066]\n",
      "epoch:34 step:163465[D loss: 0.999947] [G loss: 1.000108]\n",
      "epoch:34 step:163470[D loss: 1.000029] [G loss: 1.000019]\n",
      "epoch:34 step:163475[D loss: 0.999958] [G loss: 1.000042]\n",
      "epoch:34 step:163480[D loss: 0.999994] [G loss: 0.999998]\n",
      "epoch:34 step:163485[D loss: 1.000002] [G loss: 1.000031]\n",
      "epoch:34 step:163490[D loss: 1.000000] [G loss: 1.000047]\n",
      "epoch:34 step:163495[D loss: 0.999969] [G loss: 1.000094]\n",
      "epoch:34 step:163500[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:34 step:163505[D loss: 0.999921] [G loss: 1.000097]\n",
      "epoch:34 step:163510[D loss: 1.000020] [G loss: 1.000110]\n",
      "epoch:34 step:163515[D loss: 0.999960] [G loss: 1.000125]\n",
      "epoch:34 step:163520[D loss: 0.999953] [G loss: 1.000074]\n",
      "epoch:34 step:163525[D loss: 0.999939] [G loss: 1.000088]\n",
      "epoch:34 step:163530[D loss: 0.999935] [G loss: 1.000081]\n",
      "epoch:34 step:163535[D loss: 0.999940] [G loss: 1.000048]\n",
      "epoch:34 step:163540[D loss: 1.000017] [G loss: 1.000013]\n",
      "epoch:34 step:163545[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:34 step:163550[D loss: 0.999967] [G loss: 1.000078]\n",
      "epoch:34 step:163555[D loss: 0.999976] [G loss: 1.000074]\n",
      "epoch:34 step:163560[D loss: 0.999949] [G loss: 1.000130]\n",
      "epoch:34 step:163565[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:34 step:163570[D loss: 0.999998] [G loss: 1.000091]\n",
      "epoch:34 step:163575[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:34 step:163580[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:34 step:163585[D loss: 0.999978] [G loss: 1.000107]\n",
      "epoch:34 step:163590[D loss: 1.000002] [G loss: 1.000022]\n",
      "epoch:34 step:163595[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:34 step:163600[D loss: 0.999955] [G loss: 1.000106]\n",
      "epoch:34 step:163605[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:34 step:163610[D loss: 0.999968] [G loss: 1.000125]\n",
      "epoch:34 step:163615[D loss: 0.999961] [G loss: 1.000093]\n",
      "epoch:34 step:163620[D loss: 0.999982] [G loss: 1.000029]\n",
      "epoch:34 step:163625[D loss: 0.999948] [G loss: 1.000116]\n",
      "epoch:34 step:163630[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:34 step:163635[D loss: 0.999998] [G loss: 1.000037]\n",
      "epoch:34 step:163640[D loss: 1.000034] [G loss: 0.999970]\n",
      "epoch:34 step:163645[D loss: 0.999973] [G loss: 1.000050]\n",
      "epoch:34 step:163650[D loss: 1.000064] [G loss: 0.999969]\n",
      "epoch:34 step:163655[D loss: 0.999965] [G loss: 1.000070]\n",
      "epoch:34 step:163660[D loss: 0.999973] [G loss: 1.000049]\n",
      "epoch:34 step:163665[D loss: 0.999998] [G loss: 1.000020]\n",
      "epoch:34 step:163670[D loss: 0.999942] [G loss: 1.000101]\n",
      "epoch:34 step:163675[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:34 step:163680[D loss: 0.999961] [G loss: 1.000069]\n",
      "epoch:34 step:163685[D loss: 0.999986] [G loss: 1.000080]\n",
      "epoch:34 step:163690[D loss: 0.999986] [G loss: 1.000026]\n",
      "epoch:34 step:163695[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:34 step:163700[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:34 step:163705[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:34 step:163710[D loss: 0.999968] [G loss: 1.000082]\n",
      "epoch:34 step:163715[D loss: 1.000022] [G loss: 1.000056]\n",
      "epoch:34 step:163720[D loss: 0.999998] [G loss: 1.000039]\n",
      "epoch:34 step:163725[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:34 step:163730[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:34 step:163735[D loss: 1.000085] [G loss: 0.999933]\n",
      "epoch:34 step:163740[D loss: 1.000002] [G loss: 0.999986]\n",
      "epoch:34 step:163745[D loss: 0.999976] [G loss: 1.000108]\n",
      "epoch:34 step:163750[D loss: 0.999998] [G loss: 0.999971]\n",
      "epoch:34 step:163755[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:34 step:163760[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:34 step:163765[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:34 step:163770[D loss: 0.999878] [G loss: 1.000286]\n",
      "epoch:34 step:163775[D loss: 1.000070] [G loss: 0.999925]\n",
      "epoch:34 step:163780[D loss: 0.999861] [G loss: 1.000166]\n",
      "epoch:34 step:163785[D loss: 0.999972] [G loss: 1.000054]\n",
      "epoch:34 step:163790[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:34 step:163795[D loss: 1.000016] [G loss: 1.000075]\n",
      "epoch:34 step:163800[D loss: 0.999955] [G loss: 1.000047]\n",
      "epoch:34 step:163805[D loss: 0.999995] [G loss: 1.000058]\n",
      "epoch:34 step:163810[D loss: 0.999996] [G loss: 1.000130]\n",
      "epoch:34 step:163815[D loss: 0.999945] [G loss: 1.000121]\n",
      "epoch:34 step:163820[D loss: 1.000008] [G loss: 1.000110]\n",
      "epoch:34 step:163825[D loss: 0.999964] [G loss: 1.000044]\n",
      "epoch:34 step:163830[D loss: 1.000093] [G loss: 0.999993]\n",
      "epoch:34 step:163835[D loss: 1.000037] [G loss: 0.999909]\n",
      "epoch:34 step:163840[D loss: 0.999880] [G loss: 1.000137]\n",
      "epoch:34 step:163845[D loss: 0.999946] [G loss: 1.000084]\n",
      "epoch:34 step:163850[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:34 step:163855[D loss: 0.999947] [G loss: 1.000072]\n",
      "epoch:34 step:163860[D loss: 0.999941] [G loss: 1.000107]\n",
      "epoch:34 step:163865[D loss: 0.999982] [G loss: 1.000056]\n",
      "epoch:34 step:163870[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:34 step:163875[D loss: 0.999980] [G loss: 1.000069]\n",
      "epoch:34 step:163880[D loss: 0.999983] [G loss: 1.000069]\n",
      "epoch:34 step:163885[D loss: 1.000041] [G loss: 0.999961]\n",
      "epoch:34 step:163890[D loss: 0.999998] [G loss: 1.000090]\n",
      "epoch:34 step:163895[D loss: 1.000000] [G loss: 1.000072]\n",
      "epoch:34 step:163900[D loss: 0.999940] [G loss: 1.000120]\n",
      "epoch:34 step:163905[D loss: 1.000004] [G loss: 1.000029]\n",
      "epoch:34 step:163910[D loss: 1.000033] [G loss: 0.999922]\n",
      "epoch:34 step:163915[D loss: 0.999936] [G loss: 1.000053]\n",
      "epoch:34 step:163920[D loss: 0.999968] [G loss: 0.999996]\n",
      "epoch:34 step:163925[D loss: 1.000017] [G loss: 1.000071]\n",
      "epoch:34 step:163930[D loss: 1.000029] [G loss: 0.999942]\n",
      "epoch:34 step:163935[D loss: 0.999961] [G loss: 1.000055]\n",
      "epoch:34 step:163940[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:34 step:163945[D loss: 1.000000] [G loss: 1.000074]\n",
      "epoch:34 step:163950[D loss: 1.000005] [G loss: 1.000012]\n",
      "epoch:34 step:163955[D loss: 1.000009] [G loss: 1.000024]\n",
      "epoch:34 step:163960[D loss: 1.000008] [G loss: 1.000031]\n",
      "epoch:34 step:163965[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:34 step:163970[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:34 step:163975[D loss: 0.999957] [G loss: 1.000135]\n",
      "epoch:35 step:163980[D loss: 0.999917] [G loss: 1.000251]\n",
      "epoch:35 step:163985[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:35 step:163990[D loss: 0.999965] [G loss: 1.000080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:163995[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:35 step:164000[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:35 step:164005[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:35 step:164010[D loss: 1.000024] [G loss: 1.000012]\n",
      "epoch:35 step:164015[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:35 step:164020[D loss: 1.000065] [G loss: 0.999978]\n",
      "epoch:35 step:164025[D loss: 1.000003] [G loss: 1.000123]\n",
      "epoch:35 step:164030[D loss: 0.999899] [G loss: 1.000226]\n",
      "epoch:35 step:164035[D loss: 0.999913] [G loss: 1.000111]\n",
      "epoch:35 step:164040[D loss: 0.999956] [G loss: 1.000046]\n",
      "epoch:35 step:164045[D loss: 0.999989] [G loss: 1.000005]\n",
      "epoch:35 step:164050[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:35 step:164055[D loss: 0.999977] [G loss: 1.000083]\n",
      "epoch:35 step:164060[D loss: 0.999940] [G loss: 1.000124]\n",
      "epoch:35 step:164065[D loss: 0.999954] [G loss: 1.000099]\n",
      "epoch:35 step:164070[D loss: 0.999961] [G loss: 1.000116]\n",
      "epoch:35 step:164075[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:35 step:164080[D loss: 0.999963] [G loss: 1.000128]\n",
      "epoch:35 step:164085[D loss: 0.999949] [G loss: 1.000260]\n",
      "epoch:35 step:164090[D loss: 0.999970] [G loss: 1.000031]\n",
      "epoch:35 step:164095[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:35 step:164100[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:35 step:164105[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:35 step:164110[D loss: 0.999982] [G loss: 1.000098]\n",
      "epoch:35 step:164115[D loss: 0.999962] [G loss: 1.000066]\n",
      "epoch:35 step:164120[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:35 step:164125[D loss: 0.999979] [G loss: 1.000033]\n",
      "epoch:35 step:164130[D loss: 0.999998] [G loss: 1.000056]\n",
      "epoch:35 step:164135[D loss: 0.999963] [G loss: 1.000079]\n",
      "epoch:35 step:164140[D loss: 0.999957] [G loss: 1.000088]\n",
      "epoch:35 step:164145[D loss: 0.999999] [G loss: 1.000093]\n",
      "epoch:35 step:164150[D loss: 0.999955] [G loss: 1.000173]\n",
      "epoch:35 step:164155[D loss: 1.000022] [G loss: 1.000040]\n",
      "epoch:35 step:164160[D loss: 0.999947] [G loss: 1.000132]\n",
      "epoch:35 step:164165[D loss: 0.999969] [G loss: 1.000057]\n",
      "epoch:35 step:164170[D loss: 1.000003] [G loss: 1.000039]\n",
      "epoch:35 step:164175[D loss: 1.000096] [G loss: 0.999831]\n",
      "epoch:35 step:164180[D loss: 1.000010] [G loss: 1.000018]\n",
      "epoch:35 step:164185[D loss: 0.999945] [G loss: 1.000021]\n",
      "epoch:35 step:164190[D loss: 0.999999] [G loss: 0.999978]\n",
      "epoch:35 step:164195[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:35 step:164200[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:35 step:164205[D loss: 0.999939] [G loss: 1.000103]\n",
      "epoch:35 step:164210[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:35 step:164215[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:35 step:164220[D loss: 0.999974] [G loss: 1.000077]\n",
      "epoch:35 step:164225[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:35 step:164230[D loss: 0.999982] [G loss: 1.000068]\n",
      "epoch:35 step:164235[D loss: 0.999965] [G loss: 1.000104]\n",
      "epoch:35 step:164240[D loss: 0.999978] [G loss: 1.000120]\n",
      "epoch:35 step:164245[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:35 step:164250[D loss: 0.999972] [G loss: 1.000114]\n",
      "epoch:35 step:164255[D loss: 0.999956] [G loss: 1.000142]\n",
      "epoch:35 step:164260[D loss: 0.999989] [G loss: 1.000078]\n",
      "epoch:35 step:164265[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:35 step:164270[D loss: 0.999973] [G loss: 1.000076]\n",
      "epoch:35 step:164275[D loss: 1.000016] [G loss: 0.999932]\n",
      "epoch:35 step:164280[D loss: 0.999970] [G loss: 1.000062]\n",
      "epoch:35 step:164285[D loss: 0.999993] [G loss: 1.000083]\n",
      "epoch:35 step:164290[D loss: 0.999948] [G loss: 1.000166]\n",
      "epoch:35 step:164295[D loss: 0.999999] [G loss: 1.000119]\n",
      "epoch:35 step:164300[D loss: 0.999942] [G loss: 1.000065]\n",
      "epoch:35 step:164305[D loss: 0.999945] [G loss: 1.000024]\n",
      "epoch:35 step:164310[D loss: 0.999992] [G loss: 1.000033]\n",
      "epoch:35 step:164315[D loss: 1.000013] [G loss: 0.999953]\n",
      "epoch:35 step:164320[D loss: 1.000036] [G loss: 1.000104]\n",
      "epoch:35 step:164325[D loss: 0.999967] [G loss: 1.000069]\n",
      "epoch:35 step:164330[D loss: 1.000051] [G loss: 0.999936]\n",
      "epoch:35 step:164335[D loss: 1.000043] [G loss: 1.000014]\n",
      "epoch:35 step:164340[D loss: 1.000006] [G loss: 0.999998]\n",
      "epoch:35 step:164345[D loss: 0.999983] [G loss: 1.000005]\n",
      "epoch:35 step:164350[D loss: 1.000054] [G loss: 0.999954]\n",
      "epoch:35 step:164355[D loss: 0.999984] [G loss: 1.000007]\n",
      "epoch:35 step:164360[D loss: 1.000053] [G loss: 0.999974]\n",
      "epoch:35 step:164365[D loss: 0.999951] [G loss: 1.000094]\n",
      "epoch:35 step:164370[D loss: 0.999882] [G loss: 1.000207]\n",
      "epoch:35 step:164375[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:35 step:164380[D loss: 0.999938] [G loss: 1.000218]\n",
      "epoch:35 step:164385[D loss: 0.999998] [G loss: 1.000018]\n",
      "epoch:35 step:164390[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:35 step:164395[D loss: 1.000028] [G loss: 0.999963]\n",
      "epoch:35 step:164400[D loss: 0.999977] [G loss: 1.000092]\n",
      "epoch:35 step:164405[D loss: 1.000018] [G loss: 0.999892]\n",
      "epoch:35 step:164410[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:35 step:164415[D loss: 0.999994] [G loss: 1.000213]\n",
      "epoch:35 step:164420[D loss: 1.000037] [G loss: 1.000159]\n",
      "epoch:35 step:164425[D loss: 0.999972] [G loss: 1.000137]\n",
      "epoch:35 step:164430[D loss: 0.999956] [G loss: 1.000094]\n",
      "epoch:35 step:164435[D loss: 1.000014] [G loss: 0.999897]\n",
      "epoch:35 step:164440[D loss: 1.000024] [G loss: 0.999966]\n",
      "epoch:35 step:164445[D loss: 0.999941] [G loss: 1.000046]\n",
      "epoch:35 step:164450[D loss: 1.000010] [G loss: 1.000154]\n",
      "epoch:35 step:164455[D loss: 0.999941] [G loss: 1.000188]\n",
      "epoch:35 step:164460[D loss: 1.000062] [G loss: 1.000072]\n",
      "epoch:35 step:164465[D loss: 1.000081] [G loss: 1.000091]\n",
      "epoch:35 step:164470[D loss: 0.999949] [G loss: 1.000156]\n",
      "epoch:35 step:164475[D loss: 0.999977] [G loss: 1.000097]\n",
      "epoch:35 step:164480[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:35 step:164485[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:35 step:164490[D loss: 1.000062] [G loss: 0.999879]\n",
      "epoch:35 step:164495[D loss: 1.000023] [G loss: 0.999904]\n",
      "epoch:35 step:164500[D loss: 1.000014] [G loss: 0.999947]\n",
      "epoch:35 step:164505[D loss: 1.000022] [G loss: 0.999932]\n",
      "epoch:35 step:164510[D loss: 1.000088] [G loss: 0.999886]\n",
      "epoch:35 step:164515[D loss: 1.000011] [G loss: 1.000033]\n",
      "epoch:35 step:164520[D loss: 0.999952] [G loss: 1.000031]\n",
      "epoch:35 step:164525[D loss: 0.999892] [G loss: 1.000170]\n",
      "epoch:35 step:164530[D loss: 0.999966] [G loss: 1.000083]\n",
      "epoch:35 step:164535[D loss: 0.999992] [G loss: 1.000053]\n",
      "epoch:35 step:164540[D loss: 1.000063] [G loss: 0.999968]\n",
      "epoch:35 step:164545[D loss: 0.999963] [G loss: 1.000134]\n",
      "epoch:35 step:164550[D loss: 0.999912] [G loss: 1.000224]\n",
      "epoch:35 step:164555[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:35 step:164560[D loss: 0.999959] [G loss: 1.000108]\n",
      "epoch:35 step:164565[D loss: 1.000061] [G loss: 0.999979]\n",
      "epoch:35 step:164570[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:35 step:164575[D loss: 0.999861] [G loss: 1.000172]\n",
      "epoch:35 step:164580[D loss: 0.999988] [G loss: 1.000048]\n",
      "epoch:35 step:164585[D loss: 0.999988] [G loss: 1.000081]\n",
      "epoch:35 step:164590[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:35 step:164595[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:35 step:164600[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:35 step:164605[D loss: 0.999889] [G loss: 1.000088]\n",
      "epoch:35 step:164610[D loss: 0.999980] [G loss: 1.000024]\n",
      "epoch:35 step:164615[D loss: 0.999988] [G loss: 1.000075]\n",
      "epoch:35 step:164620[D loss: 0.999999] [G loss: 1.000071]\n",
      "epoch:35 step:164625[D loss: 0.999966] [G loss: 1.000062]\n",
      "epoch:35 step:164630[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:35 step:164635[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:35 step:164640[D loss: 0.999962] [G loss: 1.000115]\n",
      "epoch:35 step:164645[D loss: 0.999950] [G loss: 1.000071]\n",
      "epoch:35 step:164650[D loss: 0.999958] [G loss: 1.000071]\n",
      "epoch:35 step:164655[D loss: 0.999975] [G loss: 1.000045]\n",
      "epoch:35 step:164660[D loss: 0.999993] [G loss: 1.000030]\n",
      "epoch:35 step:164665[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:35 step:164670[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:35 step:164675[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:35 step:164680[D loss: 0.999974] [G loss: 1.000075]\n",
      "epoch:35 step:164685[D loss: 0.999968] [G loss: 1.000066]\n",
      "epoch:35 step:164690[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:35 step:164695[D loss: 0.999963] [G loss: 1.000060]\n",
      "epoch:35 step:164700[D loss: 0.999986] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:164705[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:35 step:164710[D loss: 0.999965] [G loss: 1.000059]\n",
      "epoch:35 step:164715[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:35 step:164720[D loss: 1.000005] [G loss: 1.000048]\n",
      "epoch:35 step:164725[D loss: 1.000072] [G loss: 0.999863]\n",
      "epoch:35 step:164730[D loss: 1.000000] [G loss: 0.999971]\n",
      "epoch:35 step:164735[D loss: 0.999954] [G loss: 1.000034]\n",
      "epoch:35 step:164740[D loss: 0.999963] [G loss: 1.000043]\n",
      "epoch:35 step:164745[D loss: 1.000096] [G loss: 0.999864]\n",
      "epoch:35 step:164750[D loss: 1.000058] [G loss: 0.999948]\n",
      "epoch:35 step:164755[D loss: 1.000060] [G loss: 1.000109]\n",
      "epoch:35 step:164760[D loss: 0.999914] [G loss: 1.000109]\n",
      "epoch:35 step:164765[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:35 step:164770[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:35 step:164775[D loss: 0.999958] [G loss: 1.000093]\n",
      "epoch:35 step:164780[D loss: 0.999994] [G loss: 1.000027]\n",
      "epoch:35 step:164785[D loss: 0.999910] [G loss: 1.000156]\n",
      "epoch:35 step:164790[D loss: 0.999971] [G loss: 1.000085]\n",
      "epoch:35 step:164795[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:35 step:164800[D loss: 1.000012] [G loss: 0.999998]\n",
      "epoch:35 step:164805[D loss: 0.999995] [G loss: 1.000010]\n",
      "epoch:35 step:164810[D loss: 0.999902] [G loss: 1.000097]\n",
      "epoch:35 step:164815[D loss: 1.000017] [G loss: 1.000070]\n",
      "epoch:35 step:164820[D loss: 0.999955] [G loss: 1.000082]\n",
      "epoch:35 step:164825[D loss: 1.000019] [G loss: 0.999980]\n",
      "epoch:35 step:164830[D loss: 0.999960] [G loss: 1.000064]\n",
      "epoch:35 step:164835[D loss: 0.999974] [G loss: 1.000020]\n",
      "epoch:35 step:164840[D loss: 0.999953] [G loss: 1.000089]\n",
      "epoch:35 step:164845[D loss: 0.999960] [G loss: 1.000072]\n",
      "epoch:35 step:164850[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:35 step:164855[D loss: 1.000003] [G loss: 1.000013]\n",
      "epoch:35 step:164860[D loss: 0.999958] [G loss: 1.000085]\n",
      "epoch:35 step:164865[D loss: 1.000019] [G loss: 0.999989]\n",
      "epoch:35 step:164870[D loss: 1.000053] [G loss: 1.000004]\n",
      "epoch:35 step:164875[D loss: 0.999908] [G loss: 1.000135]\n",
      "epoch:35 step:164880[D loss: 0.999954] [G loss: 1.000143]\n",
      "epoch:35 step:164885[D loss: 0.999968] [G loss: 1.000074]\n",
      "epoch:35 step:164890[D loss: 0.999956] [G loss: 1.000082]\n",
      "epoch:35 step:164895[D loss: 0.999986] [G loss: 1.000072]\n",
      "epoch:35 step:164900[D loss: 1.000053] [G loss: 0.999919]\n",
      "epoch:35 step:164905[D loss: 0.999962] [G loss: 1.000013]\n",
      "epoch:35 step:164910[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:35 step:164915[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:35 step:164920[D loss: 0.999908] [G loss: 1.000086]\n",
      "epoch:35 step:164925[D loss: 0.999998] [G loss: 0.999991]\n",
      "epoch:35 step:164930[D loss: 0.999993] [G loss: 1.000010]\n",
      "epoch:35 step:164935[D loss: 0.999952] [G loss: 1.000050]\n",
      "epoch:35 step:164940[D loss: 0.999984] [G loss: 1.000056]\n",
      "epoch:35 step:164945[D loss: 0.999994] [G loss: 1.000050]\n",
      "epoch:35 step:164950[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:35 step:164955[D loss: 0.999995] [G loss: 1.000133]\n",
      "epoch:35 step:164960[D loss: 1.000027] [G loss: 1.000019]\n",
      "epoch:35 step:164965[D loss: 1.000053] [G loss: 1.000054]\n",
      "epoch:35 step:164970[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:35 step:164975[D loss: 1.000070] [G loss: 1.000303]\n",
      "epoch:35 step:164980[D loss: 0.999866] [G loss: 1.000268]\n",
      "epoch:35 step:164985[D loss: 0.999950] [G loss: 1.000176]\n",
      "epoch:35 step:164990[D loss: 0.999976] [G loss: 1.000083]\n",
      "epoch:35 step:164995[D loss: 0.999992] [G loss: 0.999987]\n",
      "epoch:35 step:165000[D loss: 1.000046] [G loss: 0.999896]\n",
      "epoch:35 step:165005[D loss: 1.000080] [G loss: 0.999912]\n",
      "epoch:35 step:165010[D loss: 1.000061] [G loss: 0.999898]\n",
      "epoch:35 step:165015[D loss: 0.999789] [G loss: 1.000056]\n",
      "epoch:35 step:165020[D loss: 1.000123] [G loss: 0.999871]\n",
      "epoch:35 step:165025[D loss: 1.000294] [G loss: 0.999590]\n",
      "epoch:35 step:165030[D loss: 0.999944] [G loss: 1.000162]\n",
      "epoch:35 step:165035[D loss: 0.999920] [G loss: 1.000199]\n",
      "epoch:35 step:165040[D loss: 0.999981] [G loss: 1.000104]\n",
      "epoch:35 step:165045[D loss: 0.999961] [G loss: 1.000192]\n",
      "epoch:35 step:165050[D loss: 0.999905] [G loss: 1.000205]\n",
      "epoch:35 step:165055[D loss: 0.999922] [G loss: 1.000220]\n",
      "epoch:35 step:165060[D loss: 1.000196] [G loss: 1.000076]\n",
      "epoch:35 step:165065[D loss: 0.999844] [G loss: 1.000231]\n",
      "epoch:35 step:165070[D loss: 0.999936] [G loss: 1.000103]\n",
      "epoch:35 step:165075[D loss: 0.999954] [G loss: 1.000095]\n",
      "epoch:35 step:165080[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:35 step:165085[D loss: 1.000046] [G loss: 0.999910]\n",
      "epoch:35 step:165090[D loss: 1.000211] [G loss: 0.999647]\n",
      "epoch:35 step:165095[D loss: 0.999936] [G loss: 0.999994]\n",
      "epoch:35 step:165100[D loss: 1.000031] [G loss: 1.000082]\n",
      "epoch:35 step:165105[D loss: 1.000126] [G loss: 1.000112]\n",
      "epoch:35 step:165110[D loss: 1.000111] [G loss: 1.000097]\n",
      "epoch:35 step:165115[D loss: 0.999957] [G loss: 1.000067]\n",
      "epoch:35 step:165120[D loss: 0.999928] [G loss: 1.000073]\n",
      "epoch:35 step:165125[D loss: 1.000084] [G loss: 1.000035]\n",
      "epoch:35 step:165130[D loss: 0.999857] [G loss: 1.000269]\n",
      "epoch:35 step:165135[D loss: 0.999928] [G loss: 1.000097]\n",
      "epoch:35 step:165140[D loss: 0.999973] [G loss: 1.000093]\n",
      "epoch:35 step:165145[D loss: 1.000007] [G loss: 1.000096]\n",
      "epoch:35 step:165150[D loss: 0.999974] [G loss: 1.000174]\n",
      "epoch:35 step:165155[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:35 step:165160[D loss: 0.999993] [G loss: 1.000082]\n",
      "epoch:35 step:165165[D loss: 1.000001] [G loss: 1.000010]\n",
      "epoch:35 step:165170[D loss: 0.999936] [G loss: 1.000078]\n",
      "epoch:35 step:165175[D loss: 1.000109] [G loss: 0.999894]\n",
      "epoch:35 step:165180[D loss: 1.000200] [G loss: 0.999792]\n",
      "epoch:35 step:165185[D loss: 1.000037] [G loss: 0.999926]\n",
      "epoch:35 step:165190[D loss: 0.999897] [G loss: 1.000151]\n",
      "epoch:35 step:165195[D loss: 0.999990] [G loss: 1.000163]\n",
      "epoch:35 step:165200[D loss: 0.999959] [G loss: 1.000127]\n",
      "epoch:35 step:165205[D loss: 0.999996] [G loss: 1.000006]\n",
      "epoch:35 step:165210[D loss: 0.999990] [G loss: 1.000085]\n",
      "epoch:35 step:165215[D loss: 1.000010] [G loss: 1.000095]\n",
      "epoch:35 step:165220[D loss: 0.999975] [G loss: 1.000012]\n",
      "epoch:35 step:165225[D loss: 0.999981] [G loss: 1.000116]\n",
      "epoch:35 step:165230[D loss: 1.000074] [G loss: 1.000004]\n",
      "epoch:35 step:165235[D loss: 0.999897] [G loss: 1.000142]\n",
      "epoch:35 step:165240[D loss: 0.999976] [G loss: 1.000177]\n",
      "epoch:35 step:165245[D loss: 0.999883] [G loss: 1.000230]\n",
      "epoch:35 step:165250[D loss: 0.999950] [G loss: 1.000181]\n",
      "epoch:35 step:165255[D loss: 0.999992] [G loss: 0.999976]\n",
      "epoch:35 step:165260[D loss: 0.999947] [G loss: 1.000108]\n",
      "epoch:35 step:165265[D loss: 1.000014] [G loss: 1.000047]\n",
      "epoch:35 step:165270[D loss: 0.999966] [G loss: 1.000100]\n",
      "epoch:35 step:165275[D loss: 1.000016] [G loss: 1.000057]\n",
      "epoch:35 step:165280[D loss: 0.999940] [G loss: 1.000061]\n",
      "epoch:35 step:165285[D loss: 0.999945] [G loss: 1.000096]\n",
      "epoch:35 step:165290[D loss: 1.000134] [G loss: 0.999834]\n",
      "epoch:35 step:165295[D loss: 1.000065] [G loss: 0.999995]\n",
      "epoch:35 step:165300[D loss: 0.999975] [G loss: 1.000024]\n",
      "epoch:35 step:165305[D loss: 1.000004] [G loss: 1.000253]\n",
      "epoch:35 step:165310[D loss: 0.999840] [G loss: 1.000196]\n",
      "epoch:35 step:165315[D loss: 0.999902] [G loss: 1.000103]\n",
      "epoch:35 step:165320[D loss: 0.999956] [G loss: 1.000056]\n",
      "epoch:35 step:165325[D loss: 0.999996] [G loss: 1.000040]\n",
      "epoch:35 step:165330[D loss: 1.000025] [G loss: 0.999998]\n",
      "epoch:35 step:165335[D loss: 0.999936] [G loss: 1.000055]\n",
      "epoch:35 step:165340[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:35 step:165345[D loss: 0.999970] [G loss: 1.000063]\n",
      "epoch:35 step:165350[D loss: 1.000039] [G loss: 0.999985]\n",
      "epoch:35 step:165355[D loss: 0.999959] [G loss: 1.000118]\n",
      "epoch:35 step:165360[D loss: 0.999906] [G loss: 1.000110]\n",
      "epoch:35 step:165365[D loss: 1.000044] [G loss: 1.000044]\n",
      "epoch:35 step:165370[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:35 step:165375[D loss: 0.999968] [G loss: 1.000076]\n",
      "epoch:35 step:165380[D loss: 0.999997] [G loss: 1.000070]\n",
      "epoch:35 step:165385[D loss: 0.999987] [G loss: 1.000041]\n",
      "epoch:35 step:165390[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:35 step:165395[D loss: 0.999996] [G loss: 1.000033]\n",
      "epoch:35 step:165400[D loss: 0.999997] [G loss: 1.000050]\n",
      "epoch:35 step:165405[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:35 step:165410[D loss: 0.999944] [G loss: 1.000074]\n",
      "epoch:35 step:165415[D loss: 0.999985] [G loss: 1.000031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:165420[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:35 step:165425[D loss: 0.999940] [G loss: 1.000069]\n",
      "epoch:35 step:165430[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:35 step:165435[D loss: 0.999987] [G loss: 1.000046]\n",
      "epoch:35 step:165440[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:35 step:165445[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:35 step:165450[D loss: 1.000021] [G loss: 1.000003]\n",
      "epoch:35 step:165455[D loss: 0.999957] [G loss: 1.000094]\n",
      "epoch:35 step:165460[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:35 step:165465[D loss: 0.999996] [G loss: 0.999999]\n",
      "epoch:35 step:165470[D loss: 0.999990] [G loss: 1.000000]\n",
      "epoch:35 step:165475[D loss: 0.999947] [G loss: 1.000134]\n",
      "epoch:35 step:165480[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:35 step:165485[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:35 step:165490[D loss: 0.999993] [G loss: 1.000080]\n",
      "epoch:35 step:165495[D loss: 0.999973] [G loss: 1.000028]\n",
      "epoch:35 step:165500[D loss: 1.000007] [G loss: 1.000004]\n",
      "epoch:35 step:165505[D loss: 1.000002] [G loss: 1.000033]\n",
      "epoch:35 step:165510[D loss: 0.999955] [G loss: 1.000041]\n",
      "epoch:35 step:165515[D loss: 0.999935] [G loss: 1.000109]\n",
      "epoch:35 step:165520[D loss: 0.999969] [G loss: 1.000027]\n",
      "epoch:35 step:165525[D loss: 0.999999] [G loss: 1.000073]\n",
      "epoch:35 step:165530[D loss: 1.000037] [G loss: 0.999997]\n",
      "epoch:35 step:165535[D loss: 1.000028] [G loss: 0.999977]\n",
      "epoch:35 step:165540[D loss: 1.000013] [G loss: 0.999938]\n",
      "epoch:35 step:165545[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:35 step:165550[D loss: 0.999966] [G loss: 1.000145]\n",
      "epoch:35 step:165555[D loss: 1.000013] [G loss: 1.000108]\n",
      "epoch:35 step:165560[D loss: 1.000004] [G loss: 0.999994]\n",
      "epoch:35 step:165565[D loss: 1.000020] [G loss: 0.999942]\n",
      "epoch:35 step:165570[D loss: 1.000091] [G loss: 0.999865]\n",
      "epoch:35 step:165575[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:35 step:165580[D loss: 1.000097] [G loss: 1.000023]\n",
      "epoch:35 step:165585[D loss: 0.999983] [G loss: 1.000193]\n",
      "epoch:35 step:165590[D loss: 0.999941] [G loss: 1.000239]\n",
      "epoch:35 step:165595[D loss: 0.999895] [G loss: 1.000156]\n",
      "epoch:35 step:165600[D loss: 0.999942] [G loss: 1.000103]\n",
      "epoch:35 step:165605[D loss: 1.000057] [G loss: 0.999893]\n",
      "epoch:35 step:165610[D loss: 1.000209] [G loss: 0.999758]\n",
      "epoch:35 step:165615[D loss: 0.999943] [G loss: 1.000005]\n",
      "epoch:35 step:165620[D loss: 0.999918] [G loss: 1.000039]\n",
      "epoch:35 step:165625[D loss: 0.999876] [G loss: 1.000023]\n",
      "epoch:35 step:165630[D loss: 1.000038] [G loss: 0.999955]\n",
      "epoch:35 step:165635[D loss: 0.999878] [G loss: 1.000208]\n",
      "epoch:35 step:165640[D loss: 0.999929] [G loss: 1.000183]\n",
      "epoch:35 step:165645[D loss: 0.999890] [G loss: 1.000165]\n",
      "epoch:35 step:165650[D loss: 0.999925] [G loss: 1.000122]\n",
      "epoch:35 step:165655[D loss: 0.999987] [G loss: 1.000036]\n",
      "epoch:35 step:165660[D loss: 1.000030] [G loss: 0.999979]\n",
      "epoch:35 step:165665[D loss: 1.000013] [G loss: 0.999968]\n",
      "epoch:35 step:165670[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:35 step:165675[D loss: 1.000042] [G loss: 0.999850]\n",
      "epoch:35 step:165680[D loss: 1.000022] [G loss: 1.000048]\n",
      "epoch:35 step:165685[D loss: 1.000004] [G loss: 1.000018]\n",
      "epoch:35 step:165690[D loss: 0.999981] [G loss: 1.000022]\n",
      "epoch:35 step:165695[D loss: 0.999955] [G loss: 1.000069]\n",
      "epoch:35 step:165700[D loss: 1.000014] [G loss: 1.000059]\n",
      "epoch:35 step:165705[D loss: 0.999958] [G loss: 1.000095]\n",
      "epoch:35 step:165710[D loss: 0.999968] [G loss: 1.000067]\n",
      "epoch:35 step:165715[D loss: 0.999928] [G loss: 1.000115]\n",
      "epoch:35 step:165720[D loss: 1.000103] [G loss: 0.999989]\n",
      "epoch:35 step:165725[D loss: 0.999946] [G loss: 1.000084]\n",
      "epoch:35 step:165730[D loss: 1.000031] [G loss: 1.000067]\n",
      "epoch:35 step:165735[D loss: 1.000027] [G loss: 1.000007]\n",
      "epoch:35 step:165740[D loss: 0.999865] [G loss: 1.000231]\n",
      "epoch:35 step:165745[D loss: 0.999943] [G loss: 1.000109]\n",
      "epoch:35 step:165750[D loss: 0.999997] [G loss: 1.000030]\n",
      "epoch:35 step:165755[D loss: 0.999968] [G loss: 0.999994]\n",
      "epoch:35 step:165760[D loss: 0.999983] [G loss: 1.000055]\n",
      "epoch:35 step:165765[D loss: 1.000054] [G loss: 1.000016]\n",
      "epoch:35 step:165770[D loss: 0.999948] [G loss: 1.000049]\n",
      "epoch:35 step:165775[D loss: 1.000082] [G loss: 0.999950]\n",
      "epoch:35 step:165780[D loss: 0.999919] [G loss: 1.000194]\n",
      "epoch:35 step:165785[D loss: 0.999953] [G loss: 1.000041]\n",
      "epoch:35 step:165790[D loss: 1.000063] [G loss: 0.999955]\n",
      "epoch:35 step:165795[D loss: 1.000144] [G loss: 0.999943]\n",
      "epoch:35 step:165800[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:35 step:165805[D loss: 1.000006] [G loss: 1.000034]\n",
      "epoch:35 step:165810[D loss: 1.000043] [G loss: 1.000235]\n",
      "epoch:35 step:165815[D loss: 0.999960] [G loss: 1.000096]\n",
      "epoch:35 step:165820[D loss: 1.000009] [G loss: 0.999999]\n",
      "epoch:35 step:165825[D loss: 0.999972] [G loss: 1.000073]\n",
      "epoch:35 step:165830[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:35 step:165835[D loss: 0.999953] [G loss: 1.000066]\n",
      "epoch:35 step:165840[D loss: 1.000017] [G loss: 0.999970]\n",
      "epoch:35 step:165845[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:35 step:165850[D loss: 1.000054] [G loss: 0.999971]\n",
      "epoch:35 step:165855[D loss: 1.000092] [G loss: 0.999821]\n",
      "epoch:35 step:165860[D loss: 1.000089] [G loss: 0.999869]\n",
      "epoch:35 step:165865[D loss: 1.000260] [G loss: 0.999813]\n",
      "epoch:35 step:165870[D loss: 0.999892] [G loss: 1.000168]\n",
      "epoch:35 step:165875[D loss: 0.999892] [G loss: 1.000103]\n",
      "epoch:35 step:165880[D loss: 0.999934] [G loss: 1.000066]\n",
      "epoch:35 step:165885[D loss: 0.999980] [G loss: 1.000047]\n",
      "epoch:35 step:165890[D loss: 1.000015] [G loss: 1.000019]\n",
      "epoch:35 step:165895[D loss: 1.000014] [G loss: 1.000024]\n",
      "epoch:35 step:165900[D loss: 1.000036] [G loss: 1.000221]\n",
      "epoch:35 step:165905[D loss: 0.999901] [G loss: 1.000139]\n",
      "epoch:35 step:165910[D loss: 0.999992] [G loss: 1.000211]\n",
      "epoch:35 step:165915[D loss: 0.999961] [G loss: 1.000159]\n",
      "epoch:35 step:165920[D loss: 0.999949] [G loss: 1.000046]\n",
      "epoch:35 step:165925[D loss: 0.999991] [G loss: 1.000089]\n",
      "epoch:35 step:165930[D loss: 1.000018] [G loss: 0.999992]\n",
      "epoch:35 step:165935[D loss: 0.999930] [G loss: 1.000043]\n",
      "epoch:35 step:165940[D loss: 1.000018] [G loss: 0.999984]\n",
      "epoch:35 step:165945[D loss: 0.999975] [G loss: 1.000040]\n",
      "epoch:35 step:165950[D loss: 0.999946] [G loss: 1.000055]\n",
      "epoch:35 step:165955[D loss: 0.999962] [G loss: 1.000043]\n",
      "epoch:35 step:165960[D loss: 1.000005] [G loss: 0.999989]\n",
      "epoch:35 step:165965[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:35 step:165970[D loss: 0.999920] [G loss: 1.000046]\n",
      "epoch:35 step:165975[D loss: 1.000065] [G loss: 0.999944]\n",
      "epoch:35 step:165980[D loss: 1.000034] [G loss: 0.999930]\n",
      "epoch:35 step:165985[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:35 step:165990[D loss: 0.999960] [G loss: 1.000140]\n",
      "epoch:35 step:165995[D loss: 1.000006] [G loss: 0.999999]\n",
      "epoch:35 step:166000[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:35 step:166005[D loss: 0.999986] [G loss: 1.000003]\n",
      "epoch:35 step:166010[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:35 step:166015[D loss: 0.999953] [G loss: 1.000025]\n",
      "epoch:35 step:166020[D loss: 0.999930] [G loss: 1.000126]\n",
      "epoch:35 step:166025[D loss: 1.000151] [G loss: 1.000076]\n",
      "epoch:35 step:166030[D loss: 0.999847] [G loss: 1.000171]\n",
      "epoch:35 step:166035[D loss: 0.999953] [G loss: 1.000053]\n",
      "epoch:35 step:166040[D loss: 0.999994] [G loss: 0.999985]\n",
      "epoch:35 step:166045[D loss: 1.000058] [G loss: 0.999895]\n",
      "epoch:35 step:166050[D loss: 0.999957] [G loss: 1.000060]\n",
      "epoch:35 step:166055[D loss: 0.999976] [G loss: 1.000078]\n",
      "epoch:35 step:166060[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:35 step:166065[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:35 step:166070[D loss: 0.999973] [G loss: 1.000080]\n",
      "epoch:35 step:166075[D loss: 0.999949] [G loss: 1.000090]\n",
      "epoch:35 step:166080[D loss: 1.000025] [G loss: 1.000057]\n",
      "epoch:35 step:166085[D loss: 1.000005] [G loss: 1.000026]\n",
      "epoch:35 step:166090[D loss: 0.999919] [G loss: 1.000137]\n",
      "epoch:35 step:166095[D loss: 0.999904] [G loss: 1.000206]\n",
      "epoch:35 step:166100[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:35 step:166105[D loss: 1.000016] [G loss: 0.999990]\n",
      "epoch:35 step:166110[D loss: 0.999996] [G loss: 0.999948]\n",
      "epoch:35 step:166115[D loss: 1.000096] [G loss: 0.999902]\n",
      "epoch:35 step:166120[D loss: 0.999896] [G loss: 1.000192]\n",
      "epoch:35 step:166125[D loss: 0.999942] [G loss: 1.000103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:166130[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:35 step:166135[D loss: 1.000025] [G loss: 1.000135]\n",
      "epoch:35 step:166140[D loss: 0.999948] [G loss: 1.000146]\n",
      "epoch:35 step:166145[D loss: 1.000009] [G loss: 1.000048]\n",
      "epoch:35 step:166150[D loss: 0.999982] [G loss: 1.000033]\n",
      "epoch:35 step:166155[D loss: 1.000037] [G loss: 0.999989]\n",
      "epoch:35 step:166160[D loss: 0.999928] [G loss: 1.000113]\n",
      "epoch:35 step:166165[D loss: 0.999938] [G loss: 1.000121]\n",
      "epoch:35 step:166170[D loss: 0.999952] [G loss: 1.000050]\n",
      "epoch:35 step:166175[D loss: 1.000005] [G loss: 1.000052]\n",
      "epoch:35 step:166180[D loss: 1.000014] [G loss: 1.000014]\n",
      "epoch:35 step:166185[D loss: 0.999941] [G loss: 1.000143]\n",
      "epoch:35 step:166190[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:35 step:166195[D loss: 0.999954] [G loss: 1.000104]\n",
      "epoch:35 step:166200[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:35 step:166205[D loss: 0.999999] [G loss: 1.000103]\n",
      "epoch:35 step:166210[D loss: 0.999975] [G loss: 1.000096]\n",
      "epoch:35 step:166215[D loss: 0.999964] [G loss: 1.000138]\n",
      "epoch:35 step:166220[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:35 step:166225[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:35 step:166230[D loss: 0.999991] [G loss: 1.000076]\n",
      "epoch:35 step:166235[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:35 step:166240[D loss: 1.000019] [G loss: 0.999981]\n",
      "epoch:35 step:166245[D loss: 1.000010] [G loss: 1.000044]\n",
      "epoch:35 step:166250[D loss: 0.999931] [G loss: 1.000115]\n",
      "epoch:35 step:166255[D loss: 0.999963] [G loss: 1.000048]\n",
      "epoch:35 step:166260[D loss: 1.000006] [G loss: 1.000044]\n",
      "epoch:35 step:166265[D loss: 0.999953] [G loss: 1.000160]\n",
      "epoch:35 step:166270[D loss: 1.000141] [G loss: 1.000235]\n",
      "epoch:35 step:166275[D loss: 0.999991] [G loss: 1.000006]\n",
      "epoch:35 step:166280[D loss: 0.999904] [G loss: 1.000203]\n",
      "epoch:35 step:166285[D loss: 0.999936] [G loss: 1.000079]\n",
      "epoch:35 step:166290[D loss: 0.999993] [G loss: 0.999990]\n",
      "epoch:35 step:166295[D loss: 1.000019] [G loss: 1.000004]\n",
      "epoch:35 step:166300[D loss: 1.000100] [G loss: 0.999780]\n",
      "epoch:35 step:166305[D loss: 0.999985] [G loss: 0.999942]\n",
      "epoch:35 step:166310[D loss: 0.999951] [G loss: 1.000056]\n",
      "epoch:35 step:166315[D loss: 1.000025] [G loss: 1.000114]\n",
      "epoch:35 step:166320[D loss: 1.000173] [G loss: 0.999881]\n",
      "epoch:35 step:166325[D loss: 0.999868] [G loss: 1.000205]\n",
      "epoch:35 step:166330[D loss: 0.999976] [G loss: 1.000157]\n",
      "epoch:35 step:166335[D loss: 0.999913] [G loss: 1.000152]\n",
      "epoch:35 step:166340[D loss: 1.000012] [G loss: 0.999992]\n",
      "epoch:35 step:166345[D loss: 1.000125] [G loss: 0.999791]\n",
      "epoch:35 step:166350[D loss: 0.999954] [G loss: 0.999935]\n",
      "epoch:35 step:166355[D loss: 1.000148] [G loss: 0.999788]\n",
      "epoch:35 step:166360[D loss: 0.999899] [G loss: 1.000044]\n",
      "epoch:35 step:166365[D loss: 1.000181] [G loss: 0.999693]\n",
      "epoch:35 step:166370[D loss: 1.000005] [G loss: 0.999913]\n",
      "epoch:35 step:166375[D loss: 1.000055] [G loss: 0.999943]\n",
      "epoch:35 step:166380[D loss: 0.999876] [G loss: 1.000267]\n",
      "epoch:35 step:166385[D loss: 0.999912] [G loss: 1.000101]\n",
      "epoch:35 step:166390[D loss: 0.999990] [G loss: 1.000136]\n",
      "epoch:35 step:166395[D loss: 0.999957] [G loss: 1.000130]\n",
      "epoch:35 step:166400[D loss: 1.000198] [G loss: 0.999932]\n",
      "epoch:35 step:166405[D loss: 0.999927] [G loss: 1.000121]\n",
      "epoch:35 step:166410[D loss: 1.000016] [G loss: 1.000039]\n",
      "epoch:35 step:166415[D loss: 1.000062] [G loss: 1.000059]\n",
      "epoch:35 step:166420[D loss: 1.000021] [G loss: 1.000208]\n",
      "epoch:35 step:166425[D loss: 0.999901] [G loss: 1.000250]\n",
      "epoch:35 step:166430[D loss: 0.999874] [G loss: 1.000300]\n",
      "epoch:35 step:166435[D loss: 0.999945] [G loss: 1.000270]\n",
      "epoch:35 step:166440[D loss: 0.999973] [G loss: 1.000406]\n",
      "epoch:35 step:166445[D loss: 0.999930] [G loss: 1.000339]\n",
      "epoch:35 step:166450[D loss: 0.999905] [G loss: 1.000179]\n",
      "epoch:35 step:166455[D loss: 1.000099] [G loss: 1.000156]\n",
      "epoch:35 step:166460[D loss: 0.999960] [G loss: 1.000164]\n",
      "epoch:35 step:166465[D loss: 0.999972] [G loss: 1.000047]\n",
      "epoch:35 step:166470[D loss: 1.000178] [G loss: 0.999782]\n",
      "epoch:35 step:166475[D loss: 1.000273] [G loss: 0.999693]\n",
      "epoch:35 step:166480[D loss: 0.999996] [G loss: 0.999782]\n",
      "epoch:35 step:166485[D loss: 1.000045] [G loss: 0.999820]\n",
      "epoch:35 step:166490[D loss: 0.999936] [G loss: 0.999973]\n",
      "epoch:35 step:166495[D loss: 1.000046] [G loss: 0.999874]\n",
      "epoch:35 step:166500[D loss: 0.999932] [G loss: 1.000081]\n",
      "epoch:35 step:166505[D loss: 0.999966] [G loss: 1.000044]\n",
      "epoch:35 step:166510[D loss: 1.000137] [G loss: 0.999942]\n",
      "epoch:35 step:166515[D loss: 1.000045] [G loss: 1.000101]\n",
      "epoch:35 step:166520[D loss: 1.000027] [G loss: 1.000082]\n",
      "epoch:35 step:166525[D loss: 0.999909] [G loss: 1.000570]\n",
      "epoch:35 step:166530[D loss: 0.999840] [G loss: 1.000232]\n",
      "epoch:35 step:166535[D loss: 0.999911] [G loss: 1.000082]\n",
      "epoch:35 step:166540[D loss: 1.000003] [G loss: 1.000032]\n",
      "epoch:35 step:166545[D loss: 1.000094] [G loss: 0.999819]\n",
      "epoch:35 step:166550[D loss: 1.000019] [G loss: 0.999823]\n",
      "epoch:35 step:166555[D loss: 0.999943] [G loss: 1.000002]\n",
      "epoch:35 step:166560[D loss: 1.000243] [G loss: 0.999928]\n",
      "epoch:35 step:166565[D loss: 0.999945] [G loss: 1.000105]\n",
      "epoch:35 step:166570[D loss: 0.999953] [G loss: 1.000158]\n",
      "epoch:35 step:166575[D loss: 1.000015] [G loss: 1.000078]\n",
      "epoch:35 step:166580[D loss: 0.999934] [G loss: 1.000247]\n",
      "epoch:35 step:166585[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:35 step:166590[D loss: 0.999963] [G loss: 1.000084]\n",
      "epoch:35 step:166595[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:35 step:166600[D loss: 1.000138] [G loss: 0.999813]\n",
      "epoch:35 step:166605[D loss: 1.000107] [G loss: 0.999930]\n",
      "epoch:35 step:166610[D loss: 0.999961] [G loss: 1.000017]\n",
      "epoch:35 step:166615[D loss: 0.999917] [G loss: 1.000072]\n",
      "epoch:35 step:166620[D loss: 0.999960] [G loss: 1.000018]\n",
      "epoch:35 step:166625[D loss: 1.000003] [G loss: 1.000006]\n",
      "epoch:35 step:166630[D loss: 0.999962] [G loss: 1.000099]\n",
      "epoch:35 step:166635[D loss: 0.999972] [G loss: 1.000081]\n",
      "epoch:35 step:166640[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:35 step:166645[D loss: 1.000018] [G loss: 1.000049]\n",
      "epoch:35 step:166650[D loss: 0.999971] [G loss: 1.000036]\n",
      "epoch:35 step:166655[D loss: 1.000112] [G loss: 1.000016]\n",
      "epoch:35 step:166660[D loss: 1.000017] [G loss: 1.000182]\n",
      "epoch:35 step:166665[D loss: 1.000065] [G loss: 1.000012]\n",
      "epoch:35 step:166670[D loss: 0.999992] [G loss: 1.000098]\n",
      "epoch:35 step:166675[D loss: 0.999936] [G loss: 1.000180]\n",
      "epoch:35 step:166680[D loss: 0.999928] [G loss: 1.000130]\n",
      "epoch:35 step:166685[D loss: 0.999968] [G loss: 1.000020]\n",
      "epoch:35 step:166690[D loss: 1.000302] [G loss: 0.999704]\n",
      "epoch:35 step:166695[D loss: 0.999997] [G loss: 0.999819]\n",
      "epoch:35 step:166700[D loss: 0.999998] [G loss: 1.000107]\n",
      "epoch:35 step:166705[D loss: 0.999992] [G loss: 1.000023]\n",
      "epoch:35 step:166710[D loss: 0.999979] [G loss: 0.999946]\n",
      "epoch:35 step:166715[D loss: 0.999975] [G loss: 1.000081]\n",
      "epoch:35 step:166720[D loss: 0.999904] [G loss: 1.000173]\n",
      "epoch:35 step:166725[D loss: 1.000064] [G loss: 0.999952]\n",
      "epoch:35 step:166730[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:35 step:166735[D loss: 0.999953] [G loss: 1.000115]\n",
      "epoch:35 step:166740[D loss: 1.000049] [G loss: 0.999949]\n",
      "epoch:35 step:166745[D loss: 0.999936] [G loss: 1.000020]\n",
      "epoch:35 step:166750[D loss: 1.000039] [G loss: 0.999923]\n",
      "epoch:35 step:166755[D loss: 1.000035] [G loss: 0.999926]\n",
      "epoch:35 step:166760[D loss: 0.999905] [G loss: 1.000167]\n",
      "epoch:35 step:166765[D loss: 0.999982] [G loss: 1.000139]\n",
      "epoch:35 step:166770[D loss: 0.999975] [G loss: 1.000009]\n",
      "epoch:35 step:166775[D loss: 0.999968] [G loss: 1.000052]\n",
      "epoch:35 step:166780[D loss: 0.999925] [G loss: 1.000123]\n",
      "epoch:35 step:166785[D loss: 0.999970] [G loss: 1.000071]\n",
      "epoch:35 step:166790[D loss: 1.000004] [G loss: 1.000048]\n",
      "epoch:35 step:166795[D loss: 0.999944] [G loss: 1.000080]\n",
      "epoch:35 step:166800[D loss: 0.999956] [G loss: 1.000115]\n",
      "epoch:35 step:166805[D loss: 0.999931] [G loss: 1.000113]\n",
      "epoch:35 step:166810[D loss: 0.999960] [G loss: 1.000128]\n",
      "epoch:35 step:166815[D loss: 0.999951] [G loss: 1.000118]\n",
      "epoch:35 step:166820[D loss: 0.999993] [G loss: 1.000111]\n",
      "epoch:35 step:166825[D loss: 0.999975] [G loss: 1.000100]\n",
      "epoch:35 step:166830[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:35 step:166835[D loss: 0.999967] [G loss: 1.000073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:166840[D loss: 1.000082] [G loss: 1.000073]\n",
      "epoch:35 step:166845[D loss: 0.999931] [G loss: 1.000079]\n",
      "epoch:35 step:166850[D loss: 1.000043] [G loss: 1.000094]\n",
      "epoch:35 step:166855[D loss: 0.999986] [G loss: 1.000097]\n",
      "epoch:35 step:166860[D loss: 0.999946] [G loss: 1.000030]\n",
      "epoch:35 step:166865[D loss: 0.999943] [G loss: 1.000208]\n",
      "epoch:35 step:166870[D loss: 0.999925] [G loss: 1.000106]\n",
      "epoch:35 step:166875[D loss: 0.999995] [G loss: 1.000200]\n",
      "epoch:35 step:166880[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:35 step:166885[D loss: 0.999994] [G loss: 0.999999]\n",
      "epoch:35 step:166890[D loss: 1.000023] [G loss: 0.999946]\n",
      "epoch:35 step:166895[D loss: 0.999956] [G loss: 0.999974]\n",
      "epoch:35 step:166900[D loss: 0.999949] [G loss: 1.000094]\n",
      "epoch:35 step:166905[D loss: 1.000064] [G loss: 0.999923]\n",
      "epoch:35 step:166910[D loss: 0.999940] [G loss: 1.000107]\n",
      "epoch:35 step:166915[D loss: 0.999996] [G loss: 1.000126]\n",
      "epoch:35 step:166920[D loss: 1.000024] [G loss: 1.000153]\n",
      "epoch:35 step:166925[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:35 step:166930[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:35 step:166935[D loss: 1.000074] [G loss: 0.999922]\n",
      "epoch:35 step:166940[D loss: 1.000146] [G loss: 0.999751]\n",
      "epoch:35 step:166945[D loss: 1.000094] [G loss: 0.999829]\n",
      "epoch:35 step:166950[D loss: 1.000308] [G loss: 0.999844]\n",
      "epoch:35 step:166955[D loss: 1.000032] [G loss: 0.999943]\n",
      "epoch:35 step:166960[D loss: 0.999900] [G loss: 1.000069]\n",
      "epoch:35 step:166965[D loss: 0.999943] [G loss: 1.000168]\n",
      "epoch:35 step:166970[D loss: 0.999993] [G loss: 1.000085]\n",
      "epoch:35 step:166975[D loss: 0.999942] [G loss: 1.000187]\n",
      "epoch:35 step:166980[D loss: 1.000060] [G loss: 0.999945]\n",
      "epoch:35 step:166985[D loss: 1.000051] [G loss: 0.999931]\n",
      "epoch:35 step:166990[D loss: 1.000047] [G loss: 0.999891]\n",
      "epoch:35 step:166995[D loss: 0.999978] [G loss: 1.000051]\n",
      "epoch:35 step:167000[D loss: 1.000032] [G loss: 0.999846]\n",
      "epoch:35 step:167005[D loss: 0.999926] [G loss: 1.000057]\n",
      "epoch:35 step:167010[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:35 step:167015[D loss: 0.999965] [G loss: 1.000057]\n",
      "epoch:35 step:167020[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:35 step:167025[D loss: 0.999984] [G loss: 1.000016]\n",
      "epoch:35 step:167030[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:35 step:167035[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:35 step:167040[D loss: 0.999967] [G loss: 1.000015]\n",
      "epoch:35 step:167045[D loss: 1.000006] [G loss: 0.999958]\n",
      "epoch:35 step:167050[D loss: 0.999989] [G loss: 1.000023]\n",
      "epoch:35 step:167055[D loss: 0.999974] [G loss: 1.000031]\n",
      "epoch:35 step:167060[D loss: 1.000015] [G loss: 1.000022]\n",
      "epoch:35 step:167065[D loss: 1.000038] [G loss: 0.999901]\n",
      "epoch:35 step:167070[D loss: 0.999942] [G loss: 1.000039]\n",
      "epoch:35 step:167075[D loss: 1.000036] [G loss: 1.000083]\n",
      "epoch:35 step:167080[D loss: 0.999955] [G loss: 1.000053]\n",
      "epoch:35 step:167085[D loss: 0.999959] [G loss: 1.000143]\n",
      "epoch:35 step:167090[D loss: 0.999966] [G loss: 1.000109]\n",
      "epoch:35 step:167095[D loss: 0.999998] [G loss: 1.000017]\n",
      "epoch:35 step:167100[D loss: 0.999989] [G loss: 1.000136]\n",
      "epoch:35 step:167105[D loss: 0.999970] [G loss: 1.000036]\n",
      "epoch:35 step:167110[D loss: 1.000149] [G loss: 0.999894]\n",
      "epoch:35 step:167115[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:35 step:167120[D loss: 0.999987] [G loss: 0.999946]\n",
      "epoch:35 step:167125[D loss: 1.000066] [G loss: 1.000002]\n",
      "epoch:35 step:167130[D loss: 0.999975] [G loss: 1.000084]\n",
      "epoch:35 step:167135[D loss: 0.999944] [G loss: 1.000128]\n",
      "epoch:35 step:167140[D loss: 0.999949] [G loss: 1.000082]\n",
      "epoch:35 step:167145[D loss: 0.999983] [G loss: 1.000010]\n",
      "epoch:35 step:167150[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:35 step:167155[D loss: 1.000134] [G loss: 0.999969]\n",
      "epoch:35 step:167160[D loss: 1.000135] [G loss: 0.999943]\n",
      "epoch:35 step:167165[D loss: 0.999883] [G loss: 1.000124]\n",
      "epoch:35 step:167170[D loss: 0.999951] [G loss: 1.000050]\n",
      "epoch:35 step:167175[D loss: 0.999965] [G loss: 1.000095]\n",
      "epoch:35 step:167180[D loss: 0.999960] [G loss: 1.000157]\n",
      "epoch:35 step:167185[D loss: 0.999965] [G loss: 1.000052]\n",
      "epoch:35 step:167190[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:35 step:167195[D loss: 0.999981] [G loss: 0.999999]\n",
      "epoch:35 step:167200[D loss: 0.999996] [G loss: 1.000074]\n",
      "epoch:35 step:167205[D loss: 1.000071] [G loss: 0.999957]\n",
      "epoch:35 step:167210[D loss: 0.999863] [G loss: 1.000119]\n",
      "epoch:35 step:167215[D loss: 0.999989] [G loss: 1.000055]\n",
      "epoch:35 step:167220[D loss: 1.000059] [G loss: 1.000024]\n",
      "epoch:35 step:167225[D loss: 0.999978] [G loss: 1.000035]\n",
      "epoch:35 step:167230[D loss: 1.000035] [G loss: 1.000050]\n",
      "epoch:35 step:167235[D loss: 0.999917] [G loss: 1.000099]\n",
      "epoch:35 step:167240[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:35 step:167245[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:35 step:167250[D loss: 0.999967] [G loss: 1.000052]\n",
      "epoch:35 step:167255[D loss: 1.000044] [G loss: 1.000045]\n",
      "epoch:35 step:167260[D loss: 1.000025] [G loss: 0.999994]\n",
      "epoch:35 step:167265[D loss: 0.999937] [G loss: 1.000076]\n",
      "epoch:35 step:167270[D loss: 1.000015] [G loss: 1.000072]\n",
      "epoch:35 step:167275[D loss: 0.999946] [G loss: 1.000066]\n",
      "epoch:35 step:167280[D loss: 0.999928] [G loss: 1.000137]\n",
      "epoch:35 step:167285[D loss: 1.000124] [G loss: 0.999942]\n",
      "epoch:35 step:167290[D loss: 1.000112] [G loss: 0.999921]\n",
      "epoch:35 step:167295[D loss: 0.999915] [G loss: 1.000054]\n",
      "epoch:35 step:167300[D loss: 0.999997] [G loss: 1.000029]\n",
      "epoch:35 step:167305[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:35 step:167310[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:35 step:167315[D loss: 0.999989] [G loss: 1.000011]\n",
      "epoch:35 step:167320[D loss: 0.999975] [G loss: 1.000052]\n",
      "epoch:35 step:167325[D loss: 0.999945] [G loss: 1.000048]\n",
      "epoch:35 step:167330[D loss: 0.999992] [G loss: 1.000041]\n",
      "epoch:35 step:167335[D loss: 0.999973] [G loss: 1.000035]\n",
      "epoch:35 step:167340[D loss: 0.999981] [G loss: 0.999998]\n",
      "epoch:35 step:167345[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:35 step:167350[D loss: 0.999942] [G loss: 1.000087]\n",
      "epoch:35 step:167355[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:35 step:167360[D loss: 0.999992] [G loss: 1.000069]\n",
      "epoch:35 step:167365[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:35 step:167370[D loss: 1.000014] [G loss: 0.999995]\n",
      "epoch:35 step:167375[D loss: 0.999979] [G loss: 1.000036]\n",
      "epoch:35 step:167380[D loss: 0.999968] [G loss: 1.000038]\n",
      "epoch:35 step:167385[D loss: 1.000011] [G loss: 1.000032]\n",
      "epoch:35 step:167390[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:35 step:167395[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:35 step:167400[D loss: 0.999996] [G loss: 1.000029]\n",
      "epoch:35 step:167405[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:35 step:167410[D loss: 0.999974] [G loss: 1.000098]\n",
      "epoch:35 step:167415[D loss: 0.999976] [G loss: 1.000136]\n",
      "epoch:35 step:167420[D loss: 0.999988] [G loss: 1.000079]\n",
      "epoch:35 step:167425[D loss: 0.999936] [G loss: 1.000111]\n",
      "epoch:35 step:167430[D loss: 0.999943] [G loss: 1.000085]\n",
      "epoch:35 step:167435[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:35 step:167440[D loss: 1.000069] [G loss: 0.999986]\n",
      "epoch:35 step:167445[D loss: 1.000085] [G loss: 0.999845]\n",
      "epoch:35 step:167450[D loss: 0.999895] [G loss: 1.000099]\n",
      "epoch:35 step:167455[D loss: 0.999992] [G loss: 1.000064]\n",
      "epoch:35 step:167460[D loss: 0.999917] [G loss: 1.000097]\n",
      "epoch:35 step:167465[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:35 step:167470[D loss: 1.000029] [G loss: 0.999956]\n",
      "epoch:35 step:167475[D loss: 0.999997] [G loss: 1.000012]\n",
      "epoch:35 step:167480[D loss: 1.000017] [G loss: 1.000063]\n",
      "epoch:35 step:167485[D loss: 0.999995] [G loss: 1.000052]\n",
      "epoch:35 step:167490[D loss: 1.000033] [G loss: 1.000003]\n",
      "epoch:35 step:167495[D loss: 0.999947] [G loss: 1.000159]\n",
      "epoch:35 step:167500[D loss: 1.000074] [G loss: 0.999952]\n",
      "epoch:35 step:167505[D loss: 0.999990] [G loss: 1.000119]\n",
      "epoch:35 step:167510[D loss: 0.999956] [G loss: 1.000101]\n",
      "epoch:35 step:167515[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:35 step:167520[D loss: 1.000182] [G loss: 0.999995]\n",
      "epoch:35 step:167525[D loss: 1.000258] [G loss: 0.999775]\n",
      "epoch:35 step:167530[D loss: 1.000058] [G loss: 0.999972]\n",
      "epoch:35 step:167535[D loss: 0.999862] [G loss: 1.000217]\n",
      "epoch:35 step:167540[D loss: 0.999973] [G loss: 1.000074]\n",
      "epoch:35 step:167545[D loss: 1.000074] [G loss: 1.000059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:167550[D loss: 0.999931] [G loss: 1.000173]\n",
      "epoch:35 step:167555[D loss: 1.000021] [G loss: 0.999992]\n",
      "epoch:35 step:167560[D loss: 1.000054] [G loss: 0.999950]\n",
      "epoch:35 step:167565[D loss: 1.000018] [G loss: 0.999979]\n",
      "epoch:35 step:167570[D loss: 1.000058] [G loss: 1.000079]\n",
      "epoch:35 step:167575[D loss: 0.999908] [G loss: 1.000104]\n",
      "epoch:35 step:167580[D loss: 0.999931] [G loss: 1.000155]\n",
      "epoch:35 step:167585[D loss: 0.999959] [G loss: 1.000180]\n",
      "epoch:35 step:167590[D loss: 0.999958] [G loss: 1.000140]\n",
      "epoch:35 step:167595[D loss: 0.999957] [G loss: 1.000106]\n",
      "epoch:35 step:167600[D loss: 0.999949] [G loss: 1.000143]\n",
      "epoch:35 step:167605[D loss: 1.000041] [G loss: 0.999972]\n",
      "epoch:35 step:167610[D loss: 0.999973] [G loss: 0.999974]\n",
      "epoch:35 step:167615[D loss: 1.000136] [G loss: 0.999889]\n",
      "epoch:35 step:167620[D loss: 0.999925] [G loss: 1.000060]\n",
      "epoch:35 step:167625[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:35 step:167630[D loss: 1.000005] [G loss: 1.000028]\n",
      "epoch:35 step:167635[D loss: 0.999966] [G loss: 1.000053]\n",
      "epoch:35 step:167640[D loss: 0.999988] [G loss: 1.000049]\n",
      "epoch:35 step:167645[D loss: 0.999980] [G loss: 1.000005]\n",
      "epoch:35 step:167650[D loss: 0.999983] [G loss: 1.000044]\n",
      "epoch:35 step:167655[D loss: 0.999979] [G loss: 1.000069]\n",
      "epoch:35 step:167660[D loss: 0.999998] [G loss: 1.000154]\n",
      "epoch:35 step:167665[D loss: 0.999925] [G loss: 1.000121]\n",
      "epoch:35 step:167670[D loss: 1.000048] [G loss: 1.000164]\n",
      "epoch:35 step:167675[D loss: 0.999996] [G loss: 0.999982]\n",
      "epoch:35 step:167680[D loss: 0.999938] [G loss: 1.000071]\n",
      "epoch:35 step:167685[D loss: 1.000231] [G loss: 0.999744]\n",
      "epoch:35 step:167690[D loss: 0.999902] [G loss: 1.000057]\n",
      "epoch:35 step:167695[D loss: 0.999974] [G loss: 1.000051]\n",
      "epoch:35 step:167700[D loss: 0.999970] [G loss: 1.000055]\n",
      "epoch:35 step:167705[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:35 step:167710[D loss: 1.000001] [G loss: 1.000026]\n",
      "epoch:35 step:167715[D loss: 0.999973] [G loss: 1.000065]\n",
      "epoch:35 step:167720[D loss: 0.999937] [G loss: 1.000075]\n",
      "epoch:35 step:167725[D loss: 1.000035] [G loss: 1.000058]\n",
      "epoch:35 step:167730[D loss: 1.000008] [G loss: 1.000006]\n",
      "epoch:35 step:167735[D loss: 0.999988] [G loss: 1.000037]\n",
      "epoch:35 step:167740[D loss: 0.999968] [G loss: 1.000070]\n",
      "epoch:35 step:167745[D loss: 1.000033] [G loss: 1.000078]\n",
      "epoch:35 step:167750[D loss: 0.999979] [G loss: 1.000106]\n",
      "epoch:35 step:167755[D loss: 1.000052] [G loss: 1.000020]\n",
      "epoch:35 step:167760[D loss: 1.000144] [G loss: 0.999749]\n",
      "epoch:35 step:167765[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:35 step:167770[D loss: 0.999790] [G loss: 1.000210]\n",
      "epoch:35 step:167775[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:35 step:167780[D loss: 1.000092] [G loss: 1.000030]\n",
      "epoch:35 step:167785[D loss: 1.000021] [G loss: 1.000299]\n",
      "epoch:35 step:167790[D loss: 0.999929] [G loss: 1.000163]\n",
      "epoch:35 step:167795[D loss: 0.999960] [G loss: 1.000094]\n",
      "epoch:35 step:167800[D loss: 0.999997] [G loss: 1.000054]\n",
      "epoch:35 step:167805[D loss: 0.999948] [G loss: 1.000069]\n",
      "epoch:35 step:167810[D loss: 0.999958] [G loss: 1.000060]\n",
      "epoch:35 step:167815[D loss: 0.999964] [G loss: 1.000081]\n",
      "epoch:35 step:167820[D loss: 0.999997] [G loss: 0.999990]\n",
      "epoch:35 step:167825[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:35 step:167830[D loss: 1.000113] [G loss: 0.999862]\n",
      "epoch:35 step:167835[D loss: 1.000162] [G loss: 0.999904]\n",
      "epoch:35 step:167840[D loss: 0.999726] [G loss: 1.000343]\n",
      "epoch:35 step:167845[D loss: 1.000050] [G loss: 1.000105]\n",
      "epoch:35 step:167850[D loss: 0.999960] [G loss: 1.000040]\n",
      "epoch:35 step:167855[D loss: 0.999941] [G loss: 1.000173]\n",
      "epoch:35 step:167860[D loss: 1.000029] [G loss: 0.999977]\n",
      "epoch:35 step:167865[D loss: 1.000055] [G loss: 0.999977]\n",
      "epoch:35 step:167870[D loss: 1.000045] [G loss: 1.000186]\n",
      "epoch:35 step:167875[D loss: 0.999840] [G loss: 1.000252]\n",
      "epoch:35 step:167880[D loss: 0.999941] [G loss: 1.000089]\n",
      "epoch:35 step:167885[D loss: 0.999982] [G loss: 1.000085]\n",
      "epoch:35 step:167890[D loss: 0.999970] [G loss: 1.000095]\n",
      "epoch:35 step:167895[D loss: 0.999941] [G loss: 1.000085]\n",
      "epoch:35 step:167900[D loss: 0.999936] [G loss: 1.000105]\n",
      "epoch:35 step:167905[D loss: 0.999933] [G loss: 1.000123]\n",
      "epoch:35 step:167910[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:35 step:167915[D loss: 0.999997] [G loss: 1.000118]\n",
      "epoch:35 step:167920[D loss: 1.000059] [G loss: 1.000104]\n",
      "epoch:35 step:167925[D loss: 0.999883] [G loss: 1.000112]\n",
      "epoch:35 step:167930[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:35 step:167935[D loss: 0.999967] [G loss: 1.000068]\n",
      "epoch:35 step:167940[D loss: 0.999953] [G loss: 1.000061]\n",
      "epoch:35 step:167945[D loss: 1.000019] [G loss: 1.000012]\n",
      "epoch:35 step:167950[D loss: 1.000140] [G loss: 0.999894]\n",
      "epoch:35 step:167955[D loss: 1.000043] [G loss: 0.999972]\n",
      "epoch:35 step:167960[D loss: 0.999876] [G loss: 1.000199]\n",
      "epoch:35 step:167965[D loss: 0.999917] [G loss: 1.000278]\n",
      "epoch:35 step:167970[D loss: 0.999919] [G loss: 1.000148]\n",
      "epoch:35 step:167975[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:35 step:167980[D loss: 1.000032] [G loss: 1.000010]\n",
      "epoch:35 step:167985[D loss: 1.000010] [G loss: 0.999987]\n",
      "epoch:35 step:167990[D loss: 0.999947] [G loss: 1.000114]\n",
      "epoch:35 step:167995[D loss: 0.999998] [G loss: 1.000079]\n",
      "epoch:35 step:168000[D loss: 1.000112] [G loss: 0.999946]\n",
      "epoch:35 step:168005[D loss: 0.999956] [G loss: 1.000124]\n",
      "epoch:35 step:168010[D loss: 0.999993] [G loss: 1.000099]\n",
      "epoch:35 step:168015[D loss: 1.000151] [G loss: 1.000074]\n",
      "epoch:35 step:168020[D loss: 0.999914] [G loss: 1.000153]\n",
      "epoch:35 step:168025[D loss: 0.999948] [G loss: 1.000095]\n",
      "epoch:35 step:168030[D loss: 0.999969] [G loss: 1.000028]\n",
      "epoch:35 step:168035[D loss: 1.000020] [G loss: 0.999907]\n",
      "epoch:35 step:168040[D loss: 0.999856] [G loss: 1.000238]\n",
      "epoch:35 step:168045[D loss: 1.000075] [G loss: 0.999973]\n",
      "epoch:35 step:168050[D loss: 0.999892] [G loss: 1.000129]\n",
      "epoch:35 step:168055[D loss: 0.999943] [G loss: 1.000140]\n",
      "epoch:35 step:168060[D loss: 0.999952] [G loss: 1.000093]\n",
      "epoch:35 step:168065[D loss: 1.000100] [G loss: 1.000004]\n",
      "epoch:35 step:168070[D loss: 0.999912] [G loss: 1.000114]\n",
      "epoch:35 step:168075[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:35 step:168080[D loss: 0.999964] [G loss: 1.000118]\n",
      "epoch:35 step:168085[D loss: 0.999961] [G loss: 1.000111]\n",
      "epoch:35 step:168090[D loss: 0.999955] [G loss: 1.000097]\n",
      "epoch:35 step:168095[D loss: 0.999977] [G loss: 1.000087]\n",
      "epoch:35 step:168100[D loss: 0.999988] [G loss: 1.000124]\n",
      "epoch:35 step:168105[D loss: 1.000022] [G loss: 1.000007]\n",
      "epoch:35 step:168110[D loss: 0.999965] [G loss: 1.000106]\n",
      "epoch:35 step:168115[D loss: 0.999987] [G loss: 1.000087]\n",
      "epoch:35 step:168120[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:35 step:168125[D loss: 1.000059] [G loss: 0.999968]\n",
      "epoch:35 step:168130[D loss: 1.000023] [G loss: 1.000015]\n",
      "epoch:35 step:168135[D loss: 1.000055] [G loss: 1.000006]\n",
      "epoch:35 step:168140[D loss: 0.999883] [G loss: 1.000190]\n",
      "epoch:35 step:168145[D loss: 0.999994] [G loss: 1.000185]\n",
      "epoch:35 step:168150[D loss: 0.999938] [G loss: 1.000123]\n",
      "epoch:35 step:168155[D loss: 0.999977] [G loss: 1.000060]\n",
      "epoch:35 step:168160[D loss: 0.999982] [G loss: 1.000043]\n",
      "epoch:35 step:168165[D loss: 0.999927] [G loss: 1.000061]\n",
      "epoch:35 step:168170[D loss: 0.999980] [G loss: 1.000038]\n",
      "epoch:35 step:168175[D loss: 0.999976] [G loss: 1.000085]\n",
      "epoch:35 step:168180[D loss: 0.999999] [G loss: 1.000095]\n",
      "epoch:35 step:168185[D loss: 0.999962] [G loss: 1.000113]\n",
      "epoch:35 step:168190[D loss: 0.999986] [G loss: 1.000048]\n",
      "epoch:35 step:168195[D loss: 0.999987] [G loss: 1.000179]\n",
      "epoch:35 step:168200[D loss: 0.999959] [G loss: 1.000140]\n",
      "epoch:35 step:168205[D loss: 0.999972] [G loss: 1.000076]\n",
      "epoch:35 step:168210[D loss: 0.999987] [G loss: 1.000028]\n",
      "epoch:35 step:168215[D loss: 0.999952] [G loss: 1.000051]\n",
      "epoch:35 step:168220[D loss: 1.000020] [G loss: 1.000065]\n",
      "epoch:35 step:168225[D loss: 0.999940] [G loss: 1.000092]\n",
      "epoch:35 step:168230[D loss: 0.999969] [G loss: 1.000112]\n",
      "epoch:35 step:168235[D loss: 1.000015] [G loss: 1.000011]\n",
      "epoch:35 step:168240[D loss: 1.000137] [G loss: 0.999900]\n",
      "epoch:35 step:168245[D loss: 0.999912] [G loss: 1.000125]\n",
      "epoch:35 step:168250[D loss: 0.999936] [G loss: 1.000097]\n",
      "epoch:35 step:168255[D loss: 0.999951] [G loss: 1.000189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:168260[D loss: 0.999905] [G loss: 1.000140]\n",
      "epoch:35 step:168265[D loss: 0.999924] [G loss: 1.000127]\n",
      "epoch:35 step:168270[D loss: 1.000002] [G loss: 1.000093]\n",
      "epoch:35 step:168275[D loss: 1.000012] [G loss: 1.000048]\n",
      "epoch:35 step:168280[D loss: 1.000025] [G loss: 0.999952]\n",
      "epoch:35 step:168285[D loss: 1.000018] [G loss: 1.000000]\n",
      "epoch:35 step:168290[D loss: 0.999930] [G loss: 1.000106]\n",
      "epoch:35 step:168295[D loss: 0.999991] [G loss: 1.000085]\n",
      "epoch:35 step:168300[D loss: 0.999966] [G loss: 1.000107]\n",
      "epoch:35 step:168305[D loss: 0.999953] [G loss: 1.000107]\n",
      "epoch:35 step:168310[D loss: 0.999986] [G loss: 1.000070]\n",
      "epoch:35 step:168315[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:35 step:168320[D loss: 0.999989] [G loss: 1.000106]\n",
      "epoch:35 step:168325[D loss: 1.000019] [G loss: 1.000142]\n",
      "epoch:35 step:168330[D loss: 0.999956] [G loss: 1.000046]\n",
      "epoch:35 step:168335[D loss: 1.000028] [G loss: 0.999963]\n",
      "epoch:35 step:168340[D loss: 0.999975] [G loss: 1.000049]\n",
      "epoch:35 step:168345[D loss: 0.999989] [G loss: 1.000015]\n",
      "epoch:35 step:168350[D loss: 1.000007] [G loss: 1.000006]\n",
      "epoch:35 step:168355[D loss: 0.999958] [G loss: 1.000067]\n",
      "epoch:35 step:168360[D loss: 0.999939] [G loss: 1.000099]\n",
      "epoch:35 step:168365[D loss: 1.000022] [G loss: 0.999984]\n",
      "epoch:35 step:168370[D loss: 0.999942] [G loss: 1.000066]\n",
      "epoch:35 step:168375[D loss: 0.999976] [G loss: 1.000054]\n",
      "epoch:35 step:168380[D loss: 0.999966] [G loss: 1.000069]\n",
      "epoch:35 step:168385[D loss: 0.999984] [G loss: 1.000085]\n",
      "epoch:35 step:168390[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:35 step:168395[D loss: 0.999979] [G loss: 1.000081]\n",
      "epoch:35 step:168400[D loss: 1.000068] [G loss: 0.999999]\n",
      "epoch:35 step:168405[D loss: 0.999954] [G loss: 1.000162]\n",
      "epoch:35 step:168410[D loss: 0.999947] [G loss: 1.000099]\n",
      "epoch:35 step:168415[D loss: 1.000051] [G loss: 0.999952]\n",
      "epoch:35 step:168420[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:35 step:168425[D loss: 1.000046] [G loss: 1.000045]\n",
      "epoch:35 step:168430[D loss: 0.999892] [G loss: 1.000133]\n",
      "epoch:35 step:168435[D loss: 0.999961] [G loss: 1.000084]\n",
      "epoch:35 step:168440[D loss: 1.000019] [G loss: 1.000044]\n",
      "epoch:35 step:168445[D loss: 0.999933] [G loss: 1.000094]\n",
      "epoch:35 step:168450[D loss: 0.999927] [G loss: 1.000103]\n",
      "epoch:35 step:168455[D loss: 0.999927] [G loss: 1.000085]\n",
      "epoch:35 step:168460[D loss: 0.999984] [G loss: 1.000068]\n",
      "epoch:35 step:168465[D loss: 0.999992] [G loss: 1.000080]\n",
      "epoch:35 step:168470[D loss: 0.999973] [G loss: 1.000096]\n",
      "epoch:35 step:168475[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:35 step:168480[D loss: 1.000106] [G loss: 0.999990]\n",
      "epoch:35 step:168485[D loss: 0.999940] [G loss: 1.000129]\n",
      "epoch:35 step:168490[D loss: 0.999976] [G loss: 1.000087]\n",
      "epoch:35 step:168495[D loss: 1.000023] [G loss: 1.000010]\n",
      "epoch:35 step:168500[D loss: 0.999990] [G loss: 1.000057]\n",
      "epoch:35 step:168505[D loss: 1.000045] [G loss: 1.000084]\n",
      "epoch:35 step:168510[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:35 step:168515[D loss: 1.000091] [G loss: 0.999946]\n",
      "epoch:35 step:168520[D loss: 1.000041] [G loss: 0.999970]\n",
      "epoch:35 step:168525[D loss: 0.999925] [G loss: 1.000050]\n",
      "epoch:35 step:168530[D loss: 0.999946] [G loss: 1.000104]\n",
      "epoch:35 step:168535[D loss: 0.999954] [G loss: 1.000075]\n",
      "epoch:35 step:168540[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:35 step:168545[D loss: 0.999976] [G loss: 1.000068]\n",
      "epoch:35 step:168550[D loss: 0.999952] [G loss: 1.000066]\n",
      "epoch:35 step:168555[D loss: 0.999995] [G loss: 0.999997]\n",
      "epoch:35 step:168560[D loss: 0.999971] [G loss: 1.000153]\n",
      "epoch:35 step:168565[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:35 step:168570[D loss: 1.000008] [G loss: 1.000005]\n",
      "epoch:35 step:168575[D loss: 1.000015] [G loss: 0.999988]\n",
      "epoch:35 step:168580[D loss: 1.000074] [G loss: 0.999989]\n",
      "epoch:35 step:168585[D loss: 0.999951] [G loss: 1.000105]\n",
      "epoch:35 step:168590[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:35 step:168595[D loss: 0.999952] [G loss: 1.000133]\n",
      "epoch:35 step:168600[D loss: 0.999960] [G loss: 1.000082]\n",
      "epoch:35 step:168605[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:35 step:168610[D loss: 0.999967] [G loss: 1.000070]\n",
      "epoch:35 step:168615[D loss: 1.000045] [G loss: 1.000010]\n",
      "epoch:35 step:168620[D loss: 0.999931] [G loss: 1.000106]\n",
      "epoch:35 step:168625[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:35 step:168630[D loss: 0.999982] [G loss: 1.000067]\n",
      "epoch:35 step:168635[D loss: 0.999965] [G loss: 1.000087]\n",
      "epoch:35 step:168640[D loss: 1.000000] [G loss: 1.000057]\n",
      "epoch:35 step:168645[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:35 step:168650[D loss: 1.000006] [G loss: 1.000068]\n",
      "epoch:35 step:168655[D loss: 0.999991] [G loss: 1.000077]\n",
      "epoch:35 step:168660[D loss: 0.999981] [G loss: 1.000107]\n",
      "epoch:36 step:168665[D loss: 0.999978] [G loss: 1.000122]\n",
      "epoch:36 step:168670[D loss: 0.999909] [G loss: 1.000233]\n",
      "epoch:36 step:168675[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:36 step:168680[D loss: 0.999956] [G loss: 1.000084]\n",
      "epoch:36 step:168685[D loss: 0.999904] [G loss: 1.000206]\n",
      "epoch:36 step:168690[D loss: 0.999940] [G loss: 1.000135]\n",
      "epoch:36 step:168695[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:36 step:168700[D loss: 0.999985] [G loss: 1.000051]\n",
      "epoch:36 step:168705[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:36 step:168710[D loss: 1.000027] [G loss: 1.000077]\n",
      "epoch:36 step:168715[D loss: 1.000195] [G loss: 0.999797]\n",
      "epoch:36 step:168720[D loss: 0.999879] [G loss: 0.999961]\n",
      "epoch:36 step:168725[D loss: 0.999863] [G loss: 1.000098]\n",
      "epoch:36 step:168730[D loss: 0.999947] [G loss: 1.000108]\n",
      "epoch:36 step:168735[D loss: 0.999946] [G loss: 1.000182]\n",
      "epoch:36 step:168740[D loss: 1.000007] [G loss: 1.000068]\n",
      "epoch:36 step:168745[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:36 step:168750[D loss: 1.000037] [G loss: 0.999977]\n",
      "epoch:36 step:168755[D loss: 1.000012] [G loss: 1.000024]\n",
      "epoch:36 step:168760[D loss: 0.999969] [G loss: 0.999964]\n",
      "epoch:36 step:168765[D loss: 1.000080] [G loss: 0.999948]\n",
      "epoch:36 step:168770[D loss: 1.000236] [G loss: 0.999940]\n",
      "epoch:36 step:168775[D loss: 0.999800] [G loss: 1.000234]\n",
      "epoch:36 step:168780[D loss: 0.999859] [G loss: 1.000329]\n",
      "epoch:36 step:168785[D loss: 0.999973] [G loss: 1.000156]\n",
      "epoch:36 step:168790[D loss: 1.000006] [G loss: 1.000085]\n",
      "epoch:36 step:168795[D loss: 0.999992] [G loss: 1.000315]\n",
      "epoch:36 step:168800[D loss: 0.999877] [G loss: 1.000148]\n",
      "epoch:36 step:168805[D loss: 0.999983] [G loss: 1.000035]\n",
      "epoch:36 step:168810[D loss: 1.000032] [G loss: 0.999988]\n",
      "epoch:36 step:168815[D loss: 0.999957] [G loss: 1.000004]\n",
      "epoch:36 step:168820[D loss: 0.999934] [G loss: 1.000073]\n",
      "epoch:36 step:168825[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:36 step:168830[D loss: 0.999974] [G loss: 1.000091]\n",
      "epoch:36 step:168835[D loss: 0.999953] [G loss: 1.000070]\n",
      "epoch:36 step:168840[D loss: 0.999961] [G loss: 1.000060]\n",
      "epoch:36 step:168845[D loss: 1.000011] [G loss: 1.000082]\n",
      "epoch:36 step:168850[D loss: 0.999925] [G loss: 1.000112]\n",
      "epoch:36 step:168855[D loss: 0.999998] [G loss: 1.000032]\n",
      "epoch:36 step:168860[D loss: 0.999979] [G loss: 1.000275]\n",
      "epoch:36 step:168865[D loss: 0.999959] [G loss: 1.000194]\n",
      "epoch:36 step:168870[D loss: 0.999986] [G loss: 1.000025]\n",
      "epoch:36 step:168875[D loss: 1.000011] [G loss: 1.000036]\n",
      "epoch:36 step:168880[D loss: 1.000031] [G loss: 0.999954]\n",
      "epoch:36 step:168885[D loss: 0.999941] [G loss: 1.000007]\n",
      "epoch:36 step:168890[D loss: 0.999990] [G loss: 1.000088]\n",
      "epoch:36 step:168895[D loss: 0.999988] [G loss: 0.999970]\n",
      "epoch:36 step:168900[D loss: 0.999957] [G loss: 1.000098]\n",
      "epoch:36 step:168905[D loss: 0.999925] [G loss: 1.000205]\n",
      "epoch:36 step:168910[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:36 step:168915[D loss: 0.999960] [G loss: 1.000084]\n",
      "epoch:36 step:168920[D loss: 1.000060] [G loss: 1.000000]\n",
      "epoch:36 step:168925[D loss: 0.999903] [G loss: 1.000121]\n",
      "epoch:36 step:168930[D loss: 0.999950] [G loss: 1.000062]\n",
      "epoch:36 step:168935[D loss: 0.999970] [G loss: 1.000101]\n",
      "epoch:36 step:168940[D loss: 0.999959] [G loss: 1.000100]\n",
      "epoch:36 step:168945[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:36 step:168950[D loss: 0.999955] [G loss: 1.000101]\n",
      "epoch:36 step:168955[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:36 step:168960[D loss: 0.999946] [G loss: 1.000101]\n",
      "epoch:36 step:168965[D loss: 0.999988] [G loss: 1.000096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:168970[D loss: 1.000046] [G loss: 1.000006]\n",
      "epoch:36 step:168975[D loss: 1.000009] [G loss: 1.000099]\n",
      "epoch:36 step:168980[D loss: 1.000005] [G loss: 1.000086]\n",
      "epoch:36 step:168985[D loss: 0.999996] [G loss: 1.000022]\n",
      "epoch:36 step:168990[D loss: 1.000031] [G loss: 0.999923]\n",
      "epoch:36 step:168995[D loss: 0.999976] [G loss: 1.000019]\n",
      "epoch:36 step:169000[D loss: 1.000004] [G loss: 1.000025]\n",
      "epoch:36 step:169005[D loss: 1.000053] [G loss: 1.000140]\n",
      "epoch:36 step:169010[D loss: 0.999968] [G loss: 1.000239]\n",
      "epoch:36 step:169015[D loss: 1.000018] [G loss: 1.000071]\n",
      "epoch:36 step:169020[D loss: 1.000024] [G loss: 1.000120]\n",
      "epoch:36 step:169025[D loss: 0.999962] [G loss: 1.000100]\n",
      "epoch:36 step:169030[D loss: 0.999991] [G loss: 0.999988]\n",
      "epoch:36 step:169035[D loss: 1.000120] [G loss: 0.999829]\n",
      "epoch:36 step:169040[D loss: 1.000037] [G loss: 0.999957]\n",
      "epoch:36 step:169045[D loss: 0.999906] [G loss: 1.000235]\n",
      "epoch:36 step:169050[D loss: 1.000077] [G loss: 1.000052]\n",
      "epoch:36 step:169055[D loss: 1.000063] [G loss: 0.999951]\n",
      "epoch:36 step:169060[D loss: 0.999951] [G loss: 1.000091]\n",
      "epoch:36 step:169065[D loss: 1.000076] [G loss: 1.000062]\n",
      "epoch:36 step:169070[D loss: 0.999940] [G loss: 1.000052]\n",
      "epoch:36 step:169075[D loss: 0.999932] [G loss: 1.000096]\n",
      "epoch:36 step:169080[D loss: 0.999964] [G loss: 1.000063]\n",
      "epoch:36 step:169085[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:36 step:169090[D loss: 0.999992] [G loss: 1.000008]\n",
      "epoch:36 step:169095[D loss: 1.000008] [G loss: 1.000099]\n",
      "epoch:36 step:169100[D loss: 1.000141] [G loss: 0.999869]\n",
      "epoch:36 step:169105[D loss: 1.000037] [G loss: 1.000192]\n",
      "epoch:36 step:169110[D loss: 0.999914] [G loss: 1.000102]\n",
      "epoch:36 step:169115[D loss: 0.999898] [G loss: 1.000205]\n",
      "epoch:36 step:169120[D loss: 0.999930] [G loss: 1.000130]\n",
      "epoch:36 step:169125[D loss: 1.000049] [G loss: 1.000019]\n",
      "epoch:36 step:169130[D loss: 1.000065] [G loss: 0.999870]\n",
      "epoch:36 step:169135[D loss: 1.000063] [G loss: 1.000084]\n",
      "epoch:36 step:169140[D loss: 1.000121] [G loss: 0.999885]\n",
      "epoch:36 step:169145[D loss: 0.999931] [G loss: 1.000220]\n",
      "epoch:36 step:169150[D loss: 1.000016] [G loss: 1.000065]\n",
      "epoch:36 step:169155[D loss: 1.000023] [G loss: 1.000067]\n",
      "epoch:36 step:169160[D loss: 1.000016] [G loss: 1.000057]\n",
      "epoch:36 step:169165[D loss: 0.999922] [G loss: 1.000087]\n",
      "epoch:36 step:169170[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:36 step:169175[D loss: 1.000014] [G loss: 1.000007]\n",
      "epoch:36 step:169180[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:36 step:169185[D loss: 1.000162] [G loss: 0.999697]\n",
      "epoch:36 step:169190[D loss: 1.000030] [G loss: 0.999886]\n",
      "epoch:36 step:169195[D loss: 1.000146] [G loss: 0.999792]\n",
      "epoch:36 step:169200[D loss: 0.999993] [G loss: 1.000096]\n",
      "epoch:36 step:169205[D loss: 0.999810] [G loss: 1.000211]\n",
      "epoch:36 step:169210[D loss: 1.000070] [G loss: 0.999996]\n",
      "epoch:36 step:169215[D loss: 0.999909] [G loss: 1.000146]\n",
      "epoch:36 step:169220[D loss: 0.999959] [G loss: 1.000145]\n",
      "epoch:36 step:169225[D loss: 0.999979] [G loss: 1.000135]\n",
      "epoch:36 step:169230[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:36 step:169235[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:36 step:169240[D loss: 0.999949] [G loss: 1.000103]\n",
      "epoch:36 step:169245[D loss: 1.000069] [G loss: 1.000021]\n",
      "epoch:36 step:169250[D loss: 0.999915] [G loss: 1.000251]\n",
      "epoch:36 step:169255[D loss: 1.000097] [G loss: 1.000109]\n",
      "epoch:36 step:169260[D loss: 0.999933] [G loss: 1.000174]\n",
      "epoch:36 step:169265[D loss: 0.999971] [G loss: 1.000150]\n",
      "epoch:36 step:169270[D loss: 0.999970] [G loss: 1.000110]\n",
      "epoch:36 step:169275[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:36 step:169280[D loss: 0.999976] [G loss: 1.000072]\n",
      "epoch:36 step:169285[D loss: 1.000036] [G loss: 1.000000]\n",
      "epoch:36 step:169290[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:36 step:169295[D loss: 0.999974] [G loss: 1.000021]\n",
      "epoch:36 step:169300[D loss: 0.999975] [G loss: 1.000063]\n",
      "epoch:36 step:169305[D loss: 1.000040] [G loss: 0.999967]\n",
      "epoch:36 step:169310[D loss: 0.999917] [G loss: 1.000075]\n",
      "epoch:36 step:169315[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:36 step:169320[D loss: 1.000024] [G loss: 1.000007]\n",
      "epoch:36 step:169325[D loss: 0.999952] [G loss: 1.000109]\n",
      "epoch:36 step:169330[D loss: 0.999971] [G loss: 1.000096]\n",
      "epoch:36 step:169335[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:36 step:169340[D loss: 1.000012] [G loss: 1.000025]\n",
      "epoch:36 step:169345[D loss: 0.999999] [G loss: 1.000051]\n",
      "epoch:36 step:169350[D loss: 0.999968] [G loss: 1.000057]\n",
      "epoch:36 step:169355[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:36 step:169360[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:36 step:169365[D loss: 0.999985] [G loss: 1.000037]\n",
      "epoch:36 step:169370[D loss: 0.999945] [G loss: 1.000102]\n",
      "epoch:36 step:169375[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:36 step:169380[D loss: 0.999966] [G loss: 1.000063]\n",
      "epoch:36 step:169385[D loss: 0.999980] [G loss: 1.000081]\n",
      "epoch:36 step:169390[D loss: 0.999955] [G loss: 1.000079]\n",
      "epoch:36 step:169395[D loss: 1.000005] [G loss: 1.000045]\n",
      "epoch:36 step:169400[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:36 step:169405[D loss: 1.000037] [G loss: 1.000004]\n",
      "epoch:36 step:169410[D loss: 1.000033] [G loss: 0.999910]\n",
      "epoch:36 step:169415[D loss: 0.999970] [G loss: 1.000018]\n",
      "epoch:36 step:169420[D loss: 0.999982] [G loss: 1.000026]\n",
      "epoch:36 step:169425[D loss: 1.000002] [G loss: 1.000028]\n",
      "epoch:36 step:169430[D loss: 0.999983] [G loss: 1.000056]\n",
      "epoch:36 step:169435[D loss: 1.000043] [G loss: 0.999992]\n",
      "epoch:36 step:169440[D loss: 1.000028] [G loss: 1.000097]\n",
      "epoch:36 step:169445[D loss: 0.999899] [G loss: 1.000099]\n",
      "epoch:36 step:169450[D loss: 0.999978] [G loss: 1.000054]\n",
      "epoch:36 step:169455[D loss: 0.999980] [G loss: 0.999964]\n",
      "epoch:36 step:169460[D loss: 1.000125] [G loss: 0.999783]\n",
      "epoch:36 step:169465[D loss: 1.000066] [G loss: 1.000024]\n",
      "epoch:36 step:169470[D loss: 1.000123] [G loss: 0.999957]\n",
      "epoch:36 step:169475[D loss: 0.999905] [G loss: 1.000174]\n",
      "epoch:36 step:169480[D loss: 0.999922] [G loss: 1.000099]\n",
      "epoch:36 step:169485[D loss: 0.999934] [G loss: 1.000048]\n",
      "epoch:36 step:169490[D loss: 0.999999] [G loss: 0.999979]\n",
      "epoch:36 step:169495[D loss: 0.999984] [G loss: 1.000012]\n",
      "epoch:36 step:169500[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:36 step:169505[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:36 step:169510[D loss: 0.999966] [G loss: 1.000088]\n",
      "epoch:36 step:169515[D loss: 0.999966] [G loss: 1.000087]\n",
      "epoch:36 step:169520[D loss: 0.999953] [G loss: 1.000082]\n",
      "epoch:36 step:169525[D loss: 0.999965] [G loss: 1.000043]\n",
      "epoch:36 step:169530[D loss: 0.999974] [G loss: 1.000090]\n",
      "epoch:36 step:169535[D loss: 0.999969] [G loss: 1.000052]\n",
      "epoch:36 step:169540[D loss: 0.999979] [G loss: 1.000112]\n",
      "epoch:36 step:169545[D loss: 0.999958] [G loss: 1.000076]\n",
      "epoch:36 step:169550[D loss: 0.999992] [G loss: 1.000105]\n",
      "epoch:36 step:169555[D loss: 0.999918] [G loss: 1.000179]\n",
      "epoch:36 step:169560[D loss: 0.999969] [G loss: 1.000062]\n",
      "epoch:36 step:169565[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:36 step:169570[D loss: 0.999959] [G loss: 1.000060]\n",
      "epoch:36 step:169575[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:36 step:169580[D loss: 0.999985] [G loss: 1.000044]\n",
      "epoch:36 step:169585[D loss: 1.000019] [G loss: 1.000046]\n",
      "epoch:36 step:169590[D loss: 1.000077] [G loss: 0.999980]\n",
      "epoch:36 step:169595[D loss: 0.999943] [G loss: 1.000074]\n",
      "epoch:36 step:169600[D loss: 0.999980] [G loss: 1.000115]\n",
      "epoch:36 step:169605[D loss: 0.999985] [G loss: 1.000026]\n",
      "epoch:36 step:169610[D loss: 0.999966] [G loss: 1.000032]\n",
      "epoch:36 step:169615[D loss: 1.000033] [G loss: 1.000042]\n",
      "epoch:36 step:169620[D loss: 0.999957] [G loss: 1.000052]\n",
      "epoch:36 step:169625[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:36 step:169630[D loss: 1.000013] [G loss: 1.000018]\n",
      "epoch:36 step:169635[D loss: 1.000020] [G loss: 0.999964]\n",
      "epoch:36 step:169640[D loss: 0.999994] [G loss: 1.000033]\n",
      "epoch:36 step:169645[D loss: 0.999938] [G loss: 1.000183]\n",
      "epoch:36 step:169650[D loss: 1.000074] [G loss: 1.000140]\n",
      "epoch:36 step:169655[D loss: 0.999905] [G loss: 1.000211]\n",
      "epoch:36 step:169660[D loss: 0.999957] [G loss: 1.000292]\n",
      "epoch:36 step:169665[D loss: 0.999947] [G loss: 1.000162]\n",
      "epoch:36 step:169670[D loss: 0.999943] [G loss: 1.000139]\n",
      "epoch:36 step:169675[D loss: 0.999973] [G loss: 1.000061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:169680[D loss: 1.000023] [G loss: 0.999938]\n",
      "epoch:36 step:169685[D loss: 1.000016] [G loss: 0.999942]\n",
      "epoch:36 step:169690[D loss: 1.000101] [G loss: 0.999861]\n",
      "epoch:36 step:169695[D loss: 1.000073] [G loss: 0.999947]\n",
      "epoch:36 step:169700[D loss: 0.999789] [G loss: 1.000106]\n",
      "epoch:36 step:169705[D loss: 0.999962] [G loss: 1.000087]\n",
      "epoch:36 step:169710[D loss: 1.000007] [G loss: 1.000070]\n",
      "epoch:36 step:169715[D loss: 1.000039] [G loss: 0.999996]\n",
      "epoch:36 step:169720[D loss: 0.999939] [G loss: 1.000160]\n",
      "epoch:36 step:169725[D loss: 0.999922] [G loss: 1.000132]\n",
      "epoch:36 step:169730[D loss: 0.999983] [G loss: 1.000108]\n",
      "epoch:36 step:169735[D loss: 0.999968] [G loss: 1.000108]\n",
      "epoch:36 step:169740[D loss: 1.000014] [G loss: 1.000088]\n",
      "epoch:36 step:169745[D loss: 1.000061] [G loss: 1.000226]\n",
      "epoch:36 step:169750[D loss: 0.999831] [G loss: 1.000260]\n",
      "epoch:36 step:169755[D loss: 0.999951] [G loss: 1.000087]\n",
      "epoch:36 step:169760[D loss: 1.000012] [G loss: 1.000020]\n",
      "epoch:36 step:169765[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:36 step:169770[D loss: 0.999997] [G loss: 1.000033]\n",
      "epoch:36 step:169775[D loss: 1.000061] [G loss: 0.999946]\n",
      "epoch:36 step:169780[D loss: 1.000035] [G loss: 0.999882]\n",
      "epoch:36 step:169785[D loss: 1.000005] [G loss: 1.000073]\n",
      "epoch:36 step:169790[D loss: 1.000244] [G loss: 1.000008]\n",
      "epoch:36 step:169795[D loss: 1.000085] [G loss: 1.000135]\n",
      "epoch:36 step:169800[D loss: 1.000005] [G loss: 1.000067]\n",
      "epoch:36 step:169805[D loss: 0.999877] [G loss: 1.000256]\n",
      "epoch:36 step:169810[D loss: 0.999983] [G loss: 1.000185]\n",
      "epoch:36 step:169815[D loss: 0.999947] [G loss: 1.000114]\n",
      "epoch:36 step:169820[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:36 step:169825[D loss: 0.999938] [G loss: 1.000080]\n",
      "epoch:36 step:169830[D loss: 0.999911] [G loss: 1.000140]\n",
      "epoch:36 step:169835[D loss: 0.999947] [G loss: 1.000140]\n",
      "epoch:36 step:169840[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:36 step:169845[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:36 step:169850[D loss: 1.000028] [G loss: 1.000055]\n",
      "epoch:36 step:169855[D loss: 0.999960] [G loss: 1.000068]\n",
      "epoch:36 step:169860[D loss: 0.999968] [G loss: 1.000131]\n",
      "epoch:36 step:169865[D loss: 1.000102] [G loss: 1.000018]\n",
      "epoch:36 step:169870[D loss: 0.999953] [G loss: 1.000092]\n",
      "epoch:36 step:169875[D loss: 0.999975] [G loss: 1.000088]\n",
      "epoch:36 step:169880[D loss: 1.000014] [G loss: 1.000045]\n",
      "epoch:36 step:169885[D loss: 0.999984] [G loss: 1.000136]\n",
      "epoch:36 step:169890[D loss: 0.999969] [G loss: 1.000078]\n",
      "epoch:36 step:169895[D loss: 1.000017] [G loss: 0.999972]\n",
      "epoch:36 step:169900[D loss: 1.000043] [G loss: 1.000070]\n",
      "epoch:36 step:169905[D loss: 0.999963] [G loss: 1.000110]\n",
      "epoch:36 step:169910[D loss: 0.999927] [G loss: 1.000135]\n",
      "epoch:36 step:169915[D loss: 1.000013] [G loss: 0.999969]\n",
      "epoch:36 step:169920[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:36 step:169925[D loss: 0.999983] [G loss: 1.000092]\n",
      "epoch:36 step:169930[D loss: 0.999974] [G loss: 1.000115]\n",
      "epoch:36 step:169935[D loss: 1.000034] [G loss: 1.000068]\n",
      "epoch:36 step:169940[D loss: 0.999969] [G loss: 1.000130]\n",
      "epoch:36 step:169945[D loss: 0.999964] [G loss: 1.000100]\n",
      "epoch:36 step:169950[D loss: 1.000103] [G loss: 0.999837]\n",
      "epoch:36 step:169955[D loss: 1.000016] [G loss: 0.999920]\n",
      "epoch:36 step:169960[D loss: 0.999981] [G loss: 1.000110]\n",
      "epoch:36 step:169965[D loss: 0.999843] [G loss: 1.000177]\n",
      "epoch:36 step:169970[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:36 step:169975[D loss: 0.999995] [G loss: 1.000003]\n",
      "epoch:36 step:169980[D loss: 0.999968] [G loss: 1.000056]\n",
      "epoch:36 step:169985[D loss: 1.000017] [G loss: 1.000014]\n",
      "epoch:36 step:169990[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:36 step:169995[D loss: 0.999966] [G loss: 1.000077]\n",
      "epoch:36 step:170000[D loss: 0.999987] [G loss: 1.000067]\n",
      "epoch:36 step:170005[D loss: 0.999954] [G loss: 1.000080]\n",
      "epoch:36 step:170010[D loss: 0.999994] [G loss: 1.000096]\n",
      "epoch:36 step:170015[D loss: 0.999964] [G loss: 1.000065]\n",
      "epoch:36 step:170020[D loss: 1.000024] [G loss: 1.000118]\n",
      "epoch:36 step:170025[D loss: 1.000030] [G loss: 1.000070]\n",
      "epoch:36 step:170030[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:36 step:170035[D loss: 1.000051] [G loss: 0.999980]\n",
      "epoch:36 step:170040[D loss: 1.000018] [G loss: 1.000030]\n",
      "epoch:36 step:170045[D loss: 0.999978] [G loss: 1.000004]\n",
      "epoch:36 step:170050[D loss: 0.999939] [G loss: 1.000096]\n",
      "epoch:36 step:170055[D loss: 0.999943] [G loss: 1.000092]\n",
      "epoch:36 step:170060[D loss: 0.999876] [G loss: 1.000172]\n",
      "epoch:36 step:170065[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:36 step:170070[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:36 step:170075[D loss: 0.999929] [G loss: 1.000129]\n",
      "epoch:36 step:170080[D loss: 0.999977] [G loss: 1.000115]\n",
      "epoch:36 step:170085[D loss: 1.000035] [G loss: 0.999965]\n",
      "epoch:36 step:170090[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:36 step:170095[D loss: 0.999970] [G loss: 1.000078]\n",
      "epoch:36 step:170100[D loss: 0.999971] [G loss: 1.000095]\n",
      "epoch:36 step:170105[D loss: 1.000057] [G loss: 1.000060]\n",
      "epoch:36 step:170110[D loss: 0.999941] [G loss: 1.000077]\n",
      "epoch:36 step:170115[D loss: 0.999969] [G loss: 1.000195]\n",
      "epoch:36 step:170120[D loss: 0.999918] [G loss: 1.000110]\n",
      "epoch:36 step:170125[D loss: 1.000050] [G loss: 0.999907]\n",
      "epoch:36 step:170130[D loss: 0.999982] [G loss: 0.999949]\n",
      "epoch:36 step:170135[D loss: 1.000007] [G loss: 1.000043]\n",
      "epoch:36 step:170140[D loss: 0.999976] [G loss: 1.000113]\n",
      "epoch:36 step:170145[D loss: 1.000002] [G loss: 1.000052]\n",
      "epoch:36 step:170150[D loss: 0.999973] [G loss: 1.000095]\n",
      "epoch:36 step:170155[D loss: 0.999939] [G loss: 1.000104]\n",
      "epoch:36 step:170160[D loss: 1.000001] [G loss: 1.000047]\n",
      "epoch:36 step:170165[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:36 step:170170[D loss: 0.999945] [G loss: 1.000085]\n",
      "epoch:36 step:170175[D loss: 1.000024] [G loss: 1.000014]\n",
      "epoch:36 step:170180[D loss: 0.999936] [G loss: 1.000067]\n",
      "epoch:36 step:170185[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:36 step:170190[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:36 step:170195[D loss: 1.000000] [G loss: 1.000098]\n",
      "epoch:36 step:170200[D loss: 0.999986] [G loss: 1.000044]\n",
      "epoch:36 step:170205[D loss: 0.999948] [G loss: 1.000120]\n",
      "epoch:36 step:170210[D loss: 0.999995] [G loss: 1.000103]\n",
      "epoch:36 step:170215[D loss: 1.000047] [G loss: 1.000123]\n",
      "epoch:36 step:170220[D loss: 0.999809] [G loss: 1.000202]\n",
      "epoch:36 step:170225[D loss: 0.999959] [G loss: 1.000068]\n",
      "epoch:36 step:170230[D loss: 0.999973] [G loss: 1.000086]\n",
      "epoch:36 step:170235[D loss: 1.000034] [G loss: 1.000061]\n",
      "epoch:36 step:170240[D loss: 0.999931] [G loss: 1.000238]\n",
      "epoch:36 step:170245[D loss: 0.999997] [G loss: 0.999970]\n",
      "epoch:36 step:170250[D loss: 1.000110] [G loss: 0.999811]\n",
      "epoch:36 step:170255[D loss: 1.000121] [G loss: 0.999741]\n",
      "epoch:36 step:170260[D loss: 0.999990] [G loss: 0.999976]\n",
      "epoch:36 step:170265[D loss: 1.000111] [G loss: 0.999925]\n",
      "epoch:36 step:170270[D loss: 0.999747] [G loss: 1.000443]\n",
      "epoch:36 step:170275[D loss: 1.000017] [G loss: 1.000162]\n",
      "epoch:36 step:170280[D loss: 0.999900] [G loss: 1.000094]\n",
      "epoch:36 step:170285[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:36 step:170290[D loss: 1.000003] [G loss: 0.999990]\n",
      "epoch:36 step:170295[D loss: 1.000001] [G loss: 1.000100]\n",
      "epoch:36 step:170300[D loss: 0.999957] [G loss: 0.999981]\n",
      "epoch:36 step:170305[D loss: 1.000030] [G loss: 0.999933]\n",
      "epoch:36 step:170310[D loss: 0.999913] [G loss: 1.000089]\n",
      "epoch:36 step:170315[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:36 step:170320[D loss: 0.999949] [G loss: 1.000127]\n",
      "epoch:36 step:170325[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:36 step:170330[D loss: 1.000006] [G loss: 0.999979]\n",
      "epoch:36 step:170335[D loss: 0.999964] [G loss: 1.000078]\n",
      "epoch:36 step:170340[D loss: 0.999944] [G loss: 1.000100]\n",
      "epoch:36 step:170345[D loss: 1.000044] [G loss: 0.999910]\n",
      "epoch:36 step:170350[D loss: 1.000010] [G loss: 1.000008]\n",
      "epoch:36 step:170355[D loss: 0.999963] [G loss: 1.000073]\n",
      "epoch:36 step:170360[D loss: 0.999961] [G loss: 1.000075]\n",
      "epoch:36 step:170365[D loss: 0.999964] [G loss: 1.000089]\n",
      "epoch:36 step:170370[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:36 step:170375[D loss: 0.999965] [G loss: 1.000094]\n",
      "epoch:36 step:170380[D loss: 1.000036] [G loss: 0.999989]\n",
      "epoch:36 step:170385[D loss: 0.999970] [G loss: 0.999996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:170390[D loss: 1.000157] [G loss: 1.000025]\n",
      "epoch:36 step:170395[D loss: 0.999916] [G loss: 1.000109]\n",
      "epoch:36 step:170400[D loss: 1.000026] [G loss: 0.999997]\n",
      "epoch:36 step:170405[D loss: 0.999974] [G loss: 1.000076]\n",
      "epoch:36 step:170410[D loss: 0.999968] [G loss: 1.000047]\n",
      "epoch:36 step:170415[D loss: 1.000048] [G loss: 0.999972]\n",
      "epoch:36 step:170420[D loss: 0.999939] [G loss: 1.000141]\n",
      "epoch:36 step:170425[D loss: 0.999933] [G loss: 1.000129]\n",
      "epoch:36 step:170430[D loss: 0.999987] [G loss: 1.000068]\n",
      "epoch:36 step:170435[D loss: 1.000046] [G loss: 0.999986]\n",
      "epoch:36 step:170440[D loss: 0.999927] [G loss: 1.000117]\n",
      "epoch:36 step:170445[D loss: 0.999970] [G loss: 1.000076]\n",
      "epoch:36 step:170450[D loss: 1.000016] [G loss: 1.000044]\n",
      "epoch:36 step:170455[D loss: 0.999972] [G loss: 1.000038]\n",
      "epoch:36 step:170460[D loss: 0.999987] [G loss: 1.000126]\n",
      "epoch:36 step:170465[D loss: 0.999963] [G loss: 1.000076]\n",
      "epoch:36 step:170470[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:36 step:170475[D loss: 1.000034] [G loss: 1.000079]\n",
      "epoch:36 step:170480[D loss: 1.000174] [G loss: 0.999848]\n",
      "epoch:36 step:170485[D loss: 0.999995] [G loss: 1.000053]\n",
      "epoch:36 step:170490[D loss: 0.999996] [G loss: 1.000056]\n",
      "epoch:36 step:170495[D loss: 0.999983] [G loss: 1.000120]\n",
      "epoch:36 step:170500[D loss: 0.999954] [G loss: 1.000128]\n",
      "epoch:36 step:170505[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:36 step:170510[D loss: 0.999986] [G loss: 1.000079]\n",
      "epoch:36 step:170515[D loss: 0.999976] [G loss: 1.000010]\n",
      "epoch:36 step:170520[D loss: 0.999930] [G loss: 1.000114]\n",
      "epoch:36 step:170525[D loss: 0.999995] [G loss: 0.999997]\n",
      "epoch:36 step:170530[D loss: 0.999971] [G loss: 1.000086]\n",
      "epoch:36 step:170535[D loss: 0.999974] [G loss: 1.000108]\n",
      "epoch:36 step:170540[D loss: 0.999934] [G loss: 1.000123]\n",
      "epoch:36 step:170545[D loss: 1.000044] [G loss: 0.999986]\n",
      "epoch:36 step:170550[D loss: 1.000033] [G loss: 1.000173]\n",
      "epoch:36 step:170555[D loss: 0.999963] [G loss: 1.000051]\n",
      "epoch:36 step:170560[D loss: 0.999909] [G loss: 1.000108]\n",
      "epoch:36 step:170565[D loss: 0.999962] [G loss: 1.000079]\n",
      "epoch:36 step:170570[D loss: 0.999963] [G loss: 1.000088]\n",
      "epoch:36 step:170575[D loss: 1.000000] [G loss: 1.000034]\n",
      "epoch:36 step:170580[D loss: 1.000014] [G loss: 0.999983]\n",
      "epoch:36 step:170585[D loss: 1.000166] [G loss: 0.999961]\n",
      "epoch:36 step:170590[D loss: 0.999863] [G loss: 1.000131]\n",
      "epoch:36 step:170595[D loss: 1.000083] [G loss: 1.000082]\n",
      "epoch:36 step:170600[D loss: 0.999941] [G loss: 1.000153]\n",
      "epoch:36 step:170605[D loss: 1.000058] [G loss: 0.999961]\n",
      "epoch:36 step:170610[D loss: 0.999946] [G loss: 0.999951]\n",
      "epoch:36 step:170615[D loss: 1.000104] [G loss: 0.999962]\n",
      "epoch:36 step:170620[D loss: 0.999923] [G loss: 1.000092]\n",
      "epoch:36 step:170625[D loss: 0.999987] [G loss: 0.999981]\n",
      "epoch:36 step:170630[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:36 step:170635[D loss: 0.999982] [G loss: 1.000023]\n",
      "epoch:36 step:170640[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:36 step:170645[D loss: 0.999992] [G loss: 1.000065]\n",
      "epoch:36 step:170650[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:36 step:170655[D loss: 0.999979] [G loss: 1.000087]\n",
      "epoch:36 step:170660[D loss: 0.999991] [G loss: 0.999991]\n",
      "epoch:36 step:170665[D loss: 0.999992] [G loss: 1.000068]\n",
      "epoch:36 step:170670[D loss: 0.999978] [G loss: 1.000046]\n",
      "epoch:36 step:170675[D loss: 0.999998] [G loss: 1.000092]\n",
      "epoch:36 step:170680[D loss: 0.999981] [G loss: 1.000105]\n",
      "epoch:36 step:170685[D loss: 0.999995] [G loss: 1.000043]\n",
      "epoch:36 step:170690[D loss: 0.999972] [G loss: 1.000037]\n",
      "epoch:36 step:170695[D loss: 1.000015] [G loss: 1.000049]\n",
      "epoch:36 step:170700[D loss: 1.000036] [G loss: 0.999952]\n",
      "epoch:36 step:170705[D loss: 1.000028] [G loss: 0.999936]\n",
      "epoch:36 step:170710[D loss: 0.999972] [G loss: 1.000065]\n",
      "epoch:36 step:170715[D loss: 0.999945] [G loss: 1.000068]\n",
      "epoch:36 step:170720[D loss: 1.000044] [G loss: 1.000018]\n",
      "epoch:36 step:170725[D loss: 0.999981] [G loss: 1.000067]\n",
      "epoch:36 step:170730[D loss: 0.999956] [G loss: 1.000107]\n",
      "epoch:36 step:170735[D loss: 1.000058] [G loss: 0.999966]\n",
      "epoch:36 step:170740[D loss: 0.999942] [G loss: 1.000176]\n",
      "epoch:36 step:170745[D loss: 0.999908] [G loss: 1.000150]\n",
      "epoch:36 step:170750[D loss: 1.000072] [G loss: 0.999972]\n",
      "epoch:36 step:170755[D loss: 0.999935] [G loss: 1.000122]\n",
      "epoch:36 step:170760[D loss: 0.999981] [G loss: 1.000063]\n",
      "epoch:36 step:170765[D loss: 1.000010] [G loss: 1.000093]\n",
      "epoch:36 step:170770[D loss: 1.000041] [G loss: 1.000061]\n",
      "epoch:36 step:170775[D loss: 0.999977] [G loss: 1.000079]\n",
      "epoch:36 step:170780[D loss: 0.999989] [G loss: 1.000050]\n",
      "epoch:36 step:170785[D loss: 0.999990] [G loss: 1.000064]\n",
      "epoch:36 step:170790[D loss: 1.000002] [G loss: 1.000030]\n",
      "epoch:36 step:170795[D loss: 0.999953] [G loss: 1.000087]\n",
      "epoch:36 step:170800[D loss: 0.999986] [G loss: 1.000055]\n",
      "epoch:36 step:170805[D loss: 1.000112] [G loss: 0.999845]\n",
      "epoch:36 step:170810[D loss: 0.999903] [G loss: 1.000104]\n",
      "epoch:36 step:170815[D loss: 1.000003] [G loss: 0.999987]\n",
      "epoch:36 step:170820[D loss: 0.999946] [G loss: 1.000204]\n",
      "epoch:36 step:170825[D loss: 1.000006] [G loss: 1.000059]\n",
      "epoch:36 step:170830[D loss: 1.000031] [G loss: 1.000043]\n",
      "epoch:36 step:170835[D loss: 0.999970] [G loss: 1.000092]\n",
      "epoch:36 step:170840[D loss: 0.999979] [G loss: 1.000076]\n",
      "epoch:36 step:170845[D loss: 0.999944] [G loss: 1.000065]\n",
      "epoch:36 step:170850[D loss: 0.999984] [G loss: 1.000060]\n",
      "epoch:36 step:170855[D loss: 0.999982] [G loss: 1.000060]\n",
      "epoch:36 step:170860[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:36 step:170865[D loss: 0.999985] [G loss: 1.000016]\n",
      "epoch:36 step:170870[D loss: 1.000026] [G loss: 0.999988]\n",
      "epoch:36 step:170875[D loss: 0.999931] [G loss: 1.000096]\n",
      "epoch:36 step:170880[D loss: 0.999970] [G loss: 1.000089]\n",
      "epoch:36 step:170885[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:36 step:170890[D loss: 1.000000] [G loss: 1.000069]\n",
      "epoch:36 step:170895[D loss: 0.999980] [G loss: 1.000085]\n",
      "epoch:36 step:170900[D loss: 0.999937] [G loss: 1.000204]\n",
      "epoch:36 step:170905[D loss: 0.999951] [G loss: 1.000122]\n",
      "epoch:36 step:170910[D loss: 0.999895] [G loss: 1.000205]\n",
      "epoch:36 step:170915[D loss: 0.999974] [G loss: 1.000058]\n",
      "epoch:36 step:170920[D loss: 1.000054] [G loss: 0.999986]\n",
      "epoch:36 step:170925[D loss: 0.999925] [G loss: 1.000111]\n",
      "epoch:36 step:170930[D loss: 0.999990] [G loss: 1.000021]\n",
      "epoch:36 step:170935[D loss: 0.999970] [G loss: 1.000002]\n",
      "epoch:36 step:170940[D loss: 1.000034] [G loss: 0.999891]\n",
      "epoch:36 step:170945[D loss: 0.999997] [G loss: 0.999971]\n",
      "epoch:36 step:170950[D loss: 1.000211] [G loss: 0.999799]\n",
      "epoch:36 step:170955[D loss: 1.000272] [G loss: 1.000067]\n",
      "epoch:36 step:170960[D loss: 0.999862] [G loss: 1.000225]\n",
      "epoch:36 step:170965[D loss: 0.999951] [G loss: 1.000122]\n",
      "epoch:36 step:170970[D loss: 0.999908] [G loss: 1.000082]\n",
      "epoch:36 step:170975[D loss: 0.999984] [G loss: 1.000057]\n",
      "epoch:36 step:170980[D loss: 1.000011] [G loss: 0.999999]\n",
      "epoch:36 step:170985[D loss: 1.000041] [G loss: 1.000081]\n",
      "epoch:36 step:170990[D loss: 0.999934] [G loss: 1.000060]\n",
      "epoch:36 step:170995[D loss: 1.000016] [G loss: 1.000053]\n",
      "epoch:36 step:171000[D loss: 1.000033] [G loss: 1.000138]\n",
      "epoch:36 step:171005[D loss: 1.000085] [G loss: 1.000062]\n",
      "epoch:36 step:171010[D loss: 0.999907] [G loss: 1.000149]\n",
      "epoch:36 step:171015[D loss: 0.999890] [G loss: 1.000187]\n",
      "epoch:36 step:171020[D loss: 0.999985] [G loss: 1.000023]\n",
      "epoch:36 step:171025[D loss: 1.000009] [G loss: 1.000027]\n",
      "epoch:36 step:171030[D loss: 0.999950] [G loss: 1.000094]\n",
      "epoch:36 step:171035[D loss: 1.000044] [G loss: 0.999958]\n",
      "epoch:36 step:171040[D loss: 0.999874] [G loss: 1.000160]\n",
      "epoch:36 step:171045[D loss: 0.999946] [G loss: 1.000079]\n",
      "epoch:36 step:171050[D loss: 1.000091] [G loss: 0.999988]\n",
      "epoch:36 step:171055[D loss: 0.999954] [G loss: 1.000106]\n",
      "epoch:36 step:171060[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:36 step:171065[D loss: 0.999986] [G loss: 1.000119]\n",
      "epoch:36 step:171070[D loss: 1.000029] [G loss: 0.999982]\n",
      "epoch:36 step:171075[D loss: 0.999953] [G loss: 1.000088]\n",
      "epoch:36 step:171080[D loss: 1.000008] [G loss: 1.000072]\n",
      "epoch:36 step:171085[D loss: 1.000055] [G loss: 1.000010]\n",
      "epoch:36 step:171090[D loss: 0.999906] [G loss: 1.000155]\n",
      "epoch:36 step:171095[D loss: 1.000124] [G loss: 1.000014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:171100[D loss: 0.999947] [G loss: 1.000237]\n",
      "epoch:36 step:171105[D loss: 1.000000] [G loss: 1.000101]\n",
      "epoch:36 step:171110[D loss: 0.999945] [G loss: 1.000229]\n",
      "epoch:36 step:171115[D loss: 0.999948] [G loss: 1.000132]\n",
      "epoch:36 step:171120[D loss: 0.999965] [G loss: 1.000153]\n",
      "epoch:36 step:171125[D loss: 1.000018] [G loss: 1.000152]\n",
      "epoch:36 step:171130[D loss: 1.000049] [G loss: 1.000055]\n",
      "epoch:36 step:171135[D loss: 0.999965] [G loss: 1.000032]\n",
      "epoch:36 step:171140[D loss: 1.000072] [G loss: 1.000045]\n",
      "epoch:36 step:171145[D loss: 0.999952] [G loss: 1.000160]\n",
      "epoch:36 step:171150[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:36 step:171155[D loss: 1.000030] [G loss: 1.000055]\n",
      "epoch:36 step:171160[D loss: 1.000179] [G loss: 0.999999]\n",
      "epoch:36 step:171165[D loss: 0.999856] [G loss: 1.000052]\n",
      "epoch:36 step:171170[D loss: 0.999904] [G loss: 1.000122]\n",
      "epoch:36 step:171175[D loss: 0.999935] [G loss: 1.000111]\n",
      "epoch:36 step:171180[D loss: 0.999969] [G loss: 1.000067]\n",
      "epoch:36 step:171185[D loss: 0.999941] [G loss: 1.000164]\n",
      "epoch:36 step:171190[D loss: 0.999993] [G loss: 1.000053]\n",
      "epoch:36 step:171195[D loss: 1.000004] [G loss: 1.000096]\n",
      "epoch:36 step:171200[D loss: 0.999931] [G loss: 1.000202]\n",
      "epoch:36 step:171205[D loss: 1.000039] [G loss: 0.999988]\n",
      "epoch:36 step:171210[D loss: 1.000040] [G loss: 1.000182]\n",
      "epoch:36 step:171215[D loss: 0.999960] [G loss: 1.000157]\n",
      "epoch:36 step:171220[D loss: 0.999996] [G loss: 1.000054]\n",
      "epoch:36 step:171225[D loss: 0.999992] [G loss: 0.999999]\n",
      "epoch:36 step:171230[D loss: 1.000020] [G loss: 0.999969]\n",
      "epoch:36 step:171235[D loss: 0.999920] [G loss: 1.000109]\n",
      "epoch:36 step:171240[D loss: 0.999958] [G loss: 1.000052]\n",
      "epoch:36 step:171245[D loss: 1.000060] [G loss: 1.000131]\n",
      "epoch:36 step:171250[D loss: 0.999853] [G loss: 1.000206]\n",
      "epoch:36 step:171255[D loss: 0.999951] [G loss: 1.000207]\n",
      "epoch:36 step:171260[D loss: 0.999860] [G loss: 1.000238]\n",
      "epoch:36 step:171265[D loss: 0.999975] [G loss: 1.000099]\n",
      "epoch:36 step:171270[D loss: 1.000000] [G loss: 1.000064]\n",
      "epoch:36 step:171275[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:36 step:171280[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:36 step:171285[D loss: 1.000017] [G loss: 0.999980]\n",
      "epoch:36 step:171290[D loss: 1.000056] [G loss: 0.999884]\n",
      "epoch:36 step:171295[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:36 step:171300[D loss: 0.999997] [G loss: 1.000087]\n",
      "epoch:36 step:171305[D loss: 0.999931] [G loss: 1.000160]\n",
      "epoch:36 step:171310[D loss: 1.000038] [G loss: 0.999996]\n",
      "epoch:36 step:171315[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:36 step:171320[D loss: 0.999996] [G loss: 1.000011]\n",
      "epoch:36 step:171325[D loss: 0.999967] [G loss: 1.000093]\n",
      "epoch:36 step:171330[D loss: 1.000073] [G loss: 1.000039]\n",
      "epoch:36 step:171335[D loss: 0.999920] [G loss: 1.000104]\n",
      "epoch:36 step:171340[D loss: 1.000138] [G loss: 1.000098]\n",
      "epoch:36 step:171345[D loss: 0.999856] [G loss: 1.000361]\n",
      "epoch:36 step:171350[D loss: 1.000039] [G loss: 1.000093]\n",
      "epoch:36 step:171355[D loss: 0.999834] [G loss: 1.000355]\n",
      "epoch:36 step:171360[D loss: 0.999906] [G loss: 1.000222]\n",
      "epoch:36 step:171365[D loss: 0.999960] [G loss: 1.000145]\n",
      "epoch:36 step:171370[D loss: 0.999996] [G loss: 1.000002]\n",
      "epoch:36 step:171375[D loss: 1.000111] [G loss: 0.999970]\n",
      "epoch:36 step:171380[D loss: 0.999991] [G loss: 0.999960]\n",
      "epoch:36 step:171385[D loss: 0.999941] [G loss: 1.000084]\n",
      "epoch:36 step:171390[D loss: 1.000090] [G loss: 0.999896]\n",
      "epoch:36 step:171395[D loss: 0.999892] [G loss: 1.000039]\n",
      "epoch:36 step:171400[D loss: 1.000033] [G loss: 1.000002]\n",
      "epoch:36 step:171405[D loss: 1.000052] [G loss: 1.000045]\n",
      "epoch:36 step:171410[D loss: 1.000098] [G loss: 0.999960]\n",
      "epoch:36 step:171415[D loss: 0.999760] [G loss: 1.000242]\n",
      "epoch:36 step:171420[D loss: 0.999986] [G loss: 1.000101]\n",
      "epoch:36 step:171425[D loss: 0.999974] [G loss: 1.000053]\n",
      "epoch:36 step:171430[D loss: 0.999975] [G loss: 1.000087]\n",
      "epoch:36 step:171435[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:36 step:171440[D loss: 1.000038] [G loss: 0.999938]\n",
      "epoch:36 step:171445[D loss: 1.000001] [G loss: 1.000052]\n",
      "epoch:36 step:171450[D loss: 1.000100] [G loss: 0.999986]\n",
      "epoch:36 step:171455[D loss: 1.000065] [G loss: 1.000019]\n",
      "epoch:36 step:171460[D loss: 0.999811] [G loss: 1.000271]\n",
      "epoch:36 step:171465[D loss: 0.999934] [G loss: 1.000172]\n",
      "epoch:36 step:171470[D loss: 0.999925] [G loss: 1.000215]\n",
      "epoch:36 step:171475[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:36 step:171480[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:36 step:171485[D loss: 0.999980] [G loss: 1.000101]\n",
      "epoch:36 step:171490[D loss: 0.999992] [G loss: 1.000001]\n",
      "epoch:36 step:171495[D loss: 1.000075] [G loss: 0.999818]\n",
      "epoch:36 step:171500[D loss: 0.999940] [G loss: 1.000118]\n",
      "epoch:36 step:171505[D loss: 0.999899] [G loss: 1.000098]\n",
      "epoch:36 step:171510[D loss: 0.999987] [G loss: 1.000095]\n",
      "epoch:36 step:171515[D loss: 0.999948] [G loss: 1.000061]\n",
      "epoch:36 step:171520[D loss: 0.999995] [G loss: 1.000041]\n",
      "epoch:36 step:171525[D loss: 0.999968] [G loss: 1.000032]\n",
      "epoch:36 step:171530[D loss: 0.999995] [G loss: 1.000008]\n",
      "epoch:36 step:171535[D loss: 1.000032] [G loss: 1.000033]\n",
      "epoch:36 step:171540[D loss: 1.000034] [G loss: 1.000002]\n",
      "epoch:36 step:171545[D loss: 0.999909] [G loss: 1.000092]\n",
      "epoch:36 step:171550[D loss: 0.999998] [G loss: 1.000068]\n",
      "epoch:36 step:171555[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:36 step:171560[D loss: 0.999955] [G loss: 1.000128]\n",
      "epoch:36 step:171565[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:36 step:171570[D loss: 1.000022] [G loss: 0.999970]\n",
      "epoch:36 step:171575[D loss: 1.000016] [G loss: 0.999959]\n",
      "epoch:36 step:171580[D loss: 0.999971] [G loss: 1.000055]\n",
      "epoch:36 step:171585[D loss: 0.999942] [G loss: 1.000088]\n",
      "epoch:36 step:171590[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:36 step:171595[D loss: 1.000025] [G loss: 0.999977]\n",
      "epoch:36 step:171600[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:36 step:171605[D loss: 1.000129] [G loss: 1.000133]\n",
      "epoch:36 step:171610[D loss: 0.999895] [G loss: 1.000106]\n",
      "epoch:36 step:171615[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:36 step:171620[D loss: 1.000074] [G loss: 0.999923]\n",
      "epoch:36 step:171625[D loss: 1.000116] [G loss: 0.999861]\n",
      "epoch:36 step:171630[D loss: 1.000072] [G loss: 0.999897]\n",
      "epoch:36 step:171635[D loss: 1.000144] [G loss: 0.999864]\n",
      "epoch:36 step:171640[D loss: 0.999811] [G loss: 1.000285]\n",
      "epoch:36 step:171645[D loss: 1.000033] [G loss: 0.999945]\n",
      "epoch:36 step:171650[D loss: 1.000009] [G loss: 1.000088]\n",
      "epoch:36 step:171655[D loss: 0.999913] [G loss: 1.000166]\n",
      "epoch:36 step:171660[D loss: 0.999931] [G loss: 1.000193]\n",
      "epoch:36 step:171665[D loss: 1.000051] [G loss: 0.999940]\n",
      "epoch:36 step:171670[D loss: 1.000029] [G loss: 0.999890]\n",
      "epoch:36 step:171675[D loss: 0.999923] [G loss: 1.000041]\n",
      "epoch:36 step:171680[D loss: 1.000072] [G loss: 0.999867]\n",
      "epoch:36 step:171685[D loss: 1.000018] [G loss: 0.999890]\n",
      "epoch:36 step:171690[D loss: 1.000041] [G loss: 0.999938]\n",
      "epoch:36 step:171695[D loss: 0.999895] [G loss: 1.000036]\n",
      "epoch:36 step:171700[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:36 step:171705[D loss: 1.000071] [G loss: 0.999924]\n",
      "epoch:36 step:171710[D loss: 0.999944] [G loss: 0.999980]\n",
      "epoch:36 step:171715[D loss: 1.000036] [G loss: 1.000031]\n",
      "epoch:36 step:171720[D loss: 1.000005] [G loss: 0.999982]\n",
      "epoch:36 step:171725[D loss: 0.999925] [G loss: 1.000087]\n",
      "epoch:36 step:171730[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:36 step:171735[D loss: 0.999965] [G loss: 1.000037]\n",
      "epoch:36 step:171740[D loss: 0.999992] [G loss: 1.000049]\n",
      "epoch:36 step:171745[D loss: 1.000026] [G loss: 1.000000]\n",
      "epoch:36 step:171750[D loss: 1.000024] [G loss: 0.999965]\n",
      "epoch:36 step:171755[D loss: 0.999943] [G loss: 1.000041]\n",
      "epoch:36 step:171760[D loss: 0.999965] [G loss: 1.000101]\n",
      "epoch:36 step:171765[D loss: 0.999986] [G loss: 0.999997]\n",
      "epoch:36 step:171770[D loss: 1.000031] [G loss: 1.000097]\n",
      "epoch:36 step:171775[D loss: 0.999952] [G loss: 1.000093]\n",
      "epoch:36 step:171780[D loss: 0.999976] [G loss: 1.000069]\n",
      "epoch:36 step:171785[D loss: 1.000021] [G loss: 1.000074]\n",
      "epoch:36 step:171790[D loss: 0.999951] [G loss: 1.000065]\n",
      "epoch:36 step:171795[D loss: 0.999959] [G loss: 1.000057]\n",
      "epoch:36 step:171800[D loss: 0.999925] [G loss: 1.000060]\n",
      "epoch:36 step:171805[D loss: 0.999993] [G loss: 1.000058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:171810[D loss: 1.000096] [G loss: 1.000015]\n",
      "epoch:36 step:171815[D loss: 0.999966] [G loss: 1.000118]\n",
      "epoch:36 step:171820[D loss: 0.999950] [G loss: 1.000145]\n",
      "epoch:36 step:171825[D loss: 0.999899] [G loss: 1.000223]\n",
      "epoch:36 step:171830[D loss: 0.999961] [G loss: 1.000071]\n",
      "epoch:36 step:171835[D loss: 1.000001] [G loss: 0.999995]\n",
      "epoch:36 step:171840[D loss: 0.999963] [G loss: 1.000058]\n",
      "epoch:36 step:171845[D loss: 1.000160] [G loss: 0.999927]\n",
      "epoch:36 step:171850[D loss: 0.999832] [G loss: 1.000033]\n",
      "epoch:36 step:171855[D loss: 0.999865] [G loss: 1.000063]\n",
      "epoch:36 step:171860[D loss: 1.000206] [G loss: 0.999860]\n",
      "epoch:36 step:171865[D loss: 1.000133] [G loss: 1.000044]\n",
      "epoch:36 step:171870[D loss: 0.999865] [G loss: 1.000219]\n",
      "epoch:36 step:171875[D loss: 0.999836] [G loss: 1.000184]\n",
      "epoch:36 step:171880[D loss: 1.000016] [G loss: 0.999983]\n",
      "epoch:36 step:171885[D loss: 1.000016] [G loss: 0.999965]\n",
      "epoch:36 step:171890[D loss: 1.000056] [G loss: 0.999881]\n",
      "epoch:36 step:171895[D loss: 0.999964] [G loss: 1.000015]\n",
      "epoch:36 step:171900[D loss: 0.999912] [G loss: 1.000087]\n",
      "epoch:36 step:171905[D loss: 1.000036] [G loss: 0.999992]\n",
      "epoch:36 step:171910[D loss: 0.999990] [G loss: 1.000022]\n",
      "epoch:36 step:171915[D loss: 1.000069] [G loss: 1.000216]\n",
      "epoch:36 step:171920[D loss: 0.999946] [G loss: 1.000090]\n",
      "epoch:36 step:171925[D loss: 1.000028] [G loss: 1.000028]\n",
      "epoch:36 step:171930[D loss: 0.999895] [G loss: 1.000220]\n",
      "epoch:36 step:171935[D loss: 1.000039] [G loss: 1.000101]\n",
      "epoch:36 step:171940[D loss: 0.999952] [G loss: 1.000084]\n",
      "epoch:36 step:171945[D loss: 1.000005] [G loss: 1.000006]\n",
      "epoch:36 step:171950[D loss: 0.999951] [G loss: 1.000034]\n",
      "epoch:36 step:171955[D loss: 0.999972] [G loss: 1.000044]\n",
      "epoch:36 step:171960[D loss: 1.000006] [G loss: 1.000025]\n",
      "epoch:36 step:171965[D loss: 0.999947] [G loss: 1.000083]\n",
      "epoch:36 step:171970[D loss: 1.000030] [G loss: 1.000023]\n",
      "epoch:36 step:171975[D loss: 0.999946] [G loss: 1.000120]\n",
      "epoch:36 step:171980[D loss: 0.999985] [G loss: 1.000043]\n",
      "epoch:36 step:171985[D loss: 1.000041] [G loss: 1.000019]\n",
      "epoch:36 step:171990[D loss: 1.000004] [G loss: 1.000069]\n",
      "epoch:36 step:171995[D loss: 0.999973] [G loss: 1.000022]\n",
      "epoch:36 step:172000[D loss: 0.999958] [G loss: 1.000087]\n",
      "epoch:36 step:172005[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:36 step:172010[D loss: 0.999961] [G loss: 1.000076]\n",
      "epoch:36 step:172015[D loss: 0.999953] [G loss: 1.000049]\n",
      "epoch:36 step:172020[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:36 step:172025[D loss: 1.000001] [G loss: 1.000104]\n",
      "epoch:36 step:172030[D loss: 0.999929] [G loss: 1.000103]\n",
      "epoch:36 step:172035[D loss: 1.000000] [G loss: 1.000076]\n",
      "epoch:36 step:172040[D loss: 0.999963] [G loss: 1.000067]\n",
      "epoch:36 step:172045[D loss: 0.999985] [G loss: 1.000053]\n",
      "epoch:36 step:172050[D loss: 0.999995] [G loss: 1.000059]\n",
      "epoch:36 step:172055[D loss: 0.999998] [G loss: 1.000053]\n",
      "epoch:36 step:172060[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:36 step:172065[D loss: 0.999949] [G loss: 1.000103]\n",
      "epoch:36 step:172070[D loss: 1.000045] [G loss: 1.000017]\n",
      "epoch:36 step:172075[D loss: 0.999910] [G loss: 1.000128]\n",
      "epoch:36 step:172080[D loss: 1.000001] [G loss: 0.999982]\n",
      "epoch:36 step:172085[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:36 step:172090[D loss: 0.999979] [G loss: 1.000038]\n",
      "epoch:36 step:172095[D loss: 0.999970] [G loss: 1.000051]\n",
      "epoch:36 step:172100[D loss: 0.999956] [G loss: 1.000078]\n",
      "epoch:36 step:172105[D loss: 1.000050] [G loss: 0.999983]\n",
      "epoch:36 step:172110[D loss: 0.999951] [G loss: 1.000128]\n",
      "epoch:36 step:172115[D loss: 0.999978] [G loss: 1.000080]\n",
      "epoch:36 step:172120[D loss: 0.999923] [G loss: 1.000191]\n",
      "epoch:36 step:172125[D loss: 1.000058] [G loss: 0.999971]\n",
      "epoch:36 step:172130[D loss: 0.999939] [G loss: 1.000142]\n",
      "epoch:36 step:172135[D loss: 0.999905] [G loss: 1.000098]\n",
      "epoch:36 step:172140[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:36 step:172145[D loss: 0.999969] [G loss: 1.000066]\n",
      "epoch:36 step:172150[D loss: 1.000013] [G loss: 1.000021]\n",
      "epoch:36 step:172155[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:36 step:172160[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:36 step:172165[D loss: 0.999990] [G loss: 1.000051]\n",
      "epoch:36 step:172170[D loss: 0.999951] [G loss: 1.000089]\n",
      "epoch:36 step:172175[D loss: 0.999984] [G loss: 1.000048]\n",
      "epoch:36 step:172180[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:36 step:172185[D loss: 0.999991] [G loss: 1.000078]\n",
      "epoch:36 step:172190[D loss: 0.999999] [G loss: 1.000033]\n",
      "epoch:36 step:172195[D loss: 0.999930] [G loss: 1.000102]\n",
      "epoch:36 step:172200[D loss: 0.999945] [G loss: 1.000077]\n",
      "epoch:36 step:172205[D loss: 1.000091] [G loss: 0.999947]\n",
      "epoch:36 step:172210[D loss: 1.000026] [G loss: 1.000059]\n",
      "epoch:36 step:172215[D loss: 1.000099] [G loss: 0.999965]\n",
      "epoch:36 step:172220[D loss: 0.999925] [G loss: 1.000148]\n",
      "epoch:36 step:172225[D loss: 0.999961] [G loss: 1.000106]\n",
      "epoch:36 step:172230[D loss: 0.999945] [G loss: 1.000190]\n",
      "epoch:36 step:172235[D loss: 0.999986] [G loss: 1.000039]\n",
      "epoch:36 step:172240[D loss: 0.999991] [G loss: 1.000023]\n",
      "epoch:36 step:172245[D loss: 0.999943] [G loss: 1.000047]\n",
      "epoch:36 step:172250[D loss: 0.999995] [G loss: 1.000025]\n",
      "epoch:36 step:172255[D loss: 1.000106] [G loss: 0.999919]\n",
      "epoch:36 step:172260[D loss: 0.999969] [G loss: 1.000014]\n",
      "epoch:36 step:172265[D loss: 1.000042] [G loss: 0.999997]\n",
      "epoch:36 step:172270[D loss: 0.999964] [G loss: 1.000117]\n",
      "epoch:36 step:172275[D loss: 0.999949] [G loss: 1.000083]\n",
      "epoch:36 step:172280[D loss: 0.999958] [G loss: 1.000090]\n",
      "epoch:36 step:172285[D loss: 0.999972] [G loss: 1.000051]\n",
      "epoch:36 step:172290[D loss: 1.000015] [G loss: 0.999950]\n",
      "epoch:36 step:172295[D loss: 0.999969] [G loss: 0.999984]\n",
      "epoch:36 step:172300[D loss: 0.999933] [G loss: 1.000250]\n",
      "epoch:36 step:172305[D loss: 0.999909] [G loss: 1.000099]\n",
      "epoch:36 step:172310[D loss: 0.999946] [G loss: 1.000063]\n",
      "epoch:36 step:172315[D loss: 0.999963] [G loss: 1.000092]\n",
      "epoch:36 step:172320[D loss: 0.999930] [G loss: 1.000086]\n",
      "epoch:36 step:172325[D loss: 0.999979] [G loss: 1.000026]\n",
      "epoch:36 step:172330[D loss: 0.999999] [G loss: 1.000000]\n",
      "epoch:36 step:172335[D loss: 0.999939] [G loss: 1.000136]\n",
      "epoch:36 step:172340[D loss: 0.999963] [G loss: 1.000021]\n",
      "epoch:36 step:172345[D loss: 1.000187] [G loss: 0.999924]\n",
      "epoch:36 step:172350[D loss: 0.999947] [G loss: 1.000142]\n",
      "epoch:36 step:172355[D loss: 1.000256] [G loss: 0.999931]\n",
      "epoch:36 step:172360[D loss: 0.999949] [G loss: 1.000262]\n",
      "epoch:36 step:172365[D loss: 0.999977] [G loss: 1.000123]\n",
      "epoch:36 step:172370[D loss: 0.999967] [G loss: 1.000022]\n",
      "epoch:36 step:172375[D loss: 0.999978] [G loss: 1.000096]\n",
      "epoch:36 step:172380[D loss: 0.999969] [G loss: 0.999992]\n",
      "epoch:36 step:172385[D loss: 0.999946] [G loss: 1.000046]\n",
      "epoch:36 step:172390[D loss: 0.999985] [G loss: 0.999984]\n",
      "epoch:36 step:172395[D loss: 0.999978] [G loss: 0.999985]\n",
      "epoch:36 step:172400[D loss: 0.999987] [G loss: 1.000010]\n",
      "epoch:36 step:172405[D loss: 0.999978] [G loss: 0.999997]\n",
      "epoch:36 step:172410[D loss: 1.000088] [G loss: 0.999917]\n",
      "epoch:36 step:172415[D loss: 0.999959] [G loss: 0.999986]\n",
      "epoch:36 step:172420[D loss: 1.000053] [G loss: 0.999827]\n",
      "epoch:36 step:172425[D loss: 1.000070] [G loss: 1.000009]\n",
      "epoch:36 step:172430[D loss: 1.000157] [G loss: 1.000042]\n",
      "epoch:36 step:172435[D loss: 0.999983] [G loss: 1.000080]\n",
      "epoch:36 step:172440[D loss: 0.999965] [G loss: 1.000034]\n",
      "epoch:36 step:172445[D loss: 1.000080] [G loss: 0.999870]\n",
      "epoch:36 step:172450[D loss: 1.000078] [G loss: 0.999937]\n",
      "epoch:36 step:172455[D loss: 0.999997] [G loss: 1.000040]\n",
      "epoch:36 step:172460[D loss: 0.999975] [G loss: 1.000125]\n",
      "epoch:36 step:172465[D loss: 1.000214] [G loss: 0.999872]\n",
      "epoch:36 step:172470[D loss: 0.999927] [G loss: 1.000423]\n",
      "epoch:36 step:172475[D loss: 0.999965] [G loss: 1.000174]\n",
      "epoch:36 step:172480[D loss: 0.999858] [G loss: 1.000319]\n",
      "epoch:36 step:172485[D loss: 0.999935] [G loss: 1.000227]\n",
      "epoch:36 step:172490[D loss: 0.999912] [G loss: 1.000188]\n",
      "epoch:36 step:172495[D loss: 1.000011] [G loss: 1.000157]\n",
      "epoch:36 step:172500[D loss: 1.000003] [G loss: 1.000066]\n",
      "epoch:36 step:172505[D loss: 0.999970] [G loss: 1.000025]\n",
      "epoch:36 step:172510[D loss: 1.000053] [G loss: 0.999942]\n",
      "epoch:36 step:172515[D loss: 1.000006] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:172520[D loss: 1.000079] [G loss: 0.999933]\n",
      "epoch:36 step:172525[D loss: 1.000006] [G loss: 1.000039]\n",
      "epoch:36 step:172530[D loss: 1.000310] [G loss: 0.999878]\n",
      "epoch:36 step:172535[D loss: 0.999902] [G loss: 0.999961]\n",
      "epoch:36 step:172540[D loss: 1.000014] [G loss: 1.000041]\n",
      "epoch:36 step:172545[D loss: 0.999832] [G loss: 1.000193]\n",
      "epoch:36 step:172550[D loss: 0.999959] [G loss: 1.000038]\n",
      "epoch:36 step:172555[D loss: 1.000107] [G loss: 0.999897]\n",
      "epoch:36 step:172560[D loss: 0.999873] [G loss: 1.000113]\n",
      "epoch:36 step:172565[D loss: 0.999959] [G loss: 1.000038]\n",
      "epoch:36 step:172570[D loss: 0.999976] [G loss: 1.000059]\n",
      "epoch:36 step:172575[D loss: 0.999980] [G loss: 1.000092]\n",
      "epoch:36 step:172580[D loss: 1.000001] [G loss: 1.000078]\n",
      "epoch:36 step:172585[D loss: 0.999982] [G loss: 1.000019]\n",
      "epoch:36 step:172590[D loss: 0.999926] [G loss: 1.000119]\n",
      "epoch:36 step:172595[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:36 step:172600[D loss: 0.999984] [G loss: 1.000065]\n",
      "epoch:36 step:172605[D loss: 0.999932] [G loss: 1.000260]\n",
      "epoch:36 step:172610[D loss: 0.999900] [G loss: 1.000086]\n",
      "epoch:36 step:172615[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:36 step:172620[D loss: 0.999952] [G loss: 1.000058]\n",
      "epoch:36 step:172625[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:36 step:172630[D loss: 0.999978] [G loss: 1.000094]\n",
      "epoch:36 step:172635[D loss: 0.999945] [G loss: 1.000113]\n",
      "epoch:36 step:172640[D loss: 0.999952] [G loss: 1.000085]\n",
      "epoch:36 step:172645[D loss: 0.999960] [G loss: 1.000074]\n",
      "epoch:36 step:172650[D loss: 0.999977] [G loss: 1.000089]\n",
      "epoch:36 step:172655[D loss: 0.999967] [G loss: 1.000062]\n",
      "epoch:36 step:172660[D loss: 0.999978] [G loss: 1.000042]\n",
      "epoch:36 step:172665[D loss: 0.999984] [G loss: 1.000063]\n",
      "epoch:36 step:172670[D loss: 0.999955] [G loss: 1.000071]\n",
      "epoch:36 step:172675[D loss: 0.999999] [G loss: 1.000045]\n",
      "epoch:36 step:172680[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:36 step:172685[D loss: 0.999957] [G loss: 1.000097]\n",
      "epoch:36 step:172690[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:36 step:172695[D loss: 0.999981] [G loss: 1.000005]\n",
      "epoch:36 step:172700[D loss: 1.000024] [G loss: 1.000062]\n",
      "epoch:36 step:172705[D loss: 0.999896] [G loss: 1.000149]\n",
      "epoch:36 step:172710[D loss: 0.999964] [G loss: 1.000099]\n",
      "epoch:36 step:172715[D loss: 0.999988] [G loss: 1.000143]\n",
      "epoch:36 step:172720[D loss: 0.999956] [G loss: 1.000103]\n",
      "epoch:36 step:172725[D loss: 0.999957] [G loss: 1.000061]\n",
      "epoch:36 step:172730[D loss: 0.999970] [G loss: 1.000024]\n",
      "epoch:36 step:172735[D loss: 0.999980] [G loss: 1.000057]\n",
      "epoch:36 step:172740[D loss: 1.000003] [G loss: 1.000013]\n",
      "epoch:36 step:172745[D loss: 0.999962] [G loss: 1.000018]\n",
      "epoch:36 step:172750[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:36 step:172755[D loss: 0.999964] [G loss: 1.000058]\n",
      "epoch:36 step:172760[D loss: 0.999969] [G loss: 1.000059]\n",
      "epoch:36 step:172765[D loss: 0.999962] [G loss: 1.000047]\n",
      "epoch:36 step:172770[D loss: 1.000056] [G loss: 0.999968]\n",
      "epoch:36 step:172775[D loss: 0.999986] [G loss: 1.000016]\n",
      "epoch:36 step:172780[D loss: 0.999961] [G loss: 1.000049]\n",
      "epoch:36 step:172785[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:36 step:172790[D loss: 0.999973] [G loss: 1.000068]\n",
      "epoch:36 step:172795[D loss: 1.000006] [G loss: 1.000052]\n",
      "epoch:36 step:172800[D loss: 0.999970] [G loss: 1.000050]\n",
      "epoch:36 step:172805[D loss: 0.999968] [G loss: 1.000135]\n",
      "epoch:36 step:172810[D loss: 0.999914] [G loss: 1.000109]\n",
      "epoch:36 step:172815[D loss: 0.999946] [G loss: 1.000094]\n",
      "epoch:36 step:172820[D loss: 1.000240] [G loss: 0.999853]\n",
      "epoch:36 step:172825[D loss: 1.000057] [G loss: 0.999708]\n",
      "epoch:36 step:172830[D loss: 1.000168] [G loss: 0.999884]\n",
      "epoch:36 step:172835[D loss: 0.999815] [G loss: 1.000128]\n",
      "epoch:36 step:172840[D loss: 0.999891] [G loss: 1.000129]\n",
      "epoch:36 step:172845[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:36 step:172850[D loss: 0.999978] [G loss: 1.000023]\n",
      "epoch:36 step:172855[D loss: 1.000017] [G loss: 1.000064]\n",
      "epoch:36 step:172860[D loss: 0.999996] [G loss: 1.000006]\n",
      "epoch:36 step:172865[D loss: 1.000065] [G loss: 0.999905]\n",
      "epoch:36 step:172870[D loss: 1.000078] [G loss: 0.999901]\n",
      "epoch:36 step:172875[D loss: 1.000067] [G loss: 0.999880]\n",
      "epoch:36 step:172880[D loss: 1.000059] [G loss: 1.000132]\n",
      "epoch:36 step:172885[D loss: 0.999973] [G loss: 1.000070]\n",
      "epoch:36 step:172890[D loss: 0.999893] [G loss: 1.000222]\n",
      "epoch:36 step:172895[D loss: 0.999920] [G loss: 1.000206]\n",
      "epoch:36 step:172900[D loss: 0.999915] [G loss: 1.000178]\n",
      "epoch:36 step:172905[D loss: 1.000101] [G loss: 1.000216]\n",
      "epoch:36 step:172910[D loss: 0.999898] [G loss: 1.000129]\n",
      "epoch:36 step:172915[D loss: 0.999945] [G loss: 1.000089]\n",
      "epoch:36 step:172920[D loss: 0.999992] [G loss: 1.000005]\n",
      "epoch:36 step:172925[D loss: 1.000023] [G loss: 0.999937]\n",
      "epoch:36 step:172930[D loss: 1.000004] [G loss: 0.999895]\n",
      "epoch:36 step:172935[D loss: 1.000040] [G loss: 0.999937]\n",
      "epoch:36 step:172940[D loss: 1.000130] [G loss: 0.999880]\n",
      "epoch:36 step:172945[D loss: 1.000020] [G loss: 1.000021]\n",
      "epoch:36 step:172950[D loss: 1.000084] [G loss: 0.999913]\n",
      "epoch:36 step:172955[D loss: 0.999937] [G loss: 1.000238]\n",
      "epoch:36 step:172960[D loss: 0.999977] [G loss: 1.000059]\n",
      "epoch:36 step:172965[D loss: 0.999907] [G loss: 1.000134]\n",
      "epoch:36 step:172970[D loss: 0.999907] [G loss: 1.000124]\n",
      "epoch:36 step:172975[D loss: 1.000041] [G loss: 0.999971]\n",
      "epoch:36 step:172980[D loss: 1.000126] [G loss: 0.999870]\n",
      "epoch:36 step:172985[D loss: 0.999976] [G loss: 0.999988]\n",
      "epoch:36 step:172990[D loss: 0.999937] [G loss: 1.000064]\n",
      "epoch:36 step:172995[D loss: 1.000039] [G loss: 0.999931]\n",
      "epoch:36 step:173000[D loss: 1.000040] [G loss: 1.000003]\n",
      "epoch:36 step:173005[D loss: 0.999990] [G loss: 1.000165]\n",
      "epoch:36 step:173010[D loss: 1.000047] [G loss: 1.000111]\n",
      "epoch:36 step:173015[D loss: 0.999875] [G loss: 1.000100]\n",
      "epoch:36 step:173020[D loss: 0.999956] [G loss: 1.000077]\n",
      "epoch:36 step:173025[D loss: 1.000048] [G loss: 1.000069]\n",
      "epoch:36 step:173030[D loss: 0.999965] [G loss: 1.000085]\n",
      "epoch:36 step:173035[D loss: 0.999964] [G loss: 1.000057]\n",
      "epoch:36 step:173040[D loss: 1.000029] [G loss: 1.000017]\n",
      "epoch:36 step:173045[D loss: 0.999948] [G loss: 1.000023]\n",
      "epoch:36 step:173050[D loss: 0.999989] [G loss: 1.000080]\n",
      "epoch:36 step:173055[D loss: 1.000009] [G loss: 1.000013]\n",
      "epoch:36 step:173060[D loss: 1.000113] [G loss: 0.999954]\n",
      "epoch:36 step:173065[D loss: 0.999852] [G loss: 1.000170]\n",
      "epoch:36 step:173070[D loss: 0.999949] [G loss: 1.000074]\n",
      "epoch:36 step:173075[D loss: 0.999957] [G loss: 1.000093]\n",
      "epoch:36 step:173080[D loss: 0.999989] [G loss: 1.000046]\n",
      "epoch:36 step:173085[D loss: 1.000088] [G loss: 1.000065]\n",
      "epoch:36 step:173090[D loss: 0.999946] [G loss: 1.000137]\n",
      "epoch:36 step:173095[D loss: 1.000008] [G loss: 1.000072]\n",
      "epoch:36 step:173100[D loss: 0.999935] [G loss: 1.000082]\n",
      "epoch:36 step:173105[D loss: 0.999921] [G loss: 1.000227]\n",
      "epoch:36 step:173110[D loss: 0.999965] [G loss: 1.000086]\n",
      "epoch:36 step:173115[D loss: 0.999986] [G loss: 1.000057]\n",
      "epoch:36 step:173120[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:36 step:173125[D loss: 0.999950] [G loss: 1.000098]\n",
      "epoch:36 step:173130[D loss: 0.999974] [G loss: 1.000067]\n",
      "epoch:36 step:173135[D loss: 0.999978] [G loss: 1.000101]\n",
      "epoch:36 step:173140[D loss: 1.000073] [G loss: 0.999992]\n",
      "epoch:36 step:173145[D loss: 1.000011] [G loss: 0.999941]\n",
      "epoch:36 step:173150[D loss: 0.999962] [G loss: 1.000083]\n",
      "epoch:36 step:173155[D loss: 0.999992] [G loss: 1.000038]\n",
      "epoch:36 step:173160[D loss: 0.999981] [G loss: 1.000081]\n",
      "epoch:36 step:173165[D loss: 0.999987] [G loss: 1.000057]\n",
      "epoch:36 step:173170[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:36 step:173175[D loss: 1.000004] [G loss: 0.999985]\n",
      "epoch:36 step:173180[D loss: 1.000005] [G loss: 0.999991]\n",
      "epoch:36 step:173185[D loss: 0.999993] [G loss: 1.000078]\n",
      "epoch:36 step:173190[D loss: 1.000032] [G loss: 1.000036]\n",
      "epoch:36 step:173195[D loss: 0.999968] [G loss: 1.000024]\n",
      "epoch:36 step:173200[D loss: 1.000007] [G loss: 1.000030]\n",
      "epoch:36 step:173205[D loss: 1.000047] [G loss: 0.999950]\n",
      "epoch:36 step:173210[D loss: 0.999922] [G loss: 1.000104]\n",
      "epoch:36 step:173215[D loss: 1.000020] [G loss: 0.999993]\n",
      "epoch:36 step:173220[D loss: 0.999924] [G loss: 1.000094]\n",
      "epoch:36 step:173225[D loss: 0.999977] [G loss: 1.000056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:173230[D loss: 0.999968] [G loss: 1.000144]\n",
      "epoch:36 step:173235[D loss: 1.000016] [G loss: 1.000081]\n",
      "epoch:36 step:173240[D loss: 0.999958] [G loss: 1.000089]\n",
      "epoch:36 step:173245[D loss: 1.000024] [G loss: 1.000099]\n",
      "epoch:36 step:173250[D loss: 1.000000] [G loss: 0.999982]\n",
      "epoch:36 step:173255[D loss: 1.000026] [G loss: 0.999950]\n",
      "epoch:36 step:173260[D loss: 0.999902] [G loss: 1.000089]\n",
      "epoch:36 step:173265[D loss: 0.999971] [G loss: 1.000027]\n",
      "epoch:36 step:173270[D loss: 1.000015] [G loss: 1.000074]\n",
      "epoch:36 step:173275[D loss: 0.999962] [G loss: 1.000027]\n",
      "epoch:36 step:173280[D loss: 0.999927] [G loss: 1.000084]\n",
      "epoch:36 step:173285[D loss: 0.999952] [G loss: 1.000056]\n",
      "epoch:36 step:173290[D loss: 0.999957] [G loss: 1.000095]\n",
      "epoch:36 step:173295[D loss: 0.999959] [G loss: 1.000071]\n",
      "epoch:36 step:173300[D loss: 1.000067] [G loss: 0.999947]\n",
      "epoch:36 step:173305[D loss: 0.999949] [G loss: 1.000026]\n",
      "epoch:36 step:173310[D loss: 0.999977] [G loss: 1.000031]\n",
      "epoch:36 step:173315[D loss: 0.999969] [G loss: 1.000070]\n",
      "epoch:36 step:173320[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:36 step:173325[D loss: 1.000013] [G loss: 1.000022]\n",
      "epoch:36 step:173330[D loss: 0.999951] [G loss: 1.000078]\n",
      "epoch:36 step:173335[D loss: 1.000034] [G loss: 0.999985]\n",
      "epoch:36 step:173340[D loss: 0.999977] [G loss: 1.000070]\n",
      "epoch:36 step:173345[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:37 step:173350[D loss: 1.000057] [G loss: 1.000001]\n",
      "epoch:37 step:173355[D loss: 0.999986] [G loss: 1.000051]\n",
      "epoch:37 step:173360[D loss: 0.999954] [G loss: 1.000081]\n",
      "epoch:37 step:173365[D loss: 0.999997] [G loss: 1.000065]\n",
      "epoch:37 step:173370[D loss: 0.999965] [G loss: 1.000063]\n",
      "epoch:37 step:173375[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:37 step:173380[D loss: 0.999994] [G loss: 1.000005]\n",
      "epoch:37 step:173385[D loss: 0.999981] [G loss: 1.000028]\n",
      "epoch:37 step:173390[D loss: 1.000004] [G loss: 1.000039]\n",
      "epoch:37 step:173395[D loss: 1.000052] [G loss: 1.000025]\n",
      "epoch:37 step:173400[D loss: 1.000008] [G loss: 1.000050]\n",
      "epoch:37 step:173405[D loss: 0.999878] [G loss: 1.000140]\n",
      "epoch:37 step:173410[D loss: 0.999928] [G loss: 1.000120]\n",
      "epoch:37 step:173415[D loss: 0.999962] [G loss: 1.000056]\n",
      "epoch:37 step:173420[D loss: 1.000042] [G loss: 0.999997]\n",
      "epoch:37 step:173425[D loss: 0.999947] [G loss: 1.000118]\n",
      "epoch:37 step:173430[D loss: 0.999954] [G loss: 1.000073]\n",
      "epoch:37 step:173435[D loss: 1.000052] [G loss: 0.999977]\n",
      "epoch:37 step:173440[D loss: 0.999967] [G loss: 1.000019]\n",
      "epoch:37 step:173445[D loss: 0.999968] [G loss: 1.000042]\n",
      "epoch:37 step:173450[D loss: 0.999991] [G loss: 1.000171]\n",
      "epoch:37 step:173455[D loss: 1.000006] [G loss: 1.000095]\n",
      "epoch:37 step:173460[D loss: 0.999970] [G loss: 1.000068]\n",
      "epoch:37 step:173465[D loss: 0.999986] [G loss: 1.000128]\n",
      "epoch:37 step:173470[D loss: 0.999925] [G loss: 1.000094]\n",
      "epoch:37 step:173475[D loss: 0.999972] [G loss: 1.000139]\n",
      "epoch:37 step:173480[D loss: 0.999986] [G loss: 1.000142]\n",
      "epoch:37 step:173485[D loss: 0.999961] [G loss: 1.000065]\n",
      "epoch:37 step:173490[D loss: 1.000066] [G loss: 0.999941]\n",
      "epoch:37 step:173495[D loss: 0.999972] [G loss: 1.000134]\n",
      "epoch:37 step:173500[D loss: 0.999974] [G loss: 1.000064]\n",
      "epoch:37 step:173505[D loss: 1.000035] [G loss: 1.000071]\n",
      "epoch:37 step:173510[D loss: 1.000016] [G loss: 0.999977]\n",
      "epoch:37 step:173515[D loss: 1.000034] [G loss: 1.000003]\n",
      "epoch:37 step:173520[D loss: 0.999948] [G loss: 1.000143]\n",
      "epoch:37 step:173525[D loss: 1.000070] [G loss: 1.000028]\n",
      "epoch:37 step:173530[D loss: 1.000060] [G loss: 1.000044]\n",
      "epoch:37 step:173535[D loss: 0.999966] [G loss: 1.000058]\n",
      "epoch:37 step:173540[D loss: 1.000046] [G loss: 0.999933]\n",
      "epoch:37 step:173545[D loss: 1.000130] [G loss: 1.000088]\n",
      "epoch:37 step:173550[D loss: 0.999987] [G loss: 1.000031]\n",
      "epoch:37 step:173555[D loss: 0.999932] [G loss: 0.999991]\n",
      "epoch:37 step:173560[D loss: 1.000006] [G loss: 1.000038]\n",
      "epoch:37 step:173565[D loss: 0.999995] [G loss: 1.000049]\n",
      "epoch:37 step:173570[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:37 step:173575[D loss: 0.999938] [G loss: 1.000045]\n",
      "epoch:37 step:173580[D loss: 0.999937] [G loss: 1.000072]\n",
      "epoch:37 step:173585[D loss: 0.999939] [G loss: 1.000174]\n",
      "epoch:37 step:173590[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:37 step:173595[D loss: 1.000007] [G loss: 1.000036]\n",
      "epoch:37 step:173600[D loss: 0.999965] [G loss: 1.000091]\n",
      "epoch:37 step:173605[D loss: 1.000012] [G loss: 1.000018]\n",
      "epoch:37 step:173610[D loss: 0.999952] [G loss: 1.000092]\n",
      "epoch:37 step:173615[D loss: 1.000018] [G loss: 0.999983]\n",
      "epoch:37 step:173620[D loss: 0.999944] [G loss: 1.000091]\n",
      "epoch:37 step:173625[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:37 step:173630[D loss: 1.000025] [G loss: 1.000053]\n",
      "epoch:37 step:173635[D loss: 0.999942] [G loss: 1.000120]\n",
      "epoch:37 step:173640[D loss: 0.999940] [G loss: 1.000180]\n",
      "epoch:37 step:173645[D loss: 0.999993] [G loss: 1.000027]\n",
      "epoch:37 step:173650[D loss: 0.999958] [G loss: 1.000068]\n",
      "epoch:37 step:173655[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:37 step:173660[D loss: 1.000033] [G loss: 0.999979]\n",
      "epoch:37 step:173665[D loss: 0.999973] [G loss: 1.000124]\n",
      "epoch:37 step:173670[D loss: 1.000070] [G loss: 0.999940]\n",
      "epoch:37 step:173675[D loss: 1.000041] [G loss: 0.999986]\n",
      "epoch:37 step:173680[D loss: 1.000019] [G loss: 1.000026]\n",
      "epoch:37 step:173685[D loss: 0.999953] [G loss: 1.000030]\n",
      "epoch:37 step:173690[D loss: 1.000177] [G loss: 0.999904]\n",
      "epoch:37 step:173695[D loss: 0.999840] [G loss: 1.000328]\n",
      "epoch:37 step:173700[D loss: 0.999926] [G loss: 1.000165]\n",
      "epoch:37 step:173705[D loss: 1.000031] [G loss: 1.000116]\n",
      "epoch:37 step:173710[D loss: 0.999990] [G loss: 1.000035]\n",
      "epoch:37 step:173715[D loss: 1.000168] [G loss: 0.999807]\n",
      "epoch:37 step:173720[D loss: 1.000044] [G loss: 0.999901]\n",
      "epoch:37 step:173725[D loss: 0.999903] [G loss: 0.999998]\n",
      "epoch:37 step:173730[D loss: 1.000053] [G loss: 1.000002]\n",
      "epoch:37 step:173735[D loss: 0.999895] [G loss: 1.000294]\n",
      "epoch:37 step:173740[D loss: 0.999894] [G loss: 1.000191]\n",
      "epoch:37 step:173745[D loss: 0.999868] [G loss: 1.000229]\n",
      "epoch:37 step:173750[D loss: 0.999797] [G loss: 1.000446]\n",
      "epoch:37 step:173755[D loss: 0.999939] [G loss: 1.000066]\n",
      "epoch:37 step:173760[D loss: 0.999950] [G loss: 1.000077]\n",
      "epoch:37 step:173765[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:37 step:173770[D loss: 1.000056] [G loss: 0.999933]\n",
      "epoch:37 step:173775[D loss: 0.999977] [G loss: 0.999920]\n",
      "epoch:37 step:173780[D loss: 1.000009] [G loss: 1.000023]\n",
      "epoch:37 step:173785[D loss: 0.999843] [G loss: 1.000192]\n",
      "epoch:37 step:173790[D loss: 1.000265] [G loss: 0.999850]\n",
      "epoch:37 step:173795[D loss: 1.000023] [G loss: 0.999947]\n",
      "epoch:37 step:173800[D loss: 0.999824] [G loss: 1.000160]\n",
      "epoch:37 step:173805[D loss: 0.999916] [G loss: 1.000127]\n",
      "epoch:37 step:173810[D loss: 0.999912] [G loss: 1.000116]\n",
      "epoch:37 step:173815[D loss: 0.999985] [G loss: 1.000048]\n",
      "epoch:37 step:173820[D loss: 1.000036] [G loss: 1.000022]\n",
      "epoch:37 step:173825[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:37 step:173830[D loss: 1.000127] [G loss: 0.999877]\n",
      "epoch:37 step:173835[D loss: 0.999955] [G loss: 1.000093]\n",
      "epoch:37 step:173840[D loss: 1.000025] [G loss: 1.000012]\n",
      "epoch:37 step:173845[D loss: 1.000046] [G loss: 0.999899]\n",
      "epoch:37 step:173850[D loss: 0.999896] [G loss: 1.000118]\n",
      "epoch:37 step:173855[D loss: 0.999947] [G loss: 1.000095]\n",
      "epoch:37 step:173860[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:37 step:173865[D loss: 0.999981] [G loss: 1.000038]\n",
      "epoch:37 step:173870[D loss: 0.999980] [G loss: 0.999990]\n",
      "epoch:37 step:173875[D loss: 0.999939] [G loss: 1.000019]\n",
      "epoch:37 step:173880[D loss: 0.999970] [G loss: 1.000082]\n",
      "epoch:37 step:173885[D loss: 1.000005] [G loss: 0.999992]\n",
      "epoch:37 step:173890[D loss: 0.999942] [G loss: 1.000049]\n",
      "epoch:37 step:173895[D loss: 0.999984] [G loss: 1.000015]\n",
      "epoch:37 step:173900[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:37 step:173905[D loss: 0.999978] [G loss: 1.000071]\n",
      "epoch:37 step:173910[D loss: 1.000026] [G loss: 1.000001]\n",
      "epoch:37 step:173915[D loss: 1.000029] [G loss: 0.999948]\n",
      "epoch:37 step:173920[D loss: 1.000070] [G loss: 1.000001]\n",
      "epoch:37 step:173925[D loss: 0.999969] [G loss: 1.000050]\n",
      "epoch:37 step:173930[D loss: 1.000087] [G loss: 1.000092]\n",
      "epoch:37 step:173935[D loss: 1.000179] [G loss: 0.999907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:173940[D loss: 1.000223] [G loss: 0.999691]\n",
      "epoch:37 step:173945[D loss: 1.000055] [G loss: 0.999964]\n",
      "epoch:37 step:173950[D loss: 0.999953] [G loss: 1.000069]\n",
      "epoch:37 step:173955[D loss: 0.999934] [G loss: 1.000116]\n",
      "epoch:37 step:173960[D loss: 0.999966] [G loss: 1.000074]\n",
      "epoch:37 step:173965[D loss: 1.000023] [G loss: 0.999998]\n",
      "epoch:37 step:173970[D loss: 1.000099] [G loss: 0.999913]\n",
      "epoch:37 step:173975[D loss: 0.999938] [G loss: 1.000030]\n",
      "epoch:37 step:173980[D loss: 1.000085] [G loss: 0.999816]\n",
      "epoch:37 step:173985[D loss: 1.000009] [G loss: 1.000002]\n",
      "epoch:37 step:173990[D loss: 1.000032] [G loss: 1.000013]\n",
      "epoch:37 step:173995[D loss: 0.999928] [G loss: 0.999997]\n",
      "epoch:37 step:174000[D loss: 0.999962] [G loss: 1.000097]\n",
      "epoch:37 step:174005[D loss: 0.999891] [G loss: 1.000137]\n",
      "epoch:37 step:174010[D loss: 1.000038] [G loss: 0.999981]\n",
      "epoch:37 step:174015[D loss: 0.999928] [G loss: 1.000134]\n",
      "epoch:37 step:174020[D loss: 0.999891] [G loss: 1.000116]\n",
      "epoch:37 step:174025[D loss: 0.999970] [G loss: 1.000024]\n",
      "epoch:37 step:174030[D loss: 0.999988] [G loss: 1.000036]\n",
      "epoch:37 step:174035[D loss: 0.999958] [G loss: 1.000043]\n",
      "epoch:37 step:174040[D loss: 0.999974] [G loss: 1.000061]\n",
      "epoch:37 step:174045[D loss: 0.999970] [G loss: 1.000085]\n",
      "epoch:37 step:174050[D loss: 0.999988] [G loss: 1.000050]\n",
      "epoch:37 step:174055[D loss: 0.999956] [G loss: 1.000100]\n",
      "epoch:37 step:174060[D loss: 0.999969] [G loss: 1.000068]\n",
      "epoch:37 step:174065[D loss: 0.999976] [G loss: 1.000051]\n",
      "epoch:37 step:174070[D loss: 0.999946] [G loss: 1.000072]\n",
      "epoch:37 step:174075[D loss: 0.999989] [G loss: 1.000026]\n",
      "epoch:37 step:174080[D loss: 0.999991] [G loss: 1.000106]\n",
      "epoch:37 step:174085[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:37 step:174090[D loss: 0.999991] [G loss: 1.000003]\n",
      "epoch:37 step:174095[D loss: 0.999990] [G loss: 1.000043]\n",
      "epoch:37 step:174100[D loss: 0.999973] [G loss: 1.000051]\n",
      "epoch:37 step:174105[D loss: 0.999979] [G loss: 1.000043]\n",
      "epoch:37 step:174110[D loss: 0.999961] [G loss: 1.000077]\n",
      "epoch:37 step:174115[D loss: 0.999983] [G loss: 1.000081]\n",
      "epoch:37 step:174120[D loss: 0.999891] [G loss: 1.000193]\n",
      "epoch:37 step:174125[D loss: 0.999995] [G loss: 1.000136]\n",
      "epoch:37 step:174130[D loss: 1.000009] [G loss: 0.999989]\n",
      "epoch:37 step:174135[D loss: 1.000028] [G loss: 1.000013]\n",
      "epoch:37 step:174140[D loss: 0.999961] [G loss: 1.000045]\n",
      "epoch:37 step:174145[D loss: 1.000064] [G loss: 0.999993]\n",
      "epoch:37 step:174150[D loss: 1.000062] [G loss: 0.999988]\n",
      "epoch:37 step:174155[D loss: 1.000006] [G loss: 1.000093]\n",
      "epoch:37 step:174160[D loss: 0.999917] [G loss: 1.000130]\n",
      "epoch:37 step:174165[D loss: 0.999874] [G loss: 1.000148]\n",
      "epoch:37 step:174170[D loss: 1.000050] [G loss: 0.999949]\n",
      "epoch:37 step:174175[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:37 step:174180[D loss: 0.999963] [G loss: 0.999970]\n",
      "epoch:37 step:174185[D loss: 0.999898] [G loss: 1.000113]\n",
      "epoch:37 step:174190[D loss: 0.999935] [G loss: 1.000090]\n",
      "epoch:37 step:174195[D loss: 0.999992] [G loss: 1.000055]\n",
      "epoch:37 step:174200[D loss: 0.999958] [G loss: 1.000079]\n",
      "epoch:37 step:174205[D loss: 1.000013] [G loss: 1.000066]\n",
      "epoch:37 step:174210[D loss: 0.999925] [G loss: 1.000109]\n",
      "epoch:37 step:174215[D loss: 0.999946] [G loss: 1.000119]\n",
      "epoch:37 step:174220[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:37 step:174225[D loss: 0.999995] [G loss: 1.000027]\n",
      "epoch:37 step:174230[D loss: 0.999996] [G loss: 1.000131]\n",
      "epoch:37 step:174235[D loss: 1.000004] [G loss: 1.000055]\n",
      "epoch:37 step:174240[D loss: 1.000017] [G loss: 1.000078]\n",
      "epoch:37 step:174245[D loss: 0.999965] [G loss: 1.000084]\n",
      "epoch:37 step:174250[D loss: 0.999985] [G loss: 1.000098]\n",
      "epoch:37 step:174255[D loss: 1.000006] [G loss: 1.000058]\n",
      "epoch:37 step:174260[D loss: 1.000057] [G loss: 0.999983]\n",
      "epoch:37 step:174265[D loss: 0.999966] [G loss: 1.000095]\n",
      "epoch:37 step:174270[D loss: 1.000088] [G loss: 1.000001]\n",
      "epoch:37 step:174275[D loss: 0.999994] [G loss: 0.999968]\n",
      "epoch:37 step:174280[D loss: 0.999967] [G loss: 1.000047]\n",
      "epoch:37 step:174285[D loss: 1.000091] [G loss: 1.000069]\n",
      "epoch:37 step:174290[D loss: 0.999853] [G loss: 1.000159]\n",
      "epoch:37 step:174295[D loss: 0.999925] [G loss: 1.000094]\n",
      "epoch:37 step:174300[D loss: 0.999961] [G loss: 1.000116]\n",
      "epoch:37 step:174305[D loss: 0.999956] [G loss: 1.000136]\n",
      "epoch:37 step:174310[D loss: 0.999993] [G loss: 1.000143]\n",
      "epoch:37 step:174315[D loss: 1.000039] [G loss: 0.999987]\n",
      "epoch:37 step:174320[D loss: 1.000044] [G loss: 0.999971]\n",
      "epoch:37 step:174325[D loss: 1.000095] [G loss: 0.999825]\n",
      "epoch:37 step:174330[D loss: 1.000126] [G loss: 0.999887]\n",
      "epoch:37 step:174335[D loss: 1.000105] [G loss: 1.000131]\n",
      "epoch:37 step:174340[D loss: 1.000059] [G loss: 0.999945]\n",
      "epoch:37 step:174345[D loss: 1.000133] [G loss: 1.000211]\n",
      "epoch:37 step:174350[D loss: 0.999858] [G loss: 1.000246]\n",
      "epoch:37 step:174355[D loss: 0.999968] [G loss: 1.000313]\n",
      "epoch:37 step:174360[D loss: 0.999915] [G loss: 1.000358]\n",
      "epoch:37 step:174365[D loss: 0.999925] [G loss: 1.000168]\n",
      "epoch:37 step:174370[D loss: 1.000004] [G loss: 1.000057]\n",
      "epoch:37 step:174375[D loss: 0.999989] [G loss: 1.000021]\n",
      "epoch:37 step:174380[D loss: 1.000103] [G loss: 0.999886]\n",
      "epoch:37 step:174385[D loss: 0.999904] [G loss: 0.999998]\n",
      "epoch:37 step:174390[D loss: 1.000186] [G loss: 0.999857]\n",
      "epoch:37 step:174395[D loss: 0.999930] [G loss: 1.000150]\n",
      "epoch:37 step:174400[D loss: 1.000271] [G loss: 0.999636]\n",
      "epoch:37 step:174405[D loss: 1.000026] [G loss: 1.000082]\n",
      "epoch:37 step:174410[D loss: 1.000008] [G loss: 1.000137]\n",
      "epoch:37 step:174415[D loss: 0.999894] [G loss: 1.000154]\n",
      "epoch:37 step:174420[D loss: 0.999844] [G loss: 1.000269]\n",
      "epoch:37 step:174425[D loss: 0.999867] [G loss: 1.000333]\n",
      "epoch:37 step:174430[D loss: 1.000399] [G loss: 0.999996]\n",
      "epoch:37 step:174435[D loss: 0.999708] [G loss: 1.000422]\n",
      "epoch:37 step:174440[D loss: 0.999816] [G loss: 1.000296]\n",
      "epoch:37 step:174445[D loss: 1.000016] [G loss: 1.000016]\n",
      "epoch:37 step:174450[D loss: 0.999966] [G loss: 1.000115]\n",
      "epoch:37 step:174455[D loss: 1.000065] [G loss: 0.999929]\n",
      "epoch:37 step:174460[D loss: 1.000082] [G loss: 0.999974]\n",
      "epoch:37 step:174465[D loss: 1.000020] [G loss: 0.999984]\n",
      "epoch:37 step:174470[D loss: 1.000102] [G loss: 0.999936]\n",
      "epoch:37 step:174475[D loss: 1.000160] [G loss: 0.999973]\n",
      "epoch:37 step:174480[D loss: 1.000157] [G loss: 1.000088]\n",
      "epoch:37 step:174485[D loss: 0.999865] [G loss: 1.000047]\n",
      "epoch:37 step:174490[D loss: 0.999854] [G loss: 1.000113]\n",
      "epoch:37 step:174495[D loss: 0.999951] [G loss: 1.000233]\n",
      "epoch:37 step:174500[D loss: 0.999855] [G loss: 1.000342]\n",
      "epoch:37 step:174505[D loss: 0.999919] [G loss: 1.000308]\n",
      "epoch:37 step:174510[D loss: 1.000046] [G loss: 1.000237]\n",
      "epoch:37 step:174515[D loss: 1.000030] [G loss: 1.000341]\n",
      "epoch:37 step:174520[D loss: 0.999972] [G loss: 1.000408]\n",
      "epoch:37 step:174525[D loss: 0.999853] [G loss: 1.000344]\n",
      "epoch:37 step:174530[D loss: 1.000006] [G loss: 1.000070]\n",
      "epoch:37 step:174535[D loss: 1.000015] [G loss: 0.999901]\n",
      "epoch:37 step:174540[D loss: 1.000063] [G loss: 0.999986]\n",
      "epoch:37 step:174545[D loss: 1.000106] [G loss: 0.999831]\n",
      "epoch:37 step:174550[D loss: 1.000094] [G loss: 0.999940]\n",
      "epoch:37 step:174555[D loss: 1.000041] [G loss: 0.999911]\n",
      "epoch:37 step:174560[D loss: 0.999959] [G loss: 0.999991]\n",
      "epoch:37 step:174565[D loss: 1.000257] [G loss: 0.999795]\n",
      "epoch:37 step:174570[D loss: 0.999889] [G loss: 0.999871]\n",
      "epoch:37 step:174575[D loss: 0.999867] [G loss: 1.000123]\n",
      "epoch:37 step:174580[D loss: 0.999894] [G loss: 1.000025]\n",
      "epoch:37 step:174585[D loss: 0.999930] [G loss: 1.000322]\n",
      "epoch:37 step:174590[D loss: 0.999976] [G loss: 1.000270]\n",
      "epoch:37 step:174595[D loss: 0.999986] [G loss: 1.000061]\n",
      "epoch:37 step:174600[D loss: 1.000009] [G loss: 0.999967]\n",
      "epoch:37 step:174605[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:37 step:174610[D loss: 1.000091] [G loss: 0.999968]\n",
      "epoch:37 step:174615[D loss: 1.000161] [G loss: 0.999954]\n",
      "epoch:37 step:174620[D loss: 1.000129] [G loss: 0.999900]\n",
      "epoch:37 step:174625[D loss: 0.999925] [G loss: 1.000169]\n",
      "epoch:37 step:174630[D loss: 1.000020] [G loss: 1.000023]\n",
      "epoch:37 step:174635[D loss: 1.000063] [G loss: 1.000196]\n",
      "epoch:37 step:174640[D loss: 0.999809] [G loss: 1.000275]\n",
      "epoch:37 step:174645[D loss: 1.000016] [G loss: 1.000039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:174650[D loss: 0.999892] [G loss: 1.000168]\n",
      "epoch:37 step:174655[D loss: 0.999969] [G loss: 1.000091]\n",
      "epoch:37 step:174660[D loss: 1.000126] [G loss: 0.999890]\n",
      "epoch:37 step:174665[D loss: 0.999945] [G loss: 1.000170]\n",
      "epoch:37 step:174670[D loss: 0.999901] [G loss: 1.000129]\n",
      "epoch:37 step:174675[D loss: 1.000017] [G loss: 1.000127]\n",
      "epoch:37 step:174680[D loss: 0.999982] [G loss: 1.000028]\n",
      "epoch:37 step:174685[D loss: 0.999907] [G loss: 1.000108]\n",
      "epoch:37 step:174690[D loss: 0.999989] [G loss: 1.000066]\n",
      "epoch:37 step:174695[D loss: 1.000073] [G loss: 0.999983]\n",
      "epoch:37 step:174700[D loss: 0.999955] [G loss: 1.000123]\n",
      "epoch:37 step:174705[D loss: 1.000090] [G loss: 1.000120]\n",
      "epoch:37 step:174710[D loss: 0.999843] [G loss: 1.000363]\n",
      "epoch:37 step:174715[D loss: 0.999923] [G loss: 1.000146]\n",
      "epoch:37 step:174720[D loss: 0.999963] [G loss: 1.000040]\n",
      "epoch:37 step:174725[D loss: 1.000040] [G loss: 0.999979]\n",
      "epoch:37 step:174730[D loss: 1.000043] [G loss: 0.999979]\n",
      "epoch:37 step:174735[D loss: 1.000073] [G loss: 0.999874]\n",
      "epoch:37 step:174740[D loss: 0.999835] [G loss: 1.000204]\n",
      "epoch:37 step:174745[D loss: 0.999919] [G loss: 1.000273]\n",
      "epoch:37 step:174750[D loss: 0.999924] [G loss: 1.000132]\n",
      "epoch:37 step:174755[D loss: 0.999974] [G loss: 1.000157]\n",
      "epoch:37 step:174760[D loss: 0.999930] [G loss: 1.000197]\n",
      "epoch:37 step:174765[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:37 step:174770[D loss: 1.000034] [G loss: 0.999934]\n",
      "epoch:37 step:174775[D loss: 0.999951] [G loss: 1.000084]\n",
      "epoch:37 step:174780[D loss: 0.999952] [G loss: 1.000116]\n",
      "epoch:37 step:174785[D loss: 0.999966] [G loss: 1.000090]\n",
      "epoch:37 step:174790[D loss: 0.999980] [G loss: 1.000152]\n",
      "epoch:37 step:174795[D loss: 0.999958] [G loss: 1.000100]\n",
      "epoch:37 step:174800[D loss: 0.999972] [G loss: 1.000063]\n",
      "epoch:37 step:174805[D loss: 0.999977] [G loss: 1.000061]\n",
      "epoch:37 step:174810[D loss: 1.000011] [G loss: 1.000117]\n",
      "epoch:37 step:174815[D loss: 0.999931] [G loss: 1.000166]\n",
      "epoch:37 step:174820[D loss: 1.000024] [G loss: 1.000190]\n",
      "epoch:37 step:174825[D loss: 0.999970] [G loss: 1.000077]\n",
      "epoch:37 step:174830[D loss: 0.999952] [G loss: 1.000088]\n",
      "epoch:37 step:174835[D loss: 1.000027] [G loss: 0.999971]\n",
      "epoch:37 step:174840[D loss: 0.999972] [G loss: 1.000078]\n",
      "epoch:37 step:174845[D loss: 1.000031] [G loss: 1.000084]\n",
      "epoch:37 step:174850[D loss: 0.999935] [G loss: 1.000146]\n",
      "epoch:37 step:174855[D loss: 0.999977] [G loss: 1.000167]\n",
      "epoch:37 step:174860[D loss: 1.000047] [G loss: 1.000106]\n",
      "epoch:37 step:174865[D loss: 0.999947] [G loss: 1.000094]\n",
      "epoch:37 step:174870[D loss: 0.999955] [G loss: 1.000099]\n",
      "epoch:37 step:174875[D loss: 1.000073] [G loss: 0.999899]\n",
      "epoch:37 step:174880[D loss: 0.999948] [G loss: 1.000030]\n",
      "epoch:37 step:174885[D loss: 0.999987] [G loss: 1.000030]\n",
      "epoch:37 step:174890[D loss: 1.000033] [G loss: 0.999924]\n",
      "epoch:37 step:174895[D loss: 0.999906] [G loss: 1.000017]\n",
      "epoch:37 step:174900[D loss: 1.000004] [G loss: 0.999983]\n",
      "epoch:37 step:174905[D loss: 0.999969] [G loss: 1.000043]\n",
      "epoch:37 step:174910[D loss: 0.999980] [G loss: 1.000034]\n",
      "epoch:37 step:174915[D loss: 0.999968] [G loss: 1.000045]\n",
      "epoch:37 step:174920[D loss: 1.000033] [G loss: 0.999984]\n",
      "epoch:37 step:174925[D loss: 1.000104] [G loss: 0.999979]\n",
      "epoch:37 step:174930[D loss: 0.999938] [G loss: 0.999981]\n",
      "epoch:37 step:174935[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:37 step:174940[D loss: 0.999995] [G loss: 1.000048]\n",
      "epoch:37 step:174945[D loss: 0.999940] [G loss: 1.000050]\n",
      "epoch:37 step:174950[D loss: 1.000134] [G loss: 0.999856]\n",
      "epoch:37 step:174955[D loss: 1.000070] [G loss: 0.999848]\n",
      "epoch:37 step:174960[D loss: 0.999876] [G loss: 1.000245]\n",
      "epoch:37 step:174965[D loss: 0.999956] [G loss: 1.000057]\n",
      "epoch:37 step:174970[D loss: 0.999958] [G loss: 1.000037]\n",
      "epoch:37 step:174975[D loss: 1.000035] [G loss: 0.999973]\n",
      "epoch:37 step:174980[D loss: 1.000061] [G loss: 0.999934]\n",
      "epoch:37 step:174985[D loss: 0.999931] [G loss: 1.000028]\n",
      "epoch:37 step:174990[D loss: 1.000029] [G loss: 1.000013]\n",
      "epoch:37 step:174995[D loss: 0.999886] [G loss: 1.000092]\n",
      "epoch:37 step:175000[D loss: 0.999927] [G loss: 1.000102]\n",
      "epoch:37 step:175005[D loss: 0.999961] [G loss: 1.000062]\n",
      "epoch:37 step:175010[D loss: 0.999950] [G loss: 1.000103]\n",
      "epoch:37 step:175015[D loss: 1.000019] [G loss: 1.000033]\n",
      "epoch:37 step:175020[D loss: 0.999965] [G loss: 0.999999]\n",
      "epoch:37 step:175025[D loss: 1.000062] [G loss: 0.999900]\n",
      "epoch:37 step:175030[D loss: 1.000072] [G loss: 0.999932]\n",
      "epoch:37 step:175035[D loss: 0.999918] [G loss: 1.000200]\n",
      "epoch:37 step:175040[D loss: 1.000012] [G loss: 1.000060]\n",
      "epoch:37 step:175045[D loss: 0.999871] [G loss: 1.000115]\n",
      "epoch:37 step:175050[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:37 step:175055[D loss: 1.000026] [G loss: 0.999934]\n",
      "epoch:37 step:175060[D loss: 0.999990] [G loss: 1.000027]\n",
      "epoch:37 step:175065[D loss: 0.999939] [G loss: 1.000106]\n",
      "epoch:37 step:175070[D loss: 0.999929] [G loss: 1.000087]\n",
      "epoch:37 step:175075[D loss: 1.000101] [G loss: 1.000151]\n",
      "epoch:37 step:175080[D loss: 0.999891] [G loss: 1.000116]\n",
      "epoch:37 step:175085[D loss: 0.999948] [G loss: 1.000055]\n",
      "epoch:37 step:175090[D loss: 1.000123] [G loss: 1.000052]\n",
      "epoch:37 step:175095[D loss: 0.999900] [G loss: 1.000156]\n",
      "epoch:37 step:175100[D loss: 0.999995] [G loss: 1.000107]\n",
      "epoch:37 step:175105[D loss: 0.999982] [G loss: 1.000152]\n",
      "epoch:37 step:175110[D loss: 0.999992] [G loss: 1.000079]\n",
      "epoch:37 step:175115[D loss: 1.000011] [G loss: 1.000054]\n",
      "epoch:37 step:175120[D loss: 0.999989] [G loss: 1.000006]\n",
      "epoch:37 step:175125[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:37 step:175130[D loss: 0.999940] [G loss: 1.000078]\n",
      "epoch:37 step:175135[D loss: 1.000238] [G loss: 0.999817]\n",
      "epoch:37 step:175140[D loss: 0.999916] [G loss: 1.000027]\n",
      "epoch:37 step:175145[D loss: 1.000233] [G loss: 0.999869]\n",
      "epoch:37 step:175150[D loss: 1.000037] [G loss: 1.000055]\n",
      "epoch:37 step:175155[D loss: 0.999941] [G loss: 1.000051]\n",
      "epoch:37 step:175160[D loss: 0.999989] [G loss: 0.999996]\n",
      "epoch:37 step:175165[D loss: 1.000125] [G loss: 0.999893]\n",
      "epoch:37 step:175170[D loss: 1.000064] [G loss: 1.000024]\n",
      "epoch:37 step:175175[D loss: 1.000033] [G loss: 1.000023]\n",
      "epoch:37 step:175180[D loss: 1.000098] [G loss: 1.000082]\n",
      "epoch:37 step:175185[D loss: 0.999870] [G loss: 1.000167]\n",
      "epoch:37 step:175190[D loss: 0.999991] [G loss: 1.000172]\n",
      "epoch:37 step:175195[D loss: 0.999934] [G loss: 1.000142]\n",
      "epoch:37 step:175200[D loss: 0.999939] [G loss: 1.000263]\n",
      "epoch:37 step:175205[D loss: 0.999951] [G loss: 1.000130]\n",
      "epoch:37 step:175210[D loss: 0.999964] [G loss: 1.000039]\n",
      "epoch:37 step:175215[D loss: 1.000013] [G loss: 1.000125]\n",
      "epoch:37 step:175220[D loss: 1.000044] [G loss: 0.999876]\n",
      "epoch:37 step:175225[D loss: 1.000026] [G loss: 0.999944]\n",
      "epoch:37 step:175230[D loss: 0.999970] [G loss: 0.999963]\n",
      "epoch:37 step:175235[D loss: 1.000136] [G loss: 1.000013]\n",
      "epoch:37 step:175240[D loss: 1.000131] [G loss: 0.999908]\n",
      "epoch:37 step:175245[D loss: 0.999835] [G loss: 1.000086]\n",
      "epoch:37 step:175250[D loss: 0.999948] [G loss: 1.000064]\n",
      "epoch:37 step:175255[D loss: 0.999897] [G loss: 1.000107]\n",
      "epoch:37 step:175260[D loss: 0.999947] [G loss: 1.000069]\n",
      "epoch:37 step:175265[D loss: 0.999960] [G loss: 1.000054]\n",
      "epoch:37 step:175270[D loss: 1.000049] [G loss: 1.000018]\n",
      "epoch:37 step:175275[D loss: 0.999953] [G loss: 1.000052]\n",
      "epoch:37 step:175280[D loss: 1.000087] [G loss: 0.999952]\n",
      "epoch:37 step:175285[D loss: 0.999950] [G loss: 1.000039]\n",
      "epoch:37 step:175290[D loss: 0.999973] [G loss: 1.000101]\n",
      "epoch:37 step:175295[D loss: 1.000008] [G loss: 0.999999]\n",
      "epoch:37 step:175300[D loss: 1.000038] [G loss: 0.999933]\n",
      "epoch:37 step:175305[D loss: 1.000011] [G loss: 1.000048]\n",
      "epoch:37 step:175310[D loss: 0.999953] [G loss: 1.000048]\n",
      "epoch:37 step:175315[D loss: 0.999979] [G loss: 1.000059]\n",
      "epoch:37 step:175320[D loss: 0.999994] [G loss: 1.000053]\n",
      "epoch:37 step:175325[D loss: 0.999994] [G loss: 1.000102]\n",
      "epoch:37 step:175330[D loss: 0.999941] [G loss: 1.000071]\n",
      "epoch:37 step:175335[D loss: 0.999986] [G loss: 1.000047]\n",
      "epoch:37 step:175340[D loss: 1.000020] [G loss: 1.000034]\n",
      "epoch:37 step:175345[D loss: 0.999949] [G loss: 1.000050]\n",
      "epoch:37 step:175350[D loss: 0.999935] [G loss: 1.000168]\n",
      "epoch:37 step:175355[D loss: 0.999961] [G loss: 1.000117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:175360[D loss: 1.000004] [G loss: 1.000032]\n",
      "epoch:37 step:175365[D loss: 0.999951] [G loss: 1.000095]\n",
      "epoch:37 step:175370[D loss: 1.000012] [G loss: 0.999934]\n",
      "epoch:37 step:175375[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:37 step:175380[D loss: 1.000035] [G loss: 0.999995]\n",
      "epoch:37 step:175385[D loss: 0.999962] [G loss: 1.000034]\n",
      "epoch:37 step:175390[D loss: 0.999991] [G loss: 1.000059]\n",
      "epoch:37 step:175395[D loss: 1.000039] [G loss: 1.000020]\n",
      "epoch:37 step:175400[D loss: 0.999977] [G loss: 1.000035]\n",
      "epoch:37 step:175405[D loss: 1.000009] [G loss: 1.000010]\n",
      "epoch:37 step:175410[D loss: 0.999993] [G loss: 1.000040]\n",
      "epoch:37 step:175415[D loss: 0.999976] [G loss: 1.000096]\n",
      "epoch:37 step:175420[D loss: 0.999985] [G loss: 1.000089]\n",
      "epoch:37 step:175425[D loss: 0.999941] [G loss: 1.000116]\n",
      "epoch:37 step:175430[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:37 step:175435[D loss: 0.999967] [G loss: 1.000083]\n",
      "epoch:37 step:175440[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:37 step:175445[D loss: 0.999987] [G loss: 1.000042]\n",
      "epoch:37 step:175450[D loss: 1.000003] [G loss: 1.000061]\n",
      "epoch:37 step:175455[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:37 step:175460[D loss: 0.999982] [G loss: 1.000046]\n",
      "epoch:37 step:175465[D loss: 0.999949] [G loss: 1.000125]\n",
      "epoch:37 step:175470[D loss: 1.000006] [G loss: 0.999986]\n",
      "epoch:37 step:175475[D loss: 0.999977] [G loss: 1.000068]\n",
      "epoch:37 step:175480[D loss: 1.000073] [G loss: 0.999882]\n",
      "epoch:37 step:175485[D loss: 0.999874] [G loss: 1.000147]\n",
      "epoch:37 step:175490[D loss: 0.999996] [G loss: 1.000037]\n",
      "epoch:37 step:175495[D loss: 0.999876] [G loss: 1.000206]\n",
      "epoch:37 step:175500[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:37 step:175505[D loss: 0.999977] [G loss: 1.000067]\n",
      "epoch:37 step:175510[D loss: 0.999977] [G loss: 1.000063]\n",
      "epoch:37 step:175515[D loss: 1.000006] [G loss: 1.000032]\n",
      "epoch:37 step:175520[D loss: 0.999980] [G loss: 1.000075]\n",
      "epoch:37 step:175525[D loss: 1.000094] [G loss: 1.000023]\n",
      "epoch:37 step:175530[D loss: 0.999928] [G loss: 1.000109]\n",
      "epoch:37 step:175535[D loss: 0.999988] [G loss: 1.000083]\n",
      "epoch:37 step:175540[D loss: 1.000045] [G loss: 1.000002]\n",
      "epoch:37 step:175545[D loss: 0.999942] [G loss: 1.000107]\n",
      "epoch:37 step:175550[D loss: 0.999980] [G loss: 1.000046]\n",
      "epoch:37 step:175555[D loss: 1.000019] [G loss: 0.999962]\n",
      "epoch:37 step:175560[D loss: 0.999921] [G loss: 1.000096]\n",
      "epoch:37 step:175565[D loss: 0.999974] [G loss: 1.000079]\n",
      "epoch:37 step:175570[D loss: 0.999962] [G loss: 1.000029]\n",
      "epoch:37 step:175575[D loss: 1.000017] [G loss: 1.000047]\n",
      "epoch:37 step:175580[D loss: 1.000080] [G loss: 1.000001]\n",
      "epoch:37 step:175585[D loss: 1.000054] [G loss: 1.000040]\n",
      "epoch:37 step:175590[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:37 step:175595[D loss: 0.999977] [G loss: 1.000157]\n",
      "epoch:37 step:175600[D loss: 0.999956] [G loss: 1.000092]\n",
      "epoch:37 step:175605[D loss: 0.999947] [G loss: 1.000081]\n",
      "epoch:37 step:175610[D loss: 0.999984] [G loss: 1.000061]\n",
      "epoch:37 step:175615[D loss: 1.000011] [G loss: 1.000025]\n",
      "epoch:37 step:175620[D loss: 1.000090] [G loss: 0.999733]\n",
      "epoch:37 step:175625[D loss: 0.999977] [G loss: 1.000034]\n",
      "epoch:37 step:175630[D loss: 1.000057] [G loss: 1.000019]\n",
      "epoch:37 step:175635[D loss: 1.000036] [G loss: 1.000042]\n",
      "epoch:37 step:175640[D loss: 1.000145] [G loss: 1.000168]\n",
      "epoch:37 step:175645[D loss: 0.999891] [G loss: 1.000237]\n",
      "epoch:37 step:175650[D loss: 0.999986] [G loss: 1.000041]\n",
      "epoch:37 step:175655[D loss: 0.999944] [G loss: 1.000044]\n",
      "epoch:37 step:175660[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:37 step:175665[D loss: 0.999981] [G loss: 1.000088]\n",
      "epoch:37 step:175670[D loss: 1.000008] [G loss: 1.000060]\n",
      "epoch:37 step:175675[D loss: 0.999950] [G loss: 1.000112]\n",
      "epoch:37 step:175680[D loss: 0.999979] [G loss: 1.000073]\n",
      "epoch:37 step:175685[D loss: 1.000028] [G loss: 1.000145]\n",
      "epoch:37 step:175690[D loss: 1.000132] [G loss: 1.000154]\n",
      "epoch:37 step:175695[D loss: 0.999807] [G loss: 1.000371]\n",
      "epoch:37 step:175700[D loss: 0.999935] [G loss: 1.000354]\n",
      "epoch:37 step:175705[D loss: 0.999928] [G loss: 1.000209]\n",
      "epoch:37 step:175710[D loss: 1.000010] [G loss: 1.000009]\n",
      "epoch:37 step:175715[D loss: 1.000222] [G loss: 0.999594]\n",
      "epoch:37 step:175720[D loss: 0.999975] [G loss: 0.999974]\n",
      "epoch:37 step:175725[D loss: 0.999986] [G loss: 1.000014]\n",
      "epoch:37 step:175730[D loss: 1.000026] [G loss: 0.999960]\n",
      "epoch:37 step:175735[D loss: 1.000124] [G loss: 0.999937]\n",
      "epoch:37 step:175740[D loss: 0.999847] [G loss: 1.000050]\n",
      "epoch:37 step:175745[D loss: 0.999991] [G loss: 1.000045]\n",
      "epoch:37 step:175750[D loss: 0.999996] [G loss: 1.000031]\n",
      "epoch:37 step:175755[D loss: 0.999942] [G loss: 1.000087]\n",
      "epoch:37 step:175760[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:37 step:175765[D loss: 0.999980] [G loss: 1.000093]\n",
      "epoch:37 step:175770[D loss: 1.000136] [G loss: 0.999919]\n",
      "epoch:37 step:175775[D loss: 0.999958] [G loss: 1.000072]\n",
      "epoch:37 step:175780[D loss: 1.000040] [G loss: 1.000069]\n",
      "epoch:37 step:175785[D loss: 1.000113] [G loss: 1.000083]\n",
      "epoch:37 step:175790[D loss: 0.999969] [G loss: 1.000124]\n",
      "epoch:37 step:175795[D loss: 0.999990] [G loss: 1.000178]\n",
      "epoch:37 step:175800[D loss: 0.999933] [G loss: 1.000043]\n",
      "epoch:37 step:175805[D loss: 1.000159] [G loss: 1.000010]\n",
      "epoch:37 step:175810[D loss: 1.000002] [G loss: 1.000393]\n",
      "epoch:37 step:175815[D loss: 1.000088] [G loss: 1.000221]\n",
      "epoch:37 step:175820[D loss: 0.999906] [G loss: 1.000111]\n",
      "epoch:37 step:175825[D loss: 1.000043] [G loss: 1.000444]\n",
      "epoch:37 step:175830[D loss: 0.999961] [G loss: 1.000197]\n",
      "epoch:37 step:175835[D loss: 0.999962] [G loss: 1.000069]\n",
      "epoch:37 step:175840[D loss: 1.000121] [G loss: 0.999813]\n",
      "epoch:37 step:175845[D loss: 1.000305] [G loss: 0.999667]\n",
      "epoch:37 step:175850[D loss: 0.999929] [G loss: 0.999834]\n",
      "epoch:37 step:175855[D loss: 1.000114] [G loss: 0.999724]\n",
      "epoch:37 step:175860[D loss: 0.999847] [G loss: 1.000001]\n",
      "epoch:37 step:175865[D loss: 0.999857] [G loss: 1.000086]\n",
      "epoch:37 step:175870[D loss: 1.000004] [G loss: 0.999999]\n",
      "epoch:37 step:175875[D loss: 0.999896] [G loss: 1.000120]\n",
      "epoch:37 step:175880[D loss: 1.000166] [G loss: 1.000005]\n",
      "epoch:37 step:175885[D loss: 1.000053] [G loss: 1.000116]\n",
      "epoch:37 step:175890[D loss: 0.999944] [G loss: 1.000039]\n",
      "epoch:37 step:175895[D loss: 1.000263] [G loss: 1.000076]\n",
      "epoch:37 step:175900[D loss: 0.999903] [G loss: 1.000242]\n",
      "epoch:37 step:175905[D loss: 0.999825] [G loss: 1.000191]\n",
      "epoch:37 step:175910[D loss: 0.999941] [G loss: 1.000079]\n",
      "epoch:37 step:175915[D loss: 1.000100] [G loss: 0.999900]\n",
      "epoch:37 step:175920[D loss: 1.000064] [G loss: 0.999877]\n",
      "epoch:37 step:175925[D loss: 0.999973] [G loss: 0.999949]\n",
      "epoch:37 step:175930[D loss: 1.000378] [G loss: 0.999694]\n",
      "epoch:37 step:175935[D loss: 0.999933] [G loss: 1.000177]\n",
      "epoch:37 step:175940[D loss: 1.000054] [G loss: 1.000045]\n",
      "epoch:37 step:175945[D loss: 0.999847] [G loss: 1.000193]\n",
      "epoch:37 step:175950[D loss: 0.999948] [G loss: 1.000123]\n",
      "epoch:37 step:175955[D loss: 0.999908] [G loss: 1.000070]\n",
      "epoch:37 step:175960[D loss: 0.999937] [G loss: 1.000159]\n",
      "epoch:37 step:175965[D loss: 0.999981] [G loss: 1.000256]\n",
      "epoch:37 step:175970[D loss: 0.999952] [G loss: 1.000150]\n",
      "epoch:37 step:175975[D loss: 0.999990] [G loss: 1.000000]\n",
      "epoch:37 step:175980[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:37 step:175985[D loss: 1.000029] [G loss: 0.999907]\n",
      "epoch:37 step:175990[D loss: 0.999959] [G loss: 1.000101]\n",
      "epoch:37 step:175995[D loss: 0.999883] [G loss: 1.000035]\n",
      "epoch:37 step:176000[D loss: 1.000048] [G loss: 1.000031]\n",
      "epoch:37 step:176005[D loss: 0.999900] [G loss: 1.000099]\n",
      "epoch:37 step:176010[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:37 step:176015[D loss: 1.000030] [G loss: 1.000011]\n",
      "epoch:37 step:176020[D loss: 0.999937] [G loss: 1.000081]\n",
      "epoch:37 step:176025[D loss: 1.000011] [G loss: 1.000149]\n",
      "epoch:37 step:176030[D loss: 1.000173] [G loss: 0.999997]\n",
      "epoch:37 step:176035[D loss: 1.000053] [G loss: 1.000160]\n",
      "epoch:37 step:176040[D loss: 0.999927] [G loss: 1.000313]\n",
      "epoch:37 step:176045[D loss: 0.999833] [G loss: 1.000277]\n",
      "epoch:37 step:176050[D loss: 0.999926] [G loss: 1.000171]\n",
      "epoch:37 step:176055[D loss: 0.999955] [G loss: 1.000088]\n",
      "epoch:37 step:176060[D loss: 1.000217] [G loss: 0.999762]\n",
      "epoch:37 step:176065[D loss: 0.999999] [G loss: 0.999925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:176070[D loss: 1.000162] [G loss: 0.999617]\n",
      "epoch:37 step:176075[D loss: 1.000057] [G loss: 0.999955]\n",
      "epoch:37 step:176080[D loss: 0.999972] [G loss: 0.999980]\n",
      "epoch:37 step:176085[D loss: 0.999883] [G loss: 1.000211]\n",
      "epoch:37 step:176090[D loss: 1.000006] [G loss: 1.000103]\n",
      "epoch:37 step:176095[D loss: 0.999921] [G loss: 1.000338]\n",
      "epoch:37 step:176100[D loss: 0.999861] [G loss: 1.000153]\n",
      "epoch:37 step:176105[D loss: 0.999963] [G loss: 1.000083]\n",
      "epoch:37 step:176110[D loss: 1.000031] [G loss: 1.000040]\n",
      "epoch:37 step:176115[D loss: 0.999918] [G loss: 1.000044]\n",
      "epoch:37 step:176120[D loss: 1.000021] [G loss: 0.999979]\n",
      "epoch:37 step:176125[D loss: 0.999957] [G loss: 1.000090]\n",
      "epoch:37 step:176130[D loss: 0.999925] [G loss: 1.000068]\n",
      "epoch:37 step:176135[D loss: 0.999986] [G loss: 1.000085]\n",
      "epoch:37 step:176140[D loss: 0.999924] [G loss: 1.000108]\n",
      "epoch:37 step:176145[D loss: 0.999975] [G loss: 1.000046]\n",
      "epoch:37 step:176150[D loss: 0.999965] [G loss: 1.000071]\n",
      "epoch:37 step:176155[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:37 step:176160[D loss: 1.000013] [G loss: 1.000005]\n",
      "epoch:37 step:176165[D loss: 0.999974] [G loss: 1.000050]\n",
      "epoch:37 step:176170[D loss: 0.999987] [G loss: 1.000061]\n",
      "epoch:37 step:176175[D loss: 0.999945] [G loss: 1.000071]\n",
      "epoch:37 step:176180[D loss: 0.999981] [G loss: 1.000068]\n",
      "epoch:37 step:176185[D loss: 0.999932] [G loss: 1.000094]\n",
      "epoch:37 step:176190[D loss: 0.999983] [G loss: 1.000079]\n",
      "epoch:37 step:176195[D loss: 0.999995] [G loss: 1.000013]\n",
      "epoch:37 step:176200[D loss: 0.999947] [G loss: 1.000106]\n",
      "epoch:37 step:176205[D loss: 0.999992] [G loss: 1.000129]\n",
      "epoch:37 step:176210[D loss: 1.000001] [G loss: 1.000009]\n",
      "epoch:37 step:176215[D loss: 0.999967] [G loss: 1.000045]\n",
      "epoch:37 step:176220[D loss: 1.000067] [G loss: 0.999998]\n",
      "epoch:37 step:176225[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:37 step:176230[D loss: 0.999951] [G loss: 1.000067]\n",
      "epoch:37 step:176235[D loss: 0.999987] [G loss: 1.000120]\n",
      "epoch:37 step:176240[D loss: 0.999960] [G loss: 1.000075]\n",
      "epoch:37 step:176245[D loss: 1.000175] [G loss: 0.999868]\n",
      "epoch:37 step:176250[D loss: 0.999950] [G loss: 1.000091]\n",
      "epoch:37 step:176255[D loss: 0.999991] [G loss: 1.000033]\n",
      "epoch:37 step:176260[D loss: 0.999971] [G loss: 1.000017]\n",
      "epoch:37 step:176265[D loss: 0.999967] [G loss: 1.000041]\n",
      "epoch:37 step:176270[D loss: 0.999962] [G loss: 1.000089]\n",
      "epoch:37 step:176275[D loss: 0.999984] [G loss: 1.000051]\n",
      "epoch:37 step:176280[D loss: 1.000067] [G loss: 0.999877]\n",
      "epoch:37 step:176285[D loss: 1.000004] [G loss: 1.000086]\n",
      "epoch:37 step:176290[D loss: 0.999972] [G loss: 1.000217]\n",
      "epoch:37 step:176295[D loss: 0.999926] [G loss: 1.000136]\n",
      "epoch:37 step:176300[D loss: 0.999965] [G loss: 1.000088]\n",
      "epoch:37 step:176305[D loss: 1.000066] [G loss: 0.999950]\n",
      "epoch:37 step:176310[D loss: 1.000150] [G loss: 0.999967]\n",
      "epoch:37 step:176315[D loss: 0.999980] [G loss: 1.000016]\n",
      "epoch:37 step:176320[D loss: 1.000374] [G loss: 0.999892]\n",
      "epoch:37 step:176325[D loss: 0.999797] [G loss: 1.000174]\n",
      "epoch:37 step:176330[D loss: 0.999801] [G loss: 1.000274]\n",
      "epoch:37 step:176335[D loss: 0.999944] [G loss: 1.000099]\n",
      "epoch:37 step:176340[D loss: 0.999847] [G loss: 1.000258]\n",
      "epoch:37 step:176345[D loss: 0.999935] [G loss: 1.000196]\n",
      "epoch:37 step:176350[D loss: 0.999954] [G loss: 1.000027]\n",
      "epoch:37 step:176355[D loss: 1.000018] [G loss: 0.999862]\n",
      "epoch:37 step:176360[D loss: 0.999972] [G loss: 1.000013]\n",
      "epoch:37 step:176365[D loss: 1.000023] [G loss: 0.999824]\n",
      "epoch:37 step:176370[D loss: 0.999907] [G loss: 1.000073]\n",
      "epoch:37 step:176375[D loss: 0.999973] [G loss: 0.999952]\n",
      "epoch:37 step:176380[D loss: 1.000003] [G loss: 1.000033]\n",
      "epoch:37 step:176385[D loss: 1.000022] [G loss: 0.999983]\n",
      "epoch:37 step:176390[D loss: 1.000046] [G loss: 1.000089]\n",
      "epoch:37 step:176395[D loss: 0.999920] [G loss: 1.000119]\n",
      "epoch:37 step:176400[D loss: 1.000020] [G loss: 1.000098]\n",
      "epoch:37 step:176405[D loss: 1.000035] [G loss: 0.999985]\n",
      "epoch:37 step:176410[D loss: 0.999944] [G loss: 1.000019]\n",
      "epoch:37 step:176415[D loss: 0.999988] [G loss: 0.999979]\n",
      "epoch:37 step:176420[D loss: 1.000026] [G loss: 0.999949]\n",
      "epoch:37 step:176425[D loss: 0.999964] [G loss: 1.000012]\n",
      "epoch:37 step:176430[D loss: 1.000100] [G loss: 0.999948]\n",
      "epoch:37 step:176435[D loss: 1.000052] [G loss: 0.999928]\n",
      "epoch:37 step:176440[D loss: 0.999931] [G loss: 1.000050]\n",
      "epoch:37 step:176445[D loss: 1.000040] [G loss: 1.000027]\n",
      "epoch:37 step:176450[D loss: 0.999946] [G loss: 1.000080]\n",
      "epoch:37 step:176455[D loss: 1.000001] [G loss: 1.000183]\n",
      "epoch:37 step:176460[D loss: 0.999940] [G loss: 1.000101]\n",
      "epoch:37 step:176465[D loss: 0.999981] [G loss: 1.000075]\n",
      "epoch:37 step:176470[D loss: 0.999960] [G loss: 1.000130]\n",
      "epoch:37 step:176475[D loss: 0.999944] [G loss: 1.000079]\n",
      "epoch:37 step:176480[D loss: 1.000033] [G loss: 1.000063]\n",
      "epoch:37 step:176485[D loss: 0.999925] [G loss: 1.000117]\n",
      "epoch:37 step:176490[D loss: 0.999931] [G loss: 1.000151]\n",
      "epoch:37 step:176495[D loss: 0.999934] [G loss: 1.000138]\n",
      "epoch:37 step:176500[D loss: 0.999968] [G loss: 1.000109]\n",
      "epoch:37 step:176505[D loss: 1.000057] [G loss: 1.000063]\n",
      "epoch:37 step:176510[D loss: 0.999878] [G loss: 1.000234]\n",
      "epoch:37 step:176515[D loss: 0.999977] [G loss: 1.000033]\n",
      "epoch:37 step:176520[D loss: 1.000041] [G loss: 0.999930]\n",
      "epoch:37 step:176525[D loss: 1.000021] [G loss: 0.999894]\n",
      "epoch:37 step:176530[D loss: 1.000194] [G loss: 0.999852]\n",
      "epoch:37 step:176535[D loss: 0.999888] [G loss: 0.999978]\n",
      "epoch:37 step:176540[D loss: 0.999878] [G loss: 1.000105]\n",
      "epoch:37 step:176545[D loss: 1.000124] [G loss: 0.999924]\n",
      "epoch:37 step:176550[D loss: 1.000112] [G loss: 1.000000]\n",
      "epoch:37 step:176555[D loss: 0.999898] [G loss: 1.000182]\n",
      "epoch:37 step:176560[D loss: 0.999929] [G loss: 1.000082]\n",
      "epoch:37 step:176565[D loss: 0.999993] [G loss: 1.000019]\n",
      "epoch:37 step:176570[D loss: 0.999984] [G loss: 0.999958]\n",
      "epoch:37 step:176575[D loss: 1.000086] [G loss: 0.999906]\n",
      "epoch:37 step:176580[D loss: 0.999974] [G loss: 0.999926]\n",
      "epoch:37 step:176585[D loss: 1.000007] [G loss: 0.999989]\n",
      "epoch:37 step:176590[D loss: 1.000050] [G loss: 1.000050]\n",
      "epoch:37 step:176595[D loss: 0.999915] [G loss: 1.000142]\n",
      "epoch:37 step:176600[D loss: 1.000210] [G loss: 0.999974]\n",
      "epoch:37 step:176605[D loss: 0.999987] [G loss: 0.999997]\n",
      "epoch:37 step:176610[D loss: 0.999926] [G loss: 1.000236]\n",
      "epoch:37 step:176615[D loss: 0.999931] [G loss: 1.000120]\n",
      "epoch:37 step:176620[D loss: 0.999955] [G loss: 1.000083]\n",
      "epoch:37 step:176625[D loss: 1.000070] [G loss: 0.999923]\n",
      "epoch:37 step:176630[D loss: 1.000067] [G loss: 0.999846]\n",
      "epoch:37 step:176635[D loss: 0.999930] [G loss: 0.999915]\n",
      "epoch:37 step:176640[D loss: 0.999935] [G loss: 1.000010]\n",
      "epoch:37 step:176645[D loss: 1.000045] [G loss: 0.999986]\n",
      "epoch:37 step:176650[D loss: 0.999947] [G loss: 1.000054]\n",
      "epoch:37 step:176655[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:37 step:176660[D loss: 1.000059] [G loss: 1.000078]\n",
      "epoch:37 step:176665[D loss: 0.999894] [G loss: 1.000111]\n",
      "epoch:37 step:176670[D loss: 0.999996] [G loss: 1.000059]\n",
      "epoch:37 step:176675[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:37 step:176680[D loss: 0.999996] [G loss: 1.000087]\n",
      "epoch:37 step:176685[D loss: 0.999952] [G loss: 1.000092]\n",
      "epoch:37 step:176690[D loss: 0.999968] [G loss: 1.000075]\n",
      "epoch:37 step:176695[D loss: 0.999981] [G loss: 1.000061]\n",
      "epoch:37 step:176700[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:37 step:176705[D loss: 0.999992] [G loss: 1.000028]\n",
      "epoch:37 step:176710[D loss: 0.999960] [G loss: 1.000055]\n",
      "epoch:37 step:176715[D loss: 0.999958] [G loss: 1.000049]\n",
      "epoch:37 step:176720[D loss: 0.999979] [G loss: 1.000048]\n",
      "epoch:37 step:176725[D loss: 0.999977] [G loss: 1.000037]\n",
      "epoch:37 step:176730[D loss: 0.999983] [G loss: 1.000071]\n",
      "epoch:37 step:176735[D loss: 0.999964] [G loss: 1.000090]\n",
      "epoch:37 step:176740[D loss: 0.999939] [G loss: 1.000087]\n",
      "epoch:37 step:176745[D loss: 0.999979] [G loss: 1.000054]\n",
      "epoch:37 step:176750[D loss: 0.999976] [G loss: 1.000036]\n",
      "epoch:37 step:176755[D loss: 0.999990] [G loss: 1.000082]\n",
      "epoch:37 step:176760[D loss: 1.000001] [G loss: 1.000016]\n",
      "epoch:37 step:176765[D loss: 0.999957] [G loss: 1.000083]\n",
      "epoch:37 step:176770[D loss: 1.000033] [G loss: 0.999921]\n",
      "epoch:37 step:176775[D loss: 0.999990] [G loss: 1.000018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:176780[D loss: 0.999995] [G loss: 1.000074]\n",
      "epoch:37 step:176785[D loss: 0.999985] [G loss: 1.000054]\n",
      "epoch:37 step:176790[D loss: 1.000079] [G loss: 0.999965]\n",
      "epoch:37 step:176795[D loss: 0.999978] [G loss: 1.000027]\n",
      "epoch:37 step:176800[D loss: 0.999949] [G loss: 1.000034]\n",
      "epoch:37 step:176805[D loss: 0.999989] [G loss: 1.000057]\n",
      "epoch:37 step:176810[D loss: 1.000083] [G loss: 1.000070]\n",
      "epoch:37 step:176815[D loss: 0.999916] [G loss: 1.000149]\n",
      "epoch:37 step:176820[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:37 step:176825[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:37 step:176830[D loss: 1.000031] [G loss: 0.999944]\n",
      "epoch:37 step:176835[D loss: 0.999930] [G loss: 1.000090]\n",
      "epoch:37 step:176840[D loss: 1.000139] [G loss: 0.999905]\n",
      "epoch:37 step:176845[D loss: 0.999962] [G loss: 1.000052]\n",
      "epoch:37 step:176850[D loss: 1.000009] [G loss: 1.000053]\n",
      "epoch:37 step:176855[D loss: 0.999936] [G loss: 1.000107]\n",
      "epoch:37 step:176860[D loss: 0.999997] [G loss: 1.000062]\n",
      "epoch:37 step:176865[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:37 step:176870[D loss: 0.999963] [G loss: 1.000080]\n",
      "epoch:37 step:176875[D loss: 1.000007] [G loss: 0.999974]\n",
      "epoch:37 step:176880[D loss: 0.999983] [G loss: 1.000038]\n",
      "epoch:37 step:176885[D loss: 0.999968] [G loss: 1.000055]\n",
      "epoch:37 step:176890[D loss: 0.999997] [G loss: 1.000092]\n",
      "epoch:37 step:176895[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:37 step:176900[D loss: 1.000070] [G loss: 0.999939]\n",
      "epoch:37 step:176905[D loss: 1.000062] [G loss: 0.999892]\n",
      "epoch:37 step:176910[D loss: 1.000047] [G loss: 0.999944]\n",
      "epoch:37 step:176915[D loss: 1.000090] [G loss: 1.000091]\n",
      "epoch:37 step:176920[D loss: 0.999985] [G loss: 1.000040]\n",
      "epoch:37 step:176925[D loss: 1.000045] [G loss: 0.999964]\n",
      "epoch:37 step:176930[D loss: 1.000030] [G loss: 0.999892]\n",
      "epoch:37 step:176935[D loss: 1.000001] [G loss: 0.999945]\n",
      "epoch:37 step:176940[D loss: 1.000057] [G loss: 0.999947]\n",
      "epoch:37 step:176945[D loss: 0.999890] [G loss: 1.000136]\n",
      "epoch:37 step:176950[D loss: 0.999960] [G loss: 1.000119]\n",
      "epoch:37 step:176955[D loss: 0.999957] [G loss: 1.000146]\n",
      "epoch:37 step:176960[D loss: 0.999971] [G loss: 1.000121]\n",
      "epoch:37 step:176965[D loss: 0.999946] [G loss: 1.000113]\n",
      "epoch:37 step:176970[D loss: 0.999985] [G loss: 1.000061]\n",
      "epoch:37 step:176975[D loss: 1.000016] [G loss: 1.000012]\n",
      "epoch:37 step:176980[D loss: 0.999932] [G loss: 1.000053]\n",
      "epoch:37 step:176985[D loss: 1.000079] [G loss: 1.000018]\n",
      "epoch:37 step:176990[D loss: 0.999935] [G loss: 1.000088]\n",
      "epoch:37 step:176995[D loss: 0.999974] [G loss: 1.000052]\n",
      "epoch:37 step:177000[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:37 step:177005[D loss: 0.999988] [G loss: 1.000051]\n",
      "epoch:37 step:177010[D loss: 0.999949] [G loss: 1.000031]\n",
      "epoch:37 step:177015[D loss: 1.000020] [G loss: 0.999999]\n",
      "epoch:37 step:177020[D loss: 1.000018] [G loss: 1.000015]\n",
      "epoch:37 step:177025[D loss: 0.999943] [G loss: 1.000054]\n",
      "epoch:37 step:177030[D loss: 1.000114] [G loss: 1.000031]\n",
      "epoch:37 step:177035[D loss: 0.999880] [G loss: 1.000176]\n",
      "epoch:37 step:177040[D loss: 0.999984] [G loss: 1.000232]\n",
      "epoch:37 step:177045[D loss: 0.999943] [G loss: 1.000095]\n",
      "epoch:37 step:177050[D loss: 1.000006] [G loss: 1.000023]\n",
      "epoch:37 step:177055[D loss: 1.000025] [G loss: 1.000136]\n",
      "epoch:37 step:177060[D loss: 0.999843] [G loss: 1.000061]\n",
      "epoch:37 step:177065[D loss: 1.000042] [G loss: 0.999930]\n",
      "epoch:37 step:177070[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:37 step:177075[D loss: 0.999881] [G loss: 1.000096]\n",
      "epoch:37 step:177080[D loss: 0.999963] [G loss: 1.000065]\n",
      "epoch:37 step:177085[D loss: 0.999982] [G loss: 1.000059]\n",
      "epoch:37 step:177090[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:37 step:177095[D loss: 1.000020] [G loss: 0.999995]\n",
      "epoch:37 step:177100[D loss: 1.000007] [G loss: 1.000004]\n",
      "epoch:37 step:177105[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:37 step:177110[D loss: 0.999983] [G loss: 1.000077]\n",
      "epoch:37 step:177115[D loss: 1.000037] [G loss: 1.000086]\n",
      "epoch:37 step:177120[D loss: 0.999994] [G loss: 1.000052]\n",
      "epoch:37 step:177125[D loss: 0.999949] [G loss: 1.000085]\n",
      "epoch:37 step:177130[D loss: 1.000024] [G loss: 1.000007]\n",
      "epoch:37 step:177135[D loss: 1.000002] [G loss: 1.000082]\n",
      "epoch:37 step:177140[D loss: 0.999934] [G loss: 1.000084]\n",
      "epoch:37 step:177145[D loss: 0.999919] [G loss: 1.000136]\n",
      "epoch:37 step:177150[D loss: 0.999949] [G loss: 1.000172]\n",
      "epoch:37 step:177155[D loss: 1.000012] [G loss: 1.000143]\n",
      "epoch:37 step:177160[D loss: 0.999970] [G loss: 1.000042]\n",
      "epoch:37 step:177165[D loss: 0.999983] [G loss: 1.000101]\n",
      "epoch:37 step:177170[D loss: 0.999990] [G loss: 1.000033]\n",
      "epoch:37 step:177175[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:37 step:177180[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:37 step:177185[D loss: 1.000052] [G loss: 0.999935]\n",
      "epoch:37 step:177190[D loss: 0.999902] [G loss: 1.000059]\n",
      "epoch:37 step:177195[D loss: 0.999957] [G loss: 1.000115]\n",
      "epoch:37 step:177200[D loss: 1.000037] [G loss: 1.000043]\n",
      "epoch:37 step:177205[D loss: 1.000076] [G loss: 0.999933]\n",
      "epoch:37 step:177210[D loss: 1.000040] [G loss: 0.999883]\n",
      "epoch:37 step:177215[D loss: 1.000107] [G loss: 0.999964]\n",
      "epoch:37 step:177220[D loss: 0.999835] [G loss: 1.000169]\n",
      "epoch:37 step:177225[D loss: 0.999985] [G loss: 1.000074]\n",
      "epoch:37 step:177230[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:37 step:177235[D loss: 1.000035] [G loss: 0.999999]\n",
      "epoch:37 step:177240[D loss: 1.000062] [G loss: 1.000112]\n",
      "epoch:37 step:177245[D loss: 0.999995] [G loss: 1.000009]\n",
      "epoch:37 step:177250[D loss: 0.999941] [G loss: 1.000044]\n",
      "epoch:37 step:177255[D loss: 0.999940] [G loss: 1.000137]\n",
      "epoch:37 step:177260[D loss: 0.999950] [G loss: 1.000156]\n",
      "epoch:37 step:177265[D loss: 0.999980] [G loss: 1.000094]\n",
      "epoch:37 step:177270[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:37 step:177275[D loss: 0.999977] [G loss: 1.000086]\n",
      "epoch:37 step:177280[D loss: 0.999984] [G loss: 1.000010]\n",
      "epoch:37 step:177285[D loss: 0.999989] [G loss: 1.000017]\n",
      "epoch:37 step:177290[D loss: 0.999955] [G loss: 1.000092]\n",
      "epoch:37 step:177295[D loss: 1.000052] [G loss: 1.000013]\n",
      "epoch:37 step:177300[D loss: 0.999955] [G loss: 1.000113]\n",
      "epoch:37 step:177305[D loss: 0.999947] [G loss: 1.000045]\n",
      "epoch:37 step:177310[D loss: 0.999887] [G loss: 1.000168]\n",
      "epoch:37 step:177315[D loss: 0.999913] [G loss: 1.000177]\n",
      "epoch:37 step:177320[D loss: 1.000018] [G loss: 1.000216]\n",
      "epoch:37 step:177325[D loss: 0.999966] [G loss: 1.000133]\n",
      "epoch:37 step:177330[D loss: 1.000004] [G loss: 1.000054]\n",
      "epoch:37 step:177335[D loss: 1.000035] [G loss: 1.000009]\n",
      "epoch:37 step:177340[D loss: 0.999990] [G loss: 1.000036]\n",
      "epoch:37 step:177345[D loss: 1.000028] [G loss: 1.000044]\n",
      "epoch:37 step:177350[D loss: 1.000059] [G loss: 0.999949]\n",
      "epoch:37 step:177355[D loss: 1.000022] [G loss: 0.999984]\n",
      "epoch:37 step:177360[D loss: 0.999919] [G loss: 1.000136]\n",
      "epoch:37 step:177365[D loss: 1.000039] [G loss: 1.000042]\n",
      "epoch:37 step:177370[D loss: 0.999960] [G loss: 1.000166]\n",
      "epoch:37 step:177375[D loss: 0.999962] [G loss: 1.000140]\n",
      "epoch:37 step:177380[D loss: 0.999853] [G loss: 1.000281]\n",
      "epoch:37 step:177385[D loss: 1.000094] [G loss: 1.000161]\n",
      "epoch:37 step:177390[D loss: 0.999888] [G loss: 1.000150]\n",
      "epoch:37 step:177395[D loss: 0.999939] [G loss: 1.000123]\n",
      "epoch:37 step:177400[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:37 step:177405[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:37 step:177410[D loss: 0.999997] [G loss: 1.000022]\n",
      "epoch:37 step:177415[D loss: 1.000042] [G loss: 1.000031]\n",
      "epoch:37 step:177420[D loss: 0.999905] [G loss: 1.000052]\n",
      "epoch:37 step:177425[D loss: 1.000009] [G loss: 1.000071]\n",
      "epoch:37 step:177430[D loss: 0.999945] [G loss: 1.000093]\n",
      "epoch:37 step:177435[D loss: 0.999967] [G loss: 1.000129]\n",
      "epoch:37 step:177440[D loss: 0.999970] [G loss: 1.000015]\n",
      "epoch:37 step:177445[D loss: 0.999995] [G loss: 1.000101]\n",
      "epoch:37 step:177450[D loss: 0.999954] [G loss: 1.000053]\n",
      "epoch:37 step:177455[D loss: 1.000004] [G loss: 1.000037]\n",
      "epoch:37 step:177460[D loss: 1.000021] [G loss: 0.999888]\n",
      "epoch:37 step:177465[D loss: 0.999934] [G loss: 1.000086]\n",
      "epoch:37 step:177470[D loss: 0.999965] [G loss: 1.000082]\n",
      "epoch:37 step:177475[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:37 step:177480[D loss: 0.999976] [G loss: 1.000070]\n",
      "epoch:37 step:177485[D loss: 1.000002] [G loss: 1.000017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:177490[D loss: 1.000000] [G loss: 1.000035]\n",
      "epoch:37 step:177495[D loss: 0.999969] [G loss: 1.000097]\n",
      "epoch:37 step:177500[D loss: 1.000046] [G loss: 0.999935]\n",
      "epoch:37 step:177505[D loss: 1.000049] [G loss: 0.999996]\n",
      "epoch:37 step:177510[D loss: 0.999913] [G loss: 1.000054]\n",
      "epoch:37 step:177515[D loss: 1.000026] [G loss: 1.000228]\n",
      "epoch:37 step:177520[D loss: 0.999940] [G loss: 1.000136]\n",
      "epoch:37 step:177525[D loss: 0.999997] [G loss: 1.000061]\n",
      "epoch:37 step:177530[D loss: 1.000007] [G loss: 0.999969]\n",
      "epoch:37 step:177535[D loss: 1.000078] [G loss: 0.999847]\n",
      "epoch:37 step:177540[D loss: 0.999965] [G loss: 1.000051]\n",
      "epoch:37 step:177545[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:37 step:177550[D loss: 1.000002] [G loss: 1.000074]\n",
      "epoch:37 step:177555[D loss: 0.999956] [G loss: 1.000067]\n",
      "epoch:37 step:177560[D loss: 0.999928] [G loss: 1.000144]\n",
      "epoch:37 step:177565[D loss: 0.999985] [G loss: 1.000117]\n",
      "epoch:37 step:177570[D loss: 0.999890] [G loss: 1.000159]\n",
      "epoch:37 step:177575[D loss: 0.999945] [G loss: 1.000054]\n",
      "epoch:37 step:177580[D loss: 0.999967] [G loss: 1.000073]\n",
      "epoch:37 step:177585[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:37 step:177590[D loss: 0.999967] [G loss: 1.000103]\n",
      "epoch:37 step:177595[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:37 step:177600[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:37 step:177605[D loss: 0.999987] [G loss: 1.000009]\n",
      "epoch:37 step:177610[D loss: 0.999997] [G loss: 1.000003]\n",
      "epoch:37 step:177615[D loss: 0.999991] [G loss: 0.999997]\n",
      "epoch:37 step:177620[D loss: 0.999984] [G loss: 1.000086]\n",
      "epoch:37 step:177625[D loss: 1.000091] [G loss: 1.000054]\n",
      "epoch:37 step:177630[D loss: 0.999918] [G loss: 1.000189]\n",
      "epoch:37 step:177635[D loss: 0.999940] [G loss: 1.000102]\n",
      "epoch:37 step:177640[D loss: 0.999947] [G loss: 1.000146]\n",
      "epoch:37 step:177645[D loss: 1.000030] [G loss: 1.000037]\n",
      "epoch:37 step:177650[D loss: 1.000046] [G loss: 0.999946]\n",
      "epoch:37 step:177655[D loss: 0.999972] [G loss: 1.000082]\n",
      "epoch:37 step:177660[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:37 step:177665[D loss: 0.999943] [G loss: 1.000066]\n",
      "epoch:37 step:177670[D loss: 0.999986] [G loss: 1.000092]\n",
      "epoch:37 step:177675[D loss: 0.999967] [G loss: 1.000089]\n",
      "epoch:37 step:177680[D loss: 0.999974] [G loss: 1.000107]\n",
      "epoch:37 step:177685[D loss: 0.999988] [G loss: 1.000085]\n",
      "epoch:37 step:177690[D loss: 1.000000] [G loss: 1.000000]\n",
      "epoch:37 step:177695[D loss: 1.000007] [G loss: 1.000074]\n",
      "epoch:37 step:177700[D loss: 0.999959] [G loss: 1.000075]\n",
      "epoch:37 step:177705[D loss: 1.000004] [G loss: 1.000049]\n",
      "epoch:37 step:177710[D loss: 0.999983] [G loss: 1.000048]\n",
      "epoch:37 step:177715[D loss: 0.999979] [G loss: 1.000039]\n",
      "epoch:37 step:177720[D loss: 0.999978] [G loss: 1.000078]\n",
      "epoch:37 step:177725[D loss: 1.000048] [G loss: 1.000032]\n",
      "epoch:37 step:177730[D loss: 0.999962] [G loss: 1.000015]\n",
      "epoch:37 step:177735[D loss: 0.999972] [G loss: 1.000079]\n",
      "epoch:37 step:177740[D loss: 0.999979] [G loss: 1.000071]\n",
      "epoch:37 step:177745[D loss: 0.999988] [G loss: 1.000077]\n",
      "epoch:37 step:177750[D loss: 0.999953] [G loss: 1.000055]\n",
      "epoch:37 step:177755[D loss: 0.999924] [G loss: 1.000137]\n",
      "epoch:37 step:177760[D loss: 0.999959] [G loss: 1.000067]\n",
      "epoch:37 step:177765[D loss: 0.999959] [G loss: 1.000082]\n",
      "epoch:37 step:177770[D loss: 1.000048] [G loss: 1.000073]\n",
      "epoch:37 step:177775[D loss: 0.999979] [G loss: 1.000101]\n",
      "epoch:37 step:177780[D loss: 0.999941] [G loss: 1.000142]\n",
      "epoch:37 step:177785[D loss: 0.999962] [G loss: 1.000024]\n",
      "epoch:37 step:177790[D loss: 0.999975] [G loss: 1.000082]\n",
      "epoch:37 step:177795[D loss: 0.999995] [G loss: 1.000032]\n",
      "epoch:37 step:177800[D loss: 0.999981] [G loss: 1.000034]\n",
      "epoch:37 step:177805[D loss: 0.999926] [G loss: 1.000086]\n",
      "epoch:37 step:177810[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:37 step:177815[D loss: 0.999964] [G loss: 1.000046]\n",
      "epoch:37 step:177820[D loss: 0.999973] [G loss: 1.000089]\n",
      "epoch:37 step:177825[D loss: 1.000044] [G loss: 0.999996]\n",
      "epoch:37 step:177830[D loss: 0.999968] [G loss: 1.000077]\n",
      "epoch:37 step:177835[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:37 step:177840[D loss: 0.999975] [G loss: 1.000069]\n",
      "epoch:37 step:177845[D loss: 0.999980] [G loss: 1.000083]\n",
      "epoch:37 step:177850[D loss: 1.000067] [G loss: 1.000049]\n",
      "epoch:37 step:177855[D loss: 0.999991] [G loss: 1.000013]\n",
      "epoch:37 step:177860[D loss: 0.999975] [G loss: 1.000043]\n",
      "epoch:37 step:177865[D loss: 0.999955] [G loss: 1.000080]\n",
      "epoch:37 step:177870[D loss: 0.999993] [G loss: 1.000031]\n",
      "epoch:37 step:177875[D loss: 1.000089] [G loss: 0.999876]\n",
      "epoch:37 step:177880[D loss: 0.999958] [G loss: 1.000049]\n",
      "epoch:37 step:177885[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:37 step:177890[D loss: 0.999962] [G loss: 1.000076]\n",
      "epoch:37 step:177895[D loss: 0.999964] [G loss: 1.000094]\n",
      "epoch:37 step:177900[D loss: 0.999988] [G loss: 1.000062]\n",
      "epoch:37 step:177905[D loss: 1.000003] [G loss: 1.000032]\n",
      "epoch:37 step:177910[D loss: 0.999889] [G loss: 1.000166]\n",
      "epoch:37 step:177915[D loss: 0.999959] [G loss: 1.000084]\n",
      "epoch:37 step:177920[D loss: 0.999970] [G loss: 1.000056]\n",
      "epoch:37 step:177925[D loss: 1.000012] [G loss: 1.000013]\n",
      "epoch:37 step:177930[D loss: 1.000063] [G loss: 1.000111]\n",
      "epoch:37 step:177935[D loss: 0.999967] [G loss: 1.000021]\n",
      "epoch:37 step:177940[D loss: 0.999999] [G loss: 1.000042]\n",
      "epoch:37 step:177945[D loss: 1.000003] [G loss: 1.000005]\n",
      "epoch:37 step:177950[D loss: 1.000021] [G loss: 0.999957]\n",
      "epoch:37 step:177955[D loss: 0.999962] [G loss: 1.000093]\n",
      "epoch:37 step:177960[D loss: 1.000027] [G loss: 0.999934]\n",
      "epoch:37 step:177965[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:37 step:177970[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:37 step:177975[D loss: 0.999966] [G loss: 1.000075]\n",
      "epoch:37 step:177980[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:37 step:177985[D loss: 0.999988] [G loss: 1.000041]\n",
      "epoch:37 step:177990[D loss: 0.999954] [G loss: 1.000121]\n",
      "epoch:37 step:177995[D loss: 0.999982] [G loss: 1.000065]\n",
      "epoch:37 step:178000[D loss: 0.999979] [G loss: 1.000062]\n",
      "epoch:37 step:178005[D loss: 0.999959] [G loss: 1.000081]\n",
      "epoch:37 step:178010[D loss: 0.999971] [G loss: 1.000084]\n",
      "epoch:37 step:178015[D loss: 0.999984] [G loss: 1.000069]\n",
      "epoch:37 step:178020[D loss: 0.999988] [G loss: 1.000080]\n",
      "epoch:37 step:178025[D loss: 1.000008] [G loss: 0.999995]\n",
      "epoch:37 step:178030[D loss: 0.999992] [G loss: 1.000070]\n",
      "epoch:38 step:178035[D loss: 0.999987] [G loss: 1.000069]\n",
      "epoch:38 step:178040[D loss: 0.999939] [G loss: 1.000131]\n",
      "epoch:38 step:178045[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:38 step:178050[D loss: 0.999988] [G loss: 1.000046]\n",
      "epoch:38 step:178055[D loss: 0.999943] [G loss: 1.000086]\n",
      "epoch:38 step:178060[D loss: 0.999978] [G loss: 1.000057]\n",
      "epoch:38 step:178065[D loss: 0.999970] [G loss: 1.000064]\n",
      "epoch:38 step:178070[D loss: 0.999963] [G loss: 1.000074]\n",
      "epoch:38 step:178075[D loss: 1.000051] [G loss: 0.999902]\n",
      "epoch:38 step:178080[D loss: 1.000058] [G loss: 1.000018]\n",
      "epoch:38 step:178085[D loss: 1.000035] [G loss: 1.000018]\n",
      "epoch:38 step:178090[D loss: 0.999917] [G loss: 1.000049]\n",
      "epoch:38 step:178095[D loss: 0.999925] [G loss: 1.000084]\n",
      "epoch:38 step:178100[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:38 step:178105[D loss: 0.999984] [G loss: 1.000080]\n",
      "epoch:38 step:178110[D loss: 0.999974] [G loss: 1.000068]\n",
      "epoch:38 step:178115[D loss: 0.999966] [G loss: 1.000080]\n",
      "epoch:38 step:178120[D loss: 1.000045] [G loss: 0.999993]\n",
      "epoch:38 step:178125[D loss: 1.000001] [G loss: 1.000005]\n",
      "epoch:38 step:178130[D loss: 0.999895] [G loss: 1.000148]\n",
      "epoch:38 step:178135[D loss: 0.999997] [G loss: 1.000142]\n",
      "epoch:38 step:178140[D loss: 0.999974] [G loss: 1.000142]\n",
      "epoch:38 step:178145[D loss: 0.999997] [G loss: 1.000019]\n",
      "epoch:38 step:178150[D loss: 0.999982] [G loss: 1.000038]\n",
      "epoch:38 step:178155[D loss: 0.999986] [G loss: 1.000024]\n",
      "epoch:38 step:178160[D loss: 0.999969] [G loss: 1.000083]\n",
      "epoch:38 step:178165[D loss: 1.000066] [G loss: 0.999970]\n",
      "epoch:38 step:178170[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:38 step:178175[D loss: 0.999983] [G loss: 1.000063]\n",
      "epoch:38 step:178180[D loss: 1.000010] [G loss: 1.000053]\n",
      "epoch:38 step:178185[D loss: 0.999985] [G loss: 1.000076]\n",
      "epoch:38 step:178190[D loss: 1.000014] [G loss: 1.000050]\n",
      "epoch:38 step:178195[D loss: 1.000029] [G loss: 1.000047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:178200[D loss: 1.000004] [G loss: 1.000155]\n",
      "epoch:38 step:178205[D loss: 0.999893] [G loss: 1.000190]\n",
      "epoch:38 step:178210[D loss: 1.000007] [G loss: 1.000154]\n",
      "epoch:38 step:178215[D loss: 0.999973] [G loss: 1.000147]\n",
      "epoch:38 step:178220[D loss: 0.999984] [G loss: 1.000083]\n",
      "epoch:38 step:178225[D loss: 1.000079] [G loss: 0.999932]\n",
      "epoch:38 step:178230[D loss: 1.000065] [G loss: 1.000074]\n",
      "epoch:38 step:178235[D loss: 1.000053] [G loss: 0.999964]\n",
      "epoch:38 step:178240[D loss: 0.999946] [G loss: 1.000037]\n",
      "epoch:38 step:178245[D loss: 0.999952] [G loss: 1.000076]\n",
      "epoch:38 step:178250[D loss: 0.999979] [G loss: 1.000074]\n",
      "epoch:38 step:178255[D loss: 0.999959] [G loss: 1.000093]\n",
      "epoch:38 step:178260[D loss: 0.999994] [G loss: 1.000083]\n",
      "epoch:38 step:178265[D loss: 0.999948] [G loss: 1.000093]\n",
      "epoch:38 step:178270[D loss: 0.999966] [G loss: 1.000119]\n",
      "epoch:38 step:178275[D loss: 0.999987] [G loss: 1.000025]\n",
      "epoch:38 step:178280[D loss: 0.999961] [G loss: 1.000095]\n",
      "epoch:38 step:178285[D loss: 0.999952] [G loss: 1.000114]\n",
      "epoch:38 step:178290[D loss: 1.000032] [G loss: 1.000048]\n",
      "epoch:38 step:178295[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:38 step:178300[D loss: 0.999991] [G loss: 1.000066]\n",
      "epoch:38 step:178305[D loss: 0.999998] [G loss: 0.999984]\n",
      "epoch:38 step:178310[D loss: 0.999985] [G loss: 1.000056]\n",
      "epoch:38 step:178315[D loss: 0.999950] [G loss: 1.000118]\n",
      "epoch:38 step:178320[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:38 step:178325[D loss: 0.999973] [G loss: 1.000097]\n",
      "epoch:38 step:178330[D loss: 1.000022] [G loss: 1.000031]\n",
      "epoch:38 step:178335[D loss: 0.999945] [G loss: 1.000084]\n",
      "epoch:38 step:178340[D loss: 0.999972] [G loss: 1.000092]\n",
      "epoch:38 step:178345[D loss: 1.000021] [G loss: 1.000076]\n",
      "epoch:38 step:178350[D loss: 1.000035] [G loss: 1.000042]\n",
      "epoch:38 step:178355[D loss: 0.999991] [G loss: 1.000043]\n",
      "epoch:38 step:178360[D loss: 1.000016] [G loss: 0.999992]\n",
      "epoch:38 step:178365[D loss: 1.000047] [G loss: 1.000030]\n",
      "epoch:38 step:178370[D loss: 0.999912] [G loss: 1.000193]\n",
      "epoch:38 step:178375[D loss: 1.000104] [G loss: 1.000069]\n",
      "epoch:38 step:178380[D loss: 0.999871] [G loss: 1.000164]\n",
      "epoch:38 step:178385[D loss: 1.000067] [G loss: 0.999992]\n",
      "epoch:38 step:178390[D loss: 0.999907] [G loss: 1.000241]\n",
      "epoch:38 step:178395[D loss: 1.000006] [G loss: 0.999992]\n",
      "epoch:38 step:178400[D loss: 1.000049] [G loss: 0.999940]\n",
      "epoch:38 step:178405[D loss: 1.000092] [G loss: 0.999876]\n",
      "epoch:38 step:178410[D loss: 1.000081] [G loss: 0.999841]\n",
      "epoch:38 step:178415[D loss: 1.000053] [G loss: 0.999929]\n",
      "epoch:38 step:178420[D loss: 0.999941] [G loss: 1.000031]\n",
      "epoch:38 step:178425[D loss: 0.999933] [G loss: 1.000152]\n",
      "epoch:38 step:178430[D loss: 0.999939] [G loss: 1.000082]\n",
      "epoch:38 step:178435[D loss: 1.000063] [G loss: 1.000153]\n",
      "epoch:38 step:178440[D loss: 0.999936] [G loss: 1.000065]\n",
      "epoch:38 step:178445[D loss: 1.000050] [G loss: 1.000107]\n",
      "epoch:38 step:178450[D loss: 0.999922] [G loss: 1.000070]\n",
      "epoch:38 step:178455[D loss: 1.000024] [G loss: 0.999940]\n",
      "epoch:38 step:178460[D loss: 1.000127] [G loss: 0.999884]\n",
      "epoch:38 step:178465[D loss: 1.000017] [G loss: 0.999959]\n",
      "epoch:38 step:178470[D loss: 1.000205] [G loss: 0.999688]\n",
      "epoch:38 step:178475[D loss: 1.000045] [G loss: 1.000256]\n",
      "epoch:38 step:178480[D loss: 0.999861] [G loss: 1.000246]\n",
      "epoch:38 step:178485[D loss: 1.000019] [G loss: 0.999960]\n",
      "epoch:38 step:178490[D loss: 0.999844] [G loss: 1.000287]\n",
      "epoch:38 step:178495[D loss: 0.999934] [G loss: 1.000105]\n",
      "epoch:38 step:178500[D loss: 0.999982] [G loss: 1.000003]\n",
      "epoch:38 step:178505[D loss: 1.000143] [G loss: 0.999769]\n",
      "epoch:38 step:178510[D loss: 1.000070] [G loss: 0.999934]\n",
      "epoch:38 step:178515[D loss: 1.000127] [G loss: 0.999968]\n",
      "epoch:38 step:178520[D loss: 1.000165] [G loss: 0.999750]\n",
      "epoch:38 step:178525[D loss: 1.000001] [G loss: 1.000116]\n",
      "epoch:38 step:178530[D loss: 0.999854] [G loss: 1.000243]\n",
      "epoch:38 step:178535[D loss: 0.999948] [G loss: 1.000053]\n",
      "epoch:38 step:178540[D loss: 1.000048] [G loss: 1.000031]\n",
      "epoch:38 step:178545[D loss: 0.999960] [G loss: 1.000117]\n",
      "epoch:38 step:178550[D loss: 0.999954] [G loss: 1.000045]\n",
      "epoch:38 step:178555[D loss: 1.000012] [G loss: 1.000013]\n",
      "epoch:38 step:178560[D loss: 0.999999] [G loss: 1.000035]\n",
      "epoch:38 step:178565[D loss: 0.999952] [G loss: 1.000112]\n",
      "epoch:38 step:178570[D loss: 1.000048] [G loss: 1.000112]\n",
      "epoch:38 step:178575[D loss: 0.999901] [G loss: 1.000117]\n",
      "epoch:38 step:178580[D loss: 0.999977] [G loss: 1.000065]\n",
      "epoch:38 step:178585[D loss: 0.999940] [G loss: 1.000108]\n",
      "epoch:38 step:178590[D loss: 0.999988] [G loss: 1.000160]\n",
      "epoch:38 step:178595[D loss: 1.000029] [G loss: 1.000103]\n",
      "epoch:38 step:178600[D loss: 0.999916] [G loss: 1.000117]\n",
      "epoch:38 step:178605[D loss: 1.000027] [G loss: 1.000136]\n",
      "epoch:38 step:178610[D loss: 0.999933] [G loss: 1.000102]\n",
      "epoch:38 step:178615[D loss: 1.000056] [G loss: 1.000024]\n",
      "epoch:38 step:178620[D loss: 1.000170] [G loss: 0.999896]\n",
      "epoch:38 step:178625[D loss: 1.000180] [G loss: 0.999974]\n",
      "epoch:38 step:178630[D loss: 0.999799] [G loss: 1.000211]\n",
      "epoch:38 step:178635[D loss: 1.000096] [G loss: 0.999985]\n",
      "epoch:38 step:178640[D loss: 1.000070] [G loss: 0.999990]\n",
      "epoch:38 step:178645[D loss: 0.999895] [G loss: 1.000257]\n",
      "epoch:38 step:178650[D loss: 0.999953] [G loss: 1.000114]\n",
      "epoch:38 step:178655[D loss: 0.999993] [G loss: 0.999975]\n",
      "epoch:38 step:178660[D loss: 0.999976] [G loss: 1.000013]\n",
      "epoch:38 step:178665[D loss: 0.999973] [G loss: 1.000009]\n",
      "epoch:38 step:178670[D loss: 0.999977] [G loss: 0.999997]\n",
      "epoch:38 step:178675[D loss: 1.000151] [G loss: 0.999770]\n",
      "epoch:38 step:178680[D loss: 0.999978] [G loss: 0.999997]\n",
      "epoch:38 step:178685[D loss: 0.999850] [G loss: 1.000154]\n",
      "epoch:38 step:178690[D loss: 0.999983] [G loss: 1.000093]\n",
      "epoch:38 step:178695[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:38 step:178700[D loss: 0.999959] [G loss: 1.000131]\n",
      "epoch:38 step:178705[D loss: 0.999955] [G loss: 1.000127]\n",
      "epoch:38 step:178710[D loss: 0.999998] [G loss: 0.999996]\n",
      "epoch:38 step:178715[D loss: 1.000038] [G loss: 0.999939]\n",
      "epoch:38 step:178720[D loss: 0.999945] [G loss: 1.000035]\n",
      "epoch:38 step:178725[D loss: 0.999930] [G loss: 1.000069]\n",
      "epoch:38 step:178730[D loss: 1.000049] [G loss: 0.999932]\n",
      "epoch:38 step:178735[D loss: 0.999942] [G loss: 1.000142]\n",
      "epoch:38 step:178740[D loss: 0.999953] [G loss: 1.000168]\n",
      "epoch:38 step:178745[D loss: 0.999959] [G loss: 1.000113]\n",
      "epoch:38 step:178750[D loss: 0.999934] [G loss: 1.000128]\n",
      "epoch:38 step:178755[D loss: 0.999953] [G loss: 1.000239]\n",
      "epoch:38 step:178760[D loss: 1.000012] [G loss: 1.000069]\n",
      "epoch:38 step:178765[D loss: 1.000023] [G loss: 1.000228]\n",
      "epoch:38 step:178770[D loss: 0.999938] [G loss: 1.000084]\n",
      "epoch:38 step:178775[D loss: 0.999969] [G loss: 0.999996]\n",
      "epoch:38 step:178780[D loss: 1.000014] [G loss: 0.999971]\n",
      "epoch:38 step:178785[D loss: 0.999984] [G loss: 0.999840]\n",
      "epoch:38 step:178790[D loss: 0.999920] [G loss: 1.000047]\n",
      "epoch:38 step:178795[D loss: 1.000054] [G loss: 0.999836]\n",
      "epoch:38 step:178800[D loss: 0.999953] [G loss: 1.000030]\n",
      "epoch:38 step:178805[D loss: 0.999925] [G loss: 1.000099]\n",
      "epoch:38 step:178810[D loss: 0.999967] [G loss: 1.000024]\n",
      "epoch:38 step:178815[D loss: 0.999937] [G loss: 1.000174]\n",
      "epoch:38 step:178820[D loss: 1.000002] [G loss: 0.999997]\n",
      "epoch:38 step:178825[D loss: 0.999943] [G loss: 1.000105]\n",
      "epoch:38 step:178830[D loss: 0.999963] [G loss: 1.000125]\n",
      "epoch:38 step:178835[D loss: 1.000030] [G loss: 1.000187]\n",
      "epoch:38 step:178840[D loss: 0.999932] [G loss: 1.000140]\n",
      "epoch:38 step:178845[D loss: 0.999969] [G loss: 1.000080]\n",
      "epoch:38 step:178850[D loss: 1.000009] [G loss: 1.000059]\n",
      "epoch:38 step:178855[D loss: 1.000119] [G loss: 0.999886]\n",
      "epoch:38 step:178860[D loss: 1.000051] [G loss: 1.000044]\n",
      "epoch:38 step:178865[D loss: 0.999914] [G loss: 1.000077]\n",
      "epoch:38 step:178870[D loss: 0.999938] [G loss: 1.000088]\n",
      "epoch:38 step:178875[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:38 step:178880[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:38 step:178885[D loss: 0.999979] [G loss: 1.000049]\n",
      "epoch:38 step:178890[D loss: 0.999986] [G loss: 1.000063]\n",
      "epoch:38 step:178895[D loss: 0.999995] [G loss: 1.000037]\n",
      "epoch:38 step:178900[D loss: 0.999960] [G loss: 1.000089]\n",
      "epoch:38 step:178905[D loss: 1.000001] [G loss: 1.000088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:178910[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:38 step:178915[D loss: 0.999973] [G loss: 1.000092]\n",
      "epoch:38 step:178920[D loss: 1.000018] [G loss: 1.000033]\n",
      "epoch:38 step:178925[D loss: 0.999928] [G loss: 1.000124]\n",
      "epoch:38 step:178930[D loss: 0.999957] [G loss: 1.000071]\n",
      "epoch:38 step:178935[D loss: 0.999995] [G loss: 1.000084]\n",
      "epoch:38 step:178940[D loss: 0.999928] [G loss: 1.000141]\n",
      "epoch:38 step:178945[D loss: 0.999927] [G loss: 1.000159]\n",
      "epoch:38 step:178950[D loss: 0.999968] [G loss: 1.000119]\n",
      "epoch:38 step:178955[D loss: 1.000026] [G loss: 0.999971]\n",
      "epoch:38 step:178960[D loss: 0.999978] [G loss: 1.000039]\n",
      "epoch:38 step:178965[D loss: 0.999977] [G loss: 1.000041]\n",
      "epoch:38 step:178970[D loss: 0.999998] [G loss: 1.000076]\n",
      "epoch:38 step:178975[D loss: 1.000013] [G loss: 0.999988]\n",
      "epoch:38 step:178980[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:38 step:178985[D loss: 0.999973] [G loss: 1.000081]\n",
      "epoch:38 step:178990[D loss: 0.999924] [G loss: 1.000106]\n",
      "epoch:38 step:178995[D loss: 0.999978] [G loss: 1.000074]\n",
      "epoch:38 step:179000[D loss: 1.000012] [G loss: 1.000060]\n",
      "epoch:38 step:179005[D loss: 1.000015] [G loss: 1.000094]\n",
      "epoch:38 step:179010[D loss: 1.000010] [G loss: 1.000063]\n",
      "epoch:38 step:179015[D loss: 0.999983] [G loss: 1.000247]\n",
      "epoch:38 step:179020[D loss: 1.000024] [G loss: 1.000169]\n",
      "epoch:38 step:179025[D loss: 0.999981] [G loss: 1.000111]\n",
      "epoch:38 step:179030[D loss: 1.000060] [G loss: 1.000077]\n",
      "epoch:38 step:179035[D loss: 0.999935] [G loss: 1.000138]\n",
      "epoch:38 step:179040[D loss: 0.999974] [G loss: 1.000106]\n",
      "epoch:38 step:179045[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:38 step:179050[D loss: 1.000033] [G loss: 0.999959]\n",
      "epoch:38 step:179055[D loss: 1.000029] [G loss: 0.999853]\n",
      "epoch:38 step:179060[D loss: 1.000140] [G loss: 0.999741]\n",
      "epoch:38 step:179065[D loss: 1.000119] [G loss: 0.999919]\n",
      "epoch:38 step:179070[D loss: 0.999869] [G loss: 1.000055]\n",
      "epoch:38 step:179075[D loss: 0.999958] [G loss: 1.000231]\n",
      "epoch:38 step:179080[D loss: 1.000008] [G loss: 1.000052]\n",
      "epoch:38 step:179085[D loss: 0.999816] [G loss: 1.000337]\n",
      "epoch:38 step:179090[D loss: 0.999985] [G loss: 1.000108]\n",
      "epoch:38 step:179095[D loss: 0.999917] [G loss: 1.000183]\n",
      "epoch:38 step:179100[D loss: 0.999980] [G loss: 1.000185]\n",
      "epoch:38 step:179105[D loss: 0.999994] [G loss: 1.000095]\n",
      "epoch:38 step:179110[D loss: 0.999969] [G loss: 1.000104]\n",
      "epoch:38 step:179115[D loss: 1.000046] [G loss: 1.000180]\n",
      "epoch:38 step:179120[D loss: 0.999958] [G loss: 1.000125]\n",
      "epoch:38 step:179125[D loss: 0.999975] [G loss: 1.000034]\n",
      "epoch:38 step:179130[D loss: 0.999989] [G loss: 1.000075]\n",
      "epoch:38 step:179135[D loss: 1.000030] [G loss: 1.000064]\n",
      "epoch:38 step:179140[D loss: 1.000000] [G loss: 1.000054]\n",
      "epoch:38 step:179145[D loss: 1.000096] [G loss: 0.999905]\n",
      "epoch:38 step:179150[D loss: 0.999945] [G loss: 1.000146]\n",
      "epoch:38 step:179155[D loss: 1.000040] [G loss: 1.000052]\n",
      "epoch:38 step:179160[D loss: 1.000008] [G loss: 1.000255]\n",
      "epoch:38 step:179165[D loss: 1.000184] [G loss: 0.999929]\n",
      "epoch:38 step:179170[D loss: 0.999808] [G loss: 1.000246]\n",
      "epoch:38 step:179175[D loss: 0.999985] [G loss: 1.000109]\n",
      "epoch:38 step:179180[D loss: 0.999962] [G loss: 1.000194]\n",
      "epoch:38 step:179185[D loss: 0.999943] [G loss: 1.000140]\n",
      "epoch:38 step:179190[D loss: 0.999958] [G loss: 1.000103]\n",
      "epoch:38 step:179195[D loss: 0.999978] [G loss: 1.000109]\n",
      "epoch:38 step:179200[D loss: 0.999994] [G loss: 1.000111]\n",
      "epoch:38 step:179205[D loss: 0.999981] [G loss: 1.000140]\n",
      "epoch:38 step:179210[D loss: 0.999978] [G loss: 1.000084]\n",
      "epoch:38 step:179215[D loss: 1.000004] [G loss: 1.000086]\n",
      "epoch:38 step:179220[D loss: 0.999964] [G loss: 1.000107]\n",
      "epoch:38 step:179225[D loss: 0.999950] [G loss: 1.000078]\n",
      "epoch:38 step:179230[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:38 step:179235[D loss: 1.000093] [G loss: 0.999997]\n",
      "epoch:38 step:179240[D loss: 1.000111] [G loss: 0.999986]\n",
      "epoch:38 step:179245[D loss: 0.999988] [G loss: 1.000026]\n",
      "epoch:38 step:179250[D loss: 0.999984] [G loss: 1.000185]\n",
      "epoch:38 step:179255[D loss: 0.999957] [G loss: 1.000123]\n",
      "epoch:38 step:179260[D loss: 0.999977] [G loss: 1.000045]\n",
      "epoch:38 step:179265[D loss: 1.000036] [G loss: 1.000008]\n",
      "epoch:38 step:179270[D loss: 0.999922] [G loss: 1.000119]\n",
      "epoch:38 step:179275[D loss: 0.999937] [G loss: 1.000118]\n",
      "epoch:38 step:179280[D loss: 0.999981] [G loss: 1.000090]\n",
      "epoch:38 step:179285[D loss: 0.999979] [G loss: 1.000136]\n",
      "epoch:38 step:179290[D loss: 1.000003] [G loss: 1.000048]\n",
      "epoch:38 step:179295[D loss: 0.999988] [G loss: 1.000146]\n",
      "epoch:38 step:179300[D loss: 0.999960] [G loss: 1.000149]\n",
      "epoch:38 step:179305[D loss: 0.999991] [G loss: 1.000082]\n",
      "epoch:38 step:179310[D loss: 1.000042] [G loss: 0.999883]\n",
      "epoch:38 step:179315[D loss: 0.999904] [G loss: 1.000079]\n",
      "epoch:38 step:179320[D loss: 0.999875] [G loss: 1.000054]\n",
      "epoch:38 step:179325[D loss: 1.000029] [G loss: 1.000099]\n",
      "epoch:38 step:179330[D loss: 1.000011] [G loss: 1.000096]\n",
      "epoch:38 step:179335[D loss: 0.999912] [G loss: 1.000133]\n",
      "epoch:38 step:179340[D loss: 0.999974] [G loss: 1.000073]\n",
      "epoch:38 step:179345[D loss: 1.000000] [G loss: 1.000042]\n",
      "epoch:38 step:179350[D loss: 0.999950] [G loss: 1.000087]\n",
      "epoch:38 step:179355[D loss: 1.000038] [G loss: 1.000016]\n",
      "epoch:38 step:179360[D loss: 0.999956] [G loss: 1.000072]\n",
      "epoch:38 step:179365[D loss: 0.999976] [G loss: 1.000102]\n",
      "epoch:38 step:179370[D loss: 1.000008] [G loss: 1.000084]\n",
      "epoch:38 step:179375[D loss: 0.999951] [G loss: 1.000152]\n",
      "epoch:38 step:179380[D loss: 1.000037] [G loss: 1.000046]\n",
      "epoch:38 step:179385[D loss: 1.000068] [G loss: 1.000012]\n",
      "epoch:38 step:179390[D loss: 0.999924] [G loss: 1.000077]\n",
      "epoch:38 step:179395[D loss: 1.000009] [G loss: 0.999966]\n",
      "epoch:38 step:179400[D loss: 0.999980] [G loss: 1.000055]\n",
      "epoch:38 step:179405[D loss: 0.999947] [G loss: 0.999989]\n",
      "epoch:38 step:179410[D loss: 0.999960] [G loss: 1.000080]\n",
      "epoch:38 step:179415[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:38 step:179420[D loss: 0.999979] [G loss: 1.000104]\n",
      "epoch:38 step:179425[D loss: 0.999984] [G loss: 1.000046]\n",
      "epoch:38 step:179430[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:38 step:179435[D loss: 0.999994] [G loss: 1.000062]\n",
      "epoch:38 step:179440[D loss: 0.999944] [G loss: 1.000165]\n",
      "epoch:38 step:179445[D loss: 0.999978] [G loss: 1.000087]\n",
      "epoch:38 step:179450[D loss: 0.999951] [G loss: 1.000096]\n",
      "epoch:38 step:179455[D loss: 0.999987] [G loss: 1.000085]\n",
      "epoch:38 step:179460[D loss: 0.999978] [G loss: 1.000105]\n",
      "epoch:38 step:179465[D loss: 0.999999] [G loss: 1.000102]\n",
      "epoch:38 step:179470[D loss: 1.000012] [G loss: 1.000045]\n",
      "epoch:38 step:179475[D loss: 0.999882] [G loss: 1.000137]\n",
      "epoch:38 step:179480[D loss: 0.999986] [G loss: 1.000034]\n",
      "epoch:38 step:179485[D loss: 0.999960] [G loss: 1.000110]\n",
      "epoch:38 step:179490[D loss: 0.999951] [G loss: 1.000106]\n",
      "epoch:38 step:179495[D loss: 1.000014] [G loss: 1.000069]\n",
      "epoch:38 step:179500[D loss: 0.999986] [G loss: 1.000062]\n",
      "epoch:38 step:179505[D loss: 0.999998] [G loss: 1.000019]\n",
      "epoch:38 step:179510[D loss: 0.999923] [G loss: 1.000140]\n",
      "epoch:38 step:179515[D loss: 0.999976] [G loss: 1.000092]\n",
      "epoch:38 step:179520[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:38 step:179525[D loss: 0.999958] [G loss: 1.000101]\n",
      "epoch:38 step:179530[D loss: 0.999929] [G loss: 1.000189]\n",
      "epoch:38 step:179535[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:38 step:179540[D loss: 1.000015] [G loss: 1.000046]\n",
      "epoch:38 step:179545[D loss: 0.999996] [G loss: 1.000088]\n",
      "epoch:38 step:179550[D loss: 0.999940] [G loss: 1.000077]\n",
      "epoch:38 step:179555[D loss: 1.000032] [G loss: 0.999947]\n",
      "epoch:38 step:179560[D loss: 0.999984] [G loss: 1.000019]\n",
      "epoch:38 step:179565[D loss: 0.999960] [G loss: 1.000091]\n",
      "epoch:38 step:179570[D loss: 0.999990] [G loss: 1.000070]\n",
      "epoch:38 step:179575[D loss: 1.000003] [G loss: 1.000066]\n",
      "epoch:38 step:179580[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:38 step:179585[D loss: 1.000009] [G loss: 1.000101]\n",
      "epoch:38 step:179590[D loss: 0.999950] [G loss: 1.000095]\n",
      "epoch:38 step:179595[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:38 step:179600[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:38 step:179605[D loss: 0.999963] [G loss: 1.000056]\n",
      "epoch:38 step:179610[D loss: 1.000027] [G loss: 1.000038]\n",
      "epoch:38 step:179615[D loss: 0.999982] [G loss: 1.000008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:179620[D loss: 0.999972] [G loss: 1.000021]\n",
      "epoch:38 step:179625[D loss: 1.000046] [G loss: 1.000038]\n",
      "epoch:38 step:179630[D loss: 1.000042] [G loss: 1.000059]\n",
      "epoch:38 step:179635[D loss: 0.999985] [G loss: 1.000201]\n",
      "epoch:38 step:179640[D loss: 1.000010] [G loss: 1.000106]\n",
      "epoch:38 step:179645[D loss: 1.000073] [G loss: 1.000043]\n",
      "epoch:38 step:179650[D loss: 0.999992] [G loss: 0.999968]\n",
      "epoch:38 step:179655[D loss: 1.000050] [G loss: 0.999804]\n",
      "epoch:38 step:179660[D loss: 1.000147] [G loss: 0.999788]\n",
      "epoch:38 step:179665[D loss: 1.000163] [G loss: 0.999928]\n",
      "epoch:38 step:179670[D loss: 0.999967] [G loss: 1.000013]\n",
      "epoch:38 step:179675[D loss: 1.000058] [G loss: 1.000000]\n",
      "epoch:38 step:179680[D loss: 0.999879] [G loss: 1.000212]\n",
      "epoch:38 step:179685[D loss: 0.999891] [G loss: 1.000188]\n",
      "epoch:38 step:179690[D loss: 0.999946] [G loss: 1.000174]\n",
      "epoch:38 step:179695[D loss: 0.999962] [G loss: 1.000134]\n",
      "epoch:38 step:179700[D loss: 0.999994] [G loss: 1.000065]\n",
      "epoch:38 step:179705[D loss: 0.999958] [G loss: 1.000017]\n",
      "epoch:38 step:179710[D loss: 1.000055] [G loss: 1.000003]\n",
      "epoch:38 step:179715[D loss: 1.000176] [G loss: 0.999804]\n",
      "epoch:38 step:179720[D loss: 0.999934] [G loss: 0.999986]\n",
      "epoch:38 step:179725[D loss: 0.999965] [G loss: 1.000157]\n",
      "epoch:38 step:179730[D loss: 0.999959] [G loss: 1.000037]\n",
      "epoch:38 step:179735[D loss: 0.999961] [G loss: 1.000115]\n",
      "epoch:38 step:179740[D loss: 0.999981] [G loss: 1.000052]\n",
      "epoch:38 step:179745[D loss: 0.999954] [G loss: 1.000089]\n",
      "epoch:38 step:179750[D loss: 0.999980] [G loss: 1.000072]\n",
      "epoch:38 step:179755[D loss: 1.000000] [G loss: 1.000081]\n",
      "epoch:38 step:179760[D loss: 1.000085] [G loss: 0.999990]\n",
      "epoch:38 step:179765[D loss: 0.999966] [G loss: 1.000045]\n",
      "epoch:38 step:179770[D loss: 0.999954] [G loss: 1.000098]\n",
      "epoch:38 step:179775[D loss: 1.000108] [G loss: 0.999986]\n",
      "epoch:38 step:179780[D loss: 0.999933] [G loss: 1.000131]\n",
      "epoch:38 step:179785[D loss: 1.000102] [G loss: 0.999943]\n",
      "epoch:38 step:179790[D loss: 0.999992] [G loss: 1.000181]\n",
      "epoch:38 step:179795[D loss: 0.999925] [G loss: 1.000135]\n",
      "epoch:38 step:179800[D loss: 0.999966] [G loss: 1.000103]\n",
      "epoch:38 step:179805[D loss: 1.000008] [G loss: 0.999981]\n",
      "epoch:38 step:179810[D loss: 0.999997] [G loss: 1.000023]\n",
      "epoch:38 step:179815[D loss: 0.999986] [G loss: 1.000015]\n",
      "epoch:38 step:179820[D loss: 1.000128] [G loss: 0.999901]\n",
      "epoch:38 step:179825[D loss: 0.999861] [G loss: 1.000136]\n",
      "epoch:38 step:179830[D loss: 0.999995] [G loss: 1.000159]\n",
      "epoch:38 step:179835[D loss: 0.999918] [G loss: 1.000081]\n",
      "epoch:38 step:179840[D loss: 0.999936] [G loss: 1.000120]\n",
      "epoch:38 step:179845[D loss: 0.999996] [G loss: 1.000062]\n",
      "epoch:38 step:179850[D loss: 1.000053] [G loss: 1.000016]\n",
      "epoch:38 step:179855[D loss: 0.999936] [G loss: 1.000126]\n",
      "epoch:38 step:179860[D loss: 0.999963] [G loss: 1.000096]\n",
      "epoch:38 step:179865[D loss: 1.000168] [G loss: 0.999945]\n",
      "epoch:38 step:179870[D loss: 1.000025] [G loss: 1.000098]\n",
      "epoch:38 step:179875[D loss: 1.000028] [G loss: 1.000152]\n",
      "epoch:38 step:179880[D loss: 0.999930] [G loss: 1.000153]\n",
      "epoch:38 step:179885[D loss: 0.999997] [G loss: 1.000037]\n",
      "epoch:38 step:179890[D loss: 0.999952] [G loss: 1.000089]\n",
      "epoch:38 step:179895[D loss: 0.999959] [G loss: 1.000035]\n",
      "epoch:38 step:179900[D loss: 1.000032] [G loss: 1.000028]\n",
      "epoch:38 step:179905[D loss: 1.000019] [G loss: 0.999980]\n",
      "epoch:38 step:179910[D loss: 0.999999] [G loss: 1.000038]\n",
      "epoch:38 step:179915[D loss: 0.999897] [G loss: 1.000153]\n",
      "epoch:38 step:179920[D loss: 1.000222] [G loss: 0.999854]\n",
      "epoch:38 step:179925[D loss: 0.999970] [G loss: 1.000067]\n",
      "epoch:38 step:179930[D loss: 0.999840] [G loss: 1.000162]\n",
      "epoch:38 step:179935[D loss: 0.999974] [G loss: 1.000044]\n",
      "epoch:38 step:179940[D loss: 1.000057] [G loss: 1.000013]\n",
      "epoch:38 step:179945[D loss: 0.999974] [G loss: 1.000045]\n",
      "epoch:38 step:179950[D loss: 0.999976] [G loss: 1.000064]\n",
      "epoch:38 step:179955[D loss: 1.000015] [G loss: 1.000101]\n",
      "epoch:38 step:179960[D loss: 0.999990] [G loss: 0.999956]\n",
      "epoch:38 step:179965[D loss: 1.000144] [G loss: 0.999988]\n",
      "epoch:38 step:179970[D loss: 0.999883] [G loss: 1.000218]\n",
      "epoch:38 step:179975[D loss: 0.999923] [G loss: 1.000030]\n",
      "epoch:38 step:179980[D loss: 0.999986] [G loss: 1.000115]\n",
      "epoch:38 step:179985[D loss: 0.999974] [G loss: 1.000035]\n",
      "epoch:38 step:179990[D loss: 0.999963] [G loss: 1.000061]\n",
      "epoch:38 step:179995[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:38 step:180000[D loss: 1.000012] [G loss: 1.000001]\n",
      "epoch:38 step:180005[D loss: 0.999945] [G loss: 1.000067]\n",
      "epoch:38 step:180010[D loss: 0.999969] [G loss: 1.000058]\n",
      "epoch:38 step:180015[D loss: 1.000065] [G loss: 0.999877]\n",
      "epoch:38 step:180020[D loss: 0.999970] [G loss: 1.000098]\n",
      "epoch:38 step:180025[D loss: 1.000082] [G loss: 0.999949]\n",
      "epoch:38 step:180030[D loss: 1.000053] [G loss: 0.999984]\n",
      "epoch:38 step:180035[D loss: 1.000057] [G loss: 0.999913]\n",
      "epoch:38 step:180040[D loss: 0.999902] [G loss: 1.000205]\n",
      "epoch:38 step:180045[D loss: 1.000050] [G loss: 1.000004]\n",
      "epoch:38 step:180050[D loss: 0.999943] [G loss: 1.000097]\n",
      "epoch:38 step:180055[D loss: 1.000026] [G loss: 0.999940]\n",
      "epoch:38 step:180060[D loss: 0.999972] [G loss: 1.000096]\n",
      "epoch:38 step:180065[D loss: 0.999995] [G loss: 1.000060]\n",
      "epoch:38 step:180070[D loss: 0.999939] [G loss: 1.000071]\n",
      "epoch:38 step:180075[D loss: 0.999978] [G loss: 1.000073]\n",
      "epoch:38 step:180080[D loss: 1.000071] [G loss: 1.000013]\n",
      "epoch:38 step:180085[D loss: 0.999985] [G loss: 1.000086]\n",
      "epoch:38 step:180090[D loss: 0.999992] [G loss: 1.000024]\n",
      "epoch:38 step:180095[D loss: 0.999962] [G loss: 1.000126]\n",
      "epoch:38 step:180100[D loss: 0.999969] [G loss: 1.000056]\n",
      "epoch:38 step:180105[D loss: 0.999959] [G loss: 1.000096]\n",
      "epoch:38 step:180110[D loss: 0.999968] [G loss: 1.000098]\n",
      "epoch:38 step:180115[D loss: 0.999990] [G loss: 1.000017]\n",
      "epoch:38 step:180120[D loss: 0.999997] [G loss: 1.000086]\n",
      "epoch:38 step:180125[D loss: 0.999944] [G loss: 1.000106]\n",
      "epoch:38 step:180130[D loss: 0.999981] [G loss: 1.000094]\n",
      "epoch:38 step:180135[D loss: 1.000090] [G loss: 1.000063]\n",
      "epoch:38 step:180140[D loss: 1.000002] [G loss: 1.000121]\n",
      "epoch:38 step:180145[D loss: 0.999947] [G loss: 1.000121]\n",
      "epoch:38 step:180150[D loss: 0.999964] [G loss: 1.000213]\n",
      "epoch:38 step:180155[D loss: 1.000011] [G loss: 1.000067]\n",
      "epoch:38 step:180160[D loss: 1.000007] [G loss: 0.999987]\n",
      "epoch:38 step:180165[D loss: 1.000076] [G loss: 0.999938]\n",
      "epoch:38 step:180170[D loss: 1.000074] [G loss: 0.999879]\n",
      "epoch:38 step:180175[D loss: 1.000032] [G loss: 0.999964]\n",
      "epoch:38 step:180180[D loss: 1.000059] [G loss: 0.999909]\n",
      "epoch:38 step:180185[D loss: 1.000084] [G loss: 1.000006]\n",
      "epoch:38 step:180190[D loss: 1.000003] [G loss: 1.000113]\n",
      "epoch:38 step:180195[D loss: 0.999903] [G loss: 1.000173]\n",
      "epoch:38 step:180200[D loss: 0.999901] [G loss: 1.000220]\n",
      "epoch:38 step:180205[D loss: 1.000016] [G loss: 1.000060]\n",
      "epoch:38 step:180210[D loss: 1.000008] [G loss: 1.000028]\n",
      "epoch:38 step:180215[D loss: 0.999925] [G loss: 1.000015]\n",
      "epoch:38 step:180220[D loss: 0.999990] [G loss: 0.999998]\n",
      "epoch:38 step:180225[D loss: 0.999918] [G loss: 1.000063]\n",
      "epoch:38 step:180230[D loss: 1.000034] [G loss: 1.000099]\n",
      "epoch:38 step:180235[D loss: 1.000040] [G loss: 0.999980]\n",
      "epoch:38 step:180240[D loss: 1.000025] [G loss: 1.000077]\n",
      "epoch:38 step:180245[D loss: 0.999974] [G loss: 1.000066]\n",
      "epoch:38 step:180250[D loss: 0.999938] [G loss: 1.000191]\n",
      "epoch:38 step:180255[D loss: 0.999922] [G loss: 1.000084]\n",
      "epoch:38 step:180260[D loss: 1.000140] [G loss: 0.999995]\n",
      "epoch:38 step:180265[D loss: 0.999987] [G loss: 1.000192]\n",
      "epoch:38 step:180270[D loss: 1.000082] [G loss: 1.000047]\n",
      "epoch:38 step:180275[D loss: 0.999917] [G loss: 1.000131]\n",
      "epoch:38 step:180280[D loss: 0.999987] [G loss: 1.000118]\n",
      "epoch:38 step:180285[D loss: 0.999996] [G loss: 0.999973]\n",
      "epoch:38 step:180290[D loss: 0.999968] [G loss: 1.000054]\n",
      "epoch:38 step:180295[D loss: 0.999997] [G loss: 1.000053]\n",
      "epoch:38 step:180300[D loss: 0.999991] [G loss: 1.000038]\n",
      "epoch:38 step:180305[D loss: 1.000017] [G loss: 0.999979]\n",
      "epoch:38 step:180310[D loss: 0.999973] [G loss: 1.000044]\n",
      "epoch:38 step:180315[D loss: 1.000054] [G loss: 1.000060]\n",
      "epoch:38 step:180320[D loss: 1.000069] [G loss: 1.000093]\n",
      "epoch:38 step:180325[D loss: 1.000215] [G loss: 1.000084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:180330[D loss: 0.999839] [G loss: 1.000251]\n",
      "epoch:38 step:180335[D loss: 0.999967] [G loss: 1.000076]\n",
      "epoch:38 step:180340[D loss: 1.000000] [G loss: 1.000036]\n",
      "epoch:38 step:180345[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:38 step:180350[D loss: 0.999880] [G loss: 1.000205]\n",
      "epoch:38 step:180355[D loss: 0.999933] [G loss: 1.000125]\n",
      "epoch:38 step:180360[D loss: 0.999911] [G loss: 1.000156]\n",
      "epoch:38 step:180365[D loss: 1.000045] [G loss: 1.000030]\n",
      "epoch:38 step:180370[D loss: 1.000089] [G loss: 1.000120]\n",
      "epoch:38 step:180375[D loss: 1.000124] [G loss: 1.000228]\n",
      "epoch:38 step:180380[D loss: 0.999946] [G loss: 1.000125]\n",
      "epoch:38 step:180385[D loss: 0.999855] [G loss: 1.000371]\n",
      "epoch:38 step:180390[D loss: 0.999951] [G loss: 1.000143]\n",
      "epoch:38 step:180395[D loss: 1.000043] [G loss: 0.999927]\n",
      "epoch:38 step:180400[D loss: 1.000004] [G loss: 1.000030]\n",
      "epoch:38 step:180405[D loss: 0.999889] [G loss: 1.000043]\n",
      "epoch:38 step:180410[D loss: 1.000049] [G loss: 0.999908]\n",
      "epoch:38 step:180415[D loss: 0.999922] [G loss: 1.000039]\n",
      "epoch:38 step:180420[D loss: 1.000042] [G loss: 1.000119]\n",
      "epoch:38 step:180425[D loss: 0.999976] [G loss: 0.999954]\n",
      "epoch:38 step:180430[D loss: 0.999973] [G loss: 1.000091]\n",
      "epoch:38 step:180435[D loss: 1.000028] [G loss: 1.000107]\n",
      "epoch:38 step:180440[D loss: 0.999925] [G loss: 1.000144]\n",
      "epoch:38 step:180445[D loss: 1.000006] [G loss: 1.000061]\n",
      "epoch:38 step:180450[D loss: 0.999971] [G loss: 1.000123]\n",
      "epoch:38 step:180455[D loss: 1.000159] [G loss: 0.999844]\n",
      "epoch:38 step:180460[D loss: 0.999994] [G loss: 1.000032]\n",
      "epoch:38 step:180465[D loss: 0.999999] [G loss: 1.000097]\n",
      "epoch:38 step:180470[D loss: 1.000074] [G loss: 0.999987]\n",
      "epoch:38 step:180475[D loss: 1.000077] [G loss: 0.999956]\n",
      "epoch:38 step:180480[D loss: 1.000026] [G loss: 1.000214]\n",
      "epoch:38 step:180485[D loss: 0.999813] [G loss: 1.000430]\n",
      "epoch:38 step:180490[D loss: 1.000026] [G loss: 1.000158]\n",
      "epoch:38 step:180495[D loss: 1.000079] [G loss: 1.000304]\n",
      "epoch:38 step:180500[D loss: 0.999991] [G loss: 1.000428]\n",
      "epoch:38 step:180505[D loss: 0.999807] [G loss: 1.000235]\n",
      "epoch:38 step:180510[D loss: 1.000106] [G loss: 1.000393]\n",
      "epoch:38 step:180515[D loss: 0.999896] [G loss: 1.000340]\n",
      "epoch:38 step:180520[D loss: 0.999918] [G loss: 1.000168]\n",
      "epoch:38 step:180525[D loss: 1.000096] [G loss: 0.999846]\n",
      "epoch:38 step:180530[D loss: 1.000126] [G loss: 0.999856]\n",
      "epoch:38 step:180535[D loss: 0.999889] [G loss: 0.999899]\n",
      "epoch:38 step:180540[D loss: 1.000011] [G loss: 0.999904]\n",
      "epoch:38 step:180545[D loss: 0.999949] [G loss: 0.999973]\n",
      "epoch:38 step:180550[D loss: 0.999950] [G loss: 1.000013]\n",
      "epoch:38 step:180555[D loss: 1.000057] [G loss: 0.999916]\n",
      "epoch:38 step:180560[D loss: 0.999660] [G loss: 1.000402]\n",
      "epoch:38 step:180565[D loss: 0.999960] [G loss: 1.000175]\n",
      "epoch:38 step:180570[D loss: 1.000034] [G loss: 1.000267]\n",
      "epoch:38 step:180575[D loss: 1.000004] [G loss: 1.000139]\n",
      "epoch:38 step:180580[D loss: 1.000363] [G loss: 0.999941]\n",
      "epoch:38 step:180585[D loss: 0.999971] [G loss: 1.000182]\n",
      "epoch:38 step:180590[D loss: 0.999748] [G loss: 1.000292]\n",
      "epoch:38 step:180595[D loss: 0.999931] [G loss: 1.000143]\n",
      "epoch:38 step:180600[D loss: 0.999997] [G loss: 0.999953]\n",
      "epoch:38 step:180605[D loss: 1.000044] [G loss: 0.999971]\n",
      "epoch:38 step:180610[D loss: 1.000052] [G loss: 0.999846]\n",
      "epoch:38 step:180615[D loss: 1.000169] [G loss: 0.999881]\n",
      "epoch:38 step:180620[D loss: 0.999855] [G loss: 1.000017]\n",
      "epoch:38 step:180625[D loss: 1.000091] [G loss: 0.999947]\n",
      "epoch:38 step:180630[D loss: 0.999919] [G loss: 1.000292]\n",
      "epoch:38 step:180635[D loss: 1.000198] [G loss: 0.999845]\n",
      "epoch:38 step:180640[D loss: 0.999870] [G loss: 1.000117]\n",
      "epoch:38 step:180645[D loss: 1.000006] [G loss: 1.000165]\n",
      "epoch:38 step:180650[D loss: 1.000020] [G loss: 1.000149]\n",
      "epoch:38 step:180655[D loss: 0.999882] [G loss: 1.000181]\n",
      "epoch:38 step:180660[D loss: 0.999948] [G loss: 1.000107]\n",
      "epoch:38 step:180665[D loss: 0.999956] [G loss: 1.000061]\n",
      "epoch:38 step:180670[D loss: 0.999991] [G loss: 1.000002]\n",
      "epoch:38 step:180675[D loss: 0.999980] [G loss: 0.999998]\n",
      "epoch:38 step:180680[D loss: 0.999982] [G loss: 1.000037]\n",
      "epoch:38 step:180685[D loss: 1.000015] [G loss: 1.000009]\n",
      "epoch:38 step:180690[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:38 step:180695[D loss: 0.999927] [G loss: 1.000052]\n",
      "epoch:38 step:180700[D loss: 0.999961] [G loss: 1.000086]\n",
      "epoch:38 step:180705[D loss: 0.999949] [G loss: 1.000070]\n",
      "epoch:38 step:180710[D loss: 0.999991] [G loss: 1.000081]\n",
      "epoch:38 step:180715[D loss: 1.000039] [G loss: 1.000045]\n",
      "epoch:38 step:180720[D loss: 1.000049] [G loss: 1.000007]\n",
      "epoch:38 step:180725[D loss: 1.000009] [G loss: 1.000064]\n",
      "epoch:38 step:180730[D loss: 0.999941] [G loss: 1.000105]\n",
      "epoch:38 step:180735[D loss: 0.999965] [G loss: 1.000073]\n",
      "epoch:38 step:180740[D loss: 1.000026] [G loss: 1.000011]\n",
      "epoch:38 step:180745[D loss: 1.000142] [G loss: 0.999889]\n",
      "epoch:38 step:180750[D loss: 1.000031] [G loss: 0.999906]\n",
      "epoch:38 step:180755[D loss: 0.999988] [G loss: 1.000022]\n",
      "epoch:38 step:180760[D loss: 0.999992] [G loss: 1.000044]\n",
      "epoch:38 step:180765[D loss: 1.000011] [G loss: 1.000008]\n",
      "epoch:38 step:180770[D loss: 1.000010] [G loss: 1.000016]\n",
      "epoch:38 step:180775[D loss: 0.999942] [G loss: 1.000092]\n",
      "epoch:38 step:180780[D loss: 1.000054] [G loss: 1.000042]\n",
      "epoch:38 step:180785[D loss: 1.000003] [G loss: 1.000035]\n",
      "epoch:38 step:180790[D loss: 1.000007] [G loss: 1.000024]\n",
      "epoch:38 step:180795[D loss: 0.999972] [G loss: 1.000072]\n",
      "epoch:38 step:180800[D loss: 0.999971] [G loss: 1.000027]\n",
      "epoch:38 step:180805[D loss: 0.999990] [G loss: 0.999998]\n",
      "epoch:38 step:180810[D loss: 0.999969] [G loss: 1.000077]\n",
      "epoch:38 step:180815[D loss: 0.999963] [G loss: 1.000075]\n",
      "epoch:38 step:180820[D loss: 1.000006] [G loss: 0.999983]\n",
      "epoch:38 step:180825[D loss: 0.999982] [G loss: 1.000032]\n",
      "epoch:38 step:180830[D loss: 0.999987] [G loss: 1.000021]\n",
      "epoch:38 step:180835[D loss: 0.999948] [G loss: 1.000075]\n",
      "epoch:38 step:180840[D loss: 0.999954] [G loss: 1.000058]\n",
      "epoch:38 step:180845[D loss: 0.999999] [G loss: 1.000059]\n",
      "epoch:38 step:180850[D loss: 1.000000] [G loss: 1.000045]\n",
      "epoch:38 step:180855[D loss: 1.000003] [G loss: 1.000021]\n",
      "epoch:38 step:180860[D loss: 0.999972] [G loss: 1.000059]\n",
      "epoch:38 step:180865[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:38 step:180870[D loss: 0.999990] [G loss: 1.000041]\n",
      "epoch:38 step:180875[D loss: 0.999990] [G loss: 1.000071]\n",
      "epoch:38 step:180880[D loss: 1.000007] [G loss: 0.999963]\n",
      "epoch:38 step:180885[D loss: 0.999954] [G loss: 1.000123]\n",
      "epoch:38 step:180890[D loss: 0.999959] [G loss: 1.000121]\n",
      "epoch:38 step:180895[D loss: 0.999971] [G loss: 1.000057]\n",
      "epoch:38 step:180900[D loss: 0.999970] [G loss: 1.000014]\n",
      "epoch:38 step:180905[D loss: 1.000037] [G loss: 1.000082]\n",
      "epoch:38 step:180910[D loss: 1.000126] [G loss: 0.999726]\n",
      "epoch:38 step:180915[D loss: 0.999855] [G loss: 1.000136]\n",
      "epoch:38 step:180920[D loss: 1.000087] [G loss: 1.000041]\n",
      "epoch:38 step:180925[D loss: 0.999984] [G loss: 1.000017]\n",
      "epoch:38 step:180930[D loss: 1.000076] [G loss: 1.000230]\n",
      "epoch:38 step:180935[D loss: 0.999929] [G loss: 1.000099]\n",
      "epoch:38 step:180940[D loss: 0.999951] [G loss: 1.000055]\n",
      "epoch:38 step:180945[D loss: 1.000018] [G loss: 0.999962]\n",
      "epoch:38 step:180950[D loss: 0.999948] [G loss: 1.000044]\n",
      "epoch:38 step:180955[D loss: 1.000042] [G loss: 0.999957]\n",
      "epoch:38 step:180960[D loss: 1.000043] [G loss: 1.000025]\n",
      "epoch:38 step:180965[D loss: 0.999965] [G loss: 0.999988]\n",
      "epoch:38 step:180970[D loss: 1.000087] [G loss: 1.000031]\n",
      "epoch:38 step:180975[D loss: 1.000125] [G loss: 0.999992]\n",
      "epoch:38 step:180980[D loss: 0.999981] [G loss: 0.999980]\n",
      "epoch:38 step:180985[D loss: 0.999893] [G loss: 1.000169]\n",
      "epoch:38 step:180990[D loss: 1.000046] [G loss: 0.999985]\n",
      "epoch:38 step:180995[D loss: 1.000081] [G loss: 0.999928]\n",
      "epoch:38 step:181000[D loss: 1.000141] [G loss: 0.999876]\n",
      "epoch:38 step:181005[D loss: 1.000007] [G loss: 1.000092]\n",
      "epoch:38 step:181010[D loss: 1.000015] [G loss: 0.999898]\n",
      "epoch:38 step:181015[D loss: 0.999833] [G loss: 1.000194]\n",
      "epoch:38 step:181020[D loss: 0.999996] [G loss: 1.000084]\n",
      "epoch:38 step:181025[D loss: 0.999917] [G loss: 1.000198]\n",
      "epoch:38 step:181030[D loss: 0.999964] [G loss: 1.000108]\n",
      "epoch:38 step:181035[D loss: 1.000031] [G loss: 0.999988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:181040[D loss: 1.000031] [G loss: 0.999991]\n",
      "epoch:38 step:181045[D loss: 0.999953] [G loss: 1.000081]\n",
      "epoch:38 step:181050[D loss: 1.000098] [G loss: 0.999775]\n",
      "epoch:38 step:181055[D loss: 0.999919] [G loss: 1.000073]\n",
      "epoch:38 step:181060[D loss: 0.999980] [G loss: 0.999941]\n",
      "epoch:38 step:181065[D loss: 0.999949] [G loss: 1.000048]\n",
      "epoch:38 step:181070[D loss: 1.000003] [G loss: 1.000007]\n",
      "epoch:38 step:181075[D loss: 1.000345] [G loss: 0.999817]\n",
      "epoch:38 step:181080[D loss: 0.999842] [G loss: 1.000081]\n",
      "epoch:38 step:181085[D loss: 1.000030] [G loss: 1.000057]\n",
      "epoch:38 step:181090[D loss: 1.000003] [G loss: 1.000062]\n",
      "epoch:38 step:181095[D loss: 0.999975] [G loss: 0.999991]\n",
      "epoch:38 step:181100[D loss: 0.999984] [G loss: 1.000023]\n",
      "epoch:38 step:181105[D loss: 0.999964] [G loss: 0.999920]\n",
      "epoch:38 step:181110[D loss: 0.999925] [G loss: 0.999971]\n",
      "epoch:38 step:181115[D loss: 1.000110] [G loss: 1.000078]\n",
      "epoch:38 step:181120[D loss: 0.999951] [G loss: 0.999983]\n",
      "epoch:38 step:181125[D loss: 0.999854] [G loss: 1.000077]\n",
      "epoch:38 step:181130[D loss: 0.999983] [G loss: 1.000112]\n",
      "epoch:38 step:181135[D loss: 1.000072] [G loss: 0.999985]\n",
      "epoch:38 step:181140[D loss: 1.000035] [G loss: 1.000120]\n",
      "epoch:38 step:181145[D loss: 0.999941] [G loss: 1.000138]\n",
      "epoch:38 step:181150[D loss: 0.999876] [G loss: 1.000228]\n",
      "epoch:38 step:181155[D loss: 0.999913] [G loss: 1.000253]\n",
      "epoch:38 step:181160[D loss: 0.999905] [G loss: 1.000143]\n",
      "epoch:38 step:181165[D loss: 1.000047] [G loss: 0.999970]\n",
      "epoch:38 step:181170[D loss: 1.000004] [G loss: 0.999872]\n",
      "epoch:38 step:181175[D loss: 0.999918] [G loss: 1.000062]\n",
      "epoch:38 step:181180[D loss: 1.000014] [G loss: 1.000051]\n",
      "epoch:38 step:181185[D loss: 0.999903] [G loss: 1.000094]\n",
      "epoch:38 step:181190[D loss: 1.000041] [G loss: 1.000127]\n",
      "epoch:38 step:181195[D loss: 0.999937] [G loss: 1.000129]\n",
      "epoch:38 step:181200[D loss: 0.999971] [G loss: 1.000051]\n",
      "epoch:38 step:181205[D loss: 0.999919] [G loss: 1.000123]\n",
      "epoch:38 step:181210[D loss: 0.999988] [G loss: 1.000073]\n",
      "epoch:38 step:181215[D loss: 1.000234] [G loss: 0.999842]\n",
      "epoch:38 step:181220[D loss: 0.999909] [G loss: 0.999968]\n",
      "epoch:38 step:181225[D loss: 0.999936] [G loss: 1.000092]\n",
      "epoch:38 step:181230[D loss: 1.000061] [G loss: 0.999932]\n",
      "epoch:38 step:181235[D loss: 1.000003] [G loss: 1.000076]\n",
      "epoch:38 step:181240[D loss: 0.999937] [G loss: 1.000126]\n",
      "epoch:38 step:181245[D loss: 0.999997] [G loss: 1.000042]\n",
      "epoch:38 step:181250[D loss: 1.000110] [G loss: 0.999929]\n",
      "epoch:38 step:181255[D loss: 0.999914] [G loss: 1.000035]\n",
      "epoch:38 step:181260[D loss: 1.000022] [G loss: 1.000001]\n",
      "epoch:38 step:181265[D loss: 0.999941] [G loss: 1.000101]\n",
      "epoch:38 step:181270[D loss: 0.999968] [G loss: 1.000095]\n",
      "epoch:38 step:181275[D loss: 0.999977] [G loss: 1.000116]\n",
      "epoch:38 step:181280[D loss: 0.999964] [G loss: 1.000061]\n",
      "epoch:38 step:181285[D loss: 1.000007] [G loss: 1.000051]\n",
      "epoch:38 step:181290[D loss: 0.999962] [G loss: 1.000075]\n",
      "epoch:38 step:181295[D loss: 0.999981] [G loss: 1.000049]\n",
      "epoch:38 step:181300[D loss: 0.999996] [G loss: 1.000089]\n",
      "epoch:38 step:181305[D loss: 0.999966] [G loss: 1.000079]\n",
      "epoch:38 step:181310[D loss: 0.999945] [G loss: 1.000124]\n",
      "epoch:38 step:181315[D loss: 1.000098] [G loss: 0.999879]\n",
      "epoch:38 step:181320[D loss: 0.999920] [G loss: 1.000093]\n",
      "epoch:38 step:181325[D loss: 1.000033] [G loss: 1.000034]\n",
      "epoch:38 step:181330[D loss: 0.999975] [G loss: 1.000037]\n",
      "epoch:38 step:181335[D loss: 1.000009] [G loss: 1.000012]\n",
      "epoch:38 step:181340[D loss: 1.000123] [G loss: 0.999930]\n",
      "epoch:38 step:181345[D loss: 1.000039] [G loss: 1.000068]\n",
      "epoch:38 step:181350[D loss: 0.999978] [G loss: 0.999957]\n",
      "epoch:38 step:181355[D loss: 0.999968] [G loss: 1.000058]\n",
      "epoch:38 step:181360[D loss: 0.999956] [G loss: 1.000076]\n",
      "epoch:38 step:181365[D loss: 0.999981] [G loss: 1.000069]\n",
      "epoch:38 step:181370[D loss: 0.999947] [G loss: 1.000051]\n",
      "epoch:38 step:181375[D loss: 0.999930] [G loss: 1.000062]\n",
      "epoch:38 step:181380[D loss: 1.000034] [G loss: 0.999972]\n",
      "epoch:38 step:181385[D loss: 0.999911] [G loss: 1.000099]\n",
      "epoch:38 step:181390[D loss: 1.000027] [G loss: 1.000081]\n",
      "epoch:38 step:181395[D loss: 1.000027] [G loss: 1.000108]\n",
      "epoch:38 step:181400[D loss: 0.999903] [G loss: 1.000163]\n",
      "epoch:38 step:181405[D loss: 1.000010] [G loss: 1.000006]\n",
      "epoch:38 step:181410[D loss: 1.000027] [G loss: 0.999940]\n",
      "epoch:38 step:181415[D loss: 0.999984] [G loss: 1.000016]\n",
      "epoch:38 step:181420[D loss: 1.000167] [G loss: 0.999891]\n",
      "epoch:38 step:181425[D loss: 0.999993] [G loss: 0.999956]\n",
      "epoch:38 step:181430[D loss: 0.999911] [G loss: 1.000191]\n",
      "epoch:38 step:181435[D loss: 0.999977] [G loss: 1.000080]\n",
      "epoch:38 step:181440[D loss: 0.999882] [G loss: 1.000231]\n",
      "epoch:38 step:181445[D loss: 0.999954] [G loss: 1.000083]\n",
      "epoch:38 step:181450[D loss: 0.999995] [G loss: 1.000045]\n",
      "epoch:38 step:181455[D loss: 1.000027] [G loss: 1.000019]\n",
      "epoch:38 step:181460[D loss: 1.000027] [G loss: 0.999947]\n",
      "epoch:38 step:181465[D loss: 0.999931] [G loss: 1.000079]\n",
      "epoch:38 step:181470[D loss: 1.000010] [G loss: 1.000038]\n",
      "epoch:38 step:181475[D loss: 0.999950] [G loss: 1.000105]\n",
      "epoch:38 step:181480[D loss: 0.999955] [G loss: 1.000105]\n",
      "epoch:38 step:181485[D loss: 0.999956] [G loss: 1.000099]\n",
      "epoch:38 step:181490[D loss: 0.999972] [G loss: 1.000087]\n",
      "epoch:38 step:181495[D loss: 1.000073] [G loss: 1.000092]\n",
      "epoch:38 step:181500[D loss: 1.000052] [G loss: 1.000009]\n",
      "epoch:38 step:181505[D loss: 0.999962] [G loss: 1.000110]\n",
      "epoch:38 step:181510[D loss: 0.999961] [G loss: 1.000082]\n",
      "epoch:38 step:181515[D loss: 0.999985] [G loss: 1.000075]\n",
      "epoch:38 step:181520[D loss: 0.999999] [G loss: 1.000027]\n",
      "epoch:38 step:181525[D loss: 0.999968] [G loss: 1.000069]\n",
      "epoch:38 step:181530[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:38 step:181535[D loss: 0.999981] [G loss: 1.000072]\n",
      "epoch:38 step:181540[D loss: 0.999990] [G loss: 1.000048]\n",
      "epoch:38 step:181545[D loss: 0.999994] [G loss: 1.000120]\n",
      "epoch:38 step:181550[D loss: 0.999956] [G loss: 1.000188]\n",
      "epoch:38 step:181555[D loss: 1.000004] [G loss: 1.000156]\n",
      "epoch:38 step:181560[D loss: 1.000007] [G loss: 1.000109]\n",
      "epoch:38 step:181565[D loss: 0.999921] [G loss: 1.000153]\n",
      "epoch:38 step:181570[D loss: 0.999912] [G loss: 1.000106]\n",
      "epoch:38 step:181575[D loss: 1.000051] [G loss: 0.999935]\n",
      "epoch:38 step:181580[D loss: 1.000195] [G loss: 0.999829]\n",
      "epoch:38 step:181585[D loss: 0.999975] [G loss: 1.000255]\n",
      "epoch:38 step:181590[D loss: 0.999895] [G loss: 1.000070]\n",
      "epoch:38 step:181595[D loss: 1.000003] [G loss: 0.999830]\n",
      "epoch:38 step:181600[D loss: 1.000089] [G loss: 1.000208]\n",
      "epoch:38 step:181605[D loss: 1.000168] [G loss: 0.999865]\n",
      "epoch:38 step:181610[D loss: 0.999952] [G loss: 1.000079]\n",
      "epoch:38 step:181615[D loss: 1.000039] [G loss: 0.999963]\n",
      "epoch:38 step:181620[D loss: 0.999990] [G loss: 0.999985]\n",
      "epoch:38 step:181625[D loss: 1.000093] [G loss: 0.999911]\n",
      "epoch:38 step:181630[D loss: 1.000010] [G loss: 0.999947]\n",
      "epoch:38 step:181635[D loss: 0.999994] [G loss: 1.000038]\n",
      "epoch:38 step:181640[D loss: 0.999994] [G loss: 1.000147]\n",
      "epoch:38 step:181645[D loss: 1.000093] [G loss: 1.000063]\n",
      "epoch:38 step:181650[D loss: 0.999913] [G loss: 1.000152]\n",
      "epoch:38 step:181655[D loss: 0.999883] [G loss: 1.000222]\n",
      "epoch:38 step:181660[D loss: 0.999918] [G loss: 1.000160]\n",
      "epoch:38 step:181665[D loss: 1.000010] [G loss: 1.000180]\n",
      "epoch:38 step:181670[D loss: 1.000063] [G loss: 0.999957]\n",
      "epoch:38 step:181675[D loss: 0.999973] [G loss: 1.000053]\n",
      "epoch:38 step:181680[D loss: 0.999966] [G loss: 1.000073]\n",
      "epoch:38 step:181685[D loss: 1.000010] [G loss: 0.999999]\n",
      "epoch:38 step:181690[D loss: 0.999973] [G loss: 1.000062]\n",
      "epoch:38 step:181695[D loss: 1.000015] [G loss: 1.000003]\n",
      "epoch:38 step:181700[D loss: 0.999931] [G loss: 1.000061]\n",
      "epoch:38 step:181705[D loss: 1.000007] [G loss: 1.000001]\n",
      "epoch:38 step:181710[D loss: 1.000018] [G loss: 1.000121]\n",
      "epoch:38 step:181715[D loss: 0.999994] [G loss: 1.000083]\n",
      "epoch:38 step:181720[D loss: 0.999951] [G loss: 1.000080]\n",
      "epoch:38 step:181725[D loss: 1.000032] [G loss: 1.000176]\n",
      "epoch:38 step:181730[D loss: 0.999948] [G loss: 1.000147]\n",
      "epoch:38 step:181735[D loss: 0.999945] [G loss: 1.000097]\n",
      "epoch:38 step:181740[D loss: 0.999976] [G loss: 1.000053]\n",
      "epoch:38 step:181745[D loss: 1.000065] [G loss: 1.000086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:181750[D loss: 0.999885] [G loss: 1.000129]\n",
      "epoch:38 step:181755[D loss: 0.999961] [G loss: 1.000121]\n",
      "epoch:38 step:181760[D loss: 0.999979] [G loss: 1.000095]\n",
      "epoch:38 step:181765[D loss: 0.999963] [G loss: 1.000172]\n",
      "epoch:38 step:181770[D loss: 0.999977] [G loss: 1.000109]\n",
      "epoch:38 step:181775[D loss: 0.999948] [G loss: 1.000105]\n",
      "epoch:38 step:181780[D loss: 1.000147] [G loss: 0.999862]\n",
      "epoch:38 step:181785[D loss: 0.999909] [G loss: 1.000110]\n",
      "epoch:38 step:181790[D loss: 0.999942] [G loss: 0.999991]\n",
      "epoch:38 step:181795[D loss: 1.000006] [G loss: 0.999971]\n",
      "epoch:38 step:181800[D loss: 1.000152] [G loss: 1.000130]\n",
      "epoch:38 step:181805[D loss: 1.000058] [G loss: 1.000072]\n",
      "epoch:38 step:181810[D loss: 0.999911] [G loss: 1.000088]\n",
      "epoch:38 step:181815[D loss: 1.000047] [G loss: 1.000043]\n",
      "epoch:38 step:181820[D loss: 0.999981] [G loss: 1.000122]\n",
      "epoch:38 step:181825[D loss: 0.999959] [G loss: 1.000098]\n",
      "epoch:38 step:181830[D loss: 1.000025] [G loss: 1.000047]\n",
      "epoch:38 step:181835[D loss: 1.000047] [G loss: 0.999961]\n",
      "epoch:38 step:181840[D loss: 1.000118] [G loss: 1.000200]\n",
      "epoch:38 step:181845[D loss: 0.999996] [G loss: 0.999962]\n",
      "epoch:38 step:181850[D loss: 0.999988] [G loss: 1.000160]\n",
      "epoch:38 step:181855[D loss: 0.999963] [G loss: 1.000086]\n",
      "epoch:38 step:181860[D loss: 0.999967] [G loss: 1.000023]\n",
      "epoch:38 step:181865[D loss: 0.999994] [G loss: 1.000049]\n",
      "epoch:38 step:181870[D loss: 1.000055] [G loss: 0.999886]\n",
      "epoch:38 step:181875[D loss: 0.999957] [G loss: 0.999995]\n",
      "epoch:38 step:181880[D loss: 1.000033] [G loss: 1.000090]\n",
      "epoch:38 step:181885[D loss: 1.000211] [G loss: 0.999926]\n",
      "epoch:38 step:181890[D loss: 1.000013] [G loss: 1.000029]\n",
      "epoch:38 step:181895[D loss: 0.999918] [G loss: 1.000167]\n",
      "epoch:38 step:181900[D loss: 0.999876] [G loss: 1.000237]\n",
      "epoch:38 step:181905[D loss: 0.999937] [G loss: 1.000096]\n",
      "epoch:38 step:181910[D loss: 1.000022] [G loss: 1.000056]\n",
      "epoch:38 step:181915[D loss: 0.999985] [G loss: 1.000025]\n",
      "epoch:38 step:181920[D loss: 0.999995] [G loss: 0.999999]\n",
      "epoch:38 step:181925[D loss: 1.000147] [G loss: 0.999872]\n",
      "epoch:38 step:181930[D loss: 0.999953] [G loss: 0.999992]\n",
      "epoch:38 step:181935[D loss: 0.999933] [G loss: 1.000064]\n",
      "epoch:38 step:181940[D loss: 0.999971] [G loss: 1.000048]\n",
      "epoch:38 step:181945[D loss: 0.999998] [G loss: 1.000048]\n",
      "epoch:38 step:181950[D loss: 1.000005] [G loss: 1.000054]\n",
      "epoch:38 step:181955[D loss: 0.999972] [G loss: 1.000113]\n",
      "epoch:38 step:181960[D loss: 0.999987] [G loss: 1.000126]\n",
      "epoch:38 step:181965[D loss: 0.999963] [G loss: 1.000093]\n",
      "epoch:38 step:181970[D loss: 0.999948] [G loss: 1.000140]\n",
      "epoch:38 step:181975[D loss: 0.999980] [G loss: 1.000217]\n",
      "epoch:38 step:181980[D loss: 0.999979] [G loss: 1.000070]\n",
      "epoch:38 step:181985[D loss: 1.000013] [G loss: 1.000023]\n",
      "epoch:38 step:181990[D loss: 0.999983] [G loss: 0.999974]\n",
      "epoch:38 step:181995[D loss: 0.999970] [G loss: 1.000074]\n",
      "epoch:38 step:182000[D loss: 0.999996] [G loss: 1.000046]\n",
      "epoch:38 step:182005[D loss: 1.000083] [G loss: 1.000000]\n",
      "epoch:38 step:182010[D loss: 0.999903] [G loss: 1.000021]\n",
      "epoch:38 step:182015[D loss: 0.999926] [G loss: 1.000133]\n",
      "epoch:38 step:182020[D loss: 1.000124] [G loss: 0.999886]\n",
      "epoch:38 step:182025[D loss: 0.999994] [G loss: 1.000078]\n",
      "epoch:38 step:182030[D loss: 0.999931] [G loss: 1.000084]\n",
      "epoch:38 step:182035[D loss: 0.999987] [G loss: 1.000059]\n",
      "epoch:38 step:182040[D loss: 0.999989] [G loss: 0.999988]\n",
      "epoch:38 step:182045[D loss: 0.999996] [G loss: 0.999997]\n",
      "epoch:38 step:182050[D loss: 1.000017] [G loss: 1.000031]\n",
      "epoch:38 step:182055[D loss: 1.000079] [G loss: 0.999979]\n",
      "epoch:38 step:182060[D loss: 0.999837] [G loss: 1.000147]\n",
      "epoch:38 step:182065[D loss: 1.000051] [G loss: 1.000016]\n",
      "epoch:38 step:182070[D loss: 1.000167] [G loss: 1.000070]\n",
      "epoch:38 step:182075[D loss: 0.999943] [G loss: 1.000105]\n",
      "epoch:38 step:182080[D loss: 0.999936] [G loss: 1.000135]\n",
      "epoch:38 step:182085[D loss: 0.999992] [G loss: 1.000106]\n",
      "epoch:38 step:182090[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:38 step:182095[D loss: 0.999987] [G loss: 1.000045]\n",
      "epoch:38 step:182100[D loss: 1.000142] [G loss: 0.999873]\n",
      "epoch:38 step:182105[D loss: 0.999939] [G loss: 0.999908]\n",
      "epoch:38 step:182110[D loss: 0.999964] [G loss: 1.000053]\n",
      "epoch:38 step:182115[D loss: 0.999928] [G loss: 1.000144]\n",
      "epoch:38 step:182120[D loss: 0.999964] [G loss: 1.000074]\n",
      "epoch:38 step:182125[D loss: 0.999984] [G loss: 1.000098]\n",
      "epoch:38 step:182130[D loss: 0.999985] [G loss: 1.000057]\n",
      "epoch:38 step:182135[D loss: 0.999957] [G loss: 1.000118]\n",
      "epoch:38 step:182140[D loss: 0.999994] [G loss: 1.000111]\n",
      "epoch:38 step:182145[D loss: 0.999942] [G loss: 1.000086]\n",
      "epoch:38 step:182150[D loss: 1.000000] [G loss: 1.000012]\n",
      "epoch:38 step:182155[D loss: 0.999993] [G loss: 1.000057]\n",
      "epoch:38 step:182160[D loss: 1.000010] [G loss: 1.000041]\n",
      "epoch:38 step:182165[D loss: 0.999918] [G loss: 1.000156]\n",
      "epoch:38 step:182170[D loss: 0.999958] [G loss: 1.000098]\n",
      "epoch:38 step:182175[D loss: 0.999955] [G loss: 1.000129]\n",
      "epoch:38 step:182180[D loss: 1.000102] [G loss: 0.999970]\n",
      "epoch:38 step:182185[D loss: 0.999991] [G loss: 1.000083]\n",
      "epoch:38 step:182190[D loss: 1.000045] [G loss: 1.000045]\n",
      "epoch:38 step:182195[D loss: 0.999873] [G loss: 1.000201]\n",
      "epoch:38 step:182200[D loss: 0.999979] [G loss: 1.000160]\n",
      "epoch:38 step:182205[D loss: 0.999858] [G loss: 1.000217]\n",
      "epoch:38 step:182210[D loss: 1.000031] [G loss: 0.999964]\n",
      "epoch:38 step:182215[D loss: 0.999989] [G loss: 1.000016]\n",
      "epoch:38 step:182220[D loss: 0.999970] [G loss: 1.000061]\n",
      "epoch:38 step:182225[D loss: 0.999994] [G loss: 1.000118]\n",
      "epoch:38 step:182230[D loss: 0.999978] [G loss: 1.000108]\n",
      "epoch:38 step:182235[D loss: 0.999984] [G loss: 1.000032]\n",
      "epoch:38 step:182240[D loss: 0.999973] [G loss: 1.000060]\n",
      "epoch:38 step:182245[D loss: 0.999957] [G loss: 1.000047]\n",
      "epoch:38 step:182250[D loss: 1.000033] [G loss: 1.000123]\n",
      "epoch:38 step:182255[D loss: 0.999924] [G loss: 1.000134]\n",
      "epoch:38 step:182260[D loss: 0.999903] [G loss: 1.000147]\n",
      "epoch:38 step:182265[D loss: 0.999973] [G loss: 1.000098]\n",
      "epoch:38 step:182270[D loss: 0.999979] [G loss: 1.000088]\n",
      "epoch:38 step:182275[D loss: 1.000059] [G loss: 0.999966]\n",
      "epoch:38 step:182280[D loss: 0.999959] [G loss: 1.000094]\n",
      "epoch:38 step:182285[D loss: 0.999973] [G loss: 1.000071]\n",
      "epoch:38 step:182290[D loss: 0.999970] [G loss: 1.000069]\n",
      "epoch:38 step:182295[D loss: 1.000008] [G loss: 1.000070]\n",
      "epoch:38 step:182300[D loss: 1.000034] [G loss: 0.999916]\n",
      "epoch:38 step:182305[D loss: 0.999965] [G loss: 1.000031]\n",
      "epoch:38 step:182310[D loss: 1.000180] [G loss: 0.999861]\n",
      "epoch:38 step:182315[D loss: 1.000064] [G loss: 0.999908]\n",
      "epoch:38 step:182320[D loss: 0.999933] [G loss: 1.000145]\n",
      "epoch:38 step:182325[D loss: 1.000001] [G loss: 1.000151]\n",
      "epoch:38 step:182330[D loss: 0.999955] [G loss: 1.000042]\n",
      "epoch:38 step:182335[D loss: 0.999991] [G loss: 1.000017]\n",
      "epoch:38 step:182340[D loss: 1.000014] [G loss: 1.000029]\n",
      "epoch:38 step:182345[D loss: 1.000061] [G loss: 0.999979]\n",
      "epoch:38 step:182350[D loss: 0.999967] [G loss: 1.000157]\n",
      "epoch:38 step:182355[D loss: 1.000009] [G loss: 1.000032]\n",
      "epoch:38 step:182360[D loss: 0.999949] [G loss: 1.000118]\n",
      "epoch:38 step:182365[D loss: 0.999970] [G loss: 1.000182]\n",
      "epoch:38 step:182370[D loss: 0.999974] [G loss: 1.000081]\n",
      "epoch:38 step:182375[D loss: 0.999949] [G loss: 1.000106]\n",
      "epoch:38 step:182380[D loss: 1.000010] [G loss: 1.000151]\n",
      "epoch:38 step:182385[D loss: 0.999982] [G loss: 1.000001]\n",
      "epoch:38 step:182390[D loss: 1.000069] [G loss: 1.000004]\n",
      "epoch:38 step:182395[D loss: 0.999940] [G loss: 1.000086]\n",
      "epoch:38 step:182400[D loss: 0.999994] [G loss: 1.000037]\n",
      "epoch:38 step:182405[D loss: 0.999975] [G loss: 1.000035]\n",
      "epoch:38 step:182410[D loss: 1.000054] [G loss: 0.999929]\n",
      "epoch:38 step:182415[D loss: 0.999961] [G loss: 1.000063]\n",
      "epoch:38 step:182420[D loss: 1.000006] [G loss: 1.000051]\n",
      "epoch:38 step:182425[D loss: 0.999996] [G loss: 1.000073]\n",
      "epoch:38 step:182430[D loss: 0.999986] [G loss: 1.000084]\n",
      "epoch:38 step:182435[D loss: 0.999975] [G loss: 1.000073]\n",
      "epoch:38 step:182440[D loss: 1.000028] [G loss: 1.000003]\n",
      "epoch:38 step:182445[D loss: 0.999922] [G loss: 1.000113]\n",
      "epoch:38 step:182450[D loss: 0.999979] [G loss: 1.000050]\n",
      "epoch:38 step:182455[D loss: 1.000074] [G loss: 1.000027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:182460[D loss: 1.000053] [G loss: 0.999985]\n",
      "epoch:38 step:182465[D loss: 0.999899] [G loss: 1.000134]\n",
      "epoch:38 step:182470[D loss: 0.999984] [G loss: 1.000047]\n",
      "epoch:38 step:182475[D loss: 0.999949] [G loss: 1.000069]\n",
      "epoch:38 step:182480[D loss: 1.000009] [G loss: 1.000050]\n",
      "epoch:38 step:182485[D loss: 1.000077] [G loss: 1.000017]\n",
      "epoch:38 step:182490[D loss: 0.999955] [G loss: 1.000056]\n",
      "epoch:38 step:182495[D loss: 1.000002] [G loss: 1.000049]\n",
      "epoch:38 step:182500[D loss: 0.999955] [G loss: 1.000058]\n",
      "epoch:38 step:182505[D loss: 0.999948] [G loss: 1.000061]\n",
      "epoch:38 step:182510[D loss: 1.000002] [G loss: 1.000101]\n",
      "epoch:38 step:182515[D loss: 0.999963] [G loss: 1.000111]\n",
      "epoch:38 step:182520[D loss: 0.999943] [G loss: 1.000131]\n",
      "epoch:38 step:182525[D loss: 1.000016] [G loss: 1.000074]\n",
      "epoch:38 step:182530[D loss: 0.999904] [G loss: 1.000113]\n",
      "epoch:38 step:182535[D loss: 1.000105] [G loss: 0.999950]\n",
      "epoch:38 step:182540[D loss: 0.999949] [G loss: 1.000070]\n",
      "epoch:38 step:182545[D loss: 0.999961] [G loss: 1.000080]\n",
      "epoch:38 step:182550[D loss: 0.999953] [G loss: 1.000156]\n",
      "epoch:38 step:182555[D loss: 0.999978] [G loss: 1.000083]\n",
      "epoch:38 step:182560[D loss: 1.000014] [G loss: 1.000076]\n",
      "epoch:38 step:182565[D loss: 1.000017] [G loss: 0.999989]\n",
      "epoch:38 step:182570[D loss: 1.000115] [G loss: 0.999950]\n",
      "epoch:38 step:182575[D loss: 0.999960] [G loss: 1.000078]\n",
      "epoch:38 step:182580[D loss: 0.999939] [G loss: 1.000078]\n",
      "epoch:38 step:182585[D loss: 0.999971] [G loss: 1.000070]\n",
      "epoch:38 step:182590[D loss: 0.999980] [G loss: 1.000048]\n",
      "epoch:38 step:182595[D loss: 0.999971] [G loss: 1.000067]\n",
      "epoch:38 step:182600[D loss: 0.999961] [G loss: 1.000059]\n",
      "epoch:38 step:182605[D loss: 0.999987] [G loss: 1.000017]\n",
      "epoch:38 step:182610[D loss: 1.000046] [G loss: 0.999857]\n",
      "epoch:38 step:182615[D loss: 0.999956] [G loss: 1.000146]\n",
      "epoch:38 step:182620[D loss: 0.999949] [G loss: 1.000098]\n",
      "epoch:38 step:182625[D loss: 0.999987] [G loss: 1.000039]\n",
      "epoch:38 step:182630[D loss: 1.000015] [G loss: 1.000005]\n",
      "epoch:38 step:182635[D loss: 0.999972] [G loss: 1.000002]\n",
      "epoch:38 step:182640[D loss: 1.000021] [G loss: 1.000025]\n",
      "epoch:38 step:182645[D loss: 0.999987] [G loss: 1.000082]\n",
      "epoch:38 step:182650[D loss: 0.999988] [G loss: 1.000012]\n",
      "epoch:38 step:182655[D loss: 0.999927] [G loss: 1.000089]\n",
      "epoch:38 step:182660[D loss: 0.999927] [G loss: 1.000067]\n",
      "epoch:38 step:182665[D loss: 0.999960] [G loss: 1.000067]\n",
      "epoch:38 step:182670[D loss: 1.000009] [G loss: 1.000099]\n",
      "epoch:38 step:182675[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:38 step:182680[D loss: 0.999970] [G loss: 1.000099]\n",
      "epoch:38 step:182685[D loss: 0.999978] [G loss: 1.000067]\n",
      "epoch:38 step:182690[D loss: 0.999980] [G loss: 1.000063]\n",
      "epoch:38 step:182695[D loss: 0.999991] [G loss: 1.000030]\n",
      "epoch:38 step:182700[D loss: 0.999987] [G loss: 1.000052]\n",
      "epoch:38 step:182705[D loss: 1.000008] [G loss: 1.000091]\n",
      "epoch:38 step:182710[D loss: 0.999971] [G loss: 1.000081]\n",
      "epoch:38 step:182715[D loss: 1.000018] [G loss: 1.000000]\n",
      "epoch:39 step:182720[D loss: 0.999968] [G loss: 1.000105]\n",
      "epoch:39 step:182725[D loss: 1.000001] [G loss: 1.000035]\n",
      "epoch:39 step:182730[D loss: 0.999947] [G loss: 1.000011]\n",
      "epoch:39 step:182735[D loss: 1.000003] [G loss: 1.000044]\n",
      "epoch:39 step:182740[D loss: 0.999937] [G loss: 1.000082]\n",
      "epoch:39 step:182745[D loss: 0.999971] [G loss: 1.000091]\n",
      "epoch:39 step:182750[D loss: 1.000006] [G loss: 0.999993]\n",
      "epoch:39 step:182755[D loss: 0.999941] [G loss: 1.000075]\n",
      "epoch:39 step:182760[D loss: 1.000039] [G loss: 1.000019]\n",
      "epoch:39 step:182765[D loss: 1.000108] [G loss: 0.999869]\n",
      "epoch:39 step:182770[D loss: 1.000098] [G loss: 0.999948]\n",
      "epoch:39 step:182775[D loss: 0.999916] [G loss: 1.000113]\n",
      "epoch:39 step:182780[D loss: 0.999995] [G loss: 1.000062]\n",
      "epoch:39 step:182785[D loss: 0.999964] [G loss: 1.000072]\n",
      "epoch:39 step:182790[D loss: 0.999976] [G loss: 1.000071]\n",
      "epoch:39 step:182795[D loss: 0.999975] [G loss: 1.000074]\n",
      "epoch:39 step:182800[D loss: 0.999974] [G loss: 1.000085]\n",
      "epoch:39 step:182805[D loss: 1.000012] [G loss: 1.000039]\n",
      "epoch:39 step:182810[D loss: 0.999937] [G loss: 1.000134]\n",
      "epoch:39 step:182815[D loss: 0.999925] [G loss: 1.000099]\n",
      "epoch:39 step:182820[D loss: 1.000012] [G loss: 1.000056]\n",
      "epoch:39 step:182825[D loss: 1.000026] [G loss: 1.000114]\n",
      "epoch:39 step:182830[D loss: 0.999974] [G loss: 1.000055]\n",
      "epoch:39 step:182835[D loss: 0.999998] [G loss: 1.000077]\n",
      "epoch:39 step:182840[D loss: 0.999966] [G loss: 1.000071]\n",
      "epoch:39 step:182845[D loss: 0.999966] [G loss: 1.000123]\n",
      "epoch:39 step:182850[D loss: 0.999989] [G loss: 1.000148]\n",
      "epoch:39 step:182855[D loss: 0.999949] [G loss: 1.000096]\n",
      "epoch:39 step:182860[D loss: 1.000010] [G loss: 1.000055]\n",
      "epoch:39 step:182865[D loss: 0.999981] [G loss: 1.000076]\n",
      "epoch:39 step:182870[D loss: 0.999971] [G loss: 1.000022]\n",
      "epoch:39 step:182875[D loss: 0.999948] [G loss: 1.000073]\n",
      "epoch:39 step:182880[D loss: 0.999963] [G loss: 1.000070]\n",
      "epoch:39 step:182885[D loss: 1.000015] [G loss: 1.000000]\n",
      "epoch:39 step:182890[D loss: 0.999947] [G loss: 1.000152]\n",
      "epoch:39 step:182895[D loss: 1.000016] [G loss: 1.000195]\n",
      "epoch:39 step:182900[D loss: 0.999977] [G loss: 1.000156]\n",
      "epoch:39 step:182905[D loss: 0.999926] [G loss: 1.000121]\n",
      "epoch:39 step:182910[D loss: 0.999982] [G loss: 1.000057]\n",
      "epoch:39 step:182915[D loss: 1.000046] [G loss: 1.000083]\n",
      "epoch:39 step:182920[D loss: 0.999979] [G loss: 0.999949]\n",
      "epoch:39 step:182925[D loss: 0.999965] [G loss: 1.000001]\n",
      "epoch:39 step:182930[D loss: 0.999907] [G loss: 1.000168]\n",
      "epoch:39 step:182935[D loss: 0.999956] [G loss: 1.000087]\n",
      "epoch:39 step:182940[D loss: 0.999976] [G loss: 1.000067]\n",
      "epoch:39 step:182945[D loss: 0.999964] [G loss: 1.000075]\n",
      "epoch:39 step:182950[D loss: 0.999983] [G loss: 1.000072]\n",
      "epoch:39 step:182955[D loss: 0.999954] [G loss: 1.000117]\n",
      "epoch:39 step:182960[D loss: 0.999967] [G loss: 1.000090]\n",
      "epoch:39 step:182965[D loss: 0.999995] [G loss: 1.000063]\n",
      "epoch:39 step:182970[D loss: 0.999980] [G loss: 1.000032]\n",
      "epoch:39 step:182975[D loss: 0.999956] [G loss: 1.000090]\n",
      "epoch:39 step:182980[D loss: 1.000026] [G loss: 1.000102]\n",
      "epoch:39 step:182985[D loss: 1.000013] [G loss: 1.000116]\n",
      "epoch:39 step:182990[D loss: 0.999949] [G loss: 1.000131]\n",
      "epoch:39 step:182995[D loss: 0.999988] [G loss: 1.000058]\n",
      "epoch:39 step:183000[D loss: 0.999983] [G loss: 1.000073]\n",
      "epoch:39 step:183005[D loss: 0.999962] [G loss: 1.000088]\n",
      "epoch:39 step:183010[D loss: 1.000014] [G loss: 1.000063]\n",
      "epoch:39 step:183015[D loss: 0.999986] [G loss: 1.000056]\n",
      "epoch:39 step:183020[D loss: 0.999973] [G loss: 1.000094]\n",
      "epoch:39 step:183025[D loss: 0.999953] [G loss: 1.000140]\n",
      "epoch:39 step:183030[D loss: 0.999992] [G loss: 1.000075]\n",
      "epoch:39 step:183035[D loss: 0.999963] [G loss: 1.000106]\n",
      "epoch:39 step:183040[D loss: 0.999971] [G loss: 1.000082]\n",
      "epoch:39 step:183045[D loss: 1.000039] [G loss: 1.000028]\n",
      "epoch:39 step:183050[D loss: 0.999964] [G loss: 1.000054]\n",
      "epoch:39 step:183055[D loss: 0.999979] [G loss: 1.000052]\n",
      "epoch:39 step:183060[D loss: 1.000153] [G loss: 0.999915]\n",
      "epoch:39 step:183065[D loss: 0.999997] [G loss: 1.000026]\n",
      "epoch:39 step:183070[D loss: 1.000053] [G loss: 0.999945]\n",
      "epoch:39 step:183075[D loss: 1.000067] [G loss: 1.000037]\n",
      "epoch:39 step:183080[D loss: 0.999963] [G loss: 1.000085]\n",
      "epoch:39 step:183085[D loss: 1.000085] [G loss: 0.999981]\n",
      "epoch:39 step:183090[D loss: 1.000110] [G loss: 1.000022]\n",
      "epoch:39 step:183095[D loss: 0.999974] [G loss: 1.000223]\n",
      "epoch:39 step:183100[D loss: 1.000029] [G loss: 1.000041]\n",
      "epoch:39 step:183105[D loss: 0.999994] [G loss: 1.000145]\n",
      "epoch:39 step:183110[D loss: 1.000021] [G loss: 1.000128]\n",
      "epoch:39 step:183115[D loss: 0.999992] [G loss: 1.000059]\n",
      "epoch:39 step:183120[D loss: 0.999957] [G loss: 1.000212]\n",
      "epoch:39 step:183125[D loss: 1.000037] [G loss: 0.999940]\n",
      "epoch:39 step:183130[D loss: 0.999974] [G loss: 0.999997]\n",
      "epoch:39 step:183135[D loss: 0.999997] [G loss: 1.000045]\n",
      "epoch:39 step:183140[D loss: 1.000074] [G loss: 0.999882]\n",
      "epoch:39 step:183145[D loss: 0.999992] [G loss: 0.999980]\n",
      "epoch:39 step:183150[D loss: 0.999950] [G loss: 1.000059]\n",
      "epoch:39 step:183155[D loss: 0.999981] [G loss: 1.000140]\n",
      "epoch:39 step:183160[D loss: 1.000053] [G loss: 1.000146]\n",
      "epoch:39 step:183165[D loss: 0.999900] [G loss: 1.000233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:183170[D loss: 0.999989] [G loss: 1.000061]\n",
      "epoch:39 step:183175[D loss: 0.999978] [G loss: 1.000070]\n",
      "epoch:39 step:183180[D loss: 1.000034] [G loss: 1.000089]\n",
      "epoch:39 step:183185[D loss: 1.000099] [G loss: 0.999888]\n",
      "epoch:39 step:183190[D loss: 1.000004] [G loss: 1.000081]\n",
      "epoch:39 step:183195[D loss: 1.000086] [G loss: 0.999964]\n",
      "epoch:39 step:183200[D loss: 1.000013] [G loss: 1.000051]\n",
      "epoch:39 step:183205[D loss: 0.999936] [G loss: 1.000160]\n",
      "epoch:39 step:183210[D loss: 0.999995] [G loss: 1.000124]\n",
      "epoch:39 step:183215[D loss: 0.999923] [G loss: 1.000175]\n",
      "epoch:39 step:183220[D loss: 0.999969] [G loss: 1.000010]\n",
      "epoch:39 step:183225[D loss: 0.999938] [G loss: 1.000103]\n",
      "epoch:39 step:183230[D loss: 1.000037] [G loss: 0.999883]\n",
      "epoch:39 step:183235[D loss: 1.000053] [G loss: 0.999861]\n",
      "epoch:39 step:183240[D loss: 1.000050] [G loss: 0.999939]\n",
      "epoch:39 step:183245[D loss: 1.000145] [G loss: 0.999761]\n",
      "epoch:39 step:183250[D loss: 1.000136] [G loss: 0.999884]\n",
      "epoch:39 step:183255[D loss: 1.000028] [G loss: 0.999912]\n",
      "epoch:39 step:183260[D loss: 0.999806] [G loss: 1.000226]\n",
      "epoch:39 step:183265[D loss: 0.999983] [G loss: 1.000211]\n",
      "epoch:39 step:183270[D loss: 0.999923] [G loss: 1.000152]\n",
      "epoch:39 step:183275[D loss: 0.999977] [G loss: 1.000091]\n",
      "epoch:39 step:183280[D loss: 1.000040] [G loss: 1.000015]\n",
      "epoch:39 step:183285[D loss: 0.999969] [G loss: 1.000084]\n",
      "epoch:39 step:183290[D loss: 1.000015] [G loss: 1.000059]\n",
      "epoch:39 step:183295[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:39 step:183300[D loss: 1.000065] [G loss: 0.999967]\n",
      "epoch:39 step:183305[D loss: 1.000328] [G loss: 0.999860]\n",
      "epoch:39 step:183310[D loss: 1.000205] [G loss: 0.999960]\n",
      "epoch:39 step:183315[D loss: 1.000012] [G loss: 0.999995]\n",
      "epoch:39 step:183320[D loss: 0.999950] [G loss: 1.000222]\n",
      "epoch:39 step:183325[D loss: 0.999854] [G loss: 1.000302]\n",
      "epoch:39 step:183330[D loss: 0.999935] [G loss: 1.000178]\n",
      "epoch:39 step:183335[D loss: 0.999965] [G loss: 1.000118]\n",
      "epoch:39 step:183340[D loss: 1.000029] [G loss: 0.999999]\n",
      "epoch:39 step:183345[D loss: 0.999930] [G loss: 1.000046]\n",
      "epoch:39 step:183350[D loss: 1.000001] [G loss: 0.999939]\n",
      "epoch:39 step:183355[D loss: 1.000139] [G loss: 0.999769]\n",
      "epoch:39 step:183360[D loss: 1.000167] [G loss: 0.999800]\n",
      "epoch:39 step:183365[D loss: 0.999898] [G loss: 1.000038]\n",
      "epoch:39 step:183370[D loss: 0.999945] [G loss: 1.000161]\n",
      "epoch:39 step:183375[D loss: 1.000064] [G loss: 0.999986]\n",
      "epoch:39 step:183380[D loss: 1.000056] [G loss: 0.999967]\n",
      "epoch:39 step:183385[D loss: 0.999916] [G loss: 1.000136]\n",
      "epoch:39 step:183390[D loss: 0.999924] [G loss: 1.000166]\n",
      "epoch:39 step:183395[D loss: 0.999992] [G loss: 1.000004]\n",
      "epoch:39 step:183400[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:39 step:183405[D loss: 1.000003] [G loss: 0.999943]\n",
      "epoch:39 step:183410[D loss: 0.999945] [G loss: 1.000115]\n",
      "epoch:39 step:183415[D loss: 1.000015] [G loss: 1.000010]\n",
      "epoch:39 step:183420[D loss: 0.999956] [G loss: 1.000102]\n",
      "epoch:39 step:183425[D loss: 1.000042] [G loss: 1.000000]\n",
      "epoch:39 step:183430[D loss: 0.999964] [G loss: 1.000134]\n",
      "epoch:39 step:183435[D loss: 1.000008] [G loss: 1.000167]\n",
      "epoch:39 step:183440[D loss: 1.000034] [G loss: 1.000076]\n",
      "epoch:39 step:183445[D loss: 0.999987] [G loss: 1.000058]\n",
      "epoch:39 step:183450[D loss: 1.000067] [G loss: 1.000195]\n",
      "epoch:39 step:183455[D loss: 0.999869] [G loss: 1.000173]\n",
      "epoch:39 step:183460[D loss: 0.999994] [G loss: 0.999999]\n",
      "epoch:39 step:183465[D loss: 1.000053] [G loss: 0.999857]\n",
      "epoch:39 step:183470[D loss: 0.999893] [G loss: 1.000007]\n",
      "epoch:39 step:183475[D loss: 0.999969] [G loss: 1.000048]\n",
      "epoch:39 step:183480[D loss: 0.999987] [G loss: 1.000004]\n",
      "epoch:39 step:183485[D loss: 0.999949] [G loss: 1.000100]\n",
      "epoch:39 step:183490[D loss: 0.999983] [G loss: 1.000074]\n",
      "epoch:39 step:183495[D loss: 1.000039] [G loss: 1.000085]\n",
      "epoch:39 step:183500[D loss: 0.999999] [G loss: 1.000082]\n",
      "epoch:39 step:183505[D loss: 0.999959] [G loss: 1.000119]\n",
      "epoch:39 step:183510[D loss: 1.000006] [G loss: 0.999974]\n",
      "epoch:39 step:183515[D loss: 0.999991] [G loss: 1.000053]\n",
      "epoch:39 step:183520[D loss: 1.000006] [G loss: 1.000031]\n",
      "epoch:39 step:183525[D loss: 1.000023] [G loss: 1.000080]\n",
      "epoch:39 step:183530[D loss: 0.999942] [G loss: 1.000113]\n",
      "epoch:39 step:183535[D loss: 0.999916] [G loss: 1.000113]\n",
      "epoch:39 step:183540[D loss: 1.000013] [G loss: 1.000083]\n",
      "epoch:39 step:183545[D loss: 0.999936] [G loss: 1.000069]\n",
      "epoch:39 step:183550[D loss: 0.999968] [G loss: 1.000041]\n",
      "epoch:39 step:183555[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:39 step:183560[D loss: 0.999986] [G loss: 1.000068]\n",
      "epoch:39 step:183565[D loss: 0.999984] [G loss: 1.000044]\n",
      "epoch:39 step:183570[D loss: 0.999927] [G loss: 1.000118]\n",
      "epoch:39 step:183575[D loss: 1.000019] [G loss: 1.000032]\n",
      "epoch:39 step:183580[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:39 step:183585[D loss: 0.999998] [G loss: 1.000061]\n",
      "epoch:39 step:183590[D loss: 0.999933] [G loss: 1.000112]\n",
      "epoch:39 step:183595[D loss: 0.999996] [G loss: 1.000024]\n",
      "epoch:39 step:183600[D loss: 0.999958] [G loss: 1.000136]\n",
      "epoch:39 step:183605[D loss: 0.999925] [G loss: 1.000154]\n",
      "epoch:39 step:183610[D loss: 1.000006] [G loss: 1.000067]\n",
      "epoch:39 step:183615[D loss: 0.999975] [G loss: 1.000065]\n",
      "epoch:39 step:183620[D loss: 0.999969] [G loss: 1.000114]\n",
      "epoch:39 step:183625[D loss: 0.999996] [G loss: 1.000053]\n",
      "epoch:39 step:183630[D loss: 0.999990] [G loss: 1.000069]\n",
      "epoch:39 step:183635[D loss: 0.999995] [G loss: 1.000003]\n",
      "epoch:39 step:183640[D loss: 1.000090] [G loss: 0.999890]\n",
      "epoch:39 step:183645[D loss: 0.999915] [G loss: 1.000035]\n",
      "epoch:39 step:183650[D loss: 1.000033] [G loss: 0.999984]\n",
      "epoch:39 step:183655[D loss: 1.000064] [G loss: 1.000066]\n",
      "epoch:39 step:183660[D loss: 0.999926] [G loss: 1.000103]\n",
      "epoch:39 step:183665[D loss: 0.999947] [G loss: 1.000150]\n",
      "epoch:39 step:183670[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:39 step:183675[D loss: 0.999962] [G loss: 1.000067]\n",
      "epoch:39 step:183680[D loss: 0.999970] [G loss: 1.000126]\n",
      "epoch:39 step:183685[D loss: 1.000053] [G loss: 1.000027]\n",
      "epoch:39 step:183690[D loss: 1.000042] [G loss: 0.999926]\n",
      "epoch:39 step:183695[D loss: 0.999966] [G loss: 1.000068]\n",
      "epoch:39 step:183700[D loss: 1.000109] [G loss: 1.000117]\n",
      "epoch:39 step:183705[D loss: 1.000051] [G loss: 1.000148]\n",
      "epoch:39 step:183710[D loss: 0.999935] [G loss: 1.000304]\n",
      "epoch:39 step:183715[D loss: 1.000036] [G loss: 1.000235]\n",
      "epoch:39 step:183720[D loss: 0.999894] [G loss: 1.000388]\n",
      "epoch:39 step:183725[D loss: 0.999886] [G loss: 1.000253]\n",
      "epoch:39 step:183730[D loss: 0.999974] [G loss: 1.000142]\n",
      "epoch:39 step:183735[D loss: 0.999983] [G loss: 1.000099]\n",
      "epoch:39 step:183740[D loss: 0.999989] [G loss: 1.000028]\n",
      "epoch:39 step:183745[D loss: 1.000021] [G loss: 0.999942]\n",
      "epoch:39 step:183750[D loss: 0.999968] [G loss: 0.999937]\n",
      "epoch:39 step:183755[D loss: 0.999923] [G loss: 0.999964]\n",
      "epoch:39 step:183760[D loss: 1.000112] [G loss: 0.999970]\n",
      "epoch:39 step:183765[D loss: 0.999941] [G loss: 1.000082]\n",
      "epoch:39 step:183770[D loss: 0.999959] [G loss: 1.000121]\n",
      "epoch:39 step:183775[D loss: 1.000080] [G loss: 1.000014]\n",
      "epoch:39 step:183780[D loss: 0.999870] [G loss: 1.000207]\n",
      "epoch:39 step:183785[D loss: 0.999923] [G loss: 1.000201]\n",
      "epoch:39 step:183790[D loss: 1.000003] [G loss: 1.000065]\n",
      "epoch:39 step:183795[D loss: 0.999837] [G loss: 1.000357]\n",
      "epoch:39 step:183800[D loss: 1.000337] [G loss: 0.999956]\n",
      "epoch:39 step:183805[D loss: 0.999859] [G loss: 1.000307]\n",
      "epoch:39 step:183810[D loss: 0.999914] [G loss: 1.000194]\n",
      "epoch:39 step:183815[D loss: 0.999964] [G loss: 1.000174]\n",
      "epoch:39 step:183820[D loss: 0.999987] [G loss: 1.000044]\n",
      "epoch:39 step:183825[D loss: 0.999999] [G loss: 1.000044]\n",
      "epoch:39 step:183830[D loss: 1.000121] [G loss: 0.999832]\n",
      "epoch:39 step:183835[D loss: 0.999913] [G loss: 0.999985]\n",
      "epoch:39 step:183840[D loss: 1.000107] [G loss: 0.999894]\n",
      "epoch:39 step:183845[D loss: 1.000166] [G loss: 0.999929]\n",
      "epoch:39 step:183850[D loss: 1.000428] [G loss: 0.999799]\n",
      "epoch:39 step:183855[D loss: 0.999895] [G loss: 1.000159]\n",
      "epoch:39 step:183860[D loss: 0.999975] [G loss: 1.000024]\n",
      "epoch:39 step:183865[D loss: 1.000067] [G loss: 1.000138]\n",
      "epoch:39 step:183870[D loss: 0.999904] [G loss: 1.000285]\n",
      "epoch:39 step:183875[D loss: 0.999847] [G loss: 1.000330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:183880[D loss: 0.999895] [G loss: 1.000304]\n",
      "epoch:39 step:183885[D loss: 0.999918] [G loss: 1.000315]\n",
      "epoch:39 step:183890[D loss: 0.999946] [G loss: 1.000291]\n",
      "epoch:39 step:183895[D loss: 0.999940] [G loss: 1.000145]\n",
      "epoch:39 step:183900[D loss: 1.000029] [G loss: 1.000015]\n",
      "epoch:39 step:183905[D loss: 1.000080] [G loss: 0.999905]\n",
      "epoch:39 step:183910[D loss: 0.999993] [G loss: 0.999994]\n",
      "epoch:39 step:183915[D loss: 1.000123] [G loss: 1.000037]\n",
      "epoch:39 step:183920[D loss: 1.000142] [G loss: 0.999967]\n",
      "epoch:39 step:183925[D loss: 0.999976] [G loss: 0.999960]\n",
      "epoch:39 step:183930[D loss: 0.999929] [G loss: 1.000143]\n",
      "epoch:39 step:183935[D loss: 0.999995] [G loss: 1.000231]\n",
      "epoch:39 step:183940[D loss: 1.000018] [G loss: 1.000037]\n",
      "epoch:39 step:183945[D loss: 0.999919] [G loss: 1.000177]\n",
      "epoch:39 step:183950[D loss: 0.999965] [G loss: 1.000077]\n",
      "epoch:39 step:183955[D loss: 0.999984] [G loss: 1.000129]\n",
      "epoch:39 step:183960[D loss: 0.999914] [G loss: 1.000129]\n",
      "epoch:39 step:183965[D loss: 0.999999] [G loss: 1.000062]\n",
      "epoch:39 step:183970[D loss: 0.999967] [G loss: 1.000064]\n",
      "epoch:39 step:183975[D loss: 0.999903] [G loss: 1.000124]\n",
      "epoch:39 step:183980[D loss: 1.000051] [G loss: 1.000053]\n",
      "epoch:39 step:183985[D loss: 0.999982] [G loss: 1.000196]\n",
      "epoch:39 step:183990[D loss: 0.999967] [G loss: 1.000130]\n",
      "epoch:39 step:183995[D loss: 0.999957] [G loss: 1.000137]\n",
      "epoch:39 step:184000[D loss: 0.999980] [G loss: 1.000108]\n",
      "epoch:39 step:184005[D loss: 0.999999] [G loss: 1.000173]\n",
      "epoch:39 step:184010[D loss: 0.999928] [G loss: 1.000168]\n",
      "epoch:39 step:184015[D loss: 1.000016] [G loss: 1.000040]\n",
      "epoch:39 step:184020[D loss: 0.999966] [G loss: 1.000067]\n",
      "epoch:39 step:184025[D loss: 0.999965] [G loss: 1.000092]\n",
      "epoch:39 step:184030[D loss: 1.000055] [G loss: 0.999970]\n",
      "epoch:39 step:184035[D loss: 0.999891] [G loss: 1.000106]\n",
      "epoch:39 step:184040[D loss: 0.999906] [G loss: 1.000111]\n",
      "epoch:39 step:184045[D loss: 1.000019] [G loss: 1.000078]\n",
      "epoch:39 step:184050[D loss: 0.999925] [G loss: 1.000167]\n",
      "epoch:39 step:184055[D loss: 0.999984] [G loss: 1.000049]\n",
      "epoch:39 step:184060[D loss: 0.999959] [G loss: 1.000091]\n",
      "epoch:39 step:184065[D loss: 0.999993] [G loss: 1.000071]\n",
      "epoch:39 step:184070[D loss: 0.999977] [G loss: 1.000016]\n",
      "epoch:39 step:184075[D loss: 0.999984] [G loss: 1.000078]\n",
      "epoch:39 step:184080[D loss: 0.999967] [G loss: 1.000079]\n",
      "epoch:39 step:184085[D loss: 0.999965] [G loss: 1.000109]\n",
      "epoch:39 step:184090[D loss: 1.000034] [G loss: 1.000013]\n",
      "epoch:39 step:184095[D loss: 1.000013] [G loss: 1.000091]\n",
      "epoch:39 step:184100[D loss: 0.999949] [G loss: 1.000120]\n",
      "epoch:39 step:184105[D loss: 1.000043] [G loss: 1.000050]\n",
      "epoch:39 step:184110[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:39 step:184115[D loss: 0.999887] [G loss: 1.000196]\n",
      "epoch:39 step:184120[D loss: 0.999984] [G loss: 0.999991]\n",
      "epoch:39 step:184125[D loss: 1.000030] [G loss: 0.999953]\n",
      "epoch:39 step:184130[D loss: 0.999887] [G loss: 1.000117]\n",
      "epoch:39 step:184135[D loss: 1.000021] [G loss: 1.000013]\n",
      "epoch:39 step:184140[D loss: 1.000108] [G loss: 0.999835]\n",
      "epoch:39 step:184145[D loss: 0.999932] [G loss: 1.000031]\n",
      "epoch:39 step:184150[D loss: 0.999995] [G loss: 1.000051]\n",
      "epoch:39 step:184155[D loss: 0.999985] [G loss: 1.000065]\n",
      "epoch:39 step:184160[D loss: 0.999948] [G loss: 1.000094]\n",
      "epoch:39 step:184165[D loss: 1.000000] [G loss: 1.000085]\n",
      "epoch:39 step:184170[D loss: 0.999973] [G loss: 1.000115]\n",
      "epoch:39 step:184175[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:39 step:184180[D loss: 1.000011] [G loss: 1.000045]\n",
      "epoch:39 step:184185[D loss: 0.999968] [G loss: 1.000092]\n",
      "epoch:39 step:184190[D loss: 1.000004] [G loss: 1.000065]\n",
      "epoch:39 step:184195[D loss: 0.999952] [G loss: 1.000111]\n",
      "epoch:39 step:184200[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:39 step:184205[D loss: 1.000002] [G loss: 1.000044]\n",
      "epoch:39 step:184210[D loss: 0.999964] [G loss: 1.000071]\n",
      "epoch:39 step:184215[D loss: 1.000010] [G loss: 1.000022]\n",
      "epoch:39 step:184220[D loss: 0.999920] [G loss: 1.000132]\n",
      "epoch:39 step:184225[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:39 step:184230[D loss: 0.999950] [G loss: 1.000157]\n",
      "epoch:39 step:184235[D loss: 0.999985] [G loss: 1.000050]\n",
      "epoch:39 step:184240[D loss: 0.999994] [G loss: 1.000008]\n",
      "epoch:39 step:184245[D loss: 0.999979] [G loss: 1.000023]\n",
      "epoch:39 step:184250[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:39 step:184255[D loss: 0.999973] [G loss: 1.000064]\n",
      "epoch:39 step:184260[D loss: 0.999982] [G loss: 1.000045]\n",
      "epoch:39 step:184265[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:39 step:184270[D loss: 0.999988] [G loss: 1.000054]\n",
      "epoch:39 step:184275[D loss: 0.999965] [G loss: 1.000018]\n",
      "epoch:39 step:184280[D loss: 0.999973] [G loss: 1.000046]\n",
      "epoch:39 step:184285[D loss: 0.999980] [G loss: 1.000060]\n",
      "epoch:39 step:184290[D loss: 1.000008] [G loss: 1.000070]\n",
      "epoch:39 step:184295[D loss: 0.999972] [G loss: 1.000170]\n",
      "epoch:39 step:184300[D loss: 1.000001] [G loss: 0.999987]\n",
      "epoch:39 step:184305[D loss: 0.999948] [G loss: 1.000028]\n",
      "epoch:39 step:184310[D loss: 1.000007] [G loss: 1.000016]\n",
      "epoch:39 step:184315[D loss: 1.000033] [G loss: 0.999937]\n",
      "epoch:39 step:184320[D loss: 1.000076] [G loss: 0.999980]\n",
      "epoch:39 step:184325[D loss: 0.999949] [G loss: 1.000099]\n",
      "epoch:39 step:184330[D loss: 1.000013] [G loss: 1.000067]\n",
      "epoch:39 step:184335[D loss: 0.999898] [G loss: 1.000050]\n",
      "epoch:39 step:184340[D loss: 0.999980] [G loss: 1.000031]\n",
      "epoch:39 step:184345[D loss: 1.000004] [G loss: 1.000047]\n",
      "epoch:39 step:184350[D loss: 1.000093] [G loss: 0.999906]\n",
      "epoch:39 step:184355[D loss: 1.000014] [G loss: 0.999902]\n",
      "epoch:39 step:184360[D loss: 0.999869] [G loss: 1.000211]\n",
      "epoch:39 step:184365[D loss: 0.999960] [G loss: 1.000070]\n",
      "epoch:39 step:184370[D loss: 0.999953] [G loss: 1.000079]\n",
      "epoch:39 step:184375[D loss: 0.999975] [G loss: 1.000077]\n",
      "epoch:39 step:184380[D loss: 0.999965] [G loss: 1.000050]\n",
      "epoch:39 step:184385[D loss: 1.000096] [G loss: 0.999864]\n",
      "epoch:39 step:184390[D loss: 0.999890] [G loss: 1.000019]\n",
      "epoch:39 step:184395[D loss: 1.000040] [G loss: 0.999974]\n",
      "epoch:39 step:184400[D loss: 1.000053] [G loss: 1.000043]\n",
      "epoch:39 step:184405[D loss: 0.999974] [G loss: 1.000065]\n",
      "epoch:39 step:184410[D loss: 0.999958] [G loss: 1.000108]\n",
      "epoch:39 step:184415[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:39 step:184420[D loss: 0.999989] [G loss: 1.000029]\n",
      "epoch:39 step:184425[D loss: 0.999998] [G loss: 1.000042]\n",
      "epoch:39 step:184430[D loss: 0.999991] [G loss: 1.000063]\n",
      "epoch:39 step:184435[D loss: 0.999986] [G loss: 1.000132]\n",
      "epoch:39 step:184440[D loss: 0.999954] [G loss: 1.000027]\n",
      "epoch:39 step:184445[D loss: 1.000170] [G loss: 0.999926]\n",
      "epoch:39 step:184450[D loss: 0.999859] [G loss: 1.000153]\n",
      "epoch:39 step:184455[D loss: 0.999942] [G loss: 1.000066]\n",
      "epoch:39 step:184460[D loss: 1.000031] [G loss: 1.000063]\n",
      "epoch:39 step:184465[D loss: 0.999978] [G loss: 1.000050]\n",
      "epoch:39 step:184470[D loss: 0.999972] [G loss: 1.000110]\n",
      "epoch:39 step:184475[D loss: 0.999964] [G loss: 1.000101]\n",
      "epoch:39 step:184480[D loss: 0.999958] [G loss: 1.000082]\n",
      "epoch:39 step:184485[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:39 step:184490[D loss: 1.000008] [G loss: 1.000024]\n",
      "epoch:39 step:184495[D loss: 0.999980] [G loss: 0.999983]\n",
      "epoch:39 step:184500[D loss: 0.999962] [G loss: 1.000081]\n",
      "epoch:39 step:184505[D loss: 1.000059] [G loss: 1.000103]\n",
      "epoch:39 step:184510[D loss: 0.999962] [G loss: 1.000055]\n",
      "epoch:39 step:184515[D loss: 1.000022] [G loss: 1.000094]\n",
      "epoch:39 step:184520[D loss: 0.999976] [G loss: 1.000029]\n",
      "epoch:39 step:184525[D loss: 1.000004] [G loss: 1.000009]\n",
      "epoch:39 step:184530[D loss: 1.000027] [G loss: 1.000070]\n",
      "epoch:39 step:184535[D loss: 0.999990] [G loss: 1.000042]\n",
      "epoch:39 step:184540[D loss: 1.000001] [G loss: 1.000111]\n",
      "epoch:39 step:184545[D loss: 0.999944] [G loss: 1.000258]\n",
      "epoch:39 step:184550[D loss: 1.000021] [G loss: 1.000188]\n",
      "epoch:39 step:184555[D loss: 0.999977] [G loss: 1.000099]\n",
      "epoch:39 step:184560[D loss: 0.999968] [G loss: 1.000104]\n",
      "epoch:39 step:184565[D loss: 0.999920] [G loss: 1.000159]\n",
      "epoch:39 step:184570[D loss: 1.000002] [G loss: 1.000036]\n",
      "epoch:39 step:184575[D loss: 1.000002] [G loss: 1.000042]\n",
      "epoch:39 step:184580[D loss: 0.999975] [G loss: 0.999982]\n",
      "epoch:39 step:184585[D loss: 1.000011] [G loss: 1.000077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:184590[D loss: 1.000000] [G loss: 1.000021]\n",
      "epoch:39 step:184595[D loss: 0.999964] [G loss: 1.000048]\n",
      "epoch:39 step:184600[D loss: 1.000048] [G loss: 0.999927]\n",
      "epoch:39 step:184605[D loss: 1.000271] [G loss: 0.999779]\n",
      "epoch:39 step:184610[D loss: 0.999960] [G loss: 1.000103]\n",
      "epoch:39 step:184615[D loss: 0.999838] [G loss: 1.000162]\n",
      "epoch:39 step:184620[D loss: 0.999908] [G loss: 1.000144]\n",
      "epoch:39 step:184625[D loss: 0.999962] [G loss: 1.000117]\n",
      "epoch:39 step:184630[D loss: 1.000057] [G loss: 0.999941]\n",
      "epoch:39 step:184635[D loss: 0.999994] [G loss: 1.000016]\n",
      "epoch:39 step:184640[D loss: 1.000198] [G loss: 0.999969]\n",
      "epoch:39 step:184645[D loss: 0.999840] [G loss: 1.000186]\n",
      "epoch:39 step:184650[D loss: 1.000005] [G loss: 1.000184]\n",
      "epoch:39 step:184655[D loss: 1.000052] [G loss: 0.999974]\n",
      "epoch:39 step:184660[D loss: 0.999991] [G loss: 1.000047]\n",
      "epoch:39 step:184665[D loss: 0.999967] [G loss: 1.000057]\n",
      "epoch:39 step:184670[D loss: 1.000035] [G loss: 1.000016]\n",
      "epoch:39 step:184675[D loss: 0.999899] [G loss: 1.000085]\n",
      "epoch:39 step:184680[D loss: 0.999969] [G loss: 1.000071]\n",
      "epoch:39 step:184685[D loss: 0.999985] [G loss: 1.000035]\n",
      "epoch:39 step:184690[D loss: 0.999964] [G loss: 1.000077]\n",
      "epoch:39 step:184695[D loss: 0.999964] [G loss: 1.000088]\n",
      "epoch:39 step:184700[D loss: 0.999989] [G loss: 1.000082]\n",
      "epoch:39 step:184705[D loss: 0.999977] [G loss: 1.000077]\n",
      "epoch:39 step:184710[D loss: 0.999935] [G loss: 1.000087]\n",
      "epoch:39 step:184715[D loss: 0.999947] [G loss: 1.000088]\n",
      "epoch:39 step:184720[D loss: 1.000051] [G loss: 1.000018]\n",
      "epoch:39 step:184725[D loss: 1.000054] [G loss: 0.999940]\n",
      "epoch:39 step:184730[D loss: 1.000062] [G loss: 1.000012]\n",
      "epoch:39 step:184735[D loss: 0.999971] [G loss: 1.000060]\n",
      "epoch:39 step:184740[D loss: 0.999994] [G loss: 1.000047]\n",
      "epoch:39 step:184745[D loss: 0.999971] [G loss: 1.000066]\n",
      "epoch:39 step:184750[D loss: 1.000085] [G loss: 1.000073]\n",
      "epoch:39 step:184755[D loss: 0.999927] [G loss: 1.000086]\n",
      "epoch:39 step:184760[D loss: 0.999978] [G loss: 1.000072]\n",
      "epoch:39 step:184765[D loss: 1.000055] [G loss: 1.000055]\n",
      "epoch:39 step:184770[D loss: 0.999898] [G loss: 1.000150]\n",
      "epoch:39 step:184775[D loss: 0.999944] [G loss: 1.000086]\n",
      "epoch:39 step:184780[D loss: 1.000083] [G loss: 0.999900]\n",
      "epoch:39 step:184785[D loss: 0.999958] [G loss: 1.000081]\n",
      "epoch:39 step:184790[D loss: 0.999914] [G loss: 1.000044]\n",
      "epoch:39 step:184795[D loss: 0.999979] [G loss: 1.000063]\n",
      "epoch:39 step:184800[D loss: 0.999959] [G loss: 1.000050]\n",
      "epoch:39 step:184805[D loss: 0.999932] [G loss: 1.000104]\n",
      "epoch:39 step:184810[D loss: 0.999959] [G loss: 1.000069]\n",
      "epoch:39 step:184815[D loss: 0.999982] [G loss: 1.000053]\n",
      "epoch:39 step:184820[D loss: 1.000127] [G loss: 1.000003]\n",
      "epoch:39 step:184825[D loss: 0.999984] [G loss: 1.000073]\n",
      "epoch:39 step:184830[D loss: 0.999981] [G loss: 1.000051]\n",
      "epoch:39 step:184835[D loss: 0.999936] [G loss: 1.000157]\n",
      "epoch:39 step:184840[D loss: 0.999922] [G loss: 1.000189]\n",
      "epoch:39 step:184845[D loss: 0.999959] [G loss: 1.000092]\n",
      "epoch:39 step:184850[D loss: 1.000014] [G loss: 1.000008]\n",
      "epoch:39 step:184855[D loss: 0.999971] [G loss: 1.000049]\n",
      "epoch:39 step:184860[D loss: 1.000034] [G loss: 0.999972]\n",
      "epoch:39 step:184865[D loss: 1.000151] [G loss: 0.999874]\n",
      "epoch:39 step:184870[D loss: 0.999860] [G loss: 1.000141]\n",
      "epoch:39 step:184875[D loss: 0.999928] [G loss: 1.000248]\n",
      "epoch:39 step:184880[D loss: 0.999954] [G loss: 1.000115]\n",
      "epoch:39 step:184885[D loss: 0.999999] [G loss: 1.000057]\n",
      "epoch:39 step:184890[D loss: 0.999935] [G loss: 1.000060]\n",
      "epoch:39 step:184895[D loss: 1.000187] [G loss: 0.999935]\n",
      "epoch:39 step:184900[D loss: 1.000024] [G loss: 0.999840]\n",
      "epoch:39 step:184905[D loss: 1.000041] [G loss: 0.999973]\n",
      "epoch:39 step:184910[D loss: 0.999868] [G loss: 1.000092]\n",
      "epoch:39 step:184915[D loss: 0.999946] [G loss: 1.000216]\n",
      "epoch:39 step:184920[D loss: 1.000014] [G loss: 1.000100]\n",
      "epoch:39 step:184925[D loss: 0.999896] [G loss: 1.000178]\n",
      "epoch:39 step:184930[D loss: 0.999949] [G loss: 1.000059]\n",
      "epoch:39 step:184935[D loss: 0.999957] [G loss: 1.000061]\n",
      "epoch:39 step:184940[D loss: 0.999968] [G loss: 1.000043]\n",
      "epoch:39 step:184945[D loss: 0.999953] [G loss: 1.000109]\n",
      "epoch:39 step:184950[D loss: 1.000000] [G loss: 1.000078]\n",
      "epoch:39 step:184955[D loss: 1.000071] [G loss: 1.000031]\n",
      "epoch:39 step:184960[D loss: 0.999907] [G loss: 1.000152]\n",
      "epoch:39 step:184965[D loss: 0.999969] [G loss: 1.000115]\n",
      "epoch:39 step:184970[D loss: 0.999994] [G loss: 1.000015]\n",
      "epoch:39 step:184975[D loss: 0.999968] [G loss: 1.000046]\n",
      "epoch:39 step:184980[D loss: 1.000000] [G loss: 1.000014]\n",
      "epoch:39 step:184985[D loss: 1.000005] [G loss: 1.000007]\n",
      "epoch:39 step:184990[D loss: 1.000021] [G loss: 0.999966]\n",
      "epoch:39 step:184995[D loss: 0.999938] [G loss: 1.000100]\n",
      "epoch:39 step:185000[D loss: 1.000017] [G loss: 1.000005]\n",
      "epoch:39 step:185005[D loss: 1.000019] [G loss: 1.000129]\n",
      "epoch:39 step:185010[D loss: 1.000170] [G loss: 0.999986]\n",
      "epoch:39 step:185015[D loss: 0.999954] [G loss: 1.000032]\n",
      "epoch:39 step:185020[D loss: 1.000014] [G loss: 0.999964]\n",
      "epoch:39 step:185025[D loss: 0.999958] [G loss: 1.000064]\n",
      "epoch:39 step:185030[D loss: 1.000045] [G loss: 0.999873]\n",
      "epoch:39 step:185035[D loss: 1.000107] [G loss: 0.999841]\n",
      "epoch:39 step:185040[D loss: 1.000074] [G loss: 0.999979]\n",
      "epoch:39 step:185045[D loss: 1.000088] [G loss: 0.999951]\n",
      "epoch:39 step:185050[D loss: 0.999877] [G loss: 1.000168]\n",
      "epoch:39 step:185055[D loss: 1.000027] [G loss: 1.000179]\n",
      "epoch:39 step:185060[D loss: 1.000164] [G loss: 1.000100]\n",
      "epoch:39 step:185065[D loss: 0.999915] [G loss: 1.000140]\n",
      "epoch:39 step:185070[D loss: 0.999914] [G loss: 1.000161]\n",
      "epoch:39 step:185075[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:39 step:185080[D loss: 0.999990] [G loss: 1.000054]\n",
      "epoch:39 step:185085[D loss: 1.000134] [G loss: 0.999823]\n",
      "epoch:39 step:185090[D loss: 0.999789] [G loss: 1.000161]\n",
      "epoch:39 step:185095[D loss: 0.999879] [G loss: 1.000087]\n",
      "epoch:39 step:185100[D loss: 1.000001] [G loss: 0.999978]\n",
      "epoch:39 step:185105[D loss: 0.999972] [G loss: 1.000155]\n",
      "epoch:39 step:185110[D loss: 0.999902] [G loss: 1.000060]\n",
      "epoch:39 step:185115[D loss: 0.999913] [G loss: 1.000116]\n",
      "epoch:39 step:185120[D loss: 1.000102] [G loss: 0.999971]\n",
      "epoch:39 step:185125[D loss: 0.999942] [G loss: 1.000116]\n",
      "epoch:39 step:185130[D loss: 0.999972] [G loss: 1.000109]\n",
      "epoch:39 step:185135[D loss: 0.999981] [G loss: 1.000119]\n",
      "epoch:39 step:185140[D loss: 1.000067] [G loss: 1.000036]\n",
      "epoch:39 step:185145[D loss: 0.999874] [G loss: 1.000160]\n",
      "epoch:39 step:185150[D loss: 0.999930] [G loss: 1.000073]\n",
      "epoch:39 step:185155[D loss: 1.000184] [G loss: 0.999904]\n",
      "epoch:39 step:185160[D loss: 0.999938] [G loss: 1.000178]\n",
      "epoch:39 step:185165[D loss: 1.000035] [G loss: 1.000179]\n",
      "epoch:39 step:185170[D loss: 0.999659] [G loss: 1.000501]\n",
      "epoch:39 step:185175[D loss: 0.999858] [G loss: 1.000546]\n",
      "epoch:39 step:185180[D loss: 1.000084] [G loss: 1.000268]\n",
      "epoch:39 step:185185[D loss: 0.999972] [G loss: 1.000393]\n",
      "epoch:39 step:185190[D loss: 0.999927] [G loss: 1.000223]\n",
      "epoch:39 step:185195[D loss: 1.000103] [G loss: 1.000251]\n",
      "epoch:39 step:185200[D loss: 0.999978] [G loss: 1.000171]\n",
      "epoch:39 step:185205[D loss: 0.999956] [G loss: 1.000012]\n",
      "epoch:39 step:185210[D loss: 1.000182] [G loss: 0.999814]\n",
      "epoch:39 step:185215[D loss: 1.000149] [G loss: 0.999836]\n",
      "epoch:39 step:185220[D loss: 0.999887] [G loss: 0.999958]\n",
      "epoch:39 step:185225[D loss: 0.999983] [G loss: 1.000041]\n",
      "epoch:39 step:185230[D loss: 0.999930] [G loss: 1.000053]\n",
      "epoch:39 step:185235[D loss: 0.999995] [G loss: 0.999996]\n",
      "epoch:39 step:185240[D loss: 0.999985] [G loss: 1.000132]\n",
      "epoch:39 step:185245[D loss: 0.999950] [G loss: 1.000079]\n",
      "epoch:39 step:185250[D loss: 1.000165] [G loss: 1.000005]\n",
      "epoch:39 step:185255[D loss: 1.000006] [G loss: 1.000108]\n",
      "epoch:39 step:185260[D loss: 1.000059] [G loss: 1.000057]\n",
      "epoch:39 step:185265[D loss: 1.000100] [G loss: 1.000348]\n",
      "epoch:39 step:185270[D loss: 1.000011] [G loss: 1.000091]\n",
      "epoch:39 step:185275[D loss: 0.999986] [G loss: 1.000046]\n",
      "epoch:39 step:185280[D loss: 1.000110] [G loss: 0.999956]\n",
      "epoch:39 step:185285[D loss: 1.000129] [G loss: 0.999888]\n",
      "epoch:39 step:185290[D loss: 0.999917] [G loss: 1.000134]\n",
      "epoch:39 step:185295[D loss: 0.999964] [G loss: 1.000075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:185300[D loss: 1.000182] [G loss: 0.999916]\n",
      "epoch:39 step:185305[D loss: 0.999916] [G loss: 1.000083]\n",
      "epoch:39 step:185310[D loss: 0.999945] [G loss: 1.000210]\n",
      "epoch:39 step:185315[D loss: 1.000031] [G loss: 1.000129]\n",
      "epoch:39 step:185320[D loss: 0.999894] [G loss: 1.000179]\n",
      "epoch:39 step:185325[D loss: 0.999971] [G loss: 1.000093]\n",
      "epoch:39 step:185330[D loss: 0.999935] [G loss: 1.000115]\n",
      "epoch:39 step:185335[D loss: 0.999994] [G loss: 1.000089]\n",
      "epoch:39 step:185340[D loss: 0.999946] [G loss: 1.000125]\n",
      "epoch:39 step:185345[D loss: 0.999980] [G loss: 1.000056]\n",
      "epoch:39 step:185350[D loss: 0.999962] [G loss: 1.000090]\n",
      "epoch:39 step:185355[D loss: 0.999965] [G loss: 1.000093]\n",
      "epoch:39 step:185360[D loss: 0.999970] [G loss: 1.000040]\n",
      "epoch:39 step:185365[D loss: 1.000010] [G loss: 1.000054]\n",
      "epoch:39 step:185370[D loss: 0.999943] [G loss: 1.000091]\n",
      "epoch:39 step:185375[D loss: 0.999927] [G loss: 1.000073]\n",
      "epoch:39 step:185380[D loss: 0.999978] [G loss: 1.000052]\n",
      "epoch:39 step:185385[D loss: 1.000027] [G loss: 1.000154]\n",
      "epoch:39 step:185390[D loss: 0.999921] [G loss: 1.000110]\n",
      "epoch:39 step:185395[D loss: 1.000043] [G loss: 1.000160]\n",
      "epoch:39 step:185400[D loss: 0.999958] [G loss: 1.000249]\n",
      "epoch:39 step:185405[D loss: 1.000010] [G loss: 1.000104]\n",
      "epoch:39 step:185410[D loss: 0.999979] [G loss: 1.000119]\n",
      "epoch:39 step:185415[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:39 step:185420[D loss: 1.000031] [G loss: 0.999937]\n",
      "epoch:39 step:185425[D loss: 1.000080] [G loss: 0.999887]\n",
      "epoch:39 step:185430[D loss: 1.000175] [G loss: 0.999997]\n",
      "epoch:39 step:185435[D loss: 1.000043] [G loss: 0.999926]\n",
      "epoch:39 step:185440[D loss: 0.999985] [G loss: 1.000046]\n",
      "epoch:39 step:185445[D loss: 1.000084] [G loss: 0.999934]\n",
      "epoch:39 step:185450[D loss: 0.999936] [G loss: 1.000046]\n",
      "epoch:39 step:185455[D loss: 0.999976] [G loss: 1.000058]\n",
      "epoch:39 step:185460[D loss: 0.999949] [G loss: 1.000097]\n",
      "epoch:39 step:185465[D loss: 1.000016] [G loss: 1.000071]\n",
      "epoch:39 step:185470[D loss: 0.999982] [G loss: 1.000049]\n",
      "epoch:39 step:185475[D loss: 0.999968] [G loss: 1.000050]\n",
      "epoch:39 step:185480[D loss: 1.000024] [G loss: 0.999998]\n",
      "epoch:39 step:185485[D loss: 0.999901] [G loss: 1.000042]\n",
      "epoch:39 step:185490[D loss: 1.000029] [G loss: 0.999988]\n",
      "epoch:39 step:185495[D loss: 0.999984] [G loss: 1.000043]\n",
      "epoch:39 step:185500[D loss: 0.999969] [G loss: 1.000085]\n",
      "epoch:39 step:185505[D loss: 0.999979] [G loss: 1.000032]\n",
      "epoch:39 step:185510[D loss: 0.999970] [G loss: 1.000054]\n",
      "epoch:39 step:185515[D loss: 0.999980] [G loss: 1.000071]\n",
      "epoch:39 step:185520[D loss: 1.000019] [G loss: 0.999979]\n",
      "epoch:39 step:185525[D loss: 0.999968] [G loss: 1.000034]\n",
      "epoch:39 step:185530[D loss: 0.999971] [G loss: 1.000058]\n",
      "epoch:39 step:185535[D loss: 0.999951] [G loss: 1.000101]\n",
      "epoch:39 step:185540[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:39 step:185545[D loss: 0.999971] [G loss: 1.000061]\n",
      "epoch:39 step:185550[D loss: 0.999981] [G loss: 1.000056]\n",
      "epoch:39 step:185555[D loss: 0.999982] [G loss: 1.000054]\n",
      "epoch:39 step:185560[D loss: 0.999972] [G loss: 1.000061]\n",
      "epoch:39 step:185565[D loss: 0.999938] [G loss: 1.000089]\n",
      "epoch:39 step:185570[D loss: 0.999979] [G loss: 1.000080]\n",
      "epoch:39 step:185575[D loss: 0.999991] [G loss: 1.000054]\n",
      "epoch:39 step:185580[D loss: 1.000006] [G loss: 1.000043]\n",
      "epoch:39 step:185585[D loss: 0.999970] [G loss: 1.000065]\n",
      "epoch:39 step:185590[D loss: 1.000050] [G loss: 1.000085]\n",
      "epoch:39 step:185595[D loss: 0.999920] [G loss: 1.000175]\n",
      "epoch:39 step:185600[D loss: 1.000009] [G loss: 1.000022]\n",
      "epoch:39 step:185605[D loss: 0.999963] [G loss: 1.000039]\n",
      "epoch:39 step:185610[D loss: 0.999976] [G loss: 1.000029]\n",
      "epoch:39 step:185615[D loss: 1.000026] [G loss: 1.000016]\n",
      "epoch:39 step:185620[D loss: 1.000011] [G loss: 1.000011]\n",
      "epoch:39 step:185625[D loss: 1.000059] [G loss: 0.999890]\n",
      "epoch:39 step:185630[D loss: 0.999962] [G loss: 1.000058]\n",
      "epoch:39 step:185635[D loss: 1.000016] [G loss: 1.000049]\n",
      "epoch:39 step:185640[D loss: 0.999962] [G loss: 1.000086]\n",
      "epoch:39 step:185645[D loss: 0.999985] [G loss: 1.000039]\n",
      "epoch:39 step:185650[D loss: 1.000010] [G loss: 1.000036]\n",
      "epoch:39 step:185655[D loss: 1.000060] [G loss: 0.999901]\n",
      "epoch:39 step:185660[D loss: 1.000178] [G loss: 0.999918]\n",
      "epoch:39 step:185665[D loss: 0.999889] [G loss: 1.000117]\n",
      "epoch:39 step:185670[D loss: 0.999971] [G loss: 1.000064]\n",
      "epoch:39 step:185675[D loss: 1.000081] [G loss: 0.999914]\n",
      "epoch:39 step:185680[D loss: 1.000118] [G loss: 0.999914]\n",
      "epoch:39 step:185685[D loss: 0.999870] [G loss: 1.000137]\n",
      "epoch:39 step:185690[D loss: 1.000205] [G loss: 1.000192]\n",
      "epoch:39 step:185695[D loss: 0.999965] [G loss: 1.000216]\n",
      "epoch:39 step:185700[D loss: 0.999810] [G loss: 1.000287]\n",
      "epoch:39 step:185705[D loss: 0.999893] [G loss: 1.000270]\n",
      "epoch:39 step:185710[D loss: 0.999955] [G loss: 1.000132]\n",
      "epoch:39 step:185715[D loss: 0.999979] [G loss: 1.000097]\n",
      "epoch:39 step:185720[D loss: 1.000071] [G loss: 0.999954]\n",
      "epoch:39 step:185725[D loss: 1.000039] [G loss: 0.999854]\n",
      "epoch:39 step:185730[D loss: 1.000024] [G loss: 0.999903]\n",
      "epoch:39 step:185735[D loss: 0.999986] [G loss: 1.000023]\n",
      "epoch:39 step:185740[D loss: 0.999963] [G loss: 0.999958]\n",
      "epoch:39 step:185745[D loss: 0.999993] [G loss: 1.000014]\n",
      "epoch:39 step:185750[D loss: 0.999950] [G loss: 1.000086]\n",
      "epoch:39 step:185755[D loss: 1.000072] [G loss: 0.999912]\n",
      "epoch:39 step:185760[D loss: 1.000011] [G loss: 1.000155]\n",
      "epoch:39 step:185765[D loss: 0.999983] [G loss: 1.000005]\n",
      "epoch:39 step:185770[D loss: 1.000005] [G loss: 1.000124]\n",
      "epoch:39 step:185775[D loss: 1.000013] [G loss: 1.000027]\n",
      "epoch:39 step:185780[D loss: 1.000020] [G loss: 0.999991]\n",
      "epoch:39 step:185785[D loss: 0.999962] [G loss: 1.000033]\n",
      "epoch:39 step:185790[D loss: 0.999964] [G loss: 1.000032]\n",
      "epoch:39 step:185795[D loss: 0.999975] [G loss: 1.000051]\n",
      "epoch:39 step:185800[D loss: 0.999988] [G loss: 1.000117]\n",
      "epoch:39 step:185805[D loss: 0.999955] [G loss: 1.000090]\n",
      "epoch:39 step:185810[D loss: 0.999955] [G loss: 0.999984]\n",
      "epoch:39 step:185815[D loss: 1.000068] [G loss: 1.000065]\n",
      "epoch:39 step:185820[D loss: 0.999815] [G loss: 1.000194]\n",
      "epoch:39 step:185825[D loss: 1.000166] [G loss: 0.999943]\n",
      "epoch:39 step:185830[D loss: 0.999887] [G loss: 1.000164]\n",
      "epoch:39 step:185835[D loss: 0.999946] [G loss: 1.000147]\n",
      "epoch:39 step:185840[D loss: 1.000031] [G loss: 1.000119]\n",
      "epoch:39 step:185845[D loss: 0.999918] [G loss: 1.000172]\n",
      "epoch:39 step:185850[D loss: 1.000078] [G loss: 0.999890]\n",
      "epoch:39 step:185855[D loss: 1.000007] [G loss: 0.999947]\n",
      "epoch:39 step:185860[D loss: 1.000021] [G loss: 0.999835]\n",
      "epoch:39 step:185865[D loss: 1.000017] [G loss: 0.999950]\n",
      "epoch:39 step:185870[D loss: 1.000058] [G loss: 0.999951]\n",
      "epoch:39 step:185875[D loss: 0.999955] [G loss: 1.000316]\n",
      "epoch:39 step:185880[D loss: 1.000004] [G loss: 1.000222]\n",
      "epoch:39 step:185885[D loss: 0.999940] [G loss: 1.000163]\n",
      "epoch:39 step:185890[D loss: 0.999968] [G loss: 1.000142]\n",
      "epoch:39 step:185895[D loss: 0.999992] [G loss: 0.999997]\n",
      "epoch:39 step:185900[D loss: 1.000097] [G loss: 0.999903]\n",
      "epoch:39 step:185905[D loss: 0.999981] [G loss: 0.999912]\n",
      "epoch:39 step:185910[D loss: 0.999914] [G loss: 0.999999]\n",
      "epoch:39 step:185915[D loss: 1.000066] [G loss: 0.999949]\n",
      "epoch:39 step:185920[D loss: 1.000191] [G loss: 0.999899]\n",
      "epoch:39 step:185925[D loss: 0.999913] [G loss: 1.000297]\n",
      "epoch:39 step:185930[D loss: 0.999803] [G loss: 1.000182]\n",
      "epoch:39 step:185935[D loss: 0.999973] [G loss: 1.000011]\n",
      "epoch:39 step:185940[D loss: 0.999894] [G loss: 1.000134]\n",
      "epoch:39 step:185945[D loss: 1.000035] [G loss: 1.000034]\n",
      "epoch:39 step:185950[D loss: 0.999951] [G loss: 1.000069]\n",
      "epoch:39 step:185955[D loss: 0.999885] [G loss: 1.000086]\n",
      "epoch:39 step:185960[D loss: 1.000126] [G loss: 0.999895]\n",
      "epoch:39 step:185965[D loss: 0.999988] [G loss: 1.000125]\n",
      "epoch:39 step:185970[D loss: 0.999971] [G loss: 1.000240]\n",
      "epoch:39 step:185975[D loss: 0.999975] [G loss: 1.000137]\n",
      "epoch:39 step:185980[D loss: 1.000072] [G loss: 1.000136]\n",
      "epoch:39 step:185985[D loss: 0.999749] [G loss: 1.000378]\n",
      "epoch:39 step:185990[D loss: 0.999836] [G loss: 1.000369]\n",
      "epoch:39 step:185995[D loss: 0.999992] [G loss: 1.000100]\n",
      "epoch:39 step:186000[D loss: 0.999999] [G loss: 1.000120]\n",
      "epoch:39 step:186005[D loss: 0.999946] [G loss: 1.000016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:186010[D loss: 0.999963] [G loss: 1.000089]\n",
      "epoch:39 step:186015[D loss: 1.000054] [G loss: 0.999897]\n",
      "epoch:39 step:186020[D loss: 0.999926] [G loss: 1.000099]\n",
      "epoch:39 step:186025[D loss: 0.999960] [G loss: 1.000090]\n",
      "epoch:39 step:186030[D loss: 0.999992] [G loss: 1.000074]\n",
      "epoch:39 step:186035[D loss: 0.999962] [G loss: 1.000072]\n",
      "epoch:39 step:186040[D loss: 0.999985] [G loss: 1.000013]\n",
      "epoch:39 step:186045[D loss: 0.999977] [G loss: 1.000069]\n",
      "epoch:39 step:186050[D loss: 0.999972] [G loss: 1.000099]\n",
      "epoch:39 step:186055[D loss: 0.999980] [G loss: 1.000039]\n",
      "epoch:39 step:186060[D loss: 0.999966] [G loss: 1.000049]\n",
      "epoch:39 step:186065[D loss: 0.999981] [G loss: 1.000099]\n",
      "epoch:39 step:186070[D loss: 0.999963] [G loss: 1.000082]\n",
      "epoch:39 step:186075[D loss: 0.999976] [G loss: 1.000052]\n",
      "epoch:39 step:186080[D loss: 0.999997] [G loss: 1.000110]\n",
      "epoch:39 step:186085[D loss: 0.999984] [G loss: 1.000053]\n",
      "epoch:39 step:186090[D loss: 1.000013] [G loss: 1.000034]\n",
      "epoch:39 step:186095[D loss: 0.999964] [G loss: 1.000040]\n",
      "epoch:39 step:186100[D loss: 1.000004] [G loss: 1.000089]\n",
      "epoch:39 step:186105[D loss: 1.000024] [G loss: 1.000237]\n",
      "epoch:39 step:186110[D loss: 0.999915] [G loss: 1.000225]\n",
      "epoch:39 step:186115[D loss: 1.000044] [G loss: 1.000024]\n",
      "epoch:39 step:186120[D loss: 0.999947] [G loss: 1.000095]\n",
      "epoch:39 step:186125[D loss: 0.999971] [G loss: 1.000102]\n",
      "epoch:39 step:186130[D loss: 1.000005] [G loss: 0.999974]\n",
      "epoch:39 step:186135[D loss: 0.999955] [G loss: 1.000055]\n",
      "epoch:39 step:186140[D loss: 1.000047] [G loss: 0.999984]\n",
      "epoch:39 step:186145[D loss: 1.000034] [G loss: 0.999949]\n",
      "epoch:39 step:186150[D loss: 0.999969] [G loss: 1.000060]\n",
      "epoch:39 step:186155[D loss: 0.999988] [G loss: 1.000063]\n",
      "epoch:39 step:186160[D loss: 1.000057] [G loss: 0.999942]\n",
      "epoch:39 step:186165[D loss: 0.999942] [G loss: 1.000109]\n",
      "epoch:39 step:186170[D loss: 1.000026] [G loss: 1.000070]\n",
      "epoch:39 step:186175[D loss: 0.999951] [G loss: 1.000181]\n",
      "epoch:39 step:186180[D loss: 1.000049] [G loss: 1.000063]\n",
      "epoch:39 step:186185[D loss: 1.000011] [G loss: 1.000027]\n",
      "epoch:39 step:186190[D loss: 0.999906] [G loss: 0.999998]\n",
      "epoch:39 step:186195[D loss: 0.999916] [G loss: 1.000144]\n",
      "epoch:39 step:186200[D loss: 0.999957] [G loss: 1.000108]\n",
      "epoch:39 step:186205[D loss: 1.000006] [G loss: 1.000042]\n",
      "epoch:39 step:186210[D loss: 0.999990] [G loss: 1.000028]\n",
      "epoch:39 step:186215[D loss: 0.999975] [G loss: 1.000031]\n",
      "epoch:39 step:186220[D loss: 1.000009] [G loss: 1.000007]\n",
      "epoch:39 step:186225[D loss: 1.000016] [G loss: 1.000030]\n",
      "epoch:39 step:186230[D loss: 0.999995] [G loss: 1.000061]\n",
      "epoch:39 step:186235[D loss: 1.000043] [G loss: 0.999930]\n",
      "epoch:39 step:186240[D loss: 1.000045] [G loss: 1.000100]\n",
      "epoch:39 step:186245[D loss: 0.999957] [G loss: 1.000124]\n",
      "epoch:39 step:186250[D loss: 0.999966] [G loss: 1.000116]\n",
      "epoch:39 step:186255[D loss: 1.000003] [G loss: 1.000012]\n",
      "epoch:39 step:186260[D loss: 1.000060] [G loss: 0.999966]\n",
      "epoch:39 step:186265[D loss: 1.000074] [G loss: 0.999961]\n",
      "epoch:39 step:186270[D loss: 0.999911] [G loss: 1.000052]\n",
      "epoch:39 step:186275[D loss: 0.999970] [G loss: 1.000006]\n",
      "epoch:39 step:186280[D loss: 0.999860] [G loss: 1.000172]\n",
      "epoch:39 step:186285[D loss: 1.000138] [G loss: 1.000070]\n",
      "epoch:39 step:186290[D loss: 0.999869] [G loss: 1.000250]\n",
      "epoch:39 step:186295[D loss: 0.999982] [G loss: 1.000081]\n",
      "epoch:39 step:186300[D loss: 0.999953] [G loss: 1.000051]\n",
      "epoch:39 step:186305[D loss: 0.999976] [G loss: 1.000050]\n",
      "epoch:39 step:186310[D loss: 0.999961] [G loss: 1.000009]\n",
      "epoch:39 step:186315[D loss: 1.000098] [G loss: 0.999987]\n",
      "epoch:39 step:186320[D loss: 0.999984] [G loss: 1.000097]\n",
      "epoch:39 step:186325[D loss: 1.000033] [G loss: 1.000089]\n",
      "epoch:39 step:186330[D loss: 1.000012] [G loss: 1.000186]\n",
      "epoch:39 step:186335[D loss: 0.999932] [G loss: 1.000155]\n",
      "epoch:39 step:186340[D loss: 0.999925] [G loss: 1.000136]\n",
      "epoch:39 step:186345[D loss: 0.999968] [G loss: 1.000053]\n",
      "epoch:39 step:186350[D loss: 1.000020] [G loss: 1.000077]\n",
      "epoch:39 step:186355[D loss: 0.999999] [G loss: 1.000022]\n",
      "epoch:39 step:186360[D loss: 0.999970] [G loss: 1.000008]\n",
      "epoch:39 step:186365[D loss: 0.999967] [G loss: 1.000050]\n",
      "epoch:39 step:186370[D loss: 1.000087] [G loss: 1.000012]\n",
      "epoch:39 step:186375[D loss: 0.999995] [G loss: 1.000068]\n",
      "epoch:39 step:186380[D loss: 1.000001] [G loss: 1.000054]\n",
      "epoch:39 step:186385[D loss: 0.999998] [G loss: 1.000054]\n",
      "epoch:39 step:186390[D loss: 0.999947] [G loss: 1.000105]\n",
      "epoch:39 step:186395[D loss: 0.999980] [G loss: 1.000045]\n",
      "epoch:39 step:186400[D loss: 1.000165] [G loss: 0.999988]\n",
      "epoch:39 step:186405[D loss: 0.999848] [G loss: 1.000221]\n",
      "epoch:39 step:186410[D loss: 1.000212] [G loss: 0.999940]\n",
      "epoch:39 step:186415[D loss: 0.999894] [G loss: 1.000355]\n",
      "epoch:39 step:186420[D loss: 0.999926] [G loss: 1.000181]\n",
      "epoch:39 step:186425[D loss: 0.999996] [G loss: 1.000082]\n",
      "epoch:39 step:186430[D loss: 0.999966] [G loss: 1.000101]\n",
      "epoch:39 step:186435[D loss: 0.999969] [G loss: 1.000021]\n",
      "epoch:39 step:186440[D loss: 0.999962] [G loss: 1.000015]\n",
      "epoch:39 step:186445[D loss: 0.999971] [G loss: 1.000031]\n",
      "epoch:39 step:186450[D loss: 0.999967] [G loss: 1.000067]\n",
      "epoch:39 step:186455[D loss: 0.999958] [G loss: 1.000016]\n",
      "epoch:39 step:186460[D loss: 0.999987] [G loss: 1.000020]\n",
      "epoch:39 step:186465[D loss: 1.000167] [G loss: 0.999928]\n",
      "epoch:39 step:186470[D loss: 1.000092] [G loss: 0.999823]\n",
      "epoch:39 step:186475[D loss: 0.999915] [G loss: 1.000090]\n",
      "epoch:39 step:186480[D loss: 0.999929] [G loss: 1.000102]\n",
      "epoch:39 step:186485[D loss: 0.999942] [G loss: 1.000220]\n",
      "epoch:39 step:186490[D loss: 0.999966] [G loss: 1.000155]\n",
      "epoch:39 step:186495[D loss: 0.999948] [G loss: 1.000076]\n",
      "epoch:39 step:186500[D loss: 0.999989] [G loss: 1.000228]\n",
      "epoch:39 step:186505[D loss: 1.000085] [G loss: 1.000001]\n",
      "epoch:39 step:186510[D loss: 0.999951] [G loss: 1.000135]\n",
      "epoch:39 step:186515[D loss: 1.000011] [G loss: 1.000121]\n",
      "epoch:39 step:186520[D loss: 0.999976] [G loss: 1.000106]\n",
      "epoch:39 step:186525[D loss: 1.000059] [G loss: 1.000027]\n",
      "epoch:39 step:186530[D loss: 0.999967] [G loss: 1.000065]\n",
      "epoch:39 step:186535[D loss: 0.999960] [G loss: 1.000087]\n",
      "epoch:39 step:186540[D loss: 0.999975] [G loss: 1.000089]\n",
      "epoch:39 step:186545[D loss: 1.000010] [G loss: 0.999946]\n",
      "epoch:39 step:186550[D loss: 0.999976] [G loss: 1.000021]\n",
      "epoch:39 step:186555[D loss: 1.000057] [G loss: 0.999961]\n",
      "epoch:39 step:186560[D loss: 0.999967] [G loss: 1.000091]\n",
      "epoch:39 step:186565[D loss: 0.999978] [G loss: 1.000085]\n",
      "epoch:39 step:186570[D loss: 0.999936] [G loss: 1.000095]\n",
      "epoch:39 step:186575[D loss: 1.000006] [G loss: 1.000027]\n",
      "epoch:39 step:186580[D loss: 0.999968] [G loss: 1.000068]\n",
      "epoch:39 step:186585[D loss: 1.000088] [G loss: 0.999923]\n",
      "epoch:39 step:186590[D loss: 0.999955] [G loss: 1.000050]\n",
      "epoch:39 step:186595[D loss: 0.999995] [G loss: 1.000036]\n",
      "epoch:39 step:186600[D loss: 0.999978] [G loss: 1.000040]\n",
      "epoch:39 step:186605[D loss: 0.999994] [G loss: 1.000112]\n",
      "epoch:39 step:186610[D loss: 1.000080] [G loss: 1.000029]\n",
      "epoch:39 step:186615[D loss: 0.999935] [G loss: 1.000148]\n",
      "epoch:39 step:186620[D loss: 1.000067] [G loss: 1.000049]\n",
      "epoch:39 step:186625[D loss: 0.999946] [G loss: 1.000139]\n",
      "epoch:39 step:186630[D loss: 0.999959] [G loss: 1.000083]\n",
      "epoch:39 step:186635[D loss: 0.999954] [G loss: 1.000078]\n",
      "epoch:39 step:186640[D loss: 0.999963] [G loss: 1.000072]\n",
      "epoch:39 step:186645[D loss: 0.999964] [G loss: 1.000085]\n",
      "epoch:39 step:186650[D loss: 0.999984] [G loss: 1.000089]\n",
      "epoch:39 step:186655[D loss: 0.999953] [G loss: 1.000097]\n",
      "epoch:39 step:186660[D loss: 1.000048] [G loss: 0.999982]\n",
      "epoch:39 step:186665[D loss: 0.999910] [G loss: 1.000085]\n",
      "epoch:39 step:186670[D loss: 0.999944] [G loss: 1.000093]\n",
      "epoch:39 step:186675[D loss: 0.999956] [G loss: 1.000088]\n",
      "epoch:39 step:186680[D loss: 1.000003] [G loss: 1.000027]\n",
      "epoch:39 step:186685[D loss: 0.999969] [G loss: 1.000072]\n",
      "epoch:39 step:186690[D loss: 0.999984] [G loss: 1.000108]\n",
      "epoch:39 step:186695[D loss: 0.999998] [G loss: 1.000014]\n",
      "epoch:39 step:186700[D loss: 1.000018] [G loss: 1.000042]\n",
      "epoch:39 step:186705[D loss: 1.000145] [G loss: 0.999917]\n",
      "epoch:39 step:186710[D loss: 0.999930] [G loss: 1.000171]\n",
      "epoch:39 step:186715[D loss: 0.999960] [G loss: 1.000054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:186720[D loss: 1.000121] [G loss: 0.999942]\n",
      "epoch:39 step:186725[D loss: 1.000028] [G loss: 0.999908]\n",
      "epoch:39 step:186730[D loss: 0.999963] [G loss: 1.000055]\n",
      "epoch:39 step:186735[D loss: 1.000049] [G loss: 1.000054]\n",
      "epoch:39 step:186740[D loss: 1.000073] [G loss: 1.000060]\n",
      "epoch:39 step:186745[D loss: 0.999923] [G loss: 1.000147]\n",
      "epoch:39 step:186750[D loss: 0.999984] [G loss: 1.000134]\n",
      "epoch:39 step:186755[D loss: 1.000111] [G loss: 1.000099]\n",
      "epoch:39 step:186760[D loss: 0.999885] [G loss: 1.000128]\n",
      "epoch:39 step:186765[D loss: 0.999982] [G loss: 1.000072]\n",
      "epoch:39 step:186770[D loss: 0.999963] [G loss: 1.000101]\n",
      "epoch:39 step:186775[D loss: 0.999948] [G loss: 1.000090]\n",
      "epoch:39 step:186780[D loss: 0.999958] [G loss: 1.000075]\n",
      "epoch:39 step:186785[D loss: 0.999947] [G loss: 1.000096]\n",
      "epoch:39 step:186790[D loss: 0.999976] [G loss: 1.000101]\n",
      "epoch:39 step:186795[D loss: 1.000015] [G loss: 1.000011]\n",
      "epoch:39 step:186800[D loss: 0.999947] [G loss: 1.000076]\n",
      "epoch:39 step:186805[D loss: 1.000007] [G loss: 1.000071]\n",
      "epoch:39 step:186810[D loss: 0.999974] [G loss: 0.999998]\n",
      "epoch:39 step:186815[D loss: 0.999944] [G loss: 1.000183]\n",
      "epoch:39 step:186820[D loss: 0.999966] [G loss: 1.000091]\n",
      "epoch:39 step:186825[D loss: 1.000006] [G loss: 1.000003]\n",
      "epoch:39 step:186830[D loss: 1.000010] [G loss: 0.999982]\n",
      "epoch:39 step:186835[D loss: 0.999960] [G loss: 1.000071]\n",
      "epoch:39 step:186840[D loss: 0.999965] [G loss: 1.000081]\n",
      "epoch:39 step:186845[D loss: 1.000007] [G loss: 1.000093]\n",
      "epoch:39 step:186850[D loss: 0.999991] [G loss: 1.000064]\n",
      "epoch:39 step:186855[D loss: 0.999967] [G loss: 1.000081]\n",
      "epoch:39 step:186860[D loss: 1.000025] [G loss: 1.000112]\n",
      "epoch:39 step:186865[D loss: 0.999948] [G loss: 1.000127]\n",
      "epoch:39 step:186870[D loss: 1.000034] [G loss: 0.999943]\n",
      "epoch:39 step:186875[D loss: 1.000211] [G loss: 0.999793]\n",
      "epoch:39 step:186880[D loss: 0.999918] [G loss: 1.000053]\n",
      "epoch:39 step:186885[D loss: 1.000075] [G loss: 1.000064]\n",
      "epoch:39 step:186890[D loss: 0.999979] [G loss: 1.000175]\n",
      "epoch:39 step:186895[D loss: 0.999914] [G loss: 1.000143]\n",
      "epoch:39 step:186900[D loss: 0.999909] [G loss: 1.000108]\n",
      "epoch:39 step:186905[D loss: 0.999971] [G loss: 1.000076]\n",
      "epoch:39 step:186910[D loss: 0.999999] [G loss: 1.000074]\n",
      "epoch:39 step:186915[D loss: 0.999998] [G loss: 1.000019]\n",
      "epoch:39 step:186920[D loss: 1.000041] [G loss: 0.999953]\n",
      "epoch:39 step:186925[D loss: 1.000008] [G loss: 0.999947]\n",
      "epoch:39 step:186930[D loss: 1.000003] [G loss: 1.000015]\n",
      "epoch:39 step:186935[D loss: 1.000138] [G loss: 1.000051]\n",
      "epoch:39 step:186940[D loss: 0.999944] [G loss: 1.000132]\n",
      "epoch:39 step:186945[D loss: 0.999925] [G loss: 1.000252]\n",
      "epoch:39 step:186950[D loss: 0.999885] [G loss: 1.000356]\n",
      "epoch:39 step:186955[D loss: 0.999875] [G loss: 1.000298]\n",
      "epoch:39 step:186960[D loss: 1.000044] [G loss: 1.000199]\n",
      "epoch:39 step:186965[D loss: 0.999836] [G loss: 1.000286]\n",
      "epoch:39 step:186970[D loss: 0.999985] [G loss: 1.000063]\n",
      "epoch:39 step:186975[D loss: 0.999990] [G loss: 1.000009]\n",
      "epoch:39 step:186980[D loss: 1.000078] [G loss: 0.999918]\n",
      "epoch:39 step:186985[D loss: 0.999908] [G loss: 0.999917]\n",
      "epoch:39 step:186990[D loss: 1.000124] [G loss: 0.999847]\n",
      "epoch:39 step:186995[D loss: 1.000139] [G loss: 0.999980]\n",
      "epoch:39 step:187000[D loss: 0.999898] [G loss: 1.000142]\n",
      "epoch:39 step:187005[D loss: 1.000166] [G loss: 0.999822]\n",
      "epoch:39 step:187010[D loss: 1.000124] [G loss: 1.000060]\n",
      "epoch:39 step:187015[D loss: 1.000017] [G loss: 0.999983]\n",
      "epoch:39 step:187020[D loss: 0.999800] [G loss: 1.000251]\n",
      "epoch:39 step:187025[D loss: 0.999957] [G loss: 1.000116]\n",
      "epoch:39 step:187030[D loss: 0.999980] [G loss: 1.000079]\n",
      "epoch:39 step:187035[D loss: 1.000059] [G loss: 0.999981]\n",
      "epoch:39 step:187040[D loss: 1.000081] [G loss: 0.999903]\n",
      "epoch:39 step:187045[D loss: 0.999971] [G loss: 1.000154]\n",
      "epoch:39 step:187050[D loss: 1.000068] [G loss: 1.000106]\n",
      "epoch:39 step:187055[D loss: 0.999961] [G loss: 1.000171]\n",
      "epoch:39 step:187060[D loss: 0.999918] [G loss: 1.000346]\n",
      "epoch:39 step:187065[D loss: 1.000058] [G loss: 1.000186]\n",
      "epoch:39 step:187070[D loss: 0.999967] [G loss: 1.000049]\n",
      "epoch:39 step:187075[D loss: 0.999966] [G loss: 0.999993]\n",
      "epoch:39 step:187080[D loss: 0.999968] [G loss: 1.000061]\n",
      "epoch:39 step:187085[D loss: 1.000040] [G loss: 0.999956]\n",
      "epoch:39 step:187090[D loss: 0.999989] [G loss: 0.999974]\n",
      "epoch:39 step:187095[D loss: 1.000029] [G loss: 0.999914]\n",
      "epoch:39 step:187100[D loss: 0.999912] [G loss: 0.999997]\n",
      "epoch:39 step:187105[D loss: 0.999865] [G loss: 1.000149]\n",
      "epoch:39 step:187110[D loss: 0.999894] [G loss: 1.000110]\n",
      "epoch:39 step:187115[D loss: 1.000078] [G loss: 1.000016]\n",
      "epoch:39 step:187120[D loss: 0.999817] [G loss: 1.000143]\n",
      "epoch:39 step:187125[D loss: 0.999918] [G loss: 1.000096]\n",
      "epoch:39 step:187130[D loss: 0.999968] [G loss: 1.000085]\n",
      "epoch:39 step:187135[D loss: 0.999963] [G loss: 1.000095]\n",
      "epoch:39 step:187140[D loss: 1.000042] [G loss: 0.999999]\n",
      "epoch:39 step:187145[D loss: 1.000000] [G loss: 1.000067]\n",
      "epoch:39 step:187150[D loss: 1.000018] [G loss: 0.999931]\n",
      "epoch:39 step:187155[D loss: 0.999925] [G loss: 1.000097]\n",
      "epoch:39 step:187160[D loss: 0.999996] [G loss: 1.000105]\n",
      "epoch:39 step:187165[D loss: 0.999935] [G loss: 1.000131]\n",
      "epoch:39 step:187170[D loss: 0.999987] [G loss: 1.000084]\n",
      "epoch:39 step:187175[D loss: 0.999956] [G loss: 1.000085]\n",
      "epoch:39 step:187180[D loss: 0.999983] [G loss: 1.000066]\n",
      "epoch:39 step:187185[D loss: 0.999974] [G loss: 1.000161]\n",
      "epoch:39 step:187190[D loss: 0.999965] [G loss: 1.000075]\n",
      "epoch:39 step:187195[D loss: 1.000034] [G loss: 1.000031]\n",
      "epoch:39 step:187200[D loss: 0.999983] [G loss: 1.000064]\n",
      "epoch:39 step:187205[D loss: 0.999966] [G loss: 1.000078]\n",
      "epoch:39 step:187210[D loss: 0.999972] [G loss: 1.000071]\n",
      "epoch:39 step:187215[D loss: 0.999968] [G loss: 1.000083]\n",
      "epoch:39 step:187220[D loss: 1.000080] [G loss: 0.999963]\n",
      "epoch:39 step:187225[D loss: 0.999974] [G loss: 1.000074]\n",
      "epoch:39 step:187230[D loss: 1.000005] [G loss: 1.000042]\n",
      "epoch:39 step:187235[D loss: 1.000031] [G loss: 1.000023]\n",
      "epoch:39 step:187240[D loss: 0.999976] [G loss: 1.000042]\n",
      "epoch:39 step:187245[D loss: 1.000045] [G loss: 1.000061]\n",
      "epoch:39 step:187250[D loss: 0.999961] [G loss: 1.000046]\n",
      "epoch:39 step:187255[D loss: 1.000101] [G loss: 0.999951]\n",
      "epoch:39 step:187260[D loss: 0.999914] [G loss: 1.000088]\n",
      "epoch:39 step:187265[D loss: 0.999935] [G loss: 0.999988]\n",
      "epoch:39 step:187270[D loss: 0.999972] [G loss: 1.000069]\n",
      "epoch:39 step:187275[D loss: 0.999977] [G loss: 1.000044]\n",
      "epoch:39 step:187280[D loss: 1.000035] [G loss: 0.999893]\n",
      "epoch:39 step:187285[D loss: 0.999965] [G loss: 1.000076]\n",
      "epoch:39 step:187290[D loss: 0.999989] [G loss: 1.000068]\n",
      "epoch:39 step:187295[D loss: 0.999961] [G loss: 1.000078]\n",
      "epoch:39 step:187300[D loss: 1.000138] [G loss: 0.999936]\n",
      "epoch:39 step:187305[D loss: 0.999982] [G loss: 0.999984]\n",
      "epoch:39 step:187310[D loss: 0.999967] [G loss: 0.999999]\n",
      "epoch:39 step:187315[D loss: 0.999991] [G loss: 1.000027]\n",
      "epoch:39 step:187320[D loss: 1.000023] [G loss: 1.000019]\n",
      "epoch:39 step:187325[D loss: 0.999970] [G loss: 1.000084]\n",
      "epoch:39 step:187330[D loss: 0.999941] [G loss: 1.000092]\n",
      "epoch:39 step:187335[D loss: 0.999963] [G loss: 1.000077]\n",
      "epoch:39 step:187340[D loss: 0.999958] [G loss: 1.000044]\n",
      "epoch:39 step:187345[D loss: 0.999969] [G loss: 1.000053]\n",
      "epoch:39 step:187350[D loss: 1.000029] [G loss: 0.999974]\n",
      "epoch:39 step:187355[D loss: 0.999999] [G loss: 1.000041]\n",
      "epoch:39 step:187360[D loss: 0.999945] [G loss: 1.000069]\n",
      "epoch:39 step:187365[D loss: 0.999946] [G loss: 1.000110]\n",
      "epoch:39 step:187370[D loss: 0.999969] [G loss: 1.000055]\n",
      "epoch:39 step:187375[D loss: 0.999982] [G loss: 1.000044]\n",
      "epoch:39 step:187380[D loss: 1.000067] [G loss: 0.999951]\n",
      "epoch:39 step:187385[D loss: 0.999933] [G loss: 1.000158]\n",
      "epoch:39 step:187390[D loss: 0.999979] [G loss: 1.000067]\n",
      "epoch:39 step:187395[D loss: 0.999974] [G loss: 1.000078]\n",
      "epoch:39 step:187400[D loss: 1.000046] [G loss: 0.999953]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = fashion_mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of images\n",
    "                    # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    # imgs = X_train[idx]\n",
    "\n",
    "                    # Sample noise as generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                    # Generate a batch of new images\n",
    "                    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                    # Train the critic\n",
    "                    d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                    d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                    d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                    # Clip critic weights\n",
    "                    for l in self.critic.layers:\n",
    "                        weights = l.get_weights()\n",
    "                        weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                        l.set_weights(weights)\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d[D loss: %f] [G loss: %f]\" % (epoch, global_step, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch, global_step)\n",
    "\n",
    "    def sample_images(self, epoch, global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_wgan_fashion_mnist'):\n",
    "            os.mkdir('images_wgan_fashion_mnist')\n",
    "        fig.savefig(\"images_wgan_fashion_mnist/epoch_%d_step_%d.png\" % (epoch, global_step))\n",
    "        plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGAN()\n",
    "    wgan.train(epochs=40, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
