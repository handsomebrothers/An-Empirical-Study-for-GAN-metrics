{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.292869, acc.: 68.75%] [G loss: 0.837729]\n",
      "epoch:0 step:2 [D loss: 2.628053, acc.: 39.84%] [G loss: 1.100568]\n",
      "epoch:0 step:3 [D loss: 0.548781, acc.: 38.28%] [G loss: 0.949492]\n",
      "epoch:0 step:4 [D loss: 0.190073, acc.: 78.91%] [G loss: 0.935954]\n",
      "epoch:0 step:5 [D loss: 0.263412, acc.: 62.50%] [G loss: 0.866519]\n",
      "epoch:0 step:6 [D loss: 0.198448, acc.: 75.00%] [G loss: 0.851447]\n",
      "epoch:0 step:7 [D loss: 0.141225, acc.: 82.81%] [G loss: 1.020959]\n",
      "epoch:0 step:8 [D loss: 0.133630, acc.: 81.25%] [G loss: 1.052579]\n",
      "epoch:0 step:9 [D loss: 0.144996, acc.: 81.25%] [G loss: 0.980982]\n",
      "epoch:0 step:10 [D loss: 0.122165, acc.: 85.94%] [G loss: 0.926761]\n",
      "epoch:0 step:11 [D loss: 0.099432, acc.: 90.62%] [G loss: 1.027935]\n",
      "epoch:0 step:12 [D loss: 0.163766, acc.: 76.56%] [G loss: 0.920839]\n",
      "epoch:0 step:13 [D loss: 0.132623, acc.: 82.81%] [G loss: 1.037970]\n",
      "epoch:0 step:14 [D loss: 0.218907, acc.: 67.97%] [G loss: 0.887577]\n",
      "epoch:0 step:15 [D loss: 0.469538, acc.: 40.62%] [G loss: 0.951429]\n",
      "epoch:0 step:16 [D loss: 0.940237, acc.: 38.28%] [G loss: 0.957551]\n",
      "epoch:0 step:17 [D loss: 1.392805, acc.: 39.06%] [G loss: 0.875818]\n",
      "epoch:0 step:18 [D loss: 0.884825, acc.: 39.06%] [G loss: 0.880257]\n",
      "epoch:0 step:19 [D loss: 0.190024, acc.: 74.22%] [G loss: 1.090546]\n",
      "epoch:0 step:20 [D loss: 0.091695, acc.: 89.84%] [G loss: 1.031004]\n",
      "epoch:0 step:21 [D loss: 0.118223, acc.: 89.06%] [G loss: 0.973296]\n",
      "epoch:0 step:22 [D loss: 0.112802, acc.: 85.16%] [G loss: 1.132493]\n",
      "epoch:0 step:23 [D loss: 0.100869, acc.: 89.06%] [G loss: 1.053318]\n",
      "epoch:0 step:24 [D loss: 0.093422, acc.: 89.84%] [G loss: 1.126890]\n",
      "epoch:0 step:25 [D loss: 0.122355, acc.: 85.16%] [G loss: 1.094924]\n",
      "epoch:0 step:26 [D loss: 0.083793, acc.: 90.62%] [G loss: 1.017104]\n",
      "epoch:0 step:27 [D loss: 0.108617, acc.: 84.38%] [G loss: 1.077522]\n",
      "epoch:0 step:28 [D loss: 0.093310, acc.: 88.28%] [G loss: 0.966698]\n",
      "epoch:0 step:29 [D loss: 0.102260, acc.: 85.16%] [G loss: 0.965688]\n",
      "epoch:0 step:30 [D loss: 0.103789, acc.: 82.81%] [G loss: 0.957796]\n",
      "epoch:0 step:31 [D loss: 0.117252, acc.: 85.16%] [G loss: 1.053267]\n",
      "epoch:0 step:32 [D loss: 0.127022, acc.: 82.81%] [G loss: 1.114994]\n",
      "epoch:0 step:33 [D loss: 0.156399, acc.: 82.81%] [G loss: 1.180344]\n",
      "epoch:0 step:34 [D loss: 0.098342, acc.: 86.72%] [G loss: 1.169410]\n",
      "epoch:0 step:35 [D loss: 0.083246, acc.: 92.97%] [G loss: 1.075930]\n",
      "epoch:0 step:36 [D loss: 0.137693, acc.: 85.94%] [G loss: 1.040040]\n",
      "epoch:0 step:37 [D loss: 0.080670, acc.: 92.19%] [G loss: 1.379457]\n",
      "epoch:0 step:38 [D loss: 0.098613, acc.: 89.06%] [G loss: 1.060957]\n",
      "epoch:0 step:39 [D loss: 0.090384, acc.: 88.28%] [G loss: 1.042482]\n",
      "epoch:0 step:40 [D loss: 0.090058, acc.: 91.41%] [G loss: 1.121387]\n",
      "epoch:0 step:41 [D loss: 0.072463, acc.: 91.41%] [G loss: 1.074846]\n",
      "epoch:0 step:42 [D loss: 0.085559, acc.: 93.75%] [G loss: 0.985198]\n",
      "epoch:0 step:43 [D loss: 0.115378, acc.: 85.16%] [G loss: 0.952611]\n",
      "epoch:0 step:44 [D loss: 0.113205, acc.: 86.72%] [G loss: 1.100130]\n",
      "epoch:0 step:45 [D loss: 0.083170, acc.: 90.62%] [G loss: 0.920193]\n",
      "epoch:0 step:46 [D loss: 0.108550, acc.: 89.06%] [G loss: 1.005665]\n",
      "epoch:0 step:47 [D loss: 0.136081, acc.: 87.50%] [G loss: 0.964639]\n",
      "epoch:0 step:48 [D loss: 0.195893, acc.: 75.78%] [G loss: 1.136192]\n",
      "epoch:0 step:49 [D loss: 0.224317, acc.: 59.38%] [G loss: 0.865119]\n",
      "epoch:0 step:50 [D loss: 0.289598, acc.: 50.78%] [G loss: 1.231475]\n",
      "epoch:0 step:51 [D loss: 0.370954, acc.: 38.28%] [G loss: 1.070126]\n",
      "epoch:0 step:52 [D loss: 0.429909, acc.: 42.19%] [G loss: 0.968728]\n",
      "epoch:0 step:53 [D loss: 0.447836, acc.: 43.75%] [G loss: 0.919984]\n",
      "epoch:0 step:54 [D loss: 0.298902, acc.: 43.75%] [G loss: 1.056045]\n",
      "epoch:0 step:55 [D loss: 0.142275, acc.: 82.03%] [G loss: 0.990230]\n",
      "epoch:0 step:56 [D loss: 0.069287, acc.: 94.53%] [G loss: 1.139851]\n",
      "epoch:0 step:57 [D loss: 0.073267, acc.: 92.19%] [G loss: 1.015340]\n",
      "epoch:0 step:58 [D loss: 0.063816, acc.: 92.97%] [G loss: 1.080103]\n",
      "epoch:0 step:59 [D loss: 0.078613, acc.: 89.84%] [G loss: 0.987971]\n",
      "epoch:0 step:60 [D loss: 0.091531, acc.: 90.62%] [G loss: 0.828950]\n",
      "epoch:0 step:61 [D loss: 0.088592, acc.: 89.84%] [G loss: 1.019806]\n",
      "epoch:0 step:62 [D loss: 0.067479, acc.: 92.19%] [G loss: 1.134020]\n",
      "epoch:0 step:63 [D loss: 0.073297, acc.: 92.19%] [G loss: 1.301823]\n",
      "epoch:0 step:64 [D loss: 0.069364, acc.: 91.41%] [G loss: 0.964231]\n",
      "epoch:0 step:65 [D loss: 0.082439, acc.: 89.84%] [G loss: 1.070634]\n",
      "epoch:0 step:66 [D loss: 0.084673, acc.: 91.41%] [G loss: 0.979320]\n",
      "epoch:0 step:67 [D loss: 0.110581, acc.: 89.06%] [G loss: 1.109817]\n",
      "epoch:0 step:68 [D loss: 0.076864, acc.: 92.19%] [G loss: 1.208159]\n",
      "epoch:0 step:69 [D loss: 0.063238, acc.: 92.97%] [G loss: 1.037893]\n",
      "epoch:0 step:70 [D loss: 0.077055, acc.: 92.19%] [G loss: 0.866371]\n",
      "epoch:0 step:71 [D loss: 0.099436, acc.: 89.84%] [G loss: 0.971869]\n",
      "epoch:0 step:72 [D loss: 0.072601, acc.: 90.62%] [G loss: 1.026105]\n",
      "epoch:0 step:73 [D loss: 0.044724, acc.: 96.09%] [G loss: 1.077256]\n",
      "epoch:0 step:74 [D loss: 0.056546, acc.: 94.53%] [G loss: 0.983317]\n",
      "epoch:0 step:75 [D loss: 0.084479, acc.: 90.62%] [G loss: 0.917050]\n",
      "epoch:0 step:76 [D loss: 0.105124, acc.: 88.28%] [G loss: 0.860059]\n",
      "epoch:0 step:77 [D loss: 0.095320, acc.: 91.41%] [G loss: 0.971350]\n",
      "epoch:0 step:78 [D loss: 0.081839, acc.: 92.19%] [G loss: 0.936548]\n",
      "epoch:0 step:79 [D loss: 0.094022, acc.: 89.84%] [G loss: 0.933333]\n",
      "epoch:0 step:80 [D loss: 0.084445, acc.: 89.06%] [G loss: 1.039236]\n",
      "epoch:0 step:81 [D loss: 0.055346, acc.: 95.31%] [G loss: 1.064994]\n",
      "epoch:0 step:82 [D loss: 0.059575, acc.: 92.97%] [G loss: 0.956714]\n",
      "epoch:0 step:83 [D loss: 0.096245, acc.: 88.28%] [G loss: 1.034748]\n",
      "epoch:0 step:84 [D loss: 0.057960, acc.: 93.75%] [G loss: 0.988814]\n",
      "epoch:0 step:85 [D loss: 0.067756, acc.: 93.75%] [G loss: 1.149988]\n",
      "epoch:0 step:86 [D loss: 0.054350, acc.: 93.75%] [G loss: 0.940233]\n",
      "epoch:0 step:87 [D loss: 0.051773, acc.: 92.19%] [G loss: 1.085113]\n",
      "epoch:0 step:88 [D loss: 0.047715, acc.: 96.88%] [G loss: 1.144054]\n",
      "epoch:0 step:89 [D loss: 0.060617, acc.: 93.75%] [G loss: 1.157825]\n",
      "epoch:0 step:90 [D loss: 0.065613, acc.: 92.19%] [G loss: 0.956349]\n",
      "epoch:0 step:91 [D loss: 0.074660, acc.: 93.75%] [G loss: 0.908116]\n",
      "epoch:0 step:92 [D loss: 0.096984, acc.: 86.72%] [G loss: 1.146005]\n",
      "epoch:0 step:93 [D loss: 0.111405, acc.: 85.94%] [G loss: 1.003048]\n",
      "epoch:0 step:94 [D loss: 0.119773, acc.: 84.38%] [G loss: 1.053459]\n",
      "epoch:0 step:95 [D loss: 0.089863, acc.: 92.97%] [G loss: 1.194264]\n",
      "epoch:0 step:96 [D loss: 0.101498, acc.: 91.41%] [G loss: 1.035773]\n",
      "epoch:0 step:97 [D loss: 0.086580, acc.: 91.41%] [G loss: 0.912480]\n",
      "epoch:0 step:98 [D loss: 0.104160, acc.: 86.72%] [G loss: 0.922807]\n",
      "epoch:0 step:99 [D loss: 0.089445, acc.: 93.75%] [G loss: 0.899520]\n",
      "epoch:0 step:100 [D loss: 0.090794, acc.: 92.97%] [G loss: 0.947437]\n",
      "epoch:0 step:101 [D loss: 0.075113, acc.: 94.53%] [G loss: 1.104295]\n",
      "epoch:0 step:102 [D loss: 0.090954, acc.: 92.97%] [G loss: 0.901297]\n",
      "epoch:0 step:103 [D loss: 0.124602, acc.: 87.50%] [G loss: 1.012335]\n",
      "epoch:0 step:104 [D loss: 0.218982, acc.: 75.78%] [G loss: 0.948841]\n",
      "epoch:0 step:105 [D loss: 0.227689, acc.: 75.00%] [G loss: 1.318295]\n",
      "epoch:0 step:106 [D loss: 0.265148, acc.: 71.09%] [G loss: 1.102005]\n",
      "epoch:0 step:107 [D loss: 0.194291, acc.: 75.78%] [G loss: 1.245103]\n",
      "epoch:0 step:108 [D loss: 0.157171, acc.: 82.81%] [G loss: 1.143881]\n",
      "epoch:0 step:109 [D loss: 0.074043, acc.: 96.09%] [G loss: 1.073293]\n",
      "epoch:0 step:110 [D loss: 0.065178, acc.: 93.75%] [G loss: 0.981446]\n",
      "epoch:0 step:111 [D loss: 0.065727, acc.: 94.53%] [G loss: 0.916972]\n",
      "epoch:0 step:112 [D loss: 0.045249, acc.: 96.88%] [G loss: 0.901778]\n",
      "epoch:0 step:113 [D loss: 0.059962, acc.: 95.31%] [G loss: 0.998073]\n",
      "epoch:0 step:114 [D loss: 0.078817, acc.: 89.06%] [G loss: 1.109812]\n",
      "epoch:0 step:115 [D loss: 0.093678, acc.: 88.28%] [G loss: 0.957094]\n",
      "epoch:0 step:116 [D loss: 0.110094, acc.: 85.16%] [G loss: 0.691169]\n",
      "epoch:0 step:117 [D loss: 0.106651, acc.: 84.38%] [G loss: 0.721885]\n",
      "epoch:0 step:118 [D loss: 0.067064, acc.: 92.97%] [G loss: 0.878982]\n",
      "epoch:0 step:119 [D loss: 0.056839, acc.: 94.53%] [G loss: 0.986010]\n",
      "epoch:0 step:120 [D loss: 0.046591, acc.: 96.88%] [G loss: 0.989821]\n",
      "epoch:0 step:121 [D loss: 0.037396, acc.: 96.88%] [G loss: 1.111912]\n",
      "epoch:0 step:122 [D loss: 0.037005, acc.: 98.44%] [G loss: 1.191473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:123 [D loss: 0.039231, acc.: 97.66%] [G loss: 1.127414]\n",
      "epoch:0 step:124 [D loss: 0.048097, acc.: 96.09%] [G loss: 0.833695]\n",
      "epoch:0 step:125 [D loss: 0.044648, acc.: 96.09%] [G loss: 1.014460]\n",
      "epoch:0 step:126 [D loss: 0.036737, acc.: 98.44%] [G loss: 0.970165]\n",
      "epoch:0 step:127 [D loss: 0.039463, acc.: 98.44%] [G loss: 1.161327]\n",
      "epoch:0 step:128 [D loss: 0.051928, acc.: 96.88%] [G loss: 0.945276]\n",
      "epoch:0 step:129 [D loss: 0.068303, acc.: 91.41%] [G loss: 0.842481]\n",
      "epoch:0 step:130 [D loss: 0.082397, acc.: 89.06%] [G loss: 0.971017]\n",
      "epoch:0 step:131 [D loss: 0.102991, acc.: 83.59%] [G loss: 0.956188]\n",
      "epoch:0 step:132 [D loss: 0.127116, acc.: 82.81%] [G loss: 1.020632]\n",
      "epoch:0 step:133 [D loss: 0.162610, acc.: 79.69%] [G loss: 0.924660]\n",
      "epoch:0 step:134 [D loss: 0.192542, acc.: 74.22%] [G loss: 0.976635]\n",
      "epoch:0 step:135 [D loss: 0.185557, acc.: 71.88%] [G loss: 0.901361]\n",
      "epoch:0 step:136 [D loss: 0.087966, acc.: 90.62%] [G loss: 1.051427]\n",
      "epoch:0 step:137 [D loss: 0.081878, acc.: 89.84%] [G loss: 1.000533]\n",
      "epoch:0 step:138 [D loss: 0.082332, acc.: 89.84%] [G loss: 1.000341]\n",
      "epoch:0 step:139 [D loss: 0.088063, acc.: 89.84%] [G loss: 0.962301]\n",
      "epoch:0 step:140 [D loss: 0.037966, acc.: 99.22%] [G loss: 1.153791]\n",
      "epoch:0 step:141 [D loss: 0.044301, acc.: 96.88%] [G loss: 0.925112]\n",
      "epoch:0 step:142 [D loss: 0.039289, acc.: 96.88%] [G loss: 0.863768]\n",
      "epoch:0 step:143 [D loss: 0.035522, acc.: 98.44%] [G loss: 1.017167]\n",
      "epoch:0 step:144 [D loss: 0.038593, acc.: 98.44%] [G loss: 1.202536]\n",
      "epoch:0 step:145 [D loss: 0.036882, acc.: 98.44%] [G loss: 0.959781]\n",
      "epoch:0 step:146 [D loss: 0.035189, acc.: 98.44%] [G loss: 1.010252]\n",
      "epoch:0 step:147 [D loss: 0.036166, acc.: 97.66%] [G loss: 0.913481]\n",
      "epoch:0 step:148 [D loss: 0.060402, acc.: 94.53%] [G loss: 1.027665]\n",
      "epoch:0 step:149 [D loss: 0.049408, acc.: 97.66%] [G loss: 0.869757]\n",
      "epoch:0 step:150 [D loss: 0.047678, acc.: 95.31%] [G loss: 0.931658]\n",
      "epoch:0 step:151 [D loss: 0.056251, acc.: 93.75%] [G loss: 0.970247]\n",
      "epoch:0 step:152 [D loss: 0.071158, acc.: 92.97%] [G loss: 0.945074]\n",
      "epoch:0 step:153 [D loss: 0.090738, acc.: 86.72%] [G loss: 1.035392]\n",
      "epoch:0 step:154 [D loss: 0.082080, acc.: 89.06%] [G loss: 1.050988]\n",
      "epoch:0 step:155 [D loss: 0.086882, acc.: 88.28%] [G loss: 0.912972]\n",
      "epoch:0 step:156 [D loss: 0.072400, acc.: 89.84%] [G loss: 1.021145]\n",
      "epoch:0 step:157 [D loss: 0.075435, acc.: 92.19%] [G loss: 0.931615]\n",
      "epoch:0 step:158 [D loss: 0.069496, acc.: 98.44%] [G loss: 1.092886]\n",
      "epoch:0 step:159 [D loss: 0.095248, acc.: 92.97%] [G loss: 0.951210]\n",
      "epoch:0 step:160 [D loss: 0.077909, acc.: 96.88%] [G loss: 1.099755]\n",
      "epoch:0 step:161 [D loss: 0.093781, acc.: 89.84%] [G loss: 0.865944]\n",
      "epoch:0 step:162 [D loss: 0.091551, acc.: 95.31%] [G loss: 1.004791]\n",
      "epoch:0 step:163 [D loss: 0.144945, acc.: 83.59%] [G loss: 0.896713]\n",
      "epoch:0 step:164 [D loss: 0.130414, acc.: 89.06%] [G loss: 1.161439]\n",
      "epoch:0 step:165 [D loss: 0.159292, acc.: 78.91%] [G loss: 0.795816]\n",
      "epoch:0 step:166 [D loss: 0.117852, acc.: 92.97%] [G loss: 1.082304]\n",
      "epoch:0 step:167 [D loss: 0.114959, acc.: 90.62%] [G loss: 0.779839]\n",
      "epoch:0 step:168 [D loss: 0.084342, acc.: 92.97%] [G loss: 1.097061]\n",
      "epoch:0 step:169 [D loss: 0.058332, acc.: 97.66%] [G loss: 0.959143]\n",
      "epoch:0 step:170 [D loss: 0.031482, acc.: 99.22%] [G loss: 1.062361]\n",
      "epoch:0 step:171 [D loss: 0.037719, acc.: 98.44%] [G loss: 0.971898]\n",
      "epoch:0 step:172 [D loss: 0.023310, acc.: 100.00%] [G loss: 0.915533]\n",
      "epoch:0 step:173 [D loss: 0.025727, acc.: 100.00%] [G loss: 0.886538]\n",
      "epoch:0 step:174 [D loss: 0.026383, acc.: 100.00%] [G loss: 0.983877]\n",
      "epoch:0 step:175 [D loss: 0.027888, acc.: 100.00%] [G loss: 1.133554]\n",
      "epoch:0 step:176 [D loss: 0.025567, acc.: 98.44%] [G loss: 0.924104]\n",
      "epoch:0 step:177 [D loss: 0.028691, acc.: 100.00%] [G loss: 0.959687]\n",
      "epoch:0 step:178 [D loss: 0.031707, acc.: 100.00%] [G loss: 0.928946]\n",
      "epoch:0 step:179 [D loss: 0.032996, acc.: 98.44%] [G loss: 1.076449]\n",
      "epoch:0 step:180 [D loss: 0.027481, acc.: 100.00%] [G loss: 0.967057]\n",
      "epoch:0 step:181 [D loss: 0.025969, acc.: 98.44%] [G loss: 0.874139]\n",
      "epoch:0 step:182 [D loss: 0.030985, acc.: 98.44%] [G loss: 0.985817]\n",
      "epoch:0 step:183 [D loss: 0.022457, acc.: 99.22%] [G loss: 0.942301]\n",
      "epoch:0 step:184 [D loss: 0.016215, acc.: 100.00%] [G loss: 1.005938]\n",
      "epoch:0 step:185 [D loss: 0.021484, acc.: 100.00%] [G loss: 0.999430]\n",
      "epoch:0 step:186 [D loss: 0.036943, acc.: 97.66%] [G loss: 1.058919]\n",
      "epoch:0 step:187 [D loss: 0.033522, acc.: 99.22%] [G loss: 0.920624]\n",
      "epoch:0 step:188 [D loss: 0.030724, acc.: 100.00%] [G loss: 1.012717]\n",
      "epoch:0 step:189 [D loss: 0.031452, acc.: 100.00%] [G loss: 1.073739]\n",
      "epoch:0 step:190 [D loss: 0.052261, acc.: 98.44%] [G loss: 0.992102]\n",
      "epoch:0 step:191 [D loss: 0.055819, acc.: 99.22%] [G loss: 0.953394]\n",
      "epoch:0 step:192 [D loss: 0.117144, acc.: 83.59%] [G loss: 0.781544]\n",
      "epoch:0 step:193 [D loss: 0.151304, acc.: 82.81%] [G loss: 1.116832]\n",
      "epoch:0 step:194 [D loss: 0.226648, acc.: 71.09%] [G loss: 0.589248]\n",
      "epoch:0 step:195 [D loss: 0.242369, acc.: 65.62%] [G loss: 0.770828]\n",
      "epoch:0 step:196 [D loss: 0.220497, acc.: 71.09%] [G loss: 0.640947]\n",
      "epoch:0 step:197 [D loss: 0.067031, acc.: 97.66%] [G loss: 0.984485]\n",
      "epoch:0 step:198 [D loss: 0.054429, acc.: 98.44%] [G loss: 0.961131]\n",
      "epoch:0 step:199 [D loss: 0.032139, acc.: 99.22%] [G loss: 0.910931]\n",
      "epoch:0 step:200 [D loss: 0.037874, acc.: 99.22%] [G loss: 0.858385]\n",
      "epoch:0 step:201 [D loss: 0.041213, acc.: 98.44%] [G loss: 1.011606]\n",
      "epoch:0 step:202 [D loss: 0.056199, acc.: 96.88%] [G loss: 0.920766]\n",
      "epoch:0 step:203 [D loss: 0.032381, acc.: 98.44%] [G loss: 1.004415]\n",
      "epoch:0 step:204 [D loss: 0.023882, acc.: 100.00%] [G loss: 0.999517]\n",
      "epoch:0 step:205 [D loss: 0.035032, acc.: 97.66%] [G loss: 0.904897]\n",
      "epoch:0 step:206 [D loss: 0.030780, acc.: 100.00%] [G loss: 0.950484]\n",
      "epoch:0 step:207 [D loss: 0.044775, acc.: 97.66%] [G loss: 0.841234]\n",
      "epoch:0 step:208 [D loss: 0.037652, acc.: 97.66%] [G loss: 0.858990]\n",
      "epoch:0 step:209 [D loss: 0.043994, acc.: 97.66%] [G loss: 0.897243]\n",
      "epoch:0 step:210 [D loss: 0.029837, acc.: 98.44%] [G loss: 1.007191]\n",
      "epoch:0 step:211 [D loss: 0.035564, acc.: 99.22%] [G loss: 0.877591]\n",
      "epoch:0 step:212 [D loss: 0.037518, acc.: 97.66%] [G loss: 0.984602]\n",
      "epoch:0 step:213 [D loss: 0.040533, acc.: 98.44%] [G loss: 0.902733]\n",
      "epoch:0 step:214 [D loss: 0.031559, acc.: 97.66%] [G loss: 0.945026]\n",
      "epoch:0 step:215 [D loss: 0.027499, acc.: 97.66%] [G loss: 0.931968]\n",
      "epoch:0 step:216 [D loss: 0.021470, acc.: 99.22%] [G loss: 1.032400]\n",
      "epoch:0 step:217 [D loss: 0.029364, acc.: 99.22%] [G loss: 1.017879]\n",
      "epoch:0 step:218 [D loss: 0.024137, acc.: 100.00%] [G loss: 0.953550]\n",
      "epoch:0 step:219 [D loss: 0.035265, acc.: 99.22%] [G loss: 0.823682]\n",
      "epoch:0 step:220 [D loss: 0.044205, acc.: 95.31%] [G loss: 1.009057]\n",
      "epoch:0 step:221 [D loss: 0.044812, acc.: 95.31%] [G loss: 0.877817]\n",
      "epoch:0 step:222 [D loss: 0.041847, acc.: 98.44%] [G loss: 0.855397]\n",
      "epoch:0 step:223 [D loss: 0.044285, acc.: 98.44%] [G loss: 1.014798]\n",
      "epoch:0 step:224 [D loss: 0.064703, acc.: 96.09%] [G loss: 0.999523]\n",
      "epoch:0 step:225 [D loss: 0.059847, acc.: 97.66%] [G loss: 0.936647]\n",
      "epoch:0 step:226 [D loss: 0.081672, acc.: 92.97%] [G loss: 0.877305]\n",
      "epoch:0 step:227 [D loss: 0.048129, acc.: 100.00%] [G loss: 0.983061]\n",
      "epoch:0 step:228 [D loss: 0.116320, acc.: 89.84%] [G loss: 0.741352]\n",
      "epoch:0 step:229 [D loss: 0.075306, acc.: 96.88%] [G loss: 1.153543]\n",
      "epoch:0 step:230 [D loss: 0.146676, acc.: 82.03%] [G loss: 0.734459]\n",
      "epoch:0 step:231 [D loss: 0.208101, acc.: 56.25%] [G loss: 1.091260]\n",
      "epoch:0 step:232 [D loss: 0.362001, acc.: 47.66%] [G loss: 0.603200]\n",
      "epoch:0 step:233 [D loss: 0.212479, acc.: 59.38%] [G loss: 1.007677]\n",
      "epoch:0 step:234 [D loss: 0.171842, acc.: 67.19%] [G loss: 0.868639]\n",
      "epoch:0 step:235 [D loss: 0.087282, acc.: 94.53%] [G loss: 0.971169]\n",
      "epoch:0 step:236 [D loss: 0.059018, acc.: 98.44%] [G loss: 0.841993]\n",
      "epoch:0 step:237 [D loss: 0.037641, acc.: 96.09%] [G loss: 0.750147]\n",
      "epoch:0 step:238 [D loss: 0.039899, acc.: 98.44%] [G loss: 0.934551]\n",
      "epoch:0 step:239 [D loss: 0.037702, acc.: 98.44%] [G loss: 0.913515]\n",
      "epoch:0 step:240 [D loss: 0.039812, acc.: 96.09%] [G loss: 0.992972]\n",
      "epoch:0 step:241 [D loss: 0.031989, acc.: 97.66%] [G loss: 0.924063]\n",
      "epoch:0 step:242 [D loss: 0.043104, acc.: 94.53%] [G loss: 1.012954]\n",
      "epoch:0 step:243 [D loss: 0.042462, acc.: 96.88%] [G loss: 0.911246]\n",
      "epoch:0 step:244 [D loss: 0.037027, acc.: 96.09%] [G loss: 0.819762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:245 [D loss: 0.038958, acc.: 97.66%] [G loss: 0.892798]\n",
      "epoch:0 step:246 [D loss: 0.028661, acc.: 99.22%] [G loss: 0.907781]\n",
      "epoch:0 step:247 [D loss: 0.048008, acc.: 93.75%] [G loss: 0.867638]\n",
      "epoch:0 step:248 [D loss: 0.051388, acc.: 93.75%] [G loss: 0.873442]\n",
      "epoch:0 step:249 [D loss: 0.037752, acc.: 96.09%] [G loss: 0.864442]\n",
      "epoch:0 step:250 [D loss: 0.037225, acc.: 96.09%] [G loss: 1.014658]\n",
      "epoch:0 step:251 [D loss: 0.052702, acc.: 95.31%] [G loss: 0.840049]\n",
      "epoch:0 step:252 [D loss: 0.052476, acc.: 93.75%] [G loss: 0.940374]\n",
      "epoch:0 step:253 [D loss: 0.031450, acc.: 96.88%] [G loss: 0.925862]\n",
      "epoch:0 step:254 [D loss: 0.032462, acc.: 96.88%] [G loss: 0.913063]\n",
      "epoch:0 step:255 [D loss: 0.058091, acc.: 90.62%] [G loss: 0.870694]\n",
      "epoch:0 step:256 [D loss: 0.042752, acc.: 96.09%] [G loss: 0.953492]\n",
      "epoch:0 step:257 [D loss: 0.049753, acc.: 96.09%] [G loss: 0.885050]\n",
      "epoch:0 step:258 [D loss: 0.058887, acc.: 92.19%] [G loss: 0.906096]\n",
      "epoch:0 step:259 [D loss: 0.035261, acc.: 97.66%] [G loss: 0.929089]\n",
      "epoch:0 step:260 [D loss: 0.041762, acc.: 93.75%] [G loss: 0.942294]\n",
      "epoch:0 step:261 [D loss: 0.056167, acc.: 92.97%] [G loss: 0.889244]\n",
      "epoch:0 step:262 [D loss: 0.031402, acc.: 99.22%] [G loss: 0.913502]\n",
      "epoch:0 step:263 [D loss: 0.064203, acc.: 92.19%] [G loss: 0.926224]\n",
      "epoch:0 step:264 [D loss: 0.041173, acc.: 95.31%] [G loss: 0.960509]\n",
      "epoch:0 step:265 [D loss: 0.081709, acc.: 92.19%] [G loss: 0.774498]\n",
      "epoch:0 step:266 [D loss: 0.040739, acc.: 98.44%] [G loss: 1.068972]\n",
      "epoch:0 step:267 [D loss: 0.061269, acc.: 95.31%] [G loss: 0.863696]\n",
      "epoch:0 step:268 [D loss: 0.059249, acc.: 94.53%] [G loss: 0.950201]\n",
      "epoch:0 step:269 [D loss: 0.078816, acc.: 93.75%] [G loss: 0.740872]\n",
      "epoch:0 step:270 [D loss: 0.045373, acc.: 98.44%] [G loss: 1.042094]\n",
      "epoch:0 step:271 [D loss: 0.085902, acc.: 90.62%] [G loss: 0.845135]\n",
      "epoch:0 step:272 [D loss: 0.076473, acc.: 90.62%] [G loss: 0.919718]\n",
      "epoch:0 step:273 [D loss: 0.132657, acc.: 84.38%] [G loss: 0.753864]\n",
      "epoch:0 step:274 [D loss: 0.050060, acc.: 93.75%] [G loss: 0.987158]\n",
      "epoch:0 step:275 [D loss: 0.064611, acc.: 92.97%] [G loss: 1.012421]\n",
      "epoch:0 step:276 [D loss: 0.047240, acc.: 92.97%] [G loss: 0.897440]\n",
      "epoch:0 step:277 [D loss: 0.060939, acc.: 92.97%] [G loss: 0.869265]\n",
      "epoch:0 step:278 [D loss: 0.043638, acc.: 94.53%] [G loss: 0.934861]\n",
      "epoch:0 step:279 [D loss: 0.048315, acc.: 93.75%] [G loss: 0.944285]\n",
      "epoch:0 step:280 [D loss: 0.036367, acc.: 96.88%] [G loss: 0.936915]\n",
      "epoch:0 step:281 [D loss: 0.090660, acc.: 89.06%] [G loss: 0.765033]\n",
      "epoch:0 step:282 [D loss: 0.050727, acc.: 92.19%] [G loss: 0.969231]\n",
      "epoch:0 step:283 [D loss: 0.122271, acc.: 85.16%] [G loss: 0.707414]\n",
      "epoch:0 step:284 [D loss: 0.067312, acc.: 95.31%] [G loss: 1.084426]\n",
      "epoch:0 step:285 [D loss: 0.140947, acc.: 83.59%] [G loss: 0.785296]\n",
      "epoch:0 step:286 [D loss: 0.047287, acc.: 96.88%] [G loss: 0.904500]\n",
      "epoch:0 step:287 [D loss: 0.083085, acc.: 89.84%] [G loss: 0.903337]\n",
      "epoch:0 step:288 [D loss: 0.050828, acc.: 95.31%] [G loss: 0.781766]\n",
      "epoch:0 step:289 [D loss: 0.058819, acc.: 92.97%] [G loss: 0.870430]\n",
      "epoch:0 step:290 [D loss: 0.081310, acc.: 88.28%] [G loss: 1.042414]\n",
      "epoch:0 step:291 [D loss: 0.055516, acc.: 95.31%] [G loss: 0.922417]\n",
      "epoch:0 step:292 [D loss: 0.056073, acc.: 95.31%] [G loss: 0.861076]\n",
      "epoch:0 step:293 [D loss: 0.080127, acc.: 85.16%] [G loss: 0.974305]\n",
      "epoch:0 step:294 [D loss: 0.062560, acc.: 92.97%] [G loss: 0.838220]\n",
      "epoch:0 step:295 [D loss: 0.073329, acc.: 89.06%] [G loss: 0.834154]\n",
      "epoch:0 step:296 [D loss: 0.065822, acc.: 91.41%] [G loss: 0.849247]\n",
      "epoch:0 step:297 [D loss: 0.037521, acc.: 96.88%] [G loss: 0.963299]\n",
      "epoch:0 step:298 [D loss: 0.066907, acc.: 89.84%] [G loss: 0.905186]\n",
      "epoch:0 step:299 [D loss: 0.064760, acc.: 90.62%] [G loss: 1.026325]\n",
      "epoch:0 step:300 [D loss: 0.097008, acc.: 89.84%] [G loss: 0.799200]\n",
      "epoch:0 step:301 [D loss: 0.068092, acc.: 91.41%] [G loss: 0.891619]\n",
      "epoch:0 step:302 [D loss: 0.054711, acc.: 91.41%] [G loss: 0.914968]\n",
      "epoch:0 step:303 [D loss: 0.110517, acc.: 85.16%] [G loss: 0.772638]\n",
      "epoch:0 step:304 [D loss: 0.047577, acc.: 93.75%] [G loss: 1.065078]\n",
      "epoch:0 step:305 [D loss: 0.143234, acc.: 82.03%] [G loss: 0.729618]\n",
      "epoch:0 step:306 [D loss: 0.035521, acc.: 98.44%] [G loss: 1.018390]\n",
      "epoch:0 step:307 [D loss: 0.112903, acc.: 90.62%] [G loss: 0.735605]\n",
      "epoch:0 step:308 [D loss: 0.048726, acc.: 99.22%] [G loss: 1.082329]\n",
      "epoch:0 step:309 [D loss: 0.155402, acc.: 78.12%] [G loss: 0.765129]\n",
      "epoch:0 step:310 [D loss: 0.065933, acc.: 89.84%] [G loss: 1.021997]\n",
      "epoch:0 step:311 [D loss: 0.118069, acc.: 85.16%] [G loss: 0.822306]\n",
      "epoch:0 step:312 [D loss: 0.073812, acc.: 86.72%] [G loss: 0.951259]\n",
      "epoch:0 step:313 [D loss: 0.097068, acc.: 86.72%] [G loss: 0.780596]\n",
      "epoch:0 step:314 [D loss: 0.051750, acc.: 96.88%] [G loss: 0.903988]\n",
      "epoch:0 step:315 [D loss: 0.062947, acc.: 93.75%] [G loss: 0.836635]\n",
      "epoch:0 step:316 [D loss: 0.054379, acc.: 91.41%] [G loss: 0.843421]\n",
      "epoch:0 step:317 [D loss: 0.056452, acc.: 91.41%] [G loss: 0.893443]\n",
      "epoch:0 step:318 [D loss: 0.059601, acc.: 91.41%] [G loss: 0.976341]\n",
      "epoch:0 step:319 [D loss: 0.061913, acc.: 92.19%] [G loss: 0.714668]\n",
      "epoch:0 step:320 [D loss: 0.042303, acc.: 93.75%] [G loss: 0.956186]\n",
      "epoch:0 step:321 [D loss: 0.133414, acc.: 80.47%] [G loss: 0.834368]\n",
      "epoch:0 step:322 [D loss: 0.042511, acc.: 92.97%] [G loss: 0.926594]\n",
      "epoch:0 step:323 [D loss: 0.110145, acc.: 84.38%] [G loss: 0.876724]\n",
      "epoch:0 step:324 [D loss: 0.041688, acc.: 92.19%] [G loss: 0.999279]\n",
      "epoch:0 step:325 [D loss: 0.089270, acc.: 85.94%] [G loss: 0.909848]\n",
      "epoch:0 step:326 [D loss: 0.066287, acc.: 92.19%] [G loss: 0.815040]\n",
      "epoch:0 step:327 [D loss: 0.075798, acc.: 92.19%] [G loss: 0.959973]\n",
      "epoch:0 step:328 [D loss: 0.058102, acc.: 92.19%] [G loss: 0.899682]\n",
      "epoch:0 step:329 [D loss: 0.069448, acc.: 89.84%] [G loss: 0.933121]\n",
      "epoch:0 step:330 [D loss: 0.063309, acc.: 94.53%] [G loss: 0.936451]\n",
      "epoch:0 step:331 [D loss: 0.171087, acc.: 76.56%] [G loss: 0.740347]\n",
      "epoch:0 step:332 [D loss: 0.041077, acc.: 99.22%] [G loss: 1.071440]\n",
      "epoch:0 step:333 [D loss: 0.232512, acc.: 62.50%] [G loss: 0.798890]\n",
      "epoch:0 step:334 [D loss: 0.098920, acc.: 96.88%] [G loss: 1.309525]\n",
      "epoch:0 step:335 [D loss: 0.316879, acc.: 35.94%] [G loss: 0.600095]\n",
      "epoch:0 step:336 [D loss: 0.103374, acc.: 91.41%] [G loss: 1.044926]\n",
      "epoch:0 step:337 [D loss: 0.159321, acc.: 77.34%] [G loss: 0.744258]\n",
      "epoch:0 step:338 [D loss: 0.046527, acc.: 92.19%] [G loss: 0.888892]\n",
      "epoch:0 step:339 [D loss: 0.095430, acc.: 85.94%] [G loss: 0.826969]\n",
      "epoch:0 step:340 [D loss: 0.051683, acc.: 96.88%] [G loss: 0.894403]\n",
      "epoch:0 step:341 [D loss: 0.076004, acc.: 89.06%] [G loss: 0.866368]\n",
      "epoch:0 step:342 [D loss: 0.035557, acc.: 96.09%] [G loss: 0.977915]\n",
      "epoch:0 step:343 [D loss: 0.055481, acc.: 93.75%] [G loss: 1.000879]\n",
      "epoch:0 step:344 [D loss: 0.053212, acc.: 92.97%] [G loss: 0.769105]\n",
      "epoch:0 step:345 [D loss: 0.075380, acc.: 87.50%] [G loss: 0.845690]\n",
      "epoch:0 step:346 [D loss: 0.096802, acc.: 86.72%] [G loss: 0.838668]\n",
      "epoch:0 step:347 [D loss: 0.052344, acc.: 92.97%] [G loss: 0.916380]\n",
      "epoch:0 step:348 [D loss: 0.090183, acc.: 85.94%] [G loss: 0.796224]\n",
      "epoch:0 step:349 [D loss: 0.061399, acc.: 89.84%] [G loss: 0.868320]\n",
      "epoch:0 step:350 [D loss: 0.093774, acc.: 84.38%] [G loss: 0.922502]\n",
      "epoch:0 step:351 [D loss: 0.067620, acc.: 92.19%] [G loss: 0.853049]\n",
      "epoch:0 step:352 [D loss: 0.080944, acc.: 85.94%] [G loss: 0.929535]\n",
      "epoch:0 step:353 [D loss: 0.082142, acc.: 89.06%] [G loss: 0.811468]\n",
      "epoch:0 step:354 [D loss: 0.061961, acc.: 92.97%] [G loss: 0.854121]\n",
      "epoch:0 step:355 [D loss: 0.086519, acc.: 87.50%] [G loss: 0.895130]\n",
      "epoch:0 step:356 [D loss: 0.072535, acc.: 89.06%] [G loss: 0.916433]\n",
      "epoch:0 step:357 [D loss: 0.106394, acc.: 84.38%] [G loss: 0.838615]\n",
      "epoch:0 step:358 [D loss: 0.049917, acc.: 94.53%] [G loss: 0.972205]\n",
      "epoch:0 step:359 [D loss: 0.119169, acc.: 82.81%] [G loss: 0.767660]\n",
      "epoch:0 step:360 [D loss: 0.054122, acc.: 91.41%] [G loss: 0.995785]\n",
      "epoch:0 step:361 [D loss: 0.137116, acc.: 80.47%] [G loss: 0.805955]\n",
      "epoch:0 step:362 [D loss: 0.051029, acc.: 95.31%] [G loss: 1.000811]\n",
      "epoch:0 step:363 [D loss: 0.129110, acc.: 81.25%] [G loss: 0.813265]\n",
      "epoch:0 step:364 [D loss: 0.043775, acc.: 94.53%] [G loss: 0.903190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:365 [D loss: 0.110482, acc.: 89.84%] [G loss: 0.708641]\n",
      "epoch:0 step:366 [D loss: 0.047834, acc.: 92.97%] [G loss: 1.094296]\n",
      "epoch:0 step:367 [D loss: 0.170509, acc.: 73.44%] [G loss: 0.787106]\n",
      "epoch:0 step:368 [D loss: 0.052966, acc.: 92.19%] [G loss: 0.989157]\n",
      "epoch:0 step:369 [D loss: 0.144042, acc.: 81.25%] [G loss: 0.686020]\n",
      "epoch:0 step:370 [D loss: 0.071977, acc.: 92.97%] [G loss: 1.125323]\n",
      "epoch:0 step:371 [D loss: 0.192195, acc.: 66.41%] [G loss: 0.675810]\n",
      "epoch:0 step:372 [D loss: 0.067065, acc.: 94.53%] [G loss: 1.136472]\n",
      "epoch:0 step:373 [D loss: 0.142052, acc.: 78.91%] [G loss: 0.785574]\n",
      "epoch:0 step:374 [D loss: 0.060097, acc.: 89.84%] [G loss: 0.917390]\n",
      "epoch:0 step:375 [D loss: 0.075547, acc.: 92.97%] [G loss: 0.874280]\n",
      "epoch:0 step:376 [D loss: 0.063525, acc.: 90.62%] [G loss: 0.912392]\n",
      "epoch:0 step:377 [D loss: 0.074137, acc.: 88.28%] [G loss: 0.864419]\n",
      "epoch:0 step:378 [D loss: 0.061036, acc.: 91.41%] [G loss: 0.915378]\n",
      "epoch:0 step:379 [D loss: 0.073492, acc.: 88.28%] [G loss: 0.814176]\n",
      "epoch:0 step:380 [D loss: 0.068679, acc.: 91.41%] [G loss: 0.857777]\n",
      "epoch:0 step:381 [D loss: 0.050249, acc.: 92.97%] [G loss: 1.004058]\n",
      "epoch:0 step:382 [D loss: 0.147482, acc.: 76.56%] [G loss: 0.777856]\n",
      "epoch:0 step:383 [D loss: 0.058046, acc.: 91.41%] [G loss: 0.957451]\n",
      "epoch:0 step:384 [D loss: 0.131933, acc.: 82.03%] [G loss: 0.752815]\n",
      "epoch:0 step:385 [D loss: 0.068919, acc.: 87.50%] [G loss: 0.967825]\n",
      "epoch:0 step:386 [D loss: 0.133815, acc.: 78.91%] [G loss: 0.845147]\n",
      "epoch:0 step:387 [D loss: 0.053075, acc.: 94.53%] [G loss: 0.989010]\n",
      "epoch:0 step:388 [D loss: 0.112564, acc.: 85.16%] [G loss: 0.899468]\n",
      "epoch:0 step:389 [D loss: 0.032539, acc.: 96.88%] [G loss: 0.964711]\n",
      "epoch:0 step:390 [D loss: 0.111135, acc.: 79.69%] [G loss: 0.833373]\n",
      "epoch:0 step:391 [D loss: 0.077167, acc.: 84.38%] [G loss: 0.945159]\n",
      "epoch:0 step:392 [D loss: 0.122057, acc.: 83.59%] [G loss: 0.767866]\n",
      "epoch:0 step:393 [D loss: 0.082006, acc.: 87.50%] [G loss: 0.907387]\n",
      "epoch:0 step:394 [D loss: 0.119655, acc.: 82.03%] [G loss: 0.859241]\n",
      "epoch:0 step:395 [D loss: 0.045977, acc.: 92.19%] [G loss: 0.949765]\n",
      "epoch:0 step:396 [D loss: 0.165317, acc.: 78.12%] [G loss: 0.691126]\n",
      "epoch:0 step:397 [D loss: 0.053975, acc.: 100.00%] [G loss: 1.083770]\n",
      "epoch:0 step:398 [D loss: 0.271418, acc.: 50.00%] [G loss: 0.616095]\n",
      "epoch:0 step:399 [D loss: 0.066842, acc.: 98.44%] [G loss: 1.137219]\n",
      "epoch:0 step:400 [D loss: 0.237677, acc.: 52.34%] [G loss: 0.695159]\n",
      "epoch:0 step:401 [D loss: 0.088464, acc.: 87.50%] [G loss: 1.059308]\n",
      "epoch:0 step:402 [D loss: 0.158571, acc.: 75.00%] [G loss: 0.716349]\n",
      "epoch:0 step:403 [D loss: 0.057600, acc.: 89.06%] [G loss: 0.880909]\n",
      "epoch:0 step:404 [D loss: 0.083941, acc.: 86.72%] [G loss: 0.842796]\n",
      "epoch:0 step:405 [D loss: 0.056401, acc.: 96.09%] [G loss: 1.013625]\n",
      "epoch:0 step:406 [D loss: 0.073370, acc.: 91.41%] [G loss: 0.827620]\n",
      "epoch:0 step:407 [D loss: 0.058103, acc.: 92.19%] [G loss: 0.889122]\n",
      "epoch:0 step:408 [D loss: 0.086455, acc.: 89.84%] [G loss: 0.846146]\n",
      "epoch:0 step:409 [D loss: 0.053042, acc.: 95.31%] [G loss: 0.933705]\n",
      "epoch:0 step:410 [D loss: 0.076297, acc.: 89.84%] [G loss: 0.804269]\n",
      "epoch:0 step:411 [D loss: 0.073308, acc.: 89.84%] [G loss: 1.044865]\n",
      "epoch:0 step:412 [D loss: 0.101279, acc.: 85.94%] [G loss: 0.924147]\n",
      "epoch:0 step:413 [D loss: 0.074802, acc.: 88.28%] [G loss: 0.914341]\n",
      "epoch:0 step:414 [D loss: 0.085449, acc.: 86.72%] [G loss: 0.910573]\n",
      "epoch:0 step:415 [D loss: 0.073636, acc.: 91.41%] [G loss: 0.954351]\n",
      "epoch:0 step:416 [D loss: 0.057803, acc.: 94.53%] [G loss: 0.898357]\n",
      "epoch:0 step:417 [D loss: 0.068295, acc.: 90.62%] [G loss: 0.940716]\n",
      "epoch:0 step:418 [D loss: 0.096885, acc.: 85.16%] [G loss: 0.843872]\n",
      "epoch:0 step:419 [D loss: 0.065373, acc.: 90.62%] [G loss: 0.971980]\n",
      "epoch:0 step:420 [D loss: 0.072589, acc.: 92.19%] [G loss: 0.860102]\n",
      "epoch:0 step:421 [D loss: 0.089777, acc.: 82.81%] [G loss: 0.998801]\n",
      "epoch:0 step:422 [D loss: 0.128219, acc.: 79.69%] [G loss: 0.946420]\n",
      "epoch:0 step:423 [D loss: 0.060004, acc.: 94.53%] [G loss: 0.969276]\n",
      "epoch:0 step:424 [D loss: 0.127788, acc.: 82.81%] [G loss: 0.905641]\n",
      "epoch:0 step:425 [D loss: 0.055978, acc.: 94.53%] [G loss: 0.937672]\n",
      "epoch:0 step:426 [D loss: 0.132994, acc.: 75.00%] [G loss: 0.818774]\n",
      "epoch:0 step:427 [D loss: 0.064564, acc.: 92.97%] [G loss: 1.041433]\n",
      "epoch:0 step:428 [D loss: 0.069917, acc.: 92.97%] [G loss: 0.900868]\n",
      "epoch:0 step:429 [D loss: 0.070008, acc.: 86.72%] [G loss: 0.908499]\n",
      "epoch:0 step:430 [D loss: 0.132874, acc.: 78.91%] [G loss: 0.924379]\n",
      "epoch:0 step:431 [D loss: 0.103738, acc.: 79.69%] [G loss: 0.825812]\n",
      "epoch:0 step:432 [D loss: 0.111295, acc.: 85.94%] [G loss: 0.854501]\n",
      "epoch:0 step:433 [D loss: 0.051704, acc.: 96.09%] [G loss: 1.029441]\n",
      "epoch:0 step:434 [D loss: 0.138265, acc.: 78.91%] [G loss: 0.800527]\n",
      "epoch:0 step:435 [D loss: 0.053393, acc.: 97.66%] [G loss: 1.057459]\n",
      "epoch:0 step:436 [D loss: 0.157408, acc.: 74.22%] [G loss: 0.854894]\n",
      "epoch:0 step:437 [D loss: 0.068644, acc.: 90.62%] [G loss: 0.974818]\n",
      "epoch:0 step:438 [D loss: 0.108777, acc.: 84.38%] [G loss: 0.754750]\n",
      "epoch:0 step:439 [D loss: 0.056875, acc.: 92.97%] [G loss: 1.039676]\n",
      "epoch:0 step:440 [D loss: 0.131457, acc.: 84.38%] [G loss: 0.763712]\n",
      "epoch:0 step:441 [D loss: 0.059872, acc.: 90.62%] [G loss: 1.181453]\n",
      "epoch:0 step:442 [D loss: 0.156397, acc.: 76.56%] [G loss: 0.781144]\n",
      "epoch:0 step:443 [D loss: 0.049643, acc.: 93.75%] [G loss: 0.932272]\n",
      "epoch:0 step:444 [D loss: 0.089509, acc.: 87.50%] [G loss: 0.824008]\n",
      "epoch:0 step:445 [D loss: 0.080007, acc.: 87.50%] [G loss: 1.024125]\n",
      "epoch:0 step:446 [D loss: 0.109768, acc.: 85.16%] [G loss: 0.887200]\n",
      "epoch:0 step:447 [D loss: 0.056608, acc.: 97.66%] [G loss: 1.164148]\n",
      "epoch:0 step:448 [D loss: 0.214604, acc.: 65.62%] [G loss: 0.678128]\n",
      "epoch:0 step:449 [D loss: 0.077237, acc.: 92.97%] [G loss: 1.114467]\n",
      "epoch:0 step:450 [D loss: 0.164937, acc.: 75.00%] [G loss: 0.689175]\n",
      "epoch:0 step:451 [D loss: 0.072447, acc.: 87.50%] [G loss: 0.963083]\n",
      "epoch:0 step:452 [D loss: 0.130894, acc.: 80.47%] [G loss: 0.769966]\n",
      "epoch:0 step:453 [D loss: 0.068755, acc.: 89.84%] [G loss: 0.968430]\n",
      "epoch:0 step:454 [D loss: 0.117119, acc.: 82.03%] [G loss: 0.836373]\n",
      "epoch:0 step:455 [D loss: 0.056558, acc.: 92.97%] [G loss: 0.930494]\n",
      "epoch:0 step:456 [D loss: 0.078127, acc.: 89.84%] [G loss: 0.913532]\n",
      "epoch:0 step:457 [D loss: 0.069297, acc.: 91.41%] [G loss: 0.963192]\n",
      "epoch:0 step:458 [D loss: 0.115516, acc.: 82.03%] [G loss: 0.823209]\n",
      "epoch:0 step:459 [D loss: 0.047960, acc.: 95.31%] [G loss: 0.929979]\n",
      "epoch:0 step:460 [D loss: 0.075150, acc.: 90.62%] [G loss: 0.907335]\n",
      "epoch:0 step:461 [D loss: 0.052639, acc.: 95.31%] [G loss: 0.901035]\n",
      "epoch:0 step:462 [D loss: 0.133586, acc.: 78.91%] [G loss: 0.958466]\n",
      "epoch:0 step:463 [D loss: 0.057822, acc.: 92.19%] [G loss: 0.918455]\n",
      "epoch:0 step:464 [D loss: 0.111561, acc.: 81.25%] [G loss: 0.884781]\n",
      "epoch:0 step:465 [D loss: 0.063944, acc.: 93.75%] [G loss: 0.958181]\n",
      "epoch:0 step:466 [D loss: 0.073122, acc.: 89.84%] [G loss: 0.855039]\n",
      "epoch:0 step:467 [D loss: 0.111586, acc.: 82.03%] [G loss: 0.933812]\n",
      "epoch:0 step:468 [D loss: 0.126601, acc.: 78.91%] [G loss: 0.841740]\n",
      "epoch:0 step:469 [D loss: 0.062929, acc.: 90.62%] [G loss: 0.983203]\n",
      "epoch:0 step:470 [D loss: 0.111791, acc.: 83.59%] [G loss: 0.919130]\n",
      "epoch:0 step:471 [D loss: 0.046599, acc.: 97.66%] [G loss: 1.025042]\n",
      "epoch:0 step:472 [D loss: 0.143101, acc.: 75.78%] [G loss: 0.817125]\n",
      "epoch:0 step:473 [D loss: 0.093683, acc.: 87.50%] [G loss: 0.937269]\n",
      "epoch:0 step:474 [D loss: 0.063814, acc.: 94.53%] [G loss: 0.862958]\n",
      "epoch:0 step:475 [D loss: 0.069975, acc.: 91.41%] [G loss: 0.972049]\n",
      "epoch:0 step:476 [D loss: 0.126288, acc.: 81.25%] [G loss: 1.010453]\n",
      "epoch:0 step:477 [D loss: 0.095011, acc.: 84.38%] [G loss: 0.943789]\n",
      "epoch:0 step:478 [D loss: 0.089449, acc.: 86.72%] [G loss: 0.960984]\n",
      "epoch:0 step:479 [D loss: 0.077177, acc.: 87.50%] [G loss: 0.984340]\n",
      "epoch:0 step:480 [D loss: 0.078433, acc.: 87.50%] [G loss: 1.000772]\n",
      "epoch:0 step:481 [D loss: 0.076344, acc.: 88.28%] [G loss: 1.000962]\n",
      "epoch:0 step:482 [D loss: 0.119556, acc.: 84.38%] [G loss: 0.793427]\n",
      "epoch:0 step:483 [D loss: 0.060490, acc.: 91.41%] [G loss: 1.035751]\n",
      "epoch:0 step:484 [D loss: 0.088480, acc.: 87.50%] [G loss: 0.860653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:485 [D loss: 0.116148, acc.: 83.59%] [G loss: 0.794820]\n",
      "epoch:0 step:486 [D loss: 0.086054, acc.: 84.38%] [G loss: 0.973784]\n",
      "epoch:0 step:487 [D loss: 0.122699, acc.: 83.59%] [G loss: 0.866345]\n",
      "epoch:0 step:488 [D loss: 0.054304, acc.: 93.75%] [G loss: 1.006421]\n",
      "epoch:0 step:489 [D loss: 0.138458, acc.: 81.25%] [G loss: 0.864443]\n",
      "epoch:0 step:490 [D loss: 0.064596, acc.: 89.84%] [G loss: 0.884157]\n",
      "epoch:0 step:491 [D loss: 0.128814, acc.: 80.47%] [G loss: 0.844139]\n",
      "epoch:0 step:492 [D loss: 0.120854, acc.: 80.47%] [G loss: 0.948360]\n",
      "epoch:0 step:493 [D loss: 0.095996, acc.: 85.16%] [G loss: 0.901265]\n",
      "epoch:0 step:494 [D loss: 0.086138, acc.: 88.28%] [G loss: 0.973848]\n",
      "epoch:0 step:495 [D loss: 0.120418, acc.: 81.25%] [G loss: 0.710579]\n",
      "epoch:0 step:496 [D loss: 0.057897, acc.: 94.53%] [G loss: 1.020132]\n",
      "epoch:0 step:497 [D loss: 0.138156, acc.: 78.12%] [G loss: 0.817444]\n",
      "epoch:0 step:498 [D loss: 0.059854, acc.: 93.75%] [G loss: 0.986616]\n",
      "epoch:0 step:499 [D loss: 0.125119, acc.: 82.03%] [G loss: 0.843208]\n",
      "epoch:0 step:500 [D loss: 0.085704, acc.: 85.94%] [G loss: 0.975113]\n",
      "epoch:0 step:501 [D loss: 0.139135, acc.: 80.47%] [G loss: 0.843759]\n",
      "epoch:0 step:502 [D loss: 0.052905, acc.: 92.97%] [G loss: 0.978585]\n",
      "epoch:0 step:503 [D loss: 0.110393, acc.: 86.72%] [G loss: 0.816115]\n",
      "epoch:0 step:504 [D loss: 0.057371, acc.: 94.53%] [G loss: 0.941581]\n",
      "epoch:0 step:505 [D loss: 0.113618, acc.: 82.81%] [G loss: 0.804957]\n",
      "epoch:0 step:506 [D loss: 0.046258, acc.: 97.66%] [G loss: 0.971319]\n",
      "epoch:0 step:507 [D loss: 0.111351, acc.: 86.72%] [G loss: 0.900695]\n",
      "epoch:0 step:508 [D loss: 0.077842, acc.: 95.31%] [G loss: 0.987584]\n",
      "epoch:0 step:509 [D loss: 0.127815, acc.: 82.03%] [G loss: 0.835474]\n",
      "epoch:0 step:510 [D loss: 0.059175, acc.: 95.31%] [G loss: 1.076631]\n",
      "epoch:0 step:511 [D loss: 0.100868, acc.: 88.28%] [G loss: 0.815383]\n",
      "epoch:0 step:512 [D loss: 0.045689, acc.: 97.66%] [G loss: 1.173794]\n",
      "epoch:0 step:513 [D loss: 0.159203, acc.: 75.00%] [G loss: 0.748782]\n",
      "epoch:0 step:514 [D loss: 0.066497, acc.: 93.75%] [G loss: 1.061656]\n",
      "epoch:0 step:515 [D loss: 0.145364, acc.: 74.22%] [G loss: 0.898605]\n",
      "epoch:0 step:516 [D loss: 0.092331, acc.: 89.06%] [G loss: 0.913098]\n",
      "epoch:0 step:517 [D loss: 0.123950, acc.: 82.03%] [G loss: 0.946350]\n",
      "epoch:0 step:518 [D loss: 0.049194, acc.: 96.09%] [G loss: 0.992410]\n",
      "epoch:0 step:519 [D loss: 0.170592, acc.: 75.78%] [G loss: 0.772634]\n",
      "epoch:0 step:520 [D loss: 0.045152, acc.: 98.44%] [G loss: 1.028834]\n",
      "epoch:0 step:521 [D loss: 0.113010, acc.: 86.72%] [G loss: 0.825364]\n",
      "epoch:0 step:522 [D loss: 0.060424, acc.: 94.53%] [G loss: 0.947148]\n",
      "epoch:0 step:523 [D loss: 0.092600, acc.: 85.94%] [G loss: 0.933661]\n",
      "epoch:0 step:524 [D loss: 0.104534, acc.: 85.16%] [G loss: 0.964111]\n",
      "epoch:0 step:525 [D loss: 0.093365, acc.: 87.50%] [G loss: 0.957502]\n",
      "epoch:0 step:526 [D loss: 0.080775, acc.: 89.06%] [G loss: 1.055272]\n",
      "epoch:0 step:527 [D loss: 0.103504, acc.: 88.28%] [G loss: 0.903821]\n",
      "epoch:0 step:528 [D loss: 0.081580, acc.: 92.19%] [G loss: 1.072306]\n",
      "epoch:0 step:529 [D loss: 0.102847, acc.: 89.84%] [G loss: 0.999324]\n",
      "epoch:0 step:530 [D loss: 0.080457, acc.: 89.84%] [G loss: 0.887219]\n",
      "epoch:0 step:531 [D loss: 0.140830, acc.: 78.91%] [G loss: 1.004755]\n",
      "epoch:0 step:532 [D loss: 0.074272, acc.: 93.75%] [G loss: 1.055267]\n",
      "epoch:0 step:533 [D loss: 0.092661, acc.: 88.28%] [G loss: 1.078558]\n",
      "epoch:0 step:534 [D loss: 0.112906, acc.: 90.62%] [G loss: 1.054678]\n",
      "epoch:0 step:535 [D loss: 0.122541, acc.: 78.91%] [G loss: 0.847000]\n",
      "epoch:0 step:536 [D loss: 0.091531, acc.: 92.97%] [G loss: 1.028499]\n",
      "epoch:0 step:537 [D loss: 0.090199, acc.: 90.62%] [G loss: 0.981357]\n",
      "epoch:0 step:538 [D loss: 0.123267, acc.: 82.81%] [G loss: 1.094767]\n",
      "epoch:0 step:539 [D loss: 0.089589, acc.: 88.28%] [G loss: 0.864053]\n",
      "epoch:0 step:540 [D loss: 0.091507, acc.: 89.84%] [G loss: 1.097033]\n",
      "epoch:0 step:541 [D loss: 0.118884, acc.: 82.81%] [G loss: 0.990478]\n",
      "epoch:0 step:542 [D loss: 0.142783, acc.: 78.12%] [G loss: 1.067748]\n",
      "epoch:0 step:543 [D loss: 0.094087, acc.: 93.75%] [G loss: 0.920781]\n",
      "epoch:0 step:544 [D loss: 0.101881, acc.: 86.72%] [G loss: 1.089797]\n",
      "epoch:0 step:545 [D loss: 0.166711, acc.: 73.44%] [G loss: 0.809773]\n",
      "epoch:0 step:546 [D loss: 0.077940, acc.: 90.62%] [G loss: 0.996455]\n",
      "epoch:0 step:547 [D loss: 0.102428, acc.: 87.50%] [G loss: 0.925204]\n",
      "epoch:0 step:548 [D loss: 0.116694, acc.: 80.47%] [G loss: 0.948439]\n",
      "epoch:0 step:549 [D loss: 0.123531, acc.: 80.47%] [G loss: 0.964103]\n",
      "epoch:0 step:550 [D loss: 0.119281, acc.: 81.25%] [G loss: 1.023070]\n",
      "epoch:0 step:551 [D loss: 0.157308, acc.: 78.12%] [G loss: 0.884495]\n",
      "epoch:0 step:552 [D loss: 0.082683, acc.: 92.97%] [G loss: 0.857741]\n",
      "epoch:0 step:553 [D loss: 0.083029, acc.: 91.41%] [G loss: 1.052261]\n",
      "epoch:0 step:554 [D loss: 0.086561, acc.: 91.41%] [G loss: 0.920406]\n",
      "epoch:0 step:555 [D loss: 0.072779, acc.: 94.53%] [G loss: 1.116710]\n",
      "epoch:0 step:556 [D loss: 0.084686, acc.: 87.50%] [G loss: 0.914368]\n",
      "epoch:0 step:557 [D loss: 0.092420, acc.: 85.94%] [G loss: 0.973588]\n",
      "epoch:0 step:558 [D loss: 0.122878, acc.: 82.03%] [G loss: 0.849812]\n",
      "epoch:0 step:559 [D loss: 0.108625, acc.: 84.38%] [G loss: 1.004143]\n",
      "epoch:0 step:560 [D loss: 0.085925, acc.: 88.28%] [G loss: 0.992178]\n",
      "epoch:0 step:561 [D loss: 0.136902, acc.: 75.78%] [G loss: 0.916902]\n",
      "epoch:0 step:562 [D loss: 0.106211, acc.: 87.50%] [G loss: 0.882496]\n",
      "epoch:0 step:563 [D loss: 0.100666, acc.: 86.72%] [G loss: 0.972957]\n",
      "epoch:0 step:564 [D loss: 0.090401, acc.: 90.62%] [G loss: 0.896518]\n",
      "epoch:0 step:565 [D loss: 0.120242, acc.: 83.59%] [G loss: 0.920746]\n",
      "epoch:0 step:566 [D loss: 0.097058, acc.: 91.41%] [G loss: 0.871629]\n",
      "epoch:0 step:567 [D loss: 0.093205, acc.: 91.41%] [G loss: 0.963051]\n",
      "epoch:0 step:568 [D loss: 0.103064, acc.: 89.84%] [G loss: 0.962273]\n",
      "epoch:0 step:569 [D loss: 0.148506, acc.: 78.12%] [G loss: 1.014416]\n",
      "epoch:0 step:570 [D loss: 0.082329, acc.: 90.62%] [G loss: 1.009734]\n",
      "epoch:0 step:571 [D loss: 0.136857, acc.: 82.03%] [G loss: 0.923154]\n",
      "epoch:0 step:572 [D loss: 0.062207, acc.: 96.09%] [G loss: 1.009261]\n",
      "epoch:0 step:573 [D loss: 0.096209, acc.: 90.62%] [G loss: 0.960851]\n",
      "epoch:0 step:574 [D loss: 0.078752, acc.: 94.53%] [G loss: 1.001546]\n",
      "epoch:0 step:575 [D loss: 0.110385, acc.: 87.50%] [G loss: 0.961013]\n",
      "epoch:0 step:576 [D loss: 0.134911, acc.: 80.47%] [G loss: 1.093283]\n",
      "epoch:0 step:577 [D loss: 0.109922, acc.: 81.25%] [G loss: 1.010089]\n",
      "epoch:0 step:578 [D loss: 0.080115, acc.: 90.62%] [G loss: 0.894919]\n",
      "epoch:0 step:579 [D loss: 0.074694, acc.: 92.19%] [G loss: 1.055592]\n",
      "epoch:0 step:580 [D loss: 0.125932, acc.: 80.47%] [G loss: 0.989600]\n",
      "epoch:0 step:581 [D loss: 0.113177, acc.: 87.50%] [G loss: 0.979625]\n",
      "epoch:0 step:582 [D loss: 0.074216, acc.: 96.09%] [G loss: 0.945719]\n",
      "epoch:0 step:583 [D loss: 0.095567, acc.: 91.41%] [G loss: 1.082018]\n",
      "epoch:0 step:584 [D loss: 0.108137, acc.: 86.72%] [G loss: 1.009674]\n",
      "epoch:0 step:585 [D loss: 0.080132, acc.: 94.53%] [G loss: 0.894319]\n",
      "epoch:0 step:586 [D loss: 0.102158, acc.: 88.28%] [G loss: 1.228944]\n",
      "epoch:0 step:587 [D loss: 0.160594, acc.: 74.22%] [G loss: 0.937623]\n",
      "epoch:0 step:588 [D loss: 0.074948, acc.: 92.19%] [G loss: 1.000082]\n",
      "epoch:0 step:589 [D loss: 0.102916, acc.: 88.28%] [G loss: 0.982115]\n",
      "epoch:0 step:590 [D loss: 0.122162, acc.: 82.81%] [G loss: 1.079753]\n",
      "epoch:0 step:591 [D loss: 0.116662, acc.: 82.81%] [G loss: 1.002153]\n",
      "epoch:0 step:592 [D loss: 0.085075, acc.: 88.28%] [G loss: 1.109544]\n",
      "epoch:0 step:593 [D loss: 0.107041, acc.: 87.50%] [G loss: 0.986039]\n",
      "epoch:0 step:594 [D loss: 0.066452, acc.: 96.88%] [G loss: 1.134832]\n",
      "epoch:0 step:595 [D loss: 0.119542, acc.: 84.38%] [G loss: 0.867352]\n",
      "epoch:0 step:596 [D loss: 0.097943, acc.: 89.84%] [G loss: 1.058236]\n",
      "epoch:0 step:597 [D loss: 0.105250, acc.: 93.75%] [G loss: 0.922656]\n",
      "epoch:0 step:598 [D loss: 0.076394, acc.: 92.97%] [G loss: 1.128624]\n",
      "epoch:0 step:599 [D loss: 0.118555, acc.: 83.59%] [G loss: 1.006246]\n",
      "epoch:0 step:600 [D loss: 0.095841, acc.: 91.41%] [G loss: 0.984503]\n",
      "epoch:0 step:601 [D loss: 0.092377, acc.: 88.28%] [G loss: 1.104233]\n",
      "epoch:0 step:602 [D loss: 0.094173, acc.: 89.84%] [G loss: 0.958538]\n",
      "epoch:0 step:603 [D loss: 0.079685, acc.: 91.41%] [G loss: 1.098446]\n",
      "epoch:0 step:604 [D loss: 0.120652, acc.: 85.16%] [G loss: 0.952120]\n",
      "epoch:0 step:605 [D loss: 0.079635, acc.: 95.31%] [G loss: 1.023881]\n",
      "epoch:0 step:606 [D loss: 0.090060, acc.: 88.28%] [G loss: 1.014319]\n",
      "epoch:0 step:607 [D loss: 0.099232, acc.: 85.16%] [G loss: 1.130005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:608 [D loss: 0.097532, acc.: 92.97%] [G loss: 1.082504]\n",
      "epoch:0 step:609 [D loss: 0.105783, acc.: 89.84%] [G loss: 1.139314]\n",
      "epoch:0 step:610 [D loss: 0.121291, acc.: 84.38%] [G loss: 1.003272]\n",
      "epoch:0 step:611 [D loss: 0.052100, acc.: 98.44%] [G loss: 1.143906]\n",
      "epoch:0 step:612 [D loss: 0.138724, acc.: 81.25%] [G loss: 0.930140]\n",
      "epoch:0 step:613 [D loss: 0.073001, acc.: 96.88%] [G loss: 1.103540]\n",
      "epoch:0 step:614 [D loss: 0.158818, acc.: 72.66%] [G loss: 0.973583]\n",
      "epoch:0 step:615 [D loss: 0.084629, acc.: 90.62%] [G loss: 1.086431]\n",
      "epoch:0 step:616 [D loss: 0.114013, acc.: 89.06%] [G loss: 0.969881]\n",
      "epoch:0 step:617 [D loss: 0.122340, acc.: 77.34%] [G loss: 1.130651]\n",
      "epoch:0 step:618 [D loss: 0.081261, acc.: 93.75%] [G loss: 0.918923]\n",
      "epoch:0 step:619 [D loss: 0.092307, acc.: 93.75%] [G loss: 1.163490]\n",
      "epoch:0 step:620 [D loss: 0.136396, acc.: 78.91%] [G loss: 0.956888]\n",
      "epoch:0 step:621 [D loss: 0.118349, acc.: 82.03%] [G loss: 1.094349]\n",
      "epoch:0 step:622 [D loss: 0.189580, acc.: 65.62%] [G loss: 0.879208]\n",
      "epoch:0 step:623 [D loss: 0.081129, acc.: 90.62%] [G loss: 1.203824]\n",
      "epoch:0 step:624 [D loss: 0.191966, acc.: 67.97%] [G loss: 0.963640]\n",
      "epoch:0 step:625 [D loss: 0.075611, acc.: 91.41%] [G loss: 1.161853]\n",
      "epoch:0 step:626 [D loss: 0.169593, acc.: 75.00%] [G loss: 0.998407]\n",
      "epoch:0 step:627 [D loss: 0.046484, acc.: 99.22%] [G loss: 1.089053]\n",
      "epoch:0 step:628 [D loss: 0.150349, acc.: 78.12%] [G loss: 0.928397]\n",
      "epoch:0 step:629 [D loss: 0.099835, acc.: 92.97%] [G loss: 0.927578]\n",
      "epoch:0 step:630 [D loss: 0.118092, acc.: 83.59%] [G loss: 0.912068]\n",
      "epoch:0 step:631 [D loss: 0.099686, acc.: 86.72%] [G loss: 1.053863]\n",
      "epoch:0 step:632 [D loss: 0.115747, acc.: 89.06%] [G loss: 0.924525]\n",
      "epoch:0 step:633 [D loss: 0.084322, acc.: 94.53%] [G loss: 0.993066]\n",
      "epoch:0 step:634 [D loss: 0.111235, acc.: 92.19%] [G loss: 1.037472]\n",
      "epoch:0 step:635 [D loss: 0.085678, acc.: 93.75%] [G loss: 0.885153]\n",
      "epoch:0 step:636 [D loss: 0.139814, acc.: 82.81%] [G loss: 0.997188]\n",
      "epoch:0 step:637 [D loss: 0.104570, acc.: 85.94%] [G loss: 1.068705]\n",
      "epoch:0 step:638 [D loss: 0.086418, acc.: 92.19%] [G loss: 0.946038]\n",
      "epoch:0 step:639 [D loss: 0.134514, acc.: 85.16%] [G loss: 1.059931]\n",
      "epoch:0 step:640 [D loss: 0.139084, acc.: 82.03%] [G loss: 0.978458]\n",
      "epoch:0 step:641 [D loss: 0.114614, acc.: 84.38%] [G loss: 1.013045]\n",
      "epoch:0 step:642 [D loss: 0.106567, acc.: 82.03%] [G loss: 1.070861]\n",
      "epoch:0 step:643 [D loss: 0.128922, acc.: 79.69%] [G loss: 1.035484]\n",
      "epoch:0 step:644 [D loss: 0.093990, acc.: 89.06%] [G loss: 0.949874]\n",
      "epoch:0 step:645 [D loss: 0.102018, acc.: 90.62%] [G loss: 1.012506]\n",
      "epoch:0 step:646 [D loss: 0.151384, acc.: 77.34%] [G loss: 1.045436]\n",
      "epoch:0 step:647 [D loss: 0.120463, acc.: 89.06%] [G loss: 0.872361]\n",
      "epoch:0 step:648 [D loss: 0.051651, acc.: 96.09%] [G loss: 1.120384]\n",
      "epoch:0 step:649 [D loss: 0.125517, acc.: 86.72%] [G loss: 0.946246]\n",
      "epoch:0 step:650 [D loss: 0.093156, acc.: 92.97%] [G loss: 1.081173]\n",
      "epoch:0 step:651 [D loss: 0.151413, acc.: 78.12%] [G loss: 0.983230]\n",
      "epoch:0 step:652 [D loss: 0.139914, acc.: 77.34%] [G loss: 1.102876]\n",
      "epoch:0 step:653 [D loss: 0.107626, acc.: 85.16%] [G loss: 1.008615]\n",
      "epoch:0 step:654 [D loss: 0.108175, acc.: 83.59%] [G loss: 1.222548]\n",
      "epoch:0 step:655 [D loss: 0.190943, acc.: 69.53%] [G loss: 0.971034]\n",
      "epoch:0 step:656 [D loss: 0.066110, acc.: 97.66%] [G loss: 1.050388]\n",
      "epoch:0 step:657 [D loss: 0.111556, acc.: 89.06%] [G loss: 1.076597]\n",
      "epoch:0 step:658 [D loss: 0.106351, acc.: 89.84%] [G loss: 1.179357]\n",
      "epoch:0 step:659 [D loss: 0.082984, acc.: 92.97%] [G loss: 0.957268]\n",
      "epoch:0 step:660 [D loss: 0.114197, acc.: 89.84%] [G loss: 1.171682]\n",
      "epoch:0 step:661 [D loss: 0.093958, acc.: 90.62%] [G loss: 1.030889]\n",
      "epoch:0 step:662 [D loss: 0.113422, acc.: 89.84%] [G loss: 1.065730]\n",
      "epoch:0 step:663 [D loss: 0.116897, acc.: 85.16%] [G loss: 1.099824]\n",
      "epoch:0 step:664 [D loss: 0.100793, acc.: 89.06%] [G loss: 1.158060]\n",
      "epoch:0 step:665 [D loss: 0.116509, acc.: 85.16%] [G loss: 0.944229]\n",
      "epoch:0 step:666 [D loss: 0.088296, acc.: 90.62%] [G loss: 1.172588]\n",
      "epoch:0 step:667 [D loss: 0.135190, acc.: 79.69%] [G loss: 1.106566]\n",
      "epoch:0 step:668 [D loss: 0.093126, acc.: 94.53%] [G loss: 1.020682]\n",
      "epoch:0 step:669 [D loss: 0.126480, acc.: 85.94%] [G loss: 1.287983]\n",
      "epoch:0 step:670 [D loss: 0.091276, acc.: 91.41%] [G loss: 0.962862]\n",
      "epoch:0 step:671 [D loss: 0.114232, acc.: 84.38%] [G loss: 1.228385]\n",
      "epoch:0 step:672 [D loss: 0.178899, acc.: 67.19%] [G loss: 1.108530]\n",
      "epoch:0 step:673 [D loss: 0.080240, acc.: 92.19%] [G loss: 1.103834]\n",
      "epoch:0 step:674 [D loss: 0.129004, acc.: 82.81%] [G loss: 0.982987]\n",
      "epoch:0 step:675 [D loss: 0.117243, acc.: 89.84%] [G loss: 1.198141]\n",
      "epoch:0 step:676 [D loss: 0.143086, acc.: 78.91%] [G loss: 1.154622]\n",
      "epoch:0 step:677 [D loss: 0.134305, acc.: 83.59%] [G loss: 1.087160]\n",
      "epoch:0 step:678 [D loss: 0.103474, acc.: 92.97%] [G loss: 1.202121]\n",
      "epoch:0 step:679 [D loss: 0.163891, acc.: 76.56%] [G loss: 0.912878]\n",
      "epoch:0 step:680 [D loss: 0.118225, acc.: 85.16%] [G loss: 1.149149]\n",
      "epoch:0 step:681 [D loss: 0.120704, acc.: 83.59%] [G loss: 0.947772]\n",
      "epoch:0 step:682 [D loss: 0.066598, acc.: 96.88%] [G loss: 1.073234]\n",
      "epoch:0 step:683 [D loss: 0.165145, acc.: 76.56%] [G loss: 1.061424]\n",
      "epoch:0 step:684 [D loss: 0.109336, acc.: 89.84%] [G loss: 0.979762]\n",
      "epoch:0 step:685 [D loss: 0.122027, acc.: 84.38%] [G loss: 0.950467]\n",
      "epoch:0 step:686 [D loss: 0.115219, acc.: 82.81%] [G loss: 1.032929]\n",
      "epoch:0 step:687 [D loss: 0.107936, acc.: 89.06%] [G loss: 0.957980]\n",
      "epoch:0 step:688 [D loss: 0.107284, acc.: 88.28%] [G loss: 1.065240]\n",
      "epoch:0 step:689 [D loss: 0.133253, acc.: 84.38%] [G loss: 1.020726]\n",
      "epoch:0 step:690 [D loss: 0.113967, acc.: 91.41%] [G loss: 0.956370]\n",
      "epoch:0 step:691 [D loss: 0.151019, acc.: 79.69%] [G loss: 0.960082]\n",
      "epoch:0 step:692 [D loss: 0.092460, acc.: 92.97%] [G loss: 0.995984]\n",
      "epoch:0 step:693 [D loss: 0.133376, acc.: 85.16%] [G loss: 0.988717]\n",
      "epoch:0 step:694 [D loss: 0.124142, acc.: 85.94%] [G loss: 1.026854]\n",
      "epoch:0 step:695 [D loss: 0.098224, acc.: 90.62%] [G loss: 1.045511]\n",
      "epoch:0 step:696 [D loss: 0.111200, acc.: 85.94%] [G loss: 1.206236]\n",
      "epoch:0 step:697 [D loss: 0.111791, acc.: 88.28%] [G loss: 1.064312]\n",
      "epoch:0 step:698 [D loss: 0.124752, acc.: 86.72%] [G loss: 1.102084]\n",
      "epoch:0 step:699 [D loss: 0.121465, acc.: 86.72%] [G loss: 1.122456]\n",
      "epoch:0 step:700 [D loss: 0.131675, acc.: 83.59%] [G loss: 1.141124]\n",
      "epoch:0 step:701 [D loss: 0.135765, acc.: 85.94%] [G loss: 1.061548]\n",
      "epoch:0 step:702 [D loss: 0.169570, acc.: 82.03%] [G loss: 1.185716]\n",
      "epoch:0 step:703 [D loss: 0.142959, acc.: 78.12%] [G loss: 0.953519]\n",
      "epoch:0 step:704 [D loss: 0.109807, acc.: 87.50%] [G loss: 1.079664]\n",
      "epoch:0 step:705 [D loss: 0.110974, acc.: 89.84%] [G loss: 1.114998]\n",
      "epoch:0 step:706 [D loss: 0.117947, acc.: 83.59%] [G loss: 0.871496]\n",
      "epoch:0 step:707 [D loss: 0.070181, acc.: 93.75%] [G loss: 1.146874]\n",
      "epoch:0 step:708 [D loss: 0.144873, acc.: 85.94%] [G loss: 0.966015]\n",
      "epoch:0 step:709 [D loss: 0.091159, acc.: 89.84%] [G loss: 1.206252]\n",
      "epoch:0 step:710 [D loss: 0.205046, acc.: 64.84%] [G loss: 1.145700]\n",
      "epoch:0 step:711 [D loss: 0.133280, acc.: 82.03%] [G loss: 1.054958]\n",
      "epoch:0 step:712 [D loss: 0.133715, acc.: 83.59%] [G loss: 0.982132]\n",
      "epoch:0 step:713 [D loss: 0.119728, acc.: 84.38%] [G loss: 1.122075]\n",
      "epoch:0 step:714 [D loss: 0.172880, acc.: 75.00%] [G loss: 1.118895]\n",
      "epoch:0 step:715 [D loss: 0.139803, acc.: 82.03%] [G loss: 1.076881]\n",
      "epoch:0 step:716 [D loss: 0.158541, acc.: 80.47%] [G loss: 0.989583]\n",
      "epoch:0 step:717 [D loss: 0.147410, acc.: 78.12%] [G loss: 1.066977]\n",
      "epoch:0 step:718 [D loss: 0.115251, acc.: 85.16%] [G loss: 0.983208]\n",
      "epoch:0 step:719 [D loss: 0.129734, acc.: 82.81%] [G loss: 1.076280]\n",
      "epoch:0 step:720 [D loss: 0.140931, acc.: 82.03%] [G loss: 0.908002]\n",
      "epoch:0 step:721 [D loss: 0.137799, acc.: 83.59%] [G loss: 1.030646]\n",
      "epoch:0 step:722 [D loss: 0.119749, acc.: 88.28%] [G loss: 1.009117]\n",
      "epoch:0 step:723 [D loss: 0.174329, acc.: 79.69%] [G loss: 0.924216]\n",
      "epoch:0 step:724 [D loss: 0.101583, acc.: 93.75%] [G loss: 1.034567]\n",
      "epoch:0 step:725 [D loss: 0.136656, acc.: 82.81%] [G loss: 1.012233]\n",
      "epoch:0 step:726 [D loss: 0.107307, acc.: 86.72%] [G loss: 0.940135]\n",
      "epoch:0 step:727 [D loss: 0.165398, acc.: 77.34%] [G loss: 0.912029]\n",
      "epoch:0 step:728 [D loss: 0.128343, acc.: 85.94%] [G loss: 0.891555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:729 [D loss: 0.096409, acc.: 92.97%] [G loss: 1.052703]\n",
      "epoch:0 step:730 [D loss: 0.155926, acc.: 78.91%] [G loss: 1.045241]\n",
      "epoch:0 step:731 [D loss: 0.076218, acc.: 96.09%] [G loss: 0.907479]\n",
      "epoch:0 step:732 [D loss: 0.229701, acc.: 54.69%] [G loss: 0.875369]\n",
      "epoch:0 step:733 [D loss: 0.105893, acc.: 92.97%] [G loss: 1.070592]\n",
      "epoch:0 step:734 [D loss: 0.170694, acc.: 80.47%] [G loss: 0.808528]\n",
      "epoch:0 step:735 [D loss: 0.099554, acc.: 88.28%] [G loss: 0.952883]\n",
      "epoch:0 step:736 [D loss: 0.095291, acc.: 93.75%] [G loss: 1.014580]\n",
      "epoch:0 step:737 [D loss: 0.172426, acc.: 78.91%] [G loss: 0.888297]\n",
      "epoch:0 step:738 [D loss: 0.116188, acc.: 82.03%] [G loss: 1.009990]\n",
      "epoch:0 step:739 [D loss: 0.136134, acc.: 85.94%] [G loss: 0.895657]\n",
      "epoch:0 step:740 [D loss: 0.128444, acc.: 87.50%] [G loss: 1.008412]\n",
      "epoch:0 step:741 [D loss: 0.224362, acc.: 62.50%] [G loss: 0.869662]\n",
      "epoch:0 step:742 [D loss: 0.134943, acc.: 85.16%] [G loss: 0.977297]\n",
      "epoch:0 step:743 [D loss: 0.112719, acc.: 91.41%] [G loss: 0.889432]\n",
      "epoch:0 step:744 [D loss: 0.163990, acc.: 77.34%] [G loss: 0.895450]\n",
      "epoch:0 step:745 [D loss: 0.115513, acc.: 91.41%] [G loss: 0.928595]\n",
      "epoch:0 step:746 [D loss: 0.156217, acc.: 82.03%] [G loss: 0.906525]\n",
      "epoch:0 step:747 [D loss: 0.115842, acc.: 88.28%] [G loss: 0.907189]\n",
      "epoch:0 step:748 [D loss: 0.124998, acc.: 89.84%] [G loss: 0.988223]\n",
      "epoch:0 step:749 [D loss: 0.136668, acc.: 80.47%] [G loss: 0.922725]\n",
      "epoch:0 step:750 [D loss: 0.112975, acc.: 90.62%] [G loss: 1.007636]\n",
      "epoch:0 step:751 [D loss: 0.132714, acc.: 85.16%] [G loss: 1.023342]\n",
      "epoch:0 step:752 [D loss: 0.137088, acc.: 87.50%] [G loss: 0.947172]\n",
      "epoch:0 step:753 [D loss: 0.137751, acc.: 85.16%] [G loss: 0.969004]\n",
      "epoch:0 step:754 [D loss: 0.140277, acc.: 85.94%] [G loss: 0.939154]\n",
      "epoch:0 step:755 [D loss: 0.135815, acc.: 87.50%] [G loss: 0.859833]\n",
      "epoch:0 step:756 [D loss: 0.148667, acc.: 80.47%] [G loss: 1.046007]\n",
      "epoch:0 step:757 [D loss: 0.164452, acc.: 80.47%] [G loss: 0.848193]\n",
      "epoch:0 step:758 [D loss: 0.099954, acc.: 90.62%] [G loss: 0.995864]\n",
      "epoch:0 step:759 [D loss: 0.181208, acc.: 70.31%] [G loss: 0.873974]\n",
      "epoch:0 step:760 [D loss: 0.129807, acc.: 85.94%] [G loss: 0.913678]\n",
      "epoch:0 step:761 [D loss: 0.117170, acc.: 86.72%] [G loss: 0.933236]\n",
      "epoch:0 step:762 [D loss: 0.114847, acc.: 89.84%] [G loss: 0.910847]\n",
      "epoch:0 step:763 [D loss: 0.159052, acc.: 82.03%] [G loss: 1.029425]\n",
      "epoch:0 step:764 [D loss: 0.121504, acc.: 88.28%] [G loss: 0.939376]\n",
      "epoch:0 step:765 [D loss: 0.237059, acc.: 56.25%] [G loss: 0.836769]\n",
      "epoch:0 step:766 [D loss: 0.165977, acc.: 81.25%] [G loss: 0.981800]\n",
      "epoch:0 step:767 [D loss: 0.183711, acc.: 77.34%] [G loss: 0.909848]\n",
      "epoch:0 step:768 [D loss: 0.111918, acc.: 92.19%] [G loss: 0.919450]\n",
      "epoch:0 step:769 [D loss: 0.094665, acc.: 93.75%] [G loss: 0.962803]\n",
      "epoch:0 step:770 [D loss: 0.144307, acc.: 81.25%] [G loss: 0.897058]\n",
      "epoch:0 step:771 [D loss: 0.127232, acc.: 84.38%] [G loss: 0.910981]\n",
      "epoch:0 step:772 [D loss: 0.115346, acc.: 88.28%] [G loss: 0.896322]\n",
      "epoch:0 step:773 [D loss: 0.152148, acc.: 82.81%] [G loss: 1.137893]\n",
      "epoch:0 step:774 [D loss: 0.219064, acc.: 63.28%] [G loss: 0.851194]\n",
      "epoch:0 step:775 [D loss: 0.083958, acc.: 95.31%] [G loss: 1.087010]\n",
      "epoch:0 step:776 [D loss: 0.147703, acc.: 81.25%] [G loss: 0.959871]\n",
      "epoch:0 step:777 [D loss: 0.132495, acc.: 88.28%] [G loss: 1.132034]\n",
      "epoch:0 step:778 [D loss: 0.276174, acc.: 54.69%] [G loss: 0.921170]\n",
      "epoch:0 step:779 [D loss: 0.133769, acc.: 85.16%] [G loss: 1.187127]\n",
      "epoch:0 step:780 [D loss: 0.138259, acc.: 86.72%] [G loss: 0.900283]\n",
      "epoch:0 step:781 [D loss: 0.096289, acc.: 92.19%] [G loss: 0.955031]\n",
      "epoch:0 step:782 [D loss: 0.143062, acc.: 82.81%] [G loss: 0.996920]\n",
      "epoch:0 step:783 [D loss: 0.157074, acc.: 82.03%] [G loss: 1.085705]\n",
      "epoch:0 step:784 [D loss: 0.200281, acc.: 71.09%] [G loss: 0.827180]\n",
      "epoch:0 step:785 [D loss: 0.112339, acc.: 92.19%] [G loss: 1.065149]\n",
      "epoch:0 step:786 [D loss: 0.191588, acc.: 72.66%] [G loss: 1.029446]\n",
      "epoch:0 step:787 [D loss: 0.199226, acc.: 74.22%] [G loss: 0.865534]\n",
      "epoch:0 step:788 [D loss: 0.160113, acc.: 78.91%] [G loss: 1.035201]\n",
      "epoch:0 step:789 [D loss: 0.144991, acc.: 85.94%] [G loss: 0.914305]\n",
      "epoch:0 step:790 [D loss: 0.189586, acc.: 70.31%] [G loss: 0.862987]\n",
      "epoch:0 step:791 [D loss: 0.117411, acc.: 91.41%] [G loss: 0.980979]\n",
      "epoch:0 step:792 [D loss: 0.124001, acc.: 89.84%] [G loss: 0.963276]\n",
      "epoch:0 step:793 [D loss: 0.185999, acc.: 78.91%] [G loss: 0.915373]\n",
      "epoch:0 step:794 [D loss: 0.156481, acc.: 77.34%] [G loss: 0.926882]\n",
      "epoch:0 step:795 [D loss: 0.122462, acc.: 86.72%] [G loss: 0.991307]\n",
      "epoch:0 step:796 [D loss: 0.116772, acc.: 92.97%] [G loss: 0.970592]\n",
      "epoch:0 step:797 [D loss: 0.150717, acc.: 82.81%] [G loss: 0.953780]\n",
      "epoch:0 step:798 [D loss: 0.101668, acc.: 89.84%] [G loss: 0.939765]\n",
      "epoch:0 step:799 [D loss: 0.157328, acc.: 82.81%] [G loss: 0.888259]\n",
      "epoch:0 step:800 [D loss: 0.174196, acc.: 82.81%] [G loss: 0.902064]\n",
      "epoch:0 step:801 [D loss: 0.075966, acc.: 95.31%] [G loss: 1.042473]\n",
      "epoch:0 step:802 [D loss: 0.110330, acc.: 89.84%] [G loss: 0.957018]\n",
      "epoch:0 step:803 [D loss: 0.129894, acc.: 89.84%] [G loss: 0.969037]\n",
      "epoch:0 step:804 [D loss: 0.161642, acc.: 82.03%] [G loss: 0.927149]\n",
      "epoch:0 step:805 [D loss: 0.138417, acc.: 89.06%] [G loss: 0.974852]\n",
      "epoch:0 step:806 [D loss: 0.120864, acc.: 88.28%] [G loss: 0.966152]\n",
      "epoch:0 step:807 [D loss: 0.118983, acc.: 86.72%] [G loss: 0.971003]\n",
      "epoch:0 step:808 [D loss: 0.155579, acc.: 82.03%] [G loss: 1.017869]\n",
      "epoch:0 step:809 [D loss: 0.152941, acc.: 80.47%] [G loss: 0.952792]\n",
      "epoch:0 step:810 [D loss: 0.101770, acc.: 92.19%] [G loss: 1.013279]\n",
      "epoch:0 step:811 [D loss: 0.198446, acc.: 71.88%] [G loss: 0.979586]\n",
      "epoch:0 step:812 [D loss: 0.096605, acc.: 92.19%] [G loss: 0.981921]\n",
      "epoch:0 step:813 [D loss: 0.132977, acc.: 85.16%] [G loss: 0.902567]\n",
      "epoch:0 step:814 [D loss: 0.108774, acc.: 90.62%] [G loss: 1.051877]\n",
      "epoch:0 step:815 [D loss: 0.198051, acc.: 67.97%] [G loss: 1.026257]\n",
      "epoch:0 step:816 [D loss: 0.111453, acc.: 88.28%] [G loss: 1.152736]\n",
      "epoch:0 step:817 [D loss: 0.165461, acc.: 76.56%] [G loss: 0.982519]\n",
      "epoch:0 step:818 [D loss: 0.152848, acc.: 85.94%] [G loss: 0.952691]\n",
      "epoch:0 step:819 [D loss: 0.206690, acc.: 66.41%] [G loss: 1.082687]\n",
      "epoch:0 step:820 [D loss: 0.151203, acc.: 82.03%] [G loss: 0.909025]\n",
      "epoch:0 step:821 [D loss: 0.112499, acc.: 91.41%] [G loss: 1.017762]\n",
      "epoch:0 step:822 [D loss: 0.149302, acc.: 87.50%] [G loss: 0.947745]\n",
      "epoch:0 step:823 [D loss: 0.198896, acc.: 71.88%] [G loss: 0.869206]\n",
      "epoch:0 step:824 [D loss: 0.201021, acc.: 64.84%] [G loss: 0.856326]\n",
      "epoch:0 step:825 [D loss: 0.125080, acc.: 89.84%] [G loss: 1.015604]\n",
      "epoch:0 step:826 [D loss: 0.180964, acc.: 77.34%] [G loss: 0.914852]\n",
      "epoch:0 step:827 [D loss: 0.165385, acc.: 82.81%] [G loss: 0.898704]\n",
      "epoch:0 step:828 [D loss: 0.195752, acc.: 70.31%] [G loss: 0.765644]\n",
      "epoch:0 step:829 [D loss: 0.130072, acc.: 84.38%] [G loss: 1.172481]\n",
      "epoch:0 step:830 [D loss: 0.171988, acc.: 76.56%] [G loss: 0.838245]\n",
      "epoch:0 step:831 [D loss: 0.169592, acc.: 78.91%] [G loss: 0.865094]\n",
      "epoch:0 step:832 [D loss: 0.118028, acc.: 87.50%] [G loss: 1.205197]\n",
      "epoch:0 step:833 [D loss: 0.231990, acc.: 64.84%] [G loss: 0.944637]\n",
      "epoch:0 step:834 [D loss: 0.138037, acc.: 82.81%] [G loss: 0.949494]\n",
      "epoch:0 step:835 [D loss: 0.149261, acc.: 82.03%] [G loss: 0.893734]\n",
      "epoch:0 step:836 [D loss: 0.171832, acc.: 74.22%] [G loss: 0.931895]\n",
      "epoch:0 step:837 [D loss: 0.194817, acc.: 68.75%] [G loss: 0.952404]\n",
      "epoch:0 step:838 [D loss: 0.145665, acc.: 81.25%] [G loss: 0.826898]\n",
      "epoch:0 step:839 [D loss: 0.163289, acc.: 79.69%] [G loss: 0.951408]\n",
      "epoch:0 step:840 [D loss: 0.153138, acc.: 81.25%] [G loss: 1.002551]\n",
      "epoch:0 step:841 [D loss: 0.128346, acc.: 88.28%] [G loss: 0.964693]\n",
      "epoch:0 step:842 [D loss: 0.185841, acc.: 76.56%] [G loss: 0.935287]\n",
      "epoch:0 step:843 [D loss: 0.140469, acc.: 86.72%] [G loss: 0.944031]\n",
      "epoch:0 step:844 [D loss: 0.155041, acc.: 84.38%] [G loss: 0.926995]\n",
      "epoch:0 step:845 [D loss: 0.132295, acc.: 85.16%] [G loss: 0.936210]\n",
      "epoch:0 step:846 [D loss: 0.163435, acc.: 78.91%] [G loss: 0.958452]\n",
      "epoch:0 step:847 [D loss: 0.150856, acc.: 85.16%] [G loss: 0.890469]\n",
      "epoch:0 step:848 [D loss: 0.127909, acc.: 88.28%] [G loss: 1.109976]\n",
      "epoch:0 step:849 [D loss: 0.204983, acc.: 63.28%] [G loss: 0.786197]\n",
      "epoch:0 step:850 [D loss: 0.139800, acc.: 82.81%] [G loss: 1.027477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:851 [D loss: 0.141250, acc.: 85.16%] [G loss: 0.901203]\n",
      "epoch:0 step:852 [D loss: 0.131671, acc.: 83.59%] [G loss: 1.018958]\n",
      "epoch:0 step:853 [D loss: 0.125145, acc.: 92.19%] [G loss: 0.930643]\n",
      "epoch:0 step:854 [D loss: 0.139285, acc.: 85.16%] [G loss: 0.872051]\n",
      "epoch:0 step:855 [D loss: 0.205902, acc.: 67.19%] [G loss: 0.883495]\n",
      "epoch:0 step:856 [D loss: 0.110762, acc.: 92.97%] [G loss: 0.925948]\n",
      "epoch:0 step:857 [D loss: 0.144700, acc.: 83.59%] [G loss: 0.845399]\n",
      "epoch:0 step:858 [D loss: 0.268130, acc.: 52.34%] [G loss: 0.883170]\n",
      "epoch:0 step:859 [D loss: 0.169267, acc.: 76.56%] [G loss: 0.886016]\n",
      "epoch:0 step:860 [D loss: 0.097098, acc.: 92.97%] [G loss: 0.913154]\n",
      "epoch:0 step:861 [D loss: 0.144255, acc.: 84.38%] [G loss: 0.833628]\n",
      "epoch:0 step:862 [D loss: 0.075565, acc.: 95.31%] [G loss: 1.038454]\n",
      "epoch:0 step:863 [D loss: 0.127245, acc.: 85.94%] [G loss: 0.842933]\n",
      "epoch:0 step:864 [D loss: 0.108005, acc.: 93.75%] [G loss: 0.968814]\n",
      "epoch:0 step:865 [D loss: 0.132129, acc.: 85.94%] [G loss: 0.884607]\n",
      "epoch:0 step:866 [D loss: 0.120990, acc.: 89.84%] [G loss: 0.923930]\n",
      "epoch:0 step:867 [D loss: 0.156357, acc.: 82.03%] [G loss: 0.834069]\n",
      "epoch:0 step:868 [D loss: 0.091478, acc.: 94.53%] [G loss: 1.062809]\n",
      "epoch:0 step:869 [D loss: 0.157073, acc.: 85.16%] [G loss: 0.815060]\n",
      "epoch:0 step:870 [D loss: 0.103702, acc.: 91.41%] [G loss: 1.048278]\n",
      "epoch:0 step:871 [D loss: 0.091198, acc.: 90.62%] [G loss: 0.979872]\n",
      "epoch:0 step:872 [D loss: 0.114397, acc.: 88.28%] [G loss: 0.962003]\n",
      "epoch:0 step:873 [D loss: 0.144327, acc.: 83.59%] [G loss: 0.910469]\n",
      "epoch:0 step:874 [D loss: 0.172502, acc.: 76.56%] [G loss: 0.987947]\n",
      "epoch:0 step:875 [D loss: 0.115529, acc.: 90.62%] [G loss: 0.932911]\n",
      "epoch:0 step:876 [D loss: 0.164027, acc.: 81.25%] [G loss: 0.908773]\n",
      "epoch:0 step:877 [D loss: 0.141544, acc.: 82.81%] [G loss: 1.081316]\n",
      "epoch:0 step:878 [D loss: 0.147984, acc.: 82.81%] [G loss: 1.023681]\n",
      "epoch:0 step:879 [D loss: 0.215747, acc.: 67.19%] [G loss: 0.914842]\n",
      "epoch:0 step:880 [D loss: 0.185504, acc.: 75.78%] [G loss: 1.021621]\n",
      "epoch:0 step:881 [D loss: 0.148683, acc.: 83.59%] [G loss: 0.861631]\n",
      "epoch:0 step:882 [D loss: 0.175156, acc.: 75.00%] [G loss: 0.943040]\n",
      "epoch:0 step:883 [D loss: 0.258623, acc.: 58.59%] [G loss: 1.069775]\n",
      "epoch:0 step:884 [D loss: 0.133276, acc.: 80.47%] [G loss: 0.941534]\n",
      "epoch:0 step:885 [D loss: 0.114809, acc.: 89.06%] [G loss: 1.017402]\n",
      "epoch:0 step:886 [D loss: 0.130543, acc.: 86.72%] [G loss: 0.996740]\n",
      "epoch:0 step:887 [D loss: 0.162318, acc.: 77.34%] [G loss: 1.074087]\n",
      "epoch:0 step:888 [D loss: 0.152900, acc.: 83.59%] [G loss: 0.974711]\n",
      "epoch:0 step:889 [D loss: 0.094614, acc.: 88.28%] [G loss: 0.940077]\n",
      "epoch:0 step:890 [D loss: 0.120859, acc.: 85.94%] [G loss: 0.998375]\n",
      "epoch:0 step:891 [D loss: 0.264902, acc.: 55.47%] [G loss: 0.786359]\n",
      "epoch:0 step:892 [D loss: 0.198433, acc.: 70.31%] [G loss: 0.946063]\n",
      "epoch:0 step:893 [D loss: 0.189922, acc.: 71.88%] [G loss: 0.928130]\n",
      "epoch:0 step:894 [D loss: 0.143504, acc.: 83.59%] [G loss: 1.022969]\n",
      "epoch:0 step:895 [D loss: 0.100547, acc.: 92.97%] [G loss: 1.044683]\n",
      "epoch:0 step:896 [D loss: 0.186655, acc.: 70.31%] [G loss: 0.810894]\n",
      "epoch:0 step:897 [D loss: 0.086047, acc.: 90.62%] [G loss: 0.929787]\n",
      "epoch:0 step:898 [D loss: 0.211787, acc.: 67.19%] [G loss: 0.944655]\n",
      "epoch:0 step:899 [D loss: 0.167073, acc.: 79.69%] [G loss: 0.876020]\n",
      "epoch:0 step:900 [D loss: 0.174379, acc.: 76.56%] [G loss: 0.789466]\n",
      "epoch:0 step:901 [D loss: 0.145252, acc.: 81.25%] [G loss: 0.824662]\n",
      "epoch:0 step:902 [D loss: 0.187009, acc.: 71.09%] [G loss: 0.911549]\n",
      "epoch:0 step:903 [D loss: 0.166887, acc.: 82.81%] [G loss: 0.993993]\n",
      "epoch:0 step:904 [D loss: 0.149694, acc.: 84.38%] [G loss: 0.886785]\n",
      "epoch:0 step:905 [D loss: 0.176131, acc.: 73.44%] [G loss: 0.919675]\n",
      "epoch:0 step:906 [D loss: 0.133832, acc.: 85.94%] [G loss: 0.904573]\n",
      "epoch:0 step:907 [D loss: 0.183550, acc.: 75.78%] [G loss: 0.867119]\n",
      "epoch:0 step:908 [D loss: 0.163525, acc.: 78.91%] [G loss: 0.824236]\n",
      "epoch:0 step:909 [D loss: 0.174541, acc.: 78.12%] [G loss: 0.974784]\n",
      "epoch:0 step:910 [D loss: 0.147661, acc.: 78.91%] [G loss: 0.885459]\n",
      "epoch:0 step:911 [D loss: 0.143250, acc.: 80.47%] [G loss: 0.911843]\n",
      "epoch:0 step:912 [D loss: 0.151178, acc.: 88.28%] [G loss: 0.900519]\n",
      "epoch:0 step:913 [D loss: 0.236888, acc.: 64.84%] [G loss: 0.836437]\n",
      "epoch:0 step:914 [D loss: 0.134543, acc.: 86.72%] [G loss: 0.920050]\n",
      "epoch:0 step:915 [D loss: 0.186995, acc.: 74.22%] [G loss: 0.909742]\n",
      "epoch:0 step:916 [D loss: 0.130427, acc.: 85.94%] [G loss: 1.015604]\n",
      "epoch:0 step:917 [D loss: 0.219786, acc.: 63.28%] [G loss: 1.084706]\n",
      "epoch:0 step:918 [D loss: 0.195142, acc.: 75.00%] [G loss: 0.944758]\n",
      "epoch:0 step:919 [D loss: 0.184693, acc.: 75.78%] [G loss: 0.940260]\n",
      "epoch:0 step:920 [D loss: 0.346119, acc.: 40.62%] [G loss: 0.776030]\n",
      "epoch:0 step:921 [D loss: 0.163525, acc.: 76.56%] [G loss: 0.977910]\n",
      "epoch:0 step:922 [D loss: 0.328490, acc.: 46.09%] [G loss: 0.710180]\n",
      "epoch:0 step:923 [D loss: 0.096197, acc.: 95.31%] [G loss: 1.048688]\n",
      "epoch:0 step:924 [D loss: 0.176079, acc.: 77.34%] [G loss: 0.849466]\n",
      "epoch:0 step:925 [D loss: 0.060970, acc.: 97.66%] [G loss: 1.026778]\n",
      "epoch:0 step:926 [D loss: 0.124481, acc.: 85.94%] [G loss: 0.783032]\n",
      "epoch:0 step:927 [D loss: 0.114970, acc.: 89.06%] [G loss: 0.932563]\n",
      "epoch:0 step:928 [D loss: 0.199526, acc.: 80.47%] [G loss: 0.893885]\n",
      "epoch:0 step:929 [D loss: 0.042530, acc.: 96.09%] [G loss: 1.130381]\n",
      "epoch:0 step:930 [D loss: 0.179225, acc.: 76.56%] [G loss: 0.767065]\n",
      "epoch:0 step:931 [D loss: 0.165469, acc.: 82.81%] [G loss: 0.925218]\n",
      "epoch:0 step:932 [D loss: 0.207854, acc.: 71.88%] [G loss: 1.037106]\n",
      "epoch:0 step:933 [D loss: 0.138404, acc.: 83.59%] [G loss: 0.894765]\n",
      "epoch:0 step:934 [D loss: 0.170353, acc.: 82.03%] [G loss: 0.930999]\n",
      "epoch:0 step:935 [D loss: 0.136995, acc.: 87.50%] [G loss: 0.975471]\n",
      "epoch:0 step:936 [D loss: 0.066042, acc.: 95.31%] [G loss: 1.021990]\n",
      "epoch:0 step:937 [D loss: 0.345164, acc.: 38.28%] [G loss: 0.857782]\n",
      "epoch:1 step:938 [D loss: 0.140709, acc.: 81.25%] [G loss: 1.004556]\n",
      "epoch:1 step:939 [D loss: 0.181424, acc.: 75.78%] [G loss: 0.834640]\n",
      "epoch:1 step:940 [D loss: 0.183248, acc.: 75.78%] [G loss: 0.846775]\n",
      "epoch:1 step:941 [D loss: 0.155843, acc.: 86.72%] [G loss: 0.879064]\n",
      "epoch:1 step:942 [D loss: 0.138106, acc.: 89.84%] [G loss: 0.941133]\n",
      "epoch:1 step:943 [D loss: 0.163937, acc.: 78.91%] [G loss: 0.859406]\n",
      "epoch:1 step:944 [D loss: 0.107638, acc.: 92.97%] [G loss: 0.984153]\n",
      "epoch:1 step:945 [D loss: 0.214412, acc.: 65.62%] [G loss: 0.759418]\n",
      "epoch:1 step:946 [D loss: 0.151362, acc.: 82.81%] [G loss: 0.872053]\n",
      "epoch:1 step:947 [D loss: 0.153166, acc.: 83.59%] [G loss: 0.808117]\n",
      "epoch:1 step:948 [D loss: 0.143663, acc.: 86.72%] [G loss: 0.837724]\n",
      "epoch:1 step:949 [D loss: 0.166663, acc.: 83.59%] [G loss: 0.836670]\n",
      "epoch:1 step:950 [D loss: 0.172712, acc.: 78.12%] [G loss: 0.785340]\n",
      "epoch:1 step:951 [D loss: 0.174387, acc.: 81.25%] [G loss: 0.744936]\n",
      "epoch:1 step:952 [D loss: 0.160444, acc.: 82.03%] [G loss: 0.756038]\n",
      "epoch:1 step:953 [D loss: 0.173708, acc.: 80.47%] [G loss: 0.772795]\n",
      "epoch:1 step:954 [D loss: 0.176828, acc.: 78.91%] [G loss: 0.786149]\n",
      "epoch:1 step:955 [D loss: 0.149426, acc.: 85.94%] [G loss: 0.853224]\n",
      "epoch:1 step:956 [D loss: 0.184762, acc.: 78.91%] [G loss: 0.719534]\n",
      "epoch:1 step:957 [D loss: 0.155029, acc.: 82.03%] [G loss: 0.854453]\n",
      "epoch:1 step:958 [D loss: 0.102716, acc.: 88.28%] [G loss: 0.923880]\n",
      "epoch:1 step:959 [D loss: 0.081734, acc.: 92.19%] [G loss: 0.938426]\n",
      "epoch:1 step:960 [D loss: 0.311006, acc.: 46.88%] [G loss: 0.717946]\n",
      "epoch:1 step:961 [D loss: 0.134152, acc.: 85.16%] [G loss: 0.930339]\n",
      "epoch:1 step:962 [D loss: 0.213449, acc.: 71.88%] [G loss: 0.675334]\n",
      "epoch:1 step:963 [D loss: 0.133322, acc.: 82.81%] [G loss: 0.872974]\n",
      "epoch:1 step:964 [D loss: 0.140428, acc.: 85.16%] [G loss: 0.754395]\n",
      "epoch:1 step:965 [D loss: 0.153318, acc.: 81.25%] [G loss: 0.753140]\n",
      "epoch:1 step:966 [D loss: 0.101997, acc.: 89.06%] [G loss: 0.933963]\n",
      "epoch:1 step:967 [D loss: 0.149135, acc.: 84.38%] [G loss: 0.784572]\n",
      "epoch:1 step:968 [D loss: 0.127031, acc.: 88.28%] [G loss: 0.852596]\n",
      "epoch:1 step:969 [D loss: 0.098099, acc.: 89.84%] [G loss: 0.925198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:970 [D loss: 0.163848, acc.: 82.81%] [G loss: 0.726218]\n",
      "epoch:1 step:971 [D loss: 0.129086, acc.: 87.50%] [G loss: 0.879953]\n",
      "epoch:1 step:972 [D loss: 0.158404, acc.: 78.12%] [G loss: 0.875218]\n",
      "epoch:1 step:973 [D loss: 0.149180, acc.: 82.03%] [G loss: 1.012724]\n",
      "epoch:1 step:974 [D loss: 0.181524, acc.: 82.03%] [G loss: 0.765840]\n",
      "epoch:1 step:975 [D loss: 0.193034, acc.: 78.12%] [G loss: 0.815743]\n",
      "epoch:1 step:976 [D loss: 0.095597, acc.: 92.97%] [G loss: 0.954024]\n",
      "epoch:1 step:977 [D loss: 0.136336, acc.: 90.62%] [G loss: 0.812170]\n",
      "epoch:1 step:978 [D loss: 0.109516, acc.: 91.41%] [G loss: 0.962813]\n",
      "epoch:1 step:979 [D loss: 0.187696, acc.: 76.56%] [G loss: 0.799509]\n",
      "epoch:1 step:980 [D loss: 0.149576, acc.: 82.81%] [G loss: 0.803852]\n",
      "epoch:1 step:981 [D loss: 0.189573, acc.: 71.88%] [G loss: 0.792748]\n",
      "epoch:1 step:982 [D loss: 0.162372, acc.: 78.91%] [G loss: 0.898502]\n",
      "epoch:1 step:983 [D loss: 0.118789, acc.: 87.50%] [G loss: 0.866715]\n",
      "epoch:1 step:984 [D loss: 0.163631, acc.: 85.16%] [G loss: 0.808957]\n",
      "epoch:1 step:985 [D loss: 0.145262, acc.: 85.94%] [G loss: 0.880449]\n",
      "epoch:1 step:986 [D loss: 0.208337, acc.: 67.97%] [G loss: 0.841329]\n",
      "epoch:1 step:987 [D loss: 0.116463, acc.: 87.50%] [G loss: 0.942571]\n",
      "epoch:1 step:988 [D loss: 0.193647, acc.: 75.00%] [G loss: 0.786418]\n",
      "epoch:1 step:989 [D loss: 0.116270, acc.: 88.28%] [G loss: 0.901000]\n",
      "epoch:1 step:990 [D loss: 0.169282, acc.: 75.78%] [G loss: 0.873287]\n",
      "epoch:1 step:991 [D loss: 0.127597, acc.: 86.72%] [G loss: 0.817734]\n",
      "epoch:1 step:992 [D loss: 0.170406, acc.: 78.12%] [G loss: 0.861560]\n",
      "epoch:1 step:993 [D loss: 0.146327, acc.: 83.59%] [G loss: 0.825855]\n",
      "epoch:1 step:994 [D loss: 0.157245, acc.: 81.25%] [G loss: 0.956297]\n",
      "epoch:1 step:995 [D loss: 0.162378, acc.: 78.91%] [G loss: 0.876432]\n",
      "epoch:1 step:996 [D loss: 0.178981, acc.: 77.34%] [G loss: 0.793839]\n",
      "epoch:1 step:997 [D loss: 0.102271, acc.: 90.62%] [G loss: 0.856608]\n",
      "epoch:1 step:998 [D loss: 0.155553, acc.: 82.81%] [G loss: 0.760336]\n",
      "epoch:1 step:999 [D loss: 0.105375, acc.: 92.19%] [G loss: 1.047117]\n",
      "epoch:1 step:1000 [D loss: 0.175707, acc.: 76.56%] [G loss: 0.846673]\n",
      "epoch:1 step:1001 [D loss: 0.214291, acc.: 63.28%] [G loss: 0.841695]\n",
      "epoch:1 step:1002 [D loss: 0.138921, acc.: 85.16%] [G loss: 0.923842]\n",
      "epoch:1 step:1003 [D loss: 0.161749, acc.: 75.78%] [G loss: 0.855404]\n",
      "epoch:1 step:1004 [D loss: 0.137820, acc.: 87.50%] [G loss: 0.847631]\n",
      "epoch:1 step:1005 [D loss: 0.135731, acc.: 84.38%] [G loss: 0.850535]\n",
      "epoch:1 step:1006 [D loss: 0.148400, acc.: 82.81%] [G loss: 0.877392]\n",
      "epoch:1 step:1007 [D loss: 0.153650, acc.: 81.25%] [G loss: 0.815067]\n",
      "epoch:1 step:1008 [D loss: 0.124428, acc.: 87.50%] [G loss: 0.906894]\n",
      "epoch:1 step:1009 [D loss: 0.158242, acc.: 80.47%] [G loss: 0.866819]\n",
      "epoch:1 step:1010 [D loss: 0.123759, acc.: 87.50%] [G loss: 0.902984]\n",
      "epoch:1 step:1011 [D loss: 0.181897, acc.: 78.12%] [G loss: 0.775583]\n",
      "epoch:1 step:1012 [D loss: 0.178385, acc.: 75.78%] [G loss: 0.850957]\n",
      "epoch:1 step:1013 [D loss: 0.161968, acc.: 78.91%] [G loss: 0.882203]\n",
      "epoch:1 step:1014 [D loss: 0.119151, acc.: 85.16%] [G loss: 0.909741]\n",
      "epoch:1 step:1015 [D loss: 0.209317, acc.: 64.84%] [G loss: 0.784134]\n",
      "epoch:1 step:1016 [D loss: 0.145773, acc.: 80.47%] [G loss: 0.843354]\n",
      "epoch:1 step:1017 [D loss: 0.112943, acc.: 87.50%] [G loss: 0.910087]\n",
      "epoch:1 step:1018 [D loss: 0.155032, acc.: 82.03%] [G loss: 0.784620]\n",
      "epoch:1 step:1019 [D loss: 0.107626, acc.: 89.06%] [G loss: 0.961769]\n",
      "epoch:1 step:1020 [D loss: 0.140031, acc.: 86.72%] [G loss: 0.819434]\n",
      "epoch:1 step:1021 [D loss: 0.090934, acc.: 92.97%] [G loss: 0.901505]\n",
      "epoch:1 step:1022 [D loss: 0.128521, acc.: 86.72%] [G loss: 0.867040]\n",
      "epoch:1 step:1023 [D loss: 0.120733, acc.: 87.50%] [G loss: 0.897995]\n",
      "epoch:1 step:1024 [D loss: 0.080494, acc.: 94.53%] [G loss: 0.977209]\n",
      "epoch:1 step:1025 [D loss: 0.124180, acc.: 85.94%] [G loss: 0.899180]\n",
      "epoch:1 step:1026 [D loss: 0.138631, acc.: 85.16%] [G loss: 0.884717]\n",
      "epoch:1 step:1027 [D loss: 0.125363, acc.: 84.38%] [G loss: 0.938812]\n",
      "epoch:1 step:1028 [D loss: 0.160362, acc.: 79.69%] [G loss: 0.782307]\n",
      "epoch:1 step:1029 [D loss: 0.155475, acc.: 79.69%] [G loss: 0.870217]\n",
      "epoch:1 step:1030 [D loss: 0.127443, acc.: 89.06%] [G loss: 0.907606]\n",
      "epoch:1 step:1031 [D loss: 0.090631, acc.: 91.41%] [G loss: 0.931381]\n",
      "epoch:1 step:1032 [D loss: 0.129171, acc.: 89.06%] [G loss: 0.927696]\n",
      "epoch:1 step:1033 [D loss: 0.121178, acc.: 87.50%] [G loss: 0.893107]\n",
      "epoch:1 step:1034 [D loss: 0.169816, acc.: 78.91%] [G loss: 0.886088]\n",
      "epoch:1 step:1035 [D loss: 0.149015, acc.: 81.25%] [G loss: 0.801091]\n",
      "epoch:1 step:1036 [D loss: 0.134263, acc.: 85.94%] [G loss: 0.856821]\n",
      "epoch:1 step:1037 [D loss: 0.141975, acc.: 85.94%] [G loss: 0.814234]\n",
      "epoch:1 step:1038 [D loss: 0.122992, acc.: 86.72%] [G loss: 0.842251]\n",
      "epoch:1 step:1039 [D loss: 0.182284, acc.: 78.12%] [G loss: 0.798180]\n",
      "epoch:1 step:1040 [D loss: 0.083149, acc.: 92.19%] [G loss: 0.971920]\n",
      "epoch:1 step:1041 [D loss: 0.156654, acc.: 80.47%] [G loss: 0.826027]\n",
      "epoch:1 step:1042 [D loss: 0.163108, acc.: 78.91%] [G loss: 0.889754]\n",
      "epoch:1 step:1043 [D loss: 0.191611, acc.: 70.31%] [G loss: 0.990955]\n",
      "epoch:1 step:1044 [D loss: 0.187767, acc.: 71.09%] [G loss: 0.949095]\n",
      "epoch:1 step:1045 [D loss: 0.112817, acc.: 85.94%] [G loss: 0.999866]\n",
      "epoch:1 step:1046 [D loss: 0.183353, acc.: 76.56%] [G loss: 0.800553]\n",
      "epoch:1 step:1047 [D loss: 0.124565, acc.: 80.47%] [G loss: 0.823702]\n",
      "epoch:1 step:1048 [D loss: 0.154316, acc.: 81.25%] [G loss: 0.818692]\n",
      "epoch:1 step:1049 [D loss: 0.137588, acc.: 85.94%] [G loss: 0.844790]\n",
      "epoch:1 step:1050 [D loss: 0.187997, acc.: 72.66%] [G loss: 0.973267]\n",
      "epoch:1 step:1051 [D loss: 0.167286, acc.: 80.47%] [G loss: 0.842429]\n",
      "epoch:1 step:1052 [D loss: 0.131338, acc.: 85.94%] [G loss: 1.036842]\n",
      "epoch:1 step:1053 [D loss: 0.127002, acc.: 88.28%] [G loss: 0.954347]\n",
      "epoch:1 step:1054 [D loss: 0.125286, acc.: 90.62%] [G loss: 0.917900]\n",
      "epoch:1 step:1055 [D loss: 0.109921, acc.: 87.50%] [G loss: 0.970928]\n",
      "epoch:1 step:1056 [D loss: 0.108715, acc.: 89.06%] [G loss: 0.943409]\n",
      "epoch:1 step:1057 [D loss: 0.187685, acc.: 79.69%] [G loss: 0.823726]\n",
      "epoch:1 step:1058 [D loss: 0.119080, acc.: 89.84%] [G loss: 1.009689]\n",
      "epoch:1 step:1059 [D loss: 0.157898, acc.: 84.38%] [G loss: 0.897671]\n",
      "epoch:1 step:1060 [D loss: 0.134778, acc.: 87.50%] [G loss: 0.930261]\n",
      "epoch:1 step:1061 [D loss: 0.145141, acc.: 87.50%] [G loss: 0.910649]\n",
      "epoch:1 step:1062 [D loss: 0.091325, acc.: 90.62%] [G loss: 0.972179]\n",
      "epoch:1 step:1063 [D loss: 0.152760, acc.: 86.72%] [G loss: 0.849009]\n",
      "epoch:1 step:1064 [D loss: 0.150907, acc.: 83.59%] [G loss: 0.828157]\n",
      "epoch:1 step:1065 [D loss: 0.189798, acc.: 73.44%] [G loss: 0.845098]\n",
      "epoch:1 step:1066 [D loss: 0.180476, acc.: 71.09%] [G loss: 0.910193]\n",
      "epoch:1 step:1067 [D loss: 0.087661, acc.: 92.97%] [G loss: 0.997780]\n",
      "epoch:1 step:1068 [D loss: 0.125499, acc.: 89.06%] [G loss: 0.824520]\n",
      "epoch:1 step:1069 [D loss: 0.129785, acc.: 89.06%] [G loss: 0.852060]\n",
      "epoch:1 step:1070 [D loss: 0.160322, acc.: 81.25%] [G loss: 0.832522]\n",
      "epoch:1 step:1071 [D loss: 0.098807, acc.: 89.06%] [G loss: 0.915716]\n",
      "epoch:1 step:1072 [D loss: 0.146875, acc.: 82.03%] [G loss: 0.751424]\n",
      "epoch:1 step:1073 [D loss: 0.080179, acc.: 94.53%] [G loss: 0.933557]\n",
      "epoch:1 step:1074 [D loss: 0.142820, acc.: 85.16%] [G loss: 0.795425]\n",
      "epoch:1 step:1075 [D loss: 0.084887, acc.: 91.41%] [G loss: 0.949826]\n",
      "epoch:1 step:1076 [D loss: 0.180068, acc.: 83.59%] [G loss: 0.743595]\n",
      "epoch:1 step:1077 [D loss: 0.117397, acc.: 89.84%] [G loss: 0.923900]\n",
      "epoch:1 step:1078 [D loss: 0.133668, acc.: 85.16%] [G loss: 0.905509]\n",
      "epoch:1 step:1079 [D loss: 0.140455, acc.: 86.72%] [G loss: 0.787678]\n",
      "epoch:1 step:1080 [D loss: 0.178266, acc.: 74.22%] [G loss: 0.894685]\n",
      "epoch:1 step:1081 [D loss: 0.111585, acc.: 89.06%] [G loss: 0.939180]\n",
      "epoch:1 step:1082 [D loss: 0.119565, acc.: 86.72%] [G loss: 0.896479]\n",
      "epoch:1 step:1083 [D loss: 0.092021, acc.: 93.75%] [G loss: 0.910087]\n",
      "epoch:1 step:1084 [D loss: 0.137420, acc.: 85.94%] [G loss: 0.897050]\n",
      "epoch:1 step:1085 [D loss: 0.130901, acc.: 85.16%] [G loss: 0.843978]\n",
      "epoch:1 step:1086 [D loss: 0.095940, acc.: 92.97%] [G loss: 0.951094]\n",
      "epoch:1 step:1087 [D loss: 0.204540, acc.: 67.97%] [G loss: 0.797395]\n",
      "epoch:1 step:1088 [D loss: 0.082151, acc.: 95.31%] [G loss: 0.947122]\n",
      "epoch:1 step:1089 [D loss: 0.094156, acc.: 91.41%] [G loss: 0.839297]\n",
      "epoch:1 step:1090 [D loss: 0.163201, acc.: 85.16%] [G loss: 0.893863]\n",
      "epoch:1 step:1091 [D loss: 0.161787, acc.: 83.59%] [G loss: 0.815121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1092 [D loss: 0.091351, acc.: 91.41%] [G loss: 0.909882]\n",
      "epoch:1 step:1093 [D loss: 0.130620, acc.: 85.94%] [G loss: 0.828885]\n",
      "epoch:1 step:1094 [D loss: 0.092477, acc.: 95.31%] [G loss: 0.909251]\n",
      "epoch:1 step:1095 [D loss: 0.158815, acc.: 80.47%] [G loss: 0.791541]\n",
      "epoch:1 step:1096 [D loss: 0.114252, acc.: 90.62%] [G loss: 0.883671]\n",
      "epoch:1 step:1097 [D loss: 0.134509, acc.: 88.28%] [G loss: 0.803752]\n",
      "epoch:1 step:1098 [D loss: 0.091427, acc.: 89.06%] [G loss: 0.939001]\n",
      "epoch:1 step:1099 [D loss: 0.115785, acc.: 88.28%] [G loss: 0.878293]\n",
      "epoch:1 step:1100 [D loss: 0.134455, acc.: 83.59%] [G loss: 0.840487]\n",
      "epoch:1 step:1101 [D loss: 0.111415, acc.: 87.50%] [G loss: 0.851132]\n",
      "epoch:1 step:1102 [D loss: 0.095282, acc.: 92.97%] [G loss: 0.947271]\n",
      "epoch:1 step:1103 [D loss: 0.181443, acc.: 79.69%] [G loss: 0.766740]\n",
      "epoch:1 step:1104 [D loss: 0.118155, acc.: 88.28%] [G loss: 0.869147]\n",
      "epoch:1 step:1105 [D loss: 0.129571, acc.: 88.28%] [G loss: 0.861168]\n",
      "epoch:1 step:1106 [D loss: 0.133209, acc.: 79.69%] [G loss: 0.920693]\n",
      "epoch:1 step:1107 [D loss: 0.120269, acc.: 85.94%] [G loss: 0.860668]\n",
      "epoch:1 step:1108 [D loss: 0.088532, acc.: 93.75%] [G loss: 0.942712]\n",
      "epoch:1 step:1109 [D loss: 0.143540, acc.: 85.94%] [G loss: 0.862000]\n",
      "epoch:1 step:1110 [D loss: 0.109133, acc.: 92.19%] [G loss: 0.919246]\n",
      "epoch:1 step:1111 [D loss: 0.138974, acc.: 85.94%] [G loss: 0.852407]\n",
      "epoch:1 step:1112 [D loss: 0.126994, acc.: 81.25%] [G loss: 0.932991]\n",
      "epoch:1 step:1113 [D loss: 0.095508, acc.: 88.28%] [G loss: 0.863310]\n",
      "epoch:1 step:1114 [D loss: 0.144703, acc.: 85.16%] [G loss: 0.870309]\n",
      "epoch:1 step:1115 [D loss: 0.150894, acc.: 84.38%] [G loss: 0.817460]\n",
      "epoch:1 step:1116 [D loss: 0.143627, acc.: 80.47%] [G loss: 0.836779]\n",
      "epoch:1 step:1117 [D loss: 0.187836, acc.: 67.97%] [G loss: 0.830358]\n",
      "epoch:1 step:1118 [D loss: 0.137987, acc.: 84.38%] [G loss: 0.923410]\n",
      "epoch:1 step:1119 [D loss: 0.130237, acc.: 85.16%] [G loss: 0.874432]\n",
      "epoch:1 step:1120 [D loss: 0.145327, acc.: 81.25%] [G loss: 0.853005]\n",
      "epoch:1 step:1121 [D loss: 0.159321, acc.: 85.16%] [G loss: 0.843868]\n",
      "epoch:1 step:1122 [D loss: 0.185450, acc.: 75.78%] [G loss: 0.861472]\n",
      "epoch:1 step:1123 [D loss: 0.156044, acc.: 80.47%] [G loss: 0.885764]\n",
      "epoch:1 step:1124 [D loss: 0.170964, acc.: 79.69%] [G loss: 0.828831]\n",
      "epoch:1 step:1125 [D loss: 0.114069, acc.: 91.41%] [G loss: 1.011223]\n",
      "epoch:1 step:1126 [D loss: 0.198191, acc.: 69.53%] [G loss: 0.771634]\n",
      "epoch:1 step:1127 [D loss: 0.100347, acc.: 90.62%] [G loss: 0.952304]\n",
      "epoch:1 step:1128 [D loss: 0.124255, acc.: 87.50%] [G loss: 0.945807]\n",
      "epoch:1 step:1129 [D loss: 0.128292, acc.: 87.50%] [G loss: 0.939695]\n",
      "epoch:1 step:1130 [D loss: 0.166327, acc.: 79.69%] [G loss: 0.838117]\n",
      "epoch:1 step:1131 [D loss: 0.152491, acc.: 82.81%] [G loss: 0.879104]\n",
      "epoch:1 step:1132 [D loss: 0.132063, acc.: 84.38%] [G loss: 0.908562]\n",
      "epoch:1 step:1133 [D loss: 0.147967, acc.: 82.81%] [G loss: 0.994771]\n",
      "epoch:1 step:1134 [D loss: 0.184099, acc.: 73.44%] [G loss: 0.985408]\n",
      "epoch:1 step:1135 [D loss: 0.109966, acc.: 87.50%] [G loss: 0.952921]\n",
      "epoch:1 step:1136 [D loss: 0.249931, acc.: 58.59%] [G loss: 0.874329]\n",
      "epoch:1 step:1137 [D loss: 0.191440, acc.: 72.66%] [G loss: 0.911013]\n",
      "epoch:1 step:1138 [D loss: 0.186193, acc.: 69.53%] [G loss: 0.900824]\n",
      "epoch:1 step:1139 [D loss: 0.197095, acc.: 75.78%] [G loss: 0.850772]\n",
      "epoch:1 step:1140 [D loss: 0.216841, acc.: 66.41%] [G loss: 0.784078]\n",
      "epoch:1 step:1141 [D loss: 0.112845, acc.: 91.41%] [G loss: 1.024125]\n",
      "epoch:1 step:1142 [D loss: 0.161707, acc.: 78.91%] [G loss: 0.817605]\n",
      "epoch:1 step:1143 [D loss: 0.155375, acc.: 81.25%] [G loss: 0.795951]\n",
      "epoch:1 step:1144 [D loss: 0.109534, acc.: 89.06%] [G loss: 0.902867]\n",
      "epoch:1 step:1145 [D loss: 0.141303, acc.: 79.69%] [G loss: 0.791001]\n",
      "epoch:1 step:1146 [D loss: 0.153498, acc.: 82.03%] [G loss: 0.828437]\n",
      "epoch:1 step:1147 [D loss: 0.159638, acc.: 81.25%] [G loss: 0.786122]\n",
      "epoch:1 step:1148 [D loss: 0.145091, acc.: 83.59%] [G loss: 0.804636]\n",
      "epoch:1 step:1149 [D loss: 0.121156, acc.: 89.06%] [G loss: 0.836250]\n",
      "epoch:1 step:1150 [D loss: 0.126084, acc.: 85.94%] [G loss: 0.861586]\n",
      "epoch:1 step:1151 [D loss: 0.204994, acc.: 71.09%] [G loss: 0.693719]\n",
      "epoch:1 step:1152 [D loss: 0.141200, acc.: 80.47%] [G loss: 0.855326]\n",
      "epoch:1 step:1153 [D loss: 0.156095, acc.: 78.12%] [G loss: 0.768412]\n",
      "epoch:1 step:1154 [D loss: 0.087433, acc.: 92.97%] [G loss: 0.932813]\n",
      "epoch:1 step:1155 [D loss: 0.157891, acc.: 81.25%] [G loss: 0.807790]\n",
      "epoch:1 step:1156 [D loss: 0.131835, acc.: 86.72%] [G loss: 0.781333]\n",
      "epoch:1 step:1157 [D loss: 0.135046, acc.: 83.59%] [G loss: 0.865901]\n",
      "epoch:1 step:1158 [D loss: 0.133108, acc.: 84.38%] [G loss: 0.775072]\n",
      "epoch:1 step:1159 [D loss: 0.123483, acc.: 85.94%] [G loss: 0.939959]\n",
      "epoch:1 step:1160 [D loss: 0.186533, acc.: 67.97%] [G loss: 0.862609]\n",
      "epoch:1 step:1161 [D loss: 0.145467, acc.: 84.38%] [G loss: 0.785304]\n",
      "epoch:1 step:1162 [D loss: 0.166690, acc.: 77.34%] [G loss: 0.744498]\n",
      "epoch:1 step:1163 [D loss: 0.144839, acc.: 81.25%] [G loss: 0.804194]\n",
      "epoch:1 step:1164 [D loss: 0.185985, acc.: 75.78%] [G loss: 0.684547]\n",
      "epoch:1 step:1165 [D loss: 0.124702, acc.: 89.06%] [G loss: 0.836217]\n",
      "epoch:1 step:1166 [D loss: 0.150379, acc.: 81.25%] [G loss: 0.761618]\n",
      "epoch:1 step:1167 [D loss: 0.097720, acc.: 92.19%] [G loss: 0.926923]\n",
      "epoch:1 step:1168 [D loss: 0.172712, acc.: 79.69%] [G loss: 0.744535]\n",
      "epoch:1 step:1169 [D loss: 0.080463, acc.: 96.88%] [G loss: 0.872070]\n",
      "epoch:1 step:1170 [D loss: 0.223889, acc.: 65.62%] [G loss: 0.639029]\n",
      "epoch:1 step:1171 [D loss: 0.158078, acc.: 78.12%] [G loss: 0.748829]\n",
      "epoch:1 step:1172 [D loss: 0.209611, acc.: 61.72%] [G loss: 0.792482]\n",
      "epoch:1 step:1173 [D loss: 0.197921, acc.: 72.66%] [G loss: 0.727046]\n",
      "epoch:1 step:1174 [D loss: 0.169705, acc.: 78.12%] [G loss: 0.725351]\n",
      "epoch:1 step:1175 [D loss: 0.145573, acc.: 83.59%] [G loss: 0.799135]\n",
      "epoch:1 step:1176 [D loss: 0.180466, acc.: 75.78%] [G loss: 0.769914]\n",
      "epoch:1 step:1177 [D loss: 0.113547, acc.: 89.84%] [G loss: 0.901195]\n",
      "epoch:1 step:1178 [D loss: 0.196247, acc.: 75.78%] [G loss: 0.756100]\n",
      "epoch:1 step:1179 [D loss: 0.169951, acc.: 75.78%] [G loss: 0.749732]\n",
      "epoch:1 step:1180 [D loss: 0.157998, acc.: 82.03%] [G loss: 0.778171]\n",
      "epoch:1 step:1181 [D loss: 0.144867, acc.: 84.38%] [G loss: 0.761969]\n",
      "epoch:1 step:1182 [D loss: 0.145469, acc.: 82.03%] [G loss: 0.768325]\n",
      "epoch:1 step:1183 [D loss: 0.192514, acc.: 73.44%] [G loss: 0.671707]\n",
      "epoch:1 step:1184 [D loss: 0.220116, acc.: 69.53%] [G loss: 0.763205]\n",
      "epoch:1 step:1185 [D loss: 0.155698, acc.: 80.47%] [G loss: 0.771634]\n",
      "epoch:1 step:1186 [D loss: 0.148124, acc.: 80.47%] [G loss: 0.764973]\n",
      "epoch:1 step:1187 [D loss: 0.148146, acc.: 82.81%] [G loss: 0.813152]\n",
      "epoch:1 step:1188 [D loss: 0.183016, acc.: 78.12%] [G loss: 0.763763]\n",
      "epoch:1 step:1189 [D loss: 0.156559, acc.: 81.25%] [G loss: 0.773294]\n",
      "epoch:1 step:1190 [D loss: 0.151913, acc.: 78.12%] [G loss: 0.808130]\n",
      "epoch:1 step:1191 [D loss: 0.160138, acc.: 78.91%] [G loss: 0.719971]\n",
      "epoch:1 step:1192 [D loss: 0.142963, acc.: 80.47%] [G loss: 0.809270]\n",
      "epoch:1 step:1193 [D loss: 0.149166, acc.: 78.91%] [G loss: 0.834667]\n",
      "epoch:1 step:1194 [D loss: 0.155408, acc.: 80.47%] [G loss: 0.738891]\n",
      "epoch:1 step:1195 [D loss: 0.129301, acc.: 84.38%] [G loss: 0.806281]\n",
      "epoch:1 step:1196 [D loss: 0.142777, acc.: 81.25%] [G loss: 0.835576]\n",
      "epoch:1 step:1197 [D loss: 0.159756, acc.: 76.56%] [G loss: 0.755045]\n",
      "epoch:1 step:1198 [D loss: 0.176896, acc.: 75.78%] [G loss: 0.708598]\n",
      "epoch:1 step:1199 [D loss: 0.113900, acc.: 89.84%] [G loss: 0.807413]\n",
      "epoch:1 step:1200 [D loss: 0.264923, acc.: 57.81%] [G loss: 0.670423]\n",
      "epoch:1 step:1201 [D loss: 0.124453, acc.: 88.28%] [G loss: 0.851220]\n",
      "epoch:1 step:1202 [D loss: 0.212856, acc.: 67.19%] [G loss: 0.657053]\n",
      "epoch:1 step:1203 [D loss: 0.136117, acc.: 82.03%] [G loss: 0.788564]\n",
      "epoch:1 step:1204 [D loss: 0.179602, acc.: 73.44%] [G loss: 0.681432]\n",
      "epoch:1 step:1205 [D loss: 0.151965, acc.: 82.03%] [G loss: 0.738764]\n",
      "epoch:1 step:1206 [D loss: 0.162107, acc.: 77.34%] [G loss: 0.688458]\n",
      "epoch:1 step:1207 [D loss: 0.158157, acc.: 78.12%] [G loss: 0.799029]\n",
      "epoch:1 step:1208 [D loss: 0.098987, acc.: 89.06%] [G loss: 0.826856]\n",
      "epoch:1 step:1209 [D loss: 0.181090, acc.: 75.78%] [G loss: 0.652072]\n",
      "epoch:1 step:1210 [D loss: 0.126893, acc.: 86.72%] [G loss: 0.798618]\n",
      "epoch:1 step:1211 [D loss: 0.188867, acc.: 74.22%] [G loss: 0.664596]\n",
      "epoch:1 step:1212 [D loss: 0.189535, acc.: 68.75%] [G loss: 0.718096]\n",
      "epoch:1 step:1213 [D loss: 0.158748, acc.: 80.47%] [G loss: 0.743586]\n",
      "epoch:1 step:1214 [D loss: 0.172819, acc.: 76.56%] [G loss: 0.685921]\n",
      "epoch:1 step:1215 [D loss: 0.153813, acc.: 80.47%] [G loss: 0.732948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1216 [D loss: 0.179503, acc.: 73.44%] [G loss: 0.776775]\n",
      "epoch:1 step:1217 [D loss: 0.166726, acc.: 73.44%] [G loss: 0.704663]\n",
      "epoch:1 step:1218 [D loss: 0.134516, acc.: 83.59%] [G loss: 0.735584]\n",
      "epoch:1 step:1219 [D loss: 0.144094, acc.: 82.81%] [G loss: 0.757595]\n",
      "epoch:1 step:1220 [D loss: 0.151850, acc.: 79.69%] [G loss: 0.734731]\n",
      "epoch:1 step:1221 [D loss: 0.113716, acc.: 91.41%] [G loss: 0.789198]\n",
      "epoch:1 step:1222 [D loss: 0.143157, acc.: 80.47%] [G loss: 0.730094]\n",
      "epoch:1 step:1223 [D loss: 0.163730, acc.: 78.12%] [G loss: 0.688020]\n",
      "epoch:1 step:1224 [D loss: 0.187672, acc.: 74.22%] [G loss: 0.673530]\n",
      "epoch:1 step:1225 [D loss: 0.187119, acc.: 75.78%] [G loss: 0.701988]\n",
      "epoch:1 step:1226 [D loss: 0.175715, acc.: 79.69%] [G loss: 0.737520]\n",
      "epoch:1 step:1227 [D loss: 0.138015, acc.: 82.81%] [G loss: 0.725810]\n",
      "epoch:1 step:1228 [D loss: 0.153734, acc.: 77.34%] [G loss: 0.676237]\n",
      "epoch:1 step:1229 [D loss: 0.136279, acc.: 81.25%] [G loss: 0.818683]\n",
      "epoch:1 step:1230 [D loss: 0.158652, acc.: 81.25%] [G loss: 0.742181]\n",
      "epoch:1 step:1231 [D loss: 0.148197, acc.: 82.03%] [G loss: 0.721218]\n",
      "epoch:1 step:1232 [D loss: 0.164454, acc.: 82.03%] [G loss: 0.707960]\n",
      "epoch:1 step:1233 [D loss: 0.102770, acc.: 89.84%] [G loss: 0.843116]\n",
      "epoch:1 step:1234 [D loss: 0.157308, acc.: 78.12%] [G loss: 0.751139]\n",
      "epoch:1 step:1235 [D loss: 0.134846, acc.: 82.03%] [G loss: 0.752691]\n",
      "epoch:1 step:1236 [D loss: 0.123814, acc.: 88.28%] [G loss: 0.766577]\n",
      "epoch:1 step:1237 [D loss: 0.143706, acc.: 83.59%] [G loss: 0.675978]\n",
      "epoch:1 step:1238 [D loss: 0.130116, acc.: 86.72%] [G loss: 0.719245]\n",
      "epoch:1 step:1239 [D loss: 0.161804, acc.: 78.91%] [G loss: 0.701692]\n",
      "epoch:1 step:1240 [D loss: 0.108749, acc.: 90.62%] [G loss: 0.780997]\n",
      "epoch:1 step:1241 [D loss: 0.152775, acc.: 84.38%] [G loss: 0.745286]\n",
      "epoch:1 step:1242 [D loss: 0.124324, acc.: 87.50%] [G loss: 0.758177]\n",
      "epoch:1 step:1243 [D loss: 0.148256, acc.: 81.25%] [G loss: 0.784547]\n",
      "epoch:1 step:1244 [D loss: 0.121257, acc.: 89.84%] [G loss: 0.760649]\n",
      "epoch:1 step:1245 [D loss: 0.145572, acc.: 82.03%] [G loss: 0.760481]\n",
      "epoch:1 step:1246 [D loss: 0.124503, acc.: 86.72%] [G loss: 0.840740]\n",
      "epoch:1 step:1247 [D loss: 0.149008, acc.: 79.69%] [G loss: 0.727464]\n",
      "epoch:1 step:1248 [D loss: 0.158406, acc.: 82.81%] [G loss: 0.774511]\n",
      "epoch:1 step:1249 [D loss: 0.130905, acc.: 85.16%] [G loss: 0.956699]\n",
      "epoch:1 step:1250 [D loss: 0.216939, acc.: 71.88%] [G loss: 0.660417]\n",
      "epoch:1 step:1251 [D loss: 0.107812, acc.: 91.41%] [G loss: 0.867694]\n",
      "epoch:1 step:1252 [D loss: 0.161234, acc.: 77.34%] [G loss: 0.728725]\n",
      "epoch:1 step:1253 [D loss: 0.214527, acc.: 67.97%] [G loss: 0.698159]\n",
      "epoch:1 step:1254 [D loss: 0.178351, acc.: 78.91%] [G loss: 0.706238]\n",
      "epoch:1 step:1255 [D loss: 0.155993, acc.: 76.56%] [G loss: 0.742723]\n",
      "epoch:1 step:1256 [D loss: 0.125969, acc.: 85.16%] [G loss: 0.803301]\n",
      "epoch:1 step:1257 [D loss: 0.193330, acc.: 71.09%] [G loss: 0.643717]\n",
      "epoch:1 step:1258 [D loss: 0.116355, acc.: 88.28%] [G loss: 0.778887]\n",
      "epoch:1 step:1259 [D loss: 0.130140, acc.: 85.16%] [G loss: 0.794659]\n",
      "epoch:1 step:1260 [D loss: 0.144287, acc.: 82.03%] [G loss: 0.762532]\n",
      "epoch:1 step:1261 [D loss: 0.121066, acc.: 85.16%] [G loss: 0.800565]\n",
      "epoch:1 step:1262 [D loss: 0.133467, acc.: 82.03%] [G loss: 0.749859]\n",
      "epoch:1 step:1263 [D loss: 0.187514, acc.: 71.88%] [G loss: 0.750459]\n",
      "epoch:1 step:1264 [D loss: 0.130510, acc.: 82.81%] [G loss: 0.762603]\n",
      "epoch:1 step:1265 [D loss: 0.129367, acc.: 82.03%] [G loss: 0.829472]\n",
      "epoch:1 step:1266 [D loss: 0.159777, acc.: 81.25%] [G loss: 0.752020]\n",
      "epoch:1 step:1267 [D loss: 0.177318, acc.: 79.69%] [G loss: 0.698942]\n",
      "epoch:1 step:1268 [D loss: 0.136367, acc.: 89.06%] [G loss: 0.762945]\n",
      "epoch:1 step:1269 [D loss: 0.122940, acc.: 89.06%] [G loss: 0.764302]\n",
      "epoch:1 step:1270 [D loss: 0.133507, acc.: 83.59%] [G loss: 0.790787]\n",
      "epoch:1 step:1271 [D loss: 0.168117, acc.: 79.69%] [G loss: 0.771324]\n",
      "epoch:1 step:1272 [D loss: 0.129674, acc.: 90.62%] [G loss: 0.847513]\n",
      "epoch:1 step:1273 [D loss: 0.175846, acc.: 73.44%] [G loss: 0.805859]\n",
      "epoch:1 step:1274 [D loss: 0.131113, acc.: 84.38%] [G loss: 0.822468]\n",
      "epoch:1 step:1275 [D loss: 0.191137, acc.: 71.88%] [G loss: 0.812482]\n",
      "epoch:1 step:1276 [D loss: 0.156680, acc.: 78.91%] [G loss: 0.775247]\n",
      "epoch:1 step:1277 [D loss: 0.173017, acc.: 78.91%] [G loss: 0.739061]\n",
      "epoch:1 step:1278 [D loss: 0.146238, acc.: 78.91%] [G loss: 0.832650]\n",
      "epoch:1 step:1279 [D loss: 0.133185, acc.: 84.38%] [G loss: 0.837084]\n",
      "epoch:1 step:1280 [D loss: 0.093283, acc.: 85.94%] [G loss: 0.897008]\n",
      "epoch:1 step:1281 [D loss: 0.135152, acc.: 82.03%] [G loss: 0.766273]\n",
      "epoch:1 step:1282 [D loss: 0.174818, acc.: 78.12%] [G loss: 0.716464]\n",
      "epoch:1 step:1283 [D loss: 0.134003, acc.: 89.06%] [G loss: 0.830467]\n",
      "epoch:1 step:1284 [D loss: 0.142811, acc.: 82.03%] [G loss: 0.782714]\n",
      "epoch:1 step:1285 [D loss: 0.221631, acc.: 69.53%] [G loss: 0.770873]\n",
      "epoch:1 step:1286 [D loss: 0.196163, acc.: 67.97%] [G loss: 0.742428]\n",
      "epoch:1 step:1287 [D loss: 0.168819, acc.: 72.66%] [G loss: 0.859884]\n",
      "epoch:1 step:1288 [D loss: 0.131183, acc.: 82.81%] [G loss: 0.886342]\n",
      "epoch:1 step:1289 [D loss: 0.165723, acc.: 77.34%] [G loss: 0.810167]\n",
      "epoch:1 step:1290 [D loss: 0.138582, acc.: 88.28%] [G loss: 0.786056]\n",
      "epoch:1 step:1291 [D loss: 0.117085, acc.: 89.06%] [G loss: 0.873706]\n",
      "epoch:1 step:1292 [D loss: 0.152694, acc.: 81.25%] [G loss: 0.786582]\n",
      "epoch:1 step:1293 [D loss: 0.136936, acc.: 82.81%] [G loss: 0.676868]\n",
      "epoch:1 step:1294 [D loss: 0.117996, acc.: 86.72%] [G loss: 0.838287]\n",
      "epoch:1 step:1295 [D loss: 0.121426, acc.: 85.16%] [G loss: 0.803129]\n",
      "epoch:1 step:1296 [D loss: 0.123963, acc.: 85.94%] [G loss: 0.726958]\n",
      "epoch:1 step:1297 [D loss: 0.143630, acc.: 85.94%] [G loss: 0.815916]\n",
      "epoch:1 step:1298 [D loss: 0.123962, acc.: 89.06%] [G loss: 0.805726]\n",
      "epoch:1 step:1299 [D loss: 0.164712, acc.: 82.03%] [G loss: 0.771745]\n",
      "epoch:1 step:1300 [D loss: 0.155719, acc.: 82.03%] [G loss: 0.703110]\n",
      "epoch:1 step:1301 [D loss: 0.103578, acc.: 89.84%] [G loss: 0.800677]\n",
      "epoch:1 step:1302 [D loss: 0.150099, acc.: 84.38%] [G loss: 0.727485]\n",
      "epoch:1 step:1303 [D loss: 0.114504, acc.: 89.06%] [G loss: 0.845881]\n",
      "epoch:1 step:1304 [D loss: 0.145583, acc.: 83.59%] [G loss: 0.778901]\n",
      "epoch:1 step:1305 [D loss: 0.129246, acc.: 85.94%] [G loss: 0.827321]\n",
      "epoch:1 step:1306 [D loss: 0.176178, acc.: 79.69%] [G loss: 0.731154]\n",
      "epoch:1 step:1307 [D loss: 0.109379, acc.: 87.50%] [G loss: 0.922380]\n",
      "epoch:1 step:1308 [D loss: 0.110512, acc.: 86.72%] [G loss: 0.875344]\n",
      "epoch:1 step:1309 [D loss: 0.167299, acc.: 76.56%] [G loss: 0.746248]\n",
      "epoch:1 step:1310 [D loss: 0.140707, acc.: 85.16%] [G loss: 0.858868]\n",
      "epoch:1 step:1311 [D loss: 0.122531, acc.: 88.28%] [G loss: 0.821630]\n",
      "epoch:1 step:1312 [D loss: 0.133545, acc.: 85.16%] [G loss: 0.735110]\n",
      "epoch:1 step:1313 [D loss: 0.139835, acc.: 85.94%] [G loss: 0.805903]\n",
      "epoch:1 step:1314 [D loss: 0.169978, acc.: 78.12%] [G loss: 0.802658]\n",
      "epoch:1 step:1315 [D loss: 0.131600, acc.: 89.06%] [G loss: 0.866057]\n",
      "epoch:1 step:1316 [D loss: 0.133719, acc.: 87.50%] [G loss: 0.800448]\n",
      "epoch:1 step:1317 [D loss: 0.122535, acc.: 88.28%] [G loss: 0.784754]\n",
      "epoch:1 step:1318 [D loss: 0.131604, acc.: 85.94%] [G loss: 0.859086]\n",
      "epoch:1 step:1319 [D loss: 0.121759, acc.: 86.72%] [G loss: 0.816087]\n",
      "epoch:1 step:1320 [D loss: 0.153509, acc.: 82.03%] [G loss: 0.728065]\n",
      "epoch:1 step:1321 [D loss: 0.125967, acc.: 85.16%] [G loss: 0.854384]\n",
      "epoch:1 step:1322 [D loss: 0.127501, acc.: 86.72%] [G loss: 0.824441]\n",
      "epoch:1 step:1323 [D loss: 0.128114, acc.: 85.94%] [G loss: 0.824418]\n",
      "epoch:1 step:1324 [D loss: 0.121809, acc.: 87.50%] [G loss: 0.813097]\n",
      "epoch:1 step:1325 [D loss: 0.121596, acc.: 85.94%] [G loss: 0.835976]\n",
      "epoch:1 step:1326 [D loss: 0.151564, acc.: 82.81%] [G loss: 0.811347]\n",
      "epoch:1 step:1327 [D loss: 0.162886, acc.: 81.25%] [G loss: 0.742145]\n",
      "epoch:1 step:1328 [D loss: 0.134023, acc.: 87.50%] [G loss: 0.850669]\n",
      "epoch:1 step:1329 [D loss: 0.109012, acc.: 87.50%] [G loss: 0.916111]\n",
      "epoch:1 step:1330 [D loss: 0.170195, acc.: 77.34%] [G loss: 0.789550]\n",
      "epoch:1 step:1331 [D loss: 0.142516, acc.: 81.25%] [G loss: 0.866170]\n",
      "epoch:1 step:1332 [D loss: 0.110561, acc.: 90.62%] [G loss: 0.824321]\n",
      "epoch:1 step:1333 [D loss: 0.209170, acc.: 66.41%] [G loss: 0.674568]\n",
      "epoch:1 step:1334 [D loss: 0.093695, acc.: 89.84%] [G loss: 1.049770]\n",
      "epoch:1 step:1335 [D loss: 0.148710, acc.: 78.12%] [G loss: 0.725223]\n",
      "epoch:1 step:1336 [D loss: 0.104029, acc.: 91.41%] [G loss: 0.790855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1337 [D loss: 0.179228, acc.: 78.91%] [G loss: 0.759639]\n",
      "epoch:1 step:1338 [D loss: 0.151787, acc.: 78.91%] [G loss: 0.807022]\n",
      "epoch:1 step:1339 [D loss: 0.114073, acc.: 87.50%] [G loss: 0.893741]\n",
      "epoch:1 step:1340 [D loss: 0.189986, acc.: 75.00%] [G loss: 0.693841]\n",
      "epoch:1 step:1341 [D loss: 0.171850, acc.: 77.34%] [G loss: 0.710315]\n",
      "epoch:1 step:1342 [D loss: 0.127524, acc.: 84.38%] [G loss: 0.898083]\n",
      "epoch:1 step:1343 [D loss: 0.166610, acc.: 81.25%] [G loss: 0.818854]\n",
      "epoch:1 step:1344 [D loss: 0.144688, acc.: 83.59%] [G loss: 0.883800]\n",
      "epoch:1 step:1345 [D loss: 0.130083, acc.: 85.16%] [G loss: 0.830955]\n",
      "epoch:1 step:1346 [D loss: 0.199425, acc.: 72.66%] [G loss: 0.658875]\n",
      "epoch:1 step:1347 [D loss: 0.162907, acc.: 78.12%] [G loss: 0.865774]\n",
      "epoch:1 step:1348 [D loss: 0.165564, acc.: 79.69%] [G loss: 0.794377]\n",
      "epoch:1 step:1349 [D loss: 0.179799, acc.: 75.00%] [G loss: 0.722164]\n",
      "epoch:1 step:1350 [D loss: 0.163291, acc.: 81.25%] [G loss: 0.815238]\n",
      "epoch:1 step:1351 [D loss: 0.198251, acc.: 71.88%] [G loss: 0.765962]\n",
      "epoch:1 step:1352 [D loss: 0.107994, acc.: 91.41%] [G loss: 0.895179]\n",
      "epoch:1 step:1353 [D loss: 0.145323, acc.: 82.03%] [G loss: 0.799582]\n",
      "epoch:1 step:1354 [D loss: 0.141996, acc.: 80.47%] [G loss: 0.864526]\n",
      "epoch:1 step:1355 [D loss: 0.183715, acc.: 73.44%] [G loss: 0.704266]\n",
      "epoch:1 step:1356 [D loss: 0.120423, acc.: 89.06%] [G loss: 0.887091]\n",
      "epoch:1 step:1357 [D loss: 0.144491, acc.: 79.69%] [G loss: 0.802314]\n",
      "epoch:1 step:1358 [D loss: 0.171865, acc.: 75.78%] [G loss: 0.820816]\n",
      "epoch:1 step:1359 [D loss: 0.195912, acc.: 73.44%] [G loss: 0.724698]\n",
      "epoch:1 step:1360 [D loss: 0.132859, acc.: 84.38%] [G loss: 0.816758]\n",
      "epoch:1 step:1361 [D loss: 0.207843, acc.: 72.66%] [G loss: 0.712931]\n",
      "epoch:1 step:1362 [D loss: 0.114192, acc.: 88.28%] [G loss: 0.899996]\n",
      "epoch:1 step:1363 [D loss: 0.155282, acc.: 82.03%] [G loss: 0.750428]\n",
      "epoch:1 step:1364 [D loss: 0.098759, acc.: 90.62%] [G loss: 0.847068]\n",
      "epoch:1 step:1365 [D loss: 0.121294, acc.: 84.38%] [G loss: 0.838977]\n",
      "epoch:1 step:1366 [D loss: 0.144685, acc.: 83.59%] [G loss: 0.724154]\n",
      "epoch:1 step:1367 [D loss: 0.132448, acc.: 83.59%] [G loss: 0.808733]\n",
      "epoch:1 step:1368 [D loss: 0.143998, acc.: 82.81%] [G loss: 0.820396]\n",
      "epoch:1 step:1369 [D loss: 0.183122, acc.: 73.44%] [G loss: 0.720819]\n",
      "epoch:1 step:1370 [D loss: 0.139929, acc.: 83.59%] [G loss: 0.845454]\n",
      "epoch:1 step:1371 [D loss: 0.191899, acc.: 75.78%] [G loss: 0.700748]\n",
      "epoch:1 step:1372 [D loss: 0.156587, acc.: 78.91%] [G loss: 0.714275]\n",
      "epoch:1 step:1373 [D loss: 0.148256, acc.: 78.12%] [G loss: 0.824660]\n",
      "epoch:1 step:1374 [D loss: 0.203909, acc.: 72.66%] [G loss: 0.700500]\n",
      "epoch:1 step:1375 [D loss: 0.141207, acc.: 84.38%] [G loss: 0.778133]\n",
      "epoch:1 step:1376 [D loss: 0.129613, acc.: 84.38%] [G loss: 0.828224]\n",
      "epoch:1 step:1377 [D loss: 0.156910, acc.: 83.59%] [G loss: 0.717564]\n",
      "epoch:1 step:1378 [D loss: 0.160093, acc.: 78.91%] [G loss: 0.786108]\n",
      "epoch:1 step:1379 [D loss: 0.170926, acc.: 77.34%] [G loss: 0.757786]\n",
      "epoch:1 step:1380 [D loss: 0.158215, acc.: 78.91%] [G loss: 0.792452]\n",
      "epoch:1 step:1381 [D loss: 0.144969, acc.: 85.16%] [G loss: 0.754439]\n",
      "epoch:1 step:1382 [D loss: 0.168928, acc.: 77.34%] [G loss: 0.796787]\n",
      "epoch:1 step:1383 [D loss: 0.164517, acc.: 78.12%] [G loss: 0.819500]\n",
      "epoch:1 step:1384 [D loss: 0.140776, acc.: 85.94%] [G loss: 0.783155]\n",
      "epoch:1 step:1385 [D loss: 0.244703, acc.: 65.62%] [G loss: 0.684298]\n",
      "epoch:1 step:1386 [D loss: 0.160839, acc.: 78.12%] [G loss: 0.748589]\n",
      "epoch:1 step:1387 [D loss: 0.144807, acc.: 82.81%] [G loss: 0.791380]\n",
      "epoch:1 step:1388 [D loss: 0.139171, acc.: 84.38%] [G loss: 0.840834]\n",
      "epoch:1 step:1389 [D loss: 0.175424, acc.: 78.12%] [G loss: 0.735059]\n",
      "epoch:1 step:1390 [D loss: 0.160560, acc.: 78.12%] [G loss: 0.787517]\n",
      "epoch:1 step:1391 [D loss: 0.185707, acc.: 73.44%] [G loss: 0.732416]\n",
      "epoch:1 step:1392 [D loss: 0.179246, acc.: 70.31%] [G loss: 0.779830]\n",
      "epoch:1 step:1393 [D loss: 0.144010, acc.: 82.03%] [G loss: 0.843447]\n",
      "epoch:1 step:1394 [D loss: 0.197133, acc.: 71.88%] [G loss: 0.748729]\n",
      "epoch:1 step:1395 [D loss: 0.143868, acc.: 78.91%] [G loss: 0.844312]\n",
      "epoch:1 step:1396 [D loss: 0.192056, acc.: 75.78%] [G loss: 0.749337]\n",
      "epoch:1 step:1397 [D loss: 0.132860, acc.: 84.38%] [G loss: 0.817328]\n",
      "epoch:1 step:1398 [D loss: 0.140846, acc.: 82.81%] [G loss: 0.789655]\n",
      "epoch:1 step:1399 [D loss: 0.185657, acc.: 74.22%] [G loss: 0.716874]\n",
      "epoch:1 step:1400 [D loss: 0.165287, acc.: 79.69%] [G loss: 0.698131]\n",
      "epoch:1 step:1401 [D loss: 0.127457, acc.: 86.72%] [G loss: 0.815453]\n",
      "epoch:1 step:1402 [D loss: 0.206610, acc.: 71.09%] [G loss: 0.680818]\n",
      "epoch:1 step:1403 [D loss: 0.136243, acc.: 85.94%] [G loss: 0.794390]\n",
      "epoch:1 step:1404 [D loss: 0.152645, acc.: 84.38%] [G loss: 0.795938]\n",
      "epoch:1 step:1405 [D loss: 0.166704, acc.: 78.91%] [G loss: 0.767181]\n",
      "epoch:1 step:1406 [D loss: 0.167131, acc.: 73.44%] [G loss: 0.740119]\n",
      "epoch:1 step:1407 [D loss: 0.130681, acc.: 85.16%] [G loss: 0.823704]\n",
      "epoch:1 step:1408 [D loss: 0.109326, acc.: 85.94%] [G loss: 0.823013]\n",
      "epoch:1 step:1409 [D loss: 0.187569, acc.: 69.53%] [G loss: 0.678886]\n",
      "epoch:1 step:1410 [D loss: 0.176620, acc.: 77.34%] [G loss: 0.714432]\n",
      "epoch:1 step:1411 [D loss: 0.155178, acc.: 82.81%] [G loss: 0.742701]\n",
      "epoch:1 step:1412 [D loss: 0.119494, acc.: 88.28%] [G loss: 0.802287]\n",
      "epoch:1 step:1413 [D loss: 0.123480, acc.: 86.72%] [G loss: 0.771311]\n",
      "epoch:1 step:1414 [D loss: 0.174111, acc.: 78.12%] [G loss: 0.698361]\n",
      "epoch:1 step:1415 [D loss: 0.126710, acc.: 88.28%] [G loss: 0.762415]\n",
      "epoch:1 step:1416 [D loss: 0.195178, acc.: 68.75%] [G loss: 0.694987]\n",
      "epoch:1 step:1417 [D loss: 0.128653, acc.: 85.16%] [G loss: 0.743559]\n",
      "epoch:1 step:1418 [D loss: 0.149384, acc.: 77.34%] [G loss: 0.767427]\n",
      "epoch:1 step:1419 [D loss: 0.164820, acc.: 78.12%] [G loss: 0.713883]\n",
      "epoch:1 step:1420 [D loss: 0.122867, acc.: 85.94%] [G loss: 0.744280]\n",
      "epoch:1 step:1421 [D loss: 0.140737, acc.: 82.81%] [G loss: 0.767132]\n",
      "epoch:1 step:1422 [D loss: 0.141334, acc.: 85.94%] [G loss: 0.737417]\n",
      "epoch:1 step:1423 [D loss: 0.131545, acc.: 84.38%] [G loss: 0.719462]\n",
      "epoch:1 step:1424 [D loss: 0.137063, acc.: 82.81%] [G loss: 0.805434]\n",
      "epoch:1 step:1425 [D loss: 0.131253, acc.: 84.38%] [G loss: 0.825384]\n",
      "epoch:1 step:1426 [D loss: 0.189662, acc.: 70.31%] [G loss: 0.714637]\n",
      "epoch:1 step:1427 [D loss: 0.126655, acc.: 87.50%] [G loss: 0.788580]\n",
      "epoch:1 step:1428 [D loss: 0.154332, acc.: 82.81%] [G loss: 0.815759]\n",
      "epoch:1 step:1429 [D loss: 0.182697, acc.: 73.44%] [G loss: 0.664501]\n",
      "epoch:1 step:1430 [D loss: 0.157548, acc.: 80.47%] [G loss: 0.781043]\n",
      "epoch:1 step:1431 [D loss: 0.161417, acc.: 80.47%] [G loss: 0.778128]\n",
      "epoch:1 step:1432 [D loss: 0.201591, acc.: 70.31%] [G loss: 0.688005]\n",
      "epoch:1 step:1433 [D loss: 0.163582, acc.: 79.69%] [G loss: 0.766468]\n",
      "epoch:1 step:1434 [D loss: 0.129181, acc.: 84.38%] [G loss: 0.812159]\n",
      "epoch:1 step:1435 [D loss: 0.125121, acc.: 88.28%] [G loss: 0.820779]\n",
      "epoch:1 step:1436 [D loss: 0.144606, acc.: 80.47%] [G loss: 0.821619]\n",
      "epoch:1 step:1437 [D loss: 0.178209, acc.: 73.44%] [G loss: 0.732814]\n",
      "epoch:1 step:1438 [D loss: 0.168240, acc.: 81.25%] [G loss: 0.722155]\n",
      "epoch:1 step:1439 [D loss: 0.146296, acc.: 83.59%] [G loss: 0.830419]\n",
      "epoch:1 step:1440 [D loss: 0.143002, acc.: 82.81%] [G loss: 0.933135]\n",
      "epoch:1 step:1441 [D loss: 0.143113, acc.: 82.03%] [G loss: 0.769765]\n",
      "epoch:1 step:1442 [D loss: 0.157653, acc.: 79.69%] [G loss: 0.802208]\n",
      "epoch:1 step:1443 [D loss: 0.134272, acc.: 84.38%] [G loss: 0.882506]\n",
      "epoch:1 step:1444 [D loss: 0.121055, acc.: 83.59%] [G loss: 0.861584]\n",
      "epoch:1 step:1445 [D loss: 0.154065, acc.: 84.38%] [G loss: 0.780542]\n",
      "epoch:1 step:1446 [D loss: 0.166425, acc.: 80.47%] [G loss: 0.824190]\n",
      "epoch:1 step:1447 [D loss: 0.154146, acc.: 77.34%] [G loss: 0.817080]\n",
      "epoch:1 step:1448 [D loss: 0.129848, acc.: 82.03%] [G loss: 0.800915]\n",
      "epoch:1 step:1449 [D loss: 0.161473, acc.: 75.78%] [G loss: 0.753700]\n",
      "epoch:1 step:1450 [D loss: 0.141399, acc.: 81.25%] [G loss: 0.798952]\n",
      "epoch:1 step:1451 [D loss: 0.147536, acc.: 83.59%] [G loss: 0.862866]\n",
      "epoch:1 step:1452 [D loss: 0.138555, acc.: 84.38%] [G loss: 0.887141]\n",
      "epoch:1 step:1453 [D loss: 0.169697, acc.: 75.78%] [G loss: 0.777375]\n",
      "epoch:1 step:1454 [D loss: 0.179823, acc.: 76.56%] [G loss: 0.730351]\n",
      "epoch:1 step:1455 [D loss: 0.119429, acc.: 85.16%] [G loss: 0.852041]\n",
      "epoch:1 step:1456 [D loss: 0.195750, acc.: 70.31%] [G loss: 0.692698]\n",
      "epoch:1 step:1457 [D loss: 0.139370, acc.: 83.59%] [G loss: 0.826282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1458 [D loss: 0.141129, acc.: 82.81%] [G loss: 0.784198]\n",
      "epoch:1 step:1459 [D loss: 0.165386, acc.: 76.56%] [G loss: 0.765016]\n",
      "epoch:1 step:1460 [D loss: 0.145534, acc.: 81.25%] [G loss: 0.828286]\n",
      "epoch:1 step:1461 [D loss: 0.162315, acc.: 77.34%] [G loss: 0.710887]\n",
      "epoch:1 step:1462 [D loss: 0.205752, acc.: 64.06%] [G loss: 0.836132]\n",
      "epoch:1 step:1463 [D loss: 0.134026, acc.: 85.16%] [G loss: 0.870219]\n",
      "epoch:1 step:1464 [D loss: 0.220266, acc.: 62.50%] [G loss: 0.667104]\n",
      "epoch:1 step:1465 [D loss: 0.141161, acc.: 85.16%] [G loss: 0.875019]\n",
      "epoch:1 step:1466 [D loss: 0.163649, acc.: 77.34%] [G loss: 0.794936]\n",
      "epoch:1 step:1467 [D loss: 0.157813, acc.: 78.12%] [G loss: 0.797098]\n",
      "epoch:1 step:1468 [D loss: 0.189694, acc.: 71.88%] [G loss: 0.684657]\n",
      "epoch:1 step:1469 [D loss: 0.164217, acc.: 80.47%] [G loss: 0.782754]\n",
      "epoch:1 step:1470 [D loss: 0.127378, acc.: 88.28%] [G loss: 0.890451]\n",
      "epoch:1 step:1471 [D loss: 0.150538, acc.: 81.25%] [G loss: 0.777602]\n",
      "epoch:1 step:1472 [D loss: 0.207561, acc.: 65.62%] [G loss: 0.711939]\n",
      "epoch:1 step:1473 [D loss: 0.125236, acc.: 89.06%] [G loss: 0.822462]\n",
      "epoch:1 step:1474 [D loss: 0.153205, acc.: 79.69%] [G loss: 0.779282]\n",
      "epoch:1 step:1475 [D loss: 0.165233, acc.: 78.12%] [G loss: 0.826190]\n",
      "epoch:1 step:1476 [D loss: 0.138800, acc.: 82.03%] [G loss: 0.776322]\n",
      "epoch:1 step:1477 [D loss: 0.140221, acc.: 81.25%] [G loss: 0.827161]\n",
      "epoch:1 step:1478 [D loss: 0.155336, acc.: 82.81%] [G loss: 0.791554]\n",
      "epoch:1 step:1479 [D loss: 0.138353, acc.: 84.38%] [G loss: 0.833505]\n",
      "epoch:1 step:1480 [D loss: 0.158148, acc.: 78.91%] [G loss: 0.712564]\n",
      "epoch:1 step:1481 [D loss: 0.120471, acc.: 87.50%] [G loss: 0.805655]\n",
      "epoch:1 step:1482 [D loss: 0.144895, acc.: 82.03%] [G loss: 0.779251]\n",
      "epoch:1 step:1483 [D loss: 0.120955, acc.: 84.38%] [G loss: 0.878011]\n",
      "epoch:1 step:1484 [D loss: 0.142264, acc.: 85.94%] [G loss: 0.756809]\n",
      "epoch:1 step:1485 [D loss: 0.099426, acc.: 89.84%] [G loss: 0.838972]\n",
      "epoch:1 step:1486 [D loss: 0.203839, acc.: 71.09%] [G loss: 0.709448]\n",
      "epoch:1 step:1487 [D loss: 0.112325, acc.: 87.50%] [G loss: 0.891912]\n",
      "epoch:1 step:1488 [D loss: 0.178657, acc.: 79.69%] [G loss: 0.697937]\n",
      "epoch:1 step:1489 [D loss: 0.108002, acc.: 89.84%] [G loss: 0.905136]\n",
      "epoch:1 step:1490 [D loss: 0.153183, acc.: 83.59%] [G loss: 0.775830]\n",
      "epoch:1 step:1491 [D loss: 0.113610, acc.: 88.28%] [G loss: 0.899580]\n",
      "epoch:1 step:1492 [D loss: 0.134531, acc.: 83.59%] [G loss: 0.823824]\n",
      "epoch:1 step:1493 [D loss: 0.105297, acc.: 88.28%] [G loss: 0.849812]\n",
      "epoch:1 step:1494 [D loss: 0.140783, acc.: 86.72%] [G loss: 0.767926]\n",
      "epoch:1 step:1495 [D loss: 0.118775, acc.: 87.50%] [G loss: 0.806200]\n",
      "epoch:1 step:1496 [D loss: 0.199451, acc.: 69.53%] [G loss: 0.670649]\n",
      "epoch:1 step:1497 [D loss: 0.166349, acc.: 81.25%] [G loss: 0.739419]\n",
      "epoch:1 step:1498 [D loss: 0.146686, acc.: 82.81%] [G loss: 0.744728]\n",
      "epoch:1 step:1499 [D loss: 0.150775, acc.: 78.91%] [G loss: 0.769624]\n",
      "epoch:1 step:1500 [D loss: 0.124678, acc.: 87.50%] [G loss: 0.827258]\n",
      "epoch:1 step:1501 [D loss: 0.150266, acc.: 82.81%] [G loss: 0.779333]\n",
      "epoch:1 step:1502 [D loss: 0.130146, acc.: 86.72%] [G loss: 0.870094]\n",
      "epoch:1 step:1503 [D loss: 0.198288, acc.: 71.09%] [G loss: 0.760275]\n",
      "epoch:1 step:1504 [D loss: 0.111963, acc.: 85.16%] [G loss: 0.864143]\n",
      "epoch:1 step:1505 [D loss: 0.124825, acc.: 82.03%] [G loss: 0.838470]\n",
      "epoch:1 step:1506 [D loss: 0.133682, acc.: 82.03%] [G loss: 0.798122]\n",
      "epoch:1 step:1507 [D loss: 0.137072, acc.: 81.25%] [G loss: 0.855054]\n",
      "epoch:1 step:1508 [D loss: 0.159893, acc.: 78.12%] [G loss: 0.735710]\n",
      "epoch:1 step:1509 [D loss: 0.109656, acc.: 89.84%] [G loss: 0.941916]\n",
      "epoch:1 step:1510 [D loss: 0.191662, acc.: 74.22%] [G loss: 0.759119]\n",
      "epoch:1 step:1511 [D loss: 0.152854, acc.: 82.03%] [G loss: 0.865843]\n",
      "epoch:1 step:1512 [D loss: 0.123257, acc.: 83.59%] [G loss: 0.814079]\n",
      "epoch:1 step:1513 [D loss: 0.204545, acc.: 70.31%] [G loss: 0.728358]\n",
      "epoch:1 step:1514 [D loss: 0.162146, acc.: 78.12%] [G loss: 0.816934]\n",
      "epoch:1 step:1515 [D loss: 0.142923, acc.: 85.94%] [G loss: 0.873888]\n",
      "epoch:1 step:1516 [D loss: 0.138160, acc.: 83.59%] [G loss: 0.865373]\n",
      "epoch:1 step:1517 [D loss: 0.156643, acc.: 79.69%] [G loss: 0.836894]\n",
      "epoch:1 step:1518 [D loss: 0.165554, acc.: 79.69%] [G loss: 0.761021]\n",
      "epoch:1 step:1519 [D loss: 0.122624, acc.: 85.16%] [G loss: 0.918089]\n",
      "epoch:1 step:1520 [D loss: 0.237235, acc.: 65.62%] [G loss: 0.688406]\n",
      "epoch:1 step:1521 [D loss: 0.150114, acc.: 82.81%] [G loss: 0.784530]\n",
      "epoch:1 step:1522 [D loss: 0.214751, acc.: 67.97%] [G loss: 0.736864]\n",
      "epoch:1 step:1523 [D loss: 0.203765, acc.: 68.75%] [G loss: 0.681375]\n",
      "epoch:1 step:1524 [D loss: 0.182020, acc.: 74.22%] [G loss: 0.767230]\n",
      "epoch:1 step:1525 [D loss: 0.202911, acc.: 71.09%] [G loss: 0.749086]\n",
      "epoch:1 step:1526 [D loss: 0.173849, acc.: 77.34%] [G loss: 0.793436]\n",
      "epoch:1 step:1527 [D loss: 0.154423, acc.: 82.81%] [G loss: 0.770699]\n",
      "epoch:1 step:1528 [D loss: 0.122339, acc.: 86.72%] [G loss: 0.822677]\n",
      "epoch:1 step:1529 [D loss: 0.116806, acc.: 83.59%] [G loss: 0.832992]\n",
      "epoch:1 step:1530 [D loss: 0.181501, acc.: 77.34%] [G loss: 0.731042]\n",
      "epoch:1 step:1531 [D loss: 0.168598, acc.: 75.78%] [G loss: 0.759156]\n",
      "epoch:1 step:1532 [D loss: 0.153103, acc.: 83.59%] [G loss: 0.739304]\n",
      "epoch:1 step:1533 [D loss: 0.155431, acc.: 78.91%] [G loss: 0.744452]\n",
      "epoch:1 step:1534 [D loss: 0.144017, acc.: 81.25%] [G loss: 0.778563]\n",
      "epoch:1 step:1535 [D loss: 0.127773, acc.: 85.16%] [G loss: 0.835048]\n",
      "epoch:1 step:1536 [D loss: 0.149818, acc.: 78.12%] [G loss: 0.783545]\n",
      "epoch:1 step:1537 [D loss: 0.167646, acc.: 75.78%] [G loss: 0.666426]\n",
      "epoch:1 step:1538 [D loss: 0.153578, acc.: 83.59%] [G loss: 0.763614]\n",
      "epoch:1 step:1539 [D loss: 0.114995, acc.: 87.50%] [G loss: 0.785478]\n",
      "epoch:1 step:1540 [D loss: 0.125429, acc.: 86.72%] [G loss: 0.799019]\n",
      "epoch:1 step:1541 [D loss: 0.170078, acc.: 75.00%] [G loss: 0.698873]\n",
      "epoch:1 step:1542 [D loss: 0.108289, acc.: 85.94%] [G loss: 0.817318]\n",
      "epoch:1 step:1543 [D loss: 0.141855, acc.: 82.03%] [G loss: 0.769998]\n",
      "epoch:1 step:1544 [D loss: 0.179850, acc.: 70.31%] [G loss: 0.726339]\n",
      "epoch:1 step:1545 [D loss: 0.143499, acc.: 85.94%] [G loss: 0.760775]\n",
      "epoch:1 step:1546 [D loss: 0.142119, acc.: 81.25%] [G loss: 0.755489]\n",
      "epoch:1 step:1547 [D loss: 0.159014, acc.: 78.91%] [G loss: 0.729792]\n",
      "epoch:1 step:1548 [D loss: 0.109384, acc.: 91.41%] [G loss: 0.814406]\n",
      "epoch:1 step:1549 [D loss: 0.139127, acc.: 86.72%] [G loss: 0.791423]\n",
      "epoch:1 step:1550 [D loss: 0.129280, acc.: 84.38%] [G loss: 0.743359]\n",
      "epoch:1 step:1551 [D loss: 0.102042, acc.: 91.41%] [G loss: 0.765945]\n",
      "epoch:1 step:1552 [D loss: 0.188845, acc.: 71.09%] [G loss: 0.623270]\n",
      "epoch:1 step:1553 [D loss: 0.116113, acc.: 88.28%] [G loss: 0.835550]\n",
      "epoch:1 step:1554 [D loss: 0.141188, acc.: 84.38%] [G loss: 0.786926]\n",
      "epoch:1 step:1555 [D loss: 0.148658, acc.: 84.38%] [G loss: 0.681730]\n",
      "epoch:1 step:1556 [D loss: 0.116331, acc.: 87.50%] [G loss: 0.807917]\n",
      "epoch:1 step:1557 [D loss: 0.122235, acc.: 88.28%] [G loss: 0.781732]\n",
      "epoch:1 step:1558 [D loss: 0.178411, acc.: 75.78%] [G loss: 0.643803]\n",
      "epoch:1 step:1559 [D loss: 0.156372, acc.: 84.38%] [G loss: 0.715580]\n",
      "epoch:1 step:1560 [D loss: 0.144708, acc.: 84.38%] [G loss: 0.728541]\n",
      "epoch:1 step:1561 [D loss: 0.138210, acc.: 84.38%] [G loss: 0.747676]\n",
      "epoch:1 step:1562 [D loss: 0.175399, acc.: 78.12%] [G loss: 0.669767]\n",
      "epoch:1 step:1563 [D loss: 0.140371, acc.: 82.81%] [G loss: 0.803980]\n",
      "epoch:1 step:1564 [D loss: 0.140412, acc.: 83.59%] [G loss: 0.737193]\n",
      "epoch:1 step:1565 [D loss: 0.143271, acc.: 85.16%] [G loss: 0.694991]\n",
      "epoch:1 step:1566 [D loss: 0.137998, acc.: 85.16%] [G loss: 0.809630]\n",
      "epoch:1 step:1567 [D loss: 0.156301, acc.: 83.59%] [G loss: 0.683940]\n",
      "epoch:1 step:1568 [D loss: 0.117961, acc.: 92.19%] [G loss: 0.714576]\n",
      "epoch:1 step:1569 [D loss: 0.136820, acc.: 82.03%] [G loss: 0.730474]\n",
      "epoch:1 step:1570 [D loss: 0.099488, acc.: 91.41%] [G loss: 0.835845]\n",
      "epoch:1 step:1571 [D loss: 0.145064, acc.: 82.03%] [G loss: 0.726118]\n",
      "epoch:1 step:1572 [D loss: 0.140518, acc.: 84.38%] [G loss: 0.801766]\n",
      "epoch:1 step:1573 [D loss: 0.193854, acc.: 71.88%] [G loss: 0.673461]\n",
      "epoch:1 step:1574 [D loss: 0.124261, acc.: 83.59%] [G loss: 0.808329]\n",
      "epoch:1 step:1575 [D loss: 0.102104, acc.: 89.06%] [G loss: 0.805359]\n",
      "epoch:1 step:1576 [D loss: 0.134251, acc.: 85.94%] [G loss: 0.718726]\n",
      "epoch:1 step:1577 [D loss: 0.116162, acc.: 88.28%] [G loss: 0.737473]\n",
      "epoch:1 step:1578 [D loss: 0.108788, acc.: 86.72%] [G loss: 0.828081]\n",
      "epoch:1 step:1579 [D loss: 0.104939, acc.: 88.28%] [G loss: 0.759273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1580 [D loss: 0.135981, acc.: 85.16%] [G loss: 0.728897]\n",
      "epoch:1 step:1581 [D loss: 0.138563, acc.: 86.72%] [G loss: 0.763531]\n",
      "epoch:1 step:1582 [D loss: 0.138859, acc.: 85.16%] [G loss: 0.832339]\n",
      "epoch:1 step:1583 [D loss: 0.127252, acc.: 84.38%] [G loss: 0.819110]\n",
      "epoch:1 step:1584 [D loss: 0.136557, acc.: 84.38%] [G loss: 0.792003]\n",
      "epoch:1 step:1585 [D loss: 0.120988, acc.: 89.06%] [G loss: 0.858697]\n",
      "epoch:1 step:1586 [D loss: 0.155661, acc.: 78.91%] [G loss: 0.772114]\n",
      "epoch:1 step:1587 [D loss: 0.121780, acc.: 85.16%] [G loss: 0.786854]\n",
      "epoch:1 step:1588 [D loss: 0.154612, acc.: 79.69%] [G loss: 0.788796]\n",
      "epoch:1 step:1589 [D loss: 0.190856, acc.: 74.22%] [G loss: 0.705799]\n",
      "epoch:1 step:1590 [D loss: 0.174556, acc.: 71.88%] [G loss: 0.796633]\n",
      "epoch:1 step:1591 [D loss: 0.129373, acc.: 83.59%] [G loss: 0.804432]\n",
      "epoch:1 step:1592 [D loss: 0.195579, acc.: 73.44%] [G loss: 0.736840]\n",
      "epoch:1 step:1593 [D loss: 0.101533, acc.: 89.84%] [G loss: 0.816804]\n",
      "epoch:1 step:1594 [D loss: 0.131575, acc.: 86.72%] [G loss: 0.810822]\n",
      "epoch:1 step:1595 [D loss: 0.115945, acc.: 88.28%] [G loss: 0.738939]\n",
      "epoch:1 step:1596 [D loss: 0.139908, acc.: 82.81%] [G loss: 0.740868]\n",
      "epoch:1 step:1597 [D loss: 0.123050, acc.: 85.94%] [G loss: 0.828813]\n",
      "epoch:1 step:1598 [D loss: 0.115370, acc.: 85.16%] [G loss: 0.817602]\n",
      "epoch:1 step:1599 [D loss: 0.173001, acc.: 79.69%] [G loss: 0.684723]\n",
      "epoch:1 step:1600 [D loss: 0.094840, acc.: 95.31%] [G loss: 0.888577]\n",
      "epoch:1 step:1601 [D loss: 0.197802, acc.: 69.53%] [G loss: 0.700965]\n",
      "epoch:1 step:1602 [D loss: 0.146945, acc.: 81.25%] [G loss: 0.817228]\n",
      "epoch:1 step:1603 [D loss: 0.141154, acc.: 82.03%] [G loss: 0.762896]\n",
      "epoch:1 step:1604 [D loss: 0.135968, acc.: 83.59%] [G loss: 0.691671]\n",
      "epoch:1 step:1605 [D loss: 0.141850, acc.: 80.47%] [G loss: 0.761204]\n",
      "epoch:1 step:1606 [D loss: 0.120256, acc.: 87.50%] [G loss: 0.807803]\n",
      "epoch:1 step:1607 [D loss: 0.135084, acc.: 85.16%] [G loss: 0.694047]\n",
      "epoch:1 step:1608 [D loss: 0.175692, acc.: 74.22%] [G loss: 0.744438]\n",
      "epoch:1 step:1609 [D loss: 0.240923, acc.: 63.28%] [G loss: 0.656270]\n",
      "epoch:1 step:1610 [D loss: 0.194223, acc.: 64.06%] [G loss: 0.750031]\n",
      "epoch:1 step:1611 [D loss: 0.170248, acc.: 75.00%] [G loss: 0.819648]\n",
      "epoch:1 step:1612 [D loss: 0.142928, acc.: 80.47%] [G loss: 0.843951]\n",
      "epoch:1 step:1613 [D loss: 0.146709, acc.: 79.69%] [G loss: 0.767870]\n",
      "epoch:1 step:1614 [D loss: 0.152211, acc.: 78.12%] [G loss: 0.826386]\n",
      "epoch:1 step:1615 [D loss: 0.138252, acc.: 85.16%] [G loss: 0.766375]\n",
      "epoch:1 step:1616 [D loss: 0.175281, acc.: 74.22%] [G loss: 0.757197]\n",
      "epoch:1 step:1617 [D loss: 0.135019, acc.: 87.50%] [G loss: 0.816876]\n",
      "epoch:1 step:1618 [D loss: 0.199402, acc.: 65.62%] [G loss: 0.666260]\n",
      "epoch:1 step:1619 [D loss: 0.135620, acc.: 79.69%] [G loss: 0.838077]\n",
      "epoch:1 step:1620 [D loss: 0.214702, acc.: 69.53%] [G loss: 0.657068]\n",
      "epoch:1 step:1621 [D loss: 0.157462, acc.: 76.56%] [G loss: 0.781159]\n",
      "epoch:1 step:1622 [D loss: 0.190842, acc.: 74.22%] [G loss: 0.753604]\n",
      "epoch:1 step:1623 [D loss: 0.177011, acc.: 75.78%] [G loss: 0.663944]\n",
      "epoch:1 step:1624 [D loss: 0.175014, acc.: 72.66%] [G loss: 0.733019]\n",
      "epoch:1 step:1625 [D loss: 0.163652, acc.: 79.69%] [G loss: 0.715161]\n",
      "epoch:1 step:1626 [D loss: 0.132508, acc.: 85.94%] [G loss: 0.734979]\n",
      "epoch:1 step:1627 [D loss: 0.160938, acc.: 80.47%] [G loss: 0.728141]\n",
      "epoch:1 step:1628 [D loss: 0.142250, acc.: 82.81%] [G loss: 0.785776]\n",
      "epoch:1 step:1629 [D loss: 0.179486, acc.: 75.00%] [G loss: 0.669785]\n",
      "epoch:1 step:1630 [D loss: 0.147608, acc.: 80.47%] [G loss: 0.732576]\n",
      "epoch:1 step:1631 [D loss: 0.159160, acc.: 82.03%] [G loss: 0.729841]\n",
      "epoch:1 step:1632 [D loss: 0.132995, acc.: 82.03%] [G loss: 0.781323]\n",
      "epoch:1 step:1633 [D loss: 0.200237, acc.: 71.09%] [G loss: 0.658130]\n",
      "epoch:1 step:1634 [D loss: 0.124710, acc.: 85.16%] [G loss: 0.808936]\n",
      "epoch:1 step:1635 [D loss: 0.170191, acc.: 77.34%] [G loss: 0.722929]\n",
      "epoch:1 step:1636 [D loss: 0.148198, acc.: 78.12%] [G loss: 0.717889]\n",
      "epoch:1 step:1637 [D loss: 0.179351, acc.: 76.56%] [G loss: 0.711174]\n",
      "epoch:1 step:1638 [D loss: 0.150699, acc.: 83.59%] [G loss: 0.834798]\n",
      "epoch:1 step:1639 [D loss: 0.164066, acc.: 79.69%] [G loss: 0.800879]\n",
      "epoch:1 step:1640 [D loss: 0.159852, acc.: 77.34%] [G loss: 0.768266]\n",
      "epoch:1 step:1641 [D loss: 0.165879, acc.: 77.34%] [G loss: 0.713305]\n",
      "epoch:1 step:1642 [D loss: 0.153105, acc.: 80.47%] [G loss: 0.767200]\n",
      "epoch:1 step:1643 [D loss: 0.154643, acc.: 79.69%] [G loss: 0.683478]\n",
      "epoch:1 step:1644 [D loss: 0.110766, acc.: 85.94%] [G loss: 0.812154]\n",
      "epoch:1 step:1645 [D loss: 0.124349, acc.: 82.03%] [G loss: 0.800349]\n",
      "epoch:1 step:1646 [D loss: 0.128247, acc.: 83.59%] [G loss: 0.802484]\n",
      "epoch:1 step:1647 [D loss: 0.279595, acc.: 56.25%] [G loss: 0.594706]\n",
      "epoch:1 step:1648 [D loss: 0.197934, acc.: 69.53%] [G loss: 0.706847]\n",
      "epoch:1 step:1649 [D loss: 0.125195, acc.: 84.38%] [G loss: 0.818352]\n",
      "epoch:1 step:1650 [D loss: 0.168586, acc.: 78.91%] [G loss: 0.652490]\n",
      "epoch:1 step:1651 [D loss: 0.134756, acc.: 85.16%] [G loss: 0.800896]\n",
      "epoch:1 step:1652 [D loss: 0.148430, acc.: 81.25%] [G loss: 0.690097]\n",
      "epoch:1 step:1653 [D loss: 0.201458, acc.: 72.66%] [G loss: 0.648960]\n",
      "epoch:1 step:1654 [D loss: 0.140124, acc.: 80.47%] [G loss: 0.766497]\n",
      "epoch:1 step:1655 [D loss: 0.155427, acc.: 80.47%] [G loss: 0.735966]\n",
      "epoch:1 step:1656 [D loss: 0.164506, acc.: 78.91%] [G loss: 0.683585]\n",
      "epoch:1 step:1657 [D loss: 0.179589, acc.: 76.56%] [G loss: 0.696824]\n",
      "epoch:1 step:1658 [D loss: 0.128617, acc.: 83.59%] [G loss: 0.773880]\n",
      "epoch:1 step:1659 [D loss: 0.123714, acc.: 85.94%] [G loss: 0.791369]\n",
      "epoch:1 step:1660 [D loss: 0.217494, acc.: 67.19%] [G loss: 0.607307]\n",
      "epoch:1 step:1661 [D loss: 0.150833, acc.: 78.91%] [G loss: 0.811497]\n",
      "epoch:1 step:1662 [D loss: 0.136885, acc.: 86.72%] [G loss: 0.761760]\n",
      "epoch:1 step:1663 [D loss: 0.153002, acc.: 81.25%] [G loss: 0.704610]\n",
      "epoch:1 step:1664 [D loss: 0.149060, acc.: 87.50%] [G loss: 0.747848]\n",
      "epoch:1 step:1665 [D loss: 0.121388, acc.: 85.94%] [G loss: 0.750053]\n",
      "epoch:1 step:1666 [D loss: 0.118742, acc.: 84.38%] [G loss: 0.696755]\n",
      "epoch:1 step:1667 [D loss: 0.136743, acc.: 82.81%] [G loss: 0.772182]\n",
      "epoch:1 step:1668 [D loss: 0.123498, acc.: 82.81%] [G loss: 0.832307]\n",
      "epoch:1 step:1669 [D loss: 0.144622, acc.: 81.25%] [G loss: 0.786858]\n",
      "epoch:1 step:1670 [D loss: 0.180325, acc.: 75.78%] [G loss: 0.691455]\n",
      "epoch:1 step:1671 [D loss: 0.149197, acc.: 79.69%] [G loss: 0.741875]\n",
      "epoch:1 step:1672 [D loss: 0.144812, acc.: 85.94%] [G loss: 0.768902]\n",
      "epoch:1 step:1673 [D loss: 0.159015, acc.: 80.47%] [G loss: 0.745656]\n",
      "epoch:1 step:1674 [D loss: 0.171125, acc.: 78.91%] [G loss: 0.702876]\n",
      "epoch:1 step:1675 [D loss: 0.169686, acc.: 74.22%] [G loss: 0.715529]\n",
      "epoch:1 step:1676 [D loss: 0.177730, acc.: 77.34%] [G loss: 0.720657]\n",
      "epoch:1 step:1677 [D loss: 0.225724, acc.: 67.97%] [G loss: 0.605249]\n",
      "epoch:1 step:1678 [D loss: 0.144402, acc.: 84.38%] [G loss: 0.689980]\n",
      "epoch:1 step:1679 [D loss: 0.177675, acc.: 77.34%] [G loss: 0.776376]\n",
      "epoch:1 step:1680 [D loss: 0.138420, acc.: 84.38%] [G loss: 0.757823]\n",
      "epoch:1 step:1681 [D loss: 0.170088, acc.: 78.12%] [G loss: 0.645258]\n",
      "epoch:1 step:1682 [D loss: 0.116570, acc.: 85.94%] [G loss: 0.750490]\n",
      "epoch:1 step:1683 [D loss: 0.092040, acc.: 91.41%] [G loss: 0.811672]\n",
      "epoch:1 step:1684 [D loss: 0.095140, acc.: 86.72%] [G loss: 0.804343]\n",
      "epoch:1 step:1685 [D loss: 0.139007, acc.: 82.81%] [G loss: 0.657354]\n",
      "epoch:1 step:1686 [D loss: 0.125170, acc.: 81.25%] [G loss: 0.773345]\n",
      "epoch:1 step:1687 [D loss: 0.154693, acc.: 80.47%] [G loss: 0.752536]\n",
      "epoch:1 step:1688 [D loss: 0.143675, acc.: 82.03%] [G loss: 0.753034]\n",
      "epoch:1 step:1689 [D loss: 0.100244, acc.: 91.41%] [G loss: 0.844659]\n",
      "epoch:1 step:1690 [D loss: 0.130012, acc.: 87.50%] [G loss: 0.773976]\n",
      "epoch:1 step:1691 [D loss: 0.099327, acc.: 90.62%] [G loss: 0.791610]\n",
      "epoch:1 step:1692 [D loss: 0.150167, acc.: 79.69%] [G loss: 0.765389]\n",
      "epoch:1 step:1693 [D loss: 0.150783, acc.: 80.47%] [G loss: 0.752883]\n",
      "epoch:1 step:1694 [D loss: 0.120091, acc.: 85.16%] [G loss: 0.926101]\n",
      "epoch:1 step:1695 [D loss: 0.146231, acc.: 80.47%] [G loss: 0.803320]\n",
      "epoch:1 step:1696 [D loss: 0.136240, acc.: 85.94%] [G loss: 0.747676]\n",
      "epoch:1 step:1697 [D loss: 0.135583, acc.: 83.59%] [G loss: 0.796922]\n",
      "epoch:1 step:1698 [D loss: 0.128833, acc.: 85.94%] [G loss: 0.757335]\n",
      "epoch:1 step:1699 [D loss: 0.130692, acc.: 83.59%] [G loss: 0.719872]\n",
      "epoch:1 step:1700 [D loss: 0.109268, acc.: 88.28%] [G loss: 0.865087]\n",
      "epoch:1 step:1701 [D loss: 0.127184, acc.: 84.38%] [G loss: 0.809165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1702 [D loss: 0.229317, acc.: 68.75%] [G loss: 0.666595]\n",
      "epoch:1 step:1703 [D loss: 0.194670, acc.: 67.97%] [G loss: 0.692383]\n",
      "epoch:1 step:1704 [D loss: 0.135885, acc.: 82.03%] [G loss: 0.803578]\n",
      "epoch:1 step:1705 [D loss: 0.166333, acc.: 80.47%] [G loss: 0.722643]\n",
      "epoch:1 step:1706 [D loss: 0.115006, acc.: 88.28%] [G loss: 0.786509]\n",
      "epoch:1 step:1707 [D loss: 0.131239, acc.: 85.16%] [G loss: 0.791637]\n",
      "epoch:1 step:1708 [D loss: 0.121816, acc.: 87.50%] [G loss: 0.761170]\n",
      "epoch:1 step:1709 [D loss: 0.119909, acc.: 84.38%] [G loss: 0.820303]\n",
      "epoch:1 step:1710 [D loss: 0.128497, acc.: 85.16%] [G loss: 0.808493]\n",
      "epoch:1 step:1711 [D loss: 0.229139, acc.: 64.84%] [G loss: 0.653563]\n",
      "epoch:1 step:1712 [D loss: 0.116388, acc.: 86.72%] [G loss: 0.842623]\n",
      "epoch:1 step:1713 [D loss: 0.125960, acc.: 84.38%] [G loss: 0.809047]\n",
      "epoch:1 step:1714 [D loss: 0.161359, acc.: 78.12%] [G loss: 0.728500]\n",
      "epoch:1 step:1715 [D loss: 0.152594, acc.: 81.25%] [G loss: 0.794265]\n",
      "epoch:1 step:1716 [D loss: 0.146283, acc.: 81.25%] [G loss: 0.850911]\n",
      "epoch:1 step:1717 [D loss: 0.152421, acc.: 82.03%] [G loss: 0.786631]\n",
      "epoch:1 step:1718 [D loss: 0.115793, acc.: 86.72%] [G loss: 0.877689]\n",
      "epoch:1 step:1719 [D loss: 0.133677, acc.: 82.03%] [G loss: 0.801989]\n",
      "epoch:1 step:1720 [D loss: 0.163458, acc.: 78.12%] [G loss: 0.787138]\n",
      "epoch:1 step:1721 [D loss: 0.155071, acc.: 82.03%] [G loss: 0.824179]\n",
      "epoch:1 step:1722 [D loss: 0.158478, acc.: 78.12%] [G loss: 0.665539]\n",
      "epoch:1 step:1723 [D loss: 0.107712, acc.: 85.94%] [G loss: 0.931963]\n",
      "epoch:1 step:1724 [D loss: 0.212393, acc.: 72.66%] [G loss: 0.758578]\n",
      "epoch:1 step:1725 [D loss: 0.177339, acc.: 70.31%] [G loss: 0.790584]\n",
      "epoch:1 step:1726 [D loss: 0.156433, acc.: 80.47%] [G loss: 0.794343]\n",
      "epoch:1 step:1727 [D loss: 0.181722, acc.: 78.12%] [G loss: 0.716764]\n",
      "epoch:1 step:1728 [D loss: 0.127046, acc.: 82.03%] [G loss: 0.890330]\n",
      "epoch:1 step:1729 [D loss: 0.146851, acc.: 79.69%] [G loss: 0.815551]\n",
      "epoch:1 step:1730 [D loss: 0.191483, acc.: 75.00%] [G loss: 0.714972]\n",
      "epoch:1 step:1731 [D loss: 0.152987, acc.: 78.12%] [G loss: 0.864478]\n",
      "epoch:1 step:1732 [D loss: 0.146679, acc.: 84.38%] [G loss: 0.818688]\n",
      "epoch:1 step:1733 [D loss: 0.162831, acc.: 82.03%] [G loss: 0.812516]\n",
      "epoch:1 step:1734 [D loss: 0.181044, acc.: 75.00%] [G loss: 0.738888]\n",
      "epoch:1 step:1735 [D loss: 0.098136, acc.: 89.84%] [G loss: 0.861075]\n",
      "epoch:1 step:1736 [D loss: 0.197429, acc.: 73.44%] [G loss: 0.667524]\n",
      "epoch:1 step:1737 [D loss: 0.170683, acc.: 77.34%] [G loss: 0.745076]\n",
      "epoch:1 step:1738 [D loss: 0.121179, acc.: 86.72%] [G loss: 0.825985]\n",
      "epoch:1 step:1739 [D loss: 0.140646, acc.: 79.69%] [G loss: 0.758536]\n",
      "epoch:1 step:1740 [D loss: 0.142812, acc.: 83.59%] [G loss: 0.773071]\n",
      "epoch:1 step:1741 [D loss: 0.144450, acc.: 82.03%] [G loss: 0.702065]\n",
      "epoch:1 step:1742 [D loss: 0.104706, acc.: 90.62%] [G loss: 0.833193]\n",
      "epoch:1 step:1743 [D loss: 0.133299, acc.: 86.72%] [G loss: 0.837282]\n",
      "epoch:1 step:1744 [D loss: 0.146317, acc.: 82.03%] [G loss: 0.757668]\n",
      "epoch:1 step:1745 [D loss: 0.166066, acc.: 78.12%] [G loss: 0.746734]\n",
      "epoch:1 step:1746 [D loss: 0.190137, acc.: 77.34%] [G loss: 0.716523]\n",
      "epoch:1 step:1747 [D loss: 0.167183, acc.: 77.34%] [G loss: 0.722157]\n",
      "epoch:1 step:1748 [D loss: 0.184876, acc.: 72.66%] [G loss: 0.727119]\n",
      "epoch:1 step:1749 [D loss: 0.145401, acc.: 85.94%] [G loss: 0.802380]\n",
      "epoch:1 step:1750 [D loss: 0.147007, acc.: 82.03%] [G loss: 0.759780]\n",
      "epoch:1 step:1751 [D loss: 0.161297, acc.: 81.25%] [G loss: 0.752548]\n",
      "epoch:1 step:1752 [D loss: 0.199548, acc.: 68.75%] [G loss: 0.714351]\n",
      "epoch:1 step:1753 [D loss: 0.138039, acc.: 85.16%] [G loss: 0.791804]\n",
      "epoch:1 step:1754 [D loss: 0.189615, acc.: 75.00%] [G loss: 0.739618]\n",
      "epoch:1 step:1755 [D loss: 0.134714, acc.: 85.16%] [G loss: 0.751097]\n",
      "epoch:1 step:1756 [D loss: 0.122724, acc.: 84.38%] [G loss: 0.809987]\n",
      "epoch:1 step:1757 [D loss: 0.149792, acc.: 83.59%] [G loss: 0.706409]\n",
      "epoch:1 step:1758 [D loss: 0.145968, acc.: 85.94%] [G loss: 0.652410]\n",
      "epoch:1 step:1759 [D loss: 0.086380, acc.: 94.53%] [G loss: 0.808489]\n",
      "epoch:1 step:1760 [D loss: 0.142002, acc.: 81.25%] [G loss: 0.733208]\n",
      "epoch:1 step:1761 [D loss: 0.203034, acc.: 70.31%] [G loss: 0.616906]\n",
      "epoch:1 step:1762 [D loss: 0.151741, acc.: 82.03%] [G loss: 0.731086]\n",
      "epoch:1 step:1763 [D loss: 0.160801, acc.: 78.91%] [G loss: 0.691223]\n",
      "epoch:1 step:1764 [D loss: 0.182361, acc.: 75.78%] [G loss: 0.643517]\n",
      "epoch:1 step:1765 [D loss: 0.170886, acc.: 79.69%] [G loss: 0.689872]\n",
      "epoch:1 step:1766 [D loss: 0.100185, acc.: 91.41%] [G loss: 0.780311]\n",
      "epoch:1 step:1767 [D loss: 0.113875, acc.: 90.62%] [G loss: 0.756564]\n",
      "epoch:1 step:1768 [D loss: 0.171205, acc.: 76.56%] [G loss: 0.678877]\n",
      "epoch:1 step:1769 [D loss: 0.116933, acc.: 85.94%] [G loss: 0.778171]\n",
      "epoch:1 step:1770 [D loss: 0.103443, acc.: 89.84%] [G loss: 0.796265]\n",
      "epoch:1 step:1771 [D loss: 0.139990, acc.: 83.59%] [G loss: 0.692324]\n",
      "epoch:1 step:1772 [D loss: 0.111115, acc.: 88.28%] [G loss: 0.739564]\n",
      "epoch:1 step:1773 [D loss: 0.176068, acc.: 74.22%] [G loss: 0.657494]\n",
      "epoch:1 step:1774 [D loss: 0.120114, acc.: 85.16%] [G loss: 0.787741]\n",
      "epoch:1 step:1775 [D loss: 0.156298, acc.: 78.91%] [G loss: 0.736041]\n",
      "epoch:1 step:1776 [D loss: 0.160081, acc.: 81.25%] [G loss: 0.697477]\n",
      "epoch:1 step:1777 [D loss: 0.165937, acc.: 77.34%] [G loss: 0.720456]\n",
      "epoch:1 step:1778 [D loss: 0.112892, acc.: 89.06%] [G loss: 0.789987]\n",
      "epoch:1 step:1779 [D loss: 0.146963, acc.: 81.25%] [G loss: 0.775206]\n",
      "epoch:1 step:1780 [D loss: 0.146294, acc.: 80.47%] [G loss: 0.720978]\n",
      "epoch:1 step:1781 [D loss: 0.134678, acc.: 82.03%] [G loss: 0.744425]\n",
      "epoch:1 step:1782 [D loss: 0.116013, acc.: 84.38%] [G loss: 0.815596]\n",
      "epoch:1 step:1783 [D loss: 0.130748, acc.: 83.59%] [G loss: 0.725830]\n",
      "epoch:1 step:1784 [D loss: 0.108565, acc.: 89.84%] [G loss: 0.705209]\n",
      "epoch:1 step:1785 [D loss: 0.112689, acc.: 85.94%] [G loss: 0.769633]\n",
      "epoch:1 step:1786 [D loss: 0.144273, acc.: 85.16%] [G loss: 0.657841]\n",
      "epoch:1 step:1787 [D loss: 0.127727, acc.: 85.16%] [G loss: 0.789836]\n",
      "epoch:1 step:1788 [D loss: 0.150438, acc.: 80.47%] [G loss: 0.712187]\n",
      "epoch:1 step:1789 [D loss: 0.100068, acc.: 92.19%] [G loss: 0.844435]\n",
      "epoch:1 step:1790 [D loss: 0.125373, acc.: 84.38%] [G loss: 0.799249]\n",
      "epoch:1 step:1791 [D loss: 0.114340, acc.: 86.72%] [G loss: 0.762281]\n",
      "epoch:1 step:1792 [D loss: 0.134929, acc.: 82.03%] [G loss: 0.729808]\n",
      "epoch:1 step:1793 [D loss: 0.125570, acc.: 84.38%] [G loss: 0.755738]\n",
      "epoch:1 step:1794 [D loss: 0.129228, acc.: 86.72%] [G loss: 0.741425]\n",
      "epoch:1 step:1795 [D loss: 0.265775, acc.: 60.94%] [G loss: 0.654912]\n",
      "epoch:1 step:1796 [D loss: 0.130312, acc.: 83.59%] [G loss: 0.764438]\n",
      "epoch:1 step:1797 [D loss: 0.095955, acc.: 89.06%] [G loss: 0.843208]\n",
      "epoch:1 step:1798 [D loss: 0.161230, acc.: 72.66%] [G loss: 0.655318]\n",
      "epoch:1 step:1799 [D loss: 0.122251, acc.: 85.94%] [G loss: 0.808182]\n",
      "epoch:1 step:1800 [D loss: 0.146117, acc.: 83.59%] [G loss: 0.779412]\n",
      "epoch:1 step:1801 [D loss: 0.156080, acc.: 78.91%] [G loss: 0.721677]\n",
      "epoch:1 step:1802 [D loss: 0.129797, acc.: 85.94%] [G loss: 0.708806]\n",
      "epoch:1 step:1803 [D loss: 0.151732, acc.: 83.59%] [G loss: 0.706969]\n",
      "epoch:1 step:1804 [D loss: 0.175586, acc.: 74.22%] [G loss: 0.657167]\n",
      "epoch:1 step:1805 [D loss: 0.131209, acc.: 85.94%] [G loss: 0.766454]\n",
      "epoch:1 step:1806 [D loss: 0.124613, acc.: 84.38%] [G loss: 0.756433]\n",
      "epoch:1 step:1807 [D loss: 0.145688, acc.: 80.47%] [G loss: 0.759207]\n",
      "epoch:1 step:1808 [D loss: 0.125960, acc.: 85.94%] [G loss: 0.791259]\n",
      "epoch:1 step:1809 [D loss: 0.128263, acc.: 84.38%] [G loss: 0.813637]\n",
      "epoch:1 step:1810 [D loss: 0.143938, acc.: 81.25%] [G loss: 0.709286]\n",
      "epoch:1 step:1811 [D loss: 0.125550, acc.: 85.16%] [G loss: 0.803529]\n",
      "epoch:1 step:1812 [D loss: 0.113636, acc.: 85.94%] [G loss: 0.792532]\n",
      "epoch:1 step:1813 [D loss: 0.197072, acc.: 68.75%] [G loss: 0.687593]\n",
      "epoch:1 step:1814 [D loss: 0.126762, acc.: 84.38%] [G loss: 0.807095]\n",
      "epoch:1 step:1815 [D loss: 0.186433, acc.: 73.44%] [G loss: 0.734481]\n",
      "epoch:1 step:1816 [D loss: 0.152099, acc.: 82.81%] [G loss: 0.723998]\n",
      "epoch:1 step:1817 [D loss: 0.172448, acc.: 75.78%] [G loss: 0.694241]\n",
      "epoch:1 step:1818 [D loss: 0.137977, acc.: 83.59%] [G loss: 0.804829]\n",
      "epoch:1 step:1819 [D loss: 0.147339, acc.: 75.78%] [G loss: 0.781351]\n",
      "epoch:1 step:1820 [D loss: 0.147230, acc.: 82.03%] [G loss: 0.763435]\n",
      "epoch:1 step:1821 [D loss: 0.125059, acc.: 83.59%] [G loss: 0.834023]\n",
      "epoch:1 step:1822 [D loss: 0.121962, acc.: 83.59%] [G loss: 0.805129]\n",
      "epoch:1 step:1823 [D loss: 0.118456, acc.: 84.38%] [G loss: 0.838134]\n",
      "epoch:1 step:1824 [D loss: 0.169936, acc.: 76.56%] [G loss: 0.803934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1825 [D loss: 0.112358, acc.: 86.72%] [G loss: 0.834478]\n",
      "epoch:1 step:1826 [D loss: 0.119236, acc.: 86.72%] [G loss: 0.750130]\n",
      "epoch:1 step:1827 [D loss: 0.146044, acc.: 82.03%] [G loss: 0.818961]\n",
      "epoch:1 step:1828 [D loss: 0.197636, acc.: 73.44%] [G loss: 0.647954]\n",
      "epoch:1 step:1829 [D loss: 0.252073, acc.: 53.91%] [G loss: 0.681782]\n",
      "epoch:1 step:1830 [D loss: 0.126342, acc.: 85.94%] [G loss: 0.831924]\n",
      "epoch:1 step:1831 [D loss: 0.143629, acc.: 79.69%] [G loss: 0.757288]\n",
      "epoch:1 step:1832 [D loss: 0.200031, acc.: 69.53%] [G loss: 0.682203]\n",
      "epoch:1 step:1833 [D loss: 0.151069, acc.: 78.91%] [G loss: 0.761499]\n",
      "epoch:1 step:1834 [D loss: 0.124602, acc.: 82.81%] [G loss: 0.802688]\n",
      "epoch:1 step:1835 [D loss: 0.153365, acc.: 80.47%] [G loss: 0.775221]\n",
      "epoch:1 step:1836 [D loss: 0.145266, acc.: 84.38%] [G loss: 0.721295]\n",
      "epoch:1 step:1837 [D loss: 0.143852, acc.: 82.81%] [G loss: 0.804003]\n",
      "epoch:1 step:1838 [D loss: 0.134794, acc.: 85.16%] [G loss: 0.716643]\n",
      "epoch:1 step:1839 [D loss: 0.190221, acc.: 71.88%] [G loss: 0.704730]\n",
      "epoch:1 step:1840 [D loss: 0.170576, acc.: 72.66%] [G loss: 0.802136]\n",
      "epoch:1 step:1841 [D loss: 0.143630, acc.: 78.12%] [G loss: 0.783179]\n",
      "epoch:1 step:1842 [D loss: 0.135357, acc.: 81.25%] [G loss: 0.795728]\n",
      "epoch:1 step:1843 [D loss: 0.134938, acc.: 85.16%] [G loss: 0.817768]\n",
      "epoch:1 step:1844 [D loss: 0.144320, acc.: 83.59%] [G loss: 0.789776]\n",
      "epoch:1 step:1845 [D loss: 0.132209, acc.: 85.94%] [G loss: 0.772053]\n",
      "epoch:1 step:1846 [D loss: 0.198100, acc.: 68.75%] [G loss: 0.704640]\n",
      "epoch:1 step:1847 [D loss: 0.132685, acc.: 83.59%] [G loss: 0.798190]\n",
      "epoch:1 step:1848 [D loss: 0.143048, acc.: 75.78%] [G loss: 0.798494]\n",
      "epoch:1 step:1849 [D loss: 0.114258, acc.: 85.94%] [G loss: 0.856879]\n",
      "epoch:1 step:1850 [D loss: 0.162665, acc.: 76.56%] [G loss: 0.757898]\n",
      "epoch:1 step:1851 [D loss: 0.114214, acc.: 82.81%] [G loss: 0.776817]\n",
      "epoch:1 step:1852 [D loss: 0.192185, acc.: 70.31%] [G loss: 0.632037]\n",
      "epoch:1 step:1853 [D loss: 0.155315, acc.: 81.25%] [G loss: 0.727200]\n",
      "epoch:1 step:1854 [D loss: 0.171940, acc.: 75.78%] [G loss: 0.735503]\n",
      "epoch:1 step:1855 [D loss: 0.157414, acc.: 75.78%] [G loss: 0.734803]\n",
      "epoch:1 step:1856 [D loss: 0.159688, acc.: 78.91%] [G loss: 0.707792]\n",
      "epoch:1 step:1857 [D loss: 0.165811, acc.: 78.91%] [G loss: 0.696944]\n",
      "epoch:1 step:1858 [D loss: 0.073357, acc.: 96.09%] [G loss: 0.895604]\n",
      "epoch:1 step:1859 [D loss: 0.134470, acc.: 81.25%] [G loss: 0.715489]\n",
      "epoch:1 step:1860 [D loss: 0.092463, acc.: 92.97%] [G loss: 0.869615]\n",
      "epoch:1 step:1861 [D loss: 0.090436, acc.: 92.19%] [G loss: 0.823914]\n",
      "epoch:1 step:1862 [D loss: 0.083719, acc.: 92.97%] [G loss: 0.853898]\n",
      "epoch:1 step:1863 [D loss: 0.126498, acc.: 85.16%] [G loss: 0.788940]\n",
      "epoch:1 step:1864 [D loss: 0.094356, acc.: 91.41%] [G loss: 0.883929]\n",
      "epoch:1 step:1865 [D loss: 0.257858, acc.: 66.41%] [G loss: 0.719765]\n",
      "epoch:1 step:1866 [D loss: 0.079589, acc.: 91.41%] [G loss: 1.059913]\n",
      "epoch:1 step:1867 [D loss: 0.204996, acc.: 72.66%] [G loss: 0.662145]\n",
      "epoch:1 step:1868 [D loss: 0.121776, acc.: 85.16%] [G loss: 0.717384]\n",
      "epoch:1 step:1869 [D loss: 0.145298, acc.: 77.34%] [G loss: 0.733709]\n",
      "epoch:1 step:1870 [D loss: 0.116046, acc.: 86.72%] [G loss: 0.741744]\n",
      "epoch:1 step:1871 [D loss: 0.128859, acc.: 83.59%] [G loss: 0.771500]\n",
      "epoch:1 step:1872 [D loss: 0.123210, acc.: 88.28%] [G loss: 0.759808]\n",
      "epoch:1 step:1873 [D loss: 0.056392, acc.: 96.88%] [G loss: 0.959763]\n",
      "epoch:1 step:1874 [D loss: 0.266051, acc.: 54.69%] [G loss: 0.633334]\n",
      "epoch:2 step:1875 [D loss: 0.171906, acc.: 73.44%] [G loss: 0.792670]\n",
      "epoch:2 step:1876 [D loss: 0.143454, acc.: 82.81%] [G loss: 0.705606]\n",
      "epoch:2 step:1877 [D loss: 0.215562, acc.: 69.53%] [G loss: 0.639206]\n",
      "epoch:2 step:1878 [D loss: 0.128798, acc.: 84.38%] [G loss: 0.801759]\n",
      "epoch:2 step:1879 [D loss: 0.152216, acc.: 78.12%] [G loss: 0.719873]\n",
      "epoch:2 step:1880 [D loss: 0.144447, acc.: 83.59%] [G loss: 0.791180]\n",
      "epoch:2 step:1881 [D loss: 0.166541, acc.: 79.69%] [G loss: 0.726147]\n",
      "epoch:2 step:1882 [D loss: 0.176356, acc.: 78.91%] [G loss: 0.666761]\n",
      "epoch:2 step:1883 [D loss: 0.153728, acc.: 78.91%] [G loss: 0.745589]\n",
      "epoch:2 step:1884 [D loss: 0.168895, acc.: 74.22%] [G loss: 0.725599]\n",
      "epoch:2 step:1885 [D loss: 0.141233, acc.: 82.81%] [G loss: 0.781557]\n",
      "epoch:2 step:1886 [D loss: 0.158150, acc.: 78.12%] [G loss: 0.734917]\n",
      "epoch:2 step:1887 [D loss: 0.147378, acc.: 78.91%] [G loss: 0.757637]\n",
      "epoch:2 step:1888 [D loss: 0.143969, acc.: 81.25%] [G loss: 0.754315]\n",
      "epoch:2 step:1889 [D loss: 0.175011, acc.: 77.34%] [G loss: 0.717881]\n",
      "epoch:2 step:1890 [D loss: 0.153972, acc.: 76.56%] [G loss: 0.805693]\n",
      "epoch:2 step:1891 [D loss: 0.199347, acc.: 69.53%] [G loss: 0.649427]\n",
      "epoch:2 step:1892 [D loss: 0.171111, acc.: 78.91%] [G loss: 0.661007]\n",
      "epoch:2 step:1893 [D loss: 0.161473, acc.: 77.34%] [G loss: 0.797875]\n",
      "epoch:2 step:1894 [D loss: 0.220207, acc.: 66.41%] [G loss: 0.630946]\n",
      "epoch:2 step:1895 [D loss: 0.130234, acc.: 85.16%] [G loss: 0.756092]\n",
      "epoch:2 step:1896 [D loss: 0.128973, acc.: 85.94%] [G loss: 0.830836]\n",
      "epoch:2 step:1897 [D loss: 0.171098, acc.: 74.22%] [G loss: 0.697913]\n",
      "epoch:2 step:1898 [D loss: 0.126619, acc.: 87.50%] [G loss: 0.759329]\n",
      "epoch:2 step:1899 [D loss: 0.157204, acc.: 78.12%] [G loss: 0.726198]\n",
      "epoch:2 step:1900 [D loss: 0.143650, acc.: 83.59%] [G loss: 0.728081]\n",
      "epoch:2 step:1901 [D loss: 0.145847, acc.: 80.47%] [G loss: 0.779515]\n",
      "epoch:2 step:1902 [D loss: 0.142703, acc.: 85.16%] [G loss: 0.664638]\n",
      "epoch:2 step:1903 [D loss: 0.111061, acc.: 89.84%] [G loss: 0.746839]\n",
      "epoch:2 step:1904 [D loss: 0.161913, acc.: 78.12%] [G loss: 0.700873]\n",
      "epoch:2 step:1905 [D loss: 0.150983, acc.: 80.47%] [G loss: 0.704037]\n",
      "epoch:2 step:1906 [D loss: 0.139466, acc.: 84.38%] [G loss: 0.747059]\n",
      "epoch:2 step:1907 [D loss: 0.129598, acc.: 83.59%] [G loss: 0.777397]\n",
      "epoch:2 step:1908 [D loss: 0.142875, acc.: 81.25%] [G loss: 0.785840]\n",
      "epoch:2 step:1909 [D loss: 0.105746, acc.: 91.41%] [G loss: 0.819105]\n",
      "epoch:2 step:1910 [D loss: 0.123100, acc.: 84.38%] [G loss: 0.802611]\n",
      "epoch:2 step:1911 [D loss: 0.135722, acc.: 82.81%] [G loss: 0.751194]\n",
      "epoch:2 step:1912 [D loss: 0.190388, acc.: 75.78%] [G loss: 0.722478]\n",
      "epoch:2 step:1913 [D loss: 0.116861, acc.: 87.50%] [G loss: 0.812354]\n",
      "epoch:2 step:1914 [D loss: 0.151345, acc.: 79.69%] [G loss: 0.821897]\n",
      "epoch:2 step:1915 [D loss: 0.143415, acc.: 81.25%] [G loss: 0.726733]\n",
      "epoch:2 step:1916 [D loss: 0.152283, acc.: 79.69%] [G loss: 0.666612]\n",
      "epoch:2 step:1917 [D loss: 0.157164, acc.: 78.12%] [G loss: 0.752188]\n",
      "epoch:2 step:1918 [D loss: 0.181027, acc.: 71.88%] [G loss: 0.726173]\n",
      "epoch:2 step:1919 [D loss: 0.139611, acc.: 82.03%] [G loss: 0.734623]\n",
      "epoch:2 step:1920 [D loss: 0.146367, acc.: 81.25%] [G loss: 0.769817]\n",
      "epoch:2 step:1921 [D loss: 0.166416, acc.: 74.22%] [G loss: 0.733480]\n",
      "epoch:2 step:1922 [D loss: 0.146800, acc.: 78.12%] [G loss: 0.756330]\n",
      "epoch:2 step:1923 [D loss: 0.195848, acc.: 71.88%] [G loss: 0.687726]\n",
      "epoch:2 step:1924 [D loss: 0.164135, acc.: 80.47%] [G loss: 0.778695]\n",
      "epoch:2 step:1925 [D loss: 0.151268, acc.: 78.91%] [G loss: 0.765966]\n",
      "epoch:2 step:1926 [D loss: 0.157874, acc.: 82.03%] [G loss: 0.746959]\n",
      "epoch:2 step:1927 [D loss: 0.133778, acc.: 87.50%] [G loss: 0.738721]\n",
      "epoch:2 step:1928 [D loss: 0.140060, acc.: 80.47%] [G loss: 0.764912]\n",
      "epoch:2 step:1929 [D loss: 0.173828, acc.: 71.88%] [G loss: 0.707250]\n",
      "epoch:2 step:1930 [D loss: 0.150507, acc.: 81.25%] [G loss: 0.748513]\n",
      "epoch:2 step:1931 [D loss: 0.146594, acc.: 82.81%] [G loss: 0.751964]\n",
      "epoch:2 step:1932 [D loss: 0.169481, acc.: 80.47%] [G loss: 0.686617]\n",
      "epoch:2 step:1933 [D loss: 0.125491, acc.: 88.28%] [G loss: 0.752173]\n",
      "epoch:2 step:1934 [D loss: 0.144929, acc.: 78.12%] [G loss: 0.733922]\n",
      "epoch:2 step:1935 [D loss: 0.194714, acc.: 69.53%] [G loss: 0.642322]\n",
      "epoch:2 step:1936 [D loss: 0.150089, acc.: 80.47%] [G loss: 0.709946]\n",
      "epoch:2 step:1937 [D loss: 0.142395, acc.: 83.59%] [G loss: 0.715678]\n",
      "epoch:2 step:1938 [D loss: 0.149384, acc.: 81.25%] [G loss: 0.748421]\n",
      "epoch:2 step:1939 [D loss: 0.155122, acc.: 77.34%] [G loss: 0.691688]\n",
      "epoch:2 step:1940 [D loss: 0.175716, acc.: 75.78%] [G loss: 0.693140]\n",
      "epoch:2 step:1941 [D loss: 0.168325, acc.: 77.34%] [G loss: 0.700145]\n",
      "epoch:2 step:1942 [D loss: 0.167645, acc.: 78.12%] [G loss: 0.719569]\n",
      "epoch:2 step:1943 [D loss: 0.184353, acc.: 70.31%] [G loss: 0.694553]\n",
      "epoch:2 step:1944 [D loss: 0.147860, acc.: 78.91%] [G loss: 0.733131]\n",
      "epoch:2 step:1945 [D loss: 0.160450, acc.: 81.25%] [G loss: 0.705718]\n",
      "epoch:2 step:1946 [D loss: 0.119821, acc.: 88.28%] [G loss: 0.780113]\n",
      "epoch:2 step:1947 [D loss: 0.128762, acc.: 86.72%] [G loss: 0.730983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1948 [D loss: 0.135419, acc.: 82.03%] [G loss: 0.750811]\n",
      "epoch:2 step:1949 [D loss: 0.152218, acc.: 78.91%] [G loss: 0.727878]\n",
      "epoch:2 step:1950 [D loss: 0.126568, acc.: 83.59%] [G loss: 0.773937]\n",
      "epoch:2 step:1951 [D loss: 0.122264, acc.: 85.16%] [G loss: 0.793024]\n",
      "epoch:2 step:1952 [D loss: 0.206598, acc.: 71.09%] [G loss: 0.626416]\n",
      "epoch:2 step:1953 [D loss: 0.168651, acc.: 75.78%] [G loss: 0.710804]\n",
      "epoch:2 step:1954 [D loss: 0.147398, acc.: 79.69%] [G loss: 0.713631]\n",
      "epoch:2 step:1955 [D loss: 0.199390, acc.: 67.97%] [G loss: 0.630662]\n",
      "epoch:2 step:1956 [D loss: 0.153807, acc.: 80.47%] [G loss: 0.689730]\n",
      "epoch:2 step:1957 [D loss: 0.174771, acc.: 77.34%] [G loss: 0.682385]\n",
      "epoch:2 step:1958 [D loss: 0.139780, acc.: 80.47%] [G loss: 0.733775]\n",
      "epoch:2 step:1959 [D loss: 0.124979, acc.: 85.94%] [G loss: 0.742308]\n",
      "epoch:2 step:1960 [D loss: 0.129126, acc.: 82.81%] [G loss: 0.729395]\n",
      "epoch:2 step:1961 [D loss: 0.125519, acc.: 86.72%] [G loss: 0.733048]\n",
      "epoch:2 step:1962 [D loss: 0.109139, acc.: 89.84%] [G loss: 0.787642]\n",
      "epoch:2 step:1963 [D loss: 0.169688, acc.: 75.78%] [G loss: 0.655609]\n",
      "epoch:2 step:1964 [D loss: 0.150031, acc.: 78.12%] [G loss: 0.709486]\n",
      "epoch:2 step:1965 [D loss: 0.165859, acc.: 77.34%] [G loss: 0.662525]\n",
      "epoch:2 step:1966 [D loss: 0.170883, acc.: 77.34%] [G loss: 0.672802]\n",
      "epoch:2 step:1967 [D loss: 0.151719, acc.: 80.47%] [G loss: 0.717367]\n",
      "epoch:2 step:1968 [D loss: 0.113979, acc.: 87.50%] [G loss: 0.779390]\n",
      "epoch:2 step:1969 [D loss: 0.148103, acc.: 82.03%] [G loss: 0.772037]\n",
      "epoch:2 step:1970 [D loss: 0.117453, acc.: 86.72%] [G loss: 0.785632]\n",
      "epoch:2 step:1971 [D loss: 0.151857, acc.: 81.25%] [G loss: 0.771965]\n",
      "epoch:2 step:1972 [D loss: 0.173960, acc.: 73.44%] [G loss: 0.627932]\n",
      "epoch:2 step:1973 [D loss: 0.148360, acc.: 77.34%] [G loss: 0.693568]\n",
      "epoch:2 step:1974 [D loss: 0.112714, acc.: 89.06%] [G loss: 0.848311]\n",
      "epoch:2 step:1975 [D loss: 0.161277, acc.: 83.59%] [G loss: 0.689093]\n",
      "epoch:2 step:1976 [D loss: 0.193566, acc.: 74.22%] [G loss: 0.610221]\n",
      "epoch:2 step:1977 [D loss: 0.113706, acc.: 84.38%] [G loss: 0.729701]\n",
      "epoch:2 step:1978 [D loss: 0.152690, acc.: 78.12%] [G loss: 0.690494]\n",
      "epoch:2 step:1979 [D loss: 0.178074, acc.: 72.66%] [G loss: 0.657441]\n",
      "epoch:2 step:1980 [D loss: 0.215867, acc.: 68.75%] [G loss: 0.603378]\n",
      "epoch:2 step:1981 [D loss: 0.171124, acc.: 75.78%] [G loss: 0.707824]\n",
      "epoch:2 step:1982 [D loss: 0.139960, acc.: 78.91%] [G loss: 0.793326]\n",
      "epoch:2 step:1983 [D loss: 0.179797, acc.: 77.34%] [G loss: 0.673320]\n",
      "epoch:2 step:1984 [D loss: 0.152492, acc.: 78.91%] [G loss: 0.658722]\n",
      "epoch:2 step:1985 [D loss: 0.153234, acc.: 82.03%] [G loss: 0.670957]\n",
      "epoch:2 step:1986 [D loss: 0.133106, acc.: 86.72%] [G loss: 0.671776]\n",
      "epoch:2 step:1987 [D loss: 0.179971, acc.: 72.66%] [G loss: 0.674050]\n",
      "epoch:2 step:1988 [D loss: 0.163645, acc.: 78.91%] [G loss: 0.716109]\n",
      "epoch:2 step:1989 [D loss: 0.148387, acc.: 79.69%] [G loss: 0.681045]\n",
      "epoch:2 step:1990 [D loss: 0.184884, acc.: 74.22%] [G loss: 0.675882]\n",
      "epoch:2 step:1991 [D loss: 0.157983, acc.: 76.56%] [G loss: 0.799345]\n",
      "epoch:2 step:1992 [D loss: 0.152537, acc.: 80.47%] [G loss: 0.748062]\n",
      "epoch:2 step:1993 [D loss: 0.128019, acc.: 85.94%] [G loss: 0.757481]\n",
      "epoch:2 step:1994 [D loss: 0.241841, acc.: 66.41%] [G loss: 0.627555]\n",
      "epoch:2 step:1995 [D loss: 0.196362, acc.: 72.66%] [G loss: 0.650197]\n",
      "epoch:2 step:1996 [D loss: 0.155909, acc.: 78.91%] [G loss: 0.664373]\n",
      "epoch:2 step:1997 [D loss: 0.180766, acc.: 71.09%] [G loss: 0.632696]\n",
      "epoch:2 step:1998 [D loss: 0.151328, acc.: 80.47%] [G loss: 0.668478]\n",
      "epoch:2 step:1999 [D loss: 0.133417, acc.: 84.38%] [G loss: 0.775063]\n",
      "epoch:2 step:2000 [D loss: 0.142650, acc.: 79.69%] [G loss: 0.704034]\n",
      "epoch:2 step:2001 [D loss: 0.169405, acc.: 75.78%] [G loss: 0.663069]\n",
      "epoch:2 step:2002 [D loss: 0.173270, acc.: 75.00%] [G loss: 0.605937]\n",
      "epoch:2 step:2003 [D loss: 0.156967, acc.: 78.91%] [G loss: 0.664334]\n",
      "epoch:2 step:2004 [D loss: 0.125469, acc.: 83.59%] [G loss: 0.765720]\n",
      "epoch:2 step:2005 [D loss: 0.134220, acc.: 82.81%] [G loss: 0.763091]\n",
      "epoch:2 step:2006 [D loss: 0.151323, acc.: 80.47%] [G loss: 0.683372]\n",
      "epoch:2 step:2007 [D loss: 0.174067, acc.: 76.56%] [G loss: 0.658050]\n",
      "epoch:2 step:2008 [D loss: 0.119412, acc.: 84.38%] [G loss: 0.791684]\n",
      "epoch:2 step:2009 [D loss: 0.142181, acc.: 83.59%] [G loss: 0.663539]\n",
      "epoch:2 step:2010 [D loss: 0.160633, acc.: 83.59%] [G loss: 0.654879]\n",
      "epoch:2 step:2011 [D loss: 0.179587, acc.: 79.69%] [G loss: 0.610740]\n",
      "epoch:2 step:2012 [D loss: 0.168323, acc.: 79.69%] [G loss: 0.653680]\n",
      "epoch:2 step:2013 [D loss: 0.186233, acc.: 73.44%] [G loss: 0.630671]\n",
      "epoch:2 step:2014 [D loss: 0.163339, acc.: 76.56%] [G loss: 0.649898]\n",
      "epoch:2 step:2015 [D loss: 0.145281, acc.: 76.56%] [G loss: 0.728709]\n",
      "epoch:2 step:2016 [D loss: 0.160138, acc.: 81.25%] [G loss: 0.677121]\n",
      "epoch:2 step:2017 [D loss: 0.168868, acc.: 74.22%] [G loss: 0.619127]\n",
      "epoch:2 step:2018 [D loss: 0.126518, acc.: 85.94%] [G loss: 0.736659]\n",
      "epoch:2 step:2019 [D loss: 0.152032, acc.: 78.91%] [G loss: 0.755884]\n",
      "epoch:2 step:2020 [D loss: 0.135951, acc.: 82.81%] [G loss: 0.760976]\n",
      "epoch:2 step:2021 [D loss: 0.163566, acc.: 78.12%] [G loss: 0.670041]\n",
      "epoch:2 step:2022 [D loss: 0.154079, acc.: 81.25%] [G loss: 0.651997]\n",
      "epoch:2 step:2023 [D loss: 0.124362, acc.: 85.16%] [G loss: 0.763165]\n",
      "epoch:2 step:2024 [D loss: 0.190942, acc.: 78.91%] [G loss: 0.670175]\n",
      "epoch:2 step:2025 [D loss: 0.153397, acc.: 78.91%] [G loss: 0.729443]\n",
      "epoch:2 step:2026 [D loss: 0.109982, acc.: 88.28%] [G loss: 0.778314]\n",
      "epoch:2 step:2027 [D loss: 0.177869, acc.: 77.34%] [G loss: 0.629940]\n",
      "epoch:2 step:2028 [D loss: 0.136848, acc.: 85.94%] [G loss: 0.702976]\n",
      "epoch:2 step:2029 [D loss: 0.107160, acc.: 92.19%] [G loss: 0.738464]\n",
      "epoch:2 step:2030 [D loss: 0.168127, acc.: 78.91%] [G loss: 0.677043]\n",
      "epoch:2 step:2031 [D loss: 0.135571, acc.: 82.81%] [G loss: 0.749893]\n",
      "epoch:2 step:2032 [D loss: 0.189927, acc.: 75.00%] [G loss: 0.680980]\n",
      "epoch:2 step:2033 [D loss: 0.144824, acc.: 79.69%] [G loss: 0.715240]\n",
      "epoch:2 step:2034 [D loss: 0.170162, acc.: 78.91%] [G loss: 0.668301]\n",
      "epoch:2 step:2035 [D loss: 0.111053, acc.: 85.94%] [G loss: 0.757892]\n",
      "epoch:2 step:2036 [D loss: 0.128029, acc.: 80.47%] [G loss: 0.809732]\n",
      "epoch:2 step:2037 [D loss: 0.150278, acc.: 80.47%] [G loss: 0.767876]\n",
      "epoch:2 step:2038 [D loss: 0.127524, acc.: 84.38%] [G loss: 0.796841]\n",
      "epoch:2 step:2039 [D loss: 0.143124, acc.: 82.81%] [G loss: 0.723937]\n",
      "epoch:2 step:2040 [D loss: 0.166341, acc.: 72.66%] [G loss: 0.653240]\n",
      "epoch:2 step:2041 [D loss: 0.181334, acc.: 71.88%] [G loss: 0.671638]\n",
      "epoch:2 step:2042 [D loss: 0.164032, acc.: 77.34%] [G loss: 0.691739]\n",
      "epoch:2 step:2043 [D loss: 0.163209, acc.: 80.47%] [G loss: 0.737869]\n",
      "epoch:2 step:2044 [D loss: 0.127308, acc.: 82.03%] [G loss: 0.776684]\n",
      "epoch:2 step:2045 [D loss: 0.163576, acc.: 76.56%] [G loss: 0.674716]\n",
      "epoch:2 step:2046 [D loss: 0.181452, acc.: 71.88%] [G loss: 0.661992]\n",
      "epoch:2 step:2047 [D loss: 0.123637, acc.: 85.16%] [G loss: 0.750640]\n",
      "epoch:2 step:2048 [D loss: 0.172244, acc.: 76.56%] [G loss: 0.651121]\n",
      "epoch:2 step:2049 [D loss: 0.144218, acc.: 82.03%] [G loss: 0.705599]\n",
      "epoch:2 step:2050 [D loss: 0.134760, acc.: 83.59%] [G loss: 0.753295]\n",
      "epoch:2 step:2051 [D loss: 0.166305, acc.: 78.12%] [G loss: 0.679220]\n",
      "epoch:2 step:2052 [D loss: 0.147640, acc.: 80.47%] [G loss: 0.732667]\n",
      "epoch:2 step:2053 [D loss: 0.152199, acc.: 78.12%] [G loss: 0.741415]\n",
      "epoch:2 step:2054 [D loss: 0.158796, acc.: 80.47%] [G loss: 0.685606]\n",
      "epoch:2 step:2055 [D loss: 0.146268, acc.: 80.47%] [G loss: 0.710824]\n",
      "epoch:2 step:2056 [D loss: 0.140733, acc.: 81.25%] [G loss: 0.751456]\n",
      "epoch:2 step:2057 [D loss: 0.171630, acc.: 77.34%] [G loss: 0.716573]\n",
      "epoch:2 step:2058 [D loss: 0.164839, acc.: 77.34%] [G loss: 0.716818]\n",
      "epoch:2 step:2059 [D loss: 0.161533, acc.: 84.38%] [G loss: 0.672920]\n",
      "epoch:2 step:2060 [D loss: 0.155060, acc.: 82.03%] [G loss: 0.728906]\n",
      "epoch:2 step:2061 [D loss: 0.196866, acc.: 76.56%] [G loss: 0.671631]\n",
      "epoch:2 step:2062 [D loss: 0.150879, acc.: 78.91%] [G loss: 0.687714]\n",
      "epoch:2 step:2063 [D loss: 0.187651, acc.: 72.66%] [G loss: 0.628960]\n",
      "epoch:2 step:2064 [D loss: 0.106051, acc.: 88.28%] [G loss: 0.732694]\n",
      "epoch:2 step:2065 [D loss: 0.134053, acc.: 85.16%] [G loss: 0.715371]\n",
      "epoch:2 step:2066 [D loss: 0.155215, acc.: 81.25%] [G loss: 0.683347]\n",
      "epoch:2 step:2067 [D loss: 0.172164, acc.: 76.56%] [G loss: 0.634631]\n",
      "epoch:2 step:2068 [D loss: 0.108688, acc.: 87.50%] [G loss: 0.769483]\n",
      "epoch:2 step:2069 [D loss: 0.166953, acc.: 73.44%] [G loss: 0.647534]\n",
      "epoch:2 step:2070 [D loss: 0.138060, acc.: 83.59%] [G loss: 0.716509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2071 [D loss: 0.156989, acc.: 78.12%] [G loss: 0.730209]\n",
      "epoch:2 step:2072 [D loss: 0.120362, acc.: 86.72%] [G loss: 0.708822]\n",
      "epoch:2 step:2073 [D loss: 0.147763, acc.: 80.47%] [G loss: 0.750504]\n",
      "epoch:2 step:2074 [D loss: 0.199842, acc.: 71.88%] [G loss: 0.676709]\n",
      "epoch:2 step:2075 [D loss: 0.144274, acc.: 80.47%] [G loss: 0.734088]\n",
      "epoch:2 step:2076 [D loss: 0.159575, acc.: 81.25%] [G loss: 0.671157]\n",
      "epoch:2 step:2077 [D loss: 0.173055, acc.: 77.34%] [G loss: 0.656171]\n",
      "epoch:2 step:2078 [D loss: 0.106191, acc.: 91.41%] [G loss: 0.729416]\n",
      "epoch:2 step:2079 [D loss: 0.140525, acc.: 78.12%] [G loss: 0.778812]\n",
      "epoch:2 step:2080 [D loss: 0.139827, acc.: 82.03%] [G loss: 0.717429]\n",
      "epoch:2 step:2081 [D loss: 0.126299, acc.: 85.16%] [G loss: 0.790695]\n",
      "epoch:2 step:2082 [D loss: 0.107720, acc.: 87.50%] [G loss: 0.780659]\n",
      "epoch:2 step:2083 [D loss: 0.154854, acc.: 83.59%] [G loss: 0.674930]\n",
      "epoch:2 step:2084 [D loss: 0.180516, acc.: 72.66%] [G loss: 0.691970]\n",
      "epoch:2 step:2085 [D loss: 0.161631, acc.: 77.34%] [G loss: 0.689086]\n",
      "epoch:2 step:2086 [D loss: 0.125789, acc.: 86.72%] [G loss: 0.721156]\n",
      "epoch:2 step:2087 [D loss: 0.117739, acc.: 85.16%] [G loss: 0.731266]\n",
      "epoch:2 step:2088 [D loss: 0.188697, acc.: 71.88%] [G loss: 0.599296]\n",
      "epoch:2 step:2089 [D loss: 0.165551, acc.: 75.78%] [G loss: 0.670198]\n",
      "epoch:2 step:2090 [D loss: 0.169471, acc.: 74.22%] [G loss: 0.719296]\n",
      "epoch:2 step:2091 [D loss: 0.138150, acc.: 85.94%] [G loss: 0.810770]\n",
      "epoch:2 step:2092 [D loss: 0.122898, acc.: 86.72%] [G loss: 0.741188]\n",
      "epoch:2 step:2093 [D loss: 0.162893, acc.: 80.47%] [G loss: 0.670852]\n",
      "epoch:2 step:2094 [D loss: 0.157505, acc.: 80.47%] [G loss: 0.732638]\n",
      "epoch:2 step:2095 [D loss: 0.121097, acc.: 85.94%] [G loss: 0.880790]\n",
      "epoch:2 step:2096 [D loss: 0.154746, acc.: 81.25%] [G loss: 0.603054]\n",
      "epoch:2 step:2097 [D loss: 0.153538, acc.: 80.47%] [G loss: 0.758801]\n",
      "epoch:2 step:2098 [D loss: 0.156390, acc.: 77.34%] [G loss: 0.723449]\n",
      "epoch:2 step:2099 [D loss: 0.167159, acc.: 76.56%] [G loss: 0.636967]\n",
      "epoch:2 step:2100 [D loss: 0.173638, acc.: 75.78%] [G loss: 0.634373]\n",
      "epoch:2 step:2101 [D loss: 0.171119, acc.: 74.22%] [G loss: 0.665245]\n",
      "epoch:2 step:2102 [D loss: 0.160444, acc.: 78.12%] [G loss: 0.650671]\n",
      "epoch:2 step:2103 [D loss: 0.171678, acc.: 75.78%] [G loss: 0.683762]\n",
      "epoch:2 step:2104 [D loss: 0.134777, acc.: 84.38%] [G loss: 0.736903]\n",
      "epoch:2 step:2105 [D loss: 0.173633, acc.: 73.44%] [G loss: 0.707117]\n",
      "epoch:2 step:2106 [D loss: 0.122575, acc.: 89.06%] [G loss: 0.770429]\n",
      "epoch:2 step:2107 [D loss: 0.184015, acc.: 75.78%] [G loss: 0.679931]\n",
      "epoch:2 step:2108 [D loss: 0.152805, acc.: 82.03%] [G loss: 0.653088]\n",
      "epoch:2 step:2109 [D loss: 0.173757, acc.: 74.22%] [G loss: 0.671737]\n",
      "epoch:2 step:2110 [D loss: 0.130357, acc.: 84.38%] [G loss: 0.718710]\n",
      "epoch:2 step:2111 [D loss: 0.183684, acc.: 74.22%] [G loss: 0.668755]\n",
      "epoch:2 step:2112 [D loss: 0.166335, acc.: 78.91%] [G loss: 0.694813]\n",
      "epoch:2 step:2113 [D loss: 0.196608, acc.: 66.41%] [G loss: 0.707447]\n",
      "epoch:2 step:2114 [D loss: 0.132926, acc.: 83.59%] [G loss: 0.727753]\n",
      "epoch:2 step:2115 [D loss: 0.186007, acc.: 69.53%] [G loss: 0.665085]\n",
      "epoch:2 step:2116 [D loss: 0.178074, acc.: 71.09%] [G loss: 0.713939]\n",
      "epoch:2 step:2117 [D loss: 0.149518, acc.: 80.47%] [G loss: 0.735368]\n",
      "epoch:2 step:2118 [D loss: 0.150243, acc.: 82.03%] [G loss: 0.681293]\n",
      "epoch:2 step:2119 [D loss: 0.143165, acc.: 85.16%] [G loss: 0.737787]\n",
      "epoch:2 step:2120 [D loss: 0.176098, acc.: 75.78%] [G loss: 0.716972]\n",
      "epoch:2 step:2121 [D loss: 0.168068, acc.: 73.44%] [G loss: 0.620729]\n",
      "epoch:2 step:2122 [D loss: 0.153456, acc.: 75.78%] [G loss: 0.696620]\n",
      "epoch:2 step:2123 [D loss: 0.153002, acc.: 75.78%] [G loss: 0.719757]\n",
      "epoch:2 step:2124 [D loss: 0.197220, acc.: 68.75%] [G loss: 0.670645]\n",
      "epoch:2 step:2125 [D loss: 0.178298, acc.: 74.22%] [G loss: 0.682295]\n",
      "epoch:2 step:2126 [D loss: 0.150053, acc.: 82.03%] [G loss: 0.782637]\n",
      "epoch:2 step:2127 [D loss: 0.155920, acc.: 78.12%] [G loss: 0.643407]\n",
      "epoch:2 step:2128 [D loss: 0.134325, acc.: 84.38%] [G loss: 0.692017]\n",
      "epoch:2 step:2129 [D loss: 0.136952, acc.: 82.81%] [G loss: 0.742080]\n",
      "epoch:2 step:2130 [D loss: 0.149412, acc.: 78.12%] [G loss: 0.699997]\n",
      "epoch:2 step:2131 [D loss: 0.162894, acc.: 75.00%] [G loss: 0.730220]\n",
      "epoch:2 step:2132 [D loss: 0.145947, acc.: 83.59%] [G loss: 0.692519]\n",
      "epoch:2 step:2133 [D loss: 0.121374, acc.: 85.94%] [G loss: 0.751022]\n",
      "epoch:2 step:2134 [D loss: 0.133671, acc.: 89.06%] [G loss: 0.730302]\n",
      "epoch:2 step:2135 [D loss: 0.165295, acc.: 77.34%] [G loss: 0.708503]\n",
      "epoch:2 step:2136 [D loss: 0.152860, acc.: 79.69%] [G loss: 0.724846]\n",
      "epoch:2 step:2137 [D loss: 0.269940, acc.: 57.03%] [G loss: 0.587855]\n",
      "epoch:2 step:2138 [D loss: 0.150960, acc.: 78.91%] [G loss: 0.767483]\n",
      "epoch:2 step:2139 [D loss: 0.169437, acc.: 78.12%] [G loss: 0.708508]\n",
      "epoch:2 step:2140 [D loss: 0.163741, acc.: 75.78%] [G loss: 0.679285]\n",
      "epoch:2 step:2141 [D loss: 0.155287, acc.: 80.47%] [G loss: 0.697922]\n",
      "epoch:2 step:2142 [D loss: 0.142079, acc.: 85.16%] [G loss: 0.739287]\n",
      "epoch:2 step:2143 [D loss: 0.139780, acc.: 85.16%] [G loss: 0.702057]\n",
      "epoch:2 step:2144 [D loss: 0.142162, acc.: 78.91%] [G loss: 0.755976]\n",
      "epoch:2 step:2145 [D loss: 0.109241, acc.: 88.28%] [G loss: 0.754531]\n",
      "epoch:2 step:2146 [D loss: 0.191335, acc.: 72.66%] [G loss: 0.678529]\n",
      "epoch:2 step:2147 [D loss: 0.132290, acc.: 81.25%] [G loss: 0.795727]\n",
      "epoch:2 step:2148 [D loss: 0.218931, acc.: 67.19%] [G loss: 0.670109]\n",
      "epoch:2 step:2149 [D loss: 0.190549, acc.: 76.56%] [G loss: 0.626086]\n",
      "epoch:2 step:2150 [D loss: 0.150826, acc.: 79.69%] [G loss: 0.701159]\n",
      "epoch:2 step:2151 [D loss: 0.162333, acc.: 78.12%] [G loss: 0.750664]\n",
      "epoch:2 step:2152 [D loss: 0.137175, acc.: 82.03%] [G loss: 0.799995]\n",
      "epoch:2 step:2153 [D loss: 0.163681, acc.: 76.56%] [G loss: 0.737484]\n",
      "epoch:2 step:2154 [D loss: 0.150623, acc.: 82.03%] [G loss: 0.755036]\n",
      "epoch:2 step:2155 [D loss: 0.167490, acc.: 78.91%] [G loss: 0.708932]\n",
      "epoch:2 step:2156 [D loss: 0.154200, acc.: 76.56%] [G loss: 0.702690]\n",
      "epoch:2 step:2157 [D loss: 0.127223, acc.: 84.38%] [G loss: 0.750017]\n",
      "epoch:2 step:2158 [D loss: 0.118181, acc.: 84.38%] [G loss: 0.726503]\n",
      "epoch:2 step:2159 [D loss: 0.133698, acc.: 82.03%] [G loss: 0.721693]\n",
      "epoch:2 step:2160 [D loss: 0.124667, acc.: 82.81%] [G loss: 0.714572]\n",
      "epoch:2 step:2161 [D loss: 0.182123, acc.: 74.22%] [G loss: 0.681498]\n",
      "epoch:2 step:2162 [D loss: 0.149685, acc.: 75.78%] [G loss: 0.716039]\n",
      "epoch:2 step:2163 [D loss: 0.122415, acc.: 85.94%] [G loss: 0.754344]\n",
      "epoch:2 step:2164 [D loss: 0.158373, acc.: 75.00%] [G loss: 0.756282]\n",
      "epoch:2 step:2165 [D loss: 0.184957, acc.: 77.34%] [G loss: 0.683802]\n",
      "epoch:2 step:2166 [D loss: 0.160407, acc.: 80.47%] [G loss: 0.704603]\n",
      "epoch:2 step:2167 [D loss: 0.138368, acc.: 82.03%] [G loss: 0.695247]\n",
      "epoch:2 step:2168 [D loss: 0.153197, acc.: 76.56%] [G loss: 0.718845]\n",
      "epoch:2 step:2169 [D loss: 0.130128, acc.: 88.28%] [G loss: 0.730173]\n",
      "epoch:2 step:2170 [D loss: 0.138188, acc.: 82.81%] [G loss: 0.742132]\n",
      "epoch:2 step:2171 [D loss: 0.158312, acc.: 85.16%] [G loss: 0.667014]\n",
      "epoch:2 step:2172 [D loss: 0.160502, acc.: 81.25%] [G loss: 0.711112]\n",
      "epoch:2 step:2173 [D loss: 0.160162, acc.: 78.91%] [G loss: 0.708045]\n",
      "epoch:2 step:2174 [D loss: 0.149709, acc.: 84.38%] [G loss: 0.710804]\n",
      "epoch:2 step:2175 [D loss: 0.168358, acc.: 77.34%] [G loss: 0.660368]\n",
      "epoch:2 step:2176 [D loss: 0.143582, acc.: 78.91%] [G loss: 0.742292]\n",
      "epoch:2 step:2177 [D loss: 0.163705, acc.: 78.91%] [G loss: 0.774889]\n",
      "epoch:2 step:2178 [D loss: 0.127984, acc.: 81.25%] [G loss: 0.796192]\n",
      "epoch:2 step:2179 [D loss: 0.161481, acc.: 78.91%] [G loss: 0.715036]\n",
      "epoch:2 step:2180 [D loss: 0.146777, acc.: 78.12%] [G loss: 0.719398]\n",
      "epoch:2 step:2181 [D loss: 0.130531, acc.: 79.69%] [G loss: 0.708468]\n",
      "epoch:2 step:2182 [D loss: 0.159399, acc.: 80.47%] [G loss: 0.745430]\n",
      "epoch:2 step:2183 [D loss: 0.139810, acc.: 82.03%] [G loss: 0.733599]\n",
      "epoch:2 step:2184 [D loss: 0.134241, acc.: 83.59%] [G loss: 0.735059]\n",
      "epoch:2 step:2185 [D loss: 0.139537, acc.: 80.47%] [G loss: 0.765999]\n",
      "epoch:2 step:2186 [D loss: 0.126244, acc.: 85.16%] [G loss: 0.790441]\n",
      "epoch:2 step:2187 [D loss: 0.126707, acc.: 86.72%] [G loss: 0.737031]\n",
      "epoch:2 step:2188 [D loss: 0.111220, acc.: 87.50%] [G loss: 0.910317]\n",
      "epoch:2 step:2189 [D loss: 0.156183, acc.: 80.47%] [G loss: 0.734564]\n",
      "epoch:2 step:2190 [D loss: 0.217133, acc.: 61.72%] [G loss: 0.624860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2191 [D loss: 0.129950, acc.: 85.16%] [G loss: 0.703935]\n",
      "epoch:2 step:2192 [D loss: 0.144429, acc.: 81.25%] [G loss: 0.733356]\n",
      "epoch:2 step:2193 [D loss: 0.156046, acc.: 76.56%] [G loss: 0.720387]\n",
      "epoch:2 step:2194 [D loss: 0.156331, acc.: 82.03%] [G loss: 0.729114]\n",
      "epoch:2 step:2195 [D loss: 0.135935, acc.: 82.81%] [G loss: 0.713886]\n",
      "epoch:2 step:2196 [D loss: 0.175145, acc.: 75.78%] [G loss: 0.683148]\n",
      "epoch:2 step:2197 [D loss: 0.202118, acc.: 71.88%] [G loss: 0.596029]\n",
      "epoch:2 step:2198 [D loss: 0.142505, acc.: 78.91%] [G loss: 0.656749]\n",
      "epoch:2 step:2199 [D loss: 0.171178, acc.: 73.44%] [G loss: 0.741677]\n",
      "epoch:2 step:2200 [D loss: 0.161749, acc.: 75.78%] [G loss: 0.743745]\n",
      "epoch:2 step:2201 [D loss: 0.184263, acc.: 75.00%] [G loss: 0.657454]\n",
      "epoch:2 step:2202 [D loss: 0.164731, acc.: 76.56%] [G loss: 0.651676]\n",
      "epoch:2 step:2203 [D loss: 0.137629, acc.: 83.59%] [G loss: 0.718379]\n",
      "epoch:2 step:2204 [D loss: 0.167357, acc.: 78.91%] [G loss: 0.655215]\n",
      "epoch:2 step:2205 [D loss: 0.122540, acc.: 87.50%] [G loss: 0.711379]\n",
      "epoch:2 step:2206 [D loss: 0.121269, acc.: 85.16%] [G loss: 0.731433]\n",
      "epoch:2 step:2207 [D loss: 0.113026, acc.: 89.06%] [G loss: 0.801469]\n",
      "epoch:2 step:2208 [D loss: 0.163877, acc.: 73.44%] [G loss: 0.693648]\n",
      "epoch:2 step:2209 [D loss: 0.123907, acc.: 86.72%] [G loss: 0.809649]\n",
      "epoch:2 step:2210 [D loss: 0.135971, acc.: 81.25%] [G loss: 0.742707]\n",
      "epoch:2 step:2211 [D loss: 0.140260, acc.: 84.38%] [G loss: 0.654729]\n",
      "epoch:2 step:2212 [D loss: 0.162540, acc.: 78.91%] [G loss: 0.657156]\n",
      "epoch:2 step:2213 [D loss: 0.123669, acc.: 85.16%] [G loss: 0.759545]\n",
      "epoch:2 step:2214 [D loss: 0.153190, acc.: 78.12%] [G loss: 0.690235]\n",
      "epoch:2 step:2215 [D loss: 0.153956, acc.: 75.78%] [G loss: 0.671670]\n",
      "epoch:2 step:2216 [D loss: 0.156747, acc.: 79.69%] [G loss: 0.749889]\n",
      "epoch:2 step:2217 [D loss: 0.113255, acc.: 85.94%] [G loss: 0.801443]\n",
      "epoch:2 step:2218 [D loss: 0.141328, acc.: 81.25%] [G loss: 0.749088]\n",
      "epoch:2 step:2219 [D loss: 0.145784, acc.: 79.69%] [G loss: 0.739467]\n",
      "epoch:2 step:2220 [D loss: 0.108892, acc.: 85.94%] [G loss: 0.740724]\n",
      "epoch:2 step:2221 [D loss: 0.123354, acc.: 83.59%] [G loss: 0.765443]\n",
      "epoch:2 step:2222 [D loss: 0.178572, acc.: 76.56%] [G loss: 0.709607]\n",
      "epoch:2 step:2223 [D loss: 0.218189, acc.: 64.06%] [G loss: 0.614744]\n",
      "epoch:2 step:2224 [D loss: 0.114887, acc.: 89.84%] [G loss: 0.757999]\n",
      "epoch:2 step:2225 [D loss: 0.126401, acc.: 83.59%] [G loss: 0.761902]\n",
      "epoch:2 step:2226 [D loss: 0.187433, acc.: 71.88%] [G loss: 0.642362]\n",
      "epoch:2 step:2227 [D loss: 0.117175, acc.: 89.06%] [G loss: 0.745478]\n",
      "epoch:2 step:2228 [D loss: 0.132020, acc.: 82.81%] [G loss: 0.699799]\n",
      "epoch:2 step:2229 [D loss: 0.175055, acc.: 78.12%] [G loss: 0.708372]\n",
      "epoch:2 step:2230 [D loss: 0.147841, acc.: 82.81%] [G loss: 0.705090]\n",
      "epoch:2 step:2231 [D loss: 0.122534, acc.: 82.81%] [G loss: 0.773844]\n",
      "epoch:2 step:2232 [D loss: 0.118912, acc.: 88.28%] [G loss: 0.794087]\n",
      "epoch:2 step:2233 [D loss: 0.138428, acc.: 83.59%] [G loss: 0.793484]\n",
      "epoch:2 step:2234 [D loss: 0.141911, acc.: 82.03%] [G loss: 0.710427]\n",
      "epoch:2 step:2235 [D loss: 0.158594, acc.: 79.69%] [G loss: 0.686017]\n",
      "epoch:2 step:2236 [D loss: 0.151032, acc.: 78.12%] [G loss: 0.667769]\n",
      "epoch:2 step:2237 [D loss: 0.162949, acc.: 78.12%] [G loss: 0.737693]\n",
      "epoch:2 step:2238 [D loss: 0.152972, acc.: 77.34%] [G loss: 0.783059]\n",
      "epoch:2 step:2239 [D loss: 0.146115, acc.: 81.25%] [G loss: 0.663325]\n",
      "epoch:2 step:2240 [D loss: 0.155363, acc.: 78.91%] [G loss: 0.716065]\n",
      "epoch:2 step:2241 [D loss: 0.168640, acc.: 75.00%] [G loss: 0.708763]\n",
      "epoch:2 step:2242 [D loss: 0.128389, acc.: 84.38%] [G loss: 0.750603]\n",
      "epoch:2 step:2243 [D loss: 0.182649, acc.: 74.22%] [G loss: 0.605777]\n",
      "epoch:2 step:2244 [D loss: 0.158715, acc.: 75.78%] [G loss: 0.666718]\n",
      "epoch:2 step:2245 [D loss: 0.122760, acc.: 89.84%] [G loss: 0.734107]\n",
      "epoch:2 step:2246 [D loss: 0.121822, acc.: 84.38%] [G loss: 0.776108]\n",
      "epoch:2 step:2247 [D loss: 0.180854, acc.: 75.00%] [G loss: 0.659264]\n",
      "epoch:2 step:2248 [D loss: 0.121044, acc.: 89.06%] [G loss: 0.760154]\n",
      "epoch:2 step:2249 [D loss: 0.160393, acc.: 83.59%] [G loss: 0.723121]\n",
      "epoch:2 step:2250 [D loss: 0.216614, acc.: 72.66%] [G loss: 0.640132]\n",
      "epoch:2 step:2251 [D loss: 0.141551, acc.: 79.69%] [G loss: 0.701882]\n",
      "epoch:2 step:2252 [D loss: 0.149592, acc.: 75.00%] [G loss: 0.730216]\n",
      "epoch:2 step:2253 [D loss: 0.146681, acc.: 82.81%] [G loss: 0.678869]\n",
      "epoch:2 step:2254 [D loss: 0.172179, acc.: 75.78%] [G loss: 0.662730]\n",
      "epoch:2 step:2255 [D loss: 0.103497, acc.: 91.41%] [G loss: 0.799690]\n",
      "epoch:2 step:2256 [D loss: 0.132221, acc.: 87.50%] [G loss: 0.719802]\n",
      "epoch:2 step:2257 [D loss: 0.185095, acc.: 73.44%] [G loss: 0.687061]\n",
      "epoch:2 step:2258 [D loss: 0.145894, acc.: 81.25%] [G loss: 0.747467]\n",
      "epoch:2 step:2259 [D loss: 0.154894, acc.: 79.69%] [G loss: 0.724972]\n",
      "epoch:2 step:2260 [D loss: 0.155070, acc.: 75.78%] [G loss: 0.699910]\n",
      "epoch:2 step:2261 [D loss: 0.177997, acc.: 73.44%] [G loss: 0.671077]\n",
      "epoch:2 step:2262 [D loss: 0.132616, acc.: 85.94%] [G loss: 0.721484]\n",
      "epoch:2 step:2263 [D loss: 0.151487, acc.: 76.56%] [G loss: 0.672690]\n",
      "epoch:2 step:2264 [D loss: 0.178134, acc.: 74.22%] [G loss: 0.676284]\n",
      "epoch:2 step:2265 [D loss: 0.108607, acc.: 85.94%] [G loss: 0.781456]\n",
      "epoch:2 step:2266 [D loss: 0.128313, acc.: 84.38%] [G loss: 0.696250]\n",
      "epoch:2 step:2267 [D loss: 0.148387, acc.: 78.12%] [G loss: 0.665124]\n",
      "epoch:2 step:2268 [D loss: 0.113047, acc.: 89.84%] [G loss: 0.755977]\n",
      "epoch:2 step:2269 [D loss: 0.124249, acc.: 83.59%] [G loss: 0.756327]\n",
      "epoch:2 step:2270 [D loss: 0.166785, acc.: 78.91%] [G loss: 0.670107]\n",
      "epoch:2 step:2271 [D loss: 0.110008, acc.: 85.16%] [G loss: 0.804738]\n",
      "epoch:2 step:2272 [D loss: 0.112260, acc.: 84.38%] [G loss: 0.814910]\n",
      "epoch:2 step:2273 [D loss: 0.122181, acc.: 85.94%] [G loss: 0.688887]\n",
      "epoch:2 step:2274 [D loss: 0.156158, acc.: 78.91%] [G loss: 0.633904]\n",
      "epoch:2 step:2275 [D loss: 0.138975, acc.: 78.91%] [G loss: 0.686146]\n",
      "epoch:2 step:2276 [D loss: 0.098003, acc.: 86.72%] [G loss: 0.783964]\n",
      "epoch:2 step:2277 [D loss: 0.137709, acc.: 79.69%] [G loss: 0.749316]\n",
      "epoch:2 step:2278 [D loss: 0.187978, acc.: 73.44%] [G loss: 0.640594]\n",
      "epoch:2 step:2279 [D loss: 0.174328, acc.: 75.78%] [G loss: 0.715454]\n",
      "epoch:2 step:2280 [D loss: 0.156369, acc.: 80.47%] [G loss: 0.747540]\n",
      "epoch:2 step:2281 [D loss: 0.168583, acc.: 74.22%] [G loss: 0.679820]\n",
      "epoch:2 step:2282 [D loss: 0.146159, acc.: 84.38%] [G loss: 0.703076]\n",
      "epoch:2 step:2283 [D loss: 0.116552, acc.: 88.28%] [G loss: 0.742050]\n",
      "epoch:2 step:2284 [D loss: 0.126827, acc.: 86.72%] [G loss: 0.721143]\n",
      "epoch:2 step:2285 [D loss: 0.148637, acc.: 83.59%] [G loss: 0.711405]\n",
      "epoch:2 step:2286 [D loss: 0.134763, acc.: 83.59%] [G loss: 0.684110]\n",
      "epoch:2 step:2287 [D loss: 0.145272, acc.: 81.25%] [G loss: 0.710403]\n",
      "epoch:2 step:2288 [D loss: 0.148765, acc.: 78.12%] [G loss: 0.695738]\n",
      "epoch:2 step:2289 [D loss: 0.178579, acc.: 71.88%] [G loss: 0.690943]\n",
      "epoch:2 step:2290 [D loss: 0.165697, acc.: 78.12%] [G loss: 0.716663]\n",
      "epoch:2 step:2291 [D loss: 0.179591, acc.: 74.22%] [G loss: 0.678545]\n",
      "epoch:2 step:2292 [D loss: 0.137634, acc.: 83.59%] [G loss: 0.707413]\n",
      "epoch:2 step:2293 [D loss: 0.148566, acc.: 82.81%] [G loss: 0.732165]\n",
      "epoch:2 step:2294 [D loss: 0.167205, acc.: 74.22%] [G loss: 0.715460]\n",
      "epoch:2 step:2295 [D loss: 0.171440, acc.: 75.00%] [G loss: 0.645060]\n",
      "epoch:2 step:2296 [D loss: 0.116227, acc.: 85.16%] [G loss: 0.720519]\n",
      "epoch:2 step:2297 [D loss: 0.131747, acc.: 85.94%] [G loss: 0.750640]\n",
      "epoch:2 step:2298 [D loss: 0.160838, acc.: 77.34%] [G loss: 0.685072]\n",
      "epoch:2 step:2299 [D loss: 0.159338, acc.: 78.12%] [G loss: 0.730872]\n",
      "epoch:2 step:2300 [D loss: 0.125642, acc.: 83.59%] [G loss: 0.792151]\n",
      "epoch:2 step:2301 [D loss: 0.125746, acc.: 87.50%] [G loss: 0.757481]\n",
      "epoch:2 step:2302 [D loss: 0.128703, acc.: 84.38%] [G loss: 0.734228]\n",
      "epoch:2 step:2303 [D loss: 0.138899, acc.: 82.03%] [G loss: 0.791540]\n",
      "epoch:2 step:2304 [D loss: 0.145614, acc.: 79.69%] [G loss: 0.704223]\n",
      "epoch:2 step:2305 [D loss: 0.112964, acc.: 89.06%] [G loss: 0.725124]\n",
      "epoch:2 step:2306 [D loss: 0.166368, acc.: 76.56%] [G loss: 0.735873]\n",
      "epoch:2 step:2307 [D loss: 0.150607, acc.: 81.25%] [G loss: 0.703152]\n",
      "epoch:2 step:2308 [D loss: 0.162375, acc.: 76.56%] [G loss: 0.690953]\n",
      "epoch:2 step:2309 [D loss: 0.134083, acc.: 82.81%] [G loss: 0.711341]\n",
      "epoch:2 step:2310 [D loss: 0.140297, acc.: 86.72%] [G loss: 0.709057]\n",
      "epoch:2 step:2311 [D loss: 0.216888, acc.: 66.41%] [G loss: 0.600654]\n",
      "epoch:2 step:2312 [D loss: 0.136194, acc.: 82.03%] [G loss: 0.695816]\n",
      "epoch:2 step:2313 [D loss: 0.149041, acc.: 81.25%] [G loss: 0.688460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2314 [D loss: 0.160269, acc.: 78.91%] [G loss: 0.671202]\n",
      "epoch:2 step:2315 [D loss: 0.159017, acc.: 76.56%] [G loss: 0.678655]\n",
      "epoch:2 step:2316 [D loss: 0.123662, acc.: 87.50%] [G loss: 0.710614]\n",
      "epoch:2 step:2317 [D loss: 0.146431, acc.: 80.47%] [G loss: 0.685551]\n",
      "epoch:2 step:2318 [D loss: 0.135883, acc.: 83.59%] [G loss: 0.727543]\n",
      "epoch:2 step:2319 [D loss: 0.146718, acc.: 80.47%] [G loss: 0.672599]\n",
      "epoch:2 step:2320 [D loss: 0.154232, acc.: 77.34%] [G loss: 0.723590]\n",
      "epoch:2 step:2321 [D loss: 0.106718, acc.: 86.72%] [G loss: 0.721764]\n",
      "epoch:2 step:2322 [D loss: 0.185826, acc.: 74.22%] [G loss: 0.672088]\n",
      "epoch:2 step:2323 [D loss: 0.145327, acc.: 82.81%] [G loss: 0.717342]\n",
      "epoch:2 step:2324 [D loss: 0.104597, acc.: 89.84%] [G loss: 0.795725]\n",
      "epoch:2 step:2325 [D loss: 0.115783, acc.: 85.16%] [G loss: 0.861320]\n",
      "epoch:2 step:2326 [D loss: 0.172210, acc.: 85.16%] [G loss: 0.725144]\n",
      "epoch:2 step:2327 [D loss: 0.125200, acc.: 86.72%] [G loss: 0.739951]\n",
      "epoch:2 step:2328 [D loss: 0.214406, acc.: 73.44%] [G loss: 0.614139]\n",
      "epoch:2 step:2329 [D loss: 0.148946, acc.: 80.47%] [G loss: 0.631750]\n",
      "epoch:2 step:2330 [D loss: 0.157102, acc.: 82.81%] [G loss: 0.690437]\n",
      "epoch:2 step:2331 [D loss: 0.134888, acc.: 81.25%] [G loss: 0.742114]\n",
      "epoch:2 step:2332 [D loss: 0.150635, acc.: 80.47%] [G loss: 0.695383]\n",
      "epoch:2 step:2333 [D loss: 0.137614, acc.: 82.81%] [G loss: 0.772329]\n",
      "epoch:2 step:2334 [D loss: 0.120488, acc.: 85.16%] [G loss: 0.804139]\n",
      "epoch:2 step:2335 [D loss: 0.122824, acc.: 85.16%] [G loss: 0.734715]\n",
      "epoch:2 step:2336 [D loss: 0.134216, acc.: 84.38%] [G loss: 0.651356]\n",
      "epoch:2 step:2337 [D loss: 0.139300, acc.: 82.81%] [G loss: 0.631841]\n",
      "epoch:2 step:2338 [D loss: 0.145589, acc.: 80.47%] [G loss: 0.713910]\n",
      "epoch:2 step:2339 [D loss: 0.176887, acc.: 72.66%] [G loss: 0.654466]\n",
      "epoch:2 step:2340 [D loss: 0.161155, acc.: 78.91%] [G loss: 0.735684]\n",
      "epoch:2 step:2341 [D loss: 0.128110, acc.: 83.59%] [G loss: 0.754139]\n",
      "epoch:2 step:2342 [D loss: 0.191500, acc.: 67.19%] [G loss: 0.712174]\n",
      "epoch:2 step:2343 [D loss: 0.162961, acc.: 79.69%] [G loss: 0.729499]\n",
      "epoch:2 step:2344 [D loss: 0.146584, acc.: 76.56%] [G loss: 0.745678]\n",
      "epoch:2 step:2345 [D loss: 0.129245, acc.: 84.38%] [G loss: 0.745647]\n",
      "epoch:2 step:2346 [D loss: 0.115965, acc.: 87.50%] [G loss: 0.781545]\n",
      "epoch:2 step:2347 [D loss: 0.207586, acc.: 67.97%] [G loss: 0.652569]\n",
      "epoch:2 step:2348 [D loss: 0.115570, acc.: 86.72%] [G loss: 0.837734]\n",
      "epoch:2 step:2349 [D loss: 0.136376, acc.: 80.47%] [G loss: 0.722105]\n",
      "epoch:2 step:2350 [D loss: 0.139480, acc.: 85.16%] [G loss: 0.756186]\n",
      "epoch:2 step:2351 [D loss: 0.176156, acc.: 78.91%] [G loss: 0.640471]\n",
      "epoch:2 step:2352 [D loss: 0.166363, acc.: 73.44%] [G loss: 0.682107]\n",
      "epoch:2 step:2353 [D loss: 0.195772, acc.: 72.66%] [G loss: 0.677520]\n",
      "epoch:2 step:2354 [D loss: 0.150382, acc.: 78.91%] [G loss: 0.681787]\n",
      "epoch:2 step:2355 [D loss: 0.166544, acc.: 76.56%] [G loss: 0.689820]\n",
      "epoch:2 step:2356 [D loss: 0.183263, acc.: 79.69%] [G loss: 0.633355]\n",
      "epoch:2 step:2357 [D loss: 0.190161, acc.: 74.22%] [G loss: 0.623486]\n",
      "epoch:2 step:2358 [D loss: 0.132209, acc.: 85.16%] [G loss: 0.747168]\n",
      "epoch:2 step:2359 [D loss: 0.158967, acc.: 78.12%] [G loss: 0.659163]\n",
      "epoch:2 step:2360 [D loss: 0.167475, acc.: 78.12%] [G loss: 0.686131]\n",
      "epoch:2 step:2361 [D loss: 0.160806, acc.: 81.25%] [G loss: 0.757909]\n",
      "epoch:2 step:2362 [D loss: 0.126459, acc.: 80.47%] [G loss: 0.706259]\n",
      "epoch:2 step:2363 [D loss: 0.170245, acc.: 73.44%] [G loss: 0.647893]\n",
      "epoch:2 step:2364 [D loss: 0.155860, acc.: 75.00%] [G loss: 0.724235]\n",
      "epoch:2 step:2365 [D loss: 0.135316, acc.: 79.69%] [G loss: 0.777649]\n",
      "epoch:2 step:2366 [D loss: 0.137189, acc.: 82.03%] [G loss: 0.722761]\n",
      "epoch:2 step:2367 [D loss: 0.199660, acc.: 66.41%] [G loss: 0.667807]\n",
      "epoch:2 step:2368 [D loss: 0.154404, acc.: 78.91%] [G loss: 0.697047]\n",
      "epoch:2 step:2369 [D loss: 0.134101, acc.: 86.72%] [G loss: 0.694170]\n",
      "epoch:2 step:2370 [D loss: 0.172039, acc.: 74.22%] [G loss: 0.680635]\n",
      "epoch:2 step:2371 [D loss: 0.116604, acc.: 85.94%] [G loss: 0.745908]\n",
      "epoch:2 step:2372 [D loss: 0.109767, acc.: 89.06%] [G loss: 0.801192]\n",
      "epoch:2 step:2373 [D loss: 0.127609, acc.: 86.72%] [G loss: 0.790064]\n",
      "epoch:2 step:2374 [D loss: 0.235221, acc.: 68.75%] [G loss: 0.591251]\n",
      "epoch:2 step:2375 [D loss: 0.182316, acc.: 73.44%] [G loss: 0.632203]\n",
      "epoch:2 step:2376 [D loss: 0.132024, acc.: 83.59%] [G loss: 0.720903]\n",
      "epoch:2 step:2377 [D loss: 0.142128, acc.: 83.59%] [G loss: 0.717848]\n",
      "epoch:2 step:2378 [D loss: 0.146386, acc.: 77.34%] [G loss: 0.708711]\n",
      "epoch:2 step:2379 [D loss: 0.128391, acc.: 84.38%] [G loss: 0.721960]\n",
      "epoch:2 step:2380 [D loss: 0.144061, acc.: 78.12%] [G loss: 0.693090]\n",
      "epoch:2 step:2381 [D loss: 0.147682, acc.: 85.16%] [G loss: 0.675635]\n",
      "epoch:2 step:2382 [D loss: 0.129208, acc.: 83.59%] [G loss: 0.716054]\n",
      "epoch:2 step:2383 [D loss: 0.124455, acc.: 83.59%] [G loss: 0.737026]\n",
      "epoch:2 step:2384 [D loss: 0.165158, acc.: 76.56%] [G loss: 0.608003]\n",
      "epoch:2 step:2385 [D loss: 0.170520, acc.: 73.44%] [G loss: 0.743430]\n",
      "epoch:2 step:2386 [D loss: 0.156751, acc.: 77.34%] [G loss: 0.724022]\n",
      "epoch:2 step:2387 [D loss: 0.153990, acc.: 78.91%] [G loss: 0.734098]\n",
      "epoch:2 step:2388 [D loss: 0.134133, acc.: 85.16%] [G loss: 0.716953]\n",
      "epoch:2 step:2389 [D loss: 0.113137, acc.: 87.50%] [G loss: 0.788677]\n",
      "epoch:2 step:2390 [D loss: 0.139555, acc.: 80.47%] [G loss: 0.672951]\n",
      "epoch:2 step:2391 [D loss: 0.166314, acc.: 78.12%] [G loss: 0.669461]\n",
      "epoch:2 step:2392 [D loss: 0.092665, acc.: 92.97%] [G loss: 0.778891]\n",
      "epoch:2 step:2393 [D loss: 0.172479, acc.: 75.00%] [G loss: 0.690801]\n",
      "epoch:2 step:2394 [D loss: 0.126929, acc.: 85.94%] [G loss: 0.722250]\n",
      "epoch:2 step:2395 [D loss: 0.106364, acc.: 90.62%] [G loss: 0.738671]\n",
      "epoch:2 step:2396 [D loss: 0.157174, acc.: 76.56%] [G loss: 0.668046]\n",
      "epoch:2 step:2397 [D loss: 0.161652, acc.: 81.25%] [G loss: 0.744345]\n",
      "epoch:2 step:2398 [D loss: 0.177457, acc.: 72.66%] [G loss: 0.689022]\n",
      "epoch:2 step:2399 [D loss: 0.190744, acc.: 69.53%] [G loss: 0.658674]\n",
      "epoch:2 step:2400 [D loss: 0.134667, acc.: 83.59%] [G loss: 0.724505]\n",
      "epoch:2 step:2401 [D loss: 0.212649, acc.: 67.19%] [G loss: 0.641532]\n",
      "epoch:2 step:2402 [D loss: 0.205469, acc.: 74.22%] [G loss: 0.718663]\n",
      "epoch:2 step:2403 [D loss: 0.133792, acc.: 82.03%] [G loss: 0.784976]\n",
      "epoch:2 step:2404 [D loss: 0.138586, acc.: 85.94%] [G loss: 0.753191]\n",
      "epoch:2 step:2405 [D loss: 0.175327, acc.: 77.34%] [G loss: 0.678264]\n",
      "epoch:2 step:2406 [D loss: 0.132699, acc.: 85.16%] [G loss: 0.713094]\n",
      "epoch:2 step:2407 [D loss: 0.141072, acc.: 80.47%] [G loss: 0.719825]\n",
      "epoch:2 step:2408 [D loss: 0.148455, acc.: 82.03%] [G loss: 0.708222]\n",
      "epoch:2 step:2409 [D loss: 0.180703, acc.: 71.88%] [G loss: 0.664463]\n",
      "epoch:2 step:2410 [D loss: 0.133050, acc.: 85.94%] [G loss: 0.742836]\n",
      "epoch:2 step:2411 [D loss: 0.155266, acc.: 79.69%] [G loss: 0.753148]\n",
      "epoch:2 step:2412 [D loss: 0.171968, acc.: 76.56%] [G loss: 0.717039]\n",
      "epoch:2 step:2413 [D loss: 0.161898, acc.: 78.91%] [G loss: 0.698933]\n",
      "epoch:2 step:2414 [D loss: 0.129045, acc.: 85.94%] [G loss: 0.760038]\n",
      "epoch:2 step:2415 [D loss: 0.129312, acc.: 82.81%] [G loss: 0.740492]\n",
      "epoch:2 step:2416 [D loss: 0.221535, acc.: 71.09%] [G loss: 0.607776]\n",
      "epoch:2 step:2417 [D loss: 0.186784, acc.: 72.66%] [G loss: 0.743239]\n",
      "epoch:2 step:2418 [D loss: 0.152908, acc.: 78.12%] [G loss: 0.746144]\n",
      "epoch:2 step:2419 [D loss: 0.183585, acc.: 71.88%] [G loss: 0.674218]\n",
      "epoch:2 step:2420 [D loss: 0.125243, acc.: 82.81%] [G loss: 0.786636]\n",
      "epoch:2 step:2421 [D loss: 0.131347, acc.: 80.47%] [G loss: 0.783876]\n",
      "epoch:2 step:2422 [D loss: 0.142976, acc.: 82.03%] [G loss: 0.799957]\n",
      "epoch:2 step:2423 [D loss: 0.149168, acc.: 83.59%] [G loss: 0.702453]\n",
      "epoch:2 step:2424 [D loss: 0.167793, acc.: 75.00%] [G loss: 0.724986]\n",
      "epoch:2 step:2425 [D loss: 0.168326, acc.: 77.34%] [G loss: 0.705887]\n",
      "epoch:2 step:2426 [D loss: 0.136527, acc.: 85.16%] [G loss: 0.738856]\n",
      "epoch:2 step:2427 [D loss: 0.138096, acc.: 82.03%] [G loss: 0.754274]\n",
      "epoch:2 step:2428 [D loss: 0.126857, acc.: 83.59%] [G loss: 0.791567]\n",
      "epoch:2 step:2429 [D loss: 0.136461, acc.: 83.59%] [G loss: 0.794527]\n",
      "epoch:2 step:2430 [D loss: 0.135819, acc.: 82.81%] [G loss: 0.680974]\n",
      "epoch:2 step:2431 [D loss: 0.121501, acc.: 86.72%] [G loss: 0.757051]\n",
      "epoch:2 step:2432 [D loss: 0.115970, acc.: 83.59%] [G loss: 0.824131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2433 [D loss: 0.170364, acc.: 78.91%] [G loss: 0.641291]\n",
      "epoch:2 step:2434 [D loss: 0.159191, acc.: 77.34%] [G loss: 0.669812]\n",
      "epoch:2 step:2435 [D loss: 0.135142, acc.: 79.69%] [G loss: 0.749471]\n",
      "epoch:2 step:2436 [D loss: 0.170038, acc.: 76.56%] [G loss: 0.704666]\n",
      "epoch:2 step:2437 [D loss: 0.186809, acc.: 71.88%] [G loss: 0.659561]\n",
      "epoch:2 step:2438 [D loss: 0.169987, acc.: 75.78%] [G loss: 0.668385]\n",
      "epoch:2 step:2439 [D loss: 0.142951, acc.: 82.81%] [G loss: 0.792805]\n",
      "epoch:2 step:2440 [D loss: 0.216974, acc.: 66.41%] [G loss: 0.657809]\n",
      "epoch:2 step:2441 [D loss: 0.132792, acc.: 85.16%] [G loss: 0.781372]\n",
      "epoch:2 step:2442 [D loss: 0.120163, acc.: 85.16%] [G loss: 0.793580]\n",
      "epoch:2 step:2443 [D loss: 0.186797, acc.: 69.53%] [G loss: 0.642661]\n",
      "epoch:2 step:2444 [D loss: 0.151737, acc.: 84.38%] [G loss: 0.715506]\n",
      "epoch:2 step:2445 [D loss: 0.129864, acc.: 84.38%] [G loss: 0.746415]\n",
      "epoch:2 step:2446 [D loss: 0.155610, acc.: 75.78%] [G loss: 0.689674]\n",
      "epoch:2 step:2447 [D loss: 0.147243, acc.: 76.56%] [G loss: 0.675730]\n",
      "epoch:2 step:2448 [D loss: 0.123061, acc.: 83.59%] [G loss: 0.766342]\n",
      "epoch:2 step:2449 [D loss: 0.125614, acc.: 83.59%] [G loss: 0.755552]\n",
      "epoch:2 step:2450 [D loss: 0.168328, acc.: 75.00%] [G loss: 0.667671]\n",
      "epoch:2 step:2451 [D loss: 0.137725, acc.: 82.81%] [G loss: 0.718174]\n",
      "epoch:2 step:2452 [D loss: 0.137226, acc.: 84.38%] [G loss: 0.719300]\n",
      "epoch:2 step:2453 [D loss: 0.131997, acc.: 87.50%] [G loss: 0.710585]\n",
      "epoch:2 step:2454 [D loss: 0.133206, acc.: 85.16%] [G loss: 0.701960]\n",
      "epoch:2 step:2455 [D loss: 0.124255, acc.: 86.72%] [G loss: 0.796274]\n",
      "epoch:2 step:2456 [D loss: 0.150227, acc.: 80.47%] [G loss: 0.775645]\n",
      "epoch:2 step:2457 [D loss: 0.154004, acc.: 80.47%] [G loss: 0.728022]\n",
      "epoch:2 step:2458 [D loss: 0.177902, acc.: 71.88%] [G loss: 0.729981]\n",
      "epoch:2 step:2459 [D loss: 0.161741, acc.: 75.00%] [G loss: 0.746983]\n",
      "epoch:2 step:2460 [D loss: 0.133808, acc.: 79.69%] [G loss: 0.786022]\n",
      "epoch:2 step:2461 [D loss: 0.159324, acc.: 80.47%] [G loss: 0.667718]\n",
      "epoch:2 step:2462 [D loss: 0.156699, acc.: 75.78%] [G loss: 0.705588]\n",
      "epoch:2 step:2463 [D loss: 0.150582, acc.: 81.25%] [G loss: 0.747405]\n",
      "epoch:2 step:2464 [D loss: 0.150898, acc.: 78.91%] [G loss: 0.710565]\n",
      "epoch:2 step:2465 [D loss: 0.112472, acc.: 88.28%] [G loss: 0.753608]\n",
      "epoch:2 step:2466 [D loss: 0.137045, acc.: 78.91%] [G loss: 0.759525]\n",
      "epoch:2 step:2467 [D loss: 0.159836, acc.: 79.69%] [G loss: 0.737737]\n",
      "epoch:2 step:2468 [D loss: 0.120274, acc.: 88.28%] [G loss: 0.720232]\n",
      "epoch:2 step:2469 [D loss: 0.117317, acc.: 90.62%] [G loss: 0.709029]\n",
      "epoch:2 step:2470 [D loss: 0.134085, acc.: 82.81%] [G loss: 0.740802]\n",
      "epoch:2 step:2471 [D loss: 0.123942, acc.: 85.16%] [G loss: 0.699046]\n",
      "epoch:2 step:2472 [D loss: 0.133272, acc.: 85.16%] [G loss: 0.720427]\n",
      "epoch:2 step:2473 [D loss: 0.176575, acc.: 75.00%] [G loss: 0.691563]\n",
      "epoch:2 step:2474 [D loss: 0.180170, acc.: 71.88%] [G loss: 0.626347]\n",
      "epoch:2 step:2475 [D loss: 0.166312, acc.: 79.69%] [G loss: 0.673210]\n",
      "epoch:2 step:2476 [D loss: 0.139250, acc.: 79.69%] [G loss: 0.755197]\n",
      "epoch:2 step:2477 [D loss: 0.146939, acc.: 78.91%] [G loss: 0.692813]\n",
      "epoch:2 step:2478 [D loss: 0.132303, acc.: 82.81%] [G loss: 0.760956]\n",
      "epoch:2 step:2479 [D loss: 0.136370, acc.: 84.38%] [G loss: 0.687419]\n",
      "epoch:2 step:2480 [D loss: 0.149683, acc.: 78.91%] [G loss: 0.708793]\n",
      "epoch:2 step:2481 [D loss: 0.168379, acc.: 73.44%] [G loss: 0.649974]\n",
      "epoch:2 step:2482 [D loss: 0.138455, acc.: 81.25%] [G loss: 0.724380]\n",
      "epoch:2 step:2483 [D loss: 0.157200, acc.: 75.00%] [G loss: 0.771618]\n",
      "epoch:2 step:2484 [D loss: 0.160758, acc.: 77.34%] [G loss: 0.723117]\n",
      "epoch:2 step:2485 [D loss: 0.124602, acc.: 87.50%] [G loss: 0.704934]\n",
      "epoch:2 step:2486 [D loss: 0.141225, acc.: 86.72%] [G loss: 0.699714]\n",
      "epoch:2 step:2487 [D loss: 0.127580, acc.: 85.94%] [G loss: 0.739581]\n",
      "epoch:2 step:2488 [D loss: 0.139196, acc.: 81.25%] [G loss: 0.697116]\n",
      "epoch:2 step:2489 [D loss: 0.203911, acc.: 70.31%] [G loss: 0.656653]\n",
      "epoch:2 step:2490 [D loss: 0.134724, acc.: 82.81%] [G loss: 0.736667]\n",
      "epoch:2 step:2491 [D loss: 0.187830, acc.: 74.22%] [G loss: 0.674279]\n",
      "epoch:2 step:2492 [D loss: 0.183175, acc.: 72.66%] [G loss: 0.599892]\n",
      "epoch:2 step:2493 [D loss: 0.148700, acc.: 78.12%] [G loss: 0.700122]\n",
      "epoch:2 step:2494 [D loss: 0.160561, acc.: 76.56%] [G loss: 0.656686]\n",
      "epoch:2 step:2495 [D loss: 0.181203, acc.: 72.66%] [G loss: 0.649977]\n",
      "epoch:2 step:2496 [D loss: 0.263970, acc.: 57.81%] [G loss: 0.593677]\n",
      "epoch:2 step:2497 [D loss: 0.154990, acc.: 80.47%] [G loss: 0.715071]\n",
      "epoch:2 step:2498 [D loss: 0.170161, acc.: 76.56%] [G loss: 0.714240]\n",
      "epoch:2 step:2499 [D loss: 0.189742, acc.: 71.09%] [G loss: 0.673901]\n",
      "epoch:2 step:2500 [D loss: 0.147524, acc.: 79.69%] [G loss: 0.693038]\n",
      "epoch:2 step:2501 [D loss: 0.182660, acc.: 70.31%] [G loss: 0.633891]\n",
      "epoch:2 step:2502 [D loss: 0.144166, acc.: 84.38%] [G loss: 0.724205]\n",
      "epoch:2 step:2503 [D loss: 0.137965, acc.: 84.38%] [G loss: 0.720821]\n",
      "epoch:2 step:2504 [D loss: 0.169813, acc.: 73.44%] [G loss: 0.702707]\n",
      "epoch:2 step:2505 [D loss: 0.125628, acc.: 83.59%] [G loss: 0.751104]\n",
      "epoch:2 step:2506 [D loss: 0.119108, acc.: 85.94%] [G loss: 0.764992]\n",
      "epoch:2 step:2507 [D loss: 0.129858, acc.: 81.25%] [G loss: 0.803268]\n",
      "epoch:2 step:2508 [D loss: 0.154688, acc.: 78.12%] [G loss: 0.705750]\n",
      "epoch:2 step:2509 [D loss: 0.121411, acc.: 84.38%] [G loss: 0.747537]\n",
      "epoch:2 step:2510 [D loss: 0.208488, acc.: 69.53%] [G loss: 0.684239]\n",
      "epoch:2 step:2511 [D loss: 0.204735, acc.: 71.09%] [G loss: 0.617013]\n",
      "epoch:2 step:2512 [D loss: 0.127597, acc.: 82.81%] [G loss: 0.719912]\n",
      "epoch:2 step:2513 [D loss: 0.124185, acc.: 83.59%] [G loss: 0.797587]\n",
      "epoch:2 step:2514 [D loss: 0.158267, acc.: 77.34%] [G loss: 0.701243]\n",
      "epoch:2 step:2515 [D loss: 0.118650, acc.: 80.47%] [G loss: 0.721303]\n",
      "epoch:2 step:2516 [D loss: 0.135910, acc.: 83.59%] [G loss: 0.731861]\n",
      "epoch:2 step:2517 [D loss: 0.157065, acc.: 79.69%] [G loss: 0.734197]\n",
      "epoch:2 step:2518 [D loss: 0.158531, acc.: 77.34%] [G loss: 0.696142]\n",
      "epoch:2 step:2519 [D loss: 0.152066, acc.: 82.81%] [G loss: 0.696649]\n",
      "epoch:2 step:2520 [D loss: 0.154140, acc.: 78.12%] [G loss: 0.712781]\n",
      "epoch:2 step:2521 [D loss: 0.114811, acc.: 85.94%] [G loss: 0.783312]\n",
      "epoch:2 step:2522 [D loss: 0.121588, acc.: 83.59%] [G loss: 0.792576]\n",
      "epoch:2 step:2523 [D loss: 0.148885, acc.: 82.03%] [G loss: 0.683895]\n",
      "epoch:2 step:2524 [D loss: 0.155215, acc.: 76.56%] [G loss: 0.718786]\n",
      "epoch:2 step:2525 [D loss: 0.148658, acc.: 79.69%] [G loss: 0.709289]\n",
      "epoch:2 step:2526 [D loss: 0.171147, acc.: 75.78%] [G loss: 0.639503]\n",
      "epoch:2 step:2527 [D loss: 0.147626, acc.: 81.25%] [G loss: 0.661796]\n",
      "epoch:2 step:2528 [D loss: 0.138194, acc.: 82.03%] [G loss: 0.759952]\n",
      "epoch:2 step:2529 [D loss: 0.151394, acc.: 80.47%] [G loss: 0.735070]\n",
      "epoch:2 step:2530 [D loss: 0.149305, acc.: 84.38%] [G loss: 0.704649]\n",
      "epoch:2 step:2531 [D loss: 0.146452, acc.: 79.69%] [G loss: 0.690836]\n",
      "epoch:2 step:2532 [D loss: 0.162737, acc.: 77.34%] [G loss: 0.700884]\n",
      "epoch:2 step:2533 [D loss: 0.144909, acc.: 82.03%] [G loss: 0.686977]\n",
      "epoch:2 step:2534 [D loss: 0.138582, acc.: 79.69%] [G loss: 0.700997]\n",
      "epoch:2 step:2535 [D loss: 0.127789, acc.: 82.81%] [G loss: 0.745766]\n",
      "epoch:2 step:2536 [D loss: 0.147809, acc.: 79.69%] [G loss: 0.690840]\n",
      "epoch:2 step:2537 [D loss: 0.138559, acc.: 83.59%] [G loss: 0.729763]\n",
      "epoch:2 step:2538 [D loss: 0.200700, acc.: 71.09%] [G loss: 0.679455]\n",
      "epoch:2 step:2539 [D loss: 0.150824, acc.: 80.47%] [G loss: 0.685891]\n",
      "epoch:2 step:2540 [D loss: 0.109074, acc.: 88.28%] [G loss: 0.736196]\n",
      "epoch:2 step:2541 [D loss: 0.136013, acc.: 82.03%] [G loss: 0.699071]\n",
      "epoch:2 step:2542 [D loss: 0.145051, acc.: 80.47%] [G loss: 0.728815]\n",
      "epoch:2 step:2543 [D loss: 0.168461, acc.: 80.47%] [G loss: 0.632547]\n",
      "epoch:2 step:2544 [D loss: 0.131836, acc.: 81.25%] [G loss: 0.740807]\n",
      "epoch:2 step:2545 [D loss: 0.172124, acc.: 78.12%] [G loss: 0.675746]\n",
      "epoch:2 step:2546 [D loss: 0.199958, acc.: 68.75%] [G loss: 0.625055]\n",
      "epoch:2 step:2547 [D loss: 0.154177, acc.: 82.03%] [G loss: 0.690623]\n",
      "epoch:2 step:2548 [D loss: 0.141032, acc.: 84.38%] [G loss: 0.741374]\n",
      "epoch:2 step:2549 [D loss: 0.158638, acc.: 83.59%] [G loss: 0.712189]\n",
      "epoch:2 step:2550 [D loss: 0.160760, acc.: 78.12%] [G loss: 0.712556]\n",
      "epoch:2 step:2551 [D loss: 0.118398, acc.: 88.28%] [G loss: 0.746559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2552 [D loss: 0.129024, acc.: 83.59%] [G loss: 0.752722]\n",
      "epoch:2 step:2553 [D loss: 0.162777, acc.: 78.91%] [G loss: 0.670162]\n",
      "epoch:2 step:2554 [D loss: 0.132047, acc.: 85.94%] [G loss: 0.666502]\n",
      "epoch:2 step:2555 [D loss: 0.151768, acc.: 80.47%] [G loss: 0.673331]\n",
      "epoch:2 step:2556 [D loss: 0.153936, acc.: 78.12%] [G loss: 0.676416]\n",
      "epoch:2 step:2557 [D loss: 0.189413, acc.: 78.12%] [G loss: 0.665917]\n",
      "epoch:2 step:2558 [D loss: 0.144292, acc.: 81.25%] [G loss: 0.695243]\n",
      "epoch:2 step:2559 [D loss: 0.174932, acc.: 74.22%] [G loss: 0.631160]\n",
      "epoch:2 step:2560 [D loss: 0.162735, acc.: 75.78%] [G loss: 0.678949]\n",
      "epoch:2 step:2561 [D loss: 0.186917, acc.: 75.78%] [G loss: 0.632509]\n",
      "epoch:2 step:2562 [D loss: 0.163530, acc.: 77.34%] [G loss: 0.720850]\n",
      "epoch:2 step:2563 [D loss: 0.149462, acc.: 80.47%] [G loss: 0.681522]\n",
      "epoch:2 step:2564 [D loss: 0.152776, acc.: 78.12%] [G loss: 0.683668]\n",
      "epoch:2 step:2565 [D loss: 0.153098, acc.: 81.25%] [G loss: 0.673205]\n",
      "epoch:2 step:2566 [D loss: 0.145970, acc.: 82.03%] [G loss: 0.637408]\n",
      "epoch:2 step:2567 [D loss: 0.156544, acc.: 78.91%] [G loss: 0.686162]\n",
      "epoch:2 step:2568 [D loss: 0.143962, acc.: 78.91%] [G loss: 0.724605]\n",
      "epoch:2 step:2569 [D loss: 0.152153, acc.: 81.25%] [G loss: 0.675695]\n",
      "epoch:2 step:2570 [D loss: 0.182867, acc.: 74.22%] [G loss: 0.608746]\n",
      "epoch:2 step:2571 [D loss: 0.143724, acc.: 84.38%] [G loss: 0.731086]\n",
      "epoch:2 step:2572 [D loss: 0.152534, acc.: 79.69%] [G loss: 0.618256]\n",
      "epoch:2 step:2573 [D loss: 0.169546, acc.: 78.12%] [G loss: 0.595217]\n",
      "epoch:2 step:2574 [D loss: 0.165329, acc.: 78.91%] [G loss: 0.639954]\n",
      "epoch:2 step:2575 [D loss: 0.163178, acc.: 77.34%] [G loss: 0.710275]\n",
      "epoch:2 step:2576 [D loss: 0.167180, acc.: 76.56%] [G loss: 0.701019]\n",
      "epoch:2 step:2577 [D loss: 0.181363, acc.: 74.22%] [G loss: 0.630345]\n",
      "epoch:2 step:2578 [D loss: 0.156352, acc.: 78.91%] [G loss: 0.653709]\n",
      "epoch:2 step:2579 [D loss: 0.161508, acc.: 78.91%] [G loss: 0.681642]\n",
      "epoch:2 step:2580 [D loss: 0.192062, acc.: 74.22%] [G loss: 0.615803]\n",
      "epoch:2 step:2581 [D loss: 0.123802, acc.: 82.81%] [G loss: 0.705968]\n",
      "epoch:2 step:2582 [D loss: 0.143842, acc.: 79.69%] [G loss: 0.691244]\n",
      "epoch:2 step:2583 [D loss: 0.133913, acc.: 78.12%] [G loss: 0.708236]\n",
      "epoch:2 step:2584 [D loss: 0.251734, acc.: 62.50%] [G loss: 0.576387]\n",
      "epoch:2 step:2585 [D loss: 0.166904, acc.: 78.12%] [G loss: 0.696333]\n",
      "epoch:2 step:2586 [D loss: 0.165957, acc.: 75.78%] [G loss: 0.618398]\n",
      "epoch:2 step:2587 [D loss: 0.157445, acc.: 76.56%] [G loss: 0.650547]\n",
      "epoch:2 step:2588 [D loss: 0.152923, acc.: 77.34%] [G loss: 0.724306]\n",
      "epoch:2 step:2589 [D loss: 0.216217, acc.: 71.09%] [G loss: 0.600036]\n",
      "epoch:2 step:2590 [D loss: 0.186242, acc.: 71.88%] [G loss: 0.586351]\n",
      "epoch:2 step:2591 [D loss: 0.166362, acc.: 75.78%] [G loss: 0.650635]\n",
      "epoch:2 step:2592 [D loss: 0.173697, acc.: 77.34%] [G loss: 0.627952]\n",
      "epoch:2 step:2593 [D loss: 0.176921, acc.: 77.34%] [G loss: 0.607181]\n",
      "epoch:2 step:2594 [D loss: 0.185760, acc.: 75.00%] [G loss: 0.639584]\n",
      "epoch:2 step:2595 [D loss: 0.176187, acc.: 72.66%] [G loss: 0.627725]\n",
      "epoch:2 step:2596 [D loss: 0.140729, acc.: 83.59%] [G loss: 0.713272]\n",
      "epoch:2 step:2597 [D loss: 0.173817, acc.: 76.56%] [G loss: 0.627806]\n",
      "epoch:2 step:2598 [D loss: 0.199916, acc.: 72.66%] [G loss: 0.586221]\n",
      "epoch:2 step:2599 [D loss: 0.131274, acc.: 85.94%] [G loss: 0.686122]\n",
      "epoch:2 step:2600 [D loss: 0.157493, acc.: 78.91%] [G loss: 0.667500]\n",
      "epoch:2 step:2601 [D loss: 0.219904, acc.: 64.06%] [G loss: 0.575525]\n",
      "epoch:2 step:2602 [D loss: 0.156672, acc.: 79.69%] [G loss: 0.619344]\n",
      "epoch:2 step:2603 [D loss: 0.166383, acc.: 76.56%] [G loss: 0.680518]\n",
      "epoch:2 step:2604 [D loss: 0.145581, acc.: 83.59%] [G loss: 0.675433]\n",
      "epoch:2 step:2605 [D loss: 0.168730, acc.: 75.00%] [G loss: 0.638278]\n",
      "epoch:2 step:2606 [D loss: 0.137641, acc.: 79.69%] [G loss: 0.734866]\n",
      "epoch:2 step:2607 [D loss: 0.138981, acc.: 77.34%] [G loss: 0.695428]\n",
      "epoch:2 step:2608 [D loss: 0.167013, acc.: 75.00%] [G loss: 0.615485]\n",
      "epoch:2 step:2609 [D loss: 0.181392, acc.: 71.09%] [G loss: 0.626636]\n",
      "epoch:2 step:2610 [D loss: 0.123118, acc.: 83.59%] [G loss: 0.701707]\n",
      "epoch:2 step:2611 [D loss: 0.185711, acc.: 73.44%] [G loss: 0.654768]\n",
      "epoch:2 step:2612 [D loss: 0.193962, acc.: 71.88%] [G loss: 0.628441]\n",
      "epoch:2 step:2613 [D loss: 0.168982, acc.: 76.56%] [G loss: 0.687898]\n",
      "epoch:2 step:2614 [D loss: 0.199869, acc.: 69.53%] [G loss: 0.586842]\n",
      "epoch:2 step:2615 [D loss: 0.181196, acc.: 80.47%] [G loss: 0.605798]\n",
      "epoch:2 step:2616 [D loss: 0.192376, acc.: 71.09%] [G loss: 0.641391]\n",
      "epoch:2 step:2617 [D loss: 0.146152, acc.: 81.25%] [G loss: 0.693249]\n",
      "epoch:2 step:2618 [D loss: 0.136384, acc.: 80.47%] [G loss: 0.706706]\n",
      "epoch:2 step:2619 [D loss: 0.159211, acc.: 76.56%] [G loss: 0.641831]\n",
      "epoch:2 step:2620 [D loss: 0.146503, acc.: 82.03%] [G loss: 0.697093]\n",
      "epoch:2 step:2621 [D loss: 0.117061, acc.: 84.38%] [G loss: 0.750563]\n",
      "epoch:2 step:2622 [D loss: 0.158049, acc.: 80.47%] [G loss: 0.665461]\n",
      "epoch:2 step:2623 [D loss: 0.163425, acc.: 75.00%] [G loss: 0.669173]\n",
      "epoch:2 step:2624 [D loss: 0.164461, acc.: 72.66%] [G loss: 0.651327]\n",
      "epoch:2 step:2625 [D loss: 0.194821, acc.: 71.09%] [G loss: 0.605724]\n",
      "epoch:2 step:2626 [D loss: 0.180183, acc.: 73.44%] [G loss: 0.626179]\n",
      "epoch:2 step:2627 [D loss: 0.141969, acc.: 81.25%] [G loss: 0.743067]\n",
      "epoch:2 step:2628 [D loss: 0.125513, acc.: 81.25%] [G loss: 0.710888]\n",
      "epoch:2 step:2629 [D loss: 0.175992, acc.: 75.00%] [G loss: 0.714718]\n",
      "epoch:2 step:2630 [D loss: 0.151936, acc.: 80.47%] [G loss: 0.703309]\n",
      "epoch:2 step:2631 [D loss: 0.118230, acc.: 87.50%] [G loss: 0.697544]\n",
      "epoch:2 step:2632 [D loss: 0.153348, acc.: 78.91%] [G loss: 0.629700]\n",
      "epoch:2 step:2633 [D loss: 0.141102, acc.: 82.03%] [G loss: 0.687571]\n",
      "epoch:2 step:2634 [D loss: 0.162927, acc.: 78.12%] [G loss: 0.693998]\n",
      "epoch:2 step:2635 [D loss: 0.202748, acc.: 71.09%] [G loss: 0.630265]\n",
      "epoch:2 step:2636 [D loss: 0.190774, acc.: 68.75%] [G loss: 0.655231]\n",
      "epoch:2 step:2637 [D loss: 0.155327, acc.: 75.78%] [G loss: 0.663187]\n",
      "epoch:2 step:2638 [D loss: 0.176076, acc.: 75.78%] [G loss: 0.668280]\n",
      "epoch:2 step:2639 [D loss: 0.207275, acc.: 66.41%] [G loss: 0.654317]\n",
      "epoch:2 step:2640 [D loss: 0.230607, acc.: 58.59%] [G loss: 0.598521]\n",
      "epoch:2 step:2641 [D loss: 0.151329, acc.: 77.34%] [G loss: 0.710107]\n",
      "epoch:2 step:2642 [D loss: 0.174520, acc.: 75.78%] [G loss: 0.723150]\n",
      "epoch:2 step:2643 [D loss: 0.136199, acc.: 86.72%] [G loss: 0.671502]\n",
      "epoch:2 step:2644 [D loss: 0.173572, acc.: 75.78%] [G loss: 0.659926]\n",
      "epoch:2 step:2645 [D loss: 0.167317, acc.: 72.66%] [G loss: 0.659200]\n",
      "epoch:2 step:2646 [D loss: 0.168663, acc.: 76.56%] [G loss: 0.719637]\n",
      "epoch:2 step:2647 [D loss: 0.173605, acc.: 71.88%] [G loss: 0.634884]\n",
      "epoch:2 step:2648 [D loss: 0.168678, acc.: 76.56%] [G loss: 0.673000]\n",
      "epoch:2 step:2649 [D loss: 0.152089, acc.: 75.78%] [G loss: 0.665227]\n",
      "epoch:2 step:2650 [D loss: 0.181022, acc.: 71.88%] [G loss: 0.691951]\n",
      "epoch:2 step:2651 [D loss: 0.151573, acc.: 82.03%] [G loss: 0.675981]\n",
      "epoch:2 step:2652 [D loss: 0.181471, acc.: 77.34%] [G loss: 0.646159]\n",
      "epoch:2 step:2653 [D loss: 0.153736, acc.: 76.56%] [G loss: 0.729845]\n",
      "epoch:2 step:2654 [D loss: 0.157222, acc.: 76.56%] [G loss: 0.691049]\n",
      "epoch:2 step:2655 [D loss: 0.142495, acc.: 82.03%] [G loss: 0.670848]\n",
      "epoch:2 step:2656 [D loss: 0.161632, acc.: 75.78%] [G loss: 0.708365]\n",
      "epoch:2 step:2657 [D loss: 0.198777, acc.: 73.44%] [G loss: 0.621028]\n",
      "epoch:2 step:2658 [D loss: 0.168004, acc.: 79.69%] [G loss: 0.640059]\n",
      "epoch:2 step:2659 [D loss: 0.168252, acc.: 78.12%] [G loss: 0.656235]\n",
      "epoch:2 step:2660 [D loss: 0.150964, acc.: 80.47%] [G loss: 0.700573]\n",
      "epoch:2 step:2661 [D loss: 0.209698, acc.: 64.84%] [G loss: 0.608327]\n",
      "epoch:2 step:2662 [D loss: 0.191660, acc.: 72.66%] [G loss: 0.630834]\n",
      "epoch:2 step:2663 [D loss: 0.146791, acc.: 79.69%] [G loss: 0.640177]\n",
      "epoch:2 step:2664 [D loss: 0.156273, acc.: 77.34%] [G loss: 0.675577]\n",
      "epoch:2 step:2665 [D loss: 0.201240, acc.: 67.19%] [G loss: 0.613581]\n",
      "epoch:2 step:2666 [D loss: 0.145944, acc.: 78.12%] [G loss: 0.761526]\n",
      "epoch:2 step:2667 [D loss: 0.206871, acc.: 69.53%] [G loss: 0.630955]\n",
      "epoch:2 step:2668 [D loss: 0.218942, acc.: 66.41%] [G loss: 0.599764]\n",
      "epoch:2 step:2669 [D loss: 0.147766, acc.: 79.69%] [G loss: 0.699015]\n",
      "epoch:2 step:2670 [D loss: 0.178470, acc.: 69.53%] [G loss: 0.710345]\n",
      "epoch:2 step:2671 [D loss: 0.199120, acc.: 67.19%] [G loss: 0.640824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2672 [D loss: 0.151699, acc.: 78.91%] [G loss: 0.698325]\n",
      "epoch:2 step:2673 [D loss: 0.208737, acc.: 69.53%] [G loss: 0.594546]\n",
      "epoch:2 step:2674 [D loss: 0.167303, acc.: 73.44%] [G loss: 0.658064]\n",
      "epoch:2 step:2675 [D loss: 0.155978, acc.: 78.12%] [G loss: 0.659630]\n",
      "epoch:2 step:2676 [D loss: 0.154647, acc.: 74.22%] [G loss: 0.645445]\n",
      "epoch:2 step:2677 [D loss: 0.138513, acc.: 83.59%] [G loss: 0.705489]\n",
      "epoch:2 step:2678 [D loss: 0.168428, acc.: 74.22%] [G loss: 0.580298]\n",
      "epoch:2 step:2679 [D loss: 0.147910, acc.: 78.91%] [G loss: 0.648861]\n",
      "epoch:2 step:2680 [D loss: 0.138462, acc.: 82.03%] [G loss: 0.692375]\n",
      "epoch:2 step:2681 [D loss: 0.169477, acc.: 78.12%] [G loss: 0.697158]\n",
      "epoch:2 step:2682 [D loss: 0.230109, acc.: 64.84%] [G loss: 0.567478]\n",
      "epoch:2 step:2683 [D loss: 0.208027, acc.: 71.88%] [G loss: 0.612758]\n",
      "epoch:2 step:2684 [D loss: 0.143881, acc.: 78.12%] [G loss: 0.696884]\n",
      "epoch:2 step:2685 [D loss: 0.173738, acc.: 72.66%] [G loss: 0.714273]\n",
      "epoch:2 step:2686 [D loss: 0.194485, acc.: 71.88%] [G loss: 0.599353]\n",
      "epoch:2 step:2687 [D loss: 0.163925, acc.: 75.78%] [G loss: 0.691298]\n",
      "epoch:2 step:2688 [D loss: 0.179318, acc.: 67.97%] [G loss: 0.689512]\n",
      "epoch:2 step:2689 [D loss: 0.185389, acc.: 68.75%] [G loss: 0.655915]\n",
      "epoch:2 step:2690 [D loss: 0.155797, acc.: 80.47%] [G loss: 0.650226]\n",
      "epoch:2 step:2691 [D loss: 0.197551, acc.: 66.41%] [G loss: 0.661475]\n",
      "epoch:2 step:2692 [D loss: 0.200043, acc.: 68.75%] [G loss: 0.676692]\n",
      "epoch:2 step:2693 [D loss: 0.157134, acc.: 82.03%] [G loss: 0.666624]\n",
      "epoch:2 step:2694 [D loss: 0.200436, acc.: 68.75%] [G loss: 0.621161]\n",
      "epoch:2 step:2695 [D loss: 0.179480, acc.: 78.12%] [G loss: 0.646319]\n",
      "epoch:2 step:2696 [D loss: 0.130748, acc.: 85.16%] [G loss: 0.738658]\n",
      "epoch:2 step:2697 [D loss: 0.142286, acc.: 82.03%] [G loss: 0.758523]\n",
      "epoch:2 step:2698 [D loss: 0.231009, acc.: 67.97%] [G loss: 0.546711]\n",
      "epoch:2 step:2699 [D loss: 0.148995, acc.: 80.47%] [G loss: 0.702000]\n",
      "epoch:2 step:2700 [D loss: 0.157051, acc.: 78.91%] [G loss: 0.672508]\n",
      "epoch:2 step:2701 [D loss: 0.210609, acc.: 67.19%] [G loss: 0.638744]\n",
      "epoch:2 step:2702 [D loss: 0.206944, acc.: 71.09%] [G loss: 0.592124]\n",
      "epoch:2 step:2703 [D loss: 0.157765, acc.: 80.47%] [G loss: 0.703439]\n",
      "epoch:2 step:2704 [D loss: 0.168952, acc.: 76.56%] [G loss: 0.682088]\n",
      "epoch:2 step:2705 [D loss: 0.191081, acc.: 75.00%] [G loss: 0.644926]\n",
      "epoch:2 step:2706 [D loss: 0.189219, acc.: 72.66%] [G loss: 0.698653]\n",
      "epoch:2 step:2707 [D loss: 0.147370, acc.: 83.59%] [G loss: 0.702674]\n",
      "epoch:2 step:2708 [D loss: 0.154623, acc.: 79.69%] [G loss: 0.662044]\n",
      "epoch:2 step:2709 [D loss: 0.163061, acc.: 75.78%] [G loss: 0.623574]\n",
      "epoch:2 step:2710 [D loss: 0.184415, acc.: 72.66%] [G loss: 0.613009]\n",
      "epoch:2 step:2711 [D loss: 0.160403, acc.: 82.81%] [G loss: 0.633686]\n",
      "epoch:2 step:2712 [D loss: 0.173151, acc.: 74.22%] [G loss: 0.687725]\n",
      "epoch:2 step:2713 [D loss: 0.172153, acc.: 77.34%] [G loss: 0.634912]\n",
      "epoch:2 step:2714 [D loss: 0.215567, acc.: 68.75%] [G loss: 0.608745]\n",
      "epoch:2 step:2715 [D loss: 0.153975, acc.: 80.47%] [G loss: 0.647211]\n",
      "epoch:2 step:2716 [D loss: 0.170908, acc.: 78.12%] [G loss: 0.667430]\n",
      "epoch:2 step:2717 [D loss: 0.207566, acc.: 71.88%] [G loss: 0.655467]\n",
      "epoch:2 step:2718 [D loss: 0.168280, acc.: 79.69%] [G loss: 0.697215]\n",
      "epoch:2 step:2719 [D loss: 0.171673, acc.: 77.34%] [G loss: 0.646376]\n",
      "epoch:2 step:2720 [D loss: 0.158933, acc.: 80.47%] [G loss: 0.629063]\n",
      "epoch:2 step:2721 [D loss: 0.152795, acc.: 75.78%] [G loss: 0.658413]\n",
      "epoch:2 step:2722 [D loss: 0.155672, acc.: 77.34%] [G loss: 0.626544]\n",
      "epoch:2 step:2723 [D loss: 0.183027, acc.: 72.66%] [G loss: 0.635365]\n",
      "epoch:2 step:2724 [D loss: 0.186538, acc.: 75.78%] [G loss: 0.653597]\n",
      "epoch:2 step:2725 [D loss: 0.182672, acc.: 71.88%] [G loss: 0.655694]\n",
      "epoch:2 step:2726 [D loss: 0.136499, acc.: 85.16%] [G loss: 0.761876]\n",
      "epoch:2 step:2727 [D loss: 0.134763, acc.: 83.59%] [G loss: 0.771166]\n",
      "epoch:2 step:2728 [D loss: 0.128959, acc.: 83.59%] [G loss: 0.739714]\n",
      "epoch:2 step:2729 [D loss: 0.180538, acc.: 68.75%] [G loss: 0.645852]\n",
      "epoch:2 step:2730 [D loss: 0.200179, acc.: 66.41%] [G loss: 0.602171]\n",
      "epoch:2 step:2731 [D loss: 0.132675, acc.: 82.03%] [G loss: 0.761764]\n",
      "epoch:2 step:2732 [D loss: 0.263260, acc.: 53.12%] [G loss: 0.581855]\n",
      "epoch:2 step:2733 [D loss: 0.209858, acc.: 71.88%] [G loss: 0.626879]\n",
      "epoch:2 step:2734 [D loss: 0.113852, acc.: 87.50%] [G loss: 0.756616]\n",
      "epoch:2 step:2735 [D loss: 0.193313, acc.: 66.41%] [G loss: 0.579666]\n",
      "epoch:2 step:2736 [D loss: 0.161093, acc.: 77.34%] [G loss: 0.652939]\n",
      "epoch:2 step:2737 [D loss: 0.174434, acc.: 76.56%] [G loss: 0.605293]\n",
      "epoch:2 step:2738 [D loss: 0.158583, acc.: 76.56%] [G loss: 0.671990]\n",
      "epoch:2 step:2739 [D loss: 0.179697, acc.: 73.44%] [G loss: 0.634482]\n",
      "epoch:2 step:2740 [D loss: 0.154802, acc.: 79.69%] [G loss: 0.629307]\n",
      "epoch:2 step:2741 [D loss: 0.190146, acc.: 71.09%] [G loss: 0.636235]\n",
      "epoch:2 step:2742 [D loss: 0.145162, acc.: 83.59%] [G loss: 0.662752]\n",
      "epoch:2 step:2743 [D loss: 0.188538, acc.: 71.09%] [G loss: 0.578314]\n",
      "epoch:2 step:2744 [D loss: 0.133786, acc.: 84.38%] [G loss: 0.675216]\n",
      "epoch:2 step:2745 [D loss: 0.129351, acc.: 83.59%] [G loss: 0.738516]\n",
      "epoch:2 step:2746 [D loss: 0.188618, acc.: 73.44%] [G loss: 0.631714]\n",
      "epoch:2 step:2747 [D loss: 0.193452, acc.: 66.41%] [G loss: 0.601181]\n",
      "epoch:2 step:2748 [D loss: 0.152286, acc.: 77.34%] [G loss: 0.616721]\n",
      "epoch:2 step:2749 [D loss: 0.153392, acc.: 78.91%] [G loss: 0.675147]\n",
      "epoch:2 step:2750 [D loss: 0.170297, acc.: 78.12%] [G loss: 0.665620]\n",
      "epoch:2 step:2751 [D loss: 0.171737, acc.: 75.78%] [G loss: 0.691584]\n",
      "epoch:2 step:2752 [D loss: 0.198716, acc.: 66.41%] [G loss: 0.605944]\n",
      "epoch:2 step:2753 [D loss: 0.173198, acc.: 74.22%] [G loss: 0.638628]\n",
      "epoch:2 step:2754 [D loss: 0.209531, acc.: 68.75%] [G loss: 0.556995]\n",
      "epoch:2 step:2755 [D loss: 0.138800, acc.: 87.50%] [G loss: 0.641910]\n",
      "epoch:2 step:2756 [D loss: 0.149389, acc.: 77.34%] [G loss: 0.664213]\n",
      "epoch:2 step:2757 [D loss: 0.161172, acc.: 80.47%] [G loss: 0.642174]\n",
      "epoch:2 step:2758 [D loss: 0.164540, acc.: 75.78%] [G loss: 0.658648]\n",
      "epoch:2 step:2759 [D loss: 0.139291, acc.: 78.91%] [G loss: 0.711354]\n",
      "epoch:2 step:2760 [D loss: 0.147840, acc.: 79.69%] [G loss: 0.711121]\n",
      "epoch:2 step:2761 [D loss: 0.133798, acc.: 81.25%] [G loss: 0.679524]\n",
      "epoch:2 step:2762 [D loss: 0.121078, acc.: 85.94%] [G loss: 0.693516]\n",
      "epoch:2 step:2763 [D loss: 0.155282, acc.: 78.91%] [G loss: 0.660141]\n",
      "epoch:2 step:2764 [D loss: 0.148984, acc.: 84.38%] [G loss: 0.673031]\n",
      "epoch:2 step:2765 [D loss: 0.183103, acc.: 78.12%] [G loss: 0.599151]\n",
      "epoch:2 step:2766 [D loss: 0.220140, acc.: 67.19%] [G loss: 0.563420]\n",
      "epoch:2 step:2767 [D loss: 0.171982, acc.: 74.22%] [G loss: 0.686599]\n",
      "epoch:2 step:2768 [D loss: 0.194365, acc.: 67.97%] [G loss: 0.662734]\n",
      "epoch:2 step:2769 [D loss: 0.160659, acc.: 75.78%] [G loss: 0.708701]\n",
      "epoch:2 step:2770 [D loss: 0.169055, acc.: 73.44%] [G loss: 0.590450]\n",
      "epoch:2 step:2771 [D loss: 0.156193, acc.: 79.69%] [G loss: 0.622354]\n",
      "epoch:2 step:2772 [D loss: 0.159425, acc.: 75.78%] [G loss: 0.725641]\n",
      "epoch:2 step:2773 [D loss: 0.169780, acc.: 77.34%] [G loss: 0.681288]\n",
      "epoch:2 step:2774 [D loss: 0.168402, acc.: 77.34%] [G loss: 0.641670]\n",
      "epoch:2 step:2775 [D loss: 0.206466, acc.: 66.41%] [G loss: 0.620057]\n",
      "epoch:2 step:2776 [D loss: 0.201518, acc.: 75.00%] [G loss: 0.596932]\n",
      "epoch:2 step:2777 [D loss: 0.173465, acc.: 74.22%] [G loss: 0.611983]\n",
      "epoch:2 step:2778 [D loss: 0.146091, acc.: 81.25%] [G loss: 0.671081]\n",
      "epoch:2 step:2779 [D loss: 0.161805, acc.: 75.78%] [G loss: 0.672184]\n",
      "epoch:2 step:2780 [D loss: 0.183058, acc.: 73.44%] [G loss: 0.664911]\n",
      "epoch:2 step:2781 [D loss: 0.191992, acc.: 66.41%] [G loss: 0.617946]\n",
      "epoch:2 step:2782 [D loss: 0.160547, acc.: 81.25%] [G loss: 0.614518]\n",
      "epoch:2 step:2783 [D loss: 0.154766, acc.: 79.69%] [G loss: 0.654948]\n",
      "epoch:2 step:2784 [D loss: 0.156103, acc.: 78.12%] [G loss: 0.733775]\n",
      "epoch:2 step:2785 [D loss: 0.128119, acc.: 85.94%] [G loss: 0.748000]\n",
      "epoch:2 step:2786 [D loss: 0.175459, acc.: 73.44%] [G loss: 0.661087]\n",
      "epoch:2 step:2787 [D loss: 0.175167, acc.: 76.56%] [G loss: 0.659966]\n",
      "epoch:2 step:2788 [D loss: 0.173631, acc.: 78.91%] [G loss: 0.670428]\n",
      "epoch:2 step:2789 [D loss: 0.207282, acc.: 69.53%] [G loss: 0.580203]\n",
      "epoch:2 step:2790 [D loss: 0.213192, acc.: 63.28%] [G loss: 0.587708]\n",
      "epoch:2 step:2791 [D loss: 0.187837, acc.: 67.97%] [G loss: 0.641822]\n",
      "epoch:2 step:2792 [D loss: 0.171396, acc.: 73.44%] [G loss: 0.719431]\n",
      "epoch:2 step:2793 [D loss: 0.199659, acc.: 70.31%] [G loss: 0.584931]\n",
      "epoch:2 step:2794 [D loss: 0.227133, acc.: 66.41%] [G loss: 0.572819]\n",
      "epoch:2 step:2795 [D loss: 0.141715, acc.: 81.25%] [G loss: 0.705005]\n",
      "epoch:2 step:2796 [D loss: 0.224528, acc.: 65.62%] [G loss: 0.575599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2797 [D loss: 0.105785, acc.: 89.06%] [G loss: 0.716833]\n",
      "epoch:2 step:2798 [D loss: 0.140475, acc.: 83.59%] [G loss: 0.743719]\n",
      "epoch:2 step:2799 [D loss: 0.139117, acc.: 81.25%] [G loss: 0.810609]\n",
      "epoch:2 step:2800 [D loss: 0.161704, acc.: 75.78%] [G loss: 0.758877]\n",
      "epoch:2 step:2801 [D loss: 0.189118, acc.: 71.88%] [G loss: 0.743397]\n",
      "epoch:2 step:2802 [D loss: 0.283282, acc.: 65.62%] [G loss: 0.605908]\n",
      "epoch:2 step:2803 [D loss: 0.091951, acc.: 88.28%] [G loss: 0.912376]\n",
      "epoch:2 step:2804 [D loss: 0.183192, acc.: 72.66%] [G loss: 0.671538]\n",
      "epoch:2 step:2805 [D loss: 0.170911, acc.: 73.44%] [G loss: 0.570012]\n",
      "epoch:2 step:2806 [D loss: 0.141052, acc.: 82.03%] [G loss: 0.643829]\n",
      "epoch:2 step:2807 [D loss: 0.141758, acc.: 82.03%] [G loss: 0.696979]\n",
      "epoch:2 step:2808 [D loss: 0.172800, acc.: 72.66%] [G loss: 0.647524]\n",
      "epoch:2 step:2809 [D loss: 0.161475, acc.: 76.56%] [G loss: 0.686413]\n",
      "epoch:2 step:2810 [D loss: 0.085906, acc.: 91.41%] [G loss: 0.829130]\n",
      "epoch:2 step:2811 [D loss: 0.167568, acc.: 75.00%] [G loss: 0.749484]\n",
      "epoch:3 step:2812 [D loss: 0.196755, acc.: 70.31%] [G loss: 0.663290]\n",
      "epoch:3 step:2813 [D loss: 0.159606, acc.: 81.25%] [G loss: 0.677914]\n",
      "epoch:3 step:2814 [D loss: 0.190216, acc.: 75.78%] [G loss: 0.612798]\n",
      "epoch:3 step:2815 [D loss: 0.155804, acc.: 78.12%] [G loss: 0.687738]\n",
      "epoch:3 step:2816 [D loss: 0.164717, acc.: 75.00%] [G loss: 0.646733]\n",
      "epoch:3 step:2817 [D loss: 0.174480, acc.: 72.66%] [G loss: 0.594380]\n",
      "epoch:3 step:2818 [D loss: 0.185936, acc.: 69.53%] [G loss: 0.613184]\n",
      "epoch:3 step:2819 [D loss: 0.160617, acc.: 78.91%] [G loss: 0.650189]\n",
      "epoch:3 step:2820 [D loss: 0.190317, acc.: 68.75%] [G loss: 0.663724]\n",
      "epoch:3 step:2821 [D loss: 0.190335, acc.: 72.66%] [G loss: 0.661957]\n",
      "epoch:3 step:2822 [D loss: 0.158316, acc.: 80.47%] [G loss: 0.649697]\n",
      "epoch:3 step:2823 [D loss: 0.158653, acc.: 77.34%] [G loss: 0.655790]\n",
      "epoch:3 step:2824 [D loss: 0.169507, acc.: 79.69%] [G loss: 0.623561]\n",
      "epoch:3 step:2825 [D loss: 0.150083, acc.: 78.12%] [G loss: 0.680768]\n",
      "epoch:3 step:2826 [D loss: 0.119847, acc.: 84.38%] [G loss: 0.683413]\n",
      "epoch:3 step:2827 [D loss: 0.172677, acc.: 76.56%] [G loss: 0.676777]\n",
      "epoch:3 step:2828 [D loss: 0.201683, acc.: 74.22%] [G loss: 0.620688]\n",
      "epoch:3 step:2829 [D loss: 0.225869, acc.: 63.28%] [G loss: 0.547323]\n",
      "epoch:3 step:2830 [D loss: 0.184714, acc.: 67.97%] [G loss: 0.611194]\n",
      "epoch:3 step:2831 [D loss: 0.240458, acc.: 61.72%] [G loss: 0.531527]\n",
      "epoch:3 step:2832 [D loss: 0.126541, acc.: 85.16%] [G loss: 0.703840]\n",
      "epoch:3 step:2833 [D loss: 0.151166, acc.: 81.25%] [G loss: 0.638260]\n",
      "epoch:3 step:2834 [D loss: 0.149981, acc.: 80.47%] [G loss: 0.702005]\n",
      "epoch:3 step:2835 [D loss: 0.172675, acc.: 70.31%] [G loss: 0.677339]\n",
      "epoch:3 step:2836 [D loss: 0.151139, acc.: 76.56%] [G loss: 0.665900]\n",
      "epoch:3 step:2837 [D loss: 0.176196, acc.: 77.34%] [G loss: 0.609070]\n",
      "epoch:3 step:2838 [D loss: 0.172469, acc.: 74.22%] [G loss: 0.663156]\n",
      "epoch:3 step:2839 [D loss: 0.136767, acc.: 78.91%] [G loss: 0.691017]\n",
      "epoch:3 step:2840 [D loss: 0.150857, acc.: 78.91%] [G loss: 0.650132]\n",
      "epoch:3 step:2841 [D loss: 0.207980, acc.: 66.41%] [G loss: 0.557711]\n",
      "epoch:3 step:2842 [D loss: 0.199953, acc.: 66.41%] [G loss: 0.637868]\n",
      "epoch:3 step:2843 [D loss: 0.186294, acc.: 75.00%] [G loss: 0.640259]\n",
      "epoch:3 step:2844 [D loss: 0.173591, acc.: 71.88%] [G loss: 0.611235]\n",
      "epoch:3 step:2845 [D loss: 0.162329, acc.: 76.56%] [G loss: 0.633228]\n",
      "epoch:3 step:2846 [D loss: 0.147213, acc.: 79.69%] [G loss: 0.624277]\n",
      "epoch:3 step:2847 [D loss: 0.154978, acc.: 77.34%] [G loss: 0.676053]\n",
      "epoch:3 step:2848 [D loss: 0.149211, acc.: 79.69%] [G loss: 0.648076]\n",
      "epoch:3 step:2849 [D loss: 0.171925, acc.: 75.00%] [G loss: 0.596318]\n",
      "epoch:3 step:2850 [D loss: 0.147323, acc.: 78.91%] [G loss: 0.671521]\n",
      "epoch:3 step:2851 [D loss: 0.142157, acc.: 80.47%] [G loss: 0.697493]\n",
      "epoch:3 step:2852 [D loss: 0.186058, acc.: 73.44%] [G loss: 0.614859]\n",
      "epoch:3 step:2853 [D loss: 0.177897, acc.: 76.56%] [G loss: 0.600201]\n",
      "epoch:3 step:2854 [D loss: 0.144242, acc.: 79.69%] [G loss: 0.685966]\n",
      "epoch:3 step:2855 [D loss: 0.210074, acc.: 70.31%] [G loss: 0.569138]\n",
      "epoch:3 step:2856 [D loss: 0.173722, acc.: 73.44%] [G loss: 0.587377]\n",
      "epoch:3 step:2857 [D loss: 0.162973, acc.: 73.44%] [G loss: 0.632566]\n",
      "epoch:3 step:2858 [D loss: 0.155846, acc.: 80.47%] [G loss: 0.662150]\n",
      "epoch:3 step:2859 [D loss: 0.148318, acc.: 79.69%] [G loss: 0.651626]\n",
      "epoch:3 step:2860 [D loss: 0.193027, acc.: 71.88%] [G loss: 0.619242]\n",
      "epoch:3 step:2861 [D loss: 0.153987, acc.: 80.47%] [G loss: 0.660988]\n",
      "epoch:3 step:2862 [D loss: 0.158158, acc.: 78.91%] [G loss: 0.643120]\n",
      "epoch:3 step:2863 [D loss: 0.158032, acc.: 78.91%] [G loss: 0.685354]\n",
      "epoch:3 step:2864 [D loss: 0.163578, acc.: 78.91%] [G loss: 0.648337]\n",
      "epoch:3 step:2865 [D loss: 0.175574, acc.: 78.12%] [G loss: 0.659801]\n",
      "epoch:3 step:2866 [D loss: 0.143414, acc.: 78.12%] [G loss: 0.727671]\n",
      "epoch:3 step:2867 [D loss: 0.182623, acc.: 70.31%] [G loss: 0.651764]\n",
      "epoch:3 step:2868 [D loss: 0.140209, acc.: 81.25%] [G loss: 0.684381]\n",
      "epoch:3 step:2869 [D loss: 0.168299, acc.: 78.91%] [G loss: 0.688836]\n",
      "epoch:3 step:2870 [D loss: 0.156235, acc.: 76.56%] [G loss: 0.728296]\n",
      "epoch:3 step:2871 [D loss: 0.163301, acc.: 77.34%] [G loss: 0.657730]\n",
      "epoch:3 step:2872 [D loss: 0.174368, acc.: 72.66%] [G loss: 0.658642]\n",
      "epoch:3 step:2873 [D loss: 0.186190, acc.: 75.78%] [G loss: 0.625880]\n",
      "epoch:3 step:2874 [D loss: 0.181758, acc.: 71.88%] [G loss: 0.654272]\n",
      "epoch:3 step:2875 [D loss: 0.135121, acc.: 82.03%] [G loss: 0.707447]\n",
      "epoch:3 step:2876 [D loss: 0.150923, acc.: 79.69%] [G loss: 0.652408]\n",
      "epoch:3 step:2877 [D loss: 0.168486, acc.: 75.78%] [G loss: 0.612785]\n",
      "epoch:3 step:2878 [D loss: 0.155291, acc.: 77.34%] [G loss: 0.646014]\n",
      "epoch:3 step:2879 [D loss: 0.157293, acc.: 79.69%] [G loss: 0.631652]\n",
      "epoch:3 step:2880 [D loss: 0.178043, acc.: 72.66%] [G loss: 0.670860]\n",
      "epoch:3 step:2881 [D loss: 0.150145, acc.: 83.59%] [G loss: 0.673673]\n",
      "epoch:3 step:2882 [D loss: 0.168588, acc.: 77.34%] [G loss: 0.627205]\n",
      "epoch:3 step:2883 [D loss: 0.135314, acc.: 82.81%] [G loss: 0.709010]\n",
      "epoch:3 step:2884 [D loss: 0.159486, acc.: 76.56%] [G loss: 0.722150]\n",
      "epoch:3 step:2885 [D loss: 0.178397, acc.: 75.00%] [G loss: 0.628109]\n",
      "epoch:3 step:2886 [D loss: 0.110624, acc.: 87.50%] [G loss: 0.698194]\n",
      "epoch:3 step:2887 [D loss: 0.165888, acc.: 75.00%] [G loss: 0.658934]\n",
      "epoch:3 step:2888 [D loss: 0.122950, acc.: 82.81%] [G loss: 0.709750]\n",
      "epoch:3 step:2889 [D loss: 0.218221, acc.: 67.97%] [G loss: 0.579391]\n",
      "epoch:3 step:2890 [D loss: 0.163729, acc.: 78.91%] [G loss: 0.586391]\n",
      "epoch:3 step:2891 [D loss: 0.166747, acc.: 71.09%] [G loss: 0.604718]\n",
      "epoch:3 step:2892 [D loss: 0.203335, acc.: 73.44%] [G loss: 0.630334]\n",
      "epoch:3 step:2893 [D loss: 0.129579, acc.: 78.91%] [G loss: 0.696543]\n",
      "epoch:3 step:2894 [D loss: 0.169972, acc.: 77.34%] [G loss: 0.630085]\n",
      "epoch:3 step:2895 [D loss: 0.170459, acc.: 75.00%] [G loss: 0.635940]\n",
      "epoch:3 step:2896 [D loss: 0.172432, acc.: 71.09%] [G loss: 0.629011]\n",
      "epoch:3 step:2897 [D loss: 0.167393, acc.: 78.91%] [G loss: 0.640384]\n",
      "epoch:3 step:2898 [D loss: 0.141936, acc.: 80.47%] [G loss: 0.684972]\n",
      "epoch:3 step:2899 [D loss: 0.150574, acc.: 78.91%] [G loss: 0.627811]\n",
      "epoch:3 step:2900 [D loss: 0.141165, acc.: 82.03%] [G loss: 0.690859]\n",
      "epoch:3 step:2901 [D loss: 0.151475, acc.: 82.81%] [G loss: 0.646750]\n",
      "epoch:3 step:2902 [D loss: 0.191279, acc.: 68.75%] [G loss: 0.632505]\n",
      "epoch:3 step:2903 [D loss: 0.172317, acc.: 75.78%] [G loss: 0.675088]\n",
      "epoch:3 step:2904 [D loss: 0.144569, acc.: 78.12%] [G loss: 0.696129]\n",
      "epoch:3 step:2905 [D loss: 0.184939, acc.: 75.00%] [G loss: 0.660307]\n",
      "epoch:3 step:2906 [D loss: 0.188215, acc.: 70.31%] [G loss: 0.653514]\n",
      "epoch:3 step:2907 [D loss: 0.108335, acc.: 89.06%] [G loss: 0.756199]\n",
      "epoch:3 step:2908 [D loss: 0.168520, acc.: 77.34%] [G loss: 0.682820]\n",
      "epoch:3 step:2909 [D loss: 0.178613, acc.: 71.09%] [G loss: 0.607231]\n",
      "epoch:3 step:2910 [D loss: 0.183369, acc.: 71.88%] [G loss: 0.645168]\n",
      "epoch:3 step:2911 [D loss: 0.152702, acc.: 78.12%] [G loss: 0.748007]\n",
      "epoch:3 step:2912 [D loss: 0.196021, acc.: 70.31%] [G loss: 0.610415]\n",
      "epoch:3 step:2913 [D loss: 0.224213, acc.: 67.19%] [G loss: 0.575325]\n",
      "epoch:3 step:2914 [D loss: 0.130223, acc.: 85.94%] [G loss: 0.652874]\n",
      "epoch:3 step:2915 [D loss: 0.161220, acc.: 79.69%] [G loss: 0.598110]\n",
      "epoch:3 step:2916 [D loss: 0.165806, acc.: 74.22%] [G loss: 0.627114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2917 [D loss: 0.180353, acc.: 71.09%] [G loss: 0.628812]\n",
      "epoch:3 step:2918 [D loss: 0.225214, acc.: 64.06%] [G loss: 0.656274]\n",
      "epoch:3 step:2919 [D loss: 0.227480, acc.: 64.06%] [G loss: 0.598846]\n",
      "epoch:3 step:2920 [D loss: 0.228593, acc.: 62.50%] [G loss: 0.589349]\n",
      "epoch:3 step:2921 [D loss: 0.183463, acc.: 70.31%] [G loss: 0.562680]\n",
      "epoch:3 step:2922 [D loss: 0.163148, acc.: 78.12%] [G loss: 0.665812]\n",
      "epoch:3 step:2923 [D loss: 0.149628, acc.: 81.25%] [G loss: 0.711923]\n",
      "epoch:3 step:2924 [D loss: 0.240197, acc.: 60.94%] [G loss: 0.564325]\n",
      "epoch:3 step:2925 [D loss: 0.198880, acc.: 71.88%] [G loss: 0.606436]\n",
      "epoch:3 step:2926 [D loss: 0.216472, acc.: 67.97%] [G loss: 0.666463]\n",
      "epoch:3 step:2927 [D loss: 0.212804, acc.: 65.62%] [G loss: 0.626137]\n",
      "epoch:3 step:2928 [D loss: 0.133135, acc.: 87.50%] [G loss: 0.689877]\n",
      "epoch:3 step:2929 [D loss: 0.191239, acc.: 72.66%] [G loss: 0.596544]\n",
      "epoch:3 step:2930 [D loss: 0.122301, acc.: 86.72%] [G loss: 0.787725]\n",
      "epoch:3 step:2931 [D loss: 0.288370, acc.: 61.72%] [G loss: 0.553371]\n",
      "epoch:3 step:2932 [D loss: 0.182379, acc.: 71.09%] [G loss: 0.568490]\n",
      "epoch:3 step:2933 [D loss: 0.159042, acc.: 76.56%] [G loss: 0.667420]\n",
      "epoch:3 step:2934 [D loss: 0.165251, acc.: 82.03%] [G loss: 0.625123]\n",
      "epoch:3 step:2935 [D loss: 0.179640, acc.: 73.44%] [G loss: 0.622006]\n",
      "epoch:3 step:2936 [D loss: 0.194196, acc.: 71.88%] [G loss: 0.622558]\n",
      "epoch:3 step:2937 [D loss: 0.197045, acc.: 74.22%] [G loss: 0.648744]\n",
      "epoch:3 step:2938 [D loss: 0.185344, acc.: 73.44%] [G loss: 0.622839]\n",
      "epoch:3 step:2939 [D loss: 0.185583, acc.: 72.66%] [G loss: 0.568809]\n",
      "epoch:3 step:2940 [D loss: 0.213221, acc.: 63.28%] [G loss: 0.539389]\n",
      "epoch:3 step:2941 [D loss: 0.154651, acc.: 80.47%] [G loss: 0.671272]\n",
      "epoch:3 step:2942 [D loss: 0.160357, acc.: 78.91%] [G loss: 0.603863]\n",
      "epoch:3 step:2943 [D loss: 0.174260, acc.: 77.34%] [G loss: 0.645429]\n",
      "epoch:3 step:2944 [D loss: 0.201686, acc.: 67.97%] [G loss: 0.571616]\n",
      "epoch:3 step:2945 [D loss: 0.176128, acc.: 79.69%] [G loss: 0.613147]\n",
      "epoch:3 step:2946 [D loss: 0.156064, acc.: 73.44%] [G loss: 0.724868]\n",
      "epoch:3 step:2947 [D loss: 0.206310, acc.: 67.97%] [G loss: 0.591209]\n",
      "epoch:3 step:2948 [D loss: 0.184464, acc.: 71.88%] [G loss: 0.602165]\n",
      "epoch:3 step:2949 [D loss: 0.168974, acc.: 72.66%] [G loss: 0.557688]\n",
      "epoch:3 step:2950 [D loss: 0.164201, acc.: 74.22%] [G loss: 0.650483]\n",
      "epoch:3 step:2951 [D loss: 0.154971, acc.: 76.56%] [G loss: 0.647457]\n",
      "epoch:3 step:2952 [D loss: 0.158563, acc.: 78.12%] [G loss: 0.617890]\n",
      "epoch:3 step:2953 [D loss: 0.174965, acc.: 73.44%] [G loss: 0.617895]\n",
      "epoch:3 step:2954 [D loss: 0.185336, acc.: 68.75%] [G loss: 0.588039]\n",
      "epoch:3 step:2955 [D loss: 0.161784, acc.: 75.78%] [G loss: 0.637524]\n",
      "epoch:3 step:2956 [D loss: 0.184193, acc.: 71.09%] [G loss: 0.609627]\n",
      "epoch:3 step:2957 [D loss: 0.181317, acc.: 74.22%] [G loss: 0.637720]\n",
      "epoch:3 step:2958 [D loss: 0.173575, acc.: 76.56%] [G loss: 0.605173]\n",
      "epoch:3 step:2959 [D loss: 0.180193, acc.: 75.78%] [G loss: 0.587524]\n",
      "epoch:3 step:2960 [D loss: 0.153754, acc.: 78.12%] [G loss: 0.670201]\n",
      "epoch:3 step:2961 [D loss: 0.195423, acc.: 73.44%] [G loss: 0.599343]\n",
      "epoch:3 step:2962 [D loss: 0.133977, acc.: 81.25%] [G loss: 0.655804]\n",
      "epoch:3 step:2963 [D loss: 0.158434, acc.: 78.12%] [G loss: 0.639337]\n",
      "epoch:3 step:2964 [D loss: 0.204442, acc.: 71.09%] [G loss: 0.580056]\n",
      "epoch:3 step:2965 [D loss: 0.189026, acc.: 74.22%] [G loss: 0.658096]\n",
      "epoch:3 step:2966 [D loss: 0.133243, acc.: 85.94%] [G loss: 0.717231]\n",
      "epoch:3 step:2967 [D loss: 0.182031, acc.: 75.78%] [G loss: 0.640678]\n",
      "epoch:3 step:2968 [D loss: 0.158305, acc.: 80.47%] [G loss: 0.621614]\n",
      "epoch:3 step:2969 [D loss: 0.183578, acc.: 71.88%] [G loss: 0.602619]\n",
      "epoch:3 step:2970 [D loss: 0.158025, acc.: 75.78%] [G loss: 0.666982]\n",
      "epoch:3 step:2971 [D loss: 0.196725, acc.: 71.88%] [G loss: 0.594630]\n",
      "epoch:3 step:2972 [D loss: 0.198459, acc.: 68.75%] [G loss: 0.629320]\n",
      "epoch:3 step:2973 [D loss: 0.165237, acc.: 78.12%] [G loss: 0.725927]\n",
      "epoch:3 step:2974 [D loss: 0.179073, acc.: 72.66%] [G loss: 0.629428]\n",
      "epoch:3 step:2975 [D loss: 0.147538, acc.: 85.16%] [G loss: 0.660334]\n",
      "epoch:3 step:2976 [D loss: 0.161277, acc.: 78.91%] [G loss: 0.640116]\n",
      "epoch:3 step:2977 [D loss: 0.156388, acc.: 82.03%] [G loss: 0.630854]\n",
      "epoch:3 step:2978 [D loss: 0.140296, acc.: 83.59%] [G loss: 0.645848]\n",
      "epoch:3 step:2979 [D loss: 0.159743, acc.: 80.47%] [G loss: 0.657503]\n",
      "epoch:3 step:2980 [D loss: 0.163114, acc.: 76.56%] [G loss: 0.632990]\n",
      "epoch:3 step:2981 [D loss: 0.155006, acc.: 83.59%] [G loss: 0.612303]\n",
      "epoch:3 step:2982 [D loss: 0.150232, acc.: 79.69%] [G loss: 0.679737]\n",
      "epoch:3 step:2983 [D loss: 0.147836, acc.: 84.38%] [G loss: 0.679928]\n",
      "epoch:3 step:2984 [D loss: 0.163325, acc.: 78.91%] [G loss: 0.639057]\n",
      "epoch:3 step:2985 [D loss: 0.179692, acc.: 72.66%] [G loss: 0.625865]\n",
      "epoch:3 step:2986 [D loss: 0.154887, acc.: 77.34%] [G loss: 0.628126]\n",
      "epoch:3 step:2987 [D loss: 0.180652, acc.: 74.22%] [G loss: 0.631550]\n",
      "epoch:3 step:2988 [D loss: 0.149521, acc.: 81.25%] [G loss: 0.658841]\n",
      "epoch:3 step:2989 [D loss: 0.143388, acc.: 85.94%] [G loss: 0.634979]\n",
      "epoch:3 step:2990 [D loss: 0.173474, acc.: 75.00%] [G loss: 0.657326]\n",
      "epoch:3 step:2991 [D loss: 0.188329, acc.: 74.22%] [G loss: 0.622669]\n",
      "epoch:3 step:2992 [D loss: 0.145524, acc.: 82.03%] [G loss: 0.610053]\n",
      "epoch:3 step:2993 [D loss: 0.188059, acc.: 71.09%] [G loss: 0.608193]\n",
      "epoch:3 step:2994 [D loss: 0.171180, acc.: 77.34%] [G loss: 0.657325]\n",
      "epoch:3 step:2995 [D loss: 0.194398, acc.: 68.75%] [G loss: 0.608698]\n",
      "epoch:3 step:2996 [D loss: 0.195168, acc.: 71.88%] [G loss: 0.592658]\n",
      "epoch:3 step:2997 [D loss: 0.195108, acc.: 71.88%] [G loss: 0.634565]\n",
      "epoch:3 step:2998 [D loss: 0.186237, acc.: 74.22%] [G loss: 0.667224]\n",
      "epoch:3 step:2999 [D loss: 0.155989, acc.: 79.69%] [G loss: 0.642871]\n",
      "epoch:3 step:3000 [D loss: 0.166325, acc.: 78.12%] [G loss: 0.661090]\n",
      "epoch:3 step:3001 [D loss: 0.132971, acc.: 80.47%] [G loss: 0.680778]\n",
      "epoch:3 step:3002 [D loss: 0.149999, acc.: 78.12%] [G loss: 0.666247]\n",
      "epoch:3 step:3003 [D loss: 0.158019, acc.: 75.00%] [G loss: 0.671018]\n",
      "epoch:3 step:3004 [D loss: 0.188614, acc.: 70.31%] [G loss: 0.670198]\n",
      "epoch:3 step:3005 [D loss: 0.148510, acc.: 82.03%] [G loss: 0.594099]\n",
      "epoch:3 step:3006 [D loss: 0.180219, acc.: 71.09%] [G loss: 0.718982]\n",
      "epoch:3 step:3007 [D loss: 0.198947, acc.: 70.31%] [G loss: 0.630574]\n",
      "epoch:3 step:3008 [D loss: 0.185010, acc.: 71.09%] [G loss: 0.621424]\n",
      "epoch:3 step:3009 [D loss: 0.123735, acc.: 85.94%] [G loss: 0.742603]\n",
      "epoch:3 step:3010 [D loss: 0.190692, acc.: 72.66%] [G loss: 0.631143]\n",
      "epoch:3 step:3011 [D loss: 0.222068, acc.: 64.84%] [G loss: 0.589412]\n",
      "epoch:3 step:3012 [D loss: 0.164093, acc.: 78.12%] [G loss: 0.623835]\n",
      "epoch:3 step:3013 [D loss: 0.191982, acc.: 70.31%] [G loss: 0.655800]\n",
      "epoch:3 step:3014 [D loss: 0.214357, acc.: 67.19%] [G loss: 0.617899]\n",
      "epoch:3 step:3015 [D loss: 0.141956, acc.: 82.81%] [G loss: 0.705737]\n",
      "epoch:3 step:3016 [D loss: 0.172921, acc.: 75.78%] [G loss: 0.693509]\n",
      "epoch:3 step:3017 [D loss: 0.174364, acc.: 76.56%] [G loss: 0.660917]\n",
      "epoch:3 step:3018 [D loss: 0.131160, acc.: 81.25%] [G loss: 0.724848]\n",
      "epoch:3 step:3019 [D loss: 0.157216, acc.: 78.12%] [G loss: 0.661952]\n",
      "epoch:3 step:3020 [D loss: 0.161212, acc.: 79.69%] [G loss: 0.651380]\n",
      "epoch:3 step:3021 [D loss: 0.179467, acc.: 73.44%] [G loss: 0.610524]\n",
      "epoch:3 step:3022 [D loss: 0.174902, acc.: 75.00%] [G loss: 0.640785]\n",
      "epoch:3 step:3023 [D loss: 0.147214, acc.: 78.12%] [G loss: 0.696476]\n",
      "epoch:3 step:3024 [D loss: 0.192527, acc.: 68.75%] [G loss: 0.629225]\n",
      "epoch:3 step:3025 [D loss: 0.225875, acc.: 61.72%] [G loss: 0.562609]\n",
      "epoch:3 step:3026 [D loss: 0.188944, acc.: 72.66%] [G loss: 0.629160]\n",
      "epoch:3 step:3027 [D loss: 0.143724, acc.: 80.47%] [G loss: 0.658122]\n",
      "epoch:3 step:3028 [D loss: 0.151910, acc.: 78.91%] [G loss: 0.615113]\n",
      "epoch:3 step:3029 [D loss: 0.149398, acc.: 82.81%] [G loss: 0.642139]\n",
      "epoch:3 step:3030 [D loss: 0.174046, acc.: 72.66%] [G loss: 0.656696]\n",
      "epoch:3 step:3031 [D loss: 0.209811, acc.: 67.19%] [G loss: 0.608132]\n",
      "epoch:3 step:3032 [D loss: 0.163573, acc.: 78.91%] [G loss: 0.663723]\n",
      "epoch:3 step:3033 [D loss: 0.151757, acc.: 77.34%] [G loss: 0.700581]\n",
      "epoch:3 step:3034 [D loss: 0.146384, acc.: 83.59%] [G loss: 0.649781]\n",
      "epoch:3 step:3035 [D loss: 0.158126, acc.: 79.69%] [G loss: 0.651251]\n",
      "epoch:3 step:3036 [D loss: 0.217364, acc.: 65.62%] [G loss: 0.607122]\n",
      "epoch:3 step:3037 [D loss: 0.198289, acc.: 67.97%] [G loss: 0.565304]\n",
      "epoch:3 step:3038 [D loss: 0.172578, acc.: 73.44%] [G loss: 0.573447]\n",
      "epoch:3 step:3039 [D loss: 0.198797, acc.: 69.53%] [G loss: 0.567338]\n",
      "epoch:3 step:3040 [D loss: 0.161991, acc.: 79.69%] [G loss: 0.642670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3041 [D loss: 0.164259, acc.: 77.34%] [G loss: 0.617476]\n",
      "epoch:3 step:3042 [D loss: 0.111951, acc.: 89.06%] [G loss: 0.790336]\n",
      "epoch:3 step:3043 [D loss: 0.136118, acc.: 78.91%] [G loss: 0.736040]\n",
      "epoch:3 step:3044 [D loss: 0.203063, acc.: 69.53%] [G loss: 0.557555]\n",
      "epoch:3 step:3045 [D loss: 0.167556, acc.: 76.56%] [G loss: 0.613196]\n",
      "epoch:3 step:3046 [D loss: 0.167508, acc.: 75.78%] [G loss: 0.620129]\n",
      "epoch:3 step:3047 [D loss: 0.175580, acc.: 73.44%] [G loss: 0.645195]\n",
      "epoch:3 step:3048 [D loss: 0.184699, acc.: 76.56%] [G loss: 0.699971]\n",
      "epoch:3 step:3049 [D loss: 0.166910, acc.: 79.69%] [G loss: 0.593512]\n",
      "epoch:3 step:3050 [D loss: 0.168751, acc.: 71.88%] [G loss: 0.611049]\n",
      "epoch:3 step:3051 [D loss: 0.154712, acc.: 79.69%] [G loss: 0.667970]\n",
      "epoch:3 step:3052 [D loss: 0.209979, acc.: 67.19%] [G loss: 0.591994]\n",
      "epoch:3 step:3053 [D loss: 0.171295, acc.: 77.34%] [G loss: 0.640531]\n",
      "epoch:3 step:3054 [D loss: 0.163710, acc.: 75.78%] [G loss: 0.640575]\n",
      "epoch:3 step:3055 [D loss: 0.138529, acc.: 84.38%] [G loss: 0.645179]\n",
      "epoch:3 step:3056 [D loss: 0.144444, acc.: 81.25%] [G loss: 0.624996]\n",
      "epoch:3 step:3057 [D loss: 0.214280, acc.: 68.75%] [G loss: 0.614839]\n",
      "epoch:3 step:3058 [D loss: 0.228363, acc.: 63.28%] [G loss: 0.628219]\n",
      "epoch:3 step:3059 [D loss: 0.156011, acc.: 78.91%] [G loss: 0.635061]\n",
      "epoch:3 step:3060 [D loss: 0.162908, acc.: 76.56%] [G loss: 0.589112]\n",
      "epoch:3 step:3061 [D loss: 0.182336, acc.: 73.44%] [G loss: 0.601150]\n",
      "epoch:3 step:3062 [D loss: 0.157079, acc.: 78.12%] [G loss: 0.651987]\n",
      "epoch:3 step:3063 [D loss: 0.187364, acc.: 79.69%] [G loss: 0.668108]\n",
      "epoch:3 step:3064 [D loss: 0.156419, acc.: 76.56%] [G loss: 0.614624]\n",
      "epoch:3 step:3065 [D loss: 0.147596, acc.: 81.25%] [G loss: 0.667907]\n",
      "epoch:3 step:3066 [D loss: 0.152590, acc.: 79.69%] [G loss: 0.686596]\n",
      "epoch:3 step:3067 [D loss: 0.153795, acc.: 78.91%] [G loss: 0.661737]\n",
      "epoch:3 step:3068 [D loss: 0.171834, acc.: 72.66%] [G loss: 0.623256]\n",
      "epoch:3 step:3069 [D loss: 0.148959, acc.: 85.94%] [G loss: 0.688952]\n",
      "epoch:3 step:3070 [D loss: 0.152667, acc.: 78.12%] [G loss: 0.664346]\n",
      "epoch:3 step:3071 [D loss: 0.157796, acc.: 78.12%] [G loss: 0.584667]\n",
      "epoch:3 step:3072 [D loss: 0.200954, acc.: 68.75%] [G loss: 0.597421]\n",
      "epoch:3 step:3073 [D loss: 0.179647, acc.: 75.00%] [G loss: 0.667226]\n",
      "epoch:3 step:3074 [D loss: 0.185866, acc.: 74.22%] [G loss: 0.639779]\n",
      "epoch:3 step:3075 [D loss: 0.139501, acc.: 82.81%] [G loss: 0.664846]\n",
      "epoch:3 step:3076 [D loss: 0.208732, acc.: 68.75%] [G loss: 0.563019]\n",
      "epoch:3 step:3077 [D loss: 0.170585, acc.: 76.56%] [G loss: 0.664072]\n",
      "epoch:3 step:3078 [D loss: 0.174865, acc.: 73.44%] [G loss: 0.636070]\n",
      "epoch:3 step:3079 [D loss: 0.149583, acc.: 83.59%] [G loss: 0.652482]\n",
      "epoch:3 step:3080 [D loss: 0.183706, acc.: 70.31%] [G loss: 0.675035]\n",
      "epoch:3 step:3081 [D loss: 0.168468, acc.: 77.34%] [G loss: 0.641669]\n",
      "epoch:3 step:3082 [D loss: 0.135376, acc.: 82.81%] [G loss: 0.701784]\n",
      "epoch:3 step:3083 [D loss: 0.210530, acc.: 67.97%] [G loss: 0.570197]\n",
      "epoch:3 step:3084 [D loss: 0.145080, acc.: 82.81%] [G loss: 0.665515]\n",
      "epoch:3 step:3085 [D loss: 0.173183, acc.: 73.44%] [G loss: 0.681644]\n",
      "epoch:3 step:3086 [D loss: 0.217298, acc.: 67.19%] [G loss: 0.583168]\n",
      "epoch:3 step:3087 [D loss: 0.214639, acc.: 68.75%] [G loss: 0.620417]\n",
      "epoch:3 step:3088 [D loss: 0.201939, acc.: 70.31%] [G loss: 0.572494]\n",
      "epoch:3 step:3089 [D loss: 0.180105, acc.: 68.75%] [G loss: 0.674852]\n",
      "epoch:3 step:3090 [D loss: 0.204557, acc.: 65.62%] [G loss: 0.624738]\n",
      "epoch:3 step:3091 [D loss: 0.169466, acc.: 73.44%] [G loss: 0.650667]\n",
      "epoch:3 step:3092 [D loss: 0.168687, acc.: 75.00%] [G loss: 0.616440]\n",
      "epoch:3 step:3093 [D loss: 0.217406, acc.: 67.19%] [G loss: 0.560070]\n",
      "epoch:3 step:3094 [D loss: 0.143145, acc.: 78.12%] [G loss: 0.661726]\n",
      "epoch:3 step:3095 [D loss: 0.142484, acc.: 79.69%] [G loss: 0.684839]\n",
      "epoch:3 step:3096 [D loss: 0.151413, acc.: 81.25%] [G loss: 0.675341]\n",
      "epoch:3 step:3097 [D loss: 0.172556, acc.: 76.56%] [G loss: 0.607237]\n",
      "epoch:3 step:3098 [D loss: 0.136735, acc.: 84.38%] [G loss: 0.650599]\n",
      "epoch:3 step:3099 [D loss: 0.217964, acc.: 65.62%] [G loss: 0.553282]\n",
      "epoch:3 step:3100 [D loss: 0.160358, acc.: 76.56%] [G loss: 0.688978]\n",
      "epoch:3 step:3101 [D loss: 0.142550, acc.: 84.38%] [G loss: 0.679580]\n",
      "epoch:3 step:3102 [D loss: 0.190862, acc.: 67.97%] [G loss: 0.630872]\n",
      "epoch:3 step:3103 [D loss: 0.218992, acc.: 67.19%] [G loss: 0.565703]\n",
      "epoch:3 step:3104 [D loss: 0.150529, acc.: 82.03%] [G loss: 0.724128]\n",
      "epoch:3 step:3105 [D loss: 0.191034, acc.: 69.53%] [G loss: 0.587750]\n",
      "epoch:3 step:3106 [D loss: 0.175004, acc.: 77.34%] [G loss: 0.671872]\n",
      "epoch:3 step:3107 [D loss: 0.140382, acc.: 78.91%] [G loss: 0.671745]\n",
      "epoch:3 step:3108 [D loss: 0.196326, acc.: 71.09%] [G loss: 0.653651]\n",
      "epoch:3 step:3109 [D loss: 0.174023, acc.: 75.78%] [G loss: 0.645638]\n",
      "epoch:3 step:3110 [D loss: 0.173741, acc.: 78.12%] [G loss: 0.597953]\n",
      "epoch:3 step:3111 [D loss: 0.179015, acc.: 74.22%] [G loss: 0.646923]\n",
      "epoch:3 step:3112 [D loss: 0.212030, acc.: 68.75%] [G loss: 0.612338]\n",
      "epoch:3 step:3113 [D loss: 0.140436, acc.: 81.25%] [G loss: 0.639364]\n",
      "epoch:3 step:3114 [D loss: 0.191259, acc.: 73.44%] [G loss: 0.638895]\n",
      "epoch:3 step:3115 [D loss: 0.138547, acc.: 80.47%] [G loss: 0.676241]\n",
      "epoch:3 step:3116 [D loss: 0.153169, acc.: 77.34%] [G loss: 0.661613]\n",
      "epoch:3 step:3117 [D loss: 0.185817, acc.: 76.56%] [G loss: 0.715752]\n",
      "epoch:3 step:3118 [D loss: 0.162287, acc.: 79.69%] [G loss: 0.659215]\n",
      "epoch:3 step:3119 [D loss: 0.171601, acc.: 72.66%] [G loss: 0.671916]\n",
      "epoch:3 step:3120 [D loss: 0.155400, acc.: 77.34%] [G loss: 0.614630]\n",
      "epoch:3 step:3121 [D loss: 0.142366, acc.: 76.56%] [G loss: 0.702321]\n",
      "epoch:3 step:3122 [D loss: 0.149302, acc.: 81.25%] [G loss: 0.653547]\n",
      "epoch:3 step:3123 [D loss: 0.101949, acc.: 86.72%] [G loss: 0.774480]\n",
      "epoch:3 step:3124 [D loss: 0.154274, acc.: 75.78%] [G loss: 0.695786]\n",
      "epoch:3 step:3125 [D loss: 0.124635, acc.: 87.50%] [G loss: 0.746505]\n",
      "epoch:3 step:3126 [D loss: 0.134847, acc.: 84.38%] [G loss: 0.693367]\n",
      "epoch:3 step:3127 [D loss: 0.226220, acc.: 66.41%] [G loss: 0.536579]\n",
      "epoch:3 step:3128 [D loss: 0.182488, acc.: 71.88%] [G loss: 0.590073]\n",
      "epoch:3 step:3129 [D loss: 0.156037, acc.: 80.47%] [G loss: 0.654510]\n",
      "epoch:3 step:3130 [D loss: 0.153285, acc.: 79.69%] [G loss: 0.705118]\n",
      "epoch:3 step:3131 [D loss: 0.151185, acc.: 81.25%] [G loss: 0.655822]\n",
      "epoch:3 step:3132 [D loss: 0.135327, acc.: 82.03%] [G loss: 0.682661]\n",
      "epoch:3 step:3133 [D loss: 0.130618, acc.: 84.38%] [G loss: 0.714006]\n",
      "epoch:3 step:3134 [D loss: 0.185690, acc.: 77.34%] [G loss: 0.569183]\n",
      "epoch:3 step:3135 [D loss: 0.172249, acc.: 73.44%] [G loss: 0.644228]\n",
      "epoch:3 step:3136 [D loss: 0.132754, acc.: 83.59%] [G loss: 0.681328]\n",
      "epoch:3 step:3137 [D loss: 0.155169, acc.: 82.03%] [G loss: 0.621421]\n",
      "epoch:3 step:3138 [D loss: 0.168645, acc.: 75.78%] [G loss: 0.618206]\n",
      "epoch:3 step:3139 [D loss: 0.180339, acc.: 74.22%] [G loss: 0.616592]\n",
      "epoch:3 step:3140 [D loss: 0.152636, acc.: 78.91%] [G loss: 0.689713]\n",
      "epoch:3 step:3141 [D loss: 0.143442, acc.: 81.25%] [G loss: 0.644259]\n",
      "epoch:3 step:3142 [D loss: 0.119080, acc.: 86.72%] [G loss: 0.702466]\n",
      "epoch:3 step:3143 [D loss: 0.155150, acc.: 76.56%] [G loss: 0.649050]\n",
      "epoch:3 step:3144 [D loss: 0.153074, acc.: 81.25%] [G loss: 0.708154]\n",
      "epoch:3 step:3145 [D loss: 0.198016, acc.: 72.66%] [G loss: 0.613474]\n",
      "epoch:3 step:3146 [D loss: 0.149350, acc.: 77.34%] [G loss: 0.652170]\n",
      "epoch:3 step:3147 [D loss: 0.132743, acc.: 83.59%] [G loss: 0.773046]\n",
      "epoch:3 step:3148 [D loss: 0.147821, acc.: 75.78%] [G loss: 0.720759]\n",
      "epoch:3 step:3149 [D loss: 0.174173, acc.: 76.56%] [G loss: 0.677540]\n",
      "epoch:3 step:3150 [D loss: 0.119060, acc.: 85.16%] [G loss: 0.777766]\n",
      "epoch:3 step:3151 [D loss: 0.187718, acc.: 73.44%] [G loss: 0.686363]\n",
      "epoch:3 step:3152 [D loss: 0.178211, acc.: 80.47%] [G loss: 0.640630]\n",
      "epoch:3 step:3153 [D loss: 0.146081, acc.: 78.12%] [G loss: 0.688902]\n",
      "epoch:3 step:3154 [D loss: 0.130999, acc.: 82.81%] [G loss: 0.764630]\n",
      "epoch:3 step:3155 [D loss: 0.140270, acc.: 84.38%] [G loss: 0.709103]\n",
      "epoch:3 step:3156 [D loss: 0.139432, acc.: 83.59%] [G loss: 0.662991]\n",
      "epoch:3 step:3157 [D loss: 0.153912, acc.: 75.78%] [G loss: 0.676011]\n",
      "epoch:3 step:3158 [D loss: 0.135746, acc.: 82.03%] [G loss: 0.752582]\n",
      "epoch:3 step:3159 [D loss: 0.200692, acc.: 71.88%] [G loss: 0.609714]\n",
      "epoch:3 step:3160 [D loss: 0.208499, acc.: 71.09%] [G loss: 0.539086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3161 [D loss: 0.123380, acc.: 85.16%] [G loss: 0.682201]\n",
      "epoch:3 step:3162 [D loss: 0.166672, acc.: 78.12%] [G loss: 0.652579]\n",
      "epoch:3 step:3163 [D loss: 0.195813, acc.: 71.88%] [G loss: 0.654897]\n",
      "epoch:3 step:3164 [D loss: 0.141040, acc.: 82.03%] [G loss: 0.705595]\n",
      "epoch:3 step:3165 [D loss: 0.130673, acc.: 82.03%] [G loss: 0.726411]\n",
      "epoch:3 step:3166 [D loss: 0.164529, acc.: 75.78%] [G loss: 0.705230]\n",
      "epoch:3 step:3167 [D loss: 0.216269, acc.: 66.41%] [G loss: 0.598417]\n",
      "epoch:3 step:3168 [D loss: 0.146101, acc.: 82.03%] [G loss: 0.650257]\n",
      "epoch:3 step:3169 [D loss: 0.155499, acc.: 80.47%] [G loss: 0.687059]\n",
      "epoch:3 step:3170 [D loss: 0.157971, acc.: 81.25%] [G loss: 0.690291]\n",
      "epoch:3 step:3171 [D loss: 0.182037, acc.: 75.78%] [G loss: 0.680871]\n",
      "epoch:3 step:3172 [D loss: 0.150963, acc.: 78.91%] [G loss: 0.659833]\n",
      "epoch:3 step:3173 [D loss: 0.173233, acc.: 78.91%] [G loss: 0.650200]\n",
      "epoch:3 step:3174 [D loss: 0.155941, acc.: 82.03%] [G loss: 0.700034]\n",
      "epoch:3 step:3175 [D loss: 0.157566, acc.: 78.91%] [G loss: 0.672839]\n",
      "epoch:3 step:3176 [D loss: 0.149570, acc.: 80.47%] [G loss: 0.685684]\n",
      "epoch:3 step:3177 [D loss: 0.131931, acc.: 78.91%] [G loss: 0.709219]\n",
      "epoch:3 step:3178 [D loss: 0.187327, acc.: 71.09%] [G loss: 0.620045]\n",
      "epoch:3 step:3179 [D loss: 0.189962, acc.: 69.53%] [G loss: 0.664395]\n",
      "epoch:3 step:3180 [D loss: 0.180965, acc.: 68.75%] [G loss: 0.646577]\n",
      "epoch:3 step:3181 [D loss: 0.177752, acc.: 72.66%] [G loss: 0.663116]\n",
      "epoch:3 step:3182 [D loss: 0.206771, acc.: 69.53%] [G loss: 0.623775]\n",
      "epoch:3 step:3183 [D loss: 0.142098, acc.: 75.78%] [G loss: 0.668579]\n",
      "epoch:3 step:3184 [D loss: 0.196972, acc.: 69.53%] [G loss: 0.631150]\n",
      "epoch:3 step:3185 [D loss: 0.128216, acc.: 85.16%] [G loss: 0.680969]\n",
      "epoch:3 step:3186 [D loss: 0.155889, acc.: 81.25%] [G loss: 0.617941]\n",
      "epoch:3 step:3187 [D loss: 0.219980, acc.: 64.06%] [G loss: 0.567241]\n",
      "epoch:3 step:3188 [D loss: 0.198357, acc.: 78.12%] [G loss: 0.633068]\n",
      "epoch:3 step:3189 [D loss: 0.166863, acc.: 74.22%] [G loss: 0.667239]\n",
      "epoch:3 step:3190 [D loss: 0.170642, acc.: 76.56%] [G loss: 0.696801]\n",
      "epoch:3 step:3191 [D loss: 0.146996, acc.: 85.16%] [G loss: 0.633448]\n",
      "epoch:3 step:3192 [D loss: 0.139292, acc.: 81.25%] [G loss: 0.699140]\n",
      "epoch:3 step:3193 [D loss: 0.153645, acc.: 81.25%] [G loss: 0.677296]\n",
      "epoch:3 step:3194 [D loss: 0.163871, acc.: 78.12%] [G loss: 0.601025]\n",
      "epoch:3 step:3195 [D loss: 0.164373, acc.: 73.44%] [G loss: 0.640601]\n",
      "epoch:3 step:3196 [D loss: 0.149611, acc.: 78.91%] [G loss: 0.690498]\n",
      "epoch:3 step:3197 [D loss: 0.209477, acc.: 67.19%] [G loss: 0.607955]\n",
      "epoch:3 step:3198 [D loss: 0.174351, acc.: 78.12%] [G loss: 0.593202]\n",
      "epoch:3 step:3199 [D loss: 0.175613, acc.: 76.56%] [G loss: 0.631689]\n",
      "epoch:3 step:3200 [D loss: 0.177244, acc.: 75.78%] [G loss: 0.662940]\n",
      "epoch:3 step:3201 [D loss: 0.197499, acc.: 69.53%] [G loss: 0.562167]\n",
      "epoch:3 step:3202 [D loss: 0.159325, acc.: 75.78%] [G loss: 0.605461]\n",
      "epoch:3 step:3203 [D loss: 0.165669, acc.: 75.78%] [G loss: 0.662251]\n",
      "epoch:3 step:3204 [D loss: 0.149467, acc.: 78.91%] [G loss: 0.611079]\n",
      "epoch:3 step:3205 [D loss: 0.150094, acc.: 83.59%] [G loss: 0.621913]\n",
      "epoch:3 step:3206 [D loss: 0.192442, acc.: 73.44%] [G loss: 0.640830]\n",
      "epoch:3 step:3207 [D loss: 0.189283, acc.: 75.00%] [G loss: 0.564615]\n",
      "epoch:3 step:3208 [D loss: 0.112855, acc.: 82.81%] [G loss: 0.700355]\n",
      "epoch:3 step:3209 [D loss: 0.174270, acc.: 75.78%] [G loss: 0.722100]\n",
      "epoch:3 step:3210 [D loss: 0.128017, acc.: 82.81%] [G loss: 0.778263]\n",
      "epoch:3 step:3211 [D loss: 0.204087, acc.: 67.97%] [G loss: 0.620439]\n",
      "epoch:3 step:3212 [D loss: 0.162059, acc.: 76.56%] [G loss: 0.683264]\n",
      "epoch:3 step:3213 [D loss: 0.164971, acc.: 74.22%] [G loss: 0.646210]\n",
      "epoch:3 step:3214 [D loss: 0.195487, acc.: 72.66%] [G loss: 0.626736]\n",
      "epoch:3 step:3215 [D loss: 0.214788, acc.: 64.06%] [G loss: 0.607141]\n",
      "epoch:3 step:3216 [D loss: 0.163592, acc.: 75.78%] [G loss: 0.676575]\n",
      "epoch:3 step:3217 [D loss: 0.190258, acc.: 73.44%] [G loss: 0.636403]\n",
      "epoch:3 step:3218 [D loss: 0.194975, acc.: 68.75%] [G loss: 0.622812]\n",
      "epoch:3 step:3219 [D loss: 0.151972, acc.: 82.03%] [G loss: 0.679756]\n",
      "epoch:3 step:3220 [D loss: 0.138189, acc.: 81.25%] [G loss: 0.690595]\n",
      "epoch:3 step:3221 [D loss: 0.164692, acc.: 79.69%] [G loss: 0.583566]\n",
      "epoch:3 step:3222 [D loss: 0.170934, acc.: 75.00%] [G loss: 0.559449]\n",
      "epoch:3 step:3223 [D loss: 0.178842, acc.: 75.00%] [G loss: 0.627597]\n",
      "epoch:3 step:3224 [D loss: 0.184987, acc.: 73.44%] [G loss: 0.612208]\n",
      "epoch:3 step:3225 [D loss: 0.184900, acc.: 72.66%] [G loss: 0.568437]\n",
      "epoch:3 step:3226 [D loss: 0.142081, acc.: 82.81%] [G loss: 0.667634]\n",
      "epoch:3 step:3227 [D loss: 0.162796, acc.: 77.34%] [G loss: 0.684485]\n",
      "epoch:3 step:3228 [D loss: 0.204057, acc.: 63.28%] [G loss: 0.644251]\n",
      "epoch:3 step:3229 [D loss: 0.179394, acc.: 74.22%] [G loss: 0.632823]\n",
      "epoch:3 step:3230 [D loss: 0.164548, acc.: 72.66%] [G loss: 0.619649]\n",
      "epoch:3 step:3231 [D loss: 0.174558, acc.: 73.44%] [G loss: 0.612962]\n",
      "epoch:3 step:3232 [D loss: 0.190564, acc.: 75.78%] [G loss: 0.555542]\n",
      "epoch:3 step:3233 [D loss: 0.209191, acc.: 65.62%] [G loss: 0.580991]\n",
      "epoch:3 step:3234 [D loss: 0.165004, acc.: 78.12%] [G loss: 0.623784]\n",
      "epoch:3 step:3235 [D loss: 0.189671, acc.: 77.34%] [G loss: 0.605612]\n",
      "epoch:3 step:3236 [D loss: 0.173362, acc.: 71.88%] [G loss: 0.585337]\n",
      "epoch:3 step:3237 [D loss: 0.141940, acc.: 78.91%] [G loss: 0.685031]\n",
      "epoch:3 step:3238 [D loss: 0.141764, acc.: 79.69%] [G loss: 0.744578]\n",
      "epoch:3 step:3239 [D loss: 0.149979, acc.: 82.81%] [G loss: 0.693521]\n",
      "epoch:3 step:3240 [D loss: 0.187361, acc.: 71.09%] [G loss: 0.707929]\n",
      "epoch:3 step:3241 [D loss: 0.161064, acc.: 78.12%] [G loss: 0.728915]\n",
      "epoch:3 step:3242 [D loss: 0.159339, acc.: 76.56%] [G loss: 0.638039]\n",
      "epoch:3 step:3243 [D loss: 0.196141, acc.: 67.19%] [G loss: 0.586885]\n",
      "epoch:3 step:3244 [D loss: 0.132830, acc.: 83.59%] [G loss: 0.677421]\n",
      "epoch:3 step:3245 [D loss: 0.159874, acc.: 78.12%] [G loss: 0.668912]\n",
      "epoch:3 step:3246 [D loss: 0.177328, acc.: 75.78%] [G loss: 0.623858]\n",
      "epoch:3 step:3247 [D loss: 0.147631, acc.: 78.91%] [G loss: 0.695912]\n",
      "epoch:3 step:3248 [D loss: 0.226376, acc.: 68.75%] [G loss: 0.603949]\n",
      "epoch:3 step:3249 [D loss: 0.168686, acc.: 77.34%] [G loss: 0.605078]\n",
      "epoch:3 step:3250 [D loss: 0.189374, acc.: 69.53%] [G loss: 0.671931]\n",
      "epoch:3 step:3251 [D loss: 0.179304, acc.: 71.88%] [G loss: 0.639180]\n",
      "epoch:3 step:3252 [D loss: 0.162611, acc.: 78.12%] [G loss: 0.625633]\n",
      "epoch:3 step:3253 [D loss: 0.137171, acc.: 83.59%] [G loss: 0.637448]\n",
      "epoch:3 step:3254 [D loss: 0.207870, acc.: 67.97%] [G loss: 0.615694]\n",
      "epoch:3 step:3255 [D loss: 0.189284, acc.: 73.44%] [G loss: 0.638509]\n",
      "epoch:3 step:3256 [D loss: 0.177468, acc.: 71.09%] [G loss: 0.617326]\n",
      "epoch:3 step:3257 [D loss: 0.164564, acc.: 80.47%] [G loss: 0.703759]\n",
      "epoch:3 step:3258 [D loss: 0.136185, acc.: 82.03%] [G loss: 0.680038]\n",
      "epoch:3 step:3259 [D loss: 0.197901, acc.: 69.53%] [G loss: 0.617615]\n",
      "epoch:3 step:3260 [D loss: 0.156081, acc.: 80.47%] [G loss: 0.641430]\n",
      "epoch:3 step:3261 [D loss: 0.146807, acc.: 80.47%] [G loss: 0.632702]\n",
      "epoch:3 step:3262 [D loss: 0.123791, acc.: 83.59%] [G loss: 0.700769]\n",
      "epoch:3 step:3263 [D loss: 0.169908, acc.: 78.12%] [G loss: 0.685380]\n",
      "epoch:3 step:3264 [D loss: 0.178361, acc.: 78.91%] [G loss: 0.663176]\n",
      "epoch:3 step:3265 [D loss: 0.179470, acc.: 69.53%] [G loss: 0.603981]\n",
      "epoch:3 step:3266 [D loss: 0.181058, acc.: 74.22%] [G loss: 0.622310]\n",
      "epoch:3 step:3267 [D loss: 0.181781, acc.: 75.00%] [G loss: 0.681416]\n",
      "epoch:3 step:3268 [D loss: 0.179965, acc.: 73.44%] [G loss: 0.701230]\n",
      "epoch:3 step:3269 [D loss: 0.227641, acc.: 65.62%] [G loss: 0.586839]\n",
      "epoch:3 step:3270 [D loss: 0.173879, acc.: 76.56%] [G loss: 0.663815]\n",
      "epoch:3 step:3271 [D loss: 0.184022, acc.: 73.44%] [G loss: 0.633498]\n",
      "epoch:3 step:3272 [D loss: 0.209414, acc.: 67.19%] [G loss: 0.637485]\n",
      "epoch:3 step:3273 [D loss: 0.195517, acc.: 71.88%] [G loss: 0.586604]\n",
      "epoch:3 step:3274 [D loss: 0.187571, acc.: 73.44%] [G loss: 0.609923]\n",
      "epoch:3 step:3275 [D loss: 0.161735, acc.: 77.34%] [G loss: 0.646540]\n",
      "epoch:3 step:3276 [D loss: 0.220131, acc.: 66.41%] [G loss: 0.616205]\n",
      "epoch:3 step:3277 [D loss: 0.166727, acc.: 71.09%] [G loss: 0.699355]\n",
      "epoch:3 step:3278 [D loss: 0.167169, acc.: 79.69%] [G loss: 0.664393]\n",
      "epoch:3 step:3279 [D loss: 0.188808, acc.: 69.53%] [G loss: 0.609858]\n",
      "epoch:3 step:3280 [D loss: 0.184413, acc.: 70.31%] [G loss: 0.631513]\n",
      "epoch:3 step:3281 [D loss: 0.171811, acc.: 75.78%] [G loss: 0.670054]\n",
      "epoch:3 step:3282 [D loss: 0.155094, acc.: 80.47%] [G loss: 0.699533]\n",
      "epoch:3 step:3283 [D loss: 0.156316, acc.: 78.91%] [G loss: 0.673589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3284 [D loss: 0.228997, acc.: 62.50%] [G loss: 0.598206]\n",
      "epoch:3 step:3285 [D loss: 0.139145, acc.: 78.12%] [G loss: 0.666666]\n",
      "epoch:3 step:3286 [D loss: 0.170500, acc.: 71.09%] [G loss: 0.621452]\n",
      "epoch:3 step:3287 [D loss: 0.216545, acc.: 69.53%] [G loss: 0.671889]\n",
      "epoch:3 step:3288 [D loss: 0.221115, acc.: 66.41%] [G loss: 0.580403]\n",
      "epoch:3 step:3289 [D loss: 0.212886, acc.: 64.84%] [G loss: 0.599292]\n",
      "epoch:3 step:3290 [D loss: 0.190379, acc.: 72.66%] [G loss: 0.611234]\n",
      "epoch:3 step:3291 [D loss: 0.231697, acc.: 59.38%] [G loss: 0.518906]\n",
      "epoch:3 step:3292 [D loss: 0.157377, acc.: 84.38%] [G loss: 0.603452]\n",
      "epoch:3 step:3293 [D loss: 0.225708, acc.: 64.06%] [G loss: 0.533191]\n",
      "epoch:3 step:3294 [D loss: 0.203405, acc.: 71.09%] [G loss: 0.583861]\n",
      "epoch:3 step:3295 [D loss: 0.161443, acc.: 78.91%] [G loss: 0.649631]\n",
      "epoch:3 step:3296 [D loss: 0.196153, acc.: 71.88%] [G loss: 0.611736]\n",
      "epoch:3 step:3297 [D loss: 0.185698, acc.: 71.09%] [G loss: 0.643315]\n",
      "epoch:3 step:3298 [D loss: 0.186941, acc.: 75.00%] [G loss: 0.593108]\n",
      "epoch:3 step:3299 [D loss: 0.152844, acc.: 85.16%] [G loss: 0.647469]\n",
      "epoch:3 step:3300 [D loss: 0.165067, acc.: 80.47%] [G loss: 0.644336]\n",
      "epoch:3 step:3301 [D loss: 0.202663, acc.: 67.19%] [G loss: 0.595576]\n",
      "epoch:3 step:3302 [D loss: 0.187266, acc.: 73.44%] [G loss: 0.622793]\n",
      "epoch:3 step:3303 [D loss: 0.182154, acc.: 72.66%] [G loss: 0.590888]\n",
      "epoch:3 step:3304 [D loss: 0.191811, acc.: 71.88%] [G loss: 0.627200]\n",
      "epoch:3 step:3305 [D loss: 0.152262, acc.: 82.03%] [G loss: 0.683463]\n",
      "epoch:3 step:3306 [D loss: 0.161177, acc.: 78.91%] [G loss: 0.633533]\n",
      "epoch:3 step:3307 [D loss: 0.181115, acc.: 70.31%] [G loss: 0.549561]\n",
      "epoch:3 step:3308 [D loss: 0.160550, acc.: 78.12%] [G loss: 0.627318]\n",
      "epoch:3 step:3309 [D loss: 0.145981, acc.: 81.25%] [G loss: 0.710041]\n",
      "epoch:3 step:3310 [D loss: 0.151195, acc.: 82.03%] [G loss: 0.659052]\n",
      "epoch:3 step:3311 [D loss: 0.245465, acc.: 60.94%] [G loss: 0.532710]\n",
      "epoch:3 step:3312 [D loss: 0.241674, acc.: 60.16%] [G loss: 0.534267]\n",
      "epoch:3 step:3313 [D loss: 0.171284, acc.: 75.78%] [G loss: 0.638936]\n",
      "epoch:3 step:3314 [D loss: 0.136205, acc.: 81.25%] [G loss: 0.672398]\n",
      "epoch:3 step:3315 [D loss: 0.160051, acc.: 75.00%] [G loss: 0.695191]\n",
      "epoch:3 step:3316 [D loss: 0.165977, acc.: 76.56%] [G loss: 0.640450]\n",
      "epoch:3 step:3317 [D loss: 0.176266, acc.: 72.66%] [G loss: 0.602429]\n",
      "epoch:3 step:3318 [D loss: 0.154774, acc.: 79.69%] [G loss: 0.609929]\n",
      "epoch:3 step:3319 [D loss: 0.134595, acc.: 82.03%] [G loss: 0.707899]\n",
      "epoch:3 step:3320 [D loss: 0.194736, acc.: 73.44%] [G loss: 0.634154]\n",
      "epoch:3 step:3321 [D loss: 0.185288, acc.: 68.75%] [G loss: 0.569226]\n",
      "epoch:3 step:3322 [D loss: 0.167866, acc.: 78.91%] [G loss: 0.594576]\n",
      "epoch:3 step:3323 [D loss: 0.198882, acc.: 68.75%] [G loss: 0.584730]\n",
      "epoch:3 step:3324 [D loss: 0.185376, acc.: 72.66%] [G loss: 0.634582]\n",
      "epoch:3 step:3325 [D loss: 0.173878, acc.: 74.22%] [G loss: 0.679366]\n",
      "epoch:3 step:3326 [D loss: 0.144812, acc.: 82.03%] [G loss: 0.673656]\n",
      "epoch:3 step:3327 [D loss: 0.161262, acc.: 78.12%] [G loss: 0.642405]\n",
      "epoch:3 step:3328 [D loss: 0.177597, acc.: 78.12%] [G loss: 0.630097]\n",
      "epoch:3 step:3329 [D loss: 0.122898, acc.: 89.06%] [G loss: 0.665493]\n",
      "epoch:3 step:3330 [D loss: 0.149035, acc.: 82.81%] [G loss: 0.632026]\n",
      "epoch:3 step:3331 [D loss: 0.160058, acc.: 76.56%] [G loss: 0.646101]\n",
      "epoch:3 step:3332 [D loss: 0.144158, acc.: 78.91%] [G loss: 0.646436]\n",
      "epoch:3 step:3333 [D loss: 0.141422, acc.: 81.25%] [G loss: 0.617173]\n",
      "epoch:3 step:3334 [D loss: 0.143633, acc.: 82.81%] [G loss: 0.719253]\n",
      "epoch:3 step:3335 [D loss: 0.186404, acc.: 71.88%] [G loss: 0.622617]\n",
      "epoch:3 step:3336 [D loss: 0.207812, acc.: 68.75%] [G loss: 0.643089]\n",
      "epoch:3 step:3337 [D loss: 0.171674, acc.: 75.78%] [G loss: 0.621277]\n",
      "epoch:3 step:3338 [D loss: 0.192622, acc.: 69.53%] [G loss: 0.653474]\n",
      "epoch:3 step:3339 [D loss: 0.206001, acc.: 67.97%] [G loss: 0.619648]\n",
      "epoch:3 step:3340 [D loss: 0.165570, acc.: 78.91%] [G loss: 0.625955]\n",
      "epoch:3 step:3341 [D loss: 0.156482, acc.: 76.56%] [G loss: 0.610566]\n",
      "epoch:3 step:3342 [D loss: 0.203041, acc.: 75.78%] [G loss: 0.600148]\n",
      "epoch:3 step:3343 [D loss: 0.164270, acc.: 75.78%] [G loss: 0.605669]\n",
      "epoch:3 step:3344 [D loss: 0.182857, acc.: 71.88%] [G loss: 0.607000]\n",
      "epoch:3 step:3345 [D loss: 0.141329, acc.: 81.25%] [G loss: 0.712402]\n",
      "epoch:3 step:3346 [D loss: 0.175932, acc.: 78.91%] [G loss: 0.626147]\n",
      "epoch:3 step:3347 [D loss: 0.159976, acc.: 78.91%] [G loss: 0.601030]\n",
      "epoch:3 step:3348 [D loss: 0.161490, acc.: 78.91%] [G loss: 0.617047]\n",
      "epoch:3 step:3349 [D loss: 0.213711, acc.: 64.84%] [G loss: 0.604676]\n",
      "epoch:3 step:3350 [D loss: 0.183769, acc.: 74.22%] [G loss: 0.648357]\n",
      "epoch:3 step:3351 [D loss: 0.153565, acc.: 78.91%] [G loss: 0.595337]\n",
      "epoch:3 step:3352 [D loss: 0.165198, acc.: 75.78%] [G loss: 0.654653]\n",
      "epoch:3 step:3353 [D loss: 0.185045, acc.: 71.09%] [G loss: 0.646152]\n",
      "epoch:3 step:3354 [D loss: 0.179996, acc.: 72.66%] [G loss: 0.679990]\n",
      "epoch:3 step:3355 [D loss: 0.176011, acc.: 74.22%] [G loss: 0.644456]\n",
      "epoch:3 step:3356 [D loss: 0.140929, acc.: 79.69%] [G loss: 0.663944]\n",
      "epoch:3 step:3357 [D loss: 0.150208, acc.: 77.34%] [G loss: 0.640127]\n",
      "epoch:3 step:3358 [D loss: 0.139870, acc.: 80.47%] [G loss: 0.674580]\n",
      "epoch:3 step:3359 [D loss: 0.158958, acc.: 79.69%] [G loss: 0.655396]\n",
      "epoch:3 step:3360 [D loss: 0.173245, acc.: 75.00%] [G loss: 0.604416]\n",
      "epoch:3 step:3361 [D loss: 0.165007, acc.: 78.12%] [G loss: 0.677891]\n",
      "epoch:3 step:3362 [D loss: 0.164659, acc.: 76.56%] [G loss: 0.623276]\n",
      "epoch:3 step:3363 [D loss: 0.136643, acc.: 81.25%] [G loss: 0.702095]\n",
      "epoch:3 step:3364 [D loss: 0.182057, acc.: 68.75%] [G loss: 0.615921]\n",
      "epoch:3 step:3365 [D loss: 0.152382, acc.: 77.34%] [G loss: 0.707284]\n",
      "epoch:3 step:3366 [D loss: 0.155389, acc.: 75.78%] [G loss: 0.680723]\n",
      "epoch:3 step:3367 [D loss: 0.136226, acc.: 78.12%] [G loss: 0.650653]\n",
      "epoch:3 step:3368 [D loss: 0.145918, acc.: 84.38%] [G loss: 0.646044]\n",
      "epoch:3 step:3369 [D loss: 0.144010, acc.: 81.25%] [G loss: 0.620432]\n",
      "epoch:3 step:3370 [D loss: 0.208300, acc.: 67.97%] [G loss: 0.628215]\n",
      "epoch:3 step:3371 [D loss: 0.185143, acc.: 75.78%] [G loss: 0.587820]\n",
      "epoch:3 step:3372 [D loss: 0.144273, acc.: 78.91%] [G loss: 0.677229]\n",
      "epoch:3 step:3373 [D loss: 0.160607, acc.: 74.22%] [G loss: 0.658871]\n",
      "epoch:3 step:3374 [D loss: 0.168171, acc.: 78.91%] [G loss: 0.579395]\n",
      "epoch:3 step:3375 [D loss: 0.134193, acc.: 85.94%] [G loss: 0.738498]\n",
      "epoch:3 step:3376 [D loss: 0.194720, acc.: 74.22%] [G loss: 0.671429]\n",
      "epoch:3 step:3377 [D loss: 0.176291, acc.: 76.56%] [G loss: 0.633747]\n",
      "epoch:3 step:3378 [D loss: 0.144852, acc.: 78.12%] [G loss: 0.673116]\n",
      "epoch:3 step:3379 [D loss: 0.121994, acc.: 84.38%] [G loss: 0.638092]\n",
      "epoch:3 step:3380 [D loss: 0.216802, acc.: 68.75%] [G loss: 0.656026]\n",
      "epoch:3 step:3381 [D loss: 0.144572, acc.: 84.38%] [G loss: 0.722396]\n",
      "epoch:3 step:3382 [D loss: 0.178927, acc.: 75.78%] [G loss: 0.615043]\n",
      "epoch:3 step:3383 [D loss: 0.158119, acc.: 78.91%] [G loss: 0.639344]\n",
      "epoch:3 step:3384 [D loss: 0.181442, acc.: 73.44%] [G loss: 0.611661]\n",
      "epoch:3 step:3385 [D loss: 0.124476, acc.: 83.59%] [G loss: 0.774621]\n",
      "epoch:3 step:3386 [D loss: 0.142652, acc.: 82.03%] [G loss: 0.681738]\n",
      "epoch:3 step:3387 [D loss: 0.157240, acc.: 79.69%] [G loss: 0.611905]\n",
      "epoch:3 step:3388 [D loss: 0.151162, acc.: 78.12%] [G loss: 0.636063]\n",
      "epoch:3 step:3389 [D loss: 0.163322, acc.: 75.78%] [G loss: 0.618086]\n",
      "epoch:3 step:3390 [D loss: 0.175418, acc.: 74.22%] [G loss: 0.598802]\n",
      "epoch:3 step:3391 [D loss: 0.150055, acc.: 79.69%] [G loss: 0.660423]\n",
      "epoch:3 step:3392 [D loss: 0.146492, acc.: 77.34%] [G loss: 0.692543]\n",
      "epoch:3 step:3393 [D loss: 0.138820, acc.: 79.69%] [G loss: 0.672115]\n",
      "epoch:3 step:3394 [D loss: 0.216517, acc.: 69.53%] [G loss: 0.648357]\n",
      "epoch:3 step:3395 [D loss: 0.167071, acc.: 75.00%] [G loss: 0.663815]\n",
      "epoch:3 step:3396 [D loss: 0.182855, acc.: 77.34%] [G loss: 0.621137]\n",
      "epoch:3 step:3397 [D loss: 0.145658, acc.: 79.69%] [G loss: 0.660642]\n",
      "epoch:3 step:3398 [D loss: 0.152828, acc.: 78.12%] [G loss: 0.627241]\n",
      "epoch:3 step:3399 [D loss: 0.209533, acc.: 64.84%] [G loss: 0.584331]\n",
      "epoch:3 step:3400 [D loss: 0.141405, acc.: 85.16%] [G loss: 0.689936]\n",
      "epoch:3 step:3401 [D loss: 0.228147, acc.: 71.09%] [G loss: 0.590068]\n",
      "epoch:3 step:3402 [D loss: 0.155930, acc.: 77.34%] [G loss: 0.654702]\n",
      "epoch:3 step:3403 [D loss: 0.139135, acc.: 82.81%] [G loss: 0.709640]\n",
      "epoch:3 step:3404 [D loss: 0.218054, acc.: 64.84%] [G loss: 0.594225]\n",
      "epoch:3 step:3405 [D loss: 0.200825, acc.: 70.31%] [G loss: 0.592480]\n",
      "epoch:3 step:3406 [D loss: 0.169736, acc.: 76.56%] [G loss: 0.603813]\n",
      "epoch:3 step:3407 [D loss: 0.195811, acc.: 72.66%] [G loss: 0.610002]\n",
      "epoch:3 step:3408 [D loss: 0.171985, acc.: 74.22%] [G loss: 0.597741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3409 [D loss: 0.136389, acc.: 82.03%] [G loss: 0.688591]\n",
      "epoch:3 step:3410 [D loss: 0.213254, acc.: 65.62%] [G loss: 0.599024]\n",
      "epoch:3 step:3411 [D loss: 0.206903, acc.: 67.97%] [G loss: 0.611541]\n",
      "epoch:3 step:3412 [D loss: 0.177345, acc.: 75.00%] [G loss: 0.652883]\n",
      "epoch:3 step:3413 [D loss: 0.192173, acc.: 75.00%] [G loss: 0.695123]\n",
      "epoch:3 step:3414 [D loss: 0.203972, acc.: 71.09%] [G loss: 0.659036]\n",
      "epoch:3 step:3415 [D loss: 0.170723, acc.: 74.22%] [G loss: 0.586924]\n",
      "epoch:3 step:3416 [D loss: 0.158046, acc.: 76.56%] [G loss: 0.628224]\n",
      "epoch:3 step:3417 [D loss: 0.196553, acc.: 67.97%] [G loss: 0.570958]\n",
      "epoch:3 step:3418 [D loss: 0.184254, acc.: 74.22%] [G loss: 0.605019]\n",
      "epoch:3 step:3419 [D loss: 0.188702, acc.: 70.31%] [G loss: 0.559362]\n",
      "epoch:3 step:3420 [D loss: 0.162950, acc.: 75.78%] [G loss: 0.626563]\n",
      "epoch:3 step:3421 [D loss: 0.156112, acc.: 80.47%] [G loss: 0.635768]\n",
      "epoch:3 step:3422 [D loss: 0.148372, acc.: 78.91%] [G loss: 0.623679]\n",
      "epoch:3 step:3423 [D loss: 0.191614, acc.: 67.97%] [G loss: 0.591080]\n",
      "epoch:3 step:3424 [D loss: 0.148098, acc.: 81.25%] [G loss: 0.648600]\n",
      "epoch:3 step:3425 [D loss: 0.201959, acc.: 70.31%] [G loss: 0.597649]\n",
      "epoch:3 step:3426 [D loss: 0.199568, acc.: 71.09%] [G loss: 0.619291]\n",
      "epoch:3 step:3427 [D loss: 0.135265, acc.: 84.38%] [G loss: 0.650906]\n",
      "epoch:3 step:3428 [D loss: 0.199646, acc.: 68.75%] [G loss: 0.592137]\n",
      "epoch:3 step:3429 [D loss: 0.192613, acc.: 69.53%] [G loss: 0.573505]\n",
      "epoch:3 step:3430 [D loss: 0.157775, acc.: 78.91%] [G loss: 0.636177]\n",
      "epoch:3 step:3431 [D loss: 0.130272, acc.: 82.03%] [G loss: 0.622715]\n",
      "epoch:3 step:3432 [D loss: 0.174986, acc.: 72.66%] [G loss: 0.617715]\n",
      "epoch:3 step:3433 [D loss: 0.272919, acc.: 58.59%] [G loss: 0.544761]\n",
      "epoch:3 step:3434 [D loss: 0.157524, acc.: 79.69%] [G loss: 0.664439]\n",
      "epoch:3 step:3435 [D loss: 0.185255, acc.: 71.09%] [G loss: 0.651185]\n",
      "epoch:3 step:3436 [D loss: 0.212880, acc.: 68.75%] [G loss: 0.563105]\n",
      "epoch:3 step:3437 [D loss: 0.199170, acc.: 73.44%] [G loss: 0.606885]\n",
      "epoch:3 step:3438 [D loss: 0.180191, acc.: 73.44%] [G loss: 0.561106]\n",
      "epoch:3 step:3439 [D loss: 0.205178, acc.: 71.09%] [G loss: 0.591946]\n",
      "epoch:3 step:3440 [D loss: 0.188859, acc.: 69.53%] [G loss: 0.633905]\n",
      "epoch:3 step:3441 [D loss: 0.190230, acc.: 73.44%] [G loss: 0.623454]\n",
      "epoch:3 step:3442 [D loss: 0.155767, acc.: 79.69%] [G loss: 0.596347]\n",
      "epoch:3 step:3443 [D loss: 0.165021, acc.: 75.78%] [G loss: 0.640140]\n",
      "epoch:3 step:3444 [D loss: 0.159489, acc.: 80.47%] [G loss: 0.668910]\n",
      "epoch:3 step:3445 [D loss: 0.162675, acc.: 77.34%] [G loss: 0.636989]\n",
      "epoch:3 step:3446 [D loss: 0.168413, acc.: 75.78%] [G loss: 0.666387]\n",
      "epoch:3 step:3447 [D loss: 0.213564, acc.: 64.84%] [G loss: 0.544823]\n",
      "epoch:3 step:3448 [D loss: 0.181345, acc.: 71.09%] [G loss: 0.609473]\n",
      "epoch:3 step:3449 [D loss: 0.166450, acc.: 75.78%] [G loss: 0.644353]\n",
      "epoch:3 step:3450 [D loss: 0.135278, acc.: 82.81%] [G loss: 0.741706]\n",
      "epoch:3 step:3451 [D loss: 0.178382, acc.: 71.09%] [G loss: 0.634525]\n",
      "epoch:3 step:3452 [D loss: 0.163724, acc.: 72.66%] [G loss: 0.610550]\n",
      "epoch:3 step:3453 [D loss: 0.128712, acc.: 82.81%] [G loss: 0.757173]\n",
      "epoch:3 step:3454 [D loss: 0.190063, acc.: 75.00%] [G loss: 0.646748]\n",
      "epoch:3 step:3455 [D loss: 0.173054, acc.: 77.34%] [G loss: 0.611342]\n",
      "epoch:3 step:3456 [D loss: 0.198289, acc.: 70.31%] [G loss: 0.578941]\n",
      "epoch:3 step:3457 [D loss: 0.221661, acc.: 64.84%] [G loss: 0.625566]\n",
      "epoch:3 step:3458 [D loss: 0.189611, acc.: 71.09%] [G loss: 0.591180]\n",
      "epoch:3 step:3459 [D loss: 0.136231, acc.: 85.16%] [G loss: 0.749828]\n",
      "epoch:3 step:3460 [D loss: 0.171638, acc.: 75.78%] [G loss: 0.621212]\n",
      "epoch:3 step:3461 [D loss: 0.180165, acc.: 71.88%] [G loss: 0.649542]\n",
      "epoch:3 step:3462 [D loss: 0.175908, acc.: 75.00%] [G loss: 0.612541]\n",
      "epoch:3 step:3463 [D loss: 0.188690, acc.: 76.56%] [G loss: 0.608013]\n",
      "epoch:3 step:3464 [D loss: 0.187278, acc.: 69.53%] [G loss: 0.587112]\n",
      "epoch:3 step:3465 [D loss: 0.192188, acc.: 67.19%] [G loss: 0.636478]\n",
      "epoch:3 step:3466 [D loss: 0.216691, acc.: 69.53%] [G loss: 0.549807]\n",
      "epoch:3 step:3467 [D loss: 0.170086, acc.: 72.66%] [G loss: 0.602638]\n",
      "epoch:3 step:3468 [D loss: 0.187490, acc.: 71.88%] [G loss: 0.576700]\n",
      "epoch:3 step:3469 [D loss: 0.177936, acc.: 73.44%] [G loss: 0.586687]\n",
      "epoch:3 step:3470 [D loss: 0.160732, acc.: 78.12%] [G loss: 0.627850]\n",
      "epoch:3 step:3471 [D loss: 0.161037, acc.: 76.56%] [G loss: 0.625943]\n",
      "epoch:3 step:3472 [D loss: 0.152236, acc.: 79.69%] [G loss: 0.676646]\n",
      "epoch:3 step:3473 [D loss: 0.175528, acc.: 74.22%] [G loss: 0.670003]\n",
      "epoch:3 step:3474 [D loss: 0.149219, acc.: 75.00%] [G loss: 0.640879]\n",
      "epoch:3 step:3475 [D loss: 0.166501, acc.: 75.78%] [G loss: 0.645737]\n",
      "epoch:3 step:3476 [D loss: 0.203001, acc.: 71.09%] [G loss: 0.638249]\n",
      "epoch:3 step:3477 [D loss: 0.161214, acc.: 76.56%] [G loss: 0.680133]\n",
      "epoch:3 step:3478 [D loss: 0.202638, acc.: 65.62%] [G loss: 0.587093]\n",
      "epoch:3 step:3479 [D loss: 0.153515, acc.: 83.59%] [G loss: 0.664152]\n",
      "epoch:3 step:3480 [D loss: 0.187642, acc.: 69.53%] [G loss: 0.589156]\n",
      "epoch:3 step:3481 [D loss: 0.169144, acc.: 75.78%] [G loss: 0.625409]\n",
      "epoch:3 step:3482 [D loss: 0.190230, acc.: 76.56%] [G loss: 0.567464]\n",
      "epoch:3 step:3483 [D loss: 0.254460, acc.: 60.94%] [G loss: 0.546093]\n",
      "epoch:3 step:3484 [D loss: 0.176739, acc.: 74.22%] [G loss: 0.596572]\n",
      "epoch:3 step:3485 [D loss: 0.166624, acc.: 80.47%] [G loss: 0.603061]\n",
      "epoch:3 step:3486 [D loss: 0.178411, acc.: 74.22%] [G loss: 0.617718]\n",
      "epoch:3 step:3487 [D loss: 0.159320, acc.: 75.00%] [G loss: 0.644493]\n",
      "epoch:3 step:3488 [D loss: 0.150557, acc.: 82.81%] [G loss: 0.660885]\n",
      "epoch:3 step:3489 [D loss: 0.185887, acc.: 71.09%] [G loss: 0.605578]\n",
      "epoch:3 step:3490 [D loss: 0.170850, acc.: 74.22%] [G loss: 0.614672]\n",
      "epoch:3 step:3491 [D loss: 0.177027, acc.: 73.44%] [G loss: 0.610035]\n",
      "epoch:3 step:3492 [D loss: 0.149686, acc.: 74.22%] [G loss: 0.671330]\n",
      "epoch:3 step:3493 [D loss: 0.211297, acc.: 67.19%] [G loss: 0.573576]\n",
      "epoch:3 step:3494 [D loss: 0.181143, acc.: 75.78%] [G loss: 0.601390]\n",
      "epoch:3 step:3495 [D loss: 0.153333, acc.: 78.91%] [G loss: 0.598338]\n",
      "epoch:3 step:3496 [D loss: 0.153424, acc.: 81.25%] [G loss: 0.632301]\n",
      "epoch:3 step:3497 [D loss: 0.189950, acc.: 73.44%] [G loss: 0.687961]\n",
      "epoch:3 step:3498 [D loss: 0.193653, acc.: 74.22%] [G loss: 0.609320]\n",
      "epoch:3 step:3499 [D loss: 0.180035, acc.: 76.56%] [G loss: 0.647381]\n",
      "epoch:3 step:3500 [D loss: 0.188127, acc.: 67.97%] [G loss: 0.639162]\n",
      "epoch:3 step:3501 [D loss: 0.180245, acc.: 71.09%] [G loss: 0.652614]\n",
      "epoch:3 step:3502 [D loss: 0.198064, acc.: 68.75%] [G loss: 0.633591]\n",
      "epoch:3 step:3503 [D loss: 0.151167, acc.: 78.12%] [G loss: 0.671522]\n",
      "epoch:3 step:3504 [D loss: 0.147280, acc.: 79.69%] [G loss: 0.681611]\n",
      "epoch:3 step:3505 [D loss: 0.169463, acc.: 72.66%] [G loss: 0.652353]\n",
      "epoch:3 step:3506 [D loss: 0.168499, acc.: 77.34%] [G loss: 0.600061]\n",
      "epoch:3 step:3507 [D loss: 0.209351, acc.: 67.19%] [G loss: 0.569560]\n",
      "epoch:3 step:3508 [D loss: 0.197985, acc.: 71.09%] [G loss: 0.640615]\n",
      "epoch:3 step:3509 [D loss: 0.186129, acc.: 74.22%] [G loss: 0.595755]\n",
      "epoch:3 step:3510 [D loss: 0.243012, acc.: 60.16%] [G loss: 0.550070]\n",
      "epoch:3 step:3511 [D loss: 0.185024, acc.: 72.66%] [G loss: 0.627716]\n",
      "epoch:3 step:3512 [D loss: 0.152675, acc.: 77.34%] [G loss: 0.680156]\n",
      "epoch:3 step:3513 [D loss: 0.192296, acc.: 69.53%] [G loss: 0.670038]\n",
      "epoch:3 step:3514 [D loss: 0.209077, acc.: 70.31%] [G loss: 0.621049]\n",
      "epoch:3 step:3515 [D loss: 0.181466, acc.: 72.66%] [G loss: 0.629268]\n",
      "epoch:3 step:3516 [D loss: 0.191101, acc.: 68.75%] [G loss: 0.622503]\n",
      "epoch:3 step:3517 [D loss: 0.191528, acc.: 70.31%] [G loss: 0.649702]\n",
      "epoch:3 step:3518 [D loss: 0.106629, acc.: 88.28%] [G loss: 0.722460]\n",
      "epoch:3 step:3519 [D loss: 0.183527, acc.: 71.09%] [G loss: 0.600085]\n",
      "epoch:3 step:3520 [D loss: 0.131307, acc.: 85.16%] [G loss: 0.709393]\n",
      "epoch:3 step:3521 [D loss: 0.197562, acc.: 75.00%] [G loss: 0.574792]\n",
      "epoch:3 step:3522 [D loss: 0.191600, acc.: 71.88%] [G loss: 0.610016]\n",
      "epoch:3 step:3523 [D loss: 0.168345, acc.: 77.34%] [G loss: 0.687229]\n",
      "epoch:3 step:3524 [D loss: 0.194930, acc.: 70.31%] [G loss: 0.580657]\n",
      "epoch:3 step:3525 [D loss: 0.167299, acc.: 75.78%] [G loss: 0.633537]\n",
      "epoch:3 step:3526 [D loss: 0.162295, acc.: 76.56%] [G loss: 0.648134]\n",
      "epoch:3 step:3527 [D loss: 0.208063, acc.: 72.66%] [G loss: 0.548618]\n",
      "epoch:3 step:3528 [D loss: 0.198849, acc.: 69.53%] [G loss: 0.566603]\n",
      "epoch:3 step:3529 [D loss: 0.173605, acc.: 78.91%] [G loss: 0.650117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3530 [D loss: 0.193387, acc.: 67.19%] [G loss: 0.634493]\n",
      "epoch:3 step:3531 [D loss: 0.175881, acc.: 74.22%] [G loss: 0.658174]\n",
      "epoch:3 step:3532 [D loss: 0.175841, acc.: 74.22%] [G loss: 0.635121]\n",
      "epoch:3 step:3533 [D loss: 0.197526, acc.: 70.31%] [G loss: 0.607610]\n",
      "epoch:3 step:3534 [D loss: 0.159945, acc.: 78.91%] [G loss: 0.652049]\n",
      "epoch:3 step:3535 [D loss: 0.174873, acc.: 72.66%] [G loss: 0.641797]\n",
      "epoch:3 step:3536 [D loss: 0.160566, acc.: 76.56%] [G loss: 0.698998]\n",
      "epoch:3 step:3537 [D loss: 0.187203, acc.: 70.31%] [G loss: 0.601735]\n",
      "epoch:3 step:3538 [D loss: 0.206971, acc.: 64.84%] [G loss: 0.530294]\n",
      "epoch:3 step:3539 [D loss: 0.174930, acc.: 72.66%] [G loss: 0.630794]\n",
      "epoch:3 step:3540 [D loss: 0.183452, acc.: 72.66%] [G loss: 0.606600]\n",
      "epoch:3 step:3541 [D loss: 0.146876, acc.: 79.69%] [G loss: 0.696766]\n",
      "epoch:3 step:3542 [D loss: 0.195800, acc.: 67.97%] [G loss: 0.708017]\n",
      "epoch:3 step:3543 [D loss: 0.176105, acc.: 74.22%] [G loss: 0.626129]\n",
      "epoch:3 step:3544 [D loss: 0.167849, acc.: 73.44%] [G loss: 0.618495]\n",
      "epoch:3 step:3545 [D loss: 0.163204, acc.: 78.12%] [G loss: 0.616632]\n",
      "epoch:3 step:3546 [D loss: 0.190221, acc.: 71.09%] [G loss: 0.547379]\n",
      "epoch:3 step:3547 [D loss: 0.172381, acc.: 76.56%] [G loss: 0.584171]\n",
      "epoch:3 step:3548 [D loss: 0.154557, acc.: 82.81%] [G loss: 0.682507]\n",
      "epoch:3 step:3549 [D loss: 0.239558, acc.: 60.94%] [G loss: 0.534153]\n",
      "epoch:3 step:3550 [D loss: 0.235588, acc.: 62.50%] [G loss: 0.600003]\n",
      "epoch:3 step:3551 [D loss: 0.208650, acc.: 68.75%] [G loss: 0.644632]\n",
      "epoch:3 step:3552 [D loss: 0.200946, acc.: 77.34%] [G loss: 0.597401]\n",
      "epoch:3 step:3553 [D loss: 0.171670, acc.: 72.66%] [G loss: 0.586196]\n",
      "epoch:3 step:3554 [D loss: 0.169884, acc.: 80.47%] [G loss: 0.600821]\n",
      "epoch:3 step:3555 [D loss: 0.152489, acc.: 80.47%] [G loss: 0.641791]\n",
      "epoch:3 step:3556 [D loss: 0.186437, acc.: 75.00%] [G loss: 0.545768]\n",
      "epoch:3 step:3557 [D loss: 0.155561, acc.: 78.12%] [G loss: 0.689913]\n",
      "epoch:3 step:3558 [D loss: 0.187993, acc.: 67.97%] [G loss: 0.607000]\n",
      "epoch:3 step:3559 [D loss: 0.191448, acc.: 69.53%] [G loss: 0.590550]\n",
      "epoch:3 step:3560 [D loss: 0.201526, acc.: 69.53%] [G loss: 0.544299]\n",
      "epoch:3 step:3561 [D loss: 0.171142, acc.: 73.44%] [G loss: 0.579415]\n",
      "epoch:3 step:3562 [D loss: 0.194919, acc.: 70.31%] [G loss: 0.571915]\n",
      "epoch:3 step:3563 [D loss: 0.167305, acc.: 73.44%] [G loss: 0.629660]\n",
      "epoch:3 step:3564 [D loss: 0.182533, acc.: 69.53%] [G loss: 0.659437]\n",
      "epoch:3 step:3565 [D loss: 0.146648, acc.: 78.12%] [G loss: 0.646827]\n",
      "epoch:3 step:3566 [D loss: 0.180569, acc.: 68.75%] [G loss: 0.615530]\n",
      "epoch:3 step:3567 [D loss: 0.184528, acc.: 71.09%] [G loss: 0.567802]\n",
      "epoch:3 step:3568 [D loss: 0.164548, acc.: 69.53%] [G loss: 0.670401]\n",
      "epoch:3 step:3569 [D loss: 0.154715, acc.: 76.56%] [G loss: 0.633388]\n",
      "epoch:3 step:3570 [D loss: 0.196778, acc.: 70.31%] [G loss: 0.619090]\n",
      "epoch:3 step:3571 [D loss: 0.168075, acc.: 79.69%] [G loss: 0.629097]\n",
      "epoch:3 step:3572 [D loss: 0.179481, acc.: 71.09%] [G loss: 0.604889]\n",
      "epoch:3 step:3573 [D loss: 0.208858, acc.: 65.62%] [G loss: 0.587923]\n",
      "epoch:3 step:3574 [D loss: 0.186183, acc.: 71.88%] [G loss: 0.631107]\n",
      "epoch:3 step:3575 [D loss: 0.184781, acc.: 71.09%] [G loss: 0.576227]\n",
      "epoch:3 step:3576 [D loss: 0.244880, acc.: 64.84%] [G loss: 0.612599]\n",
      "epoch:3 step:3577 [D loss: 0.264765, acc.: 53.91%] [G loss: 0.585801]\n",
      "epoch:3 step:3578 [D loss: 0.193385, acc.: 70.31%] [G loss: 0.630667]\n",
      "epoch:3 step:3579 [D loss: 0.197422, acc.: 67.97%] [G loss: 0.633486]\n",
      "epoch:3 step:3580 [D loss: 0.155388, acc.: 74.22%] [G loss: 0.670826]\n",
      "epoch:3 step:3581 [D loss: 0.193070, acc.: 67.97%] [G loss: 0.615977]\n",
      "epoch:3 step:3582 [D loss: 0.181422, acc.: 71.09%] [G loss: 0.627565]\n",
      "epoch:3 step:3583 [D loss: 0.200748, acc.: 69.53%] [G loss: 0.598034]\n",
      "epoch:3 step:3584 [D loss: 0.181881, acc.: 71.88%] [G loss: 0.615584]\n",
      "epoch:3 step:3585 [D loss: 0.218103, acc.: 67.19%] [G loss: 0.533947]\n",
      "epoch:3 step:3586 [D loss: 0.151610, acc.: 78.91%] [G loss: 0.651980]\n",
      "epoch:3 step:3587 [D loss: 0.190010, acc.: 69.53%] [G loss: 0.603015]\n",
      "epoch:3 step:3588 [D loss: 0.172682, acc.: 69.53%] [G loss: 0.608657]\n",
      "epoch:3 step:3589 [D loss: 0.194653, acc.: 66.41%] [G loss: 0.589984]\n",
      "epoch:3 step:3590 [D loss: 0.189638, acc.: 72.66%] [G loss: 0.593220]\n",
      "epoch:3 step:3591 [D loss: 0.152190, acc.: 76.56%] [G loss: 0.621289]\n",
      "epoch:3 step:3592 [D loss: 0.144456, acc.: 76.56%] [G loss: 0.661068]\n",
      "epoch:3 step:3593 [D loss: 0.178716, acc.: 70.31%] [G loss: 0.640555]\n",
      "epoch:3 step:3594 [D loss: 0.179296, acc.: 74.22%] [G loss: 0.649198]\n",
      "epoch:3 step:3595 [D loss: 0.195838, acc.: 71.09%] [G loss: 0.521678]\n",
      "epoch:3 step:3596 [D loss: 0.179969, acc.: 75.00%] [G loss: 0.570777]\n",
      "epoch:3 step:3597 [D loss: 0.159009, acc.: 77.34%] [G loss: 0.622112]\n",
      "epoch:3 step:3598 [D loss: 0.195759, acc.: 72.66%] [G loss: 0.603488]\n",
      "epoch:3 step:3599 [D loss: 0.236923, acc.: 59.38%] [G loss: 0.543131]\n",
      "epoch:3 step:3600 [D loss: 0.174764, acc.: 73.44%] [G loss: 0.634862]\n",
      "epoch:3 step:3601 [D loss: 0.198623, acc.: 75.78%] [G loss: 0.562590]\n",
      "epoch:3 step:3602 [D loss: 0.188097, acc.: 73.44%] [G loss: 0.602356]\n",
      "epoch:3 step:3603 [D loss: 0.111245, acc.: 86.72%] [G loss: 0.704605]\n",
      "epoch:3 step:3604 [D loss: 0.195668, acc.: 70.31%] [G loss: 0.628777]\n",
      "epoch:3 step:3605 [D loss: 0.195548, acc.: 64.84%] [G loss: 0.591112]\n",
      "epoch:3 step:3606 [D loss: 0.192106, acc.: 70.31%] [G loss: 0.626789]\n",
      "epoch:3 step:3607 [D loss: 0.183719, acc.: 73.44%] [G loss: 0.602392]\n",
      "epoch:3 step:3608 [D loss: 0.175961, acc.: 70.31%] [G loss: 0.632552]\n",
      "epoch:3 step:3609 [D loss: 0.155583, acc.: 78.12%] [G loss: 0.573281]\n",
      "epoch:3 step:3610 [D loss: 0.188799, acc.: 75.00%] [G loss: 0.553289]\n",
      "epoch:3 step:3611 [D loss: 0.180333, acc.: 72.66%] [G loss: 0.570199]\n",
      "epoch:3 step:3612 [D loss: 0.186428, acc.: 72.66%] [G loss: 0.576891]\n",
      "epoch:3 step:3613 [D loss: 0.184867, acc.: 71.09%] [G loss: 0.664465]\n",
      "epoch:3 step:3614 [D loss: 0.172156, acc.: 75.78%] [G loss: 0.662267]\n",
      "epoch:3 step:3615 [D loss: 0.192882, acc.: 71.88%] [G loss: 0.583413]\n",
      "epoch:3 step:3616 [D loss: 0.169344, acc.: 72.66%] [G loss: 0.640160]\n",
      "epoch:3 step:3617 [D loss: 0.146680, acc.: 79.69%] [G loss: 0.651608]\n",
      "epoch:3 step:3618 [D loss: 0.190999, acc.: 67.97%] [G loss: 0.595528]\n",
      "epoch:3 step:3619 [D loss: 0.188322, acc.: 67.97%] [G loss: 0.573935]\n",
      "epoch:3 step:3620 [D loss: 0.176573, acc.: 73.44%] [G loss: 0.620427]\n",
      "epoch:3 step:3621 [D loss: 0.175095, acc.: 74.22%] [G loss: 0.591892]\n",
      "epoch:3 step:3622 [D loss: 0.183101, acc.: 67.97%] [G loss: 0.655112]\n",
      "epoch:3 step:3623 [D loss: 0.220754, acc.: 64.06%] [G loss: 0.643734]\n",
      "epoch:3 step:3624 [D loss: 0.187602, acc.: 66.41%] [G loss: 0.627345]\n",
      "epoch:3 step:3625 [D loss: 0.211048, acc.: 71.09%] [G loss: 0.542933]\n",
      "epoch:3 step:3626 [D loss: 0.181438, acc.: 71.09%] [G loss: 0.662924]\n",
      "epoch:3 step:3627 [D loss: 0.179338, acc.: 68.75%] [G loss: 0.666428]\n",
      "epoch:3 step:3628 [D loss: 0.202780, acc.: 64.06%] [G loss: 0.593728]\n",
      "epoch:3 step:3629 [D loss: 0.224924, acc.: 64.84%] [G loss: 0.610832]\n",
      "epoch:3 step:3630 [D loss: 0.160862, acc.: 73.44%] [G loss: 0.573709]\n",
      "epoch:3 step:3631 [D loss: 0.204294, acc.: 68.75%] [G loss: 0.542638]\n",
      "epoch:3 step:3632 [D loss: 0.178320, acc.: 78.12%] [G loss: 0.581370]\n",
      "epoch:3 step:3633 [D loss: 0.166036, acc.: 78.91%] [G loss: 0.648513]\n",
      "epoch:3 step:3634 [D loss: 0.174818, acc.: 75.00%] [G loss: 0.647811]\n",
      "epoch:3 step:3635 [D loss: 0.208818, acc.: 65.62%] [G loss: 0.563913]\n",
      "epoch:3 step:3636 [D loss: 0.170184, acc.: 78.12%] [G loss: 0.702875]\n",
      "epoch:3 step:3637 [D loss: 0.181475, acc.: 71.09%] [G loss: 0.661331]\n",
      "epoch:3 step:3638 [D loss: 0.225433, acc.: 57.81%] [G loss: 0.547138]\n",
      "epoch:3 step:3639 [D loss: 0.190235, acc.: 70.31%] [G loss: 0.617921]\n",
      "epoch:3 step:3640 [D loss: 0.164733, acc.: 77.34%] [G loss: 0.647885]\n",
      "epoch:3 step:3641 [D loss: 0.174095, acc.: 74.22%] [G loss: 0.647168]\n",
      "epoch:3 step:3642 [D loss: 0.169112, acc.: 78.91%] [G loss: 0.662321]\n",
      "epoch:3 step:3643 [D loss: 0.149520, acc.: 78.12%] [G loss: 0.629532]\n",
      "epoch:3 step:3644 [D loss: 0.149062, acc.: 81.25%] [G loss: 0.619669]\n",
      "epoch:3 step:3645 [D loss: 0.143927, acc.: 83.59%] [G loss: 0.675437]\n",
      "epoch:3 step:3646 [D loss: 0.165609, acc.: 77.34%] [G loss: 0.624302]\n",
      "epoch:3 step:3647 [D loss: 0.182395, acc.: 78.12%] [G loss: 0.620678]\n",
      "epoch:3 step:3648 [D loss: 0.164325, acc.: 74.22%] [G loss: 0.580525]\n",
      "epoch:3 step:3649 [D loss: 0.160789, acc.: 80.47%] [G loss: 0.640448]\n",
      "epoch:3 step:3650 [D loss: 0.193358, acc.: 77.34%] [G loss: 0.617906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3651 [D loss: 0.192809, acc.: 71.09%] [G loss: 0.625733]\n",
      "epoch:3 step:3652 [D loss: 0.148596, acc.: 77.34%] [G loss: 0.639115]\n",
      "epoch:3 step:3653 [D loss: 0.151815, acc.: 79.69%] [G loss: 0.623928]\n",
      "epoch:3 step:3654 [D loss: 0.182396, acc.: 73.44%] [G loss: 0.592470]\n",
      "epoch:3 step:3655 [D loss: 0.174554, acc.: 76.56%] [G loss: 0.587286]\n",
      "epoch:3 step:3656 [D loss: 0.152810, acc.: 75.78%] [G loss: 0.646062]\n",
      "epoch:3 step:3657 [D loss: 0.188044, acc.: 70.31%] [G loss: 0.597047]\n",
      "epoch:3 step:3658 [D loss: 0.191615, acc.: 72.66%] [G loss: 0.637729]\n",
      "epoch:3 step:3659 [D loss: 0.220230, acc.: 65.62%] [G loss: 0.622649]\n",
      "epoch:3 step:3660 [D loss: 0.225232, acc.: 66.41%] [G loss: 0.611456]\n",
      "epoch:3 step:3661 [D loss: 0.216328, acc.: 66.41%] [G loss: 0.602343]\n",
      "epoch:3 step:3662 [D loss: 0.205072, acc.: 67.19%] [G loss: 0.600578]\n",
      "epoch:3 step:3663 [D loss: 0.193402, acc.: 68.75%] [G loss: 0.608717]\n",
      "epoch:3 step:3664 [D loss: 0.166959, acc.: 74.22%] [G loss: 0.719862]\n",
      "epoch:3 step:3665 [D loss: 0.161720, acc.: 76.56%] [G loss: 0.602439]\n",
      "epoch:3 step:3666 [D loss: 0.203823, acc.: 70.31%] [G loss: 0.616117]\n",
      "epoch:3 step:3667 [D loss: 0.192076, acc.: 71.88%] [G loss: 0.671892]\n",
      "epoch:3 step:3668 [D loss: 0.204597, acc.: 73.44%] [G loss: 0.664860]\n",
      "epoch:3 step:3669 [D loss: 0.268192, acc.: 57.81%] [G loss: 0.525148]\n",
      "epoch:3 step:3670 [D loss: 0.207865, acc.: 69.53%] [G loss: 0.626616]\n",
      "epoch:3 step:3671 [D loss: 0.146058, acc.: 78.91%] [G loss: 0.687158]\n",
      "epoch:3 step:3672 [D loss: 0.228969, acc.: 61.72%] [G loss: 0.548671]\n",
      "epoch:3 step:3673 [D loss: 0.191540, acc.: 72.66%] [G loss: 0.611429]\n",
      "epoch:3 step:3674 [D loss: 0.175706, acc.: 76.56%] [G loss: 0.655215]\n",
      "epoch:3 step:3675 [D loss: 0.218230, acc.: 66.41%] [G loss: 0.619065]\n",
      "epoch:3 step:3676 [D loss: 0.185692, acc.: 73.44%] [G loss: 0.598740]\n",
      "epoch:3 step:3677 [D loss: 0.196670, acc.: 71.09%] [G loss: 0.535459]\n",
      "epoch:3 step:3678 [D loss: 0.236429, acc.: 63.28%] [G loss: 0.519234]\n",
      "epoch:3 step:3679 [D loss: 0.170233, acc.: 75.00%] [G loss: 0.613536]\n",
      "epoch:3 step:3680 [D loss: 0.184424, acc.: 72.66%] [G loss: 0.602964]\n",
      "epoch:3 step:3681 [D loss: 0.191050, acc.: 71.09%] [G loss: 0.607625]\n",
      "epoch:3 step:3682 [D loss: 0.170186, acc.: 75.78%] [G loss: 0.640600]\n",
      "epoch:3 step:3683 [D loss: 0.182740, acc.: 73.44%] [G loss: 0.617052]\n",
      "epoch:3 step:3684 [D loss: 0.202009, acc.: 67.97%] [G loss: 0.549477]\n",
      "epoch:3 step:3685 [D loss: 0.211468, acc.: 69.53%] [G loss: 0.522221]\n",
      "epoch:3 step:3686 [D loss: 0.175111, acc.: 78.12%] [G loss: 0.605470]\n",
      "epoch:3 step:3687 [D loss: 0.184319, acc.: 69.53%] [G loss: 0.619771]\n",
      "epoch:3 step:3688 [D loss: 0.174297, acc.: 71.88%] [G loss: 0.571772]\n",
      "epoch:3 step:3689 [D loss: 0.216871, acc.: 65.62%] [G loss: 0.550390]\n",
      "epoch:3 step:3690 [D loss: 0.195374, acc.: 70.31%] [G loss: 0.609540]\n",
      "epoch:3 step:3691 [D loss: 0.234729, acc.: 59.38%] [G loss: 0.558659]\n",
      "epoch:3 step:3692 [D loss: 0.164937, acc.: 77.34%] [G loss: 0.618027]\n",
      "epoch:3 step:3693 [D loss: 0.217070, acc.: 66.41%] [G loss: 0.537379]\n",
      "epoch:3 step:3694 [D loss: 0.192978, acc.: 67.19%] [G loss: 0.546890]\n",
      "epoch:3 step:3695 [D loss: 0.145861, acc.: 80.47%] [G loss: 0.640415]\n",
      "epoch:3 step:3696 [D loss: 0.180965, acc.: 78.12%] [G loss: 0.643182]\n",
      "epoch:3 step:3697 [D loss: 0.162890, acc.: 75.78%] [G loss: 0.671315]\n",
      "epoch:3 step:3698 [D loss: 0.166331, acc.: 75.78%] [G loss: 0.604406]\n",
      "epoch:3 step:3699 [D loss: 0.190244, acc.: 67.19%] [G loss: 0.646457]\n",
      "epoch:3 step:3700 [D loss: 0.189291, acc.: 67.97%] [G loss: 0.632298]\n",
      "epoch:3 step:3701 [D loss: 0.148001, acc.: 78.91%] [G loss: 0.636220]\n",
      "epoch:3 step:3702 [D loss: 0.242638, acc.: 60.94%] [G loss: 0.493082]\n",
      "epoch:3 step:3703 [D loss: 0.221989, acc.: 66.41%] [G loss: 0.535448]\n",
      "epoch:3 step:3704 [D loss: 0.158798, acc.: 77.34%] [G loss: 0.672875]\n",
      "epoch:3 step:3705 [D loss: 0.188610, acc.: 67.19%] [G loss: 0.634177]\n",
      "epoch:3 step:3706 [D loss: 0.210239, acc.: 67.19%] [G loss: 0.625452]\n",
      "epoch:3 step:3707 [D loss: 0.202592, acc.: 69.53%] [G loss: 0.576419]\n",
      "epoch:3 step:3708 [D loss: 0.188274, acc.: 71.88%] [G loss: 0.609972]\n",
      "epoch:3 step:3709 [D loss: 0.175041, acc.: 75.78%] [G loss: 0.610922]\n",
      "epoch:3 step:3710 [D loss: 0.142002, acc.: 78.12%] [G loss: 0.636889]\n",
      "epoch:3 step:3711 [D loss: 0.198276, acc.: 74.22%] [G loss: 0.581453]\n",
      "epoch:3 step:3712 [D loss: 0.158193, acc.: 75.00%] [G loss: 0.637179]\n",
      "epoch:3 step:3713 [D loss: 0.192870, acc.: 73.44%] [G loss: 0.582746]\n",
      "epoch:3 step:3714 [D loss: 0.206483, acc.: 68.75%] [G loss: 0.527371]\n",
      "epoch:3 step:3715 [D loss: 0.200015, acc.: 74.22%] [G loss: 0.614286]\n",
      "epoch:3 step:3716 [D loss: 0.200340, acc.: 65.62%] [G loss: 0.599832]\n",
      "epoch:3 step:3717 [D loss: 0.164080, acc.: 77.34%] [G loss: 0.664773]\n",
      "epoch:3 step:3718 [D loss: 0.211798, acc.: 64.84%] [G loss: 0.554234]\n",
      "epoch:3 step:3719 [D loss: 0.201206, acc.: 71.09%] [G loss: 0.581440]\n",
      "epoch:3 step:3720 [D loss: 0.159623, acc.: 76.56%] [G loss: 0.626271]\n",
      "epoch:3 step:3721 [D loss: 0.175835, acc.: 75.78%] [G loss: 0.666317]\n",
      "epoch:3 step:3722 [D loss: 0.166096, acc.: 78.12%] [G loss: 0.685659]\n",
      "epoch:3 step:3723 [D loss: 0.141448, acc.: 81.25%] [G loss: 0.691717]\n",
      "epoch:3 step:3724 [D loss: 0.204870, acc.: 65.62%] [G loss: 0.582817]\n",
      "epoch:3 step:3725 [D loss: 0.173145, acc.: 74.22%] [G loss: 0.613710]\n",
      "epoch:3 step:3726 [D loss: 0.184837, acc.: 74.22%] [G loss: 0.564393]\n",
      "epoch:3 step:3727 [D loss: 0.209158, acc.: 71.88%] [G loss: 0.556180]\n",
      "epoch:3 step:3728 [D loss: 0.225314, acc.: 65.62%] [G loss: 0.593468]\n",
      "epoch:3 step:3729 [D loss: 0.149666, acc.: 80.47%] [G loss: 0.661285]\n",
      "epoch:3 step:3730 [D loss: 0.163582, acc.: 75.78%] [G loss: 0.644009]\n",
      "epoch:3 step:3731 [D loss: 0.269891, acc.: 56.25%] [G loss: 0.556908]\n",
      "epoch:3 step:3732 [D loss: 0.164256, acc.: 76.56%] [G loss: 0.691351]\n",
      "epoch:3 step:3733 [D loss: 0.219769, acc.: 62.50%] [G loss: 0.551574]\n",
      "epoch:3 step:3734 [D loss: 0.147948, acc.: 83.59%] [G loss: 0.667405]\n",
      "epoch:3 step:3735 [D loss: 0.125443, acc.: 82.03%] [G loss: 0.721654]\n",
      "epoch:3 step:3736 [D loss: 0.141152, acc.: 81.25%] [G loss: 0.775298]\n",
      "epoch:3 step:3737 [D loss: 0.179620, acc.: 72.66%] [G loss: 0.698838]\n",
      "epoch:3 step:3738 [D loss: 0.137545, acc.: 84.38%] [G loss: 0.825273]\n",
      "epoch:3 step:3739 [D loss: 0.329885, acc.: 61.72%] [G loss: 0.569274]\n",
      "epoch:3 step:3740 [D loss: 0.141054, acc.: 81.25%] [G loss: 0.831470]\n",
      "epoch:3 step:3741 [D loss: 0.206597, acc.: 66.41%] [G loss: 0.684701]\n",
      "epoch:3 step:3742 [D loss: 0.180726, acc.: 72.66%] [G loss: 0.529694]\n",
      "epoch:3 step:3743 [D loss: 0.191019, acc.: 72.66%] [G loss: 0.572800]\n",
      "epoch:3 step:3744 [D loss: 0.170919, acc.: 79.69%] [G loss: 0.655459]\n",
      "epoch:3 step:3745 [D loss: 0.183109, acc.: 74.22%] [G loss: 0.678842]\n",
      "epoch:3 step:3746 [D loss: 0.187451, acc.: 71.88%] [G loss: 0.668763]\n",
      "epoch:3 step:3747 [D loss: 0.120645, acc.: 82.03%] [G loss: 0.701874]\n",
      "epoch:3 step:3748 [D loss: 0.117052, acc.: 82.03%] [G loss: 0.740565]\n",
      "epoch:4 step:3749 [D loss: 0.249132, acc.: 64.06%] [G loss: 0.630742]\n",
      "epoch:4 step:3750 [D loss: 0.206395, acc.: 69.53%] [G loss: 0.619942]\n",
      "epoch:4 step:3751 [D loss: 0.198179, acc.: 74.22%] [G loss: 0.594122]\n",
      "epoch:4 step:3752 [D loss: 0.208928, acc.: 67.19%] [G loss: 0.604792]\n",
      "epoch:4 step:3753 [D loss: 0.191340, acc.: 71.09%] [G loss: 0.585706]\n",
      "epoch:4 step:3754 [D loss: 0.181075, acc.: 76.56%] [G loss: 0.689908]\n",
      "epoch:4 step:3755 [D loss: 0.185039, acc.: 75.00%] [G loss: 0.617185]\n",
      "epoch:4 step:3756 [D loss: 0.225426, acc.: 67.19%] [G loss: 0.584283]\n",
      "epoch:4 step:3757 [D loss: 0.182954, acc.: 68.75%] [G loss: 0.604675]\n",
      "epoch:4 step:3758 [D loss: 0.211214, acc.: 68.75%] [G loss: 0.562175]\n",
      "epoch:4 step:3759 [D loss: 0.172588, acc.: 82.81%] [G loss: 0.585221]\n",
      "epoch:4 step:3760 [D loss: 0.214073, acc.: 66.41%] [G loss: 0.531567]\n",
      "epoch:4 step:3761 [D loss: 0.187289, acc.: 71.09%] [G loss: 0.588112]\n",
      "epoch:4 step:3762 [D loss: 0.179201, acc.: 73.44%] [G loss: 0.583809]\n",
      "epoch:4 step:3763 [D loss: 0.186477, acc.: 74.22%] [G loss: 0.606532]\n",
      "epoch:4 step:3764 [D loss: 0.186965, acc.: 72.66%] [G loss: 0.615263]\n",
      "epoch:4 step:3765 [D loss: 0.244902, acc.: 57.81%] [G loss: 0.566973]\n",
      "epoch:4 step:3766 [D loss: 0.249528, acc.: 58.59%] [G loss: 0.523168]\n",
      "epoch:4 step:3767 [D loss: 0.215115, acc.: 66.41%] [G loss: 0.602595]\n",
      "epoch:4 step:3768 [D loss: 0.215129, acc.: 65.62%] [G loss: 0.606499]\n",
      "epoch:4 step:3769 [D loss: 0.214635, acc.: 64.84%] [G loss: 0.544205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3770 [D loss: 0.182402, acc.: 76.56%] [G loss: 0.609798]\n",
      "epoch:4 step:3771 [D loss: 0.178129, acc.: 71.09%] [G loss: 0.558732]\n",
      "epoch:4 step:3772 [D loss: 0.204543, acc.: 68.75%] [G loss: 0.586849]\n",
      "epoch:4 step:3773 [D loss: 0.162790, acc.: 75.00%] [G loss: 0.637188]\n",
      "epoch:4 step:3774 [D loss: 0.201218, acc.: 72.66%] [G loss: 0.547798]\n",
      "epoch:4 step:3775 [D loss: 0.177403, acc.: 76.56%] [G loss: 0.539943]\n",
      "epoch:4 step:3776 [D loss: 0.142052, acc.: 85.16%] [G loss: 0.598100]\n",
      "epoch:4 step:3777 [D loss: 0.154790, acc.: 75.00%] [G loss: 0.625330]\n",
      "epoch:4 step:3778 [D loss: 0.204691, acc.: 71.09%] [G loss: 0.573214]\n",
      "epoch:4 step:3779 [D loss: 0.153988, acc.: 79.69%] [G loss: 0.626541]\n",
      "epoch:4 step:3780 [D loss: 0.195166, acc.: 67.97%] [G loss: 0.566808]\n",
      "epoch:4 step:3781 [D loss: 0.144843, acc.: 80.47%] [G loss: 0.641790]\n",
      "epoch:4 step:3782 [D loss: 0.166498, acc.: 74.22%] [G loss: 0.605572]\n",
      "epoch:4 step:3783 [D loss: 0.162852, acc.: 75.00%] [G loss: 0.591934]\n",
      "epoch:4 step:3784 [D loss: 0.113587, acc.: 87.50%] [G loss: 0.663647]\n",
      "epoch:4 step:3785 [D loss: 0.179307, acc.: 75.78%] [G loss: 0.634813]\n",
      "epoch:4 step:3786 [D loss: 0.199420, acc.: 73.44%] [G loss: 0.559383]\n",
      "epoch:4 step:3787 [D loss: 0.156704, acc.: 80.47%] [G loss: 0.648864]\n",
      "epoch:4 step:3788 [D loss: 0.139636, acc.: 82.03%] [G loss: 0.651424]\n",
      "epoch:4 step:3789 [D loss: 0.222469, acc.: 65.62%] [G loss: 0.590375]\n",
      "epoch:4 step:3790 [D loss: 0.176306, acc.: 74.22%] [G loss: 0.613859]\n",
      "epoch:4 step:3791 [D loss: 0.165257, acc.: 78.91%] [G loss: 0.638770]\n",
      "epoch:4 step:3792 [D loss: 0.218708, acc.: 64.84%] [G loss: 0.533981]\n",
      "epoch:4 step:3793 [D loss: 0.189123, acc.: 71.88%] [G loss: 0.556149]\n",
      "epoch:4 step:3794 [D loss: 0.197850, acc.: 75.00%] [G loss: 0.588240]\n",
      "epoch:4 step:3795 [D loss: 0.201352, acc.: 70.31%] [G loss: 0.540635]\n",
      "epoch:4 step:3796 [D loss: 0.192442, acc.: 69.53%] [G loss: 0.633958]\n",
      "epoch:4 step:3797 [D loss: 0.149109, acc.: 78.12%] [G loss: 0.593884]\n",
      "epoch:4 step:3798 [D loss: 0.187660, acc.: 69.53%] [G loss: 0.549904]\n",
      "epoch:4 step:3799 [D loss: 0.240786, acc.: 61.72%] [G loss: 0.612934]\n",
      "epoch:4 step:3800 [D loss: 0.205121, acc.: 70.31%] [G loss: 0.603905]\n",
      "epoch:4 step:3801 [D loss: 0.205169, acc.: 69.53%] [G loss: 0.610940]\n",
      "epoch:4 step:3802 [D loss: 0.180620, acc.: 73.44%] [G loss: 0.613243]\n",
      "epoch:4 step:3803 [D loss: 0.179543, acc.: 71.09%] [G loss: 0.599463]\n",
      "epoch:4 step:3804 [D loss: 0.171242, acc.: 72.66%] [G loss: 0.622351]\n",
      "epoch:4 step:3805 [D loss: 0.163522, acc.: 75.00%] [G loss: 0.619057]\n",
      "epoch:4 step:3806 [D loss: 0.197866, acc.: 70.31%] [G loss: 0.599702]\n",
      "epoch:4 step:3807 [D loss: 0.181155, acc.: 75.78%] [G loss: 0.594638]\n",
      "epoch:4 step:3808 [D loss: 0.193243, acc.: 67.97%] [G loss: 0.587955]\n",
      "epoch:4 step:3809 [D loss: 0.186640, acc.: 71.88%] [G loss: 0.590675]\n",
      "epoch:4 step:3810 [D loss: 0.174194, acc.: 74.22%] [G loss: 0.555425]\n",
      "epoch:4 step:3811 [D loss: 0.175607, acc.: 73.44%] [G loss: 0.586137]\n",
      "epoch:4 step:3812 [D loss: 0.175762, acc.: 76.56%] [G loss: 0.582604]\n",
      "epoch:4 step:3813 [D loss: 0.203243, acc.: 69.53%] [G loss: 0.584687]\n",
      "epoch:4 step:3814 [D loss: 0.198066, acc.: 67.97%] [G loss: 0.568088]\n",
      "epoch:4 step:3815 [D loss: 0.185875, acc.: 75.78%] [G loss: 0.570984]\n",
      "epoch:4 step:3816 [D loss: 0.169826, acc.: 74.22%] [G loss: 0.628003]\n",
      "epoch:4 step:3817 [D loss: 0.176068, acc.: 75.00%] [G loss: 0.620785]\n",
      "epoch:4 step:3818 [D loss: 0.177967, acc.: 72.66%] [G loss: 0.625750]\n",
      "epoch:4 step:3819 [D loss: 0.168239, acc.: 76.56%] [G loss: 0.595510]\n",
      "epoch:4 step:3820 [D loss: 0.189857, acc.: 73.44%] [G loss: 0.537786]\n",
      "epoch:4 step:3821 [D loss: 0.165446, acc.: 76.56%] [G loss: 0.585823]\n",
      "epoch:4 step:3822 [D loss: 0.144030, acc.: 78.91%] [G loss: 0.602317]\n",
      "epoch:4 step:3823 [D loss: 0.195632, acc.: 74.22%] [G loss: 0.604435]\n",
      "epoch:4 step:3824 [D loss: 0.153026, acc.: 78.91%] [G loss: 0.668730]\n",
      "epoch:4 step:3825 [D loss: 0.183823, acc.: 73.44%] [G loss: 0.615210]\n",
      "epoch:4 step:3826 [D loss: 0.238849, acc.: 56.25%] [G loss: 0.526407]\n",
      "epoch:4 step:3827 [D loss: 0.206112, acc.: 67.19%] [G loss: 0.539395]\n",
      "epoch:4 step:3828 [D loss: 0.183276, acc.: 72.66%] [G loss: 0.555081]\n",
      "epoch:4 step:3829 [D loss: 0.215745, acc.: 66.41%] [G loss: 0.601498]\n",
      "epoch:4 step:3830 [D loss: 0.169010, acc.: 74.22%] [G loss: 0.575908]\n",
      "epoch:4 step:3831 [D loss: 0.177123, acc.: 72.66%] [G loss: 0.616384]\n",
      "epoch:4 step:3832 [D loss: 0.174342, acc.: 72.66%] [G loss: 0.569451]\n",
      "epoch:4 step:3833 [D loss: 0.191755, acc.: 75.00%] [G loss: 0.574937]\n",
      "epoch:4 step:3834 [D loss: 0.186629, acc.: 71.88%] [G loss: 0.578935]\n",
      "epoch:4 step:3835 [D loss: 0.167168, acc.: 73.44%] [G loss: 0.579717]\n",
      "epoch:4 step:3836 [D loss: 0.157777, acc.: 79.69%] [G loss: 0.615924]\n",
      "epoch:4 step:3837 [D loss: 0.189373, acc.: 75.78%] [G loss: 0.536731]\n",
      "epoch:4 step:3838 [D loss: 0.165803, acc.: 78.12%] [G loss: 0.538470]\n",
      "epoch:4 step:3839 [D loss: 0.186374, acc.: 73.44%] [G loss: 0.577726]\n",
      "epoch:4 step:3840 [D loss: 0.164293, acc.: 80.47%] [G loss: 0.591369]\n",
      "epoch:4 step:3841 [D loss: 0.179915, acc.: 71.09%] [G loss: 0.593398]\n",
      "epoch:4 step:3842 [D loss: 0.171689, acc.: 71.88%] [G loss: 0.562199]\n",
      "epoch:4 step:3843 [D loss: 0.201774, acc.: 70.31%] [G loss: 0.601934]\n",
      "epoch:4 step:3844 [D loss: 0.152359, acc.: 78.91%] [G loss: 0.612699]\n",
      "epoch:4 step:3845 [D loss: 0.166714, acc.: 79.69%] [G loss: 0.674970]\n",
      "epoch:4 step:3846 [D loss: 0.213243, acc.: 69.53%] [G loss: 0.548699]\n",
      "epoch:4 step:3847 [D loss: 0.214522, acc.: 67.19%] [G loss: 0.575566]\n",
      "epoch:4 step:3848 [D loss: 0.146603, acc.: 75.78%] [G loss: 0.656793]\n",
      "epoch:4 step:3849 [D loss: 0.165121, acc.: 74.22%] [G loss: 0.655624]\n",
      "epoch:4 step:3850 [D loss: 0.203513, acc.: 67.97%] [G loss: 0.513632]\n",
      "epoch:4 step:3851 [D loss: 0.163431, acc.: 76.56%] [G loss: 0.564364]\n",
      "epoch:4 step:3852 [D loss: 0.180102, acc.: 76.56%] [G loss: 0.585222]\n",
      "epoch:4 step:3853 [D loss: 0.193579, acc.: 66.41%] [G loss: 0.541600]\n",
      "epoch:4 step:3854 [D loss: 0.165219, acc.: 76.56%] [G loss: 0.607631]\n",
      "epoch:4 step:3855 [D loss: 0.229444, acc.: 60.16%] [G loss: 0.570555]\n",
      "epoch:4 step:3856 [D loss: 0.214677, acc.: 65.62%] [G loss: 0.589338]\n",
      "epoch:4 step:3857 [D loss: 0.219914, acc.: 64.06%] [G loss: 0.583757]\n",
      "epoch:4 step:3858 [D loss: 0.192432, acc.: 63.28%] [G loss: 0.554900]\n",
      "epoch:4 step:3859 [D loss: 0.175030, acc.: 69.53%] [G loss: 0.573073]\n",
      "epoch:4 step:3860 [D loss: 0.200169, acc.: 69.53%] [G loss: 0.579671]\n",
      "epoch:4 step:3861 [D loss: 0.189689, acc.: 71.88%] [G loss: 0.589286]\n",
      "epoch:4 step:3862 [D loss: 0.188423, acc.: 75.00%] [G loss: 0.590738]\n",
      "epoch:4 step:3863 [D loss: 0.209179, acc.: 67.97%] [G loss: 0.599467]\n",
      "epoch:4 step:3864 [D loss: 0.178217, acc.: 68.75%] [G loss: 0.655927]\n",
      "epoch:4 step:3865 [D loss: 0.215531, acc.: 65.62%] [G loss: 0.596992]\n",
      "epoch:4 step:3866 [D loss: 0.189197, acc.: 71.88%] [G loss: 0.584548]\n",
      "epoch:4 step:3867 [D loss: 0.174205, acc.: 75.00%] [G loss: 0.623772]\n",
      "epoch:4 step:3868 [D loss: 0.274265, acc.: 60.16%] [G loss: 0.549992]\n",
      "epoch:4 step:3869 [D loss: 0.175377, acc.: 76.56%] [G loss: 0.641438]\n",
      "epoch:4 step:3870 [D loss: 0.169784, acc.: 77.34%] [G loss: 0.656475]\n",
      "epoch:4 step:3871 [D loss: 0.171791, acc.: 76.56%] [G loss: 0.647673]\n",
      "epoch:4 step:3872 [D loss: 0.203981, acc.: 69.53%] [G loss: 0.521850]\n",
      "epoch:4 step:3873 [D loss: 0.198668, acc.: 69.53%] [G loss: 0.548517]\n",
      "epoch:4 step:3874 [D loss: 0.174188, acc.: 75.78%] [G loss: 0.625200]\n",
      "epoch:4 step:3875 [D loss: 0.196338, acc.: 71.88%] [G loss: 0.581128]\n",
      "epoch:4 step:3876 [D loss: 0.200932, acc.: 64.84%] [G loss: 0.530568]\n",
      "epoch:4 step:3877 [D loss: 0.224645, acc.: 68.75%] [G loss: 0.543059]\n",
      "epoch:4 step:3878 [D loss: 0.193465, acc.: 71.88%] [G loss: 0.541472]\n",
      "epoch:4 step:3879 [D loss: 0.176969, acc.: 75.78%] [G loss: 0.637500]\n",
      "epoch:4 step:3880 [D loss: 0.198041, acc.: 67.97%] [G loss: 0.603900]\n",
      "epoch:4 step:3881 [D loss: 0.239027, acc.: 59.38%] [G loss: 0.529335]\n",
      "epoch:4 step:3882 [D loss: 0.191387, acc.: 68.75%] [G loss: 0.625058]\n",
      "epoch:4 step:3883 [D loss: 0.180599, acc.: 75.00%] [G loss: 0.627499]\n",
      "epoch:4 step:3884 [D loss: 0.217329, acc.: 62.50%] [G loss: 0.543796]\n",
      "epoch:4 step:3885 [D loss: 0.214584, acc.: 67.97%] [G loss: 0.545178]\n",
      "epoch:4 step:3886 [D loss: 0.207749, acc.: 67.97%] [G loss: 0.553961]\n",
      "epoch:4 step:3887 [D loss: 0.201584, acc.: 67.97%] [G loss: 0.590177]\n",
      "epoch:4 step:3888 [D loss: 0.177869, acc.: 70.31%] [G loss: 0.539320]\n",
      "epoch:4 step:3889 [D loss: 0.163573, acc.: 75.00%] [G loss: 0.555644]\n",
      "epoch:4 step:3890 [D loss: 0.181944, acc.: 71.09%] [G loss: 0.559034]\n",
      "epoch:4 step:3891 [D loss: 0.205639, acc.: 68.75%] [G loss: 0.519740]\n",
      "epoch:4 step:3892 [D loss: 0.152418, acc.: 74.22%] [G loss: 0.621720]\n",
      "epoch:4 step:3893 [D loss: 0.182882, acc.: 71.88%] [G loss: 0.605415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3894 [D loss: 0.203941, acc.: 70.31%] [G loss: 0.610719]\n",
      "epoch:4 step:3895 [D loss: 0.210476, acc.: 69.53%] [G loss: 0.542171]\n",
      "epoch:4 step:3896 [D loss: 0.194773, acc.: 71.09%] [G loss: 0.570004]\n",
      "epoch:4 step:3897 [D loss: 0.168175, acc.: 73.44%] [G loss: 0.626689]\n",
      "epoch:4 step:3898 [D loss: 0.224418, acc.: 66.41%] [G loss: 0.549324]\n",
      "epoch:4 step:3899 [D loss: 0.143960, acc.: 81.25%] [G loss: 0.643170]\n",
      "epoch:4 step:3900 [D loss: 0.187147, acc.: 75.00%] [G loss: 0.657111]\n",
      "epoch:4 step:3901 [D loss: 0.190297, acc.: 69.53%] [G loss: 0.624262]\n",
      "epoch:4 step:3902 [D loss: 0.190216, acc.: 67.19%] [G loss: 0.569045]\n",
      "epoch:4 step:3903 [D loss: 0.186809, acc.: 71.88%] [G loss: 0.592192]\n",
      "epoch:4 step:3904 [D loss: 0.188004, acc.: 69.53%] [G loss: 0.591840]\n",
      "epoch:4 step:3905 [D loss: 0.204546, acc.: 65.62%] [G loss: 0.548254]\n",
      "epoch:4 step:3906 [D loss: 0.198064, acc.: 68.75%] [G loss: 0.535734]\n",
      "epoch:4 step:3907 [D loss: 0.177337, acc.: 78.12%] [G loss: 0.604117]\n",
      "epoch:4 step:3908 [D loss: 0.243286, acc.: 64.06%] [G loss: 0.533488]\n",
      "epoch:4 step:3909 [D loss: 0.159754, acc.: 75.00%] [G loss: 0.598387]\n",
      "epoch:4 step:3910 [D loss: 0.172371, acc.: 76.56%] [G loss: 0.619142]\n",
      "epoch:4 step:3911 [D loss: 0.174102, acc.: 71.09%] [G loss: 0.618415]\n",
      "epoch:4 step:3912 [D loss: 0.187405, acc.: 74.22%] [G loss: 0.562821]\n",
      "epoch:4 step:3913 [D loss: 0.189590, acc.: 74.22%] [G loss: 0.547304]\n",
      "epoch:4 step:3914 [D loss: 0.152199, acc.: 78.12%] [G loss: 0.596489]\n",
      "epoch:4 step:3915 [D loss: 0.174545, acc.: 70.31%] [G loss: 0.611696]\n",
      "epoch:4 step:3916 [D loss: 0.163757, acc.: 76.56%] [G loss: 0.528623]\n",
      "epoch:4 step:3917 [D loss: 0.204423, acc.: 67.97%] [G loss: 0.532807]\n",
      "epoch:4 step:3918 [D loss: 0.195681, acc.: 72.66%] [G loss: 0.546057]\n",
      "epoch:4 step:3919 [D loss: 0.198064, acc.: 66.41%] [G loss: 0.572130]\n",
      "epoch:4 step:3920 [D loss: 0.159285, acc.: 75.00%] [G loss: 0.663688]\n",
      "epoch:4 step:3921 [D loss: 0.166044, acc.: 77.34%] [G loss: 0.590061]\n",
      "epoch:4 step:3922 [D loss: 0.207956, acc.: 68.75%] [G loss: 0.572436]\n",
      "epoch:4 step:3923 [D loss: 0.202806, acc.: 68.75%] [G loss: 0.523530]\n",
      "epoch:4 step:3924 [D loss: 0.193008, acc.: 71.09%] [G loss: 0.562465]\n",
      "epoch:4 step:3925 [D loss: 0.188260, acc.: 72.66%] [G loss: 0.554664]\n",
      "epoch:4 step:3926 [D loss: 0.176724, acc.: 71.88%] [G loss: 0.558661]\n",
      "epoch:4 step:3927 [D loss: 0.184175, acc.: 75.78%] [G loss: 0.547627]\n",
      "epoch:4 step:3928 [D loss: 0.170974, acc.: 76.56%] [G loss: 0.593692]\n",
      "epoch:4 step:3929 [D loss: 0.171097, acc.: 73.44%] [G loss: 0.651974]\n",
      "epoch:4 step:3930 [D loss: 0.217554, acc.: 64.84%] [G loss: 0.578653]\n",
      "epoch:4 step:3931 [D loss: 0.191562, acc.: 69.53%] [G loss: 0.640704]\n",
      "epoch:4 step:3932 [D loss: 0.194895, acc.: 74.22%] [G loss: 0.561931]\n",
      "epoch:4 step:3933 [D loss: 0.202506, acc.: 70.31%] [G loss: 0.540190]\n",
      "epoch:4 step:3934 [D loss: 0.212104, acc.: 64.84%] [G loss: 0.600923]\n",
      "epoch:4 step:3935 [D loss: 0.228024, acc.: 63.28%] [G loss: 0.574649]\n",
      "epoch:4 step:3936 [D loss: 0.212236, acc.: 67.97%] [G loss: 0.576147]\n",
      "epoch:4 step:3937 [D loss: 0.218419, acc.: 63.28%] [G loss: 0.568175]\n",
      "epoch:4 step:3938 [D loss: 0.169208, acc.: 70.31%] [G loss: 0.605476]\n",
      "epoch:4 step:3939 [D loss: 0.198315, acc.: 72.66%] [G loss: 0.590063]\n",
      "epoch:4 step:3940 [D loss: 0.184495, acc.: 75.00%] [G loss: 0.595086]\n",
      "epoch:4 step:3941 [D loss: 0.180991, acc.: 73.44%] [G loss: 0.562060]\n",
      "epoch:4 step:3942 [D loss: 0.165645, acc.: 76.56%] [G loss: 0.581045]\n",
      "epoch:4 step:3943 [D loss: 0.179065, acc.: 69.53%] [G loss: 0.619352]\n",
      "epoch:4 step:3944 [D loss: 0.203040, acc.: 69.53%] [G loss: 0.595947]\n",
      "epoch:4 step:3945 [D loss: 0.160275, acc.: 74.22%] [G loss: 0.556675]\n",
      "epoch:4 step:3946 [D loss: 0.164485, acc.: 76.56%] [G loss: 0.631205]\n",
      "epoch:4 step:3947 [D loss: 0.184498, acc.: 71.88%] [G loss: 0.588923]\n",
      "epoch:4 step:3948 [D loss: 0.250166, acc.: 55.47%] [G loss: 0.525341]\n",
      "epoch:4 step:3949 [D loss: 0.194660, acc.: 66.41%] [G loss: 0.567274]\n",
      "epoch:4 step:3950 [D loss: 0.185770, acc.: 69.53%] [G loss: 0.597120]\n",
      "epoch:4 step:3951 [D loss: 0.234517, acc.: 64.06%] [G loss: 0.531320]\n",
      "epoch:4 step:3952 [D loss: 0.198922, acc.: 77.34%] [G loss: 0.571625]\n",
      "epoch:4 step:3953 [D loss: 0.219373, acc.: 70.31%] [G loss: 0.569787]\n",
      "epoch:4 step:3954 [D loss: 0.184789, acc.: 68.75%] [G loss: 0.634836]\n",
      "epoch:4 step:3955 [D loss: 0.164411, acc.: 80.47%] [G loss: 0.643594]\n",
      "epoch:4 step:3956 [D loss: 0.136743, acc.: 80.47%] [G loss: 0.660331]\n",
      "epoch:4 step:3957 [D loss: 0.185624, acc.: 71.88%] [G loss: 0.595338]\n",
      "epoch:4 step:3958 [D loss: 0.199866, acc.: 70.31%] [G loss: 0.574723]\n",
      "epoch:4 step:3959 [D loss: 0.216092, acc.: 68.75%] [G loss: 0.564223]\n",
      "epoch:4 step:3960 [D loss: 0.192494, acc.: 71.88%] [G loss: 0.577850]\n",
      "epoch:4 step:3961 [D loss: 0.186080, acc.: 72.66%] [G loss: 0.594124]\n",
      "epoch:4 step:3962 [D loss: 0.223388, acc.: 61.72%] [G loss: 0.583992]\n",
      "epoch:4 step:3963 [D loss: 0.249232, acc.: 61.72%] [G loss: 0.558747]\n",
      "epoch:4 step:3964 [D loss: 0.168028, acc.: 74.22%] [G loss: 0.681076]\n",
      "epoch:4 step:3965 [D loss: 0.199866, acc.: 70.31%] [G loss: 0.613451]\n",
      "epoch:4 step:3966 [D loss: 0.193431, acc.: 69.53%] [G loss: 0.593320]\n",
      "epoch:4 step:3967 [D loss: 0.170337, acc.: 78.91%] [G loss: 0.595611]\n",
      "epoch:4 step:3968 [D loss: 0.253880, acc.: 55.47%] [G loss: 0.533250]\n",
      "epoch:4 step:3969 [D loss: 0.168938, acc.: 75.78%] [G loss: 0.609974]\n",
      "epoch:4 step:3970 [D loss: 0.164445, acc.: 77.34%] [G loss: 0.675945]\n",
      "epoch:4 step:3971 [D loss: 0.157807, acc.: 82.81%] [G loss: 0.668040]\n",
      "epoch:4 step:3972 [D loss: 0.206306, acc.: 63.28%] [G loss: 0.575444]\n",
      "epoch:4 step:3973 [D loss: 0.241986, acc.: 60.16%] [G loss: 0.507020]\n",
      "epoch:4 step:3974 [D loss: 0.211536, acc.: 62.50%] [G loss: 0.526801]\n",
      "epoch:4 step:3975 [D loss: 0.199226, acc.: 68.75%] [G loss: 0.530850]\n",
      "epoch:4 step:3976 [D loss: 0.213014, acc.: 64.06%] [G loss: 0.520803]\n",
      "epoch:4 step:3977 [D loss: 0.195511, acc.: 70.31%] [G loss: 0.534501]\n",
      "epoch:4 step:3978 [D loss: 0.177534, acc.: 71.88%] [G loss: 0.609918]\n",
      "epoch:4 step:3979 [D loss: 0.164730, acc.: 81.25%] [G loss: 0.704132]\n",
      "epoch:4 step:3980 [D loss: 0.148479, acc.: 78.12%] [G loss: 0.667796]\n",
      "epoch:4 step:3981 [D loss: 0.232988, acc.: 70.31%] [G loss: 0.595927]\n",
      "epoch:4 step:3982 [D loss: 0.190498, acc.: 74.22%] [G loss: 0.566475]\n",
      "epoch:4 step:3983 [D loss: 0.217002, acc.: 67.19%] [G loss: 0.547327]\n",
      "epoch:4 step:3984 [D loss: 0.151870, acc.: 78.91%] [G loss: 0.616564]\n",
      "epoch:4 step:3985 [D loss: 0.193584, acc.: 72.66%] [G loss: 0.548068]\n",
      "epoch:4 step:3986 [D loss: 0.223305, acc.: 68.75%] [G loss: 0.583468]\n",
      "epoch:4 step:3987 [D loss: 0.181288, acc.: 73.44%] [G loss: 0.583529]\n",
      "epoch:4 step:3988 [D loss: 0.178762, acc.: 71.09%] [G loss: 0.629765]\n",
      "epoch:4 step:3989 [D loss: 0.209709, acc.: 65.62%] [G loss: 0.578780]\n",
      "epoch:4 step:3990 [D loss: 0.216684, acc.: 68.75%] [G loss: 0.582647]\n",
      "epoch:4 step:3991 [D loss: 0.171444, acc.: 78.12%] [G loss: 0.591010]\n",
      "epoch:4 step:3992 [D loss: 0.220826, acc.: 65.62%] [G loss: 0.541570]\n",
      "epoch:4 step:3993 [D loss: 0.156455, acc.: 75.78%] [G loss: 0.612870]\n",
      "epoch:4 step:3994 [D loss: 0.216544, acc.: 63.28%] [G loss: 0.536217]\n",
      "epoch:4 step:3995 [D loss: 0.185988, acc.: 73.44%] [G loss: 0.590495]\n",
      "epoch:4 step:3996 [D loss: 0.173863, acc.: 76.56%] [G loss: 0.576850]\n",
      "epoch:4 step:3997 [D loss: 0.195783, acc.: 67.97%] [G loss: 0.589758]\n",
      "epoch:4 step:3998 [D loss: 0.250486, acc.: 57.81%] [G loss: 0.571813]\n",
      "epoch:4 step:3999 [D loss: 0.200626, acc.: 66.41%] [G loss: 0.575723]\n",
      "epoch:4 step:4000 [D loss: 0.228267, acc.: 65.62%] [G loss: 0.529517]\n",
      "epoch:4 step:4001 [D loss: 0.178919, acc.: 74.22%] [G loss: 0.569965]\n",
      "epoch:4 step:4002 [D loss: 0.196594, acc.: 70.31%] [G loss: 0.649398]\n",
      "epoch:4 step:4003 [D loss: 0.178666, acc.: 70.31%] [G loss: 0.577395]\n",
      "epoch:4 step:4004 [D loss: 0.167808, acc.: 75.00%] [G loss: 0.585014]\n",
      "epoch:4 step:4005 [D loss: 0.182565, acc.: 75.00%] [G loss: 0.570677]\n",
      "epoch:4 step:4006 [D loss: 0.193779, acc.: 72.66%] [G loss: 0.581304]\n",
      "epoch:4 step:4007 [D loss: 0.176716, acc.: 75.00%] [G loss: 0.611242]\n",
      "epoch:4 step:4008 [D loss: 0.217026, acc.: 62.50%] [G loss: 0.583780]\n",
      "epoch:4 step:4009 [D loss: 0.184346, acc.: 70.31%] [G loss: 0.563106]\n",
      "epoch:4 step:4010 [D loss: 0.202978, acc.: 67.19%] [G loss: 0.552124]\n",
      "epoch:4 step:4011 [D loss: 0.228089, acc.: 64.84%] [G loss: 0.567965]\n",
      "epoch:4 step:4012 [D loss: 0.164488, acc.: 75.00%] [G loss: 0.620462]\n",
      "epoch:4 step:4013 [D loss: 0.228695, acc.: 66.41%] [G loss: 0.506426]\n",
      "epoch:4 step:4014 [D loss: 0.180283, acc.: 71.88%] [G loss: 0.546936]\n",
      "epoch:4 step:4015 [D loss: 0.179742, acc.: 75.00%] [G loss: 0.573820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4016 [D loss: 0.180749, acc.: 73.44%] [G loss: 0.596476]\n",
      "epoch:4 step:4017 [D loss: 0.191815, acc.: 75.00%] [G loss: 0.550320]\n",
      "epoch:4 step:4018 [D loss: 0.169864, acc.: 72.66%] [G loss: 0.614243]\n",
      "epoch:4 step:4019 [D loss: 0.147400, acc.: 82.03%] [G loss: 0.609450]\n",
      "epoch:4 step:4020 [D loss: 0.188917, acc.: 69.53%] [G loss: 0.641180]\n",
      "epoch:4 step:4021 [D loss: 0.211673, acc.: 64.06%] [G loss: 0.572880]\n",
      "epoch:4 step:4022 [D loss: 0.204612, acc.: 71.88%] [G loss: 0.551889]\n",
      "epoch:4 step:4023 [D loss: 0.227055, acc.: 63.28%] [G loss: 0.581519]\n",
      "epoch:4 step:4024 [D loss: 0.207931, acc.: 67.19%] [G loss: 0.543945]\n",
      "epoch:4 step:4025 [D loss: 0.248926, acc.: 59.38%] [G loss: 0.560628]\n",
      "epoch:4 step:4026 [D loss: 0.206380, acc.: 71.88%] [G loss: 0.570697]\n",
      "epoch:4 step:4027 [D loss: 0.198423, acc.: 72.66%] [G loss: 0.548683]\n",
      "epoch:4 step:4028 [D loss: 0.173078, acc.: 74.22%] [G loss: 0.611872]\n",
      "epoch:4 step:4029 [D loss: 0.256992, acc.: 62.50%] [G loss: 0.492780]\n",
      "epoch:4 step:4030 [D loss: 0.188675, acc.: 71.09%] [G loss: 0.520276]\n",
      "epoch:4 step:4031 [D loss: 0.164646, acc.: 75.78%] [G loss: 0.592585]\n",
      "epoch:4 step:4032 [D loss: 0.186987, acc.: 79.69%] [G loss: 0.552848]\n",
      "epoch:4 step:4033 [D loss: 0.178420, acc.: 73.44%] [G loss: 0.558696]\n",
      "epoch:4 step:4034 [D loss: 0.156714, acc.: 78.12%] [G loss: 0.577250]\n",
      "epoch:4 step:4035 [D loss: 0.226431, acc.: 63.28%] [G loss: 0.583016]\n",
      "epoch:4 step:4036 [D loss: 0.209731, acc.: 72.66%] [G loss: 0.616911]\n",
      "epoch:4 step:4037 [D loss: 0.173860, acc.: 73.44%] [G loss: 0.596061]\n",
      "epoch:4 step:4038 [D loss: 0.182721, acc.: 72.66%] [G loss: 0.568317]\n",
      "epoch:4 step:4039 [D loss: 0.188149, acc.: 72.66%] [G loss: 0.529448]\n",
      "epoch:4 step:4040 [D loss: 0.224057, acc.: 65.62%] [G loss: 0.538676]\n",
      "epoch:4 step:4041 [D loss: 0.182444, acc.: 73.44%] [G loss: 0.574248]\n",
      "epoch:4 step:4042 [D loss: 0.201650, acc.: 66.41%] [G loss: 0.588304]\n",
      "epoch:4 step:4043 [D loss: 0.193727, acc.: 69.53%] [G loss: 0.638361]\n",
      "epoch:4 step:4044 [D loss: 0.163149, acc.: 76.56%] [G loss: 0.690592]\n",
      "epoch:4 step:4045 [D loss: 0.223245, acc.: 65.62%] [G loss: 0.546397]\n",
      "epoch:4 step:4046 [D loss: 0.182281, acc.: 72.66%] [G loss: 0.550986]\n",
      "epoch:4 step:4047 [D loss: 0.194415, acc.: 71.88%] [G loss: 0.542612]\n",
      "epoch:4 step:4048 [D loss: 0.183106, acc.: 71.09%] [G loss: 0.577538]\n",
      "epoch:4 step:4049 [D loss: 0.212142, acc.: 66.41%] [G loss: 0.585975]\n",
      "epoch:4 step:4050 [D loss: 0.204933, acc.: 67.19%] [G loss: 0.548722]\n",
      "epoch:4 step:4051 [D loss: 0.167902, acc.: 73.44%] [G loss: 0.556283]\n",
      "epoch:4 step:4052 [D loss: 0.162849, acc.: 76.56%] [G loss: 0.552699]\n",
      "epoch:4 step:4053 [D loss: 0.156936, acc.: 79.69%] [G loss: 0.613584]\n",
      "epoch:4 step:4054 [D loss: 0.200583, acc.: 69.53%] [G loss: 0.604039]\n",
      "epoch:4 step:4055 [D loss: 0.172287, acc.: 76.56%] [G loss: 0.606833]\n",
      "epoch:4 step:4056 [D loss: 0.188696, acc.: 71.09%] [G loss: 0.561801]\n",
      "epoch:4 step:4057 [D loss: 0.157251, acc.: 80.47%] [G loss: 0.597671]\n",
      "epoch:4 step:4058 [D loss: 0.212831, acc.: 67.19%] [G loss: 0.543486]\n",
      "epoch:4 step:4059 [D loss: 0.185661, acc.: 71.88%] [G loss: 0.588663]\n",
      "epoch:4 step:4060 [D loss: 0.149116, acc.: 78.91%] [G loss: 0.711022]\n",
      "epoch:4 step:4061 [D loss: 0.178824, acc.: 71.88%] [G loss: 0.665144]\n",
      "epoch:4 step:4062 [D loss: 0.153592, acc.: 82.81%] [G loss: 0.639318]\n",
      "epoch:4 step:4063 [D loss: 0.155113, acc.: 81.25%] [G loss: 0.617177]\n",
      "epoch:4 step:4064 [D loss: 0.219313, acc.: 67.97%] [G loss: 0.540118]\n",
      "epoch:4 step:4065 [D loss: 0.190945, acc.: 67.19%] [G loss: 0.500118]\n",
      "epoch:4 step:4066 [D loss: 0.187870, acc.: 70.31%] [G loss: 0.548101]\n",
      "epoch:4 step:4067 [D loss: 0.203581, acc.: 65.62%] [G loss: 0.557759]\n",
      "epoch:4 step:4068 [D loss: 0.192597, acc.: 73.44%] [G loss: 0.565723]\n",
      "epoch:4 step:4069 [D loss: 0.136541, acc.: 83.59%] [G loss: 0.601497]\n",
      "epoch:4 step:4070 [D loss: 0.202118, acc.: 71.09%] [G loss: 0.546386]\n",
      "epoch:4 step:4071 [D loss: 0.215916, acc.: 69.53%] [G loss: 0.599540]\n",
      "epoch:4 step:4072 [D loss: 0.178440, acc.: 76.56%] [G loss: 0.579780]\n",
      "epoch:4 step:4073 [D loss: 0.170742, acc.: 75.78%] [G loss: 0.605175]\n",
      "epoch:4 step:4074 [D loss: 0.181477, acc.: 74.22%] [G loss: 0.553460]\n",
      "epoch:4 step:4075 [D loss: 0.179077, acc.: 74.22%] [G loss: 0.563961]\n",
      "epoch:4 step:4076 [D loss: 0.172380, acc.: 80.47%] [G loss: 0.607951]\n",
      "epoch:4 step:4077 [D loss: 0.203344, acc.: 68.75%] [G loss: 0.632557]\n",
      "epoch:4 step:4078 [D loss: 0.175347, acc.: 75.78%] [G loss: 0.574717]\n",
      "epoch:4 step:4079 [D loss: 0.182631, acc.: 71.09%] [G loss: 0.582844]\n",
      "epoch:4 step:4080 [D loss: 0.151813, acc.: 82.81%] [G loss: 0.611626]\n",
      "epoch:4 step:4081 [D loss: 0.178392, acc.: 74.22%] [G loss: 0.597724]\n",
      "epoch:4 step:4082 [D loss: 0.222925, acc.: 67.19%] [G loss: 0.556488]\n",
      "epoch:4 step:4083 [D loss: 0.197149, acc.: 68.75%] [G loss: 0.587596]\n",
      "epoch:4 step:4084 [D loss: 0.180184, acc.: 75.00%] [G loss: 0.615279]\n",
      "epoch:4 step:4085 [D loss: 0.164789, acc.: 75.78%] [G loss: 0.649843]\n",
      "epoch:4 step:4086 [D loss: 0.188905, acc.: 75.00%] [G loss: 0.581416]\n",
      "epoch:4 step:4087 [D loss: 0.153571, acc.: 76.56%] [G loss: 0.617609]\n",
      "epoch:4 step:4088 [D loss: 0.172452, acc.: 75.00%] [G loss: 0.642182]\n",
      "epoch:4 step:4089 [D loss: 0.224569, acc.: 68.75%] [G loss: 0.521891]\n",
      "epoch:4 step:4090 [D loss: 0.206883, acc.: 70.31%] [G loss: 0.556515]\n",
      "epoch:4 step:4091 [D loss: 0.123517, acc.: 82.03%] [G loss: 0.711700]\n",
      "epoch:4 step:4092 [D loss: 0.153437, acc.: 78.12%] [G loss: 0.617774]\n",
      "epoch:4 step:4093 [D loss: 0.177791, acc.: 78.91%] [G loss: 0.617819]\n",
      "epoch:4 step:4094 [D loss: 0.178592, acc.: 75.78%] [G loss: 0.618319]\n",
      "epoch:4 step:4095 [D loss: 0.168648, acc.: 76.56%] [G loss: 0.643000]\n",
      "epoch:4 step:4096 [D loss: 0.265264, acc.: 62.50%] [G loss: 0.545441]\n",
      "epoch:4 step:4097 [D loss: 0.250387, acc.: 57.03%] [G loss: 0.524428]\n",
      "epoch:4 step:4098 [D loss: 0.162680, acc.: 75.00%] [G loss: 0.571132]\n",
      "epoch:4 step:4099 [D loss: 0.174676, acc.: 74.22%] [G loss: 0.598897]\n",
      "epoch:4 step:4100 [D loss: 0.240716, acc.: 65.62%] [G loss: 0.540419]\n",
      "epoch:4 step:4101 [D loss: 0.189833, acc.: 68.75%] [G loss: 0.566589]\n",
      "epoch:4 step:4102 [D loss: 0.176452, acc.: 75.78%] [G loss: 0.564641]\n",
      "epoch:4 step:4103 [D loss: 0.216977, acc.: 63.28%] [G loss: 0.548036]\n",
      "epoch:4 step:4104 [D loss: 0.208402, acc.: 68.75%] [G loss: 0.528135]\n",
      "epoch:4 step:4105 [D loss: 0.170213, acc.: 75.78%] [G loss: 0.587907]\n",
      "epoch:4 step:4106 [D loss: 0.181204, acc.: 72.66%] [G loss: 0.542305]\n",
      "epoch:4 step:4107 [D loss: 0.179805, acc.: 74.22%] [G loss: 0.620898]\n",
      "epoch:4 step:4108 [D loss: 0.182417, acc.: 75.00%] [G loss: 0.602619]\n",
      "epoch:4 step:4109 [D loss: 0.204507, acc.: 67.97%] [G loss: 0.528730]\n",
      "epoch:4 step:4110 [D loss: 0.203299, acc.: 69.53%] [G loss: 0.504690]\n",
      "epoch:4 step:4111 [D loss: 0.176029, acc.: 78.12%] [G loss: 0.595569]\n",
      "epoch:4 step:4112 [D loss: 0.208435, acc.: 67.97%] [G loss: 0.542749]\n",
      "epoch:4 step:4113 [D loss: 0.172604, acc.: 75.00%] [G loss: 0.560164]\n",
      "epoch:4 step:4114 [D loss: 0.167781, acc.: 75.78%] [G loss: 0.557276]\n",
      "epoch:4 step:4115 [D loss: 0.192621, acc.: 71.09%] [G loss: 0.557117]\n",
      "epoch:4 step:4116 [D loss: 0.189251, acc.: 70.31%] [G loss: 0.568793]\n",
      "epoch:4 step:4117 [D loss: 0.186301, acc.: 72.66%] [G loss: 0.577089]\n",
      "epoch:4 step:4118 [D loss: 0.195287, acc.: 70.31%] [G loss: 0.582600]\n",
      "epoch:4 step:4119 [D loss: 0.213304, acc.: 64.06%] [G loss: 0.610416]\n",
      "epoch:4 step:4120 [D loss: 0.175498, acc.: 72.66%] [G loss: 0.648024]\n",
      "epoch:4 step:4121 [D loss: 0.196022, acc.: 67.19%] [G loss: 0.576486]\n",
      "epoch:4 step:4122 [D loss: 0.176702, acc.: 75.78%] [G loss: 0.539689]\n",
      "epoch:4 step:4123 [D loss: 0.227043, acc.: 66.41%] [G loss: 0.550448]\n",
      "epoch:4 step:4124 [D loss: 0.240662, acc.: 60.16%] [G loss: 0.527790]\n",
      "epoch:4 step:4125 [D loss: 0.239344, acc.: 62.50%] [G loss: 0.510374]\n",
      "epoch:4 step:4126 [D loss: 0.175411, acc.: 77.34%] [G loss: 0.570635]\n",
      "epoch:4 step:4127 [D loss: 0.168379, acc.: 77.34%] [G loss: 0.548286]\n",
      "epoch:4 step:4128 [D loss: 0.234276, acc.: 64.84%] [G loss: 0.539974]\n",
      "epoch:4 step:4129 [D loss: 0.159030, acc.: 78.12%] [G loss: 0.632329]\n",
      "epoch:4 step:4130 [D loss: 0.191495, acc.: 71.09%] [G loss: 0.588288]\n",
      "epoch:4 step:4131 [D loss: 0.236567, acc.: 62.50%] [G loss: 0.543011]\n",
      "epoch:4 step:4132 [D loss: 0.188967, acc.: 70.31%] [G loss: 0.524529]\n",
      "epoch:4 step:4133 [D loss: 0.198004, acc.: 68.75%] [G loss: 0.570590]\n",
      "epoch:4 step:4134 [D loss: 0.208923, acc.: 70.31%] [G loss: 0.558132]\n",
      "epoch:4 step:4135 [D loss: 0.204309, acc.: 69.53%] [G loss: 0.559208]\n",
      "epoch:4 step:4136 [D loss: 0.172084, acc.: 76.56%] [G loss: 0.594561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4137 [D loss: 0.234102, acc.: 62.50%] [G loss: 0.514864]\n",
      "epoch:4 step:4138 [D loss: 0.201638, acc.: 65.62%] [G loss: 0.522400]\n",
      "epoch:4 step:4139 [D loss: 0.163488, acc.: 80.47%] [G loss: 0.578208]\n",
      "epoch:4 step:4140 [D loss: 0.178559, acc.: 71.88%] [G loss: 0.619369]\n",
      "epoch:4 step:4141 [D loss: 0.211102, acc.: 65.62%] [G loss: 0.552640]\n",
      "epoch:4 step:4142 [D loss: 0.188836, acc.: 71.88%] [G loss: 0.563050]\n",
      "epoch:4 step:4143 [D loss: 0.217647, acc.: 65.62%] [G loss: 0.537519]\n",
      "epoch:4 step:4144 [D loss: 0.218253, acc.: 64.84%] [G loss: 0.566019]\n",
      "epoch:4 step:4145 [D loss: 0.175307, acc.: 71.09%] [G loss: 0.599418]\n",
      "epoch:4 step:4146 [D loss: 0.175906, acc.: 71.88%] [G loss: 0.665857]\n",
      "epoch:4 step:4147 [D loss: 0.170889, acc.: 75.78%] [G loss: 0.652856]\n",
      "epoch:4 step:4148 [D loss: 0.231691, acc.: 66.41%] [G loss: 0.505934]\n",
      "epoch:4 step:4149 [D loss: 0.206192, acc.: 71.88%] [G loss: 0.517624]\n",
      "epoch:4 step:4150 [D loss: 0.173051, acc.: 74.22%] [G loss: 0.618180]\n",
      "epoch:4 step:4151 [D loss: 0.179916, acc.: 71.09%] [G loss: 0.573235]\n",
      "epoch:4 step:4152 [D loss: 0.242270, acc.: 60.94%] [G loss: 0.502366]\n",
      "epoch:4 step:4153 [D loss: 0.187534, acc.: 72.66%] [G loss: 0.576744]\n",
      "epoch:4 step:4154 [D loss: 0.164272, acc.: 75.00%] [G loss: 0.679828]\n",
      "epoch:4 step:4155 [D loss: 0.220980, acc.: 64.06%] [G loss: 0.573645]\n",
      "epoch:4 step:4156 [D loss: 0.235743, acc.: 64.84%] [G loss: 0.549003]\n",
      "epoch:4 step:4157 [D loss: 0.175143, acc.: 75.78%] [G loss: 0.623425]\n",
      "epoch:4 step:4158 [D loss: 0.228973, acc.: 69.53%] [G loss: 0.571658]\n",
      "epoch:4 step:4159 [D loss: 0.220780, acc.: 62.50%] [G loss: 0.547883]\n",
      "epoch:4 step:4160 [D loss: 0.208069, acc.: 67.19%] [G loss: 0.534770]\n",
      "epoch:4 step:4161 [D loss: 0.228868, acc.: 63.28%] [G loss: 0.526488]\n",
      "epoch:4 step:4162 [D loss: 0.188673, acc.: 71.88%] [G loss: 0.541771]\n",
      "epoch:4 step:4163 [D loss: 0.185658, acc.: 74.22%] [G loss: 0.603722]\n",
      "epoch:4 step:4164 [D loss: 0.181007, acc.: 71.09%] [G loss: 0.539801]\n",
      "epoch:4 step:4165 [D loss: 0.238900, acc.: 57.81%] [G loss: 0.543922]\n",
      "epoch:4 step:4166 [D loss: 0.238636, acc.: 64.06%] [G loss: 0.517744]\n",
      "epoch:4 step:4167 [D loss: 0.195380, acc.: 72.66%] [G loss: 0.559281]\n",
      "epoch:4 step:4168 [D loss: 0.206743, acc.: 67.97%] [G loss: 0.544106]\n",
      "epoch:4 step:4169 [D loss: 0.265142, acc.: 52.34%] [G loss: 0.530234]\n",
      "epoch:4 step:4170 [D loss: 0.256942, acc.: 54.69%] [G loss: 0.506969]\n",
      "epoch:4 step:4171 [D loss: 0.206082, acc.: 71.88%] [G loss: 0.523245]\n",
      "epoch:4 step:4172 [D loss: 0.214394, acc.: 65.62%] [G loss: 0.517617]\n",
      "epoch:4 step:4173 [D loss: 0.194116, acc.: 74.22%] [G loss: 0.578031]\n",
      "epoch:4 step:4174 [D loss: 0.183356, acc.: 73.44%] [G loss: 0.593269]\n",
      "epoch:4 step:4175 [D loss: 0.174400, acc.: 71.88%] [G loss: 0.671300]\n",
      "epoch:4 step:4176 [D loss: 0.165778, acc.: 75.78%] [G loss: 0.613222]\n",
      "epoch:4 step:4177 [D loss: 0.158108, acc.: 78.91%] [G loss: 0.648152]\n",
      "epoch:4 step:4178 [D loss: 0.180613, acc.: 75.00%] [G loss: 0.602758]\n",
      "epoch:4 step:4179 [D loss: 0.216228, acc.: 64.84%] [G loss: 0.535828]\n",
      "epoch:4 step:4180 [D loss: 0.206753, acc.: 68.75%] [G loss: 0.559256]\n",
      "epoch:4 step:4181 [D loss: 0.178081, acc.: 72.66%] [G loss: 0.557002]\n",
      "epoch:4 step:4182 [D loss: 0.178643, acc.: 70.31%] [G loss: 0.513265]\n",
      "epoch:4 step:4183 [D loss: 0.192238, acc.: 75.00%] [G loss: 0.544936]\n",
      "epoch:4 step:4184 [D loss: 0.164844, acc.: 73.44%] [G loss: 0.562135]\n",
      "epoch:4 step:4185 [D loss: 0.249443, acc.: 56.25%] [G loss: 0.524491]\n",
      "epoch:4 step:4186 [D loss: 0.221247, acc.: 64.84%] [G loss: 0.512754]\n",
      "epoch:4 step:4187 [D loss: 0.205742, acc.: 62.50%] [G loss: 0.574457]\n",
      "epoch:4 step:4188 [D loss: 0.187070, acc.: 74.22%] [G loss: 0.575154]\n",
      "epoch:4 step:4189 [D loss: 0.210872, acc.: 65.62%] [G loss: 0.539631]\n",
      "epoch:4 step:4190 [D loss: 0.201374, acc.: 69.53%] [G loss: 0.591463]\n",
      "epoch:4 step:4191 [D loss: 0.208692, acc.: 64.84%] [G loss: 0.563326]\n",
      "epoch:4 step:4192 [D loss: 0.189160, acc.: 66.41%] [G loss: 0.605850]\n",
      "epoch:4 step:4193 [D loss: 0.180714, acc.: 68.75%] [G loss: 0.605020]\n",
      "epoch:4 step:4194 [D loss: 0.208845, acc.: 65.62%] [G loss: 0.531043]\n",
      "epoch:4 step:4195 [D loss: 0.192472, acc.: 72.66%] [G loss: 0.594337]\n",
      "epoch:4 step:4196 [D loss: 0.224553, acc.: 68.75%] [G loss: 0.510052]\n",
      "epoch:4 step:4197 [D loss: 0.188154, acc.: 69.53%] [G loss: 0.541506]\n",
      "epoch:4 step:4198 [D loss: 0.181351, acc.: 75.78%] [G loss: 0.578528]\n",
      "epoch:4 step:4199 [D loss: 0.135723, acc.: 81.25%] [G loss: 0.631534]\n",
      "epoch:4 step:4200 [D loss: 0.175885, acc.: 78.12%] [G loss: 0.610255]\n",
      "epoch:4 step:4201 [D loss: 0.174329, acc.: 76.56%] [G loss: 0.569713]\n",
      "epoch:4 step:4202 [D loss: 0.227078, acc.: 69.53%] [G loss: 0.504147]\n",
      "epoch:4 step:4203 [D loss: 0.196278, acc.: 67.97%] [G loss: 0.570047]\n",
      "epoch:4 step:4204 [D loss: 0.214540, acc.: 63.28%] [G loss: 0.565405]\n",
      "epoch:4 step:4205 [D loss: 0.189555, acc.: 64.84%] [G loss: 0.592755]\n",
      "epoch:4 step:4206 [D loss: 0.243439, acc.: 67.97%] [G loss: 0.551850]\n",
      "epoch:4 step:4207 [D loss: 0.215838, acc.: 66.41%] [G loss: 0.501191]\n",
      "epoch:4 step:4208 [D loss: 0.201364, acc.: 68.75%] [G loss: 0.583621]\n",
      "epoch:4 step:4209 [D loss: 0.231009, acc.: 58.59%] [G loss: 0.548045]\n",
      "epoch:4 step:4210 [D loss: 0.233080, acc.: 64.06%] [G loss: 0.525585]\n",
      "epoch:4 step:4211 [D loss: 0.218397, acc.: 63.28%] [G loss: 0.481845]\n",
      "epoch:4 step:4212 [D loss: 0.200241, acc.: 68.75%] [G loss: 0.455218]\n",
      "epoch:4 step:4213 [D loss: 0.243660, acc.: 57.81%] [G loss: 0.472439]\n",
      "epoch:4 step:4214 [D loss: 0.197217, acc.: 67.19%] [G loss: 0.566334]\n",
      "epoch:4 step:4215 [D loss: 0.229087, acc.: 67.19%] [G loss: 0.570549]\n",
      "epoch:4 step:4216 [D loss: 0.228148, acc.: 59.38%] [G loss: 0.524492]\n",
      "epoch:4 step:4217 [D loss: 0.193158, acc.: 71.09%] [G loss: 0.586296]\n",
      "epoch:4 step:4218 [D loss: 0.215660, acc.: 66.41%] [G loss: 0.596060]\n",
      "epoch:4 step:4219 [D loss: 0.185846, acc.: 70.31%] [G loss: 0.628357]\n",
      "epoch:4 step:4220 [D loss: 0.194995, acc.: 76.56%] [G loss: 0.589849]\n",
      "epoch:4 step:4221 [D loss: 0.253099, acc.: 60.94%] [G loss: 0.496654]\n",
      "epoch:4 step:4222 [D loss: 0.157388, acc.: 76.56%] [G loss: 0.605468]\n",
      "epoch:4 step:4223 [D loss: 0.170418, acc.: 75.78%] [G loss: 0.614029]\n",
      "epoch:4 step:4224 [D loss: 0.224627, acc.: 66.41%] [G loss: 0.606179]\n",
      "epoch:4 step:4225 [D loss: 0.243006, acc.: 62.50%] [G loss: 0.500113]\n",
      "epoch:4 step:4226 [D loss: 0.189051, acc.: 75.78%] [G loss: 0.499583]\n",
      "epoch:4 step:4227 [D loss: 0.206398, acc.: 66.41%] [G loss: 0.546849]\n",
      "epoch:4 step:4228 [D loss: 0.200788, acc.: 67.97%] [G loss: 0.549119]\n",
      "epoch:4 step:4229 [D loss: 0.184849, acc.: 75.00%] [G loss: 0.555837]\n",
      "epoch:4 step:4230 [D loss: 0.268680, acc.: 59.38%] [G loss: 0.514902]\n",
      "epoch:4 step:4231 [D loss: 0.233820, acc.: 65.62%] [G loss: 0.494416]\n",
      "epoch:4 step:4232 [D loss: 0.162861, acc.: 76.56%] [G loss: 0.590438]\n",
      "epoch:4 step:4233 [D loss: 0.201474, acc.: 64.06%] [G loss: 0.556681]\n",
      "epoch:4 step:4234 [D loss: 0.207060, acc.: 64.06%] [G loss: 0.512902]\n",
      "epoch:4 step:4235 [D loss: 0.217153, acc.: 65.62%] [G loss: 0.537948]\n",
      "epoch:4 step:4236 [D loss: 0.155518, acc.: 82.81%] [G loss: 0.594115]\n",
      "epoch:4 step:4237 [D loss: 0.208738, acc.: 66.41%] [G loss: 0.583499]\n",
      "epoch:4 step:4238 [D loss: 0.203700, acc.: 64.84%] [G loss: 0.533536]\n",
      "epoch:4 step:4239 [D loss: 0.205166, acc.: 67.19%] [G loss: 0.534247]\n",
      "epoch:4 step:4240 [D loss: 0.225873, acc.: 60.16%] [G loss: 0.527385]\n",
      "epoch:4 step:4241 [D loss: 0.176821, acc.: 77.34%] [G loss: 0.577641]\n",
      "epoch:4 step:4242 [D loss: 0.187200, acc.: 70.31%] [G loss: 0.525288]\n",
      "epoch:4 step:4243 [D loss: 0.186013, acc.: 71.09%] [G loss: 0.584864]\n",
      "epoch:4 step:4244 [D loss: 0.210721, acc.: 70.31%] [G loss: 0.590053]\n",
      "epoch:4 step:4245 [D loss: 0.194551, acc.: 63.28%] [G loss: 0.621575]\n",
      "epoch:4 step:4246 [D loss: 0.179591, acc.: 71.09%] [G loss: 0.602428]\n",
      "epoch:4 step:4247 [D loss: 0.141313, acc.: 80.47%] [G loss: 0.672053]\n",
      "epoch:4 step:4248 [D loss: 0.262269, acc.: 56.25%] [G loss: 0.529906]\n",
      "epoch:4 step:4249 [D loss: 0.248097, acc.: 65.62%] [G loss: 0.503927]\n",
      "epoch:4 step:4250 [D loss: 0.207038, acc.: 67.19%] [G loss: 0.491449]\n",
      "epoch:4 step:4251 [D loss: 0.152338, acc.: 81.25%] [G loss: 0.585624]\n",
      "epoch:4 step:4252 [D loss: 0.195354, acc.: 75.00%] [G loss: 0.581818]\n",
      "epoch:4 step:4253 [D loss: 0.179236, acc.: 75.00%] [G loss: 0.630979]\n",
      "epoch:4 step:4254 [D loss: 0.213959, acc.: 69.53%] [G loss: 0.530091]\n",
      "epoch:4 step:4255 [D loss: 0.194533, acc.: 70.31%] [G loss: 0.547010]\n",
      "epoch:4 step:4256 [D loss: 0.163559, acc.: 75.78%] [G loss: 0.628505]\n",
      "epoch:4 step:4257 [D loss: 0.185627, acc.: 70.31%] [G loss: 0.593942]\n",
      "epoch:4 step:4258 [D loss: 0.198351, acc.: 69.53%] [G loss: 0.544153]\n",
      "epoch:4 step:4259 [D loss: 0.230369, acc.: 62.50%] [G loss: 0.536158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4260 [D loss: 0.191107, acc.: 67.19%] [G loss: 0.574715]\n",
      "epoch:4 step:4261 [D loss: 0.185000, acc.: 71.88%] [G loss: 0.567007]\n",
      "epoch:4 step:4262 [D loss: 0.229067, acc.: 57.03%] [G loss: 0.564514]\n",
      "epoch:4 step:4263 [D loss: 0.178443, acc.: 70.31%] [G loss: 0.596033]\n",
      "epoch:4 step:4264 [D loss: 0.194621, acc.: 70.31%] [G loss: 0.574034]\n",
      "epoch:4 step:4265 [D loss: 0.198044, acc.: 66.41%] [G loss: 0.557903]\n",
      "epoch:4 step:4266 [D loss: 0.188963, acc.: 74.22%] [G loss: 0.578882]\n",
      "epoch:4 step:4267 [D loss: 0.184876, acc.: 77.34%] [G loss: 0.596455]\n",
      "epoch:4 step:4268 [D loss: 0.183165, acc.: 77.34%] [G loss: 0.583645]\n",
      "epoch:4 step:4269 [D loss: 0.183387, acc.: 73.44%] [G loss: 0.555728]\n",
      "epoch:4 step:4270 [D loss: 0.174632, acc.: 72.66%] [G loss: 0.554089]\n",
      "epoch:4 step:4271 [D loss: 0.178085, acc.: 77.34%] [G loss: 0.550051]\n",
      "epoch:4 step:4272 [D loss: 0.200167, acc.: 60.94%] [G loss: 0.561273]\n",
      "epoch:4 step:4273 [D loss: 0.226339, acc.: 62.50%] [G loss: 0.598773]\n",
      "epoch:4 step:4274 [D loss: 0.178665, acc.: 76.56%] [G loss: 0.571651]\n",
      "epoch:4 step:4275 [D loss: 0.219365, acc.: 65.62%] [G loss: 0.549405]\n",
      "epoch:4 step:4276 [D loss: 0.228145, acc.: 64.06%] [G loss: 0.499319]\n",
      "epoch:4 step:4277 [D loss: 0.200869, acc.: 71.09%] [G loss: 0.533040]\n",
      "epoch:4 step:4278 [D loss: 0.200890, acc.: 71.09%] [G loss: 0.596161]\n",
      "epoch:4 step:4279 [D loss: 0.230536, acc.: 62.50%] [G loss: 0.511021]\n",
      "epoch:4 step:4280 [D loss: 0.187047, acc.: 72.66%] [G loss: 0.572846]\n",
      "epoch:4 step:4281 [D loss: 0.223849, acc.: 64.84%] [G loss: 0.565400]\n",
      "epoch:4 step:4282 [D loss: 0.150329, acc.: 75.78%] [G loss: 0.633194]\n",
      "epoch:4 step:4283 [D loss: 0.265037, acc.: 55.47%] [G loss: 0.464394]\n",
      "epoch:4 step:4284 [D loss: 0.165478, acc.: 78.12%] [G loss: 0.538727]\n",
      "epoch:4 step:4285 [D loss: 0.198289, acc.: 65.62%] [G loss: 0.570666]\n",
      "epoch:4 step:4286 [D loss: 0.215907, acc.: 64.06%] [G loss: 0.512248]\n",
      "epoch:4 step:4287 [D loss: 0.191132, acc.: 70.31%] [G loss: 0.537396]\n",
      "epoch:4 step:4288 [D loss: 0.198393, acc.: 66.41%] [G loss: 0.543327]\n",
      "epoch:4 step:4289 [D loss: 0.157242, acc.: 75.00%] [G loss: 0.589462]\n",
      "epoch:4 step:4290 [D loss: 0.238751, acc.: 60.94%] [G loss: 0.531739]\n",
      "epoch:4 step:4291 [D loss: 0.225692, acc.: 60.94%] [G loss: 0.471244]\n",
      "epoch:4 step:4292 [D loss: 0.201009, acc.: 71.88%] [G loss: 0.568442]\n",
      "epoch:4 step:4293 [D loss: 0.186435, acc.: 72.66%] [G loss: 0.546432]\n",
      "epoch:4 step:4294 [D loss: 0.184805, acc.: 75.78%] [G loss: 0.589814]\n",
      "epoch:4 step:4295 [D loss: 0.175541, acc.: 76.56%] [G loss: 0.589467]\n",
      "epoch:4 step:4296 [D loss: 0.154674, acc.: 76.56%] [G loss: 0.641881]\n",
      "epoch:4 step:4297 [D loss: 0.163851, acc.: 77.34%] [G loss: 0.621277]\n",
      "epoch:4 step:4298 [D loss: 0.188947, acc.: 72.66%] [G loss: 0.539357]\n",
      "epoch:4 step:4299 [D loss: 0.178680, acc.: 75.00%] [G loss: 0.574759]\n",
      "epoch:4 step:4300 [D loss: 0.170098, acc.: 76.56%] [G loss: 0.573339]\n",
      "epoch:4 step:4301 [D loss: 0.225885, acc.: 65.62%] [G loss: 0.557570]\n",
      "epoch:4 step:4302 [D loss: 0.172349, acc.: 75.00%] [G loss: 0.591745]\n",
      "epoch:4 step:4303 [D loss: 0.190428, acc.: 75.00%] [G loss: 0.546755]\n",
      "epoch:4 step:4304 [D loss: 0.170259, acc.: 75.78%] [G loss: 0.619390]\n",
      "epoch:4 step:4305 [D loss: 0.186192, acc.: 73.44%] [G loss: 0.606783]\n",
      "epoch:4 step:4306 [D loss: 0.158181, acc.: 78.12%] [G loss: 0.599971]\n",
      "epoch:4 step:4307 [D loss: 0.206032, acc.: 67.19%] [G loss: 0.521994]\n",
      "epoch:4 step:4308 [D loss: 0.211595, acc.: 65.62%] [G loss: 0.550906]\n",
      "epoch:4 step:4309 [D loss: 0.167171, acc.: 77.34%] [G loss: 0.599454]\n",
      "epoch:4 step:4310 [D loss: 0.242387, acc.: 60.94%] [G loss: 0.552322]\n",
      "epoch:4 step:4311 [D loss: 0.218720, acc.: 65.62%] [G loss: 0.560956]\n",
      "epoch:4 step:4312 [D loss: 0.166420, acc.: 75.78%] [G loss: 0.631542]\n",
      "epoch:4 step:4313 [D loss: 0.240217, acc.: 57.03%] [G loss: 0.539935]\n",
      "epoch:4 step:4314 [D loss: 0.238003, acc.: 62.50%] [G loss: 0.508290]\n",
      "epoch:4 step:4315 [D loss: 0.147683, acc.: 81.25%] [G loss: 0.596236]\n",
      "epoch:4 step:4316 [D loss: 0.175787, acc.: 77.34%] [G loss: 0.578426]\n",
      "epoch:4 step:4317 [D loss: 0.208771, acc.: 71.09%] [G loss: 0.569276]\n",
      "epoch:4 step:4318 [D loss: 0.177261, acc.: 76.56%] [G loss: 0.558108]\n",
      "epoch:4 step:4319 [D loss: 0.195718, acc.: 67.97%] [G loss: 0.535544]\n",
      "epoch:4 step:4320 [D loss: 0.213549, acc.: 71.88%] [G loss: 0.532687]\n",
      "epoch:4 step:4321 [D loss: 0.180042, acc.: 71.88%] [G loss: 0.580508]\n",
      "epoch:4 step:4322 [D loss: 0.162926, acc.: 75.00%] [G loss: 0.586292]\n",
      "epoch:4 step:4323 [D loss: 0.162811, acc.: 77.34%] [G loss: 0.634758]\n",
      "epoch:4 step:4324 [D loss: 0.236244, acc.: 55.47%] [G loss: 0.540881]\n",
      "epoch:4 step:4325 [D loss: 0.203850, acc.: 71.09%] [G loss: 0.564659]\n",
      "epoch:4 step:4326 [D loss: 0.226739, acc.: 61.72%] [G loss: 0.557261]\n",
      "epoch:4 step:4327 [D loss: 0.205927, acc.: 70.31%] [G loss: 0.501188]\n",
      "epoch:4 step:4328 [D loss: 0.208261, acc.: 67.19%] [G loss: 0.546913]\n",
      "epoch:4 step:4329 [D loss: 0.206305, acc.: 69.53%] [G loss: 0.511277]\n",
      "epoch:4 step:4330 [D loss: 0.187721, acc.: 75.00%] [G loss: 0.548593]\n",
      "epoch:4 step:4331 [D loss: 0.205704, acc.: 69.53%] [G loss: 0.557292]\n",
      "epoch:4 step:4332 [D loss: 0.236989, acc.: 65.62%] [G loss: 0.490914]\n",
      "epoch:4 step:4333 [D loss: 0.188093, acc.: 69.53%] [G loss: 0.520878]\n",
      "epoch:4 step:4334 [D loss: 0.197617, acc.: 71.09%] [G loss: 0.545992]\n",
      "epoch:4 step:4335 [D loss: 0.170935, acc.: 73.44%] [G loss: 0.617905]\n",
      "epoch:4 step:4336 [D loss: 0.177826, acc.: 74.22%] [G loss: 0.574355]\n",
      "epoch:4 step:4337 [D loss: 0.199782, acc.: 70.31%] [G loss: 0.600358]\n",
      "epoch:4 step:4338 [D loss: 0.250321, acc.: 61.72%] [G loss: 0.519257]\n",
      "epoch:4 step:4339 [D loss: 0.198204, acc.: 69.53%] [G loss: 0.560634]\n",
      "epoch:4 step:4340 [D loss: 0.177539, acc.: 73.44%] [G loss: 0.592647]\n",
      "epoch:4 step:4341 [D loss: 0.238373, acc.: 61.72%] [G loss: 0.522995]\n",
      "epoch:4 step:4342 [D loss: 0.215032, acc.: 66.41%] [G loss: 0.519954]\n",
      "epoch:4 step:4343 [D loss: 0.198945, acc.: 71.88%] [G loss: 0.511422]\n",
      "epoch:4 step:4344 [D loss: 0.224926, acc.: 65.62%] [G loss: 0.497416]\n",
      "epoch:4 step:4345 [D loss: 0.193940, acc.: 68.75%] [G loss: 0.531296]\n",
      "epoch:4 step:4346 [D loss: 0.179408, acc.: 78.12%] [G loss: 0.552417]\n",
      "epoch:4 step:4347 [D loss: 0.207327, acc.: 68.75%] [G loss: 0.541448]\n",
      "epoch:4 step:4348 [D loss: 0.214827, acc.: 60.94%] [G loss: 0.495502]\n",
      "epoch:4 step:4349 [D loss: 0.178048, acc.: 76.56%] [G loss: 0.534392]\n",
      "epoch:4 step:4350 [D loss: 0.188961, acc.: 69.53%] [G loss: 0.545256]\n",
      "epoch:4 step:4351 [D loss: 0.192895, acc.: 75.78%] [G loss: 0.543078]\n",
      "epoch:4 step:4352 [D loss: 0.216458, acc.: 68.75%] [G loss: 0.519005]\n",
      "epoch:4 step:4353 [D loss: 0.169422, acc.: 78.12%] [G loss: 0.559230]\n",
      "epoch:4 step:4354 [D loss: 0.211677, acc.: 67.19%] [G loss: 0.518394]\n",
      "epoch:4 step:4355 [D loss: 0.192173, acc.: 71.09%] [G loss: 0.563573]\n",
      "epoch:4 step:4356 [D loss: 0.209519, acc.: 71.09%] [G loss: 0.511644]\n",
      "epoch:4 step:4357 [D loss: 0.199923, acc.: 70.31%] [G loss: 0.544843]\n",
      "epoch:4 step:4358 [D loss: 0.199828, acc.: 68.75%] [G loss: 0.560091]\n",
      "epoch:4 step:4359 [D loss: 0.167361, acc.: 76.56%] [G loss: 0.587379]\n",
      "epoch:4 step:4360 [D loss: 0.213103, acc.: 69.53%] [G loss: 0.491702]\n",
      "epoch:4 step:4361 [D loss: 0.183141, acc.: 70.31%] [G loss: 0.559696]\n",
      "epoch:4 step:4362 [D loss: 0.189071, acc.: 75.78%] [G loss: 0.533391]\n",
      "epoch:4 step:4363 [D loss: 0.231930, acc.: 62.50%] [G loss: 0.510129]\n",
      "epoch:4 step:4364 [D loss: 0.211061, acc.: 68.75%] [G loss: 0.550685]\n",
      "epoch:4 step:4365 [D loss: 0.166352, acc.: 79.69%] [G loss: 0.579978]\n",
      "epoch:4 step:4366 [D loss: 0.188032, acc.: 69.53%] [G loss: 0.549219]\n",
      "epoch:4 step:4367 [D loss: 0.188674, acc.: 71.09%] [G loss: 0.529920]\n",
      "epoch:4 step:4368 [D loss: 0.201257, acc.: 65.62%] [G loss: 0.538319]\n",
      "epoch:4 step:4369 [D loss: 0.203115, acc.: 69.53%] [G loss: 0.490603]\n",
      "epoch:4 step:4370 [D loss: 0.273896, acc.: 52.34%] [G loss: 0.507103]\n",
      "epoch:4 step:4371 [D loss: 0.195865, acc.: 67.19%] [G loss: 0.570488]\n",
      "epoch:4 step:4372 [D loss: 0.199718, acc.: 68.75%] [G loss: 0.548576]\n",
      "epoch:4 step:4373 [D loss: 0.230757, acc.: 60.16%] [G loss: 0.545856]\n",
      "epoch:4 step:4374 [D loss: 0.207101, acc.: 72.66%] [G loss: 0.531662]\n",
      "epoch:4 step:4375 [D loss: 0.206300, acc.: 64.06%] [G loss: 0.572983]\n",
      "epoch:4 step:4376 [D loss: 0.220262, acc.: 64.06%] [G loss: 0.485182]\n",
      "epoch:4 step:4377 [D loss: 0.178112, acc.: 76.56%] [G loss: 0.568582]\n",
      "epoch:4 step:4378 [D loss: 0.196047, acc.: 75.00%] [G loss: 0.503698]\n",
      "epoch:4 step:4379 [D loss: 0.181992, acc.: 69.53%] [G loss: 0.512197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4380 [D loss: 0.182736, acc.: 73.44%] [G loss: 0.544171]\n",
      "epoch:4 step:4381 [D loss: 0.182498, acc.: 72.66%] [G loss: 0.582930]\n",
      "epoch:4 step:4382 [D loss: 0.182746, acc.: 72.66%] [G loss: 0.540085]\n",
      "epoch:4 step:4383 [D loss: 0.183891, acc.: 71.88%] [G loss: 0.550271]\n",
      "epoch:4 step:4384 [D loss: 0.209522, acc.: 70.31%] [G loss: 0.518598]\n",
      "epoch:4 step:4385 [D loss: 0.176253, acc.: 74.22%] [G loss: 0.520867]\n",
      "epoch:4 step:4386 [D loss: 0.216769, acc.: 67.97%] [G loss: 0.489792]\n",
      "epoch:4 step:4387 [D loss: 0.177128, acc.: 76.56%] [G loss: 0.531805]\n",
      "epoch:4 step:4388 [D loss: 0.182489, acc.: 69.53%] [G loss: 0.558908]\n",
      "epoch:4 step:4389 [D loss: 0.184478, acc.: 72.66%] [G loss: 0.602798]\n",
      "epoch:4 step:4390 [D loss: 0.190438, acc.: 72.66%] [G loss: 0.609810]\n",
      "epoch:4 step:4391 [D loss: 0.180944, acc.: 73.44%] [G loss: 0.565173]\n",
      "epoch:4 step:4392 [D loss: 0.193465, acc.: 67.19%] [G loss: 0.545013]\n",
      "epoch:4 step:4393 [D loss: 0.207467, acc.: 66.41%] [G loss: 0.501667]\n",
      "epoch:4 step:4394 [D loss: 0.196655, acc.: 66.41%] [G loss: 0.574775]\n",
      "epoch:4 step:4395 [D loss: 0.160271, acc.: 75.78%] [G loss: 0.579372]\n",
      "epoch:4 step:4396 [D loss: 0.143432, acc.: 78.12%] [G loss: 0.648977]\n",
      "epoch:4 step:4397 [D loss: 0.185523, acc.: 73.44%] [G loss: 0.638402]\n",
      "epoch:4 step:4398 [D loss: 0.178934, acc.: 70.31%] [G loss: 0.614077]\n",
      "epoch:4 step:4399 [D loss: 0.216480, acc.: 70.31%] [G loss: 0.599030]\n",
      "epoch:4 step:4400 [D loss: 0.209166, acc.: 64.06%] [G loss: 0.566366]\n",
      "epoch:4 step:4401 [D loss: 0.230326, acc.: 59.38%] [G loss: 0.499718]\n",
      "epoch:4 step:4402 [D loss: 0.196166, acc.: 69.53%] [G loss: 0.579476]\n",
      "epoch:4 step:4403 [D loss: 0.213055, acc.: 66.41%] [G loss: 0.537017]\n",
      "epoch:4 step:4404 [D loss: 0.207433, acc.: 64.84%] [G loss: 0.541387]\n",
      "epoch:4 step:4405 [D loss: 0.204992, acc.: 64.06%] [G loss: 0.581669]\n",
      "epoch:4 step:4406 [D loss: 0.204304, acc.: 69.53%] [G loss: 0.564217]\n",
      "epoch:4 step:4407 [D loss: 0.179153, acc.: 75.00%] [G loss: 0.554976]\n",
      "epoch:4 step:4408 [D loss: 0.183863, acc.: 77.34%] [G loss: 0.513447]\n",
      "epoch:4 step:4409 [D loss: 0.161580, acc.: 78.12%] [G loss: 0.593672]\n",
      "epoch:4 step:4410 [D loss: 0.196445, acc.: 73.44%] [G loss: 0.562796]\n",
      "epoch:4 step:4411 [D loss: 0.196596, acc.: 65.62%] [G loss: 0.517844]\n",
      "epoch:4 step:4412 [D loss: 0.182874, acc.: 68.75%] [G loss: 0.551826]\n",
      "epoch:4 step:4413 [D loss: 0.223514, acc.: 64.06%] [G loss: 0.533663]\n",
      "epoch:4 step:4414 [D loss: 0.221683, acc.: 64.84%] [G loss: 0.533644]\n",
      "epoch:4 step:4415 [D loss: 0.221463, acc.: 66.41%] [G loss: 0.547324]\n",
      "epoch:4 step:4416 [D loss: 0.199808, acc.: 70.31%] [G loss: 0.540355]\n",
      "epoch:4 step:4417 [D loss: 0.175984, acc.: 73.44%] [G loss: 0.549234]\n",
      "epoch:4 step:4418 [D loss: 0.234917, acc.: 63.28%] [G loss: 0.547297]\n",
      "epoch:4 step:4419 [D loss: 0.227355, acc.: 60.94%] [G loss: 0.505269]\n",
      "epoch:4 step:4420 [D loss: 0.262202, acc.: 57.03%] [G loss: 0.564789]\n",
      "epoch:4 step:4421 [D loss: 0.209129, acc.: 64.84%] [G loss: 0.538408]\n",
      "epoch:4 step:4422 [D loss: 0.226655, acc.: 68.75%] [G loss: 0.526789]\n",
      "epoch:4 step:4423 [D loss: 0.184884, acc.: 69.53%] [G loss: 0.571294]\n",
      "epoch:4 step:4424 [D loss: 0.197056, acc.: 68.75%] [G loss: 0.546093]\n",
      "epoch:4 step:4425 [D loss: 0.171757, acc.: 75.00%] [G loss: 0.554082]\n",
      "epoch:4 step:4426 [D loss: 0.203235, acc.: 66.41%] [G loss: 0.536455]\n",
      "epoch:4 step:4427 [D loss: 0.215356, acc.: 62.50%] [G loss: 0.519345]\n",
      "epoch:4 step:4428 [D loss: 0.162850, acc.: 77.34%] [G loss: 0.548711]\n",
      "epoch:4 step:4429 [D loss: 0.204917, acc.: 67.19%] [G loss: 0.550696]\n",
      "epoch:4 step:4430 [D loss: 0.208609, acc.: 67.97%] [G loss: 0.504208]\n",
      "epoch:4 step:4431 [D loss: 0.204433, acc.: 67.97%] [G loss: 0.530114]\n",
      "epoch:4 step:4432 [D loss: 0.195203, acc.: 71.09%] [G loss: 0.569483]\n",
      "epoch:4 step:4433 [D loss: 0.228782, acc.: 64.06%] [G loss: 0.516236]\n",
      "epoch:4 step:4434 [D loss: 0.225797, acc.: 65.62%] [G loss: 0.501186]\n",
      "epoch:4 step:4435 [D loss: 0.240358, acc.: 64.84%] [G loss: 0.553689]\n",
      "epoch:4 step:4436 [D loss: 0.208081, acc.: 68.75%] [G loss: 0.581419]\n",
      "epoch:4 step:4437 [D loss: 0.218373, acc.: 63.28%] [G loss: 0.564124]\n",
      "epoch:4 step:4438 [D loss: 0.179983, acc.: 68.75%] [G loss: 0.597425]\n",
      "epoch:4 step:4439 [D loss: 0.209487, acc.: 67.19%] [G loss: 0.594728]\n",
      "epoch:4 step:4440 [D loss: 0.196754, acc.: 68.75%] [G loss: 0.563025]\n",
      "epoch:4 step:4441 [D loss: 0.187059, acc.: 73.44%] [G loss: 0.607796]\n",
      "epoch:4 step:4442 [D loss: 0.181006, acc.: 71.09%] [G loss: 0.632020]\n",
      "epoch:4 step:4443 [D loss: 0.206400, acc.: 69.53%] [G loss: 0.562758]\n",
      "epoch:4 step:4444 [D loss: 0.226071, acc.: 64.84%] [G loss: 0.571176]\n",
      "epoch:4 step:4445 [D loss: 0.197425, acc.: 72.66%] [G loss: 0.565519]\n",
      "epoch:4 step:4446 [D loss: 0.212464, acc.: 71.09%] [G loss: 0.556248]\n",
      "epoch:4 step:4447 [D loss: 0.200267, acc.: 67.97%] [G loss: 0.590456]\n",
      "epoch:4 step:4448 [D loss: 0.191057, acc.: 74.22%] [G loss: 0.614269]\n",
      "epoch:4 step:4449 [D loss: 0.194815, acc.: 70.31%] [G loss: 0.579822]\n",
      "epoch:4 step:4450 [D loss: 0.221094, acc.: 64.84%] [G loss: 0.503661]\n",
      "epoch:4 step:4451 [D loss: 0.220759, acc.: 64.06%] [G loss: 0.511655]\n",
      "epoch:4 step:4452 [D loss: 0.188518, acc.: 69.53%] [G loss: 0.557513]\n",
      "epoch:4 step:4453 [D loss: 0.214223, acc.: 67.19%] [G loss: 0.548392]\n",
      "epoch:4 step:4454 [D loss: 0.189231, acc.: 70.31%] [G loss: 0.557746]\n",
      "epoch:4 step:4455 [D loss: 0.135163, acc.: 84.38%] [G loss: 0.598919]\n",
      "epoch:4 step:4456 [D loss: 0.187845, acc.: 75.78%] [G loss: 0.635049]\n",
      "epoch:4 step:4457 [D loss: 0.196981, acc.: 69.53%] [G loss: 0.598977]\n",
      "epoch:4 step:4458 [D loss: 0.243221, acc.: 59.38%] [G loss: 0.521764]\n",
      "epoch:4 step:4459 [D loss: 0.223930, acc.: 61.72%] [G loss: 0.500136]\n",
      "epoch:4 step:4460 [D loss: 0.183709, acc.: 75.00%] [G loss: 0.585157]\n",
      "epoch:4 step:4461 [D loss: 0.209013, acc.: 65.62%] [G loss: 0.514161]\n",
      "epoch:4 step:4462 [D loss: 0.190192, acc.: 71.09%] [G loss: 0.553620]\n",
      "epoch:4 step:4463 [D loss: 0.226301, acc.: 62.50%] [G loss: 0.504589]\n",
      "epoch:4 step:4464 [D loss: 0.287882, acc.: 53.91%] [G loss: 0.505585]\n",
      "epoch:4 step:4465 [D loss: 0.195316, acc.: 66.41%] [G loss: 0.569438]\n",
      "epoch:4 step:4466 [D loss: 0.212098, acc.: 67.19%] [G loss: 0.582219]\n",
      "epoch:4 step:4467 [D loss: 0.199245, acc.: 67.19%] [G loss: 0.564492]\n",
      "epoch:4 step:4468 [D loss: 0.206621, acc.: 65.62%] [G loss: 0.519927]\n",
      "epoch:4 step:4469 [D loss: 0.230861, acc.: 61.72%] [G loss: 0.558643]\n",
      "epoch:4 step:4470 [D loss: 0.227831, acc.: 58.59%] [G loss: 0.556889]\n",
      "epoch:4 step:4471 [D loss: 0.200028, acc.: 69.53%] [G loss: 0.587817]\n",
      "epoch:4 step:4472 [D loss: 0.213502, acc.: 68.75%] [G loss: 0.572096]\n",
      "epoch:4 step:4473 [D loss: 0.171903, acc.: 77.34%] [G loss: 0.572913]\n",
      "epoch:4 step:4474 [D loss: 0.209355, acc.: 67.97%] [G loss: 0.550852]\n",
      "epoch:4 step:4475 [D loss: 0.236825, acc.: 61.72%] [G loss: 0.494936]\n",
      "epoch:4 step:4476 [D loss: 0.200224, acc.: 67.97%] [G loss: 0.491351]\n",
      "epoch:4 step:4477 [D loss: 0.234246, acc.: 63.28%] [G loss: 0.511838]\n",
      "epoch:4 step:4478 [D loss: 0.186636, acc.: 72.66%] [G loss: 0.533550]\n",
      "epoch:4 step:4479 [D loss: 0.182931, acc.: 66.41%] [G loss: 0.597320]\n",
      "epoch:4 step:4480 [D loss: 0.208151, acc.: 65.62%] [G loss: 0.591701]\n",
      "epoch:4 step:4481 [D loss: 0.208406, acc.: 66.41%] [G loss: 0.552281]\n",
      "epoch:4 step:4482 [D loss: 0.240776, acc.: 61.72%] [G loss: 0.490656]\n",
      "epoch:4 step:4483 [D loss: 0.213702, acc.: 67.97%] [G loss: 0.544285]\n",
      "epoch:4 step:4484 [D loss: 0.207825, acc.: 64.84%] [G loss: 0.598973]\n",
      "epoch:4 step:4485 [D loss: 0.187005, acc.: 75.78%] [G loss: 0.589592]\n",
      "epoch:4 step:4486 [D loss: 0.216819, acc.: 60.94%] [G loss: 0.504658]\n",
      "epoch:4 step:4487 [D loss: 0.229804, acc.: 59.38%] [G loss: 0.511847]\n",
      "epoch:4 step:4488 [D loss: 0.235352, acc.: 62.50%] [G loss: 0.508974]\n",
      "epoch:4 step:4489 [D loss: 0.258262, acc.: 58.59%] [G loss: 0.491407]\n",
      "epoch:4 step:4490 [D loss: 0.214744, acc.: 64.84%] [G loss: 0.494714]\n",
      "epoch:4 step:4491 [D loss: 0.213739, acc.: 67.97%] [G loss: 0.495386]\n",
      "epoch:4 step:4492 [D loss: 0.201200, acc.: 67.97%] [G loss: 0.550633]\n",
      "epoch:4 step:4493 [D loss: 0.205244, acc.: 66.41%] [G loss: 0.517646]\n",
      "epoch:4 step:4494 [D loss: 0.169940, acc.: 72.66%] [G loss: 0.593287]\n",
      "epoch:4 step:4495 [D loss: 0.204377, acc.: 64.06%] [G loss: 0.572441]\n",
      "epoch:4 step:4496 [D loss: 0.190795, acc.: 68.75%] [G loss: 0.591705]\n",
      "epoch:4 step:4497 [D loss: 0.211202, acc.: 62.50%] [G loss: 0.515828]\n",
      "epoch:4 step:4498 [D loss: 0.186104, acc.: 74.22%] [G loss: 0.531135]\n",
      "epoch:4 step:4499 [D loss: 0.218406, acc.: 64.84%] [G loss: 0.526077]\n",
      "epoch:4 step:4500 [D loss: 0.197697, acc.: 69.53%] [G loss: 0.535666]\n",
      "epoch:4 step:4501 [D loss: 0.189735, acc.: 71.88%] [G loss: 0.575803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4502 [D loss: 0.195298, acc.: 71.88%] [G loss: 0.549984]\n",
      "epoch:4 step:4503 [D loss: 0.206500, acc.: 70.31%] [G loss: 0.536066]\n",
      "epoch:4 step:4504 [D loss: 0.212967, acc.: 67.97%] [G loss: 0.513041]\n",
      "epoch:4 step:4505 [D loss: 0.183266, acc.: 75.00%] [G loss: 0.538685]\n",
      "epoch:4 step:4506 [D loss: 0.159383, acc.: 75.78%] [G loss: 0.582165]\n",
      "epoch:4 step:4507 [D loss: 0.169070, acc.: 72.66%] [G loss: 0.545764]\n",
      "epoch:4 step:4508 [D loss: 0.209605, acc.: 64.06%] [G loss: 0.524235]\n",
      "epoch:4 step:4509 [D loss: 0.196629, acc.: 64.84%] [G loss: 0.536790]\n",
      "epoch:4 step:4510 [D loss: 0.211627, acc.: 64.84%] [G loss: 0.505334]\n",
      "epoch:4 step:4511 [D loss: 0.191821, acc.: 69.53%] [G loss: 0.538739]\n",
      "epoch:4 step:4512 [D loss: 0.233096, acc.: 60.94%] [G loss: 0.493929]\n",
      "epoch:4 step:4513 [D loss: 0.275674, acc.: 57.81%] [G loss: 0.499845]\n",
      "epoch:4 step:4514 [D loss: 0.230628, acc.: 61.72%] [G loss: 0.540197]\n",
      "epoch:4 step:4515 [D loss: 0.186118, acc.: 71.88%] [G loss: 0.584907]\n",
      "epoch:4 step:4516 [D loss: 0.208898, acc.: 67.19%] [G loss: 0.555691]\n",
      "epoch:4 step:4517 [D loss: 0.193961, acc.: 71.09%] [G loss: 0.522288]\n",
      "epoch:4 step:4518 [D loss: 0.210306, acc.: 69.53%] [G loss: 0.570568]\n",
      "epoch:4 step:4519 [D loss: 0.208998, acc.: 66.41%] [G loss: 0.541519]\n",
      "epoch:4 step:4520 [D loss: 0.195319, acc.: 70.31%] [G loss: 0.573243]\n",
      "epoch:4 step:4521 [D loss: 0.186065, acc.: 73.44%] [G loss: 0.527039]\n",
      "epoch:4 step:4522 [D loss: 0.200654, acc.: 71.09%] [G loss: 0.557516]\n",
      "epoch:4 step:4523 [D loss: 0.175476, acc.: 74.22%] [G loss: 0.606935]\n",
      "epoch:4 step:4524 [D loss: 0.228065, acc.: 61.72%] [G loss: 0.512607]\n",
      "epoch:4 step:4525 [D loss: 0.186320, acc.: 70.31%] [G loss: 0.562246]\n",
      "epoch:4 step:4526 [D loss: 0.193538, acc.: 69.53%] [G loss: 0.548387]\n",
      "epoch:4 step:4527 [D loss: 0.181077, acc.: 72.66%] [G loss: 0.561769]\n",
      "epoch:4 step:4528 [D loss: 0.182966, acc.: 73.44%] [G loss: 0.520331]\n",
      "epoch:4 step:4529 [D loss: 0.181425, acc.: 75.78%] [G loss: 0.580443]\n",
      "epoch:4 step:4530 [D loss: 0.187541, acc.: 72.66%] [G loss: 0.609924]\n",
      "epoch:4 step:4531 [D loss: 0.239442, acc.: 62.50%] [G loss: 0.548345]\n",
      "epoch:4 step:4532 [D loss: 0.232450, acc.: 65.62%] [G loss: 0.522549]\n",
      "epoch:4 step:4533 [D loss: 0.188819, acc.: 74.22%] [G loss: 0.549438]\n",
      "epoch:4 step:4534 [D loss: 0.152370, acc.: 79.69%] [G loss: 0.620310]\n",
      "epoch:4 step:4535 [D loss: 0.221893, acc.: 64.84%] [G loss: 0.523322]\n",
      "epoch:4 step:4536 [D loss: 0.255360, acc.: 55.47%] [G loss: 0.506849]\n",
      "epoch:4 step:4537 [D loss: 0.176164, acc.: 74.22%] [G loss: 0.549704]\n",
      "epoch:4 step:4538 [D loss: 0.193569, acc.: 71.09%] [G loss: 0.557616]\n",
      "epoch:4 step:4539 [D loss: 0.229459, acc.: 66.41%] [G loss: 0.494851]\n",
      "epoch:4 step:4540 [D loss: 0.166057, acc.: 75.78%] [G loss: 0.533667]\n",
      "epoch:4 step:4541 [D loss: 0.204668, acc.: 71.88%] [G loss: 0.590939]\n",
      "epoch:4 step:4542 [D loss: 0.221814, acc.: 64.06%] [G loss: 0.516390]\n",
      "epoch:4 step:4543 [D loss: 0.186632, acc.: 69.53%] [G loss: 0.560858]\n",
      "epoch:4 step:4544 [D loss: 0.179282, acc.: 74.22%] [G loss: 0.541112]\n",
      "epoch:4 step:4545 [D loss: 0.227562, acc.: 58.59%] [G loss: 0.526267]\n",
      "epoch:4 step:4546 [D loss: 0.228247, acc.: 65.62%] [G loss: 0.497591]\n",
      "epoch:4 step:4547 [D loss: 0.200719, acc.: 69.53%] [G loss: 0.511847]\n",
      "epoch:4 step:4548 [D loss: 0.185673, acc.: 71.09%] [G loss: 0.551728]\n",
      "epoch:4 step:4549 [D loss: 0.190295, acc.: 68.75%] [G loss: 0.588465]\n",
      "epoch:4 step:4550 [D loss: 0.178416, acc.: 73.44%] [G loss: 0.595608]\n",
      "epoch:4 step:4551 [D loss: 0.166637, acc.: 73.44%] [G loss: 0.613424]\n",
      "epoch:4 step:4552 [D loss: 0.207923, acc.: 65.62%] [G loss: 0.523234]\n",
      "epoch:4 step:4553 [D loss: 0.175267, acc.: 76.56%] [G loss: 0.604455]\n",
      "epoch:4 step:4554 [D loss: 0.175448, acc.: 70.31%] [G loss: 0.611283]\n",
      "epoch:4 step:4555 [D loss: 0.210246, acc.: 64.84%] [G loss: 0.548980]\n",
      "epoch:4 step:4556 [D loss: 0.229885, acc.: 66.41%] [G loss: 0.559967]\n",
      "epoch:4 step:4557 [D loss: 0.216196, acc.: 71.09%] [G loss: 0.524108]\n",
      "epoch:4 step:4558 [D loss: 0.207497, acc.: 66.41%] [G loss: 0.518953]\n",
      "epoch:4 step:4559 [D loss: 0.217986, acc.: 61.72%] [G loss: 0.538549]\n",
      "epoch:4 step:4560 [D loss: 0.239247, acc.: 64.06%] [G loss: 0.507159]\n",
      "epoch:4 step:4561 [D loss: 0.205107, acc.: 71.88%] [G loss: 0.544717]\n",
      "epoch:4 step:4562 [D loss: 0.208911, acc.: 66.41%] [G loss: 0.571385]\n",
      "epoch:4 step:4563 [D loss: 0.187884, acc.: 69.53%] [G loss: 0.605130]\n",
      "epoch:4 step:4564 [D loss: 0.190563, acc.: 67.19%] [G loss: 0.625395]\n",
      "epoch:4 step:4565 [D loss: 0.248701, acc.: 60.16%] [G loss: 0.464269]\n",
      "epoch:4 step:4566 [D loss: 0.228843, acc.: 57.03%] [G loss: 0.524414]\n",
      "epoch:4 step:4567 [D loss: 0.178708, acc.: 77.34%] [G loss: 0.559820]\n",
      "epoch:4 step:4568 [D loss: 0.219459, acc.: 67.19%] [G loss: 0.494199]\n",
      "epoch:4 step:4569 [D loss: 0.180895, acc.: 67.97%] [G loss: 0.563600]\n",
      "epoch:4 step:4570 [D loss: 0.191057, acc.: 68.75%] [G loss: 0.548648]\n",
      "epoch:4 step:4571 [D loss: 0.202628, acc.: 65.62%] [G loss: 0.532752]\n",
      "epoch:4 step:4572 [D loss: 0.247882, acc.: 62.50%] [G loss: 0.475767]\n",
      "epoch:4 step:4573 [D loss: 0.198933, acc.: 70.31%] [G loss: 0.511262]\n",
      "epoch:4 step:4574 [D loss: 0.226593, acc.: 62.50%] [G loss: 0.510334]\n",
      "epoch:4 step:4575 [D loss: 0.238615, acc.: 59.38%] [G loss: 0.511087]\n",
      "epoch:4 step:4576 [D loss: 0.208803, acc.: 66.41%] [G loss: 0.523280]\n",
      "epoch:4 step:4577 [D loss: 0.186633, acc.: 75.00%] [G loss: 0.553195]\n",
      "epoch:4 step:4578 [D loss: 0.203063, acc.: 72.66%] [G loss: 0.488853]\n",
      "epoch:4 step:4579 [D loss: 0.210165, acc.: 64.84%] [G loss: 0.508466]\n",
      "epoch:4 step:4580 [D loss: 0.173659, acc.: 73.44%] [G loss: 0.552039]\n",
      "epoch:4 step:4581 [D loss: 0.175203, acc.: 78.12%] [G loss: 0.549534]\n",
      "epoch:4 step:4582 [D loss: 0.235487, acc.: 60.94%] [G loss: 0.494656]\n",
      "epoch:4 step:4583 [D loss: 0.182813, acc.: 71.88%] [G loss: 0.572444]\n",
      "epoch:4 step:4584 [D loss: 0.221815, acc.: 64.84%] [G loss: 0.552854]\n",
      "epoch:4 step:4585 [D loss: 0.174534, acc.: 75.78%] [G loss: 0.567813]\n",
      "epoch:4 step:4586 [D loss: 0.199956, acc.: 64.06%] [G loss: 0.524676]\n",
      "epoch:4 step:4587 [D loss: 0.177101, acc.: 72.66%] [G loss: 0.523202]\n",
      "epoch:4 step:4588 [D loss: 0.204517, acc.: 69.53%] [G loss: 0.550498]\n",
      "epoch:4 step:4589 [D loss: 0.204247, acc.: 70.31%] [G loss: 0.525007]\n",
      "epoch:4 step:4590 [D loss: 0.185647, acc.: 69.53%] [G loss: 0.557269]\n",
      "epoch:4 step:4591 [D loss: 0.197662, acc.: 69.53%] [G loss: 0.609657]\n",
      "epoch:4 step:4592 [D loss: 0.198489, acc.: 72.66%] [G loss: 0.556120]\n",
      "epoch:4 step:4593 [D loss: 0.200690, acc.: 71.09%] [G loss: 0.577520]\n",
      "epoch:4 step:4594 [D loss: 0.210776, acc.: 67.19%] [G loss: 0.518450]\n",
      "epoch:4 step:4595 [D loss: 0.201773, acc.: 71.88%] [G loss: 0.541876]\n",
      "epoch:4 step:4596 [D loss: 0.198675, acc.: 67.97%] [G loss: 0.490209]\n",
      "epoch:4 step:4597 [D loss: 0.193882, acc.: 71.09%] [G loss: 0.542475]\n",
      "epoch:4 step:4598 [D loss: 0.203545, acc.: 69.53%] [G loss: 0.528516]\n",
      "epoch:4 step:4599 [D loss: 0.207637, acc.: 66.41%] [G loss: 0.516847]\n",
      "epoch:4 step:4600 [D loss: 0.218449, acc.: 65.62%] [G loss: 0.554681]\n",
      "epoch:4 step:4601 [D loss: 0.180775, acc.: 71.88%] [G loss: 0.614967]\n",
      "epoch:4 step:4602 [D loss: 0.178057, acc.: 72.66%] [G loss: 0.564268]\n",
      "epoch:4 step:4603 [D loss: 0.221023, acc.: 65.62%] [G loss: 0.542376]\n",
      "epoch:4 step:4604 [D loss: 0.202211, acc.: 65.62%] [G loss: 0.526363]\n",
      "epoch:4 step:4605 [D loss: 0.203267, acc.: 71.88%] [G loss: 0.483631]\n",
      "epoch:4 step:4606 [D loss: 0.233560, acc.: 61.72%] [G loss: 0.533060]\n",
      "epoch:4 step:4607 [D loss: 0.215699, acc.: 65.62%] [G loss: 0.537304]\n",
      "epoch:4 step:4608 [D loss: 0.153614, acc.: 82.81%] [G loss: 0.599702]\n",
      "epoch:4 step:4609 [D loss: 0.232951, acc.: 64.84%] [G loss: 0.478173]\n",
      "epoch:4 step:4610 [D loss: 0.206114, acc.: 71.09%] [G loss: 0.538830]\n",
      "epoch:4 step:4611 [D loss: 0.206388, acc.: 66.41%] [G loss: 0.507738]\n",
      "epoch:4 step:4612 [D loss: 0.194400, acc.: 74.22%] [G loss: 0.555699]\n",
      "epoch:4 step:4613 [D loss: 0.199990, acc.: 76.56%] [G loss: 0.515134]\n",
      "epoch:4 step:4614 [D loss: 0.207489, acc.: 67.97%] [G loss: 0.512528]\n",
      "epoch:4 step:4615 [D loss: 0.210438, acc.: 65.62%] [G loss: 0.524325]\n",
      "epoch:4 step:4616 [D loss: 0.206469, acc.: 71.09%] [G loss: 0.512775]\n",
      "epoch:4 step:4617 [D loss: 0.226838, acc.: 65.62%] [G loss: 0.504328]\n",
      "epoch:4 step:4618 [D loss: 0.220977, acc.: 66.41%] [G loss: 0.515886]\n",
      "epoch:4 step:4619 [D loss: 0.170843, acc.: 75.00%] [G loss: 0.605208]\n",
      "epoch:4 step:4620 [D loss: 0.212664, acc.: 67.19%] [G loss: 0.551693]\n",
      "epoch:4 step:4621 [D loss: 0.208682, acc.: 68.75%] [G loss: 0.570407]\n",
      "epoch:4 step:4622 [D loss: 0.218418, acc.: 64.06%] [G loss: 0.490452]\n",
      "epoch:4 step:4623 [D loss: 0.156610, acc.: 76.56%] [G loss: 0.603191]\n",
      "epoch:4 step:4624 [D loss: 0.231488, acc.: 59.38%] [G loss: 0.498682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4625 [D loss: 0.212791, acc.: 67.19%] [G loss: 0.510769]\n",
      "epoch:4 step:4626 [D loss: 0.201608, acc.: 71.88%] [G loss: 0.512670]\n",
      "epoch:4 step:4627 [D loss: 0.219412, acc.: 68.75%] [G loss: 0.531735]\n",
      "epoch:4 step:4628 [D loss: 0.246670, acc.: 60.16%] [G loss: 0.502490]\n",
      "epoch:4 step:4629 [D loss: 0.214769, acc.: 64.84%] [G loss: 0.524901]\n",
      "epoch:4 step:4630 [D loss: 0.201825, acc.: 69.53%] [G loss: 0.570348]\n",
      "epoch:4 step:4631 [D loss: 0.244485, acc.: 60.94%] [G loss: 0.510935]\n",
      "epoch:4 step:4632 [D loss: 0.178846, acc.: 71.88%] [G loss: 0.577017]\n",
      "epoch:4 step:4633 [D loss: 0.197989, acc.: 64.06%] [G loss: 0.562703]\n",
      "epoch:4 step:4634 [D loss: 0.183792, acc.: 70.31%] [G loss: 0.546712]\n",
      "epoch:4 step:4635 [D loss: 0.201616, acc.: 66.41%] [G loss: 0.582539]\n",
      "epoch:4 step:4636 [D loss: 0.188887, acc.: 71.09%] [G loss: 0.566667]\n",
      "epoch:4 step:4637 [D loss: 0.179197, acc.: 74.22%] [G loss: 0.541822]\n",
      "epoch:4 step:4638 [D loss: 0.173473, acc.: 72.66%] [G loss: 0.523711]\n",
      "epoch:4 step:4639 [D loss: 0.250147, acc.: 59.38%] [G loss: 0.479965]\n",
      "epoch:4 step:4640 [D loss: 0.235806, acc.: 57.81%] [G loss: 0.496922]\n",
      "epoch:4 step:4641 [D loss: 0.190834, acc.: 70.31%] [G loss: 0.548973]\n",
      "epoch:4 step:4642 [D loss: 0.194663, acc.: 65.62%] [G loss: 0.613531]\n",
      "epoch:4 step:4643 [D loss: 0.223929, acc.: 68.75%] [G loss: 0.544083]\n",
      "epoch:4 step:4644 [D loss: 0.199938, acc.: 68.75%] [G loss: 0.587947]\n",
      "epoch:4 step:4645 [D loss: 0.175022, acc.: 75.00%] [G loss: 0.551035]\n",
      "epoch:4 step:4646 [D loss: 0.183184, acc.: 69.53%] [G loss: 0.541824]\n",
      "epoch:4 step:4647 [D loss: 0.176996, acc.: 76.56%] [G loss: 0.565924]\n",
      "epoch:4 step:4648 [D loss: 0.167461, acc.: 77.34%] [G loss: 0.638027]\n",
      "epoch:4 step:4649 [D loss: 0.210758, acc.: 66.41%] [G loss: 0.520139]\n",
      "epoch:4 step:4650 [D loss: 0.218824, acc.: 62.50%] [G loss: 0.479353]\n",
      "epoch:4 step:4651 [D loss: 0.196728, acc.: 69.53%] [G loss: 0.539273]\n",
      "epoch:4 step:4652 [D loss: 0.199961, acc.: 75.78%] [G loss: 0.554306]\n",
      "epoch:4 step:4653 [D loss: 0.223488, acc.: 64.84%] [G loss: 0.546145]\n",
      "epoch:4 step:4654 [D loss: 0.167705, acc.: 72.66%] [G loss: 0.618378]\n",
      "epoch:4 step:4655 [D loss: 0.219589, acc.: 66.41%] [G loss: 0.546502]\n",
      "epoch:4 step:4656 [D loss: 0.201990, acc.: 67.19%] [G loss: 0.493926]\n",
      "epoch:4 step:4657 [D loss: 0.148809, acc.: 78.91%] [G loss: 0.593614]\n",
      "epoch:4 step:4658 [D loss: 0.196434, acc.: 67.97%] [G loss: 0.583384]\n",
      "epoch:4 step:4659 [D loss: 0.181537, acc.: 75.00%] [G loss: 0.625568]\n",
      "epoch:4 step:4660 [D loss: 0.152121, acc.: 78.12%] [G loss: 0.636487]\n",
      "epoch:4 step:4661 [D loss: 0.225684, acc.: 65.62%] [G loss: 0.609205]\n",
      "epoch:4 step:4662 [D loss: 0.233244, acc.: 69.53%] [G loss: 0.645473]\n",
      "epoch:4 step:4663 [D loss: 0.206576, acc.: 65.62%] [G loss: 0.552133]\n",
      "epoch:4 step:4664 [D loss: 0.249606, acc.: 59.38%] [G loss: 0.529331]\n",
      "epoch:4 step:4665 [D loss: 0.259291, acc.: 53.91%] [G loss: 0.487170]\n",
      "epoch:4 step:4666 [D loss: 0.159434, acc.: 76.56%] [G loss: 0.590315]\n",
      "epoch:4 step:4667 [D loss: 0.179161, acc.: 74.22%] [G loss: 0.604179]\n",
      "epoch:4 step:4668 [D loss: 0.308180, acc.: 51.56%] [G loss: 0.522412]\n",
      "epoch:4 step:4669 [D loss: 0.156015, acc.: 75.00%] [G loss: 0.610747]\n",
      "epoch:4 step:4670 [D loss: 0.258730, acc.: 54.69%] [G loss: 0.558084]\n",
      "epoch:4 step:4671 [D loss: 0.174191, acc.: 74.22%] [G loss: 0.587880]\n",
      "epoch:4 step:4672 [D loss: 0.162983, acc.: 77.34%] [G loss: 0.646936]\n",
      "epoch:4 step:4673 [D loss: 0.156760, acc.: 78.12%] [G loss: 0.704710]\n",
      "epoch:4 step:4674 [D loss: 0.157347, acc.: 81.25%] [G loss: 0.638581]\n",
      "epoch:4 step:4675 [D loss: 0.183297, acc.: 74.22%] [G loss: 0.712424]\n",
      "epoch:4 step:4676 [D loss: 0.348659, acc.: 46.88%] [G loss: 0.556231]\n",
      "epoch:4 step:4677 [D loss: 0.115734, acc.: 86.72%] [G loss: 0.749369]\n",
      "epoch:4 step:4678 [D loss: 0.229221, acc.: 64.06%] [G loss: 0.552601]\n",
      "epoch:4 step:4679 [D loss: 0.225140, acc.: 65.62%] [G loss: 0.522732]\n",
      "epoch:4 step:4680 [D loss: 0.201365, acc.: 67.19%] [G loss: 0.561955]\n",
      "epoch:4 step:4681 [D loss: 0.202500, acc.: 70.31%] [G loss: 0.583858]\n",
      "epoch:4 step:4682 [D loss: 0.196286, acc.: 67.19%] [G loss: 0.583904]\n",
      "epoch:4 step:4683 [D loss: 0.192367, acc.: 72.66%] [G loss: 0.527686]\n",
      "epoch:4 step:4684 [D loss: 0.146773, acc.: 82.03%] [G loss: 0.622198]\n",
      "epoch:4 step:4685 [D loss: 0.145454, acc.: 81.25%] [G loss: 0.650416]\n",
      "epoch:5 step:4686 [D loss: 0.244663, acc.: 62.50%] [G loss: 0.620286]\n",
      "epoch:5 step:4687 [D loss: 0.188225, acc.: 73.44%] [G loss: 0.555538]\n",
      "epoch:5 step:4688 [D loss: 0.231309, acc.: 65.62%] [G loss: 0.581509]\n",
      "epoch:5 step:4689 [D loss: 0.221117, acc.: 64.84%] [G loss: 0.533411]\n",
      "epoch:5 step:4690 [D loss: 0.184353, acc.: 70.31%] [G loss: 0.610807]\n",
      "epoch:5 step:4691 [D loss: 0.212175, acc.: 65.62%] [G loss: 0.556100]\n",
      "epoch:5 step:4692 [D loss: 0.197891, acc.: 69.53%] [G loss: 0.596066]\n",
      "epoch:5 step:4693 [D loss: 0.222400, acc.: 61.72%] [G loss: 0.552199]\n",
      "epoch:5 step:4694 [D loss: 0.175935, acc.: 76.56%] [G loss: 0.557371]\n",
      "epoch:5 step:4695 [D loss: 0.196384, acc.: 67.19%] [G loss: 0.580137]\n",
      "epoch:5 step:4696 [D loss: 0.193087, acc.: 71.88%] [G loss: 0.604212]\n",
      "epoch:5 step:4697 [D loss: 0.209642, acc.: 69.53%] [G loss: 0.562596]\n",
      "epoch:5 step:4698 [D loss: 0.217166, acc.: 63.28%] [G loss: 0.534875]\n",
      "epoch:5 step:4699 [D loss: 0.184415, acc.: 74.22%] [G loss: 0.562116]\n",
      "epoch:5 step:4700 [D loss: 0.198138, acc.: 66.41%] [G loss: 0.573098]\n",
      "epoch:5 step:4701 [D loss: 0.204116, acc.: 68.75%] [G loss: 0.560668]\n",
      "epoch:5 step:4702 [D loss: 0.261315, acc.: 55.47%] [G loss: 0.467120]\n",
      "epoch:5 step:4703 [D loss: 0.224620, acc.: 64.84%] [G loss: 0.522624]\n",
      "epoch:5 step:4704 [D loss: 0.229039, acc.: 64.06%] [G loss: 0.506597]\n",
      "epoch:5 step:4705 [D loss: 0.276577, acc.: 51.56%] [G loss: 0.507042]\n",
      "epoch:5 step:4706 [D loss: 0.206030, acc.: 67.97%] [G loss: 0.535980]\n",
      "epoch:5 step:4707 [D loss: 0.195255, acc.: 71.09%] [G loss: 0.618342]\n",
      "epoch:5 step:4708 [D loss: 0.239509, acc.: 59.38%] [G loss: 0.513554]\n",
      "epoch:5 step:4709 [D loss: 0.202972, acc.: 68.75%] [G loss: 0.504672]\n",
      "epoch:5 step:4710 [D loss: 0.168700, acc.: 72.66%] [G loss: 0.570739]\n",
      "epoch:5 step:4711 [D loss: 0.216689, acc.: 67.19%] [G loss: 0.563177]\n",
      "epoch:5 step:4712 [D loss: 0.196048, acc.: 65.62%] [G loss: 0.556460]\n",
      "epoch:5 step:4713 [D loss: 0.193091, acc.: 74.22%] [G loss: 0.570461]\n",
      "epoch:5 step:4714 [D loss: 0.186736, acc.: 73.44%] [G loss: 0.552972]\n",
      "epoch:5 step:4715 [D loss: 0.224461, acc.: 62.50%] [G loss: 0.520776]\n",
      "epoch:5 step:4716 [D loss: 0.235317, acc.: 63.28%] [G loss: 0.518558]\n",
      "epoch:5 step:4717 [D loss: 0.210036, acc.: 67.97%] [G loss: 0.528021]\n",
      "epoch:5 step:4718 [D loss: 0.197279, acc.: 72.66%] [G loss: 0.522249]\n",
      "epoch:5 step:4719 [D loss: 0.198037, acc.: 71.09%] [G loss: 0.520856]\n",
      "epoch:5 step:4720 [D loss: 0.180112, acc.: 73.44%] [G loss: 0.524113]\n",
      "epoch:5 step:4721 [D loss: 0.182505, acc.: 71.09%] [G loss: 0.560774]\n",
      "epoch:5 step:4722 [D loss: 0.173542, acc.: 76.56%] [G loss: 0.548104]\n",
      "epoch:5 step:4723 [D loss: 0.228889, acc.: 63.28%] [G loss: 0.507012]\n",
      "epoch:5 step:4724 [D loss: 0.165948, acc.: 75.00%] [G loss: 0.536497]\n",
      "epoch:5 step:4725 [D loss: 0.165655, acc.: 76.56%] [G loss: 0.594919]\n",
      "epoch:5 step:4726 [D loss: 0.198725, acc.: 69.53%] [G loss: 0.556367]\n",
      "epoch:5 step:4727 [D loss: 0.188094, acc.: 68.75%] [G loss: 0.536716]\n",
      "epoch:5 step:4728 [D loss: 0.168255, acc.: 79.69%] [G loss: 0.569627]\n",
      "epoch:5 step:4729 [D loss: 0.231174, acc.: 63.28%] [G loss: 0.515049]\n",
      "epoch:5 step:4730 [D loss: 0.233095, acc.: 64.84%] [G loss: 0.493536]\n",
      "epoch:5 step:4731 [D loss: 0.202802, acc.: 67.19%] [G loss: 0.485835]\n",
      "epoch:5 step:4732 [D loss: 0.197208, acc.: 66.41%] [G loss: 0.551722]\n",
      "epoch:5 step:4733 [D loss: 0.227429, acc.: 69.53%] [G loss: 0.492355]\n",
      "epoch:5 step:4734 [D loss: 0.180572, acc.: 74.22%] [G loss: 0.569486]\n",
      "epoch:5 step:4735 [D loss: 0.194479, acc.: 67.19%] [G loss: 0.591754]\n",
      "epoch:5 step:4736 [D loss: 0.244876, acc.: 60.94%] [G loss: 0.539492]\n",
      "epoch:5 step:4737 [D loss: 0.217111, acc.: 64.06%] [G loss: 0.536775]\n",
      "epoch:5 step:4738 [D loss: 0.178047, acc.: 74.22%] [G loss: 0.603120]\n",
      "epoch:5 step:4739 [D loss: 0.201563, acc.: 66.41%] [G loss: 0.524901]\n",
      "epoch:5 step:4740 [D loss: 0.194915, acc.: 75.00%] [G loss: 0.576373]\n",
      "epoch:5 step:4741 [D loss: 0.185556, acc.: 70.31%] [G loss: 0.589593]\n",
      "epoch:5 step:4742 [D loss: 0.184636, acc.: 72.66%] [G loss: 0.588539]\n",
      "epoch:5 step:4743 [D loss: 0.203005, acc.: 67.97%] [G loss: 0.524619]\n",
      "epoch:5 step:4744 [D loss: 0.186872, acc.: 69.53%] [G loss: 0.540042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4745 [D loss: 0.200895, acc.: 67.97%] [G loss: 0.545214]\n",
      "epoch:5 step:4746 [D loss: 0.213035, acc.: 61.72%] [G loss: 0.504593]\n",
      "epoch:5 step:4747 [D loss: 0.175603, acc.: 71.88%] [G loss: 0.534048]\n",
      "epoch:5 step:4748 [D loss: 0.214855, acc.: 68.75%] [G loss: 0.563695]\n",
      "epoch:5 step:4749 [D loss: 0.181178, acc.: 73.44%] [G loss: 0.586985]\n",
      "epoch:5 step:4750 [D loss: 0.227385, acc.: 64.84%] [G loss: 0.489141]\n",
      "epoch:5 step:4751 [D loss: 0.202936, acc.: 67.97%] [G loss: 0.539395]\n",
      "epoch:5 step:4752 [D loss: 0.194955, acc.: 68.75%] [G loss: 0.533840]\n",
      "epoch:5 step:4753 [D loss: 0.179781, acc.: 74.22%] [G loss: 0.560479]\n",
      "epoch:5 step:4754 [D loss: 0.176605, acc.: 75.78%] [G loss: 0.499138]\n",
      "epoch:5 step:4755 [D loss: 0.190955, acc.: 67.97%] [G loss: 0.574780]\n",
      "epoch:5 step:4756 [D loss: 0.180512, acc.: 73.44%] [G loss: 0.546020]\n",
      "epoch:5 step:4757 [D loss: 0.198027, acc.: 68.75%] [G loss: 0.521904]\n",
      "epoch:5 step:4758 [D loss: 0.192958, acc.: 68.75%] [G loss: 0.546878]\n",
      "epoch:5 step:4759 [D loss: 0.168882, acc.: 75.78%] [G loss: 0.565729]\n",
      "epoch:5 step:4760 [D loss: 0.179459, acc.: 70.31%] [G loss: 0.627970]\n",
      "epoch:5 step:4761 [D loss: 0.177106, acc.: 72.66%] [G loss: 0.587051]\n",
      "epoch:5 step:4762 [D loss: 0.188839, acc.: 66.41%] [G loss: 0.628625]\n",
      "epoch:5 step:4763 [D loss: 0.275917, acc.: 56.25%] [G loss: 0.483882]\n",
      "epoch:5 step:4764 [D loss: 0.210242, acc.: 66.41%] [G loss: 0.485209]\n",
      "epoch:5 step:4765 [D loss: 0.195834, acc.: 68.75%] [G loss: 0.497009]\n",
      "epoch:5 step:4766 [D loss: 0.260397, acc.: 53.12%] [G loss: 0.488114]\n",
      "epoch:5 step:4767 [D loss: 0.190760, acc.: 71.09%] [G loss: 0.540058]\n",
      "epoch:5 step:4768 [D loss: 0.180093, acc.: 71.88%] [G loss: 0.572568]\n",
      "epoch:5 step:4769 [D loss: 0.197238, acc.: 71.09%] [G loss: 0.566129]\n",
      "epoch:5 step:4770 [D loss: 0.215247, acc.: 67.97%] [G loss: 0.532885]\n",
      "epoch:5 step:4771 [D loss: 0.222363, acc.: 63.28%] [G loss: 0.507085]\n",
      "epoch:5 step:4772 [D loss: 0.205152, acc.: 65.62%] [G loss: 0.522674]\n",
      "epoch:5 step:4773 [D loss: 0.182044, acc.: 72.66%] [G loss: 0.554081]\n",
      "epoch:5 step:4774 [D loss: 0.189374, acc.: 75.78%] [G loss: 0.551297]\n",
      "epoch:5 step:4775 [D loss: 0.195321, acc.: 67.97%] [G loss: 0.505130]\n",
      "epoch:5 step:4776 [D loss: 0.242590, acc.: 57.03%] [G loss: 0.512788]\n",
      "epoch:5 step:4777 [D loss: 0.189325, acc.: 71.09%] [G loss: 0.564838]\n",
      "epoch:5 step:4778 [D loss: 0.235710, acc.: 64.84%] [G loss: 0.525235]\n",
      "epoch:5 step:4779 [D loss: 0.214811, acc.: 66.41%] [G loss: 0.564323]\n",
      "epoch:5 step:4780 [D loss: 0.176333, acc.: 72.66%] [G loss: 0.574013]\n",
      "epoch:5 step:4781 [D loss: 0.174048, acc.: 71.88%] [G loss: 0.549054]\n",
      "epoch:5 step:4782 [D loss: 0.169961, acc.: 75.00%] [G loss: 0.553712]\n",
      "epoch:5 step:4783 [D loss: 0.211066, acc.: 68.75%] [G loss: 0.515522]\n",
      "epoch:5 step:4784 [D loss: 0.241976, acc.: 57.03%] [G loss: 0.512190]\n",
      "epoch:5 step:4785 [D loss: 0.163793, acc.: 78.91%] [G loss: 0.586996]\n",
      "epoch:5 step:4786 [D loss: 0.194869, acc.: 70.31%] [G loss: 0.522284]\n",
      "epoch:5 step:4787 [D loss: 0.212625, acc.: 73.44%] [G loss: 0.528765]\n",
      "epoch:5 step:4788 [D loss: 0.198165, acc.: 70.31%] [G loss: 0.510821]\n",
      "epoch:5 step:4789 [D loss: 0.194822, acc.: 67.19%] [G loss: 0.484710]\n",
      "epoch:5 step:4790 [D loss: 0.249380, acc.: 58.59%] [G loss: 0.510916]\n",
      "epoch:5 step:4791 [D loss: 0.211711, acc.: 66.41%] [G loss: 0.544905]\n",
      "epoch:5 step:4792 [D loss: 0.233478, acc.: 61.72%] [G loss: 0.568448]\n",
      "epoch:5 step:4793 [D loss: 0.268271, acc.: 57.03%] [G loss: 0.519351]\n",
      "epoch:5 step:4794 [D loss: 0.228312, acc.: 60.16%] [G loss: 0.519096]\n",
      "epoch:5 step:4795 [D loss: 0.210696, acc.: 64.84%] [G loss: 0.521111]\n",
      "epoch:5 step:4796 [D loss: 0.194584, acc.: 71.88%] [G loss: 0.572416]\n",
      "epoch:5 step:4797 [D loss: 0.220785, acc.: 66.41%] [G loss: 0.522212]\n",
      "epoch:5 step:4798 [D loss: 0.228894, acc.: 60.94%] [G loss: 0.526392]\n",
      "epoch:5 step:4799 [D loss: 0.188665, acc.: 76.56%] [G loss: 0.523174]\n",
      "epoch:5 step:4800 [D loss: 0.199095, acc.: 70.31%] [G loss: 0.619955]\n",
      "epoch:5 step:4801 [D loss: 0.208687, acc.: 67.97%] [G loss: 0.632104]\n",
      "epoch:5 step:4802 [D loss: 0.186945, acc.: 70.31%] [G loss: 0.578773]\n",
      "epoch:5 step:4803 [D loss: 0.209165, acc.: 71.88%] [G loss: 0.515294]\n",
      "epoch:5 step:4804 [D loss: 0.165372, acc.: 76.56%] [G loss: 0.643549]\n",
      "epoch:5 step:4805 [D loss: 0.227219, acc.: 68.75%] [G loss: 0.578034]\n",
      "epoch:5 step:4806 [D loss: 0.209080, acc.: 64.06%] [G loss: 0.532657]\n",
      "epoch:5 step:4807 [D loss: 0.179316, acc.: 75.78%] [G loss: 0.529839]\n",
      "epoch:5 step:4808 [D loss: 0.214900, acc.: 68.75%] [G loss: 0.560093]\n",
      "epoch:5 step:4809 [D loss: 0.215097, acc.: 66.41%] [G loss: 0.469124]\n",
      "epoch:5 step:4810 [D loss: 0.209596, acc.: 64.84%] [G loss: 0.448217]\n",
      "epoch:5 step:4811 [D loss: 0.177831, acc.: 75.78%] [G loss: 0.539265]\n",
      "epoch:5 step:4812 [D loss: 0.200263, acc.: 66.41%] [G loss: 0.551497]\n",
      "epoch:5 step:4813 [D loss: 0.227656, acc.: 66.41%] [G loss: 0.525606]\n",
      "epoch:5 step:4814 [D loss: 0.245351, acc.: 59.38%] [G loss: 0.496953]\n",
      "epoch:5 step:4815 [D loss: 0.166472, acc.: 74.22%] [G loss: 0.548545]\n",
      "epoch:5 step:4816 [D loss: 0.202490, acc.: 73.44%] [G loss: 0.525075]\n",
      "epoch:5 step:4817 [D loss: 0.219118, acc.: 66.41%] [G loss: 0.516998]\n",
      "epoch:5 step:4818 [D loss: 0.246091, acc.: 62.50%] [G loss: 0.478493]\n",
      "epoch:5 step:4819 [D loss: 0.203936, acc.: 65.62%] [G loss: 0.536516]\n",
      "epoch:5 step:4820 [D loss: 0.199159, acc.: 71.88%] [G loss: 0.584209]\n",
      "epoch:5 step:4821 [D loss: 0.220885, acc.: 67.19%] [G loss: 0.535815]\n",
      "epoch:5 step:4822 [D loss: 0.253869, acc.: 60.16%] [G loss: 0.496765]\n",
      "epoch:5 step:4823 [D loss: 0.220186, acc.: 67.97%] [G loss: 0.510359]\n",
      "epoch:5 step:4824 [D loss: 0.221519, acc.: 67.97%] [G loss: 0.548285]\n",
      "epoch:5 step:4825 [D loss: 0.229272, acc.: 54.69%] [G loss: 0.557496]\n",
      "epoch:5 step:4826 [D loss: 0.219488, acc.: 64.06%] [G loss: 0.514717]\n",
      "epoch:5 step:4827 [D loss: 0.222548, acc.: 65.62%] [G loss: 0.445547]\n",
      "epoch:5 step:4828 [D loss: 0.238286, acc.: 60.16%] [G loss: 0.475742]\n",
      "epoch:5 step:4829 [D loss: 0.194554, acc.: 74.22%] [G loss: 0.545595]\n",
      "epoch:5 step:4830 [D loss: 0.241308, acc.: 57.81%] [G loss: 0.525888]\n",
      "epoch:5 step:4831 [D loss: 0.198826, acc.: 69.53%] [G loss: 0.484019]\n",
      "epoch:5 step:4832 [D loss: 0.247288, acc.: 57.81%] [G loss: 0.514294]\n",
      "epoch:5 step:4833 [D loss: 0.219340, acc.: 64.84%] [G loss: 0.539195]\n",
      "epoch:5 step:4834 [D loss: 0.196392, acc.: 69.53%] [G loss: 0.567803]\n",
      "epoch:5 step:4835 [D loss: 0.219296, acc.: 66.41%] [G loss: 0.553606]\n",
      "epoch:5 step:4836 [D loss: 0.185194, acc.: 71.88%] [G loss: 0.612737]\n",
      "epoch:5 step:4837 [D loss: 0.213057, acc.: 67.97%] [G loss: 0.537869]\n",
      "epoch:5 step:4838 [D loss: 0.238122, acc.: 63.28%] [G loss: 0.506838]\n",
      "epoch:5 step:4839 [D loss: 0.211691, acc.: 70.31%] [G loss: 0.537569]\n",
      "epoch:5 step:4840 [D loss: 0.176931, acc.: 77.34%] [G loss: 0.547943]\n",
      "epoch:5 step:4841 [D loss: 0.182996, acc.: 75.00%] [G loss: 0.544673]\n",
      "epoch:5 step:4842 [D loss: 0.236186, acc.: 56.25%] [G loss: 0.501409]\n",
      "epoch:5 step:4843 [D loss: 0.213912, acc.: 64.84%] [G loss: 0.513922]\n",
      "epoch:5 step:4844 [D loss: 0.193181, acc.: 67.97%] [G loss: 0.555390]\n",
      "epoch:5 step:4845 [D loss: 0.235050, acc.: 60.16%] [G loss: 0.538994]\n",
      "epoch:5 step:4846 [D loss: 0.194707, acc.: 66.41%] [G loss: 0.529702]\n",
      "epoch:5 step:4847 [D loss: 0.164943, acc.: 78.91%] [G loss: 0.565688]\n",
      "epoch:5 step:4848 [D loss: 0.172016, acc.: 67.97%] [G loss: 0.586198]\n",
      "epoch:5 step:4849 [D loss: 0.195670, acc.: 71.09%] [G loss: 0.526591]\n",
      "epoch:5 step:4850 [D loss: 0.190024, acc.: 71.09%] [G loss: 0.533857]\n",
      "epoch:5 step:4851 [D loss: 0.201599, acc.: 70.31%] [G loss: 0.532392]\n",
      "epoch:5 step:4852 [D loss: 0.203404, acc.: 67.19%] [G loss: 0.494750]\n",
      "epoch:5 step:4853 [D loss: 0.209172, acc.: 65.62%] [G loss: 0.528423]\n",
      "epoch:5 step:4854 [D loss: 0.201219, acc.: 67.97%] [G loss: 0.556317]\n",
      "epoch:5 step:4855 [D loss: 0.221823, acc.: 61.72%] [G loss: 0.525272]\n",
      "epoch:5 step:4856 [D loss: 0.187053, acc.: 67.97%] [G loss: 0.557135]\n",
      "epoch:5 step:4857 [D loss: 0.229415, acc.: 67.19%] [G loss: 0.469442]\n",
      "epoch:5 step:4858 [D loss: 0.173483, acc.: 76.56%] [G loss: 0.527127]\n",
      "epoch:5 step:4859 [D loss: 0.197413, acc.: 68.75%] [G loss: 0.532605]\n",
      "epoch:5 step:4860 [D loss: 0.229315, acc.: 60.94%] [G loss: 0.459454]\n",
      "epoch:5 step:4861 [D loss: 0.223518, acc.: 64.06%] [G loss: 0.482512]\n",
      "epoch:5 step:4862 [D loss: 0.217922, acc.: 68.75%] [G loss: 0.495850]\n",
      "epoch:5 step:4863 [D loss: 0.202784, acc.: 68.75%] [G loss: 0.519247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4864 [D loss: 0.199278, acc.: 71.09%] [G loss: 0.529033]\n",
      "epoch:5 step:4865 [D loss: 0.222564, acc.: 64.06%] [G loss: 0.527104]\n",
      "epoch:5 step:4866 [D loss: 0.209090, acc.: 66.41%] [G loss: 0.499163]\n",
      "epoch:5 step:4867 [D loss: 0.222943, acc.: 63.28%] [G loss: 0.526262]\n",
      "epoch:5 step:4868 [D loss: 0.215538, acc.: 74.22%] [G loss: 0.507423]\n",
      "epoch:5 step:4869 [D loss: 0.213617, acc.: 68.75%] [G loss: 0.500893]\n",
      "epoch:5 step:4870 [D loss: 0.232409, acc.: 61.72%] [G loss: 0.452092]\n",
      "epoch:5 step:4871 [D loss: 0.221126, acc.: 62.50%] [G loss: 0.501545]\n",
      "epoch:5 step:4872 [D loss: 0.232532, acc.: 60.16%] [G loss: 0.510419]\n",
      "epoch:5 step:4873 [D loss: 0.217365, acc.: 63.28%] [G loss: 0.510288]\n",
      "epoch:5 step:4874 [D loss: 0.247442, acc.: 57.03%] [G loss: 0.469510]\n",
      "epoch:5 step:4875 [D loss: 0.182119, acc.: 71.09%] [G loss: 0.530830]\n",
      "epoch:5 step:4876 [D loss: 0.208653, acc.: 71.88%] [G loss: 0.509355]\n",
      "epoch:5 step:4877 [D loss: 0.201676, acc.: 75.00%] [G loss: 0.561048]\n",
      "epoch:5 step:4878 [D loss: 0.190949, acc.: 75.78%] [G loss: 0.536885]\n",
      "epoch:5 step:4879 [D loss: 0.172239, acc.: 75.78%] [G loss: 0.572720]\n",
      "epoch:5 step:4880 [D loss: 0.192249, acc.: 71.09%] [G loss: 0.566724]\n",
      "epoch:5 step:4881 [D loss: 0.224033, acc.: 64.06%] [G loss: 0.532654]\n",
      "epoch:5 step:4882 [D loss: 0.173133, acc.: 75.78%] [G loss: 0.590696]\n",
      "epoch:5 step:4883 [D loss: 0.171445, acc.: 75.78%] [G loss: 0.575531]\n",
      "epoch:5 step:4884 [D loss: 0.218407, acc.: 69.53%] [G loss: 0.561680]\n",
      "epoch:5 step:4885 [D loss: 0.250471, acc.: 58.59%] [G loss: 0.479488]\n",
      "epoch:5 step:4886 [D loss: 0.230191, acc.: 59.38%] [G loss: 0.519981]\n",
      "epoch:5 step:4887 [D loss: 0.203022, acc.: 69.53%] [G loss: 0.550994]\n",
      "epoch:5 step:4888 [D loss: 0.250251, acc.: 58.59%] [G loss: 0.498905]\n",
      "epoch:5 step:4889 [D loss: 0.218900, acc.: 62.50%] [G loss: 0.483449]\n",
      "epoch:5 step:4890 [D loss: 0.207848, acc.: 65.62%] [G loss: 0.526452]\n",
      "epoch:5 step:4891 [D loss: 0.182899, acc.: 73.44%] [G loss: 0.538418]\n",
      "epoch:5 step:4892 [D loss: 0.168265, acc.: 77.34%] [G loss: 0.552320]\n",
      "epoch:5 step:4893 [D loss: 0.164325, acc.: 76.56%] [G loss: 0.578794]\n",
      "epoch:5 step:4894 [D loss: 0.184879, acc.: 71.09%] [G loss: 0.538325]\n",
      "epoch:5 step:4895 [D loss: 0.210786, acc.: 69.53%] [G loss: 0.482768]\n",
      "epoch:5 step:4896 [D loss: 0.206129, acc.: 70.31%] [G loss: 0.485585]\n",
      "epoch:5 step:4897 [D loss: 0.180276, acc.: 74.22%] [G loss: 0.541800]\n",
      "epoch:5 step:4898 [D loss: 0.215360, acc.: 66.41%] [G loss: 0.523248]\n",
      "epoch:5 step:4899 [D loss: 0.231902, acc.: 62.50%] [G loss: 0.495951]\n",
      "epoch:5 step:4900 [D loss: 0.239276, acc.: 61.72%] [G loss: 0.485065]\n",
      "epoch:5 step:4901 [D loss: 0.229687, acc.: 60.94%] [G loss: 0.539717]\n",
      "epoch:5 step:4902 [D loss: 0.184119, acc.: 74.22%] [G loss: 0.584744]\n",
      "epoch:5 step:4903 [D loss: 0.206306, acc.: 68.75%] [G loss: 0.533623]\n",
      "epoch:5 step:4904 [D loss: 0.184331, acc.: 71.88%] [G loss: 0.556716]\n",
      "epoch:5 step:4905 [D loss: 0.276087, acc.: 54.69%] [G loss: 0.558405]\n",
      "epoch:5 step:4906 [D loss: 0.163464, acc.: 78.91%] [G loss: 0.601888]\n",
      "epoch:5 step:4907 [D loss: 0.176540, acc.: 71.88%] [G loss: 0.622140]\n",
      "epoch:5 step:4908 [D loss: 0.173326, acc.: 78.12%] [G loss: 0.557708]\n",
      "epoch:5 step:4909 [D loss: 0.277156, acc.: 58.59%] [G loss: 0.466975]\n",
      "epoch:5 step:4910 [D loss: 0.217625, acc.: 65.62%] [G loss: 0.511691]\n",
      "epoch:5 step:4911 [D loss: 0.224160, acc.: 62.50%] [G loss: 0.498199]\n",
      "epoch:5 step:4912 [D loss: 0.206987, acc.: 68.75%] [G loss: 0.484259]\n",
      "epoch:5 step:4913 [D loss: 0.237624, acc.: 59.38%] [G loss: 0.500184]\n",
      "epoch:5 step:4914 [D loss: 0.182490, acc.: 75.00%] [G loss: 0.520596]\n",
      "epoch:5 step:4915 [D loss: 0.190207, acc.: 70.31%] [G loss: 0.518808]\n",
      "epoch:5 step:4916 [D loss: 0.177878, acc.: 75.00%] [G loss: 0.600917]\n",
      "epoch:5 step:4917 [D loss: 0.184507, acc.: 73.44%] [G loss: 0.620728]\n",
      "epoch:5 step:4918 [D loss: 0.243796, acc.: 62.50%] [G loss: 0.518931]\n",
      "epoch:5 step:4919 [D loss: 0.242822, acc.: 61.72%] [G loss: 0.484258]\n",
      "epoch:5 step:4920 [D loss: 0.243282, acc.: 55.47%] [G loss: 0.481749]\n",
      "epoch:5 step:4921 [D loss: 0.177277, acc.: 74.22%] [G loss: 0.562895]\n",
      "epoch:5 step:4922 [D loss: 0.205308, acc.: 65.62%] [G loss: 0.508367]\n",
      "epoch:5 step:4923 [D loss: 0.242377, acc.: 62.50%] [G loss: 0.484738]\n",
      "epoch:5 step:4924 [D loss: 0.192480, acc.: 68.75%] [G loss: 0.568426]\n",
      "epoch:5 step:4925 [D loss: 0.211132, acc.: 65.62%] [G loss: 0.503664]\n",
      "epoch:5 step:4926 [D loss: 0.193398, acc.: 69.53%] [G loss: 0.532676]\n",
      "epoch:5 step:4927 [D loss: 0.214008, acc.: 64.06%] [G loss: 0.534002]\n",
      "epoch:5 step:4928 [D loss: 0.193132, acc.: 65.62%] [G loss: 0.587688]\n",
      "epoch:5 step:4929 [D loss: 0.174471, acc.: 75.00%] [G loss: 0.533681]\n",
      "epoch:5 step:4930 [D loss: 0.204608, acc.: 66.41%] [G loss: 0.531207]\n",
      "epoch:5 step:4931 [D loss: 0.237255, acc.: 65.62%] [G loss: 0.509144]\n",
      "epoch:5 step:4932 [D loss: 0.197286, acc.: 69.53%] [G loss: 0.546928]\n",
      "epoch:5 step:4933 [D loss: 0.224406, acc.: 63.28%] [G loss: 0.488046]\n",
      "epoch:5 step:4934 [D loss: 0.218043, acc.: 63.28%] [G loss: 0.493543]\n",
      "epoch:5 step:4935 [D loss: 0.226727, acc.: 64.84%] [G loss: 0.543692]\n",
      "epoch:5 step:4936 [D loss: 0.215805, acc.: 61.72%] [G loss: 0.490650]\n",
      "epoch:5 step:4937 [D loss: 0.211132, acc.: 70.31%] [G loss: 0.509971]\n",
      "epoch:5 step:4938 [D loss: 0.198552, acc.: 63.28%] [G loss: 0.501606]\n",
      "epoch:5 step:4939 [D loss: 0.219371, acc.: 68.75%] [G loss: 0.536156]\n",
      "epoch:5 step:4940 [D loss: 0.214306, acc.: 64.06%] [G loss: 0.534192]\n",
      "epoch:5 step:4941 [D loss: 0.229765, acc.: 63.28%] [G loss: 0.494225]\n",
      "epoch:5 step:4942 [D loss: 0.192275, acc.: 73.44%] [G loss: 0.553447]\n",
      "epoch:5 step:4943 [D loss: 0.209625, acc.: 64.84%] [G loss: 0.491259]\n",
      "epoch:5 step:4944 [D loss: 0.204905, acc.: 67.19%] [G loss: 0.524597]\n",
      "epoch:5 step:4945 [D loss: 0.199551, acc.: 66.41%] [G loss: 0.530544]\n",
      "epoch:5 step:4946 [D loss: 0.209564, acc.: 63.28%] [G loss: 0.482314]\n",
      "epoch:5 step:4947 [D loss: 0.230960, acc.: 62.50%] [G loss: 0.541947]\n",
      "epoch:5 step:4948 [D loss: 0.242549, acc.: 59.38%] [G loss: 0.529630]\n",
      "epoch:5 step:4949 [D loss: 0.183541, acc.: 71.88%] [G loss: 0.564993]\n",
      "epoch:5 step:4950 [D loss: 0.270272, acc.: 50.00%] [G loss: 0.466626]\n",
      "epoch:5 step:4951 [D loss: 0.216551, acc.: 63.28%] [G loss: 0.469854]\n",
      "epoch:5 step:4952 [D loss: 0.217046, acc.: 71.09%] [G loss: 0.472292]\n",
      "epoch:5 step:4953 [D loss: 0.202943, acc.: 71.09%] [G loss: 0.517479]\n",
      "epoch:5 step:4954 [D loss: 0.193610, acc.: 72.66%] [G loss: 0.512874]\n",
      "epoch:5 step:4955 [D loss: 0.195077, acc.: 71.88%] [G loss: 0.532940]\n",
      "epoch:5 step:4956 [D loss: 0.178819, acc.: 71.88%] [G loss: 0.549233]\n",
      "epoch:5 step:4957 [D loss: 0.222940, acc.: 63.28%] [G loss: 0.482569]\n",
      "epoch:5 step:4958 [D loss: 0.212479, acc.: 64.06%] [G loss: 0.530710]\n",
      "epoch:5 step:4959 [D loss: 0.200744, acc.: 68.75%] [G loss: 0.496475]\n",
      "epoch:5 step:4960 [D loss: 0.242424, acc.: 59.38%] [G loss: 0.451802]\n",
      "epoch:5 step:4961 [D loss: 0.232720, acc.: 62.50%] [G loss: 0.543315]\n",
      "epoch:5 step:4962 [D loss: 0.238104, acc.: 60.94%] [G loss: 0.573751]\n",
      "epoch:5 step:4963 [D loss: 0.242645, acc.: 64.06%] [G loss: 0.534208]\n",
      "epoch:5 step:4964 [D loss: 0.232025, acc.: 66.41%] [G loss: 0.526409]\n",
      "epoch:5 step:4965 [D loss: 0.198525, acc.: 71.88%] [G loss: 0.544818]\n",
      "epoch:5 step:4966 [D loss: 0.256502, acc.: 59.38%] [G loss: 0.479038]\n",
      "epoch:5 step:4967 [D loss: 0.189618, acc.: 72.66%] [G loss: 0.556590]\n",
      "epoch:5 step:4968 [D loss: 0.184770, acc.: 72.66%] [G loss: 0.552724]\n",
      "epoch:5 step:4969 [D loss: 0.175944, acc.: 78.91%] [G loss: 0.526438]\n",
      "epoch:5 step:4970 [D loss: 0.167220, acc.: 76.56%] [G loss: 0.558782]\n",
      "epoch:5 step:4971 [D loss: 0.188039, acc.: 75.78%] [G loss: 0.532913]\n",
      "epoch:5 step:4972 [D loss: 0.207281, acc.: 67.19%] [G loss: 0.554788]\n",
      "epoch:5 step:4973 [D loss: 0.226741, acc.: 62.50%] [G loss: 0.521039]\n",
      "epoch:5 step:4974 [D loss: 0.210484, acc.: 68.75%] [G loss: 0.588997]\n",
      "epoch:5 step:4975 [D loss: 0.199577, acc.: 67.19%] [G loss: 0.546459]\n",
      "epoch:5 step:4976 [D loss: 0.197679, acc.: 71.88%] [G loss: 0.524575]\n",
      "epoch:5 step:4977 [D loss: 0.201960, acc.: 64.06%] [G loss: 0.540333]\n",
      "epoch:5 step:4978 [D loss: 0.183521, acc.: 74.22%] [G loss: 0.554836]\n",
      "epoch:5 step:4979 [D loss: 0.260955, acc.: 59.38%] [G loss: 0.475856]\n",
      "epoch:5 step:4980 [D loss: 0.218898, acc.: 61.72%] [G loss: 0.512278]\n",
      "epoch:5 step:4981 [D loss: 0.169953, acc.: 75.00%] [G loss: 0.543477]\n",
      "epoch:5 step:4982 [D loss: 0.198415, acc.: 67.97%] [G loss: 0.550326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4983 [D loss: 0.178891, acc.: 75.78%] [G loss: 0.547187]\n",
      "epoch:5 step:4984 [D loss: 0.190652, acc.: 70.31%] [G loss: 0.583983]\n",
      "epoch:5 step:4985 [D loss: 0.172657, acc.: 73.44%] [G loss: 0.552694]\n",
      "epoch:5 step:4986 [D loss: 0.228665, acc.: 64.06%] [G loss: 0.501943]\n",
      "epoch:5 step:4987 [D loss: 0.209504, acc.: 68.75%] [G loss: 0.493307]\n",
      "epoch:5 step:4988 [D loss: 0.215941, acc.: 64.06%] [G loss: 0.506215]\n",
      "epoch:5 step:4989 [D loss: 0.173426, acc.: 74.22%] [G loss: 0.551199]\n",
      "epoch:5 step:4990 [D loss: 0.200219, acc.: 70.31%] [G loss: 0.545996]\n",
      "epoch:5 step:4991 [D loss: 0.218117, acc.: 65.62%] [G loss: 0.585774]\n",
      "epoch:5 step:4992 [D loss: 0.229415, acc.: 64.06%] [G loss: 0.436834]\n",
      "epoch:5 step:4993 [D loss: 0.214169, acc.: 68.75%] [G loss: 0.512571]\n",
      "epoch:5 step:4994 [D loss: 0.182809, acc.: 70.31%] [G loss: 0.543091]\n",
      "epoch:5 step:4995 [D loss: 0.195294, acc.: 72.66%] [G loss: 0.586197]\n",
      "epoch:5 step:4996 [D loss: 0.164357, acc.: 78.12%] [G loss: 0.557207]\n",
      "epoch:5 step:4997 [D loss: 0.174211, acc.: 71.88%] [G loss: 0.605470]\n",
      "epoch:5 step:4998 [D loss: 0.168961, acc.: 73.44%] [G loss: 0.570282]\n",
      "epoch:5 step:4999 [D loss: 0.179363, acc.: 77.34%] [G loss: 0.597463]\n",
      "epoch:5 step:5000 [D loss: 0.165339, acc.: 73.44%] [G loss: 0.588389]\n",
      "epoch:5 step:5001 [D loss: 0.276435, acc.: 58.59%] [G loss: 0.487233]\n",
      "epoch:5 step:5002 [D loss: 0.230659, acc.: 64.06%] [G loss: 0.510614]\n",
      "epoch:5 step:5003 [D loss: 0.233218, acc.: 63.28%] [G loss: 0.486764]\n",
      "epoch:5 step:5004 [D loss: 0.199402, acc.: 66.41%] [G loss: 0.550300]\n",
      "epoch:5 step:5005 [D loss: 0.188347, acc.: 69.53%] [G loss: 0.547566]\n",
      "epoch:5 step:5006 [D loss: 0.157358, acc.: 80.47%] [G loss: 0.510782]\n",
      "epoch:5 step:5007 [D loss: 0.222314, acc.: 63.28%] [G loss: 0.545282]\n",
      "epoch:5 step:5008 [D loss: 0.244234, acc.: 59.38%] [G loss: 0.498673]\n",
      "epoch:5 step:5009 [D loss: 0.196554, acc.: 70.31%] [G loss: 0.486520]\n",
      "epoch:5 step:5010 [D loss: 0.205018, acc.: 67.97%] [G loss: 0.520535]\n",
      "epoch:5 step:5011 [D loss: 0.232486, acc.: 63.28%] [G loss: 0.520251]\n",
      "epoch:5 step:5012 [D loss: 0.210697, acc.: 70.31%] [G loss: 0.524219]\n",
      "epoch:5 step:5013 [D loss: 0.204544, acc.: 71.09%] [G loss: 0.516251]\n",
      "epoch:5 step:5014 [D loss: 0.248710, acc.: 57.81%] [G loss: 0.516651]\n",
      "epoch:5 step:5015 [D loss: 0.209075, acc.: 71.88%] [G loss: 0.552609]\n",
      "epoch:5 step:5016 [D loss: 0.200944, acc.: 68.75%] [G loss: 0.521770]\n",
      "epoch:5 step:5017 [D loss: 0.179806, acc.: 71.09%] [G loss: 0.532644]\n",
      "epoch:5 step:5018 [D loss: 0.216932, acc.: 70.31%] [G loss: 0.494682]\n",
      "epoch:5 step:5019 [D loss: 0.228322, acc.: 63.28%] [G loss: 0.547643]\n",
      "epoch:5 step:5020 [D loss: 0.201141, acc.: 71.88%] [G loss: 0.537344]\n",
      "epoch:5 step:5021 [D loss: 0.186390, acc.: 70.31%] [G loss: 0.605219]\n",
      "epoch:5 step:5022 [D loss: 0.172365, acc.: 76.56%] [G loss: 0.571013]\n",
      "epoch:5 step:5023 [D loss: 0.225742, acc.: 63.28%] [G loss: 0.475389]\n",
      "epoch:5 step:5024 [D loss: 0.181749, acc.: 78.12%] [G loss: 0.561262]\n",
      "epoch:5 step:5025 [D loss: 0.203291, acc.: 63.28%] [G loss: 0.546422]\n",
      "epoch:5 step:5026 [D loss: 0.231014, acc.: 67.19%] [G loss: 0.546439]\n",
      "epoch:5 step:5027 [D loss: 0.243670, acc.: 58.59%] [G loss: 0.508338]\n",
      "epoch:5 step:5028 [D loss: 0.170997, acc.: 75.78%] [G loss: 0.550291]\n",
      "epoch:5 step:5029 [D loss: 0.173941, acc.: 76.56%] [G loss: 0.578032]\n",
      "epoch:5 step:5030 [D loss: 0.199741, acc.: 72.66%] [G loss: 0.519127]\n",
      "epoch:5 step:5031 [D loss: 0.188805, acc.: 71.09%] [G loss: 0.564785]\n",
      "epoch:5 step:5032 [D loss: 0.183294, acc.: 74.22%] [G loss: 0.645020]\n",
      "epoch:5 step:5033 [D loss: 0.258963, acc.: 54.69%] [G loss: 0.521211]\n",
      "epoch:5 step:5034 [D loss: 0.238890, acc.: 62.50%] [G loss: 0.481630]\n",
      "epoch:5 step:5035 [D loss: 0.191962, acc.: 70.31%] [G loss: 0.551607]\n",
      "epoch:5 step:5036 [D loss: 0.181086, acc.: 77.34%] [G loss: 0.535960]\n",
      "epoch:5 step:5037 [D loss: 0.224154, acc.: 65.62%] [G loss: 0.496642]\n",
      "epoch:5 step:5038 [D loss: 0.187211, acc.: 71.09%] [G loss: 0.569633]\n",
      "epoch:5 step:5039 [D loss: 0.185418, acc.: 73.44%] [G loss: 0.569458]\n",
      "epoch:5 step:5040 [D loss: 0.238948, acc.: 64.84%] [G loss: 0.548954]\n",
      "epoch:5 step:5041 [D loss: 0.221271, acc.: 64.84%] [G loss: 0.504391]\n",
      "epoch:5 step:5042 [D loss: 0.218752, acc.: 69.53%] [G loss: 0.497731]\n",
      "epoch:5 step:5043 [D loss: 0.174773, acc.: 70.31%] [G loss: 0.603945]\n",
      "epoch:5 step:5044 [D loss: 0.182205, acc.: 71.88%] [G loss: 0.591693]\n",
      "epoch:5 step:5045 [D loss: 0.192264, acc.: 68.75%] [G loss: 0.531092]\n",
      "epoch:5 step:5046 [D loss: 0.211082, acc.: 65.62%] [G loss: 0.491543]\n",
      "epoch:5 step:5047 [D loss: 0.226884, acc.: 65.62%] [G loss: 0.499949]\n",
      "epoch:5 step:5048 [D loss: 0.210901, acc.: 63.28%] [G loss: 0.490539]\n",
      "epoch:5 step:5049 [D loss: 0.169548, acc.: 78.91%] [G loss: 0.513408]\n",
      "epoch:5 step:5050 [D loss: 0.208407, acc.: 64.84%] [G loss: 0.543598]\n",
      "epoch:5 step:5051 [D loss: 0.193594, acc.: 67.97%] [G loss: 0.558383]\n",
      "epoch:5 step:5052 [D loss: 0.196033, acc.: 71.88%] [G loss: 0.561932]\n",
      "epoch:5 step:5053 [D loss: 0.190968, acc.: 71.88%] [G loss: 0.542632]\n",
      "epoch:5 step:5054 [D loss: 0.221220, acc.: 68.75%] [G loss: 0.459475]\n",
      "epoch:5 step:5055 [D loss: 0.203569, acc.: 67.19%] [G loss: 0.535263]\n",
      "epoch:5 step:5056 [D loss: 0.177025, acc.: 71.88%] [G loss: 0.559941]\n",
      "epoch:5 step:5057 [D loss: 0.201728, acc.: 67.19%] [G loss: 0.548929]\n",
      "epoch:5 step:5058 [D loss: 0.236279, acc.: 63.28%] [G loss: 0.524826]\n",
      "epoch:5 step:5059 [D loss: 0.183773, acc.: 68.75%] [G loss: 0.568902]\n",
      "epoch:5 step:5060 [D loss: 0.234917, acc.: 60.16%] [G loss: 0.513013]\n",
      "epoch:5 step:5061 [D loss: 0.263056, acc.: 53.91%] [G loss: 0.457932]\n",
      "epoch:5 step:5062 [D loss: 0.248067, acc.: 58.59%] [G loss: 0.464029]\n",
      "epoch:5 step:5063 [D loss: 0.215780, acc.: 62.50%] [G loss: 0.471800]\n",
      "epoch:5 step:5064 [D loss: 0.208643, acc.: 61.72%] [G loss: 0.501406]\n",
      "epoch:5 step:5065 [D loss: 0.205529, acc.: 64.06%] [G loss: 0.504437]\n",
      "epoch:5 step:5066 [D loss: 0.174714, acc.: 69.53%] [G loss: 0.509271]\n",
      "epoch:5 step:5067 [D loss: 0.196244, acc.: 69.53%] [G loss: 0.544389]\n",
      "epoch:5 step:5068 [D loss: 0.215899, acc.: 66.41%] [G loss: 0.476195]\n",
      "epoch:5 step:5069 [D loss: 0.211951, acc.: 65.62%] [G loss: 0.509764]\n",
      "epoch:5 step:5070 [D loss: 0.173248, acc.: 74.22%] [G loss: 0.510121]\n",
      "epoch:5 step:5071 [D loss: 0.236551, acc.: 60.16%] [G loss: 0.517572]\n",
      "epoch:5 step:5072 [D loss: 0.236328, acc.: 57.03%] [G loss: 0.513727]\n",
      "epoch:5 step:5073 [D loss: 0.189135, acc.: 74.22%] [G loss: 0.561121]\n",
      "epoch:5 step:5074 [D loss: 0.228440, acc.: 64.06%] [G loss: 0.526035]\n",
      "epoch:5 step:5075 [D loss: 0.206677, acc.: 65.62%] [G loss: 0.531440]\n",
      "epoch:5 step:5076 [D loss: 0.196795, acc.: 75.00%] [G loss: 0.550145]\n",
      "epoch:5 step:5077 [D loss: 0.187837, acc.: 74.22%] [G loss: 0.573559]\n",
      "epoch:5 step:5078 [D loss: 0.240447, acc.: 64.06%] [G loss: 0.522043]\n",
      "epoch:5 step:5079 [D loss: 0.195429, acc.: 69.53%] [G loss: 0.527432]\n",
      "epoch:5 step:5080 [D loss: 0.224864, acc.: 63.28%] [G loss: 0.484761]\n",
      "epoch:5 step:5081 [D loss: 0.255831, acc.: 57.03%] [G loss: 0.485363]\n",
      "epoch:5 step:5082 [D loss: 0.192113, acc.: 68.75%] [G loss: 0.523144]\n",
      "epoch:5 step:5083 [D loss: 0.190689, acc.: 73.44%] [G loss: 0.549229]\n",
      "epoch:5 step:5084 [D loss: 0.178559, acc.: 73.44%] [G loss: 0.554095]\n",
      "epoch:5 step:5085 [D loss: 0.243626, acc.: 63.28%] [G loss: 0.505259]\n",
      "epoch:5 step:5086 [D loss: 0.220163, acc.: 67.19%] [G loss: 0.481414]\n",
      "epoch:5 step:5087 [D loss: 0.216812, acc.: 63.28%] [G loss: 0.525605]\n",
      "epoch:5 step:5088 [D loss: 0.212900, acc.: 60.94%] [G loss: 0.498757]\n",
      "epoch:5 step:5089 [D loss: 0.231600, acc.: 61.72%] [G loss: 0.513437]\n",
      "epoch:5 step:5090 [D loss: 0.215768, acc.: 67.97%] [G loss: 0.578699]\n",
      "epoch:5 step:5091 [D loss: 0.192574, acc.: 72.66%] [G loss: 0.562387]\n",
      "epoch:5 step:5092 [D loss: 0.241825, acc.: 58.59%] [G loss: 0.512147]\n",
      "epoch:5 step:5093 [D loss: 0.230561, acc.: 59.38%] [G loss: 0.521758]\n",
      "epoch:5 step:5094 [D loss: 0.207226, acc.: 64.84%] [G loss: 0.513995]\n",
      "epoch:5 step:5095 [D loss: 0.216745, acc.: 66.41%] [G loss: 0.525408]\n",
      "epoch:5 step:5096 [D loss: 0.216762, acc.: 66.41%] [G loss: 0.520872]\n",
      "epoch:5 step:5097 [D loss: 0.203783, acc.: 65.62%] [G loss: 0.458400]\n",
      "epoch:5 step:5098 [D loss: 0.206108, acc.: 67.97%] [G loss: 0.510435]\n",
      "epoch:5 step:5099 [D loss: 0.224474, acc.: 64.06%] [G loss: 0.526718]\n",
      "epoch:5 step:5100 [D loss: 0.238868, acc.: 64.06%] [G loss: 0.497462]\n",
      "epoch:5 step:5101 [D loss: 0.192322, acc.: 75.78%] [G loss: 0.563042]\n",
      "epoch:5 step:5102 [D loss: 0.230511, acc.: 57.03%] [G loss: 0.547618]\n",
      "epoch:5 step:5103 [D loss: 0.255896, acc.: 56.25%] [G loss: 0.476695]\n",
      "epoch:5 step:5104 [D loss: 0.207429, acc.: 66.41%] [G loss: 0.477191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5105 [D loss: 0.217422, acc.: 60.94%] [G loss: 0.532572]\n",
      "epoch:5 step:5106 [D loss: 0.226712, acc.: 67.97%] [G loss: 0.518087]\n",
      "epoch:5 step:5107 [D loss: 0.230527, acc.: 61.72%] [G loss: 0.492929]\n",
      "epoch:5 step:5108 [D loss: 0.222405, acc.: 62.50%] [G loss: 0.492767]\n",
      "epoch:5 step:5109 [D loss: 0.212779, acc.: 64.06%] [G loss: 0.504742]\n",
      "epoch:5 step:5110 [D loss: 0.186997, acc.: 70.31%] [G loss: 0.537055]\n",
      "epoch:5 step:5111 [D loss: 0.167686, acc.: 78.91%] [G loss: 0.570795]\n",
      "epoch:5 step:5112 [D loss: 0.186436, acc.: 71.88%] [G loss: 0.615210]\n",
      "epoch:5 step:5113 [D loss: 0.189824, acc.: 71.88%] [G loss: 0.545095]\n",
      "epoch:5 step:5114 [D loss: 0.188350, acc.: 71.88%] [G loss: 0.635139]\n",
      "epoch:5 step:5115 [D loss: 0.204117, acc.: 71.88%] [G loss: 0.548518]\n",
      "epoch:5 step:5116 [D loss: 0.229413, acc.: 63.28%] [G loss: 0.560919]\n",
      "epoch:5 step:5117 [D loss: 0.236212, acc.: 60.16%] [G loss: 0.504820]\n",
      "epoch:5 step:5118 [D loss: 0.199694, acc.: 69.53%] [G loss: 0.537878]\n",
      "epoch:5 step:5119 [D loss: 0.192278, acc.: 71.09%] [G loss: 0.527852]\n",
      "epoch:5 step:5120 [D loss: 0.217600, acc.: 66.41%] [G loss: 0.495489]\n",
      "epoch:5 step:5121 [D loss: 0.209205, acc.: 64.06%] [G loss: 0.539177]\n",
      "epoch:5 step:5122 [D loss: 0.273060, acc.: 56.25%] [G loss: 0.483564]\n",
      "epoch:5 step:5123 [D loss: 0.228636, acc.: 64.06%] [G loss: 0.475542]\n",
      "epoch:5 step:5124 [D loss: 0.202570, acc.: 71.09%] [G loss: 0.529750]\n",
      "epoch:5 step:5125 [D loss: 0.211367, acc.: 67.97%] [G loss: 0.480531]\n",
      "epoch:5 step:5126 [D loss: 0.202481, acc.: 74.22%] [G loss: 0.486677]\n",
      "epoch:5 step:5127 [D loss: 0.195286, acc.: 67.97%] [G loss: 0.519210]\n",
      "epoch:5 step:5128 [D loss: 0.206596, acc.: 67.19%] [G loss: 0.556040]\n",
      "epoch:5 step:5129 [D loss: 0.205068, acc.: 70.31%] [G loss: 0.542759]\n",
      "epoch:5 step:5130 [D loss: 0.177577, acc.: 73.44%] [G loss: 0.533452]\n",
      "epoch:5 step:5131 [D loss: 0.216682, acc.: 65.62%] [G loss: 0.548291]\n",
      "epoch:5 step:5132 [D loss: 0.209571, acc.: 67.97%] [G loss: 0.553194]\n",
      "epoch:5 step:5133 [D loss: 0.232457, acc.: 64.06%] [G loss: 0.496108]\n",
      "epoch:5 step:5134 [D loss: 0.197568, acc.: 67.19%] [G loss: 0.497562]\n",
      "epoch:5 step:5135 [D loss: 0.197650, acc.: 68.75%] [G loss: 0.457247]\n",
      "epoch:5 step:5136 [D loss: 0.171056, acc.: 75.00%] [G loss: 0.519961]\n",
      "epoch:5 step:5137 [D loss: 0.238177, acc.: 64.06%] [G loss: 0.492330]\n",
      "epoch:5 step:5138 [D loss: 0.198234, acc.: 67.19%] [G loss: 0.545221]\n",
      "epoch:5 step:5139 [D loss: 0.219501, acc.: 67.97%] [G loss: 0.503700]\n",
      "epoch:5 step:5140 [D loss: 0.219237, acc.: 63.28%] [G loss: 0.468628]\n",
      "epoch:5 step:5141 [D loss: 0.237217, acc.: 60.94%] [G loss: 0.480431]\n",
      "epoch:5 step:5142 [D loss: 0.215245, acc.: 66.41%] [G loss: 0.524140]\n",
      "epoch:5 step:5143 [D loss: 0.276379, acc.: 56.25%] [G loss: 0.466254]\n",
      "epoch:5 step:5144 [D loss: 0.241931, acc.: 58.59%] [G loss: 0.474296]\n",
      "epoch:5 step:5145 [D loss: 0.212930, acc.: 67.97%] [G loss: 0.527681]\n",
      "epoch:5 step:5146 [D loss: 0.231512, acc.: 60.16%] [G loss: 0.498083]\n",
      "epoch:5 step:5147 [D loss: 0.226327, acc.: 61.72%] [G loss: 0.505390]\n",
      "epoch:5 step:5148 [D loss: 0.247348, acc.: 62.50%] [G loss: 0.447714]\n",
      "epoch:5 step:5149 [D loss: 0.206380, acc.: 69.53%] [G loss: 0.463674]\n",
      "epoch:5 step:5150 [D loss: 0.234432, acc.: 57.81%] [G loss: 0.447260]\n",
      "epoch:5 step:5151 [D loss: 0.202652, acc.: 68.75%] [G loss: 0.507393]\n",
      "epoch:5 step:5152 [D loss: 0.224112, acc.: 65.62%] [G loss: 0.490732]\n",
      "epoch:5 step:5153 [D loss: 0.234874, acc.: 62.50%] [G loss: 0.499986]\n",
      "epoch:5 step:5154 [D loss: 0.212006, acc.: 68.75%] [G loss: 0.561347]\n",
      "epoch:5 step:5155 [D loss: 0.222030, acc.: 65.62%] [G loss: 0.536086]\n",
      "epoch:5 step:5156 [D loss: 0.186723, acc.: 72.66%] [G loss: 0.581923]\n",
      "epoch:5 step:5157 [D loss: 0.186955, acc.: 74.22%] [G loss: 0.607154]\n",
      "epoch:5 step:5158 [D loss: 0.261678, acc.: 60.94%] [G loss: 0.516763]\n",
      "epoch:5 step:5159 [D loss: 0.176230, acc.: 71.88%] [G loss: 0.528343]\n",
      "epoch:5 step:5160 [D loss: 0.159774, acc.: 78.12%] [G loss: 0.583206]\n",
      "epoch:5 step:5161 [D loss: 0.251656, acc.: 60.94%] [G loss: 0.525797]\n",
      "epoch:5 step:5162 [D loss: 0.248953, acc.: 55.47%] [G loss: 0.486941]\n",
      "epoch:5 step:5163 [D loss: 0.232895, acc.: 60.16%] [G loss: 0.500099]\n",
      "epoch:5 step:5164 [D loss: 0.223949, acc.: 64.06%] [G loss: 0.497292]\n",
      "epoch:5 step:5165 [D loss: 0.233749, acc.: 69.53%] [G loss: 0.504765]\n",
      "epoch:5 step:5166 [D loss: 0.210317, acc.: 67.19%] [G loss: 0.515194]\n",
      "epoch:5 step:5167 [D loss: 0.269312, acc.: 53.91%] [G loss: 0.476741]\n",
      "epoch:5 step:5168 [D loss: 0.246654, acc.: 58.59%] [G loss: 0.497155]\n",
      "epoch:5 step:5169 [D loss: 0.184683, acc.: 71.88%] [G loss: 0.508191]\n",
      "epoch:5 step:5170 [D loss: 0.219032, acc.: 68.75%] [G loss: 0.532072]\n",
      "epoch:5 step:5171 [D loss: 0.221685, acc.: 65.62%] [G loss: 0.490629]\n",
      "epoch:5 step:5172 [D loss: 0.239299, acc.: 62.50%] [G loss: 0.465603]\n",
      "epoch:5 step:5173 [D loss: 0.178499, acc.: 75.00%] [G loss: 0.545103]\n",
      "epoch:5 step:5174 [D loss: 0.211839, acc.: 67.97%] [G loss: 0.505480]\n",
      "epoch:5 step:5175 [D loss: 0.225579, acc.: 64.06%] [G loss: 0.493612]\n",
      "epoch:5 step:5176 [D loss: 0.194264, acc.: 76.56%] [G loss: 0.530875]\n",
      "epoch:5 step:5177 [D loss: 0.262159, acc.: 60.16%] [G loss: 0.535990]\n",
      "epoch:5 step:5178 [D loss: 0.200789, acc.: 69.53%] [G loss: 0.510836]\n",
      "epoch:5 step:5179 [D loss: 0.209616, acc.: 70.31%] [G loss: 0.493211]\n",
      "epoch:5 step:5180 [D loss: 0.172256, acc.: 78.91%] [G loss: 0.568650]\n",
      "epoch:5 step:5181 [D loss: 0.219423, acc.: 69.53%] [G loss: 0.573019]\n",
      "epoch:5 step:5182 [D loss: 0.204844, acc.: 68.75%] [G loss: 0.572278]\n",
      "epoch:5 step:5183 [D loss: 0.203899, acc.: 67.97%] [G loss: 0.594848]\n",
      "epoch:5 step:5184 [D loss: 0.161538, acc.: 75.78%] [G loss: 0.635857]\n",
      "epoch:5 step:5185 [D loss: 0.270241, acc.: 57.81%] [G loss: 0.444275]\n",
      "epoch:5 step:5186 [D loss: 0.281608, acc.: 50.78%] [G loss: 0.412346]\n",
      "epoch:5 step:5187 [D loss: 0.216292, acc.: 67.19%] [G loss: 0.498313]\n",
      "epoch:5 step:5188 [D loss: 0.195413, acc.: 71.09%] [G loss: 0.506465]\n",
      "epoch:5 step:5189 [D loss: 0.152255, acc.: 75.78%] [G loss: 0.568859]\n",
      "epoch:5 step:5190 [D loss: 0.191283, acc.: 71.88%] [G loss: 0.594909]\n",
      "epoch:5 step:5191 [D loss: 0.230403, acc.: 64.06%] [G loss: 0.543426]\n",
      "epoch:5 step:5192 [D loss: 0.219709, acc.: 62.50%] [G loss: 0.475332]\n",
      "epoch:5 step:5193 [D loss: 0.164338, acc.: 80.47%] [G loss: 0.560634]\n",
      "epoch:5 step:5194 [D loss: 0.231495, acc.: 61.72%] [G loss: 0.526893]\n",
      "epoch:5 step:5195 [D loss: 0.207835, acc.: 64.06%] [G loss: 0.511457]\n",
      "epoch:5 step:5196 [D loss: 0.216722, acc.: 64.84%] [G loss: 0.494475]\n",
      "epoch:5 step:5197 [D loss: 0.211294, acc.: 66.41%] [G loss: 0.480392]\n",
      "epoch:5 step:5198 [D loss: 0.224963, acc.: 63.28%] [G loss: 0.510668]\n",
      "epoch:5 step:5199 [D loss: 0.210238, acc.: 67.19%] [G loss: 0.544332]\n",
      "epoch:5 step:5200 [D loss: 0.157122, acc.: 81.25%] [G loss: 0.607252]\n",
      "epoch:5 step:5201 [D loss: 0.181343, acc.: 71.09%] [G loss: 0.534870]\n",
      "epoch:5 step:5202 [D loss: 0.212341, acc.: 65.62%] [G loss: 0.509360]\n",
      "epoch:5 step:5203 [D loss: 0.178277, acc.: 76.56%] [G loss: 0.528578]\n",
      "epoch:5 step:5204 [D loss: 0.202757, acc.: 67.19%] [G loss: 0.569488]\n",
      "epoch:5 step:5205 [D loss: 0.187309, acc.: 71.88%] [G loss: 0.566011]\n",
      "epoch:5 step:5206 [D loss: 0.210920, acc.: 68.75%] [G loss: 0.494109]\n",
      "epoch:5 step:5207 [D loss: 0.176765, acc.: 74.22%] [G loss: 0.564567]\n",
      "epoch:5 step:5208 [D loss: 0.184584, acc.: 72.66%] [G loss: 0.530988]\n",
      "epoch:5 step:5209 [D loss: 0.202013, acc.: 64.06%] [G loss: 0.506994]\n",
      "epoch:5 step:5210 [D loss: 0.234136, acc.: 57.03%] [G loss: 0.492809]\n",
      "epoch:5 step:5211 [D loss: 0.206332, acc.: 66.41%] [G loss: 0.528408]\n",
      "epoch:5 step:5212 [D loss: 0.208184, acc.: 71.09%] [G loss: 0.553722]\n",
      "epoch:5 step:5213 [D loss: 0.275074, acc.: 53.91%] [G loss: 0.491057]\n",
      "epoch:5 step:5214 [D loss: 0.231405, acc.: 62.50%] [G loss: 0.532962]\n",
      "epoch:5 step:5215 [D loss: 0.196418, acc.: 74.22%] [G loss: 0.501260]\n",
      "epoch:5 step:5216 [D loss: 0.216176, acc.: 66.41%] [G loss: 0.509393]\n",
      "epoch:5 step:5217 [D loss: 0.209628, acc.: 65.62%] [G loss: 0.489556]\n",
      "epoch:5 step:5218 [D loss: 0.201866, acc.: 65.62%] [G loss: 0.554211]\n",
      "epoch:5 step:5219 [D loss: 0.201000, acc.: 66.41%] [G loss: 0.570680]\n",
      "epoch:5 step:5220 [D loss: 0.229036, acc.: 60.94%] [G loss: 0.470314]\n",
      "epoch:5 step:5221 [D loss: 0.187800, acc.: 71.09%] [G loss: 0.521642]\n",
      "epoch:5 step:5222 [D loss: 0.213918, acc.: 70.31%] [G loss: 0.510408]\n",
      "epoch:5 step:5223 [D loss: 0.232335, acc.: 60.94%] [G loss: 0.476864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5224 [D loss: 0.220536, acc.: 64.84%] [G loss: 0.496376]\n",
      "epoch:5 step:5225 [D loss: 0.188290, acc.: 78.12%] [G loss: 0.567923]\n",
      "epoch:5 step:5226 [D loss: 0.189109, acc.: 70.31%] [G loss: 0.523576]\n",
      "epoch:5 step:5227 [D loss: 0.270425, acc.: 51.56%] [G loss: 0.455378]\n",
      "epoch:5 step:5228 [D loss: 0.232032, acc.: 60.94%] [G loss: 0.508239]\n",
      "epoch:5 step:5229 [D loss: 0.238255, acc.: 65.62%] [G loss: 0.481066]\n",
      "epoch:5 step:5230 [D loss: 0.197722, acc.: 67.97%] [G loss: 0.561796]\n",
      "epoch:5 step:5231 [D loss: 0.196309, acc.: 70.31%] [G loss: 0.525199]\n",
      "epoch:5 step:5232 [D loss: 0.184690, acc.: 72.66%] [G loss: 0.563770]\n",
      "epoch:5 step:5233 [D loss: 0.204701, acc.: 67.19%] [G loss: 0.503568]\n",
      "epoch:5 step:5234 [D loss: 0.182203, acc.: 71.88%] [G loss: 0.546515]\n",
      "epoch:5 step:5235 [D loss: 0.209130, acc.: 67.97%] [G loss: 0.546618]\n",
      "epoch:5 step:5236 [D loss: 0.203436, acc.: 65.62%] [G loss: 0.542376]\n",
      "epoch:5 step:5237 [D loss: 0.189690, acc.: 73.44%] [G loss: 0.511465]\n",
      "epoch:5 step:5238 [D loss: 0.228093, acc.: 60.94%] [G loss: 0.500881]\n",
      "epoch:5 step:5239 [D loss: 0.207970, acc.: 64.84%] [G loss: 0.492171]\n",
      "epoch:5 step:5240 [D loss: 0.191306, acc.: 75.00%] [G loss: 0.558098]\n",
      "epoch:5 step:5241 [D loss: 0.196251, acc.: 75.78%] [G loss: 0.553196]\n",
      "epoch:5 step:5242 [D loss: 0.219069, acc.: 65.62%] [G loss: 0.494899]\n",
      "epoch:5 step:5243 [D loss: 0.181771, acc.: 72.66%] [G loss: 0.525725]\n",
      "epoch:5 step:5244 [D loss: 0.245429, acc.: 63.28%] [G loss: 0.529168]\n",
      "epoch:5 step:5245 [D loss: 0.243188, acc.: 56.25%] [G loss: 0.478806]\n",
      "epoch:5 step:5246 [D loss: 0.199047, acc.: 66.41%] [G loss: 0.493410]\n",
      "epoch:5 step:5247 [D loss: 0.270747, acc.: 57.03%] [G loss: 0.542306]\n",
      "epoch:5 step:5248 [D loss: 0.205473, acc.: 71.09%] [G loss: 0.562900]\n",
      "epoch:5 step:5249 [D loss: 0.143891, acc.: 82.03%] [G loss: 0.611480]\n",
      "epoch:5 step:5250 [D loss: 0.234362, acc.: 61.72%] [G loss: 0.489786]\n",
      "epoch:5 step:5251 [D loss: 0.242268, acc.: 67.97%] [G loss: 0.498434]\n",
      "epoch:5 step:5252 [D loss: 0.196005, acc.: 67.97%] [G loss: 0.576431]\n",
      "epoch:5 step:5253 [D loss: 0.212405, acc.: 66.41%] [G loss: 0.563679]\n",
      "epoch:5 step:5254 [D loss: 0.232608, acc.: 60.16%] [G loss: 0.470209]\n",
      "epoch:5 step:5255 [D loss: 0.235567, acc.: 61.72%] [G loss: 0.459983]\n",
      "epoch:5 step:5256 [D loss: 0.210316, acc.: 64.84%] [G loss: 0.519493]\n",
      "epoch:5 step:5257 [D loss: 0.240079, acc.: 67.19%] [G loss: 0.508882]\n",
      "epoch:5 step:5258 [D loss: 0.208814, acc.: 67.97%] [G loss: 0.494099]\n",
      "epoch:5 step:5259 [D loss: 0.172510, acc.: 75.00%] [G loss: 0.510792]\n",
      "epoch:5 step:5260 [D loss: 0.174392, acc.: 73.44%] [G loss: 0.580587]\n",
      "epoch:5 step:5261 [D loss: 0.235604, acc.: 53.12%] [G loss: 0.491891]\n",
      "epoch:5 step:5262 [D loss: 0.206639, acc.: 68.75%] [G loss: 0.518426]\n",
      "epoch:5 step:5263 [D loss: 0.215659, acc.: 60.94%] [G loss: 0.496219]\n",
      "epoch:5 step:5264 [D loss: 0.228284, acc.: 60.94%] [G loss: 0.474934]\n",
      "epoch:5 step:5265 [D loss: 0.219784, acc.: 66.41%] [G loss: 0.493604]\n",
      "epoch:5 step:5266 [D loss: 0.197134, acc.: 65.62%] [G loss: 0.507508]\n",
      "epoch:5 step:5267 [D loss: 0.156499, acc.: 74.22%] [G loss: 0.544101]\n",
      "epoch:5 step:5268 [D loss: 0.226138, acc.: 65.62%] [G loss: 0.526836]\n",
      "epoch:5 step:5269 [D loss: 0.238015, acc.: 57.81%] [G loss: 0.531189]\n",
      "epoch:5 step:5270 [D loss: 0.204001, acc.: 67.97%] [G loss: 0.546857]\n",
      "epoch:5 step:5271 [D loss: 0.212927, acc.: 66.41%] [G loss: 0.501944]\n",
      "epoch:5 step:5272 [D loss: 0.217151, acc.: 63.28%] [G loss: 0.536412]\n",
      "epoch:5 step:5273 [D loss: 0.219404, acc.: 67.19%] [G loss: 0.481837]\n",
      "epoch:5 step:5274 [D loss: 0.180406, acc.: 71.88%] [G loss: 0.543194]\n",
      "epoch:5 step:5275 [D loss: 0.230304, acc.: 65.62%] [G loss: 0.511588]\n",
      "epoch:5 step:5276 [D loss: 0.197304, acc.: 68.75%] [G loss: 0.557483]\n",
      "epoch:5 step:5277 [D loss: 0.172340, acc.: 75.00%] [G loss: 0.550110]\n",
      "epoch:5 step:5278 [D loss: 0.257450, acc.: 60.16%] [G loss: 0.507028]\n",
      "epoch:5 step:5279 [D loss: 0.210553, acc.: 64.84%] [G loss: 0.511412]\n",
      "epoch:5 step:5280 [D loss: 0.197962, acc.: 70.31%] [G loss: 0.485341]\n",
      "epoch:5 step:5281 [D loss: 0.221905, acc.: 65.62%] [G loss: 0.496929]\n",
      "epoch:5 step:5282 [D loss: 0.223208, acc.: 60.16%] [G loss: 0.497146]\n",
      "epoch:5 step:5283 [D loss: 0.210935, acc.: 66.41%] [G loss: 0.520459]\n",
      "epoch:5 step:5284 [D loss: 0.205138, acc.: 69.53%] [G loss: 0.531896]\n",
      "epoch:5 step:5285 [D loss: 0.270826, acc.: 59.38%] [G loss: 0.469031]\n",
      "epoch:5 step:5286 [D loss: 0.224920, acc.: 58.59%] [G loss: 0.499110]\n",
      "epoch:5 step:5287 [D loss: 0.207495, acc.: 68.75%] [G loss: 0.532593]\n",
      "epoch:5 step:5288 [D loss: 0.217172, acc.: 67.97%] [G loss: 0.550150]\n",
      "epoch:5 step:5289 [D loss: 0.207091, acc.: 69.53%] [G loss: 0.522018]\n",
      "epoch:5 step:5290 [D loss: 0.183592, acc.: 74.22%] [G loss: 0.531762]\n",
      "epoch:5 step:5291 [D loss: 0.220537, acc.: 65.62%] [G loss: 0.483770]\n",
      "epoch:5 step:5292 [D loss: 0.203774, acc.: 68.75%] [G loss: 0.529621]\n",
      "epoch:5 step:5293 [D loss: 0.213234, acc.: 70.31%] [G loss: 0.490935]\n",
      "epoch:5 step:5294 [D loss: 0.204373, acc.: 69.53%] [G loss: 0.501918]\n",
      "epoch:5 step:5295 [D loss: 0.206247, acc.: 75.00%] [G loss: 0.480469]\n",
      "epoch:5 step:5296 [D loss: 0.184009, acc.: 73.44%] [G loss: 0.549577]\n",
      "epoch:5 step:5297 [D loss: 0.220480, acc.: 65.62%] [G loss: 0.521725]\n",
      "epoch:5 step:5298 [D loss: 0.158072, acc.: 78.91%] [G loss: 0.558837]\n",
      "epoch:5 step:5299 [D loss: 0.206483, acc.: 65.62%] [G loss: 0.502197]\n",
      "epoch:5 step:5300 [D loss: 0.254517, acc.: 60.16%] [G loss: 0.524619]\n",
      "epoch:5 step:5301 [D loss: 0.211614, acc.: 67.97%] [G loss: 0.517025]\n",
      "epoch:5 step:5302 [D loss: 0.218360, acc.: 66.41%] [G loss: 0.508247]\n",
      "epoch:5 step:5303 [D loss: 0.196573, acc.: 70.31%] [G loss: 0.586559]\n",
      "epoch:5 step:5304 [D loss: 0.183312, acc.: 72.66%] [G loss: 0.559733]\n",
      "epoch:5 step:5305 [D loss: 0.199360, acc.: 70.31%] [G loss: 0.492740]\n",
      "epoch:5 step:5306 [D loss: 0.205781, acc.: 64.84%] [G loss: 0.516648]\n",
      "epoch:5 step:5307 [D loss: 0.256258, acc.: 60.16%] [G loss: 0.476333]\n",
      "epoch:5 step:5308 [D loss: 0.178926, acc.: 71.88%] [G loss: 0.536044]\n",
      "epoch:5 step:5309 [D loss: 0.183291, acc.: 70.31%] [G loss: 0.562809]\n",
      "epoch:5 step:5310 [D loss: 0.233320, acc.: 60.16%] [G loss: 0.516029]\n",
      "epoch:5 step:5311 [D loss: 0.222190, acc.: 65.62%] [G loss: 0.506180]\n",
      "epoch:5 step:5312 [D loss: 0.199105, acc.: 64.84%] [G loss: 0.494283]\n",
      "epoch:5 step:5313 [D loss: 0.236798, acc.: 56.25%] [G loss: 0.467379]\n",
      "epoch:5 step:5314 [D loss: 0.197690, acc.: 71.09%] [G loss: 0.478115]\n",
      "epoch:5 step:5315 [D loss: 0.214524, acc.: 64.84%] [G loss: 0.502080]\n",
      "epoch:5 step:5316 [D loss: 0.211659, acc.: 69.53%] [G loss: 0.549142]\n",
      "epoch:5 step:5317 [D loss: 0.177689, acc.: 69.53%] [G loss: 0.562565]\n",
      "epoch:5 step:5318 [D loss: 0.214313, acc.: 67.97%] [G loss: 0.500152]\n",
      "epoch:5 step:5319 [D loss: 0.180565, acc.: 72.66%] [G loss: 0.506164]\n",
      "epoch:5 step:5320 [D loss: 0.186429, acc.: 69.53%] [G loss: 0.546854]\n",
      "epoch:5 step:5321 [D loss: 0.215102, acc.: 62.50%] [G loss: 0.555428]\n",
      "epoch:5 step:5322 [D loss: 0.200594, acc.: 75.00%] [G loss: 0.541498]\n",
      "epoch:5 step:5323 [D loss: 0.262197, acc.: 54.69%] [G loss: 0.494769]\n",
      "epoch:5 step:5324 [D loss: 0.183251, acc.: 71.88%] [G loss: 0.550744]\n",
      "epoch:5 step:5325 [D loss: 0.164360, acc.: 75.00%] [G loss: 0.573548]\n",
      "epoch:5 step:5326 [D loss: 0.191530, acc.: 72.66%] [G loss: 0.556723]\n",
      "epoch:5 step:5327 [D loss: 0.178724, acc.: 72.66%] [G loss: 0.581567]\n",
      "epoch:5 step:5328 [D loss: 0.229491, acc.: 64.84%] [G loss: 0.544138]\n",
      "epoch:5 step:5329 [D loss: 0.210700, acc.: 67.19%] [G loss: 0.559460]\n",
      "epoch:5 step:5330 [D loss: 0.229675, acc.: 62.50%] [G loss: 0.509133]\n",
      "epoch:5 step:5331 [D loss: 0.192670, acc.: 75.78%] [G loss: 0.552521]\n",
      "epoch:5 step:5332 [D loss: 0.151354, acc.: 81.25%] [G loss: 0.609962]\n",
      "epoch:5 step:5333 [D loss: 0.169959, acc.: 77.34%] [G loss: 0.612659]\n",
      "epoch:5 step:5334 [D loss: 0.216974, acc.: 67.97%] [G loss: 0.556067]\n",
      "epoch:5 step:5335 [D loss: 0.196171, acc.: 72.66%] [G loss: 0.553647]\n",
      "epoch:5 step:5336 [D loss: 0.206490, acc.: 66.41%] [G loss: 0.523378]\n",
      "epoch:5 step:5337 [D loss: 0.232709, acc.: 60.94%] [G loss: 0.503273]\n",
      "epoch:5 step:5338 [D loss: 0.207194, acc.: 66.41%] [G loss: 0.544416]\n",
      "epoch:5 step:5339 [D loss: 0.199178, acc.: 64.06%] [G loss: 0.565734]\n",
      "epoch:5 step:5340 [D loss: 0.210056, acc.: 70.31%] [G loss: 0.521329]\n",
      "epoch:5 step:5341 [D loss: 0.226463, acc.: 60.16%] [G loss: 0.499332]\n",
      "epoch:5 step:5342 [D loss: 0.203264, acc.: 64.84%] [G loss: 0.538006]\n",
      "epoch:5 step:5343 [D loss: 0.226804, acc.: 60.16%] [G loss: 0.466580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5344 [D loss: 0.208808, acc.: 67.97%] [G loss: 0.511880]\n",
      "epoch:5 step:5345 [D loss: 0.179970, acc.: 70.31%] [G loss: 0.507004]\n",
      "epoch:5 step:5346 [D loss: 0.183633, acc.: 71.88%] [G loss: 0.541989]\n",
      "epoch:5 step:5347 [D loss: 0.242179, acc.: 61.72%] [G loss: 0.477918]\n",
      "epoch:5 step:5348 [D loss: 0.201983, acc.: 68.75%] [G loss: 0.511450]\n",
      "epoch:5 step:5349 [D loss: 0.237572, acc.: 61.72%] [G loss: 0.525236]\n",
      "epoch:5 step:5350 [D loss: 0.215224, acc.: 64.84%] [G loss: 0.550085]\n",
      "epoch:5 step:5351 [D loss: 0.232013, acc.: 58.59%] [G loss: 0.552897]\n",
      "epoch:5 step:5352 [D loss: 0.251836, acc.: 55.47%] [G loss: 0.483173]\n",
      "epoch:5 step:5353 [D loss: 0.229876, acc.: 60.16%] [G loss: 0.511372]\n",
      "epoch:5 step:5354 [D loss: 0.210864, acc.: 64.84%] [G loss: 0.486570]\n",
      "epoch:5 step:5355 [D loss: 0.214682, acc.: 65.62%] [G loss: 0.512896]\n",
      "epoch:5 step:5356 [D loss: 0.207074, acc.: 66.41%] [G loss: 0.494474]\n",
      "epoch:5 step:5357 [D loss: 0.261483, acc.: 51.56%] [G loss: 0.494100]\n",
      "epoch:5 step:5358 [D loss: 0.203248, acc.: 68.75%] [G loss: 0.522093]\n",
      "epoch:5 step:5359 [D loss: 0.203237, acc.: 67.97%] [G loss: 0.553751]\n",
      "epoch:5 step:5360 [D loss: 0.179039, acc.: 74.22%] [G loss: 0.566689]\n",
      "epoch:5 step:5361 [D loss: 0.205058, acc.: 64.84%] [G loss: 0.519367]\n",
      "epoch:5 step:5362 [D loss: 0.178753, acc.: 74.22%] [G loss: 0.564042]\n",
      "epoch:5 step:5363 [D loss: 0.224117, acc.: 64.84%] [G loss: 0.499340]\n",
      "epoch:5 step:5364 [D loss: 0.200193, acc.: 65.62%] [G loss: 0.517544]\n",
      "epoch:5 step:5365 [D loss: 0.191792, acc.: 67.97%] [G loss: 0.539247]\n",
      "epoch:5 step:5366 [D loss: 0.202032, acc.: 71.09%] [G loss: 0.531320]\n",
      "epoch:5 step:5367 [D loss: 0.193525, acc.: 70.31%] [G loss: 0.528143]\n",
      "epoch:5 step:5368 [D loss: 0.228179, acc.: 66.41%] [G loss: 0.506284]\n",
      "epoch:5 step:5369 [D loss: 0.236588, acc.: 65.62%] [G loss: 0.491947]\n",
      "epoch:5 step:5370 [D loss: 0.194610, acc.: 68.75%] [G loss: 0.546160]\n",
      "epoch:5 step:5371 [D loss: 0.218330, acc.: 64.06%] [G loss: 0.522536]\n",
      "epoch:5 step:5372 [D loss: 0.245944, acc.: 58.59%] [G loss: 0.446848]\n",
      "epoch:5 step:5373 [D loss: 0.228536, acc.: 61.72%] [G loss: 0.503417]\n",
      "epoch:5 step:5374 [D loss: 0.206012, acc.: 67.97%] [G loss: 0.514023]\n",
      "epoch:5 step:5375 [D loss: 0.197061, acc.: 70.31%] [G loss: 0.540335]\n",
      "epoch:5 step:5376 [D loss: 0.191018, acc.: 68.75%] [G loss: 0.545176]\n",
      "epoch:5 step:5377 [D loss: 0.207175, acc.: 65.62%] [G loss: 0.533166]\n",
      "epoch:5 step:5378 [D loss: 0.188826, acc.: 74.22%] [G loss: 0.557928]\n",
      "epoch:5 step:5379 [D loss: 0.184999, acc.: 69.53%] [G loss: 0.584705]\n",
      "epoch:5 step:5380 [D loss: 0.189482, acc.: 71.88%] [G loss: 0.559337]\n",
      "epoch:5 step:5381 [D loss: 0.255373, acc.: 57.81%] [G loss: 0.487687]\n",
      "epoch:5 step:5382 [D loss: 0.186008, acc.: 71.88%] [G loss: 0.520509]\n",
      "epoch:5 step:5383 [D loss: 0.206050, acc.: 66.41%] [G loss: 0.539835]\n",
      "epoch:5 step:5384 [D loss: 0.209407, acc.: 65.62%] [G loss: 0.511158]\n",
      "epoch:5 step:5385 [D loss: 0.206103, acc.: 65.62%] [G loss: 0.581776]\n",
      "epoch:5 step:5386 [D loss: 0.193608, acc.: 73.44%] [G loss: 0.584124]\n",
      "epoch:5 step:5387 [D loss: 0.242850, acc.: 62.50%] [G loss: 0.509229]\n",
      "epoch:5 step:5388 [D loss: 0.220802, acc.: 67.97%] [G loss: 0.455594]\n",
      "epoch:5 step:5389 [D loss: 0.240076, acc.: 62.50%] [G loss: 0.471695]\n",
      "epoch:5 step:5390 [D loss: 0.199082, acc.: 70.31%] [G loss: 0.493570]\n",
      "epoch:5 step:5391 [D loss: 0.200041, acc.: 68.75%] [G loss: 0.517088]\n",
      "epoch:5 step:5392 [D loss: 0.172622, acc.: 80.47%] [G loss: 0.557464]\n",
      "epoch:5 step:5393 [D loss: 0.195962, acc.: 71.09%] [G loss: 0.545716]\n",
      "epoch:5 step:5394 [D loss: 0.185212, acc.: 71.88%] [G loss: 0.553455]\n",
      "epoch:5 step:5395 [D loss: 0.252943, acc.: 60.94%] [G loss: 0.544587]\n",
      "epoch:5 step:5396 [D loss: 0.239630, acc.: 58.59%] [G loss: 0.508160]\n",
      "epoch:5 step:5397 [D loss: 0.209961, acc.: 61.72%] [G loss: 0.507375]\n",
      "epoch:5 step:5398 [D loss: 0.266914, acc.: 50.78%] [G loss: 0.490764]\n",
      "epoch:5 step:5399 [D loss: 0.215559, acc.: 67.19%] [G loss: 0.533985]\n",
      "epoch:5 step:5400 [D loss: 0.223279, acc.: 64.84%] [G loss: 0.489238]\n",
      "epoch:5 step:5401 [D loss: 0.258989, acc.: 57.81%] [G loss: 0.506007]\n",
      "epoch:5 step:5402 [D loss: 0.196392, acc.: 71.88%] [G loss: 0.541784]\n",
      "epoch:5 step:5403 [D loss: 0.216146, acc.: 64.84%] [G loss: 0.517725]\n",
      "epoch:5 step:5404 [D loss: 0.229498, acc.: 62.50%] [G loss: 0.509238]\n",
      "epoch:5 step:5405 [D loss: 0.238759, acc.: 60.16%] [G loss: 0.524072]\n",
      "epoch:5 step:5406 [D loss: 0.268585, acc.: 53.91%] [G loss: 0.503200]\n",
      "epoch:5 step:5407 [D loss: 0.246640, acc.: 58.59%] [G loss: 0.470086]\n",
      "epoch:5 step:5408 [D loss: 0.209890, acc.: 66.41%] [G loss: 0.510719]\n",
      "epoch:5 step:5409 [D loss: 0.185466, acc.: 72.66%] [G loss: 0.542882]\n",
      "epoch:5 step:5410 [D loss: 0.187424, acc.: 70.31%] [G loss: 0.591693]\n",
      "epoch:5 step:5411 [D loss: 0.228402, acc.: 64.06%] [G loss: 0.531605]\n",
      "epoch:5 step:5412 [D loss: 0.289840, acc.: 48.44%] [G loss: 0.431682]\n",
      "epoch:5 step:5413 [D loss: 0.204195, acc.: 67.97%] [G loss: 0.490069]\n",
      "epoch:5 step:5414 [D loss: 0.243183, acc.: 60.94%] [G loss: 0.460499]\n",
      "epoch:5 step:5415 [D loss: 0.196366, acc.: 72.66%] [G loss: 0.526674]\n",
      "epoch:5 step:5416 [D loss: 0.192678, acc.: 67.97%] [G loss: 0.573410]\n",
      "epoch:5 step:5417 [D loss: 0.204931, acc.: 62.50%] [G loss: 0.534240]\n",
      "epoch:5 step:5418 [D loss: 0.213622, acc.: 67.97%] [G loss: 0.513442]\n",
      "epoch:5 step:5419 [D loss: 0.246234, acc.: 55.47%] [G loss: 0.457243]\n",
      "epoch:5 step:5420 [D loss: 0.194788, acc.: 65.62%] [G loss: 0.478004]\n",
      "epoch:5 step:5421 [D loss: 0.199902, acc.: 67.97%] [G loss: 0.478727]\n",
      "epoch:5 step:5422 [D loss: 0.176077, acc.: 75.78%] [G loss: 0.537359]\n",
      "epoch:5 step:5423 [D loss: 0.236426, acc.: 60.16%] [G loss: 0.493693]\n",
      "epoch:5 step:5424 [D loss: 0.265990, acc.: 50.78%] [G loss: 0.442273]\n",
      "epoch:5 step:5425 [D loss: 0.231965, acc.: 60.94%] [G loss: 0.468404]\n",
      "epoch:5 step:5426 [D loss: 0.213691, acc.: 65.62%] [G loss: 0.495245]\n",
      "epoch:5 step:5427 [D loss: 0.228723, acc.: 62.50%] [G loss: 0.489928]\n",
      "epoch:5 step:5428 [D loss: 0.191988, acc.: 68.75%] [G loss: 0.570456]\n",
      "epoch:5 step:5429 [D loss: 0.236329, acc.: 67.19%] [G loss: 0.484023]\n",
      "epoch:5 step:5430 [D loss: 0.241386, acc.: 60.16%] [G loss: 0.503225]\n",
      "epoch:5 step:5431 [D loss: 0.203736, acc.: 68.75%] [G loss: 0.520292]\n",
      "epoch:5 step:5432 [D loss: 0.184908, acc.: 70.31%] [G loss: 0.536878]\n",
      "epoch:5 step:5433 [D loss: 0.219552, acc.: 61.72%] [G loss: 0.488548]\n",
      "epoch:5 step:5434 [D loss: 0.226913, acc.: 67.97%] [G loss: 0.517408]\n",
      "epoch:5 step:5435 [D loss: 0.168088, acc.: 75.78%] [G loss: 0.558347]\n",
      "epoch:5 step:5436 [D loss: 0.235449, acc.: 57.81%] [G loss: 0.497835]\n",
      "epoch:5 step:5437 [D loss: 0.216568, acc.: 65.62%] [G loss: 0.500984]\n",
      "epoch:5 step:5438 [D loss: 0.208017, acc.: 67.19%] [G loss: 0.492858]\n",
      "epoch:5 step:5439 [D loss: 0.183662, acc.: 67.97%] [G loss: 0.516099]\n",
      "epoch:5 step:5440 [D loss: 0.208367, acc.: 65.62%] [G loss: 0.483276]\n",
      "epoch:5 step:5441 [D loss: 0.205780, acc.: 70.31%] [G loss: 0.525095]\n",
      "epoch:5 step:5442 [D loss: 0.193464, acc.: 75.00%] [G loss: 0.521302]\n",
      "epoch:5 step:5443 [D loss: 0.205271, acc.: 72.66%] [G loss: 0.466945]\n",
      "epoch:5 step:5444 [D loss: 0.220645, acc.: 63.28%] [G loss: 0.500858]\n",
      "epoch:5 step:5445 [D loss: 0.240933, acc.: 60.16%] [G loss: 0.495603]\n",
      "epoch:5 step:5446 [D loss: 0.209421, acc.: 65.62%] [G loss: 0.556177]\n",
      "epoch:5 step:5447 [D loss: 0.221661, acc.: 61.72%] [G loss: 0.473458]\n",
      "epoch:5 step:5448 [D loss: 0.227010, acc.: 69.53%] [G loss: 0.490038]\n",
      "epoch:5 step:5449 [D loss: 0.262834, acc.: 52.34%] [G loss: 0.522212]\n",
      "epoch:5 step:5450 [D loss: 0.272924, acc.: 53.91%] [G loss: 0.516403]\n",
      "epoch:5 step:5451 [D loss: 0.258532, acc.: 54.69%] [G loss: 0.537444]\n",
      "epoch:5 step:5452 [D loss: 0.225257, acc.: 64.06%] [G loss: 0.516066]\n",
      "epoch:5 step:5453 [D loss: 0.240480, acc.: 60.16%] [G loss: 0.553803]\n",
      "epoch:5 step:5454 [D loss: 0.201633, acc.: 71.09%] [G loss: 0.533774]\n",
      "epoch:5 step:5455 [D loss: 0.205739, acc.: 67.97%] [G loss: 0.495176]\n",
      "epoch:5 step:5456 [D loss: 0.220142, acc.: 64.06%] [G loss: 0.443258]\n",
      "epoch:5 step:5457 [D loss: 0.192051, acc.: 70.31%] [G loss: 0.517120]\n",
      "epoch:5 step:5458 [D loss: 0.186224, acc.: 67.97%] [G loss: 0.542846]\n",
      "epoch:5 step:5459 [D loss: 0.220285, acc.: 64.06%] [G loss: 0.483507]\n",
      "epoch:5 step:5460 [D loss: 0.192312, acc.: 68.75%] [G loss: 0.548421]\n",
      "epoch:5 step:5461 [D loss: 0.232415, acc.: 60.16%] [G loss: 0.486288]\n",
      "epoch:5 step:5462 [D loss: 0.194637, acc.: 71.09%] [G loss: 0.521298]\n",
      "epoch:5 step:5463 [D loss: 0.222360, acc.: 64.84%] [G loss: 0.492482]\n",
      "epoch:5 step:5464 [D loss: 0.207140, acc.: 69.53%] [G loss: 0.519883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5465 [D loss: 0.216431, acc.: 66.41%] [G loss: 0.483390]\n",
      "epoch:5 step:5466 [D loss: 0.198409, acc.: 67.97%] [G loss: 0.525677]\n",
      "epoch:5 step:5467 [D loss: 0.171247, acc.: 75.78%] [G loss: 0.630290]\n",
      "epoch:5 step:5468 [D loss: 0.252313, acc.: 57.81%] [G loss: 0.545787]\n",
      "epoch:5 step:5469 [D loss: 0.250233, acc.: 54.69%] [G loss: 0.477770]\n",
      "epoch:5 step:5470 [D loss: 0.225441, acc.: 64.84%] [G loss: 0.495309]\n",
      "epoch:5 step:5471 [D loss: 0.224031, acc.: 61.72%] [G loss: 0.487029]\n",
      "epoch:5 step:5472 [D loss: 0.226170, acc.: 64.84%] [G loss: 0.530767]\n",
      "epoch:5 step:5473 [D loss: 0.248732, acc.: 57.81%] [G loss: 0.503340]\n",
      "epoch:5 step:5474 [D loss: 0.190609, acc.: 71.09%] [G loss: 0.495021]\n",
      "epoch:5 step:5475 [D loss: 0.228257, acc.: 64.84%] [G loss: 0.525514]\n",
      "epoch:5 step:5476 [D loss: 0.259137, acc.: 57.03%] [G loss: 0.463130]\n",
      "epoch:5 step:5477 [D loss: 0.158958, acc.: 81.25%] [G loss: 0.562030]\n",
      "epoch:5 step:5478 [D loss: 0.234937, acc.: 60.16%] [G loss: 0.555956]\n",
      "epoch:5 step:5479 [D loss: 0.224791, acc.: 64.84%] [G loss: 0.532396]\n",
      "epoch:5 step:5480 [D loss: 0.236832, acc.: 60.16%] [G loss: 0.506929]\n",
      "epoch:5 step:5481 [D loss: 0.214071, acc.: 64.84%] [G loss: 0.588912]\n",
      "epoch:5 step:5482 [D loss: 0.224666, acc.: 64.06%] [G loss: 0.511881]\n",
      "epoch:5 step:5483 [D loss: 0.199275, acc.: 69.53%] [G loss: 0.516797]\n",
      "epoch:5 step:5484 [D loss: 0.235164, acc.: 62.50%] [G loss: 0.492597]\n",
      "epoch:5 step:5485 [D loss: 0.257698, acc.: 60.16%] [G loss: 0.488476]\n",
      "epoch:5 step:5486 [D loss: 0.195466, acc.: 68.75%] [G loss: 0.487764]\n",
      "epoch:5 step:5487 [D loss: 0.188704, acc.: 71.09%] [G loss: 0.575766]\n",
      "epoch:5 step:5488 [D loss: 0.229111, acc.: 63.28%] [G loss: 0.484898]\n",
      "epoch:5 step:5489 [D loss: 0.205355, acc.: 70.31%] [G loss: 0.494466]\n",
      "epoch:5 step:5490 [D loss: 0.192506, acc.: 70.31%] [G loss: 0.484801]\n",
      "epoch:5 step:5491 [D loss: 0.181689, acc.: 70.31%] [G loss: 0.530323]\n",
      "epoch:5 step:5492 [D loss: 0.209951, acc.: 68.75%] [G loss: 0.541675]\n",
      "epoch:5 step:5493 [D loss: 0.227442, acc.: 66.41%] [G loss: 0.470186]\n",
      "epoch:5 step:5494 [D loss: 0.238587, acc.: 61.72%] [G loss: 0.495552]\n",
      "epoch:5 step:5495 [D loss: 0.186037, acc.: 69.53%] [G loss: 0.572902]\n",
      "epoch:5 step:5496 [D loss: 0.234492, acc.: 62.50%] [G loss: 0.478274]\n",
      "epoch:5 step:5497 [D loss: 0.250366, acc.: 57.81%] [G loss: 0.451585]\n",
      "epoch:5 step:5498 [D loss: 0.196855, acc.: 71.09%] [G loss: 0.482508]\n",
      "epoch:5 step:5499 [D loss: 0.220999, acc.: 68.75%] [G loss: 0.511621]\n",
      "epoch:5 step:5500 [D loss: 0.173129, acc.: 73.44%] [G loss: 0.570540]\n",
      "epoch:5 step:5501 [D loss: 0.212109, acc.: 67.97%] [G loss: 0.512187]\n",
      "epoch:5 step:5502 [D loss: 0.244915, acc.: 59.38%] [G loss: 0.444852]\n",
      "epoch:5 step:5503 [D loss: 0.222275, acc.: 61.72%] [G loss: 0.501855]\n",
      "epoch:5 step:5504 [D loss: 0.212451, acc.: 68.75%] [G loss: 0.498340]\n",
      "epoch:5 step:5505 [D loss: 0.267637, acc.: 55.47%] [G loss: 0.481286]\n",
      "epoch:5 step:5506 [D loss: 0.204188, acc.: 68.75%] [G loss: 0.465545]\n",
      "epoch:5 step:5507 [D loss: 0.187609, acc.: 73.44%] [G loss: 0.508830]\n",
      "epoch:5 step:5508 [D loss: 0.189155, acc.: 69.53%] [G loss: 0.525842]\n",
      "epoch:5 step:5509 [D loss: 0.244796, acc.: 59.38%] [G loss: 0.475742]\n",
      "epoch:5 step:5510 [D loss: 0.205697, acc.: 68.75%] [G loss: 0.471318]\n",
      "epoch:5 step:5511 [D loss: 0.229266, acc.: 63.28%] [G loss: 0.485381]\n",
      "epoch:5 step:5512 [D loss: 0.261930, acc.: 55.47%] [G loss: 0.459453]\n",
      "epoch:5 step:5513 [D loss: 0.260788, acc.: 52.34%] [G loss: 0.449118]\n",
      "epoch:5 step:5514 [D loss: 0.226824, acc.: 63.28%] [G loss: 0.463474]\n",
      "epoch:5 step:5515 [D loss: 0.212583, acc.: 64.84%] [G loss: 0.499711]\n",
      "epoch:5 step:5516 [D loss: 0.224096, acc.: 59.38%] [G loss: 0.503514]\n",
      "epoch:5 step:5517 [D loss: 0.178077, acc.: 78.91%] [G loss: 0.576677]\n",
      "epoch:5 step:5518 [D loss: 0.206443, acc.: 66.41%] [G loss: 0.539362]\n",
      "epoch:5 step:5519 [D loss: 0.214768, acc.: 65.62%] [G loss: 0.516405]\n",
      "epoch:5 step:5520 [D loss: 0.192933, acc.: 69.53%] [G loss: 0.518584]\n",
      "epoch:5 step:5521 [D loss: 0.216376, acc.: 64.84%] [G loss: 0.467261]\n",
      "epoch:5 step:5522 [D loss: 0.192209, acc.: 71.09%] [G loss: 0.502743]\n",
      "epoch:5 step:5523 [D loss: 0.186688, acc.: 73.44%] [G loss: 0.507553]\n",
      "epoch:5 step:5524 [D loss: 0.198715, acc.: 67.97%] [G loss: 0.480745]\n",
      "epoch:5 step:5525 [D loss: 0.196634, acc.: 67.19%] [G loss: 0.524242]\n",
      "epoch:5 step:5526 [D loss: 0.201063, acc.: 61.72%] [G loss: 0.491807]\n",
      "epoch:5 step:5527 [D loss: 0.194407, acc.: 72.66%] [G loss: 0.555082]\n",
      "epoch:5 step:5528 [D loss: 0.227478, acc.: 59.38%] [G loss: 0.514188]\n",
      "epoch:5 step:5529 [D loss: 0.213795, acc.: 68.75%] [G loss: 0.558892]\n",
      "epoch:5 step:5530 [D loss: 0.209576, acc.: 70.31%] [G loss: 0.552416]\n",
      "epoch:5 step:5531 [D loss: 0.227738, acc.: 57.81%] [G loss: 0.470573]\n",
      "epoch:5 step:5532 [D loss: 0.202960, acc.: 69.53%] [G loss: 0.505756]\n",
      "epoch:5 step:5533 [D loss: 0.225030, acc.: 61.72%] [G loss: 0.469140]\n",
      "epoch:5 step:5534 [D loss: 0.206081, acc.: 67.97%] [G loss: 0.498712]\n",
      "epoch:5 step:5535 [D loss: 0.243923, acc.: 59.38%] [G loss: 0.493126]\n",
      "epoch:5 step:5536 [D loss: 0.228307, acc.: 62.50%] [G loss: 0.495582]\n",
      "epoch:5 step:5537 [D loss: 0.210615, acc.: 64.84%] [G loss: 0.514648]\n",
      "epoch:5 step:5538 [D loss: 0.194212, acc.: 70.31%] [G loss: 0.583028]\n",
      "epoch:5 step:5539 [D loss: 0.208261, acc.: 72.66%] [G loss: 0.529091]\n",
      "epoch:5 step:5540 [D loss: 0.234296, acc.: 61.72%] [G loss: 0.502178]\n",
      "epoch:5 step:5541 [D loss: 0.231890, acc.: 59.38%] [G loss: 0.512919]\n",
      "epoch:5 step:5542 [D loss: 0.205006, acc.: 71.09%] [G loss: 0.478051]\n",
      "epoch:5 step:5543 [D loss: 0.242508, acc.: 59.38%] [G loss: 0.476664]\n",
      "epoch:5 step:5544 [D loss: 0.201260, acc.: 68.75%] [G loss: 0.561507]\n",
      "epoch:5 step:5545 [D loss: 0.155451, acc.: 79.69%] [G loss: 0.568778]\n",
      "epoch:5 step:5546 [D loss: 0.232288, acc.: 60.94%] [G loss: 0.508169]\n",
      "epoch:5 step:5547 [D loss: 0.224858, acc.: 64.84%] [G loss: 0.462718]\n",
      "epoch:5 step:5548 [D loss: 0.209118, acc.: 63.28%] [G loss: 0.473393]\n",
      "epoch:5 step:5549 [D loss: 0.238914, acc.: 64.06%] [G loss: 0.463450]\n",
      "epoch:5 step:5550 [D loss: 0.199932, acc.: 71.88%] [G loss: 0.523287]\n",
      "epoch:5 step:5551 [D loss: 0.251846, acc.: 62.50%] [G loss: 0.496487]\n",
      "epoch:5 step:5552 [D loss: 0.234381, acc.: 64.06%] [G loss: 0.492228]\n",
      "epoch:5 step:5553 [D loss: 0.210820, acc.: 70.31%] [G loss: 0.498771]\n",
      "epoch:5 step:5554 [D loss: 0.219565, acc.: 60.94%] [G loss: 0.530373]\n",
      "epoch:5 step:5555 [D loss: 0.194472, acc.: 73.44%] [G loss: 0.514120]\n",
      "epoch:5 step:5556 [D loss: 0.188854, acc.: 67.19%] [G loss: 0.562169]\n",
      "epoch:5 step:5557 [D loss: 0.226526, acc.: 63.28%] [G loss: 0.535298]\n",
      "epoch:5 step:5558 [D loss: 0.233652, acc.: 64.84%] [G loss: 0.489332]\n",
      "epoch:5 step:5559 [D loss: 0.196076, acc.: 67.97%] [G loss: 0.495260]\n",
      "epoch:5 step:5560 [D loss: 0.175592, acc.: 71.09%] [G loss: 0.523028]\n",
      "epoch:5 step:5561 [D loss: 0.196270, acc.: 71.09%] [G loss: 0.519881]\n",
      "epoch:5 step:5562 [D loss: 0.218033, acc.: 68.75%] [G loss: 0.496633]\n",
      "epoch:5 step:5563 [D loss: 0.239576, acc.: 55.47%] [G loss: 0.479230]\n",
      "epoch:5 step:5564 [D loss: 0.237325, acc.: 60.16%] [G loss: 0.468264]\n",
      "epoch:5 step:5565 [D loss: 0.244181, acc.: 57.81%] [G loss: 0.475648]\n",
      "epoch:5 step:5566 [D loss: 0.205233, acc.: 71.88%] [G loss: 0.505057]\n",
      "epoch:5 step:5567 [D loss: 0.214079, acc.: 65.62%] [G loss: 0.493599]\n",
      "epoch:5 step:5568 [D loss: 0.221272, acc.: 67.97%] [G loss: 0.487069]\n",
      "epoch:5 step:5569 [D loss: 0.183264, acc.: 76.56%] [G loss: 0.516291]\n",
      "epoch:5 step:5570 [D loss: 0.186694, acc.: 69.53%] [G loss: 0.596889]\n",
      "epoch:5 step:5571 [D loss: 0.195019, acc.: 73.44%] [G loss: 0.537553]\n",
      "epoch:5 step:5572 [D loss: 0.221834, acc.: 64.84%] [G loss: 0.506049]\n",
      "epoch:5 step:5573 [D loss: 0.193322, acc.: 66.41%] [G loss: 0.499038]\n",
      "epoch:5 step:5574 [D loss: 0.221450, acc.: 65.62%] [G loss: 0.486588]\n",
      "epoch:5 step:5575 [D loss: 0.216479, acc.: 60.16%] [G loss: 0.466791]\n",
      "epoch:5 step:5576 [D loss: 0.246592, acc.: 60.16%] [G loss: 0.496726]\n",
      "epoch:5 step:5577 [D loss: 0.265696, acc.: 56.25%] [G loss: 0.513195]\n",
      "epoch:5 step:5578 [D loss: 0.174151, acc.: 76.56%] [G loss: 0.539344]\n",
      "epoch:5 step:5579 [D loss: 0.196261, acc.: 69.53%] [G loss: 0.559795]\n",
      "epoch:5 step:5580 [D loss: 0.206978, acc.: 74.22%] [G loss: 0.495381]\n",
      "epoch:5 step:5581 [D loss: 0.218013, acc.: 67.19%] [G loss: 0.537133]\n",
      "epoch:5 step:5582 [D loss: 0.184987, acc.: 73.44%] [G loss: 0.534886]\n",
      "epoch:5 step:5583 [D loss: 0.201707, acc.: 67.19%] [G loss: 0.531127]\n",
      "epoch:5 step:5584 [D loss: 0.178142, acc.: 67.97%] [G loss: 0.593240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5585 [D loss: 0.199292, acc.: 71.09%] [G loss: 0.533822]\n",
      "epoch:5 step:5586 [D loss: 0.235454, acc.: 60.94%] [G loss: 0.506556]\n",
      "epoch:5 step:5587 [D loss: 0.227007, acc.: 57.81%] [G loss: 0.513156]\n",
      "epoch:5 step:5588 [D loss: 0.208360, acc.: 68.75%] [G loss: 0.509737]\n",
      "epoch:5 step:5589 [D loss: 0.208953, acc.: 71.09%] [G loss: 0.469575]\n",
      "epoch:5 step:5590 [D loss: 0.199974, acc.: 67.97%] [G loss: 0.540244]\n",
      "epoch:5 step:5591 [D loss: 0.205452, acc.: 68.75%] [G loss: 0.554768]\n",
      "epoch:5 step:5592 [D loss: 0.271773, acc.: 55.47%] [G loss: 0.486609]\n",
      "epoch:5 step:5593 [D loss: 0.208746, acc.: 68.75%] [G loss: 0.504435]\n",
      "epoch:5 step:5594 [D loss: 0.174627, acc.: 78.91%] [G loss: 0.527914]\n",
      "epoch:5 step:5595 [D loss: 0.229811, acc.: 64.84%] [G loss: 0.553279]\n",
      "epoch:5 step:5596 [D loss: 0.177664, acc.: 73.44%] [G loss: 0.543460]\n",
      "epoch:5 step:5597 [D loss: 0.178977, acc.: 73.44%] [G loss: 0.502703]\n",
      "epoch:5 step:5598 [D loss: 0.216775, acc.: 62.50%] [G loss: 0.560300]\n",
      "epoch:5 step:5599 [D loss: 0.185879, acc.: 69.53%] [G loss: 0.537055]\n",
      "epoch:5 step:5600 [D loss: 0.247844, acc.: 62.50%] [G loss: 0.474498]\n",
      "epoch:5 step:5601 [D loss: 0.263205, acc.: 57.81%] [G loss: 0.512453]\n",
      "epoch:5 step:5602 [D loss: 0.205180, acc.: 69.53%] [G loss: 0.551340]\n",
      "epoch:5 step:5603 [D loss: 0.215129, acc.: 64.06%] [G loss: 0.569080]\n",
      "epoch:5 step:5604 [D loss: 0.205127, acc.: 70.31%] [G loss: 0.577185]\n",
      "epoch:5 step:5605 [D loss: 0.288059, acc.: 54.69%] [G loss: 0.522483]\n",
      "epoch:5 step:5606 [D loss: 0.179474, acc.: 71.88%] [G loss: 0.603176]\n",
      "epoch:5 step:5607 [D loss: 0.236394, acc.: 65.62%] [G loss: 0.537310]\n",
      "epoch:5 step:5608 [D loss: 0.178276, acc.: 73.44%] [G loss: 0.564090]\n",
      "epoch:5 step:5609 [D loss: 0.167137, acc.: 78.12%] [G loss: 0.642215]\n",
      "epoch:5 step:5610 [D loss: 0.156829, acc.: 80.47%] [G loss: 0.640527]\n",
      "epoch:5 step:5611 [D loss: 0.166199, acc.: 72.66%] [G loss: 0.627258]\n",
      "epoch:5 step:5612 [D loss: 0.178524, acc.: 72.66%] [G loss: 0.738589]\n",
      "epoch:5 step:5613 [D loss: 0.362682, acc.: 57.03%] [G loss: 0.589513]\n",
      "epoch:5 step:5614 [D loss: 0.143617, acc.: 82.03%] [G loss: 0.638160]\n",
      "epoch:5 step:5615 [D loss: 0.213227, acc.: 65.62%] [G loss: 0.552326]\n",
      "epoch:5 step:5616 [D loss: 0.221276, acc.: 62.50%] [G loss: 0.497755]\n",
      "epoch:5 step:5617 [D loss: 0.221143, acc.: 61.72%] [G loss: 0.521884]\n",
      "epoch:5 step:5618 [D loss: 0.204613, acc.: 68.75%] [G loss: 0.518026]\n",
      "epoch:5 step:5619 [D loss: 0.170740, acc.: 77.34%] [G loss: 0.594718]\n",
      "epoch:5 step:5620 [D loss: 0.213137, acc.: 65.62%] [G loss: 0.578828]\n",
      "epoch:5 step:5621 [D loss: 0.141858, acc.: 80.47%] [G loss: 0.581760]\n",
      "epoch:5 step:5622 [D loss: 0.148979, acc.: 80.47%] [G loss: 0.709448]\n",
      "epoch:6 step:5623 [D loss: 0.263907, acc.: 59.38%] [G loss: 0.561145]\n",
      "epoch:6 step:5624 [D loss: 0.222738, acc.: 63.28%] [G loss: 0.526229]\n",
      "epoch:6 step:5625 [D loss: 0.234685, acc.: 62.50%] [G loss: 0.540356]\n",
      "epoch:6 step:5626 [D loss: 0.200942, acc.: 71.09%] [G loss: 0.546250]\n",
      "epoch:6 step:5627 [D loss: 0.208734, acc.: 63.28%] [G loss: 0.523572]\n",
      "epoch:6 step:5628 [D loss: 0.215022, acc.: 67.97%] [G loss: 0.522138]\n",
      "epoch:6 step:5629 [D loss: 0.184484, acc.: 74.22%] [G loss: 0.513730]\n",
      "epoch:6 step:5630 [D loss: 0.231596, acc.: 62.50%] [G loss: 0.504802]\n",
      "epoch:6 step:5631 [D loss: 0.193770, acc.: 71.09%] [G loss: 0.549298]\n",
      "epoch:6 step:5632 [D loss: 0.214533, acc.: 65.62%] [G loss: 0.542681]\n",
      "epoch:6 step:5633 [D loss: 0.200131, acc.: 64.84%] [G loss: 0.546531]\n",
      "epoch:6 step:5634 [D loss: 0.230160, acc.: 66.41%] [G loss: 0.533993]\n",
      "epoch:6 step:5635 [D loss: 0.212916, acc.: 65.62%] [G loss: 0.493191]\n",
      "epoch:6 step:5636 [D loss: 0.181364, acc.: 74.22%] [G loss: 0.511307]\n",
      "epoch:6 step:5637 [D loss: 0.161951, acc.: 75.78%] [G loss: 0.582173]\n",
      "epoch:6 step:5638 [D loss: 0.201338, acc.: 68.75%] [G loss: 0.543812]\n",
      "epoch:6 step:5639 [D loss: 0.227448, acc.: 60.16%] [G loss: 0.491603]\n",
      "epoch:6 step:5640 [D loss: 0.256577, acc.: 57.81%] [G loss: 0.489258]\n",
      "epoch:6 step:5641 [D loss: 0.229048, acc.: 63.28%] [G loss: 0.557571]\n",
      "epoch:6 step:5642 [D loss: 0.247315, acc.: 56.25%] [G loss: 0.466546]\n",
      "epoch:6 step:5643 [D loss: 0.220706, acc.: 62.50%] [G loss: 0.535575]\n",
      "epoch:6 step:5644 [D loss: 0.197365, acc.: 66.41%] [G loss: 0.531326]\n",
      "epoch:6 step:5645 [D loss: 0.216168, acc.: 66.41%] [G loss: 0.454194]\n",
      "epoch:6 step:5646 [D loss: 0.203516, acc.: 67.19%] [G loss: 0.518088]\n",
      "epoch:6 step:5647 [D loss: 0.205848, acc.: 67.97%] [G loss: 0.485712]\n",
      "epoch:6 step:5648 [D loss: 0.227976, acc.: 57.81%] [G loss: 0.517109]\n",
      "epoch:6 step:5649 [D loss: 0.203099, acc.: 67.19%] [G loss: 0.470941]\n",
      "epoch:6 step:5650 [D loss: 0.214048, acc.: 59.38%] [G loss: 0.440640]\n",
      "epoch:6 step:5651 [D loss: 0.213123, acc.: 65.62%] [G loss: 0.469451]\n",
      "epoch:6 step:5652 [D loss: 0.200179, acc.: 67.19%] [G loss: 0.489142]\n",
      "epoch:6 step:5653 [D loss: 0.222960, acc.: 62.50%] [G loss: 0.511510]\n",
      "epoch:6 step:5654 [D loss: 0.209942, acc.: 65.62%] [G loss: 0.503950]\n",
      "epoch:6 step:5655 [D loss: 0.191985, acc.: 71.09%] [G loss: 0.497076]\n",
      "epoch:6 step:5656 [D loss: 0.230758, acc.: 61.72%] [G loss: 0.489538]\n",
      "epoch:6 step:5657 [D loss: 0.186991, acc.: 71.88%] [G loss: 0.487109]\n",
      "epoch:6 step:5658 [D loss: 0.183934, acc.: 73.44%] [G loss: 0.545020]\n",
      "epoch:6 step:5659 [D loss: 0.224085, acc.: 58.59%] [G loss: 0.506768]\n",
      "epoch:6 step:5660 [D loss: 0.239321, acc.: 61.72%] [G loss: 0.486162]\n",
      "epoch:6 step:5661 [D loss: 0.174430, acc.: 75.78%] [G loss: 0.537875]\n",
      "epoch:6 step:5662 [D loss: 0.172272, acc.: 74.22%] [G loss: 0.590172]\n",
      "epoch:6 step:5663 [D loss: 0.203102, acc.: 69.53%] [G loss: 0.552803]\n",
      "epoch:6 step:5664 [D loss: 0.187785, acc.: 74.22%] [G loss: 0.550106]\n",
      "epoch:6 step:5665 [D loss: 0.205923, acc.: 66.41%] [G loss: 0.496504]\n",
      "epoch:6 step:5666 [D loss: 0.223901, acc.: 62.50%] [G loss: 0.501202]\n",
      "epoch:6 step:5667 [D loss: 0.228174, acc.: 61.72%] [G loss: 0.463112]\n",
      "epoch:6 step:5668 [D loss: 0.209623, acc.: 67.19%] [G loss: 0.496331]\n",
      "epoch:6 step:5669 [D loss: 0.194471, acc.: 70.31%] [G loss: 0.515828]\n",
      "epoch:6 step:5670 [D loss: 0.201020, acc.: 70.31%] [G loss: 0.510542]\n",
      "epoch:6 step:5671 [D loss: 0.221669, acc.: 65.62%] [G loss: 0.524330]\n",
      "epoch:6 step:5672 [D loss: 0.200885, acc.: 69.53%] [G loss: 0.532355]\n",
      "epoch:6 step:5673 [D loss: 0.240307, acc.: 61.72%] [G loss: 0.498053]\n",
      "epoch:6 step:5674 [D loss: 0.213885, acc.: 65.62%] [G loss: 0.542661]\n",
      "epoch:6 step:5675 [D loss: 0.197646, acc.: 74.22%] [G loss: 0.527111]\n",
      "epoch:6 step:5676 [D loss: 0.200473, acc.: 71.09%] [G loss: 0.544540]\n",
      "epoch:6 step:5677 [D loss: 0.209800, acc.: 67.19%] [G loss: 0.538781]\n",
      "epoch:6 step:5678 [D loss: 0.221328, acc.: 64.06%] [G loss: 0.509189]\n",
      "epoch:6 step:5679 [D loss: 0.179157, acc.: 72.66%] [G loss: 0.581087]\n",
      "epoch:6 step:5680 [D loss: 0.192249, acc.: 71.88%] [G loss: 0.543705]\n",
      "epoch:6 step:5681 [D loss: 0.199317, acc.: 67.97%] [G loss: 0.518370]\n",
      "epoch:6 step:5682 [D loss: 0.242617, acc.: 50.00%] [G loss: 0.503732]\n",
      "epoch:6 step:5683 [D loss: 0.226805, acc.: 63.28%] [G loss: 0.519306]\n",
      "epoch:6 step:5684 [D loss: 0.212763, acc.: 66.41%] [G loss: 0.479393]\n",
      "epoch:6 step:5685 [D loss: 0.207693, acc.: 67.19%] [G loss: 0.527416]\n",
      "epoch:6 step:5686 [D loss: 0.245326, acc.: 60.94%] [G loss: 0.497408]\n",
      "epoch:6 step:5687 [D loss: 0.196692, acc.: 72.66%] [G loss: 0.557268]\n",
      "epoch:6 step:5688 [D loss: 0.224929, acc.: 64.06%] [G loss: 0.514725]\n",
      "epoch:6 step:5689 [D loss: 0.210253, acc.: 71.09%] [G loss: 0.506165]\n",
      "epoch:6 step:5690 [D loss: 0.202520, acc.: 67.97%] [G loss: 0.520290]\n",
      "epoch:6 step:5691 [D loss: 0.184802, acc.: 72.66%] [G loss: 0.552552]\n",
      "epoch:6 step:5692 [D loss: 0.203080, acc.: 67.97%] [G loss: 0.547146]\n",
      "epoch:6 step:5693 [D loss: 0.224429, acc.: 59.38%] [G loss: 0.555990]\n",
      "epoch:6 step:5694 [D loss: 0.210749, acc.: 67.97%] [G loss: 0.499940]\n",
      "epoch:6 step:5695 [D loss: 0.225556, acc.: 57.81%] [G loss: 0.451404]\n",
      "epoch:6 step:5696 [D loss: 0.190751, acc.: 76.56%] [G loss: 0.538316]\n",
      "epoch:6 step:5697 [D loss: 0.193472, acc.: 71.88%] [G loss: 0.513043]\n",
      "epoch:6 step:5698 [D loss: 0.199752, acc.: 67.19%] [G loss: 0.546353]\n",
      "epoch:6 step:5699 [D loss: 0.188695, acc.: 72.66%] [G loss: 0.607912]\n",
      "epoch:6 step:5700 [D loss: 0.260228, acc.: 57.81%] [G loss: 0.493056]\n",
      "epoch:6 step:5701 [D loss: 0.217707, acc.: 63.28%] [G loss: 0.447315]\n",
      "epoch:6 step:5702 [D loss: 0.214682, acc.: 64.84%] [G loss: 0.475917]\n",
      "epoch:6 step:5703 [D loss: 0.206476, acc.: 69.53%] [G loss: 0.538542]\n",
      "epoch:6 step:5704 [D loss: 0.167046, acc.: 78.12%] [G loss: 0.525772]\n",
      "epoch:6 step:5705 [D loss: 0.202583, acc.: 67.19%] [G loss: 0.552861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5706 [D loss: 0.200523, acc.: 70.31%] [G loss: 0.539405]\n",
      "epoch:6 step:5707 [D loss: 0.227618, acc.: 64.84%] [G loss: 0.503703]\n",
      "epoch:6 step:5708 [D loss: 0.197018, acc.: 67.19%] [G loss: 0.537061]\n",
      "epoch:6 step:5709 [D loss: 0.201040, acc.: 71.88%] [G loss: 0.497544]\n",
      "epoch:6 step:5710 [D loss: 0.198926, acc.: 67.97%] [G loss: 0.511629]\n",
      "epoch:6 step:5711 [D loss: 0.224574, acc.: 64.06%] [G loss: 0.480410]\n",
      "epoch:6 step:5712 [D loss: 0.212051, acc.: 71.09%] [G loss: 0.490493]\n",
      "epoch:6 step:5713 [D loss: 0.206605, acc.: 71.09%] [G loss: 0.495528]\n",
      "epoch:6 step:5714 [D loss: 0.178795, acc.: 71.88%] [G loss: 0.547846]\n",
      "epoch:6 step:5715 [D loss: 0.219516, acc.: 61.72%] [G loss: 0.570223]\n",
      "epoch:6 step:5716 [D loss: 0.230468, acc.: 63.28%] [G loss: 0.525239]\n",
      "epoch:6 step:5717 [D loss: 0.206158, acc.: 67.97%] [G loss: 0.605067]\n",
      "epoch:6 step:5718 [D loss: 0.170601, acc.: 72.66%] [G loss: 0.547195]\n",
      "epoch:6 step:5719 [D loss: 0.186807, acc.: 72.66%] [G loss: 0.571052]\n",
      "epoch:6 step:5720 [D loss: 0.206458, acc.: 68.75%] [G loss: 0.546923]\n",
      "epoch:6 step:5721 [D loss: 0.247285, acc.: 59.38%] [G loss: 0.486329]\n",
      "epoch:6 step:5722 [D loss: 0.192579, acc.: 71.88%] [G loss: 0.530674]\n",
      "epoch:6 step:5723 [D loss: 0.217358, acc.: 63.28%] [G loss: 0.548733]\n",
      "epoch:6 step:5724 [D loss: 0.195125, acc.: 71.09%] [G loss: 0.536169]\n",
      "epoch:6 step:5725 [D loss: 0.195593, acc.: 67.97%] [G loss: 0.465433]\n",
      "epoch:6 step:5726 [D loss: 0.206573, acc.: 67.97%] [G loss: 0.522542]\n",
      "epoch:6 step:5727 [D loss: 0.240141, acc.: 62.50%] [G loss: 0.493908]\n",
      "epoch:6 step:5728 [D loss: 0.178380, acc.: 77.34%] [G loss: 0.503439]\n",
      "epoch:6 step:5729 [D loss: 0.210884, acc.: 66.41%] [G loss: 0.541730]\n",
      "epoch:6 step:5730 [D loss: 0.245343, acc.: 58.59%] [G loss: 0.518498]\n",
      "epoch:6 step:5731 [D loss: 0.233774, acc.: 59.38%] [G loss: 0.470335]\n",
      "epoch:6 step:5732 [D loss: 0.230725, acc.: 60.94%] [G loss: 0.489888]\n",
      "epoch:6 step:5733 [D loss: 0.202210, acc.: 67.19%] [G loss: 0.491720]\n",
      "epoch:6 step:5734 [D loss: 0.175588, acc.: 74.22%] [G loss: 0.552186]\n",
      "epoch:6 step:5735 [D loss: 0.246833, acc.: 56.25%] [G loss: 0.499114]\n",
      "epoch:6 step:5736 [D loss: 0.212870, acc.: 69.53%] [G loss: 0.520520]\n",
      "epoch:6 step:5737 [D loss: 0.194365, acc.: 66.41%] [G loss: 0.572443]\n",
      "epoch:6 step:5738 [D loss: 0.194411, acc.: 69.53%] [G loss: 0.589696]\n",
      "epoch:6 step:5739 [D loss: 0.198723, acc.: 67.97%] [G loss: 0.559252]\n",
      "epoch:6 step:5740 [D loss: 0.218368, acc.: 60.94%] [G loss: 0.562527]\n",
      "epoch:6 step:5741 [D loss: 0.175715, acc.: 73.44%] [G loss: 0.598113]\n",
      "epoch:6 step:5742 [D loss: 0.298548, acc.: 58.59%] [G loss: 0.512127]\n",
      "epoch:6 step:5743 [D loss: 0.223038, acc.: 64.06%] [G loss: 0.514813]\n",
      "epoch:6 step:5744 [D loss: 0.188091, acc.: 75.78%] [G loss: 0.547600]\n",
      "epoch:6 step:5745 [D loss: 0.184968, acc.: 78.12%] [G loss: 0.544766]\n",
      "epoch:6 step:5746 [D loss: 0.233725, acc.: 59.38%] [G loss: 0.494791]\n",
      "epoch:6 step:5747 [D loss: 0.228921, acc.: 63.28%] [G loss: 0.503038]\n",
      "epoch:6 step:5748 [D loss: 0.207282, acc.: 66.41%] [G loss: 0.515262]\n",
      "epoch:6 step:5749 [D loss: 0.188543, acc.: 73.44%] [G loss: 0.515176]\n",
      "epoch:6 step:5750 [D loss: 0.242537, acc.: 60.16%] [G loss: 0.485034]\n",
      "epoch:6 step:5751 [D loss: 0.233954, acc.: 64.06%] [G loss: 0.465691]\n",
      "epoch:6 step:5752 [D loss: 0.196643, acc.: 71.88%] [G loss: 0.514494]\n",
      "epoch:6 step:5753 [D loss: 0.218145, acc.: 64.84%] [G loss: 0.481508]\n",
      "epoch:6 step:5754 [D loss: 0.213002, acc.: 69.53%] [G loss: 0.497967]\n",
      "epoch:6 step:5755 [D loss: 0.245698, acc.: 57.81%] [G loss: 0.535141]\n",
      "epoch:6 step:5756 [D loss: 0.205244, acc.: 69.53%] [G loss: 0.512109]\n",
      "epoch:6 step:5757 [D loss: 0.220664, acc.: 63.28%] [G loss: 0.540771]\n",
      "epoch:6 step:5758 [D loss: 0.223698, acc.: 67.19%] [G loss: 0.553020]\n",
      "epoch:6 step:5759 [D loss: 0.263703, acc.: 56.25%] [G loss: 0.478422]\n",
      "epoch:6 step:5760 [D loss: 0.224377, acc.: 67.97%] [G loss: 0.483995]\n",
      "epoch:6 step:5761 [D loss: 0.201081, acc.: 69.53%] [G loss: 0.515258]\n",
      "epoch:6 step:5762 [D loss: 0.222812, acc.: 61.72%] [G loss: 0.488712]\n",
      "epoch:6 step:5763 [D loss: 0.223974, acc.: 60.94%] [G loss: 0.475979]\n",
      "epoch:6 step:5764 [D loss: 0.227994, acc.: 66.41%] [G loss: 0.478717]\n",
      "epoch:6 step:5765 [D loss: 0.230125, acc.: 58.59%] [G loss: 0.479443]\n",
      "epoch:6 step:5766 [D loss: 0.189107, acc.: 73.44%] [G loss: 0.548916]\n",
      "epoch:6 step:5767 [D loss: 0.199346, acc.: 67.19%] [G loss: 0.584490]\n",
      "epoch:6 step:5768 [D loss: 0.214216, acc.: 67.19%] [G loss: 0.492448]\n",
      "epoch:6 step:5769 [D loss: 0.238696, acc.: 60.16%] [G loss: 0.479309]\n",
      "epoch:6 step:5770 [D loss: 0.228650, acc.: 64.84%] [G loss: 0.486386]\n",
      "epoch:6 step:5771 [D loss: 0.189868, acc.: 71.88%] [G loss: 0.540891]\n",
      "epoch:6 step:5772 [D loss: 0.267577, acc.: 60.94%] [G loss: 0.440236]\n",
      "epoch:6 step:5773 [D loss: 0.190936, acc.: 71.09%] [G loss: 0.528443]\n",
      "epoch:6 step:5774 [D loss: 0.212207, acc.: 66.41%] [G loss: 0.486024]\n",
      "epoch:6 step:5775 [D loss: 0.227322, acc.: 61.72%] [G loss: 0.482654]\n",
      "epoch:6 step:5776 [D loss: 0.239977, acc.: 60.94%] [G loss: 0.464532]\n",
      "epoch:6 step:5777 [D loss: 0.189656, acc.: 70.31%] [G loss: 0.534228]\n",
      "epoch:6 step:5778 [D loss: 0.195052, acc.: 70.31%] [G loss: 0.573869]\n",
      "epoch:6 step:5779 [D loss: 0.218328, acc.: 59.38%] [G loss: 0.512720]\n",
      "epoch:6 step:5780 [D loss: 0.222631, acc.: 63.28%] [G loss: 0.496626]\n",
      "epoch:6 step:5781 [D loss: 0.189888, acc.: 72.66%] [G loss: 0.522829]\n",
      "epoch:6 step:5782 [D loss: 0.261394, acc.: 57.81%] [G loss: 0.463112]\n",
      "epoch:6 step:5783 [D loss: 0.205051, acc.: 67.97%] [G loss: 0.541158]\n",
      "epoch:6 step:5784 [D loss: 0.188529, acc.: 69.53%] [G loss: 0.519164]\n",
      "epoch:6 step:5785 [D loss: 0.181326, acc.: 70.31%] [G loss: 0.587858]\n",
      "epoch:6 step:5786 [D loss: 0.213611, acc.: 59.38%] [G loss: 0.501085]\n",
      "epoch:6 step:5787 [D loss: 0.217592, acc.: 67.19%] [G loss: 0.511056]\n",
      "epoch:6 step:5788 [D loss: 0.195108, acc.: 71.88%] [G loss: 0.477001]\n",
      "epoch:6 step:5789 [D loss: 0.219556, acc.: 62.50%] [G loss: 0.465403]\n",
      "epoch:6 step:5790 [D loss: 0.197379, acc.: 71.09%] [G loss: 0.488972]\n",
      "epoch:6 step:5791 [D loss: 0.215240, acc.: 66.41%] [G loss: 0.463282]\n",
      "epoch:6 step:5792 [D loss: 0.240066, acc.: 57.81%] [G loss: 0.470848]\n",
      "epoch:6 step:5793 [D loss: 0.193750, acc.: 71.88%] [G loss: 0.494906]\n",
      "epoch:6 step:5794 [D loss: 0.199798, acc.: 71.09%] [G loss: 0.541784]\n",
      "epoch:6 step:5795 [D loss: 0.184366, acc.: 78.12%] [G loss: 0.554387]\n",
      "epoch:6 step:5796 [D loss: 0.222996, acc.: 64.06%] [G loss: 0.476326]\n",
      "epoch:6 step:5797 [D loss: 0.211114, acc.: 67.19%] [G loss: 0.455271]\n",
      "epoch:6 step:5798 [D loss: 0.208348, acc.: 66.41%] [G loss: 0.478428]\n",
      "epoch:6 step:5799 [D loss: 0.209598, acc.: 65.62%] [G loss: 0.492936]\n",
      "epoch:6 step:5800 [D loss: 0.206431, acc.: 68.75%] [G loss: 0.520923]\n",
      "epoch:6 step:5801 [D loss: 0.205258, acc.: 72.66%] [G loss: 0.495434]\n",
      "epoch:6 step:5802 [D loss: 0.213860, acc.: 67.97%] [G loss: 0.513908]\n",
      "epoch:6 step:5803 [D loss: 0.220153, acc.: 64.06%] [G loss: 0.520771]\n",
      "epoch:6 step:5804 [D loss: 0.234161, acc.: 61.72%] [G loss: 0.517523]\n",
      "epoch:6 step:5805 [D loss: 0.229270, acc.: 61.72%] [G loss: 0.490971]\n",
      "epoch:6 step:5806 [D loss: 0.216414, acc.: 67.19%] [G loss: 0.480569]\n",
      "epoch:6 step:5807 [D loss: 0.204865, acc.: 68.75%] [G loss: 0.494763]\n",
      "epoch:6 step:5808 [D loss: 0.239658, acc.: 62.50%] [G loss: 0.446170]\n",
      "epoch:6 step:5809 [D loss: 0.202355, acc.: 70.31%] [G loss: 0.533649]\n",
      "epoch:6 step:5810 [D loss: 0.227421, acc.: 59.38%] [G loss: 0.537924]\n",
      "epoch:6 step:5811 [D loss: 0.228103, acc.: 62.50%] [G loss: 0.478514]\n",
      "epoch:6 step:5812 [D loss: 0.196806, acc.: 70.31%] [G loss: 0.463143]\n",
      "epoch:6 step:5813 [D loss: 0.195658, acc.: 70.31%] [G loss: 0.501134]\n",
      "epoch:6 step:5814 [D loss: 0.205534, acc.: 68.75%] [G loss: 0.523155]\n",
      "epoch:6 step:5815 [D loss: 0.235326, acc.: 63.28%] [G loss: 0.468546]\n",
      "epoch:6 step:5816 [D loss: 0.181541, acc.: 73.44%] [G loss: 0.504207]\n",
      "epoch:6 step:5817 [D loss: 0.218422, acc.: 67.19%] [G loss: 0.514611]\n",
      "epoch:6 step:5818 [D loss: 0.254119, acc.: 53.91%] [G loss: 0.488298]\n",
      "epoch:6 step:5819 [D loss: 0.199265, acc.: 67.97%] [G loss: 0.505119]\n",
      "epoch:6 step:5820 [D loss: 0.203141, acc.: 73.44%] [G loss: 0.512670]\n",
      "epoch:6 step:5821 [D loss: 0.203378, acc.: 67.19%] [G loss: 0.548637]\n",
      "epoch:6 step:5822 [D loss: 0.246765, acc.: 60.16%] [G loss: 0.518102]\n",
      "epoch:6 step:5823 [D loss: 0.233718, acc.: 62.50%] [G loss: 0.510512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5824 [D loss: 0.212548, acc.: 68.75%] [G loss: 0.544876]\n",
      "epoch:6 step:5825 [D loss: 0.254010, acc.: 59.38%] [G loss: 0.525428]\n",
      "epoch:6 step:5826 [D loss: 0.229468, acc.: 66.41%] [G loss: 0.518587]\n",
      "epoch:6 step:5827 [D loss: 0.222206, acc.: 64.06%] [G loss: 0.529165]\n",
      "epoch:6 step:5828 [D loss: 0.195682, acc.: 69.53%] [G loss: 0.512254]\n",
      "epoch:6 step:5829 [D loss: 0.166048, acc.: 75.78%] [G loss: 0.525097]\n",
      "epoch:6 step:5830 [D loss: 0.162687, acc.: 73.44%] [G loss: 0.554437]\n",
      "epoch:6 step:5831 [D loss: 0.200834, acc.: 70.31%] [G loss: 0.546866]\n",
      "epoch:6 step:5832 [D loss: 0.205376, acc.: 66.41%] [G loss: 0.486448]\n",
      "epoch:6 step:5833 [D loss: 0.255029, acc.: 53.12%] [G loss: 0.483212]\n",
      "epoch:6 step:5834 [D loss: 0.200360, acc.: 71.09%] [G loss: 0.479793]\n",
      "epoch:6 step:5835 [D loss: 0.219312, acc.: 65.62%] [G loss: 0.457945]\n",
      "epoch:6 step:5836 [D loss: 0.276996, acc.: 51.56%] [G loss: 0.460830]\n",
      "epoch:6 step:5837 [D loss: 0.240229, acc.: 60.16%] [G loss: 0.452875]\n",
      "epoch:6 step:5838 [D loss: 0.211705, acc.: 66.41%] [G loss: 0.525758]\n",
      "epoch:6 step:5839 [D loss: 0.193623, acc.: 66.41%] [G loss: 0.531452]\n",
      "epoch:6 step:5840 [D loss: 0.198394, acc.: 68.75%] [G loss: 0.556611]\n",
      "epoch:6 step:5841 [D loss: 0.187239, acc.: 74.22%] [G loss: 0.487984]\n",
      "epoch:6 step:5842 [D loss: 0.266622, acc.: 58.59%] [G loss: 0.457017]\n",
      "epoch:6 step:5843 [D loss: 0.166788, acc.: 71.88%] [G loss: 0.586032]\n",
      "epoch:6 step:5844 [D loss: 0.204233, acc.: 64.84%] [G loss: 0.507400]\n",
      "epoch:6 step:5845 [D loss: 0.197930, acc.: 68.75%] [G loss: 0.484535]\n",
      "epoch:6 step:5846 [D loss: 0.238969, acc.: 63.28%] [G loss: 0.486718]\n",
      "epoch:6 step:5847 [D loss: 0.221874, acc.: 60.94%] [G loss: 0.492308]\n",
      "epoch:6 step:5848 [D loss: 0.243775, acc.: 57.03%] [G loss: 0.434618]\n",
      "epoch:6 step:5849 [D loss: 0.219400, acc.: 67.19%] [G loss: 0.490788]\n",
      "epoch:6 step:5850 [D loss: 0.256202, acc.: 54.69%] [G loss: 0.488456]\n",
      "epoch:6 step:5851 [D loss: 0.222803, acc.: 62.50%] [G loss: 0.495330]\n",
      "epoch:6 step:5852 [D loss: 0.186316, acc.: 71.09%] [G loss: 0.540058]\n",
      "epoch:6 step:5853 [D loss: 0.221504, acc.: 63.28%] [G loss: 0.541592]\n",
      "epoch:6 step:5854 [D loss: 0.157275, acc.: 78.12%] [G loss: 0.628756]\n",
      "epoch:6 step:5855 [D loss: 0.271086, acc.: 56.25%] [G loss: 0.501361]\n",
      "epoch:6 step:5856 [D loss: 0.245748, acc.: 53.12%] [G loss: 0.455461]\n",
      "epoch:6 step:5857 [D loss: 0.226985, acc.: 62.50%] [G loss: 0.479840]\n",
      "epoch:6 step:5858 [D loss: 0.232062, acc.: 60.16%] [G loss: 0.496063]\n",
      "epoch:6 step:5859 [D loss: 0.205428, acc.: 62.50%] [G loss: 0.531604]\n",
      "epoch:6 step:5860 [D loss: 0.209706, acc.: 68.75%] [G loss: 0.494599]\n",
      "epoch:6 step:5861 [D loss: 0.217594, acc.: 62.50%] [G loss: 0.475357]\n",
      "epoch:6 step:5862 [D loss: 0.217508, acc.: 65.62%] [G loss: 0.502540]\n",
      "epoch:6 step:5863 [D loss: 0.222652, acc.: 65.62%] [G loss: 0.463894]\n",
      "epoch:6 step:5864 [D loss: 0.200372, acc.: 67.19%] [G loss: 0.561570]\n",
      "epoch:6 step:5865 [D loss: 0.203110, acc.: 66.41%] [G loss: 0.542847]\n",
      "epoch:6 step:5866 [D loss: 0.250555, acc.: 62.50%] [G loss: 0.459904]\n",
      "epoch:6 step:5867 [D loss: 0.200436, acc.: 69.53%] [G loss: 0.515374]\n",
      "epoch:6 step:5868 [D loss: 0.243670, acc.: 60.16%] [G loss: 0.503663]\n",
      "epoch:6 step:5869 [D loss: 0.237663, acc.: 58.59%] [G loss: 0.510162]\n",
      "epoch:6 step:5870 [D loss: 0.196195, acc.: 71.88%] [G loss: 0.590751]\n",
      "epoch:6 step:5871 [D loss: 0.247039, acc.: 60.16%] [G loss: 0.480334]\n",
      "epoch:6 step:5872 [D loss: 0.265116, acc.: 55.47%] [G loss: 0.434830]\n",
      "epoch:6 step:5873 [D loss: 0.250773, acc.: 53.12%] [G loss: 0.512675]\n",
      "epoch:6 step:5874 [D loss: 0.215263, acc.: 66.41%] [G loss: 0.510522]\n",
      "epoch:6 step:5875 [D loss: 0.222490, acc.: 60.16%] [G loss: 0.528488]\n",
      "epoch:6 step:5876 [D loss: 0.181807, acc.: 74.22%] [G loss: 0.541026]\n",
      "epoch:6 step:5877 [D loss: 0.213792, acc.: 64.06%] [G loss: 0.495288]\n",
      "epoch:6 step:5878 [D loss: 0.216933, acc.: 69.53%] [G loss: 0.471155]\n",
      "epoch:6 step:5879 [D loss: 0.195975, acc.: 70.31%] [G loss: 0.493743]\n",
      "epoch:6 step:5880 [D loss: 0.204899, acc.: 68.75%] [G loss: 0.510665]\n",
      "epoch:6 step:5881 [D loss: 0.178358, acc.: 77.34%] [G loss: 0.541448]\n",
      "epoch:6 step:5882 [D loss: 0.249366, acc.: 50.00%] [G loss: 0.488397]\n",
      "epoch:6 step:5883 [D loss: 0.228959, acc.: 66.41%] [G loss: 0.517831]\n",
      "epoch:6 step:5884 [D loss: 0.202056, acc.: 69.53%] [G loss: 0.532845]\n",
      "epoch:6 step:5885 [D loss: 0.215738, acc.: 65.62%] [G loss: 0.528209]\n",
      "epoch:6 step:5886 [D loss: 0.187968, acc.: 70.31%] [G loss: 0.547631]\n",
      "epoch:6 step:5887 [D loss: 0.312689, acc.: 46.88%] [G loss: 0.444398]\n",
      "epoch:6 step:5888 [D loss: 0.222012, acc.: 64.84%] [G loss: 0.482136]\n",
      "epoch:6 step:5889 [D loss: 0.219386, acc.: 70.31%] [G loss: 0.472983]\n",
      "epoch:6 step:5890 [D loss: 0.198372, acc.: 67.19%] [G loss: 0.511598]\n",
      "epoch:6 step:5891 [D loss: 0.241501, acc.: 60.16%] [G loss: 0.465536]\n",
      "epoch:6 step:5892 [D loss: 0.193647, acc.: 68.75%] [G loss: 0.530224]\n",
      "epoch:6 step:5893 [D loss: 0.186588, acc.: 73.44%] [G loss: 0.545724]\n",
      "epoch:6 step:5894 [D loss: 0.212503, acc.: 64.84%] [G loss: 0.503058]\n",
      "epoch:6 step:5895 [D loss: 0.223043, acc.: 67.97%] [G loss: 0.480890]\n",
      "epoch:6 step:5896 [D loss: 0.197173, acc.: 72.66%] [G loss: 0.494651]\n",
      "epoch:6 step:5897 [D loss: 0.241040, acc.: 59.38%] [G loss: 0.496426]\n",
      "epoch:6 step:5898 [D loss: 0.227645, acc.: 64.06%] [G loss: 0.517515]\n",
      "epoch:6 step:5899 [D loss: 0.231396, acc.: 66.41%] [G loss: 0.477775]\n",
      "epoch:6 step:5900 [D loss: 0.240051, acc.: 57.81%] [G loss: 0.498292]\n",
      "epoch:6 step:5901 [D loss: 0.208259, acc.: 71.88%] [G loss: 0.505567]\n",
      "epoch:6 step:5902 [D loss: 0.206895, acc.: 63.28%] [G loss: 0.529376]\n",
      "epoch:6 step:5903 [D loss: 0.254575, acc.: 59.38%] [G loss: 0.529064]\n",
      "epoch:6 step:5904 [D loss: 0.207668, acc.: 67.97%] [G loss: 0.469728]\n",
      "epoch:6 step:5905 [D loss: 0.175325, acc.: 74.22%] [G loss: 0.545196]\n",
      "epoch:6 step:5906 [D loss: 0.223207, acc.: 60.16%] [G loss: 0.511956]\n",
      "epoch:6 step:5907 [D loss: 0.195418, acc.: 65.62%] [G loss: 0.514774]\n",
      "epoch:6 step:5908 [D loss: 0.182552, acc.: 73.44%] [G loss: 0.539117]\n",
      "epoch:6 step:5909 [D loss: 0.234302, acc.: 64.06%] [G loss: 0.525683]\n",
      "epoch:6 step:5910 [D loss: 0.240125, acc.: 57.81%] [G loss: 0.456934]\n",
      "epoch:6 step:5911 [D loss: 0.234174, acc.: 59.38%] [G loss: 0.472331]\n",
      "epoch:6 step:5912 [D loss: 0.212475, acc.: 66.41%] [G loss: 0.554132]\n",
      "epoch:6 step:5913 [D loss: 0.236628, acc.: 58.59%] [G loss: 0.470023]\n",
      "epoch:6 step:5914 [D loss: 0.198821, acc.: 65.62%] [G loss: 0.513268]\n",
      "epoch:6 step:5915 [D loss: 0.216515, acc.: 69.53%] [G loss: 0.526016]\n",
      "epoch:6 step:5916 [D loss: 0.266000, acc.: 57.03%] [G loss: 0.473950]\n",
      "epoch:6 step:5917 [D loss: 0.228606, acc.: 60.94%] [G loss: 0.520329]\n",
      "epoch:6 step:5918 [D loss: 0.186575, acc.: 73.44%] [G loss: 0.542685]\n",
      "epoch:6 step:5919 [D loss: 0.209839, acc.: 70.31%] [G loss: 0.543604]\n",
      "epoch:6 step:5920 [D loss: 0.174441, acc.: 70.31%] [G loss: 0.576856]\n",
      "epoch:6 step:5921 [D loss: 0.197361, acc.: 71.09%] [G loss: 0.496435]\n",
      "epoch:6 step:5922 [D loss: 0.216101, acc.: 66.41%] [G loss: 0.541996]\n",
      "epoch:6 step:5923 [D loss: 0.246207, acc.: 64.84%] [G loss: 0.483868]\n",
      "epoch:6 step:5924 [D loss: 0.218256, acc.: 63.28%] [G loss: 0.508389]\n",
      "epoch:6 step:5925 [D loss: 0.203764, acc.: 64.06%] [G loss: 0.519333]\n",
      "epoch:6 step:5926 [D loss: 0.204501, acc.: 71.88%] [G loss: 0.511631]\n",
      "epoch:6 step:5927 [D loss: 0.201111, acc.: 69.53%] [G loss: 0.560668]\n",
      "epoch:6 step:5928 [D loss: 0.209252, acc.: 69.53%] [G loss: 0.507904]\n",
      "epoch:6 step:5929 [D loss: 0.189861, acc.: 72.66%] [G loss: 0.506056]\n",
      "epoch:6 step:5930 [D loss: 0.195407, acc.: 69.53%] [G loss: 0.530665]\n",
      "epoch:6 step:5931 [D loss: 0.220090, acc.: 65.62%] [G loss: 0.512997]\n",
      "epoch:6 step:5932 [D loss: 0.170386, acc.: 73.44%] [G loss: 0.556349]\n",
      "epoch:6 step:5933 [D loss: 0.179325, acc.: 76.56%] [G loss: 0.557090]\n",
      "epoch:6 step:5934 [D loss: 0.177522, acc.: 75.00%] [G loss: 0.528532]\n",
      "epoch:6 step:5935 [D loss: 0.172017, acc.: 74.22%] [G loss: 0.589779]\n",
      "epoch:6 step:5936 [D loss: 0.182182, acc.: 75.00%] [G loss: 0.638316]\n",
      "epoch:6 step:5937 [D loss: 0.196721, acc.: 71.88%] [G loss: 0.569076]\n",
      "epoch:6 step:5938 [D loss: 0.259359, acc.: 56.25%] [G loss: 0.546897]\n",
      "epoch:6 step:5939 [D loss: 0.203140, acc.: 70.31%] [G loss: 0.482628]\n",
      "epoch:6 step:5940 [D loss: 0.199719, acc.: 64.84%] [G loss: 0.485005]\n",
      "epoch:6 step:5941 [D loss: 0.202647, acc.: 66.41%] [G loss: 0.516019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5942 [D loss: 0.201966, acc.: 71.88%] [G loss: 0.532785]\n",
      "epoch:6 step:5943 [D loss: 0.161556, acc.: 77.34%] [G loss: 0.534485]\n",
      "epoch:6 step:5944 [D loss: 0.230900, acc.: 63.28%] [G loss: 0.496849]\n",
      "epoch:6 step:5945 [D loss: 0.236000, acc.: 59.38%] [G loss: 0.496236]\n",
      "epoch:6 step:5946 [D loss: 0.219445, acc.: 64.06%] [G loss: 0.473424]\n",
      "epoch:6 step:5947 [D loss: 0.237280, acc.: 59.38%] [G loss: 0.509091]\n",
      "epoch:6 step:5948 [D loss: 0.233975, acc.: 60.16%] [G loss: 0.500222]\n",
      "epoch:6 step:5949 [D loss: 0.205996, acc.: 67.19%] [G loss: 0.470017]\n",
      "epoch:6 step:5950 [D loss: 0.205805, acc.: 66.41%] [G loss: 0.518800]\n",
      "epoch:6 step:5951 [D loss: 0.216996, acc.: 67.97%] [G loss: 0.526303]\n",
      "epoch:6 step:5952 [D loss: 0.218005, acc.: 66.41%] [G loss: 0.488917]\n",
      "epoch:6 step:5953 [D loss: 0.207523, acc.: 67.97%] [G loss: 0.479851]\n",
      "epoch:6 step:5954 [D loss: 0.195043, acc.: 73.44%] [G loss: 0.466735]\n",
      "epoch:6 step:5955 [D loss: 0.195288, acc.: 68.75%] [G loss: 0.519865]\n",
      "epoch:6 step:5956 [D loss: 0.240932, acc.: 58.59%] [G loss: 0.495063]\n",
      "epoch:6 step:5957 [D loss: 0.208591, acc.: 68.75%] [G loss: 0.516944]\n",
      "epoch:6 step:5958 [D loss: 0.192724, acc.: 72.66%] [G loss: 0.535547]\n",
      "epoch:6 step:5959 [D loss: 0.168707, acc.: 75.78%] [G loss: 0.554806]\n",
      "epoch:6 step:5960 [D loss: 0.223866, acc.: 64.06%] [G loss: 0.502807]\n",
      "epoch:6 step:5961 [D loss: 0.181200, acc.: 71.09%] [G loss: 0.556537]\n",
      "epoch:6 step:5962 [D loss: 0.220044, acc.: 64.84%] [G loss: 0.545296]\n",
      "epoch:6 step:5963 [D loss: 0.253205, acc.: 60.94%] [G loss: 0.499494]\n",
      "epoch:6 step:5964 [D loss: 0.217688, acc.: 63.28%] [G loss: 0.525759]\n",
      "epoch:6 step:5965 [D loss: 0.194640, acc.: 68.75%] [G loss: 0.561077]\n",
      "epoch:6 step:5966 [D loss: 0.179312, acc.: 75.00%] [G loss: 0.585836]\n",
      "epoch:6 step:5967 [D loss: 0.196474, acc.: 67.97%] [G loss: 0.502687]\n",
      "epoch:6 step:5968 [D loss: 0.269234, acc.: 57.03%] [G loss: 0.583555]\n",
      "epoch:6 step:5969 [D loss: 0.209185, acc.: 65.62%] [G loss: 0.669233]\n",
      "epoch:6 step:5970 [D loss: 0.285634, acc.: 52.34%] [G loss: 0.515672]\n",
      "epoch:6 step:5971 [D loss: 0.257218, acc.: 52.34%] [G loss: 0.444817]\n",
      "epoch:6 step:5972 [D loss: 0.214672, acc.: 65.62%] [G loss: 0.479560]\n",
      "epoch:6 step:5973 [D loss: 0.203976, acc.: 67.97%] [G loss: 0.537165]\n",
      "epoch:6 step:5974 [D loss: 0.212715, acc.: 70.31%] [G loss: 0.563464]\n",
      "epoch:6 step:5975 [D loss: 0.223320, acc.: 60.16%] [G loss: 0.525381]\n",
      "epoch:6 step:5976 [D loss: 0.183430, acc.: 75.78%] [G loss: 0.584635]\n",
      "epoch:6 step:5977 [D loss: 0.232039, acc.: 63.28%] [G loss: 0.499577]\n",
      "epoch:6 step:5978 [D loss: 0.242529, acc.: 60.94%] [G loss: 0.483588]\n",
      "epoch:6 step:5979 [D loss: 0.198705, acc.: 67.19%] [G loss: 0.493642]\n",
      "epoch:6 step:5980 [D loss: 0.189418, acc.: 74.22%] [G loss: 0.549732]\n",
      "epoch:6 step:5981 [D loss: 0.176992, acc.: 75.78%] [G loss: 0.562997]\n",
      "epoch:6 step:5982 [D loss: 0.189286, acc.: 68.75%] [G loss: 0.490952]\n",
      "epoch:6 step:5983 [D loss: 0.185421, acc.: 74.22%] [G loss: 0.507502]\n",
      "epoch:6 step:5984 [D loss: 0.230648, acc.: 60.94%] [G loss: 0.492116]\n",
      "epoch:6 step:5985 [D loss: 0.203411, acc.: 67.97%] [G loss: 0.504725]\n",
      "epoch:6 step:5986 [D loss: 0.194163, acc.: 68.75%] [G loss: 0.491542]\n",
      "epoch:6 step:5987 [D loss: 0.218739, acc.: 59.38%] [G loss: 0.507572]\n",
      "epoch:6 step:5988 [D loss: 0.177031, acc.: 78.12%] [G loss: 0.514755]\n",
      "epoch:6 step:5989 [D loss: 0.174500, acc.: 75.00%] [G loss: 0.525303]\n",
      "epoch:6 step:5990 [D loss: 0.228663, acc.: 65.62%] [G loss: 0.481226]\n",
      "epoch:6 step:5991 [D loss: 0.223068, acc.: 65.62%] [G loss: 0.448119]\n",
      "epoch:6 step:5992 [D loss: 0.202055, acc.: 69.53%] [G loss: 0.506029]\n",
      "epoch:6 step:5993 [D loss: 0.176648, acc.: 76.56%] [G loss: 0.560703]\n",
      "epoch:6 step:5994 [D loss: 0.201686, acc.: 67.19%] [G loss: 0.523198]\n",
      "epoch:6 step:5995 [D loss: 0.213345, acc.: 67.19%] [G loss: 0.536783]\n",
      "epoch:6 step:5996 [D loss: 0.179201, acc.: 75.00%] [G loss: 0.551405]\n",
      "epoch:6 step:5997 [D loss: 0.273679, acc.: 57.03%] [G loss: 0.466419]\n",
      "epoch:6 step:5998 [D loss: 0.279148, acc.: 51.56%] [G loss: 0.444777]\n",
      "epoch:6 step:5999 [D loss: 0.290109, acc.: 46.88%] [G loss: 0.463126]\n",
      "epoch:6 step:6000 [D loss: 0.211680, acc.: 65.62%] [G loss: 0.503927]\n",
      "epoch:6 step:6001 [D loss: 0.230001, acc.: 59.38%] [G loss: 0.499014]\n",
      "epoch:6 step:6002 [D loss: 0.199675, acc.: 72.66%] [G loss: 0.498366]\n",
      "epoch:6 step:6003 [D loss: 0.154581, acc.: 85.16%] [G loss: 0.516921]\n",
      "epoch:6 step:6004 [D loss: 0.223441, acc.: 64.06%] [G loss: 0.501076]\n",
      "epoch:6 step:6005 [D loss: 0.225385, acc.: 60.94%] [G loss: 0.523118]\n",
      "epoch:6 step:6006 [D loss: 0.211678, acc.: 60.94%] [G loss: 0.533162]\n",
      "epoch:6 step:6007 [D loss: 0.212641, acc.: 67.97%] [G loss: 0.463613]\n",
      "epoch:6 step:6008 [D loss: 0.232395, acc.: 62.50%] [G loss: 0.506321]\n",
      "epoch:6 step:6009 [D loss: 0.230956, acc.: 64.06%] [G loss: 0.511891]\n",
      "epoch:6 step:6010 [D loss: 0.211176, acc.: 64.06%] [G loss: 0.530813]\n",
      "epoch:6 step:6011 [D loss: 0.210423, acc.: 73.44%] [G loss: 0.539283]\n",
      "epoch:6 step:6012 [D loss: 0.246905, acc.: 57.03%] [G loss: 0.466131]\n",
      "epoch:6 step:6013 [D loss: 0.217729, acc.: 64.06%] [G loss: 0.474626]\n",
      "epoch:6 step:6014 [D loss: 0.230748, acc.: 60.16%] [G loss: 0.516370]\n",
      "epoch:6 step:6015 [D loss: 0.225756, acc.: 66.41%] [G loss: 0.512389]\n",
      "epoch:6 step:6016 [D loss: 0.203702, acc.: 71.09%] [G loss: 0.498113]\n",
      "epoch:6 step:6017 [D loss: 0.214672, acc.: 65.62%] [G loss: 0.465240]\n",
      "epoch:6 step:6018 [D loss: 0.261218, acc.: 57.81%] [G loss: 0.513930]\n",
      "epoch:6 step:6019 [D loss: 0.202305, acc.: 69.53%] [G loss: 0.507519]\n",
      "epoch:6 step:6020 [D loss: 0.186806, acc.: 72.66%] [G loss: 0.594921]\n",
      "epoch:6 step:6021 [D loss: 0.191071, acc.: 68.75%] [G loss: 0.525239]\n",
      "epoch:6 step:6022 [D loss: 0.262540, acc.: 53.91%] [G loss: 0.491529]\n",
      "epoch:6 step:6023 [D loss: 0.211286, acc.: 66.41%] [G loss: 0.507465]\n",
      "epoch:6 step:6024 [D loss: 0.187169, acc.: 74.22%] [G loss: 0.496718]\n",
      "epoch:6 step:6025 [D loss: 0.229909, acc.: 60.16%] [G loss: 0.496038]\n",
      "epoch:6 step:6026 [D loss: 0.247144, acc.: 57.81%] [G loss: 0.525294]\n",
      "epoch:6 step:6027 [D loss: 0.215963, acc.: 65.62%] [G loss: 0.495311]\n",
      "epoch:6 step:6028 [D loss: 0.202825, acc.: 67.97%] [G loss: 0.513004]\n",
      "epoch:6 step:6029 [D loss: 0.262690, acc.: 48.44%] [G loss: 0.443575]\n",
      "epoch:6 step:6030 [D loss: 0.281967, acc.: 54.69%] [G loss: 0.481842]\n",
      "epoch:6 step:6031 [D loss: 0.217023, acc.: 67.97%] [G loss: 0.530192]\n",
      "epoch:6 step:6032 [D loss: 0.240357, acc.: 54.69%] [G loss: 0.484063]\n",
      "epoch:6 step:6033 [D loss: 0.225311, acc.: 60.94%] [G loss: 0.547001]\n",
      "epoch:6 step:6034 [D loss: 0.213596, acc.: 65.62%] [G loss: 0.499795]\n",
      "epoch:6 step:6035 [D loss: 0.219809, acc.: 64.06%] [G loss: 0.475464]\n",
      "epoch:6 step:6036 [D loss: 0.236521, acc.: 57.81%] [G loss: 0.475670]\n",
      "epoch:6 step:6037 [D loss: 0.216599, acc.: 71.09%] [G loss: 0.492169]\n",
      "epoch:6 step:6038 [D loss: 0.168563, acc.: 77.34%] [G loss: 0.573926]\n",
      "epoch:6 step:6039 [D loss: 0.233652, acc.: 64.84%] [G loss: 0.557234]\n",
      "epoch:6 step:6040 [D loss: 0.253213, acc.: 60.94%] [G loss: 0.519745]\n",
      "epoch:6 step:6041 [D loss: 0.219566, acc.: 71.09%] [G loss: 0.531018]\n",
      "epoch:6 step:6042 [D loss: 0.244862, acc.: 54.69%] [G loss: 0.478275]\n",
      "epoch:6 step:6043 [D loss: 0.242562, acc.: 59.38%] [G loss: 0.532128]\n",
      "epoch:6 step:6044 [D loss: 0.241776, acc.: 59.38%] [G loss: 0.495004]\n",
      "epoch:6 step:6045 [D loss: 0.232921, acc.: 57.81%] [G loss: 0.475594]\n",
      "epoch:6 step:6046 [D loss: 0.204630, acc.: 67.97%] [G loss: 0.494182]\n",
      "epoch:6 step:6047 [D loss: 0.215189, acc.: 64.84%] [G loss: 0.482390]\n",
      "epoch:6 step:6048 [D loss: 0.179746, acc.: 75.00%] [G loss: 0.540467]\n",
      "epoch:6 step:6049 [D loss: 0.204174, acc.: 69.53%] [G loss: 0.522390]\n",
      "epoch:6 step:6050 [D loss: 0.208562, acc.: 68.75%] [G loss: 0.509599]\n",
      "epoch:6 step:6051 [D loss: 0.177239, acc.: 76.56%] [G loss: 0.574851]\n",
      "epoch:6 step:6052 [D loss: 0.200239, acc.: 69.53%] [G loss: 0.557841]\n",
      "epoch:6 step:6053 [D loss: 0.209959, acc.: 66.41%] [G loss: 0.567829]\n",
      "epoch:6 step:6054 [D loss: 0.235616, acc.: 58.59%] [G loss: 0.493258]\n",
      "epoch:6 step:6055 [D loss: 0.218858, acc.: 67.97%] [G loss: 0.470156]\n",
      "epoch:6 step:6056 [D loss: 0.195846, acc.: 70.31%] [G loss: 0.558651]\n",
      "epoch:6 step:6057 [D loss: 0.234184, acc.: 66.41%] [G loss: 0.470781]\n",
      "epoch:6 step:6058 [D loss: 0.195875, acc.: 69.53%] [G loss: 0.517224]\n",
      "epoch:6 step:6059 [D loss: 0.273858, acc.: 60.94%] [G loss: 0.454692]\n",
      "epoch:6 step:6060 [D loss: 0.217797, acc.: 61.72%] [G loss: 0.544247]\n",
      "epoch:6 step:6061 [D loss: 0.221247, acc.: 62.50%] [G loss: 0.486740]\n",
      "epoch:6 step:6062 [D loss: 0.205066, acc.: 69.53%] [G loss: 0.511111]\n",
      "epoch:6 step:6063 [D loss: 0.234858, acc.: 64.84%] [G loss: 0.502738]\n",
      "epoch:6 step:6064 [D loss: 0.190883, acc.: 76.56%] [G loss: 0.494497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6065 [D loss: 0.219890, acc.: 67.97%] [G loss: 0.477116]\n",
      "epoch:6 step:6066 [D loss: 0.220506, acc.: 67.19%] [G loss: 0.532202]\n",
      "epoch:6 step:6067 [D loss: 0.180298, acc.: 69.53%] [G loss: 0.551136]\n",
      "epoch:6 step:6068 [D loss: 0.208579, acc.: 67.97%] [G loss: 0.536366]\n",
      "epoch:6 step:6069 [D loss: 0.213408, acc.: 67.19%] [G loss: 0.549350]\n",
      "epoch:6 step:6070 [D loss: 0.229632, acc.: 64.84%] [G loss: 0.494114]\n",
      "epoch:6 step:6071 [D loss: 0.193215, acc.: 70.31%] [G loss: 0.497095]\n",
      "epoch:6 step:6072 [D loss: 0.213228, acc.: 65.62%] [G loss: 0.495725]\n",
      "epoch:6 step:6073 [D loss: 0.189222, acc.: 71.09%] [G loss: 0.556631]\n",
      "epoch:6 step:6074 [D loss: 0.220783, acc.: 62.50%] [G loss: 0.525260]\n",
      "epoch:6 step:6075 [D loss: 0.212872, acc.: 61.72%] [G loss: 0.506488]\n",
      "epoch:6 step:6076 [D loss: 0.229614, acc.: 63.28%] [G loss: 0.485424]\n",
      "epoch:6 step:6077 [D loss: 0.242719, acc.: 60.16%] [G loss: 0.445247]\n",
      "epoch:6 step:6078 [D loss: 0.209879, acc.: 64.06%] [G loss: 0.511407]\n",
      "epoch:6 step:6079 [D loss: 0.242190, acc.: 60.94%] [G loss: 0.507023]\n",
      "epoch:6 step:6080 [D loss: 0.271663, acc.: 53.12%] [G loss: 0.499886]\n",
      "epoch:6 step:6081 [D loss: 0.228637, acc.: 64.84%] [G loss: 0.471363]\n",
      "epoch:6 step:6082 [D loss: 0.188846, acc.: 69.53%] [G loss: 0.553416]\n",
      "epoch:6 step:6083 [D loss: 0.222498, acc.: 64.06%] [G loss: 0.512305]\n",
      "epoch:6 step:6084 [D loss: 0.225722, acc.: 60.94%] [G loss: 0.459186]\n",
      "epoch:6 step:6085 [D loss: 0.247434, acc.: 55.47%] [G loss: 0.449399]\n",
      "epoch:6 step:6086 [D loss: 0.194398, acc.: 71.88%] [G loss: 0.521663]\n",
      "epoch:6 step:6087 [D loss: 0.259330, acc.: 59.38%] [G loss: 0.495575]\n",
      "epoch:6 step:6088 [D loss: 0.222103, acc.: 59.38%] [G loss: 0.460745]\n",
      "epoch:6 step:6089 [D loss: 0.196475, acc.: 71.09%] [G loss: 0.507030]\n",
      "epoch:6 step:6090 [D loss: 0.216682, acc.: 66.41%] [G loss: 0.510540]\n",
      "epoch:6 step:6091 [D loss: 0.225680, acc.: 63.28%] [G loss: 0.530771]\n",
      "epoch:6 step:6092 [D loss: 0.188787, acc.: 71.09%] [G loss: 0.517060]\n",
      "epoch:6 step:6093 [D loss: 0.185744, acc.: 72.66%] [G loss: 0.505813]\n",
      "epoch:6 step:6094 [D loss: 0.196404, acc.: 69.53%] [G loss: 0.553153]\n",
      "epoch:6 step:6095 [D loss: 0.276013, acc.: 44.53%] [G loss: 0.458449]\n",
      "epoch:6 step:6096 [D loss: 0.223702, acc.: 58.59%] [G loss: 0.451164]\n",
      "epoch:6 step:6097 [D loss: 0.173697, acc.: 76.56%] [G loss: 0.547236]\n",
      "epoch:6 step:6098 [D loss: 0.250228, acc.: 63.28%] [G loss: 0.503397]\n",
      "epoch:6 step:6099 [D loss: 0.255057, acc.: 50.78%] [G loss: 0.471063]\n",
      "epoch:6 step:6100 [D loss: 0.245450, acc.: 60.94%] [G loss: 0.442414]\n",
      "epoch:6 step:6101 [D loss: 0.200976, acc.: 68.75%] [G loss: 0.475996]\n",
      "epoch:6 step:6102 [D loss: 0.235673, acc.: 62.50%] [G loss: 0.466502]\n",
      "epoch:6 step:6103 [D loss: 0.198531, acc.: 75.00%] [G loss: 0.514299]\n",
      "epoch:6 step:6104 [D loss: 0.256786, acc.: 54.69%] [G loss: 0.455430]\n",
      "epoch:6 step:6105 [D loss: 0.258283, acc.: 55.47%] [G loss: 0.431685]\n",
      "epoch:6 step:6106 [D loss: 0.196876, acc.: 69.53%] [G loss: 0.508778]\n",
      "epoch:6 step:6107 [D loss: 0.227749, acc.: 58.59%] [G loss: 0.511550]\n",
      "epoch:6 step:6108 [D loss: 0.228406, acc.: 65.62%] [G loss: 0.494838]\n",
      "epoch:6 step:6109 [D loss: 0.246179, acc.: 57.03%] [G loss: 0.466121]\n",
      "epoch:6 step:6110 [D loss: 0.194409, acc.: 67.19%] [G loss: 0.473160]\n",
      "epoch:6 step:6111 [D loss: 0.209942, acc.: 67.97%] [G loss: 0.500293]\n",
      "epoch:6 step:6112 [D loss: 0.201506, acc.: 68.75%] [G loss: 0.465918]\n",
      "epoch:6 step:6113 [D loss: 0.215756, acc.: 64.06%] [G loss: 0.506088]\n",
      "epoch:6 step:6114 [D loss: 0.233417, acc.: 61.72%] [G loss: 0.470466]\n",
      "epoch:6 step:6115 [D loss: 0.223531, acc.: 62.50%] [G loss: 0.431263]\n",
      "epoch:6 step:6116 [D loss: 0.192469, acc.: 75.78%] [G loss: 0.498198]\n",
      "epoch:6 step:6117 [D loss: 0.199349, acc.: 67.19%] [G loss: 0.607474]\n",
      "epoch:6 step:6118 [D loss: 0.208199, acc.: 71.09%] [G loss: 0.549949]\n",
      "epoch:6 step:6119 [D loss: 0.207661, acc.: 65.62%] [G loss: 0.539843]\n",
      "epoch:6 step:6120 [D loss: 0.214789, acc.: 64.06%] [G loss: 0.545487]\n",
      "epoch:6 step:6121 [D loss: 0.155629, acc.: 75.00%] [G loss: 0.576645]\n",
      "epoch:6 step:6122 [D loss: 0.276818, acc.: 53.91%] [G loss: 0.448776]\n",
      "epoch:6 step:6123 [D loss: 0.287283, acc.: 55.47%] [G loss: 0.467440]\n",
      "epoch:6 step:6124 [D loss: 0.208144, acc.: 68.75%] [G loss: 0.490744]\n",
      "epoch:6 step:6125 [D loss: 0.171466, acc.: 75.00%] [G loss: 0.490957]\n",
      "epoch:6 step:6126 [D loss: 0.190379, acc.: 68.75%] [G loss: 0.532838]\n",
      "epoch:6 step:6127 [D loss: 0.175244, acc.: 76.56%] [G loss: 0.529516]\n",
      "epoch:6 step:6128 [D loss: 0.247137, acc.: 61.72%] [G loss: 0.490534]\n",
      "epoch:6 step:6129 [D loss: 0.200000, acc.: 65.62%] [G loss: 0.540921]\n",
      "epoch:6 step:6130 [D loss: 0.180822, acc.: 76.56%] [G loss: 0.528362]\n",
      "epoch:6 step:6131 [D loss: 0.215332, acc.: 64.06%] [G loss: 0.511731]\n",
      "epoch:6 step:6132 [D loss: 0.260380, acc.: 60.94%] [G loss: 0.483612]\n",
      "epoch:6 step:6133 [D loss: 0.245523, acc.: 62.50%] [G loss: 0.453694]\n",
      "epoch:6 step:6134 [D loss: 0.223298, acc.: 65.62%] [G loss: 0.477211]\n",
      "epoch:6 step:6135 [D loss: 0.210902, acc.: 62.50%] [G loss: 0.482224]\n",
      "epoch:6 step:6136 [D loss: 0.202668, acc.: 67.19%] [G loss: 0.505106]\n",
      "epoch:6 step:6137 [D loss: 0.217435, acc.: 67.97%] [G loss: 0.552165]\n",
      "epoch:6 step:6138 [D loss: 0.201657, acc.: 67.97%] [G loss: 0.534986]\n",
      "epoch:6 step:6139 [D loss: 0.255773, acc.: 58.59%] [G loss: 0.489539]\n",
      "epoch:6 step:6140 [D loss: 0.199901, acc.: 68.75%] [G loss: 0.487702]\n",
      "epoch:6 step:6141 [D loss: 0.204399, acc.: 66.41%] [G loss: 0.494929]\n",
      "epoch:6 step:6142 [D loss: 0.179993, acc.: 75.00%] [G loss: 0.584893]\n",
      "epoch:6 step:6143 [D loss: 0.230507, acc.: 65.62%] [G loss: 0.490263]\n",
      "epoch:6 step:6144 [D loss: 0.188142, acc.: 71.88%] [G loss: 0.490663]\n",
      "epoch:6 step:6145 [D loss: 0.211253, acc.: 66.41%] [G loss: 0.487356]\n",
      "epoch:6 step:6146 [D loss: 0.238432, acc.: 61.72%] [G loss: 0.505144]\n",
      "epoch:6 step:6147 [D loss: 0.223582, acc.: 64.06%] [G loss: 0.490558]\n",
      "epoch:6 step:6148 [D loss: 0.222093, acc.: 64.84%] [G loss: 0.474992]\n",
      "epoch:6 step:6149 [D loss: 0.213511, acc.: 71.09%] [G loss: 0.474848]\n",
      "epoch:6 step:6150 [D loss: 0.265072, acc.: 52.34%] [G loss: 0.508041]\n",
      "epoch:6 step:6151 [D loss: 0.212070, acc.: 68.75%] [G loss: 0.482587]\n",
      "epoch:6 step:6152 [D loss: 0.197736, acc.: 75.78%] [G loss: 0.504187]\n",
      "epoch:6 step:6153 [D loss: 0.272052, acc.: 53.12%] [G loss: 0.455440]\n",
      "epoch:6 step:6154 [D loss: 0.205545, acc.: 65.62%] [G loss: 0.504726]\n",
      "epoch:6 step:6155 [D loss: 0.196810, acc.: 63.28%] [G loss: 0.534269]\n",
      "epoch:6 step:6156 [D loss: 0.190542, acc.: 65.62%] [G loss: 0.558672]\n",
      "epoch:6 step:6157 [D loss: 0.255391, acc.: 57.81%] [G loss: 0.478532]\n",
      "epoch:6 step:6158 [D loss: 0.182505, acc.: 76.56%] [G loss: 0.465132]\n",
      "epoch:6 step:6159 [D loss: 0.220839, acc.: 66.41%] [G loss: 0.524674]\n",
      "epoch:6 step:6160 [D loss: 0.222248, acc.: 61.72%] [G loss: 0.507589]\n",
      "epoch:6 step:6161 [D loss: 0.221687, acc.: 64.06%] [G loss: 0.483441]\n",
      "epoch:6 step:6162 [D loss: 0.204838, acc.: 67.19%] [G loss: 0.583809]\n",
      "epoch:6 step:6163 [D loss: 0.202862, acc.: 64.84%] [G loss: 0.512651]\n",
      "epoch:6 step:6164 [D loss: 0.269716, acc.: 48.44%] [G loss: 0.465843]\n",
      "epoch:6 step:6165 [D loss: 0.209482, acc.: 67.97%] [G loss: 0.519922]\n",
      "epoch:6 step:6166 [D loss: 0.231921, acc.: 60.94%] [G loss: 0.503186]\n",
      "epoch:6 step:6167 [D loss: 0.196329, acc.: 71.09%] [G loss: 0.508163]\n",
      "epoch:6 step:6168 [D loss: 0.213545, acc.: 65.62%] [G loss: 0.492867]\n",
      "epoch:6 step:6169 [D loss: 0.192890, acc.: 64.84%] [G loss: 0.545776]\n",
      "epoch:6 step:6170 [D loss: 0.207318, acc.: 66.41%] [G loss: 0.516391]\n",
      "epoch:6 step:6171 [D loss: 0.201117, acc.: 69.53%] [G loss: 0.476562]\n",
      "epoch:6 step:6172 [D loss: 0.208977, acc.: 64.84%] [G loss: 0.525077]\n",
      "epoch:6 step:6173 [D loss: 0.188993, acc.: 70.31%] [G loss: 0.556328]\n",
      "epoch:6 step:6174 [D loss: 0.201153, acc.: 70.31%] [G loss: 0.511810]\n",
      "epoch:6 step:6175 [D loss: 0.237170, acc.: 61.72%] [G loss: 0.471748]\n",
      "epoch:6 step:6176 [D loss: 0.209420, acc.: 68.75%] [G loss: 0.508247]\n",
      "epoch:6 step:6177 [D loss: 0.190512, acc.: 66.41%] [G loss: 0.571924]\n",
      "epoch:6 step:6178 [D loss: 0.202945, acc.: 68.75%] [G loss: 0.510136]\n",
      "epoch:6 step:6179 [D loss: 0.212215, acc.: 63.28%] [G loss: 0.444814]\n",
      "epoch:6 step:6180 [D loss: 0.200709, acc.: 71.09%] [G loss: 0.553677]\n",
      "epoch:6 step:6181 [D loss: 0.268805, acc.: 53.12%] [G loss: 0.484622]\n",
      "epoch:6 step:6182 [D loss: 0.242719, acc.: 59.38%] [G loss: 0.474194]\n",
      "epoch:6 step:6183 [D loss: 0.208309, acc.: 68.75%] [G loss: 0.465577]\n",
      "epoch:6 step:6184 [D loss: 0.246270, acc.: 54.69%] [G loss: 0.482147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6185 [D loss: 0.213725, acc.: 68.75%] [G loss: 0.565616]\n",
      "epoch:6 step:6186 [D loss: 0.194415, acc.: 65.62%] [G loss: 0.526366]\n",
      "epoch:6 step:6187 [D loss: 0.237255, acc.: 60.94%] [G loss: 0.555782]\n",
      "epoch:6 step:6188 [D loss: 0.258595, acc.: 60.16%] [G loss: 0.478297]\n",
      "epoch:6 step:6189 [D loss: 0.200627, acc.: 70.31%] [G loss: 0.510410]\n",
      "epoch:6 step:6190 [D loss: 0.186932, acc.: 68.75%] [G loss: 0.529103]\n",
      "epoch:6 step:6191 [D loss: 0.251060, acc.: 59.38%] [G loss: 0.476085]\n",
      "epoch:6 step:6192 [D loss: 0.200035, acc.: 68.75%] [G loss: 0.472796]\n",
      "epoch:6 step:6193 [D loss: 0.210113, acc.: 70.31%] [G loss: 0.489713]\n",
      "epoch:6 step:6194 [D loss: 0.199946, acc.: 69.53%] [G loss: 0.487983]\n",
      "epoch:6 step:6195 [D loss: 0.236762, acc.: 62.50%] [G loss: 0.525372]\n",
      "epoch:6 step:6196 [D loss: 0.175551, acc.: 73.44%] [G loss: 0.529504]\n",
      "epoch:6 step:6197 [D loss: 0.199172, acc.: 67.19%] [G loss: 0.547145]\n",
      "epoch:6 step:6198 [D loss: 0.241690, acc.: 57.03%] [G loss: 0.542947]\n",
      "epoch:6 step:6199 [D loss: 0.233950, acc.: 65.62%] [G loss: 0.476660]\n",
      "epoch:6 step:6200 [D loss: 0.222037, acc.: 60.94%] [G loss: 0.480907]\n",
      "epoch:6 step:6201 [D loss: 0.198247, acc.: 71.09%] [G loss: 0.521313]\n",
      "epoch:6 step:6202 [D loss: 0.250857, acc.: 56.25%] [G loss: 0.433688]\n",
      "epoch:6 step:6203 [D loss: 0.216208, acc.: 62.50%] [G loss: 0.524285]\n",
      "epoch:6 step:6204 [D loss: 0.203716, acc.: 65.62%] [G loss: 0.524920]\n",
      "epoch:6 step:6205 [D loss: 0.249489, acc.: 59.38%] [G loss: 0.490732]\n",
      "epoch:6 step:6206 [D loss: 0.248966, acc.: 60.94%] [G loss: 0.472885]\n",
      "epoch:6 step:6207 [D loss: 0.222090, acc.: 62.50%] [G loss: 0.493073]\n",
      "epoch:6 step:6208 [D loss: 0.233173, acc.: 60.94%] [G loss: 0.456871]\n",
      "epoch:6 step:6209 [D loss: 0.242234, acc.: 58.59%] [G loss: 0.452055]\n",
      "epoch:6 step:6210 [D loss: 0.219002, acc.: 67.19%] [G loss: 0.514277]\n",
      "epoch:6 step:6211 [D loss: 0.207580, acc.: 67.19%] [G loss: 0.485279]\n",
      "epoch:6 step:6212 [D loss: 0.266518, acc.: 53.12%] [G loss: 0.457138]\n",
      "epoch:6 step:6213 [D loss: 0.219040, acc.: 65.62%] [G loss: 0.504349]\n",
      "epoch:6 step:6214 [D loss: 0.197782, acc.: 69.53%] [G loss: 0.477700]\n",
      "epoch:6 step:6215 [D loss: 0.208040, acc.: 70.31%] [G loss: 0.525151]\n",
      "epoch:6 step:6216 [D loss: 0.243643, acc.: 57.81%] [G loss: 0.480968]\n",
      "epoch:6 step:6217 [D loss: 0.222303, acc.: 61.72%] [G loss: 0.512141]\n",
      "epoch:6 step:6218 [D loss: 0.242663, acc.: 59.38%] [G loss: 0.478350]\n",
      "epoch:6 step:6219 [D loss: 0.211778, acc.: 67.19%] [G loss: 0.488675]\n",
      "epoch:6 step:6220 [D loss: 0.210586, acc.: 67.97%] [G loss: 0.471164]\n",
      "epoch:6 step:6221 [D loss: 0.223094, acc.: 67.19%] [G loss: 0.488173]\n",
      "epoch:6 step:6222 [D loss: 0.246473, acc.: 60.16%] [G loss: 0.456150]\n",
      "epoch:6 step:6223 [D loss: 0.237726, acc.: 63.28%] [G loss: 0.470808]\n",
      "epoch:6 step:6224 [D loss: 0.251606, acc.: 59.38%] [G loss: 0.469422]\n",
      "epoch:6 step:6225 [D loss: 0.214947, acc.: 66.41%] [G loss: 0.484583]\n",
      "epoch:6 step:6226 [D loss: 0.207161, acc.: 63.28%] [G loss: 0.503902]\n",
      "epoch:6 step:6227 [D loss: 0.189525, acc.: 71.88%] [G loss: 0.486218]\n",
      "epoch:6 step:6228 [D loss: 0.230836, acc.: 56.25%] [G loss: 0.479182]\n",
      "epoch:6 step:6229 [D loss: 0.211582, acc.: 67.19%] [G loss: 0.471720]\n",
      "epoch:6 step:6230 [D loss: 0.181913, acc.: 78.91%] [G loss: 0.547452]\n",
      "epoch:6 step:6231 [D loss: 0.209960, acc.: 64.84%] [G loss: 0.479097]\n",
      "epoch:6 step:6232 [D loss: 0.206212, acc.: 71.09%] [G loss: 0.467766]\n",
      "epoch:6 step:6233 [D loss: 0.236645, acc.: 58.59%] [G loss: 0.430252]\n",
      "epoch:6 step:6234 [D loss: 0.200869, acc.: 67.97%] [G loss: 0.485390]\n",
      "epoch:6 step:6235 [D loss: 0.173522, acc.: 75.00%] [G loss: 0.553106]\n",
      "epoch:6 step:6236 [D loss: 0.216506, acc.: 65.62%] [G loss: 0.504219]\n",
      "epoch:6 step:6237 [D loss: 0.265469, acc.: 53.12%] [G loss: 0.464826]\n",
      "epoch:6 step:6238 [D loss: 0.242839, acc.: 58.59%] [G loss: 0.483540]\n",
      "epoch:6 step:6239 [D loss: 0.200590, acc.: 68.75%] [G loss: 0.500221]\n",
      "epoch:6 step:6240 [D loss: 0.196345, acc.: 64.06%] [G loss: 0.516841]\n",
      "epoch:6 step:6241 [D loss: 0.251313, acc.: 59.38%] [G loss: 0.497254]\n",
      "epoch:6 step:6242 [D loss: 0.203793, acc.: 70.31%] [G loss: 0.549822]\n",
      "epoch:6 step:6243 [D loss: 0.205630, acc.: 65.62%] [G loss: 0.522901]\n",
      "epoch:6 step:6244 [D loss: 0.254211, acc.: 55.47%] [G loss: 0.492546]\n",
      "epoch:6 step:6245 [D loss: 0.236424, acc.: 63.28%] [G loss: 0.451172]\n",
      "epoch:6 step:6246 [D loss: 0.182042, acc.: 71.88%] [G loss: 0.542571]\n",
      "epoch:6 step:6247 [D loss: 0.219601, acc.: 64.84%] [G loss: 0.546264]\n",
      "epoch:6 step:6248 [D loss: 0.271951, acc.: 49.22%] [G loss: 0.458558]\n",
      "epoch:6 step:6249 [D loss: 0.199357, acc.: 68.75%] [G loss: 0.523808]\n",
      "epoch:6 step:6250 [D loss: 0.254988, acc.: 55.47%] [G loss: 0.440428]\n",
      "epoch:6 step:6251 [D loss: 0.191438, acc.: 78.12%] [G loss: 0.520592]\n",
      "epoch:6 step:6252 [D loss: 0.238068, acc.: 60.16%] [G loss: 0.505333]\n",
      "epoch:6 step:6253 [D loss: 0.201446, acc.: 67.19%] [G loss: 0.495032]\n",
      "epoch:6 step:6254 [D loss: 0.190174, acc.: 73.44%] [G loss: 0.506721]\n",
      "epoch:6 step:6255 [D loss: 0.225144, acc.: 67.19%] [G loss: 0.509199]\n",
      "epoch:6 step:6256 [D loss: 0.186398, acc.: 67.97%] [G loss: 0.546821]\n",
      "epoch:6 step:6257 [D loss: 0.197848, acc.: 65.62%] [G loss: 0.492760]\n",
      "epoch:6 step:6258 [D loss: 0.236867, acc.: 59.38%] [G loss: 0.505905]\n",
      "epoch:6 step:6259 [D loss: 0.223367, acc.: 64.06%] [G loss: 0.495467]\n",
      "epoch:6 step:6260 [D loss: 0.220446, acc.: 66.41%] [G loss: 0.477479]\n",
      "epoch:6 step:6261 [D loss: 0.210856, acc.: 64.84%] [G loss: 0.512025]\n",
      "epoch:6 step:6262 [D loss: 0.202114, acc.: 67.19%] [G loss: 0.515985]\n",
      "epoch:6 step:6263 [D loss: 0.194354, acc.: 70.31%] [G loss: 0.529879]\n",
      "epoch:6 step:6264 [D loss: 0.162452, acc.: 77.34%] [G loss: 0.586104]\n",
      "epoch:6 step:6265 [D loss: 0.235415, acc.: 59.38%] [G loss: 0.525984]\n",
      "epoch:6 step:6266 [D loss: 0.223720, acc.: 62.50%] [G loss: 0.525501]\n",
      "epoch:6 step:6267 [D loss: 0.228406, acc.: 64.84%] [G loss: 0.466708]\n",
      "epoch:6 step:6268 [D loss: 0.195651, acc.: 70.31%] [G loss: 0.549693]\n",
      "epoch:6 step:6269 [D loss: 0.166794, acc.: 77.34%] [G loss: 0.572333]\n",
      "epoch:6 step:6270 [D loss: 0.150269, acc.: 79.69%] [G loss: 0.643202]\n",
      "epoch:6 step:6271 [D loss: 0.195314, acc.: 71.88%] [G loss: 0.566899]\n",
      "epoch:6 step:6272 [D loss: 0.196029, acc.: 71.88%] [G loss: 0.561255]\n",
      "epoch:6 step:6273 [D loss: 0.207330, acc.: 67.97%] [G loss: 0.528512]\n",
      "epoch:6 step:6274 [D loss: 0.235951, acc.: 62.50%] [G loss: 0.463166]\n",
      "epoch:6 step:6275 [D loss: 0.204678, acc.: 63.28%] [G loss: 0.499472]\n",
      "epoch:6 step:6276 [D loss: 0.227355, acc.: 62.50%] [G loss: 0.539449]\n",
      "epoch:6 step:6277 [D loss: 0.229845, acc.: 67.19%] [G loss: 0.540837]\n",
      "epoch:6 step:6278 [D loss: 0.235338, acc.: 60.94%] [G loss: 0.486267]\n",
      "epoch:6 step:6279 [D loss: 0.232380, acc.: 60.16%] [G loss: 0.460994]\n",
      "epoch:6 step:6280 [D loss: 0.259885, acc.: 59.38%] [G loss: 0.481315]\n",
      "epoch:6 step:6281 [D loss: 0.209894, acc.: 65.62%] [G loss: 0.512948]\n",
      "epoch:6 step:6282 [D loss: 0.187116, acc.: 69.53%] [G loss: 0.529995]\n",
      "epoch:6 step:6283 [D loss: 0.171766, acc.: 73.44%] [G loss: 0.577134]\n",
      "epoch:6 step:6284 [D loss: 0.256770, acc.: 60.16%] [G loss: 0.470286]\n",
      "epoch:6 step:6285 [D loss: 0.202654, acc.: 69.53%] [G loss: 0.505598]\n",
      "epoch:6 step:6286 [D loss: 0.211955, acc.: 70.31%] [G loss: 0.520053]\n",
      "epoch:6 step:6287 [D loss: 0.235547, acc.: 60.94%] [G loss: 0.484743]\n",
      "epoch:6 step:6288 [D loss: 0.208044, acc.: 69.53%] [G loss: 0.474322]\n",
      "epoch:6 step:6289 [D loss: 0.246079, acc.: 62.50%] [G loss: 0.489991]\n",
      "epoch:6 step:6290 [D loss: 0.256607, acc.: 57.03%] [G loss: 0.496512]\n",
      "epoch:6 step:6291 [D loss: 0.186458, acc.: 70.31%] [G loss: 0.514795]\n",
      "epoch:6 step:6292 [D loss: 0.220996, acc.: 64.06%] [G loss: 0.452854]\n",
      "epoch:6 step:6293 [D loss: 0.225013, acc.: 64.06%] [G loss: 0.464618]\n",
      "epoch:6 step:6294 [D loss: 0.280433, acc.: 58.59%] [G loss: 0.443445]\n",
      "epoch:6 step:6295 [D loss: 0.233202, acc.: 61.72%] [G loss: 0.483188]\n",
      "epoch:6 step:6296 [D loss: 0.231386, acc.: 59.38%] [G loss: 0.534287]\n",
      "epoch:6 step:6297 [D loss: 0.216910, acc.: 60.94%] [G loss: 0.476224]\n",
      "epoch:6 step:6298 [D loss: 0.208247, acc.: 65.62%] [G loss: 0.498019]\n",
      "epoch:6 step:6299 [D loss: 0.194318, acc.: 70.31%] [G loss: 0.501115]\n",
      "epoch:6 step:6300 [D loss: 0.243855, acc.: 64.06%] [G loss: 0.456566]\n",
      "epoch:6 step:6301 [D loss: 0.220902, acc.: 65.62%] [G loss: 0.479614]\n",
      "epoch:6 step:6302 [D loss: 0.216437, acc.: 66.41%] [G loss: 0.512374]\n",
      "epoch:6 step:6303 [D loss: 0.194544, acc.: 69.53%] [G loss: 0.543243]\n",
      "epoch:6 step:6304 [D loss: 0.208053, acc.: 67.97%] [G loss: 0.481133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6305 [D loss: 0.235161, acc.: 61.72%] [G loss: 0.435275]\n",
      "epoch:6 step:6306 [D loss: 0.235712, acc.: 65.62%] [G loss: 0.466579]\n",
      "epoch:6 step:6307 [D loss: 0.199797, acc.: 70.31%] [G loss: 0.489818]\n",
      "epoch:6 step:6308 [D loss: 0.227410, acc.: 65.62%] [G loss: 0.489421]\n",
      "epoch:6 step:6309 [D loss: 0.236493, acc.: 65.62%] [G loss: 0.468772]\n",
      "epoch:6 step:6310 [D loss: 0.202439, acc.: 68.75%] [G loss: 0.504309]\n",
      "epoch:6 step:6311 [D loss: 0.242052, acc.: 57.03%] [G loss: 0.483413]\n",
      "epoch:6 step:6312 [D loss: 0.207000, acc.: 61.72%] [G loss: 0.549848]\n",
      "epoch:6 step:6313 [D loss: 0.199588, acc.: 68.75%] [G loss: 0.529451]\n",
      "epoch:6 step:6314 [D loss: 0.201523, acc.: 67.19%] [G loss: 0.533267]\n",
      "epoch:6 step:6315 [D loss: 0.201542, acc.: 71.88%] [G loss: 0.533058]\n",
      "epoch:6 step:6316 [D loss: 0.208185, acc.: 69.53%] [G loss: 0.535573]\n",
      "epoch:6 step:6317 [D loss: 0.206201, acc.: 64.06%] [G loss: 0.526476]\n",
      "epoch:6 step:6318 [D loss: 0.240769, acc.: 54.69%] [G loss: 0.488736]\n",
      "epoch:6 step:6319 [D loss: 0.215939, acc.: 61.72%] [G loss: 0.489297]\n",
      "epoch:6 step:6320 [D loss: 0.222227, acc.: 63.28%] [G loss: 0.489701]\n",
      "epoch:6 step:6321 [D loss: 0.198523, acc.: 64.84%] [G loss: 0.491627]\n",
      "epoch:6 step:6322 [D loss: 0.214137, acc.: 67.97%] [G loss: 0.507237]\n",
      "epoch:6 step:6323 [D loss: 0.205755, acc.: 70.31%] [G loss: 0.540690]\n",
      "epoch:6 step:6324 [D loss: 0.266602, acc.: 55.47%] [G loss: 0.495323]\n",
      "epoch:6 step:6325 [D loss: 0.223288, acc.: 62.50%] [G loss: 0.469464]\n",
      "epoch:6 step:6326 [D loss: 0.234999, acc.: 59.38%] [G loss: 0.492409]\n",
      "epoch:6 step:6327 [D loss: 0.228475, acc.: 67.19%] [G loss: 0.517566]\n",
      "epoch:6 step:6328 [D loss: 0.184484, acc.: 69.53%] [G loss: 0.516274]\n",
      "epoch:6 step:6329 [D loss: 0.196553, acc.: 71.88%] [G loss: 0.509192]\n",
      "epoch:6 step:6330 [D loss: 0.184834, acc.: 67.19%] [G loss: 0.527559]\n",
      "epoch:6 step:6331 [D loss: 0.192572, acc.: 68.75%] [G loss: 0.528843]\n",
      "epoch:6 step:6332 [D loss: 0.233380, acc.: 60.94%] [G loss: 0.496025]\n",
      "epoch:6 step:6333 [D loss: 0.219301, acc.: 60.94%] [G loss: 0.482749]\n",
      "epoch:6 step:6334 [D loss: 0.206580, acc.: 65.62%] [G loss: 0.516382]\n",
      "epoch:6 step:6335 [D loss: 0.228546, acc.: 66.41%] [G loss: 0.522142]\n",
      "epoch:6 step:6336 [D loss: 0.229400, acc.: 66.41%] [G loss: 0.554961]\n",
      "epoch:6 step:6337 [D loss: 0.220894, acc.: 62.50%] [G loss: 0.513230]\n",
      "epoch:6 step:6338 [D loss: 0.242786, acc.: 56.25%] [G loss: 0.478485]\n",
      "epoch:6 step:6339 [D loss: 0.235316, acc.: 58.59%] [G loss: 0.508137]\n",
      "epoch:6 step:6340 [D loss: 0.217873, acc.: 67.19%] [G loss: 0.504664]\n",
      "epoch:6 step:6341 [D loss: 0.200701, acc.: 67.97%] [G loss: 0.505343]\n",
      "epoch:6 step:6342 [D loss: 0.237893, acc.: 60.94%] [G loss: 0.499942]\n",
      "epoch:6 step:6343 [D loss: 0.206943, acc.: 71.88%] [G loss: 0.477312]\n",
      "epoch:6 step:6344 [D loss: 0.238239, acc.: 60.94%] [G loss: 0.502141]\n",
      "epoch:6 step:6345 [D loss: 0.216697, acc.: 66.41%] [G loss: 0.483818]\n",
      "epoch:6 step:6346 [D loss: 0.219722, acc.: 60.94%] [G loss: 0.509108]\n",
      "epoch:6 step:6347 [D loss: 0.212869, acc.: 66.41%] [G loss: 0.497327]\n",
      "epoch:6 step:6348 [D loss: 0.218995, acc.: 66.41%] [G loss: 0.540584]\n",
      "epoch:6 step:6349 [D loss: 0.243451, acc.: 56.25%] [G loss: 0.494485]\n",
      "epoch:6 step:6350 [D loss: 0.187221, acc.: 74.22%] [G loss: 0.485872]\n",
      "epoch:6 step:6351 [D loss: 0.221580, acc.: 64.06%] [G loss: 0.513395]\n",
      "epoch:6 step:6352 [D loss: 0.184497, acc.: 71.88%] [G loss: 0.503528]\n",
      "epoch:6 step:6353 [D loss: 0.204012, acc.: 64.84%] [G loss: 0.564105]\n",
      "epoch:6 step:6354 [D loss: 0.229847, acc.: 60.94%] [G loss: 0.531389]\n",
      "epoch:6 step:6355 [D loss: 0.225339, acc.: 64.06%] [G loss: 0.489399]\n",
      "epoch:6 step:6356 [D loss: 0.232675, acc.: 60.16%] [G loss: 0.452762]\n",
      "epoch:6 step:6357 [D loss: 0.207325, acc.: 67.97%] [G loss: 0.474999]\n",
      "epoch:6 step:6358 [D loss: 0.207173, acc.: 64.06%] [G loss: 0.497239]\n",
      "epoch:6 step:6359 [D loss: 0.185360, acc.: 70.31%] [G loss: 0.500438]\n",
      "epoch:6 step:6360 [D loss: 0.227669, acc.: 60.94%] [G loss: 0.455468]\n",
      "epoch:6 step:6361 [D loss: 0.261257, acc.: 53.12%] [G loss: 0.401224]\n",
      "epoch:6 step:6362 [D loss: 0.263911, acc.: 54.69%] [G loss: 0.488803]\n",
      "epoch:6 step:6363 [D loss: 0.229319, acc.: 64.06%] [G loss: 0.484952]\n",
      "epoch:6 step:6364 [D loss: 0.229468, acc.: 61.72%] [G loss: 0.485493]\n",
      "epoch:6 step:6365 [D loss: 0.213069, acc.: 64.06%] [G loss: 0.399243]\n",
      "epoch:6 step:6366 [D loss: 0.236318, acc.: 59.38%] [G loss: 0.488782]\n",
      "epoch:6 step:6367 [D loss: 0.215473, acc.: 64.06%] [G loss: 0.525927]\n",
      "epoch:6 step:6368 [D loss: 0.206841, acc.: 65.62%] [G loss: 0.472223]\n",
      "epoch:6 step:6369 [D loss: 0.201671, acc.: 69.53%] [G loss: 0.525063]\n",
      "epoch:6 step:6370 [D loss: 0.242473, acc.: 59.38%] [G loss: 0.473613]\n",
      "epoch:6 step:6371 [D loss: 0.245448, acc.: 59.38%] [G loss: 0.438396]\n",
      "epoch:6 step:6372 [D loss: 0.205966, acc.: 68.75%] [G loss: 0.498731]\n",
      "epoch:6 step:6373 [D loss: 0.229375, acc.: 53.12%] [G loss: 0.464057]\n",
      "epoch:6 step:6374 [D loss: 0.226026, acc.: 64.06%] [G loss: 0.459207]\n",
      "epoch:6 step:6375 [D loss: 0.198012, acc.: 67.97%] [G loss: 0.504838]\n",
      "epoch:6 step:6376 [D loss: 0.203614, acc.: 66.41%] [G loss: 0.510727]\n",
      "epoch:6 step:6377 [D loss: 0.206536, acc.: 66.41%] [G loss: 0.492144]\n",
      "epoch:6 step:6378 [D loss: 0.196136, acc.: 72.66%] [G loss: 0.464841]\n",
      "epoch:6 step:6379 [D loss: 0.234952, acc.: 60.94%] [G loss: 0.501847]\n",
      "epoch:6 step:6380 [D loss: 0.189655, acc.: 75.00%] [G loss: 0.480612]\n",
      "epoch:6 step:6381 [D loss: 0.223437, acc.: 61.72%] [G loss: 0.519266]\n",
      "epoch:6 step:6382 [D loss: 0.190673, acc.: 71.09%] [G loss: 0.489949]\n",
      "epoch:6 step:6383 [D loss: 0.225934, acc.: 62.50%] [G loss: 0.441634]\n",
      "epoch:6 step:6384 [D loss: 0.255617, acc.: 52.34%] [G loss: 0.457234]\n",
      "epoch:6 step:6385 [D loss: 0.209782, acc.: 67.19%] [G loss: 0.482605]\n",
      "epoch:6 step:6386 [D loss: 0.224247, acc.: 58.59%] [G loss: 0.444297]\n",
      "epoch:6 step:6387 [D loss: 0.273741, acc.: 49.22%] [G loss: 0.430493]\n",
      "epoch:6 step:6388 [D loss: 0.244621, acc.: 57.03%] [G loss: 0.467379]\n",
      "epoch:6 step:6389 [D loss: 0.215667, acc.: 67.97%] [G loss: 0.482951]\n",
      "epoch:6 step:6390 [D loss: 0.212087, acc.: 70.31%] [G loss: 0.503789]\n",
      "epoch:6 step:6391 [D loss: 0.196863, acc.: 67.97%] [G loss: 0.522992]\n",
      "epoch:6 step:6392 [D loss: 0.207189, acc.: 67.97%] [G loss: 0.509795]\n",
      "epoch:6 step:6393 [D loss: 0.197792, acc.: 67.19%] [G loss: 0.504459]\n",
      "epoch:6 step:6394 [D loss: 0.197953, acc.: 66.41%] [G loss: 0.513710]\n",
      "epoch:6 step:6395 [D loss: 0.204957, acc.: 66.41%] [G loss: 0.518751]\n",
      "epoch:6 step:6396 [D loss: 0.250883, acc.: 59.38%] [G loss: 0.485427]\n",
      "epoch:6 step:6397 [D loss: 0.213921, acc.: 66.41%] [G loss: 0.517604]\n",
      "epoch:6 step:6398 [D loss: 0.237314, acc.: 64.06%] [G loss: 0.514666]\n",
      "epoch:6 step:6399 [D loss: 0.216748, acc.: 64.84%] [G loss: 0.503586]\n",
      "epoch:6 step:6400 [D loss: 0.239241, acc.: 56.25%] [G loss: 0.439578]\n",
      "epoch:6 step:6401 [D loss: 0.235685, acc.: 58.59%] [G loss: 0.507092]\n",
      "epoch:6 step:6402 [D loss: 0.197373, acc.: 71.88%] [G loss: 0.502610]\n",
      "epoch:6 step:6403 [D loss: 0.213075, acc.: 65.62%] [G loss: 0.515056]\n",
      "epoch:6 step:6404 [D loss: 0.205812, acc.: 67.97%] [G loss: 0.511935]\n",
      "epoch:6 step:6405 [D loss: 0.242091, acc.: 57.03%] [G loss: 0.527649]\n",
      "epoch:6 step:6406 [D loss: 0.227329, acc.: 63.28%] [G loss: 0.474392]\n",
      "epoch:6 step:6407 [D loss: 0.237644, acc.: 58.59%] [G loss: 0.423427]\n",
      "epoch:6 step:6408 [D loss: 0.182013, acc.: 70.31%] [G loss: 0.490065]\n",
      "epoch:6 step:6409 [D loss: 0.242770, acc.: 59.38%] [G loss: 0.497607]\n",
      "epoch:6 step:6410 [D loss: 0.265293, acc.: 52.34%] [G loss: 0.476876]\n",
      "epoch:6 step:6411 [D loss: 0.223022, acc.: 62.50%] [G loss: 0.463861]\n",
      "epoch:6 step:6412 [D loss: 0.204784, acc.: 68.75%] [G loss: 0.475742]\n",
      "epoch:6 step:6413 [D loss: 0.245302, acc.: 60.94%] [G loss: 0.431243]\n",
      "epoch:6 step:6414 [D loss: 0.185060, acc.: 72.66%] [G loss: 0.512714]\n",
      "epoch:6 step:6415 [D loss: 0.237473, acc.: 64.06%] [G loss: 0.514511]\n",
      "epoch:6 step:6416 [D loss: 0.261186, acc.: 55.47%] [G loss: 0.447916]\n",
      "epoch:6 step:6417 [D loss: 0.255175, acc.: 58.59%] [G loss: 0.471511]\n",
      "epoch:6 step:6418 [D loss: 0.214828, acc.: 68.75%] [G loss: 0.545183]\n",
      "epoch:6 step:6419 [D loss: 0.245656, acc.: 56.25%] [G loss: 0.504429]\n",
      "epoch:6 step:6420 [D loss: 0.219598, acc.: 64.84%] [G loss: 0.471787]\n",
      "epoch:6 step:6421 [D loss: 0.199715, acc.: 67.19%] [G loss: 0.500179]\n",
      "epoch:6 step:6422 [D loss: 0.236124, acc.: 60.94%] [G loss: 0.513233]\n",
      "epoch:6 step:6423 [D loss: 0.210032, acc.: 68.75%] [G loss: 0.473906]\n",
      "epoch:6 step:6424 [D loss: 0.195495, acc.: 69.53%] [G loss: 0.525292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6425 [D loss: 0.213396, acc.: 69.53%] [G loss: 0.501745]\n",
      "epoch:6 step:6426 [D loss: 0.193236, acc.: 67.97%] [G loss: 0.491957]\n",
      "epoch:6 step:6427 [D loss: 0.204671, acc.: 67.97%] [G loss: 0.467454]\n",
      "epoch:6 step:6428 [D loss: 0.232279, acc.: 60.94%] [G loss: 0.476946]\n",
      "epoch:6 step:6429 [D loss: 0.239127, acc.: 58.59%] [G loss: 0.490975]\n",
      "epoch:6 step:6430 [D loss: 0.250827, acc.: 53.91%] [G loss: 0.469517]\n",
      "epoch:6 step:6431 [D loss: 0.238869, acc.: 58.59%] [G loss: 0.496515]\n",
      "epoch:6 step:6432 [D loss: 0.216282, acc.: 67.19%] [G loss: 0.525104]\n",
      "epoch:6 step:6433 [D loss: 0.229824, acc.: 60.94%] [G loss: 0.509460]\n",
      "epoch:6 step:6434 [D loss: 0.259375, acc.: 53.91%] [G loss: 0.458939]\n",
      "epoch:6 step:6435 [D loss: 0.215214, acc.: 64.84%] [G loss: 0.451637]\n",
      "epoch:6 step:6436 [D loss: 0.219680, acc.: 68.75%] [G loss: 0.482968]\n",
      "epoch:6 step:6437 [D loss: 0.195198, acc.: 71.09%] [G loss: 0.520414]\n",
      "epoch:6 step:6438 [D loss: 0.203942, acc.: 68.75%] [G loss: 0.543472]\n",
      "epoch:6 step:6439 [D loss: 0.243874, acc.: 56.25%] [G loss: 0.469922]\n",
      "epoch:6 step:6440 [D loss: 0.236556, acc.: 60.94%] [G loss: 0.438041]\n",
      "epoch:6 step:6441 [D loss: 0.201871, acc.: 66.41%] [G loss: 0.493298]\n",
      "epoch:6 step:6442 [D loss: 0.238853, acc.: 57.81%] [G loss: 0.507102]\n",
      "epoch:6 step:6443 [D loss: 0.213207, acc.: 67.97%] [G loss: 0.441338]\n",
      "epoch:6 step:6444 [D loss: 0.192758, acc.: 69.53%] [G loss: 0.465589]\n",
      "epoch:6 step:6445 [D loss: 0.204763, acc.: 66.41%] [G loss: 0.442870]\n",
      "epoch:6 step:6446 [D loss: 0.242055, acc.: 63.28%] [G loss: 0.470804]\n",
      "epoch:6 step:6447 [D loss: 0.204214, acc.: 71.88%] [G loss: 0.468297]\n",
      "epoch:6 step:6448 [D loss: 0.211600, acc.: 67.19%] [G loss: 0.524293]\n",
      "epoch:6 step:6449 [D loss: 0.226176, acc.: 62.50%] [G loss: 0.443966]\n",
      "epoch:6 step:6450 [D loss: 0.241650, acc.: 59.38%] [G loss: 0.471895]\n",
      "epoch:6 step:6451 [D loss: 0.232270, acc.: 60.16%] [G loss: 0.486368]\n",
      "epoch:6 step:6452 [D loss: 0.210981, acc.: 68.75%] [G loss: 0.545790]\n",
      "epoch:6 step:6453 [D loss: 0.234807, acc.: 62.50%] [G loss: 0.467829]\n",
      "epoch:6 step:6454 [D loss: 0.208131, acc.: 68.75%] [G loss: 0.471762]\n",
      "epoch:6 step:6455 [D loss: 0.202425, acc.: 68.75%] [G loss: 0.517593]\n",
      "epoch:6 step:6456 [D loss: 0.230042, acc.: 62.50%] [G loss: 0.500219]\n",
      "epoch:6 step:6457 [D loss: 0.188919, acc.: 71.09%] [G loss: 0.545763]\n",
      "epoch:6 step:6458 [D loss: 0.210946, acc.: 67.97%] [G loss: 0.503158]\n",
      "epoch:6 step:6459 [D loss: 0.211574, acc.: 69.53%] [G loss: 0.504416]\n",
      "epoch:6 step:6460 [D loss: 0.223257, acc.: 63.28%] [G loss: 0.498446]\n",
      "epoch:6 step:6461 [D loss: 0.236864, acc.: 59.38%] [G loss: 0.497451]\n",
      "epoch:6 step:6462 [D loss: 0.224954, acc.: 61.72%] [G loss: 0.506174]\n",
      "epoch:6 step:6463 [D loss: 0.233152, acc.: 55.47%] [G loss: 0.525384]\n",
      "epoch:6 step:6464 [D loss: 0.205800, acc.: 67.19%] [G loss: 0.493450]\n",
      "epoch:6 step:6465 [D loss: 0.221575, acc.: 62.50%] [G loss: 0.495095]\n",
      "epoch:6 step:6466 [D loss: 0.238435, acc.: 59.38%] [G loss: 0.454691]\n",
      "epoch:6 step:6467 [D loss: 0.197442, acc.: 70.31%] [G loss: 0.569373]\n",
      "epoch:6 step:6468 [D loss: 0.246157, acc.: 59.38%] [G loss: 0.515831]\n",
      "epoch:6 step:6469 [D loss: 0.230699, acc.: 63.28%] [G loss: 0.413457]\n",
      "epoch:6 step:6470 [D loss: 0.216063, acc.: 62.50%] [G loss: 0.425019]\n",
      "epoch:6 step:6471 [D loss: 0.221030, acc.: 64.84%] [G loss: 0.522277]\n",
      "epoch:6 step:6472 [D loss: 0.235808, acc.: 57.03%] [G loss: 0.447322]\n",
      "epoch:6 step:6473 [D loss: 0.211161, acc.: 65.62%] [G loss: 0.511136]\n",
      "epoch:6 step:6474 [D loss: 0.197196, acc.: 62.50%] [G loss: 0.506157]\n",
      "epoch:6 step:6475 [D loss: 0.213157, acc.: 65.62%] [G loss: 0.475184]\n",
      "epoch:6 step:6476 [D loss: 0.200966, acc.: 71.88%] [G loss: 0.491703]\n",
      "epoch:6 step:6477 [D loss: 0.216468, acc.: 68.75%] [G loss: 0.501913]\n",
      "epoch:6 step:6478 [D loss: 0.227274, acc.: 60.94%] [G loss: 0.457956]\n",
      "epoch:6 step:6479 [D loss: 0.213794, acc.: 70.31%] [G loss: 0.484761]\n",
      "epoch:6 step:6480 [D loss: 0.245590, acc.: 58.59%] [G loss: 0.464009]\n",
      "epoch:6 step:6481 [D loss: 0.215899, acc.: 64.06%] [G loss: 0.484329]\n",
      "epoch:6 step:6482 [D loss: 0.151475, acc.: 82.03%] [G loss: 0.560080]\n",
      "epoch:6 step:6483 [D loss: 0.254640, acc.: 57.81%] [G loss: 0.446061]\n",
      "epoch:6 step:6484 [D loss: 0.246198, acc.: 60.16%] [G loss: 0.450569]\n",
      "epoch:6 step:6485 [D loss: 0.230411, acc.: 59.38%] [G loss: 0.431535]\n",
      "epoch:6 step:6486 [D loss: 0.245039, acc.: 57.81%] [G loss: 0.419190]\n",
      "epoch:6 step:6487 [D loss: 0.203406, acc.: 68.75%] [G loss: 0.462237]\n",
      "epoch:6 step:6488 [D loss: 0.220444, acc.: 61.72%] [G loss: 0.445264]\n",
      "epoch:6 step:6489 [D loss: 0.237884, acc.: 56.25%] [G loss: 0.503227]\n",
      "epoch:6 step:6490 [D loss: 0.223519, acc.: 62.50%] [G loss: 0.488745]\n",
      "epoch:6 step:6491 [D loss: 0.229936, acc.: 59.38%] [G loss: 0.467802]\n",
      "epoch:6 step:6492 [D loss: 0.196023, acc.: 69.53%] [G loss: 0.475082]\n",
      "epoch:6 step:6493 [D loss: 0.201255, acc.: 69.53%] [G loss: 0.492246]\n",
      "epoch:6 step:6494 [D loss: 0.212571, acc.: 62.50%] [G loss: 0.493990]\n",
      "epoch:6 step:6495 [D loss: 0.208805, acc.: 68.75%] [G loss: 0.493074]\n",
      "epoch:6 step:6496 [D loss: 0.235953, acc.: 61.72%] [G loss: 0.465231]\n",
      "epoch:6 step:6497 [D loss: 0.197579, acc.: 76.56%] [G loss: 0.554469]\n",
      "epoch:6 step:6498 [D loss: 0.236801, acc.: 62.50%] [G loss: 0.508053]\n",
      "epoch:6 step:6499 [D loss: 0.239804, acc.: 59.38%] [G loss: 0.479749]\n",
      "epoch:6 step:6500 [D loss: 0.234627, acc.: 60.16%] [G loss: 0.469779]\n",
      "epoch:6 step:6501 [D loss: 0.220076, acc.: 62.50%] [G loss: 0.513827]\n",
      "epoch:6 step:6502 [D loss: 0.249131, acc.: 54.69%] [G loss: 0.419679]\n",
      "epoch:6 step:6503 [D loss: 0.203476, acc.: 67.19%] [G loss: 0.464131]\n",
      "epoch:6 step:6504 [D loss: 0.211447, acc.: 67.97%] [G loss: 0.461485]\n",
      "epoch:6 step:6505 [D loss: 0.234585, acc.: 59.38%] [G loss: 0.470816]\n",
      "epoch:6 step:6506 [D loss: 0.219022, acc.: 68.75%] [G loss: 0.498181]\n",
      "epoch:6 step:6507 [D loss: 0.210123, acc.: 65.62%] [G loss: 0.510290]\n",
      "epoch:6 step:6508 [D loss: 0.206925, acc.: 67.19%] [G loss: 0.505482]\n",
      "epoch:6 step:6509 [D loss: 0.198468, acc.: 68.75%] [G loss: 0.508790]\n",
      "epoch:6 step:6510 [D loss: 0.181689, acc.: 70.31%] [G loss: 0.514685]\n",
      "epoch:6 step:6511 [D loss: 0.221283, acc.: 60.16%] [G loss: 0.481495]\n",
      "epoch:6 step:6512 [D loss: 0.186448, acc.: 72.66%] [G loss: 0.476811]\n",
      "epoch:6 step:6513 [D loss: 0.238299, acc.: 57.81%] [G loss: 0.486029]\n",
      "epoch:6 step:6514 [D loss: 0.239548, acc.: 59.38%] [G loss: 0.497896]\n",
      "epoch:6 step:6515 [D loss: 0.203485, acc.: 71.09%] [G loss: 0.533175]\n",
      "epoch:6 step:6516 [D loss: 0.198969, acc.: 70.31%] [G loss: 0.528674]\n",
      "epoch:6 step:6517 [D loss: 0.223772, acc.: 62.50%] [G loss: 0.537437]\n",
      "epoch:6 step:6518 [D loss: 0.230728, acc.: 62.50%] [G loss: 0.505354]\n",
      "epoch:6 step:6519 [D loss: 0.179615, acc.: 71.09%] [G loss: 0.505644]\n",
      "epoch:6 step:6520 [D loss: 0.215185, acc.: 65.62%] [G loss: 0.499971]\n",
      "epoch:6 step:6521 [D loss: 0.184067, acc.: 70.31%] [G loss: 0.566836]\n",
      "epoch:6 step:6522 [D loss: 0.213556, acc.: 68.75%] [G loss: 0.525357]\n",
      "epoch:6 step:6523 [D loss: 0.218764, acc.: 66.41%] [G loss: 0.504903]\n",
      "epoch:6 step:6524 [D loss: 0.242315, acc.: 60.16%] [G loss: 0.472980]\n",
      "epoch:6 step:6525 [D loss: 0.211766, acc.: 64.84%] [G loss: 0.491907]\n",
      "epoch:6 step:6526 [D loss: 0.241720, acc.: 59.38%] [G loss: 0.467144]\n",
      "epoch:6 step:6527 [D loss: 0.205742, acc.: 67.19%] [G loss: 0.515647]\n",
      "epoch:6 step:6528 [D loss: 0.217369, acc.: 65.62%] [G loss: 0.518896]\n",
      "epoch:6 step:6529 [D loss: 0.268091, acc.: 56.25%] [G loss: 0.467572]\n",
      "epoch:6 step:6530 [D loss: 0.198690, acc.: 71.88%] [G loss: 0.453447]\n",
      "epoch:6 step:6531 [D loss: 0.189060, acc.: 70.31%] [G loss: 0.471281]\n",
      "epoch:6 step:6532 [D loss: 0.225185, acc.: 60.94%] [G loss: 0.466001]\n",
      "epoch:6 step:6533 [D loss: 0.186365, acc.: 74.22%] [G loss: 0.531447]\n",
      "epoch:6 step:6534 [D loss: 0.144020, acc.: 82.81%] [G loss: 0.557659]\n",
      "epoch:6 step:6535 [D loss: 0.219110, acc.: 69.53%] [G loss: 0.557589]\n",
      "epoch:6 step:6536 [D loss: 0.200367, acc.: 65.62%] [G loss: 0.527960]\n",
      "epoch:6 step:6537 [D loss: 0.257738, acc.: 58.59%] [G loss: 0.481099]\n",
      "epoch:6 step:6538 [D loss: 0.218599, acc.: 64.06%] [G loss: 0.466777]\n",
      "epoch:6 step:6539 [D loss: 0.219533, acc.: 64.84%] [G loss: 0.522501]\n",
      "epoch:6 step:6540 [D loss: 0.196871, acc.: 68.75%] [G loss: 0.559072]\n",
      "epoch:6 step:6541 [D loss: 0.192614, acc.: 67.97%] [G loss: 0.604194]\n",
      "epoch:6 step:6542 [D loss: 0.256549, acc.: 55.47%] [G loss: 0.525517]\n",
      "epoch:6 step:6543 [D loss: 0.192589, acc.: 72.66%] [G loss: 0.527589]\n",
      "epoch:6 step:6544 [D loss: 0.253746, acc.: 55.47%] [G loss: 0.503509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6545 [D loss: 0.175832, acc.: 78.12%] [G loss: 0.571422]\n",
      "epoch:6 step:6546 [D loss: 0.147436, acc.: 82.81%] [G loss: 0.547100]\n",
      "epoch:6 step:6547 [D loss: 0.140766, acc.: 87.50%] [G loss: 0.630518]\n",
      "epoch:6 step:6548 [D loss: 0.165496, acc.: 78.12%] [G loss: 0.663087]\n",
      "epoch:6 step:6549 [D loss: 0.199819, acc.: 69.53%] [G loss: 0.692653]\n",
      "epoch:6 step:6550 [D loss: 0.353374, acc.: 58.59%] [G loss: 0.543650]\n",
      "epoch:6 step:6551 [D loss: 0.164203, acc.: 75.00%] [G loss: 0.596006]\n",
      "epoch:6 step:6552 [D loss: 0.186967, acc.: 73.44%] [G loss: 0.559733]\n",
      "epoch:6 step:6553 [D loss: 0.203891, acc.: 67.19%] [G loss: 0.526718]\n",
      "epoch:6 step:6554 [D loss: 0.220431, acc.: 64.84%] [G loss: 0.471695]\n",
      "epoch:6 step:6555 [D loss: 0.214336, acc.: 69.53%] [G loss: 0.528116]\n",
      "epoch:6 step:6556 [D loss: 0.188369, acc.: 75.78%] [G loss: 0.578818]\n",
      "epoch:6 step:6557 [D loss: 0.186616, acc.: 71.09%] [G loss: 0.549382]\n",
      "epoch:6 step:6558 [D loss: 0.162333, acc.: 76.56%] [G loss: 0.608943]\n",
      "epoch:6 step:6559 [D loss: 0.124805, acc.: 85.16%] [G loss: 0.648565]\n",
      "epoch:7 step:6560 [D loss: 0.281143, acc.: 54.69%] [G loss: 0.575637]\n",
      "epoch:7 step:6561 [D loss: 0.232881, acc.: 63.28%] [G loss: 0.504290]\n",
      "epoch:7 step:6562 [D loss: 0.242355, acc.: 59.38%] [G loss: 0.550575]\n",
      "epoch:7 step:6563 [D loss: 0.230294, acc.: 63.28%] [G loss: 0.510039]\n",
      "epoch:7 step:6564 [D loss: 0.208859, acc.: 62.50%] [G loss: 0.511349]\n",
      "epoch:7 step:6565 [D loss: 0.203240, acc.: 72.66%] [G loss: 0.555897]\n",
      "epoch:7 step:6566 [D loss: 0.184736, acc.: 77.34%] [G loss: 0.558440]\n",
      "epoch:7 step:6567 [D loss: 0.231893, acc.: 60.16%] [G loss: 0.451001]\n",
      "epoch:7 step:6568 [D loss: 0.172761, acc.: 71.88%] [G loss: 0.536044]\n",
      "epoch:7 step:6569 [D loss: 0.200616, acc.: 65.62%] [G loss: 0.555457]\n",
      "epoch:7 step:6570 [D loss: 0.188473, acc.: 66.41%] [G loss: 0.575538]\n",
      "epoch:7 step:6571 [D loss: 0.219380, acc.: 64.84%] [G loss: 0.543003]\n",
      "epoch:7 step:6572 [D loss: 0.229929, acc.: 57.81%] [G loss: 0.514110]\n",
      "epoch:7 step:6573 [D loss: 0.198156, acc.: 71.09%] [G loss: 0.542003]\n",
      "epoch:7 step:6574 [D loss: 0.197014, acc.: 68.75%] [G loss: 0.483242]\n",
      "epoch:7 step:6575 [D loss: 0.187605, acc.: 71.88%] [G loss: 0.504695]\n",
      "epoch:7 step:6576 [D loss: 0.277732, acc.: 48.44%] [G loss: 0.472683]\n",
      "epoch:7 step:6577 [D loss: 0.262411, acc.: 53.91%] [G loss: 0.534728]\n",
      "epoch:7 step:6578 [D loss: 0.226617, acc.: 61.72%] [G loss: 0.501764]\n",
      "epoch:7 step:6579 [D loss: 0.268720, acc.: 50.78%] [G loss: 0.477004]\n",
      "epoch:7 step:6580 [D loss: 0.201966, acc.: 71.88%] [G loss: 0.534710]\n",
      "epoch:7 step:6581 [D loss: 0.214130, acc.: 68.75%] [G loss: 0.471344]\n",
      "epoch:7 step:6582 [D loss: 0.195367, acc.: 71.88%] [G loss: 0.480152]\n",
      "epoch:7 step:6583 [D loss: 0.211346, acc.: 66.41%] [G loss: 0.494896]\n",
      "epoch:7 step:6584 [D loss: 0.213384, acc.: 60.94%] [G loss: 0.503237]\n",
      "epoch:7 step:6585 [D loss: 0.240820, acc.: 61.72%] [G loss: 0.494120]\n",
      "epoch:7 step:6586 [D loss: 0.220888, acc.: 64.06%] [G loss: 0.460309]\n",
      "epoch:7 step:6587 [D loss: 0.232101, acc.: 55.47%] [G loss: 0.463580]\n",
      "epoch:7 step:6588 [D loss: 0.199282, acc.: 67.97%] [G loss: 0.479930]\n",
      "epoch:7 step:6589 [D loss: 0.210916, acc.: 65.62%] [G loss: 0.459829]\n",
      "epoch:7 step:6590 [D loss: 0.232536, acc.: 61.72%] [G loss: 0.437157]\n",
      "epoch:7 step:6591 [D loss: 0.206861, acc.: 70.31%] [G loss: 0.489602]\n",
      "epoch:7 step:6592 [D loss: 0.227055, acc.: 63.28%] [G loss: 0.463052]\n",
      "epoch:7 step:6593 [D loss: 0.230787, acc.: 64.84%] [G loss: 0.458064]\n",
      "epoch:7 step:6594 [D loss: 0.221491, acc.: 61.72%] [G loss: 0.482774]\n",
      "epoch:7 step:6595 [D loss: 0.200723, acc.: 70.31%] [G loss: 0.480374]\n",
      "epoch:7 step:6596 [D loss: 0.231113, acc.: 62.50%] [G loss: 0.483873]\n",
      "epoch:7 step:6597 [D loss: 0.231845, acc.: 58.59%] [G loss: 0.467578]\n",
      "epoch:7 step:6598 [D loss: 0.206632, acc.: 71.88%] [G loss: 0.463967]\n",
      "epoch:7 step:6599 [D loss: 0.168948, acc.: 74.22%] [G loss: 0.554119]\n",
      "epoch:7 step:6600 [D loss: 0.230910, acc.: 63.28%] [G loss: 0.549590]\n",
      "epoch:7 step:6601 [D loss: 0.212909, acc.: 64.84%] [G loss: 0.535281]\n",
      "epoch:7 step:6602 [D loss: 0.189938, acc.: 71.09%] [G loss: 0.493043]\n",
      "epoch:7 step:6603 [D loss: 0.253647, acc.: 57.03%] [G loss: 0.425798]\n",
      "epoch:7 step:6604 [D loss: 0.218389, acc.: 61.72%] [G loss: 0.524332]\n",
      "epoch:7 step:6605 [D loss: 0.235396, acc.: 60.94%] [G loss: 0.460520]\n",
      "epoch:7 step:6606 [D loss: 0.196271, acc.: 73.44%] [G loss: 0.490763]\n",
      "epoch:7 step:6607 [D loss: 0.217127, acc.: 62.50%] [G loss: 0.493695]\n",
      "epoch:7 step:6608 [D loss: 0.193325, acc.: 68.75%] [G loss: 0.545284]\n",
      "epoch:7 step:6609 [D loss: 0.207092, acc.: 64.84%] [G loss: 0.496295]\n",
      "epoch:7 step:6610 [D loss: 0.230675, acc.: 62.50%] [G loss: 0.470081]\n",
      "epoch:7 step:6611 [D loss: 0.215914, acc.: 60.16%] [G loss: 0.439663]\n",
      "epoch:7 step:6612 [D loss: 0.212741, acc.: 65.62%] [G loss: 0.531613]\n",
      "epoch:7 step:6613 [D loss: 0.180040, acc.: 69.53%] [G loss: 0.495000]\n",
      "epoch:7 step:6614 [D loss: 0.198462, acc.: 71.09%] [G loss: 0.492110]\n",
      "epoch:7 step:6615 [D loss: 0.206762, acc.: 67.97%] [G loss: 0.484664]\n",
      "epoch:7 step:6616 [D loss: 0.183567, acc.: 72.66%] [G loss: 0.526891]\n",
      "epoch:7 step:6617 [D loss: 0.209996, acc.: 67.19%] [G loss: 0.544885]\n",
      "epoch:7 step:6618 [D loss: 0.196445, acc.: 71.88%] [G loss: 0.542919]\n",
      "epoch:7 step:6619 [D loss: 0.247273, acc.: 57.81%] [G loss: 0.487796]\n",
      "epoch:7 step:6620 [D loss: 0.215237, acc.: 69.53%] [G loss: 0.515315]\n",
      "epoch:7 step:6621 [D loss: 0.221224, acc.: 66.41%] [G loss: 0.488401]\n",
      "epoch:7 step:6622 [D loss: 0.214636, acc.: 64.84%] [G loss: 0.490233]\n",
      "epoch:7 step:6623 [D loss: 0.215548, acc.: 65.62%] [G loss: 0.525306]\n",
      "epoch:7 step:6624 [D loss: 0.200643, acc.: 66.41%] [G loss: 0.524612]\n",
      "epoch:7 step:6625 [D loss: 0.205415, acc.: 64.84%] [G loss: 0.497191]\n",
      "epoch:7 step:6626 [D loss: 0.239376, acc.: 63.28%] [G loss: 0.459866]\n",
      "epoch:7 step:6627 [D loss: 0.188119, acc.: 71.09%] [G loss: 0.487697]\n",
      "epoch:7 step:6628 [D loss: 0.208540, acc.: 68.75%] [G loss: 0.499997]\n",
      "epoch:7 step:6629 [D loss: 0.186684, acc.: 71.88%] [G loss: 0.506584]\n",
      "epoch:7 step:6630 [D loss: 0.221618, acc.: 64.84%] [G loss: 0.492094]\n",
      "epoch:7 step:6631 [D loss: 0.232853, acc.: 59.38%] [G loss: 0.448633]\n",
      "epoch:7 step:6632 [D loss: 0.219740, acc.: 66.41%] [G loss: 0.504867]\n",
      "epoch:7 step:6633 [D loss: 0.203224, acc.: 67.97%] [G loss: 0.502495]\n",
      "epoch:7 step:6634 [D loss: 0.212629, acc.: 66.41%] [G loss: 0.546770]\n",
      "epoch:7 step:6635 [D loss: 0.184876, acc.: 73.44%] [G loss: 0.579759]\n",
      "epoch:7 step:6636 [D loss: 0.192823, acc.: 71.88%] [G loss: 0.589294]\n",
      "epoch:7 step:6637 [D loss: 0.275100, acc.: 58.59%] [G loss: 0.460790]\n",
      "epoch:7 step:6638 [D loss: 0.217762, acc.: 65.62%] [G loss: 0.456547]\n",
      "epoch:7 step:6639 [D loss: 0.221859, acc.: 64.06%] [G loss: 0.489193]\n",
      "epoch:7 step:6640 [D loss: 0.229286, acc.: 60.94%] [G loss: 0.526553]\n",
      "epoch:7 step:6641 [D loss: 0.220303, acc.: 71.09%] [G loss: 0.480834]\n",
      "epoch:7 step:6642 [D loss: 0.200933, acc.: 70.31%] [G loss: 0.524194]\n",
      "epoch:7 step:6643 [D loss: 0.205202, acc.: 68.75%] [G loss: 0.523100]\n",
      "epoch:7 step:6644 [D loss: 0.209597, acc.: 69.53%] [G loss: 0.525335]\n",
      "epoch:7 step:6645 [D loss: 0.232499, acc.: 60.16%] [G loss: 0.511377]\n",
      "epoch:7 step:6646 [D loss: 0.227860, acc.: 64.06%] [G loss: 0.444988]\n",
      "epoch:7 step:6647 [D loss: 0.206383, acc.: 67.97%] [G loss: 0.491128]\n",
      "epoch:7 step:6648 [D loss: 0.188281, acc.: 71.88%] [G loss: 0.528902]\n",
      "epoch:7 step:6649 [D loss: 0.211267, acc.: 69.53%] [G loss: 0.472957]\n",
      "epoch:7 step:6650 [D loss: 0.209852, acc.: 67.97%] [G loss: 0.475083]\n",
      "epoch:7 step:6651 [D loss: 0.179178, acc.: 72.66%] [G loss: 0.514724]\n",
      "epoch:7 step:6652 [D loss: 0.198564, acc.: 66.41%] [G loss: 0.517096]\n",
      "epoch:7 step:6653 [D loss: 0.220018, acc.: 61.72%] [G loss: 0.497150]\n",
      "epoch:7 step:6654 [D loss: 0.204684, acc.: 64.84%] [G loss: 0.536063]\n",
      "epoch:7 step:6655 [D loss: 0.206450, acc.: 66.41%] [G loss: 0.522221]\n",
      "epoch:7 step:6656 [D loss: 0.185146, acc.: 73.44%] [G loss: 0.525330]\n",
      "epoch:7 step:6657 [D loss: 0.218814, acc.: 65.62%] [G loss: 0.500682]\n",
      "epoch:7 step:6658 [D loss: 0.237437, acc.: 60.16%] [G loss: 0.468614]\n",
      "epoch:7 step:6659 [D loss: 0.175923, acc.: 70.31%] [G loss: 0.535657]\n",
      "epoch:7 step:6660 [D loss: 0.180933, acc.: 71.09%] [G loss: 0.536630]\n",
      "epoch:7 step:6661 [D loss: 0.224061, acc.: 64.06%] [G loss: 0.486335]\n",
      "epoch:7 step:6662 [D loss: 0.204931, acc.: 71.09%] [G loss: 0.498361]\n",
      "epoch:7 step:6663 [D loss: 0.200489, acc.: 65.62%] [G loss: 0.539490]\n",
      "epoch:7 step:6664 [D loss: 0.232466, acc.: 62.50%] [G loss: 0.489162]\n",
      "epoch:7 step:6665 [D loss: 0.227003, acc.: 60.94%] [G loss: 0.475626]\n",
      "epoch:7 step:6666 [D loss: 0.177695, acc.: 77.34%] [G loss: 0.529704]\n",
      "epoch:7 step:6667 [D loss: 0.290304, acc.: 50.78%] [G loss: 0.476327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6668 [D loss: 0.245333, acc.: 58.59%] [G loss: 0.474223]\n",
      "epoch:7 step:6669 [D loss: 0.210158, acc.: 64.06%] [G loss: 0.460929]\n",
      "epoch:7 step:6670 [D loss: 0.214015, acc.: 70.31%] [G loss: 0.460649]\n",
      "epoch:7 step:6671 [D loss: 0.196712, acc.: 72.66%] [G loss: 0.490982]\n",
      "epoch:7 step:6672 [D loss: 0.202950, acc.: 69.53%] [G loss: 0.497392]\n",
      "epoch:7 step:6673 [D loss: 0.216636, acc.: 70.31%] [G loss: 0.525445]\n",
      "epoch:7 step:6674 [D loss: 0.207537, acc.: 67.19%] [G loss: 0.555668]\n",
      "epoch:7 step:6675 [D loss: 0.211695, acc.: 67.19%] [G loss: 0.519985]\n",
      "epoch:7 step:6676 [D loss: 0.203750, acc.: 66.41%] [G loss: 0.523480]\n",
      "epoch:7 step:6677 [D loss: 0.224333, acc.: 60.16%] [G loss: 0.475252]\n",
      "epoch:7 step:6678 [D loss: 0.177096, acc.: 75.00%] [G loss: 0.579620]\n",
      "epoch:7 step:6679 [D loss: 0.251380, acc.: 60.16%] [G loss: 0.530460]\n",
      "epoch:7 step:6680 [D loss: 0.201794, acc.: 71.88%] [G loss: 0.503071]\n",
      "epoch:7 step:6681 [D loss: 0.161390, acc.: 78.12%] [G loss: 0.528900]\n",
      "epoch:7 step:6682 [D loss: 0.208964, acc.: 67.19%] [G loss: 0.520774]\n",
      "epoch:7 step:6683 [D loss: 0.227583, acc.: 60.94%] [G loss: 0.528236]\n",
      "epoch:7 step:6684 [D loss: 0.204069, acc.: 68.75%] [G loss: 0.506466]\n",
      "epoch:7 step:6685 [D loss: 0.193002, acc.: 67.97%] [G loss: 0.502767]\n",
      "epoch:7 step:6686 [D loss: 0.236775, acc.: 64.84%] [G loss: 0.469098]\n",
      "epoch:7 step:6687 [D loss: 0.233694, acc.: 60.16%] [G loss: 0.465002]\n",
      "epoch:7 step:6688 [D loss: 0.218982, acc.: 65.62%] [G loss: 0.472141]\n",
      "epoch:7 step:6689 [D loss: 0.176462, acc.: 77.34%] [G loss: 0.541747]\n",
      "epoch:7 step:6690 [D loss: 0.222155, acc.: 61.72%] [G loss: 0.509831]\n",
      "epoch:7 step:6691 [D loss: 0.186363, acc.: 72.66%] [G loss: 0.512610]\n",
      "epoch:7 step:6692 [D loss: 0.235655, acc.: 59.38%] [G loss: 0.516163]\n",
      "epoch:7 step:6693 [D loss: 0.214144, acc.: 67.97%] [G loss: 0.528529]\n",
      "epoch:7 step:6694 [D loss: 0.235854, acc.: 64.06%] [G loss: 0.499923]\n",
      "epoch:7 step:6695 [D loss: 0.264225, acc.: 60.94%] [G loss: 0.482493]\n",
      "epoch:7 step:6696 [D loss: 0.256018, acc.: 57.81%] [G loss: 0.442478]\n",
      "epoch:7 step:6697 [D loss: 0.221453, acc.: 64.06%] [G loss: 0.407133]\n",
      "epoch:7 step:6698 [D loss: 0.229537, acc.: 61.72%] [G loss: 0.457801]\n",
      "epoch:7 step:6699 [D loss: 0.202939, acc.: 69.53%] [G loss: 0.454683]\n",
      "epoch:7 step:6700 [D loss: 0.242753, acc.: 62.50%] [G loss: 0.441620]\n",
      "epoch:7 step:6701 [D loss: 0.212252, acc.: 66.41%] [G loss: 0.487492]\n",
      "epoch:7 step:6702 [D loss: 0.223058, acc.: 63.28%] [G loss: 0.477428]\n",
      "epoch:7 step:6703 [D loss: 0.228569, acc.: 64.84%] [G loss: 0.493602]\n",
      "epoch:7 step:6704 [D loss: 0.229977, acc.: 60.94%] [G loss: 0.514855]\n",
      "epoch:7 step:6705 [D loss: 0.231801, acc.: 61.72%] [G loss: 0.499494]\n",
      "epoch:7 step:6706 [D loss: 0.214294, acc.: 60.16%] [G loss: 0.478038]\n",
      "epoch:7 step:6707 [D loss: 0.221813, acc.: 64.06%] [G loss: 0.442206]\n",
      "epoch:7 step:6708 [D loss: 0.198989, acc.: 69.53%] [G loss: 0.456098]\n",
      "epoch:7 step:6709 [D loss: 0.237747, acc.: 63.28%] [G loss: 0.489623]\n",
      "epoch:7 step:6710 [D loss: 0.251726, acc.: 60.16%] [G loss: 0.507491]\n",
      "epoch:7 step:6711 [D loss: 0.190129, acc.: 68.75%] [G loss: 0.547789]\n",
      "epoch:7 step:6712 [D loss: 0.245031, acc.: 59.38%] [G loss: 0.475411]\n",
      "epoch:7 step:6713 [D loss: 0.225834, acc.: 68.75%] [G loss: 0.511697]\n",
      "epoch:7 step:6714 [D loss: 0.216945, acc.: 64.84%] [G loss: 0.482477]\n",
      "epoch:7 step:6715 [D loss: 0.189118, acc.: 71.09%] [G loss: 0.527622]\n",
      "epoch:7 step:6716 [D loss: 0.227015, acc.: 66.41%] [G loss: 0.542328]\n",
      "epoch:7 step:6717 [D loss: 0.212735, acc.: 67.19%] [G loss: 0.501911]\n",
      "epoch:7 step:6718 [D loss: 0.212541, acc.: 65.62%] [G loss: 0.480889]\n",
      "epoch:7 step:6719 [D loss: 0.294455, acc.: 51.56%] [G loss: 0.499520]\n",
      "epoch:7 step:6720 [D loss: 0.210618, acc.: 68.75%] [G loss: 0.539712]\n",
      "epoch:7 step:6721 [D loss: 0.211080, acc.: 71.88%] [G loss: 0.521461]\n",
      "epoch:7 step:6722 [D loss: 0.251446, acc.: 63.28%] [G loss: 0.500210]\n",
      "epoch:7 step:6723 [D loss: 0.219272, acc.: 64.06%] [G loss: 0.459902]\n",
      "epoch:7 step:6724 [D loss: 0.223261, acc.: 69.53%] [G loss: 0.490429]\n",
      "epoch:7 step:6725 [D loss: 0.233921, acc.: 62.50%] [G loss: 0.407564]\n",
      "epoch:7 step:6726 [D loss: 0.205198, acc.: 70.31%] [G loss: 0.488760]\n",
      "epoch:7 step:6727 [D loss: 0.212784, acc.: 65.62%] [G loss: 0.432245]\n",
      "epoch:7 step:6728 [D loss: 0.243881, acc.: 55.47%] [G loss: 0.498485]\n",
      "epoch:7 step:6729 [D loss: 0.258963, acc.: 53.91%] [G loss: 0.452053]\n",
      "epoch:7 step:6730 [D loss: 0.210823, acc.: 64.06%] [G loss: 0.519123]\n",
      "epoch:7 step:6731 [D loss: 0.234605, acc.: 60.94%] [G loss: 0.475853]\n",
      "epoch:7 step:6732 [D loss: 0.183049, acc.: 73.44%] [G loss: 0.516777]\n",
      "epoch:7 step:6733 [D loss: 0.254572, acc.: 57.03%] [G loss: 0.458361]\n",
      "epoch:7 step:6734 [D loss: 0.214013, acc.: 63.28%] [G loss: 0.457138]\n",
      "epoch:7 step:6735 [D loss: 0.216504, acc.: 66.41%] [G loss: 0.477065]\n",
      "epoch:7 step:6736 [D loss: 0.226805, acc.: 64.84%] [G loss: 0.443884]\n",
      "epoch:7 step:6737 [D loss: 0.228606, acc.: 63.28%] [G loss: 0.499559]\n",
      "epoch:7 step:6738 [D loss: 0.185762, acc.: 75.00%] [G loss: 0.499155]\n",
      "epoch:7 step:6739 [D loss: 0.215778, acc.: 67.19%] [G loss: 0.509722]\n",
      "epoch:7 step:6740 [D loss: 0.222419, acc.: 63.28%] [G loss: 0.449225]\n",
      "epoch:7 step:6741 [D loss: 0.245296, acc.: 56.25%] [G loss: 0.439779]\n",
      "epoch:7 step:6742 [D loss: 0.249773, acc.: 64.06%] [G loss: 0.499908]\n",
      "epoch:7 step:6743 [D loss: 0.227075, acc.: 67.97%] [G loss: 0.469884]\n",
      "epoch:7 step:6744 [D loss: 0.227007, acc.: 64.06%] [G loss: 0.492012]\n",
      "epoch:7 step:6745 [D loss: 0.231650, acc.: 65.62%] [G loss: 0.503053]\n",
      "epoch:7 step:6746 [D loss: 0.230733, acc.: 60.94%] [G loss: 0.467399]\n",
      "epoch:7 step:6747 [D loss: 0.260235, acc.: 59.38%] [G loss: 0.485482]\n",
      "epoch:7 step:6748 [D loss: 0.228305, acc.: 62.50%] [G loss: 0.445769]\n",
      "epoch:7 step:6749 [D loss: 0.182243, acc.: 74.22%] [G loss: 0.473124]\n",
      "epoch:7 step:6750 [D loss: 0.211674, acc.: 66.41%] [G loss: 0.476775]\n",
      "epoch:7 step:6751 [D loss: 0.211628, acc.: 65.62%] [G loss: 0.502725]\n",
      "epoch:7 step:6752 [D loss: 0.217208, acc.: 68.75%] [G loss: 0.491991]\n",
      "epoch:7 step:6753 [D loss: 0.199006, acc.: 70.31%] [G loss: 0.503985]\n",
      "epoch:7 step:6754 [D loss: 0.191705, acc.: 67.19%] [G loss: 0.536664]\n",
      "epoch:7 step:6755 [D loss: 0.230855, acc.: 66.41%] [G loss: 0.437622]\n",
      "epoch:7 step:6756 [D loss: 0.203862, acc.: 67.97%] [G loss: 0.475406]\n",
      "epoch:7 step:6757 [D loss: 0.197535, acc.: 75.78%] [G loss: 0.515136]\n",
      "epoch:7 step:6758 [D loss: 0.214719, acc.: 64.84%] [G loss: 0.543489]\n",
      "epoch:7 step:6759 [D loss: 0.248629, acc.: 59.38%] [G loss: 0.460834]\n",
      "epoch:7 step:6760 [D loss: 0.248799, acc.: 56.25%] [G loss: 0.534574]\n",
      "epoch:7 step:6761 [D loss: 0.225193, acc.: 62.50%] [G loss: 0.524027]\n",
      "epoch:7 step:6762 [D loss: 0.272043, acc.: 50.78%] [G loss: 0.534869]\n",
      "epoch:7 step:6763 [D loss: 0.218573, acc.: 63.28%] [G loss: 0.519294]\n",
      "epoch:7 step:6764 [D loss: 0.182434, acc.: 75.78%] [G loss: 0.539717]\n",
      "epoch:7 step:6765 [D loss: 0.198453, acc.: 71.88%] [G loss: 0.478196]\n",
      "epoch:7 step:6766 [D loss: 0.177335, acc.: 73.44%] [G loss: 0.494253]\n",
      "epoch:7 step:6767 [D loss: 0.179825, acc.: 71.88%] [G loss: 0.525770]\n",
      "epoch:7 step:6768 [D loss: 0.185361, acc.: 70.31%] [G loss: 0.517629]\n",
      "epoch:7 step:6769 [D loss: 0.249067, acc.: 58.59%] [G loss: 0.466598]\n",
      "epoch:7 step:6770 [D loss: 0.241582, acc.: 54.69%] [G loss: 0.439759]\n",
      "epoch:7 step:6771 [D loss: 0.213371, acc.: 69.53%] [G loss: 0.445534]\n",
      "epoch:7 step:6772 [D loss: 0.217508, acc.: 67.97%] [G loss: 0.425876]\n",
      "epoch:7 step:6773 [D loss: 0.223727, acc.: 63.28%] [G loss: 0.469200]\n",
      "epoch:7 step:6774 [D loss: 0.221722, acc.: 60.16%] [G loss: 0.473432]\n",
      "epoch:7 step:6775 [D loss: 0.242774, acc.: 57.81%] [G loss: 0.464131]\n",
      "epoch:7 step:6776 [D loss: 0.180441, acc.: 76.56%] [G loss: 0.551915]\n",
      "epoch:7 step:6777 [D loss: 0.191007, acc.: 70.31%] [G loss: 0.514816]\n",
      "epoch:7 step:6778 [D loss: 0.194517, acc.: 65.62%] [G loss: 0.513384]\n",
      "epoch:7 step:6779 [D loss: 0.281331, acc.: 52.34%] [G loss: 0.429639]\n",
      "epoch:7 step:6780 [D loss: 0.191963, acc.: 71.09%] [G loss: 0.521089]\n",
      "epoch:7 step:6781 [D loss: 0.200585, acc.: 67.97%] [G loss: 0.528693]\n",
      "epoch:7 step:6782 [D loss: 0.203882, acc.: 71.09%] [G loss: 0.550367]\n",
      "epoch:7 step:6783 [D loss: 0.259869, acc.: 57.81%] [G loss: 0.458071]\n",
      "epoch:7 step:6784 [D loss: 0.260946, acc.: 57.03%] [G loss: 0.480944]\n",
      "epoch:7 step:6785 [D loss: 0.247621, acc.: 56.25%] [G loss: 0.429188]\n",
      "epoch:7 step:6786 [D loss: 0.223407, acc.: 62.50%] [G loss: 0.487934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6787 [D loss: 0.231004, acc.: 60.94%] [G loss: 0.470345]\n",
      "epoch:7 step:6788 [D loss: 0.201783, acc.: 69.53%] [G loss: 0.455026]\n",
      "epoch:7 step:6789 [D loss: 0.184589, acc.: 70.31%] [G loss: 0.494526]\n",
      "epoch:7 step:6790 [D loss: 0.174284, acc.: 72.66%] [G loss: 0.556913]\n",
      "epoch:7 step:6791 [D loss: 0.180861, acc.: 71.88%] [G loss: 0.557244]\n",
      "epoch:7 step:6792 [D loss: 0.281837, acc.: 59.38%] [G loss: 0.495440]\n",
      "epoch:7 step:6793 [D loss: 0.239807, acc.: 60.94%] [G loss: 0.463958]\n",
      "epoch:7 step:6794 [D loss: 0.257328, acc.: 52.34%] [G loss: 0.486520]\n",
      "epoch:7 step:6795 [D loss: 0.200543, acc.: 75.00%] [G loss: 0.467847]\n",
      "epoch:7 step:6796 [D loss: 0.245046, acc.: 58.59%] [G loss: 0.449006]\n",
      "epoch:7 step:6797 [D loss: 0.225044, acc.: 64.84%] [G loss: 0.493973]\n",
      "epoch:7 step:6798 [D loss: 0.211101, acc.: 64.84%] [G loss: 0.461090]\n",
      "epoch:7 step:6799 [D loss: 0.226735, acc.: 62.50%] [G loss: 0.460725]\n",
      "epoch:7 step:6800 [D loss: 0.207187, acc.: 66.41%] [G loss: 0.457254]\n",
      "epoch:7 step:6801 [D loss: 0.185636, acc.: 72.66%] [G loss: 0.521051]\n",
      "epoch:7 step:6802 [D loss: 0.198310, acc.: 67.19%] [G loss: 0.536828]\n",
      "epoch:7 step:6803 [D loss: 0.195021, acc.: 66.41%] [G loss: 0.518079]\n",
      "epoch:7 step:6804 [D loss: 0.200947, acc.: 66.41%] [G loss: 0.510799]\n",
      "epoch:7 step:6805 [D loss: 0.234929, acc.: 59.38%] [G loss: 0.471887]\n",
      "epoch:7 step:6806 [D loss: 0.218235, acc.: 69.53%] [G loss: 0.464367]\n",
      "epoch:7 step:6807 [D loss: 0.220077, acc.: 65.62%] [G loss: 0.524186]\n",
      "epoch:7 step:6808 [D loss: 0.207594, acc.: 71.88%] [G loss: 0.524239]\n",
      "epoch:7 step:6809 [D loss: 0.241213, acc.: 64.06%] [G loss: 0.499066]\n",
      "epoch:7 step:6810 [D loss: 0.210404, acc.: 66.41%] [G loss: 0.474040]\n",
      "epoch:7 step:6811 [D loss: 0.212786, acc.: 64.84%] [G loss: 0.456073]\n",
      "epoch:7 step:6812 [D loss: 0.178681, acc.: 75.00%] [G loss: 0.525643]\n",
      "epoch:7 step:6813 [D loss: 0.215052, acc.: 67.97%] [G loss: 0.437099]\n",
      "epoch:7 step:6814 [D loss: 0.225558, acc.: 63.28%] [G loss: 0.460872]\n",
      "epoch:7 step:6815 [D loss: 0.193957, acc.: 67.97%] [G loss: 0.545900]\n",
      "epoch:7 step:6816 [D loss: 0.232792, acc.: 60.94%] [G loss: 0.482497]\n",
      "epoch:7 step:6817 [D loss: 0.209666, acc.: 66.41%] [G loss: 0.490214]\n",
      "epoch:7 step:6818 [D loss: 0.168116, acc.: 78.12%] [G loss: 0.528534]\n",
      "epoch:7 step:6819 [D loss: 0.213164, acc.: 69.53%] [G loss: 0.483173]\n",
      "epoch:7 step:6820 [D loss: 0.236954, acc.: 58.59%] [G loss: 0.497592]\n",
      "epoch:7 step:6821 [D loss: 0.235021, acc.: 58.59%] [G loss: 0.490824]\n",
      "epoch:7 step:6822 [D loss: 0.231798, acc.: 63.28%] [G loss: 0.462392]\n",
      "epoch:7 step:6823 [D loss: 0.189340, acc.: 73.44%] [G loss: 0.539939]\n",
      "epoch:7 step:6824 [D loss: 0.265126, acc.: 55.47%] [G loss: 0.444785]\n",
      "epoch:7 step:6825 [D loss: 0.196109, acc.: 69.53%] [G loss: 0.495135]\n",
      "epoch:7 step:6826 [D loss: 0.226147, acc.: 64.06%] [G loss: 0.418764]\n",
      "epoch:7 step:6827 [D loss: 0.208663, acc.: 64.84%] [G loss: 0.475400]\n",
      "epoch:7 step:6828 [D loss: 0.225334, acc.: 65.62%] [G loss: 0.503867]\n",
      "epoch:7 step:6829 [D loss: 0.181805, acc.: 71.88%] [G loss: 0.499363]\n",
      "epoch:7 step:6830 [D loss: 0.189028, acc.: 73.44%] [G loss: 0.509421]\n",
      "epoch:7 step:6831 [D loss: 0.202591, acc.: 67.19%] [G loss: 0.558737]\n",
      "epoch:7 step:6832 [D loss: 0.212285, acc.: 67.19%] [G loss: 0.449894]\n",
      "epoch:7 step:6833 [D loss: 0.211340, acc.: 71.88%] [G loss: 0.456156]\n",
      "epoch:7 step:6834 [D loss: 0.218480, acc.: 64.84%] [G loss: 0.480954]\n",
      "epoch:7 step:6835 [D loss: 0.231061, acc.: 59.38%] [G loss: 0.469889]\n",
      "epoch:7 step:6836 [D loss: 0.223162, acc.: 64.06%] [G loss: 0.490604]\n",
      "epoch:7 step:6837 [D loss: 0.224299, acc.: 64.84%] [G loss: 0.492004]\n",
      "epoch:7 step:6838 [D loss: 0.201482, acc.: 66.41%] [G loss: 0.483506]\n",
      "epoch:7 step:6839 [D loss: 0.213548, acc.: 65.62%] [G loss: 0.524172]\n",
      "epoch:7 step:6840 [D loss: 0.254753, acc.: 51.56%] [G loss: 0.458367]\n",
      "epoch:7 step:6841 [D loss: 0.214698, acc.: 70.31%] [G loss: 0.475420]\n",
      "epoch:7 step:6842 [D loss: 0.199950, acc.: 70.31%] [G loss: 0.525401]\n",
      "epoch:7 step:6843 [D loss: 0.227006, acc.: 60.94%] [G loss: 0.482301]\n",
      "epoch:7 step:6844 [D loss: 0.200843, acc.: 74.22%] [G loss: 0.527808]\n",
      "epoch:7 step:6845 [D loss: 0.232266, acc.: 71.88%] [G loss: 0.489076]\n",
      "epoch:7 step:6846 [D loss: 0.224507, acc.: 64.84%] [G loss: 0.522787]\n",
      "epoch:7 step:6847 [D loss: 0.249086, acc.: 57.81%] [G loss: 0.522473]\n",
      "epoch:7 step:6848 [D loss: 0.198586, acc.: 70.31%] [G loss: 0.549332]\n",
      "epoch:7 step:6849 [D loss: 0.212665, acc.: 68.75%] [G loss: 0.454811]\n",
      "epoch:7 step:6850 [D loss: 0.205177, acc.: 70.31%] [G loss: 0.408952]\n",
      "epoch:7 step:6851 [D loss: 0.232149, acc.: 55.47%] [G loss: 0.494297]\n",
      "epoch:7 step:6852 [D loss: 0.203609, acc.: 67.19%] [G loss: 0.536383]\n",
      "epoch:7 step:6853 [D loss: 0.223240, acc.: 59.38%] [G loss: 0.449314]\n",
      "epoch:7 step:6854 [D loss: 0.243386, acc.: 58.59%] [G loss: 0.430733]\n",
      "epoch:7 step:6855 [D loss: 0.185773, acc.: 73.44%] [G loss: 0.510898]\n",
      "epoch:7 step:6856 [D loss: 0.210383, acc.: 65.62%] [G loss: 0.541325]\n",
      "epoch:7 step:6857 [D loss: 0.200062, acc.: 70.31%] [G loss: 0.531042]\n",
      "epoch:7 step:6858 [D loss: 0.192090, acc.: 71.09%] [G loss: 0.486637]\n",
      "epoch:7 step:6859 [D loss: 0.199025, acc.: 70.31%] [G loss: 0.532956]\n",
      "epoch:7 step:6860 [D loss: 0.271229, acc.: 58.59%] [G loss: 0.479466]\n",
      "epoch:7 step:6861 [D loss: 0.216387, acc.: 64.84%] [G loss: 0.466262]\n",
      "epoch:7 step:6862 [D loss: 0.206032, acc.: 66.41%] [G loss: 0.491848]\n",
      "epoch:7 step:6863 [D loss: 0.192392, acc.: 69.53%] [G loss: 0.514117]\n",
      "epoch:7 step:6864 [D loss: 0.216081, acc.: 64.84%] [G loss: 0.467427]\n",
      "epoch:7 step:6865 [D loss: 0.209972, acc.: 67.19%] [G loss: 0.513133]\n",
      "epoch:7 step:6866 [D loss: 0.211365, acc.: 70.31%] [G loss: 0.508775]\n",
      "epoch:7 step:6867 [D loss: 0.228297, acc.: 65.62%] [G loss: 0.496302]\n",
      "epoch:7 step:6868 [D loss: 0.184810, acc.: 71.88%] [G loss: 0.477984]\n",
      "epoch:7 step:6869 [D loss: 0.191553, acc.: 71.88%] [G loss: 0.491008]\n",
      "epoch:7 step:6870 [D loss: 0.182684, acc.: 73.44%] [G loss: 0.524798]\n",
      "epoch:7 step:6871 [D loss: 0.193391, acc.: 70.31%] [G loss: 0.519693]\n",
      "epoch:7 step:6872 [D loss: 0.149671, acc.: 75.00%] [G loss: 0.629021]\n",
      "epoch:7 step:6873 [D loss: 0.162396, acc.: 78.12%] [G loss: 0.537500]\n",
      "epoch:7 step:6874 [D loss: 0.183036, acc.: 74.22%] [G loss: 0.544807]\n",
      "epoch:7 step:6875 [D loss: 0.275482, acc.: 57.03%] [G loss: 0.479466]\n",
      "epoch:7 step:6876 [D loss: 0.209811, acc.: 66.41%] [G loss: 0.448926]\n",
      "epoch:7 step:6877 [D loss: 0.217229, acc.: 67.19%] [G loss: 0.454540]\n",
      "epoch:7 step:6878 [D loss: 0.216379, acc.: 63.28%] [G loss: 0.510881]\n",
      "epoch:7 step:6879 [D loss: 0.212111, acc.: 64.84%] [G loss: 0.466687]\n",
      "epoch:7 step:6880 [D loss: 0.164883, acc.: 78.91%] [G loss: 0.527504]\n",
      "epoch:7 step:6881 [D loss: 0.216980, acc.: 64.84%] [G loss: 0.504068]\n",
      "epoch:7 step:6882 [D loss: 0.249611, acc.: 56.25%] [G loss: 0.473139]\n",
      "epoch:7 step:6883 [D loss: 0.201091, acc.: 71.09%] [G loss: 0.470681]\n",
      "epoch:7 step:6884 [D loss: 0.211063, acc.: 65.62%] [G loss: 0.482035]\n",
      "epoch:7 step:6885 [D loss: 0.219176, acc.: 63.28%] [G loss: 0.516827]\n",
      "epoch:7 step:6886 [D loss: 0.210393, acc.: 64.06%] [G loss: 0.492999]\n",
      "epoch:7 step:6887 [D loss: 0.189255, acc.: 71.88%] [G loss: 0.508944]\n",
      "epoch:7 step:6888 [D loss: 0.262839, acc.: 60.16%] [G loss: 0.509639]\n",
      "epoch:7 step:6889 [D loss: 0.218504, acc.: 64.06%] [G loss: 0.499622]\n",
      "epoch:7 step:6890 [D loss: 0.217022, acc.: 63.28%] [G loss: 0.495488]\n",
      "epoch:7 step:6891 [D loss: 0.210794, acc.: 67.97%] [G loss: 0.469246]\n",
      "epoch:7 step:6892 [D loss: 0.181305, acc.: 74.22%] [G loss: 0.487914]\n",
      "epoch:7 step:6893 [D loss: 0.232086, acc.: 66.41%] [G loss: 0.493565]\n",
      "epoch:7 step:6894 [D loss: 0.177217, acc.: 74.22%] [G loss: 0.509089]\n",
      "epoch:7 step:6895 [D loss: 0.219671, acc.: 63.28%] [G loss: 0.472506]\n",
      "epoch:7 step:6896 [D loss: 0.204232, acc.: 66.41%] [G loss: 0.503971]\n",
      "epoch:7 step:6897 [D loss: 0.227831, acc.: 61.72%] [G loss: 0.499561]\n",
      "epoch:7 step:6898 [D loss: 0.177464, acc.: 72.66%] [G loss: 0.516721]\n",
      "epoch:7 step:6899 [D loss: 0.203845, acc.: 66.41%] [G loss: 0.513277]\n",
      "epoch:7 step:6900 [D loss: 0.295806, acc.: 50.00%] [G loss: 0.445055]\n",
      "epoch:7 step:6901 [D loss: 0.220482, acc.: 64.84%] [G loss: 0.475503]\n",
      "epoch:7 step:6902 [D loss: 0.200444, acc.: 70.31%] [G loss: 0.566370]\n",
      "epoch:7 step:6903 [D loss: 0.201789, acc.: 68.75%] [G loss: 0.555432]\n",
      "epoch:7 step:6904 [D loss: 0.199363, acc.: 71.09%] [G loss: 0.583661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6905 [D loss: 0.221711, acc.: 64.06%] [G loss: 0.509387]\n",
      "epoch:7 step:6906 [D loss: 0.192803, acc.: 69.53%] [G loss: 0.584988]\n",
      "epoch:7 step:6907 [D loss: 0.284848, acc.: 50.78%] [G loss: 0.452736]\n",
      "epoch:7 step:6908 [D loss: 0.263179, acc.: 50.00%] [G loss: 0.425785]\n",
      "epoch:7 step:6909 [D loss: 0.213637, acc.: 67.97%] [G loss: 0.483631]\n",
      "epoch:7 step:6910 [D loss: 0.212140, acc.: 63.28%] [G loss: 0.478819]\n",
      "epoch:7 step:6911 [D loss: 0.231298, acc.: 58.59%] [G loss: 0.522200]\n",
      "epoch:7 step:6912 [D loss: 0.218360, acc.: 60.94%] [G loss: 0.569922]\n",
      "epoch:7 step:6913 [D loss: 0.173352, acc.: 72.66%] [G loss: 0.580598]\n",
      "epoch:7 step:6914 [D loss: 0.237618, acc.: 61.72%] [G loss: 0.539102]\n",
      "epoch:7 step:6915 [D loss: 0.236913, acc.: 65.62%] [G loss: 0.485959]\n",
      "epoch:7 step:6916 [D loss: 0.192961, acc.: 68.75%] [G loss: 0.497703]\n",
      "epoch:7 step:6917 [D loss: 0.187343, acc.: 72.66%] [G loss: 0.534693]\n",
      "epoch:7 step:6918 [D loss: 0.185567, acc.: 69.53%] [G loss: 0.518381]\n",
      "epoch:7 step:6919 [D loss: 0.187963, acc.: 71.09%] [G loss: 0.561791]\n",
      "epoch:7 step:6920 [D loss: 0.188497, acc.: 69.53%] [G loss: 0.512228]\n",
      "epoch:7 step:6921 [D loss: 0.255916, acc.: 53.91%] [G loss: 0.471940]\n",
      "epoch:7 step:6922 [D loss: 0.212199, acc.: 64.06%] [G loss: 0.457293]\n",
      "epoch:7 step:6923 [D loss: 0.196795, acc.: 73.44%] [G loss: 0.492379]\n",
      "epoch:7 step:6924 [D loss: 0.224499, acc.: 60.94%] [G loss: 0.476022]\n",
      "epoch:7 step:6925 [D loss: 0.214919, acc.: 67.19%] [G loss: 0.473588]\n",
      "epoch:7 step:6926 [D loss: 0.207655, acc.: 64.06%] [G loss: 0.524920]\n",
      "epoch:7 step:6927 [D loss: 0.177134, acc.: 71.09%] [G loss: 0.543118]\n",
      "epoch:7 step:6928 [D loss: 0.204824, acc.: 69.53%] [G loss: 0.496189]\n",
      "epoch:7 step:6929 [D loss: 0.218878, acc.: 65.62%] [G loss: 0.499613]\n",
      "epoch:7 step:6930 [D loss: 0.189537, acc.: 73.44%] [G loss: 0.549224]\n",
      "epoch:7 step:6931 [D loss: 0.207856, acc.: 62.50%] [G loss: 0.519428]\n",
      "epoch:7 step:6932 [D loss: 0.250885, acc.: 54.69%] [G loss: 0.492184]\n",
      "epoch:7 step:6933 [D loss: 0.192628, acc.: 72.66%] [G loss: 0.529476]\n",
      "epoch:7 step:6934 [D loss: 0.220748, acc.: 65.62%] [G loss: 0.481229]\n",
      "epoch:7 step:6935 [D loss: 0.253248, acc.: 52.34%] [G loss: 0.447214]\n",
      "epoch:7 step:6936 [D loss: 0.260798, acc.: 56.25%] [G loss: 0.441419]\n",
      "epoch:7 step:6937 [D loss: 0.218956, acc.: 67.19%] [G loss: 0.459258]\n",
      "epoch:7 step:6938 [D loss: 0.219130, acc.: 72.66%] [G loss: 0.484935]\n",
      "epoch:7 step:6939 [D loss: 0.218117, acc.: 67.19%] [G loss: 0.472718]\n",
      "epoch:7 step:6940 [D loss: 0.168615, acc.: 78.91%] [G loss: 0.501522]\n",
      "epoch:7 step:6941 [D loss: 0.239444, acc.: 60.94%] [G loss: 0.491804]\n",
      "epoch:7 step:6942 [D loss: 0.250654, acc.: 57.81%] [G loss: 0.484056]\n",
      "epoch:7 step:6943 [D loss: 0.227692, acc.: 63.28%] [G loss: 0.483670]\n",
      "epoch:7 step:6944 [D loss: 0.203497, acc.: 67.97%] [G loss: 0.479489]\n",
      "epoch:7 step:6945 [D loss: 0.225052, acc.: 65.62%] [G loss: 0.519677]\n",
      "epoch:7 step:6946 [D loss: 0.225083, acc.: 64.06%] [G loss: 0.502605]\n",
      "epoch:7 step:6947 [D loss: 0.237302, acc.: 57.81%] [G loss: 0.485492]\n",
      "epoch:7 step:6948 [D loss: 0.238166, acc.: 61.72%] [G loss: 0.510998]\n",
      "epoch:7 step:6949 [D loss: 0.261674, acc.: 52.34%] [G loss: 0.465948]\n",
      "epoch:7 step:6950 [D loss: 0.207876, acc.: 70.31%] [G loss: 0.478437]\n",
      "epoch:7 step:6951 [D loss: 0.192652, acc.: 73.44%] [G loss: 0.494405]\n",
      "epoch:7 step:6952 [D loss: 0.231226, acc.: 57.03%] [G loss: 0.486655]\n",
      "epoch:7 step:6953 [D loss: 0.213072, acc.: 66.41%] [G loss: 0.486424]\n",
      "epoch:7 step:6954 [D loss: 0.210016, acc.: 64.84%] [G loss: 0.537624]\n",
      "epoch:7 step:6955 [D loss: 0.290213, acc.: 51.56%] [G loss: 0.458209]\n",
      "epoch:7 step:6956 [D loss: 0.216976, acc.: 61.72%] [G loss: 0.439474]\n",
      "epoch:7 step:6957 [D loss: 0.151579, acc.: 75.00%] [G loss: 0.527101]\n",
      "epoch:7 step:6958 [D loss: 0.182113, acc.: 71.88%] [G loss: 0.556562]\n",
      "epoch:7 step:6959 [D loss: 0.274947, acc.: 53.12%] [G loss: 0.464871]\n",
      "epoch:7 step:6960 [D loss: 0.228613, acc.: 64.06%] [G loss: 0.523541]\n",
      "epoch:7 step:6961 [D loss: 0.207849, acc.: 67.19%] [G loss: 0.503770]\n",
      "epoch:7 step:6962 [D loss: 0.214728, acc.: 67.97%] [G loss: 0.519587]\n",
      "epoch:7 step:6963 [D loss: 0.250085, acc.: 58.59%] [G loss: 0.452432]\n",
      "epoch:7 step:6964 [D loss: 0.199815, acc.: 67.97%] [G loss: 0.465428]\n",
      "epoch:7 step:6965 [D loss: 0.209480, acc.: 65.62%] [G loss: 0.502871]\n",
      "epoch:7 step:6966 [D loss: 0.241331, acc.: 57.03%] [G loss: 0.511298]\n",
      "epoch:7 step:6967 [D loss: 0.260649, acc.: 53.91%] [G loss: 0.460281]\n",
      "epoch:7 step:6968 [D loss: 0.225030, acc.: 63.28%] [G loss: 0.483331]\n",
      "epoch:7 step:6969 [D loss: 0.209760, acc.: 68.75%] [G loss: 0.484555]\n",
      "epoch:7 step:6970 [D loss: 0.215581, acc.: 63.28%] [G loss: 0.486489]\n",
      "epoch:7 step:6971 [D loss: 0.232530, acc.: 59.38%] [G loss: 0.437064]\n",
      "epoch:7 step:6972 [D loss: 0.226648, acc.: 60.16%] [G loss: 0.483383]\n",
      "epoch:7 step:6973 [D loss: 0.225849, acc.: 63.28%] [G loss: 0.484441]\n",
      "epoch:7 step:6974 [D loss: 0.224078, acc.: 68.75%] [G loss: 0.535813]\n",
      "epoch:7 step:6975 [D loss: 0.181242, acc.: 73.44%] [G loss: 0.529588]\n",
      "epoch:7 step:6976 [D loss: 0.243680, acc.: 57.81%] [G loss: 0.497251]\n",
      "epoch:7 step:6977 [D loss: 0.271174, acc.: 53.91%] [G loss: 0.463200]\n",
      "epoch:7 step:6978 [D loss: 0.218658, acc.: 66.41%] [G loss: 0.523151]\n",
      "epoch:7 step:6979 [D loss: 0.239577, acc.: 59.38%] [G loss: 0.499863]\n",
      "epoch:7 step:6980 [D loss: 0.245144, acc.: 61.72%] [G loss: 0.463575]\n",
      "epoch:7 step:6981 [D loss: 0.250840, acc.: 54.69%] [G loss: 0.418090]\n",
      "epoch:7 step:6982 [D loss: 0.244498, acc.: 60.16%] [G loss: 0.453021]\n",
      "epoch:7 step:6983 [D loss: 0.195470, acc.: 70.31%] [G loss: 0.465127]\n",
      "epoch:7 step:6984 [D loss: 0.238701, acc.: 60.94%] [G loss: 0.474264]\n",
      "epoch:7 step:6985 [D loss: 0.188471, acc.: 71.09%] [G loss: 0.491262]\n",
      "epoch:7 step:6986 [D loss: 0.187143, acc.: 71.09%] [G loss: 0.564850]\n",
      "epoch:7 step:6987 [D loss: 0.198674, acc.: 71.09%] [G loss: 0.569322]\n",
      "epoch:7 step:6988 [D loss: 0.204192, acc.: 67.19%] [G loss: 0.560697]\n",
      "epoch:7 step:6989 [D loss: 0.203348, acc.: 67.19%] [G loss: 0.566998]\n",
      "epoch:7 step:6990 [D loss: 0.224409, acc.: 65.62%] [G loss: 0.530846]\n",
      "epoch:7 step:6991 [D loss: 0.222440, acc.: 62.50%] [G loss: 0.511049]\n",
      "epoch:7 step:6992 [D loss: 0.239791, acc.: 64.84%] [G loss: 0.487592]\n",
      "epoch:7 step:6993 [D loss: 0.191541, acc.: 75.78%] [G loss: 0.545334]\n",
      "epoch:7 step:6994 [D loss: 0.256746, acc.: 53.91%] [G loss: 0.463001]\n",
      "epoch:7 step:6995 [D loss: 0.209068, acc.: 66.41%] [G loss: 0.522686]\n",
      "epoch:7 step:6996 [D loss: 0.295818, acc.: 47.66%] [G loss: 0.440816]\n",
      "epoch:7 step:6997 [D loss: 0.258503, acc.: 52.34%] [G loss: 0.440174]\n",
      "epoch:7 step:6998 [D loss: 0.206833, acc.: 64.84%] [G loss: 0.494276]\n",
      "epoch:7 step:6999 [D loss: 0.200977, acc.: 70.31%] [G loss: 0.485988]\n",
      "epoch:7 step:7000 [D loss: 0.215421, acc.: 64.84%] [G loss: 0.545823]\n",
      "epoch:7 step:7001 [D loss: 0.238596, acc.: 59.38%] [G loss: 0.478958]\n",
      "epoch:7 step:7002 [D loss: 0.244704, acc.: 58.59%] [G loss: 0.465106]\n",
      "epoch:7 step:7003 [D loss: 0.240712, acc.: 56.25%] [G loss: 0.491914]\n",
      "epoch:7 step:7004 [D loss: 0.210810, acc.: 64.06%] [G loss: 0.509704]\n",
      "epoch:7 step:7005 [D loss: 0.232028, acc.: 61.72%] [G loss: 0.523041]\n",
      "epoch:7 step:7006 [D loss: 0.214018, acc.: 69.53%] [G loss: 0.489764]\n",
      "epoch:7 step:7007 [D loss: 0.228026, acc.: 67.19%] [G loss: 0.458804]\n",
      "epoch:7 step:7008 [D loss: 0.200635, acc.: 68.75%] [G loss: 0.464349]\n",
      "epoch:7 step:7009 [D loss: 0.208590, acc.: 70.31%] [G loss: 0.491852]\n",
      "epoch:7 step:7010 [D loss: 0.189654, acc.: 70.31%] [G loss: 0.484190]\n",
      "epoch:7 step:7011 [D loss: 0.209873, acc.: 71.88%] [G loss: 0.511095]\n",
      "epoch:7 step:7012 [D loss: 0.176350, acc.: 77.34%] [G loss: 0.560414]\n",
      "epoch:7 step:7013 [D loss: 0.211864, acc.: 65.62%] [G loss: 0.490229]\n",
      "epoch:7 step:7014 [D loss: 0.226713, acc.: 57.81%] [G loss: 0.450549]\n",
      "epoch:7 step:7015 [D loss: 0.234787, acc.: 64.84%] [G loss: 0.485452]\n",
      "epoch:7 step:7016 [D loss: 0.196766, acc.: 69.53%] [G loss: 0.590559]\n",
      "epoch:7 step:7017 [D loss: 0.262305, acc.: 53.12%] [G loss: 0.481590]\n",
      "epoch:7 step:7018 [D loss: 0.235557, acc.: 65.62%] [G loss: 0.431097]\n",
      "epoch:7 step:7019 [D loss: 0.226327, acc.: 61.72%] [G loss: 0.481179]\n",
      "epoch:7 step:7020 [D loss: 0.221230, acc.: 68.75%] [G loss: 0.490727]\n",
      "epoch:7 step:7021 [D loss: 0.256000, acc.: 55.47%] [G loss: 0.471126]\n",
      "epoch:7 step:7022 [D loss: 0.256882, acc.: 57.03%] [G loss: 0.450007]\n",
      "epoch:7 step:7023 [D loss: 0.209569, acc.: 64.84%] [G loss: 0.482011]\n",
      "epoch:7 step:7024 [D loss: 0.240867, acc.: 57.81%] [G loss: 0.425217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7025 [D loss: 0.242081, acc.: 64.06%] [G loss: 0.447422]\n",
      "epoch:7 step:7026 [D loss: 0.235133, acc.: 57.03%] [G loss: 0.448225]\n",
      "epoch:7 step:7027 [D loss: 0.231887, acc.: 66.41%] [G loss: 0.546676]\n",
      "epoch:7 step:7028 [D loss: 0.222437, acc.: 62.50%] [G loss: 0.525104]\n",
      "epoch:7 step:7029 [D loss: 0.238850, acc.: 60.16%] [G loss: 0.456843]\n",
      "epoch:7 step:7030 [D loss: 0.173155, acc.: 76.56%] [G loss: 0.543958]\n",
      "epoch:7 step:7031 [D loss: 0.191226, acc.: 76.56%] [G loss: 0.567289]\n",
      "epoch:7 step:7032 [D loss: 0.257323, acc.: 58.59%] [G loss: 0.454567]\n",
      "epoch:7 step:7033 [D loss: 0.199853, acc.: 65.62%] [G loss: 0.532636]\n",
      "epoch:7 step:7034 [D loss: 0.211782, acc.: 65.62%] [G loss: 0.520614]\n",
      "epoch:7 step:7035 [D loss: 0.225500, acc.: 65.62%] [G loss: 0.525299]\n",
      "epoch:7 step:7036 [D loss: 0.267181, acc.: 53.91%] [G loss: 0.401110]\n",
      "epoch:7 step:7037 [D loss: 0.244161, acc.: 60.16%] [G loss: 0.461848]\n",
      "epoch:7 step:7038 [D loss: 0.233432, acc.: 62.50%] [G loss: 0.472645]\n",
      "epoch:7 step:7039 [D loss: 0.225917, acc.: 60.16%] [G loss: 0.490827]\n",
      "epoch:7 step:7040 [D loss: 0.194050, acc.: 72.66%] [G loss: 0.554020]\n",
      "epoch:7 step:7041 [D loss: 0.259979, acc.: 58.59%] [G loss: 0.456745]\n",
      "epoch:7 step:7042 [D loss: 0.224881, acc.: 58.59%] [G loss: 0.409032]\n",
      "epoch:7 step:7043 [D loss: 0.201854, acc.: 67.97%] [G loss: 0.478447]\n",
      "epoch:7 step:7044 [D loss: 0.229477, acc.: 60.94%] [G loss: 0.502504]\n",
      "epoch:7 step:7045 [D loss: 0.256476, acc.: 58.59%] [G loss: 0.439224]\n",
      "epoch:7 step:7046 [D loss: 0.224880, acc.: 66.41%] [G loss: 0.456842]\n",
      "epoch:7 step:7047 [D loss: 0.211473, acc.: 65.62%] [G loss: 0.516040]\n",
      "epoch:7 step:7048 [D loss: 0.242677, acc.: 57.03%] [G loss: 0.447166]\n",
      "epoch:7 step:7049 [D loss: 0.224426, acc.: 67.97%] [G loss: 0.462195]\n",
      "epoch:7 step:7050 [D loss: 0.231504, acc.: 66.41%] [G loss: 0.481893]\n",
      "epoch:7 step:7051 [D loss: 0.226056, acc.: 64.06%] [G loss: 0.509500]\n",
      "epoch:7 step:7052 [D loss: 0.214972, acc.: 68.75%] [G loss: 0.485782]\n",
      "epoch:7 step:7053 [D loss: 0.204930, acc.: 69.53%] [G loss: 0.506644]\n",
      "epoch:7 step:7054 [D loss: 0.183259, acc.: 76.56%] [G loss: 0.509115]\n",
      "epoch:7 step:7055 [D loss: 0.223239, acc.: 70.31%] [G loss: 0.488760]\n",
      "epoch:7 step:7056 [D loss: 0.195147, acc.: 77.34%] [G loss: 0.478011]\n",
      "epoch:7 step:7057 [D loss: 0.208764, acc.: 70.31%] [G loss: 0.522982]\n",
      "epoch:7 step:7058 [D loss: 0.175735, acc.: 75.78%] [G loss: 0.525840]\n",
      "epoch:7 step:7059 [D loss: 0.277354, acc.: 57.03%] [G loss: 0.482502]\n",
      "epoch:7 step:7060 [D loss: 0.274541, acc.: 53.91%] [G loss: 0.466573]\n",
      "epoch:7 step:7061 [D loss: 0.225629, acc.: 60.16%] [G loss: 0.455623]\n",
      "epoch:7 step:7062 [D loss: 0.196166, acc.: 70.31%] [G loss: 0.462382]\n",
      "epoch:7 step:7063 [D loss: 0.192898, acc.: 69.53%] [G loss: 0.513841]\n",
      "epoch:7 step:7064 [D loss: 0.190446, acc.: 74.22%] [G loss: 0.602781]\n",
      "epoch:7 step:7065 [D loss: 0.230374, acc.: 62.50%] [G loss: 0.498389]\n",
      "epoch:7 step:7066 [D loss: 0.215545, acc.: 61.72%] [G loss: 0.515462]\n",
      "epoch:7 step:7067 [D loss: 0.190147, acc.: 70.31%] [G loss: 0.542204]\n",
      "epoch:7 step:7068 [D loss: 0.230845, acc.: 65.62%] [G loss: 0.487352]\n",
      "epoch:7 step:7069 [D loss: 0.212454, acc.: 70.31%] [G loss: 0.478312]\n",
      "epoch:7 step:7070 [D loss: 0.237390, acc.: 59.38%] [G loss: 0.494778]\n",
      "epoch:7 step:7071 [D loss: 0.213835, acc.: 65.62%] [G loss: 0.489345]\n",
      "epoch:7 step:7072 [D loss: 0.220407, acc.: 66.41%] [G loss: 0.534359]\n",
      "epoch:7 step:7073 [D loss: 0.207231, acc.: 66.41%] [G loss: 0.538098]\n",
      "epoch:7 step:7074 [D loss: 0.186371, acc.: 71.09%] [G loss: 0.579080]\n",
      "epoch:7 step:7075 [D loss: 0.196051, acc.: 70.31%] [G loss: 0.519026]\n",
      "epoch:7 step:7076 [D loss: 0.233019, acc.: 60.16%] [G loss: 0.483683]\n",
      "epoch:7 step:7077 [D loss: 0.224322, acc.: 63.28%] [G loss: 0.448299]\n",
      "epoch:7 step:7078 [D loss: 0.185959, acc.: 75.00%] [G loss: 0.524208]\n",
      "epoch:7 step:7079 [D loss: 0.216153, acc.: 66.41%] [G loss: 0.531803]\n",
      "epoch:7 step:7080 [D loss: 0.192155, acc.: 71.88%] [G loss: 0.531968]\n",
      "epoch:7 step:7081 [D loss: 0.200144, acc.: 70.31%] [G loss: 0.429302]\n",
      "epoch:7 step:7082 [D loss: 0.193640, acc.: 71.88%] [G loss: 0.485456]\n",
      "epoch:7 step:7083 [D loss: 0.220740, acc.: 57.81%] [G loss: 0.455236]\n",
      "epoch:7 step:7084 [D loss: 0.221144, acc.: 63.28%] [G loss: 0.478932]\n",
      "epoch:7 step:7085 [D loss: 0.206129, acc.: 68.75%] [G loss: 0.491993]\n",
      "epoch:7 step:7086 [D loss: 0.227703, acc.: 66.41%] [G loss: 0.517681]\n",
      "epoch:7 step:7087 [D loss: 0.278337, acc.: 50.00%] [G loss: 0.489142]\n",
      "epoch:7 step:7088 [D loss: 0.240670, acc.: 63.28%] [G loss: 0.483696]\n",
      "epoch:7 step:7089 [D loss: 0.224885, acc.: 63.28%] [G loss: 0.512355]\n",
      "epoch:7 step:7090 [D loss: 0.245490, acc.: 59.38%] [G loss: 0.454528]\n",
      "epoch:7 step:7091 [D loss: 0.236488, acc.: 64.06%] [G loss: 0.469744]\n",
      "epoch:7 step:7092 [D loss: 0.240018, acc.: 55.47%] [G loss: 0.460491]\n",
      "epoch:7 step:7093 [D loss: 0.187067, acc.: 71.09%] [G loss: 0.561067]\n",
      "epoch:7 step:7094 [D loss: 0.241083, acc.: 57.03%] [G loss: 0.489948]\n",
      "epoch:7 step:7095 [D loss: 0.197490, acc.: 74.22%] [G loss: 0.466376]\n",
      "epoch:7 step:7096 [D loss: 0.254712, acc.: 56.25%] [G loss: 0.454933]\n",
      "epoch:7 step:7097 [D loss: 0.241485, acc.: 59.38%] [G loss: 0.460101]\n",
      "epoch:7 step:7098 [D loss: 0.218560, acc.: 64.84%] [G loss: 0.478132]\n",
      "epoch:7 step:7099 [D loss: 0.240480, acc.: 64.06%] [G loss: 0.495207]\n",
      "epoch:7 step:7100 [D loss: 0.211451, acc.: 64.06%] [G loss: 0.492172]\n",
      "epoch:7 step:7101 [D loss: 0.268565, acc.: 50.78%] [G loss: 0.441173]\n",
      "epoch:7 step:7102 [D loss: 0.227554, acc.: 61.72%] [G loss: 0.446128]\n",
      "epoch:7 step:7103 [D loss: 0.202627, acc.: 67.19%] [G loss: 0.438931]\n",
      "epoch:7 step:7104 [D loss: 0.218482, acc.: 62.50%] [G loss: 0.489463]\n",
      "epoch:7 step:7105 [D loss: 0.229629, acc.: 62.50%] [G loss: 0.462470]\n",
      "epoch:7 step:7106 [D loss: 0.208333, acc.: 65.62%] [G loss: 0.483748]\n",
      "epoch:7 step:7107 [D loss: 0.189490, acc.: 70.31%] [G loss: 0.515732]\n",
      "epoch:7 step:7108 [D loss: 0.238594, acc.: 60.16%] [G loss: 0.474168]\n",
      "epoch:7 step:7109 [D loss: 0.205487, acc.: 68.75%] [G loss: 0.517081]\n",
      "epoch:7 step:7110 [D loss: 0.196345, acc.: 70.31%] [G loss: 0.526715]\n",
      "epoch:7 step:7111 [D loss: 0.229138, acc.: 61.72%] [G loss: 0.522025]\n",
      "epoch:7 step:7112 [D loss: 0.236280, acc.: 64.06%] [G loss: 0.477453]\n",
      "epoch:7 step:7113 [D loss: 0.193508, acc.: 71.88%] [G loss: 0.520845]\n",
      "epoch:7 step:7114 [D loss: 0.185037, acc.: 71.09%] [G loss: 0.518519]\n",
      "epoch:7 step:7115 [D loss: 0.189711, acc.: 74.22%] [G loss: 0.531873]\n",
      "epoch:7 step:7116 [D loss: 0.193109, acc.: 70.31%] [G loss: 0.496342]\n",
      "epoch:7 step:7117 [D loss: 0.195082, acc.: 66.41%] [G loss: 0.504740]\n",
      "epoch:7 step:7118 [D loss: 0.241599, acc.: 63.28%] [G loss: 0.489797]\n",
      "epoch:7 step:7119 [D loss: 0.246329, acc.: 54.69%] [G loss: 0.441749]\n",
      "epoch:7 step:7120 [D loss: 0.199715, acc.: 65.62%] [G loss: 0.503123]\n",
      "epoch:7 step:7121 [D loss: 0.252812, acc.: 56.25%] [G loss: 0.524393]\n",
      "epoch:7 step:7122 [D loss: 0.204382, acc.: 67.19%] [G loss: 0.503114]\n",
      "epoch:7 step:7123 [D loss: 0.189091, acc.: 72.66%] [G loss: 0.528798]\n",
      "epoch:7 step:7124 [D loss: 0.240958, acc.: 60.94%] [G loss: 0.500075]\n",
      "epoch:7 step:7125 [D loss: 0.282509, acc.: 49.22%] [G loss: 0.434042]\n",
      "epoch:7 step:7126 [D loss: 0.194423, acc.: 73.44%] [G loss: 0.490843]\n",
      "epoch:7 step:7127 [D loss: 0.198164, acc.: 69.53%] [G loss: 0.506483]\n",
      "epoch:7 step:7128 [D loss: 0.229252, acc.: 60.16%] [G loss: 0.472075]\n",
      "epoch:7 step:7129 [D loss: 0.229831, acc.: 61.72%] [G loss: 0.487907]\n",
      "epoch:7 step:7130 [D loss: 0.195085, acc.: 71.09%] [G loss: 0.459771]\n",
      "epoch:7 step:7131 [D loss: 0.241823, acc.: 60.94%] [G loss: 0.460165]\n",
      "epoch:7 step:7132 [D loss: 0.220055, acc.: 70.31%] [G loss: 0.456510]\n",
      "epoch:7 step:7133 [D loss: 0.176155, acc.: 76.56%] [G loss: 0.546960]\n",
      "epoch:7 step:7134 [D loss: 0.199022, acc.: 67.19%] [G loss: 0.502098]\n",
      "epoch:7 step:7135 [D loss: 0.258813, acc.: 51.56%] [G loss: 0.441502]\n",
      "epoch:7 step:7136 [D loss: 0.237225, acc.: 61.72%] [G loss: 0.427799]\n",
      "epoch:7 step:7137 [D loss: 0.220490, acc.: 61.72%] [G loss: 0.478904]\n",
      "epoch:7 step:7138 [D loss: 0.249766, acc.: 58.59%] [G loss: 0.435807]\n",
      "epoch:7 step:7139 [D loss: 0.259945, acc.: 50.78%] [G loss: 0.460119]\n",
      "epoch:7 step:7140 [D loss: 0.214548, acc.: 64.06%] [G loss: 0.525394]\n",
      "epoch:7 step:7141 [D loss: 0.180610, acc.: 73.44%] [G loss: 0.517344]\n",
      "epoch:7 step:7142 [D loss: 0.208663, acc.: 65.62%] [G loss: 0.476185]\n",
      "epoch:7 step:7143 [D loss: 0.254103, acc.: 55.47%] [G loss: 0.470968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7144 [D loss: 0.242303, acc.: 58.59%] [G loss: 0.467717]\n",
      "epoch:7 step:7145 [D loss: 0.237160, acc.: 61.72%] [G loss: 0.496394]\n",
      "epoch:7 step:7146 [D loss: 0.237172, acc.: 61.72%] [G loss: 0.445011]\n",
      "epoch:7 step:7147 [D loss: 0.198176, acc.: 71.09%] [G loss: 0.516184]\n",
      "epoch:7 step:7148 [D loss: 0.198875, acc.: 70.31%] [G loss: 0.522809]\n",
      "epoch:7 step:7149 [D loss: 0.261075, acc.: 54.69%] [G loss: 0.460185]\n",
      "epoch:7 step:7150 [D loss: 0.222222, acc.: 63.28%] [G loss: 0.501671]\n",
      "epoch:7 step:7151 [D loss: 0.207621, acc.: 67.97%] [G loss: 0.466843]\n",
      "epoch:7 step:7152 [D loss: 0.222600, acc.: 65.62%] [G loss: 0.482690]\n",
      "epoch:7 step:7153 [D loss: 0.254215, acc.: 58.59%] [G loss: 0.444356]\n",
      "epoch:7 step:7154 [D loss: 0.223951, acc.: 59.38%] [G loss: 0.477686]\n",
      "epoch:7 step:7155 [D loss: 0.247766, acc.: 59.38%] [G loss: 0.471697]\n",
      "epoch:7 step:7156 [D loss: 0.245168, acc.: 60.94%] [G loss: 0.439150]\n",
      "epoch:7 step:7157 [D loss: 0.214119, acc.: 66.41%] [G loss: 0.463123]\n",
      "epoch:7 step:7158 [D loss: 0.242968, acc.: 57.81%] [G loss: 0.464800]\n",
      "epoch:7 step:7159 [D loss: 0.236081, acc.: 58.59%] [G loss: 0.434048]\n",
      "epoch:7 step:7160 [D loss: 0.234160, acc.: 61.72%] [G loss: 0.450457]\n",
      "epoch:7 step:7161 [D loss: 0.256626, acc.: 58.59%] [G loss: 0.534285]\n",
      "epoch:7 step:7162 [D loss: 0.245301, acc.: 62.50%] [G loss: 0.486942]\n",
      "epoch:7 step:7163 [D loss: 0.202824, acc.: 69.53%] [G loss: 0.503306]\n",
      "epoch:7 step:7164 [D loss: 0.190292, acc.: 71.09%] [G loss: 0.490291]\n",
      "epoch:7 step:7165 [D loss: 0.232389, acc.: 61.72%] [G loss: 0.447387]\n",
      "epoch:7 step:7166 [D loss: 0.198094, acc.: 67.97%] [G loss: 0.463510]\n",
      "epoch:7 step:7167 [D loss: 0.204902, acc.: 68.75%] [G loss: 0.526846]\n",
      "epoch:7 step:7168 [D loss: 0.209271, acc.: 62.50%] [G loss: 0.478536]\n",
      "epoch:7 step:7169 [D loss: 0.230415, acc.: 64.84%] [G loss: 0.458495]\n",
      "epoch:7 step:7170 [D loss: 0.214020, acc.: 62.50%] [G loss: 0.479662]\n",
      "epoch:7 step:7171 [D loss: 0.234224, acc.: 61.72%] [G loss: 0.460947]\n",
      "epoch:7 step:7172 [D loss: 0.190419, acc.: 72.66%] [G loss: 0.492455]\n",
      "epoch:7 step:7173 [D loss: 0.232621, acc.: 62.50%] [G loss: 0.475645]\n",
      "epoch:7 step:7174 [D loss: 0.234985, acc.: 64.84%] [G loss: 0.450725]\n",
      "epoch:7 step:7175 [D loss: 0.257534, acc.: 57.81%] [G loss: 0.475001]\n",
      "epoch:7 step:7176 [D loss: 0.218211, acc.: 67.19%] [G loss: 0.490653]\n",
      "epoch:7 step:7177 [D loss: 0.208538, acc.: 69.53%] [G loss: 0.527988]\n",
      "epoch:7 step:7178 [D loss: 0.227790, acc.: 63.28%] [G loss: 0.514640]\n",
      "epoch:7 step:7179 [D loss: 0.219557, acc.: 64.06%] [G loss: 0.470141]\n",
      "epoch:7 step:7180 [D loss: 0.227182, acc.: 61.72%] [G loss: 0.486933]\n",
      "epoch:7 step:7181 [D loss: 0.251817, acc.: 59.38%] [G loss: 0.481610]\n",
      "epoch:7 step:7182 [D loss: 0.226065, acc.: 68.75%] [G loss: 0.459321]\n",
      "epoch:7 step:7183 [D loss: 0.191429, acc.: 71.09%] [G loss: 0.508355]\n",
      "epoch:7 step:7184 [D loss: 0.228921, acc.: 60.94%] [G loss: 0.486087]\n",
      "epoch:7 step:7185 [D loss: 0.231951, acc.: 60.16%] [G loss: 0.480387]\n",
      "epoch:7 step:7186 [D loss: 0.223329, acc.: 65.62%] [G loss: 0.458250]\n",
      "epoch:7 step:7187 [D loss: 0.223990, acc.: 60.94%] [G loss: 0.482290]\n",
      "epoch:7 step:7188 [D loss: 0.192431, acc.: 65.62%] [G loss: 0.482549]\n",
      "epoch:7 step:7189 [D loss: 0.222138, acc.: 64.06%] [G loss: 0.477306]\n",
      "epoch:7 step:7190 [D loss: 0.205916, acc.: 70.31%] [G loss: 0.450384]\n",
      "epoch:7 step:7191 [D loss: 0.195331, acc.: 68.75%] [G loss: 0.497485]\n",
      "epoch:7 step:7192 [D loss: 0.199862, acc.: 70.31%] [G loss: 0.511163]\n",
      "epoch:7 step:7193 [D loss: 0.202423, acc.: 70.31%] [G loss: 0.498277]\n",
      "epoch:7 step:7194 [D loss: 0.214253, acc.: 66.41%] [G loss: 0.551313]\n",
      "epoch:7 step:7195 [D loss: 0.224551, acc.: 58.59%] [G loss: 0.490490]\n",
      "epoch:7 step:7196 [D loss: 0.216447, acc.: 65.62%] [G loss: 0.466275]\n",
      "epoch:7 step:7197 [D loss: 0.229751, acc.: 59.38%] [G loss: 0.474612]\n",
      "epoch:7 step:7198 [D loss: 0.221846, acc.: 58.59%] [G loss: 0.440557]\n",
      "epoch:7 step:7199 [D loss: 0.208418, acc.: 64.84%] [G loss: 0.469296]\n",
      "epoch:7 step:7200 [D loss: 0.191811, acc.: 74.22%] [G loss: 0.547842]\n",
      "epoch:7 step:7201 [D loss: 0.186394, acc.: 71.09%] [G loss: 0.564860]\n",
      "epoch:7 step:7202 [D loss: 0.229143, acc.: 66.41%] [G loss: 0.530755]\n",
      "epoch:7 step:7203 [D loss: 0.228143, acc.: 60.16%] [G loss: 0.477646]\n",
      "epoch:7 step:7204 [D loss: 0.218752, acc.: 63.28%] [G loss: 0.510689]\n",
      "epoch:7 step:7205 [D loss: 0.207553, acc.: 71.09%] [G loss: 0.493771]\n",
      "epoch:7 step:7206 [D loss: 0.202413, acc.: 70.31%] [G loss: 0.523566]\n",
      "epoch:7 step:7207 [D loss: 0.167971, acc.: 76.56%] [G loss: 0.575177]\n",
      "epoch:7 step:7208 [D loss: 0.215431, acc.: 66.41%] [G loss: 0.526570]\n",
      "epoch:7 step:7209 [D loss: 0.208194, acc.: 69.53%] [G loss: 0.495755]\n",
      "epoch:7 step:7210 [D loss: 0.235840, acc.: 57.81%] [G loss: 0.478803]\n",
      "epoch:7 step:7211 [D loss: 0.240753, acc.: 60.94%] [G loss: 0.470900]\n",
      "epoch:7 step:7212 [D loss: 0.234969, acc.: 59.38%] [G loss: 0.463102]\n",
      "epoch:7 step:7213 [D loss: 0.217980, acc.: 60.16%] [G loss: 0.531502]\n",
      "epoch:7 step:7214 [D loss: 0.231783, acc.: 66.41%] [G loss: 0.535778]\n",
      "epoch:7 step:7215 [D loss: 0.221163, acc.: 60.94%] [G loss: 0.439231]\n",
      "epoch:7 step:7216 [D loss: 0.211939, acc.: 67.19%] [G loss: 0.501882]\n",
      "epoch:7 step:7217 [D loss: 0.226052, acc.: 60.94%] [G loss: 0.494777]\n",
      "epoch:7 step:7218 [D loss: 0.220006, acc.: 63.28%] [G loss: 0.518892]\n",
      "epoch:7 step:7219 [D loss: 0.217003, acc.: 64.84%] [G loss: 0.459030]\n",
      "epoch:7 step:7220 [D loss: 0.200896, acc.: 75.00%] [G loss: 0.478363]\n",
      "epoch:7 step:7221 [D loss: 0.237596, acc.: 60.16%] [G loss: 0.487320]\n",
      "epoch:7 step:7222 [D loss: 0.243872, acc.: 60.94%] [G loss: 0.489090]\n",
      "epoch:7 step:7223 [D loss: 0.228735, acc.: 63.28%] [G loss: 0.465539]\n",
      "epoch:7 step:7224 [D loss: 0.208443, acc.: 65.62%] [G loss: 0.530980]\n",
      "epoch:7 step:7225 [D loss: 0.190286, acc.: 69.53%] [G loss: 0.507898]\n",
      "epoch:7 step:7226 [D loss: 0.226568, acc.: 65.62%] [G loss: 0.498062]\n",
      "epoch:7 step:7227 [D loss: 0.255320, acc.: 59.38%] [G loss: 0.457272]\n",
      "epoch:7 step:7228 [D loss: 0.202527, acc.: 66.41%] [G loss: 0.437841]\n",
      "epoch:7 step:7229 [D loss: 0.220424, acc.: 61.72%] [G loss: 0.453117]\n",
      "epoch:7 step:7230 [D loss: 0.253947, acc.: 55.47%] [G loss: 0.425536]\n",
      "epoch:7 step:7231 [D loss: 0.259290, acc.: 52.34%] [G loss: 0.500032]\n",
      "epoch:7 step:7232 [D loss: 0.256110, acc.: 55.47%] [G loss: 0.458629]\n",
      "epoch:7 step:7233 [D loss: 0.228210, acc.: 64.06%] [G loss: 0.518915]\n",
      "epoch:7 step:7234 [D loss: 0.259166, acc.: 51.56%] [G loss: 0.473621]\n",
      "epoch:7 step:7235 [D loss: 0.192781, acc.: 75.78%] [G loss: 0.482252]\n",
      "epoch:7 step:7236 [D loss: 0.192512, acc.: 66.41%] [G loss: 0.458595]\n",
      "epoch:7 step:7237 [D loss: 0.252366, acc.: 59.38%] [G loss: 0.437464]\n",
      "epoch:7 step:7238 [D loss: 0.217246, acc.: 67.19%] [G loss: 0.467464]\n",
      "epoch:7 step:7239 [D loss: 0.225836, acc.: 63.28%] [G loss: 0.484724]\n",
      "epoch:7 step:7240 [D loss: 0.220867, acc.: 63.28%] [G loss: 0.453772]\n",
      "epoch:7 step:7241 [D loss: 0.232433, acc.: 64.06%] [G loss: 0.451132]\n",
      "epoch:7 step:7242 [D loss: 0.247885, acc.: 58.59%] [G loss: 0.454635]\n",
      "epoch:7 step:7243 [D loss: 0.230776, acc.: 61.72%] [G loss: 0.466806]\n",
      "epoch:7 step:7244 [D loss: 0.218102, acc.: 65.62%] [G loss: 0.471512]\n",
      "epoch:7 step:7245 [D loss: 0.221951, acc.: 64.84%] [G loss: 0.467274]\n",
      "epoch:7 step:7246 [D loss: 0.224725, acc.: 60.16%] [G loss: 0.443972]\n",
      "epoch:7 step:7247 [D loss: 0.241322, acc.: 59.38%] [G loss: 0.447508]\n",
      "epoch:7 step:7248 [D loss: 0.242037, acc.: 59.38%] [G loss: 0.545418]\n",
      "epoch:7 step:7249 [D loss: 0.185651, acc.: 73.44%] [G loss: 0.523591]\n",
      "epoch:7 step:7250 [D loss: 0.217477, acc.: 64.06%] [G loss: 0.492723]\n",
      "epoch:7 step:7251 [D loss: 0.205040, acc.: 68.75%] [G loss: 0.518282]\n",
      "epoch:7 step:7252 [D loss: 0.184403, acc.: 72.66%] [G loss: 0.512408]\n",
      "epoch:7 step:7253 [D loss: 0.189415, acc.: 75.78%] [G loss: 0.565316]\n",
      "epoch:7 step:7254 [D loss: 0.208279, acc.: 66.41%] [G loss: 0.515706]\n",
      "epoch:7 step:7255 [D loss: 0.228450, acc.: 61.72%] [G loss: 0.455405]\n",
      "epoch:7 step:7256 [D loss: 0.219044, acc.: 64.84%] [G loss: 0.458712]\n",
      "epoch:7 step:7257 [D loss: 0.220818, acc.: 67.19%] [G loss: 0.451294]\n",
      "epoch:7 step:7258 [D loss: 0.198158, acc.: 72.66%] [G loss: 0.519247]\n",
      "epoch:7 step:7259 [D loss: 0.203244, acc.: 63.28%] [G loss: 0.520048]\n",
      "epoch:7 step:7260 [D loss: 0.201211, acc.: 68.75%] [G loss: 0.526841]\n",
      "epoch:7 step:7261 [D loss: 0.268282, acc.: 57.03%] [G loss: 0.456982]\n",
      "epoch:7 step:7262 [D loss: 0.240054, acc.: 57.03%] [G loss: 0.412705]\n",
      "epoch:7 step:7263 [D loss: 0.251251, acc.: 53.12%] [G loss: 0.478403]\n",
      "epoch:7 step:7264 [D loss: 0.203648, acc.: 63.28%] [G loss: 0.478939]\n",
      "epoch:7 step:7265 [D loss: 0.216146, acc.: 66.41%] [G loss: 0.454084]\n",
      "epoch:7 step:7266 [D loss: 0.200050, acc.: 67.97%] [G loss: 0.477055]\n",
      "epoch:7 step:7267 [D loss: 0.191586, acc.: 71.88%] [G loss: 0.532337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7268 [D loss: 0.192522, acc.: 67.97%] [G loss: 0.502549]\n",
      "epoch:7 step:7269 [D loss: 0.267495, acc.: 57.81%] [G loss: 0.438494]\n",
      "epoch:7 step:7270 [D loss: 0.221940, acc.: 62.50%] [G loss: 0.472617]\n",
      "epoch:7 step:7271 [D loss: 0.220135, acc.: 61.72%] [G loss: 0.519184]\n",
      "epoch:7 step:7272 [D loss: 0.206152, acc.: 67.19%] [G loss: 0.526741]\n",
      "epoch:7 step:7273 [D loss: 0.237463, acc.: 57.03%] [G loss: 0.475717]\n",
      "epoch:7 step:7274 [D loss: 0.220790, acc.: 60.94%] [G loss: 0.462963]\n",
      "epoch:7 step:7275 [D loss: 0.249659, acc.: 53.12%] [G loss: 0.446427]\n",
      "epoch:7 step:7276 [D loss: 0.223941, acc.: 66.41%] [G loss: 0.474645]\n",
      "epoch:7 step:7277 [D loss: 0.248453, acc.: 57.81%] [G loss: 0.488340]\n",
      "epoch:7 step:7278 [D loss: 0.220507, acc.: 64.06%] [G loss: 0.524589]\n",
      "epoch:7 step:7279 [D loss: 0.228320, acc.: 60.94%] [G loss: 0.489759]\n",
      "epoch:7 step:7280 [D loss: 0.234294, acc.: 59.38%] [G loss: 0.482517]\n",
      "epoch:7 step:7281 [D loss: 0.250769, acc.: 61.72%] [G loss: 0.434330]\n",
      "epoch:7 step:7282 [D loss: 0.225523, acc.: 61.72%] [G loss: 0.495711]\n",
      "epoch:7 step:7283 [D loss: 0.219869, acc.: 66.41%] [G loss: 0.469399]\n",
      "epoch:7 step:7284 [D loss: 0.204097, acc.: 67.97%] [G loss: 0.468473]\n",
      "epoch:7 step:7285 [D loss: 0.212332, acc.: 67.97%] [G loss: 0.549225]\n",
      "epoch:7 step:7286 [D loss: 0.255168, acc.: 57.03%] [G loss: 0.438355]\n",
      "epoch:7 step:7287 [D loss: 0.199855, acc.: 71.88%] [G loss: 0.456359]\n",
      "epoch:7 step:7288 [D loss: 0.243387, acc.: 63.28%] [G loss: 0.455294]\n",
      "epoch:7 step:7289 [D loss: 0.194131, acc.: 71.09%] [G loss: 0.504804]\n",
      "epoch:7 step:7290 [D loss: 0.191853, acc.: 68.75%] [G loss: 0.488144]\n",
      "epoch:7 step:7291 [D loss: 0.238568, acc.: 57.03%] [G loss: 0.441661]\n",
      "epoch:7 step:7292 [D loss: 0.193534, acc.: 69.53%] [G loss: 0.526579]\n",
      "epoch:7 step:7293 [D loss: 0.254440, acc.: 56.25%] [G loss: 0.487614]\n",
      "epoch:7 step:7294 [D loss: 0.218832, acc.: 64.84%] [G loss: 0.450052]\n",
      "epoch:7 step:7295 [D loss: 0.191039, acc.: 70.31%] [G loss: 0.520481]\n",
      "epoch:7 step:7296 [D loss: 0.233347, acc.: 65.62%] [G loss: 0.472870]\n",
      "epoch:7 step:7297 [D loss: 0.231091, acc.: 59.38%] [G loss: 0.484888]\n",
      "epoch:7 step:7298 [D loss: 0.241465, acc.: 59.38%] [G loss: 0.470208]\n",
      "epoch:7 step:7299 [D loss: 0.242720, acc.: 56.25%] [G loss: 0.441697]\n",
      "epoch:7 step:7300 [D loss: 0.238032, acc.: 61.72%] [G loss: 0.464952]\n",
      "epoch:7 step:7301 [D loss: 0.228974, acc.: 62.50%] [G loss: 0.511112]\n",
      "epoch:7 step:7302 [D loss: 0.220204, acc.: 64.06%] [G loss: 0.508472]\n",
      "epoch:7 step:7303 [D loss: 0.233844, acc.: 60.16%] [G loss: 0.513290]\n",
      "epoch:7 step:7304 [D loss: 0.257870, acc.: 53.12%] [G loss: 0.474791]\n",
      "epoch:7 step:7305 [D loss: 0.216750, acc.: 66.41%] [G loss: 0.520777]\n",
      "epoch:7 step:7306 [D loss: 0.189649, acc.: 76.56%] [G loss: 0.490111]\n",
      "epoch:7 step:7307 [D loss: 0.232722, acc.: 62.50%] [G loss: 0.458155]\n",
      "epoch:7 step:7308 [D loss: 0.202424, acc.: 71.09%] [G loss: 0.483745]\n",
      "epoch:7 step:7309 [D loss: 0.226705, acc.: 67.19%] [G loss: 0.475807]\n",
      "epoch:7 step:7310 [D loss: 0.224690, acc.: 63.28%] [G loss: 0.489514]\n",
      "epoch:7 step:7311 [D loss: 0.238629, acc.: 59.38%] [G loss: 0.464902]\n",
      "epoch:7 step:7312 [D loss: 0.237964, acc.: 61.72%] [G loss: 0.444237]\n",
      "epoch:7 step:7313 [D loss: 0.216810, acc.: 65.62%] [G loss: 0.464577]\n",
      "epoch:7 step:7314 [D loss: 0.210285, acc.: 69.53%] [G loss: 0.501058]\n",
      "epoch:7 step:7315 [D loss: 0.187925, acc.: 72.66%] [G loss: 0.479172]\n",
      "epoch:7 step:7316 [D loss: 0.250669, acc.: 54.69%] [G loss: 0.492224]\n",
      "epoch:7 step:7317 [D loss: 0.198274, acc.: 69.53%] [G loss: 0.481189]\n",
      "epoch:7 step:7318 [D loss: 0.235949, acc.: 54.69%] [G loss: 0.444663]\n",
      "epoch:7 step:7319 [D loss: 0.210861, acc.: 65.62%] [G loss: 0.473514]\n",
      "epoch:7 step:7320 [D loss: 0.209317, acc.: 61.72%] [G loss: 0.496973]\n",
      "epoch:7 step:7321 [D loss: 0.242185, acc.: 56.25%] [G loss: 0.470634]\n",
      "epoch:7 step:7322 [D loss: 0.244857, acc.: 54.69%] [G loss: 0.493644]\n",
      "epoch:7 step:7323 [D loss: 0.220841, acc.: 60.94%] [G loss: 0.512762]\n",
      "epoch:7 step:7324 [D loss: 0.276280, acc.: 50.00%] [G loss: 0.460530]\n",
      "epoch:7 step:7325 [D loss: 0.234558, acc.: 59.38%] [G loss: 0.499169]\n",
      "epoch:7 step:7326 [D loss: 0.211128, acc.: 66.41%] [G loss: 0.507006]\n",
      "epoch:7 step:7327 [D loss: 0.234417, acc.: 63.28%] [G loss: 0.490892]\n",
      "epoch:7 step:7328 [D loss: 0.200194, acc.: 65.62%] [G loss: 0.491980]\n",
      "epoch:7 step:7329 [D loss: 0.229291, acc.: 66.41%] [G loss: 0.486678]\n",
      "epoch:7 step:7330 [D loss: 0.193638, acc.: 71.09%] [G loss: 0.516859]\n",
      "epoch:7 step:7331 [D loss: 0.213246, acc.: 66.41%] [G loss: 0.472526]\n",
      "epoch:7 step:7332 [D loss: 0.198520, acc.: 71.88%] [G loss: 0.490313]\n",
      "epoch:7 step:7333 [D loss: 0.224174, acc.: 64.84%] [G loss: 0.549649]\n",
      "epoch:7 step:7334 [D loss: 0.206779, acc.: 66.41%] [G loss: 0.511056]\n",
      "epoch:7 step:7335 [D loss: 0.241400, acc.: 67.19%] [G loss: 0.486511]\n",
      "epoch:7 step:7336 [D loss: 0.242370, acc.: 61.72%] [G loss: 0.514464]\n",
      "epoch:7 step:7337 [D loss: 0.225807, acc.: 62.50%] [G loss: 0.499368]\n",
      "epoch:7 step:7338 [D loss: 0.218992, acc.: 66.41%] [G loss: 0.516498]\n",
      "epoch:7 step:7339 [D loss: 0.199329, acc.: 72.66%] [G loss: 0.505421]\n",
      "epoch:7 step:7340 [D loss: 0.185707, acc.: 71.09%] [G loss: 0.512583]\n",
      "epoch:7 step:7341 [D loss: 0.189320, acc.: 72.66%] [G loss: 0.617993]\n",
      "epoch:7 step:7342 [D loss: 0.253252, acc.: 60.94%] [G loss: 0.465611]\n",
      "epoch:7 step:7343 [D loss: 0.258621, acc.: 57.03%] [G loss: 0.445804]\n",
      "epoch:7 step:7344 [D loss: 0.240184, acc.: 60.16%] [G loss: 0.462493]\n",
      "epoch:7 step:7345 [D loss: 0.190171, acc.: 69.53%] [G loss: 0.533209]\n",
      "epoch:7 step:7346 [D loss: 0.252286, acc.: 56.25%] [G loss: 0.436065]\n",
      "epoch:7 step:7347 [D loss: 0.253976, acc.: 51.56%] [G loss: 0.475308]\n",
      "epoch:7 step:7348 [D loss: 0.208558, acc.: 64.06%] [G loss: 0.473336]\n",
      "epoch:7 step:7349 [D loss: 0.215826, acc.: 63.28%] [G loss: 0.485550]\n",
      "epoch:7 step:7350 [D loss: 0.240298, acc.: 60.94%] [G loss: 0.452115]\n",
      "epoch:7 step:7351 [D loss: 0.178067, acc.: 75.78%] [G loss: 0.475825]\n",
      "epoch:7 step:7352 [D loss: 0.206341, acc.: 66.41%] [G loss: 0.515453]\n",
      "epoch:7 step:7353 [D loss: 0.224416, acc.: 59.38%] [G loss: 0.495896]\n",
      "epoch:7 step:7354 [D loss: 0.226592, acc.: 66.41%] [G loss: 0.512283]\n",
      "epoch:7 step:7355 [D loss: 0.210166, acc.: 71.09%] [G loss: 0.481654]\n",
      "epoch:7 step:7356 [D loss: 0.254655, acc.: 53.91%] [G loss: 0.464214]\n",
      "epoch:7 step:7357 [D loss: 0.225158, acc.: 62.50%] [G loss: 0.462431]\n",
      "epoch:7 step:7358 [D loss: 0.180531, acc.: 75.78%] [G loss: 0.494933]\n",
      "epoch:7 step:7359 [D loss: 0.244025, acc.: 57.81%] [G loss: 0.465590]\n",
      "epoch:7 step:7360 [D loss: 0.200814, acc.: 70.31%] [G loss: 0.527794]\n",
      "epoch:7 step:7361 [D loss: 0.204684, acc.: 67.19%] [G loss: 0.488702]\n",
      "epoch:7 step:7362 [D loss: 0.210777, acc.: 64.06%] [G loss: 0.463850]\n",
      "epoch:7 step:7363 [D loss: 0.211109, acc.: 70.31%] [G loss: 0.464804]\n",
      "epoch:7 step:7364 [D loss: 0.205189, acc.: 70.31%] [G loss: 0.458821]\n",
      "epoch:7 step:7365 [D loss: 0.227282, acc.: 60.16%] [G loss: 0.439903]\n",
      "epoch:7 step:7366 [D loss: 0.204112, acc.: 69.53%] [G loss: 0.472777]\n",
      "epoch:7 step:7367 [D loss: 0.239526, acc.: 57.03%] [G loss: 0.487722]\n",
      "epoch:7 step:7368 [D loss: 0.211076, acc.: 67.19%] [G loss: 0.493625]\n",
      "epoch:7 step:7369 [D loss: 0.227587, acc.: 64.84%] [G loss: 0.454679]\n",
      "epoch:7 step:7370 [D loss: 0.206841, acc.: 72.66%] [G loss: 0.509117]\n",
      "epoch:7 step:7371 [D loss: 0.256958, acc.: 56.25%] [G loss: 0.434207]\n",
      "epoch:7 step:7372 [D loss: 0.210692, acc.: 66.41%] [G loss: 0.462536]\n",
      "epoch:7 step:7373 [D loss: 0.230150, acc.: 61.72%] [G loss: 0.464568]\n",
      "epoch:7 step:7374 [D loss: 0.196169, acc.: 70.31%] [G loss: 0.472975]\n",
      "epoch:7 step:7375 [D loss: 0.225816, acc.: 62.50%] [G loss: 0.544574]\n",
      "epoch:7 step:7376 [D loss: 0.247154, acc.: 58.59%] [G loss: 0.482350]\n",
      "epoch:7 step:7377 [D loss: 0.226705, acc.: 59.38%] [G loss: 0.461719]\n",
      "epoch:7 step:7378 [D loss: 0.229477, acc.: 64.06%] [G loss: 0.460552]\n",
      "epoch:7 step:7379 [D loss: 0.257686, acc.: 51.56%] [G loss: 0.453087]\n",
      "epoch:7 step:7380 [D loss: 0.232888, acc.: 58.59%] [G loss: 0.400206]\n",
      "epoch:7 step:7381 [D loss: 0.211319, acc.: 68.75%] [G loss: 0.442367]\n",
      "epoch:7 step:7382 [D loss: 0.198302, acc.: 67.97%] [G loss: 0.506948]\n",
      "epoch:7 step:7383 [D loss: 0.236894, acc.: 62.50%] [G loss: 0.449379]\n",
      "epoch:7 step:7384 [D loss: 0.213146, acc.: 67.19%] [G loss: 0.460795]\n",
      "epoch:7 step:7385 [D loss: 0.223933, acc.: 65.62%] [G loss: 0.491387]\n",
      "epoch:7 step:7386 [D loss: 0.277556, acc.: 48.44%] [G loss: 0.460584]\n",
      "epoch:7 step:7387 [D loss: 0.265122, acc.: 57.03%] [G loss: 0.445182]\n",
      "epoch:7 step:7388 [D loss: 0.223072, acc.: 64.84%] [G loss: 0.470478]\n",
      "epoch:7 step:7389 [D loss: 0.218592, acc.: 64.06%] [G loss: 0.467887]\n",
      "epoch:7 step:7390 [D loss: 0.252105, acc.: 57.03%] [G loss: 0.454730]\n",
      "epoch:7 step:7391 [D loss: 0.210590, acc.: 69.53%] [G loss: 0.462595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7392 [D loss: 0.214885, acc.: 64.84%] [G loss: 0.507267]\n",
      "epoch:7 step:7393 [D loss: 0.231775, acc.: 60.16%] [G loss: 0.457283]\n",
      "epoch:7 step:7394 [D loss: 0.214547, acc.: 64.84%] [G loss: 0.462282]\n",
      "epoch:7 step:7395 [D loss: 0.224902, acc.: 64.06%] [G loss: 0.463772]\n",
      "epoch:7 step:7396 [D loss: 0.204384, acc.: 71.88%] [G loss: 0.505731]\n",
      "epoch:7 step:7397 [D loss: 0.201390, acc.: 71.88%] [G loss: 0.516053]\n",
      "epoch:7 step:7398 [D loss: 0.219829, acc.: 60.94%] [G loss: 0.465247]\n",
      "epoch:7 step:7399 [D loss: 0.193344, acc.: 75.78%] [G loss: 0.500524]\n",
      "epoch:7 step:7400 [D loss: 0.222940, acc.: 66.41%] [G loss: 0.477948]\n",
      "epoch:7 step:7401 [D loss: 0.203989, acc.: 68.75%] [G loss: 0.510251]\n",
      "epoch:7 step:7402 [D loss: 0.229877, acc.: 61.72%] [G loss: 0.451487]\n",
      "epoch:7 step:7403 [D loss: 0.229716, acc.: 65.62%] [G loss: 0.512910]\n",
      "epoch:7 step:7404 [D loss: 0.220745, acc.: 64.06%] [G loss: 0.476479]\n",
      "epoch:7 step:7405 [D loss: 0.241040, acc.: 57.81%] [G loss: 0.469549]\n",
      "epoch:7 step:7406 [D loss: 0.246395, acc.: 61.72%] [G loss: 0.426290]\n",
      "epoch:7 step:7407 [D loss: 0.252816, acc.: 53.91%] [G loss: 0.471125]\n",
      "epoch:7 step:7408 [D loss: 0.243885, acc.: 57.03%] [G loss: 0.440821]\n",
      "epoch:7 step:7409 [D loss: 0.211593, acc.: 66.41%] [G loss: 0.479256]\n",
      "epoch:7 step:7410 [D loss: 0.237593, acc.: 60.16%] [G loss: 0.469972]\n",
      "epoch:7 step:7411 [D loss: 0.184415, acc.: 75.00%] [G loss: 0.470786]\n",
      "epoch:7 step:7412 [D loss: 0.228872, acc.: 64.84%] [G loss: 0.510332]\n",
      "epoch:7 step:7413 [D loss: 0.232875, acc.: 64.84%] [G loss: 0.511812]\n",
      "epoch:7 step:7414 [D loss: 0.233732, acc.: 63.28%] [G loss: 0.487962]\n",
      "epoch:7 step:7415 [D loss: 0.252793, acc.: 53.91%] [G loss: 0.447375]\n",
      "epoch:7 step:7416 [D loss: 0.209814, acc.: 63.28%] [G loss: 0.471950]\n",
      "epoch:7 step:7417 [D loss: 0.248031, acc.: 53.12%] [G loss: 0.431098]\n",
      "epoch:7 step:7418 [D loss: 0.208663, acc.: 64.06%] [G loss: 0.516174]\n",
      "epoch:7 step:7419 [D loss: 0.185015, acc.: 74.22%] [G loss: 0.518573]\n",
      "epoch:7 step:7420 [D loss: 0.229971, acc.: 60.94%] [G loss: 0.486737]\n",
      "epoch:7 step:7421 [D loss: 0.220641, acc.: 67.97%] [G loss: 0.475694]\n",
      "epoch:7 step:7422 [D loss: 0.215418, acc.: 63.28%] [G loss: 0.455492]\n",
      "epoch:7 step:7423 [D loss: 0.245738, acc.: 57.03%] [G loss: 0.433318]\n",
      "epoch:7 step:7424 [D loss: 0.229683, acc.: 59.38%] [G loss: 0.446502]\n",
      "epoch:7 step:7425 [D loss: 0.241632, acc.: 60.94%] [G loss: 0.436930]\n",
      "epoch:7 step:7426 [D loss: 0.221231, acc.: 63.28%] [G loss: 0.480927]\n",
      "epoch:7 step:7427 [D loss: 0.231117, acc.: 62.50%] [G loss: 0.458872]\n",
      "epoch:7 step:7428 [D loss: 0.226960, acc.: 61.72%] [G loss: 0.426929]\n",
      "epoch:7 step:7429 [D loss: 0.186243, acc.: 71.88%] [G loss: 0.506666]\n",
      "epoch:7 step:7430 [D loss: 0.198194, acc.: 66.41%] [G loss: 0.500546]\n",
      "epoch:7 step:7431 [D loss: 0.232486, acc.: 62.50%] [G loss: 0.442230]\n",
      "epoch:7 step:7432 [D loss: 0.231578, acc.: 66.41%] [G loss: 0.458036]\n",
      "epoch:7 step:7433 [D loss: 0.266355, acc.: 56.25%] [G loss: 0.427117]\n",
      "epoch:7 step:7434 [D loss: 0.170900, acc.: 75.78%] [G loss: 0.531847]\n",
      "epoch:7 step:7435 [D loss: 0.218406, acc.: 67.97%] [G loss: 0.558969]\n",
      "epoch:7 step:7436 [D loss: 0.235948, acc.: 56.25%] [G loss: 0.457386]\n",
      "epoch:7 step:7437 [D loss: 0.229067, acc.: 59.38%] [G loss: 0.463817]\n",
      "epoch:7 step:7438 [D loss: 0.216437, acc.: 60.16%] [G loss: 0.473531]\n",
      "epoch:7 step:7439 [D loss: 0.219748, acc.: 63.28%] [G loss: 0.455961]\n",
      "epoch:7 step:7440 [D loss: 0.207497, acc.: 67.97%] [G loss: 0.437525]\n",
      "epoch:7 step:7441 [D loss: 0.230178, acc.: 64.84%] [G loss: 0.420967]\n",
      "epoch:7 step:7442 [D loss: 0.206789, acc.: 71.09%] [G loss: 0.489304]\n",
      "epoch:7 step:7443 [D loss: 0.204185, acc.: 68.75%] [G loss: 0.506921]\n",
      "epoch:7 step:7444 [D loss: 0.213246, acc.: 63.28%] [G loss: 0.548215]\n",
      "epoch:7 step:7445 [D loss: 0.191414, acc.: 70.31%] [G loss: 0.588007]\n",
      "epoch:7 step:7446 [D loss: 0.209218, acc.: 67.97%] [G loss: 0.527400]\n",
      "epoch:7 step:7447 [D loss: 0.208073, acc.: 67.97%] [G loss: 0.534128]\n",
      "epoch:7 step:7448 [D loss: 0.198986, acc.: 66.41%] [G loss: 0.530146]\n",
      "epoch:7 step:7449 [D loss: 0.188199, acc.: 72.66%] [G loss: 0.456568]\n",
      "epoch:7 step:7450 [D loss: 0.243991, acc.: 60.16%] [G loss: 0.409399]\n",
      "epoch:7 step:7451 [D loss: 0.269099, acc.: 51.56%] [G loss: 0.423001]\n",
      "epoch:7 step:7452 [D loss: 0.179053, acc.: 77.34%] [G loss: 0.524900]\n",
      "epoch:7 step:7453 [D loss: 0.183926, acc.: 71.88%] [G loss: 0.554991]\n",
      "epoch:7 step:7454 [D loss: 0.203422, acc.: 66.41%] [G loss: 0.496975]\n",
      "epoch:7 step:7455 [D loss: 0.208731, acc.: 67.19%] [G loss: 0.519594]\n",
      "epoch:7 step:7456 [D loss: 0.194239, acc.: 67.19%] [G loss: 0.515334]\n",
      "epoch:7 step:7457 [D loss: 0.189853, acc.: 69.53%] [G loss: 0.489347]\n",
      "epoch:7 step:7458 [D loss: 0.192371, acc.: 65.62%] [G loss: 0.523432]\n",
      "epoch:7 step:7459 [D loss: 0.222433, acc.: 72.66%] [G loss: 0.497406]\n",
      "epoch:7 step:7460 [D loss: 0.217787, acc.: 64.84%] [G loss: 0.482636]\n",
      "epoch:7 step:7461 [D loss: 0.211253, acc.: 67.97%] [G loss: 0.510698]\n",
      "epoch:7 step:7462 [D loss: 0.213136, acc.: 63.28%] [G loss: 0.471359]\n",
      "epoch:7 step:7463 [D loss: 0.241238, acc.: 60.94%] [G loss: 0.472470]\n",
      "epoch:7 step:7464 [D loss: 0.216785, acc.: 67.19%] [G loss: 0.494945]\n",
      "epoch:7 step:7465 [D loss: 0.233034, acc.: 63.28%] [G loss: 0.531506]\n",
      "epoch:7 step:7466 [D loss: 0.235072, acc.: 64.84%] [G loss: 0.511747]\n",
      "epoch:7 step:7467 [D loss: 0.235178, acc.: 64.06%] [G loss: 0.487454]\n",
      "epoch:7 step:7468 [D loss: 0.197435, acc.: 71.88%] [G loss: 0.473530]\n",
      "epoch:7 step:7469 [D loss: 0.260148, acc.: 57.03%] [G loss: 0.488699]\n",
      "epoch:7 step:7470 [D loss: 0.168901, acc.: 78.91%] [G loss: 0.487807]\n",
      "epoch:7 step:7471 [D loss: 0.179091, acc.: 78.91%] [G loss: 0.556523]\n",
      "epoch:7 step:7472 [D loss: 0.204235, acc.: 68.75%] [G loss: 0.496812]\n",
      "epoch:7 step:7473 [D loss: 0.203554, acc.: 65.62%] [G loss: 0.494405]\n",
      "epoch:7 step:7474 [D loss: 0.275269, acc.: 59.38%] [G loss: 0.467376]\n",
      "epoch:7 step:7475 [D loss: 0.248896, acc.: 59.38%] [G loss: 0.465763]\n",
      "epoch:7 step:7476 [D loss: 0.254726, acc.: 56.25%] [G loss: 0.508139]\n",
      "epoch:7 step:7477 [D loss: 0.197974, acc.: 67.19%] [G loss: 0.555125]\n",
      "epoch:7 step:7478 [D loss: 0.217931, acc.: 67.97%] [G loss: 0.595928]\n",
      "epoch:7 step:7479 [D loss: 0.291050, acc.: 53.12%] [G loss: 0.480031]\n",
      "epoch:7 step:7480 [D loss: 0.210366, acc.: 74.22%] [G loss: 0.512269]\n",
      "epoch:7 step:7481 [D loss: 0.269813, acc.: 46.88%] [G loss: 0.473818]\n",
      "epoch:7 step:7482 [D loss: 0.222109, acc.: 67.19%] [G loss: 0.476598]\n",
      "epoch:7 step:7483 [D loss: 0.167624, acc.: 77.34%] [G loss: 0.563710]\n",
      "epoch:7 step:7484 [D loss: 0.153598, acc.: 81.25%] [G loss: 0.571247]\n",
      "epoch:7 step:7485 [D loss: 0.178165, acc.: 76.56%] [G loss: 0.570709]\n",
      "epoch:7 step:7486 [D loss: 0.197943, acc.: 69.53%] [G loss: 0.593609]\n",
      "epoch:7 step:7487 [D loss: 0.345956, acc.: 57.81%] [G loss: 0.612539]\n",
      "epoch:7 step:7488 [D loss: 0.141902, acc.: 82.03%] [G loss: 0.639928]\n",
      "epoch:7 step:7489 [D loss: 0.242845, acc.: 65.62%] [G loss: 0.543962]\n",
      "epoch:7 step:7490 [D loss: 0.223650, acc.: 67.19%] [G loss: 0.468078]\n",
      "epoch:7 step:7491 [D loss: 0.251330, acc.: 61.72%] [G loss: 0.458564]\n",
      "epoch:7 step:7492 [D loss: 0.221430, acc.: 64.06%] [G loss: 0.521892]\n",
      "epoch:7 step:7493 [D loss: 0.190589, acc.: 68.75%] [G loss: 0.556649]\n",
      "epoch:7 step:7494 [D loss: 0.227157, acc.: 70.31%] [G loss: 0.507676]\n",
      "epoch:7 step:7495 [D loss: 0.155378, acc.: 80.47%] [G loss: 0.563752]\n",
      "epoch:7 step:7496 [D loss: 0.158685, acc.: 82.03%] [G loss: 0.591012]\n",
      "epoch:8 step:7497 [D loss: 0.281906, acc.: 57.81%] [G loss: 0.521336]\n",
      "epoch:8 step:7498 [D loss: 0.246495, acc.: 57.03%] [G loss: 0.505251]\n",
      "epoch:8 step:7499 [D loss: 0.234888, acc.: 58.59%] [G loss: 0.499896]\n",
      "epoch:8 step:7500 [D loss: 0.236907, acc.: 66.41%] [G loss: 0.488358]\n",
      "epoch:8 step:7501 [D loss: 0.209436, acc.: 62.50%] [G loss: 0.527746]\n",
      "epoch:8 step:7502 [D loss: 0.188357, acc.: 69.53%] [G loss: 0.505040]\n",
      "epoch:8 step:7503 [D loss: 0.225660, acc.: 63.28%] [G loss: 0.483088]\n",
      "epoch:8 step:7504 [D loss: 0.220694, acc.: 70.31%] [G loss: 0.503774]\n",
      "epoch:8 step:7505 [D loss: 0.203243, acc.: 70.31%] [G loss: 0.473721]\n",
      "epoch:8 step:7506 [D loss: 0.231226, acc.: 60.94%] [G loss: 0.504300]\n",
      "epoch:8 step:7507 [D loss: 0.200919, acc.: 72.66%] [G loss: 0.549533]\n",
      "epoch:8 step:7508 [D loss: 0.200410, acc.: 70.31%] [G loss: 0.520402]\n",
      "epoch:8 step:7509 [D loss: 0.180499, acc.: 71.09%] [G loss: 0.497790]\n",
      "epoch:8 step:7510 [D loss: 0.210187, acc.: 69.53%] [G loss: 0.489750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7511 [D loss: 0.195080, acc.: 71.09%] [G loss: 0.521087]\n",
      "epoch:8 step:7512 [D loss: 0.196149, acc.: 72.66%] [G loss: 0.500967]\n",
      "epoch:8 step:7513 [D loss: 0.271854, acc.: 52.34%] [G loss: 0.499238]\n",
      "epoch:8 step:7514 [D loss: 0.238345, acc.: 62.50%] [G loss: 0.467938]\n",
      "epoch:8 step:7515 [D loss: 0.244675, acc.: 59.38%] [G loss: 0.452300]\n",
      "epoch:8 step:7516 [D loss: 0.267336, acc.: 54.69%] [G loss: 0.459760]\n",
      "epoch:8 step:7517 [D loss: 0.228980, acc.: 61.72%] [G loss: 0.471057]\n",
      "epoch:8 step:7518 [D loss: 0.190897, acc.: 71.88%] [G loss: 0.546306]\n",
      "epoch:8 step:7519 [D loss: 0.254239, acc.: 57.81%] [G loss: 0.450322]\n",
      "epoch:8 step:7520 [D loss: 0.221522, acc.: 60.94%] [G loss: 0.445763]\n",
      "epoch:8 step:7521 [D loss: 0.178472, acc.: 74.22%] [G loss: 0.494958]\n",
      "epoch:8 step:7522 [D loss: 0.226583, acc.: 60.94%] [G loss: 0.417036]\n",
      "epoch:8 step:7523 [D loss: 0.213598, acc.: 68.75%] [G loss: 0.430557]\n",
      "epoch:8 step:7524 [D loss: 0.232881, acc.: 63.28%] [G loss: 0.454545]\n",
      "epoch:8 step:7525 [D loss: 0.219402, acc.: 64.84%] [G loss: 0.490013]\n",
      "epoch:8 step:7526 [D loss: 0.231869, acc.: 60.16%] [G loss: 0.470337]\n",
      "epoch:8 step:7527 [D loss: 0.249564, acc.: 60.16%] [G loss: 0.452628]\n",
      "epoch:8 step:7528 [D loss: 0.207030, acc.: 61.72%] [G loss: 0.477894]\n",
      "epoch:8 step:7529 [D loss: 0.210469, acc.: 67.97%] [G loss: 0.469480]\n",
      "epoch:8 step:7530 [D loss: 0.231023, acc.: 66.41%] [G loss: 0.447875]\n",
      "epoch:8 step:7531 [D loss: 0.190135, acc.: 68.75%] [G loss: 0.459858]\n",
      "epoch:8 step:7532 [D loss: 0.229765, acc.: 67.19%] [G loss: 0.457515]\n",
      "epoch:8 step:7533 [D loss: 0.209089, acc.: 68.75%] [G loss: 0.501983]\n",
      "epoch:8 step:7534 [D loss: 0.259001, acc.: 56.25%] [G loss: 0.423826]\n",
      "epoch:8 step:7535 [D loss: 0.191656, acc.: 74.22%] [G loss: 0.481253]\n",
      "epoch:8 step:7536 [D loss: 0.174997, acc.: 74.22%] [G loss: 0.540311]\n",
      "epoch:8 step:7537 [D loss: 0.221384, acc.: 64.84%] [G loss: 0.535253]\n",
      "epoch:8 step:7538 [D loss: 0.218252, acc.: 67.19%] [G loss: 0.464886]\n",
      "epoch:8 step:7539 [D loss: 0.206597, acc.: 70.31%] [G loss: 0.450873]\n",
      "epoch:8 step:7540 [D loss: 0.239609, acc.: 58.59%] [G loss: 0.492635]\n",
      "epoch:8 step:7541 [D loss: 0.216974, acc.: 62.50%] [G loss: 0.488176]\n",
      "epoch:8 step:7542 [D loss: 0.222341, acc.: 67.19%] [G loss: 0.509115]\n",
      "epoch:8 step:7543 [D loss: 0.199470, acc.: 69.53%] [G loss: 0.507220]\n",
      "epoch:8 step:7544 [D loss: 0.182017, acc.: 75.78%] [G loss: 0.518460]\n",
      "epoch:8 step:7545 [D loss: 0.211528, acc.: 68.75%] [G loss: 0.494092]\n",
      "epoch:8 step:7546 [D loss: 0.212120, acc.: 67.19%] [G loss: 0.480291]\n",
      "epoch:8 step:7547 [D loss: 0.232231, acc.: 63.28%] [G loss: 0.463616]\n",
      "epoch:8 step:7548 [D loss: 0.201449, acc.: 67.97%] [G loss: 0.475216]\n",
      "epoch:8 step:7549 [D loss: 0.189865, acc.: 73.44%] [G loss: 0.513837]\n",
      "epoch:8 step:7550 [D loss: 0.210354, acc.: 64.06%] [G loss: 0.526668]\n",
      "epoch:8 step:7551 [D loss: 0.217111, acc.: 66.41%] [G loss: 0.545068]\n",
      "epoch:8 step:7552 [D loss: 0.215334, acc.: 64.84%] [G loss: 0.501025]\n",
      "epoch:8 step:7553 [D loss: 0.217463, acc.: 66.41%] [G loss: 0.465174]\n",
      "epoch:8 step:7554 [D loss: 0.189470, acc.: 72.66%] [G loss: 0.494011]\n",
      "epoch:8 step:7555 [D loss: 0.198232, acc.: 69.53%] [G loss: 0.506271]\n",
      "epoch:8 step:7556 [D loss: 0.250106, acc.: 55.47%] [G loss: 0.432775]\n",
      "epoch:8 step:7557 [D loss: 0.245711, acc.: 54.69%] [G loss: 0.477009]\n",
      "epoch:8 step:7558 [D loss: 0.213322, acc.: 72.66%] [G loss: 0.461265]\n",
      "epoch:8 step:7559 [D loss: 0.196326, acc.: 73.44%] [G loss: 0.504450]\n",
      "epoch:8 step:7560 [D loss: 0.255472, acc.: 54.69%] [G loss: 0.442931]\n",
      "epoch:8 step:7561 [D loss: 0.206927, acc.: 69.53%] [G loss: 0.470144]\n",
      "epoch:8 step:7562 [D loss: 0.196753, acc.: 67.97%] [G loss: 0.514370]\n",
      "epoch:8 step:7563 [D loss: 0.225328, acc.: 64.06%] [G loss: 0.479341]\n",
      "epoch:8 step:7564 [D loss: 0.210712, acc.: 68.75%] [G loss: 0.463362]\n",
      "epoch:8 step:7565 [D loss: 0.197104, acc.: 74.22%] [G loss: 0.494704]\n",
      "epoch:8 step:7566 [D loss: 0.208885, acc.: 64.06%] [G loss: 0.481396]\n",
      "epoch:8 step:7567 [D loss: 0.226199, acc.: 63.28%] [G loss: 0.503532]\n",
      "epoch:8 step:7568 [D loss: 0.205263, acc.: 64.84%] [G loss: 0.509872]\n",
      "epoch:8 step:7569 [D loss: 0.245818, acc.: 55.47%] [G loss: 0.431950]\n",
      "epoch:8 step:7570 [D loss: 0.193017, acc.: 67.97%] [G loss: 0.504677]\n",
      "epoch:8 step:7571 [D loss: 0.234636, acc.: 62.50%] [G loss: 0.470811]\n",
      "epoch:8 step:7572 [D loss: 0.196806, acc.: 67.19%] [G loss: 0.492017]\n",
      "epoch:8 step:7573 [D loss: 0.187218, acc.: 67.97%] [G loss: 0.529937]\n",
      "epoch:8 step:7574 [D loss: 0.278162, acc.: 52.34%] [G loss: 0.440540]\n",
      "epoch:8 step:7575 [D loss: 0.246604, acc.: 57.03%] [G loss: 0.439437]\n",
      "epoch:8 step:7576 [D loss: 0.224719, acc.: 65.62%] [G loss: 0.427781]\n",
      "epoch:8 step:7577 [D loss: 0.226960, acc.: 60.16%] [G loss: 0.471072]\n",
      "epoch:8 step:7578 [D loss: 0.209700, acc.: 70.31%] [G loss: 0.516857]\n",
      "epoch:8 step:7579 [D loss: 0.208065, acc.: 67.19%] [G loss: 0.531208]\n",
      "epoch:8 step:7580 [D loss: 0.208327, acc.: 64.06%] [G loss: 0.523194]\n",
      "epoch:8 step:7581 [D loss: 0.209723, acc.: 69.53%] [G loss: 0.493531]\n",
      "epoch:8 step:7582 [D loss: 0.236174, acc.: 57.81%] [G loss: 0.410780]\n",
      "epoch:8 step:7583 [D loss: 0.223822, acc.: 67.19%] [G loss: 0.441810]\n",
      "epoch:8 step:7584 [D loss: 0.190723, acc.: 68.75%] [G loss: 0.487084]\n",
      "epoch:8 step:7585 [D loss: 0.188713, acc.: 72.66%] [G loss: 0.535853]\n",
      "epoch:8 step:7586 [D loss: 0.206186, acc.: 66.41%] [G loss: 0.470787]\n",
      "epoch:8 step:7587 [D loss: 0.238280, acc.: 60.94%] [G loss: 0.448994]\n",
      "epoch:8 step:7588 [D loss: 0.192967, acc.: 71.88%] [G loss: 0.484857]\n",
      "epoch:8 step:7589 [D loss: 0.220742, acc.: 60.16%] [G loss: 0.490080]\n",
      "epoch:8 step:7590 [D loss: 0.221328, acc.: 64.84%] [G loss: 0.491740]\n",
      "epoch:8 step:7591 [D loss: 0.200894, acc.: 72.66%] [G loss: 0.515072]\n",
      "epoch:8 step:7592 [D loss: 0.191834, acc.: 71.88%] [G loss: 0.500880]\n",
      "epoch:8 step:7593 [D loss: 0.189202, acc.: 67.19%] [G loss: 0.493904]\n",
      "epoch:8 step:7594 [D loss: 0.236590, acc.: 60.94%] [G loss: 0.450108]\n",
      "epoch:8 step:7595 [D loss: 0.218075, acc.: 67.97%] [G loss: 0.480683]\n",
      "epoch:8 step:7596 [D loss: 0.168859, acc.: 72.66%] [G loss: 0.550394]\n",
      "epoch:8 step:7597 [D loss: 0.218563, acc.: 67.97%] [G loss: 0.492167]\n",
      "epoch:8 step:7598 [D loss: 0.237302, acc.: 63.28%] [G loss: 0.483123]\n",
      "epoch:8 step:7599 [D loss: 0.209446, acc.: 66.41%] [G loss: 0.476501]\n",
      "epoch:8 step:7600 [D loss: 0.227814, acc.: 66.41%] [G loss: 0.456831]\n",
      "epoch:8 step:7601 [D loss: 0.253786, acc.: 58.59%] [G loss: 0.414012]\n",
      "epoch:8 step:7602 [D loss: 0.245335, acc.: 56.25%] [G loss: 0.459797]\n",
      "epoch:8 step:7603 [D loss: 0.200926, acc.: 75.00%] [G loss: 0.531477]\n",
      "epoch:8 step:7604 [D loss: 0.278250, acc.: 49.22%] [G loss: 0.518018]\n",
      "epoch:8 step:7605 [D loss: 0.259930, acc.: 55.47%] [G loss: 0.427639]\n",
      "epoch:8 step:7606 [D loss: 0.252242, acc.: 60.16%] [G loss: 0.447396]\n",
      "epoch:8 step:7607 [D loss: 0.191023, acc.: 71.88%] [G loss: 0.532768]\n",
      "epoch:8 step:7608 [D loss: 0.216276, acc.: 69.53%] [G loss: 0.493786]\n",
      "epoch:8 step:7609 [D loss: 0.227238, acc.: 62.50%] [G loss: 0.471145]\n",
      "epoch:8 step:7610 [D loss: 0.201236, acc.: 67.97%] [G loss: 0.558527]\n",
      "epoch:8 step:7611 [D loss: 0.211152, acc.: 67.19%] [G loss: 0.533340]\n",
      "epoch:8 step:7612 [D loss: 0.222031, acc.: 63.28%] [G loss: 0.533827]\n",
      "epoch:8 step:7613 [D loss: 0.202199, acc.: 70.31%] [G loss: 0.511273]\n",
      "epoch:8 step:7614 [D loss: 0.219667, acc.: 60.94%] [G loss: 0.525048]\n",
      "epoch:8 step:7615 [D loss: 0.170073, acc.: 77.34%] [G loss: 0.559342]\n",
      "epoch:8 step:7616 [D loss: 0.241519, acc.: 64.06%] [G loss: 0.517008]\n",
      "epoch:8 step:7617 [D loss: 0.234230, acc.: 59.38%] [G loss: 0.478781]\n",
      "epoch:8 step:7618 [D loss: 0.188347, acc.: 67.19%] [G loss: 0.524313]\n",
      "epoch:8 step:7619 [D loss: 0.219470, acc.: 65.62%] [G loss: 0.483696]\n",
      "epoch:8 step:7620 [D loss: 0.227320, acc.: 57.81%] [G loss: 0.505610]\n",
      "epoch:8 step:7621 [D loss: 0.250791, acc.: 53.12%] [G loss: 0.464465]\n",
      "epoch:8 step:7622 [D loss: 0.202769, acc.: 67.97%] [G loss: 0.452834]\n",
      "epoch:8 step:7623 [D loss: 0.220573, acc.: 61.72%] [G loss: 0.507796]\n",
      "epoch:8 step:7624 [D loss: 0.245509, acc.: 58.59%] [G loss: 0.461340]\n",
      "epoch:8 step:7625 [D loss: 0.233827, acc.: 62.50%] [G loss: 0.494104]\n",
      "epoch:8 step:7626 [D loss: 0.195037, acc.: 76.56%] [G loss: 0.505043]\n",
      "epoch:8 step:7627 [D loss: 0.217229, acc.: 62.50%] [G loss: 0.496279]\n",
      "epoch:8 step:7628 [D loss: 0.227616, acc.: 62.50%] [G loss: 0.470011]\n",
      "epoch:8 step:7629 [D loss: 0.257367, acc.: 54.69%] [G loss: 0.515583]\n",
      "epoch:8 step:7630 [D loss: 0.217051, acc.: 66.41%] [G loss: 0.465503]\n",
      "epoch:8 step:7631 [D loss: 0.201217, acc.: 71.09%] [G loss: 0.479839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7632 [D loss: 0.223772, acc.: 63.28%] [G loss: 0.489705]\n",
      "epoch:8 step:7633 [D loss: 0.248664, acc.: 60.94%] [G loss: 0.446621]\n",
      "epoch:8 step:7634 [D loss: 0.211809, acc.: 65.62%] [G loss: 0.427335]\n",
      "epoch:8 step:7635 [D loss: 0.215747, acc.: 62.50%] [G loss: 0.434998]\n",
      "epoch:8 step:7636 [D loss: 0.232260, acc.: 60.94%] [G loss: 0.467842]\n",
      "epoch:8 step:7637 [D loss: 0.226186, acc.: 61.72%] [G loss: 0.465333]\n",
      "epoch:8 step:7638 [D loss: 0.235390, acc.: 56.25%] [G loss: 0.427689]\n",
      "epoch:8 step:7639 [D loss: 0.249013, acc.: 56.25%] [G loss: 0.411862]\n",
      "epoch:8 step:7640 [D loss: 0.206028, acc.: 69.53%] [G loss: 0.459207]\n",
      "epoch:8 step:7641 [D loss: 0.248347, acc.: 53.12%] [G loss: 0.440380]\n",
      "epoch:8 step:7642 [D loss: 0.223050, acc.: 61.72%] [G loss: 0.521456]\n",
      "epoch:8 step:7643 [D loss: 0.224293, acc.: 67.19%] [G loss: 0.486417]\n",
      "epoch:8 step:7644 [D loss: 0.213302, acc.: 66.41%] [G loss: 0.501502]\n",
      "epoch:8 step:7645 [D loss: 0.209561, acc.: 71.09%] [G loss: 0.482275]\n",
      "epoch:8 step:7646 [D loss: 0.255360, acc.: 55.47%] [G loss: 0.454222]\n",
      "epoch:8 step:7647 [D loss: 0.209661, acc.: 71.09%] [G loss: 0.514751]\n",
      "epoch:8 step:7648 [D loss: 0.225921, acc.: 66.41%] [G loss: 0.481494]\n",
      "epoch:8 step:7649 [D loss: 0.210922, acc.: 64.06%] [G loss: 0.505311]\n",
      "epoch:8 step:7650 [D loss: 0.231403, acc.: 60.94%] [G loss: 0.457497]\n",
      "epoch:8 step:7651 [D loss: 0.192574, acc.: 73.44%] [G loss: 0.512803]\n",
      "epoch:8 step:7652 [D loss: 0.203939, acc.: 67.97%] [G loss: 0.545903]\n",
      "epoch:8 step:7653 [D loss: 0.245009, acc.: 62.50%] [G loss: 0.490792]\n",
      "epoch:8 step:7654 [D loss: 0.220053, acc.: 59.38%] [G loss: 0.460075]\n",
      "epoch:8 step:7655 [D loss: 0.205332, acc.: 71.88%] [G loss: 0.554367]\n",
      "epoch:8 step:7656 [D loss: 0.275671, acc.: 55.47%] [G loss: 0.470503]\n",
      "epoch:8 step:7657 [D loss: 0.207994, acc.: 68.75%] [G loss: 0.536587]\n",
      "epoch:8 step:7658 [D loss: 0.232338, acc.: 61.72%] [G loss: 0.498851]\n",
      "epoch:8 step:7659 [D loss: 0.246206, acc.: 58.59%] [G loss: 0.464995]\n",
      "epoch:8 step:7660 [D loss: 0.237893, acc.: 57.81%] [G loss: 0.455396]\n",
      "epoch:8 step:7661 [D loss: 0.219347, acc.: 63.28%] [G loss: 0.460192]\n",
      "epoch:8 step:7662 [D loss: 0.233520, acc.: 64.06%] [G loss: 0.509948]\n",
      "epoch:8 step:7663 [D loss: 0.216098, acc.: 63.28%] [G loss: 0.484203]\n",
      "epoch:8 step:7664 [D loss: 0.220339, acc.: 67.19%] [G loss: 0.455685]\n",
      "epoch:8 step:7665 [D loss: 0.226647, acc.: 64.06%] [G loss: 0.470813]\n",
      "epoch:8 step:7666 [D loss: 0.246372, acc.: 57.03%] [G loss: 0.448471]\n",
      "epoch:8 step:7667 [D loss: 0.233192, acc.: 57.03%] [G loss: 0.497523]\n",
      "epoch:8 step:7668 [D loss: 0.212109, acc.: 66.41%] [G loss: 0.498935]\n",
      "epoch:8 step:7669 [D loss: 0.199723, acc.: 67.19%] [G loss: 0.496859]\n",
      "epoch:8 step:7670 [D loss: 0.256953, acc.: 57.03%] [G loss: 0.452675]\n",
      "epoch:8 step:7671 [D loss: 0.229859, acc.: 64.06%] [G loss: 0.471294]\n",
      "epoch:8 step:7672 [D loss: 0.198977, acc.: 67.97%] [G loss: 0.486783]\n",
      "epoch:8 step:7673 [D loss: 0.231035, acc.: 57.81%] [G loss: 0.484134]\n",
      "epoch:8 step:7674 [D loss: 0.225016, acc.: 64.06%] [G loss: 0.449530]\n",
      "epoch:8 step:7675 [D loss: 0.245899, acc.: 55.47%] [G loss: 0.477810]\n",
      "epoch:8 step:7676 [D loss: 0.232834, acc.: 59.38%] [G loss: 0.488698]\n",
      "epoch:8 step:7677 [D loss: 0.233433, acc.: 62.50%] [G loss: 0.450352]\n",
      "epoch:8 step:7678 [D loss: 0.233184, acc.: 64.06%] [G loss: 0.506107]\n",
      "epoch:8 step:7679 [D loss: 0.238052, acc.: 64.06%] [G loss: 0.479641]\n",
      "epoch:8 step:7680 [D loss: 0.224610, acc.: 64.84%] [G loss: 0.442080]\n",
      "epoch:8 step:7681 [D loss: 0.220311, acc.: 67.19%] [G loss: 0.446692]\n",
      "epoch:8 step:7682 [D loss: 0.230230, acc.: 62.50%] [G loss: 0.455158]\n",
      "epoch:8 step:7683 [D loss: 0.251968, acc.: 55.47%] [G loss: 0.466934]\n",
      "epoch:8 step:7684 [D loss: 0.216337, acc.: 64.84%] [G loss: 0.454117]\n",
      "epoch:8 step:7685 [D loss: 0.263831, acc.: 48.44%] [G loss: 0.435111]\n",
      "epoch:8 step:7686 [D loss: 0.213304, acc.: 65.62%] [G loss: 0.472291]\n",
      "epoch:8 step:7687 [D loss: 0.226154, acc.: 64.84%] [G loss: 0.451190]\n",
      "epoch:8 step:7688 [D loss: 0.195265, acc.: 71.88%] [G loss: 0.483629]\n",
      "epoch:8 step:7689 [D loss: 0.221751, acc.: 60.16%] [G loss: 0.454222]\n",
      "epoch:8 step:7690 [D loss: 0.177304, acc.: 75.00%] [G loss: 0.493906]\n",
      "epoch:8 step:7691 [D loss: 0.222444, acc.: 60.94%] [G loss: 0.481483]\n",
      "epoch:8 step:7692 [D loss: 0.226784, acc.: 64.06%] [G loss: 0.503066]\n",
      "epoch:8 step:7693 [D loss: 0.218696, acc.: 68.75%] [G loss: 0.472956]\n",
      "epoch:8 step:7694 [D loss: 0.172334, acc.: 71.09%] [G loss: 0.539816]\n",
      "epoch:8 step:7695 [D loss: 0.226916, acc.: 63.28%] [G loss: 0.508157]\n",
      "epoch:8 step:7696 [D loss: 0.247916, acc.: 57.81%] [G loss: 0.455857]\n",
      "epoch:8 step:7697 [D loss: 0.241485, acc.: 62.50%] [G loss: 0.427099]\n",
      "epoch:8 step:7698 [D loss: 0.200070, acc.: 72.66%] [G loss: 0.510093]\n",
      "epoch:8 step:7699 [D loss: 0.244474, acc.: 58.59%] [G loss: 0.513419]\n",
      "epoch:8 step:7700 [D loss: 0.222264, acc.: 62.50%] [G loss: 0.494258]\n",
      "epoch:8 step:7701 [D loss: 0.190914, acc.: 73.44%] [G loss: 0.532947]\n",
      "epoch:8 step:7702 [D loss: 0.199961, acc.: 69.53%] [G loss: 0.501403]\n",
      "epoch:8 step:7703 [D loss: 0.204434, acc.: 68.75%] [G loss: 0.506716]\n",
      "epoch:8 step:7704 [D loss: 0.197858, acc.: 68.75%] [G loss: 0.567264]\n",
      "epoch:8 step:7705 [D loss: 0.200571, acc.: 67.19%] [G loss: 0.541355]\n",
      "epoch:8 step:7706 [D loss: 0.264707, acc.: 55.47%] [G loss: 0.443837]\n",
      "epoch:8 step:7707 [D loss: 0.247264, acc.: 56.25%] [G loss: 0.426796]\n",
      "epoch:8 step:7708 [D loss: 0.253967, acc.: 61.72%] [G loss: 0.455372]\n",
      "epoch:8 step:7709 [D loss: 0.251899, acc.: 60.94%] [G loss: 0.406736]\n",
      "epoch:8 step:7710 [D loss: 0.254739, acc.: 53.12%] [G loss: 0.424149]\n",
      "epoch:8 step:7711 [D loss: 0.239894, acc.: 60.16%] [G loss: 0.429870]\n",
      "epoch:8 step:7712 [D loss: 0.219190, acc.: 66.41%] [G loss: 0.481632]\n",
      "epoch:8 step:7713 [D loss: 0.214686, acc.: 65.62%] [G loss: 0.492754]\n",
      "epoch:8 step:7714 [D loss: 0.199135, acc.: 71.09%] [G loss: 0.486928]\n",
      "epoch:8 step:7715 [D loss: 0.191917, acc.: 69.53%] [G loss: 0.498680]\n",
      "epoch:8 step:7716 [D loss: 0.280263, acc.: 53.12%] [G loss: 0.461085]\n",
      "epoch:8 step:7717 [D loss: 0.179215, acc.: 70.31%] [G loss: 0.516125]\n",
      "epoch:8 step:7718 [D loss: 0.202227, acc.: 68.75%] [G loss: 0.514302]\n",
      "epoch:8 step:7719 [D loss: 0.214325, acc.: 68.75%] [G loss: 0.486950]\n",
      "epoch:8 step:7720 [D loss: 0.253722, acc.: 60.16%] [G loss: 0.461377]\n",
      "epoch:8 step:7721 [D loss: 0.229464, acc.: 61.72%] [G loss: 0.443365]\n",
      "epoch:8 step:7722 [D loss: 0.241530, acc.: 57.81%] [G loss: 0.423122]\n",
      "epoch:8 step:7723 [D loss: 0.216919, acc.: 65.62%] [G loss: 0.459975]\n",
      "epoch:8 step:7724 [D loss: 0.252240, acc.: 55.47%] [G loss: 0.440879]\n",
      "epoch:8 step:7725 [D loss: 0.202162, acc.: 67.97%] [G loss: 0.457710]\n",
      "epoch:8 step:7726 [D loss: 0.178620, acc.: 69.53%] [G loss: 0.514451]\n",
      "epoch:8 step:7727 [D loss: 0.190555, acc.: 70.31%] [G loss: 0.578324]\n",
      "epoch:8 step:7728 [D loss: 0.170810, acc.: 77.34%] [G loss: 0.572411]\n",
      "epoch:8 step:7729 [D loss: 0.243091, acc.: 62.50%] [G loss: 0.504854]\n",
      "epoch:8 step:7730 [D loss: 0.237970, acc.: 59.38%] [G loss: 0.465493]\n",
      "epoch:8 step:7731 [D loss: 0.221402, acc.: 66.41%] [G loss: 0.467721]\n",
      "epoch:8 step:7732 [D loss: 0.201507, acc.: 72.66%] [G loss: 0.499689]\n",
      "epoch:8 step:7733 [D loss: 0.227404, acc.: 58.59%] [G loss: 0.448120]\n",
      "epoch:8 step:7734 [D loss: 0.216366, acc.: 67.19%] [G loss: 0.484897]\n",
      "epoch:8 step:7735 [D loss: 0.212081, acc.: 67.97%] [G loss: 0.511149]\n",
      "epoch:8 step:7736 [D loss: 0.217994, acc.: 62.50%] [G loss: 0.464949]\n",
      "epoch:8 step:7737 [D loss: 0.199422, acc.: 72.66%] [G loss: 0.485625]\n",
      "epoch:8 step:7738 [D loss: 0.190949, acc.: 70.31%] [G loss: 0.530754]\n",
      "epoch:8 step:7739 [D loss: 0.206130, acc.: 66.41%] [G loss: 0.525648]\n",
      "epoch:8 step:7740 [D loss: 0.213259, acc.: 65.62%] [G loss: 0.488641]\n",
      "epoch:8 step:7741 [D loss: 0.204676, acc.: 64.06%] [G loss: 0.491876]\n",
      "epoch:8 step:7742 [D loss: 0.215627, acc.: 65.62%] [G loss: 0.504612]\n",
      "epoch:8 step:7743 [D loss: 0.240738, acc.: 65.62%] [G loss: 0.528852]\n",
      "epoch:8 step:7744 [D loss: 0.209408, acc.: 62.50%] [G loss: 0.480733]\n",
      "epoch:8 step:7745 [D loss: 0.248014, acc.: 57.03%] [G loss: 0.488056]\n",
      "epoch:8 step:7746 [D loss: 0.271924, acc.: 55.47%] [G loss: 0.480844]\n",
      "epoch:8 step:7747 [D loss: 0.245392, acc.: 59.38%] [G loss: 0.521183]\n",
      "epoch:8 step:7748 [D loss: 0.223071, acc.: 62.50%] [G loss: 0.502059]\n",
      "epoch:8 step:7749 [D loss: 0.198104, acc.: 64.84%] [G loss: 0.467684]\n",
      "epoch:8 step:7750 [D loss: 0.226066, acc.: 65.62%] [G loss: 0.460602]\n",
      "epoch:8 step:7751 [D loss: 0.221647, acc.: 66.41%] [G loss: 0.485381]\n",
      "epoch:8 step:7752 [D loss: 0.234626, acc.: 61.72%] [G loss: 0.435052]\n",
      "epoch:8 step:7753 [D loss: 0.228968, acc.: 64.84%] [G loss: 0.444630]\n",
      "epoch:8 step:7754 [D loss: 0.234273, acc.: 64.84%] [G loss: 0.459222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7755 [D loss: 0.196960, acc.: 72.66%] [G loss: 0.499551]\n",
      "epoch:8 step:7756 [D loss: 0.235912, acc.: 57.81%] [G loss: 0.474510]\n",
      "epoch:8 step:7757 [D loss: 0.227642, acc.: 61.72%] [G loss: 0.489677]\n",
      "epoch:8 step:7758 [D loss: 0.197793, acc.: 71.88%] [G loss: 0.510653]\n",
      "epoch:8 step:7759 [D loss: 0.233300, acc.: 57.03%] [G loss: 0.480209]\n",
      "epoch:8 step:7760 [D loss: 0.174524, acc.: 73.44%] [G loss: 0.535895]\n",
      "epoch:8 step:7761 [D loss: 0.254946, acc.: 53.91%] [G loss: 0.453210]\n",
      "epoch:8 step:7762 [D loss: 0.229624, acc.: 64.06%] [G loss: 0.475046]\n",
      "epoch:8 step:7763 [D loss: 0.225200, acc.: 59.38%] [G loss: 0.465347]\n",
      "epoch:8 step:7764 [D loss: 0.214370, acc.: 64.84%] [G loss: 0.475457]\n",
      "epoch:8 step:7765 [D loss: 0.213538, acc.: 64.06%] [G loss: 0.462435]\n",
      "epoch:8 step:7766 [D loss: 0.195006, acc.: 72.66%] [G loss: 0.507370]\n",
      "epoch:8 step:7767 [D loss: 0.189920, acc.: 73.44%] [G loss: 0.530685]\n",
      "epoch:8 step:7768 [D loss: 0.243903, acc.: 60.16%] [G loss: 0.465257]\n",
      "epoch:8 step:7769 [D loss: 0.219305, acc.: 57.81%] [G loss: 0.456963]\n",
      "epoch:8 step:7770 [D loss: 0.210422, acc.: 67.19%] [G loss: 0.462869]\n",
      "epoch:8 step:7771 [D loss: 0.245173, acc.: 67.19%] [G loss: 0.485547]\n",
      "epoch:8 step:7772 [D loss: 0.228350, acc.: 62.50%] [G loss: 0.469408]\n",
      "epoch:8 step:7773 [D loss: 0.229843, acc.: 63.28%] [G loss: 0.464643]\n",
      "epoch:8 step:7774 [D loss: 0.225356, acc.: 65.62%] [G loss: 0.470519]\n",
      "epoch:8 step:7775 [D loss: 0.208712, acc.: 67.19%] [G loss: 0.436085]\n",
      "epoch:8 step:7776 [D loss: 0.202489, acc.: 64.84%] [G loss: 0.546955]\n",
      "epoch:8 step:7777 [D loss: 0.271322, acc.: 56.25%] [G loss: 0.443107]\n",
      "epoch:8 step:7778 [D loss: 0.231345, acc.: 64.06%] [G loss: 0.414008]\n",
      "epoch:8 step:7779 [D loss: 0.213038, acc.: 64.84%] [G loss: 0.461301]\n",
      "epoch:8 step:7780 [D loss: 0.204278, acc.: 66.41%] [G loss: 0.493317]\n",
      "epoch:8 step:7781 [D loss: 0.219393, acc.: 64.84%] [G loss: 0.508312]\n",
      "epoch:8 step:7782 [D loss: 0.228717, acc.: 65.62%] [G loss: 0.482035]\n",
      "epoch:8 step:7783 [D loss: 0.219661, acc.: 65.62%] [G loss: 0.522650]\n",
      "epoch:8 step:7784 [D loss: 0.223090, acc.: 61.72%] [G loss: 0.470523]\n",
      "epoch:8 step:7785 [D loss: 0.238677, acc.: 61.72%] [G loss: 0.509172]\n",
      "epoch:8 step:7786 [D loss: 0.229822, acc.: 59.38%] [G loss: 0.500463]\n",
      "epoch:8 step:7787 [D loss: 0.241588, acc.: 60.94%] [G loss: 0.440920]\n",
      "epoch:8 step:7788 [D loss: 0.205812, acc.: 70.31%] [G loss: 0.471959]\n",
      "epoch:8 step:7789 [D loss: 0.215551, acc.: 64.06%] [G loss: 0.444814]\n",
      "epoch:8 step:7790 [D loss: 0.219207, acc.: 66.41%] [G loss: 0.456721]\n",
      "epoch:8 step:7791 [D loss: 0.220594, acc.: 59.38%] [G loss: 0.449775]\n",
      "epoch:8 step:7792 [D loss: 0.186350, acc.: 75.78%] [G loss: 0.472459]\n",
      "epoch:8 step:7793 [D loss: 0.210578, acc.: 67.19%] [G loss: 0.490585]\n",
      "epoch:8 step:7794 [D loss: 0.193129, acc.: 72.66%] [G loss: 0.502578]\n",
      "epoch:8 step:7795 [D loss: 0.195895, acc.: 72.66%] [G loss: 0.481690]\n",
      "epoch:8 step:7796 [D loss: 0.207000, acc.: 71.88%] [G loss: 0.519457]\n",
      "epoch:8 step:7797 [D loss: 0.299558, acc.: 52.34%] [G loss: 0.443686]\n",
      "epoch:8 step:7798 [D loss: 0.220445, acc.: 65.62%] [G loss: 0.487538]\n",
      "epoch:8 step:7799 [D loss: 0.236021, acc.: 57.03%] [G loss: 0.479211]\n",
      "epoch:8 step:7800 [D loss: 0.227358, acc.: 64.84%] [G loss: 0.496075]\n",
      "epoch:8 step:7801 [D loss: 0.231167, acc.: 60.16%] [G loss: 0.467599]\n",
      "epoch:8 step:7802 [D loss: 0.221511, acc.: 64.84%] [G loss: 0.457367]\n",
      "epoch:8 step:7803 [D loss: 0.206903, acc.: 67.19%] [G loss: 0.478177]\n",
      "epoch:8 step:7804 [D loss: 0.227187, acc.: 64.06%] [G loss: 0.455048]\n",
      "epoch:8 step:7805 [D loss: 0.238154, acc.: 59.38%] [G loss: 0.466331]\n",
      "epoch:8 step:7806 [D loss: 0.211798, acc.: 67.97%] [G loss: 0.455690]\n",
      "epoch:8 step:7807 [D loss: 0.221509, acc.: 60.94%] [G loss: 0.506391]\n",
      "epoch:8 step:7808 [D loss: 0.151456, acc.: 82.81%] [G loss: 0.557740]\n",
      "epoch:8 step:7809 [D loss: 0.162915, acc.: 78.12%] [G loss: 0.540926]\n",
      "epoch:8 step:7810 [D loss: 0.153612, acc.: 78.91%] [G loss: 0.508134]\n",
      "epoch:8 step:7811 [D loss: 0.202739, acc.: 67.19%] [G loss: 0.514374]\n",
      "epoch:8 step:7812 [D loss: 0.272382, acc.: 57.03%] [G loss: 0.477618]\n",
      "epoch:8 step:7813 [D loss: 0.222911, acc.: 65.62%] [G loss: 0.434917]\n",
      "epoch:8 step:7814 [D loss: 0.210193, acc.: 66.41%] [G loss: 0.455518]\n",
      "epoch:8 step:7815 [D loss: 0.224153, acc.: 62.50%] [G loss: 0.467731]\n",
      "epoch:8 step:7816 [D loss: 0.206873, acc.: 64.06%] [G loss: 0.492093]\n",
      "epoch:8 step:7817 [D loss: 0.164919, acc.: 77.34%] [G loss: 0.518526]\n",
      "epoch:8 step:7818 [D loss: 0.219670, acc.: 60.16%] [G loss: 0.512869]\n",
      "epoch:8 step:7819 [D loss: 0.243757, acc.: 62.50%] [G loss: 0.467015]\n",
      "epoch:8 step:7820 [D loss: 0.222417, acc.: 63.28%] [G loss: 0.486386]\n",
      "epoch:8 step:7821 [D loss: 0.216664, acc.: 66.41%] [G loss: 0.449731]\n",
      "epoch:8 step:7822 [D loss: 0.247575, acc.: 60.16%] [G loss: 0.461289]\n",
      "epoch:8 step:7823 [D loss: 0.221199, acc.: 59.38%] [G loss: 0.497256]\n",
      "epoch:8 step:7824 [D loss: 0.232877, acc.: 65.62%] [G loss: 0.534946]\n",
      "epoch:8 step:7825 [D loss: 0.227725, acc.: 56.25%] [G loss: 0.510818]\n",
      "epoch:8 step:7826 [D loss: 0.221590, acc.: 61.72%] [G loss: 0.489318]\n",
      "epoch:8 step:7827 [D loss: 0.210672, acc.: 66.41%] [G loss: 0.446694]\n",
      "epoch:8 step:7828 [D loss: 0.192365, acc.: 72.66%] [G loss: 0.489538]\n",
      "epoch:8 step:7829 [D loss: 0.197451, acc.: 62.50%] [G loss: 0.479877]\n",
      "epoch:8 step:7830 [D loss: 0.236814, acc.: 67.19%] [G loss: 0.468544]\n",
      "epoch:8 step:7831 [D loss: 0.202066, acc.: 64.06%] [G loss: 0.479117]\n",
      "epoch:8 step:7832 [D loss: 0.207934, acc.: 68.75%] [G loss: 0.468139]\n",
      "epoch:8 step:7833 [D loss: 0.208944, acc.: 67.97%] [G loss: 0.513832]\n",
      "epoch:8 step:7834 [D loss: 0.204083, acc.: 68.75%] [G loss: 0.485633]\n",
      "epoch:8 step:7835 [D loss: 0.194974, acc.: 71.09%] [G loss: 0.495321]\n",
      "epoch:8 step:7836 [D loss: 0.211288, acc.: 66.41%] [G loss: 0.448894]\n",
      "epoch:8 step:7837 [D loss: 0.276203, acc.: 53.91%] [G loss: 0.473180]\n",
      "epoch:8 step:7838 [D loss: 0.230721, acc.: 64.06%] [G loss: 0.519007]\n",
      "epoch:8 step:7839 [D loss: 0.205185, acc.: 65.62%] [G loss: 0.498126]\n",
      "epoch:8 step:7840 [D loss: 0.205744, acc.: 67.19%] [G loss: 0.516460]\n",
      "epoch:8 step:7841 [D loss: 0.207642, acc.: 70.31%] [G loss: 0.495834]\n",
      "epoch:8 step:7842 [D loss: 0.186322, acc.: 73.44%] [G loss: 0.536607]\n",
      "epoch:8 step:7843 [D loss: 0.153501, acc.: 76.56%] [G loss: 0.633628]\n",
      "epoch:8 step:7844 [D loss: 0.297872, acc.: 53.91%] [G loss: 0.448133]\n",
      "epoch:8 step:7845 [D loss: 0.258893, acc.: 54.69%] [G loss: 0.438648]\n",
      "epoch:8 step:7846 [D loss: 0.188426, acc.: 71.88%] [G loss: 0.489018]\n",
      "epoch:8 step:7847 [D loss: 0.207732, acc.: 69.53%] [G loss: 0.481915]\n",
      "epoch:8 step:7848 [D loss: 0.226508, acc.: 61.72%] [G loss: 0.474087]\n",
      "epoch:8 step:7849 [D loss: 0.203465, acc.: 68.75%] [G loss: 0.509064]\n",
      "epoch:8 step:7850 [D loss: 0.171083, acc.: 72.66%] [G loss: 0.521518]\n",
      "epoch:8 step:7851 [D loss: 0.241459, acc.: 58.59%] [G loss: 0.484441]\n",
      "epoch:8 step:7852 [D loss: 0.240105, acc.: 62.50%] [G loss: 0.465184]\n",
      "epoch:8 step:7853 [D loss: 0.210909, acc.: 67.97%] [G loss: 0.496134]\n",
      "epoch:8 step:7854 [D loss: 0.187005, acc.: 76.56%] [G loss: 0.506660]\n",
      "epoch:8 step:7855 [D loss: 0.205406, acc.: 67.97%] [G loss: 0.475192]\n",
      "epoch:8 step:7856 [D loss: 0.193525, acc.: 71.09%] [G loss: 0.478317]\n",
      "epoch:8 step:7857 [D loss: 0.202487, acc.: 68.75%] [G loss: 0.501058]\n",
      "epoch:8 step:7858 [D loss: 0.262384, acc.: 57.81%] [G loss: 0.467691]\n",
      "epoch:8 step:7859 [D loss: 0.209724, acc.: 66.41%] [G loss: 0.470484]\n",
      "epoch:8 step:7860 [D loss: 0.199866, acc.: 66.41%] [G loss: 0.478758]\n",
      "epoch:8 step:7861 [D loss: 0.227406, acc.: 60.94%] [G loss: 0.430138]\n",
      "epoch:8 step:7862 [D loss: 0.204171, acc.: 73.44%] [G loss: 0.445884]\n",
      "epoch:8 step:7863 [D loss: 0.206260, acc.: 69.53%] [G loss: 0.507729]\n",
      "epoch:8 step:7864 [D loss: 0.212540, acc.: 69.53%] [G loss: 0.475239]\n",
      "epoch:8 step:7865 [D loss: 0.234720, acc.: 59.38%] [G loss: 0.448870]\n",
      "epoch:8 step:7866 [D loss: 0.224230, acc.: 61.72%] [G loss: 0.435137]\n",
      "epoch:8 step:7867 [D loss: 0.197906, acc.: 71.09%] [G loss: 0.534366]\n",
      "epoch:8 step:7868 [D loss: 0.242791, acc.: 61.72%] [G loss: 0.494524]\n",
      "epoch:8 step:7869 [D loss: 0.262329, acc.: 52.34%] [G loss: 0.502135]\n",
      "epoch:8 step:7870 [D loss: 0.194304, acc.: 69.53%] [G loss: 0.491630]\n",
      "epoch:8 step:7871 [D loss: 0.233624, acc.: 57.81%] [G loss: 0.462521]\n",
      "epoch:8 step:7872 [D loss: 0.262519, acc.: 57.81%] [G loss: 0.427539]\n",
      "epoch:8 step:7873 [D loss: 0.289028, acc.: 47.66%] [G loss: 0.393747]\n",
      "epoch:8 step:7874 [D loss: 0.217323, acc.: 66.41%] [G loss: 0.479728]\n",
      "epoch:8 step:7875 [D loss: 0.214196, acc.: 64.84%] [G loss: 0.466528]\n",
      "epoch:8 step:7876 [D loss: 0.236633, acc.: 66.41%] [G loss: 0.443131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7877 [D loss: 0.157667, acc.: 78.91%] [G loss: 0.511528]\n",
      "epoch:8 step:7878 [D loss: 0.234738, acc.: 62.50%] [G loss: 0.451161]\n",
      "epoch:8 step:7879 [D loss: 0.230318, acc.: 59.38%] [G loss: 0.446528]\n",
      "epoch:8 step:7880 [D loss: 0.202648, acc.: 71.88%] [G loss: 0.451671]\n",
      "epoch:8 step:7881 [D loss: 0.202436, acc.: 63.28%] [G loss: 0.503927]\n",
      "epoch:8 step:7882 [D loss: 0.218173, acc.: 60.16%] [G loss: 0.482181]\n",
      "epoch:8 step:7883 [D loss: 0.226616, acc.: 67.97%] [G loss: 0.480443]\n",
      "epoch:8 step:7884 [D loss: 0.265041, acc.: 53.12%] [G loss: 0.493841]\n",
      "epoch:8 step:7885 [D loss: 0.209190, acc.: 63.28%] [G loss: 0.531467]\n",
      "epoch:8 step:7886 [D loss: 0.254310, acc.: 51.56%] [G loss: 0.445275]\n",
      "epoch:8 step:7887 [D loss: 0.218495, acc.: 64.06%] [G loss: 0.440172]\n",
      "epoch:8 step:7888 [D loss: 0.194932, acc.: 71.09%] [G loss: 0.513855]\n",
      "epoch:8 step:7889 [D loss: 0.228910, acc.: 64.84%] [G loss: 0.457998]\n",
      "epoch:8 step:7890 [D loss: 0.225990, acc.: 64.06%] [G loss: 0.480081]\n",
      "epoch:8 step:7891 [D loss: 0.226794, acc.: 60.16%] [G loss: 0.448044]\n",
      "epoch:8 step:7892 [D loss: 0.262354, acc.: 51.56%] [G loss: 0.475376]\n",
      "epoch:8 step:7893 [D loss: 0.233072, acc.: 61.72%] [G loss: 0.455903]\n",
      "epoch:8 step:7894 [D loss: 0.177519, acc.: 73.44%] [G loss: 0.514379]\n",
      "epoch:8 step:7895 [D loss: 0.194975, acc.: 66.41%] [G loss: 0.503688]\n",
      "epoch:8 step:7896 [D loss: 0.243743, acc.: 53.91%] [G loss: 0.461011]\n",
      "epoch:8 step:7897 [D loss: 0.266499, acc.: 50.00%] [G loss: 0.469607]\n",
      "epoch:8 step:7898 [D loss: 0.194566, acc.: 70.31%] [G loss: 0.488960]\n",
      "epoch:8 step:7899 [D loss: 0.211746, acc.: 63.28%] [G loss: 0.481974]\n",
      "epoch:8 step:7900 [D loss: 0.261984, acc.: 51.56%] [G loss: 0.444510]\n",
      "epoch:8 step:7901 [D loss: 0.266460, acc.: 55.47%] [G loss: 0.446172]\n",
      "epoch:8 step:7902 [D loss: 0.220442, acc.: 66.41%] [G loss: 0.485353]\n",
      "epoch:8 step:7903 [D loss: 0.267692, acc.: 53.91%] [G loss: 0.514870]\n",
      "epoch:8 step:7904 [D loss: 0.235374, acc.: 54.69%] [G loss: 0.479471]\n",
      "epoch:8 step:7905 [D loss: 0.222088, acc.: 63.28%] [G loss: 0.433348]\n",
      "epoch:8 step:7906 [D loss: 0.210128, acc.: 64.06%] [G loss: 0.503669]\n",
      "epoch:8 step:7907 [D loss: 0.232253, acc.: 64.06%] [G loss: 0.443971]\n",
      "epoch:8 step:7908 [D loss: 0.225305, acc.: 64.06%] [G loss: 0.455930]\n",
      "epoch:8 step:7909 [D loss: 0.242161, acc.: 57.81%] [G loss: 0.440475]\n",
      "epoch:8 step:7910 [D loss: 0.219581, acc.: 67.19%] [G loss: 0.484331]\n",
      "epoch:8 step:7911 [D loss: 0.205649, acc.: 68.75%] [G loss: 0.478459]\n",
      "epoch:8 step:7912 [D loss: 0.186426, acc.: 71.09%] [G loss: 0.512378]\n",
      "epoch:8 step:7913 [D loss: 0.230327, acc.: 63.28%] [G loss: 0.506669]\n",
      "epoch:8 step:7914 [D loss: 0.254244, acc.: 54.69%] [G loss: 0.454589]\n",
      "epoch:8 step:7915 [D loss: 0.196407, acc.: 73.44%] [G loss: 0.473568]\n",
      "epoch:8 step:7916 [D loss: 0.233152, acc.: 64.06%] [G loss: 0.465982]\n",
      "epoch:8 step:7917 [D loss: 0.257799, acc.: 60.94%] [G loss: 0.444838]\n",
      "epoch:8 step:7918 [D loss: 0.236452, acc.: 60.16%] [G loss: 0.466938]\n",
      "epoch:8 step:7919 [D loss: 0.248175, acc.: 60.94%] [G loss: 0.456232]\n",
      "epoch:8 step:7920 [D loss: 0.231912, acc.: 60.94%] [G loss: 0.420652]\n",
      "epoch:8 step:7921 [D loss: 0.217499, acc.: 57.81%] [G loss: 0.442999]\n",
      "epoch:8 step:7922 [D loss: 0.192874, acc.: 71.09%] [G loss: 0.515986]\n",
      "epoch:8 step:7923 [D loss: 0.200465, acc.: 69.53%] [G loss: 0.472080]\n",
      "epoch:8 step:7924 [D loss: 0.170642, acc.: 76.56%] [G loss: 0.543663]\n",
      "epoch:8 step:7925 [D loss: 0.200101, acc.: 74.22%] [G loss: 0.501022]\n",
      "epoch:8 step:7926 [D loss: 0.214501, acc.: 64.84%] [G loss: 0.506495]\n",
      "epoch:8 step:7927 [D loss: 0.243257, acc.: 60.16%] [G loss: 0.465800]\n",
      "epoch:8 step:7928 [D loss: 0.231891, acc.: 60.94%] [G loss: 0.453033]\n",
      "epoch:8 step:7929 [D loss: 0.233906, acc.: 60.16%] [G loss: 0.469471]\n",
      "epoch:8 step:7930 [D loss: 0.215383, acc.: 70.31%] [G loss: 0.510099]\n",
      "epoch:8 step:7931 [D loss: 0.213932, acc.: 65.62%] [G loss: 0.510457]\n",
      "epoch:8 step:7932 [D loss: 0.203077, acc.: 70.31%] [G loss: 0.478457]\n",
      "epoch:8 step:7933 [D loss: 0.277749, acc.: 53.12%] [G loss: 0.454786]\n",
      "epoch:8 step:7934 [D loss: 0.240951, acc.: 56.25%] [G loss: 0.446002]\n",
      "epoch:8 step:7935 [D loss: 0.202336, acc.: 69.53%] [G loss: 0.473739]\n",
      "epoch:8 step:7936 [D loss: 0.205692, acc.: 67.19%] [G loss: 0.485236]\n",
      "epoch:8 step:7937 [D loss: 0.202887, acc.: 68.75%] [G loss: 0.428351]\n",
      "epoch:8 step:7938 [D loss: 0.217092, acc.: 67.19%] [G loss: 0.472552]\n",
      "epoch:8 step:7939 [D loss: 0.232985, acc.: 62.50%] [G loss: 0.468077]\n",
      "epoch:8 step:7940 [D loss: 0.203883, acc.: 67.19%] [G loss: 0.487286]\n",
      "epoch:8 step:7941 [D loss: 0.192576, acc.: 69.53%] [G loss: 0.510607]\n",
      "epoch:8 step:7942 [D loss: 0.209420, acc.: 66.41%] [G loss: 0.471966]\n",
      "epoch:8 step:7943 [D loss: 0.234379, acc.: 59.38%] [G loss: 0.481072]\n",
      "epoch:8 step:7944 [D loss: 0.244987, acc.: 57.03%] [G loss: 0.451898]\n",
      "epoch:8 step:7945 [D loss: 0.204331, acc.: 66.41%] [G loss: 0.473184]\n",
      "epoch:8 step:7946 [D loss: 0.236271, acc.: 63.28%] [G loss: 0.453632]\n",
      "epoch:8 step:7947 [D loss: 0.209660, acc.: 67.97%] [G loss: 0.501937]\n",
      "epoch:8 step:7948 [D loss: 0.213734, acc.: 69.53%] [G loss: 0.502530]\n",
      "epoch:8 step:7949 [D loss: 0.212717, acc.: 65.62%] [G loss: 0.486158]\n",
      "epoch:8 step:7950 [D loss: 0.226241, acc.: 65.62%] [G loss: 0.447827]\n",
      "epoch:8 step:7951 [D loss: 0.273427, acc.: 51.56%] [G loss: 0.455489]\n",
      "epoch:8 step:7952 [D loss: 0.218185, acc.: 62.50%] [G loss: 0.491395]\n",
      "epoch:8 step:7953 [D loss: 0.224668, acc.: 62.50%] [G loss: 0.479642]\n",
      "epoch:8 step:7954 [D loss: 0.280722, acc.: 50.78%] [G loss: 0.426369]\n",
      "epoch:8 step:7955 [D loss: 0.245737, acc.: 60.94%] [G loss: 0.499369]\n",
      "epoch:8 step:7956 [D loss: 0.230261, acc.: 63.28%] [G loss: 0.480653]\n",
      "epoch:8 step:7957 [D loss: 0.237401, acc.: 60.94%] [G loss: 0.495679]\n",
      "epoch:8 step:7958 [D loss: 0.240574, acc.: 60.94%] [G loss: 0.475953]\n",
      "epoch:8 step:7959 [D loss: 0.235127, acc.: 58.59%] [G loss: 0.431877]\n",
      "epoch:8 step:7960 [D loss: 0.219032, acc.: 67.97%] [G loss: 0.480280]\n",
      "epoch:8 step:7961 [D loss: 0.262101, acc.: 49.22%] [G loss: 0.442229]\n",
      "epoch:8 step:7962 [D loss: 0.212411, acc.: 65.62%] [G loss: 0.458711]\n",
      "epoch:8 step:7963 [D loss: 0.227510, acc.: 65.62%] [G loss: 0.436660]\n",
      "epoch:8 step:7964 [D loss: 0.234656, acc.: 61.72%] [G loss: 0.471731]\n",
      "epoch:8 step:7965 [D loss: 0.193009, acc.: 68.75%] [G loss: 0.507026]\n",
      "epoch:8 step:7966 [D loss: 0.234049, acc.: 60.94%] [G loss: 0.512140]\n",
      "epoch:8 step:7967 [D loss: 0.186575, acc.: 78.12%] [G loss: 0.533431]\n",
      "epoch:8 step:7968 [D loss: 0.214094, acc.: 65.62%] [G loss: 0.484273]\n",
      "epoch:8 step:7969 [D loss: 0.257097, acc.: 56.25%] [G loss: 0.503518]\n",
      "epoch:8 step:7970 [D loss: 0.185540, acc.: 72.66%] [G loss: 0.518532]\n",
      "epoch:8 step:7971 [D loss: 0.199049, acc.: 68.75%] [G loss: 0.552435]\n",
      "epoch:8 step:7972 [D loss: 0.268634, acc.: 56.25%] [G loss: 0.440985]\n",
      "epoch:8 step:7973 [D loss: 0.280246, acc.: 47.66%] [G loss: 0.442226]\n",
      "epoch:8 step:7974 [D loss: 0.247194, acc.: 61.72%] [G loss: 0.426974]\n",
      "epoch:8 step:7975 [D loss: 0.230118, acc.: 69.53%] [G loss: 0.425903]\n",
      "epoch:8 step:7976 [D loss: 0.232868, acc.: 63.28%] [G loss: 0.517595]\n",
      "epoch:8 step:7977 [D loss: 0.193762, acc.: 71.88%] [G loss: 0.513451]\n",
      "epoch:8 step:7978 [D loss: 0.276847, acc.: 49.22%] [G loss: 0.426163]\n",
      "epoch:8 step:7979 [D loss: 0.242708, acc.: 56.25%] [G loss: 0.434502]\n",
      "epoch:8 step:7980 [D loss: 0.195814, acc.: 74.22%] [G loss: 0.484238]\n",
      "epoch:8 step:7981 [D loss: 0.229849, acc.: 61.72%] [G loss: 0.440268]\n",
      "epoch:8 step:7982 [D loss: 0.242296, acc.: 60.16%] [G loss: 0.467777]\n",
      "epoch:8 step:7983 [D loss: 0.245962, acc.: 57.03%] [G loss: 0.456730]\n",
      "epoch:8 step:7984 [D loss: 0.198996, acc.: 75.00%] [G loss: 0.495480]\n",
      "epoch:8 step:7985 [D loss: 0.231111, acc.: 66.41%] [G loss: 0.470127]\n",
      "epoch:8 step:7986 [D loss: 0.229723, acc.: 59.38%] [G loss: 0.461520]\n",
      "epoch:8 step:7987 [D loss: 0.232739, acc.: 61.72%] [G loss: 0.479027]\n",
      "epoch:8 step:7988 [D loss: 0.253962, acc.: 55.47%] [G loss: 0.496188]\n",
      "epoch:8 step:7989 [D loss: 0.214514, acc.: 63.28%] [G loss: 0.466906]\n",
      "epoch:8 step:7990 [D loss: 0.212445, acc.: 69.53%] [G loss: 0.437634]\n",
      "epoch:8 step:7991 [D loss: 0.167466, acc.: 80.47%] [G loss: 0.508823]\n",
      "epoch:8 step:7992 [D loss: 0.225095, acc.: 62.50%] [G loss: 0.458547]\n",
      "epoch:8 step:7993 [D loss: 0.224407, acc.: 68.75%] [G loss: 0.484048]\n",
      "epoch:8 step:7994 [D loss: 0.202057, acc.: 68.75%] [G loss: 0.486370]\n",
      "epoch:8 step:7995 [D loss: 0.169949, acc.: 78.12%] [G loss: 0.505913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7996 [D loss: 0.280035, acc.: 53.12%] [G loss: 0.490317]\n",
      "epoch:8 step:7997 [D loss: 0.274564, acc.: 57.03%] [G loss: 0.459247]\n",
      "epoch:8 step:7998 [D loss: 0.238078, acc.: 60.94%] [G loss: 0.430813]\n",
      "epoch:8 step:7999 [D loss: 0.219679, acc.: 64.06%] [G loss: 0.426885]\n",
      "epoch:8 step:8000 [D loss: 0.201537, acc.: 65.62%] [G loss: 0.505656]\n",
      "epoch:8 step:8001 [D loss: 0.202455, acc.: 64.84%] [G loss: 0.528374]\n",
      "epoch:8 step:8002 [D loss: 0.228064, acc.: 58.59%] [G loss: 0.503443]\n",
      "epoch:8 step:8003 [D loss: 0.223644, acc.: 64.84%] [G loss: 0.439300]\n",
      "epoch:8 step:8004 [D loss: 0.207732, acc.: 69.53%] [G loss: 0.526520]\n",
      "epoch:8 step:8005 [D loss: 0.250040, acc.: 57.81%] [G loss: 0.490072]\n",
      "epoch:8 step:8006 [D loss: 0.228140, acc.: 61.72%] [G loss: 0.447854]\n",
      "epoch:8 step:8007 [D loss: 0.242847, acc.: 60.16%] [G loss: 0.464338]\n",
      "epoch:8 step:8008 [D loss: 0.232845, acc.: 60.16%] [G loss: 0.467634]\n",
      "epoch:8 step:8009 [D loss: 0.216277, acc.: 68.75%] [G loss: 0.493182]\n",
      "epoch:8 step:8010 [D loss: 0.188638, acc.: 67.19%] [G loss: 0.515701]\n",
      "epoch:8 step:8011 [D loss: 0.219477, acc.: 64.84%] [G loss: 0.522012]\n",
      "epoch:8 step:8012 [D loss: 0.214091, acc.: 64.06%] [G loss: 0.514024]\n",
      "epoch:8 step:8013 [D loss: 0.242224, acc.: 60.16%] [G loss: 0.489053]\n",
      "epoch:8 step:8014 [D loss: 0.207363, acc.: 64.84%] [G loss: 0.512455]\n",
      "epoch:8 step:8015 [D loss: 0.201387, acc.: 68.75%] [G loss: 0.493844]\n",
      "epoch:8 step:8016 [D loss: 0.201132, acc.: 69.53%] [G loss: 0.484570]\n",
      "epoch:8 step:8017 [D loss: 0.245001, acc.: 58.59%] [G loss: 0.446663]\n",
      "epoch:8 step:8018 [D loss: 0.219662, acc.: 61.72%] [G loss: 0.473644]\n",
      "epoch:8 step:8019 [D loss: 0.249329, acc.: 63.28%] [G loss: 0.494331]\n",
      "epoch:8 step:8020 [D loss: 0.241196, acc.: 59.38%] [G loss: 0.465827]\n",
      "epoch:8 step:8021 [D loss: 0.205816, acc.: 68.75%] [G loss: 0.478062]\n",
      "epoch:8 step:8022 [D loss: 0.222094, acc.: 63.28%] [G loss: 0.466139]\n",
      "epoch:8 step:8023 [D loss: 0.227751, acc.: 60.16%] [G loss: 0.448497]\n",
      "epoch:8 step:8024 [D loss: 0.246678, acc.: 56.25%] [G loss: 0.471258]\n",
      "epoch:8 step:8025 [D loss: 0.262495, acc.: 53.91%] [G loss: 0.460003]\n",
      "epoch:8 step:8026 [D loss: 0.224196, acc.: 62.50%] [G loss: 0.476535]\n",
      "epoch:8 step:8027 [D loss: 0.253868, acc.: 59.38%] [G loss: 0.486214]\n",
      "epoch:8 step:8028 [D loss: 0.209364, acc.: 70.31%] [G loss: 0.445197]\n",
      "epoch:8 step:8029 [D loss: 0.208021, acc.: 66.41%] [G loss: 0.474965]\n",
      "epoch:8 step:8030 [D loss: 0.195017, acc.: 67.97%] [G loss: 0.509472]\n",
      "epoch:8 step:8031 [D loss: 0.259621, acc.: 55.47%] [G loss: 0.458073]\n",
      "epoch:8 step:8032 [D loss: 0.205844, acc.: 71.88%] [G loss: 0.433846]\n",
      "epoch:8 step:8033 [D loss: 0.240130, acc.: 63.28%] [G loss: 0.458219]\n",
      "epoch:8 step:8034 [D loss: 0.219106, acc.: 64.84%] [G loss: 0.478200]\n",
      "epoch:8 step:8035 [D loss: 0.200958, acc.: 69.53%] [G loss: 0.506175]\n",
      "epoch:8 step:8036 [D loss: 0.238544, acc.: 58.59%] [G loss: 0.461788]\n",
      "epoch:8 step:8037 [D loss: 0.217062, acc.: 65.62%] [G loss: 0.495751]\n",
      "epoch:8 step:8038 [D loss: 0.280016, acc.: 50.78%] [G loss: 0.509935]\n",
      "epoch:8 step:8039 [D loss: 0.231894, acc.: 64.84%] [G loss: 0.521969]\n",
      "epoch:8 step:8040 [D loss: 0.203319, acc.: 72.66%] [G loss: 0.504092]\n",
      "epoch:8 step:8041 [D loss: 0.245577, acc.: 60.16%] [G loss: 0.473839]\n",
      "epoch:8 step:8042 [D loss: 0.209936, acc.: 66.41%] [G loss: 0.487498]\n",
      "epoch:8 step:8043 [D loss: 0.206923, acc.: 68.75%] [G loss: 0.459399]\n",
      "epoch:8 step:8044 [D loss: 0.220422, acc.: 64.84%] [G loss: 0.493847]\n",
      "epoch:8 step:8045 [D loss: 0.201386, acc.: 67.97%] [G loss: 0.504655]\n",
      "epoch:8 step:8046 [D loss: 0.215697, acc.: 65.62%] [G loss: 0.495840]\n",
      "epoch:8 step:8047 [D loss: 0.210800, acc.: 65.62%] [G loss: 0.549494]\n",
      "epoch:8 step:8048 [D loss: 0.225381, acc.: 62.50%] [G loss: 0.491668]\n",
      "epoch:8 step:8049 [D loss: 0.241927, acc.: 62.50%] [G loss: 0.458524]\n",
      "epoch:8 step:8050 [D loss: 0.178097, acc.: 73.44%] [G loss: 0.492508]\n",
      "epoch:8 step:8051 [D loss: 0.194138, acc.: 72.66%] [G loss: 0.506049]\n",
      "epoch:8 step:8052 [D loss: 0.244768, acc.: 59.38%] [G loss: 0.465043]\n",
      "epoch:8 step:8053 [D loss: 0.200998, acc.: 61.72%] [G loss: 0.456339]\n",
      "epoch:8 step:8054 [D loss: 0.216673, acc.: 65.62%] [G loss: 0.527524]\n",
      "epoch:8 step:8055 [D loss: 0.238725, acc.: 63.28%] [G loss: 0.468008]\n",
      "epoch:8 step:8056 [D loss: 0.228267, acc.: 60.16%] [G loss: 0.464097]\n",
      "epoch:8 step:8057 [D loss: 0.203765, acc.: 68.75%] [G loss: 0.483953]\n",
      "epoch:8 step:8058 [D loss: 0.233337, acc.: 57.81%] [G loss: 0.444959]\n",
      "epoch:8 step:8059 [D loss: 0.210695, acc.: 69.53%] [G loss: 0.495122]\n",
      "epoch:8 step:8060 [D loss: 0.211388, acc.: 64.84%] [G loss: 0.532047]\n",
      "epoch:8 step:8061 [D loss: 0.246201, acc.: 57.81%] [G loss: 0.516399]\n",
      "epoch:8 step:8062 [D loss: 0.275018, acc.: 57.03%] [G loss: 0.460773]\n",
      "epoch:8 step:8063 [D loss: 0.220138, acc.: 65.62%] [G loss: 0.485814]\n",
      "epoch:8 step:8064 [D loss: 0.172885, acc.: 76.56%] [G loss: 0.518214]\n",
      "epoch:8 step:8065 [D loss: 0.249629, acc.: 61.72%] [G loss: 0.427536]\n",
      "epoch:8 step:8066 [D loss: 0.207173, acc.: 67.19%] [G loss: 0.440681]\n",
      "epoch:8 step:8067 [D loss: 0.212798, acc.: 65.62%] [G loss: 0.474640]\n",
      "epoch:8 step:8068 [D loss: 0.239171, acc.: 61.72%] [G loss: 0.489438]\n",
      "epoch:8 step:8069 [D loss: 0.229370, acc.: 58.59%] [G loss: 0.469978]\n",
      "epoch:8 step:8070 [D loss: 0.186184, acc.: 68.75%] [G loss: 0.473642]\n",
      "epoch:8 step:8071 [D loss: 0.203279, acc.: 71.09%] [G loss: 0.512489]\n",
      "epoch:8 step:8072 [D loss: 0.257117, acc.: 63.28%] [G loss: 0.436761]\n",
      "epoch:8 step:8073 [D loss: 0.229428, acc.: 67.19%] [G loss: 0.447776]\n",
      "epoch:8 step:8074 [D loss: 0.225549, acc.: 65.62%] [G loss: 0.424253]\n",
      "epoch:8 step:8075 [D loss: 0.256849, acc.: 59.38%] [G loss: 0.452449]\n",
      "epoch:8 step:8076 [D loss: 0.245109, acc.: 57.03%] [G loss: 0.482880]\n",
      "epoch:8 step:8077 [D loss: 0.216278, acc.: 67.19%] [G loss: 0.463057]\n",
      "epoch:8 step:8078 [D loss: 0.180423, acc.: 74.22%] [G loss: 0.506092]\n",
      "epoch:8 step:8079 [D loss: 0.217386, acc.: 66.41%] [G loss: 0.471546]\n",
      "epoch:8 step:8080 [D loss: 0.250401, acc.: 53.91%] [G loss: 0.459342]\n",
      "epoch:8 step:8081 [D loss: 0.224758, acc.: 64.84%] [G loss: 0.489462]\n",
      "epoch:8 step:8082 [D loss: 0.231190, acc.: 60.16%] [G loss: 0.501209]\n",
      "epoch:8 step:8083 [D loss: 0.223763, acc.: 64.06%] [G loss: 0.431206]\n",
      "epoch:8 step:8084 [D loss: 0.219850, acc.: 60.16%] [G loss: 0.480430]\n",
      "epoch:8 step:8085 [D loss: 0.220832, acc.: 69.53%] [G loss: 0.515055]\n",
      "epoch:8 step:8086 [D loss: 0.271671, acc.: 51.56%] [G loss: 0.493209]\n",
      "epoch:8 step:8087 [D loss: 0.189937, acc.: 71.09%] [G loss: 0.510271]\n",
      "epoch:8 step:8088 [D loss: 0.200230, acc.: 67.19%] [G loss: 0.489545]\n",
      "epoch:8 step:8089 [D loss: 0.222985, acc.: 61.72%] [G loss: 0.481438]\n",
      "epoch:8 step:8090 [D loss: 0.234106, acc.: 60.94%] [G loss: 0.474726]\n",
      "epoch:8 step:8091 [D loss: 0.217970, acc.: 66.41%] [G loss: 0.450491]\n",
      "epoch:8 step:8092 [D loss: 0.245608, acc.: 55.47%] [G loss: 0.469960]\n",
      "epoch:8 step:8093 [D loss: 0.228039, acc.: 68.75%] [G loss: 0.465109]\n",
      "epoch:8 step:8094 [D loss: 0.218002, acc.: 63.28%] [G loss: 0.492281]\n",
      "epoch:8 step:8095 [D loss: 0.224762, acc.: 65.62%] [G loss: 0.480596]\n",
      "epoch:8 step:8096 [D loss: 0.245128, acc.: 57.81%] [G loss: 0.448000]\n",
      "epoch:8 step:8097 [D loss: 0.229605, acc.: 60.16%] [G loss: 0.445934]\n",
      "epoch:8 step:8098 [D loss: 0.237042, acc.: 60.94%] [G loss: 0.487588]\n",
      "epoch:8 step:8099 [D loss: 0.224786, acc.: 65.62%] [G loss: 0.484979]\n",
      "epoch:8 step:8100 [D loss: 0.208719, acc.: 66.41%] [G loss: 0.487435]\n",
      "epoch:8 step:8101 [D loss: 0.211413, acc.: 66.41%] [G loss: 0.468067]\n",
      "epoch:8 step:8102 [D loss: 0.236897, acc.: 59.38%] [G loss: 0.434156]\n",
      "epoch:8 step:8103 [D loss: 0.213861, acc.: 66.41%] [G loss: 0.430987]\n",
      "epoch:8 step:8104 [D loss: 0.219695, acc.: 64.84%] [G loss: 0.476485]\n",
      "epoch:8 step:8105 [D loss: 0.214972, acc.: 66.41%] [G loss: 0.478570]\n",
      "epoch:8 step:8106 [D loss: 0.213520, acc.: 64.84%] [G loss: 0.462410]\n",
      "epoch:8 step:8107 [D loss: 0.218666, acc.: 63.28%] [G loss: 0.503426]\n",
      "epoch:8 step:8108 [D loss: 0.192238, acc.: 70.31%] [G loss: 0.442029]\n",
      "epoch:8 step:8109 [D loss: 0.222383, acc.: 64.84%] [G loss: 0.472681]\n",
      "epoch:8 step:8110 [D loss: 0.230086, acc.: 60.94%] [G loss: 0.503410]\n",
      "epoch:8 step:8111 [D loss: 0.242766, acc.: 59.38%] [G loss: 0.480258]\n",
      "epoch:8 step:8112 [D loss: 0.239798, acc.: 60.94%] [G loss: 0.452023]\n",
      "epoch:8 step:8113 [D loss: 0.212215, acc.: 62.50%] [G loss: 0.476322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8114 [D loss: 0.173721, acc.: 76.56%] [G loss: 0.512411]\n",
      "epoch:8 step:8115 [D loss: 0.248808, acc.: 60.94%] [G loss: 0.467199]\n",
      "epoch:8 step:8116 [D loss: 0.218366, acc.: 64.06%] [G loss: 0.496255]\n",
      "epoch:8 step:8117 [D loss: 0.247111, acc.: 62.50%] [G loss: 0.445046]\n",
      "epoch:8 step:8118 [D loss: 0.234329, acc.: 61.72%] [G loss: 0.495700]\n",
      "epoch:8 step:8119 [D loss: 0.196664, acc.: 71.09%] [G loss: 0.521026]\n",
      "epoch:8 step:8120 [D loss: 0.195850, acc.: 72.66%] [G loss: 0.484820]\n",
      "epoch:8 step:8121 [D loss: 0.238469, acc.: 62.50%] [G loss: 0.477192]\n",
      "epoch:8 step:8122 [D loss: 0.252161, acc.: 60.94%] [G loss: 0.449695]\n",
      "epoch:8 step:8123 [D loss: 0.236671, acc.: 59.38%] [G loss: 0.469674]\n",
      "epoch:8 step:8124 [D loss: 0.242742, acc.: 59.38%] [G loss: 0.455835]\n",
      "epoch:8 step:8125 [D loss: 0.223519, acc.: 59.38%] [G loss: 0.443179]\n",
      "epoch:8 step:8126 [D loss: 0.240790, acc.: 60.16%] [G loss: 0.446718]\n",
      "epoch:8 step:8127 [D loss: 0.198492, acc.: 74.22%] [G loss: 0.498228]\n",
      "epoch:8 step:8128 [D loss: 0.206266, acc.: 68.75%] [G loss: 0.504086]\n",
      "epoch:8 step:8129 [D loss: 0.201010, acc.: 68.75%] [G loss: 0.473293]\n",
      "epoch:8 step:8130 [D loss: 0.199810, acc.: 66.41%] [G loss: 0.506477]\n",
      "epoch:8 step:8131 [D loss: 0.216710, acc.: 64.84%] [G loss: 0.550944]\n",
      "epoch:8 step:8132 [D loss: 0.231320, acc.: 60.94%] [G loss: 0.476689]\n",
      "epoch:8 step:8133 [D loss: 0.211221, acc.: 63.28%] [G loss: 0.470716]\n",
      "epoch:8 step:8134 [D loss: 0.243971, acc.: 56.25%] [G loss: 0.486718]\n",
      "epoch:8 step:8135 [D loss: 0.212087, acc.: 64.84%] [G loss: 0.429268]\n",
      "epoch:8 step:8136 [D loss: 0.210274, acc.: 63.28%] [G loss: 0.491036]\n",
      "epoch:8 step:8137 [D loss: 0.204187, acc.: 70.31%] [G loss: 0.459423]\n",
      "epoch:8 step:8138 [D loss: 0.188009, acc.: 71.88%] [G loss: 0.526288]\n",
      "epoch:8 step:8139 [D loss: 0.234114, acc.: 60.94%] [G loss: 0.514665]\n",
      "epoch:8 step:8140 [D loss: 0.234433, acc.: 60.16%] [G loss: 0.486570]\n",
      "epoch:8 step:8141 [D loss: 0.233187, acc.: 64.84%] [G loss: 0.522360]\n",
      "epoch:8 step:8142 [D loss: 0.215361, acc.: 62.50%] [G loss: 0.491178]\n",
      "epoch:8 step:8143 [D loss: 0.173409, acc.: 76.56%] [G loss: 0.612136]\n",
      "epoch:8 step:8144 [D loss: 0.156876, acc.: 75.78%] [G loss: 0.649368]\n",
      "epoch:8 step:8145 [D loss: 0.216346, acc.: 64.06%] [G loss: 0.541109]\n",
      "epoch:8 step:8146 [D loss: 0.196292, acc.: 73.44%] [G loss: 0.530562]\n",
      "epoch:8 step:8147 [D loss: 0.219855, acc.: 67.19%] [G loss: 0.508327]\n",
      "epoch:8 step:8148 [D loss: 0.240901, acc.: 58.59%] [G loss: 0.453434]\n",
      "epoch:8 step:8149 [D loss: 0.233097, acc.: 60.94%] [G loss: 0.445584]\n",
      "epoch:8 step:8150 [D loss: 0.212598, acc.: 66.41%] [G loss: 0.470700]\n",
      "epoch:8 step:8151 [D loss: 0.225505, acc.: 69.53%] [G loss: 0.479397]\n",
      "epoch:8 step:8152 [D loss: 0.245650, acc.: 61.72%] [G loss: 0.470772]\n",
      "epoch:8 step:8153 [D loss: 0.213182, acc.: 64.84%] [G loss: 0.470940]\n",
      "epoch:8 step:8154 [D loss: 0.226042, acc.: 61.72%] [G loss: 0.495246]\n",
      "epoch:8 step:8155 [D loss: 0.230511, acc.: 58.59%] [G loss: 0.439676]\n",
      "epoch:8 step:8156 [D loss: 0.208125, acc.: 66.41%] [G loss: 0.465471]\n",
      "epoch:8 step:8157 [D loss: 0.207606, acc.: 65.62%] [G loss: 0.493639]\n",
      "epoch:8 step:8158 [D loss: 0.244522, acc.: 59.38%] [G loss: 0.464654]\n",
      "epoch:8 step:8159 [D loss: 0.235164, acc.: 57.81%] [G loss: 0.478715]\n",
      "epoch:8 step:8160 [D loss: 0.222039, acc.: 64.84%] [G loss: 0.487825]\n",
      "epoch:8 step:8161 [D loss: 0.227663, acc.: 63.28%] [G loss: 0.494211]\n",
      "epoch:8 step:8162 [D loss: 0.222725, acc.: 64.84%] [G loss: 0.488917]\n",
      "epoch:8 step:8163 [D loss: 0.238161, acc.: 62.50%] [G loss: 0.482477]\n",
      "epoch:8 step:8164 [D loss: 0.235558, acc.: 60.16%] [G loss: 0.432444]\n",
      "epoch:8 step:8165 [D loss: 0.213933, acc.: 66.41%] [G loss: 0.466009]\n",
      "epoch:8 step:8166 [D loss: 0.243842, acc.: 62.50%] [G loss: 0.437229]\n",
      "epoch:8 step:8167 [D loss: 0.234568, acc.: 59.38%] [G loss: 0.416448]\n",
      "epoch:8 step:8168 [D loss: 0.249009, acc.: 58.59%] [G loss: 0.432981]\n",
      "epoch:8 step:8169 [D loss: 0.251534, acc.: 56.25%] [G loss: 0.420955]\n",
      "epoch:8 step:8170 [D loss: 0.220082, acc.: 62.50%] [G loss: 0.486715]\n",
      "epoch:8 step:8171 [D loss: 0.226927, acc.: 60.16%] [G loss: 0.434734]\n",
      "epoch:8 step:8172 [D loss: 0.224450, acc.: 61.72%] [G loss: 0.486164]\n",
      "epoch:8 step:8173 [D loss: 0.199143, acc.: 69.53%] [G loss: 0.481096]\n",
      "epoch:8 step:8174 [D loss: 0.224997, acc.: 64.84%] [G loss: 0.442722]\n",
      "epoch:8 step:8175 [D loss: 0.210049, acc.: 67.97%] [G loss: 0.480184]\n",
      "epoch:8 step:8176 [D loss: 0.197911, acc.: 67.19%] [G loss: 0.485315]\n",
      "epoch:8 step:8177 [D loss: 0.195919, acc.: 71.09%] [G loss: 0.467848]\n",
      "epoch:8 step:8178 [D loss: 0.227438, acc.: 64.84%] [G loss: 0.493178]\n",
      "epoch:8 step:8179 [D loss: 0.243412, acc.: 57.81%] [G loss: 0.437466]\n",
      "epoch:8 step:8180 [D loss: 0.231502, acc.: 60.94%] [G loss: 0.429356]\n",
      "epoch:8 step:8181 [D loss: 0.218145, acc.: 61.72%] [G loss: 0.451168]\n",
      "epoch:8 step:8182 [D loss: 0.225838, acc.: 60.94%] [G loss: 0.492445]\n",
      "epoch:8 step:8183 [D loss: 0.235321, acc.: 60.16%] [G loss: 0.478826]\n",
      "epoch:8 step:8184 [D loss: 0.211227, acc.: 70.31%] [G loss: 0.443096]\n",
      "epoch:8 step:8185 [D loss: 0.219622, acc.: 64.06%] [G loss: 0.513868]\n",
      "epoch:8 step:8186 [D loss: 0.182831, acc.: 69.53%] [G loss: 0.508522]\n",
      "epoch:8 step:8187 [D loss: 0.209952, acc.: 72.66%] [G loss: 0.484993]\n",
      "epoch:8 step:8188 [D loss: 0.213886, acc.: 67.97%] [G loss: 0.526510]\n",
      "epoch:8 step:8189 [D loss: 0.202421, acc.: 68.75%] [G loss: 0.526952]\n",
      "epoch:8 step:8190 [D loss: 0.178154, acc.: 75.78%] [G loss: 0.496218]\n",
      "epoch:8 step:8191 [D loss: 0.227004, acc.: 59.38%] [G loss: 0.531402]\n",
      "epoch:8 step:8192 [D loss: 0.242754, acc.: 57.03%] [G loss: 0.463268]\n",
      "epoch:8 step:8193 [D loss: 0.217008, acc.: 64.84%] [G loss: 0.437669]\n",
      "epoch:8 step:8194 [D loss: 0.255929, acc.: 57.81%] [G loss: 0.437565]\n",
      "epoch:8 step:8195 [D loss: 0.211855, acc.: 66.41%] [G loss: 0.451245]\n",
      "epoch:8 step:8196 [D loss: 0.223091, acc.: 71.09%] [G loss: 0.452447]\n",
      "epoch:8 step:8197 [D loss: 0.196635, acc.: 68.75%] [G loss: 0.515165]\n",
      "epoch:8 step:8198 [D loss: 0.249007, acc.: 54.69%] [G loss: 0.452804]\n",
      "epoch:8 step:8199 [D loss: 0.232878, acc.: 65.62%] [G loss: 0.433894]\n",
      "epoch:8 step:8200 [D loss: 0.232232, acc.: 61.72%] [G loss: 0.484387]\n",
      "epoch:8 step:8201 [D loss: 0.208633, acc.: 67.19%] [G loss: 0.492261]\n",
      "epoch:8 step:8202 [D loss: 0.205852, acc.: 69.53%] [G loss: 0.488797]\n",
      "epoch:8 step:8203 [D loss: 0.199034, acc.: 72.66%] [G loss: 0.481928]\n",
      "epoch:8 step:8204 [D loss: 0.197336, acc.: 69.53%] [G loss: 0.499197]\n",
      "epoch:8 step:8205 [D loss: 0.196641, acc.: 69.53%] [G loss: 0.507725]\n",
      "epoch:8 step:8206 [D loss: 0.260641, acc.: 51.56%] [G loss: 0.491743]\n",
      "epoch:8 step:8207 [D loss: 0.218240, acc.: 68.75%] [G loss: 0.509619]\n",
      "epoch:8 step:8208 [D loss: 0.228411, acc.: 60.94%] [G loss: 0.501875]\n",
      "epoch:8 step:8209 [D loss: 0.222329, acc.: 63.28%] [G loss: 0.494200]\n",
      "epoch:8 step:8210 [D loss: 0.232744, acc.: 65.62%] [G loss: 0.483012]\n",
      "epoch:8 step:8211 [D loss: 0.248049, acc.: 60.16%] [G loss: 0.463985]\n",
      "epoch:8 step:8212 [D loss: 0.258014, acc.: 57.03%] [G loss: 0.425261]\n",
      "epoch:8 step:8213 [D loss: 0.229973, acc.: 59.38%] [G loss: 0.440266]\n",
      "epoch:8 step:8214 [D loss: 0.261538, acc.: 56.25%] [G loss: 0.434698]\n",
      "epoch:8 step:8215 [D loss: 0.201476, acc.: 71.88%] [G loss: 0.475452]\n",
      "epoch:8 step:8216 [D loss: 0.234629, acc.: 59.38%] [G loss: 0.475093]\n",
      "epoch:8 step:8217 [D loss: 0.201518, acc.: 67.19%] [G loss: 0.487741]\n",
      "epoch:8 step:8218 [D loss: 0.251128, acc.: 55.47%] [G loss: 0.441262]\n",
      "epoch:8 step:8219 [D loss: 0.219972, acc.: 64.06%] [G loss: 0.427415]\n",
      "epoch:8 step:8220 [D loss: 0.208026, acc.: 64.84%] [G loss: 0.457170]\n",
      "epoch:8 step:8221 [D loss: 0.176077, acc.: 75.78%] [G loss: 0.510985]\n",
      "epoch:8 step:8222 [D loss: 0.214503, acc.: 59.38%] [G loss: 0.493278]\n",
      "epoch:8 step:8223 [D loss: 0.223531, acc.: 61.72%] [G loss: 0.463561]\n",
      "epoch:8 step:8224 [D loss: 0.202279, acc.: 69.53%] [G loss: 0.459907]\n",
      "epoch:8 step:8225 [D loss: 0.235857, acc.: 53.91%] [G loss: 0.423008]\n",
      "epoch:8 step:8226 [D loss: 0.199051, acc.: 69.53%] [G loss: 0.487163]\n",
      "epoch:8 step:8227 [D loss: 0.207275, acc.: 64.84%] [G loss: 0.512052]\n",
      "epoch:8 step:8228 [D loss: 0.231461, acc.: 60.16%] [G loss: 0.458178]\n",
      "epoch:8 step:8229 [D loss: 0.202038, acc.: 67.97%] [G loss: 0.521541]\n",
      "epoch:8 step:8230 [D loss: 0.251698, acc.: 60.16%] [G loss: 0.462448]\n",
      "epoch:8 step:8231 [D loss: 0.218773, acc.: 67.19%] [G loss: 0.442308]\n",
      "epoch:8 step:8232 [D loss: 0.197622, acc.: 71.09%] [G loss: 0.496333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8233 [D loss: 0.212800, acc.: 62.50%] [G loss: 0.453262]\n",
      "epoch:8 step:8234 [D loss: 0.224564, acc.: 59.38%] [G loss: 0.465540]\n",
      "epoch:8 step:8235 [D loss: 0.270235, acc.: 54.69%] [G loss: 0.471730]\n",
      "epoch:8 step:8236 [D loss: 0.233394, acc.: 60.94%] [G loss: 0.456858]\n",
      "epoch:8 step:8237 [D loss: 0.223570, acc.: 63.28%] [G loss: 0.418791]\n",
      "epoch:8 step:8238 [D loss: 0.208477, acc.: 67.97%] [G loss: 0.482772]\n",
      "epoch:8 step:8239 [D loss: 0.211901, acc.: 68.75%] [G loss: 0.507770]\n",
      "epoch:8 step:8240 [D loss: 0.226672, acc.: 64.06%] [G loss: 0.520800]\n",
      "epoch:8 step:8241 [D loss: 0.203637, acc.: 67.97%] [G loss: 0.499893]\n",
      "epoch:8 step:8242 [D loss: 0.208056, acc.: 67.19%] [G loss: 0.477248]\n",
      "epoch:8 step:8243 [D loss: 0.227070, acc.: 60.16%] [G loss: 0.432030]\n",
      "epoch:8 step:8244 [D loss: 0.222773, acc.: 60.94%] [G loss: 0.418348]\n",
      "epoch:8 step:8245 [D loss: 0.233454, acc.: 54.69%] [G loss: 0.418316]\n",
      "epoch:8 step:8246 [D loss: 0.191497, acc.: 68.75%] [G loss: 0.476022]\n",
      "epoch:8 step:8247 [D loss: 0.230290, acc.: 67.19%] [G loss: 0.456743]\n",
      "epoch:8 step:8248 [D loss: 0.228903, acc.: 58.59%] [G loss: 0.457974]\n",
      "epoch:8 step:8249 [D loss: 0.237339, acc.: 61.72%] [G loss: 0.469726]\n",
      "epoch:8 step:8250 [D loss: 0.205347, acc.: 68.75%] [G loss: 0.468586]\n",
      "epoch:8 step:8251 [D loss: 0.259647, acc.: 58.59%] [G loss: 0.444148]\n",
      "epoch:8 step:8252 [D loss: 0.189320, acc.: 76.56%] [G loss: 0.491887]\n",
      "epoch:8 step:8253 [D loss: 0.234245, acc.: 58.59%] [G loss: 0.436838]\n",
      "epoch:8 step:8254 [D loss: 0.219055, acc.: 70.31%] [G loss: 0.476752]\n",
      "epoch:8 step:8255 [D loss: 0.224719, acc.: 64.06%] [G loss: 0.450699]\n",
      "epoch:8 step:8256 [D loss: 0.209953, acc.: 67.97%] [G loss: 0.444946]\n",
      "epoch:8 step:8257 [D loss: 0.234502, acc.: 57.03%] [G loss: 0.436052]\n",
      "epoch:8 step:8258 [D loss: 0.231522, acc.: 57.81%] [G loss: 0.456972]\n",
      "epoch:8 step:8259 [D loss: 0.236735, acc.: 60.16%] [G loss: 0.469016]\n",
      "epoch:8 step:8260 [D loss: 0.230829, acc.: 58.59%] [G loss: 0.468504]\n",
      "epoch:8 step:8261 [D loss: 0.254855, acc.: 60.16%] [G loss: 0.449596]\n",
      "epoch:8 step:8262 [D loss: 0.263089, acc.: 50.78%] [G loss: 0.481595]\n",
      "epoch:8 step:8263 [D loss: 0.210736, acc.: 67.19%] [G loss: 0.490754]\n",
      "epoch:8 step:8264 [D loss: 0.246550, acc.: 60.16%] [G loss: 0.509950]\n",
      "epoch:8 step:8265 [D loss: 0.184132, acc.: 71.88%] [G loss: 0.538464]\n",
      "epoch:8 step:8266 [D loss: 0.243290, acc.: 57.81%] [G loss: 0.535928]\n",
      "epoch:8 step:8267 [D loss: 0.238851, acc.: 57.81%] [G loss: 0.467804]\n",
      "epoch:8 step:8268 [D loss: 0.234738, acc.: 66.41%] [G loss: 0.461209]\n",
      "epoch:8 step:8269 [D loss: 0.216743, acc.: 67.97%] [G loss: 0.495692]\n",
      "epoch:8 step:8270 [D loss: 0.226646, acc.: 67.97%] [G loss: 0.488226]\n",
      "epoch:8 step:8271 [D loss: 0.192409, acc.: 70.31%] [G loss: 0.519334]\n",
      "epoch:8 step:8272 [D loss: 0.225082, acc.: 67.97%] [G loss: 0.472524]\n",
      "epoch:8 step:8273 [D loss: 0.232926, acc.: 58.59%] [G loss: 0.514919]\n",
      "epoch:8 step:8274 [D loss: 0.234658, acc.: 61.72%] [G loss: 0.472001]\n",
      "epoch:8 step:8275 [D loss: 0.229931, acc.: 60.16%] [G loss: 0.468386]\n",
      "epoch:8 step:8276 [D loss: 0.192300, acc.: 71.09%] [G loss: 0.534038]\n",
      "epoch:8 step:8277 [D loss: 0.205620, acc.: 70.31%] [G loss: 0.514907]\n",
      "epoch:8 step:8278 [D loss: 0.205818, acc.: 67.97%] [G loss: 0.553439]\n",
      "epoch:8 step:8279 [D loss: 0.248620, acc.: 57.03%] [G loss: 0.462178]\n",
      "epoch:8 step:8280 [D loss: 0.250448, acc.: 53.91%] [G loss: 0.453796]\n",
      "epoch:8 step:8281 [D loss: 0.255593, acc.: 56.25%] [G loss: 0.435091]\n",
      "epoch:8 step:8282 [D loss: 0.188660, acc.: 71.88%] [G loss: 0.554664]\n",
      "epoch:8 step:8283 [D loss: 0.266466, acc.: 56.25%] [G loss: 0.486501]\n",
      "epoch:8 step:8284 [D loss: 0.278035, acc.: 50.78%] [G loss: 0.431892]\n",
      "epoch:8 step:8285 [D loss: 0.223445, acc.: 64.06%] [G loss: 0.496715]\n",
      "epoch:8 step:8286 [D loss: 0.217215, acc.: 65.62%] [G loss: 0.489105]\n",
      "epoch:8 step:8287 [D loss: 0.274924, acc.: 50.78%] [G loss: 0.412207]\n",
      "epoch:8 step:8288 [D loss: 0.185087, acc.: 69.53%] [G loss: 0.519607]\n",
      "epoch:8 step:8289 [D loss: 0.238250, acc.: 59.38%] [G loss: 0.473241]\n",
      "epoch:8 step:8290 [D loss: 0.252899, acc.: 55.47%] [G loss: 0.478697]\n",
      "epoch:8 step:8291 [D loss: 0.235706, acc.: 58.59%] [G loss: 0.484217]\n",
      "epoch:8 step:8292 [D loss: 0.216693, acc.: 59.38%] [G loss: 0.492537]\n",
      "epoch:8 step:8293 [D loss: 0.231091, acc.: 61.72%] [G loss: 0.462571]\n",
      "epoch:8 step:8294 [D loss: 0.241058, acc.: 55.47%] [G loss: 0.420724]\n",
      "epoch:8 step:8295 [D loss: 0.194490, acc.: 73.44%] [G loss: 0.466152]\n",
      "epoch:8 step:8296 [D loss: 0.239106, acc.: 53.91%] [G loss: 0.449731]\n",
      "epoch:8 step:8297 [D loss: 0.224157, acc.: 65.62%] [G loss: 0.444983]\n",
      "epoch:8 step:8298 [D loss: 0.216138, acc.: 66.41%] [G loss: 0.495629]\n",
      "epoch:8 step:8299 [D loss: 0.202908, acc.: 66.41%] [G loss: 0.503634]\n",
      "epoch:8 step:8300 [D loss: 0.228489, acc.: 63.28%] [G loss: 0.452521]\n",
      "epoch:8 step:8301 [D loss: 0.236094, acc.: 57.81%] [G loss: 0.421724]\n",
      "epoch:8 step:8302 [D loss: 0.220615, acc.: 65.62%] [G loss: 0.458356]\n",
      "epoch:8 step:8303 [D loss: 0.200955, acc.: 68.75%] [G loss: 0.456292]\n",
      "epoch:8 step:8304 [D loss: 0.236800, acc.: 58.59%] [G loss: 0.453385]\n",
      "epoch:8 step:8305 [D loss: 0.231045, acc.: 57.81%] [G loss: 0.427531]\n",
      "epoch:8 step:8306 [D loss: 0.207052, acc.: 69.53%] [G loss: 0.523272]\n",
      "epoch:8 step:8307 [D loss: 0.236400, acc.: 60.16%] [G loss: 0.457513]\n",
      "epoch:8 step:8308 [D loss: 0.266416, acc.: 50.78%] [G loss: 0.430645]\n",
      "epoch:8 step:8309 [D loss: 0.197596, acc.: 75.00%] [G loss: 0.495183]\n",
      "epoch:8 step:8310 [D loss: 0.234580, acc.: 60.16%] [G loss: 0.422555]\n",
      "epoch:8 step:8311 [D loss: 0.186190, acc.: 73.44%] [G loss: 0.534063]\n",
      "epoch:8 step:8312 [D loss: 0.222730, acc.: 62.50%] [G loss: 0.492407]\n",
      "epoch:8 step:8313 [D loss: 0.256072, acc.: 64.06%] [G loss: 0.464716]\n",
      "epoch:8 step:8314 [D loss: 0.251662, acc.: 54.69%] [G loss: 0.449091]\n",
      "epoch:8 step:8315 [D loss: 0.192047, acc.: 70.31%] [G loss: 0.477750]\n",
      "epoch:8 step:8316 [D loss: 0.288331, acc.: 48.44%] [G loss: 0.430793]\n",
      "epoch:8 step:8317 [D loss: 0.212026, acc.: 65.62%] [G loss: 0.466191]\n",
      "epoch:8 step:8318 [D loss: 0.207246, acc.: 65.62%] [G loss: 0.478685]\n",
      "epoch:8 step:8319 [D loss: 0.218103, acc.: 62.50%] [G loss: 0.477640]\n",
      "epoch:8 step:8320 [D loss: 0.278657, acc.: 50.00%] [G loss: 0.429487]\n",
      "epoch:8 step:8321 [D loss: 0.189951, acc.: 72.66%] [G loss: 0.449855]\n",
      "epoch:8 step:8322 [D loss: 0.221709, acc.: 61.72%] [G loss: 0.458071]\n",
      "epoch:8 step:8323 [D loss: 0.276731, acc.: 53.91%] [G loss: 0.450188]\n",
      "epoch:8 step:8324 [D loss: 0.255461, acc.: 53.12%] [G loss: 0.472812]\n",
      "epoch:8 step:8325 [D loss: 0.227948, acc.: 60.94%] [G loss: 0.461803]\n",
      "epoch:8 step:8326 [D loss: 0.247912, acc.: 60.94%] [G loss: 0.428239]\n",
      "epoch:8 step:8327 [D loss: 0.232286, acc.: 62.50%] [G loss: 0.440897]\n",
      "epoch:8 step:8328 [D loss: 0.213431, acc.: 70.31%] [G loss: 0.471725]\n",
      "epoch:8 step:8329 [D loss: 0.209939, acc.: 67.19%] [G loss: 0.456185]\n",
      "epoch:8 step:8330 [D loss: 0.235420, acc.: 59.38%] [G loss: 0.438025]\n",
      "epoch:8 step:8331 [D loss: 0.207850, acc.: 66.41%] [G loss: 0.456579]\n",
      "epoch:8 step:8332 [D loss: 0.206183, acc.: 66.41%] [G loss: 0.470604]\n",
      "epoch:8 step:8333 [D loss: 0.233263, acc.: 64.06%] [G loss: 0.448429]\n",
      "epoch:8 step:8334 [D loss: 0.210140, acc.: 67.19%] [G loss: 0.488321]\n",
      "epoch:8 step:8335 [D loss: 0.217070, acc.: 60.16%] [G loss: 0.460178]\n",
      "epoch:8 step:8336 [D loss: 0.211542, acc.: 64.84%] [G loss: 0.487890]\n",
      "epoch:8 step:8337 [D loss: 0.207202, acc.: 67.19%] [G loss: 0.473584]\n",
      "epoch:8 step:8338 [D loss: 0.215386, acc.: 67.19%] [G loss: 0.470307]\n",
      "epoch:8 step:8339 [D loss: 0.235667, acc.: 60.94%] [G loss: 0.487881]\n",
      "epoch:8 step:8340 [D loss: 0.246897, acc.: 60.16%] [G loss: 0.441696]\n",
      "epoch:8 step:8341 [D loss: 0.206009, acc.: 71.88%] [G loss: 0.464579]\n",
      "epoch:8 step:8342 [D loss: 0.255132, acc.: 54.69%] [G loss: 0.428452]\n",
      "epoch:8 step:8343 [D loss: 0.236838, acc.: 60.16%] [G loss: 0.428199]\n",
      "epoch:8 step:8344 [D loss: 0.228140, acc.: 56.25%] [G loss: 0.452276]\n",
      "epoch:8 step:8345 [D loss: 0.211614, acc.: 69.53%] [G loss: 0.462875]\n",
      "epoch:8 step:8346 [D loss: 0.219869, acc.: 64.84%] [G loss: 0.480036]\n",
      "epoch:8 step:8347 [D loss: 0.219369, acc.: 63.28%] [G loss: 0.486353]\n",
      "epoch:8 step:8348 [D loss: 0.199152, acc.: 66.41%] [G loss: 0.517473]\n",
      "epoch:8 step:8349 [D loss: 0.212862, acc.: 67.97%] [G loss: 0.472281]\n",
      "epoch:8 step:8350 [D loss: 0.214561, acc.: 64.84%] [G loss: 0.479251]\n",
      "epoch:8 step:8351 [D loss: 0.215221, acc.: 68.75%] [G loss: 0.499390]\n",
      "epoch:8 step:8352 [D loss: 0.232638, acc.: 59.38%] [G loss: 0.517991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8353 [D loss: 0.225710, acc.: 67.19%] [G loss: 0.479984]\n",
      "epoch:8 step:8354 [D loss: 0.263063, acc.: 54.69%] [G loss: 0.443494]\n",
      "epoch:8 step:8355 [D loss: 0.213885, acc.: 65.62%] [G loss: 0.502413]\n",
      "epoch:8 step:8356 [D loss: 0.190116, acc.: 72.66%] [G loss: 0.530910]\n",
      "epoch:8 step:8357 [D loss: 0.245493, acc.: 54.69%] [G loss: 0.446975]\n",
      "epoch:8 step:8358 [D loss: 0.246241, acc.: 62.50%] [G loss: 0.421348]\n",
      "epoch:8 step:8359 [D loss: 0.213526, acc.: 66.41%] [G loss: 0.478912]\n",
      "epoch:8 step:8360 [D loss: 0.247202, acc.: 62.50%] [G loss: 0.422529]\n",
      "epoch:8 step:8361 [D loss: 0.225731, acc.: 64.06%] [G loss: 0.467441]\n",
      "epoch:8 step:8362 [D loss: 0.231362, acc.: 59.38%] [G loss: 0.431325]\n",
      "epoch:8 step:8363 [D loss: 0.229216, acc.: 61.72%] [G loss: 0.447085]\n",
      "epoch:8 step:8364 [D loss: 0.251974, acc.: 57.81%] [G loss: 0.434849]\n",
      "epoch:8 step:8365 [D loss: 0.250423, acc.: 54.69%] [G loss: 0.425785]\n",
      "epoch:8 step:8366 [D loss: 0.211759, acc.: 65.62%] [G loss: 0.434141]\n",
      "epoch:8 step:8367 [D loss: 0.242003, acc.: 63.28%] [G loss: 0.450860]\n",
      "epoch:8 step:8368 [D loss: 0.184676, acc.: 71.09%] [G loss: 0.500620]\n",
      "epoch:8 step:8369 [D loss: 0.215585, acc.: 67.19%] [G loss: 0.492518]\n",
      "epoch:8 step:8370 [D loss: 0.224179, acc.: 67.19%] [G loss: 0.442468]\n",
      "epoch:8 step:8371 [D loss: 0.200388, acc.: 65.62%] [G loss: 0.460991]\n",
      "epoch:8 step:8372 [D loss: 0.238562, acc.: 61.72%] [G loss: 0.450835]\n",
      "epoch:8 step:8373 [D loss: 0.232974, acc.: 57.03%] [G loss: 0.463370]\n",
      "epoch:8 step:8374 [D loss: 0.225283, acc.: 61.72%] [G loss: 0.472361]\n",
      "epoch:8 step:8375 [D loss: 0.217970, acc.: 66.41%] [G loss: 0.493008]\n",
      "epoch:8 step:8376 [D loss: 0.235568, acc.: 58.59%] [G loss: 0.441900]\n",
      "epoch:8 step:8377 [D loss: 0.222523, acc.: 58.59%] [G loss: 0.436364]\n",
      "epoch:8 step:8378 [D loss: 0.216904, acc.: 64.06%] [G loss: 0.431727]\n",
      "epoch:8 step:8379 [D loss: 0.241862, acc.: 60.16%] [G loss: 0.468855]\n",
      "epoch:8 step:8380 [D loss: 0.195896, acc.: 71.88%] [G loss: 0.537698]\n",
      "epoch:8 step:8381 [D loss: 0.229277, acc.: 60.94%] [G loss: 0.515211]\n",
      "epoch:8 step:8382 [D loss: 0.175009, acc.: 78.91%] [G loss: 0.525810]\n",
      "epoch:8 step:8383 [D loss: 0.249041, acc.: 59.38%] [G loss: 0.463512]\n",
      "epoch:8 step:8384 [D loss: 0.254166, acc.: 55.47%] [G loss: 0.456068]\n",
      "epoch:8 step:8385 [D loss: 0.224005, acc.: 59.38%] [G loss: 0.546765]\n",
      "epoch:8 step:8386 [D loss: 0.215518, acc.: 65.62%] [G loss: 0.449915]\n",
      "epoch:8 step:8387 [D loss: 0.268271, acc.: 53.91%] [G loss: 0.440752]\n",
      "epoch:8 step:8388 [D loss: 0.264797, acc.: 49.22%] [G loss: 0.439582]\n",
      "epoch:8 step:8389 [D loss: 0.213258, acc.: 67.19%] [G loss: 0.446035]\n",
      "epoch:8 step:8390 [D loss: 0.212374, acc.: 67.97%] [G loss: 0.481136]\n",
      "epoch:8 step:8391 [D loss: 0.224212, acc.: 62.50%] [G loss: 0.465362]\n",
      "epoch:8 step:8392 [D loss: 0.211192, acc.: 62.50%] [G loss: 0.488525]\n",
      "epoch:8 step:8393 [D loss: 0.213666, acc.: 65.62%] [G loss: 0.429219]\n",
      "epoch:8 step:8394 [D loss: 0.182626, acc.: 67.97%] [G loss: 0.499134]\n",
      "epoch:8 step:8395 [D loss: 0.185558, acc.: 69.53%] [G loss: 0.504639]\n",
      "epoch:8 step:8396 [D loss: 0.229756, acc.: 60.94%] [G loss: 0.494728]\n",
      "epoch:8 step:8397 [D loss: 0.226022, acc.: 64.06%] [G loss: 0.485605]\n",
      "epoch:8 step:8398 [D loss: 0.217057, acc.: 61.72%] [G loss: 0.491387]\n",
      "epoch:8 step:8399 [D loss: 0.229849, acc.: 60.94%] [G loss: 0.449810]\n",
      "epoch:8 step:8400 [D loss: 0.243150, acc.: 57.03%] [G loss: 0.444351]\n",
      "epoch:8 step:8401 [D loss: 0.222756, acc.: 65.62%] [G loss: 0.471964]\n",
      "epoch:8 step:8402 [D loss: 0.224358, acc.: 68.75%] [G loss: 0.514217]\n",
      "epoch:8 step:8403 [D loss: 0.228245, acc.: 64.06%] [G loss: 0.464299]\n",
      "epoch:8 step:8404 [D loss: 0.205877, acc.: 68.75%] [G loss: 0.451262]\n",
      "epoch:8 step:8405 [D loss: 0.210644, acc.: 67.97%] [G loss: 0.468215]\n",
      "epoch:8 step:8406 [D loss: 0.222036, acc.: 67.19%] [G loss: 0.493991]\n",
      "epoch:8 step:8407 [D loss: 0.194365, acc.: 67.97%] [G loss: 0.520637]\n",
      "epoch:8 step:8408 [D loss: 0.208528, acc.: 68.75%] [G loss: 0.567855]\n",
      "epoch:8 step:8409 [D loss: 0.215213, acc.: 62.50%] [G loss: 0.523722]\n",
      "epoch:8 step:8410 [D loss: 0.238939, acc.: 57.81%] [G loss: 0.514306]\n",
      "epoch:8 step:8411 [D loss: 0.247614, acc.: 54.69%] [G loss: 0.468580]\n",
      "epoch:8 step:8412 [D loss: 0.225547, acc.: 58.59%] [G loss: 0.428942]\n",
      "epoch:8 step:8413 [D loss: 0.249898, acc.: 54.69%] [G loss: 0.459043]\n",
      "epoch:8 step:8414 [D loss: 0.193355, acc.: 74.22%] [G loss: 0.503143]\n",
      "epoch:8 step:8415 [D loss: 0.232653, acc.: 60.16%] [G loss: 0.510076]\n",
      "epoch:8 step:8416 [D loss: 0.275441, acc.: 61.72%] [G loss: 0.499164]\n",
      "epoch:8 step:8417 [D loss: 0.197954, acc.: 67.19%] [G loss: 0.487468]\n",
      "epoch:8 step:8418 [D loss: 0.234269, acc.: 58.59%] [G loss: 0.508447]\n",
      "epoch:8 step:8419 [D loss: 0.177102, acc.: 75.78%] [G loss: 0.532376]\n",
      "epoch:8 step:8420 [D loss: 0.165893, acc.: 83.59%] [G loss: 0.514246]\n",
      "epoch:8 step:8421 [D loss: 0.189495, acc.: 75.78%] [G loss: 0.526000]\n",
      "epoch:8 step:8422 [D loss: 0.210493, acc.: 71.88%] [G loss: 0.569483]\n",
      "epoch:8 step:8423 [D loss: 0.202075, acc.: 66.41%] [G loss: 0.570475]\n",
      "epoch:8 step:8424 [D loss: 0.345938, acc.: 54.69%] [G loss: 0.519551]\n",
      "epoch:8 step:8425 [D loss: 0.184876, acc.: 74.22%] [G loss: 0.693345]\n",
      "epoch:8 step:8426 [D loss: 0.259284, acc.: 57.81%] [G loss: 0.552171]\n",
      "epoch:8 step:8427 [D loss: 0.246501, acc.: 53.12%] [G loss: 0.378585]\n",
      "epoch:8 step:8428 [D loss: 0.273314, acc.: 60.94%] [G loss: 0.413857]\n",
      "epoch:8 step:8429 [D loss: 0.226779, acc.: 63.28%] [G loss: 0.490643]\n",
      "epoch:8 step:8430 [D loss: 0.197558, acc.: 69.53%] [G loss: 0.526959]\n",
      "epoch:8 step:8431 [D loss: 0.212596, acc.: 67.19%] [G loss: 0.524820]\n",
      "epoch:8 step:8432 [D loss: 0.183808, acc.: 74.22%] [G loss: 0.551208]\n",
      "epoch:8 step:8433 [D loss: 0.159112, acc.: 78.12%] [G loss: 0.605912]\n",
      "epoch:9 step:8434 [D loss: 0.235472, acc.: 60.16%] [G loss: 0.473357]\n",
      "epoch:9 step:8435 [D loss: 0.283822, acc.: 58.59%] [G loss: 0.462821]\n",
      "epoch:9 step:8436 [D loss: 0.226986, acc.: 64.06%] [G loss: 0.487825]\n",
      "epoch:9 step:8437 [D loss: 0.222152, acc.: 65.62%] [G loss: 0.461859]\n",
      "epoch:9 step:8438 [D loss: 0.208702, acc.: 65.62%] [G loss: 0.502838]\n",
      "epoch:9 step:8439 [D loss: 0.206614, acc.: 67.19%] [G loss: 0.466074]\n",
      "epoch:9 step:8440 [D loss: 0.204886, acc.: 71.09%] [G loss: 0.481222]\n",
      "epoch:9 step:8441 [D loss: 0.212810, acc.: 66.41%] [G loss: 0.486006]\n",
      "epoch:9 step:8442 [D loss: 0.209669, acc.: 64.84%] [G loss: 0.473383]\n",
      "epoch:9 step:8443 [D loss: 0.214251, acc.: 68.75%] [G loss: 0.473034]\n",
      "epoch:9 step:8444 [D loss: 0.204338, acc.: 70.31%] [G loss: 0.490793]\n",
      "epoch:9 step:8445 [D loss: 0.212660, acc.: 65.62%] [G loss: 0.500256]\n",
      "epoch:9 step:8446 [D loss: 0.212003, acc.: 60.94%] [G loss: 0.481029]\n",
      "epoch:9 step:8447 [D loss: 0.199228, acc.: 69.53%] [G loss: 0.470588]\n",
      "epoch:9 step:8448 [D loss: 0.180411, acc.: 71.09%] [G loss: 0.549672]\n",
      "epoch:9 step:8449 [D loss: 0.197984, acc.: 72.66%] [G loss: 0.519897]\n",
      "epoch:9 step:8450 [D loss: 0.246842, acc.: 57.03%] [G loss: 0.463228]\n",
      "epoch:9 step:8451 [D loss: 0.234158, acc.: 63.28%] [G loss: 0.454521]\n",
      "epoch:9 step:8452 [D loss: 0.253755, acc.: 60.94%] [G loss: 0.471025]\n",
      "epoch:9 step:8453 [D loss: 0.240713, acc.: 64.84%] [G loss: 0.493562]\n",
      "epoch:9 step:8454 [D loss: 0.232420, acc.: 60.94%] [G loss: 0.479012]\n",
      "epoch:9 step:8455 [D loss: 0.196615, acc.: 70.31%] [G loss: 0.526128]\n",
      "epoch:9 step:8456 [D loss: 0.274911, acc.: 52.34%] [G loss: 0.430799]\n",
      "epoch:9 step:8457 [D loss: 0.221456, acc.: 64.84%] [G loss: 0.458345]\n",
      "epoch:9 step:8458 [D loss: 0.224327, acc.: 64.06%] [G loss: 0.440174]\n",
      "epoch:9 step:8459 [D loss: 0.240473, acc.: 59.38%] [G loss: 0.476660]\n",
      "epoch:9 step:8460 [D loss: 0.230801, acc.: 63.28%] [G loss: 0.503366]\n",
      "epoch:9 step:8461 [D loss: 0.207875, acc.: 67.97%] [G loss: 0.435378]\n",
      "epoch:9 step:8462 [D loss: 0.201507, acc.: 66.41%] [G loss: 0.451345]\n",
      "epoch:9 step:8463 [D loss: 0.245385, acc.: 57.03%] [G loss: 0.433504]\n",
      "epoch:9 step:8464 [D loss: 0.235497, acc.: 64.84%] [G loss: 0.436609]\n",
      "epoch:9 step:8465 [D loss: 0.243293, acc.: 61.72%] [G loss: 0.484518]\n",
      "epoch:9 step:8466 [D loss: 0.207432, acc.: 66.41%] [G loss: 0.470740]\n",
      "epoch:9 step:8467 [D loss: 0.233785, acc.: 55.47%] [G loss: 0.446591]\n",
      "epoch:9 step:8468 [D loss: 0.206405, acc.: 64.84%] [G loss: 0.459690]\n",
      "epoch:9 step:8469 [D loss: 0.210569, acc.: 67.97%] [G loss: 0.482901]\n",
      "epoch:9 step:8470 [D loss: 0.260175, acc.: 53.91%] [G loss: 0.449016]\n",
      "epoch:9 step:8471 [D loss: 0.268625, acc.: 51.56%] [G loss: 0.439152]\n",
      "epoch:9 step:8472 [D loss: 0.239476, acc.: 62.50%] [G loss: 0.476185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8473 [D loss: 0.183466, acc.: 74.22%] [G loss: 0.502533]\n",
      "epoch:9 step:8474 [D loss: 0.226277, acc.: 65.62%] [G loss: 0.481607]\n",
      "epoch:9 step:8475 [D loss: 0.228758, acc.: 61.72%] [G loss: 0.493870]\n",
      "epoch:9 step:8476 [D loss: 0.228901, acc.: 64.84%] [G loss: 0.479427]\n",
      "epoch:9 step:8477 [D loss: 0.248081, acc.: 54.69%] [G loss: 0.463003]\n",
      "epoch:9 step:8478 [D loss: 0.213118, acc.: 66.41%] [G loss: 0.478637]\n",
      "epoch:9 step:8479 [D loss: 0.236070, acc.: 58.59%] [G loss: 0.442189]\n",
      "epoch:9 step:8480 [D loss: 0.223021, acc.: 64.84%] [G loss: 0.444533]\n",
      "epoch:9 step:8481 [D loss: 0.210201, acc.: 64.84%] [G loss: 0.468737]\n",
      "epoch:9 step:8482 [D loss: 0.185986, acc.: 70.31%] [G loss: 0.530589]\n",
      "epoch:9 step:8483 [D loss: 0.227417, acc.: 64.84%] [G loss: 0.517360]\n",
      "epoch:9 step:8484 [D loss: 0.273146, acc.: 55.47%] [G loss: 0.472959]\n",
      "epoch:9 step:8485 [D loss: 0.216657, acc.: 63.28%] [G loss: 0.484658]\n",
      "epoch:9 step:8486 [D loss: 0.198915, acc.: 67.19%] [G loss: 0.484339]\n",
      "epoch:9 step:8487 [D loss: 0.212902, acc.: 70.31%] [G loss: 0.495744]\n",
      "epoch:9 step:8488 [D loss: 0.216523, acc.: 67.19%] [G loss: 0.510548]\n",
      "epoch:9 step:8489 [D loss: 0.202984, acc.: 67.97%] [G loss: 0.489082]\n",
      "epoch:9 step:8490 [D loss: 0.254905, acc.: 57.81%] [G loss: 0.432474]\n",
      "epoch:9 step:8491 [D loss: 0.236616, acc.: 55.47%] [G loss: 0.486679]\n",
      "epoch:9 step:8492 [D loss: 0.202923, acc.: 65.62%] [G loss: 0.468837]\n",
      "epoch:9 step:8493 [D loss: 0.245478, acc.: 53.91%] [G loss: 0.494566]\n",
      "epoch:9 step:8494 [D loss: 0.229747, acc.: 54.69%] [G loss: 0.429621]\n",
      "epoch:9 step:8495 [D loss: 0.230577, acc.: 62.50%] [G loss: 0.444151]\n",
      "epoch:9 step:8496 [D loss: 0.193438, acc.: 68.75%] [G loss: 0.483461]\n",
      "epoch:9 step:8497 [D loss: 0.246120, acc.: 58.59%] [G loss: 0.477742]\n",
      "epoch:9 step:8498 [D loss: 0.208009, acc.: 61.72%] [G loss: 0.460628]\n",
      "epoch:9 step:8499 [D loss: 0.205466, acc.: 72.66%] [G loss: 0.467651]\n",
      "epoch:9 step:8500 [D loss: 0.215261, acc.: 64.06%] [G loss: 0.450141]\n",
      "epoch:9 step:8501 [D loss: 0.194764, acc.: 71.88%] [G loss: 0.484746]\n",
      "epoch:9 step:8502 [D loss: 0.190507, acc.: 70.31%] [G loss: 0.477299]\n",
      "epoch:9 step:8503 [D loss: 0.210241, acc.: 63.28%] [G loss: 0.486510]\n",
      "epoch:9 step:8504 [D loss: 0.227633, acc.: 60.94%] [G loss: 0.423620]\n",
      "epoch:9 step:8505 [D loss: 0.243897, acc.: 57.81%] [G loss: 0.427121]\n",
      "epoch:9 step:8506 [D loss: 0.192606, acc.: 75.00%] [G loss: 0.449075]\n",
      "epoch:9 step:8507 [D loss: 0.178308, acc.: 76.56%] [G loss: 0.476647]\n",
      "epoch:9 step:8508 [D loss: 0.200694, acc.: 66.41%] [G loss: 0.516551]\n",
      "epoch:9 step:8509 [D loss: 0.179683, acc.: 71.88%] [G loss: 0.522808]\n",
      "epoch:9 step:8510 [D loss: 0.169134, acc.: 74.22%] [G loss: 0.564354]\n",
      "epoch:9 step:8511 [D loss: 0.248657, acc.: 59.38%] [G loss: 0.478166]\n",
      "epoch:9 step:8512 [D loss: 0.249685, acc.: 62.50%] [G loss: 0.425369]\n",
      "epoch:9 step:8513 [D loss: 0.241551, acc.: 58.59%] [G loss: 0.467201]\n",
      "epoch:9 step:8514 [D loss: 0.213441, acc.: 64.06%] [G loss: 0.459806]\n",
      "epoch:9 step:8515 [D loss: 0.214490, acc.: 62.50%] [G loss: 0.464590]\n",
      "epoch:9 step:8516 [D loss: 0.223837, acc.: 68.75%] [G loss: 0.467152]\n",
      "epoch:9 step:8517 [D loss: 0.201851, acc.: 72.66%] [G loss: 0.527873]\n",
      "epoch:9 step:8518 [D loss: 0.232403, acc.: 64.84%] [G loss: 0.463727]\n",
      "epoch:9 step:8519 [D loss: 0.217018, acc.: 64.84%] [G loss: 0.442485]\n",
      "epoch:9 step:8520 [D loss: 0.216084, acc.: 69.53%] [G loss: 0.439634]\n",
      "epoch:9 step:8521 [D loss: 0.195328, acc.: 67.97%] [G loss: 0.501762]\n",
      "epoch:9 step:8522 [D loss: 0.209858, acc.: 67.19%] [G loss: 0.480358]\n",
      "epoch:9 step:8523 [D loss: 0.219268, acc.: 61.72%] [G loss: 0.446690]\n",
      "epoch:9 step:8524 [D loss: 0.235340, acc.: 62.50%] [G loss: 0.435147]\n",
      "epoch:9 step:8525 [D loss: 0.207112, acc.: 71.09%] [G loss: 0.474304]\n",
      "epoch:9 step:8526 [D loss: 0.205821, acc.: 65.62%] [G loss: 0.495653]\n",
      "epoch:9 step:8527 [D loss: 0.223283, acc.: 64.06%] [G loss: 0.459673]\n",
      "epoch:9 step:8528 [D loss: 0.241969, acc.: 59.38%] [G loss: 0.426252]\n",
      "epoch:9 step:8529 [D loss: 0.216364, acc.: 69.53%] [G loss: 0.503404]\n",
      "epoch:9 step:8530 [D loss: 0.209404, acc.: 66.41%] [G loss: 0.513930]\n",
      "epoch:9 step:8531 [D loss: 0.222192, acc.: 64.06%] [G loss: 0.489196]\n",
      "epoch:9 step:8532 [D loss: 0.233730, acc.: 64.06%] [G loss: 0.463381]\n",
      "epoch:9 step:8533 [D loss: 0.202218, acc.: 69.53%] [G loss: 0.453140]\n",
      "epoch:9 step:8534 [D loss: 0.226302, acc.: 59.38%] [G loss: 0.524484]\n",
      "epoch:9 step:8535 [D loss: 0.249298, acc.: 64.06%] [G loss: 0.458213]\n",
      "epoch:9 step:8536 [D loss: 0.207578, acc.: 61.72%] [G loss: 0.487415]\n",
      "epoch:9 step:8537 [D loss: 0.229073, acc.: 60.94%] [G loss: 0.469450]\n",
      "epoch:9 step:8538 [D loss: 0.224466, acc.: 61.72%] [G loss: 0.453833]\n",
      "epoch:9 step:8539 [D loss: 0.213324, acc.: 62.50%] [G loss: 0.422232]\n",
      "epoch:9 step:8540 [D loss: 0.201316, acc.: 68.75%] [G loss: 0.556734]\n",
      "epoch:9 step:8541 [D loss: 0.271582, acc.: 53.12%] [G loss: 0.489274]\n",
      "epoch:9 step:8542 [D loss: 0.265740, acc.: 54.69%] [G loss: 0.409438]\n",
      "epoch:9 step:8543 [D loss: 0.240843, acc.: 59.38%] [G loss: 0.434709]\n",
      "epoch:9 step:8544 [D loss: 0.172948, acc.: 74.22%] [G loss: 0.522750]\n",
      "epoch:9 step:8545 [D loss: 0.201084, acc.: 72.66%] [G loss: 0.529452]\n",
      "epoch:9 step:8546 [D loss: 0.224675, acc.: 66.41%] [G loss: 0.515134]\n",
      "epoch:9 step:8547 [D loss: 0.205565, acc.: 71.09%] [G loss: 0.483647]\n",
      "epoch:9 step:8548 [D loss: 0.214584, acc.: 65.62%] [G loss: 0.516580]\n",
      "epoch:9 step:8549 [D loss: 0.198153, acc.: 70.31%] [G loss: 0.535816]\n",
      "epoch:9 step:8550 [D loss: 0.205924, acc.: 69.53%] [G loss: 0.490363]\n",
      "epoch:9 step:8551 [D loss: 0.234130, acc.: 62.50%] [G loss: 0.458581]\n",
      "epoch:9 step:8552 [D loss: 0.184704, acc.: 71.88%] [G loss: 0.581225]\n",
      "epoch:9 step:8553 [D loss: 0.249113, acc.: 65.62%] [G loss: 0.494139]\n",
      "epoch:9 step:8554 [D loss: 0.235111, acc.: 62.50%] [G loss: 0.474203]\n",
      "epoch:9 step:8555 [D loss: 0.187979, acc.: 78.12%] [G loss: 0.449898]\n",
      "epoch:9 step:8556 [D loss: 0.197644, acc.: 68.75%] [G loss: 0.472774]\n",
      "epoch:9 step:8557 [D loss: 0.225813, acc.: 57.81%] [G loss: 0.473273]\n",
      "epoch:9 step:8558 [D loss: 0.221297, acc.: 64.84%] [G loss: 0.458484]\n",
      "epoch:9 step:8559 [D loss: 0.187175, acc.: 68.75%] [G loss: 0.473194]\n",
      "epoch:9 step:8560 [D loss: 0.232114, acc.: 63.28%] [G loss: 0.465407]\n",
      "epoch:9 step:8561 [D loss: 0.241803, acc.: 58.59%] [G loss: 0.484334]\n",
      "epoch:9 step:8562 [D loss: 0.231497, acc.: 60.94%] [G loss: 0.448677]\n",
      "epoch:9 step:8563 [D loss: 0.178026, acc.: 75.78%] [G loss: 0.489653]\n",
      "epoch:9 step:8564 [D loss: 0.233664, acc.: 59.38%] [G loss: 0.495593]\n",
      "epoch:9 step:8565 [D loss: 0.215877, acc.: 65.62%] [G loss: 0.517198]\n",
      "epoch:9 step:8566 [D loss: 0.265136, acc.: 51.56%] [G loss: 0.471736]\n",
      "epoch:9 step:8567 [D loss: 0.213423, acc.: 66.41%] [G loss: 0.471032]\n",
      "epoch:9 step:8568 [D loss: 0.198278, acc.: 67.97%] [G loss: 0.524644]\n",
      "epoch:9 step:8569 [D loss: 0.239760, acc.: 63.28%] [G loss: 0.465304]\n",
      "epoch:9 step:8570 [D loss: 0.296200, acc.: 47.66%] [G loss: 0.420425]\n",
      "epoch:9 step:8571 [D loss: 0.235076, acc.: 57.03%] [G loss: 0.407801]\n",
      "epoch:9 step:8572 [D loss: 0.212666, acc.: 63.28%] [G loss: 0.508958]\n",
      "epoch:9 step:8573 [D loss: 0.221034, acc.: 67.97%] [G loss: 0.465445]\n",
      "epoch:9 step:8574 [D loss: 0.224377, acc.: 64.06%] [G loss: 0.472958]\n",
      "epoch:9 step:8575 [D loss: 0.241780, acc.: 58.59%] [G loss: 0.487580]\n",
      "epoch:9 step:8576 [D loss: 0.256657, acc.: 50.78%] [G loss: 0.468519]\n",
      "epoch:9 step:8577 [D loss: 0.224444, acc.: 64.06%] [G loss: 0.446292]\n",
      "epoch:9 step:8578 [D loss: 0.224093, acc.: 66.41%] [G loss: 0.506780]\n",
      "epoch:9 step:8579 [D loss: 0.207755, acc.: 65.62%] [G loss: 0.491829]\n",
      "epoch:9 step:8580 [D loss: 0.273709, acc.: 53.12%] [G loss: 0.424903]\n",
      "epoch:9 step:8581 [D loss: 0.254062, acc.: 56.25%] [G loss: 0.435867]\n",
      "epoch:9 step:8582 [D loss: 0.237269, acc.: 65.62%] [G loss: 0.429820]\n",
      "epoch:9 step:8583 [D loss: 0.258699, acc.: 57.03%] [G loss: 0.451774]\n",
      "epoch:9 step:8584 [D loss: 0.212617, acc.: 64.84%] [G loss: 0.464287]\n",
      "epoch:9 step:8585 [D loss: 0.250332, acc.: 58.59%] [G loss: 0.474839]\n",
      "epoch:9 step:8586 [D loss: 0.251890, acc.: 55.47%] [G loss: 0.458675]\n",
      "epoch:9 step:8587 [D loss: 0.200940, acc.: 66.41%] [G loss: 0.505000]\n",
      "epoch:9 step:8588 [D loss: 0.199700, acc.: 67.19%] [G loss: 0.472568]\n",
      "epoch:9 step:8589 [D loss: 0.207997, acc.: 71.88%] [G loss: 0.500601]\n",
      "epoch:9 step:8590 [D loss: 0.240415, acc.: 56.25%] [G loss: 0.426258]\n",
      "epoch:9 step:8591 [D loss: 0.211601, acc.: 69.53%] [G loss: 0.472866]\n",
      "epoch:9 step:8592 [D loss: 0.199490, acc.: 71.88%] [G loss: 0.491575]\n",
      "epoch:9 step:8593 [D loss: 0.262097, acc.: 58.59%] [G loss: 0.468112]\n",
      "epoch:9 step:8594 [D loss: 0.239673, acc.: 60.94%] [G loss: 0.482502]\n",
      "epoch:9 step:8595 [D loss: 0.240408, acc.: 61.72%] [G loss: 0.482314]\n",
      "epoch:9 step:8596 [D loss: 0.231015, acc.: 64.06%] [G loss: 0.467299]\n",
      "epoch:9 step:8597 [D loss: 0.210481, acc.: 66.41%] [G loss: 0.468196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8598 [D loss: 0.209925, acc.: 67.97%] [G loss: 0.486181]\n",
      "epoch:9 step:8599 [D loss: 0.209607, acc.: 60.94%] [G loss: 0.436710]\n",
      "epoch:9 step:8600 [D loss: 0.221467, acc.: 64.84%] [G loss: 0.432515]\n",
      "epoch:9 step:8601 [D loss: 0.212544, acc.: 67.19%] [G loss: 0.478269]\n",
      "epoch:9 step:8602 [D loss: 0.225782, acc.: 61.72%] [G loss: 0.457829]\n",
      "epoch:9 step:8603 [D loss: 0.238572, acc.: 63.28%] [G loss: 0.489353]\n",
      "epoch:9 step:8604 [D loss: 0.225417, acc.: 60.16%] [G loss: 0.470005]\n",
      "epoch:9 step:8605 [D loss: 0.234174, acc.: 57.03%] [G loss: 0.444421]\n",
      "epoch:9 step:8606 [D loss: 0.201577, acc.: 68.75%] [G loss: 0.508086]\n",
      "epoch:9 step:8607 [D loss: 0.263458, acc.: 54.69%] [G loss: 0.445678]\n",
      "epoch:9 step:8608 [D loss: 0.248056, acc.: 60.94%] [G loss: 0.456265]\n",
      "epoch:9 step:8609 [D loss: 0.197772, acc.: 66.41%] [G loss: 0.458544]\n",
      "epoch:9 step:8610 [D loss: 0.242792, acc.: 62.50%] [G loss: 0.478261]\n",
      "epoch:9 step:8611 [D loss: 0.235321, acc.: 64.06%] [G loss: 0.460932]\n",
      "epoch:9 step:8612 [D loss: 0.244847, acc.: 61.72%] [G loss: 0.467851]\n",
      "epoch:9 step:8613 [D loss: 0.249176, acc.: 56.25%] [G loss: 0.446628]\n",
      "epoch:9 step:8614 [D loss: 0.224387, acc.: 66.41%] [G loss: 0.495408]\n",
      "epoch:9 step:8615 [D loss: 0.293164, acc.: 54.69%] [G loss: 0.422061]\n",
      "epoch:9 step:8616 [D loss: 0.260308, acc.: 56.25%] [G loss: 0.427825]\n",
      "epoch:9 step:8617 [D loss: 0.214316, acc.: 65.62%] [G loss: 0.466898]\n",
      "epoch:9 step:8618 [D loss: 0.205428, acc.: 70.31%] [G loss: 0.459577]\n",
      "epoch:9 step:8619 [D loss: 0.222288, acc.: 67.19%] [G loss: 0.502348]\n",
      "epoch:9 step:8620 [D loss: 0.258580, acc.: 54.69%] [G loss: 0.448881]\n",
      "epoch:9 step:8621 [D loss: 0.226332, acc.: 62.50%] [G loss: 0.449748]\n",
      "epoch:9 step:8622 [D loss: 0.262920, acc.: 54.69%] [G loss: 0.439297]\n",
      "epoch:9 step:8623 [D loss: 0.207654, acc.: 66.41%] [G loss: 0.432806]\n",
      "epoch:9 step:8624 [D loss: 0.190973, acc.: 75.78%] [G loss: 0.482118]\n",
      "epoch:9 step:8625 [D loss: 0.220626, acc.: 61.72%] [G loss: 0.493935]\n",
      "epoch:9 step:8626 [D loss: 0.217077, acc.: 60.16%] [G loss: 0.485045]\n",
      "epoch:9 step:8627 [D loss: 0.185704, acc.: 74.22%] [G loss: 0.490809]\n",
      "epoch:9 step:8628 [D loss: 0.233450, acc.: 57.03%] [G loss: 0.475673]\n",
      "epoch:9 step:8629 [D loss: 0.248253, acc.: 58.59%] [G loss: 0.440185]\n",
      "epoch:9 step:8630 [D loss: 0.222702, acc.: 62.50%] [G loss: 0.462711]\n",
      "epoch:9 step:8631 [D loss: 0.189693, acc.: 69.53%] [G loss: 0.512566]\n",
      "epoch:9 step:8632 [D loss: 0.250977, acc.: 53.91%] [G loss: 0.463237]\n",
      "epoch:9 step:8633 [D loss: 0.225213, acc.: 60.16%] [G loss: 0.474860]\n",
      "epoch:9 step:8634 [D loss: 0.241194, acc.: 62.50%] [G loss: 0.452244]\n",
      "epoch:9 step:8635 [D loss: 0.206892, acc.: 67.19%] [G loss: 0.457889]\n",
      "epoch:9 step:8636 [D loss: 0.236497, acc.: 61.72%] [G loss: 0.464361]\n",
      "epoch:9 step:8637 [D loss: 0.209652, acc.: 64.84%] [G loss: 0.461880]\n",
      "epoch:9 step:8638 [D loss: 0.212696, acc.: 69.53%] [G loss: 0.509106]\n",
      "epoch:9 step:8639 [D loss: 0.201285, acc.: 70.31%] [G loss: 0.527297]\n",
      "epoch:9 step:8640 [D loss: 0.182302, acc.: 69.53%] [G loss: 0.526045]\n",
      "epoch:9 step:8641 [D loss: 0.226353, acc.: 64.84%] [G loss: 0.526291]\n",
      "epoch:9 step:8642 [D loss: 0.206743, acc.: 67.19%] [G loss: 0.575531]\n",
      "epoch:9 step:8643 [D loss: 0.265608, acc.: 52.34%] [G loss: 0.471915]\n",
      "epoch:9 step:8644 [D loss: 0.258640, acc.: 56.25%] [G loss: 0.428361]\n",
      "epoch:9 step:8645 [D loss: 0.258107, acc.: 57.03%] [G loss: 0.414688]\n",
      "epoch:9 step:8646 [D loss: 0.216622, acc.: 60.94%] [G loss: 0.443008]\n",
      "epoch:9 step:8647 [D loss: 0.259730, acc.: 56.25%] [G loss: 0.417639]\n",
      "epoch:9 step:8648 [D loss: 0.247069, acc.: 60.94%] [G loss: 0.415194]\n",
      "epoch:9 step:8649 [D loss: 0.217592, acc.: 60.94%] [G loss: 0.456846]\n",
      "epoch:9 step:8650 [D loss: 0.232046, acc.: 62.50%] [G loss: 0.467970]\n",
      "epoch:9 step:8651 [D loss: 0.185756, acc.: 71.88%] [G loss: 0.520253]\n",
      "epoch:9 step:8652 [D loss: 0.191489, acc.: 67.19%] [G loss: 0.483674]\n",
      "epoch:9 step:8653 [D loss: 0.266511, acc.: 53.91%] [G loss: 0.439882]\n",
      "epoch:9 step:8654 [D loss: 0.220754, acc.: 65.62%] [G loss: 0.439660]\n",
      "epoch:9 step:8655 [D loss: 0.227628, acc.: 61.72%] [G loss: 0.462093]\n",
      "epoch:9 step:8656 [D loss: 0.230549, acc.: 66.41%] [G loss: 0.481943]\n",
      "epoch:9 step:8657 [D loss: 0.262850, acc.: 57.81%] [G loss: 0.475526]\n",
      "epoch:9 step:8658 [D loss: 0.242178, acc.: 60.16%] [G loss: 0.455246]\n",
      "epoch:9 step:8659 [D loss: 0.252353, acc.: 53.91%] [G loss: 0.432802]\n",
      "epoch:9 step:8660 [D loss: 0.241919, acc.: 55.47%] [G loss: 0.423427]\n",
      "epoch:9 step:8661 [D loss: 0.238621, acc.: 55.47%] [G loss: 0.411205]\n",
      "epoch:9 step:8662 [D loss: 0.210506, acc.: 67.97%] [G loss: 0.471603]\n",
      "epoch:9 step:8663 [D loss: 0.191892, acc.: 69.53%] [G loss: 0.501646]\n",
      "epoch:9 step:8664 [D loss: 0.198152, acc.: 70.31%] [G loss: 0.495155]\n",
      "epoch:9 step:8665 [D loss: 0.180140, acc.: 72.66%] [G loss: 0.570775]\n",
      "epoch:9 step:8666 [D loss: 0.246346, acc.: 63.28%] [G loss: 0.470208]\n",
      "epoch:9 step:8667 [D loss: 0.237911, acc.: 57.03%] [G loss: 0.439729]\n",
      "epoch:9 step:8668 [D loss: 0.235395, acc.: 57.03%] [G loss: 0.422892]\n",
      "epoch:9 step:8669 [D loss: 0.221040, acc.: 64.84%] [G loss: 0.452165]\n",
      "epoch:9 step:8670 [D loss: 0.243507, acc.: 57.03%] [G loss: 0.449157]\n",
      "epoch:9 step:8671 [D loss: 0.231772, acc.: 64.06%] [G loss: 0.482782]\n",
      "epoch:9 step:8672 [D loss: 0.216202, acc.: 71.09%] [G loss: 0.515920]\n",
      "epoch:9 step:8673 [D loss: 0.224034, acc.: 63.28%] [G loss: 0.493615]\n",
      "epoch:9 step:8674 [D loss: 0.194691, acc.: 75.78%] [G loss: 0.510381]\n",
      "epoch:9 step:8675 [D loss: 0.194361, acc.: 71.88%] [G loss: 0.503029]\n",
      "epoch:9 step:8676 [D loss: 0.207770, acc.: 71.88%] [G loss: 0.453442]\n",
      "epoch:9 step:8677 [D loss: 0.211855, acc.: 64.84%] [G loss: 0.472944]\n",
      "epoch:9 step:8678 [D loss: 0.197497, acc.: 67.97%] [G loss: 0.461774]\n",
      "epoch:9 step:8679 [D loss: 0.214965, acc.: 64.84%] [G loss: 0.512510]\n",
      "epoch:9 step:8680 [D loss: 0.230815, acc.: 59.38%] [G loss: 0.459793]\n",
      "epoch:9 step:8681 [D loss: 0.201698, acc.: 70.31%] [G loss: 0.482997]\n",
      "epoch:9 step:8682 [D loss: 0.254284, acc.: 59.38%] [G loss: 0.463492]\n",
      "epoch:9 step:8683 [D loss: 0.287911, acc.: 47.66%] [G loss: 0.436799]\n",
      "epoch:9 step:8684 [D loss: 0.267123, acc.: 56.25%] [G loss: 0.445451]\n",
      "epoch:9 step:8685 [D loss: 0.226686, acc.: 60.94%] [G loss: 0.492383]\n",
      "epoch:9 step:8686 [D loss: 0.214203, acc.: 64.06%] [G loss: 0.475336]\n",
      "epoch:9 step:8687 [D loss: 0.227958, acc.: 63.28%] [G loss: 0.439048]\n",
      "epoch:9 step:8688 [D loss: 0.227438, acc.: 60.16%] [G loss: 0.459199]\n",
      "epoch:9 step:8689 [D loss: 0.224403, acc.: 65.62%] [G loss: 0.463082]\n",
      "epoch:9 step:8690 [D loss: 0.233106, acc.: 57.03%] [G loss: 0.446545]\n",
      "epoch:9 step:8691 [D loss: 0.200577, acc.: 69.53%] [G loss: 0.470355]\n",
      "epoch:9 step:8692 [D loss: 0.201773, acc.: 70.31%] [G loss: 0.473835]\n",
      "epoch:9 step:8693 [D loss: 0.225097, acc.: 60.16%] [G loss: 0.482420]\n",
      "epoch:9 step:8694 [D loss: 0.216941, acc.: 57.81%] [G loss: 0.461270]\n",
      "epoch:9 step:8695 [D loss: 0.201709, acc.: 66.41%] [G loss: 0.529942]\n",
      "epoch:9 step:8696 [D loss: 0.224809, acc.: 63.28%] [G loss: 0.496805]\n",
      "epoch:9 step:8697 [D loss: 0.189783, acc.: 68.75%] [G loss: 0.461753]\n",
      "epoch:9 step:8698 [D loss: 0.262092, acc.: 51.56%] [G loss: 0.457661]\n",
      "epoch:9 step:8699 [D loss: 0.237236, acc.: 56.25%] [G loss: 0.415911]\n",
      "epoch:9 step:8700 [D loss: 0.233107, acc.: 60.94%] [G loss: 0.472382]\n",
      "epoch:9 step:8701 [D loss: 0.222101, acc.: 62.50%] [G loss: 0.494029]\n",
      "epoch:9 step:8702 [D loss: 0.211163, acc.: 64.84%] [G loss: 0.523916]\n",
      "epoch:9 step:8703 [D loss: 0.199058, acc.: 69.53%] [G loss: 0.473503]\n",
      "epoch:9 step:8704 [D loss: 0.209476, acc.: 69.53%] [G loss: 0.487855]\n",
      "epoch:9 step:8705 [D loss: 0.218792, acc.: 63.28%] [G loss: 0.486745]\n",
      "epoch:9 step:8706 [D loss: 0.202095, acc.: 71.88%] [G loss: 0.470570]\n",
      "epoch:9 step:8707 [D loss: 0.206519, acc.: 68.75%] [G loss: 0.503108]\n",
      "epoch:9 step:8708 [D loss: 0.239486, acc.: 59.38%] [G loss: 0.500431]\n",
      "epoch:9 step:8709 [D loss: 0.216423, acc.: 67.19%] [G loss: 0.476802]\n",
      "epoch:9 step:8710 [D loss: 0.278703, acc.: 50.78%] [G loss: 0.426495]\n",
      "epoch:9 step:8711 [D loss: 0.242797, acc.: 54.69%] [G loss: 0.453474]\n",
      "epoch:9 step:8712 [D loss: 0.225889, acc.: 59.38%] [G loss: 0.448663]\n",
      "epoch:9 step:8713 [D loss: 0.229470, acc.: 64.84%] [G loss: 0.460362]\n",
      "epoch:9 step:8714 [D loss: 0.265783, acc.: 53.91%] [G loss: 0.418467]\n",
      "epoch:9 step:8715 [D loss: 0.225067, acc.: 64.06%] [G loss: 0.444650]\n",
      "epoch:9 step:8716 [D loss: 0.204120, acc.: 71.88%] [G loss: 0.469960]\n",
      "epoch:9 step:8717 [D loss: 0.193909, acc.: 71.88%] [G loss: 0.480756]\n",
      "epoch:9 step:8718 [D loss: 0.200909, acc.: 71.88%] [G loss: 0.451231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8719 [D loss: 0.204758, acc.: 66.41%] [G loss: 0.507480]\n",
      "epoch:9 step:8720 [D loss: 0.230335, acc.: 67.19%] [G loss: 0.483886]\n",
      "epoch:9 step:8721 [D loss: 0.212737, acc.: 64.06%] [G loss: 0.468275]\n",
      "epoch:9 step:8722 [D loss: 0.212008, acc.: 64.84%] [G loss: 0.491648]\n",
      "epoch:9 step:8723 [D loss: 0.209611, acc.: 67.19%] [G loss: 0.506794]\n",
      "epoch:9 step:8724 [D loss: 0.239932, acc.: 63.28%] [G loss: 0.498684]\n",
      "epoch:9 step:8725 [D loss: 0.233042, acc.: 64.06%] [G loss: 0.462571]\n",
      "epoch:9 step:8726 [D loss: 0.227206, acc.: 63.28%] [G loss: 0.447629]\n",
      "epoch:9 step:8727 [D loss: 0.241681, acc.: 61.72%] [G loss: 0.441336]\n",
      "epoch:9 step:8728 [D loss: 0.232778, acc.: 56.25%] [G loss: 0.477451]\n",
      "epoch:9 step:8729 [D loss: 0.190606, acc.: 73.44%] [G loss: 0.472937]\n",
      "epoch:9 step:8730 [D loss: 0.234573, acc.: 58.59%] [G loss: 0.440225]\n",
      "epoch:9 step:8731 [D loss: 0.224151, acc.: 62.50%] [G loss: 0.481953]\n",
      "epoch:9 step:8732 [D loss: 0.196732, acc.: 71.88%] [G loss: 0.473623]\n",
      "epoch:9 step:8733 [D loss: 0.197698, acc.: 73.44%] [G loss: 0.473986]\n",
      "epoch:9 step:8734 [D loss: 0.325254, acc.: 41.41%] [G loss: 0.437971]\n",
      "epoch:9 step:8735 [D loss: 0.221411, acc.: 64.84%] [G loss: 0.455154]\n",
      "epoch:9 step:8736 [D loss: 0.234955, acc.: 63.28%] [G loss: 0.456875]\n",
      "epoch:9 step:8737 [D loss: 0.226849, acc.: 57.81%] [G loss: 0.454392]\n",
      "epoch:9 step:8738 [D loss: 0.206981, acc.: 65.62%] [G loss: 0.481624]\n",
      "epoch:9 step:8739 [D loss: 0.215736, acc.: 65.62%] [G loss: 0.456649]\n",
      "epoch:9 step:8740 [D loss: 0.213616, acc.: 65.62%] [G loss: 0.475309]\n",
      "epoch:9 step:8741 [D loss: 0.229874, acc.: 60.94%] [G loss: 0.427226]\n",
      "epoch:9 step:8742 [D loss: 0.191033, acc.: 74.22%] [G loss: 0.477739]\n",
      "epoch:9 step:8743 [D loss: 0.234342, acc.: 61.72%] [G loss: 0.469205]\n",
      "epoch:9 step:8744 [D loss: 0.203513, acc.: 71.09%] [G loss: 0.480818]\n",
      "epoch:9 step:8745 [D loss: 0.184058, acc.: 70.31%] [G loss: 0.534923]\n",
      "epoch:9 step:8746 [D loss: 0.185053, acc.: 71.88%] [G loss: 0.595012]\n",
      "epoch:9 step:8747 [D loss: 0.169774, acc.: 69.53%] [G loss: 0.483053]\n",
      "epoch:9 step:8748 [D loss: 0.194082, acc.: 66.41%] [G loss: 0.509138]\n",
      "epoch:9 step:8749 [D loss: 0.257529, acc.: 60.94%] [G loss: 0.459117]\n",
      "epoch:9 step:8750 [D loss: 0.218185, acc.: 64.06%] [G loss: 0.437583]\n",
      "epoch:9 step:8751 [D loss: 0.208565, acc.: 69.53%] [G loss: 0.477303]\n",
      "epoch:9 step:8752 [D loss: 0.199863, acc.: 67.97%] [G loss: 0.491568]\n",
      "epoch:9 step:8753 [D loss: 0.219823, acc.: 62.50%] [G loss: 0.441219]\n",
      "epoch:9 step:8754 [D loss: 0.206082, acc.: 67.97%] [G loss: 0.478792]\n",
      "epoch:9 step:8755 [D loss: 0.228124, acc.: 64.84%] [G loss: 0.470562]\n",
      "epoch:9 step:8756 [D loss: 0.263332, acc.: 51.56%] [G loss: 0.427686]\n",
      "epoch:9 step:8757 [D loss: 0.214742, acc.: 63.28%] [G loss: 0.452938]\n",
      "epoch:9 step:8758 [D loss: 0.221875, acc.: 60.16%] [G loss: 0.461758]\n",
      "epoch:9 step:8759 [D loss: 0.203504, acc.: 71.09%] [G loss: 0.476465]\n",
      "epoch:9 step:8760 [D loss: 0.250875, acc.: 59.38%] [G loss: 0.445299]\n",
      "epoch:9 step:8761 [D loss: 0.203496, acc.: 67.19%] [G loss: 0.502574]\n",
      "epoch:9 step:8762 [D loss: 0.213657, acc.: 64.06%] [G loss: 0.482149]\n",
      "epoch:9 step:8763 [D loss: 0.231645, acc.: 62.50%] [G loss: 0.444993]\n",
      "epoch:9 step:8764 [D loss: 0.220900, acc.: 66.41%] [G loss: 0.422568]\n",
      "epoch:9 step:8765 [D loss: 0.199205, acc.: 67.97%] [G loss: 0.454590]\n",
      "epoch:9 step:8766 [D loss: 0.207538, acc.: 65.62%] [G loss: 0.462019]\n",
      "epoch:9 step:8767 [D loss: 0.223441, acc.: 65.62%] [G loss: 0.446053]\n",
      "epoch:9 step:8768 [D loss: 0.211131, acc.: 70.31%] [G loss: 0.502424]\n",
      "epoch:9 step:8769 [D loss: 0.199132, acc.: 72.66%] [G loss: 0.476750]\n",
      "epoch:9 step:8770 [D loss: 0.229882, acc.: 64.06%] [G loss: 0.491943]\n",
      "epoch:9 step:8771 [D loss: 0.223203, acc.: 67.19%] [G loss: 0.438471]\n",
      "epoch:9 step:8772 [D loss: 0.208501, acc.: 74.22%] [G loss: 0.491433]\n",
      "epoch:9 step:8773 [D loss: 0.199257, acc.: 67.97%] [G loss: 0.524593]\n",
      "epoch:9 step:8774 [D loss: 0.288116, acc.: 50.00%] [G loss: 0.446660]\n",
      "epoch:9 step:8775 [D loss: 0.248133, acc.: 55.47%] [G loss: 0.485117]\n",
      "epoch:9 step:8776 [D loss: 0.212448, acc.: 64.06%] [G loss: 0.492077]\n",
      "epoch:9 step:8777 [D loss: 0.190878, acc.: 71.09%] [G loss: 0.501805]\n",
      "epoch:9 step:8778 [D loss: 0.211004, acc.: 64.84%] [G loss: 0.488160]\n",
      "epoch:9 step:8779 [D loss: 0.202516, acc.: 64.84%] [G loss: 0.524933]\n",
      "epoch:9 step:8780 [D loss: 0.194964, acc.: 74.22%] [G loss: 0.539078]\n",
      "epoch:9 step:8781 [D loss: 0.292085, acc.: 55.47%] [G loss: 0.487212]\n",
      "epoch:9 step:8782 [D loss: 0.282041, acc.: 45.31%] [G loss: 0.439486]\n",
      "epoch:9 step:8783 [D loss: 0.213154, acc.: 63.28%] [G loss: 0.434613]\n",
      "epoch:9 step:8784 [D loss: 0.229153, acc.: 60.94%] [G loss: 0.446045]\n",
      "epoch:9 step:8785 [D loss: 0.234726, acc.: 61.72%] [G loss: 0.448402]\n",
      "epoch:9 step:8786 [D loss: 0.202514, acc.: 64.06%] [G loss: 0.486078]\n",
      "epoch:9 step:8787 [D loss: 0.156343, acc.: 78.12%] [G loss: 0.509749]\n",
      "epoch:9 step:8788 [D loss: 0.228940, acc.: 64.84%] [G loss: 0.468981]\n",
      "epoch:9 step:8789 [D loss: 0.237380, acc.: 63.28%] [G loss: 0.468753]\n",
      "epoch:9 step:8790 [D loss: 0.212082, acc.: 67.19%] [G loss: 0.490913]\n",
      "epoch:9 step:8791 [D loss: 0.187303, acc.: 71.09%] [G loss: 0.522609]\n",
      "epoch:9 step:8792 [D loss: 0.203481, acc.: 70.31%] [G loss: 0.471222]\n",
      "epoch:9 step:8793 [D loss: 0.204394, acc.: 67.19%] [G loss: 0.463085]\n",
      "epoch:9 step:8794 [D loss: 0.213185, acc.: 71.88%] [G loss: 0.481522]\n",
      "epoch:9 step:8795 [D loss: 0.245075, acc.: 53.91%] [G loss: 0.441757]\n",
      "epoch:9 step:8796 [D loss: 0.210612, acc.: 65.62%] [G loss: 0.478022]\n",
      "epoch:9 step:8797 [D loss: 0.220226, acc.: 64.06%] [G loss: 0.479314]\n",
      "epoch:9 step:8798 [D loss: 0.216618, acc.: 66.41%] [G loss: 0.464119]\n",
      "epoch:9 step:8799 [D loss: 0.211476, acc.: 65.62%] [G loss: 0.479436]\n",
      "epoch:9 step:8800 [D loss: 0.227412, acc.: 58.59%] [G loss: 0.484886]\n",
      "epoch:9 step:8801 [D loss: 0.254375, acc.: 60.16%] [G loss: 0.454958]\n",
      "epoch:9 step:8802 [D loss: 0.231223, acc.: 67.19%] [G loss: 0.416575]\n",
      "epoch:9 step:8803 [D loss: 0.216542, acc.: 66.41%] [G loss: 0.449506]\n",
      "epoch:9 step:8804 [D loss: 0.204730, acc.: 67.19%] [G loss: 0.465985]\n",
      "epoch:9 step:8805 [D loss: 0.228119, acc.: 60.94%] [G loss: 0.456790]\n",
      "epoch:9 step:8806 [D loss: 0.241382, acc.: 57.81%] [G loss: 0.417156]\n",
      "epoch:9 step:8807 [D loss: 0.212302, acc.: 68.75%] [G loss: 0.470601]\n",
      "epoch:9 step:8808 [D loss: 0.242597, acc.: 54.69%] [G loss: 0.478312]\n",
      "epoch:9 step:8809 [D loss: 0.257409, acc.: 52.34%] [G loss: 0.434897]\n",
      "epoch:9 step:8810 [D loss: 0.273374, acc.: 46.88%] [G loss: 0.389782]\n",
      "epoch:9 step:8811 [D loss: 0.222502, acc.: 64.84%] [G loss: 0.414881]\n",
      "epoch:9 step:8812 [D loss: 0.214293, acc.: 64.84%] [G loss: 0.444000]\n",
      "epoch:9 step:8813 [D loss: 0.225775, acc.: 62.50%] [G loss: 0.428284]\n",
      "epoch:9 step:8814 [D loss: 0.185448, acc.: 74.22%] [G loss: 0.446227]\n",
      "epoch:9 step:8815 [D loss: 0.200111, acc.: 70.31%] [G loss: 0.473131]\n",
      "epoch:9 step:8816 [D loss: 0.239476, acc.: 57.81%] [G loss: 0.440126]\n",
      "epoch:9 step:8817 [D loss: 0.214842, acc.: 65.62%] [G loss: 0.464542]\n",
      "epoch:9 step:8818 [D loss: 0.212104, acc.: 67.97%] [G loss: 0.470246]\n",
      "epoch:9 step:8819 [D loss: 0.253077, acc.: 56.25%] [G loss: 0.463267]\n",
      "epoch:9 step:8820 [D loss: 0.216392, acc.: 69.53%] [G loss: 0.503954]\n",
      "epoch:9 step:8821 [D loss: 0.238073, acc.: 54.69%] [G loss: 0.489946]\n",
      "epoch:9 step:8822 [D loss: 0.230095, acc.: 60.94%] [G loss: 0.519028]\n",
      "epoch:9 step:8823 [D loss: 0.231341, acc.: 61.72%] [G loss: 0.455825]\n",
      "epoch:9 step:8824 [D loss: 0.190596, acc.: 71.88%] [G loss: 0.504164]\n",
      "epoch:9 step:8825 [D loss: 0.202446, acc.: 69.53%] [G loss: 0.462261]\n",
      "epoch:9 step:8826 [D loss: 0.263302, acc.: 55.47%] [G loss: 0.466995]\n",
      "epoch:9 step:8827 [D loss: 0.197502, acc.: 70.31%] [G loss: 0.478896]\n",
      "epoch:9 step:8828 [D loss: 0.230577, acc.: 59.38%] [G loss: 0.462701]\n",
      "epoch:9 step:8829 [D loss: 0.253845, acc.: 55.47%] [G loss: 0.440426]\n",
      "epoch:9 step:8830 [D loss: 0.218143, acc.: 67.19%] [G loss: 0.451139]\n",
      "epoch:9 step:8831 [D loss: 0.210950, acc.: 70.31%] [G loss: 0.532787]\n",
      "epoch:9 step:8832 [D loss: 0.192841, acc.: 69.53%] [G loss: 0.501000]\n",
      "epoch:9 step:8833 [D loss: 0.296740, acc.: 41.41%] [G loss: 0.415292]\n",
      "epoch:9 step:8834 [D loss: 0.242161, acc.: 54.69%] [G loss: 0.440550]\n",
      "epoch:9 step:8835 [D loss: 0.215046, acc.: 62.50%] [G loss: 0.429019]\n",
      "epoch:9 step:8836 [D loss: 0.225434, acc.: 61.72%] [G loss: 0.490483]\n",
      "epoch:9 step:8837 [D loss: 0.230842, acc.: 60.94%] [G loss: 0.470616]\n",
      "epoch:9 step:8838 [D loss: 0.194311, acc.: 71.88%] [G loss: 0.526982]\n",
      "epoch:9 step:8839 [D loss: 0.189181, acc.: 72.66%] [G loss: 0.494010]\n",
      "epoch:9 step:8840 [D loss: 0.258143, acc.: 58.59%] [G loss: 0.449241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8841 [D loss: 0.232063, acc.: 61.72%] [G loss: 0.450188]\n",
      "epoch:9 step:8842 [D loss: 0.229617, acc.: 63.28%] [G loss: 0.435770]\n",
      "epoch:9 step:8843 [D loss: 0.246238, acc.: 60.16%] [G loss: 0.444693]\n",
      "epoch:9 step:8844 [D loss: 0.240378, acc.: 59.38%] [G loss: 0.434291]\n",
      "epoch:9 step:8845 [D loss: 0.236085, acc.: 60.16%] [G loss: 0.457427]\n",
      "epoch:9 step:8846 [D loss: 0.253423, acc.: 61.72%] [G loss: 0.492616]\n",
      "epoch:9 step:8847 [D loss: 0.246227, acc.: 57.03%] [G loss: 0.456839]\n",
      "epoch:9 step:8848 [D loss: 0.205341, acc.: 68.75%] [G loss: 0.500747]\n",
      "epoch:9 step:8849 [D loss: 0.184081, acc.: 75.78%] [G loss: 0.544259]\n",
      "epoch:9 step:8850 [D loss: 0.243953, acc.: 59.38%] [G loss: 0.483107]\n",
      "epoch:9 step:8851 [D loss: 0.249871, acc.: 57.03%] [G loss: 0.470531]\n",
      "epoch:9 step:8852 [D loss: 0.233688, acc.: 65.62%] [G loss: 0.484308]\n",
      "epoch:9 step:8853 [D loss: 0.218798, acc.: 64.06%] [G loss: 0.436663]\n",
      "epoch:9 step:8854 [D loss: 0.270131, acc.: 57.81%] [G loss: 0.436996]\n",
      "epoch:9 step:8855 [D loss: 0.247677, acc.: 57.81%] [G loss: 0.414081]\n",
      "epoch:9 step:8856 [D loss: 0.236213, acc.: 55.47%] [G loss: 0.412786]\n",
      "epoch:9 step:8857 [D loss: 0.240560, acc.: 59.38%] [G loss: 0.488350]\n",
      "epoch:9 step:8858 [D loss: 0.192694, acc.: 67.19%] [G loss: 0.491142]\n",
      "epoch:9 step:8859 [D loss: 0.205166, acc.: 68.75%] [G loss: 0.478772]\n",
      "epoch:9 step:8860 [D loss: 0.205679, acc.: 68.75%] [G loss: 0.494799]\n",
      "epoch:9 step:8861 [D loss: 0.195850, acc.: 68.75%] [G loss: 0.524876]\n",
      "epoch:9 step:8862 [D loss: 0.218279, acc.: 69.53%] [G loss: 0.519525]\n",
      "epoch:9 step:8863 [D loss: 0.208894, acc.: 69.53%] [G loss: 0.539633]\n",
      "epoch:9 step:8864 [D loss: 0.237306, acc.: 60.16%] [G loss: 0.462303]\n",
      "epoch:9 step:8865 [D loss: 0.228353, acc.: 57.81%] [G loss: 0.462565]\n",
      "epoch:9 step:8866 [D loss: 0.253462, acc.: 54.69%] [G loss: 0.395494]\n",
      "epoch:9 step:8867 [D loss: 0.208431, acc.: 67.97%] [G loss: 0.492105]\n",
      "epoch:9 step:8868 [D loss: 0.216167, acc.: 66.41%] [G loss: 0.481088]\n",
      "epoch:9 step:8869 [D loss: 0.188880, acc.: 69.53%] [G loss: 0.479897]\n",
      "epoch:9 step:8870 [D loss: 0.273544, acc.: 51.56%] [G loss: 0.434534]\n",
      "epoch:9 step:8871 [D loss: 0.236121, acc.: 61.72%] [G loss: 0.436985]\n",
      "epoch:9 step:8872 [D loss: 0.219001, acc.: 63.28%] [G loss: 0.466890]\n",
      "epoch:9 step:8873 [D loss: 0.221028, acc.: 63.28%] [G loss: 0.467681]\n",
      "epoch:9 step:8874 [D loss: 0.220719, acc.: 64.06%] [G loss: 0.519444]\n",
      "epoch:9 step:8875 [D loss: 0.254695, acc.: 60.16%] [G loss: 0.453085]\n",
      "epoch:9 step:8876 [D loss: 0.237281, acc.: 59.38%] [G loss: 0.488385]\n",
      "epoch:9 step:8877 [D loss: 0.208385, acc.: 67.97%] [G loss: 0.479710]\n",
      "epoch:9 step:8878 [D loss: 0.228337, acc.: 58.59%] [G loss: 0.463533]\n",
      "epoch:9 step:8879 [D loss: 0.205086, acc.: 72.66%] [G loss: 0.488675]\n",
      "epoch:9 step:8880 [D loss: 0.209226, acc.: 69.53%] [G loss: 0.460820]\n",
      "epoch:9 step:8881 [D loss: 0.231141, acc.: 60.16%] [G loss: 0.429400]\n",
      "epoch:9 step:8882 [D loss: 0.204798, acc.: 65.62%] [G loss: 0.460964]\n",
      "epoch:9 step:8883 [D loss: 0.223286, acc.: 60.94%] [G loss: 0.474773]\n",
      "epoch:9 step:8884 [D loss: 0.191508, acc.: 75.00%] [G loss: 0.469075]\n",
      "epoch:9 step:8885 [D loss: 0.216208, acc.: 64.06%] [G loss: 0.481848]\n",
      "epoch:9 step:8886 [D loss: 0.182120, acc.: 72.66%] [G loss: 0.467731]\n",
      "epoch:9 step:8887 [D loss: 0.221155, acc.: 68.75%] [G loss: 0.485066]\n",
      "epoch:9 step:8888 [D loss: 0.250056, acc.: 56.25%] [G loss: 0.444294]\n",
      "epoch:9 step:8889 [D loss: 0.249457, acc.: 57.03%] [G loss: 0.439036]\n",
      "epoch:9 step:8890 [D loss: 0.221761, acc.: 66.41%] [G loss: 0.486986]\n",
      "epoch:9 step:8891 [D loss: 0.248049, acc.: 60.16%] [G loss: 0.438559]\n",
      "epoch:9 step:8892 [D loss: 0.245350, acc.: 58.59%] [G loss: 0.446921]\n",
      "epoch:9 step:8893 [D loss: 0.220335, acc.: 64.06%] [G loss: 0.455956]\n",
      "epoch:9 step:8894 [D loss: 0.233060, acc.: 60.94%] [G loss: 0.454682]\n",
      "epoch:9 step:8895 [D loss: 0.239492, acc.: 60.16%] [G loss: 0.473484]\n",
      "epoch:9 step:8896 [D loss: 0.232595, acc.: 60.94%] [G loss: 0.421755]\n",
      "epoch:9 step:8897 [D loss: 0.209088, acc.: 66.41%] [G loss: 0.402004]\n",
      "epoch:9 step:8898 [D loss: 0.263584, acc.: 54.69%] [G loss: 0.411931]\n",
      "epoch:9 step:8899 [D loss: 0.223370, acc.: 63.28%] [G loss: 0.422551]\n",
      "epoch:9 step:8900 [D loss: 0.225282, acc.: 65.62%] [G loss: 0.488268]\n",
      "epoch:9 step:8901 [D loss: 0.235352, acc.: 62.50%] [G loss: 0.479620]\n",
      "epoch:9 step:8902 [D loss: 0.201656, acc.: 65.62%] [G loss: 0.519972]\n",
      "epoch:9 step:8903 [D loss: 0.214601, acc.: 70.31%] [G loss: 0.480407]\n",
      "epoch:9 step:8904 [D loss: 0.216950, acc.: 66.41%] [G loss: 0.553717]\n",
      "epoch:9 step:8905 [D loss: 0.190385, acc.: 70.31%] [G loss: 0.488565]\n",
      "epoch:9 step:8906 [D loss: 0.273699, acc.: 52.34%] [G loss: 0.428134]\n",
      "epoch:9 step:8907 [D loss: 0.225616, acc.: 62.50%] [G loss: 0.476532]\n",
      "epoch:9 step:8908 [D loss: 0.206112, acc.: 68.75%] [G loss: 0.478174]\n",
      "epoch:9 step:8909 [D loss: 0.216458, acc.: 67.97%] [G loss: 0.508149]\n",
      "epoch:9 step:8910 [D loss: 0.266996, acc.: 50.78%] [G loss: 0.413147]\n",
      "epoch:9 step:8911 [D loss: 0.235327, acc.: 63.28%] [G loss: 0.414301]\n",
      "epoch:9 step:8912 [D loss: 0.241584, acc.: 60.16%] [G loss: 0.423445]\n",
      "epoch:9 step:8913 [D loss: 0.247522, acc.: 56.25%] [G loss: 0.451662]\n",
      "epoch:9 step:8914 [D loss: 0.180897, acc.: 76.56%] [G loss: 0.482535]\n",
      "epoch:9 step:8915 [D loss: 0.256305, acc.: 53.12%] [G loss: 0.443557]\n",
      "epoch:9 step:8916 [D loss: 0.259832, acc.: 54.69%] [G loss: 0.434226]\n",
      "epoch:9 step:8917 [D loss: 0.182568, acc.: 78.12%] [G loss: 0.488046]\n",
      "epoch:9 step:8918 [D loss: 0.223007, acc.: 59.38%] [G loss: 0.464876]\n",
      "epoch:9 step:8919 [D loss: 0.230837, acc.: 63.28%] [G loss: 0.468865]\n",
      "epoch:9 step:8920 [D loss: 0.232948, acc.: 57.81%] [G loss: 0.435166]\n",
      "epoch:9 step:8921 [D loss: 0.198168, acc.: 68.75%] [G loss: 0.469957]\n",
      "epoch:9 step:8922 [D loss: 0.249999, acc.: 57.81%] [G loss: 0.433912]\n",
      "epoch:9 step:8923 [D loss: 0.245168, acc.: 57.81%] [G loss: 0.426435]\n",
      "epoch:9 step:8924 [D loss: 0.215566, acc.: 66.41%] [G loss: 0.467701]\n",
      "epoch:9 step:8925 [D loss: 0.231946, acc.: 62.50%] [G loss: 0.459888]\n",
      "epoch:9 step:8926 [D loss: 0.217285, acc.: 67.97%] [G loss: 0.438066]\n",
      "epoch:9 step:8927 [D loss: 0.195101, acc.: 73.44%] [G loss: 0.473542]\n",
      "epoch:9 step:8928 [D loss: 0.194097, acc.: 73.44%] [G loss: 0.457395]\n",
      "epoch:9 step:8929 [D loss: 0.221598, acc.: 64.06%] [G loss: 0.522294]\n",
      "epoch:9 step:8930 [D loss: 0.210505, acc.: 70.31%] [G loss: 0.450905]\n",
      "epoch:9 step:8931 [D loss: 0.208676, acc.: 67.97%] [G loss: 0.511176]\n",
      "epoch:9 step:8932 [D loss: 0.181588, acc.: 70.31%] [G loss: 0.538759]\n",
      "epoch:9 step:8933 [D loss: 0.274199, acc.: 55.47%] [G loss: 0.459318]\n",
      "epoch:9 step:8934 [D loss: 0.253946, acc.: 57.81%] [G loss: 0.429461]\n",
      "epoch:9 step:8935 [D loss: 0.215186, acc.: 67.19%] [G loss: 0.452386]\n",
      "epoch:9 step:8936 [D loss: 0.211501, acc.: 62.50%] [G loss: 0.467101]\n",
      "epoch:9 step:8937 [D loss: 0.198128, acc.: 69.53%] [G loss: 0.527768]\n",
      "epoch:9 step:8938 [D loss: 0.203110, acc.: 68.75%] [G loss: 0.511135]\n",
      "epoch:9 step:8939 [D loss: 0.227564, acc.: 66.41%] [G loss: 0.504684]\n",
      "epoch:9 step:8940 [D loss: 0.205712, acc.: 65.62%] [G loss: 0.518343]\n",
      "epoch:9 step:8941 [D loss: 0.175254, acc.: 72.66%] [G loss: 0.523497]\n",
      "epoch:9 step:8942 [D loss: 0.240273, acc.: 60.94%] [G loss: 0.458166]\n",
      "epoch:9 step:8943 [D loss: 0.242889, acc.: 56.25%] [G loss: 0.436346]\n",
      "epoch:9 step:8944 [D loss: 0.225986, acc.: 57.03%] [G loss: 0.461694]\n",
      "epoch:9 step:8945 [D loss: 0.228195, acc.: 64.84%] [G loss: 0.445670]\n",
      "epoch:9 step:8946 [D loss: 0.218278, acc.: 70.31%] [G loss: 0.443819]\n",
      "epoch:9 step:8947 [D loss: 0.211770, acc.: 64.84%] [G loss: 0.476997]\n",
      "epoch:9 step:8948 [D loss: 0.177325, acc.: 78.12%] [G loss: 0.470213]\n",
      "epoch:9 step:8949 [D loss: 0.208325, acc.: 69.53%] [G loss: 0.454508]\n",
      "epoch:9 step:8950 [D loss: 0.241525, acc.: 57.81%] [G loss: 0.486871]\n",
      "epoch:9 step:8951 [D loss: 0.217330, acc.: 66.41%] [G loss: 0.471269]\n",
      "epoch:9 step:8952 [D loss: 0.197075, acc.: 71.88%] [G loss: 0.465640]\n",
      "epoch:9 step:8953 [D loss: 0.191198, acc.: 67.97%] [G loss: 0.519809]\n",
      "epoch:9 step:8954 [D loss: 0.216981, acc.: 67.19%] [G loss: 0.460704]\n",
      "epoch:9 step:8955 [D loss: 0.205045, acc.: 75.00%] [G loss: 0.513219]\n",
      "epoch:9 step:8956 [D loss: 0.217546, acc.: 71.09%] [G loss: 0.530517]\n",
      "epoch:9 step:8957 [D loss: 0.236311, acc.: 66.41%] [G loss: 0.485427]\n",
      "epoch:9 step:8958 [D loss: 0.234425, acc.: 64.06%] [G loss: 0.465304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8959 [D loss: 0.207657, acc.: 66.41%] [G loss: 0.511769]\n",
      "epoch:9 step:8960 [D loss: 0.253489, acc.: 64.06%] [G loss: 0.437740]\n",
      "epoch:9 step:8961 [D loss: 0.275863, acc.: 50.00%] [G loss: 0.459324]\n",
      "epoch:9 step:8962 [D loss: 0.234572, acc.: 57.81%] [G loss: 0.437564]\n",
      "epoch:9 step:8963 [D loss: 0.191361, acc.: 70.31%] [G loss: 0.475115]\n",
      "epoch:9 step:8964 [D loss: 0.257239, acc.: 51.56%] [G loss: 0.454386]\n",
      "epoch:9 step:8965 [D loss: 0.231182, acc.: 61.72%] [G loss: 0.458767]\n",
      "epoch:9 step:8966 [D loss: 0.230345, acc.: 58.59%] [G loss: 0.460295]\n",
      "epoch:9 step:8967 [D loss: 0.182594, acc.: 69.53%] [G loss: 0.518978]\n",
      "epoch:9 step:8968 [D loss: 0.245457, acc.: 59.38%] [G loss: 0.474144]\n",
      "epoch:9 step:8969 [D loss: 0.222929, acc.: 60.16%] [G loss: 0.464476]\n",
      "epoch:9 step:8970 [D loss: 0.249664, acc.: 58.59%] [G loss: 0.442951]\n",
      "epoch:9 step:8971 [D loss: 0.251453, acc.: 60.94%] [G loss: 0.449368]\n",
      "epoch:9 step:8972 [D loss: 0.250257, acc.: 57.03%] [G loss: 0.478154]\n",
      "epoch:9 step:8973 [D loss: 0.242982, acc.: 56.25%] [G loss: 0.445551]\n",
      "epoch:9 step:8974 [D loss: 0.248764, acc.: 57.03%] [G loss: 0.484514]\n",
      "epoch:9 step:8975 [D loss: 0.267383, acc.: 49.22%] [G loss: 0.461289]\n",
      "epoch:9 step:8976 [D loss: 0.245678, acc.: 61.72%] [G loss: 0.444130]\n",
      "epoch:9 step:8977 [D loss: 0.221109, acc.: 63.28%] [G loss: 0.456326]\n",
      "epoch:9 step:8978 [D loss: 0.229754, acc.: 64.84%] [G loss: 0.460648]\n",
      "epoch:9 step:8979 [D loss: 0.225486, acc.: 63.28%] [G loss: 0.452201]\n",
      "epoch:9 step:8980 [D loss: 0.220386, acc.: 63.28%] [G loss: 0.470720]\n",
      "epoch:9 step:8981 [D loss: 0.187041, acc.: 69.53%] [G loss: 0.461329]\n",
      "epoch:9 step:8982 [D loss: 0.193931, acc.: 69.53%] [G loss: 0.480949]\n",
      "epoch:9 step:8983 [D loss: 0.226957, acc.: 57.81%] [G loss: 0.489230]\n",
      "epoch:9 step:8984 [D loss: 0.227093, acc.: 60.16%] [G loss: 0.482771]\n",
      "epoch:9 step:8985 [D loss: 0.228258, acc.: 64.84%] [G loss: 0.499315]\n",
      "epoch:9 step:8986 [D loss: 0.241896, acc.: 60.16%] [G loss: 0.467770]\n",
      "epoch:9 step:8987 [D loss: 0.191294, acc.: 72.66%] [G loss: 0.515551]\n",
      "epoch:9 step:8988 [D loss: 0.185121, acc.: 73.44%] [G loss: 0.490574]\n",
      "epoch:9 step:8989 [D loss: 0.202004, acc.: 68.75%] [G loss: 0.444624]\n",
      "epoch:9 step:8990 [D loss: 0.195546, acc.: 67.19%] [G loss: 0.485486]\n",
      "epoch:9 step:8991 [D loss: 0.182937, acc.: 74.22%] [G loss: 0.493369]\n",
      "epoch:9 step:8992 [D loss: 0.238205, acc.: 60.16%] [G loss: 0.474698]\n",
      "epoch:9 step:8993 [D loss: 0.242119, acc.: 57.81%] [G loss: 0.430160]\n",
      "epoch:9 step:8994 [D loss: 0.215980, acc.: 64.84%] [G loss: 0.463636]\n",
      "epoch:9 step:8995 [D loss: 0.250742, acc.: 60.16%] [G loss: 0.434246]\n",
      "epoch:9 step:8996 [D loss: 0.202162, acc.: 70.31%] [G loss: 0.480935]\n",
      "epoch:9 step:8997 [D loss: 0.206351, acc.: 64.06%] [G loss: 0.473043]\n",
      "epoch:9 step:8998 [D loss: 0.232808, acc.: 64.84%] [G loss: 0.494195]\n",
      "epoch:9 step:8999 [D loss: 0.247594, acc.: 59.38%] [G loss: 0.473452]\n",
      "epoch:9 step:9000 [D loss: 0.209626, acc.: 65.62%] [G loss: 0.477819]\n",
      "epoch:9 step:9001 [D loss: 0.185600, acc.: 71.88%] [G loss: 0.462430]\n",
      "epoch:9 step:9002 [D loss: 0.273441, acc.: 50.00%] [G loss: 0.423202]\n",
      "epoch:9 step:9003 [D loss: 0.221256, acc.: 69.53%] [G loss: 0.434193]\n",
      "epoch:9 step:9004 [D loss: 0.198057, acc.: 72.66%] [G loss: 0.502735]\n",
      "epoch:9 step:9005 [D loss: 0.207247, acc.: 66.41%] [G loss: 0.422266]\n",
      "epoch:9 step:9006 [D loss: 0.245072, acc.: 58.59%] [G loss: 0.429890]\n",
      "epoch:9 step:9007 [D loss: 0.189443, acc.: 71.88%] [G loss: 0.510339]\n",
      "epoch:9 step:9008 [D loss: 0.198698, acc.: 72.66%] [G loss: 0.484521]\n",
      "epoch:9 step:9009 [D loss: 0.290974, acc.: 50.78%] [G loss: 0.469558]\n",
      "epoch:9 step:9010 [D loss: 0.224129, acc.: 66.41%] [G loss: 0.497684]\n",
      "epoch:9 step:9011 [D loss: 0.217824, acc.: 63.28%] [G loss: 0.449688]\n",
      "epoch:9 step:9012 [D loss: 0.234994, acc.: 58.59%] [G loss: 0.448660]\n",
      "epoch:9 step:9013 [D loss: 0.239757, acc.: 52.34%] [G loss: 0.425461]\n",
      "epoch:9 step:9014 [D loss: 0.214721, acc.: 64.06%] [G loss: 0.510820]\n",
      "epoch:9 step:9015 [D loss: 0.192580, acc.: 73.44%] [G loss: 0.512856]\n",
      "epoch:9 step:9016 [D loss: 0.225060, acc.: 60.94%] [G loss: 0.530271]\n",
      "epoch:9 step:9017 [D loss: 0.228924, acc.: 60.16%] [G loss: 0.429680]\n",
      "epoch:9 step:9018 [D loss: 0.231545, acc.: 64.06%] [G loss: 0.483512]\n",
      "epoch:9 step:9019 [D loss: 0.218046, acc.: 63.28%] [G loss: 0.501694]\n",
      "epoch:9 step:9020 [D loss: 0.239311, acc.: 59.38%] [G loss: 0.443019]\n",
      "epoch:9 step:9021 [D loss: 0.204647, acc.: 65.62%] [G loss: 0.468789]\n",
      "epoch:9 step:9022 [D loss: 0.205917, acc.: 72.66%] [G loss: 0.474752]\n",
      "epoch:9 step:9023 [D loss: 0.230696, acc.: 65.62%] [G loss: 0.460309]\n",
      "epoch:9 step:9024 [D loss: 0.228235, acc.: 65.62%] [G loss: 0.423840]\n",
      "epoch:9 step:9025 [D loss: 0.195108, acc.: 71.88%] [G loss: 0.442857]\n",
      "epoch:9 step:9026 [D loss: 0.234722, acc.: 60.94%] [G loss: 0.545908]\n",
      "epoch:9 step:9027 [D loss: 0.224106, acc.: 64.06%] [G loss: 0.473249]\n",
      "epoch:9 step:9028 [D loss: 0.206388, acc.: 67.97%] [G loss: 0.464963]\n",
      "epoch:9 step:9029 [D loss: 0.265336, acc.: 53.91%] [G loss: 0.441401]\n",
      "epoch:9 step:9030 [D loss: 0.252022, acc.: 58.59%] [G loss: 0.437288]\n",
      "epoch:9 step:9031 [D loss: 0.186926, acc.: 75.00%] [G loss: 0.481455]\n",
      "epoch:9 step:9032 [D loss: 0.232017, acc.: 63.28%] [G loss: 0.450545]\n",
      "epoch:9 step:9033 [D loss: 0.264677, acc.: 50.78%] [G loss: 0.420647]\n",
      "epoch:9 step:9034 [D loss: 0.253672, acc.: 60.16%] [G loss: 0.448541]\n",
      "epoch:9 step:9035 [D loss: 0.227505, acc.: 64.84%] [G loss: 0.441248]\n",
      "epoch:9 step:9036 [D loss: 0.218820, acc.: 66.41%] [G loss: 0.456795]\n",
      "epoch:9 step:9037 [D loss: 0.230833, acc.: 56.25%] [G loss: 0.417429]\n",
      "epoch:9 step:9038 [D loss: 0.194663, acc.: 70.31%] [G loss: 0.436036]\n",
      "epoch:9 step:9039 [D loss: 0.230009, acc.: 62.50%] [G loss: 0.443361]\n",
      "epoch:9 step:9040 [D loss: 0.244138, acc.: 60.16%] [G loss: 0.418317]\n",
      "epoch:9 step:9041 [D loss: 0.203055, acc.: 74.22%] [G loss: 0.480776]\n",
      "epoch:9 step:9042 [D loss: 0.219763, acc.: 62.50%] [G loss: 0.487825]\n",
      "epoch:9 step:9043 [D loss: 0.232188, acc.: 60.94%] [G loss: 0.441240]\n",
      "epoch:9 step:9044 [D loss: 0.222086, acc.: 63.28%] [G loss: 0.413371]\n",
      "epoch:9 step:9045 [D loss: 0.217026, acc.: 64.84%] [G loss: 0.450885]\n",
      "epoch:9 step:9046 [D loss: 0.195580, acc.: 71.88%] [G loss: 0.473701]\n",
      "epoch:9 step:9047 [D loss: 0.246675, acc.: 58.59%] [G loss: 0.433544]\n",
      "epoch:9 step:9048 [D loss: 0.250751, acc.: 60.16%] [G loss: 0.451286]\n",
      "epoch:9 step:9049 [D loss: 0.227972, acc.: 62.50%] [G loss: 0.455396]\n",
      "epoch:9 step:9050 [D loss: 0.209100, acc.: 70.31%] [G loss: 0.475108]\n",
      "epoch:9 step:9051 [D loss: 0.223127, acc.: 66.41%] [G loss: 0.466569]\n",
      "epoch:9 step:9052 [D loss: 0.238363, acc.: 58.59%] [G loss: 0.481238]\n",
      "epoch:9 step:9053 [D loss: 0.221996, acc.: 62.50%] [G loss: 0.487441]\n",
      "epoch:9 step:9054 [D loss: 0.250846, acc.: 57.03%] [G loss: 0.441165]\n",
      "epoch:9 step:9055 [D loss: 0.248045, acc.: 60.16%] [G loss: 0.413194]\n",
      "epoch:9 step:9056 [D loss: 0.232176, acc.: 63.28%] [G loss: 0.444257]\n",
      "epoch:9 step:9057 [D loss: 0.191231, acc.: 70.31%] [G loss: 0.533738]\n",
      "epoch:9 step:9058 [D loss: 0.241583, acc.: 60.94%] [G loss: 0.435244]\n",
      "epoch:9 step:9059 [D loss: 0.232290, acc.: 62.50%] [G loss: 0.453975]\n",
      "epoch:9 step:9060 [D loss: 0.212274, acc.: 66.41%] [G loss: 0.453631]\n",
      "epoch:9 step:9061 [D loss: 0.237150, acc.: 62.50%] [G loss: 0.455100]\n",
      "epoch:9 step:9062 [D loss: 0.201908, acc.: 67.97%] [G loss: 0.452766]\n",
      "epoch:9 step:9063 [D loss: 0.236418, acc.: 60.94%] [G loss: 0.438855]\n",
      "epoch:9 step:9064 [D loss: 0.219878, acc.: 66.41%] [G loss: 0.411060]\n",
      "epoch:9 step:9065 [D loss: 0.225806, acc.: 64.84%] [G loss: 0.484356]\n",
      "epoch:9 step:9066 [D loss: 0.224058, acc.: 60.94%] [G loss: 0.508967]\n",
      "epoch:9 step:9067 [D loss: 0.194748, acc.: 69.53%] [G loss: 0.513152]\n",
      "epoch:9 step:9068 [D loss: 0.206299, acc.: 69.53%] [G loss: 0.516422]\n",
      "epoch:9 step:9069 [D loss: 0.255179, acc.: 54.69%] [G loss: 0.468877]\n",
      "epoch:9 step:9070 [D loss: 0.199529, acc.: 70.31%] [G loss: 0.463537]\n",
      "epoch:9 step:9071 [D loss: 0.223538, acc.: 63.28%] [G loss: 0.466033]\n",
      "epoch:9 step:9072 [D loss: 0.212793, acc.: 67.97%] [G loss: 0.438735]\n",
      "epoch:9 step:9073 [D loss: 0.196144, acc.: 66.41%] [G loss: 0.496402]\n",
      "epoch:9 step:9074 [D loss: 0.196873, acc.: 71.09%] [G loss: 0.498548]\n",
      "epoch:9 step:9075 [D loss: 0.205120, acc.: 65.62%] [G loss: 0.500230]\n",
      "epoch:9 step:9076 [D loss: 0.206843, acc.: 68.75%] [G loss: 0.505307]\n",
      "epoch:9 step:9077 [D loss: 0.241567, acc.: 57.03%] [G loss: 0.508065]\n",
      "epoch:9 step:9078 [D loss: 0.216166, acc.: 65.62%] [G loss: 0.470638]\n",
      "epoch:9 step:9079 [D loss: 0.205142, acc.: 64.84%] [G loss: 0.480306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9080 [D loss: 0.193048, acc.: 71.09%] [G loss: 0.527741]\n",
      "epoch:9 step:9081 [D loss: 0.179202, acc.: 71.88%] [G loss: 0.515640]\n",
      "epoch:9 step:9082 [D loss: 0.205040, acc.: 67.19%] [G loss: 0.516241]\n",
      "epoch:9 step:9083 [D loss: 0.213252, acc.: 65.62%] [G loss: 0.506508]\n",
      "epoch:9 step:9084 [D loss: 0.209720, acc.: 64.84%] [G loss: 0.476436]\n",
      "epoch:9 step:9085 [D loss: 0.231478, acc.: 59.38%] [G loss: 0.424408]\n",
      "epoch:9 step:9086 [D loss: 0.197313, acc.: 71.09%] [G loss: 0.479954]\n",
      "epoch:9 step:9087 [D loss: 0.206786, acc.: 68.75%] [G loss: 0.496753]\n",
      "epoch:9 step:9088 [D loss: 0.235463, acc.: 64.84%] [G loss: 0.486102]\n",
      "epoch:9 step:9089 [D loss: 0.233601, acc.: 60.94%] [G loss: 0.467099]\n",
      "epoch:9 step:9090 [D loss: 0.217786, acc.: 65.62%] [G loss: 0.496533]\n",
      "epoch:9 step:9091 [D loss: 0.259773, acc.: 58.59%] [G loss: 0.445408]\n",
      "epoch:9 step:9092 [D loss: 0.214824, acc.: 62.50%] [G loss: 0.454125]\n",
      "epoch:9 step:9093 [D loss: 0.206339, acc.: 64.84%] [G loss: 0.447009]\n",
      "epoch:9 step:9094 [D loss: 0.217952, acc.: 67.19%] [G loss: 0.468143]\n",
      "epoch:9 step:9095 [D loss: 0.249741, acc.: 57.81%] [G loss: 0.468166]\n",
      "epoch:9 step:9096 [D loss: 0.215918, acc.: 64.06%] [G loss: 0.477289]\n",
      "epoch:9 step:9097 [D loss: 0.226977, acc.: 62.50%] [G loss: 0.453123]\n",
      "epoch:9 step:9098 [D loss: 0.225720, acc.: 64.06%] [G loss: 0.497849]\n",
      "epoch:9 step:9099 [D loss: 0.222369, acc.: 67.97%] [G loss: 0.502978]\n",
      "epoch:9 step:9100 [D loss: 0.241567, acc.: 60.16%] [G loss: 0.501498]\n",
      "epoch:9 step:9101 [D loss: 0.256836, acc.: 59.38%] [G loss: 0.435012]\n",
      "epoch:9 step:9102 [D loss: 0.211512, acc.: 66.41%] [G loss: 0.440016]\n",
      "epoch:9 step:9103 [D loss: 0.250029, acc.: 63.28%] [G loss: 0.420828]\n",
      "epoch:9 step:9104 [D loss: 0.231796, acc.: 65.62%] [G loss: 0.457474]\n",
      "epoch:9 step:9105 [D loss: 0.242034, acc.: 60.16%] [G loss: 0.480272]\n",
      "epoch:9 step:9106 [D loss: 0.246417, acc.: 58.59%] [G loss: 0.455719]\n",
      "epoch:9 step:9107 [D loss: 0.214803, acc.: 66.41%] [G loss: 0.467341]\n",
      "epoch:9 step:9108 [D loss: 0.255865, acc.: 59.38%] [G loss: 0.457729]\n",
      "epoch:9 step:9109 [D loss: 0.222032, acc.: 63.28%] [G loss: 0.471590]\n",
      "epoch:9 step:9110 [D loss: 0.229753, acc.: 64.84%] [G loss: 0.450709]\n",
      "epoch:9 step:9111 [D loss: 0.244499, acc.: 61.72%] [G loss: 0.437775]\n",
      "epoch:9 step:9112 [D loss: 0.193118, acc.: 71.09%] [G loss: 0.496499]\n",
      "epoch:9 step:9113 [D loss: 0.213310, acc.: 65.62%] [G loss: 0.481796]\n",
      "epoch:9 step:9114 [D loss: 0.211999, acc.: 65.62%] [G loss: 0.465025]\n",
      "epoch:9 step:9115 [D loss: 0.227587, acc.: 66.41%] [G loss: 0.451233]\n",
      "epoch:9 step:9116 [D loss: 0.225452, acc.: 66.41%] [G loss: 0.460832]\n",
      "epoch:9 step:9117 [D loss: 0.247312, acc.: 53.91%] [G loss: 0.459379]\n",
      "epoch:9 step:9118 [D loss: 0.219444, acc.: 69.53%] [G loss: 0.458154]\n",
      "epoch:9 step:9119 [D loss: 0.252135, acc.: 57.81%] [G loss: 0.472434]\n",
      "epoch:9 step:9120 [D loss: 0.236530, acc.: 60.16%] [G loss: 0.431023]\n",
      "epoch:9 step:9121 [D loss: 0.198389, acc.: 70.31%] [G loss: 0.474653]\n",
      "epoch:9 step:9122 [D loss: 0.232851, acc.: 59.38%] [G loss: 0.474983]\n",
      "epoch:9 step:9123 [D loss: 0.214719, acc.: 67.19%] [G loss: 0.509858]\n",
      "epoch:9 step:9124 [D loss: 0.206226, acc.: 67.97%] [G loss: 0.493562]\n",
      "epoch:9 step:9125 [D loss: 0.208239, acc.: 64.06%] [G loss: 0.463655]\n",
      "epoch:9 step:9126 [D loss: 0.213395, acc.: 71.88%] [G loss: 0.522557]\n",
      "epoch:9 step:9127 [D loss: 0.215712, acc.: 68.75%] [G loss: 0.527007]\n",
      "epoch:9 step:9128 [D loss: 0.209441, acc.: 61.72%] [G loss: 0.533911]\n",
      "epoch:9 step:9129 [D loss: 0.264411, acc.: 56.25%] [G loss: 0.447688]\n",
      "epoch:9 step:9130 [D loss: 0.227190, acc.: 59.38%] [G loss: 0.457402]\n",
      "epoch:9 step:9131 [D loss: 0.235350, acc.: 62.50%] [G loss: 0.441190]\n",
      "epoch:9 step:9132 [D loss: 0.211808, acc.: 66.41%] [G loss: 0.501751]\n",
      "epoch:9 step:9133 [D loss: 0.226036, acc.: 64.06%] [G loss: 0.484505]\n",
      "epoch:9 step:9134 [D loss: 0.191939, acc.: 68.75%] [G loss: 0.521828]\n",
      "epoch:9 step:9135 [D loss: 0.264206, acc.: 56.25%] [G loss: 0.473913]\n",
      "epoch:9 step:9136 [D loss: 0.262709, acc.: 53.91%] [G loss: 0.454988]\n",
      "epoch:9 step:9137 [D loss: 0.262755, acc.: 53.12%] [G loss: 0.433840]\n",
      "epoch:9 step:9138 [D loss: 0.238157, acc.: 56.25%] [G loss: 0.474480]\n",
      "epoch:9 step:9139 [D loss: 0.206817, acc.: 64.06%] [G loss: 0.494884]\n",
      "epoch:9 step:9140 [D loss: 0.230100, acc.: 60.16%] [G loss: 0.465847]\n",
      "epoch:9 step:9141 [D loss: 0.180552, acc.: 73.44%] [G loss: 0.550229]\n",
      "epoch:9 step:9142 [D loss: 0.208754, acc.: 64.06%] [G loss: 0.496464]\n",
      "epoch:9 step:9143 [D loss: 0.254010, acc.: 52.34%] [G loss: 0.490834]\n",
      "epoch:9 step:9144 [D loss: 0.220733, acc.: 66.41%] [G loss: 0.446013]\n",
      "epoch:9 step:9145 [D loss: 0.243742, acc.: 62.50%] [G loss: 0.491080]\n",
      "epoch:9 step:9146 [D loss: 0.213801, acc.: 66.41%] [G loss: 0.464636]\n",
      "epoch:9 step:9147 [D loss: 0.245972, acc.: 59.38%] [G loss: 0.440238]\n",
      "epoch:9 step:9148 [D loss: 0.242988, acc.: 60.94%] [G loss: 0.413241]\n",
      "epoch:9 step:9149 [D loss: 0.282030, acc.: 53.12%] [G loss: 0.423080]\n",
      "epoch:9 step:9150 [D loss: 0.225007, acc.: 64.06%] [G loss: 0.486989]\n",
      "epoch:9 step:9151 [D loss: 0.231860, acc.: 61.72%] [G loss: 0.490241]\n",
      "epoch:9 step:9152 [D loss: 0.223927, acc.: 64.06%] [G loss: 0.478713]\n",
      "epoch:9 step:9153 [D loss: 0.230445, acc.: 60.16%] [G loss: 0.491173]\n",
      "epoch:9 step:9154 [D loss: 0.229327, acc.: 63.28%] [G loss: 0.473514]\n",
      "epoch:9 step:9155 [D loss: 0.265889, acc.: 54.69%] [G loss: 0.511583]\n",
      "epoch:9 step:9156 [D loss: 0.218851, acc.: 64.84%] [G loss: 0.458436]\n",
      "epoch:9 step:9157 [D loss: 0.232559, acc.: 64.06%] [G loss: 0.432234]\n",
      "epoch:9 step:9158 [D loss: 0.185020, acc.: 72.66%] [G loss: 0.527969]\n",
      "epoch:9 step:9159 [D loss: 0.219694, acc.: 62.50%] [G loss: 0.477816]\n",
      "epoch:9 step:9160 [D loss: 0.245070, acc.: 57.03%] [G loss: 0.445654]\n",
      "epoch:9 step:9161 [D loss: 0.201980, acc.: 66.41%] [G loss: 0.482926]\n",
      "epoch:9 step:9162 [D loss: 0.242307, acc.: 57.03%] [G loss: 0.460626]\n",
      "epoch:9 step:9163 [D loss: 0.210642, acc.: 65.62%] [G loss: 0.454702]\n",
      "epoch:9 step:9164 [D loss: 0.206583, acc.: 64.84%] [G loss: 0.489643]\n",
      "epoch:9 step:9165 [D loss: 0.203945, acc.: 71.88%] [G loss: 0.446339]\n",
      "epoch:9 step:9166 [D loss: 0.237827, acc.: 64.06%] [G loss: 0.468849]\n",
      "epoch:9 step:9167 [D loss: 0.245386, acc.: 55.47%] [G loss: 0.480793]\n",
      "epoch:9 step:9168 [D loss: 0.210000, acc.: 69.53%] [G loss: 0.476734]\n",
      "epoch:9 step:9169 [D loss: 0.205404, acc.: 69.53%] [G loss: 0.445783]\n",
      "epoch:9 step:9170 [D loss: 0.208745, acc.: 71.09%] [G loss: 0.454865]\n",
      "epoch:9 step:9171 [D loss: 0.257154, acc.: 53.91%] [G loss: 0.435943]\n",
      "epoch:9 step:9172 [D loss: 0.256859, acc.: 53.91%] [G loss: 0.447866]\n",
      "epoch:9 step:9173 [D loss: 0.235424, acc.: 60.16%] [G loss: 0.434158]\n",
      "epoch:9 step:9174 [D loss: 0.234981, acc.: 61.72%] [G loss: 0.424188]\n",
      "epoch:9 step:9175 [D loss: 0.225001, acc.: 64.06%] [G loss: 0.469966]\n",
      "epoch:9 step:9176 [D loss: 0.200887, acc.: 69.53%] [G loss: 0.484638]\n",
      "epoch:9 step:9177 [D loss: 0.237408, acc.: 59.38%] [G loss: 0.491850]\n",
      "epoch:9 step:9178 [D loss: 0.256813, acc.: 55.47%] [G loss: 0.451330]\n",
      "epoch:9 step:9179 [D loss: 0.226589, acc.: 64.06%] [G loss: 0.436834]\n",
      "epoch:9 step:9180 [D loss: 0.220335, acc.: 63.28%] [G loss: 0.482041]\n",
      "epoch:9 step:9181 [D loss: 0.203609, acc.: 71.09%] [G loss: 0.452245]\n",
      "epoch:9 step:9182 [D loss: 0.225835, acc.: 60.94%] [G loss: 0.447845]\n",
      "epoch:9 step:9183 [D loss: 0.213535, acc.: 62.50%] [G loss: 0.478918]\n",
      "epoch:9 step:9184 [D loss: 0.190985, acc.: 67.97%] [G loss: 0.451806]\n",
      "epoch:9 step:9185 [D loss: 0.196945, acc.: 67.97%] [G loss: 0.470916]\n",
      "epoch:9 step:9186 [D loss: 0.224188, acc.: 64.06%] [G loss: 0.418264]\n",
      "epoch:9 step:9187 [D loss: 0.212841, acc.: 64.06%] [G loss: 0.477331]\n",
      "epoch:9 step:9188 [D loss: 0.230720, acc.: 63.28%] [G loss: 0.502785]\n",
      "epoch:9 step:9189 [D loss: 0.216470, acc.: 63.28%] [G loss: 0.443214]\n",
      "epoch:9 step:9190 [D loss: 0.211859, acc.: 67.97%] [G loss: 0.494782]\n",
      "epoch:9 step:9191 [D loss: 0.221828, acc.: 65.62%] [G loss: 0.473911]\n",
      "epoch:9 step:9192 [D loss: 0.233605, acc.: 62.50%] [G loss: 0.430491]\n",
      "epoch:9 step:9193 [D loss: 0.239092, acc.: 57.81%] [G loss: 0.429223]\n",
      "epoch:9 step:9194 [D loss: 0.233799, acc.: 58.59%] [G loss: 0.466616]\n",
      "epoch:9 step:9195 [D loss: 0.236527, acc.: 60.94%] [G loss: 0.425856]\n",
      "epoch:9 step:9196 [D loss: 0.216270, acc.: 62.50%] [G loss: 0.457601]\n",
      "epoch:9 step:9197 [D loss: 0.234544, acc.: 64.06%] [G loss: 0.431030]\n",
      "epoch:9 step:9198 [D loss: 0.288724, acc.: 52.34%] [G loss: 0.423865]\n",
      "epoch:9 step:9199 [D loss: 0.266920, acc.: 57.03%] [G loss: 0.459301]\n",
      "epoch:9 step:9200 [D loss: 0.243825, acc.: 58.59%] [G loss: 0.462196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9201 [D loss: 0.235446, acc.: 60.16%] [G loss: 0.512093]\n",
      "epoch:9 step:9202 [D loss: 0.209057, acc.: 64.84%] [G loss: 0.498176]\n",
      "epoch:9 step:9203 [D loss: 0.230580, acc.: 61.72%] [G loss: 0.482193]\n",
      "epoch:9 step:9204 [D loss: 0.220195, acc.: 64.06%] [G loss: 0.455287]\n",
      "epoch:9 step:9205 [D loss: 0.209789, acc.: 67.97%] [G loss: 0.432200]\n",
      "epoch:9 step:9206 [D loss: 0.233193, acc.: 59.38%] [G loss: 0.453290]\n",
      "epoch:9 step:9207 [D loss: 0.237963, acc.: 60.94%] [G loss: 0.479897]\n",
      "epoch:9 step:9208 [D loss: 0.204763, acc.: 68.75%] [G loss: 0.497782]\n",
      "epoch:9 step:9209 [D loss: 0.215268, acc.: 63.28%] [G loss: 0.516192]\n",
      "epoch:9 step:9210 [D loss: 0.234248, acc.: 60.16%] [G loss: 0.436672]\n",
      "epoch:9 step:9211 [D loss: 0.241200, acc.: 56.25%] [G loss: 0.469495]\n",
      "epoch:9 step:9212 [D loss: 0.220210, acc.: 66.41%] [G loss: 0.441165]\n",
      "epoch:9 step:9213 [D loss: 0.212015, acc.: 67.19%] [G loss: 0.468037]\n",
      "epoch:9 step:9214 [D loss: 0.181882, acc.: 74.22%] [G loss: 0.545095]\n",
      "epoch:9 step:9215 [D loss: 0.193916, acc.: 74.22%] [G loss: 0.512540]\n",
      "epoch:9 step:9216 [D loss: 0.240871, acc.: 56.25%] [G loss: 0.473330]\n",
      "epoch:9 step:9217 [D loss: 0.263013, acc.: 52.34%] [G loss: 0.413893]\n",
      "epoch:9 step:9218 [D loss: 0.244773, acc.: 59.38%] [G loss: 0.410578]\n",
      "epoch:9 step:9219 [D loss: 0.176955, acc.: 75.00%] [G loss: 0.489070]\n",
      "epoch:9 step:9220 [D loss: 0.254309, acc.: 53.12%] [G loss: 0.421470]\n",
      "epoch:9 step:9221 [D loss: 0.275737, acc.: 50.78%] [G loss: 0.410166]\n",
      "epoch:9 step:9222 [D loss: 0.224454, acc.: 59.38%] [G loss: 0.457490]\n",
      "epoch:9 step:9223 [D loss: 0.210984, acc.: 71.09%] [G loss: 0.451916]\n",
      "epoch:9 step:9224 [D loss: 0.269783, acc.: 52.34%] [G loss: 0.433427]\n",
      "epoch:9 step:9225 [D loss: 0.188081, acc.: 72.66%] [G loss: 0.438384]\n",
      "epoch:9 step:9226 [D loss: 0.209119, acc.: 64.06%] [G loss: 0.467899]\n",
      "epoch:9 step:9227 [D loss: 0.243175, acc.: 57.03%] [G loss: 0.468685]\n",
      "epoch:9 step:9228 [D loss: 0.239758, acc.: 57.81%] [G loss: 0.437203]\n",
      "epoch:9 step:9229 [D loss: 0.206869, acc.: 66.41%] [G loss: 0.497290]\n",
      "epoch:9 step:9230 [D loss: 0.250277, acc.: 50.00%] [G loss: 0.448335]\n",
      "epoch:9 step:9231 [D loss: 0.200519, acc.: 67.97%] [G loss: 0.461884]\n",
      "epoch:9 step:9232 [D loss: 0.212431, acc.: 62.50%] [G loss: 0.460357]\n",
      "epoch:9 step:9233 [D loss: 0.259575, acc.: 54.69%] [G loss: 0.492248]\n",
      "epoch:9 step:9234 [D loss: 0.213470, acc.: 64.06%] [G loss: 0.502244]\n",
      "epoch:9 step:9235 [D loss: 0.204660, acc.: 68.75%] [G loss: 0.533148]\n",
      "epoch:9 step:9236 [D loss: 0.215761, acc.: 64.84%] [G loss: 0.476371]\n",
      "epoch:9 step:9237 [D loss: 0.239438, acc.: 59.38%] [G loss: 0.439575]\n",
      "epoch:9 step:9238 [D loss: 0.211192, acc.: 61.72%] [G loss: 0.464428]\n",
      "epoch:9 step:9239 [D loss: 0.238508, acc.: 69.53%] [G loss: 0.467192]\n",
      "epoch:9 step:9240 [D loss: 0.207331, acc.: 67.97%] [G loss: 0.473706]\n",
      "epoch:9 step:9241 [D loss: 0.249690, acc.: 57.81%] [G loss: 0.438470]\n",
      "epoch:9 step:9242 [D loss: 0.219458, acc.: 60.94%] [G loss: 0.443447]\n",
      "epoch:9 step:9243 [D loss: 0.195280, acc.: 75.78%] [G loss: 0.463072]\n",
      "epoch:9 step:9244 [D loss: 0.263494, acc.: 54.69%] [G loss: 0.480530]\n",
      "epoch:9 step:9245 [D loss: 0.255399, acc.: 60.16%] [G loss: 0.482503]\n",
      "epoch:9 step:9246 [D loss: 0.229716, acc.: 62.50%] [G loss: 0.475310]\n",
      "epoch:9 step:9247 [D loss: 0.235046, acc.: 61.72%] [G loss: 0.478931]\n",
      "epoch:9 step:9248 [D loss: 0.195123, acc.: 71.09%] [G loss: 0.519208]\n",
      "epoch:9 step:9249 [D loss: 0.234477, acc.: 60.94%] [G loss: 0.536676]\n",
      "epoch:9 step:9250 [D loss: 0.236805, acc.: 62.50%] [G loss: 0.463579]\n",
      "epoch:9 step:9251 [D loss: 0.262266, acc.: 55.47%] [G loss: 0.427522]\n",
      "epoch:9 step:9252 [D loss: 0.227331, acc.: 61.72%] [G loss: 0.450107]\n",
      "epoch:9 step:9253 [D loss: 0.259701, acc.: 57.03%] [G loss: 0.456990]\n",
      "epoch:9 step:9254 [D loss: 0.227953, acc.: 60.94%] [G loss: 0.440818]\n",
      "epoch:9 step:9255 [D loss: 0.200299, acc.: 66.41%] [G loss: 0.480746]\n",
      "epoch:9 step:9256 [D loss: 0.204602, acc.: 63.28%] [G loss: 0.481020]\n",
      "epoch:9 step:9257 [D loss: 0.256633, acc.: 56.25%] [G loss: 0.434504]\n",
      "epoch:9 step:9258 [D loss: 0.202035, acc.: 69.53%] [G loss: 0.448028]\n",
      "epoch:9 step:9259 [D loss: 0.218415, acc.: 62.50%] [G loss: 0.453391]\n",
      "epoch:9 step:9260 [D loss: 0.246785, acc.: 51.56%] [G loss: 0.401432]\n",
      "epoch:9 step:9261 [D loss: 0.262956, acc.: 55.47%] [G loss: 0.442509]\n",
      "epoch:9 step:9262 [D loss: 0.220270, acc.: 66.41%] [G loss: 0.465725]\n",
      "epoch:9 step:9263 [D loss: 0.219750, acc.: 65.62%] [G loss: 0.450542]\n",
      "epoch:9 step:9264 [D loss: 0.222048, acc.: 67.19%] [G loss: 0.420730]\n",
      "epoch:9 step:9265 [D loss: 0.209668, acc.: 64.06%] [G loss: 0.457290]\n",
      "epoch:9 step:9266 [D loss: 0.221734, acc.: 63.28%] [G loss: 0.482431]\n",
      "epoch:9 step:9267 [D loss: 0.214228, acc.: 65.62%] [G loss: 0.466289]\n",
      "epoch:9 step:9268 [D loss: 0.204324, acc.: 67.97%] [G loss: 0.463111]\n",
      "epoch:9 step:9269 [D loss: 0.221601, acc.: 66.41%] [G loss: 0.452390]\n",
      "epoch:9 step:9270 [D loss: 0.209649, acc.: 65.62%] [G loss: 0.433165]\n",
      "epoch:9 step:9271 [D loss: 0.225986, acc.: 60.16%] [G loss: 0.429629]\n",
      "epoch:9 step:9272 [D loss: 0.212536, acc.: 68.75%] [G loss: 0.463400]\n",
      "epoch:9 step:9273 [D loss: 0.204571, acc.: 71.09%] [G loss: 0.457038]\n",
      "epoch:9 step:9274 [D loss: 0.232882, acc.: 60.94%] [G loss: 0.428696]\n",
      "epoch:9 step:9275 [D loss: 0.205755, acc.: 67.97%] [G loss: 0.481599]\n",
      "epoch:9 step:9276 [D loss: 0.226809, acc.: 67.19%] [G loss: 0.455830]\n",
      "epoch:9 step:9277 [D loss: 0.230619, acc.: 64.06%] [G loss: 0.451069]\n",
      "epoch:9 step:9278 [D loss: 0.208895, acc.: 68.75%] [G loss: 0.462461]\n",
      "epoch:9 step:9279 [D loss: 0.247528, acc.: 55.47%] [G loss: 0.453533]\n",
      "epoch:9 step:9280 [D loss: 0.231318, acc.: 65.62%] [G loss: 0.450519]\n",
      "epoch:9 step:9281 [D loss: 0.230516, acc.: 58.59%] [G loss: 0.442952]\n",
      "epoch:9 step:9282 [D loss: 0.204045, acc.: 69.53%] [G loss: 0.475308]\n",
      "epoch:9 step:9283 [D loss: 0.236077, acc.: 57.81%] [G loss: 0.490045]\n",
      "epoch:9 step:9284 [D loss: 0.229333, acc.: 59.38%] [G loss: 0.430046]\n",
      "epoch:9 step:9285 [D loss: 0.209374, acc.: 64.84%] [G loss: 0.460750]\n",
      "epoch:9 step:9286 [D loss: 0.213983, acc.: 64.06%] [G loss: 0.513944]\n",
      "epoch:9 step:9287 [D loss: 0.214135, acc.: 61.72%] [G loss: 0.451833]\n",
      "epoch:9 step:9288 [D loss: 0.235991, acc.: 64.06%] [G loss: 0.430470]\n",
      "epoch:9 step:9289 [D loss: 0.217898, acc.: 62.50%] [G loss: 0.442668]\n",
      "epoch:9 step:9290 [D loss: 0.202587, acc.: 67.97%] [G loss: 0.434401]\n",
      "epoch:9 step:9291 [D loss: 0.257784, acc.: 53.12%] [G loss: 0.422991]\n",
      "epoch:9 step:9292 [D loss: 0.239152, acc.: 62.50%] [G loss: 0.479620]\n",
      "epoch:9 step:9293 [D loss: 0.196698, acc.: 71.88%] [G loss: 0.502660]\n",
      "epoch:9 step:9294 [D loss: 0.235675, acc.: 61.72%] [G loss: 0.472521]\n",
      "epoch:9 step:9295 [D loss: 0.233094, acc.: 59.38%] [G loss: 0.412173]\n",
      "epoch:9 step:9296 [D loss: 0.221286, acc.: 63.28%] [G loss: 0.437268]\n",
      "epoch:9 step:9297 [D loss: 0.224165, acc.: 64.84%] [G loss: 0.451486]\n",
      "epoch:9 step:9298 [D loss: 0.227503, acc.: 61.72%] [G loss: 0.466710]\n",
      "epoch:9 step:9299 [D loss: 0.227404, acc.: 58.59%] [G loss: 0.412772]\n",
      "epoch:9 step:9300 [D loss: 0.231513, acc.: 61.72%] [G loss: 0.453285]\n",
      "epoch:9 step:9301 [D loss: 0.229574, acc.: 61.72%] [G loss: 0.462720]\n",
      "epoch:9 step:9302 [D loss: 0.243132, acc.: 57.03%] [G loss: 0.449557]\n",
      "epoch:9 step:9303 [D loss: 0.218262, acc.: 67.97%] [G loss: 0.422120]\n",
      "epoch:9 step:9304 [D loss: 0.232855, acc.: 61.72%] [G loss: 0.439805]\n",
      "epoch:9 step:9305 [D loss: 0.205484, acc.: 67.97%] [G loss: 0.438781]\n",
      "epoch:9 step:9306 [D loss: 0.230516, acc.: 63.28%] [G loss: 0.434847]\n",
      "epoch:9 step:9307 [D loss: 0.236121, acc.: 59.38%] [G loss: 0.483086]\n",
      "epoch:9 step:9308 [D loss: 0.196434, acc.: 70.31%] [G loss: 0.486821]\n",
      "epoch:9 step:9309 [D loss: 0.242366, acc.: 60.16%] [G loss: 0.441394]\n",
      "epoch:9 step:9310 [D loss: 0.246829, acc.: 54.69%] [G loss: 0.435523]\n",
      "epoch:9 step:9311 [D loss: 0.241070, acc.: 58.59%] [G loss: 0.462438]\n",
      "epoch:9 step:9312 [D loss: 0.232566, acc.: 60.16%] [G loss: 0.431838]\n",
      "epoch:9 step:9313 [D loss: 0.243783, acc.: 56.25%] [G loss: 0.426013]\n",
      "epoch:9 step:9314 [D loss: 0.246212, acc.: 59.38%] [G loss: 0.430317]\n",
      "epoch:9 step:9315 [D loss: 0.223115, acc.: 62.50%] [G loss: 0.466829]\n",
      "epoch:9 step:9316 [D loss: 0.232278, acc.: 64.06%] [G loss: 0.467813]\n",
      "epoch:9 step:9317 [D loss: 0.177267, acc.: 75.78%] [G loss: 0.489327]\n",
      "epoch:9 step:9318 [D loss: 0.221364, acc.: 57.81%] [G loss: 0.491290]\n",
      "epoch:9 step:9319 [D loss: 0.189083, acc.: 68.75%] [G loss: 0.553430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9320 [D loss: 0.252065, acc.: 57.03%] [G loss: 0.470306]\n",
      "epoch:9 step:9321 [D loss: 0.235309, acc.: 55.47%] [G loss: 0.458892]\n",
      "epoch:9 step:9322 [D loss: 0.221277, acc.: 61.72%] [G loss: 0.460360]\n",
      "epoch:9 step:9323 [D loss: 0.191298, acc.: 71.09%] [G loss: 0.501564]\n",
      "epoch:9 step:9324 [D loss: 0.242522, acc.: 55.47%] [G loss: 0.453915]\n",
      "epoch:9 step:9325 [D loss: 0.254506, acc.: 53.12%] [G loss: 0.429885]\n",
      "epoch:9 step:9326 [D loss: 0.215984, acc.: 65.62%] [G loss: 0.470773]\n",
      "epoch:9 step:9327 [D loss: 0.195524, acc.: 70.31%] [G loss: 0.470596]\n",
      "epoch:9 step:9328 [D loss: 0.202404, acc.: 71.09%] [G loss: 0.493890]\n",
      "epoch:9 step:9329 [D loss: 0.214777, acc.: 64.84%] [G loss: 0.480038]\n",
      "epoch:9 step:9330 [D loss: 0.197451, acc.: 71.09%] [G loss: 0.491161]\n",
      "epoch:9 step:9331 [D loss: 0.220490, acc.: 69.53%] [G loss: 0.449340]\n",
      "epoch:9 step:9332 [D loss: 0.178736, acc.: 76.56%] [G loss: 0.519584]\n",
      "epoch:9 step:9333 [D loss: 0.220950, acc.: 62.50%] [G loss: 0.498945]\n",
      "epoch:9 step:9334 [D loss: 0.224719, acc.: 62.50%] [G loss: 0.459070]\n",
      "epoch:9 step:9335 [D loss: 0.210315, acc.: 65.62%] [G loss: 0.452357]\n",
      "epoch:9 step:9336 [D loss: 0.234846, acc.: 66.41%] [G loss: 0.432296]\n",
      "epoch:9 step:9337 [D loss: 0.231704, acc.: 60.16%] [G loss: 0.440488]\n",
      "epoch:9 step:9338 [D loss: 0.199047, acc.: 64.84%] [G loss: 0.505337]\n",
      "epoch:9 step:9339 [D loss: 0.206272, acc.: 67.97%] [G loss: 0.495323]\n",
      "epoch:9 step:9340 [D loss: 0.230156, acc.: 65.62%] [G loss: 0.487691]\n",
      "epoch:9 step:9341 [D loss: 0.210236, acc.: 66.41%] [G loss: 0.488013]\n",
      "epoch:9 step:9342 [D loss: 0.192946, acc.: 71.09%] [G loss: 0.498128]\n",
      "epoch:9 step:9343 [D loss: 0.231633, acc.: 59.38%] [G loss: 0.453925]\n",
      "epoch:9 step:9344 [D loss: 0.182328, acc.: 71.09%] [G loss: 0.460198]\n",
      "epoch:9 step:9345 [D loss: 0.159484, acc.: 81.25%] [G loss: 0.552932]\n",
      "epoch:9 step:9346 [D loss: 0.224990, acc.: 64.84%] [G loss: 0.518079]\n",
      "epoch:9 step:9347 [D loss: 0.217756, acc.: 65.62%] [G loss: 0.507982]\n",
      "epoch:9 step:9348 [D loss: 0.236463, acc.: 59.38%] [G loss: 0.404215]\n",
      "epoch:9 step:9349 [D loss: 0.251646, acc.: 58.59%] [G loss: 0.457341]\n",
      "epoch:9 step:9350 [D loss: 0.243332, acc.: 57.81%] [G loss: 0.450866]\n",
      "epoch:9 step:9351 [D loss: 0.192987, acc.: 72.66%] [G loss: 0.499900]\n",
      "epoch:9 step:9352 [D loss: 0.193274, acc.: 70.31%] [G loss: 0.520999]\n",
      "epoch:9 step:9353 [D loss: 0.314694, acc.: 43.75%] [G loss: 0.428505]\n",
      "epoch:9 step:9354 [D loss: 0.203063, acc.: 71.09%] [G loss: 0.508913]\n",
      "epoch:9 step:9355 [D loss: 0.234589, acc.: 58.59%] [G loss: 0.449916]\n",
      "epoch:9 step:9356 [D loss: 0.208658, acc.: 67.97%] [G loss: 0.475774]\n",
      "epoch:9 step:9357 [D loss: 0.167635, acc.: 78.12%] [G loss: 0.547505]\n",
      "epoch:9 step:9358 [D loss: 0.179928, acc.: 75.78%] [G loss: 0.582773]\n",
      "epoch:9 step:9359 [D loss: 0.193240, acc.: 71.09%] [G loss: 0.580804]\n",
      "epoch:9 step:9360 [D loss: 0.236977, acc.: 61.72%] [G loss: 0.584947]\n",
      "epoch:9 step:9361 [D loss: 0.327953, acc.: 58.59%] [G loss: 0.551454]\n",
      "epoch:9 step:9362 [D loss: 0.216217, acc.: 64.06%] [G loss: 0.621643]\n",
      "epoch:9 step:9363 [D loss: 0.233898, acc.: 63.28%] [G loss: 0.528902]\n",
      "epoch:9 step:9364 [D loss: 0.266130, acc.: 52.34%] [G loss: 0.402102]\n",
      "epoch:9 step:9365 [D loss: 0.225242, acc.: 64.06%] [G loss: 0.431570]\n",
      "epoch:9 step:9366 [D loss: 0.268421, acc.: 56.25%] [G loss: 0.437054]\n",
      "epoch:9 step:9367 [D loss: 0.198979, acc.: 62.50%] [G loss: 0.530566]\n",
      "epoch:9 step:9368 [D loss: 0.220151, acc.: 67.19%] [G loss: 0.526066]\n",
      "epoch:9 step:9369 [D loss: 0.193037, acc.: 69.53%] [G loss: 0.525315]\n",
      "epoch:9 step:9370 [D loss: 0.209690, acc.: 70.31%] [G loss: 0.600239]\n",
      "epoch:10 step:9371 [D loss: 0.237911, acc.: 61.72%] [G loss: 0.492047]\n",
      "epoch:10 step:9372 [D loss: 0.243961, acc.: 64.06%] [G loss: 0.489409]\n",
      "epoch:10 step:9373 [D loss: 0.242346, acc.: 58.59%] [G loss: 0.456872]\n",
      "epoch:10 step:9374 [D loss: 0.228927, acc.: 62.50%] [G loss: 0.451877]\n",
      "epoch:10 step:9375 [D loss: 0.239237, acc.: 60.16%] [G loss: 0.461374]\n",
      "epoch:10 step:9376 [D loss: 0.243153, acc.: 64.06%] [G loss: 0.417427]\n",
      "epoch:10 step:9377 [D loss: 0.224669, acc.: 64.06%] [G loss: 0.453760]\n",
      "epoch:10 step:9378 [D loss: 0.201735, acc.: 69.53%] [G loss: 0.484664]\n",
      "epoch:10 step:9379 [D loss: 0.220396, acc.: 65.62%] [G loss: 0.482964]\n",
      "epoch:10 step:9380 [D loss: 0.229955, acc.: 62.50%] [G loss: 0.481915]\n",
      "epoch:10 step:9381 [D loss: 0.187958, acc.: 75.78%] [G loss: 0.520021]\n",
      "epoch:10 step:9382 [D loss: 0.235580, acc.: 60.94%] [G loss: 0.469108]\n",
      "epoch:10 step:9383 [D loss: 0.207099, acc.: 65.62%] [G loss: 0.469722]\n",
      "epoch:10 step:9384 [D loss: 0.200736, acc.: 71.09%] [G loss: 0.499689]\n",
      "epoch:10 step:9385 [D loss: 0.188550, acc.: 69.53%] [G loss: 0.557004]\n",
      "epoch:10 step:9386 [D loss: 0.185148, acc.: 75.00%] [G loss: 0.534290]\n",
      "epoch:10 step:9387 [D loss: 0.247171, acc.: 54.69%] [G loss: 0.462397]\n",
      "epoch:10 step:9388 [D loss: 0.244547, acc.: 56.25%] [G loss: 0.426266]\n",
      "epoch:10 step:9389 [D loss: 0.255267, acc.: 53.91%] [G loss: 0.463247]\n",
      "epoch:10 step:9390 [D loss: 0.234834, acc.: 59.38%] [G loss: 0.460808]\n",
      "epoch:10 step:9391 [D loss: 0.211657, acc.: 66.41%] [G loss: 0.444671]\n",
      "epoch:10 step:9392 [D loss: 0.210080, acc.: 67.97%] [G loss: 0.546704]\n",
      "epoch:10 step:9393 [D loss: 0.246426, acc.: 57.81%] [G loss: 0.444651]\n",
      "epoch:10 step:9394 [D loss: 0.206736, acc.: 68.75%] [G loss: 0.458893]\n",
      "epoch:10 step:9395 [D loss: 0.191824, acc.: 70.31%] [G loss: 0.460955]\n",
      "epoch:10 step:9396 [D loss: 0.261121, acc.: 57.03%] [G loss: 0.440370]\n",
      "epoch:10 step:9397 [D loss: 0.226076, acc.: 63.28%] [G loss: 0.438776]\n",
      "epoch:10 step:9398 [D loss: 0.221456, acc.: 62.50%] [G loss: 0.444600]\n",
      "epoch:10 step:9399 [D loss: 0.197043, acc.: 71.09%] [G loss: 0.456652]\n",
      "epoch:10 step:9400 [D loss: 0.229771, acc.: 64.06%] [G loss: 0.435721]\n",
      "epoch:10 step:9401 [D loss: 0.240915, acc.: 60.16%] [G loss: 0.392775]\n",
      "epoch:10 step:9402 [D loss: 0.221492, acc.: 65.62%] [G loss: 0.452021]\n",
      "epoch:10 step:9403 [D loss: 0.195647, acc.: 71.09%] [G loss: 0.458416]\n",
      "epoch:10 step:9404 [D loss: 0.256168, acc.: 53.91%] [G loss: 0.426400]\n",
      "epoch:10 step:9405 [D loss: 0.206701, acc.: 66.41%] [G loss: 0.463112]\n",
      "epoch:10 step:9406 [D loss: 0.207074, acc.: 66.41%] [G loss: 0.519337]\n",
      "epoch:10 step:9407 [D loss: 0.238282, acc.: 60.16%] [G loss: 0.448869]\n",
      "epoch:10 step:9408 [D loss: 0.276646, acc.: 54.69%] [G loss: 0.434852]\n",
      "epoch:10 step:9409 [D loss: 0.228887, acc.: 60.16%] [G loss: 0.455716]\n",
      "epoch:10 step:9410 [D loss: 0.200258, acc.: 71.09%] [G loss: 0.528706]\n",
      "epoch:10 step:9411 [D loss: 0.218836, acc.: 67.97%] [G loss: 0.468429]\n",
      "epoch:10 step:9412 [D loss: 0.218158, acc.: 63.28%] [G loss: 0.460410]\n",
      "epoch:10 step:9413 [D loss: 0.209422, acc.: 64.06%] [G loss: 0.479603]\n",
      "epoch:10 step:9414 [D loss: 0.246782, acc.: 57.03%] [G loss: 0.435010]\n",
      "epoch:10 step:9415 [D loss: 0.236644, acc.: 58.59%] [G loss: 0.423657]\n",
      "epoch:10 step:9416 [D loss: 0.247648, acc.: 57.81%] [G loss: 0.454558]\n",
      "epoch:10 step:9417 [D loss: 0.210116, acc.: 67.97%] [G loss: 0.455945]\n",
      "epoch:10 step:9418 [D loss: 0.211931, acc.: 67.19%] [G loss: 0.467907]\n",
      "epoch:10 step:9419 [D loss: 0.209659, acc.: 64.84%] [G loss: 0.491888]\n",
      "epoch:10 step:9420 [D loss: 0.206077, acc.: 67.19%] [G loss: 0.493328]\n",
      "epoch:10 step:9421 [D loss: 0.258602, acc.: 52.34%] [G loss: 0.442713]\n",
      "epoch:10 step:9422 [D loss: 0.225637, acc.: 64.06%] [G loss: 0.478070]\n",
      "epoch:10 step:9423 [D loss: 0.208715, acc.: 64.84%] [G loss: 0.491203]\n",
      "epoch:10 step:9424 [D loss: 0.212075, acc.: 62.50%] [G loss: 0.473199]\n",
      "epoch:10 step:9425 [D loss: 0.231247, acc.: 61.72%] [G loss: 0.484867]\n",
      "epoch:10 step:9426 [D loss: 0.233721, acc.: 62.50%] [G loss: 0.511078]\n",
      "epoch:10 step:9427 [D loss: 0.237489, acc.: 61.72%] [G loss: 0.467725]\n",
      "epoch:10 step:9428 [D loss: 0.225062, acc.: 65.62%] [G loss: 0.471355]\n",
      "epoch:10 step:9429 [D loss: 0.228904, acc.: 60.16%] [G loss: 0.449701]\n",
      "epoch:10 step:9430 [D loss: 0.236559, acc.: 60.94%] [G loss: 0.442970]\n",
      "epoch:10 step:9431 [D loss: 0.246150, acc.: 56.25%] [G loss: 0.405073]\n",
      "epoch:10 step:9432 [D loss: 0.217000, acc.: 66.41%] [G loss: 0.431757]\n",
      "epoch:10 step:9433 [D loss: 0.231430, acc.: 63.28%] [G loss: 0.461503]\n",
      "epoch:10 step:9434 [D loss: 0.230839, acc.: 63.28%] [G loss: 0.488397]\n",
      "epoch:10 step:9435 [D loss: 0.237729, acc.: 61.72%] [G loss: 0.442494]\n",
      "epoch:10 step:9436 [D loss: 0.215690, acc.: 68.75%] [G loss: 0.430761]\n",
      "epoch:10 step:9437 [D loss: 0.233017, acc.: 64.06%] [G loss: 0.450731]\n",
      "epoch:10 step:9438 [D loss: 0.220595, acc.: 61.72%] [G loss: 0.460787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9439 [D loss: 0.195983, acc.: 72.66%] [G loss: 0.457921]\n",
      "epoch:10 step:9440 [D loss: 0.214665, acc.: 68.75%] [G loss: 0.447171]\n",
      "epoch:10 step:9441 [D loss: 0.228408, acc.: 60.94%] [G loss: 0.431499]\n",
      "epoch:10 step:9442 [D loss: 0.217255, acc.: 65.62%] [G loss: 0.467998]\n",
      "epoch:10 step:9443 [D loss: 0.207746, acc.: 69.53%] [G loss: 0.459973]\n",
      "epoch:10 step:9444 [D loss: 0.190339, acc.: 70.31%] [G loss: 0.478475]\n",
      "epoch:10 step:9445 [D loss: 0.205646, acc.: 67.97%] [G loss: 0.508846]\n",
      "epoch:10 step:9446 [D loss: 0.206117, acc.: 67.97%] [G loss: 0.494605]\n",
      "epoch:10 step:9447 [D loss: 0.178144, acc.: 71.09%] [G loss: 0.513545]\n",
      "epoch:10 step:9448 [D loss: 0.281197, acc.: 53.12%] [G loss: 0.441543]\n",
      "epoch:10 step:9449 [D loss: 0.240971, acc.: 56.25%] [G loss: 0.406297]\n",
      "epoch:10 step:9450 [D loss: 0.229249, acc.: 67.19%] [G loss: 0.411349]\n",
      "epoch:10 step:9451 [D loss: 0.226941, acc.: 59.38%] [G loss: 0.436128]\n",
      "epoch:10 step:9452 [D loss: 0.220041, acc.: 60.94%] [G loss: 0.491510]\n",
      "epoch:10 step:9453 [D loss: 0.208201, acc.: 69.53%] [G loss: 0.531342]\n",
      "epoch:10 step:9454 [D loss: 0.193281, acc.: 71.88%] [G loss: 0.504021]\n",
      "epoch:10 step:9455 [D loss: 0.223516, acc.: 61.72%] [G loss: 0.467672]\n",
      "epoch:10 step:9456 [D loss: 0.233641, acc.: 65.62%] [G loss: 0.409657]\n",
      "epoch:10 step:9457 [D loss: 0.256271, acc.: 58.59%] [G loss: 0.449362]\n",
      "epoch:10 step:9458 [D loss: 0.218900, acc.: 65.62%] [G loss: 0.451447]\n",
      "epoch:10 step:9459 [D loss: 0.229596, acc.: 61.72%] [G loss: 0.431196]\n",
      "epoch:10 step:9460 [D loss: 0.220099, acc.: 68.75%] [G loss: 0.461373]\n",
      "epoch:10 step:9461 [D loss: 0.221451, acc.: 61.72%] [G loss: 0.411992]\n",
      "epoch:10 step:9462 [D loss: 0.191586, acc.: 74.22%] [G loss: 0.475882]\n",
      "epoch:10 step:9463 [D loss: 0.218061, acc.: 62.50%] [G loss: 0.489166]\n",
      "epoch:10 step:9464 [D loss: 0.236459, acc.: 61.72%] [G loss: 0.462937]\n",
      "epoch:10 step:9465 [D loss: 0.205057, acc.: 67.97%] [G loss: 0.511207]\n",
      "epoch:10 step:9466 [D loss: 0.192344, acc.: 72.66%] [G loss: 0.469366]\n",
      "epoch:10 step:9467 [D loss: 0.204381, acc.: 66.41%] [G loss: 0.509828]\n",
      "epoch:10 step:9468 [D loss: 0.252886, acc.: 57.81%] [G loss: 0.451197]\n",
      "epoch:10 step:9469 [D loss: 0.228644, acc.: 63.28%] [G loss: 0.439580]\n",
      "epoch:10 step:9470 [D loss: 0.189013, acc.: 67.97%] [G loss: 0.476978]\n",
      "epoch:10 step:9471 [D loss: 0.217220, acc.: 70.31%] [G loss: 0.480185]\n",
      "epoch:10 step:9472 [D loss: 0.254939, acc.: 58.59%] [G loss: 0.438184]\n",
      "epoch:10 step:9473 [D loss: 0.242197, acc.: 58.59%] [G loss: 0.430838]\n",
      "epoch:10 step:9474 [D loss: 0.226739, acc.: 62.50%] [G loss: 0.458203]\n",
      "epoch:10 step:9475 [D loss: 0.223920, acc.: 60.16%] [G loss: 0.422791]\n",
      "epoch:10 step:9476 [D loss: 0.214389, acc.: 67.97%] [G loss: 0.451823]\n",
      "epoch:10 step:9477 [D loss: 0.196582, acc.: 69.53%] [G loss: 0.540036]\n",
      "epoch:10 step:9478 [D loss: 0.316336, acc.: 47.66%] [G loss: 0.446993]\n",
      "epoch:10 step:9479 [D loss: 0.283385, acc.: 52.34%] [G loss: 0.420151]\n",
      "epoch:10 step:9480 [D loss: 0.250820, acc.: 53.91%] [G loss: 0.376120]\n",
      "epoch:10 step:9481 [D loss: 0.196575, acc.: 67.97%] [G loss: 0.467715]\n",
      "epoch:10 step:9482 [D loss: 0.214928, acc.: 69.53%] [G loss: 0.484817]\n",
      "epoch:10 step:9483 [D loss: 0.226539, acc.: 62.50%] [G loss: 0.477069]\n",
      "epoch:10 step:9484 [D loss: 0.211160, acc.: 71.09%] [G loss: 0.497475]\n",
      "epoch:10 step:9485 [D loss: 0.217250, acc.: 65.62%] [G loss: 0.497202]\n",
      "epoch:10 step:9486 [D loss: 0.227808, acc.: 63.28%] [G loss: 0.496509]\n",
      "epoch:10 step:9487 [D loss: 0.221185, acc.: 64.84%] [G loss: 0.503492]\n",
      "epoch:10 step:9488 [D loss: 0.230441, acc.: 59.38%] [G loss: 0.474051]\n",
      "epoch:10 step:9489 [D loss: 0.190746, acc.: 73.44%] [G loss: 0.510316]\n",
      "epoch:10 step:9490 [D loss: 0.248630, acc.: 55.47%] [G loss: 0.464895]\n",
      "epoch:10 step:9491 [D loss: 0.260373, acc.: 58.59%] [G loss: 0.413716]\n",
      "epoch:10 step:9492 [D loss: 0.193589, acc.: 71.09%] [G loss: 0.493394]\n",
      "epoch:10 step:9493 [D loss: 0.192321, acc.: 68.75%] [G loss: 0.510669]\n",
      "epoch:10 step:9494 [D loss: 0.226633, acc.: 61.72%] [G loss: 0.467407]\n",
      "epoch:10 step:9495 [D loss: 0.233511, acc.: 61.72%] [G loss: 0.449031]\n",
      "epoch:10 step:9496 [D loss: 0.188838, acc.: 72.66%] [G loss: 0.481402]\n",
      "epoch:10 step:9497 [D loss: 0.210381, acc.: 64.84%] [G loss: 0.477834]\n",
      "epoch:10 step:9498 [D loss: 0.229821, acc.: 63.28%] [G loss: 0.484503]\n",
      "epoch:10 step:9499 [D loss: 0.241583, acc.: 55.47%] [G loss: 0.399804]\n",
      "epoch:10 step:9500 [D loss: 0.183157, acc.: 71.09%] [G loss: 0.476367]\n",
      "epoch:10 step:9501 [D loss: 0.219187, acc.: 67.97%] [G loss: 0.460434]\n",
      "epoch:10 step:9502 [D loss: 0.245236, acc.: 60.16%] [G loss: 0.462957]\n",
      "epoch:10 step:9503 [D loss: 0.257045, acc.: 55.47%] [G loss: 0.482937]\n",
      "epoch:10 step:9504 [D loss: 0.209334, acc.: 64.84%] [G loss: 0.423012]\n",
      "epoch:10 step:9505 [D loss: 0.221313, acc.: 67.19%] [G loss: 0.449038]\n",
      "epoch:10 step:9506 [D loss: 0.211468, acc.: 64.84%] [G loss: 0.459167]\n",
      "epoch:10 step:9507 [D loss: 0.266537, acc.: 58.59%] [G loss: 0.437826]\n",
      "epoch:10 step:9508 [D loss: 0.233110, acc.: 61.72%] [G loss: 0.428874]\n",
      "epoch:10 step:9509 [D loss: 0.237351, acc.: 60.94%] [G loss: 0.426671]\n",
      "epoch:10 step:9510 [D loss: 0.224083, acc.: 60.16%] [G loss: 0.431494]\n",
      "epoch:10 step:9511 [D loss: 0.243594, acc.: 54.69%] [G loss: 0.428908]\n",
      "epoch:10 step:9512 [D loss: 0.278075, acc.: 56.25%] [G loss: 0.389188]\n",
      "epoch:10 step:9513 [D loss: 0.215236, acc.: 65.62%] [G loss: 0.463728]\n",
      "epoch:10 step:9514 [D loss: 0.216263, acc.: 67.19%] [G loss: 0.425215]\n",
      "epoch:10 step:9515 [D loss: 0.205938, acc.: 70.31%] [G loss: 0.521089]\n",
      "epoch:10 step:9516 [D loss: 0.213262, acc.: 61.72%] [G loss: 0.477202]\n",
      "epoch:10 step:9517 [D loss: 0.233709, acc.: 61.72%] [G loss: 0.443373]\n",
      "epoch:10 step:9518 [D loss: 0.271025, acc.: 56.25%] [G loss: 0.456505]\n",
      "epoch:10 step:9519 [D loss: 0.201439, acc.: 70.31%] [G loss: 0.456866]\n",
      "epoch:10 step:9520 [D loss: 0.262550, acc.: 57.03%] [G loss: 0.452811]\n",
      "epoch:10 step:9521 [D loss: 0.241351, acc.: 60.94%] [G loss: 0.430278]\n",
      "epoch:10 step:9522 [D loss: 0.227254, acc.: 62.50%] [G loss: 0.452888]\n",
      "epoch:10 step:9523 [D loss: 0.263741, acc.: 55.47%] [G loss: 0.463472]\n",
      "epoch:10 step:9524 [D loss: 0.233869, acc.: 62.50%] [G loss: 0.450605]\n",
      "epoch:10 step:9525 [D loss: 0.234245, acc.: 60.16%] [G loss: 0.428870]\n",
      "epoch:10 step:9526 [D loss: 0.200912, acc.: 68.75%] [G loss: 0.485886]\n",
      "epoch:10 step:9527 [D loss: 0.240057, acc.: 57.03%] [G loss: 0.444942]\n",
      "epoch:10 step:9528 [D loss: 0.224412, acc.: 67.19%] [G loss: 0.445848]\n",
      "epoch:10 step:9529 [D loss: 0.206932, acc.: 69.53%] [G loss: 0.475751]\n",
      "epoch:10 step:9530 [D loss: 0.289687, acc.: 50.78%] [G loss: 0.482029]\n",
      "epoch:10 step:9531 [D loss: 0.258955, acc.: 53.12%] [G loss: 0.459090]\n",
      "epoch:10 step:9532 [D loss: 0.265311, acc.: 57.03%] [G loss: 0.494138]\n",
      "epoch:10 step:9533 [D loss: 0.222027, acc.: 66.41%] [G loss: 0.493590]\n",
      "epoch:10 step:9534 [D loss: 0.236389, acc.: 57.81%] [G loss: 0.454383]\n",
      "epoch:10 step:9535 [D loss: 0.228718, acc.: 60.16%] [G loss: 0.429917]\n",
      "epoch:10 step:9536 [D loss: 0.207092, acc.: 71.09%] [G loss: 0.453351]\n",
      "epoch:10 step:9537 [D loss: 0.248188, acc.: 56.25%] [G loss: 0.390592]\n",
      "epoch:10 step:9538 [D loss: 0.203662, acc.: 68.75%] [G loss: 0.461578]\n",
      "epoch:10 step:9539 [D loss: 0.215412, acc.: 60.94%] [G loss: 0.435087]\n",
      "epoch:10 step:9540 [D loss: 0.232999, acc.: 62.50%] [G loss: 0.417521]\n",
      "epoch:10 step:9541 [D loss: 0.202005, acc.: 65.62%] [G loss: 0.432824]\n",
      "epoch:10 step:9542 [D loss: 0.212125, acc.: 61.72%] [G loss: 0.459428]\n",
      "epoch:10 step:9543 [D loss: 0.213649, acc.: 64.06%] [G loss: 0.468719]\n",
      "epoch:10 step:9544 [D loss: 0.235676, acc.: 59.38%] [G loss: 0.422165]\n",
      "epoch:10 step:9545 [D loss: 0.239997, acc.: 57.03%] [G loss: 0.452245]\n",
      "epoch:10 step:9546 [D loss: 0.247152, acc.: 58.59%] [G loss: 0.390783]\n",
      "epoch:10 step:9547 [D loss: 0.241261, acc.: 57.81%] [G loss: 0.455544]\n",
      "epoch:10 step:9548 [D loss: 0.240084, acc.: 63.28%] [G loss: 0.447048]\n",
      "epoch:10 step:9549 [D loss: 0.222433, acc.: 66.41%] [G loss: 0.460694]\n",
      "epoch:10 step:9550 [D loss: 0.233997, acc.: 57.03%] [G loss: 0.448836]\n",
      "epoch:10 step:9551 [D loss: 0.220802, acc.: 66.41%] [G loss: 0.434910]\n",
      "epoch:10 step:9552 [D loss: 0.255880, acc.: 59.38%] [G loss: 0.497311]\n",
      "epoch:10 step:9553 [D loss: 0.253812, acc.: 57.81%] [G loss: 0.488065]\n",
      "epoch:10 step:9554 [D loss: 0.223131, acc.: 65.62%] [G loss: 0.485534]\n",
      "epoch:10 step:9555 [D loss: 0.240682, acc.: 57.81%] [G loss: 0.433497]\n",
      "epoch:10 step:9556 [D loss: 0.248897, acc.: 57.03%] [G loss: 0.414000]\n",
      "epoch:10 step:9557 [D loss: 0.217127, acc.: 64.84%] [G loss: 0.460612]\n",
      "epoch:10 step:9558 [D loss: 0.255486, acc.: 57.81%] [G loss: 0.453098]\n",
      "epoch:10 step:9559 [D loss: 0.248445, acc.: 58.59%] [G loss: 0.427792]\n",
      "epoch:10 step:9560 [D loss: 0.197866, acc.: 64.84%] [G loss: 0.434444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9561 [D loss: 0.214991, acc.: 66.41%] [G loss: 0.442102]\n",
      "epoch:10 step:9562 [D loss: 0.200770, acc.: 65.62%] [G loss: 0.487155]\n",
      "epoch:10 step:9563 [D loss: 0.225907, acc.: 63.28%] [G loss: 0.481712]\n",
      "epoch:10 step:9564 [D loss: 0.197135, acc.: 72.66%] [G loss: 0.467274]\n",
      "epoch:10 step:9565 [D loss: 0.245750, acc.: 62.50%] [G loss: 0.417291]\n",
      "epoch:10 step:9566 [D loss: 0.202977, acc.: 71.09%] [G loss: 0.444078]\n",
      "epoch:10 step:9567 [D loss: 0.206988, acc.: 69.53%] [G loss: 0.471610]\n",
      "epoch:10 step:9568 [D loss: 0.205060, acc.: 68.75%] [G loss: 0.469596]\n",
      "epoch:10 step:9569 [D loss: 0.225366, acc.: 64.06%] [G loss: 0.498686]\n",
      "epoch:10 step:9570 [D loss: 0.246449, acc.: 61.72%] [G loss: 0.452499]\n",
      "epoch:10 step:9571 [D loss: 0.237447, acc.: 57.81%] [G loss: 0.454767]\n",
      "epoch:10 step:9572 [D loss: 0.209993, acc.: 66.41%] [G loss: 0.490758]\n",
      "epoch:10 step:9573 [D loss: 0.246307, acc.: 55.47%] [G loss: 0.475701]\n",
      "epoch:10 step:9574 [D loss: 0.221003, acc.: 67.19%] [G loss: 0.514981]\n",
      "epoch:10 step:9575 [D loss: 0.208871, acc.: 67.19%] [G loss: 0.499004]\n",
      "epoch:10 step:9576 [D loss: 0.208009, acc.: 70.31%] [G loss: 0.495702]\n",
      "epoch:10 step:9577 [D loss: 0.187941, acc.: 71.09%] [G loss: 0.479750]\n",
      "epoch:10 step:9578 [D loss: 0.200880, acc.: 66.41%] [G loss: 0.520596]\n",
      "epoch:10 step:9579 [D loss: 0.194773, acc.: 71.09%] [G loss: 0.564026]\n",
      "epoch:10 step:9580 [D loss: 0.256606, acc.: 55.47%] [G loss: 0.457854]\n",
      "epoch:10 step:9581 [D loss: 0.244685, acc.: 52.34%] [G loss: 0.384961]\n",
      "epoch:10 step:9582 [D loss: 0.233192, acc.: 59.38%] [G loss: 0.409044]\n",
      "epoch:10 step:9583 [D loss: 0.220706, acc.: 67.19%] [G loss: 0.429806]\n",
      "epoch:10 step:9584 [D loss: 0.265049, acc.: 54.69%] [G loss: 0.422094]\n",
      "epoch:10 step:9585 [D loss: 0.234225, acc.: 58.59%] [G loss: 0.427741]\n",
      "epoch:10 step:9586 [D loss: 0.205193, acc.: 63.28%] [G loss: 0.489724]\n",
      "epoch:10 step:9587 [D loss: 0.224750, acc.: 64.84%] [G loss: 0.486530]\n",
      "epoch:10 step:9588 [D loss: 0.208036, acc.: 61.72%] [G loss: 0.482873]\n",
      "epoch:10 step:9589 [D loss: 0.189641, acc.: 72.66%] [G loss: 0.512510]\n",
      "epoch:10 step:9590 [D loss: 0.277007, acc.: 53.91%] [G loss: 0.439065]\n",
      "epoch:10 step:9591 [D loss: 0.206937, acc.: 67.19%] [G loss: 0.491381]\n",
      "epoch:10 step:9592 [D loss: 0.186538, acc.: 74.22%] [G loss: 0.491025]\n",
      "epoch:10 step:9593 [D loss: 0.211769, acc.: 69.53%] [G loss: 0.481244]\n",
      "epoch:10 step:9594 [D loss: 0.260427, acc.: 57.81%] [G loss: 0.431406]\n",
      "epoch:10 step:9595 [D loss: 0.237090, acc.: 67.19%] [G loss: 0.432933]\n",
      "epoch:10 step:9596 [D loss: 0.281041, acc.: 52.34%] [G loss: 0.415668]\n",
      "epoch:10 step:9597 [D loss: 0.245320, acc.: 60.16%] [G loss: 0.405187]\n",
      "epoch:10 step:9598 [D loss: 0.221885, acc.: 64.06%] [G loss: 0.455490]\n",
      "epoch:10 step:9599 [D loss: 0.228697, acc.: 60.16%] [G loss: 0.450919]\n",
      "epoch:10 step:9600 [D loss: 0.196003, acc.: 70.31%] [G loss: 0.496008]\n",
      "epoch:10 step:9601 [D loss: 0.179243, acc.: 71.09%] [G loss: 0.491012]\n",
      "epoch:10 step:9602 [D loss: 0.190164, acc.: 73.44%] [G loss: 0.551892]\n",
      "epoch:10 step:9603 [D loss: 0.245660, acc.: 58.59%] [G loss: 0.466269]\n",
      "epoch:10 step:9604 [D loss: 0.226199, acc.: 61.72%] [G loss: 0.447178]\n",
      "epoch:10 step:9605 [D loss: 0.264392, acc.: 57.81%] [G loss: 0.449941]\n",
      "epoch:10 step:9606 [D loss: 0.208162, acc.: 68.75%] [G loss: 0.448388]\n",
      "epoch:10 step:9607 [D loss: 0.255187, acc.: 53.12%] [G loss: 0.454007]\n",
      "epoch:10 step:9608 [D loss: 0.226288, acc.: 60.94%] [G loss: 0.457311]\n",
      "epoch:10 step:9609 [D loss: 0.245219, acc.: 54.69%] [G loss: 0.468826]\n",
      "epoch:10 step:9610 [D loss: 0.229610, acc.: 61.72%] [G loss: 0.455249]\n",
      "epoch:10 step:9611 [D loss: 0.216617, acc.: 64.84%] [G loss: 0.463668]\n",
      "epoch:10 step:9612 [D loss: 0.205623, acc.: 71.09%] [G loss: 0.488593]\n",
      "epoch:10 step:9613 [D loss: 0.204180, acc.: 66.41%] [G loss: 0.443508]\n",
      "epoch:10 step:9614 [D loss: 0.212757, acc.: 65.62%] [G loss: 0.493797]\n",
      "epoch:10 step:9615 [D loss: 0.210031, acc.: 69.53%] [G loss: 0.482121]\n",
      "epoch:10 step:9616 [D loss: 0.214700, acc.: 64.84%] [G loss: 0.495510]\n",
      "epoch:10 step:9617 [D loss: 0.229283, acc.: 58.59%] [G loss: 0.473837]\n",
      "epoch:10 step:9618 [D loss: 0.213873, acc.: 63.28%] [G loss: 0.503195]\n",
      "epoch:10 step:9619 [D loss: 0.287515, acc.: 53.12%] [G loss: 0.486546]\n",
      "epoch:10 step:9620 [D loss: 0.260477, acc.: 57.81%] [G loss: 0.456112]\n",
      "epoch:10 step:9621 [D loss: 0.240723, acc.: 63.28%] [G loss: 0.448388]\n",
      "epoch:10 step:9622 [D loss: 0.216266, acc.: 66.41%] [G loss: 0.463577]\n",
      "epoch:10 step:9623 [D loss: 0.247810, acc.: 57.81%] [G loss: 0.450128]\n",
      "epoch:10 step:9624 [D loss: 0.216766, acc.: 64.06%] [G loss: 0.496697]\n",
      "epoch:10 step:9625 [D loss: 0.219436, acc.: 65.62%] [G loss: 0.426159]\n",
      "epoch:10 step:9626 [D loss: 0.207723, acc.: 67.19%] [G loss: 0.465497]\n",
      "epoch:10 step:9627 [D loss: 0.218259, acc.: 60.94%] [G loss: 0.420935]\n",
      "epoch:10 step:9628 [D loss: 0.212871, acc.: 67.97%] [G loss: 0.466721]\n",
      "epoch:10 step:9629 [D loss: 0.220590, acc.: 60.94%] [G loss: 0.433365]\n",
      "epoch:10 step:9630 [D loss: 0.224083, acc.: 63.28%] [G loss: 0.457064]\n",
      "epoch:10 step:9631 [D loss: 0.206835, acc.: 66.41%] [G loss: 0.456382]\n",
      "epoch:10 step:9632 [D loss: 0.225614, acc.: 60.16%] [G loss: 0.476607]\n",
      "epoch:10 step:9633 [D loss: 0.243491, acc.: 56.25%] [G loss: 0.501033]\n",
      "epoch:10 step:9634 [D loss: 0.188737, acc.: 73.44%] [G loss: 0.507030]\n",
      "epoch:10 step:9635 [D loss: 0.272456, acc.: 49.22%] [G loss: 0.452667]\n",
      "epoch:10 step:9636 [D loss: 0.240987, acc.: 57.81%] [G loss: 0.419974]\n",
      "epoch:10 step:9637 [D loss: 0.224527, acc.: 67.19%] [G loss: 0.466670]\n",
      "epoch:10 step:9638 [D loss: 0.228234, acc.: 64.06%] [G loss: 0.435180]\n",
      "epoch:10 step:9639 [D loss: 0.217460, acc.: 67.97%] [G loss: 0.473698]\n",
      "epoch:10 step:9640 [D loss: 0.198037, acc.: 72.66%] [G loss: 0.509362]\n",
      "epoch:10 step:9641 [D loss: 0.202832, acc.: 65.62%] [G loss: 0.456564]\n",
      "epoch:10 step:9642 [D loss: 0.211794, acc.: 69.53%] [G loss: 0.437086]\n",
      "epoch:10 step:9643 [D loss: 0.233313, acc.: 59.38%] [G loss: 0.418057]\n",
      "epoch:10 step:9644 [D loss: 0.204628, acc.: 68.75%] [G loss: 0.458285]\n",
      "epoch:10 step:9645 [D loss: 0.233336, acc.: 58.59%] [G loss: 0.478734]\n",
      "epoch:10 step:9646 [D loss: 0.195418, acc.: 72.66%] [G loss: 0.493217]\n",
      "epoch:10 step:9647 [D loss: 0.248505, acc.: 56.25%] [G loss: 0.433610]\n",
      "epoch:10 step:9648 [D loss: 0.234960, acc.: 59.38%] [G loss: 0.453797]\n",
      "epoch:10 step:9649 [D loss: 0.228472, acc.: 58.59%] [G loss: 0.425724]\n",
      "epoch:10 step:9650 [D loss: 0.211715, acc.: 64.84%] [G loss: 0.480540]\n",
      "epoch:10 step:9651 [D loss: 0.233851, acc.: 64.84%] [G loss: 0.389632]\n",
      "epoch:10 step:9652 [D loss: 0.223177, acc.: 65.62%] [G loss: 0.406568]\n",
      "epoch:10 step:9653 [D loss: 0.214081, acc.: 65.62%] [G loss: 0.443574]\n",
      "epoch:10 step:9654 [D loss: 0.236981, acc.: 66.41%] [G loss: 0.414332]\n",
      "epoch:10 step:9655 [D loss: 0.234952, acc.: 57.03%] [G loss: 0.454053]\n",
      "epoch:10 step:9656 [D loss: 0.201499, acc.: 66.41%] [G loss: 0.513622]\n",
      "epoch:10 step:9657 [D loss: 0.234869, acc.: 57.81%] [G loss: 0.447637]\n",
      "epoch:10 step:9658 [D loss: 0.249409, acc.: 59.38%] [G loss: 0.473819]\n",
      "epoch:10 step:9659 [D loss: 0.219536, acc.: 67.97%] [G loss: 0.466980]\n",
      "epoch:10 step:9660 [D loss: 0.210659, acc.: 69.53%] [G loss: 0.521253]\n",
      "epoch:10 step:9661 [D loss: 0.258139, acc.: 53.12%] [G loss: 0.413602]\n",
      "epoch:10 step:9662 [D loss: 0.220993, acc.: 63.28%] [G loss: 0.431290]\n",
      "epoch:10 step:9663 [D loss: 0.213884, acc.: 68.75%] [G loss: 0.448857]\n",
      "epoch:10 step:9664 [D loss: 0.234754, acc.: 57.03%] [G loss: 0.427449]\n",
      "epoch:10 step:9665 [D loss: 0.242478, acc.: 57.03%] [G loss: 0.409604]\n",
      "epoch:10 step:9666 [D loss: 0.217707, acc.: 65.62%] [G loss: 0.462840]\n",
      "epoch:10 step:9667 [D loss: 0.211110, acc.: 70.31%] [G loss: 0.458378]\n",
      "epoch:10 step:9668 [D loss: 0.222756, acc.: 66.41%] [G loss: 0.449581]\n",
      "epoch:10 step:9669 [D loss: 0.208201, acc.: 66.41%] [G loss: 0.500607]\n",
      "epoch:10 step:9670 [D loss: 0.195992, acc.: 70.31%] [G loss: 0.505415]\n",
      "epoch:10 step:9671 [D loss: 0.290146, acc.: 47.66%] [G loss: 0.431501]\n",
      "epoch:10 step:9672 [D loss: 0.224832, acc.: 66.41%] [G loss: 0.477767]\n",
      "epoch:10 step:9673 [D loss: 0.236594, acc.: 60.16%] [G loss: 0.501269]\n",
      "epoch:10 step:9674 [D loss: 0.223224, acc.: 60.94%] [G loss: 0.472320]\n",
      "epoch:10 step:9675 [D loss: 0.225510, acc.: 65.62%] [G loss: 0.451258]\n",
      "epoch:10 step:9676 [D loss: 0.244445, acc.: 59.38%] [G loss: 0.471715]\n",
      "epoch:10 step:9677 [D loss: 0.220955, acc.: 66.41%] [G loss: 0.454896]\n",
      "epoch:10 step:9678 [D loss: 0.221367, acc.: 64.06%] [G loss: 0.422295]\n",
      "epoch:10 step:9679 [D loss: 0.203088, acc.: 67.97%] [G loss: 0.450515]\n",
      "epoch:10 step:9680 [D loss: 0.219579, acc.: 64.06%] [G loss: 0.411909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9681 [D loss: 0.192449, acc.: 71.88%] [G loss: 0.464631]\n",
      "epoch:10 step:9682 [D loss: 0.157052, acc.: 78.12%] [G loss: 0.539367]\n",
      "epoch:10 step:9683 [D loss: 0.185287, acc.: 76.56%] [G loss: 0.499842]\n",
      "epoch:10 step:9684 [D loss: 0.201508, acc.: 67.19%] [G loss: 0.515814]\n",
      "epoch:10 step:9685 [D loss: 0.191857, acc.: 71.09%] [G loss: 0.519388]\n",
      "epoch:10 step:9686 [D loss: 0.275494, acc.: 49.22%] [G loss: 0.459667]\n",
      "epoch:10 step:9687 [D loss: 0.233566, acc.: 61.72%] [G loss: 0.438946]\n",
      "epoch:10 step:9688 [D loss: 0.201979, acc.: 69.53%] [G loss: 0.502832]\n",
      "epoch:10 step:9689 [D loss: 0.195616, acc.: 70.31%] [G loss: 0.512966]\n",
      "epoch:10 step:9690 [D loss: 0.197699, acc.: 70.31%] [G loss: 0.515237]\n",
      "epoch:10 step:9691 [D loss: 0.211745, acc.: 69.53%] [G loss: 0.474854]\n",
      "epoch:10 step:9692 [D loss: 0.219075, acc.: 61.72%] [G loss: 0.517321]\n",
      "epoch:10 step:9693 [D loss: 0.261650, acc.: 53.91%] [G loss: 0.441794]\n",
      "epoch:10 step:9694 [D loss: 0.258965, acc.: 58.59%] [G loss: 0.420562]\n",
      "epoch:10 step:9695 [D loss: 0.201567, acc.: 67.97%] [G loss: 0.440758]\n",
      "epoch:10 step:9696 [D loss: 0.214309, acc.: 65.62%] [G loss: 0.484786]\n",
      "epoch:10 step:9697 [D loss: 0.242371, acc.: 60.94%] [G loss: 0.499874]\n",
      "epoch:10 step:9698 [D loss: 0.212520, acc.: 61.72%] [G loss: 0.496503]\n",
      "epoch:10 step:9699 [D loss: 0.214438, acc.: 64.84%] [G loss: 0.506307]\n",
      "epoch:10 step:9700 [D loss: 0.223867, acc.: 62.50%] [G loss: 0.461367]\n",
      "epoch:10 step:9701 [D loss: 0.226420, acc.: 62.50%] [G loss: 0.455721]\n",
      "epoch:10 step:9702 [D loss: 0.211231, acc.: 67.97%] [G loss: 0.429790]\n",
      "epoch:10 step:9703 [D loss: 0.202744, acc.: 67.19%] [G loss: 0.442924]\n",
      "epoch:10 step:9704 [D loss: 0.225926, acc.: 62.50%] [G loss: 0.438563]\n",
      "epoch:10 step:9705 [D loss: 0.199137, acc.: 64.06%] [G loss: 0.461303]\n",
      "epoch:10 step:9706 [D loss: 0.210706, acc.: 69.53%] [G loss: 0.452529]\n",
      "epoch:10 step:9707 [D loss: 0.207662, acc.: 64.06%] [G loss: 0.464604]\n",
      "epoch:10 step:9708 [D loss: 0.208404, acc.: 71.09%] [G loss: 0.483026]\n",
      "epoch:10 step:9709 [D loss: 0.221402, acc.: 66.41%] [G loss: 0.459186]\n",
      "epoch:10 step:9710 [D loss: 0.218222, acc.: 70.31%] [G loss: 0.476468]\n",
      "epoch:10 step:9711 [D loss: 0.289394, acc.: 56.25%] [G loss: 0.433350]\n",
      "epoch:10 step:9712 [D loss: 0.255134, acc.: 51.56%] [G loss: 0.446773]\n",
      "epoch:10 step:9713 [D loss: 0.197871, acc.: 69.53%] [G loss: 0.492510]\n",
      "epoch:10 step:9714 [D loss: 0.186701, acc.: 72.66%] [G loss: 0.510722]\n",
      "epoch:10 step:9715 [D loss: 0.219849, acc.: 67.19%] [G loss: 0.493302]\n",
      "epoch:10 step:9716 [D loss: 0.197140, acc.: 68.75%] [G loss: 0.509337]\n",
      "epoch:10 step:9717 [D loss: 0.199375, acc.: 67.97%] [G loss: 0.543474]\n",
      "epoch:10 step:9718 [D loss: 0.263458, acc.: 60.94%] [G loss: 0.450358]\n",
      "epoch:10 step:9719 [D loss: 0.269600, acc.: 49.22%] [G loss: 0.422776]\n",
      "epoch:10 step:9720 [D loss: 0.219434, acc.: 65.62%] [G loss: 0.446089]\n",
      "epoch:10 step:9721 [D loss: 0.226076, acc.: 64.06%] [G loss: 0.434852]\n",
      "epoch:10 step:9722 [D loss: 0.225271, acc.: 61.72%] [G loss: 0.445750]\n",
      "epoch:10 step:9723 [D loss: 0.190278, acc.: 65.62%] [G loss: 0.540854]\n",
      "epoch:10 step:9724 [D loss: 0.186526, acc.: 72.66%] [G loss: 0.531825]\n",
      "epoch:10 step:9725 [D loss: 0.241547, acc.: 63.28%] [G loss: 0.486424]\n",
      "epoch:10 step:9726 [D loss: 0.246482, acc.: 61.72%] [G loss: 0.464147]\n",
      "epoch:10 step:9727 [D loss: 0.196391, acc.: 67.19%] [G loss: 0.459526]\n",
      "epoch:10 step:9728 [D loss: 0.229286, acc.: 63.28%] [G loss: 0.509873]\n",
      "epoch:10 step:9729 [D loss: 0.190553, acc.: 77.34%] [G loss: 0.544343]\n",
      "epoch:10 step:9730 [D loss: 0.208594, acc.: 69.53%] [G loss: 0.491828]\n",
      "epoch:10 step:9731 [D loss: 0.223342, acc.: 64.84%] [G loss: 0.496969]\n",
      "epoch:10 step:9732 [D loss: 0.240468, acc.: 59.38%] [G loss: 0.451913]\n",
      "epoch:10 step:9733 [D loss: 0.206533, acc.: 68.75%] [G loss: 0.443834]\n",
      "epoch:10 step:9734 [D loss: 0.216037, acc.: 66.41%] [G loss: 0.436502]\n",
      "epoch:10 step:9735 [D loss: 0.216767, acc.: 66.41%] [G loss: 0.470922]\n",
      "epoch:10 step:9736 [D loss: 0.196091, acc.: 71.09%] [G loss: 0.459308]\n",
      "epoch:10 step:9737 [D loss: 0.223237, acc.: 64.06%] [G loss: 0.494157]\n",
      "epoch:10 step:9738 [D loss: 0.237022, acc.: 61.72%] [G loss: 0.437800]\n",
      "epoch:10 step:9739 [D loss: 0.236903, acc.: 59.38%] [G loss: 0.452712]\n",
      "epoch:10 step:9740 [D loss: 0.194348, acc.: 71.88%] [G loss: 0.471610]\n",
      "epoch:10 step:9741 [D loss: 0.191081, acc.: 68.75%] [G loss: 0.479038]\n",
      "epoch:10 step:9742 [D loss: 0.210826, acc.: 69.53%] [G loss: 0.493969]\n",
      "epoch:10 step:9743 [D loss: 0.238655, acc.: 58.59%] [G loss: 0.463794]\n",
      "epoch:10 step:9744 [D loss: 0.212211, acc.: 64.84%] [G loss: 0.461303]\n",
      "epoch:10 step:9745 [D loss: 0.218701, acc.: 67.97%] [G loss: 0.455680]\n",
      "epoch:10 step:9746 [D loss: 0.276762, acc.: 50.78%] [G loss: 0.424665]\n",
      "epoch:10 step:9747 [D loss: 0.258582, acc.: 53.91%] [G loss: 0.413997]\n",
      "epoch:10 step:9748 [D loss: 0.235127, acc.: 62.50%] [G loss: 0.444078]\n",
      "epoch:10 step:9749 [D loss: 0.230050, acc.: 61.72%] [G loss: 0.465995]\n",
      "epoch:10 step:9750 [D loss: 0.233400, acc.: 63.28%] [G loss: 0.464218]\n",
      "epoch:10 step:9751 [D loss: 0.198798, acc.: 70.31%] [G loss: 0.441731]\n",
      "epoch:10 step:9752 [D loss: 0.214346, acc.: 65.62%] [G loss: 0.431920]\n",
      "epoch:10 step:9753 [D loss: 0.227689, acc.: 59.38%] [G loss: 0.432416]\n",
      "epoch:10 step:9754 [D loss: 0.208418, acc.: 65.62%] [G loss: 0.443805]\n",
      "epoch:10 step:9755 [D loss: 0.212018, acc.: 68.75%] [G loss: 0.483338]\n",
      "epoch:10 step:9756 [D loss: 0.219421, acc.: 63.28%] [G loss: 0.428849]\n",
      "epoch:10 step:9757 [D loss: 0.212899, acc.: 64.84%] [G loss: 0.456997]\n",
      "epoch:10 step:9758 [D loss: 0.218264, acc.: 61.72%] [G loss: 0.490481]\n",
      "epoch:10 step:9759 [D loss: 0.247006, acc.: 58.59%] [G loss: 0.465326]\n",
      "epoch:10 step:9760 [D loss: 0.253263, acc.: 58.59%] [G loss: 0.464059]\n",
      "epoch:10 step:9761 [D loss: 0.225052, acc.: 64.84%] [G loss: 0.485244]\n",
      "epoch:10 step:9762 [D loss: 0.234549, acc.: 60.16%] [G loss: 0.450189]\n",
      "epoch:10 step:9763 [D loss: 0.232370, acc.: 64.84%] [G loss: 0.491777]\n",
      "epoch:10 step:9764 [D loss: 0.211721, acc.: 65.62%] [G loss: 0.451272]\n",
      "epoch:10 step:9765 [D loss: 0.213999, acc.: 63.28%] [G loss: 0.454169]\n",
      "epoch:10 step:9766 [D loss: 0.274736, acc.: 49.22%] [G loss: 0.439261]\n",
      "epoch:10 step:9767 [D loss: 0.231882, acc.: 61.72%] [G loss: 0.448510]\n",
      "epoch:10 step:9768 [D loss: 0.189602, acc.: 75.78%] [G loss: 0.501420]\n",
      "epoch:10 step:9769 [D loss: 0.207422, acc.: 64.84%] [G loss: 0.533959]\n",
      "epoch:10 step:9770 [D loss: 0.269358, acc.: 50.00%] [G loss: 0.413267]\n",
      "epoch:10 step:9771 [D loss: 0.224178, acc.: 60.94%] [G loss: 0.476475]\n",
      "epoch:10 step:9772 [D loss: 0.203942, acc.: 69.53%] [G loss: 0.444156]\n",
      "epoch:10 step:9773 [D loss: 0.240427, acc.: 60.94%] [G loss: 0.443165]\n",
      "epoch:10 step:9774 [D loss: 0.216665, acc.: 66.41%] [G loss: 0.470763]\n",
      "epoch:10 step:9775 [D loss: 0.190400, acc.: 70.31%] [G loss: 0.485489]\n",
      "epoch:10 step:9776 [D loss: 0.206689, acc.: 66.41%] [G loss: 0.464351]\n",
      "epoch:10 step:9777 [D loss: 0.266936, acc.: 51.56%] [G loss: 0.447055]\n",
      "epoch:10 step:9778 [D loss: 0.231534, acc.: 64.06%] [G loss: 0.498073]\n",
      "epoch:10 step:9779 [D loss: 0.225979, acc.: 66.41%] [G loss: 0.483941]\n",
      "epoch:10 step:9780 [D loss: 0.240992, acc.: 57.03%] [G loss: 0.437852]\n",
      "epoch:10 step:9781 [D loss: 0.249932, acc.: 57.03%] [G loss: 0.452143]\n",
      "epoch:10 step:9782 [D loss: 0.238841, acc.: 61.72%] [G loss: 0.447314]\n",
      "epoch:10 step:9783 [D loss: 0.264197, acc.: 50.78%] [G loss: 0.441235]\n",
      "epoch:10 step:9784 [D loss: 0.241454, acc.: 58.59%] [G loss: 0.446054]\n",
      "epoch:10 step:9785 [D loss: 0.223026, acc.: 62.50%] [G loss: 0.480394]\n",
      "epoch:10 step:9786 [D loss: 0.204411, acc.: 64.84%] [G loss: 0.478433]\n",
      "epoch:10 step:9787 [D loss: 0.262994, acc.: 54.69%] [G loss: 0.469233]\n",
      "epoch:10 step:9788 [D loss: 0.291675, acc.: 46.09%] [G loss: 0.417897]\n",
      "epoch:10 step:9789 [D loss: 0.223506, acc.: 63.28%] [G loss: 0.460504]\n",
      "epoch:10 step:9790 [D loss: 0.234733, acc.: 58.59%] [G loss: 0.446649]\n",
      "epoch:10 step:9791 [D loss: 0.267438, acc.: 50.00%] [G loss: 0.445058]\n",
      "epoch:10 step:9792 [D loss: 0.275332, acc.: 44.53%] [G loss: 0.372902]\n",
      "epoch:10 step:9793 [D loss: 0.225833, acc.: 64.06%] [G loss: 0.411954]\n",
      "epoch:10 step:9794 [D loss: 0.240469, acc.: 55.47%] [G loss: 0.415066]\n",
      "epoch:10 step:9795 [D loss: 0.223888, acc.: 61.72%] [G loss: 0.465131]\n",
      "epoch:10 step:9796 [D loss: 0.205728, acc.: 69.53%] [G loss: 0.483010]\n",
      "epoch:10 step:9797 [D loss: 0.176971, acc.: 74.22%] [G loss: 0.493294]\n",
      "epoch:10 step:9798 [D loss: 0.186557, acc.: 70.31%] [G loss: 0.486858]\n",
      "epoch:10 step:9799 [D loss: 0.228550, acc.: 60.16%] [G loss: 0.470939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9800 [D loss: 0.215812, acc.: 67.97%] [G loss: 0.450648]\n",
      "epoch:10 step:9801 [D loss: 0.243820, acc.: 57.81%] [G loss: 0.484599]\n",
      "epoch:10 step:9802 [D loss: 0.227068, acc.: 60.94%] [G loss: 0.421843]\n",
      "epoch:10 step:9803 [D loss: 0.232251, acc.: 63.28%] [G loss: 0.416285]\n",
      "epoch:10 step:9804 [D loss: 0.234441, acc.: 61.72%] [G loss: 0.429315]\n",
      "epoch:10 step:9805 [D loss: 0.226583, acc.: 64.06%] [G loss: 0.441853]\n",
      "epoch:10 step:9806 [D loss: 0.208177, acc.: 71.09%] [G loss: 0.489558]\n",
      "epoch:10 step:9807 [D loss: 0.298243, acc.: 45.31%] [G loss: 0.453936]\n",
      "epoch:10 step:9808 [D loss: 0.250552, acc.: 53.12%] [G loss: 0.402751]\n",
      "epoch:10 step:9809 [D loss: 0.192444, acc.: 69.53%] [G loss: 0.485957]\n",
      "epoch:10 step:9810 [D loss: 0.206721, acc.: 67.19%] [G loss: 0.449484]\n",
      "epoch:10 step:9811 [D loss: 0.224841, acc.: 62.50%] [G loss: 0.423569]\n",
      "epoch:10 step:9812 [D loss: 0.231648, acc.: 60.16%] [G loss: 0.416667]\n",
      "epoch:10 step:9813 [D loss: 0.220350, acc.: 64.84%] [G loss: 0.472808]\n",
      "epoch:10 step:9814 [D loss: 0.224700, acc.: 64.84%] [G loss: 0.466501]\n",
      "epoch:10 step:9815 [D loss: 0.205337, acc.: 67.19%] [G loss: 0.514313]\n",
      "epoch:10 step:9816 [D loss: 0.222951, acc.: 58.59%] [G loss: 0.473492]\n",
      "epoch:10 step:9817 [D loss: 0.224197, acc.: 64.06%] [G loss: 0.456897]\n",
      "epoch:10 step:9818 [D loss: 0.275894, acc.: 48.44%] [G loss: 0.497409]\n",
      "epoch:10 step:9819 [D loss: 0.223891, acc.: 60.94%] [G loss: 0.462043]\n",
      "epoch:10 step:9820 [D loss: 0.233126, acc.: 59.38%] [G loss: 0.443538]\n",
      "epoch:10 step:9821 [D loss: 0.170697, acc.: 78.91%] [G loss: 0.501605]\n",
      "epoch:10 step:9822 [D loss: 0.221101, acc.: 66.41%] [G loss: 0.456995]\n",
      "epoch:10 step:9823 [D loss: 0.216812, acc.: 64.06%] [G loss: 0.461299]\n",
      "epoch:10 step:9824 [D loss: 0.210679, acc.: 64.84%] [G loss: 0.479603]\n",
      "epoch:10 step:9825 [D loss: 0.257381, acc.: 53.91%] [G loss: 0.429691]\n",
      "epoch:10 step:9826 [D loss: 0.247612, acc.: 47.66%] [G loss: 0.494876]\n",
      "epoch:10 step:9827 [D loss: 0.212720, acc.: 72.66%] [G loss: 0.493371]\n",
      "epoch:10 step:9828 [D loss: 0.275875, acc.: 55.47%] [G loss: 0.451478]\n",
      "epoch:10 step:9829 [D loss: 0.238441, acc.: 55.47%] [G loss: 0.450333]\n",
      "epoch:10 step:9830 [D loss: 0.207410, acc.: 65.62%] [G loss: 0.454989]\n",
      "epoch:10 step:9831 [D loss: 0.245488, acc.: 60.94%] [G loss: 0.417978]\n",
      "epoch:10 step:9832 [D loss: 0.253125, acc.: 56.25%] [G loss: 0.435373]\n",
      "epoch:10 step:9833 [D loss: 0.265043, acc.: 57.81%] [G loss: 0.404181]\n",
      "epoch:10 step:9834 [D loss: 0.226968, acc.: 63.28%] [G loss: 0.408317]\n",
      "epoch:10 step:9835 [D loss: 0.240061, acc.: 59.38%] [G loss: 0.422430]\n",
      "epoch:10 step:9836 [D loss: 0.218307, acc.: 64.84%] [G loss: 0.471655]\n",
      "epoch:10 step:9837 [D loss: 0.241028, acc.: 64.84%] [G loss: 0.464443]\n",
      "epoch:10 step:9838 [D loss: 0.229519, acc.: 62.50%] [G loss: 0.451090]\n",
      "epoch:10 step:9839 [D loss: 0.204340, acc.: 69.53%] [G loss: 0.502465]\n",
      "epoch:10 step:9840 [D loss: 0.213163, acc.: 70.31%] [G loss: 0.459006]\n",
      "epoch:10 step:9841 [D loss: 0.190751, acc.: 72.66%] [G loss: 0.487495]\n",
      "epoch:10 step:9842 [D loss: 0.234218, acc.: 64.84%] [G loss: 0.457604]\n",
      "epoch:10 step:9843 [D loss: 0.258193, acc.: 52.34%] [G loss: 0.430880]\n",
      "epoch:10 step:9844 [D loss: 0.217913, acc.: 58.59%] [G loss: 0.437767]\n",
      "epoch:10 step:9845 [D loss: 0.207583, acc.: 67.19%] [G loss: 0.438025]\n",
      "epoch:10 step:9846 [D loss: 0.242751, acc.: 57.81%] [G loss: 0.465674]\n",
      "epoch:10 step:9847 [D loss: 0.251762, acc.: 53.91%] [G loss: 0.402401]\n",
      "epoch:10 step:9848 [D loss: 0.233243, acc.: 64.06%] [G loss: 0.395071]\n",
      "epoch:10 step:9849 [D loss: 0.216889, acc.: 67.19%] [G loss: 0.409206]\n",
      "epoch:10 step:9850 [D loss: 0.249191, acc.: 57.81%] [G loss: 0.397845]\n",
      "epoch:10 step:9851 [D loss: 0.186720, acc.: 70.31%] [G loss: 0.465614]\n",
      "epoch:10 step:9852 [D loss: 0.300038, acc.: 48.44%] [G loss: 0.429458]\n",
      "epoch:10 step:9853 [D loss: 0.266066, acc.: 56.25%] [G loss: 0.415204]\n",
      "epoch:10 step:9854 [D loss: 0.176670, acc.: 78.91%] [G loss: 0.502698]\n",
      "epoch:10 step:9855 [D loss: 0.215262, acc.: 62.50%] [G loss: 0.473692]\n",
      "epoch:10 step:9856 [D loss: 0.236239, acc.: 63.28%] [G loss: 0.474661]\n",
      "epoch:10 step:9857 [D loss: 0.227581, acc.: 60.16%] [G loss: 0.434704]\n",
      "epoch:10 step:9858 [D loss: 0.208345, acc.: 64.06%] [G loss: 0.434729]\n",
      "epoch:10 step:9859 [D loss: 0.250916, acc.: 59.38%] [G loss: 0.428816]\n",
      "epoch:10 step:9860 [D loss: 0.249529, acc.: 59.38%] [G loss: 0.437046]\n",
      "epoch:10 step:9861 [D loss: 0.228939, acc.: 58.59%] [G loss: 0.450409]\n",
      "epoch:10 step:9862 [D loss: 0.229350, acc.: 64.06%] [G loss: 0.472773]\n",
      "epoch:10 step:9863 [D loss: 0.224197, acc.: 60.94%] [G loss: 0.429350]\n",
      "epoch:10 step:9864 [D loss: 0.223731, acc.: 63.28%] [G loss: 0.454379]\n",
      "epoch:10 step:9865 [D loss: 0.185151, acc.: 72.66%] [G loss: 0.492074]\n",
      "epoch:10 step:9866 [D loss: 0.210472, acc.: 68.75%] [G loss: 0.509768]\n",
      "epoch:10 step:9867 [D loss: 0.232778, acc.: 63.28%] [G loss: 0.450062]\n",
      "epoch:10 step:9868 [D loss: 0.223282, acc.: 64.06%] [G loss: 0.468266]\n",
      "epoch:10 step:9869 [D loss: 0.176462, acc.: 76.56%] [G loss: 0.479385]\n",
      "epoch:10 step:9870 [D loss: 0.304688, acc.: 46.88%] [G loss: 0.481629]\n",
      "epoch:10 step:9871 [D loss: 0.265095, acc.: 56.25%] [G loss: 0.453772]\n",
      "epoch:10 step:9872 [D loss: 0.239108, acc.: 57.81%] [G loss: 0.433165]\n",
      "epoch:10 step:9873 [D loss: 0.225727, acc.: 63.28%] [G loss: 0.449441]\n",
      "epoch:10 step:9874 [D loss: 0.171022, acc.: 78.91%] [G loss: 0.510449]\n",
      "epoch:10 step:9875 [D loss: 0.188114, acc.: 70.31%] [G loss: 0.504822]\n",
      "epoch:10 step:9876 [D loss: 0.233999, acc.: 58.59%] [G loss: 0.460948]\n",
      "epoch:10 step:9877 [D loss: 0.222671, acc.: 62.50%] [G loss: 0.481207]\n",
      "epoch:10 step:9878 [D loss: 0.164433, acc.: 75.78%] [G loss: 0.522929]\n",
      "epoch:10 step:9879 [D loss: 0.243635, acc.: 57.03%] [G loss: 0.449261]\n",
      "epoch:10 step:9880 [D loss: 0.247033, acc.: 55.47%] [G loss: 0.437291]\n",
      "epoch:10 step:9881 [D loss: 0.241878, acc.: 56.25%] [G loss: 0.421858]\n",
      "epoch:10 step:9882 [D loss: 0.230303, acc.: 60.94%] [G loss: 0.450264]\n",
      "epoch:10 step:9883 [D loss: 0.197518, acc.: 69.53%] [G loss: 0.481074]\n",
      "epoch:10 step:9884 [D loss: 0.205682, acc.: 66.41%] [G loss: 0.493718]\n",
      "epoch:10 step:9885 [D loss: 0.192268, acc.: 69.53%] [G loss: 0.475993]\n",
      "epoch:10 step:9886 [D loss: 0.229336, acc.: 63.28%] [G loss: 0.486446]\n",
      "epoch:10 step:9887 [D loss: 0.246109, acc.: 56.25%] [G loss: 0.442787]\n",
      "epoch:10 step:9888 [D loss: 0.226103, acc.: 60.94%] [G loss: 0.433107]\n",
      "epoch:10 step:9889 [D loss: 0.195606, acc.: 71.09%] [G loss: 0.471737]\n",
      "epoch:10 step:9890 [D loss: 0.194631, acc.: 71.88%] [G loss: 0.475050]\n",
      "epoch:10 step:9891 [D loss: 0.228351, acc.: 64.84%] [G loss: 0.489676]\n",
      "epoch:10 step:9892 [D loss: 0.199836, acc.: 67.97%] [G loss: 0.460186]\n",
      "epoch:10 step:9893 [D loss: 0.213335, acc.: 67.97%] [G loss: 0.489916]\n",
      "epoch:10 step:9894 [D loss: 0.238362, acc.: 64.84%] [G loss: 0.450627]\n",
      "epoch:10 step:9895 [D loss: 0.212563, acc.: 63.28%] [G loss: 0.513581]\n",
      "epoch:10 step:9896 [D loss: 0.215035, acc.: 67.97%] [G loss: 0.506570]\n",
      "epoch:10 step:9897 [D loss: 0.248352, acc.: 60.16%] [G loss: 0.416908]\n",
      "epoch:10 step:9898 [D loss: 0.259812, acc.: 48.44%] [G loss: 0.448070]\n",
      "epoch:10 step:9899 [D loss: 0.245701, acc.: 60.94%] [G loss: 0.444640]\n",
      "epoch:10 step:9900 [D loss: 0.216445, acc.: 67.97%] [G loss: 0.459751]\n",
      "epoch:10 step:9901 [D loss: 0.233288, acc.: 62.50%] [G loss: 0.414329]\n",
      "epoch:10 step:9902 [D loss: 0.227343, acc.: 61.72%] [G loss: 0.448154]\n",
      "epoch:10 step:9903 [D loss: 0.231267, acc.: 58.59%] [G loss: 0.435437]\n",
      "epoch:10 step:9904 [D loss: 0.200406, acc.: 71.09%] [G loss: 0.490386]\n",
      "epoch:10 step:9905 [D loss: 0.248677, acc.: 56.25%] [G loss: 0.455269]\n",
      "epoch:10 step:9906 [D loss: 0.205940, acc.: 67.97%] [G loss: 0.460694]\n",
      "epoch:10 step:9907 [D loss: 0.243187, acc.: 57.03%] [G loss: 0.431315]\n",
      "epoch:10 step:9908 [D loss: 0.217040, acc.: 64.84%] [G loss: 0.511862]\n",
      "epoch:10 step:9909 [D loss: 0.254248, acc.: 59.38%] [G loss: 0.463403]\n",
      "epoch:10 step:9910 [D loss: 0.221004, acc.: 60.94%] [G loss: 0.431711]\n",
      "epoch:10 step:9911 [D loss: 0.217709, acc.: 65.62%] [G loss: 0.485694]\n",
      "epoch:10 step:9912 [D loss: 0.255293, acc.: 50.78%] [G loss: 0.439060]\n",
      "epoch:10 step:9913 [D loss: 0.231888, acc.: 63.28%] [G loss: 0.453521]\n",
      "epoch:10 step:9914 [D loss: 0.215751, acc.: 64.84%] [G loss: 0.469773]\n",
      "epoch:10 step:9915 [D loss: 0.219830, acc.: 65.62%] [G loss: 0.493861]\n",
      "epoch:10 step:9916 [D loss: 0.218783, acc.: 62.50%] [G loss: 0.446410]\n",
      "epoch:10 step:9917 [D loss: 0.242231, acc.: 62.50%] [G loss: 0.448262]\n",
      "epoch:10 step:9918 [D loss: 0.218619, acc.: 64.84%] [G loss: 0.446792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9919 [D loss: 0.195735, acc.: 71.09%] [G loss: 0.490230]\n",
      "epoch:10 step:9920 [D loss: 0.193349, acc.: 71.09%] [G loss: 0.549543]\n",
      "epoch:10 step:9921 [D loss: 0.193444, acc.: 71.88%] [G loss: 0.523652]\n",
      "epoch:10 step:9922 [D loss: 0.206475, acc.: 65.62%] [G loss: 0.496515]\n",
      "epoch:10 step:9923 [D loss: 0.246205, acc.: 53.91%] [G loss: 0.429609]\n",
      "epoch:10 step:9924 [D loss: 0.230457, acc.: 62.50%] [G loss: 0.480673]\n",
      "epoch:10 step:9925 [D loss: 0.190017, acc.: 71.88%] [G loss: 0.518945]\n",
      "epoch:10 step:9926 [D loss: 0.226263, acc.: 60.16%] [G loss: 0.498601]\n",
      "epoch:10 step:9927 [D loss: 0.195771, acc.: 73.44%] [G loss: 0.459373]\n",
      "epoch:10 step:9928 [D loss: 0.202187, acc.: 67.97%] [G loss: 0.498108]\n",
      "epoch:10 step:9929 [D loss: 0.277902, acc.: 49.22%] [G loss: 0.455580]\n",
      "epoch:10 step:9930 [D loss: 0.240565, acc.: 55.47%] [G loss: 0.443053]\n",
      "epoch:10 step:9931 [D loss: 0.220715, acc.: 61.72%] [G loss: 0.430117]\n",
      "epoch:10 step:9932 [D loss: 0.250015, acc.: 53.91%] [G loss: 0.451163]\n",
      "epoch:10 step:9933 [D loss: 0.201162, acc.: 72.66%] [G loss: 0.452484]\n",
      "epoch:10 step:9934 [D loss: 0.203069, acc.: 65.62%] [G loss: 0.490176]\n",
      "epoch:10 step:9935 [D loss: 0.232983, acc.: 60.94%] [G loss: 0.460775]\n",
      "epoch:10 step:9936 [D loss: 0.304316, acc.: 46.09%] [G loss: 0.442048]\n",
      "epoch:10 step:9937 [D loss: 0.196183, acc.: 70.31%] [G loss: 0.468467]\n",
      "epoch:10 step:9938 [D loss: 0.215093, acc.: 66.41%] [G loss: 0.485842]\n",
      "epoch:10 step:9939 [D loss: 0.260691, acc.: 52.34%] [G loss: 0.429484]\n",
      "epoch:10 step:9940 [D loss: 0.191811, acc.: 73.44%] [G loss: 0.467863]\n",
      "epoch:10 step:9941 [D loss: 0.214625, acc.: 63.28%] [G loss: 0.422089]\n",
      "epoch:10 step:9942 [D loss: 0.229440, acc.: 60.94%] [G loss: 0.475135]\n",
      "epoch:10 step:9943 [D loss: 0.215837, acc.: 63.28%] [G loss: 0.505218]\n",
      "epoch:10 step:9944 [D loss: 0.185954, acc.: 77.34%] [G loss: 0.535843]\n",
      "epoch:10 step:9945 [D loss: 0.203667, acc.: 65.62%] [G loss: 0.492560]\n",
      "epoch:10 step:9946 [D loss: 0.247441, acc.: 57.03%] [G loss: 0.447031]\n",
      "epoch:10 step:9947 [D loss: 0.231274, acc.: 64.06%] [G loss: 0.439913]\n",
      "epoch:10 step:9948 [D loss: 0.201227, acc.: 66.41%] [G loss: 0.447942]\n",
      "epoch:10 step:9949 [D loss: 0.280227, acc.: 49.22%] [G loss: 0.431982]\n",
      "epoch:10 step:9950 [D loss: 0.222898, acc.: 59.38%] [G loss: 0.470831]\n",
      "epoch:10 step:9951 [D loss: 0.209467, acc.: 69.53%] [G loss: 0.530226]\n",
      "epoch:10 step:9952 [D loss: 0.225932, acc.: 63.28%] [G loss: 0.490439]\n",
      "epoch:10 step:9953 [D loss: 0.220391, acc.: 63.28%] [G loss: 0.523327]\n",
      "epoch:10 step:9954 [D loss: 0.244867, acc.: 57.81%] [G loss: 0.466595]\n",
      "epoch:10 step:9955 [D loss: 0.230579, acc.: 65.62%] [G loss: 0.426965]\n",
      "epoch:10 step:9956 [D loss: 0.228960, acc.: 65.62%] [G loss: 0.442466]\n",
      "epoch:10 step:9957 [D loss: 0.264843, acc.: 50.78%] [G loss: 0.442906]\n",
      "epoch:10 step:9958 [D loss: 0.233513, acc.: 60.94%] [G loss: 0.428260]\n",
      "epoch:10 step:9959 [D loss: 0.220700, acc.: 67.97%] [G loss: 0.484910]\n",
      "epoch:10 step:9960 [D loss: 0.273604, acc.: 50.00%] [G loss: 0.455410]\n",
      "epoch:10 step:9961 [D loss: 0.211152, acc.: 64.84%] [G loss: 0.478801]\n",
      "epoch:10 step:9962 [D loss: 0.207215, acc.: 67.97%] [G loss: 0.446839]\n",
      "epoch:10 step:9963 [D loss: 0.209673, acc.: 69.53%] [G loss: 0.451001]\n",
      "epoch:10 step:9964 [D loss: 0.234525, acc.: 60.94%] [G loss: 0.431057]\n",
      "epoch:10 step:9965 [D loss: 0.195096, acc.: 76.56%] [G loss: 0.454010]\n",
      "epoch:10 step:9966 [D loss: 0.256420, acc.: 50.78%] [G loss: 0.427022]\n",
      "epoch:10 step:9967 [D loss: 0.239771, acc.: 62.50%] [G loss: 0.453948]\n",
      "epoch:10 step:9968 [D loss: 0.214853, acc.: 68.75%] [G loss: 0.436894]\n",
      "epoch:10 step:9969 [D loss: 0.238659, acc.: 57.81%] [G loss: 0.478882]\n",
      "epoch:10 step:9970 [D loss: 0.248160, acc.: 58.59%] [G loss: 0.445480]\n",
      "epoch:10 step:9971 [D loss: 0.242728, acc.: 63.28%] [G loss: 0.451018]\n",
      "epoch:10 step:9972 [D loss: 0.234119, acc.: 62.50%] [G loss: 0.481414]\n",
      "epoch:10 step:9973 [D loss: 0.230280, acc.: 61.72%] [G loss: 0.464305]\n",
      "epoch:10 step:9974 [D loss: 0.228110, acc.: 63.28%] [G loss: 0.440682]\n",
      "epoch:10 step:9975 [D loss: 0.234925, acc.: 63.28%] [G loss: 0.463218]\n",
      "epoch:10 step:9976 [D loss: 0.239812, acc.: 64.06%] [G loss: 0.434679]\n",
      "epoch:10 step:9977 [D loss: 0.218750, acc.: 58.59%] [G loss: 0.420708]\n",
      "epoch:10 step:9978 [D loss: 0.215884, acc.: 70.31%] [G loss: 0.454348]\n",
      "epoch:10 step:9979 [D loss: 0.246468, acc.: 57.03%] [G loss: 0.463981]\n",
      "epoch:10 step:9980 [D loss: 0.231524, acc.: 58.59%] [G loss: 0.450025]\n",
      "epoch:10 step:9981 [D loss: 0.215888, acc.: 69.53%] [G loss: 0.429570]\n",
      "epoch:10 step:9982 [D loss: 0.219290, acc.: 66.41%] [G loss: 0.445614]\n",
      "epoch:10 step:9983 [D loss: 0.201459, acc.: 69.53%] [G loss: 0.431483]\n",
      "epoch:10 step:9984 [D loss: 0.252365, acc.: 50.78%] [G loss: 0.404341]\n",
      "epoch:10 step:9985 [D loss: 0.250495, acc.: 58.59%] [G loss: 0.452922]\n",
      "epoch:10 step:9986 [D loss: 0.246580, acc.: 60.94%] [G loss: 0.452033]\n",
      "epoch:10 step:9987 [D loss: 0.206436, acc.: 67.19%] [G loss: 0.465122]\n",
      "epoch:10 step:9988 [D loss: 0.239746, acc.: 58.59%] [G loss: 0.428654]\n",
      "epoch:10 step:9989 [D loss: 0.231346, acc.: 62.50%] [G loss: 0.453571]\n",
      "epoch:10 step:9990 [D loss: 0.206188, acc.: 67.19%] [G loss: 0.462514]\n",
      "epoch:10 step:9991 [D loss: 0.237085, acc.: 59.38%] [G loss: 0.504746]\n",
      "epoch:10 step:9992 [D loss: 0.232432, acc.: 61.72%] [G loss: 0.467455]\n",
      "epoch:10 step:9993 [D loss: 0.222151, acc.: 66.41%] [G loss: 0.455171]\n",
      "epoch:10 step:9994 [D loss: 0.178833, acc.: 74.22%] [G loss: 0.535553]\n",
      "epoch:10 step:9995 [D loss: 0.259065, acc.: 49.22%] [G loss: 0.449017]\n",
      "epoch:10 step:9996 [D loss: 0.222228, acc.: 61.72%] [G loss: 0.470592]\n",
      "epoch:10 step:9997 [D loss: 0.203503, acc.: 65.62%] [G loss: 0.457986]\n",
      "epoch:10 step:9998 [D loss: 0.240420, acc.: 60.16%] [G loss: 0.438026]\n",
      "epoch:10 step:9999 [D loss: 0.208400, acc.: 65.62%] [G loss: 0.468203]\n",
      "epoch:10 step:10000 [D loss: 0.231109, acc.: 63.28%] [G loss: 0.429817]\n",
      "epoch:10 step:10001 [D loss: 0.200266, acc.: 71.88%] [G loss: 0.461853]\n",
      "epoch:10 step:10002 [D loss: 0.234786, acc.: 56.25%] [G loss: 0.494547]\n",
      "epoch:10 step:10003 [D loss: 0.223196, acc.: 65.62%] [G loss: 0.493254]\n",
      "epoch:10 step:10004 [D loss: 0.190936, acc.: 69.53%] [G loss: 0.537966]\n",
      "epoch:10 step:10005 [D loss: 0.202249, acc.: 66.41%] [G loss: 0.508816]\n",
      "epoch:10 step:10006 [D loss: 0.233468, acc.: 60.94%] [G loss: 0.450404]\n",
      "epoch:10 step:10007 [D loss: 0.214607, acc.: 67.97%] [G loss: 0.455686]\n",
      "epoch:10 step:10008 [D loss: 0.239470, acc.: 57.03%] [G loss: 0.457575]\n",
      "epoch:10 step:10009 [D loss: 0.240535, acc.: 56.25%] [G loss: 0.451705]\n",
      "epoch:10 step:10010 [D loss: 0.193551, acc.: 69.53%] [G loss: 0.476095]\n",
      "epoch:10 step:10011 [D loss: 0.187994, acc.: 71.09%] [G loss: 0.517295]\n",
      "epoch:10 step:10012 [D loss: 0.195067, acc.: 68.75%] [G loss: 0.543133]\n",
      "epoch:10 step:10013 [D loss: 0.260760, acc.: 60.94%] [G loss: 0.430792]\n",
      "epoch:10 step:10014 [D loss: 0.229342, acc.: 63.28%] [G loss: 0.472404]\n",
      "epoch:10 step:10015 [D loss: 0.214458, acc.: 65.62%] [G loss: 0.487800]\n",
      "epoch:10 step:10016 [D loss: 0.211720, acc.: 68.75%] [G loss: 0.462042]\n",
      "epoch:10 step:10017 [D loss: 0.200288, acc.: 70.31%] [G loss: 0.484459]\n",
      "epoch:10 step:10018 [D loss: 0.194527, acc.: 70.31%] [G loss: 0.552323]\n",
      "epoch:10 step:10019 [D loss: 0.208044, acc.: 65.62%] [G loss: 0.527278]\n",
      "epoch:10 step:10020 [D loss: 0.203222, acc.: 71.88%] [G loss: 0.496552]\n",
      "epoch:10 step:10021 [D loss: 0.245749, acc.: 57.03%] [G loss: 0.459767]\n",
      "epoch:10 step:10022 [D loss: 0.234411, acc.: 65.62%] [G loss: 0.449379]\n",
      "epoch:10 step:10023 [D loss: 0.212710, acc.: 66.41%] [G loss: 0.501265]\n",
      "epoch:10 step:10024 [D loss: 0.219920, acc.: 65.62%] [G loss: 0.480282]\n",
      "epoch:10 step:10025 [D loss: 0.245981, acc.: 59.38%] [G loss: 0.473354]\n",
      "epoch:10 step:10026 [D loss: 0.212122, acc.: 64.84%] [G loss: 0.510939]\n",
      "epoch:10 step:10027 [D loss: 0.224201, acc.: 62.50%] [G loss: 0.456267]\n",
      "epoch:10 step:10028 [D loss: 0.225908, acc.: 62.50%] [G loss: 0.454244]\n",
      "epoch:10 step:10029 [D loss: 0.212242, acc.: 64.84%] [G loss: 0.461277]\n",
      "epoch:10 step:10030 [D loss: 0.213179, acc.: 64.06%] [G loss: 0.472166]\n",
      "epoch:10 step:10031 [D loss: 0.207403, acc.: 71.09%] [G loss: 0.474683]\n",
      "epoch:10 step:10032 [D loss: 0.246743, acc.: 59.38%] [G loss: 0.447306]\n",
      "epoch:10 step:10033 [D loss: 0.244679, acc.: 60.16%] [G loss: 0.442984]\n",
      "epoch:10 step:10034 [D loss: 0.237654, acc.: 57.81%] [G loss: 0.475804]\n",
      "epoch:10 step:10035 [D loss: 0.210996, acc.: 68.75%] [G loss: 0.433424]\n",
      "epoch:10 step:10036 [D loss: 0.233681, acc.: 64.06%] [G loss: 0.493352]\n",
      "epoch:10 step:10037 [D loss: 0.240964, acc.: 62.50%] [G loss: 0.469258]\n",
      "epoch:10 step:10038 [D loss: 0.224328, acc.: 63.28%] [G loss: 0.450312]\n",
      "epoch:10 step:10039 [D loss: 0.223838, acc.: 64.06%] [G loss: 0.440394]\n",
      "epoch:10 step:10040 [D loss: 0.269375, acc.: 55.47%] [G loss: 0.425488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10041 [D loss: 0.231230, acc.: 65.62%] [G loss: 0.440901]\n",
      "epoch:10 step:10042 [D loss: 0.248891, acc.: 60.94%] [G loss: 0.469700]\n",
      "epoch:10 step:10043 [D loss: 0.246162, acc.: 54.69%] [G loss: 0.450434]\n",
      "epoch:10 step:10044 [D loss: 0.227376, acc.: 67.19%] [G loss: 0.463139]\n",
      "epoch:10 step:10045 [D loss: 0.257293, acc.: 57.03%] [G loss: 0.442873]\n",
      "epoch:10 step:10046 [D loss: 0.233566, acc.: 60.94%] [G loss: 0.428756]\n",
      "epoch:10 step:10047 [D loss: 0.186185, acc.: 73.44%] [G loss: 0.477166]\n",
      "epoch:10 step:10048 [D loss: 0.221719, acc.: 62.50%] [G loss: 0.444757]\n",
      "epoch:10 step:10049 [D loss: 0.208205, acc.: 66.41%] [G loss: 0.475015]\n",
      "epoch:10 step:10050 [D loss: 0.220039, acc.: 67.19%] [G loss: 0.466969]\n",
      "epoch:10 step:10051 [D loss: 0.212946, acc.: 67.97%] [G loss: 0.470493]\n",
      "epoch:10 step:10052 [D loss: 0.218918, acc.: 65.62%] [G loss: 0.429772]\n",
      "epoch:10 step:10053 [D loss: 0.246523, acc.: 58.59%] [G loss: 0.430499]\n",
      "epoch:10 step:10054 [D loss: 0.233328, acc.: 58.59%] [G loss: 0.431385]\n",
      "epoch:10 step:10055 [D loss: 0.213371, acc.: 68.75%] [G loss: 0.426402]\n",
      "epoch:10 step:10056 [D loss: 0.239414, acc.: 61.72%] [G loss: 0.415705]\n",
      "epoch:10 step:10057 [D loss: 0.232941, acc.: 59.38%] [G loss: 0.540365]\n",
      "epoch:10 step:10058 [D loss: 0.198748, acc.: 69.53%] [G loss: 0.503596]\n",
      "epoch:10 step:10059 [D loss: 0.237939, acc.: 60.94%] [G loss: 0.474996]\n",
      "epoch:10 step:10060 [D loss: 0.213526, acc.: 63.28%] [G loss: 0.441844]\n",
      "epoch:10 step:10061 [D loss: 0.192222, acc.: 71.88%] [G loss: 0.511441]\n",
      "epoch:10 step:10062 [D loss: 0.205648, acc.: 67.97%] [G loss: 0.524591]\n",
      "epoch:10 step:10063 [D loss: 0.233347, acc.: 62.50%] [G loss: 0.457253]\n",
      "epoch:10 step:10064 [D loss: 0.219375, acc.: 65.62%] [G loss: 0.470010]\n",
      "epoch:10 step:10065 [D loss: 0.208249, acc.: 71.88%] [G loss: 0.522045]\n",
      "epoch:10 step:10066 [D loss: 0.250692, acc.: 53.12%] [G loss: 0.433328]\n",
      "epoch:10 step:10067 [D loss: 0.235618, acc.: 53.91%] [G loss: 0.446842]\n",
      "epoch:10 step:10068 [D loss: 0.233384, acc.: 59.38%] [G loss: 0.450686]\n",
      "epoch:10 step:10069 [D loss: 0.220832, acc.: 64.84%] [G loss: 0.470311]\n",
      "epoch:10 step:10070 [D loss: 0.213223, acc.: 64.84%] [G loss: 0.420624]\n",
      "epoch:10 step:10071 [D loss: 0.191955, acc.: 70.31%] [G loss: 0.466873]\n",
      "epoch:10 step:10072 [D loss: 0.234010, acc.: 57.81%] [G loss: 0.499090]\n",
      "epoch:10 step:10073 [D loss: 0.245874, acc.: 63.28%] [G loss: 0.414904]\n",
      "epoch:10 step:10074 [D loss: 0.262339, acc.: 53.91%] [G loss: 0.455219]\n",
      "epoch:10 step:10075 [D loss: 0.213750, acc.: 66.41%] [G loss: 0.461646]\n",
      "epoch:10 step:10076 [D loss: 0.241344, acc.: 63.28%] [G loss: 0.438119]\n",
      "epoch:10 step:10077 [D loss: 0.203498, acc.: 67.97%] [G loss: 0.475791]\n",
      "epoch:10 step:10078 [D loss: 0.212852, acc.: 66.41%] [G loss: 0.472594]\n",
      "epoch:10 step:10079 [D loss: 0.198919, acc.: 70.31%] [G loss: 0.496830]\n",
      "epoch:10 step:10080 [D loss: 0.237683, acc.: 60.16%] [G loss: 0.447202]\n",
      "epoch:10 step:10081 [D loss: 0.214711, acc.: 62.50%] [G loss: 0.472496]\n",
      "epoch:10 step:10082 [D loss: 0.232325, acc.: 64.06%] [G loss: 0.476095]\n",
      "epoch:10 step:10083 [D loss: 0.245662, acc.: 60.16%] [G loss: 0.475962]\n",
      "epoch:10 step:10084 [D loss: 0.231931, acc.: 62.50%] [G loss: 0.462910]\n",
      "epoch:10 step:10085 [D loss: 0.191587, acc.: 69.53%] [G loss: 0.460907]\n",
      "epoch:10 step:10086 [D loss: 0.232033, acc.: 58.59%] [G loss: 0.395411]\n",
      "epoch:10 step:10087 [D loss: 0.233126, acc.: 60.94%] [G loss: 0.446979]\n",
      "epoch:10 step:10088 [D loss: 0.252200, acc.: 59.38%] [G loss: 0.420169]\n",
      "epoch:10 step:10089 [D loss: 0.214470, acc.: 65.62%] [G loss: 0.496387]\n",
      "epoch:10 step:10090 [D loss: 0.218646, acc.: 63.28%] [G loss: 0.482792]\n",
      "epoch:10 step:10091 [D loss: 0.235381, acc.: 60.94%] [G loss: 0.436210]\n",
      "epoch:10 step:10092 [D loss: 0.248368, acc.: 53.91%] [G loss: 0.486954]\n",
      "epoch:10 step:10093 [D loss: 0.224555, acc.: 67.97%] [G loss: 0.493079]\n",
      "epoch:10 step:10094 [D loss: 0.228641, acc.: 62.50%] [G loss: 0.500538]\n",
      "epoch:10 step:10095 [D loss: 0.185792, acc.: 76.56%] [G loss: 0.524251]\n",
      "epoch:10 step:10096 [D loss: 0.198153, acc.: 72.66%] [G loss: 0.474974]\n",
      "epoch:10 step:10097 [D loss: 0.252893, acc.: 60.94%] [G loss: 0.410116]\n",
      "epoch:10 step:10098 [D loss: 0.217771, acc.: 66.41%] [G loss: 0.443660]\n",
      "epoch:10 step:10099 [D loss: 0.251826, acc.: 53.91%] [G loss: 0.467441]\n",
      "epoch:10 step:10100 [D loss: 0.207447, acc.: 71.09%] [G loss: 0.479886]\n",
      "epoch:10 step:10101 [D loss: 0.230024, acc.: 63.28%] [G loss: 0.509405]\n",
      "epoch:10 step:10102 [D loss: 0.204342, acc.: 70.31%] [G loss: 0.501931]\n",
      "epoch:10 step:10103 [D loss: 0.220779, acc.: 58.59%] [G loss: 0.436991]\n",
      "epoch:10 step:10104 [D loss: 0.226885, acc.: 66.41%] [G loss: 0.487540]\n",
      "epoch:10 step:10105 [D loss: 0.226204, acc.: 65.62%] [G loss: 0.425428]\n",
      "epoch:10 step:10106 [D loss: 0.204894, acc.: 71.88%] [G loss: 0.456625]\n",
      "epoch:10 step:10107 [D loss: 0.203508, acc.: 67.97%] [G loss: 0.422960]\n",
      "epoch:10 step:10108 [D loss: 0.240026, acc.: 59.38%] [G loss: 0.426028]\n",
      "epoch:10 step:10109 [D loss: 0.245598, acc.: 58.59%] [G loss: 0.409808]\n",
      "epoch:10 step:10110 [D loss: 0.254913, acc.: 53.12%] [G loss: 0.405636]\n",
      "epoch:10 step:10111 [D loss: 0.227140, acc.: 61.72%] [G loss: 0.425945]\n",
      "epoch:10 step:10112 [D loss: 0.204204, acc.: 64.06%] [G loss: 0.478860]\n",
      "epoch:10 step:10113 [D loss: 0.215702, acc.: 60.94%] [G loss: 0.464206]\n",
      "epoch:10 step:10114 [D loss: 0.217690, acc.: 68.75%] [G loss: 0.500882]\n",
      "epoch:10 step:10115 [D loss: 0.223347, acc.: 62.50%] [G loss: 0.465353]\n",
      "epoch:10 step:10116 [D loss: 0.214268, acc.: 70.31%] [G loss: 0.465566]\n",
      "epoch:10 step:10117 [D loss: 0.232174, acc.: 62.50%] [G loss: 0.413947]\n",
      "epoch:10 step:10118 [D loss: 0.234582, acc.: 61.72%] [G loss: 0.423452]\n",
      "epoch:10 step:10119 [D loss: 0.220237, acc.: 64.06%] [G loss: 0.459013]\n",
      "epoch:10 step:10120 [D loss: 0.243804, acc.: 65.62%] [G loss: 0.417639]\n",
      "epoch:10 step:10121 [D loss: 0.228017, acc.: 61.72%] [G loss: 0.426964]\n",
      "epoch:10 step:10122 [D loss: 0.230191, acc.: 63.28%] [G loss: 0.410203]\n",
      "epoch:10 step:10123 [D loss: 0.192588, acc.: 68.75%] [G loss: 0.511370]\n",
      "epoch:10 step:10124 [D loss: 0.219622, acc.: 64.84%] [G loss: 0.445070]\n",
      "epoch:10 step:10125 [D loss: 0.226507, acc.: 64.06%] [G loss: 0.475249]\n",
      "epoch:10 step:10126 [D loss: 0.202374, acc.: 70.31%] [G loss: 0.466294]\n",
      "epoch:10 step:10127 [D loss: 0.239081, acc.: 57.03%] [G loss: 0.413890]\n",
      "epoch:10 step:10128 [D loss: 0.228346, acc.: 60.94%] [G loss: 0.437460]\n",
      "epoch:10 step:10129 [D loss: 0.226633, acc.: 57.81%] [G loss: 0.449849]\n",
      "epoch:10 step:10130 [D loss: 0.246153, acc.: 57.03%] [G loss: 0.442546]\n",
      "epoch:10 step:10131 [D loss: 0.222613, acc.: 65.62%] [G loss: 0.465380]\n",
      "epoch:10 step:10132 [D loss: 0.237098, acc.: 60.94%] [G loss: 0.415679]\n",
      "epoch:10 step:10133 [D loss: 0.219841, acc.: 67.19%] [G loss: 0.455556]\n",
      "epoch:10 step:10134 [D loss: 0.237195, acc.: 60.16%] [G loss: 0.455626]\n",
      "epoch:10 step:10135 [D loss: 0.267144, acc.: 51.56%] [G loss: 0.416744]\n",
      "epoch:10 step:10136 [D loss: 0.248993, acc.: 59.38%] [G loss: 0.450947]\n",
      "epoch:10 step:10137 [D loss: 0.198202, acc.: 67.97%] [G loss: 0.490652]\n",
      "epoch:10 step:10138 [D loss: 0.248112, acc.: 64.06%] [G loss: 0.450471]\n",
      "epoch:10 step:10139 [D loss: 0.192055, acc.: 71.09%] [G loss: 0.501014]\n",
      "epoch:10 step:10140 [D loss: 0.248520, acc.: 57.03%] [G loss: 0.510607]\n",
      "epoch:10 step:10141 [D loss: 0.234061, acc.: 65.62%] [G loss: 0.435948]\n",
      "epoch:10 step:10142 [D loss: 0.220381, acc.: 60.94%] [G loss: 0.452940]\n",
      "epoch:10 step:10143 [D loss: 0.234969, acc.: 60.94%] [G loss: 0.427233]\n",
      "epoch:10 step:10144 [D loss: 0.231314, acc.: 61.72%] [G loss: 0.425906]\n",
      "epoch:10 step:10145 [D loss: 0.207210, acc.: 67.97%] [G loss: 0.512432]\n",
      "epoch:10 step:10146 [D loss: 0.218926, acc.: 64.84%] [G loss: 0.468644]\n",
      "epoch:10 step:10147 [D loss: 0.230630, acc.: 61.72%] [G loss: 0.475643]\n",
      "epoch:10 step:10148 [D loss: 0.227752, acc.: 58.59%] [G loss: 0.472294]\n",
      "epoch:10 step:10149 [D loss: 0.232752, acc.: 57.81%] [G loss: 0.461819]\n",
      "epoch:10 step:10150 [D loss: 0.216075, acc.: 69.53%] [G loss: 0.457014]\n",
      "epoch:10 step:10151 [D loss: 0.160956, acc.: 79.69%] [G loss: 0.536297]\n",
      "epoch:10 step:10152 [D loss: 0.178943, acc.: 76.56%] [G loss: 0.563269]\n",
      "epoch:10 step:10153 [D loss: 0.274906, acc.: 52.34%] [G loss: 0.479634]\n",
      "epoch:10 step:10154 [D loss: 0.275290, acc.: 50.00%] [G loss: 0.413926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10155 [D loss: 0.226447, acc.: 57.81%] [G loss: 0.418481]\n",
      "epoch:10 step:10156 [D loss: 0.201262, acc.: 68.75%] [G loss: 0.514034]\n",
      "epoch:10 step:10157 [D loss: 0.246770, acc.: 57.03%] [G loss: 0.479640]\n",
      "epoch:10 step:10158 [D loss: 0.239336, acc.: 60.94%] [G loss: 0.442115]\n",
      "epoch:10 step:10159 [D loss: 0.218543, acc.: 64.06%] [G loss: 0.458119]\n",
      "epoch:10 step:10160 [D loss: 0.222535, acc.: 60.94%] [G loss: 0.462337]\n",
      "epoch:10 step:10161 [D loss: 0.252687, acc.: 54.69%] [G loss: 0.421936]\n",
      "epoch:10 step:10162 [D loss: 0.187402, acc.: 73.44%] [G loss: 0.466349]\n",
      "epoch:10 step:10163 [D loss: 0.238730, acc.: 58.59%] [G loss: 0.459942]\n",
      "epoch:10 step:10164 [D loss: 0.245802, acc.: 53.91%] [G loss: 0.488090]\n",
      "epoch:10 step:10165 [D loss: 0.251335, acc.: 59.38%] [G loss: 0.436742]\n",
      "epoch:10 step:10166 [D loss: 0.200082, acc.: 69.53%] [G loss: 0.466694]\n",
      "epoch:10 step:10167 [D loss: 0.257995, acc.: 50.00%] [G loss: 0.459315]\n",
      "epoch:10 step:10168 [D loss: 0.244484, acc.: 56.25%] [G loss: 0.433993]\n",
      "epoch:10 step:10169 [D loss: 0.225883, acc.: 66.41%] [G loss: 0.432618]\n",
      "epoch:10 step:10170 [D loss: 0.233366, acc.: 57.03%] [G loss: 0.466277]\n",
      "epoch:10 step:10171 [D loss: 0.210681, acc.: 62.50%] [G loss: 0.483783]\n",
      "epoch:10 step:10172 [D loss: 0.208188, acc.: 67.97%] [G loss: 0.523339]\n",
      "epoch:10 step:10173 [D loss: 0.229552, acc.: 62.50%] [G loss: 0.455168]\n",
      "epoch:10 step:10174 [D loss: 0.238877, acc.: 54.69%] [G loss: 0.452806]\n",
      "epoch:10 step:10175 [D loss: 0.203611, acc.: 67.97%] [G loss: 0.451095]\n",
      "epoch:10 step:10176 [D loss: 0.216026, acc.: 66.41%] [G loss: 0.450567]\n",
      "epoch:10 step:10177 [D loss: 0.210296, acc.: 64.84%] [G loss: 0.452022]\n",
      "epoch:10 step:10178 [D loss: 0.245098, acc.: 57.03%] [G loss: 0.441996]\n",
      "epoch:10 step:10179 [D loss: 0.242475, acc.: 63.28%] [G loss: 0.491450]\n",
      "epoch:10 step:10180 [D loss: 0.228699, acc.: 65.62%] [G loss: 0.485134]\n",
      "epoch:10 step:10181 [D loss: 0.243339, acc.: 58.59%] [G loss: 0.485531]\n",
      "epoch:10 step:10182 [D loss: 0.245864, acc.: 59.38%] [G loss: 0.443405]\n",
      "epoch:10 step:10183 [D loss: 0.230984, acc.: 63.28%] [G loss: 0.438108]\n",
      "epoch:10 step:10184 [D loss: 0.242616, acc.: 57.81%] [G loss: 0.459042]\n",
      "epoch:10 step:10185 [D loss: 0.209818, acc.: 65.62%] [G loss: 0.518137]\n",
      "epoch:10 step:10186 [D loss: 0.229997, acc.: 62.50%] [G loss: 0.497675]\n",
      "epoch:10 step:10187 [D loss: 0.254622, acc.: 57.03%] [G loss: 0.466464]\n",
      "epoch:10 step:10188 [D loss: 0.273352, acc.: 53.91%] [G loss: 0.446822]\n",
      "epoch:10 step:10189 [D loss: 0.229358, acc.: 62.50%] [G loss: 0.417024]\n",
      "epoch:10 step:10190 [D loss: 0.260219, acc.: 53.12%] [G loss: 0.439926]\n",
      "epoch:10 step:10191 [D loss: 0.226494, acc.: 63.28%] [G loss: 0.451179]\n",
      "epoch:10 step:10192 [D loss: 0.199184, acc.: 67.19%] [G loss: 0.453412]\n",
      "epoch:10 step:10193 [D loss: 0.205431, acc.: 65.62%] [G loss: 0.422027]\n",
      "epoch:10 step:10194 [D loss: 0.233667, acc.: 60.94%] [G loss: 0.395304]\n",
      "epoch:10 step:10195 [D loss: 0.202595, acc.: 64.06%] [G loss: 0.447465]\n",
      "epoch:10 step:10196 [D loss: 0.208579, acc.: 64.84%] [G loss: 0.437127]\n",
      "epoch:10 step:10197 [D loss: 0.252808, acc.: 48.44%] [G loss: 0.422276]\n",
      "epoch:10 step:10198 [D loss: 0.268963, acc.: 50.00%] [G loss: 0.439266]\n",
      "epoch:10 step:10199 [D loss: 0.230727, acc.: 61.72%] [G loss: 0.459891]\n",
      "epoch:10 step:10200 [D loss: 0.226729, acc.: 58.59%] [G loss: 0.489732]\n",
      "epoch:10 step:10201 [D loss: 0.246342, acc.: 59.38%] [G loss: 0.410413]\n",
      "epoch:10 step:10202 [D loss: 0.213047, acc.: 64.84%] [G loss: 0.479161]\n",
      "epoch:10 step:10203 [D loss: 0.203662, acc.: 67.97%] [G loss: 0.487351]\n",
      "epoch:10 step:10204 [D loss: 0.232354, acc.: 56.25%] [G loss: 0.471384]\n",
      "epoch:10 step:10205 [D loss: 0.214031, acc.: 64.84%] [G loss: 0.427242]\n",
      "epoch:10 step:10206 [D loss: 0.207971, acc.: 67.97%] [G loss: 0.411441]\n",
      "epoch:10 step:10207 [D loss: 0.200720, acc.: 69.53%] [G loss: 0.462331]\n",
      "epoch:10 step:10208 [D loss: 0.211643, acc.: 59.38%] [G loss: 0.425538]\n",
      "epoch:10 step:10209 [D loss: 0.242312, acc.: 60.16%] [G loss: 0.438027]\n",
      "epoch:10 step:10210 [D loss: 0.214092, acc.: 63.28%] [G loss: 0.478297]\n",
      "epoch:10 step:10211 [D loss: 0.235739, acc.: 56.25%] [G loss: 0.455795]\n",
      "epoch:10 step:10212 [D loss: 0.232663, acc.: 60.16%] [G loss: 0.468470]\n",
      "epoch:10 step:10213 [D loss: 0.242992, acc.: 57.03%] [G loss: 0.447582]\n",
      "epoch:10 step:10214 [D loss: 0.239065, acc.: 60.94%] [G loss: 0.453048]\n",
      "epoch:10 step:10215 [D loss: 0.207139, acc.: 67.19%] [G loss: 0.463922]\n",
      "epoch:10 step:10216 [D loss: 0.257411, acc.: 53.12%] [G loss: 0.473150]\n",
      "epoch:10 step:10217 [D loss: 0.207604, acc.: 67.97%] [G loss: 0.472222]\n",
      "epoch:10 step:10218 [D loss: 0.239342, acc.: 61.72%] [G loss: 0.419706]\n",
      "epoch:10 step:10219 [D loss: 0.205266, acc.: 69.53%] [G loss: 0.462800]\n",
      "epoch:10 step:10220 [D loss: 0.219147, acc.: 64.06%] [G loss: 0.470264]\n",
      "epoch:10 step:10221 [D loss: 0.236107, acc.: 60.94%] [G loss: 0.446150]\n",
      "epoch:10 step:10222 [D loss: 0.205207, acc.: 67.97%] [G loss: 0.466765]\n",
      "epoch:10 step:10223 [D loss: 0.228855, acc.: 62.50%] [G loss: 0.474329]\n",
      "epoch:10 step:10224 [D loss: 0.201281, acc.: 65.62%] [G loss: 0.461006]\n",
      "epoch:10 step:10225 [D loss: 0.257298, acc.: 59.38%] [G loss: 0.430933]\n",
      "epoch:10 step:10226 [D loss: 0.240974, acc.: 55.47%] [G loss: 0.467378]\n",
      "epoch:10 step:10227 [D loss: 0.233089, acc.: 66.41%] [G loss: 0.479977]\n",
      "epoch:10 step:10228 [D loss: 0.257390, acc.: 53.12%] [G loss: 0.456435]\n",
      "epoch:10 step:10229 [D loss: 0.231333, acc.: 60.16%] [G loss: 0.461225]\n",
      "epoch:10 step:10230 [D loss: 0.189853, acc.: 72.66%] [G loss: 0.493161]\n",
      "epoch:10 step:10231 [D loss: 0.244608, acc.: 60.16%] [G loss: 0.468833]\n",
      "epoch:10 step:10232 [D loss: 0.232138, acc.: 61.72%] [G loss: 0.461779]\n",
      "epoch:10 step:10233 [D loss: 0.211763, acc.: 67.19%] [G loss: 0.452310]\n",
      "epoch:10 step:10234 [D loss: 0.232147, acc.: 67.97%] [G loss: 0.436973]\n",
      "epoch:10 step:10235 [D loss: 0.250180, acc.: 58.59%] [G loss: 0.418656]\n",
      "epoch:10 step:10236 [D loss: 0.235346, acc.: 61.72%] [G loss: 0.453153]\n",
      "epoch:10 step:10237 [D loss: 0.230705, acc.: 58.59%] [G loss: 0.503262]\n",
      "epoch:10 step:10238 [D loss: 0.273788, acc.: 52.34%] [G loss: 0.409127]\n",
      "epoch:10 step:10239 [D loss: 0.236348, acc.: 62.50%] [G loss: 0.426549]\n",
      "epoch:10 step:10240 [D loss: 0.222411, acc.: 61.72%] [G loss: 0.444808]\n",
      "epoch:10 step:10241 [D loss: 0.232203, acc.: 61.72%] [G loss: 0.422592]\n",
      "epoch:10 step:10242 [D loss: 0.229492, acc.: 57.81%] [G loss: 0.437610]\n",
      "epoch:10 step:10243 [D loss: 0.227681, acc.: 64.84%] [G loss: 0.458914]\n",
      "epoch:10 step:10244 [D loss: 0.235625, acc.: 64.06%] [G loss: 0.440878]\n",
      "epoch:10 step:10245 [D loss: 0.202634, acc.: 65.62%] [G loss: 0.448239]\n",
      "epoch:10 step:10246 [D loss: 0.222311, acc.: 61.72%] [G loss: 0.425857]\n",
      "epoch:10 step:10247 [D loss: 0.230024, acc.: 60.94%] [G loss: 0.442840]\n",
      "epoch:10 step:10248 [D loss: 0.216022, acc.: 66.41%] [G loss: 0.466421]\n",
      "epoch:10 step:10249 [D loss: 0.229054, acc.: 63.28%] [G loss: 0.416066]\n",
      "epoch:10 step:10250 [D loss: 0.262382, acc.: 52.34%] [G loss: 0.390141]\n",
      "epoch:10 step:10251 [D loss: 0.242314, acc.: 58.59%] [G loss: 0.442333]\n",
      "epoch:10 step:10252 [D loss: 0.215553, acc.: 68.75%] [G loss: 0.417783]\n",
      "epoch:10 step:10253 [D loss: 0.240828, acc.: 62.50%] [G loss: 0.411497]\n",
      "epoch:10 step:10254 [D loss: 0.220384, acc.: 58.59%] [G loss: 0.456501]\n",
      "epoch:10 step:10255 [D loss: 0.216149, acc.: 66.41%] [G loss: 0.504397]\n",
      "epoch:10 step:10256 [D loss: 0.216161, acc.: 65.62%] [G loss: 0.494313]\n",
      "epoch:10 step:10257 [D loss: 0.229838, acc.: 60.94%] [G loss: 0.469641]\n",
      "epoch:10 step:10258 [D loss: 0.235334, acc.: 57.03%] [G loss: 0.455368]\n",
      "epoch:10 step:10259 [D loss: 0.212780, acc.: 65.62%] [G loss: 0.493073]\n",
      "epoch:10 step:10260 [D loss: 0.207752, acc.: 68.75%] [G loss: 0.466104]\n",
      "epoch:10 step:10261 [D loss: 0.262472, acc.: 53.12%] [G loss: 0.397699]\n",
      "epoch:10 step:10262 [D loss: 0.237770, acc.: 61.72%] [G loss: 0.430820]\n",
      "epoch:10 step:10263 [D loss: 0.226811, acc.: 61.72%] [G loss: 0.416711]\n",
      "epoch:10 step:10264 [D loss: 0.202064, acc.: 71.09%] [G loss: 0.502610]\n",
      "epoch:10 step:10265 [D loss: 0.216759, acc.: 68.75%] [G loss: 0.462684]\n",
      "epoch:10 step:10266 [D loss: 0.195216, acc.: 68.75%] [G loss: 0.469934]\n",
      "epoch:10 step:10267 [D loss: 0.220272, acc.: 67.97%] [G loss: 0.466218]\n",
      "epoch:10 step:10268 [D loss: 0.212318, acc.: 68.75%] [G loss: 0.443959]\n",
      "epoch:10 step:10269 [D loss: 0.201656, acc.: 67.19%] [G loss: 0.469409]\n",
      "epoch:10 step:10270 [D loss: 0.221126, acc.: 68.75%] [G loss: 0.475208]\n",
      "epoch:10 step:10271 [D loss: 0.224271, acc.: 60.16%] [G loss: 0.472339]\n",
      "epoch:10 step:10272 [D loss: 0.246019, acc.: 58.59%] [G loss: 0.419364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10273 [D loss: 0.228228, acc.: 62.50%] [G loss: 0.433240]\n",
      "epoch:10 step:10274 [D loss: 0.225882, acc.: 58.59%] [G loss: 0.412373]\n",
      "epoch:10 step:10275 [D loss: 0.207288, acc.: 69.53%] [G loss: 0.465718]\n",
      "epoch:10 step:10276 [D loss: 0.197014, acc.: 71.88%] [G loss: 0.473019]\n",
      "epoch:10 step:10277 [D loss: 0.222094, acc.: 66.41%] [G loss: 0.442920]\n",
      "epoch:10 step:10278 [D loss: 0.204197, acc.: 68.75%] [G loss: 0.522367]\n",
      "epoch:10 step:10279 [D loss: 0.233279, acc.: 60.16%] [G loss: 0.484484]\n",
      "epoch:10 step:10280 [D loss: 0.241705, acc.: 55.47%] [G loss: 0.464788]\n",
      "epoch:10 step:10281 [D loss: 0.189648, acc.: 70.31%] [G loss: 0.475462]\n",
      "epoch:10 step:10282 [D loss: 0.186279, acc.: 77.34%] [G loss: 0.484765]\n",
      "epoch:10 step:10283 [D loss: 0.236166, acc.: 59.38%] [G loss: 0.457532]\n",
      "epoch:10 step:10284 [D loss: 0.221005, acc.: 68.75%] [G loss: 0.425496]\n",
      "epoch:10 step:10285 [D loss: 0.264771, acc.: 57.03%] [G loss: 0.425823]\n",
      "epoch:10 step:10286 [D loss: 0.242759, acc.: 60.94%] [G loss: 0.426412]\n",
      "epoch:10 step:10287 [D loss: 0.227619, acc.: 65.62%] [G loss: 0.460327]\n",
      "epoch:10 step:10288 [D loss: 0.194225, acc.: 70.31%] [G loss: 0.469158]\n",
      "epoch:10 step:10289 [D loss: 0.182113, acc.: 71.88%] [G loss: 0.570200]\n",
      "epoch:10 step:10290 [D loss: 0.296535, acc.: 50.00%] [G loss: 0.448630]\n",
      "epoch:10 step:10291 [D loss: 0.185097, acc.: 74.22%] [G loss: 0.503280]\n",
      "epoch:10 step:10292 [D loss: 0.248334, acc.: 61.72%] [G loss: 0.440949]\n",
      "epoch:10 step:10293 [D loss: 0.217738, acc.: 67.19%] [G loss: 0.472484]\n",
      "epoch:10 step:10294 [D loss: 0.174624, acc.: 75.00%] [G loss: 0.508123]\n",
      "epoch:10 step:10295 [D loss: 0.184131, acc.: 70.31%] [G loss: 0.557578]\n",
      "epoch:10 step:10296 [D loss: 0.177155, acc.: 75.00%] [G loss: 0.520181]\n",
      "epoch:10 step:10297 [D loss: 0.212471, acc.: 67.19%] [G loss: 0.602757]\n",
      "epoch:10 step:10298 [D loss: 0.329492, acc.: 52.34%] [G loss: 0.569765]\n",
      "epoch:10 step:10299 [D loss: 0.230891, acc.: 66.41%] [G loss: 0.630981]\n",
      "epoch:10 step:10300 [D loss: 0.199739, acc.: 67.97%] [G loss: 0.499078]\n",
      "epoch:10 step:10301 [D loss: 0.218169, acc.: 64.84%] [G loss: 0.432556]\n",
      "epoch:10 step:10302 [D loss: 0.296329, acc.: 49.22%] [G loss: 0.405563]\n",
      "epoch:10 step:10303 [D loss: 0.243998, acc.: 63.28%] [G loss: 0.444986]\n",
      "epoch:10 step:10304 [D loss: 0.209915, acc.: 66.41%] [G loss: 0.488574]\n",
      "epoch:10 step:10305 [D loss: 0.202178, acc.: 71.09%] [G loss: 0.550260]\n",
      "epoch:10 step:10306 [D loss: 0.183248, acc.: 75.00%] [G loss: 0.535481]\n",
      "epoch:10 step:10307 [D loss: 0.154526, acc.: 80.47%] [G loss: 0.551318]\n",
      "epoch:11 step:10308 [D loss: 0.232995, acc.: 67.19%] [G loss: 0.496156]\n",
      "epoch:11 step:10309 [D loss: 0.240344, acc.: 64.84%] [G loss: 0.487628]\n",
      "epoch:11 step:10310 [D loss: 0.222962, acc.: 61.72%] [G loss: 0.477956]\n",
      "epoch:11 step:10311 [D loss: 0.242292, acc.: 58.59%] [G loss: 0.446857]\n",
      "epoch:11 step:10312 [D loss: 0.223876, acc.: 64.06%] [G loss: 0.461011]\n",
      "epoch:11 step:10313 [D loss: 0.221942, acc.: 63.28%] [G loss: 0.512787]\n",
      "epoch:11 step:10314 [D loss: 0.221491, acc.: 64.06%] [G loss: 0.455857]\n",
      "epoch:11 step:10315 [D loss: 0.213040, acc.: 61.72%] [G loss: 0.472056]\n",
      "epoch:11 step:10316 [D loss: 0.202847, acc.: 67.97%] [G loss: 0.505553]\n",
      "epoch:11 step:10317 [D loss: 0.224035, acc.: 60.94%] [G loss: 0.494794]\n",
      "epoch:11 step:10318 [D loss: 0.216690, acc.: 66.41%] [G loss: 0.493370]\n",
      "epoch:11 step:10319 [D loss: 0.217765, acc.: 64.84%] [G loss: 0.499067]\n",
      "epoch:11 step:10320 [D loss: 0.239814, acc.: 56.25%] [G loss: 0.472883]\n",
      "epoch:11 step:10321 [D loss: 0.193750, acc.: 71.09%] [G loss: 0.489134]\n",
      "epoch:11 step:10322 [D loss: 0.206362, acc.: 67.19%] [G loss: 0.481762]\n",
      "epoch:11 step:10323 [D loss: 0.197253, acc.: 69.53%] [G loss: 0.473592]\n",
      "epoch:11 step:10324 [D loss: 0.244943, acc.: 57.03%] [G loss: 0.478062]\n",
      "epoch:11 step:10325 [D loss: 0.235522, acc.: 61.72%] [G loss: 0.447427]\n",
      "epoch:11 step:10326 [D loss: 0.256382, acc.: 54.69%] [G loss: 0.456415]\n",
      "epoch:11 step:10327 [D loss: 0.234233, acc.: 64.06%] [G loss: 0.422291]\n",
      "epoch:11 step:10328 [D loss: 0.228395, acc.: 62.50%] [G loss: 0.459726]\n",
      "epoch:11 step:10329 [D loss: 0.214024, acc.: 71.88%] [G loss: 0.519110]\n",
      "epoch:11 step:10330 [D loss: 0.243061, acc.: 57.03%] [G loss: 0.445006]\n",
      "epoch:11 step:10331 [D loss: 0.202053, acc.: 67.97%] [G loss: 0.453435]\n",
      "epoch:11 step:10332 [D loss: 0.199722, acc.: 68.75%] [G loss: 0.489272]\n",
      "epoch:11 step:10333 [D loss: 0.223852, acc.: 64.84%] [G loss: 0.470058]\n",
      "epoch:11 step:10334 [D loss: 0.233078, acc.: 59.38%] [G loss: 0.433898]\n",
      "epoch:11 step:10335 [D loss: 0.241207, acc.: 53.12%] [G loss: 0.405537]\n",
      "epoch:11 step:10336 [D loss: 0.243052, acc.: 59.38%] [G loss: 0.442642]\n",
      "epoch:11 step:10337 [D loss: 0.239315, acc.: 57.03%] [G loss: 0.419545]\n",
      "epoch:11 step:10338 [D loss: 0.226102, acc.: 63.28%] [G loss: 0.432123]\n",
      "epoch:11 step:10339 [D loss: 0.229968, acc.: 66.41%] [G loss: 0.468203]\n",
      "epoch:11 step:10340 [D loss: 0.221439, acc.: 60.94%] [G loss: 0.434913]\n",
      "epoch:11 step:10341 [D loss: 0.235718, acc.: 58.59%] [G loss: 0.419785]\n",
      "epoch:11 step:10342 [D loss: 0.233947, acc.: 57.81%] [G loss: 0.433987]\n",
      "epoch:11 step:10343 [D loss: 0.220697, acc.: 60.16%] [G loss: 0.445039]\n",
      "epoch:11 step:10344 [D loss: 0.232002, acc.: 61.72%] [G loss: 0.460896]\n",
      "epoch:11 step:10345 [D loss: 0.254010, acc.: 54.69%] [G loss: 0.444589]\n",
      "epoch:11 step:10346 [D loss: 0.217259, acc.: 61.72%] [G loss: 0.471804]\n",
      "epoch:11 step:10347 [D loss: 0.187529, acc.: 68.75%] [G loss: 0.496212]\n",
      "epoch:11 step:10348 [D loss: 0.229856, acc.: 57.03%] [G loss: 0.467117]\n",
      "epoch:11 step:10349 [D loss: 0.219617, acc.: 64.84%] [G loss: 0.450214]\n",
      "epoch:11 step:10350 [D loss: 0.231320, acc.: 64.84%] [G loss: 0.420476]\n",
      "epoch:11 step:10351 [D loss: 0.239674, acc.: 57.03%] [G loss: 0.439108]\n",
      "epoch:11 step:10352 [D loss: 0.237229, acc.: 57.03%] [G loss: 0.469239]\n",
      "epoch:11 step:10353 [D loss: 0.247104, acc.: 50.00%] [G loss: 0.434169]\n",
      "epoch:11 step:10354 [D loss: 0.239497, acc.: 57.03%] [G loss: 0.427512]\n",
      "epoch:11 step:10355 [D loss: 0.216250, acc.: 66.41%] [G loss: 0.457437]\n",
      "epoch:11 step:10356 [D loss: 0.198918, acc.: 71.88%] [G loss: 0.514398]\n",
      "epoch:11 step:10357 [D loss: 0.208626, acc.: 67.97%] [G loss: 0.473305]\n",
      "epoch:11 step:10358 [D loss: 0.254986, acc.: 56.25%] [G loss: 0.452420]\n",
      "epoch:11 step:10359 [D loss: 0.204128, acc.: 62.50%] [G loss: 0.479722]\n",
      "epoch:11 step:10360 [D loss: 0.229190, acc.: 59.38%] [G loss: 0.464888]\n",
      "epoch:11 step:10361 [D loss: 0.209888, acc.: 64.06%] [G loss: 0.469446]\n",
      "epoch:11 step:10362 [D loss: 0.234036, acc.: 61.72%] [G loss: 0.428870]\n",
      "epoch:11 step:10363 [D loss: 0.225212, acc.: 64.06%] [G loss: 0.462397]\n",
      "epoch:11 step:10364 [D loss: 0.227785, acc.: 63.28%] [G loss: 0.446698]\n",
      "epoch:11 step:10365 [D loss: 0.229615, acc.: 66.41%] [G loss: 0.427223]\n",
      "epoch:11 step:10366 [D loss: 0.225940, acc.: 62.50%] [G loss: 0.466237]\n",
      "epoch:11 step:10367 [D loss: 0.252775, acc.: 57.03%] [G loss: 0.470856]\n",
      "epoch:11 step:10368 [D loss: 0.229394, acc.: 63.28%] [G loss: 0.435176]\n",
      "epoch:11 step:10369 [D loss: 0.247380, acc.: 57.81%] [G loss: 0.410769]\n",
      "epoch:11 step:10370 [D loss: 0.187338, acc.: 71.09%] [G loss: 0.456433]\n",
      "epoch:11 step:10371 [D loss: 0.200340, acc.: 71.09%] [G loss: 0.430124]\n",
      "epoch:11 step:10372 [D loss: 0.240966, acc.: 59.38%] [G loss: 0.443567]\n",
      "epoch:11 step:10373 [D loss: 0.211387, acc.: 67.97%] [G loss: 0.475798]\n",
      "epoch:11 step:10374 [D loss: 0.214977, acc.: 67.97%] [G loss: 0.464725]\n",
      "epoch:11 step:10375 [D loss: 0.236241, acc.: 61.72%] [G loss: 0.442802]\n",
      "epoch:11 step:10376 [D loss: 0.185071, acc.: 72.66%] [G loss: 0.481267]\n",
      "epoch:11 step:10377 [D loss: 0.217288, acc.: 65.62%] [G loss: 0.485340]\n",
      "epoch:11 step:10378 [D loss: 0.236271, acc.: 57.03%] [G loss: 0.452268]\n",
      "epoch:11 step:10379 [D loss: 0.229586, acc.: 57.81%] [G loss: 0.411453]\n",
      "epoch:11 step:10380 [D loss: 0.234313, acc.: 60.94%] [G loss: 0.424763]\n",
      "epoch:11 step:10381 [D loss: 0.205025, acc.: 71.09%] [G loss: 0.478782]\n",
      "epoch:11 step:10382 [D loss: 0.206523, acc.: 67.19%] [G loss: 0.490869]\n",
      "epoch:11 step:10383 [D loss: 0.185587, acc.: 70.31%] [G loss: 0.524666]\n",
      "epoch:11 step:10384 [D loss: 0.199036, acc.: 69.53%] [G loss: 0.505433]\n",
      "epoch:11 step:10385 [D loss: 0.251701, acc.: 61.72%] [G loss: 0.465365]\n",
      "epoch:11 step:10386 [D loss: 0.252532, acc.: 57.03%] [G loss: 0.380877]\n",
      "epoch:11 step:10387 [D loss: 0.215039, acc.: 67.97%] [G loss: 0.433825]\n",
      "epoch:11 step:10388 [D loss: 0.228660, acc.: 61.72%] [G loss: 0.438839]\n",
      "epoch:11 step:10389 [D loss: 0.224943, acc.: 63.28%] [G loss: 0.462940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10390 [D loss: 0.201197, acc.: 71.88%] [G loss: 0.462062]\n",
      "epoch:11 step:10391 [D loss: 0.196018, acc.: 71.09%] [G loss: 0.470681]\n",
      "epoch:11 step:10392 [D loss: 0.205850, acc.: 64.84%] [G loss: 0.468138]\n",
      "epoch:11 step:10393 [D loss: 0.231041, acc.: 63.28%] [G loss: 0.446883]\n",
      "epoch:11 step:10394 [D loss: 0.214514, acc.: 69.53%] [G loss: 0.485428]\n",
      "epoch:11 step:10395 [D loss: 0.224381, acc.: 67.97%] [G loss: 0.453550]\n",
      "epoch:11 step:10396 [D loss: 0.214473, acc.: 68.75%] [G loss: 0.469045]\n",
      "epoch:11 step:10397 [D loss: 0.219007, acc.: 65.62%] [G loss: 0.466999]\n",
      "epoch:11 step:10398 [D loss: 0.228368, acc.: 64.84%] [G loss: 0.486363]\n",
      "epoch:11 step:10399 [D loss: 0.228554, acc.: 63.28%] [G loss: 0.471572]\n",
      "epoch:11 step:10400 [D loss: 0.194008, acc.: 71.09%] [G loss: 0.501027]\n",
      "epoch:11 step:10401 [D loss: 0.221695, acc.: 63.28%] [G loss: 0.494265]\n",
      "epoch:11 step:10402 [D loss: 0.209746, acc.: 68.75%] [G loss: 0.430134]\n",
      "epoch:11 step:10403 [D loss: 0.201056, acc.: 70.31%] [G loss: 0.480564]\n",
      "epoch:11 step:10404 [D loss: 0.183677, acc.: 71.88%] [G loss: 0.534339]\n",
      "epoch:11 step:10405 [D loss: 0.221754, acc.: 64.84%] [G loss: 0.489228]\n",
      "epoch:11 step:10406 [D loss: 0.224068, acc.: 64.84%] [G loss: 0.445892]\n",
      "epoch:11 step:10407 [D loss: 0.186337, acc.: 70.31%] [G loss: 0.488152]\n",
      "epoch:11 step:10408 [D loss: 0.234624, acc.: 62.50%] [G loss: 0.502353]\n",
      "epoch:11 step:10409 [D loss: 0.257559, acc.: 56.25%] [G loss: 0.436041]\n",
      "epoch:11 step:10410 [D loss: 0.230935, acc.: 60.16%] [G loss: 0.434137]\n",
      "epoch:11 step:10411 [D loss: 0.231037, acc.: 62.50%] [G loss: 0.440766]\n",
      "epoch:11 step:10412 [D loss: 0.246116, acc.: 54.69%] [G loss: 0.429586]\n",
      "epoch:11 step:10413 [D loss: 0.226391, acc.: 61.72%] [G loss: 0.459504]\n",
      "epoch:11 step:10414 [D loss: 0.204506, acc.: 67.19%] [G loss: 0.526004]\n",
      "epoch:11 step:10415 [D loss: 0.277545, acc.: 50.78%] [G loss: 0.485470]\n",
      "epoch:11 step:10416 [D loss: 0.279989, acc.: 45.31%] [G loss: 0.427006]\n",
      "epoch:11 step:10417 [D loss: 0.237437, acc.: 57.81%] [G loss: 0.450892]\n",
      "epoch:11 step:10418 [D loss: 0.202863, acc.: 65.62%] [G loss: 0.465518]\n",
      "epoch:11 step:10419 [D loss: 0.205759, acc.: 71.09%] [G loss: 0.486031]\n",
      "epoch:11 step:10420 [D loss: 0.228699, acc.: 64.06%] [G loss: 0.531077]\n",
      "epoch:11 step:10421 [D loss: 0.214497, acc.: 71.88%] [G loss: 0.502893]\n",
      "epoch:11 step:10422 [D loss: 0.206091, acc.: 67.19%] [G loss: 0.522656]\n",
      "epoch:11 step:10423 [D loss: 0.220203, acc.: 66.41%] [G loss: 0.472479]\n",
      "epoch:11 step:10424 [D loss: 0.192598, acc.: 70.31%] [G loss: 0.515349]\n",
      "epoch:11 step:10425 [D loss: 0.181388, acc.: 71.88%] [G loss: 0.500525]\n",
      "epoch:11 step:10426 [D loss: 0.190319, acc.: 67.19%] [G loss: 0.550011]\n",
      "epoch:11 step:10427 [D loss: 0.267603, acc.: 59.38%] [G loss: 0.488057]\n",
      "epoch:11 step:10428 [D loss: 0.250627, acc.: 57.81%] [G loss: 0.481646]\n",
      "epoch:11 step:10429 [D loss: 0.197626, acc.: 72.66%] [G loss: 0.492865]\n",
      "epoch:11 step:10430 [D loss: 0.211398, acc.: 66.41%] [G loss: 0.506541]\n",
      "epoch:11 step:10431 [D loss: 0.230220, acc.: 61.72%] [G loss: 0.488681]\n",
      "epoch:11 step:10432 [D loss: 0.223382, acc.: 61.72%] [G loss: 0.455629]\n",
      "epoch:11 step:10433 [D loss: 0.209468, acc.: 65.62%] [G loss: 0.455213]\n",
      "epoch:11 step:10434 [D loss: 0.221716, acc.: 61.72%] [G loss: 0.464912]\n",
      "epoch:11 step:10435 [D loss: 0.236349, acc.: 60.94%] [G loss: 0.443652]\n",
      "epoch:11 step:10436 [D loss: 0.225234, acc.: 64.06%] [G loss: 0.436276]\n",
      "epoch:11 step:10437 [D loss: 0.189563, acc.: 71.09%] [G loss: 0.503140]\n",
      "epoch:11 step:10438 [D loss: 0.227260, acc.: 61.72%] [G loss: 0.499429]\n",
      "epoch:11 step:10439 [D loss: 0.215039, acc.: 67.19%] [G loss: 0.476984]\n",
      "epoch:11 step:10440 [D loss: 0.227311, acc.: 60.16%] [G loss: 0.475534]\n",
      "epoch:11 step:10441 [D loss: 0.226678, acc.: 62.50%] [G loss: 0.440250]\n",
      "epoch:11 step:10442 [D loss: 0.198646, acc.: 71.09%] [G loss: 0.484920]\n",
      "epoch:11 step:10443 [D loss: 0.240597, acc.: 56.25%] [G loss: 0.477277]\n",
      "epoch:11 step:10444 [D loss: 0.241972, acc.: 59.38%] [G loss: 0.487027]\n",
      "epoch:11 step:10445 [D loss: 0.255646, acc.: 54.69%] [G loss: 0.393775]\n",
      "epoch:11 step:10446 [D loss: 0.229524, acc.: 59.38%] [G loss: 0.473957]\n",
      "epoch:11 step:10447 [D loss: 0.222451, acc.: 66.41%] [G loss: 0.465160]\n",
      "epoch:11 step:10448 [D loss: 0.240013, acc.: 52.34%] [G loss: 0.416619]\n",
      "epoch:11 step:10449 [D loss: 0.241673, acc.: 52.34%] [G loss: 0.436957]\n",
      "epoch:11 step:10450 [D loss: 0.229226, acc.: 56.25%] [G loss: 0.466163]\n",
      "epoch:11 step:10451 [D loss: 0.201363, acc.: 73.44%] [G loss: 0.491562]\n",
      "epoch:11 step:10452 [D loss: 0.216974, acc.: 61.72%] [G loss: 0.510127]\n",
      "epoch:11 step:10453 [D loss: 0.226198, acc.: 60.94%] [G loss: 0.498913]\n",
      "epoch:11 step:10454 [D loss: 0.252659, acc.: 57.81%] [G loss: 0.446529]\n",
      "epoch:11 step:10455 [D loss: 0.245907, acc.: 59.38%] [G loss: 0.435518]\n",
      "epoch:11 step:10456 [D loss: 0.194360, acc.: 71.88%] [G loss: 0.441109]\n",
      "epoch:11 step:10457 [D loss: 0.239811, acc.: 61.72%] [G loss: 0.391053]\n",
      "epoch:11 step:10458 [D loss: 0.234054, acc.: 61.72%] [G loss: 0.438019]\n",
      "epoch:11 step:10459 [D loss: 0.212902, acc.: 65.62%] [G loss: 0.467079]\n",
      "epoch:11 step:10460 [D loss: 0.234005, acc.: 61.72%] [G loss: 0.453317]\n",
      "epoch:11 step:10461 [D loss: 0.236569, acc.: 57.03%] [G loss: 0.440332]\n",
      "epoch:11 step:10462 [D loss: 0.192565, acc.: 69.53%] [G loss: 0.474623]\n",
      "epoch:11 step:10463 [D loss: 0.230342, acc.: 59.38%] [G loss: 0.459196]\n",
      "epoch:11 step:10464 [D loss: 0.231719, acc.: 60.16%] [G loss: 0.460294]\n",
      "epoch:11 step:10465 [D loss: 0.232438, acc.: 63.28%] [G loss: 0.490252]\n",
      "epoch:11 step:10466 [D loss: 0.231525, acc.: 59.38%] [G loss: 0.464453]\n",
      "epoch:11 step:10467 [D loss: 0.281233, acc.: 46.09%] [G loss: 0.447044]\n",
      "epoch:11 step:10468 [D loss: 0.214814, acc.: 67.19%] [G loss: 0.528072]\n",
      "epoch:11 step:10469 [D loss: 0.217586, acc.: 64.84%] [G loss: 0.446271]\n",
      "epoch:11 step:10470 [D loss: 0.219129, acc.: 65.62%] [G loss: 0.441471]\n",
      "epoch:11 step:10471 [D loss: 0.244811, acc.: 59.38%] [G loss: 0.427077]\n",
      "epoch:11 step:10472 [D loss: 0.235256, acc.: 57.81%] [G loss: 0.431285]\n",
      "epoch:11 step:10473 [D loss: 0.209155, acc.: 63.28%] [G loss: 0.451676]\n",
      "epoch:11 step:10474 [D loss: 0.219929, acc.: 64.06%] [G loss: 0.489101]\n",
      "epoch:11 step:10475 [D loss: 0.208378, acc.: 67.19%] [G loss: 0.466892]\n",
      "epoch:11 step:10476 [D loss: 0.223030, acc.: 59.38%] [G loss: 0.469852]\n",
      "epoch:11 step:10477 [D loss: 0.242694, acc.: 53.91%] [G loss: 0.441801]\n",
      "epoch:11 step:10478 [D loss: 0.207069, acc.: 64.84%] [G loss: 0.458579]\n",
      "epoch:11 step:10479 [D loss: 0.224517, acc.: 60.16%] [G loss: 0.462115]\n",
      "epoch:11 step:10480 [D loss: 0.202980, acc.: 65.62%] [G loss: 0.484138]\n",
      "epoch:11 step:10481 [D loss: 0.234561, acc.: 59.38%] [G loss: 0.408461]\n",
      "epoch:11 step:10482 [D loss: 0.244127, acc.: 57.81%] [G loss: 0.442675]\n",
      "epoch:11 step:10483 [D loss: 0.239615, acc.: 58.59%] [G loss: 0.436771]\n",
      "epoch:11 step:10484 [D loss: 0.246877, acc.: 59.38%] [G loss: 0.439441]\n",
      "epoch:11 step:10485 [D loss: 0.217955, acc.: 61.72%] [G loss: 0.448028]\n",
      "epoch:11 step:10486 [D loss: 0.226525, acc.: 64.84%] [G loss: 0.445647]\n",
      "epoch:11 step:10487 [D loss: 0.226932, acc.: 58.59%] [G loss: 0.418371]\n",
      "epoch:11 step:10488 [D loss: 0.248077, acc.: 54.69%] [G loss: 0.416505]\n",
      "epoch:11 step:10489 [D loss: 0.264609, acc.: 59.38%] [G loss: 0.472430]\n",
      "epoch:11 step:10490 [D loss: 0.232559, acc.: 65.62%] [G loss: 0.473236]\n",
      "epoch:11 step:10491 [D loss: 0.243839, acc.: 55.47%] [G loss: 0.447969]\n",
      "epoch:11 step:10492 [D loss: 0.227425, acc.: 65.62%] [G loss: 0.452697]\n",
      "epoch:11 step:10493 [D loss: 0.222612, acc.: 67.19%] [G loss: 0.486555]\n",
      "epoch:11 step:10494 [D loss: 0.250759, acc.: 57.81%] [G loss: 0.442046]\n",
      "epoch:11 step:10495 [D loss: 0.252222, acc.: 57.03%] [G loss: 0.413091]\n",
      "epoch:11 step:10496 [D loss: 0.250411, acc.: 50.78%] [G loss: 0.428022]\n",
      "epoch:11 step:10497 [D loss: 0.207983, acc.: 67.19%] [G loss: 0.457032]\n",
      "epoch:11 step:10498 [D loss: 0.212388, acc.: 70.31%] [G loss: 0.469112]\n",
      "epoch:11 step:10499 [D loss: 0.189330, acc.: 67.97%] [G loss: 0.490059]\n",
      "epoch:11 step:10500 [D loss: 0.213250, acc.: 66.41%] [G loss: 0.462169]\n",
      "epoch:11 step:10501 [D loss: 0.213293, acc.: 63.28%] [G loss: 0.481564]\n",
      "epoch:11 step:10502 [D loss: 0.217461, acc.: 67.19%] [G loss: 0.469274]\n",
      "epoch:11 step:10503 [D loss: 0.221650, acc.: 58.59%] [G loss: 0.496527]\n",
      "epoch:11 step:10504 [D loss: 0.220460, acc.: 64.06%] [G loss: 0.439751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10505 [D loss: 0.189580, acc.: 69.53%] [G loss: 0.425525]\n",
      "epoch:11 step:10506 [D loss: 0.248421, acc.: 56.25%] [G loss: 0.438503]\n",
      "epoch:11 step:10507 [D loss: 0.228181, acc.: 62.50%] [G loss: 0.413741]\n",
      "epoch:11 step:10508 [D loss: 0.224134, acc.: 65.62%] [G loss: 0.448990]\n",
      "epoch:11 step:10509 [D loss: 0.231247, acc.: 62.50%] [G loss: 0.464802]\n",
      "epoch:11 step:10510 [D loss: 0.247427, acc.: 54.69%] [G loss: 0.462567]\n",
      "epoch:11 step:10511 [D loss: 0.223049, acc.: 61.72%] [G loss: 0.463435]\n",
      "epoch:11 step:10512 [D loss: 0.197646, acc.: 73.44%] [G loss: 0.542665]\n",
      "epoch:11 step:10513 [D loss: 0.229468, acc.: 59.38%] [G loss: 0.555092]\n",
      "epoch:11 step:10514 [D loss: 0.222430, acc.: 64.84%] [G loss: 0.524514]\n",
      "epoch:11 step:10515 [D loss: 0.169247, acc.: 73.44%] [G loss: 0.527546]\n",
      "epoch:11 step:10516 [D loss: 0.215040, acc.: 59.38%] [G loss: 0.482346]\n",
      "epoch:11 step:10517 [D loss: 0.287301, acc.: 52.34%] [G loss: 0.457564]\n",
      "epoch:11 step:10518 [D loss: 0.254296, acc.: 53.91%] [G loss: 0.405531]\n",
      "epoch:11 step:10519 [D loss: 0.248873, acc.: 57.03%] [G loss: 0.432439]\n",
      "epoch:11 step:10520 [D loss: 0.245197, acc.: 58.59%] [G loss: 0.416960]\n",
      "epoch:11 step:10521 [D loss: 0.225316, acc.: 62.50%] [G loss: 0.446250]\n",
      "epoch:11 step:10522 [D loss: 0.231969, acc.: 60.94%] [G loss: 0.415818]\n",
      "epoch:11 step:10523 [D loss: 0.226330, acc.: 62.50%] [G loss: 0.428112]\n",
      "epoch:11 step:10524 [D loss: 0.201902, acc.: 68.75%] [G loss: 0.447035]\n",
      "epoch:11 step:10525 [D loss: 0.185050, acc.: 76.56%] [G loss: 0.471117]\n",
      "epoch:11 step:10526 [D loss: 0.189458, acc.: 69.53%] [G loss: 0.491562]\n",
      "epoch:11 step:10527 [D loss: 0.267650, acc.: 55.47%] [G loss: 0.426751]\n",
      "epoch:11 step:10528 [D loss: 0.238429, acc.: 60.94%] [G loss: 0.410960]\n",
      "epoch:11 step:10529 [D loss: 0.209799, acc.: 66.41%] [G loss: 0.502871]\n",
      "epoch:11 step:10530 [D loss: 0.227047, acc.: 57.81%] [G loss: 0.500335]\n",
      "epoch:11 step:10531 [D loss: 0.252163, acc.: 57.81%] [G loss: 0.438966]\n",
      "epoch:11 step:10532 [D loss: 0.227347, acc.: 65.62%] [G loss: 0.474245]\n",
      "epoch:11 step:10533 [D loss: 0.263720, acc.: 57.03%] [G loss: 0.408072]\n",
      "epoch:11 step:10534 [D loss: 0.216603, acc.: 67.19%] [G loss: 0.441868]\n",
      "epoch:11 step:10535 [D loss: 0.241089, acc.: 53.12%] [G loss: 0.445698]\n",
      "epoch:11 step:10536 [D loss: 0.200371, acc.: 69.53%] [G loss: 0.467056]\n",
      "epoch:11 step:10537 [D loss: 0.201540, acc.: 69.53%] [G loss: 0.478281]\n",
      "epoch:11 step:10538 [D loss: 0.184036, acc.: 71.09%] [G loss: 0.507699]\n",
      "epoch:11 step:10539 [D loss: 0.168327, acc.: 73.44%] [G loss: 0.574843]\n",
      "epoch:11 step:10540 [D loss: 0.286168, acc.: 55.47%] [G loss: 0.455617]\n",
      "epoch:11 step:10541 [D loss: 0.238805, acc.: 58.59%] [G loss: 0.447583]\n",
      "epoch:11 step:10542 [D loss: 0.234979, acc.: 59.38%] [G loss: 0.470208]\n",
      "epoch:11 step:10543 [D loss: 0.242838, acc.: 59.38%] [G loss: 0.418235]\n",
      "epoch:11 step:10544 [D loss: 0.224730, acc.: 63.28%] [G loss: 0.419956]\n",
      "epoch:11 step:10545 [D loss: 0.189464, acc.: 72.66%] [G loss: 0.457567]\n",
      "epoch:11 step:10546 [D loss: 0.226632, acc.: 67.19%] [G loss: 0.450930]\n",
      "epoch:11 step:10547 [D loss: 0.209592, acc.: 68.75%] [G loss: 0.461533]\n",
      "epoch:11 step:10548 [D loss: 0.187899, acc.: 70.31%] [G loss: 0.518039]\n",
      "epoch:11 step:10549 [D loss: 0.237368, acc.: 64.06%] [G loss: 0.512751]\n",
      "epoch:11 step:10550 [D loss: 0.209475, acc.: 63.28%] [G loss: 0.486573]\n",
      "epoch:11 step:10551 [D loss: 0.209134, acc.: 65.62%] [G loss: 0.491931]\n",
      "epoch:11 step:10552 [D loss: 0.222747, acc.: 67.19%] [G loss: 0.477278]\n",
      "epoch:11 step:10553 [D loss: 0.224913, acc.: 64.84%] [G loss: 0.462300]\n",
      "epoch:11 step:10554 [D loss: 0.226854, acc.: 64.06%] [G loss: 0.452372]\n",
      "epoch:11 step:10555 [D loss: 0.217671, acc.: 64.84%] [G loss: 0.508320]\n",
      "epoch:11 step:10556 [D loss: 0.278570, acc.: 48.44%] [G loss: 0.462040]\n",
      "epoch:11 step:10557 [D loss: 0.306723, acc.: 41.41%] [G loss: 0.433288]\n",
      "epoch:11 step:10558 [D loss: 0.242536, acc.: 56.25%] [G loss: 0.475986]\n",
      "epoch:11 step:10559 [D loss: 0.225087, acc.: 62.50%] [G loss: 0.466816]\n",
      "epoch:11 step:10560 [D loss: 0.249140, acc.: 57.03%] [G loss: 0.449808]\n",
      "epoch:11 step:10561 [D loss: 0.192112, acc.: 71.09%] [G loss: 0.446479]\n",
      "epoch:11 step:10562 [D loss: 0.218968, acc.: 64.06%] [G loss: 0.413741]\n",
      "epoch:11 step:10563 [D loss: 0.232740, acc.: 65.62%] [G loss: 0.423880]\n",
      "epoch:11 step:10564 [D loss: 0.228591, acc.: 58.59%] [G loss: 0.445157]\n",
      "epoch:11 step:10565 [D loss: 0.215719, acc.: 66.41%] [G loss: 0.432280]\n",
      "epoch:11 step:10566 [D loss: 0.203029, acc.: 63.28%] [G loss: 0.452207]\n",
      "epoch:11 step:10567 [D loss: 0.209027, acc.: 67.19%] [G loss: 0.505220]\n",
      "epoch:11 step:10568 [D loss: 0.227034, acc.: 63.28%] [G loss: 0.486659]\n",
      "epoch:11 step:10569 [D loss: 0.202032, acc.: 64.06%] [G loss: 0.501830]\n",
      "epoch:11 step:10570 [D loss: 0.265084, acc.: 50.78%] [G loss: 0.449778]\n",
      "epoch:11 step:10571 [D loss: 0.219482, acc.: 70.31%] [G loss: 0.439284]\n",
      "epoch:11 step:10572 [D loss: 0.270864, acc.: 52.34%] [G loss: 0.417271]\n",
      "epoch:11 step:10573 [D loss: 0.219865, acc.: 64.06%] [G loss: 0.444172]\n",
      "epoch:11 step:10574 [D loss: 0.231521, acc.: 64.84%] [G loss: 0.431483]\n",
      "epoch:11 step:10575 [D loss: 0.242244, acc.: 57.03%] [G loss: 0.424789]\n",
      "epoch:11 step:10576 [D loss: 0.209389, acc.: 69.53%] [G loss: 0.465990]\n",
      "epoch:11 step:10577 [D loss: 0.208389, acc.: 67.97%] [G loss: 0.464641]\n",
      "epoch:11 step:10578 [D loss: 0.192002, acc.: 71.09%] [G loss: 0.460930]\n",
      "epoch:11 step:10579 [D loss: 0.223946, acc.: 64.06%] [G loss: 0.462737]\n",
      "epoch:11 step:10580 [D loss: 0.217223, acc.: 66.41%] [G loss: 0.434487]\n",
      "epoch:11 step:10581 [D loss: 0.219614, acc.: 67.97%] [G loss: 0.443784]\n",
      "epoch:11 step:10582 [D loss: 0.241987, acc.: 58.59%] [G loss: 0.434801]\n",
      "epoch:11 step:10583 [D loss: 0.204631, acc.: 69.53%] [G loss: 0.488623]\n",
      "epoch:11 step:10584 [D loss: 0.254897, acc.: 50.00%] [G loss: 0.459188]\n",
      "epoch:11 step:10585 [D loss: 0.240080, acc.: 60.16%] [G loss: 0.492873]\n",
      "epoch:11 step:10586 [D loss: 0.207468, acc.: 68.75%] [G loss: 0.504290]\n",
      "epoch:11 step:10587 [D loss: 0.221941, acc.: 64.84%] [G loss: 0.509030]\n",
      "epoch:11 step:10588 [D loss: 0.292936, acc.: 45.31%] [G loss: 0.402590]\n",
      "epoch:11 step:10589 [D loss: 0.226545, acc.: 62.50%] [G loss: 0.417022]\n",
      "epoch:11 step:10590 [D loss: 0.211141, acc.: 64.06%] [G loss: 0.426243]\n",
      "epoch:11 step:10591 [D loss: 0.231253, acc.: 56.25%] [G loss: 0.433779]\n",
      "epoch:11 step:10592 [D loss: 0.244372, acc.: 58.59%] [G loss: 0.435230]\n",
      "epoch:11 step:10593 [D loss: 0.226412, acc.: 63.28%] [G loss: 0.451008]\n",
      "epoch:11 step:10594 [D loss: 0.244033, acc.: 53.91%] [G loss: 0.428514]\n",
      "epoch:11 step:10595 [D loss: 0.230709, acc.: 62.50%] [G loss: 0.432019]\n",
      "epoch:11 step:10596 [D loss: 0.206917, acc.: 65.62%] [G loss: 0.507007]\n",
      "epoch:11 step:10597 [D loss: 0.227508, acc.: 57.81%] [G loss: 0.466618]\n",
      "epoch:11 step:10598 [D loss: 0.254651, acc.: 52.34%] [G loss: 0.417536]\n",
      "epoch:11 step:10599 [D loss: 0.252707, acc.: 60.94%] [G loss: 0.415533]\n",
      "epoch:11 step:10600 [D loss: 0.209392, acc.: 68.75%] [G loss: 0.440743]\n",
      "epoch:11 step:10601 [D loss: 0.238062, acc.: 61.72%] [G loss: 0.417771]\n",
      "epoch:11 step:10602 [D loss: 0.227066, acc.: 57.81%] [G loss: 0.433834]\n",
      "epoch:11 step:10603 [D loss: 0.181387, acc.: 76.56%] [G loss: 0.447627]\n",
      "epoch:11 step:10604 [D loss: 0.197543, acc.: 69.53%] [G loss: 0.458402]\n",
      "epoch:11 step:10605 [D loss: 0.217283, acc.: 62.50%] [G loss: 0.466857]\n",
      "epoch:11 step:10606 [D loss: 0.195811, acc.: 68.75%] [G loss: 0.481038]\n",
      "epoch:11 step:10607 [D loss: 0.204339, acc.: 68.75%] [G loss: 0.503117]\n",
      "epoch:11 step:10608 [D loss: 0.251535, acc.: 50.78%] [G loss: 0.468012]\n",
      "epoch:11 step:10609 [D loss: 0.196591, acc.: 71.88%] [G loss: 0.464087]\n",
      "epoch:11 step:10610 [D loss: 0.241404, acc.: 55.47%] [G loss: 0.467587]\n",
      "epoch:11 step:10611 [D loss: 0.219163, acc.: 67.19%] [G loss: 0.496010]\n",
      "epoch:11 step:10612 [D loss: 0.225991, acc.: 60.94%] [G loss: 0.438785]\n",
      "epoch:11 step:10613 [D loss: 0.219672, acc.: 64.84%] [G loss: 0.475289]\n",
      "epoch:11 step:10614 [D loss: 0.224328, acc.: 66.41%] [G loss: 0.439596]\n",
      "epoch:11 step:10615 [D loss: 0.235423, acc.: 58.59%] [G loss: 0.498003]\n",
      "epoch:11 step:10616 [D loss: 0.213086, acc.: 64.06%] [G loss: 0.440998]\n",
      "epoch:11 step:10617 [D loss: 0.205939, acc.: 67.19%] [G loss: 0.480808]\n",
      "epoch:11 step:10618 [D loss: 0.223377, acc.: 65.62%] [G loss: 0.438624]\n",
      "epoch:11 step:10619 [D loss: 0.185651, acc.: 70.31%] [G loss: 0.526910]\n",
      "epoch:11 step:10620 [D loss: 0.173232, acc.: 71.09%] [G loss: 0.513562]\n",
      "epoch:11 step:10621 [D loss: 0.187875, acc.: 67.19%] [G loss: 0.515539]\n",
      "epoch:11 step:10622 [D loss: 0.218616, acc.: 66.41%] [G loss: 0.555081]\n",
      "epoch:11 step:10623 [D loss: 0.294118, acc.: 47.66%] [G loss: 0.493372]\n",
      "epoch:11 step:10624 [D loss: 0.231229, acc.: 60.16%] [G loss: 0.469665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10625 [D loss: 0.196600, acc.: 71.09%] [G loss: 0.481932]\n",
      "epoch:11 step:10626 [D loss: 0.231350, acc.: 59.38%] [G loss: 0.453452]\n",
      "epoch:11 step:10627 [D loss: 0.210675, acc.: 64.84%] [G loss: 0.467796]\n",
      "epoch:11 step:10628 [D loss: 0.197764, acc.: 69.53%] [G loss: 0.507697]\n",
      "epoch:11 step:10629 [D loss: 0.201816, acc.: 74.22%] [G loss: 0.515778]\n",
      "epoch:11 step:10630 [D loss: 0.277038, acc.: 50.00%] [G loss: 0.430240]\n",
      "epoch:11 step:10631 [D loss: 0.233399, acc.: 62.50%] [G loss: 0.436860]\n",
      "epoch:11 step:10632 [D loss: 0.216335, acc.: 65.62%] [G loss: 0.480417]\n",
      "epoch:11 step:10633 [D loss: 0.228729, acc.: 61.72%] [G loss: 0.459642]\n",
      "epoch:11 step:10634 [D loss: 0.240571, acc.: 56.25%] [G loss: 0.459654]\n",
      "epoch:11 step:10635 [D loss: 0.190574, acc.: 69.53%] [G loss: 0.500829]\n",
      "epoch:11 step:10636 [D loss: 0.227323, acc.: 62.50%] [G loss: 0.419482]\n",
      "epoch:11 step:10637 [D loss: 0.212496, acc.: 64.06%] [G loss: 0.433847]\n",
      "epoch:11 step:10638 [D loss: 0.206374, acc.: 67.19%] [G loss: 0.459910]\n",
      "epoch:11 step:10639 [D loss: 0.214100, acc.: 66.41%] [G loss: 0.477896]\n",
      "epoch:11 step:10640 [D loss: 0.203727, acc.: 74.22%] [G loss: 0.484907]\n",
      "epoch:11 step:10641 [D loss: 0.235495, acc.: 57.03%] [G loss: 0.444367]\n",
      "epoch:11 step:10642 [D loss: 0.220275, acc.: 70.31%] [G loss: 0.470589]\n",
      "epoch:11 step:10643 [D loss: 0.212031, acc.: 66.41%] [G loss: 0.430420]\n",
      "epoch:11 step:10644 [D loss: 0.206498, acc.: 71.88%] [G loss: 0.469448]\n",
      "epoch:11 step:10645 [D loss: 0.251323, acc.: 58.59%] [G loss: 0.416307]\n",
      "epoch:11 step:10646 [D loss: 0.208214, acc.: 69.53%] [G loss: 0.471559]\n",
      "epoch:11 step:10647 [D loss: 0.222118, acc.: 65.62%] [G loss: 0.487507]\n",
      "epoch:11 step:10648 [D loss: 0.283672, acc.: 52.34%] [G loss: 0.395730]\n",
      "epoch:11 step:10649 [D loss: 0.247923, acc.: 53.91%] [G loss: 0.447848]\n",
      "epoch:11 step:10650 [D loss: 0.249179, acc.: 60.16%] [G loss: 0.471491]\n",
      "epoch:11 step:10651 [D loss: 0.223473, acc.: 66.41%] [G loss: 0.533345]\n",
      "epoch:11 step:10652 [D loss: 0.233972, acc.: 61.72%] [G loss: 0.519158]\n",
      "epoch:11 step:10653 [D loss: 0.198413, acc.: 69.53%] [G loss: 0.483848]\n",
      "epoch:11 step:10654 [D loss: 0.189874, acc.: 67.19%] [G loss: 0.566854]\n",
      "epoch:11 step:10655 [D loss: 0.301047, acc.: 49.22%] [G loss: 0.424846]\n",
      "epoch:11 step:10656 [D loss: 0.278979, acc.: 50.00%] [G loss: 0.451655]\n",
      "epoch:11 step:10657 [D loss: 0.195837, acc.: 73.44%] [G loss: 0.463052]\n",
      "epoch:11 step:10658 [D loss: 0.240024, acc.: 62.50%] [G loss: 0.454193]\n",
      "epoch:11 step:10659 [D loss: 0.217545, acc.: 64.84%] [G loss: 0.484414]\n",
      "epoch:11 step:10660 [D loss: 0.200577, acc.: 69.53%] [G loss: 0.485389]\n",
      "epoch:11 step:10661 [D loss: 0.183630, acc.: 75.00%] [G loss: 0.491474]\n",
      "epoch:11 step:10662 [D loss: 0.232010, acc.: 65.62%] [G loss: 0.433838]\n",
      "epoch:11 step:10663 [D loss: 0.242615, acc.: 60.16%] [G loss: 0.464021]\n",
      "epoch:11 step:10664 [D loss: 0.177713, acc.: 76.56%] [G loss: 0.509366]\n",
      "epoch:11 step:10665 [D loss: 0.205061, acc.: 67.19%] [G loss: 0.476910]\n",
      "epoch:11 step:10666 [D loss: 0.216406, acc.: 60.94%] [G loss: 0.483110]\n",
      "epoch:11 step:10667 [D loss: 0.204924, acc.: 65.62%] [G loss: 0.480166]\n",
      "epoch:11 step:10668 [D loss: 0.214330, acc.: 70.31%] [G loss: 0.474455]\n",
      "epoch:11 step:10669 [D loss: 0.222081, acc.: 62.50%] [G loss: 0.465194]\n",
      "epoch:11 step:10670 [D loss: 0.216074, acc.: 64.84%] [G loss: 0.420982]\n",
      "epoch:11 step:10671 [D loss: 0.207992, acc.: 66.41%] [G loss: 0.418646]\n",
      "epoch:11 step:10672 [D loss: 0.260030, acc.: 54.69%] [G loss: 0.394725]\n",
      "epoch:11 step:10673 [D loss: 0.213807, acc.: 67.19%] [G loss: 0.432521]\n",
      "epoch:11 step:10674 [D loss: 0.227158, acc.: 65.62%] [G loss: 0.449492]\n",
      "epoch:11 step:10675 [D loss: 0.208677, acc.: 72.66%] [G loss: 0.475728]\n",
      "epoch:11 step:10676 [D loss: 0.229387, acc.: 58.59%] [G loss: 0.444137]\n",
      "epoch:11 step:10677 [D loss: 0.220906, acc.: 64.06%] [G loss: 0.475995]\n",
      "epoch:11 step:10678 [D loss: 0.188228, acc.: 74.22%] [G loss: 0.461108]\n",
      "epoch:11 step:10679 [D loss: 0.225340, acc.: 64.06%] [G loss: 0.471876]\n",
      "epoch:11 step:10680 [D loss: 0.247702, acc.: 58.59%] [G loss: 0.459870]\n",
      "epoch:11 step:10681 [D loss: 0.222562, acc.: 66.41%] [G loss: 0.447799]\n",
      "epoch:11 step:10682 [D loss: 0.227157, acc.: 60.16%] [G loss: 0.482242]\n",
      "epoch:11 step:10683 [D loss: 0.243578, acc.: 58.59%] [G loss: 0.455179]\n",
      "epoch:11 step:10684 [D loss: 0.279090, acc.: 49.22%] [G loss: 0.394423]\n",
      "epoch:11 step:10685 [D loss: 0.219867, acc.: 61.72%] [G loss: 0.407731]\n",
      "epoch:11 step:10686 [D loss: 0.213116, acc.: 65.62%] [G loss: 0.422890]\n",
      "epoch:11 step:10687 [D loss: 0.223480, acc.: 59.38%] [G loss: 0.465274]\n",
      "epoch:11 step:10688 [D loss: 0.208154, acc.: 67.97%] [G loss: 0.446320]\n",
      "epoch:11 step:10689 [D loss: 0.219935, acc.: 62.50%] [G loss: 0.465414]\n",
      "epoch:11 step:10690 [D loss: 0.241270, acc.: 60.16%] [G loss: 0.431463]\n",
      "epoch:11 step:10691 [D loss: 0.207329, acc.: 70.31%] [G loss: 0.436818]\n",
      "epoch:11 step:10692 [D loss: 0.204924, acc.: 69.53%] [G loss: 0.444544]\n",
      "epoch:11 step:10693 [D loss: 0.222942, acc.: 65.62%] [G loss: 0.455227]\n",
      "epoch:11 step:10694 [D loss: 0.203721, acc.: 66.41%] [G loss: 0.444331]\n",
      "epoch:11 step:10695 [D loss: 0.221640, acc.: 66.41%] [G loss: 0.512534]\n",
      "epoch:11 step:10696 [D loss: 0.222744, acc.: 63.28%] [G loss: 0.504529]\n",
      "epoch:11 step:10697 [D loss: 0.238997, acc.: 56.25%] [G loss: 0.447041]\n",
      "epoch:11 step:10698 [D loss: 0.217715, acc.: 58.59%] [G loss: 0.440099]\n",
      "epoch:11 step:10699 [D loss: 0.220435, acc.: 63.28%] [G loss: 0.425692]\n",
      "epoch:11 step:10700 [D loss: 0.242103, acc.: 59.38%] [G loss: 0.412147]\n",
      "epoch:11 step:10701 [D loss: 0.239389, acc.: 60.94%] [G loss: 0.427792]\n",
      "epoch:11 step:10702 [D loss: 0.224749, acc.: 63.28%] [G loss: 0.450453]\n",
      "epoch:11 step:10703 [D loss: 0.251793, acc.: 57.81%] [G loss: 0.487334]\n",
      "epoch:11 step:10704 [D loss: 0.241102, acc.: 63.28%] [G loss: 0.469297]\n",
      "epoch:11 step:10705 [D loss: 0.194182, acc.: 69.53%] [G loss: 0.565531]\n",
      "epoch:11 step:10706 [D loss: 0.223401, acc.: 66.41%] [G loss: 0.511930]\n",
      "epoch:11 step:10707 [D loss: 0.277687, acc.: 50.00%] [G loss: 0.437365]\n",
      "epoch:11 step:10708 [D loss: 0.252499, acc.: 53.12%] [G loss: 0.436729]\n",
      "epoch:11 step:10709 [D loss: 0.205624, acc.: 71.09%] [G loss: 0.432811]\n",
      "epoch:11 step:10710 [D loss: 0.239411, acc.: 57.03%] [G loss: 0.431245]\n",
      "epoch:11 step:10711 [D loss: 0.246194, acc.: 59.38%] [G loss: 0.428911]\n",
      "epoch:11 step:10712 [D loss: 0.210753, acc.: 65.62%] [G loss: 0.494922]\n",
      "epoch:11 step:10713 [D loss: 0.215502, acc.: 64.84%] [G loss: 0.478401]\n",
      "epoch:11 step:10714 [D loss: 0.280491, acc.: 52.34%] [G loss: 0.490792]\n",
      "epoch:11 step:10715 [D loss: 0.241035, acc.: 58.59%] [G loss: 0.442521]\n",
      "epoch:11 step:10716 [D loss: 0.230881, acc.: 61.72%] [G loss: 0.440921]\n",
      "epoch:11 step:10717 [D loss: 0.236789, acc.: 62.50%] [G loss: 0.413304]\n",
      "epoch:11 step:10718 [D loss: 0.265866, acc.: 47.66%] [G loss: 0.389281]\n",
      "epoch:11 step:10719 [D loss: 0.232346, acc.: 54.69%] [G loss: 0.430854]\n",
      "epoch:11 step:10720 [D loss: 0.248651, acc.: 54.69%] [G loss: 0.432251]\n",
      "epoch:11 step:10721 [D loss: 0.224309, acc.: 62.50%] [G loss: 0.441885]\n",
      "epoch:11 step:10722 [D loss: 0.212336, acc.: 71.09%] [G loss: 0.509904]\n",
      "epoch:11 step:10723 [D loss: 0.195687, acc.: 73.44%] [G loss: 0.504857]\n",
      "epoch:11 step:10724 [D loss: 0.202886, acc.: 68.75%] [G loss: 0.501006]\n",
      "epoch:11 step:10725 [D loss: 0.249387, acc.: 57.81%] [G loss: 0.438095]\n",
      "epoch:11 step:10726 [D loss: 0.219173, acc.: 61.72%] [G loss: 0.463774]\n",
      "epoch:11 step:10727 [D loss: 0.248038, acc.: 57.03%] [G loss: 0.441052]\n",
      "epoch:11 step:10728 [D loss: 0.246566, acc.: 57.03%] [G loss: 0.440233]\n",
      "epoch:11 step:10729 [D loss: 0.249809, acc.: 53.12%] [G loss: 0.428121]\n",
      "epoch:11 step:10730 [D loss: 0.248505, acc.: 50.78%] [G loss: 0.438524]\n",
      "epoch:11 step:10731 [D loss: 0.224249, acc.: 68.75%] [G loss: 0.437809]\n",
      "epoch:11 step:10732 [D loss: 0.216851, acc.: 61.72%] [G loss: 0.435024]\n",
      "epoch:11 step:10733 [D loss: 0.206897, acc.: 68.75%] [G loss: 0.444592]\n",
      "epoch:11 step:10734 [D loss: 0.213029, acc.: 64.06%] [G loss: 0.433277]\n",
      "epoch:11 step:10735 [D loss: 0.220471, acc.: 67.19%] [G loss: 0.510677]\n",
      "epoch:11 step:10736 [D loss: 0.195879, acc.: 72.66%] [G loss: 0.515498]\n",
      "epoch:11 step:10737 [D loss: 0.212142, acc.: 67.97%] [G loss: 0.504133]\n",
      "epoch:11 step:10738 [D loss: 0.225227, acc.: 61.72%] [G loss: 0.461224]\n",
      "epoch:11 step:10739 [D loss: 0.234048, acc.: 60.16%] [G loss: 0.481145]\n",
      "epoch:11 step:10740 [D loss: 0.247327, acc.: 56.25%] [G loss: 0.408646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10741 [D loss: 0.221869, acc.: 60.94%] [G loss: 0.445100]\n",
      "epoch:11 step:10742 [D loss: 0.214264, acc.: 67.19%] [G loss: 0.443624]\n",
      "epoch:11 step:10743 [D loss: 0.200160, acc.: 67.97%] [G loss: 0.445641]\n",
      "epoch:11 step:10744 [D loss: 0.285627, acc.: 46.09%] [G loss: 0.428010]\n",
      "epoch:11 step:10745 [D loss: 0.239376, acc.: 54.69%] [G loss: 0.454745]\n",
      "epoch:11 step:10746 [D loss: 0.226146, acc.: 64.06%] [G loss: 0.445986]\n",
      "epoch:11 step:10747 [D loss: 0.245115, acc.: 56.25%] [G loss: 0.446713]\n",
      "epoch:11 step:10748 [D loss: 0.238494, acc.: 60.16%] [G loss: 0.481028]\n",
      "epoch:11 step:10749 [D loss: 0.242944, acc.: 56.25%] [G loss: 0.471057]\n",
      "epoch:11 step:10750 [D loss: 0.216697, acc.: 64.06%] [G loss: 0.429011]\n",
      "epoch:11 step:10751 [D loss: 0.266333, acc.: 56.25%] [G loss: 0.431556]\n",
      "epoch:11 step:10752 [D loss: 0.207331, acc.: 64.06%] [G loss: 0.492985]\n",
      "epoch:11 step:10753 [D loss: 0.221405, acc.: 60.94%] [G loss: 0.494259]\n",
      "epoch:11 step:10754 [D loss: 0.219764, acc.: 64.84%] [G loss: 0.466459]\n",
      "epoch:11 step:10755 [D loss: 0.223990, acc.: 59.38%] [G loss: 0.469298]\n",
      "epoch:11 step:10756 [D loss: 0.232160, acc.: 60.16%] [G loss: 0.442624]\n",
      "epoch:11 step:10757 [D loss: 0.224317, acc.: 64.06%] [G loss: 0.419479]\n",
      "epoch:11 step:10758 [D loss: 0.197123, acc.: 70.31%] [G loss: 0.477711]\n",
      "epoch:11 step:10759 [D loss: 0.216287, acc.: 60.94%] [G loss: 0.482053]\n",
      "epoch:11 step:10760 [D loss: 0.171592, acc.: 78.91%] [G loss: 0.527749]\n",
      "epoch:11 step:10761 [D loss: 0.220803, acc.: 67.97%] [G loss: 0.482063]\n",
      "epoch:11 step:10762 [D loss: 0.251377, acc.: 55.47%] [G loss: 0.457840]\n",
      "epoch:11 step:10763 [D loss: 0.241777, acc.: 62.50%] [G loss: 0.457939]\n",
      "epoch:11 step:10764 [D loss: 0.219683, acc.: 65.62%] [G loss: 0.514004]\n",
      "epoch:11 step:10765 [D loss: 0.285984, acc.: 54.69%] [G loss: 0.442607]\n",
      "epoch:11 step:10766 [D loss: 0.237371, acc.: 64.06%] [G loss: 0.448707]\n",
      "epoch:11 step:10767 [D loss: 0.211442, acc.: 65.62%] [G loss: 0.453447]\n",
      "epoch:11 step:10768 [D loss: 0.226830, acc.: 63.28%] [G loss: 0.424789]\n",
      "epoch:11 step:10769 [D loss: 0.236067, acc.: 58.59%] [G loss: 0.448673]\n",
      "epoch:11 step:10770 [D loss: 0.236987, acc.: 65.62%] [G loss: 0.394365]\n",
      "epoch:11 step:10771 [D loss: 0.234047, acc.: 65.62%] [G loss: 0.387156]\n",
      "epoch:11 step:10772 [D loss: 0.237343, acc.: 62.50%] [G loss: 0.461383]\n",
      "epoch:11 step:10773 [D loss: 0.235954, acc.: 60.94%] [G loss: 0.453536]\n",
      "epoch:11 step:10774 [D loss: 0.232984, acc.: 60.94%] [G loss: 0.425122]\n",
      "epoch:11 step:10775 [D loss: 0.222044, acc.: 67.19%] [G loss: 0.499971]\n",
      "epoch:11 step:10776 [D loss: 0.218284, acc.: 59.38%] [G loss: 0.462153]\n",
      "epoch:11 step:10777 [D loss: 0.218458, acc.: 67.97%] [G loss: 0.499509]\n",
      "epoch:11 step:10778 [D loss: 0.204198, acc.: 69.53%] [G loss: 0.531094]\n",
      "epoch:11 step:10779 [D loss: 0.193894, acc.: 66.41%] [G loss: 0.526191]\n",
      "epoch:11 step:10780 [D loss: 0.258809, acc.: 56.25%] [G loss: 0.457289]\n",
      "epoch:11 step:10781 [D loss: 0.210809, acc.: 68.75%] [G loss: 0.467882]\n",
      "epoch:11 step:10782 [D loss: 0.202713, acc.: 67.97%] [G loss: 0.501688]\n",
      "epoch:11 step:10783 [D loss: 0.241876, acc.: 60.16%] [G loss: 0.478349]\n",
      "epoch:11 step:10784 [D loss: 0.290088, acc.: 53.12%] [G loss: 0.405974]\n",
      "epoch:11 step:10785 [D loss: 0.234410, acc.: 57.03%] [G loss: 0.447340]\n",
      "epoch:11 step:10786 [D loss: 0.235856, acc.: 60.94%] [G loss: 0.414800]\n",
      "epoch:11 step:10787 [D loss: 0.245916, acc.: 59.38%] [G loss: 0.417808]\n",
      "epoch:11 step:10788 [D loss: 0.180765, acc.: 75.00%] [G loss: 0.456416]\n",
      "epoch:11 step:10789 [D loss: 0.260284, acc.: 51.56%] [G loss: 0.435115]\n",
      "epoch:11 step:10790 [D loss: 0.240199, acc.: 57.81%] [G loss: 0.433281]\n",
      "epoch:11 step:10791 [D loss: 0.211822, acc.: 71.09%] [G loss: 0.439995]\n",
      "epoch:11 step:10792 [D loss: 0.208061, acc.: 69.53%] [G loss: 0.489892]\n",
      "epoch:11 step:10793 [D loss: 0.252549, acc.: 58.59%] [G loss: 0.488689]\n",
      "epoch:11 step:10794 [D loss: 0.242795, acc.: 55.47%] [G loss: 0.444848]\n",
      "epoch:11 step:10795 [D loss: 0.194690, acc.: 72.66%] [G loss: 0.477611]\n",
      "epoch:11 step:10796 [D loss: 0.241539, acc.: 56.25%] [G loss: 0.412489]\n",
      "epoch:11 step:10797 [D loss: 0.236959, acc.: 60.94%] [G loss: 0.407728]\n",
      "epoch:11 step:10798 [D loss: 0.208205, acc.: 64.84%] [G loss: 0.448723]\n",
      "epoch:11 step:10799 [D loss: 0.242976, acc.: 62.50%] [G loss: 0.411875]\n",
      "epoch:11 step:10800 [D loss: 0.212128, acc.: 62.50%] [G loss: 0.442589]\n",
      "epoch:11 step:10801 [D loss: 0.239078, acc.: 64.06%] [G loss: 0.464901]\n",
      "epoch:11 step:10802 [D loss: 0.201923, acc.: 70.31%] [G loss: 0.529630]\n",
      "epoch:11 step:10803 [D loss: 0.242658, acc.: 58.59%] [G loss: 0.501156]\n",
      "epoch:11 step:10804 [D loss: 0.215435, acc.: 67.97%] [G loss: 0.483392]\n",
      "epoch:11 step:10805 [D loss: 0.210088, acc.: 67.19%] [G loss: 0.496035]\n",
      "epoch:11 step:10806 [D loss: 0.170898, acc.: 75.00%] [G loss: 0.545150]\n",
      "epoch:11 step:10807 [D loss: 0.297294, acc.: 47.66%] [G loss: 0.410807]\n",
      "epoch:11 step:10808 [D loss: 0.282999, acc.: 46.88%] [G loss: 0.408585]\n",
      "epoch:11 step:10809 [D loss: 0.225779, acc.: 57.03%] [G loss: 0.492492]\n",
      "epoch:11 step:10810 [D loss: 0.201001, acc.: 67.97%] [G loss: 0.447684]\n",
      "epoch:11 step:10811 [D loss: 0.192892, acc.: 71.88%] [G loss: 0.468915]\n",
      "epoch:11 step:10812 [D loss: 0.220707, acc.: 63.28%] [G loss: 0.511481]\n",
      "epoch:11 step:10813 [D loss: 0.227063, acc.: 64.84%] [G loss: 0.477879]\n",
      "epoch:11 step:10814 [D loss: 0.215258, acc.: 66.41%] [G loss: 0.501622]\n",
      "epoch:11 step:10815 [D loss: 0.190007, acc.: 71.09%] [G loss: 0.477352]\n",
      "epoch:11 step:10816 [D loss: 0.248237, acc.: 56.25%] [G loss: 0.475021]\n",
      "epoch:11 step:10817 [D loss: 0.241237, acc.: 53.12%] [G loss: 0.440326]\n",
      "epoch:11 step:10818 [D loss: 0.238582, acc.: 55.47%] [G loss: 0.418994]\n",
      "epoch:11 step:10819 [D loss: 0.217774, acc.: 60.16%] [G loss: 0.449762]\n",
      "epoch:11 step:10820 [D loss: 0.223331, acc.: 68.75%] [G loss: 0.453882]\n",
      "epoch:11 step:10821 [D loss: 0.201392, acc.: 67.97%] [G loss: 0.446500]\n",
      "epoch:11 step:10822 [D loss: 0.197805, acc.: 71.88%] [G loss: 0.478128]\n",
      "epoch:11 step:10823 [D loss: 0.212908, acc.: 62.50%] [G loss: 0.485852]\n",
      "epoch:11 step:10824 [D loss: 0.265150, acc.: 53.12%] [G loss: 0.431335]\n",
      "epoch:11 step:10825 [D loss: 0.260150, acc.: 59.38%] [G loss: 0.409669]\n",
      "epoch:11 step:10826 [D loss: 0.193403, acc.: 72.66%] [G loss: 0.463517]\n",
      "epoch:11 step:10827 [D loss: 0.194015, acc.: 73.44%] [G loss: 0.477081]\n",
      "epoch:11 step:10828 [D loss: 0.218833, acc.: 63.28%] [G loss: 0.446336]\n",
      "epoch:11 step:10829 [D loss: 0.242769, acc.: 63.28%] [G loss: 0.486460]\n",
      "epoch:11 step:10830 [D loss: 0.221956, acc.: 59.38%] [G loss: 0.458054]\n",
      "epoch:11 step:10831 [D loss: 0.260917, acc.: 56.25%] [G loss: 0.415449]\n",
      "epoch:11 step:10832 [D loss: 0.211010, acc.: 70.31%] [G loss: 0.461849]\n",
      "epoch:11 step:10833 [D loss: 0.213690, acc.: 65.62%] [G loss: 0.488552]\n",
      "epoch:11 step:10834 [D loss: 0.230676, acc.: 63.28%] [G loss: 0.472295]\n",
      "epoch:11 step:10835 [D loss: 0.257961, acc.: 50.78%] [G loss: 0.474187]\n",
      "epoch:11 step:10836 [D loss: 0.248316, acc.: 60.94%] [G loss: 0.425574]\n",
      "epoch:11 step:10837 [D loss: 0.203464, acc.: 71.88%] [G loss: 0.493643]\n",
      "epoch:11 step:10838 [D loss: 0.242050, acc.: 61.72%] [G loss: 0.412207]\n",
      "epoch:11 step:10839 [D loss: 0.223938, acc.: 63.28%] [G loss: 0.447200]\n",
      "epoch:11 step:10840 [D loss: 0.215026, acc.: 63.28%] [G loss: 0.453941]\n",
      "epoch:11 step:10841 [D loss: 0.202762, acc.: 66.41%] [G loss: 0.472152]\n",
      "epoch:11 step:10842 [D loss: 0.240553, acc.: 60.16%] [G loss: 0.431672]\n",
      "epoch:11 step:10843 [D loss: 0.200677, acc.: 67.97%] [G loss: 0.460037]\n",
      "epoch:11 step:10844 [D loss: 0.238284, acc.: 61.72%] [G loss: 0.445591]\n",
      "epoch:11 step:10845 [D loss: 0.242204, acc.: 63.28%] [G loss: 0.408159]\n",
      "epoch:11 step:10846 [D loss: 0.236496, acc.: 59.38%] [G loss: 0.439719]\n",
      "epoch:11 step:10847 [D loss: 0.248051, acc.: 55.47%] [G loss: 0.465865]\n",
      "epoch:11 step:10848 [D loss: 0.238896, acc.: 60.94%] [G loss: 0.429930]\n",
      "epoch:11 step:10849 [D loss: 0.239152, acc.: 54.69%] [G loss: 0.473915]\n",
      "epoch:11 step:10850 [D loss: 0.228287, acc.: 64.06%] [G loss: 0.444867]\n",
      "epoch:11 step:10851 [D loss: 0.251836, acc.: 55.47%] [G loss: 0.483566]\n",
      "epoch:11 step:10852 [D loss: 0.250953, acc.: 60.94%] [G loss: 0.485982]\n",
      "epoch:11 step:10853 [D loss: 0.215226, acc.: 64.06%] [G loss: 0.493660]\n",
      "epoch:11 step:10854 [D loss: 0.229764, acc.: 63.28%] [G loss: 0.470863]\n",
      "epoch:11 step:10855 [D loss: 0.209208, acc.: 65.62%] [G loss: 0.482269]\n",
      "epoch:11 step:10856 [D loss: 0.205487, acc.: 67.19%] [G loss: 0.488533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10857 [D loss: 0.193366, acc.: 72.66%] [G loss: 0.489582]\n",
      "epoch:11 step:10858 [D loss: 0.207497, acc.: 64.06%] [G loss: 0.514818]\n",
      "epoch:11 step:10859 [D loss: 0.188721, acc.: 69.53%] [G loss: 0.494869]\n",
      "epoch:11 step:10860 [D loss: 0.269578, acc.: 53.91%] [G loss: 0.425291]\n",
      "epoch:11 step:10861 [D loss: 0.216291, acc.: 64.84%] [G loss: 0.490546]\n",
      "epoch:11 step:10862 [D loss: 0.186506, acc.: 73.44%] [G loss: 0.496247]\n",
      "epoch:11 step:10863 [D loss: 0.214710, acc.: 69.53%] [G loss: 0.452746]\n",
      "epoch:11 step:10864 [D loss: 0.205972, acc.: 63.28%] [G loss: 0.453411]\n",
      "epoch:11 step:10865 [D loss: 0.201441, acc.: 67.19%] [G loss: 0.489480]\n",
      "epoch:11 step:10866 [D loss: 0.269943, acc.: 50.78%] [G loss: 0.460404]\n",
      "epoch:11 step:10867 [D loss: 0.245684, acc.: 58.59%] [G loss: 0.413061]\n",
      "epoch:11 step:10868 [D loss: 0.223607, acc.: 64.06%] [G loss: 0.437081]\n",
      "epoch:11 step:10869 [D loss: 0.240413, acc.: 55.47%] [G loss: 0.442595]\n",
      "epoch:11 step:10870 [D loss: 0.208062, acc.: 67.19%] [G loss: 0.511396]\n",
      "epoch:11 step:10871 [D loss: 0.212020, acc.: 67.97%] [G loss: 0.480344]\n",
      "epoch:11 step:10872 [D loss: 0.259080, acc.: 57.03%] [G loss: 0.466943]\n",
      "epoch:11 step:10873 [D loss: 0.256905, acc.: 60.16%] [G loss: 0.470408]\n",
      "epoch:11 step:10874 [D loss: 0.219281, acc.: 64.84%] [G loss: 0.413121]\n",
      "epoch:11 step:10875 [D loss: 0.198584, acc.: 71.88%] [G loss: 0.509991]\n",
      "epoch:11 step:10876 [D loss: 0.256087, acc.: 56.25%] [G loss: 0.434207]\n",
      "epoch:11 step:10877 [D loss: 0.196520, acc.: 72.66%] [G loss: 0.460589]\n",
      "epoch:11 step:10878 [D loss: 0.224360, acc.: 64.84%] [G loss: 0.429628]\n",
      "epoch:11 step:10879 [D loss: 0.212267, acc.: 72.66%] [G loss: 0.481414]\n",
      "epoch:11 step:10880 [D loss: 0.264670, acc.: 50.78%] [G loss: 0.436493]\n",
      "epoch:11 step:10881 [D loss: 0.170487, acc.: 78.12%] [G loss: 0.498887]\n",
      "epoch:11 step:10882 [D loss: 0.214726, acc.: 67.19%] [G loss: 0.492644]\n",
      "epoch:11 step:10883 [D loss: 0.238706, acc.: 57.81%] [G loss: 0.426209]\n",
      "epoch:11 step:10884 [D loss: 0.244898, acc.: 60.94%] [G loss: 0.434841]\n",
      "epoch:11 step:10885 [D loss: 0.236368, acc.: 55.47%] [G loss: 0.419497]\n",
      "epoch:11 step:10886 [D loss: 0.251866, acc.: 57.03%] [G loss: 0.401452]\n",
      "epoch:11 step:10887 [D loss: 0.242192, acc.: 58.59%] [G loss: 0.405484]\n",
      "epoch:11 step:10888 [D loss: 0.226584, acc.: 60.16%] [G loss: 0.499542]\n",
      "epoch:11 step:10889 [D loss: 0.204370, acc.: 67.19%] [G loss: 0.509038]\n",
      "epoch:11 step:10890 [D loss: 0.210564, acc.: 65.62%] [G loss: 0.488545]\n",
      "epoch:11 step:10891 [D loss: 0.243748, acc.: 59.38%] [G loss: 0.451911]\n",
      "epoch:11 step:10892 [D loss: 0.211153, acc.: 67.97%] [G loss: 0.430667]\n",
      "epoch:11 step:10893 [D loss: 0.234905, acc.: 59.38%] [G loss: 0.420766]\n",
      "epoch:11 step:10894 [D loss: 0.246884, acc.: 57.03%] [G loss: 0.418864]\n",
      "epoch:11 step:10895 [D loss: 0.222047, acc.: 64.84%] [G loss: 0.414624]\n",
      "epoch:11 step:10896 [D loss: 0.189236, acc.: 72.66%] [G loss: 0.437605]\n",
      "epoch:11 step:10897 [D loss: 0.287384, acc.: 51.56%] [G loss: 0.466738]\n",
      "epoch:11 step:10898 [D loss: 0.214676, acc.: 67.97%] [G loss: 0.496393]\n",
      "epoch:11 step:10899 [D loss: 0.194383, acc.: 72.66%] [G loss: 0.486938]\n",
      "epoch:11 step:10900 [D loss: 0.251597, acc.: 57.03%] [G loss: 0.447953]\n",
      "epoch:11 step:10901 [D loss: 0.249279, acc.: 53.12%] [G loss: 0.472564]\n",
      "epoch:11 step:10902 [D loss: 0.229457, acc.: 60.16%] [G loss: 0.446143]\n",
      "epoch:11 step:10903 [D loss: 0.236759, acc.: 60.16%] [G loss: 0.443157]\n",
      "epoch:11 step:10904 [D loss: 0.247657, acc.: 56.25%] [G loss: 0.438790]\n",
      "epoch:11 step:10905 [D loss: 0.229889, acc.: 63.28%] [G loss: 0.455630]\n",
      "epoch:11 step:10906 [D loss: 0.221328, acc.: 69.53%] [G loss: 0.480847]\n",
      "epoch:11 step:10907 [D loss: 0.221180, acc.: 67.19%] [G loss: 0.460974]\n",
      "epoch:11 step:10908 [D loss: 0.229845, acc.: 67.97%] [G loss: 0.406718]\n",
      "epoch:11 step:10909 [D loss: 0.242966, acc.: 55.47%] [G loss: 0.425931]\n",
      "epoch:11 step:10910 [D loss: 0.223827, acc.: 63.28%] [G loss: 0.442966]\n",
      "epoch:11 step:10911 [D loss: 0.231163, acc.: 58.59%] [G loss: 0.452934]\n",
      "epoch:11 step:10912 [D loss: 0.203318, acc.: 64.84%] [G loss: 0.444080]\n",
      "epoch:11 step:10913 [D loss: 0.219726, acc.: 63.28%] [G loss: 0.428230]\n",
      "epoch:11 step:10914 [D loss: 0.230059, acc.: 57.81%] [G loss: 0.451863]\n",
      "epoch:11 step:10915 [D loss: 0.232828, acc.: 60.16%] [G loss: 0.447308]\n",
      "epoch:11 step:10916 [D loss: 0.213809, acc.: 63.28%] [G loss: 0.417211]\n",
      "epoch:11 step:10917 [D loss: 0.253997, acc.: 57.81%] [G loss: 0.429770]\n",
      "epoch:11 step:10918 [D loss: 0.232903, acc.: 60.16%] [G loss: 0.461151]\n",
      "epoch:11 step:10919 [D loss: 0.216598, acc.: 67.19%] [G loss: 0.456970]\n",
      "epoch:11 step:10920 [D loss: 0.177870, acc.: 76.56%] [G loss: 0.458956]\n",
      "epoch:11 step:10921 [D loss: 0.230599, acc.: 61.72%] [G loss: 0.470891]\n",
      "epoch:11 step:10922 [D loss: 0.256565, acc.: 57.03%] [G loss: 0.436988]\n",
      "epoch:11 step:10923 [D loss: 0.237734, acc.: 64.06%] [G loss: 0.424099]\n",
      "epoch:11 step:10924 [D loss: 0.207354, acc.: 67.19%] [G loss: 0.445703]\n",
      "epoch:11 step:10925 [D loss: 0.215620, acc.: 62.50%] [G loss: 0.491732]\n",
      "epoch:11 step:10926 [D loss: 0.255492, acc.: 59.38%] [G loss: 0.425474]\n",
      "epoch:11 step:10927 [D loss: 0.211989, acc.: 69.53%] [G loss: 0.414015]\n",
      "epoch:11 step:10928 [D loss: 0.227327, acc.: 60.16%] [G loss: 0.444281]\n",
      "epoch:11 step:10929 [D loss: 0.226164, acc.: 63.28%] [G loss: 0.446825]\n",
      "epoch:11 step:10930 [D loss: 0.205949, acc.: 67.19%] [G loss: 0.415055]\n",
      "epoch:11 step:10931 [D loss: 0.214723, acc.: 67.19%] [G loss: 0.455579]\n",
      "epoch:11 step:10932 [D loss: 0.242802, acc.: 59.38%] [G loss: 0.506741]\n",
      "epoch:11 step:10933 [D loss: 0.245047, acc.: 64.06%] [G loss: 0.440669]\n",
      "epoch:11 step:10934 [D loss: 0.200094, acc.: 65.62%] [G loss: 0.479824]\n",
      "epoch:11 step:10935 [D loss: 0.242827, acc.: 61.72%] [G loss: 0.424988]\n",
      "epoch:11 step:10936 [D loss: 0.195552, acc.: 71.88%] [G loss: 0.454935]\n",
      "epoch:11 step:10937 [D loss: 0.226500, acc.: 63.28%] [G loss: 0.430790]\n",
      "epoch:11 step:10938 [D loss: 0.212543, acc.: 64.84%] [G loss: 0.470478]\n",
      "epoch:11 step:10939 [D loss: 0.211982, acc.: 64.84%] [G loss: 0.496897]\n",
      "epoch:11 step:10940 [D loss: 0.197732, acc.: 69.53%] [G loss: 0.489576]\n",
      "epoch:11 step:10941 [D loss: 0.204692, acc.: 68.75%] [G loss: 0.488697]\n",
      "epoch:11 step:10942 [D loss: 0.200547, acc.: 71.88%] [G loss: 0.510938]\n",
      "epoch:11 step:10943 [D loss: 0.241527, acc.: 57.03%] [G loss: 0.438633]\n",
      "epoch:11 step:10944 [D loss: 0.226359, acc.: 66.41%] [G loss: 0.467169]\n",
      "epoch:11 step:10945 [D loss: 0.226110, acc.: 59.38%] [G loss: 0.440802]\n",
      "epoch:11 step:10946 [D loss: 0.223658, acc.: 66.41%] [G loss: 0.467767]\n",
      "epoch:11 step:10947 [D loss: 0.216487, acc.: 64.84%] [G loss: 0.481652]\n",
      "epoch:11 step:10948 [D loss: 0.223294, acc.: 65.62%] [G loss: 0.489158]\n",
      "epoch:11 step:10949 [D loss: 0.178623, acc.: 73.44%] [G loss: 0.557566]\n",
      "epoch:11 step:10950 [D loss: 0.233830, acc.: 61.72%] [G loss: 0.478725]\n",
      "epoch:11 step:10951 [D loss: 0.230832, acc.: 57.81%] [G loss: 0.424113]\n",
      "epoch:11 step:10952 [D loss: 0.210387, acc.: 64.06%] [G loss: 0.468030]\n",
      "epoch:11 step:10953 [D loss: 0.231398, acc.: 60.16%] [G loss: 0.482054]\n",
      "epoch:11 step:10954 [D loss: 0.212933, acc.: 70.31%] [G loss: 0.490903]\n",
      "epoch:11 step:10955 [D loss: 0.191783, acc.: 71.88%] [G loss: 0.488327]\n",
      "epoch:11 step:10956 [D loss: 0.198997, acc.: 64.84%] [G loss: 0.533107]\n",
      "epoch:11 step:10957 [D loss: 0.211628, acc.: 67.19%] [G loss: 0.491820]\n",
      "epoch:11 step:10958 [D loss: 0.239094, acc.: 65.62%] [G loss: 0.466009]\n",
      "epoch:11 step:10959 [D loss: 0.231954, acc.: 60.16%] [G loss: 0.455207]\n",
      "epoch:11 step:10960 [D loss: 0.228059, acc.: 65.62%] [G loss: 0.466590]\n",
      "epoch:11 step:10961 [D loss: 0.221142, acc.: 64.06%] [G loss: 0.507802]\n",
      "epoch:11 step:10962 [D loss: 0.258734, acc.: 58.59%] [G loss: 0.465167]\n",
      "epoch:11 step:10963 [D loss: 0.242700, acc.: 58.59%] [G loss: 0.436491]\n",
      "epoch:11 step:10964 [D loss: 0.231243, acc.: 60.16%] [G loss: 0.439229]\n",
      "epoch:11 step:10965 [D loss: 0.251847, acc.: 58.59%] [G loss: 0.448488]\n",
      "epoch:11 step:10966 [D loss: 0.208847, acc.: 64.06%] [G loss: 0.456747]\n",
      "epoch:11 step:10967 [D loss: 0.202301, acc.: 67.19%] [G loss: 0.434320]\n",
      "epoch:11 step:10968 [D loss: 0.228625, acc.: 64.84%] [G loss: 0.483213]\n",
      "epoch:11 step:10969 [D loss: 0.197969, acc.: 71.88%] [G loss: 0.475070]\n",
      "epoch:11 step:10970 [D loss: 0.212642, acc.: 64.06%] [G loss: 0.461487]\n",
      "epoch:11 step:10971 [D loss: 0.216536, acc.: 65.62%] [G loss: 0.449586]\n",
      "epoch:11 step:10972 [D loss: 0.224489, acc.: 66.41%] [G loss: 0.459365]\n",
      "epoch:11 step:10973 [D loss: 0.188116, acc.: 75.00%] [G loss: 0.484345]\n",
      "epoch:11 step:10974 [D loss: 0.262255, acc.: 54.69%] [G loss: 0.446764]\n",
      "epoch:11 step:10975 [D loss: 0.249536, acc.: 60.94%] [G loss: 0.459462]\n",
      "epoch:11 step:10976 [D loss: 0.213783, acc.: 68.75%] [G loss: 0.441495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10977 [D loss: 0.229434, acc.: 65.62%] [G loss: 0.473976]\n",
      "epoch:11 step:10978 [D loss: 0.228791, acc.: 64.06%] [G loss: 0.412486]\n",
      "epoch:11 step:10979 [D loss: 0.247142, acc.: 58.59%] [G loss: 0.398099]\n",
      "epoch:11 step:10980 [D loss: 0.228135, acc.: 64.06%] [G loss: 0.511528]\n",
      "epoch:11 step:10981 [D loss: 0.216745, acc.: 63.28%] [G loss: 0.485826]\n",
      "epoch:11 step:10982 [D loss: 0.296424, acc.: 47.66%] [G loss: 0.440147]\n",
      "epoch:11 step:10983 [D loss: 0.227297, acc.: 64.84%] [G loss: 0.448993]\n",
      "epoch:11 step:10984 [D loss: 0.193932, acc.: 70.31%] [G loss: 0.444950]\n",
      "epoch:11 step:10985 [D loss: 0.233440, acc.: 62.50%] [G loss: 0.438661]\n",
      "epoch:11 step:10986 [D loss: 0.222410, acc.: 67.19%] [G loss: 0.434586]\n",
      "epoch:11 step:10987 [D loss: 0.239699, acc.: 61.72%] [G loss: 0.452854]\n",
      "epoch:11 step:10988 [D loss: 0.199919, acc.: 70.31%] [G loss: 0.494292]\n",
      "epoch:11 step:10989 [D loss: 0.230299, acc.: 57.03%] [G loss: 0.456542]\n",
      "epoch:11 step:10990 [D loss: 0.235974, acc.: 60.16%] [G loss: 0.443950]\n",
      "epoch:11 step:10991 [D loss: 0.230810, acc.: 58.59%] [G loss: 0.408398]\n",
      "epoch:11 step:10992 [D loss: 0.216749, acc.: 66.41%] [G loss: 0.418826]\n",
      "epoch:11 step:10993 [D loss: 0.243896, acc.: 57.81%] [G loss: 0.417742]\n",
      "epoch:11 step:10994 [D loss: 0.238734, acc.: 60.16%] [G loss: 0.425805]\n",
      "epoch:11 step:10995 [D loss: 0.216863, acc.: 66.41%] [G loss: 0.448290]\n",
      "epoch:11 step:10996 [D loss: 0.235918, acc.: 60.16%] [G loss: 0.481487]\n",
      "epoch:11 step:10997 [D loss: 0.210833, acc.: 67.19%] [G loss: 0.456781]\n",
      "epoch:11 step:10998 [D loss: 0.234104, acc.: 64.06%] [G loss: 0.501254]\n",
      "epoch:11 step:10999 [D loss: 0.215708, acc.: 68.75%] [G loss: 0.502296]\n",
      "epoch:11 step:11000 [D loss: 0.207700, acc.: 69.53%] [G loss: 0.520310]\n",
      "epoch:11 step:11001 [D loss: 0.215246, acc.: 63.28%] [G loss: 0.473429]\n",
      "epoch:11 step:11002 [D loss: 0.225844, acc.: 64.84%] [G loss: 0.482072]\n",
      "epoch:11 step:11003 [D loss: 0.264821, acc.: 49.22%] [G loss: 0.428252]\n",
      "epoch:11 step:11004 [D loss: 0.220987, acc.: 61.72%] [G loss: 0.436772]\n",
      "epoch:11 step:11005 [D loss: 0.230226, acc.: 63.28%] [G loss: 0.465152]\n",
      "epoch:11 step:11006 [D loss: 0.200360, acc.: 75.00%] [G loss: 0.459630]\n",
      "epoch:11 step:11007 [D loss: 0.209756, acc.: 67.19%] [G loss: 0.466462]\n",
      "epoch:11 step:11008 [D loss: 0.207216, acc.: 66.41%] [G loss: 0.481279]\n",
      "epoch:11 step:11009 [D loss: 0.240451, acc.: 56.25%] [G loss: 0.432282]\n",
      "epoch:11 step:11010 [D loss: 0.238742, acc.: 57.81%] [G loss: 0.421297]\n",
      "epoch:11 step:11011 [D loss: 0.247540, acc.: 53.12%] [G loss: 0.417315]\n",
      "epoch:11 step:11012 [D loss: 0.210071, acc.: 67.97%] [G loss: 0.441919]\n",
      "epoch:11 step:11013 [D loss: 0.209191, acc.: 61.72%] [G loss: 0.445422]\n",
      "epoch:11 step:11014 [D loss: 0.193362, acc.: 74.22%] [G loss: 0.443953]\n",
      "epoch:11 step:11015 [D loss: 0.208220, acc.: 63.28%] [G loss: 0.459644]\n",
      "epoch:11 step:11016 [D loss: 0.197242, acc.: 68.75%] [G loss: 0.494045]\n",
      "epoch:11 step:11017 [D loss: 0.234388, acc.: 57.81%] [G loss: 0.483462]\n",
      "epoch:11 step:11018 [D loss: 0.234897, acc.: 63.28%] [G loss: 0.473132]\n",
      "epoch:11 step:11019 [D loss: 0.226877, acc.: 64.06%] [G loss: 0.476461]\n",
      "epoch:11 step:11020 [D loss: 0.216478, acc.: 68.75%] [G loss: 0.480842]\n",
      "epoch:11 step:11021 [D loss: 0.233774, acc.: 62.50%] [G loss: 0.459815]\n",
      "epoch:11 step:11022 [D loss: 0.224143, acc.: 60.16%] [G loss: 0.412350]\n",
      "epoch:11 step:11023 [D loss: 0.225078, acc.: 65.62%] [G loss: 0.461672]\n",
      "epoch:11 step:11024 [D loss: 0.217236, acc.: 66.41%] [G loss: 0.425952]\n",
      "epoch:11 step:11025 [D loss: 0.213900, acc.: 69.53%] [G loss: 0.488290]\n",
      "epoch:11 step:11026 [D loss: 0.206286, acc.: 66.41%] [G loss: 0.496938]\n",
      "epoch:11 step:11027 [D loss: 0.232027, acc.: 64.06%] [G loss: 0.498572]\n",
      "epoch:11 step:11028 [D loss: 0.242474, acc.: 59.38%] [G loss: 0.463552]\n",
      "epoch:11 step:11029 [D loss: 0.268431, acc.: 50.00%] [G loss: 0.441097]\n",
      "epoch:11 step:11030 [D loss: 0.235254, acc.: 55.47%] [G loss: 0.423723]\n",
      "epoch:11 step:11031 [D loss: 0.233301, acc.: 59.38%] [G loss: 0.430881]\n",
      "epoch:11 step:11032 [D loss: 0.195923, acc.: 71.09%] [G loss: 0.472248]\n",
      "epoch:11 step:11033 [D loss: 0.226338, acc.: 62.50%] [G loss: 0.506460]\n",
      "epoch:11 step:11034 [D loss: 0.246018, acc.: 59.38%] [G loss: 0.425661]\n",
      "epoch:11 step:11035 [D loss: 0.213238, acc.: 64.84%] [G loss: 0.446270]\n",
      "epoch:11 step:11036 [D loss: 0.238023, acc.: 53.12%] [G loss: 0.402139]\n",
      "epoch:11 step:11037 [D loss: 0.205247, acc.: 67.97%] [G loss: 0.448133]\n",
      "epoch:11 step:11038 [D loss: 0.224625, acc.: 69.53%] [G loss: 0.471081]\n",
      "epoch:11 step:11039 [D loss: 0.207146, acc.: 72.66%] [G loss: 0.443453]\n",
      "epoch:11 step:11040 [D loss: 0.214391, acc.: 69.53%] [G loss: 0.421035]\n",
      "epoch:11 step:11041 [D loss: 0.219562, acc.: 63.28%] [G loss: 0.437528]\n",
      "epoch:11 step:11042 [D loss: 0.254645, acc.: 54.69%] [G loss: 0.424806]\n",
      "epoch:11 step:11043 [D loss: 0.180521, acc.: 77.34%] [G loss: 0.462167]\n",
      "epoch:11 step:11044 [D loss: 0.225963, acc.: 62.50%] [G loss: 0.480216]\n",
      "epoch:11 step:11045 [D loss: 0.244032, acc.: 51.56%] [G loss: 0.424662]\n",
      "epoch:11 step:11046 [D loss: 0.271782, acc.: 56.25%] [G loss: 0.413800]\n",
      "epoch:11 step:11047 [D loss: 0.260750, acc.: 53.91%] [G loss: 0.423013]\n",
      "epoch:11 step:11048 [D loss: 0.222235, acc.: 64.06%] [G loss: 0.417726]\n",
      "epoch:11 step:11049 [D loss: 0.211743, acc.: 66.41%] [G loss: 0.473513]\n",
      "epoch:11 step:11050 [D loss: 0.229648, acc.: 57.81%] [G loss: 0.457846]\n",
      "epoch:11 step:11051 [D loss: 0.227139, acc.: 66.41%] [G loss: 0.478621]\n",
      "epoch:11 step:11052 [D loss: 0.212586, acc.: 64.84%] [G loss: 0.457481]\n",
      "epoch:11 step:11053 [D loss: 0.234385, acc.: 61.72%] [G loss: 0.441919]\n",
      "epoch:11 step:11054 [D loss: 0.193435, acc.: 70.31%] [G loss: 0.485432]\n",
      "epoch:11 step:11055 [D loss: 0.249460, acc.: 60.94%] [G loss: 0.450556]\n",
      "epoch:11 step:11056 [D loss: 0.236156, acc.: 62.50%] [G loss: 0.440962]\n",
      "epoch:11 step:11057 [D loss: 0.221331, acc.: 65.62%] [G loss: 0.433099]\n",
      "epoch:11 step:11058 [D loss: 0.214861, acc.: 67.19%] [G loss: 0.436410]\n",
      "epoch:11 step:11059 [D loss: 0.216354, acc.: 63.28%] [G loss: 0.440398]\n",
      "epoch:11 step:11060 [D loss: 0.226960, acc.: 61.72%] [G loss: 0.409996]\n",
      "epoch:11 step:11061 [D loss: 0.222969, acc.: 63.28%] [G loss: 0.431975]\n",
      "epoch:11 step:11062 [D loss: 0.219944, acc.: 67.97%] [G loss: 0.449112]\n",
      "epoch:11 step:11063 [D loss: 0.235095, acc.: 64.06%] [G loss: 0.447097]\n",
      "epoch:11 step:11064 [D loss: 0.229263, acc.: 61.72%] [G loss: 0.453986]\n",
      "epoch:11 step:11065 [D loss: 0.230060, acc.: 57.03%] [G loss: 0.417180]\n",
      "epoch:11 step:11066 [D loss: 0.239053, acc.: 61.72%] [G loss: 0.408140]\n",
      "epoch:11 step:11067 [D loss: 0.224076, acc.: 64.84%] [G loss: 0.410998]\n",
      "epoch:11 step:11068 [D loss: 0.227702, acc.: 64.06%] [G loss: 0.469455]\n",
      "epoch:11 step:11069 [D loss: 0.249096, acc.: 56.25%] [G loss: 0.454134]\n",
      "epoch:11 step:11070 [D loss: 0.210254, acc.: 64.84%] [G loss: 0.476175]\n",
      "epoch:11 step:11071 [D loss: 0.218213, acc.: 66.41%] [G loss: 0.455878]\n",
      "epoch:11 step:11072 [D loss: 0.272255, acc.: 52.34%] [G loss: 0.377778]\n",
      "epoch:11 step:11073 [D loss: 0.229033, acc.: 63.28%] [G loss: 0.453790]\n",
      "epoch:11 step:11074 [D loss: 0.219686, acc.: 65.62%] [G loss: 0.499560]\n",
      "epoch:11 step:11075 [D loss: 0.254795, acc.: 58.59%] [G loss: 0.483457]\n",
      "epoch:11 step:11076 [D loss: 0.201323, acc.: 72.66%] [G loss: 0.477492]\n",
      "epoch:11 step:11077 [D loss: 0.227467, acc.: 61.72%] [G loss: 0.462986]\n",
      "epoch:11 step:11078 [D loss: 0.210173, acc.: 66.41%] [G loss: 0.447611]\n",
      "epoch:11 step:11079 [D loss: 0.224456, acc.: 62.50%] [G loss: 0.440408]\n",
      "epoch:11 step:11080 [D loss: 0.215150, acc.: 68.75%] [G loss: 0.480245]\n",
      "epoch:11 step:11081 [D loss: 0.232126, acc.: 67.19%] [G loss: 0.446690]\n",
      "epoch:11 step:11082 [D loss: 0.227926, acc.: 64.84%] [G loss: 0.465873]\n",
      "epoch:11 step:11083 [D loss: 0.201429, acc.: 69.53%] [G loss: 0.465447]\n",
      "epoch:11 step:11084 [D loss: 0.257883, acc.: 53.12%] [G loss: 0.478067]\n",
      "epoch:11 step:11085 [D loss: 0.224358, acc.: 60.94%] [G loss: 0.486046]\n",
      "epoch:11 step:11086 [D loss: 0.213362, acc.: 68.75%] [G loss: 0.447106]\n",
      "epoch:11 step:11087 [D loss: 0.216267, acc.: 67.97%] [G loss: 0.482235]\n",
      "epoch:11 step:11088 [D loss: 0.183672, acc.: 74.22%] [G loss: 0.510284]\n",
      "epoch:11 step:11089 [D loss: 0.207175, acc.: 68.75%] [G loss: 0.517897]\n",
      "epoch:11 step:11090 [D loss: 0.253141, acc.: 51.56%] [G loss: 0.456451]\n",
      "epoch:11 step:11091 [D loss: 0.261097, acc.: 54.69%] [G loss: 0.406973]\n",
      "epoch:11 step:11092 [D loss: 0.210745, acc.: 63.28%] [G loss: 0.461296]\n",
      "epoch:11 step:11093 [D loss: 0.201118, acc.: 71.88%] [G loss: 0.437489]\n",
      "epoch:11 step:11094 [D loss: 0.235870, acc.: 64.06%] [G loss: 0.447094]\n",
      "epoch:11 step:11095 [D loss: 0.231721, acc.: 59.38%] [G loss: 0.444305]\n",
      "epoch:11 step:11096 [D loss: 0.227820, acc.: 60.94%] [G loss: 0.491895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11097 [D loss: 0.198083, acc.: 68.75%] [G loss: 0.494221]\n",
      "epoch:11 step:11098 [D loss: 0.262958, acc.: 53.91%] [G loss: 0.446837]\n",
      "epoch:11 step:11099 [D loss: 0.185648, acc.: 78.12%] [G loss: 0.465032]\n",
      "epoch:11 step:11100 [D loss: 0.220913, acc.: 61.72%] [G loss: 0.480747]\n",
      "epoch:11 step:11101 [D loss: 0.241940, acc.: 57.81%] [G loss: 0.468201]\n",
      "epoch:11 step:11102 [D loss: 0.233883, acc.: 62.50%] [G loss: 0.464326]\n",
      "epoch:11 step:11103 [D loss: 0.203225, acc.: 69.53%] [G loss: 0.471085]\n",
      "epoch:11 step:11104 [D loss: 0.248685, acc.: 53.91%] [G loss: 0.451941]\n",
      "epoch:11 step:11105 [D loss: 0.211049, acc.: 68.75%] [G loss: 0.458885]\n",
      "epoch:11 step:11106 [D loss: 0.244996, acc.: 62.50%] [G loss: 0.485227]\n",
      "epoch:11 step:11107 [D loss: 0.256143, acc.: 53.12%] [G loss: 0.457896]\n",
      "epoch:11 step:11108 [D loss: 0.199227, acc.: 70.31%] [G loss: 0.510050]\n",
      "epoch:11 step:11109 [D loss: 0.198118, acc.: 71.88%] [G loss: 0.517526]\n",
      "epoch:11 step:11110 [D loss: 0.220403, acc.: 62.50%] [G loss: 0.467716]\n",
      "epoch:11 step:11111 [D loss: 0.238345, acc.: 60.94%] [G loss: 0.457473]\n",
      "epoch:11 step:11112 [D loss: 0.220599, acc.: 64.84%] [G loss: 0.459030]\n",
      "epoch:11 step:11113 [D loss: 0.225087, acc.: 64.84%] [G loss: 0.459448]\n",
      "epoch:11 step:11114 [D loss: 0.216407, acc.: 65.62%] [G loss: 0.469967]\n",
      "epoch:11 step:11115 [D loss: 0.253956, acc.: 57.03%] [G loss: 0.407478]\n",
      "epoch:11 step:11116 [D loss: 0.239336, acc.: 61.72%] [G loss: 0.415460]\n",
      "epoch:11 step:11117 [D loss: 0.203487, acc.: 67.19%] [G loss: 0.439836]\n",
      "epoch:11 step:11118 [D loss: 0.241875, acc.: 63.28%] [G loss: 0.438327]\n",
      "epoch:11 step:11119 [D loss: 0.245435, acc.: 57.03%] [G loss: 0.418101]\n",
      "epoch:11 step:11120 [D loss: 0.201578, acc.: 72.66%] [G loss: 0.438206]\n",
      "epoch:11 step:11121 [D loss: 0.238480, acc.: 64.06%] [G loss: 0.457869]\n",
      "epoch:11 step:11122 [D loss: 0.181434, acc.: 70.31%] [G loss: 0.563931]\n",
      "epoch:11 step:11123 [D loss: 0.228926, acc.: 65.62%] [G loss: 0.512114]\n",
      "epoch:11 step:11124 [D loss: 0.280607, acc.: 64.06%] [G loss: 0.460816]\n",
      "epoch:11 step:11125 [D loss: 0.243130, acc.: 60.16%] [G loss: 0.472023]\n",
      "epoch:11 step:11126 [D loss: 0.206652, acc.: 66.41%] [G loss: 0.450566]\n",
      "epoch:11 step:11127 [D loss: 0.262118, acc.: 50.00%] [G loss: 0.412731]\n",
      "epoch:11 step:11128 [D loss: 0.240048, acc.: 54.69%] [G loss: 0.451959]\n",
      "epoch:11 step:11129 [D loss: 0.220648, acc.: 64.06%] [G loss: 0.482568]\n",
      "epoch:11 step:11130 [D loss: 0.207138, acc.: 64.84%] [G loss: 0.490069]\n",
      "epoch:11 step:11131 [D loss: 0.229927, acc.: 59.38%] [G loss: 0.448144]\n",
      "epoch:11 step:11132 [D loss: 0.208432, acc.: 67.97%] [G loss: 0.434948]\n",
      "epoch:11 step:11133 [D loss: 0.218550, acc.: 68.75%] [G loss: 0.479893]\n",
      "epoch:11 step:11134 [D loss: 0.257093, acc.: 52.34%] [G loss: 0.466389]\n",
      "epoch:11 step:11135 [D loss: 0.251860, acc.: 57.81%] [G loss: 0.424292]\n",
      "epoch:11 step:11136 [D loss: 0.216945, acc.: 64.84%] [G loss: 0.451930]\n",
      "epoch:11 step:11137 [D loss: 0.222221, acc.: 64.06%] [G loss: 0.468804]\n",
      "epoch:11 step:11138 [D loss: 0.231292, acc.: 64.06%] [G loss: 0.454542]\n",
      "epoch:11 step:11139 [D loss: 0.218174, acc.: 65.62%] [G loss: 0.493119]\n",
      "epoch:11 step:11140 [D loss: 0.218517, acc.: 64.84%] [G loss: 0.447351]\n",
      "epoch:11 step:11141 [D loss: 0.245556, acc.: 59.38%] [G loss: 0.424791]\n",
      "epoch:11 step:11142 [D loss: 0.215174, acc.: 61.72%] [G loss: 0.470101]\n",
      "epoch:11 step:11143 [D loss: 0.228559, acc.: 61.72%] [G loss: 0.454907]\n",
      "epoch:11 step:11144 [D loss: 0.252454, acc.: 62.50%] [G loss: 0.459485]\n",
      "epoch:11 step:11145 [D loss: 0.214155, acc.: 65.62%] [G loss: 0.468325]\n",
      "epoch:11 step:11146 [D loss: 0.201530, acc.: 68.75%] [G loss: 0.456949]\n",
      "epoch:11 step:11147 [D loss: 0.223192, acc.: 60.94%] [G loss: 0.422761]\n",
      "epoch:11 step:11148 [D loss: 0.222086, acc.: 62.50%] [G loss: 0.463504]\n",
      "epoch:11 step:11149 [D loss: 0.213858, acc.: 71.09%] [G loss: 0.430568]\n",
      "epoch:11 step:11150 [D loss: 0.239227, acc.: 62.50%] [G loss: 0.444931]\n",
      "epoch:11 step:11151 [D loss: 0.211842, acc.: 67.97%] [G loss: 0.470333]\n",
      "epoch:11 step:11152 [D loss: 0.198589, acc.: 64.84%] [G loss: 0.507258]\n",
      "epoch:11 step:11153 [D loss: 0.231976, acc.: 60.94%] [G loss: 0.462401]\n",
      "epoch:11 step:11154 [D loss: 0.223618, acc.: 61.72%] [G loss: 0.437014]\n",
      "epoch:11 step:11155 [D loss: 0.217277, acc.: 65.62%] [G loss: 0.428592]\n",
      "epoch:11 step:11156 [D loss: 0.193313, acc.: 76.56%] [G loss: 0.473423]\n",
      "epoch:11 step:11157 [D loss: 0.232175, acc.: 57.81%] [G loss: 0.463875]\n",
      "epoch:11 step:11158 [D loss: 0.236766, acc.: 57.81%] [G loss: 0.442406]\n",
      "epoch:11 step:11159 [D loss: 0.229534, acc.: 58.59%] [G loss: 0.451666]\n",
      "epoch:11 step:11160 [D loss: 0.202818, acc.: 67.19%] [G loss: 0.507383]\n",
      "epoch:11 step:11161 [D loss: 0.227499, acc.: 60.16%] [G loss: 0.455110]\n",
      "epoch:11 step:11162 [D loss: 0.244709, acc.: 58.59%] [G loss: 0.451529]\n",
      "epoch:11 step:11163 [D loss: 0.208579, acc.: 66.41%] [G loss: 0.508508]\n",
      "epoch:11 step:11164 [D loss: 0.208209, acc.: 67.97%] [G loss: 0.444443]\n",
      "epoch:11 step:11165 [D loss: 0.258661, acc.: 50.78%] [G loss: 0.449364]\n",
      "epoch:11 step:11166 [D loss: 0.229478, acc.: 62.50%] [G loss: 0.467035]\n",
      "epoch:11 step:11167 [D loss: 0.208660, acc.: 67.97%] [G loss: 0.481233]\n",
      "epoch:11 step:11168 [D loss: 0.244206, acc.: 60.16%] [G loss: 0.425832]\n",
      "epoch:11 step:11169 [D loss: 0.221618, acc.: 64.06%] [G loss: 0.419026]\n",
      "epoch:11 step:11170 [D loss: 0.197084, acc.: 69.53%] [G loss: 0.460209]\n",
      "epoch:11 step:11171 [D loss: 0.223226, acc.: 62.50%] [G loss: 0.420100]\n",
      "epoch:11 step:11172 [D loss: 0.257515, acc.: 55.47%] [G loss: 0.423311]\n",
      "epoch:11 step:11173 [D loss: 0.226596, acc.: 64.06%] [G loss: 0.423771]\n",
      "epoch:11 step:11174 [D loss: 0.263446, acc.: 54.69%] [G loss: 0.474447]\n",
      "epoch:11 step:11175 [D loss: 0.233028, acc.: 63.28%] [G loss: 0.462011]\n",
      "epoch:11 step:11176 [D loss: 0.238640, acc.: 58.59%] [G loss: 0.428006]\n",
      "epoch:11 step:11177 [D loss: 0.209040, acc.: 67.19%] [G loss: 0.452085]\n",
      "epoch:11 step:11178 [D loss: 0.213373, acc.: 64.06%] [G loss: 0.477159]\n",
      "epoch:11 step:11179 [D loss: 0.235221, acc.: 60.16%] [G loss: 0.421378]\n",
      "epoch:11 step:11180 [D loss: 0.233408, acc.: 59.38%] [G loss: 0.423243]\n",
      "epoch:11 step:11181 [D loss: 0.219961, acc.: 62.50%] [G loss: 0.420513]\n",
      "epoch:11 step:11182 [D loss: 0.212449, acc.: 70.31%] [G loss: 0.444957]\n",
      "epoch:11 step:11183 [D loss: 0.216131, acc.: 66.41%] [G loss: 0.438205]\n",
      "epoch:11 step:11184 [D loss: 0.256043, acc.: 59.38%] [G loss: 0.437558]\n",
      "epoch:11 step:11185 [D loss: 0.237645, acc.: 61.72%] [G loss: 0.467509]\n",
      "epoch:11 step:11186 [D loss: 0.240027, acc.: 59.38%] [G loss: 0.443716]\n",
      "epoch:11 step:11187 [D loss: 0.267391, acc.: 50.78%] [G loss: 0.405421]\n",
      "epoch:11 step:11188 [D loss: 0.225107, acc.: 58.59%] [G loss: 0.430256]\n",
      "epoch:11 step:11189 [D loss: 0.217029, acc.: 65.62%] [G loss: 0.409438]\n",
      "epoch:11 step:11190 [D loss: 0.217922, acc.: 66.41%] [G loss: 0.452303]\n",
      "epoch:11 step:11191 [D loss: 0.212957, acc.: 67.19%] [G loss: 0.470280]\n",
      "epoch:11 step:11192 [D loss: 0.216378, acc.: 65.62%] [G loss: 0.502089]\n",
      "epoch:11 step:11193 [D loss: 0.215134, acc.: 69.53%] [G loss: 0.526049]\n",
      "epoch:11 step:11194 [D loss: 0.205598, acc.: 64.84%] [G loss: 0.534499]\n",
      "epoch:11 step:11195 [D loss: 0.241845, acc.: 55.47%] [G loss: 0.446166]\n",
      "epoch:11 step:11196 [D loss: 0.224527, acc.: 62.50%] [G loss: 0.452572]\n",
      "epoch:11 step:11197 [D loss: 0.202812, acc.: 68.75%] [G loss: 0.450401]\n",
      "epoch:11 step:11198 [D loss: 0.256384, acc.: 54.69%] [G loss: 0.406615]\n",
      "epoch:11 step:11199 [D loss: 0.234144, acc.: 51.56%] [G loss: 0.430123]\n",
      "epoch:11 step:11200 [D loss: 0.204682, acc.: 70.31%] [G loss: 0.416722]\n",
      "epoch:11 step:11201 [D loss: 0.217800, acc.: 62.50%] [G loss: 0.469214]\n",
      "epoch:11 step:11202 [D loss: 0.215434, acc.: 65.62%] [G loss: 0.491406]\n",
      "epoch:11 step:11203 [D loss: 0.238865, acc.: 60.94%] [G loss: 0.466821]\n",
      "epoch:11 step:11204 [D loss: 0.211149, acc.: 66.41%] [G loss: 0.523373]\n",
      "epoch:11 step:11205 [D loss: 0.185731, acc.: 70.31%] [G loss: 0.485910]\n",
      "epoch:11 step:11206 [D loss: 0.193543, acc.: 73.44%] [G loss: 0.453529]\n",
      "epoch:11 step:11207 [D loss: 0.202978, acc.: 67.19%] [G loss: 0.495311]\n",
      "epoch:11 step:11208 [D loss: 0.217891, acc.: 64.84%] [G loss: 0.448871]\n",
      "epoch:11 step:11209 [D loss: 0.249498, acc.: 56.25%] [G loss: 0.435277]\n",
      "epoch:11 step:11210 [D loss: 0.202031, acc.: 69.53%] [G loss: 0.470644]\n",
      "epoch:11 step:11211 [D loss: 0.222057, acc.: 64.84%] [G loss: 0.446020]\n",
      "epoch:11 step:11212 [D loss: 0.210374, acc.: 64.06%] [G loss: 0.439410]\n",
      "epoch:11 step:11213 [D loss: 0.216196, acc.: 64.06%] [G loss: 0.489995]\n",
      "epoch:11 step:11214 [D loss: 0.228835, acc.: 57.81%] [G loss: 0.468040]\n",
      "epoch:11 step:11215 [D loss: 0.205520, acc.: 67.97%] [G loss: 0.464204]\n",
      "epoch:11 step:11216 [D loss: 0.202058, acc.: 66.41%] [G loss: 0.488560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11217 [D loss: 0.240705, acc.: 63.28%] [G loss: 0.449047]\n",
      "epoch:11 step:11218 [D loss: 0.208304, acc.: 65.62%] [G loss: 0.477639]\n",
      "epoch:11 step:11219 [D loss: 0.192768, acc.: 75.00%] [G loss: 0.498328]\n",
      "epoch:11 step:11220 [D loss: 0.224100, acc.: 64.06%] [G loss: 0.468834]\n",
      "epoch:11 step:11221 [D loss: 0.229306, acc.: 60.94%] [G loss: 0.499642]\n",
      "epoch:11 step:11222 [D loss: 0.254128, acc.: 54.69%] [G loss: 0.421872]\n",
      "epoch:11 step:11223 [D loss: 0.248647, acc.: 58.59%] [G loss: 0.438235]\n",
      "epoch:11 step:11224 [D loss: 0.218587, acc.: 67.19%] [G loss: 0.468666]\n",
      "epoch:11 step:11225 [D loss: 0.228924, acc.: 63.28%] [G loss: 0.470550]\n",
      "epoch:11 step:11226 [D loss: 0.199575, acc.: 68.75%] [G loss: 0.547909]\n",
      "epoch:11 step:11227 [D loss: 0.275522, acc.: 59.38%] [G loss: 0.542312]\n",
      "epoch:11 step:11228 [D loss: 0.218472, acc.: 64.06%] [G loss: 0.519906]\n",
      "epoch:11 step:11229 [D loss: 0.237530, acc.: 60.94%] [G loss: 0.470086]\n",
      "epoch:11 step:11230 [D loss: 0.179407, acc.: 76.56%] [G loss: 0.480788]\n",
      "epoch:11 step:11231 [D loss: 0.176374, acc.: 78.12%] [G loss: 0.491787]\n",
      "epoch:11 step:11232 [D loss: 0.179744, acc.: 79.69%] [G loss: 0.543537]\n",
      "epoch:11 step:11233 [D loss: 0.167937, acc.: 78.12%] [G loss: 0.565929]\n",
      "epoch:11 step:11234 [D loss: 0.210257, acc.: 67.97%] [G loss: 0.601885]\n",
      "epoch:11 step:11235 [D loss: 0.323179, acc.: 53.91%] [G loss: 0.498892]\n",
      "epoch:11 step:11236 [D loss: 0.210164, acc.: 67.19%] [G loss: 0.596174]\n",
      "epoch:11 step:11237 [D loss: 0.249474, acc.: 64.06%] [G loss: 0.548921]\n",
      "epoch:11 step:11238 [D loss: 0.303455, acc.: 47.66%] [G loss: 0.425397]\n",
      "epoch:11 step:11239 [D loss: 0.244116, acc.: 53.91%] [G loss: 0.383051]\n",
      "epoch:11 step:11240 [D loss: 0.221507, acc.: 64.06%] [G loss: 0.437849]\n",
      "epoch:11 step:11241 [D loss: 0.210133, acc.: 67.19%] [G loss: 0.508582]\n",
      "epoch:11 step:11242 [D loss: 0.199250, acc.: 69.53%] [G loss: 0.525142]\n",
      "epoch:11 step:11243 [D loss: 0.167622, acc.: 73.44%] [G loss: 0.589146]\n",
      "epoch:11 step:11244 [D loss: 0.168626, acc.: 84.38%] [G loss: 0.556335]\n",
      "epoch:12 step:11245 [D loss: 0.242499, acc.: 61.72%] [G loss: 0.500571]\n",
      "epoch:12 step:11246 [D loss: 0.253796, acc.: 61.72%] [G loss: 0.488104]\n",
      "epoch:12 step:11247 [D loss: 0.249238, acc.: 57.03%] [G loss: 0.467135]\n",
      "epoch:12 step:11248 [D loss: 0.236030, acc.: 64.84%] [G loss: 0.475358]\n",
      "epoch:12 step:11249 [D loss: 0.252682, acc.: 55.47%] [G loss: 0.433379]\n",
      "epoch:12 step:11250 [D loss: 0.239698, acc.: 54.69%] [G loss: 0.436881]\n",
      "epoch:12 step:11251 [D loss: 0.222833, acc.: 60.94%] [G loss: 0.488780]\n",
      "epoch:12 step:11252 [D loss: 0.217053, acc.: 64.06%] [G loss: 0.441926]\n",
      "epoch:12 step:11253 [D loss: 0.192574, acc.: 69.53%] [G loss: 0.501712]\n",
      "epoch:12 step:11254 [D loss: 0.226936, acc.: 64.06%] [G loss: 0.487994]\n",
      "epoch:12 step:11255 [D loss: 0.204494, acc.: 63.28%] [G loss: 0.485181]\n",
      "epoch:12 step:11256 [D loss: 0.238482, acc.: 64.06%] [G loss: 0.503372]\n",
      "epoch:12 step:11257 [D loss: 0.217974, acc.: 63.28%] [G loss: 0.533736]\n",
      "epoch:12 step:11258 [D loss: 0.205053, acc.: 67.97%] [G loss: 0.498803]\n",
      "epoch:12 step:11259 [D loss: 0.196972, acc.: 68.75%] [G loss: 0.529494]\n",
      "epoch:12 step:11260 [D loss: 0.200752, acc.: 67.19%] [G loss: 0.534675]\n",
      "epoch:12 step:11261 [D loss: 0.224152, acc.: 62.50%] [G loss: 0.489489]\n",
      "epoch:12 step:11262 [D loss: 0.258404, acc.: 52.34%] [G loss: 0.440874]\n",
      "epoch:12 step:11263 [D loss: 0.262655, acc.: 57.81%] [G loss: 0.464207]\n",
      "epoch:12 step:11264 [D loss: 0.256374, acc.: 50.78%] [G loss: 0.466558]\n",
      "epoch:12 step:11265 [D loss: 0.230905, acc.: 61.72%] [G loss: 0.502005]\n",
      "epoch:12 step:11266 [D loss: 0.190296, acc.: 71.09%] [G loss: 0.540527]\n",
      "epoch:12 step:11267 [D loss: 0.271541, acc.: 57.03%] [G loss: 0.389732]\n",
      "epoch:12 step:11268 [D loss: 0.195202, acc.: 67.19%] [G loss: 0.431728]\n",
      "epoch:12 step:11269 [D loss: 0.199335, acc.: 65.62%] [G loss: 0.443991]\n",
      "epoch:12 step:11270 [D loss: 0.246176, acc.: 59.38%] [G loss: 0.446886]\n",
      "epoch:12 step:11271 [D loss: 0.231232, acc.: 57.81%] [G loss: 0.423239]\n",
      "epoch:12 step:11272 [D loss: 0.241366, acc.: 55.47%] [G loss: 0.437911]\n",
      "epoch:12 step:11273 [D loss: 0.231316, acc.: 62.50%] [G loss: 0.454140]\n",
      "epoch:12 step:11274 [D loss: 0.223921, acc.: 57.81%] [G loss: 0.458875]\n",
      "epoch:12 step:11275 [D loss: 0.242680, acc.: 54.69%] [G loss: 0.422141]\n",
      "epoch:12 step:11276 [D loss: 0.236848, acc.: 58.59%] [G loss: 0.435869]\n",
      "epoch:12 step:11277 [D loss: 0.223996, acc.: 66.41%] [G loss: 0.467560]\n",
      "epoch:12 step:11278 [D loss: 0.237415, acc.: 57.03%] [G loss: 0.446133]\n",
      "epoch:12 step:11279 [D loss: 0.215783, acc.: 64.84%] [G loss: 0.469922]\n",
      "epoch:12 step:11280 [D loss: 0.199318, acc.: 72.66%] [G loss: 0.470796]\n",
      "epoch:12 step:11281 [D loss: 0.224559, acc.: 60.16%] [G loss: 0.416210]\n",
      "epoch:12 step:11282 [D loss: 0.246428, acc.: 56.25%] [G loss: 0.424582]\n",
      "epoch:12 step:11283 [D loss: 0.225016, acc.: 65.62%] [G loss: 0.407483]\n",
      "epoch:12 step:11284 [D loss: 0.187855, acc.: 71.88%] [G loss: 0.451747]\n",
      "epoch:12 step:11285 [D loss: 0.242326, acc.: 55.47%] [G loss: 0.470930]\n",
      "epoch:12 step:11286 [D loss: 0.223113, acc.: 65.62%] [G loss: 0.435834]\n",
      "epoch:12 step:11287 [D loss: 0.228113, acc.: 63.28%] [G loss: 0.429896]\n",
      "epoch:12 step:11288 [D loss: 0.246346, acc.: 57.81%] [G loss: 0.427383]\n",
      "epoch:12 step:11289 [D loss: 0.224231, acc.: 66.41%] [G loss: 0.423717]\n",
      "epoch:12 step:11290 [D loss: 0.243302, acc.: 59.38%] [G loss: 0.463141]\n",
      "epoch:12 step:11291 [D loss: 0.219124, acc.: 61.72%] [G loss: 0.444220]\n",
      "epoch:12 step:11292 [D loss: 0.207240, acc.: 69.53%] [G loss: 0.440802]\n",
      "epoch:12 step:11293 [D loss: 0.203594, acc.: 67.97%] [G loss: 0.479555]\n",
      "epoch:12 step:11294 [D loss: 0.199152, acc.: 69.53%] [G loss: 0.480934]\n",
      "epoch:12 step:11295 [D loss: 0.256315, acc.: 60.94%] [G loss: 0.431872]\n",
      "epoch:12 step:11296 [D loss: 0.219361, acc.: 64.06%] [G loss: 0.438333]\n",
      "epoch:12 step:11297 [D loss: 0.220822, acc.: 64.84%] [G loss: 0.484436]\n",
      "epoch:12 step:11298 [D loss: 0.223311, acc.: 67.19%] [G loss: 0.455420]\n",
      "epoch:12 step:11299 [D loss: 0.221651, acc.: 63.28%] [G loss: 0.457631]\n",
      "epoch:12 step:11300 [D loss: 0.208016, acc.: 66.41%] [G loss: 0.470090]\n",
      "epoch:12 step:11301 [D loss: 0.238127, acc.: 56.25%] [G loss: 0.419906]\n",
      "epoch:12 step:11302 [D loss: 0.211502, acc.: 66.41%] [G loss: 0.486610]\n",
      "epoch:12 step:11303 [D loss: 0.187984, acc.: 71.88%] [G loss: 0.467832]\n",
      "epoch:12 step:11304 [D loss: 0.249474, acc.: 53.91%] [G loss: 0.403931]\n",
      "epoch:12 step:11305 [D loss: 0.225327, acc.: 65.62%] [G loss: 0.453163]\n",
      "epoch:12 step:11306 [D loss: 0.248424, acc.: 60.16%] [G loss: 0.441965]\n",
      "epoch:12 step:11307 [D loss: 0.232300, acc.: 57.81%] [G loss: 0.474376]\n",
      "epoch:12 step:11308 [D loss: 0.234943, acc.: 65.62%] [G loss: 0.442486]\n",
      "epoch:12 step:11309 [D loss: 0.232065, acc.: 63.28%] [G loss: 0.420489]\n",
      "epoch:12 step:11310 [D loss: 0.200187, acc.: 71.09%] [G loss: 0.444403]\n",
      "epoch:12 step:11311 [D loss: 0.212949, acc.: 66.41%] [G loss: 0.459955]\n",
      "epoch:12 step:11312 [D loss: 0.223528, acc.: 64.06%] [G loss: 0.446267]\n",
      "epoch:12 step:11313 [D loss: 0.197698, acc.: 73.44%] [G loss: 0.455701]\n",
      "epoch:12 step:11314 [D loss: 0.209288, acc.: 62.50%] [G loss: 0.474589]\n",
      "epoch:12 step:11315 [D loss: 0.234502, acc.: 59.38%] [G loss: 0.434669]\n",
      "epoch:12 step:11316 [D loss: 0.233529, acc.: 63.28%] [G loss: 0.426727]\n",
      "epoch:12 step:11317 [D loss: 0.241794, acc.: 58.59%] [G loss: 0.436208]\n",
      "epoch:12 step:11318 [D loss: 0.185876, acc.: 71.88%] [G loss: 0.445593]\n",
      "epoch:12 step:11319 [D loss: 0.206226, acc.: 68.75%] [G loss: 0.474054]\n",
      "epoch:12 step:11320 [D loss: 0.199732, acc.: 66.41%] [G loss: 0.499299]\n",
      "epoch:12 step:11321 [D loss: 0.202181, acc.: 67.97%] [G loss: 0.518172]\n",
      "epoch:12 step:11322 [D loss: 0.267108, acc.: 57.03%] [G loss: 0.427387]\n",
      "epoch:12 step:11323 [D loss: 0.249830, acc.: 60.94%] [G loss: 0.423494]\n",
      "epoch:12 step:11324 [D loss: 0.222699, acc.: 63.28%] [G loss: 0.442993]\n",
      "epoch:12 step:11325 [D loss: 0.218366, acc.: 64.06%] [G loss: 0.467752]\n",
      "epoch:12 step:11326 [D loss: 0.221467, acc.: 64.06%] [G loss: 0.478218]\n",
      "epoch:12 step:11327 [D loss: 0.224383, acc.: 69.53%] [G loss: 0.456292]\n",
      "epoch:12 step:11328 [D loss: 0.219524, acc.: 66.41%] [G loss: 0.492498]\n",
      "epoch:12 step:11329 [D loss: 0.225677, acc.: 64.84%] [G loss: 0.461391]\n",
      "epoch:12 step:11330 [D loss: 0.211066, acc.: 67.97%] [G loss: 0.485923]\n",
      "epoch:12 step:11331 [D loss: 0.226297, acc.: 66.41%] [G loss: 0.404870]\n",
      "epoch:12 step:11332 [D loss: 0.226115, acc.: 61.72%] [G loss: 0.406800]\n",
      "epoch:12 step:11333 [D loss: 0.211572, acc.: 67.19%] [G loss: 0.466328]\n",
      "epoch:12 step:11334 [D loss: 0.210821, acc.: 68.75%] [G loss: 0.449595]\n",
      "epoch:12 step:11335 [D loss: 0.234860, acc.: 63.28%] [G loss: 0.435049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11336 [D loss: 0.217169, acc.: 67.97%] [G loss: 0.498472]\n",
      "epoch:12 step:11337 [D loss: 0.233988, acc.: 57.03%] [G loss: 0.502174]\n",
      "epoch:12 step:11338 [D loss: 0.237682, acc.: 60.16%] [G loss: 0.494593]\n",
      "epoch:12 step:11339 [D loss: 0.222640, acc.: 68.75%] [G loss: 0.460358]\n",
      "epoch:12 step:11340 [D loss: 0.205495, acc.: 67.97%] [G loss: 0.477416]\n",
      "epoch:12 step:11341 [D loss: 0.215367, acc.: 64.06%] [G loss: 0.466610]\n",
      "epoch:12 step:11342 [D loss: 0.227367, acc.: 63.28%] [G loss: 0.491155]\n",
      "epoch:12 step:11343 [D loss: 0.234171, acc.: 63.28%] [G loss: 0.408889]\n",
      "epoch:12 step:11344 [D loss: 0.160187, acc.: 77.34%] [G loss: 0.480269]\n",
      "epoch:12 step:11345 [D loss: 0.218275, acc.: 65.62%] [G loss: 0.459309]\n",
      "epoch:12 step:11346 [D loss: 0.248485, acc.: 58.59%] [G loss: 0.410841]\n",
      "epoch:12 step:11347 [D loss: 0.248359, acc.: 60.94%] [G loss: 0.400578]\n",
      "epoch:12 step:11348 [D loss: 0.213481, acc.: 64.84%] [G loss: 0.452621]\n",
      "epoch:12 step:11349 [D loss: 0.231969, acc.: 60.16%] [G loss: 0.412266]\n",
      "epoch:12 step:11350 [D loss: 0.222117, acc.: 67.19%] [G loss: 0.452431]\n",
      "epoch:12 step:11351 [D loss: 0.185565, acc.: 68.75%] [G loss: 0.510682]\n",
      "epoch:12 step:11352 [D loss: 0.356618, acc.: 44.53%] [G loss: 0.480600]\n",
      "epoch:12 step:11353 [D loss: 0.271113, acc.: 50.00%] [G loss: 0.422385]\n",
      "epoch:12 step:11354 [D loss: 0.223206, acc.: 62.50%] [G loss: 0.439013]\n",
      "epoch:12 step:11355 [D loss: 0.229875, acc.: 58.59%] [G loss: 0.427148]\n",
      "epoch:12 step:11356 [D loss: 0.181720, acc.: 77.34%] [G loss: 0.451304]\n",
      "epoch:12 step:11357 [D loss: 0.226791, acc.: 64.84%] [G loss: 0.430645]\n",
      "epoch:12 step:11358 [D loss: 0.221668, acc.: 64.84%] [G loss: 0.476122]\n",
      "epoch:12 step:11359 [D loss: 0.216254, acc.: 69.53%] [G loss: 0.523630]\n",
      "epoch:12 step:11360 [D loss: 0.204769, acc.: 73.44%] [G loss: 0.489900]\n",
      "epoch:12 step:11361 [D loss: 0.215452, acc.: 64.84%] [G loss: 0.473152]\n",
      "epoch:12 step:11362 [D loss: 0.208665, acc.: 67.97%] [G loss: 0.473684]\n",
      "epoch:12 step:11363 [D loss: 0.186151, acc.: 73.44%] [G loss: 0.535005]\n",
      "epoch:12 step:11364 [D loss: 0.277961, acc.: 56.25%] [G loss: 0.490454]\n",
      "epoch:12 step:11365 [D loss: 0.245221, acc.: 58.59%] [G loss: 0.450294]\n",
      "epoch:12 step:11366 [D loss: 0.204284, acc.: 67.97%] [G loss: 0.445585]\n",
      "epoch:12 step:11367 [D loss: 0.209481, acc.: 69.53%] [G loss: 0.465727]\n",
      "epoch:12 step:11368 [D loss: 0.240601, acc.: 60.94%] [G loss: 0.485965]\n",
      "epoch:12 step:11369 [D loss: 0.248626, acc.: 60.94%] [G loss: 0.404770]\n",
      "epoch:12 step:11370 [D loss: 0.208383, acc.: 67.19%] [G loss: 0.470212]\n",
      "epoch:12 step:11371 [D loss: 0.199859, acc.: 64.84%] [G loss: 0.464403]\n",
      "epoch:12 step:11372 [D loss: 0.236970, acc.: 59.38%] [G loss: 0.434892]\n",
      "epoch:12 step:11373 [D loss: 0.252060, acc.: 58.59%] [G loss: 0.416403]\n",
      "epoch:12 step:11374 [D loss: 0.198792, acc.: 67.97%] [G loss: 0.459680]\n",
      "epoch:12 step:11375 [D loss: 0.209091, acc.: 70.31%] [G loss: 0.491908]\n",
      "epoch:12 step:11376 [D loss: 0.211281, acc.: 67.97%] [G loss: 0.437864]\n",
      "epoch:12 step:11377 [D loss: 0.284869, acc.: 52.34%] [G loss: 0.444818]\n",
      "epoch:12 step:11378 [D loss: 0.227495, acc.: 62.50%] [G loss: 0.455461]\n",
      "epoch:12 step:11379 [D loss: 0.254863, acc.: 59.38%] [G loss: 0.423772]\n",
      "epoch:12 step:11380 [D loss: 0.202570, acc.: 70.31%] [G loss: 0.447202]\n",
      "epoch:12 step:11381 [D loss: 0.253826, acc.: 57.81%] [G loss: 0.436653]\n",
      "epoch:12 step:11382 [D loss: 0.232257, acc.: 62.50%] [G loss: 0.429750]\n",
      "epoch:12 step:11383 [D loss: 0.221882, acc.: 64.84%] [G loss: 0.447794]\n",
      "epoch:12 step:11384 [D loss: 0.233969, acc.: 60.94%] [G loss: 0.477829]\n",
      "epoch:12 step:11385 [D loss: 0.244899, acc.: 60.16%] [G loss: 0.420135]\n",
      "epoch:12 step:11386 [D loss: 0.237753, acc.: 59.38%] [G loss: 0.438405]\n",
      "epoch:12 step:11387 [D loss: 0.247337, acc.: 52.34%] [G loss: 0.440993]\n",
      "epoch:12 step:11388 [D loss: 0.212375, acc.: 70.31%] [G loss: 0.439181]\n",
      "epoch:12 step:11389 [D loss: 0.225328, acc.: 57.03%] [G loss: 0.428082]\n",
      "epoch:12 step:11390 [D loss: 0.234404, acc.: 61.72%] [G loss: 0.460911]\n",
      "epoch:12 step:11391 [D loss: 0.254773, acc.: 53.91%] [G loss: 0.432363]\n",
      "epoch:12 step:11392 [D loss: 0.261363, acc.: 55.47%] [G loss: 0.407597]\n",
      "epoch:12 step:11393 [D loss: 0.220953, acc.: 62.50%] [G loss: 0.443613]\n",
      "epoch:12 step:11394 [D loss: 0.242814, acc.: 59.38%] [G loss: 0.416882]\n",
      "epoch:12 step:11395 [D loss: 0.219374, acc.: 65.62%] [G loss: 0.482565]\n",
      "epoch:12 step:11396 [D loss: 0.233699, acc.: 60.94%] [G loss: 0.446274]\n",
      "epoch:12 step:11397 [D loss: 0.259628, acc.: 50.00%] [G loss: 0.408774]\n",
      "epoch:12 step:11398 [D loss: 0.213455, acc.: 63.28%] [G loss: 0.479935]\n",
      "epoch:12 step:11399 [D loss: 0.189650, acc.: 71.09%] [G loss: 0.464226]\n",
      "epoch:12 step:11400 [D loss: 0.211639, acc.: 69.53%] [G loss: 0.487808]\n",
      "epoch:12 step:11401 [D loss: 0.241663, acc.: 59.38%] [G loss: 0.430928]\n",
      "epoch:12 step:11402 [D loss: 0.216958, acc.: 65.62%] [G loss: 0.461039]\n",
      "epoch:12 step:11403 [D loss: 0.237913, acc.: 58.59%] [G loss: 0.411923]\n",
      "epoch:12 step:11404 [D loss: 0.263172, acc.: 54.69%] [G loss: 0.379021]\n",
      "epoch:12 step:11405 [D loss: 0.216899, acc.: 67.19%] [G loss: 0.471586]\n",
      "epoch:12 step:11406 [D loss: 0.223243, acc.: 64.06%] [G loss: 0.424544]\n",
      "epoch:12 step:11407 [D loss: 0.242179, acc.: 61.72%] [G loss: 0.423390]\n",
      "epoch:12 step:11408 [D loss: 0.218794, acc.: 62.50%] [G loss: 0.440437]\n",
      "epoch:12 step:11409 [D loss: 0.242974, acc.: 64.06%] [G loss: 0.415224]\n",
      "epoch:12 step:11410 [D loss: 0.220153, acc.: 63.28%] [G loss: 0.423400]\n",
      "epoch:12 step:11411 [D loss: 0.196608, acc.: 67.19%] [G loss: 0.482147]\n",
      "epoch:12 step:11412 [D loss: 0.206938, acc.: 71.09%] [G loss: 0.496530]\n",
      "epoch:12 step:11413 [D loss: 0.237378, acc.: 57.81%] [G loss: 0.400381]\n",
      "epoch:12 step:11414 [D loss: 0.250366, acc.: 57.03%] [G loss: 0.407194]\n",
      "epoch:12 step:11415 [D loss: 0.230258, acc.: 60.94%] [G loss: 0.424463]\n",
      "epoch:12 step:11416 [D loss: 0.219718, acc.: 64.84%] [G loss: 0.423661]\n",
      "epoch:12 step:11417 [D loss: 0.210824, acc.: 64.06%] [G loss: 0.442029]\n",
      "epoch:12 step:11418 [D loss: 0.257062, acc.: 50.78%] [G loss: 0.440772]\n",
      "epoch:12 step:11419 [D loss: 0.242799, acc.: 55.47%] [G loss: 0.434018]\n",
      "epoch:12 step:11420 [D loss: 0.237577, acc.: 55.47%] [G loss: 0.428659]\n",
      "epoch:12 step:11421 [D loss: 0.218541, acc.: 67.19%] [G loss: 0.465122]\n",
      "epoch:12 step:11422 [D loss: 0.236216, acc.: 64.84%] [G loss: 0.450731]\n",
      "epoch:12 step:11423 [D loss: 0.234797, acc.: 60.16%] [G loss: 0.409070]\n",
      "epoch:12 step:11424 [D loss: 0.218143, acc.: 62.50%] [G loss: 0.470512]\n",
      "epoch:12 step:11425 [D loss: 0.257039, acc.: 60.16%] [G loss: 0.393678]\n",
      "epoch:12 step:11426 [D loss: 0.239805, acc.: 60.94%] [G loss: 0.427929]\n",
      "epoch:12 step:11427 [D loss: 0.228283, acc.: 62.50%] [G loss: 0.474801]\n",
      "epoch:12 step:11428 [D loss: 0.229366, acc.: 65.62%] [G loss: 0.421200]\n",
      "epoch:12 step:11429 [D loss: 0.225612, acc.: 65.62%] [G loss: 0.449360]\n",
      "epoch:12 step:11430 [D loss: 0.234836, acc.: 60.94%] [G loss: 0.434242]\n",
      "epoch:12 step:11431 [D loss: 0.236046, acc.: 58.59%] [G loss: 0.439389]\n",
      "epoch:12 step:11432 [D loss: 0.252223, acc.: 58.59%] [G loss: 0.413655]\n",
      "epoch:12 step:11433 [D loss: 0.262010, acc.: 48.44%] [G loss: 0.411128]\n",
      "epoch:12 step:11434 [D loss: 0.209544, acc.: 70.31%] [G loss: 0.450249]\n",
      "epoch:12 step:11435 [D loss: 0.203400, acc.: 71.88%] [G loss: 0.443410]\n",
      "epoch:12 step:11436 [D loss: 0.187125, acc.: 75.00%] [G loss: 0.467862]\n",
      "epoch:12 step:11437 [D loss: 0.216155, acc.: 62.50%] [G loss: 0.458902]\n",
      "epoch:12 step:11438 [D loss: 0.191084, acc.: 73.44%] [G loss: 0.499201]\n",
      "epoch:12 step:11439 [D loss: 0.230558, acc.: 60.16%] [G loss: 0.427999]\n",
      "epoch:12 step:11440 [D loss: 0.245053, acc.: 54.69%] [G loss: 0.480882]\n",
      "epoch:12 step:11441 [D loss: 0.219294, acc.: 63.28%] [G loss: 0.445081]\n",
      "epoch:12 step:11442 [D loss: 0.221116, acc.: 63.28%] [G loss: 0.469838]\n",
      "epoch:12 step:11443 [D loss: 0.233770, acc.: 61.72%] [G loss: 0.468338]\n",
      "epoch:12 step:11444 [D loss: 0.248099, acc.: 56.25%] [G loss: 0.476805]\n",
      "epoch:12 step:11445 [D loss: 0.228879, acc.: 64.84%] [G loss: 0.447230]\n",
      "epoch:12 step:11446 [D loss: 0.220751, acc.: 64.06%] [G loss: 0.426119]\n",
      "epoch:12 step:11447 [D loss: 0.221268, acc.: 64.84%] [G loss: 0.460807]\n",
      "epoch:12 step:11448 [D loss: 0.218097, acc.: 66.41%] [G loss: 0.490599]\n",
      "epoch:12 step:11449 [D loss: 0.228315, acc.: 65.62%] [G loss: 0.501468]\n",
      "epoch:12 step:11450 [D loss: 0.213431, acc.: 64.84%] [G loss: 0.511615]\n",
      "epoch:12 step:11451 [D loss: 0.195973, acc.: 69.53%] [G loss: 0.497416]\n",
      "epoch:12 step:11452 [D loss: 0.188194, acc.: 64.84%] [G loss: 0.480384]\n",
      "epoch:12 step:11453 [D loss: 0.189020, acc.: 71.88%] [G loss: 0.470582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11454 [D loss: 0.274851, acc.: 55.47%] [G loss: 0.446653]\n",
      "epoch:12 step:11455 [D loss: 0.251080, acc.: 57.03%] [G loss: 0.417264]\n",
      "epoch:12 step:11456 [D loss: 0.257718, acc.: 55.47%] [G loss: 0.396074]\n",
      "epoch:12 step:11457 [D loss: 0.221550, acc.: 64.06%] [G loss: 0.448834]\n",
      "epoch:12 step:11458 [D loss: 0.261748, acc.: 57.81%] [G loss: 0.408929]\n",
      "epoch:12 step:11459 [D loss: 0.252508, acc.: 53.12%] [G loss: 0.424926]\n",
      "epoch:12 step:11460 [D loss: 0.216353, acc.: 64.84%] [G loss: 0.454326]\n",
      "epoch:12 step:11461 [D loss: 0.230636, acc.: 64.06%] [G loss: 0.461371]\n",
      "epoch:12 step:11462 [D loss: 0.183334, acc.: 72.66%] [G loss: 0.471193]\n",
      "epoch:12 step:11463 [D loss: 0.183996, acc.: 71.88%] [G loss: 0.524436]\n",
      "epoch:12 step:11464 [D loss: 0.258644, acc.: 54.69%] [G loss: 0.443067]\n",
      "epoch:12 step:11465 [D loss: 0.232375, acc.: 61.72%] [G loss: 0.503869]\n",
      "epoch:12 step:11466 [D loss: 0.213985, acc.: 65.62%] [G loss: 0.497020]\n",
      "epoch:12 step:11467 [D loss: 0.191656, acc.: 75.78%] [G loss: 0.483225]\n",
      "epoch:12 step:11468 [D loss: 0.290684, acc.: 49.22%] [G loss: 0.409305]\n",
      "epoch:12 step:11469 [D loss: 0.231944, acc.: 62.50%] [G loss: 0.410438]\n",
      "epoch:12 step:11470 [D loss: 0.242243, acc.: 60.16%] [G loss: 0.411703]\n",
      "epoch:12 step:11471 [D loss: 0.216674, acc.: 65.62%] [G loss: 0.415798]\n",
      "epoch:12 step:11472 [D loss: 0.221792, acc.: 64.06%] [G loss: 0.449376]\n",
      "epoch:12 step:11473 [D loss: 0.211813, acc.: 65.62%] [G loss: 0.455767]\n",
      "epoch:12 step:11474 [D loss: 0.188741, acc.: 71.09%] [G loss: 0.494995]\n",
      "epoch:12 step:11475 [D loss: 0.193803, acc.: 69.53%] [G loss: 0.536687]\n",
      "epoch:12 step:11476 [D loss: 0.168780, acc.: 78.12%] [G loss: 0.555688]\n",
      "epoch:12 step:11477 [D loss: 0.227366, acc.: 66.41%] [G loss: 0.489230]\n",
      "epoch:12 step:11478 [D loss: 0.252040, acc.: 59.38%] [G loss: 0.462166]\n",
      "epoch:12 step:11479 [D loss: 0.225047, acc.: 61.72%] [G loss: 0.460387]\n",
      "epoch:12 step:11480 [D loss: 0.239637, acc.: 60.16%] [G loss: 0.434227]\n",
      "epoch:12 step:11481 [D loss: 0.231741, acc.: 63.28%] [G loss: 0.433964]\n",
      "epoch:12 step:11482 [D loss: 0.212057, acc.: 66.41%] [G loss: 0.471031]\n",
      "epoch:12 step:11483 [D loss: 0.227832, acc.: 60.94%] [G loss: 0.461202]\n",
      "epoch:12 step:11484 [D loss: 0.216110, acc.: 64.84%] [G loss: 0.474823]\n",
      "epoch:12 step:11485 [D loss: 0.192429, acc.: 71.88%] [G loss: 0.476665]\n",
      "epoch:12 step:11486 [D loss: 0.231968, acc.: 63.28%] [G loss: 0.478155]\n",
      "epoch:12 step:11487 [D loss: 0.215695, acc.: 67.97%] [G loss: 0.494993]\n",
      "epoch:12 step:11488 [D loss: 0.212834, acc.: 67.19%] [G loss: 0.504323]\n",
      "epoch:12 step:11489 [D loss: 0.216023, acc.: 67.19%] [G loss: 0.477821]\n",
      "epoch:12 step:11490 [D loss: 0.222360, acc.: 60.94%] [G loss: 0.437271]\n",
      "epoch:12 step:11491 [D loss: 0.231543, acc.: 58.59%] [G loss: 0.424922]\n",
      "epoch:12 step:11492 [D loss: 0.213446, acc.: 69.53%] [G loss: 0.460776]\n",
      "epoch:12 step:11493 [D loss: 0.267492, acc.: 55.47%] [G loss: 0.410993]\n",
      "epoch:12 step:11494 [D loss: 0.263017, acc.: 51.56%] [G loss: 0.423332]\n",
      "epoch:12 step:11495 [D loss: 0.241485, acc.: 61.72%] [G loss: 0.425419]\n",
      "epoch:12 step:11496 [D loss: 0.229306, acc.: 62.50%] [G loss: 0.427931]\n",
      "epoch:12 step:11497 [D loss: 0.209684, acc.: 67.19%] [G loss: 0.463958]\n",
      "epoch:12 step:11498 [D loss: 0.217995, acc.: 63.28%] [G loss: 0.474581]\n",
      "epoch:12 step:11499 [D loss: 0.217411, acc.: 65.62%] [G loss: 0.456986]\n",
      "epoch:12 step:11500 [D loss: 0.222976, acc.: 66.41%] [G loss: 0.444541]\n",
      "epoch:12 step:11501 [D loss: 0.233615, acc.: 64.06%] [G loss: 0.430129]\n",
      "epoch:12 step:11502 [D loss: 0.213817, acc.: 67.97%] [G loss: 0.437686]\n",
      "epoch:12 step:11503 [D loss: 0.185202, acc.: 75.78%] [G loss: 0.494679]\n",
      "epoch:12 step:11504 [D loss: 0.218798, acc.: 67.97%] [G loss: 0.436579]\n",
      "epoch:12 step:11505 [D loss: 0.221453, acc.: 67.97%] [G loss: 0.457471]\n",
      "epoch:12 step:11506 [D loss: 0.222334, acc.: 60.94%] [G loss: 0.437801]\n",
      "epoch:12 step:11507 [D loss: 0.237863, acc.: 61.72%] [G loss: 0.457857]\n",
      "epoch:12 step:11508 [D loss: 0.209574, acc.: 69.53%] [G loss: 0.465414]\n",
      "epoch:12 step:11509 [D loss: 0.271426, acc.: 50.78%] [G loss: 0.441429]\n",
      "epoch:12 step:11510 [D loss: 0.227204, acc.: 62.50%] [G loss: 0.442418]\n",
      "epoch:12 step:11511 [D loss: 0.229260, acc.: 60.16%] [G loss: 0.456849]\n",
      "epoch:12 step:11512 [D loss: 0.247391, acc.: 57.03%] [G loss: 0.430667]\n",
      "epoch:12 step:11513 [D loss: 0.213037, acc.: 66.41%] [G loss: 0.448658]\n",
      "epoch:12 step:11514 [D loss: 0.217790, acc.: 63.28%] [G loss: 0.432725]\n",
      "epoch:12 step:11515 [D loss: 0.204280, acc.: 70.31%] [G loss: 0.501097]\n",
      "epoch:12 step:11516 [D loss: 0.220725, acc.: 63.28%] [G loss: 0.459791]\n",
      "epoch:12 step:11517 [D loss: 0.225284, acc.: 65.62%] [G loss: 0.447599]\n",
      "epoch:12 step:11518 [D loss: 0.225405, acc.: 63.28%] [G loss: 0.446522]\n",
      "epoch:12 step:11519 [D loss: 0.209323, acc.: 68.75%] [G loss: 0.481022]\n",
      "epoch:12 step:11520 [D loss: 0.213749, acc.: 66.41%] [G loss: 0.459524]\n",
      "epoch:12 step:11521 [D loss: 0.233147, acc.: 58.59%] [G loss: 0.459966]\n",
      "epoch:12 step:11522 [D loss: 0.265919, acc.: 52.34%] [G loss: 0.452858]\n",
      "epoch:12 step:11523 [D loss: 0.221382, acc.: 62.50%] [G loss: 0.449589]\n",
      "epoch:12 step:11524 [D loss: 0.222913, acc.: 62.50%] [G loss: 0.462312]\n",
      "epoch:12 step:11525 [D loss: 0.260151, acc.: 51.56%] [G loss: 0.431612]\n",
      "epoch:12 step:11526 [D loss: 0.236512, acc.: 60.16%] [G loss: 0.444053]\n",
      "epoch:12 step:11527 [D loss: 0.201286, acc.: 64.06%] [G loss: 0.453103]\n",
      "epoch:12 step:11528 [D loss: 0.247851, acc.: 57.03%] [G loss: 0.393285]\n",
      "epoch:12 step:11529 [D loss: 0.218009, acc.: 65.62%] [G loss: 0.419019]\n",
      "epoch:12 step:11530 [D loss: 0.204075, acc.: 66.41%] [G loss: 0.444382]\n",
      "epoch:12 step:11531 [D loss: 0.222573, acc.: 60.16%] [G loss: 0.464089]\n",
      "epoch:12 step:11532 [D loss: 0.236811, acc.: 60.94%] [G loss: 0.455261]\n",
      "epoch:12 step:11533 [D loss: 0.210722, acc.: 65.62%] [G loss: 0.475942]\n",
      "epoch:12 step:11534 [D loss: 0.204398, acc.: 71.88%] [G loss: 0.473900]\n",
      "epoch:12 step:11535 [D loss: 0.256965, acc.: 57.03%] [G loss: 0.443732]\n",
      "epoch:12 step:11536 [D loss: 0.224837, acc.: 59.38%] [G loss: 0.446321]\n",
      "epoch:12 step:11537 [D loss: 0.244446, acc.: 60.16%] [G loss: 0.417355]\n",
      "epoch:12 step:11538 [D loss: 0.234292, acc.: 54.69%] [G loss: 0.443856]\n",
      "epoch:12 step:11539 [D loss: 0.249738, acc.: 50.78%] [G loss: 0.422393]\n",
      "epoch:12 step:11540 [D loss: 0.200334, acc.: 71.09%] [G loss: 0.468734]\n",
      "epoch:12 step:11541 [D loss: 0.227282, acc.: 61.72%] [G loss: 0.451636]\n",
      "epoch:12 step:11542 [D loss: 0.201475, acc.: 70.31%] [G loss: 0.456096]\n",
      "epoch:12 step:11543 [D loss: 0.189897, acc.: 72.66%] [G loss: 0.435799]\n",
      "epoch:12 step:11544 [D loss: 0.191278, acc.: 73.44%] [G loss: 0.466922]\n",
      "epoch:12 step:11545 [D loss: 0.258670, acc.: 53.91%] [G loss: 0.434932]\n",
      "epoch:12 step:11546 [D loss: 0.196764, acc.: 71.09%] [G loss: 0.471037]\n",
      "epoch:12 step:11547 [D loss: 0.249055, acc.: 49.22%] [G loss: 0.452580]\n",
      "epoch:12 step:11548 [D loss: 0.224849, acc.: 62.50%] [G loss: 0.481201]\n",
      "epoch:12 step:11549 [D loss: 0.232340, acc.: 60.16%] [G loss: 0.497292]\n",
      "epoch:12 step:11550 [D loss: 0.214811, acc.: 63.28%] [G loss: 0.491063]\n",
      "epoch:12 step:11551 [D loss: 0.224316, acc.: 67.19%] [G loss: 0.445279]\n",
      "epoch:12 step:11552 [D loss: 0.211002, acc.: 65.62%] [G loss: 0.486890]\n",
      "epoch:12 step:11553 [D loss: 0.200968, acc.: 66.41%] [G loss: 0.465834]\n",
      "epoch:12 step:11554 [D loss: 0.219112, acc.: 67.19%] [G loss: 0.450730]\n",
      "epoch:12 step:11555 [D loss: 0.182841, acc.: 71.88%] [G loss: 0.454752]\n",
      "epoch:12 step:11556 [D loss: 0.185555, acc.: 68.75%] [G loss: 0.528326]\n",
      "epoch:12 step:11557 [D loss: 0.184605, acc.: 65.62%] [G loss: 0.530952]\n",
      "epoch:12 step:11558 [D loss: 0.192102, acc.: 66.41%] [G loss: 0.508654]\n",
      "epoch:12 step:11559 [D loss: 0.230391, acc.: 61.72%] [G loss: 0.485291]\n",
      "epoch:12 step:11560 [D loss: 0.295624, acc.: 53.12%] [G loss: 0.465150]\n",
      "epoch:12 step:11561 [D loss: 0.235771, acc.: 62.50%] [G loss: 0.446338]\n",
      "epoch:12 step:11562 [D loss: 0.225181, acc.: 61.72%] [G loss: 0.449516]\n",
      "epoch:12 step:11563 [D loss: 0.215776, acc.: 64.06%] [G loss: 0.430148]\n",
      "epoch:12 step:11564 [D loss: 0.213015, acc.: 60.94%] [G loss: 0.481483]\n",
      "epoch:12 step:11565 [D loss: 0.177557, acc.: 75.00%] [G loss: 0.479414]\n",
      "epoch:12 step:11566 [D loss: 0.215905, acc.: 67.19%] [G loss: 0.492076]\n",
      "epoch:12 step:11567 [D loss: 0.272469, acc.: 51.56%] [G loss: 0.469036]\n",
      "epoch:12 step:11568 [D loss: 0.216478, acc.: 66.41%] [G loss: 0.450340]\n",
      "epoch:12 step:11569 [D loss: 0.194085, acc.: 71.09%] [G loss: 0.447139]\n",
      "epoch:12 step:11570 [D loss: 0.228944, acc.: 64.84%] [G loss: 0.448171]\n",
      "epoch:12 step:11571 [D loss: 0.220828, acc.: 66.41%] [G loss: 0.448576]\n",
      "epoch:12 step:11572 [D loss: 0.191587, acc.: 72.66%] [G loss: 0.514172]\n",
      "epoch:12 step:11573 [D loss: 0.240492, acc.: 57.81%] [G loss: 0.442694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11574 [D loss: 0.222291, acc.: 66.41%] [G loss: 0.439458]\n",
      "epoch:12 step:11575 [D loss: 0.230082, acc.: 61.72%] [G loss: 0.445607]\n",
      "epoch:12 step:11576 [D loss: 0.215615, acc.: 67.19%] [G loss: 0.465692]\n",
      "epoch:12 step:11577 [D loss: 0.199549, acc.: 73.44%] [G loss: 0.445670]\n",
      "epoch:12 step:11578 [D loss: 0.221306, acc.: 64.06%] [G loss: 0.446512]\n",
      "epoch:12 step:11579 [D loss: 0.223863, acc.: 66.41%] [G loss: 0.481363]\n",
      "epoch:12 step:11580 [D loss: 0.204041, acc.: 67.97%] [G loss: 0.491438]\n",
      "epoch:12 step:11581 [D loss: 0.216354, acc.: 64.06%] [G loss: 0.448251]\n",
      "epoch:12 step:11582 [D loss: 0.206604, acc.: 70.31%] [G loss: 0.445347]\n",
      "epoch:12 step:11583 [D loss: 0.222536, acc.: 67.19%] [G loss: 0.422202]\n",
      "epoch:12 step:11584 [D loss: 0.217759, acc.: 67.97%] [G loss: 0.448351]\n",
      "epoch:12 step:11585 [D loss: 0.292814, acc.: 49.22%] [G loss: 0.424956]\n",
      "epoch:12 step:11586 [D loss: 0.237485, acc.: 59.38%] [G loss: 0.510272]\n",
      "epoch:12 step:11587 [D loss: 0.238675, acc.: 63.28%] [G loss: 0.436658]\n",
      "epoch:12 step:11588 [D loss: 0.206964, acc.: 63.28%] [G loss: 0.453013]\n",
      "epoch:12 step:11589 [D loss: 0.187539, acc.: 75.00%] [G loss: 0.555357]\n",
      "epoch:12 step:11590 [D loss: 0.194927, acc.: 71.09%] [G loss: 0.513852]\n",
      "epoch:12 step:11591 [D loss: 0.170310, acc.: 76.56%] [G loss: 0.537819]\n",
      "epoch:12 step:11592 [D loss: 0.298849, acc.: 54.69%] [G loss: 0.450408]\n",
      "epoch:12 step:11593 [D loss: 0.260443, acc.: 49.22%] [G loss: 0.376577]\n",
      "epoch:12 step:11594 [D loss: 0.230408, acc.: 64.06%] [G loss: 0.402616]\n",
      "epoch:12 step:11595 [D loss: 0.221363, acc.: 62.50%] [G loss: 0.432245]\n",
      "epoch:12 step:11596 [D loss: 0.214644, acc.: 67.19%] [G loss: 0.511345]\n",
      "epoch:12 step:11597 [D loss: 0.196049, acc.: 68.75%] [G loss: 0.459953]\n",
      "epoch:12 step:11598 [D loss: 0.176427, acc.: 75.78%] [G loss: 0.469347]\n",
      "epoch:12 step:11599 [D loss: 0.243808, acc.: 61.72%] [G loss: 0.454966]\n",
      "epoch:12 step:11600 [D loss: 0.223125, acc.: 67.19%] [G loss: 0.454150]\n",
      "epoch:12 step:11601 [D loss: 0.200858, acc.: 64.84%] [G loss: 0.479383]\n",
      "epoch:12 step:11602 [D loss: 0.195204, acc.: 70.31%] [G loss: 0.484504]\n",
      "epoch:12 step:11603 [D loss: 0.183192, acc.: 73.44%] [G loss: 0.473136]\n",
      "epoch:12 step:11604 [D loss: 0.203879, acc.: 66.41%] [G loss: 0.468278]\n",
      "epoch:12 step:11605 [D loss: 0.195476, acc.: 75.00%] [G loss: 0.501084]\n",
      "epoch:12 step:11606 [D loss: 0.229982, acc.: 64.06%] [G loss: 0.457762]\n",
      "epoch:12 step:11607 [D loss: 0.263997, acc.: 53.12%] [G loss: 0.372993]\n",
      "epoch:12 step:11608 [D loss: 0.194935, acc.: 64.84%] [G loss: 0.487858]\n",
      "epoch:12 step:11609 [D loss: 0.235655, acc.: 60.94%] [G loss: 0.408793]\n",
      "epoch:12 step:11610 [D loss: 0.215920, acc.: 64.84%] [G loss: 0.452373]\n",
      "epoch:12 step:11611 [D loss: 0.250997, acc.: 59.38%] [G loss: 0.426178]\n",
      "epoch:12 step:11612 [D loss: 0.235405, acc.: 57.03%] [G loss: 0.436847]\n",
      "epoch:12 step:11613 [D loss: 0.226661, acc.: 60.16%] [G loss: 0.451143]\n",
      "epoch:12 step:11614 [D loss: 0.213204, acc.: 64.84%] [G loss: 0.525406]\n",
      "epoch:12 step:11615 [D loss: 0.209733, acc.: 69.53%] [G loss: 0.470041]\n",
      "epoch:12 step:11616 [D loss: 0.247204, acc.: 53.12%] [G loss: 0.438873]\n",
      "epoch:12 step:11617 [D loss: 0.272663, acc.: 53.12%] [G loss: 0.447870]\n",
      "epoch:12 step:11618 [D loss: 0.194278, acc.: 69.53%] [G loss: 0.465580]\n",
      "epoch:12 step:11619 [D loss: 0.242924, acc.: 62.50%] [G loss: 0.478722]\n",
      "epoch:12 step:11620 [D loss: 0.249735, acc.: 57.81%] [G loss: 0.412546]\n",
      "epoch:12 step:11621 [D loss: 0.269728, acc.: 49.22%] [G loss: 0.445589]\n",
      "epoch:12 step:11622 [D loss: 0.216106, acc.: 62.50%] [G loss: 0.455184]\n",
      "epoch:12 step:11623 [D loss: 0.250151, acc.: 55.47%] [G loss: 0.421621]\n",
      "epoch:12 step:11624 [D loss: 0.242133, acc.: 63.28%] [G loss: 0.440713]\n",
      "epoch:12 step:11625 [D loss: 0.188220, acc.: 68.75%] [G loss: 0.427056]\n",
      "epoch:12 step:11626 [D loss: 0.221238, acc.: 68.75%] [G loss: 0.442401]\n",
      "epoch:12 step:11627 [D loss: 0.235090, acc.: 55.47%] [G loss: 0.440126]\n",
      "epoch:12 step:11628 [D loss: 0.217590, acc.: 64.84%] [G loss: 0.422488]\n",
      "epoch:12 step:11629 [D loss: 0.187840, acc.: 74.22%] [G loss: 0.442789]\n",
      "epoch:12 step:11630 [D loss: 0.210836, acc.: 66.41%] [G loss: 0.480309]\n",
      "epoch:12 step:11631 [D loss: 0.245964, acc.: 58.59%] [G loss: 0.434982]\n",
      "epoch:12 step:11632 [D loss: 0.206278, acc.: 70.31%] [G loss: 0.507821]\n",
      "epoch:12 step:11633 [D loss: 0.220959, acc.: 67.19%] [G loss: 0.428129]\n",
      "epoch:12 step:11634 [D loss: 0.237550, acc.: 63.28%] [G loss: 0.440887]\n",
      "epoch:12 step:11635 [D loss: 0.217008, acc.: 64.84%] [G loss: 0.425414]\n",
      "epoch:12 step:11636 [D loss: 0.194252, acc.: 70.31%] [G loss: 0.455901]\n",
      "epoch:12 step:11637 [D loss: 0.234574, acc.: 57.81%] [G loss: 0.423603]\n",
      "epoch:12 step:11638 [D loss: 0.239699, acc.: 60.16%] [G loss: 0.427551]\n",
      "epoch:12 step:11639 [D loss: 0.227112, acc.: 64.06%] [G loss: 0.459806]\n",
      "epoch:12 step:11640 [D loss: 0.273516, acc.: 50.00%] [G loss: 0.467581]\n",
      "epoch:12 step:11641 [D loss: 0.214478, acc.: 64.06%] [G loss: 0.459693]\n",
      "epoch:12 step:11642 [D loss: 0.218156, acc.: 62.50%] [G loss: 0.493767]\n",
      "epoch:12 step:11643 [D loss: 0.205369, acc.: 68.75%] [G loss: 0.504652]\n",
      "epoch:12 step:11644 [D loss: 0.291187, acc.: 47.66%] [G loss: 0.442976]\n",
      "epoch:12 step:11645 [D loss: 0.226310, acc.: 61.72%] [G loss: 0.419298]\n",
      "epoch:12 step:11646 [D loss: 0.212107, acc.: 71.09%] [G loss: 0.433892]\n",
      "epoch:12 step:11647 [D loss: 0.223891, acc.: 56.25%] [G loss: 0.435862]\n",
      "epoch:12 step:11648 [D loss: 0.243341, acc.: 57.81%] [G loss: 0.435368]\n",
      "epoch:12 step:11649 [D loss: 0.195828, acc.: 71.88%] [G loss: 0.445601]\n",
      "epoch:12 step:11650 [D loss: 0.213496, acc.: 64.84%] [G loss: 0.503519]\n",
      "epoch:12 step:11651 [D loss: 0.278944, acc.: 51.56%] [G loss: 0.454524]\n",
      "epoch:12 step:11652 [D loss: 0.241575, acc.: 60.94%] [G loss: 0.456930]\n",
      "epoch:12 step:11653 [D loss: 0.217839, acc.: 64.06%] [G loss: 0.414476]\n",
      "epoch:12 step:11654 [D loss: 0.213974, acc.: 68.75%] [G loss: 0.465161]\n",
      "epoch:12 step:11655 [D loss: 0.245182, acc.: 57.81%] [G loss: 0.400965]\n",
      "epoch:12 step:11656 [D loss: 0.235266, acc.: 60.94%] [G loss: 0.420324]\n",
      "epoch:12 step:11657 [D loss: 0.248097, acc.: 58.59%] [G loss: 0.418034]\n",
      "epoch:12 step:11658 [D loss: 0.235499, acc.: 60.94%] [G loss: 0.444311]\n",
      "epoch:12 step:11659 [D loss: 0.185258, acc.: 76.56%] [G loss: 0.506026]\n",
      "epoch:12 step:11660 [D loss: 0.191651, acc.: 77.34%] [G loss: 0.498462]\n",
      "epoch:12 step:11661 [D loss: 0.215869, acc.: 64.84%] [G loss: 0.501378]\n",
      "epoch:12 step:11662 [D loss: 0.275135, acc.: 53.12%] [G loss: 0.465100]\n",
      "epoch:12 step:11663 [D loss: 0.246833, acc.: 60.16%] [G loss: 0.440380]\n",
      "epoch:12 step:11664 [D loss: 0.212634, acc.: 64.84%] [G loss: 0.473445]\n",
      "epoch:12 step:11665 [D loss: 0.257761, acc.: 55.47%] [G loss: 0.379599]\n",
      "epoch:12 step:11666 [D loss: 0.253366, acc.: 55.47%] [G loss: 0.415315]\n",
      "epoch:12 step:11667 [D loss: 0.221019, acc.: 63.28%] [G loss: 0.411219]\n",
      "epoch:12 step:11668 [D loss: 0.221118, acc.: 66.41%] [G loss: 0.425359]\n",
      "epoch:12 step:11669 [D loss: 0.204899, acc.: 64.84%] [G loss: 0.447934]\n",
      "epoch:12 step:11670 [D loss: 0.247718, acc.: 60.16%] [G loss: 0.408781]\n",
      "epoch:12 step:11671 [D loss: 0.202826, acc.: 67.97%] [G loss: 0.465291]\n",
      "epoch:12 step:11672 [D loss: 0.201746, acc.: 71.09%] [G loss: 0.495245]\n",
      "epoch:12 step:11673 [D loss: 0.189517, acc.: 74.22%] [G loss: 0.546824]\n",
      "epoch:12 step:11674 [D loss: 0.214698, acc.: 65.62%] [G loss: 0.488620]\n",
      "epoch:12 step:11675 [D loss: 0.234034, acc.: 60.94%] [G loss: 0.450346]\n",
      "epoch:12 step:11676 [D loss: 0.245774, acc.: 53.91%] [G loss: 0.469576]\n",
      "epoch:12 step:11677 [D loss: 0.237712, acc.: 60.16%] [G loss: 0.445321]\n",
      "epoch:12 step:11678 [D loss: 0.231391, acc.: 64.84%] [G loss: 0.442750]\n",
      "epoch:12 step:11679 [D loss: 0.200221, acc.: 67.97%] [G loss: 0.507592]\n",
      "epoch:12 step:11680 [D loss: 0.200539, acc.: 72.66%] [G loss: 0.531634]\n",
      "epoch:12 step:11681 [D loss: 0.285103, acc.: 47.66%] [G loss: 0.445765]\n",
      "epoch:12 step:11682 [D loss: 0.233288, acc.: 57.03%] [G loss: 0.465070]\n",
      "epoch:12 step:11683 [D loss: 0.208845, acc.: 67.19%] [G loss: 0.459234]\n",
      "epoch:12 step:11684 [D loss: 0.244445, acc.: 61.72%] [G loss: 0.417428]\n",
      "epoch:12 step:11685 [D loss: 0.213319, acc.: 66.41%] [G loss: 0.516689]\n",
      "epoch:12 step:11686 [D loss: 0.244317, acc.: 57.81%] [G loss: 0.446615]\n",
      "epoch:12 step:11687 [D loss: 0.256985, acc.: 58.59%] [G loss: 0.432557]\n",
      "epoch:12 step:11688 [D loss: 0.235957, acc.: 62.50%] [G loss: 0.450037]\n",
      "epoch:12 step:11689 [D loss: 0.234659, acc.: 60.16%] [G loss: 0.415173]\n",
      "epoch:12 step:11690 [D loss: 0.222139, acc.: 64.84%] [G loss: 0.429874]\n",
      "epoch:12 step:11691 [D loss: 0.231032, acc.: 66.41%] [G loss: 0.429392]\n",
      "epoch:12 step:11692 [D loss: 0.246369, acc.: 54.69%] [G loss: 0.440326]\n",
      "epoch:12 step:11693 [D loss: 0.223466, acc.: 60.16%] [G loss: 0.458854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11694 [D loss: 0.251814, acc.: 58.59%] [G loss: 0.461526]\n",
      "epoch:12 step:11695 [D loss: 0.192037, acc.: 71.09%] [G loss: 0.493097]\n",
      "epoch:12 step:11696 [D loss: 0.195676, acc.: 71.09%] [G loss: 0.468491]\n",
      "epoch:12 step:11697 [D loss: 0.227955, acc.: 62.50%] [G loss: 0.450572]\n",
      "epoch:12 step:11698 [D loss: 0.225335, acc.: 64.84%] [G loss: 0.484336]\n",
      "epoch:12 step:11699 [D loss: 0.251083, acc.: 56.25%] [G loss: 0.477334]\n",
      "epoch:12 step:11700 [D loss: 0.228198, acc.: 63.28%] [G loss: 0.483176]\n",
      "epoch:12 step:11701 [D loss: 0.226964, acc.: 61.72%] [G loss: 0.451144]\n",
      "epoch:12 step:11702 [D loss: 0.300367, acc.: 48.44%] [G loss: 0.428047]\n",
      "epoch:12 step:11703 [D loss: 0.245231, acc.: 57.03%] [G loss: 0.402072]\n",
      "epoch:12 step:11704 [D loss: 0.233927, acc.: 61.72%] [G loss: 0.409911]\n",
      "epoch:12 step:11705 [D loss: 0.222733, acc.: 68.75%] [G loss: 0.435072]\n",
      "epoch:12 step:11706 [D loss: 0.234344, acc.: 60.16%] [G loss: 0.428819]\n",
      "epoch:12 step:11707 [D loss: 0.214847, acc.: 63.28%] [G loss: 0.424441]\n",
      "epoch:12 step:11708 [D loss: 0.230629, acc.: 56.25%] [G loss: 0.423724]\n",
      "epoch:12 step:11709 [D loss: 0.246562, acc.: 57.03%] [G loss: 0.385435]\n",
      "epoch:12 step:11710 [D loss: 0.229004, acc.: 62.50%] [G loss: 0.408351]\n",
      "epoch:12 step:11711 [D loss: 0.236898, acc.: 63.28%] [G loss: 0.414208]\n",
      "epoch:12 step:11712 [D loss: 0.217126, acc.: 66.41%] [G loss: 0.476782]\n",
      "epoch:12 step:11713 [D loss: 0.218350, acc.: 67.97%] [G loss: 0.483869]\n",
      "epoch:12 step:11714 [D loss: 0.204160, acc.: 67.19%] [G loss: 0.467191]\n",
      "epoch:12 step:11715 [D loss: 0.176730, acc.: 77.34%] [G loss: 0.519091]\n",
      "epoch:12 step:11716 [D loss: 0.223930, acc.: 66.41%] [G loss: 0.546866]\n",
      "epoch:12 step:11717 [D loss: 0.263713, acc.: 57.81%] [G loss: 0.447058]\n",
      "epoch:12 step:11718 [D loss: 0.211860, acc.: 66.41%] [G loss: 0.476024]\n",
      "epoch:12 step:11719 [D loss: 0.225590, acc.: 66.41%] [G loss: 0.436821]\n",
      "epoch:12 step:11720 [D loss: 0.226897, acc.: 62.50%] [G loss: 0.498676]\n",
      "epoch:12 step:11721 [D loss: 0.261905, acc.: 54.69%] [G loss: 0.419810]\n",
      "epoch:12 step:11722 [D loss: 0.257111, acc.: 51.56%] [G loss: 0.402045]\n",
      "epoch:12 step:11723 [D loss: 0.225138, acc.: 66.41%] [G loss: 0.427775]\n",
      "epoch:12 step:11724 [D loss: 0.221956, acc.: 63.28%] [G loss: 0.456959]\n",
      "epoch:12 step:11725 [D loss: 0.191282, acc.: 75.00%] [G loss: 0.502535]\n",
      "epoch:12 step:11726 [D loss: 0.268194, acc.: 54.69%] [G loss: 0.444898]\n",
      "epoch:12 step:11727 [D loss: 0.253502, acc.: 51.56%] [G loss: 0.425137]\n",
      "epoch:12 step:11728 [D loss: 0.191271, acc.: 74.22%] [G loss: 0.478833]\n",
      "epoch:12 step:11729 [D loss: 0.234859, acc.: 60.94%] [G loss: 0.414712]\n",
      "epoch:12 step:11730 [D loss: 0.210899, acc.: 68.75%] [G loss: 0.457368]\n",
      "epoch:12 step:11731 [D loss: 0.233965, acc.: 62.50%] [G loss: 0.481656]\n",
      "epoch:12 step:11732 [D loss: 0.198749, acc.: 69.53%] [G loss: 0.473831]\n",
      "epoch:12 step:11733 [D loss: 0.260987, acc.: 54.69%] [G loss: 0.471314]\n",
      "epoch:12 step:11734 [D loss: 0.253241, acc.: 56.25%] [G loss: 0.435622]\n",
      "epoch:12 step:11735 [D loss: 0.206439, acc.: 70.31%] [G loss: 0.467833]\n",
      "epoch:12 step:11736 [D loss: 0.233050, acc.: 60.94%] [G loss: 0.435498]\n",
      "epoch:12 step:11737 [D loss: 0.228628, acc.: 64.84%] [G loss: 0.456242]\n",
      "epoch:12 step:11738 [D loss: 0.208309, acc.: 66.41%] [G loss: 0.478663]\n",
      "epoch:12 step:11739 [D loss: 0.184360, acc.: 77.34%] [G loss: 0.493570]\n",
      "epoch:12 step:11740 [D loss: 0.224130, acc.: 67.97%] [G loss: 0.502157]\n",
      "epoch:12 step:11741 [D loss: 0.201887, acc.: 67.19%] [G loss: 0.489848]\n",
      "epoch:12 step:11742 [D loss: 0.207196, acc.: 68.75%] [G loss: 0.518618]\n",
      "epoch:12 step:11743 [D loss: 0.185274, acc.: 77.34%] [G loss: 0.529383]\n",
      "epoch:12 step:11744 [D loss: 0.286059, acc.: 53.12%] [G loss: 0.458636]\n",
      "epoch:12 step:11745 [D loss: 0.267217, acc.: 55.47%] [G loss: 0.468139]\n",
      "epoch:12 step:11746 [D loss: 0.210370, acc.: 65.62%] [G loss: 0.421986]\n",
      "epoch:12 step:11747 [D loss: 0.197721, acc.: 72.66%] [G loss: 0.425435]\n",
      "epoch:12 step:11748 [D loss: 0.198529, acc.: 65.62%] [G loss: 0.504760]\n",
      "epoch:12 step:11749 [D loss: 0.202902, acc.: 69.53%] [G loss: 0.527410]\n",
      "epoch:12 step:11750 [D loss: 0.235080, acc.: 60.94%] [G loss: 0.461515]\n",
      "epoch:12 step:11751 [D loss: 0.228427, acc.: 64.06%] [G loss: 0.487649]\n",
      "epoch:12 step:11752 [D loss: 0.183523, acc.: 74.22%] [G loss: 0.486772]\n",
      "epoch:12 step:11753 [D loss: 0.260807, acc.: 50.78%] [G loss: 0.418537]\n",
      "epoch:12 step:11754 [D loss: 0.239100, acc.: 57.03%] [G loss: 0.424798]\n",
      "epoch:12 step:11755 [D loss: 0.224384, acc.: 62.50%] [G loss: 0.437202]\n",
      "epoch:12 step:11756 [D loss: 0.245514, acc.: 56.25%] [G loss: 0.430149]\n",
      "epoch:12 step:11757 [D loss: 0.221772, acc.: 64.06%] [G loss: 0.455484]\n",
      "epoch:12 step:11758 [D loss: 0.223226, acc.: 60.94%] [G loss: 0.460591]\n",
      "epoch:12 step:11759 [D loss: 0.202173, acc.: 68.75%] [G loss: 0.450988]\n",
      "epoch:12 step:11760 [D loss: 0.207636, acc.: 68.75%] [G loss: 0.498303]\n",
      "epoch:12 step:11761 [D loss: 0.242436, acc.: 56.25%] [G loss: 0.475127]\n",
      "epoch:12 step:11762 [D loss: 0.230899, acc.: 63.28%] [G loss: 0.433613]\n",
      "epoch:12 step:11763 [D loss: 0.191131, acc.: 69.53%] [G loss: 0.471073]\n",
      "epoch:12 step:11764 [D loss: 0.207859, acc.: 68.75%] [G loss: 0.449712]\n",
      "epoch:12 step:11765 [D loss: 0.196426, acc.: 72.66%] [G loss: 0.500161]\n",
      "epoch:12 step:11766 [D loss: 0.216655, acc.: 65.62%] [G loss: 0.451051]\n",
      "epoch:12 step:11767 [D loss: 0.210969, acc.: 63.28%] [G loss: 0.434365]\n",
      "epoch:12 step:11768 [D loss: 0.225451, acc.: 66.41%] [G loss: 0.455716]\n",
      "epoch:12 step:11769 [D loss: 0.195097, acc.: 69.53%] [G loss: 0.503264]\n",
      "epoch:12 step:11770 [D loss: 0.205703, acc.: 67.97%] [G loss: 0.469590]\n",
      "epoch:12 step:11771 [D loss: 0.218602, acc.: 62.50%] [G loss: 0.491696]\n",
      "epoch:12 step:11772 [D loss: 0.267976, acc.: 45.31%] [G loss: 0.426491]\n",
      "epoch:12 step:11773 [D loss: 0.253629, acc.: 56.25%] [G loss: 0.417713]\n",
      "epoch:12 step:11774 [D loss: 0.212374, acc.: 67.97%] [G loss: 0.462201]\n",
      "epoch:12 step:11775 [D loss: 0.263373, acc.: 52.34%] [G loss: 0.424287]\n",
      "epoch:12 step:11776 [D loss: 0.218913, acc.: 58.59%] [G loss: 0.482868]\n",
      "epoch:12 step:11777 [D loss: 0.213271, acc.: 68.75%] [G loss: 0.474382]\n",
      "epoch:12 step:11778 [D loss: 0.203830, acc.: 67.97%] [G loss: 0.480664]\n",
      "epoch:12 step:11779 [D loss: 0.259658, acc.: 54.69%] [G loss: 0.447390]\n",
      "epoch:12 step:11780 [D loss: 0.224718, acc.: 64.84%] [G loss: 0.441985]\n",
      "epoch:12 step:11781 [D loss: 0.248872, acc.: 56.25%] [G loss: 0.442318]\n",
      "epoch:12 step:11782 [D loss: 0.230956, acc.: 61.72%] [G loss: 0.421782]\n",
      "epoch:12 step:11783 [D loss: 0.208059, acc.: 64.06%] [G loss: 0.415765]\n",
      "epoch:12 step:11784 [D loss: 0.235394, acc.: 59.38%] [G loss: 0.404429]\n",
      "epoch:12 step:11785 [D loss: 0.214012, acc.: 64.06%] [G loss: 0.440682]\n",
      "epoch:12 step:11786 [D loss: 0.246765, acc.: 58.59%] [G loss: 0.440261]\n",
      "epoch:12 step:11787 [D loss: 0.223277, acc.: 59.38%] [G loss: 0.477964]\n",
      "epoch:12 step:11788 [D loss: 0.220684, acc.: 67.97%] [G loss: 0.435750]\n",
      "epoch:12 step:11789 [D loss: 0.225180, acc.: 66.41%] [G loss: 0.457211]\n",
      "epoch:12 step:11790 [D loss: 0.205529, acc.: 67.19%] [G loss: 0.432807]\n",
      "epoch:12 step:11791 [D loss: 0.216716, acc.: 64.84%] [G loss: 0.476191]\n",
      "epoch:12 step:11792 [D loss: 0.198908, acc.: 69.53%] [G loss: 0.463798]\n",
      "epoch:12 step:11793 [D loss: 0.184752, acc.: 70.31%] [G loss: 0.498857]\n",
      "epoch:12 step:11794 [D loss: 0.194258, acc.: 75.78%] [G loss: 0.466056]\n",
      "epoch:12 step:11795 [D loss: 0.212082, acc.: 65.62%] [G loss: 0.496962]\n",
      "epoch:12 step:11796 [D loss: 0.210157, acc.: 71.88%] [G loss: 0.460980]\n",
      "epoch:12 step:11797 [D loss: 0.250824, acc.: 61.72%] [G loss: 0.466864]\n",
      "epoch:12 step:11798 [D loss: 0.196689, acc.: 70.31%] [G loss: 0.435172]\n",
      "epoch:12 step:11799 [D loss: 0.196131, acc.: 71.88%] [G loss: 0.439788]\n",
      "epoch:12 step:11800 [D loss: 0.205424, acc.: 66.41%] [G loss: 0.473673]\n",
      "epoch:12 step:11801 [D loss: 0.216204, acc.: 64.06%] [G loss: 0.466826]\n",
      "epoch:12 step:11802 [D loss: 0.194598, acc.: 71.09%] [G loss: 0.490824]\n",
      "epoch:12 step:11803 [D loss: 0.268434, acc.: 48.44%] [G loss: 0.397378]\n",
      "epoch:12 step:11804 [D loss: 0.242154, acc.: 59.38%] [G loss: 0.442384]\n",
      "epoch:12 step:11805 [D loss: 0.209348, acc.: 61.72%] [G loss: 0.460742]\n",
      "epoch:12 step:11806 [D loss: 0.227486, acc.: 61.72%] [G loss: 0.439133]\n",
      "epoch:12 step:11807 [D loss: 0.225232, acc.: 64.06%] [G loss: 0.508283]\n",
      "epoch:12 step:11808 [D loss: 0.203375, acc.: 69.53%] [G loss: 0.447747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11809 [D loss: 0.233357, acc.: 53.91%] [G loss: 0.452550]\n",
      "epoch:12 step:11810 [D loss: 0.284975, acc.: 55.47%] [G loss: 0.428731]\n",
      "epoch:12 step:11811 [D loss: 0.229041, acc.: 60.16%] [G loss: 0.510199]\n",
      "epoch:12 step:11812 [D loss: 0.215382, acc.: 62.50%] [G loss: 0.444461]\n",
      "epoch:12 step:11813 [D loss: 0.258820, acc.: 57.81%] [G loss: 0.458302]\n",
      "epoch:12 step:11814 [D loss: 0.201094, acc.: 71.09%] [G loss: 0.436938]\n",
      "epoch:12 step:11815 [D loss: 0.206085, acc.: 70.31%] [G loss: 0.428007]\n",
      "epoch:12 step:11816 [D loss: 0.207323, acc.: 68.75%] [G loss: 0.459599]\n",
      "epoch:12 step:11817 [D loss: 0.224317, acc.: 61.72%] [G loss: 0.442236]\n",
      "epoch:12 step:11818 [D loss: 0.175960, acc.: 76.56%] [G loss: 0.494144]\n",
      "epoch:12 step:11819 [D loss: 0.208757, acc.: 68.75%] [G loss: 0.479150]\n",
      "epoch:12 step:11820 [D loss: 0.246041, acc.: 60.94%] [G loss: 0.469851]\n",
      "epoch:12 step:11821 [D loss: 0.240009, acc.: 55.47%] [G loss: 0.460209]\n",
      "epoch:12 step:11822 [D loss: 0.218999, acc.: 62.50%] [G loss: 0.460811]\n",
      "epoch:12 step:11823 [D loss: 0.214983, acc.: 67.19%] [G loss: 0.456461]\n",
      "epoch:12 step:11824 [D loss: 0.235313, acc.: 59.38%] [G loss: 0.418355]\n",
      "epoch:12 step:11825 [D loss: 0.215227, acc.: 65.62%] [G loss: 0.438684]\n",
      "epoch:12 step:11826 [D loss: 0.179636, acc.: 73.44%] [G loss: 0.474378]\n",
      "epoch:12 step:11827 [D loss: 0.249746, acc.: 57.81%] [G loss: 0.468803]\n",
      "epoch:12 step:11828 [D loss: 0.233631, acc.: 60.94%] [G loss: 0.506361]\n",
      "epoch:12 step:11829 [D loss: 0.227042, acc.: 66.41%] [G loss: 0.485460]\n",
      "epoch:12 step:11830 [D loss: 0.238572, acc.: 60.94%] [G loss: 0.440102]\n",
      "epoch:12 step:11831 [D loss: 0.240400, acc.: 57.81%] [G loss: 0.431802]\n",
      "epoch:12 step:11832 [D loss: 0.247982, acc.: 55.47%] [G loss: 0.441781]\n",
      "epoch:12 step:11833 [D loss: 0.217331, acc.: 64.84%] [G loss: 0.451783]\n",
      "epoch:12 step:11834 [D loss: 0.263238, acc.: 56.25%] [G loss: 0.445585]\n",
      "epoch:12 step:11835 [D loss: 0.210695, acc.: 67.19%] [G loss: 0.450000]\n",
      "epoch:12 step:11836 [D loss: 0.194083, acc.: 69.53%] [G loss: 0.499199]\n",
      "epoch:12 step:11837 [D loss: 0.206622, acc.: 69.53%] [G loss: 0.503863]\n",
      "epoch:12 step:11838 [D loss: 0.216432, acc.: 62.50%] [G loss: 0.451771]\n",
      "epoch:12 step:11839 [D loss: 0.212644, acc.: 65.62%] [G loss: 0.445053]\n",
      "epoch:12 step:11840 [D loss: 0.230943, acc.: 67.19%] [G loss: 0.471499]\n",
      "epoch:12 step:11841 [D loss: 0.219930, acc.: 65.62%] [G loss: 0.486384]\n",
      "epoch:12 step:11842 [D loss: 0.199782, acc.: 69.53%] [G loss: 0.455782]\n",
      "epoch:12 step:11843 [D loss: 0.211071, acc.: 68.75%] [G loss: 0.455966]\n",
      "epoch:12 step:11844 [D loss: 0.245901, acc.: 58.59%] [G loss: 0.468001]\n",
      "epoch:12 step:11845 [D loss: 0.236961, acc.: 57.81%] [G loss: 0.444654]\n",
      "epoch:12 step:11846 [D loss: 0.231238, acc.: 60.16%] [G loss: 0.421282]\n",
      "epoch:12 step:11847 [D loss: 0.247344, acc.: 57.81%] [G loss: 0.425138]\n",
      "epoch:12 step:11848 [D loss: 0.223919, acc.: 61.72%] [G loss: 0.435476]\n",
      "epoch:12 step:11849 [D loss: 0.208655, acc.: 67.19%] [G loss: 0.466651]\n",
      "epoch:12 step:11850 [D loss: 0.218488, acc.: 64.06%] [G loss: 0.428975]\n",
      "epoch:12 step:11851 [D loss: 0.222113, acc.: 64.06%] [G loss: 0.430231]\n",
      "epoch:12 step:11852 [D loss: 0.237956, acc.: 58.59%] [G loss: 0.417058]\n",
      "epoch:12 step:11853 [D loss: 0.205224, acc.: 67.19%] [G loss: 0.472212]\n",
      "epoch:12 step:11854 [D loss: 0.240086, acc.: 60.94%] [G loss: 0.427551]\n",
      "epoch:12 step:11855 [D loss: 0.204912, acc.: 66.41%] [G loss: 0.431117]\n",
      "epoch:12 step:11856 [D loss: 0.227132, acc.: 63.28%] [G loss: 0.465729]\n",
      "epoch:12 step:11857 [D loss: 0.223398, acc.: 64.06%] [G loss: 0.428891]\n",
      "epoch:12 step:11858 [D loss: 0.224027, acc.: 60.16%] [G loss: 0.443285]\n",
      "epoch:12 step:11859 [D loss: 0.239565, acc.: 64.06%] [G loss: 0.451120]\n",
      "epoch:12 step:11860 [D loss: 0.255209, acc.: 60.94%] [G loss: 0.412178]\n",
      "epoch:12 step:11861 [D loss: 0.207674, acc.: 70.31%] [G loss: 0.463643]\n",
      "epoch:12 step:11862 [D loss: 0.190296, acc.: 73.44%] [G loss: 0.519457]\n",
      "epoch:12 step:11863 [D loss: 0.260311, acc.: 59.38%] [G loss: 0.436773]\n",
      "epoch:12 step:11864 [D loss: 0.219899, acc.: 65.62%] [G loss: 0.446332]\n",
      "epoch:12 step:11865 [D loss: 0.240219, acc.: 60.94%] [G loss: 0.430813]\n",
      "epoch:12 step:11866 [D loss: 0.239385, acc.: 60.94%] [G loss: 0.471266]\n",
      "epoch:12 step:11867 [D loss: 0.227471, acc.: 63.28%] [G loss: 0.454279]\n",
      "epoch:12 step:11868 [D loss: 0.179998, acc.: 73.44%] [G loss: 0.507710]\n",
      "epoch:12 step:11869 [D loss: 0.234354, acc.: 61.72%] [G loss: 0.450254]\n",
      "epoch:12 step:11870 [D loss: 0.244224, acc.: 57.03%] [G loss: 0.423957]\n",
      "epoch:12 step:11871 [D loss: 0.196736, acc.: 75.00%] [G loss: 0.461780]\n",
      "epoch:12 step:11872 [D loss: 0.230199, acc.: 67.19%] [G loss: 0.419275]\n",
      "epoch:12 step:11873 [D loss: 0.222478, acc.: 67.19%] [G loss: 0.451451]\n",
      "epoch:12 step:11874 [D loss: 0.230225, acc.: 67.19%] [G loss: 0.427279]\n",
      "epoch:12 step:11875 [D loss: 0.203810, acc.: 66.41%] [G loss: 0.456523]\n",
      "epoch:12 step:11876 [D loss: 0.216929, acc.: 63.28%] [G loss: 0.470573]\n",
      "epoch:12 step:11877 [D loss: 0.228687, acc.: 61.72%] [G loss: 0.485126]\n",
      "epoch:12 step:11878 [D loss: 0.206688, acc.: 66.41%] [G loss: 0.528923]\n",
      "epoch:12 step:11879 [D loss: 0.215154, acc.: 63.28%] [G loss: 0.528348]\n",
      "epoch:12 step:11880 [D loss: 0.236067, acc.: 61.72%] [G loss: 0.515512]\n",
      "epoch:12 step:11881 [D loss: 0.226479, acc.: 63.28%] [G loss: 0.498662]\n",
      "epoch:12 step:11882 [D loss: 0.235263, acc.: 54.69%] [G loss: 0.439011]\n",
      "epoch:12 step:11883 [D loss: 0.229810, acc.: 60.94%] [G loss: 0.433567]\n",
      "epoch:12 step:11884 [D loss: 0.214548, acc.: 64.06%] [G loss: 0.459857]\n",
      "epoch:12 step:11885 [D loss: 0.200369, acc.: 68.75%] [G loss: 0.476022]\n",
      "epoch:12 step:11886 [D loss: 0.197853, acc.: 66.41%] [G loss: 0.508116]\n",
      "epoch:12 step:11887 [D loss: 0.215784, acc.: 63.28%] [G loss: 0.465640]\n",
      "epoch:12 step:11888 [D loss: 0.250692, acc.: 55.47%] [G loss: 0.403022]\n",
      "epoch:12 step:11889 [D loss: 0.216386, acc.: 64.06%] [G loss: 0.467522]\n",
      "epoch:12 step:11890 [D loss: 0.227233, acc.: 61.72%] [G loss: 0.455953]\n",
      "epoch:12 step:11891 [D loss: 0.196252, acc.: 71.09%] [G loss: 0.453268]\n",
      "epoch:12 step:11892 [D loss: 0.181301, acc.: 75.78%] [G loss: 0.546150]\n",
      "epoch:12 step:11893 [D loss: 0.224113, acc.: 63.28%] [G loss: 0.521084]\n",
      "epoch:12 step:11894 [D loss: 0.190688, acc.: 71.88%] [G loss: 0.521791]\n",
      "epoch:12 step:11895 [D loss: 0.214893, acc.: 64.06%] [G loss: 0.501045]\n",
      "epoch:12 step:11896 [D loss: 0.237213, acc.: 64.84%] [G loss: 0.409266]\n",
      "epoch:12 step:11897 [D loss: 0.233586, acc.: 67.97%] [G loss: 0.433203]\n",
      "epoch:12 step:11898 [D loss: 0.225021, acc.: 60.94%] [G loss: 0.439745]\n",
      "epoch:12 step:11899 [D loss: 0.246596, acc.: 60.16%] [G loss: 0.460620]\n",
      "epoch:12 step:11900 [D loss: 0.237355, acc.: 59.38%] [G loss: 0.435358]\n",
      "epoch:12 step:11901 [D loss: 0.223056, acc.: 63.28%] [G loss: 0.459366]\n",
      "epoch:12 step:11902 [D loss: 0.245607, acc.: 56.25%] [G loss: 0.406250]\n",
      "epoch:12 step:11903 [D loss: 0.212735, acc.: 67.97%] [G loss: 0.400958]\n",
      "epoch:12 step:11904 [D loss: 0.194155, acc.: 69.53%] [G loss: 0.451097]\n",
      "epoch:12 step:11905 [D loss: 0.212076, acc.: 67.97%] [G loss: 0.461272]\n",
      "epoch:12 step:11906 [D loss: 0.224624, acc.: 60.94%] [G loss: 0.483720]\n",
      "epoch:12 step:11907 [D loss: 0.233797, acc.: 54.69%] [G loss: 0.436059]\n",
      "epoch:12 step:11908 [D loss: 0.255318, acc.: 57.81%] [G loss: 0.470846]\n",
      "epoch:12 step:11909 [D loss: 0.211591, acc.: 64.06%] [G loss: 0.469304]\n",
      "epoch:12 step:11910 [D loss: 0.204815, acc.: 67.19%] [G loss: 0.462822]\n",
      "epoch:12 step:11911 [D loss: 0.227705, acc.: 60.16%] [G loss: 0.437646]\n",
      "epoch:12 step:11912 [D loss: 0.224490, acc.: 62.50%] [G loss: 0.440785]\n",
      "epoch:12 step:11913 [D loss: 0.216086, acc.: 64.06%] [G loss: 0.421308]\n",
      "epoch:12 step:11914 [D loss: 0.260099, acc.: 54.69%] [G loss: 0.389163]\n",
      "epoch:12 step:11915 [D loss: 0.228168, acc.: 65.62%] [G loss: 0.397026]\n",
      "epoch:12 step:11916 [D loss: 0.233777, acc.: 60.16%] [G loss: 0.400289]\n",
      "epoch:12 step:11917 [D loss: 0.242074, acc.: 60.16%] [G loss: 0.407129]\n",
      "epoch:12 step:11918 [D loss: 0.203424, acc.: 68.75%] [G loss: 0.446356]\n",
      "epoch:12 step:11919 [D loss: 0.235717, acc.: 60.94%] [G loss: 0.438297]\n",
      "epoch:12 step:11920 [D loss: 0.219040, acc.: 65.62%] [G loss: 0.448597]\n",
      "epoch:12 step:11921 [D loss: 0.205863, acc.: 67.97%] [G loss: 0.468221]\n",
      "epoch:12 step:11922 [D loss: 0.216446, acc.: 64.06%] [G loss: 0.464134]\n",
      "epoch:12 step:11923 [D loss: 0.225249, acc.: 66.41%] [G loss: 0.449324]\n",
      "epoch:12 step:11924 [D loss: 0.210918, acc.: 66.41%] [G loss: 0.478972]\n",
      "epoch:12 step:11925 [D loss: 0.204473, acc.: 71.09%] [G loss: 0.438798]\n",
      "epoch:12 step:11926 [D loss: 0.218462, acc.: 66.41%] [G loss: 0.432914]\n",
      "epoch:12 step:11927 [D loss: 0.238176, acc.: 57.03%] [G loss: 0.440122]\n",
      "epoch:12 step:11928 [D loss: 0.218362, acc.: 63.28%] [G loss: 0.440466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11929 [D loss: 0.226726, acc.: 66.41%] [G loss: 0.448542]\n",
      "epoch:12 step:11930 [D loss: 0.209231, acc.: 67.19%] [G loss: 0.445934]\n",
      "epoch:12 step:11931 [D loss: 0.220376, acc.: 67.97%] [G loss: 0.445942]\n",
      "epoch:12 step:11932 [D loss: 0.197059, acc.: 73.44%] [G loss: 0.453164]\n",
      "epoch:12 step:11933 [D loss: 0.239194, acc.: 59.38%] [G loss: 0.453044]\n",
      "epoch:12 step:11934 [D loss: 0.230702, acc.: 56.25%] [G loss: 0.479261]\n",
      "epoch:12 step:11935 [D loss: 0.210848, acc.: 64.06%] [G loss: 0.487951]\n",
      "epoch:12 step:11936 [D loss: 0.209060, acc.: 67.19%] [G loss: 0.509661]\n",
      "epoch:12 step:11937 [D loss: 0.187844, acc.: 73.44%] [G loss: 0.501532]\n",
      "epoch:12 step:11938 [D loss: 0.191666, acc.: 69.53%] [G loss: 0.487240]\n",
      "epoch:12 step:11939 [D loss: 0.239576, acc.: 60.16%] [G loss: 0.455616]\n",
      "epoch:12 step:11940 [D loss: 0.226342, acc.: 57.81%] [G loss: 0.478023]\n",
      "epoch:12 step:11941 [D loss: 0.242673, acc.: 54.69%] [G loss: 0.443841]\n",
      "epoch:12 step:11942 [D loss: 0.238041, acc.: 54.69%] [G loss: 0.454149]\n",
      "epoch:12 step:11943 [D loss: 0.221578, acc.: 64.84%] [G loss: 0.440755]\n",
      "epoch:12 step:11944 [D loss: 0.216455, acc.: 65.62%] [G loss: 0.451152]\n",
      "epoch:12 step:11945 [D loss: 0.208127, acc.: 65.62%] [G loss: 0.471930]\n",
      "epoch:12 step:11946 [D loss: 0.219264, acc.: 64.84%] [G loss: 0.474094]\n",
      "epoch:12 step:11947 [D loss: 0.247413, acc.: 59.38%] [G loss: 0.433190]\n",
      "epoch:12 step:11948 [D loss: 0.256921, acc.: 55.47%] [G loss: 0.377645]\n",
      "epoch:12 step:11949 [D loss: 0.206246, acc.: 66.41%] [G loss: 0.433432]\n",
      "epoch:12 step:11950 [D loss: 0.220265, acc.: 63.28%] [G loss: 0.434817]\n",
      "epoch:12 step:11951 [D loss: 0.210569, acc.: 67.19%] [G loss: 0.462083]\n",
      "epoch:12 step:11952 [D loss: 0.211043, acc.: 69.53%] [G loss: 0.444780]\n",
      "epoch:12 step:11953 [D loss: 0.204419, acc.: 70.31%] [G loss: 0.452600]\n",
      "epoch:12 step:11954 [D loss: 0.263940, acc.: 55.47%] [G loss: 0.390534]\n",
      "epoch:12 step:11955 [D loss: 0.236233, acc.: 57.81%] [G loss: 0.449329]\n",
      "epoch:12 step:11956 [D loss: 0.217122, acc.: 59.38%] [G loss: 0.453231]\n",
      "epoch:12 step:11957 [D loss: 0.238501, acc.: 61.72%] [G loss: 0.502864]\n",
      "epoch:12 step:11958 [D loss: 0.243386, acc.: 62.50%] [G loss: 0.477605]\n",
      "epoch:12 step:11959 [D loss: 0.246194, acc.: 60.94%] [G loss: 0.431343]\n",
      "epoch:12 step:11960 [D loss: 0.271416, acc.: 53.12%] [G loss: 0.404385]\n",
      "epoch:12 step:11961 [D loss: 0.233951, acc.: 60.16%] [G loss: 0.456839]\n",
      "epoch:12 step:11962 [D loss: 0.224561, acc.: 66.41%] [G loss: 0.476871]\n",
      "epoch:12 step:11963 [D loss: 0.212109, acc.: 69.53%] [G loss: 0.453762]\n",
      "epoch:12 step:11964 [D loss: 0.225103, acc.: 63.28%] [G loss: 0.491050]\n",
      "epoch:12 step:11965 [D loss: 0.232133, acc.: 57.81%] [G loss: 0.446904]\n",
      "epoch:12 step:11966 [D loss: 0.241657, acc.: 57.81%] [G loss: 0.435556]\n",
      "epoch:12 step:11967 [D loss: 0.224986, acc.: 71.88%] [G loss: 0.473966]\n",
      "epoch:12 step:11968 [D loss: 0.230011, acc.: 58.59%] [G loss: 0.480122]\n",
      "epoch:12 step:11969 [D loss: 0.220563, acc.: 65.62%] [G loss: 0.515390]\n",
      "epoch:12 step:11970 [D loss: 0.257025, acc.: 54.69%] [G loss: 0.488566]\n",
      "epoch:12 step:11971 [D loss: 0.214601, acc.: 68.75%] [G loss: 0.454772]\n",
      "epoch:12 step:11972 [D loss: 0.228605, acc.: 64.06%] [G loss: 0.406535]\n",
      "epoch:12 step:11973 [D loss: 0.203164, acc.: 65.62%] [G loss: 0.437242]\n",
      "epoch:12 step:11974 [D loss: 0.204131, acc.: 66.41%] [G loss: 0.448276]\n",
      "epoch:12 step:11975 [D loss: 0.204135, acc.: 70.31%] [G loss: 0.467198]\n",
      "epoch:12 step:11976 [D loss: 0.223793, acc.: 62.50%] [G loss: 0.463990]\n",
      "epoch:12 step:11977 [D loss: 0.211710, acc.: 67.19%] [G loss: 0.421762]\n",
      "epoch:12 step:11978 [D loss: 0.275521, acc.: 53.12%] [G loss: 0.392020]\n",
      "epoch:12 step:11979 [D loss: 0.240297, acc.: 52.34%] [G loss: 0.463325]\n",
      "epoch:12 step:11980 [D loss: 0.198107, acc.: 67.97%] [G loss: 0.456123]\n",
      "epoch:12 step:11981 [D loss: 0.207733, acc.: 64.84%] [G loss: 0.438295]\n",
      "epoch:12 step:11982 [D loss: 0.239136, acc.: 57.81%] [G loss: 0.458110]\n",
      "epoch:12 step:11983 [D loss: 0.256197, acc.: 59.38%] [G loss: 0.407182]\n",
      "epoch:12 step:11984 [D loss: 0.234465, acc.: 62.50%] [G loss: 0.458132]\n",
      "epoch:12 step:11985 [D loss: 0.220828, acc.: 64.84%] [G loss: 0.464772]\n",
      "epoch:12 step:11986 [D loss: 0.228104, acc.: 58.59%] [G loss: 0.433211]\n",
      "epoch:12 step:11987 [D loss: 0.210217, acc.: 64.06%] [G loss: 0.435686]\n",
      "epoch:12 step:11988 [D loss: 0.241033, acc.: 64.06%] [G loss: 0.476936]\n",
      "epoch:12 step:11989 [D loss: 0.223008, acc.: 60.16%] [G loss: 0.456842]\n",
      "epoch:12 step:11990 [D loss: 0.211181, acc.: 66.41%] [G loss: 0.408623]\n",
      "epoch:12 step:11991 [D loss: 0.226949, acc.: 67.19%] [G loss: 0.439379]\n",
      "epoch:12 step:11992 [D loss: 0.205302, acc.: 66.41%] [G loss: 0.451687]\n",
      "epoch:12 step:11993 [D loss: 0.222085, acc.: 62.50%] [G loss: 0.451032]\n",
      "epoch:12 step:11994 [D loss: 0.238592, acc.: 57.81%] [G loss: 0.438520]\n",
      "epoch:12 step:11995 [D loss: 0.228392, acc.: 61.72%] [G loss: 0.441155]\n",
      "epoch:12 step:11996 [D loss: 0.231381, acc.: 60.16%] [G loss: 0.420403]\n",
      "epoch:12 step:11997 [D loss: 0.228690, acc.: 60.94%] [G loss: 0.421531]\n",
      "epoch:12 step:11998 [D loss: 0.224617, acc.: 62.50%] [G loss: 0.430386]\n",
      "epoch:12 step:11999 [D loss: 0.227025, acc.: 59.38%] [G loss: 0.434082]\n",
      "epoch:12 step:12000 [D loss: 0.198292, acc.: 67.19%] [G loss: 0.478708]\n",
      "epoch:12 step:12001 [D loss: 0.227047, acc.: 63.28%] [G loss: 0.444839]\n",
      "epoch:12 step:12002 [D loss: 0.253099, acc.: 55.47%] [G loss: 0.438486]\n",
      "epoch:12 step:12003 [D loss: 0.231546, acc.: 60.94%] [G loss: 0.428615]\n",
      "epoch:12 step:12004 [D loss: 0.245373, acc.: 60.16%] [G loss: 0.414819]\n",
      "epoch:12 step:12005 [D loss: 0.244911, acc.: 59.38%] [G loss: 0.447279]\n",
      "epoch:12 step:12006 [D loss: 0.237655, acc.: 57.81%] [G loss: 0.424688]\n",
      "epoch:12 step:12007 [D loss: 0.211669, acc.: 64.06%] [G loss: 0.449561]\n",
      "epoch:12 step:12008 [D loss: 0.221022, acc.: 63.28%] [G loss: 0.479967]\n",
      "epoch:12 step:12009 [D loss: 0.277783, acc.: 52.34%] [G loss: 0.413611]\n",
      "epoch:12 step:12010 [D loss: 0.248190, acc.: 56.25%] [G loss: 0.410234]\n",
      "epoch:12 step:12011 [D loss: 0.208196, acc.: 65.62%] [G loss: 0.468634]\n",
      "epoch:12 step:12012 [D loss: 0.218700, acc.: 62.50%] [G loss: 0.466595]\n",
      "epoch:12 step:12013 [D loss: 0.200096, acc.: 64.84%] [G loss: 0.459544]\n",
      "epoch:12 step:12014 [D loss: 0.236116, acc.: 57.81%] [G loss: 0.460021]\n",
      "epoch:12 step:12015 [D loss: 0.238198, acc.: 62.50%] [G loss: 0.439553]\n",
      "epoch:12 step:12016 [D loss: 0.242570, acc.: 58.59%] [G loss: 0.490142]\n",
      "epoch:12 step:12017 [D loss: 0.189645, acc.: 72.66%] [G loss: 0.499491]\n",
      "epoch:12 step:12018 [D loss: 0.252684, acc.: 58.59%] [G loss: 0.436455]\n",
      "epoch:12 step:12019 [D loss: 0.187948, acc.: 68.75%] [G loss: 0.462017]\n",
      "epoch:12 step:12020 [D loss: 0.250750, acc.: 56.25%] [G loss: 0.454975]\n",
      "epoch:12 step:12021 [D loss: 0.214012, acc.: 67.97%] [G loss: 0.486117]\n",
      "epoch:12 step:12022 [D loss: 0.237264, acc.: 57.03%] [G loss: 0.463621]\n",
      "epoch:12 step:12023 [D loss: 0.253239, acc.: 57.03%] [G loss: 0.429805]\n",
      "epoch:12 step:12024 [D loss: 0.218150, acc.: 67.97%] [G loss: 0.505038]\n",
      "epoch:12 step:12025 [D loss: 0.185796, acc.: 71.88%] [G loss: 0.488583]\n",
      "epoch:12 step:12026 [D loss: 0.206280, acc.: 63.28%] [G loss: 0.523649]\n",
      "epoch:12 step:12027 [D loss: 0.250108, acc.: 59.38%] [G loss: 0.488917]\n",
      "epoch:12 step:12028 [D loss: 0.279734, acc.: 46.88%] [G loss: 0.409665]\n",
      "epoch:12 step:12029 [D loss: 0.242819, acc.: 59.38%] [G loss: 0.404055]\n",
      "epoch:12 step:12030 [D loss: 0.223299, acc.: 61.72%] [G loss: 0.410729]\n",
      "epoch:12 step:12031 [D loss: 0.248435, acc.: 50.78%] [G loss: 0.435702]\n",
      "epoch:12 step:12032 [D loss: 0.259040, acc.: 50.78%] [G loss: 0.395634]\n",
      "epoch:12 step:12033 [D loss: 0.221749, acc.: 61.72%] [G loss: 0.455160]\n",
      "epoch:12 step:12034 [D loss: 0.223345, acc.: 58.59%] [G loss: 0.434830]\n",
      "epoch:12 step:12035 [D loss: 0.251296, acc.: 57.81%] [G loss: 0.425924]\n",
      "epoch:12 step:12036 [D loss: 0.208200, acc.: 65.62%] [G loss: 0.439223]\n",
      "epoch:12 step:12037 [D loss: 0.212970, acc.: 65.62%] [G loss: 0.453872]\n",
      "epoch:12 step:12038 [D loss: 0.256656, acc.: 49.22%] [G loss: 0.395070]\n",
      "epoch:12 step:12039 [D loss: 0.251795, acc.: 59.38%] [G loss: 0.437935]\n",
      "epoch:12 step:12040 [D loss: 0.214048, acc.: 66.41%] [G loss: 0.499144]\n",
      "epoch:12 step:12041 [D loss: 0.240764, acc.: 58.59%] [G loss: 0.448583]\n",
      "epoch:12 step:12042 [D loss: 0.243988, acc.: 57.03%] [G loss: 0.454265]\n",
      "epoch:12 step:12043 [D loss: 0.197178, acc.: 71.88%] [G loss: 0.468517]\n",
      "epoch:12 step:12044 [D loss: 0.242153, acc.: 56.25%] [G loss: 0.419620]\n",
      "epoch:12 step:12045 [D loss: 0.230900, acc.: 63.28%] [G loss: 0.436300]\n",
      "epoch:12 step:12046 [D loss: 0.237132, acc.: 62.50%] [G loss: 0.466001]\n",
      "epoch:12 step:12047 [D loss: 0.214430, acc.: 67.19%] [G loss: 0.455164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12048 [D loss: 0.219811, acc.: 64.84%] [G loss: 0.429488]\n",
      "epoch:12 step:12049 [D loss: 0.233463, acc.: 59.38%] [G loss: 0.425439]\n",
      "epoch:12 step:12050 [D loss: 0.219103, acc.: 63.28%] [G loss: 0.492072]\n",
      "epoch:12 step:12051 [D loss: 0.209774, acc.: 67.97%] [G loss: 0.486545]\n",
      "epoch:12 step:12052 [D loss: 0.231329, acc.: 60.94%] [G loss: 0.457262]\n",
      "epoch:12 step:12053 [D loss: 0.248212, acc.: 60.16%] [G loss: 0.413613]\n",
      "epoch:12 step:12054 [D loss: 0.224584, acc.: 60.16%] [G loss: 0.460642]\n",
      "epoch:12 step:12055 [D loss: 0.241843, acc.: 59.38%] [G loss: 0.476689]\n",
      "epoch:12 step:12056 [D loss: 0.261044, acc.: 50.00%] [G loss: 0.464640]\n",
      "epoch:12 step:12057 [D loss: 0.201195, acc.: 67.19%] [G loss: 0.469390]\n",
      "epoch:12 step:12058 [D loss: 0.253705, acc.: 56.25%] [G loss: 0.437147]\n",
      "epoch:12 step:12059 [D loss: 0.196130, acc.: 67.97%] [G loss: 0.490850]\n",
      "epoch:12 step:12060 [D loss: 0.235475, acc.: 61.72%] [G loss: 0.523476]\n",
      "epoch:12 step:12061 [D loss: 0.235271, acc.: 68.75%] [G loss: 0.462090]\n",
      "epoch:12 step:12062 [D loss: 0.241418, acc.: 59.38%] [G loss: 0.447132]\n",
      "epoch:12 step:12063 [D loss: 0.219284, acc.: 64.84%] [G loss: 0.440867]\n",
      "epoch:12 step:12064 [D loss: 0.283232, acc.: 50.78%] [G loss: 0.418227]\n",
      "epoch:12 step:12065 [D loss: 0.221676, acc.: 63.28%] [G loss: 0.388434]\n",
      "epoch:12 step:12066 [D loss: 0.214198, acc.: 65.62%] [G loss: 0.456590]\n",
      "epoch:12 step:12067 [D loss: 0.212447, acc.: 67.19%] [G loss: 0.474167]\n",
      "epoch:12 step:12068 [D loss: 0.240281, acc.: 58.59%] [G loss: 0.458509]\n",
      "epoch:12 step:12069 [D loss: 0.233853, acc.: 61.72%] [G loss: 0.442000]\n",
      "epoch:12 step:12070 [D loss: 0.224908, acc.: 61.72%] [G loss: 0.461762]\n",
      "epoch:12 step:12071 [D loss: 0.240860, acc.: 50.78%] [G loss: 0.421820]\n",
      "epoch:12 step:12072 [D loss: 0.248160, acc.: 57.03%] [G loss: 0.433991]\n",
      "epoch:12 step:12073 [D loss: 0.226824, acc.: 60.94%] [G loss: 0.452143]\n",
      "epoch:12 step:12074 [D loss: 0.240188, acc.: 58.59%] [G loss: 0.433425]\n",
      "epoch:12 step:12075 [D loss: 0.246652, acc.: 55.47%] [G loss: 0.439469]\n",
      "epoch:12 step:12076 [D loss: 0.201983, acc.: 71.09%] [G loss: 0.462252]\n",
      "epoch:12 step:12077 [D loss: 0.213858, acc.: 63.28%] [G loss: 0.425959]\n",
      "epoch:12 step:12078 [D loss: 0.237324, acc.: 57.03%] [G loss: 0.417047]\n",
      "epoch:12 step:12079 [D loss: 0.200337, acc.: 72.66%] [G loss: 0.478499]\n",
      "epoch:12 step:12080 [D loss: 0.224042, acc.: 62.50%] [G loss: 0.402603]\n",
      "epoch:12 step:12081 [D loss: 0.214695, acc.: 68.75%] [G loss: 0.444272]\n",
      "epoch:12 step:12082 [D loss: 0.218768, acc.: 61.72%] [G loss: 0.430625]\n",
      "epoch:12 step:12083 [D loss: 0.208370, acc.: 69.53%] [G loss: 0.468273]\n",
      "epoch:12 step:12084 [D loss: 0.213563, acc.: 65.62%] [G loss: 0.460342]\n",
      "epoch:12 step:12085 [D loss: 0.227240, acc.: 64.06%] [G loss: 0.409033]\n",
      "epoch:12 step:12086 [D loss: 0.200462, acc.: 65.62%] [G loss: 0.445839]\n",
      "epoch:12 step:12087 [D loss: 0.226676, acc.: 63.28%] [G loss: 0.413625]\n",
      "epoch:12 step:12088 [D loss: 0.222033, acc.: 64.84%] [G loss: 0.450979]\n",
      "epoch:12 step:12089 [D loss: 0.192041, acc.: 67.97%] [G loss: 0.516711]\n",
      "epoch:12 step:12090 [D loss: 0.257442, acc.: 54.69%] [G loss: 0.467621]\n",
      "epoch:12 step:12091 [D loss: 0.229702, acc.: 60.94%] [G loss: 0.451320]\n",
      "epoch:12 step:12092 [D loss: 0.227437, acc.: 57.81%] [G loss: 0.428648]\n",
      "epoch:12 step:12093 [D loss: 0.201275, acc.: 67.97%] [G loss: 0.426602]\n",
      "epoch:12 step:12094 [D loss: 0.249646, acc.: 56.25%] [G loss: 0.408684]\n",
      "epoch:12 step:12095 [D loss: 0.236797, acc.: 56.25%] [G loss: 0.456103]\n",
      "epoch:12 step:12096 [D loss: 0.203748, acc.: 67.19%] [G loss: 0.460250]\n",
      "epoch:12 step:12097 [D loss: 0.209381, acc.: 68.75%] [G loss: 0.465648]\n",
      "epoch:12 step:12098 [D loss: 0.235414, acc.: 61.72%] [G loss: 0.443412]\n",
      "epoch:12 step:12099 [D loss: 0.224129, acc.: 66.41%] [G loss: 0.487623]\n",
      "epoch:12 step:12100 [D loss: 0.249380, acc.: 60.16%] [G loss: 0.412491]\n",
      "epoch:12 step:12101 [D loss: 0.210571, acc.: 66.41%] [G loss: 0.451698]\n",
      "epoch:12 step:12102 [D loss: 0.277408, acc.: 46.88%] [G loss: 0.454911]\n",
      "epoch:12 step:12103 [D loss: 0.221212, acc.: 64.84%] [G loss: 0.472992]\n",
      "epoch:12 step:12104 [D loss: 0.225207, acc.: 65.62%] [G loss: 0.497796]\n",
      "epoch:12 step:12105 [D loss: 0.250767, acc.: 58.59%] [G loss: 0.440190]\n",
      "epoch:12 step:12106 [D loss: 0.227347, acc.: 61.72%] [G loss: 0.438086]\n",
      "epoch:12 step:12107 [D loss: 0.231250, acc.: 62.50%] [G loss: 0.408814]\n",
      "epoch:12 step:12108 [D loss: 0.225267, acc.: 60.94%] [G loss: 0.428468]\n",
      "epoch:12 step:12109 [D loss: 0.236576, acc.: 57.81%] [G loss: 0.422015]\n",
      "epoch:12 step:12110 [D loss: 0.241170, acc.: 55.47%] [G loss: 0.415804]\n",
      "epoch:12 step:12111 [D loss: 0.220096, acc.: 60.16%] [G loss: 0.428372]\n",
      "epoch:12 step:12112 [D loss: 0.216978, acc.: 63.28%] [G loss: 0.417769]\n",
      "epoch:12 step:12113 [D loss: 0.247690, acc.: 55.47%] [G loss: 0.405343]\n",
      "epoch:12 step:12114 [D loss: 0.208153, acc.: 64.06%] [G loss: 0.496447]\n",
      "epoch:12 step:12115 [D loss: 0.235862, acc.: 59.38%] [G loss: 0.443937]\n",
      "epoch:12 step:12116 [D loss: 0.221439, acc.: 67.97%] [G loss: 0.449464]\n",
      "epoch:12 step:12117 [D loss: 0.213457, acc.: 69.53%] [G loss: 0.406562]\n",
      "epoch:12 step:12118 [D loss: 0.242156, acc.: 59.38%] [G loss: 0.434169]\n",
      "epoch:12 step:12119 [D loss: 0.205216, acc.: 71.09%] [G loss: 0.450924]\n",
      "epoch:12 step:12120 [D loss: 0.223530, acc.: 65.62%] [G loss: 0.463375]\n",
      "epoch:12 step:12121 [D loss: 0.223300, acc.: 60.16%] [G loss: 0.435506]\n",
      "epoch:12 step:12122 [D loss: 0.236409, acc.: 54.69%] [G loss: 0.443030]\n",
      "epoch:12 step:12123 [D loss: 0.231522, acc.: 58.59%] [G loss: 0.443305]\n",
      "epoch:12 step:12124 [D loss: 0.245529, acc.: 58.59%] [G loss: 0.413023]\n",
      "epoch:12 step:12125 [D loss: 0.228680, acc.: 66.41%] [G loss: 0.443708]\n",
      "epoch:12 step:12126 [D loss: 0.240981, acc.: 60.16%] [G loss: 0.397808]\n",
      "epoch:12 step:12127 [D loss: 0.246081, acc.: 61.72%] [G loss: 0.416607]\n",
      "epoch:12 step:12128 [D loss: 0.206637, acc.: 67.97%] [G loss: 0.466093]\n",
      "epoch:12 step:12129 [D loss: 0.219443, acc.: 64.84%] [G loss: 0.457949]\n",
      "epoch:12 step:12130 [D loss: 0.195607, acc.: 71.09%] [G loss: 0.491321]\n",
      "epoch:12 step:12131 [D loss: 0.243435, acc.: 57.81%] [G loss: 0.475716]\n",
      "epoch:12 step:12132 [D loss: 0.233669, acc.: 63.28%] [G loss: 0.462246]\n",
      "epoch:12 step:12133 [D loss: 0.204967, acc.: 64.84%] [G loss: 0.444380]\n",
      "epoch:12 step:12134 [D loss: 0.204479, acc.: 64.06%] [G loss: 0.434699]\n",
      "epoch:12 step:12135 [D loss: 0.261220, acc.: 53.12%] [G loss: 0.395918]\n",
      "epoch:12 step:12136 [D loss: 0.259068, acc.: 48.44%] [G loss: 0.410770]\n",
      "epoch:12 step:12137 [D loss: 0.196830, acc.: 75.78%] [G loss: 0.445806]\n",
      "epoch:12 step:12138 [D loss: 0.222114, acc.: 65.62%] [G loss: 0.440581]\n",
      "epoch:12 step:12139 [D loss: 0.215066, acc.: 67.19%] [G loss: 0.496440]\n",
      "epoch:12 step:12140 [D loss: 0.201936, acc.: 66.41%] [G loss: 0.448463]\n",
      "epoch:12 step:12141 [D loss: 0.219114, acc.: 67.19%] [G loss: 0.461538]\n",
      "epoch:12 step:12142 [D loss: 0.198803, acc.: 70.31%] [G loss: 0.478666]\n",
      "epoch:12 step:12143 [D loss: 0.198215, acc.: 69.53%] [G loss: 0.490645]\n",
      "epoch:12 step:12144 [D loss: 0.232759, acc.: 60.16%] [G loss: 0.451360]\n",
      "epoch:12 step:12145 [D loss: 0.227720, acc.: 60.16%] [G loss: 0.463296]\n",
      "epoch:12 step:12146 [D loss: 0.234204, acc.: 57.03%] [G loss: 0.442482]\n",
      "epoch:12 step:12147 [D loss: 0.220899, acc.: 67.19%] [G loss: 0.427574]\n",
      "epoch:12 step:12148 [D loss: 0.224778, acc.: 62.50%] [G loss: 0.462863]\n",
      "epoch:12 step:12149 [D loss: 0.218306, acc.: 64.06%] [G loss: 0.469736]\n",
      "epoch:12 step:12150 [D loss: 0.232134, acc.: 61.72%] [G loss: 0.505453]\n",
      "epoch:12 step:12151 [D loss: 0.217160, acc.: 64.84%] [G loss: 0.473521]\n",
      "epoch:12 step:12152 [D loss: 0.228945, acc.: 62.50%] [G loss: 0.433636]\n",
      "epoch:12 step:12153 [D loss: 0.194395, acc.: 66.41%] [G loss: 0.489012]\n",
      "epoch:12 step:12154 [D loss: 0.242591, acc.: 55.47%] [G loss: 0.448492]\n",
      "epoch:12 step:12155 [D loss: 0.214017, acc.: 67.97%] [G loss: 0.439396]\n",
      "epoch:12 step:12156 [D loss: 0.203513, acc.: 70.31%] [G loss: 0.483009]\n",
      "epoch:12 step:12157 [D loss: 0.212506, acc.: 68.75%] [G loss: 0.448567]\n",
      "epoch:12 step:12158 [D loss: 0.230791, acc.: 67.19%] [G loss: 0.488933]\n",
      "epoch:12 step:12159 [D loss: 0.283323, acc.: 56.25%] [G loss: 0.432228]\n",
      "epoch:12 step:12160 [D loss: 0.204417, acc.: 71.09%] [G loss: 0.465803]\n",
      "epoch:12 step:12161 [D loss: 0.260921, acc.: 57.03%] [G loss: 0.448650]\n",
      "epoch:12 step:12162 [D loss: 0.182757, acc.: 76.56%] [G loss: 0.556007]\n",
      "epoch:12 step:12163 [D loss: 0.233903, acc.: 63.28%] [G loss: 0.457482]\n",
      "epoch:12 step:12164 [D loss: 0.277544, acc.: 49.22%] [G loss: 0.419573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12165 [D loss: 0.221713, acc.: 62.50%] [G loss: 0.467316]\n",
      "epoch:12 step:12166 [D loss: 0.239086, acc.: 63.28%] [G loss: 0.465226]\n",
      "epoch:12 step:12167 [D loss: 0.184159, acc.: 76.56%] [G loss: 0.504371]\n",
      "epoch:12 step:12168 [D loss: 0.189250, acc.: 67.97%] [G loss: 0.527687]\n",
      "epoch:12 step:12169 [D loss: 0.199587, acc.: 71.09%] [G loss: 0.505152]\n",
      "epoch:12 step:12170 [D loss: 0.185965, acc.: 77.34%] [G loss: 0.534343]\n",
      "epoch:12 step:12171 [D loss: 0.211425, acc.: 65.62%] [G loss: 0.541353]\n",
      "epoch:12 step:12172 [D loss: 0.293964, acc.: 52.34%] [G loss: 0.600264]\n",
      "epoch:12 step:12173 [D loss: 0.229402, acc.: 63.28%] [G loss: 0.682873]\n",
      "epoch:12 step:12174 [D loss: 0.235265, acc.: 63.28%] [G loss: 0.527806]\n",
      "epoch:12 step:12175 [D loss: 0.269096, acc.: 55.47%] [G loss: 0.436271]\n",
      "epoch:12 step:12176 [D loss: 0.270842, acc.: 49.22%] [G loss: 0.445220]\n",
      "epoch:12 step:12177 [D loss: 0.221098, acc.: 68.75%] [G loss: 0.452353]\n",
      "epoch:12 step:12178 [D loss: 0.219704, acc.: 70.31%] [G loss: 0.471653]\n",
      "epoch:12 step:12179 [D loss: 0.206686, acc.: 70.31%] [G loss: 0.489042]\n",
      "epoch:12 step:12180 [D loss: 0.197325, acc.: 72.66%] [G loss: 0.531012]\n",
      "epoch:12 step:12181 [D loss: 0.160725, acc.: 77.34%] [G loss: 0.556420]\n",
      "epoch:13 step:12182 [D loss: 0.256681, acc.: 60.16%] [G loss: 0.473628]\n",
      "epoch:13 step:12183 [D loss: 0.253580, acc.: 62.50%] [G loss: 0.443932]\n",
      "epoch:13 step:12184 [D loss: 0.215053, acc.: 62.50%] [G loss: 0.509394]\n",
      "epoch:13 step:12185 [D loss: 0.225188, acc.: 64.06%] [G loss: 0.479054]\n",
      "epoch:13 step:12186 [D loss: 0.219194, acc.: 67.19%] [G loss: 0.492479]\n",
      "epoch:13 step:12187 [D loss: 0.220318, acc.: 65.62%] [G loss: 0.475076]\n",
      "epoch:13 step:12188 [D loss: 0.214853, acc.: 65.62%] [G loss: 0.436768]\n",
      "epoch:13 step:12189 [D loss: 0.212594, acc.: 68.75%] [G loss: 0.427777]\n",
      "epoch:13 step:12190 [D loss: 0.210519, acc.: 63.28%] [G loss: 0.477923]\n",
      "epoch:13 step:12191 [D loss: 0.236403, acc.: 64.06%] [G loss: 0.471838]\n",
      "epoch:13 step:12192 [D loss: 0.192944, acc.: 70.31%] [G loss: 0.514028]\n",
      "epoch:13 step:12193 [D loss: 0.241265, acc.: 61.72%] [G loss: 0.513773]\n",
      "epoch:13 step:12194 [D loss: 0.214412, acc.: 64.84%] [G loss: 0.483025]\n",
      "epoch:13 step:12195 [D loss: 0.217029, acc.: 64.84%] [G loss: 0.470460]\n",
      "epoch:13 step:12196 [D loss: 0.215756, acc.: 60.94%] [G loss: 0.477994]\n",
      "epoch:13 step:12197 [D loss: 0.194424, acc.: 76.56%] [G loss: 0.489047]\n",
      "epoch:13 step:12198 [D loss: 0.238941, acc.: 59.38%] [G loss: 0.441900]\n",
      "epoch:13 step:12199 [D loss: 0.233704, acc.: 64.06%] [G loss: 0.436325]\n",
      "epoch:13 step:12200 [D loss: 0.253984, acc.: 53.12%] [G loss: 0.459098]\n",
      "epoch:13 step:12201 [D loss: 0.251405, acc.: 52.34%] [G loss: 0.462496]\n",
      "epoch:13 step:12202 [D loss: 0.216762, acc.: 62.50%] [G loss: 0.481216]\n",
      "epoch:13 step:12203 [D loss: 0.196287, acc.: 70.31%] [G loss: 0.561761]\n",
      "epoch:13 step:12204 [D loss: 0.248938, acc.: 63.28%] [G loss: 0.447824]\n",
      "epoch:13 step:12205 [D loss: 0.204944, acc.: 67.97%] [G loss: 0.421014]\n",
      "epoch:13 step:12206 [D loss: 0.194504, acc.: 73.44%] [G loss: 0.431960]\n",
      "epoch:13 step:12207 [D loss: 0.238623, acc.: 59.38%] [G loss: 0.436016]\n",
      "epoch:13 step:12208 [D loss: 0.232988, acc.: 60.94%] [G loss: 0.411123]\n",
      "epoch:13 step:12209 [D loss: 0.224938, acc.: 58.59%] [G loss: 0.426211]\n",
      "epoch:13 step:12210 [D loss: 0.227985, acc.: 57.81%] [G loss: 0.407289]\n",
      "epoch:13 step:12211 [D loss: 0.217788, acc.: 58.59%] [G loss: 0.447872]\n",
      "epoch:13 step:12212 [D loss: 0.236858, acc.: 59.38%] [G loss: 0.386256]\n",
      "epoch:13 step:12213 [D loss: 0.224636, acc.: 63.28%] [G loss: 0.437744]\n",
      "epoch:13 step:12214 [D loss: 0.221565, acc.: 66.41%] [G loss: 0.434373]\n",
      "epoch:13 step:12215 [D loss: 0.220656, acc.: 64.06%] [G loss: 0.443057]\n",
      "epoch:13 step:12216 [D loss: 0.225674, acc.: 64.06%] [G loss: 0.433580]\n",
      "epoch:13 step:12217 [D loss: 0.205047, acc.: 71.09%] [G loss: 0.425554]\n",
      "epoch:13 step:12218 [D loss: 0.228319, acc.: 64.06%] [G loss: 0.466509]\n",
      "epoch:13 step:12219 [D loss: 0.264297, acc.: 54.69%] [G loss: 0.451432]\n",
      "epoch:13 step:12220 [D loss: 0.217081, acc.: 66.41%] [G loss: 0.462222]\n",
      "epoch:13 step:12221 [D loss: 0.197867, acc.: 69.53%] [G loss: 0.497476]\n",
      "epoch:13 step:12222 [D loss: 0.223944, acc.: 64.06%] [G loss: 0.469074]\n",
      "epoch:13 step:12223 [D loss: 0.227865, acc.: 62.50%] [G loss: 0.428875]\n",
      "epoch:13 step:12224 [D loss: 0.237852, acc.: 63.28%] [G loss: 0.423118]\n",
      "epoch:13 step:12225 [D loss: 0.236793, acc.: 61.72%] [G loss: 0.467575]\n",
      "epoch:13 step:12226 [D loss: 0.240029, acc.: 53.91%] [G loss: 0.454822]\n",
      "epoch:13 step:12227 [D loss: 0.218359, acc.: 66.41%] [G loss: 0.472901]\n",
      "epoch:13 step:12228 [D loss: 0.216493, acc.: 62.50%] [G loss: 0.435742]\n",
      "epoch:13 step:12229 [D loss: 0.197038, acc.: 70.31%] [G loss: 0.433808]\n",
      "epoch:13 step:12230 [D loss: 0.211782, acc.: 64.06%] [G loss: 0.445924]\n",
      "epoch:13 step:12231 [D loss: 0.213988, acc.: 70.31%] [G loss: 0.437377]\n",
      "epoch:13 step:12232 [D loss: 0.249036, acc.: 59.38%] [G loss: 0.473229]\n",
      "epoch:13 step:12233 [D loss: 0.208999, acc.: 67.19%] [G loss: 0.452065]\n",
      "epoch:13 step:12234 [D loss: 0.212171, acc.: 64.06%] [G loss: 0.459590]\n",
      "epoch:13 step:12235 [D loss: 0.190555, acc.: 71.09%] [G loss: 0.528830]\n",
      "epoch:13 step:12236 [D loss: 0.207241, acc.: 66.41%] [G loss: 0.496759]\n",
      "epoch:13 step:12237 [D loss: 0.215740, acc.: 65.62%] [G loss: 0.439531]\n",
      "epoch:13 step:12238 [D loss: 0.233348, acc.: 58.59%] [G loss: 0.448200]\n",
      "epoch:13 step:12239 [D loss: 0.211620, acc.: 64.84%] [G loss: 0.455810]\n",
      "epoch:13 step:12240 [D loss: 0.189197, acc.: 70.31%] [G loss: 0.467624]\n",
      "epoch:13 step:12241 [D loss: 0.239604, acc.: 57.03%] [G loss: 0.461069]\n",
      "epoch:13 step:12242 [D loss: 0.222736, acc.: 61.72%] [G loss: 0.441160]\n",
      "epoch:13 step:12243 [D loss: 0.252375, acc.: 54.69%] [G loss: 0.412863]\n",
      "epoch:13 step:12244 [D loss: 0.233347, acc.: 62.50%] [G loss: 0.420903]\n",
      "epoch:13 step:12245 [D loss: 0.212802, acc.: 64.84%] [G loss: 0.482615]\n",
      "epoch:13 step:12246 [D loss: 0.236818, acc.: 57.03%] [G loss: 0.458300]\n",
      "epoch:13 step:12247 [D loss: 0.227431, acc.: 63.28%] [G loss: 0.455308]\n",
      "epoch:13 step:12248 [D loss: 0.220777, acc.: 65.62%] [G loss: 0.450241]\n",
      "epoch:13 step:12249 [D loss: 0.229508, acc.: 64.84%] [G loss: 0.434090]\n",
      "epoch:13 step:12250 [D loss: 0.197167, acc.: 69.53%] [G loss: 0.452207]\n",
      "epoch:13 step:12251 [D loss: 0.194581, acc.: 71.88%] [G loss: 0.500033]\n",
      "epoch:13 step:12252 [D loss: 0.239642, acc.: 54.69%] [G loss: 0.442258]\n",
      "epoch:13 step:12253 [D loss: 0.237963, acc.: 61.72%] [G loss: 0.407856]\n",
      "epoch:13 step:12254 [D loss: 0.220688, acc.: 61.72%] [G loss: 0.449601]\n",
      "epoch:13 step:12255 [D loss: 0.179666, acc.: 75.00%] [G loss: 0.498446]\n",
      "epoch:13 step:12256 [D loss: 0.229277, acc.: 64.84%] [G loss: 0.455600]\n",
      "epoch:13 step:12257 [D loss: 0.193998, acc.: 67.97%] [G loss: 0.513746]\n",
      "epoch:13 step:12258 [D loss: 0.205683, acc.: 63.28%] [G loss: 0.517933]\n",
      "epoch:13 step:12259 [D loss: 0.287076, acc.: 49.22%] [G loss: 0.450487]\n",
      "epoch:13 step:12260 [D loss: 0.239001, acc.: 63.28%] [G loss: 0.405749]\n",
      "epoch:13 step:12261 [D loss: 0.226692, acc.: 66.41%] [G loss: 0.420071]\n",
      "epoch:13 step:12262 [D loss: 0.250056, acc.: 53.12%] [G loss: 0.452836]\n",
      "epoch:13 step:12263 [D loss: 0.225218, acc.: 64.06%] [G loss: 0.450200]\n",
      "epoch:13 step:12264 [D loss: 0.214608, acc.: 65.62%] [G loss: 0.465648]\n",
      "epoch:13 step:12265 [D loss: 0.229799, acc.: 62.50%] [G loss: 0.446810]\n",
      "epoch:13 step:12266 [D loss: 0.221850, acc.: 58.59%] [G loss: 0.481745]\n",
      "epoch:13 step:12267 [D loss: 0.235441, acc.: 62.50%] [G loss: 0.409541]\n",
      "epoch:13 step:12268 [D loss: 0.214908, acc.: 66.41%] [G loss: 0.451037]\n",
      "epoch:13 step:12269 [D loss: 0.225999, acc.: 57.81%] [G loss: 0.465286]\n",
      "epoch:13 step:12270 [D loss: 0.186221, acc.: 70.31%] [G loss: 0.454626]\n",
      "epoch:13 step:12271 [D loss: 0.223091, acc.: 65.62%] [G loss: 0.457307]\n",
      "epoch:13 step:12272 [D loss: 0.234038, acc.: 62.50%] [G loss: 0.450081]\n",
      "epoch:13 step:12273 [D loss: 0.206153, acc.: 73.44%] [G loss: 0.483111]\n",
      "epoch:13 step:12274 [D loss: 0.205903, acc.: 69.53%] [G loss: 0.523284]\n",
      "epoch:13 step:12275 [D loss: 0.243699, acc.: 60.94%] [G loss: 0.495675]\n",
      "epoch:13 step:12276 [D loss: 0.237535, acc.: 64.84%] [G loss: 0.438228]\n",
      "epoch:13 step:12277 [D loss: 0.208432, acc.: 71.09%] [G loss: 0.435168]\n",
      "epoch:13 step:12278 [D loss: 0.196072, acc.: 69.53%] [G loss: 0.482412]\n",
      "epoch:13 step:12279 [D loss: 0.235876, acc.: 59.38%] [G loss: 0.450885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12280 [D loss: 0.212270, acc.: 64.84%] [G loss: 0.488814]\n",
      "epoch:13 step:12281 [D loss: 0.215385, acc.: 64.84%] [G loss: 0.456358]\n",
      "epoch:13 step:12282 [D loss: 0.203733, acc.: 66.41%] [G loss: 0.469758]\n",
      "epoch:13 step:12283 [D loss: 0.249139, acc.: 56.25%] [G loss: 0.407265]\n",
      "epoch:13 step:12284 [D loss: 0.230758, acc.: 55.47%] [G loss: 0.418182]\n",
      "epoch:13 step:12285 [D loss: 0.240128, acc.: 58.59%] [G loss: 0.398918]\n",
      "epoch:13 step:12286 [D loss: 0.244610, acc.: 53.91%] [G loss: 0.395180]\n",
      "epoch:13 step:12287 [D loss: 0.212309, acc.: 71.09%] [G loss: 0.462089]\n",
      "epoch:13 step:12288 [D loss: 0.200909, acc.: 67.19%] [G loss: 0.440659]\n",
      "epoch:13 step:12289 [D loss: 0.280630, acc.: 50.78%] [G loss: 0.446117]\n",
      "epoch:13 step:12290 [D loss: 0.291299, acc.: 47.66%] [G loss: 0.415926]\n",
      "epoch:13 step:12291 [D loss: 0.245024, acc.: 60.16%] [G loss: 0.439632]\n",
      "epoch:13 step:12292 [D loss: 0.198838, acc.: 70.31%] [G loss: 0.482659]\n",
      "epoch:13 step:12293 [D loss: 0.234388, acc.: 59.38%] [G loss: 0.477545]\n",
      "epoch:13 step:12294 [D loss: 0.231229, acc.: 60.16%] [G loss: 0.464008]\n",
      "epoch:13 step:12295 [D loss: 0.254456, acc.: 56.25%] [G loss: 0.493412]\n",
      "epoch:13 step:12296 [D loss: 0.193878, acc.: 70.31%] [G loss: 0.502018]\n",
      "epoch:13 step:12297 [D loss: 0.213698, acc.: 62.50%] [G loss: 0.496480]\n",
      "epoch:13 step:12298 [D loss: 0.230645, acc.: 60.16%] [G loss: 0.489182]\n",
      "epoch:13 step:12299 [D loss: 0.204354, acc.: 67.19%] [G loss: 0.458056]\n",
      "epoch:13 step:12300 [D loss: 0.190906, acc.: 71.09%] [G loss: 0.543675]\n",
      "epoch:13 step:12301 [D loss: 0.258591, acc.: 60.94%] [G loss: 0.472108]\n",
      "epoch:13 step:12302 [D loss: 0.227551, acc.: 66.41%] [G loss: 0.438207]\n",
      "epoch:13 step:12303 [D loss: 0.211246, acc.: 67.19%] [G loss: 0.460609]\n",
      "epoch:13 step:12304 [D loss: 0.209840, acc.: 65.62%] [G loss: 0.464982]\n",
      "epoch:13 step:12305 [D loss: 0.243906, acc.: 56.25%] [G loss: 0.446986]\n",
      "epoch:13 step:12306 [D loss: 0.233931, acc.: 63.28%] [G loss: 0.434060]\n",
      "epoch:13 step:12307 [D loss: 0.193434, acc.: 67.97%] [G loss: 0.461392]\n",
      "epoch:13 step:12308 [D loss: 0.214157, acc.: 65.62%] [G loss: 0.442172]\n",
      "epoch:13 step:12309 [D loss: 0.246473, acc.: 58.59%] [G loss: 0.438060]\n",
      "epoch:13 step:12310 [D loss: 0.223542, acc.: 62.50%] [G loss: 0.446582]\n",
      "epoch:13 step:12311 [D loss: 0.201045, acc.: 71.09%] [G loss: 0.437178]\n",
      "epoch:13 step:12312 [D loss: 0.215441, acc.: 61.72%] [G loss: 0.462368]\n",
      "epoch:13 step:12313 [D loss: 0.228356, acc.: 65.62%] [G loss: 0.427614]\n",
      "epoch:13 step:12314 [D loss: 0.261957, acc.: 55.47%] [G loss: 0.455928]\n",
      "epoch:13 step:12315 [D loss: 0.192255, acc.: 71.09%] [G loss: 0.473786]\n",
      "epoch:13 step:12316 [D loss: 0.211589, acc.: 67.19%] [G loss: 0.447511]\n",
      "epoch:13 step:12317 [D loss: 0.256255, acc.: 55.47%] [G loss: 0.446892]\n",
      "epoch:13 step:12318 [D loss: 0.261498, acc.: 57.03%] [G loss: 0.418340]\n",
      "epoch:13 step:12319 [D loss: 0.240339, acc.: 60.16%] [G loss: 0.420219]\n",
      "epoch:13 step:12320 [D loss: 0.226989, acc.: 62.50%] [G loss: 0.434637]\n",
      "epoch:13 step:12321 [D loss: 0.220511, acc.: 63.28%] [G loss: 0.448615]\n",
      "epoch:13 step:12322 [D loss: 0.238285, acc.: 60.16%] [G loss: 0.468293]\n",
      "epoch:13 step:12323 [D loss: 0.235573, acc.: 59.38%] [G loss: 0.422733]\n",
      "epoch:13 step:12324 [D loss: 0.262977, acc.: 51.56%] [G loss: 0.409416]\n",
      "epoch:13 step:12325 [D loss: 0.208895, acc.: 68.75%] [G loss: 0.431029]\n",
      "epoch:13 step:12326 [D loss: 0.240728, acc.: 56.25%] [G loss: 0.436980]\n",
      "epoch:13 step:12327 [D loss: 0.202441, acc.: 69.53%] [G loss: 0.510849]\n",
      "epoch:13 step:12328 [D loss: 0.230141, acc.: 61.72%] [G loss: 0.438085]\n",
      "epoch:13 step:12329 [D loss: 0.249778, acc.: 56.25%] [G loss: 0.426505]\n",
      "epoch:13 step:12330 [D loss: 0.195999, acc.: 67.19%] [G loss: 0.441631]\n",
      "epoch:13 step:12331 [D loss: 0.252667, acc.: 59.38%] [G loss: 0.384976]\n",
      "epoch:13 step:12332 [D loss: 0.196092, acc.: 71.09%] [G loss: 0.458613]\n",
      "epoch:13 step:12333 [D loss: 0.230788, acc.: 64.06%] [G loss: 0.483094]\n",
      "epoch:13 step:12334 [D loss: 0.240690, acc.: 56.25%] [G loss: 0.480610]\n",
      "epoch:13 step:12335 [D loss: 0.235638, acc.: 60.16%] [G loss: 0.426565]\n",
      "epoch:13 step:12336 [D loss: 0.195720, acc.: 70.31%] [G loss: 0.494854]\n",
      "epoch:13 step:12337 [D loss: 0.223453, acc.: 64.06%] [G loss: 0.427500]\n",
      "epoch:13 step:12338 [D loss: 0.224755, acc.: 62.50%] [G loss: 0.440600]\n",
      "epoch:13 step:12339 [D loss: 0.223982, acc.: 62.50%] [G loss: 0.425872]\n",
      "epoch:13 step:12340 [D loss: 0.220252, acc.: 64.84%] [G loss: 0.447975]\n",
      "epoch:13 step:12341 [D loss: 0.259472, acc.: 54.69%] [G loss: 0.455196]\n",
      "epoch:13 step:12342 [D loss: 0.233241, acc.: 60.94%] [G loss: 0.487729]\n",
      "epoch:13 step:12343 [D loss: 0.221774, acc.: 68.75%] [G loss: 0.459601]\n",
      "epoch:13 step:12344 [D loss: 0.235629, acc.: 63.28%] [G loss: 0.457757]\n",
      "epoch:13 step:12345 [D loss: 0.236790, acc.: 61.72%] [G loss: 0.415511]\n",
      "epoch:13 step:12346 [D loss: 0.225451, acc.: 64.06%] [G loss: 0.457616]\n",
      "epoch:13 step:12347 [D loss: 0.216538, acc.: 67.19%] [G loss: 0.399438]\n",
      "epoch:13 step:12348 [D loss: 0.205485, acc.: 67.97%] [G loss: 0.450490]\n",
      "epoch:13 step:12349 [D loss: 0.195746, acc.: 67.97%] [G loss: 0.455317]\n",
      "epoch:13 step:12350 [D loss: 0.229150, acc.: 64.06%] [G loss: 0.441561]\n",
      "epoch:13 step:12351 [D loss: 0.254761, acc.: 60.16%] [G loss: 0.401030]\n",
      "epoch:13 step:12352 [D loss: 0.223079, acc.: 61.72%] [G loss: 0.414439]\n",
      "epoch:13 step:12353 [D loss: 0.233431, acc.: 58.59%] [G loss: 0.411348]\n",
      "epoch:13 step:12354 [D loss: 0.231961, acc.: 63.28%] [G loss: 0.416532]\n",
      "epoch:13 step:12355 [D loss: 0.242016, acc.: 56.25%] [G loss: 0.417535]\n",
      "epoch:13 step:12356 [D loss: 0.238204, acc.: 57.03%] [G loss: 0.430282]\n",
      "epoch:13 step:12357 [D loss: 0.213425, acc.: 64.84%] [G loss: 0.408208]\n",
      "epoch:13 step:12358 [D loss: 0.238385, acc.: 60.16%] [G loss: 0.431920]\n",
      "epoch:13 step:12359 [D loss: 0.227411, acc.: 62.50%] [G loss: 0.431921]\n",
      "epoch:13 step:12360 [D loss: 0.220138, acc.: 63.28%] [G loss: 0.431878]\n",
      "epoch:13 step:12361 [D loss: 0.232404, acc.: 61.72%] [G loss: 0.452478]\n",
      "epoch:13 step:12362 [D loss: 0.223119, acc.: 62.50%] [G loss: 0.458791]\n",
      "epoch:13 step:12363 [D loss: 0.241526, acc.: 57.81%] [G loss: 0.497211]\n",
      "epoch:13 step:12364 [D loss: 0.231495, acc.: 65.62%] [G loss: 0.454431]\n",
      "epoch:13 step:12365 [D loss: 0.233154, acc.: 63.28%] [G loss: 0.452716]\n",
      "epoch:13 step:12366 [D loss: 0.229797, acc.: 64.06%] [G loss: 0.413457]\n",
      "epoch:13 step:12367 [D loss: 0.225600, acc.: 64.06%] [G loss: 0.438506]\n",
      "epoch:13 step:12368 [D loss: 0.225375, acc.: 60.94%] [G loss: 0.435008]\n",
      "epoch:13 step:12369 [D loss: 0.243661, acc.: 58.59%] [G loss: 0.464616]\n",
      "epoch:13 step:12370 [D loss: 0.247433, acc.: 60.16%] [G loss: 0.405835]\n",
      "epoch:13 step:12371 [D loss: 0.224547, acc.: 63.28%] [G loss: 0.449839]\n",
      "epoch:13 step:12372 [D loss: 0.223543, acc.: 61.72%] [G loss: 0.435027]\n",
      "epoch:13 step:12373 [D loss: 0.220262, acc.: 65.62%] [G loss: 0.443059]\n",
      "epoch:13 step:12374 [D loss: 0.217949, acc.: 64.06%] [G loss: 0.453536]\n",
      "epoch:13 step:12375 [D loss: 0.224474, acc.: 60.94%] [G loss: 0.441709]\n",
      "epoch:13 step:12376 [D loss: 0.211047, acc.: 67.97%] [G loss: 0.469940]\n",
      "epoch:13 step:12377 [D loss: 0.220659, acc.: 62.50%] [G loss: 0.431101]\n",
      "epoch:13 step:12378 [D loss: 0.226408, acc.: 58.59%] [G loss: 0.463831]\n",
      "epoch:13 step:12379 [D loss: 0.201229, acc.: 69.53%] [G loss: 0.485486]\n",
      "epoch:13 step:12380 [D loss: 0.224454, acc.: 59.38%] [G loss: 0.459154]\n",
      "epoch:13 step:12381 [D loss: 0.246324, acc.: 59.38%] [G loss: 0.434363]\n",
      "epoch:13 step:12382 [D loss: 0.223884, acc.: 63.28%] [G loss: 0.430285]\n",
      "epoch:13 step:12383 [D loss: 0.246351, acc.: 56.25%] [G loss: 0.442512]\n",
      "epoch:13 step:12384 [D loss: 0.235099, acc.: 57.03%] [G loss: 0.461848]\n",
      "epoch:13 step:12385 [D loss: 0.228782, acc.: 58.59%] [G loss: 0.482002]\n",
      "epoch:13 step:12386 [D loss: 0.208995, acc.: 62.50%] [G loss: 0.478247]\n",
      "epoch:13 step:12387 [D loss: 0.214041, acc.: 65.62%] [G loss: 0.472858]\n",
      "epoch:13 step:12388 [D loss: 0.198643, acc.: 71.09%] [G loss: 0.452696]\n",
      "epoch:13 step:12389 [D loss: 0.189232, acc.: 69.53%] [G loss: 0.469048]\n",
      "epoch:13 step:12390 [D loss: 0.199126, acc.: 67.97%] [G loss: 0.574769]\n",
      "epoch:13 step:12391 [D loss: 0.268337, acc.: 58.59%] [G loss: 0.452904]\n",
      "epoch:13 step:12392 [D loss: 0.241098, acc.: 60.16%] [G loss: 0.403267]\n",
      "epoch:13 step:12393 [D loss: 0.229347, acc.: 66.41%] [G loss: 0.454378]\n",
      "epoch:13 step:12394 [D loss: 0.227666, acc.: 64.84%] [G loss: 0.437225]\n",
      "epoch:13 step:12395 [D loss: 0.247460, acc.: 53.91%] [G loss: 0.437279]\n",
      "epoch:13 step:12396 [D loss: 0.262921, acc.: 56.25%] [G loss: 0.399023]\n",
      "epoch:13 step:12397 [D loss: 0.230528, acc.: 59.38%] [G loss: 0.426813]\n",
      "epoch:13 step:12398 [D loss: 0.233481, acc.: 62.50%] [G loss: 0.473140]\n",
      "epoch:13 step:12399 [D loss: 0.186882, acc.: 72.66%] [G loss: 0.500461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12400 [D loss: 0.204799, acc.: 65.62%] [G loss: 0.492111]\n",
      "epoch:13 step:12401 [D loss: 0.265122, acc.: 52.34%] [G loss: 0.455759]\n",
      "epoch:13 step:12402 [D loss: 0.193365, acc.: 71.09%] [G loss: 0.479113]\n",
      "epoch:13 step:12403 [D loss: 0.227250, acc.: 60.94%] [G loss: 0.479127]\n",
      "epoch:13 step:12404 [D loss: 0.215263, acc.: 64.06%] [G loss: 0.479139]\n",
      "epoch:13 step:12405 [D loss: 0.236339, acc.: 64.84%] [G loss: 0.455529]\n",
      "epoch:13 step:12406 [D loss: 0.238930, acc.: 60.94%] [G loss: 0.427407]\n",
      "epoch:13 step:12407 [D loss: 0.256649, acc.: 53.91%] [G loss: 0.390757]\n",
      "epoch:13 step:12408 [D loss: 0.206072, acc.: 67.97%] [G loss: 0.445763]\n",
      "epoch:13 step:12409 [D loss: 0.247827, acc.: 57.81%] [G loss: 0.412709]\n",
      "epoch:13 step:12410 [D loss: 0.204438, acc.: 71.88%] [G loss: 0.449297]\n",
      "epoch:13 step:12411 [D loss: 0.203156, acc.: 71.09%] [G loss: 0.553414]\n",
      "epoch:13 step:12412 [D loss: 0.221986, acc.: 66.41%] [G loss: 0.526033]\n",
      "epoch:13 step:12413 [D loss: 0.176990, acc.: 75.00%] [G loss: 0.520144]\n",
      "epoch:13 step:12414 [D loss: 0.262335, acc.: 60.94%] [G loss: 0.446451]\n",
      "epoch:13 step:12415 [D loss: 0.234365, acc.: 61.72%] [G loss: 0.420765]\n",
      "epoch:13 step:12416 [D loss: 0.247522, acc.: 54.69%] [G loss: 0.418778]\n",
      "epoch:13 step:12417 [D loss: 0.214370, acc.: 65.62%] [G loss: 0.463699]\n",
      "epoch:13 step:12418 [D loss: 0.212259, acc.: 67.97%] [G loss: 0.420962]\n",
      "epoch:13 step:12419 [D loss: 0.216291, acc.: 62.50%] [G loss: 0.463325]\n",
      "epoch:13 step:12420 [D loss: 0.198392, acc.: 72.66%] [G loss: 0.471191]\n",
      "epoch:13 step:12421 [D loss: 0.241750, acc.: 59.38%] [G loss: 0.422844]\n",
      "epoch:13 step:12422 [D loss: 0.201521, acc.: 67.97%] [G loss: 0.507496]\n",
      "epoch:13 step:12423 [D loss: 0.205028, acc.: 66.41%] [G loss: 0.487403]\n",
      "epoch:13 step:12424 [D loss: 0.235695, acc.: 60.94%] [G loss: 0.448980]\n",
      "epoch:13 step:12425 [D loss: 0.209972, acc.: 60.94%] [G loss: 0.474809]\n",
      "epoch:13 step:12426 [D loss: 0.209600, acc.: 69.53%] [G loss: 0.487279]\n",
      "epoch:13 step:12427 [D loss: 0.211434, acc.: 65.62%] [G loss: 0.461478]\n",
      "epoch:13 step:12428 [D loss: 0.210748, acc.: 63.28%] [G loss: 0.469015]\n",
      "epoch:13 step:12429 [D loss: 0.192674, acc.: 68.75%] [G loss: 0.460835]\n",
      "epoch:13 step:12430 [D loss: 0.260212, acc.: 51.56%] [G loss: 0.426118]\n",
      "epoch:13 step:12431 [D loss: 0.274679, acc.: 51.56%] [G loss: 0.424173]\n",
      "epoch:13 step:12432 [D loss: 0.243333, acc.: 60.16%] [G loss: 0.459404]\n",
      "epoch:13 step:12433 [D loss: 0.225466, acc.: 61.72%] [G loss: 0.447825]\n",
      "epoch:13 step:12434 [D loss: 0.219492, acc.: 69.53%] [G loss: 0.437396]\n",
      "epoch:13 step:12435 [D loss: 0.213343, acc.: 64.84%] [G loss: 0.453144]\n",
      "epoch:13 step:12436 [D loss: 0.200523, acc.: 71.09%] [G loss: 0.476948]\n",
      "epoch:13 step:12437 [D loss: 0.211127, acc.: 64.84%] [G loss: 0.414846]\n",
      "epoch:13 step:12438 [D loss: 0.236824, acc.: 60.94%] [G loss: 0.387089]\n",
      "epoch:13 step:12439 [D loss: 0.218931, acc.: 64.06%] [G loss: 0.427296]\n",
      "epoch:13 step:12440 [D loss: 0.187370, acc.: 71.09%] [G loss: 0.483818]\n",
      "epoch:13 step:12441 [D loss: 0.216099, acc.: 64.84%] [G loss: 0.455154]\n",
      "epoch:13 step:12442 [D loss: 0.225012, acc.: 63.28%] [G loss: 0.449915]\n",
      "epoch:13 step:12443 [D loss: 0.209869, acc.: 63.28%] [G loss: 0.481091]\n",
      "epoch:13 step:12444 [D loss: 0.261281, acc.: 56.25%] [G loss: 0.438408]\n",
      "epoch:13 step:12445 [D loss: 0.195557, acc.: 71.88%] [G loss: 0.464654]\n",
      "epoch:13 step:12446 [D loss: 0.257316, acc.: 56.25%] [G loss: 0.436403]\n",
      "epoch:13 step:12447 [D loss: 0.220996, acc.: 62.50%] [G loss: 0.421743]\n",
      "epoch:13 step:12448 [D loss: 0.223427, acc.: 63.28%] [G loss: 0.423923]\n",
      "epoch:13 step:12449 [D loss: 0.244733, acc.: 54.69%] [G loss: 0.446663]\n",
      "epoch:13 step:12450 [D loss: 0.210956, acc.: 65.62%] [G loss: 0.474816]\n",
      "epoch:13 step:12451 [D loss: 0.210856, acc.: 66.41%] [G loss: 0.457601]\n",
      "epoch:13 step:12452 [D loss: 0.218583, acc.: 58.59%] [G loss: 0.417732]\n",
      "epoch:13 step:12453 [D loss: 0.224996, acc.: 64.06%] [G loss: 0.440912]\n",
      "epoch:13 step:12454 [D loss: 0.234345, acc.: 57.03%] [G loss: 0.473008]\n",
      "epoch:13 step:12455 [D loss: 0.206782, acc.: 70.31%] [G loss: 0.441161]\n",
      "epoch:13 step:12456 [D loss: 0.234516, acc.: 64.84%] [G loss: 0.460258]\n",
      "epoch:13 step:12457 [D loss: 0.217481, acc.: 64.06%] [G loss: 0.476040]\n",
      "epoch:13 step:12458 [D loss: 0.249247, acc.: 55.47%] [G loss: 0.493638]\n",
      "epoch:13 step:12459 [D loss: 0.234037, acc.: 61.72%] [G loss: 0.449615]\n",
      "epoch:13 step:12460 [D loss: 0.221999, acc.: 61.72%] [G loss: 0.444431]\n",
      "epoch:13 step:12461 [D loss: 0.228540, acc.: 63.28%] [G loss: 0.436529]\n",
      "epoch:13 step:12462 [D loss: 0.267320, acc.: 57.03%] [G loss: 0.396284]\n",
      "epoch:13 step:12463 [D loss: 0.211033, acc.: 64.84%] [G loss: 0.417183]\n",
      "epoch:13 step:12464 [D loss: 0.198710, acc.: 69.53%] [G loss: 0.446804]\n",
      "epoch:13 step:12465 [D loss: 0.215069, acc.: 65.62%] [G loss: 0.439371]\n",
      "epoch:13 step:12466 [D loss: 0.216567, acc.: 62.50%] [G loss: 0.463519]\n",
      "epoch:13 step:12467 [D loss: 0.214099, acc.: 67.19%] [G loss: 0.446973]\n",
      "epoch:13 step:12468 [D loss: 0.235597, acc.: 60.94%] [G loss: 0.452731]\n",
      "epoch:13 step:12469 [D loss: 0.241278, acc.: 63.28%] [G loss: 0.457673]\n",
      "epoch:13 step:12470 [D loss: 0.223211, acc.: 64.06%] [G loss: 0.454699]\n",
      "epoch:13 step:12471 [D loss: 0.227414, acc.: 62.50%] [G loss: 0.443738]\n",
      "epoch:13 step:12472 [D loss: 0.267496, acc.: 52.34%] [G loss: 0.399269]\n",
      "epoch:13 step:12473 [D loss: 0.241027, acc.: 57.03%] [G loss: 0.432250]\n",
      "epoch:13 step:12474 [D loss: 0.212939, acc.: 65.62%] [G loss: 0.436316]\n",
      "epoch:13 step:12475 [D loss: 0.228893, acc.: 59.38%] [G loss: 0.433908]\n",
      "epoch:13 step:12476 [D loss: 0.242362, acc.: 60.16%] [G loss: 0.418087]\n",
      "epoch:13 step:12477 [D loss: 0.204762, acc.: 72.66%] [G loss: 0.446816]\n",
      "epoch:13 step:12478 [D loss: 0.240465, acc.: 61.72%] [G loss: 0.443474]\n",
      "epoch:13 step:12479 [D loss: 0.210202, acc.: 66.41%] [G loss: 0.468064]\n",
      "epoch:13 step:12480 [D loss: 0.182328, acc.: 75.78%] [G loss: 0.471297]\n",
      "epoch:13 step:12481 [D loss: 0.219308, acc.: 66.41%] [G loss: 0.432395]\n",
      "epoch:13 step:12482 [D loss: 0.261629, acc.: 52.34%] [G loss: 0.428265]\n",
      "epoch:13 step:12483 [D loss: 0.199859, acc.: 69.53%] [G loss: 0.464455]\n",
      "epoch:13 step:12484 [D loss: 0.235452, acc.: 58.59%] [G loss: 0.458821]\n",
      "epoch:13 step:12485 [D loss: 0.203131, acc.: 64.06%] [G loss: 0.476448]\n",
      "epoch:13 step:12486 [D loss: 0.222425, acc.: 65.62%] [G loss: 0.462094]\n",
      "epoch:13 step:12487 [D loss: 0.213776, acc.: 63.28%] [G loss: 0.437671]\n",
      "epoch:13 step:12488 [D loss: 0.201787, acc.: 69.53%] [G loss: 0.438169]\n",
      "epoch:13 step:12489 [D loss: 0.234925, acc.: 60.94%] [G loss: 0.393745]\n",
      "epoch:13 step:12490 [D loss: 0.202672, acc.: 71.09%] [G loss: 0.420304]\n",
      "epoch:13 step:12491 [D loss: 0.242801, acc.: 59.38%] [G loss: 0.463010]\n",
      "epoch:13 step:12492 [D loss: 0.212290, acc.: 66.41%] [G loss: 0.468109]\n",
      "epoch:13 step:12493 [D loss: 0.195595, acc.: 68.75%] [G loss: 0.497617]\n",
      "epoch:13 step:12494 [D loss: 0.201329, acc.: 65.62%] [G loss: 0.538268]\n",
      "epoch:13 step:12495 [D loss: 0.185704, acc.: 71.09%] [G loss: 0.529028]\n",
      "epoch:13 step:12496 [D loss: 0.189012, acc.: 69.53%] [G loss: 0.501951]\n",
      "epoch:13 step:12497 [D loss: 0.300095, acc.: 48.44%] [G loss: 0.405519]\n",
      "epoch:13 step:12498 [D loss: 0.236660, acc.: 58.59%] [G loss: 0.429219]\n",
      "epoch:13 step:12499 [D loss: 0.214239, acc.: 65.62%] [G loss: 0.465846]\n",
      "epoch:13 step:12500 [D loss: 0.204346, acc.: 68.75%] [G loss: 0.422621]\n",
      "epoch:13 step:12501 [D loss: 0.205120, acc.: 67.19%] [G loss: 0.443298]\n",
      "epoch:13 step:12502 [D loss: 0.202468, acc.: 67.19%] [G loss: 0.447787]\n",
      "epoch:13 step:12503 [D loss: 0.212541, acc.: 67.97%] [G loss: 0.522876]\n",
      "epoch:13 step:12504 [D loss: 0.256789, acc.: 53.91%] [G loss: 0.439337]\n",
      "epoch:13 step:12505 [D loss: 0.225657, acc.: 70.31%] [G loss: 0.424565]\n",
      "epoch:13 step:12506 [D loss: 0.214231, acc.: 66.41%] [G loss: 0.431468]\n",
      "epoch:13 step:12507 [D loss: 0.204833, acc.: 64.84%] [G loss: 0.469965]\n",
      "epoch:13 step:12508 [D loss: 0.233412, acc.: 64.84%] [G loss: 0.481324]\n",
      "epoch:13 step:12509 [D loss: 0.222296, acc.: 67.19%] [G loss: 0.458986]\n",
      "epoch:13 step:12510 [D loss: 0.239682, acc.: 54.69%] [G loss: 0.442662]\n",
      "epoch:13 step:12511 [D loss: 0.218932, acc.: 68.75%] [G loss: 0.418830]\n",
      "epoch:13 step:12512 [D loss: 0.205333, acc.: 67.19%] [G loss: 0.450726]\n",
      "epoch:13 step:12513 [D loss: 0.211588, acc.: 69.53%] [G loss: 0.460070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12514 [D loss: 0.220293, acc.: 64.84%] [G loss: 0.438716]\n",
      "epoch:13 step:12515 [D loss: 0.224379, acc.: 60.94%] [G loss: 0.455222]\n",
      "epoch:13 step:12516 [D loss: 0.201014, acc.: 66.41%] [G loss: 0.515780]\n",
      "epoch:13 step:12517 [D loss: 0.210281, acc.: 67.19%] [G loss: 0.485134]\n",
      "epoch:13 step:12518 [D loss: 0.218279, acc.: 65.62%] [G loss: 0.459684]\n",
      "epoch:13 step:12519 [D loss: 0.225340, acc.: 63.28%] [G loss: 0.465400]\n",
      "epoch:13 step:12520 [D loss: 0.218686, acc.: 67.19%] [G loss: 0.437056]\n",
      "epoch:13 step:12521 [D loss: 0.218406, acc.: 60.94%] [G loss: 0.483385]\n",
      "epoch:13 step:12522 [D loss: 0.279640, acc.: 53.91%] [G loss: 0.425179]\n",
      "epoch:13 step:12523 [D loss: 0.226070, acc.: 60.16%] [G loss: 0.447417]\n",
      "epoch:13 step:12524 [D loss: 0.242467, acc.: 62.50%] [G loss: 0.435212]\n",
      "epoch:13 step:12525 [D loss: 0.202275, acc.: 71.88%] [G loss: 0.445645]\n",
      "epoch:13 step:12526 [D loss: 0.222444, acc.: 63.28%] [G loss: 0.498189]\n",
      "epoch:13 step:12527 [D loss: 0.213261, acc.: 64.84%] [G loss: 0.514394]\n",
      "epoch:13 step:12528 [D loss: 0.190216, acc.: 70.31%] [G loss: 0.546702]\n",
      "epoch:13 step:12529 [D loss: 0.264106, acc.: 60.16%] [G loss: 0.452460]\n",
      "epoch:13 step:12530 [D loss: 0.260451, acc.: 55.47%] [G loss: 0.415125]\n",
      "epoch:13 step:12531 [D loss: 0.210886, acc.: 72.66%] [G loss: 0.416464]\n",
      "epoch:13 step:12532 [D loss: 0.241698, acc.: 58.59%] [G loss: 0.437990]\n",
      "epoch:13 step:12533 [D loss: 0.239943, acc.: 61.72%] [G loss: 0.483024]\n",
      "epoch:13 step:12534 [D loss: 0.200508, acc.: 68.75%] [G loss: 0.490347]\n",
      "epoch:13 step:12535 [D loss: 0.190136, acc.: 70.31%] [G loss: 0.488846]\n",
      "epoch:13 step:12536 [D loss: 0.243248, acc.: 58.59%] [G loss: 0.448876]\n",
      "epoch:13 step:12537 [D loss: 0.229601, acc.: 60.94%] [G loss: 0.449294]\n",
      "epoch:13 step:12538 [D loss: 0.207198, acc.: 67.19%] [G loss: 0.424733]\n",
      "epoch:13 step:12539 [D loss: 0.218340, acc.: 64.84%] [G loss: 0.466849]\n",
      "epoch:13 step:12540 [D loss: 0.191626, acc.: 73.44%] [G loss: 0.497130]\n",
      "epoch:13 step:12541 [D loss: 0.219618, acc.: 62.50%] [G loss: 0.468164]\n",
      "epoch:13 step:12542 [D loss: 0.203880, acc.: 66.41%] [G loss: 0.483027]\n",
      "epoch:13 step:12543 [D loss: 0.231584, acc.: 60.16%] [G loss: 0.423965]\n",
      "epoch:13 step:12544 [D loss: 0.243240, acc.: 56.25%] [G loss: 0.396071]\n",
      "epoch:13 step:12545 [D loss: 0.166054, acc.: 80.47%] [G loss: 0.481228]\n",
      "epoch:13 step:12546 [D loss: 0.215766, acc.: 67.19%] [G loss: 0.444770]\n",
      "epoch:13 step:12547 [D loss: 0.237636, acc.: 57.03%] [G loss: 0.427751]\n",
      "epoch:13 step:12548 [D loss: 0.221151, acc.: 67.97%] [G loss: 0.472062]\n",
      "epoch:13 step:12549 [D loss: 0.243717, acc.: 57.81%] [G loss: 0.443303]\n",
      "epoch:13 step:12550 [D loss: 0.211783, acc.: 67.19%] [G loss: 0.403437]\n",
      "epoch:13 step:12551 [D loss: 0.226050, acc.: 64.06%] [G loss: 0.395762]\n",
      "epoch:13 step:12552 [D loss: 0.197099, acc.: 74.22%] [G loss: 0.467778]\n",
      "epoch:13 step:12553 [D loss: 0.207906, acc.: 67.19%] [G loss: 0.468483]\n",
      "epoch:13 step:12554 [D loss: 0.264084, acc.: 53.91%] [G loss: 0.414471]\n",
      "epoch:13 step:12555 [D loss: 0.202143, acc.: 64.06%] [G loss: 0.423288]\n",
      "epoch:13 step:12556 [D loss: 0.243330, acc.: 61.72%] [G loss: 0.487702]\n",
      "epoch:13 step:12557 [D loss: 0.241091, acc.: 59.38%] [G loss: 0.458302]\n",
      "epoch:13 step:12558 [D loss: 0.254617, acc.: 57.81%] [G loss: 0.400701]\n",
      "epoch:13 step:12559 [D loss: 0.234382, acc.: 62.50%] [G loss: 0.396995]\n",
      "epoch:13 step:12560 [D loss: 0.241374, acc.: 53.91%] [G loss: 0.458772]\n",
      "epoch:13 step:12561 [D loss: 0.232890, acc.: 64.84%] [G loss: 0.468904]\n",
      "epoch:13 step:12562 [D loss: 0.218356, acc.: 64.06%] [G loss: 0.446161]\n",
      "epoch:13 step:12563 [D loss: 0.220248, acc.: 64.84%] [G loss: 0.428989]\n",
      "epoch:13 step:12564 [D loss: 0.228094, acc.: 62.50%] [G loss: 0.452994]\n",
      "epoch:13 step:12565 [D loss: 0.199447, acc.: 67.97%] [G loss: 0.427485]\n",
      "epoch:13 step:12566 [D loss: 0.214369, acc.: 65.62%] [G loss: 0.441389]\n",
      "epoch:13 step:12567 [D loss: 0.216508, acc.: 66.41%] [G loss: 0.458370]\n",
      "epoch:13 step:12568 [D loss: 0.234917, acc.: 64.84%] [G loss: 0.440658]\n",
      "epoch:13 step:12569 [D loss: 0.229935, acc.: 61.72%] [G loss: 0.409268]\n",
      "epoch:13 step:12570 [D loss: 0.218877, acc.: 64.06%] [G loss: 0.478538]\n",
      "epoch:13 step:12571 [D loss: 0.237187, acc.: 57.81%] [G loss: 0.422179]\n",
      "epoch:13 step:12572 [D loss: 0.212916, acc.: 65.62%] [G loss: 0.470216]\n",
      "epoch:13 step:12573 [D loss: 0.222197, acc.: 60.94%] [G loss: 0.436795]\n",
      "epoch:13 step:12574 [D loss: 0.240233, acc.: 63.28%] [G loss: 0.460450]\n",
      "epoch:13 step:12575 [D loss: 0.216448, acc.: 68.75%] [G loss: 0.437000]\n",
      "epoch:13 step:12576 [D loss: 0.239722, acc.: 60.94%] [G loss: 0.432782]\n",
      "epoch:13 step:12577 [D loss: 0.256463, acc.: 55.47%] [G loss: 0.430167]\n",
      "epoch:13 step:12578 [D loss: 0.231020, acc.: 63.28%] [G loss: 0.434061]\n",
      "epoch:13 step:12579 [D loss: 0.219200, acc.: 66.41%] [G loss: 0.423782]\n",
      "epoch:13 step:12580 [D loss: 0.224805, acc.: 62.50%] [G loss: 0.510728]\n",
      "epoch:13 step:12581 [D loss: 0.266374, acc.: 49.22%] [G loss: 0.440287]\n",
      "epoch:13 step:12582 [D loss: 0.237852, acc.: 63.28%] [G loss: 0.430350]\n",
      "epoch:13 step:12583 [D loss: 0.221462, acc.: 67.97%] [G loss: 0.453829]\n",
      "epoch:13 step:12584 [D loss: 0.242054, acc.: 55.47%] [G loss: 0.449140]\n",
      "epoch:13 step:12585 [D loss: 0.249444, acc.: 56.25%] [G loss: 0.433862]\n",
      "epoch:13 step:12586 [D loss: 0.213652, acc.: 69.53%] [G loss: 0.444304]\n",
      "epoch:13 step:12587 [D loss: 0.222593, acc.: 64.06%] [G loss: 0.478073]\n",
      "epoch:13 step:12588 [D loss: 0.260164, acc.: 55.47%] [G loss: 0.466707]\n",
      "epoch:13 step:12589 [D loss: 0.278668, acc.: 50.78%] [G loss: 0.410893]\n",
      "epoch:13 step:12590 [D loss: 0.226285, acc.: 64.84%] [G loss: 0.418176]\n",
      "epoch:13 step:12591 [D loss: 0.205700, acc.: 70.31%] [G loss: 0.452766]\n",
      "epoch:13 step:12592 [D loss: 0.251702, acc.: 55.47%] [G loss: 0.430931]\n",
      "epoch:13 step:12593 [D loss: 0.232059, acc.: 64.06%] [G loss: 0.415811]\n",
      "epoch:13 step:12594 [D loss: 0.228010, acc.: 63.28%] [G loss: 0.443314]\n",
      "epoch:13 step:12595 [D loss: 0.217674, acc.: 67.19%] [G loss: 0.466657]\n",
      "epoch:13 step:12596 [D loss: 0.232186, acc.: 64.06%] [G loss: 0.502762]\n",
      "epoch:13 step:12597 [D loss: 0.202995, acc.: 66.41%] [G loss: 0.535985]\n",
      "epoch:13 step:12598 [D loss: 0.236165, acc.: 63.28%] [G loss: 0.512055]\n",
      "epoch:13 step:12599 [D loss: 0.255701, acc.: 53.12%] [G loss: 0.386820]\n",
      "epoch:13 step:12600 [D loss: 0.228798, acc.: 64.06%] [G loss: 0.400434]\n",
      "epoch:13 step:12601 [D loss: 0.238532, acc.: 63.28%] [G loss: 0.415262]\n",
      "epoch:13 step:12602 [D loss: 0.261564, acc.: 57.81%] [G loss: 0.426335]\n",
      "epoch:13 step:12603 [D loss: 0.237343, acc.: 60.16%] [G loss: 0.399578]\n",
      "epoch:13 step:12604 [D loss: 0.232540, acc.: 60.94%] [G loss: 0.442816]\n",
      "epoch:13 step:12605 [D loss: 0.221286, acc.: 65.62%] [G loss: 0.445090]\n",
      "epoch:13 step:12606 [D loss: 0.215056, acc.: 64.06%] [G loss: 0.458854]\n",
      "epoch:13 step:12607 [D loss: 0.195627, acc.: 72.66%] [G loss: 0.416020]\n",
      "epoch:13 step:12608 [D loss: 0.206496, acc.: 70.31%] [G loss: 0.499479]\n",
      "epoch:13 step:12609 [D loss: 0.209878, acc.: 67.19%] [G loss: 0.527980]\n",
      "epoch:13 step:12610 [D loss: 0.177029, acc.: 73.44%] [G loss: 0.530507]\n",
      "epoch:13 step:12611 [D loss: 0.204147, acc.: 68.75%] [G loss: 0.508706]\n",
      "epoch:13 step:12612 [D loss: 0.242317, acc.: 61.72%] [G loss: 0.431197]\n",
      "epoch:13 step:12613 [D loss: 0.236518, acc.: 57.81%] [G loss: 0.468352]\n",
      "epoch:13 step:12614 [D loss: 0.247829, acc.: 57.81%] [G loss: 0.416341]\n",
      "epoch:13 step:12615 [D loss: 0.210718, acc.: 66.41%] [G loss: 0.515183]\n",
      "epoch:13 step:12616 [D loss: 0.225780, acc.: 63.28%] [G loss: 0.437118]\n",
      "epoch:13 step:12617 [D loss: 0.189776, acc.: 73.44%] [G loss: 0.494279]\n",
      "epoch:13 step:12618 [D loss: 0.298158, acc.: 50.00%] [G loss: 0.413307]\n",
      "epoch:13 step:12619 [D loss: 0.239936, acc.: 59.38%] [G loss: 0.432852]\n",
      "epoch:13 step:12620 [D loss: 0.210751, acc.: 65.62%] [G loss: 0.414505]\n",
      "epoch:13 step:12621 [D loss: 0.229744, acc.: 62.50%] [G loss: 0.414009]\n",
      "epoch:13 step:12622 [D loss: 0.248820, acc.: 60.16%] [G loss: 0.444963]\n",
      "epoch:13 step:12623 [D loss: 0.241748, acc.: 60.16%] [G loss: 0.466494]\n",
      "epoch:13 step:12624 [D loss: 0.231545, acc.: 61.72%] [G loss: 0.416719]\n",
      "epoch:13 step:12625 [D loss: 0.228048, acc.: 65.62%] [G loss: 0.444836]\n",
      "epoch:13 step:12626 [D loss: 0.226248, acc.: 67.97%] [G loss: 0.465204]\n",
      "epoch:13 step:12627 [D loss: 0.223838, acc.: 62.50%] [G loss: 0.458084]\n",
      "epoch:13 step:12628 [D loss: 0.227069, acc.: 62.50%] [G loss: 0.435500]\n",
      "epoch:13 step:12629 [D loss: 0.251365, acc.: 55.47%] [G loss: 0.424730]\n",
      "epoch:13 step:12630 [D loss: 0.220416, acc.: 65.62%] [G loss: 0.434488]\n",
      "epoch:13 step:12631 [D loss: 0.236380, acc.: 64.06%] [G loss: 0.442433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12632 [D loss: 0.216170, acc.: 65.62%] [G loss: 0.464982]\n",
      "epoch:13 step:12633 [D loss: 0.224552, acc.: 62.50%] [G loss: 0.441549]\n",
      "epoch:13 step:12634 [D loss: 0.218852, acc.: 67.97%] [G loss: 0.496349]\n",
      "epoch:13 step:12635 [D loss: 0.229362, acc.: 62.50%] [G loss: 0.439302]\n",
      "epoch:13 step:12636 [D loss: 0.242569, acc.: 60.94%] [G loss: 0.438145]\n",
      "epoch:13 step:12637 [D loss: 0.238054, acc.: 64.84%] [G loss: 0.461426]\n",
      "epoch:13 step:12638 [D loss: 0.186170, acc.: 75.78%] [G loss: 0.482251]\n",
      "epoch:13 step:12639 [D loss: 0.294701, acc.: 53.91%] [G loss: 0.428653]\n",
      "epoch:13 step:12640 [D loss: 0.242407, acc.: 57.03%] [G loss: 0.437600]\n",
      "epoch:13 step:12641 [D loss: 0.237721, acc.: 60.16%] [G loss: 0.430159]\n",
      "epoch:13 step:12642 [D loss: 0.231045, acc.: 61.72%] [G loss: 0.418331]\n",
      "epoch:13 step:12643 [D loss: 0.244885, acc.: 56.25%] [G loss: 0.430257]\n",
      "epoch:13 step:12644 [D loss: 0.230486, acc.: 61.72%] [G loss: 0.430653]\n",
      "epoch:13 step:12645 [D loss: 0.234038, acc.: 57.03%] [G loss: 0.417964]\n",
      "epoch:13 step:12646 [D loss: 0.247460, acc.: 53.12%] [G loss: 0.429969]\n",
      "epoch:13 step:12647 [D loss: 0.227744, acc.: 55.47%] [G loss: 0.418996]\n",
      "epoch:13 step:12648 [D loss: 0.208883, acc.: 65.62%] [G loss: 0.480057]\n",
      "epoch:13 step:12649 [D loss: 0.228610, acc.: 63.28%] [G loss: 0.440542]\n",
      "epoch:13 step:12650 [D loss: 0.207143, acc.: 67.19%] [G loss: 0.501122]\n",
      "epoch:13 step:12651 [D loss: 0.205261, acc.: 68.75%] [G loss: 0.546631]\n",
      "epoch:13 step:12652 [D loss: 0.217216, acc.: 66.41%] [G loss: 0.532205]\n",
      "epoch:13 step:12653 [D loss: 0.189826, acc.: 75.00%] [G loss: 0.500551]\n",
      "epoch:13 step:12654 [D loss: 0.262525, acc.: 56.25%] [G loss: 0.441878]\n",
      "epoch:13 step:12655 [D loss: 0.211453, acc.: 68.75%] [G loss: 0.466735]\n",
      "epoch:13 step:12656 [D loss: 0.207621, acc.: 71.88%] [G loss: 0.451975]\n",
      "epoch:13 step:12657 [D loss: 0.222971, acc.: 64.84%] [G loss: 0.453276]\n",
      "epoch:13 step:12658 [D loss: 0.285551, acc.: 48.44%] [G loss: 0.429728]\n",
      "epoch:13 step:12659 [D loss: 0.253290, acc.: 53.12%] [G loss: 0.414240]\n",
      "epoch:13 step:12660 [D loss: 0.212542, acc.: 65.62%] [G loss: 0.407613]\n",
      "epoch:13 step:12661 [D loss: 0.211881, acc.: 67.19%] [G loss: 0.436901]\n",
      "epoch:13 step:12662 [D loss: 0.197867, acc.: 71.88%] [G loss: 0.464771]\n",
      "epoch:13 step:12663 [D loss: 0.272903, acc.: 49.22%] [G loss: 0.401839]\n",
      "epoch:13 step:12664 [D loss: 0.232445, acc.: 60.16%] [G loss: 0.449610]\n",
      "epoch:13 step:12665 [D loss: 0.194773, acc.: 68.75%] [G loss: 0.471874]\n",
      "epoch:13 step:12666 [D loss: 0.221630, acc.: 63.28%] [G loss: 0.412804]\n",
      "epoch:13 step:12667 [D loss: 0.248950, acc.: 58.59%] [G loss: 0.464591]\n",
      "epoch:13 step:12668 [D loss: 0.232984, acc.: 63.28%] [G loss: 0.462160]\n",
      "epoch:13 step:12669 [D loss: 0.202982, acc.: 71.88%] [G loss: 0.476506]\n",
      "epoch:13 step:12670 [D loss: 0.244978, acc.: 53.91%] [G loss: 0.457392]\n",
      "epoch:13 step:12671 [D loss: 0.249301, acc.: 55.47%] [G loss: 0.434678]\n",
      "epoch:13 step:12672 [D loss: 0.219806, acc.: 65.62%] [G loss: 0.478273]\n",
      "epoch:13 step:12673 [D loss: 0.229196, acc.: 61.72%] [G loss: 0.468757]\n",
      "epoch:13 step:12674 [D loss: 0.213144, acc.: 67.19%] [G loss: 0.462396]\n",
      "epoch:13 step:12675 [D loss: 0.206409, acc.: 67.97%] [G loss: 0.459812]\n",
      "epoch:13 step:12676 [D loss: 0.178457, acc.: 73.44%] [G loss: 0.464416]\n",
      "epoch:13 step:12677 [D loss: 0.203693, acc.: 69.53%] [G loss: 0.432727]\n",
      "epoch:13 step:12678 [D loss: 0.196108, acc.: 69.53%] [G loss: 0.433569]\n",
      "epoch:13 step:12679 [D loss: 0.235195, acc.: 64.06%] [G loss: 0.462802]\n",
      "epoch:13 step:12680 [D loss: 0.181265, acc.: 74.22%] [G loss: 0.494195]\n",
      "epoch:13 step:12681 [D loss: 0.236723, acc.: 57.81%] [G loss: 0.475843]\n",
      "epoch:13 step:12682 [D loss: 0.284250, acc.: 49.22%] [G loss: 0.417764]\n",
      "epoch:13 step:12683 [D loss: 0.244408, acc.: 56.25%] [G loss: 0.456174]\n",
      "epoch:13 step:12684 [D loss: 0.217942, acc.: 61.72%] [G loss: 0.490309]\n",
      "epoch:13 step:12685 [D loss: 0.195014, acc.: 71.09%] [G loss: 0.482725]\n",
      "epoch:13 step:12686 [D loss: 0.206873, acc.: 71.09%] [G loss: 0.513538]\n",
      "epoch:13 step:12687 [D loss: 0.237939, acc.: 63.28%] [G loss: 0.451598]\n",
      "epoch:13 step:12688 [D loss: 0.206146, acc.: 66.41%] [G loss: 0.430948]\n",
      "epoch:13 step:12689 [D loss: 0.176232, acc.: 73.44%] [G loss: 0.484605]\n",
      "epoch:13 step:12690 [D loss: 0.249391, acc.: 60.16%] [G loss: 0.452127]\n",
      "epoch:13 step:12691 [D loss: 0.217060, acc.: 64.84%] [G loss: 0.436507]\n",
      "epoch:13 step:12692 [D loss: 0.231703, acc.: 60.94%] [G loss: 0.459275]\n",
      "epoch:13 step:12693 [D loss: 0.201844, acc.: 69.53%] [G loss: 0.410742]\n",
      "epoch:13 step:12694 [D loss: 0.215821, acc.: 61.72%] [G loss: 0.414219]\n",
      "epoch:13 step:12695 [D loss: 0.210619, acc.: 64.84%] [G loss: 0.456367]\n",
      "epoch:13 step:12696 [D loss: 0.212693, acc.: 68.75%] [G loss: 0.426977]\n",
      "epoch:13 step:12697 [D loss: 0.229364, acc.: 62.50%] [G loss: 0.442576]\n",
      "epoch:13 step:12698 [D loss: 0.245787, acc.: 57.03%] [G loss: 0.469866]\n",
      "epoch:13 step:12699 [D loss: 0.226505, acc.: 66.41%] [G loss: 0.446190]\n",
      "epoch:13 step:12700 [D loss: 0.194970, acc.: 71.88%] [G loss: 0.472485]\n",
      "epoch:13 step:12701 [D loss: 0.196376, acc.: 70.31%] [G loss: 0.501199]\n",
      "epoch:13 step:12702 [D loss: 0.189084, acc.: 72.66%] [G loss: 0.503334]\n",
      "epoch:13 step:12703 [D loss: 0.213041, acc.: 65.62%] [G loss: 0.471154]\n",
      "epoch:13 step:12704 [D loss: 0.220720, acc.: 64.06%] [G loss: 0.471668]\n",
      "epoch:13 step:12705 [D loss: 0.204709, acc.: 74.22%] [G loss: 0.473101]\n",
      "epoch:13 step:12706 [D loss: 0.211274, acc.: 71.09%] [G loss: 0.491507]\n",
      "epoch:13 step:12707 [D loss: 0.218522, acc.: 64.84%] [G loss: 0.464988]\n",
      "epoch:13 step:12708 [D loss: 0.238139, acc.: 58.59%] [G loss: 0.464969]\n",
      "epoch:13 step:12709 [D loss: 0.262514, acc.: 52.34%] [G loss: 0.450235]\n",
      "epoch:13 step:12710 [D loss: 0.246692, acc.: 55.47%] [G loss: 0.449666]\n",
      "epoch:13 step:12711 [D loss: 0.223577, acc.: 62.50%] [G loss: 0.460733]\n",
      "epoch:13 step:12712 [D loss: 0.226549, acc.: 65.62%] [G loss: 0.442400]\n",
      "epoch:13 step:12713 [D loss: 0.236488, acc.: 57.03%] [G loss: 0.413938]\n",
      "epoch:13 step:12714 [D loss: 0.232338, acc.: 57.81%] [G loss: 0.467752]\n",
      "epoch:13 step:12715 [D loss: 0.184859, acc.: 66.41%] [G loss: 0.481184]\n",
      "epoch:13 step:12716 [D loss: 0.243919, acc.: 57.81%] [G loss: 0.466083]\n",
      "epoch:13 step:12717 [D loss: 0.215345, acc.: 62.50%] [G loss: 0.438851]\n",
      "epoch:13 step:12718 [D loss: 0.240983, acc.: 59.38%] [G loss: 0.448484]\n",
      "epoch:13 step:12719 [D loss: 0.217523, acc.: 63.28%] [G loss: 0.425659]\n",
      "epoch:13 step:12720 [D loss: 0.244586, acc.: 53.91%] [G loss: 0.460868]\n",
      "epoch:13 step:12721 [D loss: 0.206584, acc.: 65.62%] [G loss: 0.475257]\n",
      "epoch:13 step:12722 [D loss: 0.225195, acc.: 62.50%] [G loss: 0.392730]\n",
      "epoch:13 step:12723 [D loss: 0.249053, acc.: 55.47%] [G loss: 0.421552]\n",
      "epoch:13 step:12724 [D loss: 0.222359, acc.: 61.72%] [G loss: 0.456938]\n",
      "epoch:13 step:12725 [D loss: 0.234221, acc.: 68.75%] [G loss: 0.427319]\n",
      "epoch:13 step:12726 [D loss: 0.211666, acc.: 69.53%] [G loss: 0.521559]\n",
      "epoch:13 step:12727 [D loss: 0.208835, acc.: 67.97%] [G loss: 0.440496]\n",
      "epoch:13 step:12728 [D loss: 0.245292, acc.: 55.47%] [G loss: 0.457520]\n",
      "epoch:13 step:12729 [D loss: 0.205881, acc.: 68.75%] [G loss: 0.471263]\n",
      "epoch:13 step:12730 [D loss: 0.200199, acc.: 65.62%] [G loss: 0.468882]\n",
      "epoch:13 step:12731 [D loss: 0.191016, acc.: 69.53%] [G loss: 0.496046]\n",
      "epoch:13 step:12732 [D loss: 0.202380, acc.: 70.31%] [G loss: 0.519562]\n",
      "epoch:13 step:12733 [D loss: 0.204872, acc.: 66.41%] [G loss: 0.476274]\n",
      "epoch:13 step:12734 [D loss: 0.241149, acc.: 56.25%] [G loss: 0.405744]\n",
      "epoch:13 step:12735 [D loss: 0.211733, acc.: 64.84%] [G loss: 0.436072]\n",
      "epoch:13 step:12736 [D loss: 0.209480, acc.: 68.75%] [G loss: 0.429205]\n",
      "epoch:13 step:12737 [D loss: 0.197922, acc.: 74.22%] [G loss: 0.435175]\n",
      "epoch:13 step:12738 [D loss: 0.189716, acc.: 71.09%] [G loss: 0.467029]\n",
      "epoch:13 step:12739 [D loss: 0.225429, acc.: 66.41%] [G loss: 0.457397]\n",
      "epoch:13 step:12740 [D loss: 0.253934, acc.: 51.56%] [G loss: 0.490243]\n",
      "epoch:13 step:12741 [D loss: 0.224077, acc.: 60.94%] [G loss: 0.482382]\n",
      "epoch:13 step:12742 [D loss: 0.195511, acc.: 66.41%] [G loss: 0.470314]\n",
      "epoch:13 step:12743 [D loss: 0.239206, acc.: 60.16%] [G loss: 0.457437]\n",
      "epoch:13 step:12744 [D loss: 0.203318, acc.: 67.97%] [G loss: 0.472196]\n",
      "epoch:13 step:12745 [D loss: 0.178030, acc.: 74.22%] [G loss: 0.498714]\n",
      "epoch:13 step:12746 [D loss: 0.246595, acc.: 59.38%] [G loss: 0.498340]\n",
      "epoch:13 step:12747 [D loss: 0.270992, acc.: 52.34%] [G loss: 0.489220]\n",
      "epoch:13 step:12748 [D loss: 0.203885, acc.: 67.19%] [G loss: 0.489167]\n",
      "epoch:13 step:12749 [D loss: 0.207514, acc.: 69.53%] [G loss: 0.458400]\n",
      "epoch:13 step:12750 [D loss: 0.239009, acc.: 59.38%] [G loss: 0.463696]\n",
      "epoch:13 step:12751 [D loss: 0.190519, acc.: 66.41%] [G loss: 0.456129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12752 [D loss: 0.231045, acc.: 59.38%] [G loss: 0.429000]\n",
      "epoch:13 step:12753 [D loss: 0.204754, acc.: 68.75%] [G loss: 0.474756]\n",
      "epoch:13 step:12754 [D loss: 0.233647, acc.: 65.62%] [G loss: 0.478858]\n",
      "epoch:13 step:12755 [D loss: 0.206374, acc.: 73.44%] [G loss: 0.490969]\n",
      "epoch:13 step:12756 [D loss: 0.203247, acc.: 67.19%] [G loss: 0.479581]\n",
      "epoch:13 step:12757 [D loss: 0.235875, acc.: 64.06%] [G loss: 0.462293]\n",
      "epoch:13 step:12758 [D loss: 0.213770, acc.: 65.62%] [G loss: 0.451764]\n",
      "epoch:13 step:12759 [D loss: 0.237325, acc.: 56.25%] [G loss: 0.437547]\n",
      "epoch:13 step:12760 [D loss: 0.240994, acc.: 59.38%] [G loss: 0.455535]\n",
      "epoch:13 step:12761 [D loss: 0.231808, acc.: 63.28%] [G loss: 0.444449]\n",
      "epoch:13 step:12762 [D loss: 0.234801, acc.: 60.94%] [G loss: 0.445928]\n",
      "epoch:13 step:12763 [D loss: 0.196302, acc.: 75.78%] [G loss: 0.512699]\n",
      "epoch:13 step:12764 [D loss: 0.221527, acc.: 65.62%] [G loss: 0.463686]\n",
      "epoch:13 step:12765 [D loss: 0.230742, acc.: 63.28%] [G loss: 0.481011]\n",
      "epoch:13 step:12766 [D loss: 0.264065, acc.: 53.91%] [G loss: 0.463216]\n",
      "epoch:13 step:12767 [D loss: 0.238663, acc.: 58.59%] [G loss: 0.476406]\n",
      "epoch:13 step:12768 [D loss: 0.255714, acc.: 49.22%] [G loss: 0.449743]\n",
      "epoch:13 step:12769 [D loss: 0.217915, acc.: 67.19%] [G loss: 0.420569]\n",
      "epoch:13 step:12770 [D loss: 0.209939, acc.: 66.41%] [G loss: 0.469923]\n",
      "epoch:13 step:12771 [D loss: 0.278059, acc.: 50.78%] [G loss: 0.466153]\n",
      "epoch:13 step:12772 [D loss: 0.218120, acc.: 65.62%] [G loss: 0.457128]\n",
      "epoch:13 step:12773 [D loss: 0.194896, acc.: 73.44%] [G loss: 0.468628]\n",
      "epoch:13 step:12774 [D loss: 0.205491, acc.: 65.62%] [G loss: 0.486408]\n",
      "epoch:13 step:12775 [D loss: 0.241897, acc.: 59.38%] [G loss: 0.438596]\n",
      "epoch:13 step:12776 [D loss: 0.225458, acc.: 63.28%] [G loss: 0.444554]\n",
      "epoch:13 step:12777 [D loss: 0.237757, acc.: 60.94%] [G loss: 0.410733]\n",
      "epoch:13 step:12778 [D loss: 0.230334, acc.: 64.84%] [G loss: 0.398277]\n",
      "epoch:13 step:12779 [D loss: 0.196707, acc.: 73.44%] [G loss: 0.449434]\n",
      "epoch:13 step:12780 [D loss: 0.244563, acc.: 57.03%] [G loss: 0.447111]\n",
      "epoch:13 step:12781 [D loss: 0.223230, acc.: 64.06%] [G loss: 0.408913]\n",
      "epoch:13 step:12782 [D loss: 0.226877, acc.: 65.62%] [G loss: 0.446565]\n",
      "epoch:13 step:12783 [D loss: 0.236257, acc.: 60.16%] [G loss: 0.439382]\n",
      "epoch:13 step:12784 [D loss: 0.233043, acc.: 60.94%] [G loss: 0.447841]\n",
      "epoch:13 step:12785 [D loss: 0.235383, acc.: 57.81%] [G loss: 0.459094]\n",
      "epoch:13 step:12786 [D loss: 0.229965, acc.: 62.50%] [G loss: 0.417703]\n",
      "epoch:13 step:12787 [D loss: 0.247558, acc.: 53.12%] [G loss: 0.410022]\n",
      "epoch:13 step:12788 [D loss: 0.224220, acc.: 60.16%] [G loss: 0.434536]\n",
      "epoch:13 step:12789 [D loss: 0.228937, acc.: 61.72%] [G loss: 0.463996]\n",
      "epoch:13 step:12790 [D loss: 0.227008, acc.: 64.84%] [G loss: 0.462632]\n",
      "epoch:13 step:12791 [D loss: 0.230531, acc.: 61.72%] [G loss: 0.451351]\n",
      "epoch:13 step:12792 [D loss: 0.212024, acc.: 66.41%] [G loss: 0.445829]\n",
      "epoch:13 step:12793 [D loss: 0.252659, acc.: 60.94%] [G loss: 0.445438]\n",
      "epoch:13 step:12794 [D loss: 0.219410, acc.: 67.19%] [G loss: 0.416609]\n",
      "epoch:13 step:12795 [D loss: 0.224528, acc.: 60.94%] [G loss: 0.453483]\n",
      "epoch:13 step:12796 [D loss: 0.277575, acc.: 51.56%] [G loss: 0.395663]\n",
      "epoch:13 step:12797 [D loss: 0.238796, acc.: 60.16%] [G loss: 0.436585]\n",
      "epoch:13 step:12798 [D loss: 0.214521, acc.: 63.28%] [G loss: 0.447146]\n",
      "epoch:13 step:12799 [D loss: 0.235677, acc.: 61.72%] [G loss: 0.437419]\n",
      "epoch:13 step:12800 [D loss: 0.241395, acc.: 56.25%] [G loss: 0.411977]\n",
      "epoch:13 step:12801 [D loss: 0.211829, acc.: 61.72%] [G loss: 0.461980]\n",
      "epoch:13 step:12802 [D loss: 0.226735, acc.: 60.94%] [G loss: 0.444504]\n",
      "epoch:13 step:12803 [D loss: 0.237500, acc.: 55.47%] [G loss: 0.418768]\n",
      "epoch:13 step:12804 [D loss: 0.260369, acc.: 53.12%] [G loss: 0.408642]\n",
      "epoch:13 step:12805 [D loss: 0.202552, acc.: 74.22%] [G loss: 0.486034]\n",
      "epoch:13 step:12806 [D loss: 0.233639, acc.: 59.38%] [G loss: 0.441835]\n",
      "epoch:13 step:12807 [D loss: 0.252601, acc.: 53.91%] [G loss: 0.444379]\n",
      "epoch:13 step:12808 [D loss: 0.215685, acc.: 64.84%] [G loss: 0.427970]\n",
      "epoch:13 step:12809 [D loss: 0.241095, acc.: 58.59%] [G loss: 0.426670]\n",
      "epoch:13 step:12810 [D loss: 0.204361, acc.: 73.44%] [G loss: 0.395225]\n",
      "epoch:13 step:12811 [D loss: 0.235041, acc.: 60.94%] [G loss: 0.443339]\n",
      "epoch:13 step:12812 [D loss: 0.187775, acc.: 71.88%] [G loss: 0.482841]\n",
      "epoch:13 step:12813 [D loss: 0.211472, acc.: 70.31%] [G loss: 0.461358]\n",
      "epoch:13 step:12814 [D loss: 0.216727, acc.: 71.88%] [G loss: 0.434442]\n",
      "epoch:13 step:12815 [D loss: 0.187794, acc.: 73.44%] [G loss: 0.478065]\n",
      "epoch:13 step:12816 [D loss: 0.204678, acc.: 70.31%] [G loss: 0.475967]\n",
      "epoch:13 step:12817 [D loss: 0.234117, acc.: 57.81%] [G loss: 0.476248]\n",
      "epoch:13 step:12818 [D loss: 0.210476, acc.: 66.41%] [G loss: 0.481427]\n",
      "epoch:13 step:12819 [D loss: 0.200378, acc.: 67.97%] [G loss: 0.486482]\n",
      "epoch:13 step:12820 [D loss: 0.239232, acc.: 58.59%] [G loss: 0.446949]\n",
      "epoch:13 step:12821 [D loss: 0.206894, acc.: 66.41%] [G loss: 0.482285]\n",
      "epoch:13 step:12822 [D loss: 0.201329, acc.: 68.75%] [G loss: 0.488411]\n",
      "epoch:13 step:12823 [D loss: 0.201257, acc.: 67.19%] [G loss: 0.492675]\n",
      "epoch:13 step:12824 [D loss: 0.224222, acc.: 60.16%] [G loss: 0.444520]\n",
      "epoch:13 step:12825 [D loss: 0.211356, acc.: 61.72%] [G loss: 0.425374]\n",
      "epoch:13 step:12826 [D loss: 0.229158, acc.: 60.16%] [G loss: 0.452639]\n",
      "epoch:13 step:12827 [D loss: 0.222989, acc.: 63.28%] [G loss: 0.502913]\n",
      "epoch:13 step:12828 [D loss: 0.206788, acc.: 70.31%] [G loss: 0.494131]\n",
      "epoch:13 step:12829 [D loss: 0.173646, acc.: 77.34%] [G loss: 0.513928]\n",
      "epoch:13 step:12830 [D loss: 0.220519, acc.: 60.94%] [G loss: 0.517077]\n",
      "epoch:13 step:12831 [D loss: 0.194344, acc.: 73.44%] [G loss: 0.504815]\n",
      "epoch:13 step:12832 [D loss: 0.238599, acc.: 64.84%] [G loss: 0.451949]\n",
      "epoch:13 step:12833 [D loss: 0.238509, acc.: 56.25%] [G loss: 0.453165]\n",
      "epoch:13 step:12834 [D loss: 0.221318, acc.: 62.50%] [G loss: 0.442528]\n",
      "epoch:13 step:12835 [D loss: 0.196385, acc.: 65.62%] [G loss: 0.509414]\n",
      "epoch:13 step:12836 [D loss: 0.242322, acc.: 64.06%] [G loss: 0.522457]\n",
      "epoch:13 step:12837 [D loss: 0.250200, acc.: 60.16%] [G loss: 0.438478]\n",
      "epoch:13 step:12838 [D loss: 0.236257, acc.: 59.38%] [G loss: 0.457193]\n",
      "epoch:13 step:12839 [D loss: 0.234612, acc.: 60.94%] [G loss: 0.474605]\n",
      "epoch:13 step:12840 [D loss: 0.209476, acc.: 64.84%] [G loss: 0.455597]\n",
      "epoch:13 step:12841 [D loss: 0.199266, acc.: 70.31%] [G loss: 0.479011]\n",
      "epoch:13 step:12842 [D loss: 0.225522, acc.: 62.50%] [G loss: 0.464303]\n",
      "epoch:13 step:12843 [D loss: 0.236483, acc.: 58.59%] [G loss: 0.437420]\n",
      "epoch:13 step:12844 [D loss: 0.245767, acc.: 52.34%] [G loss: 0.427403]\n",
      "epoch:13 step:12845 [D loss: 0.237761, acc.: 60.16%] [G loss: 0.441304]\n",
      "epoch:13 step:12846 [D loss: 0.235335, acc.: 60.94%] [G loss: 0.469927]\n",
      "epoch:13 step:12847 [D loss: 0.218142, acc.: 64.84%] [G loss: 0.439232]\n",
      "epoch:13 step:12848 [D loss: 0.254103, acc.: 54.69%] [G loss: 0.418144]\n",
      "epoch:13 step:12849 [D loss: 0.229789, acc.: 57.81%] [G loss: 0.408358]\n",
      "epoch:13 step:12850 [D loss: 0.210374, acc.: 64.06%] [G loss: 0.406556]\n",
      "epoch:13 step:12851 [D loss: 0.219803, acc.: 73.44%] [G loss: 0.451012]\n",
      "epoch:13 step:12852 [D loss: 0.236324, acc.: 58.59%] [G loss: 0.388571]\n",
      "epoch:13 step:12853 [D loss: 0.247058, acc.: 57.03%] [G loss: 0.413490]\n",
      "epoch:13 step:12854 [D loss: 0.230260, acc.: 63.28%] [G loss: 0.422571]\n",
      "epoch:13 step:12855 [D loss: 0.206646, acc.: 69.53%] [G loss: 0.482216]\n",
      "epoch:13 step:12856 [D loss: 0.242683, acc.: 60.16%] [G loss: 0.427813]\n",
      "epoch:13 step:12857 [D loss: 0.235472, acc.: 60.16%] [G loss: 0.421724]\n",
      "epoch:13 step:12858 [D loss: 0.186610, acc.: 75.00%] [G loss: 0.424323]\n",
      "epoch:13 step:12859 [D loss: 0.236440, acc.: 62.50%] [G loss: 0.413186]\n",
      "epoch:13 step:12860 [D loss: 0.227216, acc.: 58.59%] [G loss: 0.485934]\n",
      "epoch:13 step:12861 [D loss: 0.210618, acc.: 64.84%] [G loss: 0.463158]\n",
      "epoch:13 step:12862 [D loss: 0.203024, acc.: 70.31%] [G loss: 0.438944]\n",
      "epoch:13 step:12863 [D loss: 0.244121, acc.: 54.69%] [G loss: 0.424932]\n",
      "epoch:13 step:12864 [D loss: 0.229233, acc.: 60.16%] [G loss: 0.409790]\n",
      "epoch:13 step:12865 [D loss: 0.225180, acc.: 60.16%] [G loss: 0.417955]\n",
      "epoch:13 step:12866 [D loss: 0.220239, acc.: 63.28%] [G loss: 0.413995]\n",
      "epoch:13 step:12867 [D loss: 0.218317, acc.: 65.62%] [G loss: 0.452196]\n",
      "epoch:13 step:12868 [D loss: 0.222788, acc.: 62.50%] [G loss: 0.406885]\n",
      "epoch:13 step:12869 [D loss: 0.212196, acc.: 65.62%] [G loss: 0.457811]\n",
      "epoch:13 step:12870 [D loss: 0.229620, acc.: 60.16%] [G loss: 0.453842]\n",
      "epoch:13 step:12871 [D loss: 0.232444, acc.: 60.16%] [G loss: 0.442282]\n",
      "epoch:13 step:12872 [D loss: 0.194672, acc.: 71.88%] [G loss: 0.456644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12873 [D loss: 0.218815, acc.: 60.16%] [G loss: 0.451755]\n",
      "epoch:13 step:12874 [D loss: 0.235942, acc.: 64.84%] [G loss: 0.490284]\n",
      "epoch:13 step:12875 [D loss: 0.184405, acc.: 71.88%] [G loss: 0.520053]\n",
      "epoch:13 step:12876 [D loss: 0.199861, acc.: 67.97%] [G loss: 0.496441]\n",
      "epoch:13 step:12877 [D loss: 0.243988, acc.: 57.03%] [G loss: 0.460354]\n",
      "epoch:13 step:12878 [D loss: 0.233696, acc.: 59.38%] [G loss: 0.449712]\n",
      "epoch:13 step:12879 [D loss: 0.227544, acc.: 64.06%] [G loss: 0.466467]\n",
      "epoch:13 step:12880 [D loss: 0.219839, acc.: 64.06%] [G loss: 0.458814]\n",
      "epoch:13 step:12881 [D loss: 0.214726, acc.: 61.72%] [G loss: 0.469207]\n",
      "epoch:13 step:12882 [D loss: 0.224096, acc.: 62.50%] [G loss: 0.483398]\n",
      "epoch:13 step:12883 [D loss: 0.254456, acc.: 57.81%] [G loss: 0.445346]\n",
      "epoch:13 step:12884 [D loss: 0.244576, acc.: 57.81%] [G loss: 0.437423]\n",
      "epoch:13 step:12885 [D loss: 0.268973, acc.: 50.00%] [G loss: 0.385640]\n",
      "epoch:13 step:12886 [D loss: 0.210437, acc.: 66.41%] [G loss: 0.427597]\n",
      "epoch:13 step:12887 [D loss: 0.241963, acc.: 57.03%] [G loss: 0.418049]\n",
      "epoch:13 step:12888 [D loss: 0.209134, acc.: 72.66%] [G loss: 0.442153]\n",
      "epoch:13 step:12889 [D loss: 0.214867, acc.: 64.84%] [G loss: 0.468655]\n",
      "epoch:13 step:12890 [D loss: 0.196717, acc.: 70.31%] [G loss: 0.470482]\n",
      "epoch:13 step:12891 [D loss: 0.257797, acc.: 56.25%] [G loss: 0.380280]\n",
      "epoch:13 step:12892 [D loss: 0.252955, acc.: 64.06%] [G loss: 0.471230]\n",
      "epoch:13 step:12893 [D loss: 0.215683, acc.: 62.50%] [G loss: 0.455654]\n",
      "epoch:13 step:12894 [D loss: 0.236371, acc.: 60.16%] [G loss: 0.427800]\n",
      "epoch:13 step:12895 [D loss: 0.209266, acc.: 66.41%] [G loss: 0.468526]\n",
      "epoch:13 step:12896 [D loss: 0.201597, acc.: 71.88%] [G loss: 0.427593]\n",
      "epoch:13 step:12897 [D loss: 0.239047, acc.: 59.38%] [G loss: 0.442878]\n",
      "epoch:13 step:12898 [D loss: 0.217592, acc.: 64.06%] [G loss: 0.416907]\n",
      "epoch:13 step:12899 [D loss: 0.231594, acc.: 63.28%] [G loss: 0.454903]\n",
      "epoch:13 step:12900 [D loss: 0.212064, acc.: 65.62%] [G loss: 0.470063]\n",
      "epoch:13 step:12901 [D loss: 0.219982, acc.: 64.06%] [G loss: 0.468761]\n",
      "epoch:13 step:12902 [D loss: 0.219287, acc.: 64.84%] [G loss: 0.465225]\n",
      "epoch:13 step:12903 [D loss: 0.252824, acc.: 49.22%] [G loss: 0.416861]\n",
      "epoch:13 step:12904 [D loss: 0.205682, acc.: 66.41%] [G loss: 0.493545]\n",
      "epoch:13 step:12905 [D loss: 0.186129, acc.: 71.88%] [G loss: 0.479800]\n",
      "epoch:13 step:12906 [D loss: 0.192560, acc.: 70.31%] [G loss: 0.446827]\n",
      "epoch:13 step:12907 [D loss: 0.206687, acc.: 67.97%] [G loss: 0.460661]\n",
      "epoch:13 step:12908 [D loss: 0.230959, acc.: 62.50%] [G loss: 0.404718]\n",
      "epoch:13 step:12909 [D loss: 0.210614, acc.: 67.97%] [G loss: 0.474079]\n",
      "epoch:13 step:12910 [D loss: 0.214004, acc.: 70.31%] [G loss: 0.451114]\n",
      "epoch:13 step:12911 [D loss: 0.200596, acc.: 73.44%] [G loss: 0.436245]\n",
      "epoch:13 step:12912 [D loss: 0.228304, acc.: 57.81%] [G loss: 0.436787]\n",
      "epoch:13 step:12913 [D loss: 0.219467, acc.: 66.41%] [G loss: 0.437520]\n",
      "epoch:13 step:12914 [D loss: 0.233559, acc.: 62.50%] [G loss: 0.431958]\n",
      "epoch:13 step:12915 [D loss: 0.240515, acc.: 59.38%] [G loss: 0.466591]\n",
      "epoch:13 step:12916 [D loss: 0.226685, acc.: 64.84%] [G loss: 0.444693]\n",
      "epoch:13 step:12917 [D loss: 0.226043, acc.: 61.72%] [G loss: 0.408069]\n",
      "epoch:13 step:12918 [D loss: 0.200592, acc.: 65.62%] [G loss: 0.432798]\n",
      "epoch:13 step:12919 [D loss: 0.217921, acc.: 60.94%] [G loss: 0.446799]\n",
      "epoch:13 step:12920 [D loss: 0.267245, acc.: 57.03%] [G loss: 0.423751]\n",
      "epoch:13 step:12921 [D loss: 0.238080, acc.: 60.16%] [G loss: 0.462162]\n",
      "epoch:13 step:12922 [D loss: 0.224673, acc.: 64.06%] [G loss: 0.448073]\n",
      "epoch:13 step:12923 [D loss: 0.235475, acc.: 61.72%] [G loss: 0.446523]\n",
      "epoch:13 step:12924 [D loss: 0.202458, acc.: 67.19%] [G loss: 0.462717]\n",
      "epoch:13 step:12925 [D loss: 0.238120, acc.: 60.94%] [G loss: 0.416877]\n",
      "epoch:13 step:12926 [D loss: 0.216045, acc.: 67.19%] [G loss: 0.448087]\n",
      "epoch:13 step:12927 [D loss: 0.209503, acc.: 67.19%] [G loss: 0.465210]\n",
      "epoch:13 step:12928 [D loss: 0.247479, acc.: 60.94%] [G loss: 0.412408]\n",
      "epoch:13 step:12929 [D loss: 0.215654, acc.: 67.97%] [G loss: 0.482844]\n",
      "epoch:13 step:12930 [D loss: 0.224365, acc.: 61.72%] [G loss: 0.447329]\n",
      "epoch:13 step:12931 [D loss: 0.205572, acc.: 63.28%] [G loss: 0.481518]\n",
      "epoch:13 step:12932 [D loss: 0.213006, acc.: 70.31%] [G loss: 0.453495]\n",
      "epoch:13 step:12933 [D loss: 0.234271, acc.: 60.94%] [G loss: 0.418521]\n",
      "epoch:13 step:12934 [D loss: 0.214574, acc.: 68.75%] [G loss: 0.444480]\n",
      "epoch:13 step:12935 [D loss: 0.198325, acc.: 68.75%] [G loss: 0.411373]\n",
      "epoch:13 step:12936 [D loss: 0.208733, acc.: 68.75%] [G loss: 0.434172]\n",
      "epoch:13 step:12937 [D loss: 0.213251, acc.: 71.09%] [G loss: 0.456813]\n",
      "epoch:13 step:12938 [D loss: 0.215759, acc.: 64.06%] [G loss: 0.420751]\n",
      "epoch:13 step:12939 [D loss: 0.239792, acc.: 60.16%] [G loss: 0.477148]\n",
      "epoch:13 step:12940 [D loss: 0.248257, acc.: 53.91%] [G loss: 0.412821]\n",
      "epoch:13 step:12941 [D loss: 0.205303, acc.: 68.75%] [G loss: 0.451188]\n",
      "epoch:13 step:12942 [D loss: 0.244132, acc.: 57.03%] [G loss: 0.467054]\n",
      "epoch:13 step:12943 [D loss: 0.251650, acc.: 55.47%] [G loss: 0.431722]\n",
      "epoch:13 step:12944 [D loss: 0.230049, acc.: 60.94%] [G loss: 0.422171]\n",
      "epoch:13 step:12945 [D loss: 0.229216, acc.: 59.38%] [G loss: 0.450263]\n",
      "epoch:13 step:12946 [D loss: 0.286552, acc.: 48.44%] [G loss: 0.425749]\n",
      "epoch:13 step:12947 [D loss: 0.257717, acc.: 51.56%] [G loss: 0.440560]\n",
      "epoch:13 step:12948 [D loss: 0.226189, acc.: 65.62%] [G loss: 0.438521]\n",
      "epoch:13 step:12949 [D loss: 0.253047, acc.: 57.81%] [G loss: 0.432835]\n",
      "epoch:13 step:12950 [D loss: 0.200818, acc.: 64.84%] [G loss: 0.453692]\n",
      "epoch:13 step:12951 [D loss: 0.241099, acc.: 55.47%] [G loss: 0.434905]\n",
      "epoch:13 step:12952 [D loss: 0.221514, acc.: 67.19%] [G loss: 0.442759]\n",
      "epoch:13 step:12953 [D loss: 0.262840, acc.: 53.91%] [G loss: 0.390209]\n",
      "epoch:13 step:12954 [D loss: 0.198554, acc.: 71.09%] [G loss: 0.491092]\n",
      "epoch:13 step:12955 [D loss: 0.224941, acc.: 67.19%] [G loss: 0.420474]\n",
      "epoch:13 step:12956 [D loss: 0.200584, acc.: 67.19%] [G loss: 0.485483]\n",
      "epoch:13 step:12957 [D loss: 0.216125, acc.: 64.06%] [G loss: 0.463237]\n",
      "epoch:13 step:12958 [D loss: 0.221177, acc.: 67.19%] [G loss: 0.447920]\n",
      "epoch:13 step:12959 [D loss: 0.211340, acc.: 61.72%] [G loss: 0.487740]\n",
      "epoch:13 step:12960 [D loss: 0.221175, acc.: 65.62%] [G loss: 0.441420]\n",
      "epoch:13 step:12961 [D loss: 0.219917, acc.: 67.19%] [G loss: 0.442161]\n",
      "epoch:13 step:12962 [D loss: 0.185238, acc.: 75.78%] [G loss: 0.475364]\n",
      "epoch:13 step:12963 [D loss: 0.206954, acc.: 65.62%] [G loss: 0.479671]\n",
      "epoch:13 step:12964 [D loss: 0.244625, acc.: 56.25%] [G loss: 0.520520]\n",
      "epoch:13 step:12965 [D loss: 0.290928, acc.: 46.88%] [G loss: 0.436991]\n",
      "epoch:13 step:12966 [D loss: 0.218477, acc.: 63.28%] [G loss: 0.441611]\n",
      "epoch:13 step:12967 [D loss: 0.215073, acc.: 69.53%] [G loss: 0.454139]\n",
      "epoch:13 step:12968 [D loss: 0.256168, acc.: 53.12%] [G loss: 0.407141]\n",
      "epoch:13 step:12969 [D loss: 0.245368, acc.: 57.81%] [G loss: 0.443114]\n",
      "epoch:13 step:12970 [D loss: 0.222232, acc.: 60.94%] [G loss: 0.446712]\n",
      "epoch:13 step:12971 [D loss: 0.212800, acc.: 65.62%] [G loss: 0.503818]\n",
      "epoch:13 step:12972 [D loss: 0.280921, acc.: 50.78%] [G loss: 0.401663]\n",
      "epoch:13 step:12973 [D loss: 0.198183, acc.: 72.66%] [G loss: 0.495383]\n",
      "epoch:13 step:12974 [D loss: 0.217211, acc.: 61.72%] [G loss: 0.493520]\n",
      "epoch:13 step:12975 [D loss: 0.257447, acc.: 52.34%] [G loss: 0.470258]\n",
      "epoch:13 step:12976 [D loss: 0.248640, acc.: 57.03%] [G loss: 0.444005]\n",
      "epoch:13 step:12977 [D loss: 0.212941, acc.: 63.28%] [G loss: 0.484557]\n",
      "epoch:13 step:12978 [D loss: 0.256006, acc.: 53.91%] [G loss: 0.431608]\n",
      "epoch:13 step:12979 [D loss: 0.242171, acc.: 55.47%] [G loss: 0.458841]\n",
      "epoch:13 step:12980 [D loss: 0.218450, acc.: 66.41%] [G loss: 0.442545]\n",
      "epoch:13 step:12981 [D loss: 0.250502, acc.: 53.91%] [G loss: 0.446334]\n",
      "epoch:13 step:12982 [D loss: 0.235354, acc.: 62.50%] [G loss: 0.431148]\n",
      "epoch:13 step:12983 [D loss: 0.236757, acc.: 60.94%] [G loss: 0.493284]\n",
      "epoch:13 step:12984 [D loss: 0.204414, acc.: 67.97%] [G loss: 0.505535]\n",
      "epoch:13 step:12985 [D loss: 0.214547, acc.: 67.97%] [G loss: 0.421521]\n",
      "epoch:13 step:12986 [D loss: 0.255230, acc.: 57.81%] [G loss: 0.410327]\n",
      "epoch:13 step:12987 [D loss: 0.212560, acc.: 64.06%] [G loss: 0.442837]\n",
      "epoch:13 step:12988 [D loss: 0.212941, acc.: 67.19%] [G loss: 0.469746]\n",
      "epoch:13 step:12989 [D loss: 0.233677, acc.: 57.81%] [G loss: 0.458761]\n",
      "epoch:13 step:12990 [D loss: 0.227834, acc.: 59.38%] [G loss: 0.406919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12991 [D loss: 0.221876, acc.: 66.41%] [G loss: 0.435710]\n",
      "epoch:13 step:12992 [D loss: 0.241361, acc.: 53.12%] [G loss: 0.471451]\n",
      "epoch:13 step:12993 [D loss: 0.235044, acc.: 61.72%] [G loss: 0.454748]\n",
      "epoch:13 step:12994 [D loss: 0.227240, acc.: 62.50%] [G loss: 0.428356]\n",
      "epoch:13 step:12995 [D loss: 0.228427, acc.: 64.84%] [G loss: 0.474506]\n",
      "epoch:13 step:12996 [D loss: 0.176685, acc.: 77.34%] [G loss: 0.522744]\n",
      "epoch:13 step:12997 [D loss: 0.229381, acc.: 62.50%] [G loss: 0.503538]\n",
      "epoch:13 step:12998 [D loss: 0.250497, acc.: 57.03%] [G loss: 0.440087]\n",
      "epoch:13 step:12999 [D loss: 0.241274, acc.: 60.94%] [G loss: 0.391715]\n",
      "epoch:13 step:13000 [D loss: 0.236173, acc.: 60.94%] [G loss: 0.431852]\n",
      "epoch:13 step:13001 [D loss: 0.272922, acc.: 49.22%] [G loss: 0.447814]\n",
      "epoch:13 step:13002 [D loss: 0.227220, acc.: 57.81%] [G loss: 0.460618]\n",
      "epoch:13 step:13003 [D loss: 0.202928, acc.: 70.31%] [G loss: 0.418166]\n",
      "epoch:13 step:13004 [D loss: 0.192205, acc.: 74.22%] [G loss: 0.461258]\n",
      "epoch:13 step:13005 [D loss: 0.252250, acc.: 57.81%] [G loss: 0.425405]\n",
      "epoch:13 step:13006 [D loss: 0.212499, acc.: 67.97%] [G loss: 0.451900]\n",
      "epoch:13 step:13007 [D loss: 0.227534, acc.: 60.94%] [G loss: 0.469734]\n",
      "epoch:13 step:13008 [D loss: 0.262806, acc.: 47.66%] [G loss: 0.435518]\n",
      "epoch:13 step:13009 [D loss: 0.245301, acc.: 60.94%] [G loss: 0.455847]\n",
      "epoch:13 step:13010 [D loss: 0.228533, acc.: 63.28%] [G loss: 0.452664]\n",
      "epoch:13 step:13011 [D loss: 0.248494, acc.: 58.59%] [G loss: 0.451307]\n",
      "epoch:13 step:13012 [D loss: 0.266577, acc.: 50.78%] [G loss: 0.444851]\n",
      "epoch:13 step:13013 [D loss: 0.227402, acc.: 63.28%] [G loss: 0.434977]\n",
      "epoch:13 step:13014 [D loss: 0.217719, acc.: 67.19%] [G loss: 0.460239]\n",
      "epoch:13 step:13015 [D loss: 0.248484, acc.: 60.16%] [G loss: 0.432561]\n",
      "epoch:13 step:13016 [D loss: 0.219805, acc.: 62.50%] [G loss: 0.438305]\n",
      "epoch:13 step:13017 [D loss: 0.215662, acc.: 61.72%] [G loss: 0.470399]\n",
      "epoch:13 step:13018 [D loss: 0.219150, acc.: 66.41%] [G loss: 0.429090]\n",
      "epoch:13 step:13019 [D loss: 0.227019, acc.: 65.62%] [G loss: 0.436603]\n",
      "epoch:13 step:13020 [D loss: 0.228915, acc.: 60.94%] [G loss: 0.463768]\n",
      "epoch:13 step:13021 [D loss: 0.217713, acc.: 61.72%] [G loss: 0.444743]\n",
      "epoch:13 step:13022 [D loss: 0.219491, acc.: 66.41%] [G loss: 0.432053]\n",
      "epoch:13 step:13023 [D loss: 0.197120, acc.: 68.75%] [G loss: 0.424943]\n",
      "epoch:13 step:13024 [D loss: 0.237827, acc.: 60.16%] [G loss: 0.401387]\n",
      "epoch:13 step:13025 [D loss: 0.222256, acc.: 65.62%] [G loss: 0.413848]\n",
      "epoch:13 step:13026 [D loss: 0.222922, acc.: 61.72%] [G loss: 0.489210]\n",
      "epoch:13 step:13027 [D loss: 0.225579, acc.: 61.72%] [G loss: 0.461129]\n",
      "epoch:13 step:13028 [D loss: 0.238528, acc.: 64.84%] [G loss: 0.429386]\n",
      "epoch:13 step:13029 [D loss: 0.227059, acc.: 62.50%] [G loss: 0.405782]\n",
      "epoch:13 step:13030 [D loss: 0.187946, acc.: 71.88%] [G loss: 0.448878]\n",
      "epoch:13 step:13031 [D loss: 0.232858, acc.: 57.81%] [G loss: 0.442921]\n",
      "epoch:13 step:13032 [D loss: 0.260241, acc.: 55.47%] [G loss: 0.452181]\n",
      "epoch:13 step:13033 [D loss: 0.206153, acc.: 62.50%] [G loss: 0.450491]\n",
      "epoch:13 step:13034 [D loss: 0.241736, acc.: 63.28%] [G loss: 0.443137]\n",
      "epoch:13 step:13035 [D loss: 0.206657, acc.: 70.31%] [G loss: 0.466831]\n",
      "epoch:13 step:13036 [D loss: 0.240790, acc.: 57.81%] [G loss: 0.457853]\n",
      "epoch:13 step:13037 [D loss: 0.222058, acc.: 61.72%] [G loss: 0.440195]\n",
      "epoch:13 step:13038 [D loss: 0.227247, acc.: 59.38%] [G loss: 0.407103]\n",
      "epoch:13 step:13039 [D loss: 0.271367, acc.: 53.12%] [G loss: 0.412164]\n",
      "epoch:13 step:13040 [D loss: 0.221517, acc.: 67.19%] [G loss: 0.439454]\n",
      "epoch:13 step:13041 [D loss: 0.216209, acc.: 67.97%] [G loss: 0.454597]\n",
      "epoch:13 step:13042 [D loss: 0.272260, acc.: 49.22%] [G loss: 0.421182]\n",
      "epoch:13 step:13043 [D loss: 0.250733, acc.: 53.12%] [G loss: 0.373353]\n",
      "epoch:13 step:13044 [D loss: 0.219012, acc.: 71.09%] [G loss: 0.441331]\n",
      "epoch:13 step:13045 [D loss: 0.220150, acc.: 67.97%] [G loss: 0.471954]\n",
      "epoch:13 step:13046 [D loss: 0.246650, acc.: 57.81%] [G loss: 0.394178]\n",
      "epoch:13 step:13047 [D loss: 0.231757, acc.: 61.72%] [G loss: 0.423660]\n",
      "epoch:13 step:13048 [D loss: 0.232036, acc.: 58.59%] [G loss: 0.474372]\n",
      "epoch:13 step:13049 [D loss: 0.233597, acc.: 57.03%] [G loss: 0.422202]\n",
      "epoch:13 step:13050 [D loss: 0.241420, acc.: 56.25%] [G loss: 0.446289]\n",
      "epoch:13 step:13051 [D loss: 0.224072, acc.: 64.06%] [G loss: 0.448550]\n",
      "epoch:13 step:13052 [D loss: 0.236876, acc.: 57.81%] [G loss: 0.444476]\n",
      "epoch:13 step:13053 [D loss: 0.241038, acc.: 58.59%] [G loss: 0.463410]\n",
      "epoch:13 step:13054 [D loss: 0.229665, acc.: 60.94%] [G loss: 0.449479]\n",
      "epoch:13 step:13055 [D loss: 0.225851, acc.: 62.50%] [G loss: 0.461612]\n",
      "epoch:13 step:13056 [D loss: 0.198681, acc.: 71.09%] [G loss: 0.442181]\n",
      "epoch:13 step:13057 [D loss: 0.221722, acc.: 61.72%] [G loss: 0.432614]\n",
      "epoch:13 step:13058 [D loss: 0.235242, acc.: 59.38%] [G loss: 0.433000]\n",
      "epoch:13 step:13059 [D loss: 0.231415, acc.: 62.50%] [G loss: 0.429588]\n",
      "epoch:13 step:13060 [D loss: 0.232293, acc.: 60.94%] [G loss: 0.438231]\n",
      "epoch:13 step:13061 [D loss: 0.255472, acc.: 53.12%] [G loss: 0.393345]\n",
      "epoch:13 step:13062 [D loss: 0.242969, acc.: 62.50%] [G loss: 0.411853]\n",
      "epoch:13 step:13063 [D loss: 0.229168, acc.: 58.59%] [G loss: 0.459879]\n",
      "epoch:13 step:13064 [D loss: 0.246118, acc.: 58.59%] [G loss: 0.425198]\n",
      "epoch:13 step:13065 [D loss: 0.195431, acc.: 71.09%] [G loss: 0.480441]\n",
      "epoch:13 step:13066 [D loss: 0.238169, acc.: 58.59%] [G loss: 0.503072]\n",
      "epoch:13 step:13067 [D loss: 0.183660, acc.: 71.09%] [G loss: 0.516950]\n",
      "epoch:13 step:13068 [D loss: 0.250479, acc.: 55.47%] [G loss: 0.434839]\n",
      "epoch:13 step:13069 [D loss: 0.243087, acc.: 58.59%] [G loss: 0.452547]\n",
      "epoch:13 step:13070 [D loss: 0.223719, acc.: 60.16%] [G loss: 0.446293]\n",
      "epoch:13 step:13071 [D loss: 0.234556, acc.: 58.59%] [G loss: 0.450425]\n",
      "epoch:13 step:13072 [D loss: 0.244377, acc.: 57.81%] [G loss: 0.438342]\n",
      "epoch:13 step:13073 [D loss: 0.234011, acc.: 60.94%] [G loss: 0.438025]\n",
      "epoch:13 step:13074 [D loss: 0.213846, acc.: 60.94%] [G loss: 0.404874]\n",
      "epoch:13 step:13075 [D loss: 0.212023, acc.: 62.50%] [G loss: 0.446372]\n",
      "epoch:13 step:13076 [D loss: 0.191024, acc.: 67.97%] [G loss: 0.490544]\n",
      "epoch:13 step:13077 [D loss: 0.214317, acc.: 63.28%] [G loss: 0.425561]\n",
      "epoch:13 step:13078 [D loss: 0.201821, acc.: 73.44%] [G loss: 0.467952]\n",
      "epoch:13 step:13079 [D loss: 0.203936, acc.: 67.97%] [G loss: 0.446592]\n",
      "epoch:13 step:13080 [D loss: 0.179652, acc.: 73.44%] [G loss: 0.505281]\n",
      "epoch:13 step:13081 [D loss: 0.221234, acc.: 64.06%] [G loss: 0.457478]\n",
      "epoch:13 step:13082 [D loss: 0.220890, acc.: 60.16%] [G loss: 0.479643]\n",
      "epoch:13 step:13083 [D loss: 0.207130, acc.: 64.84%] [G loss: 0.469978]\n",
      "epoch:13 step:13084 [D loss: 0.221215, acc.: 64.06%] [G loss: 0.442749]\n",
      "epoch:13 step:13085 [D loss: 0.223871, acc.: 62.50%] [G loss: 0.416729]\n",
      "epoch:13 step:13086 [D loss: 0.200990, acc.: 71.88%] [G loss: 0.444890]\n",
      "epoch:13 step:13087 [D loss: 0.241163, acc.: 61.72%] [G loss: 0.451328]\n",
      "epoch:13 step:13088 [D loss: 0.243708, acc.: 58.59%] [G loss: 0.490612]\n",
      "epoch:13 step:13089 [D loss: 0.231579, acc.: 64.84%] [G loss: 0.458216]\n",
      "epoch:13 step:13090 [D loss: 0.205364, acc.: 71.09%] [G loss: 0.488399]\n",
      "epoch:13 step:13091 [D loss: 0.222790, acc.: 64.06%] [G loss: 0.456271]\n",
      "epoch:13 step:13092 [D loss: 0.198738, acc.: 71.09%] [G loss: 0.425547]\n",
      "epoch:13 step:13093 [D loss: 0.193325, acc.: 70.31%] [G loss: 0.498929]\n",
      "epoch:13 step:13094 [D loss: 0.243792, acc.: 60.94%] [G loss: 0.452569]\n",
      "epoch:13 step:13095 [D loss: 0.228882, acc.: 60.94%] [G loss: 0.460774]\n",
      "epoch:13 step:13096 [D loss: 0.273091, acc.: 53.91%] [G loss: 0.479824]\n",
      "epoch:13 step:13097 [D loss: 0.220051, acc.: 62.50%] [G loss: 0.430975]\n",
      "epoch:13 step:13098 [D loss: 0.246106, acc.: 54.69%] [G loss: 0.463866]\n",
      "epoch:13 step:13099 [D loss: 0.187683, acc.: 73.44%] [G loss: 0.472181]\n",
      "epoch:13 step:13100 [D loss: 0.198513, acc.: 68.75%] [G loss: 0.476850]\n",
      "epoch:13 step:13101 [D loss: 0.287105, acc.: 50.78%] [G loss: 0.476061]\n",
      "epoch:13 step:13102 [D loss: 0.202898, acc.: 63.28%] [G loss: 0.490967]\n",
      "epoch:13 step:13103 [D loss: 0.245745, acc.: 58.59%] [G loss: 0.458479]\n",
      "epoch:13 step:13104 [D loss: 0.203826, acc.: 67.97%] [G loss: 0.485432]\n",
      "epoch:13 step:13105 [D loss: 0.213545, acc.: 69.53%] [G loss: 0.480009]\n",
      "epoch:13 step:13106 [D loss: 0.175079, acc.: 76.56%] [G loss: 0.563497]\n",
      "epoch:13 step:13107 [D loss: 0.166874, acc.: 78.91%] [G loss: 0.559059]\n",
      "epoch:13 step:13108 [D loss: 0.191565, acc.: 67.97%] [G loss: 0.568084]\n",
      "epoch:13 step:13109 [D loss: 0.337371, acc.: 55.47%] [G loss: 0.495042]\n",
      "epoch:13 step:13110 [D loss: 0.222433, acc.: 64.84%] [G loss: 0.553094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13111 [D loss: 0.192317, acc.: 69.53%] [G loss: 0.583970]\n",
      "epoch:13 step:13112 [D loss: 0.264343, acc.: 53.91%] [G loss: 0.398326]\n",
      "epoch:13 step:13113 [D loss: 0.254219, acc.: 55.47%] [G loss: 0.472294]\n",
      "epoch:13 step:13114 [D loss: 0.234895, acc.: 64.06%] [G loss: 0.452953]\n",
      "epoch:13 step:13115 [D loss: 0.229478, acc.: 64.06%] [G loss: 0.488020]\n",
      "epoch:13 step:13116 [D loss: 0.205179, acc.: 68.75%] [G loss: 0.537138]\n",
      "epoch:13 step:13117 [D loss: 0.156696, acc.: 82.03%] [G loss: 0.554318]\n",
      "epoch:13 step:13118 [D loss: 0.195315, acc.: 70.31%] [G loss: 0.567979]\n",
      "epoch:14 step:13119 [D loss: 0.233069, acc.: 63.28%] [G loss: 0.523738]\n",
      "epoch:14 step:13120 [D loss: 0.296577, acc.: 53.91%] [G loss: 0.443682]\n",
      "epoch:14 step:13121 [D loss: 0.232900, acc.: 61.72%] [G loss: 0.443045]\n",
      "epoch:14 step:13122 [D loss: 0.236248, acc.: 57.03%] [G loss: 0.481121]\n",
      "epoch:14 step:13123 [D loss: 0.254099, acc.: 58.59%] [G loss: 0.434324]\n",
      "epoch:14 step:13124 [D loss: 0.231673, acc.: 65.62%] [G loss: 0.465819]\n",
      "epoch:14 step:13125 [D loss: 0.223425, acc.: 58.59%] [G loss: 0.438690]\n",
      "epoch:14 step:13126 [D loss: 0.236576, acc.: 60.16%] [G loss: 0.421308]\n",
      "epoch:14 step:13127 [D loss: 0.197827, acc.: 71.09%] [G loss: 0.432586]\n",
      "epoch:14 step:13128 [D loss: 0.207307, acc.: 62.50%] [G loss: 0.501609]\n",
      "epoch:14 step:13129 [D loss: 0.207950, acc.: 67.97%] [G loss: 0.455519]\n",
      "epoch:14 step:13130 [D loss: 0.228341, acc.: 64.84%] [G loss: 0.468783]\n",
      "epoch:14 step:13131 [D loss: 0.199637, acc.: 67.97%] [G loss: 0.487628]\n",
      "epoch:14 step:13132 [D loss: 0.221127, acc.: 66.41%] [G loss: 0.428837]\n",
      "epoch:14 step:13133 [D loss: 0.170186, acc.: 72.66%] [G loss: 0.545196]\n",
      "epoch:14 step:13134 [D loss: 0.205072, acc.: 65.62%] [G loss: 0.502084]\n",
      "epoch:14 step:13135 [D loss: 0.234303, acc.: 61.72%] [G loss: 0.442928]\n",
      "epoch:14 step:13136 [D loss: 0.257501, acc.: 58.59%] [G loss: 0.447810]\n",
      "epoch:14 step:13137 [D loss: 0.238743, acc.: 60.16%] [G loss: 0.443299]\n",
      "epoch:14 step:13138 [D loss: 0.255728, acc.: 56.25%] [G loss: 0.486078]\n",
      "epoch:14 step:13139 [D loss: 0.242530, acc.: 58.59%] [G loss: 0.498407]\n",
      "epoch:14 step:13140 [D loss: 0.171173, acc.: 74.22%] [G loss: 0.510398]\n",
      "epoch:14 step:13141 [D loss: 0.258382, acc.: 55.47%] [G loss: 0.403359]\n",
      "epoch:14 step:13142 [D loss: 0.217259, acc.: 64.06%] [G loss: 0.464436]\n",
      "epoch:14 step:13143 [D loss: 0.183001, acc.: 75.78%] [G loss: 0.480003]\n",
      "epoch:14 step:13144 [D loss: 0.246315, acc.: 53.91%] [G loss: 0.440614]\n",
      "epoch:14 step:13145 [D loss: 0.222685, acc.: 56.25%] [G loss: 0.454862]\n",
      "epoch:14 step:13146 [D loss: 0.226019, acc.: 67.19%] [G loss: 0.432807]\n",
      "epoch:14 step:13147 [D loss: 0.220376, acc.: 60.94%] [G loss: 0.463938]\n",
      "epoch:14 step:13148 [D loss: 0.229935, acc.: 57.03%] [G loss: 0.454042]\n",
      "epoch:14 step:13149 [D loss: 0.258143, acc.: 52.34%] [G loss: 0.453172]\n",
      "epoch:14 step:13150 [D loss: 0.221774, acc.: 60.94%] [G loss: 0.468501]\n",
      "epoch:14 step:13151 [D loss: 0.204323, acc.: 67.97%] [G loss: 0.452423]\n",
      "epoch:14 step:13152 [D loss: 0.241302, acc.: 57.03%] [G loss: 0.424615]\n",
      "epoch:14 step:13153 [D loss: 0.228590, acc.: 67.19%] [G loss: 0.393135]\n",
      "epoch:14 step:13154 [D loss: 0.195160, acc.: 68.75%] [G loss: 0.474943]\n",
      "epoch:14 step:13155 [D loss: 0.226162, acc.: 64.06%] [G loss: 0.415782]\n",
      "epoch:14 step:13156 [D loss: 0.255052, acc.: 58.59%] [G loss: 0.385144]\n",
      "epoch:14 step:13157 [D loss: 0.227196, acc.: 64.06%] [G loss: 0.405713]\n",
      "epoch:14 step:13158 [D loss: 0.196809, acc.: 66.41%] [G loss: 0.467242]\n",
      "epoch:14 step:13159 [D loss: 0.241444, acc.: 62.50%] [G loss: 0.417592]\n",
      "epoch:14 step:13160 [D loss: 0.207025, acc.: 71.09%] [G loss: 0.432456]\n",
      "epoch:14 step:13161 [D loss: 0.226267, acc.: 65.62%] [G loss: 0.433410]\n",
      "epoch:14 step:13162 [D loss: 0.223496, acc.: 62.50%] [G loss: 0.459165]\n",
      "epoch:14 step:13163 [D loss: 0.233917, acc.: 61.72%] [G loss: 0.448791]\n",
      "epoch:14 step:13164 [D loss: 0.234556, acc.: 57.81%] [G loss: 0.444869]\n",
      "epoch:14 step:13165 [D loss: 0.217340, acc.: 60.94%] [G loss: 0.440428]\n",
      "epoch:14 step:13166 [D loss: 0.204451, acc.: 67.97%] [G loss: 0.483023]\n",
      "epoch:14 step:13167 [D loss: 0.201240, acc.: 69.53%] [G loss: 0.447141]\n",
      "epoch:14 step:13168 [D loss: 0.203372, acc.: 67.19%] [G loss: 0.479674]\n",
      "epoch:14 step:13169 [D loss: 0.223578, acc.: 64.84%] [G loss: 0.458073]\n",
      "epoch:14 step:13170 [D loss: 0.226623, acc.: 60.16%] [G loss: 0.440554]\n",
      "epoch:14 step:13171 [D loss: 0.223750, acc.: 68.75%] [G loss: 0.469004]\n",
      "epoch:14 step:13172 [D loss: 0.205703, acc.: 65.62%] [G loss: 0.502749]\n",
      "epoch:14 step:13173 [D loss: 0.219562, acc.: 66.41%] [G loss: 0.478134]\n",
      "epoch:14 step:13174 [D loss: 0.221915, acc.: 67.19%] [G loss: 0.441212]\n",
      "epoch:14 step:13175 [D loss: 0.219875, acc.: 63.28%] [G loss: 0.425091]\n",
      "epoch:14 step:13176 [D loss: 0.231480, acc.: 62.50%] [G loss: 0.447908]\n",
      "epoch:14 step:13177 [D loss: 0.203713, acc.: 64.84%] [G loss: 0.503498]\n",
      "epoch:14 step:13178 [D loss: 0.231518, acc.: 57.81%] [G loss: 0.446183]\n",
      "epoch:14 step:13179 [D loss: 0.239684, acc.: 60.94%] [G loss: 0.424024]\n",
      "epoch:14 step:13180 [D loss: 0.232716, acc.: 60.94%] [G loss: 0.427059]\n",
      "epoch:14 step:13181 [D loss: 0.242580, acc.: 61.72%] [G loss: 0.439332]\n",
      "epoch:14 step:13182 [D loss: 0.225693, acc.: 64.84%] [G loss: 0.424418]\n",
      "epoch:14 step:13183 [D loss: 0.210643, acc.: 64.06%] [G loss: 0.444768]\n",
      "epoch:14 step:13184 [D loss: 0.223076, acc.: 65.62%] [G loss: 0.406804]\n",
      "epoch:14 step:13185 [D loss: 0.223451, acc.: 64.84%] [G loss: 0.466070]\n",
      "epoch:14 step:13186 [D loss: 0.228620, acc.: 63.28%] [G loss: 0.435993]\n",
      "epoch:14 step:13187 [D loss: 0.178256, acc.: 74.22%] [G loss: 0.465788]\n",
      "epoch:14 step:13188 [D loss: 0.218078, acc.: 65.62%] [G loss: 0.462554]\n",
      "epoch:14 step:13189 [D loss: 0.219370, acc.: 58.59%] [G loss: 0.443338]\n",
      "epoch:14 step:13190 [D loss: 0.237145, acc.: 57.81%] [G loss: 0.397350]\n",
      "epoch:14 step:13191 [D loss: 0.240117, acc.: 56.25%] [G loss: 0.418294]\n",
      "epoch:14 step:13192 [D loss: 0.192910, acc.: 71.88%] [G loss: 0.454404]\n",
      "epoch:14 step:13193 [D loss: 0.184163, acc.: 73.44%] [G loss: 0.475630]\n",
      "epoch:14 step:13194 [D loss: 0.192649, acc.: 68.75%] [G loss: 0.506021]\n",
      "epoch:14 step:13195 [D loss: 0.203492, acc.: 63.28%] [G loss: 0.536779]\n",
      "epoch:14 step:13196 [D loss: 0.282706, acc.: 50.78%] [G loss: 0.473301]\n",
      "epoch:14 step:13197 [D loss: 0.240999, acc.: 59.38%] [G loss: 0.405456]\n",
      "epoch:14 step:13198 [D loss: 0.224405, acc.: 62.50%] [G loss: 0.421609]\n",
      "epoch:14 step:13199 [D loss: 0.229796, acc.: 57.81%] [G loss: 0.421282]\n",
      "epoch:14 step:13200 [D loss: 0.223331, acc.: 60.94%] [G loss: 0.437308]\n",
      "epoch:14 step:13201 [D loss: 0.211243, acc.: 71.09%] [G loss: 0.468750]\n",
      "epoch:14 step:13202 [D loss: 0.206250, acc.: 68.75%] [G loss: 0.458197]\n",
      "epoch:14 step:13203 [D loss: 0.227804, acc.: 62.50%] [G loss: 0.490302]\n",
      "epoch:14 step:13204 [D loss: 0.219789, acc.: 64.06%] [G loss: 0.461116]\n",
      "epoch:14 step:13205 [D loss: 0.212705, acc.: 68.75%] [G loss: 0.415075]\n",
      "epoch:14 step:13206 [D loss: 0.208393, acc.: 67.19%] [G loss: 0.433087]\n",
      "epoch:14 step:13207 [D loss: 0.199172, acc.: 71.09%] [G loss: 0.488020]\n",
      "epoch:14 step:13208 [D loss: 0.200149, acc.: 67.97%] [G loss: 0.468041]\n",
      "epoch:14 step:13209 [D loss: 0.243073, acc.: 59.38%] [G loss: 0.444553]\n",
      "epoch:14 step:13210 [D loss: 0.209583, acc.: 71.09%] [G loss: 0.465948]\n",
      "epoch:14 step:13211 [D loss: 0.223460, acc.: 61.72%] [G loss: 0.453362]\n",
      "epoch:14 step:13212 [D loss: 0.246698, acc.: 53.91%] [G loss: 0.454906]\n",
      "epoch:14 step:13213 [D loss: 0.210885, acc.: 64.84%] [G loss: 0.477243]\n",
      "epoch:14 step:13214 [D loss: 0.212491, acc.: 67.19%] [G loss: 0.460753]\n",
      "epoch:14 step:13215 [D loss: 0.199749, acc.: 71.88%] [G loss: 0.491116]\n",
      "epoch:14 step:13216 [D loss: 0.221240, acc.: 63.28%] [G loss: 0.455265]\n",
      "epoch:14 step:13217 [D loss: 0.234707, acc.: 62.50%] [G loss: 0.479428]\n",
      "epoch:14 step:13218 [D loss: 0.193178, acc.: 71.09%] [G loss: 0.487512]\n",
      "epoch:14 step:13219 [D loss: 0.210529, acc.: 67.19%] [G loss: 0.434116]\n",
      "epoch:14 step:13220 [D loss: 0.258040, acc.: 54.69%] [G loss: 0.422446]\n",
      "epoch:14 step:13221 [D loss: 0.222901, acc.: 61.72%] [G loss: 0.445306]\n",
      "epoch:14 step:13222 [D loss: 0.243453, acc.: 57.81%] [G loss: 0.422999]\n",
      "epoch:14 step:13223 [D loss: 0.258709, acc.: 53.12%] [G loss: 0.418526]\n",
      "epoch:14 step:13224 [D loss: 0.210966, acc.: 64.84%] [G loss: 0.420872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13225 [D loss: 0.206221, acc.: 69.53%] [G loss: 0.474437]\n",
      "epoch:14 step:13226 [D loss: 0.281515, acc.: 47.66%] [G loss: 0.454738]\n",
      "epoch:14 step:13227 [D loss: 0.247821, acc.: 58.59%] [G loss: 0.425223]\n",
      "epoch:14 step:13228 [D loss: 0.233678, acc.: 57.03%] [G loss: 0.431234]\n",
      "epoch:14 step:13229 [D loss: 0.202000, acc.: 67.19%] [G loss: 0.414241]\n",
      "epoch:14 step:13230 [D loss: 0.205549, acc.: 69.53%] [G loss: 0.452092]\n",
      "epoch:14 step:13231 [D loss: 0.195923, acc.: 71.88%] [G loss: 0.451666]\n",
      "epoch:14 step:13232 [D loss: 0.219340, acc.: 67.97%] [G loss: 0.443742]\n",
      "epoch:14 step:13233 [D loss: 0.194372, acc.: 71.09%] [G loss: 0.515973]\n",
      "epoch:14 step:13234 [D loss: 0.202680, acc.: 67.97%] [G loss: 0.505226]\n",
      "epoch:14 step:13235 [D loss: 0.208300, acc.: 64.84%] [G loss: 0.480652]\n",
      "epoch:14 step:13236 [D loss: 0.232487, acc.: 60.16%] [G loss: 0.449460]\n",
      "epoch:14 step:13237 [D loss: 0.183658, acc.: 74.22%] [G loss: 0.537598]\n",
      "epoch:14 step:13238 [D loss: 0.268543, acc.: 58.59%] [G loss: 0.448151]\n",
      "epoch:14 step:13239 [D loss: 0.231610, acc.: 65.62%] [G loss: 0.417869]\n",
      "epoch:14 step:13240 [D loss: 0.206841, acc.: 64.84%] [G loss: 0.469170]\n",
      "epoch:14 step:13241 [D loss: 0.216617, acc.: 67.97%] [G loss: 0.483274]\n",
      "epoch:14 step:13242 [D loss: 0.242429, acc.: 61.72%] [G loss: 0.486034]\n",
      "epoch:14 step:13243 [D loss: 0.229740, acc.: 60.94%] [G loss: 0.423563]\n",
      "epoch:14 step:13244 [D loss: 0.188375, acc.: 70.31%] [G loss: 0.491167]\n",
      "epoch:14 step:13245 [D loss: 0.206185, acc.: 68.75%] [G loss: 0.454190]\n",
      "epoch:14 step:13246 [D loss: 0.267188, acc.: 54.69%] [G loss: 0.439961]\n",
      "epoch:14 step:13247 [D loss: 0.216516, acc.: 69.53%] [G loss: 0.413027]\n",
      "epoch:14 step:13248 [D loss: 0.212224, acc.: 64.84%] [G loss: 0.439822]\n",
      "epoch:14 step:13249 [D loss: 0.233561, acc.: 59.38%] [G loss: 0.468218]\n",
      "epoch:14 step:13250 [D loss: 0.198861, acc.: 70.31%] [G loss: 0.429613]\n",
      "epoch:14 step:13251 [D loss: 0.272575, acc.: 50.00%] [G loss: 0.442507]\n",
      "epoch:14 step:13252 [D loss: 0.229343, acc.: 62.50%] [G loss: 0.418304]\n",
      "epoch:14 step:13253 [D loss: 0.206637, acc.: 65.62%] [G loss: 0.432367]\n",
      "epoch:14 step:13254 [D loss: 0.251743, acc.: 58.59%] [G loss: 0.460402]\n",
      "epoch:14 step:13255 [D loss: 0.245194, acc.: 59.38%] [G loss: 0.468076]\n",
      "epoch:14 step:13256 [D loss: 0.256840, acc.: 53.91%] [G loss: 0.403184]\n",
      "epoch:14 step:13257 [D loss: 0.240561, acc.: 57.03%] [G loss: 0.379332]\n",
      "epoch:14 step:13258 [D loss: 0.233110, acc.: 57.03%] [G loss: 0.412924]\n",
      "epoch:14 step:13259 [D loss: 0.226633, acc.: 63.28%] [G loss: 0.472752]\n",
      "epoch:14 step:13260 [D loss: 0.227339, acc.: 61.72%] [G loss: 0.424627]\n",
      "epoch:14 step:13261 [D loss: 0.259952, acc.: 53.91%] [G loss: 0.405747]\n",
      "epoch:14 step:13262 [D loss: 0.209771, acc.: 66.41%] [G loss: 0.416659]\n",
      "epoch:14 step:13263 [D loss: 0.220891, acc.: 65.62%] [G loss: 0.452948]\n",
      "epoch:14 step:13264 [D loss: 0.221130, acc.: 64.06%] [G loss: 0.448004]\n",
      "epoch:14 step:13265 [D loss: 0.242081, acc.: 58.59%] [G loss: 0.416662]\n",
      "epoch:14 step:13266 [D loss: 0.234452, acc.: 60.16%] [G loss: 0.459426]\n",
      "epoch:14 step:13267 [D loss: 0.226656, acc.: 60.94%] [G loss: 0.477133]\n",
      "epoch:14 step:13268 [D loss: 0.256770, acc.: 59.38%] [G loss: 0.426399]\n",
      "epoch:14 step:13269 [D loss: 0.186125, acc.: 71.88%] [G loss: 0.507565]\n",
      "epoch:14 step:13270 [D loss: 0.246986, acc.: 64.06%] [G loss: 0.450785]\n",
      "epoch:14 step:13271 [D loss: 0.241915, acc.: 58.59%] [G loss: 0.459160]\n",
      "epoch:14 step:13272 [D loss: 0.207674, acc.: 64.84%] [G loss: 0.471843]\n",
      "epoch:14 step:13273 [D loss: 0.190672, acc.: 69.53%] [G loss: 0.473993]\n",
      "epoch:14 step:13274 [D loss: 0.219806, acc.: 62.50%] [G loss: 0.440636]\n",
      "epoch:14 step:13275 [D loss: 0.249105, acc.: 54.69%] [G loss: 0.433173]\n",
      "epoch:14 step:13276 [D loss: 0.234851, acc.: 60.16%] [G loss: 0.465185]\n",
      "epoch:14 step:13277 [D loss: 0.214600, acc.: 67.97%] [G loss: 0.437689]\n",
      "epoch:14 step:13278 [D loss: 0.294759, acc.: 46.88%] [G loss: 0.418662]\n",
      "epoch:14 step:13279 [D loss: 0.253091, acc.: 53.91%] [G loss: 0.429588]\n",
      "epoch:14 step:13280 [D loss: 0.239976, acc.: 59.38%] [G loss: 0.426243]\n",
      "epoch:14 step:13281 [D loss: 0.203385, acc.: 70.31%] [G loss: 0.451218]\n",
      "epoch:14 step:13282 [D loss: 0.245494, acc.: 55.47%] [G loss: 0.456436]\n",
      "epoch:14 step:13283 [D loss: 0.229337, acc.: 64.84%] [G loss: 0.425905]\n",
      "epoch:14 step:13284 [D loss: 0.233433, acc.: 61.72%] [G loss: 0.408420]\n",
      "epoch:14 step:13285 [D loss: 0.213265, acc.: 66.41%] [G loss: 0.461074]\n",
      "epoch:14 step:13286 [D loss: 0.225768, acc.: 63.28%] [G loss: 0.455296]\n",
      "epoch:14 step:13287 [D loss: 0.250584, acc.: 60.16%] [G loss: 0.417315]\n",
      "epoch:14 step:13288 [D loss: 0.267460, acc.: 51.56%] [G loss: 0.406020]\n",
      "epoch:14 step:13289 [D loss: 0.211864, acc.: 64.06%] [G loss: 0.410910]\n",
      "epoch:14 step:13290 [D loss: 0.252067, acc.: 55.47%] [G loss: 0.398377]\n",
      "epoch:14 step:13291 [D loss: 0.198330, acc.: 72.66%] [G loss: 0.431632]\n",
      "epoch:14 step:13292 [D loss: 0.269045, acc.: 47.66%] [G loss: 0.410411]\n",
      "epoch:14 step:13293 [D loss: 0.252359, acc.: 52.34%] [G loss: 0.432490]\n",
      "epoch:14 step:13294 [D loss: 0.217507, acc.: 63.28%] [G loss: 0.447325]\n",
      "epoch:14 step:13295 [D loss: 0.244071, acc.: 53.91%] [G loss: 0.412027]\n",
      "epoch:14 step:13296 [D loss: 0.227491, acc.: 57.03%] [G loss: 0.428080]\n",
      "epoch:14 step:13297 [D loss: 0.222752, acc.: 64.06%] [G loss: 0.428828]\n",
      "epoch:14 step:13298 [D loss: 0.234803, acc.: 60.16%] [G loss: 0.419146]\n",
      "epoch:14 step:13299 [D loss: 0.247159, acc.: 54.69%] [G loss: 0.422368]\n",
      "epoch:14 step:13300 [D loss: 0.225209, acc.: 63.28%] [G loss: 0.480435]\n",
      "epoch:14 step:13301 [D loss: 0.248016, acc.: 57.03%] [G loss: 0.477982]\n",
      "epoch:14 step:13302 [D loss: 0.212244, acc.: 64.84%] [G loss: 0.482112]\n",
      "epoch:14 step:13303 [D loss: 0.235353, acc.: 60.16%] [G loss: 0.438707]\n",
      "epoch:14 step:13304 [D loss: 0.221984, acc.: 63.28%] [G loss: 0.450820]\n",
      "epoch:14 step:13305 [D loss: 0.235875, acc.: 59.38%] [G loss: 0.434242]\n",
      "epoch:14 step:13306 [D loss: 0.246842, acc.: 56.25%] [G loss: 0.414840]\n",
      "epoch:14 step:13307 [D loss: 0.240170, acc.: 61.72%] [G loss: 0.424816]\n",
      "epoch:14 step:13308 [D loss: 0.231849, acc.: 63.28%] [G loss: 0.374737]\n",
      "epoch:14 step:13309 [D loss: 0.214051, acc.: 67.19%] [G loss: 0.420338]\n",
      "epoch:14 step:13310 [D loss: 0.199418, acc.: 69.53%] [G loss: 0.446801]\n",
      "epoch:14 step:13311 [D loss: 0.231427, acc.: 65.62%] [G loss: 0.427957]\n",
      "epoch:14 step:13312 [D loss: 0.206832, acc.: 65.62%] [G loss: 0.465070]\n",
      "epoch:14 step:13313 [D loss: 0.219639, acc.: 61.72%] [G loss: 0.428170]\n",
      "epoch:14 step:13314 [D loss: 0.229171, acc.: 60.94%] [G loss: 0.476239]\n",
      "epoch:14 step:13315 [D loss: 0.198145, acc.: 69.53%] [G loss: 0.425165]\n",
      "epoch:14 step:13316 [D loss: 0.186534, acc.: 75.78%] [G loss: 0.471606]\n",
      "epoch:14 step:13317 [D loss: 0.234824, acc.: 61.72%] [G loss: 0.476843]\n",
      "epoch:14 step:13318 [D loss: 0.266729, acc.: 57.03%] [G loss: 0.420415]\n",
      "epoch:14 step:13319 [D loss: 0.223880, acc.: 64.06%] [G loss: 0.453818]\n",
      "epoch:14 step:13320 [D loss: 0.215281, acc.: 67.19%] [G loss: 0.436092]\n",
      "epoch:14 step:13321 [D loss: 0.277964, acc.: 50.78%] [G loss: 0.384133]\n",
      "epoch:14 step:13322 [D loss: 0.243523, acc.: 57.81%] [G loss: 0.406972]\n",
      "epoch:14 step:13323 [D loss: 0.222219, acc.: 60.16%] [G loss: 0.509605]\n",
      "epoch:14 step:13324 [D loss: 0.213881, acc.: 67.19%] [G loss: 0.540156]\n",
      "epoch:14 step:13325 [D loss: 0.229479, acc.: 57.81%] [G loss: 0.451590]\n",
      "epoch:14 step:13326 [D loss: 0.200918, acc.: 68.75%] [G loss: 0.457116]\n",
      "epoch:14 step:13327 [D loss: 0.197913, acc.: 70.31%] [G loss: 0.495200]\n",
      "epoch:14 step:13328 [D loss: 0.247443, acc.: 59.38%] [G loss: 0.434363]\n",
      "epoch:14 step:13329 [D loss: 0.230229, acc.: 57.81%] [G loss: 0.414873]\n",
      "epoch:14 step:13330 [D loss: 0.239097, acc.: 60.16%] [G loss: 0.385179]\n",
      "epoch:14 step:13331 [D loss: 0.222098, acc.: 60.16%] [G loss: 0.447046]\n",
      "epoch:14 step:13332 [D loss: 0.254653, acc.: 55.47%] [G loss: 0.481101]\n",
      "epoch:14 step:13333 [D loss: 0.229852, acc.: 59.38%] [G loss: 0.474660]\n",
      "epoch:14 step:13334 [D loss: 0.217660, acc.: 60.94%] [G loss: 0.447146]\n",
      "epoch:14 step:13335 [D loss: 0.230293, acc.: 61.72%] [G loss: 0.458926]\n",
      "epoch:14 step:13336 [D loss: 0.182512, acc.: 75.00%] [G loss: 0.496807]\n",
      "epoch:14 step:13337 [D loss: 0.189111, acc.: 75.00%] [G loss: 0.509942]\n",
      "epoch:14 step:13338 [D loss: 0.284745, acc.: 49.22%] [G loss: 0.463233]\n",
      "epoch:14 step:13339 [D loss: 0.213097, acc.: 64.06%] [G loss: 0.448246]\n",
      "epoch:14 step:13340 [D loss: 0.202900, acc.: 67.97%] [G loss: 0.517852]\n",
      "epoch:14 step:13341 [D loss: 0.177302, acc.: 71.88%] [G loss: 0.528053]\n",
      "epoch:14 step:13342 [D loss: 0.270428, acc.: 51.56%] [G loss: 0.441319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13343 [D loss: 0.244487, acc.: 60.16%] [G loss: 0.445414]\n",
      "epoch:14 step:13344 [D loss: 0.230171, acc.: 60.16%] [G loss: 0.401607]\n",
      "epoch:14 step:13345 [D loss: 0.218106, acc.: 63.28%] [G loss: 0.411744]\n",
      "epoch:14 step:13346 [D loss: 0.250854, acc.: 53.91%] [G loss: 0.429073]\n",
      "epoch:14 step:13347 [D loss: 0.195388, acc.: 71.09%] [G loss: 0.488646]\n",
      "epoch:14 step:13348 [D loss: 0.229834, acc.: 65.62%] [G loss: 0.484148]\n",
      "epoch:14 step:13349 [D loss: 0.176892, acc.: 74.22%] [G loss: 0.595094]\n",
      "epoch:14 step:13350 [D loss: 0.175033, acc.: 78.12%] [G loss: 0.536706]\n",
      "epoch:14 step:13351 [D loss: 0.247739, acc.: 60.16%] [G loss: 0.438582]\n",
      "epoch:14 step:13352 [D loss: 0.249120, acc.: 56.25%] [G loss: 0.408168]\n",
      "epoch:14 step:13353 [D loss: 0.229043, acc.: 59.38%] [G loss: 0.453181]\n",
      "epoch:14 step:13354 [D loss: 0.199807, acc.: 67.19%] [G loss: 0.433487]\n",
      "epoch:14 step:13355 [D loss: 0.204946, acc.: 70.31%] [G loss: 0.440510]\n",
      "epoch:14 step:13356 [D loss: 0.236189, acc.: 60.16%] [G loss: 0.424312]\n",
      "epoch:14 step:13357 [D loss: 0.214716, acc.: 66.41%] [G loss: 0.438049]\n",
      "epoch:14 step:13358 [D loss: 0.220972, acc.: 65.62%] [G loss: 0.465492]\n",
      "epoch:14 step:13359 [D loss: 0.207955, acc.: 64.84%] [G loss: 0.441610]\n",
      "epoch:14 step:13360 [D loss: 0.209503, acc.: 66.41%] [G loss: 0.480879]\n",
      "epoch:14 step:13361 [D loss: 0.199202, acc.: 65.62%] [G loss: 0.462766]\n",
      "epoch:14 step:13362 [D loss: 0.201641, acc.: 71.88%] [G loss: 0.475224]\n",
      "epoch:14 step:13363 [D loss: 0.194255, acc.: 64.84%] [G loss: 0.463826]\n",
      "epoch:14 step:13364 [D loss: 0.200946, acc.: 71.88%] [G loss: 0.505582]\n",
      "epoch:14 step:13365 [D loss: 0.223018, acc.: 60.94%] [G loss: 0.469970]\n",
      "epoch:14 step:13366 [D loss: 0.228934, acc.: 60.94%] [G loss: 0.498939]\n",
      "epoch:14 step:13367 [D loss: 0.249186, acc.: 64.06%] [G loss: 0.479825]\n",
      "epoch:14 step:13368 [D loss: 0.253892, acc.: 51.56%] [G loss: 0.436170]\n",
      "epoch:14 step:13369 [D loss: 0.228429, acc.: 62.50%] [G loss: 0.458370]\n",
      "epoch:14 step:13370 [D loss: 0.220404, acc.: 65.62%] [G loss: 0.438779]\n",
      "epoch:14 step:13371 [D loss: 0.210394, acc.: 67.97%] [G loss: 0.440648]\n",
      "epoch:14 step:13372 [D loss: 0.236941, acc.: 64.06%] [G loss: 0.422201]\n",
      "epoch:14 step:13373 [D loss: 0.222654, acc.: 64.84%] [G loss: 0.411737]\n",
      "epoch:14 step:13374 [D loss: 0.234598, acc.: 57.81%] [G loss: 0.425955]\n",
      "epoch:14 step:13375 [D loss: 0.223122, acc.: 59.38%] [G loss: 0.421141]\n",
      "epoch:14 step:13376 [D loss: 0.212963, acc.: 67.19%] [G loss: 0.439206]\n",
      "epoch:14 step:13377 [D loss: 0.210756, acc.: 66.41%] [G loss: 0.460839]\n",
      "epoch:14 step:13378 [D loss: 0.232951, acc.: 57.03%] [G loss: 0.451876]\n",
      "epoch:14 step:13379 [D loss: 0.204950, acc.: 67.97%] [G loss: 0.458087]\n",
      "epoch:14 step:13380 [D loss: 0.205012, acc.: 67.19%] [G loss: 0.490476]\n",
      "epoch:14 step:13381 [D loss: 0.254391, acc.: 57.03%] [G loss: 0.487985]\n",
      "epoch:14 step:13382 [D loss: 0.199919, acc.: 74.22%] [G loss: 0.512757]\n",
      "epoch:14 step:13383 [D loss: 0.251823, acc.: 58.59%] [G loss: 0.429075]\n",
      "epoch:14 step:13384 [D loss: 0.275256, acc.: 55.47%] [G loss: 0.422452]\n",
      "epoch:14 step:13385 [D loss: 0.220136, acc.: 60.16%] [G loss: 0.428823]\n",
      "epoch:14 step:13386 [D loss: 0.231330, acc.: 57.81%] [G loss: 0.441959]\n",
      "epoch:14 step:13387 [D loss: 0.247952, acc.: 54.69%] [G loss: 0.434878]\n",
      "epoch:14 step:13388 [D loss: 0.237260, acc.: 59.38%] [G loss: 0.430355]\n",
      "epoch:14 step:13389 [D loss: 0.198732, acc.: 71.09%] [G loss: 0.457077]\n",
      "epoch:14 step:13390 [D loss: 0.207599, acc.: 68.75%] [G loss: 0.461828]\n",
      "epoch:14 step:13391 [D loss: 0.237126, acc.: 59.38%] [G loss: 0.426469]\n",
      "epoch:14 step:13392 [D loss: 0.232028, acc.: 68.75%] [G loss: 0.431858]\n",
      "epoch:14 step:13393 [D loss: 0.221473, acc.: 64.84%] [G loss: 0.445019]\n",
      "epoch:14 step:13394 [D loss: 0.216393, acc.: 64.06%] [G loss: 0.457041]\n",
      "epoch:14 step:13395 [D loss: 0.241986, acc.: 57.81%] [G loss: 0.448859]\n",
      "epoch:14 step:13396 [D loss: 0.246141, acc.: 57.81%] [G loss: 0.466504]\n",
      "epoch:14 step:13397 [D loss: 0.228177, acc.: 58.59%] [G loss: 0.446868]\n",
      "epoch:14 step:13398 [D loss: 0.224578, acc.: 62.50%] [G loss: 0.440992]\n",
      "epoch:14 step:13399 [D loss: 0.278246, acc.: 51.56%] [G loss: 0.396270]\n",
      "epoch:14 step:13400 [D loss: 0.229914, acc.: 65.62%] [G loss: 0.422110]\n",
      "epoch:14 step:13401 [D loss: 0.204408, acc.: 71.88%] [G loss: 0.449511]\n",
      "epoch:14 step:13402 [D loss: 0.230735, acc.: 62.50%] [G loss: 0.430834]\n",
      "epoch:14 step:13403 [D loss: 0.209339, acc.: 67.97%] [G loss: 0.410399]\n",
      "epoch:14 step:13404 [D loss: 0.219442, acc.: 67.19%] [G loss: 0.455406]\n",
      "epoch:14 step:13405 [D loss: 0.239195, acc.: 61.72%] [G loss: 0.432965]\n",
      "epoch:14 step:13406 [D loss: 0.240419, acc.: 55.47%] [G loss: 0.412718]\n",
      "epoch:14 step:13407 [D loss: 0.228762, acc.: 64.84%] [G loss: 0.483965]\n",
      "epoch:14 step:13408 [D loss: 0.237610, acc.: 54.69%] [G loss: 0.448668]\n",
      "epoch:14 step:13409 [D loss: 0.250857, acc.: 57.81%] [G loss: 0.392144]\n",
      "epoch:14 step:13410 [D loss: 0.231535, acc.: 64.84%] [G loss: 0.439088]\n",
      "epoch:14 step:13411 [D loss: 0.226750, acc.: 63.28%] [G loss: 0.432512]\n",
      "epoch:14 step:13412 [D loss: 0.241513, acc.: 56.25%] [G loss: 0.458119]\n",
      "epoch:14 step:13413 [D loss: 0.229404, acc.: 64.84%] [G loss: 0.426087]\n",
      "epoch:14 step:13414 [D loss: 0.185002, acc.: 71.88%] [G loss: 0.451236]\n",
      "epoch:14 step:13415 [D loss: 0.223267, acc.: 61.72%] [G loss: 0.433877]\n",
      "epoch:14 step:13416 [D loss: 0.216293, acc.: 61.72%] [G loss: 0.456619]\n",
      "epoch:14 step:13417 [D loss: 0.195405, acc.: 67.19%] [G loss: 0.509629]\n",
      "epoch:14 step:13418 [D loss: 0.234017, acc.: 61.72%] [G loss: 0.473553]\n",
      "epoch:14 step:13419 [D loss: 0.259061, acc.: 56.25%] [G loss: 0.441232]\n",
      "epoch:14 step:13420 [D loss: 0.209623, acc.: 63.28%] [G loss: 0.460336]\n",
      "epoch:14 step:13421 [D loss: 0.227639, acc.: 66.41%] [G loss: 0.441406]\n",
      "epoch:14 step:13422 [D loss: 0.210865, acc.: 69.53%] [G loss: 0.450062]\n",
      "epoch:14 step:13423 [D loss: 0.221255, acc.: 64.06%] [G loss: 0.422925]\n",
      "epoch:14 step:13424 [D loss: 0.218436, acc.: 60.16%] [G loss: 0.389472]\n",
      "epoch:14 step:13425 [D loss: 0.233092, acc.: 64.06%] [G loss: 0.455454]\n",
      "epoch:14 step:13426 [D loss: 0.239053, acc.: 59.38%] [G loss: 0.436479]\n",
      "epoch:14 step:13427 [D loss: 0.213868, acc.: 63.28%] [G loss: 0.458351]\n",
      "epoch:14 step:13428 [D loss: 0.240178, acc.: 59.38%] [G loss: 0.452185]\n",
      "epoch:14 step:13429 [D loss: 0.209133, acc.: 70.31%] [G loss: 0.471501]\n",
      "epoch:14 step:13430 [D loss: 0.177740, acc.: 78.12%] [G loss: 0.476574]\n",
      "epoch:14 step:13431 [D loss: 0.174468, acc.: 77.34%] [G loss: 0.545852]\n",
      "epoch:14 step:13432 [D loss: 0.185724, acc.: 67.97%] [G loss: 0.483183]\n",
      "epoch:14 step:13433 [D loss: 0.202756, acc.: 68.75%] [G loss: 0.549363]\n",
      "epoch:14 step:13434 [D loss: 0.284689, acc.: 52.34%] [G loss: 0.468342]\n",
      "epoch:14 step:13435 [D loss: 0.237152, acc.: 58.59%] [G loss: 0.426484]\n",
      "epoch:14 step:13436 [D loss: 0.221503, acc.: 61.72%] [G loss: 0.448043]\n",
      "epoch:14 step:13437 [D loss: 0.219071, acc.: 65.62%] [G loss: 0.496450]\n",
      "epoch:14 step:13438 [D loss: 0.230141, acc.: 60.16%] [G loss: 0.441353]\n",
      "epoch:14 step:13439 [D loss: 0.199870, acc.: 67.97%] [G loss: 0.486719]\n",
      "epoch:14 step:13440 [D loss: 0.213858, acc.: 67.19%] [G loss: 0.451410]\n",
      "epoch:14 step:13441 [D loss: 0.299912, acc.: 49.22%] [G loss: 0.434287]\n",
      "epoch:14 step:13442 [D loss: 0.223615, acc.: 67.97%] [G loss: 0.427511]\n",
      "epoch:14 step:13443 [D loss: 0.217188, acc.: 61.72%] [G loss: 0.429285]\n",
      "epoch:14 step:13444 [D loss: 0.223116, acc.: 64.84%] [G loss: 0.462988]\n",
      "epoch:14 step:13445 [D loss: 0.225229, acc.: 60.94%] [G loss: 0.481437]\n",
      "epoch:14 step:13446 [D loss: 0.209941, acc.: 69.53%] [G loss: 0.490299]\n",
      "epoch:14 step:13447 [D loss: 0.237958, acc.: 56.25%] [G loss: 0.418438]\n",
      "epoch:14 step:13448 [D loss: 0.206055, acc.: 69.53%] [G loss: 0.441038]\n",
      "epoch:14 step:13449 [D loss: 0.205178, acc.: 68.75%] [G loss: 0.454144]\n",
      "epoch:14 step:13450 [D loss: 0.200623, acc.: 71.88%] [G loss: 0.451789]\n",
      "epoch:14 step:13451 [D loss: 0.218887, acc.: 66.41%] [G loss: 0.456575]\n",
      "epoch:14 step:13452 [D loss: 0.248397, acc.: 57.03%] [G loss: 0.464253]\n",
      "epoch:14 step:13453 [D loss: 0.223778, acc.: 60.16%] [G loss: 0.422164]\n",
      "epoch:14 step:13454 [D loss: 0.223357, acc.: 66.41%] [G loss: 0.478857]\n",
      "epoch:14 step:13455 [D loss: 0.219031, acc.: 60.94%] [G loss: 0.471079]\n",
      "epoch:14 step:13456 [D loss: 0.215326, acc.: 64.84%] [G loss: 0.461082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13457 [D loss: 0.210050, acc.: 68.75%] [G loss: 0.465462]\n",
      "epoch:14 step:13458 [D loss: 0.216083, acc.: 61.72%] [G loss: 0.437775]\n",
      "epoch:14 step:13459 [D loss: 0.294995, acc.: 45.31%] [G loss: 0.405459]\n",
      "epoch:14 step:13460 [D loss: 0.246921, acc.: 57.81%] [G loss: 0.463376]\n",
      "epoch:14 step:13461 [D loss: 0.217135, acc.: 67.19%] [G loss: 0.492811]\n",
      "epoch:14 step:13462 [D loss: 0.221004, acc.: 67.97%] [G loss: 0.479691]\n",
      "epoch:14 step:13463 [D loss: 0.215800, acc.: 70.31%] [G loss: 0.479780]\n",
      "epoch:14 step:13464 [D loss: 0.206682, acc.: 66.41%] [G loss: 0.503210]\n",
      "epoch:14 step:13465 [D loss: 0.173045, acc.: 73.44%] [G loss: 0.496859]\n",
      "epoch:14 step:13466 [D loss: 0.280066, acc.: 57.81%] [G loss: 0.435044]\n",
      "epoch:14 step:13467 [D loss: 0.251197, acc.: 56.25%] [G loss: 0.426161]\n",
      "epoch:14 step:13468 [D loss: 0.213436, acc.: 65.62%] [G loss: 0.397283]\n",
      "epoch:14 step:13469 [D loss: 0.238652, acc.: 62.50%] [G loss: 0.391756]\n",
      "epoch:14 step:13470 [D loss: 0.235776, acc.: 61.72%] [G loss: 0.435497]\n",
      "epoch:14 step:13471 [D loss: 0.215663, acc.: 65.62%] [G loss: 0.470856]\n",
      "epoch:14 step:13472 [D loss: 0.186894, acc.: 71.09%] [G loss: 0.524958]\n",
      "epoch:14 step:13473 [D loss: 0.229416, acc.: 66.41%] [G loss: 0.445683]\n",
      "epoch:14 step:13474 [D loss: 0.218135, acc.: 65.62%] [G loss: 0.452001]\n",
      "epoch:14 step:13475 [D loss: 0.204958, acc.: 71.09%] [G loss: 0.469864]\n",
      "epoch:14 step:13476 [D loss: 0.212603, acc.: 64.84%] [G loss: 0.474887]\n",
      "epoch:14 step:13477 [D loss: 0.206156, acc.: 71.09%] [G loss: 0.458025]\n",
      "epoch:14 step:13478 [D loss: 0.201892, acc.: 66.41%] [G loss: 0.480231]\n",
      "epoch:14 step:13479 [D loss: 0.219558, acc.: 64.06%] [G loss: 0.430656]\n",
      "epoch:14 step:13480 [D loss: 0.223829, acc.: 60.16%] [G loss: 0.438418]\n",
      "epoch:14 step:13481 [D loss: 0.233423, acc.: 58.59%] [G loss: 0.421491]\n",
      "epoch:14 step:13482 [D loss: 0.218644, acc.: 66.41%] [G loss: 0.415325]\n",
      "epoch:14 step:13483 [D loss: 0.217096, acc.: 61.72%] [G loss: 0.441332]\n",
      "epoch:14 step:13484 [D loss: 0.212409, acc.: 68.75%] [G loss: 0.460977]\n",
      "epoch:14 step:13485 [D loss: 0.233395, acc.: 64.06%] [G loss: 0.475888]\n",
      "epoch:14 step:13486 [D loss: 0.207864, acc.: 67.97%] [G loss: 0.447522]\n",
      "epoch:14 step:13487 [D loss: 0.215460, acc.: 63.28%] [G loss: 0.414189]\n",
      "epoch:14 step:13488 [D loss: 0.227029, acc.: 61.72%] [G loss: 0.423009]\n",
      "epoch:14 step:13489 [D loss: 0.184914, acc.: 76.56%] [G loss: 0.492882]\n",
      "epoch:14 step:13490 [D loss: 0.209255, acc.: 65.62%] [G loss: 0.468186]\n",
      "epoch:14 step:13491 [D loss: 0.263607, acc.: 54.69%] [G loss: 0.420308]\n",
      "epoch:14 step:13492 [D loss: 0.175147, acc.: 76.56%] [G loss: 0.440918]\n",
      "epoch:14 step:13493 [D loss: 0.244952, acc.: 60.16%] [G loss: 0.410832]\n",
      "epoch:14 step:13494 [D loss: 0.262609, acc.: 53.12%] [G loss: 0.443772]\n",
      "epoch:14 step:13495 [D loss: 0.262941, acc.: 51.56%] [G loss: 0.439917]\n",
      "epoch:14 step:13496 [D loss: 0.227565, acc.: 63.28%] [G loss: 0.459401]\n",
      "epoch:14 step:13497 [D loss: 0.232430, acc.: 58.59%] [G loss: 0.444611]\n",
      "epoch:14 step:13498 [D loss: 0.252627, acc.: 62.50%] [G loss: 0.405788]\n",
      "epoch:14 step:13499 [D loss: 0.212368, acc.: 68.75%] [G loss: 0.437726]\n",
      "epoch:14 step:13500 [D loss: 0.202945, acc.: 72.66%] [G loss: 0.435878]\n",
      "epoch:14 step:13501 [D loss: 0.244344, acc.: 59.38%] [G loss: 0.412219]\n",
      "epoch:14 step:13502 [D loss: 0.214790, acc.: 67.19%] [G loss: 0.421833]\n",
      "epoch:14 step:13503 [D loss: 0.196032, acc.: 71.88%] [G loss: 0.456106]\n",
      "epoch:14 step:13504 [D loss: 0.219367, acc.: 63.28%] [G loss: 0.478747]\n",
      "epoch:14 step:13505 [D loss: 0.211218, acc.: 64.06%] [G loss: 0.467358]\n",
      "epoch:14 step:13506 [D loss: 0.224068, acc.: 60.16%] [G loss: 0.461854]\n",
      "epoch:14 step:13507 [D loss: 0.225438, acc.: 61.72%] [G loss: 0.473847]\n",
      "epoch:14 step:13508 [D loss: 0.257654, acc.: 59.38%] [G loss: 0.421578]\n",
      "epoch:14 step:13509 [D loss: 0.216848, acc.: 67.19%] [G loss: 0.423826]\n",
      "epoch:14 step:13510 [D loss: 0.230480, acc.: 63.28%] [G loss: 0.426545]\n",
      "epoch:14 step:13511 [D loss: 0.231863, acc.: 58.59%] [G loss: 0.439226]\n",
      "epoch:14 step:13512 [D loss: 0.207312, acc.: 67.19%] [G loss: 0.470584]\n",
      "epoch:14 step:13513 [D loss: 0.220566, acc.: 62.50%] [G loss: 0.389101]\n",
      "epoch:14 step:13514 [D loss: 0.267800, acc.: 51.56%] [G loss: 0.409193]\n",
      "epoch:14 step:13515 [D loss: 0.222970, acc.: 60.94%] [G loss: 0.457190]\n",
      "epoch:14 step:13516 [D loss: 0.205717, acc.: 67.97%] [G loss: 0.469077]\n",
      "epoch:14 step:13517 [D loss: 0.224286, acc.: 64.06%] [G loss: 0.478675]\n",
      "epoch:14 step:13518 [D loss: 0.249439, acc.: 57.03%] [G loss: 0.468280]\n",
      "epoch:14 step:13519 [D loss: 0.224057, acc.: 61.72%] [G loss: 0.445358]\n",
      "epoch:14 step:13520 [D loss: 0.207923, acc.: 69.53%] [G loss: 0.486683]\n",
      "epoch:14 step:13521 [D loss: 0.243390, acc.: 59.38%] [G loss: 0.428121]\n",
      "epoch:14 step:13522 [D loss: 0.203287, acc.: 71.88%] [G loss: 0.470989]\n",
      "epoch:14 step:13523 [D loss: 0.210135, acc.: 67.97%] [G loss: 0.456072]\n",
      "epoch:14 step:13524 [D loss: 0.207694, acc.: 72.66%] [G loss: 0.502243]\n",
      "epoch:14 step:13525 [D loss: 0.245459, acc.: 59.38%] [G loss: 0.486866]\n",
      "epoch:14 step:13526 [D loss: 0.276169, acc.: 53.12%] [G loss: 0.447033]\n",
      "epoch:14 step:13527 [D loss: 0.234824, acc.: 63.28%] [G loss: 0.448314]\n",
      "epoch:14 step:13528 [D loss: 0.248632, acc.: 53.91%] [G loss: 0.432595]\n",
      "epoch:14 step:13529 [D loss: 0.242375, acc.: 58.59%] [G loss: 0.404835]\n",
      "epoch:14 step:13530 [D loss: 0.237367, acc.: 56.25%] [G loss: 0.420071]\n",
      "epoch:14 step:13531 [D loss: 0.224806, acc.: 62.50%] [G loss: 0.412164]\n",
      "epoch:14 step:13532 [D loss: 0.234031, acc.: 55.47%] [G loss: 0.396173]\n",
      "epoch:14 step:13533 [D loss: 0.203595, acc.: 67.97%] [G loss: 0.465578]\n",
      "epoch:14 step:13534 [D loss: 0.197281, acc.: 64.84%] [G loss: 0.495607]\n",
      "epoch:14 step:13535 [D loss: 0.235521, acc.: 60.16%] [G loss: 0.508023]\n",
      "epoch:14 step:13536 [D loss: 0.262001, acc.: 49.22%] [G loss: 0.424045]\n",
      "epoch:14 step:13537 [D loss: 0.239913, acc.: 60.16%] [G loss: 0.440489]\n",
      "epoch:14 step:13538 [D loss: 0.240260, acc.: 56.25%] [G loss: 0.454057]\n",
      "epoch:14 step:13539 [D loss: 0.261949, acc.: 50.00%] [G loss: 0.431520]\n",
      "epoch:14 step:13540 [D loss: 0.252979, acc.: 50.00%] [G loss: 0.409916]\n",
      "epoch:14 step:13541 [D loss: 0.249434, acc.: 56.25%] [G loss: 0.418975]\n",
      "epoch:14 step:13542 [D loss: 0.227005, acc.: 62.50%] [G loss: 0.420488]\n",
      "epoch:14 step:13543 [D loss: 0.219189, acc.: 64.84%] [G loss: 0.436965]\n",
      "epoch:14 step:13544 [D loss: 0.206157, acc.: 64.84%] [G loss: 0.452451]\n",
      "epoch:14 step:13545 [D loss: 0.198964, acc.: 72.66%] [G loss: 0.465518]\n",
      "epoch:14 step:13546 [D loss: 0.208193, acc.: 70.31%] [G loss: 0.461437]\n",
      "epoch:14 step:13547 [D loss: 0.206385, acc.: 69.53%] [G loss: 0.481143]\n",
      "epoch:14 step:13548 [D loss: 0.224071, acc.: 62.50%] [G loss: 0.462895]\n",
      "epoch:14 step:13549 [D loss: 0.237544, acc.: 56.25%] [G loss: 0.411704]\n",
      "epoch:14 step:13550 [D loss: 0.240755, acc.: 55.47%] [G loss: 0.444859]\n",
      "epoch:14 step:13551 [D loss: 0.232653, acc.: 64.06%] [G loss: 0.416636]\n",
      "epoch:14 step:13552 [D loss: 0.225966, acc.: 59.38%] [G loss: 0.453439]\n",
      "epoch:14 step:13553 [D loss: 0.210120, acc.: 64.06%] [G loss: 0.478753]\n",
      "epoch:14 step:13554 [D loss: 0.195844, acc.: 68.75%] [G loss: 0.478146]\n",
      "epoch:14 step:13555 [D loss: 0.253155, acc.: 55.47%] [G loss: 0.473688]\n",
      "epoch:14 step:13556 [D loss: 0.249517, acc.: 57.03%] [G loss: 0.415661]\n",
      "epoch:14 step:13557 [D loss: 0.208888, acc.: 69.53%] [G loss: 0.447085]\n",
      "epoch:14 step:13558 [D loss: 0.212039, acc.: 66.41%] [G loss: 0.466033]\n",
      "epoch:14 step:13559 [D loss: 0.232796, acc.: 62.50%] [G loss: 0.521141]\n",
      "epoch:14 step:13560 [D loss: 0.246372, acc.: 64.06%] [G loss: 0.412141]\n",
      "epoch:14 step:13561 [D loss: 0.232262, acc.: 60.94%] [G loss: 0.450302]\n",
      "epoch:14 step:13562 [D loss: 0.223855, acc.: 63.28%] [G loss: 0.400335]\n",
      "epoch:14 step:13563 [D loss: 0.218457, acc.: 62.50%] [G loss: 0.469089]\n",
      "epoch:14 step:13564 [D loss: 0.224365, acc.: 66.41%] [G loss: 0.480189]\n",
      "epoch:14 step:13565 [D loss: 0.203222, acc.: 67.19%] [G loss: 0.483572]\n",
      "epoch:14 step:13566 [D loss: 0.253754, acc.: 56.25%] [G loss: 0.409274]\n",
      "epoch:14 step:13567 [D loss: 0.236939, acc.: 60.16%] [G loss: 0.425916]\n",
      "epoch:14 step:13568 [D loss: 0.225732, acc.: 62.50%] [G loss: 0.433036]\n",
      "epoch:14 step:13569 [D loss: 0.205067, acc.: 66.41%] [G loss: 0.447661]\n",
      "epoch:14 step:13570 [D loss: 0.209733, acc.: 66.41%] [G loss: 0.443960]\n",
      "epoch:14 step:13571 [D loss: 0.190577, acc.: 71.09%] [G loss: 0.475453]\n",
      "epoch:14 step:13572 [D loss: 0.230623, acc.: 60.94%] [G loss: 0.459283]\n",
      "epoch:14 step:13573 [D loss: 0.246047, acc.: 57.81%] [G loss: 0.452467]\n",
      "epoch:14 step:13574 [D loss: 0.239272, acc.: 63.28%] [G loss: 0.507009]\n",
      "epoch:14 step:13575 [D loss: 0.228479, acc.: 64.06%] [G loss: 0.478937]\n",
      "epoch:14 step:13576 [D loss: 0.300977, acc.: 48.44%] [G loss: 0.484269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13577 [D loss: 0.238833, acc.: 62.50%] [G loss: 0.474450]\n",
      "epoch:14 step:13578 [D loss: 0.226496, acc.: 64.06%] [G loss: 0.417415]\n",
      "epoch:14 step:13579 [D loss: 0.206948, acc.: 64.84%] [G loss: 0.445407]\n",
      "epoch:14 step:13580 [D loss: 0.256993, acc.: 51.56%] [G loss: 0.467486]\n",
      "epoch:14 step:13581 [D loss: 0.259458, acc.: 53.12%] [G loss: 0.395563]\n",
      "epoch:14 step:13582 [D loss: 0.219443, acc.: 61.72%] [G loss: 0.436995]\n",
      "epoch:14 step:13583 [D loss: 0.224436, acc.: 68.75%] [G loss: 0.447099]\n",
      "epoch:14 step:13584 [D loss: 0.225850, acc.: 62.50%] [G loss: 0.449263]\n",
      "epoch:14 step:13585 [D loss: 0.235623, acc.: 59.38%] [G loss: 0.406990]\n",
      "epoch:14 step:13586 [D loss: 0.204649, acc.: 71.09%] [G loss: 0.456122]\n",
      "epoch:14 step:13587 [D loss: 0.218470, acc.: 60.16%] [G loss: 0.498563]\n",
      "epoch:14 step:13588 [D loss: 0.231138, acc.: 65.62%] [G loss: 0.470313]\n",
      "epoch:14 step:13589 [D loss: 0.208923, acc.: 74.22%] [G loss: 0.484104]\n",
      "epoch:14 step:13590 [D loss: 0.188237, acc.: 71.09%] [G loss: 0.517753]\n",
      "epoch:14 step:13591 [D loss: 0.262912, acc.: 56.25%] [G loss: 0.460976]\n",
      "epoch:14 step:13592 [D loss: 0.200133, acc.: 67.19%] [G loss: 0.454823]\n",
      "epoch:14 step:13593 [D loss: 0.201155, acc.: 70.31%] [G loss: 0.449734]\n",
      "epoch:14 step:13594 [D loss: 0.250015, acc.: 57.81%] [G loss: 0.464814]\n",
      "epoch:14 step:13595 [D loss: 0.256295, acc.: 51.56%] [G loss: 0.435132]\n",
      "epoch:14 step:13596 [D loss: 0.261632, acc.: 50.00%] [G loss: 0.433938]\n",
      "epoch:14 step:13597 [D loss: 0.216143, acc.: 70.31%] [G loss: 0.449384]\n",
      "epoch:14 step:13598 [D loss: 0.221556, acc.: 67.19%] [G loss: 0.429284]\n",
      "epoch:14 step:13599 [D loss: 0.200463, acc.: 70.31%] [G loss: 0.449796]\n",
      "epoch:14 step:13600 [D loss: 0.272292, acc.: 56.25%] [G loss: 0.423373]\n",
      "epoch:14 step:13601 [D loss: 0.237049, acc.: 60.94%] [G loss: 0.471222]\n",
      "epoch:14 step:13602 [D loss: 0.177550, acc.: 71.09%] [G loss: 0.462422]\n",
      "epoch:14 step:13603 [D loss: 0.233130, acc.: 61.72%] [G loss: 0.425405]\n",
      "epoch:14 step:13604 [D loss: 0.259187, acc.: 52.34%] [G loss: 0.435057]\n",
      "epoch:14 step:13605 [D loss: 0.236869, acc.: 54.69%] [G loss: 0.424995]\n",
      "epoch:14 step:13606 [D loss: 0.203185, acc.: 67.97%] [G loss: 0.485137]\n",
      "epoch:14 step:13607 [D loss: 0.241354, acc.: 57.81%] [G loss: 0.464338]\n",
      "epoch:14 step:13608 [D loss: 0.249693, acc.: 55.47%] [G loss: 0.413380]\n",
      "epoch:14 step:13609 [D loss: 0.241230, acc.: 60.94%] [G loss: 0.421315]\n",
      "epoch:14 step:13610 [D loss: 0.235980, acc.: 59.38%] [G loss: 0.422420]\n",
      "epoch:14 step:13611 [D loss: 0.230017, acc.: 63.28%] [G loss: 0.444122]\n",
      "epoch:14 step:13612 [D loss: 0.216769, acc.: 64.84%] [G loss: 0.457972]\n",
      "epoch:14 step:13613 [D loss: 0.189862, acc.: 69.53%] [G loss: 0.467211]\n",
      "epoch:14 step:13614 [D loss: 0.220209, acc.: 67.19%] [G loss: 0.460169]\n",
      "epoch:14 step:13615 [D loss: 0.221724, acc.: 64.84%] [G loss: 0.453795]\n",
      "epoch:14 step:13616 [D loss: 0.204425, acc.: 66.41%] [G loss: 0.440792]\n",
      "epoch:14 step:13617 [D loss: 0.182205, acc.: 73.44%] [G loss: 0.548906]\n",
      "epoch:14 step:13618 [D loss: 0.260973, acc.: 53.12%] [G loss: 0.458968]\n",
      "epoch:14 step:13619 [D loss: 0.284926, acc.: 48.44%] [G loss: 0.460810]\n",
      "epoch:14 step:13620 [D loss: 0.235627, acc.: 58.59%] [G loss: 0.450618]\n",
      "epoch:14 step:13621 [D loss: 0.221868, acc.: 65.62%] [G loss: 0.405902]\n",
      "epoch:14 step:13622 [D loss: 0.202617, acc.: 64.84%] [G loss: 0.463935]\n",
      "epoch:14 step:13623 [D loss: 0.186198, acc.: 73.44%] [G loss: 0.507858]\n",
      "epoch:14 step:13624 [D loss: 0.237493, acc.: 58.59%] [G loss: 0.481773]\n",
      "epoch:14 step:13625 [D loss: 0.215605, acc.: 64.06%] [G loss: 0.487195]\n",
      "epoch:14 step:13626 [D loss: 0.177277, acc.: 74.22%] [G loss: 0.486489]\n",
      "epoch:14 step:13627 [D loss: 0.235899, acc.: 60.94%] [G loss: 0.436932]\n",
      "epoch:14 step:13628 [D loss: 0.226951, acc.: 64.06%] [G loss: 0.409868]\n",
      "epoch:14 step:13629 [D loss: 0.243000, acc.: 59.38%] [G loss: 0.441120]\n",
      "epoch:14 step:13630 [D loss: 0.220693, acc.: 64.06%] [G loss: 0.417696]\n",
      "epoch:14 step:13631 [D loss: 0.232347, acc.: 60.94%] [G loss: 0.446640]\n",
      "epoch:14 step:13632 [D loss: 0.209426, acc.: 61.72%] [G loss: 0.455327]\n",
      "epoch:14 step:13633 [D loss: 0.190292, acc.: 73.44%] [G loss: 0.450785]\n",
      "epoch:14 step:13634 [D loss: 0.182398, acc.: 67.19%] [G loss: 0.463105]\n",
      "epoch:14 step:13635 [D loss: 0.223460, acc.: 64.84%] [G loss: 0.465928]\n",
      "epoch:14 step:13636 [D loss: 0.250648, acc.: 60.16%] [G loss: 0.423532]\n",
      "epoch:14 step:13637 [D loss: 0.208154, acc.: 67.97%] [G loss: 0.452257]\n",
      "epoch:14 step:13638 [D loss: 0.198943, acc.: 71.09%] [G loss: 0.497519]\n",
      "epoch:14 step:13639 [D loss: 0.209655, acc.: 65.62%] [G loss: 0.450415]\n",
      "epoch:14 step:13640 [D loss: 0.224763, acc.: 61.72%] [G loss: 0.429844]\n",
      "epoch:14 step:13641 [D loss: 0.212535, acc.: 67.19%] [G loss: 0.443918]\n",
      "epoch:14 step:13642 [D loss: 0.218679, acc.: 64.06%] [G loss: 0.486795]\n",
      "epoch:14 step:13643 [D loss: 0.222646, acc.: 63.28%] [G loss: 0.461428]\n",
      "epoch:14 step:13644 [D loss: 0.200415, acc.: 71.88%] [G loss: 0.486259]\n",
      "epoch:14 step:13645 [D loss: 0.233364, acc.: 57.03%] [G loss: 0.462480]\n",
      "epoch:14 step:13646 [D loss: 0.277776, acc.: 52.34%] [G loss: 0.409204]\n",
      "epoch:14 step:13647 [D loss: 0.242645, acc.: 53.91%] [G loss: 0.390118]\n",
      "epoch:14 step:13648 [D loss: 0.216619, acc.: 67.97%] [G loss: 0.439795]\n",
      "epoch:14 step:13649 [D loss: 0.236921, acc.: 59.38%] [G loss: 0.417632]\n",
      "epoch:14 step:13650 [D loss: 0.223922, acc.: 62.50%] [G loss: 0.457866]\n",
      "epoch:14 step:13651 [D loss: 0.242060, acc.: 50.78%] [G loss: 0.454642]\n",
      "epoch:14 step:13652 [D loss: 0.191815, acc.: 71.09%] [G loss: 0.470214]\n",
      "epoch:14 step:13653 [D loss: 0.254939, acc.: 53.91%] [G loss: 0.430080]\n",
      "epoch:14 step:13654 [D loss: 0.253023, acc.: 59.38%] [G loss: 0.374869]\n",
      "epoch:14 step:13655 [D loss: 0.233080, acc.: 66.41%] [G loss: 0.424408]\n",
      "epoch:14 step:13656 [D loss: 0.208890, acc.: 66.41%] [G loss: 0.453989]\n",
      "epoch:14 step:13657 [D loss: 0.224873, acc.: 60.94%] [G loss: 0.435395]\n",
      "epoch:14 step:13658 [D loss: 0.219993, acc.: 57.81%] [G loss: 0.466628]\n",
      "epoch:14 step:13659 [D loss: 0.218622, acc.: 64.06%] [G loss: 0.431090]\n",
      "epoch:14 step:13660 [D loss: 0.249634, acc.: 53.91%] [G loss: 0.414270]\n",
      "epoch:14 step:13661 [D loss: 0.228299, acc.: 60.16%] [G loss: 0.428186]\n",
      "epoch:14 step:13662 [D loss: 0.199465, acc.: 71.88%] [G loss: 0.438020]\n",
      "epoch:14 step:13663 [D loss: 0.230078, acc.: 64.84%] [G loss: 0.404409]\n",
      "epoch:14 step:13664 [D loss: 0.203873, acc.: 70.31%] [G loss: 0.454759]\n",
      "epoch:14 step:13665 [D loss: 0.225760, acc.: 63.28%] [G loss: 0.480421]\n",
      "epoch:14 step:13666 [D loss: 0.213257, acc.: 67.19%] [G loss: 0.436899]\n",
      "epoch:14 step:13667 [D loss: 0.205085, acc.: 67.19%] [G loss: 0.469347]\n",
      "epoch:14 step:13668 [D loss: 0.215524, acc.: 64.84%] [G loss: 0.435999]\n",
      "epoch:14 step:13669 [D loss: 0.213932, acc.: 66.41%] [G loss: 0.531435]\n",
      "epoch:14 step:13670 [D loss: 0.215501, acc.: 66.41%] [G loss: 0.471623]\n",
      "epoch:14 step:13671 [D loss: 0.215642, acc.: 67.19%] [G loss: 0.470085]\n",
      "epoch:14 step:13672 [D loss: 0.207800, acc.: 69.53%] [G loss: 0.457113]\n",
      "epoch:14 step:13673 [D loss: 0.203470, acc.: 69.53%] [G loss: 0.412692]\n",
      "epoch:14 step:13674 [D loss: 0.209293, acc.: 67.19%] [G loss: 0.464345]\n",
      "epoch:14 step:13675 [D loss: 0.201893, acc.: 65.62%] [G loss: 0.471120]\n",
      "epoch:14 step:13676 [D loss: 0.218138, acc.: 64.06%] [G loss: 0.504229]\n",
      "epoch:14 step:13677 [D loss: 0.235714, acc.: 54.69%] [G loss: 0.475120]\n",
      "epoch:14 step:13678 [D loss: 0.246732, acc.: 60.16%] [G loss: 0.455445]\n",
      "epoch:14 step:13679 [D loss: 0.227231, acc.: 57.81%] [G loss: 0.461441]\n",
      "epoch:14 step:13680 [D loss: 0.218697, acc.: 63.28%] [G loss: 0.477522]\n",
      "epoch:14 step:13681 [D loss: 0.221561, acc.: 57.81%] [G loss: 0.492536]\n",
      "epoch:14 step:13682 [D loss: 0.200568, acc.: 70.31%] [G loss: 0.510412]\n",
      "epoch:14 step:13683 [D loss: 0.246816, acc.: 61.72%] [G loss: 0.486390]\n",
      "epoch:14 step:13684 [D loss: 0.262000, acc.: 53.91%] [G loss: 0.428000]\n",
      "epoch:14 step:13685 [D loss: 0.193203, acc.: 67.97%] [G loss: 0.468589]\n",
      "epoch:14 step:13686 [D loss: 0.208863, acc.: 67.19%] [G loss: 0.465712]\n",
      "epoch:14 step:13687 [D loss: 0.259577, acc.: 61.72%] [G loss: 0.418996]\n",
      "epoch:14 step:13688 [D loss: 0.200806, acc.: 67.19%] [G loss: 0.420571]\n",
      "epoch:14 step:13689 [D loss: 0.203045, acc.: 67.19%] [G loss: 0.446074]\n",
      "epoch:14 step:13690 [D loss: 0.235781, acc.: 60.94%] [G loss: 0.448157]\n",
      "epoch:14 step:13691 [D loss: 0.232074, acc.: 62.50%] [G loss: 0.469583]\n",
      "epoch:14 step:13692 [D loss: 0.189334, acc.: 75.00%] [G loss: 0.479303]\n",
      "epoch:14 step:13693 [D loss: 0.207973, acc.: 70.31%] [G loss: 0.531629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13694 [D loss: 0.209058, acc.: 64.06%] [G loss: 0.461290]\n",
      "epoch:14 step:13695 [D loss: 0.228079, acc.: 64.06%] [G loss: 0.469962]\n",
      "epoch:14 step:13696 [D loss: 0.210105, acc.: 66.41%] [G loss: 0.461685]\n",
      "epoch:14 step:13697 [D loss: 0.240266, acc.: 60.16%] [G loss: 0.425909]\n",
      "epoch:14 step:13698 [D loss: 0.228363, acc.: 61.72%] [G loss: 0.451196]\n",
      "epoch:14 step:13699 [D loss: 0.207808, acc.: 61.72%] [G loss: 0.451237]\n",
      "epoch:14 step:13700 [D loss: 0.196544, acc.: 71.88%] [G loss: 0.491095]\n",
      "epoch:14 step:13701 [D loss: 0.247046, acc.: 60.16%] [G loss: 0.489704]\n",
      "epoch:14 step:13702 [D loss: 0.219884, acc.: 60.94%] [G loss: 0.505634]\n",
      "epoch:14 step:13703 [D loss: 0.222412, acc.: 60.16%] [G loss: 0.472499]\n",
      "epoch:14 step:13704 [D loss: 0.212158, acc.: 65.62%] [G loss: 0.425135]\n",
      "epoch:14 step:13705 [D loss: 0.229653, acc.: 57.03%] [G loss: 0.468284]\n",
      "epoch:14 step:13706 [D loss: 0.210573, acc.: 64.06%] [G loss: 0.388232]\n",
      "epoch:14 step:13707 [D loss: 0.194729, acc.: 67.97%] [G loss: 0.435112]\n",
      "epoch:14 step:13708 [D loss: 0.249391, acc.: 60.16%] [G loss: 0.426774]\n",
      "epoch:14 step:13709 [D loss: 0.240970, acc.: 58.59%] [G loss: 0.449053]\n",
      "epoch:14 step:13710 [D loss: 0.197631, acc.: 71.88%] [G loss: 0.479238]\n",
      "epoch:14 step:13711 [D loss: 0.229437, acc.: 60.94%] [G loss: 0.426045]\n",
      "epoch:14 step:13712 [D loss: 0.234976, acc.: 60.16%] [G loss: 0.423202]\n",
      "epoch:14 step:13713 [D loss: 0.220133, acc.: 64.06%] [G loss: 0.421954]\n",
      "epoch:14 step:13714 [D loss: 0.214025, acc.: 64.84%] [G loss: 0.459461]\n",
      "epoch:14 step:13715 [D loss: 0.217827, acc.: 64.06%] [G loss: 0.427210]\n",
      "epoch:14 step:13716 [D loss: 0.217356, acc.: 73.44%] [G loss: 0.453034]\n",
      "epoch:14 step:13717 [D loss: 0.213746, acc.: 66.41%] [G loss: 0.469938]\n",
      "epoch:14 step:13718 [D loss: 0.263471, acc.: 50.78%] [G loss: 0.410989]\n",
      "epoch:14 step:13719 [D loss: 0.218260, acc.: 63.28%] [G loss: 0.440658]\n",
      "epoch:14 step:13720 [D loss: 0.237745, acc.: 60.16%] [G loss: 0.423973]\n",
      "epoch:14 step:13721 [D loss: 0.227752, acc.: 60.16%] [G loss: 0.466758]\n",
      "epoch:14 step:13722 [D loss: 0.220644, acc.: 67.19%] [G loss: 0.436361]\n",
      "epoch:14 step:13723 [D loss: 0.241978, acc.: 64.06%] [G loss: 0.416754]\n",
      "epoch:14 step:13724 [D loss: 0.239103, acc.: 60.94%] [G loss: 0.405964]\n",
      "epoch:14 step:13725 [D loss: 0.237991, acc.: 62.50%] [G loss: 0.475124]\n",
      "epoch:14 step:13726 [D loss: 0.213623, acc.: 65.62%] [G loss: 0.481052]\n",
      "epoch:14 step:13727 [D loss: 0.236200, acc.: 54.69%] [G loss: 0.408493]\n",
      "epoch:14 step:13728 [D loss: 0.225190, acc.: 64.84%] [G loss: 0.436680]\n",
      "epoch:14 step:13729 [D loss: 0.223548, acc.: 62.50%] [G loss: 0.445822]\n",
      "epoch:14 step:13730 [D loss: 0.218186, acc.: 63.28%] [G loss: 0.451501]\n",
      "epoch:14 step:13731 [D loss: 0.205099, acc.: 71.88%] [G loss: 0.420155]\n",
      "epoch:14 step:13732 [D loss: 0.241452, acc.: 58.59%] [G loss: 0.450899]\n",
      "epoch:14 step:13733 [D loss: 0.266188, acc.: 54.69%] [G loss: 0.390146]\n",
      "epoch:14 step:13734 [D loss: 0.255240, acc.: 60.16%] [G loss: 0.406302]\n",
      "epoch:14 step:13735 [D loss: 0.256597, acc.: 57.81%] [G loss: 0.437361]\n",
      "epoch:14 step:13736 [D loss: 0.210128, acc.: 67.97%] [G loss: 0.477329]\n",
      "epoch:14 step:13737 [D loss: 0.239942, acc.: 60.94%] [G loss: 0.451869]\n",
      "epoch:14 step:13738 [D loss: 0.200826, acc.: 68.75%] [G loss: 0.427604]\n",
      "epoch:14 step:13739 [D loss: 0.232907, acc.: 57.81%] [G loss: 0.423985]\n",
      "epoch:14 step:13740 [D loss: 0.267005, acc.: 55.47%] [G loss: 0.433324]\n",
      "epoch:14 step:13741 [D loss: 0.231037, acc.: 64.06%] [G loss: 0.422917]\n",
      "epoch:14 step:13742 [D loss: 0.181965, acc.: 73.44%] [G loss: 0.468196]\n",
      "epoch:14 step:13743 [D loss: 0.245116, acc.: 58.59%] [G loss: 0.456143]\n",
      "epoch:14 step:13744 [D loss: 0.263080, acc.: 57.03%] [G loss: 0.410046]\n",
      "epoch:14 step:13745 [D loss: 0.202851, acc.: 70.31%] [G loss: 0.439217]\n",
      "epoch:14 step:13746 [D loss: 0.235747, acc.: 58.59%] [G loss: 0.410955]\n",
      "epoch:14 step:13747 [D loss: 0.188027, acc.: 74.22%] [G loss: 0.453363]\n",
      "epoch:14 step:13748 [D loss: 0.246883, acc.: 57.81%] [G loss: 0.442620]\n",
      "epoch:14 step:13749 [D loss: 0.221781, acc.: 66.41%] [G loss: 0.464836]\n",
      "epoch:14 step:13750 [D loss: 0.233725, acc.: 64.84%] [G loss: 0.425892]\n",
      "epoch:14 step:13751 [D loss: 0.234420, acc.: 59.38%] [G loss: 0.477804]\n",
      "epoch:14 step:13752 [D loss: 0.199309, acc.: 70.31%] [G loss: 0.484483]\n",
      "epoch:14 step:13753 [D loss: 0.199859, acc.: 70.31%] [G loss: 0.536466]\n",
      "epoch:14 step:13754 [D loss: 0.259201, acc.: 55.47%] [G loss: 0.437474]\n",
      "epoch:14 step:13755 [D loss: 0.207616, acc.: 67.19%] [G loss: 0.468023]\n",
      "epoch:14 step:13756 [D loss: 0.253339, acc.: 57.81%] [G loss: 0.469530]\n",
      "epoch:14 step:13757 [D loss: 0.219607, acc.: 64.06%] [G loss: 0.446182]\n",
      "epoch:14 step:13758 [D loss: 0.224377, acc.: 64.84%] [G loss: 0.444530]\n",
      "epoch:14 step:13759 [D loss: 0.198072, acc.: 71.88%] [G loss: 0.471086]\n",
      "epoch:14 step:13760 [D loss: 0.198573, acc.: 71.09%] [G loss: 0.477931]\n",
      "epoch:14 step:13761 [D loss: 0.244538, acc.: 57.81%] [G loss: 0.437609]\n",
      "epoch:14 step:13762 [D loss: 0.226686, acc.: 64.06%] [G loss: 0.410723]\n",
      "epoch:14 step:13763 [D loss: 0.200677, acc.: 64.06%] [G loss: 0.436632]\n",
      "epoch:14 step:13764 [D loss: 0.225786, acc.: 65.62%] [G loss: 0.458719]\n",
      "epoch:14 step:13765 [D loss: 0.216054, acc.: 64.06%] [G loss: 0.489048]\n",
      "epoch:14 step:13766 [D loss: 0.193343, acc.: 69.53%] [G loss: 0.525636]\n",
      "epoch:14 step:13767 [D loss: 0.207170, acc.: 65.62%] [G loss: 0.491400]\n",
      "epoch:14 step:13768 [D loss: 0.205783, acc.: 67.97%] [G loss: 0.470643]\n",
      "epoch:14 step:13769 [D loss: 0.239205, acc.: 62.50%] [G loss: 0.426243]\n",
      "epoch:14 step:13770 [D loss: 0.228694, acc.: 55.47%] [G loss: 0.434752]\n",
      "epoch:14 step:13771 [D loss: 0.229166, acc.: 63.28%] [G loss: 0.445237]\n",
      "epoch:14 step:13772 [D loss: 0.211332, acc.: 67.19%] [G loss: 0.482746]\n",
      "epoch:14 step:13773 [D loss: 0.260781, acc.: 55.47%] [G loss: 0.484270]\n",
      "epoch:14 step:13774 [D loss: 0.212738, acc.: 64.84%] [G loss: 0.485480]\n",
      "epoch:14 step:13775 [D loss: 0.213327, acc.: 66.41%] [G loss: 0.488748]\n",
      "epoch:14 step:13776 [D loss: 0.221575, acc.: 64.06%] [G loss: 0.433708]\n",
      "epoch:14 step:13777 [D loss: 0.225916, acc.: 58.59%] [G loss: 0.442422]\n",
      "epoch:14 step:13778 [D loss: 0.224729, acc.: 64.84%] [G loss: 0.450327]\n",
      "epoch:14 step:13779 [D loss: 0.212143, acc.: 64.06%] [G loss: 0.463824]\n",
      "epoch:14 step:13780 [D loss: 0.245236, acc.: 58.59%] [G loss: 0.458046]\n",
      "epoch:14 step:13781 [D loss: 0.217091, acc.: 68.75%] [G loss: 0.465061]\n",
      "epoch:14 step:13782 [D loss: 0.233073, acc.: 59.38%] [G loss: 0.465567]\n",
      "epoch:14 step:13783 [D loss: 0.217047, acc.: 62.50%] [G loss: 0.448038]\n",
      "epoch:14 step:13784 [D loss: 0.237368, acc.: 65.62%] [G loss: 0.424849]\n",
      "epoch:14 step:13785 [D loss: 0.214216, acc.: 70.31%] [G loss: 0.461785]\n",
      "epoch:14 step:13786 [D loss: 0.229189, acc.: 60.94%] [G loss: 0.459993]\n",
      "epoch:14 step:13787 [D loss: 0.230164, acc.: 57.03%] [G loss: 0.404035]\n",
      "epoch:14 step:13788 [D loss: 0.226538, acc.: 60.94%] [G loss: 0.445705]\n",
      "epoch:14 step:13789 [D loss: 0.240937, acc.: 58.59%] [G loss: 0.417883]\n",
      "epoch:14 step:13790 [D loss: 0.262365, acc.: 50.00%] [G loss: 0.450604]\n",
      "epoch:14 step:13791 [D loss: 0.268051, acc.: 55.47%] [G loss: 0.430086]\n",
      "epoch:14 step:13792 [D loss: 0.206169, acc.: 70.31%] [G loss: 0.471893]\n",
      "epoch:14 step:13793 [D loss: 0.264097, acc.: 52.34%] [G loss: 0.395634]\n",
      "epoch:14 step:13794 [D loss: 0.243246, acc.: 59.38%] [G loss: 0.405845]\n",
      "epoch:14 step:13795 [D loss: 0.201836, acc.: 71.88%] [G loss: 0.420916]\n",
      "epoch:14 step:13796 [D loss: 0.221944, acc.: 62.50%] [G loss: 0.485692]\n",
      "epoch:14 step:13797 [D loss: 0.215105, acc.: 63.28%] [G loss: 0.458428]\n",
      "epoch:14 step:13798 [D loss: 0.231992, acc.: 64.84%] [G loss: 0.432347]\n",
      "epoch:14 step:13799 [D loss: 0.201621, acc.: 69.53%] [G loss: 0.439700]\n",
      "epoch:14 step:13800 [D loss: 0.239484, acc.: 61.72%] [G loss: 0.430062]\n",
      "epoch:14 step:13801 [D loss: 0.243131, acc.: 59.38%] [G loss: 0.414370]\n",
      "epoch:14 step:13802 [D loss: 0.239400, acc.: 59.38%] [G loss: 0.384993]\n",
      "epoch:14 step:13803 [D loss: 0.217424, acc.: 66.41%] [G loss: 0.428081]\n",
      "epoch:14 step:13804 [D loss: 0.221847, acc.: 60.16%] [G loss: 0.404685]\n",
      "epoch:14 step:13805 [D loss: 0.242853, acc.: 59.38%] [G loss: 0.454339]\n",
      "epoch:14 step:13806 [D loss: 0.227515, acc.: 63.28%] [G loss: 0.442607]\n",
      "epoch:14 step:13807 [D loss: 0.238351, acc.: 57.03%] [G loss: 0.455155]\n",
      "epoch:14 step:13808 [D loss: 0.234907, acc.: 60.16%] [G loss: 0.459615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13809 [D loss: 0.230348, acc.: 64.06%] [G loss: 0.484684]\n",
      "epoch:14 step:13810 [D loss: 0.201695, acc.: 71.88%] [G loss: 0.476761]\n",
      "epoch:14 step:13811 [D loss: 0.220754, acc.: 62.50%] [G loss: 0.463192]\n",
      "epoch:14 step:13812 [D loss: 0.204143, acc.: 67.19%] [G loss: 0.508109]\n",
      "epoch:14 step:13813 [D loss: 0.237833, acc.: 60.94%] [G loss: 0.486274]\n",
      "epoch:14 step:13814 [D loss: 0.268507, acc.: 50.78%] [G loss: 0.455540]\n",
      "epoch:14 step:13815 [D loss: 0.234259, acc.: 59.38%] [G loss: 0.434946]\n",
      "epoch:14 step:13816 [D loss: 0.242686, acc.: 55.47%] [G loss: 0.441739]\n",
      "epoch:14 step:13817 [D loss: 0.204778, acc.: 68.75%] [G loss: 0.416822]\n",
      "epoch:14 step:13818 [D loss: 0.207832, acc.: 67.19%] [G loss: 0.482857]\n",
      "epoch:14 step:13819 [D loss: 0.200305, acc.: 67.97%] [G loss: 0.500119]\n",
      "epoch:14 step:13820 [D loss: 0.224549, acc.: 66.41%] [G loss: 0.461093]\n",
      "epoch:14 step:13821 [D loss: 0.255957, acc.: 58.59%] [G loss: 0.411793]\n",
      "epoch:14 step:13822 [D loss: 0.252134, acc.: 53.91%] [G loss: 0.418226]\n",
      "epoch:14 step:13823 [D loss: 0.217403, acc.: 64.84%] [G loss: 0.456014]\n",
      "epoch:14 step:13824 [D loss: 0.241275, acc.: 57.81%] [G loss: 0.417505]\n",
      "epoch:14 step:13825 [D loss: 0.206927, acc.: 66.41%] [G loss: 0.451940]\n",
      "epoch:14 step:13826 [D loss: 0.186393, acc.: 73.44%] [G loss: 0.454003]\n",
      "epoch:14 step:13827 [D loss: 0.206585, acc.: 65.62%] [G loss: 0.490097]\n",
      "epoch:14 step:13828 [D loss: 0.272839, acc.: 59.38%] [G loss: 0.439116]\n",
      "epoch:14 step:13829 [D loss: 0.204151, acc.: 71.09%] [G loss: 0.462133]\n",
      "epoch:14 step:13830 [D loss: 0.223123, acc.: 65.62%] [G loss: 0.443885]\n",
      "epoch:14 step:13831 [D loss: 0.225387, acc.: 64.06%] [G loss: 0.439470]\n",
      "epoch:14 step:13832 [D loss: 0.207381, acc.: 69.53%] [G loss: 0.479325]\n",
      "epoch:14 step:13833 [D loss: 0.247276, acc.: 55.47%] [G loss: 0.452863]\n",
      "epoch:14 step:13834 [D loss: 0.252278, acc.: 53.12%] [G loss: 0.410791]\n",
      "epoch:14 step:13835 [D loss: 0.230847, acc.: 65.62%] [G loss: 0.447874]\n",
      "epoch:14 step:13836 [D loss: 0.214588, acc.: 66.41%] [G loss: 0.438745]\n",
      "epoch:14 step:13837 [D loss: 0.209804, acc.: 66.41%] [G loss: 0.494114]\n",
      "epoch:14 step:13838 [D loss: 0.243957, acc.: 62.50%] [G loss: 0.421248]\n",
      "epoch:14 step:13839 [D loss: 0.222579, acc.: 64.84%] [G loss: 0.443389]\n",
      "epoch:14 step:13840 [D loss: 0.223391, acc.: 64.06%] [G loss: 0.416724]\n",
      "epoch:14 step:13841 [D loss: 0.198003, acc.: 69.53%] [G loss: 0.446287]\n",
      "epoch:14 step:13842 [D loss: 0.192962, acc.: 71.09%] [G loss: 0.436372]\n",
      "epoch:14 step:13843 [D loss: 0.224681, acc.: 67.19%] [G loss: 0.467676]\n",
      "epoch:14 step:13844 [D loss: 0.215685, acc.: 64.84%] [G loss: 0.509750]\n",
      "epoch:14 step:13845 [D loss: 0.234535, acc.: 58.59%] [G loss: 0.420609]\n",
      "epoch:14 step:13846 [D loss: 0.228889, acc.: 64.84%] [G loss: 0.421690]\n",
      "epoch:14 step:13847 [D loss: 0.238538, acc.: 62.50%] [G loss: 0.430123]\n",
      "epoch:14 step:13848 [D loss: 0.202009, acc.: 74.22%] [G loss: 0.435667]\n",
      "epoch:14 step:13849 [D loss: 0.231032, acc.: 64.84%] [G loss: 0.420798]\n",
      "epoch:14 step:13850 [D loss: 0.230926, acc.: 60.94%] [G loss: 0.477639]\n",
      "epoch:14 step:13851 [D loss: 0.200472, acc.: 71.88%] [G loss: 0.427209]\n",
      "epoch:14 step:13852 [D loss: 0.231363, acc.: 56.25%] [G loss: 0.416380]\n",
      "epoch:14 step:13853 [D loss: 0.219821, acc.: 63.28%] [G loss: 0.425796]\n",
      "epoch:14 step:13854 [D loss: 0.222686, acc.: 66.41%] [G loss: 0.420104]\n",
      "epoch:14 step:13855 [D loss: 0.217333, acc.: 62.50%] [G loss: 0.410783]\n",
      "epoch:14 step:13856 [D loss: 0.255857, acc.: 50.78%] [G loss: 0.398682]\n",
      "epoch:14 step:13857 [D loss: 0.255548, acc.: 53.91%] [G loss: 0.414757]\n",
      "epoch:14 step:13858 [D loss: 0.226889, acc.: 63.28%] [G loss: 0.405518]\n",
      "epoch:14 step:13859 [D loss: 0.232024, acc.: 61.72%] [G loss: 0.442390]\n",
      "epoch:14 step:13860 [D loss: 0.223069, acc.: 64.84%] [G loss: 0.401078]\n",
      "epoch:14 step:13861 [D loss: 0.200129, acc.: 71.09%] [G loss: 0.433928]\n",
      "epoch:14 step:13862 [D loss: 0.217413, acc.: 65.62%] [G loss: 0.440797]\n",
      "epoch:14 step:13863 [D loss: 0.242650, acc.: 57.03%] [G loss: 0.431846]\n",
      "epoch:14 step:13864 [D loss: 0.211071, acc.: 69.53%] [G loss: 0.436068]\n",
      "epoch:14 step:13865 [D loss: 0.216499, acc.: 66.41%] [G loss: 0.482659]\n",
      "epoch:14 step:13866 [D loss: 0.239063, acc.: 61.72%] [G loss: 0.428403]\n",
      "epoch:14 step:13867 [D loss: 0.241539, acc.: 58.59%] [G loss: 0.403038]\n",
      "epoch:14 step:13868 [D loss: 0.216929, acc.: 63.28%] [G loss: 0.434376]\n",
      "epoch:14 step:13869 [D loss: 0.211342, acc.: 67.19%] [G loss: 0.425941]\n",
      "epoch:14 step:13870 [D loss: 0.223224, acc.: 69.53%] [G loss: 0.450712]\n",
      "epoch:14 step:13871 [D loss: 0.249750, acc.: 62.50%] [G loss: 0.410372]\n",
      "epoch:14 step:13872 [D loss: 0.224147, acc.: 63.28%] [G loss: 0.429970]\n",
      "epoch:14 step:13873 [D loss: 0.231919, acc.: 61.72%] [G loss: 0.481324]\n",
      "epoch:14 step:13874 [D loss: 0.222109, acc.: 65.62%] [G loss: 0.440828]\n",
      "epoch:14 step:13875 [D loss: 0.235610, acc.: 63.28%] [G loss: 0.415450]\n",
      "epoch:14 step:13876 [D loss: 0.252733, acc.: 57.03%] [G loss: 0.449446]\n",
      "epoch:14 step:13877 [D loss: 0.233520, acc.: 64.06%] [G loss: 0.414407]\n",
      "epoch:14 step:13878 [D loss: 0.216549, acc.: 64.06%] [G loss: 0.397125]\n",
      "epoch:14 step:13879 [D loss: 0.224322, acc.: 60.94%] [G loss: 0.454936]\n",
      "epoch:14 step:13880 [D loss: 0.216326, acc.: 64.84%] [G loss: 0.449092]\n",
      "epoch:14 step:13881 [D loss: 0.219190, acc.: 64.06%] [G loss: 0.457931]\n",
      "epoch:14 step:13882 [D loss: 0.247644, acc.: 53.91%] [G loss: 0.453117]\n",
      "epoch:14 step:13883 [D loss: 0.274068, acc.: 50.78%] [G loss: 0.411511]\n",
      "epoch:14 step:13884 [D loss: 0.226697, acc.: 62.50%] [G loss: 0.406281]\n",
      "epoch:14 step:13885 [D loss: 0.217415, acc.: 64.06%] [G loss: 0.440154]\n",
      "epoch:14 step:13886 [D loss: 0.249700, acc.: 61.72%] [G loss: 0.458738]\n",
      "epoch:14 step:13887 [D loss: 0.209686, acc.: 65.62%] [G loss: 0.472289]\n",
      "epoch:14 step:13888 [D loss: 0.224814, acc.: 60.16%] [G loss: 0.412087]\n",
      "epoch:14 step:13889 [D loss: 0.253635, acc.: 57.81%] [G loss: 0.400518]\n",
      "epoch:14 step:13890 [D loss: 0.223921, acc.: 62.50%] [G loss: 0.436081]\n",
      "epoch:14 step:13891 [D loss: 0.210650, acc.: 67.19%] [G loss: 0.465907]\n",
      "epoch:14 step:13892 [D loss: 0.220695, acc.: 64.84%] [G loss: 0.457741]\n",
      "epoch:14 step:13893 [D loss: 0.213633, acc.: 64.06%] [G loss: 0.408488]\n",
      "epoch:14 step:13894 [D loss: 0.250531, acc.: 55.47%] [G loss: 0.418172]\n",
      "epoch:14 step:13895 [D loss: 0.209784, acc.: 69.53%] [G loss: 0.412854]\n",
      "epoch:14 step:13896 [D loss: 0.205157, acc.: 67.97%] [G loss: 0.472651]\n",
      "epoch:14 step:13897 [D loss: 0.253008, acc.: 59.38%] [G loss: 0.469755]\n",
      "epoch:14 step:13898 [D loss: 0.218586, acc.: 67.19%] [G loss: 0.465088]\n",
      "epoch:14 step:13899 [D loss: 0.178838, acc.: 70.31%] [G loss: 0.528456]\n",
      "epoch:14 step:13900 [D loss: 0.198027, acc.: 72.66%] [G loss: 0.545014]\n",
      "epoch:14 step:13901 [D loss: 0.235451, acc.: 57.03%] [G loss: 0.454760]\n",
      "epoch:14 step:13902 [D loss: 0.271815, acc.: 50.78%] [G loss: 0.390668]\n",
      "epoch:14 step:13903 [D loss: 0.226196, acc.: 64.84%] [G loss: 0.426598]\n",
      "epoch:14 step:13904 [D loss: 0.216476, acc.: 62.50%] [G loss: 0.434312]\n",
      "epoch:14 step:13905 [D loss: 0.233706, acc.: 60.94%] [G loss: 0.447557]\n",
      "epoch:14 step:13906 [D loss: 0.248501, acc.: 53.12%] [G loss: 0.431675]\n",
      "epoch:14 step:13907 [D loss: 0.238629, acc.: 61.72%] [G loss: 0.404101]\n",
      "epoch:14 step:13908 [D loss: 0.205932, acc.: 69.53%] [G loss: 0.458397]\n",
      "epoch:14 step:13909 [D loss: 0.264907, acc.: 53.12%] [G loss: 0.422529]\n",
      "epoch:14 step:13910 [D loss: 0.203301, acc.: 67.19%] [G loss: 0.440044]\n",
      "epoch:14 step:13911 [D loss: 0.247306, acc.: 59.38%] [G loss: 0.441979]\n",
      "epoch:14 step:13912 [D loss: 0.255265, acc.: 53.12%] [G loss: 0.439604]\n",
      "epoch:14 step:13913 [D loss: 0.242303, acc.: 55.47%] [G loss: 0.460714]\n",
      "epoch:14 step:13914 [D loss: 0.197270, acc.: 68.75%] [G loss: 0.450378]\n",
      "epoch:14 step:13915 [D loss: 0.257120, acc.: 52.34%] [G loss: 0.416912]\n",
      "epoch:14 step:13916 [D loss: 0.228349, acc.: 60.16%] [G loss: 0.404416]\n",
      "epoch:14 step:13917 [D loss: 0.214650, acc.: 63.28%] [G loss: 0.466856]\n",
      "epoch:14 step:13918 [D loss: 0.255184, acc.: 54.69%] [G loss: 0.404544]\n",
      "epoch:14 step:13919 [D loss: 0.236624, acc.: 57.03%] [G loss: 0.499540]\n",
      "epoch:14 step:13920 [D loss: 0.220141, acc.: 64.84%] [G loss: 0.531156]\n",
      "epoch:14 step:13921 [D loss: 0.210999, acc.: 66.41%] [G loss: 0.437161]\n",
      "epoch:14 step:13922 [D loss: 0.221609, acc.: 63.28%] [G loss: 0.459454]\n",
      "epoch:14 step:13923 [D loss: 0.223400, acc.: 63.28%] [G loss: 0.421948]\n",
      "epoch:14 step:13924 [D loss: 0.215128, acc.: 64.06%] [G loss: 0.446344]\n",
      "epoch:14 step:13925 [D loss: 0.212335, acc.: 69.53%] [G loss: 0.460467]\n",
      "epoch:14 step:13926 [D loss: 0.249309, acc.: 53.91%] [G loss: 0.384076]\n",
      "epoch:14 step:13927 [D loss: 0.250921, acc.: 56.25%] [G loss: 0.392139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13928 [D loss: 0.243580, acc.: 57.81%] [G loss: 0.417124]\n",
      "epoch:14 step:13929 [D loss: 0.239414, acc.: 64.06%] [G loss: 0.444847]\n",
      "epoch:14 step:13930 [D loss: 0.246214, acc.: 57.03%] [G loss: 0.438226]\n",
      "epoch:14 step:13931 [D loss: 0.224696, acc.: 64.06%] [G loss: 0.424065]\n",
      "epoch:14 step:13932 [D loss: 0.243939, acc.: 60.94%] [G loss: 0.450296]\n",
      "epoch:14 step:13933 [D loss: 0.215348, acc.: 64.84%] [G loss: 0.500108]\n",
      "epoch:14 step:13934 [D loss: 0.224728, acc.: 57.81%] [G loss: 0.488801]\n",
      "epoch:14 step:13935 [D loss: 0.243478, acc.: 61.72%] [G loss: 0.420790]\n",
      "epoch:14 step:13936 [D loss: 0.235738, acc.: 59.38%] [G loss: 0.440652]\n",
      "epoch:14 step:13937 [D loss: 0.212436, acc.: 62.50%] [G loss: 0.456637]\n",
      "epoch:14 step:13938 [D loss: 0.278912, acc.: 47.66%] [G loss: 0.433845]\n",
      "epoch:14 step:13939 [D loss: 0.231353, acc.: 56.25%] [G loss: 0.396532]\n",
      "epoch:14 step:13940 [D loss: 0.218923, acc.: 60.16%] [G loss: 0.441441]\n",
      "epoch:14 step:13941 [D loss: 0.218891, acc.: 65.62%] [G loss: 0.451040]\n",
      "epoch:14 step:13942 [D loss: 0.239385, acc.: 63.28%] [G loss: 0.421408]\n",
      "epoch:14 step:13943 [D loss: 0.206313, acc.: 73.44%] [G loss: 0.421669]\n",
      "epoch:14 step:13944 [D loss: 0.251746, acc.: 61.72%] [G loss: 0.440827]\n",
      "epoch:14 step:13945 [D loss: 0.221193, acc.: 62.50%] [G loss: 0.486542]\n",
      "epoch:14 step:13946 [D loss: 0.247616, acc.: 50.00%] [G loss: 0.421927]\n",
      "epoch:14 step:13947 [D loss: 0.208474, acc.: 71.09%] [G loss: 0.431291]\n",
      "epoch:14 step:13948 [D loss: 0.246205, acc.: 60.16%] [G loss: 0.439444]\n",
      "epoch:14 step:13949 [D loss: 0.249933, acc.: 53.12%] [G loss: 0.431435]\n",
      "epoch:14 step:13950 [D loss: 0.235221, acc.: 63.28%] [G loss: 0.423557]\n",
      "epoch:14 step:13951 [D loss: 0.189224, acc.: 75.00%] [G loss: 0.479162]\n",
      "epoch:14 step:13952 [D loss: 0.240828, acc.: 60.94%] [G loss: 0.402827]\n",
      "epoch:14 step:13953 [D loss: 0.189901, acc.: 71.88%] [G loss: 0.487435]\n",
      "epoch:14 step:13954 [D loss: 0.238929, acc.: 59.38%] [G loss: 0.428877]\n",
      "epoch:14 step:13955 [D loss: 0.222128, acc.: 69.53%] [G loss: 0.422941]\n",
      "epoch:14 step:13956 [D loss: 0.228467, acc.: 64.06%] [G loss: 0.438783]\n",
      "epoch:14 step:13957 [D loss: 0.206113, acc.: 65.62%] [G loss: 0.471528]\n",
      "epoch:14 step:13958 [D loss: 0.212650, acc.: 67.97%] [G loss: 0.399076]\n",
      "epoch:14 step:13959 [D loss: 0.224573, acc.: 64.84%] [G loss: 0.423999]\n",
      "epoch:14 step:13960 [D loss: 0.194079, acc.: 68.75%] [G loss: 0.468362]\n",
      "epoch:14 step:13961 [D loss: 0.241770, acc.: 60.16%] [G loss: 0.422475]\n",
      "epoch:14 step:13962 [D loss: 0.208522, acc.: 64.84%] [G loss: 0.484897]\n",
      "epoch:14 step:13963 [D loss: 0.208007, acc.: 69.53%] [G loss: 0.450978]\n",
      "epoch:14 step:13964 [D loss: 0.243511, acc.: 57.03%] [G loss: 0.422893]\n",
      "epoch:14 step:13965 [D loss: 0.233215, acc.: 59.38%] [G loss: 0.426661]\n",
      "epoch:14 step:13966 [D loss: 0.231762, acc.: 64.06%] [G loss: 0.409874]\n",
      "epoch:14 step:13967 [D loss: 0.189687, acc.: 71.09%] [G loss: 0.433317]\n",
      "epoch:14 step:13968 [D loss: 0.246337, acc.: 58.59%] [G loss: 0.424543]\n",
      "epoch:14 step:13969 [D loss: 0.240019, acc.: 57.03%] [G loss: 0.430875]\n",
      "epoch:14 step:13970 [D loss: 0.216585, acc.: 59.38%] [G loss: 0.472269]\n",
      "epoch:14 step:13971 [D loss: 0.237918, acc.: 61.72%] [G loss: 0.493329]\n",
      "epoch:14 step:13972 [D loss: 0.219220, acc.: 64.06%] [G loss: 0.443795]\n",
      "epoch:14 step:13973 [D loss: 0.216143, acc.: 64.84%] [G loss: 0.479918]\n",
      "epoch:14 step:13974 [D loss: 0.249626, acc.: 54.69%] [G loss: 0.402698]\n",
      "epoch:14 step:13975 [D loss: 0.204894, acc.: 72.66%] [G loss: 0.438362]\n",
      "epoch:14 step:13976 [D loss: 0.280901, acc.: 50.00%] [G loss: 0.409091]\n",
      "epoch:14 step:13977 [D loss: 0.222217, acc.: 66.41%] [G loss: 0.465936]\n",
      "epoch:14 step:13978 [D loss: 0.219198, acc.: 66.41%] [G loss: 0.479670]\n",
      "epoch:14 step:13979 [D loss: 0.236204, acc.: 59.38%] [G loss: 0.469327]\n",
      "epoch:14 step:13980 [D loss: 0.231317, acc.: 63.28%] [G loss: 0.412213]\n",
      "epoch:14 step:13981 [D loss: 0.238849, acc.: 59.38%] [G loss: 0.404892]\n",
      "epoch:14 step:13982 [D loss: 0.222365, acc.: 63.28%] [G loss: 0.438916]\n",
      "epoch:14 step:13983 [D loss: 0.243654, acc.: 56.25%] [G loss: 0.429895]\n",
      "epoch:14 step:13984 [D loss: 0.225860, acc.: 64.06%] [G loss: 0.428750]\n",
      "epoch:14 step:13985 [D loss: 0.243407, acc.: 53.12%] [G loss: 0.412586]\n",
      "epoch:14 step:13986 [D loss: 0.241348, acc.: 55.47%] [G loss: 0.440033]\n",
      "epoch:14 step:13987 [D loss: 0.250661, acc.: 52.34%] [G loss: 0.437482]\n",
      "epoch:14 step:13988 [D loss: 0.207374, acc.: 65.62%] [G loss: 0.452725]\n",
      "epoch:14 step:13989 [D loss: 0.216800, acc.: 62.50%] [G loss: 0.469988]\n",
      "epoch:14 step:13990 [D loss: 0.230510, acc.: 60.16%] [G loss: 0.420430]\n",
      "epoch:14 step:13991 [D loss: 0.209280, acc.: 70.31%] [G loss: 0.458078]\n",
      "epoch:14 step:13992 [D loss: 0.225092, acc.: 60.94%] [G loss: 0.413972]\n",
      "epoch:14 step:13993 [D loss: 0.184393, acc.: 68.75%] [G loss: 0.459340]\n",
      "epoch:14 step:13994 [D loss: 0.236403, acc.: 60.94%] [G loss: 0.440509]\n",
      "epoch:14 step:13995 [D loss: 0.233736, acc.: 60.16%] [G loss: 0.427500]\n",
      "epoch:14 step:13996 [D loss: 0.238559, acc.: 59.38%] [G loss: 0.442607]\n",
      "epoch:14 step:13997 [D loss: 0.223011, acc.: 65.62%] [G loss: 0.397426]\n",
      "epoch:14 step:13998 [D loss: 0.247356, acc.: 56.25%] [G loss: 0.447140]\n",
      "epoch:14 step:13999 [D loss: 0.240387, acc.: 57.03%] [G loss: 0.407074]\n",
      "epoch:14 step:14000 [D loss: 0.225272, acc.: 65.62%] [G loss: 0.447905]\n",
      "epoch:14 step:14001 [D loss: 0.233095, acc.: 64.06%] [G loss: 0.428486]\n",
      "epoch:14 step:14002 [D loss: 0.214679, acc.: 65.62%] [G loss: 0.474884]\n",
      "epoch:14 step:14003 [D loss: 0.222277, acc.: 60.16%] [G loss: 0.513399]\n",
      "epoch:14 step:14004 [D loss: 0.209481, acc.: 65.62%] [G loss: 0.508334]\n",
      "epoch:14 step:14005 [D loss: 0.235767, acc.: 57.03%] [G loss: 0.458307]\n",
      "epoch:14 step:14006 [D loss: 0.225168, acc.: 59.38%] [G loss: 0.501018]\n",
      "epoch:14 step:14007 [D loss: 0.205146, acc.: 64.06%] [G loss: 0.453203]\n",
      "epoch:14 step:14008 [D loss: 0.225311, acc.: 57.81%] [G loss: 0.433227]\n",
      "epoch:14 step:14009 [D loss: 0.241376, acc.: 57.81%] [G loss: 0.440773]\n",
      "epoch:14 step:14010 [D loss: 0.260387, acc.: 52.34%] [G loss: 0.444550]\n",
      "epoch:14 step:14011 [D loss: 0.197394, acc.: 71.88%] [G loss: 0.426678]\n",
      "epoch:14 step:14012 [D loss: 0.191895, acc.: 71.09%] [G loss: 0.482672]\n",
      "epoch:14 step:14013 [D loss: 0.213946, acc.: 65.62%] [G loss: 0.476765]\n",
      "epoch:14 step:14014 [D loss: 0.241728, acc.: 61.72%] [G loss: 0.445421]\n",
      "epoch:14 step:14015 [D loss: 0.204647, acc.: 71.88%] [G loss: 0.481328]\n",
      "epoch:14 step:14016 [D loss: 0.196340, acc.: 68.75%] [G loss: 0.476538]\n",
      "epoch:14 step:14017 [D loss: 0.184100, acc.: 72.66%] [G loss: 0.503209]\n",
      "epoch:14 step:14018 [D loss: 0.205165, acc.: 69.53%] [G loss: 0.504422]\n",
      "epoch:14 step:14019 [D loss: 0.222909, acc.: 65.62%] [G loss: 0.447708]\n",
      "epoch:14 step:14020 [D loss: 0.230650, acc.: 57.81%] [G loss: 0.416290]\n",
      "epoch:14 step:14021 [D loss: 0.205342, acc.: 70.31%] [G loss: 0.464810]\n",
      "epoch:14 step:14022 [D loss: 0.237112, acc.: 63.28%] [G loss: 0.435657]\n",
      "epoch:14 step:14023 [D loss: 0.219074, acc.: 69.53%] [G loss: 0.479939]\n",
      "epoch:14 step:14024 [D loss: 0.238642, acc.: 61.72%] [G loss: 0.481318]\n",
      "epoch:14 step:14025 [D loss: 0.233277, acc.: 61.72%] [G loss: 0.449667]\n",
      "epoch:14 step:14026 [D loss: 0.201166, acc.: 68.75%] [G loss: 0.453088]\n",
      "epoch:14 step:14027 [D loss: 0.208532, acc.: 69.53%] [G loss: 0.460363]\n",
      "epoch:14 step:14028 [D loss: 0.200912, acc.: 68.75%] [G loss: 0.468301]\n",
      "epoch:14 step:14029 [D loss: 0.200182, acc.: 71.09%] [G loss: 0.463528]\n",
      "epoch:14 step:14030 [D loss: 0.244071, acc.: 61.72%] [G loss: 0.419786]\n",
      "epoch:14 step:14031 [D loss: 0.223286, acc.: 62.50%] [G loss: 0.494664]\n",
      "epoch:14 step:14032 [D loss: 0.227468, acc.: 60.16%] [G loss: 0.443206]\n",
      "epoch:14 step:14033 [D loss: 0.262447, acc.: 56.25%] [G loss: 0.427833]\n",
      "epoch:14 step:14034 [D loss: 0.248593, acc.: 55.47%] [G loss: 0.458266]\n",
      "epoch:14 step:14035 [D loss: 0.239787, acc.: 57.03%] [G loss: 0.458396]\n",
      "epoch:14 step:14036 [D loss: 0.229389, acc.: 65.62%] [G loss: 0.432883]\n",
      "epoch:14 step:14037 [D loss: 0.216668, acc.: 64.84%] [G loss: 0.514728]\n",
      "epoch:14 step:14038 [D loss: 0.261746, acc.: 50.00%] [G loss: 0.490879]\n",
      "epoch:14 step:14039 [D loss: 0.214447, acc.: 63.28%] [G loss: 0.469626]\n",
      "epoch:14 step:14040 [D loss: 0.236558, acc.: 64.06%] [G loss: 0.460318]\n",
      "epoch:14 step:14041 [D loss: 0.198502, acc.: 69.53%] [G loss: 0.456939]\n",
      "epoch:14 step:14042 [D loss: 0.197613, acc.: 68.75%] [G loss: 0.489621]\n",
      "epoch:14 step:14043 [D loss: 0.188747, acc.: 71.88%] [G loss: 0.509783]\n",
      "epoch:14 step:14044 [D loss: 0.190620, acc.: 71.09%] [G loss: 0.538993]\n",
      "epoch:14 step:14045 [D loss: 0.194532, acc.: 69.53%] [G loss: 0.557950]\n",
      "epoch:14 step:14046 [D loss: 0.334223, acc.: 50.78%] [G loss: 0.527950]\n",
      "epoch:14 step:14047 [D loss: 0.211623, acc.: 67.19%] [G loss: 0.576917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14048 [D loss: 0.202120, acc.: 66.41%] [G loss: 0.486643]\n",
      "epoch:14 step:14049 [D loss: 0.271474, acc.: 55.47%] [G loss: 0.459043]\n",
      "epoch:14 step:14050 [D loss: 0.264276, acc.: 56.25%] [G loss: 0.450057]\n",
      "epoch:14 step:14051 [D loss: 0.223613, acc.: 66.41%] [G loss: 0.426366]\n",
      "epoch:14 step:14052 [D loss: 0.194835, acc.: 69.53%] [G loss: 0.463959]\n",
      "epoch:14 step:14053 [D loss: 0.212431, acc.: 63.28%] [G loss: 0.520649]\n",
      "epoch:14 step:14054 [D loss: 0.185258, acc.: 69.53%] [G loss: 0.542150]\n",
      "epoch:14 step:14055 [D loss: 0.157314, acc.: 79.69%] [G loss: 0.530362]\n",
      "epoch:15 step:14056 [D loss: 0.236787, acc.: 67.19%] [G loss: 0.495399]\n",
      "epoch:15 step:14057 [D loss: 0.248742, acc.: 55.47%] [G loss: 0.399246]\n",
      "epoch:15 step:14058 [D loss: 0.251370, acc.: 56.25%] [G loss: 0.416896]\n",
      "epoch:15 step:14059 [D loss: 0.226648, acc.: 58.59%] [G loss: 0.461250]\n",
      "epoch:15 step:14060 [D loss: 0.222009, acc.: 62.50%] [G loss: 0.453340]\n",
      "epoch:15 step:14061 [D loss: 0.216133, acc.: 65.62%] [G loss: 0.459157]\n",
      "epoch:15 step:14062 [D loss: 0.212274, acc.: 63.28%] [G loss: 0.478946]\n",
      "epoch:15 step:14063 [D loss: 0.234041, acc.: 60.16%] [G loss: 0.447317]\n",
      "epoch:15 step:14064 [D loss: 0.209776, acc.: 64.06%] [G loss: 0.478066]\n",
      "epoch:15 step:14065 [D loss: 0.212765, acc.: 64.06%] [G loss: 0.470624]\n",
      "epoch:15 step:14066 [D loss: 0.202737, acc.: 70.31%] [G loss: 0.493660]\n",
      "epoch:15 step:14067 [D loss: 0.216519, acc.: 64.06%] [G loss: 0.486302]\n",
      "epoch:15 step:14068 [D loss: 0.221195, acc.: 63.28%] [G loss: 0.478127]\n",
      "epoch:15 step:14069 [D loss: 0.216799, acc.: 67.19%] [G loss: 0.502034]\n",
      "epoch:15 step:14070 [D loss: 0.191860, acc.: 71.09%] [G loss: 0.475894]\n",
      "epoch:15 step:14071 [D loss: 0.184285, acc.: 71.88%] [G loss: 0.469155]\n",
      "epoch:15 step:14072 [D loss: 0.242389, acc.: 56.25%] [G loss: 0.442162]\n",
      "epoch:15 step:14073 [D loss: 0.250939, acc.: 54.69%] [G loss: 0.443259]\n",
      "epoch:15 step:14074 [D loss: 0.220570, acc.: 64.84%] [G loss: 0.444884]\n",
      "epoch:15 step:14075 [D loss: 0.275768, acc.: 50.00%] [G loss: 0.419814]\n",
      "epoch:15 step:14076 [D loss: 0.226285, acc.: 62.50%] [G loss: 0.459918]\n",
      "epoch:15 step:14077 [D loss: 0.182577, acc.: 68.75%] [G loss: 0.505709]\n",
      "epoch:15 step:14078 [D loss: 0.266603, acc.: 51.56%] [G loss: 0.409871]\n",
      "epoch:15 step:14079 [D loss: 0.225253, acc.: 61.72%] [G loss: 0.416532]\n",
      "epoch:15 step:14080 [D loss: 0.203939, acc.: 67.97%] [G loss: 0.435632]\n",
      "epoch:15 step:14081 [D loss: 0.249986, acc.: 53.12%] [G loss: 0.422453]\n",
      "epoch:15 step:14082 [D loss: 0.231143, acc.: 56.25%] [G loss: 0.411203]\n",
      "epoch:15 step:14083 [D loss: 0.228646, acc.: 60.16%] [G loss: 0.451791]\n",
      "epoch:15 step:14084 [D loss: 0.217042, acc.: 65.62%] [G loss: 0.436605]\n",
      "epoch:15 step:14085 [D loss: 0.222365, acc.: 58.59%] [G loss: 0.452423]\n",
      "epoch:15 step:14086 [D loss: 0.246347, acc.: 53.12%] [G loss: 0.427581]\n",
      "epoch:15 step:14087 [D loss: 0.233999, acc.: 59.38%] [G loss: 0.437492]\n",
      "epoch:15 step:14088 [D loss: 0.209225, acc.: 68.75%] [G loss: 0.450514]\n",
      "epoch:15 step:14089 [D loss: 0.242340, acc.: 55.47%] [G loss: 0.430664]\n",
      "epoch:15 step:14090 [D loss: 0.225454, acc.: 65.62%] [G loss: 0.403585]\n",
      "epoch:15 step:14091 [D loss: 0.194850, acc.: 69.53%] [G loss: 0.487234]\n",
      "epoch:15 step:14092 [D loss: 0.207619, acc.: 64.84%] [G loss: 0.426950]\n",
      "epoch:15 step:14093 [D loss: 0.249488, acc.: 57.03%] [G loss: 0.404995]\n",
      "epoch:15 step:14094 [D loss: 0.239499, acc.: 57.03%] [G loss: 0.422761]\n",
      "epoch:15 step:14095 [D loss: 0.186785, acc.: 70.31%] [G loss: 0.461852]\n",
      "epoch:15 step:14096 [D loss: 0.262193, acc.: 53.91%] [G loss: 0.447167]\n",
      "epoch:15 step:14097 [D loss: 0.217121, acc.: 68.75%] [G loss: 0.432061]\n",
      "epoch:15 step:14098 [D loss: 0.222207, acc.: 60.94%] [G loss: 0.442667]\n",
      "epoch:15 step:14099 [D loss: 0.232762, acc.: 60.94%] [G loss: 0.402840]\n",
      "epoch:15 step:14100 [D loss: 0.225244, acc.: 64.06%] [G loss: 0.451114]\n",
      "epoch:15 step:14101 [D loss: 0.227194, acc.: 63.28%] [G loss: 0.440341]\n",
      "epoch:15 step:14102 [D loss: 0.218248, acc.: 65.62%] [G loss: 0.468571]\n",
      "epoch:15 step:14103 [D loss: 0.208294, acc.: 67.19%] [G loss: 0.438240]\n",
      "epoch:15 step:14104 [D loss: 0.215155, acc.: 69.53%] [G loss: 0.519108]\n",
      "epoch:15 step:14105 [D loss: 0.222716, acc.: 67.97%] [G loss: 0.446574]\n",
      "epoch:15 step:14106 [D loss: 0.239337, acc.: 63.28%] [G loss: 0.418432]\n",
      "epoch:15 step:14107 [D loss: 0.210778, acc.: 64.84%] [G loss: 0.430123]\n",
      "epoch:15 step:14108 [D loss: 0.192689, acc.: 71.88%] [G loss: 0.445635]\n",
      "epoch:15 step:14109 [D loss: 0.218207, acc.: 69.53%] [G loss: 0.446571]\n",
      "epoch:15 step:14110 [D loss: 0.227195, acc.: 70.31%] [G loss: 0.516105]\n",
      "epoch:15 step:14111 [D loss: 0.212546, acc.: 71.09%] [G loss: 0.471282]\n",
      "epoch:15 step:14112 [D loss: 0.254731, acc.: 53.91%] [G loss: 0.415664]\n",
      "epoch:15 step:14113 [D loss: 0.213811, acc.: 68.75%] [G loss: 0.474972]\n",
      "epoch:15 step:14114 [D loss: 0.244202, acc.: 62.50%] [G loss: 0.448048]\n",
      "epoch:15 step:14115 [D loss: 0.242337, acc.: 59.38%] [G loss: 0.409770]\n",
      "epoch:15 step:14116 [D loss: 0.250644, acc.: 55.47%] [G loss: 0.426196]\n",
      "epoch:15 step:14117 [D loss: 0.221165, acc.: 61.72%] [G loss: 0.454759]\n",
      "epoch:15 step:14118 [D loss: 0.218897, acc.: 62.50%] [G loss: 0.452466]\n",
      "epoch:15 step:14119 [D loss: 0.217130, acc.: 65.62%] [G loss: 0.435187]\n",
      "epoch:15 step:14120 [D loss: 0.208019, acc.: 64.06%] [G loss: 0.433734]\n",
      "epoch:15 step:14121 [D loss: 0.210724, acc.: 64.84%] [G loss: 0.422364]\n",
      "epoch:15 step:14122 [D loss: 0.204516, acc.: 67.19%] [G loss: 0.408235]\n",
      "epoch:15 step:14123 [D loss: 0.222640, acc.: 64.06%] [G loss: 0.455865]\n",
      "epoch:15 step:14124 [D loss: 0.212720, acc.: 67.19%] [G loss: 0.499932]\n",
      "epoch:15 step:14125 [D loss: 0.198880, acc.: 72.66%] [G loss: 0.481701]\n",
      "epoch:15 step:14126 [D loss: 0.229106, acc.: 64.84%] [G loss: 0.453654]\n",
      "epoch:15 step:14127 [D loss: 0.226145, acc.: 63.28%] [G loss: 0.384521]\n",
      "epoch:15 step:14128 [D loss: 0.250866, acc.: 60.94%] [G loss: 0.396587]\n",
      "epoch:15 step:14129 [D loss: 0.183519, acc.: 75.78%] [G loss: 0.480046]\n",
      "epoch:15 step:14130 [D loss: 0.206083, acc.: 63.28%] [G loss: 0.475810]\n",
      "epoch:15 step:14131 [D loss: 0.195489, acc.: 68.75%] [G loss: 0.563586]\n",
      "epoch:15 step:14132 [D loss: 0.169075, acc.: 75.00%] [G loss: 0.534905]\n",
      "epoch:15 step:14133 [D loss: 0.312378, acc.: 46.09%] [G loss: 0.406451]\n",
      "epoch:15 step:14134 [D loss: 0.253735, acc.: 55.47%] [G loss: 0.402292]\n",
      "epoch:15 step:14135 [D loss: 0.215595, acc.: 62.50%] [G loss: 0.416598]\n",
      "epoch:15 step:14136 [D loss: 0.216816, acc.: 62.50%] [G loss: 0.454474]\n",
      "epoch:15 step:14137 [D loss: 0.238828, acc.: 61.72%] [G loss: 0.428331]\n",
      "epoch:15 step:14138 [D loss: 0.205526, acc.: 70.31%] [G loss: 0.482674]\n",
      "epoch:15 step:14139 [D loss: 0.212998, acc.: 67.97%] [G loss: 0.458719]\n",
      "epoch:15 step:14140 [D loss: 0.234328, acc.: 63.28%] [G loss: 0.432742]\n",
      "epoch:15 step:14141 [D loss: 0.229884, acc.: 61.72%] [G loss: 0.438270]\n",
      "epoch:15 step:14142 [D loss: 0.209968, acc.: 64.84%] [G loss: 0.496396]\n",
      "epoch:15 step:14143 [D loss: 0.220241, acc.: 68.75%] [G loss: 0.496940]\n",
      "epoch:15 step:14144 [D loss: 0.227815, acc.: 64.06%] [G loss: 0.443886]\n",
      "epoch:15 step:14145 [D loss: 0.207499, acc.: 65.62%] [G loss: 0.434318]\n",
      "epoch:15 step:14146 [D loss: 0.230883, acc.: 60.94%] [G loss: 0.418618]\n",
      "epoch:15 step:14147 [D loss: 0.222890, acc.: 64.84%] [G loss: 0.505437]\n",
      "epoch:15 step:14148 [D loss: 0.198265, acc.: 67.97%] [G loss: 0.480728]\n",
      "epoch:15 step:14149 [D loss: 0.240906, acc.: 60.94%] [G loss: 0.463378]\n",
      "epoch:15 step:14150 [D loss: 0.229081, acc.: 62.50%] [G loss: 0.438741]\n",
      "epoch:15 step:14151 [D loss: 0.221127, acc.: 61.72%] [G loss: 0.450649]\n",
      "epoch:15 step:14152 [D loss: 0.226953, acc.: 59.38%] [G loss: 0.475637]\n",
      "epoch:15 step:14153 [D loss: 0.226372, acc.: 59.38%] [G loss: 0.471945]\n",
      "epoch:15 step:14154 [D loss: 0.192776, acc.: 71.88%] [G loss: 0.451570]\n",
      "epoch:15 step:14155 [D loss: 0.192603, acc.: 70.31%] [G loss: 0.483500]\n",
      "epoch:15 step:14156 [D loss: 0.228504, acc.: 57.81%] [G loss: 0.453321]\n",
      "epoch:15 step:14157 [D loss: 0.221730, acc.: 62.50%] [G loss: 0.483953]\n",
      "epoch:15 step:14158 [D loss: 0.239081, acc.: 63.28%] [G loss: 0.426794]\n",
      "epoch:15 step:14159 [D loss: 0.262398, acc.: 58.59%] [G loss: 0.429250]\n",
      "epoch:15 step:14160 [D loss: 0.220586, acc.: 60.94%] [G loss: 0.412819]\n",
      "epoch:15 step:14161 [D loss: 0.199279, acc.: 72.66%] [G loss: 0.414825]\n",
      "epoch:15 step:14162 [D loss: 0.228107, acc.: 64.06%] [G loss: 0.464581]\n",
      "epoch:15 step:14163 [D loss: 0.239428, acc.: 57.03%] [G loss: 0.450065]\n",
      "epoch:15 step:14164 [D loss: 0.251223, acc.: 59.38%] [G loss: 0.422146]\n",
      "epoch:15 step:14165 [D loss: 0.269138, acc.: 50.00%] [G loss: 0.397082]\n",
      "epoch:15 step:14166 [D loss: 0.211844, acc.: 62.50%] [G loss: 0.412013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14167 [D loss: 0.198485, acc.: 75.78%] [G loss: 0.449454]\n",
      "epoch:15 step:14168 [D loss: 0.218565, acc.: 64.84%] [G loss: 0.450464]\n",
      "epoch:15 step:14169 [D loss: 0.217297, acc.: 64.84%] [G loss: 0.444124]\n",
      "epoch:15 step:14170 [D loss: 0.186834, acc.: 75.78%] [G loss: 0.487068]\n",
      "epoch:15 step:14171 [D loss: 0.222669, acc.: 62.50%] [G loss: 0.478301]\n",
      "epoch:15 step:14172 [D loss: 0.216422, acc.: 64.84%] [G loss: 0.477419]\n",
      "epoch:15 step:14173 [D loss: 0.214387, acc.: 66.41%] [G loss: 0.460010]\n",
      "epoch:15 step:14174 [D loss: 0.200025, acc.: 65.62%] [G loss: 0.507249]\n",
      "epoch:15 step:14175 [D loss: 0.243074, acc.: 59.38%] [G loss: 0.554000]\n",
      "epoch:15 step:14176 [D loss: 0.224959, acc.: 67.19%] [G loss: 0.445057]\n",
      "epoch:15 step:14177 [D loss: 0.204029, acc.: 67.19%] [G loss: 0.476779]\n",
      "epoch:15 step:14178 [D loss: 0.205478, acc.: 64.84%] [G loss: 0.493159]\n",
      "epoch:15 step:14179 [D loss: 0.257576, acc.: 52.34%] [G loss: 0.454688]\n",
      "epoch:15 step:14180 [D loss: 0.221770, acc.: 60.16%] [G loss: 0.419088]\n",
      "epoch:15 step:14181 [D loss: 0.198311, acc.: 67.97%] [G loss: 0.428714]\n",
      "epoch:15 step:14182 [D loss: 0.203762, acc.: 68.75%] [G loss: 0.436926]\n",
      "epoch:15 step:14183 [D loss: 0.242160, acc.: 57.81%] [G loss: 0.418116]\n",
      "epoch:15 step:14184 [D loss: 0.223488, acc.: 63.28%] [G loss: 0.415215]\n",
      "epoch:15 step:14185 [D loss: 0.201918, acc.: 71.09%] [G loss: 0.456525]\n",
      "epoch:15 step:14186 [D loss: 0.222910, acc.: 61.72%] [G loss: 0.469973]\n",
      "epoch:15 step:14187 [D loss: 0.225863, acc.: 61.72%] [G loss: 0.435831]\n",
      "epoch:15 step:14188 [D loss: 0.235979, acc.: 57.03%] [G loss: 0.463154]\n",
      "epoch:15 step:14189 [D loss: 0.215172, acc.: 67.19%] [G loss: 0.489173]\n",
      "epoch:15 step:14190 [D loss: 0.211137, acc.: 68.75%] [G loss: 0.462477]\n",
      "epoch:15 step:14191 [D loss: 0.240324, acc.: 57.03%] [G loss: 0.435996]\n",
      "epoch:15 step:14192 [D loss: 0.245564, acc.: 63.28%] [G loss: 0.420793]\n",
      "epoch:15 step:14193 [D loss: 0.269803, acc.: 51.56%] [G loss: 0.401477]\n",
      "epoch:15 step:14194 [D loss: 0.217064, acc.: 64.84%] [G loss: 0.439165]\n",
      "epoch:15 step:14195 [D loss: 0.214298, acc.: 70.31%] [G loss: 0.466987]\n",
      "epoch:15 step:14196 [D loss: 0.222796, acc.: 61.72%] [G loss: 0.421567]\n",
      "epoch:15 step:14197 [D loss: 0.238014, acc.: 59.38%] [G loss: 0.385866]\n",
      "epoch:15 step:14198 [D loss: 0.245582, acc.: 63.28%] [G loss: 0.430061]\n",
      "epoch:15 step:14199 [D loss: 0.230214, acc.: 60.16%] [G loss: 0.403446]\n",
      "epoch:15 step:14200 [D loss: 0.215524, acc.: 59.38%] [G loss: 0.454302]\n",
      "epoch:15 step:14201 [D loss: 0.225059, acc.: 60.16%] [G loss: 0.458827]\n",
      "epoch:15 step:14202 [D loss: 0.245909, acc.: 62.50%] [G loss: 0.452617]\n",
      "epoch:15 step:14203 [D loss: 0.235736, acc.: 58.59%] [G loss: 0.444454]\n",
      "epoch:15 step:14204 [D loss: 0.216787, acc.: 66.41%] [G loss: 0.441619]\n",
      "epoch:15 step:14205 [D loss: 0.266782, acc.: 53.91%] [G loss: 0.387286]\n",
      "epoch:15 step:14206 [D loss: 0.221873, acc.: 67.19%] [G loss: 0.395127]\n",
      "epoch:15 step:14207 [D loss: 0.244311, acc.: 62.50%] [G loss: 0.438682]\n",
      "epoch:15 step:14208 [D loss: 0.226580, acc.: 63.28%] [G loss: 0.480818]\n",
      "epoch:15 step:14209 [D loss: 0.236538, acc.: 56.25%] [G loss: 0.435387]\n",
      "epoch:15 step:14210 [D loss: 0.184448, acc.: 75.00%] [G loss: 0.498160]\n",
      "epoch:15 step:14211 [D loss: 0.197003, acc.: 68.75%] [G loss: 0.487996]\n",
      "epoch:15 step:14212 [D loss: 0.219455, acc.: 64.84%] [G loss: 0.461316]\n",
      "epoch:15 step:14213 [D loss: 0.232776, acc.: 59.38%] [G loss: 0.447688]\n",
      "epoch:15 step:14214 [D loss: 0.225815, acc.: 66.41%] [G loss: 0.432294]\n",
      "epoch:15 step:14215 [D loss: 0.277828, acc.: 52.34%] [G loss: 0.417292]\n",
      "epoch:15 step:14216 [D loss: 0.222630, acc.: 57.81%] [G loss: 0.456944]\n",
      "epoch:15 step:14217 [D loss: 0.227552, acc.: 67.19%] [G loss: 0.457598]\n",
      "epoch:15 step:14218 [D loss: 0.228182, acc.: 61.72%] [G loss: 0.425431]\n",
      "epoch:15 step:14219 [D loss: 0.227662, acc.: 61.72%] [G loss: 0.434823]\n",
      "epoch:15 step:14220 [D loss: 0.248654, acc.: 54.69%] [G loss: 0.398435]\n",
      "epoch:15 step:14221 [D loss: 0.217644, acc.: 60.94%] [G loss: 0.421564]\n",
      "epoch:15 step:14222 [D loss: 0.217885, acc.: 67.19%] [G loss: 0.432722]\n",
      "epoch:15 step:14223 [D loss: 0.229091, acc.: 64.06%] [G loss: 0.429172]\n",
      "epoch:15 step:14224 [D loss: 0.276020, acc.: 51.56%] [G loss: 0.401694]\n",
      "epoch:15 step:14225 [D loss: 0.237771, acc.: 57.03%] [G loss: 0.367519]\n",
      "epoch:15 step:14226 [D loss: 0.238609, acc.: 57.81%] [G loss: 0.416244]\n",
      "epoch:15 step:14227 [D loss: 0.224513, acc.: 64.84%] [G loss: 0.418684]\n",
      "epoch:15 step:14228 [D loss: 0.196823, acc.: 70.31%] [G loss: 0.481112]\n",
      "epoch:15 step:14229 [D loss: 0.251203, acc.: 54.69%] [G loss: 0.406094]\n",
      "epoch:15 step:14230 [D loss: 0.245530, acc.: 56.25%] [G loss: 0.423016]\n",
      "epoch:15 step:14231 [D loss: 0.242461, acc.: 58.59%] [G loss: 0.377383]\n",
      "epoch:15 step:14232 [D loss: 0.246639, acc.: 57.81%] [G loss: 0.416426]\n",
      "epoch:15 step:14233 [D loss: 0.233768, acc.: 58.59%] [G loss: 0.446722]\n",
      "epoch:15 step:14234 [D loss: 0.229716, acc.: 58.59%] [G loss: 0.454337]\n",
      "epoch:15 step:14235 [D loss: 0.238860, acc.: 56.25%] [G loss: 0.422683]\n",
      "epoch:15 step:14236 [D loss: 0.242390, acc.: 53.12%] [G loss: 0.453160]\n",
      "epoch:15 step:14237 [D loss: 0.247024, acc.: 57.03%] [G loss: 0.433399]\n",
      "epoch:15 step:14238 [D loss: 0.250639, acc.: 57.81%] [G loss: 0.422241]\n",
      "epoch:15 step:14239 [D loss: 0.237664, acc.: 63.28%] [G loss: 0.455135]\n",
      "epoch:15 step:14240 [D loss: 0.209826, acc.: 65.62%] [G loss: 0.427988]\n",
      "epoch:15 step:14241 [D loss: 0.233058, acc.: 57.03%] [G loss: 0.408156]\n",
      "epoch:15 step:14242 [D loss: 0.247264, acc.: 51.56%] [G loss: 0.401756]\n",
      "epoch:15 step:14243 [D loss: 0.237366, acc.: 58.59%] [G loss: 0.422560]\n",
      "epoch:15 step:14244 [D loss: 0.230785, acc.: 64.06%] [G loss: 0.426667]\n",
      "epoch:15 step:14245 [D loss: 0.206008, acc.: 70.31%] [G loss: 0.418717]\n",
      "epoch:15 step:14246 [D loss: 0.214201, acc.: 67.97%] [G loss: 0.389623]\n",
      "epoch:15 step:14247 [D loss: 0.227978, acc.: 66.41%] [G loss: 0.384132]\n",
      "epoch:15 step:14248 [D loss: 0.211770, acc.: 64.84%] [G loss: 0.441533]\n",
      "epoch:15 step:14249 [D loss: 0.201919, acc.: 69.53%] [G loss: 0.431346]\n",
      "epoch:15 step:14250 [D loss: 0.265507, acc.: 54.69%] [G loss: 0.449510]\n",
      "epoch:15 step:14251 [D loss: 0.227731, acc.: 61.72%] [G loss: 0.437338]\n",
      "epoch:15 step:14252 [D loss: 0.217777, acc.: 68.75%] [G loss: 0.448915]\n",
      "epoch:15 step:14253 [D loss: 0.205937, acc.: 65.62%] [G loss: 0.469681]\n",
      "epoch:15 step:14254 [D loss: 0.219978, acc.: 64.84%] [G loss: 0.440590]\n",
      "epoch:15 step:14255 [D loss: 0.270456, acc.: 51.56%] [G loss: 0.407833]\n",
      "epoch:15 step:14256 [D loss: 0.242516, acc.: 60.94%] [G loss: 0.431547]\n",
      "epoch:15 step:14257 [D loss: 0.239698, acc.: 60.94%] [G loss: 0.459593]\n",
      "epoch:15 step:14258 [D loss: 0.248281, acc.: 57.03%] [G loss: 0.482799]\n",
      "epoch:15 step:14259 [D loss: 0.254078, acc.: 62.50%] [G loss: 0.431395]\n",
      "epoch:15 step:14260 [D loss: 0.198259, acc.: 71.09%] [G loss: 0.502037]\n",
      "epoch:15 step:14261 [D loss: 0.241981, acc.: 57.81%] [G loss: 0.426513]\n",
      "epoch:15 step:14262 [D loss: 0.198348, acc.: 69.53%] [G loss: 0.464929]\n",
      "epoch:15 step:14263 [D loss: 0.166571, acc.: 73.44%] [G loss: 0.497492]\n",
      "epoch:15 step:14264 [D loss: 0.224701, acc.: 63.28%] [G loss: 0.486070]\n",
      "epoch:15 step:14265 [D loss: 0.257555, acc.: 54.69%] [G loss: 0.405394]\n",
      "epoch:15 step:14266 [D loss: 0.230223, acc.: 60.94%] [G loss: 0.420353]\n",
      "epoch:15 step:14267 [D loss: 0.237752, acc.: 59.38%] [G loss: 0.412805]\n",
      "epoch:15 step:14268 [D loss: 0.211040, acc.: 64.84%] [G loss: 0.408034]\n",
      "epoch:15 step:14269 [D loss: 0.259826, acc.: 52.34%] [G loss: 0.421878]\n",
      "epoch:15 step:14270 [D loss: 0.259554, acc.: 49.22%] [G loss: 0.418901]\n",
      "epoch:15 step:14271 [D loss: 0.213053, acc.: 61.72%] [G loss: 0.410392]\n",
      "epoch:15 step:14272 [D loss: 0.207299, acc.: 67.19%] [G loss: 0.451777]\n",
      "epoch:15 step:14273 [D loss: 0.197779, acc.: 74.22%] [G loss: 0.453381]\n",
      "epoch:15 step:14274 [D loss: 0.187209, acc.: 73.44%] [G loss: 0.489547]\n",
      "epoch:15 step:14275 [D loss: 0.283499, acc.: 53.91%] [G loss: 0.410424]\n",
      "epoch:15 step:14276 [D loss: 0.224943, acc.: 61.72%] [G loss: 0.427202]\n",
      "epoch:15 step:14277 [D loss: 0.209900, acc.: 66.41%] [G loss: 0.506572]\n",
      "epoch:15 step:14278 [D loss: 0.220341, acc.: 62.50%] [G loss: 0.460383]\n",
      "epoch:15 step:14279 [D loss: 0.214608, acc.: 67.19%] [G loss: 0.458147]\n",
      "epoch:15 step:14280 [D loss: 0.236699, acc.: 60.16%] [G loss: 0.419107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14281 [D loss: 0.222027, acc.: 64.84%] [G loss: 0.428334]\n",
      "epoch:15 step:14282 [D loss: 0.252068, acc.: 57.81%] [G loss: 0.414027]\n",
      "epoch:15 step:14283 [D loss: 0.234861, acc.: 60.94%] [G loss: 0.450758]\n",
      "epoch:15 step:14284 [D loss: 0.212732, acc.: 62.50%] [G loss: 0.429395]\n",
      "epoch:15 step:14285 [D loss: 0.189358, acc.: 71.09%] [G loss: 0.457385]\n",
      "epoch:15 step:14286 [D loss: 0.192589, acc.: 69.53%] [G loss: 0.486357]\n",
      "epoch:15 step:14287 [D loss: 0.162727, acc.: 78.12%] [G loss: 0.505507]\n",
      "epoch:15 step:14288 [D loss: 0.253186, acc.: 57.81%] [G loss: 0.449127]\n",
      "epoch:15 step:14289 [D loss: 0.252427, acc.: 56.25%] [G loss: 0.404892]\n",
      "epoch:15 step:14290 [D loss: 0.233523, acc.: 57.81%] [G loss: 0.432186]\n",
      "epoch:15 step:14291 [D loss: 0.220915, acc.: 61.72%] [G loss: 0.400374]\n",
      "epoch:15 step:14292 [D loss: 0.235897, acc.: 60.16%] [G loss: 0.453606]\n",
      "epoch:15 step:14293 [D loss: 0.219433, acc.: 64.84%] [G loss: 0.469433]\n",
      "epoch:15 step:14294 [D loss: 0.198939, acc.: 68.75%] [G loss: 0.484798]\n",
      "epoch:15 step:14295 [D loss: 0.237543, acc.: 59.38%] [G loss: 0.451749]\n",
      "epoch:15 step:14296 [D loss: 0.206296, acc.: 71.88%] [G loss: 0.434007]\n",
      "epoch:15 step:14297 [D loss: 0.221296, acc.: 64.06%] [G loss: 0.428660]\n",
      "epoch:15 step:14298 [D loss: 0.235265, acc.: 57.03%] [G loss: 0.425889]\n",
      "epoch:15 step:14299 [D loss: 0.222618, acc.: 64.84%] [G loss: 0.440472]\n",
      "epoch:15 step:14300 [D loss: 0.220101, acc.: 63.28%] [G loss: 0.484890]\n",
      "epoch:15 step:14301 [D loss: 0.225934, acc.: 62.50%] [G loss: 0.447780]\n",
      "epoch:15 step:14302 [D loss: 0.211599, acc.: 63.28%] [G loss: 0.448142]\n",
      "epoch:15 step:14303 [D loss: 0.211023, acc.: 64.84%] [G loss: 0.468763]\n",
      "epoch:15 step:14304 [D loss: 0.267819, acc.: 56.25%] [G loss: 0.462717]\n",
      "epoch:15 step:14305 [D loss: 0.252838, acc.: 53.91%] [G loss: 0.414506]\n",
      "epoch:15 step:14306 [D loss: 0.273381, acc.: 55.47%] [G loss: 0.433443]\n",
      "epoch:15 step:14307 [D loss: 0.256586, acc.: 48.44%] [G loss: 0.423696]\n",
      "epoch:15 step:14308 [D loss: 0.215389, acc.: 64.84%] [G loss: 0.466165]\n",
      "epoch:15 step:14309 [D loss: 0.239173, acc.: 57.03%] [G loss: 0.428582]\n",
      "epoch:15 step:14310 [D loss: 0.231019, acc.: 60.16%] [G loss: 0.451919]\n",
      "epoch:15 step:14311 [D loss: 0.218147, acc.: 60.16%] [G loss: 0.422233]\n",
      "epoch:15 step:14312 [D loss: 0.232061, acc.: 63.28%] [G loss: 0.383959]\n",
      "epoch:15 step:14313 [D loss: 0.230408, acc.: 61.72%] [G loss: 0.401941]\n",
      "epoch:15 step:14314 [D loss: 0.202203, acc.: 71.09%] [G loss: 0.444842]\n",
      "epoch:15 step:14315 [D loss: 0.218588, acc.: 59.38%] [G loss: 0.420105]\n",
      "epoch:15 step:14316 [D loss: 0.238688, acc.: 64.06%] [G loss: 0.437292]\n",
      "epoch:15 step:14317 [D loss: 0.216842, acc.: 61.72%] [G loss: 0.423050]\n",
      "epoch:15 step:14318 [D loss: 0.240428, acc.: 56.25%] [G loss: 0.422231]\n",
      "epoch:15 step:14319 [D loss: 0.193391, acc.: 72.66%] [G loss: 0.506633]\n",
      "epoch:15 step:14320 [D loss: 0.239986, acc.: 53.12%] [G loss: 0.417816]\n",
      "epoch:15 step:14321 [D loss: 0.254761, acc.: 52.34%] [G loss: 0.387795]\n",
      "epoch:15 step:14322 [D loss: 0.201482, acc.: 72.66%] [G loss: 0.452776]\n",
      "epoch:15 step:14323 [D loss: 0.240635, acc.: 55.47%] [G loss: 0.412291]\n",
      "epoch:15 step:14324 [D loss: 0.205888, acc.: 68.75%] [G loss: 0.491929]\n",
      "epoch:15 step:14325 [D loss: 0.210489, acc.: 68.75%] [G loss: 0.447052]\n",
      "epoch:15 step:14326 [D loss: 0.196083, acc.: 70.31%] [G loss: 0.438315]\n",
      "epoch:15 step:14327 [D loss: 0.222763, acc.: 58.59%] [G loss: 0.406499]\n",
      "epoch:15 step:14328 [D loss: 0.228002, acc.: 64.06%] [G loss: 0.421738]\n",
      "epoch:15 step:14329 [D loss: 0.193055, acc.: 71.88%] [G loss: 0.449933]\n",
      "epoch:15 step:14330 [D loss: 0.206024, acc.: 64.06%] [G loss: 0.439906]\n",
      "epoch:15 step:14331 [D loss: 0.203478, acc.: 67.97%] [G loss: 0.430236]\n",
      "epoch:15 step:14332 [D loss: 0.253972, acc.: 54.69%] [G loss: 0.424685]\n",
      "epoch:15 step:14333 [D loss: 0.238893, acc.: 57.03%] [G loss: 0.411237]\n",
      "epoch:15 step:14334 [D loss: 0.237736, acc.: 57.03%] [G loss: 0.448974]\n",
      "epoch:15 step:14335 [D loss: 0.208156, acc.: 64.06%] [G loss: 0.451580]\n",
      "epoch:15 step:14336 [D loss: 0.252754, acc.: 53.91%] [G loss: 0.412995]\n",
      "epoch:15 step:14337 [D loss: 0.219389, acc.: 63.28%] [G loss: 0.435880]\n",
      "epoch:15 step:14338 [D loss: 0.218938, acc.: 67.19%] [G loss: 0.415523]\n",
      "epoch:15 step:14339 [D loss: 0.234009, acc.: 57.81%] [G loss: 0.422439]\n",
      "epoch:15 step:14340 [D loss: 0.237155, acc.: 63.28%] [G loss: 0.398819]\n",
      "epoch:15 step:14341 [D loss: 0.216565, acc.: 63.28%] [G loss: 0.432323]\n",
      "epoch:15 step:14342 [D loss: 0.253206, acc.: 52.34%] [G loss: 0.396851]\n",
      "epoch:15 step:14343 [D loss: 0.217717, acc.: 62.50%] [G loss: 0.515452]\n",
      "epoch:15 step:14344 [D loss: 0.229840, acc.: 57.81%] [G loss: 0.461386]\n",
      "epoch:15 step:14345 [D loss: 0.243372, acc.: 57.81%] [G loss: 0.488114]\n",
      "epoch:15 step:14346 [D loss: 0.250687, acc.: 57.81%] [G loss: 0.445377]\n",
      "epoch:15 step:14347 [D loss: 0.213828, acc.: 66.41%] [G loss: 0.440736]\n",
      "epoch:15 step:14348 [D loss: 0.218120, acc.: 63.28%] [G loss: 0.413396]\n",
      "epoch:15 step:14349 [D loss: 0.239463, acc.: 59.38%] [G loss: 0.417584]\n",
      "epoch:15 step:14350 [D loss: 0.225412, acc.: 61.72%] [G loss: 0.410660]\n",
      "epoch:15 step:14351 [D loss: 0.221156, acc.: 67.97%] [G loss: 0.415663]\n",
      "epoch:15 step:14352 [D loss: 0.236785, acc.: 61.72%] [G loss: 0.439689]\n",
      "epoch:15 step:14353 [D loss: 0.197897, acc.: 69.53%] [G loss: 0.456362]\n",
      "epoch:15 step:14354 [D loss: 0.213744, acc.: 67.97%] [G loss: 0.484795]\n",
      "epoch:15 step:14355 [D loss: 0.212036, acc.: 66.41%] [G loss: 0.448798]\n",
      "epoch:15 step:14356 [D loss: 0.257181, acc.: 56.25%] [G loss: 0.409782]\n",
      "epoch:15 step:14357 [D loss: 0.223907, acc.: 63.28%] [G loss: 0.455932]\n",
      "epoch:15 step:14358 [D loss: 0.232849, acc.: 64.06%] [G loss: 0.431692]\n",
      "epoch:15 step:14359 [D loss: 0.211522, acc.: 75.00%] [G loss: 0.406657]\n",
      "epoch:15 step:14360 [D loss: 0.250831, acc.: 53.91%] [G loss: 0.400345]\n",
      "epoch:15 step:14361 [D loss: 0.212935, acc.: 64.84%] [G loss: 0.455039]\n",
      "epoch:15 step:14362 [D loss: 0.200347, acc.: 65.62%] [G loss: 0.475306]\n",
      "epoch:15 step:14363 [D loss: 0.229821, acc.: 64.06%] [G loss: 0.486171]\n",
      "epoch:15 step:14364 [D loss: 0.228577, acc.: 64.06%] [G loss: 0.453646]\n",
      "epoch:15 step:14365 [D loss: 0.224530, acc.: 63.28%] [G loss: 0.426269]\n",
      "epoch:15 step:14366 [D loss: 0.200700, acc.: 71.09%] [G loss: 0.453518]\n",
      "epoch:15 step:14367 [D loss: 0.176134, acc.: 76.56%] [G loss: 0.539203]\n",
      "epoch:15 step:14368 [D loss: 0.192505, acc.: 66.41%] [G loss: 0.532071]\n",
      "epoch:15 step:14369 [D loss: 0.189749, acc.: 71.88%] [G loss: 0.490738]\n",
      "epoch:15 step:14370 [D loss: 0.208167, acc.: 68.75%] [G loss: 0.494221]\n",
      "epoch:15 step:14371 [D loss: 0.278219, acc.: 54.69%] [G loss: 0.488515]\n",
      "epoch:15 step:14372 [D loss: 0.253467, acc.: 57.81%] [G loss: 0.397716]\n",
      "epoch:15 step:14373 [D loss: 0.203997, acc.: 67.97%] [G loss: 0.419804]\n",
      "epoch:15 step:14374 [D loss: 0.212057, acc.: 62.50%] [G loss: 0.481247]\n",
      "epoch:15 step:14375 [D loss: 0.235371, acc.: 55.47%] [G loss: 0.425005]\n",
      "epoch:15 step:14376 [D loss: 0.197173, acc.: 68.75%] [G loss: 0.462546]\n",
      "epoch:15 step:14377 [D loss: 0.222430, acc.: 64.06%] [G loss: 0.450627]\n",
      "epoch:15 step:14378 [D loss: 0.259983, acc.: 47.66%] [G loss: 0.460177]\n",
      "epoch:15 step:14379 [D loss: 0.225524, acc.: 61.72%] [G loss: 0.407550]\n",
      "epoch:15 step:14380 [D loss: 0.238783, acc.: 59.38%] [G loss: 0.398775]\n",
      "epoch:15 step:14381 [D loss: 0.217529, acc.: 65.62%] [G loss: 0.435170]\n",
      "epoch:15 step:14382 [D loss: 0.242379, acc.: 59.38%] [G loss: 0.464785]\n",
      "epoch:15 step:14383 [D loss: 0.225570, acc.: 63.28%] [G loss: 0.459973]\n",
      "epoch:15 step:14384 [D loss: 0.246354, acc.: 54.69%] [G loss: 0.443074]\n",
      "epoch:15 step:14385 [D loss: 0.235348, acc.: 62.50%] [G loss: 0.430479]\n",
      "epoch:15 step:14386 [D loss: 0.201531, acc.: 67.19%] [G loss: 0.468184]\n",
      "epoch:15 step:14387 [D loss: 0.206007, acc.: 68.75%] [G loss: 0.450829]\n",
      "epoch:15 step:14388 [D loss: 0.205530, acc.: 68.75%] [G loss: 0.417162]\n",
      "epoch:15 step:14389 [D loss: 0.213572, acc.: 69.53%] [G loss: 0.431727]\n",
      "epoch:15 step:14390 [D loss: 0.213719, acc.: 64.06%] [G loss: 0.445457]\n",
      "epoch:15 step:14391 [D loss: 0.221908, acc.: 64.06%] [G loss: 0.467827]\n",
      "epoch:15 step:14392 [D loss: 0.225804, acc.: 63.28%] [G loss: 0.443074]\n",
      "epoch:15 step:14393 [D loss: 0.215212, acc.: 66.41%] [G loss: 0.474640]\n",
      "epoch:15 step:14394 [D loss: 0.195125, acc.: 67.19%] [G loss: 0.466038]\n",
      "epoch:15 step:14395 [D loss: 0.219273, acc.: 63.28%] [G loss: 0.440988]\n",
      "epoch:15 step:14396 [D loss: 0.273678, acc.: 50.00%] [G loss: 0.426988]\n",
      "epoch:15 step:14397 [D loss: 0.251673, acc.: 53.91%] [G loss: 0.439020]\n",
      "epoch:15 step:14398 [D loss: 0.204542, acc.: 71.09%] [G loss: 0.430230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14399 [D loss: 0.212506, acc.: 71.88%] [G loss: 0.480075]\n",
      "epoch:15 step:14400 [D loss: 0.209892, acc.: 66.41%] [G loss: 0.455167]\n",
      "epoch:15 step:14401 [D loss: 0.203103, acc.: 67.97%] [G loss: 0.475816]\n",
      "epoch:15 step:14402 [D loss: 0.199556, acc.: 69.53%] [G loss: 0.496882]\n",
      "epoch:15 step:14403 [D loss: 0.298851, acc.: 51.56%] [G loss: 0.439770]\n",
      "epoch:15 step:14404 [D loss: 0.297118, acc.: 47.66%] [G loss: 0.417903]\n",
      "epoch:15 step:14405 [D loss: 0.218122, acc.: 64.84%] [G loss: 0.401667]\n",
      "epoch:15 step:14406 [D loss: 0.221266, acc.: 65.62%] [G loss: 0.411022]\n",
      "epoch:15 step:14407 [D loss: 0.224770, acc.: 68.75%] [G loss: 0.461858]\n",
      "epoch:15 step:14408 [D loss: 0.205084, acc.: 64.06%] [G loss: 0.461848]\n",
      "epoch:15 step:14409 [D loss: 0.181168, acc.: 76.56%] [G loss: 0.480886]\n",
      "epoch:15 step:14410 [D loss: 0.223043, acc.: 65.62%] [G loss: 0.485020]\n",
      "epoch:15 step:14411 [D loss: 0.241905, acc.: 58.59%] [G loss: 0.422164]\n",
      "epoch:15 step:14412 [D loss: 0.212824, acc.: 60.94%] [G loss: 0.435903]\n",
      "epoch:15 step:14413 [D loss: 0.197726, acc.: 67.97%] [G loss: 0.508771]\n",
      "epoch:15 step:14414 [D loss: 0.213232, acc.: 63.28%] [G loss: 0.428278]\n",
      "epoch:15 step:14415 [D loss: 0.207825, acc.: 65.62%] [G loss: 0.470153]\n",
      "epoch:15 step:14416 [D loss: 0.200138, acc.: 75.78%] [G loss: 0.503045]\n",
      "epoch:15 step:14417 [D loss: 0.230704, acc.: 61.72%] [G loss: 0.419982]\n",
      "epoch:15 step:14418 [D loss: 0.226464, acc.: 69.53%] [G loss: 0.411038]\n",
      "epoch:15 step:14419 [D loss: 0.190616, acc.: 71.88%] [G loss: 0.444745]\n",
      "epoch:15 step:14420 [D loss: 0.236167, acc.: 60.16%] [G loss: 0.391889]\n",
      "epoch:15 step:14421 [D loss: 0.222111, acc.: 64.84%] [G loss: 0.425054]\n",
      "epoch:15 step:14422 [D loss: 0.232595, acc.: 64.06%] [G loss: 0.422801]\n",
      "epoch:15 step:14423 [D loss: 0.218313, acc.: 64.06%] [G loss: 0.426583]\n",
      "epoch:15 step:14424 [D loss: 0.242912, acc.: 58.59%] [G loss: 0.434831]\n",
      "epoch:15 step:14425 [D loss: 0.191748, acc.: 73.44%] [G loss: 0.434000]\n",
      "epoch:15 step:14426 [D loss: 0.213338, acc.: 71.09%] [G loss: 0.458313]\n",
      "epoch:15 step:14427 [D loss: 0.238929, acc.: 62.50%] [G loss: 0.402754]\n",
      "epoch:15 step:14428 [D loss: 0.244155, acc.: 53.91%] [G loss: 0.460285]\n",
      "epoch:15 step:14429 [D loss: 0.184902, acc.: 67.97%] [G loss: 0.469447]\n",
      "epoch:15 step:14430 [D loss: 0.251031, acc.: 57.81%] [G loss: 0.467668]\n",
      "epoch:15 step:14431 [D loss: 0.261860, acc.: 52.34%] [G loss: 0.451592]\n",
      "epoch:15 step:14432 [D loss: 0.254906, acc.: 54.69%] [G loss: 0.436874]\n",
      "epoch:15 step:14433 [D loss: 0.220710, acc.: 61.72%] [G loss: 0.404606]\n",
      "epoch:15 step:14434 [D loss: 0.233718, acc.: 58.59%] [G loss: 0.406045]\n",
      "epoch:15 step:14435 [D loss: 0.246516, acc.: 56.25%] [G loss: 0.453797]\n",
      "epoch:15 step:14436 [D loss: 0.213145, acc.: 67.97%] [G loss: 0.423335]\n",
      "epoch:15 step:14437 [D loss: 0.213043, acc.: 64.84%] [G loss: 0.452271]\n",
      "epoch:15 step:14438 [D loss: 0.238803, acc.: 58.59%] [G loss: 0.424943]\n",
      "epoch:15 step:14439 [D loss: 0.203685, acc.: 66.41%] [G loss: 0.463428]\n",
      "epoch:15 step:14440 [D loss: 0.206736, acc.: 66.41%] [G loss: 0.453892]\n",
      "epoch:15 step:14441 [D loss: 0.223839, acc.: 61.72%] [G loss: 0.447494]\n",
      "epoch:15 step:14442 [D loss: 0.219504, acc.: 64.06%] [G loss: 0.454100]\n",
      "epoch:15 step:14443 [D loss: 0.205667, acc.: 66.41%] [G loss: 0.496953]\n",
      "epoch:15 step:14444 [D loss: 0.230201, acc.: 60.94%] [G loss: 0.448040]\n",
      "epoch:15 step:14445 [D loss: 0.250512, acc.: 52.34%] [G loss: 0.435698]\n",
      "epoch:15 step:14446 [D loss: 0.214006, acc.: 64.84%] [G loss: 0.419762]\n",
      "epoch:15 step:14447 [D loss: 0.227718, acc.: 62.50%] [G loss: 0.407289]\n",
      "epoch:15 step:14448 [D loss: 0.243921, acc.: 60.16%] [G loss: 0.445683]\n",
      "epoch:15 step:14449 [D loss: 0.212990, acc.: 67.97%] [G loss: 0.405206]\n",
      "epoch:15 step:14450 [D loss: 0.210280, acc.: 64.84%] [G loss: 0.420788]\n",
      "epoch:15 step:14451 [D loss: 0.257175, acc.: 53.12%] [G loss: 0.410347]\n",
      "epoch:15 step:14452 [D loss: 0.230229, acc.: 60.16%] [G loss: 0.407389]\n",
      "epoch:15 step:14453 [D loss: 0.208486, acc.: 67.97%] [G loss: 0.437920]\n",
      "epoch:15 step:14454 [D loss: 0.221637, acc.: 65.62%] [G loss: 0.458679]\n",
      "epoch:15 step:14455 [D loss: 0.280144, acc.: 46.88%] [G loss: 0.435123]\n",
      "epoch:15 step:14456 [D loss: 0.222270, acc.: 60.94%] [G loss: 0.397169]\n",
      "epoch:15 step:14457 [D loss: 0.205544, acc.: 70.31%] [G loss: 0.430105]\n",
      "epoch:15 step:14458 [D loss: 0.230456, acc.: 61.72%] [G loss: 0.405900]\n",
      "epoch:15 step:14459 [D loss: 0.229681, acc.: 64.84%] [G loss: 0.417680]\n",
      "epoch:15 step:14460 [D loss: 0.202847, acc.: 64.06%] [G loss: 0.448070]\n",
      "epoch:15 step:14461 [D loss: 0.232198, acc.: 64.06%] [G loss: 0.507144]\n",
      "epoch:15 step:14462 [D loss: 0.231887, acc.: 67.19%] [G loss: 0.488317]\n",
      "epoch:15 step:14463 [D loss: 0.255513, acc.: 60.16%] [G loss: 0.419608]\n",
      "epoch:15 step:14464 [D loss: 0.233426, acc.: 57.03%] [G loss: 0.442295]\n",
      "epoch:15 step:14465 [D loss: 0.245941, acc.: 64.06%] [G loss: 0.425074]\n",
      "epoch:15 step:14466 [D loss: 0.234376, acc.: 56.25%] [G loss: 0.453314]\n",
      "epoch:15 step:14467 [D loss: 0.215255, acc.: 62.50%] [G loss: 0.455556]\n",
      "epoch:15 step:14468 [D loss: 0.227783, acc.: 65.62%] [G loss: 0.417999]\n",
      "epoch:15 step:14469 [D loss: 0.228796, acc.: 60.94%] [G loss: 0.452943]\n",
      "epoch:15 step:14470 [D loss: 0.209385, acc.: 70.31%] [G loss: 0.410224]\n",
      "epoch:15 step:14471 [D loss: 0.196861, acc.: 71.88%] [G loss: 0.492763]\n",
      "epoch:15 step:14472 [D loss: 0.232709, acc.: 64.84%] [G loss: 0.486675]\n",
      "epoch:15 step:14473 [D loss: 0.253887, acc.: 53.12%] [G loss: 0.418931]\n",
      "epoch:15 step:14474 [D loss: 0.237577, acc.: 60.94%] [G loss: 0.413183]\n",
      "epoch:15 step:14475 [D loss: 0.219701, acc.: 62.50%] [G loss: 0.439199]\n",
      "epoch:15 step:14476 [D loss: 0.256621, acc.: 52.34%] [G loss: 0.429581]\n",
      "epoch:15 step:14477 [D loss: 0.242750, acc.: 59.38%] [G loss: 0.411684]\n",
      "epoch:15 step:14478 [D loss: 0.245792, acc.: 59.38%] [G loss: 0.413628]\n",
      "epoch:15 step:14479 [D loss: 0.228172, acc.: 61.72%] [G loss: 0.432264]\n",
      "epoch:15 step:14480 [D loss: 0.212608, acc.: 62.50%] [G loss: 0.430806]\n",
      "epoch:15 step:14481 [D loss: 0.237802, acc.: 59.38%] [G loss: 0.422771]\n",
      "epoch:15 step:14482 [D loss: 0.202312, acc.: 70.31%] [G loss: 0.468452]\n",
      "epoch:15 step:14483 [D loss: 0.228300, acc.: 63.28%] [G loss: 0.437530]\n",
      "epoch:15 step:14484 [D loss: 0.197376, acc.: 71.88%] [G loss: 0.472991]\n",
      "epoch:15 step:14485 [D loss: 0.222453, acc.: 65.62%] [G loss: 0.461729]\n",
      "epoch:15 step:14486 [D loss: 0.236683, acc.: 57.03%] [G loss: 0.474587]\n",
      "epoch:15 step:14487 [D loss: 0.233430, acc.: 58.59%] [G loss: 0.442134]\n",
      "epoch:15 step:14488 [D loss: 0.245571, acc.: 54.69%] [G loss: 0.457405]\n",
      "epoch:15 step:14489 [D loss: 0.202430, acc.: 68.75%] [G loss: 0.443420]\n",
      "epoch:15 step:14490 [D loss: 0.210097, acc.: 71.09%] [G loss: 0.436088]\n",
      "epoch:15 step:14491 [D loss: 0.203972, acc.: 68.75%] [G loss: 0.476761]\n",
      "epoch:15 step:14492 [D loss: 0.288263, acc.: 45.31%] [G loss: 0.424515]\n",
      "epoch:15 step:14493 [D loss: 0.255211, acc.: 50.78%] [G loss: 0.451621]\n",
      "epoch:15 step:14494 [D loss: 0.224560, acc.: 64.06%] [G loss: 0.453729]\n",
      "epoch:15 step:14495 [D loss: 0.217161, acc.: 62.50%] [G loss: 0.426323]\n",
      "epoch:15 step:14496 [D loss: 0.241383, acc.: 59.38%] [G loss: 0.447715]\n",
      "epoch:15 step:14497 [D loss: 0.231533, acc.: 62.50%] [G loss: 0.467718]\n",
      "epoch:15 step:14498 [D loss: 0.253570, acc.: 57.81%] [G loss: 0.421889]\n",
      "epoch:15 step:14499 [D loss: 0.233667, acc.: 64.06%] [G loss: 0.450941]\n",
      "epoch:15 step:14500 [D loss: 0.221835, acc.: 68.75%] [G loss: 0.454881]\n",
      "epoch:15 step:14501 [D loss: 0.229560, acc.: 60.94%] [G loss: 0.451880]\n",
      "epoch:15 step:14502 [D loss: 0.220983, acc.: 66.41%] [G loss: 0.456363]\n",
      "epoch:15 step:14503 [D loss: 0.272377, acc.: 57.81%] [G loss: 0.415806]\n",
      "epoch:15 step:14504 [D loss: 0.197305, acc.: 67.97%] [G loss: 0.468040]\n",
      "epoch:15 step:14505 [D loss: 0.220726, acc.: 61.72%] [G loss: 0.411405]\n",
      "epoch:15 step:14506 [D loss: 0.201320, acc.: 72.66%] [G loss: 0.430248]\n",
      "epoch:15 step:14507 [D loss: 0.225909, acc.: 66.41%] [G loss: 0.466107]\n",
      "epoch:15 step:14508 [D loss: 0.225021, acc.: 64.06%] [G loss: 0.478019]\n",
      "epoch:15 step:14509 [D loss: 0.209550, acc.: 69.53%] [G loss: 0.477467]\n",
      "epoch:15 step:14510 [D loss: 0.240991, acc.: 60.16%] [G loss: 0.428326]\n",
      "epoch:15 step:14511 [D loss: 0.232212, acc.: 65.62%] [G loss: 0.432228]\n",
      "epoch:15 step:14512 [D loss: 0.204815, acc.: 67.97%] [G loss: 0.466707]\n",
      "epoch:15 step:14513 [D loss: 0.276856, acc.: 54.69%] [G loss: 0.389650]\n",
      "epoch:15 step:14514 [D loss: 0.242483, acc.: 59.38%] [G loss: 0.397105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14515 [D loss: 0.237350, acc.: 56.25%] [G loss: 0.393107]\n",
      "epoch:15 step:14516 [D loss: 0.241598, acc.: 60.16%] [G loss: 0.395239]\n",
      "epoch:15 step:14517 [D loss: 0.215160, acc.: 63.28%] [G loss: 0.423621]\n",
      "epoch:15 step:14518 [D loss: 0.215212, acc.: 65.62%] [G loss: 0.431650]\n",
      "epoch:15 step:14519 [D loss: 0.231733, acc.: 60.94%] [G loss: 0.419122]\n",
      "epoch:15 step:14520 [D loss: 0.223141, acc.: 66.41%] [G loss: 0.423618]\n",
      "epoch:15 step:14521 [D loss: 0.221453, acc.: 64.06%] [G loss: 0.428092]\n",
      "epoch:15 step:14522 [D loss: 0.216950, acc.: 67.19%] [G loss: 0.450640]\n",
      "epoch:15 step:14523 [D loss: 0.206195, acc.: 68.75%] [G loss: 0.466958]\n",
      "epoch:15 step:14524 [D loss: 0.213745, acc.: 62.50%] [G loss: 0.439924]\n",
      "epoch:15 step:14525 [D loss: 0.213024, acc.: 65.62%] [G loss: 0.474010]\n",
      "epoch:15 step:14526 [D loss: 0.190942, acc.: 74.22%] [G loss: 0.518727]\n",
      "epoch:15 step:14527 [D loss: 0.231825, acc.: 65.62%] [G loss: 0.501073]\n",
      "epoch:15 step:14528 [D loss: 0.300708, acc.: 47.66%] [G loss: 0.461154]\n",
      "epoch:15 step:14529 [D loss: 0.182239, acc.: 74.22%] [G loss: 0.537142]\n",
      "epoch:15 step:14530 [D loss: 0.207513, acc.: 68.75%] [G loss: 0.493787]\n",
      "epoch:15 step:14531 [D loss: 0.244622, acc.: 60.94%] [G loss: 0.423859]\n",
      "epoch:15 step:14532 [D loss: 0.275205, acc.: 51.56%] [G loss: 0.401648]\n",
      "epoch:15 step:14533 [D loss: 0.245264, acc.: 59.38%] [G loss: 0.386055]\n",
      "epoch:15 step:14534 [D loss: 0.229881, acc.: 64.06%] [G loss: 0.407135]\n",
      "epoch:15 step:14535 [D loss: 0.238004, acc.: 55.47%] [G loss: 0.393972]\n",
      "epoch:15 step:14536 [D loss: 0.173075, acc.: 78.91%] [G loss: 0.477949]\n",
      "epoch:15 step:14537 [D loss: 0.277400, acc.: 52.34%] [G loss: 0.376309]\n",
      "epoch:15 step:14538 [D loss: 0.236108, acc.: 59.38%] [G loss: 0.398706]\n",
      "epoch:15 step:14539 [D loss: 0.206776, acc.: 67.97%] [G loss: 0.440376]\n",
      "epoch:15 step:14540 [D loss: 0.241093, acc.: 61.72%] [G loss: 0.442499]\n",
      "epoch:15 step:14541 [D loss: 0.240241, acc.: 60.94%] [G loss: 0.446795]\n",
      "epoch:15 step:14542 [D loss: 0.241425, acc.: 56.25%] [G loss: 0.459374]\n",
      "epoch:15 step:14543 [D loss: 0.191241, acc.: 73.44%] [G loss: 0.455689]\n",
      "epoch:15 step:14544 [D loss: 0.255027, acc.: 57.03%] [G loss: 0.386436]\n",
      "epoch:15 step:14545 [D loss: 0.231695, acc.: 60.94%] [G loss: 0.433000]\n",
      "epoch:15 step:14546 [D loss: 0.228568, acc.: 60.16%] [G loss: 0.422312]\n",
      "epoch:15 step:14547 [D loss: 0.233518, acc.: 61.72%] [G loss: 0.415164]\n",
      "epoch:15 step:14548 [D loss: 0.226051, acc.: 60.94%] [G loss: 0.457816]\n",
      "epoch:15 step:14549 [D loss: 0.208135, acc.: 69.53%] [G loss: 0.466200]\n",
      "epoch:15 step:14550 [D loss: 0.205132, acc.: 67.19%] [G loss: 0.462132]\n",
      "epoch:15 step:14551 [D loss: 0.238091, acc.: 63.28%] [G loss: 0.491255]\n",
      "epoch:15 step:14552 [D loss: 0.220438, acc.: 65.62%] [G loss: 0.471357]\n",
      "epoch:15 step:14553 [D loss: 0.177238, acc.: 73.44%] [G loss: 0.498937]\n",
      "epoch:15 step:14554 [D loss: 0.171728, acc.: 78.12%] [G loss: 0.475962]\n",
      "epoch:15 step:14555 [D loss: 0.277040, acc.: 55.47%] [G loss: 0.499985]\n",
      "epoch:15 step:14556 [D loss: 0.268820, acc.: 52.34%] [G loss: 0.416321]\n",
      "epoch:15 step:14557 [D loss: 0.245911, acc.: 54.69%] [G loss: 0.475723]\n",
      "epoch:15 step:14558 [D loss: 0.218755, acc.: 64.84%] [G loss: 0.432485]\n",
      "epoch:15 step:14559 [D loss: 0.188037, acc.: 72.66%] [G loss: 0.474785]\n",
      "epoch:15 step:14560 [D loss: 0.206552, acc.: 68.75%] [G loss: 0.530593]\n",
      "epoch:15 step:14561 [D loss: 0.286102, acc.: 53.12%] [G loss: 0.446864]\n",
      "epoch:15 step:14562 [D loss: 0.209344, acc.: 67.19%] [G loss: 0.503214]\n",
      "epoch:15 step:14563 [D loss: 0.208876, acc.: 71.09%] [G loss: 0.490300]\n",
      "epoch:15 step:14564 [D loss: 0.244824, acc.: 55.47%] [G loss: 0.421759]\n",
      "epoch:15 step:14565 [D loss: 0.252430, acc.: 54.69%] [G loss: 0.395720]\n",
      "epoch:15 step:14566 [D loss: 0.229961, acc.: 57.81%] [G loss: 0.444025]\n",
      "epoch:15 step:14567 [D loss: 0.242222, acc.: 53.91%] [G loss: 0.425865]\n",
      "epoch:15 step:14568 [D loss: 0.191363, acc.: 72.66%] [G loss: 0.494051]\n",
      "epoch:15 step:14569 [D loss: 0.215821, acc.: 61.72%] [G loss: 0.463980]\n",
      "epoch:15 step:14570 [D loss: 0.202025, acc.: 70.31%] [G loss: 0.495820]\n",
      "epoch:15 step:14571 [D loss: 0.212393, acc.: 65.62%] [G loss: 0.473643]\n",
      "epoch:15 step:14572 [D loss: 0.220334, acc.: 64.06%] [G loss: 0.453726]\n",
      "epoch:15 step:14573 [D loss: 0.226317, acc.: 64.06%] [G loss: 0.463259]\n",
      "epoch:15 step:14574 [D loss: 0.218878, acc.: 67.19%] [G loss: 0.406454]\n",
      "epoch:15 step:14575 [D loss: 0.205918, acc.: 66.41%] [G loss: 0.452878]\n",
      "epoch:15 step:14576 [D loss: 0.209765, acc.: 65.62%] [G loss: 0.447744]\n",
      "epoch:15 step:14577 [D loss: 0.193511, acc.: 71.88%] [G loss: 0.464818]\n",
      "epoch:15 step:14578 [D loss: 0.202511, acc.: 67.97%] [G loss: 0.431264]\n",
      "epoch:15 step:14579 [D loss: 0.219244, acc.: 64.06%] [G loss: 0.421739]\n",
      "epoch:15 step:14580 [D loss: 0.225390, acc.: 64.84%] [G loss: 0.459884]\n",
      "epoch:15 step:14581 [D loss: 0.198792, acc.: 71.09%] [G loss: 0.469051]\n",
      "epoch:15 step:14582 [D loss: 0.254388, acc.: 53.91%] [G loss: 0.425600]\n",
      "epoch:15 step:14583 [D loss: 0.267065, acc.: 51.56%] [G loss: 0.446799]\n",
      "epoch:15 step:14584 [D loss: 0.244910, acc.: 57.03%] [G loss: 0.446332]\n",
      "epoch:15 step:14585 [D loss: 0.218673, acc.: 64.84%] [G loss: 0.448669]\n",
      "epoch:15 step:14586 [D loss: 0.253349, acc.: 54.69%] [G loss: 0.400424]\n",
      "epoch:15 step:14587 [D loss: 0.245410, acc.: 61.72%] [G loss: 0.420887]\n",
      "epoch:15 step:14588 [D loss: 0.227112, acc.: 60.16%] [G loss: 0.425487]\n",
      "epoch:15 step:14589 [D loss: 0.185801, acc.: 76.56%] [G loss: 0.472828]\n",
      "epoch:15 step:14590 [D loss: 0.246150, acc.: 57.03%] [G loss: 0.428900]\n",
      "epoch:15 step:14591 [D loss: 0.215578, acc.: 66.41%] [G loss: 0.448076]\n",
      "epoch:15 step:14592 [D loss: 0.249516, acc.: 56.25%] [G loss: 0.432005]\n",
      "epoch:15 step:14593 [D loss: 0.250193, acc.: 57.81%] [G loss: 0.461008]\n",
      "epoch:15 step:14594 [D loss: 0.236562, acc.: 57.81%] [G loss: 0.443511]\n",
      "epoch:15 step:14595 [D loss: 0.230682, acc.: 60.94%] [G loss: 0.465895]\n",
      "epoch:15 step:14596 [D loss: 0.227617, acc.: 61.72%] [G loss: 0.423263]\n",
      "epoch:15 step:14597 [D loss: 0.239432, acc.: 60.16%] [G loss: 0.429282]\n",
      "epoch:15 step:14598 [D loss: 0.225875, acc.: 59.38%] [G loss: 0.461380]\n",
      "epoch:15 step:14599 [D loss: 0.223502, acc.: 63.28%] [G loss: 0.437613]\n",
      "epoch:15 step:14600 [D loss: 0.243531, acc.: 63.28%] [G loss: 0.447996]\n",
      "epoch:15 step:14601 [D loss: 0.214354, acc.: 64.06%] [G loss: 0.478016]\n",
      "epoch:15 step:14602 [D loss: 0.210771, acc.: 63.28%] [G loss: 0.459354]\n",
      "epoch:15 step:14603 [D loss: 0.208857, acc.: 63.28%] [G loss: 0.445447]\n",
      "epoch:15 step:14604 [D loss: 0.189921, acc.: 67.19%] [G loss: 0.446390]\n",
      "epoch:15 step:14605 [D loss: 0.204672, acc.: 73.44%] [G loss: 0.458005]\n",
      "epoch:15 step:14606 [D loss: 0.187918, acc.: 73.44%] [G loss: 0.462935]\n",
      "epoch:15 step:14607 [D loss: 0.212874, acc.: 69.53%] [G loss: 0.463219]\n",
      "epoch:15 step:14608 [D loss: 0.246192, acc.: 57.81%] [G loss: 0.415075]\n",
      "epoch:15 step:14609 [D loss: 0.184782, acc.: 73.44%] [G loss: 0.473211]\n",
      "epoch:15 step:14610 [D loss: 0.212288, acc.: 66.41%] [G loss: 0.455662]\n",
      "epoch:15 step:14611 [D loss: 0.209876, acc.: 66.41%] [G loss: 0.513449]\n",
      "epoch:15 step:14612 [D loss: 0.193873, acc.: 69.53%] [G loss: 0.476824]\n",
      "epoch:15 step:14613 [D loss: 0.229333, acc.: 57.03%] [G loss: 0.463788]\n",
      "epoch:15 step:14614 [D loss: 0.280856, acc.: 47.66%] [G loss: 0.428682]\n",
      "epoch:15 step:14615 [D loss: 0.253255, acc.: 57.03%] [G loss: 0.436592]\n",
      "epoch:15 step:14616 [D loss: 0.223893, acc.: 58.59%] [G loss: 0.464048]\n",
      "epoch:15 step:14617 [D loss: 0.205119, acc.: 67.19%] [G loss: 0.454909]\n",
      "epoch:15 step:14618 [D loss: 0.230726, acc.: 58.59%] [G loss: 0.488415]\n",
      "epoch:15 step:14619 [D loss: 0.182301, acc.: 74.22%] [G loss: 0.476671]\n",
      "epoch:15 step:14620 [D loss: 0.242667, acc.: 60.94%] [G loss: 0.455799]\n",
      "epoch:15 step:14621 [D loss: 0.254078, acc.: 61.72%] [G loss: 0.421437]\n",
      "epoch:15 step:14622 [D loss: 0.229212, acc.: 63.28%] [G loss: 0.444700]\n",
      "epoch:15 step:14623 [D loss: 0.222639, acc.: 59.38%] [G loss: 0.425701]\n",
      "epoch:15 step:14624 [D loss: 0.240894, acc.: 53.12%] [G loss: 0.431692]\n",
      "epoch:15 step:14625 [D loss: 0.196324, acc.: 68.75%] [G loss: 0.438437]\n",
      "epoch:15 step:14626 [D loss: 0.215475, acc.: 63.28%] [G loss: 0.424289]\n",
      "epoch:15 step:14627 [D loss: 0.212940, acc.: 71.09%] [G loss: 0.462922]\n",
      "epoch:15 step:14628 [D loss: 0.251884, acc.: 60.16%] [G loss: 0.454867]\n",
      "epoch:15 step:14629 [D loss: 0.182854, acc.: 68.75%] [G loss: 0.498103]\n",
      "epoch:15 step:14630 [D loss: 0.202916, acc.: 64.84%] [G loss: 0.492206]\n",
      "epoch:15 step:14631 [D loss: 0.238576, acc.: 57.81%] [G loss: 0.435618]\n",
      "epoch:15 step:14632 [D loss: 0.234253, acc.: 64.06%] [G loss: 0.412620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14633 [D loss: 0.229140, acc.: 60.94%] [G loss: 0.439016]\n",
      "epoch:15 step:14634 [D loss: 0.266825, acc.: 53.91%] [G loss: 0.424705]\n",
      "epoch:15 step:14635 [D loss: 0.230219, acc.: 61.72%] [G loss: 0.465447]\n",
      "epoch:15 step:14636 [D loss: 0.227546, acc.: 63.28%] [G loss: 0.482038]\n",
      "epoch:15 step:14637 [D loss: 0.201325, acc.: 68.75%] [G loss: 0.503100]\n",
      "epoch:15 step:14638 [D loss: 0.233001, acc.: 60.16%] [G loss: 0.484102]\n",
      "epoch:15 step:14639 [D loss: 0.232207, acc.: 63.28%] [G loss: 0.462974]\n",
      "epoch:15 step:14640 [D loss: 0.209584, acc.: 64.06%] [G loss: 0.440718]\n",
      "epoch:15 step:14641 [D loss: 0.234183, acc.: 56.25%] [G loss: 0.416390]\n",
      "epoch:15 step:14642 [D loss: 0.233035, acc.: 60.16%] [G loss: 0.457770]\n",
      "epoch:15 step:14643 [D loss: 0.215720, acc.: 59.38%] [G loss: 0.470429]\n",
      "epoch:15 step:14644 [D loss: 0.199028, acc.: 66.41%] [G loss: 0.456785]\n",
      "epoch:15 step:14645 [D loss: 0.253506, acc.: 62.50%] [G loss: 0.481558]\n",
      "epoch:15 step:14646 [D loss: 0.213825, acc.: 64.06%] [G loss: 0.440436]\n",
      "epoch:15 step:14647 [D loss: 0.207724, acc.: 67.19%] [G loss: 0.437856]\n",
      "epoch:15 step:14648 [D loss: 0.209940, acc.: 62.50%] [G loss: 0.445109]\n",
      "epoch:15 step:14649 [D loss: 0.220469, acc.: 60.94%] [G loss: 0.450280]\n",
      "epoch:15 step:14650 [D loss: 0.224184, acc.: 66.41%] [G loss: 0.435110]\n",
      "epoch:15 step:14651 [D loss: 0.238034, acc.: 57.81%] [G loss: 0.446545]\n",
      "epoch:15 step:14652 [D loss: 0.218179, acc.: 64.84%] [G loss: 0.469511]\n",
      "epoch:15 step:14653 [D loss: 0.213324, acc.: 71.09%] [G loss: 0.430009]\n",
      "epoch:15 step:14654 [D loss: 0.211048, acc.: 60.94%] [G loss: 0.462103]\n",
      "epoch:15 step:14655 [D loss: 0.264844, acc.: 53.91%] [G loss: 0.437889]\n",
      "epoch:15 step:14656 [D loss: 0.219989, acc.: 62.50%] [G loss: 0.408340]\n",
      "epoch:15 step:14657 [D loss: 0.255822, acc.: 55.47%] [G loss: 0.447904]\n",
      "epoch:15 step:14658 [D loss: 0.242493, acc.: 60.94%] [G loss: 0.387354]\n",
      "epoch:15 step:14659 [D loss: 0.220263, acc.: 64.84%] [G loss: 0.414938]\n",
      "epoch:15 step:14660 [D loss: 0.200614, acc.: 73.44%] [G loss: 0.452177]\n",
      "epoch:15 step:14661 [D loss: 0.224531, acc.: 63.28%] [G loss: 0.413161]\n",
      "epoch:15 step:14662 [D loss: 0.228008, acc.: 54.69%] [G loss: 0.456438]\n",
      "epoch:15 step:14663 [D loss: 0.216610, acc.: 64.06%] [G loss: 0.445917]\n",
      "epoch:15 step:14664 [D loss: 0.210549, acc.: 62.50%] [G loss: 0.476705]\n",
      "epoch:15 step:14665 [D loss: 0.229271, acc.: 62.50%] [G loss: 0.420058]\n",
      "epoch:15 step:14666 [D loss: 0.222031, acc.: 71.09%] [G loss: 0.405203]\n",
      "epoch:15 step:14667 [D loss: 0.248198, acc.: 60.16%] [G loss: 0.432545]\n",
      "epoch:15 step:14668 [D loss: 0.196955, acc.: 71.88%] [G loss: 0.468999]\n",
      "epoch:15 step:14669 [D loss: 0.237768, acc.: 58.59%] [G loss: 0.460303]\n",
      "epoch:15 step:14670 [D loss: 0.270845, acc.: 55.47%] [G loss: 0.405960]\n",
      "epoch:15 step:14671 [D loss: 0.248444, acc.: 60.16%] [G loss: 0.415436]\n",
      "epoch:15 step:14672 [D loss: 0.202806, acc.: 67.97%] [G loss: 0.448789]\n",
      "epoch:15 step:14673 [D loss: 0.208054, acc.: 65.62%] [G loss: 0.462495]\n",
      "epoch:15 step:14674 [D loss: 0.238924, acc.: 60.94%] [G loss: 0.444618]\n",
      "epoch:15 step:14675 [D loss: 0.225433, acc.: 64.84%] [G loss: 0.452529]\n",
      "epoch:15 step:14676 [D loss: 0.220292, acc.: 64.06%] [G loss: 0.454774]\n",
      "epoch:15 step:14677 [D loss: 0.220141, acc.: 64.84%] [G loss: 0.468935]\n",
      "epoch:15 step:14678 [D loss: 0.220811, acc.: 61.72%] [G loss: 0.429777]\n",
      "epoch:15 step:14679 [D loss: 0.188632, acc.: 72.66%] [G loss: 0.451582]\n",
      "epoch:15 step:14680 [D loss: 0.239108, acc.: 57.81%] [G loss: 0.429715]\n",
      "epoch:15 step:14681 [D loss: 0.245692, acc.: 60.16%] [G loss: 0.423021]\n",
      "epoch:15 step:14682 [D loss: 0.221528, acc.: 67.97%] [G loss: 0.434432]\n",
      "epoch:15 step:14683 [D loss: 0.240911, acc.: 61.72%] [G loss: 0.445783]\n",
      "epoch:15 step:14684 [D loss: 0.213903, acc.: 65.62%] [G loss: 0.455692]\n",
      "epoch:15 step:14685 [D loss: 0.252369, acc.: 64.84%] [G loss: 0.423265]\n",
      "epoch:15 step:14686 [D loss: 0.213684, acc.: 64.84%] [G loss: 0.459968]\n",
      "epoch:15 step:14687 [D loss: 0.207765, acc.: 68.75%] [G loss: 0.461349]\n",
      "epoch:15 step:14688 [D loss: 0.223601, acc.: 64.84%] [G loss: 0.454694]\n",
      "epoch:15 step:14689 [D loss: 0.190298, acc.: 73.44%] [G loss: 0.468095]\n",
      "epoch:15 step:14690 [D loss: 0.216876, acc.: 67.97%] [G loss: 0.443950]\n",
      "epoch:15 step:14691 [D loss: 0.240474, acc.: 63.28%] [G loss: 0.447317]\n",
      "epoch:15 step:14692 [D loss: 0.224351, acc.: 64.06%] [G loss: 0.444625]\n",
      "epoch:15 step:14693 [D loss: 0.230299, acc.: 60.16%] [G loss: 0.453497]\n",
      "epoch:15 step:14694 [D loss: 0.244762, acc.: 58.59%] [G loss: 0.425163]\n",
      "epoch:15 step:14695 [D loss: 0.234519, acc.: 58.59%] [G loss: 0.453738]\n",
      "epoch:15 step:14696 [D loss: 0.191365, acc.: 73.44%] [G loss: 0.516225]\n",
      "epoch:15 step:14697 [D loss: 0.185194, acc.: 71.09%] [G loss: 0.513733]\n",
      "epoch:15 step:14698 [D loss: 0.241368, acc.: 64.84%] [G loss: 0.439623]\n",
      "epoch:15 step:14699 [D loss: 0.218651, acc.: 67.19%] [G loss: 0.424777]\n",
      "epoch:15 step:14700 [D loss: 0.223669, acc.: 60.94%] [G loss: 0.431336]\n",
      "epoch:15 step:14701 [D loss: 0.221744, acc.: 64.06%] [G loss: 0.453594]\n",
      "epoch:15 step:14702 [D loss: 0.214320, acc.: 68.75%] [G loss: 0.468944]\n",
      "epoch:15 step:14703 [D loss: 0.173407, acc.: 76.56%] [G loss: 0.512138]\n",
      "epoch:15 step:14704 [D loss: 0.224843, acc.: 64.84%] [G loss: 0.527771]\n",
      "epoch:15 step:14705 [D loss: 0.201108, acc.: 69.53%] [G loss: 0.528471]\n",
      "epoch:15 step:14706 [D loss: 0.237812, acc.: 63.28%] [G loss: 0.442180]\n",
      "epoch:15 step:14707 [D loss: 0.219806, acc.: 63.28%] [G loss: 0.433329]\n",
      "epoch:15 step:14708 [D loss: 0.219581, acc.: 67.19%] [G loss: 0.470466]\n",
      "epoch:15 step:14709 [D loss: 0.198943, acc.: 69.53%] [G loss: 0.433763]\n",
      "epoch:15 step:14710 [D loss: 0.232639, acc.: 65.62%] [G loss: 0.432498]\n",
      "epoch:15 step:14711 [D loss: 0.247932, acc.: 60.16%] [G loss: 0.404626]\n",
      "epoch:15 step:14712 [D loss: 0.248290, acc.: 55.47%] [G loss: 0.455809]\n",
      "epoch:15 step:14713 [D loss: 0.229930, acc.: 62.50%] [G loss: 0.466639]\n",
      "epoch:15 step:14714 [D loss: 0.223176, acc.: 60.94%] [G loss: 0.488734]\n",
      "epoch:15 step:14715 [D loss: 0.224108, acc.: 65.62%] [G loss: 0.380248]\n",
      "epoch:15 step:14716 [D loss: 0.218971, acc.: 65.62%] [G loss: 0.436396]\n",
      "epoch:15 step:14717 [D loss: 0.207826, acc.: 64.84%] [G loss: 0.454219]\n",
      "epoch:15 step:14718 [D loss: 0.234592, acc.: 59.38%] [G loss: 0.434274]\n",
      "epoch:15 step:14719 [D loss: 0.220102, acc.: 63.28%] [G loss: 0.457595]\n",
      "epoch:15 step:14720 [D loss: 0.205756, acc.: 70.31%] [G loss: 0.441478]\n",
      "epoch:15 step:14721 [D loss: 0.234805, acc.: 60.16%] [G loss: 0.468870]\n",
      "epoch:15 step:14722 [D loss: 0.228789, acc.: 57.81%] [G loss: 0.442912]\n",
      "epoch:15 step:14723 [D loss: 0.250075, acc.: 54.69%] [G loss: 0.438656]\n",
      "epoch:15 step:14724 [D loss: 0.212739, acc.: 66.41%] [G loss: 0.431304]\n",
      "epoch:15 step:14725 [D loss: 0.239727, acc.: 58.59%] [G loss: 0.387796]\n",
      "epoch:15 step:14726 [D loss: 0.227645, acc.: 64.06%] [G loss: 0.403943]\n",
      "epoch:15 step:14727 [D loss: 0.246809, acc.: 57.03%] [G loss: 0.405147]\n",
      "epoch:15 step:14728 [D loss: 0.238334, acc.: 60.94%] [G loss: 0.421613]\n",
      "epoch:15 step:14729 [D loss: 0.218265, acc.: 63.28%] [G loss: 0.443501]\n",
      "epoch:15 step:14730 [D loss: 0.262314, acc.: 53.91%] [G loss: 0.420120]\n",
      "epoch:15 step:14731 [D loss: 0.219816, acc.: 67.19%] [G loss: 0.431316]\n",
      "epoch:15 step:14732 [D loss: 0.213719, acc.: 67.97%] [G loss: 0.412544]\n",
      "epoch:15 step:14733 [D loss: 0.222578, acc.: 65.62%] [G loss: 0.415789]\n",
      "epoch:15 step:14734 [D loss: 0.218580, acc.: 62.50%] [G loss: 0.411229]\n",
      "epoch:15 step:14735 [D loss: 0.229442, acc.: 60.16%] [G loss: 0.430909]\n",
      "epoch:15 step:14736 [D loss: 0.206106, acc.: 67.19%] [G loss: 0.446963]\n",
      "epoch:15 step:14737 [D loss: 0.211252, acc.: 71.09%] [G loss: 0.407787]\n",
      "epoch:15 step:14738 [D loss: 0.221240, acc.: 61.72%] [G loss: 0.424710]\n",
      "epoch:15 step:14739 [D loss: 0.252457, acc.: 57.81%] [G loss: 0.388785]\n",
      "epoch:15 step:14740 [D loss: 0.215741, acc.: 64.84%] [G loss: 0.410397]\n",
      "epoch:15 step:14741 [D loss: 0.234268, acc.: 62.50%] [G loss: 0.435843]\n",
      "epoch:15 step:14742 [D loss: 0.228750, acc.: 57.81%] [G loss: 0.406933]\n",
      "epoch:15 step:14743 [D loss: 0.203780, acc.: 71.88%] [G loss: 0.477856]\n",
      "epoch:15 step:14744 [D loss: 0.248410, acc.: 57.81%] [G loss: 0.436890]\n",
      "epoch:15 step:14745 [D loss: 0.214375, acc.: 66.41%] [G loss: 0.447420]\n",
      "epoch:15 step:14746 [D loss: 0.223366, acc.: 61.72%] [G loss: 0.440510]\n",
      "epoch:15 step:14747 [D loss: 0.221452, acc.: 66.41%] [G loss: 0.483220]\n",
      "epoch:15 step:14748 [D loss: 0.201636, acc.: 71.09%] [G loss: 0.476255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14749 [D loss: 0.204621, acc.: 63.28%] [G loss: 0.492384]\n",
      "epoch:15 step:14750 [D loss: 0.213774, acc.: 66.41%] [G loss: 0.498625]\n",
      "epoch:15 step:14751 [D loss: 0.264846, acc.: 53.91%] [G loss: 0.416000]\n",
      "epoch:15 step:14752 [D loss: 0.234874, acc.: 60.16%] [G loss: 0.416486]\n",
      "epoch:15 step:14753 [D loss: 0.233920, acc.: 60.16%] [G loss: 0.433732]\n",
      "epoch:15 step:14754 [D loss: 0.216420, acc.: 67.19%] [G loss: 0.448991]\n",
      "epoch:15 step:14755 [D loss: 0.209160, acc.: 67.97%] [G loss: 0.437442]\n",
      "epoch:15 step:14756 [D loss: 0.209845, acc.: 67.97%] [G loss: 0.446471]\n",
      "epoch:15 step:14757 [D loss: 0.239583, acc.: 59.38%] [G loss: 0.437683]\n",
      "epoch:15 step:14758 [D loss: 0.233136, acc.: 63.28%] [G loss: 0.444217]\n",
      "epoch:15 step:14759 [D loss: 0.239711, acc.: 57.81%] [G loss: 0.413175]\n",
      "epoch:15 step:14760 [D loss: 0.211953, acc.: 68.75%] [G loss: 0.445455]\n",
      "epoch:15 step:14761 [D loss: 0.223562, acc.: 57.81%] [G loss: 0.451298]\n",
      "epoch:15 step:14762 [D loss: 0.199367, acc.: 70.31%] [G loss: 0.463197]\n",
      "epoch:15 step:14763 [D loss: 0.202829, acc.: 65.62%] [G loss: 0.453657]\n",
      "epoch:15 step:14764 [D loss: 0.185755, acc.: 70.31%] [G loss: 0.499934]\n",
      "epoch:15 step:14765 [D loss: 0.256798, acc.: 59.38%] [G loss: 0.391462]\n",
      "epoch:15 step:14766 [D loss: 0.225608, acc.: 60.94%] [G loss: 0.399546]\n",
      "epoch:15 step:14767 [D loss: 0.224086, acc.: 59.38%] [G loss: 0.495607]\n",
      "epoch:15 step:14768 [D loss: 0.211253, acc.: 63.28%] [G loss: 0.474945]\n",
      "epoch:15 step:14769 [D loss: 0.201108, acc.: 67.19%] [G loss: 0.460995]\n",
      "epoch:15 step:14770 [D loss: 0.232528, acc.: 55.47%] [G loss: 0.412514]\n",
      "epoch:15 step:14771 [D loss: 0.259210, acc.: 54.69%] [G loss: 0.391509]\n",
      "epoch:15 step:14772 [D loss: 0.213507, acc.: 66.41%] [G loss: 0.465409]\n",
      "epoch:15 step:14773 [D loss: 0.223411, acc.: 67.19%] [G loss: 0.445114]\n",
      "epoch:15 step:14774 [D loss: 0.199369, acc.: 69.53%] [G loss: 0.469600]\n",
      "epoch:15 step:14775 [D loss: 0.224305, acc.: 64.84%] [G loss: 0.484283]\n",
      "epoch:15 step:14776 [D loss: 0.232434, acc.: 60.16%] [G loss: 0.485289]\n",
      "epoch:15 step:14777 [D loss: 0.245600, acc.: 57.81%] [G loss: 0.423518]\n",
      "epoch:15 step:14778 [D loss: 0.210532, acc.: 65.62%] [G loss: 0.445295]\n",
      "epoch:15 step:14779 [D loss: 0.200697, acc.: 67.97%] [G loss: 0.455009]\n",
      "epoch:15 step:14780 [D loss: 0.217210, acc.: 66.41%] [G loss: 0.450934]\n",
      "epoch:15 step:14781 [D loss: 0.219010, acc.: 63.28%] [G loss: 0.463054]\n",
      "epoch:15 step:14782 [D loss: 0.242606, acc.: 60.16%] [G loss: 0.428367]\n",
      "epoch:15 step:14783 [D loss: 0.237580, acc.: 57.81%] [G loss: 0.414102]\n",
      "epoch:15 step:14784 [D loss: 0.237283, acc.: 59.38%] [G loss: 0.399837]\n",
      "epoch:15 step:14785 [D loss: 0.198808, acc.: 70.31%] [G loss: 0.442342]\n",
      "epoch:15 step:14786 [D loss: 0.213451, acc.: 67.97%] [G loss: 0.438059]\n",
      "epoch:15 step:14787 [D loss: 0.231522, acc.: 66.41%] [G loss: 0.467509]\n",
      "epoch:15 step:14788 [D loss: 0.195152, acc.: 67.97%] [G loss: 0.500458]\n",
      "epoch:15 step:14789 [D loss: 0.226147, acc.: 61.72%] [G loss: 0.437394]\n",
      "epoch:15 step:14790 [D loss: 0.236375, acc.: 60.16%] [G loss: 0.410885]\n",
      "epoch:15 step:14791 [D loss: 0.208003, acc.: 64.84%] [G loss: 0.418189]\n",
      "epoch:15 step:14792 [D loss: 0.240249, acc.: 55.47%] [G loss: 0.396456]\n",
      "epoch:15 step:14793 [D loss: 0.229056, acc.: 61.72%] [G loss: 0.456138]\n",
      "epoch:15 step:14794 [D loss: 0.251550, acc.: 50.78%] [G loss: 0.443573]\n",
      "epoch:15 step:14795 [D loss: 0.238695, acc.: 53.91%] [G loss: 0.421983]\n",
      "epoch:15 step:14796 [D loss: 0.245709, acc.: 60.16%] [G loss: 0.451625]\n",
      "epoch:15 step:14797 [D loss: 0.225883, acc.: 60.94%] [G loss: 0.472802]\n",
      "epoch:15 step:14798 [D loss: 0.235952, acc.: 64.06%] [G loss: 0.444616]\n",
      "epoch:15 step:14799 [D loss: 0.225188, acc.: 65.62%] [G loss: 0.453223]\n",
      "epoch:15 step:14800 [D loss: 0.251220, acc.: 57.03%] [G loss: 0.382145]\n",
      "epoch:15 step:14801 [D loss: 0.227041, acc.: 58.59%] [G loss: 0.432630]\n",
      "epoch:15 step:14802 [D loss: 0.213951, acc.: 64.84%] [G loss: 0.434491]\n",
      "epoch:15 step:14803 [D loss: 0.225960, acc.: 64.06%] [G loss: 0.418995]\n",
      "epoch:15 step:14804 [D loss: 0.255772, acc.: 53.91%] [G loss: 0.401511]\n",
      "epoch:15 step:14805 [D loss: 0.227344, acc.: 62.50%] [G loss: 0.425358]\n",
      "epoch:15 step:14806 [D loss: 0.227778, acc.: 57.03%] [G loss: 0.433755]\n",
      "epoch:15 step:14807 [D loss: 0.240204, acc.: 56.25%] [G loss: 0.446526]\n",
      "epoch:15 step:14808 [D loss: 0.239812, acc.: 62.50%] [G loss: 0.442930]\n",
      "epoch:15 step:14809 [D loss: 0.198844, acc.: 68.75%] [G loss: 0.453245]\n",
      "epoch:15 step:14810 [D loss: 0.228345, acc.: 63.28%] [G loss: 0.414617]\n",
      "epoch:15 step:14811 [D loss: 0.221138, acc.: 61.72%] [G loss: 0.458955]\n",
      "epoch:15 step:14812 [D loss: 0.239232, acc.: 59.38%] [G loss: 0.449543]\n",
      "epoch:15 step:14813 [D loss: 0.236972, acc.: 57.03%] [G loss: 0.428679]\n",
      "epoch:15 step:14814 [D loss: 0.256683, acc.: 53.91%] [G loss: 0.398828]\n",
      "epoch:15 step:14815 [D loss: 0.240428, acc.: 60.94%] [G loss: 0.421427]\n",
      "epoch:15 step:14816 [D loss: 0.247721, acc.: 58.59%] [G loss: 0.407274]\n",
      "epoch:15 step:14817 [D loss: 0.219223, acc.: 62.50%] [G loss: 0.441152]\n",
      "epoch:15 step:14818 [D loss: 0.215091, acc.: 68.75%] [G loss: 0.417140]\n",
      "epoch:15 step:14819 [D loss: 0.206552, acc.: 67.19%] [G loss: 0.471298]\n",
      "epoch:15 step:14820 [D loss: 0.274821, acc.: 53.12%] [G loss: 0.432064]\n",
      "epoch:15 step:14821 [D loss: 0.250193, acc.: 62.50%] [G loss: 0.455161]\n",
      "epoch:15 step:14822 [D loss: 0.214228, acc.: 68.75%] [G loss: 0.482266]\n",
      "epoch:15 step:14823 [D loss: 0.244250, acc.: 57.81%] [G loss: 0.494689]\n",
      "epoch:15 step:14824 [D loss: 0.210022, acc.: 67.19%] [G loss: 0.469924]\n",
      "epoch:15 step:14825 [D loss: 0.261093, acc.: 58.59%] [G loss: 0.476007]\n",
      "epoch:15 step:14826 [D loss: 0.243982, acc.: 61.72%] [G loss: 0.459480]\n",
      "epoch:15 step:14827 [D loss: 0.223130, acc.: 63.28%] [G loss: 0.423110]\n",
      "epoch:15 step:14828 [D loss: 0.216587, acc.: 64.06%] [G loss: 0.408667]\n",
      "epoch:15 step:14829 [D loss: 0.260614, acc.: 60.16%] [G loss: 0.416670]\n",
      "epoch:15 step:14830 [D loss: 0.226449, acc.: 59.38%] [G loss: 0.428015]\n",
      "epoch:15 step:14831 [D loss: 0.233903, acc.: 55.47%] [G loss: 0.438255]\n",
      "epoch:15 step:14832 [D loss: 0.218862, acc.: 66.41%] [G loss: 0.476033]\n",
      "epoch:15 step:14833 [D loss: 0.244477, acc.: 57.81%] [G loss: 0.469731]\n",
      "epoch:15 step:14834 [D loss: 0.233384, acc.: 62.50%] [G loss: 0.406220]\n",
      "epoch:15 step:14835 [D loss: 0.235422, acc.: 62.50%] [G loss: 0.492286]\n",
      "epoch:15 step:14836 [D loss: 0.182507, acc.: 73.44%] [G loss: 0.470265]\n",
      "epoch:15 step:14837 [D loss: 0.175755, acc.: 75.78%] [G loss: 0.481961]\n",
      "epoch:15 step:14838 [D loss: 0.247773, acc.: 57.03%] [G loss: 0.434868]\n",
      "epoch:15 step:14839 [D loss: 0.270172, acc.: 52.34%] [G loss: 0.397896]\n",
      "epoch:15 step:14840 [D loss: 0.248525, acc.: 56.25%] [G loss: 0.396078]\n",
      "epoch:15 step:14841 [D loss: 0.217801, acc.: 60.94%] [G loss: 0.432763]\n",
      "epoch:15 step:14842 [D loss: 0.249735, acc.: 53.12%] [G loss: 0.419839]\n",
      "epoch:15 step:14843 [D loss: 0.243714, acc.: 53.12%] [G loss: 0.456351]\n",
      "epoch:15 step:14844 [D loss: 0.230655, acc.: 62.50%] [G loss: 0.451666]\n",
      "epoch:15 step:14845 [D loss: 0.225947, acc.: 60.16%] [G loss: 0.443420]\n",
      "epoch:15 step:14846 [D loss: 0.277383, acc.: 53.12%] [G loss: 0.400814]\n",
      "epoch:15 step:14847 [D loss: 0.200661, acc.: 68.75%] [G loss: 0.398116]\n",
      "epoch:15 step:14848 [D loss: 0.247268, acc.: 56.25%] [G loss: 0.440644]\n",
      "epoch:15 step:14849 [D loss: 0.250532, acc.: 52.34%] [G loss: 0.452838]\n",
      "epoch:15 step:14850 [D loss: 0.238048, acc.: 59.38%] [G loss: 0.420391]\n",
      "epoch:15 step:14851 [D loss: 0.222782, acc.: 62.50%] [G loss: 0.450317]\n",
      "epoch:15 step:14852 [D loss: 0.250248, acc.: 53.91%] [G loss: 0.429665]\n",
      "epoch:15 step:14853 [D loss: 0.243258, acc.: 58.59%] [G loss: 0.413677]\n",
      "epoch:15 step:14854 [D loss: 0.218485, acc.: 65.62%] [G loss: 0.476656]\n",
      "epoch:15 step:14855 [D loss: 0.264745, acc.: 53.91%] [G loss: 0.431918]\n",
      "epoch:15 step:14856 [D loss: 0.234892, acc.: 54.69%] [G loss: 0.485473]\n",
      "epoch:15 step:14857 [D loss: 0.200470, acc.: 69.53%] [G loss: 0.505668]\n",
      "epoch:15 step:14858 [D loss: 0.211719, acc.: 65.62%] [G loss: 0.434457]\n",
      "epoch:15 step:14859 [D loss: 0.249973, acc.: 58.59%] [G loss: 0.406796]\n",
      "epoch:15 step:14860 [D loss: 0.212875, acc.: 65.62%] [G loss: 0.447364]\n",
      "epoch:15 step:14861 [D loss: 0.241873, acc.: 60.16%] [G loss: 0.432131]\n",
      "epoch:15 step:14862 [D loss: 0.235550, acc.: 60.16%] [G loss: 0.430077]\n",
      "epoch:15 step:14863 [D loss: 0.231108, acc.: 61.72%] [G loss: 0.452373]\n",
      "epoch:15 step:14864 [D loss: 0.246103, acc.: 59.38%] [G loss: 0.448487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14865 [D loss: 0.230874, acc.: 63.28%] [G loss: 0.477018]\n",
      "epoch:15 step:14866 [D loss: 0.238524, acc.: 62.50%] [G loss: 0.473398]\n",
      "epoch:15 step:14867 [D loss: 0.242746, acc.: 60.16%] [G loss: 0.447681]\n",
      "epoch:15 step:14868 [D loss: 0.202217, acc.: 71.09%] [G loss: 0.446025]\n",
      "epoch:15 step:14869 [D loss: 0.228888, acc.: 63.28%] [G loss: 0.412816]\n",
      "epoch:15 step:14870 [D loss: 0.224157, acc.: 67.19%] [G loss: 0.431395]\n",
      "epoch:15 step:14871 [D loss: 0.234733, acc.: 59.38%] [G loss: 0.449371]\n",
      "epoch:15 step:14872 [D loss: 0.265429, acc.: 50.00%] [G loss: 0.445237]\n",
      "epoch:15 step:14873 [D loss: 0.251309, acc.: 57.03%] [G loss: 0.413718]\n",
      "epoch:15 step:14874 [D loss: 0.212022, acc.: 70.31%] [G loss: 0.422585]\n",
      "epoch:15 step:14875 [D loss: 0.255867, acc.: 58.59%] [G loss: 0.413779]\n",
      "epoch:15 step:14876 [D loss: 0.216398, acc.: 63.28%] [G loss: 0.431122]\n",
      "epoch:15 step:14877 [D loss: 0.238403, acc.: 54.69%] [G loss: 0.443772]\n",
      "epoch:15 step:14878 [D loss: 0.212157, acc.: 67.97%] [G loss: 0.440145]\n",
      "epoch:15 step:14879 [D loss: 0.261229, acc.: 53.91%] [G loss: 0.429078]\n",
      "epoch:15 step:14880 [D loss: 0.229885, acc.: 63.28%] [G loss: 0.430190]\n",
      "epoch:15 step:14881 [D loss: 0.214621, acc.: 69.53%] [G loss: 0.452093]\n",
      "epoch:15 step:14882 [D loss: 0.248319, acc.: 54.69%] [G loss: 0.432268]\n",
      "epoch:15 step:14883 [D loss: 0.260298, acc.: 52.34%] [G loss: 0.437555]\n",
      "epoch:15 step:14884 [D loss: 0.231546, acc.: 61.72%] [G loss: 0.432925]\n",
      "epoch:15 step:14885 [D loss: 0.237733, acc.: 59.38%] [G loss: 0.437297]\n",
      "epoch:15 step:14886 [D loss: 0.236007, acc.: 60.94%] [G loss: 0.401862]\n",
      "epoch:15 step:14887 [D loss: 0.241476, acc.: 60.16%] [G loss: 0.432393]\n",
      "epoch:15 step:14888 [D loss: 0.210510, acc.: 66.41%] [G loss: 0.451706]\n",
      "epoch:15 step:14889 [D loss: 0.240845, acc.: 57.03%] [G loss: 0.416899]\n",
      "epoch:15 step:14890 [D loss: 0.217319, acc.: 66.41%] [G loss: 0.425234]\n",
      "epoch:15 step:14891 [D loss: 0.217454, acc.: 62.50%] [G loss: 0.432240]\n",
      "epoch:15 step:14892 [D loss: 0.211496, acc.: 62.50%] [G loss: 0.422937]\n",
      "epoch:15 step:14893 [D loss: 0.234016, acc.: 54.69%] [G loss: 0.414010]\n",
      "epoch:15 step:14894 [D loss: 0.223056, acc.: 66.41%] [G loss: 0.456921]\n",
      "epoch:15 step:14895 [D loss: 0.215492, acc.: 64.06%] [G loss: 0.437530]\n",
      "epoch:15 step:14896 [D loss: 0.247372, acc.: 57.81%] [G loss: 0.412830]\n",
      "epoch:15 step:14897 [D loss: 0.196960, acc.: 73.44%] [G loss: 0.433130]\n",
      "epoch:15 step:14898 [D loss: 0.228506, acc.: 57.81%] [G loss: 0.448412]\n",
      "epoch:15 step:14899 [D loss: 0.250919, acc.: 56.25%] [G loss: 0.412720]\n",
      "epoch:15 step:14900 [D loss: 0.214522, acc.: 64.84%] [G loss: 0.406235]\n",
      "epoch:15 step:14901 [D loss: 0.233266, acc.: 57.81%] [G loss: 0.439920]\n",
      "epoch:15 step:14902 [D loss: 0.234794, acc.: 57.03%] [G loss: 0.434303]\n",
      "epoch:15 step:14903 [D loss: 0.251916, acc.: 51.56%] [G loss: 0.415781]\n",
      "epoch:15 step:14904 [D loss: 0.191149, acc.: 71.09%] [G loss: 0.405896]\n",
      "epoch:15 step:14905 [D loss: 0.242358, acc.: 57.81%] [G loss: 0.441597]\n",
      "epoch:15 step:14906 [D loss: 0.246677, acc.: 53.91%] [G loss: 0.397667]\n",
      "epoch:15 step:14907 [D loss: 0.211867, acc.: 64.06%] [G loss: 0.432421]\n",
      "epoch:15 step:14908 [D loss: 0.220752, acc.: 63.28%] [G loss: 0.460152]\n",
      "epoch:15 step:14909 [D loss: 0.216642, acc.: 64.06%] [G loss: 0.469909]\n",
      "epoch:15 step:14910 [D loss: 0.261315, acc.: 56.25%] [G loss: 0.423974]\n",
      "epoch:15 step:14911 [D loss: 0.246688, acc.: 52.34%] [G loss: 0.398063]\n",
      "epoch:15 step:14912 [D loss: 0.227487, acc.: 58.59%] [G loss: 0.414781]\n",
      "epoch:15 step:14913 [D loss: 0.267353, acc.: 54.69%] [G loss: 0.471476]\n",
      "epoch:15 step:14914 [D loss: 0.237281, acc.: 56.25%] [G loss: 0.430636]\n",
      "epoch:15 step:14915 [D loss: 0.223823, acc.: 60.94%] [G loss: 0.443575]\n",
      "epoch:15 step:14916 [D loss: 0.247345, acc.: 59.38%] [G loss: 0.458654]\n",
      "epoch:15 step:14917 [D loss: 0.244505, acc.: 60.94%] [G loss: 0.445291]\n",
      "epoch:15 step:14918 [D loss: 0.219577, acc.: 63.28%] [G loss: 0.426683]\n",
      "epoch:15 step:14919 [D loss: 0.250258, acc.: 59.38%] [G loss: 0.435575]\n",
      "epoch:15 step:14920 [D loss: 0.246197, acc.: 54.69%] [G loss: 0.385717]\n",
      "epoch:15 step:14921 [D loss: 0.236634, acc.: 59.38%] [G loss: 0.388992]\n",
      "epoch:15 step:14922 [D loss: 0.232935, acc.: 57.81%] [G loss: 0.414742]\n",
      "epoch:15 step:14923 [D loss: 0.232668, acc.: 55.47%] [G loss: 0.405388]\n",
      "epoch:15 step:14924 [D loss: 0.230646, acc.: 63.28%] [G loss: 0.426855]\n",
      "epoch:15 step:14925 [D loss: 0.232509, acc.: 58.59%] [G loss: 0.417385]\n",
      "epoch:15 step:14926 [D loss: 0.202983, acc.: 66.41%] [G loss: 0.423378]\n",
      "epoch:15 step:14927 [D loss: 0.237240, acc.: 60.16%] [G loss: 0.378269]\n",
      "epoch:15 step:14928 [D loss: 0.236081, acc.: 61.72%] [G loss: 0.429543]\n",
      "epoch:15 step:14929 [D loss: 0.225744, acc.: 61.72%] [G loss: 0.459830]\n",
      "epoch:15 step:14930 [D loss: 0.191935, acc.: 74.22%] [G loss: 0.447626]\n",
      "epoch:15 step:14931 [D loss: 0.235296, acc.: 60.16%] [G loss: 0.405385]\n",
      "epoch:15 step:14932 [D loss: 0.241865, acc.: 53.91%] [G loss: 0.415663]\n",
      "epoch:15 step:14933 [D loss: 0.243060, acc.: 57.81%] [G loss: 0.423022]\n",
      "epoch:15 step:14934 [D loss: 0.216597, acc.: 64.84%] [G loss: 0.438239]\n",
      "epoch:15 step:14935 [D loss: 0.249492, acc.: 57.81%] [G loss: 0.426225]\n",
      "epoch:15 step:14936 [D loss: 0.224725, acc.: 63.28%] [G loss: 0.409862]\n",
      "epoch:15 step:14937 [D loss: 0.220516, acc.: 62.50%] [G loss: 0.396248]\n",
      "epoch:15 step:14938 [D loss: 0.242018, acc.: 57.81%] [G loss: 0.410162]\n",
      "epoch:15 step:14939 [D loss: 0.194393, acc.: 72.66%] [G loss: 0.467689]\n",
      "epoch:15 step:14940 [D loss: 0.244368, acc.: 59.38%] [G loss: 0.436196]\n",
      "epoch:15 step:14941 [D loss: 0.214522, acc.: 67.19%] [G loss: 0.444573]\n",
      "epoch:15 step:14942 [D loss: 0.210423, acc.: 63.28%] [G loss: 0.475434]\n",
      "epoch:15 step:14943 [D loss: 0.216672, acc.: 60.94%] [G loss: 0.436965]\n",
      "epoch:15 step:14944 [D loss: 0.199966, acc.: 70.31%] [G loss: 0.481251]\n",
      "epoch:15 step:14945 [D loss: 0.212823, acc.: 64.06%] [G loss: 0.424352]\n",
      "epoch:15 step:14946 [D loss: 0.270504, acc.: 48.44%] [G loss: 0.410892]\n",
      "epoch:15 step:14947 [D loss: 0.266139, acc.: 50.78%] [G loss: 0.408847]\n",
      "epoch:15 step:14948 [D loss: 0.211467, acc.: 67.97%] [G loss: 0.425124]\n",
      "epoch:15 step:14949 [D loss: 0.197314, acc.: 74.22%] [G loss: 0.453778]\n",
      "epoch:15 step:14950 [D loss: 0.224721, acc.: 62.50%] [G loss: 0.467387]\n",
      "epoch:15 step:14951 [D loss: 0.207352, acc.: 66.41%] [G loss: 0.474093]\n",
      "epoch:15 step:14952 [D loss: 0.190596, acc.: 67.97%] [G loss: 0.461600]\n",
      "epoch:15 step:14953 [D loss: 0.214419, acc.: 71.88%] [G loss: 0.453148]\n",
      "epoch:15 step:14954 [D loss: 0.189175, acc.: 73.44%] [G loss: 0.471061]\n",
      "epoch:15 step:14955 [D loss: 0.211153, acc.: 66.41%] [G loss: 0.477021]\n",
      "epoch:15 step:14956 [D loss: 0.219536, acc.: 65.62%] [G loss: 0.441188]\n",
      "epoch:15 step:14957 [D loss: 0.254314, acc.: 53.91%] [G loss: 0.395865]\n",
      "epoch:15 step:14958 [D loss: 0.224646, acc.: 61.72%] [G loss: 0.441697]\n",
      "epoch:15 step:14959 [D loss: 0.210366, acc.: 63.28%] [G loss: 0.423100]\n",
      "epoch:15 step:14960 [D loss: 0.220472, acc.: 65.62%] [G loss: 0.480930]\n",
      "epoch:15 step:14961 [D loss: 0.213977, acc.: 70.31%] [G loss: 0.492405]\n",
      "epoch:15 step:14962 [D loss: 0.230483, acc.: 63.28%] [G loss: 0.446648]\n",
      "epoch:15 step:14963 [D loss: 0.231115, acc.: 67.19%] [G loss: 0.417947]\n",
      "epoch:15 step:14964 [D loss: 0.204784, acc.: 70.31%] [G loss: 0.433539]\n",
      "epoch:15 step:14965 [D loss: 0.228084, acc.: 59.38%] [G loss: 0.436547]\n",
      "epoch:15 step:14966 [D loss: 0.210538, acc.: 65.62%] [G loss: 0.442776]\n",
      "epoch:15 step:14967 [D loss: 0.221168, acc.: 61.72%] [G loss: 0.452947]\n",
      "epoch:15 step:14968 [D loss: 0.215546, acc.: 64.84%] [G loss: 0.453905]\n",
      "epoch:15 step:14969 [D loss: 0.238736, acc.: 61.72%] [G loss: 0.446973]\n",
      "epoch:15 step:14970 [D loss: 0.312673, acc.: 46.88%] [G loss: 0.409105]\n",
      "epoch:15 step:14971 [D loss: 0.266089, acc.: 53.91%] [G loss: 0.396050]\n",
      "epoch:15 step:14972 [D loss: 0.228220, acc.: 60.16%] [G loss: 0.420849]\n",
      "epoch:15 step:14973 [D loss: 0.196922, acc.: 71.09%] [G loss: 0.441370]\n",
      "epoch:15 step:14974 [D loss: 0.193720, acc.: 68.75%] [G loss: 0.474730]\n",
      "epoch:15 step:14975 [D loss: 0.289142, acc.: 45.31%] [G loss: 0.407566]\n",
      "epoch:15 step:14976 [D loss: 0.208724, acc.: 67.19%] [G loss: 0.493497]\n",
      "epoch:15 step:14977 [D loss: 0.240139, acc.: 60.94%] [G loss: 0.446959]\n",
      "epoch:15 step:14978 [D loss: 0.215527, acc.: 60.94%] [G loss: 0.433794]\n",
      "epoch:15 step:14979 [D loss: 0.170161, acc.: 74.22%] [G loss: 0.474686]\n",
      "epoch:15 step:14980 [D loss: 0.168420, acc.: 76.56%] [G loss: 0.475996]\n",
      "epoch:15 step:14981 [D loss: 0.184920, acc.: 72.66%] [G loss: 0.534341]\n",
      "epoch:15 step:14982 [D loss: 0.165868, acc.: 76.56%] [G loss: 0.545740]\n",
      "epoch:15 step:14983 [D loss: 0.377842, acc.: 45.31%] [G loss: 0.492999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14984 [D loss: 0.209618, acc.: 67.97%] [G loss: 0.587619]\n",
      "epoch:15 step:14985 [D loss: 0.226687, acc.: 66.41%] [G loss: 0.522446]\n",
      "epoch:15 step:14986 [D loss: 0.257834, acc.: 53.12%] [G loss: 0.426597]\n",
      "epoch:15 step:14987 [D loss: 0.265307, acc.: 53.91%] [G loss: 0.394328]\n",
      "epoch:15 step:14988 [D loss: 0.241073, acc.: 59.38%] [G loss: 0.412616]\n",
      "epoch:15 step:14989 [D loss: 0.231804, acc.: 62.50%] [G loss: 0.433578]\n",
      "epoch:15 step:14990 [D loss: 0.196731, acc.: 72.66%] [G loss: 0.495200]\n",
      "epoch:15 step:14991 [D loss: 0.177547, acc.: 75.00%] [G loss: 0.535809]\n",
      "epoch:15 step:14992 [D loss: 0.211104, acc.: 66.41%] [G loss: 0.504280]\n",
      "epoch:16 step:14993 [D loss: 0.230341, acc.: 63.28%] [G loss: 0.490946]\n",
      "epoch:16 step:14994 [D loss: 0.266692, acc.: 57.03%] [G loss: 0.456088]\n",
      "epoch:16 step:14995 [D loss: 0.229366, acc.: 61.72%] [G loss: 0.439320]\n",
      "epoch:16 step:14996 [D loss: 0.247065, acc.: 59.38%] [G loss: 0.437245]\n",
      "epoch:16 step:14997 [D loss: 0.217702, acc.: 61.72%] [G loss: 0.469177]\n",
      "epoch:16 step:14998 [D loss: 0.237008, acc.: 61.72%] [G loss: 0.458220]\n",
      "epoch:16 step:14999 [D loss: 0.201721, acc.: 68.75%] [G loss: 0.477042]\n",
      "epoch:16 step:15000 [D loss: 0.229203, acc.: 64.06%] [G loss: 0.454803]\n",
      "epoch:16 step:15001 [D loss: 0.201352, acc.: 71.09%] [G loss: 0.459003]\n",
      "epoch:16 step:15002 [D loss: 0.221014, acc.: 60.94%] [G loss: 0.474151]\n",
      "epoch:16 step:15003 [D loss: 0.194578, acc.: 69.53%] [G loss: 0.447357]\n",
      "epoch:16 step:15004 [D loss: 0.233967, acc.: 62.50%] [G loss: 0.433574]\n",
      "epoch:16 step:15005 [D loss: 0.202634, acc.: 66.41%] [G loss: 0.506196]\n",
      "epoch:16 step:15006 [D loss: 0.202310, acc.: 70.31%] [G loss: 0.459677]\n",
      "epoch:16 step:15007 [D loss: 0.189888, acc.: 71.09%] [G loss: 0.505644]\n",
      "epoch:16 step:15008 [D loss: 0.224637, acc.: 59.38%] [G loss: 0.495577]\n",
      "epoch:16 step:15009 [D loss: 0.243473, acc.: 59.38%] [G loss: 0.523940]\n",
      "epoch:16 step:15010 [D loss: 0.230982, acc.: 65.62%] [G loss: 0.484256]\n",
      "epoch:16 step:15011 [D loss: 0.278331, acc.: 57.03%] [G loss: 0.430400]\n",
      "epoch:16 step:15012 [D loss: 0.255072, acc.: 56.25%] [G loss: 0.451527]\n",
      "epoch:16 step:15013 [D loss: 0.247638, acc.: 57.03%] [G loss: 0.469855]\n",
      "epoch:16 step:15014 [D loss: 0.184852, acc.: 71.09%] [G loss: 0.500756]\n",
      "epoch:16 step:15015 [D loss: 0.288085, acc.: 48.44%] [G loss: 0.396350]\n",
      "epoch:16 step:15016 [D loss: 0.196533, acc.: 71.88%] [G loss: 0.430028]\n",
      "epoch:16 step:15017 [D loss: 0.195081, acc.: 71.88%] [G loss: 0.448341]\n",
      "epoch:16 step:15018 [D loss: 0.238372, acc.: 55.47%] [G loss: 0.426669]\n",
      "epoch:16 step:15019 [D loss: 0.251246, acc.: 49.22%] [G loss: 0.410937]\n",
      "epoch:16 step:15020 [D loss: 0.230735, acc.: 58.59%] [G loss: 0.408033]\n",
      "epoch:16 step:15021 [D loss: 0.219414, acc.: 62.50%] [G loss: 0.433822]\n",
      "epoch:16 step:15022 [D loss: 0.240478, acc.: 58.59%] [G loss: 0.413598]\n",
      "epoch:16 step:15023 [D loss: 0.247845, acc.: 54.69%] [G loss: 0.397065]\n",
      "epoch:16 step:15024 [D loss: 0.215910, acc.: 67.19%] [G loss: 0.433299]\n",
      "epoch:16 step:15025 [D loss: 0.230515, acc.: 57.03%] [G loss: 0.428801]\n",
      "epoch:16 step:15026 [D loss: 0.228351, acc.: 63.28%] [G loss: 0.383122]\n",
      "epoch:16 step:15027 [D loss: 0.240727, acc.: 55.47%] [G loss: 0.421003]\n",
      "epoch:16 step:15028 [D loss: 0.214236, acc.: 64.84%] [G loss: 0.434428]\n",
      "epoch:16 step:15029 [D loss: 0.233368, acc.: 58.59%] [G loss: 0.429634]\n",
      "epoch:16 step:15030 [D loss: 0.255875, acc.: 56.25%] [G loss: 0.407971]\n",
      "epoch:16 step:15031 [D loss: 0.236952, acc.: 59.38%] [G loss: 0.402084]\n",
      "epoch:16 step:15032 [D loss: 0.203437, acc.: 68.75%] [G loss: 0.450009]\n",
      "epoch:16 step:15033 [D loss: 0.253856, acc.: 56.25%] [G loss: 0.464864]\n",
      "epoch:16 step:15034 [D loss: 0.213366, acc.: 67.97%] [G loss: 0.402597]\n",
      "epoch:16 step:15035 [D loss: 0.216753, acc.: 63.28%] [G loss: 0.423395]\n",
      "epoch:16 step:15036 [D loss: 0.231514, acc.: 57.81%] [G loss: 0.416634]\n",
      "epoch:16 step:15037 [D loss: 0.219967, acc.: 63.28%] [G loss: 0.426228]\n",
      "epoch:16 step:15038 [D loss: 0.255776, acc.: 51.56%] [G loss: 0.401399]\n",
      "epoch:16 step:15039 [D loss: 0.207182, acc.: 64.84%] [G loss: 0.434943]\n",
      "epoch:16 step:15040 [D loss: 0.220836, acc.: 66.41%] [G loss: 0.420758]\n",
      "epoch:16 step:15041 [D loss: 0.203667, acc.: 67.19%] [G loss: 0.441644]\n",
      "epoch:16 step:15042 [D loss: 0.225492, acc.: 60.94%] [G loss: 0.464937]\n",
      "epoch:16 step:15043 [D loss: 0.233681, acc.: 60.16%] [G loss: 0.432889]\n",
      "epoch:16 step:15044 [D loss: 0.226287, acc.: 54.69%] [G loss: 0.415641]\n",
      "epoch:16 step:15045 [D loss: 0.211496, acc.: 66.41%] [G loss: 0.476313]\n",
      "epoch:16 step:15046 [D loss: 0.220232, acc.: 62.50%] [G loss: 0.458673]\n",
      "epoch:16 step:15047 [D loss: 0.221551, acc.: 60.94%] [G loss: 0.487784]\n",
      "epoch:16 step:15048 [D loss: 0.226729, acc.: 60.16%] [G loss: 0.474616]\n",
      "epoch:16 step:15049 [D loss: 0.232671, acc.: 57.03%] [G loss: 0.448344]\n",
      "epoch:16 step:15050 [D loss: 0.224774, acc.: 64.06%] [G loss: 0.425477]\n",
      "epoch:16 step:15051 [D loss: 0.204860, acc.: 67.19%] [G loss: 0.456757]\n",
      "epoch:16 step:15052 [D loss: 0.233662, acc.: 53.91%] [G loss: 0.440583]\n",
      "epoch:16 step:15053 [D loss: 0.226490, acc.: 58.59%] [G loss: 0.436675]\n",
      "epoch:16 step:15054 [D loss: 0.231249, acc.: 59.38%] [G loss: 0.394437]\n",
      "epoch:16 step:15055 [D loss: 0.232330, acc.: 62.50%] [G loss: 0.404774]\n",
      "epoch:16 step:15056 [D loss: 0.224904, acc.: 62.50%] [G loss: 0.414594]\n",
      "epoch:16 step:15057 [D loss: 0.234415, acc.: 64.06%] [G loss: 0.404291]\n",
      "epoch:16 step:15058 [D loss: 0.236746, acc.: 57.81%] [G loss: 0.435905]\n",
      "epoch:16 step:15059 [D loss: 0.213566, acc.: 66.41%] [G loss: 0.460714]\n",
      "epoch:16 step:15060 [D loss: 0.218761, acc.: 64.84%] [G loss: 0.440391]\n",
      "epoch:16 step:15061 [D loss: 0.192136, acc.: 71.88%] [G loss: 0.454817]\n",
      "epoch:16 step:15062 [D loss: 0.216585, acc.: 67.19%] [G loss: 0.444861]\n",
      "epoch:16 step:15063 [D loss: 0.240686, acc.: 56.25%] [G loss: 0.459930]\n",
      "epoch:16 step:15064 [D loss: 0.234557, acc.: 58.59%] [G loss: 0.391560]\n",
      "epoch:16 step:15065 [D loss: 0.228028, acc.: 59.38%] [G loss: 0.440666]\n",
      "epoch:16 step:15066 [D loss: 0.203104, acc.: 71.88%] [G loss: 0.450945]\n",
      "epoch:16 step:15067 [D loss: 0.197563, acc.: 66.41%] [G loss: 0.459943]\n",
      "epoch:16 step:15068 [D loss: 0.172318, acc.: 73.44%] [G loss: 0.521320]\n",
      "epoch:16 step:15069 [D loss: 0.202471, acc.: 65.62%] [G loss: 0.489129]\n",
      "epoch:16 step:15070 [D loss: 0.278128, acc.: 50.00%] [G loss: 0.409199]\n",
      "epoch:16 step:15071 [D loss: 0.226233, acc.: 58.59%] [G loss: 0.425209]\n",
      "epoch:16 step:15072 [D loss: 0.240492, acc.: 64.84%] [G loss: 0.438234]\n",
      "epoch:16 step:15073 [D loss: 0.221552, acc.: 65.62%] [G loss: 0.454728]\n",
      "epoch:16 step:15074 [D loss: 0.205496, acc.: 71.09%] [G loss: 0.495332]\n",
      "epoch:16 step:15075 [D loss: 0.216797, acc.: 65.62%] [G loss: 0.477459]\n",
      "epoch:16 step:15076 [D loss: 0.209585, acc.: 64.84%] [G loss: 0.451451]\n",
      "epoch:16 step:15077 [D loss: 0.246279, acc.: 59.38%] [G loss: 0.471660]\n",
      "epoch:16 step:15078 [D loss: 0.230047, acc.: 64.06%] [G loss: 0.477283]\n",
      "epoch:16 step:15079 [D loss: 0.220489, acc.: 62.50%] [G loss: 0.428134]\n",
      "epoch:16 step:15080 [D loss: 0.223310, acc.: 61.72%] [G loss: 0.443408]\n",
      "epoch:16 step:15081 [D loss: 0.205648, acc.: 67.19%] [G loss: 0.437353]\n",
      "epoch:16 step:15082 [D loss: 0.202749, acc.: 69.53%] [G loss: 0.433511]\n",
      "epoch:16 step:15083 [D loss: 0.224043, acc.: 66.41%] [G loss: 0.434830]\n",
      "epoch:16 step:15084 [D loss: 0.224495, acc.: 65.62%] [G loss: 0.446027]\n",
      "epoch:16 step:15085 [D loss: 0.189439, acc.: 70.31%] [G loss: 0.453761]\n",
      "epoch:16 step:15086 [D loss: 0.242965, acc.: 61.72%] [G loss: 0.441158]\n",
      "epoch:16 step:15087 [D loss: 0.228761, acc.: 65.62%] [G loss: 0.474162]\n",
      "epoch:16 step:15088 [D loss: 0.217864, acc.: 66.41%] [G loss: 0.476862]\n",
      "epoch:16 step:15089 [D loss: 0.195004, acc.: 70.31%] [G loss: 0.503220]\n",
      "epoch:16 step:15090 [D loss: 0.270853, acc.: 49.22%] [G loss: 0.423761]\n",
      "epoch:16 step:15091 [D loss: 0.270734, acc.: 53.91%] [G loss: 0.446398]\n",
      "epoch:16 step:15092 [D loss: 0.200279, acc.: 72.66%] [G loss: 0.468745]\n",
      "epoch:16 step:15093 [D loss: 0.207860, acc.: 66.41%] [G loss: 0.489466]\n",
      "epoch:16 step:15094 [D loss: 0.224291, acc.: 64.84%] [G loss: 0.433527]\n",
      "epoch:16 step:15095 [D loss: 0.264358, acc.: 53.12%] [G loss: 0.426780]\n",
      "epoch:16 step:15096 [D loss: 0.232784, acc.: 54.69%] [G loss: 0.397161]\n",
      "epoch:16 step:15097 [D loss: 0.230569, acc.: 57.81%] [G loss: 0.424647]\n",
      "epoch:16 step:15098 [D loss: 0.202508, acc.: 72.66%] [G loss: 0.469211]\n",
      "epoch:16 step:15099 [D loss: 0.192199, acc.: 71.88%] [G loss: 0.476972]\n",
      "epoch:16 step:15100 [D loss: 0.280220, acc.: 49.22%] [G loss: 0.446351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15101 [D loss: 0.301029, acc.: 37.50%] [G loss: 0.363693]\n",
      "epoch:16 step:15102 [D loss: 0.236758, acc.: 58.59%] [G loss: 0.442376]\n",
      "epoch:16 step:15103 [D loss: 0.195589, acc.: 67.19%] [G loss: 0.434036]\n",
      "epoch:16 step:15104 [D loss: 0.210609, acc.: 64.84%] [G loss: 0.445893]\n",
      "epoch:16 step:15105 [D loss: 0.196970, acc.: 72.66%] [G loss: 0.456430]\n",
      "epoch:16 step:15106 [D loss: 0.209318, acc.: 72.66%] [G loss: 0.509974]\n",
      "epoch:16 step:15107 [D loss: 0.225424, acc.: 65.62%] [G loss: 0.498507]\n",
      "epoch:16 step:15108 [D loss: 0.207406, acc.: 69.53%] [G loss: 0.474733]\n",
      "epoch:16 step:15109 [D loss: 0.204256, acc.: 64.06%] [G loss: 0.470746]\n",
      "epoch:16 step:15110 [D loss: 0.193234, acc.: 72.66%] [G loss: 0.450271]\n",
      "epoch:16 step:15111 [D loss: 0.184645, acc.: 73.44%] [G loss: 0.535103]\n",
      "epoch:16 step:15112 [D loss: 0.234670, acc.: 64.06%] [G loss: 0.509729]\n",
      "epoch:16 step:15113 [D loss: 0.248149, acc.: 58.59%] [G loss: 0.446710]\n",
      "epoch:16 step:15114 [D loss: 0.191646, acc.: 70.31%] [G loss: 0.490074]\n",
      "epoch:16 step:15115 [D loss: 0.201092, acc.: 66.41%] [G loss: 0.479994]\n",
      "epoch:16 step:15116 [D loss: 0.227842, acc.: 60.16%] [G loss: 0.493403]\n",
      "epoch:16 step:15117 [D loss: 0.248368, acc.: 54.69%] [G loss: 0.427864]\n",
      "epoch:16 step:15118 [D loss: 0.186470, acc.: 71.09%] [G loss: 0.478287]\n",
      "epoch:16 step:15119 [D loss: 0.201594, acc.: 70.31%] [G loss: 0.489489]\n",
      "epoch:16 step:15120 [D loss: 0.235052, acc.: 61.72%] [G loss: 0.450082]\n",
      "epoch:16 step:15121 [D loss: 0.227552, acc.: 61.72%] [G loss: 0.407604]\n",
      "epoch:16 step:15122 [D loss: 0.206735, acc.: 67.97%] [G loss: 0.422664]\n",
      "epoch:16 step:15123 [D loss: 0.227175, acc.: 64.84%] [G loss: 0.435292]\n",
      "epoch:16 step:15124 [D loss: 0.232274, acc.: 60.16%] [G loss: 0.436276]\n",
      "epoch:16 step:15125 [D loss: 0.235076, acc.: 56.25%] [G loss: 0.491227]\n",
      "epoch:16 step:15126 [D loss: 0.228700, acc.: 65.62%] [G loss: 0.458479]\n",
      "epoch:16 step:15127 [D loss: 0.224540, acc.: 67.19%] [G loss: 0.473506]\n",
      "epoch:16 step:15128 [D loss: 0.229192, acc.: 57.03%] [G loss: 0.452236]\n",
      "epoch:16 step:15129 [D loss: 0.241274, acc.: 57.81%] [G loss: 0.396655]\n",
      "epoch:16 step:15130 [D loss: 0.267571, acc.: 52.34%] [G loss: 0.402498]\n",
      "epoch:16 step:15131 [D loss: 0.224549, acc.: 63.28%] [G loss: 0.406931]\n",
      "epoch:16 step:15132 [D loss: 0.234838, acc.: 57.81%] [G loss: 0.399722]\n",
      "epoch:16 step:15133 [D loss: 0.243574, acc.: 51.56%] [G loss: 0.445080]\n",
      "epoch:16 step:15134 [D loss: 0.236918, acc.: 62.50%] [G loss: 0.428105]\n",
      "epoch:16 step:15135 [D loss: 0.220073, acc.: 60.94%] [G loss: 0.418881]\n",
      "epoch:16 step:15136 [D loss: 0.202546, acc.: 67.97%] [G loss: 0.421187]\n",
      "epoch:16 step:15137 [D loss: 0.205819, acc.: 63.28%] [G loss: 0.513421]\n",
      "epoch:16 step:15138 [D loss: 0.230242, acc.: 61.72%] [G loss: 0.478967]\n",
      "epoch:16 step:15139 [D loss: 0.238593, acc.: 61.72%] [G loss: 0.445986]\n",
      "epoch:16 step:15140 [D loss: 0.251695, acc.: 56.25%] [G loss: 0.431334]\n",
      "epoch:16 step:15141 [D loss: 0.208840, acc.: 65.62%] [G loss: 0.437032]\n",
      "epoch:16 step:15142 [D loss: 0.259592, acc.: 53.91%] [G loss: 0.412006]\n",
      "epoch:16 step:15143 [D loss: 0.192479, acc.: 73.44%] [G loss: 0.460797]\n",
      "epoch:16 step:15144 [D loss: 0.224694, acc.: 64.06%] [G loss: 0.449316]\n",
      "epoch:16 step:15145 [D loss: 0.243649, acc.: 58.59%] [G loss: 0.453164]\n",
      "epoch:16 step:15146 [D loss: 0.214460, acc.: 66.41%] [G loss: 0.448139]\n",
      "epoch:16 step:15147 [D loss: 0.197641, acc.: 67.97%] [G loss: 0.474314]\n",
      "epoch:16 step:15148 [D loss: 0.212671, acc.: 67.97%] [G loss: 0.470245]\n",
      "epoch:16 step:15149 [D loss: 0.235480, acc.: 60.94%] [G loss: 0.456737]\n",
      "epoch:16 step:15150 [D loss: 0.249304, acc.: 55.47%] [G loss: 0.406948]\n",
      "epoch:16 step:15151 [D loss: 0.203447, acc.: 66.41%] [G loss: 0.453285]\n",
      "epoch:16 step:15152 [D loss: 0.280109, acc.: 49.22%] [G loss: 0.421064]\n",
      "epoch:16 step:15153 [D loss: 0.239582, acc.: 57.81%] [G loss: 0.458523]\n",
      "epoch:16 step:15154 [D loss: 0.228243, acc.: 64.84%] [G loss: 0.420531]\n",
      "epoch:16 step:15155 [D loss: 0.220736, acc.: 59.38%] [G loss: 0.446243]\n",
      "epoch:16 step:15156 [D loss: 0.237003, acc.: 63.28%] [G loss: 0.417218]\n",
      "epoch:16 step:15157 [D loss: 0.222634, acc.: 65.62%] [G loss: 0.463000]\n",
      "epoch:16 step:15158 [D loss: 0.215318, acc.: 62.50%] [G loss: 0.422030]\n",
      "epoch:16 step:15159 [D loss: 0.227561, acc.: 57.81%] [G loss: 0.400022]\n",
      "epoch:16 step:15160 [D loss: 0.224457, acc.: 66.41%] [G loss: 0.410481]\n",
      "epoch:16 step:15161 [D loss: 0.256684, acc.: 53.91%] [G loss: 0.415447]\n",
      "epoch:16 step:15162 [D loss: 0.242148, acc.: 59.38%] [G loss: 0.418630]\n",
      "epoch:16 step:15163 [D loss: 0.217067, acc.: 64.06%] [G loss: 0.399079]\n",
      "epoch:16 step:15164 [D loss: 0.232952, acc.: 55.47%] [G loss: 0.386761]\n",
      "epoch:16 step:15165 [D loss: 0.225714, acc.: 59.38%] [G loss: 0.392899]\n",
      "epoch:16 step:15166 [D loss: 0.230840, acc.: 62.50%] [G loss: 0.407994]\n",
      "epoch:16 step:15167 [D loss: 0.255866, acc.: 47.66%] [G loss: 0.408961]\n",
      "epoch:16 step:15168 [D loss: 0.208246, acc.: 67.97%] [G loss: 0.408512]\n",
      "epoch:16 step:15169 [D loss: 0.243558, acc.: 60.94%] [G loss: 0.382140]\n",
      "epoch:16 step:15170 [D loss: 0.231099, acc.: 62.50%] [G loss: 0.411090]\n",
      "epoch:16 step:15171 [D loss: 0.243452, acc.: 60.94%] [G loss: 0.439131]\n",
      "epoch:16 step:15172 [D loss: 0.229264, acc.: 60.16%] [G loss: 0.410025]\n",
      "epoch:16 step:15173 [D loss: 0.237989, acc.: 53.91%] [G loss: 0.421274]\n",
      "epoch:16 step:15174 [D loss: 0.236529, acc.: 58.59%] [G loss: 0.441381]\n",
      "epoch:16 step:15175 [D loss: 0.225407, acc.: 65.62%] [G loss: 0.446875]\n",
      "epoch:16 step:15176 [D loss: 0.220939, acc.: 60.16%] [G loss: 0.429856]\n",
      "epoch:16 step:15177 [D loss: 0.231521, acc.: 61.72%] [G loss: 0.408256]\n",
      "epoch:16 step:15178 [D loss: 0.218576, acc.: 65.62%] [G loss: 0.462604]\n",
      "epoch:16 step:15179 [D loss: 0.233010, acc.: 60.94%] [G loss: 0.445790]\n",
      "epoch:16 step:15180 [D loss: 0.219726, acc.: 64.06%] [G loss: 0.437032]\n",
      "epoch:16 step:15181 [D loss: 0.268938, acc.: 54.69%] [G loss: 0.400639]\n",
      "epoch:16 step:15182 [D loss: 0.214157, acc.: 67.19%] [G loss: 0.460258]\n",
      "epoch:16 step:15183 [D loss: 0.201675, acc.: 67.19%] [G loss: 0.445967]\n",
      "epoch:16 step:15184 [D loss: 0.239944, acc.: 60.16%] [G loss: 0.390715]\n",
      "epoch:16 step:15185 [D loss: 0.217598, acc.: 62.50%] [G loss: 0.425068]\n",
      "epoch:16 step:15186 [D loss: 0.201223, acc.: 67.97%] [G loss: 0.429711]\n",
      "epoch:16 step:15187 [D loss: 0.235118, acc.: 60.94%] [G loss: 0.432061]\n",
      "epoch:16 step:15188 [D loss: 0.238430, acc.: 57.03%] [G loss: 0.439139]\n",
      "epoch:16 step:15189 [D loss: 0.215217, acc.: 63.28%] [G loss: 0.455774]\n",
      "epoch:16 step:15190 [D loss: 0.207087, acc.: 72.66%] [G loss: 0.449607]\n",
      "epoch:16 step:15191 [D loss: 0.245593, acc.: 57.81%] [G loss: 0.449166]\n",
      "epoch:16 step:15192 [D loss: 0.255804, acc.: 55.47%] [G loss: 0.431420]\n",
      "epoch:16 step:15193 [D loss: 0.256448, acc.: 55.47%] [G loss: 0.413597]\n",
      "epoch:16 step:15194 [D loss: 0.225266, acc.: 64.06%] [G loss: 0.428782]\n",
      "epoch:16 step:15195 [D loss: 0.263843, acc.: 51.56%] [G loss: 0.436234]\n",
      "epoch:16 step:15196 [D loss: 0.233955, acc.: 59.38%] [G loss: 0.428815]\n",
      "epoch:16 step:15197 [D loss: 0.214041, acc.: 67.19%] [G loss: 0.532885]\n",
      "epoch:16 step:15198 [D loss: 0.217952, acc.: 63.28%] [G loss: 0.485999]\n",
      "epoch:16 step:15199 [D loss: 0.193023, acc.: 71.88%] [G loss: 0.437185]\n",
      "epoch:16 step:15200 [D loss: 0.190488, acc.: 70.31%] [G loss: 0.452523]\n",
      "epoch:16 step:15201 [D loss: 0.195978, acc.: 65.62%] [G loss: 0.498398]\n",
      "epoch:16 step:15202 [D loss: 0.259006, acc.: 59.38%] [G loss: 0.430250]\n",
      "epoch:16 step:15203 [D loss: 0.256434, acc.: 57.03%] [G loss: 0.420025]\n",
      "epoch:16 step:15204 [D loss: 0.252545, acc.: 58.59%] [G loss: 0.432571]\n",
      "epoch:16 step:15205 [D loss: 0.222667, acc.: 60.94%] [G loss: 0.442036]\n",
      "epoch:16 step:15206 [D loss: 0.254027, acc.: 56.25%] [G loss: 0.445463]\n",
      "epoch:16 step:15207 [D loss: 0.257267, acc.: 59.38%] [G loss: 0.375624]\n",
      "epoch:16 step:15208 [D loss: 0.204051, acc.: 66.41%] [G loss: 0.441149]\n",
      "epoch:16 step:15209 [D loss: 0.238290, acc.: 61.72%] [G loss: 0.454597]\n",
      "epoch:16 step:15210 [D loss: 0.199049, acc.: 71.09%] [G loss: 0.489023]\n",
      "epoch:16 step:15211 [D loss: 0.191843, acc.: 71.88%] [G loss: 0.520068]\n",
      "epoch:16 step:15212 [D loss: 0.273116, acc.: 53.12%] [G loss: 0.462207]\n",
      "epoch:16 step:15213 [D loss: 0.217846, acc.: 60.94%] [G loss: 0.474785]\n",
      "epoch:16 step:15214 [D loss: 0.222286, acc.: 64.06%] [G loss: 0.459786]\n",
      "epoch:16 step:15215 [D loss: 0.197077, acc.: 68.75%] [G loss: 0.481070]\n",
      "epoch:16 step:15216 [D loss: 0.243559, acc.: 59.38%] [G loss: 0.432533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15217 [D loss: 0.241480, acc.: 58.59%] [G loss: 0.433865]\n",
      "epoch:16 step:15218 [D loss: 0.239305, acc.: 62.50%] [G loss: 0.427526]\n",
      "epoch:16 step:15219 [D loss: 0.213499, acc.: 68.75%] [G loss: 0.412068]\n",
      "epoch:16 step:15220 [D loss: 0.225743, acc.: 64.06%] [G loss: 0.392707]\n",
      "epoch:16 step:15221 [D loss: 0.202068, acc.: 67.97%] [G loss: 0.443236]\n",
      "epoch:16 step:15222 [D loss: 0.199520, acc.: 72.66%] [G loss: 0.422258]\n",
      "epoch:16 step:15223 [D loss: 0.159548, acc.: 78.91%] [G loss: 0.483191]\n",
      "epoch:16 step:15224 [D loss: 0.168000, acc.: 78.12%] [G loss: 0.538036]\n",
      "epoch:16 step:15225 [D loss: 0.261449, acc.: 55.47%] [G loss: 0.445784]\n",
      "epoch:16 step:15226 [D loss: 0.280680, acc.: 50.78%] [G loss: 0.387997]\n",
      "epoch:16 step:15227 [D loss: 0.228994, acc.: 60.94%] [G loss: 0.438900]\n",
      "epoch:16 step:15228 [D loss: 0.231751, acc.: 60.94%] [G loss: 0.412809]\n",
      "epoch:16 step:15229 [D loss: 0.228320, acc.: 63.28%] [G loss: 0.410454]\n",
      "epoch:16 step:15230 [D loss: 0.207255, acc.: 73.44%] [G loss: 0.428270]\n",
      "epoch:16 step:15231 [D loss: 0.215758, acc.: 63.28%] [G loss: 0.404958]\n",
      "epoch:16 step:15232 [D loss: 0.230177, acc.: 57.81%] [G loss: 0.467896]\n",
      "epoch:16 step:15233 [D loss: 0.180363, acc.: 74.22%] [G loss: 0.521097]\n",
      "epoch:16 step:15234 [D loss: 0.216375, acc.: 66.41%] [G loss: 0.480239]\n",
      "epoch:16 step:15235 [D loss: 0.230304, acc.: 62.50%] [G loss: 0.466957]\n",
      "epoch:16 step:15236 [D loss: 0.205921, acc.: 70.31%] [G loss: 0.493914]\n",
      "epoch:16 step:15237 [D loss: 0.211585, acc.: 66.41%] [G loss: 0.482511]\n",
      "epoch:16 step:15238 [D loss: 0.214766, acc.: 64.84%] [G loss: 0.481465]\n",
      "epoch:16 step:15239 [D loss: 0.218596, acc.: 61.72%] [G loss: 0.467888]\n",
      "epoch:16 step:15240 [D loss: 0.222296, acc.: 66.41%] [G loss: 0.500592]\n",
      "epoch:16 step:15241 [D loss: 0.252135, acc.: 51.56%] [G loss: 0.415482]\n",
      "epoch:16 step:15242 [D loss: 0.237349, acc.: 56.25%] [G loss: 0.424294]\n",
      "epoch:16 step:15243 [D loss: 0.245327, acc.: 55.47%] [G loss: 0.411245]\n",
      "epoch:16 step:15244 [D loss: 0.234086, acc.: 60.16%] [G loss: 0.415527]\n",
      "epoch:16 step:15245 [D loss: 0.197421, acc.: 71.09%] [G loss: 0.453651]\n",
      "epoch:16 step:15246 [D loss: 0.237319, acc.: 57.03%] [G loss: 0.440634]\n",
      "epoch:16 step:15247 [D loss: 0.217176, acc.: 63.28%] [G loss: 0.406287]\n",
      "epoch:16 step:15248 [D loss: 0.216326, acc.: 64.84%] [G loss: 0.453011]\n",
      "epoch:16 step:15249 [D loss: 0.229656, acc.: 61.72%] [G loss: 0.425508]\n",
      "epoch:16 step:15250 [D loss: 0.206983, acc.: 67.97%] [G loss: 0.445616]\n",
      "epoch:16 step:15251 [D loss: 0.235889, acc.: 56.25%] [G loss: 0.424456]\n",
      "epoch:16 step:15252 [D loss: 0.248609, acc.: 54.69%] [G loss: 0.442048]\n",
      "epoch:16 step:15253 [D loss: 0.227428, acc.: 60.16%] [G loss: 0.447262]\n",
      "epoch:16 step:15254 [D loss: 0.213899, acc.: 61.72%] [G loss: 0.439931]\n",
      "epoch:16 step:15255 [D loss: 0.242120, acc.: 57.03%] [G loss: 0.424485]\n",
      "epoch:16 step:15256 [D loss: 0.194319, acc.: 71.88%] [G loss: 0.454240]\n",
      "epoch:16 step:15257 [D loss: 0.226916, acc.: 63.28%] [G loss: 0.473960]\n",
      "epoch:16 step:15258 [D loss: 0.236642, acc.: 59.38%] [G loss: 0.439719]\n",
      "epoch:16 step:15259 [D loss: 0.226701, acc.: 63.28%] [G loss: 0.393402]\n",
      "epoch:16 step:15260 [D loss: 0.219556, acc.: 59.38%] [G loss: 0.442773]\n",
      "epoch:16 step:15261 [D loss: 0.237636, acc.: 56.25%] [G loss: 0.431872]\n",
      "epoch:16 step:15262 [D loss: 0.232779, acc.: 66.41%] [G loss: 0.462153]\n",
      "epoch:16 step:15263 [D loss: 0.187935, acc.: 71.88%] [G loss: 0.463766]\n",
      "epoch:16 step:15264 [D loss: 0.224401, acc.: 64.06%] [G loss: 0.449121]\n",
      "epoch:16 step:15265 [D loss: 0.246559, acc.: 57.81%] [G loss: 0.419411]\n",
      "epoch:16 step:15266 [D loss: 0.205178, acc.: 67.97%] [G loss: 0.458000]\n",
      "epoch:16 step:15267 [D loss: 0.208860, acc.: 69.53%] [G loss: 0.468538]\n",
      "epoch:16 step:15268 [D loss: 0.220356, acc.: 65.62%] [G loss: 0.453988]\n",
      "epoch:16 step:15269 [D loss: 0.237970, acc.: 60.16%] [G loss: 0.460597]\n",
      "epoch:16 step:15270 [D loss: 0.245426, acc.: 57.03%] [G loss: 0.433228]\n",
      "epoch:16 step:15271 [D loss: 0.249955, acc.: 60.16%] [G loss: 0.449233]\n",
      "epoch:16 step:15272 [D loss: 0.222175, acc.: 61.72%] [G loss: 0.429603]\n",
      "epoch:16 step:15273 [D loss: 0.264730, acc.: 50.78%] [G loss: 0.380966]\n",
      "epoch:16 step:15274 [D loss: 0.233536, acc.: 59.38%] [G loss: 0.387298]\n",
      "epoch:16 step:15275 [D loss: 0.198338, acc.: 71.88%] [G loss: 0.425871]\n",
      "epoch:16 step:15276 [D loss: 0.221986, acc.: 62.50%] [G loss: 0.423254]\n",
      "epoch:16 step:15277 [D loss: 0.208519, acc.: 66.41%] [G loss: 0.433623]\n",
      "epoch:16 step:15278 [D loss: 0.202598, acc.: 68.75%] [G loss: 0.424994]\n",
      "epoch:16 step:15279 [D loss: 0.242246, acc.: 59.38%] [G loss: 0.436836]\n",
      "epoch:16 step:15280 [D loss: 0.222311, acc.: 64.06%] [G loss: 0.446227]\n",
      "epoch:16 step:15281 [D loss: 0.225547, acc.: 63.28%] [G loss: 0.460728]\n",
      "epoch:16 step:15282 [D loss: 0.211242, acc.: 67.19%] [G loss: 0.467309]\n",
      "epoch:16 step:15283 [D loss: 0.250785, acc.: 56.25%] [G loss: 0.420763]\n",
      "epoch:16 step:15284 [D loss: 0.224449, acc.: 60.94%] [G loss: 0.436127]\n",
      "epoch:16 step:15285 [D loss: 0.220221, acc.: 65.62%] [G loss: 0.434549]\n",
      "epoch:16 step:15286 [D loss: 0.265317, acc.: 57.81%] [G loss: 0.390923]\n",
      "epoch:16 step:15287 [D loss: 0.238780, acc.: 53.91%] [G loss: 0.416373]\n",
      "epoch:16 step:15288 [D loss: 0.199932, acc.: 69.53%] [G loss: 0.455773]\n",
      "epoch:16 step:15289 [D loss: 0.242383, acc.: 56.25%] [G loss: 0.454004]\n",
      "epoch:16 step:15290 [D loss: 0.211257, acc.: 64.84%] [G loss: 0.465987]\n",
      "epoch:16 step:15291 [D loss: 0.204954, acc.: 64.06%] [G loss: 0.449391]\n",
      "epoch:16 step:15292 [D loss: 0.200195, acc.: 66.41%] [G loss: 0.436942]\n",
      "epoch:16 step:15293 [D loss: 0.274899, acc.: 50.00%] [G loss: 0.398650]\n",
      "epoch:16 step:15294 [D loss: 0.257583, acc.: 53.12%] [G loss: 0.398865]\n",
      "epoch:16 step:15295 [D loss: 0.243138, acc.: 59.38%] [G loss: 0.430466]\n",
      "epoch:16 step:15296 [D loss: 0.237306, acc.: 54.69%] [G loss: 0.442320]\n",
      "epoch:16 step:15297 [D loss: 0.225600, acc.: 55.47%] [G loss: 0.416703]\n",
      "epoch:16 step:15298 [D loss: 0.231879, acc.: 60.94%] [G loss: 0.430319]\n",
      "epoch:16 step:15299 [D loss: 0.218670, acc.: 64.84%] [G loss: 0.433504]\n",
      "epoch:16 step:15300 [D loss: 0.217538, acc.: 64.84%] [G loss: 0.471133]\n",
      "epoch:16 step:15301 [D loss: 0.207005, acc.: 64.06%] [G loss: 0.401603]\n",
      "epoch:16 step:15302 [D loss: 0.229072, acc.: 63.28%] [G loss: 0.421008]\n",
      "epoch:16 step:15303 [D loss: 0.211863, acc.: 67.97%] [G loss: 0.437820]\n",
      "epoch:16 step:15304 [D loss: 0.196661, acc.: 70.31%] [G loss: 0.480594]\n",
      "epoch:16 step:15305 [D loss: 0.190904, acc.: 69.53%] [G loss: 0.490065]\n",
      "epoch:16 step:15306 [D loss: 0.189372, acc.: 69.53%] [G loss: 0.545576]\n",
      "epoch:16 step:15307 [D loss: 0.191018, acc.: 69.53%] [G loss: 0.511433]\n",
      "epoch:16 step:15308 [D loss: 0.266447, acc.: 60.16%] [G loss: 0.419133]\n",
      "epoch:16 step:15309 [D loss: 0.242774, acc.: 53.12%] [G loss: 0.433028]\n",
      "epoch:16 step:15310 [D loss: 0.205394, acc.: 67.19%] [G loss: 0.438632]\n",
      "epoch:16 step:15311 [D loss: 0.217998, acc.: 60.16%] [G loss: 0.402792]\n",
      "epoch:16 step:15312 [D loss: 0.222276, acc.: 67.19%] [G loss: 0.420853]\n",
      "epoch:16 step:15313 [D loss: 0.239029, acc.: 55.47%] [G loss: 0.446092]\n",
      "epoch:16 step:15314 [D loss: 0.224673, acc.: 62.50%] [G loss: 0.510079]\n",
      "epoch:16 step:15315 [D loss: 0.234659, acc.: 61.72%] [G loss: 0.446026]\n",
      "epoch:16 step:15316 [D loss: 0.244447, acc.: 54.69%] [G loss: 0.435407]\n",
      "epoch:16 step:15317 [D loss: 0.228251, acc.: 61.72%] [G loss: 0.428292]\n",
      "epoch:16 step:15318 [D loss: 0.244620, acc.: 59.38%] [G loss: 0.409686]\n",
      "epoch:16 step:15319 [D loss: 0.227145, acc.: 62.50%] [G loss: 0.462621]\n",
      "epoch:16 step:15320 [D loss: 0.203597, acc.: 68.75%] [G loss: 0.445755]\n",
      "epoch:16 step:15321 [D loss: 0.220961, acc.: 62.50%] [G loss: 0.429876]\n",
      "epoch:16 step:15322 [D loss: 0.209277, acc.: 67.97%] [G loss: 0.414387]\n",
      "epoch:16 step:15323 [D loss: 0.222142, acc.: 64.06%] [G loss: 0.442865]\n",
      "epoch:16 step:15324 [D loss: 0.223444, acc.: 60.16%] [G loss: 0.456120]\n",
      "epoch:16 step:15325 [D loss: 0.210542, acc.: 66.41%] [G loss: 0.498340]\n",
      "epoch:16 step:15326 [D loss: 0.231948, acc.: 62.50%] [G loss: 0.416399]\n",
      "epoch:16 step:15327 [D loss: 0.234237, acc.: 64.06%] [G loss: 0.495706]\n",
      "epoch:16 step:15328 [D loss: 0.208238, acc.: 69.53%] [G loss: 0.447915]\n",
      "epoch:16 step:15329 [D loss: 0.234692, acc.: 60.94%] [G loss: 0.454500]\n",
      "epoch:16 step:15330 [D loss: 0.198554, acc.: 74.22%] [G loss: 0.406985]\n",
      "epoch:16 step:15331 [D loss: 0.205261, acc.: 71.09%] [G loss: 0.438326]\n",
      "epoch:16 step:15332 [D loss: 0.225840, acc.: 62.50%] [G loss: 0.455732]\n",
      "epoch:16 step:15333 [D loss: 0.272911, acc.: 52.34%] [G loss: 0.452684]\n",
      "epoch:16 step:15334 [D loss: 0.216247, acc.: 63.28%] [G loss: 0.483440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15335 [D loss: 0.218169, acc.: 66.41%] [G loss: 0.424252]\n",
      "epoch:16 step:15336 [D loss: 0.190026, acc.: 71.88%] [G loss: 0.459390]\n",
      "epoch:16 step:15337 [D loss: 0.211017, acc.: 66.41%] [G loss: 0.449517]\n",
      "epoch:16 step:15338 [D loss: 0.198775, acc.: 67.97%] [G loss: 0.504099]\n",
      "epoch:16 step:15339 [D loss: 0.208346, acc.: 66.41%] [G loss: 0.501646]\n",
      "epoch:16 step:15340 [D loss: 0.294741, acc.: 50.78%] [G loss: 0.434324]\n",
      "epoch:16 step:15341 [D loss: 0.276856, acc.: 48.44%] [G loss: 0.414731]\n",
      "epoch:16 step:15342 [D loss: 0.218749, acc.: 64.84%] [G loss: 0.426453]\n",
      "epoch:16 step:15343 [D loss: 0.238295, acc.: 53.91%] [G loss: 0.410680]\n",
      "epoch:16 step:15344 [D loss: 0.256044, acc.: 56.25%] [G loss: 0.432052]\n",
      "epoch:16 step:15345 [D loss: 0.213963, acc.: 60.94%] [G loss: 0.457603]\n",
      "epoch:16 step:15346 [D loss: 0.181223, acc.: 75.00%] [G loss: 0.481799]\n",
      "epoch:16 step:15347 [D loss: 0.224757, acc.: 67.97%] [G loss: 0.442903]\n",
      "epoch:16 step:15348 [D loss: 0.245226, acc.: 61.72%] [G loss: 0.421164]\n",
      "epoch:16 step:15349 [D loss: 0.194676, acc.: 71.88%] [G loss: 0.453939]\n",
      "epoch:16 step:15350 [D loss: 0.200239, acc.: 67.97%] [G loss: 0.460932]\n",
      "epoch:16 step:15351 [D loss: 0.230406, acc.: 68.75%] [G loss: 0.448356]\n",
      "epoch:16 step:15352 [D loss: 0.216345, acc.: 66.41%] [G loss: 0.461890]\n",
      "epoch:16 step:15353 [D loss: 0.207820, acc.: 67.19%] [G loss: 0.471532]\n",
      "epoch:16 step:15354 [D loss: 0.231371, acc.: 57.03%] [G loss: 0.446258]\n",
      "epoch:16 step:15355 [D loss: 0.217408, acc.: 64.84%] [G loss: 0.429412]\n",
      "epoch:16 step:15356 [D loss: 0.200752, acc.: 65.62%] [G loss: 0.444186]\n",
      "epoch:16 step:15357 [D loss: 0.215652, acc.: 61.72%] [G loss: 0.424738]\n",
      "epoch:16 step:15358 [D loss: 0.225113, acc.: 66.41%] [G loss: 0.418266]\n",
      "epoch:16 step:15359 [D loss: 0.219384, acc.: 64.84%] [G loss: 0.453409]\n",
      "epoch:16 step:15360 [D loss: 0.234065, acc.: 57.03%] [G loss: 0.454490]\n",
      "epoch:16 step:15361 [D loss: 0.231846, acc.: 60.16%] [G loss: 0.430531]\n",
      "epoch:16 step:15362 [D loss: 0.212246, acc.: 69.53%] [G loss: 0.444623]\n",
      "epoch:16 step:15363 [D loss: 0.209885, acc.: 66.41%] [G loss: 0.460546]\n",
      "epoch:16 step:15364 [D loss: 0.216586, acc.: 66.41%] [G loss: 0.496683]\n",
      "epoch:16 step:15365 [D loss: 0.247376, acc.: 57.81%] [G loss: 0.430665]\n",
      "epoch:16 step:15366 [D loss: 0.187403, acc.: 72.66%] [G loss: 0.488082]\n",
      "epoch:16 step:15367 [D loss: 0.231389, acc.: 64.06%] [G loss: 0.479428]\n",
      "epoch:16 step:15368 [D loss: 0.264279, acc.: 57.81%] [G loss: 0.429280]\n",
      "epoch:16 step:15369 [D loss: 0.258124, acc.: 53.12%] [G loss: 0.406840]\n",
      "epoch:16 step:15370 [D loss: 0.209726, acc.: 64.84%] [G loss: 0.428413]\n",
      "epoch:16 step:15371 [D loss: 0.227410, acc.: 58.59%] [G loss: 0.423629]\n",
      "epoch:16 step:15372 [D loss: 0.243436, acc.: 56.25%] [G loss: 0.402086]\n",
      "epoch:16 step:15373 [D loss: 0.200122, acc.: 65.62%] [G loss: 0.434281]\n",
      "epoch:16 step:15374 [D loss: 0.223834, acc.: 60.94%] [G loss: 0.437721]\n",
      "epoch:16 step:15375 [D loss: 0.238038, acc.: 60.94%] [G loss: 0.407846]\n",
      "epoch:16 step:15376 [D loss: 0.194156, acc.: 70.31%] [G loss: 0.443960]\n",
      "epoch:16 step:15377 [D loss: 0.177180, acc.: 72.66%] [G loss: 0.466712]\n",
      "epoch:16 step:15378 [D loss: 0.264602, acc.: 53.91%] [G loss: 0.452635]\n",
      "epoch:16 step:15379 [D loss: 0.235421, acc.: 57.81%] [G loss: 0.422143]\n",
      "epoch:16 step:15380 [D loss: 0.201419, acc.: 69.53%] [G loss: 0.459193]\n",
      "epoch:16 step:15381 [D loss: 0.228600, acc.: 60.16%] [G loss: 0.476202]\n",
      "epoch:16 step:15382 [D loss: 0.250325, acc.: 59.38%] [G loss: 0.417985]\n",
      "epoch:16 step:15383 [D loss: 0.204259, acc.: 66.41%] [G loss: 0.431944]\n",
      "epoch:16 step:15384 [D loss: 0.221282, acc.: 61.72%] [G loss: 0.433500]\n",
      "epoch:16 step:15385 [D loss: 0.217812, acc.: 63.28%] [G loss: 0.440263]\n",
      "epoch:16 step:15386 [D loss: 0.200280, acc.: 73.44%] [G loss: 0.425404]\n",
      "epoch:16 step:15387 [D loss: 0.209174, acc.: 74.22%] [G loss: 0.420363]\n",
      "epoch:16 step:15388 [D loss: 0.282660, acc.: 52.34%] [G loss: 0.432923]\n",
      "epoch:16 step:15389 [D loss: 0.220944, acc.: 65.62%] [G loss: 0.436596]\n",
      "epoch:16 step:15390 [D loss: 0.209028, acc.: 64.84%] [G loss: 0.476846]\n",
      "epoch:16 step:15391 [D loss: 0.202630, acc.: 67.97%] [G loss: 0.514013]\n",
      "epoch:16 step:15392 [D loss: 0.269041, acc.: 48.44%] [G loss: 0.438679]\n",
      "epoch:16 step:15393 [D loss: 0.213052, acc.: 67.19%] [G loss: 0.468591]\n",
      "epoch:16 step:15394 [D loss: 0.227889, acc.: 69.53%] [G loss: 0.423107]\n",
      "epoch:16 step:15395 [D loss: 0.240043, acc.: 61.72%] [G loss: 0.421061]\n",
      "epoch:16 step:15396 [D loss: 0.227771, acc.: 66.41%] [G loss: 0.426947]\n",
      "epoch:16 step:15397 [D loss: 0.214694, acc.: 69.53%] [G loss: 0.433716]\n",
      "epoch:16 step:15398 [D loss: 0.198788, acc.: 68.75%] [G loss: 0.490920]\n",
      "epoch:16 step:15399 [D loss: 0.232313, acc.: 62.50%] [G loss: 0.461101]\n",
      "epoch:16 step:15400 [D loss: 0.263106, acc.: 56.25%] [G loss: 0.464026]\n",
      "epoch:16 step:15401 [D loss: 0.215710, acc.: 64.84%] [G loss: 0.471986]\n",
      "epoch:16 step:15402 [D loss: 0.245167, acc.: 60.94%] [G loss: 0.435638]\n",
      "epoch:16 step:15403 [D loss: 0.243817, acc.: 53.91%] [G loss: 0.438200]\n",
      "epoch:16 step:15404 [D loss: 0.215122, acc.: 60.94%] [G loss: 0.456134]\n",
      "epoch:16 step:15405 [D loss: 0.223116, acc.: 65.62%] [G loss: 0.428421]\n",
      "epoch:16 step:15406 [D loss: 0.223982, acc.: 60.94%] [G loss: 0.431096]\n",
      "epoch:16 step:15407 [D loss: 0.217666, acc.: 64.06%] [G loss: 0.445201]\n",
      "epoch:16 step:15408 [D loss: 0.201848, acc.: 70.31%] [G loss: 0.521870]\n",
      "epoch:16 step:15409 [D loss: 0.230232, acc.: 64.84%] [G loss: 0.487234]\n",
      "epoch:16 step:15410 [D loss: 0.264568, acc.: 53.12%] [G loss: 0.402362]\n",
      "epoch:16 step:15411 [D loss: 0.233762, acc.: 61.72%] [G loss: 0.405612]\n",
      "epoch:16 step:15412 [D loss: 0.221340, acc.: 65.62%] [G loss: 0.426010]\n",
      "epoch:16 step:15413 [D loss: 0.234958, acc.: 60.94%] [G loss: 0.436738]\n",
      "epoch:16 step:15414 [D loss: 0.262724, acc.: 49.22%] [G loss: 0.423416]\n",
      "epoch:16 step:15415 [D loss: 0.235897, acc.: 63.28%] [G loss: 0.433094]\n",
      "epoch:16 step:15416 [D loss: 0.222091, acc.: 64.06%] [G loss: 0.443023]\n",
      "epoch:16 step:15417 [D loss: 0.206959, acc.: 70.31%] [G loss: 0.460719]\n",
      "epoch:16 step:15418 [D loss: 0.213458, acc.: 71.09%] [G loss: 0.430274]\n",
      "epoch:16 step:15419 [D loss: 0.198595, acc.: 71.09%] [G loss: 0.438187]\n",
      "epoch:16 step:15420 [D loss: 0.216618, acc.: 67.19%] [G loss: 0.478735]\n",
      "epoch:16 step:15421 [D loss: 0.216317, acc.: 68.75%] [G loss: 0.487401]\n",
      "epoch:16 step:15422 [D loss: 0.194371, acc.: 67.97%] [G loss: 0.486095]\n",
      "epoch:16 step:15423 [D loss: 0.254860, acc.: 63.28%] [G loss: 0.435522]\n",
      "epoch:16 step:15424 [D loss: 0.235707, acc.: 55.47%] [G loss: 0.439828]\n",
      "epoch:16 step:15425 [D loss: 0.220259, acc.: 64.06%] [G loss: 0.442802]\n",
      "epoch:16 step:15426 [D loss: 0.209467, acc.: 68.75%] [G loss: 0.467254]\n",
      "epoch:16 step:15427 [D loss: 0.223311, acc.: 66.41%] [G loss: 0.458151]\n",
      "epoch:16 step:15428 [D loss: 0.194916, acc.: 71.88%] [G loss: 0.492356]\n",
      "epoch:16 step:15429 [D loss: 0.270856, acc.: 46.09%] [G loss: 0.487352]\n",
      "epoch:16 step:15430 [D loss: 0.256998, acc.: 51.56%] [G loss: 0.440058]\n",
      "epoch:16 step:15431 [D loss: 0.217330, acc.: 65.62%] [G loss: 0.446435]\n",
      "epoch:16 step:15432 [D loss: 0.216531, acc.: 64.84%] [G loss: 0.435189]\n",
      "epoch:16 step:15433 [D loss: 0.236989, acc.: 56.25%] [G loss: 0.410609]\n",
      "epoch:16 step:15434 [D loss: 0.238925, acc.: 57.81%] [G loss: 0.450988]\n",
      "epoch:16 step:15435 [D loss: 0.241015, acc.: 57.81%] [G loss: 0.417793]\n",
      "epoch:16 step:15436 [D loss: 0.234590, acc.: 60.94%] [G loss: 0.462743]\n",
      "epoch:16 step:15437 [D loss: 0.206551, acc.: 71.09%] [G loss: 0.456899]\n",
      "epoch:16 step:15438 [D loss: 0.225930, acc.: 57.03%] [G loss: 0.426348]\n",
      "epoch:16 step:15439 [D loss: 0.228909, acc.: 62.50%] [G loss: 0.424407]\n",
      "epoch:16 step:15440 [D loss: 0.225125, acc.: 60.16%] [G loss: 0.414881]\n",
      "epoch:16 step:15441 [D loss: 0.227460, acc.: 63.28%] [G loss: 0.418545]\n",
      "epoch:16 step:15442 [D loss: 0.236103, acc.: 59.38%] [G loss: 0.393388]\n",
      "epoch:16 step:15443 [D loss: 0.219159, acc.: 64.06%] [G loss: 0.459942]\n",
      "epoch:16 step:15444 [D loss: 0.211551, acc.: 60.94%] [G loss: 0.498882]\n",
      "epoch:16 step:15445 [D loss: 0.211956, acc.: 66.41%] [G loss: 0.466610]\n",
      "epoch:16 step:15446 [D loss: 0.216578, acc.: 62.50%] [G loss: 0.495303]\n",
      "epoch:16 step:15447 [D loss: 0.227576, acc.: 60.16%] [G loss: 0.439738]\n",
      "epoch:16 step:15448 [D loss: 0.220878, acc.: 63.28%] [G loss: 0.422487]\n",
      "epoch:16 step:15449 [D loss: 0.231533, acc.: 61.72%] [G loss: 0.420679]\n",
      "epoch:16 step:15450 [D loss: 0.248770, acc.: 60.16%] [G loss: 0.429216]\n",
      "epoch:16 step:15451 [D loss: 0.252299, acc.: 57.81%] [G loss: 0.413849]\n",
      "epoch:16 step:15452 [D loss: 0.232547, acc.: 64.06%] [G loss: 0.411806]\n",
      "epoch:16 step:15453 [D loss: 0.229292, acc.: 64.84%] [G loss: 0.455360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15454 [D loss: 0.215496, acc.: 67.97%] [G loss: 0.410101]\n",
      "epoch:16 step:15455 [D loss: 0.217899, acc.: 64.06%] [G loss: 0.448955]\n",
      "epoch:16 step:15456 [D loss: 0.208011, acc.: 66.41%] [G loss: 0.449276]\n",
      "epoch:16 step:15457 [D loss: 0.253951, acc.: 57.81%] [G loss: 0.412624]\n",
      "epoch:16 step:15458 [D loss: 0.209141, acc.: 67.19%] [G loss: 0.432186]\n",
      "epoch:16 step:15459 [D loss: 0.216024, acc.: 67.97%] [G loss: 0.466823]\n",
      "epoch:16 step:15460 [D loss: 0.226980, acc.: 57.03%] [G loss: 0.424853]\n",
      "epoch:16 step:15461 [D loss: 0.204421, acc.: 63.28%] [G loss: 0.478922]\n",
      "epoch:16 step:15462 [D loss: 0.207049, acc.: 66.41%] [G loss: 0.470035]\n",
      "epoch:16 step:15463 [D loss: 0.190943, acc.: 75.00%] [G loss: 0.504428]\n",
      "epoch:16 step:15464 [D loss: 0.192500, acc.: 71.09%] [G loss: 0.510832]\n",
      "epoch:16 step:15465 [D loss: 0.288536, acc.: 53.12%] [G loss: 0.397013]\n",
      "epoch:16 step:15466 [D loss: 0.214890, acc.: 67.19%] [G loss: 0.499498]\n",
      "epoch:16 step:15467 [D loss: 0.206251, acc.: 68.75%] [G loss: 0.499224]\n",
      "epoch:16 step:15468 [D loss: 0.242052, acc.: 56.25%] [G loss: 0.463601]\n",
      "epoch:16 step:15469 [D loss: 0.261236, acc.: 53.91%] [G loss: 0.423841]\n",
      "epoch:16 step:15470 [D loss: 0.265525, acc.: 51.56%] [G loss: 0.384184]\n",
      "epoch:16 step:15471 [D loss: 0.219545, acc.: 64.84%] [G loss: 0.430425]\n",
      "epoch:16 step:15472 [D loss: 0.225047, acc.: 63.28%] [G loss: 0.397337]\n",
      "epoch:16 step:15473 [D loss: 0.217295, acc.: 64.84%] [G loss: 0.485532]\n",
      "epoch:16 step:15474 [D loss: 0.275057, acc.: 50.00%] [G loss: 0.447001]\n",
      "epoch:16 step:15475 [D loss: 0.219928, acc.: 63.28%] [G loss: 0.497106]\n",
      "epoch:16 step:15476 [D loss: 0.219250, acc.: 64.06%] [G loss: 0.443858]\n",
      "epoch:16 step:15477 [D loss: 0.226385, acc.: 63.28%] [G loss: 0.434819]\n",
      "epoch:16 step:15478 [D loss: 0.235857, acc.: 62.50%] [G loss: 0.444772]\n",
      "epoch:16 step:15479 [D loss: 0.234228, acc.: 59.38%] [G loss: 0.423704]\n",
      "epoch:16 step:15480 [D loss: 0.198532, acc.: 68.75%] [G loss: 0.405690]\n",
      "epoch:16 step:15481 [D loss: 0.258717, acc.: 54.69%] [G loss: 0.428064]\n",
      "epoch:16 step:15482 [D loss: 0.225027, acc.: 66.41%] [G loss: 0.402991]\n",
      "epoch:16 step:15483 [D loss: 0.227887, acc.: 61.72%] [G loss: 0.403156]\n",
      "epoch:16 step:15484 [D loss: 0.228087, acc.: 60.16%] [G loss: 0.431124]\n",
      "epoch:16 step:15485 [D loss: 0.235859, acc.: 60.16%] [G loss: 0.418453]\n",
      "epoch:16 step:15486 [D loss: 0.226535, acc.: 69.53%] [G loss: 0.461848]\n",
      "epoch:16 step:15487 [D loss: 0.181345, acc.: 76.56%] [G loss: 0.495859]\n",
      "epoch:16 step:15488 [D loss: 0.218572, acc.: 67.97%] [G loss: 0.483984]\n",
      "epoch:16 step:15489 [D loss: 0.209814, acc.: 67.97%] [G loss: 0.481232]\n",
      "epoch:16 step:15490 [D loss: 0.192830, acc.: 73.44%] [G loss: 0.473835]\n",
      "epoch:16 step:15491 [D loss: 0.199531, acc.: 74.22%] [G loss: 0.500700]\n",
      "epoch:16 step:15492 [D loss: 0.278393, acc.: 54.69%] [G loss: 0.452736]\n",
      "epoch:16 step:15493 [D loss: 0.279239, acc.: 52.34%] [G loss: 0.405525]\n",
      "epoch:16 step:15494 [D loss: 0.265197, acc.: 45.31%] [G loss: 0.394991]\n",
      "epoch:16 step:15495 [D loss: 0.220681, acc.: 65.62%] [G loss: 0.422153]\n",
      "epoch:16 step:15496 [D loss: 0.194776, acc.: 69.53%] [G loss: 0.426799]\n",
      "epoch:16 step:15497 [D loss: 0.211817, acc.: 65.62%] [G loss: 0.447757]\n",
      "epoch:16 step:15498 [D loss: 0.219809, acc.: 65.62%] [G loss: 0.466460]\n",
      "epoch:16 step:15499 [D loss: 0.225819, acc.: 60.94%] [G loss: 0.468248]\n",
      "epoch:16 step:15500 [D loss: 0.186856, acc.: 71.88%] [G loss: 0.473443]\n",
      "epoch:16 step:15501 [D loss: 0.260431, acc.: 56.25%] [G loss: 0.440901]\n",
      "epoch:16 step:15502 [D loss: 0.258040, acc.: 56.25%] [G loss: 0.437577]\n",
      "epoch:16 step:15503 [D loss: 0.251762, acc.: 53.12%] [G loss: 0.407908]\n",
      "epoch:16 step:15504 [D loss: 0.208356, acc.: 67.97%] [G loss: 0.449387]\n",
      "epoch:16 step:15505 [D loss: 0.226527, acc.: 62.50%] [G loss: 0.430311]\n",
      "epoch:16 step:15506 [D loss: 0.220661, acc.: 60.16%] [G loss: 0.431430]\n",
      "epoch:16 step:15507 [D loss: 0.202078, acc.: 71.09%] [G loss: 0.447682]\n",
      "epoch:16 step:15508 [D loss: 0.203963, acc.: 66.41%] [G loss: 0.477162]\n",
      "epoch:16 step:15509 [D loss: 0.232893, acc.: 60.94%] [G loss: 0.428211]\n",
      "epoch:16 step:15510 [D loss: 0.234272, acc.: 59.38%] [G loss: 0.416773]\n",
      "epoch:16 step:15511 [D loss: 0.195097, acc.: 71.09%] [G loss: 0.460349]\n",
      "epoch:16 step:15512 [D loss: 0.207982, acc.: 69.53%] [G loss: 0.441098]\n",
      "epoch:16 step:15513 [D loss: 0.207692, acc.: 67.97%] [G loss: 0.408326]\n",
      "epoch:16 step:15514 [D loss: 0.215095, acc.: 67.19%] [G loss: 0.436647]\n",
      "epoch:16 step:15515 [D loss: 0.210892, acc.: 63.28%] [G loss: 0.463699]\n",
      "epoch:16 step:15516 [D loss: 0.242568, acc.: 51.56%] [G loss: 0.448174]\n",
      "epoch:16 step:15517 [D loss: 0.232236, acc.: 63.28%] [G loss: 0.474184]\n",
      "epoch:16 step:15518 [D loss: 0.199632, acc.: 70.31%] [G loss: 0.519730]\n",
      "epoch:16 step:15519 [D loss: 0.239819, acc.: 57.03%] [G loss: 0.455484]\n",
      "epoch:16 step:15520 [D loss: 0.254336, acc.: 54.69%] [G loss: 0.455593]\n",
      "epoch:16 step:15521 [D loss: 0.264577, acc.: 50.78%] [G loss: 0.447520]\n",
      "epoch:16 step:15522 [D loss: 0.224940, acc.: 64.06%] [G loss: 0.472923]\n",
      "epoch:16 step:15523 [D loss: 0.244098, acc.: 59.38%] [G loss: 0.421837]\n",
      "epoch:16 step:15524 [D loss: 0.224171, acc.: 63.28%] [G loss: 0.432415]\n",
      "epoch:16 step:15525 [D loss: 0.259833, acc.: 56.25%] [G loss: 0.420481]\n",
      "epoch:16 step:15526 [D loss: 0.191795, acc.: 68.75%] [G loss: 0.440963]\n",
      "epoch:16 step:15527 [D loss: 0.221389, acc.: 65.62%] [G loss: 0.464577]\n",
      "epoch:16 step:15528 [D loss: 0.226087, acc.: 62.50%] [G loss: 0.429631]\n",
      "epoch:16 step:15529 [D loss: 0.258701, acc.: 55.47%] [G loss: 0.408948]\n",
      "epoch:16 step:15530 [D loss: 0.237446, acc.: 57.81%] [G loss: 0.453852]\n",
      "epoch:16 step:15531 [D loss: 0.213141, acc.: 63.28%] [G loss: 0.468117]\n",
      "epoch:16 step:15532 [D loss: 0.223924, acc.: 57.81%] [G loss: 0.429062]\n",
      "epoch:16 step:15533 [D loss: 0.216408, acc.: 63.28%] [G loss: 0.423257]\n",
      "epoch:16 step:15534 [D loss: 0.250508, acc.: 55.47%] [G loss: 0.420521]\n",
      "epoch:16 step:15535 [D loss: 0.214207, acc.: 62.50%] [G loss: 0.439930]\n",
      "epoch:16 step:15536 [D loss: 0.213910, acc.: 67.19%] [G loss: 0.466643]\n",
      "epoch:16 step:15537 [D loss: 0.223723, acc.: 63.28%] [G loss: 0.452412]\n",
      "epoch:16 step:15538 [D loss: 0.215752, acc.: 66.41%] [G loss: 0.398152]\n",
      "epoch:16 step:15539 [D loss: 0.251876, acc.: 57.81%] [G loss: 0.435943]\n",
      "epoch:16 step:15540 [D loss: 0.172518, acc.: 76.56%] [G loss: 0.460455]\n",
      "epoch:16 step:15541 [D loss: 0.237530, acc.: 62.50%] [G loss: 0.416025]\n",
      "epoch:16 step:15542 [D loss: 0.193238, acc.: 75.00%] [G loss: 0.492038]\n",
      "epoch:16 step:15543 [D loss: 0.203584, acc.: 71.09%] [G loss: 0.491537]\n",
      "epoch:16 step:15544 [D loss: 0.225754, acc.: 64.84%] [G loss: 0.480278]\n",
      "epoch:16 step:15545 [D loss: 0.235002, acc.: 57.81%] [G loss: 0.473163]\n",
      "epoch:16 step:15546 [D loss: 0.206948, acc.: 70.31%] [G loss: 0.446452]\n",
      "epoch:16 step:15547 [D loss: 0.189827, acc.: 69.53%] [G loss: 0.468063]\n",
      "epoch:16 step:15548 [D loss: 0.229142, acc.: 64.84%] [G loss: 0.454813]\n",
      "epoch:16 step:15549 [D loss: 0.203200, acc.: 67.97%] [G loss: 0.452761]\n",
      "epoch:16 step:15550 [D loss: 0.212325, acc.: 64.06%] [G loss: 0.442766]\n",
      "epoch:16 step:15551 [D loss: 0.262398, acc.: 50.78%] [G loss: 0.465440]\n",
      "epoch:16 step:15552 [D loss: 0.243929, acc.: 60.16%] [G loss: 0.429952]\n",
      "epoch:16 step:15553 [D loss: 0.209693, acc.: 71.88%] [G loss: 0.448405]\n",
      "epoch:16 step:15554 [D loss: 0.213336, acc.: 66.41%] [G loss: 0.483770]\n",
      "epoch:16 step:15555 [D loss: 0.204096, acc.: 66.41%] [G loss: 0.501261]\n",
      "epoch:16 step:15556 [D loss: 0.212814, acc.: 62.50%] [G loss: 0.499963]\n",
      "epoch:16 step:15557 [D loss: 0.224590, acc.: 61.72%] [G loss: 0.483889]\n",
      "epoch:16 step:15558 [D loss: 0.284767, acc.: 52.34%] [G loss: 0.437938]\n",
      "epoch:16 step:15559 [D loss: 0.216470, acc.: 62.50%] [G loss: 0.455477]\n",
      "epoch:16 step:15560 [D loss: 0.199358, acc.: 70.31%] [G loss: 0.472220]\n",
      "epoch:16 step:15561 [D loss: 0.254029, acc.: 57.03%] [G loss: 0.411584]\n",
      "epoch:16 step:15562 [D loss: 0.233248, acc.: 58.59%] [G loss: 0.376427]\n",
      "epoch:16 step:15563 [D loss: 0.209752, acc.: 64.84%] [G loss: 0.470403]\n",
      "epoch:16 step:15564 [D loss: 0.238749, acc.: 57.81%] [G loss: 0.412151]\n",
      "epoch:16 step:15565 [D loss: 0.231221, acc.: 63.28%] [G loss: 0.468993]\n",
      "epoch:16 step:15566 [D loss: 0.168075, acc.: 73.44%] [G loss: 0.537398]\n",
      "epoch:16 step:15567 [D loss: 0.208023, acc.: 67.19%] [G loss: 0.449171]\n",
      "epoch:16 step:15568 [D loss: 0.244845, acc.: 55.47%] [G loss: 0.412740]\n",
      "epoch:16 step:15569 [D loss: 0.244378, acc.: 58.59%] [G loss: 0.412474]\n",
      "epoch:16 step:15570 [D loss: 0.225141, acc.: 64.06%] [G loss: 0.432889]\n",
      "epoch:16 step:15571 [D loss: 0.252274, acc.: 48.44%] [G loss: 0.454578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15572 [D loss: 0.234131, acc.: 56.25%] [G loss: 0.473254]\n",
      "epoch:16 step:15573 [D loss: 0.228726, acc.: 62.50%] [G loss: 0.422935]\n",
      "epoch:16 step:15574 [D loss: 0.199401, acc.: 70.31%] [G loss: 0.514512]\n",
      "epoch:16 step:15575 [D loss: 0.231542, acc.: 59.38%] [G loss: 0.465705]\n",
      "epoch:16 step:15576 [D loss: 0.240618, acc.: 56.25%] [G loss: 0.466936]\n",
      "epoch:16 step:15577 [D loss: 0.222759, acc.: 59.38%] [G loss: 0.475319]\n",
      "epoch:16 step:15578 [D loss: 0.243291, acc.: 54.69%] [G loss: 0.459453]\n",
      "epoch:16 step:15579 [D loss: 0.238997, acc.: 59.38%] [G loss: 0.430908]\n",
      "epoch:16 step:15580 [D loss: 0.190635, acc.: 68.75%] [G loss: 0.466355]\n",
      "epoch:16 step:15581 [D loss: 0.191356, acc.: 71.88%] [G loss: 0.477359]\n",
      "epoch:16 step:15582 [D loss: 0.263243, acc.: 60.94%] [G loss: 0.444665]\n",
      "epoch:16 step:15583 [D loss: 0.216496, acc.: 67.19%] [G loss: 0.426638]\n",
      "epoch:16 step:15584 [D loss: 0.187869, acc.: 71.88%] [G loss: 0.456504]\n",
      "epoch:16 step:15585 [D loss: 0.220627, acc.: 64.06%] [G loss: 0.448330]\n",
      "epoch:16 step:15586 [D loss: 0.242290, acc.: 56.25%] [G loss: 0.445274]\n",
      "epoch:16 step:15587 [D loss: 0.202758, acc.: 71.09%] [G loss: 0.473983]\n",
      "epoch:16 step:15588 [D loss: 0.216083, acc.: 63.28%] [G loss: 0.429814]\n",
      "epoch:16 step:15589 [D loss: 0.252243, acc.: 51.56%] [G loss: 0.405487]\n",
      "epoch:16 step:15590 [D loss: 0.216388, acc.: 69.53%] [G loss: 0.431833]\n",
      "epoch:16 step:15591 [D loss: 0.231531, acc.: 58.59%] [G loss: 0.450557]\n",
      "epoch:16 step:15592 [D loss: 0.242025, acc.: 54.69%] [G loss: 0.429794]\n",
      "epoch:16 step:15593 [D loss: 0.245788, acc.: 59.38%] [G loss: 0.425052]\n",
      "epoch:16 step:15594 [D loss: 0.219261, acc.: 65.62%] [G loss: 0.456610]\n",
      "epoch:16 step:15595 [D loss: 0.229172, acc.: 63.28%] [G loss: 0.427566]\n",
      "epoch:16 step:15596 [D loss: 0.217725, acc.: 64.84%] [G loss: 0.464015]\n",
      "epoch:16 step:15597 [D loss: 0.231139, acc.: 61.72%] [G loss: 0.443838]\n",
      "epoch:16 step:15598 [D loss: 0.223207, acc.: 64.84%] [G loss: 0.424239]\n",
      "epoch:16 step:15599 [D loss: 0.228814, acc.: 63.28%] [G loss: 0.411123]\n",
      "epoch:16 step:15600 [D loss: 0.214722, acc.: 67.19%] [G loss: 0.424464]\n",
      "epoch:16 step:15601 [D loss: 0.236607, acc.: 54.69%] [G loss: 0.445346]\n",
      "epoch:16 step:15602 [D loss: 0.210951, acc.: 63.28%] [G loss: 0.466596]\n",
      "epoch:16 step:15603 [D loss: 0.233037, acc.: 60.16%] [G loss: 0.448300]\n",
      "epoch:16 step:15604 [D loss: 0.230800, acc.: 64.84%] [G loss: 0.394035]\n",
      "epoch:16 step:15605 [D loss: 0.219556, acc.: 67.19%] [G loss: 0.420622]\n",
      "epoch:16 step:15606 [D loss: 0.234126, acc.: 57.81%] [G loss: 0.416709]\n",
      "epoch:16 step:15607 [D loss: 0.274647, acc.: 49.22%] [G loss: 0.389411]\n",
      "epoch:16 step:15608 [D loss: 0.257661, acc.: 57.81%] [G loss: 0.429092]\n",
      "epoch:16 step:15609 [D loss: 0.221998, acc.: 62.50%] [G loss: 0.500361]\n",
      "epoch:16 step:15610 [D loss: 0.212192, acc.: 67.19%] [G loss: 0.492176]\n",
      "epoch:16 step:15611 [D loss: 0.208764, acc.: 66.41%] [G loss: 0.480573]\n",
      "epoch:16 step:15612 [D loss: 0.196191, acc.: 71.09%] [G loss: 0.425665]\n",
      "epoch:16 step:15613 [D loss: 0.248148, acc.: 57.81%] [G loss: 0.407750]\n",
      "epoch:16 step:15614 [D loss: 0.246282, acc.: 55.47%] [G loss: 0.416794]\n",
      "epoch:16 step:15615 [D loss: 0.218746, acc.: 67.97%] [G loss: 0.422872]\n",
      "epoch:16 step:15616 [D loss: 0.173280, acc.: 75.78%] [G loss: 0.472656]\n",
      "epoch:16 step:15617 [D loss: 0.237896, acc.: 56.25%] [G loss: 0.437899]\n",
      "epoch:16 step:15618 [D loss: 0.220125, acc.: 66.41%] [G loss: 0.451725]\n",
      "epoch:16 step:15619 [D loss: 0.225560, acc.: 62.50%] [G loss: 0.404077]\n",
      "epoch:16 step:15620 [D loss: 0.235383, acc.: 64.06%] [G loss: 0.407490]\n",
      "epoch:16 step:15621 [D loss: 0.201262, acc.: 71.88%] [G loss: 0.444471]\n",
      "epoch:16 step:15622 [D loss: 0.231938, acc.: 58.59%] [G loss: 0.458262]\n",
      "epoch:16 step:15623 [D loss: 0.210525, acc.: 67.97%] [G loss: 0.478117]\n",
      "epoch:16 step:15624 [D loss: 0.219792, acc.: 64.84%] [G loss: 0.440921]\n",
      "epoch:16 step:15625 [D loss: 0.227992, acc.: 62.50%] [G loss: 0.429105]\n",
      "epoch:16 step:15626 [D loss: 0.219702, acc.: 64.84%] [G loss: 0.450281]\n",
      "epoch:16 step:15627 [D loss: 0.198196, acc.: 67.97%] [G loss: 0.495340]\n",
      "epoch:16 step:15628 [D loss: 0.214196, acc.: 67.97%] [G loss: 0.449564]\n",
      "epoch:16 step:15629 [D loss: 0.239185, acc.: 63.28%] [G loss: 0.444342]\n",
      "epoch:16 step:15630 [D loss: 0.235139, acc.: 59.38%] [G loss: 0.404114]\n",
      "epoch:16 step:15631 [D loss: 0.225275, acc.: 60.94%] [G loss: 0.455460]\n",
      "epoch:16 step:15632 [D loss: 0.214909, acc.: 63.28%] [G loss: 0.471853]\n",
      "epoch:16 step:15633 [D loss: 0.197381, acc.: 74.22%] [G loss: 0.503581]\n",
      "epoch:16 step:15634 [D loss: 0.181794, acc.: 75.78%] [G loss: 0.543659]\n",
      "epoch:16 step:15635 [D loss: 0.243721, acc.: 59.38%] [G loss: 0.425902]\n",
      "epoch:16 step:15636 [D loss: 0.255196, acc.: 53.91%] [G loss: 0.393659]\n",
      "epoch:16 step:15637 [D loss: 0.217331, acc.: 60.94%] [G loss: 0.425516]\n",
      "epoch:16 step:15638 [D loss: 0.257856, acc.: 57.81%] [G loss: 0.463410]\n",
      "epoch:16 step:15639 [D loss: 0.193554, acc.: 73.44%] [G loss: 0.510863]\n",
      "epoch:16 step:15640 [D loss: 0.177097, acc.: 82.03%] [G loss: 0.541306]\n",
      "epoch:16 step:15641 [D loss: 0.213906, acc.: 67.19%] [G loss: 0.474223]\n",
      "epoch:16 step:15642 [D loss: 0.198286, acc.: 68.75%] [G loss: 0.474954]\n",
      "epoch:16 step:15643 [D loss: 0.223152, acc.: 66.41%] [G loss: 0.449224]\n",
      "epoch:16 step:15644 [D loss: 0.216255, acc.: 64.84%] [G loss: 0.430773]\n",
      "epoch:16 step:15645 [D loss: 0.232737, acc.: 58.59%] [G loss: 0.429928]\n",
      "epoch:16 step:15646 [D loss: 0.198082, acc.: 66.41%] [G loss: 0.475516]\n",
      "epoch:16 step:15647 [D loss: 0.244942, acc.: 57.81%] [G loss: 0.475340]\n",
      "epoch:16 step:15648 [D loss: 0.242447, acc.: 60.94%] [G loss: 0.441919]\n",
      "epoch:16 step:15649 [D loss: 0.236932, acc.: 59.38%] [G loss: 0.442882]\n",
      "epoch:16 step:15650 [D loss: 0.252110, acc.: 50.00%] [G loss: 0.425809]\n",
      "epoch:16 step:15651 [D loss: 0.204950, acc.: 71.09%] [G loss: 0.448961]\n",
      "epoch:16 step:15652 [D loss: 0.220650, acc.: 67.97%] [G loss: 0.434466]\n",
      "epoch:16 step:15653 [D loss: 0.219625, acc.: 64.84%] [G loss: 0.430918]\n",
      "epoch:16 step:15654 [D loss: 0.230184, acc.: 60.94%] [G loss: 0.412539]\n",
      "epoch:16 step:15655 [D loss: 0.238063, acc.: 57.03%] [G loss: 0.460443]\n",
      "epoch:16 step:15656 [D loss: 0.247561, acc.: 58.59%] [G loss: 0.461089]\n",
      "epoch:16 step:15657 [D loss: 0.206697, acc.: 67.19%] [G loss: 0.465475]\n",
      "epoch:16 step:15658 [D loss: 0.223764, acc.: 64.06%] [G loss: 0.440237]\n",
      "epoch:16 step:15659 [D loss: 0.216374, acc.: 64.06%] [G loss: 0.470609]\n",
      "epoch:16 step:15660 [D loss: 0.238742, acc.: 61.72%] [G loss: 0.456629]\n",
      "epoch:16 step:15661 [D loss: 0.224184, acc.: 61.72%] [G loss: 0.409423]\n",
      "epoch:16 step:15662 [D loss: 0.275658, acc.: 52.34%] [G loss: 0.397727]\n",
      "epoch:16 step:15663 [D loss: 0.244908, acc.: 53.12%] [G loss: 0.428907]\n",
      "epoch:16 step:15664 [D loss: 0.243307, acc.: 57.81%] [G loss: 0.418349]\n",
      "epoch:16 step:15665 [D loss: 0.232566, acc.: 63.28%] [G loss: 0.441568]\n",
      "epoch:16 step:15666 [D loss: 0.213666, acc.: 67.97%] [G loss: 0.464584]\n",
      "epoch:16 step:15667 [D loss: 0.258497, acc.: 51.56%] [G loss: 0.409103]\n",
      "epoch:16 step:15668 [D loss: 0.212805, acc.: 69.53%] [G loss: 0.440310]\n",
      "epoch:16 step:15669 [D loss: 0.218354, acc.: 63.28%] [G loss: 0.435159]\n",
      "epoch:16 step:15670 [D loss: 0.218303, acc.: 69.53%] [G loss: 0.434455]\n",
      "epoch:16 step:15671 [D loss: 0.217186, acc.: 64.06%] [G loss: 0.443988]\n",
      "epoch:16 step:15672 [D loss: 0.220361, acc.: 62.50%] [G loss: 0.415709]\n",
      "epoch:16 step:15673 [D loss: 0.188164, acc.: 67.97%] [G loss: 0.454644]\n",
      "epoch:16 step:15674 [D loss: 0.219963, acc.: 64.84%] [G loss: 0.434982]\n",
      "epoch:16 step:15675 [D loss: 0.247607, acc.: 57.03%] [G loss: 0.407156]\n",
      "epoch:16 step:15676 [D loss: 0.225288, acc.: 63.28%] [G loss: 0.395551]\n",
      "epoch:16 step:15677 [D loss: 0.214691, acc.: 62.50%] [G loss: 0.429000]\n",
      "epoch:16 step:15678 [D loss: 0.206671, acc.: 67.97%] [G loss: 0.434148]\n",
      "epoch:16 step:15679 [D loss: 0.226566, acc.: 60.94%] [G loss: 0.429547]\n",
      "epoch:16 step:15680 [D loss: 0.212114, acc.: 66.41%] [G loss: 0.427397]\n",
      "epoch:16 step:15681 [D loss: 0.250974, acc.: 51.56%] [G loss: 0.448262]\n",
      "epoch:16 step:15682 [D loss: 0.206834, acc.: 67.97%] [G loss: 0.449510]\n",
      "epoch:16 step:15683 [D loss: 0.206885, acc.: 62.50%] [G loss: 0.487196]\n",
      "epoch:16 step:15684 [D loss: 0.210835, acc.: 63.28%] [G loss: 0.469459]\n",
      "epoch:16 step:15685 [D loss: 0.195011, acc.: 71.88%] [G loss: 0.508360]\n",
      "epoch:16 step:15686 [D loss: 0.199473, acc.: 71.09%] [G loss: 0.476924]\n",
      "epoch:16 step:15687 [D loss: 0.213086, acc.: 67.19%] [G loss: 0.487763]\n",
      "epoch:16 step:15688 [D loss: 0.251898, acc.: 57.03%] [G loss: 0.424232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15689 [D loss: 0.236798, acc.: 57.81%] [G loss: 0.402534]\n",
      "epoch:16 step:15690 [D loss: 0.228720, acc.: 62.50%] [G loss: 0.414861]\n",
      "epoch:16 step:15691 [D loss: 0.198345, acc.: 72.66%] [G loss: 0.445690]\n",
      "epoch:16 step:15692 [D loss: 0.223120, acc.: 60.94%] [G loss: 0.432523]\n",
      "epoch:16 step:15693 [D loss: 0.210195, acc.: 62.50%] [G loss: 0.451896]\n",
      "epoch:16 step:15694 [D loss: 0.253008, acc.: 57.03%] [G loss: 0.441405]\n",
      "epoch:16 step:15695 [D loss: 0.231390, acc.: 64.06%] [G loss: 0.439631]\n",
      "epoch:16 step:15696 [D loss: 0.229087, acc.: 63.28%] [G loss: 0.410159]\n",
      "epoch:16 step:15697 [D loss: 0.232868, acc.: 60.16%] [G loss: 0.434595]\n",
      "epoch:16 step:15698 [D loss: 0.202506, acc.: 70.31%] [G loss: 0.493943]\n",
      "epoch:16 step:15699 [D loss: 0.214063, acc.: 62.50%] [G loss: 0.457475]\n",
      "epoch:16 step:15700 [D loss: 0.207367, acc.: 64.06%] [G loss: 0.442343]\n",
      "epoch:16 step:15701 [D loss: 0.193972, acc.: 67.19%] [G loss: 0.441005]\n",
      "epoch:16 step:15702 [D loss: 0.239001, acc.: 57.81%] [G loss: 0.449261]\n",
      "epoch:16 step:15703 [D loss: 0.235377, acc.: 59.38%] [G loss: 0.428132]\n",
      "epoch:16 step:15704 [D loss: 0.221617, acc.: 66.41%] [G loss: 0.454984]\n",
      "epoch:16 step:15705 [D loss: 0.218594, acc.: 64.06%] [G loss: 0.420100]\n",
      "epoch:16 step:15706 [D loss: 0.210993, acc.: 67.97%] [G loss: 0.448391]\n",
      "epoch:16 step:15707 [D loss: 0.222516, acc.: 62.50%] [G loss: 0.467814]\n",
      "epoch:16 step:15708 [D loss: 0.236751, acc.: 60.16%] [G loss: 0.416294]\n",
      "epoch:16 step:15709 [D loss: 0.213037, acc.: 71.88%] [G loss: 0.415074]\n",
      "epoch:16 step:15710 [D loss: 0.223920, acc.: 64.06%] [G loss: 0.429629]\n",
      "epoch:16 step:15711 [D loss: 0.199623, acc.: 68.75%] [G loss: 0.440580]\n",
      "epoch:16 step:15712 [D loss: 0.245722, acc.: 57.81%] [G loss: 0.437851]\n",
      "epoch:16 step:15713 [D loss: 0.207166, acc.: 64.84%] [G loss: 0.470571]\n",
      "epoch:16 step:15714 [D loss: 0.266961, acc.: 50.00%] [G loss: 0.396435]\n",
      "epoch:16 step:15715 [D loss: 0.201943, acc.: 71.09%] [G loss: 0.481711]\n",
      "epoch:16 step:15716 [D loss: 0.199981, acc.: 71.88%] [G loss: 0.503039]\n",
      "epoch:16 step:15717 [D loss: 0.192095, acc.: 75.00%] [G loss: 0.463175]\n",
      "epoch:16 step:15718 [D loss: 0.224884, acc.: 63.28%] [G loss: 0.466421]\n",
      "epoch:16 step:15719 [D loss: 0.225057, acc.: 63.28%] [G loss: 0.457463]\n",
      "epoch:16 step:15720 [D loss: 0.235233, acc.: 60.16%] [G loss: 0.444778]\n",
      "epoch:16 step:15721 [D loss: 0.218941, acc.: 65.62%] [G loss: 0.421683]\n",
      "epoch:16 step:15722 [D loss: 0.207206, acc.: 70.31%] [G loss: 0.450534]\n",
      "epoch:16 step:15723 [D loss: 0.221312, acc.: 67.19%] [G loss: 0.463690]\n",
      "epoch:16 step:15724 [D loss: 0.220222, acc.: 67.19%] [G loss: 0.448799]\n",
      "epoch:16 step:15725 [D loss: 0.199314, acc.: 71.88%] [G loss: 0.432455]\n",
      "epoch:16 step:15726 [D loss: 0.247179, acc.: 55.47%] [G loss: 0.405400]\n",
      "epoch:16 step:15727 [D loss: 0.254827, acc.: 53.12%] [G loss: 0.384158]\n",
      "epoch:16 step:15728 [D loss: 0.218875, acc.: 62.50%] [G loss: 0.422725]\n",
      "epoch:16 step:15729 [D loss: 0.217805, acc.: 64.84%] [G loss: 0.470873]\n",
      "epoch:16 step:15730 [D loss: 0.241758, acc.: 55.47%] [G loss: 0.420233]\n",
      "epoch:16 step:15731 [D loss: 0.260508, acc.: 53.91%] [G loss: 0.374975]\n",
      "epoch:16 step:15732 [D loss: 0.236591, acc.: 64.06%] [G loss: 0.402089]\n",
      "epoch:16 step:15733 [D loss: 0.239097, acc.: 61.72%] [G loss: 0.387099]\n",
      "epoch:16 step:15734 [D loss: 0.225782, acc.: 63.28%] [G loss: 0.444704]\n",
      "epoch:16 step:15735 [D loss: 0.194213, acc.: 72.66%] [G loss: 0.469770]\n",
      "epoch:16 step:15736 [D loss: 0.241442, acc.: 60.16%] [G loss: 0.425098]\n",
      "epoch:16 step:15737 [D loss: 0.247396, acc.: 53.91%] [G loss: 0.392808]\n",
      "epoch:16 step:15738 [D loss: 0.197369, acc.: 70.31%] [G loss: 0.418785]\n",
      "epoch:16 step:15739 [D loss: 0.213050, acc.: 67.97%] [G loss: 0.426484]\n",
      "epoch:16 step:15740 [D loss: 0.248846, acc.: 54.69%] [G loss: 0.400121]\n",
      "epoch:16 step:15741 [D loss: 0.225069, acc.: 63.28%] [G loss: 0.425795]\n",
      "epoch:16 step:15742 [D loss: 0.221777, acc.: 63.28%] [G loss: 0.444294]\n",
      "epoch:16 step:15743 [D loss: 0.210793, acc.: 67.19%] [G loss: 0.472276]\n",
      "epoch:16 step:15744 [D loss: 0.245203, acc.: 57.81%] [G loss: 0.442564]\n",
      "epoch:16 step:15745 [D loss: 0.209441, acc.: 66.41%] [G loss: 0.418820]\n",
      "epoch:16 step:15746 [D loss: 0.211581, acc.: 64.06%] [G loss: 0.441905]\n",
      "epoch:16 step:15747 [D loss: 0.196413, acc.: 69.53%] [G loss: 0.442095]\n",
      "epoch:16 step:15748 [D loss: 0.229134, acc.: 60.94%] [G loss: 0.395270]\n",
      "epoch:16 step:15749 [D loss: 0.237992, acc.: 60.94%] [G loss: 0.441818]\n",
      "epoch:16 step:15750 [D loss: 0.218080, acc.: 67.19%] [G loss: 0.421838]\n",
      "epoch:16 step:15751 [D loss: 0.252405, acc.: 55.47%] [G loss: 0.406484]\n",
      "epoch:16 step:15752 [D loss: 0.229758, acc.: 62.50%] [G loss: 0.434531]\n",
      "epoch:16 step:15753 [D loss: 0.234487, acc.: 64.84%] [G loss: 0.393607]\n",
      "epoch:16 step:15754 [D loss: 0.238077, acc.: 58.59%] [G loss: 0.408820]\n",
      "epoch:16 step:15755 [D loss: 0.233531, acc.: 61.72%] [G loss: 0.441670]\n",
      "epoch:16 step:15756 [D loss: 0.224093, acc.: 57.81%] [G loss: 0.428690]\n",
      "epoch:16 step:15757 [D loss: 0.270374, acc.: 53.91%] [G loss: 0.417339]\n",
      "epoch:16 step:15758 [D loss: 0.222267, acc.: 64.84%] [G loss: 0.471484]\n",
      "epoch:16 step:15759 [D loss: 0.207553, acc.: 64.84%] [G loss: 0.463440]\n",
      "epoch:16 step:15760 [D loss: 0.231684, acc.: 60.16%] [G loss: 0.478023]\n",
      "epoch:16 step:15761 [D loss: 0.216478, acc.: 66.41%] [G loss: 0.495585]\n",
      "epoch:16 step:15762 [D loss: 0.244015, acc.: 62.50%] [G loss: 0.442089]\n",
      "epoch:16 step:15763 [D loss: 0.209676, acc.: 64.06%] [G loss: 0.470639]\n",
      "epoch:16 step:15764 [D loss: 0.243068, acc.: 59.38%] [G loss: 0.422071]\n",
      "epoch:16 step:15765 [D loss: 0.202151, acc.: 67.97%] [G loss: 0.454587]\n",
      "epoch:16 step:15766 [D loss: 0.222566, acc.: 66.41%] [G loss: 0.435317]\n",
      "epoch:16 step:15767 [D loss: 0.199355, acc.: 69.53%] [G loss: 0.472611]\n",
      "epoch:16 step:15768 [D loss: 0.234648, acc.: 58.59%] [G loss: 0.483460]\n",
      "epoch:16 step:15769 [D loss: 0.223856, acc.: 64.06%] [G loss: 0.424227]\n",
      "epoch:16 step:15770 [D loss: 0.228713, acc.: 60.94%] [G loss: 0.459729]\n",
      "epoch:16 step:15771 [D loss: 0.232287, acc.: 63.28%] [G loss: 0.429359]\n",
      "epoch:16 step:15772 [D loss: 0.224376, acc.: 60.94%] [G loss: 0.449481]\n",
      "epoch:16 step:15773 [D loss: 0.178715, acc.: 76.56%] [G loss: 0.519032]\n",
      "epoch:16 step:15774 [D loss: 0.191869, acc.: 69.53%] [G loss: 0.523875]\n",
      "epoch:16 step:15775 [D loss: 0.277360, acc.: 50.00%] [G loss: 0.471379]\n",
      "epoch:16 step:15776 [D loss: 0.252555, acc.: 59.38%] [G loss: 0.426566]\n",
      "epoch:16 step:15777 [D loss: 0.205956, acc.: 71.09%] [G loss: 0.415160]\n",
      "epoch:16 step:15778 [D loss: 0.208056, acc.: 66.41%] [G loss: 0.459455]\n",
      "epoch:16 step:15779 [D loss: 0.239266, acc.: 57.81%] [G loss: 0.422867]\n",
      "epoch:16 step:15780 [D loss: 0.259319, acc.: 58.59%] [G loss: 0.400449]\n",
      "epoch:16 step:15781 [D loss: 0.219016, acc.: 60.16%] [G loss: 0.420250]\n",
      "epoch:16 step:15782 [D loss: 0.223810, acc.: 64.06%] [G loss: 0.446711]\n",
      "epoch:16 step:15783 [D loss: 0.267598, acc.: 53.12%] [G loss: 0.418469]\n",
      "epoch:16 step:15784 [D loss: 0.226569, acc.: 63.28%] [G loss: 0.422656]\n",
      "epoch:16 step:15785 [D loss: 0.233474, acc.: 57.81%] [G loss: 0.492993]\n",
      "epoch:16 step:15786 [D loss: 0.225456, acc.: 60.16%] [G loss: 0.487151]\n",
      "epoch:16 step:15787 [D loss: 0.249143, acc.: 52.34%] [G loss: 0.446890]\n",
      "epoch:16 step:15788 [D loss: 0.194725, acc.: 72.66%] [G loss: 0.491078]\n",
      "epoch:16 step:15789 [D loss: 0.248172, acc.: 57.03%] [G loss: 0.416696]\n",
      "epoch:16 step:15790 [D loss: 0.247698, acc.: 57.03%] [G loss: 0.396365]\n",
      "epoch:16 step:15791 [D loss: 0.245905, acc.: 61.72%] [G loss: 0.408307]\n",
      "epoch:16 step:15792 [D loss: 0.260604, acc.: 46.88%] [G loss: 0.426755]\n",
      "epoch:16 step:15793 [D loss: 0.221762, acc.: 64.06%] [G loss: 0.476912]\n",
      "epoch:16 step:15794 [D loss: 0.215808, acc.: 64.84%] [G loss: 0.492296]\n",
      "epoch:16 step:15795 [D loss: 0.199145, acc.: 71.09%] [G loss: 0.510791]\n",
      "epoch:16 step:15796 [D loss: 0.234246, acc.: 61.72%] [G loss: 0.456845]\n",
      "epoch:16 step:15797 [D loss: 0.208142, acc.: 67.97%] [G loss: 0.453794]\n",
      "epoch:16 step:15798 [D loss: 0.213575, acc.: 67.19%] [G loss: 0.420413]\n",
      "epoch:16 step:15799 [D loss: 0.229005, acc.: 62.50%] [G loss: 0.442746]\n",
      "epoch:16 step:15800 [D loss: 0.259374, acc.: 48.44%] [G loss: 0.385929]\n",
      "epoch:16 step:15801 [D loss: 0.224491, acc.: 62.50%] [G loss: 0.441340]\n",
      "epoch:16 step:15802 [D loss: 0.218919, acc.: 64.06%] [G loss: 0.443130]\n",
      "epoch:16 step:15803 [D loss: 0.231943, acc.: 60.16%] [G loss: 0.452489]\n",
      "epoch:16 step:15804 [D loss: 0.249892, acc.: 61.72%] [G loss: 0.379628]\n",
      "epoch:16 step:15805 [D loss: 0.207771, acc.: 66.41%] [G loss: 0.450102]\n",
      "epoch:16 step:15806 [D loss: 0.234606, acc.: 64.84%] [G loss: 0.419095]\n",
      "epoch:16 step:15807 [D loss: 0.221276, acc.: 66.41%] [G loss: 0.438308]\n",
      "epoch:16 step:15808 [D loss: 0.227509, acc.: 57.03%] [G loss: 0.430704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15809 [D loss: 0.239174, acc.: 60.94%] [G loss: 0.467128]\n",
      "epoch:16 step:15810 [D loss: 0.268919, acc.: 51.56%] [G loss: 0.431959]\n",
      "epoch:16 step:15811 [D loss: 0.206366, acc.: 66.41%] [G loss: 0.438746]\n",
      "epoch:16 step:15812 [D loss: 0.265141, acc.: 52.34%] [G loss: 0.406512]\n",
      "epoch:16 step:15813 [D loss: 0.222811, acc.: 64.84%] [G loss: 0.441826]\n",
      "epoch:16 step:15814 [D loss: 0.206768, acc.: 67.19%] [G loss: 0.458157]\n",
      "epoch:16 step:15815 [D loss: 0.202689, acc.: 72.66%] [G loss: 0.447046]\n",
      "epoch:16 step:15816 [D loss: 0.249677, acc.: 55.47%] [G loss: 0.412842]\n",
      "epoch:16 step:15817 [D loss: 0.215779, acc.: 60.94%] [G loss: 0.450705]\n",
      "epoch:16 step:15818 [D loss: 0.226842, acc.: 59.38%] [G loss: 0.435859]\n",
      "epoch:16 step:15819 [D loss: 0.246405, acc.: 53.91%] [G loss: 0.451101]\n",
      "epoch:16 step:15820 [D loss: 0.248712, acc.: 57.81%] [G loss: 0.402576]\n",
      "epoch:16 step:15821 [D loss: 0.240879, acc.: 57.81%] [G loss: 0.425404]\n",
      "epoch:16 step:15822 [D loss: 0.239739, acc.: 62.50%] [G loss: 0.418360]\n",
      "epoch:16 step:15823 [D loss: 0.217233, acc.: 64.84%] [G loss: 0.433458]\n",
      "epoch:16 step:15824 [D loss: 0.222581, acc.: 65.62%] [G loss: 0.428663]\n",
      "epoch:16 step:15825 [D loss: 0.211356, acc.: 69.53%] [G loss: 0.451815]\n",
      "epoch:16 step:15826 [D loss: 0.228574, acc.: 57.81%] [G loss: 0.455603]\n",
      "epoch:16 step:15827 [D loss: 0.212350, acc.: 67.97%] [G loss: 0.422443]\n",
      "epoch:16 step:15828 [D loss: 0.239536, acc.: 58.59%] [G loss: 0.416781]\n",
      "epoch:16 step:15829 [D loss: 0.205953, acc.: 71.09%] [G loss: 0.441462]\n",
      "epoch:16 step:15830 [D loss: 0.208653, acc.: 69.53%] [G loss: 0.454884]\n",
      "epoch:16 step:15831 [D loss: 0.209241, acc.: 63.28%] [G loss: 0.439288]\n",
      "epoch:16 step:15832 [D loss: 0.206783, acc.: 68.75%] [G loss: 0.448181]\n",
      "epoch:16 step:15833 [D loss: 0.215263, acc.: 63.28%] [G loss: 0.444016]\n",
      "epoch:16 step:15834 [D loss: 0.197359, acc.: 69.53%] [G loss: 0.418210]\n",
      "epoch:16 step:15835 [D loss: 0.240554, acc.: 59.38%] [G loss: 0.453991]\n",
      "epoch:16 step:15836 [D loss: 0.248704, acc.: 53.12%] [G loss: 0.453841]\n",
      "epoch:16 step:15837 [D loss: 0.203300, acc.: 66.41%] [G loss: 0.503591]\n",
      "epoch:16 step:15838 [D loss: 0.250426, acc.: 52.34%] [G loss: 0.413575]\n",
      "epoch:16 step:15839 [D loss: 0.247473, acc.: 59.38%] [G loss: 0.423488]\n",
      "epoch:16 step:15840 [D loss: 0.232457, acc.: 61.72%] [G loss: 0.394672]\n",
      "epoch:16 step:15841 [D loss: 0.204248, acc.: 68.75%] [G loss: 0.431469]\n",
      "epoch:16 step:15842 [D loss: 0.265415, acc.: 53.12%] [G loss: 0.423798]\n",
      "epoch:16 step:15843 [D loss: 0.256689, acc.: 54.69%] [G loss: 0.428422]\n",
      "epoch:16 step:15844 [D loss: 0.199568, acc.: 67.97%] [G loss: 0.478761]\n",
      "epoch:16 step:15845 [D loss: 0.225262, acc.: 64.06%] [G loss: 0.467290]\n",
      "epoch:16 step:15846 [D loss: 0.229578, acc.: 59.38%] [G loss: 0.444794]\n",
      "epoch:16 step:15847 [D loss: 0.240821, acc.: 52.34%] [G loss: 0.443750]\n",
      "epoch:16 step:15848 [D loss: 0.210528, acc.: 65.62%] [G loss: 0.464553]\n",
      "epoch:16 step:15849 [D loss: 0.221869, acc.: 64.06%] [G loss: 0.421991]\n",
      "epoch:16 step:15850 [D loss: 0.290158, acc.: 41.41%] [G loss: 0.346593]\n",
      "epoch:16 step:15851 [D loss: 0.230778, acc.: 64.06%] [G loss: 0.412183]\n",
      "epoch:16 step:15852 [D loss: 0.203385, acc.: 71.88%] [G loss: 0.464107]\n",
      "epoch:16 step:15853 [D loss: 0.251438, acc.: 55.47%] [G loss: 0.436948]\n",
      "epoch:16 step:15854 [D loss: 0.223323, acc.: 62.50%] [G loss: 0.424223]\n",
      "epoch:16 step:15855 [D loss: 0.226420, acc.: 60.94%] [G loss: 0.405920]\n",
      "epoch:16 step:15856 [D loss: 0.229681, acc.: 62.50%] [G loss: 0.394834]\n",
      "epoch:16 step:15857 [D loss: 0.235844, acc.: 58.59%] [G loss: 0.425198]\n",
      "epoch:16 step:15858 [D loss: 0.238292, acc.: 53.91%] [G loss: 0.366070]\n",
      "epoch:16 step:15859 [D loss: 0.243466, acc.: 56.25%] [G loss: 0.409785]\n",
      "epoch:16 step:15860 [D loss: 0.229096, acc.: 60.94%] [G loss: 0.399724]\n",
      "epoch:16 step:15861 [D loss: 0.248975, acc.: 52.34%] [G loss: 0.408408]\n",
      "epoch:16 step:15862 [D loss: 0.221124, acc.: 60.94%] [G loss: 0.437012]\n",
      "epoch:16 step:15863 [D loss: 0.204138, acc.: 64.84%] [G loss: 0.478354]\n",
      "epoch:16 step:15864 [D loss: 0.240170, acc.: 64.06%] [G loss: 0.418871]\n",
      "epoch:16 step:15865 [D loss: 0.262676, acc.: 57.03%] [G loss: 0.406592]\n",
      "epoch:16 step:15866 [D loss: 0.234911, acc.: 57.03%] [G loss: 0.437321]\n",
      "epoch:16 step:15867 [D loss: 0.210733, acc.: 71.09%] [G loss: 0.456252]\n",
      "epoch:16 step:15868 [D loss: 0.244051, acc.: 63.28%] [G loss: 0.436942]\n",
      "epoch:16 step:15869 [D loss: 0.240504, acc.: 57.81%] [G loss: 0.421553]\n",
      "epoch:16 step:15870 [D loss: 0.230309, acc.: 60.94%] [G loss: 0.443977]\n",
      "epoch:16 step:15871 [D loss: 0.230218, acc.: 58.59%] [G loss: 0.431836]\n",
      "epoch:16 step:15872 [D loss: 0.249392, acc.: 56.25%] [G loss: 0.394590]\n",
      "epoch:16 step:15873 [D loss: 0.223356, acc.: 59.38%] [G loss: 0.435956]\n",
      "epoch:16 step:15874 [D loss: 0.233526, acc.: 64.06%] [G loss: 0.432835]\n",
      "epoch:16 step:15875 [D loss: 0.234469, acc.: 60.94%] [G loss: 0.440556]\n",
      "epoch:16 step:15876 [D loss: 0.187926, acc.: 71.09%] [G loss: 0.471043]\n",
      "epoch:16 step:15877 [D loss: 0.224552, acc.: 64.06%] [G loss: 0.481115]\n",
      "epoch:16 step:15878 [D loss: 0.197319, acc.: 67.97%] [G loss: 0.462130]\n",
      "epoch:16 step:15879 [D loss: 0.215313, acc.: 63.28%] [G loss: 0.473628]\n",
      "epoch:16 step:15880 [D loss: 0.244281, acc.: 59.38%] [G loss: 0.459535]\n",
      "epoch:16 step:15881 [D loss: 0.237962, acc.: 60.94%] [G loss: 0.449443]\n",
      "epoch:16 step:15882 [D loss: 0.217190, acc.: 61.72%] [G loss: 0.436594]\n",
      "epoch:16 step:15883 [D loss: 0.240527, acc.: 60.16%] [G loss: 0.437332]\n",
      "epoch:16 step:15884 [D loss: 0.258503, acc.: 50.78%] [G loss: 0.378691]\n",
      "epoch:16 step:15885 [D loss: 0.221892, acc.: 67.19%] [G loss: 0.410428]\n",
      "epoch:16 step:15886 [D loss: 0.209045, acc.: 67.19%] [G loss: 0.446743]\n",
      "epoch:16 step:15887 [D loss: 0.220597, acc.: 63.28%] [G loss: 0.422044]\n",
      "epoch:16 step:15888 [D loss: 0.213749, acc.: 68.75%] [G loss: 0.491586]\n",
      "epoch:16 step:15889 [D loss: 0.210972, acc.: 67.19%] [G loss: 0.493186]\n",
      "epoch:16 step:15890 [D loss: 0.211769, acc.: 67.19%] [G loss: 0.471171]\n",
      "epoch:16 step:15891 [D loss: 0.177195, acc.: 77.34%] [G loss: 0.478904]\n",
      "epoch:16 step:15892 [D loss: 0.209257, acc.: 64.84%] [G loss: 0.456961]\n",
      "epoch:16 step:15893 [D loss: 0.231392, acc.: 60.94%] [G loss: 0.423801]\n",
      "epoch:16 step:15894 [D loss: 0.242756, acc.: 60.94%] [G loss: 0.449486]\n",
      "epoch:16 step:15895 [D loss: 0.221877, acc.: 62.50%] [G loss: 0.433585]\n",
      "epoch:16 step:15896 [D loss: 0.239714, acc.: 56.25%] [G loss: 0.442697]\n",
      "epoch:16 step:15897 [D loss: 0.196618, acc.: 74.22%] [G loss: 0.443920]\n",
      "epoch:16 step:15898 [D loss: 0.245716, acc.: 57.81%] [G loss: 0.512369]\n",
      "epoch:16 step:15899 [D loss: 0.254322, acc.: 58.59%] [G loss: 0.443020]\n",
      "epoch:16 step:15900 [D loss: 0.219356, acc.: 70.31%] [G loss: 0.437980]\n",
      "epoch:16 step:15901 [D loss: 0.186596, acc.: 75.00%] [G loss: 0.452205]\n",
      "epoch:16 step:15902 [D loss: 0.211316, acc.: 67.19%] [G loss: 0.433271]\n",
      "epoch:16 step:15903 [D loss: 0.206268, acc.: 69.53%] [G loss: 0.476666]\n",
      "epoch:16 step:15904 [D loss: 0.212285, acc.: 68.75%] [G loss: 0.448361]\n",
      "epoch:16 step:15905 [D loss: 0.198727, acc.: 69.53%] [G loss: 0.499432]\n",
      "epoch:16 step:15906 [D loss: 0.225288, acc.: 57.81%] [G loss: 0.479183]\n",
      "epoch:16 step:15907 [D loss: 0.263088, acc.: 57.03%] [G loss: 0.399326]\n",
      "epoch:16 step:15908 [D loss: 0.232017, acc.: 56.25%] [G loss: 0.386826]\n",
      "epoch:16 step:15909 [D loss: 0.217891, acc.: 64.06%] [G loss: 0.455414]\n",
      "epoch:16 step:15910 [D loss: 0.189425, acc.: 72.66%] [G loss: 0.465998]\n",
      "epoch:16 step:15911 [D loss: 0.191257, acc.: 67.97%] [G loss: 0.522796]\n",
      "epoch:16 step:15912 [D loss: 0.255239, acc.: 55.47%] [G loss: 0.455053]\n",
      "epoch:16 step:15913 [D loss: 0.190108, acc.: 66.41%] [G loss: 0.546408]\n",
      "epoch:16 step:15914 [D loss: 0.247481, acc.: 57.03%] [G loss: 0.452090]\n",
      "epoch:16 step:15915 [D loss: 0.213555, acc.: 68.75%] [G loss: 0.430334]\n",
      "epoch:16 step:15916 [D loss: 0.170216, acc.: 75.00%] [G loss: 0.475019]\n",
      "epoch:16 step:15917 [D loss: 0.196765, acc.: 67.97%] [G loss: 0.459833]\n",
      "epoch:16 step:15918 [D loss: 0.174727, acc.: 78.91%] [G loss: 0.528154]\n",
      "epoch:16 step:15919 [D loss: 0.193964, acc.: 64.84%] [G loss: 0.481049]\n",
      "epoch:16 step:15920 [D loss: 0.331588, acc.: 50.78%] [G loss: 0.500054]\n",
      "epoch:16 step:15921 [D loss: 0.200324, acc.: 65.62%] [G loss: 0.587139]\n",
      "epoch:16 step:15922 [D loss: 0.224380, acc.: 67.19%] [G loss: 0.572433]\n",
      "epoch:16 step:15923 [D loss: 0.246934, acc.: 60.94%] [G loss: 0.494213]\n",
      "epoch:16 step:15924 [D loss: 0.286544, acc.: 48.44%] [G loss: 0.421858]\n",
      "epoch:16 step:15925 [D loss: 0.217480, acc.: 64.84%] [G loss: 0.443817]\n",
      "epoch:16 step:15926 [D loss: 0.243709, acc.: 60.94%] [G loss: 0.454018]\n",
      "epoch:16 step:15927 [D loss: 0.205056, acc.: 67.19%] [G loss: 0.452877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15928 [D loss: 0.177340, acc.: 75.78%] [G loss: 0.512308]\n",
      "epoch:16 step:15929 [D loss: 0.183052, acc.: 73.44%] [G loss: 0.516000]\n",
      "epoch:17 step:15930 [D loss: 0.246422, acc.: 63.28%] [G loss: 0.447635]\n",
      "epoch:17 step:15931 [D loss: 0.240224, acc.: 60.94%] [G loss: 0.455036]\n",
      "epoch:17 step:15932 [D loss: 0.252305, acc.: 60.16%] [G loss: 0.425957]\n",
      "epoch:17 step:15933 [D loss: 0.246960, acc.: 59.38%] [G loss: 0.431978]\n",
      "epoch:17 step:15934 [D loss: 0.229755, acc.: 59.38%] [G loss: 0.443247]\n",
      "epoch:17 step:15935 [D loss: 0.233516, acc.: 57.81%] [G loss: 0.462524]\n",
      "epoch:17 step:15936 [D loss: 0.233132, acc.: 55.47%] [G loss: 0.415576]\n",
      "epoch:17 step:15937 [D loss: 0.228146, acc.: 63.28%] [G loss: 0.404912]\n",
      "epoch:17 step:15938 [D loss: 0.196550, acc.: 68.75%] [G loss: 0.460498]\n",
      "epoch:17 step:15939 [D loss: 0.199278, acc.: 70.31%] [G loss: 0.511170]\n",
      "epoch:17 step:15940 [D loss: 0.239429, acc.: 57.03%] [G loss: 0.473956]\n",
      "epoch:17 step:15941 [D loss: 0.211105, acc.: 65.62%] [G loss: 0.472838]\n",
      "epoch:17 step:15942 [D loss: 0.184418, acc.: 74.22%] [G loss: 0.485685]\n",
      "epoch:17 step:15943 [D loss: 0.207337, acc.: 68.75%] [G loss: 0.457102]\n",
      "epoch:17 step:15944 [D loss: 0.197825, acc.: 72.66%] [G loss: 0.493972]\n",
      "epoch:17 step:15945 [D loss: 0.219538, acc.: 67.19%] [G loss: 0.468496]\n",
      "epoch:17 step:15946 [D loss: 0.241999, acc.: 63.28%] [G loss: 0.471851]\n",
      "epoch:17 step:15947 [D loss: 0.228612, acc.: 61.72%] [G loss: 0.417451]\n",
      "epoch:17 step:15948 [D loss: 0.252038, acc.: 57.03%] [G loss: 0.393974]\n",
      "epoch:17 step:15949 [D loss: 0.237704, acc.: 63.28%] [G loss: 0.459261]\n",
      "epoch:17 step:15950 [D loss: 0.236115, acc.: 59.38%] [G loss: 0.468732]\n",
      "epoch:17 step:15951 [D loss: 0.188583, acc.: 71.09%] [G loss: 0.505941]\n",
      "epoch:17 step:15952 [D loss: 0.248611, acc.: 54.69%] [G loss: 0.389757]\n",
      "epoch:17 step:15953 [D loss: 0.220374, acc.: 64.06%] [G loss: 0.384365]\n",
      "epoch:17 step:15954 [D loss: 0.215178, acc.: 64.06%] [G loss: 0.425488]\n",
      "epoch:17 step:15955 [D loss: 0.255471, acc.: 53.91%] [G loss: 0.434316]\n",
      "epoch:17 step:15956 [D loss: 0.225410, acc.: 60.16%] [G loss: 0.492658]\n",
      "epoch:17 step:15957 [D loss: 0.237021, acc.: 57.03%] [G loss: 0.414995]\n",
      "epoch:17 step:15958 [D loss: 0.220325, acc.: 62.50%] [G loss: 0.437458]\n",
      "epoch:17 step:15959 [D loss: 0.227895, acc.: 59.38%] [G loss: 0.437112]\n",
      "epoch:17 step:15960 [D loss: 0.253558, acc.: 55.47%] [G loss: 0.432284]\n",
      "epoch:17 step:15961 [D loss: 0.219398, acc.: 65.62%] [G loss: 0.438206]\n",
      "epoch:17 step:15962 [D loss: 0.221882, acc.: 66.41%] [G loss: 0.416425]\n",
      "epoch:17 step:15963 [D loss: 0.246881, acc.: 55.47%] [G loss: 0.423860]\n",
      "epoch:17 step:15964 [D loss: 0.218850, acc.: 61.72%] [G loss: 0.430919]\n",
      "epoch:17 step:15965 [D loss: 0.193329, acc.: 71.09%] [G loss: 0.427861]\n",
      "epoch:17 step:15966 [D loss: 0.227423, acc.: 63.28%] [G loss: 0.430373]\n",
      "epoch:17 step:15967 [D loss: 0.261200, acc.: 58.59%] [G loss: 0.424948]\n",
      "epoch:17 step:15968 [D loss: 0.222103, acc.: 60.16%] [G loss: 0.448406]\n",
      "epoch:17 step:15969 [D loss: 0.188919, acc.: 75.00%] [G loss: 0.459370]\n",
      "epoch:17 step:15970 [D loss: 0.236157, acc.: 62.50%] [G loss: 0.446672]\n",
      "epoch:17 step:15971 [D loss: 0.202523, acc.: 67.97%] [G loss: 0.446254]\n",
      "epoch:17 step:15972 [D loss: 0.208481, acc.: 66.41%] [G loss: 0.472754]\n",
      "epoch:17 step:15973 [D loss: 0.259041, acc.: 58.59%] [G loss: 0.424374]\n",
      "epoch:17 step:15974 [D loss: 0.233643, acc.: 58.59%] [G loss: 0.479591]\n",
      "epoch:17 step:15975 [D loss: 0.236639, acc.: 58.59%] [G loss: 0.446523]\n",
      "epoch:17 step:15976 [D loss: 0.230658, acc.: 58.59%] [G loss: 0.443416]\n",
      "epoch:17 step:15977 [D loss: 0.208038, acc.: 66.41%] [G loss: 0.461004]\n",
      "epoch:17 step:15978 [D loss: 0.205087, acc.: 65.62%] [G loss: 0.438124]\n",
      "epoch:17 step:15979 [D loss: 0.217220, acc.: 66.41%] [G loss: 0.467874]\n",
      "epoch:17 step:15980 [D loss: 0.249123, acc.: 54.69%] [G loss: 0.400339]\n",
      "epoch:17 step:15981 [D loss: 0.219452, acc.: 66.41%] [G loss: 0.460832]\n",
      "epoch:17 step:15982 [D loss: 0.215234, acc.: 68.75%] [G loss: 0.443255]\n",
      "epoch:17 step:15983 [D loss: 0.212664, acc.: 67.19%] [G loss: 0.539276]\n",
      "epoch:17 step:15984 [D loss: 0.230354, acc.: 60.16%] [G loss: 0.438718]\n",
      "epoch:17 step:15985 [D loss: 0.218195, acc.: 68.75%] [G loss: 0.441066]\n",
      "epoch:17 step:15986 [D loss: 0.231030, acc.: 62.50%] [G loss: 0.452174]\n",
      "epoch:17 step:15987 [D loss: 0.221399, acc.: 60.94%] [G loss: 0.419327]\n",
      "epoch:17 step:15988 [D loss: 0.210112, acc.: 65.62%] [G loss: 0.483240]\n",
      "epoch:17 step:15989 [D loss: 0.229713, acc.: 60.94%] [G loss: 0.404290]\n",
      "epoch:17 step:15990 [D loss: 0.245283, acc.: 57.03%] [G loss: 0.398365]\n",
      "epoch:17 step:15991 [D loss: 0.215733, acc.: 62.50%] [G loss: 0.426214]\n",
      "epoch:17 step:15992 [D loss: 0.215351, acc.: 66.41%] [G loss: 0.431555]\n",
      "epoch:17 step:15993 [D loss: 0.219246, acc.: 63.28%] [G loss: 0.428507]\n",
      "epoch:17 step:15994 [D loss: 0.239581, acc.: 57.03%] [G loss: 0.393693]\n",
      "epoch:17 step:15995 [D loss: 0.232474, acc.: 63.28%] [G loss: 0.426984]\n",
      "epoch:17 step:15996 [D loss: 0.212421, acc.: 64.06%] [G loss: 0.427094]\n",
      "epoch:17 step:15997 [D loss: 0.236470, acc.: 60.16%] [G loss: 0.429290]\n",
      "epoch:17 step:15998 [D loss: 0.190703, acc.: 77.34%] [G loss: 0.466787]\n",
      "epoch:17 step:15999 [D loss: 0.180523, acc.: 77.34%] [G loss: 0.478291]\n",
      "epoch:17 step:16000 [D loss: 0.252530, acc.: 56.25%] [G loss: 0.411308]\n",
      "epoch:17 step:16001 [D loss: 0.228680, acc.: 60.16%] [G loss: 0.387619]\n",
      "epoch:17 step:16002 [D loss: 0.233565, acc.: 58.59%] [G loss: 0.411937]\n",
      "epoch:17 step:16003 [D loss: 0.186375, acc.: 75.78%] [G loss: 0.420679]\n",
      "epoch:17 step:16004 [D loss: 0.209208, acc.: 67.97%] [G loss: 0.436554]\n",
      "epoch:17 step:16005 [D loss: 0.215418, acc.: 64.84%] [G loss: 0.464623]\n",
      "epoch:17 step:16006 [D loss: 0.177645, acc.: 73.44%] [G loss: 0.534697]\n",
      "epoch:17 step:16007 [D loss: 0.275474, acc.: 56.25%] [G loss: 0.462254]\n",
      "epoch:17 step:16008 [D loss: 0.245271, acc.: 60.94%] [G loss: 0.418675]\n",
      "epoch:17 step:16009 [D loss: 0.220337, acc.: 67.19%] [G loss: 0.416130]\n",
      "epoch:17 step:16010 [D loss: 0.222497, acc.: 61.72%] [G loss: 0.427976]\n",
      "epoch:17 step:16011 [D loss: 0.192424, acc.: 71.09%] [G loss: 0.434264]\n",
      "epoch:17 step:16012 [D loss: 0.198126, acc.: 69.53%] [G loss: 0.450858]\n",
      "epoch:17 step:16013 [D loss: 0.217823, acc.: 64.84%] [G loss: 0.485993]\n",
      "epoch:17 step:16014 [D loss: 0.231702, acc.: 64.84%] [G loss: 0.493251]\n",
      "epoch:17 step:16015 [D loss: 0.246630, acc.: 56.25%] [G loss: 0.423746]\n",
      "epoch:17 step:16016 [D loss: 0.220121, acc.: 64.84%] [G loss: 0.439566]\n",
      "epoch:17 step:16017 [D loss: 0.224094, acc.: 64.06%] [G loss: 0.438458]\n",
      "epoch:17 step:16018 [D loss: 0.218910, acc.: 63.28%] [G loss: 0.434355]\n",
      "epoch:17 step:16019 [D loss: 0.212624, acc.: 67.19%] [G loss: 0.464283]\n",
      "epoch:17 step:16020 [D loss: 0.226398, acc.: 64.06%] [G loss: 0.442317]\n",
      "epoch:17 step:16021 [D loss: 0.191367, acc.: 75.78%] [G loss: 0.481857]\n",
      "epoch:17 step:16022 [D loss: 0.212065, acc.: 63.28%] [G loss: 0.467090]\n",
      "epoch:17 step:16023 [D loss: 0.226413, acc.: 64.06%] [G loss: 0.474938]\n",
      "epoch:17 step:16024 [D loss: 0.225502, acc.: 63.28%] [G loss: 0.454448]\n",
      "epoch:17 step:16025 [D loss: 0.199200, acc.: 71.09%] [G loss: 0.433410]\n",
      "epoch:17 step:16026 [D loss: 0.207998, acc.: 65.62%] [G loss: 0.513979]\n",
      "epoch:17 step:16027 [D loss: 0.216302, acc.: 63.28%] [G loss: 0.471720]\n",
      "epoch:17 step:16028 [D loss: 0.226479, acc.: 61.72%] [G loss: 0.532172]\n",
      "epoch:17 step:16029 [D loss: 0.198939, acc.: 71.88%] [G loss: 0.472955]\n",
      "epoch:17 step:16030 [D loss: 0.217175, acc.: 69.53%] [G loss: 0.493172]\n",
      "epoch:17 step:16031 [D loss: 0.226809, acc.: 64.06%] [G loss: 0.466011]\n",
      "epoch:17 step:16032 [D loss: 0.249724, acc.: 57.81%] [G loss: 0.392381]\n",
      "epoch:17 step:16033 [D loss: 0.235619, acc.: 57.03%] [G loss: 0.410101]\n",
      "epoch:17 step:16034 [D loss: 0.236672, acc.: 57.81%] [G loss: 0.419538]\n",
      "epoch:17 step:16035 [D loss: 0.212684, acc.: 64.84%] [G loss: 0.430058]\n",
      "epoch:17 step:16036 [D loss: 0.219845, acc.: 64.84%] [G loss: 0.479091]\n",
      "epoch:17 step:16037 [D loss: 0.265451, acc.: 53.91%] [G loss: 0.480449]\n",
      "epoch:17 step:16038 [D loss: 0.259896, acc.: 57.03%] [G loss: 0.412750]\n",
      "epoch:17 step:16039 [D loss: 0.246490, acc.: 60.94%] [G loss: 0.399041]\n",
      "epoch:17 step:16040 [D loss: 0.210180, acc.: 65.62%] [G loss: 0.418011]\n",
      "epoch:17 step:16041 [D loss: 0.212990, acc.: 69.53%] [G loss: 0.411007]\n",
      "epoch:17 step:16042 [D loss: 0.228943, acc.: 60.16%] [G loss: 0.458137]\n",
      "epoch:17 step:16043 [D loss: 0.195262, acc.: 71.09%] [G loss: 0.499147]\n",
      "epoch:17 step:16044 [D loss: 0.212583, acc.: 69.53%] [G loss: 0.487536]\n",
      "epoch:17 step:16045 [D loss: 0.205392, acc.: 67.19%] [G loss: 0.512263]\n",
      "epoch:17 step:16046 [D loss: 0.195426, acc.: 67.97%] [G loss: 0.499151]\n",
      "epoch:17 step:16047 [D loss: 0.195144, acc.: 71.88%] [G loss: 0.482575]\n",
      "epoch:17 step:16048 [D loss: 0.187406, acc.: 70.31%] [G loss: 0.474133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16049 [D loss: 0.256027, acc.: 54.69%] [G loss: 0.503601]\n",
      "epoch:17 step:16050 [D loss: 0.237598, acc.: 57.81%] [G loss: 0.509680]\n",
      "epoch:17 step:16051 [D loss: 0.195190, acc.: 69.53%] [G loss: 0.525967]\n",
      "epoch:17 step:16052 [D loss: 0.225945, acc.: 61.72%] [G loss: 0.480390]\n",
      "epoch:17 step:16053 [D loss: 0.248860, acc.: 55.47%] [G loss: 0.445173]\n",
      "epoch:17 step:16054 [D loss: 0.258817, acc.: 57.81%] [G loss: 0.411676]\n",
      "epoch:17 step:16055 [D loss: 0.228666, acc.: 61.72%] [G loss: 0.424284]\n",
      "epoch:17 step:16056 [D loss: 0.211287, acc.: 67.97%] [G loss: 0.468208]\n",
      "epoch:17 step:16057 [D loss: 0.232613, acc.: 57.81%] [G loss: 0.440297]\n",
      "epoch:17 step:16058 [D loss: 0.254389, acc.: 57.81%] [G loss: 0.392740]\n",
      "epoch:17 step:16059 [D loss: 0.198743, acc.: 67.19%] [G loss: 0.453054]\n",
      "epoch:17 step:16060 [D loss: 0.208696, acc.: 68.75%] [G loss: 0.480001]\n",
      "epoch:17 step:16061 [D loss: 0.214531, acc.: 65.62%] [G loss: 0.445919]\n",
      "epoch:17 step:16062 [D loss: 0.279959, acc.: 50.00%] [G loss: 0.449307]\n",
      "epoch:17 step:16063 [D loss: 0.219394, acc.: 66.41%] [G loss: 0.438953]\n",
      "epoch:17 step:16064 [D loss: 0.224015, acc.: 60.94%] [G loss: 0.462572]\n",
      "epoch:17 step:16065 [D loss: 0.201484, acc.: 73.44%] [G loss: 0.473329]\n",
      "epoch:17 step:16066 [D loss: 0.267655, acc.: 56.25%] [G loss: 0.425497]\n",
      "epoch:17 step:16067 [D loss: 0.250085, acc.: 56.25%] [G loss: 0.401156]\n",
      "epoch:17 step:16068 [D loss: 0.220613, acc.: 60.16%] [G loss: 0.414916]\n",
      "epoch:17 step:16069 [D loss: 0.232153, acc.: 60.94%] [G loss: 0.418986]\n",
      "epoch:17 step:16070 [D loss: 0.216133, acc.: 66.41%] [G loss: 0.429983]\n",
      "epoch:17 step:16071 [D loss: 0.238061, acc.: 58.59%] [G loss: 0.409914]\n",
      "epoch:17 step:16072 [D loss: 0.225995, acc.: 58.59%] [G loss: 0.393884]\n",
      "epoch:17 step:16073 [D loss: 0.220062, acc.: 65.62%] [G loss: 0.401418]\n",
      "epoch:17 step:16074 [D loss: 0.230097, acc.: 60.16%] [G loss: 0.433275]\n",
      "epoch:17 step:16075 [D loss: 0.230898, acc.: 61.72%] [G loss: 0.450967]\n",
      "epoch:17 step:16076 [D loss: 0.226402, acc.: 60.94%] [G loss: 0.420620]\n",
      "epoch:17 step:16077 [D loss: 0.234311, acc.: 64.84%] [G loss: 0.467594]\n",
      "epoch:17 step:16078 [D loss: 0.212599, acc.: 64.06%] [G loss: 0.423827]\n",
      "epoch:17 step:16079 [D loss: 0.275926, acc.: 49.22%] [G loss: 0.417843]\n",
      "epoch:17 step:16080 [D loss: 0.196194, acc.: 74.22%] [G loss: 0.411159]\n",
      "epoch:17 step:16081 [D loss: 0.243821, acc.: 60.16%] [G loss: 0.436083]\n",
      "epoch:17 step:16082 [D loss: 0.244236, acc.: 57.81%] [G loss: 0.438957]\n",
      "epoch:17 step:16083 [D loss: 0.212911, acc.: 62.50%] [G loss: 0.450935]\n",
      "epoch:17 step:16084 [D loss: 0.185537, acc.: 67.97%] [G loss: 0.472863]\n",
      "epoch:17 step:16085 [D loss: 0.195746, acc.: 71.09%] [G loss: 0.487803]\n",
      "epoch:17 step:16086 [D loss: 0.214731, acc.: 64.06%] [G loss: 0.431830]\n",
      "epoch:17 step:16087 [D loss: 0.237908, acc.: 56.25%] [G loss: 0.408383]\n",
      "epoch:17 step:16088 [D loss: 0.194216, acc.: 73.44%] [G loss: 0.443220]\n",
      "epoch:17 step:16089 [D loss: 0.270475, acc.: 57.03%] [G loss: 0.388084]\n",
      "epoch:17 step:16090 [D loss: 0.229282, acc.: 57.81%] [G loss: 0.419648]\n",
      "epoch:17 step:16091 [D loss: 0.225773, acc.: 64.84%] [G loss: 0.441543]\n",
      "epoch:17 step:16092 [D loss: 0.220067, acc.: 65.62%] [G loss: 0.491243]\n",
      "epoch:17 step:16093 [D loss: 0.217613, acc.: 64.06%] [G loss: 0.464546]\n",
      "epoch:17 step:16094 [D loss: 0.234003, acc.: 61.72%] [G loss: 0.430375]\n",
      "epoch:17 step:16095 [D loss: 0.246020, acc.: 53.91%] [G loss: 0.437283]\n",
      "epoch:17 step:16096 [D loss: 0.231379, acc.: 58.59%] [G loss: 0.426334]\n",
      "epoch:17 step:16097 [D loss: 0.218284, acc.: 66.41%] [G loss: 0.461269]\n",
      "epoch:17 step:16098 [D loss: 0.240107, acc.: 60.16%] [G loss: 0.435395]\n",
      "epoch:17 step:16099 [D loss: 0.250292, acc.: 52.34%] [G loss: 0.379214]\n",
      "epoch:17 step:16100 [D loss: 0.228533, acc.: 60.16%] [G loss: 0.389893]\n",
      "epoch:17 step:16101 [D loss: 0.224682, acc.: 68.75%] [G loss: 0.418328]\n",
      "epoch:17 step:16102 [D loss: 0.211144, acc.: 63.28%] [G loss: 0.460768]\n",
      "epoch:17 step:16103 [D loss: 0.238096, acc.: 55.47%] [G loss: 0.419246]\n",
      "epoch:17 step:16104 [D loss: 0.245059, acc.: 55.47%] [G loss: 0.439642]\n",
      "epoch:17 step:16105 [D loss: 0.235180, acc.: 61.72%] [G loss: 0.435152]\n",
      "epoch:17 step:16106 [D loss: 0.239784, acc.: 58.59%] [G loss: 0.375180]\n",
      "epoch:17 step:16107 [D loss: 0.225200, acc.: 59.38%] [G loss: 0.435489]\n",
      "epoch:17 step:16108 [D loss: 0.228766, acc.: 60.94%] [G loss: 0.434724]\n",
      "epoch:17 step:16109 [D loss: 0.236252, acc.: 59.38%] [G loss: 0.401873]\n",
      "epoch:17 step:16110 [D loss: 0.217460, acc.: 66.41%] [G loss: 0.437997]\n",
      "epoch:17 step:16111 [D loss: 0.230694, acc.: 56.25%] [G loss: 0.417931]\n",
      "epoch:17 step:16112 [D loss: 0.228271, acc.: 62.50%] [G loss: 0.424646]\n",
      "epoch:17 step:16113 [D loss: 0.230613, acc.: 60.94%] [G loss: 0.459817]\n",
      "epoch:17 step:16114 [D loss: 0.219575, acc.: 64.06%] [G loss: 0.438737]\n",
      "epoch:17 step:16115 [D loss: 0.235032, acc.: 58.59%] [G loss: 0.471746]\n",
      "epoch:17 step:16116 [D loss: 0.215420, acc.: 67.97%] [G loss: 0.420297]\n",
      "epoch:17 step:16117 [D loss: 0.243469, acc.: 58.59%] [G loss: 0.413594]\n",
      "epoch:17 step:16118 [D loss: 0.236279, acc.: 59.38%] [G loss: 0.417368]\n",
      "epoch:17 step:16119 [D loss: 0.220578, acc.: 64.84%] [G loss: 0.434007]\n",
      "epoch:17 step:16120 [D loss: 0.212695, acc.: 64.84%] [G loss: 0.459075]\n",
      "epoch:17 step:16121 [D loss: 0.211237, acc.: 67.97%] [G loss: 0.450039]\n",
      "epoch:17 step:16122 [D loss: 0.195868, acc.: 69.53%] [G loss: 0.436723]\n",
      "epoch:17 step:16123 [D loss: 0.206234, acc.: 67.97%] [G loss: 0.443601]\n",
      "epoch:17 step:16124 [D loss: 0.243535, acc.: 63.28%] [G loss: 0.467737]\n",
      "epoch:17 step:16125 [D loss: 0.266019, acc.: 53.12%] [G loss: 0.433124]\n",
      "epoch:17 step:16126 [D loss: 0.207208, acc.: 65.62%] [G loss: 0.450702]\n",
      "epoch:17 step:16127 [D loss: 0.204665, acc.: 71.09%] [G loss: 0.451182]\n",
      "epoch:17 step:16128 [D loss: 0.236827, acc.: 56.25%] [G loss: 0.433428]\n",
      "epoch:17 step:16129 [D loss: 0.217668, acc.: 62.50%] [G loss: 0.461895]\n",
      "epoch:17 step:16130 [D loss: 0.221487, acc.: 64.06%] [G loss: 0.464780]\n",
      "epoch:17 step:16131 [D loss: 0.240402, acc.: 59.38%] [G loss: 0.435679]\n",
      "epoch:17 step:16132 [D loss: 0.275033, acc.: 50.78%] [G loss: 0.425314]\n",
      "epoch:17 step:16133 [D loss: 0.219126, acc.: 65.62%] [G loss: 0.470546]\n",
      "epoch:17 step:16134 [D loss: 0.230680, acc.: 63.28%] [G loss: 0.461162]\n",
      "epoch:17 step:16135 [D loss: 0.209773, acc.: 68.75%] [G loss: 0.507115]\n",
      "epoch:17 step:16136 [D loss: 0.199369, acc.: 69.53%] [G loss: 0.448218]\n",
      "epoch:17 step:16137 [D loss: 0.209297, acc.: 64.84%] [G loss: 0.463096]\n",
      "epoch:17 step:16138 [D loss: 0.212168, acc.: 63.28%] [G loss: 0.447634]\n",
      "epoch:17 step:16139 [D loss: 0.265836, acc.: 53.12%] [G loss: 0.438391]\n",
      "epoch:17 step:16140 [D loss: 0.242059, acc.: 57.03%] [G loss: 0.451201]\n",
      "epoch:17 step:16141 [D loss: 0.225561, acc.: 60.16%] [G loss: 0.426083]\n",
      "epoch:17 step:16142 [D loss: 0.225322, acc.: 62.50%] [G loss: 0.416588]\n",
      "epoch:17 step:16143 [D loss: 0.237247, acc.: 59.38%] [G loss: 0.390520]\n",
      "epoch:17 step:16144 [D loss: 0.238683, acc.: 57.03%] [G loss: 0.395446]\n",
      "epoch:17 step:16145 [D loss: 0.202346, acc.: 64.84%] [G loss: 0.442940]\n",
      "epoch:17 step:16146 [D loss: 0.198752, acc.: 70.31%] [G loss: 0.457890]\n",
      "epoch:17 step:16147 [D loss: 0.204758, acc.: 65.62%] [G loss: 0.462809]\n",
      "epoch:17 step:16148 [D loss: 0.192220, acc.: 66.41%] [G loss: 0.505764]\n",
      "epoch:17 step:16149 [D loss: 0.258177, acc.: 59.38%] [G loss: 0.448836]\n",
      "epoch:17 step:16150 [D loss: 0.204041, acc.: 68.75%] [G loss: 0.455944]\n",
      "epoch:17 step:16151 [D loss: 0.214355, acc.: 64.06%] [G loss: 0.451666]\n",
      "epoch:17 step:16152 [D loss: 0.201568, acc.: 69.53%] [G loss: 0.471873]\n",
      "epoch:17 step:16153 [D loss: 0.254912, acc.: 57.81%] [G loss: 0.427230]\n",
      "epoch:17 step:16154 [D loss: 0.237791, acc.: 64.84%] [G loss: 0.373907]\n",
      "epoch:17 step:16155 [D loss: 0.233697, acc.: 56.25%] [G loss: 0.382847]\n",
      "epoch:17 step:16156 [D loss: 0.228456, acc.: 64.84%] [G loss: 0.433201]\n",
      "epoch:17 step:16157 [D loss: 0.233503, acc.: 60.16%] [G loss: 0.402934]\n",
      "epoch:17 step:16158 [D loss: 0.193745, acc.: 71.09%] [G loss: 0.444177]\n",
      "epoch:17 step:16159 [D loss: 0.201447, acc.: 68.75%] [G loss: 0.491164]\n",
      "epoch:17 step:16160 [D loss: 0.162607, acc.: 75.78%] [G loss: 0.563880]\n",
      "epoch:17 step:16161 [D loss: 0.175460, acc.: 74.22%] [G loss: 0.505695]\n",
      "epoch:17 step:16162 [D loss: 0.259833, acc.: 59.38%] [G loss: 0.443335]\n",
      "epoch:17 step:16163 [D loss: 0.256257, acc.: 56.25%] [G loss: 0.425824]\n",
      "epoch:17 step:16164 [D loss: 0.233911, acc.: 59.38%] [G loss: 0.435596]\n",
      "epoch:17 step:16165 [D loss: 0.229059, acc.: 65.62%] [G loss: 0.407302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16166 [D loss: 0.243437, acc.: 57.81%] [G loss: 0.413530]\n",
      "epoch:17 step:16167 [D loss: 0.209758, acc.: 66.41%] [G loss: 0.437035]\n",
      "epoch:17 step:16168 [D loss: 0.233544, acc.: 60.16%] [G loss: 0.396071]\n",
      "epoch:17 step:16169 [D loss: 0.236523, acc.: 60.16%] [G loss: 0.433432]\n",
      "epoch:17 step:16170 [D loss: 0.198715, acc.: 72.66%] [G loss: 0.447654]\n",
      "epoch:17 step:16171 [D loss: 0.201826, acc.: 71.09%] [G loss: 0.480010]\n",
      "epoch:17 step:16172 [D loss: 0.218159, acc.: 63.28%] [G loss: 0.452257]\n",
      "epoch:17 step:16173 [D loss: 0.218424, acc.: 64.84%] [G loss: 0.438581]\n",
      "epoch:17 step:16174 [D loss: 0.224718, acc.: 58.59%] [G loss: 0.463559]\n",
      "epoch:17 step:16175 [D loss: 0.211644, acc.: 64.84%] [G loss: 0.435033]\n",
      "epoch:17 step:16176 [D loss: 0.226628, acc.: 61.72%] [G loss: 0.452029]\n",
      "epoch:17 step:16177 [D loss: 0.202887, acc.: 71.09%] [G loss: 0.490521]\n",
      "epoch:17 step:16178 [D loss: 0.248301, acc.: 58.59%] [G loss: 0.444187]\n",
      "epoch:17 step:16179 [D loss: 0.295431, acc.: 48.44%] [G loss: 0.443529]\n",
      "epoch:17 step:16180 [D loss: 0.275274, acc.: 48.44%] [G loss: 0.447820]\n",
      "epoch:17 step:16181 [D loss: 0.232472, acc.: 58.59%] [G loss: 0.456287]\n",
      "epoch:17 step:16182 [D loss: 0.224910, acc.: 65.62%] [G loss: 0.413903]\n",
      "epoch:17 step:16183 [D loss: 0.231122, acc.: 59.38%] [G loss: 0.396555]\n",
      "epoch:17 step:16184 [D loss: 0.225396, acc.: 64.84%] [G loss: 0.390594]\n",
      "epoch:17 step:16185 [D loss: 0.223893, acc.: 61.72%] [G loss: 0.425889]\n",
      "epoch:17 step:16186 [D loss: 0.221370, acc.: 64.84%] [G loss: 0.420535]\n",
      "epoch:17 step:16187 [D loss: 0.204196, acc.: 72.66%] [G loss: 0.413279]\n",
      "epoch:17 step:16188 [D loss: 0.258185, acc.: 56.25%] [G loss: 0.426693]\n",
      "epoch:17 step:16189 [D loss: 0.223097, acc.: 56.25%] [G loss: 0.422896]\n",
      "epoch:17 step:16190 [D loss: 0.216267, acc.: 64.06%] [G loss: 0.436254]\n",
      "epoch:17 step:16191 [D loss: 0.206636, acc.: 65.62%] [G loss: 0.430934]\n",
      "epoch:17 step:16192 [D loss: 0.227765, acc.: 65.62%] [G loss: 0.441443]\n",
      "epoch:17 step:16193 [D loss: 0.206577, acc.: 71.88%] [G loss: 0.411786]\n",
      "epoch:17 step:16194 [D loss: 0.251409, acc.: 57.03%] [G loss: 0.409995]\n",
      "epoch:17 step:16195 [D loss: 0.231264, acc.: 57.81%] [G loss: 0.427203]\n",
      "epoch:17 step:16196 [D loss: 0.246498, acc.: 65.62%] [G loss: 0.407149]\n",
      "epoch:17 step:16197 [D loss: 0.232155, acc.: 60.94%] [G loss: 0.430148]\n",
      "epoch:17 step:16198 [D loss: 0.234076, acc.: 65.62%] [G loss: 0.397581]\n",
      "epoch:17 step:16199 [D loss: 0.193745, acc.: 72.66%] [G loss: 0.454057]\n",
      "epoch:17 step:16200 [D loss: 0.205662, acc.: 67.19%] [G loss: 0.433260]\n",
      "epoch:17 step:16201 [D loss: 0.238299, acc.: 59.38%] [G loss: 0.420992]\n",
      "epoch:17 step:16202 [D loss: 0.215070, acc.: 63.28%] [G loss: 0.450126]\n",
      "epoch:17 step:16203 [D loss: 0.212077, acc.: 64.06%] [G loss: 0.470503]\n",
      "epoch:17 step:16204 [D loss: 0.213610, acc.: 69.53%] [G loss: 0.456465]\n",
      "epoch:17 step:16205 [D loss: 0.200798, acc.: 66.41%] [G loss: 0.452778]\n",
      "epoch:17 step:16206 [D loss: 0.258803, acc.: 54.69%] [G loss: 0.415941]\n",
      "epoch:17 step:16207 [D loss: 0.246038, acc.: 57.81%] [G loss: 0.425646]\n",
      "epoch:17 step:16208 [D loss: 0.223932, acc.: 64.06%] [G loss: 0.454928]\n",
      "epoch:17 step:16209 [D loss: 0.207136, acc.: 71.88%] [G loss: 0.426327]\n",
      "epoch:17 step:16210 [D loss: 0.270316, acc.: 50.00%] [G loss: 0.360898]\n",
      "epoch:17 step:16211 [D loss: 0.227767, acc.: 57.81%] [G loss: 0.413226]\n",
      "epoch:17 step:16212 [D loss: 0.221422, acc.: 64.06%] [G loss: 0.425357]\n",
      "epoch:17 step:16213 [D loss: 0.224757, acc.: 64.06%] [G loss: 0.414367]\n",
      "epoch:17 step:16214 [D loss: 0.241517, acc.: 59.38%] [G loss: 0.438343]\n",
      "epoch:17 step:16215 [D loss: 0.224165, acc.: 64.84%] [G loss: 0.454131]\n",
      "epoch:17 step:16216 [D loss: 0.257421, acc.: 50.78%] [G loss: 0.470510]\n",
      "epoch:17 step:16217 [D loss: 0.226476, acc.: 63.28%] [G loss: 0.443432]\n",
      "epoch:17 step:16218 [D loss: 0.251403, acc.: 55.47%] [G loss: 0.435112]\n",
      "epoch:17 step:16219 [D loss: 0.224520, acc.: 61.72%] [G loss: 0.475071]\n",
      "epoch:17 step:16220 [D loss: 0.243372, acc.: 57.81%] [G loss: 0.423063]\n",
      "epoch:17 step:16221 [D loss: 0.224072, acc.: 62.50%] [G loss: 0.415493]\n",
      "epoch:17 step:16222 [D loss: 0.247417, acc.: 54.69%] [G loss: 0.420140]\n",
      "epoch:17 step:16223 [D loss: 0.223606, acc.: 64.84%] [G loss: 0.436422]\n",
      "epoch:17 step:16224 [D loss: 0.227014, acc.: 60.16%] [G loss: 0.410154]\n",
      "epoch:17 step:16225 [D loss: 0.208419, acc.: 66.41%] [G loss: 0.444763]\n",
      "epoch:17 step:16226 [D loss: 0.236672, acc.: 56.25%] [G loss: 0.414399]\n",
      "epoch:17 step:16227 [D loss: 0.211314, acc.: 64.84%] [G loss: 0.429099]\n",
      "epoch:17 step:16228 [D loss: 0.192301, acc.: 72.66%] [G loss: 0.490417]\n",
      "epoch:17 step:16229 [D loss: 0.222344, acc.: 64.06%] [G loss: 0.468274]\n",
      "epoch:17 step:16230 [D loss: 0.249800, acc.: 55.47%] [G loss: 0.467280]\n",
      "epoch:17 step:16231 [D loss: 0.219769, acc.: 64.06%] [G loss: 0.450743]\n",
      "epoch:17 step:16232 [D loss: 0.239628, acc.: 58.59%] [G loss: 0.452272]\n",
      "epoch:17 step:16233 [D loss: 0.217337, acc.: 64.06%] [G loss: 0.430963]\n",
      "epoch:17 step:16234 [D loss: 0.217537, acc.: 61.72%] [G loss: 0.428143]\n",
      "epoch:17 step:16235 [D loss: 0.212955, acc.: 67.19%] [G loss: 0.412230]\n",
      "epoch:17 step:16236 [D loss: 0.235278, acc.: 64.06%] [G loss: 0.408904]\n",
      "epoch:17 step:16237 [D loss: 0.212827, acc.: 67.19%] [G loss: 0.426715]\n",
      "epoch:17 step:16238 [D loss: 0.214263, acc.: 68.75%] [G loss: 0.426292]\n",
      "epoch:17 step:16239 [D loss: 0.205994, acc.: 67.97%] [G loss: 0.427661]\n",
      "epoch:17 step:16240 [D loss: 0.223123, acc.: 59.38%] [G loss: 0.412336]\n",
      "epoch:17 step:16241 [D loss: 0.159750, acc.: 79.69%] [G loss: 0.489957]\n",
      "epoch:17 step:16242 [D loss: 0.186247, acc.: 71.09%] [G loss: 0.451691]\n",
      "epoch:17 step:16243 [D loss: 0.182740, acc.: 74.22%] [G loss: 0.502273]\n",
      "epoch:17 step:16244 [D loss: 0.208567, acc.: 70.31%] [G loss: 0.519603]\n",
      "epoch:17 step:16245 [D loss: 0.250489, acc.: 59.38%] [G loss: 0.496737]\n",
      "epoch:17 step:16246 [D loss: 0.239290, acc.: 57.81%] [G loss: 0.413800]\n",
      "epoch:17 step:16247 [D loss: 0.220550, acc.: 57.81%] [G loss: 0.427660]\n",
      "epoch:17 step:16248 [D loss: 0.209132, acc.: 64.06%] [G loss: 0.440444]\n",
      "epoch:17 step:16249 [D loss: 0.208151, acc.: 68.75%] [G loss: 0.441105]\n",
      "epoch:17 step:16250 [D loss: 0.226176, acc.: 63.28%] [G loss: 0.421318]\n",
      "epoch:17 step:16251 [D loss: 0.206948, acc.: 67.19%] [G loss: 0.463267]\n",
      "epoch:17 step:16252 [D loss: 0.251232, acc.: 56.25%] [G loss: 0.434756]\n",
      "epoch:17 step:16253 [D loss: 0.235994, acc.: 61.72%] [G loss: 0.416018]\n",
      "epoch:17 step:16254 [D loss: 0.194443, acc.: 70.31%] [G loss: 0.477206]\n",
      "epoch:17 step:16255 [D loss: 0.216007, acc.: 71.09%] [G loss: 0.448039]\n",
      "epoch:17 step:16256 [D loss: 0.234141, acc.: 58.59%] [G loss: 0.437789]\n",
      "epoch:17 step:16257 [D loss: 0.224849, acc.: 63.28%] [G loss: 0.462612]\n",
      "epoch:17 step:16258 [D loss: 0.223756, acc.: 59.38%] [G loss: 0.445071]\n",
      "epoch:17 step:16259 [D loss: 0.232126, acc.: 64.84%] [G loss: 0.427043]\n",
      "epoch:17 step:16260 [D loss: 0.205260, acc.: 69.53%] [G loss: 0.438787]\n",
      "epoch:17 step:16261 [D loss: 0.184653, acc.: 77.34%] [G loss: 0.446935]\n",
      "epoch:17 step:16262 [D loss: 0.220585, acc.: 64.06%] [G loss: 0.406573]\n",
      "epoch:17 step:16263 [D loss: 0.214915, acc.: 67.97%] [G loss: 0.424058]\n",
      "epoch:17 step:16264 [D loss: 0.220034, acc.: 64.84%] [G loss: 0.492564]\n",
      "epoch:17 step:16265 [D loss: 0.215503, acc.: 65.62%] [G loss: 0.478549]\n",
      "epoch:17 step:16266 [D loss: 0.224068, acc.: 60.16%] [G loss: 0.490742]\n",
      "epoch:17 step:16267 [D loss: 0.217192, acc.: 63.28%] [G loss: 0.441669]\n",
      "epoch:17 step:16268 [D loss: 0.207156, acc.: 66.41%] [G loss: 0.455812]\n",
      "epoch:17 step:16269 [D loss: 0.233686, acc.: 57.03%] [G loss: 0.444692]\n",
      "epoch:17 step:16270 [D loss: 0.260843, acc.: 55.47%] [G loss: 0.405868]\n",
      "epoch:17 step:16271 [D loss: 0.236191, acc.: 57.81%] [G loss: 0.460155]\n",
      "epoch:17 step:16272 [D loss: 0.211095, acc.: 66.41%] [G loss: 0.464253]\n",
      "epoch:17 step:16273 [D loss: 0.209654, acc.: 68.75%] [G loss: 0.453767]\n",
      "epoch:17 step:16274 [D loss: 0.192952, acc.: 72.66%] [G loss: 0.491060]\n",
      "epoch:17 step:16275 [D loss: 0.188926, acc.: 75.00%] [G loss: 0.478992]\n",
      "epoch:17 step:16276 [D loss: 0.160780, acc.: 82.03%] [G loss: 0.523127]\n",
      "epoch:17 step:16277 [D loss: 0.286233, acc.: 52.34%] [G loss: 0.413242]\n",
      "epoch:17 step:16278 [D loss: 0.266460, acc.: 49.22%] [G loss: 0.375482]\n",
      "epoch:17 step:16279 [D loss: 0.203869, acc.: 63.28%] [G loss: 0.411497]\n",
      "epoch:17 step:16280 [D loss: 0.235902, acc.: 62.50%] [G loss: 0.399313]\n",
      "epoch:17 step:16281 [D loss: 0.237121, acc.: 60.16%] [G loss: 0.384997]\n",
      "epoch:17 step:16282 [D loss: 0.221856, acc.: 64.84%] [G loss: 0.462130]\n",
      "epoch:17 step:16283 [D loss: 0.186768, acc.: 73.44%] [G loss: 0.474181]\n",
      "epoch:17 step:16284 [D loss: 0.223716, acc.: 60.16%] [G loss: 0.464842]\n",
      "epoch:17 step:16285 [D loss: 0.218966, acc.: 66.41%] [G loss: 0.400792]\n",
      "epoch:17 step:16286 [D loss: 0.190339, acc.: 70.31%] [G loss: 0.442241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16287 [D loss: 0.178531, acc.: 71.09%] [G loss: 0.449357]\n",
      "epoch:17 step:16288 [D loss: 0.217086, acc.: 66.41%] [G loss: 0.471915]\n",
      "epoch:17 step:16289 [D loss: 0.215005, acc.: 64.06%] [G loss: 0.418204]\n",
      "epoch:17 step:16290 [D loss: 0.201145, acc.: 67.19%] [G loss: 0.476581]\n",
      "epoch:17 step:16291 [D loss: 0.250584, acc.: 52.34%] [G loss: 0.445359]\n",
      "epoch:17 step:16292 [D loss: 0.236680, acc.: 64.06%] [G loss: 0.433793]\n",
      "epoch:17 step:16293 [D loss: 0.221656, acc.: 61.72%] [G loss: 0.405284]\n",
      "epoch:17 step:16294 [D loss: 0.225572, acc.: 61.72%] [G loss: 0.432606]\n",
      "epoch:17 step:16295 [D loss: 0.223436, acc.: 65.62%] [G loss: 0.450977]\n",
      "epoch:17 step:16296 [D loss: 0.219669, acc.: 62.50%] [G loss: 0.481204]\n",
      "epoch:17 step:16297 [D loss: 0.231943, acc.: 56.25%] [G loss: 0.430257]\n",
      "epoch:17 step:16298 [D loss: 0.235064, acc.: 62.50%] [G loss: 0.391123]\n",
      "epoch:17 step:16299 [D loss: 0.202804, acc.: 67.19%] [G loss: 0.418164]\n",
      "epoch:17 step:16300 [D loss: 0.201951, acc.: 69.53%] [G loss: 0.476252]\n",
      "epoch:17 step:16301 [D loss: 0.223895, acc.: 62.50%] [G loss: 0.425133]\n",
      "epoch:17 step:16302 [D loss: 0.256133, acc.: 53.12%] [G loss: 0.428955]\n",
      "epoch:17 step:16303 [D loss: 0.183464, acc.: 70.31%] [G loss: 0.449935]\n",
      "epoch:17 step:16304 [D loss: 0.211154, acc.: 63.28%] [G loss: 0.484451]\n",
      "epoch:17 step:16305 [D loss: 0.231644, acc.: 60.94%] [G loss: 0.457626]\n",
      "epoch:17 step:16306 [D loss: 0.267734, acc.: 47.66%] [G loss: 0.412996]\n",
      "epoch:17 step:16307 [D loss: 0.219703, acc.: 65.62%] [G loss: 0.424223]\n",
      "epoch:17 step:16308 [D loss: 0.225427, acc.: 60.16%] [G loss: 0.439103]\n",
      "epoch:17 step:16309 [D loss: 0.238695, acc.: 61.72%] [G loss: 0.433190]\n",
      "epoch:17 step:16310 [D loss: 0.187293, acc.: 72.66%] [G loss: 0.451061]\n",
      "epoch:17 step:16311 [D loss: 0.232581, acc.: 64.06%] [G loss: 0.398005]\n",
      "epoch:17 step:16312 [D loss: 0.271280, acc.: 52.34%] [G loss: 0.387444]\n",
      "epoch:17 step:16313 [D loss: 0.237888, acc.: 55.47%] [G loss: 0.386188]\n",
      "epoch:17 step:16314 [D loss: 0.208974, acc.: 70.31%] [G loss: 0.413530]\n",
      "epoch:17 step:16315 [D loss: 0.241010, acc.: 53.91%] [G loss: 0.435349]\n",
      "epoch:17 step:16316 [D loss: 0.201027, acc.: 69.53%] [G loss: 0.447808]\n",
      "epoch:17 step:16317 [D loss: 0.193781, acc.: 70.31%] [G loss: 0.448748]\n",
      "epoch:17 step:16318 [D loss: 0.214352, acc.: 60.94%] [G loss: 0.448149]\n",
      "epoch:17 step:16319 [D loss: 0.253330, acc.: 56.25%] [G loss: 0.424562]\n",
      "epoch:17 step:16320 [D loss: 0.236554, acc.: 60.94%] [G loss: 0.427983]\n",
      "epoch:17 step:16321 [D loss: 0.221691, acc.: 63.28%] [G loss: 0.408751]\n",
      "epoch:17 step:16322 [D loss: 0.248762, acc.: 54.69%] [G loss: 0.384360]\n",
      "epoch:17 step:16323 [D loss: 0.211813, acc.: 65.62%] [G loss: 0.405759]\n",
      "epoch:17 step:16324 [D loss: 0.210255, acc.: 66.41%] [G loss: 0.439884]\n",
      "epoch:17 step:16325 [D loss: 0.273191, acc.: 50.00%] [G loss: 0.428228]\n",
      "epoch:17 step:16326 [D loss: 0.215035, acc.: 64.06%] [G loss: 0.429114]\n",
      "epoch:17 step:16327 [D loss: 0.205561, acc.: 66.41%] [G loss: 0.490889]\n",
      "epoch:17 step:16328 [D loss: 0.224154, acc.: 67.97%] [G loss: 0.501729]\n",
      "epoch:17 step:16329 [D loss: 0.278495, acc.: 47.66%] [G loss: 0.443039]\n",
      "epoch:17 step:16330 [D loss: 0.244658, acc.: 53.91%] [G loss: 0.419587]\n",
      "epoch:17 step:16331 [D loss: 0.228439, acc.: 64.84%] [G loss: 0.434405]\n",
      "epoch:17 step:16332 [D loss: 0.225708, acc.: 59.38%] [G loss: 0.427119]\n",
      "epoch:17 step:16333 [D loss: 0.233360, acc.: 57.81%] [G loss: 0.412476]\n",
      "epoch:17 step:16334 [D loss: 0.187645, acc.: 71.09%] [G loss: 0.471359]\n",
      "epoch:17 step:16335 [D loss: 0.197649, acc.: 70.31%] [G loss: 0.463827]\n",
      "epoch:17 step:16336 [D loss: 0.243974, acc.: 60.94%] [G loss: 0.435069]\n",
      "epoch:17 step:16337 [D loss: 0.242271, acc.: 56.25%] [G loss: 0.447879]\n",
      "epoch:17 step:16338 [D loss: 0.215372, acc.: 63.28%] [G loss: 0.455065]\n",
      "epoch:17 step:16339 [D loss: 0.235308, acc.: 65.62%] [G loss: 0.441493]\n",
      "epoch:17 step:16340 [D loss: 0.268399, acc.: 48.44%] [G loss: 0.392104]\n",
      "epoch:17 step:16341 [D loss: 0.214317, acc.: 63.28%] [G loss: 0.446983]\n",
      "epoch:17 step:16342 [D loss: 0.222768, acc.: 63.28%] [G loss: 0.395572]\n",
      "epoch:17 step:16343 [D loss: 0.212001, acc.: 67.19%] [G loss: 0.448661]\n",
      "epoch:17 step:16344 [D loss: 0.200515, acc.: 67.19%] [G loss: 0.477266]\n",
      "epoch:17 step:16345 [D loss: 0.202075, acc.: 72.66%] [G loss: 0.517326]\n",
      "epoch:17 step:16346 [D loss: 0.236063, acc.: 57.81%] [G loss: 0.471372]\n",
      "epoch:17 step:16347 [D loss: 0.260696, acc.: 51.56%] [G loss: 0.430002]\n",
      "epoch:17 step:16348 [D loss: 0.226077, acc.: 65.62%] [G loss: 0.456317]\n",
      "epoch:17 step:16349 [D loss: 0.246300, acc.: 63.28%] [G loss: 0.460892]\n",
      "epoch:17 step:16350 [D loss: 0.270304, acc.: 57.03%] [G loss: 0.428164]\n",
      "epoch:17 step:16351 [D loss: 0.241609, acc.: 59.38%] [G loss: 0.439676]\n",
      "epoch:17 step:16352 [D loss: 0.224593, acc.: 62.50%] [G loss: 0.398365]\n",
      "epoch:17 step:16353 [D loss: 0.243052, acc.: 60.16%] [G loss: 0.388782]\n",
      "epoch:17 step:16354 [D loss: 0.221900, acc.: 65.62%] [G loss: 0.391081]\n",
      "epoch:17 step:16355 [D loss: 0.195791, acc.: 68.75%] [G loss: 0.447449]\n",
      "epoch:17 step:16356 [D loss: 0.197691, acc.: 69.53%] [G loss: 0.428088]\n",
      "epoch:17 step:16357 [D loss: 0.224215, acc.: 66.41%] [G loss: 0.452444]\n",
      "epoch:17 step:16358 [D loss: 0.197210, acc.: 68.75%] [G loss: 0.461745]\n",
      "epoch:17 step:16359 [D loss: 0.210024, acc.: 64.84%] [G loss: 0.485700]\n",
      "epoch:17 step:16360 [D loss: 0.225755, acc.: 64.84%] [G loss: 0.433720]\n",
      "epoch:17 step:16361 [D loss: 0.251759, acc.: 56.25%] [G loss: 0.410290]\n",
      "epoch:17 step:16362 [D loss: 0.219318, acc.: 63.28%] [G loss: 0.454348]\n",
      "epoch:17 step:16363 [D loss: 0.208206, acc.: 68.75%] [G loss: 0.458575]\n",
      "epoch:17 step:16364 [D loss: 0.221128, acc.: 65.62%] [G loss: 0.467841]\n",
      "epoch:17 step:16365 [D loss: 0.197460, acc.: 71.09%] [G loss: 0.527655]\n",
      "epoch:17 step:16366 [D loss: 0.289092, acc.: 48.44%] [G loss: 0.492815]\n",
      "epoch:17 step:16367 [D loss: 0.237470, acc.: 59.38%] [G loss: 0.440610]\n",
      "epoch:17 step:16368 [D loss: 0.202078, acc.: 67.19%] [G loss: 0.445942]\n",
      "epoch:17 step:16369 [D loss: 0.229381, acc.: 61.72%] [G loss: 0.424367]\n",
      "epoch:17 step:16370 [D loss: 0.239580, acc.: 57.81%] [G loss: 0.426911]\n",
      "epoch:17 step:16371 [D loss: 0.258900, acc.: 55.47%] [G loss: 0.434387]\n",
      "epoch:17 step:16372 [D loss: 0.234464, acc.: 59.38%] [G loss: 0.407709]\n",
      "epoch:17 step:16373 [D loss: 0.217474, acc.: 61.72%] [G loss: 0.442192]\n",
      "epoch:17 step:16374 [D loss: 0.229172, acc.: 65.62%] [G loss: 0.442090]\n",
      "epoch:17 step:16375 [D loss: 0.228035, acc.: 58.59%] [G loss: 0.443279]\n",
      "epoch:17 step:16376 [D loss: 0.212000, acc.: 64.06%] [G loss: 0.456206]\n",
      "epoch:17 step:16377 [D loss: 0.256888, acc.: 54.69%] [G loss: 0.409975]\n",
      "epoch:17 step:16378 [D loss: 0.206880, acc.: 62.50%] [G loss: 0.465230]\n",
      "epoch:17 step:16379 [D loss: 0.233876, acc.: 67.19%] [G loss: 0.434044]\n",
      "epoch:17 step:16380 [D loss: 0.202929, acc.: 72.66%] [G loss: 0.442084]\n",
      "epoch:17 step:16381 [D loss: 0.194654, acc.: 67.97%] [G loss: 0.454377]\n",
      "epoch:17 step:16382 [D loss: 0.218468, acc.: 67.19%] [G loss: 0.455009]\n",
      "epoch:17 step:16383 [D loss: 0.210959, acc.: 63.28%] [G loss: 0.422629]\n",
      "epoch:17 step:16384 [D loss: 0.253777, acc.: 58.59%] [G loss: 0.444628]\n",
      "epoch:17 step:16385 [D loss: 0.226427, acc.: 62.50%] [G loss: 0.487374]\n",
      "epoch:17 step:16386 [D loss: 0.208349, acc.: 71.88%] [G loss: 0.465959]\n",
      "epoch:17 step:16387 [D loss: 0.262502, acc.: 55.47%] [G loss: 0.433937]\n",
      "epoch:17 step:16388 [D loss: 0.266822, acc.: 53.12%] [G loss: 0.411070]\n",
      "epoch:17 step:16389 [D loss: 0.245155, acc.: 58.59%] [G loss: 0.435412]\n",
      "epoch:17 step:16390 [D loss: 0.214549, acc.: 63.28%] [G loss: 0.453315]\n",
      "epoch:17 step:16391 [D loss: 0.229929, acc.: 62.50%] [G loss: 0.412096]\n",
      "epoch:17 step:16392 [D loss: 0.219566, acc.: 64.84%] [G loss: 0.448149]\n",
      "epoch:17 step:16393 [D loss: 0.245592, acc.: 55.47%] [G loss: 0.417572]\n",
      "epoch:17 step:16394 [D loss: 0.230141, acc.: 60.94%] [G loss: 0.439401]\n",
      "epoch:17 step:16395 [D loss: 0.232679, acc.: 60.16%] [G loss: 0.421529]\n",
      "epoch:17 step:16396 [D loss: 0.205430, acc.: 71.88%] [G loss: 0.455873]\n",
      "epoch:17 step:16397 [D loss: 0.208484, acc.: 65.62%] [G loss: 0.453149]\n",
      "epoch:17 step:16398 [D loss: 0.197738, acc.: 64.84%] [G loss: 0.470234]\n",
      "epoch:17 step:16399 [D loss: 0.201115, acc.: 67.97%] [G loss: 0.509558]\n",
      "epoch:17 step:16400 [D loss: 0.206827, acc.: 65.62%] [G loss: 0.490152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16401 [D loss: 0.195248, acc.: 67.19%] [G loss: 0.507879]\n",
      "epoch:17 step:16402 [D loss: 0.278587, acc.: 49.22%] [G loss: 0.457765]\n",
      "epoch:17 step:16403 [D loss: 0.209062, acc.: 67.19%] [G loss: 0.471079]\n",
      "epoch:17 step:16404 [D loss: 0.201591, acc.: 73.44%] [G loss: 0.453940]\n",
      "epoch:17 step:16405 [D loss: 0.223034, acc.: 61.72%] [G loss: 0.465662]\n",
      "epoch:17 step:16406 [D loss: 0.256527, acc.: 51.56%] [G loss: 0.433253]\n",
      "epoch:17 step:16407 [D loss: 0.235497, acc.: 58.59%] [G loss: 0.405132]\n",
      "epoch:17 step:16408 [D loss: 0.203833, acc.: 75.78%] [G loss: 0.420227]\n",
      "epoch:17 step:16409 [D loss: 0.232605, acc.: 57.03%] [G loss: 0.419269]\n",
      "epoch:17 step:16410 [D loss: 0.162455, acc.: 85.94%] [G loss: 0.479627]\n",
      "epoch:17 step:16411 [D loss: 0.258635, acc.: 54.69%] [G loss: 0.453786]\n",
      "epoch:17 step:16412 [D loss: 0.225057, acc.: 60.94%] [G loss: 0.431052]\n",
      "epoch:17 step:16413 [D loss: 0.210184, acc.: 71.88%] [G loss: 0.428445]\n",
      "epoch:17 step:16414 [D loss: 0.239633, acc.: 66.41%] [G loss: 0.412708]\n",
      "epoch:17 step:16415 [D loss: 0.225749, acc.: 65.62%] [G loss: 0.472938]\n",
      "epoch:17 step:16416 [D loss: 0.250092, acc.: 56.25%] [G loss: 0.413185]\n",
      "epoch:17 step:16417 [D loss: 0.188037, acc.: 74.22%] [G loss: 0.452548]\n",
      "epoch:17 step:16418 [D loss: 0.221890, acc.: 59.38%] [G loss: 0.414580]\n",
      "epoch:17 step:16419 [D loss: 0.245050, acc.: 58.59%] [G loss: 0.423732]\n",
      "epoch:17 step:16420 [D loss: 0.213571, acc.: 66.41%] [G loss: 0.442182]\n",
      "epoch:17 step:16421 [D loss: 0.231986, acc.: 64.06%] [G loss: 0.436769]\n",
      "epoch:17 step:16422 [D loss: 0.205814, acc.: 72.66%] [G loss: 0.425624]\n",
      "epoch:17 step:16423 [D loss: 0.225755, acc.: 63.28%] [G loss: 0.394695]\n",
      "epoch:17 step:16424 [D loss: 0.195038, acc.: 72.66%] [G loss: 0.441166]\n",
      "epoch:17 step:16425 [D loss: 0.214995, acc.: 67.19%] [G loss: 0.480003]\n",
      "epoch:17 step:16426 [D loss: 0.226643, acc.: 63.28%] [G loss: 0.459154]\n",
      "epoch:17 step:16427 [D loss: 0.204546, acc.: 67.97%] [G loss: 0.466882]\n",
      "epoch:17 step:16428 [D loss: 0.187002, acc.: 74.22%] [G loss: 0.504333]\n",
      "epoch:17 step:16429 [D loss: 0.224583, acc.: 65.62%] [G loss: 0.475351]\n",
      "epoch:17 step:16430 [D loss: 0.285643, acc.: 51.56%] [G loss: 0.430684]\n",
      "epoch:17 step:16431 [D loss: 0.252665, acc.: 49.22%] [G loss: 0.435697]\n",
      "epoch:17 step:16432 [D loss: 0.236629, acc.: 56.25%] [G loss: 0.415311]\n",
      "epoch:17 step:16433 [D loss: 0.182412, acc.: 71.88%] [G loss: 0.460449]\n",
      "epoch:17 step:16434 [D loss: 0.209370, acc.: 67.19%] [G loss: 0.483872]\n",
      "epoch:17 step:16435 [D loss: 0.218334, acc.: 62.50%] [G loss: 0.467179]\n",
      "epoch:17 step:16436 [D loss: 0.215982, acc.: 64.06%] [G loss: 0.458240]\n",
      "epoch:17 step:16437 [D loss: 0.203802, acc.: 69.53%] [G loss: 0.511962]\n",
      "epoch:17 step:16438 [D loss: 0.260641, acc.: 53.91%] [G loss: 0.434892]\n",
      "epoch:17 step:16439 [D loss: 0.253174, acc.: 57.81%] [G loss: 0.399751]\n",
      "epoch:17 step:16440 [D loss: 0.227036, acc.: 62.50%] [G loss: 0.410134]\n",
      "epoch:17 step:16441 [D loss: 0.222268, acc.: 61.72%] [G loss: 0.410392]\n",
      "epoch:17 step:16442 [D loss: 0.205137, acc.: 67.97%] [G loss: 0.459163]\n",
      "epoch:17 step:16443 [D loss: 0.221124, acc.: 57.81%] [G loss: 0.475006]\n",
      "epoch:17 step:16444 [D loss: 0.209152, acc.: 68.75%] [G loss: 0.496806]\n",
      "epoch:17 step:16445 [D loss: 0.196495, acc.: 71.09%] [G loss: 0.478497]\n",
      "epoch:17 step:16446 [D loss: 0.236453, acc.: 54.69%] [G loss: 0.417233]\n",
      "epoch:17 step:16447 [D loss: 0.225129, acc.: 61.72%] [G loss: 0.455216]\n",
      "epoch:17 step:16448 [D loss: 0.220707, acc.: 65.62%] [G loss: 0.443447]\n",
      "epoch:17 step:16449 [D loss: 0.220009, acc.: 64.06%] [G loss: 0.466852]\n",
      "epoch:17 step:16450 [D loss: 0.197746, acc.: 72.66%] [G loss: 0.453785]\n",
      "epoch:17 step:16451 [D loss: 0.211133, acc.: 67.19%] [G loss: 0.438789]\n",
      "epoch:17 step:16452 [D loss: 0.224619, acc.: 64.06%] [G loss: 0.441936]\n",
      "epoch:17 step:16453 [D loss: 0.212219, acc.: 68.75%] [G loss: 0.459441]\n",
      "epoch:17 step:16454 [D loss: 0.203953, acc.: 64.84%] [G loss: 0.476139]\n",
      "epoch:17 step:16455 [D loss: 0.220241, acc.: 61.72%] [G loss: 0.470736]\n",
      "epoch:17 step:16456 [D loss: 0.229021, acc.: 64.06%] [G loss: 0.463842]\n",
      "epoch:17 step:16457 [D loss: 0.280575, acc.: 50.78%] [G loss: 0.398515]\n",
      "epoch:17 step:16458 [D loss: 0.223378, acc.: 64.06%] [G loss: 0.422418]\n",
      "epoch:17 step:16459 [D loss: 0.244830, acc.: 57.03%] [G loss: 0.479680]\n",
      "epoch:17 step:16460 [D loss: 0.244546, acc.: 56.25%] [G loss: 0.448017]\n",
      "epoch:17 step:16461 [D loss: 0.230800, acc.: 64.06%] [G loss: 0.425641]\n",
      "epoch:17 step:16462 [D loss: 0.232713, acc.: 60.16%] [G loss: 0.462645]\n",
      "epoch:17 step:16463 [D loss: 0.174132, acc.: 73.44%] [G loss: 0.505478]\n",
      "epoch:17 step:16464 [D loss: 0.234344, acc.: 59.38%] [G loss: 0.416197]\n",
      "epoch:17 step:16465 [D loss: 0.229252, acc.: 60.16%] [G loss: 0.393699]\n",
      "epoch:17 step:16466 [D loss: 0.216273, acc.: 67.97%] [G loss: 0.429498]\n",
      "epoch:17 step:16467 [D loss: 0.226409, acc.: 57.81%] [G loss: 0.420016]\n",
      "epoch:17 step:16468 [D loss: 0.196104, acc.: 67.97%] [G loss: 0.454689]\n",
      "epoch:17 step:16469 [D loss: 0.198421, acc.: 67.19%] [G loss: 0.457681]\n",
      "epoch:17 step:16470 [D loss: 0.252339, acc.: 60.16%] [G loss: 0.413225]\n",
      "epoch:17 step:16471 [D loss: 0.248415, acc.: 57.03%] [G loss: 0.435564]\n",
      "epoch:17 step:16472 [D loss: 0.208557, acc.: 71.09%] [G loss: 0.479415]\n",
      "epoch:17 step:16473 [D loss: 0.231822, acc.: 60.94%] [G loss: 0.425662]\n",
      "epoch:17 step:16474 [D loss: 0.219703, acc.: 65.62%] [G loss: 0.429934]\n",
      "epoch:17 step:16475 [D loss: 0.222248, acc.: 64.06%] [G loss: 0.429157]\n",
      "epoch:17 step:16476 [D loss: 0.228027, acc.: 63.28%] [G loss: 0.421086]\n",
      "epoch:17 step:16477 [D loss: 0.195537, acc.: 63.28%] [G loss: 0.487222]\n",
      "epoch:17 step:16478 [D loss: 0.183792, acc.: 73.44%] [G loss: 0.487395]\n",
      "epoch:17 step:16479 [D loss: 0.198709, acc.: 73.44%] [G loss: 0.473773]\n",
      "epoch:17 step:16480 [D loss: 0.216599, acc.: 64.84%] [G loss: 0.495744]\n",
      "epoch:17 step:16481 [D loss: 0.195962, acc.: 70.31%] [G loss: 0.471883]\n",
      "epoch:17 step:16482 [D loss: 0.242630, acc.: 60.16%] [G loss: 0.436668]\n",
      "epoch:17 step:16483 [D loss: 0.224770, acc.: 64.06%] [G loss: 0.460418]\n",
      "epoch:17 step:16484 [D loss: 0.210089, acc.: 69.53%] [G loss: 0.433844]\n",
      "epoch:17 step:16485 [D loss: 0.196372, acc.: 78.12%] [G loss: 0.452797]\n",
      "epoch:17 step:16486 [D loss: 0.214939, acc.: 64.06%] [G loss: 0.447873]\n",
      "epoch:17 step:16487 [D loss: 0.206817, acc.: 69.53%] [G loss: 0.446299]\n",
      "epoch:17 step:16488 [D loss: 0.262930, acc.: 50.00%] [G loss: 0.460729]\n",
      "epoch:17 step:16489 [D loss: 0.247291, acc.: 50.78%] [G loss: 0.433275]\n",
      "epoch:17 step:16490 [D loss: 0.217732, acc.: 62.50%] [G loss: 0.427283]\n",
      "epoch:17 step:16491 [D loss: 0.238834, acc.: 62.50%] [G loss: 0.451419]\n",
      "epoch:17 step:16492 [D loss: 0.215652, acc.: 62.50%] [G loss: 0.482118]\n",
      "epoch:17 step:16493 [D loss: 0.209160, acc.: 69.53%] [G loss: 0.479639]\n",
      "epoch:17 step:16494 [D loss: 0.233355, acc.: 59.38%] [G loss: 0.498618]\n",
      "epoch:17 step:16495 [D loss: 0.259377, acc.: 53.12%] [G loss: 0.410176]\n",
      "epoch:17 step:16496 [D loss: 0.241809, acc.: 57.03%] [G loss: 0.414894]\n",
      "epoch:17 step:16497 [D loss: 0.188869, acc.: 68.75%] [G loss: 0.440382]\n",
      "epoch:17 step:16498 [D loss: 0.254476, acc.: 50.00%] [G loss: 0.410109]\n",
      "epoch:17 step:16499 [D loss: 0.212159, acc.: 71.09%] [G loss: 0.419440]\n",
      "epoch:17 step:16500 [D loss: 0.220690, acc.: 64.06%] [G loss: 0.459477]\n",
      "epoch:17 step:16501 [D loss: 0.234199, acc.: 63.28%] [G loss: 0.456050]\n",
      "epoch:17 step:16502 [D loss: 0.235356, acc.: 61.72%] [G loss: 0.466641]\n",
      "epoch:17 step:16503 [D loss: 0.180061, acc.: 75.78%] [G loss: 0.512078]\n",
      "epoch:17 step:16504 [D loss: 0.224684, acc.: 66.41%] [G loss: 0.446263]\n",
      "epoch:17 step:16505 [D loss: 0.239787, acc.: 53.12%] [G loss: 0.433493]\n",
      "epoch:17 step:16506 [D loss: 0.216365, acc.: 66.41%] [G loss: 0.456572]\n",
      "epoch:17 step:16507 [D loss: 0.215397, acc.: 62.50%] [G loss: 0.416250]\n",
      "epoch:17 step:16508 [D loss: 0.240366, acc.: 57.81%] [G loss: 0.401735]\n",
      "epoch:17 step:16509 [D loss: 0.205859, acc.: 62.50%] [G loss: 0.450286]\n",
      "epoch:17 step:16510 [D loss: 0.192147, acc.: 68.75%] [G loss: 0.446121]\n",
      "epoch:17 step:16511 [D loss: 0.196284, acc.: 70.31%] [G loss: 0.547345]\n",
      "epoch:17 step:16512 [D loss: 0.227634, acc.: 66.41%] [G loss: 0.505537]\n",
      "epoch:17 step:16513 [D loss: 0.229166, acc.: 59.38%] [G loss: 0.493486]\n",
      "epoch:17 step:16514 [D loss: 0.238748, acc.: 61.72%] [G loss: 0.440568]\n",
      "epoch:17 step:16515 [D loss: 0.229794, acc.: 62.50%] [G loss: 0.453533]\n",
      "epoch:17 step:16516 [D loss: 0.235352, acc.: 54.69%] [G loss: 0.432355]\n",
      "epoch:17 step:16517 [D loss: 0.238017, acc.: 54.69%] [G loss: 0.424567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16518 [D loss: 0.203316, acc.: 65.62%] [G loss: 0.461037]\n",
      "epoch:17 step:16519 [D loss: 0.238470, acc.: 60.16%] [G loss: 0.415486]\n",
      "epoch:17 step:16520 [D loss: 0.224806, acc.: 62.50%] [G loss: 0.433852]\n",
      "epoch:17 step:16521 [D loss: 0.186421, acc.: 76.56%] [G loss: 0.440255]\n",
      "epoch:17 step:16522 [D loss: 0.213870, acc.: 71.09%] [G loss: 0.480569]\n",
      "epoch:17 step:16523 [D loss: 0.245212, acc.: 62.50%] [G loss: 0.398579]\n",
      "epoch:17 step:16524 [D loss: 0.207855, acc.: 65.62%] [G loss: 0.467441]\n",
      "epoch:17 step:16525 [D loss: 0.237878, acc.: 64.06%] [G loss: 0.430693]\n",
      "epoch:17 step:16526 [D loss: 0.226414, acc.: 62.50%] [G loss: 0.450543]\n",
      "epoch:17 step:16527 [D loss: 0.224424, acc.: 67.19%] [G loss: 0.420325]\n",
      "epoch:17 step:16528 [D loss: 0.215549, acc.: 67.19%] [G loss: 0.470808]\n",
      "epoch:17 step:16529 [D loss: 0.246162, acc.: 53.91%] [G loss: 0.420239]\n",
      "epoch:17 step:16530 [D loss: 0.230905, acc.: 60.94%] [G loss: 0.444421]\n",
      "epoch:17 step:16531 [D loss: 0.229319, acc.: 65.62%] [G loss: 0.452126]\n",
      "epoch:17 step:16532 [D loss: 0.225278, acc.: 65.62%] [G loss: 0.450734]\n",
      "epoch:17 step:16533 [D loss: 0.206738, acc.: 68.75%] [G loss: 0.431981]\n",
      "epoch:17 step:16534 [D loss: 0.210430, acc.: 64.06%] [G loss: 0.464236]\n",
      "epoch:17 step:16535 [D loss: 0.213865, acc.: 64.84%] [G loss: 0.446174]\n",
      "epoch:17 step:16536 [D loss: 0.236612, acc.: 58.59%] [G loss: 0.443522]\n",
      "epoch:17 step:16537 [D loss: 0.214051, acc.: 64.84%] [G loss: 0.477495]\n",
      "epoch:17 step:16538 [D loss: 0.223841, acc.: 62.50%] [G loss: 0.432420]\n",
      "epoch:17 step:16539 [D loss: 0.225680, acc.: 65.62%] [G loss: 0.451343]\n",
      "epoch:17 step:16540 [D loss: 0.217043, acc.: 69.53%] [G loss: 0.428460]\n",
      "epoch:17 step:16541 [D loss: 0.222015, acc.: 63.28%] [G loss: 0.430606]\n",
      "epoch:17 step:16542 [D loss: 0.230700, acc.: 62.50%] [G loss: 0.411911]\n",
      "epoch:17 step:16543 [D loss: 0.243911, acc.: 57.81%] [G loss: 0.429323]\n",
      "epoch:17 step:16544 [D loss: 0.245221, acc.: 58.59%] [G loss: 0.413643]\n",
      "epoch:17 step:16545 [D loss: 0.241466, acc.: 58.59%] [G loss: 0.395716]\n",
      "epoch:17 step:16546 [D loss: 0.227086, acc.: 64.06%] [G loss: 0.417298]\n",
      "epoch:17 step:16547 [D loss: 0.233959, acc.: 58.59%] [G loss: 0.419198]\n",
      "epoch:17 step:16548 [D loss: 0.231669, acc.: 61.72%] [G loss: 0.422054]\n",
      "epoch:17 step:16549 [D loss: 0.209897, acc.: 71.09%] [G loss: 0.440214]\n",
      "epoch:17 step:16550 [D loss: 0.240053, acc.: 56.25%] [G loss: 0.433783]\n",
      "epoch:17 step:16551 [D loss: 0.228599, acc.: 61.72%] [G loss: 0.442109]\n",
      "epoch:17 step:16552 [D loss: 0.241007, acc.: 52.34%] [G loss: 0.460757]\n",
      "epoch:17 step:16553 [D loss: 0.202480, acc.: 70.31%] [G loss: 0.484236]\n",
      "epoch:17 step:16554 [D loss: 0.245459, acc.: 56.25%] [G loss: 0.433063]\n",
      "epoch:17 step:16555 [D loss: 0.234335, acc.: 60.94%] [G loss: 0.419053]\n",
      "epoch:17 step:16556 [D loss: 0.203125, acc.: 67.97%] [G loss: 0.432720]\n",
      "epoch:17 step:16557 [D loss: 0.236784, acc.: 60.16%] [G loss: 0.412648]\n",
      "epoch:17 step:16558 [D loss: 0.211369, acc.: 70.31%] [G loss: 0.481049]\n",
      "epoch:17 step:16559 [D loss: 0.241388, acc.: 62.50%] [G loss: 0.419897]\n",
      "epoch:17 step:16560 [D loss: 0.227838, acc.: 58.59%] [G loss: 0.434392]\n",
      "epoch:17 step:16561 [D loss: 0.220491, acc.: 64.06%] [G loss: 0.462270]\n",
      "epoch:17 step:16562 [D loss: 0.222675, acc.: 60.94%] [G loss: 0.425757]\n",
      "epoch:17 step:16563 [D loss: 0.197506, acc.: 70.31%] [G loss: 0.468749]\n",
      "epoch:17 step:16564 [D loss: 0.206183, acc.: 68.75%] [G loss: 0.447187]\n",
      "epoch:17 step:16565 [D loss: 0.206144, acc.: 67.19%] [G loss: 0.475225]\n",
      "epoch:17 step:16566 [D loss: 0.204402, acc.: 69.53%] [G loss: 0.450283]\n",
      "epoch:17 step:16567 [D loss: 0.207284, acc.: 67.19%] [G loss: 0.450142]\n",
      "epoch:17 step:16568 [D loss: 0.214352, acc.: 65.62%] [G loss: 0.471483]\n",
      "epoch:17 step:16569 [D loss: 0.244958, acc.: 60.94%] [G loss: 0.448613]\n",
      "epoch:17 step:16570 [D loss: 0.208597, acc.: 64.84%] [G loss: 0.481950]\n",
      "epoch:17 step:16571 [D loss: 0.200934, acc.: 70.31%] [G loss: 0.475586]\n",
      "epoch:17 step:16572 [D loss: 0.232191, acc.: 62.50%] [G loss: 0.445928]\n",
      "epoch:17 step:16573 [D loss: 0.253182, acc.: 56.25%] [G loss: 0.435199]\n",
      "epoch:17 step:16574 [D loss: 0.238065, acc.: 60.16%] [G loss: 0.435907]\n",
      "epoch:17 step:16575 [D loss: 0.219312, acc.: 65.62%] [G loss: 0.403047]\n",
      "epoch:17 step:16576 [D loss: 0.214133, acc.: 68.75%] [G loss: 0.490105]\n",
      "epoch:17 step:16577 [D loss: 0.161477, acc.: 78.91%] [G loss: 0.534895]\n",
      "epoch:17 step:16578 [D loss: 0.199948, acc.: 68.75%] [G loss: 0.508077]\n",
      "epoch:17 step:16579 [D loss: 0.196261, acc.: 67.97%] [G loss: 0.497590]\n",
      "epoch:17 step:16580 [D loss: 0.214810, acc.: 64.84%] [G loss: 0.468507]\n",
      "epoch:17 step:16581 [D loss: 0.255570, acc.: 59.38%] [G loss: 0.468772]\n",
      "epoch:17 step:16582 [D loss: 0.208092, acc.: 73.44%] [G loss: 0.420971]\n",
      "epoch:17 step:16583 [D loss: 0.198864, acc.: 68.75%] [G loss: 0.472091]\n",
      "epoch:17 step:16584 [D loss: 0.250981, acc.: 62.50%] [G loss: 0.522309]\n",
      "epoch:17 step:16585 [D loss: 0.243678, acc.: 62.50%] [G loss: 0.450561]\n",
      "epoch:17 step:16586 [D loss: 0.213934, acc.: 65.62%] [G loss: 0.435938]\n",
      "epoch:17 step:16587 [D loss: 0.237369, acc.: 60.16%] [G loss: 0.405496]\n",
      "epoch:17 step:16588 [D loss: 0.220754, acc.: 65.62%] [G loss: 0.426449]\n",
      "epoch:17 step:16589 [D loss: 0.193719, acc.: 71.88%] [G loss: 0.464487]\n",
      "epoch:17 step:16590 [D loss: 0.196689, acc.: 73.44%] [G loss: 0.503617]\n",
      "epoch:17 step:16591 [D loss: 0.246664, acc.: 57.03%] [G loss: 0.429491]\n",
      "epoch:17 step:16592 [D loss: 0.209867, acc.: 60.16%] [G loss: 0.462673]\n",
      "epoch:17 step:16593 [D loss: 0.240967, acc.: 60.16%] [G loss: 0.447442]\n",
      "epoch:17 step:16594 [D loss: 0.231838, acc.: 62.50%] [G loss: 0.462352]\n",
      "epoch:17 step:16595 [D loss: 0.231555, acc.: 57.81%] [G loss: 0.457468]\n",
      "epoch:17 step:16596 [D loss: 0.232185, acc.: 59.38%] [G loss: 0.406751]\n",
      "epoch:17 step:16597 [D loss: 0.229465, acc.: 64.84%] [G loss: 0.445639]\n",
      "epoch:17 step:16598 [D loss: 0.229350, acc.: 60.16%] [G loss: 0.410315]\n",
      "epoch:17 step:16599 [D loss: 0.258274, acc.: 55.47%] [G loss: 0.395914]\n",
      "epoch:17 step:16600 [D loss: 0.218447, acc.: 64.06%] [G loss: 0.429753]\n",
      "epoch:17 step:16601 [D loss: 0.259315, acc.: 57.81%] [G loss: 0.415839]\n",
      "epoch:17 step:16602 [D loss: 0.228830, acc.: 63.28%] [G loss: 0.433109]\n",
      "epoch:17 step:16603 [D loss: 0.221761, acc.: 64.06%] [G loss: 0.483697]\n",
      "epoch:17 step:16604 [D loss: 0.275792, acc.: 50.78%] [G loss: 0.404034]\n",
      "epoch:17 step:16605 [D loss: 0.217391, acc.: 64.84%] [G loss: 0.412829]\n",
      "epoch:17 step:16606 [D loss: 0.191034, acc.: 75.78%] [G loss: 0.442821]\n",
      "epoch:17 step:16607 [D loss: 0.227466, acc.: 60.94%] [G loss: 0.439423]\n",
      "epoch:17 step:16608 [D loss: 0.205788, acc.: 67.19%] [G loss: 0.472061]\n",
      "epoch:17 step:16609 [D loss: 0.219303, acc.: 59.38%] [G loss: 0.439940]\n",
      "epoch:17 step:16610 [D loss: 0.201403, acc.: 70.31%] [G loss: 0.434559]\n",
      "epoch:17 step:16611 [D loss: 0.229309, acc.: 60.16%] [G loss: 0.449132]\n",
      "epoch:17 step:16612 [D loss: 0.243019, acc.: 57.81%] [G loss: 0.391315]\n",
      "epoch:17 step:16613 [D loss: 0.222443, acc.: 61.72%] [G loss: 0.403809]\n",
      "epoch:17 step:16614 [D loss: 0.219239, acc.: 64.84%] [G loss: 0.410971]\n",
      "epoch:17 step:16615 [D loss: 0.211622, acc.: 67.97%] [G loss: 0.454624]\n",
      "epoch:17 step:16616 [D loss: 0.237438, acc.: 62.50%] [G loss: 0.412799]\n",
      "epoch:17 step:16617 [D loss: 0.196799, acc.: 69.53%] [G loss: 0.495450]\n",
      "epoch:17 step:16618 [D loss: 0.227416, acc.: 69.53%] [G loss: 0.433774]\n",
      "epoch:17 step:16619 [D loss: 0.218673, acc.: 63.28%] [G loss: 0.425410]\n",
      "epoch:17 step:16620 [D loss: 0.208203, acc.: 65.62%] [G loss: 0.489908]\n",
      "epoch:17 step:16621 [D loss: 0.199018, acc.: 72.66%] [G loss: 0.519688]\n",
      "epoch:17 step:16622 [D loss: 0.201607, acc.: 67.19%] [G loss: 0.477629]\n",
      "epoch:17 step:16623 [D loss: 0.174426, acc.: 76.56%] [G loss: 0.477430]\n",
      "epoch:17 step:16624 [D loss: 0.232993, acc.: 60.94%] [G loss: 0.449859]\n",
      "epoch:17 step:16625 [D loss: 0.277280, acc.: 47.66%] [G loss: 0.451658]\n",
      "epoch:17 step:16626 [D loss: 0.235046, acc.: 59.38%] [G loss: 0.427974]\n",
      "epoch:17 step:16627 [D loss: 0.235555, acc.: 60.94%] [G loss: 0.437730]\n",
      "epoch:17 step:16628 [D loss: 0.206117, acc.: 65.62%] [G loss: 0.469358]\n",
      "epoch:17 step:16629 [D loss: 0.184506, acc.: 72.66%] [G loss: 0.473700]\n",
      "epoch:17 step:16630 [D loss: 0.213177, acc.: 67.19%] [G loss: 0.428441]\n",
      "epoch:17 step:16631 [D loss: 0.218835, acc.: 63.28%] [G loss: 0.418848]\n",
      "epoch:17 step:16632 [D loss: 0.227865, acc.: 59.38%] [G loss: 0.413738]\n",
      "epoch:17 step:16633 [D loss: 0.240162, acc.: 58.59%] [G loss: 0.422689]\n",
      "epoch:17 step:16634 [D loss: 0.226147, acc.: 65.62%] [G loss: 0.414151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16635 [D loss: 0.205586, acc.: 67.19%] [G loss: 0.452024]\n",
      "epoch:17 step:16636 [D loss: 0.188953, acc.: 70.31%] [G loss: 0.463746]\n",
      "epoch:17 step:16637 [D loss: 0.219215, acc.: 69.53%] [G loss: 0.462879]\n",
      "epoch:17 step:16638 [D loss: 0.201072, acc.: 71.09%] [G loss: 0.466788]\n",
      "epoch:17 step:16639 [D loss: 0.250265, acc.: 57.03%] [G loss: 0.429629]\n",
      "epoch:17 step:16640 [D loss: 0.214392, acc.: 64.84%] [G loss: 0.441959]\n",
      "epoch:17 step:16641 [D loss: 0.210135, acc.: 69.53%] [G loss: 0.436194]\n",
      "epoch:17 step:16642 [D loss: 0.228801, acc.: 61.72%] [G loss: 0.481941]\n",
      "epoch:17 step:16643 [D loss: 0.244921, acc.: 57.03%] [G loss: 0.438148]\n",
      "epoch:17 step:16644 [D loss: 0.210842, acc.: 64.06%] [G loss: 0.486147]\n",
      "epoch:17 step:16645 [D loss: 0.244439, acc.: 56.25%] [G loss: 0.459052]\n",
      "epoch:17 step:16646 [D loss: 0.237030, acc.: 65.62%] [G loss: 0.406182]\n",
      "epoch:17 step:16647 [D loss: 0.212292, acc.: 70.31%] [G loss: 0.434003]\n",
      "epoch:17 step:16648 [D loss: 0.212278, acc.: 70.31%] [G loss: 0.469989]\n",
      "epoch:17 step:16649 [D loss: 0.214980, acc.: 69.53%] [G loss: 0.469964]\n",
      "epoch:17 step:16650 [D loss: 0.219489, acc.: 62.50%] [G loss: 0.472450]\n",
      "epoch:17 step:16651 [D loss: 0.244605, acc.: 52.34%] [G loss: 0.481237]\n",
      "epoch:17 step:16652 [D loss: 0.217994, acc.: 67.19%] [G loss: 0.444863]\n",
      "epoch:17 step:16653 [D loss: 0.218056, acc.: 65.62%] [G loss: 0.466894]\n",
      "epoch:17 step:16654 [D loss: 0.193083, acc.: 72.66%] [G loss: 0.482642]\n",
      "epoch:17 step:16655 [D loss: 0.226668, acc.: 62.50%] [G loss: 0.464909]\n",
      "epoch:17 step:16656 [D loss: 0.253320, acc.: 57.81%] [G loss: 0.444516]\n",
      "epoch:17 step:16657 [D loss: 0.234334, acc.: 63.28%] [G loss: 0.455141]\n",
      "epoch:17 step:16658 [D loss: 0.246894, acc.: 59.38%] [G loss: 0.411878]\n",
      "epoch:17 step:16659 [D loss: 0.234967, acc.: 57.03%] [G loss: 0.442911]\n",
      "epoch:17 step:16660 [D loss: 0.222941, acc.: 56.25%] [G loss: 0.462455]\n",
      "epoch:17 step:16661 [D loss: 0.213190, acc.: 65.62%] [G loss: 0.425726]\n",
      "epoch:17 step:16662 [D loss: 0.205610, acc.: 70.31%] [G loss: 0.448609]\n",
      "epoch:17 step:16663 [D loss: 0.237077, acc.: 58.59%] [G loss: 0.374823]\n",
      "epoch:17 step:16664 [D loss: 0.242580, acc.: 60.16%] [G loss: 0.441691]\n",
      "epoch:17 step:16665 [D loss: 0.212277, acc.: 67.97%] [G loss: 0.384471]\n",
      "epoch:17 step:16666 [D loss: 0.217443, acc.: 64.06%] [G loss: 0.398810]\n",
      "epoch:17 step:16667 [D loss: 0.246853, acc.: 55.47%] [G loss: 0.430536]\n",
      "epoch:17 step:16668 [D loss: 0.266267, acc.: 49.22%] [G loss: 0.416913]\n",
      "epoch:17 step:16669 [D loss: 0.228873, acc.: 66.41%] [G loss: 0.422308]\n",
      "epoch:17 step:16670 [D loss: 0.242256, acc.: 56.25%] [G loss: 0.424322]\n",
      "epoch:17 step:16671 [D loss: 0.223256, acc.: 63.28%] [G loss: 0.442143]\n",
      "epoch:17 step:16672 [D loss: 0.221413, acc.: 64.06%] [G loss: 0.458032]\n",
      "epoch:17 step:16673 [D loss: 0.231917, acc.: 60.94%] [G loss: 0.441788]\n",
      "epoch:17 step:16674 [D loss: 0.236462, acc.: 57.81%] [G loss: 0.390613]\n",
      "epoch:17 step:16675 [D loss: 0.209477, acc.: 71.09%] [G loss: 0.454060]\n",
      "epoch:17 step:16676 [D loss: 0.201665, acc.: 66.41%] [G loss: 0.467663]\n",
      "epoch:17 step:16677 [D loss: 0.218585, acc.: 65.62%] [G loss: 0.426791]\n",
      "epoch:17 step:16678 [D loss: 0.234029, acc.: 59.38%] [G loss: 0.428744]\n",
      "epoch:17 step:16679 [D loss: 0.213556, acc.: 67.19%] [G loss: 0.440005]\n",
      "epoch:17 step:16680 [D loss: 0.235821, acc.: 59.38%] [G loss: 0.405411]\n",
      "epoch:17 step:16681 [D loss: 0.248165, acc.: 57.03%] [G loss: 0.450967]\n",
      "epoch:17 step:16682 [D loss: 0.219261, acc.: 61.72%] [G loss: 0.483720]\n",
      "epoch:17 step:16683 [D loss: 0.214010, acc.: 66.41%] [G loss: 0.434288]\n",
      "epoch:17 step:16684 [D loss: 0.213418, acc.: 66.41%] [G loss: 0.448737]\n",
      "epoch:17 step:16685 [D loss: 0.247186, acc.: 63.28%] [G loss: 0.424902]\n",
      "epoch:17 step:16686 [D loss: 0.240447, acc.: 53.91%] [G loss: 0.429308]\n",
      "epoch:17 step:16687 [D loss: 0.247447, acc.: 59.38%] [G loss: 0.402520]\n",
      "epoch:17 step:16688 [D loss: 0.234225, acc.: 63.28%] [G loss: 0.423047]\n",
      "epoch:17 step:16689 [D loss: 0.233253, acc.: 62.50%] [G loss: 0.432791]\n",
      "epoch:17 step:16690 [D loss: 0.229068, acc.: 60.94%] [G loss: 0.407423]\n",
      "epoch:17 step:16691 [D loss: 0.224347, acc.: 65.62%] [G loss: 0.424610]\n",
      "epoch:17 step:16692 [D loss: 0.222003, acc.: 65.62%] [G loss: 0.402487]\n",
      "epoch:17 step:16693 [D loss: 0.236218, acc.: 60.16%] [G loss: 0.457522]\n",
      "epoch:17 step:16694 [D loss: 0.258489, acc.: 57.81%] [G loss: 0.388204]\n",
      "epoch:17 step:16695 [D loss: 0.245556, acc.: 58.59%] [G loss: 0.433820]\n",
      "epoch:17 step:16696 [D loss: 0.184872, acc.: 73.44%] [G loss: 0.461034]\n",
      "epoch:17 step:16697 [D loss: 0.245031, acc.: 59.38%] [G loss: 0.424357]\n",
      "epoch:17 step:16698 [D loss: 0.205211, acc.: 62.50%] [G loss: 0.524282]\n",
      "epoch:17 step:16699 [D loss: 0.235959, acc.: 59.38%] [G loss: 0.455032]\n",
      "epoch:17 step:16700 [D loss: 0.249522, acc.: 58.59%] [G loss: 0.432012]\n",
      "epoch:17 step:16701 [D loss: 0.238857, acc.: 56.25%] [G loss: 0.434254]\n",
      "epoch:17 step:16702 [D loss: 0.228876, acc.: 60.16%] [G loss: 0.487937]\n",
      "epoch:17 step:16703 [D loss: 0.227309, acc.: 66.41%] [G loss: 0.441003]\n",
      "epoch:17 step:16704 [D loss: 0.210021, acc.: 64.84%] [G loss: 0.486722]\n",
      "epoch:17 step:16705 [D loss: 0.224861, acc.: 65.62%] [G loss: 0.522675]\n",
      "epoch:17 step:16706 [D loss: 0.223511, acc.: 69.53%] [G loss: 0.458799]\n",
      "epoch:17 step:16707 [D loss: 0.214771, acc.: 66.41%] [G loss: 0.447240]\n",
      "epoch:17 step:16708 [D loss: 0.243534, acc.: 57.81%] [G loss: 0.435293]\n",
      "epoch:17 step:16709 [D loss: 0.221063, acc.: 64.06%] [G loss: 0.457951]\n",
      "epoch:17 step:16710 [D loss: 0.213199, acc.: 66.41%] [G loss: 0.483772]\n",
      "epoch:17 step:16711 [D loss: 0.196296, acc.: 71.09%] [G loss: 0.522898]\n",
      "epoch:17 step:16712 [D loss: 0.239039, acc.: 57.81%] [G loss: 0.445008]\n",
      "epoch:17 step:16713 [D loss: 0.241186, acc.: 52.34%] [G loss: 0.445642]\n",
      "epoch:17 step:16714 [D loss: 0.238621, acc.: 63.28%] [G loss: 0.418751]\n",
      "epoch:17 step:16715 [D loss: 0.208868, acc.: 66.41%] [G loss: 0.449975]\n",
      "epoch:17 step:16716 [D loss: 0.241552, acc.: 60.16%] [G loss: 0.453309]\n",
      "epoch:17 step:16717 [D loss: 0.242640, acc.: 58.59%] [G loss: 0.428743]\n",
      "epoch:17 step:16718 [D loss: 0.216821, acc.: 65.62%] [G loss: 0.455718]\n",
      "epoch:17 step:16719 [D loss: 0.211446, acc.: 64.06%] [G loss: 0.441467]\n",
      "epoch:17 step:16720 [D loss: 0.264754, acc.: 62.50%] [G loss: 0.445050]\n",
      "epoch:17 step:16721 [D loss: 0.185294, acc.: 73.44%] [G loss: 0.465211]\n",
      "epoch:17 step:16722 [D loss: 0.200062, acc.: 67.19%] [G loss: 0.498187]\n",
      "epoch:17 step:16723 [D loss: 0.241210, acc.: 54.69%] [G loss: 0.493771]\n",
      "epoch:17 step:16724 [D loss: 0.236483, acc.: 60.94%] [G loss: 0.433159]\n",
      "epoch:17 step:16725 [D loss: 0.216276, acc.: 67.19%] [G loss: 0.463777]\n",
      "epoch:17 step:16726 [D loss: 0.248814, acc.: 56.25%] [G loss: 0.447206]\n",
      "epoch:17 step:16727 [D loss: 0.237791, acc.: 56.25%] [G loss: 0.434790]\n",
      "epoch:17 step:16728 [D loss: 0.226488, acc.: 63.28%] [G loss: 0.421448]\n",
      "epoch:17 step:16729 [D loss: 0.243767, acc.: 57.03%] [G loss: 0.481484]\n",
      "epoch:17 step:16730 [D loss: 0.221418, acc.: 62.50%] [G loss: 0.473215]\n",
      "epoch:17 step:16731 [D loss: 0.205423, acc.: 69.53%] [G loss: 0.496493]\n",
      "epoch:17 step:16732 [D loss: 0.248276, acc.: 61.72%] [G loss: 0.443977]\n",
      "epoch:17 step:16733 [D loss: 0.224363, acc.: 64.06%] [G loss: 0.451411]\n",
      "epoch:17 step:16734 [D loss: 0.224953, acc.: 59.38%] [G loss: 0.453100]\n",
      "epoch:17 step:16735 [D loss: 0.228569, acc.: 60.16%] [G loss: 0.431757]\n",
      "epoch:17 step:16736 [D loss: 0.226640, acc.: 64.84%] [G loss: 0.465688]\n",
      "epoch:17 step:16737 [D loss: 0.228851, acc.: 59.38%] [G loss: 0.413708]\n",
      "epoch:17 step:16738 [D loss: 0.231346, acc.: 65.62%] [G loss: 0.404061]\n",
      "epoch:17 step:16739 [D loss: 0.221105, acc.: 66.41%] [G loss: 0.401915]\n",
      "epoch:17 step:16740 [D loss: 0.222397, acc.: 60.16%] [G loss: 0.395614]\n",
      "epoch:17 step:16741 [D loss: 0.250016, acc.: 59.38%] [G loss: 0.418033]\n",
      "epoch:17 step:16742 [D loss: 0.241389, acc.: 60.16%] [G loss: 0.455138]\n",
      "epoch:17 step:16743 [D loss: 0.217386, acc.: 63.28%] [G loss: 0.493003]\n",
      "epoch:17 step:16744 [D loss: 0.179652, acc.: 72.66%] [G loss: 0.493081]\n",
      "epoch:17 step:16745 [D loss: 0.218981, acc.: 61.72%] [G loss: 0.462533]\n",
      "epoch:17 step:16746 [D loss: 0.234225, acc.: 54.69%] [G loss: 0.436469]\n",
      "epoch:17 step:16747 [D loss: 0.240946, acc.: 60.94%] [G loss: 0.426514]\n",
      "epoch:17 step:16748 [D loss: 0.218263, acc.: 64.84%] [G loss: 0.428095]\n",
      "epoch:17 step:16749 [D loss: 0.249958, acc.: 52.34%] [G loss: 0.417228]\n",
      "epoch:17 step:16750 [D loss: 0.212763, acc.: 67.97%] [G loss: 0.426056]\n",
      "epoch:17 step:16751 [D loss: 0.225795, acc.: 62.50%] [G loss: 0.441390]\n",
      "epoch:17 step:16752 [D loss: 0.223402, acc.: 63.28%] [G loss: 0.428109]\n",
      "epoch:17 step:16753 [D loss: 0.231484, acc.: 64.06%] [G loss: 0.454046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16754 [D loss: 0.208672, acc.: 67.19%] [G loss: 0.441707]\n",
      "epoch:17 step:16755 [D loss: 0.226879, acc.: 60.16%] [G loss: 0.445756]\n",
      "epoch:17 step:16756 [D loss: 0.254685, acc.: 50.78%] [G loss: 0.405929]\n",
      "epoch:17 step:16757 [D loss: 0.242063, acc.: 56.25%] [G loss: 0.400571]\n",
      "epoch:17 step:16758 [D loss: 0.213855, acc.: 66.41%] [G loss: 0.447500]\n",
      "epoch:17 step:16759 [D loss: 0.244833, acc.: 53.91%] [G loss: 0.429536]\n",
      "epoch:17 step:16760 [D loss: 0.222621, acc.: 59.38%] [G loss: 0.410987]\n",
      "epoch:17 step:16761 [D loss: 0.212137, acc.: 65.62%] [G loss: 0.442202]\n",
      "epoch:17 step:16762 [D loss: 0.201575, acc.: 65.62%] [G loss: 0.430531]\n",
      "epoch:17 step:16763 [D loss: 0.256721, acc.: 53.91%] [G loss: 0.410573]\n",
      "epoch:17 step:16764 [D loss: 0.241000, acc.: 60.16%] [G loss: 0.403172]\n",
      "epoch:17 step:16765 [D loss: 0.228305, acc.: 64.84%] [G loss: 0.404384]\n",
      "epoch:17 step:16766 [D loss: 0.211581, acc.: 65.62%] [G loss: 0.420092]\n",
      "epoch:17 step:16767 [D loss: 0.213427, acc.: 70.31%] [G loss: 0.416399]\n",
      "epoch:17 step:16768 [D loss: 0.201323, acc.: 67.19%] [G loss: 0.456556]\n",
      "epoch:17 step:16769 [D loss: 0.225499, acc.: 64.06%] [G loss: 0.410067]\n",
      "epoch:17 step:16770 [D loss: 0.210552, acc.: 70.31%] [G loss: 0.423784]\n",
      "epoch:17 step:16771 [D loss: 0.211928, acc.: 64.84%] [G loss: 0.421317]\n",
      "epoch:17 step:16772 [D loss: 0.238209, acc.: 60.94%] [G loss: 0.448483]\n",
      "epoch:17 step:16773 [D loss: 0.239079, acc.: 60.94%] [G loss: 0.441959]\n",
      "epoch:17 step:16774 [D loss: 0.206491, acc.: 64.84%] [G loss: 0.470061]\n",
      "epoch:17 step:16775 [D loss: 0.262659, acc.: 49.22%] [G loss: 0.453154]\n",
      "epoch:17 step:16776 [D loss: 0.223485, acc.: 68.75%] [G loss: 0.426157]\n",
      "epoch:17 step:16777 [D loss: 0.248060, acc.: 57.03%] [G loss: 0.418555]\n",
      "epoch:17 step:16778 [D loss: 0.228675, acc.: 60.16%] [G loss: 0.416431]\n",
      "epoch:17 step:16779 [D loss: 0.217945, acc.: 65.62%] [G loss: 0.440994]\n",
      "epoch:17 step:16780 [D loss: 0.236843, acc.: 55.47%] [G loss: 0.474758]\n",
      "epoch:17 step:16781 [D loss: 0.194492, acc.: 68.75%] [G loss: 0.486128]\n",
      "epoch:17 step:16782 [D loss: 0.203091, acc.: 67.97%] [G loss: 0.473749]\n",
      "epoch:17 step:16783 [D loss: 0.230527, acc.: 61.72%] [G loss: 0.444994]\n",
      "epoch:17 step:16784 [D loss: 0.254242, acc.: 59.38%] [G loss: 0.413077]\n",
      "epoch:17 step:16785 [D loss: 0.271199, acc.: 48.44%] [G loss: 0.377673]\n",
      "epoch:17 step:16786 [D loss: 0.191258, acc.: 73.44%] [G loss: 0.466595]\n",
      "epoch:17 step:16787 [D loss: 0.255675, acc.: 50.78%] [G loss: 0.397960]\n",
      "epoch:17 step:16788 [D loss: 0.233355, acc.: 59.38%] [G loss: 0.409920]\n",
      "epoch:17 step:16789 [D loss: 0.219106, acc.: 64.06%] [G loss: 0.432859]\n",
      "epoch:17 step:16790 [D loss: 0.240410, acc.: 53.91%] [G loss: 0.437702]\n",
      "epoch:17 step:16791 [D loss: 0.231486, acc.: 57.81%] [G loss: 0.410364]\n",
      "epoch:17 step:16792 [D loss: 0.242700, acc.: 56.25%] [G loss: 0.408243]\n",
      "epoch:17 step:16793 [D loss: 0.223476, acc.: 60.94%] [G loss: 0.438273]\n",
      "epoch:17 step:16794 [D loss: 0.231244, acc.: 57.81%] [G loss: 0.415731]\n",
      "epoch:17 step:16795 [D loss: 0.223022, acc.: 63.28%] [G loss: 0.407694]\n",
      "epoch:17 step:16796 [D loss: 0.225806, acc.: 62.50%] [G loss: 0.428617]\n",
      "epoch:17 step:16797 [D loss: 0.227309, acc.: 61.72%] [G loss: 0.410288]\n",
      "epoch:17 step:16798 [D loss: 0.233436, acc.: 60.94%] [G loss: 0.415816]\n",
      "epoch:17 step:16799 [D loss: 0.199363, acc.: 69.53%] [G loss: 0.451589]\n",
      "epoch:17 step:16800 [D loss: 0.205356, acc.: 70.31%] [G loss: 0.454059]\n",
      "epoch:17 step:16801 [D loss: 0.225171, acc.: 64.84%] [G loss: 0.428290]\n",
      "epoch:17 step:16802 [D loss: 0.206074, acc.: 64.84%] [G loss: 0.468472]\n",
      "epoch:17 step:16803 [D loss: 0.232490, acc.: 60.16%] [G loss: 0.394587]\n",
      "epoch:17 step:16804 [D loss: 0.205850, acc.: 70.31%] [G loss: 0.435219]\n",
      "epoch:17 step:16805 [D loss: 0.235092, acc.: 55.47%] [G loss: 0.417046]\n",
      "epoch:17 step:16806 [D loss: 0.254215, acc.: 53.91%] [G loss: 0.387087]\n",
      "epoch:17 step:16807 [D loss: 0.230292, acc.: 60.94%] [G loss: 0.466462]\n",
      "epoch:17 step:16808 [D loss: 0.220296, acc.: 65.62%] [G loss: 0.442667]\n",
      "epoch:17 step:16809 [D loss: 0.235884, acc.: 55.47%] [G loss: 0.419629]\n",
      "epoch:17 step:16810 [D loss: 0.227475, acc.: 60.94%] [G loss: 0.413727]\n",
      "epoch:17 step:16811 [D loss: 0.223873, acc.: 64.06%] [G loss: 0.415764]\n",
      "epoch:17 step:16812 [D loss: 0.254719, acc.: 53.12%] [G loss: 0.396810]\n",
      "epoch:17 step:16813 [D loss: 0.188716, acc.: 74.22%] [G loss: 0.493885]\n",
      "epoch:17 step:16814 [D loss: 0.201252, acc.: 71.88%] [G loss: 0.486762]\n",
      "epoch:17 step:16815 [D loss: 0.212498, acc.: 71.09%] [G loss: 0.471682]\n",
      "epoch:17 step:16816 [D loss: 0.207921, acc.: 66.41%] [G loss: 0.489119]\n",
      "epoch:17 step:16817 [D loss: 0.212908, acc.: 64.84%] [G loss: 0.464746]\n",
      "epoch:17 step:16818 [D loss: 0.213818, acc.: 69.53%] [G loss: 0.484117]\n",
      "epoch:17 step:16819 [D loss: 0.190993, acc.: 72.66%] [G loss: 0.444288]\n",
      "epoch:17 step:16820 [D loss: 0.235517, acc.: 60.94%] [G loss: 0.415709]\n",
      "epoch:17 step:16821 [D loss: 0.261993, acc.: 52.34%] [G loss: 0.409263]\n",
      "epoch:17 step:16822 [D loss: 0.202217, acc.: 68.75%] [G loss: 0.475278]\n",
      "epoch:17 step:16823 [D loss: 0.218212, acc.: 68.75%] [G loss: 0.429939]\n",
      "epoch:17 step:16824 [D loss: 0.200378, acc.: 68.75%] [G loss: 0.486123]\n",
      "epoch:17 step:16825 [D loss: 0.223537, acc.: 61.72%] [G loss: 0.446637]\n",
      "epoch:17 step:16826 [D loss: 0.203079, acc.: 70.31%] [G loss: 0.460246]\n",
      "epoch:17 step:16827 [D loss: 0.185382, acc.: 75.00%] [G loss: 0.454570]\n",
      "epoch:17 step:16828 [D loss: 0.190187, acc.: 73.44%] [G loss: 0.503326]\n",
      "epoch:17 step:16829 [D loss: 0.219693, acc.: 66.41%] [G loss: 0.490923]\n",
      "epoch:17 step:16830 [D loss: 0.216212, acc.: 67.19%] [G loss: 0.476422]\n",
      "epoch:17 step:16831 [D loss: 0.236042, acc.: 61.72%] [G loss: 0.424285]\n",
      "epoch:17 step:16832 [D loss: 0.226847, acc.: 64.84%] [G loss: 0.460579]\n",
      "epoch:17 step:16833 [D loss: 0.213029, acc.: 70.31%] [G loss: 0.432579]\n",
      "epoch:17 step:16834 [D loss: 0.192670, acc.: 68.75%] [G loss: 0.452212]\n",
      "epoch:17 step:16835 [D loss: 0.226956, acc.: 62.50%] [G loss: 0.527899]\n",
      "epoch:17 step:16836 [D loss: 0.237608, acc.: 54.69%] [G loss: 0.525234]\n",
      "epoch:17 step:16837 [D loss: 0.200714, acc.: 67.97%] [G loss: 0.485840]\n",
      "epoch:17 step:16838 [D loss: 0.228824, acc.: 64.06%] [G loss: 0.431068]\n",
      "epoch:17 step:16839 [D loss: 0.227587, acc.: 64.84%] [G loss: 0.424304]\n",
      "epoch:17 step:16840 [D loss: 0.211571, acc.: 64.06%] [G loss: 0.417633]\n",
      "epoch:17 step:16841 [D loss: 0.204620, acc.: 67.19%] [G loss: 0.472755]\n",
      "epoch:17 step:16842 [D loss: 0.253533, acc.: 55.47%] [G loss: 0.417973]\n",
      "epoch:17 step:16843 [D loss: 0.240273, acc.: 55.47%] [G loss: 0.461145]\n",
      "epoch:17 step:16844 [D loss: 0.273782, acc.: 50.00%] [G loss: 0.408267]\n",
      "epoch:17 step:16845 [D loss: 0.246799, acc.: 56.25%] [G loss: 0.406076]\n",
      "epoch:17 step:16846 [D loss: 0.220485, acc.: 62.50%] [G loss: 0.463297]\n",
      "epoch:17 step:16847 [D loss: 0.197399, acc.: 75.00%] [G loss: 0.460321]\n",
      "epoch:17 step:16848 [D loss: 0.195523, acc.: 68.75%] [G loss: 0.528035]\n",
      "epoch:17 step:16849 [D loss: 0.290655, acc.: 49.22%] [G loss: 0.477169]\n",
      "epoch:17 step:16850 [D loss: 0.232285, acc.: 53.12%] [G loss: 0.459844]\n",
      "epoch:17 step:16851 [D loss: 0.222093, acc.: 65.62%] [G loss: 0.445466]\n",
      "epoch:17 step:16852 [D loss: 0.221721, acc.: 60.94%] [G loss: 0.405342]\n",
      "epoch:17 step:16853 [D loss: 0.177727, acc.: 73.44%] [G loss: 0.467011]\n",
      "epoch:17 step:16854 [D loss: 0.191444, acc.: 71.88%] [G loss: 0.450637]\n",
      "epoch:17 step:16855 [D loss: 0.189244, acc.: 73.44%] [G loss: 0.479219]\n",
      "epoch:17 step:16856 [D loss: 0.168845, acc.: 77.34%] [G loss: 0.545387]\n",
      "epoch:17 step:16857 [D loss: 0.308513, acc.: 53.12%] [G loss: 0.506730]\n",
      "epoch:17 step:16858 [D loss: 0.227874, acc.: 65.62%] [G loss: 0.658621]\n",
      "epoch:17 step:16859 [D loss: 0.221139, acc.: 67.19%] [G loss: 0.530891]\n",
      "epoch:17 step:16860 [D loss: 0.268786, acc.: 55.47%] [G loss: 0.454966]\n",
      "epoch:17 step:16861 [D loss: 0.262574, acc.: 54.69%] [G loss: 0.476398]\n",
      "epoch:17 step:16862 [D loss: 0.217283, acc.: 64.84%] [G loss: 0.460531]\n",
      "epoch:17 step:16863 [D loss: 0.202919, acc.: 71.09%] [G loss: 0.462109]\n",
      "epoch:17 step:16864 [D loss: 0.195808, acc.: 71.09%] [G loss: 0.467636]\n",
      "epoch:17 step:16865 [D loss: 0.169526, acc.: 78.12%] [G loss: 0.468416]\n",
      "epoch:17 step:16866 [D loss: 0.184685, acc.: 73.44%] [G loss: 0.582624]\n",
      "epoch:18 step:16867 [D loss: 0.242449, acc.: 63.28%] [G loss: 0.540858]\n",
      "epoch:18 step:16868 [D loss: 0.267215, acc.: 60.94%] [G loss: 0.422311]\n",
      "epoch:18 step:16869 [D loss: 0.226462, acc.: 60.16%] [G loss: 0.509920]\n",
      "epoch:18 step:16870 [D loss: 0.237461, acc.: 62.50%] [G loss: 0.448605]\n",
      "epoch:18 step:16871 [D loss: 0.207789, acc.: 67.97%] [G loss: 0.431075]\n",
      "epoch:18 step:16872 [D loss: 0.208505, acc.: 68.75%] [G loss: 0.433499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16873 [D loss: 0.210938, acc.: 66.41%] [G loss: 0.460408]\n",
      "epoch:18 step:16874 [D loss: 0.223708, acc.: 66.41%] [G loss: 0.449228]\n",
      "epoch:18 step:16875 [D loss: 0.202278, acc.: 68.75%] [G loss: 0.471326]\n",
      "epoch:18 step:16876 [D loss: 0.204756, acc.: 64.84%] [G loss: 0.497417]\n",
      "epoch:18 step:16877 [D loss: 0.216371, acc.: 64.06%] [G loss: 0.438792]\n",
      "epoch:18 step:16878 [D loss: 0.237082, acc.: 63.28%] [G loss: 0.437200]\n",
      "epoch:18 step:16879 [D loss: 0.210266, acc.: 66.41%] [G loss: 0.450526]\n",
      "epoch:18 step:16880 [D loss: 0.204484, acc.: 70.31%] [G loss: 0.449808]\n",
      "epoch:18 step:16881 [D loss: 0.211431, acc.: 67.19%] [G loss: 0.464500]\n",
      "epoch:18 step:16882 [D loss: 0.206655, acc.: 66.41%] [G loss: 0.451958]\n",
      "epoch:18 step:16883 [D loss: 0.227314, acc.: 64.84%] [G loss: 0.454996]\n",
      "epoch:18 step:16884 [D loss: 0.225112, acc.: 66.41%] [G loss: 0.479470]\n",
      "epoch:18 step:16885 [D loss: 0.249247, acc.: 61.72%] [G loss: 0.458082]\n",
      "epoch:18 step:16886 [D loss: 0.260905, acc.: 51.56%] [G loss: 0.485398]\n",
      "epoch:18 step:16887 [D loss: 0.249665, acc.: 58.59%] [G loss: 0.501353]\n",
      "epoch:18 step:16888 [D loss: 0.193905, acc.: 68.75%] [G loss: 0.543314]\n",
      "epoch:18 step:16889 [D loss: 0.247569, acc.: 59.38%] [G loss: 0.413719]\n",
      "epoch:18 step:16890 [D loss: 0.201199, acc.: 72.66%] [G loss: 0.412022]\n",
      "epoch:18 step:16891 [D loss: 0.195704, acc.: 71.88%] [G loss: 0.460734]\n",
      "epoch:18 step:16892 [D loss: 0.241935, acc.: 58.59%] [G loss: 0.394300]\n",
      "epoch:18 step:16893 [D loss: 0.218786, acc.: 64.84%] [G loss: 0.438357]\n",
      "epoch:18 step:16894 [D loss: 0.228554, acc.: 64.06%] [G loss: 0.422466]\n",
      "epoch:18 step:16895 [D loss: 0.209361, acc.: 66.41%] [G loss: 0.456441]\n",
      "epoch:18 step:16896 [D loss: 0.230876, acc.: 59.38%] [G loss: 0.421965]\n",
      "epoch:18 step:16897 [D loss: 0.251736, acc.: 51.56%] [G loss: 0.452480]\n",
      "epoch:18 step:16898 [D loss: 0.243548, acc.: 61.72%] [G loss: 0.408488]\n",
      "epoch:18 step:16899 [D loss: 0.212261, acc.: 61.72%] [G loss: 0.429385]\n",
      "epoch:18 step:16900 [D loss: 0.226977, acc.: 63.28%] [G loss: 0.425801]\n",
      "epoch:18 step:16901 [D loss: 0.228955, acc.: 59.38%] [G loss: 0.411751]\n",
      "epoch:18 step:16902 [D loss: 0.187134, acc.: 71.88%] [G loss: 0.443762]\n",
      "epoch:18 step:16903 [D loss: 0.257520, acc.: 57.81%] [G loss: 0.372708]\n",
      "epoch:18 step:16904 [D loss: 0.264489, acc.: 46.88%] [G loss: 0.426783]\n",
      "epoch:18 step:16905 [D loss: 0.226960, acc.: 60.94%] [G loss: 0.420721]\n",
      "epoch:18 step:16906 [D loss: 0.179130, acc.: 74.22%] [G loss: 0.452411]\n",
      "epoch:18 step:16907 [D loss: 0.246031, acc.: 61.72%] [G loss: 0.419262]\n",
      "epoch:18 step:16908 [D loss: 0.210643, acc.: 65.62%] [G loss: 0.414302]\n",
      "epoch:18 step:16909 [D loss: 0.218404, acc.: 61.72%] [G loss: 0.440273]\n",
      "epoch:18 step:16910 [D loss: 0.254270, acc.: 57.03%] [G loss: 0.422164]\n",
      "epoch:18 step:16911 [D loss: 0.213305, acc.: 64.84%] [G loss: 0.443546]\n",
      "epoch:18 step:16912 [D loss: 0.253393, acc.: 54.69%] [G loss: 0.441753]\n",
      "epoch:18 step:16913 [D loss: 0.216973, acc.: 66.41%] [G loss: 0.426160]\n",
      "epoch:18 step:16914 [D loss: 0.195028, acc.: 71.09%] [G loss: 0.473320]\n",
      "epoch:18 step:16915 [D loss: 0.201449, acc.: 67.19%] [G loss: 0.504502]\n",
      "epoch:18 step:16916 [D loss: 0.212766, acc.: 63.28%] [G loss: 0.458625]\n",
      "epoch:18 step:16917 [D loss: 0.242864, acc.: 56.25%] [G loss: 0.369090]\n",
      "epoch:18 step:16918 [D loss: 0.209233, acc.: 70.31%] [G loss: 0.459413]\n",
      "epoch:18 step:16919 [D loss: 0.227956, acc.: 59.38%] [G loss: 0.434765]\n",
      "epoch:18 step:16920 [D loss: 0.212525, acc.: 66.41%] [G loss: 0.469154]\n",
      "epoch:18 step:16921 [D loss: 0.218447, acc.: 64.84%] [G loss: 0.424998]\n",
      "epoch:18 step:16922 [D loss: 0.221451, acc.: 61.72%] [G loss: 0.443666]\n",
      "epoch:18 step:16923 [D loss: 0.250645, acc.: 58.59%] [G loss: 0.400136]\n",
      "epoch:18 step:16924 [D loss: 0.240504, acc.: 53.91%] [G loss: 0.428961]\n",
      "epoch:18 step:16925 [D loss: 0.202691, acc.: 67.19%] [G loss: 0.477771]\n",
      "epoch:18 step:16926 [D loss: 0.257905, acc.: 47.66%] [G loss: 0.427157]\n",
      "epoch:18 step:16927 [D loss: 0.219157, acc.: 61.72%] [G loss: 0.452515]\n",
      "epoch:18 step:16928 [D loss: 0.251239, acc.: 57.03%] [G loss: 0.384787]\n",
      "epoch:18 step:16929 [D loss: 0.237053, acc.: 56.25%] [G loss: 0.411763]\n",
      "epoch:18 step:16930 [D loss: 0.245400, acc.: 51.56%] [G loss: 0.415636]\n",
      "epoch:18 step:16931 [D loss: 0.217295, acc.: 64.84%] [G loss: 0.464516]\n",
      "epoch:18 step:16932 [D loss: 0.223392, acc.: 64.84%] [G loss: 0.424035]\n",
      "epoch:18 step:16933 [D loss: 0.218917, acc.: 61.72%] [G loss: 0.420700]\n",
      "epoch:18 step:16934 [D loss: 0.233910, acc.: 63.28%] [G loss: 0.411493]\n",
      "epoch:18 step:16935 [D loss: 0.207406, acc.: 67.97%] [G loss: 0.478685]\n",
      "epoch:18 step:16936 [D loss: 0.223769, acc.: 63.28%] [G loss: 0.458264]\n",
      "epoch:18 step:16937 [D loss: 0.251303, acc.: 51.56%] [G loss: 0.438943]\n",
      "epoch:18 step:16938 [D loss: 0.240084, acc.: 55.47%] [G loss: 0.445490]\n",
      "epoch:18 step:16939 [D loss: 0.214233, acc.: 67.19%] [G loss: 0.454037]\n",
      "epoch:18 step:16940 [D loss: 0.206981, acc.: 70.31%] [G loss: 0.434140]\n",
      "epoch:18 step:16941 [D loss: 0.230837, acc.: 63.28%] [G loss: 0.419319]\n",
      "epoch:18 step:16942 [D loss: 0.190225, acc.: 66.41%] [G loss: 0.465621]\n",
      "epoch:18 step:16943 [D loss: 0.201184, acc.: 64.84%] [G loss: 0.477307]\n",
      "epoch:18 step:16944 [D loss: 0.283675, acc.: 53.12%] [G loss: 0.395939]\n",
      "epoch:18 step:16945 [D loss: 0.241135, acc.: 58.59%] [G loss: 0.398870]\n",
      "epoch:18 step:16946 [D loss: 0.245419, acc.: 57.81%] [G loss: 0.395166]\n",
      "epoch:18 step:16947 [D loss: 0.245007, acc.: 60.16%] [G loss: 0.397837]\n",
      "epoch:18 step:16948 [D loss: 0.215502, acc.: 67.19%] [G loss: 0.442533]\n",
      "epoch:18 step:16949 [D loss: 0.219503, acc.: 66.41%] [G loss: 0.457222]\n",
      "epoch:18 step:16950 [D loss: 0.212339, acc.: 65.62%] [G loss: 0.432776]\n",
      "epoch:18 step:16951 [D loss: 0.236785, acc.: 58.59%] [G loss: 0.424269]\n",
      "epoch:18 step:16952 [D loss: 0.229773, acc.: 63.28%] [G loss: 0.436374]\n",
      "epoch:18 step:16953 [D loss: 0.212816, acc.: 66.41%] [G loss: 0.451177]\n",
      "epoch:18 step:16954 [D loss: 0.226541, acc.: 59.38%] [G loss: 0.448417]\n",
      "epoch:18 step:16955 [D loss: 0.215812, acc.: 67.97%] [G loss: 0.416038]\n",
      "epoch:18 step:16956 [D loss: 0.203448, acc.: 68.75%] [G loss: 0.437991]\n",
      "epoch:18 step:16957 [D loss: 0.219824, acc.: 66.41%] [G loss: 0.452974]\n",
      "epoch:18 step:16958 [D loss: 0.205175, acc.: 71.88%] [G loss: 0.459821]\n",
      "epoch:18 step:16959 [D loss: 0.186343, acc.: 72.66%] [G loss: 0.535114]\n",
      "epoch:18 step:16960 [D loss: 0.254228, acc.: 54.69%] [G loss: 0.493051]\n",
      "epoch:18 step:16961 [D loss: 0.239971, acc.: 60.16%] [G loss: 0.477148]\n",
      "epoch:18 step:16962 [D loss: 0.209886, acc.: 67.19%] [G loss: 0.438222]\n",
      "epoch:18 step:16963 [D loss: 0.185496, acc.: 70.31%] [G loss: 0.487023]\n",
      "epoch:18 step:16964 [D loss: 0.228495, acc.: 62.50%] [G loss: 0.453808]\n",
      "epoch:18 step:16965 [D loss: 0.228397, acc.: 56.25%] [G loss: 0.428705]\n",
      "epoch:18 step:16966 [D loss: 0.186481, acc.: 71.88%] [G loss: 0.443094]\n",
      "epoch:18 step:16967 [D loss: 0.222661, acc.: 60.16%] [G loss: 0.459681]\n",
      "epoch:18 step:16968 [D loss: 0.237830, acc.: 57.03%] [G loss: 0.451827]\n",
      "epoch:18 step:16969 [D loss: 0.238169, acc.: 64.06%] [G loss: 0.430162]\n",
      "epoch:18 step:16970 [D loss: 0.247385, acc.: 51.56%] [G loss: 0.360728]\n",
      "epoch:18 step:16971 [D loss: 0.236473, acc.: 61.72%] [G loss: 0.421150]\n",
      "epoch:18 step:16972 [D loss: 0.212303, acc.: 66.41%] [G loss: 0.458039]\n",
      "epoch:18 step:16973 [D loss: 0.190115, acc.: 73.44%] [G loss: 0.482812]\n",
      "epoch:18 step:16974 [D loss: 0.286417, acc.: 50.00%] [G loss: 0.473548]\n",
      "epoch:18 step:16975 [D loss: 0.278122, acc.: 57.03%] [G loss: 0.408596]\n",
      "epoch:18 step:16976 [D loss: 0.240384, acc.: 58.59%] [G loss: 0.406311]\n",
      "epoch:18 step:16977 [D loss: 0.212717, acc.: 67.97%] [G loss: 0.417055]\n",
      "epoch:18 step:16978 [D loss: 0.201984, acc.: 72.66%] [G loss: 0.447362]\n",
      "epoch:18 step:16979 [D loss: 0.197444, acc.: 67.97%] [G loss: 0.463516]\n",
      "epoch:18 step:16980 [D loss: 0.205339, acc.: 71.09%] [G loss: 0.490579]\n",
      "epoch:18 step:16981 [D loss: 0.202318, acc.: 69.53%] [G loss: 0.496156]\n",
      "epoch:18 step:16982 [D loss: 0.237679, acc.: 60.94%] [G loss: 0.458844]\n",
      "epoch:18 step:16983 [D loss: 0.212725, acc.: 62.50%] [G loss: 0.469661]\n",
      "epoch:18 step:16984 [D loss: 0.206285, acc.: 65.62%] [G loss: 0.469653]\n",
      "epoch:18 step:16985 [D loss: 0.195175, acc.: 60.94%] [G loss: 0.470764]\n",
      "epoch:18 step:16986 [D loss: 0.243221, acc.: 62.50%] [G loss: 0.453030]\n",
      "epoch:18 step:16987 [D loss: 0.231754, acc.: 58.59%] [G loss: 0.454430]\n",
      "epoch:18 step:16988 [D loss: 0.206646, acc.: 64.84%] [G loss: 0.451902]\n",
      "epoch:18 step:16989 [D loss: 0.212806, acc.: 63.28%] [G loss: 0.472813]\n",
      "epoch:18 step:16990 [D loss: 0.252336, acc.: 55.47%] [G loss: 0.477658]\n",
      "epoch:18 step:16991 [D loss: 0.232592, acc.: 60.16%] [G loss: 0.409211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16992 [D loss: 0.205774, acc.: 65.62%] [G loss: 0.462955]\n",
      "epoch:18 step:16993 [D loss: 0.206857, acc.: 66.41%] [G loss: 0.443638]\n",
      "epoch:18 step:16994 [D loss: 0.234479, acc.: 60.94%] [G loss: 0.418597]\n",
      "epoch:18 step:16995 [D loss: 0.217436, acc.: 69.53%] [G loss: 0.407432]\n",
      "epoch:18 step:16996 [D loss: 0.211800, acc.: 65.62%] [G loss: 0.411257]\n",
      "epoch:18 step:16997 [D loss: 0.233722, acc.: 64.84%] [G loss: 0.416373]\n",
      "epoch:18 step:16998 [D loss: 0.217888, acc.: 66.41%] [G loss: 0.452801]\n",
      "epoch:18 step:16999 [D loss: 0.247347, acc.: 55.47%] [G loss: 0.456889]\n",
      "epoch:18 step:17000 [D loss: 0.203340, acc.: 65.62%] [G loss: 0.473550]\n",
      "epoch:18 step:17001 [D loss: 0.244284, acc.: 63.28%] [G loss: 0.451599]\n",
      "epoch:18 step:17002 [D loss: 0.221001, acc.: 70.31%] [G loss: 0.466955]\n",
      "epoch:18 step:17003 [D loss: 0.269323, acc.: 54.69%] [G loss: 0.396878]\n",
      "epoch:18 step:17004 [D loss: 0.222895, acc.: 60.16%] [G loss: 0.416335]\n",
      "epoch:18 step:17005 [D loss: 0.229951, acc.: 62.50%] [G loss: 0.414732]\n",
      "epoch:18 step:17006 [D loss: 0.195792, acc.: 71.88%] [G loss: 0.451537]\n",
      "epoch:18 step:17007 [D loss: 0.203703, acc.: 67.19%] [G loss: 0.441226]\n",
      "epoch:18 step:17008 [D loss: 0.237520, acc.: 60.16%] [G loss: 0.425541]\n",
      "epoch:18 step:17009 [D loss: 0.251938, acc.: 57.81%] [G loss: 0.432740]\n",
      "epoch:18 step:17010 [D loss: 0.199804, acc.: 75.78%] [G loss: 0.430220]\n",
      "epoch:18 step:17011 [D loss: 0.215648, acc.: 63.28%] [G loss: 0.430472]\n",
      "epoch:18 step:17012 [D loss: 0.221677, acc.: 63.28%] [G loss: 0.465265]\n",
      "epoch:18 step:17013 [D loss: 0.217713, acc.: 62.50%] [G loss: 0.428136]\n",
      "epoch:18 step:17014 [D loss: 0.256393, acc.: 60.16%] [G loss: 0.393465]\n",
      "epoch:18 step:17015 [D loss: 0.212685, acc.: 65.62%] [G loss: 0.418784]\n",
      "epoch:18 step:17016 [D loss: 0.249731, acc.: 57.03%] [G loss: 0.413182]\n",
      "epoch:18 step:17017 [D loss: 0.195390, acc.: 66.41%] [G loss: 0.461271]\n",
      "epoch:18 step:17018 [D loss: 0.216766, acc.: 65.62%] [G loss: 0.466556]\n",
      "epoch:18 step:17019 [D loss: 0.229139, acc.: 65.62%] [G loss: 0.469202]\n",
      "epoch:18 step:17020 [D loss: 0.232022, acc.: 58.59%] [G loss: 0.415614]\n",
      "epoch:18 step:17021 [D loss: 0.205217, acc.: 65.62%] [G loss: 0.453899]\n",
      "epoch:18 step:17022 [D loss: 0.217887, acc.: 60.94%] [G loss: 0.423666]\n",
      "epoch:18 step:17023 [D loss: 0.226678, acc.: 60.16%] [G loss: 0.445928]\n",
      "epoch:18 step:17024 [D loss: 0.232738, acc.: 64.84%] [G loss: 0.445639]\n",
      "epoch:18 step:17025 [D loss: 0.221524, acc.: 62.50%] [G loss: 0.411983]\n",
      "epoch:18 step:17026 [D loss: 0.268543, acc.: 55.47%] [G loss: 0.459589]\n",
      "epoch:18 step:17027 [D loss: 0.231519, acc.: 55.47%] [G loss: 0.450058]\n",
      "epoch:18 step:17028 [D loss: 0.232999, acc.: 62.50%] [G loss: 0.445905]\n",
      "epoch:18 step:17029 [D loss: 0.227078, acc.: 62.50%] [G loss: 0.425235]\n",
      "epoch:18 step:17030 [D loss: 0.235676, acc.: 64.84%] [G loss: 0.433764]\n",
      "epoch:18 step:17031 [D loss: 0.223713, acc.: 64.06%] [G loss: 0.438556]\n",
      "epoch:18 step:17032 [D loss: 0.238221, acc.: 60.94%] [G loss: 0.410726]\n",
      "epoch:18 step:17033 [D loss: 0.220749, acc.: 61.72%] [G loss: 0.423136]\n",
      "epoch:18 step:17034 [D loss: 0.220788, acc.: 59.38%] [G loss: 0.418512]\n",
      "epoch:18 step:17035 [D loss: 0.241028, acc.: 60.94%] [G loss: 0.368810]\n",
      "epoch:18 step:17036 [D loss: 0.243654, acc.: 60.16%] [G loss: 0.394882]\n",
      "epoch:18 step:17037 [D loss: 0.229427, acc.: 62.50%] [G loss: 0.397736]\n",
      "epoch:18 step:17038 [D loss: 0.215121, acc.: 65.62%] [G loss: 0.461157]\n",
      "epoch:18 step:17039 [D loss: 0.229023, acc.: 60.94%] [G loss: 0.427135]\n",
      "epoch:18 step:17040 [D loss: 0.248349, acc.: 51.56%] [G loss: 0.405666]\n",
      "epoch:18 step:17041 [D loss: 0.231741, acc.: 60.94%] [G loss: 0.422214]\n",
      "epoch:18 step:17042 [D loss: 0.219306, acc.: 60.94%] [G loss: 0.436683]\n",
      "epoch:18 step:17043 [D loss: 0.229769, acc.: 61.72%] [G loss: 0.454054]\n",
      "epoch:18 step:17044 [D loss: 0.234832, acc.: 60.16%] [G loss: 0.407707]\n",
      "epoch:18 step:17045 [D loss: 0.232574, acc.: 65.62%] [G loss: 0.411655]\n",
      "epoch:18 step:17046 [D loss: 0.252048, acc.: 64.06%] [G loss: 0.401202]\n",
      "epoch:18 step:17047 [D loss: 0.225387, acc.: 57.81%] [G loss: 0.434134]\n",
      "epoch:18 step:17048 [D loss: 0.231603, acc.: 62.50%] [G loss: 0.431360]\n",
      "epoch:18 step:17049 [D loss: 0.266426, acc.: 50.78%] [G loss: 0.388283]\n",
      "epoch:18 step:17050 [D loss: 0.250955, acc.: 58.59%] [G loss: 0.388617]\n",
      "epoch:18 step:17051 [D loss: 0.206833, acc.: 67.97%] [G loss: 0.448355]\n",
      "epoch:18 step:17052 [D loss: 0.245604, acc.: 61.72%] [G loss: 0.430970]\n",
      "epoch:18 step:17053 [D loss: 0.221253, acc.: 61.72%] [G loss: 0.444882]\n",
      "epoch:18 step:17054 [D loss: 0.246322, acc.: 54.69%] [G loss: 0.480062]\n",
      "epoch:18 step:17055 [D loss: 0.258126, acc.: 52.34%] [G loss: 0.420380]\n",
      "epoch:18 step:17056 [D loss: 0.220426, acc.: 64.84%] [G loss: 0.415762]\n",
      "epoch:18 step:17057 [D loss: 0.225956, acc.: 60.94%] [G loss: 0.410176]\n",
      "epoch:18 step:17058 [D loss: 0.213128, acc.: 60.16%] [G loss: 0.409991]\n",
      "epoch:18 step:17059 [D loss: 0.233984, acc.: 62.50%] [G loss: 0.402911]\n",
      "epoch:18 step:17060 [D loss: 0.195312, acc.: 64.06%] [G loss: 0.445679]\n",
      "epoch:18 step:17061 [D loss: 0.238737, acc.: 58.59%] [G loss: 0.440526]\n",
      "epoch:18 step:17062 [D loss: 0.222156, acc.: 63.28%] [G loss: 0.470724]\n",
      "epoch:18 step:17063 [D loss: 0.200977, acc.: 67.19%] [G loss: 0.431524]\n",
      "epoch:18 step:17064 [D loss: 0.212597, acc.: 67.19%] [G loss: 0.442176]\n",
      "epoch:18 step:17065 [D loss: 0.214052, acc.: 64.84%] [G loss: 0.448722]\n",
      "epoch:18 step:17066 [D loss: 0.254116, acc.: 60.94%] [G loss: 0.422723]\n",
      "epoch:18 step:17067 [D loss: 0.247489, acc.: 57.81%] [G loss: 0.410393]\n",
      "epoch:18 step:17068 [D loss: 0.226627, acc.: 61.72%] [G loss: 0.435164]\n",
      "epoch:18 step:17069 [D loss: 0.252905, acc.: 57.03%] [G loss: 0.405330]\n",
      "epoch:18 step:17070 [D loss: 0.234734, acc.: 58.59%] [G loss: 0.435725]\n",
      "epoch:18 step:17071 [D loss: 0.206437, acc.: 67.19%] [G loss: 0.485442]\n",
      "epoch:18 step:17072 [D loss: 0.221720, acc.: 62.50%] [G loss: 0.447646]\n",
      "epoch:18 step:17073 [D loss: 0.208630, acc.: 67.97%] [G loss: 0.458682]\n",
      "epoch:18 step:17074 [D loss: 0.180897, acc.: 70.31%] [G loss: 0.452016]\n",
      "epoch:18 step:17075 [D loss: 0.205351, acc.: 72.66%] [G loss: 0.490592]\n",
      "epoch:18 step:17076 [D loss: 0.290895, acc.: 52.34%] [G loss: 0.415193]\n",
      "epoch:18 step:17077 [D loss: 0.226578, acc.: 56.25%] [G loss: 0.432804]\n",
      "epoch:18 step:17078 [D loss: 0.234575, acc.: 62.50%] [G loss: 0.429622]\n",
      "epoch:18 step:17079 [D loss: 0.219450, acc.: 64.84%] [G loss: 0.390310]\n",
      "epoch:18 step:17080 [D loss: 0.249256, acc.: 57.81%] [G loss: 0.445966]\n",
      "epoch:18 step:17081 [D loss: 0.253550, acc.: 56.25%] [G loss: 0.380272]\n",
      "epoch:18 step:17082 [D loss: 0.221964, acc.: 60.16%] [G loss: 0.426434]\n",
      "epoch:18 step:17083 [D loss: 0.203087, acc.: 67.97%] [G loss: 0.432747]\n",
      "epoch:18 step:17084 [D loss: 0.182196, acc.: 77.34%] [G loss: 0.420542]\n",
      "epoch:18 step:17085 [D loss: 0.201835, acc.: 68.75%] [G loss: 0.498761]\n",
      "epoch:18 step:17086 [D loss: 0.273921, acc.: 55.47%] [G loss: 0.477536]\n",
      "epoch:18 step:17087 [D loss: 0.212155, acc.: 66.41%] [G loss: 0.453537]\n",
      "epoch:18 step:17088 [D loss: 0.212825, acc.: 67.97%] [G loss: 0.455014]\n",
      "epoch:18 step:17089 [D loss: 0.201576, acc.: 69.53%] [G loss: 0.462167]\n",
      "epoch:18 step:17090 [D loss: 0.247868, acc.: 54.69%] [G loss: 0.437671]\n",
      "epoch:18 step:17091 [D loss: 0.244716, acc.: 59.38%] [G loss: 0.406204]\n",
      "epoch:18 step:17092 [D loss: 0.228350, acc.: 59.38%] [G loss: 0.400116]\n",
      "epoch:18 step:17093 [D loss: 0.230993, acc.: 64.84%] [G loss: 0.409337]\n",
      "epoch:18 step:17094 [D loss: 0.251065, acc.: 53.91%] [G loss: 0.387391]\n",
      "epoch:18 step:17095 [D loss: 0.211059, acc.: 70.31%] [G loss: 0.450410]\n",
      "epoch:18 step:17096 [D loss: 0.212058, acc.: 67.19%] [G loss: 0.471933]\n",
      "epoch:18 step:17097 [D loss: 0.186331, acc.: 71.09%] [G loss: 0.516007]\n",
      "epoch:18 step:17098 [D loss: 0.176512, acc.: 72.66%] [G loss: 0.522985]\n",
      "epoch:18 step:17099 [D loss: 0.230510, acc.: 58.59%] [G loss: 0.481246]\n",
      "epoch:18 step:17100 [D loss: 0.238153, acc.: 58.59%] [G loss: 0.446170]\n",
      "epoch:18 step:17101 [D loss: 0.221296, acc.: 67.97%] [G loss: 0.419548]\n",
      "epoch:18 step:17102 [D loss: 0.194791, acc.: 69.53%] [G loss: 0.423397]\n",
      "epoch:18 step:17103 [D loss: 0.228785, acc.: 67.19%] [G loss: 0.431156]\n",
      "epoch:18 step:17104 [D loss: 0.216684, acc.: 69.53%] [G loss: 0.433756]\n",
      "epoch:18 step:17105 [D loss: 0.227407, acc.: 63.28%] [G loss: 0.407782]\n",
      "epoch:18 step:17106 [D loss: 0.230877, acc.: 62.50%] [G loss: 0.437580]\n",
      "epoch:18 step:17107 [D loss: 0.204083, acc.: 73.44%] [G loss: 0.479704]\n",
      "epoch:18 step:17108 [D loss: 0.214867, acc.: 67.19%] [G loss: 0.440508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17109 [D loss: 0.221533, acc.: 66.41%] [G loss: 0.457572]\n",
      "epoch:18 step:17110 [D loss: 0.197761, acc.: 73.44%] [G loss: 0.444215]\n",
      "epoch:18 step:17111 [D loss: 0.201097, acc.: 67.97%] [G loss: 0.427071]\n",
      "epoch:18 step:17112 [D loss: 0.234806, acc.: 62.50%] [G loss: 0.476585]\n",
      "epoch:18 step:17113 [D loss: 0.237038, acc.: 57.03%] [G loss: 0.455152]\n",
      "epoch:18 step:17114 [D loss: 0.194796, acc.: 67.97%] [G loss: 0.467701]\n",
      "epoch:18 step:17115 [D loss: 0.264067, acc.: 57.03%] [G loss: 0.501604]\n",
      "epoch:18 step:17116 [D loss: 0.278344, acc.: 49.22%] [G loss: 0.419862]\n",
      "epoch:18 step:17117 [D loss: 0.263664, acc.: 48.44%] [G loss: 0.422688]\n",
      "epoch:18 step:17118 [D loss: 0.222020, acc.: 71.09%] [G loss: 0.468983]\n",
      "epoch:18 step:17119 [D loss: 0.244587, acc.: 59.38%] [G loss: 0.442177]\n",
      "epoch:18 step:17120 [D loss: 0.219422, acc.: 67.97%] [G loss: 0.453749]\n",
      "epoch:18 step:17121 [D loss: 0.209104, acc.: 63.28%] [G loss: 0.440313]\n",
      "epoch:18 step:17122 [D loss: 0.237292, acc.: 64.06%] [G loss: 0.426688]\n",
      "epoch:18 step:17123 [D loss: 0.222403, acc.: 61.72%] [G loss: 0.425354]\n",
      "epoch:18 step:17124 [D loss: 0.190744, acc.: 66.41%] [G loss: 0.412027]\n",
      "epoch:18 step:17125 [D loss: 0.216841, acc.: 67.19%] [G loss: 0.442192]\n",
      "epoch:18 step:17126 [D loss: 0.221722, acc.: 64.06%] [G loss: 0.430647]\n",
      "epoch:18 step:17127 [D loss: 0.249561, acc.: 55.47%] [G loss: 0.459244]\n",
      "epoch:18 step:17128 [D loss: 0.215410, acc.: 64.84%] [G loss: 0.450494]\n",
      "epoch:18 step:17129 [D loss: 0.260446, acc.: 57.03%] [G loss: 0.426902]\n",
      "epoch:18 step:17130 [D loss: 0.236676, acc.: 64.84%] [G loss: 0.449715]\n",
      "epoch:18 step:17131 [D loss: 0.255424, acc.: 53.91%] [G loss: 0.503537]\n",
      "epoch:18 step:17132 [D loss: 0.226420, acc.: 64.84%] [G loss: 0.460653]\n",
      "epoch:18 step:17133 [D loss: 0.248804, acc.: 54.69%] [G loss: 0.403190]\n",
      "epoch:18 step:17134 [D loss: 0.221438, acc.: 65.62%] [G loss: 0.459644]\n",
      "epoch:18 step:17135 [D loss: 0.230612, acc.: 61.72%] [G loss: 0.438705]\n",
      "epoch:18 step:17136 [D loss: 0.205891, acc.: 64.06%] [G loss: 0.465675]\n",
      "epoch:18 step:17137 [D loss: 0.216434, acc.: 66.41%] [G loss: 0.410432]\n",
      "epoch:18 step:17138 [D loss: 0.195400, acc.: 71.88%] [G loss: 0.446450]\n",
      "epoch:18 step:17139 [D loss: 0.210164, acc.: 61.72%] [G loss: 0.414552]\n",
      "epoch:18 step:17140 [D loss: 0.204455, acc.: 72.66%] [G loss: 0.412576]\n",
      "epoch:18 step:17141 [D loss: 0.233833, acc.: 60.16%] [G loss: 0.441188]\n",
      "epoch:18 step:17142 [D loss: 0.189443, acc.: 72.66%] [G loss: 0.439509]\n",
      "epoch:18 step:17143 [D loss: 0.242535, acc.: 56.25%] [G loss: 0.420810]\n",
      "epoch:18 step:17144 [D loss: 0.257688, acc.: 53.12%] [G loss: 0.409953]\n",
      "epoch:18 step:17145 [D loss: 0.221266, acc.: 59.38%] [G loss: 0.418530]\n",
      "epoch:18 step:17146 [D loss: 0.236769, acc.: 55.47%] [G loss: 0.434120]\n",
      "epoch:18 step:17147 [D loss: 0.262278, acc.: 52.34%] [G loss: 0.435736]\n",
      "epoch:18 step:17148 [D loss: 0.235548, acc.: 56.25%] [G loss: 0.441909]\n",
      "epoch:18 step:17149 [D loss: 0.206150, acc.: 70.31%] [G loss: 0.387341]\n",
      "epoch:18 step:17150 [D loss: 0.235053, acc.: 57.81%] [G loss: 0.429835]\n",
      "epoch:18 step:17151 [D loss: 0.218457, acc.: 62.50%] [G loss: 0.429827]\n",
      "epoch:18 step:17152 [D loss: 0.223177, acc.: 64.84%] [G loss: 0.470343]\n",
      "epoch:18 step:17153 [D loss: 0.225387, acc.: 64.06%] [G loss: 0.428952]\n",
      "epoch:18 step:17154 [D loss: 0.213274, acc.: 66.41%] [G loss: 0.495894]\n",
      "epoch:18 step:17155 [D loss: 0.217643, acc.: 64.84%] [G loss: 0.451669]\n",
      "epoch:18 step:17156 [D loss: 0.210279, acc.: 65.62%] [G loss: 0.502071]\n",
      "epoch:18 step:17157 [D loss: 0.251671, acc.: 57.81%] [G loss: 0.447024]\n",
      "epoch:18 step:17158 [D loss: 0.216210, acc.: 65.62%] [G loss: 0.437450]\n",
      "epoch:18 step:17159 [D loss: 0.215190, acc.: 63.28%] [G loss: 0.444790]\n",
      "epoch:18 step:17160 [D loss: 0.239826, acc.: 57.81%] [G loss: 0.423669]\n",
      "epoch:18 step:17161 [D loss: 0.224042, acc.: 64.06%] [G loss: 0.433810]\n",
      "epoch:18 step:17162 [D loss: 0.223892, acc.: 63.28%] [G loss: 0.443335]\n",
      "epoch:18 step:17163 [D loss: 0.236987, acc.: 56.25%] [G loss: 0.475002]\n",
      "epoch:18 step:17164 [D loss: 0.223286, acc.: 64.06%] [G loss: 0.433941]\n",
      "epoch:18 step:17165 [D loss: 0.209840, acc.: 66.41%] [G loss: 0.468447]\n",
      "epoch:18 step:17166 [D loss: 0.199980, acc.: 67.97%] [G loss: 0.440510]\n",
      "epoch:18 step:17167 [D loss: 0.262817, acc.: 55.47%] [G loss: 0.417671]\n",
      "epoch:18 step:17168 [D loss: 0.223524, acc.: 63.28%] [G loss: 0.439938]\n",
      "epoch:18 step:17169 [D loss: 0.243567, acc.: 60.94%] [G loss: 0.428766]\n",
      "epoch:18 step:17170 [D loss: 0.236047, acc.: 56.25%] [G loss: 0.403518]\n",
      "epoch:18 step:17171 [D loss: 0.240778, acc.: 58.59%] [G loss: 0.394215]\n",
      "epoch:18 step:17172 [D loss: 0.233763, acc.: 60.16%] [G loss: 0.418338]\n",
      "epoch:18 step:17173 [D loss: 0.206709, acc.: 70.31%] [G loss: 0.455855]\n",
      "epoch:18 step:17174 [D loss: 0.212768, acc.: 67.19%] [G loss: 0.477700]\n",
      "epoch:18 step:17175 [D loss: 0.211798, acc.: 65.62%] [G loss: 0.444632]\n",
      "epoch:18 step:17176 [D loss: 0.223589, acc.: 62.50%] [G loss: 0.435829]\n",
      "epoch:18 step:17177 [D loss: 0.221896, acc.: 64.06%] [G loss: 0.441037]\n",
      "epoch:18 step:17178 [D loss: 0.198499, acc.: 69.53%] [G loss: 0.455961]\n",
      "epoch:18 step:17179 [D loss: 0.199163, acc.: 71.88%] [G loss: 0.455437]\n",
      "epoch:18 step:17180 [D loss: 0.178631, acc.: 73.44%] [G loss: 0.504972]\n",
      "epoch:18 step:17181 [D loss: 0.186355, acc.: 71.88%] [G loss: 0.503780]\n",
      "epoch:18 step:17182 [D loss: 0.266908, acc.: 54.69%] [G loss: 0.436929]\n",
      "epoch:18 step:17183 [D loss: 0.241340, acc.: 60.16%] [G loss: 0.427481]\n",
      "epoch:18 step:17184 [D loss: 0.227755, acc.: 62.50%] [G loss: 0.424241]\n",
      "epoch:18 step:17185 [D loss: 0.219369, acc.: 61.72%] [G loss: 0.453225]\n",
      "epoch:18 step:17186 [D loss: 0.233956, acc.: 58.59%] [G loss: 0.435369]\n",
      "epoch:18 step:17187 [D loss: 0.201992, acc.: 67.19%] [G loss: 0.467611]\n",
      "epoch:18 step:17188 [D loss: 0.215347, acc.: 62.50%] [G loss: 0.470714]\n",
      "epoch:18 step:17189 [D loss: 0.253116, acc.: 54.69%] [G loss: 0.435661]\n",
      "epoch:18 step:17190 [D loss: 0.230916, acc.: 64.84%] [G loss: 0.414488]\n",
      "epoch:18 step:17191 [D loss: 0.199690, acc.: 69.53%] [G loss: 0.459176]\n",
      "epoch:18 step:17192 [D loss: 0.240370, acc.: 57.03%] [G loss: 0.426876]\n",
      "epoch:18 step:17193 [D loss: 0.226411, acc.: 59.38%] [G loss: 0.435510]\n",
      "epoch:18 step:17194 [D loss: 0.203638, acc.: 64.84%] [G loss: 0.484500]\n",
      "epoch:18 step:17195 [D loss: 0.220075, acc.: 62.50%] [G loss: 0.448309]\n",
      "epoch:18 step:17196 [D loss: 0.227984, acc.: 65.62%] [G loss: 0.424147]\n",
      "epoch:18 step:17197 [D loss: 0.236428, acc.: 64.06%] [G loss: 0.392640]\n",
      "epoch:18 step:17198 [D loss: 0.190955, acc.: 73.44%] [G loss: 0.455897]\n",
      "epoch:18 step:17199 [D loss: 0.220941, acc.: 60.16%] [G loss: 0.436074]\n",
      "epoch:18 step:17200 [D loss: 0.248610, acc.: 60.94%] [G loss: 0.421396]\n",
      "epoch:18 step:17201 [D loss: 0.229417, acc.: 60.94%] [G loss: 0.435454]\n",
      "epoch:18 step:17202 [D loss: 0.205731, acc.: 67.97%] [G loss: 0.440849]\n",
      "epoch:18 step:17203 [D loss: 0.229476, acc.: 59.38%] [G loss: 0.473634]\n",
      "epoch:18 step:17204 [D loss: 0.215804, acc.: 64.84%] [G loss: 0.437249]\n",
      "epoch:18 step:17205 [D loss: 0.199007, acc.: 70.31%] [G loss: 0.444737]\n",
      "epoch:18 step:17206 [D loss: 0.238160, acc.: 59.38%] [G loss: 0.403337]\n",
      "epoch:18 step:17207 [D loss: 0.285673, acc.: 51.56%] [G loss: 0.446728]\n",
      "epoch:18 step:17208 [D loss: 0.239329, acc.: 64.84%] [G loss: 0.479129]\n",
      "epoch:18 step:17209 [D loss: 0.222679, acc.: 63.28%] [G loss: 0.451812]\n",
      "epoch:18 step:17210 [D loss: 0.218286, acc.: 60.94%] [G loss: 0.490262]\n",
      "epoch:18 step:17211 [D loss: 0.213109, acc.: 68.75%] [G loss: 0.469961]\n",
      "epoch:18 step:17212 [D loss: 0.196024, acc.: 70.31%] [G loss: 0.464369]\n",
      "epoch:18 step:17213 [D loss: 0.192723, acc.: 66.41%] [G loss: 0.493335]\n",
      "epoch:18 step:17214 [D loss: 0.287165, acc.: 50.00%] [G loss: 0.431310]\n",
      "epoch:18 step:17215 [D loss: 0.280921, acc.: 53.91%] [G loss: 0.434496]\n",
      "epoch:18 step:17216 [D loss: 0.213283, acc.: 68.75%] [G loss: 0.397860]\n",
      "epoch:18 step:17217 [D loss: 0.227219, acc.: 62.50%] [G loss: 0.395824]\n",
      "epoch:18 step:17218 [D loss: 0.226175, acc.: 61.72%] [G loss: 0.418002]\n",
      "epoch:18 step:17219 [D loss: 0.212680, acc.: 67.19%] [G loss: 0.460793]\n",
      "epoch:18 step:17220 [D loss: 0.190981, acc.: 71.09%] [G loss: 0.430542]\n",
      "epoch:18 step:17221 [D loss: 0.227766, acc.: 58.59%] [G loss: 0.448675]\n",
      "epoch:18 step:17222 [D loss: 0.235025, acc.: 57.81%] [G loss: 0.451864]\n",
      "epoch:18 step:17223 [D loss: 0.203789, acc.: 68.75%] [G loss: 0.454957]\n",
      "epoch:18 step:17224 [D loss: 0.210342, acc.: 67.19%] [G loss: 0.483783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17225 [D loss: 0.220715, acc.: 66.41%] [G loss: 0.452816]\n",
      "epoch:18 step:17226 [D loss: 0.210866, acc.: 67.97%] [G loss: 0.450098]\n",
      "epoch:18 step:17227 [D loss: 0.213817, acc.: 67.19%] [G loss: 0.456918]\n",
      "epoch:18 step:17228 [D loss: 0.233668, acc.: 59.38%] [G loss: 0.481747]\n",
      "epoch:18 step:17229 [D loss: 0.217542, acc.: 64.06%] [G loss: 0.430899]\n",
      "epoch:18 step:17230 [D loss: 0.204746, acc.: 65.62%] [G loss: 0.430807]\n",
      "epoch:18 step:17231 [D loss: 0.244313, acc.: 54.69%] [G loss: 0.470523]\n",
      "epoch:18 step:17232 [D loss: 0.227138, acc.: 64.06%] [G loss: 0.462092]\n",
      "epoch:18 step:17233 [D loss: 0.190004, acc.: 73.44%] [G loss: 0.497449]\n",
      "epoch:18 step:17234 [D loss: 0.243824, acc.: 55.47%] [G loss: 0.430743]\n",
      "epoch:18 step:17235 [D loss: 0.228352, acc.: 61.72%] [G loss: 0.435248]\n",
      "epoch:18 step:17236 [D loss: 0.209245, acc.: 66.41%] [G loss: 0.443342]\n",
      "epoch:18 step:17237 [D loss: 0.199253, acc.: 75.78%] [G loss: 0.445167]\n",
      "epoch:18 step:17238 [D loss: 0.227454, acc.: 60.94%] [G loss: 0.471576]\n",
      "epoch:18 step:17239 [D loss: 0.246405, acc.: 60.16%] [G loss: 0.435073]\n",
      "epoch:18 step:17240 [D loss: 0.184900, acc.: 71.09%] [G loss: 0.441231]\n",
      "epoch:18 step:17241 [D loss: 0.233501, acc.: 60.16%] [G loss: 0.457049]\n",
      "epoch:18 step:17242 [D loss: 0.260680, acc.: 54.69%] [G loss: 0.432693]\n",
      "epoch:18 step:17243 [D loss: 0.223549, acc.: 64.84%] [G loss: 0.451962]\n",
      "epoch:18 step:17244 [D loss: 0.239460, acc.: 57.81%] [G loss: 0.394613]\n",
      "epoch:18 step:17245 [D loss: 0.246345, acc.: 58.59%] [G loss: 0.405396]\n",
      "epoch:18 step:17246 [D loss: 0.237762, acc.: 55.47%] [G loss: 0.400613]\n",
      "epoch:18 step:17247 [D loss: 0.210901, acc.: 64.84%] [G loss: 0.432545]\n",
      "epoch:18 step:17248 [D loss: 0.253409, acc.: 57.81%] [G loss: 0.438500]\n",
      "epoch:18 step:17249 [D loss: 0.225322, acc.: 63.28%] [G loss: 0.430730]\n",
      "epoch:18 step:17250 [D loss: 0.214081, acc.: 61.72%] [G loss: 0.425368]\n",
      "epoch:18 step:17251 [D loss: 0.226515, acc.: 61.72%] [G loss: 0.442811]\n",
      "epoch:18 step:17252 [D loss: 0.231656, acc.: 56.25%] [G loss: 0.474735]\n",
      "epoch:18 step:17253 [D loss: 0.226357, acc.: 67.19%] [G loss: 0.434310]\n",
      "epoch:18 step:17254 [D loss: 0.197464, acc.: 70.31%] [G loss: 0.497014]\n",
      "epoch:18 step:17255 [D loss: 0.218221, acc.: 61.72%] [G loss: 0.419159]\n",
      "epoch:18 step:17256 [D loss: 0.258538, acc.: 58.59%] [G loss: 0.392023]\n",
      "epoch:18 step:17257 [D loss: 0.230038, acc.: 59.38%] [G loss: 0.425640]\n",
      "epoch:18 step:17258 [D loss: 0.239715, acc.: 55.47%] [G loss: 0.430854]\n",
      "epoch:18 step:17259 [D loss: 0.239956, acc.: 60.94%] [G loss: 0.441451]\n",
      "epoch:18 step:17260 [D loss: 0.217707, acc.: 67.19%] [G loss: 0.473654]\n",
      "epoch:18 step:17261 [D loss: 0.244182, acc.: 56.25%] [G loss: 0.398847]\n",
      "epoch:18 step:17262 [D loss: 0.272828, acc.: 46.09%] [G loss: 0.415060]\n",
      "epoch:18 step:17263 [D loss: 0.243022, acc.: 61.72%] [G loss: 0.411814]\n",
      "epoch:18 step:17264 [D loss: 0.182395, acc.: 71.09%] [G loss: 0.472390]\n",
      "epoch:18 step:17265 [D loss: 0.223372, acc.: 60.94%] [G loss: 0.490906]\n",
      "epoch:18 step:17266 [D loss: 0.270359, acc.: 47.66%] [G loss: 0.424743]\n",
      "epoch:18 step:17267 [D loss: 0.233251, acc.: 58.59%] [G loss: 0.402415]\n",
      "epoch:18 step:17268 [D loss: 0.216277, acc.: 67.19%] [G loss: 0.405539]\n",
      "epoch:18 step:17269 [D loss: 0.269144, acc.: 56.25%] [G loss: 0.421206]\n",
      "epoch:18 step:17270 [D loss: 0.247395, acc.: 53.91%] [G loss: 0.459879]\n",
      "epoch:18 step:17271 [D loss: 0.209790, acc.: 66.41%] [G loss: 0.484015]\n",
      "epoch:18 step:17272 [D loss: 0.193990, acc.: 70.31%] [G loss: 0.448602]\n",
      "epoch:18 step:17273 [D loss: 0.234960, acc.: 60.94%] [G loss: 0.445235]\n",
      "epoch:18 step:17274 [D loss: 0.243935, acc.: 57.03%] [G loss: 0.483603]\n",
      "epoch:18 step:17275 [D loss: 0.236174, acc.: 58.59%] [G loss: 0.454970]\n",
      "epoch:18 step:17276 [D loss: 0.237856, acc.: 62.50%] [G loss: 0.388797]\n",
      "epoch:18 step:17277 [D loss: 0.273071, acc.: 50.78%] [G loss: 0.380073]\n",
      "epoch:18 step:17278 [D loss: 0.232456, acc.: 57.81%] [G loss: 0.403658]\n",
      "epoch:18 step:17279 [D loss: 0.241040, acc.: 60.94%] [G loss: 0.389313]\n",
      "epoch:18 step:17280 [D loss: 0.210368, acc.: 71.09%] [G loss: 0.469178]\n",
      "epoch:18 step:17281 [D loss: 0.195383, acc.: 66.41%] [G loss: 0.500798]\n",
      "epoch:18 step:17282 [D loss: 0.200670, acc.: 72.66%] [G loss: 0.493725]\n",
      "epoch:18 step:17283 [D loss: 0.229951, acc.: 65.62%] [G loss: 0.466778]\n",
      "epoch:18 step:17284 [D loss: 0.262414, acc.: 48.44%] [G loss: 0.407431]\n",
      "epoch:18 step:17285 [D loss: 0.257215, acc.: 58.59%] [G loss: 0.444209]\n",
      "epoch:18 step:17286 [D loss: 0.222198, acc.: 67.97%] [G loss: 0.446601]\n",
      "epoch:18 step:17287 [D loss: 0.244814, acc.: 57.81%] [G loss: 0.430432]\n",
      "epoch:18 step:17288 [D loss: 0.249433, acc.: 57.81%] [G loss: 0.413846]\n",
      "epoch:18 step:17289 [D loss: 0.220885, acc.: 65.62%] [G loss: 0.454266]\n",
      "epoch:18 step:17290 [D loss: 0.257398, acc.: 50.78%] [G loss: 0.372014]\n",
      "epoch:18 step:17291 [D loss: 0.211128, acc.: 65.62%] [G loss: 0.400420]\n",
      "epoch:18 step:17292 [D loss: 0.210005, acc.: 70.31%] [G loss: 0.421162]\n",
      "epoch:18 step:17293 [D loss: 0.231126, acc.: 61.72%] [G loss: 0.424959]\n",
      "epoch:18 step:17294 [D loss: 0.221975, acc.: 67.19%] [G loss: 0.432717]\n",
      "epoch:18 step:17295 [D loss: 0.178612, acc.: 75.78%] [G loss: 0.490615]\n",
      "epoch:18 step:17296 [D loss: 0.206269, acc.: 68.75%] [G loss: 0.430877]\n",
      "epoch:18 step:17297 [D loss: 0.251146, acc.: 60.94%] [G loss: 0.430439]\n",
      "epoch:18 step:17298 [D loss: 0.228174, acc.: 60.16%] [G loss: 0.453336]\n",
      "epoch:18 step:17299 [D loss: 0.223273, acc.: 60.16%] [G loss: 0.400446]\n",
      "epoch:18 step:17300 [D loss: 0.219072, acc.: 68.75%] [G loss: 0.432551]\n",
      "epoch:18 step:17301 [D loss: 0.208237, acc.: 70.31%] [G loss: 0.455929]\n",
      "epoch:18 step:17302 [D loss: 0.226373, acc.: 63.28%] [G loss: 0.505156]\n",
      "epoch:18 step:17303 [D loss: 0.261988, acc.: 53.12%] [G loss: 0.434661]\n",
      "epoch:18 step:17304 [D loss: 0.242839, acc.: 57.81%] [G loss: 0.407242]\n",
      "epoch:18 step:17305 [D loss: 0.211585, acc.: 70.31%] [G loss: 0.444638]\n",
      "epoch:18 step:17306 [D loss: 0.232766, acc.: 66.41%] [G loss: 0.435343]\n",
      "epoch:18 step:17307 [D loss: 0.233971, acc.: 60.94%] [G loss: 0.413659]\n",
      "epoch:18 step:17308 [D loss: 0.231937, acc.: 57.81%] [G loss: 0.447685]\n",
      "epoch:18 step:17309 [D loss: 0.251795, acc.: 54.69%] [G loss: 0.401227]\n",
      "epoch:18 step:17310 [D loss: 0.219889, acc.: 63.28%] [G loss: 0.476674]\n",
      "epoch:18 step:17311 [D loss: 0.220112, acc.: 64.06%] [G loss: 0.439588]\n",
      "epoch:18 step:17312 [D loss: 0.245394, acc.: 57.03%] [G loss: 0.414954]\n",
      "epoch:18 step:17313 [D loss: 0.229619, acc.: 63.28%] [G loss: 0.468859]\n",
      "epoch:18 step:17314 [D loss: 0.264081, acc.: 48.44%] [G loss: 0.417343]\n",
      "epoch:18 step:17315 [D loss: 0.221229, acc.: 64.06%] [G loss: 0.419048]\n",
      "epoch:18 step:17316 [D loss: 0.215046, acc.: 67.19%] [G loss: 0.394965]\n",
      "epoch:18 step:17317 [D loss: 0.206765, acc.: 70.31%] [G loss: 0.449798]\n",
      "epoch:18 step:17318 [D loss: 0.208118, acc.: 65.62%] [G loss: 0.423954]\n",
      "epoch:18 step:17319 [D loss: 0.195698, acc.: 65.62%] [G loss: 0.452412]\n",
      "epoch:18 step:17320 [D loss: 0.229108, acc.: 58.59%] [G loss: 0.477287]\n",
      "epoch:18 step:17321 [D loss: 0.232474, acc.: 62.50%] [G loss: 0.439701]\n",
      "epoch:18 step:17322 [D loss: 0.222644, acc.: 65.62%] [G loss: 0.457917]\n",
      "epoch:18 step:17323 [D loss: 0.216633, acc.: 61.72%] [G loss: 0.477093]\n",
      "epoch:18 step:17324 [D loss: 0.284409, acc.: 48.44%] [G loss: 0.410486]\n",
      "epoch:18 step:17325 [D loss: 0.243779, acc.: 59.38%] [G loss: 0.393976]\n",
      "epoch:18 step:17326 [D loss: 0.219253, acc.: 66.41%] [G loss: 0.399138]\n",
      "epoch:18 step:17327 [D loss: 0.246012, acc.: 58.59%] [G loss: 0.387981]\n",
      "epoch:18 step:17328 [D loss: 0.228745, acc.: 55.47%] [G loss: 0.428791]\n",
      "epoch:18 step:17329 [D loss: 0.237635, acc.: 57.81%] [G loss: 0.429131]\n",
      "epoch:18 step:17330 [D loss: 0.221105, acc.: 62.50%] [G loss: 0.460541]\n",
      "epoch:18 step:17331 [D loss: 0.242650, acc.: 57.03%] [G loss: 0.423243]\n",
      "epoch:18 step:17332 [D loss: 0.231062, acc.: 61.72%] [G loss: 0.424803]\n",
      "epoch:18 step:17333 [D loss: 0.236485, acc.: 60.94%] [G loss: 0.419577]\n",
      "epoch:18 step:17334 [D loss: 0.203712, acc.: 64.06%] [G loss: 0.455257]\n",
      "epoch:18 step:17335 [D loss: 0.224473, acc.: 65.62%] [G loss: 0.451313]\n",
      "epoch:18 step:17336 [D loss: 0.212366, acc.: 64.84%] [G loss: 0.509527]\n",
      "epoch:18 step:17337 [D loss: 0.207795, acc.: 74.22%] [G loss: 0.496231]\n",
      "epoch:18 step:17338 [D loss: 0.200687, acc.: 72.66%] [G loss: 0.444348]\n",
      "epoch:18 step:17339 [D loss: 0.255273, acc.: 58.59%] [G loss: 0.443241]\n",
      "epoch:18 step:17340 [D loss: 0.220764, acc.: 63.28%] [G loss: 0.435687]\n",
      "epoch:18 step:17341 [D loss: 0.203212, acc.: 69.53%] [G loss: 0.427340]\n",
      "epoch:18 step:17342 [D loss: 0.224550, acc.: 67.97%] [G loss: 0.428889]\n",
      "epoch:18 step:17343 [D loss: 0.270481, acc.: 46.88%] [G loss: 0.423059]\n",
      "epoch:18 step:17344 [D loss: 0.241274, acc.: 57.81%] [G loss: 0.420063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17345 [D loss: 0.210802, acc.: 66.41%] [G loss: 0.412676]\n",
      "epoch:18 step:17346 [D loss: 0.225804, acc.: 69.53%] [G loss: 0.426974]\n",
      "epoch:18 step:17347 [D loss: 0.175542, acc.: 71.88%] [G loss: 0.464657]\n",
      "epoch:18 step:17348 [D loss: 0.259835, acc.: 53.91%] [G loss: 0.430894]\n",
      "epoch:18 step:17349 [D loss: 0.231026, acc.: 59.38%] [G loss: 0.442509]\n",
      "epoch:18 step:17350 [D loss: 0.199803, acc.: 67.19%] [G loss: 0.453813]\n",
      "epoch:18 step:17351 [D loss: 0.233380, acc.: 62.50%] [G loss: 0.465772]\n",
      "epoch:18 step:17352 [D loss: 0.216214, acc.: 64.06%] [G loss: 0.469206]\n",
      "epoch:18 step:17353 [D loss: 0.237926, acc.: 57.81%] [G loss: 0.420370]\n",
      "epoch:18 step:17354 [D loss: 0.194331, acc.: 69.53%] [G loss: 0.459602]\n",
      "epoch:18 step:17355 [D loss: 0.236517, acc.: 62.50%] [G loss: 0.465363]\n",
      "epoch:18 step:17356 [D loss: 0.242806, acc.: 61.72%] [G loss: 0.412562]\n",
      "epoch:18 step:17357 [D loss: 0.208139, acc.: 66.41%] [G loss: 0.434227]\n",
      "epoch:18 step:17358 [D loss: 0.252775, acc.: 57.81%] [G loss: 0.453868]\n",
      "epoch:18 step:17359 [D loss: 0.213540, acc.: 69.53%] [G loss: 0.430113]\n",
      "epoch:18 step:17360 [D loss: 0.215500, acc.: 64.06%] [G loss: 0.448905]\n",
      "epoch:18 step:17361 [D loss: 0.212219, acc.: 66.41%] [G loss: 0.466174]\n",
      "epoch:18 step:17362 [D loss: 0.202804, acc.: 68.75%] [G loss: 0.481744]\n",
      "epoch:18 step:17363 [D loss: 0.221804, acc.: 66.41%] [G loss: 0.441170]\n",
      "epoch:18 step:17364 [D loss: 0.209139, acc.: 65.62%] [G loss: 0.442272]\n",
      "epoch:18 step:17365 [D loss: 0.161132, acc.: 82.03%] [G loss: 0.466884]\n",
      "epoch:18 step:17366 [D loss: 0.249305, acc.: 57.81%] [G loss: 0.418050]\n",
      "epoch:18 step:17367 [D loss: 0.270526, acc.: 49.22%] [G loss: 0.433122]\n",
      "epoch:18 step:17368 [D loss: 0.254864, acc.: 53.12%] [G loss: 0.412870]\n",
      "epoch:18 step:17369 [D loss: 0.242916, acc.: 57.81%] [G loss: 0.415234]\n",
      "epoch:18 step:17370 [D loss: 0.178815, acc.: 71.09%] [G loss: 0.442358]\n",
      "epoch:18 step:17371 [D loss: 0.201696, acc.: 68.75%] [G loss: 0.496974]\n",
      "epoch:18 step:17372 [D loss: 0.240325, acc.: 58.59%] [G loss: 0.480661]\n",
      "epoch:18 step:17373 [D loss: 0.214781, acc.: 67.97%] [G loss: 0.448862]\n",
      "epoch:18 step:17374 [D loss: 0.179627, acc.: 76.56%] [G loss: 0.490090]\n",
      "epoch:18 step:17375 [D loss: 0.249462, acc.: 55.47%] [G loss: 0.467344]\n",
      "epoch:18 step:17376 [D loss: 0.240377, acc.: 57.03%] [G loss: 0.418627]\n",
      "epoch:18 step:17377 [D loss: 0.224006, acc.: 64.84%] [G loss: 0.420407]\n",
      "epoch:18 step:17378 [D loss: 0.233493, acc.: 60.16%] [G loss: 0.421986]\n",
      "epoch:18 step:17379 [D loss: 0.237853, acc.: 54.69%] [G loss: 0.427880]\n",
      "epoch:18 step:17380 [D loss: 0.215200, acc.: 65.62%] [G loss: 0.418235]\n",
      "epoch:18 step:17381 [D loss: 0.214622, acc.: 64.84%] [G loss: 0.489161]\n",
      "epoch:18 step:17382 [D loss: 0.190593, acc.: 69.53%] [G loss: 0.481725]\n",
      "epoch:18 step:17383 [D loss: 0.232780, acc.: 57.81%] [G loss: 0.435554]\n",
      "epoch:18 step:17384 [D loss: 0.245770, acc.: 53.12%] [G loss: 0.387850]\n",
      "epoch:18 step:17385 [D loss: 0.198022, acc.: 68.75%] [G loss: 0.414397]\n",
      "epoch:18 step:17386 [D loss: 0.209755, acc.: 69.53%] [G loss: 0.449547]\n",
      "epoch:18 step:17387 [D loss: 0.212109, acc.: 68.75%] [G loss: 0.432329]\n",
      "epoch:18 step:17388 [D loss: 0.206075, acc.: 62.50%] [G loss: 0.464758]\n",
      "epoch:18 step:17389 [D loss: 0.233770, acc.: 64.84%] [G loss: 0.431789]\n",
      "epoch:18 step:17390 [D loss: 0.208516, acc.: 68.75%] [G loss: 0.441303]\n",
      "epoch:18 step:17391 [D loss: 0.219714, acc.: 66.41%] [G loss: 0.476951]\n",
      "epoch:18 step:17392 [D loss: 0.211081, acc.: 64.84%] [G loss: 0.443427]\n",
      "epoch:18 step:17393 [D loss: 0.237287, acc.: 59.38%] [G loss: 0.457339]\n",
      "epoch:18 step:17394 [D loss: 0.264341, acc.: 55.47%] [G loss: 0.459836]\n",
      "epoch:18 step:17395 [D loss: 0.238762, acc.: 57.81%] [G loss: 0.406982]\n",
      "epoch:18 step:17396 [D loss: 0.234150, acc.: 59.38%] [G loss: 0.426076]\n",
      "epoch:18 step:17397 [D loss: 0.246975, acc.: 56.25%] [G loss: 0.419719]\n",
      "epoch:18 step:17398 [D loss: 0.237002, acc.: 55.47%] [G loss: 0.355252]\n",
      "epoch:18 step:17399 [D loss: 0.238331, acc.: 60.16%] [G loss: 0.400829]\n",
      "epoch:18 step:17400 [D loss: 0.188129, acc.: 71.09%] [G loss: 0.438283]\n",
      "epoch:18 step:17401 [D loss: 0.237038, acc.: 57.81%] [G loss: 0.460704]\n",
      "epoch:18 step:17402 [D loss: 0.209786, acc.: 64.84%] [G loss: 0.439033]\n",
      "epoch:18 step:17403 [D loss: 0.239349, acc.: 57.03%] [G loss: 0.430242]\n",
      "epoch:18 step:17404 [D loss: 0.252220, acc.: 54.69%] [G loss: 0.413976]\n",
      "epoch:18 step:17405 [D loss: 0.224383, acc.: 60.16%] [G loss: 0.439492]\n",
      "epoch:18 step:17406 [D loss: 0.215256, acc.: 63.28%] [G loss: 0.425920]\n",
      "epoch:18 step:17407 [D loss: 0.227531, acc.: 65.62%] [G loss: 0.424685]\n",
      "epoch:18 step:17408 [D loss: 0.238501, acc.: 57.81%] [G loss: 0.400637]\n",
      "epoch:18 step:17409 [D loss: 0.230820, acc.: 61.72%] [G loss: 0.449965]\n",
      "epoch:18 step:17410 [D loss: 0.216556, acc.: 64.06%] [G loss: 0.459827]\n",
      "epoch:18 step:17411 [D loss: 0.223021, acc.: 67.19%] [G loss: 0.428439]\n",
      "epoch:18 step:17412 [D loss: 0.202532, acc.: 67.97%] [G loss: 0.438023]\n",
      "epoch:18 step:17413 [D loss: 0.207728, acc.: 67.97%] [G loss: 0.434322]\n",
      "epoch:18 step:17414 [D loss: 0.195733, acc.: 67.97%] [G loss: 0.428408]\n",
      "epoch:18 step:17415 [D loss: 0.203519, acc.: 66.41%] [G loss: 0.449133]\n",
      "epoch:18 step:17416 [D loss: 0.197855, acc.: 68.75%] [G loss: 0.453512]\n",
      "epoch:18 step:17417 [D loss: 0.181480, acc.: 75.78%] [G loss: 0.485465]\n",
      "epoch:18 step:17418 [D loss: 0.212894, acc.: 64.84%] [G loss: 0.466630]\n",
      "epoch:18 step:17419 [D loss: 0.247239, acc.: 59.38%] [G loss: 0.450668]\n",
      "epoch:18 step:17420 [D loss: 0.193432, acc.: 73.44%] [G loss: 0.446100]\n",
      "epoch:18 step:17421 [D loss: 0.208190, acc.: 70.31%] [G loss: 0.484135]\n",
      "epoch:18 step:17422 [D loss: 0.221543, acc.: 64.06%] [G loss: 0.442372]\n",
      "epoch:18 step:17423 [D loss: 0.224290, acc.: 63.28%] [G loss: 0.456673]\n",
      "epoch:18 step:17424 [D loss: 0.205662, acc.: 68.75%] [G loss: 0.442546]\n",
      "epoch:18 step:17425 [D loss: 0.266551, acc.: 51.56%] [G loss: 0.407824]\n",
      "epoch:18 step:17426 [D loss: 0.253567, acc.: 54.69%] [G loss: 0.402915]\n",
      "epoch:18 step:17427 [D loss: 0.209957, acc.: 64.84%] [G loss: 0.467649]\n",
      "epoch:18 step:17428 [D loss: 0.217904, acc.: 59.38%] [G loss: 0.428990]\n",
      "epoch:18 step:17429 [D loss: 0.221039, acc.: 64.06%] [G loss: 0.468726]\n",
      "epoch:18 step:17430 [D loss: 0.217329, acc.: 64.06%] [G loss: 0.459284]\n",
      "epoch:18 step:17431 [D loss: 0.219284, acc.: 61.72%] [G loss: 0.459276]\n",
      "epoch:18 step:17432 [D loss: 0.267166, acc.: 50.78%] [G loss: 0.421776]\n",
      "epoch:18 step:17433 [D loss: 0.206089, acc.: 65.62%] [G loss: 0.442540]\n",
      "epoch:18 step:17434 [D loss: 0.219929, acc.: 65.62%] [G loss: 0.438330]\n",
      "epoch:18 step:17435 [D loss: 0.241446, acc.: 63.28%] [G loss: 0.409638]\n",
      "epoch:18 step:17436 [D loss: 0.201352, acc.: 69.53%] [G loss: 0.424051]\n",
      "epoch:18 step:17437 [D loss: 0.203307, acc.: 67.19%] [G loss: 0.430558]\n",
      "epoch:18 step:17438 [D loss: 0.242315, acc.: 62.50%] [G loss: 0.404550]\n",
      "epoch:18 step:17439 [D loss: 0.231460, acc.: 64.84%] [G loss: 0.469147]\n",
      "epoch:18 step:17440 [D loss: 0.200802, acc.: 68.75%] [G loss: 0.516444]\n",
      "epoch:18 step:17441 [D loss: 0.198499, acc.: 71.88%] [G loss: 0.472145]\n",
      "epoch:18 step:17442 [D loss: 0.246106, acc.: 57.03%] [G loss: 0.416430]\n",
      "epoch:18 step:17443 [D loss: 0.224961, acc.: 62.50%] [G loss: 0.405466]\n",
      "epoch:18 step:17444 [D loss: 0.252837, acc.: 57.03%] [G loss: 0.399440]\n",
      "epoch:18 step:17445 [D loss: 0.239112, acc.: 56.25%] [G loss: 0.426445]\n",
      "epoch:18 step:17446 [D loss: 0.216155, acc.: 67.97%] [G loss: 0.414767]\n",
      "epoch:18 step:17447 [D loss: 0.207430, acc.: 65.62%] [G loss: 0.414247]\n",
      "epoch:18 step:17448 [D loss: 0.192448, acc.: 69.53%] [G loss: 0.465976]\n",
      "epoch:18 step:17449 [D loss: 0.237351, acc.: 57.03%] [G loss: 0.488389]\n",
      "epoch:18 step:17450 [D loss: 0.219151, acc.: 63.28%] [G loss: 0.443507]\n",
      "epoch:18 step:17451 [D loss: 0.242918, acc.: 57.03%] [G loss: 0.444579]\n",
      "epoch:18 step:17452 [D loss: 0.207711, acc.: 64.84%] [G loss: 0.431871]\n",
      "epoch:18 step:17453 [D loss: 0.251650, acc.: 53.91%] [G loss: 0.404654]\n",
      "epoch:18 step:17454 [D loss: 0.220755, acc.: 64.84%] [G loss: 0.436187]\n",
      "epoch:18 step:17455 [D loss: 0.207549, acc.: 65.62%] [G loss: 0.452084]\n",
      "epoch:18 step:17456 [D loss: 0.264446, acc.: 50.00%] [G loss: 0.464413]\n",
      "epoch:18 step:17457 [D loss: 0.241335, acc.: 61.72%] [G loss: 0.416928]\n",
      "epoch:18 step:17458 [D loss: 0.219469, acc.: 61.72%] [G loss: 0.414766]\n",
      "epoch:18 step:17459 [D loss: 0.203634, acc.: 64.84%] [G loss: 0.460290]\n",
      "epoch:18 step:17460 [D loss: 0.252786, acc.: 54.69%] [G loss: 0.404339]\n",
      "epoch:18 step:17461 [D loss: 0.232072, acc.: 60.94%] [G loss: 0.381325]\n",
      "epoch:18 step:17462 [D loss: 0.241892, acc.: 57.03%] [G loss: 0.433570]\n",
      "epoch:18 step:17463 [D loss: 0.222815, acc.: 64.84%] [G loss: 0.439521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17464 [D loss: 0.211814, acc.: 65.62%] [G loss: 0.425294]\n",
      "epoch:18 step:17465 [D loss: 0.210288, acc.: 64.84%] [G loss: 0.446115]\n",
      "epoch:18 step:17466 [D loss: 0.235644, acc.: 61.72%] [G loss: 0.459161]\n",
      "epoch:18 step:17467 [D loss: 0.233277, acc.: 59.38%] [G loss: 0.446029]\n",
      "epoch:18 step:17468 [D loss: 0.248871, acc.: 52.34%] [G loss: 0.447567]\n",
      "epoch:18 step:17469 [D loss: 0.233501, acc.: 61.72%] [G loss: 0.415002]\n",
      "epoch:18 step:17470 [D loss: 0.215299, acc.: 61.72%] [G loss: 0.438195]\n",
      "epoch:18 step:17471 [D loss: 0.195994, acc.: 70.31%] [G loss: 0.449110]\n",
      "epoch:18 step:17472 [D loss: 0.219666, acc.: 64.06%] [G loss: 0.422680]\n",
      "epoch:18 step:17473 [D loss: 0.223885, acc.: 60.94%] [G loss: 0.432419]\n",
      "epoch:18 step:17474 [D loss: 0.216058, acc.: 64.06%] [G loss: 0.405200]\n",
      "epoch:18 step:17475 [D loss: 0.207001, acc.: 67.97%] [G loss: 0.452924]\n",
      "epoch:18 step:17476 [D loss: 0.247085, acc.: 57.03%] [G loss: 0.384914]\n",
      "epoch:18 step:17477 [D loss: 0.213650, acc.: 66.41%] [G loss: 0.392168]\n",
      "epoch:18 step:17478 [D loss: 0.233017, acc.: 59.38%] [G loss: 0.411041]\n",
      "epoch:18 step:17479 [D loss: 0.230732, acc.: 63.28%] [G loss: 0.405358]\n",
      "epoch:18 step:17480 [D loss: 0.254735, acc.: 50.78%] [G loss: 0.423455]\n",
      "epoch:18 step:17481 [D loss: 0.257782, acc.: 55.47%] [G loss: 0.406471]\n",
      "epoch:18 step:17482 [D loss: 0.251622, acc.: 57.03%] [G loss: 0.427555]\n",
      "epoch:18 step:17483 [D loss: 0.227193, acc.: 65.62%] [G loss: 0.422747]\n",
      "epoch:18 step:17484 [D loss: 0.229619, acc.: 63.28%] [G loss: 0.422698]\n",
      "epoch:18 step:17485 [D loss: 0.243535, acc.: 58.59%] [G loss: 0.439143]\n",
      "epoch:18 step:17486 [D loss: 0.195669, acc.: 64.06%] [G loss: 0.459884]\n",
      "epoch:18 step:17487 [D loss: 0.210549, acc.: 64.06%] [G loss: 0.439526]\n",
      "epoch:18 step:17488 [D loss: 0.240486, acc.: 60.16%] [G loss: 0.415793]\n",
      "epoch:18 step:17489 [D loss: 0.231747, acc.: 59.38%] [G loss: 0.395251]\n",
      "epoch:18 step:17490 [D loss: 0.194237, acc.: 69.53%] [G loss: 0.447716]\n",
      "epoch:18 step:17491 [D loss: 0.230919, acc.: 64.06%] [G loss: 0.441419]\n",
      "epoch:18 step:17492 [D loss: 0.250394, acc.: 55.47%] [G loss: 0.450595]\n",
      "epoch:18 step:17493 [D loss: 0.220329, acc.: 63.28%] [G loss: 0.451574]\n",
      "epoch:18 step:17494 [D loss: 0.210802, acc.: 70.31%] [G loss: 0.465093]\n",
      "epoch:18 step:17495 [D loss: 0.221590, acc.: 64.84%] [G loss: 0.437080]\n",
      "epoch:18 step:17496 [D loss: 0.244338, acc.: 61.72%] [G loss: 0.411107]\n",
      "epoch:18 step:17497 [D loss: 0.228549, acc.: 62.50%] [G loss: 0.446640]\n",
      "epoch:18 step:17498 [D loss: 0.230118, acc.: 60.94%] [G loss: 0.408400]\n",
      "epoch:18 step:17499 [D loss: 0.233699, acc.: 60.94%] [G loss: 0.442927]\n",
      "epoch:18 step:17500 [D loss: 0.198789, acc.: 68.75%] [G loss: 0.469464]\n",
      "epoch:18 step:17501 [D loss: 0.210036, acc.: 66.41%] [G loss: 0.447530]\n",
      "epoch:18 step:17502 [D loss: 0.217084, acc.: 64.84%] [G loss: 0.457594]\n",
      "epoch:18 step:17503 [D loss: 0.234161, acc.: 59.38%] [G loss: 0.402414]\n",
      "epoch:18 step:17504 [D loss: 0.240119, acc.: 58.59%] [G loss: 0.414250]\n",
      "epoch:18 step:17505 [D loss: 0.229396, acc.: 58.59%] [G loss: 0.461123]\n",
      "epoch:18 step:17506 [D loss: 0.220351, acc.: 64.06%] [G loss: 0.434226]\n",
      "epoch:18 step:17507 [D loss: 0.211307, acc.: 70.31%] [G loss: 0.483547]\n",
      "epoch:18 step:17508 [D loss: 0.182208, acc.: 78.91%] [G loss: 0.502506]\n",
      "epoch:18 step:17509 [D loss: 0.223340, acc.: 63.28%] [G loss: 0.443123]\n",
      "epoch:18 step:17510 [D loss: 0.240915, acc.: 54.69%] [G loss: 0.451343]\n",
      "epoch:18 step:17511 [D loss: 0.210829, acc.: 65.62%] [G loss: 0.447262]\n",
      "epoch:18 step:17512 [D loss: 0.217833, acc.: 67.19%] [G loss: 0.461506]\n",
      "epoch:18 step:17513 [D loss: 0.204935, acc.: 67.97%] [G loss: 0.468013]\n",
      "epoch:18 step:17514 [D loss: 0.171223, acc.: 78.91%] [G loss: 0.500391]\n",
      "epoch:18 step:17515 [D loss: 0.229399, acc.: 63.28%] [G loss: 0.511342]\n",
      "epoch:18 step:17516 [D loss: 0.218815, acc.: 67.19%] [G loss: 0.483514]\n",
      "epoch:18 step:17517 [D loss: 0.236070, acc.: 59.38%] [G loss: 0.448035]\n",
      "epoch:18 step:17518 [D loss: 0.218015, acc.: 61.72%] [G loss: 0.429517]\n",
      "epoch:18 step:17519 [D loss: 0.216259, acc.: 67.19%] [G loss: 0.437431]\n",
      "epoch:18 step:17520 [D loss: 0.204636, acc.: 71.09%] [G loss: 0.447355]\n",
      "epoch:18 step:17521 [D loss: 0.246190, acc.: 63.28%] [G loss: 0.411279]\n",
      "epoch:18 step:17522 [D loss: 0.253556, acc.: 57.03%] [G loss: 0.396191]\n",
      "epoch:18 step:17523 [D loss: 0.233878, acc.: 64.06%] [G loss: 0.419019]\n",
      "epoch:18 step:17524 [D loss: 0.252182, acc.: 57.81%] [G loss: 0.439628]\n",
      "epoch:18 step:17525 [D loss: 0.216692, acc.: 61.72%] [G loss: 0.440255]\n",
      "epoch:18 step:17526 [D loss: 0.181916, acc.: 75.78%] [G loss: 0.463068]\n",
      "epoch:18 step:17527 [D loss: 0.210995, acc.: 67.97%] [G loss: 0.449932]\n",
      "epoch:18 step:17528 [D loss: 0.234112, acc.: 60.16%] [G loss: 0.453005]\n",
      "epoch:18 step:17529 [D loss: 0.217231, acc.: 63.28%] [G loss: 0.472732]\n",
      "epoch:18 step:17530 [D loss: 0.230319, acc.: 60.16%] [G loss: 0.452550]\n",
      "epoch:18 step:17531 [D loss: 0.238033, acc.: 61.72%] [G loss: 0.427277]\n",
      "epoch:18 step:17532 [D loss: 0.210470, acc.: 66.41%] [G loss: 0.468141]\n",
      "epoch:18 step:17533 [D loss: 0.219312, acc.: 62.50%] [G loss: 0.409750]\n",
      "epoch:18 step:17534 [D loss: 0.247120, acc.: 60.16%] [G loss: 0.372717]\n",
      "epoch:18 step:17535 [D loss: 0.212252, acc.: 67.97%] [G loss: 0.401865]\n",
      "epoch:18 step:17536 [D loss: 0.252887, acc.: 53.91%] [G loss: 0.325781]\n",
      "epoch:18 step:17537 [D loss: 0.221447, acc.: 64.84%] [G loss: 0.432303]\n",
      "epoch:18 step:17538 [D loss: 0.254056, acc.: 57.03%] [G loss: 0.427288]\n",
      "epoch:18 step:17539 [D loss: 0.222420, acc.: 64.06%] [G loss: 0.418435]\n",
      "epoch:18 step:17540 [D loss: 0.197528, acc.: 75.00%] [G loss: 0.448701]\n",
      "epoch:18 step:17541 [D loss: 0.261605, acc.: 52.34%] [G loss: 0.448913]\n",
      "epoch:18 step:17542 [D loss: 0.209069, acc.: 71.09%] [G loss: 0.411003]\n",
      "epoch:18 step:17543 [D loss: 0.202844, acc.: 71.09%] [G loss: 0.457031]\n",
      "epoch:18 step:17544 [D loss: 0.232854, acc.: 65.62%] [G loss: 0.463563]\n",
      "epoch:18 step:17545 [D loss: 0.226473, acc.: 64.06%] [G loss: 0.444758]\n",
      "epoch:18 step:17546 [D loss: 0.241072, acc.: 62.50%] [G loss: 0.396503]\n",
      "epoch:18 step:17547 [D loss: 0.201748, acc.: 71.09%] [G loss: 0.457277]\n",
      "epoch:18 step:17548 [D loss: 0.218649, acc.: 64.06%] [G loss: 0.445154]\n",
      "epoch:18 step:17549 [D loss: 0.240784, acc.: 56.25%] [G loss: 0.399818]\n",
      "epoch:18 step:17550 [D loss: 0.242396, acc.: 60.16%] [G loss: 0.420663]\n",
      "epoch:18 step:17551 [D loss: 0.218138, acc.: 62.50%] [G loss: 0.416085]\n",
      "epoch:18 step:17552 [D loss: 0.218792, acc.: 61.72%] [G loss: 0.443190]\n",
      "epoch:18 step:17553 [D loss: 0.242338, acc.: 58.59%] [G loss: 0.417196]\n",
      "epoch:18 step:17554 [D loss: 0.200064, acc.: 75.00%] [G loss: 0.455120]\n",
      "epoch:18 step:17555 [D loss: 0.209239, acc.: 64.84%] [G loss: 0.439133]\n",
      "epoch:18 step:17556 [D loss: 0.200199, acc.: 68.75%] [G loss: 0.449483]\n",
      "epoch:18 step:17557 [D loss: 0.217489, acc.: 70.31%] [G loss: 0.442819]\n",
      "epoch:18 step:17558 [D loss: 0.215014, acc.: 64.06%] [G loss: 0.466780]\n",
      "epoch:18 step:17559 [D loss: 0.201712, acc.: 71.88%] [G loss: 0.497709]\n",
      "epoch:18 step:17560 [D loss: 0.197737, acc.: 68.75%] [G loss: 0.489124]\n",
      "epoch:18 step:17561 [D loss: 0.219132, acc.: 67.19%] [G loss: 0.474530]\n",
      "epoch:18 step:17562 [D loss: 0.262451, acc.: 49.22%] [G loss: 0.414612]\n",
      "epoch:18 step:17563 [D loss: 0.217761, acc.: 60.94%] [G loss: 0.423500]\n",
      "epoch:18 step:17564 [D loss: 0.249176, acc.: 57.81%] [G loss: 0.425272]\n",
      "epoch:18 step:17565 [D loss: 0.201683, acc.: 67.19%] [G loss: 0.436413]\n",
      "epoch:18 step:17566 [D loss: 0.227103, acc.: 63.28%] [G loss: 0.436570]\n",
      "epoch:18 step:17567 [D loss: 0.208796, acc.: 67.97%] [G loss: 0.467820]\n",
      "epoch:18 step:17568 [D loss: 0.252234, acc.: 57.81%] [G loss: 0.439398]\n",
      "epoch:18 step:17569 [D loss: 0.247450, acc.: 55.47%] [G loss: 0.413324]\n",
      "epoch:18 step:17570 [D loss: 0.247166, acc.: 55.47%] [G loss: 0.408625]\n",
      "epoch:18 step:17571 [D loss: 0.225029, acc.: 62.50%] [G loss: 0.439918]\n",
      "epoch:18 step:17572 [D loss: 0.214196, acc.: 67.97%] [G loss: 0.399581]\n",
      "epoch:18 step:17573 [D loss: 0.181490, acc.: 77.34%] [G loss: 0.458648]\n",
      "epoch:18 step:17574 [D loss: 0.201623, acc.: 71.88%] [G loss: 0.451742]\n",
      "epoch:18 step:17575 [D loss: 0.218551, acc.: 65.62%] [G loss: 0.406689]\n",
      "epoch:18 step:17576 [D loss: 0.235150, acc.: 61.72%] [G loss: 0.471709]\n",
      "epoch:18 step:17577 [D loss: 0.232363, acc.: 62.50%] [G loss: 0.449295]\n",
      "epoch:18 step:17578 [D loss: 0.222457, acc.: 65.62%] [G loss: 0.427603]\n",
      "epoch:18 step:17579 [D loss: 0.222250, acc.: 62.50%] [G loss: 0.443595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17580 [D loss: 0.230020, acc.: 56.25%] [G loss: 0.461124]\n",
      "epoch:18 step:17581 [D loss: 0.212222, acc.: 71.09%] [G loss: 0.433186]\n",
      "epoch:18 step:17582 [D loss: 0.240795, acc.: 57.03%] [G loss: 0.426459]\n",
      "epoch:18 step:17583 [D loss: 0.220665, acc.: 64.84%] [G loss: 0.425540]\n",
      "epoch:18 step:17584 [D loss: 0.200577, acc.: 70.31%] [G loss: 0.466523]\n",
      "epoch:18 step:17585 [D loss: 0.201281, acc.: 69.53%] [G loss: 0.493475]\n",
      "epoch:18 step:17586 [D loss: 0.250949, acc.: 59.38%] [G loss: 0.453059]\n",
      "epoch:18 step:17587 [D loss: 0.205602, acc.: 65.62%] [G loss: 0.438291]\n",
      "epoch:18 step:17588 [D loss: 0.228661, acc.: 65.62%] [G loss: 0.409354]\n",
      "epoch:18 step:17589 [D loss: 0.216872, acc.: 67.19%] [G loss: 0.476252]\n",
      "epoch:18 step:17590 [D loss: 0.203647, acc.: 64.84%] [G loss: 0.433208]\n",
      "epoch:18 step:17591 [D loss: 0.207660, acc.: 67.19%] [G loss: 0.443333]\n",
      "epoch:18 step:17592 [D loss: 0.227070, acc.: 60.94%] [G loss: 0.426839]\n",
      "epoch:18 step:17593 [D loss: 0.237247, acc.: 59.38%] [G loss: 0.425972]\n",
      "epoch:18 step:17594 [D loss: 0.247418, acc.: 57.81%] [G loss: 0.412799]\n",
      "epoch:18 step:17595 [D loss: 0.229713, acc.: 63.28%] [G loss: 0.387327]\n",
      "epoch:18 step:17596 [D loss: 0.210518, acc.: 64.06%] [G loss: 0.457653]\n",
      "epoch:18 step:17597 [D loss: 0.209189, acc.: 64.06%] [G loss: 0.464861]\n",
      "epoch:18 step:17598 [D loss: 0.229772, acc.: 58.59%] [G loss: 0.462930]\n",
      "epoch:18 step:17599 [D loss: 0.201368, acc.: 70.31%] [G loss: 0.483174]\n",
      "epoch:18 step:17600 [D loss: 0.239668, acc.: 58.59%] [G loss: 0.423244]\n",
      "epoch:18 step:17601 [D loss: 0.238515, acc.: 57.81%] [G loss: 0.430308]\n",
      "epoch:18 step:17602 [D loss: 0.195284, acc.: 67.19%] [G loss: 0.417161]\n",
      "epoch:18 step:17603 [D loss: 0.212454, acc.: 68.75%] [G loss: 0.453128]\n",
      "epoch:18 step:17604 [D loss: 0.248844, acc.: 51.56%] [G loss: 0.404089]\n",
      "epoch:18 step:17605 [D loss: 0.252463, acc.: 50.78%] [G loss: 0.388164]\n",
      "epoch:18 step:17606 [D loss: 0.238667, acc.: 55.47%] [G loss: 0.440297]\n",
      "epoch:18 step:17607 [D loss: 0.246572, acc.: 54.69%] [G loss: 0.421309]\n",
      "epoch:18 step:17608 [D loss: 0.238146, acc.: 60.16%] [G loss: 0.424000]\n",
      "epoch:18 step:17609 [D loss: 0.202693, acc.: 67.19%] [G loss: 0.434953]\n",
      "epoch:18 step:17610 [D loss: 0.226948, acc.: 60.16%] [G loss: 0.441218]\n",
      "epoch:18 step:17611 [D loss: 0.256445, acc.: 52.34%] [G loss: 0.430908]\n",
      "epoch:18 step:17612 [D loss: 0.196171, acc.: 70.31%] [G loss: 0.463383]\n",
      "epoch:18 step:17613 [D loss: 0.194236, acc.: 73.44%] [G loss: 0.420789]\n",
      "epoch:18 step:17614 [D loss: 0.235244, acc.: 62.50%] [G loss: 0.410245]\n",
      "epoch:18 step:17615 [D loss: 0.237135, acc.: 60.16%] [G loss: 0.373876]\n",
      "epoch:18 step:17616 [D loss: 0.220201, acc.: 63.28%] [G loss: 0.416372]\n",
      "epoch:18 step:17617 [D loss: 0.226928, acc.: 61.72%] [G loss: 0.437957]\n",
      "epoch:18 step:17618 [D loss: 0.257066, acc.: 49.22%] [G loss: 0.449837]\n",
      "epoch:18 step:17619 [D loss: 0.238283, acc.: 56.25%] [G loss: 0.400056]\n",
      "epoch:18 step:17620 [D loss: 0.217754, acc.: 64.06%] [G loss: 0.420147]\n",
      "epoch:18 step:17621 [D loss: 0.222999, acc.: 63.28%] [G loss: 0.423838]\n",
      "epoch:18 step:17622 [D loss: 0.214464, acc.: 66.41%] [G loss: 0.449628]\n",
      "epoch:18 step:17623 [D loss: 0.246719, acc.: 57.81%] [G loss: 0.430563]\n",
      "epoch:18 step:17624 [D loss: 0.231851, acc.: 60.16%] [G loss: 0.341834]\n",
      "epoch:18 step:17625 [D loss: 0.242682, acc.: 60.16%] [G loss: 0.392936]\n",
      "epoch:18 step:17626 [D loss: 0.242612, acc.: 58.59%] [G loss: 0.366733]\n",
      "epoch:18 step:17627 [D loss: 0.248921, acc.: 60.94%] [G loss: 0.454523]\n",
      "epoch:18 step:17628 [D loss: 0.247292, acc.: 58.59%] [G loss: 0.463713]\n",
      "epoch:18 step:17629 [D loss: 0.222531, acc.: 63.28%] [G loss: 0.404856]\n",
      "epoch:18 step:17630 [D loss: 0.234980, acc.: 60.94%] [G loss: 0.447369]\n",
      "epoch:18 step:17631 [D loss: 0.260283, acc.: 48.44%] [G loss: 0.418763]\n",
      "epoch:18 step:17632 [D loss: 0.214059, acc.: 67.19%] [G loss: 0.439450]\n",
      "epoch:18 step:17633 [D loss: 0.215882, acc.: 69.53%] [G loss: 0.442083]\n",
      "epoch:18 step:17634 [D loss: 0.247375, acc.: 60.16%] [G loss: 0.424804]\n",
      "epoch:18 step:17635 [D loss: 0.196996, acc.: 71.09%] [G loss: 0.467537]\n",
      "epoch:18 step:17636 [D loss: 0.220595, acc.: 62.50%] [G loss: 0.461723]\n",
      "epoch:18 step:17637 [D loss: 0.237986, acc.: 60.16%] [G loss: 0.405303]\n",
      "epoch:18 step:17638 [D loss: 0.215954, acc.: 68.75%] [G loss: 0.426943]\n",
      "epoch:18 step:17639 [D loss: 0.228976, acc.: 64.06%] [G loss: 0.420871]\n",
      "epoch:18 step:17640 [D loss: 0.236925, acc.: 64.84%] [G loss: 0.409715]\n",
      "epoch:18 step:17641 [D loss: 0.203964, acc.: 72.66%] [G loss: 0.460432]\n",
      "epoch:18 step:17642 [D loss: 0.240712, acc.: 60.16%] [G loss: 0.484991]\n",
      "epoch:18 step:17643 [D loss: 0.216886, acc.: 66.41%] [G loss: 0.452523]\n",
      "epoch:18 step:17644 [D loss: 0.248290, acc.: 58.59%] [G loss: 0.426596]\n",
      "epoch:18 step:17645 [D loss: 0.240526, acc.: 57.03%] [G loss: 0.415161]\n",
      "epoch:18 step:17646 [D loss: 0.208558, acc.: 68.75%] [G loss: 0.426121]\n",
      "epoch:18 step:17647 [D loss: 0.209808, acc.: 62.50%] [G loss: 0.471393]\n",
      "epoch:18 step:17648 [D loss: 0.207650, acc.: 64.84%] [G loss: 0.504379]\n",
      "epoch:18 step:17649 [D loss: 0.256158, acc.: 50.00%] [G loss: 0.510692]\n",
      "epoch:18 step:17650 [D loss: 0.240600, acc.: 60.16%] [G loss: 0.426066]\n",
      "epoch:18 step:17651 [D loss: 0.230161, acc.: 60.16%] [G loss: 0.444270]\n",
      "epoch:18 step:17652 [D loss: 0.218208, acc.: 62.50%] [G loss: 0.422277]\n",
      "epoch:18 step:17653 [D loss: 0.252919, acc.: 50.78%] [G loss: 0.423451]\n",
      "epoch:18 step:17654 [D loss: 0.258531, acc.: 50.78%] [G loss: 0.415112]\n",
      "epoch:18 step:17655 [D loss: 0.235516, acc.: 60.16%] [G loss: 0.466876]\n",
      "epoch:18 step:17656 [D loss: 0.220184, acc.: 65.62%] [G loss: 0.444221]\n",
      "epoch:18 step:17657 [D loss: 0.255806, acc.: 56.25%] [G loss: 0.420302]\n",
      "epoch:18 step:17658 [D loss: 0.196306, acc.: 70.31%] [G loss: 0.448256]\n",
      "epoch:18 step:17659 [D loss: 0.220826, acc.: 62.50%] [G loss: 0.454822]\n",
      "epoch:18 step:17660 [D loss: 0.248728, acc.: 55.47%] [G loss: 0.474541]\n",
      "epoch:18 step:17661 [D loss: 0.235331, acc.: 61.72%] [G loss: 0.446577]\n",
      "epoch:18 step:17662 [D loss: 0.228920, acc.: 60.94%] [G loss: 0.410687]\n",
      "epoch:18 step:17663 [D loss: 0.258521, acc.: 54.69%] [G loss: 0.373086]\n",
      "epoch:18 step:17664 [D loss: 0.226423, acc.: 62.50%] [G loss: 0.409355]\n",
      "epoch:18 step:17665 [D loss: 0.215431, acc.: 60.16%] [G loss: 0.441407]\n",
      "epoch:18 step:17666 [D loss: 0.256951, acc.: 56.25%] [G loss: 0.388929]\n",
      "epoch:18 step:17667 [D loss: 0.217730, acc.: 62.50%] [G loss: 0.431847]\n",
      "epoch:18 step:17668 [D loss: 0.204948, acc.: 69.53%] [G loss: 0.459059]\n",
      "epoch:18 step:17669 [D loss: 0.214834, acc.: 68.75%] [G loss: 0.431790]\n",
      "epoch:18 step:17670 [D loss: 0.240802, acc.: 59.38%] [G loss: 0.410962]\n",
      "epoch:18 step:17671 [D loss: 0.216657, acc.: 64.84%] [G loss: 0.415758]\n",
      "epoch:18 step:17672 [D loss: 0.221314, acc.: 63.28%] [G loss: 0.413281]\n",
      "epoch:18 step:17673 [D loss: 0.211563, acc.: 67.97%] [G loss: 0.472173]\n",
      "epoch:18 step:17674 [D loss: 0.217469, acc.: 65.62%] [G loss: 0.474305]\n",
      "epoch:18 step:17675 [D loss: 0.228051, acc.: 61.72%] [G loss: 0.399403]\n",
      "epoch:18 step:17676 [D loss: 0.218342, acc.: 61.72%] [G loss: 0.429806]\n",
      "epoch:18 step:17677 [D loss: 0.217355, acc.: 60.16%] [G loss: 0.408102]\n",
      "epoch:18 step:17678 [D loss: 0.238244, acc.: 60.16%] [G loss: 0.430792]\n",
      "epoch:18 step:17679 [D loss: 0.214162, acc.: 67.97%] [G loss: 0.418808]\n",
      "epoch:18 step:17680 [D loss: 0.226529, acc.: 61.72%] [G loss: 0.463628]\n",
      "epoch:18 step:17681 [D loss: 0.198328, acc.: 66.41%] [G loss: 0.503903]\n",
      "epoch:18 step:17682 [D loss: 0.229401, acc.: 59.38%] [G loss: 0.484322]\n",
      "epoch:18 step:17683 [D loss: 0.264586, acc.: 52.34%] [G loss: 0.415690]\n",
      "epoch:18 step:17684 [D loss: 0.240534, acc.: 59.38%] [G loss: 0.432127]\n",
      "epoch:18 step:17685 [D loss: 0.215041, acc.: 67.19%] [G loss: 0.426069]\n",
      "epoch:18 step:17686 [D loss: 0.269821, acc.: 55.47%] [G loss: 0.377004]\n",
      "epoch:18 step:17687 [D loss: 0.222962, acc.: 60.94%] [G loss: 0.418120]\n",
      "epoch:18 step:17688 [D loss: 0.215768, acc.: 60.94%] [G loss: 0.422245]\n",
      "epoch:18 step:17689 [D loss: 0.218489, acc.: 64.84%] [G loss: 0.405112]\n",
      "epoch:18 step:17690 [D loss: 0.238449, acc.: 60.94%] [G loss: 0.444840]\n",
      "epoch:18 step:17691 [D loss: 0.194482, acc.: 68.75%] [G loss: 0.401662]\n",
      "epoch:18 step:17692 [D loss: 0.212389, acc.: 62.50%] [G loss: 0.490365]\n",
      "epoch:18 step:17693 [D loss: 0.230740, acc.: 59.38%] [G loss: 0.463880]\n",
      "epoch:18 step:17694 [D loss: 0.239355, acc.: 53.12%] [G loss: 0.394601]\n",
      "epoch:18 step:17695 [D loss: 0.243489, acc.: 56.25%] [G loss: 0.406959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17696 [D loss: 0.245830, acc.: 55.47%] [G loss: 0.428562]\n",
      "epoch:18 step:17697 [D loss: 0.221693, acc.: 60.94%] [G loss: 0.402966]\n",
      "epoch:18 step:17698 [D loss: 0.208389, acc.: 69.53%] [G loss: 0.427564]\n",
      "epoch:18 step:17699 [D loss: 0.192517, acc.: 71.88%] [G loss: 0.460302]\n",
      "epoch:18 step:17700 [D loss: 0.239616, acc.: 56.25%] [G loss: 0.398366]\n",
      "epoch:18 step:17701 [D loss: 0.233857, acc.: 60.16%] [G loss: 0.400876]\n",
      "epoch:18 step:17702 [D loss: 0.219007, acc.: 65.62%] [G loss: 0.433070]\n",
      "epoch:18 step:17703 [D loss: 0.210124, acc.: 68.75%] [G loss: 0.431574]\n",
      "epoch:18 step:17704 [D loss: 0.200785, acc.: 71.09%] [G loss: 0.429340]\n",
      "epoch:18 step:17705 [D loss: 0.208134, acc.: 66.41%] [G loss: 0.448134]\n",
      "epoch:18 step:17706 [D loss: 0.222389, acc.: 65.62%] [G loss: 0.436729]\n",
      "epoch:18 step:17707 [D loss: 0.225060, acc.: 61.72%] [G loss: 0.418220]\n",
      "epoch:18 step:17708 [D loss: 0.193876, acc.: 71.88%] [G loss: 0.448368]\n",
      "epoch:18 step:17709 [D loss: 0.233096, acc.: 60.94%] [G loss: 0.441241]\n",
      "epoch:18 step:17710 [D loss: 0.244175, acc.: 58.59%] [G loss: 0.415420]\n",
      "epoch:18 step:17711 [D loss: 0.215683, acc.: 68.75%] [G loss: 0.461525]\n",
      "epoch:18 step:17712 [D loss: 0.231558, acc.: 53.12%] [G loss: 0.433809]\n",
      "epoch:18 step:17713 [D loss: 0.210992, acc.: 64.06%] [G loss: 0.405336]\n",
      "epoch:18 step:17714 [D loss: 0.249275, acc.: 53.91%] [G loss: 0.420325]\n",
      "epoch:18 step:17715 [D loss: 0.224421, acc.: 65.62%] [G loss: 0.384860]\n",
      "epoch:18 step:17716 [D loss: 0.249973, acc.: 55.47%] [G loss: 0.447695]\n",
      "epoch:18 step:17717 [D loss: 0.232193, acc.: 58.59%] [G loss: 0.438140]\n",
      "epoch:18 step:17718 [D loss: 0.228817, acc.: 63.28%] [G loss: 0.448806]\n",
      "epoch:18 step:17719 [D loss: 0.208144, acc.: 68.75%] [G loss: 0.455938]\n",
      "epoch:18 step:17720 [D loss: 0.222325, acc.: 63.28%] [G loss: 0.400023]\n",
      "epoch:18 step:17721 [D loss: 0.245410, acc.: 60.16%] [G loss: 0.448606]\n",
      "epoch:18 step:17722 [D loss: 0.238240, acc.: 57.81%] [G loss: 0.440482]\n",
      "epoch:18 step:17723 [D loss: 0.242057, acc.: 54.69%] [G loss: 0.404151]\n",
      "epoch:18 step:17724 [D loss: 0.250939, acc.: 55.47%] [G loss: 0.439679]\n",
      "epoch:18 step:17725 [D loss: 0.237688, acc.: 63.28%] [G loss: 0.431547]\n",
      "epoch:18 step:17726 [D loss: 0.205585, acc.: 69.53%] [G loss: 0.480857]\n",
      "epoch:18 step:17727 [D loss: 0.249755, acc.: 55.47%] [G loss: 0.441846]\n",
      "epoch:18 step:17728 [D loss: 0.230746, acc.: 61.72%] [G loss: 0.430117]\n",
      "epoch:18 step:17729 [D loss: 0.241359, acc.: 57.81%] [G loss: 0.430434]\n",
      "epoch:18 step:17730 [D loss: 0.228484, acc.: 60.16%] [G loss: 0.419468]\n",
      "epoch:18 step:17731 [D loss: 0.261569, acc.: 53.91%] [G loss: 0.402961]\n",
      "epoch:18 step:17732 [D loss: 0.219192, acc.: 62.50%] [G loss: 0.406446]\n",
      "epoch:18 step:17733 [D loss: 0.219012, acc.: 65.62%] [G loss: 0.385633]\n",
      "epoch:18 step:17734 [D loss: 0.229192, acc.: 59.38%] [G loss: 0.444908]\n",
      "epoch:18 step:17735 [D loss: 0.253700, acc.: 55.47%] [G loss: 0.409536]\n",
      "epoch:18 step:17736 [D loss: 0.230637, acc.: 57.81%] [G loss: 0.438972]\n",
      "epoch:18 step:17737 [D loss: 0.216165, acc.: 63.28%] [G loss: 0.434328]\n",
      "epoch:18 step:17738 [D loss: 0.228280, acc.: 62.50%] [G loss: 0.445320]\n",
      "epoch:18 step:17739 [D loss: 0.223139, acc.: 64.84%] [G loss: 0.438664]\n",
      "epoch:18 step:17740 [D loss: 0.222341, acc.: 60.94%] [G loss: 0.445513]\n",
      "epoch:18 step:17741 [D loss: 0.187279, acc.: 75.78%] [G loss: 0.451090]\n",
      "epoch:18 step:17742 [D loss: 0.234708, acc.: 62.50%] [G loss: 0.459032]\n",
      "epoch:18 step:17743 [D loss: 0.240626, acc.: 55.47%] [G loss: 0.396165]\n",
      "epoch:18 step:17744 [D loss: 0.225430, acc.: 62.50%] [G loss: 0.466591]\n",
      "epoch:18 step:17745 [D loss: 0.230660, acc.: 59.38%] [G loss: 0.458840]\n",
      "epoch:18 step:17746 [D loss: 0.255314, acc.: 54.69%] [G loss: 0.444790]\n",
      "epoch:18 step:17747 [D loss: 0.206867, acc.: 64.06%] [G loss: 0.454620]\n",
      "epoch:18 step:17748 [D loss: 0.216382, acc.: 60.94%] [G loss: 0.400297]\n",
      "epoch:18 step:17749 [D loss: 0.245316, acc.: 53.91%] [G loss: 0.394761]\n",
      "epoch:18 step:17750 [D loss: 0.197444, acc.: 69.53%] [G loss: 0.461551]\n",
      "epoch:18 step:17751 [D loss: 0.242034, acc.: 60.16%] [G loss: 0.458741]\n",
      "epoch:18 step:17752 [D loss: 0.182029, acc.: 75.78%] [G loss: 0.441582]\n",
      "epoch:18 step:17753 [D loss: 0.239904, acc.: 66.41%] [G loss: 0.440983]\n",
      "epoch:18 step:17754 [D loss: 0.216471, acc.: 64.06%] [G loss: 0.469251]\n",
      "epoch:18 step:17755 [D loss: 0.225045, acc.: 61.72%] [G loss: 0.460120]\n",
      "epoch:18 step:17756 [D loss: 0.192184, acc.: 71.88%] [G loss: 0.477644]\n",
      "epoch:18 step:17757 [D loss: 0.273286, acc.: 53.12%] [G loss: 0.432666]\n",
      "epoch:18 step:17758 [D loss: 0.265664, acc.: 50.78%] [G loss: 0.424593]\n",
      "epoch:18 step:17759 [D loss: 0.235887, acc.: 60.94%] [G loss: 0.420123]\n",
      "epoch:18 step:17760 [D loss: 0.202128, acc.: 67.19%] [G loss: 0.467316]\n",
      "epoch:18 step:17761 [D loss: 0.207335, acc.: 65.62%] [G loss: 0.467420]\n",
      "epoch:18 step:17762 [D loss: 0.226008, acc.: 63.28%] [G loss: 0.435820]\n",
      "epoch:18 step:17763 [D loss: 0.231026, acc.: 60.16%] [G loss: 0.416688]\n",
      "epoch:18 step:17764 [D loss: 0.210149, acc.: 66.41%] [G loss: 0.455553]\n",
      "epoch:18 step:17765 [D loss: 0.176967, acc.: 73.44%] [G loss: 0.487840]\n",
      "epoch:18 step:17766 [D loss: 0.208727, acc.: 67.97%] [G loss: 0.477412]\n",
      "epoch:18 step:17767 [D loss: 0.226485, acc.: 60.94%] [G loss: 0.459571]\n",
      "epoch:18 step:17768 [D loss: 0.224603, acc.: 60.94%] [G loss: 0.444779]\n",
      "epoch:18 step:17769 [D loss: 0.229770, acc.: 63.28%] [G loss: 0.400534]\n",
      "epoch:18 step:17770 [D loss: 0.213604, acc.: 65.62%] [G loss: 0.423166]\n",
      "epoch:18 step:17771 [D loss: 0.216060, acc.: 64.06%] [G loss: 0.474587]\n",
      "epoch:18 step:17772 [D loss: 0.233553, acc.: 63.28%] [G loss: 0.491458]\n",
      "epoch:18 step:17773 [D loss: 0.256003, acc.: 54.69%] [G loss: 0.497254]\n",
      "epoch:18 step:17774 [D loss: 0.202773, acc.: 67.97%] [G loss: 0.456133]\n",
      "epoch:18 step:17775 [D loss: 0.195211, acc.: 68.75%] [G loss: 0.430696]\n",
      "epoch:18 step:17776 [D loss: 0.223534, acc.: 62.50%] [G loss: 0.418079]\n",
      "epoch:18 step:17777 [D loss: 0.214094, acc.: 65.62%] [G loss: 0.446552]\n",
      "epoch:18 step:17778 [D loss: 0.213099, acc.: 66.41%] [G loss: 0.463163]\n",
      "epoch:18 step:17779 [D loss: 0.240064, acc.: 60.94%] [G loss: 0.450485]\n",
      "epoch:18 step:17780 [D loss: 0.221405, acc.: 61.72%] [G loss: 0.487822]\n",
      "epoch:18 step:17781 [D loss: 0.279473, acc.: 50.78%] [G loss: 0.430651]\n",
      "epoch:18 step:17782 [D loss: 0.215733, acc.: 61.72%] [G loss: 0.472210]\n",
      "epoch:18 step:17783 [D loss: 0.211843, acc.: 64.84%] [G loss: 0.508335]\n",
      "epoch:18 step:17784 [D loss: 0.213164, acc.: 64.84%] [G loss: 0.474814]\n",
      "epoch:18 step:17785 [D loss: 0.208270, acc.: 64.06%] [G loss: 0.448251]\n",
      "epoch:18 step:17786 [D loss: 0.261300, acc.: 50.78%] [G loss: 0.414356]\n",
      "epoch:18 step:17787 [D loss: 0.206565, acc.: 69.53%] [G loss: 0.424686]\n",
      "epoch:18 step:17788 [D loss: 0.246017, acc.: 57.03%] [G loss: 0.410708]\n",
      "epoch:18 step:17789 [D loss: 0.190281, acc.: 71.88%] [G loss: 0.407105]\n",
      "epoch:18 step:17790 [D loss: 0.189875, acc.: 68.75%] [G loss: 0.457579]\n",
      "epoch:18 step:17791 [D loss: 0.166567, acc.: 78.91%] [G loss: 0.542778]\n",
      "epoch:18 step:17792 [D loss: 0.182251, acc.: 76.56%] [G loss: 0.557647]\n",
      "epoch:18 step:17793 [D loss: 0.199018, acc.: 69.53%] [G loss: 0.588064]\n",
      "epoch:18 step:17794 [D loss: 0.337674, acc.: 50.78%] [G loss: 0.610427]\n",
      "epoch:18 step:17795 [D loss: 0.231043, acc.: 62.50%] [G loss: 0.728049]\n",
      "epoch:18 step:17796 [D loss: 0.249928, acc.: 60.16%] [G loss: 0.451600]\n",
      "epoch:18 step:17797 [D loss: 0.236461, acc.: 64.84%] [G loss: 0.416655]\n",
      "epoch:18 step:17798 [D loss: 0.261183, acc.: 51.56%] [G loss: 0.413947]\n",
      "epoch:18 step:17799 [D loss: 0.221172, acc.: 71.09%] [G loss: 0.428352]\n",
      "epoch:18 step:17800 [D loss: 0.230115, acc.: 63.28%] [G loss: 0.442432]\n",
      "epoch:18 step:17801 [D loss: 0.198967, acc.: 71.09%] [G loss: 0.435919]\n",
      "epoch:18 step:17802 [D loss: 0.192344, acc.: 68.75%] [G loss: 0.525626]\n",
      "epoch:18 step:17803 [D loss: 0.164223, acc.: 73.44%] [G loss: 0.543303]\n",
      "epoch:19 step:17804 [D loss: 0.229781, acc.: 60.16%] [G loss: 0.467305]\n",
      "epoch:19 step:17805 [D loss: 0.226788, acc.: 67.97%] [G loss: 0.503809]\n",
      "epoch:19 step:17806 [D loss: 0.229384, acc.: 60.94%] [G loss: 0.451184]\n",
      "epoch:19 step:17807 [D loss: 0.235592, acc.: 61.72%] [G loss: 0.516220]\n",
      "epoch:19 step:17808 [D loss: 0.241283, acc.: 56.25%] [G loss: 0.504532]\n",
      "epoch:19 step:17809 [D loss: 0.210140, acc.: 67.19%] [G loss: 0.492669]\n",
      "epoch:19 step:17810 [D loss: 0.237027, acc.: 62.50%] [G loss: 0.439164]\n",
      "epoch:19 step:17811 [D loss: 0.234231, acc.: 57.03%] [G loss: 0.445433]\n",
      "epoch:19 step:17812 [D loss: 0.195346, acc.: 71.09%] [G loss: 0.475007]\n",
      "epoch:19 step:17813 [D loss: 0.206870, acc.: 68.75%] [G loss: 0.475486]\n",
      "epoch:19 step:17814 [D loss: 0.192186, acc.: 68.75%] [G loss: 0.510343]\n",
      "epoch:19 step:17815 [D loss: 0.243082, acc.: 60.94%] [G loss: 0.458733]\n",
      "epoch:19 step:17816 [D loss: 0.201148, acc.: 67.19%] [G loss: 0.509291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17817 [D loss: 0.207552, acc.: 68.75%] [G loss: 0.478394]\n",
      "epoch:19 step:17818 [D loss: 0.191284, acc.: 72.66%] [G loss: 0.502367]\n",
      "epoch:19 step:17819 [D loss: 0.216156, acc.: 64.06%] [G loss: 0.466615]\n",
      "epoch:19 step:17820 [D loss: 0.235817, acc.: 67.97%] [G loss: 0.438504]\n",
      "epoch:19 step:17821 [D loss: 0.232857, acc.: 60.16%] [G loss: 0.419657]\n",
      "epoch:19 step:17822 [D loss: 0.237154, acc.: 58.59%] [G loss: 0.453797]\n",
      "epoch:19 step:17823 [D loss: 0.258361, acc.: 51.56%] [G loss: 0.506338]\n",
      "epoch:19 step:17824 [D loss: 0.217417, acc.: 61.72%] [G loss: 0.475678]\n",
      "epoch:19 step:17825 [D loss: 0.200751, acc.: 71.88%] [G loss: 0.527553]\n",
      "epoch:19 step:17826 [D loss: 0.251181, acc.: 55.47%] [G loss: 0.397543]\n",
      "epoch:19 step:17827 [D loss: 0.216579, acc.: 65.62%] [G loss: 0.420251]\n",
      "epoch:19 step:17828 [D loss: 0.195650, acc.: 71.88%] [G loss: 0.457560]\n",
      "epoch:19 step:17829 [D loss: 0.234207, acc.: 60.94%] [G loss: 0.437035]\n",
      "epoch:19 step:17830 [D loss: 0.209077, acc.: 68.75%] [G loss: 0.438507]\n",
      "epoch:19 step:17831 [D loss: 0.246353, acc.: 55.47%] [G loss: 0.397101]\n",
      "epoch:19 step:17832 [D loss: 0.218895, acc.: 64.06%] [G loss: 0.442479]\n",
      "epoch:19 step:17833 [D loss: 0.215701, acc.: 66.41%] [G loss: 0.485351]\n",
      "epoch:19 step:17834 [D loss: 0.283496, acc.: 49.22%] [G loss: 0.445656]\n",
      "epoch:19 step:17835 [D loss: 0.227420, acc.: 64.06%] [G loss: 0.464818]\n",
      "epoch:19 step:17836 [D loss: 0.225513, acc.: 61.72%] [G loss: 0.437533]\n",
      "epoch:19 step:17837 [D loss: 0.247963, acc.: 55.47%] [G loss: 0.414313]\n",
      "epoch:19 step:17838 [D loss: 0.240185, acc.: 58.59%] [G loss: 0.372536]\n",
      "epoch:19 step:17839 [D loss: 0.196797, acc.: 67.97%] [G loss: 0.447844]\n",
      "epoch:19 step:17840 [D loss: 0.216294, acc.: 66.41%] [G loss: 0.447562]\n",
      "epoch:19 step:17841 [D loss: 0.263348, acc.: 53.91%] [G loss: 0.410730]\n",
      "epoch:19 step:17842 [D loss: 0.207806, acc.: 65.62%] [G loss: 0.438122]\n",
      "epoch:19 step:17843 [D loss: 0.201836, acc.: 68.75%] [G loss: 0.416958]\n",
      "epoch:19 step:17844 [D loss: 0.232245, acc.: 56.25%] [G loss: 0.433239]\n",
      "epoch:19 step:17845 [D loss: 0.202555, acc.: 69.53%] [G loss: 0.420518]\n",
      "epoch:19 step:17846 [D loss: 0.221097, acc.: 63.28%] [G loss: 0.433529]\n",
      "epoch:19 step:17847 [D loss: 0.227771, acc.: 66.41%] [G loss: 0.439471]\n",
      "epoch:19 step:17848 [D loss: 0.229387, acc.: 60.94%] [G loss: 0.448601]\n",
      "epoch:19 step:17849 [D loss: 0.221971, acc.: 64.84%] [G loss: 0.477554]\n",
      "epoch:19 step:17850 [D loss: 0.228649, acc.: 63.28%] [G loss: 0.423168]\n",
      "epoch:19 step:17851 [D loss: 0.212627, acc.: 67.19%] [G loss: 0.414864]\n",
      "epoch:19 step:17852 [D loss: 0.211823, acc.: 66.41%] [G loss: 0.467924]\n",
      "epoch:19 step:17853 [D loss: 0.205155, acc.: 67.97%] [G loss: 0.454535]\n",
      "epoch:19 step:17854 [D loss: 0.267667, acc.: 51.56%] [G loss: 0.414442]\n",
      "epoch:19 step:17855 [D loss: 0.238003, acc.: 57.81%] [G loss: 0.443477]\n",
      "epoch:19 step:17856 [D loss: 0.213854, acc.: 63.28%] [G loss: 0.480825]\n",
      "epoch:19 step:17857 [D loss: 0.190455, acc.: 69.53%] [G loss: 0.413734]\n",
      "epoch:19 step:17858 [D loss: 0.230445, acc.: 60.94%] [G loss: 0.429792]\n",
      "epoch:19 step:17859 [D loss: 0.206501, acc.: 69.53%] [G loss: 0.436260]\n",
      "epoch:19 step:17860 [D loss: 0.242507, acc.: 58.59%] [G loss: 0.447838]\n",
      "epoch:19 step:17861 [D loss: 0.224004, acc.: 61.72%] [G loss: 0.438816]\n",
      "epoch:19 step:17862 [D loss: 0.229703, acc.: 61.72%] [G loss: 0.420823]\n",
      "epoch:19 step:17863 [D loss: 0.249754, acc.: 56.25%] [G loss: 0.405063]\n",
      "epoch:19 step:17864 [D loss: 0.236441, acc.: 64.06%] [G loss: 0.445091]\n",
      "epoch:19 step:17865 [D loss: 0.221756, acc.: 59.38%] [G loss: 0.419023]\n",
      "epoch:19 step:17866 [D loss: 0.214924, acc.: 60.94%] [G loss: 0.425839]\n",
      "epoch:19 step:17867 [D loss: 0.223817, acc.: 62.50%] [G loss: 0.460266]\n",
      "epoch:19 step:17868 [D loss: 0.249827, acc.: 55.47%] [G loss: 0.392653]\n",
      "epoch:19 step:17869 [D loss: 0.218630, acc.: 64.84%] [G loss: 0.475046]\n",
      "epoch:19 step:17870 [D loss: 0.214911, acc.: 63.28%] [G loss: 0.442126]\n",
      "epoch:19 step:17871 [D loss: 0.218762, acc.: 66.41%] [G loss: 0.407508]\n",
      "epoch:19 step:17872 [D loss: 0.194777, acc.: 72.66%] [G loss: 0.437274]\n",
      "epoch:19 step:17873 [D loss: 0.206824, acc.: 66.41%] [G loss: 0.455770]\n",
      "epoch:19 step:17874 [D loss: 0.264086, acc.: 46.09%] [G loss: 0.411415]\n",
      "epoch:19 step:17875 [D loss: 0.229615, acc.: 64.06%] [G loss: 0.454143]\n",
      "epoch:19 step:17876 [D loss: 0.231638, acc.: 57.03%] [G loss: 0.374002]\n",
      "epoch:19 step:17877 [D loss: 0.182626, acc.: 78.12%] [G loss: 0.440847]\n",
      "epoch:19 step:17878 [D loss: 0.210375, acc.: 66.41%] [G loss: 0.432521]\n",
      "epoch:19 step:17879 [D loss: 0.217465, acc.: 64.84%] [G loss: 0.424005]\n",
      "epoch:19 step:17880 [D loss: 0.179446, acc.: 74.22%] [G loss: 0.518083]\n",
      "epoch:19 step:17881 [D loss: 0.290097, acc.: 49.22%] [G loss: 0.414393]\n",
      "epoch:19 step:17882 [D loss: 0.238462, acc.: 60.16%] [G loss: 0.422473]\n",
      "epoch:19 step:17883 [D loss: 0.256502, acc.: 50.78%] [G loss: 0.417175]\n",
      "epoch:19 step:17884 [D loss: 0.249459, acc.: 57.81%] [G loss: 0.432268]\n",
      "epoch:19 step:17885 [D loss: 0.207649, acc.: 63.28%] [G loss: 0.450553]\n",
      "epoch:19 step:17886 [D loss: 0.199594, acc.: 68.75%] [G loss: 0.438607]\n",
      "epoch:19 step:17887 [D loss: 0.227333, acc.: 63.28%] [G loss: 0.439737]\n",
      "epoch:19 step:17888 [D loss: 0.229099, acc.: 64.06%] [G loss: 0.442483]\n",
      "epoch:19 step:17889 [D loss: 0.237086, acc.: 64.84%] [G loss: 0.448222]\n",
      "epoch:19 step:17890 [D loss: 0.206760, acc.: 67.19%] [G loss: 0.468856]\n",
      "epoch:19 step:17891 [D loss: 0.207165, acc.: 65.62%] [G loss: 0.454485]\n",
      "epoch:19 step:17892 [D loss: 0.218671, acc.: 62.50%] [G loss: 0.437747]\n",
      "epoch:19 step:17893 [D loss: 0.210945, acc.: 64.84%] [G loss: 0.448965]\n",
      "epoch:19 step:17894 [D loss: 0.234513, acc.: 64.84%] [G loss: 0.465955]\n",
      "epoch:19 step:17895 [D loss: 0.227402, acc.: 59.38%] [G loss: 0.435860]\n",
      "epoch:19 step:17896 [D loss: 0.200188, acc.: 64.84%] [G loss: 0.422249]\n",
      "epoch:19 step:17897 [D loss: 0.234946, acc.: 55.47%] [G loss: 0.446712]\n",
      "epoch:19 step:17898 [D loss: 0.243052, acc.: 60.94%] [G loss: 0.460308]\n",
      "epoch:19 step:17899 [D loss: 0.224149, acc.: 64.06%] [G loss: 0.462808]\n",
      "epoch:19 step:17900 [D loss: 0.193782, acc.: 73.44%] [G loss: 0.457903]\n",
      "epoch:19 step:17901 [D loss: 0.224121, acc.: 64.06%] [G loss: 0.462665]\n",
      "epoch:19 step:17902 [D loss: 0.242663, acc.: 57.03%] [G loss: 0.439762]\n",
      "epoch:19 step:17903 [D loss: 0.208006, acc.: 67.97%] [G loss: 0.473132]\n",
      "epoch:19 step:17904 [D loss: 0.221942, acc.: 62.50%] [G loss: 0.452906]\n",
      "epoch:19 step:17905 [D loss: 0.217573, acc.: 61.72%] [G loss: 0.419394]\n",
      "epoch:19 step:17906 [D loss: 0.245268, acc.: 53.12%] [G loss: 0.394059]\n",
      "epoch:19 step:17907 [D loss: 0.217740, acc.: 60.94%] [G loss: 0.421135]\n",
      "epoch:19 step:17908 [D loss: 0.224027, acc.: 62.50%] [G loss: 0.416233]\n",
      "epoch:19 step:17909 [D loss: 0.211254, acc.: 67.19%] [G loss: 0.407663]\n",
      "epoch:19 step:17910 [D loss: 0.200028, acc.: 71.09%] [G loss: 0.482846]\n",
      "epoch:19 step:17911 [D loss: 0.251024, acc.: 53.12%] [G loss: 0.462627]\n",
      "epoch:19 step:17912 [D loss: 0.289770, acc.: 48.44%] [G loss: 0.401583]\n",
      "epoch:19 step:17913 [D loss: 0.223838, acc.: 63.28%] [G loss: 0.435071]\n",
      "epoch:19 step:17914 [D loss: 0.202477, acc.: 67.19%] [G loss: 0.459363]\n",
      "epoch:19 step:17915 [D loss: 0.214698, acc.: 68.75%] [G loss: 0.447084]\n",
      "epoch:19 step:17916 [D loss: 0.215749, acc.: 65.62%] [G loss: 0.436778]\n",
      "epoch:19 step:17917 [D loss: 0.203265, acc.: 71.09%] [G loss: 0.471026]\n",
      "epoch:19 step:17918 [D loss: 0.214087, acc.: 69.53%] [G loss: 0.504671]\n",
      "epoch:19 step:17919 [D loss: 0.236991, acc.: 58.59%] [G loss: 0.459820]\n",
      "epoch:19 step:17920 [D loss: 0.213651, acc.: 63.28%] [G loss: 0.455209]\n",
      "epoch:19 step:17921 [D loss: 0.201430, acc.: 71.09%] [G loss: 0.481892]\n",
      "epoch:19 step:17922 [D loss: 0.182237, acc.: 65.62%] [G loss: 0.474397]\n",
      "epoch:19 step:17923 [D loss: 0.240002, acc.: 60.16%] [G loss: 0.436339]\n",
      "epoch:19 step:17924 [D loss: 0.243182, acc.: 53.91%] [G loss: 0.451914]\n",
      "epoch:19 step:17925 [D loss: 0.168268, acc.: 77.34%] [G loss: 0.517463]\n",
      "epoch:19 step:17926 [D loss: 0.205578, acc.: 67.97%] [G loss: 0.456329]\n",
      "epoch:19 step:17927 [D loss: 0.264267, acc.: 55.47%] [G loss: 0.490017]\n",
      "epoch:19 step:17928 [D loss: 0.229721, acc.: 57.81%] [G loss: 0.427341]\n",
      "epoch:19 step:17929 [D loss: 0.208101, acc.: 65.62%] [G loss: 0.416024]\n",
      "epoch:19 step:17930 [D loss: 0.206057, acc.: 64.06%] [G loss: 0.445405]\n",
      "epoch:19 step:17931 [D loss: 0.231118, acc.: 61.72%] [G loss: 0.439293]\n",
      "epoch:19 step:17932 [D loss: 0.244325, acc.: 55.47%] [G loss: 0.423301]\n",
      "epoch:19 step:17933 [D loss: 0.224317, acc.: 62.50%] [G loss: 0.426110]\n",
      "epoch:19 step:17934 [D loss: 0.221695, acc.: 64.06%] [G loss: 0.432926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17935 [D loss: 0.219976, acc.: 64.84%] [G loss: 0.475440]\n",
      "epoch:19 step:17936 [D loss: 0.231103, acc.: 59.38%] [G loss: 0.470737]\n",
      "epoch:19 step:17937 [D loss: 0.228817, acc.: 61.72%] [G loss: 0.511007]\n",
      "epoch:19 step:17938 [D loss: 0.222820, acc.: 62.50%] [G loss: 0.474949]\n",
      "epoch:19 step:17939 [D loss: 0.202729, acc.: 67.97%] [G loss: 0.431399]\n",
      "epoch:19 step:17940 [D loss: 0.253613, acc.: 56.25%] [G loss: 0.396287]\n",
      "epoch:19 step:17941 [D loss: 0.270074, acc.: 54.69%] [G loss: 0.415862]\n",
      "epoch:19 step:17942 [D loss: 0.214916, acc.: 70.31%] [G loss: 0.443680]\n",
      "epoch:19 step:17943 [D loss: 0.215135, acc.: 65.62%] [G loss: 0.438552]\n",
      "epoch:19 step:17944 [D loss: 0.234132, acc.: 57.81%] [G loss: 0.412616]\n",
      "epoch:19 step:17945 [D loss: 0.234371, acc.: 60.16%] [G loss: 0.426545]\n",
      "epoch:19 step:17946 [D loss: 0.227031, acc.: 61.72%] [G loss: 0.438949]\n",
      "epoch:19 step:17947 [D loss: 0.217172, acc.: 64.84%] [G loss: 0.405612]\n",
      "epoch:19 step:17948 [D loss: 0.212238, acc.: 65.62%] [G loss: 0.432813]\n",
      "epoch:19 step:17949 [D loss: 0.213469, acc.: 66.41%] [G loss: 0.468980]\n",
      "epoch:19 step:17950 [D loss: 0.234268, acc.: 60.94%] [G loss: 0.446977]\n",
      "epoch:19 step:17951 [D loss: 0.243845, acc.: 57.03%] [G loss: 0.433604]\n",
      "epoch:19 step:17952 [D loss: 0.199634, acc.: 67.19%] [G loss: 0.428561]\n",
      "epoch:19 step:17953 [D loss: 0.250306, acc.: 53.91%] [G loss: 0.406723]\n",
      "epoch:19 step:17954 [D loss: 0.220959, acc.: 67.19%] [G loss: 0.416933]\n",
      "epoch:19 step:17955 [D loss: 0.218591, acc.: 64.84%] [G loss: 0.460085]\n",
      "epoch:19 step:17956 [D loss: 0.209941, acc.: 66.41%] [G loss: 0.426956]\n",
      "epoch:19 step:17957 [D loss: 0.228497, acc.: 61.72%] [G loss: 0.421816]\n",
      "epoch:19 step:17958 [D loss: 0.202864, acc.: 66.41%] [G loss: 0.433220]\n",
      "epoch:19 step:17959 [D loss: 0.223296, acc.: 61.72%] [G loss: 0.431129]\n",
      "epoch:19 step:17960 [D loss: 0.234320, acc.: 62.50%] [G loss: 0.468989]\n",
      "epoch:19 step:17961 [D loss: 0.228485, acc.: 63.28%] [G loss: 0.447551]\n",
      "epoch:19 step:17962 [D loss: 0.219067, acc.: 66.41%] [G loss: 0.431394]\n",
      "epoch:19 step:17963 [D loss: 0.271751, acc.: 54.69%] [G loss: 0.447721]\n",
      "epoch:19 step:17964 [D loss: 0.241731, acc.: 59.38%] [G loss: 0.453170]\n",
      "epoch:19 step:17965 [D loss: 0.241042, acc.: 59.38%] [G loss: 0.431079]\n",
      "epoch:19 step:17966 [D loss: 0.246215, acc.: 58.59%] [G loss: 0.411594]\n",
      "epoch:19 step:17967 [D loss: 0.195914, acc.: 67.97%] [G loss: 0.412302]\n",
      "epoch:19 step:17968 [D loss: 0.230677, acc.: 62.50%] [G loss: 0.428243]\n",
      "epoch:19 step:17969 [D loss: 0.230358, acc.: 60.94%] [G loss: 0.392282]\n",
      "epoch:19 step:17970 [D loss: 0.228343, acc.: 58.59%] [G loss: 0.395811]\n",
      "epoch:19 step:17971 [D loss: 0.222927, acc.: 64.84%] [G loss: 0.402758]\n",
      "epoch:19 step:17972 [D loss: 0.230983, acc.: 64.84%] [G loss: 0.441479]\n",
      "epoch:19 step:17973 [D loss: 0.227292, acc.: 65.62%] [G loss: 0.424080]\n",
      "epoch:19 step:17974 [D loss: 0.232939, acc.: 58.59%] [G loss: 0.397533]\n",
      "epoch:19 step:17975 [D loss: 0.217610, acc.: 67.19%] [G loss: 0.419420]\n",
      "epoch:19 step:17976 [D loss: 0.221858, acc.: 66.41%] [G loss: 0.453039]\n",
      "epoch:19 step:17977 [D loss: 0.238623, acc.: 61.72%] [G loss: 0.426404]\n",
      "epoch:19 step:17978 [D loss: 0.235571, acc.: 64.06%] [G loss: 0.422291]\n",
      "epoch:19 step:17979 [D loss: 0.225382, acc.: 60.94%] [G loss: 0.423411]\n",
      "epoch:19 step:17980 [D loss: 0.219499, acc.: 67.97%] [G loss: 0.415480]\n",
      "epoch:19 step:17981 [D loss: 0.216398, acc.: 64.06%] [G loss: 0.402422]\n",
      "epoch:19 step:17982 [D loss: 0.239413, acc.: 66.41%] [G loss: 0.422279]\n",
      "epoch:19 step:17983 [D loss: 0.228594, acc.: 62.50%] [G loss: 0.430564]\n",
      "epoch:19 step:17984 [D loss: 0.195938, acc.: 71.09%] [G loss: 0.443290]\n",
      "epoch:19 step:17985 [D loss: 0.219385, acc.: 66.41%] [G loss: 0.417247]\n",
      "epoch:19 step:17986 [D loss: 0.216893, acc.: 67.19%] [G loss: 0.436547]\n",
      "epoch:19 step:17987 [D loss: 0.203872, acc.: 65.62%] [G loss: 0.442008]\n",
      "epoch:19 step:17988 [D loss: 0.233871, acc.: 62.50%] [G loss: 0.419685]\n",
      "epoch:19 step:17989 [D loss: 0.232251, acc.: 59.38%] [G loss: 0.448570]\n",
      "epoch:19 step:17990 [D loss: 0.220057, acc.: 66.41%] [G loss: 0.432565]\n",
      "epoch:19 step:17991 [D loss: 0.246571, acc.: 59.38%] [G loss: 0.380335]\n",
      "epoch:19 step:17992 [D loss: 0.258259, acc.: 55.47%] [G loss: 0.411158]\n",
      "epoch:19 step:17993 [D loss: 0.220396, acc.: 65.62%] [G loss: 0.435021]\n",
      "epoch:19 step:17994 [D loss: 0.218206, acc.: 64.06%] [G loss: 0.424573]\n",
      "epoch:19 step:17995 [D loss: 0.222386, acc.: 63.28%] [G loss: 0.424588]\n",
      "epoch:19 step:17996 [D loss: 0.211989, acc.: 72.66%] [G loss: 0.430932]\n",
      "epoch:19 step:17997 [D loss: 0.180676, acc.: 68.75%] [G loss: 0.507122]\n",
      "epoch:19 step:17998 [D loss: 0.223248, acc.: 62.50%] [G loss: 0.429868]\n",
      "epoch:19 step:17999 [D loss: 0.244010, acc.: 55.47%] [G loss: 0.429811]\n",
      "epoch:19 step:18000 [D loss: 0.195335, acc.: 71.09%] [G loss: 0.440160]\n",
      "epoch:19 step:18001 [D loss: 0.196908, acc.: 71.09%] [G loss: 0.486509]\n",
      "epoch:19 step:18002 [D loss: 0.219348, acc.: 64.84%] [G loss: 0.461762]\n",
      "epoch:19 step:18003 [D loss: 0.236208, acc.: 59.38%] [G loss: 0.458943]\n",
      "epoch:19 step:18004 [D loss: 0.235785, acc.: 62.50%] [G loss: 0.456001]\n",
      "epoch:19 step:18005 [D loss: 0.216421, acc.: 63.28%] [G loss: 0.451563]\n",
      "epoch:19 step:18006 [D loss: 0.252054, acc.: 57.03%] [G loss: 0.483179]\n",
      "epoch:19 step:18007 [D loss: 0.236782, acc.: 63.28%] [G loss: 0.488723]\n",
      "epoch:19 step:18008 [D loss: 0.228106, acc.: 63.28%] [G loss: 0.494769]\n",
      "epoch:19 step:18009 [D loss: 0.206147, acc.: 69.53%] [G loss: 0.439640]\n",
      "epoch:19 step:18010 [D loss: 0.213683, acc.: 67.97%] [G loss: 0.465663]\n",
      "epoch:19 step:18011 [D loss: 0.201349, acc.: 67.19%] [G loss: 0.503884]\n",
      "epoch:19 step:18012 [D loss: 0.179145, acc.: 77.34%] [G loss: 0.497062]\n",
      "epoch:19 step:18013 [D loss: 0.278398, acc.: 54.69%] [G loss: 0.383000]\n",
      "epoch:19 step:18014 [D loss: 0.254303, acc.: 49.22%] [G loss: 0.420581]\n",
      "epoch:19 step:18015 [D loss: 0.246188, acc.: 54.69%] [G loss: 0.421067]\n",
      "epoch:19 step:18016 [D loss: 0.217166, acc.: 64.84%] [G loss: 0.421838]\n",
      "epoch:19 step:18017 [D loss: 0.254891, acc.: 55.47%] [G loss: 0.388114]\n",
      "epoch:19 step:18018 [D loss: 0.226048, acc.: 63.28%] [G loss: 0.406535]\n",
      "epoch:19 step:18019 [D loss: 0.210013, acc.: 65.62%] [G loss: 0.418448]\n",
      "epoch:19 step:18020 [D loss: 0.217723, acc.: 67.19%] [G loss: 0.428831]\n",
      "epoch:19 step:18021 [D loss: 0.217729, acc.: 60.94%] [G loss: 0.433147]\n",
      "epoch:19 step:18022 [D loss: 0.192761, acc.: 73.44%] [G loss: 0.457827]\n",
      "epoch:19 step:18023 [D loss: 0.278000, acc.: 50.00%] [G loss: 0.430916]\n",
      "epoch:19 step:18024 [D loss: 0.189673, acc.: 75.00%] [G loss: 0.464879]\n",
      "epoch:19 step:18025 [D loss: 0.207195, acc.: 71.09%] [G loss: 0.482356]\n",
      "epoch:19 step:18026 [D loss: 0.206637, acc.: 68.75%] [G loss: 0.447804]\n",
      "epoch:19 step:18027 [D loss: 0.258795, acc.: 53.12%] [G loss: 0.421068]\n",
      "epoch:19 step:18028 [D loss: 0.216162, acc.: 65.62%] [G loss: 0.447239]\n",
      "epoch:19 step:18029 [D loss: 0.253405, acc.: 55.47%] [G loss: 0.433263]\n",
      "epoch:19 step:18030 [D loss: 0.226549, acc.: 64.06%] [G loss: 0.390827]\n",
      "epoch:19 step:18031 [D loss: 0.261498, acc.: 47.66%] [G loss: 0.397208]\n",
      "epoch:19 step:18032 [D loss: 0.206577, acc.: 73.44%] [G loss: 0.419742]\n",
      "epoch:19 step:18033 [D loss: 0.212975, acc.: 64.84%] [G loss: 0.432497]\n",
      "epoch:19 step:18034 [D loss: 0.177540, acc.: 76.56%] [G loss: 0.510813]\n",
      "epoch:19 step:18035 [D loss: 0.179892, acc.: 69.53%] [G loss: 0.546958]\n",
      "epoch:19 step:18036 [D loss: 0.260923, acc.: 56.25%] [G loss: 0.481735]\n",
      "epoch:19 step:18037 [D loss: 0.238866, acc.: 65.62%] [G loss: 0.437430]\n",
      "epoch:19 step:18038 [D loss: 0.220440, acc.: 62.50%] [G loss: 0.395343]\n",
      "epoch:19 step:18039 [D loss: 0.209249, acc.: 68.75%] [G loss: 0.445143]\n",
      "epoch:19 step:18040 [D loss: 0.223713, acc.: 67.19%] [G loss: 0.406990]\n",
      "epoch:19 step:18041 [D loss: 0.218534, acc.: 63.28%] [G loss: 0.420199]\n",
      "epoch:19 step:18042 [D loss: 0.210918, acc.: 66.41%] [G loss: 0.461143]\n",
      "epoch:19 step:18043 [D loss: 0.203509, acc.: 70.31%] [G loss: 0.446555]\n",
      "epoch:19 step:18044 [D loss: 0.188622, acc.: 73.44%] [G loss: 0.459796]\n",
      "epoch:19 step:18045 [D loss: 0.220446, acc.: 64.06%] [G loss: 0.465184]\n",
      "epoch:19 step:18046 [D loss: 0.213507, acc.: 68.75%] [G loss: 0.476936]\n",
      "epoch:19 step:18047 [D loss: 0.212796, acc.: 68.75%] [G loss: 0.443816]\n",
      "epoch:19 step:18048 [D loss: 0.189688, acc.: 71.88%] [G loss: 0.487496]\n",
      "epoch:19 step:18049 [D loss: 0.218781, acc.: 63.28%] [G loss: 0.446374]\n",
      "epoch:19 step:18050 [D loss: 0.221648, acc.: 60.94%] [G loss: 0.459185]\n",
      "epoch:19 step:18051 [D loss: 0.194139, acc.: 65.62%] [G loss: 0.476785]\n",
      "epoch:19 step:18052 [D loss: 0.283938, acc.: 50.00%] [G loss: 0.469586]\n",
      "epoch:19 step:18053 [D loss: 0.265432, acc.: 56.25%] [G loss: 0.444514]\n",
      "epoch:19 step:18054 [D loss: 0.264333, acc.: 56.25%] [G loss: 0.453526]\n",
      "epoch:19 step:18055 [D loss: 0.235306, acc.: 62.50%] [G loss: 0.450764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18056 [D loss: 0.235934, acc.: 58.59%] [G loss: 0.429291]\n",
      "epoch:19 step:18057 [D loss: 0.224792, acc.: 59.38%] [G loss: 0.468690]\n",
      "epoch:19 step:18058 [D loss: 0.205533, acc.: 64.84%] [G loss: 0.477501]\n",
      "epoch:19 step:18059 [D loss: 0.229635, acc.: 62.50%] [G loss: 0.411208]\n",
      "epoch:19 step:18060 [D loss: 0.209271, acc.: 67.19%] [G loss: 0.462205]\n",
      "epoch:19 step:18061 [D loss: 0.186763, acc.: 75.00%] [G loss: 0.446320]\n",
      "epoch:19 step:18062 [D loss: 0.218649, acc.: 65.62%] [G loss: 0.430213]\n",
      "epoch:19 step:18063 [D loss: 0.234431, acc.: 58.59%] [G loss: 0.414263]\n",
      "epoch:19 step:18064 [D loss: 0.225978, acc.: 60.16%] [G loss: 0.425880]\n",
      "epoch:19 step:18065 [D loss: 0.219877, acc.: 65.62%] [G loss: 0.439027]\n",
      "epoch:19 step:18066 [D loss: 0.243692, acc.: 57.81%] [G loss: 0.421267]\n",
      "epoch:19 step:18067 [D loss: 0.204945, acc.: 67.97%] [G loss: 0.432137]\n",
      "epoch:19 step:18068 [D loss: 0.266077, acc.: 53.91%] [G loss: 0.437978]\n",
      "epoch:19 step:18069 [D loss: 0.266354, acc.: 51.56%] [G loss: 0.481612]\n",
      "epoch:19 step:18070 [D loss: 0.223221, acc.: 65.62%] [G loss: 0.446078]\n",
      "epoch:19 step:18071 [D loss: 0.201360, acc.: 65.62%] [G loss: 0.481313]\n",
      "epoch:19 step:18072 [D loss: 0.224545, acc.: 60.94%] [G loss: 0.425595]\n",
      "epoch:19 step:18073 [D loss: 0.237645, acc.: 57.81%] [G loss: 0.432169]\n",
      "epoch:19 step:18074 [D loss: 0.207139, acc.: 67.19%] [G loss: 0.461397]\n",
      "epoch:19 step:18075 [D loss: 0.233192, acc.: 57.03%] [G loss: 0.435737]\n",
      "epoch:19 step:18076 [D loss: 0.217773, acc.: 64.06%] [G loss: 0.416339]\n",
      "epoch:19 step:18077 [D loss: 0.196195, acc.: 71.09%] [G loss: 0.430675]\n",
      "epoch:19 step:18078 [D loss: 0.204289, acc.: 67.19%] [G loss: 0.431332]\n",
      "epoch:19 step:18079 [D loss: 0.187068, acc.: 72.66%] [G loss: 0.429623]\n",
      "epoch:19 step:18080 [D loss: 0.262903, acc.: 51.56%] [G loss: 0.448980]\n",
      "epoch:19 step:18081 [D loss: 0.235846, acc.: 60.94%] [G loss: 0.429483]\n",
      "epoch:19 step:18082 [D loss: 0.225785, acc.: 56.25%] [G loss: 0.432125]\n",
      "epoch:19 step:18083 [D loss: 0.212393, acc.: 64.84%] [G loss: 0.398128]\n",
      "epoch:19 step:18084 [D loss: 0.274438, acc.: 44.53%] [G loss: 0.409120]\n",
      "epoch:19 step:18085 [D loss: 0.209410, acc.: 63.28%] [G loss: 0.422535]\n",
      "epoch:19 step:18086 [D loss: 0.205135, acc.: 64.84%] [G loss: 0.417151]\n",
      "epoch:19 step:18087 [D loss: 0.206080, acc.: 66.41%] [G loss: 0.399155]\n",
      "epoch:19 step:18088 [D loss: 0.247395, acc.: 57.03%] [G loss: 0.366854]\n",
      "epoch:19 step:18089 [D loss: 0.199119, acc.: 71.88%] [G loss: 0.441784]\n",
      "epoch:19 step:18090 [D loss: 0.225094, acc.: 60.16%] [G loss: 0.428750]\n",
      "epoch:19 step:18091 [D loss: 0.215867, acc.: 68.75%] [G loss: 0.472360]\n",
      "epoch:19 step:18092 [D loss: 0.207260, acc.: 64.06%] [G loss: 0.461065]\n",
      "epoch:19 step:18093 [D loss: 0.216170, acc.: 63.28%] [G loss: 0.494809]\n",
      "epoch:19 step:18094 [D loss: 0.244007, acc.: 61.72%] [G loss: 0.401296]\n",
      "epoch:19 step:18095 [D loss: 0.239492, acc.: 55.47%] [G loss: 0.391290]\n",
      "epoch:19 step:18096 [D loss: 0.214294, acc.: 69.53%] [G loss: 0.437800]\n",
      "epoch:19 step:18097 [D loss: 0.245259, acc.: 55.47%] [G loss: 0.394839]\n",
      "epoch:19 step:18098 [D loss: 0.229141, acc.: 55.47%] [G loss: 0.432113]\n",
      "epoch:19 step:18099 [D loss: 0.208224, acc.: 68.75%] [G loss: 0.427369]\n",
      "epoch:19 step:18100 [D loss: 0.227100, acc.: 61.72%] [G loss: 0.412043]\n",
      "epoch:19 step:18101 [D loss: 0.212882, acc.: 64.06%] [G loss: 0.450236]\n",
      "epoch:19 step:18102 [D loss: 0.201919, acc.: 71.88%] [G loss: 0.435932]\n",
      "epoch:19 step:18103 [D loss: 0.219888, acc.: 60.94%] [G loss: 0.461463]\n",
      "epoch:19 step:18104 [D loss: 0.258345, acc.: 57.81%] [G loss: 0.478067]\n",
      "epoch:19 step:18105 [D loss: 0.203949, acc.: 71.09%] [G loss: 0.457082]\n",
      "epoch:19 step:18106 [D loss: 0.216087, acc.: 66.41%] [G loss: 0.422472]\n",
      "epoch:19 step:18107 [D loss: 0.213528, acc.: 62.50%] [G loss: 0.448032]\n",
      "epoch:19 step:18108 [D loss: 0.231670, acc.: 60.94%] [G loss: 0.398108]\n",
      "epoch:19 step:18109 [D loss: 0.210129, acc.: 67.97%] [G loss: 0.439929]\n",
      "epoch:19 step:18110 [D loss: 0.202438, acc.: 73.44%] [G loss: 0.445530]\n",
      "epoch:19 step:18111 [D loss: 0.212330, acc.: 66.41%] [G loss: 0.414248]\n",
      "epoch:19 step:18112 [D loss: 0.218513, acc.: 65.62%] [G loss: 0.410975]\n",
      "epoch:19 step:18113 [D loss: 0.229295, acc.: 63.28%] [G loss: 0.423531]\n",
      "epoch:19 step:18114 [D loss: 0.208648, acc.: 65.62%] [G loss: 0.427387]\n",
      "epoch:19 step:18115 [D loss: 0.198171, acc.: 67.97%] [G loss: 0.449692]\n",
      "epoch:19 step:18116 [D loss: 0.176120, acc.: 74.22%] [G loss: 0.515820]\n",
      "epoch:19 step:18117 [D loss: 0.181813, acc.: 73.44%] [G loss: 0.513980]\n",
      "epoch:19 step:18118 [D loss: 0.198711, acc.: 66.41%] [G loss: 0.509289]\n",
      "epoch:19 step:18119 [D loss: 0.265108, acc.: 57.81%] [G loss: 0.432802]\n",
      "epoch:19 step:18120 [D loss: 0.238328, acc.: 58.59%] [G loss: 0.397648]\n",
      "epoch:19 step:18121 [D loss: 0.227657, acc.: 55.47%] [G loss: 0.428295]\n",
      "epoch:19 step:18122 [D loss: 0.216884, acc.: 64.84%] [G loss: 0.441332]\n",
      "epoch:19 step:18123 [D loss: 0.235225, acc.: 62.50%] [G loss: 0.419281]\n",
      "epoch:19 step:18124 [D loss: 0.194226, acc.: 71.88%] [G loss: 0.463328]\n",
      "epoch:19 step:18125 [D loss: 0.197731, acc.: 67.97%] [G loss: 0.428658]\n",
      "epoch:19 step:18126 [D loss: 0.245659, acc.: 57.81%] [G loss: 0.415735]\n",
      "epoch:19 step:18127 [D loss: 0.251311, acc.: 57.81%] [G loss: 0.409750]\n",
      "epoch:19 step:18128 [D loss: 0.234100, acc.: 61.72%] [G loss: 0.411789]\n",
      "epoch:19 step:18129 [D loss: 0.214836, acc.: 70.31%] [G loss: 0.444095]\n",
      "epoch:19 step:18130 [D loss: 0.222243, acc.: 64.06%] [G loss: 0.441771]\n",
      "epoch:19 step:18131 [D loss: 0.207006, acc.: 66.41%] [G loss: 0.448295]\n",
      "epoch:19 step:18132 [D loss: 0.248027, acc.: 54.69%] [G loss: 0.417635]\n",
      "epoch:19 step:18133 [D loss: 0.222149, acc.: 63.28%] [G loss: 0.401838]\n",
      "epoch:19 step:18134 [D loss: 0.232950, acc.: 67.19%] [G loss: 0.407869]\n",
      "epoch:19 step:18135 [D loss: 0.207345, acc.: 66.41%] [G loss: 0.437960]\n",
      "epoch:19 step:18136 [D loss: 0.232061, acc.: 59.38%] [G loss: 0.437176]\n",
      "epoch:19 step:18137 [D loss: 0.231120, acc.: 62.50%] [G loss: 0.447088]\n",
      "epoch:19 step:18138 [D loss: 0.218999, acc.: 62.50%] [G loss: 0.470056]\n",
      "epoch:19 step:18139 [D loss: 0.200638, acc.: 68.75%] [G loss: 0.440718]\n",
      "epoch:19 step:18140 [D loss: 0.213439, acc.: 64.06%] [G loss: 0.408996]\n",
      "epoch:19 step:18141 [D loss: 0.216644, acc.: 62.50%] [G loss: 0.428391]\n",
      "epoch:19 step:18142 [D loss: 0.239406, acc.: 62.50%] [G loss: 0.429905]\n",
      "epoch:19 step:18143 [D loss: 0.218808, acc.: 60.16%] [G loss: 0.450297]\n",
      "epoch:19 step:18144 [D loss: 0.264666, acc.: 52.34%] [G loss: 0.434203]\n",
      "epoch:19 step:18145 [D loss: 0.224827, acc.: 60.16%] [G loss: 0.473366]\n",
      "epoch:19 step:18146 [D loss: 0.236402, acc.: 64.84%] [G loss: 0.445445]\n",
      "epoch:19 step:18147 [D loss: 0.217079, acc.: 62.50%] [G loss: 0.469994]\n",
      "epoch:19 step:18148 [D loss: 0.206134, acc.: 66.41%] [G loss: 0.461432]\n",
      "epoch:19 step:18149 [D loss: 0.192163, acc.: 66.41%] [G loss: 0.492428]\n",
      "epoch:19 step:18150 [D loss: 0.192856, acc.: 70.31%] [G loss: 0.542712]\n",
      "epoch:19 step:18151 [D loss: 0.314782, acc.: 50.78%] [G loss: 0.418561]\n",
      "epoch:19 step:18152 [D loss: 0.245709, acc.: 55.47%] [G loss: 0.428485]\n",
      "epoch:19 step:18153 [D loss: 0.249847, acc.: 59.38%] [G loss: 0.399862]\n",
      "epoch:19 step:18154 [D loss: 0.230512, acc.: 61.72%] [G loss: 0.391089]\n",
      "epoch:19 step:18155 [D loss: 0.223217, acc.: 60.94%] [G loss: 0.457203]\n",
      "epoch:19 step:18156 [D loss: 0.212442, acc.: 62.50%] [G loss: 0.446583]\n",
      "epoch:19 step:18157 [D loss: 0.183115, acc.: 73.44%] [G loss: 0.476505]\n",
      "epoch:19 step:18158 [D loss: 0.233166, acc.: 63.28%] [G loss: 0.474697]\n",
      "epoch:19 step:18159 [D loss: 0.233594, acc.: 65.62%] [G loss: 0.455383]\n",
      "epoch:19 step:18160 [D loss: 0.207877, acc.: 63.28%] [G loss: 0.434957]\n",
      "epoch:19 step:18161 [D loss: 0.227592, acc.: 63.28%] [G loss: 0.445715]\n",
      "epoch:19 step:18162 [D loss: 0.206034, acc.: 69.53%] [G loss: 0.427758]\n",
      "epoch:19 step:18163 [D loss: 0.201139, acc.: 71.09%] [G loss: 0.447261]\n",
      "epoch:19 step:18164 [D loss: 0.202262, acc.: 67.97%] [G loss: 0.438334]\n",
      "epoch:19 step:18165 [D loss: 0.230575, acc.: 64.84%] [G loss: 0.423192]\n",
      "epoch:19 step:18166 [D loss: 0.211084, acc.: 68.75%] [G loss: 0.456084]\n",
      "epoch:19 step:18167 [D loss: 0.219060, acc.: 67.97%] [G loss: 0.415954]\n",
      "epoch:19 step:18168 [D loss: 0.232847, acc.: 61.72%] [G loss: 0.460375]\n",
      "epoch:19 step:18169 [D loss: 0.205445, acc.: 68.75%] [G loss: 0.436152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18170 [D loss: 0.231540, acc.: 65.62%] [G loss: 0.468516]\n",
      "epoch:19 step:18171 [D loss: 0.267204, acc.: 55.47%] [G loss: 0.425374]\n",
      "epoch:19 step:18172 [D loss: 0.209871, acc.: 64.06%] [G loss: 0.391436]\n",
      "epoch:19 step:18173 [D loss: 0.196862, acc.: 69.53%] [G loss: 0.444778]\n",
      "epoch:19 step:18174 [D loss: 0.206215, acc.: 68.75%] [G loss: 0.451996]\n",
      "epoch:19 step:18175 [D loss: 0.208217, acc.: 69.53%] [G loss: 0.467471]\n",
      "epoch:19 step:18176 [D loss: 0.265461, acc.: 53.12%] [G loss: 0.437359]\n",
      "epoch:19 step:18177 [D loss: 0.167164, acc.: 75.00%] [G loss: 0.464280]\n",
      "epoch:19 step:18178 [D loss: 0.219257, acc.: 62.50%] [G loss: 0.434518]\n",
      "epoch:19 step:18179 [D loss: 0.245204, acc.: 57.81%] [G loss: 0.449825]\n",
      "epoch:19 step:18180 [D loss: 0.266275, acc.: 50.00%] [G loss: 0.426332]\n",
      "epoch:19 step:18181 [D loss: 0.217544, acc.: 62.50%] [G loss: 0.441277]\n",
      "epoch:19 step:18182 [D loss: 0.242417, acc.: 60.94%] [G loss: 0.415799]\n",
      "epoch:19 step:18183 [D loss: 0.234993, acc.: 55.47%] [G loss: 0.392399]\n",
      "epoch:19 step:18184 [D loss: 0.211959, acc.: 64.06%] [G loss: 0.434550]\n",
      "epoch:19 step:18185 [D loss: 0.216279, acc.: 65.62%] [G loss: 0.446277]\n",
      "epoch:19 step:18186 [D loss: 0.227120, acc.: 60.94%] [G loss: 0.417898]\n",
      "epoch:19 step:18187 [D loss: 0.204399, acc.: 63.28%] [G loss: 0.437251]\n",
      "epoch:19 step:18188 [D loss: 0.203425, acc.: 66.41%] [G loss: 0.436975]\n",
      "epoch:19 step:18189 [D loss: 0.224874, acc.: 60.16%] [G loss: 0.443258]\n",
      "epoch:19 step:18190 [D loss: 0.224820, acc.: 60.94%] [G loss: 0.436664]\n",
      "epoch:19 step:18191 [D loss: 0.202591, acc.: 69.53%] [G loss: 0.444453]\n",
      "epoch:19 step:18192 [D loss: 0.229317, acc.: 60.16%] [G loss: 0.465401]\n",
      "epoch:19 step:18193 [D loss: 0.231763, acc.: 60.94%] [G loss: 0.410536]\n",
      "epoch:19 step:18194 [D loss: 0.232911, acc.: 60.16%] [G loss: 0.412300]\n",
      "epoch:19 step:18195 [D loss: 0.244023, acc.: 53.12%] [G loss: 0.419890]\n",
      "epoch:19 step:18196 [D loss: 0.227643, acc.: 58.59%] [G loss: 0.436698]\n",
      "epoch:19 step:18197 [D loss: 0.217499, acc.: 67.97%] [G loss: 0.449476]\n",
      "epoch:19 step:18198 [D loss: 0.221385, acc.: 65.62%] [G loss: 0.460756]\n",
      "epoch:19 step:18199 [D loss: 0.247688, acc.: 58.59%] [G loss: 0.411728]\n",
      "epoch:19 step:18200 [D loss: 0.237858, acc.: 64.84%] [G loss: 0.420520]\n",
      "epoch:19 step:18201 [D loss: 0.186191, acc.: 73.44%] [G loss: 0.487453]\n",
      "epoch:19 step:18202 [D loss: 0.216970, acc.: 67.97%] [G loss: 0.530548]\n",
      "epoch:19 step:18203 [D loss: 0.262645, acc.: 57.03%] [G loss: 0.429217]\n",
      "epoch:19 step:18204 [D loss: 0.292416, acc.: 45.31%] [G loss: 0.403871]\n",
      "epoch:19 step:18205 [D loss: 0.206869, acc.: 72.66%] [G loss: 0.437522]\n",
      "epoch:19 step:18206 [D loss: 0.222262, acc.: 63.28%] [G loss: 0.464198]\n",
      "epoch:19 step:18207 [D loss: 0.241898, acc.: 57.81%] [G loss: 0.446502]\n",
      "epoch:19 step:18208 [D loss: 0.208760, acc.: 70.31%] [G loss: 0.478631]\n",
      "epoch:19 step:18209 [D loss: 0.212824, acc.: 65.62%] [G loss: 0.490440]\n",
      "epoch:19 step:18210 [D loss: 0.221704, acc.: 63.28%] [G loss: 0.485280]\n",
      "epoch:19 step:18211 [D loss: 0.261056, acc.: 49.22%] [G loss: 0.429651]\n",
      "epoch:19 step:18212 [D loss: 0.196743, acc.: 67.19%] [G loss: 0.454550]\n",
      "epoch:19 step:18213 [D loss: 0.231297, acc.: 60.16%] [G loss: 0.439110]\n",
      "epoch:19 step:18214 [D loss: 0.271640, acc.: 50.78%] [G loss: 0.412305]\n",
      "epoch:19 step:18215 [D loss: 0.216315, acc.: 64.06%] [G loss: 0.416889]\n",
      "epoch:19 step:18216 [D loss: 0.234365, acc.: 57.81%] [G loss: 0.408172]\n",
      "epoch:19 step:18217 [D loss: 0.235851, acc.: 60.16%] [G loss: 0.411250]\n",
      "epoch:19 step:18218 [D loss: 0.213019, acc.: 71.88%] [G loss: 0.475250]\n",
      "epoch:19 step:18219 [D loss: 0.172389, acc.: 80.47%] [G loss: 0.502000]\n",
      "epoch:19 step:18220 [D loss: 0.219078, acc.: 67.97%] [G loss: 0.503075]\n",
      "epoch:19 step:18221 [D loss: 0.238881, acc.: 62.50%] [G loss: 0.417730]\n",
      "epoch:19 step:18222 [D loss: 0.253440, acc.: 58.59%] [G loss: 0.433224]\n",
      "epoch:19 step:18223 [D loss: 0.219460, acc.: 65.62%] [G loss: 0.404448]\n",
      "epoch:19 step:18224 [D loss: 0.242687, acc.: 53.12%] [G loss: 0.396106]\n",
      "epoch:19 step:18225 [D loss: 0.245271, acc.: 51.56%] [G loss: 0.386403]\n",
      "epoch:19 step:18226 [D loss: 0.240947, acc.: 59.38%] [G loss: 0.394194]\n",
      "epoch:19 step:18227 [D loss: 0.213244, acc.: 64.84%] [G loss: 0.418343]\n",
      "epoch:19 step:18228 [D loss: 0.214355, acc.: 61.72%] [G loss: 0.408205]\n",
      "epoch:19 step:18229 [D loss: 0.206946, acc.: 72.66%] [G loss: 0.408636]\n",
      "epoch:19 step:18230 [D loss: 0.208894, acc.: 67.97%] [G loss: 0.413974]\n",
      "epoch:19 step:18231 [D loss: 0.197336, acc.: 71.88%] [G loss: 0.434261]\n",
      "epoch:19 step:18232 [D loss: 0.210130, acc.: 66.41%] [G loss: 0.428093]\n",
      "epoch:19 step:18233 [D loss: 0.213332, acc.: 62.50%] [G loss: 0.439579]\n",
      "epoch:19 step:18234 [D loss: 0.235496, acc.: 58.59%] [G loss: 0.455776]\n",
      "epoch:19 step:18235 [D loss: 0.227826, acc.: 57.81%] [G loss: 0.442182]\n",
      "epoch:19 step:18236 [D loss: 0.217183, acc.: 61.72%] [G loss: 0.455582]\n",
      "epoch:19 step:18237 [D loss: 0.220222, acc.: 65.62%] [G loss: 0.461975]\n",
      "epoch:19 step:18238 [D loss: 0.197364, acc.: 71.88%] [G loss: 0.486200]\n",
      "epoch:19 step:18239 [D loss: 0.213945, acc.: 68.75%] [G loss: 0.457844]\n",
      "epoch:19 step:18240 [D loss: 0.281169, acc.: 52.34%] [G loss: 0.430326]\n",
      "epoch:19 step:18241 [D loss: 0.263874, acc.: 53.12%] [G loss: 0.376419]\n",
      "epoch:19 step:18242 [D loss: 0.212531, acc.: 66.41%] [G loss: 0.448368]\n",
      "epoch:19 step:18243 [D loss: 0.225709, acc.: 64.84%] [G loss: 0.450278]\n",
      "epoch:19 step:18244 [D loss: 0.228780, acc.: 62.50%] [G loss: 0.416713]\n",
      "epoch:19 step:18245 [D loss: 0.240968, acc.: 57.03%] [G loss: 0.419609]\n",
      "epoch:19 step:18246 [D loss: 0.242742, acc.: 57.03%] [G loss: 0.396311]\n",
      "epoch:19 step:18247 [D loss: 0.248529, acc.: 58.59%] [G loss: 0.382830]\n",
      "epoch:19 step:18248 [D loss: 0.212476, acc.: 67.97%] [G loss: 0.448716]\n",
      "epoch:19 step:18249 [D loss: 0.233747, acc.: 64.84%] [G loss: 0.433142]\n",
      "epoch:19 step:18250 [D loss: 0.217779, acc.: 66.41%] [G loss: 0.403061]\n",
      "epoch:19 step:18251 [D loss: 0.230410, acc.: 60.94%] [G loss: 0.466632]\n",
      "epoch:19 step:18252 [D loss: 0.231387, acc.: 62.50%] [G loss: 0.418890]\n",
      "epoch:19 step:18253 [D loss: 0.243283, acc.: 58.59%] [G loss: 0.382157]\n",
      "epoch:19 step:18254 [D loss: 0.209027, acc.: 67.97%] [G loss: 0.423469]\n",
      "epoch:19 step:18255 [D loss: 0.228803, acc.: 60.16%] [G loss: 0.443685]\n",
      "epoch:19 step:18256 [D loss: 0.204439, acc.: 64.84%] [G loss: 0.450048]\n",
      "epoch:19 step:18257 [D loss: 0.233809, acc.: 64.06%] [G loss: 0.476168]\n",
      "epoch:19 step:18258 [D loss: 0.214051, acc.: 62.50%] [G loss: 0.440756]\n",
      "epoch:19 step:18259 [D loss: 0.214103, acc.: 67.97%] [G loss: 0.469292]\n",
      "epoch:19 step:18260 [D loss: 0.230896, acc.: 62.50%] [G loss: 0.460040]\n",
      "epoch:19 step:18261 [D loss: 0.259049, acc.: 59.38%] [G loss: 0.436593]\n",
      "epoch:19 step:18262 [D loss: 0.235591, acc.: 59.38%] [G loss: 0.430334]\n",
      "epoch:19 step:18263 [D loss: 0.220805, acc.: 60.16%] [G loss: 0.424475]\n",
      "epoch:19 step:18264 [D loss: 0.246198, acc.: 57.81%] [G loss: 0.414142]\n",
      "epoch:19 step:18265 [D loss: 0.229952, acc.: 61.72%] [G loss: 0.391645]\n",
      "epoch:19 step:18266 [D loss: 0.213364, acc.: 67.19%] [G loss: 0.423171]\n",
      "epoch:19 step:18267 [D loss: 0.231923, acc.: 57.81%] [G loss: 0.401648]\n",
      "epoch:19 step:18268 [D loss: 0.228524, acc.: 62.50%] [G loss: 0.424384]\n",
      "epoch:19 step:18269 [D loss: 0.218182, acc.: 62.50%] [G loss: 0.426607]\n",
      "epoch:19 step:18270 [D loss: 0.227353, acc.: 60.94%] [G loss: 0.407587]\n",
      "epoch:19 step:18271 [D loss: 0.210780, acc.: 62.50%] [G loss: 0.464207]\n",
      "epoch:19 step:18272 [D loss: 0.198545, acc.: 71.09%] [G loss: 0.459270]\n",
      "epoch:19 step:18273 [D loss: 0.200764, acc.: 67.97%] [G loss: 0.501379]\n",
      "epoch:19 step:18274 [D loss: 0.217568, acc.: 67.97%] [G loss: 0.450971]\n",
      "epoch:19 step:18275 [D loss: 0.189252, acc.: 72.66%] [G loss: 0.522315]\n",
      "epoch:19 step:18276 [D loss: 0.271435, acc.: 51.56%] [G loss: 0.509966]\n",
      "epoch:19 step:18277 [D loss: 0.210287, acc.: 61.72%] [G loss: 0.431398]\n",
      "epoch:19 step:18278 [D loss: 0.186048, acc.: 74.22%] [G loss: 0.443508]\n",
      "epoch:19 step:18279 [D loss: 0.250284, acc.: 63.28%] [G loss: 0.463864]\n",
      "epoch:19 step:18280 [D loss: 0.261188, acc.: 57.81%] [G loss: 0.425940]\n",
      "epoch:19 step:18281 [D loss: 0.241160, acc.: 58.59%] [G loss: 0.417091]\n",
      "epoch:19 step:18282 [D loss: 0.215411, acc.: 69.53%] [G loss: 0.426658]\n",
      "epoch:19 step:18283 [D loss: 0.223597, acc.: 62.50%] [G loss: 0.405998]\n",
      "epoch:19 step:18284 [D loss: 0.168595, acc.: 78.12%] [G loss: 0.470318]\n",
      "epoch:19 step:18285 [D loss: 0.286118, acc.: 46.09%] [G loss: 0.402577]\n",
      "epoch:19 step:18286 [D loss: 0.237417, acc.: 53.91%] [G loss: 0.427300]\n",
      "epoch:19 step:18287 [D loss: 0.212208, acc.: 62.50%] [G loss: 0.432284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18288 [D loss: 0.205097, acc.: 67.19%] [G loss: 0.451682]\n",
      "epoch:19 step:18289 [D loss: 0.234986, acc.: 58.59%] [G loss: 0.388404]\n",
      "epoch:19 step:18290 [D loss: 0.223608, acc.: 58.59%] [G loss: 0.464572]\n",
      "epoch:19 step:18291 [D loss: 0.190352, acc.: 71.88%] [G loss: 0.456935]\n",
      "epoch:19 step:18292 [D loss: 0.242713, acc.: 55.47%] [G loss: 0.451209]\n",
      "epoch:19 step:18293 [D loss: 0.230950, acc.: 60.16%] [G loss: 0.423360]\n",
      "epoch:19 step:18294 [D loss: 0.236840, acc.: 62.50%] [G loss: 0.426096]\n",
      "epoch:19 step:18295 [D loss: 0.219716, acc.: 64.84%] [G loss: 0.427098]\n",
      "epoch:19 step:18296 [D loss: 0.232013, acc.: 64.84%] [G loss: 0.432268]\n",
      "epoch:19 step:18297 [D loss: 0.226556, acc.: 60.16%] [G loss: 0.433978]\n",
      "epoch:19 step:18298 [D loss: 0.199592, acc.: 67.97%] [G loss: 0.471719]\n",
      "epoch:19 step:18299 [D loss: 0.214397, acc.: 67.19%] [G loss: 0.452974]\n",
      "epoch:19 step:18300 [D loss: 0.238448, acc.: 54.69%] [G loss: 0.449953]\n",
      "epoch:19 step:18301 [D loss: 0.187956, acc.: 71.09%] [G loss: 0.501867]\n",
      "epoch:19 step:18302 [D loss: 0.182014, acc.: 76.56%] [G loss: 0.463521]\n",
      "epoch:19 step:18303 [D loss: 0.246320, acc.: 58.59%] [G loss: 0.450653]\n",
      "epoch:19 step:18304 [D loss: 0.286478, acc.: 50.00%] [G loss: 0.413460]\n",
      "epoch:19 step:18305 [D loss: 0.219109, acc.: 61.72%] [G loss: 0.410163]\n",
      "epoch:19 step:18306 [D loss: 0.215288, acc.: 67.19%] [G loss: 0.424068]\n",
      "epoch:19 step:18307 [D loss: 0.189989, acc.: 72.66%] [G loss: 0.481921]\n",
      "epoch:19 step:18308 [D loss: 0.218002, acc.: 61.72%] [G loss: 0.446747]\n",
      "epoch:19 step:18309 [D loss: 0.234241, acc.: 60.16%] [G loss: 0.479323]\n",
      "epoch:19 step:18310 [D loss: 0.235679, acc.: 60.16%] [G loss: 0.491590]\n",
      "epoch:19 step:18311 [D loss: 0.189732, acc.: 72.66%] [G loss: 0.518746]\n",
      "epoch:19 step:18312 [D loss: 0.266385, acc.: 55.47%] [G loss: 0.412439]\n",
      "epoch:19 step:18313 [D loss: 0.248769, acc.: 56.25%] [G loss: 0.423494]\n",
      "epoch:19 step:18314 [D loss: 0.237416, acc.: 63.28%] [G loss: 0.429779]\n",
      "epoch:19 step:18315 [D loss: 0.216259, acc.: 64.06%] [G loss: 0.446509]\n",
      "epoch:19 step:18316 [D loss: 0.231058, acc.: 64.06%] [G loss: 0.489610]\n",
      "epoch:19 step:18317 [D loss: 0.221522, acc.: 60.16%] [G loss: 0.460503]\n",
      "epoch:19 step:18318 [D loss: 0.200546, acc.: 72.66%] [G loss: 0.467121]\n",
      "epoch:19 step:18319 [D loss: 0.186348, acc.: 73.44%] [G loss: 0.451131]\n",
      "epoch:19 step:18320 [D loss: 0.277994, acc.: 56.25%] [G loss: 0.414070]\n",
      "epoch:19 step:18321 [D loss: 0.228178, acc.: 66.41%] [G loss: 0.414541]\n",
      "epoch:19 step:18322 [D loss: 0.207935, acc.: 64.84%] [G loss: 0.438329]\n",
      "epoch:19 step:18323 [D loss: 0.196190, acc.: 74.22%] [G loss: 0.466744]\n",
      "epoch:19 step:18324 [D loss: 0.204810, acc.: 67.97%] [G loss: 0.433233]\n",
      "epoch:19 step:18325 [D loss: 0.221581, acc.: 64.84%] [G loss: 0.419361]\n",
      "epoch:19 step:18326 [D loss: 0.217550, acc.: 69.53%] [G loss: 0.448760]\n",
      "epoch:19 step:18327 [D loss: 0.205124, acc.: 70.31%] [G loss: 0.469724]\n",
      "epoch:19 step:18328 [D loss: 0.219461, acc.: 64.84%] [G loss: 0.442735]\n",
      "epoch:19 step:18329 [D loss: 0.215523, acc.: 64.06%] [G loss: 0.480331]\n",
      "epoch:19 step:18330 [D loss: 0.197879, acc.: 74.22%] [G loss: 0.502905]\n",
      "epoch:19 step:18331 [D loss: 0.256947, acc.: 53.91%] [G loss: 0.459101]\n",
      "epoch:19 step:18332 [D loss: 0.216018, acc.: 65.62%] [G loss: 0.437861]\n",
      "epoch:19 step:18333 [D loss: 0.230581, acc.: 66.41%] [G loss: 0.411211]\n",
      "epoch:19 step:18334 [D loss: 0.263334, acc.: 57.03%] [G loss: 0.388430]\n",
      "epoch:19 step:18335 [D loss: 0.222388, acc.: 62.50%] [G loss: 0.396095]\n",
      "epoch:19 step:18336 [D loss: 0.226616, acc.: 55.47%] [G loss: 0.448246]\n",
      "epoch:19 step:18337 [D loss: 0.173617, acc.: 77.34%] [G loss: 0.465084]\n",
      "epoch:19 step:18338 [D loss: 0.235598, acc.: 61.72%] [G loss: 0.422192]\n",
      "epoch:19 step:18339 [D loss: 0.224531, acc.: 60.94%] [G loss: 0.429147]\n",
      "epoch:19 step:18340 [D loss: 0.223994, acc.: 64.84%] [G loss: 0.451865]\n",
      "epoch:19 step:18341 [D loss: 0.244346, acc.: 57.81%] [G loss: 0.417358]\n",
      "epoch:19 step:18342 [D loss: 0.225192, acc.: 59.38%] [G loss: 0.440527]\n",
      "epoch:19 step:18343 [D loss: 0.220422, acc.: 62.50%] [G loss: 0.436599]\n",
      "epoch:19 step:18344 [D loss: 0.226002, acc.: 60.94%] [G loss: 0.415277]\n",
      "epoch:19 step:18345 [D loss: 0.249997, acc.: 52.34%] [G loss: 0.452706]\n",
      "epoch:19 step:18346 [D loss: 0.232575, acc.: 57.81%] [G loss: 0.432267]\n",
      "epoch:19 step:18347 [D loss: 0.249557, acc.: 60.16%] [G loss: 0.455897]\n",
      "epoch:19 step:18348 [D loss: 0.232970, acc.: 64.84%] [G loss: 0.408689]\n",
      "epoch:19 step:18349 [D loss: 0.212045, acc.: 63.28%] [G loss: 0.439058]\n",
      "epoch:19 step:18350 [D loss: 0.195993, acc.: 67.97%] [G loss: 0.419081]\n",
      "epoch:19 step:18351 [D loss: 0.207328, acc.: 67.97%] [G loss: 0.410745]\n",
      "epoch:19 step:18352 [D loss: 0.195214, acc.: 67.19%] [G loss: 0.458089]\n",
      "epoch:19 step:18353 [D loss: 0.210430, acc.: 69.53%] [G loss: 0.441868]\n",
      "epoch:19 step:18354 [D loss: 0.177022, acc.: 75.78%] [G loss: 0.446094]\n",
      "epoch:19 step:18355 [D loss: 0.215645, acc.: 65.62%] [G loss: 0.467475]\n",
      "epoch:19 step:18356 [D loss: 0.228768, acc.: 64.84%] [G loss: 0.438071]\n",
      "epoch:19 step:18357 [D loss: 0.213477, acc.: 65.62%] [G loss: 0.434498]\n",
      "epoch:19 step:18358 [D loss: 0.219366, acc.: 64.06%] [G loss: 0.452614]\n",
      "epoch:19 step:18359 [D loss: 0.213828, acc.: 68.75%] [G loss: 0.436270]\n",
      "epoch:19 step:18360 [D loss: 0.190759, acc.: 72.66%] [G loss: 0.447068]\n",
      "epoch:19 step:18361 [D loss: 0.207521, acc.: 71.88%] [G loss: 0.436231]\n",
      "epoch:19 step:18362 [D loss: 0.237373, acc.: 60.16%] [G loss: 0.406076]\n",
      "epoch:19 step:18363 [D loss: 0.244522, acc.: 57.81%] [G loss: 0.408924]\n",
      "epoch:19 step:18364 [D loss: 0.231749, acc.: 61.72%] [G loss: 0.436936]\n",
      "epoch:19 step:18365 [D loss: 0.216417, acc.: 66.41%] [G loss: 0.424146]\n",
      "epoch:19 step:18366 [D loss: 0.206057, acc.: 70.31%] [G loss: 0.491346]\n",
      "epoch:19 step:18367 [D loss: 0.197369, acc.: 73.44%] [G loss: 0.462916]\n",
      "epoch:19 step:18368 [D loss: 0.246943, acc.: 56.25%] [G loss: 0.472914]\n",
      "epoch:19 step:18369 [D loss: 0.246523, acc.: 57.03%] [G loss: 0.469287]\n",
      "epoch:19 step:18370 [D loss: 0.207498, acc.: 65.62%] [G loss: 0.477684]\n",
      "epoch:19 step:18371 [D loss: 0.202358, acc.: 71.09%] [G loss: 0.479345]\n",
      "epoch:19 step:18372 [D loss: 0.263022, acc.: 57.03%] [G loss: 0.391032]\n",
      "epoch:19 step:18373 [D loss: 0.206415, acc.: 69.53%] [G loss: 0.438218]\n",
      "epoch:19 step:18374 [D loss: 0.201430, acc.: 71.09%] [G loss: 0.454986]\n",
      "epoch:19 step:18375 [D loss: 0.264252, acc.: 52.34%] [G loss: 0.437571]\n",
      "epoch:19 step:18376 [D loss: 0.274383, acc.: 50.78%] [G loss: 0.427850]\n",
      "epoch:19 step:18377 [D loss: 0.194724, acc.: 70.31%] [G loss: 0.502474]\n",
      "epoch:19 step:18378 [D loss: 0.206458, acc.: 69.53%] [G loss: 0.479329]\n",
      "epoch:19 step:18379 [D loss: 0.232681, acc.: 65.62%] [G loss: 0.436827]\n",
      "epoch:19 step:18380 [D loss: 0.215492, acc.: 60.94%] [G loss: 0.399610]\n",
      "epoch:19 step:18381 [D loss: 0.226183, acc.: 66.41%] [G loss: 0.414265]\n",
      "epoch:19 step:18382 [D loss: 0.260868, acc.: 56.25%] [G loss: 0.398321]\n",
      "epoch:19 step:18383 [D loss: 0.226817, acc.: 62.50%] [G loss: 0.444908]\n",
      "epoch:19 step:18384 [D loss: 0.218333, acc.: 64.06%] [G loss: 0.471527]\n",
      "epoch:19 step:18385 [D loss: 0.214311, acc.: 62.50%] [G loss: 0.517944]\n",
      "epoch:19 step:18386 [D loss: 0.212942, acc.: 64.84%] [G loss: 0.537658]\n",
      "epoch:19 step:18387 [D loss: 0.234624, acc.: 54.69%] [G loss: 0.447932]\n",
      "epoch:19 step:18388 [D loss: 0.220989, acc.: 64.84%] [G loss: 0.474376]\n",
      "epoch:19 step:18389 [D loss: 0.212382, acc.: 64.84%] [G loss: 0.442291]\n",
      "epoch:19 step:18390 [D loss: 0.250496, acc.: 58.59%] [G loss: 0.395747]\n",
      "epoch:19 step:18391 [D loss: 0.245360, acc.: 54.69%] [G loss: 0.438930]\n",
      "epoch:19 step:18392 [D loss: 0.187074, acc.: 71.88%] [G loss: 0.485010]\n",
      "epoch:19 step:18393 [D loss: 0.252229, acc.: 58.59%] [G loss: 0.464493]\n",
      "epoch:19 step:18394 [D loss: 0.241634, acc.: 56.25%] [G loss: 0.437044]\n",
      "epoch:19 step:18395 [D loss: 0.207214, acc.: 65.62%] [G loss: 0.423991]\n",
      "epoch:19 step:18396 [D loss: 0.212914, acc.: 61.72%] [G loss: 0.455117]\n",
      "epoch:19 step:18397 [D loss: 0.228018, acc.: 62.50%] [G loss: 0.465554]\n",
      "epoch:19 step:18398 [D loss: 0.219556, acc.: 64.06%] [G loss: 0.421699]\n",
      "epoch:19 step:18399 [D loss: 0.235993, acc.: 58.59%] [G loss: 0.404948]\n",
      "epoch:19 step:18400 [D loss: 0.251982, acc.: 60.16%] [G loss: 0.430381]\n",
      "epoch:19 step:18401 [D loss: 0.213272, acc.: 67.97%] [G loss: 0.404693]\n",
      "epoch:19 step:18402 [D loss: 0.220035, acc.: 65.62%] [G loss: 0.450473]\n",
      "epoch:19 step:18403 [D loss: 0.241623, acc.: 57.81%] [G loss: 0.401730]\n",
      "epoch:19 step:18404 [D loss: 0.224974, acc.: 68.75%] [G loss: 0.389146]\n",
      "epoch:19 step:18405 [D loss: 0.238579, acc.: 57.03%] [G loss: 0.406917]\n",
      "epoch:19 step:18406 [D loss: 0.229237, acc.: 63.28%] [G loss: 0.402277]\n",
      "epoch:19 step:18407 [D loss: 0.236635, acc.: 62.50%] [G loss: 0.446156]\n",
      "epoch:19 step:18408 [D loss: 0.205935, acc.: 67.19%] [G loss: 0.439120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18409 [D loss: 0.242237, acc.: 59.38%] [G loss: 0.422460]\n",
      "epoch:19 step:18410 [D loss: 0.238460, acc.: 55.47%] [G loss: 0.395437]\n",
      "epoch:19 step:18411 [D loss: 0.238876, acc.: 57.81%] [G loss: 0.400909]\n",
      "epoch:19 step:18412 [D loss: 0.251820, acc.: 56.25%] [G loss: 0.392277]\n",
      "epoch:19 step:18413 [D loss: 0.217364, acc.: 59.38%] [G loss: 0.410488]\n",
      "epoch:19 step:18414 [D loss: 0.223537, acc.: 59.38%] [G loss: 0.415938]\n",
      "epoch:19 step:18415 [D loss: 0.249395, acc.: 60.16%] [G loss: 0.395996]\n",
      "epoch:19 step:18416 [D loss: 0.192137, acc.: 73.44%] [G loss: 0.438477]\n",
      "epoch:19 step:18417 [D loss: 0.237691, acc.: 60.16%] [G loss: 0.411060]\n",
      "epoch:19 step:18418 [D loss: 0.266379, acc.: 50.78%] [G loss: 0.381178]\n",
      "epoch:19 step:18419 [D loss: 0.234296, acc.: 59.38%] [G loss: 0.436071]\n",
      "epoch:19 step:18420 [D loss: 0.238566, acc.: 62.50%] [G loss: 0.450831]\n",
      "epoch:19 step:18421 [D loss: 0.203330, acc.: 67.19%] [G loss: 0.455510]\n",
      "epoch:19 step:18422 [D loss: 0.236102, acc.: 60.16%] [G loss: 0.439803]\n",
      "epoch:19 step:18423 [D loss: 0.215920, acc.: 69.53%] [G loss: 0.447094]\n",
      "epoch:19 step:18424 [D loss: 0.211892, acc.: 67.19%] [G loss: 0.460664]\n",
      "epoch:19 step:18425 [D loss: 0.241775, acc.: 61.72%] [G loss: 0.450682]\n",
      "epoch:19 step:18426 [D loss: 0.232024, acc.: 61.72%] [G loss: 0.397729]\n",
      "epoch:19 step:18427 [D loss: 0.182856, acc.: 78.12%] [G loss: 0.435999]\n",
      "epoch:19 step:18428 [D loss: 0.236043, acc.: 57.81%] [G loss: 0.422942]\n",
      "epoch:19 step:18429 [D loss: 0.242583, acc.: 60.16%] [G loss: 0.403865]\n",
      "epoch:19 step:18430 [D loss: 0.214755, acc.: 66.41%] [G loss: 0.402442]\n",
      "epoch:19 step:18431 [D loss: 0.218334, acc.: 69.53%] [G loss: 0.443204]\n",
      "epoch:19 step:18432 [D loss: 0.203138, acc.: 70.31%] [G loss: 0.459465]\n",
      "epoch:19 step:18433 [D loss: 0.233400, acc.: 62.50%] [G loss: 0.406372]\n",
      "epoch:19 step:18434 [D loss: 0.201901, acc.: 71.88%] [G loss: 0.446522]\n",
      "epoch:19 step:18435 [D loss: 0.211256, acc.: 66.41%] [G loss: 0.434693]\n",
      "epoch:19 step:18436 [D loss: 0.225242, acc.: 64.84%] [G loss: 0.429266]\n",
      "epoch:19 step:18437 [D loss: 0.195654, acc.: 71.88%] [G loss: 0.480416]\n",
      "epoch:19 step:18438 [D loss: 0.206739, acc.: 67.19%] [G loss: 0.400599]\n",
      "epoch:19 step:18439 [D loss: 0.221767, acc.: 65.62%] [G loss: 0.485568]\n",
      "epoch:19 step:18440 [D loss: 0.220868, acc.: 59.38%] [G loss: 0.421242]\n",
      "epoch:19 step:18441 [D loss: 0.235744, acc.: 59.38%] [G loss: 0.402661]\n",
      "epoch:19 step:18442 [D loss: 0.246821, acc.: 52.34%] [G loss: 0.428926]\n",
      "epoch:19 step:18443 [D loss: 0.190006, acc.: 68.75%] [G loss: 0.472650]\n",
      "epoch:19 step:18444 [D loss: 0.192936, acc.: 72.66%] [G loss: 0.486110]\n",
      "epoch:19 step:18445 [D loss: 0.218279, acc.: 62.50%] [G loss: 0.522155]\n",
      "epoch:19 step:18446 [D loss: 0.224489, acc.: 58.59%] [G loss: 0.453026]\n",
      "epoch:19 step:18447 [D loss: 0.224392, acc.: 64.06%] [G loss: 0.450196]\n",
      "epoch:19 step:18448 [D loss: 0.220687, acc.: 59.38%] [G loss: 0.458547]\n",
      "epoch:19 step:18449 [D loss: 0.214260, acc.: 64.84%] [G loss: 0.466600]\n",
      "epoch:19 step:18450 [D loss: 0.224513, acc.: 64.84%] [G loss: 0.476403]\n",
      "epoch:19 step:18451 [D loss: 0.182590, acc.: 76.56%] [G loss: 0.503501]\n",
      "epoch:19 step:18452 [D loss: 0.214239, acc.: 66.41%] [G loss: 0.469925]\n",
      "epoch:19 step:18453 [D loss: 0.201350, acc.: 67.19%] [G loss: 0.481704]\n",
      "epoch:19 step:18454 [D loss: 0.217915, acc.: 69.53%] [G loss: 0.487176]\n",
      "epoch:19 step:18455 [D loss: 0.228014, acc.: 60.16%] [G loss: 0.448907]\n",
      "epoch:19 step:18456 [D loss: 0.204289, acc.: 74.22%] [G loss: 0.422356]\n",
      "epoch:19 step:18457 [D loss: 0.179963, acc.: 76.56%] [G loss: 0.472466]\n",
      "epoch:19 step:18458 [D loss: 0.252503, acc.: 59.38%] [G loss: 0.423885]\n",
      "epoch:19 step:18459 [D loss: 0.248438, acc.: 60.16%] [G loss: 0.435543]\n",
      "epoch:19 step:18460 [D loss: 0.231559, acc.: 66.41%] [G loss: 0.385619]\n",
      "epoch:19 step:18461 [D loss: 0.235511, acc.: 59.38%] [G loss: 0.424108]\n",
      "epoch:19 step:18462 [D loss: 0.198348, acc.: 70.31%] [G loss: 0.445322]\n",
      "epoch:19 step:18463 [D loss: 0.187763, acc.: 71.09%] [G loss: 0.441454]\n",
      "epoch:19 step:18464 [D loss: 0.178038, acc.: 72.66%] [G loss: 0.452814]\n",
      "epoch:19 step:18465 [D loss: 0.242006, acc.: 52.34%] [G loss: 0.398881]\n",
      "epoch:19 step:18466 [D loss: 0.219518, acc.: 67.97%] [G loss: 0.437787]\n",
      "epoch:19 step:18467 [D loss: 0.220084, acc.: 61.72%] [G loss: 0.438826]\n",
      "epoch:19 step:18468 [D loss: 0.206750, acc.: 63.28%] [G loss: 0.440955]\n",
      "epoch:19 step:18469 [D loss: 0.212933, acc.: 71.88%] [G loss: 0.415061]\n",
      "epoch:19 step:18470 [D loss: 0.235437, acc.: 57.03%] [G loss: 0.469074]\n",
      "epoch:19 step:18471 [D loss: 0.231961, acc.: 60.16%] [G loss: 0.442847]\n",
      "epoch:19 step:18472 [D loss: 0.222601, acc.: 57.81%] [G loss: 0.414864]\n",
      "epoch:19 step:18473 [D loss: 0.241066, acc.: 60.16%] [G loss: 0.401388]\n",
      "epoch:19 step:18474 [D loss: 0.222244, acc.: 66.41%] [G loss: 0.418435]\n",
      "epoch:19 step:18475 [D loss: 0.235529, acc.: 58.59%] [G loss: 0.427865]\n",
      "epoch:19 step:18476 [D loss: 0.231850, acc.: 57.03%] [G loss: 0.404674]\n",
      "epoch:19 step:18477 [D loss: 0.190638, acc.: 71.09%] [G loss: 0.478836]\n",
      "epoch:19 step:18478 [D loss: 0.281558, acc.: 49.22%] [G loss: 0.424887]\n",
      "epoch:19 step:18479 [D loss: 0.232290, acc.: 66.41%] [G loss: 0.411953]\n",
      "epoch:19 step:18480 [D loss: 0.202613, acc.: 73.44%] [G loss: 0.436101]\n",
      "epoch:19 step:18481 [D loss: 0.219524, acc.: 65.62%] [G loss: 0.440377]\n",
      "epoch:19 step:18482 [D loss: 0.236765, acc.: 61.72%] [G loss: 0.436273]\n",
      "epoch:19 step:18483 [D loss: 0.227835, acc.: 55.47%] [G loss: 0.446578]\n",
      "epoch:19 step:18484 [D loss: 0.208235, acc.: 64.84%] [G loss: 0.440919]\n",
      "epoch:19 step:18485 [D loss: 0.231790, acc.: 63.28%] [G loss: 0.465843]\n",
      "epoch:19 step:18486 [D loss: 0.242737, acc.: 60.16%] [G loss: 0.425181]\n",
      "epoch:19 step:18487 [D loss: 0.244039, acc.: 55.47%] [G loss: 0.409220]\n",
      "epoch:19 step:18488 [D loss: 0.205234, acc.: 68.75%] [G loss: 0.426736]\n",
      "epoch:19 step:18489 [D loss: 0.227308, acc.: 60.16%] [G loss: 0.414365]\n",
      "epoch:19 step:18490 [D loss: 0.216818, acc.: 64.84%] [G loss: 0.441341]\n",
      "epoch:19 step:18491 [D loss: 0.201352, acc.: 71.09%] [G loss: 0.440848]\n",
      "epoch:19 step:18492 [D loss: 0.208586, acc.: 69.53%] [G loss: 0.427223]\n",
      "epoch:19 step:18493 [D loss: 0.202628, acc.: 71.88%] [G loss: 0.456447]\n",
      "epoch:19 step:18494 [D loss: 0.222286, acc.: 61.72%] [G loss: 0.457101]\n",
      "epoch:19 step:18495 [D loss: 0.214908, acc.: 64.06%] [G loss: 0.503448]\n",
      "epoch:19 step:18496 [D loss: 0.217764, acc.: 66.41%] [G loss: 0.473553]\n",
      "epoch:19 step:18497 [D loss: 0.185372, acc.: 72.66%] [G loss: 0.471049]\n",
      "epoch:19 step:18498 [D loss: 0.213247, acc.: 64.06%] [G loss: 0.457082]\n",
      "epoch:19 step:18499 [D loss: 0.270826, acc.: 53.12%] [G loss: 0.438020]\n",
      "epoch:19 step:18500 [D loss: 0.240677, acc.: 62.50%] [G loss: 0.408685]\n",
      "epoch:19 step:18501 [D loss: 0.226449, acc.: 60.94%] [G loss: 0.437217]\n",
      "epoch:19 step:18502 [D loss: 0.214442, acc.: 67.97%] [G loss: 0.429157]\n",
      "epoch:19 step:18503 [D loss: 0.231594, acc.: 66.41%] [G loss: 0.448588]\n",
      "epoch:19 step:18504 [D loss: 0.223053, acc.: 64.84%] [G loss: 0.429969]\n",
      "epoch:19 step:18505 [D loss: 0.244524, acc.: 60.94%] [G loss: 0.445869]\n",
      "epoch:19 step:18506 [D loss: 0.236811, acc.: 58.59%] [G loss: 0.435387]\n",
      "epoch:19 step:18507 [D loss: 0.250344, acc.: 53.12%] [G loss: 0.444664]\n",
      "epoch:19 step:18508 [D loss: 0.223440, acc.: 65.62%] [G loss: 0.429424]\n",
      "epoch:19 step:18509 [D loss: 0.212865, acc.: 62.50%] [G loss: 0.452566]\n",
      "epoch:19 step:18510 [D loss: 0.190806, acc.: 75.78%] [G loss: 0.493672]\n",
      "epoch:19 step:18511 [D loss: 0.204709, acc.: 64.06%] [G loss: 0.441768]\n",
      "epoch:19 step:18512 [D loss: 0.213033, acc.: 67.97%] [G loss: 0.452427]\n",
      "epoch:19 step:18513 [D loss: 0.232951, acc.: 66.41%] [G loss: 0.461234]\n",
      "epoch:19 step:18514 [D loss: 0.242911, acc.: 58.59%] [G loss: 0.417025]\n",
      "epoch:19 step:18515 [D loss: 0.204917, acc.: 67.19%] [G loss: 0.454281]\n",
      "epoch:19 step:18516 [D loss: 0.195864, acc.: 68.75%] [G loss: 0.460379]\n",
      "epoch:19 step:18517 [D loss: 0.213688, acc.: 64.06%] [G loss: 0.435365]\n",
      "epoch:19 step:18518 [D loss: 0.208436, acc.: 68.75%] [G loss: 0.398496]\n",
      "epoch:19 step:18519 [D loss: 0.215875, acc.: 64.06%] [G loss: 0.420533]\n",
      "epoch:19 step:18520 [D loss: 0.225241, acc.: 63.28%] [G loss: 0.425865]\n",
      "epoch:19 step:18521 [D loss: 0.189309, acc.: 77.34%] [G loss: 0.493757]\n",
      "epoch:19 step:18522 [D loss: 0.214751, acc.: 67.19%] [G loss: 0.471537]\n",
      "epoch:19 step:18523 [D loss: 0.219094, acc.: 67.19%] [G loss: 0.423921]\n",
      "epoch:19 step:18524 [D loss: 0.217521, acc.: 57.81%] [G loss: 0.432361]\n",
      "epoch:19 step:18525 [D loss: 0.240134, acc.: 59.38%] [G loss: 0.407425]\n",
      "epoch:19 step:18526 [D loss: 0.209742, acc.: 68.75%] [G loss: 0.452936]\n",
      "epoch:19 step:18527 [D loss: 0.194716, acc.: 71.09%] [G loss: 0.430442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18528 [D loss: 0.216207, acc.: 71.09%] [G loss: 0.446220]\n",
      "epoch:19 step:18529 [D loss: 0.188810, acc.: 71.09%] [G loss: 0.483889]\n",
      "epoch:19 step:18530 [D loss: 0.222773, acc.: 62.50%] [G loss: 0.424085]\n",
      "epoch:19 step:18531 [D loss: 0.241041, acc.: 59.38%] [G loss: 0.412194]\n",
      "epoch:19 step:18532 [D loss: 0.234648, acc.: 57.81%] [G loss: 0.430570]\n",
      "epoch:19 step:18533 [D loss: 0.218936, acc.: 62.50%] [G loss: 0.419444]\n",
      "epoch:19 step:18534 [D loss: 0.223648, acc.: 62.50%] [G loss: 0.460764]\n",
      "epoch:19 step:18535 [D loss: 0.247873, acc.: 58.59%] [G loss: 0.426407]\n",
      "epoch:19 step:18536 [D loss: 0.203394, acc.: 66.41%] [G loss: 0.443755]\n",
      "epoch:19 step:18537 [D loss: 0.251906, acc.: 57.03%] [G loss: 0.407505]\n",
      "epoch:19 step:18538 [D loss: 0.224931, acc.: 64.84%] [G loss: 0.405466]\n",
      "epoch:19 step:18539 [D loss: 0.232601, acc.: 60.16%] [G loss: 0.410204]\n",
      "epoch:19 step:18540 [D loss: 0.212824, acc.: 67.97%] [G loss: 0.437964]\n",
      "epoch:19 step:18541 [D loss: 0.260001, acc.: 51.56%] [G loss: 0.425640]\n",
      "epoch:19 step:18542 [D loss: 0.267934, acc.: 50.00%] [G loss: 0.409097]\n",
      "epoch:19 step:18543 [D loss: 0.237782, acc.: 61.72%] [G loss: 0.420504]\n",
      "epoch:19 step:18544 [D loss: 0.263414, acc.: 53.12%] [G loss: 0.409307]\n",
      "epoch:19 step:18545 [D loss: 0.214672, acc.: 67.19%] [G loss: 0.440991]\n",
      "epoch:19 step:18546 [D loss: 0.208927, acc.: 61.72%] [G loss: 0.444823]\n",
      "epoch:19 step:18547 [D loss: 0.218389, acc.: 67.19%] [G loss: 0.445702]\n",
      "epoch:19 step:18548 [D loss: 0.267826, acc.: 52.34%] [G loss: 0.422104]\n",
      "epoch:19 step:18549 [D loss: 0.213199, acc.: 63.28%] [G loss: 0.438934]\n",
      "epoch:19 step:18550 [D loss: 0.206452, acc.: 65.62%] [G loss: 0.450801]\n",
      "epoch:19 step:18551 [D loss: 0.230087, acc.: 62.50%] [G loss: 0.421830]\n",
      "epoch:19 step:18552 [D loss: 0.238394, acc.: 56.25%] [G loss: 0.407010]\n",
      "epoch:19 step:18553 [D loss: 0.218466, acc.: 60.16%] [G loss: 0.410379]\n",
      "epoch:19 step:18554 [D loss: 0.193317, acc.: 71.88%] [G loss: 0.433238]\n",
      "epoch:19 step:18555 [D loss: 0.245317, acc.: 53.91%] [G loss: 0.430908]\n",
      "epoch:19 step:18556 [D loss: 0.228954, acc.: 60.94%] [G loss: 0.430831]\n",
      "epoch:19 step:18557 [D loss: 0.216311, acc.: 60.16%] [G loss: 0.487808]\n",
      "epoch:19 step:18558 [D loss: 0.230524, acc.: 60.94%] [G loss: 0.492074]\n",
      "epoch:19 step:18559 [D loss: 0.209316, acc.: 70.31%] [G loss: 0.451686]\n",
      "epoch:19 step:18560 [D loss: 0.249237, acc.: 58.59%] [G loss: 0.402740]\n",
      "epoch:19 step:18561 [D loss: 0.251879, acc.: 53.12%] [G loss: 0.395751]\n",
      "epoch:19 step:18562 [D loss: 0.258517, acc.: 50.78%] [G loss: 0.404485]\n",
      "epoch:19 step:18563 [D loss: 0.217393, acc.: 69.53%] [G loss: 0.448634]\n",
      "epoch:19 step:18564 [D loss: 0.241448, acc.: 52.34%] [G loss: 0.443812]\n",
      "epoch:19 step:18565 [D loss: 0.227523, acc.: 60.94%] [G loss: 0.429492]\n",
      "epoch:19 step:18566 [D loss: 0.238646, acc.: 59.38%] [G loss: 0.402590]\n",
      "epoch:19 step:18567 [D loss: 0.212793, acc.: 63.28%] [G loss: 0.449707]\n",
      "epoch:19 step:18568 [D loss: 0.254758, acc.: 56.25%] [G loss: 0.405408]\n",
      "epoch:19 step:18569 [D loss: 0.252419, acc.: 55.47%] [G loss: 0.398374]\n",
      "epoch:19 step:18570 [D loss: 0.205677, acc.: 66.41%] [G loss: 0.449803]\n",
      "epoch:19 step:18571 [D loss: 0.234497, acc.: 67.19%] [G loss: 0.457769]\n",
      "epoch:19 step:18572 [D loss: 0.195346, acc.: 68.75%] [G loss: 0.493318]\n",
      "epoch:19 step:18573 [D loss: 0.243350, acc.: 56.25%] [G loss: 0.481277]\n",
      "epoch:19 step:18574 [D loss: 0.245807, acc.: 53.12%] [G loss: 0.447468]\n",
      "epoch:19 step:18575 [D loss: 0.227979, acc.: 66.41%] [G loss: 0.440183]\n",
      "epoch:19 step:18576 [D loss: 0.216347, acc.: 64.84%] [G loss: 0.446189]\n",
      "epoch:19 step:18577 [D loss: 0.205502, acc.: 73.44%] [G loss: 0.437877]\n",
      "epoch:19 step:18578 [D loss: 0.225624, acc.: 64.84%] [G loss: 0.483797]\n",
      "epoch:19 step:18579 [D loss: 0.231721, acc.: 58.59%] [G loss: 0.469502]\n",
      "epoch:19 step:18580 [D loss: 0.199077, acc.: 74.22%] [G loss: 0.471285]\n",
      "epoch:19 step:18581 [D loss: 0.226529, acc.: 64.06%] [G loss: 0.410325]\n",
      "epoch:19 step:18582 [D loss: 0.217070, acc.: 62.50%] [G loss: 0.430869]\n",
      "epoch:19 step:18583 [D loss: 0.210530, acc.: 69.53%] [G loss: 0.429822]\n",
      "epoch:19 step:18584 [D loss: 0.190588, acc.: 69.53%] [G loss: 0.512747]\n",
      "epoch:19 step:18585 [D loss: 0.202658, acc.: 66.41%] [G loss: 0.479488]\n",
      "epoch:19 step:18586 [D loss: 0.250751, acc.: 54.69%] [G loss: 0.481427]\n",
      "epoch:19 step:18587 [D loss: 0.237434, acc.: 58.59%] [G loss: 0.430376]\n",
      "epoch:19 step:18588 [D loss: 0.207776, acc.: 68.75%] [G loss: 0.425419]\n",
      "epoch:19 step:18589 [D loss: 0.236157, acc.: 62.50%] [G loss: 0.456206]\n",
      "epoch:19 step:18590 [D loss: 0.263887, acc.: 47.66%] [G loss: 0.446943]\n",
      "epoch:19 step:18591 [D loss: 0.250476, acc.: 50.78%] [G loss: 0.430821]\n",
      "epoch:19 step:18592 [D loss: 0.223561, acc.: 58.59%] [G loss: 0.454262]\n",
      "epoch:19 step:18593 [D loss: 0.228529, acc.: 60.16%] [G loss: 0.413796]\n",
      "epoch:19 step:18594 [D loss: 0.270496, acc.: 54.69%] [G loss: 0.440847]\n",
      "epoch:19 step:18595 [D loss: 0.203523, acc.: 71.09%] [G loss: 0.469923]\n",
      "epoch:19 step:18596 [D loss: 0.215595, acc.: 64.06%] [G loss: 0.452364]\n",
      "epoch:19 step:18597 [D loss: 0.270986, acc.: 50.00%] [G loss: 0.422679]\n",
      "epoch:19 step:18598 [D loss: 0.236147, acc.: 62.50%] [G loss: 0.403056]\n",
      "epoch:19 step:18599 [D loss: 0.202057, acc.: 69.53%] [G loss: 0.445609]\n",
      "epoch:19 step:18600 [D loss: 0.248337, acc.: 53.91%] [G loss: 0.453807]\n",
      "epoch:19 step:18601 [D loss: 0.228239, acc.: 60.16%] [G loss: 0.430303]\n",
      "epoch:19 step:18602 [D loss: 0.225594, acc.: 60.16%] [G loss: 0.432559]\n",
      "epoch:19 step:18603 [D loss: 0.251719, acc.: 54.69%] [G loss: 0.419095]\n",
      "epoch:19 step:18604 [D loss: 0.206468, acc.: 66.41%] [G loss: 0.442456]\n",
      "epoch:19 step:18605 [D loss: 0.225994, acc.: 66.41%] [G loss: 0.452550]\n",
      "epoch:19 step:18606 [D loss: 0.201650, acc.: 69.53%] [G loss: 0.447981]\n",
      "epoch:19 step:18607 [D loss: 0.233984, acc.: 59.38%] [G loss: 0.437071]\n",
      "epoch:19 step:18608 [D loss: 0.201523, acc.: 68.75%] [G loss: 0.464719]\n",
      "epoch:19 step:18609 [D loss: 0.215168, acc.: 71.88%] [G loss: 0.434235]\n",
      "epoch:19 step:18610 [D loss: 0.212644, acc.: 64.06%] [G loss: 0.425459]\n",
      "epoch:19 step:18611 [D loss: 0.264601, acc.: 48.44%] [G loss: 0.410433]\n",
      "epoch:19 step:18612 [D loss: 0.240878, acc.: 60.16%] [G loss: 0.396577]\n",
      "epoch:19 step:18613 [D loss: 0.214926, acc.: 65.62%] [G loss: 0.416294]\n",
      "epoch:19 step:18614 [D loss: 0.238143, acc.: 58.59%] [G loss: 0.406971]\n",
      "epoch:19 step:18615 [D loss: 0.254402, acc.: 56.25%] [G loss: 0.445342]\n",
      "epoch:19 step:18616 [D loss: 0.219920, acc.: 62.50%] [G loss: 0.423160]\n",
      "epoch:19 step:18617 [D loss: 0.224567, acc.: 62.50%] [G loss: 0.451647]\n",
      "epoch:19 step:18618 [D loss: 0.202095, acc.: 69.53%] [G loss: 0.497951]\n",
      "epoch:19 step:18619 [D loss: 0.229115, acc.: 60.94%] [G loss: 0.463232]\n",
      "epoch:19 step:18620 [D loss: 0.238840, acc.: 61.72%] [G loss: 0.431871]\n",
      "epoch:19 step:18621 [D loss: 0.260296, acc.: 56.25%] [G loss: 0.407494]\n",
      "epoch:19 step:18622 [D loss: 0.226846, acc.: 66.41%] [G loss: 0.397122]\n",
      "epoch:19 step:18623 [D loss: 0.275822, acc.: 50.00%] [G loss: 0.388436]\n",
      "epoch:19 step:18624 [D loss: 0.224827, acc.: 62.50%] [G loss: 0.395505]\n",
      "epoch:19 step:18625 [D loss: 0.233971, acc.: 59.38%] [G loss: 0.425168]\n",
      "epoch:19 step:18626 [D loss: 0.230147, acc.: 57.03%] [G loss: 0.416762]\n",
      "epoch:19 step:18627 [D loss: 0.218610, acc.: 63.28%] [G loss: 0.442333]\n",
      "epoch:19 step:18628 [D loss: 0.231367, acc.: 57.03%] [G loss: 0.416284]\n",
      "epoch:19 step:18629 [D loss: 0.223590, acc.: 62.50%] [G loss: 0.479922]\n",
      "epoch:19 step:18630 [D loss: 0.245375, acc.: 55.47%] [G loss: 0.429959]\n",
      "epoch:19 step:18631 [D loss: 0.255208, acc.: 57.81%] [G loss: 0.412254]\n",
      "epoch:19 step:18632 [D loss: 0.215611, acc.: 67.19%] [G loss: 0.424869]\n",
      "epoch:19 step:18633 [D loss: 0.232527, acc.: 54.69%] [G loss: 0.388866]\n",
      "epoch:19 step:18634 [D loss: 0.219383, acc.: 64.06%] [G loss: 0.378700]\n",
      "epoch:19 step:18635 [D loss: 0.232333, acc.: 61.72%] [G loss: 0.376821]\n",
      "epoch:19 step:18636 [D loss: 0.200842, acc.: 70.31%] [G loss: 0.418462]\n",
      "epoch:19 step:18637 [D loss: 0.243903, acc.: 59.38%] [G loss: 0.398534]\n",
      "epoch:19 step:18638 [D loss: 0.212187, acc.: 65.62%] [G loss: 0.473494]\n",
      "epoch:19 step:18639 [D loss: 0.224259, acc.: 60.16%] [G loss: 0.422796]\n",
      "epoch:19 step:18640 [D loss: 0.207507, acc.: 62.50%] [G loss: 0.417388]\n",
      "epoch:19 step:18641 [D loss: 0.209138, acc.: 67.19%] [G loss: 0.433931]\n",
      "epoch:19 step:18642 [D loss: 0.212764, acc.: 64.06%] [G loss: 0.457067]\n",
      "epoch:19 step:18643 [D loss: 0.210974, acc.: 66.41%] [G loss: 0.456223]\n",
      "epoch:19 step:18644 [D loss: 0.217930, acc.: 60.94%] [G loss: 0.438999]\n",
      "epoch:19 step:18645 [D loss: 0.188868, acc.: 68.75%] [G loss: 0.426196]\n",
      "epoch:19 step:18646 [D loss: 0.236302, acc.: 63.28%] [G loss: 0.465554]\n",
      "epoch:19 step:18647 [D loss: 0.230444, acc.: 62.50%] [G loss: 0.465601]\n",
      "epoch:19 step:18648 [D loss: 0.216487, acc.: 64.84%] [G loss: 0.485467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18649 [D loss: 0.253894, acc.: 53.12%] [G loss: 0.408215]\n",
      "epoch:19 step:18650 [D loss: 0.237394, acc.: 56.25%] [G loss: 0.407918]\n",
      "epoch:19 step:18651 [D loss: 0.228097, acc.: 64.06%] [G loss: 0.436453]\n",
      "epoch:19 step:18652 [D loss: 0.214063, acc.: 67.97%] [G loss: 0.406853]\n",
      "epoch:19 step:18653 [D loss: 0.236716, acc.: 59.38%] [G loss: 0.438093]\n",
      "epoch:19 step:18654 [D loss: 0.241425, acc.: 54.69%] [G loss: 0.414119]\n",
      "epoch:19 step:18655 [D loss: 0.206769, acc.: 64.84%] [G loss: 0.479272]\n",
      "epoch:19 step:18656 [D loss: 0.230140, acc.: 63.28%] [G loss: 0.426956]\n",
      "epoch:19 step:18657 [D loss: 0.203788, acc.: 68.75%] [G loss: 0.467786]\n",
      "epoch:19 step:18658 [D loss: 0.236883, acc.: 63.28%] [G loss: 0.433969]\n",
      "epoch:19 step:18659 [D loss: 0.251517, acc.: 53.91%] [G loss: 0.458048]\n",
      "epoch:19 step:18660 [D loss: 0.212191, acc.: 65.62%] [G loss: 0.449674]\n",
      "epoch:19 step:18661 [D loss: 0.249852, acc.: 57.03%] [G loss: 0.437886]\n",
      "epoch:19 step:18662 [D loss: 0.250691, acc.: 55.47%] [G loss: 0.431847]\n",
      "epoch:19 step:18663 [D loss: 0.207206, acc.: 68.75%] [G loss: 0.460387]\n",
      "epoch:19 step:18664 [D loss: 0.248473, acc.: 57.81%] [G loss: 0.408382]\n",
      "epoch:19 step:18665 [D loss: 0.234208, acc.: 53.12%] [G loss: 0.404600]\n",
      "epoch:19 step:18666 [D loss: 0.215992, acc.: 61.72%] [G loss: 0.437271]\n",
      "epoch:19 step:18667 [D loss: 0.218528, acc.: 67.19%] [G loss: 0.380205]\n",
      "epoch:19 step:18668 [D loss: 0.241359, acc.: 56.25%] [G loss: 0.384885]\n",
      "epoch:19 step:18669 [D loss: 0.217757, acc.: 61.72%] [G loss: 0.409856]\n",
      "epoch:19 step:18670 [D loss: 0.220312, acc.: 60.94%] [G loss: 0.467074]\n",
      "epoch:19 step:18671 [D loss: 0.234594, acc.: 57.81%] [G loss: 0.451107]\n",
      "epoch:19 step:18672 [D loss: 0.241819, acc.: 57.81%] [G loss: 0.407093]\n",
      "epoch:19 step:18673 [D loss: 0.222963, acc.: 60.94%] [G loss: 0.425441]\n",
      "epoch:19 step:18674 [D loss: 0.228245, acc.: 66.41%] [G loss: 0.432615]\n",
      "epoch:19 step:18675 [D loss: 0.214318, acc.: 66.41%] [G loss: 0.392252]\n",
      "epoch:19 step:18676 [D loss: 0.211097, acc.: 68.75%] [G loss: 0.435715]\n",
      "epoch:19 step:18677 [D loss: 0.218616, acc.: 59.38%] [G loss: 0.388743]\n",
      "epoch:19 step:18678 [D loss: 0.198082, acc.: 72.66%] [G loss: 0.444923]\n",
      "epoch:19 step:18679 [D loss: 0.225405, acc.: 60.16%] [G loss: 0.433650]\n",
      "epoch:19 step:18680 [D loss: 0.235573, acc.: 63.28%] [G loss: 0.427750]\n",
      "epoch:19 step:18681 [D loss: 0.214776, acc.: 65.62%] [G loss: 0.415090]\n",
      "epoch:19 step:18682 [D loss: 0.216316, acc.: 60.16%] [G loss: 0.445617]\n",
      "epoch:19 step:18683 [D loss: 0.253144, acc.: 58.59%] [G loss: 0.417662]\n",
      "epoch:19 step:18684 [D loss: 0.231405, acc.: 59.38%] [G loss: 0.402475]\n",
      "epoch:19 step:18685 [D loss: 0.221403, acc.: 65.62%] [G loss: 0.392033]\n",
      "epoch:19 step:18686 [D loss: 0.219196, acc.: 67.97%] [G loss: 0.426941]\n",
      "epoch:19 step:18687 [D loss: 0.205621, acc.: 64.06%] [G loss: 0.435096]\n",
      "epoch:19 step:18688 [D loss: 0.220792, acc.: 65.62%] [G loss: 0.481395]\n",
      "epoch:19 step:18689 [D loss: 0.193324, acc.: 72.66%] [G loss: 0.496335]\n",
      "epoch:19 step:18690 [D loss: 0.210945, acc.: 62.50%] [G loss: 0.479019]\n",
      "epoch:19 step:18691 [D loss: 0.222592, acc.: 60.16%] [G loss: 0.450246]\n",
      "epoch:19 step:18692 [D loss: 0.210897, acc.: 62.50%] [G loss: 0.436328]\n",
      "epoch:19 step:18693 [D loss: 0.198864, acc.: 71.88%] [G loss: 0.476870]\n",
      "epoch:19 step:18694 [D loss: 0.259244, acc.: 54.69%] [G loss: 0.427338]\n",
      "epoch:19 step:18695 [D loss: 0.254625, acc.: 49.22%] [G loss: 0.428711]\n",
      "epoch:19 step:18696 [D loss: 0.230729, acc.: 60.94%] [G loss: 0.376409]\n",
      "epoch:19 step:18697 [D loss: 0.206781, acc.: 66.41%] [G loss: 0.461261]\n",
      "epoch:19 step:18698 [D loss: 0.225873, acc.: 64.06%] [G loss: 0.444410]\n",
      "epoch:19 step:18699 [D loss: 0.204726, acc.: 72.66%] [G loss: 0.446318]\n",
      "epoch:19 step:18700 [D loss: 0.218080, acc.: 60.16%] [G loss: 0.456827]\n",
      "epoch:19 step:18701 [D loss: 0.197073, acc.: 69.53%] [G loss: 0.465557]\n",
      "epoch:19 step:18702 [D loss: 0.186044, acc.: 68.75%] [G loss: 0.493276]\n",
      "epoch:19 step:18703 [D loss: 0.214982, acc.: 62.50%] [G loss: 0.443011]\n",
      "epoch:19 step:18704 [D loss: 0.236085, acc.: 63.28%] [G loss: 0.471620]\n",
      "epoch:19 step:18705 [D loss: 0.226877, acc.: 61.72%] [G loss: 0.452799]\n",
      "epoch:19 step:18706 [D loss: 0.210964, acc.: 68.75%] [G loss: 0.471518]\n",
      "epoch:19 step:18707 [D loss: 0.230626, acc.: 62.50%] [G loss: 0.400274]\n",
      "epoch:19 step:18708 [D loss: 0.201702, acc.: 71.88%] [G loss: 0.430175]\n",
      "epoch:19 step:18709 [D loss: 0.227584, acc.: 64.84%] [G loss: 0.453542]\n",
      "epoch:19 step:18710 [D loss: 0.223026, acc.: 64.84%] [G loss: 0.476030]\n",
      "epoch:19 step:18711 [D loss: 0.213444, acc.: 69.53%] [G loss: 0.421292]\n",
      "epoch:19 step:18712 [D loss: 0.194680, acc.: 69.53%] [G loss: 0.420644]\n",
      "epoch:19 step:18713 [D loss: 0.245357, acc.: 57.03%] [G loss: 0.409025]\n",
      "epoch:19 step:18714 [D loss: 0.186334, acc.: 75.00%] [G loss: 0.417853]\n",
      "epoch:19 step:18715 [D loss: 0.197950, acc.: 70.31%] [G loss: 0.433790]\n",
      "epoch:19 step:18716 [D loss: 0.234462, acc.: 63.28%] [G loss: 0.437035]\n",
      "epoch:19 step:18717 [D loss: 0.238961, acc.: 60.94%] [G loss: 0.456805]\n",
      "epoch:19 step:18718 [D loss: 0.243193, acc.: 60.16%] [G loss: 0.434383]\n",
      "epoch:19 step:18719 [D loss: 0.248169, acc.: 55.47%] [G loss: 0.428178]\n",
      "epoch:19 step:18720 [D loss: 0.212320, acc.: 65.62%] [G loss: 0.429216]\n",
      "epoch:19 step:18721 [D loss: 0.191148, acc.: 74.22%] [G loss: 0.459459]\n",
      "epoch:19 step:18722 [D loss: 0.206160, acc.: 65.62%] [G loss: 0.468949]\n",
      "epoch:19 step:18723 [D loss: 0.259928, acc.: 57.03%] [G loss: 0.478178]\n",
      "epoch:19 step:18724 [D loss: 0.199853, acc.: 68.75%] [G loss: 0.460761]\n",
      "epoch:19 step:18725 [D loss: 0.301692, acc.: 41.41%] [G loss: 0.377155]\n",
      "epoch:19 step:18726 [D loss: 0.201554, acc.: 67.19%] [G loss: 0.430874]\n",
      "epoch:19 step:18727 [D loss: 0.197847, acc.: 70.31%] [G loss: 0.465675]\n",
      "epoch:19 step:18728 [D loss: 0.182888, acc.: 70.31%] [G loss: 0.532253]\n",
      "epoch:19 step:18729 [D loss: 0.169204, acc.: 80.47%] [G loss: 0.513898]\n",
      "epoch:19 step:18730 [D loss: 0.201410, acc.: 66.41%] [G loss: 0.486170]\n",
      "epoch:19 step:18731 [D loss: 0.328714, acc.: 44.53%] [G loss: 0.526791]\n",
      "epoch:19 step:18732 [D loss: 0.210880, acc.: 62.50%] [G loss: 0.727115]\n",
      "epoch:19 step:18733 [D loss: 0.268339, acc.: 51.56%] [G loss: 0.491511]\n",
      "epoch:19 step:18734 [D loss: 0.247526, acc.: 59.38%] [G loss: 0.401408]\n",
      "epoch:19 step:18735 [D loss: 0.251874, acc.: 60.16%] [G loss: 0.428012]\n",
      "epoch:19 step:18736 [D loss: 0.217622, acc.: 65.62%] [G loss: 0.440986]\n",
      "epoch:19 step:18737 [D loss: 0.197587, acc.: 71.09%] [G loss: 0.438761]\n",
      "epoch:19 step:18738 [D loss: 0.207359, acc.: 67.97%] [G loss: 0.492751]\n",
      "epoch:19 step:18739 [D loss: 0.197055, acc.: 71.88%] [G loss: 0.504149]\n",
      "epoch:19 step:18740 [D loss: 0.171993, acc.: 75.78%] [G loss: 0.546292]\n",
      "epoch:20 step:18741 [D loss: 0.226919, acc.: 64.84%] [G loss: 0.489561]\n",
      "epoch:20 step:18742 [D loss: 0.262152, acc.: 60.16%] [G loss: 0.423073]\n",
      "epoch:20 step:18743 [D loss: 0.240155, acc.: 58.59%] [G loss: 0.458626]\n",
      "epoch:20 step:18744 [D loss: 0.236995, acc.: 63.28%] [G loss: 0.427300]\n",
      "epoch:20 step:18745 [D loss: 0.212171, acc.: 65.62%] [G loss: 0.447252]\n",
      "epoch:20 step:18746 [D loss: 0.243499, acc.: 59.38%] [G loss: 0.472016]\n",
      "epoch:20 step:18747 [D loss: 0.207563, acc.: 65.62%] [G loss: 0.469990]\n",
      "epoch:20 step:18748 [D loss: 0.200298, acc.: 67.97%] [G loss: 0.442476]\n",
      "epoch:20 step:18749 [D loss: 0.200484, acc.: 68.75%] [G loss: 0.446293]\n",
      "epoch:20 step:18750 [D loss: 0.201658, acc.: 67.97%] [G loss: 0.490002]\n",
      "epoch:20 step:18751 [D loss: 0.238340, acc.: 61.72%] [G loss: 0.458733]\n",
      "epoch:20 step:18752 [D loss: 0.216243, acc.: 67.19%] [G loss: 0.491294]\n",
      "epoch:20 step:18753 [D loss: 0.223480, acc.: 64.06%] [G loss: 0.466799]\n",
      "epoch:20 step:18754 [D loss: 0.215351, acc.: 71.09%] [G loss: 0.454517]\n",
      "epoch:20 step:18755 [D loss: 0.186066, acc.: 74.22%] [G loss: 0.436596]\n",
      "epoch:20 step:18756 [D loss: 0.205602, acc.: 66.41%] [G loss: 0.480975]\n",
      "epoch:20 step:18757 [D loss: 0.234922, acc.: 60.94%] [G loss: 0.450512]\n",
      "epoch:20 step:18758 [D loss: 0.218537, acc.: 66.41%] [G loss: 0.492190]\n",
      "epoch:20 step:18759 [D loss: 0.252167, acc.: 58.59%] [G loss: 0.420113]\n",
      "epoch:20 step:18760 [D loss: 0.263481, acc.: 53.12%] [G loss: 0.469981]\n",
      "epoch:20 step:18761 [D loss: 0.217354, acc.: 65.62%] [G loss: 0.467301]\n",
      "epoch:20 step:18762 [D loss: 0.191185, acc.: 75.78%] [G loss: 0.557711]\n",
      "epoch:20 step:18763 [D loss: 0.274151, acc.: 50.78%] [G loss: 0.438982]\n",
      "epoch:20 step:18764 [D loss: 0.198344, acc.: 72.66%] [G loss: 0.427965]\n",
      "epoch:20 step:18765 [D loss: 0.204394, acc.: 72.66%] [G loss: 0.420519]\n",
      "epoch:20 step:18766 [D loss: 0.240494, acc.: 59.38%] [G loss: 0.422150]\n",
      "epoch:20 step:18767 [D loss: 0.218341, acc.: 65.62%] [G loss: 0.431205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18768 [D loss: 0.243836, acc.: 60.16%] [G loss: 0.408157]\n",
      "epoch:20 step:18769 [D loss: 0.203041, acc.: 70.31%] [G loss: 0.447581]\n",
      "epoch:20 step:18770 [D loss: 0.234649, acc.: 58.59%] [G loss: 0.442539]\n",
      "epoch:20 step:18771 [D loss: 0.262962, acc.: 50.00%] [G loss: 0.388606]\n",
      "epoch:20 step:18772 [D loss: 0.226881, acc.: 60.16%] [G loss: 0.468074]\n",
      "epoch:20 step:18773 [D loss: 0.222029, acc.: 60.94%] [G loss: 0.420236]\n",
      "epoch:20 step:18774 [D loss: 0.240940, acc.: 57.81%] [G loss: 0.428636]\n",
      "epoch:20 step:18775 [D loss: 0.211433, acc.: 71.88%] [G loss: 0.470240]\n",
      "epoch:20 step:18776 [D loss: 0.197011, acc.: 69.53%] [G loss: 0.439193]\n",
      "epoch:20 step:18777 [D loss: 0.228344, acc.: 64.06%] [G loss: 0.428359]\n",
      "epoch:20 step:18778 [D loss: 0.267307, acc.: 50.00%] [G loss: 0.393011]\n",
      "epoch:20 step:18779 [D loss: 0.240565, acc.: 57.03%] [G loss: 0.374092]\n",
      "epoch:20 step:18780 [D loss: 0.221569, acc.: 64.06%] [G loss: 0.419693]\n",
      "epoch:20 step:18781 [D loss: 0.231193, acc.: 63.28%] [G loss: 0.444370]\n",
      "epoch:20 step:18782 [D loss: 0.204222, acc.: 68.75%] [G loss: 0.417903]\n",
      "epoch:20 step:18783 [D loss: 0.243687, acc.: 57.81%] [G loss: 0.427913]\n",
      "epoch:20 step:18784 [D loss: 0.222943, acc.: 64.06%] [G loss: 0.453968]\n",
      "epoch:20 step:18785 [D loss: 0.230806, acc.: 57.03%] [G loss: 0.457319]\n",
      "epoch:20 step:18786 [D loss: 0.229397, acc.: 67.19%] [G loss: 0.471038]\n",
      "epoch:20 step:18787 [D loss: 0.236608, acc.: 64.06%] [G loss: 0.393995]\n",
      "epoch:20 step:18788 [D loss: 0.204412, acc.: 67.97%] [G loss: 0.435798]\n",
      "epoch:20 step:18789 [D loss: 0.224590, acc.: 62.50%] [G loss: 0.440289]\n",
      "epoch:20 step:18790 [D loss: 0.225957, acc.: 64.84%] [G loss: 0.463001]\n",
      "epoch:20 step:18791 [D loss: 0.243000, acc.: 53.91%] [G loss: 0.405288]\n",
      "epoch:20 step:18792 [D loss: 0.236618, acc.: 58.59%] [G loss: 0.406070]\n",
      "epoch:20 step:18793 [D loss: 0.198571, acc.: 69.53%] [G loss: 0.441916]\n",
      "epoch:20 step:18794 [D loss: 0.229322, acc.: 59.38%] [G loss: 0.435064]\n",
      "epoch:20 step:18795 [D loss: 0.229053, acc.: 64.06%] [G loss: 0.435260]\n",
      "epoch:20 step:18796 [D loss: 0.213978, acc.: 63.28%] [G loss: 0.458656]\n",
      "epoch:20 step:18797 [D loss: 0.242449, acc.: 64.06%] [G loss: 0.415410]\n",
      "epoch:20 step:18798 [D loss: 0.237153, acc.: 58.59%] [G loss: 0.426780]\n",
      "epoch:20 step:18799 [D loss: 0.207883, acc.: 67.19%] [G loss: 0.442012]\n",
      "epoch:20 step:18800 [D loss: 0.255217, acc.: 57.81%] [G loss: 0.435678]\n",
      "epoch:20 step:18801 [D loss: 0.229765, acc.: 57.81%] [G loss: 0.443541]\n",
      "epoch:20 step:18802 [D loss: 0.252657, acc.: 53.12%] [G loss: 0.439080]\n",
      "epoch:20 step:18803 [D loss: 0.231505, acc.: 64.06%] [G loss: 0.419889]\n",
      "epoch:20 step:18804 [D loss: 0.227893, acc.: 57.81%] [G loss: 0.432144]\n",
      "epoch:20 step:18805 [D loss: 0.229299, acc.: 62.50%] [G loss: 0.409690]\n",
      "epoch:20 step:18806 [D loss: 0.213260, acc.: 64.84%] [G loss: 0.382046]\n",
      "epoch:20 step:18807 [D loss: 0.228939, acc.: 63.28%] [G loss: 0.431455]\n",
      "epoch:20 step:18808 [D loss: 0.216282, acc.: 65.62%] [G loss: 0.454836]\n",
      "epoch:20 step:18809 [D loss: 0.198671, acc.: 68.75%] [G loss: 0.426505]\n",
      "epoch:20 step:18810 [D loss: 0.207843, acc.: 67.97%] [G loss: 0.447136]\n",
      "epoch:20 step:18811 [D loss: 0.235218, acc.: 52.34%] [G loss: 0.470151]\n",
      "epoch:20 step:18812 [D loss: 0.235719, acc.: 62.50%] [G loss: 0.424630]\n",
      "epoch:20 step:18813 [D loss: 0.218013, acc.: 62.50%] [G loss: 0.440573]\n",
      "epoch:20 step:18814 [D loss: 0.198085, acc.: 71.88%] [G loss: 0.452942]\n",
      "epoch:20 step:18815 [D loss: 0.222906, acc.: 63.28%] [G loss: 0.446986]\n",
      "epoch:20 step:18816 [D loss: 0.195433, acc.: 64.84%] [G loss: 0.493706]\n",
      "epoch:20 step:18817 [D loss: 0.186422, acc.: 69.53%] [G loss: 0.495291]\n",
      "epoch:20 step:18818 [D loss: 0.270517, acc.: 56.25%] [G loss: 0.385314]\n",
      "epoch:20 step:18819 [D loss: 0.226950, acc.: 64.84%] [G loss: 0.406820]\n",
      "epoch:20 step:18820 [D loss: 0.213207, acc.: 62.50%] [G loss: 0.396184]\n",
      "epoch:20 step:18821 [D loss: 0.238230, acc.: 58.59%] [G loss: 0.416582]\n",
      "epoch:20 step:18822 [D loss: 0.202999, acc.: 71.09%] [G loss: 0.427495]\n",
      "epoch:20 step:18823 [D loss: 0.206835, acc.: 67.19%] [G loss: 0.490407]\n",
      "epoch:20 step:18824 [D loss: 0.218950, acc.: 65.62%] [G loss: 0.437424]\n",
      "epoch:20 step:18825 [D loss: 0.227616, acc.: 67.19%] [G loss: 0.462905]\n",
      "epoch:20 step:18826 [D loss: 0.230619, acc.: 59.38%] [G loss: 0.416224]\n",
      "epoch:20 step:18827 [D loss: 0.231298, acc.: 60.94%] [G loss: 0.432749]\n",
      "epoch:20 step:18828 [D loss: 0.183012, acc.: 76.56%] [G loss: 0.432102]\n",
      "epoch:20 step:18829 [D loss: 0.223243, acc.: 64.84%] [G loss: 0.424617]\n",
      "epoch:20 step:18830 [D loss: 0.199347, acc.: 71.09%] [G loss: 0.472936]\n",
      "epoch:20 step:18831 [D loss: 0.217810, acc.: 66.41%] [G loss: 0.438069]\n",
      "epoch:20 step:18832 [D loss: 0.231938, acc.: 60.94%] [G loss: 0.485393]\n",
      "epoch:20 step:18833 [D loss: 0.192904, acc.: 74.22%] [G loss: 0.473869]\n",
      "epoch:20 step:18834 [D loss: 0.226558, acc.: 65.62%] [G loss: 0.469089]\n",
      "epoch:20 step:18835 [D loss: 0.209134, acc.: 65.62%] [G loss: 0.456771]\n",
      "epoch:20 step:18836 [D loss: 0.209846, acc.: 64.84%] [G loss: 0.409676]\n",
      "epoch:20 step:18837 [D loss: 0.220173, acc.: 64.84%] [G loss: 0.411856]\n",
      "epoch:20 step:18838 [D loss: 0.197206, acc.: 67.97%] [G loss: 0.470390]\n",
      "epoch:20 step:18839 [D loss: 0.236951, acc.: 61.72%] [G loss: 0.459996]\n",
      "epoch:20 step:18840 [D loss: 0.185411, acc.: 73.44%] [G loss: 0.458607]\n",
      "epoch:20 step:18841 [D loss: 0.249508, acc.: 53.12%] [G loss: 0.411291]\n",
      "epoch:20 step:18842 [D loss: 0.228060, acc.: 60.16%] [G loss: 0.445433]\n",
      "epoch:20 step:18843 [D loss: 0.252470, acc.: 55.47%] [G loss: 0.420418]\n",
      "epoch:20 step:18844 [D loss: 0.249691, acc.: 53.91%] [G loss: 0.419717]\n",
      "epoch:20 step:18845 [D loss: 0.234461, acc.: 60.94%] [G loss: 0.400883]\n",
      "epoch:20 step:18846 [D loss: 0.207137, acc.: 71.09%] [G loss: 0.452161]\n",
      "epoch:20 step:18847 [D loss: 0.195257, acc.: 72.66%] [G loss: 0.465884]\n",
      "epoch:20 step:18848 [D loss: 0.266218, acc.: 52.34%] [G loss: 0.456349]\n",
      "epoch:20 step:18849 [D loss: 0.274152, acc.: 53.12%] [G loss: 0.387140]\n",
      "epoch:20 step:18850 [D loss: 0.233994, acc.: 60.94%] [G loss: 0.394825]\n",
      "epoch:20 step:18851 [D loss: 0.211912, acc.: 63.28%] [G loss: 0.402465]\n",
      "epoch:20 step:18852 [D loss: 0.211492, acc.: 63.28%] [G loss: 0.419947]\n",
      "epoch:20 step:18853 [D loss: 0.218186, acc.: 62.50%] [G loss: 0.473385]\n",
      "epoch:20 step:18854 [D loss: 0.226789, acc.: 66.41%] [G loss: 0.456678]\n",
      "epoch:20 step:18855 [D loss: 0.209509, acc.: 71.09%] [G loss: 0.476982]\n",
      "epoch:20 step:18856 [D loss: 0.218853, acc.: 58.59%] [G loss: 0.453228]\n",
      "epoch:20 step:18857 [D loss: 0.204618, acc.: 67.19%] [G loss: 0.477936]\n",
      "epoch:20 step:18858 [D loss: 0.206672, acc.: 67.97%] [G loss: 0.489886]\n",
      "epoch:20 step:18859 [D loss: 0.184238, acc.: 74.22%] [G loss: 0.500299]\n",
      "epoch:20 step:18860 [D loss: 0.258995, acc.: 60.94%] [G loss: 0.446181]\n",
      "epoch:20 step:18861 [D loss: 0.246023, acc.: 57.03%] [G loss: 0.446155]\n",
      "epoch:20 step:18862 [D loss: 0.203166, acc.: 71.88%] [G loss: 0.459021]\n",
      "epoch:20 step:18863 [D loss: 0.221425, acc.: 64.06%] [G loss: 0.467734]\n",
      "epoch:20 step:18864 [D loss: 0.246858, acc.: 56.25%] [G loss: 0.406150]\n",
      "epoch:20 step:18865 [D loss: 0.244115, acc.: 60.16%] [G loss: 0.401637]\n",
      "epoch:20 step:18866 [D loss: 0.206619, acc.: 66.41%] [G loss: 0.442122]\n",
      "epoch:20 step:18867 [D loss: 0.196624, acc.: 67.19%] [G loss: 0.463079]\n",
      "epoch:20 step:18868 [D loss: 0.251128, acc.: 51.56%] [G loss: 0.448000]\n",
      "epoch:20 step:18869 [D loss: 0.232564, acc.: 60.94%] [G loss: 0.426115]\n",
      "epoch:20 step:18870 [D loss: 0.222336, acc.: 61.72%] [G loss: 0.401183]\n",
      "epoch:20 step:18871 [D loss: 0.215649, acc.: 62.50%] [G loss: 0.398102]\n",
      "epoch:20 step:18872 [D loss: 0.226189, acc.: 60.94%] [G loss: 0.418049]\n",
      "epoch:20 step:18873 [D loss: 0.264992, acc.: 56.25%] [G loss: 0.446368]\n",
      "epoch:20 step:18874 [D loss: 0.221937, acc.: 64.06%] [G loss: 0.533685]\n",
      "epoch:20 step:18875 [D loss: 0.216229, acc.: 67.97%] [G loss: 0.471743]\n",
      "epoch:20 step:18876 [D loss: 0.223644, acc.: 66.41%] [G loss: 0.412265]\n",
      "epoch:20 step:18877 [D loss: 0.254562, acc.: 57.03%] [G loss: 0.370645]\n",
      "epoch:20 step:18878 [D loss: 0.247001, acc.: 51.56%] [G loss: 0.374431]\n",
      "epoch:20 step:18879 [D loss: 0.218209, acc.: 66.41%] [G loss: 0.445633]\n",
      "epoch:20 step:18880 [D loss: 0.208138, acc.: 67.97%] [G loss: 0.437417]\n",
      "epoch:20 step:18881 [D loss: 0.215089, acc.: 70.31%] [G loss: 0.483827]\n",
      "epoch:20 step:18882 [D loss: 0.218893, acc.: 59.38%] [G loss: 0.408627]\n",
      "epoch:20 step:18883 [D loss: 0.237459, acc.: 57.81%] [G loss: 0.369759]\n",
      "epoch:20 step:18884 [D loss: 0.194367, acc.: 71.09%] [G loss: 0.450412]\n",
      "epoch:20 step:18885 [D loss: 0.245063, acc.: 60.16%] [G loss: 0.394371]\n",
      "epoch:20 step:18886 [D loss: 0.231957, acc.: 58.59%] [G loss: 0.427519]\n",
      "epoch:20 step:18887 [D loss: 0.236700, acc.: 59.38%] [G loss: 0.415563]\n",
      "epoch:20 step:18888 [D loss: 0.240904, acc.: 56.25%] [G loss: 0.417384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18889 [D loss: 0.217320, acc.: 63.28%] [G loss: 0.448657]\n",
      "epoch:20 step:18890 [D loss: 0.243349, acc.: 59.38%] [G loss: 0.429585]\n",
      "epoch:20 step:18891 [D loss: 0.201344, acc.: 64.06%] [G loss: 0.408650]\n",
      "epoch:20 step:18892 [D loss: 0.215470, acc.: 67.97%] [G loss: 0.480132]\n",
      "epoch:20 step:18893 [D loss: 0.224717, acc.: 60.94%] [G loss: 0.412576]\n",
      "epoch:20 step:18894 [D loss: 0.228001, acc.: 60.16%] [G loss: 0.407456]\n",
      "epoch:20 step:18895 [D loss: 0.195445, acc.: 71.09%] [G loss: 0.433579]\n",
      "epoch:20 step:18896 [D loss: 0.201579, acc.: 68.75%] [G loss: 0.430969]\n",
      "epoch:20 step:18897 [D loss: 0.207744, acc.: 64.84%] [G loss: 0.421130]\n",
      "epoch:20 step:18898 [D loss: 0.235138, acc.: 60.16%] [G loss: 0.429255]\n",
      "epoch:20 step:18899 [D loss: 0.215509, acc.: 66.41%] [G loss: 0.431494]\n",
      "epoch:20 step:18900 [D loss: 0.269023, acc.: 51.56%] [G loss: 0.411646]\n",
      "epoch:20 step:18901 [D loss: 0.249186, acc.: 55.47%] [G loss: 0.451024]\n",
      "epoch:20 step:18902 [D loss: 0.237213, acc.: 60.94%] [G loss: 0.400320]\n",
      "epoch:20 step:18903 [D loss: 0.227866, acc.: 58.59%] [G loss: 0.409794]\n",
      "epoch:20 step:18904 [D loss: 0.238143, acc.: 66.41%] [G loss: 0.376241]\n",
      "epoch:20 step:18905 [D loss: 0.221775, acc.: 60.94%] [G loss: 0.416971]\n",
      "epoch:20 step:18906 [D loss: 0.232937, acc.: 62.50%] [G loss: 0.425233]\n",
      "epoch:20 step:18907 [D loss: 0.216385, acc.: 60.94%] [G loss: 0.422795]\n",
      "epoch:20 step:18908 [D loss: 0.202008, acc.: 71.09%] [G loss: 0.401531]\n",
      "epoch:20 step:18909 [D loss: 0.238179, acc.: 60.94%] [G loss: 0.412156]\n",
      "epoch:20 step:18910 [D loss: 0.239809, acc.: 62.50%] [G loss: 0.419880]\n",
      "epoch:20 step:18911 [D loss: 0.216860, acc.: 71.09%] [G loss: 0.428821]\n",
      "epoch:20 step:18912 [D loss: 0.209918, acc.: 62.50%] [G loss: 0.446503]\n",
      "epoch:20 step:18913 [D loss: 0.192770, acc.: 76.56%] [G loss: 0.493131]\n",
      "epoch:20 step:18914 [D loss: 0.262342, acc.: 50.78%] [G loss: 0.400692]\n",
      "epoch:20 step:18915 [D loss: 0.239464, acc.: 61.72%] [G loss: 0.426876]\n",
      "epoch:20 step:18916 [D loss: 0.244632, acc.: 57.03%] [G loss: 0.417438]\n",
      "epoch:20 step:18917 [D loss: 0.231194, acc.: 61.72%] [G loss: 0.416791]\n",
      "epoch:20 step:18918 [D loss: 0.207716, acc.: 60.94%] [G loss: 0.436663]\n",
      "epoch:20 step:18919 [D loss: 0.210101, acc.: 72.66%] [G loss: 0.409640]\n",
      "epoch:20 step:18920 [D loss: 0.232996, acc.: 57.81%] [G loss: 0.419963]\n",
      "epoch:20 step:18921 [D loss: 0.217788, acc.: 59.38%] [G loss: 0.414998]\n",
      "epoch:20 step:18922 [D loss: 0.225607, acc.: 55.47%] [G loss: 0.443943]\n",
      "epoch:20 step:18923 [D loss: 0.229378, acc.: 62.50%] [G loss: 0.410432]\n",
      "epoch:20 step:18924 [D loss: 0.216836, acc.: 64.84%] [G loss: 0.395359]\n",
      "epoch:20 step:18925 [D loss: 0.223022, acc.: 66.41%] [G loss: 0.412006]\n",
      "epoch:20 step:18926 [D loss: 0.218402, acc.: 66.41%] [G loss: 0.452385]\n",
      "epoch:20 step:18927 [D loss: 0.244695, acc.: 54.69%] [G loss: 0.445575]\n",
      "epoch:20 step:18928 [D loss: 0.244371, acc.: 58.59%] [G loss: 0.404350]\n",
      "epoch:20 step:18929 [D loss: 0.245074, acc.: 57.81%] [G loss: 0.424172]\n",
      "epoch:20 step:18930 [D loss: 0.224592, acc.: 61.72%] [G loss: 0.440277]\n",
      "epoch:20 step:18931 [D loss: 0.191052, acc.: 74.22%] [G loss: 0.474272]\n",
      "epoch:20 step:18932 [D loss: 0.208134, acc.: 69.53%] [G loss: 0.444109]\n",
      "epoch:20 step:18933 [D loss: 0.224527, acc.: 66.41%] [G loss: 0.433639]\n",
      "epoch:20 step:18934 [D loss: 0.219783, acc.: 63.28%] [G loss: 0.445813]\n",
      "epoch:20 step:18935 [D loss: 0.232660, acc.: 65.62%] [G loss: 0.462551]\n",
      "epoch:20 step:18936 [D loss: 0.243929, acc.: 61.72%] [G loss: 0.443340]\n",
      "epoch:20 step:18937 [D loss: 0.201293, acc.: 72.66%] [G loss: 0.445902]\n",
      "epoch:20 step:18938 [D loss: 0.199163, acc.: 72.66%] [G loss: 0.446942]\n",
      "epoch:20 step:18939 [D loss: 0.221649, acc.: 60.94%] [G loss: 0.430067]\n",
      "epoch:20 step:18940 [D loss: 0.241513, acc.: 60.16%] [G loss: 0.441457]\n",
      "epoch:20 step:18941 [D loss: 0.239116, acc.: 58.59%] [G loss: 0.454704]\n",
      "epoch:20 step:18942 [D loss: 0.232902, acc.: 58.59%] [G loss: 0.443004]\n",
      "epoch:20 step:18943 [D loss: 0.261153, acc.: 54.69%] [G loss: 0.460418]\n",
      "epoch:20 step:18944 [D loss: 0.237116, acc.: 60.94%] [G loss: 0.440702]\n",
      "epoch:20 step:18945 [D loss: 0.239318, acc.: 58.59%] [G loss: 0.435688]\n",
      "epoch:20 step:18946 [D loss: 0.209823, acc.: 65.62%] [G loss: 0.433803]\n",
      "epoch:20 step:18947 [D loss: 0.217983, acc.: 64.84%] [G loss: 0.417287]\n",
      "epoch:20 step:18948 [D loss: 0.188560, acc.: 71.09%] [G loss: 0.474043]\n",
      "epoch:20 step:18949 [D loss: 0.214573, acc.: 71.09%] [G loss: 0.453289]\n",
      "epoch:20 step:18950 [D loss: 0.258793, acc.: 52.34%] [G loss: 0.438363]\n",
      "epoch:20 step:18951 [D loss: 0.239122, acc.: 59.38%] [G loss: 0.413446]\n",
      "epoch:20 step:18952 [D loss: 0.254913, acc.: 61.72%] [G loss: 0.415528]\n",
      "epoch:20 step:18953 [D loss: 0.212639, acc.: 66.41%] [G loss: 0.419815]\n",
      "epoch:20 step:18954 [D loss: 0.249970, acc.: 57.81%] [G loss: 0.382843]\n",
      "epoch:20 step:18955 [D loss: 0.234555, acc.: 58.59%] [G loss: 0.389135]\n",
      "epoch:20 step:18956 [D loss: 0.208240, acc.: 64.84%] [G loss: 0.417998]\n",
      "epoch:20 step:18957 [D loss: 0.212535, acc.: 67.97%] [G loss: 0.433843]\n",
      "epoch:20 step:18958 [D loss: 0.186575, acc.: 72.66%] [G loss: 0.479951]\n",
      "epoch:20 step:18959 [D loss: 0.214450, acc.: 70.31%] [G loss: 0.503201]\n",
      "epoch:20 step:18960 [D loss: 0.281725, acc.: 53.12%] [G loss: 0.441798]\n",
      "epoch:20 step:18961 [D loss: 0.218566, acc.: 64.06%] [G loss: 0.453520]\n",
      "epoch:20 step:18962 [D loss: 0.204703, acc.: 68.75%] [G loss: 0.490556]\n",
      "epoch:20 step:18963 [D loss: 0.188860, acc.: 69.53%] [G loss: 0.483864]\n",
      "epoch:20 step:18964 [D loss: 0.256010, acc.: 55.47%] [G loss: 0.375078]\n",
      "epoch:20 step:18965 [D loss: 0.217406, acc.: 64.84%] [G loss: 0.431731]\n",
      "epoch:20 step:18966 [D loss: 0.224136, acc.: 64.06%] [G loss: 0.404835]\n",
      "epoch:20 step:18967 [D loss: 0.229936, acc.: 67.19%] [G loss: 0.430801]\n",
      "epoch:20 step:18968 [D loss: 0.229553, acc.: 61.72%] [G loss: 0.404034]\n",
      "epoch:20 step:18969 [D loss: 0.211357, acc.: 67.19%] [G loss: 0.442783]\n",
      "epoch:20 step:18970 [D loss: 0.197048, acc.: 70.31%] [G loss: 0.504087]\n",
      "epoch:20 step:18971 [D loss: 0.186107, acc.: 73.44%] [G loss: 0.509796]\n",
      "epoch:20 step:18972 [D loss: 0.166614, acc.: 72.66%] [G loss: 0.515994]\n",
      "epoch:20 step:18973 [D loss: 0.246774, acc.: 62.50%] [G loss: 0.471660]\n",
      "epoch:20 step:18974 [D loss: 0.253753, acc.: 56.25%] [G loss: 0.420584]\n",
      "epoch:20 step:18975 [D loss: 0.226803, acc.: 59.38%] [G loss: 0.432400]\n",
      "epoch:20 step:18976 [D loss: 0.203355, acc.: 71.09%] [G loss: 0.421525]\n",
      "epoch:20 step:18977 [D loss: 0.233998, acc.: 62.50%] [G loss: 0.426835]\n",
      "epoch:20 step:18978 [D loss: 0.217403, acc.: 66.41%] [G loss: 0.396244]\n",
      "epoch:20 step:18979 [D loss: 0.216376, acc.: 62.50%] [G loss: 0.406829]\n",
      "epoch:20 step:18980 [D loss: 0.219365, acc.: 67.19%] [G loss: 0.423892]\n",
      "epoch:20 step:18981 [D loss: 0.182053, acc.: 72.66%] [G loss: 0.481472]\n",
      "epoch:20 step:18982 [D loss: 0.211346, acc.: 71.09%] [G loss: 0.445417]\n",
      "epoch:20 step:18983 [D loss: 0.226874, acc.: 59.38%] [G loss: 0.466351]\n",
      "epoch:20 step:18984 [D loss: 0.197641, acc.: 70.31%] [G loss: 0.462879]\n",
      "epoch:20 step:18985 [D loss: 0.222713, acc.: 63.28%] [G loss: 0.449995]\n",
      "epoch:20 step:18986 [D loss: 0.228919, acc.: 57.81%] [G loss: 0.458483]\n",
      "epoch:20 step:18987 [D loss: 0.246895, acc.: 52.34%] [G loss: 0.446271]\n",
      "epoch:20 step:18988 [D loss: 0.203505, acc.: 68.75%] [G loss: 0.489322]\n",
      "epoch:20 step:18989 [D loss: 0.268414, acc.: 51.56%] [G loss: 0.431037]\n",
      "epoch:20 step:18990 [D loss: 0.261870, acc.: 51.56%] [G loss: 0.405747]\n",
      "epoch:20 step:18991 [D loss: 0.273416, acc.: 50.00%] [G loss: 0.426431]\n",
      "epoch:20 step:18992 [D loss: 0.217319, acc.: 62.50%] [G loss: 0.432578]\n",
      "epoch:20 step:18993 [D loss: 0.221112, acc.: 63.28%] [G loss: 0.464780]\n",
      "epoch:20 step:18994 [D loss: 0.252314, acc.: 52.34%] [G loss: 0.368498]\n",
      "epoch:20 step:18995 [D loss: 0.211355, acc.: 67.97%] [G loss: 0.418571]\n",
      "epoch:20 step:18996 [D loss: 0.228387, acc.: 62.50%] [G loss: 0.439391]\n",
      "epoch:20 step:18997 [D loss: 0.218683, acc.: 62.50%] [G loss: 0.413426]\n",
      "epoch:20 step:18998 [D loss: 0.211840, acc.: 64.84%] [G loss: 0.410030]\n",
      "epoch:20 step:18999 [D loss: 0.217906, acc.: 67.97%] [G loss: 0.414133]\n",
      "epoch:20 step:19000 [D loss: 0.230055, acc.: 57.03%] [G loss: 0.420724]\n",
      "epoch:20 step:19001 [D loss: 0.206984, acc.: 67.19%] [G loss: 0.459272]\n",
      "epoch:20 step:19002 [D loss: 0.215860, acc.: 64.06%] [G loss: 0.416577]\n",
      "epoch:20 step:19003 [D loss: 0.228390, acc.: 63.28%] [G loss: 0.441139]\n",
      "epoch:20 step:19004 [D loss: 0.192361, acc.: 69.53%] [G loss: 0.450428]\n",
      "epoch:20 step:19005 [D loss: 0.248858, acc.: 53.12%] [G loss: 0.404101]\n",
      "epoch:20 step:19006 [D loss: 0.238618, acc.: 57.03%] [G loss: 0.431188]\n",
      "epoch:20 step:19007 [D loss: 0.231956, acc.: 62.50%] [G loss: 0.450488]\n",
      "epoch:20 step:19008 [D loss: 0.234417, acc.: 55.47%] [G loss: 0.412104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19009 [D loss: 0.224118, acc.: 57.81%] [G loss: 0.403756]\n",
      "epoch:20 step:19010 [D loss: 0.219674, acc.: 62.50%] [G loss: 0.461822]\n",
      "epoch:20 step:19011 [D loss: 0.199761, acc.: 63.28%] [G loss: 0.447299]\n",
      "epoch:20 step:19012 [D loss: 0.222451, acc.: 69.53%] [G loss: 0.454050]\n",
      "epoch:20 step:19013 [D loss: 0.230669, acc.: 62.50%] [G loss: 0.406478]\n",
      "epoch:20 step:19014 [D loss: 0.192841, acc.: 72.66%] [G loss: 0.465192]\n",
      "epoch:20 step:19015 [D loss: 0.212125, acc.: 65.62%] [G loss: 0.427249]\n",
      "epoch:20 step:19016 [D loss: 0.203583, acc.: 65.62%] [G loss: 0.473228]\n",
      "epoch:20 step:19017 [D loss: 0.250677, acc.: 54.69%] [G loss: 0.441774]\n",
      "epoch:20 step:19018 [D loss: 0.239497, acc.: 61.72%] [G loss: 0.431680]\n",
      "epoch:20 step:19019 [D loss: 0.232985, acc.: 59.38%] [G loss: 0.428576]\n",
      "epoch:20 step:19020 [D loss: 0.188610, acc.: 70.31%] [G loss: 0.455259]\n",
      "epoch:20 step:19021 [D loss: 0.250705, acc.: 52.34%] [G loss: 0.403398]\n",
      "epoch:20 step:19022 [D loss: 0.219745, acc.: 67.19%] [G loss: 0.436407]\n",
      "epoch:20 step:19023 [D loss: 0.211828, acc.: 67.97%] [G loss: 0.404004]\n",
      "epoch:20 step:19024 [D loss: 0.195730, acc.: 75.78%] [G loss: 0.443218]\n",
      "epoch:20 step:19025 [D loss: 0.246095, acc.: 55.47%] [G loss: 0.400824]\n",
      "epoch:20 step:19026 [D loss: 0.227300, acc.: 63.28%] [G loss: 0.414370]\n",
      "epoch:20 step:19027 [D loss: 0.248357, acc.: 58.59%] [G loss: 0.450515]\n",
      "epoch:20 step:19028 [D loss: 0.216939, acc.: 59.38%] [G loss: 0.496166]\n",
      "epoch:20 step:19029 [D loss: 0.214974, acc.: 70.31%] [G loss: 0.460022]\n",
      "epoch:20 step:19030 [D loss: 0.214678, acc.: 64.84%] [G loss: 0.466240]\n",
      "epoch:20 step:19031 [D loss: 0.243040, acc.: 58.59%] [G loss: 0.390585]\n",
      "epoch:20 step:19032 [D loss: 0.238194, acc.: 62.50%] [G loss: 0.402176]\n",
      "epoch:20 step:19033 [D loss: 0.215082, acc.: 64.06%] [G loss: 0.439271]\n",
      "epoch:20 step:19034 [D loss: 0.235406, acc.: 53.12%] [G loss: 0.401428]\n",
      "epoch:20 step:19035 [D loss: 0.238106, acc.: 56.25%] [G loss: 0.428598]\n",
      "epoch:20 step:19036 [D loss: 0.212535, acc.: 66.41%] [G loss: 0.413286]\n",
      "epoch:20 step:19037 [D loss: 0.218716, acc.: 63.28%] [G loss: 0.435586]\n",
      "epoch:20 step:19038 [D loss: 0.180471, acc.: 73.44%] [G loss: 0.466105]\n",
      "epoch:20 step:19039 [D loss: 0.200827, acc.: 65.62%] [G loss: 0.443632]\n",
      "epoch:20 step:19040 [D loss: 0.198806, acc.: 69.53%] [G loss: 0.475384]\n",
      "epoch:20 step:19041 [D loss: 0.255955, acc.: 55.47%] [G loss: 0.427241]\n",
      "epoch:20 step:19042 [D loss: 0.231888, acc.: 64.06%] [G loss: 0.405003]\n",
      "epoch:20 step:19043 [D loss: 0.221883, acc.: 67.19%] [G loss: 0.471281]\n",
      "epoch:20 step:19044 [D loss: 0.218582, acc.: 61.72%] [G loss: 0.481068]\n",
      "epoch:20 step:19045 [D loss: 0.240790, acc.: 60.94%] [G loss: 0.422254]\n",
      "epoch:20 step:19046 [D loss: 0.209139, acc.: 64.84%] [G loss: 0.460142]\n",
      "epoch:20 step:19047 [D loss: 0.195500, acc.: 74.22%] [G loss: 0.418113]\n",
      "epoch:20 step:19048 [D loss: 0.238979, acc.: 54.69%] [G loss: 0.452099]\n",
      "epoch:20 step:19049 [D loss: 0.211630, acc.: 60.94%] [G loss: 0.444150]\n",
      "epoch:20 step:19050 [D loss: 0.224532, acc.: 64.06%] [G loss: 0.431492]\n",
      "epoch:20 step:19051 [D loss: 0.211788, acc.: 70.31%] [G loss: 0.489879]\n",
      "epoch:20 step:19052 [D loss: 0.178157, acc.: 74.22%] [G loss: 0.456951]\n",
      "epoch:20 step:19053 [D loss: 0.183357, acc.: 71.88%] [G loss: 0.516445]\n",
      "epoch:20 step:19054 [D loss: 0.174518, acc.: 76.56%] [G loss: 0.483492]\n",
      "epoch:20 step:19055 [D loss: 0.195717, acc.: 70.31%] [G loss: 0.494932]\n",
      "epoch:20 step:19056 [D loss: 0.264185, acc.: 56.25%] [G loss: 0.399361]\n",
      "epoch:20 step:19057 [D loss: 0.235610, acc.: 60.16%] [G loss: 0.402570]\n",
      "epoch:20 step:19058 [D loss: 0.222487, acc.: 55.47%] [G loss: 0.427824]\n",
      "epoch:20 step:19059 [D loss: 0.229006, acc.: 66.41%] [G loss: 0.427228]\n",
      "epoch:20 step:19060 [D loss: 0.214675, acc.: 63.28%] [G loss: 0.458683]\n",
      "epoch:20 step:19061 [D loss: 0.202743, acc.: 71.88%] [G loss: 0.444149]\n",
      "epoch:20 step:19062 [D loss: 0.212593, acc.: 67.19%] [G loss: 0.453097]\n",
      "epoch:20 step:19063 [D loss: 0.222594, acc.: 65.62%] [G loss: 0.495898]\n",
      "epoch:20 step:19064 [D loss: 0.209874, acc.: 70.31%] [G loss: 0.435910]\n",
      "epoch:20 step:19065 [D loss: 0.209883, acc.: 67.97%] [G loss: 0.423019]\n",
      "epoch:20 step:19066 [D loss: 0.215278, acc.: 64.84%] [G loss: 0.445866]\n",
      "epoch:20 step:19067 [D loss: 0.213411, acc.: 66.41%] [G loss: 0.490965]\n",
      "epoch:20 step:19068 [D loss: 0.213178, acc.: 60.94%] [G loss: 0.464102]\n",
      "epoch:20 step:19069 [D loss: 0.223164, acc.: 60.94%] [G loss: 0.433796]\n",
      "epoch:20 step:19070 [D loss: 0.232374, acc.: 64.06%] [G loss: 0.414669]\n",
      "epoch:20 step:19071 [D loss: 0.224338, acc.: 67.19%] [G loss: 0.397915]\n",
      "epoch:20 step:19072 [D loss: 0.224633, acc.: 58.59%] [G loss: 0.450285]\n",
      "epoch:20 step:19073 [D loss: 0.206009, acc.: 67.97%] [G loss: 0.474191]\n",
      "epoch:20 step:19074 [D loss: 0.231610, acc.: 61.72%] [G loss: 0.449346]\n",
      "epoch:20 step:19075 [D loss: 0.229680, acc.: 63.28%] [G loss: 0.425087]\n",
      "epoch:20 step:19076 [D loss: 0.212019, acc.: 66.41%] [G loss: 0.486207]\n",
      "epoch:20 step:19077 [D loss: 0.224488, acc.: 65.62%] [G loss: 0.454419]\n",
      "epoch:20 step:19078 [D loss: 0.179012, acc.: 71.88%] [G loss: 0.447811]\n",
      "epoch:20 step:19079 [D loss: 0.225450, acc.: 62.50%] [G loss: 0.454217]\n",
      "epoch:20 step:19080 [D loss: 0.230926, acc.: 61.72%] [G loss: 0.469215]\n",
      "epoch:20 step:19081 [D loss: 0.280677, acc.: 50.78%] [G loss: 0.471777]\n",
      "epoch:20 step:19082 [D loss: 0.249429, acc.: 52.34%] [G loss: 0.514749]\n",
      "epoch:20 step:19083 [D loss: 0.202104, acc.: 67.97%] [G loss: 0.498120]\n",
      "epoch:20 step:19084 [D loss: 0.199181, acc.: 69.53%] [G loss: 0.499997]\n",
      "epoch:20 step:19085 [D loss: 0.205071, acc.: 67.97%] [G loss: 0.463113]\n",
      "epoch:20 step:19086 [D loss: 0.188497, acc.: 71.88%] [G loss: 0.509917]\n",
      "epoch:20 step:19087 [D loss: 0.160247, acc.: 75.78%] [G loss: 0.584795]\n",
      "epoch:20 step:19088 [D loss: 0.297773, acc.: 53.12%] [G loss: 0.417399]\n",
      "epoch:20 step:19089 [D loss: 0.273087, acc.: 52.34%] [G loss: 0.404233]\n",
      "epoch:20 step:19090 [D loss: 0.211722, acc.: 67.97%] [G loss: 0.439201]\n",
      "epoch:20 step:19091 [D loss: 0.214867, acc.: 65.62%] [G loss: 0.432966]\n",
      "epoch:20 step:19092 [D loss: 0.235476, acc.: 64.06%] [G loss: 0.392949]\n",
      "epoch:20 step:19093 [D loss: 0.204795, acc.: 66.41%] [G loss: 0.419760]\n",
      "epoch:20 step:19094 [D loss: 0.208427, acc.: 68.75%] [G loss: 0.460936]\n",
      "epoch:20 step:19095 [D loss: 0.228766, acc.: 67.19%] [G loss: 0.454163]\n",
      "epoch:20 step:19096 [D loss: 0.231247, acc.: 64.06%] [G loss: 0.423660]\n",
      "epoch:20 step:19097 [D loss: 0.197172, acc.: 71.09%] [G loss: 0.424171]\n",
      "epoch:20 step:19098 [D loss: 0.214970, acc.: 64.84%] [G loss: 0.429580]\n",
      "epoch:20 step:19099 [D loss: 0.210476, acc.: 63.28%] [G loss: 0.433203]\n",
      "epoch:20 step:19100 [D loss: 0.216495, acc.: 64.06%] [G loss: 0.453932]\n",
      "epoch:20 step:19101 [D loss: 0.194612, acc.: 74.22%] [G loss: 0.472378]\n",
      "epoch:20 step:19102 [D loss: 0.236136, acc.: 62.50%] [G loss: 0.440924]\n",
      "epoch:20 step:19103 [D loss: 0.242481, acc.: 60.16%] [G loss: 0.403566]\n",
      "epoch:20 step:19104 [D loss: 0.211236, acc.: 64.84%] [G loss: 0.430081]\n",
      "epoch:20 step:19105 [D loss: 0.224246, acc.: 62.50%] [G loss: 0.410743]\n",
      "epoch:20 step:19106 [D loss: 0.215280, acc.: 64.06%] [G loss: 0.413808]\n",
      "epoch:20 step:19107 [D loss: 0.235293, acc.: 62.50%] [G loss: 0.444908]\n",
      "epoch:20 step:19108 [D loss: 0.229798, acc.: 60.16%] [G loss: 0.426445]\n",
      "epoch:20 step:19109 [D loss: 0.227920, acc.: 62.50%] [G loss: 0.436706]\n",
      "epoch:20 step:19110 [D loss: 0.211424, acc.: 67.19%] [G loss: 0.429251]\n",
      "epoch:20 step:19111 [D loss: 0.194375, acc.: 72.66%] [G loss: 0.422534]\n",
      "epoch:20 step:19112 [D loss: 0.224290, acc.: 60.94%] [G loss: 0.428596]\n",
      "epoch:20 step:19113 [D loss: 0.255315, acc.: 59.38%] [G loss: 0.397266]\n",
      "epoch:20 step:19114 [D loss: 0.183988, acc.: 75.78%] [G loss: 0.468770]\n",
      "epoch:20 step:19115 [D loss: 0.229559, acc.: 65.62%] [G loss: 0.439138]\n",
      "epoch:20 step:19116 [D loss: 0.254530, acc.: 54.69%] [G loss: 0.450041]\n",
      "epoch:20 step:19117 [D loss: 0.246903, acc.: 54.69%] [G loss: 0.418172]\n",
      "epoch:20 step:19118 [D loss: 0.219024, acc.: 64.84%] [G loss: 0.442281]\n",
      "epoch:20 step:19119 [D loss: 0.224318, acc.: 62.50%] [G loss: 0.448545]\n",
      "epoch:20 step:19120 [D loss: 0.246576, acc.: 57.81%] [G loss: 0.417777]\n",
      "epoch:20 step:19121 [D loss: 0.213352, acc.: 65.62%] [G loss: 0.409832]\n",
      "epoch:20 step:19122 [D loss: 0.209373, acc.: 67.97%] [G loss: 0.444386]\n",
      "epoch:20 step:19123 [D loss: 0.238504, acc.: 58.59%] [G loss: 0.445785]\n",
      "epoch:20 step:19124 [D loss: 0.208206, acc.: 67.19%] [G loss: 0.454661]\n",
      "epoch:20 step:19125 [D loss: 0.175776, acc.: 71.88%] [G loss: 0.441839]\n",
      "epoch:20 step:19126 [D loss: 0.236348, acc.: 55.47%] [G loss: 0.430478]\n",
      "epoch:20 step:19127 [D loss: 0.224677, acc.: 62.50%] [G loss: 0.448323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19128 [D loss: 0.215733, acc.: 67.19%] [G loss: 0.499007]\n",
      "epoch:20 step:19129 [D loss: 0.209667, acc.: 70.31%] [G loss: 0.445755]\n",
      "epoch:20 step:19130 [D loss: 0.235197, acc.: 61.72%] [G loss: 0.416957]\n",
      "epoch:20 step:19131 [D loss: 0.227205, acc.: 60.16%] [G loss: 0.410340]\n",
      "epoch:20 step:19132 [D loss: 0.214462, acc.: 66.41%] [G loss: 0.445625]\n",
      "epoch:20 step:19133 [D loss: 0.225017, acc.: 63.28%] [G loss: 0.464792]\n",
      "epoch:20 step:19134 [D loss: 0.231373, acc.: 66.41%] [G loss: 0.407728]\n",
      "epoch:20 step:19135 [D loss: 0.221435, acc.: 62.50%] [G loss: 0.467082]\n",
      "epoch:20 step:19136 [D loss: 0.251128, acc.: 53.12%] [G loss: 0.436003]\n",
      "epoch:20 step:19137 [D loss: 0.231885, acc.: 58.59%] [G loss: 0.417835]\n",
      "epoch:20 step:19138 [D loss: 0.186003, acc.: 75.00%] [G loss: 0.489627]\n",
      "epoch:20 step:19139 [D loss: 0.225614, acc.: 68.75%] [G loss: 0.456796]\n",
      "epoch:20 step:19140 [D loss: 0.283389, acc.: 50.78%] [G loss: 0.409729]\n",
      "epoch:20 step:19141 [D loss: 0.238075, acc.: 53.91%] [G loss: 0.402688]\n",
      "epoch:20 step:19142 [D loss: 0.224326, acc.: 66.41%] [G loss: 0.420958]\n",
      "epoch:20 step:19143 [D loss: 0.224132, acc.: 64.84%] [G loss: 0.452460]\n",
      "epoch:20 step:19144 [D loss: 0.233304, acc.: 61.72%] [G loss: 0.438421]\n",
      "epoch:20 step:19145 [D loss: 0.182070, acc.: 75.00%] [G loss: 0.526578]\n",
      "epoch:20 step:19146 [D loss: 0.189629, acc.: 71.09%] [G loss: 0.488611]\n",
      "epoch:20 step:19147 [D loss: 0.224609, acc.: 64.06%] [G loss: 0.474612]\n",
      "epoch:20 step:19148 [D loss: 0.256078, acc.: 58.59%] [G loss: 0.425396]\n",
      "epoch:20 step:19149 [D loss: 0.222017, acc.: 68.75%] [G loss: 0.478285]\n",
      "epoch:20 step:19150 [D loss: 0.235604, acc.: 53.91%] [G loss: 0.438634]\n",
      "epoch:20 step:19151 [D loss: 0.258837, acc.: 53.12%] [G loss: 0.437645]\n",
      "epoch:20 step:19152 [D loss: 0.250283, acc.: 54.69%] [G loss: 0.420198]\n",
      "epoch:20 step:19153 [D loss: 0.242524, acc.: 59.38%] [G loss: 0.415059]\n",
      "epoch:20 step:19154 [D loss: 0.218493, acc.: 63.28%] [G loss: 0.489048]\n",
      "epoch:20 step:19155 [D loss: 0.212834, acc.: 62.50%] [G loss: 0.488157]\n",
      "epoch:20 step:19156 [D loss: 0.180188, acc.: 78.91%] [G loss: 0.518814]\n",
      "epoch:20 step:19157 [D loss: 0.233899, acc.: 59.38%] [G loss: 0.437510]\n",
      "epoch:20 step:19158 [D loss: 0.270931, acc.: 57.03%] [G loss: 0.399362]\n",
      "epoch:20 step:19159 [D loss: 0.267557, acc.: 48.44%] [G loss: 0.391919]\n",
      "epoch:20 step:19160 [D loss: 0.220374, acc.: 64.06%] [G loss: 0.451550]\n",
      "epoch:20 step:19161 [D loss: 0.228585, acc.: 64.84%] [G loss: 0.422491]\n",
      "epoch:20 step:19162 [D loss: 0.254175, acc.: 49.22%] [G loss: 0.412117]\n",
      "epoch:20 step:19163 [D loss: 0.227599, acc.: 60.94%] [G loss: 0.446222]\n",
      "epoch:20 step:19164 [D loss: 0.229568, acc.: 64.06%] [G loss: 0.411728]\n",
      "epoch:20 step:19165 [D loss: 0.231767, acc.: 63.28%] [G loss: 0.384973]\n",
      "epoch:20 step:19166 [D loss: 0.207237, acc.: 68.75%] [G loss: 0.468106]\n",
      "epoch:20 step:19167 [D loss: 0.182846, acc.: 78.12%] [G loss: 0.484298]\n",
      "epoch:20 step:19168 [D loss: 0.214180, acc.: 64.84%] [G loss: 0.458906]\n",
      "epoch:20 step:19169 [D loss: 0.194923, acc.: 71.09%] [G loss: 0.466653]\n",
      "epoch:20 step:19170 [D loss: 0.184554, acc.: 69.53%] [G loss: 0.482751]\n",
      "epoch:20 step:19171 [D loss: 0.219655, acc.: 64.84%] [G loss: 0.476240]\n",
      "epoch:20 step:19172 [D loss: 0.233932, acc.: 57.81%] [G loss: 0.424730]\n",
      "epoch:20 step:19173 [D loss: 0.224528, acc.: 60.94%] [G loss: 0.426975]\n",
      "epoch:20 step:19174 [D loss: 0.228562, acc.: 58.59%] [G loss: 0.419976]\n",
      "epoch:20 step:19175 [D loss: 0.236476, acc.: 62.50%] [G loss: 0.449583]\n",
      "epoch:20 step:19176 [D loss: 0.200855, acc.: 70.31%] [G loss: 0.517925]\n",
      "epoch:20 step:19177 [D loss: 0.272175, acc.: 52.34%] [G loss: 0.457335]\n",
      "epoch:20 step:19178 [D loss: 0.246526, acc.: 60.16%] [G loss: 0.402373]\n",
      "epoch:20 step:19179 [D loss: 0.236756, acc.: 58.59%] [G loss: 0.417106]\n",
      "epoch:20 step:19180 [D loss: 0.209100, acc.: 65.62%] [G loss: 0.434246]\n",
      "epoch:20 step:19181 [D loss: 0.228619, acc.: 58.59%] [G loss: 0.436177]\n",
      "epoch:20 step:19182 [D loss: 0.236287, acc.: 60.94%] [G loss: 0.419500]\n",
      "epoch:20 step:19183 [D loss: 0.253378, acc.: 60.16%] [G loss: 0.434990]\n",
      "epoch:20 step:19184 [D loss: 0.235483, acc.: 60.94%] [G loss: 0.435082]\n",
      "epoch:20 step:19185 [D loss: 0.213956, acc.: 64.06%] [G loss: 0.492346]\n",
      "epoch:20 step:19186 [D loss: 0.241009, acc.: 56.25%] [G loss: 0.453502]\n",
      "epoch:20 step:19187 [D loss: 0.237564, acc.: 60.94%] [G loss: 0.403586]\n",
      "epoch:20 step:19188 [D loss: 0.217522, acc.: 65.62%] [G loss: 0.494846]\n",
      "epoch:20 step:19189 [D loss: 0.209310, acc.: 63.28%] [G loss: 0.464734]\n",
      "epoch:20 step:19190 [D loss: 0.218120, acc.: 64.84%] [G loss: 0.423895]\n",
      "epoch:20 step:19191 [D loss: 0.204274, acc.: 68.75%] [G loss: 0.445828]\n",
      "epoch:20 step:19192 [D loss: 0.202846, acc.: 67.97%] [G loss: 0.466181]\n",
      "epoch:20 step:19193 [D loss: 0.198095, acc.: 64.06%] [G loss: 0.461540]\n",
      "epoch:20 step:19194 [D loss: 0.228146, acc.: 63.28%] [G loss: 0.445556]\n",
      "epoch:20 step:19195 [D loss: 0.216405, acc.: 67.97%] [G loss: 0.421770]\n",
      "epoch:20 step:19196 [D loss: 0.206293, acc.: 65.62%] [G loss: 0.476907]\n",
      "epoch:20 step:19197 [D loss: 0.246502, acc.: 52.34%] [G loss: 0.468928]\n",
      "epoch:20 step:19198 [D loss: 0.294738, acc.: 51.56%] [G loss: 0.450963]\n",
      "epoch:20 step:19199 [D loss: 0.242908, acc.: 54.69%] [G loss: 0.439352]\n",
      "epoch:20 step:19200 [D loss: 0.237941, acc.: 63.28%] [G loss: 0.397053]\n",
      "epoch:20 step:19201 [D loss: 0.245044, acc.: 53.91%] [G loss: 0.417457]\n",
      "epoch:20 step:19202 [D loss: 0.258306, acc.: 50.78%] [G loss: 0.387260]\n",
      "epoch:20 step:19203 [D loss: 0.218029, acc.: 64.06%] [G loss: 0.427221]\n",
      "epoch:20 step:19204 [D loss: 0.211602, acc.: 67.19%] [G loss: 0.420226]\n",
      "epoch:20 step:19205 [D loss: 0.227857, acc.: 60.94%] [G loss: 0.409098]\n",
      "epoch:20 step:19206 [D loss: 0.225115, acc.: 62.50%] [G loss: 0.388076]\n",
      "epoch:20 step:19207 [D loss: 0.225090, acc.: 62.50%] [G loss: 0.483403]\n",
      "epoch:20 step:19208 [D loss: 0.214857, acc.: 66.41%] [G loss: 0.435978]\n",
      "epoch:20 step:19209 [D loss: 0.208871, acc.: 67.97%] [G loss: 0.461065]\n",
      "epoch:20 step:19210 [D loss: 0.220123, acc.: 65.62%] [G loss: 0.524587]\n",
      "epoch:20 step:19211 [D loss: 0.179983, acc.: 73.44%] [G loss: 0.493617]\n",
      "epoch:20 step:19212 [D loss: 0.213454, acc.: 70.31%] [G loss: 0.466381]\n",
      "epoch:20 step:19213 [D loss: 0.267446, acc.: 55.47%] [G loss: 0.432417]\n",
      "epoch:20 step:19214 [D loss: 0.206853, acc.: 67.97%] [G loss: 0.488572]\n",
      "epoch:20 step:19215 [D loss: 0.217292, acc.: 60.16%] [G loss: 0.472080]\n",
      "epoch:20 step:19216 [D loss: 0.212194, acc.: 70.31%] [G loss: 0.491612]\n",
      "epoch:20 step:19217 [D loss: 0.273488, acc.: 50.00%] [G loss: 0.394964]\n",
      "epoch:20 step:19218 [D loss: 0.259149, acc.: 59.38%] [G loss: 0.399030]\n",
      "epoch:20 step:19219 [D loss: 0.203542, acc.: 73.44%] [G loss: 0.432196]\n",
      "epoch:20 step:19220 [D loss: 0.225938, acc.: 64.84%] [G loss: 0.455593]\n",
      "epoch:20 step:19221 [D loss: 0.183063, acc.: 78.12%] [G loss: 0.485903]\n",
      "epoch:20 step:19222 [D loss: 0.272053, acc.: 48.44%] [G loss: 0.425860]\n",
      "epoch:20 step:19223 [D loss: 0.224136, acc.: 62.50%] [G loss: 0.439216]\n",
      "epoch:20 step:19224 [D loss: 0.194656, acc.: 69.53%] [G loss: 0.460558]\n",
      "epoch:20 step:19225 [D loss: 0.214676, acc.: 66.41%] [G loss: 0.429545]\n",
      "epoch:20 step:19226 [D loss: 0.253199, acc.: 56.25%] [G loss: 0.428669]\n",
      "epoch:20 step:19227 [D loss: 0.227306, acc.: 62.50%] [G loss: 0.433658]\n",
      "epoch:20 step:19228 [D loss: 0.203451, acc.: 71.88%] [G loss: 0.403494]\n",
      "epoch:20 step:19229 [D loss: 0.256675, acc.: 57.03%] [G loss: 0.424094]\n",
      "epoch:20 step:19230 [D loss: 0.229570, acc.: 65.62%] [G loss: 0.436280]\n",
      "epoch:20 step:19231 [D loss: 0.225571, acc.: 64.06%] [G loss: 0.439436]\n",
      "epoch:20 step:19232 [D loss: 0.229602, acc.: 57.03%] [G loss: 0.425380]\n",
      "epoch:20 step:19233 [D loss: 0.209796, acc.: 66.41%] [G loss: 0.435412]\n",
      "epoch:20 step:19234 [D loss: 0.230444, acc.: 56.25%] [G loss: 0.443878]\n",
      "epoch:20 step:19235 [D loss: 0.177750, acc.: 78.12%] [G loss: 0.470926]\n",
      "epoch:20 step:19236 [D loss: 0.201641, acc.: 68.75%] [G loss: 0.455080]\n",
      "epoch:20 step:19237 [D loss: 0.232019, acc.: 57.81%] [G loss: 0.474692]\n",
      "epoch:20 step:19238 [D loss: 0.200308, acc.: 70.31%] [G loss: 0.450196]\n",
      "epoch:20 step:19239 [D loss: 0.197744, acc.: 73.44%] [G loss: 0.499532]\n",
      "epoch:20 step:19240 [D loss: 0.243817, acc.: 61.72%] [G loss: 0.452865]\n",
      "epoch:20 step:19241 [D loss: 0.282502, acc.: 46.88%] [G loss: 0.431149]\n",
      "epoch:20 step:19242 [D loss: 0.219879, acc.: 63.28%] [G loss: 0.427010]\n",
      "epoch:20 step:19243 [D loss: 0.206061, acc.: 71.09%] [G loss: 0.429689]\n",
      "epoch:20 step:19244 [D loss: 0.216044, acc.: 65.62%] [G loss: 0.427393]\n",
      "epoch:20 step:19245 [D loss: 0.200662, acc.: 66.41%] [G loss: 0.526897]\n",
      "epoch:20 step:19246 [D loss: 0.214526, acc.: 61.72%] [G loss: 0.486642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19247 [D loss: 0.215503, acc.: 60.94%] [G loss: 0.436430]\n",
      "epoch:20 step:19248 [D loss: 0.202633, acc.: 64.84%] [G loss: 0.489108]\n",
      "epoch:20 step:19249 [D loss: 0.219714, acc.: 69.53%] [G loss: 0.432210]\n",
      "epoch:20 step:19250 [D loss: 0.236131, acc.: 60.94%] [G loss: 0.466293]\n",
      "epoch:20 step:19251 [D loss: 0.242749, acc.: 54.69%] [G loss: 0.420432]\n",
      "epoch:20 step:19252 [D loss: 0.230946, acc.: 60.16%] [G loss: 0.424941]\n",
      "epoch:20 step:19253 [D loss: 0.175732, acc.: 73.44%] [G loss: 0.448206]\n",
      "epoch:20 step:19254 [D loss: 0.214094, acc.: 64.84%] [G loss: 0.445298]\n",
      "epoch:20 step:19255 [D loss: 0.215049, acc.: 65.62%] [G loss: 0.430166]\n",
      "epoch:20 step:19256 [D loss: 0.214208, acc.: 63.28%] [G loss: 0.473656]\n",
      "epoch:20 step:19257 [D loss: 0.232224, acc.: 64.84%] [G loss: 0.405497]\n",
      "epoch:20 step:19258 [D loss: 0.248277, acc.: 60.16%] [G loss: 0.407194]\n",
      "epoch:20 step:19259 [D loss: 0.210021, acc.: 68.75%] [G loss: 0.464931]\n",
      "epoch:20 step:19260 [D loss: 0.199699, acc.: 70.31%] [G loss: 0.476900]\n",
      "epoch:20 step:19261 [D loss: 0.199832, acc.: 68.75%] [G loss: 0.455761]\n",
      "epoch:20 step:19262 [D loss: 0.204731, acc.: 67.97%] [G loss: 0.465011]\n",
      "epoch:20 step:19263 [D loss: 0.214155, acc.: 67.97%] [G loss: 0.434169]\n",
      "epoch:20 step:19264 [D loss: 0.219984, acc.: 67.19%] [G loss: 0.521865]\n",
      "epoch:20 step:19265 [D loss: 0.231010, acc.: 61.72%] [G loss: 0.456407]\n",
      "epoch:20 step:19266 [D loss: 0.209530, acc.: 67.19%] [G loss: 0.464599]\n",
      "epoch:20 step:19267 [D loss: 0.215598, acc.: 60.94%] [G loss: 0.441264]\n",
      "epoch:20 step:19268 [D loss: 0.274188, acc.: 52.34%] [G loss: 0.410531]\n",
      "epoch:20 step:19269 [D loss: 0.234669, acc.: 62.50%] [G loss: 0.413501]\n",
      "epoch:20 step:19270 [D loss: 0.230564, acc.: 61.72%] [G loss: 0.432459]\n",
      "epoch:20 step:19271 [D loss: 0.252383, acc.: 57.81%] [G loss: 0.408461]\n",
      "epoch:20 step:19272 [D loss: 0.212859, acc.: 64.06%] [G loss: 0.420617]\n",
      "epoch:20 step:19273 [D loss: 0.219428, acc.: 66.41%] [G loss: 0.441717]\n",
      "epoch:20 step:19274 [D loss: 0.186572, acc.: 69.53%] [G loss: 0.452772]\n",
      "epoch:20 step:19275 [D loss: 0.228377, acc.: 57.81%] [G loss: 0.416125]\n",
      "epoch:20 step:19276 [D loss: 0.217239, acc.: 67.19%] [G loss: 0.459244]\n",
      "epoch:20 step:19277 [D loss: 0.241889, acc.: 58.59%] [G loss: 0.422505]\n",
      "epoch:20 step:19278 [D loss: 0.239686, acc.: 56.25%] [G loss: 0.443067]\n",
      "epoch:20 step:19279 [D loss: 0.208357, acc.: 67.97%] [G loss: 0.449722]\n",
      "epoch:20 step:19280 [D loss: 0.229243, acc.: 63.28%] [G loss: 0.404758]\n",
      "epoch:20 step:19281 [D loss: 0.246932, acc.: 57.03%] [G loss: 0.410722]\n",
      "epoch:20 step:19282 [D loss: 0.242674, acc.: 57.03%] [G loss: 0.436006]\n",
      "epoch:20 step:19283 [D loss: 0.221068, acc.: 63.28%] [G loss: 0.434795]\n",
      "epoch:20 step:19284 [D loss: 0.221351, acc.: 60.16%] [G loss: 0.405133]\n",
      "epoch:20 step:19285 [D loss: 0.216752, acc.: 63.28%] [G loss: 0.416164]\n",
      "epoch:20 step:19286 [D loss: 0.228454, acc.: 61.72%] [G loss: 0.427243]\n",
      "epoch:20 step:19287 [D loss: 0.203025, acc.: 66.41%] [G loss: 0.477745]\n",
      "epoch:20 step:19288 [D loss: 0.203391, acc.: 65.62%] [G loss: 0.434330]\n",
      "epoch:20 step:19289 [D loss: 0.200817, acc.: 67.97%] [G loss: 0.436801]\n",
      "epoch:20 step:19290 [D loss: 0.210732, acc.: 64.84%] [G loss: 0.423033]\n",
      "epoch:20 step:19291 [D loss: 0.196657, acc.: 73.44%] [G loss: 0.476207]\n",
      "epoch:20 step:19292 [D loss: 0.210728, acc.: 67.19%] [G loss: 0.446060]\n",
      "epoch:20 step:19293 [D loss: 0.233575, acc.: 61.72%] [G loss: 0.432824]\n",
      "epoch:20 step:19294 [D loss: 0.225220, acc.: 60.94%] [G loss: 0.428520]\n",
      "epoch:20 step:19295 [D loss: 0.213531, acc.: 64.84%] [G loss: 0.446622]\n",
      "epoch:20 step:19296 [D loss: 0.230444, acc.: 64.06%] [G loss: 0.438798]\n",
      "epoch:20 step:19297 [D loss: 0.212480, acc.: 69.53%] [G loss: 0.457240]\n",
      "epoch:20 step:19298 [D loss: 0.220235, acc.: 63.28%] [G loss: 0.446085]\n",
      "epoch:20 step:19299 [D loss: 0.244226, acc.: 61.72%] [G loss: 0.448334]\n",
      "epoch:20 step:19300 [D loss: 0.249611, acc.: 53.12%] [G loss: 0.424287]\n",
      "epoch:20 step:19301 [D loss: 0.210799, acc.: 67.19%] [G loss: 0.475849]\n",
      "epoch:20 step:19302 [D loss: 0.227811, acc.: 59.38%] [G loss: 0.444247]\n",
      "epoch:20 step:19303 [D loss: 0.205142, acc.: 67.97%] [G loss: 0.430354]\n",
      "epoch:20 step:19304 [D loss: 0.191679, acc.: 71.88%] [G loss: 0.494771]\n",
      "epoch:20 step:19305 [D loss: 0.239959, acc.: 59.38%] [G loss: 0.452145]\n",
      "epoch:20 step:19306 [D loss: 0.253208, acc.: 59.38%] [G loss: 0.456207]\n",
      "epoch:20 step:19307 [D loss: 0.202527, acc.: 66.41%] [G loss: 0.514670]\n",
      "epoch:20 step:19308 [D loss: 0.222041, acc.: 63.28%] [G loss: 0.432967]\n",
      "epoch:20 step:19309 [D loss: 0.273278, acc.: 54.69%] [G loss: 0.390608]\n",
      "epoch:20 step:19310 [D loss: 0.210153, acc.: 70.31%] [G loss: 0.462562]\n",
      "epoch:20 step:19311 [D loss: 0.183433, acc.: 75.00%] [G loss: 0.469171]\n",
      "epoch:20 step:19312 [D loss: 0.235352, acc.: 64.06%] [G loss: 0.432923]\n",
      "epoch:20 step:19313 [D loss: 0.230984, acc.: 62.50%] [G loss: 0.461643]\n",
      "epoch:20 step:19314 [D loss: 0.179892, acc.: 76.56%] [G loss: 0.482316]\n",
      "epoch:20 step:19315 [D loss: 0.200332, acc.: 67.97%] [G loss: 0.500789]\n",
      "epoch:20 step:19316 [D loss: 0.233451, acc.: 59.38%] [G loss: 0.492932]\n",
      "epoch:20 step:19317 [D loss: 0.222368, acc.: 65.62%] [G loss: 0.434417]\n",
      "epoch:20 step:19318 [D loss: 0.249888, acc.: 55.47%] [G loss: 0.427267]\n",
      "epoch:20 step:19319 [D loss: 0.242955, acc.: 58.59%] [G loss: 0.404955]\n",
      "epoch:20 step:19320 [D loss: 0.235055, acc.: 64.84%] [G loss: 0.417109]\n",
      "epoch:20 step:19321 [D loss: 0.196448, acc.: 67.97%] [G loss: 0.439394]\n",
      "epoch:20 step:19322 [D loss: 0.194298, acc.: 71.09%] [G loss: 0.471259]\n",
      "epoch:20 step:19323 [D loss: 0.222353, acc.: 62.50%] [G loss: 0.463944]\n",
      "epoch:20 step:19324 [D loss: 0.223764, acc.: 63.28%] [G loss: 0.468046]\n",
      "epoch:20 step:19325 [D loss: 0.220518, acc.: 60.16%] [G loss: 0.432895]\n",
      "epoch:20 step:19326 [D loss: 0.219162, acc.: 60.94%] [G loss: 0.466646]\n",
      "epoch:20 step:19327 [D loss: 0.251595, acc.: 49.22%] [G loss: 0.414074]\n",
      "epoch:20 step:19328 [D loss: 0.225668, acc.: 64.06%] [G loss: 0.390916]\n",
      "epoch:20 step:19329 [D loss: 0.211159, acc.: 64.84%] [G loss: 0.440549]\n",
      "epoch:20 step:19330 [D loss: 0.225480, acc.: 61.72%] [G loss: 0.454401]\n",
      "epoch:20 step:19331 [D loss: 0.234845, acc.: 60.16%] [G loss: 0.417589]\n",
      "epoch:20 step:19332 [D loss: 0.205564, acc.: 66.41%] [G loss: 0.405292]\n",
      "epoch:20 step:19333 [D loss: 0.214834, acc.: 65.62%] [G loss: 0.411253]\n",
      "epoch:20 step:19334 [D loss: 0.214100, acc.: 63.28%] [G loss: 0.467382]\n",
      "epoch:20 step:19335 [D loss: 0.205296, acc.: 75.00%] [G loss: 0.430536]\n",
      "epoch:20 step:19336 [D loss: 0.217753, acc.: 64.06%] [G loss: 0.430193]\n",
      "epoch:20 step:19337 [D loss: 0.232888, acc.: 58.59%] [G loss: 0.451678]\n",
      "epoch:20 step:19338 [D loss: 0.218781, acc.: 65.62%] [G loss: 0.431622]\n",
      "epoch:20 step:19339 [D loss: 0.204491, acc.: 69.53%] [G loss: 0.428649]\n",
      "epoch:20 step:19340 [D loss: 0.239664, acc.: 59.38%] [G loss: 0.405246]\n",
      "epoch:20 step:19341 [D loss: 0.222094, acc.: 64.06%] [G loss: 0.423599]\n",
      "epoch:20 step:19342 [D loss: 0.228370, acc.: 64.84%] [G loss: 0.433283]\n",
      "epoch:20 step:19343 [D loss: 0.225318, acc.: 64.06%] [G loss: 0.442564]\n",
      "epoch:20 step:19344 [D loss: 0.215594, acc.: 66.41%] [G loss: 0.453644]\n",
      "epoch:20 step:19345 [D loss: 0.221058, acc.: 61.72%] [G loss: 0.416979]\n",
      "epoch:20 step:19346 [D loss: 0.227337, acc.: 60.16%] [G loss: 0.426579]\n",
      "epoch:20 step:19347 [D loss: 0.215527, acc.: 63.28%] [G loss: 0.439345]\n",
      "epoch:20 step:19348 [D loss: 0.210934, acc.: 66.41%] [G loss: 0.462074]\n",
      "epoch:20 step:19349 [D loss: 0.231084, acc.: 61.72%] [G loss: 0.411584]\n",
      "epoch:20 step:19350 [D loss: 0.227164, acc.: 63.28%] [G loss: 0.369665]\n",
      "epoch:20 step:19351 [D loss: 0.219480, acc.: 62.50%] [G loss: 0.400010]\n",
      "epoch:20 step:19352 [D loss: 0.217748, acc.: 64.06%] [G loss: 0.424942]\n",
      "epoch:20 step:19353 [D loss: 0.202998, acc.: 71.88%] [G loss: 0.396473]\n",
      "epoch:20 step:19354 [D loss: 0.250287, acc.: 54.69%] [G loss: 0.398809]\n",
      "epoch:20 step:19355 [D loss: 0.243811, acc.: 50.78%] [G loss: 0.402795]\n",
      "epoch:20 step:19356 [D loss: 0.229491, acc.: 64.84%] [G loss: 0.392920]\n",
      "epoch:20 step:19357 [D loss: 0.216280, acc.: 68.75%] [G loss: 0.435600]\n",
      "epoch:20 step:19358 [D loss: 0.223061, acc.: 66.41%] [G loss: 0.446167]\n",
      "epoch:20 step:19359 [D loss: 0.249980, acc.: 54.69%] [G loss: 0.434685]\n",
      "epoch:20 step:19360 [D loss: 0.210769, acc.: 71.09%] [G loss: 0.436599]\n",
      "epoch:20 step:19361 [D loss: 0.232904, acc.: 57.81%] [G loss: 0.437757]\n",
      "epoch:20 step:19362 [D loss: 0.240373, acc.: 58.59%] [G loss: 0.454573]\n",
      "epoch:20 step:19363 [D loss: 0.222375, acc.: 63.28%] [G loss: 0.419103]\n",
      "epoch:20 step:19364 [D loss: 0.213250, acc.: 67.97%] [G loss: 0.415874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19365 [D loss: 0.227565, acc.: 62.50%] [G loss: 0.434920]\n",
      "epoch:20 step:19366 [D loss: 0.242208, acc.: 56.25%] [G loss: 0.429374]\n",
      "epoch:20 step:19367 [D loss: 0.218707, acc.: 61.72%] [G loss: 0.414239]\n",
      "epoch:20 step:19368 [D loss: 0.219928, acc.: 60.16%] [G loss: 0.442853]\n",
      "epoch:20 step:19369 [D loss: 0.229967, acc.: 63.28%] [G loss: 0.408150]\n",
      "epoch:20 step:19370 [D loss: 0.228767, acc.: 61.72%] [G loss: 0.440010]\n",
      "epoch:20 step:19371 [D loss: 0.192768, acc.: 70.31%] [G loss: 0.459921]\n",
      "epoch:20 step:19372 [D loss: 0.219448, acc.: 67.19%] [G loss: 0.438692]\n",
      "epoch:20 step:19373 [D loss: 0.241590, acc.: 61.72%] [G loss: 0.451877]\n",
      "epoch:20 step:19374 [D loss: 0.189283, acc.: 72.66%] [G loss: 0.490333]\n",
      "epoch:20 step:19375 [D loss: 0.208200, acc.: 66.41%] [G loss: 0.448449]\n",
      "epoch:20 step:19376 [D loss: 0.214953, acc.: 62.50%] [G loss: 0.439404]\n",
      "epoch:20 step:19377 [D loss: 0.212963, acc.: 69.53%] [G loss: 0.430166]\n",
      "epoch:20 step:19378 [D loss: 0.223651, acc.: 64.06%] [G loss: 0.412772]\n",
      "epoch:20 step:19379 [D loss: 0.227032, acc.: 55.47%] [G loss: 0.425480]\n",
      "epoch:20 step:19380 [D loss: 0.193179, acc.: 69.53%] [G loss: 0.459654]\n",
      "epoch:20 step:19381 [D loss: 0.207923, acc.: 65.62%] [G loss: 0.459201]\n",
      "epoch:20 step:19382 [D loss: 0.181205, acc.: 76.56%] [G loss: 0.515292]\n",
      "epoch:20 step:19383 [D loss: 0.246023, acc.: 60.94%] [G loss: 0.471164]\n",
      "epoch:20 step:19384 [D loss: 0.252472, acc.: 51.56%] [G loss: 0.425096]\n",
      "epoch:20 step:19385 [D loss: 0.211735, acc.: 66.41%] [G loss: 0.428121]\n",
      "epoch:20 step:19386 [D loss: 0.224460, acc.: 60.16%] [G loss: 0.466119]\n",
      "epoch:20 step:19387 [D loss: 0.211652, acc.: 67.97%] [G loss: 0.491360]\n",
      "epoch:20 step:19388 [D loss: 0.183561, acc.: 74.22%] [G loss: 0.518491]\n",
      "epoch:20 step:19389 [D loss: 0.224131, acc.: 64.84%] [G loss: 0.480997]\n",
      "epoch:20 step:19390 [D loss: 0.179789, acc.: 72.66%] [G loss: 0.518959]\n",
      "epoch:20 step:19391 [D loss: 0.234187, acc.: 60.16%] [G loss: 0.445043]\n",
      "epoch:20 step:19392 [D loss: 0.226304, acc.: 66.41%] [G loss: 0.428882]\n",
      "epoch:20 step:19393 [D loss: 0.213127, acc.: 66.41%] [G loss: 0.434795]\n",
      "epoch:20 step:19394 [D loss: 0.194003, acc.: 67.97%] [G loss: 0.465226]\n",
      "epoch:20 step:19395 [D loss: 0.242191, acc.: 53.12%] [G loss: 0.457307]\n",
      "epoch:20 step:19396 [D loss: 0.250228, acc.: 58.59%] [G loss: 0.427846]\n",
      "epoch:20 step:19397 [D loss: 0.230431, acc.: 63.28%] [G loss: 0.479849]\n",
      "epoch:20 step:19398 [D loss: 0.233564, acc.: 58.59%] [G loss: 0.455445]\n",
      "epoch:20 step:19399 [D loss: 0.241116, acc.: 57.03%] [G loss: 0.429910]\n",
      "epoch:20 step:19400 [D loss: 0.211929, acc.: 66.41%] [G loss: 0.449051]\n",
      "epoch:20 step:19401 [D loss: 0.213126, acc.: 64.84%] [G loss: 0.451041]\n",
      "epoch:20 step:19402 [D loss: 0.213145, acc.: 64.84%] [G loss: 0.429014]\n",
      "epoch:20 step:19403 [D loss: 0.213047, acc.: 64.06%] [G loss: 0.422618]\n",
      "epoch:20 step:19404 [D loss: 0.238100, acc.: 54.69%] [G loss: 0.444901]\n",
      "epoch:20 step:19405 [D loss: 0.226644, acc.: 60.94%] [G loss: 0.422881]\n",
      "epoch:20 step:19406 [D loss: 0.218440, acc.: 62.50%] [G loss: 0.439171]\n",
      "epoch:20 step:19407 [D loss: 0.252549, acc.: 58.59%] [G loss: 0.446985]\n",
      "epoch:20 step:19408 [D loss: 0.223230, acc.: 64.06%] [G loss: 0.452515]\n",
      "epoch:20 step:19409 [D loss: 0.215019, acc.: 61.72%] [G loss: 0.403497]\n",
      "epoch:20 step:19410 [D loss: 0.258629, acc.: 53.91%] [G loss: 0.408503]\n",
      "epoch:20 step:19411 [D loss: 0.237234, acc.: 60.16%] [G loss: 0.399086]\n",
      "epoch:20 step:19412 [D loss: 0.231258, acc.: 65.62%] [G loss: 0.423663]\n",
      "epoch:20 step:19413 [D loss: 0.233363, acc.: 64.06%] [G loss: 0.418572]\n",
      "epoch:20 step:19414 [D loss: 0.195939, acc.: 71.88%] [G loss: 0.484853]\n",
      "epoch:20 step:19415 [D loss: 0.252641, acc.: 56.25%] [G loss: 0.429151]\n",
      "epoch:20 step:19416 [D loss: 0.210268, acc.: 69.53%] [G loss: 0.410724]\n",
      "epoch:20 step:19417 [D loss: 0.193662, acc.: 70.31%] [G loss: 0.407496]\n",
      "epoch:20 step:19418 [D loss: 0.224127, acc.: 67.97%] [G loss: 0.424417]\n",
      "epoch:20 step:19419 [D loss: 0.195502, acc.: 72.66%] [G loss: 0.458537]\n",
      "epoch:20 step:19420 [D loss: 0.242002, acc.: 59.38%] [G loss: 0.414586]\n",
      "epoch:20 step:19421 [D loss: 0.184307, acc.: 75.78%] [G loss: 0.470052]\n",
      "epoch:20 step:19422 [D loss: 0.243900, acc.: 62.50%] [G loss: 0.445061]\n",
      "epoch:20 step:19423 [D loss: 0.241915, acc.: 60.16%] [G loss: 0.424424]\n",
      "epoch:20 step:19424 [D loss: 0.224767, acc.: 62.50%] [G loss: 0.403493]\n",
      "epoch:20 step:19425 [D loss: 0.209810, acc.: 65.62%] [G loss: 0.412416]\n",
      "epoch:20 step:19426 [D loss: 0.225021, acc.: 62.50%] [G loss: 0.388385]\n",
      "epoch:20 step:19427 [D loss: 0.234621, acc.: 54.69%] [G loss: 0.404249]\n",
      "epoch:20 step:19428 [D loss: 0.193498, acc.: 69.53%] [G loss: 0.447925]\n",
      "epoch:20 step:19429 [D loss: 0.211810, acc.: 67.19%] [G loss: 0.442351]\n",
      "epoch:20 step:19430 [D loss: 0.217063, acc.: 65.62%] [G loss: 0.465425]\n",
      "epoch:20 step:19431 [D loss: 0.199577, acc.: 73.44%] [G loss: 0.467293]\n",
      "epoch:20 step:19432 [D loss: 0.211298, acc.: 67.19%] [G loss: 0.465592]\n",
      "epoch:20 step:19433 [D loss: 0.223223, acc.: 67.19%] [G loss: 0.440684]\n",
      "epoch:20 step:19434 [D loss: 0.209829, acc.: 68.75%] [G loss: 0.485170]\n",
      "epoch:20 step:19435 [D loss: 0.220702, acc.: 62.50%] [G loss: 0.475829]\n",
      "epoch:20 step:19436 [D loss: 0.267152, acc.: 50.00%] [G loss: 0.446835]\n",
      "epoch:20 step:19437 [D loss: 0.217199, acc.: 63.28%] [G loss: 0.432965]\n",
      "epoch:20 step:19438 [D loss: 0.243882, acc.: 57.81%] [G loss: 0.418382]\n",
      "epoch:20 step:19439 [D loss: 0.203398, acc.: 72.66%] [G loss: 0.450602]\n",
      "epoch:20 step:19440 [D loss: 0.201638, acc.: 67.19%] [G loss: 0.433549]\n",
      "epoch:20 step:19441 [D loss: 0.199840, acc.: 61.72%] [G loss: 0.504382]\n",
      "epoch:20 step:19442 [D loss: 0.258591, acc.: 55.47%] [G loss: 0.427834]\n",
      "epoch:20 step:19443 [D loss: 0.252758, acc.: 58.59%] [G loss: 0.443985]\n",
      "epoch:20 step:19444 [D loss: 0.237835, acc.: 53.12%] [G loss: 0.450003]\n",
      "epoch:20 step:19445 [D loss: 0.233367, acc.: 58.59%] [G loss: 0.439726]\n",
      "epoch:20 step:19446 [D loss: 0.212727, acc.: 64.84%] [G loss: 0.415832]\n",
      "epoch:20 step:19447 [D loss: 0.217036, acc.: 60.94%] [G loss: 0.446981]\n",
      "epoch:20 step:19448 [D loss: 0.202853, acc.: 70.31%] [G loss: 0.432997]\n",
      "epoch:20 step:19449 [D loss: 0.200379, acc.: 71.09%] [G loss: 0.436845]\n",
      "epoch:20 step:19450 [D loss: 0.245513, acc.: 59.38%] [G loss: 0.413757]\n",
      "epoch:20 step:19451 [D loss: 0.233125, acc.: 58.59%] [G loss: 0.397251]\n",
      "epoch:20 step:19452 [D loss: 0.218527, acc.: 65.62%] [G loss: 0.417303]\n",
      "epoch:20 step:19453 [D loss: 0.215169, acc.: 62.50%] [G loss: 0.415722]\n",
      "epoch:20 step:19454 [D loss: 0.221092, acc.: 62.50%] [G loss: 0.434038]\n",
      "epoch:20 step:19455 [D loss: 0.227496, acc.: 64.84%] [G loss: 0.430691]\n",
      "epoch:20 step:19456 [D loss: 0.248505, acc.: 55.47%] [G loss: 0.426178]\n",
      "epoch:20 step:19457 [D loss: 0.223370, acc.: 62.50%] [G loss: 0.420429]\n",
      "epoch:20 step:19458 [D loss: 0.229618, acc.: 62.50%] [G loss: 0.398791]\n",
      "epoch:20 step:19459 [D loss: 0.237351, acc.: 64.06%] [G loss: 0.464705]\n",
      "epoch:20 step:19460 [D loss: 0.237931, acc.: 61.72%] [G loss: 0.470380]\n",
      "epoch:20 step:19461 [D loss: 0.217406, acc.: 60.94%] [G loss: 0.459307]\n",
      "epoch:20 step:19462 [D loss: 0.221889, acc.: 60.94%] [G loss: 0.447823]\n",
      "epoch:20 step:19463 [D loss: 0.233084, acc.: 60.94%] [G loss: 0.443122]\n",
      "epoch:20 step:19464 [D loss: 0.194549, acc.: 71.09%] [G loss: 0.462688]\n",
      "epoch:20 step:19465 [D loss: 0.203930, acc.: 75.00%] [G loss: 0.468482]\n",
      "epoch:20 step:19466 [D loss: 0.223061, acc.: 61.72%] [G loss: 0.476272]\n",
      "epoch:20 step:19467 [D loss: 0.240483, acc.: 53.12%] [G loss: 0.424000]\n",
      "epoch:20 step:19468 [D loss: 0.220547, acc.: 64.84%] [G loss: 0.425929]\n",
      "epoch:20 step:19469 [D loss: 0.249039, acc.: 57.03%] [G loss: 0.398437]\n",
      "epoch:20 step:19470 [D loss: 0.189740, acc.: 67.97%] [G loss: 0.450131]\n",
      "epoch:20 step:19471 [D loss: 0.200370, acc.: 67.97%] [G loss: 0.479599]\n",
      "epoch:20 step:19472 [D loss: 0.227590, acc.: 63.28%] [G loss: 0.433455]\n",
      "epoch:20 step:19473 [D loss: 0.226969, acc.: 67.19%] [G loss: 0.437165]\n",
      "epoch:20 step:19474 [D loss: 0.278292, acc.: 50.78%] [G loss: 0.394139]\n",
      "epoch:20 step:19475 [D loss: 0.232186, acc.: 62.50%] [G loss: 0.425510]\n",
      "epoch:20 step:19476 [D loss: 0.207827, acc.: 71.09%] [G loss: 0.402110]\n",
      "epoch:20 step:19477 [D loss: 0.241029, acc.: 58.59%] [G loss: 0.403181]\n",
      "epoch:20 step:19478 [D loss: 0.263055, acc.: 51.56%] [G loss: 0.422640]\n",
      "epoch:20 step:19479 [D loss: 0.246696, acc.: 57.81%] [G loss: 0.433047]\n",
      "epoch:20 step:19480 [D loss: 0.236236, acc.: 61.72%] [G loss: 0.391467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19481 [D loss: 0.234509, acc.: 60.94%] [G loss: 0.432265]\n",
      "epoch:20 step:19482 [D loss: 0.242961, acc.: 57.03%] [G loss: 0.453693]\n",
      "epoch:20 step:19483 [D loss: 0.214747, acc.: 61.72%] [G loss: 0.470208]\n",
      "epoch:20 step:19484 [D loss: 0.231993, acc.: 64.06%] [G loss: 0.449414]\n",
      "epoch:20 step:19485 [D loss: 0.235991, acc.: 61.72%] [G loss: 0.433611]\n",
      "epoch:20 step:19486 [D loss: 0.217264, acc.: 66.41%] [G loss: 0.435624]\n",
      "epoch:20 step:19487 [D loss: 0.230610, acc.: 67.97%] [G loss: 0.467269]\n",
      "epoch:20 step:19488 [D loss: 0.239628, acc.: 53.91%] [G loss: 0.437790]\n",
      "epoch:20 step:19489 [D loss: 0.217506, acc.: 65.62%] [G loss: 0.466064]\n",
      "epoch:20 step:19490 [D loss: 0.224440, acc.: 64.06%] [G loss: 0.438761]\n",
      "epoch:20 step:19491 [D loss: 0.216927, acc.: 69.53%] [G loss: 0.433456]\n",
      "epoch:20 step:19492 [D loss: 0.263263, acc.: 52.34%] [G loss: 0.399791]\n",
      "epoch:20 step:19493 [D loss: 0.216837, acc.: 66.41%] [G loss: 0.417855]\n",
      "epoch:20 step:19494 [D loss: 0.207477, acc.: 70.31%] [G loss: 0.443678]\n",
      "epoch:20 step:19495 [D loss: 0.217763, acc.: 67.97%] [G loss: 0.398558]\n",
      "epoch:20 step:19496 [D loss: 0.218678, acc.: 70.31%] [G loss: 0.385070]\n",
      "epoch:20 step:19497 [D loss: 0.221947, acc.: 64.06%] [G loss: 0.418133]\n",
      "epoch:20 step:19498 [D loss: 0.226407, acc.: 66.41%] [G loss: 0.431985]\n",
      "epoch:20 step:19499 [D loss: 0.252079, acc.: 55.47%] [G loss: 0.389209]\n",
      "epoch:20 step:19500 [D loss: 0.240890, acc.: 61.72%] [G loss: 0.435357]\n",
      "epoch:20 step:19501 [D loss: 0.220738, acc.: 64.84%] [G loss: 0.459894]\n",
      "epoch:20 step:19502 [D loss: 0.248660, acc.: 60.94%] [G loss: 0.421626]\n",
      "epoch:20 step:19503 [D loss: 0.225415, acc.: 64.06%] [G loss: 0.426014]\n",
      "epoch:20 step:19504 [D loss: 0.213733, acc.: 66.41%] [G loss: 0.433745]\n",
      "epoch:20 step:19505 [D loss: 0.238851, acc.: 58.59%] [G loss: 0.420550]\n",
      "epoch:20 step:19506 [D loss: 0.234724, acc.: 58.59%] [G loss: 0.393375]\n",
      "epoch:20 step:19507 [D loss: 0.236125, acc.: 57.81%] [G loss: 0.428670]\n",
      "epoch:20 step:19508 [D loss: 0.235340, acc.: 63.28%] [G loss: 0.490741]\n",
      "epoch:20 step:19509 [D loss: 0.196280, acc.: 70.31%] [G loss: 0.477717]\n",
      "epoch:20 step:19510 [D loss: 0.261125, acc.: 59.38%] [G loss: 0.470717]\n",
      "epoch:20 step:19511 [D loss: 0.243251, acc.: 58.59%] [G loss: 0.429387]\n",
      "epoch:20 step:19512 [D loss: 0.251717, acc.: 55.47%] [G loss: 0.435505]\n",
      "epoch:20 step:19513 [D loss: 0.220875, acc.: 61.72%] [G loss: 0.483666]\n",
      "epoch:20 step:19514 [D loss: 0.261990, acc.: 50.00%] [G loss: 0.454750]\n",
      "epoch:20 step:19515 [D loss: 0.202666, acc.: 67.19%] [G loss: 0.464351]\n",
      "epoch:20 step:19516 [D loss: 0.210938, acc.: 65.62%] [G loss: 0.461105]\n",
      "epoch:20 step:19517 [D loss: 0.195310, acc.: 67.97%] [G loss: 0.456477]\n",
      "epoch:20 step:19518 [D loss: 0.237587, acc.: 60.16%] [G loss: 0.445493]\n",
      "epoch:20 step:19519 [D loss: 0.234876, acc.: 57.81%] [G loss: 0.421270]\n",
      "epoch:20 step:19520 [D loss: 0.216927, acc.: 62.50%] [G loss: 0.468776]\n",
      "epoch:20 step:19521 [D loss: 0.218738, acc.: 57.81%] [G loss: 0.474119]\n",
      "epoch:20 step:19522 [D loss: 0.194557, acc.: 71.09%] [G loss: 0.495846]\n",
      "epoch:20 step:19523 [D loss: 0.281866, acc.: 46.88%] [G loss: 0.401990]\n",
      "epoch:20 step:19524 [D loss: 0.253086, acc.: 57.81%] [G loss: 0.447875]\n",
      "epoch:20 step:19525 [D loss: 0.238182, acc.: 57.03%] [G loss: 0.408568]\n",
      "epoch:20 step:19526 [D loss: 0.207519, acc.: 66.41%] [G loss: 0.445124]\n",
      "epoch:20 step:19527 [D loss: 0.256167, acc.: 51.56%] [G loss: 0.440746]\n",
      "epoch:20 step:19528 [D loss: 0.252765, acc.: 49.22%] [G loss: 0.396600]\n",
      "epoch:20 step:19529 [D loss: 0.221124, acc.: 57.81%] [G loss: 0.443197]\n",
      "epoch:20 step:19530 [D loss: 0.218825, acc.: 64.06%] [G loss: 0.434711]\n",
      "epoch:20 step:19531 [D loss: 0.237541, acc.: 57.03%] [G loss: 0.423996]\n",
      "epoch:20 step:19532 [D loss: 0.196532, acc.: 69.53%] [G loss: 0.443134]\n",
      "epoch:20 step:19533 [D loss: 0.234270, acc.: 59.38%] [G loss: 0.428927]\n",
      "epoch:20 step:19534 [D loss: 0.234342, acc.: 61.72%] [G loss: 0.437435]\n",
      "epoch:20 step:19535 [D loss: 0.218858, acc.: 67.19%] [G loss: 0.477970]\n",
      "epoch:20 step:19536 [D loss: 0.206660, acc.: 70.31%] [G loss: 0.464908]\n",
      "epoch:20 step:19537 [D loss: 0.290747, acc.: 50.78%] [G loss: 0.378181]\n",
      "epoch:20 step:19538 [D loss: 0.227565, acc.: 63.28%] [G loss: 0.419810]\n",
      "epoch:20 step:19539 [D loss: 0.226599, acc.: 60.16%] [G loss: 0.434112]\n",
      "epoch:20 step:19540 [D loss: 0.262668, acc.: 51.56%] [G loss: 0.454750]\n",
      "epoch:20 step:19541 [D loss: 0.232932, acc.: 57.81%] [G loss: 0.450999]\n",
      "epoch:20 step:19542 [D loss: 0.218550, acc.: 63.28%] [G loss: 0.517409]\n",
      "epoch:20 step:19543 [D loss: 0.204156, acc.: 72.66%] [G loss: 0.474157]\n",
      "epoch:20 step:19544 [D loss: 0.220831, acc.: 67.19%] [G loss: 0.444932]\n",
      "epoch:20 step:19545 [D loss: 0.204788, acc.: 64.84%] [G loss: 0.443624]\n",
      "epoch:20 step:19546 [D loss: 0.244521, acc.: 57.03%] [G loss: 0.369582]\n",
      "epoch:20 step:19547 [D loss: 0.197051, acc.: 68.75%] [G loss: 0.441764]\n",
      "epoch:20 step:19548 [D loss: 0.212758, acc.: 66.41%] [G loss: 0.437406]\n",
      "epoch:20 step:19549 [D loss: 0.211880, acc.: 64.06%] [G loss: 0.423732]\n",
      "epoch:20 step:19550 [D loss: 0.215597, acc.: 67.19%] [G loss: 0.406930]\n",
      "epoch:20 step:19551 [D loss: 0.227100, acc.: 63.28%] [G loss: 0.428522]\n",
      "epoch:20 step:19552 [D loss: 0.259007, acc.: 57.03%] [G loss: 0.363589]\n",
      "epoch:20 step:19553 [D loss: 0.213374, acc.: 64.84%] [G loss: 0.437454]\n",
      "epoch:20 step:19554 [D loss: 0.242508, acc.: 62.50%] [G loss: 0.423362]\n",
      "epoch:20 step:19555 [D loss: 0.205097, acc.: 68.75%] [G loss: 0.492252]\n",
      "epoch:20 step:19556 [D loss: 0.227440, acc.: 57.81%] [G loss: 0.453180]\n",
      "epoch:20 step:19557 [D loss: 0.233760, acc.: 57.03%] [G loss: 0.466212]\n",
      "epoch:20 step:19558 [D loss: 0.220433, acc.: 66.41%] [G loss: 0.415169]\n",
      "epoch:20 step:19559 [D loss: 0.198721, acc.: 71.09%] [G loss: 0.445028]\n",
      "epoch:20 step:19560 [D loss: 0.276196, acc.: 42.97%] [G loss: 0.424491]\n",
      "epoch:20 step:19561 [D loss: 0.231864, acc.: 64.84%] [G loss: 0.377971]\n",
      "epoch:20 step:19562 [D loss: 0.200107, acc.: 68.75%] [G loss: 0.444886]\n",
      "epoch:20 step:19563 [D loss: 0.205875, acc.: 71.88%] [G loss: 0.431113]\n",
      "epoch:20 step:19564 [D loss: 0.225035, acc.: 60.94%] [G loss: 0.439142]\n",
      "epoch:20 step:19565 [D loss: 0.217128, acc.: 68.75%] [G loss: 0.421641]\n",
      "epoch:20 step:19566 [D loss: 0.230693, acc.: 55.47%] [G loss: 0.452952]\n",
      "epoch:20 step:19567 [D loss: 0.240866, acc.: 56.25%] [G loss: 0.423825]\n",
      "epoch:20 step:19568 [D loss: 0.267545, acc.: 53.91%] [G loss: 0.388243]\n",
      "epoch:20 step:19569 [D loss: 0.233787, acc.: 57.81%] [G loss: 0.435541]\n",
      "epoch:20 step:19570 [D loss: 0.225630, acc.: 62.50%] [G loss: 0.467648]\n",
      "epoch:20 step:19571 [D loss: 0.227855, acc.: 61.72%] [G loss: 0.420290]\n",
      "epoch:20 step:19572 [D loss: 0.210654, acc.: 66.41%] [G loss: 0.434208]\n",
      "epoch:20 step:19573 [D loss: 0.208022, acc.: 68.75%] [G loss: 0.438337]\n",
      "epoch:20 step:19574 [D loss: 0.240982, acc.: 55.47%] [G loss: 0.399736]\n",
      "epoch:20 step:19575 [D loss: 0.226321, acc.: 61.72%] [G loss: 0.426575]\n",
      "epoch:20 step:19576 [D loss: 0.220748, acc.: 62.50%] [G loss: 0.427270]\n",
      "epoch:20 step:19577 [D loss: 0.196319, acc.: 76.56%] [G loss: 0.441060]\n",
      "epoch:20 step:19578 [D loss: 0.202285, acc.: 68.75%] [G loss: 0.425172]\n",
      "epoch:20 step:19579 [D loss: 0.212220, acc.: 65.62%] [G loss: 0.421573]\n",
      "epoch:20 step:19580 [D loss: 0.225944, acc.: 61.72%] [G loss: 0.439049]\n",
      "epoch:20 step:19581 [D loss: 0.199516, acc.: 67.19%] [G loss: 0.453927]\n",
      "epoch:20 step:19582 [D loss: 0.207588, acc.: 66.41%] [G loss: 0.449893]\n",
      "epoch:20 step:19583 [D loss: 0.229225, acc.: 60.94%] [G loss: 0.453980]\n",
      "epoch:20 step:19584 [D loss: 0.252405, acc.: 54.69%] [G loss: 0.426421]\n",
      "epoch:20 step:19585 [D loss: 0.220170, acc.: 64.06%] [G loss: 0.474139]\n",
      "epoch:20 step:19586 [D loss: 0.250172, acc.: 55.47%] [G loss: 0.411641]\n",
      "epoch:20 step:19587 [D loss: 0.228020, acc.: 58.59%] [G loss: 0.446950]\n",
      "epoch:20 step:19588 [D loss: 0.224474, acc.: 63.28%] [G loss: 0.420753]\n",
      "epoch:20 step:19589 [D loss: 0.232693, acc.: 57.81%] [G loss: 0.417227]\n",
      "epoch:20 step:19590 [D loss: 0.224349, acc.: 67.97%] [G loss: 0.452196]\n",
      "epoch:20 step:19591 [D loss: 0.229387, acc.: 58.59%] [G loss: 0.429123]\n",
      "epoch:20 step:19592 [D loss: 0.217670, acc.: 61.72%] [G loss: 0.499222]\n",
      "epoch:20 step:19593 [D loss: 0.234728, acc.: 59.38%] [G loss: 0.446480]\n",
      "epoch:20 step:19594 [D loss: 0.217821, acc.: 63.28%] [G loss: 0.461869]\n",
      "epoch:20 step:19595 [D loss: 0.233943, acc.: 61.72%] [G loss: 0.463714]\n",
      "epoch:20 step:19596 [D loss: 0.246943, acc.: 54.69%] [G loss: 0.439632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19597 [D loss: 0.215420, acc.: 65.62%] [G loss: 0.427669]\n",
      "epoch:20 step:19598 [D loss: 0.238364, acc.: 54.69%] [G loss: 0.430963]\n",
      "epoch:20 step:19599 [D loss: 0.254184, acc.: 58.59%] [G loss: 0.421589]\n",
      "epoch:20 step:19600 [D loss: 0.200656, acc.: 69.53%] [G loss: 0.482986]\n",
      "epoch:20 step:19601 [D loss: 0.236013, acc.: 59.38%] [G loss: 0.450198]\n",
      "epoch:20 step:19602 [D loss: 0.220997, acc.: 60.94%] [G loss: 0.442237]\n",
      "epoch:20 step:19603 [D loss: 0.222901, acc.: 64.84%] [G loss: 0.425849]\n",
      "epoch:20 step:19604 [D loss: 0.232754, acc.: 58.59%] [G loss: 0.404035]\n",
      "epoch:20 step:19605 [D loss: 0.259216, acc.: 61.72%] [G loss: 0.422271]\n",
      "epoch:20 step:19606 [D loss: 0.222635, acc.: 59.38%] [G loss: 0.408271]\n",
      "epoch:20 step:19607 [D loss: 0.235633, acc.: 60.16%] [G loss: 0.401491]\n",
      "epoch:20 step:19608 [D loss: 0.235318, acc.: 57.81%] [G loss: 0.416330]\n",
      "epoch:20 step:19609 [D loss: 0.228989, acc.: 60.16%] [G loss: 0.420715]\n",
      "epoch:20 step:19610 [D loss: 0.244532, acc.: 57.81%] [G loss: 0.420315]\n",
      "epoch:20 step:19611 [D loss: 0.229154, acc.: 60.94%] [G loss: 0.402681]\n",
      "epoch:20 step:19612 [D loss: 0.195590, acc.: 70.31%] [G loss: 0.428031]\n",
      "epoch:20 step:19613 [D loss: 0.222527, acc.: 63.28%] [G loss: 0.414591]\n",
      "epoch:20 step:19614 [D loss: 0.240611, acc.: 64.06%] [G loss: 0.426115]\n",
      "epoch:20 step:19615 [D loss: 0.207428, acc.: 70.31%] [G loss: 0.459575]\n",
      "epoch:20 step:19616 [D loss: 0.222953, acc.: 65.62%] [G loss: 0.472208]\n",
      "epoch:20 step:19617 [D loss: 0.226134, acc.: 64.84%] [G loss: 0.430848]\n",
      "epoch:20 step:19618 [D loss: 0.229481, acc.: 61.72%] [G loss: 0.441642]\n",
      "epoch:20 step:19619 [D loss: 0.240527, acc.: 56.25%] [G loss: 0.450318]\n",
      "epoch:20 step:19620 [D loss: 0.231491, acc.: 57.81%] [G loss: 0.427575]\n",
      "epoch:20 step:19621 [D loss: 0.209310, acc.: 64.84%] [G loss: 0.434341]\n",
      "epoch:20 step:19622 [D loss: 0.209267, acc.: 69.53%] [G loss: 0.443683]\n",
      "epoch:20 step:19623 [D loss: 0.244975, acc.: 59.38%] [G loss: 0.395540]\n",
      "epoch:20 step:19624 [D loss: 0.191797, acc.: 67.97%] [G loss: 0.455714]\n",
      "epoch:20 step:19625 [D loss: 0.210970, acc.: 70.31%] [G loss: 0.467559]\n",
      "epoch:20 step:19626 [D loss: 0.224756, acc.: 60.16%] [G loss: 0.482213]\n",
      "epoch:20 step:19627 [D loss: 0.229922, acc.: 60.94%] [G loss: 0.490559]\n",
      "epoch:20 step:19628 [D loss: 0.223075, acc.: 61.72%] [G loss: 0.481413]\n",
      "epoch:20 step:19629 [D loss: 0.227534, acc.: 61.72%] [G loss: 0.484319]\n",
      "epoch:20 step:19630 [D loss: 0.197696, acc.: 68.75%] [G loss: 0.477937]\n",
      "epoch:20 step:19631 [D loss: 0.267044, acc.: 52.34%] [G loss: 0.416203]\n",
      "epoch:20 step:19632 [D loss: 0.268140, acc.: 53.12%] [G loss: 0.404327]\n",
      "epoch:20 step:19633 [D loss: 0.220268, acc.: 64.06%] [G loss: 0.407417]\n",
      "epoch:20 step:19634 [D loss: 0.204561, acc.: 70.31%] [G loss: 0.453928]\n",
      "epoch:20 step:19635 [D loss: 0.213624, acc.: 65.62%] [G loss: 0.443949]\n",
      "epoch:20 step:19636 [D loss: 0.219019, acc.: 68.75%] [G loss: 0.466373]\n",
      "epoch:20 step:19637 [D loss: 0.193137, acc.: 73.44%] [G loss: 0.466108]\n",
      "epoch:20 step:19638 [D loss: 0.202960, acc.: 66.41%] [G loss: 0.436932]\n",
      "epoch:20 step:19639 [D loss: 0.183166, acc.: 69.53%] [G loss: 0.493659]\n",
      "epoch:20 step:19640 [D loss: 0.192811, acc.: 73.44%] [G loss: 0.503628]\n",
      "epoch:20 step:19641 [D loss: 0.222131, acc.: 64.06%] [G loss: 0.432227]\n",
      "epoch:20 step:19642 [D loss: 0.243610, acc.: 60.16%] [G loss: 0.464262]\n",
      "epoch:20 step:19643 [D loss: 0.235384, acc.: 60.94%] [G loss: 0.470431]\n",
      "epoch:20 step:19644 [D loss: 0.230919, acc.: 58.59%] [G loss: 0.417861]\n",
      "epoch:20 step:19645 [D loss: 0.210350, acc.: 71.88%] [G loss: 0.423858]\n",
      "epoch:20 step:19646 [D loss: 0.215170, acc.: 68.75%] [G loss: 0.459520]\n",
      "epoch:20 step:19647 [D loss: 0.233373, acc.: 63.28%] [G loss: 0.426656]\n",
      "epoch:20 step:19648 [D loss: 0.228389, acc.: 63.28%] [G loss: 0.451236]\n",
      "epoch:20 step:19649 [D loss: 0.212396, acc.: 60.94%] [G loss: 0.463479]\n",
      "epoch:20 step:19650 [D loss: 0.227232, acc.: 64.06%] [G loss: 0.424039]\n",
      "epoch:20 step:19651 [D loss: 0.202455, acc.: 70.31%] [G loss: 0.458649]\n",
      "epoch:20 step:19652 [D loss: 0.210523, acc.: 68.75%] [G loss: 0.432243]\n",
      "epoch:20 step:19653 [D loss: 0.243744, acc.: 59.38%] [G loss: 0.487196]\n",
      "epoch:20 step:19654 [D loss: 0.224597, acc.: 67.97%] [G loss: 0.460799]\n",
      "epoch:20 step:19655 [D loss: 0.277416, acc.: 48.44%] [G loss: 0.431964]\n",
      "epoch:20 step:19656 [D loss: 0.239839, acc.: 57.81%] [G loss: 0.435062]\n",
      "epoch:20 step:19657 [D loss: 0.210649, acc.: 63.28%] [G loss: 0.434312]\n",
      "epoch:20 step:19658 [D loss: 0.187321, acc.: 70.31%] [G loss: 0.476838]\n",
      "epoch:20 step:19659 [D loss: 0.208540, acc.: 68.75%] [G loss: 0.511708]\n",
      "epoch:20 step:19660 [D loss: 0.270547, acc.: 53.91%] [G loss: 0.466019]\n",
      "epoch:20 step:19661 [D loss: 0.223373, acc.: 65.62%] [G loss: 0.458340]\n",
      "epoch:20 step:19662 [D loss: 0.250732, acc.: 54.69%] [G loss: 0.399464]\n",
      "epoch:20 step:19663 [D loss: 0.191590, acc.: 75.00%] [G loss: 0.430476]\n",
      "epoch:20 step:19664 [D loss: 0.181094, acc.: 74.22%] [G loss: 0.462904]\n",
      "epoch:20 step:19665 [D loss: 0.182493, acc.: 75.78%] [G loss: 0.521725]\n",
      "epoch:20 step:19666 [D loss: 0.187688, acc.: 72.66%] [G loss: 0.532218]\n",
      "epoch:20 step:19667 [D loss: 0.179519, acc.: 73.44%] [G loss: 0.535196]\n",
      "epoch:20 step:19668 [D loss: 0.343314, acc.: 54.69%] [G loss: 0.510616]\n",
      "epoch:20 step:19669 [D loss: 0.277316, acc.: 50.00%] [G loss: 0.597833]\n",
      "epoch:20 step:19670 [D loss: 0.203626, acc.: 69.53%] [G loss: 0.623971]\n",
      "epoch:20 step:19671 [D loss: 0.235354, acc.: 60.16%] [G loss: 0.428739]\n",
      "epoch:20 step:19672 [D loss: 0.257687, acc.: 60.94%] [G loss: 0.447723]\n",
      "epoch:20 step:19673 [D loss: 0.220312, acc.: 66.41%] [G loss: 0.457313]\n",
      "epoch:20 step:19674 [D loss: 0.242808, acc.: 61.72%] [G loss: 0.457512]\n",
      "epoch:20 step:19675 [D loss: 0.208236, acc.: 73.44%] [G loss: 0.481615]\n",
      "epoch:20 step:19676 [D loss: 0.187089, acc.: 73.44%] [G loss: 0.531107]\n",
      "epoch:20 step:19677 [D loss: 0.176601, acc.: 73.44%] [G loss: 0.538775]\n",
      "epoch:21 step:19678 [D loss: 0.227519, acc.: 61.72%] [G loss: 0.531967]\n",
      "epoch:21 step:19679 [D loss: 0.252901, acc.: 63.28%] [G loss: 0.479642]\n",
      "epoch:21 step:19680 [D loss: 0.239303, acc.: 56.25%] [G loss: 0.445141]\n",
      "epoch:21 step:19681 [D loss: 0.231024, acc.: 65.62%] [G loss: 0.431466]\n",
      "epoch:21 step:19682 [D loss: 0.219852, acc.: 60.16%] [G loss: 0.413974]\n",
      "epoch:21 step:19683 [D loss: 0.242078, acc.: 59.38%] [G loss: 0.441923]\n",
      "epoch:21 step:19684 [D loss: 0.225345, acc.: 61.72%] [G loss: 0.458926]\n",
      "epoch:21 step:19685 [D loss: 0.236793, acc.: 60.16%] [G loss: 0.461767]\n",
      "epoch:21 step:19686 [D loss: 0.217398, acc.: 61.72%] [G loss: 0.503112]\n",
      "epoch:21 step:19687 [D loss: 0.222646, acc.: 67.19%] [G loss: 0.463500]\n",
      "epoch:21 step:19688 [D loss: 0.203367, acc.: 65.62%] [G loss: 0.475473]\n",
      "epoch:21 step:19689 [D loss: 0.204411, acc.: 71.88%] [G loss: 0.425851]\n",
      "epoch:21 step:19690 [D loss: 0.215155, acc.: 60.94%] [G loss: 0.439488]\n",
      "epoch:21 step:19691 [D loss: 0.221711, acc.: 64.84%] [G loss: 0.437008]\n",
      "epoch:21 step:19692 [D loss: 0.183960, acc.: 74.22%] [G loss: 0.486859]\n",
      "epoch:21 step:19693 [D loss: 0.189360, acc.: 75.78%] [G loss: 0.473176]\n",
      "epoch:21 step:19694 [D loss: 0.247338, acc.: 55.47%] [G loss: 0.435726]\n",
      "epoch:21 step:19695 [D loss: 0.232707, acc.: 59.38%] [G loss: 0.414407]\n",
      "epoch:21 step:19696 [D loss: 0.243713, acc.: 57.03%] [G loss: 0.438831]\n",
      "epoch:21 step:19697 [D loss: 0.263789, acc.: 55.47%] [G loss: 0.447431]\n",
      "epoch:21 step:19698 [D loss: 0.228495, acc.: 59.38%] [G loss: 0.467988]\n",
      "epoch:21 step:19699 [D loss: 0.205467, acc.: 67.97%] [G loss: 0.464428]\n",
      "epoch:21 step:19700 [D loss: 0.277879, acc.: 52.34%] [G loss: 0.401520]\n",
      "epoch:21 step:19701 [D loss: 0.209966, acc.: 67.19%] [G loss: 0.425897]\n",
      "epoch:21 step:19702 [D loss: 0.197635, acc.: 71.09%] [G loss: 0.426611]\n",
      "epoch:21 step:19703 [D loss: 0.253530, acc.: 48.44%] [G loss: 0.397428]\n",
      "epoch:21 step:19704 [D loss: 0.240545, acc.: 55.47%] [G loss: 0.402904]\n",
      "epoch:21 step:19705 [D loss: 0.218956, acc.: 64.84%] [G loss: 0.407200]\n",
      "epoch:21 step:19706 [D loss: 0.204871, acc.: 67.97%] [G loss: 0.433430]\n",
      "epoch:21 step:19707 [D loss: 0.235106, acc.: 57.81%] [G loss: 0.437254]\n",
      "epoch:21 step:19708 [D loss: 0.249560, acc.: 57.81%] [G loss: 0.419962]\n",
      "epoch:21 step:19709 [D loss: 0.221366, acc.: 67.97%] [G loss: 0.478917]\n",
      "epoch:21 step:19710 [D loss: 0.245583, acc.: 57.81%] [G loss: 0.417582]\n",
      "epoch:21 step:19711 [D loss: 0.248059, acc.: 57.03%] [G loss: 0.406588]\n",
      "epoch:21 step:19712 [D loss: 0.230092, acc.: 62.50%] [G loss: 0.430526]\n",
      "epoch:21 step:19713 [D loss: 0.248076, acc.: 57.81%] [G loss: 0.426059]\n",
      "epoch:21 step:19714 [D loss: 0.247714, acc.: 57.81%] [G loss: 0.427124]\n",
      "epoch:21 step:19715 [D loss: 0.259767, acc.: 49.22%] [G loss: 0.396368]\n",
      "epoch:21 step:19716 [D loss: 0.201545, acc.: 70.31%] [G loss: 0.434076]\n",
      "epoch:21 step:19717 [D loss: 0.192984, acc.: 74.22%] [G loss: 0.458438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19718 [D loss: 0.248957, acc.: 58.59%] [G loss: 0.396489]\n",
      "epoch:21 step:19719 [D loss: 0.221333, acc.: 64.06%] [G loss: 0.430552]\n",
      "epoch:21 step:19720 [D loss: 0.211245, acc.: 65.62%] [G loss: 0.439597]\n",
      "epoch:21 step:19721 [D loss: 0.233297, acc.: 65.62%] [G loss: 0.439008]\n",
      "epoch:21 step:19722 [D loss: 0.217504, acc.: 63.28%] [G loss: 0.472457]\n",
      "epoch:21 step:19723 [D loss: 0.248314, acc.: 59.38%] [G loss: 0.395615]\n",
      "epoch:21 step:19724 [D loss: 0.234292, acc.: 57.81%] [G loss: 0.436413]\n",
      "epoch:21 step:19725 [D loss: 0.186644, acc.: 73.44%] [G loss: 0.441833]\n",
      "epoch:21 step:19726 [D loss: 0.210030, acc.: 65.62%] [G loss: 0.441424]\n",
      "epoch:21 step:19727 [D loss: 0.210586, acc.: 65.62%] [G loss: 0.487734]\n",
      "epoch:21 step:19728 [D loss: 0.241838, acc.: 60.94%] [G loss: 0.440839]\n",
      "epoch:21 step:19729 [D loss: 0.218972, acc.: 60.16%] [G loss: 0.416614]\n",
      "epoch:21 step:19730 [D loss: 0.225644, acc.: 62.50%] [G loss: 0.437349]\n",
      "epoch:21 step:19731 [D loss: 0.202915, acc.: 67.19%] [G loss: 0.441850]\n",
      "epoch:21 step:19732 [D loss: 0.210030, acc.: 67.19%] [G loss: 0.461642]\n",
      "epoch:21 step:19733 [D loss: 0.204073, acc.: 66.41%] [G loss: 0.431425]\n",
      "epoch:21 step:19734 [D loss: 0.260619, acc.: 59.38%] [G loss: 0.447577]\n",
      "epoch:21 step:19735 [D loss: 0.220497, acc.: 61.72%] [G loss: 0.420741]\n",
      "epoch:21 step:19736 [D loss: 0.213843, acc.: 64.84%] [G loss: 0.447916]\n",
      "epoch:21 step:19737 [D loss: 0.233313, acc.: 64.06%] [G loss: 0.415928]\n",
      "epoch:21 step:19738 [D loss: 0.233994, acc.: 57.81%] [G loss: 0.447487]\n",
      "epoch:21 step:19739 [D loss: 0.239471, acc.: 64.06%] [G loss: 0.408225]\n",
      "epoch:21 step:19740 [D loss: 0.203965, acc.: 73.44%] [G loss: 0.423088]\n",
      "epoch:21 step:19741 [D loss: 0.242611, acc.: 60.16%] [G loss: 0.432056]\n",
      "epoch:21 step:19742 [D loss: 0.219353, acc.: 64.06%] [G loss: 0.465792]\n",
      "epoch:21 step:19743 [D loss: 0.228925, acc.: 60.94%] [G loss: 0.406141]\n",
      "epoch:21 step:19744 [D loss: 0.214132, acc.: 63.28%] [G loss: 0.422973]\n",
      "epoch:21 step:19745 [D loss: 0.232096, acc.: 60.94%] [G loss: 0.398533]\n",
      "epoch:21 step:19746 [D loss: 0.210809, acc.: 64.84%] [G loss: 0.439618]\n",
      "epoch:21 step:19747 [D loss: 0.208538, acc.: 67.97%] [G loss: 0.475660]\n",
      "epoch:21 step:19748 [D loss: 0.270137, acc.: 57.81%] [G loss: 0.421781]\n",
      "epoch:21 step:19749 [D loss: 0.241099, acc.: 58.59%] [G loss: 0.428917]\n",
      "epoch:21 step:19750 [D loss: 0.238614, acc.: 60.16%] [G loss: 0.386001]\n",
      "epoch:21 step:19751 [D loss: 0.197427, acc.: 67.19%] [G loss: 0.443680]\n",
      "epoch:21 step:19752 [D loss: 0.220682, acc.: 65.62%] [G loss: 0.437452]\n",
      "epoch:21 step:19753 [D loss: 0.198911, acc.: 65.62%] [G loss: 0.495825]\n",
      "epoch:21 step:19754 [D loss: 0.181620, acc.: 71.09%] [G loss: 0.509579]\n",
      "epoch:21 step:19755 [D loss: 0.277006, acc.: 53.12%] [G loss: 0.411279]\n",
      "epoch:21 step:19756 [D loss: 0.245744, acc.: 54.69%] [G loss: 0.411600]\n",
      "epoch:21 step:19757 [D loss: 0.223471, acc.: 61.72%] [G loss: 0.468347]\n",
      "epoch:21 step:19758 [D loss: 0.268819, acc.: 50.78%] [G loss: 0.413816]\n",
      "epoch:21 step:19759 [D loss: 0.213309, acc.: 64.84%] [G loss: 0.455337]\n",
      "epoch:21 step:19760 [D loss: 0.232678, acc.: 64.06%] [G loss: 0.448878]\n",
      "epoch:21 step:19761 [D loss: 0.196966, acc.: 71.09%] [G loss: 0.485404]\n",
      "epoch:21 step:19762 [D loss: 0.221070, acc.: 62.50%] [G loss: 0.470326]\n",
      "epoch:21 step:19763 [D loss: 0.213450, acc.: 64.84%] [G loss: 0.429676]\n",
      "epoch:21 step:19764 [D loss: 0.208212, acc.: 69.53%] [G loss: 0.434288]\n",
      "epoch:21 step:19765 [D loss: 0.215898, acc.: 65.62%] [G loss: 0.442265]\n",
      "epoch:21 step:19766 [D loss: 0.225442, acc.: 65.62%] [G loss: 0.449294]\n",
      "epoch:21 step:19767 [D loss: 0.223144, acc.: 64.84%] [G loss: 0.414844]\n",
      "epoch:21 step:19768 [D loss: 0.240091, acc.: 60.16%] [G loss: 0.435762]\n",
      "epoch:21 step:19769 [D loss: 0.213212, acc.: 63.28%] [G loss: 0.427951]\n",
      "epoch:21 step:19770 [D loss: 0.210174, acc.: 66.41%] [G loss: 0.428369]\n",
      "epoch:21 step:19771 [D loss: 0.241256, acc.: 57.81%] [G loss: 0.458188]\n",
      "epoch:21 step:19772 [D loss: 0.224178, acc.: 56.25%] [G loss: 0.452044]\n",
      "epoch:21 step:19773 [D loss: 0.206970, acc.: 67.97%] [G loss: 0.449256]\n",
      "epoch:21 step:19774 [D loss: 0.187758, acc.: 72.66%] [G loss: 0.501280]\n",
      "epoch:21 step:19775 [D loss: 0.216273, acc.: 64.84%] [G loss: 0.471480]\n",
      "epoch:21 step:19776 [D loss: 0.223431, acc.: 66.41%] [G loss: 0.440542]\n",
      "epoch:21 step:19777 [D loss: 0.203111, acc.: 70.31%] [G loss: 0.435182]\n",
      "epoch:21 step:19778 [D loss: 0.206466, acc.: 67.19%] [G loss: 0.438483]\n",
      "epoch:21 step:19779 [D loss: 0.214216, acc.: 65.62%] [G loss: 0.448837]\n",
      "epoch:21 step:19780 [D loss: 0.266023, acc.: 54.69%] [G loss: 0.356265]\n",
      "epoch:21 step:19781 [D loss: 0.227364, acc.: 55.47%] [G loss: 0.394841]\n",
      "epoch:21 step:19782 [D loss: 0.229474, acc.: 62.50%] [G loss: 0.391933]\n",
      "epoch:21 step:19783 [D loss: 0.215160, acc.: 70.31%] [G loss: 0.399849]\n",
      "epoch:21 step:19784 [D loss: 0.194614, acc.: 69.53%] [G loss: 0.487079]\n",
      "epoch:21 step:19785 [D loss: 0.250945, acc.: 53.12%] [G loss: 0.446682]\n",
      "epoch:21 step:19786 [D loss: 0.259803, acc.: 52.34%] [G loss: 0.401149]\n",
      "epoch:21 step:19787 [D loss: 0.236831, acc.: 58.59%] [G loss: 0.439699]\n",
      "epoch:21 step:19788 [D loss: 0.224007, acc.: 65.62%] [G loss: 0.409592]\n",
      "epoch:21 step:19789 [D loss: 0.175769, acc.: 73.44%] [G loss: 0.490551]\n",
      "epoch:21 step:19790 [D loss: 0.221583, acc.: 67.97%] [G loss: 0.409602]\n",
      "epoch:21 step:19791 [D loss: 0.206463, acc.: 71.88%] [G loss: 0.464048]\n",
      "epoch:21 step:19792 [D loss: 0.200854, acc.: 73.44%] [G loss: 0.493686]\n",
      "epoch:21 step:19793 [D loss: 0.218893, acc.: 64.06%] [G loss: 0.467436]\n",
      "epoch:21 step:19794 [D loss: 0.196330, acc.: 68.75%] [G loss: 0.437675]\n",
      "epoch:21 step:19795 [D loss: 0.200333, acc.: 65.62%] [G loss: 0.483265]\n",
      "epoch:21 step:19796 [D loss: 0.183836, acc.: 71.09%] [G loss: 0.484177]\n",
      "epoch:21 step:19797 [D loss: 0.245924, acc.: 63.28%] [G loss: 0.451402]\n",
      "epoch:21 step:19798 [D loss: 0.230491, acc.: 60.94%] [G loss: 0.432129]\n",
      "epoch:21 step:19799 [D loss: 0.185040, acc.: 76.56%] [G loss: 0.454328]\n",
      "epoch:21 step:19800 [D loss: 0.198346, acc.: 67.97%] [G loss: 0.512849]\n",
      "epoch:21 step:19801 [D loss: 0.248854, acc.: 55.47%] [G loss: 0.438189]\n",
      "epoch:21 step:19802 [D loss: 0.244591, acc.: 57.03%] [G loss: 0.422114]\n",
      "epoch:21 step:19803 [D loss: 0.204331, acc.: 61.72%] [G loss: 0.430773]\n",
      "epoch:21 step:19804 [D loss: 0.208347, acc.: 66.41%] [G loss: 0.432908]\n",
      "epoch:21 step:19805 [D loss: 0.224954, acc.: 60.16%] [G loss: 0.443235]\n",
      "epoch:21 step:19806 [D loss: 0.230324, acc.: 60.94%] [G loss: 0.406800]\n",
      "epoch:21 step:19807 [D loss: 0.202851, acc.: 67.97%] [G loss: 0.448750]\n",
      "epoch:21 step:19808 [D loss: 0.188481, acc.: 72.66%] [G loss: 0.450531]\n",
      "epoch:21 step:19809 [D loss: 0.205719, acc.: 67.97%] [G loss: 0.413804]\n",
      "epoch:21 step:19810 [D loss: 0.263455, acc.: 53.91%] [G loss: 0.429041]\n",
      "epoch:21 step:19811 [D loss: 0.232023, acc.: 60.16%] [G loss: 0.472492]\n",
      "epoch:21 step:19812 [D loss: 0.226067, acc.: 66.41%] [G loss: 0.441319]\n",
      "epoch:21 step:19813 [D loss: 0.208424, acc.: 67.19%] [G loss: 0.444931]\n",
      "epoch:21 step:19814 [D loss: 0.242019, acc.: 57.03%] [G loss: 0.406051]\n",
      "epoch:21 step:19815 [D loss: 0.241330, acc.: 57.03%] [G loss: 0.400181]\n",
      "epoch:21 step:19816 [D loss: 0.239663, acc.: 61.72%] [G loss: 0.411985]\n",
      "epoch:21 step:19817 [D loss: 0.253460, acc.: 53.12%] [G loss: 0.419183]\n",
      "epoch:21 step:19818 [D loss: 0.226655, acc.: 56.25%] [G loss: 0.422124]\n",
      "epoch:21 step:19819 [D loss: 0.230912, acc.: 61.72%] [G loss: 0.419188]\n",
      "epoch:21 step:19820 [D loss: 0.254144, acc.: 53.12%] [G loss: 0.415421]\n",
      "epoch:21 step:19821 [D loss: 0.219912, acc.: 63.28%] [G loss: 0.431465]\n",
      "epoch:21 step:19822 [D loss: 0.239032, acc.: 56.25%] [G loss: 0.435255]\n",
      "epoch:21 step:19823 [D loss: 0.224760, acc.: 61.72%] [G loss: 0.442998]\n",
      "epoch:21 step:19824 [D loss: 0.215471, acc.: 64.06%] [G loss: 0.450304]\n",
      "epoch:21 step:19825 [D loss: 0.220081, acc.: 61.72%] [G loss: 0.437526]\n",
      "epoch:21 step:19826 [D loss: 0.215752, acc.: 63.28%] [G loss: 0.435749]\n",
      "epoch:21 step:19827 [D loss: 0.273373, acc.: 51.56%] [G loss: 0.398431]\n",
      "epoch:21 step:19828 [D loss: 0.202897, acc.: 67.19%] [G loss: 0.453275]\n",
      "epoch:21 step:19829 [D loss: 0.208192, acc.: 71.09%] [G loss: 0.463696]\n",
      "epoch:21 step:19830 [D loss: 0.254270, acc.: 55.47%] [G loss: 0.431340]\n",
      "epoch:21 step:19831 [D loss: 0.218648, acc.: 64.06%] [G loss: 0.466513]\n",
      "epoch:21 step:19832 [D loss: 0.203371, acc.: 63.28%] [G loss: 0.450167]\n",
      "epoch:21 step:19833 [D loss: 0.203526, acc.: 69.53%] [G loss: 0.487122]\n",
      "epoch:21 step:19834 [D loss: 0.204591, acc.: 67.97%] [G loss: 0.457445]\n",
      "epoch:21 step:19835 [D loss: 0.223177, acc.: 63.28%] [G loss: 0.432866]\n",
      "epoch:21 step:19836 [D loss: 0.199847, acc.: 67.97%] [G loss: 0.433793]\n",
      "epoch:21 step:19837 [D loss: 0.259869, acc.: 53.91%] [G loss: 0.430257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19838 [D loss: 0.245676, acc.: 59.38%] [G loss: 0.419178]\n",
      "epoch:21 step:19839 [D loss: 0.236510, acc.: 64.84%] [G loss: 0.419098]\n",
      "epoch:21 step:19840 [D loss: 0.223328, acc.: 62.50%] [G loss: 0.430038]\n",
      "epoch:21 step:19841 [D loss: 0.206364, acc.: 66.41%] [G loss: 0.417422]\n",
      "epoch:21 step:19842 [D loss: 0.233226, acc.: 61.72%] [G loss: 0.412799]\n",
      "epoch:21 step:19843 [D loss: 0.230500, acc.: 63.28%] [G loss: 0.406380]\n",
      "epoch:21 step:19844 [D loss: 0.199795, acc.: 67.97%] [G loss: 0.442454]\n",
      "epoch:21 step:19845 [D loss: 0.211060, acc.: 65.62%] [G loss: 0.417270]\n",
      "epoch:21 step:19846 [D loss: 0.222249, acc.: 64.06%] [G loss: 0.428991]\n",
      "epoch:21 step:19847 [D loss: 0.265916, acc.: 52.34%] [G loss: 0.409183]\n",
      "epoch:21 step:19848 [D loss: 0.229055, acc.: 60.94%] [G loss: 0.437553]\n",
      "epoch:21 step:19849 [D loss: 0.231429, acc.: 63.28%] [G loss: 0.442165]\n",
      "epoch:21 step:19850 [D loss: 0.247623, acc.: 57.03%] [G loss: 0.413927]\n",
      "epoch:21 step:19851 [D loss: 0.249200, acc.: 53.91%] [G loss: 0.404420]\n",
      "epoch:21 step:19852 [D loss: 0.223151, acc.: 60.94%] [G loss: 0.434163]\n",
      "epoch:21 step:19853 [D loss: 0.229576, acc.: 57.81%] [G loss: 0.409248]\n",
      "epoch:21 step:19854 [D loss: 0.235947, acc.: 61.72%] [G loss: 0.385346]\n",
      "epoch:21 step:19855 [D loss: 0.227254, acc.: 64.06%] [G loss: 0.401497]\n",
      "epoch:21 step:19856 [D loss: 0.242938, acc.: 59.38%] [G loss: 0.404785]\n",
      "epoch:21 step:19857 [D loss: 0.247205, acc.: 57.03%] [G loss: 0.404818]\n",
      "epoch:21 step:19858 [D loss: 0.232786, acc.: 55.47%] [G loss: 0.407191]\n",
      "epoch:21 step:19859 [D loss: 0.236575, acc.: 54.69%] [G loss: 0.426201]\n",
      "epoch:21 step:19860 [D loss: 0.245294, acc.: 55.47%] [G loss: 0.415388]\n",
      "epoch:21 step:19861 [D loss: 0.217293, acc.: 67.19%] [G loss: 0.442208]\n",
      "epoch:21 step:19862 [D loss: 0.213474, acc.: 64.06%] [G loss: 0.414850]\n",
      "epoch:21 step:19863 [D loss: 0.213687, acc.: 65.62%] [G loss: 0.432440]\n",
      "epoch:21 step:19864 [D loss: 0.231586, acc.: 64.06%] [G loss: 0.403086]\n",
      "epoch:21 step:19865 [D loss: 0.232983, acc.: 59.38%] [G loss: 0.424926]\n",
      "epoch:21 step:19866 [D loss: 0.249094, acc.: 56.25%] [G loss: 0.394391]\n",
      "epoch:21 step:19867 [D loss: 0.196243, acc.: 67.97%] [G loss: 0.445902]\n",
      "epoch:21 step:19868 [D loss: 0.222286, acc.: 64.84%] [G loss: 0.425336]\n",
      "epoch:21 step:19869 [D loss: 0.239898, acc.: 60.94%] [G loss: 0.444075]\n",
      "epoch:21 step:19870 [D loss: 0.216158, acc.: 65.62%] [G loss: 0.420058]\n",
      "epoch:21 step:19871 [D loss: 0.215330, acc.: 66.41%] [G loss: 0.429149]\n",
      "epoch:21 step:19872 [D loss: 0.233847, acc.: 60.16%] [G loss: 0.420141]\n",
      "epoch:21 step:19873 [D loss: 0.245686, acc.: 56.25%] [G loss: 0.439058]\n",
      "epoch:21 step:19874 [D loss: 0.203163, acc.: 70.31%] [G loss: 0.427409]\n",
      "epoch:21 step:19875 [D loss: 0.192925, acc.: 71.09%] [G loss: 0.442412]\n",
      "epoch:21 step:19876 [D loss: 0.235119, acc.: 61.72%] [G loss: 0.384437]\n",
      "epoch:21 step:19877 [D loss: 0.246175, acc.: 56.25%] [G loss: 0.431441]\n",
      "epoch:21 step:19878 [D loss: 0.232411, acc.: 62.50%] [G loss: 0.406383]\n",
      "epoch:21 step:19879 [D loss: 0.251174, acc.: 54.69%] [G loss: 0.427702]\n",
      "epoch:21 step:19880 [D loss: 0.260720, acc.: 53.12%] [G loss: 0.423313]\n",
      "epoch:21 step:19881 [D loss: 0.260715, acc.: 55.47%] [G loss: 0.447018]\n",
      "epoch:21 step:19882 [D loss: 0.210898, acc.: 64.84%] [G loss: 0.479720]\n",
      "epoch:21 step:19883 [D loss: 0.226820, acc.: 60.94%] [G loss: 0.431110]\n",
      "epoch:21 step:19884 [D loss: 0.198405, acc.: 70.31%] [G loss: 0.476750]\n",
      "epoch:21 step:19885 [D loss: 0.203608, acc.: 65.62%] [G loss: 0.460139]\n",
      "epoch:21 step:19886 [D loss: 0.191087, acc.: 73.44%] [G loss: 0.483079]\n",
      "epoch:21 step:19887 [D loss: 0.248399, acc.: 56.25%] [G loss: 0.465041]\n",
      "epoch:21 step:19888 [D loss: 0.235302, acc.: 61.72%] [G loss: 0.414683]\n",
      "epoch:21 step:19889 [D loss: 0.235586, acc.: 56.25%] [G loss: 0.398808]\n",
      "epoch:21 step:19890 [D loss: 0.242610, acc.: 61.72%] [G loss: 0.402249]\n",
      "epoch:21 step:19891 [D loss: 0.264696, acc.: 52.34%] [G loss: 0.415170]\n",
      "epoch:21 step:19892 [D loss: 0.246766, acc.: 58.59%] [G loss: 0.388983]\n",
      "epoch:21 step:19893 [D loss: 0.211038, acc.: 67.19%] [G loss: 0.423328]\n",
      "epoch:21 step:19894 [D loss: 0.235855, acc.: 57.81%] [G loss: 0.413548]\n",
      "epoch:21 step:19895 [D loss: 0.198157, acc.: 70.31%] [G loss: 0.436118]\n",
      "epoch:21 step:19896 [D loss: 0.174387, acc.: 78.12%] [G loss: 0.469407]\n",
      "epoch:21 step:19897 [D loss: 0.276998, acc.: 54.69%] [G loss: 0.448657]\n",
      "epoch:21 step:19898 [D loss: 0.201626, acc.: 71.09%] [G loss: 0.440521]\n",
      "epoch:21 step:19899 [D loss: 0.220867, acc.: 64.06%] [G loss: 0.398369]\n",
      "epoch:21 step:19900 [D loss: 0.191724, acc.: 70.31%] [G loss: 0.457792]\n",
      "epoch:21 step:19901 [D loss: 0.263980, acc.: 58.59%] [G loss: 0.411358]\n",
      "epoch:21 step:19902 [D loss: 0.231434, acc.: 60.94%] [G loss: 0.423812]\n",
      "epoch:21 step:19903 [D loss: 0.228747, acc.: 60.16%] [G loss: 0.384314]\n",
      "epoch:21 step:19904 [D loss: 0.234267, acc.: 60.16%] [G loss: 0.381448]\n",
      "epoch:21 step:19905 [D loss: 0.245691, acc.: 61.72%] [G loss: 0.410157]\n",
      "epoch:21 step:19906 [D loss: 0.190996, acc.: 73.44%] [G loss: 0.427557]\n",
      "epoch:21 step:19907 [D loss: 0.205081, acc.: 67.97%] [G loss: 0.453542]\n",
      "epoch:21 step:19908 [D loss: 0.176270, acc.: 75.00%] [G loss: 0.521825]\n",
      "epoch:21 step:19909 [D loss: 0.159096, acc.: 78.12%] [G loss: 0.540071]\n",
      "epoch:21 step:19910 [D loss: 0.270378, acc.: 57.03%] [G loss: 0.452450]\n",
      "epoch:21 step:19911 [D loss: 0.239674, acc.: 63.28%] [G loss: 0.461276]\n",
      "epoch:21 step:19912 [D loss: 0.232286, acc.: 60.16%] [G loss: 0.446524]\n",
      "epoch:21 step:19913 [D loss: 0.218594, acc.: 64.06%] [G loss: 0.434851]\n",
      "epoch:21 step:19914 [D loss: 0.224173, acc.: 68.75%] [G loss: 0.383463]\n",
      "epoch:21 step:19915 [D loss: 0.221247, acc.: 64.84%] [G loss: 0.387963]\n",
      "epoch:21 step:19916 [D loss: 0.207373, acc.: 66.41%] [G loss: 0.390204]\n",
      "epoch:21 step:19917 [D loss: 0.221153, acc.: 64.84%] [G loss: 0.398987]\n",
      "epoch:21 step:19918 [D loss: 0.200224, acc.: 67.19%] [G loss: 0.432013]\n",
      "epoch:21 step:19919 [D loss: 0.214011, acc.: 69.53%] [G loss: 0.454709]\n",
      "epoch:21 step:19920 [D loss: 0.201910, acc.: 66.41%] [G loss: 0.462602]\n",
      "epoch:21 step:19921 [D loss: 0.228147, acc.: 64.84%] [G loss: 0.436208]\n",
      "epoch:21 step:19922 [D loss: 0.207926, acc.: 64.06%] [G loss: 0.432459]\n",
      "epoch:21 step:19923 [D loss: 0.228120, acc.: 61.72%] [G loss: 0.431106]\n",
      "epoch:21 step:19924 [D loss: 0.219351, acc.: 64.06%] [G loss: 0.478506]\n",
      "epoch:21 step:19925 [D loss: 0.193167, acc.: 68.75%] [G loss: 0.488123]\n",
      "epoch:21 step:19926 [D loss: 0.283848, acc.: 53.12%] [G loss: 0.438317]\n",
      "epoch:21 step:19927 [D loss: 0.257263, acc.: 60.16%] [G loss: 0.421258]\n",
      "epoch:21 step:19928 [D loss: 0.246539, acc.: 61.72%] [G loss: 0.431506]\n",
      "epoch:21 step:19929 [D loss: 0.216620, acc.: 67.19%] [G loss: 0.432670]\n",
      "epoch:21 step:19930 [D loss: 0.227081, acc.: 60.94%] [G loss: 0.440859]\n",
      "epoch:21 step:19931 [D loss: 0.235566, acc.: 60.16%] [G loss: 0.393616]\n",
      "epoch:21 step:19932 [D loss: 0.221612, acc.: 59.38%] [G loss: 0.461489]\n",
      "epoch:21 step:19933 [D loss: 0.209563, acc.: 66.41%] [G loss: 0.431091]\n",
      "epoch:21 step:19934 [D loss: 0.232637, acc.: 61.72%] [G loss: 0.425789]\n",
      "epoch:21 step:19935 [D loss: 0.192866, acc.: 71.88%] [G loss: 0.444292]\n",
      "epoch:21 step:19936 [D loss: 0.203958, acc.: 68.75%] [G loss: 0.479902]\n",
      "epoch:21 step:19937 [D loss: 0.224050, acc.: 64.06%] [G loss: 0.443551]\n",
      "epoch:21 step:19938 [D loss: 0.234449, acc.: 61.72%] [G loss: 0.453774]\n",
      "epoch:21 step:19939 [D loss: 0.222655, acc.: 65.62%] [G loss: 0.464322]\n",
      "epoch:21 step:19940 [D loss: 0.236038, acc.: 60.16%] [G loss: 0.446434]\n",
      "epoch:21 step:19941 [D loss: 0.227272, acc.: 60.16%] [G loss: 0.447157]\n",
      "epoch:21 step:19942 [D loss: 0.239589, acc.: 60.94%] [G loss: 0.456294]\n",
      "epoch:21 step:19943 [D loss: 0.251376, acc.: 53.91%] [G loss: 0.413260]\n",
      "epoch:21 step:19944 [D loss: 0.212760, acc.: 69.53%] [G loss: 0.437507]\n",
      "epoch:21 step:19945 [D loss: 0.210629, acc.: 67.19%] [G loss: 0.453206]\n",
      "epoch:21 step:19946 [D loss: 0.209469, acc.: 64.84%] [G loss: 0.485131]\n",
      "epoch:21 step:19947 [D loss: 0.232581, acc.: 64.06%] [G loss: 0.444988]\n",
      "epoch:21 step:19948 [D loss: 0.209167, acc.: 71.09%] [G loss: 0.466845]\n",
      "epoch:21 step:19949 [D loss: 0.205954, acc.: 68.75%] [G loss: 0.454375]\n",
      "epoch:21 step:19950 [D loss: 0.215026, acc.: 64.84%] [G loss: 0.422430]\n",
      "epoch:21 step:19951 [D loss: 0.196507, acc.: 67.97%] [G loss: 0.460888]\n",
      "epoch:21 step:19952 [D loss: 0.219742, acc.: 64.84%] [G loss: 0.410708]\n",
      "epoch:21 step:19953 [D loss: 0.212455, acc.: 64.06%] [G loss: 0.449406]\n",
      "epoch:21 step:19954 [D loss: 0.234461, acc.: 55.47%] [G loss: 0.448753]\n",
      "epoch:21 step:19955 [D loss: 0.261523, acc.: 52.34%] [G loss: 0.431705]\n",
      "epoch:21 step:19956 [D loss: 0.234206, acc.: 59.38%] [G loss: 0.431947]\n",
      "epoch:21 step:19957 [D loss: 0.223723, acc.: 64.84%] [G loss: 0.453021]\n",
      "epoch:21 step:19958 [D loss: 0.247282, acc.: 54.69%] [G loss: 0.411380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19959 [D loss: 0.239595, acc.: 59.38%] [G loss: 0.394388]\n",
      "epoch:21 step:19960 [D loss: 0.188120, acc.: 73.44%] [G loss: 0.436541]\n",
      "epoch:21 step:19961 [D loss: 0.238510, acc.: 62.50%] [G loss: 0.405118]\n",
      "epoch:21 step:19962 [D loss: 0.227238, acc.: 62.50%] [G loss: 0.403231]\n",
      "epoch:21 step:19963 [D loss: 0.209514, acc.: 67.97%] [G loss: 0.455252]\n",
      "epoch:21 step:19964 [D loss: 0.242187, acc.: 60.16%] [G loss: 0.416088]\n",
      "epoch:21 step:19965 [D loss: 0.210134, acc.: 65.62%] [G loss: 0.449118]\n",
      "epoch:21 step:19966 [D loss: 0.213564, acc.: 67.19%] [G loss: 0.438594]\n",
      "epoch:21 step:19967 [D loss: 0.215620, acc.: 64.06%] [G loss: 0.489343]\n",
      "epoch:21 step:19968 [D loss: 0.262724, acc.: 50.00%] [G loss: 0.419024]\n",
      "epoch:21 step:19969 [D loss: 0.209519, acc.: 67.19%] [G loss: 0.427631]\n",
      "epoch:21 step:19970 [D loss: 0.228557, acc.: 56.25%] [G loss: 0.412780]\n",
      "epoch:21 step:19971 [D loss: 0.226317, acc.: 59.38%] [G loss: 0.442609]\n",
      "epoch:21 step:19972 [D loss: 0.217653, acc.: 64.06%] [G loss: 0.443519]\n",
      "epoch:21 step:19973 [D loss: 0.196340, acc.: 68.75%] [G loss: 0.437225]\n",
      "epoch:21 step:19974 [D loss: 0.226695, acc.: 58.59%] [G loss: 0.430805]\n",
      "epoch:21 step:19975 [D loss: 0.211012, acc.: 66.41%] [G loss: 0.475217]\n",
      "epoch:21 step:19976 [D loss: 0.195473, acc.: 69.53%] [G loss: 0.433319]\n",
      "epoch:21 step:19977 [D loss: 0.217626, acc.: 65.62%] [G loss: 0.446524]\n",
      "epoch:21 step:19978 [D loss: 0.262097, acc.: 57.03%] [G loss: 0.449960]\n",
      "epoch:21 step:19979 [D loss: 0.226009, acc.: 66.41%] [G loss: 0.442243]\n",
      "epoch:21 step:19980 [D loss: 0.231516, acc.: 64.06%] [G loss: 0.448062]\n",
      "epoch:21 step:19981 [D loss: 0.228966, acc.: 58.59%] [G loss: 0.454663]\n",
      "epoch:21 step:19982 [D loss: 0.215514, acc.: 65.62%] [G loss: 0.410842]\n",
      "epoch:21 step:19983 [D loss: 0.205403, acc.: 65.62%] [G loss: 0.404768]\n",
      "epoch:21 step:19984 [D loss: 0.201253, acc.: 72.66%] [G loss: 0.425746]\n",
      "epoch:21 step:19985 [D loss: 0.232035, acc.: 59.38%] [G loss: 0.428366]\n",
      "epoch:21 step:19986 [D loss: 0.205301, acc.: 62.50%] [G loss: 0.469892]\n",
      "epoch:21 step:19987 [D loss: 0.247796, acc.: 58.59%] [G loss: 0.402909]\n",
      "epoch:21 step:19988 [D loss: 0.226047, acc.: 68.75%] [G loss: 0.421096]\n",
      "epoch:21 step:19989 [D loss: 0.195489, acc.: 70.31%] [G loss: 0.442508]\n",
      "epoch:21 step:19990 [D loss: 0.209523, acc.: 61.72%] [G loss: 0.481025]\n",
      "epoch:21 step:19991 [D loss: 0.189939, acc.: 67.19%] [G loss: 0.519090]\n",
      "epoch:21 step:19992 [D loss: 0.187912, acc.: 67.97%] [G loss: 0.500853]\n",
      "epoch:21 step:19993 [D loss: 0.263754, acc.: 55.47%] [G loss: 0.450652]\n",
      "epoch:21 step:19994 [D loss: 0.240509, acc.: 56.25%] [G loss: 0.410672]\n",
      "epoch:21 step:19995 [D loss: 0.202449, acc.: 68.75%] [G loss: 0.471831]\n",
      "epoch:21 step:19996 [D loss: 0.230073, acc.: 55.47%] [G loss: 0.495446]\n",
      "epoch:21 step:19997 [D loss: 0.218657, acc.: 66.41%] [G loss: 0.451760]\n",
      "epoch:21 step:19998 [D loss: 0.196140, acc.: 62.50%] [G loss: 0.484288]\n",
      "epoch:21 step:19999 [D loss: 0.200391, acc.: 65.62%] [G loss: 0.483813]\n",
      "epoch:21 step:20000 [D loss: 0.259601, acc.: 59.38%] [G loss: 0.451071]\n",
      "epoch:21 step:20001 [D loss: 0.221155, acc.: 64.84%] [G loss: 0.435571]\n",
      "epoch:21 step:20002 [D loss: 0.220586, acc.: 64.84%] [G loss: 0.422931]\n",
      "epoch:21 step:20003 [D loss: 0.201333, acc.: 71.09%] [G loss: 0.446853]\n",
      "epoch:21 step:20004 [D loss: 0.234728, acc.: 59.38%] [G loss: 0.446061]\n",
      "epoch:21 step:20005 [D loss: 0.215069, acc.: 66.41%] [G loss: 0.478123]\n",
      "epoch:21 step:20006 [D loss: 0.243578, acc.: 55.47%] [G loss: 0.443341]\n",
      "epoch:21 step:20007 [D loss: 0.228236, acc.: 62.50%] [G loss: 0.464475]\n",
      "epoch:21 step:20008 [D loss: 0.210244, acc.: 64.84%] [G loss: 0.450271]\n",
      "epoch:21 step:20009 [D loss: 0.204711, acc.: 65.62%] [G loss: 0.432901]\n",
      "epoch:21 step:20010 [D loss: 0.210683, acc.: 68.75%] [G loss: 0.407305]\n",
      "epoch:21 step:20011 [D loss: 0.220301, acc.: 64.84%] [G loss: 0.463324]\n",
      "epoch:21 step:20012 [D loss: 0.201762, acc.: 65.62%] [G loss: 0.484314]\n",
      "epoch:21 step:20013 [D loss: 0.182030, acc.: 76.56%] [G loss: 0.446123]\n",
      "epoch:21 step:20014 [D loss: 0.238611, acc.: 60.16%] [G loss: 0.408166]\n",
      "epoch:21 step:20015 [D loss: 0.209496, acc.: 64.84%] [G loss: 0.440884]\n",
      "epoch:21 step:20016 [D loss: 0.216479, acc.: 67.97%] [G loss: 0.475752]\n",
      "epoch:21 step:20017 [D loss: 0.226032, acc.: 61.72%] [G loss: 0.426396]\n",
      "epoch:21 step:20018 [D loss: 0.265993, acc.: 53.12%] [G loss: 0.467548]\n",
      "epoch:21 step:20019 [D loss: 0.238578, acc.: 57.03%] [G loss: 0.473780]\n",
      "epoch:21 step:20020 [D loss: 0.250092, acc.: 56.25%] [G loss: 0.447119]\n",
      "epoch:21 step:20021 [D loss: 0.202755, acc.: 66.41%] [G loss: 0.465847]\n",
      "epoch:21 step:20022 [D loss: 0.197802, acc.: 69.53%] [G loss: 0.473143]\n",
      "epoch:21 step:20023 [D loss: 0.181537, acc.: 74.22%] [G loss: 0.522841]\n",
      "epoch:21 step:20024 [D loss: 0.179689, acc.: 70.31%] [G loss: 0.528093]\n",
      "epoch:21 step:20025 [D loss: 0.272270, acc.: 56.25%] [G loss: 0.433673]\n",
      "epoch:21 step:20026 [D loss: 0.280191, acc.: 46.88%] [G loss: 0.417037]\n",
      "epoch:21 step:20027 [D loss: 0.213864, acc.: 66.41%] [G loss: 0.432266]\n",
      "epoch:21 step:20028 [D loss: 0.239037, acc.: 60.16%] [G loss: 0.402182]\n",
      "epoch:21 step:20029 [D loss: 0.236613, acc.: 54.69%] [G loss: 0.415703]\n",
      "epoch:21 step:20030 [D loss: 0.229055, acc.: 64.06%] [G loss: 0.433755]\n",
      "epoch:21 step:20031 [D loss: 0.209678, acc.: 67.19%] [G loss: 0.474158]\n",
      "epoch:21 step:20032 [D loss: 0.232437, acc.: 61.72%] [G loss: 0.452000]\n",
      "epoch:21 step:20033 [D loss: 0.239739, acc.: 56.25%] [G loss: 0.432761]\n",
      "epoch:21 step:20034 [D loss: 0.190348, acc.: 68.75%] [G loss: 0.457290]\n",
      "epoch:21 step:20035 [D loss: 0.188306, acc.: 68.75%] [G loss: 0.449557]\n",
      "epoch:21 step:20036 [D loss: 0.220805, acc.: 64.06%] [G loss: 0.455202]\n",
      "epoch:21 step:20037 [D loss: 0.206891, acc.: 64.84%] [G loss: 0.474439]\n",
      "epoch:21 step:20038 [D loss: 0.173476, acc.: 77.34%] [G loss: 0.476746]\n",
      "epoch:21 step:20039 [D loss: 0.235874, acc.: 59.38%] [G loss: 0.422237]\n",
      "epoch:21 step:20040 [D loss: 0.211596, acc.: 61.72%] [G loss: 0.435991]\n",
      "epoch:21 step:20041 [D loss: 0.210709, acc.: 65.62%] [G loss: 0.422281]\n",
      "epoch:21 step:20042 [D loss: 0.226604, acc.: 63.28%] [G loss: 0.399921]\n",
      "epoch:21 step:20043 [D loss: 0.221288, acc.: 65.62%] [G loss: 0.449788]\n",
      "epoch:21 step:20044 [D loss: 0.216633, acc.: 65.62%] [G loss: 0.477506]\n",
      "epoch:21 step:20045 [D loss: 0.238472, acc.: 59.38%] [G loss: 0.447296]\n",
      "epoch:21 step:20046 [D loss: 0.230580, acc.: 60.94%] [G loss: 0.371742]\n",
      "epoch:21 step:20047 [D loss: 0.204842, acc.: 67.19%] [G loss: 0.447458]\n",
      "epoch:21 step:20048 [D loss: 0.198620, acc.: 72.66%] [G loss: 0.459489]\n",
      "epoch:21 step:20049 [D loss: 0.220306, acc.: 61.72%] [G loss: 0.479211]\n",
      "epoch:21 step:20050 [D loss: 0.240644, acc.: 60.16%] [G loss: 0.420173]\n",
      "epoch:21 step:20051 [D loss: 0.170942, acc.: 77.34%] [G loss: 0.474035]\n",
      "epoch:21 step:20052 [D loss: 0.245441, acc.: 57.81%] [G loss: 0.446220]\n",
      "epoch:21 step:20053 [D loss: 0.244956, acc.: 61.72%] [G loss: 0.434017]\n",
      "epoch:21 step:20054 [D loss: 0.259309, acc.: 45.31%] [G loss: 0.420314]\n",
      "epoch:21 step:20055 [D loss: 0.238355, acc.: 58.59%] [G loss: 0.393684]\n",
      "epoch:21 step:20056 [D loss: 0.230028, acc.: 61.72%] [G loss: 0.418399]\n",
      "epoch:21 step:20057 [D loss: 0.238483, acc.: 53.91%] [G loss: 0.421801]\n",
      "epoch:21 step:20058 [D loss: 0.233683, acc.: 58.59%] [G loss: 0.437053]\n",
      "epoch:21 step:20059 [D loss: 0.237687, acc.: 60.94%] [G loss: 0.413010]\n",
      "epoch:21 step:20060 [D loss: 0.204401, acc.: 67.19%] [G loss: 0.487969]\n",
      "epoch:21 step:20061 [D loss: 0.211465, acc.: 63.28%] [G loss: 0.400032]\n",
      "epoch:21 step:20062 [D loss: 0.193660, acc.: 70.31%] [G loss: 0.451429]\n",
      "epoch:21 step:20063 [D loss: 0.228710, acc.: 58.59%] [G loss: 0.421723]\n",
      "epoch:21 step:20064 [D loss: 0.219235, acc.: 64.84%] [G loss: 0.410476]\n",
      "epoch:21 step:20065 [D loss: 0.201742, acc.: 72.66%] [G loss: 0.447147]\n",
      "epoch:21 step:20066 [D loss: 0.211680, acc.: 67.19%] [G loss: 0.417409]\n",
      "epoch:21 step:20067 [D loss: 0.245462, acc.: 59.38%] [G loss: 0.433219]\n",
      "epoch:21 step:20068 [D loss: 0.237341, acc.: 59.38%] [G loss: 0.422124]\n",
      "epoch:21 step:20069 [D loss: 0.224596, acc.: 60.94%] [G loss: 0.443485]\n",
      "epoch:21 step:20070 [D loss: 0.234116, acc.: 64.84%] [G loss: 0.429219]\n",
      "epoch:21 step:20071 [D loss: 0.229773, acc.: 61.72%] [G loss: 0.448032]\n",
      "epoch:21 step:20072 [D loss: 0.227723, acc.: 59.38%] [G loss: 0.438777]\n",
      "epoch:21 step:20073 [D loss: 0.255782, acc.: 53.91%] [G loss: 0.434064]\n",
      "epoch:21 step:20074 [D loss: 0.232318, acc.: 66.41%] [G loss: 0.459096]\n",
      "epoch:21 step:20075 [D loss: 0.199690, acc.: 66.41%] [G loss: 0.478253]\n",
      "epoch:21 step:20076 [D loss: 0.218638, acc.: 67.19%] [G loss: 0.480504]\n",
      "epoch:21 step:20077 [D loss: 0.265871, acc.: 46.88%] [G loss: 0.435110]\n",
      "epoch:21 step:20078 [D loss: 0.241570, acc.: 57.81%] [G loss: 0.463566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20079 [D loss: 0.226111, acc.: 64.06%] [G loss: 0.472795]\n",
      "epoch:21 step:20080 [D loss: 0.225967, acc.: 64.84%] [G loss: 0.399604]\n",
      "epoch:21 step:20081 [D loss: 0.209713, acc.: 61.72%] [G loss: 0.444993]\n",
      "epoch:21 step:20082 [D loss: 0.221323, acc.: 68.75%] [G loss: 0.493361]\n",
      "epoch:21 step:20083 [D loss: 0.224712, acc.: 60.94%] [G loss: 0.459293]\n",
      "epoch:21 step:20084 [D loss: 0.229122, acc.: 64.06%] [G loss: 0.489958]\n",
      "epoch:21 step:20085 [D loss: 0.251509, acc.: 58.59%] [G loss: 0.440472]\n",
      "epoch:21 step:20086 [D loss: 0.213368, acc.: 67.97%] [G loss: 0.445795]\n",
      "epoch:21 step:20087 [D loss: 0.228807, acc.: 60.16%] [G loss: 0.412123]\n",
      "epoch:21 step:20088 [D loss: 0.268624, acc.: 54.69%] [G loss: 0.378582]\n",
      "epoch:21 step:20089 [D loss: 0.230308, acc.: 62.50%] [G loss: 0.417493]\n",
      "epoch:21 step:20090 [D loss: 0.249615, acc.: 58.59%] [G loss: 0.420612]\n",
      "epoch:21 step:20091 [D loss: 0.212920, acc.: 70.31%] [G loss: 0.448077]\n",
      "epoch:21 step:20092 [D loss: 0.191146, acc.: 70.31%] [G loss: 0.459515]\n",
      "epoch:21 step:20093 [D loss: 0.188590, acc.: 69.53%] [G loss: 0.513241]\n",
      "epoch:21 step:20094 [D loss: 0.233992, acc.: 61.72%] [G loss: 0.482571]\n",
      "epoch:21 step:20095 [D loss: 0.263923, acc.: 52.34%] [G loss: 0.393513]\n",
      "epoch:21 step:20096 [D loss: 0.244030, acc.: 57.81%] [G loss: 0.389828]\n",
      "epoch:21 step:20097 [D loss: 0.215326, acc.: 64.06%] [G loss: 0.417805]\n",
      "epoch:21 step:20098 [D loss: 0.239425, acc.: 61.72%] [G loss: 0.421939]\n",
      "epoch:21 step:20099 [D loss: 0.227162, acc.: 65.62%] [G loss: 0.425300]\n",
      "epoch:21 step:20100 [D loss: 0.246620, acc.: 57.03%] [G loss: 0.412319]\n",
      "epoch:21 step:20101 [D loss: 0.231009, acc.: 58.59%] [G loss: 0.437610]\n",
      "epoch:21 step:20102 [D loss: 0.212014, acc.: 71.88%] [G loss: 0.463917]\n",
      "epoch:21 step:20103 [D loss: 0.222120, acc.: 60.16%] [G loss: 0.453423]\n",
      "epoch:21 step:20104 [D loss: 0.233693, acc.: 61.72%] [G loss: 0.480360]\n",
      "epoch:21 step:20105 [D loss: 0.195602, acc.: 68.75%] [G loss: 0.466508]\n",
      "epoch:21 step:20106 [D loss: 0.203234, acc.: 69.53%] [G loss: 0.450838]\n",
      "epoch:21 step:20107 [D loss: 0.205761, acc.: 66.41%] [G loss: 0.486829]\n",
      "epoch:21 step:20108 [D loss: 0.234742, acc.: 60.16%] [G loss: 0.442936]\n",
      "epoch:21 step:20109 [D loss: 0.236982, acc.: 58.59%] [G loss: 0.413543]\n",
      "epoch:21 step:20110 [D loss: 0.214330, acc.: 64.84%] [G loss: 0.441128]\n",
      "epoch:21 step:20111 [D loss: 0.230456, acc.: 63.28%] [G loss: 0.415842]\n",
      "epoch:21 step:20112 [D loss: 0.201520, acc.: 71.09%] [G loss: 0.462913]\n",
      "epoch:21 step:20113 [D loss: 0.168056, acc.: 76.56%] [G loss: 0.477340]\n",
      "epoch:21 step:20114 [D loss: 0.263173, acc.: 55.47%] [G loss: 0.442757]\n",
      "epoch:21 step:20115 [D loss: 0.253867, acc.: 53.91%] [G loss: 0.390263]\n",
      "epoch:21 step:20116 [D loss: 0.238284, acc.: 59.38%] [G loss: 0.459690]\n",
      "epoch:21 step:20117 [D loss: 0.228844, acc.: 61.72%] [G loss: 0.428107]\n",
      "epoch:21 step:20118 [D loss: 0.237466, acc.: 58.59%] [G loss: 0.416459]\n",
      "epoch:21 step:20119 [D loss: 0.214483, acc.: 65.62%] [G loss: 0.480095]\n",
      "epoch:21 step:20120 [D loss: 0.260105, acc.: 51.56%] [G loss: 0.432353]\n",
      "epoch:21 step:20121 [D loss: 0.242702, acc.: 57.81%] [G loss: 0.438372]\n",
      "epoch:21 step:20122 [D loss: 0.218316, acc.: 64.84%] [G loss: 0.457436]\n",
      "epoch:21 step:20123 [D loss: 0.230860, acc.: 65.62%] [G loss: 0.449813]\n",
      "epoch:21 step:20124 [D loss: 0.246417, acc.: 59.38%] [G loss: 0.419956]\n",
      "epoch:21 step:20125 [D loss: 0.249274, acc.: 57.03%] [G loss: 0.426299]\n",
      "epoch:21 step:20126 [D loss: 0.250895, acc.: 55.47%] [G loss: 0.432388]\n",
      "epoch:21 step:20127 [D loss: 0.195570, acc.: 70.31%] [G loss: 0.407273]\n",
      "epoch:21 step:20128 [D loss: 0.204622, acc.: 67.97%] [G loss: 0.444588]\n",
      "epoch:21 step:20129 [D loss: 0.257996, acc.: 51.56%] [G loss: 0.413679]\n",
      "epoch:21 step:20130 [D loss: 0.206217, acc.: 62.50%] [G loss: 0.457023]\n",
      "epoch:21 step:20131 [D loss: 0.219570, acc.: 65.62%] [G loss: 0.461553]\n",
      "epoch:21 step:20132 [D loss: 0.259519, acc.: 56.25%] [G loss: 0.442457]\n",
      "epoch:21 step:20133 [D loss: 0.222873, acc.: 64.06%] [G loss: 0.445189]\n",
      "epoch:21 step:20134 [D loss: 0.201674, acc.: 75.78%] [G loss: 0.481414]\n",
      "epoch:21 step:20135 [D loss: 0.291750, acc.: 50.78%] [G loss: 0.445214]\n",
      "epoch:21 step:20136 [D loss: 0.226704, acc.: 64.06%] [G loss: 0.408854]\n",
      "epoch:21 step:20137 [D loss: 0.223895, acc.: 58.59%] [G loss: 0.389019]\n",
      "epoch:21 step:20138 [D loss: 0.237232, acc.: 57.03%] [G loss: 0.409378]\n",
      "epoch:21 step:20139 [D loss: 0.231658, acc.: 60.94%] [G loss: 0.399393]\n",
      "epoch:21 step:20140 [D loss: 0.244949, acc.: 55.47%] [G loss: 0.407837]\n",
      "epoch:21 step:20141 [D loss: 0.214403, acc.: 68.75%] [G loss: 0.443635]\n",
      "epoch:21 step:20142 [D loss: 0.254588, acc.: 50.00%] [G loss: 0.384167]\n",
      "epoch:21 step:20143 [D loss: 0.202611, acc.: 71.88%] [G loss: 0.436223]\n",
      "epoch:21 step:20144 [D loss: 0.213692, acc.: 66.41%] [G loss: 0.413721]\n",
      "epoch:21 step:20145 [D loss: 0.212916, acc.: 65.62%] [G loss: 0.457532]\n",
      "epoch:21 step:20146 [D loss: 0.218405, acc.: 65.62%] [G loss: 0.453405]\n",
      "epoch:21 step:20147 [D loss: 0.226398, acc.: 61.72%] [G loss: 0.470434]\n",
      "epoch:21 step:20148 [D loss: 0.180807, acc.: 73.44%] [G loss: 0.531569]\n",
      "epoch:21 step:20149 [D loss: 0.206483, acc.: 70.31%] [G loss: 0.514427]\n",
      "epoch:21 step:20150 [D loss: 0.259215, acc.: 56.25%] [G loss: 0.446353]\n",
      "epoch:21 step:20151 [D loss: 0.203812, acc.: 72.66%] [G loss: 0.456145]\n",
      "epoch:21 step:20152 [D loss: 0.202092, acc.: 72.66%] [G loss: 0.443646]\n",
      "epoch:21 step:20153 [D loss: 0.216399, acc.: 62.50%] [G loss: 0.471780]\n",
      "epoch:21 step:20154 [D loss: 0.266410, acc.: 50.78%] [G loss: 0.423410]\n",
      "epoch:21 step:20155 [D loss: 0.219476, acc.: 66.41%] [G loss: 0.431852]\n",
      "epoch:21 step:20156 [D loss: 0.215731, acc.: 66.41%] [G loss: 0.417460]\n",
      "epoch:21 step:20157 [D loss: 0.241626, acc.: 60.16%] [G loss: 0.419797]\n",
      "epoch:21 step:20158 [D loss: 0.186047, acc.: 74.22%] [G loss: 0.458580]\n",
      "epoch:21 step:20159 [D loss: 0.249547, acc.: 58.59%] [G loss: 0.440627]\n",
      "epoch:21 step:20160 [D loss: 0.255435, acc.: 54.69%] [G loss: 0.402794]\n",
      "epoch:21 step:20161 [D loss: 0.202438, acc.: 71.09%] [G loss: 0.483678]\n",
      "epoch:21 step:20162 [D loss: 0.215642, acc.: 64.06%] [G loss: 0.453922]\n",
      "epoch:21 step:20163 [D loss: 0.233427, acc.: 60.16%] [G loss: 0.463693]\n",
      "epoch:21 step:20164 [D loss: 0.235198, acc.: 57.81%] [G loss: 0.434291]\n",
      "epoch:21 step:20165 [D loss: 0.186542, acc.: 72.66%] [G loss: 0.436056]\n",
      "epoch:21 step:20166 [D loss: 0.214545, acc.: 64.06%] [G loss: 0.433569]\n",
      "epoch:21 step:20167 [D loss: 0.244052, acc.: 60.94%] [G loss: 0.413575]\n",
      "epoch:21 step:20168 [D loss: 0.226398, acc.: 64.84%] [G loss: 0.425351]\n",
      "epoch:21 step:20169 [D loss: 0.220175, acc.: 66.41%] [G loss: 0.428311]\n",
      "epoch:21 step:20170 [D loss: 0.227021, acc.: 61.72%] [G loss: 0.433602]\n",
      "epoch:21 step:20171 [D loss: 0.218899, acc.: 64.06%] [G loss: 0.419041]\n",
      "epoch:21 step:20172 [D loss: 0.192584, acc.: 71.09%] [G loss: 0.466901]\n",
      "epoch:21 step:20173 [D loss: 0.208409, acc.: 64.06%] [G loss: 0.473352]\n",
      "epoch:21 step:20174 [D loss: 0.232497, acc.: 63.28%] [G loss: 0.427109]\n",
      "epoch:21 step:20175 [D loss: 0.182314, acc.: 74.22%] [G loss: 0.491647]\n",
      "epoch:21 step:20176 [D loss: 0.186449, acc.: 75.00%] [G loss: 0.454840]\n",
      "epoch:21 step:20177 [D loss: 0.256664, acc.: 60.16%] [G loss: 0.416871]\n",
      "epoch:21 step:20178 [D loss: 0.266724, acc.: 48.44%] [G loss: 0.410747]\n",
      "epoch:21 step:20179 [D loss: 0.228387, acc.: 60.94%] [G loss: 0.412860]\n",
      "epoch:21 step:20180 [D loss: 0.229135, acc.: 57.81%] [G loss: 0.422622]\n",
      "epoch:21 step:20181 [D loss: 0.216529, acc.: 65.62%] [G loss: 0.442618]\n",
      "epoch:21 step:20182 [D loss: 0.190657, acc.: 70.31%] [G loss: 0.452372]\n",
      "epoch:21 step:20183 [D loss: 0.232986, acc.: 62.50%] [G loss: 0.431773]\n",
      "epoch:21 step:20184 [D loss: 0.215104, acc.: 63.28%] [G loss: 0.514139]\n",
      "epoch:21 step:20185 [D loss: 0.186155, acc.: 72.66%] [G loss: 0.541720]\n",
      "epoch:21 step:20186 [D loss: 0.276131, acc.: 54.69%] [G loss: 0.445361]\n",
      "epoch:21 step:20187 [D loss: 0.230423, acc.: 64.84%] [G loss: 0.397093]\n",
      "epoch:21 step:20188 [D loss: 0.235879, acc.: 58.59%] [G loss: 0.424293]\n",
      "epoch:21 step:20189 [D loss: 0.227186, acc.: 61.72%] [G loss: 0.401365]\n",
      "epoch:21 step:20190 [D loss: 0.181955, acc.: 73.44%] [G loss: 0.469208]\n",
      "epoch:21 step:20191 [D loss: 0.234689, acc.: 63.28%] [G loss: 0.392997]\n",
      "epoch:21 step:20192 [D loss: 0.186964, acc.: 73.44%] [G loss: 0.475108]\n",
      "epoch:21 step:20193 [D loss: 0.202302, acc.: 69.53%] [G loss: 0.481701]\n",
      "epoch:21 step:20194 [D loss: 0.255550, acc.: 56.25%] [G loss: 0.442422]\n",
      "epoch:21 step:20195 [D loss: 0.253581, acc.: 56.25%] [G loss: 0.429875]\n",
      "epoch:21 step:20196 [D loss: 0.210406, acc.: 64.84%] [G loss: 0.424979]\n",
      "epoch:21 step:20197 [D loss: 0.209221, acc.: 67.19%] [G loss: 0.463301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20198 [D loss: 0.193712, acc.: 69.53%] [G loss: 0.466704]\n",
      "epoch:21 step:20199 [D loss: 0.197121, acc.: 70.31%] [G loss: 0.458924]\n",
      "epoch:21 step:20200 [D loss: 0.174551, acc.: 74.22%] [G loss: 0.501267]\n",
      "epoch:21 step:20201 [D loss: 0.228709, acc.: 64.84%] [G loss: 0.433251]\n",
      "epoch:21 step:20202 [D loss: 0.218129, acc.: 66.41%] [G loss: 0.441561]\n",
      "epoch:21 step:20203 [D loss: 0.203863, acc.: 70.31%] [G loss: 0.454709]\n",
      "epoch:21 step:20204 [D loss: 0.218478, acc.: 66.41%] [G loss: 0.423522]\n",
      "epoch:21 step:20205 [D loss: 0.261826, acc.: 54.69%] [G loss: 0.406621]\n",
      "epoch:21 step:20206 [D loss: 0.266133, acc.: 53.12%] [G loss: 0.410475]\n",
      "epoch:21 step:20207 [D loss: 0.242034, acc.: 59.38%] [G loss: 0.423780]\n",
      "epoch:21 step:20208 [D loss: 0.230317, acc.: 59.38%] [G loss: 0.433446]\n",
      "epoch:21 step:20209 [D loss: 0.224788, acc.: 64.06%] [G loss: 0.400418]\n",
      "epoch:21 step:20210 [D loss: 0.248627, acc.: 54.69%] [G loss: 0.427323]\n",
      "epoch:21 step:20211 [D loss: 0.188925, acc.: 71.09%] [G loss: 0.474266]\n",
      "epoch:21 step:20212 [D loss: 0.228470, acc.: 57.81%] [G loss: 0.431125]\n",
      "epoch:21 step:20213 [D loss: 0.242032, acc.: 60.16%] [G loss: 0.418289]\n",
      "epoch:21 step:20214 [D loss: 0.246870, acc.: 58.59%] [G loss: 0.421250]\n",
      "epoch:21 step:20215 [D loss: 0.231987, acc.: 59.38%] [G loss: 0.436866]\n",
      "epoch:21 step:20216 [D loss: 0.223924, acc.: 68.75%] [G loss: 0.435944]\n",
      "epoch:21 step:20217 [D loss: 0.227156, acc.: 59.38%] [G loss: 0.489611]\n",
      "epoch:21 step:20218 [D loss: 0.238915, acc.: 60.16%] [G loss: 0.425018]\n",
      "epoch:21 step:20219 [D loss: 0.262939, acc.: 54.69%] [G loss: 0.423891]\n",
      "epoch:21 step:20220 [D loss: 0.233014, acc.: 60.16%] [G loss: 0.402505]\n",
      "epoch:21 step:20221 [D loss: 0.215167, acc.: 62.50%] [G loss: 0.440324]\n",
      "epoch:21 step:20222 [D loss: 0.236343, acc.: 58.59%] [G loss: 0.417840]\n",
      "epoch:21 step:20223 [D loss: 0.230459, acc.: 64.06%] [G loss: 0.429941]\n",
      "epoch:21 step:20224 [D loss: 0.228171, acc.: 63.28%] [G loss: 0.431185]\n",
      "epoch:21 step:20225 [D loss: 0.214064, acc.: 64.84%] [G loss: 0.461042]\n",
      "epoch:21 step:20226 [D loss: 0.205178, acc.: 66.41%] [G loss: 0.478498]\n",
      "epoch:21 step:20227 [D loss: 0.216086, acc.: 67.19%] [G loss: 0.474092]\n",
      "epoch:21 step:20228 [D loss: 0.191182, acc.: 71.09%] [G loss: 0.467506]\n",
      "epoch:21 step:20229 [D loss: 0.195801, acc.: 70.31%] [G loss: 0.465490]\n",
      "epoch:21 step:20230 [D loss: 0.252742, acc.: 59.38%] [G loss: 0.391965]\n",
      "epoch:21 step:20231 [D loss: 0.200858, acc.: 70.31%] [G loss: 0.395162]\n",
      "epoch:21 step:20232 [D loss: 0.196621, acc.: 68.75%] [G loss: 0.479128]\n",
      "epoch:21 step:20233 [D loss: 0.221034, acc.: 67.97%] [G loss: 0.440174]\n",
      "epoch:21 step:20234 [D loss: 0.220355, acc.: 69.53%] [G loss: 0.457466]\n",
      "epoch:21 step:20235 [D loss: 0.202855, acc.: 67.97%] [G loss: 0.452421]\n",
      "epoch:21 step:20236 [D loss: 0.251849, acc.: 51.56%] [G loss: 0.434061]\n",
      "epoch:21 step:20237 [D loss: 0.233751, acc.: 55.47%] [G loss: 0.444243]\n",
      "epoch:21 step:20238 [D loss: 0.213436, acc.: 64.84%] [G loss: 0.418801]\n",
      "epoch:21 step:20239 [D loss: 0.210596, acc.: 69.53%] [G loss: 0.426287]\n",
      "epoch:21 step:20240 [D loss: 0.215039, acc.: 67.19%] [G loss: 0.499088]\n",
      "epoch:21 step:20241 [D loss: 0.205277, acc.: 74.22%] [G loss: 0.500212]\n",
      "epoch:21 step:20242 [D loss: 0.250613, acc.: 54.69%] [G loss: 0.459980]\n",
      "epoch:21 step:20243 [D loss: 0.273314, acc.: 50.00%] [G loss: 0.421695]\n",
      "epoch:21 step:20244 [D loss: 0.235233, acc.: 60.16%] [G loss: 0.438762]\n",
      "epoch:21 step:20245 [D loss: 0.205316, acc.: 67.97%] [G loss: 0.444169]\n",
      "epoch:21 step:20246 [D loss: 0.240827, acc.: 60.16%] [G loss: 0.410635]\n",
      "epoch:21 step:20247 [D loss: 0.206077, acc.: 69.53%] [G loss: 0.393281]\n",
      "epoch:21 step:20248 [D loss: 0.204449, acc.: 68.75%] [G loss: 0.432039]\n",
      "epoch:21 step:20249 [D loss: 0.216255, acc.: 64.06%] [G loss: 0.477578]\n",
      "epoch:21 step:20250 [D loss: 0.246070, acc.: 58.59%] [G loss: 0.466049]\n",
      "epoch:21 step:20251 [D loss: 0.200837, acc.: 67.97%] [G loss: 0.473852]\n",
      "epoch:21 step:20252 [D loss: 0.222803, acc.: 61.72%] [G loss: 0.484276]\n",
      "epoch:21 step:20253 [D loss: 0.222832, acc.: 59.38%] [G loss: 0.456468]\n",
      "epoch:21 step:20254 [D loss: 0.232121, acc.: 58.59%] [G loss: 0.424695]\n",
      "epoch:21 step:20255 [D loss: 0.207974, acc.: 66.41%] [G loss: 0.401160]\n",
      "epoch:21 step:20256 [D loss: 0.248049, acc.: 53.91%] [G loss: 0.409984]\n",
      "epoch:21 step:20257 [D loss: 0.230328, acc.: 62.50%] [G loss: 0.439367]\n",
      "epoch:21 step:20258 [D loss: 0.202789, acc.: 70.31%] [G loss: 0.462641]\n",
      "epoch:21 step:20259 [D loss: 0.210900, acc.: 64.84%] [G loss: 0.494082]\n",
      "epoch:21 step:20260 [D loss: 0.203699, acc.: 63.28%] [G loss: 0.499066]\n",
      "epoch:21 step:20261 [D loss: 0.246886, acc.: 58.59%] [G loss: 0.436284]\n",
      "epoch:21 step:20262 [D loss: 0.223030, acc.: 60.94%] [G loss: 0.396707]\n",
      "epoch:21 step:20263 [D loss: 0.220792, acc.: 60.94%] [G loss: 0.469030]\n",
      "epoch:21 step:20264 [D loss: 0.236469, acc.: 60.94%] [G loss: 0.407436]\n",
      "epoch:21 step:20265 [D loss: 0.217423, acc.: 68.75%] [G loss: 0.450125]\n",
      "epoch:21 step:20266 [D loss: 0.211753, acc.: 64.84%] [G loss: 0.448386]\n",
      "epoch:21 step:20267 [D loss: 0.253825, acc.: 57.03%] [G loss: 0.443328]\n",
      "epoch:21 step:20268 [D loss: 0.226539, acc.: 64.84%] [G loss: 0.421031]\n",
      "epoch:21 step:20269 [D loss: 0.221703, acc.: 67.19%] [G loss: 0.456602]\n",
      "epoch:21 step:20270 [D loss: 0.236230, acc.: 55.47%] [G loss: 0.418754]\n",
      "epoch:21 step:20271 [D loss: 0.229943, acc.: 60.94%] [G loss: 0.403360]\n",
      "epoch:21 step:20272 [D loss: 0.211052, acc.: 67.97%] [G loss: 0.404138]\n",
      "epoch:21 step:20273 [D loss: 0.222685, acc.: 62.50%] [G loss: 0.418441]\n",
      "epoch:21 step:20274 [D loss: 0.255887, acc.: 53.12%] [G loss: 0.426336]\n",
      "epoch:21 step:20275 [D loss: 0.225941, acc.: 63.28%] [G loss: 0.420717]\n",
      "epoch:21 step:20276 [D loss: 0.223508, acc.: 66.41%] [G loss: 0.436881]\n",
      "epoch:21 step:20277 [D loss: 0.236591, acc.: 57.03%] [G loss: 0.431618]\n",
      "epoch:21 step:20278 [D loss: 0.225953, acc.: 60.16%] [G loss: 0.427297]\n",
      "epoch:21 step:20279 [D loss: 0.233037, acc.: 58.59%] [G loss: 0.427095]\n",
      "epoch:21 step:20280 [D loss: 0.218372, acc.: 70.31%] [G loss: 0.427823]\n",
      "epoch:21 step:20281 [D loss: 0.202853, acc.: 65.62%] [G loss: 0.443165]\n",
      "epoch:21 step:20282 [D loss: 0.207975, acc.: 67.97%] [G loss: 0.421025]\n",
      "epoch:21 step:20283 [D loss: 0.241537, acc.: 57.81%] [G loss: 0.399847]\n",
      "epoch:21 step:20284 [D loss: 0.232152, acc.: 59.38%] [G loss: 0.389712]\n",
      "epoch:21 step:20285 [D loss: 0.202667, acc.: 67.97%] [G loss: 0.431599]\n",
      "epoch:21 step:20286 [D loss: 0.231721, acc.: 57.81%] [G loss: 0.394868]\n",
      "epoch:21 step:20287 [D loss: 0.230133, acc.: 59.38%] [G loss: 0.433341]\n",
      "epoch:21 step:20288 [D loss: 0.231057, acc.: 57.81%] [G loss: 0.407491]\n",
      "epoch:21 step:20289 [D loss: 0.238967, acc.: 53.91%] [G loss: 0.411239]\n",
      "epoch:21 step:20290 [D loss: 0.231730, acc.: 60.16%] [G loss: 0.384120]\n",
      "epoch:21 step:20291 [D loss: 0.276073, acc.: 47.66%] [G loss: 0.356391]\n",
      "epoch:21 step:20292 [D loss: 0.252538, acc.: 56.25%] [G loss: 0.415356]\n",
      "epoch:21 step:20293 [D loss: 0.241590, acc.: 54.69%] [G loss: 0.410937]\n",
      "epoch:21 step:20294 [D loss: 0.237790, acc.: 58.59%] [G loss: 0.423345]\n",
      "epoch:21 step:20295 [D loss: 0.214186, acc.: 60.94%] [G loss: 0.459608]\n",
      "epoch:21 step:20296 [D loss: 0.232598, acc.: 62.50%] [G loss: 0.421996]\n",
      "epoch:21 step:20297 [D loss: 0.203114, acc.: 65.62%] [G loss: 0.393099]\n",
      "epoch:21 step:20298 [D loss: 0.207338, acc.: 68.75%] [G loss: 0.427292]\n",
      "epoch:21 step:20299 [D loss: 0.242527, acc.: 54.69%] [G loss: 0.407243]\n",
      "epoch:21 step:20300 [D loss: 0.233488, acc.: 65.62%] [G loss: 0.402830]\n",
      "epoch:21 step:20301 [D loss: 0.203045, acc.: 64.06%] [G loss: 0.444421]\n",
      "epoch:21 step:20302 [D loss: 0.241262, acc.: 60.16%] [G loss: 0.436217]\n",
      "epoch:21 step:20303 [D loss: 0.232504, acc.: 57.81%] [G loss: 0.422970]\n",
      "epoch:21 step:20304 [D loss: 0.224155, acc.: 62.50%] [G loss: 0.433757]\n",
      "epoch:21 step:20305 [D loss: 0.215005, acc.: 66.41%] [G loss: 0.437063]\n",
      "epoch:21 step:20306 [D loss: 0.203850, acc.: 71.88%] [G loss: 0.447340]\n",
      "epoch:21 step:20307 [D loss: 0.248211, acc.: 57.03%] [G loss: 0.423326]\n",
      "epoch:21 step:20308 [D loss: 0.214916, acc.: 64.84%] [G loss: 0.434367]\n",
      "epoch:21 step:20309 [D loss: 0.204433, acc.: 67.97%] [G loss: 0.449477]\n",
      "epoch:21 step:20310 [D loss: 0.209005, acc.: 68.75%] [G loss: 0.478084]\n",
      "epoch:21 step:20311 [D loss: 0.215904, acc.: 67.97%] [G loss: 0.470541]\n",
      "epoch:21 step:20312 [D loss: 0.213243, acc.: 64.84%] [G loss: 0.445503]\n",
      "epoch:21 step:20313 [D loss: 0.243664, acc.: 56.25%] [G loss: 0.409894]\n",
      "epoch:21 step:20314 [D loss: 0.213699, acc.: 66.41%] [G loss: 0.404367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20315 [D loss: 0.212198, acc.: 65.62%] [G loss: 0.413887]\n",
      "epoch:21 step:20316 [D loss: 0.197691, acc.: 71.88%] [G loss: 0.439611]\n",
      "epoch:21 step:20317 [D loss: 0.237865, acc.: 57.81%] [G loss: 0.406737]\n",
      "epoch:21 step:20318 [D loss: 0.216275, acc.: 70.31%] [G loss: 0.435623]\n",
      "epoch:21 step:20319 [D loss: 0.200354, acc.: 68.75%] [G loss: 0.479694]\n",
      "epoch:21 step:20320 [D loss: 0.235199, acc.: 60.16%] [G loss: 0.467530]\n",
      "epoch:21 step:20321 [D loss: 0.236073, acc.: 62.50%] [G loss: 0.419372]\n",
      "epoch:21 step:20322 [D loss: 0.240899, acc.: 54.69%] [G loss: 0.419797]\n",
      "epoch:21 step:20323 [D loss: 0.240657, acc.: 60.16%] [G loss: 0.427979]\n",
      "epoch:21 step:20324 [D loss: 0.208710, acc.: 68.75%] [G loss: 0.476585]\n",
      "epoch:21 step:20325 [D loss: 0.187432, acc.: 69.53%] [G loss: 0.520642]\n",
      "epoch:21 step:20326 [D loss: 0.218904, acc.: 67.19%] [G loss: 0.526836]\n",
      "epoch:21 step:20327 [D loss: 0.202269, acc.: 65.62%] [G loss: 0.500372]\n",
      "epoch:21 step:20328 [D loss: 0.232869, acc.: 61.72%] [G loss: 0.423453]\n",
      "epoch:21 step:20329 [D loss: 0.203033, acc.: 69.53%] [G loss: 0.443979]\n",
      "epoch:21 step:20330 [D loss: 0.220329, acc.: 71.09%] [G loss: 0.428297]\n",
      "epoch:21 step:20331 [D loss: 0.195173, acc.: 73.44%] [G loss: 0.446342]\n",
      "epoch:21 step:20332 [D loss: 0.234951, acc.: 61.72%] [G loss: 0.444430]\n",
      "epoch:21 step:20333 [D loss: 0.232291, acc.: 58.59%] [G loss: 0.420951]\n",
      "epoch:21 step:20334 [D loss: 0.213228, acc.: 63.28%] [G loss: 0.441006]\n",
      "epoch:21 step:20335 [D loss: 0.249366, acc.: 60.16%] [G loss: 0.397852]\n",
      "epoch:21 step:20336 [D loss: 0.223655, acc.: 64.06%] [G loss: 0.445316]\n",
      "epoch:21 step:20337 [D loss: 0.206961, acc.: 67.97%] [G loss: 0.425883]\n",
      "epoch:21 step:20338 [D loss: 0.196646, acc.: 71.88%] [G loss: 0.466116]\n",
      "epoch:21 step:20339 [D loss: 0.225171, acc.: 63.28%] [G loss: 0.465848]\n",
      "epoch:21 step:20340 [D loss: 0.211279, acc.: 64.84%] [G loss: 0.472545]\n",
      "epoch:21 step:20341 [D loss: 0.244367, acc.: 54.69%] [G loss: 0.437848]\n",
      "epoch:21 step:20342 [D loss: 0.235105, acc.: 59.38%] [G loss: 0.415503]\n",
      "epoch:21 step:20343 [D loss: 0.210147, acc.: 66.41%] [G loss: 0.436401]\n",
      "epoch:21 step:20344 [D loss: 0.227333, acc.: 63.28%] [G loss: 0.414059]\n",
      "epoch:21 step:20345 [D loss: 0.208988, acc.: 61.72%] [G loss: 0.412108]\n",
      "epoch:21 step:20346 [D loss: 0.217009, acc.: 64.84%] [G loss: 0.424430]\n",
      "epoch:21 step:20347 [D loss: 0.244258, acc.: 55.47%] [G loss: 0.429884]\n",
      "epoch:21 step:20348 [D loss: 0.217785, acc.: 59.38%] [G loss: 0.402538]\n",
      "epoch:21 step:20349 [D loss: 0.234224, acc.: 58.59%] [G loss: 0.425239]\n",
      "epoch:21 step:20350 [D loss: 0.231579, acc.: 61.72%] [G loss: 0.423424]\n",
      "epoch:21 step:20351 [D loss: 0.196994, acc.: 70.31%] [G loss: 0.458907]\n",
      "epoch:21 step:20352 [D loss: 0.248885, acc.: 59.38%] [G loss: 0.435910]\n",
      "epoch:21 step:20353 [D loss: 0.227193, acc.: 67.97%] [G loss: 0.419940]\n",
      "epoch:21 step:20354 [D loss: 0.201270, acc.: 70.31%] [G loss: 0.430469]\n",
      "epoch:21 step:20355 [D loss: 0.227019, acc.: 63.28%] [G loss: 0.421836]\n",
      "epoch:21 step:20356 [D loss: 0.220659, acc.: 58.59%] [G loss: 0.453222]\n",
      "epoch:21 step:20357 [D loss: 0.228106, acc.: 61.72%] [G loss: 0.406203]\n",
      "epoch:21 step:20358 [D loss: 0.193425, acc.: 71.09%] [G loss: 0.426449]\n",
      "epoch:21 step:20359 [D loss: 0.279047, acc.: 54.69%] [G loss: 0.428157]\n",
      "epoch:21 step:20360 [D loss: 0.246699, acc.: 57.03%] [G loss: 0.407416]\n",
      "epoch:21 step:20361 [D loss: 0.241634, acc.: 58.59%] [G loss: 0.409703]\n",
      "epoch:21 step:20362 [D loss: 0.202388, acc.: 69.53%] [G loss: 0.450771]\n",
      "epoch:21 step:20363 [D loss: 0.229928, acc.: 60.16%] [G loss: 0.424136]\n",
      "epoch:21 step:20364 [D loss: 0.221619, acc.: 65.62%] [G loss: 0.408597]\n",
      "epoch:21 step:20365 [D loss: 0.218269, acc.: 65.62%] [G loss: 0.421285]\n",
      "epoch:21 step:20366 [D loss: 0.218878, acc.: 64.84%] [G loss: 0.448459]\n",
      "epoch:21 step:20367 [D loss: 0.195191, acc.: 73.44%] [G loss: 0.469842]\n",
      "epoch:21 step:20368 [D loss: 0.207785, acc.: 70.31%] [G loss: 0.449756]\n",
      "epoch:21 step:20369 [D loss: 0.222768, acc.: 67.97%] [G loss: 0.453661]\n",
      "epoch:21 step:20370 [D loss: 0.190663, acc.: 72.66%] [G loss: 0.448378]\n",
      "epoch:21 step:20371 [D loss: 0.174647, acc.: 75.78%] [G loss: 0.474637]\n",
      "epoch:21 step:20372 [D loss: 0.220118, acc.: 67.19%] [G loss: 0.505026]\n",
      "epoch:21 step:20373 [D loss: 0.263329, acc.: 50.78%] [G loss: 0.416109]\n",
      "epoch:21 step:20374 [D loss: 0.249288, acc.: 53.12%] [G loss: 0.455831]\n",
      "epoch:21 step:20375 [D loss: 0.229864, acc.: 62.50%] [G loss: 0.428985]\n",
      "epoch:21 step:20376 [D loss: 0.217486, acc.: 65.62%] [G loss: 0.415356]\n",
      "epoch:21 step:20377 [D loss: 0.218083, acc.: 64.06%] [G loss: 0.444924]\n",
      "epoch:21 step:20378 [D loss: 0.209243, acc.: 63.28%] [G loss: 0.494887]\n",
      "epoch:21 step:20379 [D loss: 0.214544, acc.: 68.75%] [G loss: 0.457879]\n",
      "epoch:21 step:20380 [D loss: 0.239916, acc.: 62.50%] [G loss: 0.433955]\n",
      "epoch:21 step:20381 [D loss: 0.231277, acc.: 58.59%] [G loss: 0.423126]\n",
      "epoch:21 step:20382 [D loss: 0.229361, acc.: 59.38%] [G loss: 0.414889]\n",
      "epoch:21 step:20383 [D loss: 0.202334, acc.: 70.31%] [G loss: 0.421669]\n",
      "epoch:21 step:20384 [D loss: 0.213321, acc.: 67.97%] [G loss: 0.456493]\n",
      "epoch:21 step:20385 [D loss: 0.225478, acc.: 63.28%] [G loss: 0.436560]\n",
      "epoch:21 step:20386 [D loss: 0.214704, acc.: 70.31%] [G loss: 0.448356]\n",
      "epoch:21 step:20387 [D loss: 0.255907, acc.: 58.59%] [G loss: 0.414046]\n",
      "epoch:21 step:20388 [D loss: 0.243766, acc.: 58.59%] [G loss: 0.423274]\n",
      "epoch:21 step:20389 [D loss: 0.211764, acc.: 64.84%] [G loss: 0.470547]\n",
      "epoch:21 step:20390 [D loss: 0.214420, acc.: 66.41%] [G loss: 0.508054]\n",
      "epoch:21 step:20391 [D loss: 0.216080, acc.: 66.41%] [G loss: 0.468936]\n",
      "epoch:21 step:20392 [D loss: 0.200457, acc.: 72.66%] [G loss: 0.430815]\n",
      "epoch:21 step:20393 [D loss: 0.248542, acc.: 53.12%] [G loss: 0.400903]\n",
      "epoch:21 step:20394 [D loss: 0.209788, acc.: 68.75%] [G loss: 0.398239]\n",
      "epoch:21 step:20395 [D loss: 0.220304, acc.: 67.97%] [G loss: 0.421213]\n",
      "epoch:21 step:20396 [D loss: 0.186443, acc.: 71.09%] [G loss: 0.510592]\n",
      "epoch:21 step:20397 [D loss: 0.222578, acc.: 64.06%] [G loss: 0.479870]\n",
      "epoch:21 step:20398 [D loss: 0.219737, acc.: 59.38%] [G loss: 0.425701]\n",
      "epoch:21 step:20399 [D loss: 0.248878, acc.: 56.25%] [G loss: 0.411620]\n",
      "epoch:21 step:20400 [D loss: 0.216668, acc.: 66.41%] [G loss: 0.421468]\n",
      "epoch:21 step:20401 [D loss: 0.203759, acc.: 67.19%] [G loss: 0.427171]\n",
      "epoch:21 step:20402 [D loss: 0.208437, acc.: 66.41%] [G loss: 0.468722]\n",
      "epoch:21 step:20403 [D loss: 0.217508, acc.: 61.72%] [G loss: 0.463104]\n",
      "epoch:21 step:20404 [D loss: 0.242927, acc.: 58.59%] [G loss: 0.442598]\n",
      "epoch:21 step:20405 [D loss: 0.239754, acc.: 57.03%] [G loss: 0.401569]\n",
      "epoch:21 step:20406 [D loss: 0.212997, acc.: 72.66%] [G loss: 0.405673]\n",
      "epoch:21 step:20407 [D loss: 0.197488, acc.: 74.22%] [G loss: 0.474877]\n",
      "epoch:21 step:20408 [D loss: 0.212523, acc.: 65.62%] [G loss: 0.442650]\n",
      "epoch:21 step:20409 [D loss: 0.220893, acc.: 64.06%] [G loss: 0.461599]\n",
      "epoch:21 step:20410 [D loss: 0.225185, acc.: 64.06%] [G loss: 0.471710]\n",
      "epoch:21 step:20411 [D loss: 0.240759, acc.: 62.50%] [G loss: 0.432513]\n",
      "epoch:21 step:20412 [D loss: 0.258102, acc.: 55.47%] [G loss: 0.419300]\n",
      "epoch:21 step:20413 [D loss: 0.206522, acc.: 67.19%] [G loss: 0.442329]\n",
      "epoch:21 step:20414 [D loss: 0.226928, acc.: 59.38%] [G loss: 0.421079]\n",
      "epoch:21 step:20415 [D loss: 0.245776, acc.: 55.47%] [G loss: 0.437445]\n",
      "epoch:21 step:20416 [D loss: 0.249906, acc.: 57.81%] [G loss: 0.399787]\n",
      "epoch:21 step:20417 [D loss: 0.233831, acc.: 59.38%] [G loss: 0.405712]\n",
      "epoch:21 step:20418 [D loss: 0.247476, acc.: 57.03%] [G loss: 0.383210]\n",
      "epoch:21 step:20419 [D loss: 0.230795, acc.: 61.72%] [G loss: 0.418743]\n",
      "epoch:21 step:20420 [D loss: 0.218516, acc.: 62.50%] [G loss: 0.411405]\n",
      "epoch:21 step:20421 [D loss: 0.240073, acc.: 60.94%] [G loss: 0.382963]\n",
      "epoch:21 step:20422 [D loss: 0.231575, acc.: 63.28%] [G loss: 0.376256]\n",
      "epoch:21 step:20423 [D loss: 0.214923, acc.: 65.62%] [G loss: 0.426292]\n",
      "epoch:21 step:20424 [D loss: 0.208694, acc.: 71.09%] [G loss: 0.447413]\n",
      "epoch:21 step:20425 [D loss: 0.219543, acc.: 66.41%] [G loss: 0.415079]\n",
      "epoch:21 step:20426 [D loss: 0.220686, acc.: 66.41%] [G loss: 0.415111]\n",
      "epoch:21 step:20427 [D loss: 0.203558, acc.: 71.88%] [G loss: 0.462103]\n",
      "epoch:21 step:20428 [D loss: 0.221456, acc.: 66.41%] [G loss: 0.432630]\n",
      "epoch:21 step:20429 [D loss: 0.241118, acc.: 59.38%] [G loss: 0.447001]\n",
      "epoch:21 step:20430 [D loss: 0.218934, acc.: 62.50%] [G loss: 0.441035]\n",
      "epoch:21 step:20431 [D loss: 0.195845, acc.: 75.00%] [G loss: 0.445144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20432 [D loss: 0.215030, acc.: 67.19%] [G loss: 0.477769]\n",
      "epoch:21 step:20433 [D loss: 0.211350, acc.: 67.97%] [G loss: 0.452448]\n",
      "epoch:21 step:20434 [D loss: 0.231885, acc.: 60.94%] [G loss: 0.427162]\n",
      "epoch:21 step:20435 [D loss: 0.239725, acc.: 61.72%] [G loss: 0.438572]\n",
      "epoch:21 step:20436 [D loss: 0.238995, acc.: 59.38%] [G loss: 0.401047]\n",
      "epoch:21 step:20437 [D loss: 0.236394, acc.: 57.81%] [G loss: 0.386128]\n",
      "epoch:21 step:20438 [D loss: 0.203054, acc.: 67.97%] [G loss: 0.431635]\n",
      "epoch:21 step:20439 [D loss: 0.236974, acc.: 57.81%] [G loss: 0.372211]\n",
      "epoch:21 step:20440 [D loss: 0.214890, acc.: 64.84%] [G loss: 0.418713]\n",
      "epoch:21 step:20441 [D loss: 0.244382, acc.: 53.91%] [G loss: 0.419726]\n",
      "epoch:21 step:20442 [D loss: 0.245276, acc.: 59.38%] [G loss: 0.402671]\n",
      "epoch:21 step:20443 [D loss: 0.235410, acc.: 62.50%] [G loss: 0.405787]\n",
      "epoch:21 step:20444 [D loss: 0.230239, acc.: 60.94%] [G loss: 0.433090]\n",
      "epoch:21 step:20445 [D loss: 0.241010, acc.: 59.38%] [G loss: 0.462344]\n",
      "epoch:21 step:20446 [D loss: 0.196332, acc.: 70.31%] [G loss: 0.474893]\n",
      "epoch:21 step:20447 [D loss: 0.242598, acc.: 61.72%] [G loss: 0.448079]\n",
      "epoch:21 step:20448 [D loss: 0.231214, acc.: 56.25%] [G loss: 0.422779]\n",
      "epoch:21 step:20449 [D loss: 0.208705, acc.: 66.41%] [G loss: 0.416681]\n",
      "epoch:21 step:20450 [D loss: 0.235069, acc.: 62.50%] [G loss: 0.417325]\n",
      "epoch:21 step:20451 [D loss: 0.209267, acc.: 70.31%] [G loss: 0.452785]\n",
      "epoch:21 step:20452 [D loss: 0.223605, acc.: 66.41%] [G loss: 0.465971]\n",
      "epoch:21 step:20453 [D loss: 0.233821, acc.: 61.72%] [G loss: 0.435548]\n",
      "epoch:21 step:20454 [D loss: 0.215383, acc.: 70.31%] [G loss: 0.446063]\n",
      "epoch:21 step:20455 [D loss: 0.225553, acc.: 60.94%] [G loss: 0.398791]\n",
      "epoch:21 step:20456 [D loss: 0.231161, acc.: 63.28%] [G loss: 0.409651]\n",
      "epoch:21 step:20457 [D loss: 0.204128, acc.: 67.97%] [G loss: 0.440813]\n",
      "epoch:21 step:20458 [D loss: 0.208221, acc.: 67.97%] [G loss: 0.457485]\n",
      "epoch:21 step:20459 [D loss: 0.194130, acc.: 73.44%] [G loss: 0.483342]\n",
      "epoch:21 step:20460 [D loss: 0.245398, acc.: 58.59%] [G loss: 0.431880]\n",
      "epoch:21 step:20461 [D loss: 0.237548, acc.: 60.94%] [G loss: 0.415357]\n",
      "epoch:21 step:20462 [D loss: 0.203813, acc.: 71.88%] [G loss: 0.410503]\n",
      "epoch:21 step:20463 [D loss: 0.201683, acc.: 71.88%] [G loss: 0.476796]\n",
      "epoch:21 step:20464 [D loss: 0.259784, acc.: 58.59%] [G loss: 0.435831]\n",
      "epoch:21 step:20465 [D loss: 0.239256, acc.: 58.59%] [G loss: 0.394940]\n",
      "epoch:21 step:20466 [D loss: 0.234148, acc.: 57.81%] [G loss: 0.427768]\n",
      "epoch:21 step:20467 [D loss: 0.207123, acc.: 67.19%] [G loss: 0.462734]\n",
      "epoch:21 step:20468 [D loss: 0.265068, acc.: 56.25%] [G loss: 0.399670]\n",
      "epoch:21 step:20469 [D loss: 0.203138, acc.: 70.31%] [G loss: 0.461633]\n",
      "epoch:21 step:20470 [D loss: 0.223381, acc.: 62.50%] [G loss: 0.478609]\n",
      "epoch:21 step:20471 [D loss: 0.231012, acc.: 59.38%] [G loss: 0.471734]\n",
      "epoch:21 step:20472 [D loss: 0.262268, acc.: 53.12%] [G loss: 0.444692]\n",
      "epoch:21 step:20473 [D loss: 0.202458, acc.: 65.62%] [G loss: 0.480033]\n",
      "epoch:21 step:20474 [D loss: 0.226915, acc.: 65.62%] [G loss: 0.458517]\n",
      "epoch:21 step:20475 [D loss: 0.241475, acc.: 60.16%] [G loss: 0.399834]\n",
      "epoch:21 step:20476 [D loss: 0.216471, acc.: 71.88%] [G loss: 0.452076]\n",
      "epoch:21 step:20477 [D loss: 0.253729, acc.: 55.47%] [G loss: 0.426757]\n",
      "epoch:21 step:20478 [D loss: 0.213592, acc.: 65.62%] [G loss: 0.453710]\n",
      "epoch:21 step:20479 [D loss: 0.204475, acc.: 67.97%] [G loss: 0.469656]\n",
      "epoch:21 step:20480 [D loss: 0.206649, acc.: 64.06%] [G loss: 0.449264]\n",
      "epoch:21 step:20481 [D loss: 0.233076, acc.: 60.16%] [G loss: 0.416551]\n",
      "epoch:21 step:20482 [D loss: 0.237464, acc.: 57.81%] [G loss: 0.389690]\n",
      "epoch:21 step:20483 [D loss: 0.210702, acc.: 67.19%] [G loss: 0.463587]\n",
      "epoch:21 step:20484 [D loss: 0.210428, acc.: 66.41%] [G loss: 0.460649]\n",
      "epoch:21 step:20485 [D loss: 0.249245, acc.: 57.03%] [G loss: 0.420122]\n",
      "epoch:21 step:20486 [D loss: 0.237162, acc.: 61.72%] [G loss: 0.416804]\n",
      "epoch:21 step:20487 [D loss: 0.216236, acc.: 68.75%] [G loss: 0.406056]\n",
      "epoch:21 step:20488 [D loss: 0.225212, acc.: 64.84%] [G loss: 0.449691]\n",
      "epoch:21 step:20489 [D loss: 0.219641, acc.: 63.28%] [G loss: 0.446282]\n",
      "epoch:21 step:20490 [D loss: 0.212307, acc.: 67.19%] [G loss: 0.430820]\n",
      "epoch:21 step:20491 [D loss: 0.230366, acc.: 60.94%] [G loss: 0.441151]\n",
      "epoch:21 step:20492 [D loss: 0.193730, acc.: 71.09%] [G loss: 0.476065]\n",
      "epoch:21 step:20493 [D loss: 0.231141, acc.: 60.94%] [G loss: 0.467989]\n",
      "epoch:21 step:20494 [D loss: 0.256768, acc.: 57.81%] [G loss: 0.465465]\n",
      "epoch:21 step:20495 [D loss: 0.258517, acc.: 53.12%] [G loss: 0.413326]\n",
      "epoch:21 step:20496 [D loss: 0.207378, acc.: 67.19%] [G loss: 0.432924]\n",
      "epoch:21 step:20497 [D loss: 0.271990, acc.: 46.88%] [G loss: 0.391801]\n",
      "epoch:21 step:20498 [D loss: 0.238204, acc.: 56.25%] [G loss: 0.414514]\n",
      "epoch:21 step:20499 [D loss: 0.221301, acc.: 66.41%] [G loss: 0.433814]\n",
      "epoch:21 step:20500 [D loss: 0.194602, acc.: 71.09%] [G loss: 0.420893]\n",
      "epoch:21 step:20501 [D loss: 0.248114, acc.: 60.94%] [G loss: 0.414124]\n",
      "epoch:21 step:20502 [D loss: 0.200947, acc.: 69.53%] [G loss: 0.458396]\n",
      "epoch:21 step:20503 [D loss: 0.237937, acc.: 57.03%] [G loss: 0.412128]\n",
      "epoch:21 step:20504 [D loss: 0.228053, acc.: 60.94%] [G loss: 0.433130]\n",
      "epoch:21 step:20505 [D loss: 0.280225, acc.: 50.00%] [G loss: 0.414626]\n",
      "epoch:21 step:20506 [D loss: 0.238506, acc.: 57.03%] [G loss: 0.414583]\n",
      "epoch:21 step:20507 [D loss: 0.232523, acc.: 55.47%] [G loss: 0.440361]\n",
      "epoch:21 step:20508 [D loss: 0.235378, acc.: 64.06%] [G loss: 0.385975]\n",
      "epoch:21 step:20509 [D loss: 0.207348, acc.: 64.06%] [G loss: 0.446943]\n",
      "epoch:21 step:20510 [D loss: 0.212893, acc.: 67.97%] [G loss: 0.443317]\n",
      "epoch:21 step:20511 [D loss: 0.236558, acc.: 60.16%] [G loss: 0.432295]\n",
      "epoch:21 step:20512 [D loss: 0.211557, acc.: 67.97%] [G loss: 0.427257]\n",
      "epoch:21 step:20513 [D loss: 0.233222, acc.: 60.16%] [G loss: 0.411440]\n",
      "epoch:21 step:20514 [D loss: 0.216676, acc.: 60.16%] [G loss: 0.445437]\n",
      "epoch:21 step:20515 [D loss: 0.217660, acc.: 71.09%] [G loss: 0.393604]\n",
      "epoch:21 step:20516 [D loss: 0.207052, acc.: 66.41%] [G loss: 0.428593]\n",
      "epoch:21 step:20517 [D loss: 0.211265, acc.: 65.62%] [G loss: 0.425733]\n",
      "epoch:21 step:20518 [D loss: 0.228014, acc.: 60.94%] [G loss: 0.387715]\n",
      "epoch:21 step:20519 [D loss: 0.194010, acc.: 71.88%] [G loss: 0.445771]\n",
      "epoch:21 step:20520 [D loss: 0.228277, acc.: 58.59%] [G loss: 0.437196]\n",
      "epoch:21 step:20521 [D loss: 0.259994, acc.: 50.78%] [G loss: 0.380089]\n",
      "epoch:21 step:20522 [D loss: 0.221477, acc.: 63.28%] [G loss: 0.440174]\n",
      "epoch:21 step:20523 [D loss: 0.231566, acc.: 54.69%] [G loss: 0.432280]\n",
      "epoch:21 step:20524 [D loss: 0.236613, acc.: 57.03%] [G loss: 0.402647]\n",
      "epoch:21 step:20525 [D loss: 0.229826, acc.: 62.50%] [G loss: 0.410694]\n",
      "epoch:21 step:20526 [D loss: 0.216004, acc.: 65.62%] [G loss: 0.446916]\n",
      "epoch:21 step:20527 [D loss: 0.247843, acc.: 54.69%] [G loss: 0.413523]\n",
      "epoch:21 step:20528 [D loss: 0.218934, acc.: 60.16%] [G loss: 0.429259]\n",
      "epoch:21 step:20529 [D loss: 0.233710, acc.: 59.38%] [G loss: 0.424606]\n",
      "epoch:21 step:20530 [D loss: 0.219880, acc.: 67.19%] [G loss: 0.428904]\n",
      "epoch:21 step:20531 [D loss: 0.223082, acc.: 60.16%] [G loss: 0.418095]\n",
      "epoch:21 step:20532 [D loss: 0.241840, acc.: 62.50%] [G loss: 0.439273]\n",
      "epoch:21 step:20533 [D loss: 0.222225, acc.: 61.72%] [G loss: 0.411154]\n",
      "epoch:21 step:20534 [D loss: 0.230118, acc.: 59.38%] [G loss: 0.442690]\n",
      "epoch:21 step:20535 [D loss: 0.266094, acc.: 54.69%] [G loss: 0.424156]\n",
      "epoch:21 step:20536 [D loss: 0.251633, acc.: 55.47%] [G loss: 0.457257]\n",
      "epoch:21 step:20537 [D loss: 0.216808, acc.: 65.62%] [G loss: 0.453813]\n",
      "epoch:21 step:20538 [D loss: 0.245201, acc.: 60.94%] [G loss: 0.447920]\n",
      "epoch:21 step:20539 [D loss: 0.233226, acc.: 60.94%] [G loss: 0.400575]\n",
      "epoch:21 step:20540 [D loss: 0.241612, acc.: 57.81%] [G loss: 0.422428]\n",
      "epoch:21 step:20541 [D loss: 0.236350, acc.: 60.94%] [G loss: 0.397744]\n",
      "epoch:21 step:20542 [D loss: 0.244294, acc.: 54.69%] [G loss: 0.401040]\n",
      "epoch:21 step:20543 [D loss: 0.206656, acc.: 66.41%] [G loss: 0.408864]\n",
      "epoch:21 step:20544 [D loss: 0.222895, acc.: 65.62%] [G loss: 0.403149]\n",
      "epoch:21 step:20545 [D loss: 0.233081, acc.: 60.94%] [G loss: 0.439949]\n",
      "epoch:21 step:20546 [D loss: 0.234249, acc.: 56.25%] [G loss: 0.389080]\n",
      "epoch:21 step:20547 [D loss: 0.230537, acc.: 63.28%] [G loss: 0.384510]\n",
      "epoch:21 step:20548 [D loss: 0.202436, acc.: 68.75%] [G loss: 0.409390]\n",
      "epoch:21 step:20549 [D loss: 0.251489, acc.: 60.94%] [G loss: 0.413229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20550 [D loss: 0.234681, acc.: 65.62%] [G loss: 0.450950]\n",
      "epoch:21 step:20551 [D loss: 0.228234, acc.: 64.06%] [G loss: 0.443613]\n",
      "epoch:21 step:20552 [D loss: 0.196668, acc.: 73.44%] [G loss: 0.420126]\n",
      "epoch:21 step:20553 [D loss: 0.210953, acc.: 64.84%] [G loss: 0.436237]\n",
      "epoch:21 step:20554 [D loss: 0.248415, acc.: 53.12%] [G loss: 0.429131]\n",
      "epoch:21 step:20555 [D loss: 0.232691, acc.: 61.72%] [G loss: 0.421538]\n",
      "epoch:21 step:20556 [D loss: 0.221035, acc.: 64.06%] [G loss: 0.430710]\n",
      "epoch:21 step:20557 [D loss: 0.261082, acc.: 50.78%] [G loss: 0.430252]\n",
      "epoch:21 step:20558 [D loss: 0.231227, acc.: 63.28%] [G loss: 0.412516]\n",
      "epoch:21 step:20559 [D loss: 0.229783, acc.: 60.16%] [G loss: 0.396046]\n",
      "epoch:21 step:20560 [D loss: 0.232644, acc.: 60.94%] [G loss: 0.426852]\n",
      "epoch:21 step:20561 [D loss: 0.205025, acc.: 65.62%] [G loss: 0.424860]\n",
      "epoch:21 step:20562 [D loss: 0.210950, acc.: 67.97%] [G loss: 0.465825]\n",
      "epoch:21 step:20563 [D loss: 0.209015, acc.: 66.41%] [G loss: 0.413261]\n",
      "epoch:21 step:20564 [D loss: 0.240634, acc.: 57.81%] [G loss: 0.444950]\n",
      "epoch:21 step:20565 [D loss: 0.242401, acc.: 53.91%] [G loss: 0.410682]\n",
      "epoch:21 step:20566 [D loss: 0.210731, acc.: 65.62%] [G loss: 0.415065]\n",
      "epoch:21 step:20567 [D loss: 0.201782, acc.: 68.75%] [G loss: 0.446380]\n",
      "epoch:21 step:20568 [D loss: 0.260902, acc.: 52.34%] [G loss: 0.426111]\n",
      "epoch:21 step:20569 [D loss: 0.262177, acc.: 57.03%] [G loss: 0.432685]\n",
      "epoch:21 step:20570 [D loss: 0.214410, acc.: 60.16%] [G loss: 0.435793]\n",
      "epoch:21 step:20571 [D loss: 0.217833, acc.: 69.53%] [G loss: 0.443004]\n",
      "epoch:21 step:20572 [D loss: 0.210876, acc.: 63.28%] [G loss: 0.434254]\n",
      "epoch:21 step:20573 [D loss: 0.211031, acc.: 67.97%] [G loss: 0.424222]\n",
      "epoch:21 step:20574 [D loss: 0.206962, acc.: 67.97%] [G loss: 0.480779]\n",
      "epoch:21 step:20575 [D loss: 0.197404, acc.: 67.97%] [G loss: 0.449579]\n",
      "epoch:21 step:20576 [D loss: 0.200005, acc.: 69.53%] [G loss: 0.443706]\n",
      "epoch:21 step:20577 [D loss: 0.209368, acc.: 66.41%] [G loss: 0.508905]\n",
      "epoch:21 step:20578 [D loss: 0.219347, acc.: 64.06%] [G loss: 0.503068]\n",
      "epoch:21 step:20579 [D loss: 0.232739, acc.: 57.81%] [G loss: 0.458319]\n",
      "epoch:21 step:20580 [D loss: 0.213471, acc.: 63.28%] [G loss: 0.424823]\n",
      "epoch:21 step:20581 [D loss: 0.223497, acc.: 60.16%] [G loss: 0.432333]\n",
      "epoch:21 step:20582 [D loss: 0.209528, acc.: 67.19%] [G loss: 0.448329]\n",
      "epoch:21 step:20583 [D loss: 0.232138, acc.: 66.41%] [G loss: 0.490409]\n",
      "epoch:21 step:20584 [D loss: 0.242778, acc.: 57.03%] [G loss: 0.428843]\n",
      "epoch:21 step:20585 [D loss: 0.219382, acc.: 64.84%] [G loss: 0.429415]\n",
      "epoch:21 step:20586 [D loss: 0.200552, acc.: 62.50%] [G loss: 0.443794]\n",
      "epoch:21 step:20587 [D loss: 0.234832, acc.: 60.94%] [G loss: 0.455378]\n",
      "epoch:21 step:20588 [D loss: 0.218545, acc.: 62.50%] [G loss: 0.442990]\n",
      "epoch:21 step:20589 [D loss: 0.216533, acc.: 70.31%] [G loss: 0.448033]\n",
      "epoch:21 step:20590 [D loss: 0.236123, acc.: 57.03%] [G loss: 0.438762]\n",
      "epoch:21 step:20591 [D loss: 0.205957, acc.: 66.41%] [G loss: 0.416394]\n",
      "epoch:21 step:20592 [D loss: 0.254366, acc.: 52.34%] [G loss: 0.451441]\n",
      "epoch:21 step:20593 [D loss: 0.238435, acc.: 63.28%] [G loss: 0.410857]\n",
      "epoch:21 step:20594 [D loss: 0.236737, acc.: 64.06%] [G loss: 0.440610]\n",
      "epoch:21 step:20595 [D loss: 0.193313, acc.: 72.66%] [G loss: 0.482815]\n",
      "epoch:21 step:20596 [D loss: 0.194938, acc.: 75.00%] [G loss: 0.488010]\n",
      "epoch:21 step:20597 [D loss: 0.258877, acc.: 57.03%] [G loss: 0.401139]\n",
      "epoch:21 step:20598 [D loss: 0.205010, acc.: 67.19%] [G loss: 0.411508]\n",
      "epoch:21 step:20599 [D loss: 0.218420, acc.: 64.84%] [G loss: 0.461055]\n",
      "epoch:21 step:20600 [D loss: 0.180197, acc.: 75.00%] [G loss: 0.452697]\n",
      "epoch:21 step:20601 [D loss: 0.209973, acc.: 69.53%] [G loss: 0.434126]\n",
      "epoch:21 step:20602 [D loss: 0.182632, acc.: 75.00%] [G loss: 0.493277]\n",
      "epoch:21 step:20603 [D loss: 0.221965, acc.: 68.75%] [G loss: 0.509694]\n",
      "epoch:21 step:20604 [D loss: 0.188933, acc.: 67.97%] [G loss: 0.541887]\n",
      "epoch:21 step:20605 [D loss: 0.287344, acc.: 56.25%] [G loss: 0.495750]\n",
      "epoch:21 step:20606 [D loss: 0.229504, acc.: 65.62%] [G loss: 0.539969]\n",
      "epoch:21 step:20607 [D loss: 0.215053, acc.: 63.28%] [G loss: 0.502081]\n",
      "epoch:21 step:20608 [D loss: 0.254072, acc.: 61.72%] [G loss: 0.432139]\n",
      "epoch:21 step:20609 [D loss: 0.224918, acc.: 67.19%] [G loss: 0.397414]\n",
      "epoch:21 step:20610 [D loss: 0.238478, acc.: 64.84%] [G loss: 0.429952]\n",
      "epoch:21 step:20611 [D loss: 0.252880, acc.: 61.72%] [G loss: 0.452939]\n",
      "epoch:21 step:20612 [D loss: 0.186430, acc.: 70.31%] [G loss: 0.466486]\n",
      "epoch:21 step:20613 [D loss: 0.189166, acc.: 70.31%] [G loss: 0.462691]\n",
      "epoch:21 step:20614 [D loss: 0.206540, acc.: 64.06%] [G loss: 0.476104]\n",
      "epoch:22 step:20615 [D loss: 0.206733, acc.: 71.09%] [G loss: 0.516036]\n",
      "epoch:22 step:20616 [D loss: 0.238237, acc.: 64.84%] [G loss: 0.447115]\n",
      "epoch:22 step:20617 [D loss: 0.200373, acc.: 68.75%] [G loss: 0.457589]\n",
      "epoch:22 step:20618 [D loss: 0.230825, acc.: 62.50%] [G loss: 0.443554]\n",
      "epoch:22 step:20619 [D loss: 0.230657, acc.: 62.50%] [G loss: 0.464714]\n",
      "epoch:22 step:20620 [D loss: 0.261735, acc.: 56.25%] [G loss: 0.440848]\n",
      "epoch:22 step:20621 [D loss: 0.226598, acc.: 61.72%] [G loss: 0.449905]\n",
      "epoch:22 step:20622 [D loss: 0.241160, acc.: 61.72%] [G loss: 0.445799]\n",
      "epoch:22 step:20623 [D loss: 0.184311, acc.: 74.22%] [G loss: 0.478520]\n",
      "epoch:22 step:20624 [D loss: 0.198800, acc.: 73.44%] [G loss: 0.464090]\n",
      "epoch:22 step:20625 [D loss: 0.206092, acc.: 64.84%] [G loss: 0.481189]\n",
      "epoch:22 step:20626 [D loss: 0.204851, acc.: 70.31%] [G loss: 0.480320]\n",
      "epoch:22 step:20627 [D loss: 0.227256, acc.: 56.25%] [G loss: 0.471666]\n",
      "epoch:22 step:20628 [D loss: 0.232299, acc.: 61.72%] [G loss: 0.480777]\n",
      "epoch:22 step:20629 [D loss: 0.202744, acc.: 68.75%] [G loss: 0.492657]\n",
      "epoch:22 step:20630 [D loss: 0.195270, acc.: 68.75%] [G loss: 0.461907]\n",
      "epoch:22 step:20631 [D loss: 0.239540, acc.: 54.69%] [G loss: 0.444082]\n",
      "epoch:22 step:20632 [D loss: 0.246361, acc.: 61.72%] [G loss: 0.383287]\n",
      "epoch:22 step:20633 [D loss: 0.243294, acc.: 60.94%] [G loss: 0.435500]\n",
      "epoch:22 step:20634 [D loss: 0.257249, acc.: 56.25%] [G loss: 0.438954]\n",
      "epoch:22 step:20635 [D loss: 0.266116, acc.: 53.12%] [G loss: 0.445365]\n",
      "epoch:22 step:20636 [D loss: 0.197259, acc.: 71.09%] [G loss: 0.517428]\n",
      "epoch:22 step:20637 [D loss: 0.271114, acc.: 50.78%] [G loss: 0.407154]\n",
      "epoch:22 step:20638 [D loss: 0.227867, acc.: 64.06%] [G loss: 0.385708]\n",
      "epoch:22 step:20639 [D loss: 0.209120, acc.: 65.62%] [G loss: 0.441827]\n",
      "epoch:22 step:20640 [D loss: 0.240005, acc.: 57.03%] [G loss: 0.432935]\n",
      "epoch:22 step:20641 [D loss: 0.232827, acc.: 62.50%] [G loss: 0.410877]\n",
      "epoch:22 step:20642 [D loss: 0.239824, acc.: 57.81%] [G loss: 0.407575]\n",
      "epoch:22 step:20643 [D loss: 0.218216, acc.: 59.38%] [G loss: 0.438580]\n",
      "epoch:22 step:20644 [D loss: 0.232368, acc.: 57.81%] [G loss: 0.433323]\n",
      "epoch:22 step:20645 [D loss: 0.245614, acc.: 51.56%] [G loss: 0.424928]\n",
      "epoch:22 step:20646 [D loss: 0.214177, acc.: 65.62%] [G loss: 0.438547]\n",
      "epoch:22 step:20647 [D loss: 0.215546, acc.: 66.41%] [G loss: 0.436476]\n",
      "epoch:22 step:20648 [D loss: 0.238886, acc.: 60.94%] [G loss: 0.372264]\n",
      "epoch:22 step:20649 [D loss: 0.217068, acc.: 58.59%] [G loss: 0.431313]\n",
      "epoch:22 step:20650 [D loss: 0.220717, acc.: 65.62%] [G loss: 0.406891]\n",
      "epoch:22 step:20651 [D loss: 0.229436, acc.: 63.28%] [G loss: 0.468691]\n",
      "epoch:22 step:20652 [D loss: 0.274648, acc.: 53.12%] [G loss: 0.408887]\n",
      "epoch:22 step:20653 [D loss: 0.211321, acc.: 69.53%] [G loss: 0.448205]\n",
      "epoch:22 step:20654 [D loss: 0.205429, acc.: 64.84%] [G loss: 0.445293]\n",
      "epoch:22 step:20655 [D loss: 0.233243, acc.: 60.16%] [G loss: 0.459201]\n",
      "epoch:22 step:20656 [D loss: 0.240760, acc.: 62.50%] [G loss: 0.390076]\n",
      "epoch:22 step:20657 [D loss: 0.213345, acc.: 71.88%] [G loss: 0.438660]\n",
      "epoch:22 step:20658 [D loss: 0.240206, acc.: 61.72%] [G loss: 0.468439]\n",
      "epoch:22 step:20659 [D loss: 0.225163, acc.: 61.72%] [G loss: 0.448880]\n",
      "epoch:22 step:20660 [D loss: 0.225127, acc.: 64.84%] [G loss: 0.406820]\n",
      "epoch:22 step:20661 [D loss: 0.220649, acc.: 71.09%] [G loss: 0.422284]\n",
      "epoch:22 step:20662 [D loss: 0.201821, acc.: 73.44%] [G loss: 0.479070]\n",
      "epoch:22 step:20663 [D loss: 0.213879, acc.: 64.06%] [G loss: 0.451021]\n",
      "epoch:22 step:20664 [D loss: 0.221366, acc.: 64.84%] [G loss: 0.462512]\n",
      "epoch:22 step:20665 [D loss: 0.257125, acc.: 54.69%] [G loss: 0.433510]\n",
      "epoch:22 step:20666 [D loss: 0.223190, acc.: 62.50%] [G loss: 0.461330]\n",
      "epoch:22 step:20667 [D loss: 0.233675, acc.: 57.03%] [G loss: 0.414922]\n",
      "epoch:22 step:20668 [D loss: 0.228476, acc.: 59.38%] [G loss: 0.445011]\n",
      "epoch:22 step:20669 [D loss: 0.202695, acc.: 69.53%] [G loss: 0.447021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20670 [D loss: 0.235971, acc.: 62.50%] [G loss: 0.436958]\n",
      "epoch:22 step:20671 [D loss: 0.245090, acc.: 56.25%] [G loss: 0.415637]\n",
      "epoch:22 step:20672 [D loss: 0.201696, acc.: 67.97%] [G loss: 0.466394]\n",
      "epoch:22 step:20673 [D loss: 0.209455, acc.: 65.62%] [G loss: 0.433345]\n",
      "epoch:22 step:20674 [D loss: 0.250664, acc.: 57.03%] [G loss: 0.425984]\n",
      "epoch:22 step:20675 [D loss: 0.217264, acc.: 61.72%] [G loss: 0.433607]\n",
      "epoch:22 step:20676 [D loss: 0.250234, acc.: 62.50%] [G loss: 0.452079]\n",
      "epoch:22 step:20677 [D loss: 0.219322, acc.: 67.19%] [G loss: 0.449505]\n",
      "epoch:22 step:20678 [D loss: 0.239378, acc.: 58.59%] [G loss: 0.446656]\n",
      "epoch:22 step:20679 [D loss: 0.239480, acc.: 56.25%] [G loss: 0.417328]\n",
      "epoch:22 step:20680 [D loss: 0.215564, acc.: 62.50%] [G loss: 0.405075]\n",
      "epoch:22 step:20681 [D loss: 0.202611, acc.: 68.75%] [G loss: 0.429429]\n",
      "epoch:22 step:20682 [D loss: 0.224307, acc.: 59.38%] [G loss: 0.440456]\n",
      "epoch:22 step:20683 [D loss: 0.199077, acc.: 72.66%] [G loss: 0.443333]\n",
      "epoch:22 step:20684 [D loss: 0.195896, acc.: 68.75%] [G loss: 0.482016]\n",
      "epoch:22 step:20685 [D loss: 0.272359, acc.: 48.44%] [G loss: 0.397707]\n",
      "epoch:22 step:20686 [D loss: 0.259363, acc.: 47.66%] [G loss: 0.394877]\n",
      "epoch:22 step:20687 [D loss: 0.221268, acc.: 67.19%] [G loss: 0.419469]\n",
      "epoch:22 step:20688 [D loss: 0.189571, acc.: 77.34%] [G loss: 0.406098]\n",
      "epoch:22 step:20689 [D loss: 0.206867, acc.: 69.53%] [G loss: 0.424001]\n",
      "epoch:22 step:20690 [D loss: 0.177352, acc.: 74.22%] [G loss: 0.472060]\n",
      "epoch:22 step:20691 [D loss: 0.188421, acc.: 66.41%] [G loss: 0.483177]\n",
      "epoch:22 step:20692 [D loss: 0.265907, acc.: 53.91%] [G loss: 0.408575]\n",
      "epoch:22 step:20693 [D loss: 0.224565, acc.: 59.38%] [G loss: 0.407880]\n",
      "epoch:22 step:20694 [D loss: 0.237403, acc.: 57.81%] [G loss: 0.437418]\n",
      "epoch:22 step:20695 [D loss: 0.228148, acc.: 55.47%] [G loss: 0.428590]\n",
      "epoch:22 step:20696 [D loss: 0.239486, acc.: 59.38%] [G loss: 0.382347]\n",
      "epoch:22 step:20697 [D loss: 0.196487, acc.: 67.97%] [G loss: 0.449871]\n",
      "epoch:22 step:20698 [D loss: 0.221799, acc.: 64.84%] [G loss: 0.435367]\n",
      "epoch:22 step:20699 [D loss: 0.235536, acc.: 62.50%] [G loss: 0.446443]\n",
      "epoch:22 step:20700 [D loss: 0.224539, acc.: 63.28%] [G loss: 0.466586]\n",
      "epoch:22 step:20701 [D loss: 0.225208, acc.: 63.28%] [G loss: 0.466152]\n",
      "epoch:22 step:20702 [D loss: 0.203977, acc.: 72.66%] [G loss: 0.452147]\n",
      "epoch:22 step:20703 [D loss: 0.215800, acc.: 65.62%] [G loss: 0.422045]\n",
      "epoch:22 step:20704 [D loss: 0.214350, acc.: 65.62%] [G loss: 0.444351]\n",
      "epoch:22 step:20705 [D loss: 0.215882, acc.: 65.62%] [G loss: 0.432882]\n",
      "epoch:22 step:20706 [D loss: 0.195781, acc.: 71.09%] [G loss: 0.459269]\n",
      "epoch:22 step:20707 [D loss: 0.208079, acc.: 69.53%] [G loss: 0.479148]\n",
      "epoch:22 step:20708 [D loss: 0.218809, acc.: 61.72%] [G loss: 0.498350]\n",
      "epoch:22 step:20709 [D loss: 0.237689, acc.: 59.38%] [G loss: 0.441458]\n",
      "epoch:22 step:20710 [D loss: 0.218566, acc.: 62.50%] [G loss: 0.467176]\n",
      "epoch:22 step:20711 [D loss: 0.225342, acc.: 65.62%] [G loss: 0.456312]\n",
      "epoch:22 step:20712 [D loss: 0.238138, acc.: 61.72%] [G loss: 0.478907]\n",
      "epoch:22 step:20713 [D loss: 0.230265, acc.: 61.72%] [G loss: 0.435329]\n",
      "epoch:22 step:20714 [D loss: 0.214344, acc.: 66.41%] [G loss: 0.459935]\n",
      "epoch:22 step:20715 [D loss: 0.220056, acc.: 64.84%] [G loss: 0.508347]\n",
      "epoch:22 step:20716 [D loss: 0.235348, acc.: 63.28%] [G loss: 0.432603]\n",
      "epoch:22 step:20717 [D loss: 0.242982, acc.: 60.16%] [G loss: 0.427394]\n",
      "epoch:22 step:20718 [D loss: 0.272112, acc.: 53.91%] [G loss: 0.361661]\n",
      "epoch:22 step:20719 [D loss: 0.251631, acc.: 56.25%] [G loss: 0.393464]\n",
      "epoch:22 step:20720 [D loss: 0.207398, acc.: 71.88%] [G loss: 0.441213]\n",
      "epoch:22 step:20721 [D loss: 0.197337, acc.: 72.66%] [G loss: 0.446594]\n",
      "epoch:22 step:20722 [D loss: 0.267529, acc.: 53.12%] [G loss: 0.460892]\n",
      "epoch:22 step:20723 [D loss: 0.249195, acc.: 53.12%] [G loss: 0.405957]\n",
      "epoch:22 step:20724 [D loss: 0.239547, acc.: 60.16%] [G loss: 0.387314]\n",
      "epoch:22 step:20725 [D loss: 0.215795, acc.: 64.06%] [G loss: 0.398672]\n",
      "epoch:22 step:20726 [D loss: 0.201346, acc.: 67.97%] [G loss: 0.440631]\n",
      "epoch:22 step:20727 [D loss: 0.194188, acc.: 72.66%] [G loss: 0.434429]\n",
      "epoch:22 step:20728 [D loss: 0.204130, acc.: 71.09%] [G loss: 0.445847]\n",
      "epoch:22 step:20729 [D loss: 0.177484, acc.: 72.66%] [G loss: 0.475980]\n",
      "epoch:22 step:20730 [D loss: 0.212517, acc.: 67.97%] [G loss: 0.461602]\n",
      "epoch:22 step:20731 [D loss: 0.202903, acc.: 64.84%] [G loss: 0.484095]\n",
      "epoch:22 step:20732 [D loss: 0.198678, acc.: 68.75%] [G loss: 0.476544]\n",
      "epoch:22 step:20733 [D loss: 0.179259, acc.: 72.66%] [G loss: 0.490762]\n",
      "epoch:22 step:20734 [D loss: 0.261861, acc.: 53.12%] [G loss: 0.482653]\n",
      "epoch:22 step:20735 [D loss: 0.232785, acc.: 59.38%] [G loss: 0.437894]\n",
      "epoch:22 step:20736 [D loss: 0.189171, acc.: 75.00%] [G loss: 0.471913]\n",
      "epoch:22 step:20737 [D loss: 0.200239, acc.: 70.31%] [G loss: 0.477047]\n",
      "epoch:22 step:20738 [D loss: 0.231478, acc.: 61.72%] [G loss: 0.432659]\n",
      "epoch:22 step:20739 [D loss: 0.234195, acc.: 58.59%] [G loss: 0.425114]\n",
      "epoch:22 step:20740 [D loss: 0.220203, acc.: 64.06%] [G loss: 0.420523]\n",
      "epoch:22 step:20741 [D loss: 0.201326, acc.: 67.97%] [G loss: 0.434287]\n",
      "epoch:22 step:20742 [D loss: 0.241278, acc.: 58.59%] [G loss: 0.432105]\n",
      "epoch:22 step:20743 [D loss: 0.226417, acc.: 64.84%] [G loss: 0.417572]\n",
      "epoch:22 step:20744 [D loss: 0.208486, acc.: 64.84%] [G loss: 0.486877]\n",
      "epoch:22 step:20745 [D loss: 0.219106, acc.: 67.97%] [G loss: 0.398100]\n",
      "epoch:22 step:20746 [D loss: 0.220101, acc.: 63.28%] [G loss: 0.445964]\n",
      "epoch:22 step:20747 [D loss: 0.240283, acc.: 57.81%] [G loss: 0.444909]\n",
      "epoch:22 step:20748 [D loss: 0.208822, acc.: 67.97%] [G loss: 0.471923]\n",
      "epoch:22 step:20749 [D loss: 0.207466, acc.: 69.53%] [G loss: 0.454427]\n",
      "epoch:22 step:20750 [D loss: 0.196207, acc.: 72.66%] [G loss: 0.438147]\n",
      "epoch:22 step:20751 [D loss: 0.267121, acc.: 55.47%] [G loss: 0.372217]\n",
      "epoch:22 step:20752 [D loss: 0.260650, acc.: 51.56%] [G loss: 0.419870]\n",
      "epoch:22 step:20753 [D loss: 0.232863, acc.: 59.38%] [G loss: 0.413954]\n",
      "epoch:22 step:20754 [D loss: 0.208416, acc.: 64.06%] [G loss: 0.455559]\n",
      "epoch:22 step:20755 [D loss: 0.239379, acc.: 57.03%] [G loss: 0.426237]\n",
      "epoch:22 step:20756 [D loss: 0.223467, acc.: 60.94%] [G loss: 0.431665]\n",
      "epoch:22 step:20757 [D loss: 0.245501, acc.: 60.94%] [G loss: 0.427397]\n",
      "epoch:22 step:20758 [D loss: 0.219096, acc.: 60.94%] [G loss: 0.399387]\n",
      "epoch:22 step:20759 [D loss: 0.233218, acc.: 64.84%] [G loss: 0.421282]\n",
      "epoch:22 step:20760 [D loss: 0.208641, acc.: 64.84%] [G loss: 0.453668]\n",
      "epoch:22 step:20761 [D loss: 0.227894, acc.: 62.50%] [G loss: 0.455107]\n",
      "epoch:22 step:20762 [D loss: 0.228412, acc.: 65.62%] [G loss: 0.411633]\n",
      "epoch:22 step:20763 [D loss: 0.206058, acc.: 69.53%] [G loss: 0.469892]\n",
      "epoch:22 step:20764 [D loss: 0.222436, acc.: 64.06%] [G loss: 0.412979]\n",
      "epoch:22 step:20765 [D loss: 0.221569, acc.: 71.09%] [G loss: 0.401329]\n",
      "epoch:22 step:20766 [D loss: 0.213988, acc.: 69.53%] [G loss: 0.449922]\n",
      "epoch:22 step:20767 [D loss: 0.226180, acc.: 60.16%] [G loss: 0.431576]\n",
      "epoch:22 step:20768 [D loss: 0.200964, acc.: 68.75%] [G loss: 0.460825]\n",
      "epoch:22 step:20769 [D loss: 0.217727, acc.: 61.72%] [G loss: 0.464588]\n",
      "epoch:22 step:20770 [D loss: 0.230422, acc.: 64.06%] [G loss: 0.429642]\n",
      "epoch:22 step:20771 [D loss: 0.225692, acc.: 56.25%] [G loss: 0.495853]\n",
      "epoch:22 step:20772 [D loss: 0.237259, acc.: 57.81%] [G loss: 0.429098]\n",
      "epoch:22 step:20773 [D loss: 0.188202, acc.: 74.22%] [G loss: 0.473589]\n",
      "epoch:22 step:20774 [D loss: 0.269169, acc.: 55.47%] [G loss: 0.416427]\n",
      "epoch:22 step:20775 [D loss: 0.246825, acc.: 56.25%] [G loss: 0.451729]\n",
      "epoch:22 step:20776 [D loss: 0.240572, acc.: 55.47%] [G loss: 0.446766]\n",
      "epoch:22 step:20777 [D loss: 0.223165, acc.: 58.59%] [G loss: 0.416289]\n",
      "epoch:22 step:20778 [D loss: 0.233453, acc.: 59.38%] [G loss: 0.429927]\n",
      "epoch:22 step:20779 [D loss: 0.233262, acc.: 60.16%] [G loss: 0.399818]\n",
      "epoch:22 step:20780 [D loss: 0.225606, acc.: 62.50%] [G loss: 0.419965]\n",
      "epoch:22 step:20781 [D loss: 0.223129, acc.: 60.94%] [G loss: 0.416630]\n",
      "epoch:22 step:20782 [D loss: 0.204132, acc.: 68.75%] [G loss: 0.441728]\n",
      "epoch:22 step:20783 [D loss: 0.241094, acc.: 57.81%] [G loss: 0.418678]\n",
      "epoch:22 step:20784 [D loss: 0.235515, acc.: 61.72%] [G loss: 0.425376]\n",
      "epoch:22 step:20785 [D loss: 0.230616, acc.: 62.50%] [G loss: 0.403639]\n",
      "epoch:22 step:20786 [D loss: 0.222291, acc.: 67.97%] [G loss: 0.429066]\n",
      "epoch:22 step:20787 [D loss: 0.234698, acc.: 55.47%] [G loss: 0.449379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20788 [D loss: 0.225825, acc.: 63.28%] [G loss: 0.410342]\n",
      "epoch:22 step:20789 [D loss: 0.241181, acc.: 56.25%] [G loss: 0.408868]\n",
      "epoch:22 step:20790 [D loss: 0.215117, acc.: 67.97%] [G loss: 0.428429]\n",
      "epoch:22 step:20791 [D loss: 0.244688, acc.: 58.59%] [G loss: 0.364404]\n",
      "epoch:22 step:20792 [D loss: 0.222141, acc.: 60.94%] [G loss: 0.405625]\n",
      "epoch:22 step:20793 [D loss: 0.245389, acc.: 60.16%] [G loss: 0.439201]\n",
      "epoch:22 step:20794 [D loss: 0.245943, acc.: 59.38%] [G loss: 0.411405]\n",
      "epoch:22 step:20795 [D loss: 0.246065, acc.: 58.59%] [G loss: 0.418295]\n",
      "epoch:22 step:20796 [D loss: 0.222622, acc.: 63.28%] [G loss: 0.458013]\n",
      "epoch:22 step:20797 [D loss: 0.233917, acc.: 63.28%] [G loss: 0.416988]\n",
      "epoch:22 step:20798 [D loss: 0.223896, acc.: 67.19%] [G loss: 0.415186]\n",
      "epoch:22 step:20799 [D loss: 0.223852, acc.: 63.28%] [G loss: 0.432454]\n",
      "epoch:22 step:20800 [D loss: 0.233438, acc.: 64.06%] [G loss: 0.417700]\n",
      "epoch:22 step:20801 [D loss: 0.227653, acc.: 63.28%] [G loss: 0.424081]\n",
      "epoch:22 step:20802 [D loss: 0.239541, acc.: 59.38%] [G loss: 0.384178]\n",
      "epoch:22 step:20803 [D loss: 0.241806, acc.: 53.91%] [G loss: 0.379976]\n",
      "epoch:22 step:20804 [D loss: 0.223903, acc.: 60.16%] [G loss: 0.355624]\n",
      "epoch:22 step:20805 [D loss: 0.220634, acc.: 71.09%] [G loss: 0.447423]\n",
      "epoch:22 step:20806 [D loss: 0.227062, acc.: 60.16%] [G loss: 0.431175]\n",
      "epoch:22 step:20807 [D loss: 0.227282, acc.: 61.72%] [G loss: 0.422668]\n",
      "epoch:22 step:20808 [D loss: 0.202638, acc.: 64.84%] [G loss: 0.432060]\n",
      "epoch:22 step:20809 [D loss: 0.217003, acc.: 65.62%] [G loss: 0.416114]\n",
      "epoch:22 step:20810 [D loss: 0.232506, acc.: 60.94%] [G loss: 0.451819]\n",
      "epoch:22 step:20811 [D loss: 0.203923, acc.: 69.53%] [G loss: 0.432967]\n",
      "epoch:22 step:20812 [D loss: 0.197975, acc.: 71.88%] [G loss: 0.432411]\n",
      "epoch:22 step:20813 [D loss: 0.232672, acc.: 60.16%] [G loss: 0.415205]\n",
      "epoch:22 step:20814 [D loss: 0.259731, acc.: 57.81%] [G loss: 0.405211]\n",
      "epoch:22 step:20815 [D loss: 0.244563, acc.: 60.16%] [G loss: 0.401686]\n",
      "epoch:22 step:20816 [D loss: 0.229053, acc.: 60.94%] [G loss: 0.422297]\n",
      "epoch:22 step:20817 [D loss: 0.250445, acc.: 53.91%] [G loss: 0.444002]\n",
      "epoch:22 step:20818 [D loss: 0.229032, acc.: 63.28%] [G loss: 0.424863]\n",
      "epoch:22 step:20819 [D loss: 0.225690, acc.: 58.59%] [G loss: 0.436110]\n",
      "epoch:22 step:20820 [D loss: 0.200903, acc.: 65.62%] [G loss: 0.467149]\n",
      "epoch:22 step:20821 [D loss: 0.232528, acc.: 67.19%] [G loss: 0.450654]\n",
      "epoch:22 step:20822 [D loss: 0.191730, acc.: 66.41%] [G loss: 0.501653]\n",
      "epoch:22 step:20823 [D loss: 0.201508, acc.: 62.50%] [G loss: 0.493075]\n",
      "epoch:22 step:20824 [D loss: 0.292435, acc.: 46.09%] [G loss: 0.429002]\n",
      "epoch:22 step:20825 [D loss: 0.244586, acc.: 57.03%] [G loss: 0.417529]\n",
      "epoch:22 step:20826 [D loss: 0.237492, acc.: 64.06%] [G loss: 0.420681]\n",
      "epoch:22 step:20827 [D loss: 0.211635, acc.: 62.50%] [G loss: 0.461326]\n",
      "epoch:22 step:20828 [D loss: 0.221551, acc.: 62.50%] [G loss: 0.413951]\n",
      "epoch:22 step:20829 [D loss: 0.231300, acc.: 60.94%] [G loss: 0.414398]\n",
      "epoch:22 step:20830 [D loss: 0.205794, acc.: 64.06%] [G loss: 0.458097]\n",
      "epoch:22 step:20831 [D loss: 0.225841, acc.: 59.38%] [G loss: 0.426054]\n",
      "epoch:22 step:20832 [D loss: 0.199719, acc.: 69.53%] [G loss: 0.454080]\n",
      "epoch:22 step:20833 [D loss: 0.177368, acc.: 73.44%] [G loss: 0.505734]\n",
      "epoch:22 step:20834 [D loss: 0.295657, acc.: 50.78%] [G loss: 0.449145]\n",
      "epoch:22 step:20835 [D loss: 0.221572, acc.: 60.94%] [G loss: 0.420113]\n",
      "epoch:22 step:20836 [D loss: 0.226842, acc.: 64.06%] [G loss: 0.475954]\n",
      "epoch:22 step:20837 [D loss: 0.209277, acc.: 61.72%] [G loss: 0.443950]\n",
      "epoch:22 step:20838 [D loss: 0.259666, acc.: 52.34%] [G loss: 0.417573]\n",
      "epoch:22 step:20839 [D loss: 0.218539, acc.: 67.19%] [G loss: 0.433032]\n",
      "epoch:22 step:20840 [D loss: 0.252962, acc.: 53.12%] [G loss: 0.408652]\n",
      "epoch:22 step:20841 [D loss: 0.216584, acc.: 67.19%] [G loss: 0.415662]\n",
      "epoch:22 step:20842 [D loss: 0.244017, acc.: 56.25%] [G loss: 0.385235]\n",
      "epoch:22 step:20843 [D loss: 0.189859, acc.: 71.09%] [G loss: 0.445271]\n",
      "epoch:22 step:20844 [D loss: 0.197387, acc.: 71.88%] [G loss: 0.466109]\n",
      "epoch:22 step:20845 [D loss: 0.191192, acc.: 68.75%] [G loss: 0.488028]\n",
      "epoch:22 step:20846 [D loss: 0.164425, acc.: 75.78%] [G loss: 0.493649]\n",
      "epoch:22 step:20847 [D loss: 0.271089, acc.: 57.03%] [G loss: 0.454178]\n",
      "epoch:22 step:20848 [D loss: 0.222740, acc.: 61.72%] [G loss: 0.445274]\n",
      "epoch:22 step:20849 [D loss: 0.222369, acc.: 62.50%] [G loss: 0.457364]\n",
      "epoch:22 step:20850 [D loss: 0.225737, acc.: 59.38%] [G loss: 0.421194]\n",
      "epoch:22 step:20851 [D loss: 0.222313, acc.: 64.84%] [G loss: 0.428005]\n",
      "epoch:22 step:20852 [D loss: 0.197752, acc.: 71.09%] [G loss: 0.406762]\n",
      "epoch:22 step:20853 [D loss: 0.216428, acc.: 62.50%] [G loss: 0.404163]\n",
      "epoch:22 step:20854 [D loss: 0.201803, acc.: 67.19%] [G loss: 0.472376]\n",
      "epoch:22 step:20855 [D loss: 0.209411, acc.: 64.84%] [G loss: 0.456756]\n",
      "epoch:22 step:20856 [D loss: 0.219393, acc.: 60.94%] [G loss: 0.462412]\n",
      "epoch:22 step:20857 [D loss: 0.214606, acc.: 65.62%] [G loss: 0.450219]\n",
      "epoch:22 step:20858 [D loss: 0.218418, acc.: 65.62%] [G loss: 0.459305]\n",
      "epoch:22 step:20859 [D loss: 0.205640, acc.: 64.06%] [G loss: 0.471415]\n",
      "epoch:22 step:20860 [D loss: 0.243893, acc.: 64.84%] [G loss: 0.462455]\n",
      "epoch:22 step:20861 [D loss: 0.227933, acc.: 60.94%] [G loss: 0.448148]\n",
      "epoch:22 step:20862 [D loss: 0.207971, acc.: 68.75%] [G loss: 0.478590]\n",
      "epoch:22 step:20863 [D loss: 0.263111, acc.: 55.47%] [G loss: 0.470016]\n",
      "epoch:22 step:20864 [D loss: 0.289960, acc.: 46.09%] [G loss: 0.400122]\n",
      "epoch:22 step:20865 [D loss: 0.254021, acc.: 56.25%] [G loss: 0.404239]\n",
      "epoch:22 step:20866 [D loss: 0.229696, acc.: 63.28%] [G loss: 0.462790]\n",
      "epoch:22 step:20867 [D loss: 0.236740, acc.: 60.16%] [G loss: 0.401313]\n",
      "epoch:22 step:20868 [D loss: 0.234082, acc.: 57.03%] [G loss: 0.423102]\n",
      "epoch:22 step:20869 [D loss: 0.212601, acc.: 64.06%] [G loss: 0.456726]\n",
      "epoch:22 step:20870 [D loss: 0.200027, acc.: 71.09%] [G loss: 0.415069]\n",
      "epoch:22 step:20871 [D loss: 0.230390, acc.: 60.94%] [G loss: 0.418796]\n",
      "epoch:22 step:20872 [D loss: 0.202264, acc.: 68.75%] [G loss: 0.434387]\n",
      "epoch:22 step:20873 [D loss: 0.220984, acc.: 62.50%] [G loss: 0.427255]\n",
      "epoch:22 step:20874 [D loss: 0.212375, acc.: 62.50%] [G loss: 0.455531]\n",
      "epoch:22 step:20875 [D loss: 0.236706, acc.: 53.91%] [G loss: 0.445828]\n",
      "epoch:22 step:20876 [D loss: 0.207190, acc.: 66.41%] [G loss: 0.452279]\n",
      "epoch:22 step:20877 [D loss: 0.262824, acc.: 51.56%] [G loss: 0.426700]\n",
      "epoch:22 step:20878 [D loss: 0.204601, acc.: 70.31%] [G loss: 0.432943]\n",
      "epoch:22 step:20879 [D loss: 0.236752, acc.: 61.72%] [G loss: 0.396463]\n",
      "epoch:22 step:20880 [D loss: 0.214444, acc.: 68.75%] [G loss: 0.392612]\n",
      "epoch:22 step:20881 [D loss: 0.218907, acc.: 64.84%] [G loss: 0.439442]\n",
      "epoch:22 step:20882 [D loss: 0.195277, acc.: 67.97%] [G loss: 0.438338]\n",
      "epoch:22 step:20883 [D loss: 0.218429, acc.: 64.84%] [G loss: 0.464487]\n",
      "epoch:22 step:20884 [D loss: 0.219128, acc.: 64.06%] [G loss: 0.466972]\n",
      "epoch:22 step:20885 [D loss: 0.198117, acc.: 71.88%] [G loss: 0.490853]\n",
      "epoch:22 step:20886 [D loss: 0.239615, acc.: 53.91%] [G loss: 0.463102]\n",
      "epoch:22 step:20887 [D loss: 0.210217, acc.: 64.84%] [G loss: 0.424658]\n",
      "epoch:22 step:20888 [D loss: 0.196040, acc.: 71.88%] [G loss: 0.462406]\n",
      "epoch:22 step:20889 [D loss: 0.206019, acc.: 67.97%] [G loss: 0.451429]\n",
      "epoch:22 step:20890 [D loss: 0.216999, acc.: 62.50%] [G loss: 0.428491]\n",
      "epoch:22 step:20891 [D loss: 0.265196, acc.: 53.91%] [G loss: 0.389005]\n",
      "epoch:22 step:20892 [D loss: 0.233558, acc.: 57.81%] [G loss: 0.446990]\n",
      "epoch:22 step:20893 [D loss: 0.226455, acc.: 62.50%] [G loss: 0.409887]\n",
      "epoch:22 step:20894 [D loss: 0.197579, acc.: 70.31%] [G loss: 0.461750]\n",
      "epoch:22 step:20895 [D loss: 0.245233, acc.: 56.25%] [G loss: 0.407434]\n",
      "epoch:22 step:20896 [D loss: 0.234176, acc.: 60.94%] [G loss: 0.433681]\n",
      "epoch:22 step:20897 [D loss: 0.198374, acc.: 72.66%] [G loss: 0.480319]\n",
      "epoch:22 step:20898 [D loss: 0.223889, acc.: 64.06%] [G loss: 0.408916]\n",
      "epoch:22 step:20899 [D loss: 0.244111, acc.: 59.38%] [G loss: 0.440571]\n",
      "epoch:22 step:20900 [D loss: 0.225684, acc.: 64.06%] [G loss: 0.447610]\n",
      "epoch:22 step:20901 [D loss: 0.222727, acc.: 64.84%] [G loss: 0.438204]\n",
      "epoch:22 step:20902 [D loss: 0.210085, acc.: 64.84%] [G loss: 0.446720]\n",
      "epoch:22 step:20903 [D loss: 0.199571, acc.: 70.31%] [G loss: 0.468374]\n",
      "epoch:22 step:20904 [D loss: 0.218091, acc.: 64.84%] [G loss: 0.438838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20905 [D loss: 0.255567, acc.: 54.69%] [G loss: 0.401518]\n",
      "epoch:22 step:20906 [D loss: 0.212946, acc.: 64.06%] [G loss: 0.431523]\n",
      "epoch:22 step:20907 [D loss: 0.231382, acc.: 58.59%] [G loss: 0.431282]\n",
      "epoch:22 step:20908 [D loss: 0.244512, acc.: 52.34%] [G loss: 0.405057]\n",
      "epoch:22 step:20909 [D loss: 0.204230, acc.: 67.19%] [G loss: 0.419109]\n",
      "epoch:22 step:20910 [D loss: 0.205296, acc.: 68.75%] [G loss: 0.422931]\n",
      "epoch:22 step:20911 [D loss: 0.234436, acc.: 60.16%] [G loss: 0.428499]\n",
      "epoch:22 step:20912 [D loss: 0.221296, acc.: 64.06%] [G loss: 0.439749]\n",
      "epoch:22 step:20913 [D loss: 0.205586, acc.: 69.53%] [G loss: 0.443516]\n",
      "epoch:22 step:20914 [D loss: 0.226741, acc.: 60.94%] [G loss: 0.447931]\n",
      "epoch:22 step:20915 [D loss: 0.253655, acc.: 58.59%] [G loss: 0.456104]\n",
      "epoch:22 step:20916 [D loss: 0.219878, acc.: 64.06%] [G loss: 0.436687]\n",
      "epoch:22 step:20917 [D loss: 0.233429, acc.: 67.97%] [G loss: 0.455961]\n",
      "epoch:22 step:20918 [D loss: 0.249114, acc.: 53.91%] [G loss: 0.421213]\n",
      "epoch:22 step:20919 [D loss: 0.235938, acc.: 60.16%] [G loss: 0.393090]\n",
      "epoch:22 step:20920 [D loss: 0.216102, acc.: 63.28%] [G loss: 0.458214]\n",
      "epoch:22 step:20921 [D loss: 0.204289, acc.: 68.75%] [G loss: 0.478323]\n",
      "epoch:22 step:20922 [D loss: 0.232407, acc.: 61.72%] [G loss: 0.412159]\n",
      "epoch:22 step:20923 [D loss: 0.224388, acc.: 65.62%] [G loss: 0.425812]\n",
      "epoch:22 step:20924 [D loss: 0.220649, acc.: 67.97%] [G loss: 0.444281]\n",
      "epoch:22 step:20925 [D loss: 0.211582, acc.: 64.84%] [G loss: 0.446846]\n",
      "epoch:22 step:20926 [D loss: 0.186999, acc.: 75.00%] [G loss: 0.474492]\n",
      "epoch:22 step:20927 [D loss: 0.171429, acc.: 76.56%] [G loss: 0.463231]\n",
      "epoch:22 step:20928 [D loss: 0.174952, acc.: 72.66%] [G loss: 0.513615]\n",
      "epoch:22 step:20929 [D loss: 0.201651, acc.: 67.97%] [G loss: 0.504785]\n",
      "epoch:22 step:20930 [D loss: 0.253988, acc.: 55.47%] [G loss: 0.466832]\n",
      "epoch:22 step:20931 [D loss: 0.231258, acc.: 59.38%] [G loss: 0.444577]\n",
      "epoch:22 step:20932 [D loss: 0.207168, acc.: 63.28%] [G loss: 0.473378]\n",
      "epoch:22 step:20933 [D loss: 0.232690, acc.: 58.59%] [G loss: 0.470021]\n",
      "epoch:22 step:20934 [D loss: 0.224751, acc.: 66.41%] [G loss: 0.425692]\n",
      "epoch:22 step:20935 [D loss: 0.204323, acc.: 68.75%] [G loss: 0.477289]\n",
      "epoch:22 step:20936 [D loss: 0.215399, acc.: 66.41%] [G loss: 0.474035]\n",
      "epoch:22 step:20937 [D loss: 0.270307, acc.: 55.47%] [G loss: 0.416913]\n",
      "epoch:22 step:20938 [D loss: 0.240695, acc.: 60.94%] [G loss: 0.407027]\n",
      "epoch:22 step:20939 [D loss: 0.206047, acc.: 68.75%] [G loss: 0.444196]\n",
      "epoch:22 step:20940 [D loss: 0.220221, acc.: 64.84%] [G loss: 0.473342]\n",
      "epoch:22 step:20941 [D loss: 0.219702, acc.: 64.84%] [G loss: 0.504312]\n",
      "epoch:22 step:20942 [D loss: 0.213858, acc.: 65.62%] [G loss: 0.477571]\n",
      "epoch:22 step:20943 [D loss: 0.243849, acc.: 49.22%] [G loss: 0.440382]\n",
      "epoch:22 step:20944 [D loss: 0.230243, acc.: 57.03%] [G loss: 0.357014]\n",
      "epoch:22 step:20945 [D loss: 0.210557, acc.: 67.97%] [G loss: 0.427824]\n",
      "epoch:22 step:20946 [D loss: 0.201442, acc.: 75.00%] [G loss: 0.445410]\n",
      "epoch:22 step:20947 [D loss: 0.213547, acc.: 60.16%] [G loss: 0.408392]\n",
      "epoch:22 step:20948 [D loss: 0.220824, acc.: 64.06%] [G loss: 0.471686]\n",
      "epoch:22 step:20949 [D loss: 0.203505, acc.: 67.97%] [G loss: 0.471678]\n",
      "epoch:22 step:20950 [D loss: 0.202772, acc.: 67.97%] [G loss: 0.456520]\n",
      "epoch:22 step:20951 [D loss: 0.201154, acc.: 66.41%] [G loss: 0.434778]\n",
      "epoch:22 step:20952 [D loss: 0.220124, acc.: 69.53%] [G loss: 0.424201]\n",
      "epoch:22 step:20953 [D loss: 0.192386, acc.: 70.31%] [G loss: 0.439494]\n",
      "epoch:22 step:20954 [D loss: 0.206309, acc.: 68.75%] [G loss: 0.414625]\n",
      "epoch:22 step:20955 [D loss: 0.241741, acc.: 54.69%] [G loss: 0.428307]\n",
      "epoch:22 step:20956 [D loss: 0.237173, acc.: 57.81%] [G loss: 0.452404]\n",
      "epoch:22 step:20957 [D loss: 0.221173, acc.: 64.06%] [G loss: 0.478448]\n",
      "epoch:22 step:20958 [D loss: 0.220290, acc.: 60.16%] [G loss: 0.427964]\n",
      "epoch:22 step:20959 [D loss: 0.224687, acc.: 64.84%] [G loss: 0.467268]\n",
      "epoch:22 step:20960 [D loss: 0.199313, acc.: 67.19%] [G loss: 0.520857]\n",
      "epoch:22 step:20961 [D loss: 0.212182, acc.: 69.53%] [G loss: 0.504315]\n",
      "epoch:22 step:20962 [D loss: 0.260590, acc.: 57.03%] [G loss: 0.410820]\n",
      "epoch:22 step:20963 [D loss: 0.262823, acc.: 49.22%] [G loss: 0.435879]\n",
      "epoch:22 step:20964 [D loss: 0.220693, acc.: 67.19%] [G loss: 0.401103]\n",
      "epoch:22 step:20965 [D loss: 0.233805, acc.: 59.38%] [G loss: 0.408336]\n",
      "epoch:22 step:20966 [D loss: 0.244000, acc.: 58.59%] [G loss: 0.442143]\n",
      "epoch:22 step:20967 [D loss: 0.206630, acc.: 68.75%] [G loss: 0.454176]\n",
      "epoch:22 step:20968 [D loss: 0.172769, acc.: 76.56%] [G loss: 0.497517]\n",
      "epoch:22 step:20969 [D loss: 0.222709, acc.: 67.97%] [G loss: 0.473503]\n",
      "epoch:22 step:20970 [D loss: 0.237446, acc.: 59.38%] [G loss: 0.466878]\n",
      "epoch:22 step:20971 [D loss: 0.199251, acc.: 69.53%] [G loss: 0.472862]\n",
      "epoch:22 step:20972 [D loss: 0.208542, acc.: 67.19%] [G loss: 0.449326]\n",
      "epoch:22 step:20973 [D loss: 0.224804, acc.: 67.19%] [G loss: 0.455318]\n",
      "epoch:22 step:20974 [D loss: 0.215572, acc.: 67.97%] [G loss: 0.441203]\n",
      "epoch:22 step:20975 [D loss: 0.202688, acc.: 71.88%] [G loss: 0.429929]\n",
      "epoch:22 step:20976 [D loss: 0.225764, acc.: 63.28%] [G loss: 0.467553]\n",
      "epoch:22 step:20977 [D loss: 0.229562, acc.: 61.72%] [G loss: 0.421772]\n",
      "epoch:22 step:20978 [D loss: 0.209302, acc.: 70.31%] [G loss: 0.436270]\n",
      "epoch:22 step:20979 [D loss: 0.238323, acc.: 59.38%] [G loss: 0.404169]\n",
      "epoch:22 step:20980 [D loss: 0.206986, acc.: 67.97%] [G loss: 0.429053]\n",
      "epoch:22 step:20981 [D loss: 0.219519, acc.: 64.84%] [G loss: 0.463250]\n",
      "epoch:22 step:20982 [D loss: 0.243423, acc.: 55.47%] [G loss: 0.412404]\n",
      "epoch:22 step:20983 [D loss: 0.204062, acc.: 68.75%] [G loss: 0.414933]\n",
      "epoch:22 step:20984 [D loss: 0.215034, acc.: 66.41%] [G loss: 0.415741]\n",
      "epoch:22 step:20985 [D loss: 0.189056, acc.: 72.66%] [G loss: 0.429563]\n",
      "epoch:22 step:20986 [D loss: 0.211113, acc.: 71.88%] [G loss: 0.456013]\n",
      "epoch:22 step:20987 [D loss: 0.242097, acc.: 57.03%] [G loss: 0.458181]\n",
      "epoch:22 step:20988 [D loss: 0.174535, acc.: 75.00%] [G loss: 0.444463]\n",
      "epoch:22 step:20989 [D loss: 0.233304, acc.: 61.72%] [G loss: 0.419102]\n",
      "epoch:22 step:20990 [D loss: 0.241255, acc.: 57.81%] [G loss: 0.435176]\n",
      "epoch:22 step:20991 [D loss: 0.249508, acc.: 55.47%] [G loss: 0.441021]\n",
      "epoch:22 step:20992 [D loss: 0.211648, acc.: 64.84%] [G loss: 0.425878]\n",
      "epoch:22 step:20993 [D loss: 0.237185, acc.: 57.03%] [G loss: 0.433192]\n",
      "epoch:22 step:20994 [D loss: 0.239464, acc.: 55.47%] [G loss: 0.435165]\n",
      "epoch:22 step:20995 [D loss: 0.226308, acc.: 59.38%] [G loss: 0.410985]\n",
      "epoch:22 step:20996 [D loss: 0.230647, acc.: 62.50%] [G loss: 0.471719]\n",
      "epoch:22 step:20997 [D loss: 0.221439, acc.: 63.28%] [G loss: 0.473889]\n",
      "epoch:22 step:20998 [D loss: 0.200991, acc.: 71.09%] [G loss: 0.459003]\n",
      "epoch:22 step:20999 [D loss: 0.215333, acc.: 64.06%] [G loss: 0.456237]\n",
      "epoch:22 step:21000 [D loss: 0.218476, acc.: 63.28%] [G loss: 0.428088]\n",
      "epoch:22 step:21001 [D loss: 0.206299, acc.: 68.75%] [G loss: 0.410067]\n",
      "epoch:22 step:21002 [D loss: 0.222718, acc.: 64.84%] [G loss: 0.436995]\n",
      "epoch:22 step:21003 [D loss: 0.215785, acc.: 67.19%] [G loss: 0.466306]\n",
      "epoch:22 step:21004 [D loss: 0.248390, acc.: 52.34%] [G loss: 0.411360]\n",
      "epoch:22 step:21005 [D loss: 0.222589, acc.: 64.84%] [G loss: 0.424045]\n",
      "epoch:22 step:21006 [D loss: 0.221813, acc.: 60.16%] [G loss: 0.429459]\n",
      "epoch:22 step:21007 [D loss: 0.237403, acc.: 53.12%] [G loss: 0.387313]\n",
      "epoch:22 step:21008 [D loss: 0.228076, acc.: 60.16%] [G loss: 0.447862]\n",
      "epoch:22 step:21009 [D loss: 0.235123, acc.: 58.59%] [G loss: 0.414056]\n",
      "epoch:22 step:21010 [D loss: 0.265229, acc.: 51.56%] [G loss: 0.476615]\n",
      "epoch:22 step:21011 [D loss: 0.237836, acc.: 64.06%] [G loss: 0.428993]\n",
      "epoch:22 step:21012 [D loss: 0.198046, acc.: 67.19%] [G loss: 0.525748]\n",
      "epoch:22 step:21013 [D loss: 0.207908, acc.: 65.62%] [G loss: 0.481479]\n",
      "epoch:22 step:21014 [D loss: 0.272802, acc.: 54.69%] [G loss: 0.411352]\n",
      "epoch:22 step:21015 [D loss: 0.245940, acc.: 54.69%] [G loss: 0.429696]\n",
      "epoch:22 step:21016 [D loss: 0.211441, acc.: 70.31%] [G loss: 0.457643]\n",
      "epoch:22 step:21017 [D loss: 0.217050, acc.: 64.84%] [G loss: 0.415145]\n",
      "epoch:22 step:21018 [D loss: 0.229528, acc.: 63.28%] [G loss: 0.388284]\n",
      "epoch:22 step:21019 [D loss: 0.211859, acc.: 65.62%] [G loss: 0.445713]\n",
      "epoch:22 step:21020 [D loss: 0.203775, acc.: 65.62%] [G loss: 0.509096]\n",
      "epoch:22 step:21021 [D loss: 0.234993, acc.: 56.25%] [G loss: 0.455282]\n",
      "epoch:22 step:21022 [D loss: 0.239264, acc.: 58.59%] [G loss: 0.430953]\n",
      "epoch:22 step:21023 [D loss: 0.213121, acc.: 64.84%] [G loss: 0.442042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21024 [D loss: 0.234860, acc.: 62.50%] [G loss: 0.442766]\n",
      "epoch:22 step:21025 [D loss: 0.281786, acc.: 46.88%] [G loss: 0.361232]\n",
      "epoch:22 step:21026 [D loss: 0.226061, acc.: 64.84%] [G loss: 0.423671]\n",
      "epoch:22 step:21027 [D loss: 0.213778, acc.: 67.19%] [G loss: 0.388847]\n",
      "epoch:22 step:21028 [D loss: 0.232273, acc.: 60.94%] [G loss: 0.408596]\n",
      "epoch:22 step:21029 [D loss: 0.171285, acc.: 78.91%] [G loss: 0.469132]\n",
      "epoch:22 step:21030 [D loss: 0.208339, acc.: 62.50%] [G loss: 0.482584]\n",
      "epoch:22 step:21031 [D loss: 0.224175, acc.: 59.38%] [G loss: 0.443122]\n",
      "epoch:22 step:21032 [D loss: 0.260257, acc.: 55.47%] [G loss: 0.442970]\n",
      "epoch:22 step:21033 [D loss: 0.254076, acc.: 54.69%] [G loss: 0.439526]\n",
      "epoch:22 step:21034 [D loss: 0.231079, acc.: 61.72%] [G loss: 0.395689]\n",
      "epoch:22 step:21035 [D loss: 0.237069, acc.: 55.47%] [G loss: 0.417478]\n",
      "epoch:22 step:21036 [D loss: 0.248851, acc.: 53.91%] [G loss: 0.380308]\n",
      "epoch:22 step:21037 [D loss: 0.230614, acc.: 60.16%] [G loss: 0.426521]\n",
      "epoch:22 step:21038 [D loss: 0.231504, acc.: 63.28%] [G loss: 0.412824]\n",
      "epoch:22 step:21039 [D loss: 0.200915, acc.: 66.41%] [G loss: 0.429667]\n",
      "epoch:22 step:21040 [D loss: 0.228125, acc.: 64.06%] [G loss: 0.415747]\n",
      "epoch:22 step:21041 [D loss: 0.213560, acc.: 64.84%] [G loss: 0.458947]\n",
      "epoch:22 step:21042 [D loss: 0.201260, acc.: 74.22%] [G loss: 0.443038]\n",
      "epoch:22 step:21043 [D loss: 0.189415, acc.: 72.66%] [G loss: 0.468677]\n",
      "epoch:22 step:21044 [D loss: 0.202851, acc.: 70.31%] [G loss: 0.455395]\n",
      "epoch:22 step:21045 [D loss: 0.265657, acc.: 53.91%] [G loss: 0.423403]\n",
      "epoch:22 step:21046 [D loss: 0.214464, acc.: 63.28%] [G loss: 0.448161]\n",
      "epoch:22 step:21047 [D loss: 0.225711, acc.: 67.19%] [G loss: 0.403893]\n",
      "epoch:22 step:21048 [D loss: 0.231505, acc.: 59.38%] [G loss: 0.436024]\n",
      "epoch:22 step:21049 [D loss: 0.224311, acc.: 62.50%] [G loss: 0.442536]\n",
      "epoch:22 step:21050 [D loss: 0.198013, acc.: 70.31%] [G loss: 0.475407]\n",
      "epoch:22 step:21051 [D loss: 0.290756, acc.: 46.88%] [G loss: 0.398699]\n",
      "epoch:22 step:21052 [D loss: 0.244159, acc.: 52.34%] [G loss: 0.407763]\n",
      "epoch:22 step:21053 [D loss: 0.214447, acc.: 69.53%] [G loss: 0.440790]\n",
      "epoch:22 step:21054 [D loss: 0.242290, acc.: 55.47%] [G loss: 0.475320]\n",
      "epoch:22 step:21055 [D loss: 0.226865, acc.: 60.16%] [G loss: 0.471849]\n",
      "epoch:22 step:21056 [D loss: 0.225555, acc.: 59.38%] [G loss: 0.464918]\n",
      "epoch:22 step:21057 [D loss: 0.229614, acc.: 59.38%] [G loss: 0.407971]\n",
      "epoch:22 step:21058 [D loss: 0.238734, acc.: 61.72%] [G loss: 0.434677]\n",
      "epoch:22 step:21059 [D loss: 0.204856, acc.: 69.53%] [G loss: 0.460263]\n",
      "epoch:22 step:21060 [D loss: 0.227340, acc.: 58.59%] [G loss: 0.451844]\n",
      "epoch:22 step:21061 [D loss: 0.206705, acc.: 71.88%] [G loss: 0.446062]\n",
      "epoch:22 step:21062 [D loss: 0.246313, acc.: 57.81%] [G loss: 0.446416]\n",
      "epoch:22 step:21063 [D loss: 0.205485, acc.: 66.41%] [G loss: 0.442119]\n",
      "epoch:22 step:21064 [D loss: 0.217759, acc.: 67.97%] [G loss: 0.433840]\n",
      "epoch:22 step:21065 [D loss: 0.207777, acc.: 69.53%] [G loss: 0.437631]\n",
      "epoch:22 step:21066 [D loss: 0.225917, acc.: 67.97%] [G loss: 0.429242]\n",
      "epoch:22 step:21067 [D loss: 0.195313, acc.: 70.31%] [G loss: 0.434613]\n",
      "epoch:22 step:21068 [D loss: 0.216949, acc.: 68.75%] [G loss: 0.442605]\n",
      "epoch:22 step:21069 [D loss: 0.221790, acc.: 63.28%] [G loss: 0.450603]\n",
      "epoch:22 step:21070 [D loss: 0.216827, acc.: 67.19%] [G loss: 0.466062]\n",
      "epoch:22 step:21071 [D loss: 0.206970, acc.: 68.75%] [G loss: 0.452464]\n",
      "epoch:22 step:21072 [D loss: 0.281132, acc.: 49.22%] [G loss: 0.422521]\n",
      "epoch:22 step:21073 [D loss: 0.231195, acc.: 60.16%] [G loss: 0.421500]\n",
      "epoch:22 step:21074 [D loss: 0.258616, acc.: 57.03%] [G loss: 0.401922]\n",
      "epoch:22 step:21075 [D loss: 0.217459, acc.: 61.72%] [G loss: 0.436348]\n",
      "epoch:22 step:21076 [D loss: 0.252678, acc.: 56.25%] [G loss: 0.414895]\n",
      "epoch:22 step:21077 [D loss: 0.221035, acc.: 60.16%] [G loss: 0.397817]\n",
      "epoch:22 step:21078 [D loss: 0.236240, acc.: 62.50%] [G loss: 0.422212]\n",
      "epoch:22 step:21079 [D loss: 0.247388, acc.: 57.03%] [G loss: 0.397667]\n",
      "epoch:22 step:21080 [D loss: 0.226396, acc.: 60.16%] [G loss: 0.419690]\n",
      "epoch:22 step:21081 [D loss: 0.222460, acc.: 65.62%] [G loss: 0.424661]\n",
      "epoch:22 step:21082 [D loss: 0.200570, acc.: 67.97%] [G loss: 0.466825]\n",
      "epoch:22 step:21083 [D loss: 0.210722, acc.: 67.97%] [G loss: 0.443397]\n",
      "epoch:22 step:21084 [D loss: 0.193126, acc.: 69.53%] [G loss: 0.453243]\n",
      "epoch:22 step:21085 [D loss: 0.213209, acc.: 67.19%] [G loss: 0.455770]\n",
      "epoch:22 step:21086 [D loss: 0.224921, acc.: 62.50%] [G loss: 0.487513]\n",
      "epoch:22 step:21087 [D loss: 0.258992, acc.: 53.12%] [G loss: 0.484587]\n",
      "epoch:22 step:21088 [D loss: 0.195586, acc.: 73.44%] [G loss: 0.490752]\n",
      "epoch:22 step:21089 [D loss: 0.186189, acc.: 75.78%] [G loss: 0.433707]\n",
      "epoch:22 step:21090 [D loss: 0.232494, acc.: 62.50%] [G loss: 0.445696]\n",
      "epoch:22 step:21091 [D loss: 0.248308, acc.: 62.50%] [G loss: 0.443068]\n",
      "epoch:22 step:21092 [D loss: 0.235084, acc.: 63.28%] [G loss: 0.406264]\n",
      "epoch:22 step:21093 [D loss: 0.232243, acc.: 65.62%] [G loss: 0.384588]\n",
      "epoch:22 step:21094 [D loss: 0.232282, acc.: 62.50%] [G loss: 0.470071]\n",
      "epoch:22 step:21095 [D loss: 0.186225, acc.: 75.00%] [G loss: 0.469456]\n",
      "epoch:22 step:21096 [D loss: 0.264833, acc.: 54.69%] [G loss: 0.413893]\n",
      "epoch:22 step:21097 [D loss: 0.223462, acc.: 58.59%] [G loss: 0.445360]\n",
      "epoch:22 step:21098 [D loss: 0.196447, acc.: 68.75%] [G loss: 0.453938]\n",
      "epoch:22 step:21099 [D loss: 0.202801, acc.: 68.75%] [G loss: 0.488546]\n",
      "epoch:22 step:21100 [D loss: 0.226124, acc.: 63.28%] [G loss: 0.466300]\n",
      "epoch:22 step:21101 [D loss: 0.243624, acc.: 58.59%] [G loss: 0.416521]\n",
      "epoch:22 step:21102 [D loss: 0.207650, acc.: 67.19%] [G loss: 0.457174]\n",
      "epoch:22 step:21103 [D loss: 0.229252, acc.: 65.62%] [G loss: 0.454904]\n",
      "epoch:22 step:21104 [D loss: 0.230468, acc.: 60.16%] [G loss: 0.412980]\n",
      "epoch:22 step:21105 [D loss: 0.223396, acc.: 66.41%] [G loss: 0.405599]\n",
      "epoch:22 step:21106 [D loss: 0.223801, acc.: 63.28%] [G loss: 0.473523]\n",
      "epoch:22 step:21107 [D loss: 0.209233, acc.: 68.75%] [G loss: 0.458072]\n",
      "epoch:22 step:21108 [D loss: 0.223342, acc.: 61.72%] [G loss: 0.415795]\n",
      "epoch:22 step:21109 [D loss: 0.203544, acc.: 71.09%] [G loss: 0.447346]\n",
      "epoch:22 step:21110 [D loss: 0.202275, acc.: 67.97%] [G loss: 0.465496]\n",
      "epoch:22 step:21111 [D loss: 0.214184, acc.: 66.41%] [G loss: 0.439505]\n",
      "epoch:22 step:21112 [D loss: 0.192700, acc.: 70.31%] [G loss: 0.489263]\n",
      "epoch:22 step:21113 [D loss: 0.197992, acc.: 70.31%] [G loss: 0.469804]\n",
      "epoch:22 step:21114 [D loss: 0.250905, acc.: 56.25%] [G loss: 0.469512]\n",
      "epoch:22 step:21115 [D loss: 0.268709, acc.: 51.56%] [G loss: 0.429893]\n",
      "epoch:22 step:21116 [D loss: 0.245046, acc.: 57.03%] [G loss: 0.402374]\n",
      "epoch:22 step:21117 [D loss: 0.233249, acc.: 60.94%] [G loss: 0.419276]\n",
      "epoch:22 step:21118 [D loss: 0.198402, acc.: 66.41%] [G loss: 0.455803]\n",
      "epoch:22 step:21119 [D loss: 0.188715, acc.: 73.44%] [G loss: 0.483303]\n",
      "epoch:22 step:21120 [D loss: 0.232010, acc.: 58.59%] [G loss: 0.471845]\n",
      "epoch:22 step:21121 [D loss: 0.212934, acc.: 66.41%] [G loss: 0.466757]\n",
      "epoch:22 step:21122 [D loss: 0.183737, acc.: 75.78%] [G loss: 0.530647]\n",
      "epoch:22 step:21123 [D loss: 0.268239, acc.: 53.91%] [G loss: 0.430185]\n",
      "epoch:22 step:21124 [D loss: 0.236661, acc.: 61.72%] [G loss: 0.428216]\n",
      "epoch:22 step:21125 [D loss: 0.257535, acc.: 50.00%] [G loss: 0.416260]\n",
      "epoch:22 step:21126 [D loss: 0.238099, acc.: 62.50%] [G loss: 0.417360]\n",
      "epoch:22 step:21127 [D loss: 0.225404, acc.: 63.28%] [G loss: 0.441711]\n",
      "epoch:22 step:21128 [D loss: 0.243677, acc.: 52.34%] [G loss: 0.408013]\n",
      "epoch:22 step:21129 [D loss: 0.203855, acc.: 71.09%] [G loss: 0.428659]\n",
      "epoch:22 step:21130 [D loss: 0.209494, acc.: 69.53%] [G loss: 0.447230]\n",
      "epoch:22 step:21131 [D loss: 0.217341, acc.: 67.19%] [G loss: 0.439701]\n",
      "epoch:22 step:21132 [D loss: 0.246977, acc.: 60.94%] [G loss: 0.421100]\n",
      "epoch:22 step:21133 [D loss: 0.192895, acc.: 74.22%] [G loss: 0.429363]\n",
      "epoch:22 step:21134 [D loss: 0.203333, acc.: 67.97%] [G loss: 0.436951]\n",
      "epoch:22 step:21135 [D loss: 0.211242, acc.: 66.41%] [G loss: 0.422207]\n",
      "epoch:22 step:21136 [D loss: 0.197722, acc.: 70.31%] [G loss: 0.433251]\n",
      "epoch:22 step:21137 [D loss: 0.187881, acc.: 73.44%] [G loss: 0.454962]\n",
      "epoch:22 step:21138 [D loss: 0.232255, acc.: 64.84%] [G loss: 0.427024]\n",
      "epoch:22 step:21139 [D loss: 0.206209, acc.: 67.97%] [G loss: 0.448012]\n",
      "epoch:22 step:21140 [D loss: 0.197332, acc.: 67.97%] [G loss: 0.476467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21141 [D loss: 0.238565, acc.: 59.38%] [G loss: 0.422299]\n",
      "epoch:22 step:21142 [D loss: 0.276029, acc.: 46.88%] [G loss: 0.428054]\n",
      "epoch:22 step:21143 [D loss: 0.258057, acc.: 48.44%] [G loss: 0.398285]\n",
      "epoch:22 step:21144 [D loss: 0.233948, acc.: 63.28%] [G loss: 0.457146]\n",
      "epoch:22 step:21145 [D loss: 0.251198, acc.: 53.91%] [G loss: 0.428724]\n",
      "epoch:22 step:21146 [D loss: 0.210317, acc.: 64.06%] [G loss: 0.424624]\n",
      "epoch:22 step:21147 [D loss: 0.238323, acc.: 57.81%] [G loss: 0.444277]\n",
      "epoch:22 step:21148 [D loss: 0.199535, acc.: 70.31%] [G loss: 0.449869]\n",
      "epoch:22 step:21149 [D loss: 0.225760, acc.: 58.59%] [G loss: 0.412212]\n",
      "epoch:22 step:21150 [D loss: 0.224450, acc.: 62.50%] [G loss: 0.420342]\n",
      "epoch:22 step:21151 [D loss: 0.225737, acc.: 62.50%] [G loss: 0.389589]\n",
      "epoch:22 step:21152 [D loss: 0.225000, acc.: 62.50%] [G loss: 0.394124]\n",
      "epoch:22 step:21153 [D loss: 0.208648, acc.: 63.28%] [G loss: 0.430561]\n",
      "epoch:22 step:21154 [D loss: 0.261921, acc.: 53.91%] [G loss: 0.412945]\n",
      "epoch:22 step:21155 [D loss: 0.246196, acc.: 56.25%] [G loss: 0.390271]\n",
      "epoch:22 step:21156 [D loss: 0.245044, acc.: 55.47%] [G loss: 0.436515]\n",
      "epoch:22 step:21157 [D loss: 0.237710, acc.: 59.38%] [G loss: 0.401256]\n",
      "epoch:22 step:21158 [D loss: 0.229370, acc.: 59.38%] [G loss: 0.387495]\n",
      "epoch:22 step:21159 [D loss: 0.223009, acc.: 64.84%] [G loss: 0.445272]\n",
      "epoch:22 step:21160 [D loss: 0.207753, acc.: 65.62%] [G loss: 0.419462]\n",
      "epoch:22 step:21161 [D loss: 0.227616, acc.: 64.06%] [G loss: 0.424975]\n",
      "epoch:22 step:21162 [D loss: 0.190714, acc.: 73.44%] [G loss: 0.449194]\n",
      "epoch:22 step:21163 [D loss: 0.184397, acc.: 70.31%] [G loss: 0.432902]\n",
      "epoch:22 step:21164 [D loss: 0.224274, acc.: 63.28%] [G loss: 0.416842]\n",
      "epoch:22 step:21165 [D loss: 0.191619, acc.: 72.66%] [G loss: 0.466387]\n",
      "epoch:22 step:21166 [D loss: 0.213193, acc.: 65.62%] [G loss: 0.442426]\n",
      "epoch:22 step:21167 [D loss: 0.233827, acc.: 59.38%] [G loss: 0.450994]\n",
      "epoch:22 step:21168 [D loss: 0.190763, acc.: 71.09%] [G loss: 0.459938]\n",
      "epoch:22 step:21169 [D loss: 0.207367, acc.: 64.84%] [G loss: 0.434985]\n",
      "epoch:22 step:21170 [D loss: 0.227998, acc.: 62.50%] [G loss: 0.440882]\n",
      "epoch:22 step:21171 [D loss: 0.230489, acc.: 58.59%] [G loss: 0.439172]\n",
      "epoch:22 step:21172 [D loss: 0.199836, acc.: 69.53%] [G loss: 0.437750]\n",
      "epoch:22 step:21173 [D loss: 0.248817, acc.: 55.47%] [G loss: 0.416460]\n",
      "epoch:22 step:21174 [D loss: 0.238086, acc.: 55.47%] [G loss: 0.439192]\n",
      "epoch:22 step:21175 [D loss: 0.197510, acc.: 74.22%] [G loss: 0.443041]\n",
      "epoch:22 step:21176 [D loss: 0.224965, acc.: 65.62%] [G loss: 0.442734]\n",
      "epoch:22 step:21177 [D loss: 0.193856, acc.: 71.09%] [G loss: 0.475020]\n",
      "epoch:22 step:21178 [D loss: 0.198483, acc.: 74.22%] [G loss: 0.475623]\n",
      "epoch:22 step:21179 [D loss: 0.237296, acc.: 57.81%] [G loss: 0.445893]\n",
      "epoch:22 step:21180 [D loss: 0.285183, acc.: 50.00%] [G loss: 0.422832]\n",
      "epoch:22 step:21181 [D loss: 0.209136, acc.: 65.62%] [G loss: 0.442338]\n",
      "epoch:22 step:21182 [D loss: 0.224509, acc.: 62.50%] [G loss: 0.401677]\n",
      "epoch:22 step:21183 [D loss: 0.234965, acc.: 56.25%] [G loss: 0.416464]\n",
      "epoch:22 step:21184 [D loss: 0.215151, acc.: 62.50%] [G loss: 0.407761]\n",
      "epoch:22 step:21185 [D loss: 0.200748, acc.: 71.88%] [G loss: 0.439882]\n",
      "epoch:22 step:21186 [D loss: 0.242915, acc.: 57.03%] [G loss: 0.430977]\n",
      "epoch:22 step:21187 [D loss: 0.215799, acc.: 66.41%] [G loss: 0.461554]\n",
      "epoch:22 step:21188 [D loss: 0.178666, acc.: 73.44%] [G loss: 0.513812]\n",
      "epoch:22 step:21189 [D loss: 0.223980, acc.: 65.62%] [G loss: 0.433241]\n",
      "epoch:22 step:21190 [D loss: 0.238454, acc.: 54.69%] [G loss: 0.450926]\n",
      "epoch:22 step:21191 [D loss: 0.217500, acc.: 65.62%] [G loss: 0.421967]\n",
      "epoch:22 step:21192 [D loss: 0.220947, acc.: 64.84%] [G loss: 0.423197]\n",
      "epoch:22 step:21193 [D loss: 0.260109, acc.: 49.22%] [G loss: 0.400278]\n",
      "epoch:22 step:21194 [D loss: 0.221778, acc.: 60.16%] [G loss: 0.436296]\n",
      "epoch:22 step:21195 [D loss: 0.207383, acc.: 71.09%] [G loss: 0.417886]\n",
      "epoch:22 step:21196 [D loss: 0.217231, acc.: 64.06%] [G loss: 0.481690]\n",
      "epoch:22 step:21197 [D loss: 0.197974, acc.: 70.31%] [G loss: 0.500531]\n",
      "epoch:22 step:21198 [D loss: 0.231537, acc.: 60.94%] [G loss: 0.429623]\n",
      "epoch:22 step:21199 [D loss: 0.221064, acc.: 64.06%] [G loss: 0.423079]\n",
      "epoch:22 step:21200 [D loss: 0.245849, acc.: 60.16%] [G loss: 0.443797]\n",
      "epoch:22 step:21201 [D loss: 0.249124, acc.: 59.38%] [G loss: 0.417667]\n",
      "epoch:22 step:21202 [D loss: 0.202352, acc.: 68.75%] [G loss: 0.467393]\n",
      "epoch:22 step:21203 [D loss: 0.205967, acc.: 69.53%] [G loss: 0.461060]\n",
      "epoch:22 step:21204 [D loss: 0.235666, acc.: 62.50%] [G loss: 0.440813]\n",
      "epoch:22 step:21205 [D loss: 0.230322, acc.: 60.16%] [G loss: 0.432699]\n",
      "epoch:22 step:21206 [D loss: 0.205197, acc.: 67.19%] [G loss: 0.416730]\n",
      "epoch:22 step:21207 [D loss: 0.213110, acc.: 64.84%] [G loss: 0.430596]\n",
      "epoch:22 step:21208 [D loss: 0.249048, acc.: 56.25%] [G loss: 0.411560]\n",
      "epoch:22 step:21209 [D loss: 0.219084, acc.: 64.06%] [G loss: 0.418130]\n",
      "epoch:22 step:21210 [D loss: 0.232043, acc.: 58.59%] [G loss: 0.412806]\n",
      "epoch:22 step:21211 [D loss: 0.227759, acc.: 58.59%] [G loss: 0.417618]\n",
      "epoch:22 step:21212 [D loss: 0.201995, acc.: 68.75%] [G loss: 0.445484]\n",
      "epoch:22 step:21213 [D loss: 0.225912, acc.: 59.38%] [G loss: 0.406523]\n",
      "epoch:22 step:21214 [D loss: 0.247377, acc.: 58.59%] [G loss: 0.393618]\n",
      "epoch:22 step:21215 [D loss: 0.231461, acc.: 67.19%] [G loss: 0.445075]\n",
      "epoch:22 step:21216 [D loss: 0.246421, acc.: 55.47%] [G loss: 0.457111]\n",
      "epoch:22 step:21217 [D loss: 0.229181, acc.: 60.16%] [G loss: 0.426311]\n",
      "epoch:22 step:21218 [D loss: 0.204926, acc.: 66.41%] [G loss: 0.426712]\n",
      "epoch:22 step:21219 [D loss: 0.223328, acc.: 65.62%] [G loss: 0.408465]\n",
      "epoch:22 step:21220 [D loss: 0.240348, acc.: 56.25%] [G loss: 0.405061]\n",
      "epoch:22 step:21221 [D loss: 0.231247, acc.: 57.03%] [G loss: 0.425833]\n",
      "epoch:22 step:21222 [D loss: 0.230798, acc.: 63.28%] [G loss: 0.425444]\n",
      "epoch:22 step:21223 [D loss: 0.233526, acc.: 57.81%] [G loss: 0.438527]\n",
      "epoch:22 step:21224 [D loss: 0.226199, acc.: 60.94%] [G loss: 0.400752]\n",
      "epoch:22 step:21225 [D loss: 0.223164, acc.: 65.62%] [G loss: 0.448543]\n",
      "epoch:22 step:21226 [D loss: 0.225999, acc.: 60.94%] [G loss: 0.406356]\n",
      "epoch:22 step:21227 [D loss: 0.239370, acc.: 58.59%] [G loss: 0.421367]\n",
      "epoch:22 step:21228 [D loss: 0.244871, acc.: 57.03%] [G loss: 0.457217]\n",
      "epoch:22 step:21229 [D loss: 0.258537, acc.: 49.22%] [G loss: 0.413672]\n",
      "epoch:22 step:21230 [D loss: 0.238985, acc.: 62.50%] [G loss: 0.424977]\n",
      "epoch:22 step:21231 [D loss: 0.193565, acc.: 72.66%] [G loss: 0.477492]\n",
      "epoch:22 step:21232 [D loss: 0.229164, acc.: 57.81%] [G loss: 0.442891]\n",
      "epoch:22 step:21233 [D loss: 0.263610, acc.: 50.00%] [G loss: 0.410227]\n",
      "epoch:22 step:21234 [D loss: 0.193082, acc.: 70.31%] [G loss: 0.460491]\n",
      "epoch:22 step:21235 [D loss: 0.234163, acc.: 64.06%] [G loss: 0.428851]\n",
      "epoch:22 step:21236 [D loss: 0.244950, acc.: 62.50%] [G loss: 0.422270]\n",
      "epoch:22 step:21237 [D loss: 0.226181, acc.: 57.03%] [G loss: 0.414946]\n",
      "epoch:22 step:21238 [D loss: 0.193627, acc.: 66.41%] [G loss: 0.449403]\n",
      "epoch:22 step:21239 [D loss: 0.226712, acc.: 59.38%] [G loss: 0.404952]\n",
      "epoch:22 step:21240 [D loss: 0.251341, acc.: 57.03%] [G loss: 0.445998]\n",
      "epoch:22 step:21241 [D loss: 0.258626, acc.: 54.69%] [G loss: 0.400801]\n",
      "epoch:22 step:21242 [D loss: 0.231621, acc.: 59.38%] [G loss: 0.418939]\n",
      "epoch:22 step:21243 [D loss: 0.222022, acc.: 61.72%] [G loss: 0.403375]\n",
      "epoch:22 step:21244 [D loss: 0.236882, acc.: 60.94%] [G loss: 0.434329]\n",
      "epoch:22 step:21245 [D loss: 0.200810, acc.: 67.19%] [G loss: 0.427752]\n",
      "epoch:22 step:21246 [D loss: 0.222273, acc.: 63.28%] [G loss: 0.461658]\n",
      "epoch:22 step:21247 [D loss: 0.199800, acc.: 66.41%] [G loss: 0.479283]\n",
      "epoch:22 step:21248 [D loss: 0.209290, acc.: 67.97%] [G loss: 0.473776]\n",
      "epoch:22 step:21249 [D loss: 0.211089, acc.: 64.84%] [G loss: 0.471635]\n",
      "epoch:22 step:21250 [D loss: 0.249040, acc.: 53.12%] [G loss: 0.418196]\n",
      "epoch:22 step:21251 [D loss: 0.210416, acc.: 71.09%] [G loss: 0.448998]\n",
      "epoch:22 step:21252 [D loss: 0.215827, acc.: 63.28%] [G loss: 0.440133]\n",
      "epoch:22 step:21253 [D loss: 0.212269, acc.: 64.06%] [G loss: 0.465081]\n",
      "epoch:22 step:21254 [D loss: 0.239011, acc.: 63.28%] [G loss: 0.455526]\n",
      "epoch:22 step:21255 [D loss: 0.200616, acc.: 68.75%] [G loss: 0.475478]\n",
      "epoch:22 step:21256 [D loss: 0.193473, acc.: 71.88%] [G loss: 0.464064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21257 [D loss: 0.214931, acc.: 67.19%] [G loss: 0.425397]\n",
      "epoch:22 step:21258 [D loss: 0.233803, acc.: 59.38%] [G loss: 0.451695]\n",
      "epoch:22 step:21259 [D loss: 0.231653, acc.: 63.28%] [G loss: 0.430283]\n",
      "epoch:22 step:21260 [D loss: 0.225453, acc.: 62.50%] [G loss: 0.429543]\n",
      "epoch:22 step:21261 [D loss: 0.208849, acc.: 67.19%] [G loss: 0.447687]\n",
      "epoch:22 step:21262 [D loss: 0.175497, acc.: 73.44%] [G loss: 0.484297]\n",
      "epoch:22 step:21263 [D loss: 0.214955, acc.: 67.19%] [G loss: 0.501791]\n",
      "epoch:22 step:21264 [D loss: 0.204716, acc.: 70.31%] [G loss: 0.454325]\n",
      "epoch:22 step:21265 [D loss: 0.210574, acc.: 64.06%] [G loss: 0.463446]\n",
      "epoch:22 step:21266 [D loss: 0.233586, acc.: 65.62%] [G loss: 0.470037]\n",
      "epoch:22 step:21267 [D loss: 0.227130, acc.: 67.97%] [G loss: 0.461826]\n",
      "epoch:22 step:21268 [D loss: 0.207927, acc.: 65.62%] [G loss: 0.461095]\n",
      "epoch:22 step:21269 [D loss: 0.236858, acc.: 57.81%] [G loss: 0.443757]\n",
      "epoch:22 step:21270 [D loss: 0.237181, acc.: 64.06%] [G loss: 0.404214]\n",
      "epoch:22 step:21271 [D loss: 0.216007, acc.: 64.84%] [G loss: 0.420409]\n",
      "epoch:22 step:21272 [D loss: 0.222007, acc.: 60.16%] [G loss: 0.445153]\n",
      "epoch:22 step:21273 [D loss: 0.243459, acc.: 60.94%] [G loss: 0.431028]\n",
      "epoch:22 step:21274 [D loss: 0.192598, acc.: 75.00%] [G loss: 0.481349]\n",
      "epoch:22 step:21275 [D loss: 0.222193, acc.: 65.62%] [G loss: 0.450704]\n",
      "epoch:22 step:21276 [D loss: 0.229391, acc.: 60.94%] [G loss: 0.439988]\n",
      "epoch:22 step:21277 [D loss: 0.209388, acc.: 64.84%] [G loss: 0.439080]\n",
      "epoch:22 step:21278 [D loss: 0.243851, acc.: 57.81%] [G loss: 0.430187]\n",
      "epoch:22 step:21279 [D loss: 0.208204, acc.: 63.28%] [G loss: 0.452126]\n",
      "epoch:22 step:21280 [D loss: 0.248046, acc.: 60.16%] [G loss: 0.417249]\n",
      "epoch:22 step:21281 [D loss: 0.218068, acc.: 65.62%] [G loss: 0.431547]\n",
      "epoch:22 step:21282 [D loss: 0.214421, acc.: 64.84%] [G loss: 0.422023]\n",
      "epoch:22 step:21283 [D loss: 0.200953, acc.: 71.88%] [G loss: 0.410287]\n",
      "epoch:22 step:21284 [D loss: 0.244460, acc.: 58.59%] [G loss: 0.384158]\n",
      "epoch:22 step:21285 [D loss: 0.232300, acc.: 57.03%] [G loss: 0.396167]\n",
      "epoch:22 step:21286 [D loss: 0.249469, acc.: 56.25%] [G loss: 0.382786]\n",
      "epoch:22 step:21287 [D loss: 0.211825, acc.: 63.28%] [G loss: 0.427937]\n",
      "epoch:22 step:21288 [D loss: 0.233119, acc.: 61.72%] [G loss: 0.430852]\n",
      "epoch:22 step:21289 [D loss: 0.250493, acc.: 57.03%] [G loss: 0.424627]\n",
      "epoch:22 step:21290 [D loss: 0.216810, acc.: 64.84%] [G loss: 0.426263]\n",
      "epoch:22 step:21291 [D loss: 0.193009, acc.: 72.66%] [G loss: 0.450038]\n",
      "epoch:22 step:21292 [D loss: 0.211348, acc.: 64.84%] [G loss: 0.422708]\n",
      "epoch:22 step:21293 [D loss: 0.216802, acc.: 60.94%] [G loss: 0.455029]\n",
      "epoch:22 step:21294 [D loss: 0.251625, acc.: 57.81%] [G loss: 0.415575]\n",
      "epoch:22 step:21295 [D loss: 0.201385, acc.: 71.09%] [G loss: 0.438924]\n",
      "epoch:22 step:21296 [D loss: 0.232743, acc.: 60.94%] [G loss: 0.458520]\n",
      "epoch:22 step:21297 [D loss: 0.260650, acc.: 56.25%] [G loss: 0.401483]\n",
      "epoch:22 step:21298 [D loss: 0.229660, acc.: 57.03%] [G loss: 0.401270]\n",
      "epoch:22 step:21299 [D loss: 0.198667, acc.: 68.75%] [G loss: 0.421269]\n",
      "epoch:22 step:21300 [D loss: 0.220505, acc.: 64.84%] [G loss: 0.375307]\n",
      "epoch:22 step:21301 [D loss: 0.213961, acc.: 65.62%] [G loss: 0.399181]\n",
      "epoch:22 step:21302 [D loss: 0.211496, acc.: 65.62%] [G loss: 0.396660]\n",
      "epoch:22 step:21303 [D loss: 0.230882, acc.: 60.94%] [G loss: 0.400612]\n",
      "epoch:22 step:21304 [D loss: 0.207314, acc.: 64.84%] [G loss: 0.459926]\n",
      "epoch:22 step:21305 [D loss: 0.202369, acc.: 69.53%] [G loss: 0.493426]\n",
      "epoch:22 step:21306 [D loss: 0.212107, acc.: 64.06%] [G loss: 0.473725]\n",
      "epoch:22 step:21307 [D loss: 0.196152, acc.: 71.09%] [G loss: 0.512591]\n",
      "epoch:22 step:21308 [D loss: 0.197863, acc.: 68.75%] [G loss: 0.499352]\n",
      "epoch:22 step:21309 [D loss: 0.230964, acc.: 62.50%] [G loss: 0.475923]\n",
      "epoch:22 step:21310 [D loss: 0.244514, acc.: 60.16%] [G loss: 0.468999]\n",
      "epoch:22 step:21311 [D loss: 0.246644, acc.: 57.81%] [G loss: 0.372996]\n",
      "epoch:22 step:21312 [D loss: 0.237876, acc.: 59.38%] [G loss: 0.447593]\n",
      "epoch:22 step:21313 [D loss: 0.227898, acc.: 65.62%] [G loss: 0.449060]\n",
      "epoch:22 step:21314 [D loss: 0.237221, acc.: 57.03%] [G loss: 0.443261]\n",
      "epoch:22 step:21315 [D loss: 0.199432, acc.: 71.88%] [G loss: 0.456284]\n",
      "epoch:22 step:21316 [D loss: 0.231413, acc.: 60.16%] [G loss: 0.457739]\n",
      "epoch:22 step:21317 [D loss: 0.238106, acc.: 63.28%] [G loss: 0.414715]\n",
      "epoch:22 step:21318 [D loss: 0.221465, acc.: 62.50%] [G loss: 0.403588]\n",
      "epoch:22 step:21319 [D loss: 0.233738, acc.: 60.94%] [G loss: 0.410152]\n",
      "epoch:22 step:21320 [D loss: 0.245043, acc.: 64.06%] [G loss: 0.443588]\n",
      "epoch:22 step:21321 [D loss: 0.232531, acc.: 64.84%] [G loss: 0.449437]\n",
      "epoch:22 step:21322 [D loss: 0.200730, acc.: 71.09%] [G loss: 0.481233]\n",
      "epoch:22 step:21323 [D loss: 0.198945, acc.: 72.66%] [G loss: 0.495369]\n",
      "epoch:22 step:21324 [D loss: 0.246848, acc.: 62.50%] [G loss: 0.410918]\n",
      "epoch:22 step:21325 [D loss: 0.242780, acc.: 58.59%] [G loss: 0.412606]\n",
      "epoch:22 step:21326 [D loss: 0.213335, acc.: 65.62%] [G loss: 0.449652]\n",
      "epoch:22 step:21327 [D loss: 0.214592, acc.: 63.28%] [G loss: 0.477425]\n",
      "epoch:22 step:21328 [D loss: 0.209959, acc.: 65.62%] [G loss: 0.448712]\n",
      "epoch:22 step:21329 [D loss: 0.221890, acc.: 59.38%] [G loss: 0.473270]\n",
      "epoch:22 step:21330 [D loss: 0.247320, acc.: 62.50%] [G loss: 0.429362]\n",
      "epoch:22 step:21331 [D loss: 0.239006, acc.: 61.72%] [G loss: 0.408480]\n",
      "epoch:22 step:21332 [D loss: 0.230779, acc.: 60.16%] [G loss: 0.475285]\n",
      "epoch:22 step:21333 [D loss: 0.210304, acc.: 62.50%] [G loss: 0.491575]\n",
      "epoch:22 step:21334 [D loss: 0.229727, acc.: 60.94%] [G loss: 0.503986]\n",
      "epoch:22 step:21335 [D loss: 0.211389, acc.: 64.06%] [G loss: 0.416984]\n",
      "epoch:22 step:21336 [D loss: 0.237960, acc.: 55.47%] [G loss: 0.408388]\n",
      "epoch:22 step:21337 [D loss: 0.215215, acc.: 68.75%] [G loss: 0.425097]\n",
      "epoch:22 step:21338 [D loss: 0.190052, acc.: 71.88%] [G loss: 0.500572]\n",
      "epoch:22 step:21339 [D loss: 0.214827, acc.: 65.62%] [G loss: 0.441069]\n",
      "epoch:22 step:21340 [D loss: 0.221166, acc.: 64.06%] [G loss: 0.462274]\n",
      "epoch:22 step:21341 [D loss: 0.235149, acc.: 62.50%] [G loss: 0.412556]\n",
      "epoch:22 step:21342 [D loss: 0.229499, acc.: 65.62%] [G loss: 0.424599]\n",
      "epoch:22 step:21343 [D loss: 0.228146, acc.: 62.50%] [G loss: 0.403704]\n",
      "epoch:22 step:21344 [D loss: 0.215869, acc.: 64.06%] [G loss: 0.407781]\n",
      "epoch:22 step:21345 [D loss: 0.226571, acc.: 61.72%] [G loss: 0.412630]\n",
      "epoch:22 step:21346 [D loss: 0.196326, acc.: 69.53%] [G loss: 0.457132]\n",
      "epoch:22 step:21347 [D loss: 0.232086, acc.: 63.28%] [G loss: 0.408499]\n",
      "epoch:22 step:21348 [D loss: 0.252364, acc.: 53.91%] [G loss: 0.400348]\n",
      "epoch:22 step:21349 [D loss: 0.230948, acc.: 62.50%] [G loss: 0.411836]\n",
      "epoch:22 step:21350 [D loss: 0.203035, acc.: 66.41%] [G loss: 0.440362]\n",
      "epoch:22 step:21351 [D loss: 0.225237, acc.: 63.28%] [G loss: 0.431995]\n",
      "epoch:22 step:21352 [D loss: 0.256443, acc.: 50.78%] [G loss: 0.418801]\n",
      "epoch:22 step:21353 [D loss: 0.245289, acc.: 55.47%] [G loss: 0.396183]\n",
      "epoch:22 step:21354 [D loss: 0.252072, acc.: 54.69%] [G loss: 0.422421]\n",
      "epoch:22 step:21355 [D loss: 0.240673, acc.: 57.81%] [G loss: 0.434682]\n",
      "epoch:22 step:21356 [D loss: 0.218408, acc.: 71.88%] [G loss: 0.441176]\n",
      "epoch:22 step:21357 [D loss: 0.223178, acc.: 62.50%] [G loss: 0.439184]\n",
      "epoch:22 step:21358 [D loss: 0.238725, acc.: 58.59%] [G loss: 0.456095]\n",
      "epoch:22 step:21359 [D loss: 0.239439, acc.: 60.94%] [G loss: 0.419499]\n",
      "epoch:22 step:21360 [D loss: 0.219133, acc.: 67.19%] [G loss: 0.431614]\n",
      "epoch:22 step:21361 [D loss: 0.210589, acc.: 64.84%] [G loss: 0.457606]\n",
      "epoch:22 step:21362 [D loss: 0.249141, acc.: 60.94%] [G loss: 0.429622]\n",
      "epoch:22 step:21363 [D loss: 0.228377, acc.: 62.50%] [G loss: 0.422311]\n",
      "epoch:22 step:21364 [D loss: 0.212258, acc.: 66.41%] [G loss: 0.453931]\n",
      "epoch:22 step:21365 [D loss: 0.204223, acc.: 69.53%] [G loss: 0.483258]\n",
      "epoch:22 step:21366 [D loss: 0.227557, acc.: 64.06%] [G loss: 0.450570]\n",
      "epoch:22 step:21367 [D loss: 0.218261, acc.: 69.53%] [G loss: 0.440161]\n",
      "epoch:22 step:21368 [D loss: 0.196322, acc.: 69.53%] [G loss: 0.426353]\n",
      "epoch:22 step:21369 [D loss: 0.215501, acc.: 66.41%] [G loss: 0.440763]\n",
      "epoch:22 step:21370 [D loss: 0.218434, acc.: 67.97%] [G loss: 0.436600]\n",
      "epoch:22 step:21371 [D loss: 0.228150, acc.: 57.81%] [G loss: 0.396409]\n",
      "epoch:22 step:21372 [D loss: 0.234521, acc.: 67.19%] [G loss: 0.426506]\n",
      "epoch:22 step:21373 [D loss: 0.251153, acc.: 59.38%] [G loss: 0.395085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21374 [D loss: 0.243244, acc.: 61.72%] [G loss: 0.417905]\n",
      "epoch:22 step:21375 [D loss: 0.224204, acc.: 58.59%] [G loss: 0.426274]\n",
      "epoch:22 step:21376 [D loss: 0.239839, acc.: 59.38%] [G loss: 0.413390]\n",
      "epoch:22 step:21377 [D loss: 0.227553, acc.: 59.38%] [G loss: 0.425750]\n",
      "epoch:22 step:21378 [D loss: 0.223742, acc.: 61.72%] [G loss: 0.444609]\n",
      "epoch:22 step:21379 [D loss: 0.276223, acc.: 46.88%] [G loss: 0.395354]\n",
      "epoch:22 step:21380 [D loss: 0.236122, acc.: 59.38%] [G loss: 0.427206]\n",
      "epoch:22 step:21381 [D loss: 0.218807, acc.: 62.50%] [G loss: 0.457487]\n",
      "epoch:22 step:21382 [D loss: 0.250407, acc.: 60.94%] [G loss: 0.412988]\n",
      "epoch:22 step:21383 [D loss: 0.200150, acc.: 76.56%] [G loss: 0.457734]\n",
      "epoch:22 step:21384 [D loss: 0.239606, acc.: 58.59%] [G loss: 0.455904]\n",
      "epoch:22 step:21385 [D loss: 0.221237, acc.: 64.84%] [G loss: 0.455788]\n",
      "epoch:22 step:21386 [D loss: 0.233345, acc.: 62.50%] [G loss: 0.417250]\n",
      "epoch:22 step:21387 [D loss: 0.213383, acc.: 64.84%] [G loss: 0.441780]\n",
      "epoch:22 step:21388 [D loss: 0.233547, acc.: 59.38%] [G loss: 0.413620]\n",
      "epoch:22 step:21389 [D loss: 0.213070, acc.: 65.62%] [G loss: 0.463873]\n",
      "epoch:22 step:21390 [D loss: 0.221818, acc.: 59.38%] [G loss: 0.435640]\n",
      "epoch:22 step:21391 [D loss: 0.220821, acc.: 64.06%] [G loss: 0.405909]\n",
      "epoch:22 step:21392 [D loss: 0.231928, acc.: 62.50%] [G loss: 0.433652]\n",
      "epoch:22 step:21393 [D loss: 0.221032, acc.: 68.75%] [G loss: 0.425547]\n",
      "epoch:22 step:21394 [D loss: 0.199318, acc.: 72.66%] [G loss: 0.418701]\n",
      "epoch:22 step:21395 [D loss: 0.207804, acc.: 69.53%] [G loss: 0.458014]\n",
      "epoch:22 step:21396 [D loss: 0.181765, acc.: 74.22%] [G loss: 0.493327]\n",
      "epoch:22 step:21397 [D loss: 0.245013, acc.: 57.81%] [G loss: 0.419983]\n",
      "epoch:22 step:21398 [D loss: 0.251449, acc.: 57.03%] [G loss: 0.421883]\n",
      "epoch:22 step:21399 [D loss: 0.212513, acc.: 67.19%] [G loss: 0.448962]\n",
      "epoch:22 step:21400 [D loss: 0.202179, acc.: 71.88%] [G loss: 0.464554]\n",
      "epoch:22 step:21401 [D loss: 0.253472, acc.: 62.50%] [G loss: 0.401343]\n",
      "epoch:22 step:21402 [D loss: 0.248258, acc.: 56.25%] [G loss: 0.389819]\n",
      "epoch:22 step:21403 [D loss: 0.244964, acc.: 59.38%] [G loss: 0.406527]\n",
      "epoch:22 step:21404 [D loss: 0.212186, acc.: 66.41%] [G loss: 0.447447]\n",
      "epoch:22 step:21405 [D loss: 0.248269, acc.: 60.16%] [G loss: 0.460885]\n",
      "epoch:22 step:21406 [D loss: 0.184198, acc.: 74.22%] [G loss: 0.457031]\n",
      "epoch:22 step:21407 [D loss: 0.229306, acc.: 66.41%] [G loss: 0.437731]\n",
      "epoch:22 step:21408 [D loss: 0.243764, acc.: 54.69%] [G loss: 0.448521]\n",
      "epoch:22 step:21409 [D loss: 0.227556, acc.: 66.41%] [G loss: 0.440459]\n",
      "epoch:22 step:21410 [D loss: 0.223172, acc.: 65.62%] [G loss: 0.404459]\n",
      "epoch:22 step:21411 [D loss: 0.231166, acc.: 62.50%] [G loss: 0.420453]\n",
      "epoch:22 step:21412 [D loss: 0.219280, acc.: 59.38%] [G loss: 0.402879]\n",
      "epoch:22 step:21413 [D loss: 0.208747, acc.: 68.75%] [G loss: 0.465106]\n",
      "epoch:22 step:21414 [D loss: 0.257021, acc.: 52.34%] [G loss: 0.442706]\n",
      "epoch:22 step:21415 [D loss: 0.233873, acc.: 61.72%] [G loss: 0.499383]\n",
      "epoch:22 step:21416 [D loss: 0.190293, acc.: 70.31%] [G loss: 0.523017]\n",
      "epoch:22 step:21417 [D loss: 0.208063, acc.: 69.53%] [G loss: 0.438023]\n",
      "epoch:22 step:21418 [D loss: 0.245583, acc.: 57.81%] [G loss: 0.394322]\n",
      "epoch:22 step:21419 [D loss: 0.204629, acc.: 63.28%] [G loss: 0.402951]\n",
      "epoch:22 step:21420 [D loss: 0.231763, acc.: 61.72%] [G loss: 0.428064]\n",
      "epoch:22 step:21421 [D loss: 0.207163, acc.: 64.84%] [G loss: 0.452394]\n",
      "epoch:22 step:21422 [D loss: 0.251806, acc.: 59.38%] [G loss: 0.464829]\n",
      "epoch:22 step:21423 [D loss: 0.222589, acc.: 64.06%] [G loss: 0.443356]\n",
      "epoch:22 step:21424 [D loss: 0.230731, acc.: 62.50%] [G loss: 0.394763]\n",
      "epoch:22 step:21425 [D loss: 0.247641, acc.: 54.69%] [G loss: 0.444792]\n",
      "epoch:22 step:21426 [D loss: 0.226687, acc.: 62.50%] [G loss: 0.512903]\n",
      "epoch:22 step:21427 [D loss: 0.222688, acc.: 67.19%] [G loss: 0.455185]\n",
      "epoch:22 step:21428 [D loss: 0.229533, acc.: 63.28%] [G loss: 0.423816]\n",
      "epoch:22 step:21429 [D loss: 0.221424, acc.: 62.50%] [G loss: 0.488151]\n",
      "epoch:22 step:21430 [D loss: 0.205926, acc.: 64.84%] [G loss: 0.477479]\n",
      "epoch:22 step:21431 [D loss: 0.260898, acc.: 52.34%] [G loss: 0.438983]\n",
      "epoch:22 step:21432 [D loss: 0.262492, acc.: 58.59%] [G loss: 0.403132]\n",
      "epoch:22 step:21433 [D loss: 0.201713, acc.: 70.31%] [G loss: 0.460493]\n",
      "epoch:22 step:21434 [D loss: 0.262573, acc.: 55.47%] [G loss: 0.406296]\n",
      "epoch:22 step:21435 [D loss: 0.222371, acc.: 59.38%] [G loss: 0.400005]\n",
      "epoch:22 step:21436 [D loss: 0.205853, acc.: 69.53%] [G loss: 0.427794]\n",
      "epoch:22 step:21437 [D loss: 0.203910, acc.: 67.97%] [G loss: 0.437323]\n",
      "epoch:22 step:21438 [D loss: 0.222084, acc.: 65.62%] [G loss: 0.427497]\n",
      "epoch:22 step:21439 [D loss: 0.226250, acc.: 60.94%] [G loss: 0.398513]\n",
      "epoch:22 step:21440 [D loss: 0.209550, acc.: 65.62%] [G loss: 0.463692]\n",
      "epoch:22 step:21441 [D loss: 0.250522, acc.: 53.91%] [G loss: 0.420019]\n",
      "epoch:22 step:21442 [D loss: 0.244983, acc.: 55.47%] [G loss: 0.417473]\n",
      "epoch:22 step:21443 [D loss: 0.233554, acc.: 57.81%] [G loss: 0.406654]\n",
      "epoch:22 step:21444 [D loss: 0.256392, acc.: 50.78%] [G loss: 0.391140]\n",
      "epoch:22 step:21445 [D loss: 0.198827, acc.: 69.53%] [G loss: 0.427050]\n",
      "epoch:22 step:21446 [D loss: 0.207453, acc.: 75.00%] [G loss: 0.415288]\n",
      "epoch:22 step:21447 [D loss: 0.201899, acc.: 67.97%] [G loss: 0.445232]\n",
      "epoch:22 step:21448 [D loss: 0.236227, acc.: 60.16%] [G loss: 0.424678]\n",
      "epoch:22 step:21449 [D loss: 0.234193, acc.: 60.16%] [G loss: 0.415276]\n",
      "epoch:22 step:21450 [D loss: 0.222889, acc.: 60.94%] [G loss: 0.407534]\n",
      "epoch:22 step:21451 [D loss: 0.220727, acc.: 67.19%] [G loss: 0.466408]\n",
      "epoch:22 step:21452 [D loss: 0.213436, acc.: 64.84%] [G loss: 0.475176]\n",
      "epoch:22 step:21453 [D loss: 0.199966, acc.: 71.09%] [G loss: 0.429096]\n",
      "epoch:22 step:21454 [D loss: 0.228263, acc.: 64.84%] [G loss: 0.415574]\n",
      "epoch:22 step:21455 [D loss: 0.210142, acc.: 64.84%] [G loss: 0.413626]\n",
      "epoch:22 step:21456 [D loss: 0.192006, acc.: 71.88%] [G loss: 0.408924]\n",
      "epoch:22 step:21457 [D loss: 0.236818, acc.: 57.81%] [G loss: 0.449505]\n",
      "epoch:22 step:21458 [D loss: 0.240947, acc.: 60.16%] [G loss: 0.412737]\n",
      "epoch:22 step:21459 [D loss: 0.218760, acc.: 64.06%] [G loss: 0.434067]\n",
      "epoch:22 step:21460 [D loss: 0.233940, acc.: 57.03%] [G loss: 0.426743]\n",
      "epoch:22 step:21461 [D loss: 0.236744, acc.: 59.38%] [G loss: 0.412116]\n",
      "epoch:22 step:21462 [D loss: 0.217633, acc.: 65.62%] [G loss: 0.395830]\n",
      "epoch:22 step:21463 [D loss: 0.193869, acc.: 66.41%] [G loss: 0.448754]\n",
      "epoch:22 step:21464 [D loss: 0.235807, acc.: 58.59%] [G loss: 0.387728]\n",
      "epoch:22 step:21465 [D loss: 0.232633, acc.: 59.38%] [G loss: 0.431059]\n",
      "epoch:22 step:21466 [D loss: 0.208938, acc.: 64.06%] [G loss: 0.444443]\n",
      "epoch:22 step:21467 [D loss: 0.228235, acc.: 63.28%] [G loss: 0.461756]\n",
      "epoch:22 step:21468 [D loss: 0.219274, acc.: 64.84%] [G loss: 0.465823]\n",
      "epoch:22 step:21469 [D loss: 0.244627, acc.: 61.72%] [G loss: 0.439606]\n",
      "epoch:22 step:21470 [D loss: 0.234392, acc.: 59.38%] [G loss: 0.388718]\n",
      "epoch:22 step:21471 [D loss: 0.239096, acc.: 59.38%] [G loss: 0.436106]\n",
      "epoch:22 step:21472 [D loss: 0.254363, acc.: 55.47%] [G loss: 0.421444]\n",
      "epoch:22 step:21473 [D loss: 0.255302, acc.: 58.59%] [G loss: 0.442144]\n",
      "epoch:22 step:21474 [D loss: 0.217415, acc.: 66.41%] [G loss: 0.421067]\n",
      "epoch:22 step:21475 [D loss: 0.225245, acc.: 64.06%] [G loss: 0.433755]\n",
      "epoch:22 step:21476 [D loss: 0.223743, acc.: 57.81%] [G loss: 0.419494]\n",
      "epoch:22 step:21477 [D loss: 0.229740, acc.: 54.69%] [G loss: 0.396838]\n",
      "epoch:22 step:21478 [D loss: 0.236329, acc.: 53.91%] [G loss: 0.392104]\n",
      "epoch:22 step:21479 [D loss: 0.248111, acc.: 56.25%] [G loss: 0.385721]\n",
      "epoch:22 step:21480 [D loss: 0.230561, acc.: 59.38%] [G loss: 0.401370]\n",
      "epoch:22 step:21481 [D loss: 0.236189, acc.: 63.28%] [G loss: 0.406398]\n",
      "epoch:22 step:21482 [D loss: 0.235674, acc.: 57.03%] [G loss: 0.412119]\n",
      "epoch:22 step:21483 [D loss: 0.247596, acc.: 52.34%] [G loss: 0.409799]\n",
      "epoch:22 step:21484 [D loss: 0.206477, acc.: 64.84%] [G loss: 0.386105]\n",
      "epoch:22 step:21485 [D loss: 0.234710, acc.: 59.38%] [G loss: 0.386441]\n",
      "epoch:22 step:21486 [D loss: 0.234393, acc.: 63.28%] [G loss: 0.412242]\n",
      "epoch:22 step:21487 [D loss: 0.217221, acc.: 65.62%] [G loss: 0.416186]\n",
      "epoch:22 step:21488 [D loss: 0.206037, acc.: 69.53%] [G loss: 0.450781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21489 [D loss: 0.179551, acc.: 72.66%] [G loss: 0.423130]\n",
      "epoch:22 step:21490 [D loss: 0.206534, acc.: 66.41%] [G loss: 0.445452]\n",
      "epoch:22 step:21491 [D loss: 0.262629, acc.: 56.25%] [G loss: 0.399784]\n",
      "epoch:22 step:21492 [D loss: 0.235431, acc.: 59.38%] [G loss: 0.382823]\n",
      "epoch:22 step:21493 [D loss: 0.240752, acc.: 53.91%] [G loss: 0.406294]\n",
      "epoch:22 step:21494 [D loss: 0.256578, acc.: 52.34%] [G loss: 0.412781]\n",
      "epoch:22 step:21495 [D loss: 0.212956, acc.: 65.62%] [G loss: 0.437170]\n",
      "epoch:22 step:21496 [D loss: 0.235736, acc.: 60.94%] [G loss: 0.410618]\n",
      "epoch:22 step:21497 [D loss: 0.241542, acc.: 56.25%] [G loss: 0.430068]\n",
      "epoch:22 step:21498 [D loss: 0.203447, acc.: 65.62%] [G loss: 0.435095]\n",
      "epoch:22 step:21499 [D loss: 0.232456, acc.: 56.25%] [G loss: 0.439802]\n",
      "epoch:22 step:21500 [D loss: 0.177304, acc.: 74.22%] [G loss: 0.466179]\n",
      "epoch:22 step:21501 [D loss: 0.242089, acc.: 60.16%] [G loss: 0.444642]\n",
      "epoch:22 step:21502 [D loss: 0.211907, acc.: 67.19%] [G loss: 0.478697]\n",
      "epoch:22 step:21503 [D loss: 0.218268, acc.: 67.19%] [G loss: 0.451609]\n",
      "epoch:22 step:21504 [D loss: 0.213001, acc.: 66.41%] [G loss: 0.430017]\n",
      "epoch:22 step:21505 [D loss: 0.264145, acc.: 52.34%] [G loss: 0.413586]\n",
      "epoch:22 step:21506 [D loss: 0.245395, acc.: 57.03%] [G loss: 0.425526]\n",
      "epoch:22 step:21507 [D loss: 0.202989, acc.: 64.06%] [G loss: 0.412722]\n",
      "epoch:22 step:21508 [D loss: 0.200615, acc.: 69.53%] [G loss: 0.466105]\n",
      "epoch:22 step:21509 [D loss: 0.217750, acc.: 67.97%] [G loss: 0.402781]\n",
      "epoch:22 step:21510 [D loss: 0.237617, acc.: 61.72%] [G loss: 0.409745]\n",
      "epoch:22 step:21511 [D loss: 0.203103, acc.: 61.72%] [G loss: 0.465794]\n",
      "epoch:22 step:21512 [D loss: 0.204814, acc.: 68.75%] [G loss: 0.422977]\n",
      "epoch:22 step:21513 [D loss: 0.193791, acc.: 69.53%] [G loss: 0.444749]\n",
      "epoch:22 step:21514 [D loss: 0.237032, acc.: 61.72%] [G loss: 0.466522]\n",
      "epoch:22 step:21515 [D loss: 0.231625, acc.: 62.50%] [G loss: 0.405948]\n",
      "epoch:22 step:21516 [D loss: 0.233849, acc.: 64.84%] [G loss: 0.414282]\n",
      "epoch:22 step:21517 [D loss: 0.244497, acc.: 59.38%] [G loss: 0.408968]\n",
      "epoch:22 step:21518 [D loss: 0.227717, acc.: 61.72%] [G loss: 0.429081]\n",
      "epoch:22 step:21519 [D loss: 0.222550, acc.: 63.28%] [G loss: 0.427187]\n",
      "epoch:22 step:21520 [D loss: 0.215182, acc.: 66.41%] [G loss: 0.480179]\n",
      "epoch:22 step:21521 [D loss: 0.219400, acc.: 66.41%] [G loss: 0.453233]\n",
      "epoch:22 step:21522 [D loss: 0.218099, acc.: 64.06%] [G loss: 0.431598]\n",
      "epoch:22 step:21523 [D loss: 0.185436, acc.: 69.53%] [G loss: 0.465346]\n",
      "epoch:22 step:21524 [D loss: 0.242326, acc.: 57.81%] [G loss: 0.459340]\n",
      "epoch:22 step:21525 [D loss: 0.179322, acc.: 77.34%] [G loss: 0.452077]\n",
      "epoch:22 step:21526 [D loss: 0.229711, acc.: 60.94%] [G loss: 0.450789]\n",
      "epoch:22 step:21527 [D loss: 0.232673, acc.: 65.62%] [G loss: 0.451240]\n",
      "epoch:22 step:21528 [D loss: 0.218512, acc.: 66.41%] [G loss: 0.474943]\n",
      "epoch:22 step:21529 [D loss: 0.293849, acc.: 43.75%] [G loss: 0.438276]\n",
      "epoch:22 step:21530 [D loss: 0.222347, acc.: 60.94%] [G loss: 0.434840]\n",
      "epoch:22 step:21531 [D loss: 0.213078, acc.: 63.28%] [G loss: 0.431871]\n",
      "epoch:22 step:21532 [D loss: 0.218563, acc.: 65.62%] [G loss: 0.412447]\n",
      "epoch:22 step:21533 [D loss: 0.214811, acc.: 63.28%] [G loss: 0.464521]\n",
      "epoch:22 step:21534 [D loss: 0.314517, acc.: 46.88%] [G loss: 0.391076]\n",
      "epoch:22 step:21535 [D loss: 0.227599, acc.: 59.38%] [G loss: 0.431616]\n",
      "epoch:22 step:21536 [D loss: 0.219957, acc.: 61.72%] [G loss: 0.448929]\n",
      "epoch:22 step:21537 [D loss: 0.181634, acc.: 72.66%] [G loss: 0.477208]\n",
      "epoch:22 step:21538 [D loss: 0.196310, acc.: 65.62%] [G loss: 0.437734]\n",
      "epoch:22 step:21539 [D loss: 0.185103, acc.: 74.22%] [G loss: 0.484909]\n",
      "epoch:22 step:21540 [D loss: 0.192551, acc.: 77.34%] [G loss: 0.488829]\n",
      "epoch:22 step:21541 [D loss: 0.182432, acc.: 71.88%] [G loss: 0.493589]\n",
      "epoch:22 step:21542 [D loss: 0.279411, acc.: 59.38%] [G loss: 0.460027]\n",
      "epoch:22 step:21543 [D loss: 0.281341, acc.: 50.78%] [G loss: 0.494534]\n",
      "epoch:22 step:21544 [D loss: 0.210043, acc.: 64.84%] [G loss: 0.488450]\n",
      "epoch:22 step:21545 [D loss: 0.266616, acc.: 57.81%] [G loss: 0.487227]\n",
      "epoch:22 step:21546 [D loss: 0.252645, acc.: 60.16%] [G loss: 0.427691]\n",
      "epoch:22 step:21547 [D loss: 0.210220, acc.: 67.97%] [G loss: 0.434082]\n",
      "epoch:22 step:21548 [D loss: 0.223531, acc.: 62.50%] [G loss: 0.453471]\n",
      "epoch:22 step:21549 [D loss: 0.196698, acc.: 71.88%] [G loss: 0.410140]\n",
      "epoch:22 step:21550 [D loss: 0.202902, acc.: 68.75%] [G loss: 0.490874]\n",
      "epoch:22 step:21551 [D loss: 0.187216, acc.: 72.66%] [G loss: 0.541129]\n",
      "epoch:23 step:21552 [D loss: 0.257388, acc.: 60.16%] [G loss: 0.508887]\n",
      "epoch:23 step:21553 [D loss: 0.254986, acc.: 63.28%] [G loss: 0.466189]\n",
      "epoch:23 step:21554 [D loss: 0.234276, acc.: 59.38%] [G loss: 0.432215]\n",
      "epoch:23 step:21555 [D loss: 0.240053, acc.: 59.38%] [G loss: 0.482976]\n",
      "epoch:23 step:21556 [D loss: 0.228998, acc.: 60.94%] [G loss: 0.441272]\n",
      "epoch:23 step:21557 [D loss: 0.242168, acc.: 60.16%] [G loss: 0.436641]\n",
      "epoch:23 step:21558 [D loss: 0.221066, acc.: 64.84%] [G loss: 0.449555]\n",
      "epoch:23 step:21559 [D loss: 0.205984, acc.: 71.88%] [G loss: 0.471468]\n",
      "epoch:23 step:21560 [D loss: 0.194114, acc.: 75.00%] [G loss: 0.460226]\n",
      "epoch:23 step:21561 [D loss: 0.201127, acc.: 66.41%] [G loss: 0.494344]\n",
      "epoch:23 step:21562 [D loss: 0.207871, acc.: 69.53%] [G loss: 0.421509]\n",
      "epoch:23 step:21563 [D loss: 0.230634, acc.: 62.50%] [G loss: 0.442230]\n",
      "epoch:23 step:21564 [D loss: 0.216645, acc.: 67.97%] [G loss: 0.452856]\n",
      "epoch:23 step:21565 [D loss: 0.205766, acc.: 63.28%] [G loss: 0.439368]\n",
      "epoch:23 step:21566 [D loss: 0.212445, acc.: 68.75%] [G loss: 0.470105]\n",
      "epoch:23 step:21567 [D loss: 0.190511, acc.: 72.66%] [G loss: 0.499209]\n",
      "epoch:23 step:21568 [D loss: 0.221333, acc.: 62.50%] [G loss: 0.487906]\n",
      "epoch:23 step:21569 [D loss: 0.220227, acc.: 64.06%] [G loss: 0.409312]\n",
      "epoch:23 step:21570 [D loss: 0.237382, acc.: 60.94%] [G loss: 0.434364]\n",
      "epoch:23 step:21571 [D loss: 0.249819, acc.: 57.03%] [G loss: 0.494895]\n",
      "epoch:23 step:21572 [D loss: 0.226038, acc.: 67.97%] [G loss: 0.515685]\n",
      "epoch:23 step:21573 [D loss: 0.189673, acc.: 71.88%] [G loss: 0.579761]\n",
      "epoch:23 step:21574 [D loss: 0.296161, acc.: 48.44%] [G loss: 0.372517]\n",
      "epoch:23 step:21575 [D loss: 0.206318, acc.: 67.97%] [G loss: 0.401903]\n",
      "epoch:23 step:21576 [D loss: 0.193788, acc.: 71.88%] [G loss: 0.434721]\n",
      "epoch:23 step:21577 [D loss: 0.240383, acc.: 60.16%] [G loss: 0.408846]\n",
      "epoch:23 step:21578 [D loss: 0.206532, acc.: 66.41%] [G loss: 0.429800]\n",
      "epoch:23 step:21579 [D loss: 0.218251, acc.: 63.28%] [G loss: 0.434651]\n",
      "epoch:23 step:21580 [D loss: 0.218237, acc.: 64.84%] [G loss: 0.428190]\n",
      "epoch:23 step:21581 [D loss: 0.228847, acc.: 56.25%] [G loss: 0.441309]\n",
      "epoch:23 step:21582 [D loss: 0.253222, acc.: 58.59%] [G loss: 0.437217]\n",
      "epoch:23 step:21583 [D loss: 0.219600, acc.: 63.28%] [G loss: 0.440733]\n",
      "epoch:23 step:21584 [D loss: 0.242217, acc.: 60.16%] [G loss: 0.399723]\n",
      "epoch:23 step:21585 [D loss: 0.259386, acc.: 52.34%] [G loss: 0.410692]\n",
      "epoch:23 step:21586 [D loss: 0.233379, acc.: 63.28%] [G loss: 0.424533]\n",
      "epoch:23 step:21587 [D loss: 0.221500, acc.: 64.84%] [G loss: 0.449600]\n",
      "epoch:23 step:21588 [D loss: 0.225495, acc.: 64.06%] [G loss: 0.417068]\n",
      "epoch:23 step:21589 [D loss: 0.273555, acc.: 48.44%] [G loss: 0.420437]\n",
      "epoch:23 step:21590 [D loss: 0.228338, acc.: 57.03%] [G loss: 0.421122]\n",
      "epoch:23 step:21591 [D loss: 0.180723, acc.: 75.78%] [G loss: 0.475776]\n",
      "epoch:23 step:21592 [D loss: 0.246174, acc.: 60.16%] [G loss: 0.415967]\n",
      "epoch:23 step:21593 [D loss: 0.226757, acc.: 64.84%] [G loss: 0.451764]\n",
      "epoch:23 step:21594 [D loss: 0.234761, acc.: 63.28%] [G loss: 0.435532]\n",
      "epoch:23 step:21595 [D loss: 0.224562, acc.: 64.06%] [G loss: 0.419111]\n",
      "epoch:23 step:21596 [D loss: 0.231472, acc.: 63.28%] [G loss: 0.403872]\n",
      "epoch:23 step:21597 [D loss: 0.234061, acc.: 57.81%] [G loss: 0.411688]\n",
      "epoch:23 step:21598 [D loss: 0.223476, acc.: 62.50%] [G loss: 0.428972]\n",
      "epoch:23 step:21599 [D loss: 0.220006, acc.: 67.19%] [G loss: 0.425884]\n",
      "epoch:23 step:21600 [D loss: 0.207981, acc.: 66.41%] [G loss: 0.444159]\n",
      "epoch:23 step:21601 [D loss: 0.205630, acc.: 62.50%] [G loss: 0.438705]\n",
      "epoch:23 step:21602 [D loss: 0.237444, acc.: 60.16%] [G loss: 0.424893]\n",
      "epoch:23 step:21603 [D loss: 0.230131, acc.: 63.28%] [G loss: 0.448363]\n",
      "epoch:23 step:21604 [D loss: 0.204538, acc.: 67.19%] [G loss: 0.443411]\n",
      "epoch:23 step:21605 [D loss: 0.208226, acc.: 64.84%] [G loss: 0.483809]\n",
      "epoch:23 step:21606 [D loss: 0.215690, acc.: 64.06%] [G loss: 0.453474]\n",
      "epoch:23 step:21607 [D loss: 0.220340, acc.: 64.84%] [G loss: 0.439841]\n",
      "epoch:23 step:21608 [D loss: 0.258541, acc.: 53.12%] [G loss: 0.403858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21609 [D loss: 0.227168, acc.: 62.50%] [G loss: 0.435031]\n",
      "epoch:23 step:21610 [D loss: 0.209854, acc.: 63.28%] [G loss: 0.447267]\n",
      "epoch:23 step:21611 [D loss: 0.246951, acc.: 53.91%] [G loss: 0.439585]\n",
      "epoch:23 step:21612 [D loss: 0.248826, acc.: 53.91%] [G loss: 0.415939]\n",
      "epoch:23 step:21613 [D loss: 0.229865, acc.: 60.94%] [G loss: 0.431029]\n",
      "epoch:23 step:21614 [D loss: 0.214485, acc.: 64.06%] [G loss: 0.410506]\n",
      "epoch:23 step:21615 [D loss: 0.240147, acc.: 54.69%] [G loss: 0.450352]\n",
      "epoch:23 step:21616 [D loss: 0.225633, acc.: 57.81%] [G loss: 0.420330]\n",
      "epoch:23 step:21617 [D loss: 0.224025, acc.: 59.38%] [G loss: 0.398267]\n",
      "epoch:23 step:21618 [D loss: 0.216807, acc.: 63.28%] [G loss: 0.430680]\n",
      "epoch:23 step:21619 [D loss: 0.218982, acc.: 68.75%] [G loss: 0.416792]\n",
      "epoch:23 step:21620 [D loss: 0.176388, acc.: 75.78%] [G loss: 0.444118]\n",
      "epoch:23 step:21621 [D loss: 0.217320, acc.: 64.06%] [G loss: 0.475322]\n",
      "epoch:23 step:21622 [D loss: 0.237388, acc.: 60.16%] [G loss: 0.438985]\n",
      "epoch:23 step:21623 [D loss: 0.217889, acc.: 62.50%] [G loss: 0.417515]\n",
      "epoch:23 step:21624 [D loss: 0.234918, acc.: 60.16%] [G loss: 0.358058]\n",
      "epoch:23 step:21625 [D loss: 0.191138, acc.: 71.09%] [G loss: 0.413900]\n",
      "epoch:23 step:21626 [D loss: 0.213769, acc.: 64.84%] [G loss: 0.434450]\n",
      "epoch:23 step:21627 [D loss: 0.205022, acc.: 62.50%] [G loss: 0.459933]\n",
      "epoch:23 step:21628 [D loss: 0.192523, acc.: 70.31%] [G loss: 0.436393]\n",
      "epoch:23 step:21629 [D loss: 0.249761, acc.: 58.59%] [G loss: 0.454741]\n",
      "epoch:23 step:21630 [D loss: 0.251944, acc.: 56.25%] [G loss: 0.391826]\n",
      "epoch:23 step:21631 [D loss: 0.210018, acc.: 64.84%] [G loss: 0.455099]\n",
      "epoch:23 step:21632 [D loss: 0.230878, acc.: 60.16%] [G loss: 0.396451]\n",
      "epoch:23 step:21633 [D loss: 0.208425, acc.: 67.97%] [G loss: 0.421625]\n",
      "epoch:23 step:21634 [D loss: 0.208652, acc.: 69.53%] [G loss: 0.454502]\n",
      "epoch:23 step:21635 [D loss: 0.221403, acc.: 63.28%] [G loss: 0.461594]\n",
      "epoch:23 step:21636 [D loss: 0.223588, acc.: 64.06%] [G loss: 0.429307]\n",
      "epoch:23 step:21637 [D loss: 0.230718, acc.: 64.84%] [G loss: 0.418054]\n",
      "epoch:23 step:21638 [D loss: 0.234936, acc.: 57.03%] [G loss: 0.407025]\n",
      "epoch:23 step:21639 [D loss: 0.204435, acc.: 71.88%] [G loss: 0.466674]\n",
      "epoch:23 step:21640 [D loss: 0.225002, acc.: 61.72%] [G loss: 0.442082]\n",
      "epoch:23 step:21641 [D loss: 0.204752, acc.: 63.28%] [G loss: 0.487309]\n",
      "epoch:23 step:21642 [D loss: 0.220209, acc.: 64.06%] [G loss: 0.413175]\n",
      "epoch:23 step:21643 [D loss: 0.219951, acc.: 64.06%] [G loss: 0.422030]\n",
      "epoch:23 step:21644 [D loss: 0.209232, acc.: 64.84%] [G loss: 0.462138]\n",
      "epoch:23 step:21645 [D loss: 0.221127, acc.: 60.94%] [G loss: 0.436478]\n",
      "epoch:23 step:21646 [D loss: 0.259726, acc.: 54.69%] [G loss: 0.471151]\n",
      "epoch:23 step:21647 [D loss: 0.224647, acc.: 60.94%] [G loss: 0.445831]\n",
      "epoch:23 step:21648 [D loss: 0.175290, acc.: 75.00%] [G loss: 0.506974]\n",
      "epoch:23 step:21649 [D loss: 0.231203, acc.: 58.59%] [G loss: 0.435700]\n",
      "epoch:23 step:21650 [D loss: 0.229055, acc.: 60.16%] [G loss: 0.417178]\n",
      "epoch:23 step:21651 [D loss: 0.187144, acc.: 68.75%] [G loss: 0.443078]\n",
      "epoch:23 step:21652 [D loss: 0.216019, acc.: 67.97%] [G loss: 0.439436]\n",
      "epoch:23 step:21653 [D loss: 0.241363, acc.: 55.47%] [G loss: 0.427080]\n",
      "epoch:23 step:21654 [D loss: 0.244694, acc.: 57.81%] [G loss: 0.368328]\n",
      "epoch:23 step:21655 [D loss: 0.245751, acc.: 56.25%] [G loss: 0.394859]\n",
      "epoch:23 step:21656 [D loss: 0.226285, acc.: 65.62%] [G loss: 0.366517]\n",
      "epoch:23 step:21657 [D loss: 0.208321, acc.: 69.53%] [G loss: 0.389297]\n",
      "epoch:23 step:21658 [D loss: 0.225581, acc.: 60.16%] [G loss: 0.462562]\n",
      "epoch:23 step:21659 [D loss: 0.248648, acc.: 57.81%] [G loss: 0.468961]\n",
      "epoch:23 step:21660 [D loss: 0.253441, acc.: 58.59%] [G loss: 0.436563]\n",
      "epoch:23 step:21661 [D loss: 0.261692, acc.: 52.34%] [G loss: 0.381576]\n",
      "epoch:23 step:21662 [D loss: 0.204701, acc.: 69.53%] [G loss: 0.425121]\n",
      "epoch:23 step:21663 [D loss: 0.202503, acc.: 68.75%] [G loss: 0.439697]\n",
      "epoch:23 step:21664 [D loss: 0.211680, acc.: 67.19%] [G loss: 0.460069]\n",
      "epoch:23 step:21665 [D loss: 0.210679, acc.: 67.19%] [G loss: 0.457192]\n",
      "epoch:23 step:21666 [D loss: 0.185242, acc.: 75.00%] [G loss: 0.459392]\n",
      "epoch:23 step:21667 [D loss: 0.216484, acc.: 61.72%] [G loss: 0.450748]\n",
      "epoch:23 step:21668 [D loss: 0.218117, acc.: 68.75%] [G loss: 0.466140]\n",
      "epoch:23 step:21669 [D loss: 0.212746, acc.: 62.50%] [G loss: 0.513724]\n",
      "epoch:23 step:21670 [D loss: 0.196423, acc.: 69.53%] [G loss: 0.513346]\n",
      "epoch:23 step:21671 [D loss: 0.239176, acc.: 61.72%] [G loss: 0.479124]\n",
      "epoch:23 step:21672 [D loss: 0.243946, acc.: 58.59%] [G loss: 0.427426]\n",
      "epoch:23 step:21673 [D loss: 0.186847, acc.: 72.66%] [G loss: 0.497382]\n",
      "epoch:23 step:21674 [D loss: 0.220988, acc.: 60.94%] [G loss: 0.495430]\n",
      "epoch:23 step:21675 [D loss: 0.247409, acc.: 61.72%] [G loss: 0.462630]\n",
      "epoch:23 step:21676 [D loss: 0.232171, acc.: 59.38%] [G loss: 0.428707]\n",
      "epoch:23 step:21677 [D loss: 0.201113, acc.: 67.19%] [G loss: 0.426615]\n",
      "epoch:23 step:21678 [D loss: 0.223799, acc.: 64.06%] [G loss: 0.419314]\n",
      "epoch:23 step:21679 [D loss: 0.239303, acc.: 60.16%] [G loss: 0.385620]\n",
      "epoch:23 step:21680 [D loss: 0.231639, acc.: 60.16%] [G loss: 0.398943]\n",
      "epoch:23 step:21681 [D loss: 0.205240, acc.: 65.62%] [G loss: 0.435917]\n",
      "epoch:23 step:21682 [D loss: 0.217472, acc.: 64.06%] [G loss: 0.439153]\n",
      "epoch:23 step:21683 [D loss: 0.201442, acc.: 66.41%] [G loss: 0.478703]\n",
      "epoch:23 step:21684 [D loss: 0.249337, acc.: 62.50%] [G loss: 0.446178]\n",
      "epoch:23 step:21685 [D loss: 0.229847, acc.: 61.72%] [G loss: 0.431268]\n",
      "epoch:23 step:21686 [D loss: 0.203416, acc.: 67.97%] [G loss: 0.475670]\n",
      "epoch:23 step:21687 [D loss: 0.219997, acc.: 64.84%] [G loss: 0.544773]\n",
      "epoch:23 step:21688 [D loss: 0.244376, acc.: 53.12%] [G loss: 0.444102]\n",
      "epoch:23 step:21689 [D loss: 0.207307, acc.: 61.72%] [G loss: 0.394519]\n",
      "epoch:23 step:21690 [D loss: 0.244228, acc.: 54.69%] [G loss: 0.386076]\n",
      "epoch:23 step:21691 [D loss: 0.221067, acc.: 67.19%] [G loss: 0.443890]\n",
      "epoch:23 step:21692 [D loss: 0.236707, acc.: 58.59%] [G loss: 0.437474]\n",
      "epoch:23 step:21693 [D loss: 0.239205, acc.: 54.69%] [G loss: 0.437576]\n",
      "epoch:23 step:21694 [D loss: 0.248162, acc.: 57.03%] [G loss: 0.414392]\n",
      "epoch:23 step:21695 [D loss: 0.212584, acc.: 61.72%] [G loss: 0.436856]\n",
      "epoch:23 step:21696 [D loss: 0.233710, acc.: 62.50%] [G loss: 0.424666]\n",
      "epoch:23 step:21697 [D loss: 0.218216, acc.: 65.62%] [G loss: 0.450227]\n",
      "epoch:23 step:21698 [D loss: 0.225413, acc.: 63.28%] [G loss: 0.421960]\n",
      "epoch:23 step:21699 [D loss: 0.256579, acc.: 58.59%] [G loss: 0.405859]\n",
      "epoch:23 step:21700 [D loss: 0.226021, acc.: 61.72%] [G loss: 0.401708]\n",
      "epoch:23 step:21701 [D loss: 0.243445, acc.: 57.03%] [G loss: 0.397120]\n",
      "epoch:23 step:21702 [D loss: 0.191091, acc.: 74.22%] [G loss: 0.441332]\n",
      "epoch:23 step:21703 [D loss: 0.238394, acc.: 58.59%] [G loss: 0.416335]\n",
      "epoch:23 step:21704 [D loss: 0.252678, acc.: 59.38%] [G loss: 0.415452]\n",
      "epoch:23 step:21705 [D loss: 0.227843, acc.: 61.72%] [G loss: 0.396590]\n",
      "epoch:23 step:21706 [D loss: 0.208014, acc.: 67.19%] [G loss: 0.413161]\n",
      "epoch:23 step:21707 [D loss: 0.192254, acc.: 71.88%] [G loss: 0.456811]\n",
      "epoch:23 step:21708 [D loss: 0.229803, acc.: 64.84%] [G loss: 0.421280]\n",
      "epoch:23 step:21709 [D loss: 0.229963, acc.: 64.06%] [G loss: 0.422697]\n",
      "epoch:23 step:21710 [D loss: 0.196941, acc.: 71.88%] [G loss: 0.402805]\n",
      "epoch:23 step:21711 [D loss: 0.268912, acc.: 50.00%] [G loss: 0.452766]\n",
      "epoch:23 step:21712 [D loss: 0.246810, acc.: 57.03%] [G loss: 0.475872]\n",
      "epoch:23 step:21713 [D loss: 0.271060, acc.: 54.69%] [G loss: 0.413086]\n",
      "epoch:23 step:21714 [D loss: 0.209684, acc.: 69.53%] [G loss: 0.436744]\n",
      "epoch:23 step:21715 [D loss: 0.216222, acc.: 67.19%] [G loss: 0.451331]\n",
      "epoch:23 step:21716 [D loss: 0.214273, acc.: 64.84%] [G loss: 0.401941]\n",
      "epoch:23 step:21717 [D loss: 0.245182, acc.: 59.38%] [G loss: 0.362450]\n",
      "epoch:23 step:21718 [D loss: 0.221365, acc.: 58.59%] [G loss: 0.425265]\n",
      "epoch:23 step:21719 [D loss: 0.240131, acc.: 60.94%] [G loss: 0.409206]\n",
      "epoch:23 step:21720 [D loss: 0.206273, acc.: 72.66%] [G loss: 0.445489]\n",
      "epoch:23 step:21721 [D loss: 0.240901, acc.: 57.03%] [G loss: 0.397789]\n",
      "epoch:23 step:21722 [D loss: 0.220116, acc.: 63.28%] [G loss: 0.418679]\n",
      "epoch:23 step:21723 [D loss: 0.217815, acc.: 63.28%] [G loss: 0.443785]\n",
      "epoch:23 step:21724 [D loss: 0.219853, acc.: 65.62%] [G loss: 0.417526]\n",
      "epoch:23 step:21725 [D loss: 0.238036, acc.: 58.59%] [G loss: 0.384095]\n",
      "epoch:23 step:21726 [D loss: 0.240240, acc.: 53.91%] [G loss: 0.402827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21727 [D loss: 0.232313, acc.: 63.28%] [G loss: 0.432873]\n",
      "epoch:23 step:21728 [D loss: 0.251698, acc.: 52.34%] [G loss: 0.377291]\n",
      "epoch:23 step:21729 [D loss: 0.229825, acc.: 57.03%] [G loss: 0.402980]\n",
      "epoch:23 step:21730 [D loss: 0.235693, acc.: 57.81%] [G loss: 0.421679]\n",
      "epoch:23 step:21731 [D loss: 0.238433, acc.: 57.03%] [G loss: 0.432099]\n",
      "epoch:23 step:21732 [D loss: 0.244584, acc.: 58.59%] [G loss: 0.424683]\n",
      "epoch:23 step:21733 [D loss: 0.217872, acc.: 64.06%] [G loss: 0.454064]\n",
      "epoch:23 step:21734 [D loss: 0.246768, acc.: 57.03%] [G loss: 0.418573]\n",
      "epoch:23 step:21735 [D loss: 0.237249, acc.: 66.41%] [G loss: 0.410061]\n",
      "epoch:23 step:21736 [D loss: 0.220537, acc.: 64.84%] [G loss: 0.455058]\n",
      "epoch:23 step:21737 [D loss: 0.231300, acc.: 69.53%] [G loss: 0.404114]\n",
      "epoch:23 step:21738 [D loss: 0.208728, acc.: 67.97%] [G loss: 0.418348]\n",
      "epoch:23 step:21739 [D loss: 0.242798, acc.: 59.38%] [G loss: 0.411465]\n",
      "epoch:23 step:21740 [D loss: 0.229275, acc.: 62.50%] [G loss: 0.385041]\n",
      "epoch:23 step:21741 [D loss: 0.204656, acc.: 68.75%] [G loss: 0.445173]\n",
      "epoch:23 step:21742 [D loss: 0.197597, acc.: 71.09%] [G loss: 0.440840]\n",
      "epoch:23 step:21743 [D loss: 0.233859, acc.: 57.03%] [G loss: 0.421374]\n",
      "epoch:23 step:21744 [D loss: 0.225308, acc.: 64.84%] [G loss: 0.421945]\n",
      "epoch:23 step:21745 [D loss: 0.208626, acc.: 71.88%] [G loss: 0.430412]\n",
      "epoch:23 step:21746 [D loss: 0.231323, acc.: 60.16%] [G loss: 0.423514]\n",
      "epoch:23 step:21747 [D loss: 0.254701, acc.: 54.69%] [G loss: 0.393390]\n",
      "epoch:23 step:21748 [D loss: 0.223394, acc.: 60.16%] [G loss: 0.396429]\n",
      "epoch:23 step:21749 [D loss: 0.195410, acc.: 71.88%] [G loss: 0.415673]\n",
      "epoch:23 step:21750 [D loss: 0.227861, acc.: 63.28%] [G loss: 0.433517]\n",
      "epoch:23 step:21751 [D loss: 0.256497, acc.: 56.25%] [G loss: 0.403505]\n",
      "epoch:23 step:21752 [D loss: 0.247387, acc.: 58.59%] [G loss: 0.401362]\n",
      "epoch:23 step:21753 [D loss: 0.248566, acc.: 58.59%] [G loss: 0.386642]\n",
      "epoch:23 step:21754 [D loss: 0.250688, acc.: 50.78%] [G loss: 0.421588]\n",
      "epoch:23 step:21755 [D loss: 0.214344, acc.: 62.50%] [G loss: 0.471196]\n",
      "epoch:23 step:21756 [D loss: 0.214395, acc.: 67.19%] [G loss: 0.489693]\n",
      "epoch:23 step:21757 [D loss: 0.214811, acc.: 65.62%] [G loss: 0.455908]\n",
      "epoch:23 step:21758 [D loss: 0.210207, acc.: 67.19%] [G loss: 0.456680]\n",
      "epoch:23 step:21759 [D loss: 0.223090, acc.: 62.50%] [G loss: 0.416877]\n",
      "epoch:23 step:21760 [D loss: 0.189134, acc.: 67.97%] [G loss: 0.471521]\n",
      "epoch:23 step:21761 [D loss: 0.270862, acc.: 56.25%] [G loss: 0.389622]\n",
      "epoch:23 step:21762 [D loss: 0.242812, acc.: 59.38%] [G loss: 0.394984]\n",
      "epoch:23 step:21763 [D loss: 0.243448, acc.: 57.81%] [G loss: 0.398174]\n",
      "epoch:23 step:21764 [D loss: 0.227253, acc.: 59.38%] [G loss: 0.440469]\n",
      "epoch:23 step:21765 [D loss: 0.266309, acc.: 56.25%] [G loss: 0.432028]\n",
      "epoch:23 step:21766 [D loss: 0.262679, acc.: 55.47%] [G loss: 0.440754]\n",
      "epoch:23 step:21767 [D loss: 0.220585, acc.: 61.72%] [G loss: 0.436595]\n",
      "epoch:23 step:21768 [D loss: 0.217779, acc.: 64.06%] [G loss: 0.419681]\n",
      "epoch:23 step:21769 [D loss: 0.174790, acc.: 80.47%] [G loss: 0.429587]\n",
      "epoch:23 step:21770 [D loss: 0.200391, acc.: 75.00%] [G loss: 0.448432]\n",
      "epoch:23 step:21771 [D loss: 0.266903, acc.: 54.69%] [G loss: 0.460847]\n",
      "epoch:23 step:21772 [D loss: 0.215957, acc.: 67.97%] [G loss: 0.443697]\n",
      "epoch:23 step:21773 [D loss: 0.225277, acc.: 69.53%] [G loss: 0.423861]\n",
      "epoch:23 step:21774 [D loss: 0.204282, acc.: 67.97%] [G loss: 0.475023]\n",
      "epoch:23 step:21775 [D loss: 0.244491, acc.: 56.25%] [G loss: 0.415979]\n",
      "epoch:23 step:21776 [D loss: 0.194143, acc.: 69.53%] [G loss: 0.417720]\n",
      "epoch:23 step:21777 [D loss: 0.241688, acc.: 59.38%] [G loss: 0.372277]\n",
      "epoch:23 step:21778 [D loss: 0.230846, acc.: 61.72%] [G loss: 0.376018]\n",
      "epoch:23 step:21779 [D loss: 0.243305, acc.: 60.16%] [G loss: 0.371271]\n",
      "epoch:23 step:21780 [D loss: 0.206580, acc.: 67.97%] [G loss: 0.446585]\n",
      "epoch:23 step:21781 [D loss: 0.198073, acc.: 64.84%] [G loss: 0.444709]\n",
      "epoch:23 step:21782 [D loss: 0.182860, acc.: 71.88%] [G loss: 0.515890]\n",
      "epoch:23 step:21783 [D loss: 0.158956, acc.: 78.91%] [G loss: 0.591560]\n",
      "epoch:23 step:21784 [D loss: 0.249742, acc.: 64.84%] [G loss: 0.433437]\n",
      "epoch:23 step:21785 [D loss: 0.229761, acc.: 65.62%] [G loss: 0.451559]\n",
      "epoch:23 step:21786 [D loss: 0.219086, acc.: 64.84%] [G loss: 0.411554]\n",
      "epoch:23 step:21787 [D loss: 0.235860, acc.: 60.94%] [G loss: 0.426348]\n",
      "epoch:23 step:21788 [D loss: 0.216241, acc.: 64.06%] [G loss: 0.417063]\n",
      "epoch:23 step:21789 [D loss: 0.209135, acc.: 64.06%] [G loss: 0.461824]\n",
      "epoch:23 step:21790 [D loss: 0.204258, acc.: 71.09%] [G loss: 0.432978]\n",
      "epoch:23 step:21791 [D loss: 0.217924, acc.: 65.62%] [G loss: 0.426304]\n",
      "epoch:23 step:21792 [D loss: 0.211906, acc.: 65.62%] [G loss: 0.454261]\n",
      "epoch:23 step:21793 [D loss: 0.203894, acc.: 68.75%] [G loss: 0.430556]\n",
      "epoch:23 step:21794 [D loss: 0.224518, acc.: 63.28%] [G loss: 0.445175]\n",
      "epoch:23 step:21795 [D loss: 0.199745, acc.: 71.88%] [G loss: 0.456586]\n",
      "epoch:23 step:21796 [D loss: 0.213230, acc.: 65.62%] [G loss: 0.430574]\n",
      "epoch:23 step:21797 [D loss: 0.223225, acc.: 62.50%] [G loss: 0.429446]\n",
      "epoch:23 step:21798 [D loss: 0.223326, acc.: 61.72%] [G loss: 0.449116]\n",
      "epoch:23 step:21799 [D loss: 0.201827, acc.: 73.44%] [G loss: 0.455021]\n",
      "epoch:23 step:21800 [D loss: 0.255507, acc.: 56.25%] [G loss: 0.433732]\n",
      "epoch:23 step:21801 [D loss: 0.241260, acc.: 61.72%] [G loss: 0.416210]\n",
      "epoch:23 step:21802 [D loss: 0.263862, acc.: 54.69%] [G loss: 0.421688]\n",
      "epoch:23 step:21803 [D loss: 0.220652, acc.: 63.28%] [G loss: 0.462019]\n",
      "epoch:23 step:21804 [D loss: 0.240023, acc.: 57.81%] [G loss: 0.453767]\n",
      "epoch:23 step:21805 [D loss: 0.239397, acc.: 57.03%] [G loss: 0.422212]\n",
      "epoch:23 step:21806 [D loss: 0.222186, acc.: 64.84%] [G loss: 0.452687]\n",
      "epoch:23 step:21807 [D loss: 0.209201, acc.: 66.41%] [G loss: 0.453636]\n",
      "epoch:23 step:21808 [D loss: 0.226863, acc.: 60.94%] [G loss: 0.425773]\n",
      "epoch:23 step:21809 [D loss: 0.190880, acc.: 69.53%] [G loss: 0.460886]\n",
      "epoch:23 step:21810 [D loss: 0.214684, acc.: 70.31%] [G loss: 0.463694]\n",
      "epoch:23 step:21811 [D loss: 0.219630, acc.: 57.81%] [G loss: 0.444465]\n",
      "epoch:23 step:21812 [D loss: 0.224174, acc.: 67.19%] [G loss: 0.434738]\n",
      "epoch:23 step:21813 [D loss: 0.202201, acc.: 64.84%] [G loss: 0.424824]\n",
      "epoch:23 step:21814 [D loss: 0.290748, acc.: 50.00%] [G loss: 0.391204]\n",
      "epoch:23 step:21815 [D loss: 0.194361, acc.: 73.44%] [G loss: 0.454378]\n",
      "epoch:23 step:21816 [D loss: 0.230031, acc.: 59.38%] [G loss: 0.452659]\n",
      "epoch:23 step:21817 [D loss: 0.245091, acc.: 57.81%] [G loss: 0.422596]\n",
      "epoch:23 step:21818 [D loss: 0.230865, acc.: 64.06%] [G loss: 0.409485]\n",
      "epoch:23 step:21819 [D loss: 0.208564, acc.: 64.84%] [G loss: 0.473320]\n",
      "epoch:23 step:21820 [D loss: 0.224650, acc.: 63.28%] [G loss: 0.479258]\n",
      "epoch:23 step:21821 [D loss: 0.234557, acc.: 60.94%] [G loss: 0.431904]\n",
      "epoch:23 step:21822 [D loss: 0.190177, acc.: 75.00%] [G loss: 0.450415]\n",
      "epoch:23 step:21823 [D loss: 0.210397, acc.: 70.31%] [G loss: 0.457364]\n",
      "epoch:23 step:21824 [D loss: 0.207750, acc.: 70.31%] [G loss: 0.435386]\n",
      "epoch:23 step:21825 [D loss: 0.191187, acc.: 71.09%] [G loss: 0.477020]\n",
      "epoch:23 step:21826 [D loss: 0.210153, acc.: 68.75%] [G loss: 0.456266]\n",
      "epoch:23 step:21827 [D loss: 0.208955, acc.: 71.88%] [G loss: 0.461988]\n",
      "epoch:23 step:21828 [D loss: 0.252641, acc.: 55.47%] [G loss: 0.440885]\n",
      "epoch:23 step:21829 [D loss: 0.227297, acc.: 61.72%] [G loss: 0.451047]\n",
      "epoch:23 step:21830 [D loss: 0.224795, acc.: 60.94%] [G loss: 0.423733]\n",
      "epoch:23 step:21831 [D loss: 0.199894, acc.: 70.31%] [G loss: 0.451314]\n",
      "epoch:23 step:21832 [D loss: 0.248122, acc.: 53.91%] [G loss: 0.409748]\n",
      "epoch:23 step:21833 [D loss: 0.245209, acc.: 53.12%] [G loss: 0.397785]\n",
      "epoch:23 step:21834 [D loss: 0.204969, acc.: 71.88%] [G loss: 0.449554]\n",
      "epoch:23 step:21835 [D loss: 0.217809, acc.: 64.84%] [G loss: 0.437617]\n",
      "epoch:23 step:21836 [D loss: 0.211530, acc.: 67.19%] [G loss: 0.422552]\n",
      "epoch:23 step:21837 [D loss: 0.221495, acc.: 64.84%] [G loss: 0.423685]\n",
      "epoch:23 step:21838 [D loss: 0.214668, acc.: 65.62%] [G loss: 0.465394]\n",
      "epoch:23 step:21839 [D loss: 0.203289, acc.: 66.41%] [G loss: 0.456409]\n",
      "epoch:23 step:21840 [D loss: 0.195089, acc.: 72.66%] [G loss: 0.476509]\n",
      "epoch:23 step:21841 [D loss: 0.210739, acc.: 65.62%] [G loss: 0.468470]\n",
      "epoch:23 step:21842 [D loss: 0.260151, acc.: 54.69%] [G loss: 0.404724]\n",
      "epoch:23 step:21843 [D loss: 0.215779, acc.: 60.16%] [G loss: 0.414532]\n",
      "epoch:23 step:21844 [D loss: 0.221027, acc.: 64.84%] [G loss: 0.452579]\n",
      "epoch:23 step:21845 [D loss: 0.264073, acc.: 45.31%] [G loss: 0.415319]\n",
      "epoch:23 step:21846 [D loss: 0.234685, acc.: 60.16%] [G loss: 0.409843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21847 [D loss: 0.192010, acc.: 71.88%] [G loss: 0.450975]\n",
      "epoch:23 step:21848 [D loss: 0.232351, acc.: 60.94%] [G loss: 0.438034]\n",
      "epoch:23 step:21849 [D loss: 0.225447, acc.: 64.06%] [G loss: 0.455462]\n",
      "epoch:23 step:21850 [D loss: 0.209387, acc.: 63.28%] [G loss: 0.499088]\n",
      "epoch:23 step:21851 [D loss: 0.215141, acc.: 65.62%] [G loss: 0.445363]\n",
      "epoch:23 step:21852 [D loss: 0.257784, acc.: 55.47%] [G loss: 0.471786]\n",
      "epoch:23 step:21853 [D loss: 0.238188, acc.: 59.38%] [G loss: 0.414190]\n",
      "epoch:23 step:21854 [D loss: 0.210790, acc.: 67.19%] [G loss: 0.404439]\n",
      "epoch:23 step:21855 [D loss: 0.232095, acc.: 60.94%] [G loss: 0.396847]\n",
      "epoch:23 step:21856 [D loss: 0.230349, acc.: 64.06%] [G loss: 0.439879]\n",
      "epoch:23 step:21857 [D loss: 0.226537, acc.: 64.06%] [G loss: 0.433541]\n",
      "epoch:23 step:21858 [D loss: 0.198883, acc.: 73.44%] [G loss: 0.473865]\n",
      "epoch:23 step:21859 [D loss: 0.219783, acc.: 65.62%] [G loss: 0.455133]\n",
      "epoch:23 step:21860 [D loss: 0.202665, acc.: 71.09%] [G loss: 0.443931]\n",
      "epoch:23 step:21861 [D loss: 0.251339, acc.: 60.94%] [G loss: 0.424246]\n",
      "epoch:23 step:21862 [D loss: 0.192066, acc.: 70.31%] [G loss: 0.452573]\n",
      "epoch:23 step:21863 [D loss: 0.191449, acc.: 70.31%] [G loss: 0.461005]\n",
      "epoch:23 step:21864 [D loss: 0.187511, acc.: 73.44%] [G loss: 0.474799]\n",
      "epoch:23 step:21865 [D loss: 0.201303, acc.: 71.09%] [G loss: 0.435717]\n",
      "epoch:23 step:21866 [D loss: 0.196810, acc.: 71.88%] [G loss: 0.485497]\n",
      "epoch:23 step:21867 [D loss: 0.263891, acc.: 57.03%] [G loss: 0.463604]\n",
      "epoch:23 step:21868 [D loss: 0.261404, acc.: 53.91%] [G loss: 0.428822]\n",
      "epoch:23 step:21869 [D loss: 0.214357, acc.: 64.84%] [G loss: 0.426053]\n",
      "epoch:23 step:21870 [D loss: 0.194988, acc.: 70.31%] [G loss: 0.437373]\n",
      "epoch:23 step:21871 [D loss: 0.223367, acc.: 60.94%] [G loss: 0.436512]\n",
      "epoch:23 step:21872 [D loss: 0.222118, acc.: 66.41%] [G loss: 0.409170]\n",
      "epoch:23 step:21873 [D loss: 0.195012, acc.: 67.19%] [G loss: 0.476111]\n",
      "epoch:23 step:21874 [D loss: 0.285158, acc.: 48.44%] [G loss: 0.441436]\n",
      "epoch:23 step:21875 [D loss: 0.211241, acc.: 68.75%] [G loss: 0.453678]\n",
      "epoch:23 step:21876 [D loss: 0.224394, acc.: 59.38%] [G loss: 0.424114]\n",
      "epoch:23 step:21877 [D loss: 0.183924, acc.: 75.78%] [G loss: 0.460943]\n",
      "epoch:23 step:21878 [D loss: 0.211671, acc.: 66.41%] [G loss: 0.432123]\n",
      "epoch:23 step:21879 [D loss: 0.203942, acc.: 71.09%] [G loss: 0.455204]\n",
      "epoch:23 step:21880 [D loss: 0.243001, acc.: 62.50%] [G loss: 0.407338]\n",
      "epoch:23 step:21881 [D loss: 0.215621, acc.: 68.75%] [G loss: 0.443477]\n",
      "epoch:23 step:21882 [D loss: 0.231902, acc.: 63.28%] [G loss: 0.408760]\n",
      "epoch:23 step:21883 [D loss: 0.200704, acc.: 68.75%] [G loss: 0.431235]\n",
      "epoch:23 step:21884 [D loss: 0.213997, acc.: 67.19%] [G loss: 0.408953]\n",
      "epoch:23 step:21885 [D loss: 0.224871, acc.: 64.84%] [G loss: 0.461354]\n",
      "epoch:23 step:21886 [D loss: 0.222577, acc.: 58.59%] [G loss: 0.476674]\n",
      "epoch:23 step:21887 [D loss: 0.194876, acc.: 69.53%] [G loss: 0.481172]\n",
      "epoch:23 step:21888 [D loss: 0.222177, acc.: 66.41%] [G loss: 0.424714]\n",
      "epoch:23 step:21889 [D loss: 0.224159, acc.: 66.41%] [G loss: 0.418410]\n",
      "epoch:23 step:21890 [D loss: 0.191364, acc.: 71.88%] [G loss: 0.414922]\n",
      "epoch:23 step:21891 [D loss: 0.222459, acc.: 60.94%] [G loss: 0.434229]\n",
      "epoch:23 step:21892 [D loss: 0.268000, acc.: 55.47%] [G loss: 0.404194]\n",
      "epoch:23 step:21893 [D loss: 0.235889, acc.: 59.38%] [G loss: 0.430363]\n",
      "epoch:23 step:21894 [D loss: 0.207367, acc.: 66.41%] [G loss: 0.493412]\n",
      "epoch:23 step:21895 [D loss: 0.191728, acc.: 71.88%] [G loss: 0.515034]\n",
      "epoch:23 step:21896 [D loss: 0.241931, acc.: 60.16%] [G loss: 0.435755]\n",
      "epoch:23 step:21897 [D loss: 0.201459, acc.: 64.06%] [G loss: 0.474792]\n",
      "epoch:23 step:21898 [D loss: 0.174219, acc.: 74.22%] [G loss: 0.521294]\n",
      "epoch:23 step:21899 [D loss: 0.287337, acc.: 59.38%] [G loss: 0.427499]\n",
      "epoch:23 step:21900 [D loss: 0.264882, acc.: 52.34%] [G loss: 0.455170]\n",
      "epoch:23 step:21901 [D loss: 0.216111, acc.: 64.06%] [G loss: 0.419495]\n",
      "epoch:23 step:21902 [D loss: 0.234366, acc.: 62.50%] [G loss: 0.429802]\n",
      "epoch:23 step:21903 [D loss: 0.238071, acc.: 58.59%] [G loss: 0.428759]\n",
      "epoch:23 step:21904 [D loss: 0.212505, acc.: 62.50%] [G loss: 0.420119]\n",
      "epoch:23 step:21905 [D loss: 0.203952, acc.: 72.66%] [G loss: 0.501588]\n",
      "epoch:23 step:21906 [D loss: 0.238253, acc.: 61.72%] [G loss: 0.477962]\n",
      "epoch:23 step:21907 [D loss: 0.232603, acc.: 57.81%] [G loss: 0.397354]\n",
      "epoch:23 step:21908 [D loss: 0.185702, acc.: 70.31%] [G loss: 0.445774]\n",
      "epoch:23 step:21909 [D loss: 0.203266, acc.: 66.41%] [G loss: 0.445886]\n",
      "epoch:23 step:21910 [D loss: 0.221201, acc.: 68.75%] [G loss: 0.466160]\n",
      "epoch:23 step:21911 [D loss: 0.207817, acc.: 64.84%] [G loss: 0.438656]\n",
      "epoch:23 step:21912 [D loss: 0.208157, acc.: 68.75%] [G loss: 0.423767]\n",
      "epoch:23 step:21913 [D loss: 0.233907, acc.: 58.59%] [G loss: 0.421600]\n",
      "epoch:23 step:21914 [D loss: 0.243799, acc.: 64.06%] [G loss: 0.422798]\n",
      "epoch:23 step:21915 [D loss: 0.217457, acc.: 63.28%] [G loss: 0.423998]\n",
      "epoch:23 step:21916 [D loss: 0.240419, acc.: 52.34%] [G loss: 0.414777]\n",
      "epoch:23 step:21917 [D loss: 0.226923, acc.: 63.28%] [G loss: 0.410449]\n",
      "epoch:23 step:21918 [D loss: 0.226643, acc.: 65.62%] [G loss: 0.460205]\n",
      "epoch:23 step:21919 [D loss: 0.249193, acc.: 53.12%] [G loss: 0.399744]\n",
      "epoch:23 step:21920 [D loss: 0.205517, acc.: 66.41%] [G loss: 0.431734]\n",
      "epoch:23 step:21921 [D loss: 0.216371, acc.: 64.06%] [G loss: 0.395897]\n",
      "epoch:23 step:21922 [D loss: 0.201632, acc.: 73.44%] [G loss: 0.418103]\n",
      "epoch:23 step:21923 [D loss: 0.242229, acc.: 57.03%] [G loss: 0.446082]\n",
      "epoch:23 step:21924 [D loss: 0.220517, acc.: 65.62%] [G loss: 0.428905]\n",
      "epoch:23 step:21925 [D loss: 0.178016, acc.: 75.78%] [G loss: 0.415500]\n",
      "epoch:23 step:21926 [D loss: 0.236972, acc.: 60.16%] [G loss: 0.465929]\n",
      "epoch:23 step:21927 [D loss: 0.251991, acc.: 56.25%] [G loss: 0.405002]\n",
      "epoch:23 step:21928 [D loss: 0.256180, acc.: 53.91%] [G loss: 0.412963]\n",
      "epoch:23 step:21929 [D loss: 0.228959, acc.: 61.72%] [G loss: 0.413050]\n",
      "epoch:23 step:21930 [D loss: 0.230503, acc.: 60.16%] [G loss: 0.436376]\n",
      "epoch:23 step:21931 [D loss: 0.233335, acc.: 60.16%] [G loss: 0.415736]\n",
      "epoch:23 step:21932 [D loss: 0.223041, acc.: 64.06%] [G loss: 0.413742]\n",
      "epoch:23 step:21933 [D loss: 0.206971, acc.: 65.62%] [G loss: 0.429347]\n",
      "epoch:23 step:21934 [D loss: 0.230385, acc.: 60.16%] [G loss: 0.410617]\n",
      "epoch:23 step:21935 [D loss: 0.219940, acc.: 60.16%] [G loss: 0.420029]\n",
      "epoch:23 step:21936 [D loss: 0.195639, acc.: 69.53%] [G loss: 0.483562]\n",
      "epoch:23 step:21937 [D loss: 0.237742, acc.: 61.72%] [G loss: 0.432478]\n",
      "epoch:23 step:21938 [D loss: 0.231192, acc.: 59.38%] [G loss: 0.426022]\n",
      "epoch:23 step:21939 [D loss: 0.201767, acc.: 67.19%] [G loss: 0.440992]\n",
      "epoch:23 step:21940 [D loss: 0.223315, acc.: 61.72%] [G loss: 0.469189]\n",
      "epoch:23 step:21941 [D loss: 0.255718, acc.: 56.25%] [G loss: 0.424607]\n",
      "epoch:23 step:21942 [D loss: 0.229136, acc.: 58.59%] [G loss: 0.403927]\n",
      "epoch:23 step:21943 [D loss: 0.239057, acc.: 60.16%] [G loss: 0.403144]\n",
      "epoch:23 step:21944 [D loss: 0.210278, acc.: 68.75%] [G loss: 0.439111]\n",
      "epoch:23 step:21945 [D loss: 0.221544, acc.: 65.62%] [G loss: 0.408059]\n",
      "epoch:23 step:21946 [D loss: 0.219505, acc.: 63.28%] [G loss: 0.444553]\n",
      "epoch:23 step:21947 [D loss: 0.246727, acc.: 54.69%] [G loss: 0.430017]\n",
      "epoch:23 step:21948 [D loss: 0.224566, acc.: 60.94%] [G loss: 0.501024]\n",
      "epoch:23 step:21949 [D loss: 0.204908, acc.: 67.19%] [G loss: 0.488469]\n",
      "epoch:23 step:21950 [D loss: 0.214941, acc.: 66.41%] [G loss: 0.458973]\n",
      "epoch:23 step:21951 [D loss: 0.291655, acc.: 45.31%] [G loss: 0.399303]\n",
      "epoch:23 step:21952 [D loss: 0.236284, acc.: 57.81%] [G loss: 0.415461]\n",
      "epoch:23 step:21953 [D loss: 0.217465, acc.: 70.31%] [G loss: 0.425696]\n",
      "epoch:23 step:21954 [D loss: 0.222910, acc.: 60.94%] [G loss: 0.425109]\n",
      "epoch:23 step:21955 [D loss: 0.233136, acc.: 55.47%] [G loss: 0.444613]\n",
      "epoch:23 step:21956 [D loss: 0.190413, acc.: 71.88%] [G loss: 0.442652]\n",
      "epoch:23 step:21957 [D loss: 0.230142, acc.: 59.38%] [G loss: 0.462956]\n",
      "epoch:23 step:21958 [D loss: 0.205053, acc.: 67.19%] [G loss: 0.455743]\n",
      "epoch:23 step:21959 [D loss: 0.226428, acc.: 60.94%] [G loss: 0.418712]\n",
      "epoch:23 step:21960 [D loss: 0.208341, acc.: 66.41%] [G loss: 0.413655]\n",
      "epoch:23 step:21961 [D loss: 0.244998, acc.: 58.59%] [G loss: 0.384270]\n",
      "epoch:23 step:21962 [D loss: 0.244579, acc.: 60.94%] [G loss: 0.413496]\n",
      "epoch:23 step:21963 [D loss: 0.219832, acc.: 65.62%] [G loss: 0.418908]\n",
      "epoch:23 step:21964 [D loss: 0.240424, acc.: 57.03%] [G loss: 0.407641]\n",
      "epoch:23 step:21965 [D loss: 0.221477, acc.: 64.06%] [G loss: 0.441582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21966 [D loss: 0.175786, acc.: 75.00%] [G loss: 0.485891]\n",
      "epoch:23 step:21967 [D loss: 0.178853, acc.: 74.22%] [G loss: 0.551606]\n",
      "epoch:23 step:21968 [D loss: 0.223775, acc.: 64.06%] [G loss: 0.457078]\n",
      "epoch:23 step:21969 [D loss: 0.264294, acc.: 53.91%] [G loss: 0.410698]\n",
      "epoch:23 step:21970 [D loss: 0.245428, acc.: 56.25%] [G loss: 0.430391]\n",
      "epoch:23 step:21971 [D loss: 0.232574, acc.: 60.94%] [G loss: 0.478726]\n",
      "epoch:23 step:21972 [D loss: 0.236913, acc.: 61.72%] [G loss: 0.397649]\n",
      "epoch:23 step:21973 [D loss: 0.250237, acc.: 55.47%] [G loss: 0.400589]\n",
      "epoch:23 step:21974 [D loss: 0.216095, acc.: 62.50%] [G loss: 0.449844]\n",
      "epoch:23 step:21975 [D loss: 0.219031, acc.: 63.28%] [G loss: 0.431289]\n",
      "epoch:23 step:21976 [D loss: 0.207661, acc.: 68.75%] [G loss: 0.431315]\n",
      "epoch:23 step:21977 [D loss: 0.219549, acc.: 66.41%] [G loss: 0.460990]\n",
      "epoch:23 step:21978 [D loss: 0.232525, acc.: 58.59%] [G loss: 0.420657]\n",
      "epoch:23 step:21979 [D loss: 0.232125, acc.: 62.50%] [G loss: 0.429438]\n",
      "epoch:23 step:21980 [D loss: 0.208722, acc.: 64.06%] [G loss: 0.421050]\n",
      "epoch:23 step:21981 [D loss: 0.184422, acc.: 72.66%] [G loss: 0.466250]\n",
      "epoch:23 step:21982 [D loss: 0.241579, acc.: 58.59%] [G loss: 0.449395]\n",
      "epoch:23 step:21983 [D loss: 0.236884, acc.: 55.47%] [G loss: 0.399820]\n",
      "epoch:23 step:21984 [D loss: 0.222399, acc.: 60.94%] [G loss: 0.412421]\n",
      "epoch:23 step:21985 [D loss: 0.213698, acc.: 64.06%] [G loss: 0.420880]\n",
      "epoch:23 step:21986 [D loss: 0.211055, acc.: 63.28%] [G loss: 0.445294]\n",
      "epoch:23 step:21987 [D loss: 0.193231, acc.: 69.53%] [G loss: 0.536613]\n",
      "epoch:23 step:21988 [D loss: 0.294581, acc.: 44.53%] [G loss: 0.465722]\n",
      "epoch:23 step:21989 [D loss: 0.249788, acc.: 58.59%] [G loss: 0.414867]\n",
      "epoch:23 step:21990 [D loss: 0.234570, acc.: 64.06%] [G loss: 0.396748]\n",
      "epoch:23 step:21991 [D loss: 0.228234, acc.: 59.38%] [G loss: 0.448863]\n",
      "epoch:23 step:21992 [D loss: 0.222531, acc.: 62.50%] [G loss: 0.490616]\n",
      "epoch:23 step:21993 [D loss: 0.225661, acc.: 64.06%] [G loss: 0.421039]\n",
      "epoch:23 step:21994 [D loss: 0.233586, acc.: 57.81%] [G loss: 0.369075]\n",
      "epoch:23 step:21995 [D loss: 0.237957, acc.: 60.94%] [G loss: 0.366515]\n",
      "epoch:23 step:21996 [D loss: 0.211729, acc.: 63.28%] [G loss: 0.427026]\n",
      "epoch:23 step:21997 [D loss: 0.235094, acc.: 60.16%] [G loss: 0.425795]\n",
      "epoch:23 step:21998 [D loss: 0.198845, acc.: 67.19%] [G loss: 0.426586]\n",
      "epoch:23 step:21999 [D loss: 0.253160, acc.: 52.34%] [G loss: 0.405876]\n",
      "epoch:23 step:22000 [D loss: 0.212265, acc.: 63.28%] [G loss: 0.476745]\n",
      "epoch:23 step:22001 [D loss: 0.220304, acc.: 64.84%] [G loss: 0.417035]\n",
      "epoch:23 step:22002 [D loss: 0.208106, acc.: 67.19%] [G loss: 0.434934]\n",
      "epoch:23 step:22003 [D loss: 0.232720, acc.: 62.50%] [G loss: 0.441103]\n",
      "epoch:23 step:22004 [D loss: 0.205073, acc.: 65.62%] [G loss: 0.493537]\n",
      "epoch:23 step:22005 [D loss: 0.229235, acc.: 60.16%] [G loss: 0.450886]\n",
      "epoch:23 step:22006 [D loss: 0.245604, acc.: 55.47%] [G loss: 0.438450]\n",
      "epoch:23 step:22007 [D loss: 0.223331, acc.: 64.84%] [G loss: 0.480959]\n",
      "epoch:23 step:22008 [D loss: 0.200257, acc.: 76.56%] [G loss: 0.494886]\n",
      "epoch:23 step:22009 [D loss: 0.294342, acc.: 43.75%] [G loss: 0.419371]\n",
      "epoch:23 step:22010 [D loss: 0.221930, acc.: 65.62%] [G loss: 0.417958]\n",
      "epoch:23 step:22011 [D loss: 0.217339, acc.: 64.84%] [G loss: 0.443242]\n",
      "epoch:23 step:22012 [D loss: 0.240265, acc.: 53.91%] [G loss: 0.418775]\n",
      "epoch:23 step:22013 [D loss: 0.228827, acc.: 63.28%] [G loss: 0.416810]\n",
      "epoch:23 step:22014 [D loss: 0.243214, acc.: 59.38%] [G loss: 0.398633]\n",
      "epoch:23 step:22015 [D loss: 0.188228, acc.: 73.44%] [G loss: 0.473218]\n",
      "epoch:23 step:22016 [D loss: 0.233956, acc.: 60.16%] [G loss: 0.409687]\n",
      "epoch:23 step:22017 [D loss: 0.233413, acc.: 60.16%] [G loss: 0.412212]\n",
      "epoch:23 step:22018 [D loss: 0.221242, acc.: 65.62%] [G loss: 0.418431]\n",
      "epoch:23 step:22019 [D loss: 0.206320, acc.: 67.19%] [G loss: 0.466204]\n",
      "epoch:23 step:22020 [D loss: 0.200579, acc.: 68.75%] [G loss: 0.459818]\n",
      "epoch:23 step:22021 [D loss: 0.192856, acc.: 71.88%] [G loss: 0.507426]\n",
      "epoch:23 step:22022 [D loss: 0.224743, acc.: 67.19%] [G loss: 0.489606]\n",
      "epoch:23 step:22023 [D loss: 0.199149, acc.: 68.75%] [G loss: 0.480457]\n",
      "epoch:23 step:22024 [D loss: 0.256184, acc.: 55.47%] [G loss: 0.454870]\n",
      "epoch:23 step:22025 [D loss: 0.183320, acc.: 74.22%] [G loss: 0.433867]\n",
      "epoch:23 step:22026 [D loss: 0.192320, acc.: 73.44%] [G loss: 0.454583]\n",
      "epoch:23 step:22027 [D loss: 0.216080, acc.: 69.53%] [G loss: 0.485500]\n",
      "epoch:23 step:22028 [D loss: 0.273016, acc.: 50.78%] [G loss: 0.441740]\n",
      "epoch:23 step:22029 [D loss: 0.247790, acc.: 60.16%] [G loss: 0.396540]\n",
      "epoch:23 step:22030 [D loss: 0.238355, acc.: 63.28%] [G loss: 0.412767]\n",
      "epoch:23 step:22031 [D loss: 0.224694, acc.: 58.59%] [G loss: 0.448396]\n",
      "epoch:23 step:22032 [D loss: 0.183101, acc.: 76.56%] [G loss: 0.473110]\n",
      "epoch:23 step:22033 [D loss: 0.235340, acc.: 58.59%] [G loss: 0.442903]\n",
      "epoch:23 step:22034 [D loss: 0.211259, acc.: 70.31%] [G loss: 0.404609]\n",
      "epoch:23 step:22035 [D loss: 0.193227, acc.: 72.66%] [G loss: 0.471740]\n",
      "epoch:23 step:22036 [D loss: 0.226466, acc.: 67.19%] [G loss: 0.461217]\n",
      "epoch:23 step:22037 [D loss: 0.237579, acc.: 58.59%] [G loss: 0.464319]\n",
      "epoch:23 step:22038 [D loss: 0.250016, acc.: 57.03%] [G loss: 0.447694]\n",
      "epoch:23 step:22039 [D loss: 0.204003, acc.: 71.09%] [G loss: 0.412398]\n",
      "epoch:23 step:22040 [D loss: 0.235302, acc.: 59.38%] [G loss: 0.424932]\n",
      "epoch:23 step:22041 [D loss: 0.229506, acc.: 64.84%] [G loss: 0.400904]\n",
      "epoch:23 step:22042 [D loss: 0.212028, acc.: 64.84%] [G loss: 0.403448]\n",
      "epoch:23 step:22043 [D loss: 0.239016, acc.: 58.59%] [G loss: 0.383315]\n",
      "epoch:23 step:22044 [D loss: 0.227140, acc.: 64.06%] [G loss: 0.420812]\n",
      "epoch:23 step:22045 [D loss: 0.223242, acc.: 68.75%] [G loss: 0.417633]\n",
      "epoch:23 step:22046 [D loss: 0.195743, acc.: 74.22%] [G loss: 0.518679]\n",
      "epoch:23 step:22047 [D loss: 0.207824, acc.: 70.31%] [G loss: 0.478443]\n",
      "epoch:23 step:22048 [D loss: 0.214803, acc.: 67.19%] [G loss: 0.483499]\n",
      "epoch:23 step:22049 [D loss: 0.216287, acc.: 60.16%] [G loss: 0.418858]\n",
      "epoch:23 step:22050 [D loss: 0.219119, acc.: 67.97%] [G loss: 0.463126]\n",
      "epoch:23 step:22051 [D loss: 0.248962, acc.: 57.81%] [G loss: 0.441826]\n",
      "epoch:23 step:22052 [D loss: 0.278156, acc.: 49.22%] [G loss: 0.418777]\n",
      "epoch:23 step:22053 [D loss: 0.264322, acc.: 48.44%] [G loss: 0.366035]\n",
      "epoch:23 step:22054 [D loss: 0.224726, acc.: 64.06%] [G loss: 0.431822]\n",
      "epoch:23 step:22055 [D loss: 0.200335, acc.: 66.41%] [G loss: 0.466731]\n",
      "epoch:23 step:22056 [D loss: 0.233208, acc.: 60.94%] [G loss: 0.445842]\n",
      "epoch:23 step:22057 [D loss: 0.221197, acc.: 62.50%] [G loss: 0.459244]\n",
      "epoch:23 step:22058 [D loss: 0.219051, acc.: 65.62%] [G loss: 0.467520]\n",
      "epoch:23 step:22059 [D loss: 0.194586, acc.: 67.97%] [G loss: 0.485393]\n",
      "epoch:23 step:22060 [D loss: 0.281871, acc.: 51.56%] [G loss: 0.426033]\n",
      "epoch:23 step:22061 [D loss: 0.259969, acc.: 50.78%] [G loss: 0.369835]\n",
      "epoch:23 step:22062 [D loss: 0.235345, acc.: 54.69%] [G loss: 0.425464]\n",
      "epoch:23 step:22063 [D loss: 0.224036, acc.: 62.50%] [G loss: 0.427311]\n",
      "epoch:23 step:22064 [D loss: 0.210529, acc.: 66.41%] [G loss: 0.435144]\n",
      "epoch:23 step:22065 [D loss: 0.218952, acc.: 60.16%] [G loss: 0.426131]\n",
      "epoch:23 step:22066 [D loss: 0.222800, acc.: 61.72%] [G loss: 0.419059]\n",
      "epoch:23 step:22067 [D loss: 0.206167, acc.: 71.88%] [G loss: 0.465192]\n",
      "epoch:23 step:22068 [D loss: 0.249478, acc.: 59.38%] [G loss: 0.414289]\n",
      "epoch:23 step:22069 [D loss: 0.238359, acc.: 59.38%] [G loss: 0.397504]\n",
      "epoch:23 step:22070 [D loss: 0.215246, acc.: 68.75%] [G loss: 0.419894]\n",
      "epoch:23 step:22071 [D loss: 0.205484, acc.: 73.44%] [G loss: 0.445069]\n",
      "epoch:23 step:22072 [D loss: 0.213832, acc.: 63.28%] [G loss: 0.444817]\n",
      "epoch:23 step:22073 [D loss: 0.205514, acc.: 65.62%] [G loss: 0.434997]\n",
      "epoch:23 step:22074 [D loss: 0.204729, acc.: 70.31%] [G loss: 0.440236]\n",
      "epoch:23 step:22075 [D loss: 0.229609, acc.: 59.38%] [G loss: 0.391863]\n",
      "epoch:23 step:22076 [D loss: 0.215242, acc.: 66.41%] [G loss: 0.448601]\n",
      "epoch:23 step:22077 [D loss: 0.222908, acc.: 63.28%] [G loss: 0.416519]\n",
      "epoch:23 step:22078 [D loss: 0.217893, acc.: 61.72%] [G loss: 0.455774]\n",
      "epoch:23 step:22079 [D loss: 0.270994, acc.: 52.34%] [G loss: 0.412237]\n",
      "epoch:23 step:22080 [D loss: 0.248119, acc.: 61.72%] [G loss: 0.462994]\n",
      "epoch:23 step:22081 [D loss: 0.227950, acc.: 64.84%] [G loss: 0.470857]\n",
      "epoch:23 step:22082 [D loss: 0.261830, acc.: 51.56%] [G loss: 0.414135]\n",
      "epoch:23 step:22083 [D loss: 0.222491, acc.: 63.28%] [G loss: 0.374609]\n",
      "epoch:23 step:22084 [D loss: 0.190046, acc.: 71.09%] [G loss: 0.433452]\n",
      "epoch:23 step:22085 [D loss: 0.195983, acc.: 70.31%] [G loss: 0.436987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22086 [D loss: 0.262621, acc.: 49.22%] [G loss: 0.380249]\n",
      "epoch:23 step:22087 [D loss: 0.228805, acc.: 57.81%] [G loss: 0.395885]\n",
      "epoch:23 step:22088 [D loss: 0.237230, acc.: 58.59%] [G loss: 0.430739]\n",
      "epoch:23 step:22089 [D loss: 0.234009, acc.: 58.59%] [G loss: 0.408755]\n",
      "epoch:23 step:22090 [D loss: 0.229681, acc.: 66.41%] [G loss: 0.419621]\n",
      "epoch:23 step:22091 [D loss: 0.242931, acc.: 53.12%] [G loss: 0.415330]\n",
      "epoch:23 step:22092 [D loss: 0.240608, acc.: 61.72%] [G loss: 0.392216]\n",
      "epoch:23 step:22093 [D loss: 0.254945, acc.: 54.69%] [G loss: 0.430012]\n",
      "epoch:23 step:22094 [D loss: 0.212128, acc.: 70.31%] [G loss: 0.452678]\n",
      "epoch:23 step:22095 [D loss: 0.242970, acc.: 54.69%] [G loss: 0.419186]\n",
      "epoch:23 step:22096 [D loss: 0.232426, acc.: 66.41%] [G loss: 0.429028]\n",
      "epoch:23 step:22097 [D loss: 0.212099, acc.: 64.06%] [G loss: 0.407706]\n",
      "epoch:23 step:22098 [D loss: 0.205252, acc.: 70.31%] [G loss: 0.432514]\n",
      "epoch:23 step:22099 [D loss: 0.213408, acc.: 64.84%] [G loss: 0.433071]\n",
      "epoch:23 step:22100 [D loss: 0.201562, acc.: 71.09%] [G loss: 0.430014]\n",
      "epoch:23 step:22101 [D loss: 0.212511, acc.: 67.97%] [G loss: 0.440948]\n",
      "epoch:23 step:22102 [D loss: 0.219311, acc.: 67.97%] [G loss: 0.470396]\n",
      "epoch:23 step:22103 [D loss: 0.204051, acc.: 69.53%] [G loss: 0.481103]\n",
      "epoch:23 step:22104 [D loss: 0.224225, acc.: 63.28%] [G loss: 0.453223]\n",
      "epoch:23 step:22105 [D loss: 0.203763, acc.: 72.66%] [G loss: 0.458109]\n",
      "epoch:23 step:22106 [D loss: 0.206449, acc.: 67.97%] [G loss: 0.449534]\n",
      "epoch:23 step:22107 [D loss: 0.209521, acc.: 66.41%] [G loss: 0.437174]\n",
      "epoch:23 step:22108 [D loss: 0.205405, acc.: 69.53%] [G loss: 0.466007]\n",
      "epoch:23 step:22109 [D loss: 0.210671, acc.: 65.62%] [G loss: 0.449296]\n",
      "epoch:23 step:22110 [D loss: 0.257607, acc.: 55.47%] [G loss: 0.424045]\n",
      "epoch:23 step:22111 [D loss: 0.245790, acc.: 54.69%] [G loss: 0.418397]\n",
      "epoch:23 step:22112 [D loss: 0.207764, acc.: 65.62%] [G loss: 0.467724]\n",
      "epoch:23 step:22113 [D loss: 0.224897, acc.: 67.19%] [G loss: 0.422289]\n",
      "epoch:23 step:22114 [D loss: 0.197736, acc.: 67.97%] [G loss: 0.450240]\n",
      "epoch:23 step:22115 [D loss: 0.186988, acc.: 67.97%] [G loss: 0.513598]\n",
      "epoch:23 step:22116 [D loss: 0.230289, acc.: 58.59%] [G loss: 0.474780]\n",
      "epoch:23 step:22117 [D loss: 0.247274, acc.: 58.59%] [G loss: 0.462625]\n",
      "epoch:23 step:22118 [D loss: 0.212408, acc.: 62.50%] [G loss: 0.451482]\n",
      "epoch:23 step:22119 [D loss: 0.219048, acc.: 67.97%] [G loss: 0.433171]\n",
      "epoch:23 step:22120 [D loss: 0.237391, acc.: 58.59%] [G loss: 0.409664]\n",
      "epoch:23 step:22121 [D loss: 0.223787, acc.: 65.62%] [G loss: 0.462408]\n",
      "epoch:23 step:22122 [D loss: 0.197923, acc.: 69.53%] [G loss: 0.474149]\n",
      "epoch:23 step:22123 [D loss: 0.212962, acc.: 65.62%] [G loss: 0.424393]\n",
      "epoch:23 step:22124 [D loss: 0.241963, acc.: 56.25%] [G loss: 0.402146]\n",
      "epoch:23 step:22125 [D loss: 0.206197, acc.: 67.97%] [G loss: 0.489351]\n",
      "epoch:23 step:22126 [D loss: 0.218343, acc.: 69.53%] [G loss: 0.465991]\n",
      "epoch:23 step:22127 [D loss: 0.223326, acc.: 60.94%] [G loss: 0.420157]\n",
      "epoch:23 step:22128 [D loss: 0.235501, acc.: 56.25%] [G loss: 0.393402]\n",
      "epoch:23 step:22129 [D loss: 0.220855, acc.: 61.72%] [G loss: 0.425743]\n",
      "epoch:23 step:22130 [D loss: 0.235619, acc.: 56.25%] [G loss: 0.406160]\n",
      "epoch:23 step:22131 [D loss: 0.200863, acc.: 67.19%] [G loss: 0.420363]\n",
      "epoch:23 step:22132 [D loss: 0.192784, acc.: 71.09%] [G loss: 0.453606]\n",
      "epoch:23 step:22133 [D loss: 0.206415, acc.: 68.75%] [G loss: 0.550098]\n",
      "epoch:23 step:22134 [D loss: 0.223841, acc.: 64.84%] [G loss: 0.470696]\n",
      "epoch:23 step:22135 [D loss: 0.228843, acc.: 63.28%] [G loss: 0.436332]\n",
      "epoch:23 step:22136 [D loss: 0.212660, acc.: 67.19%] [G loss: 0.462703]\n",
      "epoch:23 step:22137 [D loss: 0.215117, acc.: 64.06%] [G loss: 0.481305]\n",
      "epoch:23 step:22138 [D loss: 0.240330, acc.: 57.03%] [G loss: 0.469915]\n",
      "epoch:23 step:22139 [D loss: 0.232927, acc.: 55.47%] [G loss: 0.419381]\n",
      "epoch:23 step:22140 [D loss: 0.218033, acc.: 62.50%] [G loss: 0.485743]\n",
      "epoch:23 step:22141 [D loss: 0.236885, acc.: 56.25%] [G loss: 0.415158]\n",
      "epoch:23 step:22142 [D loss: 0.229075, acc.: 57.03%] [G loss: 0.387035]\n",
      "epoch:23 step:22143 [D loss: 0.211572, acc.: 67.19%] [G loss: 0.409264]\n",
      "epoch:23 step:22144 [D loss: 0.233015, acc.: 60.94%] [G loss: 0.400146]\n",
      "epoch:23 step:22145 [D loss: 0.213960, acc.: 65.62%] [G loss: 0.447764]\n",
      "epoch:23 step:22146 [D loss: 0.226438, acc.: 63.28%] [G loss: 0.425364]\n",
      "epoch:23 step:22147 [D loss: 0.242708, acc.: 60.94%] [G loss: 0.429077]\n",
      "epoch:23 step:22148 [D loss: 0.255660, acc.: 51.56%] [G loss: 0.440333]\n",
      "epoch:23 step:22149 [D loss: 0.216363, acc.: 68.75%] [G loss: 0.446288]\n",
      "epoch:23 step:22150 [D loss: 0.219547, acc.: 67.97%] [G loss: 0.430048]\n",
      "epoch:23 step:22151 [D loss: 0.263124, acc.: 55.47%] [G loss: 0.410984]\n",
      "epoch:23 step:22152 [D loss: 0.238299, acc.: 62.50%] [G loss: 0.404713]\n",
      "epoch:23 step:22153 [D loss: 0.225739, acc.: 66.41%] [G loss: 0.467446]\n",
      "epoch:23 step:22154 [D loss: 0.244319, acc.: 59.38%] [G loss: 0.431175]\n",
      "epoch:23 step:22155 [D loss: 0.206491, acc.: 70.31%] [G loss: 0.393754]\n",
      "epoch:23 step:22156 [D loss: 0.225919, acc.: 60.94%] [G loss: 0.447111]\n",
      "epoch:23 step:22157 [D loss: 0.203864, acc.: 71.88%] [G loss: 0.429197]\n",
      "epoch:23 step:22158 [D loss: 0.226423, acc.: 63.28%] [G loss: 0.386771]\n",
      "epoch:23 step:22159 [D loss: 0.199401, acc.: 67.19%] [G loss: 0.415222]\n",
      "epoch:23 step:22160 [D loss: 0.230466, acc.: 64.06%] [G loss: 0.408948]\n",
      "epoch:23 step:22161 [D loss: 0.232325, acc.: 58.59%] [G loss: 0.416617]\n",
      "epoch:23 step:22162 [D loss: 0.204630, acc.: 71.88%] [G loss: 0.432655]\n",
      "epoch:23 step:22163 [D loss: 0.218105, acc.: 66.41%] [G loss: 0.445058]\n",
      "epoch:23 step:22164 [D loss: 0.222506, acc.: 63.28%] [G loss: 0.407213]\n",
      "epoch:23 step:22165 [D loss: 0.249721, acc.: 51.56%] [G loss: 0.415974]\n",
      "epoch:23 step:22166 [D loss: 0.256913, acc.: 54.69%] [G loss: 0.383494]\n",
      "epoch:23 step:22167 [D loss: 0.219358, acc.: 60.94%] [G loss: 0.421938]\n",
      "epoch:23 step:22168 [D loss: 0.220971, acc.: 68.75%] [G loss: 0.452960]\n",
      "epoch:23 step:22169 [D loss: 0.239375, acc.: 55.47%] [G loss: 0.424086]\n",
      "epoch:23 step:22170 [D loss: 0.238109, acc.: 56.25%] [G loss: 0.404312]\n",
      "epoch:23 step:22171 [D loss: 0.183494, acc.: 70.31%] [G loss: 0.448486]\n",
      "epoch:23 step:22172 [D loss: 0.229849, acc.: 64.06%] [G loss: 0.424743]\n",
      "epoch:23 step:22173 [D loss: 0.240403, acc.: 58.59%] [G loss: 0.411432]\n",
      "epoch:23 step:22174 [D loss: 0.213014, acc.: 66.41%] [G loss: 0.455532]\n",
      "epoch:23 step:22175 [D loss: 0.202058, acc.: 64.84%] [G loss: 0.451593]\n",
      "epoch:23 step:22176 [D loss: 0.229481, acc.: 61.72%] [G loss: 0.444292]\n",
      "epoch:23 step:22177 [D loss: 0.239672, acc.: 61.72%] [G loss: 0.399668]\n",
      "epoch:23 step:22178 [D loss: 0.226680, acc.: 61.72%] [G loss: 0.417709]\n",
      "epoch:23 step:22179 [D loss: 0.220741, acc.: 61.72%] [G loss: 0.426469]\n",
      "epoch:23 step:22180 [D loss: 0.233284, acc.: 61.72%] [G loss: 0.429754]\n",
      "epoch:23 step:22181 [D loss: 0.236193, acc.: 59.38%] [G loss: 0.418845]\n",
      "epoch:23 step:22182 [D loss: 0.214710, acc.: 66.41%] [G loss: 0.412168]\n",
      "epoch:23 step:22183 [D loss: 0.208582, acc.: 65.62%] [G loss: 0.452203]\n",
      "epoch:23 step:22184 [D loss: 0.235330, acc.: 63.28%] [G loss: 0.406411]\n",
      "epoch:23 step:22185 [D loss: 0.199137, acc.: 65.62%] [G loss: 0.420675]\n",
      "epoch:23 step:22186 [D loss: 0.229245, acc.: 65.62%] [G loss: 0.458410]\n",
      "epoch:23 step:22187 [D loss: 0.216532, acc.: 62.50%] [G loss: 0.435936]\n",
      "epoch:23 step:22188 [D loss: 0.211700, acc.: 64.84%] [G loss: 0.444748]\n",
      "epoch:23 step:22189 [D loss: 0.234107, acc.: 58.59%] [G loss: 0.421810]\n",
      "epoch:23 step:22190 [D loss: 0.207835, acc.: 64.84%] [G loss: 0.470525]\n",
      "epoch:23 step:22191 [D loss: 0.223803, acc.: 68.75%] [G loss: 0.434395]\n",
      "epoch:23 step:22192 [D loss: 0.197003, acc.: 73.44%] [G loss: 0.490921]\n",
      "epoch:23 step:22193 [D loss: 0.196242, acc.: 66.41%] [G loss: 0.480633]\n",
      "epoch:23 step:22194 [D loss: 0.231297, acc.: 63.28%] [G loss: 0.483419]\n",
      "epoch:23 step:22195 [D loss: 0.258173, acc.: 54.69%] [G loss: 0.421444]\n",
      "epoch:23 step:22196 [D loss: 0.215287, acc.: 60.94%] [G loss: 0.411992]\n",
      "epoch:23 step:22197 [D loss: 0.224073, acc.: 58.59%] [G loss: 0.427464]\n",
      "epoch:23 step:22198 [D loss: 0.202556, acc.: 78.12%] [G loss: 0.445872]\n",
      "epoch:23 step:22199 [D loss: 0.212935, acc.: 69.53%] [G loss: 0.491349]\n",
      "epoch:23 step:22200 [D loss: 0.225426, acc.: 59.38%] [G loss: 0.496062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22201 [D loss: 0.214326, acc.: 63.28%] [G loss: 0.461690]\n",
      "epoch:23 step:22202 [D loss: 0.203753, acc.: 67.97%] [G loss: 0.499992]\n",
      "epoch:23 step:22203 [D loss: 0.219014, acc.: 67.19%] [G loss: 0.443962]\n",
      "epoch:23 step:22204 [D loss: 0.217180, acc.: 64.84%] [G loss: 0.419721]\n",
      "epoch:23 step:22205 [D loss: 0.196276, acc.: 72.66%] [G loss: 0.437891]\n",
      "epoch:23 step:22206 [D loss: 0.255454, acc.: 59.38%] [G loss: 0.434799]\n",
      "epoch:23 step:22207 [D loss: 0.239538, acc.: 59.38%] [G loss: 0.423430]\n",
      "epoch:23 step:22208 [D loss: 0.224540, acc.: 66.41%] [G loss: 0.423440]\n",
      "epoch:23 step:22209 [D loss: 0.232380, acc.: 57.81%] [G loss: 0.444250]\n",
      "epoch:23 step:22210 [D loss: 0.209862, acc.: 67.97%] [G loss: 0.411585]\n",
      "epoch:23 step:22211 [D loss: 0.205167, acc.: 71.09%] [G loss: 0.464261]\n",
      "epoch:23 step:22212 [D loss: 0.213960, acc.: 64.06%] [G loss: 0.447051]\n",
      "epoch:23 step:22213 [D loss: 0.222157, acc.: 62.50%] [G loss: 0.451033]\n",
      "epoch:23 step:22214 [D loss: 0.228676, acc.: 59.38%] [G loss: 0.433122]\n",
      "epoch:23 step:22215 [D loss: 0.236085, acc.: 60.16%] [G loss: 0.411148]\n",
      "epoch:23 step:22216 [D loss: 0.214658, acc.: 68.75%] [G loss: 0.431740]\n",
      "epoch:23 step:22217 [D loss: 0.219771, acc.: 65.62%] [G loss: 0.426595]\n",
      "epoch:23 step:22218 [D loss: 0.212519, acc.: 68.75%] [G loss: 0.449410]\n",
      "epoch:23 step:22219 [D loss: 0.218356, acc.: 65.62%] [G loss: 0.414708]\n",
      "epoch:23 step:22220 [D loss: 0.220507, acc.: 64.06%] [G loss: 0.455097]\n",
      "epoch:23 step:22221 [D loss: 0.235100, acc.: 61.72%] [G loss: 0.441040]\n",
      "epoch:23 step:22222 [D loss: 0.225832, acc.: 65.62%] [G loss: 0.438527]\n",
      "epoch:23 step:22223 [D loss: 0.226325, acc.: 60.16%] [G loss: 0.417158]\n",
      "epoch:23 step:22224 [D loss: 0.216610, acc.: 67.19%] [G loss: 0.403548]\n",
      "epoch:23 step:22225 [D loss: 0.221625, acc.: 64.84%] [G loss: 0.395768]\n",
      "epoch:23 step:22226 [D loss: 0.240378, acc.: 60.16%] [G loss: 0.403470]\n",
      "epoch:23 step:22227 [D loss: 0.216954, acc.: 69.53%] [G loss: 0.413632]\n",
      "epoch:23 step:22228 [D loss: 0.192719, acc.: 71.09%] [G loss: 0.401772]\n",
      "epoch:23 step:22229 [D loss: 0.225864, acc.: 61.72%] [G loss: 0.449212]\n",
      "epoch:23 step:22230 [D loss: 0.203771, acc.: 70.31%] [G loss: 0.425616]\n",
      "epoch:23 step:22231 [D loss: 0.213987, acc.: 67.19%] [G loss: 0.434958]\n",
      "epoch:23 step:22232 [D loss: 0.197112, acc.: 70.31%] [G loss: 0.427687]\n",
      "epoch:23 step:22233 [D loss: 0.226116, acc.: 62.50%] [G loss: 0.379906]\n",
      "epoch:23 step:22234 [D loss: 0.253391, acc.: 56.25%] [G loss: 0.398614]\n",
      "epoch:23 step:22235 [D loss: 0.244169, acc.: 58.59%] [G loss: 0.423663]\n",
      "epoch:23 step:22236 [D loss: 0.211937, acc.: 66.41%] [G loss: 0.440461]\n",
      "epoch:23 step:22237 [D loss: 0.218886, acc.: 64.06%] [G loss: 0.406230]\n",
      "epoch:23 step:22238 [D loss: 0.243232, acc.: 60.16%] [G loss: 0.408364]\n",
      "epoch:23 step:22239 [D loss: 0.211051, acc.: 67.19%] [G loss: 0.425273]\n",
      "epoch:23 step:22240 [D loss: 0.221801, acc.: 65.62%] [G loss: 0.416174]\n",
      "epoch:23 step:22241 [D loss: 0.187275, acc.: 75.00%] [G loss: 0.479672]\n",
      "epoch:23 step:22242 [D loss: 0.196545, acc.: 67.19%] [G loss: 0.478194]\n",
      "epoch:23 step:22243 [D loss: 0.203980, acc.: 72.66%] [G loss: 0.476904]\n",
      "epoch:23 step:22244 [D loss: 0.207390, acc.: 66.41%] [G loss: 0.437351]\n",
      "epoch:23 step:22245 [D loss: 0.167959, acc.: 75.78%] [G loss: 0.475791]\n",
      "epoch:23 step:22246 [D loss: 0.225290, acc.: 60.16%] [G loss: 0.462152]\n",
      "epoch:23 step:22247 [D loss: 0.258475, acc.: 51.56%] [G loss: 0.445133]\n",
      "epoch:23 step:22248 [D loss: 0.228735, acc.: 62.50%] [G loss: 0.417970]\n",
      "epoch:23 step:22249 [D loss: 0.248324, acc.: 54.69%] [G loss: 0.418857]\n",
      "epoch:23 step:22250 [D loss: 0.208225, acc.: 69.53%] [G loss: 0.442795]\n",
      "epoch:23 step:22251 [D loss: 0.216129, acc.: 67.19%] [G loss: 0.440923]\n",
      "epoch:23 step:22252 [D loss: 0.212149, acc.: 65.62%] [G loss: 0.467328]\n",
      "epoch:23 step:22253 [D loss: 0.253861, acc.: 57.81%] [G loss: 0.452731]\n",
      "epoch:23 step:22254 [D loss: 0.254928, acc.: 53.12%] [G loss: 0.469903]\n",
      "epoch:23 step:22255 [D loss: 0.219619, acc.: 61.72%] [G loss: 0.492845]\n",
      "epoch:23 step:22256 [D loss: 0.227293, acc.: 62.50%] [G loss: 0.423713]\n",
      "epoch:23 step:22257 [D loss: 0.202133, acc.: 75.00%] [G loss: 0.434142]\n",
      "epoch:23 step:22258 [D loss: 0.195521, acc.: 72.66%] [G loss: 0.397483]\n",
      "epoch:23 step:22259 [D loss: 0.207592, acc.: 72.66%] [G loss: 0.437236]\n",
      "epoch:23 step:22260 [D loss: 0.195935, acc.: 71.88%] [G loss: 0.462315]\n",
      "epoch:23 step:22261 [D loss: 0.248799, acc.: 57.81%] [G loss: 0.425755]\n",
      "epoch:23 step:22262 [D loss: 0.219308, acc.: 64.84%] [G loss: 0.420143]\n",
      "epoch:23 step:22263 [D loss: 0.220912, acc.: 62.50%] [G loss: 0.454679]\n",
      "epoch:23 step:22264 [D loss: 0.225556, acc.: 60.16%] [G loss: 0.472430]\n",
      "epoch:23 step:22265 [D loss: 0.229533, acc.: 59.38%] [G loss: 0.446872]\n",
      "epoch:23 step:22266 [D loss: 0.225560, acc.: 62.50%] [G loss: 0.472946]\n",
      "epoch:23 step:22267 [D loss: 0.245719, acc.: 58.59%] [G loss: 0.429097]\n",
      "epoch:23 step:22268 [D loss: 0.212419, acc.: 66.41%] [G loss: 0.471532]\n",
      "epoch:23 step:22269 [D loss: 0.232339, acc.: 62.50%] [G loss: 0.444435]\n",
      "epoch:23 step:22270 [D loss: 0.205053, acc.: 71.09%] [G loss: 0.451324]\n",
      "epoch:23 step:22271 [D loss: 0.218726, acc.: 64.06%] [G loss: 0.479472]\n",
      "epoch:23 step:22272 [D loss: 0.239140, acc.: 56.25%] [G loss: 0.430381]\n",
      "epoch:23 step:22273 [D loss: 0.238845, acc.: 57.03%] [G loss: 0.449309]\n",
      "epoch:23 step:22274 [D loss: 0.211777, acc.: 64.06%] [G loss: 0.465866]\n",
      "epoch:23 step:22275 [D loss: 0.207156, acc.: 63.28%] [G loss: 0.469664]\n",
      "epoch:23 step:22276 [D loss: 0.205167, acc.: 69.53%] [G loss: 0.468504]\n",
      "epoch:23 step:22277 [D loss: 0.234124, acc.: 63.28%] [G loss: 0.445938]\n",
      "epoch:23 step:22278 [D loss: 0.230090, acc.: 64.06%] [G loss: 0.409334]\n",
      "epoch:23 step:22279 [D loss: 0.221113, acc.: 64.06%] [G loss: 0.415815]\n",
      "epoch:23 step:22280 [D loss: 0.224520, acc.: 57.81%] [G loss: 0.409986]\n",
      "epoch:23 step:22281 [D loss: 0.207909, acc.: 71.09%] [G loss: 0.421957]\n",
      "epoch:23 step:22282 [D loss: 0.208539, acc.: 64.84%] [G loss: 0.415044]\n",
      "epoch:23 step:22283 [D loss: 0.212214, acc.: 64.84%] [G loss: 0.411248]\n",
      "epoch:23 step:22284 [D loss: 0.190630, acc.: 73.44%] [G loss: 0.428490]\n",
      "epoch:23 step:22285 [D loss: 0.249805, acc.: 56.25%] [G loss: 0.405643]\n",
      "epoch:23 step:22286 [D loss: 0.243978, acc.: 57.81%] [G loss: 0.402115]\n",
      "epoch:23 step:22287 [D loss: 0.219988, acc.: 65.62%] [G loss: 0.435078]\n",
      "epoch:23 step:22288 [D loss: 0.193536, acc.: 67.97%] [G loss: 0.413425]\n",
      "epoch:23 step:22289 [D loss: 0.248354, acc.: 55.47%] [G loss: 0.401927]\n",
      "epoch:23 step:22290 [D loss: 0.244802, acc.: 52.34%] [G loss: 0.381430]\n",
      "epoch:23 step:22291 [D loss: 0.221151, acc.: 64.84%] [G loss: 0.398251]\n",
      "epoch:23 step:22292 [D loss: 0.238292, acc.: 59.38%] [G loss: 0.443586]\n",
      "epoch:23 step:22293 [D loss: 0.226434, acc.: 60.94%] [G loss: 0.435449]\n",
      "epoch:23 step:22294 [D loss: 0.211834, acc.: 66.41%] [G loss: 0.428367]\n",
      "epoch:23 step:22295 [D loss: 0.261412, acc.: 54.69%] [G loss: 0.443863]\n",
      "epoch:23 step:22296 [D loss: 0.226929, acc.: 64.84%] [G loss: 0.460239]\n",
      "epoch:23 step:22297 [D loss: 0.230037, acc.: 63.28%] [G loss: 0.427416]\n",
      "epoch:23 step:22298 [D loss: 0.210778, acc.: 63.28%] [G loss: 0.444773]\n",
      "epoch:23 step:22299 [D loss: 0.259431, acc.: 59.38%] [G loss: 0.411425]\n",
      "epoch:23 step:22300 [D loss: 0.237069, acc.: 60.16%] [G loss: 0.382874]\n",
      "epoch:23 step:22301 [D loss: 0.226825, acc.: 60.16%] [G loss: 0.441921]\n",
      "epoch:23 step:22302 [D loss: 0.218987, acc.: 65.62%] [G loss: 0.440884]\n",
      "epoch:23 step:22303 [D loss: 0.224095, acc.: 64.06%] [G loss: 0.498878]\n",
      "epoch:23 step:22304 [D loss: 0.242099, acc.: 60.94%] [G loss: 0.460724]\n",
      "epoch:23 step:22305 [D loss: 0.212944, acc.: 64.84%] [G loss: 0.407364]\n",
      "epoch:23 step:22306 [D loss: 0.217794, acc.: 67.19%] [G loss: 0.449061]\n",
      "epoch:23 step:22307 [D loss: 0.228634, acc.: 60.16%] [G loss: 0.384990]\n",
      "epoch:23 step:22308 [D loss: 0.240639, acc.: 57.81%] [G loss: 0.402419]\n",
      "epoch:23 step:22309 [D loss: 0.247310, acc.: 57.81%] [G loss: 0.400997]\n",
      "epoch:23 step:22310 [D loss: 0.229325, acc.: 63.28%] [G loss: 0.395077]\n",
      "epoch:23 step:22311 [D loss: 0.231431, acc.: 61.72%] [G loss: 0.401434]\n",
      "epoch:23 step:22312 [D loss: 0.247817, acc.: 56.25%] [G loss: 0.390345]\n",
      "epoch:23 step:22313 [D loss: 0.253369, acc.: 52.34%] [G loss: 0.404804]\n",
      "epoch:23 step:22314 [D loss: 0.241714, acc.: 60.94%] [G loss: 0.390670]\n",
      "epoch:23 step:22315 [D loss: 0.222359, acc.: 60.16%] [G loss: 0.415036]\n",
      "epoch:23 step:22316 [D loss: 0.241767, acc.: 57.81%] [G loss: 0.426679]\n",
      "epoch:23 step:22317 [D loss: 0.246845, acc.: 52.34%] [G loss: 0.428093]\n",
      "epoch:23 step:22318 [D loss: 0.214382, acc.: 66.41%] [G loss: 0.449437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22319 [D loss: 0.238126, acc.: 67.19%] [G loss: 0.420929]\n",
      "epoch:23 step:22320 [D loss: 0.211345, acc.: 64.84%] [G loss: 0.449923]\n",
      "epoch:23 step:22321 [D loss: 0.237329, acc.: 63.28%] [G loss: 0.476583]\n",
      "epoch:23 step:22322 [D loss: 0.223103, acc.: 61.72%] [G loss: 0.440582]\n",
      "epoch:23 step:22323 [D loss: 0.238144, acc.: 53.12%] [G loss: 0.418578]\n",
      "epoch:23 step:22324 [D loss: 0.217091, acc.: 67.19%] [G loss: 0.405930]\n",
      "epoch:23 step:22325 [D loss: 0.243159, acc.: 57.03%] [G loss: 0.432599]\n",
      "epoch:23 step:22326 [D loss: 0.202499, acc.: 67.19%] [G loss: 0.449150]\n",
      "epoch:23 step:22327 [D loss: 0.232349, acc.: 63.28%] [G loss: 0.412038]\n",
      "epoch:23 step:22328 [D loss: 0.210986, acc.: 67.97%] [G loss: 0.428712]\n",
      "epoch:23 step:22329 [D loss: 0.232018, acc.: 60.94%] [G loss: 0.436724]\n",
      "epoch:23 step:22330 [D loss: 0.246989, acc.: 59.38%] [G loss: 0.426697]\n",
      "epoch:23 step:22331 [D loss: 0.221481, acc.: 66.41%] [G loss: 0.462918]\n",
      "epoch:23 step:22332 [D loss: 0.215443, acc.: 67.19%] [G loss: 0.480952]\n",
      "epoch:23 step:22333 [D loss: 0.187203, acc.: 72.66%] [G loss: 0.534530]\n",
      "epoch:23 step:22334 [D loss: 0.241860, acc.: 60.94%] [G loss: 0.447577]\n",
      "epoch:23 step:22335 [D loss: 0.222749, acc.: 64.84%] [G loss: 0.389263]\n",
      "epoch:23 step:22336 [D loss: 0.212945, acc.: 64.84%] [G loss: 0.392710]\n",
      "epoch:23 step:22337 [D loss: 0.193922, acc.: 73.44%] [G loss: 0.439433]\n",
      "epoch:23 step:22338 [D loss: 0.250629, acc.: 50.00%] [G loss: 0.400652]\n",
      "epoch:23 step:22339 [D loss: 0.259419, acc.: 50.00%] [G loss: 0.392322]\n",
      "epoch:23 step:22340 [D loss: 0.200678, acc.: 69.53%] [G loss: 0.436159]\n",
      "epoch:23 step:22341 [D loss: 0.218900, acc.: 64.06%] [G loss: 0.408818]\n",
      "epoch:23 step:22342 [D loss: 0.256350, acc.: 58.59%] [G loss: 0.408381]\n",
      "epoch:23 step:22343 [D loss: 0.201120, acc.: 70.31%] [G loss: 0.427442]\n",
      "epoch:23 step:22344 [D loss: 0.211343, acc.: 64.84%] [G loss: 0.456585]\n",
      "epoch:23 step:22345 [D loss: 0.272612, acc.: 50.78%] [G loss: 0.407356]\n",
      "epoch:23 step:22346 [D loss: 0.231407, acc.: 58.59%] [G loss: 0.481570]\n",
      "epoch:23 step:22347 [D loss: 0.229928, acc.: 57.81%] [G loss: 0.433790]\n",
      "epoch:23 step:22348 [D loss: 0.249892, acc.: 57.03%] [G loss: 0.409375]\n",
      "epoch:23 step:22349 [D loss: 0.218029, acc.: 63.28%] [G loss: 0.420666]\n",
      "epoch:23 step:22350 [D loss: 0.225237, acc.: 60.94%] [G loss: 0.432839]\n",
      "epoch:23 step:22351 [D loss: 0.260837, acc.: 55.47%] [G loss: 0.415733]\n",
      "epoch:23 step:22352 [D loss: 0.224421, acc.: 64.84%] [G loss: 0.415021]\n",
      "epoch:23 step:22353 [D loss: 0.205184, acc.: 65.62%] [G loss: 0.477708]\n",
      "epoch:23 step:22354 [D loss: 0.225923, acc.: 57.81%] [G loss: 0.466649]\n",
      "epoch:23 step:22355 [D loss: 0.232545, acc.: 59.38%] [G loss: 0.457509]\n",
      "epoch:23 step:22356 [D loss: 0.241157, acc.: 57.03%] [G loss: 0.388485]\n",
      "epoch:23 step:22357 [D loss: 0.230350, acc.: 61.72%] [G loss: 0.404465]\n",
      "epoch:23 step:22358 [D loss: 0.198425, acc.: 66.41%] [G loss: 0.444264]\n",
      "epoch:23 step:22359 [D loss: 0.235699, acc.: 55.47%] [G loss: 0.429085]\n",
      "epoch:23 step:22360 [D loss: 0.234318, acc.: 61.72%] [G loss: 0.399630]\n",
      "epoch:23 step:22361 [D loss: 0.215918, acc.: 64.84%] [G loss: 0.396348]\n",
      "epoch:23 step:22362 [D loss: 0.247297, acc.: 57.03%] [G loss: 0.415946]\n",
      "epoch:23 step:22363 [D loss: 0.232995, acc.: 61.72%] [G loss: 0.388004]\n",
      "epoch:23 step:22364 [D loss: 0.221625, acc.: 65.62%] [G loss: 0.420660]\n",
      "epoch:23 step:22365 [D loss: 0.229691, acc.: 64.84%] [G loss: 0.419903]\n",
      "epoch:23 step:22366 [D loss: 0.195029, acc.: 67.97%] [G loss: 0.488550]\n",
      "epoch:23 step:22367 [D loss: 0.216297, acc.: 61.72%] [G loss: 0.466495]\n",
      "epoch:23 step:22368 [D loss: 0.253169, acc.: 58.59%] [G loss: 0.445223]\n",
      "epoch:23 step:22369 [D loss: 0.245814, acc.: 57.03%] [G loss: 0.411841]\n",
      "epoch:23 step:22370 [D loss: 0.224843, acc.: 64.06%] [G loss: 0.410662]\n",
      "epoch:23 step:22371 [D loss: 0.258013, acc.: 53.91%] [G loss: 0.408697]\n",
      "epoch:23 step:22372 [D loss: 0.214551, acc.: 66.41%] [G loss: 0.451192]\n",
      "epoch:23 step:22373 [D loss: 0.217380, acc.: 66.41%] [G loss: 0.430244]\n",
      "epoch:23 step:22374 [D loss: 0.216459, acc.: 66.41%] [G loss: 0.428604]\n",
      "epoch:23 step:22375 [D loss: 0.245868, acc.: 59.38%] [G loss: 0.412971]\n",
      "epoch:23 step:22376 [D loss: 0.217980, acc.: 60.94%] [G loss: 0.453541]\n",
      "epoch:23 step:22377 [D loss: 0.211142, acc.: 60.94%] [G loss: 0.470699]\n",
      "epoch:23 step:22378 [D loss: 0.253095, acc.: 59.38%] [G loss: 0.430460]\n",
      "epoch:23 step:22379 [D loss: 0.239745, acc.: 58.59%] [G loss: 0.403756]\n",
      "epoch:23 step:22380 [D loss: 0.212108, acc.: 64.84%] [G loss: 0.427101]\n",
      "epoch:23 step:22381 [D loss: 0.245641, acc.: 60.16%] [G loss: 0.384280]\n",
      "epoch:23 step:22382 [D loss: 0.216502, acc.: 63.28%] [G loss: 0.431906]\n",
      "epoch:23 step:22383 [D loss: 0.220544, acc.: 61.72%] [G loss: 0.418147]\n",
      "epoch:23 step:22384 [D loss: 0.205613, acc.: 68.75%] [G loss: 0.425652]\n",
      "epoch:23 step:22385 [D loss: 0.237726, acc.: 60.16%] [G loss: 0.413501]\n",
      "epoch:23 step:22386 [D loss: 0.248417, acc.: 57.03%] [G loss: 0.382552]\n",
      "epoch:23 step:22387 [D loss: 0.219542, acc.: 66.41%] [G loss: 0.455252]\n",
      "epoch:23 step:22388 [D loss: 0.206079, acc.: 68.75%] [G loss: 0.438955]\n",
      "epoch:23 step:22389 [D loss: 0.209894, acc.: 67.19%] [G loss: 0.460347]\n",
      "epoch:23 step:22390 [D loss: 0.204558, acc.: 69.53%] [G loss: 0.442360]\n",
      "epoch:23 step:22391 [D loss: 0.229097, acc.: 61.72%] [G loss: 0.424411]\n",
      "epoch:23 step:22392 [D loss: 0.221922, acc.: 60.94%] [G loss: 0.430014]\n",
      "epoch:23 step:22393 [D loss: 0.187591, acc.: 74.22%] [G loss: 0.427203]\n",
      "epoch:23 step:22394 [D loss: 0.221103, acc.: 64.06%] [G loss: 0.413932]\n",
      "epoch:23 step:22395 [D loss: 0.231270, acc.: 60.94%] [G loss: 0.449169]\n",
      "epoch:23 step:22396 [D loss: 0.211231, acc.: 66.41%] [G loss: 0.445468]\n",
      "epoch:23 step:22397 [D loss: 0.234763, acc.: 56.25%] [G loss: 0.428359]\n",
      "epoch:23 step:22398 [D loss: 0.211619, acc.: 63.28%] [G loss: 0.419354]\n",
      "epoch:23 step:22399 [D loss: 0.244405, acc.: 56.25%] [G loss: 0.408677]\n",
      "epoch:23 step:22400 [D loss: 0.217893, acc.: 66.41%] [G loss: 0.406816]\n",
      "epoch:23 step:22401 [D loss: 0.233425, acc.: 57.81%] [G loss: 0.461843]\n",
      "epoch:23 step:22402 [D loss: 0.244637, acc.: 64.06%] [G loss: 0.414898]\n",
      "epoch:23 step:22403 [D loss: 0.216637, acc.: 67.97%] [G loss: 0.485458]\n",
      "epoch:23 step:22404 [D loss: 0.240272, acc.: 60.94%] [G loss: 0.480221]\n",
      "epoch:23 step:22405 [D loss: 0.221454, acc.: 61.72%] [G loss: 0.440779]\n",
      "epoch:23 step:22406 [D loss: 0.236121, acc.: 60.16%] [G loss: 0.438966]\n",
      "epoch:23 step:22407 [D loss: 0.218595, acc.: 64.06%] [G loss: 0.418980]\n",
      "epoch:23 step:22408 [D loss: 0.206067, acc.: 64.06%] [G loss: 0.418836]\n",
      "epoch:23 step:22409 [D loss: 0.242658, acc.: 57.81%] [G loss: 0.462676]\n",
      "epoch:23 step:22410 [D loss: 0.230259, acc.: 57.03%] [G loss: 0.456820]\n",
      "epoch:23 step:22411 [D loss: 0.195665, acc.: 74.22%] [G loss: 0.443831]\n",
      "epoch:23 step:22412 [D loss: 0.246434, acc.: 57.81%] [G loss: 0.442412]\n",
      "epoch:23 step:22413 [D loss: 0.249983, acc.: 57.03%] [G loss: 0.379077]\n",
      "epoch:23 step:22414 [D loss: 0.218520, acc.: 61.72%] [G loss: 0.411180]\n",
      "epoch:23 step:22415 [D loss: 0.232102, acc.: 58.59%] [G loss: 0.403633]\n",
      "epoch:23 step:22416 [D loss: 0.247248, acc.: 57.03%] [G loss: 0.417337]\n",
      "epoch:23 step:22417 [D loss: 0.230111, acc.: 53.91%] [G loss: 0.424129]\n",
      "epoch:23 step:22418 [D loss: 0.239548, acc.: 61.72%] [G loss: 0.404140]\n",
      "epoch:23 step:22419 [D loss: 0.231465, acc.: 56.25%] [G loss: 0.402848]\n",
      "epoch:23 step:22420 [D loss: 0.235811, acc.: 55.47%] [G loss: 0.400839]\n",
      "epoch:23 step:22421 [D loss: 0.213281, acc.: 66.41%] [G loss: 0.411082]\n",
      "epoch:23 step:22422 [D loss: 0.235606, acc.: 54.69%] [G loss: 0.460557]\n",
      "epoch:23 step:22423 [D loss: 0.226999, acc.: 57.81%] [G loss: 0.422074]\n",
      "epoch:23 step:22424 [D loss: 0.229108, acc.: 64.06%] [G loss: 0.412546]\n",
      "epoch:23 step:22425 [D loss: 0.219439, acc.: 60.16%] [G loss: 0.442830]\n",
      "epoch:23 step:22426 [D loss: 0.226112, acc.: 62.50%] [G loss: 0.416452]\n",
      "epoch:23 step:22427 [D loss: 0.230961, acc.: 58.59%] [G loss: 0.459866]\n",
      "epoch:23 step:22428 [D loss: 0.242142, acc.: 60.16%] [G loss: 0.401920]\n",
      "epoch:23 step:22429 [D loss: 0.229270, acc.: 64.06%] [G loss: 0.437024]\n",
      "epoch:23 step:22430 [D loss: 0.230369, acc.: 58.59%] [G loss: 0.429490]\n",
      "epoch:23 step:22431 [D loss: 0.243813, acc.: 53.91%] [G loss: 0.414444]\n",
      "epoch:23 step:22432 [D loss: 0.221094, acc.: 62.50%] [G loss: 0.402498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22433 [D loss: 0.228979, acc.: 62.50%] [G loss: 0.420917]\n",
      "epoch:23 step:22434 [D loss: 0.222513, acc.: 61.72%] [G loss: 0.423081]\n",
      "epoch:23 step:22435 [D loss: 0.213758, acc.: 67.97%] [G loss: 0.432074]\n",
      "epoch:23 step:22436 [D loss: 0.205209, acc.: 67.97%] [G loss: 0.484663]\n",
      "epoch:23 step:22437 [D loss: 0.196038, acc.: 67.97%] [G loss: 0.459459]\n",
      "epoch:23 step:22438 [D loss: 0.234676, acc.: 64.06%] [G loss: 0.463418]\n",
      "epoch:23 step:22439 [D loss: 0.257117, acc.: 50.78%] [G loss: 0.422418]\n",
      "epoch:23 step:22440 [D loss: 0.214852, acc.: 65.62%] [G loss: 0.456699]\n",
      "epoch:23 step:22441 [D loss: 0.189746, acc.: 75.00%] [G loss: 0.475820]\n",
      "epoch:23 step:22442 [D loss: 0.260665, acc.: 54.69%] [G loss: 0.434193]\n",
      "epoch:23 step:22443 [D loss: 0.261196, acc.: 55.47%] [G loss: 0.402156]\n",
      "epoch:23 step:22444 [D loss: 0.227488, acc.: 53.91%] [G loss: 0.437932]\n",
      "epoch:23 step:22445 [D loss: 0.203892, acc.: 67.97%] [G loss: 0.437117]\n",
      "epoch:23 step:22446 [D loss: 0.201425, acc.: 65.62%] [G loss: 0.448903]\n",
      "epoch:23 step:22447 [D loss: 0.222923, acc.: 65.62%] [G loss: 0.432826]\n",
      "epoch:23 step:22448 [D loss: 0.214160, acc.: 67.19%] [G loss: 0.428870]\n",
      "epoch:23 step:22449 [D loss: 0.196694, acc.: 68.75%] [G loss: 0.480215]\n",
      "epoch:23 step:22450 [D loss: 0.173167, acc.: 75.78%] [G loss: 0.501058]\n",
      "epoch:23 step:22451 [D loss: 0.221367, acc.: 64.06%] [G loss: 0.466351]\n",
      "epoch:23 step:22452 [D loss: 0.212653, acc.: 67.97%] [G loss: 0.430884]\n",
      "epoch:23 step:22453 [D loss: 0.211880, acc.: 69.53%] [G loss: 0.419450]\n",
      "epoch:23 step:22454 [D loss: 0.228484, acc.: 58.59%] [G loss: 0.426051]\n",
      "epoch:23 step:22455 [D loss: 0.228258, acc.: 64.06%] [G loss: 0.400934]\n",
      "epoch:23 step:22456 [D loss: 0.216883, acc.: 62.50%] [G loss: 0.458524]\n",
      "epoch:23 step:22457 [D loss: 0.223971, acc.: 63.28%] [G loss: 0.480484]\n",
      "epoch:23 step:22458 [D loss: 0.233072, acc.: 60.94%] [G loss: 0.439248]\n",
      "epoch:23 step:22459 [D loss: 0.230180, acc.: 61.72%] [G loss: 0.428368]\n",
      "epoch:23 step:22460 [D loss: 0.180890, acc.: 75.00%] [G loss: 0.445767]\n",
      "epoch:23 step:22461 [D loss: 0.242796, acc.: 62.50%] [G loss: 0.429051]\n",
      "epoch:23 step:22462 [D loss: 0.222777, acc.: 64.06%] [G loss: 0.425880]\n",
      "epoch:23 step:22463 [D loss: 0.200774, acc.: 67.19%] [G loss: 0.449466]\n",
      "epoch:23 step:22464 [D loss: 0.250930, acc.: 57.81%] [G loss: 0.484255]\n",
      "epoch:23 step:22465 [D loss: 0.226516, acc.: 60.94%] [G loss: 0.468437]\n",
      "epoch:23 step:22466 [D loss: 0.260238, acc.: 53.12%] [G loss: 0.426037]\n",
      "epoch:23 step:22467 [D loss: 0.230555, acc.: 62.50%] [G loss: 0.445317]\n",
      "epoch:23 step:22468 [D loss: 0.205755, acc.: 70.31%] [G loss: 0.478442]\n",
      "epoch:23 step:22469 [D loss: 0.186098, acc.: 78.12%] [G loss: 0.477946]\n",
      "epoch:23 step:22470 [D loss: 0.209806, acc.: 68.75%] [G loss: 0.505917]\n",
      "epoch:23 step:22471 [D loss: 0.310947, acc.: 42.19%] [G loss: 0.430552]\n",
      "epoch:23 step:22472 [D loss: 0.204651, acc.: 67.97%] [G loss: 0.457479]\n",
      "epoch:23 step:22473 [D loss: 0.247335, acc.: 53.91%] [G loss: 0.420223]\n",
      "epoch:23 step:22474 [D loss: 0.208389, acc.: 68.75%] [G loss: 0.460419]\n",
      "epoch:23 step:22475 [D loss: 0.184056, acc.: 73.44%] [G loss: 0.456008]\n",
      "epoch:23 step:22476 [D loss: 0.205694, acc.: 66.41%] [G loss: 0.453691]\n",
      "epoch:23 step:22477 [D loss: 0.199417, acc.: 65.62%] [G loss: 0.449348]\n",
      "epoch:23 step:22478 [D loss: 0.192882, acc.: 67.97%] [G loss: 0.554992]\n",
      "epoch:23 step:22479 [D loss: 0.321053, acc.: 46.88%] [G loss: 0.550523]\n",
      "epoch:23 step:22480 [D loss: 0.224222, acc.: 61.72%] [G loss: 0.583975]\n",
      "epoch:23 step:22481 [D loss: 0.244766, acc.: 66.41%] [G loss: 0.551301]\n",
      "epoch:23 step:22482 [D loss: 0.232913, acc.: 58.59%] [G loss: 0.443567]\n",
      "epoch:23 step:22483 [D loss: 0.276022, acc.: 50.78%] [G loss: 0.410518]\n",
      "epoch:23 step:22484 [D loss: 0.215517, acc.: 67.19%] [G loss: 0.456659]\n",
      "epoch:23 step:22485 [D loss: 0.235934, acc.: 65.62%] [G loss: 0.410151]\n",
      "epoch:23 step:22486 [D loss: 0.196460, acc.: 70.31%] [G loss: 0.501842]\n",
      "epoch:23 step:22487 [D loss: 0.173635, acc.: 77.34%] [G loss: 0.577961]\n",
      "epoch:23 step:22488 [D loss: 0.132352, acc.: 84.38%] [G loss: 0.621002]\n",
      "epoch:24 step:22489 [D loss: 0.248975, acc.: 60.16%] [G loss: 0.488981]\n",
      "epoch:24 step:22490 [D loss: 0.271355, acc.: 59.38%] [G loss: 0.413564]\n",
      "epoch:24 step:22491 [D loss: 0.242009, acc.: 55.47%] [G loss: 0.421801]\n",
      "epoch:24 step:22492 [D loss: 0.238262, acc.: 60.94%] [G loss: 0.448635]\n",
      "epoch:24 step:22493 [D loss: 0.214964, acc.: 64.84%] [G loss: 0.432307]\n",
      "epoch:24 step:22494 [D loss: 0.232221, acc.: 62.50%] [G loss: 0.432244]\n",
      "epoch:24 step:22495 [D loss: 0.222775, acc.: 59.38%] [G loss: 0.445156]\n",
      "epoch:24 step:22496 [D loss: 0.199387, acc.: 71.09%] [G loss: 0.461335]\n",
      "epoch:24 step:22497 [D loss: 0.208263, acc.: 67.97%] [G loss: 0.447153]\n",
      "epoch:24 step:22498 [D loss: 0.193931, acc.: 72.66%] [G loss: 0.507795]\n",
      "epoch:24 step:22499 [D loss: 0.199789, acc.: 67.97%] [G loss: 0.466007]\n",
      "epoch:24 step:22500 [D loss: 0.218245, acc.: 70.31%] [G loss: 0.460407]\n",
      "epoch:24 step:22501 [D loss: 0.232161, acc.: 60.16%] [G loss: 0.416928]\n",
      "epoch:24 step:22502 [D loss: 0.200096, acc.: 71.88%] [G loss: 0.454115]\n",
      "epoch:24 step:22503 [D loss: 0.196056, acc.: 73.44%] [G loss: 0.414744]\n",
      "epoch:24 step:22504 [D loss: 0.183624, acc.: 73.44%] [G loss: 0.489226]\n",
      "epoch:24 step:22505 [D loss: 0.239483, acc.: 61.72%] [G loss: 0.435419]\n",
      "epoch:24 step:22506 [D loss: 0.243937, acc.: 53.12%] [G loss: 0.424384]\n",
      "epoch:24 step:22507 [D loss: 0.244195, acc.: 59.38%] [G loss: 0.484769]\n",
      "epoch:24 step:22508 [D loss: 0.250990, acc.: 57.03%] [G loss: 0.507257]\n",
      "epoch:24 step:22509 [D loss: 0.228679, acc.: 61.72%] [G loss: 0.480073]\n",
      "epoch:24 step:22510 [D loss: 0.200766, acc.: 70.31%] [G loss: 0.523772]\n",
      "epoch:24 step:22511 [D loss: 0.264289, acc.: 53.91%] [G loss: 0.441108]\n",
      "epoch:24 step:22512 [D loss: 0.210487, acc.: 68.75%] [G loss: 0.438319]\n",
      "epoch:24 step:22513 [D loss: 0.211583, acc.: 65.62%] [G loss: 0.447404]\n",
      "epoch:24 step:22514 [D loss: 0.230698, acc.: 60.16%] [G loss: 0.413894]\n",
      "epoch:24 step:22515 [D loss: 0.208988, acc.: 67.97%] [G loss: 0.445369]\n",
      "epoch:24 step:22516 [D loss: 0.222597, acc.: 62.50%] [G loss: 0.433330]\n",
      "epoch:24 step:22517 [D loss: 0.218969, acc.: 65.62%] [G loss: 0.447241]\n",
      "epoch:24 step:22518 [D loss: 0.233868, acc.: 54.69%] [G loss: 0.424012]\n",
      "epoch:24 step:22519 [D loss: 0.251144, acc.: 55.47%] [G loss: 0.424164]\n",
      "epoch:24 step:22520 [D loss: 0.246975, acc.: 58.59%] [G loss: 0.435293]\n",
      "epoch:24 step:22521 [D loss: 0.219339, acc.: 63.28%] [G loss: 0.449333]\n",
      "epoch:24 step:22522 [D loss: 0.230255, acc.: 60.94%] [G loss: 0.391018]\n",
      "epoch:24 step:22523 [D loss: 0.237496, acc.: 61.72%] [G loss: 0.378913]\n",
      "epoch:24 step:22524 [D loss: 0.199754, acc.: 70.31%] [G loss: 0.424485]\n",
      "epoch:24 step:22525 [D loss: 0.229607, acc.: 62.50%] [G loss: 0.422264]\n",
      "epoch:24 step:22526 [D loss: 0.266425, acc.: 53.12%] [G loss: 0.406116]\n",
      "epoch:24 step:22527 [D loss: 0.216491, acc.: 64.06%] [G loss: 0.431134]\n",
      "epoch:24 step:22528 [D loss: 0.206358, acc.: 67.97%] [G loss: 0.459200]\n",
      "epoch:24 step:22529 [D loss: 0.245217, acc.: 60.16%] [G loss: 0.420777]\n",
      "epoch:24 step:22530 [D loss: 0.232186, acc.: 62.50%] [G loss: 0.434555]\n",
      "epoch:24 step:22531 [D loss: 0.228855, acc.: 60.94%] [G loss: 0.423726]\n",
      "epoch:24 step:22532 [D loss: 0.239852, acc.: 57.81%] [G loss: 0.471749]\n",
      "epoch:24 step:22533 [D loss: 0.222645, acc.: 64.06%] [G loss: 0.447811]\n",
      "epoch:24 step:22534 [D loss: 0.220382, acc.: 61.72%] [G loss: 0.438895]\n",
      "epoch:24 step:22535 [D loss: 0.229766, acc.: 58.59%] [G loss: 0.442445]\n",
      "epoch:24 step:22536 [D loss: 0.214298, acc.: 68.75%] [G loss: 0.422950]\n",
      "epoch:24 step:22537 [D loss: 0.176175, acc.: 76.56%] [G loss: 0.465014]\n",
      "epoch:24 step:22538 [D loss: 0.209734, acc.: 67.19%] [G loss: 0.404687]\n",
      "epoch:24 step:22539 [D loss: 0.253131, acc.: 50.78%] [G loss: 0.433695]\n",
      "epoch:24 step:22540 [D loss: 0.214566, acc.: 64.06%] [G loss: 0.436777]\n",
      "epoch:24 step:22541 [D loss: 0.204379, acc.: 69.53%] [G loss: 0.462363]\n",
      "epoch:24 step:22542 [D loss: 0.200999, acc.: 68.75%] [G loss: 0.468061]\n",
      "epoch:24 step:22543 [D loss: 0.220032, acc.: 64.84%] [G loss: 0.503000]\n",
      "epoch:24 step:22544 [D loss: 0.213816, acc.: 60.16%] [G loss: 0.396579]\n",
      "epoch:24 step:22545 [D loss: 0.251609, acc.: 56.25%] [G loss: 0.434052]\n",
      "epoch:24 step:22546 [D loss: 0.231490, acc.: 57.03%] [G loss: 0.419503]\n",
      "epoch:24 step:22547 [D loss: 0.199528, acc.: 71.09%] [G loss: 0.469433]\n",
      "epoch:24 step:22548 [D loss: 0.234659, acc.: 61.72%] [G loss: 0.428702]\n",
      "epoch:24 step:22549 [D loss: 0.240414, acc.: 57.81%] [G loss: 0.403277]\n",
      "epoch:24 step:22550 [D loss: 0.227136, acc.: 65.62%] [G loss: 0.429703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22551 [D loss: 0.210596, acc.: 66.41%] [G loss: 0.433978]\n",
      "epoch:24 step:22552 [D loss: 0.238450, acc.: 60.94%] [G loss: 0.452178]\n",
      "epoch:24 step:22553 [D loss: 0.224296, acc.: 64.06%] [G loss: 0.422959]\n",
      "epoch:24 step:22554 [D loss: 0.257589, acc.: 62.50%] [G loss: 0.411502]\n",
      "epoch:24 step:22555 [D loss: 0.215883, acc.: 63.28%] [G loss: 0.398692]\n",
      "epoch:24 step:22556 [D loss: 0.214631, acc.: 69.53%] [G loss: 0.450534]\n",
      "epoch:24 step:22557 [D loss: 0.183165, acc.: 76.56%] [G loss: 0.441237]\n",
      "epoch:24 step:22558 [D loss: 0.202141, acc.: 69.53%] [G loss: 0.432575]\n",
      "epoch:24 step:22559 [D loss: 0.250152, acc.: 58.59%] [G loss: 0.412580]\n",
      "epoch:24 step:22560 [D loss: 0.235660, acc.: 62.50%] [G loss: 0.410767]\n",
      "epoch:24 step:22561 [D loss: 0.226814, acc.: 66.41%] [G loss: 0.433125]\n",
      "epoch:24 step:22562 [D loss: 0.201676, acc.: 66.41%] [G loss: 0.381001]\n",
      "epoch:24 step:22563 [D loss: 0.232957, acc.: 57.81%] [G loss: 0.452345]\n",
      "epoch:24 step:22564 [D loss: 0.211905, acc.: 67.19%] [G loss: 0.444326]\n",
      "epoch:24 step:22565 [D loss: 0.192070, acc.: 69.53%] [G loss: 0.491755]\n",
      "epoch:24 step:22566 [D loss: 0.248117, acc.: 56.25%] [G loss: 0.433120]\n",
      "epoch:24 step:22567 [D loss: 0.237355, acc.: 58.59%] [G loss: 0.371031]\n",
      "epoch:24 step:22568 [D loss: 0.227888, acc.: 64.84%] [G loss: 0.369801]\n",
      "epoch:24 step:22569 [D loss: 0.253705, acc.: 56.25%] [G loss: 0.407291]\n",
      "epoch:24 step:22570 [D loss: 0.208486, acc.: 67.97%] [G loss: 0.441700]\n",
      "epoch:24 step:22571 [D loss: 0.216301, acc.: 66.41%] [G loss: 0.441998]\n",
      "epoch:24 step:22572 [D loss: 0.209796, acc.: 64.84%] [G loss: 0.474260]\n",
      "epoch:24 step:22573 [D loss: 0.242354, acc.: 59.38%] [G loss: 0.444275]\n",
      "epoch:24 step:22574 [D loss: 0.226448, acc.: 64.84%] [G loss: 0.439317]\n",
      "epoch:24 step:22575 [D loss: 0.222728, acc.: 64.84%] [G loss: 0.418998]\n",
      "epoch:24 step:22576 [D loss: 0.189814, acc.: 73.44%] [G loss: 0.448417]\n",
      "epoch:24 step:22577 [D loss: 0.243097, acc.: 60.16%] [G loss: 0.410680]\n",
      "epoch:24 step:22578 [D loss: 0.221230, acc.: 60.94%] [G loss: 0.452046]\n",
      "epoch:24 step:22579 [D loss: 0.219498, acc.: 60.94%] [G loss: 0.486832]\n",
      "epoch:24 step:22580 [D loss: 0.228327, acc.: 63.28%] [G loss: 0.436275]\n",
      "epoch:24 step:22581 [D loss: 0.212536, acc.: 66.41%] [G loss: 0.459575]\n",
      "epoch:24 step:22582 [D loss: 0.227520, acc.: 64.06%] [G loss: 0.476381]\n",
      "epoch:24 step:22583 [D loss: 0.220472, acc.: 65.62%] [G loss: 0.463775]\n",
      "epoch:24 step:22584 [D loss: 0.197632, acc.: 73.44%] [G loss: 0.429732]\n",
      "epoch:24 step:22585 [D loss: 0.203974, acc.: 66.41%] [G loss: 0.469622]\n",
      "epoch:24 step:22586 [D loss: 0.234591, acc.: 63.28%] [G loss: 0.480136]\n",
      "epoch:24 step:22587 [D loss: 0.222333, acc.: 61.72%] [G loss: 0.402184]\n",
      "epoch:24 step:22588 [D loss: 0.192353, acc.: 75.78%] [G loss: 0.468649]\n",
      "epoch:24 step:22589 [D loss: 0.233835, acc.: 62.50%] [G loss: 0.430677]\n",
      "epoch:24 step:22590 [D loss: 0.245495, acc.: 57.81%] [G loss: 0.457391]\n",
      "epoch:24 step:22591 [D loss: 0.244396, acc.: 57.03%] [G loss: 0.468314]\n",
      "epoch:24 step:22592 [D loss: 0.233460, acc.: 56.25%] [G loss: 0.435625]\n",
      "epoch:24 step:22593 [D loss: 0.229070, acc.: 58.59%] [G loss: 0.395915]\n",
      "epoch:24 step:22594 [D loss: 0.192457, acc.: 71.88%] [G loss: 0.408171]\n",
      "epoch:24 step:22595 [D loss: 0.210013, acc.: 68.75%] [G loss: 0.438029]\n",
      "epoch:24 step:22596 [D loss: 0.251798, acc.: 57.81%] [G loss: 0.485282]\n",
      "epoch:24 step:22597 [D loss: 0.262887, acc.: 53.91%] [G loss: 0.445408]\n",
      "epoch:24 step:22598 [D loss: 0.248163, acc.: 58.59%] [G loss: 0.395946]\n",
      "epoch:24 step:22599 [D loss: 0.229537, acc.: 60.94%] [G loss: 0.390954]\n",
      "epoch:24 step:22600 [D loss: 0.201112, acc.: 65.62%] [G loss: 0.376609]\n",
      "epoch:24 step:22601 [D loss: 0.214696, acc.: 63.28%] [G loss: 0.424288]\n",
      "epoch:24 step:22602 [D loss: 0.206502, acc.: 67.19%] [G loss: 0.450656]\n",
      "epoch:24 step:22603 [D loss: 0.209867, acc.: 71.09%] [G loss: 0.439936]\n",
      "epoch:24 step:22604 [D loss: 0.206471, acc.: 67.19%] [G loss: 0.458054]\n",
      "epoch:24 step:22605 [D loss: 0.206496, acc.: 65.62%] [G loss: 0.470625]\n",
      "epoch:24 step:22606 [D loss: 0.198223, acc.: 73.44%] [G loss: 0.474368]\n",
      "epoch:24 step:22607 [D loss: 0.179019, acc.: 69.53%] [G loss: 0.485313]\n",
      "epoch:24 step:22608 [D loss: 0.249168, acc.: 57.03%] [G loss: 0.457925]\n",
      "epoch:24 step:22609 [D loss: 0.246284, acc.: 59.38%] [G loss: 0.467948]\n",
      "epoch:24 step:22610 [D loss: 0.171719, acc.: 75.78%] [G loss: 0.487308]\n",
      "epoch:24 step:22611 [D loss: 0.206724, acc.: 68.75%] [G loss: 0.447822]\n",
      "epoch:24 step:22612 [D loss: 0.252644, acc.: 58.59%] [G loss: 0.450508]\n",
      "epoch:24 step:22613 [D loss: 0.241867, acc.: 52.34%] [G loss: 0.421655]\n",
      "epoch:24 step:22614 [D loss: 0.200461, acc.: 67.97%] [G loss: 0.440738]\n",
      "epoch:24 step:22615 [D loss: 0.199030, acc.: 70.31%] [G loss: 0.448665]\n",
      "epoch:24 step:22616 [D loss: 0.240763, acc.: 54.69%] [G loss: 0.426458]\n",
      "epoch:24 step:22617 [D loss: 0.223363, acc.: 64.06%] [G loss: 0.396999]\n",
      "epoch:24 step:22618 [D loss: 0.211131, acc.: 69.53%] [G loss: 0.452812]\n",
      "epoch:24 step:22619 [D loss: 0.215506, acc.: 70.31%] [G loss: 0.425525]\n",
      "epoch:24 step:22620 [D loss: 0.220360, acc.: 62.50%] [G loss: 0.448873]\n",
      "epoch:24 step:22621 [D loss: 0.250936, acc.: 57.03%] [G loss: 0.443692]\n",
      "epoch:24 step:22622 [D loss: 0.243462, acc.: 56.25%] [G loss: 0.451515]\n",
      "epoch:24 step:22623 [D loss: 0.197350, acc.: 71.09%] [G loss: 0.481431]\n",
      "epoch:24 step:22624 [D loss: 0.216800, acc.: 68.75%] [G loss: 0.450224]\n",
      "epoch:24 step:22625 [D loss: 0.243489, acc.: 57.03%] [G loss: 0.401344]\n",
      "epoch:24 step:22626 [D loss: 0.256016, acc.: 56.25%] [G loss: 0.402146]\n",
      "epoch:24 step:22627 [D loss: 0.237824, acc.: 57.81%] [G loss: 0.404939]\n",
      "epoch:24 step:22628 [D loss: 0.246044, acc.: 56.25%] [G loss: 0.424717]\n",
      "epoch:24 step:22629 [D loss: 0.252042, acc.: 50.78%] [G loss: 0.409436]\n",
      "epoch:24 step:22630 [D loss: 0.235968, acc.: 60.94%] [G loss: 0.420032]\n",
      "epoch:24 step:22631 [D loss: 0.238843, acc.: 59.38%] [G loss: 0.419092]\n",
      "epoch:24 step:22632 [D loss: 0.245042, acc.: 60.16%] [G loss: 0.408651]\n",
      "epoch:24 step:22633 [D loss: 0.248073, acc.: 60.16%] [G loss: 0.393487]\n",
      "epoch:24 step:22634 [D loss: 0.207690, acc.: 67.19%] [G loss: 0.478882]\n",
      "epoch:24 step:22635 [D loss: 0.232787, acc.: 60.94%] [G loss: 0.451457]\n",
      "epoch:24 step:22636 [D loss: 0.246154, acc.: 54.69%] [G loss: 0.430540]\n",
      "epoch:24 step:22637 [D loss: 0.223424, acc.: 61.72%] [G loss: 0.419146]\n",
      "epoch:24 step:22638 [D loss: 0.231762, acc.: 60.16%] [G loss: 0.413573]\n",
      "epoch:24 step:22639 [D loss: 0.210803, acc.: 67.97%] [G loss: 0.400478]\n",
      "epoch:24 step:22640 [D loss: 0.236191, acc.: 57.81%] [G loss: 0.426721]\n",
      "epoch:24 step:22641 [D loss: 0.217084, acc.: 64.06%] [G loss: 0.443258]\n",
      "epoch:24 step:22642 [D loss: 0.210587, acc.: 65.62%] [G loss: 0.420210]\n",
      "epoch:24 step:22643 [D loss: 0.215812, acc.: 63.28%] [G loss: 0.433151]\n",
      "epoch:24 step:22644 [D loss: 0.202374, acc.: 70.31%] [G loss: 0.445371]\n",
      "epoch:24 step:22645 [D loss: 0.244512, acc.: 59.38%] [G loss: 0.440269]\n",
      "epoch:24 step:22646 [D loss: 0.221860, acc.: 61.72%] [G loss: 0.442413]\n",
      "epoch:24 step:22647 [D loss: 0.217761, acc.: 60.16%] [G loss: 0.397311]\n",
      "epoch:24 step:22648 [D loss: 0.268497, acc.: 51.56%] [G loss: 0.422449]\n",
      "epoch:24 step:22649 [D loss: 0.225631, acc.: 57.81%] [G loss: 0.455007]\n",
      "epoch:24 step:22650 [D loss: 0.237823, acc.: 59.38%] [G loss: 0.413162]\n",
      "epoch:24 step:22651 [D loss: 0.229746, acc.: 62.50%] [G loss: 0.409754]\n",
      "epoch:24 step:22652 [D loss: 0.208137, acc.: 72.66%] [G loss: 0.417978]\n",
      "epoch:24 step:22653 [D loss: 0.228937, acc.: 61.72%] [G loss: 0.401755]\n",
      "epoch:24 step:22654 [D loss: 0.209129, acc.: 71.09%] [G loss: 0.430814]\n",
      "epoch:24 step:22655 [D loss: 0.231815, acc.: 61.72%] [G loss: 0.406790]\n",
      "epoch:24 step:22656 [D loss: 0.210005, acc.: 67.19%] [G loss: 0.398786]\n",
      "epoch:24 step:22657 [D loss: 0.233588, acc.: 57.03%] [G loss: 0.406272]\n",
      "epoch:24 step:22658 [D loss: 0.220597, acc.: 67.19%] [G loss: 0.389778]\n",
      "epoch:24 step:22659 [D loss: 0.234982, acc.: 57.81%] [G loss: 0.377173]\n",
      "epoch:24 step:22660 [D loss: 0.208286, acc.: 65.62%] [G loss: 0.433358]\n",
      "epoch:24 step:22661 [D loss: 0.242177, acc.: 60.94%] [G loss: 0.406174]\n",
      "epoch:24 step:22662 [D loss: 0.240741, acc.: 55.47%] [G loss: 0.413121]\n",
      "epoch:24 step:22663 [D loss: 0.231369, acc.: 55.47%] [G loss: 0.447231]\n",
      "epoch:24 step:22664 [D loss: 0.252928, acc.: 53.91%] [G loss: 0.407245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22665 [D loss: 0.237359, acc.: 54.69%] [G loss: 0.415053]\n",
      "epoch:24 step:22666 [D loss: 0.232546, acc.: 57.81%] [G loss: 0.401769]\n",
      "epoch:24 step:22667 [D loss: 0.238338, acc.: 66.41%] [G loss: 0.408506]\n",
      "epoch:24 step:22668 [D loss: 0.221904, acc.: 65.62%] [G loss: 0.420681]\n",
      "epoch:24 step:22669 [D loss: 0.223829, acc.: 62.50%] [G loss: 0.444595]\n",
      "epoch:24 step:22670 [D loss: 0.249932, acc.: 54.69%] [G loss: 0.438807]\n",
      "epoch:24 step:22671 [D loss: 0.218662, acc.: 67.19%] [G loss: 0.446039]\n",
      "epoch:24 step:22672 [D loss: 0.230680, acc.: 61.72%] [G loss: 0.426831]\n",
      "epoch:24 step:22673 [D loss: 0.235405, acc.: 59.38%] [G loss: 0.428817]\n",
      "epoch:24 step:22674 [D loss: 0.224925, acc.: 64.06%] [G loss: 0.410854]\n",
      "epoch:24 step:22675 [D loss: 0.230185, acc.: 61.72%] [G loss: 0.427681]\n",
      "epoch:24 step:22676 [D loss: 0.231968, acc.: 60.94%] [G loss: 0.441652]\n",
      "epoch:24 step:22677 [D loss: 0.236369, acc.: 55.47%] [G loss: 0.413309]\n",
      "epoch:24 step:22678 [D loss: 0.219903, acc.: 64.84%] [G loss: 0.396335]\n",
      "epoch:24 step:22679 [D loss: 0.205941, acc.: 67.19%] [G loss: 0.447906]\n",
      "epoch:24 step:22680 [D loss: 0.200129, acc.: 69.53%] [G loss: 0.410607]\n",
      "epoch:24 step:22681 [D loss: 0.219444, acc.: 65.62%] [G loss: 0.437057]\n",
      "epoch:24 step:22682 [D loss: 0.205115, acc.: 64.84%] [G loss: 0.486061]\n",
      "epoch:24 step:22683 [D loss: 0.218604, acc.: 64.06%] [G loss: 0.438399]\n",
      "epoch:24 step:22684 [D loss: 0.243176, acc.: 59.38%] [G loss: 0.392881]\n",
      "epoch:24 step:22685 [D loss: 0.211136, acc.: 62.50%] [G loss: 0.397845]\n",
      "epoch:24 step:22686 [D loss: 0.203649, acc.: 64.84%] [G loss: 0.441307]\n",
      "epoch:24 step:22687 [D loss: 0.210989, acc.: 72.66%] [G loss: 0.450574]\n",
      "epoch:24 step:22688 [D loss: 0.252225, acc.: 56.25%] [G loss: 0.416554]\n",
      "epoch:24 step:22689 [D loss: 0.224207, acc.: 64.84%] [G loss: 0.447738]\n",
      "epoch:24 step:22690 [D loss: 0.207920, acc.: 64.84%] [G loss: 0.425781]\n",
      "epoch:24 step:22691 [D loss: 0.246601, acc.: 55.47%] [G loss: 0.444046]\n",
      "epoch:24 step:22692 [D loss: 0.236597, acc.: 62.50%] [G loss: 0.434732]\n",
      "epoch:24 step:22693 [D loss: 0.221834, acc.: 64.06%] [G loss: 0.492893]\n",
      "epoch:24 step:22694 [D loss: 0.232595, acc.: 63.28%] [G loss: 0.480950]\n",
      "epoch:24 step:22695 [D loss: 0.230404, acc.: 60.16%] [G loss: 0.393762]\n",
      "epoch:24 step:22696 [D loss: 0.203336, acc.: 64.84%] [G loss: 0.443263]\n",
      "epoch:24 step:22697 [D loss: 0.196143, acc.: 65.62%] [G loss: 0.515511]\n",
      "epoch:24 step:22698 [D loss: 0.265755, acc.: 57.81%] [G loss: 0.445622]\n",
      "epoch:24 step:22699 [D loss: 0.228157, acc.: 60.94%] [G loss: 0.417479]\n",
      "epoch:24 step:22700 [D loss: 0.242577, acc.: 58.59%] [G loss: 0.424601]\n",
      "epoch:24 step:22701 [D loss: 0.218848, acc.: 64.84%] [G loss: 0.371396]\n",
      "epoch:24 step:22702 [D loss: 0.269393, acc.: 52.34%] [G loss: 0.391335]\n",
      "epoch:24 step:22703 [D loss: 0.246756, acc.: 54.69%] [G loss: 0.390901]\n",
      "epoch:24 step:22704 [D loss: 0.212574, acc.: 60.16%] [G loss: 0.478604]\n",
      "epoch:24 step:22705 [D loss: 0.203250, acc.: 64.06%] [G loss: 0.465747]\n",
      "epoch:24 step:22706 [D loss: 0.209077, acc.: 60.16%] [G loss: 0.446604]\n",
      "epoch:24 step:22707 [D loss: 0.175629, acc.: 75.78%] [G loss: 0.455076]\n",
      "epoch:24 step:22708 [D loss: 0.281517, acc.: 53.12%] [G loss: 0.473215]\n",
      "epoch:24 step:22709 [D loss: 0.218579, acc.: 67.97%] [G loss: 0.440286]\n",
      "epoch:24 step:22710 [D loss: 0.213496, acc.: 71.88%] [G loss: 0.446555]\n",
      "epoch:24 step:22711 [D loss: 0.211862, acc.: 64.84%] [G loss: 0.443595]\n",
      "epoch:24 step:22712 [D loss: 0.249413, acc.: 58.59%] [G loss: 0.405049]\n",
      "epoch:24 step:22713 [D loss: 0.229611, acc.: 59.38%] [G loss: 0.413157]\n",
      "epoch:24 step:22714 [D loss: 0.247352, acc.: 56.25%] [G loss: 0.380778]\n",
      "epoch:24 step:22715 [D loss: 0.225399, acc.: 64.84%] [G loss: 0.401547]\n",
      "epoch:24 step:22716 [D loss: 0.240453, acc.: 60.16%] [G loss: 0.409324]\n",
      "epoch:24 step:22717 [D loss: 0.202673, acc.: 64.84%] [G loss: 0.445866]\n",
      "epoch:24 step:22718 [D loss: 0.196119, acc.: 71.09%] [G loss: 0.471936]\n",
      "epoch:24 step:22719 [D loss: 0.165051, acc.: 74.22%] [G loss: 0.524721]\n",
      "epoch:24 step:22720 [D loss: 0.156913, acc.: 78.12%] [G loss: 0.505956]\n",
      "epoch:24 step:22721 [D loss: 0.239984, acc.: 62.50%] [G loss: 0.444067]\n",
      "epoch:24 step:22722 [D loss: 0.234497, acc.: 62.50%] [G loss: 0.408402]\n",
      "epoch:24 step:22723 [D loss: 0.228221, acc.: 61.72%] [G loss: 0.402560]\n",
      "epoch:24 step:22724 [D loss: 0.239031, acc.: 56.25%] [G loss: 0.424127]\n",
      "epoch:24 step:22725 [D loss: 0.217963, acc.: 65.62%] [G loss: 0.445258]\n",
      "epoch:24 step:22726 [D loss: 0.213905, acc.: 64.84%] [G loss: 0.446180]\n",
      "epoch:24 step:22727 [D loss: 0.194902, acc.: 71.09%] [G loss: 0.462833]\n",
      "epoch:24 step:22728 [D loss: 0.228760, acc.: 63.28%] [G loss: 0.433125]\n",
      "epoch:24 step:22729 [D loss: 0.197339, acc.: 70.31%] [G loss: 0.474337]\n",
      "epoch:24 step:22730 [D loss: 0.204194, acc.: 66.41%] [G loss: 0.418237]\n",
      "epoch:24 step:22731 [D loss: 0.215025, acc.: 67.97%] [G loss: 0.427356]\n",
      "epoch:24 step:22732 [D loss: 0.222709, acc.: 67.97%] [G loss: 0.432221]\n",
      "epoch:24 step:22733 [D loss: 0.209380, acc.: 71.09%] [G loss: 0.431825]\n",
      "epoch:24 step:22734 [D loss: 0.250575, acc.: 59.38%] [G loss: 0.435877]\n",
      "epoch:24 step:22735 [D loss: 0.212067, acc.: 67.19%] [G loss: 0.444791]\n",
      "epoch:24 step:22736 [D loss: 0.189917, acc.: 73.44%] [G loss: 0.474040]\n",
      "epoch:24 step:22737 [D loss: 0.281034, acc.: 46.09%] [G loss: 0.428663]\n",
      "epoch:24 step:22738 [D loss: 0.258733, acc.: 55.47%] [G loss: 0.402520]\n",
      "epoch:24 step:22739 [D loss: 0.244714, acc.: 64.06%] [G loss: 0.465473]\n",
      "epoch:24 step:22740 [D loss: 0.219197, acc.: 65.62%] [G loss: 0.448695]\n",
      "epoch:24 step:22741 [D loss: 0.238542, acc.: 61.72%] [G loss: 0.466810]\n",
      "epoch:24 step:22742 [D loss: 0.233509, acc.: 59.38%] [G loss: 0.410015]\n",
      "epoch:24 step:22743 [D loss: 0.195760, acc.: 71.09%] [G loss: 0.448074]\n",
      "epoch:24 step:22744 [D loss: 0.200448, acc.: 70.31%] [G loss: 0.439016]\n",
      "epoch:24 step:22745 [D loss: 0.209956, acc.: 69.53%] [G loss: 0.415813]\n",
      "epoch:24 step:22746 [D loss: 0.216040, acc.: 66.41%] [G loss: 0.440396]\n",
      "epoch:24 step:22747 [D loss: 0.219053, acc.: 60.94%] [G loss: 0.452741]\n",
      "epoch:24 step:22748 [D loss: 0.222414, acc.: 57.81%] [G loss: 0.421959]\n",
      "epoch:24 step:22749 [D loss: 0.231715, acc.: 61.72%] [G loss: 0.408188]\n",
      "epoch:24 step:22750 [D loss: 0.222319, acc.: 60.94%] [G loss: 0.427961]\n",
      "epoch:24 step:22751 [D loss: 0.240921, acc.: 54.69%] [G loss: 0.428546]\n",
      "epoch:24 step:22752 [D loss: 0.192085, acc.: 68.75%] [G loss: 0.427579]\n",
      "epoch:24 step:22753 [D loss: 0.270904, acc.: 53.91%] [G loss: 0.419326]\n",
      "epoch:24 step:22754 [D loss: 0.219331, acc.: 62.50%] [G loss: 0.422068]\n",
      "epoch:24 step:22755 [D loss: 0.232854, acc.: 64.06%] [G loss: 0.421308]\n",
      "epoch:24 step:22756 [D loss: 0.212920, acc.: 67.19%] [G loss: 0.447861]\n",
      "epoch:24 step:22757 [D loss: 0.223056, acc.: 64.84%] [G loss: 0.425101]\n",
      "epoch:24 step:22758 [D loss: 0.228422, acc.: 61.72%] [G loss: 0.412155]\n",
      "epoch:24 step:22759 [D loss: 0.190894, acc.: 71.88%] [G loss: 0.447317]\n",
      "epoch:24 step:22760 [D loss: 0.206196, acc.: 64.84%] [G loss: 0.432546]\n",
      "epoch:24 step:22761 [D loss: 0.207682, acc.: 67.19%] [G loss: 0.425473]\n",
      "epoch:24 step:22762 [D loss: 0.205768, acc.: 64.06%] [G loss: 0.475851]\n",
      "epoch:24 step:22763 [D loss: 0.237123, acc.: 60.16%] [G loss: 0.459251]\n",
      "epoch:24 step:22764 [D loss: 0.211912, acc.: 67.97%] [G loss: 0.415168]\n",
      "epoch:24 step:22765 [D loss: 0.228952, acc.: 59.38%] [G loss: 0.445074]\n",
      "epoch:24 step:22766 [D loss: 0.248928, acc.: 57.03%] [G loss: 0.418521]\n",
      "epoch:24 step:22767 [D loss: 0.217371, acc.: 59.38%] [G loss: 0.471691]\n",
      "epoch:24 step:22768 [D loss: 0.205585, acc.: 63.28%] [G loss: 0.457612]\n",
      "epoch:24 step:22769 [D loss: 0.242443, acc.: 55.47%] [G loss: 0.431932]\n",
      "epoch:24 step:22770 [D loss: 0.246754, acc.: 57.03%] [G loss: 0.449048]\n",
      "epoch:24 step:22771 [D loss: 0.203382, acc.: 66.41%] [G loss: 0.439123]\n",
      "epoch:24 step:22772 [D loss: 0.211295, acc.: 67.19%] [G loss: 0.414890]\n",
      "epoch:24 step:22773 [D loss: 0.241961, acc.: 57.81%] [G loss: 0.399320]\n",
      "epoch:24 step:22774 [D loss: 0.220515, acc.: 66.41%] [G loss: 0.451229]\n",
      "epoch:24 step:22775 [D loss: 0.235368, acc.: 57.81%] [G loss: 0.457160]\n",
      "epoch:24 step:22776 [D loss: 0.219631, acc.: 63.28%] [G loss: 0.452727]\n",
      "epoch:24 step:22777 [D loss: 0.204963, acc.: 70.31%] [G loss: 0.421511]\n",
      "epoch:24 step:22778 [D loss: 0.220725, acc.: 69.53%] [G loss: 0.431943]\n",
      "epoch:24 step:22779 [D loss: 0.222691, acc.: 60.94%] [G loss: 0.451073]\n",
      "epoch:24 step:22780 [D loss: 0.210919, acc.: 70.31%] [G loss: 0.421851]\n",
      "epoch:24 step:22781 [D loss: 0.239994, acc.: 58.59%] [G loss: 0.435072]\n",
      "epoch:24 step:22782 [D loss: 0.237552, acc.: 57.81%] [G loss: 0.456641]\n",
      "epoch:24 step:22783 [D loss: 0.225813, acc.: 58.59%] [G loss: 0.450919]\n",
      "epoch:24 step:22784 [D loss: 0.195291, acc.: 71.88%] [G loss: 0.421415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22785 [D loss: 0.235151, acc.: 61.72%] [G loss: 0.402317]\n",
      "epoch:24 step:22786 [D loss: 0.190844, acc.: 75.78%] [G loss: 0.449778]\n",
      "epoch:24 step:22787 [D loss: 0.213138, acc.: 64.84%] [G loss: 0.436814]\n",
      "epoch:24 step:22788 [D loss: 0.189539, acc.: 71.09%] [G loss: 0.432010]\n",
      "epoch:24 step:22789 [D loss: 0.261215, acc.: 50.78%] [G loss: 0.456444]\n",
      "epoch:24 step:22790 [D loss: 0.222638, acc.: 64.06%] [G loss: 0.466429]\n",
      "epoch:24 step:22791 [D loss: 0.212121, acc.: 70.31%] [G loss: 0.454544]\n",
      "epoch:24 step:22792 [D loss: 0.224047, acc.: 60.94%] [G loss: 0.414346]\n",
      "epoch:24 step:22793 [D loss: 0.219295, acc.: 64.84%] [G loss: 0.428276]\n",
      "epoch:24 step:22794 [D loss: 0.224699, acc.: 64.84%] [G loss: 0.432549]\n",
      "epoch:24 step:22795 [D loss: 0.215050, acc.: 64.84%] [G loss: 0.466662]\n",
      "epoch:24 step:22796 [D loss: 0.214359, acc.: 64.06%] [G loss: 0.433797]\n",
      "epoch:24 step:22797 [D loss: 0.220993, acc.: 63.28%] [G loss: 0.373589]\n",
      "epoch:24 step:22798 [D loss: 0.203413, acc.: 70.31%] [G loss: 0.425524]\n",
      "epoch:24 step:22799 [D loss: 0.212104, acc.: 69.53%] [G loss: 0.427153]\n",
      "epoch:24 step:22800 [D loss: 0.200595, acc.: 69.53%] [G loss: 0.452613]\n",
      "epoch:24 step:22801 [D loss: 0.195225, acc.: 71.88%] [G loss: 0.483205]\n",
      "epoch:24 step:22802 [D loss: 0.175929, acc.: 72.66%] [G loss: 0.496394]\n",
      "epoch:24 step:22803 [D loss: 0.180283, acc.: 75.00%] [G loss: 0.532836]\n",
      "epoch:24 step:22804 [D loss: 0.267323, acc.: 59.38%] [G loss: 0.429735]\n",
      "epoch:24 step:22805 [D loss: 0.224228, acc.: 62.50%] [G loss: 0.417978]\n",
      "epoch:24 step:22806 [D loss: 0.214463, acc.: 64.84%] [G loss: 0.464731]\n",
      "epoch:24 step:22807 [D loss: 0.204761, acc.: 63.28%] [G loss: 0.432706]\n",
      "epoch:24 step:22808 [D loss: 0.246554, acc.: 60.94%] [G loss: 0.465380]\n",
      "epoch:24 step:22809 [D loss: 0.208529, acc.: 63.28%] [G loss: 0.452403]\n",
      "epoch:24 step:22810 [D loss: 0.209474, acc.: 69.53%] [G loss: 0.479721]\n",
      "epoch:24 step:22811 [D loss: 0.240861, acc.: 60.16%] [G loss: 0.487728]\n",
      "epoch:24 step:22812 [D loss: 0.248987, acc.: 59.38%] [G loss: 0.414152]\n",
      "epoch:24 step:22813 [D loss: 0.231796, acc.: 58.59%] [G loss: 0.442291]\n",
      "epoch:24 step:22814 [D loss: 0.206201, acc.: 69.53%] [G loss: 0.427007]\n",
      "epoch:24 step:22815 [D loss: 0.230121, acc.: 59.38%] [G loss: 0.409705]\n",
      "epoch:24 step:22816 [D loss: 0.195621, acc.: 71.88%] [G loss: 0.449433]\n",
      "epoch:24 step:22817 [D loss: 0.234672, acc.: 57.81%] [G loss: 0.426253]\n",
      "epoch:24 step:22818 [D loss: 0.210041, acc.: 65.62%] [G loss: 0.397270]\n",
      "epoch:24 step:22819 [D loss: 0.243448, acc.: 54.69%] [G loss: 0.381030]\n",
      "epoch:24 step:22820 [D loss: 0.199468, acc.: 67.19%] [G loss: 0.440191]\n",
      "epoch:24 step:22821 [D loss: 0.227449, acc.: 60.16%] [G loss: 0.406163]\n",
      "epoch:24 step:22822 [D loss: 0.234706, acc.: 61.72%] [G loss: 0.451434]\n",
      "epoch:24 step:22823 [D loss: 0.229688, acc.: 60.94%] [G loss: 0.406238]\n",
      "epoch:24 step:22824 [D loss: 0.212483, acc.: 61.72%] [G loss: 0.461615]\n",
      "epoch:24 step:22825 [D loss: 0.211292, acc.: 64.84%] [G loss: 0.441961]\n",
      "epoch:24 step:22826 [D loss: 0.216211, acc.: 67.19%] [G loss: 0.420993]\n",
      "epoch:24 step:22827 [D loss: 0.200818, acc.: 68.75%] [G loss: 0.443493]\n",
      "epoch:24 step:22828 [D loss: 0.218263, acc.: 63.28%] [G loss: 0.421083]\n",
      "epoch:24 step:22829 [D loss: 0.280258, acc.: 51.56%] [G loss: 0.442730]\n",
      "epoch:24 step:22830 [D loss: 0.240870, acc.: 59.38%] [G loss: 0.480799]\n",
      "epoch:24 step:22831 [D loss: 0.239491, acc.: 64.84%] [G loss: 0.461222]\n",
      "epoch:24 step:22832 [D loss: 0.209793, acc.: 67.97%] [G loss: 0.432973]\n",
      "epoch:24 step:22833 [D loss: 0.199193, acc.: 64.06%] [G loss: 0.428831]\n",
      "epoch:24 step:22834 [D loss: 0.182383, acc.: 67.19%] [G loss: 0.456008]\n",
      "epoch:24 step:22835 [D loss: 0.187536, acc.: 72.66%] [G loss: 0.476010]\n",
      "epoch:24 step:22836 [D loss: 0.275519, acc.: 53.12%] [G loss: 0.403852]\n",
      "epoch:24 step:22837 [D loss: 0.282106, acc.: 52.34%] [G loss: 0.401694]\n",
      "epoch:24 step:22838 [D loss: 0.217925, acc.: 60.16%] [G loss: 0.455485]\n",
      "epoch:24 step:22839 [D loss: 0.230294, acc.: 60.16%] [G loss: 0.409877]\n",
      "epoch:24 step:22840 [D loss: 0.225862, acc.: 59.38%] [G loss: 0.432934]\n",
      "epoch:24 step:22841 [D loss: 0.199329, acc.: 68.75%] [G loss: 0.482314]\n",
      "epoch:24 step:22842 [D loss: 0.196586, acc.: 71.88%] [G loss: 0.451675]\n",
      "epoch:24 step:22843 [D loss: 0.228000, acc.: 60.16%] [G loss: 0.445485]\n",
      "epoch:24 step:22844 [D loss: 0.252577, acc.: 55.47%] [G loss: 0.435909]\n",
      "epoch:24 step:22845 [D loss: 0.217441, acc.: 60.16%] [G loss: 0.416890]\n",
      "epoch:24 step:22846 [D loss: 0.210589, acc.: 61.72%] [G loss: 0.427813]\n",
      "epoch:24 step:22847 [D loss: 0.207941, acc.: 69.53%] [G loss: 0.423367]\n",
      "epoch:24 step:22848 [D loss: 0.223285, acc.: 60.16%] [G loss: 0.463309]\n",
      "epoch:24 step:22849 [D loss: 0.196762, acc.: 69.53%] [G loss: 0.470374]\n",
      "epoch:24 step:22850 [D loss: 0.216342, acc.: 64.06%] [G loss: 0.431409]\n",
      "epoch:24 step:22851 [D loss: 0.233473, acc.: 60.16%] [G loss: 0.438898]\n",
      "epoch:24 step:22852 [D loss: 0.212280, acc.: 67.97%] [G loss: 0.468476]\n",
      "epoch:24 step:22853 [D loss: 0.233436, acc.: 60.94%] [G loss: 0.437059]\n",
      "epoch:24 step:22854 [D loss: 0.224777, acc.: 60.94%] [G loss: 0.438233]\n",
      "epoch:24 step:22855 [D loss: 0.209277, acc.: 67.97%] [G loss: 0.464775]\n",
      "epoch:24 step:22856 [D loss: 0.233865, acc.: 55.47%] [G loss: 0.412934]\n",
      "epoch:24 step:22857 [D loss: 0.214415, acc.: 64.06%] [G loss: 0.400721]\n",
      "epoch:24 step:22858 [D loss: 0.197682, acc.: 70.31%] [G loss: 0.441222]\n",
      "epoch:24 step:22859 [D loss: 0.185598, acc.: 75.78%] [G loss: 0.487888]\n",
      "epoch:24 step:22860 [D loss: 0.234635, acc.: 64.06%] [G loss: 0.422235]\n",
      "epoch:24 step:22861 [D loss: 0.243459, acc.: 58.59%] [G loss: 0.427157]\n",
      "epoch:24 step:22862 [D loss: 0.200762, acc.: 65.62%] [G loss: 0.446109]\n",
      "epoch:24 step:22863 [D loss: 0.218231, acc.: 66.41%] [G loss: 0.433404]\n",
      "epoch:24 step:22864 [D loss: 0.253509, acc.: 53.12%] [G loss: 0.401739]\n",
      "epoch:24 step:22865 [D loss: 0.250475, acc.: 53.12%] [G loss: 0.396934]\n",
      "epoch:24 step:22866 [D loss: 0.209709, acc.: 66.41%] [G loss: 0.430086]\n",
      "epoch:24 step:22867 [D loss: 0.222806, acc.: 59.38%] [G loss: 0.403442]\n",
      "epoch:24 step:22868 [D loss: 0.262407, acc.: 53.91%] [G loss: 0.358151]\n",
      "epoch:24 step:22869 [D loss: 0.199389, acc.: 68.75%] [G loss: 0.431376]\n",
      "epoch:24 step:22870 [D loss: 0.215562, acc.: 66.41%] [G loss: 0.410106]\n",
      "epoch:24 step:22871 [D loss: 0.234753, acc.: 60.16%] [G loss: 0.420529]\n",
      "epoch:24 step:22872 [D loss: 0.205498, acc.: 71.09%] [G loss: 0.413188]\n",
      "epoch:24 step:22873 [D loss: 0.202901, acc.: 64.84%] [G loss: 0.440722]\n",
      "epoch:24 step:22874 [D loss: 0.223408, acc.: 64.84%] [G loss: 0.473676]\n",
      "epoch:24 step:22875 [D loss: 0.220488, acc.: 65.62%] [G loss: 0.434683]\n",
      "epoch:24 step:22876 [D loss: 0.221960, acc.: 59.38%] [G loss: 0.493694]\n",
      "epoch:24 step:22877 [D loss: 0.219422, acc.: 63.28%] [G loss: 0.466126]\n",
      "epoch:24 step:22878 [D loss: 0.254513, acc.: 57.03%] [G loss: 0.445279]\n",
      "epoch:24 step:22879 [D loss: 0.208915, acc.: 65.62%] [G loss: 0.434057]\n",
      "epoch:24 step:22880 [D loss: 0.211253, acc.: 70.31%] [G loss: 0.434617]\n",
      "epoch:24 step:22881 [D loss: 0.237312, acc.: 58.59%] [G loss: 0.422080]\n",
      "epoch:24 step:22882 [D loss: 0.233301, acc.: 61.72%] [G loss: 0.432276]\n",
      "epoch:24 step:22883 [D loss: 0.250807, acc.: 51.56%] [G loss: 0.422296]\n",
      "epoch:24 step:22884 [D loss: 0.252419, acc.: 52.34%] [G loss: 0.426224]\n",
      "epoch:24 step:22885 [D loss: 0.224866, acc.: 64.84%] [G loss: 0.468334]\n",
      "epoch:24 step:22886 [D loss: 0.209287, acc.: 71.09%] [G loss: 0.464833]\n",
      "epoch:24 step:22887 [D loss: 0.209847, acc.: 66.41%] [G loss: 0.472721]\n",
      "epoch:24 step:22888 [D loss: 0.257717, acc.: 50.78%] [G loss: 0.444462]\n",
      "epoch:24 step:22889 [D loss: 0.237155, acc.: 58.59%] [G loss: 0.397791]\n",
      "epoch:24 step:22890 [D loss: 0.216776, acc.: 63.28%] [G loss: 0.427716]\n",
      "epoch:24 step:22891 [D loss: 0.212393, acc.: 64.84%] [G loss: 0.455996]\n",
      "epoch:24 step:22892 [D loss: 0.245838, acc.: 56.25%] [G loss: 0.411012]\n",
      "epoch:24 step:22893 [D loss: 0.214857, acc.: 70.31%] [G loss: 0.475145]\n",
      "epoch:24 step:22894 [D loss: 0.219362, acc.: 61.72%] [G loss: 0.509189]\n",
      "epoch:24 step:22895 [D loss: 0.220227, acc.: 64.84%] [G loss: 0.480261]\n",
      "epoch:24 step:22896 [D loss: 0.259079, acc.: 54.69%] [G loss: 0.437015]\n",
      "epoch:24 step:22897 [D loss: 0.219462, acc.: 62.50%] [G loss: 0.432126]\n",
      "epoch:24 step:22898 [D loss: 0.233225, acc.: 60.94%] [G loss: 0.441507]\n",
      "epoch:24 step:22899 [D loss: 0.261265, acc.: 55.47%] [G loss: 0.431369]\n",
      "epoch:24 step:22900 [D loss: 0.214467, acc.: 61.72%] [G loss: 0.387848]\n",
      "epoch:24 step:22901 [D loss: 0.239297, acc.: 60.94%] [G loss: 0.396796]\n",
      "epoch:24 step:22902 [D loss: 0.217095, acc.: 64.06%] [G loss: 0.403862]\n",
      "epoch:24 step:22903 [D loss: 0.231027, acc.: 57.81%] [G loss: 0.458142]\n",
      "epoch:24 step:22904 [D loss: 0.193911, acc.: 70.31%] [G loss: 0.482261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22905 [D loss: 0.221551, acc.: 62.50%] [G loss: 0.524462]\n",
      "epoch:24 step:22906 [D loss: 0.242624, acc.: 57.81%] [G loss: 0.432040]\n",
      "epoch:24 step:22907 [D loss: 0.246249, acc.: 55.47%] [G loss: 0.409322]\n",
      "epoch:24 step:22908 [D loss: 0.222583, acc.: 64.06%] [G loss: 0.437140]\n",
      "epoch:24 step:22909 [D loss: 0.257210, acc.: 51.56%] [G loss: 0.415131]\n",
      "epoch:24 step:22910 [D loss: 0.242471, acc.: 54.69%] [G loss: 0.398857]\n",
      "epoch:24 step:22911 [D loss: 0.225418, acc.: 66.41%] [G loss: 0.380794]\n",
      "epoch:24 step:22912 [D loss: 0.236634, acc.: 56.25%] [G loss: 0.398889]\n",
      "epoch:24 step:22913 [D loss: 0.208640, acc.: 65.62%] [G loss: 0.413373]\n",
      "epoch:24 step:22914 [D loss: 0.235607, acc.: 57.03%] [G loss: 0.418575]\n",
      "epoch:24 step:22915 [D loss: 0.224931, acc.: 60.94%] [G loss: 0.426846]\n",
      "epoch:24 step:22916 [D loss: 0.193314, acc.: 69.53%] [G loss: 0.427761]\n",
      "epoch:24 step:22917 [D loss: 0.190720, acc.: 72.66%] [G loss: 0.414669]\n",
      "epoch:24 step:22918 [D loss: 0.206998, acc.: 67.97%] [G loss: 0.476006]\n",
      "epoch:24 step:22919 [D loss: 0.257831, acc.: 50.78%] [G loss: 0.413769]\n",
      "epoch:24 step:22920 [D loss: 0.240496, acc.: 56.25%] [G loss: 0.419809]\n",
      "epoch:24 step:22921 [D loss: 0.195210, acc.: 74.22%] [G loss: 0.419427]\n",
      "epoch:24 step:22922 [D loss: 0.232938, acc.: 61.72%] [G loss: 0.407204]\n",
      "epoch:24 step:22923 [D loss: 0.212412, acc.: 66.41%] [G loss: 0.478336]\n",
      "epoch:24 step:22924 [D loss: 0.199877, acc.: 67.19%] [G loss: 0.478268]\n",
      "epoch:24 step:22925 [D loss: 0.274388, acc.: 50.78%] [G loss: 0.397635]\n",
      "epoch:24 step:22926 [D loss: 0.229872, acc.: 59.38%] [G loss: 0.398642]\n",
      "epoch:24 step:22927 [D loss: 0.237432, acc.: 64.84%] [G loss: 0.414731]\n",
      "epoch:24 step:22928 [D loss: 0.239737, acc.: 58.59%] [G loss: 0.415428]\n",
      "epoch:24 step:22929 [D loss: 0.218841, acc.: 63.28%] [G loss: 0.479934]\n",
      "epoch:24 step:22930 [D loss: 0.235062, acc.: 64.84%] [G loss: 0.447491]\n",
      "epoch:24 step:22931 [D loss: 0.229140, acc.: 64.06%] [G loss: 0.441095]\n",
      "epoch:24 step:22932 [D loss: 0.241411, acc.: 53.91%] [G loss: 0.394853]\n",
      "epoch:24 step:22933 [D loss: 0.214503, acc.: 69.53%] [G loss: 0.436008]\n",
      "epoch:24 step:22934 [D loss: 0.226162, acc.: 61.72%] [G loss: 0.405704]\n",
      "epoch:24 step:22935 [D loss: 0.178848, acc.: 75.00%] [G loss: 0.452635]\n",
      "epoch:24 step:22936 [D loss: 0.271987, acc.: 50.78%] [G loss: 0.399348]\n",
      "epoch:24 step:22937 [D loss: 0.215801, acc.: 62.50%] [G loss: 0.445232]\n",
      "epoch:24 step:22938 [D loss: 0.228507, acc.: 67.97%] [G loss: 0.443004]\n",
      "epoch:24 step:22939 [D loss: 0.194745, acc.: 71.88%] [G loss: 0.424111]\n",
      "epoch:24 step:22940 [D loss: 0.240767, acc.: 59.38%] [G loss: 0.405897]\n",
      "epoch:24 step:22941 [D loss: 0.200061, acc.: 72.66%] [G loss: 0.426129]\n",
      "epoch:24 step:22942 [D loss: 0.225644, acc.: 60.94%] [G loss: 0.433753]\n",
      "epoch:24 step:22943 [D loss: 0.211678, acc.: 67.97%] [G loss: 0.422380]\n",
      "epoch:24 step:22944 [D loss: 0.206557, acc.: 69.53%] [G loss: 0.475148]\n",
      "epoch:24 step:22945 [D loss: 0.198853, acc.: 71.09%] [G loss: 0.472774]\n",
      "epoch:24 step:22946 [D loss: 0.301950, acc.: 44.53%] [G loss: 0.411941]\n",
      "epoch:24 step:22947 [D loss: 0.236187, acc.: 62.50%] [G loss: 0.428782]\n",
      "epoch:24 step:22948 [D loss: 0.248400, acc.: 57.03%] [G loss: 0.417921]\n",
      "epoch:24 step:22949 [D loss: 0.218179, acc.: 67.19%] [G loss: 0.414796]\n",
      "epoch:24 step:22950 [D loss: 0.231366, acc.: 60.16%] [G loss: 0.395486]\n",
      "epoch:24 step:22951 [D loss: 0.236359, acc.: 56.25%] [G loss: 0.431223]\n",
      "epoch:24 step:22952 [D loss: 0.232749, acc.: 61.72%] [G loss: 0.389532]\n",
      "epoch:24 step:22953 [D loss: 0.258101, acc.: 54.69%] [G loss: 0.385470]\n",
      "epoch:24 step:22954 [D loss: 0.220071, acc.: 64.06%] [G loss: 0.419746]\n",
      "epoch:24 step:22955 [D loss: 0.275867, acc.: 50.00%] [G loss: 0.412538]\n",
      "epoch:24 step:22956 [D loss: 0.206820, acc.: 67.19%] [G loss: 0.443851]\n",
      "epoch:24 step:22957 [D loss: 0.212732, acc.: 63.28%] [G loss: 0.467196]\n",
      "epoch:24 step:22958 [D loss: 0.184719, acc.: 71.09%] [G loss: 0.447520]\n",
      "epoch:24 step:22959 [D loss: 0.200754, acc.: 73.44%] [G loss: 0.440435]\n",
      "epoch:24 step:22960 [D loss: 0.199307, acc.: 69.53%] [G loss: 0.430874]\n",
      "epoch:24 step:22961 [D loss: 0.249381, acc.: 55.47%] [G loss: 0.445888]\n",
      "epoch:24 step:22962 [D loss: 0.199238, acc.: 69.53%] [G loss: 0.433640]\n",
      "epoch:24 step:22963 [D loss: 0.192187, acc.: 75.78%] [G loss: 0.482370]\n",
      "epoch:24 step:22964 [D loss: 0.218056, acc.: 66.41%] [G loss: 0.464486]\n",
      "epoch:24 step:22965 [D loss: 0.254534, acc.: 53.12%] [G loss: 0.410177]\n",
      "epoch:24 step:22966 [D loss: 0.271650, acc.: 56.25%] [G loss: 0.397189]\n",
      "epoch:24 step:22967 [D loss: 0.216950, acc.: 68.75%] [G loss: 0.416238]\n",
      "epoch:24 step:22968 [D loss: 0.225194, acc.: 67.97%] [G loss: 0.421528]\n",
      "epoch:24 step:22969 [D loss: 0.183658, acc.: 76.56%] [G loss: 0.444308]\n",
      "epoch:24 step:22970 [D loss: 0.273513, acc.: 57.81%] [G loss: 0.410869]\n",
      "epoch:24 step:22971 [D loss: 0.235304, acc.: 52.34%] [G loss: 0.439655]\n",
      "epoch:24 step:22972 [D loss: 0.187594, acc.: 75.78%] [G loss: 0.473757]\n",
      "epoch:24 step:22973 [D loss: 0.217078, acc.: 64.06%] [G loss: 0.457566]\n",
      "epoch:24 step:22974 [D loss: 0.268167, acc.: 52.34%] [G loss: 0.430719]\n",
      "epoch:24 step:22975 [D loss: 0.226282, acc.: 59.38%] [G loss: 0.405951]\n",
      "epoch:24 step:22976 [D loss: 0.196202, acc.: 69.53%] [G loss: 0.449924]\n",
      "epoch:24 step:22977 [D loss: 0.243797, acc.: 53.91%] [G loss: 0.404872]\n",
      "epoch:24 step:22978 [D loss: 0.227529, acc.: 59.38%] [G loss: 0.436851]\n",
      "epoch:24 step:22979 [D loss: 0.226793, acc.: 65.62%] [G loss: 0.425333]\n",
      "epoch:24 step:22980 [D loss: 0.228487, acc.: 61.72%] [G loss: 0.432445]\n",
      "epoch:24 step:22981 [D loss: 0.228939, acc.: 59.38%] [G loss: 0.451513]\n",
      "epoch:24 step:22982 [D loss: 0.224336, acc.: 67.97%] [G loss: 0.448830]\n",
      "epoch:24 step:22983 [D loss: 0.194478, acc.: 72.66%] [G loss: 0.450943]\n",
      "epoch:24 step:22984 [D loss: 0.217632, acc.: 66.41%] [G loss: 0.473619]\n",
      "epoch:24 step:22985 [D loss: 0.252557, acc.: 58.59%] [G loss: 0.441444]\n",
      "epoch:24 step:22986 [D loss: 0.195835, acc.: 72.66%] [G loss: 0.495306]\n",
      "epoch:24 step:22987 [D loss: 0.196597, acc.: 76.56%] [G loss: 0.488358]\n",
      "epoch:24 step:22988 [D loss: 0.246175, acc.: 55.47%] [G loss: 0.431986]\n",
      "epoch:24 step:22989 [D loss: 0.254928, acc.: 55.47%] [G loss: 0.463004]\n",
      "epoch:24 step:22990 [D loss: 0.251011, acc.: 53.12%] [G loss: 0.419963]\n",
      "epoch:24 step:22991 [D loss: 0.230381, acc.: 60.94%] [G loss: 0.442274]\n",
      "epoch:24 step:22992 [D loss: 0.192450, acc.: 71.88%] [G loss: 0.424046]\n",
      "epoch:24 step:22993 [D loss: 0.226503, acc.: 61.72%] [G loss: 0.437928]\n",
      "epoch:24 step:22994 [D loss: 0.255610, acc.: 53.91%] [G loss: 0.435961]\n",
      "epoch:24 step:22995 [D loss: 0.217978, acc.: 64.84%] [G loss: 0.468307]\n",
      "epoch:24 step:22996 [D loss: 0.194950, acc.: 69.53%] [G loss: 0.479991]\n",
      "epoch:24 step:22997 [D loss: 0.258238, acc.: 53.12%] [G loss: 0.442569]\n",
      "epoch:24 step:22998 [D loss: 0.245734, acc.: 55.47%] [G loss: 0.422477]\n",
      "epoch:24 step:22999 [D loss: 0.242511, acc.: 56.25%] [G loss: 0.431739]\n",
      "epoch:24 step:23000 [D loss: 0.222408, acc.: 64.84%] [G loss: 0.412397]\n",
      "epoch:24 step:23001 [D loss: 0.184016, acc.: 71.09%] [G loss: 0.446513]\n",
      "epoch:24 step:23002 [D loss: 0.220825, acc.: 62.50%] [G loss: 0.415619]\n",
      "epoch:24 step:23003 [D loss: 0.183766, acc.: 78.12%] [G loss: 0.440059]\n",
      "epoch:24 step:23004 [D loss: 0.197338, acc.: 71.88%] [G loss: 0.467319]\n",
      "epoch:24 step:23005 [D loss: 0.247111, acc.: 56.25%] [G loss: 0.406928]\n",
      "epoch:24 step:23006 [D loss: 0.245773, acc.: 53.12%] [G loss: 0.407159]\n",
      "epoch:24 step:23007 [D loss: 0.196806, acc.: 69.53%] [G loss: 0.455783]\n",
      "epoch:24 step:23008 [D loss: 0.222199, acc.: 64.06%] [G loss: 0.427231]\n",
      "epoch:24 step:23009 [D loss: 0.198820, acc.: 65.62%] [G loss: 0.460660]\n",
      "epoch:24 step:23010 [D loss: 0.206978, acc.: 71.88%] [G loss: 0.457803]\n",
      "epoch:24 step:23011 [D loss: 0.201043, acc.: 71.88%] [G loss: 0.492734]\n",
      "epoch:24 step:23012 [D loss: 0.210010, acc.: 67.19%] [G loss: 0.448527]\n",
      "epoch:24 step:23013 [D loss: 0.202866, acc.: 71.09%] [G loss: 0.463174]\n",
      "epoch:24 step:23014 [D loss: 0.203881, acc.: 68.75%] [G loss: 0.523849]\n",
      "epoch:24 step:23015 [D loss: 0.212176, acc.: 62.50%] [G loss: 0.442202]\n",
      "epoch:24 step:23016 [D loss: 0.257557, acc.: 56.25%] [G loss: 0.414507]\n",
      "epoch:24 step:23017 [D loss: 0.239199, acc.: 59.38%] [G loss: 0.398699]\n",
      "epoch:24 step:23018 [D loss: 0.241553, acc.: 57.81%] [G loss: 0.483821]\n",
      "epoch:24 step:23019 [D loss: 0.220810, acc.: 67.19%] [G loss: 0.461564]\n",
      "epoch:24 step:23020 [D loss: 0.225380, acc.: 63.28%] [G loss: 0.461574]\n",
      "epoch:24 step:23021 [D loss: 0.229006, acc.: 61.72%] [G loss: 0.445340]\n",
      "epoch:24 step:23022 [D loss: 0.189514, acc.: 69.53%] [G loss: 0.473194]\n",
      "epoch:24 step:23023 [D loss: 0.246129, acc.: 53.12%] [G loss: 0.447695]\n",
      "epoch:24 step:23024 [D loss: 0.228799, acc.: 61.72%] [G loss: 0.419587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23025 [D loss: 0.236249, acc.: 59.38%] [G loss: 0.423691]\n",
      "epoch:24 step:23026 [D loss: 0.246753, acc.: 55.47%] [G loss: 0.428836]\n",
      "epoch:24 step:23027 [D loss: 0.217365, acc.: 67.19%] [G loss: 0.425118]\n",
      "epoch:24 step:23028 [D loss: 0.210685, acc.: 60.94%] [G loss: 0.431082]\n",
      "epoch:24 step:23029 [D loss: 0.242224, acc.: 57.03%] [G loss: 0.406924]\n",
      "epoch:24 step:23030 [D loss: 0.277546, acc.: 49.22%] [G loss: 0.397320]\n",
      "epoch:24 step:23031 [D loss: 0.231882, acc.: 57.81%] [G loss: 0.402316]\n",
      "epoch:24 step:23032 [D loss: 0.214678, acc.: 64.84%] [G loss: 0.435906]\n",
      "epoch:24 step:23033 [D loss: 0.219849, acc.: 66.41%] [G loss: 0.444362]\n",
      "epoch:24 step:23034 [D loss: 0.225205, acc.: 58.59%] [G loss: 0.473152]\n",
      "epoch:24 step:23035 [D loss: 0.199585, acc.: 70.31%] [G loss: 0.485220]\n",
      "epoch:24 step:23036 [D loss: 0.209273, acc.: 67.97%] [G loss: 0.453903]\n",
      "epoch:24 step:23037 [D loss: 0.202267, acc.: 68.75%] [G loss: 0.467645]\n",
      "epoch:24 step:23038 [D loss: 0.190641, acc.: 70.31%] [G loss: 0.477031]\n",
      "epoch:24 step:23039 [D loss: 0.189428, acc.: 73.44%] [G loss: 0.479640]\n",
      "epoch:24 step:23040 [D loss: 0.224520, acc.: 61.72%] [G loss: 0.466680]\n",
      "epoch:24 step:23041 [D loss: 0.227698, acc.: 64.06%] [G loss: 0.416311]\n",
      "epoch:24 step:23042 [D loss: 0.211643, acc.: 70.31%] [G loss: 0.443717]\n",
      "epoch:24 step:23043 [D loss: 0.217793, acc.: 65.62%] [G loss: 0.436509]\n",
      "epoch:24 step:23044 [D loss: 0.214213, acc.: 67.19%] [G loss: 0.475010]\n",
      "epoch:24 step:23045 [D loss: 0.210332, acc.: 67.19%] [G loss: 0.462957]\n",
      "epoch:24 step:23046 [D loss: 0.208659, acc.: 66.41%] [G loss: 0.492627]\n",
      "epoch:24 step:23047 [D loss: 0.248744, acc.: 57.81%] [G loss: 0.422962]\n",
      "epoch:24 step:23048 [D loss: 0.248008, acc.: 57.03%] [G loss: 0.454503]\n",
      "epoch:24 step:23049 [D loss: 0.206589, acc.: 71.09%] [G loss: 0.417048]\n",
      "epoch:24 step:23050 [D loss: 0.212577, acc.: 67.19%] [G loss: 0.439093]\n",
      "epoch:24 step:23051 [D loss: 0.192812, acc.: 71.09%] [G loss: 0.481677]\n",
      "epoch:24 step:23052 [D loss: 0.168711, acc.: 78.12%] [G loss: 0.488997]\n",
      "epoch:24 step:23053 [D loss: 0.251969, acc.: 56.25%] [G loss: 0.449076]\n",
      "epoch:24 step:23054 [D loss: 0.269823, acc.: 57.81%] [G loss: 0.420058]\n",
      "epoch:24 step:23055 [D loss: 0.209427, acc.: 62.50%] [G loss: 0.452658]\n",
      "epoch:24 step:23056 [D loss: 0.203847, acc.: 64.84%] [G loss: 0.467837]\n",
      "epoch:24 step:23057 [D loss: 0.264796, acc.: 48.44%] [G loss: 0.430662]\n",
      "epoch:24 step:23058 [D loss: 0.205424, acc.: 66.41%] [G loss: 0.441099]\n",
      "epoch:24 step:23059 [D loss: 0.209891, acc.: 63.28%] [G loss: 0.386398]\n",
      "epoch:24 step:23060 [D loss: 0.205292, acc.: 72.66%] [G loss: 0.445188]\n",
      "epoch:24 step:23061 [D loss: 0.236359, acc.: 62.50%] [G loss: 0.465978]\n",
      "epoch:24 step:23062 [D loss: 0.204558, acc.: 69.53%] [G loss: 0.461989]\n",
      "epoch:24 step:23063 [D loss: 0.208957, acc.: 67.19%] [G loss: 0.442397]\n",
      "epoch:24 step:23064 [D loss: 0.227722, acc.: 57.03%] [G loss: 0.438406]\n",
      "epoch:24 step:23065 [D loss: 0.210922, acc.: 64.06%] [G loss: 0.418660]\n",
      "epoch:24 step:23066 [D loss: 0.212168, acc.: 63.28%] [G loss: 0.393821]\n",
      "epoch:24 step:23067 [D loss: 0.238237, acc.: 63.28%] [G loss: 0.381310]\n",
      "epoch:24 step:23068 [D loss: 0.236787, acc.: 64.06%] [G loss: 0.392579]\n",
      "epoch:24 step:23069 [D loss: 0.214212, acc.: 67.19%] [G loss: 0.448433]\n",
      "epoch:24 step:23070 [D loss: 0.200524, acc.: 71.09%] [G loss: 0.474677]\n",
      "epoch:24 step:23071 [D loss: 0.224260, acc.: 64.84%] [G loss: 0.466228]\n",
      "epoch:24 step:23072 [D loss: 0.247196, acc.: 53.91%] [G loss: 0.422525]\n",
      "epoch:24 step:23073 [D loss: 0.231288, acc.: 61.72%] [G loss: 0.412025]\n",
      "epoch:24 step:23074 [D loss: 0.234714, acc.: 60.16%] [G loss: 0.451798]\n",
      "epoch:24 step:23075 [D loss: 0.241858, acc.: 59.38%] [G loss: 0.445229]\n",
      "epoch:24 step:23076 [D loss: 0.216911, acc.: 63.28%] [G loss: 0.419625]\n",
      "epoch:24 step:23077 [D loss: 0.230138, acc.: 60.16%] [G loss: 0.437192]\n",
      "epoch:24 step:23078 [D loss: 0.235004, acc.: 62.50%] [G loss: 0.454625]\n",
      "epoch:24 step:23079 [D loss: 0.231305, acc.: 60.94%] [G loss: 0.475429]\n",
      "epoch:24 step:23080 [D loss: 0.213565, acc.: 71.09%] [G loss: 0.422706]\n",
      "epoch:24 step:23081 [D loss: 0.236733, acc.: 58.59%] [G loss: 0.414664]\n",
      "epoch:24 step:23082 [D loss: 0.240759, acc.: 56.25%] [G loss: 0.441190]\n",
      "epoch:24 step:23083 [D loss: 0.231608, acc.: 62.50%] [G loss: 0.433576]\n",
      "epoch:24 step:23084 [D loss: 0.222343, acc.: 63.28%] [G loss: 0.453427]\n",
      "epoch:24 step:23085 [D loss: 0.247474, acc.: 59.38%] [G loss: 0.415201]\n",
      "epoch:24 step:23086 [D loss: 0.209079, acc.: 70.31%] [G loss: 0.424733]\n",
      "epoch:24 step:23087 [D loss: 0.212618, acc.: 65.62%] [G loss: 0.446017]\n",
      "epoch:24 step:23088 [D loss: 0.246922, acc.: 53.91%] [G loss: 0.413392]\n",
      "epoch:24 step:23089 [D loss: 0.212896, acc.: 65.62%] [G loss: 0.428352]\n",
      "epoch:24 step:23090 [D loss: 0.232572, acc.: 62.50%] [G loss: 0.473874]\n",
      "epoch:24 step:23091 [D loss: 0.221154, acc.: 63.28%] [G loss: 0.420839]\n",
      "epoch:24 step:23092 [D loss: 0.235570, acc.: 60.94%] [G loss: 0.393500]\n",
      "epoch:24 step:23093 [D loss: 0.226035, acc.: 64.06%] [G loss: 0.442359]\n",
      "epoch:24 step:23094 [D loss: 0.240906, acc.: 55.47%] [G loss: 0.399515]\n",
      "epoch:24 step:23095 [D loss: 0.233380, acc.: 57.03%] [G loss: 0.414003]\n",
      "epoch:24 step:23096 [D loss: 0.218946, acc.: 60.94%] [G loss: 0.410050]\n",
      "epoch:24 step:23097 [D loss: 0.211935, acc.: 65.62%] [G loss: 0.422459]\n",
      "epoch:24 step:23098 [D loss: 0.214380, acc.: 67.19%] [G loss: 0.413961]\n",
      "epoch:24 step:23099 [D loss: 0.242108, acc.: 55.47%] [G loss: 0.412596]\n",
      "epoch:24 step:23100 [D loss: 0.197695, acc.: 68.75%] [G loss: 0.449109]\n",
      "epoch:24 step:23101 [D loss: 0.215248, acc.: 62.50%] [G loss: 0.417823]\n",
      "epoch:24 step:23102 [D loss: 0.255520, acc.: 50.78%] [G loss: 0.377585]\n",
      "epoch:24 step:23103 [D loss: 0.247626, acc.: 52.34%] [G loss: 0.387749]\n",
      "epoch:24 step:23104 [D loss: 0.236626, acc.: 62.50%] [G loss: 0.421801]\n",
      "epoch:24 step:23105 [D loss: 0.201236, acc.: 73.44%] [G loss: 0.425462]\n",
      "epoch:24 step:23106 [D loss: 0.213493, acc.: 67.19%] [G loss: 0.416798]\n",
      "epoch:24 step:23107 [D loss: 0.233078, acc.: 62.50%] [G loss: 0.460812]\n",
      "epoch:24 step:23108 [D loss: 0.214082, acc.: 67.19%] [G loss: 0.423249]\n",
      "epoch:24 step:23109 [D loss: 0.233207, acc.: 57.81%] [G loss: 0.415588]\n",
      "epoch:24 step:23110 [D loss: 0.233861, acc.: 59.38%] [G loss: 0.414734]\n",
      "epoch:24 step:23111 [D loss: 0.230590, acc.: 63.28%] [G loss: 0.423092]\n",
      "epoch:24 step:23112 [D loss: 0.193052, acc.: 67.97%] [G loss: 0.463797]\n",
      "epoch:24 step:23113 [D loss: 0.232044, acc.: 64.06%] [G loss: 0.446609]\n",
      "epoch:24 step:23114 [D loss: 0.238484, acc.: 64.06%] [G loss: 0.429822]\n",
      "epoch:24 step:23115 [D loss: 0.213513, acc.: 67.19%] [G loss: 0.443190]\n",
      "epoch:24 step:23116 [D loss: 0.240130, acc.: 57.03%] [G loss: 0.448512]\n",
      "epoch:24 step:23117 [D loss: 0.202919, acc.: 66.41%] [G loss: 0.444681]\n",
      "epoch:24 step:23118 [D loss: 0.228776, acc.: 60.16%] [G loss: 0.409042]\n",
      "epoch:24 step:23119 [D loss: 0.199723, acc.: 65.62%] [G loss: 0.433445]\n",
      "epoch:24 step:23120 [D loss: 0.228548, acc.: 61.72%] [G loss: 0.414369]\n",
      "epoch:24 step:23121 [D loss: 0.220901, acc.: 64.84%] [G loss: 0.453223]\n",
      "epoch:24 step:23122 [D loss: 0.237160, acc.: 59.38%] [G loss: 0.430777]\n",
      "epoch:24 step:23123 [D loss: 0.208014, acc.: 66.41%] [G loss: 0.458944]\n",
      "epoch:24 step:23124 [D loss: 0.234321, acc.: 62.50%] [G loss: 0.430854]\n",
      "epoch:24 step:23125 [D loss: 0.209232, acc.: 69.53%] [G loss: 0.448094]\n",
      "epoch:24 step:23126 [D loss: 0.221694, acc.: 66.41%] [G loss: 0.433028]\n",
      "epoch:24 step:23127 [D loss: 0.229634, acc.: 54.69%] [G loss: 0.434083]\n",
      "epoch:24 step:23128 [D loss: 0.214246, acc.: 66.41%] [G loss: 0.463005]\n",
      "epoch:24 step:23129 [D loss: 0.201663, acc.: 71.09%] [G loss: 0.466807]\n",
      "epoch:24 step:23130 [D loss: 0.185069, acc.: 73.44%] [G loss: 0.484973]\n",
      "epoch:24 step:23131 [D loss: 0.220256, acc.: 62.50%] [G loss: 0.469049]\n",
      "epoch:24 step:23132 [D loss: 0.223548, acc.: 62.50%] [G loss: 0.440243]\n",
      "epoch:24 step:23133 [D loss: 0.223248, acc.: 58.59%] [G loss: 0.402970]\n",
      "epoch:24 step:23134 [D loss: 0.224773, acc.: 60.16%] [G loss: 0.397203]\n",
      "epoch:24 step:23135 [D loss: 0.195619, acc.: 71.09%] [G loss: 0.470763]\n",
      "epoch:24 step:23136 [D loss: 0.179363, acc.: 75.00%] [G loss: 0.518118]\n",
      "epoch:24 step:23137 [D loss: 0.220395, acc.: 61.72%] [G loss: 0.475411]\n",
      "epoch:24 step:23138 [D loss: 0.218284, acc.: 64.06%] [G loss: 0.487190]\n",
      "epoch:24 step:23139 [D loss: 0.211701, acc.: 67.97%] [G loss: 0.470063]\n",
      "epoch:24 step:23140 [D loss: 0.209646, acc.: 67.19%] [G loss: 0.460920]\n",
      "epoch:24 step:23141 [D loss: 0.217914, acc.: 65.62%] [G loss: 0.436337]\n",
      "epoch:24 step:23142 [D loss: 0.214269, acc.: 67.19%] [G loss: 0.455959]\n",
      "epoch:24 step:23143 [D loss: 0.255667, acc.: 58.59%] [G loss: 0.432948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23144 [D loss: 0.240958, acc.: 60.16%] [G loss: 0.389433]\n",
      "epoch:24 step:23145 [D loss: 0.243269, acc.: 59.38%] [G loss: 0.417786]\n",
      "epoch:24 step:23146 [D loss: 0.224018, acc.: 63.28%] [G loss: 0.444244]\n",
      "epoch:24 step:23147 [D loss: 0.215785, acc.: 64.84%] [G loss: 0.481045]\n",
      "epoch:24 step:23148 [D loss: 0.205908, acc.: 67.97%] [G loss: 0.476699]\n",
      "epoch:24 step:23149 [D loss: 0.196522, acc.: 72.66%] [G loss: 0.471128]\n",
      "epoch:24 step:23150 [D loss: 0.231069, acc.: 59.38%] [G loss: 0.452303]\n",
      "epoch:24 step:23151 [D loss: 0.234128, acc.: 58.59%] [G loss: 0.443138]\n",
      "epoch:24 step:23152 [D loss: 0.236189, acc.: 61.72%] [G loss: 0.451087]\n",
      "epoch:24 step:23153 [D loss: 0.209400, acc.: 65.62%] [G loss: 0.464005]\n",
      "epoch:24 step:23154 [D loss: 0.228644, acc.: 60.94%] [G loss: 0.458798]\n",
      "epoch:24 step:23155 [D loss: 0.237381, acc.: 61.72%] [G loss: 0.480637]\n",
      "epoch:24 step:23156 [D loss: 0.242342, acc.: 54.69%] [G loss: 0.426457]\n",
      "epoch:24 step:23157 [D loss: 0.219876, acc.: 65.62%] [G loss: 0.435943]\n",
      "epoch:24 step:23158 [D loss: 0.218684, acc.: 59.38%] [G loss: 0.466873]\n",
      "epoch:24 step:23159 [D loss: 0.226697, acc.: 57.81%] [G loss: 0.380738]\n",
      "epoch:24 step:23160 [D loss: 0.244284, acc.: 56.25%] [G loss: 0.426172]\n",
      "epoch:24 step:23161 [D loss: 0.232932, acc.: 57.81%] [G loss: 0.435274]\n",
      "epoch:24 step:23162 [D loss: 0.221096, acc.: 64.84%] [G loss: 0.413893]\n",
      "epoch:24 step:23163 [D loss: 0.243489, acc.: 57.03%] [G loss: 0.417406]\n",
      "epoch:24 step:23164 [D loss: 0.208989, acc.: 68.75%] [G loss: 0.409446]\n",
      "epoch:24 step:23165 [D loss: 0.192000, acc.: 71.88%] [G loss: 0.453819]\n",
      "epoch:24 step:23166 [D loss: 0.224298, acc.: 63.28%] [G loss: 0.405279]\n",
      "epoch:24 step:23167 [D loss: 0.215030, acc.: 63.28%] [G loss: 0.454640]\n",
      "epoch:24 step:23168 [D loss: 0.246247, acc.: 56.25%] [G loss: 0.423101]\n",
      "epoch:24 step:23169 [D loss: 0.201377, acc.: 67.19%] [G loss: 0.434834]\n",
      "epoch:24 step:23170 [D loss: 0.232969, acc.: 60.16%] [G loss: 0.445596]\n",
      "epoch:24 step:23171 [D loss: 0.245196, acc.: 57.81%] [G loss: 0.414445]\n",
      "epoch:24 step:23172 [D loss: 0.243939, acc.: 55.47%] [G loss: 0.430393]\n",
      "epoch:24 step:23173 [D loss: 0.209284, acc.: 63.28%] [G loss: 0.396331]\n",
      "epoch:24 step:23174 [D loss: 0.216515, acc.: 69.53%] [G loss: 0.404364]\n",
      "epoch:24 step:23175 [D loss: 0.244521, acc.: 60.94%] [G loss: 0.416048]\n",
      "epoch:24 step:23176 [D loss: 0.197330, acc.: 64.06%] [G loss: 0.471212]\n",
      "epoch:24 step:23177 [D loss: 0.229511, acc.: 60.16%] [G loss: 0.470392]\n",
      "epoch:24 step:23178 [D loss: 0.198477, acc.: 70.31%] [G loss: 0.436884]\n",
      "epoch:24 step:23179 [D loss: 0.216854, acc.: 64.06%] [G loss: 0.469820]\n",
      "epoch:24 step:23180 [D loss: 0.205570, acc.: 67.19%] [G loss: 0.488501]\n",
      "epoch:24 step:23181 [D loss: 0.199570, acc.: 69.53%] [G loss: 0.515949]\n",
      "epoch:24 step:23182 [D loss: 0.184494, acc.: 71.88%] [G loss: 0.539003]\n",
      "epoch:24 step:23183 [D loss: 0.236162, acc.: 63.28%] [G loss: 0.492718]\n",
      "epoch:24 step:23184 [D loss: 0.258276, acc.: 52.34%] [G loss: 0.408089]\n",
      "epoch:24 step:23185 [D loss: 0.245690, acc.: 50.78%] [G loss: 0.410814]\n",
      "epoch:24 step:23186 [D loss: 0.267229, acc.: 50.78%] [G loss: 0.392576]\n",
      "epoch:24 step:23187 [D loss: 0.227315, acc.: 67.97%] [G loss: 0.430931]\n",
      "epoch:24 step:23188 [D loss: 0.198118, acc.: 71.88%] [G loss: 0.467053]\n",
      "epoch:24 step:23189 [D loss: 0.187989, acc.: 73.44%] [G loss: 0.467517]\n",
      "epoch:24 step:23190 [D loss: 0.241503, acc.: 58.59%] [G loss: 0.478999]\n",
      "epoch:24 step:23191 [D loss: 0.264260, acc.: 53.12%] [G loss: 0.429203]\n",
      "epoch:24 step:23192 [D loss: 0.229796, acc.: 60.16%] [G loss: 0.444628]\n",
      "epoch:24 step:23193 [D loss: 0.236776, acc.: 63.28%] [G loss: 0.390903]\n",
      "epoch:24 step:23194 [D loss: 0.212105, acc.: 65.62%] [G loss: 0.449129]\n",
      "epoch:24 step:23195 [D loss: 0.196040, acc.: 71.88%] [G loss: 0.454778]\n",
      "epoch:24 step:23196 [D loss: 0.208695, acc.: 71.09%] [G loss: 0.447741]\n",
      "epoch:24 step:23197 [D loss: 0.217479, acc.: 64.84%] [G loss: 0.448004]\n",
      "epoch:24 step:23198 [D loss: 0.229577, acc.: 60.16%] [G loss: 0.422206]\n",
      "epoch:24 step:23199 [D loss: 0.234085, acc.: 56.25%] [G loss: 0.401530]\n",
      "epoch:24 step:23200 [D loss: 0.217536, acc.: 65.62%] [G loss: 0.433091]\n",
      "epoch:24 step:23201 [D loss: 0.212922, acc.: 66.41%] [G loss: 0.422141]\n",
      "epoch:24 step:23202 [D loss: 0.226069, acc.: 62.50%] [G loss: 0.438548]\n",
      "epoch:24 step:23203 [D loss: 0.219655, acc.: 64.06%] [G loss: 0.445007]\n",
      "epoch:24 step:23204 [D loss: 0.261307, acc.: 49.22%] [G loss: 0.427435]\n",
      "epoch:24 step:23205 [D loss: 0.214534, acc.: 65.62%] [G loss: 0.436314]\n",
      "epoch:24 step:23206 [D loss: 0.222123, acc.: 64.84%] [G loss: 0.474238]\n",
      "epoch:24 step:23207 [D loss: 0.208568, acc.: 64.06%] [G loss: 0.464286]\n",
      "epoch:24 step:23208 [D loss: 0.220016, acc.: 63.28%] [G loss: 0.446011]\n",
      "epoch:24 step:23209 [D loss: 0.219882, acc.: 60.94%] [G loss: 0.414643]\n",
      "epoch:24 step:23210 [D loss: 0.250564, acc.: 56.25%] [G loss: 0.416648]\n",
      "epoch:24 step:23211 [D loss: 0.210297, acc.: 68.75%] [G loss: 0.461783]\n",
      "epoch:24 step:23212 [D loss: 0.213159, acc.: 66.41%] [G loss: 0.465026]\n",
      "epoch:24 step:23213 [D loss: 0.220913, acc.: 67.19%] [G loss: 0.466029]\n",
      "epoch:24 step:23214 [D loss: 0.222602, acc.: 61.72%] [G loss: 0.468551]\n",
      "epoch:24 step:23215 [D loss: 0.235038, acc.: 58.59%] [G loss: 0.422827]\n",
      "epoch:24 step:23216 [D loss: 0.218297, acc.: 67.97%] [G loss: 0.399786]\n",
      "epoch:24 step:23217 [D loss: 0.224921, acc.: 63.28%] [G loss: 0.394061]\n",
      "epoch:24 step:23218 [D loss: 0.219112, acc.: 65.62%] [G loss: 0.408181]\n",
      "epoch:24 step:23219 [D loss: 0.211816, acc.: 67.97%] [G loss: 0.415362]\n",
      "epoch:24 step:23220 [D loss: 0.206265, acc.: 62.50%] [G loss: 0.436986]\n",
      "epoch:24 step:23221 [D loss: 0.222747, acc.: 66.41%] [G loss: 0.474617]\n",
      "epoch:24 step:23222 [D loss: 0.259489, acc.: 52.34%] [G loss: 0.398677]\n",
      "epoch:24 step:23223 [D loss: 0.233462, acc.: 64.84%] [G loss: 0.415156]\n",
      "epoch:24 step:23224 [D loss: 0.226538, acc.: 61.72%] [G loss: 0.416521]\n",
      "epoch:24 step:23225 [D loss: 0.226171, acc.: 60.16%] [G loss: 0.434362]\n",
      "epoch:24 step:23226 [D loss: 0.243929, acc.: 55.47%] [G loss: 0.410936]\n",
      "epoch:24 step:23227 [D loss: 0.237327, acc.: 60.16%] [G loss: 0.395973]\n",
      "epoch:24 step:23228 [D loss: 0.223882, acc.: 64.06%] [G loss: 0.438622]\n",
      "epoch:24 step:23229 [D loss: 0.246470, acc.: 58.59%] [G loss: 0.404929]\n",
      "epoch:24 step:23230 [D loss: 0.239738, acc.: 56.25%] [G loss: 0.403172]\n",
      "epoch:24 step:23231 [D loss: 0.213926, acc.: 67.97%] [G loss: 0.412476]\n",
      "epoch:24 step:23232 [D loss: 0.230041, acc.: 60.94%] [G loss: 0.434858]\n",
      "epoch:24 step:23233 [D loss: 0.253135, acc.: 57.03%] [G loss: 0.398852]\n",
      "epoch:24 step:23234 [D loss: 0.207835, acc.: 63.28%] [G loss: 0.405081]\n",
      "epoch:24 step:23235 [D loss: 0.211854, acc.: 61.72%] [G loss: 0.444153]\n",
      "epoch:24 step:23236 [D loss: 0.227922, acc.: 69.53%] [G loss: 0.461915]\n",
      "epoch:24 step:23237 [D loss: 0.255483, acc.: 53.91%] [G loss: 0.412832]\n",
      "epoch:24 step:23238 [D loss: 0.201201, acc.: 66.41%] [G loss: 0.428833]\n",
      "epoch:24 step:23239 [D loss: 0.227969, acc.: 57.81%] [G loss: 0.383601]\n",
      "epoch:24 step:23240 [D loss: 0.237877, acc.: 59.38%] [G loss: 0.439807]\n",
      "epoch:24 step:23241 [D loss: 0.234333, acc.: 53.12%] [G loss: 0.376042]\n",
      "epoch:24 step:23242 [D loss: 0.214177, acc.: 65.62%] [G loss: 0.460940]\n",
      "epoch:24 step:23243 [D loss: 0.232937, acc.: 59.38%] [G loss: 0.449656]\n",
      "epoch:24 step:23244 [D loss: 0.249522, acc.: 53.91%] [G loss: 0.421548]\n",
      "epoch:24 step:23245 [D loss: 0.237303, acc.: 57.03%] [G loss: 0.412842]\n",
      "epoch:24 step:23246 [D loss: 0.239723, acc.: 59.38%] [G loss: 0.442563]\n",
      "epoch:24 step:23247 [D loss: 0.238678, acc.: 57.03%] [G loss: 0.410291]\n",
      "epoch:24 step:23248 [D loss: 0.239726, acc.: 62.50%] [G loss: 0.390473]\n",
      "epoch:24 step:23249 [D loss: 0.228814, acc.: 65.62%] [G loss: 0.426573]\n",
      "epoch:24 step:23250 [D loss: 0.252068, acc.: 51.56%] [G loss: 0.403401]\n",
      "epoch:24 step:23251 [D loss: 0.217237, acc.: 65.62%] [G loss: 0.438113]\n",
      "epoch:24 step:23252 [D loss: 0.236482, acc.: 60.16%] [G loss: 0.402361]\n",
      "epoch:24 step:23253 [D loss: 0.238714, acc.: 60.94%] [G loss: 0.413072]\n",
      "epoch:24 step:23254 [D loss: 0.234803, acc.: 60.16%] [G loss: 0.415669]\n",
      "epoch:24 step:23255 [D loss: 0.196401, acc.: 73.44%] [G loss: 0.403447]\n",
      "epoch:24 step:23256 [D loss: 0.264549, acc.: 51.56%] [G loss: 0.440795]\n",
      "epoch:24 step:23257 [D loss: 0.211169, acc.: 64.06%] [G loss: 0.468398]\n",
      "epoch:24 step:23258 [D loss: 0.241668, acc.: 59.38%] [G loss: 0.407030]\n",
      "epoch:24 step:23259 [D loss: 0.237392, acc.: 61.72%] [G loss: 0.420804]\n",
      "epoch:24 step:23260 [D loss: 0.247893, acc.: 61.72%] [G loss: 0.448546]\n",
      "epoch:24 step:23261 [D loss: 0.203594, acc.: 68.75%] [G loss: 0.396198]\n",
      "epoch:24 step:23262 [D loss: 0.230344, acc.: 64.06%] [G loss: 0.427461]\n",
      "epoch:24 step:23263 [D loss: 0.220478, acc.: 64.84%] [G loss: 0.457604]\n",
      "epoch:24 step:23264 [D loss: 0.221390, acc.: 65.62%] [G loss: 0.469997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23265 [D loss: 0.212159, acc.: 62.50%] [G loss: 0.451981]\n",
      "epoch:24 step:23266 [D loss: 0.239157, acc.: 56.25%] [G loss: 0.420755]\n",
      "epoch:24 step:23267 [D loss: 0.211253, acc.: 67.97%] [G loss: 0.413405]\n",
      "epoch:24 step:23268 [D loss: 0.236470, acc.: 64.84%] [G loss: 0.436674]\n",
      "epoch:24 step:23269 [D loss: 0.205181, acc.: 67.97%] [G loss: 0.480889]\n",
      "epoch:24 step:23270 [D loss: 0.192761, acc.: 71.88%] [G loss: 0.464141]\n",
      "epoch:24 step:23271 [D loss: 0.254345, acc.: 57.81%] [G loss: 0.428254]\n",
      "epoch:24 step:23272 [D loss: 0.244336, acc.: 60.94%] [G loss: 0.442057]\n",
      "epoch:24 step:23273 [D loss: 0.206310, acc.: 63.28%] [G loss: 0.433419]\n",
      "epoch:24 step:23274 [D loss: 0.215745, acc.: 64.06%] [G loss: 0.426859]\n",
      "epoch:24 step:23275 [D loss: 0.269993, acc.: 53.12%] [G loss: 0.425082]\n",
      "epoch:24 step:23276 [D loss: 0.236304, acc.: 60.16%] [G loss: 0.432471]\n",
      "epoch:24 step:23277 [D loss: 0.239320, acc.: 58.59%] [G loss: 0.393115]\n",
      "epoch:24 step:23278 [D loss: 0.217810, acc.: 65.62%] [G loss: 0.416999]\n",
      "epoch:24 step:23279 [D loss: 0.240525, acc.: 57.03%] [G loss: 0.397475]\n",
      "epoch:24 step:23280 [D loss: 0.199458, acc.: 69.53%] [G loss: 0.420970]\n",
      "epoch:24 step:23281 [D loss: 0.218181, acc.: 67.19%] [G loss: 0.432859]\n",
      "epoch:24 step:23282 [D loss: 0.256415, acc.: 52.34%] [G loss: 0.459518]\n",
      "epoch:24 step:23283 [D loss: 0.255523, acc.: 55.47%] [G loss: 0.448227]\n",
      "epoch:24 step:23284 [D loss: 0.206963, acc.: 68.75%] [G loss: 0.436438]\n",
      "epoch:24 step:23285 [D loss: 0.273476, acc.: 49.22%] [G loss: 0.400323]\n",
      "epoch:24 step:23286 [D loss: 0.218094, acc.: 67.19%] [G loss: 0.394274]\n",
      "epoch:24 step:23287 [D loss: 0.230695, acc.: 66.41%] [G loss: 0.424452]\n",
      "epoch:24 step:23288 [D loss: 0.236662, acc.: 60.94%] [G loss: 0.433211]\n",
      "epoch:24 step:23289 [D loss: 0.211015, acc.: 67.19%] [G loss: 0.459739]\n",
      "epoch:24 step:23290 [D loss: 0.201669, acc.: 67.97%] [G loss: 0.504611]\n",
      "epoch:24 step:23291 [D loss: 0.226626, acc.: 64.06%] [G loss: 0.425095]\n",
      "epoch:24 step:23292 [D loss: 0.217523, acc.: 64.84%] [G loss: 0.461458]\n",
      "epoch:24 step:23293 [D loss: 0.223868, acc.: 60.94%] [G loss: 0.430492]\n",
      "epoch:24 step:23294 [D loss: 0.210331, acc.: 64.06%] [G loss: 0.425015]\n",
      "epoch:24 step:23295 [D loss: 0.202978, acc.: 67.19%] [G loss: 0.426661]\n",
      "epoch:24 step:23296 [D loss: 0.247649, acc.: 55.47%] [G loss: 0.377516]\n",
      "epoch:24 step:23297 [D loss: 0.222836, acc.: 65.62%] [G loss: 0.418370]\n",
      "epoch:24 step:23298 [D loss: 0.219622, acc.: 60.16%] [G loss: 0.408653]\n",
      "epoch:24 step:23299 [D loss: 0.209261, acc.: 66.41%] [G loss: 0.446374]\n",
      "epoch:24 step:23300 [D loss: 0.243755, acc.: 56.25%] [G loss: 0.424572]\n",
      "epoch:24 step:23301 [D loss: 0.236249, acc.: 63.28%] [G loss: 0.420183]\n",
      "epoch:24 step:23302 [D loss: 0.213512, acc.: 64.84%] [G loss: 0.460259]\n",
      "epoch:24 step:23303 [D loss: 0.231920, acc.: 61.72%] [G loss: 0.486911]\n",
      "epoch:24 step:23304 [D loss: 0.224170, acc.: 63.28%] [G loss: 0.483342]\n",
      "epoch:24 step:23305 [D loss: 0.226266, acc.: 63.28%] [G loss: 0.463165]\n",
      "epoch:24 step:23306 [D loss: 0.244816, acc.: 60.16%] [G loss: 0.436932]\n",
      "epoch:24 step:23307 [D loss: 0.204902, acc.: 70.31%] [G loss: 0.407293]\n",
      "epoch:24 step:23308 [D loss: 0.257594, acc.: 57.03%] [G loss: 0.408227]\n",
      "epoch:24 step:23309 [D loss: 0.227470, acc.: 61.72%] [G loss: 0.406052]\n",
      "epoch:24 step:23310 [D loss: 0.207402, acc.: 69.53%] [G loss: 0.422247]\n",
      "epoch:24 step:23311 [D loss: 0.202599, acc.: 71.88%] [G loss: 0.420275]\n",
      "epoch:24 step:23312 [D loss: 0.224773, acc.: 61.72%] [G loss: 0.404697]\n",
      "epoch:24 step:23313 [D loss: 0.235070, acc.: 58.59%] [G loss: 0.406912]\n",
      "epoch:24 step:23314 [D loss: 0.230610, acc.: 60.94%] [G loss: 0.430127]\n",
      "epoch:24 step:23315 [D loss: 0.223278, acc.: 61.72%] [G loss: 0.436830]\n",
      "epoch:24 step:23316 [D loss: 0.269401, acc.: 50.78%] [G loss: 0.400339]\n",
      "epoch:24 step:23317 [D loss: 0.225904, acc.: 60.16%] [G loss: 0.421789]\n",
      "epoch:24 step:23318 [D loss: 0.229450, acc.: 61.72%] [G loss: 0.388357]\n",
      "epoch:24 step:23319 [D loss: 0.221508, acc.: 66.41%] [G loss: 0.417041]\n",
      "epoch:24 step:23320 [D loss: 0.224515, acc.: 62.50%] [G loss: 0.485559]\n",
      "epoch:24 step:23321 [D loss: 0.212635, acc.: 67.19%] [G loss: 0.465324]\n",
      "epoch:24 step:23322 [D loss: 0.246381, acc.: 54.69%] [G loss: 0.403817]\n",
      "epoch:24 step:23323 [D loss: 0.231325, acc.: 57.03%] [G loss: 0.427201]\n",
      "epoch:24 step:23324 [D loss: 0.218085, acc.: 65.62%] [G loss: 0.411287]\n",
      "epoch:24 step:23325 [D loss: 0.216250, acc.: 61.72%] [G loss: 0.424298]\n",
      "epoch:24 step:23326 [D loss: 0.202782, acc.: 73.44%] [G loss: 0.468212]\n",
      "epoch:24 step:23327 [D loss: 0.214396, acc.: 67.19%] [G loss: 0.474491]\n",
      "epoch:24 step:23328 [D loss: 0.206993, acc.: 66.41%] [G loss: 0.446076]\n",
      "epoch:24 step:23329 [D loss: 0.239659, acc.: 57.03%] [G loss: 0.435407]\n",
      "epoch:24 step:23330 [D loss: 0.185453, acc.: 75.00%] [G loss: 0.438185]\n",
      "epoch:24 step:23331 [D loss: 0.240369, acc.: 57.81%] [G loss: 0.409578]\n",
      "epoch:24 step:23332 [D loss: 0.230067, acc.: 66.41%] [G loss: 0.425997]\n",
      "epoch:24 step:23333 [D loss: 0.213378, acc.: 70.31%] [G loss: 0.405572]\n",
      "epoch:24 step:23334 [D loss: 0.255271, acc.: 57.81%] [G loss: 0.414861]\n",
      "epoch:24 step:23335 [D loss: 0.218563, acc.: 64.84%] [G loss: 0.451765]\n",
      "epoch:24 step:23336 [D loss: 0.228621, acc.: 66.41%] [G loss: 0.426837]\n",
      "epoch:24 step:23337 [D loss: 0.208305, acc.: 67.19%] [G loss: 0.439652]\n",
      "epoch:24 step:23338 [D loss: 0.219105, acc.: 60.16%] [G loss: 0.449335]\n",
      "epoch:24 step:23339 [D loss: 0.240618, acc.: 56.25%] [G loss: 0.433039]\n",
      "epoch:24 step:23340 [D loss: 0.233071, acc.: 60.94%] [G loss: 0.422790]\n",
      "epoch:24 step:23341 [D loss: 0.209974, acc.: 71.09%] [G loss: 0.479478]\n",
      "epoch:24 step:23342 [D loss: 0.239668, acc.: 62.50%] [G loss: 0.449683]\n",
      "epoch:24 step:23343 [D loss: 0.241826, acc.: 55.47%] [G loss: 0.457250]\n",
      "epoch:24 step:23344 [D loss: 0.226984, acc.: 65.62%] [G loss: 0.417478]\n",
      "epoch:24 step:23345 [D loss: 0.206926, acc.: 68.75%] [G loss: 0.457492]\n",
      "epoch:24 step:23346 [D loss: 0.244965, acc.: 50.78%] [G loss: 0.456740]\n",
      "epoch:24 step:23347 [D loss: 0.240430, acc.: 60.16%] [G loss: 0.433570]\n",
      "epoch:24 step:23348 [D loss: 0.210029, acc.: 69.53%] [G loss: 0.438318]\n",
      "epoch:24 step:23349 [D loss: 0.250911, acc.: 56.25%] [G loss: 0.426429]\n",
      "epoch:24 step:23350 [D loss: 0.237964, acc.: 57.81%] [G loss: 0.395109]\n",
      "epoch:24 step:23351 [D loss: 0.221375, acc.: 57.81%] [G loss: 0.404158]\n",
      "epoch:24 step:23352 [D loss: 0.229643, acc.: 59.38%] [G loss: 0.403665]\n",
      "epoch:24 step:23353 [D loss: 0.253202, acc.: 55.47%] [G loss: 0.386842]\n",
      "epoch:24 step:23354 [D loss: 0.245627, acc.: 57.81%] [G loss: 0.383427]\n",
      "epoch:24 step:23355 [D loss: 0.234290, acc.: 60.16%] [G loss: 0.444933]\n",
      "epoch:24 step:23356 [D loss: 0.249501, acc.: 51.56%] [G loss: 0.418750]\n",
      "epoch:24 step:23357 [D loss: 0.244475, acc.: 56.25%] [G loss: 0.436599]\n",
      "epoch:24 step:23358 [D loss: 0.210858, acc.: 67.19%] [G loss: 0.427532]\n",
      "epoch:24 step:23359 [D loss: 0.204956, acc.: 68.75%] [G loss: 0.385358]\n",
      "epoch:24 step:23360 [D loss: 0.202806, acc.: 71.88%] [G loss: 0.433157]\n",
      "epoch:24 step:23361 [D loss: 0.227100, acc.: 60.16%] [G loss: 0.388506]\n",
      "epoch:24 step:23362 [D loss: 0.222585, acc.: 66.41%] [G loss: 0.413332]\n",
      "epoch:24 step:23363 [D loss: 0.205511, acc.: 66.41%] [G loss: 0.421155]\n",
      "epoch:24 step:23364 [D loss: 0.209499, acc.: 68.75%] [G loss: 0.423195]\n",
      "epoch:24 step:23365 [D loss: 0.233796, acc.: 53.12%] [G loss: 0.414898]\n",
      "epoch:24 step:23366 [D loss: 0.216404, acc.: 64.84%] [G loss: 0.451304]\n",
      "epoch:24 step:23367 [D loss: 0.220731, acc.: 64.06%] [G loss: 0.455767]\n",
      "epoch:24 step:23368 [D loss: 0.251676, acc.: 53.12%] [G loss: 0.435204]\n",
      "epoch:24 step:23369 [D loss: 0.220846, acc.: 67.97%] [G loss: 0.405529]\n",
      "epoch:24 step:23370 [D loss: 0.226764, acc.: 63.28%] [G loss: 0.465620]\n",
      "epoch:24 step:23371 [D loss: 0.236309, acc.: 57.81%] [G loss: 0.424161]\n",
      "epoch:24 step:23372 [D loss: 0.208676, acc.: 67.97%] [G loss: 0.416740]\n",
      "epoch:24 step:23373 [D loss: 0.217095, acc.: 63.28%] [G loss: 0.431019]\n",
      "epoch:24 step:23374 [D loss: 0.188547, acc.: 73.44%] [G loss: 0.504089]\n",
      "epoch:24 step:23375 [D loss: 0.213432, acc.: 63.28%] [G loss: 0.481420]\n",
      "epoch:24 step:23376 [D loss: 0.240619, acc.: 60.16%] [G loss: 0.478721]\n",
      "epoch:24 step:23377 [D loss: 0.220822, acc.: 62.50%] [G loss: 0.436192]\n",
      "epoch:24 step:23378 [D loss: 0.205201, acc.: 68.75%] [G loss: 0.462885]\n",
      "epoch:24 step:23379 [D loss: 0.254629, acc.: 56.25%] [G loss: 0.404465]\n",
      "epoch:24 step:23380 [D loss: 0.238660, acc.: 56.25%] [G loss: 0.432133]\n",
      "epoch:24 step:23381 [D loss: 0.219344, acc.: 62.50%] [G loss: 0.441088]\n",
      "epoch:24 step:23382 [D loss: 0.204786, acc.: 71.88%] [G loss: 0.481162]\n",
      "epoch:24 step:23383 [D loss: 0.204401, acc.: 65.62%] [G loss: 0.438971]\n",
      "epoch:24 step:23384 [D loss: 0.215498, acc.: 67.97%] [G loss: 0.438266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23385 [D loss: 0.196296, acc.: 68.75%] [G loss: 0.490667]\n",
      "epoch:24 step:23386 [D loss: 0.217109, acc.: 63.28%] [G loss: 0.449956]\n",
      "epoch:24 step:23387 [D loss: 0.184745, acc.: 74.22%] [G loss: 0.462876]\n",
      "epoch:24 step:23388 [D loss: 0.211864, acc.: 71.09%] [G loss: 0.434203]\n",
      "epoch:24 step:23389 [D loss: 0.221027, acc.: 64.06%] [G loss: 0.444321]\n",
      "epoch:24 step:23390 [D loss: 0.209507, acc.: 68.75%] [G loss: 0.478754]\n",
      "epoch:24 step:23391 [D loss: 0.232482, acc.: 64.06%] [G loss: 0.450161]\n",
      "epoch:24 step:23392 [D loss: 0.212365, acc.: 69.53%] [G loss: 0.448154]\n",
      "epoch:24 step:23393 [D loss: 0.191556, acc.: 76.56%] [G loss: 0.436677]\n",
      "epoch:24 step:23394 [D loss: 0.217580, acc.: 66.41%] [G loss: 0.404592]\n",
      "epoch:24 step:23395 [D loss: 0.240048, acc.: 64.06%] [G loss: 0.446161]\n",
      "epoch:24 step:23396 [D loss: 0.192259, acc.: 73.44%] [G loss: 0.427071]\n",
      "epoch:24 step:23397 [D loss: 0.210346, acc.: 70.31%] [G loss: 0.441526]\n",
      "epoch:24 step:23398 [D loss: 0.237741, acc.: 59.38%] [G loss: 0.452167]\n",
      "epoch:24 step:23399 [D loss: 0.196812, acc.: 71.88%] [G loss: 0.465554]\n",
      "epoch:24 step:23400 [D loss: 0.208855, acc.: 67.19%] [G loss: 0.485170]\n",
      "epoch:24 step:23401 [D loss: 0.239154, acc.: 59.38%] [G loss: 0.484741]\n",
      "epoch:24 step:23402 [D loss: 0.221213, acc.: 66.41%] [G loss: 0.446547]\n",
      "epoch:24 step:23403 [D loss: 0.258589, acc.: 53.91%] [G loss: 0.428055]\n",
      "epoch:24 step:23404 [D loss: 0.221276, acc.: 64.06%] [G loss: 0.433872]\n",
      "epoch:24 step:23405 [D loss: 0.222131, acc.: 62.50%] [G loss: 0.407824]\n",
      "epoch:24 step:23406 [D loss: 0.197142, acc.: 69.53%] [G loss: 0.443497]\n",
      "epoch:24 step:23407 [D loss: 0.208888, acc.: 64.84%] [G loss: 0.448261]\n",
      "epoch:24 step:23408 [D loss: 0.277426, acc.: 49.22%] [G loss: 0.412769]\n",
      "epoch:24 step:23409 [D loss: 0.218099, acc.: 62.50%] [G loss: 0.430913]\n",
      "epoch:24 step:23410 [D loss: 0.230316, acc.: 58.59%] [G loss: 0.444052]\n",
      "epoch:24 step:23411 [D loss: 0.198023, acc.: 72.66%] [G loss: 0.431934]\n",
      "epoch:24 step:23412 [D loss: 0.193718, acc.: 75.00%] [G loss: 0.446011]\n",
      "epoch:24 step:23413 [D loss: 0.205105, acc.: 71.88%] [G loss: 0.502036]\n",
      "epoch:24 step:23414 [D loss: 0.182942, acc.: 72.66%] [G loss: 0.487404]\n",
      "epoch:24 step:23415 [D loss: 0.197370, acc.: 68.75%] [G loss: 0.507314]\n",
      "epoch:24 step:23416 [D loss: 0.311663, acc.: 55.47%] [G loss: 0.524823]\n",
      "epoch:24 step:23417 [D loss: 0.233740, acc.: 57.81%] [G loss: 0.623227]\n",
      "epoch:24 step:23418 [D loss: 0.213037, acc.: 64.84%] [G loss: 0.549825]\n",
      "epoch:24 step:23419 [D loss: 0.221908, acc.: 64.06%] [G loss: 0.452107]\n",
      "epoch:24 step:23420 [D loss: 0.256990, acc.: 55.47%] [G loss: 0.438162]\n",
      "epoch:24 step:23421 [D loss: 0.210450, acc.: 64.06%] [G loss: 0.444707]\n",
      "epoch:24 step:23422 [D loss: 0.227301, acc.: 65.62%] [G loss: 0.478500]\n",
      "epoch:24 step:23423 [D loss: 0.208968, acc.: 67.19%] [G loss: 0.459580]\n",
      "epoch:24 step:23424 [D loss: 0.163289, acc.: 75.00%] [G loss: 0.536074]\n",
      "epoch:24 step:23425 [D loss: 0.175396, acc.: 80.47%] [G loss: 0.542407]\n",
      "epoch:25 step:23426 [D loss: 0.240361, acc.: 62.50%] [G loss: 0.527024]\n",
      "epoch:25 step:23427 [D loss: 0.269584, acc.: 62.50%] [G loss: 0.499443]\n",
      "epoch:25 step:23428 [D loss: 0.224702, acc.: 63.28%] [G loss: 0.506435]\n",
      "epoch:25 step:23429 [D loss: 0.239275, acc.: 57.03%] [G loss: 0.468153]\n",
      "epoch:25 step:23430 [D loss: 0.233839, acc.: 57.81%] [G loss: 0.398640]\n",
      "epoch:25 step:23431 [D loss: 0.245135, acc.: 56.25%] [G loss: 0.411674]\n",
      "epoch:25 step:23432 [D loss: 0.214487, acc.: 64.06%] [G loss: 0.469789]\n",
      "epoch:25 step:23433 [D loss: 0.215100, acc.: 67.97%] [G loss: 0.445519]\n",
      "epoch:25 step:23434 [D loss: 0.213121, acc.: 64.84%] [G loss: 0.443626]\n",
      "epoch:25 step:23435 [D loss: 0.208354, acc.: 66.41%] [G loss: 0.495431]\n",
      "epoch:25 step:23436 [D loss: 0.232273, acc.: 63.28%] [G loss: 0.434831]\n",
      "epoch:25 step:23437 [D loss: 0.216900, acc.: 67.19%] [G loss: 0.451016]\n",
      "epoch:25 step:23438 [D loss: 0.223065, acc.: 68.75%] [G loss: 0.433287]\n",
      "epoch:25 step:23439 [D loss: 0.193389, acc.: 71.09%] [G loss: 0.484905]\n",
      "epoch:25 step:23440 [D loss: 0.170181, acc.: 81.25%] [G loss: 0.439793]\n",
      "epoch:25 step:23441 [D loss: 0.213992, acc.: 69.53%] [G loss: 0.427847]\n",
      "epoch:25 step:23442 [D loss: 0.208684, acc.: 63.28%] [G loss: 0.486252]\n",
      "epoch:25 step:23443 [D loss: 0.234802, acc.: 61.72%] [G loss: 0.456960]\n",
      "epoch:25 step:23444 [D loss: 0.239798, acc.: 60.94%] [G loss: 0.430829]\n",
      "epoch:25 step:23445 [D loss: 0.257519, acc.: 54.69%] [G loss: 0.440447]\n",
      "epoch:25 step:23446 [D loss: 0.224802, acc.: 66.41%] [G loss: 0.467507]\n",
      "epoch:25 step:23447 [D loss: 0.185993, acc.: 70.31%] [G loss: 0.502055]\n",
      "epoch:25 step:23448 [D loss: 0.242793, acc.: 57.03%] [G loss: 0.431333]\n",
      "epoch:25 step:23449 [D loss: 0.212153, acc.: 66.41%] [G loss: 0.390979]\n",
      "epoch:25 step:23450 [D loss: 0.199759, acc.: 64.84%] [G loss: 0.422082]\n",
      "epoch:25 step:23451 [D loss: 0.214674, acc.: 64.84%] [G loss: 0.469101]\n",
      "epoch:25 step:23452 [D loss: 0.251920, acc.: 57.81%] [G loss: 0.421787]\n",
      "epoch:25 step:23453 [D loss: 0.207890, acc.: 67.19%] [G loss: 0.442069]\n",
      "epoch:25 step:23454 [D loss: 0.220575, acc.: 62.50%] [G loss: 0.445070]\n",
      "epoch:25 step:23455 [D loss: 0.207784, acc.: 67.97%] [G loss: 0.450089]\n",
      "epoch:25 step:23456 [D loss: 0.250985, acc.: 50.78%] [G loss: 0.384949]\n",
      "epoch:25 step:23457 [D loss: 0.237310, acc.: 59.38%] [G loss: 0.430316]\n",
      "epoch:25 step:23458 [D loss: 0.225683, acc.: 61.72%] [G loss: 0.421477]\n",
      "epoch:25 step:23459 [D loss: 0.252476, acc.: 53.91%] [G loss: 0.405559]\n",
      "epoch:25 step:23460 [D loss: 0.236157, acc.: 57.81%] [G loss: 0.375612]\n",
      "epoch:25 step:23461 [D loss: 0.204568, acc.: 68.75%] [G loss: 0.436371]\n",
      "epoch:25 step:23462 [D loss: 0.221132, acc.: 64.06%] [G loss: 0.428915]\n",
      "epoch:25 step:23463 [D loss: 0.274402, acc.: 53.91%] [G loss: 0.414157]\n",
      "epoch:25 step:23464 [D loss: 0.235562, acc.: 56.25%] [G loss: 0.417477]\n",
      "epoch:25 step:23465 [D loss: 0.189950, acc.: 68.75%] [G loss: 0.420595]\n",
      "epoch:25 step:23466 [D loss: 0.242246, acc.: 55.47%] [G loss: 0.410604]\n",
      "epoch:25 step:23467 [D loss: 0.221597, acc.: 65.62%] [G loss: 0.412298]\n",
      "epoch:25 step:23468 [D loss: 0.221265, acc.: 66.41%] [G loss: 0.437203]\n",
      "epoch:25 step:23469 [D loss: 0.224897, acc.: 64.84%] [G loss: 0.448511]\n",
      "epoch:25 step:23470 [D loss: 0.236189, acc.: 63.28%] [G loss: 0.447329]\n",
      "epoch:25 step:23471 [D loss: 0.216113, acc.: 61.72%] [G loss: 0.451298]\n",
      "epoch:25 step:23472 [D loss: 0.244701, acc.: 56.25%] [G loss: 0.421437]\n",
      "epoch:25 step:23473 [D loss: 0.221399, acc.: 60.94%] [G loss: 0.433552]\n",
      "epoch:25 step:23474 [D loss: 0.232615, acc.: 59.38%] [G loss: 0.415598]\n",
      "epoch:25 step:23475 [D loss: 0.220953, acc.: 64.84%] [G loss: 0.445187]\n",
      "epoch:25 step:23476 [D loss: 0.238461, acc.: 60.16%] [G loss: 0.425728]\n",
      "epoch:25 step:23477 [D loss: 0.237393, acc.: 62.50%] [G loss: 0.419145]\n",
      "epoch:25 step:23478 [D loss: 0.207493, acc.: 69.53%] [G loss: 0.444866]\n",
      "epoch:25 step:23479 [D loss: 0.222940, acc.: 60.16%] [G loss: 0.427125]\n",
      "epoch:25 step:23480 [D loss: 0.226115, acc.: 59.38%] [G loss: 0.439491]\n",
      "epoch:25 step:23481 [D loss: 0.199478, acc.: 73.44%] [G loss: 0.442183]\n",
      "epoch:25 step:23482 [D loss: 0.247859, acc.: 58.59%] [G loss: 0.404579]\n",
      "epoch:25 step:23483 [D loss: 0.217752, acc.: 64.84%] [G loss: 0.430300]\n",
      "epoch:25 step:23484 [D loss: 0.211104, acc.: 69.53%] [G loss: 0.434395]\n",
      "epoch:25 step:23485 [D loss: 0.236035, acc.: 57.03%] [G loss: 0.428714]\n",
      "epoch:25 step:23486 [D loss: 0.227088, acc.: 62.50%] [G loss: 0.408267]\n",
      "epoch:25 step:23487 [D loss: 0.238586, acc.: 58.59%] [G loss: 0.424995]\n",
      "epoch:25 step:23488 [D loss: 0.214310, acc.: 63.28%] [G loss: 0.413797]\n",
      "epoch:25 step:23489 [D loss: 0.243915, acc.: 59.38%] [G loss: 0.415326]\n",
      "epoch:25 step:23490 [D loss: 0.239766, acc.: 59.38%] [G loss: 0.388890]\n",
      "epoch:25 step:23491 [D loss: 0.229117, acc.: 60.16%] [G loss: 0.417891]\n",
      "epoch:25 step:23492 [D loss: 0.210359, acc.: 66.41%] [G loss: 0.456934]\n",
      "epoch:25 step:23493 [D loss: 0.239770, acc.: 58.59%] [G loss: 0.390189]\n",
      "epoch:25 step:23494 [D loss: 0.200007, acc.: 67.19%] [G loss: 0.399606]\n",
      "epoch:25 step:23495 [D loss: 0.216329, acc.: 64.06%] [G loss: 0.444023]\n",
      "epoch:25 step:23496 [D loss: 0.251035, acc.: 53.12%] [G loss: 0.437093]\n",
      "epoch:25 step:23497 [D loss: 0.250406, acc.: 57.03%] [G loss: 0.426036]\n",
      "epoch:25 step:23498 [D loss: 0.241376, acc.: 57.81%] [G loss: 0.373903]\n",
      "epoch:25 step:23499 [D loss: 0.177801, acc.: 77.34%] [G loss: 0.490367]\n",
      "epoch:25 step:23500 [D loss: 0.212766, acc.: 64.06%] [G loss: 0.435623]\n",
      "epoch:25 step:23501 [D loss: 0.173221, acc.: 78.12%] [G loss: 0.448551]\n",
      "epoch:25 step:23502 [D loss: 0.203547, acc.: 66.41%] [G loss: 0.485499]\n",
      "epoch:25 step:23503 [D loss: 0.256990, acc.: 54.69%] [G loss: 0.396497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23504 [D loss: 0.221689, acc.: 59.38%] [G loss: 0.397977]\n",
      "epoch:25 step:23505 [D loss: 0.213454, acc.: 67.97%] [G loss: 0.403788]\n",
      "epoch:25 step:23506 [D loss: 0.256051, acc.: 50.00%] [G loss: 0.403581]\n",
      "epoch:25 step:23507 [D loss: 0.219440, acc.: 63.28%] [G loss: 0.399164]\n",
      "epoch:25 step:23508 [D loss: 0.208651, acc.: 67.19%] [G loss: 0.441788]\n",
      "epoch:25 step:23509 [D loss: 0.213599, acc.: 63.28%] [G loss: 0.446376]\n",
      "epoch:25 step:23510 [D loss: 0.232013, acc.: 58.59%] [G loss: 0.475191]\n",
      "epoch:25 step:23511 [D loss: 0.232266, acc.: 60.16%] [G loss: 0.439246]\n",
      "epoch:25 step:23512 [D loss: 0.227919, acc.: 60.94%] [G loss: 0.397373]\n",
      "epoch:25 step:23513 [D loss: 0.222678, acc.: 64.06%] [G loss: 0.440254]\n",
      "epoch:25 step:23514 [D loss: 0.222705, acc.: 64.06%] [G loss: 0.472309]\n",
      "epoch:25 step:23515 [D loss: 0.219515, acc.: 61.72%] [G loss: 0.453099]\n",
      "epoch:25 step:23516 [D loss: 0.240264, acc.: 57.81%] [G loss: 0.486959]\n",
      "epoch:25 step:23517 [D loss: 0.232632, acc.: 60.16%] [G loss: 0.423584]\n",
      "epoch:25 step:23518 [D loss: 0.199399, acc.: 68.75%] [G loss: 0.440497]\n",
      "epoch:25 step:23519 [D loss: 0.251110, acc.: 55.47%] [G loss: 0.450046]\n",
      "epoch:25 step:23520 [D loss: 0.230408, acc.: 61.72%] [G loss: 0.434235]\n",
      "epoch:25 step:23521 [D loss: 0.239655, acc.: 60.16%] [G loss: 0.420755]\n",
      "epoch:25 step:23522 [D loss: 0.215635, acc.: 65.62%] [G loss: 0.479801]\n",
      "epoch:25 step:23523 [D loss: 0.216719, acc.: 65.62%] [G loss: 0.459303]\n",
      "epoch:25 step:23524 [D loss: 0.241896, acc.: 57.03%] [G loss: 0.390378]\n",
      "epoch:25 step:23525 [D loss: 0.180501, acc.: 71.09%] [G loss: 0.443702]\n",
      "epoch:25 step:23526 [D loss: 0.230784, acc.: 56.25%] [G loss: 0.429774]\n",
      "epoch:25 step:23527 [D loss: 0.236330, acc.: 64.06%] [G loss: 0.414554]\n",
      "epoch:25 step:23528 [D loss: 0.227819, acc.: 57.03%] [G loss: 0.406356]\n",
      "epoch:25 step:23529 [D loss: 0.237635, acc.: 60.94%] [G loss: 0.412185]\n",
      "epoch:25 step:23530 [D loss: 0.217924, acc.: 65.62%] [G loss: 0.397608]\n",
      "epoch:25 step:23531 [D loss: 0.199899, acc.: 67.19%] [G loss: 0.412378]\n",
      "epoch:25 step:23532 [D loss: 0.200648, acc.: 67.97%] [G loss: 0.468993]\n",
      "epoch:25 step:23533 [D loss: 0.261236, acc.: 57.03%] [G loss: 0.489086]\n",
      "epoch:25 step:23534 [D loss: 0.259459, acc.: 53.12%] [G loss: 0.378853]\n",
      "epoch:25 step:23535 [D loss: 0.234566, acc.: 60.94%] [G loss: 0.377613]\n",
      "epoch:25 step:23536 [D loss: 0.210260, acc.: 64.06%] [G loss: 0.432075]\n",
      "epoch:25 step:23537 [D loss: 0.208672, acc.: 65.62%] [G loss: 0.401055]\n",
      "epoch:25 step:23538 [D loss: 0.195751, acc.: 67.19%] [G loss: 0.491408]\n",
      "epoch:25 step:23539 [D loss: 0.197214, acc.: 68.75%] [G loss: 0.469435]\n",
      "epoch:25 step:23540 [D loss: 0.182387, acc.: 78.12%] [G loss: 0.469625]\n",
      "epoch:25 step:23541 [D loss: 0.212874, acc.: 64.06%] [G loss: 0.479056]\n",
      "epoch:25 step:23542 [D loss: 0.204537, acc.: 67.19%] [G loss: 0.473889]\n",
      "epoch:25 step:23543 [D loss: 0.223698, acc.: 61.72%] [G loss: 0.484575]\n",
      "epoch:25 step:23544 [D loss: 0.194687, acc.: 68.75%] [G loss: 0.462395]\n",
      "epoch:25 step:23545 [D loss: 0.242877, acc.: 60.16%] [G loss: 0.471778]\n",
      "epoch:25 step:23546 [D loss: 0.240568, acc.: 60.16%] [G loss: 0.406144]\n",
      "epoch:25 step:23547 [D loss: 0.187428, acc.: 71.88%] [G loss: 0.460044]\n",
      "epoch:25 step:23548 [D loss: 0.220003, acc.: 66.41%] [G loss: 0.444691]\n",
      "epoch:25 step:23549 [D loss: 0.256839, acc.: 51.56%] [G loss: 0.443603]\n",
      "epoch:25 step:23550 [D loss: 0.250977, acc.: 55.47%] [G loss: 0.395856]\n",
      "epoch:25 step:23551 [D loss: 0.192950, acc.: 71.88%] [G loss: 0.432747]\n",
      "epoch:25 step:23552 [D loss: 0.202425, acc.: 69.53%] [G loss: 0.432068]\n",
      "epoch:25 step:23553 [D loss: 0.226390, acc.: 62.50%] [G loss: 0.416965]\n",
      "epoch:25 step:23554 [D loss: 0.220909, acc.: 61.72%] [G loss: 0.386613]\n",
      "epoch:25 step:23555 [D loss: 0.192727, acc.: 74.22%] [G loss: 0.413188]\n",
      "epoch:25 step:23556 [D loss: 0.199035, acc.: 72.66%] [G loss: 0.445012]\n",
      "epoch:25 step:23557 [D loss: 0.221310, acc.: 65.62%] [G loss: 0.408405]\n",
      "epoch:25 step:23558 [D loss: 0.249353, acc.: 58.59%] [G loss: 0.396221]\n",
      "epoch:25 step:23559 [D loss: 0.222351, acc.: 64.84%] [G loss: 0.445422]\n",
      "epoch:25 step:23560 [D loss: 0.215402, acc.: 59.38%] [G loss: 0.442717]\n",
      "epoch:25 step:23561 [D loss: 0.203268, acc.: 68.75%] [G loss: 0.479728]\n",
      "epoch:25 step:23562 [D loss: 0.257658, acc.: 55.47%] [G loss: 0.401744]\n",
      "epoch:25 step:23563 [D loss: 0.248241, acc.: 53.91%] [G loss: 0.417331]\n",
      "epoch:25 step:23564 [D loss: 0.232910, acc.: 58.59%] [G loss: 0.408491]\n",
      "epoch:25 step:23565 [D loss: 0.225249, acc.: 60.16%] [G loss: 0.412838]\n",
      "epoch:25 step:23566 [D loss: 0.234222, acc.: 60.94%] [G loss: 0.466885]\n",
      "epoch:25 step:23567 [D loss: 0.226313, acc.: 59.38%] [G loss: 0.396675]\n",
      "epoch:25 step:23568 [D loss: 0.233969, acc.: 60.16%] [G loss: 0.411661]\n",
      "epoch:25 step:23569 [D loss: 0.221713, acc.: 64.06%] [G loss: 0.401832]\n",
      "epoch:25 step:23570 [D loss: 0.224904, acc.: 61.72%] [G loss: 0.449697]\n",
      "epoch:25 step:23571 [D loss: 0.231858, acc.: 63.28%] [G loss: 0.498585]\n",
      "epoch:25 step:23572 [D loss: 0.222762, acc.: 61.72%] [G loss: 0.456883]\n",
      "epoch:25 step:23573 [D loss: 0.263812, acc.: 50.78%] [G loss: 0.406056]\n",
      "epoch:25 step:23574 [D loss: 0.224570, acc.: 63.28%] [G loss: 0.392619]\n",
      "epoch:25 step:23575 [D loss: 0.250013, acc.: 57.03%] [G loss: 0.390744]\n",
      "epoch:25 step:23576 [D loss: 0.208089, acc.: 70.31%] [G loss: 0.413018]\n",
      "epoch:25 step:23577 [D loss: 0.216348, acc.: 67.19%] [G loss: 0.440937]\n",
      "epoch:25 step:23578 [D loss: 0.296206, acc.: 46.09%] [G loss: 0.420827]\n",
      "epoch:25 step:23579 [D loss: 0.216625, acc.: 67.97%] [G loss: 0.452934]\n",
      "epoch:25 step:23580 [D loss: 0.208676, acc.: 64.84%] [G loss: 0.445530]\n",
      "epoch:25 step:23581 [D loss: 0.188389, acc.: 72.66%] [G loss: 0.464705]\n",
      "epoch:25 step:23582 [D loss: 0.228742, acc.: 62.50%] [G loss: 0.427685]\n",
      "epoch:25 step:23583 [D loss: 0.198152, acc.: 74.22%] [G loss: 0.438868]\n",
      "epoch:25 step:23584 [D loss: 0.207471, acc.: 69.53%] [G loss: 0.445876]\n",
      "epoch:25 step:23585 [D loss: 0.267951, acc.: 53.91%] [G loss: 0.428043]\n",
      "epoch:25 step:23586 [D loss: 0.237192, acc.: 56.25%] [G loss: 0.537354]\n",
      "epoch:25 step:23587 [D loss: 0.262712, acc.: 50.78%] [G loss: 0.466861]\n",
      "epoch:25 step:23588 [D loss: 0.219125, acc.: 60.94%] [G loss: 0.426398]\n",
      "epoch:25 step:23589 [D loss: 0.231354, acc.: 64.84%] [G loss: 0.461045]\n",
      "epoch:25 step:23590 [D loss: 0.215321, acc.: 63.28%] [G loss: 0.411184]\n",
      "epoch:25 step:23591 [D loss: 0.222884, acc.: 65.62%] [G loss: 0.403057]\n",
      "epoch:25 step:23592 [D loss: 0.225558, acc.: 59.38%] [G loss: 0.401591]\n",
      "epoch:25 step:23593 [D loss: 0.225582, acc.: 65.62%] [G loss: 0.413030]\n",
      "epoch:25 step:23594 [D loss: 0.218601, acc.: 68.75%] [G loss: 0.448608]\n",
      "epoch:25 step:23595 [D loss: 0.244441, acc.: 60.94%] [G loss: 0.409050]\n",
      "epoch:25 step:23596 [D loss: 0.220150, acc.: 59.38%] [G loss: 0.447596]\n",
      "epoch:25 step:23597 [D loss: 0.212370, acc.: 65.62%] [G loss: 0.455144]\n",
      "epoch:25 step:23598 [D loss: 0.221986, acc.: 65.62%] [G loss: 0.426939]\n",
      "epoch:25 step:23599 [D loss: 0.228055, acc.: 62.50%] [G loss: 0.442771]\n",
      "epoch:25 step:23600 [D loss: 0.238649, acc.: 59.38%] [G loss: 0.415031]\n",
      "epoch:25 step:23601 [D loss: 0.215146, acc.: 65.62%] [G loss: 0.411980]\n",
      "epoch:25 step:23602 [D loss: 0.235106, acc.: 60.16%] [G loss: 0.395764]\n",
      "epoch:25 step:23603 [D loss: 0.246099, acc.: 60.16%] [G loss: 0.388446]\n",
      "epoch:25 step:23604 [D loss: 0.251772, acc.: 52.34%] [G loss: 0.387129]\n",
      "epoch:25 step:23605 [D loss: 0.218020, acc.: 66.41%] [G loss: 0.443004]\n",
      "epoch:25 step:23606 [D loss: 0.234173, acc.: 59.38%] [G loss: 0.399046]\n",
      "epoch:25 step:23607 [D loss: 0.216398, acc.: 63.28%] [G loss: 0.425997]\n",
      "epoch:25 step:23608 [D loss: 0.213878, acc.: 68.75%] [G loss: 0.415703]\n",
      "epoch:25 step:23609 [D loss: 0.237281, acc.: 57.81%] [G loss: 0.412055]\n",
      "epoch:25 step:23610 [D loss: 0.234522, acc.: 64.06%] [G loss: 0.426522]\n",
      "epoch:25 step:23611 [D loss: 0.246301, acc.: 56.25%] [G loss: 0.402333]\n",
      "epoch:25 step:23612 [D loss: 0.226602, acc.: 61.72%] [G loss: 0.417374]\n",
      "epoch:25 step:23613 [D loss: 0.250686, acc.: 53.91%] [G loss: 0.392841]\n",
      "epoch:25 step:23614 [D loss: 0.249786, acc.: 59.38%] [G loss: 0.370023]\n",
      "epoch:25 step:23615 [D loss: 0.181498, acc.: 78.91%] [G loss: 0.453259]\n",
      "epoch:25 step:23616 [D loss: 0.206089, acc.: 70.31%] [G loss: 0.446229]\n",
      "epoch:25 step:23617 [D loss: 0.205038, acc.: 71.88%] [G loss: 0.424727]\n",
      "epoch:25 step:23618 [D loss: 0.206137, acc.: 67.19%] [G loss: 0.450347]\n",
      "epoch:25 step:23619 [D loss: 0.218195, acc.: 67.19%] [G loss: 0.432099]\n",
      "epoch:25 step:23620 [D loss: 0.241877, acc.: 62.50%] [G loss: 0.462277]\n",
      "epoch:25 step:23621 [D loss: 0.231423, acc.: 64.84%] [G loss: 0.435256]\n",
      "epoch:25 step:23622 [D loss: 0.210672, acc.: 69.53%] [G loss: 0.402687]\n",
      "epoch:25 step:23623 [D loss: 0.199089, acc.: 71.88%] [G loss: 0.435383]\n",
      "epoch:25 step:23624 [D loss: 0.209700, acc.: 67.19%] [G loss: 0.446565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23625 [D loss: 0.230802, acc.: 60.94%] [G loss: 0.427578]\n",
      "epoch:25 step:23626 [D loss: 0.204147, acc.: 67.97%] [G loss: 0.429489]\n",
      "epoch:25 step:23627 [D loss: 0.235576, acc.: 63.28%] [G loss: 0.376938]\n",
      "epoch:25 step:23628 [D loss: 0.265457, acc.: 51.56%] [G loss: 0.434556]\n",
      "epoch:25 step:23629 [D loss: 0.238692, acc.: 59.38%] [G loss: 0.451411]\n",
      "epoch:25 step:23630 [D loss: 0.195463, acc.: 74.22%] [G loss: 0.526140]\n",
      "epoch:25 step:23631 [D loss: 0.230459, acc.: 64.06%] [G loss: 0.428971]\n",
      "epoch:25 step:23632 [D loss: 0.237184, acc.: 63.28%] [G loss: 0.434497]\n",
      "epoch:25 step:23633 [D loss: 0.176609, acc.: 71.88%] [G loss: 0.460735]\n",
      "epoch:25 step:23634 [D loss: 0.195699, acc.: 74.22%] [G loss: 0.463248]\n",
      "epoch:25 step:23635 [D loss: 0.281091, acc.: 49.22%] [G loss: 0.412460]\n",
      "epoch:25 step:23636 [D loss: 0.231317, acc.: 60.16%] [G loss: 0.406511]\n",
      "epoch:25 step:23637 [D loss: 0.232371, acc.: 63.28%] [G loss: 0.400056]\n",
      "epoch:25 step:23638 [D loss: 0.225800, acc.: 63.28%] [G loss: 0.430699]\n",
      "epoch:25 step:23639 [D loss: 0.235942, acc.: 61.72%] [G loss: 0.375459]\n",
      "epoch:25 step:23640 [D loss: 0.243345, acc.: 50.78%] [G loss: 0.386799]\n",
      "epoch:25 step:23641 [D loss: 0.214304, acc.: 61.72%] [G loss: 0.397404]\n",
      "epoch:25 step:23642 [D loss: 0.218079, acc.: 63.28%] [G loss: 0.441461]\n",
      "epoch:25 step:23643 [D loss: 0.200869, acc.: 77.34%] [G loss: 0.447706]\n",
      "epoch:25 step:23644 [D loss: 0.192832, acc.: 73.44%] [G loss: 0.460827]\n",
      "epoch:25 step:23645 [D loss: 0.258516, acc.: 54.69%] [G loss: 0.500754]\n",
      "epoch:25 step:23646 [D loss: 0.209153, acc.: 63.28%] [G loss: 0.445820]\n",
      "epoch:25 step:23647 [D loss: 0.227297, acc.: 64.06%] [G loss: 0.452642]\n",
      "epoch:25 step:23648 [D loss: 0.199767, acc.: 73.44%] [G loss: 0.460624]\n",
      "epoch:25 step:23649 [D loss: 0.252104, acc.: 57.81%] [G loss: 0.431515]\n",
      "epoch:25 step:23650 [D loss: 0.210426, acc.: 65.62%] [G loss: 0.455532]\n",
      "epoch:25 step:23651 [D loss: 0.226216, acc.: 60.94%] [G loss: 0.398050]\n",
      "epoch:25 step:23652 [D loss: 0.240239, acc.: 57.81%] [G loss: 0.391084]\n",
      "epoch:25 step:23653 [D loss: 0.239636, acc.: 57.03%] [G loss: 0.427368]\n",
      "epoch:25 step:23654 [D loss: 0.214765, acc.: 64.84%] [G loss: 0.430694]\n",
      "epoch:25 step:23655 [D loss: 0.221731, acc.: 62.50%] [G loss: 0.420228]\n",
      "epoch:25 step:23656 [D loss: 0.191400, acc.: 70.31%] [G loss: 0.483079]\n",
      "epoch:25 step:23657 [D loss: 0.180838, acc.: 75.78%] [G loss: 0.503621]\n",
      "epoch:25 step:23658 [D loss: 0.219662, acc.: 67.19%] [G loss: 0.473833]\n",
      "epoch:25 step:23659 [D loss: 0.258819, acc.: 56.25%] [G loss: 0.441158]\n",
      "epoch:25 step:23660 [D loss: 0.228867, acc.: 62.50%] [G loss: 0.441880]\n",
      "epoch:25 step:23661 [D loss: 0.221899, acc.: 61.72%] [G loss: 0.422017]\n",
      "epoch:25 step:23662 [D loss: 0.230046, acc.: 61.72%] [G loss: 0.399710]\n",
      "epoch:25 step:23663 [D loss: 0.226960, acc.: 60.16%] [G loss: 0.433253]\n",
      "epoch:25 step:23664 [D loss: 0.200223, acc.: 72.66%] [G loss: 0.438864]\n",
      "epoch:25 step:23665 [D loss: 0.237821, acc.: 63.28%] [G loss: 0.431624]\n",
      "epoch:25 step:23666 [D loss: 0.196230, acc.: 72.66%] [G loss: 0.464253]\n",
      "epoch:25 step:23667 [D loss: 0.219719, acc.: 66.41%] [G loss: 0.493312]\n",
      "epoch:25 step:23668 [D loss: 0.226925, acc.: 60.16%] [G loss: 0.420453]\n",
      "epoch:25 step:23669 [D loss: 0.238071, acc.: 58.59%] [G loss: 0.468451]\n",
      "epoch:25 step:23670 [D loss: 0.199497, acc.: 63.28%] [G loss: 0.452374]\n",
      "epoch:25 step:23671 [D loss: 0.231723, acc.: 60.94%] [G loss: 0.462248]\n",
      "epoch:25 step:23672 [D loss: 0.219478, acc.: 67.97%] [G loss: 0.427889]\n",
      "epoch:25 step:23673 [D loss: 0.211158, acc.: 64.84%] [G loss: 0.471413]\n",
      "epoch:25 step:23674 [D loss: 0.279955, acc.: 50.00%] [G loss: 0.475131]\n",
      "epoch:25 step:23675 [D loss: 0.269680, acc.: 54.69%] [G loss: 0.424980]\n",
      "epoch:25 step:23676 [D loss: 0.267877, acc.: 51.56%] [G loss: 0.412201]\n",
      "epoch:25 step:23677 [D loss: 0.221198, acc.: 66.41%] [G loss: 0.463621]\n",
      "epoch:25 step:23678 [D loss: 0.222682, acc.: 65.62%] [G loss: 0.428517]\n",
      "epoch:25 step:23679 [D loss: 0.239107, acc.: 58.59%] [G loss: 0.420816]\n",
      "epoch:25 step:23680 [D loss: 0.219561, acc.: 67.97%] [G loss: 0.419790]\n",
      "epoch:25 step:23681 [D loss: 0.231015, acc.: 69.53%] [G loss: 0.405815]\n",
      "epoch:25 step:23682 [D loss: 0.246322, acc.: 50.78%] [G loss: 0.429226]\n",
      "epoch:25 step:23683 [D loss: 0.193446, acc.: 69.53%] [G loss: 0.416473]\n",
      "epoch:25 step:23684 [D loss: 0.218344, acc.: 64.06%] [G loss: 0.423514]\n",
      "epoch:25 step:23685 [D loss: 0.225998, acc.: 60.94%] [G loss: 0.416200]\n",
      "epoch:25 step:23686 [D loss: 0.201119, acc.: 71.09%] [G loss: 0.433734]\n",
      "epoch:25 step:23687 [D loss: 0.220285, acc.: 67.19%] [G loss: 0.460921]\n",
      "epoch:25 step:23688 [D loss: 0.272906, acc.: 45.31%] [G loss: 0.406736]\n",
      "epoch:25 step:23689 [D loss: 0.207378, acc.: 65.62%] [G loss: 0.435038]\n",
      "epoch:25 step:23690 [D loss: 0.228542, acc.: 61.72%] [G loss: 0.413597]\n",
      "epoch:25 step:23691 [D loss: 0.254371, acc.: 57.81%] [G loss: 0.419382]\n",
      "epoch:25 step:23692 [D loss: 0.238835, acc.: 63.28%] [G loss: 0.417453]\n",
      "epoch:25 step:23693 [D loss: 0.218410, acc.: 67.97%] [G loss: 0.419839]\n",
      "epoch:25 step:23694 [D loss: 0.227855, acc.: 61.72%] [G loss: 0.441349]\n",
      "epoch:25 step:23695 [D loss: 0.219201, acc.: 63.28%] [G loss: 0.418628]\n",
      "epoch:25 step:23696 [D loss: 0.196148, acc.: 68.75%] [G loss: 0.481425]\n",
      "epoch:25 step:23697 [D loss: 0.225533, acc.: 61.72%] [G loss: 0.425866]\n",
      "epoch:25 step:23698 [D loss: 0.225235, acc.: 59.38%] [G loss: 0.406616]\n",
      "epoch:25 step:23699 [D loss: 0.204071, acc.: 71.09%] [G loss: 0.441976]\n",
      "epoch:25 step:23700 [D loss: 0.220298, acc.: 64.06%] [G loss: 0.413778]\n",
      "epoch:25 step:23701 [D loss: 0.228524, acc.: 65.62%] [G loss: 0.419798]\n",
      "epoch:25 step:23702 [D loss: 0.253319, acc.: 57.03%] [G loss: 0.436706]\n",
      "epoch:25 step:23703 [D loss: 0.235779, acc.: 58.59%] [G loss: 0.497250]\n",
      "epoch:25 step:23704 [D loss: 0.221625, acc.: 60.94%] [G loss: 0.452407]\n",
      "epoch:25 step:23705 [D loss: 0.212017, acc.: 64.06%] [G loss: 0.433880]\n",
      "epoch:25 step:23706 [D loss: 0.251308, acc.: 55.47%] [G loss: 0.407552]\n",
      "epoch:25 step:23707 [D loss: 0.244076, acc.: 52.34%] [G loss: 0.405226]\n",
      "epoch:25 step:23708 [D loss: 0.209586, acc.: 66.41%] [G loss: 0.374319]\n",
      "epoch:25 step:23709 [D loss: 0.207765, acc.: 67.97%] [G loss: 0.407438]\n",
      "epoch:25 step:23710 [D loss: 0.213886, acc.: 65.62%] [G loss: 0.436240]\n",
      "epoch:25 step:23711 [D loss: 0.213154, acc.: 64.06%] [G loss: 0.415492]\n",
      "epoch:25 step:23712 [D loss: 0.242130, acc.: 57.81%] [G loss: 0.411581]\n",
      "epoch:25 step:23713 [D loss: 0.209542, acc.: 67.19%] [G loss: 0.470003]\n",
      "epoch:25 step:23714 [D loss: 0.207123, acc.: 67.19%] [G loss: 0.459507]\n",
      "epoch:25 step:23715 [D loss: 0.213084, acc.: 64.84%] [G loss: 0.472350]\n",
      "epoch:25 step:23716 [D loss: 0.242235, acc.: 56.25%] [G loss: 0.421386]\n",
      "epoch:25 step:23717 [D loss: 0.206269, acc.: 68.75%] [G loss: 0.440236]\n",
      "epoch:25 step:23718 [D loss: 0.239147, acc.: 58.59%] [G loss: 0.407151]\n",
      "epoch:25 step:23719 [D loss: 0.231205, acc.: 57.03%] [G loss: 0.463626]\n",
      "epoch:25 step:23720 [D loss: 0.208161, acc.: 61.72%] [G loss: 0.399832]\n",
      "epoch:25 step:23721 [D loss: 0.189606, acc.: 71.88%] [G loss: 0.421920]\n",
      "epoch:25 step:23722 [D loss: 0.209634, acc.: 63.28%] [G loss: 0.439819]\n",
      "epoch:25 step:23723 [D loss: 0.233748, acc.: 65.62%] [G loss: 0.455180]\n",
      "epoch:25 step:23724 [D loss: 0.203271, acc.: 65.62%] [G loss: 0.484586]\n",
      "epoch:25 step:23725 [D loss: 0.209184, acc.: 65.62%] [G loss: 0.428521]\n",
      "epoch:25 step:23726 [D loss: 0.255927, acc.: 56.25%] [G loss: 0.432140]\n",
      "epoch:25 step:23727 [D loss: 0.215234, acc.: 64.84%] [G loss: 0.433911]\n",
      "epoch:25 step:23728 [D loss: 0.227517, acc.: 63.28%] [G loss: 0.394032]\n",
      "epoch:25 step:23729 [D loss: 0.227131, acc.: 57.03%] [G loss: 0.442546]\n",
      "epoch:25 step:23730 [D loss: 0.227850, acc.: 65.62%] [G loss: 0.413829]\n",
      "epoch:25 step:23731 [D loss: 0.196536, acc.: 67.19%] [G loss: 0.456276]\n",
      "epoch:25 step:23732 [D loss: 0.237722, acc.: 59.38%] [G loss: 0.426650]\n",
      "epoch:25 step:23733 [D loss: 0.235859, acc.: 57.81%] [G loss: 0.397288]\n",
      "epoch:25 step:23734 [D loss: 0.219402, acc.: 62.50%] [G loss: 0.410562]\n",
      "epoch:25 step:23735 [D loss: 0.195385, acc.: 68.75%] [G loss: 0.449413]\n",
      "epoch:25 step:23736 [D loss: 0.196436, acc.: 74.22%] [G loss: 0.425001]\n",
      "epoch:25 step:23737 [D loss: 0.199793, acc.: 67.97%] [G loss: 0.448777]\n",
      "epoch:25 step:23738 [D loss: 0.185732, acc.: 71.09%] [G loss: 0.489773]\n",
      "epoch:25 step:23739 [D loss: 0.175317, acc.: 77.34%] [G loss: 0.469188]\n",
      "epoch:25 step:23740 [D loss: 0.201390, acc.: 69.53%] [G loss: 0.445356]\n",
      "epoch:25 step:23741 [D loss: 0.268079, acc.: 53.12%] [G loss: 0.416265]\n",
      "epoch:25 step:23742 [D loss: 0.222516, acc.: 61.72%] [G loss: 0.452040]\n",
      "epoch:25 step:23743 [D loss: 0.223961, acc.: 60.94%] [G loss: 0.423375]\n",
      "epoch:25 step:23744 [D loss: 0.245835, acc.: 57.81%] [G loss: 0.458611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23745 [D loss: 0.234137, acc.: 61.72%] [G loss: 0.413011]\n",
      "epoch:25 step:23746 [D loss: 0.203531, acc.: 70.31%] [G loss: 0.465498]\n",
      "epoch:25 step:23747 [D loss: 0.208064, acc.: 63.28%] [G loss: 0.472048]\n",
      "epoch:25 step:23748 [D loss: 0.240452, acc.: 64.06%] [G loss: 0.417372]\n",
      "epoch:25 step:23749 [D loss: 0.240288, acc.: 63.28%] [G loss: 0.415515]\n",
      "epoch:25 step:23750 [D loss: 0.216761, acc.: 65.62%] [G loss: 0.420071]\n",
      "epoch:25 step:23751 [D loss: 0.217287, acc.: 70.31%] [G loss: 0.470114]\n",
      "epoch:25 step:23752 [D loss: 0.234759, acc.: 64.06%] [G loss: 0.441822]\n",
      "epoch:25 step:23753 [D loss: 0.223304, acc.: 64.84%] [G loss: 0.461347]\n",
      "epoch:25 step:23754 [D loss: 0.234768, acc.: 59.38%] [G loss: 0.452780]\n",
      "epoch:25 step:23755 [D loss: 0.231587, acc.: 60.94%] [G loss: 0.444540]\n",
      "epoch:25 step:23756 [D loss: 0.205292, acc.: 68.75%] [G loss: 0.463188]\n",
      "epoch:25 step:23757 [D loss: 0.211440, acc.: 65.62%] [G loss: 0.438059]\n",
      "epoch:25 step:23758 [D loss: 0.219174, acc.: 62.50%] [G loss: 0.455285]\n",
      "epoch:25 step:23759 [D loss: 0.229086, acc.: 62.50%] [G loss: 0.420029]\n",
      "epoch:25 step:23760 [D loss: 0.214150, acc.: 63.28%] [G loss: 0.427576]\n",
      "epoch:25 step:23761 [D loss: 0.201359, acc.: 69.53%] [G loss: 0.416519]\n",
      "epoch:25 step:23762 [D loss: 0.229229, acc.: 61.72%] [G loss: 0.393780]\n",
      "epoch:25 step:23763 [D loss: 0.211664, acc.: 63.28%] [G loss: 0.456542]\n",
      "epoch:25 step:23764 [D loss: 0.237197, acc.: 59.38%] [G loss: 0.441949]\n",
      "epoch:25 step:23765 [D loss: 0.223902, acc.: 60.16%] [G loss: 0.448121]\n",
      "epoch:25 step:23766 [D loss: 0.276691, acc.: 50.00%] [G loss: 0.425921]\n",
      "epoch:25 step:23767 [D loss: 0.239267, acc.: 54.69%] [G loss: 0.423373]\n",
      "epoch:25 step:23768 [D loss: 0.210466, acc.: 64.84%] [G loss: 0.429218]\n",
      "epoch:25 step:23769 [D loss: 0.212624, acc.: 67.97%] [G loss: 0.467424]\n",
      "epoch:25 step:23770 [D loss: 0.225080, acc.: 65.62%] [G loss: 0.445930]\n",
      "epoch:25 step:23771 [D loss: 0.194033, acc.: 68.75%] [G loss: 0.495305]\n",
      "epoch:25 step:23772 [D loss: 0.162293, acc.: 75.78%] [G loss: 0.512389]\n",
      "epoch:25 step:23773 [D loss: 0.285217, acc.: 51.56%] [G loss: 0.444288]\n",
      "epoch:25 step:23774 [D loss: 0.262524, acc.: 50.00%] [G loss: 0.412815]\n",
      "epoch:25 step:23775 [D loss: 0.219514, acc.: 68.75%] [G loss: 0.373884]\n",
      "epoch:25 step:23776 [D loss: 0.224644, acc.: 67.97%] [G loss: 0.429306]\n",
      "epoch:25 step:23777 [D loss: 0.216318, acc.: 63.28%] [G loss: 0.434983]\n",
      "epoch:25 step:23778 [D loss: 0.204496, acc.: 69.53%] [G loss: 0.517138]\n",
      "epoch:25 step:23779 [D loss: 0.192312, acc.: 74.22%] [G loss: 0.433074]\n",
      "epoch:25 step:23780 [D loss: 0.231971, acc.: 65.62%] [G loss: 0.415707]\n",
      "epoch:25 step:23781 [D loss: 0.236892, acc.: 60.16%] [G loss: 0.461870]\n",
      "epoch:25 step:23782 [D loss: 0.217194, acc.: 66.41%] [G loss: 0.459085]\n",
      "epoch:25 step:23783 [D loss: 0.199133, acc.: 64.84%] [G loss: 0.490091]\n",
      "epoch:25 step:23784 [D loss: 0.220912, acc.: 64.84%] [G loss: 0.420949]\n",
      "epoch:25 step:23785 [D loss: 0.247130, acc.: 60.16%] [G loss: 0.456617]\n",
      "epoch:25 step:23786 [D loss: 0.195833, acc.: 69.53%] [G loss: 0.443837]\n",
      "epoch:25 step:23787 [D loss: 0.215308, acc.: 64.84%] [G loss: 0.451563]\n",
      "epoch:25 step:23788 [D loss: 0.236664, acc.: 57.03%] [G loss: 0.412769]\n",
      "epoch:25 step:23789 [D loss: 0.201157, acc.: 67.19%] [G loss: 0.393256]\n",
      "epoch:25 step:23790 [D loss: 0.235729, acc.: 66.41%] [G loss: 0.425569]\n",
      "epoch:25 step:23791 [D loss: 0.226362, acc.: 63.28%] [G loss: 0.424004]\n",
      "epoch:25 step:23792 [D loss: 0.209013, acc.: 62.50%] [G loss: 0.487529]\n",
      "epoch:25 step:23793 [D loss: 0.237342, acc.: 56.25%] [G loss: 0.401944]\n",
      "epoch:25 step:23794 [D loss: 0.222340, acc.: 64.84%] [G loss: 0.410695]\n",
      "epoch:25 step:23795 [D loss: 0.226172, acc.: 66.41%] [G loss: 0.454066]\n",
      "epoch:25 step:23796 [D loss: 0.178689, acc.: 75.00%] [G loss: 0.458940]\n",
      "epoch:25 step:23797 [D loss: 0.232900, acc.: 63.28%] [G loss: 0.453964]\n",
      "epoch:25 step:23798 [D loss: 0.251318, acc.: 57.03%] [G loss: 0.435815]\n",
      "epoch:25 step:23799 [D loss: 0.193054, acc.: 72.66%] [G loss: 0.465273]\n",
      "epoch:25 step:23800 [D loss: 0.231247, acc.: 60.16%] [G loss: 0.405428]\n",
      "epoch:25 step:23801 [D loss: 0.259982, acc.: 56.25%] [G loss: 0.409462]\n",
      "epoch:25 step:23802 [D loss: 0.249296, acc.: 51.56%] [G loss: 0.433713]\n",
      "epoch:25 step:23803 [D loss: 0.219645, acc.: 64.84%] [G loss: 0.429043]\n",
      "epoch:25 step:23804 [D loss: 0.219863, acc.: 63.28%] [G loss: 0.447591]\n",
      "epoch:25 step:23805 [D loss: 0.238150, acc.: 54.69%] [G loss: 0.404141]\n",
      "epoch:25 step:23806 [D loss: 0.222286, acc.: 69.53%] [G loss: 0.449552]\n",
      "epoch:25 step:23807 [D loss: 0.231676, acc.: 63.28%] [G loss: 0.402438]\n",
      "epoch:25 step:23808 [D loss: 0.235192, acc.: 60.16%] [G loss: 0.412436]\n",
      "epoch:25 step:23809 [D loss: 0.209844, acc.: 63.28%] [G loss: 0.418186]\n",
      "epoch:25 step:23810 [D loss: 0.193862, acc.: 70.31%] [G loss: 0.469602]\n",
      "epoch:25 step:23811 [D loss: 0.221260, acc.: 70.31%] [G loss: 0.424401]\n",
      "epoch:25 step:23812 [D loss: 0.232170, acc.: 63.28%] [G loss: 0.440203]\n",
      "epoch:25 step:23813 [D loss: 0.208937, acc.: 64.84%] [G loss: 0.456492]\n",
      "epoch:25 step:23814 [D loss: 0.212147, acc.: 65.62%] [G loss: 0.454508]\n",
      "epoch:25 step:23815 [D loss: 0.235631, acc.: 63.28%] [G loss: 0.414337]\n",
      "epoch:25 step:23816 [D loss: 0.208645, acc.: 71.88%] [G loss: 0.402454]\n",
      "epoch:25 step:23817 [D loss: 0.215730, acc.: 63.28%] [G loss: 0.418064]\n",
      "epoch:25 step:23818 [D loss: 0.219009, acc.: 63.28%] [G loss: 0.420725]\n",
      "epoch:25 step:23819 [D loss: 0.219764, acc.: 62.50%] [G loss: 0.435459]\n",
      "epoch:25 step:23820 [D loss: 0.208077, acc.: 67.19%] [G loss: 0.401309]\n",
      "epoch:25 step:23821 [D loss: 0.272558, acc.: 50.78%] [G loss: 0.413227]\n",
      "epoch:25 step:23822 [D loss: 0.237489, acc.: 56.25%] [G loss: 0.442627]\n",
      "epoch:25 step:23823 [D loss: 0.191248, acc.: 71.88%] [G loss: 0.484725]\n",
      "epoch:25 step:23824 [D loss: 0.222084, acc.: 64.84%] [G loss: 0.487461]\n",
      "epoch:25 step:23825 [D loss: 0.262391, acc.: 50.78%] [G loss: 0.441990]\n",
      "epoch:25 step:23826 [D loss: 0.223606, acc.: 62.50%] [G loss: 0.430514]\n",
      "epoch:25 step:23827 [D loss: 0.222970, acc.: 63.28%] [G loss: 0.437495]\n",
      "epoch:25 step:23828 [D loss: 0.228455, acc.: 62.50%] [G loss: 0.415332]\n",
      "epoch:25 step:23829 [D loss: 0.218196, acc.: 67.19%] [G loss: 0.404518]\n",
      "epoch:25 step:23830 [D loss: 0.213944, acc.: 65.62%] [G loss: 0.405033]\n",
      "epoch:25 step:23831 [D loss: 0.220626, acc.: 67.97%] [G loss: 0.494449]\n",
      "epoch:25 step:23832 [D loss: 0.246751, acc.: 59.38%] [G loss: 0.450109]\n",
      "epoch:25 step:23833 [D loss: 0.222712, acc.: 62.50%] [G loss: 0.431403]\n",
      "epoch:25 step:23834 [D loss: 0.221018, acc.: 63.28%] [G loss: 0.458388]\n",
      "epoch:25 step:23835 [D loss: 0.197931, acc.: 72.66%] [G loss: 0.427431]\n",
      "epoch:25 step:23836 [D loss: 0.265048, acc.: 52.34%] [G loss: 0.427951]\n",
      "epoch:25 step:23837 [D loss: 0.204274, acc.: 65.62%] [G loss: 0.420473]\n",
      "epoch:25 step:23838 [D loss: 0.229791, acc.: 62.50%] [G loss: 0.389400]\n",
      "epoch:25 step:23839 [D loss: 0.222334, acc.: 59.38%] [G loss: 0.457242]\n",
      "epoch:25 step:23840 [D loss: 0.188095, acc.: 70.31%] [G loss: 0.503024]\n",
      "epoch:25 step:23841 [D loss: 0.204398, acc.: 64.06%] [G loss: 0.598254]\n",
      "epoch:25 step:23842 [D loss: 0.230885, acc.: 59.38%] [G loss: 0.477569]\n",
      "epoch:25 step:23843 [D loss: 0.254292, acc.: 50.78%] [G loss: 0.422811]\n",
      "epoch:25 step:23844 [D loss: 0.233945, acc.: 60.16%] [G loss: 0.421982]\n",
      "epoch:25 step:23845 [D loss: 0.238256, acc.: 59.38%] [G loss: 0.434522]\n",
      "epoch:25 step:23846 [D loss: 0.228755, acc.: 60.16%] [G loss: 0.383824]\n",
      "epoch:25 step:23847 [D loss: 0.248945, acc.: 53.12%] [G loss: 0.392687]\n",
      "epoch:25 step:23848 [D loss: 0.217423, acc.: 64.06%] [G loss: 0.396096]\n",
      "epoch:25 step:23849 [D loss: 0.210643, acc.: 66.41%] [G loss: 0.414291]\n",
      "epoch:25 step:23850 [D loss: 0.215824, acc.: 67.19%] [G loss: 0.476522]\n",
      "epoch:25 step:23851 [D loss: 0.198873, acc.: 71.88%] [G loss: 0.449565]\n",
      "epoch:25 step:23852 [D loss: 0.223215, acc.: 63.28%] [G loss: 0.428700]\n",
      "epoch:25 step:23853 [D loss: 0.227825, acc.: 67.97%] [G loss: 0.422778]\n",
      "epoch:25 step:23854 [D loss: 0.196828, acc.: 71.09%] [G loss: 0.457429]\n",
      "epoch:25 step:23855 [D loss: 0.208250, acc.: 70.31%] [G loss: 0.453288]\n",
      "epoch:25 step:23856 [D loss: 0.230518, acc.: 61.72%] [G loss: 0.419183]\n",
      "epoch:25 step:23857 [D loss: 0.242421, acc.: 58.59%] [G loss: 0.428755]\n",
      "epoch:25 step:23858 [D loss: 0.230295, acc.: 59.38%] [G loss: 0.405445]\n",
      "epoch:25 step:23859 [D loss: 0.208280, acc.: 63.28%] [G loss: 0.445409]\n",
      "epoch:25 step:23860 [D loss: 0.225907, acc.: 61.72%] [G loss: 0.471119]\n",
      "epoch:25 step:23861 [D loss: 0.202746, acc.: 69.53%] [G loss: 0.534084]\n",
      "epoch:25 step:23862 [D loss: 0.289977, acc.: 49.22%] [G loss: 0.447979]\n",
      "epoch:25 step:23863 [D loss: 0.246113, acc.: 57.81%] [G loss: 0.426185]\n",
      "epoch:25 step:23864 [D loss: 0.239606, acc.: 55.47%] [G loss: 0.417945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23865 [D loss: 0.219127, acc.: 68.75%] [G loss: 0.442467]\n",
      "epoch:25 step:23866 [D loss: 0.236145, acc.: 60.16%] [G loss: 0.392106]\n",
      "epoch:25 step:23867 [D loss: 0.216223, acc.: 62.50%] [G loss: 0.453983]\n",
      "epoch:25 step:23868 [D loss: 0.244624, acc.: 54.69%] [G loss: 0.452447]\n",
      "epoch:25 step:23869 [D loss: 0.249248, acc.: 60.16%] [G loss: 0.426861]\n",
      "epoch:25 step:23870 [D loss: 0.225670, acc.: 62.50%] [G loss: 0.414049]\n",
      "epoch:25 step:23871 [D loss: 0.232024, acc.: 61.72%] [G loss: 0.460349]\n",
      "epoch:25 step:23872 [D loss: 0.213884, acc.: 66.41%] [G loss: 0.410583]\n",
      "epoch:25 step:23873 [D loss: 0.225418, acc.: 59.38%] [G loss: 0.444749]\n",
      "epoch:25 step:23874 [D loss: 0.216588, acc.: 61.72%] [G loss: 0.440313]\n",
      "epoch:25 step:23875 [D loss: 0.208452, acc.: 65.62%] [G loss: 0.445577]\n",
      "epoch:25 step:23876 [D loss: 0.191612, acc.: 75.78%] [G loss: 0.455761]\n",
      "epoch:25 step:23877 [D loss: 0.222105, acc.: 66.41%] [G loss: 0.440179]\n",
      "epoch:25 step:23878 [D loss: 0.212811, acc.: 65.62%] [G loss: 0.453398]\n",
      "epoch:25 step:23879 [D loss: 0.187705, acc.: 72.66%] [G loss: 0.464175]\n",
      "epoch:25 step:23880 [D loss: 0.222460, acc.: 66.41%] [G loss: 0.415065]\n",
      "epoch:25 step:23881 [D loss: 0.231915, acc.: 59.38%] [G loss: 0.405066]\n",
      "epoch:25 step:23882 [D loss: 0.193768, acc.: 70.31%] [G loss: 0.480130]\n",
      "epoch:25 step:23883 [D loss: 0.271044, acc.: 53.12%] [G loss: 0.432356]\n",
      "epoch:25 step:23884 [D loss: 0.238478, acc.: 58.59%] [G loss: 0.459324]\n",
      "epoch:25 step:23885 [D loss: 0.259135, acc.: 53.12%] [G loss: 0.408109]\n",
      "epoch:25 step:23886 [D loss: 0.217149, acc.: 66.41%] [G loss: 0.446127]\n",
      "epoch:25 step:23887 [D loss: 0.232207, acc.: 60.94%] [G loss: 0.419003]\n",
      "epoch:25 step:23888 [D loss: 0.219892, acc.: 61.72%] [G loss: 0.402613]\n",
      "epoch:25 step:23889 [D loss: 0.199572, acc.: 72.66%] [G loss: 0.413500]\n",
      "epoch:25 step:23890 [D loss: 0.235626, acc.: 58.59%] [G loss: 0.405721]\n",
      "epoch:25 step:23891 [D loss: 0.233237, acc.: 63.28%] [G loss: 0.428102]\n",
      "epoch:25 step:23892 [D loss: 0.243110, acc.: 56.25%] [G loss: 0.449523]\n",
      "epoch:25 step:23893 [D loss: 0.225243, acc.: 64.06%] [G loss: 0.438941]\n",
      "epoch:25 step:23894 [D loss: 0.236746, acc.: 57.81%] [G loss: 0.419118]\n",
      "epoch:25 step:23895 [D loss: 0.195382, acc.: 69.53%] [G loss: 0.479166]\n",
      "epoch:25 step:23896 [D loss: 0.191034, acc.: 74.22%] [G loss: 0.488135]\n",
      "epoch:25 step:23897 [D loss: 0.213712, acc.: 73.44%] [G loss: 0.468328]\n",
      "epoch:25 step:23898 [D loss: 0.253218, acc.: 55.47%] [G loss: 0.403289]\n",
      "epoch:25 step:23899 [D loss: 0.212108, acc.: 67.19%] [G loss: 0.440434]\n",
      "epoch:25 step:23900 [D loss: 0.200478, acc.: 72.66%] [G loss: 0.444728]\n",
      "epoch:25 step:23901 [D loss: 0.227146, acc.: 62.50%] [G loss: 0.440142]\n",
      "epoch:25 step:23902 [D loss: 0.251593, acc.: 51.56%] [G loss: 0.417926]\n",
      "epoch:25 step:23903 [D loss: 0.245164, acc.: 60.94%] [G loss: 0.389584]\n",
      "epoch:25 step:23904 [D loss: 0.202074, acc.: 66.41%] [G loss: 0.432943]\n",
      "epoch:25 step:23905 [D loss: 0.196867, acc.: 70.31%] [G loss: 0.422903]\n",
      "epoch:25 step:23906 [D loss: 0.188381, acc.: 73.44%] [G loss: 0.418285]\n",
      "epoch:25 step:23907 [D loss: 0.241848, acc.: 53.12%] [G loss: 0.426146]\n",
      "epoch:25 step:23908 [D loss: 0.233060, acc.: 60.94%] [G loss: 0.445970]\n",
      "epoch:25 step:23909 [D loss: 0.204053, acc.: 67.97%] [G loss: 0.460433]\n",
      "epoch:25 step:23910 [D loss: 0.192082, acc.: 73.44%] [G loss: 0.482018]\n",
      "epoch:25 step:23911 [D loss: 0.270830, acc.: 51.56%] [G loss: 0.441675]\n",
      "epoch:25 step:23912 [D loss: 0.225242, acc.: 62.50%] [G loss: 0.450235]\n",
      "epoch:25 step:23913 [D loss: 0.215412, acc.: 61.72%] [G loss: 0.436560]\n",
      "epoch:25 step:23914 [D loss: 0.230345, acc.: 59.38%] [G loss: 0.409228]\n",
      "epoch:25 step:23915 [D loss: 0.224458, acc.: 62.50%] [G loss: 0.386807]\n",
      "epoch:25 step:23916 [D loss: 0.221832, acc.: 67.19%] [G loss: 0.427887]\n",
      "epoch:25 step:23917 [D loss: 0.233831, acc.: 60.16%] [G loss: 0.429969]\n",
      "epoch:25 step:23918 [D loss: 0.235004, acc.: 63.28%] [G loss: 0.423086]\n",
      "epoch:25 step:23919 [D loss: 0.201524, acc.: 71.09%] [G loss: 0.438421]\n",
      "epoch:25 step:23920 [D loss: 0.186376, acc.: 71.88%] [G loss: 0.452617]\n",
      "epoch:25 step:23921 [D loss: 0.193449, acc.: 67.19%] [G loss: 0.463147]\n",
      "epoch:25 step:23922 [D loss: 0.233954, acc.: 64.06%] [G loss: 0.421084]\n",
      "epoch:25 step:23923 [D loss: 0.186668, acc.: 74.22%] [G loss: 0.449325]\n",
      "epoch:25 step:23924 [D loss: 0.204298, acc.: 67.97%] [G loss: 0.484977]\n",
      "epoch:25 step:23925 [D loss: 0.266971, acc.: 52.34%] [G loss: 0.408479]\n",
      "epoch:25 step:23926 [D loss: 0.279391, acc.: 51.56%] [G loss: 0.396013]\n",
      "epoch:25 step:23927 [D loss: 0.230420, acc.: 60.16%] [G loss: 0.410303]\n",
      "epoch:25 step:23928 [D loss: 0.247252, acc.: 47.66%] [G loss: 0.425643]\n",
      "epoch:25 step:23929 [D loss: 0.204021, acc.: 68.75%] [G loss: 0.421997]\n",
      "epoch:25 step:23930 [D loss: 0.199607, acc.: 66.41%] [G loss: 0.441316]\n",
      "epoch:25 step:23931 [D loss: 0.221733, acc.: 60.16%] [G loss: 0.435251]\n",
      "epoch:25 step:23932 [D loss: 0.207439, acc.: 67.19%] [G loss: 0.508999]\n",
      "epoch:25 step:23933 [D loss: 0.194074, acc.: 71.88%] [G loss: 0.503579]\n",
      "epoch:25 step:23934 [D loss: 0.244641, acc.: 57.81%] [G loss: 0.437268]\n",
      "epoch:25 step:23935 [D loss: 0.248949, acc.: 61.72%] [G loss: 0.419784]\n",
      "epoch:25 step:23936 [D loss: 0.228472, acc.: 60.16%] [G loss: 0.396219]\n",
      "epoch:25 step:23937 [D loss: 0.223549, acc.: 60.94%] [G loss: 0.439446]\n",
      "epoch:25 step:23938 [D loss: 0.194499, acc.: 74.22%] [G loss: 0.451242]\n",
      "epoch:25 step:23939 [D loss: 0.211509, acc.: 65.62%] [G loss: 0.414300]\n",
      "epoch:25 step:23940 [D loss: 0.187208, acc.: 75.00%] [G loss: 0.464262]\n",
      "epoch:25 step:23941 [D loss: 0.205777, acc.: 66.41%] [G loss: 0.465802]\n",
      "epoch:25 step:23942 [D loss: 0.244617, acc.: 57.81%] [G loss: 0.442541]\n",
      "epoch:25 step:23943 [D loss: 0.239697, acc.: 60.16%] [G loss: 0.426222]\n",
      "epoch:25 step:23944 [D loss: 0.217765, acc.: 61.72%] [G loss: 0.390126]\n",
      "epoch:25 step:23945 [D loss: 0.220398, acc.: 60.94%] [G loss: 0.430790]\n",
      "epoch:25 step:23946 [D loss: 0.220545, acc.: 60.16%] [G loss: 0.416278]\n",
      "epoch:25 step:23947 [D loss: 0.207694, acc.: 73.44%] [G loss: 0.423086]\n",
      "epoch:25 step:23948 [D loss: 0.225050, acc.: 65.62%] [G loss: 0.421769]\n",
      "epoch:25 step:23949 [D loss: 0.221045, acc.: 63.28%] [G loss: 0.444798]\n",
      "epoch:25 step:23950 [D loss: 0.195941, acc.: 71.09%] [G loss: 0.465423]\n",
      "epoch:25 step:23951 [D loss: 0.201504, acc.: 67.97%] [G loss: 0.460707]\n",
      "epoch:25 step:23952 [D loss: 0.218425, acc.: 65.62%] [G loss: 0.465537]\n",
      "epoch:25 step:23953 [D loss: 0.255315, acc.: 55.47%] [G loss: 0.448209]\n",
      "epoch:25 step:23954 [D loss: 0.246135, acc.: 56.25%] [G loss: 0.469161]\n",
      "epoch:25 step:23955 [D loss: 0.229437, acc.: 59.38%] [G loss: 0.466183]\n",
      "epoch:25 step:23956 [D loss: 0.241750, acc.: 60.16%] [G loss: 0.426603]\n",
      "epoch:25 step:23957 [D loss: 0.213599, acc.: 66.41%] [G loss: 0.415263]\n",
      "epoch:25 step:23958 [D loss: 0.230989, acc.: 60.16%] [G loss: 0.413573]\n",
      "epoch:25 step:23959 [D loss: 0.185799, acc.: 71.88%] [G loss: 0.463826]\n",
      "epoch:25 step:23960 [D loss: 0.231621, acc.: 62.50%] [G loss: 0.441929]\n",
      "epoch:25 step:23961 [D loss: 0.212907, acc.: 66.41%] [G loss: 0.443444]\n",
      "epoch:25 step:23962 [D loss: 0.238803, acc.: 57.03%] [G loss: 0.417150]\n",
      "epoch:25 step:23963 [D loss: 0.228520, acc.: 63.28%] [G loss: 0.435471]\n",
      "epoch:25 step:23964 [D loss: 0.220093, acc.: 63.28%] [G loss: 0.436657]\n",
      "epoch:25 step:23965 [D loss: 0.237444, acc.: 57.03%] [G loss: 0.392141]\n",
      "epoch:25 step:23966 [D loss: 0.221241, acc.: 64.84%] [G loss: 0.387938]\n",
      "epoch:25 step:23967 [D loss: 0.251742, acc.: 59.38%] [G loss: 0.421562]\n",
      "epoch:25 step:23968 [D loss: 0.232819, acc.: 57.03%] [G loss: 0.390982]\n",
      "epoch:25 step:23969 [D loss: 0.212337, acc.: 65.62%] [G loss: 0.458303]\n",
      "epoch:25 step:23970 [D loss: 0.241154, acc.: 61.72%] [G loss: 0.398802]\n",
      "epoch:25 step:23971 [D loss: 0.213599, acc.: 61.72%] [G loss: 0.453891]\n",
      "epoch:25 step:23972 [D loss: 0.218027, acc.: 65.62%] [G loss: 0.436155]\n",
      "epoch:25 step:23973 [D loss: 0.185556, acc.: 75.00%] [G loss: 0.441664]\n",
      "epoch:25 step:23974 [D loss: 0.197747, acc.: 71.09%] [G loss: 0.450371]\n",
      "epoch:25 step:23975 [D loss: 0.194637, acc.: 68.75%] [G loss: 0.473292]\n",
      "epoch:25 step:23976 [D loss: 0.184402, acc.: 78.12%] [G loss: 0.475658]\n",
      "epoch:25 step:23977 [D loss: 0.199213, acc.: 70.31%] [G loss: 0.420891]\n",
      "epoch:25 step:23978 [D loss: 0.240985, acc.: 59.38%] [G loss: 0.433551]\n",
      "epoch:25 step:23979 [D loss: 0.205218, acc.: 70.31%] [G loss: 0.452609]\n",
      "epoch:25 step:23980 [D loss: 0.222023, acc.: 67.19%] [G loss: 0.441977]\n",
      "epoch:25 step:23981 [D loss: 0.226397, acc.: 64.06%] [G loss: 0.463079]\n",
      "epoch:25 step:23982 [D loss: 0.198770, acc.: 72.66%] [G loss: 0.489797]\n",
      "epoch:25 step:23983 [D loss: 0.221162, acc.: 65.62%] [G loss: 0.457860]\n",
      "epoch:25 step:23984 [D loss: 0.267781, acc.: 54.69%] [G loss: 0.416586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23985 [D loss: 0.236115, acc.: 58.59%] [G loss: 0.401259]\n",
      "epoch:25 step:23986 [D loss: 0.222393, acc.: 60.94%] [G loss: 0.412603]\n",
      "epoch:25 step:23987 [D loss: 0.225911, acc.: 60.16%] [G loss: 0.457781]\n",
      "epoch:25 step:23988 [D loss: 0.193442, acc.: 66.41%] [G loss: 0.509071]\n",
      "epoch:25 step:23989 [D loss: 0.204429, acc.: 70.31%] [G loss: 0.463380]\n",
      "epoch:25 step:23990 [D loss: 0.239336, acc.: 55.47%] [G loss: 0.405830]\n",
      "epoch:25 step:23991 [D loss: 0.269085, acc.: 59.38%] [G loss: 0.431439]\n",
      "epoch:25 step:23992 [D loss: 0.223820, acc.: 64.84%] [G loss: 0.433601]\n",
      "epoch:25 step:23993 [D loss: 0.210616, acc.: 71.09%] [G loss: 0.415570]\n",
      "epoch:25 step:23994 [D loss: 0.249420, acc.: 57.03%] [G loss: 0.402154]\n",
      "epoch:25 step:23995 [D loss: 0.214242, acc.: 66.41%] [G loss: 0.422944]\n",
      "epoch:25 step:23996 [D loss: 0.210580, acc.: 65.62%] [G loss: 0.458656]\n",
      "epoch:25 step:23997 [D loss: 0.235355, acc.: 57.81%] [G loss: 0.415963]\n",
      "epoch:25 step:23998 [D loss: 0.233253, acc.: 59.38%] [G loss: 0.445041]\n",
      "epoch:25 step:23999 [D loss: 0.208345, acc.: 64.84%] [G loss: 0.440733]\n",
      "epoch:25 step:24000 [D loss: 0.196397, acc.: 71.09%] [G loss: 0.419588]\n",
      "epoch:25 step:24001 [D loss: 0.231096, acc.: 62.50%] [G loss: 0.448463]\n",
      "epoch:25 step:24002 [D loss: 0.227184, acc.: 60.16%] [G loss: 0.416937]\n",
      "epoch:25 step:24003 [D loss: 0.216167, acc.: 58.59%] [G loss: 0.450505]\n",
      "epoch:25 step:24004 [D loss: 0.226056, acc.: 60.94%] [G loss: 0.429265]\n",
      "epoch:25 step:24005 [D loss: 0.207300, acc.: 64.84%] [G loss: 0.461544]\n",
      "epoch:25 step:24006 [D loss: 0.199812, acc.: 71.09%] [G loss: 0.419203]\n",
      "epoch:25 step:24007 [D loss: 0.201860, acc.: 63.28%] [G loss: 0.469727]\n",
      "epoch:25 step:24008 [D loss: 0.211673, acc.: 65.62%] [G loss: 0.447177]\n",
      "epoch:25 step:24009 [D loss: 0.235881, acc.: 60.16%] [G loss: 0.439883]\n",
      "epoch:25 step:24010 [D loss: 0.223483, acc.: 63.28%] [G loss: 0.464634]\n",
      "epoch:25 step:24011 [D loss: 0.216093, acc.: 68.75%] [G loss: 0.443207]\n",
      "epoch:25 step:24012 [D loss: 0.258447, acc.: 51.56%] [G loss: 0.405971]\n",
      "epoch:25 step:24013 [D loss: 0.221123, acc.: 63.28%] [G loss: 0.429270]\n",
      "epoch:25 step:24014 [D loss: 0.203390, acc.: 67.97%] [G loss: 0.432805]\n",
      "epoch:25 step:24015 [D loss: 0.244126, acc.: 58.59%] [G loss: 0.445743]\n",
      "epoch:25 step:24016 [D loss: 0.226042, acc.: 65.62%] [G loss: 0.443585]\n",
      "epoch:25 step:24017 [D loss: 0.206320, acc.: 67.19%] [G loss: 0.445914]\n",
      "epoch:25 step:24018 [D loss: 0.213343, acc.: 67.97%] [G loss: 0.447080]\n",
      "epoch:25 step:24019 [D loss: 0.211598, acc.: 66.41%] [G loss: 0.423708]\n",
      "epoch:25 step:24020 [D loss: 0.189562, acc.: 71.88%] [G loss: 0.392253]\n",
      "epoch:25 step:24021 [D loss: 0.226713, acc.: 60.94%] [G loss: 0.436851]\n",
      "epoch:25 step:24022 [D loss: 0.239459, acc.: 57.81%] [G loss: 0.430010]\n",
      "epoch:25 step:24023 [D loss: 0.214771, acc.: 64.84%] [G loss: 0.453894]\n",
      "epoch:25 step:24024 [D loss: 0.214580, acc.: 65.62%] [G loss: 0.430556]\n",
      "epoch:25 step:24025 [D loss: 0.249029, acc.: 53.12%] [G loss: 0.452964]\n",
      "epoch:25 step:24026 [D loss: 0.217802, acc.: 62.50%] [G loss: 0.406656]\n",
      "epoch:25 step:24027 [D loss: 0.213843, acc.: 70.31%] [G loss: 0.401497]\n",
      "epoch:25 step:24028 [D loss: 0.243098, acc.: 60.16%] [G loss: 0.374947]\n",
      "epoch:25 step:24029 [D loss: 0.185883, acc.: 70.31%] [G loss: 0.475651]\n",
      "epoch:25 step:24030 [D loss: 0.200765, acc.: 66.41%] [G loss: 0.439850]\n",
      "epoch:25 step:24031 [D loss: 0.257677, acc.: 54.69%] [G loss: 0.408879]\n",
      "epoch:25 step:24032 [D loss: 0.215866, acc.: 61.72%] [G loss: 0.462841]\n",
      "epoch:25 step:24033 [D loss: 0.228865, acc.: 58.59%] [G loss: 0.427725]\n",
      "epoch:25 step:24034 [D loss: 0.228173, acc.: 63.28%] [G loss: 0.433560]\n",
      "epoch:25 step:24035 [D loss: 0.224472, acc.: 64.06%] [G loss: 0.394055]\n",
      "epoch:25 step:24036 [D loss: 0.214616, acc.: 60.94%] [G loss: 0.404249]\n",
      "epoch:25 step:24037 [D loss: 0.231699, acc.: 59.38%] [G loss: 0.475573]\n",
      "epoch:25 step:24038 [D loss: 0.225774, acc.: 62.50%] [G loss: 0.423608]\n",
      "epoch:25 step:24039 [D loss: 0.254212, acc.: 46.09%] [G loss: 0.408008]\n",
      "epoch:25 step:24040 [D loss: 0.254160, acc.: 52.34%] [G loss: 0.383325]\n",
      "epoch:25 step:24041 [D loss: 0.231741, acc.: 68.75%] [G loss: 0.441619]\n",
      "epoch:25 step:24042 [D loss: 0.232243, acc.: 57.03%] [G loss: 0.430235]\n",
      "epoch:25 step:24043 [D loss: 0.223130, acc.: 67.97%] [G loss: 0.448442]\n",
      "epoch:25 step:24044 [D loss: 0.237327, acc.: 56.25%] [G loss: 0.461464]\n",
      "epoch:25 step:24045 [D loss: 0.194171, acc.: 68.75%] [G loss: 0.445580]\n",
      "epoch:25 step:24046 [D loss: 0.225583, acc.: 57.03%] [G loss: 0.422842]\n",
      "epoch:25 step:24047 [D loss: 0.253658, acc.: 52.34%] [G loss: 0.353812]\n",
      "epoch:25 step:24048 [D loss: 0.207423, acc.: 67.97%] [G loss: 0.412350]\n",
      "epoch:25 step:24049 [D loss: 0.187152, acc.: 75.00%] [G loss: 0.403456]\n",
      "epoch:25 step:24050 [D loss: 0.236414, acc.: 59.38%] [G loss: 0.411748]\n",
      "epoch:25 step:24051 [D loss: 0.244414, acc.: 53.91%] [G loss: 0.426823]\n",
      "epoch:25 step:24052 [D loss: 0.222381, acc.: 64.84%] [G loss: 0.419473]\n",
      "epoch:25 step:24053 [D loss: 0.228369, acc.: 60.16%] [G loss: 0.424092]\n",
      "epoch:25 step:24054 [D loss: 0.214031, acc.: 61.72%] [G loss: 0.425394]\n",
      "epoch:25 step:24055 [D loss: 0.245280, acc.: 59.38%] [G loss: 0.385600]\n",
      "epoch:25 step:24056 [D loss: 0.207244, acc.: 71.09%] [G loss: 0.421287]\n",
      "epoch:25 step:24057 [D loss: 0.209429, acc.: 69.53%] [G loss: 0.444988]\n",
      "epoch:25 step:24058 [D loss: 0.214967, acc.: 69.53%] [G loss: 0.458388]\n",
      "epoch:25 step:24059 [D loss: 0.196744, acc.: 71.09%] [G loss: 0.457043]\n",
      "epoch:25 step:24060 [D loss: 0.212968, acc.: 65.62%] [G loss: 0.469199]\n",
      "epoch:25 step:24061 [D loss: 0.256557, acc.: 57.03%] [G loss: 0.409732]\n",
      "epoch:25 step:24062 [D loss: 0.220706, acc.: 66.41%] [G loss: 0.417345]\n",
      "epoch:25 step:24063 [D loss: 0.234826, acc.: 54.69%] [G loss: 0.396325]\n",
      "epoch:25 step:24064 [D loss: 0.226029, acc.: 63.28%] [G loss: 0.447420]\n",
      "epoch:25 step:24065 [D loss: 0.209693, acc.: 69.53%] [G loss: 0.427416]\n",
      "epoch:25 step:24066 [D loss: 0.226373, acc.: 59.38%] [G loss: 0.426487]\n",
      "epoch:25 step:24067 [D loss: 0.190696, acc.: 71.88%] [G loss: 0.509235]\n",
      "epoch:25 step:24068 [D loss: 0.242154, acc.: 60.16%] [G loss: 0.458517]\n",
      "epoch:25 step:24069 [D loss: 0.233334, acc.: 60.16%] [G loss: 0.445099]\n",
      "epoch:25 step:24070 [D loss: 0.238317, acc.: 57.81%] [G loss: 0.433729]\n",
      "epoch:25 step:24071 [D loss: 0.217643, acc.: 68.75%] [G loss: 0.429885]\n",
      "epoch:25 step:24072 [D loss: 0.190693, acc.: 73.44%] [G loss: 0.512343]\n",
      "epoch:25 step:24073 [D loss: 0.174302, acc.: 78.12%] [G loss: 0.487491]\n",
      "epoch:25 step:24074 [D loss: 0.238056, acc.: 61.72%] [G loss: 0.502188]\n",
      "epoch:25 step:24075 [D loss: 0.188816, acc.: 71.88%] [G loss: 0.463329]\n",
      "epoch:25 step:24076 [D loss: 0.220953, acc.: 62.50%] [G loss: 0.446522]\n",
      "epoch:25 step:24077 [D loss: 0.212100, acc.: 67.19%] [G loss: 0.459957]\n",
      "epoch:25 step:24078 [D loss: 0.207302, acc.: 67.19%] [G loss: 0.484972]\n",
      "epoch:25 step:24079 [D loss: 0.219372, acc.: 68.75%] [G loss: 0.446387]\n",
      "epoch:25 step:24080 [D loss: 0.228431, acc.: 65.62%] [G loss: 0.410970]\n",
      "epoch:25 step:24081 [D loss: 0.227811, acc.: 63.28%] [G loss: 0.399049]\n",
      "epoch:25 step:24082 [D loss: 0.246602, acc.: 61.72%] [G loss: 0.423153]\n",
      "epoch:25 step:24083 [D loss: 0.222945, acc.: 61.72%] [G loss: 0.462919]\n",
      "epoch:25 step:24084 [D loss: 0.231260, acc.: 60.16%] [G loss: 0.407811]\n",
      "epoch:25 step:24085 [D loss: 0.195246, acc.: 67.19%] [G loss: 0.440459]\n",
      "epoch:25 step:24086 [D loss: 0.193572, acc.: 69.53%] [G loss: 0.468602]\n",
      "epoch:25 step:24087 [D loss: 0.249354, acc.: 59.38%] [G loss: 0.439450]\n",
      "epoch:25 step:24088 [D loss: 0.211824, acc.: 65.62%] [G loss: 0.489725]\n",
      "epoch:25 step:24089 [D loss: 0.239970, acc.: 56.25%] [G loss: 0.425210]\n",
      "epoch:25 step:24090 [D loss: 0.215081, acc.: 64.84%] [G loss: 0.422872]\n",
      "epoch:25 step:24091 [D loss: 0.217510, acc.: 64.06%] [G loss: 0.434564]\n",
      "epoch:25 step:24092 [D loss: 0.228839, acc.: 63.28%] [G loss: 0.423658]\n",
      "epoch:25 step:24093 [D loss: 0.244879, acc.: 63.28%] [G loss: 0.403491]\n",
      "epoch:25 step:24094 [D loss: 0.222828, acc.: 64.84%] [G loss: 0.426837]\n",
      "epoch:25 step:24095 [D loss: 0.228283, acc.: 64.06%] [G loss: 0.392974]\n",
      "epoch:25 step:24096 [D loss: 0.212628, acc.: 61.72%] [G loss: 0.425539]\n",
      "epoch:25 step:24097 [D loss: 0.232765, acc.: 65.62%] [G loss: 0.425117]\n",
      "epoch:25 step:24098 [D loss: 0.238540, acc.: 59.38%] [G loss: 0.418443]\n",
      "epoch:25 step:24099 [D loss: 0.205617, acc.: 67.97%] [G loss: 0.433673]\n",
      "epoch:25 step:24100 [D loss: 0.253968, acc.: 57.03%] [G loss: 0.421813]\n",
      "epoch:25 step:24101 [D loss: 0.218803, acc.: 64.84%] [G loss: 0.412020]\n",
      "epoch:25 step:24102 [D loss: 0.195236, acc.: 70.31%] [G loss: 0.441823]\n",
      "epoch:25 step:24103 [D loss: 0.245590, acc.: 58.59%] [G loss: 0.410441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24104 [D loss: 0.199984, acc.: 70.31%] [G loss: 0.432552]\n",
      "epoch:25 step:24105 [D loss: 0.206492, acc.: 66.41%] [G loss: 0.432553]\n",
      "epoch:25 step:24106 [D loss: 0.182130, acc.: 75.00%] [G loss: 0.450339]\n",
      "epoch:25 step:24107 [D loss: 0.241913, acc.: 64.06%] [G loss: 0.453202]\n",
      "epoch:25 step:24108 [D loss: 0.256394, acc.: 56.25%] [G loss: 0.419660]\n",
      "epoch:25 step:24109 [D loss: 0.276606, acc.: 46.09%] [G loss: 0.418123]\n",
      "epoch:25 step:24110 [D loss: 0.202535, acc.: 69.53%] [G loss: 0.437331]\n",
      "epoch:25 step:24111 [D loss: 0.230227, acc.: 61.72%] [G loss: 0.405207]\n",
      "epoch:25 step:24112 [D loss: 0.239866, acc.: 60.16%] [G loss: 0.396551]\n",
      "epoch:25 step:24113 [D loss: 0.221424, acc.: 64.84%] [G loss: 0.420045]\n",
      "epoch:25 step:24114 [D loss: 0.216569, acc.: 65.62%] [G loss: 0.453765]\n",
      "epoch:25 step:24115 [D loss: 0.197723, acc.: 69.53%] [G loss: 0.438549]\n",
      "epoch:25 step:24116 [D loss: 0.201797, acc.: 68.75%] [G loss: 0.453633]\n",
      "epoch:25 step:24117 [D loss: 0.207357, acc.: 67.97%] [G loss: 0.500502]\n",
      "epoch:25 step:24118 [D loss: 0.239167, acc.: 58.59%] [G loss: 0.428290]\n",
      "epoch:25 step:24119 [D loss: 0.171413, acc.: 76.56%] [G loss: 0.485935]\n",
      "epoch:25 step:24120 [D loss: 0.236253, acc.: 60.94%] [G loss: 0.479227]\n",
      "epoch:25 step:24121 [D loss: 0.249338, acc.: 50.78%] [G loss: 0.405845]\n",
      "epoch:25 step:24122 [D loss: 0.229069, acc.: 55.47%] [G loss: 0.424229]\n",
      "epoch:25 step:24123 [D loss: 0.236247, acc.: 58.59%] [G loss: 0.420691]\n",
      "epoch:25 step:24124 [D loss: 0.215470, acc.: 65.62%] [G loss: 0.414298]\n",
      "epoch:25 step:24125 [D loss: 0.223134, acc.: 61.72%] [G loss: 0.421625]\n",
      "epoch:25 step:24126 [D loss: 0.190728, acc.: 71.09%] [G loss: 0.481186]\n",
      "epoch:25 step:24127 [D loss: 0.272450, acc.: 53.12%] [G loss: 0.443373]\n",
      "epoch:25 step:24128 [D loss: 0.253050, acc.: 54.69%] [G loss: 0.424577]\n",
      "epoch:25 step:24129 [D loss: 0.230687, acc.: 60.16%] [G loss: 0.428836]\n",
      "epoch:25 step:24130 [D loss: 0.221103, acc.: 64.06%] [G loss: 0.423412]\n",
      "epoch:25 step:24131 [D loss: 0.211089, acc.: 70.31%] [G loss: 0.407529]\n",
      "epoch:25 step:24132 [D loss: 0.221422, acc.: 67.97%] [G loss: 0.466104]\n",
      "epoch:25 step:24133 [D loss: 0.211276, acc.: 66.41%] [G loss: 0.471582]\n",
      "epoch:25 step:24134 [D loss: 0.202238, acc.: 70.31%] [G loss: 0.452259]\n",
      "epoch:25 step:24135 [D loss: 0.250498, acc.: 57.81%] [G loss: 0.412809]\n",
      "epoch:25 step:24136 [D loss: 0.229384, acc.: 62.50%] [G loss: 0.461985]\n",
      "epoch:25 step:24137 [D loss: 0.226720, acc.: 65.62%] [G loss: 0.440362]\n",
      "epoch:25 step:24138 [D loss: 0.213040, acc.: 64.06%] [G loss: 0.488096]\n",
      "epoch:25 step:24139 [D loss: 0.238139, acc.: 57.81%] [G loss: 0.456303]\n",
      "epoch:25 step:24140 [D loss: 0.223569, acc.: 57.03%] [G loss: 0.438027]\n",
      "epoch:25 step:24141 [D loss: 0.238861, acc.: 60.94%] [G loss: 0.420920]\n",
      "epoch:25 step:24142 [D loss: 0.217001, acc.: 67.97%] [G loss: 0.393928]\n",
      "epoch:25 step:24143 [D loss: 0.229000, acc.: 65.62%] [G loss: 0.418456]\n",
      "epoch:25 step:24144 [D loss: 0.209319, acc.: 65.62%] [G loss: 0.454348]\n",
      "epoch:25 step:24145 [D loss: 0.232971, acc.: 60.16%] [G loss: 0.452692]\n",
      "epoch:25 step:24146 [D loss: 0.217916, acc.: 61.72%] [G loss: 0.443140]\n",
      "epoch:25 step:24147 [D loss: 0.248452, acc.: 56.25%] [G loss: 0.400653]\n",
      "epoch:25 step:24148 [D loss: 0.216633, acc.: 65.62%] [G loss: 0.419866]\n",
      "epoch:25 step:24149 [D loss: 0.217167, acc.: 63.28%] [G loss: 0.421360]\n",
      "epoch:25 step:24150 [D loss: 0.206864, acc.: 71.88%] [G loss: 0.430818]\n",
      "epoch:25 step:24151 [D loss: 0.205999, acc.: 62.50%] [G loss: 0.445317]\n",
      "epoch:25 step:24152 [D loss: 0.237075, acc.: 53.91%] [G loss: 0.425919]\n",
      "epoch:25 step:24153 [D loss: 0.241116, acc.: 57.03%] [G loss: 0.429787]\n",
      "epoch:25 step:24154 [D loss: 0.222824, acc.: 63.28%] [G loss: 0.448490]\n",
      "epoch:25 step:24155 [D loss: 0.224312, acc.: 64.06%] [G loss: 0.460723]\n",
      "epoch:25 step:24156 [D loss: 0.225928, acc.: 63.28%] [G loss: 0.415612]\n",
      "epoch:25 step:24157 [D loss: 0.227261, acc.: 64.06%] [G loss: 0.403163]\n",
      "epoch:25 step:24158 [D loss: 0.212108, acc.: 64.84%] [G loss: 0.451514]\n",
      "epoch:25 step:24159 [D loss: 0.236169, acc.: 57.03%] [G loss: 0.423321]\n",
      "epoch:25 step:24160 [D loss: 0.251910, acc.: 58.59%] [G loss: 0.393064]\n",
      "epoch:25 step:24161 [D loss: 0.213350, acc.: 64.06%] [G loss: 0.413917]\n",
      "epoch:25 step:24162 [D loss: 0.210423, acc.: 67.97%] [G loss: 0.404023]\n",
      "epoch:25 step:24163 [D loss: 0.241280, acc.: 56.25%] [G loss: 0.401117]\n",
      "epoch:25 step:24164 [D loss: 0.234481, acc.: 63.28%] [G loss: 0.406954]\n",
      "epoch:25 step:24165 [D loss: 0.227901, acc.: 60.16%] [G loss: 0.408045]\n",
      "epoch:25 step:24166 [D loss: 0.254494, acc.: 51.56%] [G loss: 0.429488]\n",
      "epoch:25 step:24167 [D loss: 0.230184, acc.: 63.28%] [G loss: 0.452321]\n",
      "epoch:25 step:24168 [D loss: 0.202191, acc.: 66.41%] [G loss: 0.477221]\n",
      "epoch:25 step:24169 [D loss: 0.252126, acc.: 60.94%] [G loss: 0.402090]\n",
      "epoch:25 step:24170 [D loss: 0.217795, acc.: 67.19%] [G loss: 0.423182]\n",
      "epoch:25 step:24171 [D loss: 0.231091, acc.: 64.06%] [G loss: 0.409769]\n",
      "epoch:25 step:24172 [D loss: 0.212640, acc.: 64.84%] [G loss: 0.441365]\n",
      "epoch:25 step:24173 [D loss: 0.235337, acc.: 55.47%] [G loss: 0.439209]\n",
      "epoch:25 step:24174 [D loss: 0.227173, acc.: 63.28%] [G loss: 0.436985]\n",
      "epoch:25 step:24175 [D loss: 0.199437, acc.: 69.53%] [G loss: 0.449690]\n",
      "epoch:25 step:24176 [D loss: 0.218836, acc.: 63.28%] [G loss: 0.449945]\n",
      "epoch:25 step:24177 [D loss: 0.237528, acc.: 60.94%] [G loss: 0.403436]\n",
      "epoch:25 step:24178 [D loss: 0.233105, acc.: 67.19%] [G loss: 0.423241]\n",
      "epoch:25 step:24179 [D loss: 0.227461, acc.: 62.50%] [G loss: 0.419547]\n",
      "epoch:25 step:24180 [D loss: 0.232303, acc.: 59.38%] [G loss: 0.423697]\n",
      "epoch:25 step:24181 [D loss: 0.238494, acc.: 57.81%] [G loss: 0.477439]\n",
      "epoch:25 step:24182 [D loss: 0.227354, acc.: 64.06%] [G loss: 0.426996]\n",
      "epoch:25 step:24183 [D loss: 0.218160, acc.: 65.62%] [G loss: 0.421041]\n",
      "epoch:25 step:24184 [D loss: 0.238671, acc.: 64.06%] [G loss: 0.401848]\n",
      "epoch:25 step:24185 [D loss: 0.231051, acc.: 62.50%] [G loss: 0.391748]\n",
      "epoch:25 step:24186 [D loss: 0.238880, acc.: 62.50%] [G loss: 0.415182]\n",
      "epoch:25 step:24187 [D loss: 0.247697, acc.: 50.78%] [G loss: 0.449047]\n",
      "epoch:25 step:24188 [D loss: 0.229162, acc.: 59.38%] [G loss: 0.413644]\n",
      "epoch:25 step:24189 [D loss: 0.239612, acc.: 53.91%] [G loss: 0.412341]\n",
      "epoch:25 step:24190 [D loss: 0.239724, acc.: 59.38%] [G loss: 0.429581]\n",
      "epoch:25 step:24191 [D loss: 0.253313, acc.: 61.72%] [G loss: 0.406379]\n",
      "epoch:25 step:24192 [D loss: 0.229533, acc.: 67.19%] [G loss: 0.470120]\n",
      "epoch:25 step:24193 [D loss: 0.224819, acc.: 64.84%] [G loss: 0.440052]\n",
      "epoch:25 step:24194 [D loss: 0.191027, acc.: 68.75%] [G loss: 0.446860]\n",
      "epoch:25 step:24195 [D loss: 0.230050, acc.: 63.28%] [G loss: 0.389263]\n",
      "epoch:25 step:24196 [D loss: 0.219249, acc.: 62.50%] [G loss: 0.411333]\n",
      "epoch:25 step:24197 [D loss: 0.256884, acc.: 57.03%] [G loss: 0.437602]\n",
      "epoch:25 step:24198 [D loss: 0.222949, acc.: 64.06%] [G loss: 0.449625]\n",
      "epoch:25 step:24199 [D loss: 0.230125, acc.: 64.84%] [G loss: 0.439171]\n",
      "epoch:25 step:24200 [D loss: 0.211045, acc.: 66.41%] [G loss: 0.435183]\n",
      "epoch:25 step:24201 [D loss: 0.223461, acc.: 64.84%] [G loss: 0.471710]\n",
      "epoch:25 step:24202 [D loss: 0.207197, acc.: 67.19%] [G loss: 0.425372]\n",
      "epoch:25 step:24203 [D loss: 0.243028, acc.: 61.72%] [G loss: 0.415975]\n",
      "epoch:25 step:24204 [D loss: 0.212922, acc.: 71.09%] [G loss: 0.451477]\n",
      "epoch:25 step:24205 [D loss: 0.221399, acc.: 66.41%] [G loss: 0.482124]\n",
      "epoch:25 step:24206 [D loss: 0.178968, acc.: 71.09%] [G loss: 0.504412]\n",
      "epoch:25 step:24207 [D loss: 0.204448, acc.: 71.09%] [G loss: 0.468754]\n",
      "epoch:25 step:24208 [D loss: 0.236158, acc.: 58.59%] [G loss: 0.440976]\n",
      "epoch:25 step:24209 [D loss: 0.250969, acc.: 53.91%] [G loss: 0.457879]\n",
      "epoch:25 step:24210 [D loss: 0.214590, acc.: 67.97%] [G loss: 0.434863]\n",
      "epoch:25 step:24211 [D loss: 0.210169, acc.: 66.41%] [G loss: 0.449207]\n",
      "epoch:25 step:24212 [D loss: 0.262483, acc.: 54.69%] [G loss: 0.429275]\n",
      "epoch:25 step:24213 [D loss: 0.248200, acc.: 53.12%] [G loss: 0.390163]\n",
      "epoch:25 step:24214 [D loss: 0.229409, acc.: 61.72%] [G loss: 0.433505]\n",
      "epoch:25 step:24215 [D loss: 0.189896, acc.: 73.44%] [G loss: 0.440474]\n",
      "epoch:25 step:24216 [D loss: 0.223618, acc.: 63.28%] [G loss: 0.432854]\n",
      "epoch:25 step:24217 [D loss: 0.215778, acc.: 61.72%] [G loss: 0.418158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24218 [D loss: 0.225934, acc.: 63.28%] [G loss: 0.439403]\n",
      "epoch:25 step:24219 [D loss: 0.224929, acc.: 60.16%] [G loss: 0.477549]\n",
      "epoch:25 step:24220 [D loss: 0.229572, acc.: 62.50%] [G loss: 0.437945]\n",
      "epoch:25 step:24221 [D loss: 0.213210, acc.: 64.84%] [G loss: 0.448814]\n",
      "epoch:25 step:24222 [D loss: 0.274082, acc.: 53.12%] [G loss: 0.345085]\n",
      "epoch:25 step:24223 [D loss: 0.242366, acc.: 56.25%] [G loss: 0.374020]\n",
      "epoch:25 step:24224 [D loss: 0.228394, acc.: 60.94%] [G loss: 0.395057]\n",
      "epoch:25 step:24225 [D loss: 0.254108, acc.: 52.34%] [G loss: 0.475989]\n",
      "epoch:25 step:24226 [D loss: 0.221248, acc.: 60.16%] [G loss: 0.443917]\n",
      "epoch:25 step:24227 [D loss: 0.210912, acc.: 65.62%] [G loss: 0.472020]\n",
      "epoch:25 step:24228 [D loss: 0.213845, acc.: 65.62%] [G loss: 0.418963]\n",
      "epoch:25 step:24229 [D loss: 0.222263, acc.: 61.72%] [G loss: 0.412923]\n",
      "epoch:25 step:24230 [D loss: 0.213571, acc.: 66.41%] [G loss: 0.411054]\n",
      "epoch:25 step:24231 [D loss: 0.218083, acc.: 67.97%] [G loss: 0.410597]\n",
      "epoch:25 step:24232 [D loss: 0.211075, acc.: 67.97%] [G loss: 0.417595]\n",
      "epoch:25 step:24233 [D loss: 0.248039, acc.: 53.12%] [G loss: 0.410692]\n",
      "epoch:25 step:24234 [D loss: 0.233562, acc.: 60.16%] [G loss: 0.445200]\n",
      "epoch:25 step:24235 [D loss: 0.249324, acc.: 57.81%] [G loss: 0.447629]\n",
      "epoch:25 step:24236 [D loss: 0.229131, acc.: 57.81%] [G loss: 0.402768]\n",
      "epoch:25 step:24237 [D loss: 0.233125, acc.: 57.03%] [G loss: 0.381444]\n",
      "epoch:25 step:24238 [D loss: 0.232374, acc.: 59.38%] [G loss: 0.421487]\n",
      "epoch:25 step:24239 [D loss: 0.210236, acc.: 64.84%] [G loss: 0.434689]\n",
      "epoch:25 step:24240 [D loss: 0.202625, acc.: 72.66%] [G loss: 0.504095]\n",
      "epoch:25 step:24241 [D loss: 0.209126, acc.: 66.41%] [G loss: 0.435632]\n",
      "epoch:25 step:24242 [D loss: 0.267192, acc.: 57.81%] [G loss: 0.430507]\n",
      "epoch:25 step:24243 [D loss: 0.240069, acc.: 58.59%] [G loss: 0.408611]\n",
      "epoch:25 step:24244 [D loss: 0.207405, acc.: 67.97%] [G loss: 0.438431]\n",
      "epoch:25 step:24245 [D loss: 0.233622, acc.: 59.38%] [G loss: 0.433253]\n",
      "epoch:25 step:24246 [D loss: 0.245635, acc.: 56.25%] [G loss: 0.386394]\n",
      "epoch:25 step:24247 [D loss: 0.203279, acc.: 67.97%] [G loss: 0.431047]\n",
      "epoch:25 step:24248 [D loss: 0.213659, acc.: 68.75%] [G loss: 0.402232]\n",
      "epoch:25 step:24249 [D loss: 0.224061, acc.: 64.06%] [G loss: 0.401997]\n",
      "epoch:25 step:24250 [D loss: 0.196969, acc.: 67.97%] [G loss: 0.431090]\n",
      "epoch:25 step:24251 [D loss: 0.214422, acc.: 62.50%] [G loss: 0.443764]\n",
      "epoch:25 step:24252 [D loss: 0.243655, acc.: 60.94%] [G loss: 0.451868]\n",
      "epoch:25 step:24253 [D loss: 0.232481, acc.: 61.72%] [G loss: 0.440163]\n",
      "epoch:25 step:24254 [D loss: 0.230435, acc.: 63.28%] [G loss: 0.429157]\n",
      "epoch:25 step:24255 [D loss: 0.221949, acc.: 58.59%] [G loss: 0.416337]\n",
      "epoch:25 step:24256 [D loss: 0.203703, acc.: 67.19%] [G loss: 0.416673]\n",
      "epoch:25 step:24257 [D loss: 0.208168, acc.: 63.28%] [G loss: 0.457736]\n",
      "epoch:25 step:24258 [D loss: 0.201477, acc.: 70.31%] [G loss: 0.448548]\n",
      "epoch:25 step:24259 [D loss: 0.224359, acc.: 66.41%] [G loss: 0.424041]\n",
      "epoch:25 step:24260 [D loss: 0.230548, acc.: 57.03%] [G loss: 0.454268]\n",
      "epoch:25 step:24261 [D loss: 0.220813, acc.: 66.41%] [G loss: 0.433402]\n",
      "epoch:25 step:24262 [D loss: 0.210074, acc.: 67.19%] [G loss: 0.448096]\n",
      "epoch:25 step:24263 [D loss: 0.205586, acc.: 65.62%] [G loss: 0.404615]\n",
      "epoch:25 step:24264 [D loss: 0.191790, acc.: 69.53%] [G loss: 0.455911]\n",
      "epoch:25 step:24265 [D loss: 0.225155, acc.: 60.16%] [G loss: 0.409250]\n",
      "epoch:25 step:24266 [D loss: 0.195544, acc.: 68.75%] [G loss: 0.454905]\n",
      "epoch:25 step:24267 [D loss: 0.190572, acc.: 74.22%] [G loss: 0.456626]\n",
      "epoch:25 step:24268 [D loss: 0.218777, acc.: 61.72%] [G loss: 0.402497]\n",
      "epoch:25 step:24269 [D loss: 0.229617, acc.: 63.28%] [G loss: 0.448754]\n",
      "epoch:25 step:24270 [D loss: 0.207071, acc.: 65.62%] [G loss: 0.459974]\n",
      "epoch:25 step:24271 [D loss: 0.226162, acc.: 62.50%] [G loss: 0.445657]\n",
      "epoch:25 step:24272 [D loss: 0.250725, acc.: 55.47%] [G loss: 0.419734]\n",
      "epoch:25 step:24273 [D loss: 0.232087, acc.: 57.81%] [G loss: 0.432018]\n",
      "epoch:25 step:24274 [D loss: 0.216500, acc.: 67.97%] [G loss: 0.461458]\n",
      "epoch:25 step:24275 [D loss: 0.244953, acc.: 60.94%] [G loss: 0.453506]\n",
      "epoch:25 step:24276 [D loss: 0.241774, acc.: 57.81%] [G loss: 0.396723]\n",
      "epoch:25 step:24277 [D loss: 0.216091, acc.: 60.16%] [G loss: 0.415903]\n",
      "epoch:25 step:24278 [D loss: 0.224565, acc.: 64.06%] [G loss: 0.453194]\n",
      "epoch:25 step:24279 [D loss: 0.225787, acc.: 62.50%] [G loss: 0.417819]\n",
      "epoch:25 step:24280 [D loss: 0.241200, acc.: 57.03%] [G loss: 0.447266]\n",
      "epoch:25 step:24281 [D loss: 0.241908, acc.: 60.94%] [G loss: 0.422917]\n",
      "epoch:25 step:24282 [D loss: 0.200380, acc.: 73.44%] [G loss: 0.429916]\n",
      "epoch:25 step:24283 [D loss: 0.269513, acc.: 51.56%] [G loss: 0.381358]\n",
      "epoch:25 step:24284 [D loss: 0.244822, acc.: 55.47%] [G loss: 0.414048]\n",
      "epoch:25 step:24285 [D loss: 0.207350, acc.: 69.53%] [G loss: 0.426852]\n",
      "epoch:25 step:24286 [D loss: 0.233107, acc.: 59.38%] [G loss: 0.408549]\n",
      "epoch:25 step:24287 [D loss: 0.244992, acc.: 59.38%] [G loss: 0.386328]\n",
      "epoch:25 step:24288 [D loss: 0.229150, acc.: 67.97%] [G loss: 0.412917]\n",
      "epoch:25 step:24289 [D loss: 0.227519, acc.: 64.06%] [G loss: 0.422316]\n",
      "epoch:25 step:24290 [D loss: 0.241461, acc.: 60.16%] [G loss: 0.414741]\n",
      "epoch:25 step:24291 [D loss: 0.224305, acc.: 65.62%] [G loss: 0.411741]\n",
      "epoch:25 step:24292 [D loss: 0.232959, acc.: 56.25%] [G loss: 0.416203]\n",
      "epoch:25 step:24293 [D loss: 0.218501, acc.: 64.06%] [G loss: 0.434489]\n",
      "epoch:25 step:24294 [D loss: 0.247162, acc.: 55.47%] [G loss: 0.407993]\n",
      "epoch:25 step:24295 [D loss: 0.234396, acc.: 57.81%] [G loss: 0.399549]\n",
      "epoch:25 step:24296 [D loss: 0.218718, acc.: 60.16%] [G loss: 0.430254]\n",
      "epoch:25 step:24297 [D loss: 0.221366, acc.: 64.84%] [G loss: 0.448803]\n",
      "epoch:25 step:24298 [D loss: 0.225381, acc.: 63.28%] [G loss: 0.380029]\n",
      "epoch:25 step:24299 [D loss: 0.220557, acc.: 62.50%] [G loss: 0.392950]\n",
      "epoch:25 step:24300 [D loss: 0.192440, acc.: 69.53%] [G loss: 0.430283]\n",
      "epoch:25 step:24301 [D loss: 0.243706, acc.: 56.25%] [G loss: 0.457036]\n",
      "epoch:25 step:24302 [D loss: 0.229382, acc.: 61.72%] [G loss: 0.440797]\n",
      "epoch:25 step:24303 [D loss: 0.240658, acc.: 60.16%] [G loss: 0.430897]\n",
      "epoch:25 step:24304 [D loss: 0.229615, acc.: 60.94%] [G loss: 0.414811]\n",
      "epoch:25 step:24305 [D loss: 0.239161, acc.: 57.03%] [G loss: 0.411766]\n",
      "epoch:25 step:24306 [D loss: 0.219063, acc.: 65.62%] [G loss: 0.382210]\n",
      "epoch:25 step:24307 [D loss: 0.218232, acc.: 64.06%] [G loss: 0.448579]\n",
      "epoch:25 step:24308 [D loss: 0.243153, acc.: 57.03%] [G loss: 0.411736]\n",
      "epoch:25 step:24309 [D loss: 0.234829, acc.: 57.03%] [G loss: 0.445554]\n",
      "epoch:25 step:24310 [D loss: 0.210936, acc.: 64.84%] [G loss: 0.534396]\n",
      "epoch:25 step:24311 [D loss: 0.205767, acc.: 68.75%] [G loss: 0.503614]\n",
      "epoch:25 step:24312 [D loss: 0.235063, acc.: 63.28%] [G loss: 0.500906]\n",
      "epoch:25 step:24313 [D loss: 0.249137, acc.: 58.59%] [G loss: 0.457016]\n",
      "epoch:25 step:24314 [D loss: 0.227676, acc.: 63.28%] [G loss: 0.442188]\n",
      "epoch:25 step:24315 [D loss: 0.222668, acc.: 59.38%] [G loss: 0.448107]\n",
      "epoch:25 step:24316 [D loss: 0.284646, acc.: 44.53%] [G loss: 0.434832]\n",
      "epoch:25 step:24317 [D loss: 0.250926, acc.: 50.78%] [G loss: 0.428802]\n",
      "epoch:25 step:24318 [D loss: 0.209819, acc.: 68.75%] [G loss: 0.416674]\n",
      "epoch:25 step:24319 [D loss: 0.212727, acc.: 67.19%] [G loss: 0.417753]\n",
      "epoch:25 step:24320 [D loss: 0.221066, acc.: 62.50%] [G loss: 0.401212]\n",
      "epoch:25 step:24321 [D loss: 0.210862, acc.: 66.41%] [G loss: 0.412940]\n",
      "epoch:25 step:24322 [D loss: 0.214659, acc.: 67.19%] [G loss: 0.448293]\n",
      "epoch:25 step:24323 [D loss: 0.217355, acc.: 63.28%] [G loss: 0.446468]\n",
      "epoch:25 step:24324 [D loss: 0.183944, acc.: 76.56%] [G loss: 0.495929]\n",
      "epoch:25 step:24325 [D loss: 0.217513, acc.: 64.84%] [G loss: 0.473220]\n",
      "epoch:25 step:24326 [D loss: 0.237219, acc.: 60.94%] [G loss: 0.432782]\n",
      "epoch:25 step:24327 [D loss: 0.244286, acc.: 53.91%] [G loss: 0.435834]\n",
      "epoch:25 step:24328 [D loss: 0.236914, acc.: 60.94%] [G loss: 0.385783]\n",
      "epoch:25 step:24329 [D loss: 0.232350, acc.: 58.59%] [G loss: 0.446173]\n",
      "epoch:25 step:24330 [D loss: 0.207666, acc.: 70.31%] [G loss: 0.446454]\n",
      "epoch:25 step:24331 [D loss: 0.229518, acc.: 63.28%] [G loss: 0.446229]\n",
      "epoch:25 step:24332 [D loss: 0.223802, acc.: 61.72%] [G loss: 0.425803]\n",
      "epoch:25 step:24333 [D loss: 0.218153, acc.: 64.06%] [G loss: 0.427232]\n",
      "epoch:25 step:24334 [D loss: 0.193309, acc.: 68.75%] [G loss: 0.467029]\n",
      "epoch:25 step:24335 [D loss: 0.232727, acc.: 62.50%] [G loss: 0.453213]\n",
      "epoch:25 step:24336 [D loss: 0.219668, acc.: 62.50%] [G loss: 0.427498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24337 [D loss: 0.192758, acc.: 73.44%] [G loss: 0.436812]\n",
      "epoch:25 step:24338 [D loss: 0.224992, acc.: 64.06%] [G loss: 0.455241]\n",
      "epoch:25 step:24339 [D loss: 0.227751, acc.: 60.16%] [G loss: 0.432067]\n",
      "epoch:25 step:24340 [D loss: 0.307965, acc.: 43.75%] [G loss: 0.366272]\n",
      "epoch:25 step:24341 [D loss: 0.216696, acc.: 65.62%] [G loss: 0.403398]\n",
      "epoch:25 step:24342 [D loss: 0.202343, acc.: 70.31%] [G loss: 0.426106]\n",
      "epoch:25 step:24343 [D loss: 0.193440, acc.: 70.31%] [G loss: 0.473831]\n",
      "epoch:25 step:24344 [D loss: 0.235088, acc.: 59.38%] [G loss: 0.472839]\n",
      "epoch:25 step:24345 [D loss: 0.261298, acc.: 53.12%] [G loss: 0.529377]\n",
      "epoch:25 step:24346 [D loss: 0.227140, acc.: 64.06%] [G loss: 0.453951]\n",
      "epoch:25 step:24347 [D loss: 0.262408, acc.: 53.91%] [G loss: 0.401592]\n",
      "epoch:25 step:24348 [D loss: 0.216897, acc.: 66.41%] [G loss: 0.418941]\n",
      "epoch:25 step:24349 [D loss: 0.189128, acc.: 72.66%] [G loss: 0.433613]\n",
      "epoch:25 step:24350 [D loss: 0.177710, acc.: 77.34%] [G loss: 0.428219]\n",
      "epoch:25 step:24351 [D loss: 0.198802, acc.: 70.31%] [G loss: 0.490561]\n",
      "epoch:25 step:24352 [D loss: 0.183632, acc.: 72.66%] [G loss: 0.474618]\n",
      "epoch:25 step:24353 [D loss: 0.299830, acc.: 53.91%] [G loss: 0.480842]\n",
      "epoch:25 step:24354 [D loss: 0.256133, acc.: 60.94%] [G loss: 0.574745]\n",
      "epoch:25 step:24355 [D loss: 0.198793, acc.: 71.88%] [G loss: 0.558858]\n",
      "epoch:25 step:24356 [D loss: 0.234797, acc.: 64.84%] [G loss: 0.488604]\n",
      "epoch:25 step:24357 [D loss: 0.235406, acc.: 59.38%] [G loss: 0.428899]\n",
      "epoch:25 step:24358 [D loss: 0.220472, acc.: 64.84%] [G loss: 0.452645]\n",
      "epoch:25 step:24359 [D loss: 0.239568, acc.: 60.94%] [G loss: 0.478014]\n",
      "epoch:25 step:24360 [D loss: 0.195885, acc.: 69.53%] [G loss: 0.493658]\n",
      "epoch:25 step:24361 [D loss: 0.177667, acc.: 75.00%] [G loss: 0.482357]\n",
      "epoch:25 step:24362 [D loss: 0.217109, acc.: 69.53%] [G loss: 0.489991]\n",
      "epoch:26 step:24363 [D loss: 0.227596, acc.: 64.06%] [G loss: 0.528975]\n",
      "epoch:26 step:24364 [D loss: 0.256267, acc.: 57.81%] [G loss: 0.519631]\n",
      "epoch:26 step:24365 [D loss: 0.246416, acc.: 60.16%] [G loss: 0.438230]\n",
      "epoch:26 step:24366 [D loss: 0.229785, acc.: 64.84%] [G loss: 0.429980]\n",
      "epoch:26 step:24367 [D loss: 0.237842, acc.: 59.38%] [G loss: 0.411917]\n",
      "epoch:26 step:24368 [D loss: 0.223573, acc.: 63.28%] [G loss: 0.393008]\n",
      "epoch:26 step:24369 [D loss: 0.218115, acc.: 67.19%] [G loss: 0.429746]\n",
      "epoch:26 step:24370 [D loss: 0.193014, acc.: 71.09%] [G loss: 0.461257]\n",
      "epoch:26 step:24371 [D loss: 0.213053, acc.: 64.84%] [G loss: 0.444283]\n",
      "epoch:26 step:24372 [D loss: 0.218885, acc.: 67.97%] [G loss: 0.435945]\n",
      "epoch:26 step:24373 [D loss: 0.213967, acc.: 64.84%] [G loss: 0.461277]\n",
      "epoch:26 step:24374 [D loss: 0.224836, acc.: 64.84%] [G loss: 0.435581]\n",
      "epoch:26 step:24375 [D loss: 0.207927, acc.: 67.19%] [G loss: 0.454535]\n",
      "epoch:26 step:24376 [D loss: 0.199910, acc.: 71.88%] [G loss: 0.445685]\n",
      "epoch:26 step:24377 [D loss: 0.183809, acc.: 68.75%] [G loss: 0.461369]\n",
      "epoch:26 step:24378 [D loss: 0.189662, acc.: 74.22%] [G loss: 0.436638]\n",
      "epoch:26 step:24379 [D loss: 0.218556, acc.: 60.94%] [G loss: 0.458398]\n",
      "epoch:26 step:24380 [D loss: 0.240598, acc.: 56.25%] [G loss: 0.430816]\n",
      "epoch:26 step:24381 [D loss: 0.243678, acc.: 56.25%] [G loss: 0.485950]\n",
      "epoch:26 step:24382 [D loss: 0.269069, acc.: 53.12%] [G loss: 0.517533]\n",
      "epoch:26 step:24383 [D loss: 0.236419, acc.: 58.59%] [G loss: 0.491965]\n",
      "epoch:26 step:24384 [D loss: 0.188494, acc.: 73.44%] [G loss: 0.525136]\n",
      "epoch:26 step:24385 [D loss: 0.260632, acc.: 55.47%] [G loss: 0.381320]\n",
      "epoch:26 step:24386 [D loss: 0.236610, acc.: 61.72%] [G loss: 0.398896]\n",
      "epoch:26 step:24387 [D loss: 0.204854, acc.: 64.84%] [G loss: 0.456785]\n",
      "epoch:26 step:24388 [D loss: 0.225007, acc.: 62.50%] [G loss: 0.435500]\n",
      "epoch:26 step:24389 [D loss: 0.245466, acc.: 53.12%] [G loss: 0.427918]\n",
      "epoch:26 step:24390 [D loss: 0.202884, acc.: 73.44%] [G loss: 0.452752]\n",
      "epoch:26 step:24391 [D loss: 0.208019, acc.: 67.19%] [G loss: 0.399653]\n",
      "epoch:26 step:24392 [D loss: 0.224204, acc.: 61.72%] [G loss: 0.406615]\n",
      "epoch:26 step:24393 [D loss: 0.242683, acc.: 59.38%] [G loss: 0.389914]\n",
      "epoch:26 step:24394 [D loss: 0.252879, acc.: 57.03%] [G loss: 0.423445]\n",
      "epoch:26 step:24395 [D loss: 0.242658, acc.: 57.03%] [G loss: 0.443065]\n",
      "epoch:26 step:24396 [D loss: 0.220365, acc.: 62.50%] [G loss: 0.428612]\n",
      "epoch:26 step:24397 [D loss: 0.242433, acc.: 57.03%] [G loss: 0.392376]\n",
      "epoch:26 step:24398 [D loss: 0.195455, acc.: 67.97%] [G loss: 0.398384]\n",
      "epoch:26 step:24399 [D loss: 0.253626, acc.: 56.25%] [G loss: 0.416014]\n",
      "epoch:26 step:24400 [D loss: 0.257576, acc.: 53.12%] [G loss: 0.416981]\n",
      "epoch:26 step:24401 [D loss: 0.225490, acc.: 61.72%] [G loss: 0.424778]\n",
      "epoch:26 step:24402 [D loss: 0.196547, acc.: 72.66%] [G loss: 0.390980]\n",
      "epoch:26 step:24403 [D loss: 0.229247, acc.: 60.94%] [G loss: 0.415468]\n",
      "epoch:26 step:24404 [D loss: 0.229949, acc.: 60.94%] [G loss: 0.411214]\n",
      "epoch:26 step:24405 [D loss: 0.211693, acc.: 69.53%] [G loss: 0.408345]\n",
      "epoch:26 step:24406 [D loss: 0.218263, acc.: 64.06%] [G loss: 0.449990]\n",
      "epoch:26 step:24407 [D loss: 0.219832, acc.: 63.28%] [G loss: 0.407659]\n",
      "epoch:26 step:24408 [D loss: 0.237075, acc.: 60.16%] [G loss: 0.413267]\n",
      "epoch:26 step:24409 [D loss: 0.233170, acc.: 63.28%] [G loss: 0.415598]\n",
      "epoch:26 step:24410 [D loss: 0.184814, acc.: 72.66%] [G loss: 0.390497]\n",
      "epoch:26 step:24411 [D loss: 0.206724, acc.: 66.41%] [G loss: 0.391355]\n",
      "epoch:26 step:24412 [D loss: 0.209087, acc.: 64.84%] [G loss: 0.434821]\n",
      "epoch:26 step:24413 [D loss: 0.240147, acc.: 57.03%] [G loss: 0.419845]\n",
      "epoch:26 step:24414 [D loss: 0.211471, acc.: 64.84%] [G loss: 0.474292]\n",
      "epoch:26 step:24415 [D loss: 0.200855, acc.: 70.31%] [G loss: 0.412504]\n",
      "epoch:26 step:24416 [D loss: 0.212119, acc.: 67.19%] [G loss: 0.478469]\n",
      "epoch:26 step:24417 [D loss: 0.222326, acc.: 60.94%] [G loss: 0.471062]\n",
      "epoch:26 step:24418 [D loss: 0.205957, acc.: 65.62%] [G loss: 0.489386]\n",
      "epoch:26 step:24419 [D loss: 0.230866, acc.: 52.34%] [G loss: 0.437237]\n",
      "epoch:26 step:24420 [D loss: 0.194216, acc.: 71.88%] [G loss: 0.423676]\n",
      "epoch:26 step:24421 [D loss: 0.223417, acc.: 66.41%] [G loss: 0.417788]\n",
      "epoch:26 step:24422 [D loss: 0.223978, acc.: 64.06%] [G loss: 0.444480]\n",
      "epoch:26 step:24423 [D loss: 0.227616, acc.: 63.28%] [G loss: 0.403679]\n",
      "epoch:26 step:24424 [D loss: 0.233278, acc.: 60.16%] [G loss: 0.437829]\n",
      "epoch:26 step:24425 [D loss: 0.205341, acc.: 73.44%] [G loss: 0.449514]\n",
      "epoch:26 step:24426 [D loss: 0.224868, acc.: 63.28%] [G loss: 0.385233]\n",
      "epoch:26 step:24427 [D loss: 0.216313, acc.: 67.19%] [G loss: 0.448770]\n",
      "epoch:26 step:24428 [D loss: 0.196567, acc.: 68.75%] [G loss: 0.419169]\n",
      "epoch:26 step:24429 [D loss: 0.217982, acc.: 61.72%] [G loss: 0.427556]\n",
      "epoch:26 step:24430 [D loss: 0.228055, acc.: 63.28%] [G loss: 0.453719]\n",
      "epoch:26 step:24431 [D loss: 0.192122, acc.: 71.09%] [G loss: 0.460378]\n",
      "epoch:26 step:24432 [D loss: 0.212002, acc.: 68.75%] [G loss: 0.530684]\n",
      "epoch:26 step:24433 [D loss: 0.221918, acc.: 64.06%] [G loss: 0.424580]\n",
      "epoch:26 step:24434 [D loss: 0.247460, acc.: 64.06%] [G loss: 0.422202]\n",
      "epoch:26 step:24435 [D loss: 0.221580, acc.: 69.53%] [G loss: 0.400208]\n",
      "epoch:26 step:24436 [D loss: 0.212173, acc.: 67.19%] [G loss: 0.397085]\n",
      "epoch:26 step:24437 [D loss: 0.202533, acc.: 65.62%] [G loss: 0.432957]\n",
      "epoch:26 step:24438 [D loss: 0.183882, acc.: 76.56%] [G loss: 0.446258]\n",
      "epoch:26 step:24439 [D loss: 0.175350, acc.: 73.44%] [G loss: 0.483740]\n",
      "epoch:26 step:24440 [D loss: 0.248988, acc.: 54.69%] [G loss: 0.427403]\n",
      "epoch:26 step:24441 [D loss: 0.216033, acc.: 67.97%] [G loss: 0.405785]\n",
      "epoch:26 step:24442 [D loss: 0.224721, acc.: 62.50%] [G loss: 0.429987]\n",
      "epoch:26 step:24443 [D loss: 0.245698, acc.: 56.25%] [G loss: 0.419125]\n",
      "epoch:26 step:24444 [D loss: 0.213913, acc.: 68.75%] [G loss: 0.407604]\n",
      "epoch:26 step:24445 [D loss: 0.218206, acc.: 63.28%] [G loss: 0.417017]\n",
      "epoch:26 step:24446 [D loss: 0.204938, acc.: 68.75%] [G loss: 0.484213]\n",
      "epoch:26 step:24447 [D loss: 0.225034, acc.: 58.59%] [G loss: 0.499664]\n",
      "epoch:26 step:24448 [D loss: 0.229507, acc.: 64.06%] [G loss: 0.454914]\n",
      "epoch:26 step:24449 [D loss: 0.225473, acc.: 58.59%] [G loss: 0.436266]\n",
      "epoch:26 step:24450 [D loss: 0.215938, acc.: 64.06%] [G loss: 0.429991]\n",
      "epoch:26 step:24451 [D loss: 0.219149, acc.: 64.06%] [G loss: 0.431652]\n",
      "epoch:26 step:24452 [D loss: 0.202734, acc.: 67.19%] [G loss: 0.467076]\n",
      "epoch:26 step:24453 [D loss: 0.239163, acc.: 62.50%] [G loss: 0.420695]\n",
      "epoch:26 step:24454 [D loss: 0.209032, acc.: 65.62%] [G loss: 0.436799]\n",
      "epoch:26 step:24455 [D loss: 0.216402, acc.: 63.28%] [G loss: 0.395557]\n",
      "epoch:26 step:24456 [D loss: 0.221670, acc.: 60.16%] [G loss: 0.460125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24457 [D loss: 0.224745, acc.: 62.50%] [G loss: 0.450223]\n",
      "epoch:26 step:24458 [D loss: 0.234535, acc.: 58.59%] [G loss: 0.486641]\n",
      "epoch:26 step:24459 [D loss: 0.200845, acc.: 68.75%] [G loss: 0.528815]\n",
      "epoch:26 step:24460 [D loss: 0.239295, acc.: 60.94%] [G loss: 0.476181]\n",
      "epoch:26 step:24461 [D loss: 0.237088, acc.: 55.47%] [G loss: 0.414189]\n",
      "epoch:26 step:24462 [D loss: 0.215601, acc.: 70.31%] [G loss: 0.453635]\n",
      "epoch:26 step:24463 [D loss: 0.193516, acc.: 65.62%] [G loss: 0.515109]\n",
      "epoch:26 step:24464 [D loss: 0.234768, acc.: 61.72%] [G loss: 0.422038]\n",
      "epoch:26 step:24465 [D loss: 0.240809, acc.: 55.47%] [G loss: 0.445714]\n",
      "epoch:26 step:24466 [D loss: 0.228407, acc.: 60.16%] [G loss: 0.418818]\n",
      "epoch:26 step:24467 [D loss: 0.247033, acc.: 55.47%] [G loss: 0.411806]\n",
      "epoch:26 step:24468 [D loss: 0.195424, acc.: 71.88%] [G loss: 0.399394]\n",
      "epoch:26 step:24469 [D loss: 0.215001, acc.: 65.62%] [G loss: 0.438803]\n",
      "epoch:26 step:24470 [D loss: 0.237943, acc.: 62.50%] [G loss: 0.462451]\n",
      "epoch:26 step:24471 [D loss: 0.260304, acc.: 56.25%] [G loss: 0.418934]\n",
      "epoch:26 step:24472 [D loss: 0.237596, acc.: 58.59%] [G loss: 0.434028]\n",
      "epoch:26 step:24473 [D loss: 0.208773, acc.: 65.62%] [G loss: 0.435457]\n",
      "epoch:26 step:24474 [D loss: 0.195626, acc.: 69.53%] [G loss: 0.425574]\n",
      "epoch:26 step:24475 [D loss: 0.204060, acc.: 70.31%] [G loss: 0.461848]\n",
      "epoch:26 step:24476 [D loss: 0.219270, acc.: 67.19%] [G loss: 0.462572]\n",
      "epoch:26 step:24477 [D loss: 0.197408, acc.: 67.19%] [G loss: 0.522999]\n",
      "epoch:26 step:24478 [D loss: 0.210224, acc.: 66.41%] [G loss: 0.429051]\n",
      "epoch:26 step:24479 [D loss: 0.206167, acc.: 67.19%] [G loss: 0.399799]\n",
      "epoch:26 step:24480 [D loss: 0.205844, acc.: 66.41%] [G loss: 0.488121]\n",
      "epoch:26 step:24481 [D loss: 0.196786, acc.: 67.97%] [G loss: 0.510322]\n",
      "epoch:26 step:24482 [D loss: 0.219191, acc.: 67.97%] [G loss: 0.507249]\n",
      "epoch:26 step:24483 [D loss: 0.233255, acc.: 58.59%] [G loss: 0.418687]\n",
      "epoch:26 step:24484 [D loss: 0.205083, acc.: 67.19%] [G loss: 0.446199]\n",
      "epoch:26 step:24485 [D loss: 0.221064, acc.: 62.50%] [G loss: 0.477917]\n",
      "epoch:26 step:24486 [D loss: 0.236858, acc.: 59.38%] [G loss: 0.466189]\n",
      "epoch:26 step:24487 [D loss: 0.231680, acc.: 60.94%] [G loss: 0.415509]\n",
      "epoch:26 step:24488 [D loss: 0.205925, acc.: 66.41%] [G loss: 0.445833]\n",
      "epoch:26 step:24489 [D loss: 0.193857, acc.: 69.53%] [G loss: 0.418761]\n",
      "epoch:26 step:24490 [D loss: 0.228474, acc.: 60.16%] [G loss: 0.426353]\n",
      "epoch:26 step:24491 [D loss: 0.222560, acc.: 68.75%] [G loss: 0.385518]\n",
      "epoch:26 step:24492 [D loss: 0.199411, acc.: 70.31%] [G loss: 0.415899]\n",
      "epoch:26 step:24493 [D loss: 0.199183, acc.: 72.66%] [G loss: 0.438498]\n",
      "epoch:26 step:24494 [D loss: 0.227368, acc.: 61.72%] [G loss: 0.442610]\n",
      "epoch:26 step:24495 [D loss: 0.245567, acc.: 57.03%] [G loss: 0.444673]\n",
      "epoch:26 step:24496 [D loss: 0.230073, acc.: 61.72%] [G loss: 0.432412]\n",
      "epoch:26 step:24497 [D loss: 0.187009, acc.: 71.88%] [G loss: 0.455404]\n",
      "epoch:26 step:24498 [D loss: 0.201496, acc.: 74.22%] [G loss: 0.472614]\n",
      "epoch:26 step:24499 [D loss: 0.282248, acc.: 46.88%] [G loss: 0.419030]\n",
      "epoch:26 step:24500 [D loss: 0.252862, acc.: 55.47%] [G loss: 0.375749]\n",
      "epoch:26 step:24501 [D loss: 0.219497, acc.: 64.06%] [G loss: 0.398124]\n",
      "epoch:26 step:24502 [D loss: 0.254019, acc.: 56.25%] [G loss: 0.435626]\n",
      "epoch:26 step:24503 [D loss: 0.218935, acc.: 60.94%] [G loss: 0.404286]\n",
      "epoch:26 step:24504 [D loss: 0.236057, acc.: 64.06%] [G loss: 0.378110]\n",
      "epoch:26 step:24505 [D loss: 0.266682, acc.: 52.34%] [G loss: 0.398461]\n",
      "epoch:26 step:24506 [D loss: 0.217428, acc.: 60.94%] [G loss: 0.425025]\n",
      "epoch:26 step:24507 [D loss: 0.223265, acc.: 61.72%] [G loss: 0.468338]\n",
      "epoch:26 step:24508 [D loss: 0.214148, acc.: 66.41%] [G loss: 0.450879]\n",
      "epoch:26 step:24509 [D loss: 0.213026, acc.: 64.06%] [G loss: 0.432501]\n",
      "epoch:26 step:24510 [D loss: 0.253304, acc.: 57.03%] [G loss: 0.407262]\n",
      "epoch:26 step:24511 [D loss: 0.228303, acc.: 62.50%] [G loss: 0.441179]\n",
      "epoch:26 step:24512 [D loss: 0.250109, acc.: 55.47%] [G loss: 0.444594]\n",
      "epoch:26 step:24513 [D loss: 0.197612, acc.: 70.31%] [G loss: 0.453920]\n",
      "epoch:26 step:24514 [D loss: 0.222385, acc.: 64.84%] [G loss: 0.453123]\n",
      "epoch:26 step:24515 [D loss: 0.224568, acc.: 64.84%] [G loss: 0.392786]\n",
      "epoch:26 step:24516 [D loss: 0.207186, acc.: 71.09%] [G loss: 0.409148]\n",
      "epoch:26 step:24517 [D loss: 0.196532, acc.: 68.75%] [G loss: 0.427049]\n",
      "epoch:26 step:24518 [D loss: 0.215253, acc.: 64.06%] [G loss: 0.425264]\n",
      "epoch:26 step:24519 [D loss: 0.225070, acc.: 66.41%] [G loss: 0.423419]\n",
      "epoch:26 step:24520 [D loss: 0.238314, acc.: 58.59%] [G loss: 0.433851]\n",
      "epoch:26 step:24521 [D loss: 0.211212, acc.: 70.31%] [G loss: 0.437930]\n",
      "epoch:26 step:24522 [D loss: 0.253480, acc.: 55.47%] [G loss: 0.439716]\n",
      "epoch:26 step:24523 [D loss: 0.230562, acc.: 57.03%] [G loss: 0.447919]\n",
      "epoch:26 step:24524 [D loss: 0.234786, acc.: 57.81%] [G loss: 0.418427]\n",
      "epoch:26 step:24525 [D loss: 0.224428, acc.: 62.50%] [G loss: 0.448354]\n",
      "epoch:26 step:24526 [D loss: 0.230051, acc.: 60.16%] [G loss: 0.449536]\n",
      "epoch:26 step:24527 [D loss: 0.234555, acc.: 61.72%] [G loss: 0.442195]\n",
      "epoch:26 step:24528 [D loss: 0.240707, acc.: 60.16%] [G loss: 0.413984]\n",
      "epoch:26 step:24529 [D loss: 0.198320, acc.: 69.53%] [G loss: 0.417396]\n",
      "epoch:26 step:24530 [D loss: 0.220667, acc.: 64.84%] [G loss: 0.391263]\n",
      "epoch:26 step:24531 [D loss: 0.226235, acc.: 63.28%] [G loss: 0.379542]\n",
      "epoch:26 step:24532 [D loss: 0.227313, acc.: 66.41%] [G loss: 0.402594]\n",
      "epoch:26 step:24533 [D loss: 0.224031, acc.: 63.28%] [G loss: 0.413605]\n",
      "epoch:26 step:24534 [D loss: 0.226377, acc.: 57.81%] [G loss: 0.421680]\n",
      "epoch:26 step:24535 [D loss: 0.205871, acc.: 68.75%] [G loss: 0.440397]\n",
      "epoch:26 step:24536 [D loss: 0.229674, acc.: 64.06%] [G loss: 0.419497]\n",
      "epoch:26 step:24537 [D loss: 0.228191, acc.: 64.06%] [G loss: 0.401505]\n",
      "epoch:26 step:24538 [D loss: 0.195209, acc.: 72.66%] [G loss: 0.433641]\n",
      "epoch:26 step:24539 [D loss: 0.255315, acc.: 53.91%] [G loss: 0.410532]\n",
      "epoch:26 step:24540 [D loss: 0.219271, acc.: 66.41%] [G loss: 0.420527]\n",
      "epoch:26 step:24541 [D loss: 0.205966, acc.: 67.19%] [G loss: 0.461570]\n",
      "epoch:26 step:24542 [D loss: 0.232695, acc.: 60.16%] [G loss: 0.409987]\n",
      "epoch:26 step:24543 [D loss: 0.235270, acc.: 53.91%] [G loss: 0.406154]\n",
      "epoch:26 step:24544 [D loss: 0.231253, acc.: 63.28%] [G loss: 0.433923]\n",
      "epoch:26 step:24545 [D loss: 0.239055, acc.: 62.50%] [G loss: 0.421382]\n",
      "epoch:26 step:24546 [D loss: 0.237023, acc.: 62.50%] [G loss: 0.387649]\n",
      "epoch:26 step:24547 [D loss: 0.236049, acc.: 57.03%] [G loss: 0.421905]\n",
      "epoch:26 step:24548 [D loss: 0.230970, acc.: 64.06%] [G loss: 0.412768]\n",
      "epoch:26 step:24549 [D loss: 0.226134, acc.: 64.06%] [G loss: 0.399089]\n",
      "epoch:26 step:24550 [D loss: 0.227258, acc.: 62.50%] [G loss: 0.420231]\n",
      "epoch:26 step:24551 [D loss: 0.235431, acc.: 53.91%] [G loss: 0.396349]\n",
      "epoch:26 step:24552 [D loss: 0.214045, acc.: 63.28%] [G loss: 0.401782]\n",
      "epoch:26 step:24553 [D loss: 0.220081, acc.: 60.94%] [G loss: 0.414669]\n",
      "epoch:26 step:24554 [D loss: 0.232985, acc.: 55.47%] [G loss: 0.401747]\n",
      "epoch:26 step:24555 [D loss: 0.213946, acc.: 68.75%] [G loss: 0.411039]\n",
      "epoch:26 step:24556 [D loss: 0.205544, acc.: 65.62%] [G loss: 0.448596]\n",
      "epoch:26 step:24557 [D loss: 0.223228, acc.: 61.72%] [G loss: 0.403906]\n",
      "epoch:26 step:24558 [D loss: 0.233415, acc.: 61.72%] [G loss: 0.444752]\n",
      "epoch:26 step:24559 [D loss: 0.217490, acc.: 65.62%] [G loss: 0.433847]\n",
      "epoch:26 step:24560 [D loss: 0.189732, acc.: 75.00%] [G loss: 0.437815]\n",
      "epoch:26 step:24561 [D loss: 0.260851, acc.: 58.59%] [G loss: 0.420330]\n",
      "epoch:26 step:24562 [D loss: 0.220316, acc.: 66.41%] [G loss: 0.442559]\n",
      "epoch:26 step:24563 [D loss: 0.236172, acc.: 63.28%] [G loss: 0.431190]\n",
      "epoch:26 step:24564 [D loss: 0.217501, acc.: 63.28%] [G loss: 0.462462]\n",
      "epoch:26 step:24565 [D loss: 0.244002, acc.: 57.03%] [G loss: 0.436121]\n",
      "epoch:26 step:24566 [D loss: 0.233266, acc.: 64.06%] [G loss: 0.441110]\n",
      "epoch:26 step:24567 [D loss: 0.210694, acc.: 67.97%] [G loss: 0.529330]\n",
      "epoch:26 step:24568 [D loss: 0.219699, acc.: 65.62%] [G loss: 0.486363]\n",
      "epoch:26 step:24569 [D loss: 0.237847, acc.: 60.94%] [G loss: 0.415001]\n",
      "epoch:26 step:24570 [D loss: 0.201787, acc.: 68.75%] [G loss: 0.464034]\n",
      "epoch:26 step:24571 [D loss: 0.185692, acc.: 73.44%] [G loss: 0.481765]\n",
      "epoch:26 step:24572 [D loss: 0.245903, acc.: 57.81%] [G loss: 0.437893]\n",
      "epoch:26 step:24573 [D loss: 0.262352, acc.: 51.56%] [G loss: 0.370055]\n",
      "epoch:26 step:24574 [D loss: 0.226913, acc.: 61.72%] [G loss: 0.408752]\n",
      "epoch:26 step:24575 [D loss: 0.223412, acc.: 66.41%] [G loss: 0.424052]\n",
      "epoch:26 step:24576 [D loss: 0.235912, acc.: 60.16%] [G loss: 0.389545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24577 [D loss: 0.244856, acc.: 58.59%] [G loss: 0.405912]\n",
      "epoch:26 step:24578 [D loss: 0.191760, acc.: 69.53%] [G loss: 0.442489]\n",
      "epoch:26 step:24579 [D loss: 0.233586, acc.: 62.50%] [G loss: 0.431168]\n",
      "epoch:26 step:24580 [D loss: 0.214137, acc.: 67.19%] [G loss: 0.453230]\n",
      "epoch:26 step:24581 [D loss: 0.190426, acc.: 72.66%] [G loss: 0.461090]\n",
      "epoch:26 step:24582 [D loss: 0.255728, acc.: 61.72%] [G loss: 0.470106]\n",
      "epoch:26 step:24583 [D loss: 0.209372, acc.: 70.31%] [G loss: 0.450281]\n",
      "epoch:26 step:24584 [D loss: 0.201711, acc.: 70.31%] [G loss: 0.484584]\n",
      "epoch:26 step:24585 [D loss: 0.201348, acc.: 66.41%] [G loss: 0.474750]\n",
      "epoch:26 step:24586 [D loss: 0.234822, acc.: 59.38%] [G loss: 0.409904]\n",
      "epoch:26 step:24587 [D loss: 0.240623, acc.: 58.59%] [G loss: 0.396270]\n",
      "epoch:26 step:24588 [D loss: 0.240410, acc.: 61.72%] [G loss: 0.392619]\n",
      "epoch:26 step:24589 [D loss: 0.198338, acc.: 72.66%] [G loss: 0.432832]\n",
      "epoch:26 step:24590 [D loss: 0.234815, acc.: 58.59%] [G loss: 0.413068]\n",
      "epoch:26 step:24591 [D loss: 0.206570, acc.: 67.19%] [G loss: 0.423278]\n",
      "epoch:26 step:24592 [D loss: 0.184653, acc.: 71.88%] [G loss: 0.462348]\n",
      "epoch:26 step:24593 [D loss: 0.201029, acc.: 69.53%] [G loss: 0.512200]\n",
      "epoch:26 step:24594 [D loss: 0.187627, acc.: 72.66%] [G loss: 0.535390]\n",
      "epoch:26 step:24595 [D loss: 0.262620, acc.: 57.81%] [G loss: 0.406874]\n",
      "epoch:26 step:24596 [D loss: 0.254662, acc.: 57.03%] [G loss: 0.421272]\n",
      "epoch:26 step:24597 [D loss: 0.219728, acc.: 60.94%] [G loss: 0.398524]\n",
      "epoch:26 step:24598 [D loss: 0.227228, acc.: 63.28%] [G loss: 0.446180]\n",
      "epoch:26 step:24599 [D loss: 0.211774, acc.: 64.84%] [G loss: 0.419388]\n",
      "epoch:26 step:24600 [D loss: 0.216701, acc.: 66.41%] [G loss: 0.416708]\n",
      "epoch:26 step:24601 [D loss: 0.201924, acc.: 67.19%] [G loss: 0.437454]\n",
      "epoch:26 step:24602 [D loss: 0.217718, acc.: 67.19%] [G loss: 0.422921]\n",
      "epoch:26 step:24603 [D loss: 0.192142, acc.: 72.66%] [G loss: 0.470876]\n",
      "epoch:26 step:24604 [D loss: 0.203829, acc.: 71.09%] [G loss: 0.484099]\n",
      "epoch:26 step:24605 [D loss: 0.224785, acc.: 58.59%] [G loss: 0.474683]\n",
      "epoch:26 step:24606 [D loss: 0.190662, acc.: 76.56%] [G loss: 0.456694]\n",
      "epoch:26 step:24607 [D loss: 0.211740, acc.: 67.19%] [G loss: 0.405024]\n",
      "epoch:26 step:24608 [D loss: 0.217381, acc.: 65.62%] [G loss: 0.441539]\n",
      "epoch:26 step:24609 [D loss: 0.228071, acc.: 60.94%] [G loss: 0.453113]\n",
      "epoch:26 step:24610 [D loss: 0.198341, acc.: 66.41%] [G loss: 0.477130]\n",
      "epoch:26 step:24611 [D loss: 0.263045, acc.: 57.81%] [G loss: 0.406774]\n",
      "epoch:26 step:24612 [D loss: 0.276458, acc.: 52.34%] [G loss: 0.375985]\n",
      "epoch:26 step:24613 [D loss: 0.245052, acc.: 53.91%] [G loss: 0.457337]\n",
      "epoch:26 step:24614 [D loss: 0.215294, acc.: 65.62%] [G loss: 0.470668]\n",
      "epoch:26 step:24615 [D loss: 0.226094, acc.: 61.72%] [G loss: 0.438540]\n",
      "epoch:26 step:24616 [D loss: 0.264720, acc.: 50.00%] [G loss: 0.424759]\n",
      "epoch:26 step:24617 [D loss: 0.215798, acc.: 66.41%] [G loss: 0.411534]\n",
      "epoch:26 step:24618 [D loss: 0.230808, acc.: 63.28%] [G loss: 0.441775]\n",
      "epoch:26 step:24619 [D loss: 0.258199, acc.: 53.12%] [G loss: 0.416582]\n",
      "epoch:26 step:24620 [D loss: 0.189923, acc.: 76.56%] [G loss: 0.481558]\n",
      "epoch:26 step:24621 [D loss: 0.206945, acc.: 70.31%] [G loss: 0.443128]\n",
      "epoch:26 step:24622 [D loss: 0.223490, acc.: 60.16%] [G loss: 0.395280]\n",
      "epoch:26 step:24623 [D loss: 0.228822, acc.: 62.50%] [G loss: 0.390747]\n",
      "epoch:26 step:24624 [D loss: 0.207210, acc.: 69.53%] [G loss: 0.462861]\n",
      "epoch:26 step:24625 [D loss: 0.262710, acc.: 51.56%] [G loss: 0.427561]\n",
      "epoch:26 step:24626 [D loss: 0.195306, acc.: 68.75%] [G loss: 0.435304]\n",
      "epoch:26 step:24627 [D loss: 0.230387, acc.: 57.81%] [G loss: 0.422414]\n",
      "epoch:26 step:24628 [D loss: 0.228365, acc.: 59.38%] [G loss: 0.414180]\n",
      "epoch:26 step:24629 [D loss: 0.231079, acc.: 60.16%] [G loss: 0.417969]\n",
      "epoch:26 step:24630 [D loss: 0.197660, acc.: 68.75%] [G loss: 0.477423]\n",
      "epoch:26 step:24631 [D loss: 0.208367, acc.: 69.53%] [G loss: 0.443368]\n",
      "epoch:26 step:24632 [D loss: 0.204512, acc.: 68.75%] [G loss: 0.479952]\n",
      "epoch:26 step:24633 [D loss: 0.198248, acc.: 75.00%] [G loss: 0.465926]\n",
      "epoch:26 step:24634 [D loss: 0.241290, acc.: 59.38%] [G loss: 0.437528]\n",
      "epoch:26 step:24635 [D loss: 0.205258, acc.: 73.44%] [G loss: 0.447507]\n",
      "epoch:26 step:24636 [D loss: 0.197663, acc.: 70.31%] [G loss: 0.469262]\n",
      "epoch:26 step:24637 [D loss: 0.212571, acc.: 68.75%] [G loss: 0.442768]\n",
      "epoch:26 step:24638 [D loss: 0.193674, acc.: 71.09%] [G loss: 0.422540]\n",
      "epoch:26 step:24639 [D loss: 0.235026, acc.: 58.59%] [G loss: 0.454277]\n",
      "epoch:26 step:24640 [D loss: 0.230485, acc.: 60.94%] [G loss: 0.460092]\n",
      "epoch:26 step:24641 [D loss: 0.218802, acc.: 61.72%] [G loss: 0.440962]\n",
      "epoch:26 step:24642 [D loss: 0.195902, acc.: 70.31%] [G loss: 0.441727]\n",
      "epoch:26 step:24643 [D loss: 0.242078, acc.: 57.81%] [G loss: 0.450471]\n",
      "epoch:26 step:24644 [D loss: 0.236289, acc.: 57.03%] [G loss: 0.410161]\n",
      "epoch:26 step:24645 [D loss: 0.214625, acc.: 67.97%] [G loss: 0.403717]\n",
      "epoch:26 step:24646 [D loss: 0.211344, acc.: 68.75%] [G loss: 0.447044]\n",
      "epoch:26 step:24647 [D loss: 0.239617, acc.: 53.91%] [G loss: 0.462063]\n",
      "epoch:26 step:24648 [D loss: 0.241594, acc.: 57.03%] [G loss: 0.416089]\n",
      "epoch:26 step:24649 [D loss: 0.255386, acc.: 54.69%] [G loss: 0.445866]\n",
      "epoch:26 step:24650 [D loss: 0.215508, acc.: 65.62%] [G loss: 0.445052]\n",
      "epoch:26 step:24651 [D loss: 0.207001, acc.: 65.62%] [G loss: 0.443098]\n",
      "epoch:26 step:24652 [D loss: 0.188858, acc.: 71.88%] [G loss: 0.465258]\n",
      "epoch:26 step:24653 [D loss: 0.245412, acc.: 57.81%] [G loss: 0.408686]\n",
      "epoch:26 step:24654 [D loss: 0.195659, acc.: 73.44%] [G loss: 0.430173]\n",
      "epoch:26 step:24655 [D loss: 0.218631, acc.: 60.94%] [G loss: 0.415287]\n",
      "epoch:26 step:24656 [D loss: 0.243779, acc.: 57.81%] [G loss: 0.395373]\n",
      "epoch:26 step:24657 [D loss: 0.217128, acc.: 60.94%] [G loss: 0.413244]\n",
      "epoch:26 step:24658 [D loss: 0.195370, acc.: 78.91%] [G loss: 0.430528]\n",
      "epoch:26 step:24659 [D loss: 0.231820, acc.: 59.38%] [G loss: 0.411299]\n",
      "epoch:26 step:24660 [D loss: 0.216246, acc.: 65.62%] [G loss: 0.414002]\n",
      "epoch:26 step:24661 [D loss: 0.232297, acc.: 60.16%] [G loss: 0.426267]\n",
      "epoch:26 step:24662 [D loss: 0.188819, acc.: 70.31%] [G loss: 0.475654]\n",
      "epoch:26 step:24663 [D loss: 0.239891, acc.: 63.28%] [G loss: 0.450343]\n",
      "epoch:26 step:24664 [D loss: 0.236463, acc.: 61.72%] [G loss: 0.455059]\n",
      "epoch:26 step:24665 [D loss: 0.218069, acc.: 63.28%] [G loss: 0.440709]\n",
      "epoch:26 step:24666 [D loss: 0.238563, acc.: 60.16%] [G loss: 0.413706]\n",
      "epoch:26 step:24667 [D loss: 0.216372, acc.: 71.09%] [G loss: 0.416384]\n",
      "epoch:26 step:24668 [D loss: 0.246665, acc.: 59.38%] [G loss: 0.424222]\n",
      "epoch:26 step:24669 [D loss: 0.219954, acc.: 64.06%] [G loss: 0.460073]\n",
      "epoch:26 step:24670 [D loss: 0.225314, acc.: 62.50%] [G loss: 0.461659]\n",
      "epoch:26 step:24671 [D loss: 0.215141, acc.: 65.62%] [G loss: 0.428139]\n",
      "epoch:26 step:24672 [D loss: 0.207240, acc.: 66.41%] [G loss: 0.435268]\n",
      "epoch:26 step:24673 [D loss: 0.225197, acc.: 63.28%] [G loss: 0.397629]\n",
      "epoch:26 step:24674 [D loss: 0.182836, acc.: 75.78%] [G loss: 0.457586]\n",
      "epoch:26 step:24675 [D loss: 0.182610, acc.: 73.44%] [G loss: 0.484889]\n",
      "epoch:26 step:24676 [D loss: 0.185616, acc.: 72.66%] [G loss: 0.470569]\n",
      "epoch:26 step:24677 [D loss: 0.206931, acc.: 67.19%] [G loss: 0.493431]\n",
      "epoch:26 step:24678 [D loss: 0.248701, acc.: 57.81%] [G loss: 0.452286]\n",
      "epoch:26 step:24679 [D loss: 0.237063, acc.: 60.94%] [G loss: 0.440812]\n",
      "epoch:26 step:24680 [D loss: 0.209439, acc.: 65.62%] [G loss: 0.443241]\n",
      "epoch:26 step:24681 [D loss: 0.230834, acc.: 64.06%] [G loss: 0.445334]\n",
      "epoch:26 step:24682 [D loss: 0.217272, acc.: 65.62%] [G loss: 0.423199]\n",
      "epoch:26 step:24683 [D loss: 0.205226, acc.: 69.53%] [G loss: 0.463712]\n",
      "epoch:26 step:24684 [D loss: 0.219612, acc.: 71.09%] [G loss: 0.453855]\n",
      "epoch:26 step:24685 [D loss: 0.247258, acc.: 55.47%] [G loss: 0.447418]\n",
      "epoch:26 step:24686 [D loss: 0.231606, acc.: 60.94%] [G loss: 0.434734]\n",
      "epoch:26 step:24687 [D loss: 0.215024, acc.: 63.28%] [G loss: 0.441608]\n",
      "epoch:26 step:24688 [D loss: 0.216801, acc.: 69.53%] [G loss: 0.449879]\n",
      "epoch:26 step:24689 [D loss: 0.216236, acc.: 67.97%] [G loss: 0.461555]\n",
      "epoch:26 step:24690 [D loss: 0.208105, acc.: 65.62%] [G loss: 0.441209]\n",
      "epoch:26 step:24691 [D loss: 0.241012, acc.: 60.94%] [G loss: 0.401886]\n",
      "epoch:26 step:24692 [D loss: 0.214981, acc.: 67.97%] [G loss: 0.437196]\n",
      "epoch:26 step:24693 [D loss: 0.219854, acc.: 60.16%] [G loss: 0.393005]\n",
      "epoch:26 step:24694 [D loss: 0.215884, acc.: 66.41%] [G loss: 0.416829]\n",
      "epoch:26 step:24695 [D loss: 0.224082, acc.: 61.72%] [G loss: 0.386894]\n",
      "epoch:26 step:24696 [D loss: 0.229244, acc.: 61.72%] [G loss: 0.411321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24697 [D loss: 0.231023, acc.: 62.50%] [G loss: 0.406186]\n",
      "epoch:26 step:24698 [D loss: 0.208875, acc.: 63.28%] [G loss: 0.442397]\n",
      "epoch:26 step:24699 [D loss: 0.211681, acc.: 67.97%] [G loss: 0.488328]\n",
      "epoch:26 step:24700 [D loss: 0.196971, acc.: 71.09%] [G loss: 0.438188]\n",
      "epoch:26 step:24701 [D loss: 0.213271, acc.: 64.84%] [G loss: 0.434586]\n",
      "epoch:26 step:24702 [D loss: 0.228258, acc.: 58.59%] [G loss: 0.410820]\n",
      "epoch:26 step:24703 [D loss: 0.287578, acc.: 48.44%] [G loss: 0.365776]\n",
      "epoch:26 step:24704 [D loss: 0.250524, acc.: 54.69%] [G loss: 0.436638]\n",
      "epoch:26 step:24705 [D loss: 0.228266, acc.: 63.28%] [G loss: 0.454342]\n",
      "epoch:26 step:24706 [D loss: 0.202947, acc.: 68.75%] [G loss: 0.474090]\n",
      "epoch:26 step:24707 [D loss: 0.205349, acc.: 67.19%] [G loss: 0.471886]\n",
      "epoch:26 step:24708 [D loss: 0.220538, acc.: 64.84%] [G loss: 0.479642]\n",
      "epoch:26 step:24709 [D loss: 0.196521, acc.: 65.62%] [G loss: 0.516280]\n",
      "epoch:26 step:24710 [D loss: 0.293724, acc.: 52.34%] [G loss: 0.373780]\n",
      "epoch:26 step:24711 [D loss: 0.284132, acc.: 50.78%] [G loss: 0.426323]\n",
      "epoch:26 step:24712 [D loss: 0.208607, acc.: 72.66%] [G loss: 0.430703]\n",
      "epoch:26 step:24713 [D loss: 0.233375, acc.: 56.25%] [G loss: 0.419586]\n",
      "epoch:26 step:24714 [D loss: 0.238983, acc.: 60.16%] [G loss: 0.412532]\n",
      "epoch:26 step:24715 [D loss: 0.212682, acc.: 63.28%] [G loss: 0.470815]\n",
      "epoch:26 step:24716 [D loss: 0.180988, acc.: 73.44%] [G loss: 0.488075]\n",
      "epoch:26 step:24717 [D loss: 0.222460, acc.: 61.72%] [G loss: 0.458821]\n",
      "epoch:26 step:24718 [D loss: 0.230962, acc.: 67.19%] [G loss: 0.436578]\n",
      "epoch:26 step:24719 [D loss: 0.202312, acc.: 67.97%] [G loss: 0.436785]\n",
      "epoch:26 step:24720 [D loss: 0.193933, acc.: 67.19%] [G loss: 0.443768]\n",
      "epoch:26 step:24721 [D loss: 0.204897, acc.: 73.44%] [G loss: 0.475227]\n",
      "epoch:26 step:24722 [D loss: 0.223728, acc.: 62.50%] [G loss: 0.443802]\n",
      "epoch:26 step:24723 [D loss: 0.186517, acc.: 75.00%] [G loss: 0.459677]\n",
      "epoch:26 step:24724 [D loss: 0.221932, acc.: 64.06%] [G loss: 0.449663]\n",
      "epoch:26 step:24725 [D loss: 0.236274, acc.: 58.59%] [G loss: 0.439606]\n",
      "epoch:26 step:24726 [D loss: 0.205770, acc.: 72.66%] [G loss: 0.408909]\n",
      "epoch:26 step:24727 [D loss: 0.229643, acc.: 56.25%] [G loss: 0.458261]\n",
      "epoch:26 step:24728 [D loss: 0.237200, acc.: 61.72%] [G loss: 0.421287]\n",
      "epoch:26 step:24729 [D loss: 0.196816, acc.: 68.75%] [G loss: 0.427689]\n",
      "epoch:26 step:24730 [D loss: 0.244993, acc.: 57.03%] [G loss: 0.402756]\n",
      "epoch:26 step:24731 [D loss: 0.246332, acc.: 59.38%] [G loss: 0.425081]\n",
      "epoch:26 step:24732 [D loss: 0.217198, acc.: 67.19%] [G loss: 0.426149]\n",
      "epoch:26 step:24733 [D loss: 0.184559, acc.: 77.34%] [G loss: 0.461226]\n",
      "epoch:26 step:24734 [D loss: 0.232041, acc.: 63.28%] [G loss: 0.463184]\n",
      "epoch:26 step:24735 [D loss: 0.251315, acc.: 57.81%] [G loss: 0.476846]\n",
      "epoch:26 step:24736 [D loss: 0.191192, acc.: 72.66%] [G loss: 0.444810]\n",
      "epoch:26 step:24737 [D loss: 0.246237, acc.: 63.28%] [G loss: 0.451933]\n",
      "epoch:26 step:24738 [D loss: 0.249566, acc.: 57.03%] [G loss: 0.442306]\n",
      "epoch:26 step:24739 [D loss: 0.255966, acc.: 50.00%] [G loss: 0.421457]\n",
      "epoch:26 step:24740 [D loss: 0.200827, acc.: 65.62%] [G loss: 0.411930]\n",
      "epoch:26 step:24741 [D loss: 0.228846, acc.: 64.06%] [G loss: 0.397300]\n",
      "epoch:26 step:24742 [D loss: 0.243309, acc.: 55.47%] [G loss: 0.396959]\n",
      "epoch:26 step:24743 [D loss: 0.194793, acc.: 69.53%] [G loss: 0.429119]\n",
      "epoch:26 step:24744 [D loss: 0.235048, acc.: 63.28%] [G loss: 0.401225]\n",
      "epoch:26 step:24745 [D loss: 0.221967, acc.: 57.03%] [G loss: 0.410327]\n",
      "epoch:26 step:24746 [D loss: 0.202022, acc.: 67.19%] [G loss: 0.425461]\n",
      "epoch:26 step:24747 [D loss: 0.193394, acc.: 72.66%] [G loss: 0.453274]\n",
      "epoch:26 step:24748 [D loss: 0.228183, acc.: 61.72%] [G loss: 0.462923]\n",
      "epoch:26 step:24749 [D loss: 0.232825, acc.: 55.47%] [G loss: 0.421257]\n",
      "epoch:26 step:24750 [D loss: 0.230193, acc.: 59.38%] [G loss: 0.446622]\n",
      "epoch:26 step:24751 [D loss: 0.208583, acc.: 67.19%] [G loss: 0.433602]\n",
      "epoch:26 step:24752 [D loss: 0.265411, acc.: 51.56%] [G loss: 0.384958]\n",
      "epoch:26 step:24753 [D loss: 0.213083, acc.: 70.31%] [G loss: 0.404909]\n",
      "epoch:26 step:24754 [D loss: 0.227323, acc.: 60.94%] [G loss: 0.428677]\n",
      "epoch:26 step:24755 [D loss: 0.220037, acc.: 63.28%] [G loss: 0.427832]\n",
      "epoch:26 step:24756 [D loss: 0.252291, acc.: 53.12%] [G loss: 0.397790]\n",
      "epoch:26 step:24757 [D loss: 0.218556, acc.: 63.28%] [G loss: 0.409471]\n",
      "epoch:26 step:24758 [D loss: 0.281759, acc.: 49.22%] [G loss: 0.422041]\n",
      "epoch:26 step:24759 [D loss: 0.211784, acc.: 67.19%] [G loss: 0.427211]\n",
      "epoch:26 step:24760 [D loss: 0.196398, acc.: 69.53%] [G loss: 0.416131]\n",
      "epoch:26 step:24761 [D loss: 0.197346, acc.: 69.53%] [G loss: 0.454944]\n",
      "epoch:26 step:24762 [D loss: 0.253068, acc.: 53.91%] [G loss: 0.462664]\n",
      "epoch:26 step:24763 [D loss: 0.226420, acc.: 61.72%] [G loss: 0.439408]\n",
      "epoch:26 step:24764 [D loss: 0.234685, acc.: 62.50%] [G loss: 0.436198]\n",
      "epoch:26 step:24765 [D loss: 0.233469, acc.: 53.91%] [G loss: 0.405906]\n",
      "epoch:26 step:24766 [D loss: 0.221663, acc.: 60.16%] [G loss: 0.404484]\n",
      "epoch:26 step:24767 [D loss: 0.204896, acc.: 68.75%] [G loss: 0.446663]\n",
      "epoch:26 step:24768 [D loss: 0.215690, acc.: 62.50%] [G loss: 0.444014]\n",
      "epoch:26 step:24769 [D loss: 0.234791, acc.: 54.69%] [G loss: 0.441476]\n",
      "epoch:26 step:24770 [D loss: 0.247862, acc.: 57.81%] [G loss: 0.467304]\n",
      "epoch:26 step:24771 [D loss: 0.205422, acc.: 66.41%] [G loss: 0.464385]\n",
      "epoch:26 step:24772 [D loss: 0.221608, acc.: 64.06%] [G loss: 0.404017]\n",
      "epoch:26 step:24773 [D loss: 0.247043, acc.: 57.03%] [G loss: 0.403460]\n",
      "epoch:26 step:24774 [D loss: 0.228626, acc.: 56.25%] [G loss: 0.358871]\n",
      "epoch:26 step:24775 [D loss: 0.211101, acc.: 66.41%] [G loss: 0.399668]\n",
      "epoch:26 step:24776 [D loss: 0.211039, acc.: 67.19%] [G loss: 0.423371]\n",
      "epoch:26 step:24777 [D loss: 0.210602, acc.: 65.62%] [G loss: 0.456223]\n",
      "epoch:26 step:24778 [D loss: 0.205267, acc.: 63.28%] [G loss: 0.536242]\n",
      "epoch:26 step:24779 [D loss: 0.222458, acc.: 68.75%] [G loss: 0.516827]\n",
      "epoch:26 step:24780 [D loss: 0.239904, acc.: 65.62%] [G loss: 0.432669]\n",
      "epoch:26 step:24781 [D loss: 0.221294, acc.: 67.97%] [G loss: 0.420413]\n",
      "epoch:26 step:24782 [D loss: 0.257761, acc.: 53.91%] [G loss: 0.419537]\n",
      "epoch:26 step:24783 [D loss: 0.222928, acc.: 60.16%] [G loss: 0.364563]\n",
      "epoch:26 step:24784 [D loss: 0.226545, acc.: 57.03%] [G loss: 0.410004]\n",
      "epoch:26 step:24785 [D loss: 0.226412, acc.: 67.19%] [G loss: 0.392863]\n",
      "epoch:26 step:24786 [D loss: 0.227118, acc.: 59.38%] [G loss: 0.403439]\n",
      "epoch:26 step:24787 [D loss: 0.224571, acc.: 63.28%] [G loss: 0.393219]\n",
      "epoch:26 step:24788 [D loss: 0.220659, acc.: 62.50%] [G loss: 0.410383]\n",
      "epoch:26 step:24789 [D loss: 0.200580, acc.: 66.41%] [G loss: 0.434905]\n",
      "epoch:26 step:24790 [D loss: 0.206968, acc.: 69.53%] [G loss: 0.436379]\n",
      "epoch:26 step:24791 [D loss: 0.198253, acc.: 67.97%] [G loss: 0.441353]\n",
      "epoch:26 step:24792 [D loss: 0.204939, acc.: 65.62%] [G loss: 0.465095]\n",
      "epoch:26 step:24793 [D loss: 0.228523, acc.: 57.81%] [G loss: 0.471835]\n",
      "epoch:26 step:24794 [D loss: 0.220727, acc.: 57.03%] [G loss: 0.429505]\n",
      "epoch:26 step:24795 [D loss: 0.211810, acc.: 67.97%] [G loss: 0.410155]\n",
      "epoch:26 step:24796 [D loss: 0.205296, acc.: 69.53%] [G loss: 0.420282]\n",
      "epoch:26 step:24797 [D loss: 0.216616, acc.: 65.62%] [G loss: 0.446929]\n",
      "epoch:26 step:24798 [D loss: 0.231354, acc.: 59.38%] [G loss: 0.456639]\n",
      "epoch:26 step:24799 [D loss: 0.277342, acc.: 53.91%] [G loss: 0.401575]\n",
      "epoch:26 step:24800 [D loss: 0.257164, acc.: 57.03%] [G loss: 0.430156]\n",
      "epoch:26 step:24801 [D loss: 0.212406, acc.: 67.19%] [G loss: 0.429618]\n",
      "epoch:26 step:24802 [D loss: 0.230874, acc.: 54.69%] [G loss: 0.447470]\n",
      "epoch:26 step:24803 [D loss: 0.224338, acc.: 60.16%] [G loss: 0.461989]\n",
      "epoch:26 step:24804 [D loss: 0.238953, acc.: 59.38%] [G loss: 0.427909]\n",
      "epoch:26 step:24805 [D loss: 0.232024, acc.: 57.81%] [G loss: 0.424220]\n",
      "epoch:26 step:24806 [D loss: 0.227161, acc.: 64.06%] [G loss: 0.420030]\n",
      "epoch:26 step:24807 [D loss: 0.217176, acc.: 63.28%] [G loss: 0.418786]\n",
      "epoch:26 step:24808 [D loss: 0.221185, acc.: 61.72%] [G loss: 0.430084]\n",
      "epoch:26 step:24809 [D loss: 0.215088, acc.: 70.31%] [G loss: 0.424956]\n",
      "epoch:26 step:24810 [D loss: 0.239269, acc.: 59.38%] [G loss: 0.397811]\n",
      "epoch:26 step:24811 [D loss: 0.210841, acc.: 64.84%] [G loss: 0.432992]\n",
      "epoch:26 step:24812 [D loss: 0.213717, acc.: 64.06%] [G loss: 0.452254]\n",
      "epoch:26 step:24813 [D loss: 0.211982, acc.: 65.62%] [G loss: 0.424151]\n",
      "epoch:26 step:24814 [D loss: 0.234390, acc.: 63.28%] [G loss: 0.424438]\n",
      "epoch:26 step:24815 [D loss: 0.198021, acc.: 67.19%] [G loss: 0.476140]\n",
      "epoch:26 step:24816 [D loss: 0.202533, acc.: 71.09%] [G loss: 0.472676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24817 [D loss: 0.236966, acc.: 63.28%] [G loss: 0.429007]\n",
      "epoch:26 step:24818 [D loss: 0.218999, acc.: 63.28%] [G loss: 0.442099]\n",
      "epoch:26 step:24819 [D loss: 0.233980, acc.: 62.50%] [G loss: 0.470315]\n",
      "epoch:26 step:24820 [D loss: 0.265688, acc.: 53.91%] [G loss: 0.460864]\n",
      "epoch:26 step:24821 [D loss: 0.232701, acc.: 64.06%] [G loss: 0.456482]\n",
      "epoch:26 step:24822 [D loss: 0.237075, acc.: 60.94%] [G loss: 0.424380]\n",
      "epoch:26 step:24823 [D loss: 0.245094, acc.: 58.59%] [G loss: 0.428484]\n",
      "epoch:26 step:24824 [D loss: 0.225518, acc.: 56.25%] [G loss: 0.403218]\n",
      "epoch:26 step:24825 [D loss: 0.227490, acc.: 61.72%] [G loss: 0.444753]\n",
      "epoch:26 step:24826 [D loss: 0.215540, acc.: 66.41%] [G loss: 0.408333]\n",
      "epoch:26 step:24827 [D loss: 0.236135, acc.: 61.72%] [G loss: 0.384484]\n",
      "epoch:26 step:24828 [D loss: 0.223192, acc.: 64.84%] [G loss: 0.409076]\n",
      "epoch:26 step:24829 [D loss: 0.216408, acc.: 62.50%] [G loss: 0.401033]\n",
      "epoch:26 step:24830 [D loss: 0.207175, acc.: 69.53%] [G loss: 0.477599]\n",
      "epoch:26 step:24831 [D loss: 0.204453, acc.: 66.41%] [G loss: 0.461521]\n",
      "epoch:26 step:24832 [D loss: 0.214305, acc.: 67.97%] [G loss: 0.455160]\n",
      "epoch:26 step:24833 [D loss: 0.211660, acc.: 67.19%] [G loss: 0.479173]\n",
      "epoch:26 step:24834 [D loss: 0.199062, acc.: 71.88%] [G loss: 0.505710]\n",
      "epoch:26 step:24835 [D loss: 0.266158, acc.: 57.81%] [G loss: 0.443754]\n",
      "epoch:26 step:24836 [D loss: 0.193509, acc.: 72.66%] [G loss: 0.483957]\n",
      "epoch:26 step:24837 [D loss: 0.199220, acc.: 73.44%] [G loss: 0.484805]\n",
      "epoch:26 step:24838 [D loss: 0.232476, acc.: 60.94%] [G loss: 0.435602]\n",
      "epoch:26 step:24839 [D loss: 0.251816, acc.: 52.34%] [G loss: 0.404109]\n",
      "epoch:26 step:24840 [D loss: 0.228883, acc.: 64.06%] [G loss: 0.453954]\n",
      "epoch:26 step:24841 [D loss: 0.203901, acc.: 67.97%] [G loss: 0.425855]\n",
      "epoch:26 step:24842 [D loss: 0.215075, acc.: 63.28%] [G loss: 0.421326]\n",
      "epoch:26 step:24843 [D loss: 0.182858, acc.: 72.66%] [G loss: 0.413062]\n",
      "epoch:26 step:24844 [D loss: 0.271601, acc.: 49.22%] [G loss: 0.432882]\n",
      "epoch:26 step:24845 [D loss: 0.227152, acc.: 60.16%] [G loss: 0.444526]\n",
      "epoch:26 step:24846 [D loss: 0.207120, acc.: 67.97%] [G loss: 0.470489]\n",
      "epoch:26 step:24847 [D loss: 0.238262, acc.: 60.94%] [G loss: 0.461775]\n",
      "epoch:26 step:24848 [D loss: 0.222227, acc.: 60.16%] [G loss: 0.470327]\n",
      "epoch:26 step:24849 [D loss: 0.250802, acc.: 56.25%] [G loss: 0.404405]\n",
      "epoch:26 step:24850 [D loss: 0.183808, acc.: 75.78%] [G loss: 0.449588]\n",
      "epoch:26 step:24851 [D loss: 0.237744, acc.: 57.81%] [G loss: 0.412174]\n",
      "epoch:26 step:24852 [D loss: 0.225440, acc.: 59.38%] [G loss: 0.444286]\n",
      "epoch:26 step:24853 [D loss: 0.222042, acc.: 67.97%] [G loss: 0.428175]\n",
      "epoch:26 step:24854 [D loss: 0.239701, acc.: 57.03%] [G loss: 0.458726]\n",
      "epoch:26 step:24855 [D loss: 0.228901, acc.: 60.94%] [G loss: 0.428355]\n",
      "epoch:26 step:24856 [D loss: 0.191022, acc.: 73.44%] [G loss: 0.469998]\n",
      "epoch:26 step:24857 [D loss: 0.208262, acc.: 69.53%] [G loss: 0.454837]\n",
      "epoch:26 step:24858 [D loss: 0.196066, acc.: 75.78%] [G loss: 0.477086]\n",
      "epoch:26 step:24859 [D loss: 0.216396, acc.: 64.06%] [G loss: 0.464043]\n",
      "epoch:26 step:24860 [D loss: 0.183513, acc.: 73.44%] [G loss: 0.434481]\n",
      "epoch:26 step:24861 [D loss: 0.194478, acc.: 70.31%] [G loss: 0.479454]\n",
      "epoch:26 step:24862 [D loss: 0.252702, acc.: 55.47%] [G loss: 0.425112]\n",
      "epoch:26 step:24863 [D loss: 0.255073, acc.: 58.59%] [G loss: 0.422295]\n",
      "epoch:26 step:24864 [D loss: 0.258070, acc.: 48.44%] [G loss: 0.419583]\n",
      "epoch:26 step:24865 [D loss: 0.228690, acc.: 58.59%] [G loss: 0.431266]\n",
      "epoch:26 step:24866 [D loss: 0.211034, acc.: 67.19%] [G loss: 0.467854]\n",
      "epoch:26 step:24867 [D loss: 0.213406, acc.: 65.62%] [G loss: 0.440983]\n",
      "epoch:26 step:24868 [D loss: 0.216997, acc.: 65.62%] [G loss: 0.483403]\n",
      "epoch:26 step:24869 [D loss: 0.211569, acc.: 63.28%] [G loss: 0.501325]\n",
      "epoch:26 step:24870 [D loss: 0.191982, acc.: 74.22%] [G loss: 0.473849]\n",
      "epoch:26 step:24871 [D loss: 0.259720, acc.: 51.56%] [G loss: 0.441643]\n",
      "epoch:26 step:24872 [D loss: 0.237616, acc.: 60.94%] [G loss: 0.401890]\n",
      "epoch:26 step:24873 [D loss: 0.237457, acc.: 57.81%] [G loss: 0.384348]\n",
      "epoch:26 step:24874 [D loss: 0.242948, acc.: 56.25%] [G loss: 0.415123]\n",
      "epoch:26 step:24875 [D loss: 0.199354, acc.: 69.53%] [G loss: 0.431719]\n",
      "epoch:26 step:24876 [D loss: 0.196787, acc.: 68.75%] [G loss: 0.472591]\n",
      "epoch:26 step:24877 [D loss: 0.206687, acc.: 67.97%] [G loss: 0.453074]\n",
      "epoch:26 step:24878 [D loss: 0.211605, acc.: 67.19%] [G loss: 0.485132]\n",
      "epoch:26 step:24879 [D loss: 0.245655, acc.: 57.81%] [G loss: 0.415238]\n",
      "epoch:26 step:24880 [D loss: 0.239111, acc.: 57.81%] [G loss: 0.453892]\n",
      "epoch:26 step:24881 [D loss: 0.211103, acc.: 68.75%] [G loss: 0.449496]\n",
      "epoch:26 step:24882 [D loss: 0.202161, acc.: 69.53%] [G loss: 0.452754]\n",
      "epoch:26 step:24883 [D loss: 0.199459, acc.: 63.28%] [G loss: 0.444766]\n",
      "epoch:26 step:24884 [D loss: 0.194767, acc.: 71.88%] [G loss: 0.452281]\n",
      "epoch:26 step:24885 [D loss: 0.215475, acc.: 64.06%] [G loss: 0.437071]\n",
      "epoch:26 step:24886 [D loss: 0.221673, acc.: 65.62%] [G loss: 0.443501]\n",
      "epoch:26 step:24887 [D loss: 0.223077, acc.: 62.50%] [G loss: 0.456506]\n",
      "epoch:26 step:24888 [D loss: 0.220522, acc.: 64.06%] [G loss: 0.424461]\n",
      "epoch:26 step:24889 [D loss: 0.218147, acc.: 65.62%] [G loss: 0.461922]\n",
      "epoch:26 step:24890 [D loss: 0.276021, acc.: 50.00%] [G loss: 0.440947]\n",
      "epoch:26 step:24891 [D loss: 0.226049, acc.: 60.16%] [G loss: 0.426273]\n",
      "epoch:26 step:24892 [D loss: 0.221123, acc.: 64.06%] [G loss: 0.460897]\n",
      "epoch:26 step:24893 [D loss: 0.237265, acc.: 63.28%] [G loss: 0.417141]\n",
      "epoch:26 step:24894 [D loss: 0.215565, acc.: 64.06%] [G loss: 0.425771]\n",
      "epoch:26 step:24895 [D loss: 0.229386, acc.: 64.06%] [G loss: 0.423992]\n",
      "epoch:26 step:24896 [D loss: 0.178612, acc.: 69.53%] [G loss: 0.450665]\n",
      "epoch:26 step:24897 [D loss: 0.247470, acc.: 57.03%] [G loss: 0.439025]\n",
      "epoch:26 step:24898 [D loss: 0.225941, acc.: 59.38%] [G loss: 0.421292]\n",
      "epoch:26 step:24899 [D loss: 0.238822, acc.: 63.28%] [G loss: 0.443477]\n",
      "epoch:26 step:24900 [D loss: 0.232294, acc.: 62.50%] [G loss: 0.446500]\n",
      "epoch:26 step:24901 [D loss: 0.243773, acc.: 54.69%] [G loss: 0.386174]\n",
      "epoch:26 step:24902 [D loss: 0.219973, acc.: 61.72%] [G loss: 0.426236]\n",
      "epoch:26 step:24903 [D loss: 0.230362, acc.: 60.16%] [G loss: 0.424841]\n",
      "epoch:26 step:24904 [D loss: 0.273226, acc.: 49.22%] [G loss: 0.382734]\n",
      "epoch:26 step:24905 [D loss: 0.214669, acc.: 70.31%] [G loss: 0.451979]\n",
      "epoch:26 step:24906 [D loss: 0.220227, acc.: 60.94%] [G loss: 0.425686]\n",
      "epoch:26 step:24907 [D loss: 0.225612, acc.: 64.06%] [G loss: 0.442055]\n",
      "epoch:26 step:24908 [D loss: 0.215597, acc.: 67.19%] [G loss: 0.461200]\n",
      "epoch:26 step:24909 [D loss: 0.202226, acc.: 71.09%] [G loss: 0.444290]\n",
      "epoch:26 step:24910 [D loss: 0.196255, acc.: 71.09%] [G loss: 0.478632]\n",
      "epoch:26 step:24911 [D loss: 0.191816, acc.: 73.44%] [G loss: 0.417780]\n",
      "epoch:26 step:24912 [D loss: 0.220489, acc.: 63.28%] [G loss: 0.410209]\n",
      "epoch:26 step:24913 [D loss: 0.197477, acc.: 73.44%] [G loss: 0.457812]\n",
      "epoch:26 step:24914 [D loss: 0.232681, acc.: 64.84%] [G loss: 0.435404]\n",
      "epoch:26 step:24915 [D loss: 0.226752, acc.: 61.72%] [G loss: 0.427259]\n",
      "epoch:26 step:24916 [D loss: 0.201763, acc.: 73.44%] [G loss: 0.468671]\n",
      "epoch:26 step:24917 [D loss: 0.216975, acc.: 62.50%] [G loss: 0.426206]\n",
      "epoch:26 step:24918 [D loss: 0.209810, acc.: 67.97%] [G loss: 0.424560]\n",
      "epoch:26 step:24919 [D loss: 0.212351, acc.: 67.97%] [G loss: 0.444863]\n",
      "epoch:26 step:24920 [D loss: 0.217780, acc.: 65.62%] [G loss: 0.450006]\n",
      "epoch:26 step:24921 [D loss: 0.252417, acc.: 57.03%] [G loss: 0.471808]\n",
      "epoch:26 step:24922 [D loss: 0.236964, acc.: 61.72%] [G loss: 0.432706]\n",
      "epoch:26 step:24923 [D loss: 0.206435, acc.: 64.06%] [G loss: 0.517002]\n",
      "epoch:26 step:24924 [D loss: 0.251203, acc.: 55.47%] [G loss: 0.415447]\n",
      "epoch:26 step:24925 [D loss: 0.187918, acc.: 73.44%] [G loss: 0.448306]\n",
      "epoch:26 step:24926 [D loss: 0.214278, acc.: 69.53%] [G loss: 0.425860]\n",
      "epoch:26 step:24927 [D loss: 0.257501, acc.: 56.25%] [G loss: 0.425345]\n",
      "epoch:26 step:24928 [D loss: 0.245345, acc.: 57.81%] [G loss: 0.425405]\n",
      "epoch:26 step:24929 [D loss: 0.221329, acc.: 62.50%] [G loss: 0.432375]\n",
      "epoch:26 step:24930 [D loss: 0.209738, acc.: 64.84%] [G loss: 0.418941]\n",
      "epoch:26 step:24931 [D loss: 0.237640, acc.: 58.59%] [G loss: 0.418671]\n",
      "epoch:26 step:24932 [D loss: 0.215233, acc.: 65.62%] [G loss: 0.415748]\n",
      "epoch:26 step:24933 [D loss: 0.206122, acc.: 69.53%] [G loss: 0.433206]\n",
      "epoch:26 step:24934 [D loss: 0.231924, acc.: 59.38%] [G loss: 0.431935]\n",
      "epoch:26 step:24935 [D loss: 0.241564, acc.: 56.25%] [G loss: 0.394502]\n",
      "epoch:26 step:24936 [D loss: 0.201576, acc.: 65.62%] [G loss: 0.446756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24937 [D loss: 0.191039, acc.: 76.56%] [G loss: 0.497051]\n",
      "epoch:26 step:24938 [D loss: 0.212243, acc.: 65.62%] [G loss: 0.462184]\n",
      "epoch:26 step:24939 [D loss: 0.231474, acc.: 60.94%] [G loss: 0.379057]\n",
      "epoch:26 step:24940 [D loss: 0.233025, acc.: 55.47%] [G loss: 0.405044]\n",
      "epoch:26 step:24941 [D loss: 0.231801, acc.: 61.72%] [G loss: 0.415409]\n",
      "epoch:26 step:24942 [D loss: 0.228529, acc.: 65.62%] [G loss: 0.418353]\n",
      "epoch:26 step:24943 [D loss: 0.209139, acc.: 66.41%] [G loss: 0.428924]\n",
      "epoch:26 step:24944 [D loss: 0.208145, acc.: 67.97%] [G loss: 0.456942]\n",
      "epoch:26 step:24945 [D loss: 0.232513, acc.: 55.47%] [G loss: 0.485534]\n",
      "epoch:26 step:24946 [D loss: 0.228009, acc.: 60.94%] [G loss: 0.432693]\n",
      "epoch:26 step:24947 [D loss: 0.204385, acc.: 67.97%] [G loss: 0.457482]\n",
      "epoch:26 step:24948 [D loss: 0.215473, acc.: 64.06%] [G loss: 0.438816]\n",
      "epoch:26 step:24949 [D loss: 0.220231, acc.: 63.28%] [G loss: 0.467672]\n",
      "epoch:26 step:24950 [D loss: 0.222453, acc.: 56.25%] [G loss: 0.461193]\n",
      "epoch:26 step:24951 [D loss: 0.204506, acc.: 65.62%] [G loss: 0.473535]\n",
      "epoch:26 step:24952 [D loss: 0.238718, acc.: 64.06%] [G loss: 0.473674]\n",
      "epoch:26 step:24953 [D loss: 0.228599, acc.: 61.72%] [G loss: 0.413402]\n",
      "epoch:26 step:24954 [D loss: 0.199154, acc.: 67.19%] [G loss: 0.447243]\n",
      "epoch:26 step:24955 [D loss: 0.210710, acc.: 67.97%] [G loss: 0.454829]\n",
      "epoch:26 step:24956 [D loss: 0.220301, acc.: 61.72%] [G loss: 0.395857]\n",
      "epoch:26 step:24957 [D loss: 0.190053, acc.: 72.66%] [G loss: 0.451790]\n",
      "epoch:26 step:24958 [D loss: 0.233634, acc.: 53.91%] [G loss: 0.435410]\n",
      "epoch:26 step:24959 [D loss: 0.249955, acc.: 55.47%] [G loss: 0.418131]\n",
      "epoch:26 step:24960 [D loss: 0.207111, acc.: 68.75%] [G loss: 0.444031]\n",
      "epoch:26 step:24961 [D loss: 0.221590, acc.: 63.28%] [G loss: 0.444784]\n",
      "epoch:26 step:24962 [D loss: 0.252453, acc.: 56.25%] [G loss: 0.410177]\n",
      "epoch:26 step:24963 [D loss: 0.231827, acc.: 57.81%] [G loss: 0.410455]\n",
      "epoch:26 step:24964 [D loss: 0.233718, acc.: 62.50%] [G loss: 0.424934]\n",
      "epoch:26 step:24965 [D loss: 0.213578, acc.: 66.41%] [G loss: 0.436791]\n",
      "epoch:26 step:24966 [D loss: 0.202080, acc.: 67.97%] [G loss: 0.443592]\n",
      "epoch:26 step:24967 [D loss: 0.231851, acc.: 61.72%] [G loss: 0.407428]\n",
      "epoch:26 step:24968 [D loss: 0.231628, acc.: 60.94%] [G loss: 0.442709]\n",
      "epoch:26 step:24969 [D loss: 0.218952, acc.: 64.06%] [G loss: 0.423696]\n",
      "epoch:26 step:24970 [D loss: 0.227855, acc.: 63.28%] [G loss: 0.413086]\n",
      "epoch:26 step:24971 [D loss: 0.225261, acc.: 58.59%] [G loss: 0.430386]\n",
      "epoch:26 step:24972 [D loss: 0.216769, acc.: 60.94%] [G loss: 0.455211]\n",
      "epoch:26 step:24973 [D loss: 0.219794, acc.: 66.41%] [G loss: 0.412832]\n",
      "epoch:26 step:24974 [D loss: 0.217753, acc.: 62.50%] [G loss: 0.436951]\n",
      "epoch:26 step:24975 [D loss: 0.219613, acc.: 63.28%] [G loss: 0.423459]\n",
      "epoch:26 step:24976 [D loss: 0.235627, acc.: 62.50%] [G loss: 0.397729]\n",
      "epoch:26 step:24977 [D loss: 0.269741, acc.: 53.91%] [G loss: 0.387129]\n",
      "epoch:26 step:24978 [D loss: 0.240047, acc.: 61.72%] [G loss: 0.413561]\n",
      "epoch:26 step:24979 [D loss: 0.201708, acc.: 68.75%] [G loss: 0.446443]\n",
      "epoch:26 step:24980 [D loss: 0.209743, acc.: 67.97%] [G loss: 0.455962]\n",
      "epoch:26 step:24981 [D loss: 0.213689, acc.: 66.41%] [G loss: 0.440837]\n",
      "epoch:26 step:24982 [D loss: 0.193571, acc.: 69.53%] [G loss: 0.427617]\n",
      "epoch:26 step:24983 [D loss: 0.213128, acc.: 68.75%] [G loss: 0.449138]\n",
      "epoch:26 step:24984 [D loss: 0.229679, acc.: 66.41%] [G loss: 0.422086]\n",
      "epoch:26 step:24985 [D loss: 0.235621, acc.: 53.91%] [G loss: 0.407910]\n",
      "epoch:26 step:24986 [D loss: 0.182553, acc.: 73.44%] [G loss: 0.439282]\n",
      "epoch:26 step:24987 [D loss: 0.233789, acc.: 57.81%] [G loss: 0.404908]\n",
      "epoch:26 step:24988 [D loss: 0.227589, acc.: 59.38%] [G loss: 0.438117]\n",
      "epoch:26 step:24989 [D loss: 0.219679, acc.: 69.53%] [G loss: 0.396047]\n",
      "epoch:26 step:24990 [D loss: 0.230027, acc.: 61.72%] [G loss: 0.404267]\n",
      "epoch:26 step:24991 [D loss: 0.199402, acc.: 71.09%] [G loss: 0.418742]\n",
      "epoch:26 step:24992 [D loss: 0.216583, acc.: 63.28%] [G loss: 0.429445]\n",
      "epoch:26 step:24993 [D loss: 0.209023, acc.: 64.84%] [G loss: 0.419371]\n",
      "epoch:26 step:24994 [D loss: 0.221029, acc.: 64.06%] [G loss: 0.415710]\n",
      "epoch:26 step:24995 [D loss: 0.211626, acc.: 63.28%] [G loss: 0.453390]\n",
      "epoch:26 step:24996 [D loss: 0.175640, acc.: 74.22%] [G loss: 0.483156]\n",
      "epoch:26 step:24997 [D loss: 0.224254, acc.: 66.41%] [G loss: 0.420331]\n",
      "epoch:26 step:24998 [D loss: 0.220818, acc.: 61.72%] [G loss: 0.436238]\n",
      "epoch:26 step:24999 [D loss: 0.220326, acc.: 66.41%] [G loss: 0.420023]\n",
      "epoch:26 step:25000 [D loss: 0.235255, acc.: 58.59%] [G loss: 0.441292]\n",
      "epoch:26 step:25001 [D loss: 0.223185, acc.: 62.50%] [G loss: 0.429793]\n",
      "epoch:26 step:25002 [D loss: 0.232646, acc.: 59.38%] [G loss: 0.447917]\n",
      "epoch:26 step:25003 [D loss: 0.198578, acc.: 73.44%] [G loss: 0.450534]\n",
      "epoch:26 step:25004 [D loss: 0.170305, acc.: 76.56%] [G loss: 0.497134]\n",
      "epoch:26 step:25005 [D loss: 0.225799, acc.: 60.16%] [G loss: 0.431630]\n",
      "epoch:26 step:25006 [D loss: 0.251960, acc.: 57.03%] [G loss: 0.431632]\n",
      "epoch:26 step:25007 [D loss: 0.246252, acc.: 58.59%] [G loss: 0.410900]\n",
      "epoch:26 step:25008 [D loss: 0.236240, acc.: 60.16%] [G loss: 0.424900]\n",
      "epoch:26 step:25009 [D loss: 0.209190, acc.: 64.84%] [G loss: 0.478687]\n",
      "epoch:26 step:25010 [D loss: 0.167124, acc.: 77.34%] [G loss: 0.512643]\n",
      "epoch:26 step:25011 [D loss: 0.220996, acc.: 64.84%] [G loss: 0.472726]\n",
      "epoch:26 step:25012 [D loss: 0.206556, acc.: 69.53%] [G loss: 0.471532]\n",
      "epoch:26 step:25013 [D loss: 0.235800, acc.: 60.94%] [G loss: 0.462819]\n",
      "epoch:26 step:25014 [D loss: 0.224016, acc.: 63.28%] [G loss: 0.475245]\n",
      "epoch:26 step:25015 [D loss: 0.234269, acc.: 64.06%] [G loss: 0.414827]\n",
      "epoch:26 step:25016 [D loss: 0.200202, acc.: 69.53%] [G loss: 0.442682]\n",
      "epoch:26 step:25017 [D loss: 0.241702, acc.: 59.38%] [G loss: 0.461508]\n",
      "epoch:26 step:25018 [D loss: 0.240761, acc.: 58.59%] [G loss: 0.468955]\n",
      "epoch:26 step:25019 [D loss: 0.219337, acc.: 60.94%] [G loss: 0.439192]\n",
      "epoch:26 step:25020 [D loss: 0.198260, acc.: 71.09%] [G loss: 0.431310]\n",
      "epoch:26 step:25021 [D loss: 0.206034, acc.: 68.75%] [G loss: 0.419838]\n",
      "epoch:26 step:25022 [D loss: 0.192096, acc.: 71.88%] [G loss: 0.431206]\n",
      "epoch:26 step:25023 [D loss: 0.220187, acc.: 71.09%] [G loss: 0.424434]\n",
      "epoch:26 step:25024 [D loss: 0.197522, acc.: 68.75%] [G loss: 0.471089]\n",
      "epoch:26 step:25025 [D loss: 0.225199, acc.: 60.16%] [G loss: 0.412872]\n",
      "epoch:26 step:25026 [D loss: 0.224234, acc.: 65.62%] [G loss: 0.448308]\n",
      "epoch:26 step:25027 [D loss: 0.228822, acc.: 60.94%] [G loss: 0.459483]\n",
      "epoch:26 step:25028 [D loss: 0.202816, acc.: 64.84%] [G loss: 0.462971]\n",
      "epoch:26 step:25029 [D loss: 0.223325, acc.: 65.62%] [G loss: 0.436596]\n",
      "epoch:26 step:25030 [D loss: 0.207777, acc.: 61.72%] [G loss: 0.460000]\n",
      "epoch:26 step:25031 [D loss: 0.225424, acc.: 62.50%] [G loss: 0.413060]\n",
      "epoch:26 step:25032 [D loss: 0.276581, acc.: 48.44%] [G loss: 0.371328]\n",
      "epoch:26 step:25033 [D loss: 0.217243, acc.: 65.62%] [G loss: 0.412864]\n",
      "epoch:26 step:25034 [D loss: 0.232918, acc.: 60.16%] [G loss: 0.402807]\n",
      "epoch:26 step:25035 [D loss: 0.237264, acc.: 60.16%] [G loss: 0.385160]\n",
      "epoch:26 step:25036 [D loss: 0.209877, acc.: 71.88%] [G loss: 0.421314]\n",
      "epoch:26 step:25037 [D loss: 0.231687, acc.: 62.50%] [G loss: 0.432995]\n",
      "epoch:26 step:25038 [D loss: 0.213566, acc.: 68.75%] [G loss: 0.396150]\n",
      "epoch:26 step:25039 [D loss: 0.192974, acc.: 72.66%] [G loss: 0.431302]\n",
      "epoch:26 step:25040 [D loss: 0.231437, acc.: 63.28%] [G loss: 0.432541]\n",
      "epoch:26 step:25041 [D loss: 0.217826, acc.: 65.62%] [G loss: 0.403988]\n",
      "epoch:26 step:25042 [D loss: 0.225606, acc.: 67.19%] [G loss: 0.421857]\n",
      "epoch:26 step:25043 [D loss: 0.203301, acc.: 67.97%] [G loss: 0.422745]\n",
      "epoch:26 step:25044 [D loss: 0.247081, acc.: 58.59%] [G loss: 0.388415]\n",
      "epoch:26 step:25045 [D loss: 0.225064, acc.: 65.62%] [G loss: 0.448935]\n",
      "epoch:26 step:25046 [D loss: 0.245822, acc.: 54.69%] [G loss: 0.398568]\n",
      "epoch:26 step:25047 [D loss: 0.206708, acc.: 64.84%] [G loss: 0.404423]\n",
      "epoch:26 step:25048 [D loss: 0.215342, acc.: 64.84%] [G loss: 0.444236]\n",
      "epoch:26 step:25049 [D loss: 0.239786, acc.: 61.72%] [G loss: 0.418233]\n",
      "epoch:26 step:25050 [D loss: 0.218485, acc.: 63.28%] [G loss: 0.419275]\n",
      "epoch:26 step:25051 [D loss: 0.203311, acc.: 69.53%] [G loss: 0.506626]\n",
      "epoch:26 step:25052 [D loss: 0.217408, acc.: 64.84%] [G loss: 0.434905]\n",
      "epoch:26 step:25053 [D loss: 0.210595, acc.: 63.28%] [G loss: 0.467409]\n",
      "epoch:26 step:25054 [D loss: 0.213687, acc.: 67.19%] [G loss: 0.464172]\n",
      "epoch:26 step:25055 [D loss: 0.181622, acc.: 75.00%] [G loss: 0.487254]\n",
      "epoch:26 step:25056 [D loss: 0.186196, acc.: 71.09%] [G loss: 0.454114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25057 [D loss: 0.232437, acc.: 63.28%] [G loss: 0.461021]\n",
      "epoch:26 step:25058 [D loss: 0.266247, acc.: 53.12%] [G loss: 0.447145]\n",
      "epoch:26 step:25059 [D loss: 0.227242, acc.: 61.72%] [G loss: 0.416908]\n",
      "epoch:26 step:25060 [D loss: 0.231072, acc.: 59.38%] [G loss: 0.413844]\n",
      "epoch:26 step:25061 [D loss: 0.223965, acc.: 61.72%] [G loss: 0.401280]\n",
      "epoch:26 step:25062 [D loss: 0.205171, acc.: 71.88%] [G loss: 0.441574]\n",
      "epoch:26 step:25063 [D loss: 0.210585, acc.: 66.41%] [G loss: 0.414285]\n",
      "epoch:26 step:25064 [D loss: 0.244170, acc.: 54.69%] [G loss: 0.456446]\n",
      "epoch:26 step:25065 [D loss: 0.258137, acc.: 55.47%] [G loss: 0.415940]\n",
      "epoch:26 step:25066 [D loss: 0.224397, acc.: 60.16%] [G loss: 0.439468]\n",
      "epoch:26 step:25067 [D loss: 0.223133, acc.: 60.94%] [G loss: 0.410935]\n",
      "epoch:26 step:25068 [D loss: 0.227725, acc.: 64.84%] [G loss: 0.409060]\n",
      "epoch:26 step:25069 [D loss: 0.206490, acc.: 64.06%] [G loss: 0.435074]\n",
      "epoch:26 step:25070 [D loss: 0.220723, acc.: 64.84%] [G loss: 0.424827]\n",
      "epoch:26 step:25071 [D loss: 0.199377, acc.: 67.19%] [G loss: 0.451404]\n",
      "epoch:26 step:25072 [D loss: 0.238986, acc.: 57.03%] [G loss: 0.452008]\n",
      "epoch:26 step:25073 [D loss: 0.242413, acc.: 57.03%] [G loss: 0.393300]\n",
      "epoch:26 step:25074 [D loss: 0.219702, acc.: 64.06%] [G loss: 0.442124]\n",
      "epoch:26 step:25075 [D loss: 0.226668, acc.: 60.94%] [G loss: 0.431737]\n",
      "epoch:26 step:25076 [D loss: 0.225415, acc.: 62.50%] [G loss: 0.447394]\n",
      "epoch:26 step:25077 [D loss: 0.242558, acc.: 54.69%] [G loss: 0.443346]\n",
      "epoch:26 step:25078 [D loss: 0.232753, acc.: 63.28%] [G loss: 0.431860]\n",
      "epoch:26 step:25079 [D loss: 0.237790, acc.: 60.94%] [G loss: 0.400154]\n",
      "epoch:26 step:25080 [D loss: 0.245545, acc.: 60.16%] [G loss: 0.415727]\n",
      "epoch:26 step:25081 [D loss: 0.188882, acc.: 71.88%] [G loss: 0.443178]\n",
      "epoch:26 step:25082 [D loss: 0.243154, acc.: 61.72%] [G loss: 0.439074]\n",
      "epoch:26 step:25083 [D loss: 0.215554, acc.: 60.16%] [G loss: 0.409831]\n",
      "epoch:26 step:25084 [D loss: 0.236437, acc.: 63.28%] [G loss: 0.411081]\n",
      "epoch:26 step:25085 [D loss: 0.200126, acc.: 70.31%] [G loss: 0.466121]\n",
      "epoch:26 step:25086 [D loss: 0.258082, acc.: 48.44%] [G loss: 0.449487]\n",
      "epoch:26 step:25087 [D loss: 0.205435, acc.: 71.88%] [G loss: 0.475099]\n",
      "epoch:26 step:25088 [D loss: 0.251916, acc.: 57.81%] [G loss: 0.446119]\n",
      "epoch:26 step:25089 [D loss: 0.232838, acc.: 61.72%] [G loss: 0.410980]\n",
      "epoch:26 step:25090 [D loss: 0.236598, acc.: 61.72%] [G loss: 0.444159]\n",
      "epoch:26 step:25091 [D loss: 0.225563, acc.: 62.50%] [G loss: 0.444143]\n",
      "epoch:26 step:25092 [D loss: 0.231833, acc.: 56.25%] [G loss: 0.415253]\n",
      "epoch:26 step:25093 [D loss: 0.230684, acc.: 60.94%] [G loss: 0.432520]\n",
      "epoch:26 step:25094 [D loss: 0.226954, acc.: 66.41%] [G loss: 0.426419]\n",
      "epoch:26 step:25095 [D loss: 0.203927, acc.: 65.62%] [G loss: 0.432251]\n",
      "epoch:26 step:25096 [D loss: 0.240461, acc.: 53.91%] [G loss: 0.419635]\n",
      "epoch:26 step:25097 [D loss: 0.238633, acc.: 60.94%] [G loss: 0.415472]\n",
      "epoch:26 step:25098 [D loss: 0.219074, acc.: 64.84%] [G loss: 0.450190]\n",
      "epoch:26 step:25099 [D loss: 0.223062, acc.: 61.72%] [G loss: 0.429452]\n",
      "epoch:26 step:25100 [D loss: 0.241373, acc.: 54.69%] [G loss: 0.393613]\n",
      "epoch:26 step:25101 [D loss: 0.242813, acc.: 58.59%] [G loss: 0.392798]\n",
      "epoch:26 step:25102 [D loss: 0.243411, acc.: 57.03%] [G loss: 0.403824]\n",
      "epoch:26 step:25103 [D loss: 0.240286, acc.: 57.03%] [G loss: 0.393744]\n",
      "epoch:26 step:25104 [D loss: 0.215307, acc.: 69.53%] [G loss: 0.405756]\n",
      "epoch:26 step:25105 [D loss: 0.203984, acc.: 68.75%] [G loss: 0.426581]\n",
      "epoch:26 step:25106 [D loss: 0.240541, acc.: 58.59%] [G loss: 0.409577]\n",
      "epoch:26 step:25107 [D loss: 0.244195, acc.: 54.69%] [G loss: 0.404525]\n",
      "epoch:26 step:25108 [D loss: 0.213431, acc.: 63.28%] [G loss: 0.427577]\n",
      "epoch:26 step:25109 [D loss: 0.194020, acc.: 71.88%] [G loss: 0.428239]\n",
      "epoch:26 step:25110 [D loss: 0.224661, acc.: 67.19%] [G loss: 0.404337]\n",
      "epoch:26 step:25111 [D loss: 0.264899, acc.: 56.25%] [G loss: 0.397055]\n",
      "epoch:26 step:25112 [D loss: 0.217161, acc.: 59.38%] [G loss: 0.411622]\n",
      "epoch:26 step:25113 [D loss: 0.217345, acc.: 64.84%] [G loss: 0.430496]\n",
      "epoch:26 step:25114 [D loss: 0.250028, acc.: 56.25%] [G loss: 0.413814]\n",
      "epoch:26 step:25115 [D loss: 0.225259, acc.: 65.62%] [G loss: 0.464427]\n",
      "epoch:26 step:25116 [D loss: 0.207770, acc.: 64.06%] [G loss: 0.441213]\n",
      "epoch:26 step:25117 [D loss: 0.219454, acc.: 63.28%] [G loss: 0.420022]\n",
      "epoch:26 step:25118 [D loss: 0.212084, acc.: 67.97%] [G loss: 0.449583]\n",
      "epoch:26 step:25119 [D loss: 0.219640, acc.: 60.16%] [G loss: 0.403063]\n",
      "epoch:26 step:25120 [D loss: 0.243065, acc.: 64.06%] [G loss: 0.364221]\n",
      "epoch:26 step:25121 [D loss: 0.236994, acc.: 62.50%] [G loss: 0.430337]\n",
      "epoch:26 step:25122 [D loss: 0.237599, acc.: 60.16%] [G loss: 0.419598]\n",
      "epoch:26 step:25123 [D loss: 0.233563, acc.: 57.81%] [G loss: 0.434703]\n",
      "epoch:26 step:25124 [D loss: 0.237082, acc.: 57.03%] [G loss: 0.410158]\n",
      "epoch:26 step:25125 [D loss: 0.245003, acc.: 58.59%] [G loss: 0.416025]\n",
      "epoch:26 step:25126 [D loss: 0.230653, acc.: 57.81%] [G loss: 0.407605]\n",
      "epoch:26 step:25127 [D loss: 0.249061, acc.: 55.47%] [G loss: 0.442122]\n",
      "epoch:26 step:25128 [D loss: 0.222668, acc.: 62.50%] [G loss: 0.420267]\n",
      "epoch:26 step:25129 [D loss: 0.206788, acc.: 70.31%] [G loss: 0.451438]\n",
      "epoch:26 step:25130 [D loss: 0.220365, acc.: 68.75%] [G loss: 0.446351]\n",
      "epoch:26 step:25131 [D loss: 0.214964, acc.: 67.19%] [G loss: 0.424086]\n",
      "epoch:26 step:25132 [D loss: 0.248783, acc.: 60.16%] [G loss: 0.408346]\n",
      "epoch:26 step:25133 [D loss: 0.223432, acc.: 64.84%] [G loss: 0.430418]\n",
      "epoch:26 step:25134 [D loss: 0.242686, acc.: 55.47%] [G loss: 0.403498]\n",
      "epoch:26 step:25135 [D loss: 0.219639, acc.: 65.62%] [G loss: 0.412261]\n",
      "epoch:26 step:25136 [D loss: 0.225503, acc.: 64.06%] [G loss: 0.459930]\n",
      "epoch:26 step:25137 [D loss: 0.219991, acc.: 67.97%] [G loss: 0.489598]\n",
      "epoch:26 step:25138 [D loss: 0.221121, acc.: 64.06%] [G loss: 0.454292]\n",
      "epoch:26 step:25139 [D loss: 0.215194, acc.: 66.41%] [G loss: 0.469758]\n",
      "epoch:26 step:25140 [D loss: 0.242281, acc.: 58.59%] [G loss: 0.425919]\n",
      "epoch:26 step:25141 [D loss: 0.220540, acc.: 66.41%] [G loss: 0.436856]\n",
      "epoch:26 step:25142 [D loss: 0.220374, acc.: 66.41%] [G loss: 0.476596]\n",
      "epoch:26 step:25143 [D loss: 0.219343, acc.: 68.75%] [G loss: 0.438043]\n",
      "epoch:26 step:25144 [D loss: 0.194290, acc.: 66.41%] [G loss: 0.523410]\n",
      "epoch:26 step:25145 [D loss: 0.253112, acc.: 57.81%] [G loss: 0.445279]\n",
      "epoch:26 step:25146 [D loss: 0.273158, acc.: 50.78%] [G loss: 0.449944]\n",
      "epoch:26 step:25147 [D loss: 0.215851, acc.: 64.84%] [G loss: 0.422443]\n",
      "epoch:26 step:25148 [D loss: 0.200129, acc.: 69.53%] [G loss: 0.450833]\n",
      "epoch:26 step:25149 [D loss: 0.235761, acc.: 60.16%] [G loss: 0.428569]\n",
      "epoch:26 step:25150 [D loss: 0.248534, acc.: 53.12%] [G loss: 0.433369]\n",
      "epoch:26 step:25151 [D loss: 0.207301, acc.: 64.84%] [G loss: 0.449525]\n",
      "epoch:26 step:25152 [D loss: 0.227241, acc.: 60.94%] [G loss: 0.399656]\n",
      "epoch:26 step:25153 [D loss: 0.259835, acc.: 52.34%] [G loss: 0.431885]\n",
      "epoch:26 step:25154 [D loss: 0.208829, acc.: 63.28%] [G loss: 0.438356]\n",
      "epoch:26 step:25155 [D loss: 0.212376, acc.: 70.31%] [G loss: 0.463509]\n",
      "epoch:26 step:25156 [D loss: 0.258014, acc.: 50.78%] [G loss: 0.479485]\n",
      "epoch:26 step:25157 [D loss: 0.259541, acc.: 55.47%] [G loss: 0.441309]\n",
      "epoch:26 step:25158 [D loss: 0.240212, acc.: 66.41%] [G loss: 0.409535]\n",
      "epoch:26 step:25159 [D loss: 0.268972, acc.: 49.22%] [G loss: 0.396676]\n",
      "epoch:26 step:25160 [D loss: 0.235409, acc.: 58.59%] [G loss: 0.422609]\n",
      "epoch:26 step:25161 [D loss: 0.227808, acc.: 60.16%] [G loss: 0.452367]\n",
      "epoch:26 step:25162 [D loss: 0.252086, acc.: 58.59%] [G loss: 0.429314]\n",
      "epoch:26 step:25163 [D loss: 0.219626, acc.: 62.50%] [G loss: 0.436920]\n",
      "epoch:26 step:25164 [D loss: 0.209135, acc.: 68.75%] [G loss: 0.462200]\n",
      "epoch:26 step:25165 [D loss: 0.222655, acc.: 69.53%] [G loss: 0.416799]\n",
      "epoch:26 step:25166 [D loss: 0.220564, acc.: 61.72%] [G loss: 0.442355]\n",
      "epoch:26 step:25167 [D loss: 0.221180, acc.: 67.19%] [G loss: 0.449872]\n",
      "epoch:26 step:25168 [D loss: 0.242969, acc.: 62.50%] [G loss: 0.370766]\n",
      "epoch:26 step:25169 [D loss: 0.189617, acc.: 71.88%] [G loss: 0.484648]\n",
      "epoch:26 step:25170 [D loss: 0.247902, acc.: 53.91%] [G loss: 0.401308]\n",
      "epoch:26 step:25171 [D loss: 0.224278, acc.: 61.72%] [G loss: 0.413685]\n",
      "epoch:26 step:25172 [D loss: 0.235120, acc.: 60.94%] [G loss: 0.398125]\n",
      "epoch:26 step:25173 [D loss: 0.237001, acc.: 63.28%] [G loss: 0.440402]\n",
      "epoch:26 step:25174 [D loss: 0.233367, acc.: 63.28%] [G loss: 0.441042]\n",
      "epoch:26 step:25175 [D loss: 0.244127, acc.: 60.16%] [G loss: 0.440797]\n",
      "epoch:26 step:25176 [D loss: 0.228274, acc.: 60.94%] [G loss: 0.414377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25177 [D loss: 0.186490, acc.: 70.31%] [G loss: 0.538184]\n",
      "epoch:26 step:25178 [D loss: 0.234843, acc.: 63.28%] [G loss: 0.451763]\n",
      "epoch:26 step:25179 [D loss: 0.240850, acc.: 56.25%] [G loss: 0.445473]\n",
      "epoch:26 step:25180 [D loss: 0.247479, acc.: 57.03%] [G loss: 0.398017]\n",
      "epoch:26 step:25181 [D loss: 0.227812, acc.: 57.81%] [G loss: 0.444143]\n",
      "epoch:26 step:25182 [D loss: 0.255979, acc.: 59.38%] [G loss: 0.388196]\n",
      "epoch:26 step:25183 [D loss: 0.233945, acc.: 57.03%] [G loss: 0.385100]\n",
      "epoch:26 step:25184 [D loss: 0.221481, acc.: 65.62%] [G loss: 0.404682]\n",
      "epoch:26 step:25185 [D loss: 0.216840, acc.: 60.94%] [G loss: 0.391804]\n",
      "epoch:26 step:25186 [D loss: 0.229500, acc.: 61.72%] [G loss: 0.428362]\n",
      "epoch:26 step:25187 [D loss: 0.198952, acc.: 71.09%] [G loss: 0.440789]\n",
      "epoch:26 step:25188 [D loss: 0.217128, acc.: 63.28%] [G loss: 0.453851]\n",
      "epoch:26 step:25189 [D loss: 0.240780, acc.: 59.38%] [G loss: 0.427211]\n",
      "epoch:26 step:25190 [D loss: 0.241641, acc.: 60.16%] [G loss: 0.403861]\n",
      "epoch:26 step:25191 [D loss: 0.219309, acc.: 57.81%] [G loss: 0.411199]\n",
      "epoch:26 step:25192 [D loss: 0.230988, acc.: 60.94%] [G loss: 0.382342]\n",
      "epoch:26 step:25193 [D loss: 0.232951, acc.: 60.94%] [G loss: 0.385148]\n",
      "epoch:26 step:25194 [D loss: 0.226939, acc.: 69.53%] [G loss: 0.411042]\n",
      "epoch:26 step:25195 [D loss: 0.223112, acc.: 65.62%] [G loss: 0.453646]\n",
      "epoch:26 step:25196 [D loss: 0.221950, acc.: 67.97%] [G loss: 0.448034]\n",
      "epoch:26 step:25197 [D loss: 0.241088, acc.: 57.81%] [G loss: 0.402959]\n",
      "epoch:26 step:25198 [D loss: 0.228339, acc.: 60.94%] [G loss: 0.407107]\n",
      "epoch:26 step:25199 [D loss: 0.227481, acc.: 65.62%] [G loss: 0.401511]\n",
      "epoch:26 step:25200 [D loss: 0.198641, acc.: 69.53%] [G loss: 0.462825]\n",
      "epoch:26 step:25201 [D loss: 0.220074, acc.: 61.72%] [G loss: 0.407917]\n",
      "epoch:26 step:25202 [D loss: 0.235783, acc.: 62.50%] [G loss: 0.416170]\n",
      "epoch:26 step:25203 [D loss: 0.203149, acc.: 68.75%] [G loss: 0.457610]\n",
      "epoch:26 step:25204 [D loss: 0.210731, acc.: 72.66%] [G loss: 0.423998]\n",
      "epoch:26 step:25205 [D loss: 0.229254, acc.: 59.38%] [G loss: 0.420740]\n",
      "epoch:26 step:25206 [D loss: 0.221992, acc.: 61.72%] [G loss: 0.473323]\n",
      "epoch:26 step:25207 [D loss: 0.221960, acc.: 65.62%] [G loss: 0.445989]\n",
      "epoch:26 step:25208 [D loss: 0.224887, acc.: 63.28%] [G loss: 0.441477]\n",
      "epoch:26 step:25209 [D loss: 0.223544, acc.: 60.16%] [G loss: 0.433196]\n",
      "epoch:26 step:25210 [D loss: 0.226445, acc.: 60.94%] [G loss: 0.410753]\n",
      "epoch:26 step:25211 [D loss: 0.222237, acc.: 64.84%] [G loss: 0.419259]\n",
      "epoch:26 step:25212 [D loss: 0.235417, acc.: 57.81%] [G loss: 0.433355]\n",
      "epoch:26 step:25213 [D loss: 0.220603, acc.: 65.62%] [G loss: 0.422964]\n",
      "epoch:26 step:25214 [D loss: 0.212890, acc.: 64.06%] [G loss: 0.446414]\n",
      "epoch:26 step:25215 [D loss: 0.228879, acc.: 58.59%] [G loss: 0.461478]\n",
      "epoch:26 step:25216 [D loss: 0.213066, acc.: 64.84%] [G loss: 0.414515]\n",
      "epoch:26 step:25217 [D loss: 0.240743, acc.: 58.59%] [G loss: 0.434993]\n",
      "epoch:26 step:25218 [D loss: 0.275250, acc.: 49.22%] [G loss: 0.394420]\n",
      "epoch:26 step:25219 [D loss: 0.219439, acc.: 65.62%] [G loss: 0.413870]\n",
      "epoch:26 step:25220 [D loss: 0.244795, acc.: 57.81%] [G loss: 0.438209]\n",
      "epoch:26 step:25221 [D loss: 0.241462, acc.: 55.47%] [G loss: 0.402836]\n",
      "epoch:26 step:25222 [D loss: 0.220821, acc.: 66.41%] [G loss: 0.409839]\n",
      "epoch:26 step:25223 [D loss: 0.237417, acc.: 62.50%] [G loss: 0.449280]\n",
      "epoch:26 step:25224 [D loss: 0.227935, acc.: 60.94%] [G loss: 0.402754]\n",
      "epoch:26 step:25225 [D loss: 0.225599, acc.: 64.06%] [G loss: 0.384306]\n",
      "epoch:26 step:25226 [D loss: 0.237284, acc.: 62.50%] [G loss: 0.429917]\n",
      "epoch:26 step:25227 [D loss: 0.255115, acc.: 50.78%] [G loss: 0.390944]\n",
      "epoch:26 step:25228 [D loss: 0.230450, acc.: 59.38%] [G loss: 0.413795]\n",
      "epoch:26 step:25229 [D loss: 0.204567, acc.: 70.31%] [G loss: 0.402718]\n",
      "epoch:26 step:25230 [D loss: 0.238720, acc.: 60.16%] [G loss: 0.399832]\n",
      "epoch:26 step:25231 [D loss: 0.238153, acc.: 55.47%] [G loss: 0.408163]\n",
      "epoch:26 step:25232 [D loss: 0.222537, acc.: 61.72%] [G loss: 0.402389]\n",
      "epoch:26 step:25233 [D loss: 0.200385, acc.: 69.53%] [G loss: 0.472994]\n",
      "epoch:26 step:25234 [D loss: 0.211848, acc.: 64.84%] [G loss: 0.471823]\n",
      "epoch:26 step:25235 [D loss: 0.232028, acc.: 60.94%] [G loss: 0.433006]\n",
      "epoch:26 step:25236 [D loss: 0.225652, acc.: 63.28%] [G loss: 0.392808]\n",
      "epoch:26 step:25237 [D loss: 0.216142, acc.: 63.28%] [G loss: 0.432434]\n",
      "epoch:26 step:25238 [D loss: 0.228020, acc.: 60.94%] [G loss: 0.433448]\n",
      "epoch:26 step:25239 [D loss: 0.216613, acc.: 68.75%] [G loss: 0.452326]\n",
      "epoch:26 step:25240 [D loss: 0.231122, acc.: 59.38%] [G loss: 0.453394]\n",
      "epoch:26 step:25241 [D loss: 0.235074, acc.: 56.25%] [G loss: 0.418727]\n",
      "epoch:26 step:25242 [D loss: 0.226707, acc.: 60.16%] [G loss: 0.395203]\n",
      "epoch:26 step:25243 [D loss: 0.223286, acc.: 64.84%] [G loss: 0.417023]\n",
      "epoch:26 step:25244 [D loss: 0.227539, acc.: 59.38%] [G loss: 0.391432]\n",
      "epoch:26 step:25245 [D loss: 0.231746, acc.: 60.94%] [G loss: 0.441315]\n",
      "epoch:26 step:25246 [D loss: 0.216522, acc.: 61.72%] [G loss: 0.439245]\n",
      "epoch:26 step:25247 [D loss: 0.246175, acc.: 58.59%] [G loss: 0.477183]\n",
      "epoch:26 step:25248 [D loss: 0.190310, acc.: 71.09%] [G loss: 0.513020]\n",
      "epoch:26 step:25249 [D loss: 0.221928, acc.: 63.28%] [G loss: 0.496940]\n",
      "epoch:26 step:25250 [D loss: 0.241827, acc.: 59.38%] [G loss: 0.449843]\n",
      "epoch:26 step:25251 [D loss: 0.207152, acc.: 64.84%] [G loss: 0.463345]\n",
      "epoch:26 step:25252 [D loss: 0.189026, acc.: 71.88%] [G loss: 0.421271]\n",
      "epoch:26 step:25253 [D loss: 0.256641, acc.: 55.47%] [G loss: 0.409477]\n",
      "epoch:26 step:25254 [D loss: 0.234440, acc.: 57.81%] [G loss: 0.400555]\n",
      "epoch:26 step:25255 [D loss: 0.231001, acc.: 61.72%] [G loss: 0.443194]\n",
      "epoch:26 step:25256 [D loss: 0.215801, acc.: 64.84%] [G loss: 0.400844]\n",
      "epoch:26 step:25257 [D loss: 0.206891, acc.: 68.75%] [G loss: 0.440296]\n",
      "epoch:26 step:25258 [D loss: 0.198484, acc.: 73.44%] [G loss: 0.468226]\n",
      "epoch:26 step:25259 [D loss: 0.204461, acc.: 67.97%] [G loss: 0.478561]\n",
      "epoch:26 step:25260 [D loss: 0.200359, acc.: 70.31%] [G loss: 0.434943]\n",
      "epoch:26 step:25261 [D loss: 0.178222, acc.: 74.22%] [G loss: 0.478905]\n",
      "epoch:26 step:25262 [D loss: 0.225449, acc.: 64.84%] [G loss: 0.476028]\n",
      "epoch:26 step:25263 [D loss: 0.214302, acc.: 65.62%] [G loss: 0.436890]\n",
      "epoch:26 step:25264 [D loss: 0.258012, acc.: 54.69%] [G loss: 0.413895]\n",
      "epoch:26 step:25265 [D loss: 0.228086, acc.: 64.06%] [G loss: 0.444195]\n",
      "epoch:26 step:25266 [D loss: 0.227094, acc.: 63.28%] [G loss: 0.462513]\n",
      "epoch:26 step:25267 [D loss: 0.180120, acc.: 75.78%] [G loss: 0.506430]\n",
      "epoch:26 step:25268 [D loss: 0.246877, acc.: 54.69%] [G loss: 0.480828]\n",
      "epoch:26 step:25269 [D loss: 0.264775, acc.: 58.59%] [G loss: 0.419698]\n",
      "epoch:26 step:25270 [D loss: 0.212634, acc.: 71.88%] [G loss: 0.460346]\n",
      "epoch:26 step:25271 [D loss: 0.201957, acc.: 67.19%] [G loss: 0.432375]\n",
      "epoch:26 step:25272 [D loss: 0.253941, acc.: 58.59%] [G loss: 0.401703]\n",
      "epoch:26 step:25273 [D loss: 0.225671, acc.: 64.06%] [G loss: 0.413387]\n",
      "epoch:26 step:25274 [D loss: 0.224251, acc.: 61.72%] [G loss: 0.434985]\n",
      "epoch:26 step:25275 [D loss: 0.246413, acc.: 55.47%] [G loss: 0.450384]\n",
      "epoch:26 step:25276 [D loss: 0.202408, acc.: 66.41%] [G loss: 0.445374]\n",
      "epoch:26 step:25277 [D loss: 0.258584, acc.: 55.47%] [G loss: 0.361674]\n",
      "epoch:26 step:25278 [D loss: 0.249314, acc.: 63.28%] [G loss: 0.393876]\n",
      "epoch:26 step:25279 [D loss: 0.251831, acc.: 57.03%] [G loss: 0.410100]\n",
      "epoch:26 step:25280 [D loss: 0.195798, acc.: 74.22%] [G loss: 0.464860]\n",
      "epoch:26 step:25281 [D loss: 0.213130, acc.: 67.97%] [G loss: 0.454048]\n",
      "epoch:26 step:25282 [D loss: 0.283625, acc.: 44.53%] [G loss: 0.455667]\n",
      "epoch:26 step:25283 [D loss: 0.232784, acc.: 58.59%] [G loss: 0.448529]\n",
      "epoch:26 step:25284 [D loss: 0.237077, acc.: 57.03%] [G loss: 0.427671]\n",
      "epoch:26 step:25285 [D loss: 0.220544, acc.: 62.50%] [G loss: 0.421411]\n",
      "epoch:26 step:25286 [D loss: 0.174392, acc.: 77.34%] [G loss: 0.454410]\n",
      "epoch:26 step:25287 [D loss: 0.175280, acc.: 75.78%] [G loss: 0.471570]\n",
      "epoch:26 step:25288 [D loss: 0.209214, acc.: 71.88%] [G loss: 0.462541]\n",
      "epoch:26 step:25289 [D loss: 0.184259, acc.: 72.66%] [G loss: 0.550789]\n",
      "epoch:26 step:25290 [D loss: 0.294976, acc.: 54.69%] [G loss: 0.470553]\n",
      "epoch:26 step:25291 [D loss: 0.257464, acc.: 55.47%] [G loss: 0.553138]\n",
      "epoch:26 step:25292 [D loss: 0.219805, acc.: 63.28%] [G loss: 0.550915]\n",
      "epoch:26 step:25293 [D loss: 0.221441, acc.: 62.50%] [G loss: 0.456196]\n",
      "epoch:26 step:25294 [D loss: 0.237361, acc.: 61.72%] [G loss: 0.454245]\n",
      "epoch:26 step:25295 [D loss: 0.210425, acc.: 70.31%] [G loss: 0.455982]\n",
      "epoch:26 step:25296 [D loss: 0.222328, acc.: 67.19%] [G loss: 0.446815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25297 [D loss: 0.216677, acc.: 65.62%] [G loss: 0.502860]\n",
      "epoch:26 step:25298 [D loss: 0.162849, acc.: 77.34%] [G loss: 0.501217]\n",
      "epoch:26 step:25299 [D loss: 0.213569, acc.: 64.06%] [G loss: 0.517957]\n",
      "epoch:27 step:25300 [D loss: 0.217071, acc.: 68.75%] [G loss: 0.502090]\n",
      "epoch:27 step:25301 [D loss: 0.263604, acc.: 60.94%] [G loss: 0.422867]\n",
      "epoch:27 step:25302 [D loss: 0.238508, acc.: 57.81%] [G loss: 0.435810]\n",
      "epoch:27 step:25303 [D loss: 0.235297, acc.: 59.38%] [G loss: 0.480894]\n",
      "epoch:27 step:25304 [D loss: 0.227684, acc.: 61.72%] [G loss: 0.463918]\n",
      "epoch:27 step:25305 [D loss: 0.218825, acc.: 66.41%] [G loss: 0.433440]\n",
      "epoch:27 step:25306 [D loss: 0.236926, acc.: 59.38%] [G loss: 0.412716]\n",
      "epoch:27 step:25307 [D loss: 0.221778, acc.: 65.62%] [G loss: 0.431602]\n",
      "epoch:27 step:25308 [D loss: 0.198864, acc.: 74.22%] [G loss: 0.462654]\n",
      "epoch:27 step:25309 [D loss: 0.200605, acc.: 67.97%] [G loss: 0.492341]\n",
      "epoch:27 step:25310 [D loss: 0.203494, acc.: 72.66%] [G loss: 0.479618]\n",
      "epoch:27 step:25311 [D loss: 0.242221, acc.: 57.81%] [G loss: 0.440572]\n",
      "epoch:27 step:25312 [D loss: 0.211555, acc.: 66.41%] [G loss: 0.441980]\n",
      "epoch:27 step:25313 [D loss: 0.197380, acc.: 75.00%] [G loss: 0.463375]\n",
      "epoch:27 step:25314 [D loss: 0.199285, acc.: 71.09%] [G loss: 0.446506]\n",
      "epoch:27 step:25315 [D loss: 0.207026, acc.: 66.41%] [G loss: 0.479508]\n",
      "epoch:27 step:25316 [D loss: 0.238566, acc.: 63.28%] [G loss: 0.415252]\n",
      "epoch:27 step:25317 [D loss: 0.218330, acc.: 67.19%] [G loss: 0.451397]\n",
      "epoch:27 step:25318 [D loss: 0.246233, acc.: 56.25%] [G loss: 0.446367]\n",
      "epoch:27 step:25319 [D loss: 0.265007, acc.: 51.56%] [G loss: 0.425218]\n",
      "epoch:27 step:25320 [D loss: 0.225350, acc.: 65.62%] [G loss: 0.471071]\n",
      "epoch:27 step:25321 [D loss: 0.202479, acc.: 71.88%] [G loss: 0.573030]\n",
      "epoch:27 step:25322 [D loss: 0.287363, acc.: 50.00%] [G loss: 0.422582]\n",
      "epoch:27 step:25323 [D loss: 0.231623, acc.: 60.94%] [G loss: 0.416893]\n",
      "epoch:27 step:25324 [D loss: 0.201222, acc.: 69.53%] [G loss: 0.458471]\n",
      "epoch:27 step:25325 [D loss: 0.228318, acc.: 60.94%] [G loss: 0.416185]\n",
      "epoch:27 step:25326 [D loss: 0.211434, acc.: 66.41%] [G loss: 0.406690]\n",
      "epoch:27 step:25327 [D loss: 0.208398, acc.: 69.53%] [G loss: 0.449639]\n",
      "epoch:27 step:25328 [D loss: 0.215424, acc.: 65.62%] [G loss: 0.414669]\n",
      "epoch:27 step:25329 [D loss: 0.223107, acc.: 66.41%] [G loss: 0.439989]\n",
      "epoch:27 step:25330 [D loss: 0.257991, acc.: 53.12%] [G loss: 0.458221]\n",
      "epoch:27 step:25331 [D loss: 0.233323, acc.: 64.84%] [G loss: 0.448065]\n",
      "epoch:27 step:25332 [D loss: 0.233695, acc.: 60.94%] [G loss: 0.438914]\n",
      "epoch:27 step:25333 [D loss: 0.213557, acc.: 64.06%] [G loss: 0.444977]\n",
      "epoch:27 step:25334 [D loss: 0.225125, acc.: 61.72%] [G loss: 0.429771]\n",
      "epoch:27 step:25335 [D loss: 0.204452, acc.: 70.31%] [G loss: 0.411916]\n",
      "epoch:27 step:25336 [D loss: 0.210546, acc.: 70.31%] [G loss: 0.449150]\n",
      "epoch:27 step:25337 [D loss: 0.275217, acc.: 50.78%] [G loss: 0.412821]\n",
      "epoch:27 step:25338 [D loss: 0.222708, acc.: 65.62%] [G loss: 0.414312]\n",
      "epoch:27 step:25339 [D loss: 0.222104, acc.: 61.72%] [G loss: 0.447516]\n",
      "epoch:27 step:25340 [D loss: 0.232456, acc.: 62.50%] [G loss: 0.442747]\n",
      "epoch:27 step:25341 [D loss: 0.205372, acc.: 66.41%] [G loss: 0.446074]\n",
      "epoch:27 step:25342 [D loss: 0.209558, acc.: 67.19%] [G loss: 0.427477]\n",
      "epoch:27 step:25343 [D loss: 0.240179, acc.: 58.59%] [G loss: 0.389695]\n",
      "epoch:27 step:25344 [D loss: 0.222739, acc.: 66.41%] [G loss: 0.439726]\n",
      "epoch:27 step:25345 [D loss: 0.235263, acc.: 58.59%] [G loss: 0.451539]\n",
      "epoch:27 step:25346 [D loss: 0.226526, acc.: 62.50%] [G loss: 0.442733]\n",
      "epoch:27 step:25347 [D loss: 0.200242, acc.: 70.31%] [G loss: 0.437492]\n",
      "epoch:27 step:25348 [D loss: 0.231461, acc.: 57.81%] [G loss: 0.431620]\n",
      "epoch:27 step:25349 [D loss: 0.220799, acc.: 64.84%] [G loss: 0.453464]\n",
      "epoch:27 step:25350 [D loss: 0.229834, acc.: 60.94%] [G loss: 0.418863]\n",
      "epoch:27 step:25351 [D loss: 0.206605, acc.: 66.41%] [G loss: 0.429776]\n",
      "epoch:27 step:25352 [D loss: 0.221191, acc.: 64.84%] [G loss: 0.426667]\n",
      "epoch:27 step:25353 [D loss: 0.212377, acc.: 66.41%] [G loss: 0.444571]\n",
      "epoch:27 step:25354 [D loss: 0.196883, acc.: 69.53%] [G loss: 0.447835]\n",
      "epoch:27 step:25355 [D loss: 0.209424, acc.: 67.97%] [G loss: 0.420646]\n",
      "epoch:27 step:25356 [D loss: 0.226763, acc.: 62.50%] [G loss: 0.415660]\n",
      "epoch:27 step:25357 [D loss: 0.207683, acc.: 71.09%] [G loss: 0.446733]\n",
      "epoch:27 step:25358 [D loss: 0.210459, acc.: 71.09%] [G loss: 0.423897]\n",
      "epoch:27 step:25359 [D loss: 0.259098, acc.: 57.03%] [G loss: 0.435313]\n",
      "epoch:27 step:25360 [D loss: 0.230517, acc.: 64.06%] [G loss: 0.462944]\n",
      "epoch:27 step:25361 [D loss: 0.227313, acc.: 59.38%] [G loss: 0.439749]\n",
      "epoch:27 step:25362 [D loss: 0.225865, acc.: 62.50%] [G loss: 0.407929]\n",
      "epoch:27 step:25363 [D loss: 0.230699, acc.: 62.50%] [G loss: 0.430152]\n",
      "epoch:27 step:25364 [D loss: 0.253752, acc.: 58.59%] [G loss: 0.415496]\n",
      "epoch:27 step:25365 [D loss: 0.224126, acc.: 60.94%] [G loss: 0.433956]\n",
      "epoch:27 step:25366 [D loss: 0.210098, acc.: 63.28%] [G loss: 0.457503]\n",
      "epoch:27 step:25367 [D loss: 0.226374, acc.: 66.41%] [G loss: 0.437234]\n",
      "epoch:27 step:25368 [D loss: 0.207953, acc.: 68.75%] [G loss: 0.454761]\n",
      "epoch:27 step:25369 [D loss: 0.210428, acc.: 67.19%] [G loss: 0.435472]\n",
      "epoch:27 step:25370 [D loss: 0.258992, acc.: 54.69%] [G loss: 0.420773]\n",
      "epoch:27 step:25371 [D loss: 0.232091, acc.: 60.16%] [G loss: 0.379311]\n",
      "epoch:27 step:25372 [D loss: 0.210393, acc.: 63.28%] [G loss: 0.426305]\n",
      "epoch:27 step:25373 [D loss: 0.190384, acc.: 67.97%] [G loss: 0.447325]\n",
      "epoch:27 step:25374 [D loss: 0.215446, acc.: 66.41%] [G loss: 0.441652]\n",
      "epoch:27 step:25375 [D loss: 0.187715, acc.: 68.75%] [G loss: 0.470467]\n",
      "epoch:27 step:25376 [D loss: 0.193662, acc.: 64.84%] [G loss: 0.489198]\n",
      "epoch:27 step:25377 [D loss: 0.240416, acc.: 60.16%] [G loss: 0.440854]\n",
      "epoch:27 step:25378 [D loss: 0.263636, acc.: 50.00%] [G loss: 0.404681]\n",
      "epoch:27 step:25379 [D loss: 0.216464, acc.: 60.16%] [G loss: 0.397947]\n",
      "epoch:27 step:25380 [D loss: 0.248297, acc.: 50.00%] [G loss: 0.393067]\n",
      "epoch:27 step:25381 [D loss: 0.228941, acc.: 62.50%] [G loss: 0.388277]\n",
      "epoch:27 step:25382 [D loss: 0.221863, acc.: 63.28%] [G loss: 0.432373]\n",
      "epoch:27 step:25383 [D loss: 0.235866, acc.: 59.38%] [G loss: 0.455798]\n",
      "epoch:27 step:25384 [D loss: 0.224020, acc.: 61.72%] [G loss: 0.478566]\n",
      "epoch:27 step:25385 [D loss: 0.231915, acc.: 64.84%] [G loss: 0.414390]\n",
      "epoch:27 step:25386 [D loss: 0.245235, acc.: 57.81%] [G loss: 0.392086]\n",
      "epoch:27 step:25387 [D loss: 0.206426, acc.: 70.31%] [G loss: 0.423164]\n",
      "epoch:27 step:25388 [D loss: 0.213640, acc.: 64.84%] [G loss: 0.460225]\n",
      "epoch:27 step:25389 [D loss: 0.215185, acc.: 65.62%] [G loss: 0.412664]\n",
      "epoch:27 step:25390 [D loss: 0.236334, acc.: 64.84%] [G loss: 0.382300]\n",
      "epoch:27 step:25391 [D loss: 0.224884, acc.: 62.50%] [G loss: 0.425240]\n",
      "epoch:27 step:25392 [D loss: 0.202840, acc.: 68.75%] [G loss: 0.425170]\n",
      "epoch:27 step:25393 [D loss: 0.229626, acc.: 66.41%] [G loss: 0.472623]\n",
      "epoch:27 step:25394 [D loss: 0.241037, acc.: 55.47%] [G loss: 0.435060]\n",
      "epoch:27 step:25395 [D loss: 0.217596, acc.: 60.94%] [G loss: 0.485857]\n",
      "epoch:27 step:25396 [D loss: 0.198683, acc.: 71.88%] [G loss: 0.479231]\n",
      "epoch:27 step:25397 [D loss: 0.219631, acc.: 65.62%] [G loss: 0.460273]\n",
      "epoch:27 step:25398 [D loss: 0.251129, acc.: 54.69%] [G loss: 0.426505]\n",
      "epoch:27 step:25399 [D loss: 0.185911, acc.: 71.09%] [G loss: 0.484849]\n",
      "epoch:27 step:25400 [D loss: 0.205715, acc.: 67.97%] [G loss: 0.415088]\n",
      "epoch:27 step:25401 [D loss: 0.229082, acc.: 58.59%] [G loss: 0.467082]\n",
      "epoch:27 step:25402 [D loss: 0.247876, acc.: 56.25%] [G loss: 0.428511]\n",
      "epoch:27 step:25403 [D loss: 0.232223, acc.: 56.25%] [G loss: 0.381682]\n",
      "epoch:27 step:25404 [D loss: 0.241060, acc.: 62.50%] [G loss: 0.376995]\n",
      "epoch:27 step:25405 [D loss: 0.216135, acc.: 63.28%] [G loss: 0.415245]\n",
      "epoch:27 step:25406 [D loss: 0.195545, acc.: 72.66%] [G loss: 0.400064]\n",
      "epoch:27 step:25407 [D loss: 0.272321, acc.: 52.34%] [G loss: 0.396425]\n",
      "epoch:27 step:25408 [D loss: 0.249663, acc.: 56.25%] [G loss: 0.419412]\n",
      "epoch:27 step:25409 [D loss: 0.221884, acc.: 63.28%] [G loss: 0.456472]\n",
      "epoch:27 step:25410 [D loss: 0.208455, acc.: 67.97%] [G loss: 0.420268]\n",
      "epoch:27 step:25411 [D loss: 0.200022, acc.: 67.97%] [G loss: 0.460143]\n",
      "epoch:27 step:25412 [D loss: 0.216351, acc.: 64.84%] [G loss: 0.452097]\n",
      "epoch:27 step:25413 [D loss: 0.209397, acc.: 67.19%] [G loss: 0.482364]\n",
      "epoch:27 step:25414 [D loss: 0.186281, acc.: 72.66%] [G loss: 0.552586]\n",
      "epoch:27 step:25415 [D loss: 0.220454, acc.: 66.41%] [G loss: 0.455261]\n",
      "epoch:27 step:25416 [D loss: 0.190602, acc.: 71.09%] [G loss: 0.429781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25417 [D loss: 0.189950, acc.: 70.31%] [G loss: 0.483963]\n",
      "epoch:27 step:25418 [D loss: 0.178229, acc.: 71.09%] [G loss: 0.521798]\n",
      "epoch:27 step:25419 [D loss: 0.281395, acc.: 55.47%] [G loss: 0.450581]\n",
      "epoch:27 step:25420 [D loss: 0.241418, acc.: 57.03%] [G loss: 0.445012]\n",
      "epoch:27 step:25421 [D loss: 0.193669, acc.: 71.09%] [G loss: 0.412029]\n",
      "epoch:27 step:25422 [D loss: 0.228656, acc.: 61.72%] [G loss: 0.445766]\n",
      "epoch:27 step:25423 [D loss: 0.271184, acc.: 52.34%] [G loss: 0.437405]\n",
      "epoch:27 step:25424 [D loss: 0.224157, acc.: 67.19%] [G loss: 0.457401]\n",
      "epoch:27 step:25425 [D loss: 0.206768, acc.: 67.97%] [G loss: 0.396148]\n",
      "epoch:27 step:25426 [D loss: 0.210828, acc.: 62.50%] [G loss: 0.391453]\n",
      "epoch:27 step:25427 [D loss: 0.246960, acc.: 55.47%] [G loss: 0.411306]\n",
      "epoch:27 step:25428 [D loss: 0.225220, acc.: 62.50%] [G loss: 0.405215]\n",
      "epoch:27 step:25429 [D loss: 0.202601, acc.: 69.53%] [G loss: 0.426788]\n",
      "epoch:27 step:25430 [D loss: 0.205119, acc.: 64.84%] [G loss: 0.464095]\n",
      "epoch:27 step:25431 [D loss: 0.210954, acc.: 64.84%] [G loss: 0.460527]\n",
      "epoch:27 step:25432 [D loss: 0.246645, acc.: 57.81%] [G loss: 0.446673]\n",
      "epoch:27 step:25433 [D loss: 0.221305, acc.: 66.41%] [G loss: 0.456621]\n",
      "epoch:27 step:25434 [D loss: 0.189363, acc.: 75.00%] [G loss: 0.463263]\n",
      "epoch:27 step:25435 [D loss: 0.234294, acc.: 62.50%] [G loss: 0.433337]\n",
      "epoch:27 step:25436 [D loss: 0.237018, acc.: 64.06%] [G loss: 0.434698]\n",
      "epoch:27 step:25437 [D loss: 0.268607, acc.: 46.88%] [G loss: 0.394082]\n",
      "epoch:27 step:25438 [D loss: 0.242186, acc.: 55.47%] [G loss: 0.413061]\n",
      "epoch:27 step:25439 [D loss: 0.223127, acc.: 67.19%] [G loss: 0.442999]\n",
      "epoch:27 step:25440 [D loss: 0.224770, acc.: 58.59%] [G loss: 0.439948]\n",
      "epoch:27 step:25441 [D loss: 0.250081, acc.: 53.12%] [G loss: 0.417116]\n",
      "epoch:27 step:25442 [D loss: 0.252201, acc.: 57.03%] [G loss: 0.381802]\n",
      "epoch:27 step:25443 [D loss: 0.194702, acc.: 69.53%] [G loss: 0.438268]\n",
      "epoch:27 step:25444 [D loss: 0.245246, acc.: 60.16%] [G loss: 0.445893]\n",
      "epoch:27 step:25445 [D loss: 0.229320, acc.: 62.50%] [G loss: 0.426015]\n",
      "epoch:27 step:25446 [D loss: 0.236795, acc.: 53.12%] [G loss: 0.407836]\n",
      "epoch:27 step:25447 [D loss: 0.244467, acc.: 56.25%] [G loss: 0.417454]\n",
      "epoch:27 step:25448 [D loss: 0.238017, acc.: 61.72%] [G loss: 0.409469]\n",
      "epoch:27 step:25449 [D loss: 0.221413, acc.: 65.62%] [G loss: 0.443375]\n",
      "epoch:27 step:25450 [D loss: 0.225792, acc.: 67.19%] [G loss: 0.445771]\n",
      "epoch:27 step:25451 [D loss: 0.233183, acc.: 61.72%] [G loss: 0.447080]\n",
      "epoch:27 step:25452 [D loss: 0.221960, acc.: 62.50%] [G loss: 0.385984]\n",
      "epoch:27 step:25453 [D loss: 0.229970, acc.: 57.81%] [G loss: 0.419387]\n",
      "epoch:27 step:25454 [D loss: 0.221663, acc.: 59.38%] [G loss: 0.395526]\n",
      "epoch:27 step:25455 [D loss: 0.198124, acc.: 75.00%] [G loss: 0.476774]\n",
      "epoch:27 step:25456 [D loss: 0.231933, acc.: 60.16%] [G loss: 0.399370]\n",
      "epoch:27 step:25457 [D loss: 0.218157, acc.: 65.62%] [G loss: 0.452577]\n",
      "epoch:27 step:25458 [D loss: 0.200463, acc.: 71.09%] [G loss: 0.429893]\n",
      "epoch:27 step:25459 [D loss: 0.263408, acc.: 53.91%] [G loss: 0.440847]\n",
      "epoch:27 step:25460 [D loss: 0.231004, acc.: 61.72%] [G loss: 0.502578]\n",
      "epoch:27 step:25461 [D loss: 0.260423, acc.: 53.91%] [G loss: 0.408915]\n",
      "epoch:27 step:25462 [D loss: 0.234313, acc.: 61.72%] [G loss: 0.448493]\n",
      "epoch:27 step:25463 [D loss: 0.223906, acc.: 62.50%] [G loss: 0.440581]\n",
      "epoch:27 step:25464 [D loss: 0.220556, acc.: 66.41%] [G loss: 0.420024]\n",
      "epoch:27 step:25465 [D loss: 0.232685, acc.: 60.94%] [G loss: 0.419778]\n",
      "epoch:27 step:25466 [D loss: 0.228552, acc.: 58.59%] [G loss: 0.399548]\n",
      "epoch:27 step:25467 [D loss: 0.203545, acc.: 67.19%] [G loss: 0.437858]\n",
      "epoch:27 step:25468 [D loss: 0.219466, acc.: 63.28%] [G loss: 0.447376]\n",
      "epoch:27 step:25469 [D loss: 0.238207, acc.: 60.16%] [G loss: 0.389398]\n",
      "epoch:27 step:25470 [D loss: 0.233133, acc.: 60.94%] [G loss: 0.416442]\n",
      "epoch:27 step:25471 [D loss: 0.221874, acc.: 61.72%] [G loss: 0.439589]\n",
      "epoch:27 step:25472 [D loss: 0.212419, acc.: 68.75%] [G loss: 0.441584]\n",
      "epoch:27 step:25473 [D loss: 0.228889, acc.: 58.59%] [G loss: 0.432373]\n",
      "epoch:27 step:25474 [D loss: 0.241489, acc.: 63.28%] [G loss: 0.420280]\n",
      "epoch:27 step:25475 [D loss: 0.224788, acc.: 64.06%] [G loss: 0.389542]\n",
      "epoch:27 step:25476 [D loss: 0.240398, acc.: 60.16%] [G loss: 0.427784]\n",
      "epoch:27 step:25477 [D loss: 0.239853, acc.: 64.06%] [G loss: 0.442270]\n",
      "epoch:27 step:25478 [D loss: 0.223105, acc.: 64.84%] [G loss: 0.436411]\n",
      "epoch:27 step:25479 [D loss: 0.226554, acc.: 63.28%] [G loss: 0.401652]\n",
      "epoch:27 step:25480 [D loss: 0.236811, acc.: 58.59%] [G loss: 0.396056]\n",
      "epoch:27 step:25481 [D loss: 0.237171, acc.: 60.94%] [G loss: 0.401472]\n",
      "epoch:27 step:25482 [D loss: 0.223146, acc.: 67.97%] [G loss: 0.412236]\n",
      "epoch:27 step:25483 [D loss: 0.229176, acc.: 57.81%] [G loss: 0.457479]\n",
      "epoch:27 step:25484 [D loss: 0.244828, acc.: 55.47%] [G loss: 0.424070]\n",
      "epoch:27 step:25485 [D loss: 0.239620, acc.: 56.25%] [G loss: 0.421186]\n",
      "epoch:27 step:25486 [D loss: 0.250292, acc.: 58.59%] [G loss: 0.402363]\n",
      "epoch:27 step:25487 [D loss: 0.237576, acc.: 57.03%] [G loss: 0.415625]\n",
      "epoch:27 step:25488 [D loss: 0.237537, acc.: 57.03%] [G loss: 0.403239]\n",
      "epoch:27 step:25489 [D loss: 0.224719, acc.: 61.72%] [G loss: 0.378540]\n",
      "epoch:27 step:25490 [D loss: 0.211248, acc.: 69.53%] [G loss: 0.424524]\n",
      "epoch:27 step:25491 [D loss: 0.215386, acc.: 63.28%] [G loss: 0.433440]\n",
      "epoch:27 step:25492 [D loss: 0.249946, acc.: 57.03%] [G loss: 0.423205]\n",
      "epoch:27 step:25493 [D loss: 0.205965, acc.: 69.53%] [G loss: 0.445278]\n",
      "epoch:27 step:25494 [D loss: 0.226172, acc.: 60.94%] [G loss: 0.418797]\n",
      "epoch:27 step:25495 [D loss: 0.248502, acc.: 59.38%] [G loss: 0.399681]\n",
      "epoch:27 step:25496 [D loss: 0.209485, acc.: 64.84%] [G loss: 0.431312]\n",
      "epoch:27 step:25497 [D loss: 0.195714, acc.: 68.75%] [G loss: 0.405917]\n",
      "epoch:27 step:25498 [D loss: 0.235783, acc.: 59.38%] [G loss: 0.446081]\n",
      "epoch:27 step:25499 [D loss: 0.254304, acc.: 53.91%] [G loss: 0.418291]\n",
      "epoch:27 step:25500 [D loss: 0.242524, acc.: 55.47%] [G loss: 0.440579]\n",
      "epoch:27 step:25501 [D loss: 0.208332, acc.: 74.22%] [G loss: 0.460534]\n",
      "epoch:27 step:25502 [D loss: 0.246843, acc.: 62.50%] [G loss: 0.477931]\n",
      "epoch:27 step:25503 [D loss: 0.212659, acc.: 65.62%] [G loss: 0.485457]\n",
      "epoch:27 step:25504 [D loss: 0.229166, acc.: 64.84%] [G loss: 0.529915]\n",
      "epoch:27 step:25505 [D loss: 0.234277, acc.: 64.06%] [G loss: 0.422738]\n",
      "epoch:27 step:25506 [D loss: 0.204534, acc.: 64.06%] [G loss: 0.439992]\n",
      "epoch:27 step:25507 [D loss: 0.190410, acc.: 69.53%] [G loss: 0.460402]\n",
      "epoch:27 step:25508 [D loss: 0.212618, acc.: 64.84%] [G loss: 0.454668]\n",
      "epoch:27 step:25509 [D loss: 0.261534, acc.: 54.69%] [G loss: 0.429480]\n",
      "epoch:27 step:25510 [D loss: 0.248600, acc.: 53.12%] [G loss: 0.419547]\n",
      "epoch:27 step:25511 [D loss: 0.239638, acc.: 60.94%] [G loss: 0.397428]\n",
      "epoch:27 step:25512 [D loss: 0.232986, acc.: 58.59%] [G loss: 0.406887]\n",
      "epoch:27 step:25513 [D loss: 0.226986, acc.: 64.84%] [G loss: 0.422546]\n",
      "epoch:27 step:25514 [D loss: 0.225749, acc.: 63.28%] [G loss: 0.377388]\n",
      "epoch:27 step:25515 [D loss: 0.216660, acc.: 61.72%] [G loss: 0.452462]\n",
      "epoch:27 step:25516 [D loss: 0.206925, acc.: 71.09%] [G loss: 0.444594]\n",
      "epoch:27 step:25517 [D loss: 0.184977, acc.: 73.44%] [G loss: 0.440013]\n",
      "epoch:27 step:25518 [D loss: 0.183009, acc.: 71.88%] [G loss: 0.469637]\n",
      "epoch:27 step:25519 [D loss: 0.273597, acc.: 55.47%] [G loss: 0.472703]\n",
      "epoch:27 step:25520 [D loss: 0.207734, acc.: 66.41%] [G loss: 0.477884]\n",
      "epoch:27 step:25521 [D loss: 0.207849, acc.: 66.41%] [G loss: 0.486201]\n",
      "epoch:27 step:25522 [D loss: 0.236978, acc.: 62.50%] [G loss: 0.416754]\n",
      "epoch:27 step:25523 [D loss: 0.249356, acc.: 61.72%] [G loss: 0.391094]\n",
      "epoch:27 step:25524 [D loss: 0.236970, acc.: 56.25%] [G loss: 0.399344]\n",
      "epoch:27 step:25525 [D loss: 0.215840, acc.: 64.06%] [G loss: 0.454244]\n",
      "epoch:27 step:25526 [D loss: 0.206512, acc.: 71.09%] [G loss: 0.427278]\n",
      "epoch:27 step:25527 [D loss: 0.231476, acc.: 59.38%] [G loss: 0.399612]\n",
      "epoch:27 step:25528 [D loss: 0.222461, acc.: 61.72%] [G loss: 0.424920]\n",
      "epoch:27 step:25529 [D loss: 0.200833, acc.: 67.97%] [G loss: 0.488292]\n",
      "epoch:27 step:25530 [D loss: 0.165562, acc.: 75.78%] [G loss: 0.530205]\n",
      "epoch:27 step:25531 [D loss: 0.175278, acc.: 76.56%] [G loss: 0.517641]\n",
      "epoch:27 step:25532 [D loss: 0.280755, acc.: 55.47%] [G loss: 0.425846]\n",
      "epoch:27 step:25533 [D loss: 0.222201, acc.: 60.16%] [G loss: 0.470541]\n",
      "epoch:27 step:25534 [D loss: 0.220773, acc.: 65.62%] [G loss: 0.418822]\n",
      "epoch:27 step:25535 [D loss: 0.206744, acc.: 71.88%] [G loss: 0.407978]\n",
      "epoch:27 step:25536 [D loss: 0.226097, acc.: 69.53%] [G loss: 0.416460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25537 [D loss: 0.218489, acc.: 65.62%] [G loss: 0.416234]\n",
      "epoch:27 step:25538 [D loss: 0.202383, acc.: 64.84%] [G loss: 0.414384]\n",
      "epoch:27 step:25539 [D loss: 0.221456, acc.: 64.84%] [G loss: 0.439953]\n",
      "epoch:27 step:25540 [D loss: 0.193767, acc.: 73.44%] [G loss: 0.454030]\n",
      "epoch:27 step:25541 [D loss: 0.212985, acc.: 67.19%] [G loss: 0.499761]\n",
      "epoch:27 step:25542 [D loss: 0.222132, acc.: 64.84%] [G loss: 0.450925]\n",
      "epoch:27 step:25543 [D loss: 0.191314, acc.: 70.31%] [G loss: 0.454557]\n",
      "epoch:27 step:25544 [D loss: 0.217520, acc.: 66.41%] [G loss: 0.436285]\n",
      "epoch:27 step:25545 [D loss: 0.213488, acc.: 65.62%] [G loss: 0.403001]\n",
      "epoch:27 step:25546 [D loss: 0.211477, acc.: 66.41%] [G loss: 0.431802]\n",
      "epoch:27 step:25547 [D loss: 0.189328, acc.: 69.53%] [G loss: 0.473730]\n",
      "epoch:27 step:25548 [D loss: 0.259971, acc.: 53.91%] [G loss: 0.465663]\n",
      "epoch:27 step:25549 [D loss: 0.255190, acc.: 56.25%] [G loss: 0.421727]\n",
      "epoch:27 step:25550 [D loss: 0.249037, acc.: 64.06%] [G loss: 0.436273]\n",
      "epoch:27 step:25551 [D loss: 0.215625, acc.: 69.53%] [G loss: 0.461470]\n",
      "epoch:27 step:25552 [D loss: 0.219522, acc.: 62.50%] [G loss: 0.419590]\n",
      "epoch:27 step:25553 [D loss: 0.231493, acc.: 62.50%] [G loss: 0.418889]\n",
      "epoch:27 step:25554 [D loss: 0.205560, acc.: 64.06%] [G loss: 0.441810]\n",
      "epoch:27 step:25555 [D loss: 0.236688, acc.: 62.50%] [G loss: 0.389341]\n",
      "epoch:27 step:25556 [D loss: 0.212330, acc.: 64.84%] [G loss: 0.413812]\n",
      "epoch:27 step:25557 [D loss: 0.195113, acc.: 69.53%] [G loss: 0.440705]\n",
      "epoch:27 step:25558 [D loss: 0.212386, acc.: 65.62%] [G loss: 0.450403]\n",
      "epoch:27 step:25559 [D loss: 0.229237, acc.: 59.38%] [G loss: 0.408329]\n",
      "epoch:27 step:25560 [D loss: 0.219778, acc.: 66.41%] [G loss: 0.439315]\n",
      "epoch:27 step:25561 [D loss: 0.192294, acc.: 73.44%] [G loss: 0.486430]\n",
      "epoch:27 step:25562 [D loss: 0.274320, acc.: 53.91%] [G loss: 0.422518]\n",
      "epoch:27 step:25563 [D loss: 0.196502, acc.: 73.44%] [G loss: 0.449797]\n",
      "epoch:27 step:25564 [D loss: 0.244157, acc.: 57.03%] [G loss: 0.411866]\n",
      "epoch:27 step:25565 [D loss: 0.206115, acc.: 67.19%] [G loss: 0.435496]\n",
      "epoch:27 step:25566 [D loss: 0.211084, acc.: 71.88%] [G loss: 0.434268]\n",
      "epoch:27 step:25567 [D loss: 0.186296, acc.: 73.44%] [G loss: 0.463926]\n",
      "epoch:27 step:25568 [D loss: 0.207758, acc.: 66.41%] [G loss: 0.473254]\n",
      "epoch:27 step:25569 [D loss: 0.217234, acc.: 64.84%] [G loss: 0.460226]\n",
      "epoch:27 step:25570 [D loss: 0.208303, acc.: 64.06%] [G loss: 0.433904]\n",
      "epoch:27 step:25571 [D loss: 0.232771, acc.: 60.94%] [G loss: 0.445962]\n",
      "epoch:27 step:25572 [D loss: 0.233651, acc.: 57.03%] [G loss: 0.417126]\n",
      "epoch:27 step:25573 [D loss: 0.187242, acc.: 71.88%] [G loss: 0.448048]\n",
      "epoch:27 step:25574 [D loss: 0.206897, acc.: 70.31%] [G loss: 0.459357]\n",
      "epoch:27 step:25575 [D loss: 0.199799, acc.: 73.44%] [G loss: 0.435244]\n",
      "epoch:27 step:25576 [D loss: 0.243562, acc.: 57.03%] [G loss: 0.412864]\n",
      "epoch:27 step:25577 [D loss: 0.241726, acc.: 57.03%] [G loss: 0.421610]\n",
      "epoch:27 step:25578 [D loss: 0.210714, acc.: 70.31%] [G loss: 0.435818]\n",
      "epoch:27 step:25579 [D loss: 0.218862, acc.: 63.28%] [G loss: 0.413925]\n",
      "epoch:27 step:25580 [D loss: 0.256150, acc.: 59.38%] [G loss: 0.394558]\n",
      "epoch:27 step:25581 [D loss: 0.232276, acc.: 57.81%] [G loss: 0.399960]\n",
      "epoch:27 step:25582 [D loss: 0.203734, acc.: 70.31%] [G loss: 0.432001]\n",
      "epoch:27 step:25583 [D loss: 0.210095, acc.: 67.19%] [G loss: 0.379000]\n",
      "epoch:27 step:25584 [D loss: 0.219121, acc.: 62.50%] [G loss: 0.422518]\n",
      "epoch:27 step:25585 [D loss: 0.219134, acc.: 65.62%] [G loss: 0.435034]\n",
      "epoch:27 step:25586 [D loss: 0.235800, acc.: 60.94%] [G loss: 0.452999]\n",
      "epoch:27 step:25587 [D loss: 0.201553, acc.: 68.75%] [G loss: 0.436095]\n",
      "epoch:27 step:25588 [D loss: 0.197093, acc.: 71.88%] [G loss: 0.469876]\n",
      "epoch:27 step:25589 [D loss: 0.210090, acc.: 66.41%] [G loss: 0.446783]\n",
      "epoch:27 step:25590 [D loss: 0.250295, acc.: 56.25%] [G loss: 0.423796]\n",
      "epoch:27 step:25591 [D loss: 0.203732, acc.: 68.75%] [G loss: 0.420359]\n",
      "epoch:27 step:25592 [D loss: 0.227253, acc.: 57.81%] [G loss: 0.445280]\n",
      "epoch:27 step:25593 [D loss: 0.235312, acc.: 60.16%] [G loss: 0.404369]\n",
      "epoch:27 step:25594 [D loss: 0.215706, acc.: 63.28%] [G loss: 0.410367]\n",
      "epoch:27 step:25595 [D loss: 0.211880, acc.: 64.84%] [G loss: 0.398847]\n",
      "epoch:27 step:25596 [D loss: 0.217211, acc.: 60.94%] [G loss: 0.434712]\n",
      "epoch:27 step:25597 [D loss: 0.193547, acc.: 67.97%] [G loss: 0.449577]\n",
      "epoch:27 step:25598 [D loss: 0.224644, acc.: 62.50%] [G loss: 0.445842]\n",
      "epoch:27 step:25599 [D loss: 0.179172, acc.: 73.44%] [G loss: 0.513390]\n",
      "epoch:27 step:25600 [D loss: 0.269615, acc.: 55.47%] [G loss: 0.450305]\n",
      "epoch:27 step:25601 [D loss: 0.219561, acc.: 63.28%] [G loss: 0.436696]\n",
      "epoch:27 step:25602 [D loss: 0.222285, acc.: 67.97%] [G loss: 0.435514]\n",
      "epoch:27 step:25603 [D loss: 0.237878, acc.: 56.25%] [G loss: 0.394018]\n",
      "epoch:27 step:25604 [D loss: 0.226176, acc.: 62.50%] [G loss: 0.403610]\n",
      "epoch:27 step:25605 [D loss: 0.221523, acc.: 58.59%] [G loss: 0.392048]\n",
      "epoch:27 step:25606 [D loss: 0.183499, acc.: 73.44%] [G loss: 0.487094]\n",
      "epoch:27 step:25607 [D loss: 0.254334, acc.: 54.69%] [G loss: 0.434022]\n",
      "epoch:27 step:25608 [D loss: 0.234291, acc.: 58.59%] [G loss: 0.398115]\n",
      "epoch:27 step:25609 [D loss: 0.218599, acc.: 61.72%] [G loss: 0.437022]\n",
      "epoch:27 step:25610 [D loss: 0.227979, acc.: 62.50%] [G loss: 0.440275]\n",
      "epoch:27 step:25611 [D loss: 0.192862, acc.: 77.34%] [G loss: 0.464524]\n",
      "epoch:27 step:25612 [D loss: 0.182844, acc.: 72.66%] [G loss: 0.458845]\n",
      "epoch:27 step:25613 [D loss: 0.189384, acc.: 68.75%] [G loss: 0.472502]\n",
      "epoch:27 step:25614 [D loss: 0.175554, acc.: 73.44%] [G loss: 0.500813]\n",
      "epoch:27 step:25615 [D loss: 0.265483, acc.: 55.47%] [G loss: 0.431009]\n",
      "epoch:27 step:25616 [D loss: 0.242936, acc.: 56.25%] [G loss: 0.431273]\n",
      "epoch:27 step:25617 [D loss: 0.212730, acc.: 60.94%] [G loss: 0.436517]\n",
      "epoch:27 step:25618 [D loss: 0.213743, acc.: 64.84%] [G loss: 0.435801]\n",
      "epoch:27 step:25619 [D loss: 0.231874, acc.: 62.50%] [G loss: 0.442353]\n",
      "epoch:27 step:25620 [D loss: 0.209252, acc.: 64.84%] [G loss: 0.437876]\n",
      "epoch:27 step:25621 [D loss: 0.197397, acc.: 71.09%] [G loss: 0.492152]\n",
      "epoch:27 step:25622 [D loss: 0.232635, acc.: 58.59%] [G loss: 0.435148]\n",
      "epoch:27 step:25623 [D loss: 0.238759, acc.: 57.81%] [G loss: 0.393467]\n",
      "epoch:27 step:25624 [D loss: 0.208792, acc.: 67.19%] [G loss: 0.434786]\n",
      "epoch:27 step:25625 [D loss: 0.202053, acc.: 72.66%] [G loss: 0.461901]\n",
      "epoch:27 step:25626 [D loss: 0.219452, acc.: 64.84%] [G loss: 0.392682]\n",
      "epoch:27 step:25627 [D loss: 0.200322, acc.: 68.75%] [G loss: 0.470332]\n",
      "epoch:27 step:25628 [D loss: 0.234522, acc.: 60.16%] [G loss: 0.411406]\n",
      "epoch:27 step:25629 [D loss: 0.220933, acc.: 65.62%] [G loss: 0.436187]\n",
      "epoch:27 step:25630 [D loss: 0.194380, acc.: 74.22%] [G loss: 0.450737]\n",
      "epoch:27 step:25631 [D loss: 0.215204, acc.: 66.41%] [G loss: 0.440074]\n",
      "epoch:27 step:25632 [D loss: 0.206708, acc.: 67.97%] [G loss: 0.424306]\n",
      "epoch:27 step:25633 [D loss: 0.231151, acc.: 67.19%] [G loss: 0.407254]\n",
      "epoch:27 step:25634 [D loss: 0.223572, acc.: 59.38%] [G loss: 0.430375]\n",
      "epoch:27 step:25635 [D loss: 0.213681, acc.: 66.41%] [G loss: 0.454984]\n",
      "epoch:27 step:25636 [D loss: 0.216655, acc.: 67.97%] [G loss: 0.482820]\n",
      "epoch:27 step:25637 [D loss: 0.208469, acc.: 66.41%] [G loss: 0.475733]\n",
      "epoch:27 step:25638 [D loss: 0.197735, acc.: 71.88%] [G loss: 0.458945]\n",
      "epoch:27 step:25639 [D loss: 0.219362, acc.: 64.06%] [G loss: 0.460667]\n",
      "epoch:27 step:25640 [D loss: 0.280411, acc.: 49.22%] [G loss: 0.394736]\n",
      "epoch:27 step:25641 [D loss: 0.240659, acc.: 56.25%] [G loss: 0.458219]\n",
      "epoch:27 step:25642 [D loss: 0.239355, acc.: 62.50%] [G loss: 0.428215]\n",
      "epoch:27 step:25643 [D loss: 0.204716, acc.: 68.75%] [G loss: 0.458475]\n",
      "epoch:27 step:25644 [D loss: 0.206962, acc.: 68.75%] [G loss: 0.416760]\n",
      "epoch:27 step:25645 [D loss: 0.211461, acc.: 63.28%] [G loss: 0.445752]\n",
      "epoch:27 step:25646 [D loss: 0.158332, acc.: 77.34%] [G loss: 0.541995]\n",
      "epoch:27 step:25647 [D loss: 0.291217, acc.: 48.44%] [G loss: 0.445081]\n",
      "epoch:27 step:25648 [D loss: 0.291869, acc.: 43.75%] [G loss: 0.410623]\n",
      "epoch:27 step:25649 [D loss: 0.230196, acc.: 62.50%] [G loss: 0.422694]\n",
      "epoch:27 step:25650 [D loss: 0.223640, acc.: 67.19%] [G loss: 0.401349]\n",
      "epoch:27 step:25651 [D loss: 0.250792, acc.: 52.34%] [G loss: 0.429783]\n",
      "epoch:27 step:25652 [D loss: 0.213832, acc.: 66.41%] [G loss: 0.425459]\n",
      "epoch:27 step:25653 [D loss: 0.208892, acc.: 64.84%] [G loss: 0.464262]\n",
      "epoch:27 step:25654 [D loss: 0.227857, acc.: 61.72%] [G loss: 0.482142]\n",
      "epoch:27 step:25655 [D loss: 0.270406, acc.: 57.81%] [G loss: 0.445447]\n",
      "epoch:27 step:25656 [D loss: 0.197061, acc.: 68.75%] [G loss: 0.447152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25657 [D loss: 0.218726, acc.: 65.62%] [G loss: 0.445513]\n",
      "epoch:27 step:25658 [D loss: 0.202839, acc.: 73.44%] [G loss: 0.460722]\n",
      "epoch:27 step:25659 [D loss: 0.210474, acc.: 63.28%] [G loss: 0.484863]\n",
      "epoch:27 step:25660 [D loss: 0.195418, acc.: 67.97%] [G loss: 0.460787]\n",
      "epoch:27 step:25661 [D loss: 0.241559, acc.: 58.59%] [G loss: 0.454666]\n",
      "epoch:27 step:25662 [D loss: 0.216695, acc.: 61.72%] [G loss: 0.424857]\n",
      "epoch:27 step:25663 [D loss: 0.207726, acc.: 63.28%] [G loss: 0.397158]\n",
      "epoch:27 step:25664 [D loss: 0.221560, acc.: 57.81%] [G loss: 0.419377]\n",
      "epoch:27 step:25665 [D loss: 0.218599, acc.: 67.97%] [G loss: 0.426944]\n",
      "epoch:27 step:25666 [D loss: 0.222776, acc.: 67.97%] [G loss: 0.399749]\n",
      "epoch:27 step:25667 [D loss: 0.222580, acc.: 60.16%] [G loss: 0.406696]\n",
      "epoch:27 step:25668 [D loss: 0.216614, acc.: 65.62%] [G loss: 0.411868]\n",
      "epoch:27 step:25669 [D loss: 0.220590, acc.: 65.62%] [G loss: 0.426095]\n",
      "epoch:27 step:25670 [D loss: 0.189062, acc.: 72.66%] [G loss: 0.447609]\n",
      "epoch:27 step:25671 [D loss: 0.206303, acc.: 69.53%] [G loss: 0.451686]\n",
      "epoch:27 step:25672 [D loss: 0.246593, acc.: 56.25%] [G loss: 0.398614]\n",
      "epoch:27 step:25673 [D loss: 0.187254, acc.: 70.31%] [G loss: 0.447721]\n",
      "epoch:27 step:25674 [D loss: 0.235719, acc.: 58.59%] [G loss: 0.433335]\n",
      "epoch:27 step:25675 [D loss: 0.256570, acc.: 53.12%] [G loss: 0.418364]\n",
      "epoch:27 step:25676 [D loss: 0.250974, acc.: 60.16%] [G loss: 0.424690]\n",
      "epoch:27 step:25677 [D loss: 0.228975, acc.: 62.50%] [G loss: 0.383302]\n",
      "epoch:27 step:25678 [D loss: 0.254710, acc.: 56.25%] [G loss: 0.432771]\n",
      "epoch:27 step:25679 [D loss: 0.228504, acc.: 62.50%] [G loss: 0.424480]\n",
      "epoch:27 step:25680 [D loss: 0.203829, acc.: 67.19%] [G loss: 0.445449]\n",
      "epoch:27 step:25681 [D loss: 0.242669, acc.: 60.16%] [G loss: 0.423023]\n",
      "epoch:27 step:25682 [D loss: 0.255143, acc.: 50.78%] [G loss: 0.416134]\n",
      "epoch:27 step:25683 [D loss: 0.217648, acc.: 63.28%] [G loss: 0.396214]\n",
      "epoch:27 step:25684 [D loss: 0.192131, acc.: 75.00%] [G loss: 0.469213]\n",
      "epoch:27 step:25685 [D loss: 0.211305, acc.: 66.41%] [G loss: 0.455187]\n",
      "epoch:27 step:25686 [D loss: 0.220987, acc.: 60.16%] [G loss: 0.428905]\n",
      "epoch:27 step:25687 [D loss: 0.229595, acc.: 62.50%] [G loss: 0.438805]\n",
      "epoch:27 step:25688 [D loss: 0.226791, acc.: 67.97%] [G loss: 0.416518]\n",
      "epoch:27 step:25689 [D loss: 0.250458, acc.: 56.25%] [G loss: 0.410191]\n",
      "epoch:27 step:25690 [D loss: 0.217450, acc.: 65.62%] [G loss: 0.445998]\n",
      "epoch:27 step:25691 [D loss: 0.240743, acc.: 59.38%] [G loss: 0.439643]\n",
      "epoch:27 step:25692 [D loss: 0.215552, acc.: 64.84%] [G loss: 0.423519]\n",
      "epoch:27 step:25693 [D loss: 0.219160, acc.: 64.06%] [G loss: 0.408820]\n",
      "epoch:27 step:25694 [D loss: 0.224148, acc.: 62.50%] [G loss: 0.414340]\n",
      "epoch:27 step:25695 [D loss: 0.254215, acc.: 53.91%] [G loss: 0.404843]\n",
      "epoch:27 step:25696 [D loss: 0.234651, acc.: 60.16%] [G loss: 0.424797]\n",
      "epoch:27 step:25697 [D loss: 0.195832, acc.: 68.75%] [G loss: 0.438659]\n",
      "epoch:27 step:25698 [D loss: 0.194177, acc.: 68.75%] [G loss: 0.480090]\n",
      "epoch:27 step:25699 [D loss: 0.253917, acc.: 56.25%] [G loss: 0.449388]\n",
      "epoch:27 step:25700 [D loss: 0.222737, acc.: 61.72%] [G loss: 0.416508]\n",
      "epoch:27 step:25701 [D loss: 0.212013, acc.: 67.19%] [G loss: 0.428622]\n",
      "epoch:27 step:25702 [D loss: 0.248509, acc.: 61.72%] [G loss: 0.424139]\n",
      "epoch:27 step:25703 [D loss: 0.230263, acc.: 67.97%] [G loss: 0.428837]\n",
      "epoch:27 step:25704 [D loss: 0.200696, acc.: 69.53%] [G loss: 0.463601]\n",
      "epoch:27 step:25705 [D loss: 0.213327, acc.: 64.06%] [G loss: 0.478714]\n",
      "epoch:27 step:25706 [D loss: 0.238841, acc.: 57.81%] [G loss: 0.455868]\n",
      "epoch:27 step:25707 [D loss: 0.251931, acc.: 57.03%] [G loss: 0.422898]\n",
      "epoch:27 step:25708 [D loss: 0.216217, acc.: 68.75%] [G loss: 0.493403]\n",
      "epoch:27 step:25709 [D loss: 0.221511, acc.: 63.28%] [G loss: 0.452622]\n",
      "epoch:27 step:25710 [D loss: 0.271881, acc.: 46.09%] [G loss: 0.377508]\n",
      "epoch:27 step:25711 [D loss: 0.241937, acc.: 53.91%] [G loss: 0.391959]\n",
      "epoch:27 step:25712 [D loss: 0.233673, acc.: 60.16%] [G loss: 0.379383]\n",
      "epoch:27 step:25713 [D loss: 0.208075, acc.: 64.84%] [G loss: 0.449596]\n",
      "epoch:27 step:25714 [D loss: 0.184877, acc.: 75.00%] [G loss: 0.454622]\n",
      "epoch:27 step:25715 [D loss: 0.182976, acc.: 75.78%] [G loss: 0.486368]\n",
      "epoch:27 step:25716 [D loss: 0.211261, acc.: 67.97%] [G loss: 0.501414]\n",
      "epoch:27 step:25717 [D loss: 0.256354, acc.: 55.47%] [G loss: 0.436089]\n",
      "epoch:27 step:25718 [D loss: 0.246209, acc.: 52.34%] [G loss: 0.393103]\n",
      "epoch:27 step:25719 [D loss: 0.245203, acc.: 57.03%] [G loss: 0.395501]\n",
      "epoch:27 step:25720 [D loss: 0.236033, acc.: 57.81%] [G loss: 0.417614]\n",
      "epoch:27 step:25721 [D loss: 0.268669, acc.: 50.78%] [G loss: 0.412175]\n",
      "epoch:27 step:25722 [D loss: 0.242836, acc.: 57.81%] [G loss: 0.417278]\n",
      "epoch:27 step:25723 [D loss: 0.241830, acc.: 57.03%] [G loss: 0.399119]\n",
      "epoch:27 step:25724 [D loss: 0.224388, acc.: 63.28%] [G loss: 0.404943]\n",
      "epoch:27 step:25725 [D loss: 0.239176, acc.: 57.81%] [G loss: 0.403752]\n",
      "epoch:27 step:25726 [D loss: 0.195451, acc.: 72.66%] [G loss: 0.417367]\n",
      "epoch:27 step:25727 [D loss: 0.200910, acc.: 68.75%] [G loss: 0.445004]\n",
      "epoch:27 step:25728 [D loss: 0.189481, acc.: 69.53%] [G loss: 0.461595]\n",
      "epoch:27 step:25729 [D loss: 0.193248, acc.: 71.09%] [G loss: 0.476108]\n",
      "epoch:27 step:25730 [D loss: 0.235621, acc.: 61.72%] [G loss: 0.430477]\n",
      "epoch:27 step:25731 [D loss: 0.233888, acc.: 58.59%] [G loss: 0.441428]\n",
      "epoch:27 step:25732 [D loss: 0.200149, acc.: 69.53%] [G loss: 0.424304]\n",
      "epoch:27 step:25733 [D loss: 0.223456, acc.: 60.94%] [G loss: 0.398539]\n",
      "epoch:27 step:25734 [D loss: 0.202718, acc.: 71.09%] [G loss: 0.476788]\n",
      "epoch:27 step:25735 [D loss: 0.205973, acc.: 69.53%] [G loss: 0.467190]\n",
      "epoch:27 step:25736 [D loss: 0.288307, acc.: 46.09%] [G loss: 0.451536]\n",
      "epoch:27 step:25737 [D loss: 0.240033, acc.: 59.38%] [G loss: 0.400791]\n",
      "epoch:27 step:25738 [D loss: 0.207824, acc.: 67.19%] [G loss: 0.445130]\n",
      "epoch:27 step:25739 [D loss: 0.230277, acc.: 63.28%] [G loss: 0.410888]\n",
      "epoch:27 step:25740 [D loss: 0.209510, acc.: 64.06%] [G loss: 0.435382]\n",
      "epoch:27 step:25741 [D loss: 0.239984, acc.: 60.94%] [G loss: 0.425954]\n",
      "epoch:27 step:25742 [D loss: 0.224469, acc.: 69.53%] [G loss: 0.408100]\n",
      "epoch:27 step:25743 [D loss: 0.235362, acc.: 61.72%] [G loss: 0.411614]\n",
      "epoch:27 step:25744 [D loss: 0.210213, acc.: 64.06%] [G loss: 0.473448]\n",
      "epoch:27 step:25745 [D loss: 0.229368, acc.: 63.28%] [G loss: 0.472513]\n",
      "epoch:27 step:25746 [D loss: 0.220523, acc.: 64.06%] [G loss: 0.427613]\n",
      "epoch:27 step:25747 [D loss: 0.240402, acc.: 61.72%] [G loss: 0.466424]\n",
      "epoch:27 step:25748 [D loss: 0.241327, acc.: 62.50%] [G loss: 0.451206]\n",
      "epoch:27 step:25749 [D loss: 0.216268, acc.: 67.97%] [G loss: 0.399786]\n",
      "epoch:27 step:25750 [D loss: 0.201346, acc.: 71.09%] [G loss: 0.398414]\n",
      "epoch:27 step:25751 [D loss: 0.213240, acc.: 66.41%] [G loss: 0.448553]\n",
      "epoch:27 step:25752 [D loss: 0.205157, acc.: 64.06%] [G loss: 0.426280]\n",
      "epoch:27 step:25753 [D loss: 0.213342, acc.: 65.62%] [G loss: 0.430666]\n",
      "epoch:27 step:25754 [D loss: 0.229558, acc.: 60.94%] [G loss: 0.405819]\n",
      "epoch:27 step:25755 [D loss: 0.221761, acc.: 53.91%] [G loss: 0.415116]\n",
      "epoch:27 step:25756 [D loss: 0.212544, acc.: 64.06%] [G loss: 0.479214]\n",
      "epoch:27 step:25757 [D loss: 0.278293, acc.: 50.78%] [G loss: 0.441084]\n",
      "epoch:27 step:25758 [D loss: 0.244996, acc.: 57.81%] [G loss: 0.447114]\n",
      "epoch:27 step:25759 [D loss: 0.246733, acc.: 57.03%] [G loss: 0.417075]\n",
      "epoch:27 step:25760 [D loss: 0.214672, acc.: 70.31%] [G loss: 0.388758]\n",
      "epoch:27 step:25761 [D loss: 0.232712, acc.: 60.16%] [G loss: 0.407978]\n",
      "epoch:27 step:25762 [D loss: 0.242031, acc.: 56.25%] [G loss: 0.379609]\n",
      "epoch:27 step:25763 [D loss: 0.208254, acc.: 67.19%] [G loss: 0.440991]\n",
      "epoch:27 step:25764 [D loss: 0.226133, acc.: 64.84%] [G loss: 0.454358]\n",
      "epoch:27 step:25765 [D loss: 0.232458, acc.: 57.81%] [G loss: 0.430328]\n",
      "epoch:27 step:25766 [D loss: 0.221561, acc.: 59.38%] [G loss: 0.419312]\n",
      "epoch:27 step:25767 [D loss: 0.205458, acc.: 63.28%] [G loss: 0.461352]\n",
      "epoch:27 step:25768 [D loss: 0.198833, acc.: 64.84%] [G loss: 0.457940]\n",
      "epoch:27 step:25769 [D loss: 0.212412, acc.: 70.31%] [G loss: 0.478876]\n",
      "epoch:27 step:25770 [D loss: 0.211146, acc.: 70.31%] [G loss: 0.475891]\n",
      "epoch:27 step:25771 [D loss: 0.227391, acc.: 65.62%] [G loss: 0.457401]\n",
      "epoch:27 step:25772 [D loss: 0.243584, acc.: 56.25%] [G loss: 0.471743]\n",
      "epoch:27 step:25773 [D loss: 0.219693, acc.: 63.28%] [G loss: 0.437310]\n",
      "epoch:27 step:25774 [D loss: 0.203052, acc.: 71.88%] [G loss: 0.442132]\n",
      "epoch:27 step:25775 [D loss: 0.229554, acc.: 65.62%] [G loss: 0.447523]\n",
      "epoch:27 step:25776 [D loss: 0.258489, acc.: 51.56%] [G loss: 0.416155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25777 [D loss: 0.242809, acc.: 60.94%] [G loss: 0.388368]\n",
      "epoch:27 step:25778 [D loss: 0.206080, acc.: 67.97%] [G loss: 0.429195]\n",
      "epoch:27 step:25779 [D loss: 0.212871, acc.: 64.06%] [G loss: 0.450891]\n",
      "epoch:27 step:25780 [D loss: 0.164464, acc.: 75.00%] [G loss: 0.459216]\n",
      "epoch:27 step:25781 [D loss: 0.250978, acc.: 50.00%] [G loss: 0.423375]\n",
      "epoch:27 step:25782 [D loss: 0.220333, acc.: 62.50%] [G loss: 0.417914]\n",
      "epoch:27 step:25783 [D loss: 0.209932, acc.: 69.53%] [G loss: 0.443857]\n",
      "epoch:27 step:25784 [D loss: 0.217484, acc.: 67.97%] [G loss: 0.470860]\n",
      "epoch:27 step:25785 [D loss: 0.238087, acc.: 56.25%] [G loss: 0.416208]\n",
      "epoch:27 step:25786 [D loss: 0.224006, acc.: 63.28%] [G loss: 0.440435]\n",
      "epoch:27 step:25787 [D loss: 0.200276, acc.: 70.31%] [G loss: 0.410777]\n",
      "epoch:27 step:25788 [D loss: 0.235002, acc.: 60.16%] [G loss: 0.433690]\n",
      "epoch:27 step:25789 [D loss: 0.228336, acc.: 60.16%] [G loss: 0.425978]\n",
      "epoch:27 step:25790 [D loss: 0.232322, acc.: 60.16%] [G loss: 0.431752]\n",
      "epoch:27 step:25791 [D loss: 0.217959, acc.: 64.06%] [G loss: 0.424602]\n",
      "epoch:27 step:25792 [D loss: 0.221378, acc.: 64.06%] [G loss: 0.402961]\n",
      "epoch:27 step:25793 [D loss: 0.217822, acc.: 67.19%] [G loss: 0.413611]\n",
      "epoch:27 step:25794 [D loss: 0.185693, acc.: 73.44%] [G loss: 0.498437]\n",
      "epoch:27 step:25795 [D loss: 0.201435, acc.: 65.62%] [G loss: 0.497570]\n",
      "epoch:27 step:25796 [D loss: 0.240386, acc.: 60.94%] [G loss: 0.427291]\n",
      "epoch:27 step:25797 [D loss: 0.195349, acc.: 70.31%] [G loss: 0.486552]\n",
      "epoch:27 step:25798 [D loss: 0.181659, acc.: 73.44%] [G loss: 0.456707]\n",
      "epoch:27 step:25799 [D loss: 0.246176, acc.: 56.25%] [G loss: 0.407790]\n",
      "epoch:27 step:25800 [D loss: 0.286923, acc.: 45.31%] [G loss: 0.399775]\n",
      "epoch:27 step:25801 [D loss: 0.248782, acc.: 59.38%] [G loss: 0.403687]\n",
      "epoch:27 step:25802 [D loss: 0.222247, acc.: 63.28%] [G loss: 0.400741]\n",
      "epoch:27 step:25803 [D loss: 0.202073, acc.: 69.53%] [G loss: 0.427033]\n",
      "epoch:27 step:25804 [D loss: 0.192982, acc.: 75.00%] [G loss: 0.468425]\n",
      "epoch:27 step:25805 [D loss: 0.200759, acc.: 66.41%] [G loss: 0.443879]\n",
      "epoch:27 step:25806 [D loss: 0.213272, acc.: 63.28%] [G loss: 0.449281]\n",
      "epoch:27 step:25807 [D loss: 0.184190, acc.: 74.22%] [G loss: 0.515570]\n",
      "epoch:27 step:25808 [D loss: 0.256373, acc.: 57.03%] [G loss: 0.421603]\n",
      "epoch:27 step:25809 [D loss: 0.230859, acc.: 63.28%] [G loss: 0.395160]\n",
      "epoch:27 step:25810 [D loss: 0.235663, acc.: 57.03%] [G loss: 0.434011]\n",
      "epoch:27 step:25811 [D loss: 0.242182, acc.: 60.94%] [G loss: 0.394304]\n",
      "epoch:27 step:25812 [D loss: 0.186071, acc.: 75.00%] [G loss: 0.419918]\n",
      "epoch:27 step:25813 [D loss: 0.232689, acc.: 57.03%] [G loss: 0.427845]\n",
      "epoch:27 step:25814 [D loss: 0.205222, acc.: 70.31%] [G loss: 0.413386]\n",
      "epoch:27 step:25815 [D loss: 0.185115, acc.: 70.31%] [G loss: 0.480210]\n",
      "epoch:27 step:25816 [D loss: 0.249876, acc.: 57.03%] [G loss: 0.405445]\n",
      "epoch:27 step:25817 [D loss: 0.231292, acc.: 59.38%] [G loss: 0.438247]\n",
      "epoch:27 step:25818 [D loss: 0.200497, acc.: 71.09%] [G loss: 0.449083]\n",
      "epoch:27 step:25819 [D loss: 0.223499, acc.: 60.94%] [G loss: 0.402590]\n",
      "epoch:27 step:25820 [D loss: 0.201168, acc.: 65.62%] [G loss: 0.440631]\n",
      "epoch:27 step:25821 [D loss: 0.220354, acc.: 64.84%] [G loss: 0.441423]\n",
      "epoch:27 step:25822 [D loss: 0.197319, acc.: 68.75%] [G loss: 0.440357]\n",
      "epoch:27 step:25823 [D loss: 0.223343, acc.: 64.06%] [G loss: 0.406356]\n",
      "epoch:27 step:25824 [D loss: 0.211272, acc.: 67.19%] [G loss: 0.497876]\n",
      "epoch:27 step:25825 [D loss: 0.205613, acc.: 68.75%] [G loss: 0.461758]\n",
      "epoch:27 step:25826 [D loss: 0.209911, acc.: 69.53%] [G loss: 0.469907]\n",
      "epoch:27 step:25827 [D loss: 0.269193, acc.: 50.00%] [G loss: 0.392288]\n",
      "epoch:27 step:25828 [D loss: 0.261003, acc.: 51.56%] [G loss: 0.424605]\n",
      "epoch:27 step:25829 [D loss: 0.216056, acc.: 66.41%] [G loss: 0.453473]\n",
      "epoch:27 step:25830 [D loss: 0.256343, acc.: 51.56%] [G loss: 0.430198]\n",
      "epoch:27 step:25831 [D loss: 0.226102, acc.: 57.81%] [G loss: 0.422961]\n",
      "epoch:27 step:25832 [D loss: 0.221962, acc.: 63.28%] [G loss: 0.439368]\n",
      "epoch:27 step:25833 [D loss: 0.209358, acc.: 68.75%] [G loss: 0.468724]\n",
      "epoch:27 step:25834 [D loss: 0.231639, acc.: 61.72%] [G loss: 0.459842]\n",
      "epoch:27 step:25835 [D loss: 0.225232, acc.: 64.06%] [G loss: 0.441771]\n",
      "epoch:27 step:25836 [D loss: 0.222653, acc.: 64.06%] [G loss: 0.405350]\n",
      "epoch:27 step:25837 [D loss: 0.228620, acc.: 64.06%] [G loss: 0.395714]\n",
      "epoch:27 step:25838 [D loss: 0.228008, acc.: 60.94%] [G loss: 0.422478]\n",
      "epoch:27 step:25839 [D loss: 0.246704, acc.: 55.47%] [G loss: 0.399342]\n",
      "epoch:27 step:25840 [D loss: 0.227384, acc.: 61.72%] [G loss: 0.406888]\n",
      "epoch:27 step:25841 [D loss: 0.250940, acc.: 53.12%] [G loss: 0.400157]\n",
      "epoch:27 step:25842 [D loss: 0.236899, acc.: 57.03%] [G loss: 0.414083]\n",
      "epoch:27 step:25843 [D loss: 0.222754, acc.: 62.50%] [G loss: 0.434868]\n",
      "epoch:27 step:25844 [D loss: 0.227338, acc.: 70.31%] [G loss: 0.436370]\n",
      "epoch:27 step:25845 [D loss: 0.203027, acc.: 67.19%] [G loss: 0.462915]\n",
      "epoch:27 step:25846 [D loss: 0.217961, acc.: 70.31%] [G loss: 0.449775]\n",
      "epoch:27 step:25847 [D loss: 0.199263, acc.: 73.44%] [G loss: 0.444820]\n",
      "epoch:27 step:25848 [D loss: 0.209622, acc.: 63.28%] [G loss: 0.418207]\n",
      "epoch:27 step:25849 [D loss: 0.172376, acc.: 79.69%] [G loss: 0.479291]\n",
      "epoch:27 step:25850 [D loss: 0.202220, acc.: 71.09%] [G loss: 0.469266]\n",
      "epoch:27 step:25851 [D loss: 0.222160, acc.: 62.50%] [G loss: 0.454351]\n",
      "epoch:27 step:25852 [D loss: 0.227740, acc.: 67.97%] [G loss: 0.490648]\n",
      "epoch:27 step:25853 [D loss: 0.184075, acc.: 67.97%] [G loss: 0.465147]\n",
      "epoch:27 step:25854 [D loss: 0.216107, acc.: 64.84%] [G loss: 0.453931]\n",
      "epoch:27 step:25855 [D loss: 0.197769, acc.: 67.19%] [G loss: 0.472677]\n",
      "epoch:27 step:25856 [D loss: 0.204151, acc.: 71.09%] [G loss: 0.459621]\n",
      "epoch:27 step:25857 [D loss: 0.214665, acc.: 64.06%] [G loss: 0.416269]\n",
      "epoch:27 step:25858 [D loss: 0.255530, acc.: 55.47%] [G loss: 0.445015]\n",
      "epoch:27 step:25859 [D loss: 0.240430, acc.: 57.03%] [G loss: 0.422096]\n",
      "epoch:27 step:25860 [D loss: 0.198635, acc.: 70.31%] [G loss: 0.484233]\n",
      "epoch:27 step:25861 [D loss: 0.219418, acc.: 60.94%] [G loss: 0.435227]\n",
      "epoch:27 step:25862 [D loss: 0.196304, acc.: 70.31%] [G loss: 0.452308]\n",
      "epoch:27 step:25863 [D loss: 0.214167, acc.: 67.97%] [G loss: 0.441955]\n",
      "epoch:27 step:25864 [D loss: 0.243345, acc.: 57.81%] [G loss: 0.479371]\n",
      "epoch:27 step:25865 [D loss: 0.265610, acc.: 57.03%] [G loss: 0.423534]\n",
      "epoch:27 step:25866 [D loss: 0.208970, acc.: 65.62%] [G loss: 0.430551]\n",
      "epoch:27 step:25867 [D loss: 0.216753, acc.: 67.19%] [G loss: 0.422069]\n",
      "epoch:27 step:25868 [D loss: 0.237076, acc.: 57.03%] [G loss: 0.423560]\n",
      "epoch:27 step:25869 [D loss: 0.222188, acc.: 59.38%] [G loss: 0.391232]\n",
      "epoch:27 step:25870 [D loss: 0.218108, acc.: 64.84%] [G loss: 0.401680]\n",
      "epoch:27 step:25871 [D loss: 0.235306, acc.: 55.47%] [G loss: 0.433856]\n",
      "epoch:27 step:25872 [D loss: 0.256281, acc.: 54.69%] [G loss: 0.435642]\n",
      "epoch:27 step:25873 [D loss: 0.203366, acc.: 68.75%] [G loss: 0.448973]\n",
      "epoch:27 step:25874 [D loss: 0.194027, acc.: 70.31%] [G loss: 0.499225]\n",
      "epoch:27 step:25875 [D loss: 0.229293, acc.: 61.72%] [G loss: 0.416633]\n",
      "epoch:27 step:25876 [D loss: 0.234111, acc.: 59.38%] [G loss: 0.433613]\n",
      "epoch:27 step:25877 [D loss: 0.220567, acc.: 64.06%] [G loss: 0.440488]\n",
      "epoch:27 step:25878 [D loss: 0.240007, acc.: 57.81%] [G loss: 0.382799]\n",
      "epoch:27 step:25879 [D loss: 0.224172, acc.: 66.41%] [G loss: 0.427913]\n",
      "epoch:27 step:25880 [D loss: 0.189838, acc.: 74.22%] [G loss: 0.401474]\n",
      "epoch:27 step:25881 [D loss: 0.217054, acc.: 64.06%] [G loss: 0.429495]\n",
      "epoch:27 step:25882 [D loss: 0.213870, acc.: 62.50%] [G loss: 0.502541]\n",
      "epoch:27 step:25883 [D loss: 0.228419, acc.: 60.16%] [G loss: 0.454390]\n",
      "epoch:27 step:25884 [D loss: 0.229631, acc.: 60.94%] [G loss: 0.426673]\n",
      "epoch:27 step:25885 [D loss: 0.197322, acc.: 70.31%] [G loss: 0.452534]\n",
      "epoch:27 step:25886 [D loss: 0.227139, acc.: 59.38%] [G loss: 0.444300]\n",
      "epoch:27 step:25887 [D loss: 0.204975, acc.: 64.06%] [G loss: 0.434251]\n",
      "epoch:27 step:25888 [D loss: 0.197568, acc.: 71.88%] [G loss: 0.426561]\n",
      "epoch:27 step:25889 [D loss: 0.262474, acc.: 50.78%] [G loss: 0.436911]\n",
      "epoch:27 step:25890 [D loss: 0.249336, acc.: 57.81%] [G loss: 0.384808]\n",
      "epoch:27 step:25891 [D loss: 0.211960, acc.: 65.62%] [G loss: 0.401762]\n",
      "epoch:27 step:25892 [D loss: 0.208829, acc.: 67.97%] [G loss: 0.413994]\n",
      "epoch:27 step:25893 [D loss: 0.243083, acc.: 54.69%] [G loss: 0.393045]\n",
      "epoch:27 step:25894 [D loss: 0.205997, acc.: 65.62%] [G loss: 0.459128]\n",
      "epoch:27 step:25895 [D loss: 0.224226, acc.: 63.28%] [G loss: 0.450640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25896 [D loss: 0.250139, acc.: 56.25%] [G loss: 0.385969]\n",
      "epoch:27 step:25897 [D loss: 0.212582, acc.: 65.62%] [G loss: 0.413562]\n",
      "epoch:27 step:25898 [D loss: 0.232126, acc.: 60.16%] [G loss: 0.415531]\n",
      "epoch:27 step:25899 [D loss: 0.234533, acc.: 61.72%] [G loss: 0.428752]\n",
      "epoch:27 step:25900 [D loss: 0.218085, acc.: 64.06%] [G loss: 0.437012]\n",
      "epoch:27 step:25901 [D loss: 0.244765, acc.: 60.16%] [G loss: 0.385774]\n",
      "epoch:27 step:25902 [D loss: 0.236783, acc.: 61.72%] [G loss: 0.377395]\n",
      "epoch:27 step:25903 [D loss: 0.211326, acc.: 67.19%] [G loss: 0.427415]\n",
      "epoch:27 step:25904 [D loss: 0.196268, acc.: 71.09%] [G loss: 0.422880]\n",
      "epoch:27 step:25905 [D loss: 0.242409, acc.: 60.94%] [G loss: 0.409212]\n",
      "epoch:27 step:25906 [D loss: 0.226291, acc.: 66.41%] [G loss: 0.427719]\n",
      "epoch:27 step:25907 [D loss: 0.248594, acc.: 55.47%] [G loss: 0.410283]\n",
      "epoch:27 step:25908 [D loss: 0.224718, acc.: 61.72%] [G loss: 0.418857]\n",
      "epoch:27 step:25909 [D loss: 0.230276, acc.: 61.72%] [G loss: 0.418012]\n",
      "epoch:27 step:25910 [D loss: 0.238931, acc.: 56.25%] [G loss: 0.399335]\n",
      "epoch:27 step:25911 [D loss: 0.212865, acc.: 66.41%] [G loss: 0.409153]\n",
      "epoch:27 step:25912 [D loss: 0.213265, acc.: 67.19%] [G loss: 0.424927]\n",
      "epoch:27 step:25913 [D loss: 0.263635, acc.: 50.78%] [G loss: 0.401514]\n",
      "epoch:27 step:25914 [D loss: 0.253128, acc.: 47.66%] [G loss: 0.385482]\n",
      "epoch:27 step:25915 [D loss: 0.243711, acc.: 61.72%] [G loss: 0.408192]\n",
      "epoch:27 step:25916 [D loss: 0.203082, acc.: 67.97%] [G loss: 0.456241]\n",
      "epoch:27 step:25917 [D loss: 0.206497, acc.: 64.84%] [G loss: 0.449732]\n",
      "epoch:27 step:25918 [D loss: 0.245526, acc.: 56.25%] [G loss: 0.407857]\n",
      "epoch:27 step:25919 [D loss: 0.203575, acc.: 68.75%] [G loss: 0.476565]\n",
      "epoch:27 step:25920 [D loss: 0.214758, acc.: 64.84%] [G loss: 0.391041]\n",
      "epoch:27 step:25921 [D loss: 0.233384, acc.: 58.59%] [G loss: 0.405036]\n",
      "epoch:27 step:25922 [D loss: 0.219149, acc.: 60.94%] [G loss: 0.393580]\n",
      "epoch:27 step:25923 [D loss: 0.175897, acc.: 72.66%] [G loss: 0.463416]\n",
      "epoch:27 step:25924 [D loss: 0.254416, acc.: 57.81%] [G loss: 0.425703]\n",
      "epoch:27 step:25925 [D loss: 0.254198, acc.: 53.91%] [G loss: 0.412076]\n",
      "epoch:27 step:25926 [D loss: 0.217813, acc.: 63.28%] [G loss: 0.454230]\n",
      "epoch:27 step:25927 [D loss: 0.244254, acc.: 59.38%] [G loss: 0.429642]\n",
      "epoch:27 step:25928 [D loss: 0.230001, acc.: 60.94%] [G loss: 0.458802]\n",
      "epoch:27 step:25929 [D loss: 0.206968, acc.: 67.97%] [G loss: 0.450606]\n",
      "epoch:27 step:25930 [D loss: 0.213243, acc.: 63.28%] [G loss: 0.408467]\n",
      "epoch:27 step:25931 [D loss: 0.190102, acc.: 75.00%] [G loss: 0.475404]\n",
      "epoch:27 step:25932 [D loss: 0.222873, acc.: 55.47%] [G loss: 0.436917]\n",
      "epoch:27 step:25933 [D loss: 0.198303, acc.: 71.88%] [G loss: 0.426512]\n",
      "epoch:27 step:25934 [D loss: 0.227258, acc.: 67.97%] [G loss: 0.429684]\n",
      "epoch:27 step:25935 [D loss: 0.220626, acc.: 64.06%] [G loss: 0.439114]\n",
      "epoch:27 step:25936 [D loss: 0.201766, acc.: 71.88%] [G loss: 0.452005]\n",
      "epoch:27 step:25937 [D loss: 0.223593, acc.: 60.16%] [G loss: 0.412823]\n",
      "epoch:27 step:25938 [D loss: 0.241528, acc.: 57.81%] [G loss: 0.410526]\n",
      "epoch:27 step:25939 [D loss: 0.211500, acc.: 64.06%] [G loss: 0.451455]\n",
      "epoch:27 step:25940 [D loss: 0.212915, acc.: 70.31%] [G loss: 0.442553]\n",
      "epoch:27 step:25941 [D loss: 0.187773, acc.: 68.75%] [G loss: 0.527806]\n",
      "epoch:27 step:25942 [D loss: 0.235282, acc.: 63.28%] [G loss: 0.475856]\n",
      "epoch:27 step:25943 [D loss: 0.266013, acc.: 50.78%] [G loss: 0.394460]\n",
      "epoch:27 step:25944 [D loss: 0.223676, acc.: 67.97%] [G loss: 0.430934]\n",
      "epoch:27 step:25945 [D loss: 0.219804, acc.: 54.69%] [G loss: 0.420646]\n",
      "epoch:27 step:25946 [D loss: 0.190607, acc.: 74.22%] [G loss: 0.474822]\n",
      "epoch:27 step:25947 [D loss: 0.184059, acc.: 76.56%] [G loss: 0.501447]\n",
      "epoch:27 step:25948 [D loss: 0.188206, acc.: 69.53%] [G loss: 0.497191]\n",
      "epoch:27 step:25949 [D loss: 0.219649, acc.: 64.84%] [G loss: 0.450675]\n",
      "epoch:27 step:25950 [D loss: 0.212669, acc.: 60.16%] [G loss: 0.455033]\n",
      "epoch:27 step:25951 [D loss: 0.213607, acc.: 65.62%] [G loss: 0.442876]\n",
      "epoch:27 step:25952 [D loss: 0.225283, acc.: 64.84%] [G loss: 0.442332]\n",
      "epoch:27 step:25953 [D loss: 0.194179, acc.: 71.09%] [G loss: 0.473096]\n",
      "epoch:27 step:25954 [D loss: 0.240551, acc.: 59.38%] [G loss: 0.427702]\n",
      "epoch:27 step:25955 [D loss: 0.222774, acc.: 62.50%] [G loss: 0.440599]\n",
      "epoch:27 step:25956 [D loss: 0.228984, acc.: 62.50%] [G loss: 0.429517]\n",
      "epoch:27 step:25957 [D loss: 0.244110, acc.: 54.69%] [G loss: 0.455053]\n",
      "epoch:27 step:25958 [D loss: 0.244255, acc.: 56.25%] [G loss: 0.424162]\n",
      "epoch:27 step:25959 [D loss: 0.199920, acc.: 70.31%] [G loss: 0.421904]\n",
      "epoch:27 step:25960 [D loss: 0.206977, acc.: 69.53%] [G loss: 0.454934]\n",
      "epoch:27 step:25961 [D loss: 0.206362, acc.: 66.41%] [G loss: 0.412473]\n",
      "epoch:27 step:25962 [D loss: 0.225517, acc.: 64.06%] [G loss: 0.424279]\n",
      "epoch:27 step:25963 [D loss: 0.242496, acc.: 57.81%] [G loss: 0.483328]\n",
      "epoch:27 step:25964 [D loss: 0.251516, acc.: 55.47%] [G loss: 0.414363]\n",
      "epoch:27 step:25965 [D loss: 0.207503, acc.: 67.19%] [G loss: 0.440132]\n",
      "epoch:27 step:25966 [D loss: 0.179620, acc.: 78.12%] [G loss: 0.504327]\n",
      "epoch:27 step:25967 [D loss: 0.224478, acc.: 63.28%] [G loss: 0.412197]\n",
      "epoch:27 step:25968 [D loss: 0.219468, acc.: 65.62%] [G loss: 0.429651]\n",
      "epoch:27 step:25969 [D loss: 0.262364, acc.: 53.91%] [G loss: 0.407305]\n",
      "epoch:27 step:25970 [D loss: 0.229109, acc.: 64.06%] [G loss: 0.406503]\n",
      "epoch:27 step:25971 [D loss: 0.218429, acc.: 63.28%] [G loss: 0.456948]\n",
      "epoch:27 step:25972 [D loss: 0.221630, acc.: 60.94%] [G loss: 0.426975]\n",
      "epoch:27 step:25973 [D loss: 0.214326, acc.: 69.53%] [G loss: 0.429775]\n",
      "epoch:27 step:25974 [D loss: 0.243795, acc.: 57.81%] [G loss: 0.410211]\n",
      "epoch:27 step:25975 [D loss: 0.231311, acc.: 64.06%] [G loss: 0.392867]\n",
      "epoch:27 step:25976 [D loss: 0.198562, acc.: 70.31%] [G loss: 0.421608]\n",
      "epoch:27 step:25977 [D loss: 0.197853, acc.: 71.88%] [G loss: 0.421052]\n",
      "epoch:27 step:25978 [D loss: 0.209109, acc.: 64.84%] [G loss: 0.460339]\n",
      "epoch:27 step:25979 [D loss: 0.229813, acc.: 60.94%] [G loss: 0.442328]\n",
      "epoch:27 step:25980 [D loss: 0.193081, acc.: 69.53%] [G loss: 0.454626]\n",
      "epoch:27 step:25981 [D loss: 0.245745, acc.: 53.12%] [G loss: 0.456121]\n",
      "epoch:27 step:25982 [D loss: 0.233390, acc.: 58.59%] [G loss: 0.395317]\n",
      "epoch:27 step:25983 [D loss: 0.230897, acc.: 57.03%] [G loss: 0.385158]\n",
      "epoch:27 step:25984 [D loss: 0.221295, acc.: 60.16%] [G loss: 0.411329]\n",
      "epoch:27 step:25985 [D loss: 0.227268, acc.: 61.72%] [G loss: 0.450484]\n",
      "epoch:27 step:25986 [D loss: 0.243412, acc.: 57.81%] [G loss: 0.418579]\n",
      "epoch:27 step:25987 [D loss: 0.199077, acc.: 66.41%] [G loss: 0.463859]\n",
      "epoch:27 step:25988 [D loss: 0.205267, acc.: 66.41%] [G loss: 0.408812]\n",
      "epoch:27 step:25989 [D loss: 0.215447, acc.: 66.41%] [G loss: 0.438252]\n",
      "epoch:27 step:25990 [D loss: 0.201863, acc.: 65.62%] [G loss: 0.442759]\n",
      "epoch:27 step:25991 [D loss: 0.218233, acc.: 63.28%] [G loss: 0.437143]\n",
      "epoch:27 step:25992 [D loss: 0.202068, acc.: 66.41%] [G loss: 0.483732]\n",
      "epoch:27 step:25993 [D loss: 0.219128, acc.: 63.28%] [G loss: 0.475902]\n",
      "epoch:27 step:25994 [D loss: 0.203815, acc.: 67.97%] [G loss: 0.517333]\n",
      "epoch:27 step:25995 [D loss: 0.260749, acc.: 54.69%] [G loss: 0.429389]\n",
      "epoch:27 step:25996 [D loss: 0.230779, acc.: 57.81%] [G loss: 0.432169]\n",
      "epoch:27 step:25997 [D loss: 0.250744, acc.: 53.91%] [G loss: 0.419781]\n",
      "epoch:27 step:25998 [D loss: 0.206332, acc.: 67.19%] [G loss: 0.438541]\n",
      "epoch:27 step:25999 [D loss: 0.215831, acc.: 63.28%] [G loss: 0.441315]\n",
      "epoch:27 step:26000 [D loss: 0.207013, acc.: 65.62%] [G loss: 0.444106]\n",
      "epoch:27 step:26001 [D loss: 0.257964, acc.: 55.47%] [G loss: 0.440578]\n",
      "epoch:27 step:26002 [D loss: 0.255515, acc.: 53.12%] [G loss: 0.423181]\n",
      "epoch:27 step:26003 [D loss: 0.251392, acc.: 57.81%] [G loss: 0.429502]\n",
      "epoch:27 step:26004 [D loss: 0.211544, acc.: 67.19%] [G loss: 0.436396]\n",
      "epoch:27 step:26005 [D loss: 0.226675, acc.: 58.59%] [G loss: 0.397804]\n",
      "epoch:27 step:26006 [D loss: 0.200150, acc.: 62.50%] [G loss: 0.438430]\n",
      "epoch:27 step:26007 [D loss: 0.195725, acc.: 74.22%] [G loss: 0.477438]\n",
      "epoch:27 step:26008 [D loss: 0.221954, acc.: 63.28%] [G loss: 0.434191]\n",
      "epoch:27 step:26009 [D loss: 0.218258, acc.: 61.72%] [G loss: 0.440760]\n",
      "epoch:27 step:26010 [D loss: 0.211908, acc.: 64.06%] [G loss: 0.430820]\n",
      "epoch:27 step:26011 [D loss: 0.219673, acc.: 58.59%] [G loss: 0.450619]\n",
      "epoch:27 step:26012 [D loss: 0.220374, acc.: 66.41%] [G loss: 0.467100]\n",
      "epoch:27 step:26013 [D loss: 0.210916, acc.: 67.97%] [G loss: 0.465806]\n",
      "epoch:27 step:26014 [D loss: 0.222933, acc.: 59.38%] [G loss: 0.439386]\n",
      "epoch:27 step:26015 [D loss: 0.255477, acc.: 55.47%] [G loss: 0.426389]\n",
      "epoch:27 step:26016 [D loss: 0.217234, acc.: 70.31%] [G loss: 0.436036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26017 [D loss: 0.201917, acc.: 70.31%] [G loss: 0.487512]\n",
      "epoch:27 step:26018 [D loss: 0.220491, acc.: 64.84%] [G loss: 0.447306]\n",
      "epoch:27 step:26019 [D loss: 0.214474, acc.: 65.62%] [G loss: 0.470617]\n",
      "epoch:27 step:26020 [D loss: 0.237363, acc.: 52.34%] [G loss: 0.443454]\n",
      "epoch:27 step:26021 [D loss: 0.220826, acc.: 64.06%] [G loss: 0.410267]\n",
      "epoch:27 step:26022 [D loss: 0.223791, acc.: 61.72%] [G loss: 0.415235]\n",
      "epoch:27 step:26023 [D loss: 0.217915, acc.: 62.50%] [G loss: 0.451150]\n",
      "epoch:27 step:26024 [D loss: 0.209964, acc.: 71.09%] [G loss: 0.481663]\n",
      "epoch:27 step:26025 [D loss: 0.218049, acc.: 64.06%] [G loss: 0.433984]\n",
      "epoch:27 step:26026 [D loss: 0.252017, acc.: 55.47%] [G loss: 0.437370]\n",
      "epoch:27 step:26027 [D loss: 0.222937, acc.: 64.06%] [G loss: 0.430983]\n",
      "epoch:27 step:26028 [D loss: 0.226156, acc.: 62.50%] [G loss: 0.403566]\n",
      "epoch:27 step:26029 [D loss: 0.219604, acc.: 61.72%] [G loss: 0.420342]\n",
      "epoch:27 step:26030 [D loss: 0.232132, acc.: 59.38%] [G loss: 0.420739]\n",
      "epoch:27 step:26031 [D loss: 0.190934, acc.: 68.75%] [G loss: 0.485785]\n",
      "epoch:27 step:26032 [D loss: 0.203578, acc.: 69.53%] [G loss: 0.424761]\n",
      "epoch:27 step:26033 [D loss: 0.241157, acc.: 61.72%] [G loss: 0.403143]\n",
      "epoch:27 step:26034 [D loss: 0.242137, acc.: 59.38%] [G loss: 0.409452]\n",
      "epoch:27 step:26035 [D loss: 0.218838, acc.: 62.50%] [G loss: 0.454227]\n",
      "epoch:27 step:26036 [D loss: 0.204625, acc.: 67.19%] [G loss: 0.441406]\n",
      "epoch:27 step:26037 [D loss: 0.252410, acc.: 54.69%] [G loss: 0.416166]\n",
      "epoch:27 step:26038 [D loss: 0.258778, acc.: 53.91%] [G loss: 0.397106]\n",
      "epoch:27 step:26039 [D loss: 0.235930, acc.: 55.47%] [G loss: 0.436722]\n",
      "epoch:27 step:26040 [D loss: 0.248546, acc.: 53.91%] [G loss: 0.395753]\n",
      "epoch:27 step:26041 [D loss: 0.256619, acc.: 53.12%] [G loss: 0.437435]\n",
      "epoch:27 step:26042 [D loss: 0.206562, acc.: 64.84%] [G loss: 0.480057]\n",
      "epoch:27 step:26043 [D loss: 0.236314, acc.: 61.72%] [G loss: 0.398695]\n",
      "epoch:27 step:26044 [D loss: 0.228305, acc.: 59.38%] [G loss: 0.417460]\n",
      "epoch:27 step:26045 [D loss: 0.220493, acc.: 65.62%] [G loss: 0.418084]\n",
      "epoch:27 step:26046 [D loss: 0.216521, acc.: 62.50%] [G loss: 0.388924]\n",
      "epoch:27 step:26047 [D loss: 0.219849, acc.: 63.28%] [G loss: 0.448558]\n",
      "epoch:27 step:26048 [D loss: 0.223271, acc.: 62.50%] [G loss: 0.396601]\n",
      "epoch:27 step:26049 [D loss: 0.219720, acc.: 62.50%] [G loss: 0.423717]\n",
      "epoch:27 step:26050 [D loss: 0.217341, acc.: 63.28%] [G loss: 0.514701]\n",
      "epoch:27 step:26051 [D loss: 0.235253, acc.: 57.81%] [G loss: 0.458224]\n",
      "epoch:27 step:26052 [D loss: 0.222139, acc.: 64.84%] [G loss: 0.442617]\n",
      "epoch:27 step:26053 [D loss: 0.183569, acc.: 73.44%] [G loss: 0.443420]\n",
      "epoch:27 step:26054 [D loss: 0.218960, acc.: 67.19%] [G loss: 0.457486]\n",
      "epoch:27 step:26055 [D loss: 0.229693, acc.: 59.38%] [G loss: 0.461954]\n",
      "epoch:27 step:26056 [D loss: 0.222062, acc.: 64.06%] [G loss: 0.435968]\n",
      "epoch:27 step:26057 [D loss: 0.217658, acc.: 68.75%] [G loss: 0.432787]\n",
      "epoch:27 step:26058 [D loss: 0.225228, acc.: 60.94%] [G loss: 0.406812]\n",
      "epoch:27 step:26059 [D loss: 0.256472, acc.: 57.03%] [G loss: 0.380284]\n",
      "epoch:27 step:26060 [D loss: 0.226081, acc.: 59.38%] [G loss: 0.430432]\n",
      "epoch:27 step:26061 [D loss: 0.224337, acc.: 60.16%] [G loss: 0.402888]\n",
      "epoch:27 step:26062 [D loss: 0.226550, acc.: 57.81%] [G loss: 0.412122]\n",
      "epoch:27 step:26063 [D loss: 0.228085, acc.: 59.38%] [G loss: 0.392335]\n",
      "epoch:27 step:26064 [D loss: 0.252364, acc.: 57.03%] [G loss: 0.414832]\n",
      "epoch:27 step:26065 [D loss: 0.240557, acc.: 53.91%] [G loss: 0.400772]\n",
      "epoch:27 step:26066 [D loss: 0.199018, acc.: 71.88%] [G loss: 0.406351]\n",
      "epoch:27 step:26067 [D loss: 0.244501, acc.: 59.38%] [G loss: 0.421545]\n",
      "epoch:27 step:26068 [D loss: 0.187835, acc.: 72.66%] [G loss: 0.474741]\n",
      "epoch:27 step:26069 [D loss: 0.245732, acc.: 57.81%] [G loss: 0.464381]\n",
      "epoch:27 step:26070 [D loss: 0.199416, acc.: 68.75%] [G loss: 0.455040]\n",
      "epoch:27 step:26071 [D loss: 0.218489, acc.: 64.84%] [G loss: 0.424456]\n",
      "epoch:27 step:26072 [D loss: 0.196269, acc.: 73.44%] [G loss: 0.451446]\n",
      "epoch:27 step:26073 [D loss: 0.216047, acc.: 68.75%] [G loss: 0.440154]\n",
      "epoch:27 step:26074 [D loss: 0.196463, acc.: 67.97%] [G loss: 0.457611]\n",
      "epoch:27 step:26075 [D loss: 0.211605, acc.: 68.75%] [G loss: 0.443887]\n",
      "epoch:27 step:26076 [D loss: 0.212458, acc.: 65.62%] [G loss: 0.439523]\n",
      "epoch:27 step:26077 [D loss: 0.239239, acc.: 64.84%] [G loss: 0.413136]\n",
      "epoch:27 step:26078 [D loss: 0.213719, acc.: 62.50%] [G loss: 0.453389]\n",
      "epoch:27 step:26079 [D loss: 0.196056, acc.: 71.88%] [G loss: 0.450471]\n",
      "epoch:27 step:26080 [D loss: 0.197445, acc.: 71.88%] [G loss: 0.452221]\n",
      "epoch:27 step:26081 [D loss: 0.188786, acc.: 71.88%] [G loss: 0.502807]\n",
      "epoch:27 step:26082 [D loss: 0.254021, acc.: 55.47%] [G loss: 0.463984]\n",
      "epoch:27 step:26083 [D loss: 0.246144, acc.: 60.16%] [G loss: 0.467423]\n",
      "epoch:27 step:26084 [D loss: 0.204582, acc.: 65.62%] [G loss: 0.440435]\n",
      "epoch:27 step:26085 [D loss: 0.204262, acc.: 63.28%] [G loss: 0.436722]\n",
      "epoch:27 step:26086 [D loss: 0.233508, acc.: 57.81%] [G loss: 0.432452]\n",
      "epoch:27 step:26087 [D loss: 0.247266, acc.: 56.25%] [G loss: 0.397244]\n",
      "epoch:27 step:26088 [D loss: 0.237494, acc.: 64.84%] [G loss: 0.388637]\n",
      "epoch:27 step:26089 [D loss: 0.209548, acc.: 64.84%] [G loss: 0.466208]\n",
      "epoch:27 step:26090 [D loss: 0.245363, acc.: 58.59%] [G loss: 0.390464]\n",
      "epoch:27 step:26091 [D loss: 0.215934, acc.: 64.06%] [G loss: 0.449771]\n",
      "epoch:27 step:26092 [D loss: 0.219738, acc.: 59.38%] [G loss: 0.432902]\n",
      "epoch:27 step:26093 [D loss: 0.236205, acc.: 57.03%] [G loss: 0.452755]\n",
      "epoch:27 step:26094 [D loss: 0.226171, acc.: 57.03%] [G loss: 0.463697]\n",
      "epoch:27 step:26095 [D loss: 0.203055, acc.: 71.09%] [G loss: 0.412815]\n",
      "epoch:27 step:26096 [D loss: 0.252114, acc.: 50.00%] [G loss: 0.403511]\n",
      "epoch:27 step:26097 [D loss: 0.233684, acc.: 55.47%] [G loss: 0.439635]\n",
      "epoch:27 step:26098 [D loss: 0.208546, acc.: 69.53%] [G loss: 0.439182]\n",
      "epoch:27 step:26099 [D loss: 0.272634, acc.: 50.00%] [G loss: 0.403023]\n",
      "epoch:27 step:26100 [D loss: 0.238282, acc.: 58.59%] [G loss: 0.429219]\n",
      "epoch:27 step:26101 [D loss: 0.218889, acc.: 64.06%] [G loss: 0.458538]\n",
      "epoch:27 step:26102 [D loss: 0.202504, acc.: 67.97%] [G loss: 0.440079]\n",
      "epoch:27 step:26103 [D loss: 0.233179, acc.: 67.19%] [G loss: 0.420393]\n",
      "epoch:27 step:26104 [D loss: 0.241631, acc.: 61.72%] [G loss: 0.425260]\n",
      "epoch:27 step:26105 [D loss: 0.232365, acc.: 58.59%] [G loss: 0.403361]\n",
      "epoch:27 step:26106 [D loss: 0.203456, acc.: 68.75%] [G loss: 0.413190]\n",
      "epoch:27 step:26107 [D loss: 0.234560, acc.: 60.16%] [G loss: 0.423535]\n",
      "epoch:27 step:26108 [D loss: 0.208883, acc.: 65.62%] [G loss: 0.418020]\n",
      "epoch:27 step:26109 [D loss: 0.255924, acc.: 55.47%] [G loss: 0.388131]\n",
      "epoch:27 step:26110 [D loss: 0.226203, acc.: 64.84%] [G loss: 0.444295]\n",
      "epoch:27 step:26111 [D loss: 0.245833, acc.: 57.03%] [G loss: 0.448464]\n",
      "epoch:27 step:26112 [D loss: 0.227707, acc.: 60.94%] [G loss: 0.462240]\n",
      "epoch:27 step:26113 [D loss: 0.223312, acc.: 62.50%] [G loss: 0.467161]\n",
      "epoch:27 step:26114 [D loss: 0.193703, acc.: 67.97%] [G loss: 0.451891]\n",
      "epoch:27 step:26115 [D loss: 0.204702, acc.: 66.41%] [G loss: 0.487573]\n",
      "epoch:27 step:26116 [D loss: 0.252640, acc.: 56.25%] [G loss: 0.445638]\n",
      "epoch:27 step:26117 [D loss: 0.219649, acc.: 62.50%] [G loss: 0.436503]\n",
      "epoch:27 step:26118 [D loss: 0.222606, acc.: 68.75%] [G loss: 0.467278]\n",
      "epoch:27 step:26119 [D loss: 0.272345, acc.: 50.00%] [G loss: 0.390276]\n",
      "epoch:27 step:26120 [D loss: 0.237925, acc.: 60.16%] [G loss: 0.397067]\n",
      "epoch:27 step:26121 [D loss: 0.201971, acc.: 70.31%] [G loss: 0.479488]\n",
      "epoch:27 step:26122 [D loss: 0.218683, acc.: 67.19%] [G loss: 0.428087]\n",
      "epoch:27 step:26123 [D loss: 0.232085, acc.: 61.72%] [G loss: 0.425834]\n",
      "epoch:27 step:26124 [D loss: 0.200973, acc.: 68.75%] [G loss: 0.411925]\n",
      "epoch:27 step:26125 [D loss: 0.231735, acc.: 62.50%] [G loss: 0.406172]\n",
      "epoch:27 step:26126 [D loss: 0.235823, acc.: 59.38%] [G loss: 0.432507]\n",
      "epoch:27 step:26127 [D loss: 0.235299, acc.: 64.84%] [G loss: 0.441602]\n",
      "epoch:27 step:26128 [D loss: 0.247926, acc.: 58.59%] [G loss: 0.376903]\n",
      "epoch:27 step:26129 [D loss: 0.213264, acc.: 64.84%] [G loss: 0.427372]\n",
      "epoch:27 step:26130 [D loss: 0.213804, acc.: 60.16%] [G loss: 0.396625]\n",
      "epoch:27 step:26131 [D loss: 0.232971, acc.: 60.16%] [G loss: 0.404095]\n",
      "epoch:27 step:26132 [D loss: 0.205187, acc.: 66.41%] [G loss: 0.468675]\n",
      "epoch:27 step:26133 [D loss: 0.223770, acc.: 64.84%] [G loss: 0.422073]\n",
      "epoch:27 step:26134 [D loss: 0.216856, acc.: 68.75%] [G loss: 0.476568]\n",
      "epoch:27 step:26135 [D loss: 0.214084, acc.: 71.09%] [G loss: 0.441424]\n",
      "epoch:27 step:26136 [D loss: 0.226154, acc.: 61.72%] [G loss: 0.411307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26137 [D loss: 0.209013, acc.: 67.97%] [G loss: 0.436182]\n",
      "epoch:27 step:26138 [D loss: 0.191261, acc.: 71.09%] [G loss: 0.439201]\n",
      "epoch:27 step:26139 [D loss: 0.202342, acc.: 64.84%] [G loss: 0.419092]\n",
      "epoch:27 step:26140 [D loss: 0.213763, acc.: 64.84%] [G loss: 0.426724]\n",
      "epoch:27 step:26141 [D loss: 0.197493, acc.: 71.88%] [G loss: 0.433770]\n",
      "epoch:27 step:26142 [D loss: 0.231286, acc.: 63.28%] [G loss: 0.438000]\n",
      "epoch:27 step:26143 [D loss: 0.245934, acc.: 56.25%] [G loss: 0.413254]\n",
      "epoch:27 step:26144 [D loss: 0.229762, acc.: 61.72%] [G loss: 0.402448]\n",
      "epoch:27 step:26145 [D loss: 0.246225, acc.: 57.03%] [G loss: 0.411859]\n",
      "epoch:27 step:26146 [D loss: 0.239481, acc.: 57.81%] [G loss: 0.421427]\n",
      "epoch:27 step:26147 [D loss: 0.223527, acc.: 61.72%] [G loss: 0.423546]\n",
      "epoch:27 step:26148 [D loss: 0.217753, acc.: 59.38%] [G loss: 0.406072]\n",
      "epoch:27 step:26149 [D loss: 0.257481, acc.: 57.81%] [G loss: 0.425724]\n",
      "epoch:27 step:26150 [D loss: 0.223612, acc.: 61.72%] [G loss: 0.419849]\n",
      "epoch:27 step:26151 [D loss: 0.202926, acc.: 68.75%] [G loss: 0.433009]\n",
      "epoch:27 step:26152 [D loss: 0.209952, acc.: 64.06%] [G loss: 0.479506]\n",
      "epoch:27 step:26153 [D loss: 0.236995, acc.: 56.25%] [G loss: 0.418623]\n",
      "epoch:27 step:26154 [D loss: 0.241212, acc.: 57.03%] [G loss: 0.413288]\n",
      "epoch:27 step:26155 [D loss: 0.269083, acc.: 48.44%] [G loss: 0.440527]\n",
      "epoch:27 step:26156 [D loss: 0.215715, acc.: 64.84%] [G loss: 0.433514]\n",
      "epoch:27 step:26157 [D loss: 0.251736, acc.: 52.34%] [G loss: 0.436017]\n",
      "epoch:27 step:26158 [D loss: 0.231514, acc.: 61.72%] [G loss: 0.433873]\n",
      "epoch:27 step:26159 [D loss: 0.219920, acc.: 63.28%] [G loss: 0.429436]\n",
      "epoch:27 step:26160 [D loss: 0.274367, acc.: 47.66%] [G loss: 0.379114]\n",
      "epoch:27 step:26161 [D loss: 0.231656, acc.: 64.06%] [G loss: 0.421144]\n",
      "epoch:27 step:26162 [D loss: 0.205183, acc.: 71.09%] [G loss: 0.441740]\n",
      "epoch:27 step:26163 [D loss: 0.242848, acc.: 59.38%] [G loss: 0.374800]\n",
      "epoch:27 step:26164 [D loss: 0.242484, acc.: 57.81%] [G loss: 0.358175]\n",
      "epoch:27 step:26165 [D loss: 0.217026, acc.: 66.41%] [G loss: 0.428273]\n",
      "epoch:27 step:26166 [D loss: 0.225203, acc.: 67.19%] [G loss: 0.378206]\n",
      "epoch:27 step:26167 [D loss: 0.221661, acc.: 61.72%] [G loss: 0.399536]\n",
      "epoch:27 step:26168 [D loss: 0.224364, acc.: 67.19%] [G loss: 0.424124]\n",
      "epoch:27 step:26169 [D loss: 0.219127, acc.: 63.28%] [G loss: 0.417185]\n",
      "epoch:27 step:26170 [D loss: 0.209952, acc.: 64.84%] [G loss: 0.460269]\n",
      "epoch:27 step:26171 [D loss: 0.229841, acc.: 60.16%] [G loss: 0.457685]\n",
      "epoch:27 step:26172 [D loss: 0.219871, acc.: 64.06%] [G loss: 0.402040]\n",
      "epoch:27 step:26173 [D loss: 0.196508, acc.: 78.91%] [G loss: 0.412276]\n",
      "epoch:27 step:26174 [D loss: 0.215990, acc.: 67.19%] [G loss: 0.435016]\n",
      "epoch:27 step:26175 [D loss: 0.230633, acc.: 57.03%] [G loss: 0.421734]\n",
      "epoch:27 step:26176 [D loss: 0.229424, acc.: 60.94%] [G loss: 0.459388]\n",
      "epoch:27 step:26177 [D loss: 0.226881, acc.: 64.06%] [G loss: 0.442616]\n",
      "epoch:27 step:26178 [D loss: 0.221208, acc.: 65.62%] [G loss: 0.422317]\n",
      "epoch:27 step:26179 [D loss: 0.248363, acc.: 53.91%] [G loss: 0.427080]\n",
      "epoch:27 step:26180 [D loss: 0.220584, acc.: 64.84%] [G loss: 0.404933]\n",
      "epoch:27 step:26181 [D loss: 0.228073, acc.: 59.38%] [G loss: 0.383874]\n",
      "epoch:27 step:26182 [D loss: 0.229270, acc.: 64.06%] [G loss: 0.410021]\n",
      "epoch:27 step:26183 [D loss: 0.200799, acc.: 70.31%] [G loss: 0.448882]\n",
      "epoch:27 step:26184 [D loss: 0.217048, acc.: 63.28%] [G loss: 0.446080]\n",
      "epoch:27 step:26185 [D loss: 0.204365, acc.: 67.97%] [G loss: 0.446036]\n",
      "epoch:27 step:26186 [D loss: 0.207201, acc.: 67.19%] [G loss: 0.460770]\n",
      "epoch:27 step:26187 [D loss: 0.237284, acc.: 64.06%] [G loss: 0.438823]\n",
      "epoch:27 step:26188 [D loss: 0.234869, acc.: 57.81%] [G loss: 0.431298]\n",
      "epoch:27 step:26189 [D loss: 0.205158, acc.: 68.75%] [G loss: 0.431780]\n",
      "epoch:27 step:26190 [D loss: 0.238414, acc.: 58.59%] [G loss: 0.425065]\n",
      "epoch:27 step:26191 [D loss: 0.237379, acc.: 56.25%] [G loss: 0.415417]\n",
      "epoch:27 step:26192 [D loss: 0.220982, acc.: 64.84%] [G loss: 0.407464]\n",
      "epoch:27 step:26193 [D loss: 0.198753, acc.: 72.66%] [G loss: 0.440787]\n",
      "epoch:27 step:26194 [D loss: 0.223030, acc.: 60.94%] [G loss: 0.409880]\n",
      "epoch:27 step:26195 [D loss: 0.202216, acc.: 66.41%] [G loss: 0.439420]\n",
      "epoch:27 step:26196 [D loss: 0.190454, acc.: 73.44%] [G loss: 0.460481]\n",
      "epoch:27 step:26197 [D loss: 0.207702, acc.: 71.09%] [G loss: 0.460921]\n",
      "epoch:27 step:26198 [D loss: 0.186972, acc.: 70.31%] [G loss: 0.469282]\n",
      "epoch:27 step:26199 [D loss: 0.219941, acc.: 61.72%] [G loss: 0.438726]\n",
      "epoch:27 step:26200 [D loss: 0.219961, acc.: 69.53%] [G loss: 0.441063]\n",
      "epoch:27 step:26201 [D loss: 0.241676, acc.: 60.94%] [G loss: 0.409436]\n",
      "epoch:27 step:26202 [D loss: 0.206268, acc.: 69.53%] [G loss: 0.454781]\n",
      "epoch:27 step:26203 [D loss: 0.242337, acc.: 60.16%] [G loss: 0.417926]\n",
      "epoch:27 step:26204 [D loss: 0.202693, acc.: 71.09%] [G loss: 0.451730]\n",
      "epoch:27 step:26205 [D loss: 0.229742, acc.: 62.50%] [G loss: 0.446697]\n",
      "epoch:27 step:26206 [D loss: 0.222644, acc.: 65.62%] [G loss: 0.424295]\n",
      "epoch:27 step:26207 [D loss: 0.183197, acc.: 74.22%] [G loss: 0.466844]\n",
      "epoch:27 step:26208 [D loss: 0.194714, acc.: 71.09%] [G loss: 0.422983]\n",
      "epoch:27 step:26209 [D loss: 0.241004, acc.: 58.59%] [G loss: 0.405535]\n",
      "epoch:27 step:26210 [D loss: 0.202257, acc.: 66.41%] [G loss: 0.435000]\n",
      "epoch:27 step:26211 [D loss: 0.221744, acc.: 60.94%] [G loss: 0.414659]\n",
      "epoch:27 step:26212 [D loss: 0.241886, acc.: 58.59%] [G loss: 0.395666]\n",
      "epoch:27 step:26213 [D loss: 0.236428, acc.: 58.59%] [G loss: 0.435428]\n",
      "epoch:27 step:26214 [D loss: 0.274773, acc.: 54.69%] [G loss: 0.405985]\n",
      "epoch:27 step:26215 [D loss: 0.196968, acc.: 68.75%] [G loss: 0.446673]\n",
      "epoch:27 step:26216 [D loss: 0.240697, acc.: 61.72%] [G loss: 0.478521]\n",
      "epoch:27 step:26217 [D loss: 0.197732, acc.: 67.19%] [G loss: 0.487378]\n",
      "epoch:27 step:26218 [D loss: 0.235879, acc.: 61.72%] [G loss: 0.451778]\n",
      "epoch:27 step:26219 [D loss: 0.248191, acc.: 57.03%] [G loss: 0.438050]\n",
      "epoch:27 step:26220 [D loss: 0.220063, acc.: 64.84%] [G loss: 0.449799]\n",
      "epoch:27 step:26221 [D loss: 0.248904, acc.: 52.34%] [G loss: 0.440754]\n",
      "epoch:27 step:26222 [D loss: 0.211084, acc.: 61.72%] [G loss: 0.436148]\n",
      "epoch:27 step:26223 [D loss: 0.183907, acc.: 75.78%] [G loss: 0.458289]\n",
      "epoch:27 step:26224 [D loss: 0.183818, acc.: 72.66%] [G loss: 0.477242]\n",
      "epoch:27 step:26225 [D loss: 0.186833, acc.: 70.31%] [G loss: 0.493604]\n",
      "epoch:27 step:26226 [D loss: 0.188696, acc.: 71.88%] [G loss: 0.483931]\n",
      "epoch:27 step:26227 [D loss: 0.324260, acc.: 47.66%] [G loss: 0.512845]\n",
      "epoch:27 step:26228 [D loss: 0.225319, acc.: 57.03%] [G loss: 0.527230]\n",
      "epoch:27 step:26229 [D loss: 0.226454, acc.: 64.06%] [G loss: 0.525069]\n",
      "epoch:27 step:26230 [D loss: 0.222692, acc.: 61.72%] [G loss: 0.460961]\n",
      "epoch:27 step:26231 [D loss: 0.247168, acc.: 57.03%] [G loss: 0.413922]\n",
      "epoch:27 step:26232 [D loss: 0.238065, acc.: 53.12%] [G loss: 0.423244]\n",
      "epoch:27 step:26233 [D loss: 0.215137, acc.: 67.97%] [G loss: 0.424974]\n",
      "epoch:27 step:26234 [D loss: 0.168208, acc.: 73.44%] [G loss: 0.478353]\n",
      "epoch:27 step:26235 [D loss: 0.203586, acc.: 74.22%] [G loss: 0.453123]\n",
      "epoch:27 step:26236 [D loss: 0.181137, acc.: 78.12%] [G loss: 0.541476]\n",
      "epoch:28 step:26237 [D loss: 0.205555, acc.: 70.31%] [G loss: 0.523997]\n",
      "epoch:28 step:26238 [D loss: 0.271265, acc.: 54.69%] [G loss: 0.486126]\n",
      "epoch:28 step:26239 [D loss: 0.243231, acc.: 57.03%] [G loss: 0.471357]\n",
      "epoch:28 step:26240 [D loss: 0.234630, acc.: 60.94%] [G loss: 0.409985]\n",
      "epoch:28 step:26241 [D loss: 0.223984, acc.: 63.28%] [G loss: 0.432254]\n",
      "epoch:28 step:26242 [D loss: 0.235441, acc.: 60.94%] [G loss: 0.467192]\n",
      "epoch:28 step:26243 [D loss: 0.231807, acc.: 64.06%] [G loss: 0.449513]\n",
      "epoch:28 step:26244 [D loss: 0.223287, acc.: 62.50%] [G loss: 0.455190]\n",
      "epoch:28 step:26245 [D loss: 0.206516, acc.: 69.53%] [G loss: 0.478747]\n",
      "epoch:28 step:26246 [D loss: 0.203541, acc.: 68.75%] [G loss: 0.473490]\n",
      "epoch:28 step:26247 [D loss: 0.202078, acc.: 67.97%] [G loss: 0.454475]\n",
      "epoch:28 step:26248 [D loss: 0.226760, acc.: 65.62%] [G loss: 0.447621]\n",
      "epoch:28 step:26249 [D loss: 0.207590, acc.: 68.75%] [G loss: 0.453846]\n",
      "epoch:28 step:26250 [D loss: 0.185772, acc.: 72.66%] [G loss: 0.486270]\n",
      "epoch:28 step:26251 [D loss: 0.177474, acc.: 68.75%] [G loss: 0.491935]\n",
      "epoch:28 step:26252 [D loss: 0.189570, acc.: 70.31%] [G loss: 0.473931]\n",
      "epoch:28 step:26253 [D loss: 0.236739, acc.: 60.16%] [G loss: 0.449098]\n",
      "epoch:28 step:26254 [D loss: 0.222544, acc.: 66.41%] [G loss: 0.447122]\n",
      "epoch:28 step:26255 [D loss: 0.257020, acc.: 53.91%] [G loss: 0.459153]\n",
      "epoch:28 step:26256 [D loss: 0.249292, acc.: 56.25%] [G loss: 0.490423]\n",
      "epoch:28 step:26257 [D loss: 0.252064, acc.: 56.25%] [G loss: 0.485872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26258 [D loss: 0.202477, acc.: 70.31%] [G loss: 0.538777]\n",
      "epoch:28 step:26259 [D loss: 0.280205, acc.: 46.88%] [G loss: 0.406481]\n",
      "epoch:28 step:26260 [D loss: 0.200424, acc.: 70.31%] [G loss: 0.398366]\n",
      "epoch:28 step:26261 [D loss: 0.217893, acc.: 69.53%] [G loss: 0.412520]\n",
      "epoch:28 step:26262 [D loss: 0.228592, acc.: 60.94%] [G loss: 0.420743]\n",
      "epoch:28 step:26263 [D loss: 0.210134, acc.: 67.97%] [G loss: 0.436673]\n",
      "epoch:28 step:26264 [D loss: 0.231478, acc.: 57.03%] [G loss: 0.423748]\n",
      "epoch:28 step:26265 [D loss: 0.241902, acc.: 56.25%] [G loss: 0.417058]\n",
      "epoch:28 step:26266 [D loss: 0.210390, acc.: 64.06%] [G loss: 0.460402]\n",
      "epoch:28 step:26267 [D loss: 0.249778, acc.: 56.25%] [G loss: 0.432480]\n",
      "epoch:28 step:26268 [D loss: 0.220285, acc.: 63.28%] [G loss: 0.459229]\n",
      "epoch:28 step:26269 [D loss: 0.233378, acc.: 58.59%] [G loss: 0.442866]\n",
      "epoch:28 step:26270 [D loss: 0.227295, acc.: 61.72%] [G loss: 0.434322]\n",
      "epoch:28 step:26271 [D loss: 0.210645, acc.: 66.41%] [G loss: 0.432965]\n",
      "epoch:28 step:26272 [D loss: 0.200886, acc.: 73.44%] [G loss: 0.431981]\n",
      "epoch:28 step:26273 [D loss: 0.222393, acc.: 61.72%] [G loss: 0.431305]\n",
      "epoch:28 step:26274 [D loss: 0.256648, acc.: 57.81%] [G loss: 0.384032]\n",
      "epoch:28 step:26275 [D loss: 0.230210, acc.: 60.94%] [G loss: 0.387844]\n",
      "epoch:28 step:26276 [D loss: 0.195844, acc.: 71.09%] [G loss: 0.441722]\n",
      "epoch:28 step:26277 [D loss: 0.224584, acc.: 65.62%] [G loss: 0.427525]\n",
      "epoch:28 step:26278 [D loss: 0.227171, acc.: 67.19%] [G loss: 0.446406]\n",
      "epoch:28 step:26279 [D loss: 0.229042, acc.: 64.06%] [G loss: 0.361265]\n",
      "epoch:28 step:26280 [D loss: 0.220475, acc.: 64.84%] [G loss: 0.468388]\n",
      "epoch:28 step:26281 [D loss: 0.212959, acc.: 66.41%] [G loss: 0.450912]\n",
      "epoch:28 step:26282 [D loss: 0.242012, acc.: 60.16%] [G loss: 0.401216]\n",
      "epoch:28 step:26283 [D loss: 0.263734, acc.: 49.22%] [G loss: 0.383028]\n",
      "epoch:28 step:26284 [D loss: 0.196225, acc.: 71.09%] [G loss: 0.425888]\n",
      "epoch:28 step:26285 [D loss: 0.197942, acc.: 70.31%] [G loss: 0.446351]\n",
      "epoch:28 step:26286 [D loss: 0.215636, acc.: 67.97%] [G loss: 0.449692]\n",
      "epoch:28 step:26287 [D loss: 0.236688, acc.: 64.84%] [G loss: 0.426135]\n",
      "epoch:28 step:26288 [D loss: 0.215162, acc.: 59.38%] [G loss: 0.448992]\n",
      "epoch:28 step:26289 [D loss: 0.225380, acc.: 60.16%] [G loss: 0.480377]\n",
      "epoch:28 step:26290 [D loss: 0.201133, acc.: 71.88%] [G loss: 0.436398]\n",
      "epoch:28 step:26291 [D loss: 0.233581, acc.: 62.50%] [G loss: 0.448150]\n",
      "epoch:28 step:26292 [D loss: 0.230546, acc.: 58.59%] [G loss: 0.488029]\n",
      "epoch:28 step:26293 [D loss: 0.238866, acc.: 58.59%] [G loss: 0.449177]\n",
      "epoch:28 step:26294 [D loss: 0.231367, acc.: 63.28%] [G loss: 0.434032]\n",
      "epoch:28 step:26295 [D loss: 0.213189, acc.: 61.72%] [G loss: 0.448636]\n",
      "epoch:28 step:26296 [D loss: 0.231337, acc.: 64.06%] [G loss: 0.420531]\n",
      "epoch:28 step:26297 [D loss: 0.236350, acc.: 62.50%] [G loss: 0.454456]\n",
      "epoch:28 step:26298 [D loss: 0.243507, acc.: 62.50%] [G loss: 0.442075]\n",
      "epoch:28 step:26299 [D loss: 0.206969, acc.: 64.84%] [G loss: 0.407480]\n",
      "epoch:28 step:26300 [D loss: 0.243022, acc.: 53.12%] [G loss: 0.418668]\n",
      "epoch:28 step:26301 [D loss: 0.222860, acc.: 65.62%] [G loss: 0.436238]\n",
      "epoch:28 step:26302 [D loss: 0.211505, acc.: 65.62%] [G loss: 0.410047]\n",
      "epoch:28 step:26303 [D loss: 0.217441, acc.: 64.06%] [G loss: 0.441509]\n",
      "epoch:28 step:26304 [D loss: 0.241512, acc.: 57.03%] [G loss: 0.432262]\n",
      "epoch:28 step:26305 [D loss: 0.189161, acc.: 73.44%] [G loss: 0.472105]\n",
      "epoch:28 step:26306 [D loss: 0.203649, acc.: 67.97%] [G loss: 0.483731]\n",
      "epoch:28 step:26307 [D loss: 0.263427, acc.: 55.47%] [G loss: 0.416560]\n",
      "epoch:28 step:26308 [D loss: 0.247548, acc.: 60.16%] [G loss: 0.373529]\n",
      "epoch:28 step:26309 [D loss: 0.223625, acc.: 61.72%] [G loss: 0.406512]\n",
      "epoch:28 step:26310 [D loss: 0.197625, acc.: 71.09%] [G loss: 0.428092]\n",
      "epoch:28 step:26311 [D loss: 0.181236, acc.: 75.78%] [G loss: 0.439199]\n",
      "epoch:28 step:26312 [D loss: 0.181149, acc.: 75.00%] [G loss: 0.491264]\n",
      "epoch:28 step:26313 [D loss: 0.182429, acc.: 74.22%] [G loss: 0.501685]\n",
      "epoch:28 step:26314 [D loss: 0.248619, acc.: 56.25%] [G loss: 0.420779]\n",
      "epoch:28 step:26315 [D loss: 0.243484, acc.: 57.03%] [G loss: 0.409432]\n",
      "epoch:28 step:26316 [D loss: 0.217630, acc.: 62.50%] [G loss: 0.409807]\n",
      "epoch:28 step:26317 [D loss: 0.254329, acc.: 57.81%] [G loss: 0.372792]\n",
      "epoch:28 step:26318 [D loss: 0.213722, acc.: 64.84%] [G loss: 0.415937]\n",
      "epoch:28 step:26319 [D loss: 0.210402, acc.: 65.62%] [G loss: 0.398052]\n",
      "epoch:28 step:26320 [D loss: 0.238873, acc.: 57.03%] [G loss: 0.386823]\n",
      "epoch:28 step:26321 [D loss: 0.221765, acc.: 56.25%] [G loss: 0.418633]\n",
      "epoch:28 step:26322 [D loss: 0.220889, acc.: 65.62%] [G loss: 0.420928]\n",
      "epoch:28 step:26323 [D loss: 0.222642, acc.: 63.28%] [G loss: 0.433588]\n",
      "epoch:28 step:26324 [D loss: 0.190409, acc.: 73.44%] [G loss: 0.415583]\n",
      "epoch:28 step:26325 [D loss: 0.200153, acc.: 67.19%] [G loss: 0.425118]\n",
      "epoch:28 step:26326 [D loss: 0.221554, acc.: 67.97%] [G loss: 0.437657]\n",
      "epoch:28 step:26327 [D loss: 0.223977, acc.: 69.53%] [G loss: 0.454099]\n",
      "epoch:28 step:26328 [D loss: 0.210519, acc.: 64.06%] [G loss: 0.399314]\n",
      "epoch:28 step:26329 [D loss: 0.212791, acc.: 64.84%] [G loss: 0.453625]\n",
      "epoch:28 step:26330 [D loss: 0.229255, acc.: 60.94%] [G loss: 0.491074]\n",
      "epoch:28 step:26331 [D loss: 0.223611, acc.: 64.06%] [G loss: 0.452641]\n",
      "epoch:28 step:26332 [D loss: 0.228042, acc.: 62.50%] [G loss: 0.439243]\n",
      "epoch:28 step:26333 [D loss: 0.208059, acc.: 67.97%] [G loss: 0.487808]\n",
      "epoch:28 step:26334 [D loss: 0.239914, acc.: 61.72%] [G loss: 0.433790]\n",
      "epoch:28 step:26335 [D loss: 0.220606, acc.: 64.06%] [G loss: 0.454645]\n",
      "epoch:28 step:26336 [D loss: 0.189137, acc.: 71.88%] [G loss: 0.431924]\n",
      "epoch:28 step:26337 [D loss: 0.235900, acc.: 58.59%] [G loss: 0.469204]\n",
      "epoch:28 step:26338 [D loss: 0.240600, acc.: 60.94%] [G loss: 0.418235]\n",
      "epoch:28 step:26339 [D loss: 0.238070, acc.: 52.34%] [G loss: 0.426145]\n",
      "epoch:28 step:26340 [D loss: 0.232859, acc.: 62.50%] [G loss: 0.414456]\n",
      "epoch:28 step:26341 [D loss: 0.235001, acc.: 58.59%] [G loss: 0.398256]\n",
      "epoch:28 step:26342 [D loss: 0.203760, acc.: 67.19%] [G loss: 0.432503]\n",
      "epoch:28 step:26343 [D loss: 0.195142, acc.: 76.56%] [G loss: 0.456047]\n",
      "epoch:28 step:26344 [D loss: 0.245533, acc.: 58.59%] [G loss: 0.482407]\n",
      "epoch:28 step:26345 [D loss: 0.269023, acc.: 50.00%] [G loss: 0.413197]\n",
      "epoch:28 step:26346 [D loss: 0.236266, acc.: 55.47%] [G loss: 0.434444]\n",
      "epoch:28 step:26347 [D loss: 0.214969, acc.: 66.41%] [G loss: 0.448069]\n",
      "epoch:28 step:26348 [D loss: 0.188680, acc.: 70.31%] [G loss: 0.417006]\n",
      "epoch:28 step:26349 [D loss: 0.199550, acc.: 70.31%] [G loss: 0.424708]\n",
      "epoch:28 step:26350 [D loss: 0.209720, acc.: 64.84%] [G loss: 0.446657]\n",
      "epoch:28 step:26351 [D loss: 0.219181, acc.: 64.84%] [G loss: 0.461257]\n",
      "epoch:28 step:26352 [D loss: 0.208200, acc.: 68.75%] [G loss: 0.468821]\n",
      "epoch:28 step:26353 [D loss: 0.210324, acc.: 68.75%] [G loss: 0.471143]\n",
      "epoch:28 step:26354 [D loss: 0.193402, acc.: 75.00%] [G loss: 0.468708]\n",
      "epoch:28 step:26355 [D loss: 0.181762, acc.: 70.31%] [G loss: 0.520494]\n",
      "epoch:28 step:26356 [D loss: 0.221162, acc.: 64.06%] [G loss: 0.436184]\n",
      "epoch:28 step:26357 [D loss: 0.246603, acc.: 57.81%] [G loss: 0.416302]\n",
      "epoch:28 step:26358 [D loss: 0.208335, acc.: 70.31%] [G loss: 0.461873]\n",
      "epoch:28 step:26359 [D loss: 0.223018, acc.: 62.50%] [G loss: 0.471995]\n",
      "epoch:28 step:26360 [D loss: 0.245269, acc.: 57.03%] [G loss: 0.426470]\n",
      "epoch:28 step:26361 [D loss: 0.232172, acc.: 62.50%] [G loss: 0.452357]\n",
      "epoch:28 step:26362 [D loss: 0.194425, acc.: 66.41%] [G loss: 0.430325]\n",
      "epoch:28 step:26363 [D loss: 0.200216, acc.: 70.31%] [G loss: 0.426038]\n",
      "epoch:28 step:26364 [D loss: 0.242634, acc.: 57.81%] [G loss: 0.444034]\n",
      "epoch:28 step:26365 [D loss: 0.242223, acc.: 56.25%] [G loss: 0.413645]\n",
      "epoch:28 step:26366 [D loss: 0.207037, acc.: 67.19%] [G loss: 0.448505]\n",
      "epoch:28 step:26367 [D loss: 0.213777, acc.: 65.62%] [G loss: 0.391366]\n",
      "epoch:28 step:26368 [D loss: 0.233461, acc.: 64.84%] [G loss: 0.419602]\n",
      "epoch:28 step:26369 [D loss: 0.235122, acc.: 64.06%] [G loss: 0.464390]\n",
      "epoch:28 step:26370 [D loss: 0.219441, acc.: 64.84%] [G loss: 0.442657]\n",
      "epoch:28 step:26371 [D loss: 0.207221, acc.: 64.06%] [G loss: 0.455374]\n",
      "epoch:28 step:26372 [D loss: 0.223927, acc.: 64.06%] [G loss: 0.523127]\n",
      "epoch:28 step:26373 [D loss: 0.243401, acc.: 60.94%] [G loss: 0.446732]\n",
      "epoch:28 step:26374 [D loss: 0.239749, acc.: 57.03%] [G loss: 0.391228]\n",
      "epoch:28 step:26375 [D loss: 0.229279, acc.: 57.03%] [G loss: 0.402039]\n",
      "epoch:28 step:26376 [D loss: 0.235794, acc.: 61.72%] [G loss: 0.412480]\n",
      "epoch:28 step:26377 [D loss: 0.199675, acc.: 65.62%] [G loss: 0.444602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26378 [D loss: 0.254910, acc.: 56.25%] [G loss: 0.376000]\n",
      "epoch:28 step:26379 [D loss: 0.233757, acc.: 64.06%] [G loss: 0.407493]\n",
      "epoch:28 step:26380 [D loss: 0.210827, acc.: 65.62%] [G loss: 0.458543]\n",
      "epoch:28 step:26381 [D loss: 0.221393, acc.: 63.28%] [G loss: 0.429956]\n",
      "epoch:28 step:26382 [D loss: 0.235436, acc.: 59.38%] [G loss: 0.444238]\n",
      "epoch:28 step:26383 [D loss: 0.203485, acc.: 67.19%] [G loss: 0.462568]\n",
      "epoch:28 step:26384 [D loss: 0.261888, acc.: 53.91%] [G loss: 0.405705]\n",
      "epoch:28 step:26385 [D loss: 0.222756, acc.: 57.03%] [G loss: 0.424386]\n",
      "epoch:28 step:26386 [D loss: 0.241344, acc.: 59.38%] [G loss: 0.427708]\n",
      "epoch:28 step:26387 [D loss: 0.209429, acc.: 68.75%] [G loss: 0.441036]\n",
      "epoch:28 step:26388 [D loss: 0.216714, acc.: 66.41%] [G loss: 0.438165]\n",
      "epoch:28 step:26389 [D loss: 0.234107, acc.: 59.38%] [G loss: 0.428932]\n",
      "epoch:28 step:26390 [D loss: 0.225413, acc.: 66.41%] [G loss: 0.407611]\n",
      "epoch:28 step:26391 [D loss: 0.207678, acc.: 67.97%] [G loss: 0.440095]\n",
      "epoch:28 step:26392 [D loss: 0.212303, acc.: 66.41%] [G loss: 0.433990]\n",
      "epoch:28 step:26393 [D loss: 0.222607, acc.: 64.84%] [G loss: 0.418204]\n",
      "epoch:28 step:26394 [D loss: 0.228506, acc.: 57.03%] [G loss: 0.418928]\n",
      "epoch:28 step:26395 [D loss: 0.217772, acc.: 65.62%] [G loss: 0.431096]\n",
      "epoch:28 step:26396 [D loss: 0.254271, acc.: 53.91%] [G loss: 0.458665]\n",
      "epoch:28 step:26397 [D loss: 0.221649, acc.: 64.06%] [G loss: 0.460723]\n",
      "epoch:28 step:26398 [D loss: 0.214222, acc.: 64.84%] [G loss: 0.459358]\n",
      "epoch:28 step:26399 [D loss: 0.205313, acc.: 67.97%] [G loss: 0.427558]\n",
      "epoch:28 step:26400 [D loss: 0.233302, acc.: 64.84%] [G loss: 0.437874]\n",
      "epoch:28 step:26401 [D loss: 0.255209, acc.: 55.47%] [G loss: 0.392510]\n",
      "epoch:28 step:26402 [D loss: 0.247996, acc.: 59.38%] [G loss: 0.362662]\n",
      "epoch:28 step:26403 [D loss: 0.236621, acc.: 55.47%] [G loss: 0.430179]\n",
      "epoch:28 step:26404 [D loss: 0.217037, acc.: 68.75%] [G loss: 0.437655]\n",
      "epoch:28 step:26405 [D loss: 0.228094, acc.: 61.72%] [G loss: 0.398005]\n",
      "epoch:28 step:26406 [D loss: 0.241351, acc.: 60.16%] [G loss: 0.409651]\n",
      "epoch:28 step:26407 [D loss: 0.227246, acc.: 65.62%] [G loss: 0.405354]\n",
      "epoch:28 step:26408 [D loss: 0.228948, acc.: 66.41%] [G loss: 0.424219]\n",
      "epoch:28 step:26409 [D loss: 0.222084, acc.: 62.50%] [G loss: 0.416358]\n",
      "epoch:28 step:26410 [D loss: 0.258693, acc.: 54.69%] [G loss: 0.378231]\n",
      "epoch:28 step:26411 [D loss: 0.221015, acc.: 62.50%] [G loss: 0.383830]\n",
      "epoch:28 step:26412 [D loss: 0.229556, acc.: 61.72%] [G loss: 0.407352]\n",
      "epoch:28 step:26413 [D loss: 0.242189, acc.: 52.34%] [G loss: 0.377620]\n",
      "epoch:28 step:26414 [D loss: 0.224817, acc.: 66.41%] [G loss: 0.381122]\n",
      "epoch:28 step:26415 [D loss: 0.219350, acc.: 68.75%] [G loss: 0.444223]\n",
      "epoch:28 step:26416 [D loss: 0.225554, acc.: 61.72%] [G loss: 0.415608]\n",
      "epoch:28 step:26417 [D loss: 0.219420, acc.: 60.16%] [G loss: 0.404925]\n",
      "epoch:28 step:26418 [D loss: 0.232971, acc.: 64.84%] [G loss: 0.432322]\n",
      "epoch:28 step:26419 [D loss: 0.237117, acc.: 56.25%] [G loss: 0.426659]\n",
      "epoch:28 step:26420 [D loss: 0.240486, acc.: 60.16%] [G loss: 0.426494]\n",
      "epoch:28 step:26421 [D loss: 0.254515, acc.: 54.69%] [G loss: 0.411545]\n",
      "epoch:28 step:26422 [D loss: 0.248427, acc.: 54.69%] [G loss: 0.400628]\n",
      "epoch:28 step:26423 [D loss: 0.217151, acc.: 65.62%] [G loss: 0.473776]\n",
      "epoch:28 step:26424 [D loss: 0.240630, acc.: 58.59%] [G loss: 0.406438]\n",
      "epoch:28 step:26425 [D loss: 0.252919, acc.: 52.34%] [G loss: 0.378131]\n",
      "epoch:28 step:26426 [D loss: 0.232013, acc.: 62.50%] [G loss: 0.412065]\n",
      "epoch:28 step:26427 [D loss: 0.199612, acc.: 71.88%] [G loss: 0.469695]\n",
      "epoch:28 step:26428 [D loss: 0.206361, acc.: 64.84%] [G loss: 0.440548]\n",
      "epoch:28 step:26429 [D loss: 0.234324, acc.: 58.59%] [G loss: 0.417713]\n",
      "epoch:28 step:26430 [D loss: 0.224986, acc.: 64.06%] [G loss: 0.410862]\n",
      "epoch:28 step:26431 [D loss: 0.204872, acc.: 70.31%] [G loss: 0.468121]\n",
      "epoch:28 step:26432 [D loss: 0.241051, acc.: 59.38%] [G loss: 0.395438]\n",
      "epoch:28 step:26433 [D loss: 0.198771, acc.: 68.75%] [G loss: 0.431511]\n",
      "epoch:28 step:26434 [D loss: 0.192020, acc.: 75.00%] [G loss: 0.438582]\n",
      "epoch:28 step:26435 [D loss: 0.218303, acc.: 66.41%] [G loss: 0.442335]\n",
      "epoch:28 step:26436 [D loss: 0.247397, acc.: 54.69%] [G loss: 0.430550]\n",
      "epoch:28 step:26437 [D loss: 0.231124, acc.: 60.16%] [G loss: 0.444408]\n",
      "epoch:28 step:26438 [D loss: 0.227367, acc.: 62.50%] [G loss: 0.442567]\n",
      "epoch:28 step:26439 [D loss: 0.235081, acc.: 59.38%] [G loss: 0.447376]\n",
      "epoch:28 step:26440 [D loss: 0.236472, acc.: 60.16%] [G loss: 0.441306]\n",
      "epoch:28 step:26441 [D loss: 0.200946, acc.: 63.28%] [G loss: 0.518182]\n",
      "epoch:28 step:26442 [D loss: 0.216198, acc.: 66.41%] [G loss: 0.495776]\n",
      "epoch:28 step:26443 [D loss: 0.216054, acc.: 64.84%] [G loss: 0.421925]\n",
      "epoch:28 step:26444 [D loss: 0.205502, acc.: 67.97%] [G loss: 0.442142]\n",
      "epoch:28 step:26445 [D loss: 0.196382, acc.: 68.75%] [G loss: 0.465645]\n",
      "epoch:28 step:26446 [D loss: 0.259962, acc.: 52.34%] [G loss: 0.406668]\n",
      "epoch:28 step:26447 [D loss: 0.236892, acc.: 60.16%] [G loss: 0.430458]\n",
      "epoch:28 step:26448 [D loss: 0.216727, acc.: 66.41%] [G loss: 0.401319]\n",
      "epoch:28 step:26449 [D loss: 0.210778, acc.: 64.06%] [G loss: 0.408039]\n",
      "epoch:28 step:26450 [D loss: 0.246250, acc.: 57.81%] [G loss: 0.413738]\n",
      "epoch:28 step:26451 [D loss: 0.250093, acc.: 57.03%] [G loss: 0.384207]\n",
      "epoch:28 step:26452 [D loss: 0.205718, acc.: 65.62%] [G loss: 0.428247]\n",
      "epoch:28 step:26453 [D loss: 0.213727, acc.: 66.41%] [G loss: 0.412087]\n",
      "epoch:28 step:26454 [D loss: 0.190985, acc.: 69.53%] [G loss: 0.434207]\n",
      "epoch:28 step:26455 [D loss: 0.183373, acc.: 69.53%] [G loss: 0.476303]\n",
      "epoch:28 step:26456 [D loss: 0.268727, acc.: 53.12%] [G loss: 0.454401]\n",
      "epoch:28 step:26457 [D loss: 0.244149, acc.: 58.59%] [G loss: 0.453337]\n",
      "epoch:28 step:26458 [D loss: 0.230045, acc.: 60.94%] [G loss: 0.415257]\n",
      "epoch:28 step:26459 [D loss: 0.196856, acc.: 67.97%] [G loss: 0.409279]\n",
      "epoch:28 step:26460 [D loss: 0.245824, acc.: 57.03%] [G loss: 0.397754]\n",
      "epoch:28 step:26461 [D loss: 0.220298, acc.: 64.06%] [G loss: 0.425464]\n",
      "epoch:28 step:26462 [D loss: 0.252495, acc.: 53.12%] [G loss: 0.403473]\n",
      "epoch:28 step:26463 [D loss: 0.214807, acc.: 66.41%] [G loss: 0.412345]\n",
      "epoch:28 step:26464 [D loss: 0.245896, acc.: 57.81%] [G loss: 0.417557]\n",
      "epoch:28 step:26465 [D loss: 0.215326, acc.: 68.75%] [G loss: 0.438204]\n",
      "epoch:28 step:26466 [D loss: 0.199414, acc.: 67.97%] [G loss: 0.434909]\n",
      "epoch:28 step:26467 [D loss: 0.174229, acc.: 76.56%] [G loss: 0.515134]\n",
      "epoch:28 step:26468 [D loss: 0.197517, acc.: 71.88%] [G loss: 0.506482]\n",
      "epoch:28 step:26469 [D loss: 0.242584, acc.: 61.72%] [G loss: 0.452997]\n",
      "epoch:28 step:26470 [D loss: 0.239205, acc.: 57.81%] [G loss: 0.438687]\n",
      "epoch:28 step:26471 [D loss: 0.239153, acc.: 60.94%] [G loss: 0.415586]\n",
      "epoch:28 step:26472 [D loss: 0.214709, acc.: 64.06%] [G loss: 0.428972]\n",
      "epoch:28 step:26473 [D loss: 0.221615, acc.: 63.28%] [G loss: 0.456479]\n",
      "epoch:28 step:26474 [D loss: 0.218685, acc.: 63.28%] [G loss: 0.418129]\n",
      "epoch:28 step:26475 [D loss: 0.213891, acc.: 63.28%] [G loss: 0.405272]\n",
      "epoch:28 step:26476 [D loss: 0.208683, acc.: 67.97%] [G loss: 0.470990]\n",
      "epoch:28 step:26477 [D loss: 0.186104, acc.: 72.66%] [G loss: 0.450926]\n",
      "epoch:28 step:26478 [D loss: 0.212731, acc.: 67.97%] [G loss: 0.430754]\n",
      "epoch:28 step:26479 [D loss: 0.197843, acc.: 66.41%] [G loss: 0.444132]\n",
      "epoch:28 step:26480 [D loss: 0.227493, acc.: 64.06%] [G loss: 0.435456]\n",
      "epoch:28 step:26481 [D loss: 0.189773, acc.: 75.78%] [G loss: 0.448838]\n",
      "epoch:28 step:26482 [D loss: 0.233053, acc.: 57.03%] [G loss: 0.470694]\n",
      "epoch:28 step:26483 [D loss: 0.196420, acc.: 66.41%] [G loss: 0.474181]\n",
      "epoch:28 step:26484 [D loss: 0.207605, acc.: 70.31%] [G loss: 0.462981]\n",
      "epoch:28 step:26485 [D loss: 0.262374, acc.: 50.00%] [G loss: 0.473157]\n",
      "epoch:28 step:26486 [D loss: 0.254436, acc.: 50.78%] [G loss: 0.419200]\n",
      "epoch:28 step:26487 [D loss: 0.243389, acc.: 55.47%] [G loss: 0.456169]\n",
      "epoch:28 step:26488 [D loss: 0.211540, acc.: 67.97%] [G loss: 0.445483]\n",
      "epoch:28 step:26489 [D loss: 0.238520, acc.: 58.59%] [G loss: 0.418601]\n",
      "epoch:28 step:26490 [D loss: 0.235636, acc.: 61.72%] [G loss: 0.421603]\n",
      "epoch:28 step:26491 [D loss: 0.226078, acc.: 60.16%] [G loss: 0.412098]\n",
      "epoch:28 step:26492 [D loss: 0.220380, acc.: 64.06%] [G loss: 0.452946]\n",
      "epoch:28 step:26493 [D loss: 0.225003, acc.: 62.50%] [G loss: 0.434465]\n",
      "epoch:28 step:26494 [D loss: 0.209695, acc.: 68.75%] [G loss: 0.382509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26495 [D loss: 0.232434, acc.: 67.19%] [G loss: 0.423830]\n",
      "epoch:28 step:26496 [D loss: 0.234913, acc.: 58.59%] [G loss: 0.397898]\n",
      "epoch:28 step:26497 [D loss: 0.223819, acc.: 64.84%] [G loss: 0.459631]\n",
      "epoch:28 step:26498 [D loss: 0.207167, acc.: 66.41%] [G loss: 0.424084]\n",
      "epoch:28 step:26499 [D loss: 0.230965, acc.: 63.28%] [G loss: 0.424497]\n",
      "epoch:28 step:26500 [D loss: 0.207667, acc.: 69.53%] [G loss: 0.462837]\n",
      "epoch:28 step:26501 [D loss: 0.230393, acc.: 57.81%] [G loss: 0.413287]\n",
      "epoch:28 step:26502 [D loss: 0.212257, acc.: 62.50%] [G loss: 0.442010]\n",
      "epoch:28 step:26503 [D loss: 0.228088, acc.: 61.72%] [G loss: 0.421042]\n",
      "epoch:28 step:26504 [D loss: 0.206484, acc.: 64.84%] [G loss: 0.426650]\n",
      "epoch:28 step:26505 [D loss: 0.226958, acc.: 64.84%] [G loss: 0.419199]\n",
      "epoch:28 step:26506 [D loss: 0.212421, acc.: 64.06%] [G loss: 0.427788]\n",
      "epoch:28 step:26507 [D loss: 0.202515, acc.: 67.97%] [G loss: 0.465606]\n",
      "epoch:28 step:26508 [D loss: 0.218331, acc.: 66.41%] [G loss: 0.444050]\n",
      "epoch:28 step:26509 [D loss: 0.242806, acc.: 66.41%] [G loss: 0.435996]\n",
      "epoch:28 step:26510 [D loss: 0.193370, acc.: 71.88%] [G loss: 0.506763]\n",
      "epoch:28 step:26511 [D loss: 0.219693, acc.: 66.41%] [G loss: 0.448139]\n",
      "epoch:28 step:26512 [D loss: 0.208845, acc.: 64.84%] [G loss: 0.425688]\n",
      "epoch:28 step:26513 [D loss: 0.253402, acc.: 55.47%] [G loss: 0.421876]\n",
      "epoch:28 step:26514 [D loss: 0.232009, acc.: 59.38%] [G loss: 0.452614]\n",
      "epoch:28 step:26515 [D loss: 0.220629, acc.: 68.75%] [G loss: 0.399635]\n",
      "epoch:28 step:26516 [D loss: 0.237285, acc.: 56.25%] [G loss: 0.433039]\n",
      "epoch:28 step:26517 [D loss: 0.217125, acc.: 58.59%] [G loss: 0.477593]\n",
      "epoch:28 step:26518 [D loss: 0.243624, acc.: 54.69%] [G loss: 0.435326]\n",
      "epoch:28 step:26519 [D loss: 0.202362, acc.: 75.78%] [G loss: 0.422055]\n",
      "epoch:28 step:26520 [D loss: 0.206612, acc.: 67.19%] [G loss: 0.439882]\n",
      "epoch:28 step:26521 [D loss: 0.218975, acc.: 63.28%] [G loss: 0.417702]\n",
      "epoch:28 step:26522 [D loss: 0.213677, acc.: 68.75%] [G loss: 0.386447]\n",
      "epoch:28 step:26523 [D loss: 0.231215, acc.: 60.16%] [G loss: 0.417644]\n",
      "epoch:28 step:26524 [D loss: 0.209019, acc.: 71.09%] [G loss: 0.397422]\n",
      "epoch:28 step:26525 [D loss: 0.197937, acc.: 74.22%] [G loss: 0.446090]\n",
      "epoch:28 step:26526 [D loss: 0.215179, acc.: 66.41%] [G loss: 0.448659]\n",
      "epoch:28 step:26527 [D loss: 0.224682, acc.: 62.50%] [G loss: 0.449762]\n",
      "epoch:28 step:26528 [D loss: 0.225758, acc.: 64.84%] [G loss: 0.422332]\n",
      "epoch:28 step:26529 [D loss: 0.227456, acc.: 64.06%] [G loss: 0.445624]\n",
      "epoch:28 step:26530 [D loss: 0.253916, acc.: 52.34%] [G loss: 0.393561]\n",
      "epoch:28 step:26531 [D loss: 0.245328, acc.: 52.34%] [G loss: 0.411829]\n",
      "epoch:28 step:26532 [D loss: 0.235252, acc.: 60.16%] [G loss: 0.411185]\n",
      "epoch:28 step:26533 [D loss: 0.234905, acc.: 60.16%] [G loss: 0.434741]\n",
      "epoch:28 step:26534 [D loss: 0.217652, acc.: 67.97%] [G loss: 0.420020]\n",
      "epoch:28 step:26535 [D loss: 0.203160, acc.: 64.84%] [G loss: 0.426623]\n",
      "epoch:28 step:26536 [D loss: 0.207010, acc.: 65.62%] [G loss: 0.428985]\n",
      "epoch:28 step:26537 [D loss: 0.261492, acc.: 56.25%] [G loss: 0.420390]\n",
      "epoch:28 step:26538 [D loss: 0.226553, acc.: 63.28%] [G loss: 0.409018]\n",
      "epoch:28 step:26539 [D loss: 0.215536, acc.: 63.28%] [G loss: 0.442561]\n",
      "epoch:28 step:26540 [D loss: 0.244541, acc.: 57.03%] [G loss: 0.405057]\n",
      "epoch:28 step:26541 [D loss: 0.227419, acc.: 64.06%] [G loss: 0.385504]\n",
      "epoch:28 step:26542 [D loss: 0.218446, acc.: 60.94%] [G loss: 0.422640]\n",
      "epoch:28 step:26543 [D loss: 0.205922, acc.: 65.62%] [G loss: 0.443460]\n",
      "epoch:28 step:26544 [D loss: 0.223861, acc.: 67.97%] [G loss: 0.423868]\n",
      "epoch:28 step:26545 [D loss: 0.226369, acc.: 62.50%] [G loss: 0.447262]\n",
      "epoch:28 step:26546 [D loss: 0.220741, acc.: 66.41%] [G loss: 0.427362]\n",
      "epoch:28 step:26547 [D loss: 0.218186, acc.: 63.28%] [G loss: 0.426226]\n",
      "epoch:28 step:26548 [D loss: 0.194252, acc.: 71.09%] [G loss: 0.450218]\n",
      "epoch:28 step:26549 [D loss: 0.192256, acc.: 72.66%] [G loss: 0.464624]\n",
      "epoch:28 step:26550 [D loss: 0.171794, acc.: 76.56%] [G loss: 0.489467]\n",
      "epoch:28 step:26551 [D loss: 0.203676, acc.: 64.06%] [G loss: 0.469284]\n",
      "epoch:28 step:26552 [D loss: 0.254626, acc.: 57.81%] [G loss: 0.450666]\n",
      "epoch:28 step:26553 [D loss: 0.252844, acc.: 50.00%] [G loss: 0.420456]\n",
      "epoch:28 step:26554 [D loss: 0.211756, acc.: 64.84%] [G loss: 0.420887]\n",
      "epoch:28 step:26555 [D loss: 0.207393, acc.: 72.66%] [G loss: 0.423267]\n",
      "epoch:28 step:26556 [D loss: 0.208455, acc.: 69.53%] [G loss: 0.457454]\n",
      "epoch:28 step:26557 [D loss: 0.196623, acc.: 66.41%] [G loss: 0.460527]\n",
      "epoch:28 step:26558 [D loss: 0.207478, acc.: 67.19%] [G loss: 0.453044]\n",
      "epoch:28 step:26559 [D loss: 0.232663, acc.: 62.50%] [G loss: 0.438505]\n",
      "epoch:28 step:26560 [D loss: 0.230317, acc.: 65.62%] [G loss: 0.463499]\n",
      "epoch:28 step:26561 [D loss: 0.194605, acc.: 68.75%] [G loss: 0.436830]\n",
      "epoch:28 step:26562 [D loss: 0.221365, acc.: 66.41%] [G loss: 0.402217]\n",
      "epoch:28 step:26563 [D loss: 0.243490, acc.: 59.38%] [G loss: 0.413116]\n",
      "epoch:28 step:26564 [D loss: 0.219280, acc.: 66.41%] [G loss: 0.442358]\n",
      "epoch:28 step:26565 [D loss: 0.258218, acc.: 60.94%] [G loss: 0.467356]\n",
      "epoch:28 step:26566 [D loss: 0.230689, acc.: 60.94%] [G loss: 0.406294]\n",
      "epoch:28 step:26567 [D loss: 0.227395, acc.: 62.50%] [G loss: 0.404273]\n",
      "epoch:28 step:26568 [D loss: 0.205558, acc.: 70.31%] [G loss: 0.442418]\n",
      "epoch:28 step:26569 [D loss: 0.236464, acc.: 60.94%] [G loss: 0.436512]\n",
      "epoch:28 step:26570 [D loss: 0.218205, acc.: 64.06%] [G loss: 0.436133]\n",
      "epoch:28 step:26571 [D loss: 0.221363, acc.: 64.84%] [G loss: 0.455921]\n",
      "epoch:28 step:26572 [D loss: 0.193828, acc.: 70.31%] [G loss: 0.452187]\n",
      "epoch:28 step:26573 [D loss: 0.223538, acc.: 59.38%] [G loss: 0.441880]\n",
      "epoch:28 step:26574 [D loss: 0.224295, acc.: 66.41%] [G loss: 0.393012]\n",
      "epoch:28 step:26575 [D loss: 0.212576, acc.: 65.62%] [G loss: 0.432619]\n",
      "epoch:28 step:26576 [D loss: 0.207005, acc.: 67.97%] [G loss: 0.441474]\n",
      "epoch:28 step:26577 [D loss: 0.269644, acc.: 52.34%] [G loss: 0.428004]\n",
      "epoch:28 step:26578 [D loss: 0.237808, acc.: 57.03%] [G loss: 0.485272]\n",
      "epoch:28 step:26579 [D loss: 0.226891, acc.: 64.06%] [G loss: 0.445269]\n",
      "epoch:28 step:26580 [D loss: 0.210499, acc.: 64.84%] [G loss: 0.473122]\n",
      "epoch:28 step:26581 [D loss: 0.237372, acc.: 55.47%] [G loss: 0.438667]\n",
      "epoch:28 step:26582 [D loss: 0.183764, acc.: 70.31%] [G loss: 0.471299]\n",
      "epoch:28 step:26583 [D loss: 0.178701, acc.: 74.22%] [G loss: 0.500860]\n",
      "epoch:28 step:26584 [D loss: 0.252638, acc.: 58.59%] [G loss: 0.410609]\n",
      "epoch:28 step:26585 [D loss: 0.259993, acc.: 50.78%] [G loss: 0.385484]\n",
      "epoch:28 step:26586 [D loss: 0.224825, acc.: 64.06%] [G loss: 0.361660]\n",
      "epoch:28 step:26587 [D loss: 0.222071, acc.: 62.50%] [G loss: 0.402878]\n",
      "epoch:28 step:26588 [D loss: 0.235935, acc.: 57.81%] [G loss: 0.409924]\n",
      "epoch:28 step:26589 [D loss: 0.217417, acc.: 63.28%] [G loss: 0.449708]\n",
      "epoch:28 step:26590 [D loss: 0.207261, acc.: 65.62%] [G loss: 0.467209]\n",
      "epoch:28 step:26591 [D loss: 0.225494, acc.: 64.84%] [G loss: 0.468298]\n",
      "epoch:28 step:26592 [D loss: 0.251403, acc.: 60.94%] [G loss: 0.449486]\n",
      "epoch:28 step:26593 [D loss: 0.216245, acc.: 62.50%] [G loss: 0.433405]\n",
      "epoch:28 step:26594 [D loss: 0.222239, acc.: 60.94%] [G loss: 0.436375]\n",
      "epoch:28 step:26595 [D loss: 0.215848, acc.: 67.19%] [G loss: 0.420101]\n",
      "epoch:28 step:26596 [D loss: 0.211171, acc.: 65.62%] [G loss: 0.443669]\n",
      "epoch:28 step:26597 [D loss: 0.197022, acc.: 75.78%] [G loss: 0.442926]\n",
      "epoch:28 step:26598 [D loss: 0.229340, acc.: 60.16%] [G loss: 0.425943]\n",
      "epoch:28 step:26599 [D loss: 0.231485, acc.: 61.72%] [G loss: 0.443707]\n",
      "epoch:28 step:26600 [D loss: 0.216179, acc.: 62.50%] [G loss: 0.428378]\n",
      "epoch:28 step:26601 [D loss: 0.229464, acc.: 59.38%] [G loss: 0.449034]\n",
      "epoch:28 step:26602 [D loss: 0.223139, acc.: 57.81%] [G loss: 0.410352]\n",
      "epoch:28 step:26603 [D loss: 0.218563, acc.: 61.72%] [G loss: 0.447427]\n",
      "epoch:28 step:26604 [D loss: 0.236195, acc.: 53.12%] [G loss: 0.430959]\n",
      "epoch:28 step:26605 [D loss: 0.215883, acc.: 67.97%] [G loss: 0.392622]\n",
      "epoch:28 step:26606 [D loss: 0.203600, acc.: 76.56%] [G loss: 0.406101]\n",
      "epoch:28 step:26607 [D loss: 0.203608, acc.: 68.75%] [G loss: 0.459711]\n",
      "epoch:28 step:26608 [D loss: 0.219955, acc.: 61.72%] [G loss: 0.436608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26609 [D loss: 0.234811, acc.: 57.81%] [G loss: 0.429013]\n",
      "epoch:28 step:26610 [D loss: 0.190372, acc.: 75.00%] [G loss: 0.427793]\n",
      "epoch:28 step:26611 [D loss: 0.239814, acc.: 60.16%] [G loss: 0.429729]\n",
      "epoch:28 step:26612 [D loss: 0.246904, acc.: 59.38%] [G loss: 0.448009]\n",
      "epoch:28 step:26613 [D loss: 0.240586, acc.: 57.03%] [G loss: 0.426610]\n",
      "epoch:28 step:26614 [D loss: 0.225397, acc.: 64.84%] [G loss: 0.408523]\n",
      "epoch:28 step:26615 [D loss: 0.214875, acc.: 65.62%] [G loss: 0.428979]\n",
      "epoch:28 step:26616 [D loss: 0.247152, acc.: 57.81%] [G loss: 0.400966]\n",
      "epoch:28 step:26617 [D loss: 0.224152, acc.: 60.16%] [G loss: 0.421919]\n",
      "epoch:28 step:26618 [D loss: 0.200322, acc.: 72.66%] [G loss: 0.470996]\n",
      "epoch:28 step:26619 [D loss: 0.240577, acc.: 57.03%] [G loss: 0.409510]\n",
      "epoch:28 step:26620 [D loss: 0.213803, acc.: 63.28%] [G loss: 0.434674]\n",
      "epoch:28 step:26621 [D loss: 0.198890, acc.: 68.75%] [G loss: 0.457960]\n",
      "epoch:28 step:26622 [D loss: 0.249613, acc.: 55.47%] [G loss: 0.419145]\n",
      "epoch:28 step:26623 [D loss: 0.214532, acc.: 66.41%] [G loss: 0.434714]\n",
      "epoch:28 step:26624 [D loss: 0.220919, acc.: 64.06%] [G loss: 0.418939]\n",
      "epoch:28 step:26625 [D loss: 0.247061, acc.: 57.81%] [G loss: 0.444821]\n",
      "epoch:28 step:26626 [D loss: 0.243019, acc.: 60.16%] [G loss: 0.455138]\n",
      "epoch:28 step:26627 [D loss: 0.211783, acc.: 66.41%] [G loss: 0.393634]\n",
      "epoch:28 step:26628 [D loss: 0.235401, acc.: 62.50%] [G loss: 0.411358]\n",
      "epoch:28 step:26629 [D loss: 0.223967, acc.: 60.94%] [G loss: 0.433792]\n",
      "epoch:28 step:26630 [D loss: 0.232779, acc.: 62.50%] [G loss: 0.464682]\n",
      "epoch:28 step:26631 [D loss: 0.193088, acc.: 70.31%] [G loss: 0.443493]\n",
      "epoch:28 step:26632 [D loss: 0.250141, acc.: 57.81%] [G loss: 0.409922]\n",
      "epoch:28 step:26633 [D loss: 0.210171, acc.: 64.06%] [G loss: 0.420855]\n",
      "epoch:28 step:26634 [D loss: 0.174277, acc.: 73.44%] [G loss: 0.460326]\n",
      "epoch:28 step:26635 [D loss: 0.211536, acc.: 60.94%] [G loss: 0.446071]\n",
      "epoch:28 step:26636 [D loss: 0.241594, acc.: 54.69%] [G loss: 0.392752]\n",
      "epoch:28 step:26637 [D loss: 0.258389, acc.: 55.47%] [G loss: 0.369953]\n",
      "epoch:28 step:26638 [D loss: 0.205861, acc.: 71.09%] [G loss: 0.416247]\n",
      "epoch:28 step:26639 [D loss: 0.211810, acc.: 65.62%] [G loss: 0.421381]\n",
      "epoch:28 step:26640 [D loss: 0.223788, acc.: 64.06%] [G loss: 0.439712]\n",
      "epoch:28 step:26641 [D loss: 0.198136, acc.: 71.09%] [G loss: 0.431213]\n",
      "epoch:28 step:26642 [D loss: 0.201692, acc.: 67.97%] [G loss: 0.475927]\n",
      "epoch:28 step:26643 [D loss: 0.220391, acc.: 64.84%] [G loss: 0.437232]\n",
      "epoch:28 step:26644 [D loss: 0.240351, acc.: 60.94%] [G loss: 0.445068]\n",
      "epoch:28 step:26645 [D loss: 0.211733, acc.: 65.62%] [G loss: 0.425344]\n",
      "epoch:28 step:26646 [D loss: 0.238772, acc.: 59.38%] [G loss: 0.425969]\n",
      "epoch:28 step:26647 [D loss: 0.268536, acc.: 52.34%] [G loss: 0.403107]\n",
      "epoch:28 step:26648 [D loss: 0.208628, acc.: 69.53%] [G loss: 0.398766]\n",
      "epoch:28 step:26649 [D loss: 0.240975, acc.: 60.94%] [G loss: 0.396204]\n",
      "epoch:28 step:26650 [D loss: 0.200099, acc.: 67.97%] [G loss: 0.435109]\n",
      "epoch:28 step:26651 [D loss: 0.201774, acc.: 69.53%] [G loss: 0.434291]\n",
      "epoch:28 step:26652 [D loss: 0.185078, acc.: 73.44%] [G loss: 0.520448]\n",
      "epoch:28 step:26653 [D loss: 0.256545, acc.: 54.69%] [G loss: 0.452799]\n",
      "epoch:28 step:26654 [D loss: 0.260435, acc.: 53.91%] [G loss: 0.458465]\n",
      "epoch:28 step:26655 [D loss: 0.271093, acc.: 54.69%] [G loss: 0.402804]\n",
      "epoch:28 step:26656 [D loss: 0.217694, acc.: 65.62%] [G loss: 0.466923]\n",
      "epoch:28 step:26657 [D loss: 0.266681, acc.: 53.12%] [G loss: 0.413317]\n",
      "epoch:28 step:26658 [D loss: 0.226186, acc.: 59.38%] [G loss: 0.380759]\n",
      "epoch:28 step:26659 [D loss: 0.208584, acc.: 66.41%] [G loss: 0.448571]\n",
      "epoch:28 step:26660 [D loss: 0.223162, acc.: 60.16%] [G loss: 0.388119]\n",
      "epoch:28 step:26661 [D loss: 0.205503, acc.: 60.94%] [G loss: 0.406805]\n",
      "epoch:28 step:26662 [D loss: 0.204509, acc.: 70.31%] [G loss: 0.454194]\n",
      "epoch:28 step:26663 [D loss: 0.220131, acc.: 64.06%] [G loss: 0.415747]\n",
      "epoch:28 step:26664 [D loss: 0.221181, acc.: 66.41%] [G loss: 0.441422]\n",
      "epoch:28 step:26665 [D loss: 0.193329, acc.: 72.66%] [G loss: 0.483093]\n",
      "epoch:28 step:26666 [D loss: 0.199091, acc.: 71.88%] [G loss: 0.477362]\n",
      "epoch:28 step:26667 [D loss: 0.221421, acc.: 64.84%] [G loss: 0.414135]\n",
      "epoch:28 step:26668 [D loss: 0.244699, acc.: 56.25%] [G loss: 0.391078]\n",
      "epoch:28 step:26669 [D loss: 0.213974, acc.: 66.41%] [G loss: 0.460590]\n",
      "epoch:28 step:26670 [D loss: 0.194654, acc.: 68.75%] [G loss: 0.447546]\n",
      "epoch:28 step:26671 [D loss: 0.213929, acc.: 67.19%] [G loss: 0.456004]\n",
      "epoch:28 step:26672 [D loss: 0.196626, acc.: 66.41%] [G loss: 0.443421]\n",
      "epoch:28 step:26673 [D loss: 0.294982, acc.: 48.44%] [G loss: 0.430659]\n",
      "epoch:28 step:26674 [D loss: 0.233050, acc.: 57.03%] [G loss: 0.435288]\n",
      "epoch:28 step:26675 [D loss: 0.223471, acc.: 62.50%] [G loss: 0.452861]\n",
      "epoch:28 step:26676 [D loss: 0.207639, acc.: 70.31%] [G loss: 0.444261]\n",
      "epoch:28 step:26677 [D loss: 0.198306, acc.: 66.41%] [G loss: 0.433445]\n",
      "epoch:28 step:26678 [D loss: 0.242246, acc.: 56.25%] [G loss: 0.434814]\n",
      "epoch:28 step:26679 [D loss: 0.217410, acc.: 69.53%] [G loss: 0.421360]\n",
      "epoch:28 step:26680 [D loss: 0.216947, acc.: 67.97%] [G loss: 0.392668]\n",
      "epoch:28 step:26681 [D loss: 0.209821, acc.: 68.75%] [G loss: 0.408543]\n",
      "epoch:28 step:26682 [D loss: 0.239470, acc.: 58.59%] [G loss: 0.437008]\n",
      "epoch:28 step:26683 [D loss: 0.208422, acc.: 67.97%] [G loss: 0.455768]\n",
      "epoch:28 step:26684 [D loss: 0.229217, acc.: 64.84%] [G loss: 0.452799]\n",
      "epoch:28 step:26685 [D loss: 0.230906, acc.: 61.72%] [G loss: 0.412893]\n",
      "epoch:28 step:26686 [D loss: 0.210825, acc.: 68.75%] [G loss: 0.453058]\n",
      "epoch:28 step:26687 [D loss: 0.198327, acc.: 69.53%] [G loss: 0.427167]\n",
      "epoch:28 step:26688 [D loss: 0.213191, acc.: 67.19%] [G loss: 0.478263]\n",
      "epoch:28 step:26689 [D loss: 0.188512, acc.: 72.66%] [G loss: 0.444038]\n",
      "epoch:28 step:26690 [D loss: 0.234419, acc.: 63.28%] [G loss: 0.421332]\n",
      "epoch:28 step:26691 [D loss: 0.236474, acc.: 66.41%] [G loss: 0.420831]\n",
      "epoch:28 step:26692 [D loss: 0.214421, acc.: 66.41%] [G loss: 0.447607]\n",
      "epoch:28 step:26693 [D loss: 0.224926, acc.: 63.28%] [G loss: 0.484897]\n",
      "epoch:28 step:26694 [D loss: 0.282751, acc.: 46.88%] [G loss: 0.411459]\n",
      "epoch:28 step:26695 [D loss: 0.228232, acc.: 58.59%] [G loss: 0.439448]\n",
      "epoch:28 step:26696 [D loss: 0.231526, acc.: 60.16%] [G loss: 0.427347]\n",
      "epoch:28 step:26697 [D loss: 0.219405, acc.: 60.94%] [G loss: 0.438771]\n",
      "epoch:28 step:26698 [D loss: 0.211735, acc.: 64.06%] [G loss: 0.404610]\n",
      "epoch:28 step:26699 [D loss: 0.236607, acc.: 56.25%] [G loss: 0.404850]\n",
      "epoch:28 step:26700 [D loss: 0.210608, acc.: 64.84%] [G loss: 0.443746]\n",
      "epoch:28 step:26701 [D loss: 0.212080, acc.: 69.53%] [G loss: 0.454441]\n",
      "epoch:28 step:26702 [D loss: 0.220321, acc.: 65.62%] [G loss: 0.435228]\n",
      "epoch:28 step:26703 [D loss: 0.238902, acc.: 65.62%] [G loss: 0.397158]\n",
      "epoch:28 step:26704 [D loss: 0.180087, acc.: 78.12%] [G loss: 0.456639]\n",
      "epoch:28 step:26705 [D loss: 0.208783, acc.: 68.75%] [G loss: 0.459749]\n",
      "epoch:28 step:26706 [D loss: 0.214370, acc.: 64.84%] [G loss: 0.450976]\n",
      "epoch:28 step:26707 [D loss: 0.191312, acc.: 70.31%] [G loss: 0.503239]\n",
      "epoch:28 step:26708 [D loss: 0.218276, acc.: 63.28%] [G loss: 0.484493]\n",
      "epoch:28 step:26709 [D loss: 0.267252, acc.: 52.34%] [G loss: 0.433023]\n",
      "epoch:28 step:26710 [D loss: 0.218028, acc.: 70.31%] [G loss: 0.402117]\n",
      "epoch:28 step:26711 [D loss: 0.219360, acc.: 67.97%] [G loss: 0.459062]\n",
      "epoch:28 step:26712 [D loss: 0.207956, acc.: 70.31%] [G loss: 0.438287]\n",
      "epoch:28 step:26713 [D loss: 0.248711, acc.: 53.91%] [G loss: 0.416402]\n",
      "epoch:28 step:26714 [D loss: 0.250802, acc.: 59.38%] [G loss: 0.422396]\n",
      "epoch:28 step:26715 [D loss: 0.205908, acc.: 71.09%] [G loss: 0.393266]\n",
      "epoch:28 step:26716 [D loss: 0.215202, acc.: 62.50%] [G loss: 0.430383]\n",
      "epoch:28 step:26717 [D loss: 0.182389, acc.: 72.66%] [G loss: 0.480581]\n",
      "epoch:28 step:26718 [D loss: 0.256423, acc.: 55.47%] [G loss: 0.414080]\n",
      "epoch:28 step:26719 [D loss: 0.228257, acc.: 60.16%] [G loss: 0.423234]\n",
      "epoch:28 step:26720 [D loss: 0.181771, acc.: 70.31%] [G loss: 0.502131]\n",
      "epoch:28 step:26721 [D loss: 0.193845, acc.: 72.66%] [G loss: 0.440931]\n",
      "epoch:28 step:26722 [D loss: 0.258498, acc.: 47.66%] [G loss: 0.429877]\n",
      "epoch:28 step:26723 [D loss: 0.235088, acc.: 61.72%] [G loss: 0.412863]\n",
      "epoch:28 step:26724 [D loss: 0.210340, acc.: 65.62%] [G loss: 0.429654]\n",
      "epoch:28 step:26725 [D loss: 0.219504, acc.: 62.50%] [G loss: 0.432273]\n",
      "epoch:28 step:26726 [D loss: 0.231420, acc.: 64.06%] [G loss: 0.433162]\n",
      "epoch:28 step:26727 [D loss: 0.205489, acc.: 67.19%] [G loss: 0.448099]\n",
      "epoch:28 step:26728 [D loss: 0.243914, acc.: 55.47%] [G loss: 0.386063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26729 [D loss: 0.217952, acc.: 67.19%] [G loss: 0.427345]\n",
      "epoch:28 step:26730 [D loss: 0.195711, acc.: 71.88%] [G loss: 0.427880]\n",
      "epoch:28 step:26731 [D loss: 0.172283, acc.: 75.78%] [G loss: 0.507733]\n",
      "epoch:28 step:26732 [D loss: 0.206507, acc.: 63.28%] [G loss: 0.463238]\n",
      "epoch:28 step:26733 [D loss: 0.233887, acc.: 59.38%] [G loss: 0.457378]\n",
      "epoch:28 step:26734 [D loss: 0.216466, acc.: 65.62%] [G loss: 0.472877]\n",
      "epoch:28 step:26735 [D loss: 0.195427, acc.: 67.19%] [G loss: 0.458530]\n",
      "epoch:28 step:26736 [D loss: 0.263381, acc.: 54.69%] [G loss: 0.432320]\n",
      "epoch:28 step:26737 [D loss: 0.266023, acc.: 50.00%] [G loss: 0.427457]\n",
      "epoch:28 step:26738 [D loss: 0.245556, acc.: 50.78%] [G loss: 0.415675]\n",
      "epoch:28 step:26739 [D loss: 0.221152, acc.: 65.62%] [G loss: 0.430911]\n",
      "epoch:28 step:26740 [D loss: 0.186384, acc.: 77.34%] [G loss: 0.427638]\n",
      "epoch:28 step:26741 [D loss: 0.181589, acc.: 72.66%] [G loss: 0.520701]\n",
      "epoch:28 step:26742 [D loss: 0.237978, acc.: 54.69%] [G loss: 0.455751]\n",
      "epoch:28 step:26743 [D loss: 0.184973, acc.: 71.09%] [G loss: 0.444325]\n",
      "epoch:28 step:26744 [D loss: 0.193250, acc.: 69.53%] [G loss: 0.492004]\n",
      "epoch:28 step:26745 [D loss: 0.247002, acc.: 54.69%] [G loss: 0.455351]\n",
      "epoch:28 step:26746 [D loss: 0.232912, acc.: 61.72%] [G loss: 0.444293]\n",
      "epoch:28 step:26747 [D loss: 0.248254, acc.: 58.59%] [G loss: 0.416482]\n",
      "epoch:28 step:26748 [D loss: 0.212655, acc.: 66.41%] [G loss: 0.449362]\n",
      "epoch:28 step:26749 [D loss: 0.229582, acc.: 62.50%] [G loss: 0.445513]\n",
      "epoch:28 step:26750 [D loss: 0.219534, acc.: 62.50%] [G loss: 0.456521]\n",
      "epoch:28 step:26751 [D loss: 0.208192, acc.: 66.41%] [G loss: 0.471651]\n",
      "epoch:28 step:26752 [D loss: 0.194054, acc.: 71.88%] [G loss: 0.463652]\n",
      "epoch:28 step:26753 [D loss: 0.245651, acc.: 56.25%] [G loss: 0.400739]\n",
      "epoch:28 step:26754 [D loss: 0.244931, acc.: 55.47%] [G loss: 0.376982]\n",
      "epoch:28 step:26755 [D loss: 0.207549, acc.: 69.53%] [G loss: 0.407035]\n",
      "epoch:28 step:26756 [D loss: 0.214192, acc.: 63.28%] [G loss: 0.435289]\n",
      "epoch:28 step:26757 [D loss: 0.199634, acc.: 66.41%] [G loss: 0.431631]\n",
      "epoch:28 step:26758 [D loss: 0.220460, acc.: 65.62%] [G loss: 0.402451]\n",
      "epoch:28 step:26759 [D loss: 0.198253, acc.: 71.09%] [G loss: 0.414154]\n",
      "epoch:28 step:26760 [D loss: 0.237922, acc.: 60.94%] [G loss: 0.438778]\n",
      "epoch:28 step:26761 [D loss: 0.215425, acc.: 64.84%] [G loss: 0.432520]\n",
      "epoch:28 step:26762 [D loss: 0.208693, acc.: 65.62%] [G loss: 0.440828]\n",
      "epoch:28 step:26763 [D loss: 0.252129, acc.: 54.69%] [G loss: 0.463019]\n",
      "epoch:28 step:26764 [D loss: 0.263937, acc.: 53.12%] [G loss: 0.448099]\n",
      "epoch:28 step:26765 [D loss: 0.252940, acc.: 54.69%] [G loss: 0.415296]\n",
      "epoch:28 step:26766 [D loss: 0.240951, acc.: 59.38%] [G loss: 0.434632]\n",
      "epoch:28 step:26767 [D loss: 0.265194, acc.: 53.91%] [G loss: 0.409195]\n",
      "epoch:28 step:26768 [D loss: 0.237809, acc.: 61.72%] [G loss: 0.395477]\n",
      "epoch:28 step:26769 [D loss: 0.239227, acc.: 58.59%] [G loss: 0.437041]\n",
      "epoch:28 step:26770 [D loss: 0.191882, acc.: 71.88%] [G loss: 0.458213]\n",
      "epoch:28 step:26771 [D loss: 0.249397, acc.: 54.69%] [G loss: 0.416183]\n",
      "epoch:28 step:26772 [D loss: 0.213454, acc.: 64.84%] [G loss: 0.387417]\n",
      "epoch:28 step:26773 [D loss: 0.229081, acc.: 60.94%] [G loss: 0.435662]\n",
      "epoch:28 step:26774 [D loss: 0.234421, acc.: 59.38%] [G loss: 0.427075]\n",
      "epoch:28 step:26775 [D loss: 0.216058, acc.: 64.84%] [G loss: 0.451460]\n",
      "epoch:28 step:26776 [D loss: 0.215272, acc.: 60.16%] [G loss: 0.413067]\n",
      "epoch:28 step:26777 [D loss: 0.229075, acc.: 57.81%] [G loss: 0.406817]\n",
      "epoch:28 step:26778 [D loss: 0.274220, acc.: 47.66%] [G loss: 0.405398]\n",
      "epoch:28 step:26779 [D loss: 0.238275, acc.: 62.50%] [G loss: 0.396139]\n",
      "epoch:28 step:26780 [D loss: 0.214665, acc.: 68.75%] [G loss: 0.404910]\n",
      "epoch:28 step:26781 [D loss: 0.232681, acc.: 63.28%] [G loss: 0.449105]\n",
      "epoch:28 step:26782 [D loss: 0.224446, acc.: 67.97%] [G loss: 0.411495]\n",
      "epoch:28 step:26783 [D loss: 0.205482, acc.: 69.53%] [G loss: 0.426657]\n",
      "epoch:28 step:26784 [D loss: 0.199351, acc.: 65.62%] [G loss: 0.452014]\n",
      "epoch:28 step:26785 [D loss: 0.208670, acc.: 67.97%] [G loss: 0.452909]\n",
      "epoch:28 step:26786 [D loss: 0.196620, acc.: 73.44%] [G loss: 0.476297]\n",
      "epoch:28 step:26787 [D loss: 0.210906, acc.: 67.19%] [G loss: 0.425448]\n",
      "epoch:28 step:26788 [D loss: 0.210453, acc.: 64.06%] [G loss: 0.453023]\n",
      "epoch:28 step:26789 [D loss: 0.226828, acc.: 64.06%] [G loss: 0.450078]\n",
      "epoch:28 step:26790 [D loss: 0.215985, acc.: 71.88%] [G loss: 0.434102]\n",
      "epoch:28 step:26791 [D loss: 0.204561, acc.: 67.19%] [G loss: 0.470614]\n",
      "epoch:28 step:26792 [D loss: 0.223805, acc.: 64.84%] [G loss: 0.397915]\n",
      "epoch:28 step:26793 [D loss: 0.207906, acc.: 67.97%] [G loss: 0.456144]\n",
      "epoch:28 step:26794 [D loss: 0.200745, acc.: 71.09%] [G loss: 0.468471]\n",
      "epoch:28 step:26795 [D loss: 0.263262, acc.: 49.22%] [G loss: 0.452145]\n",
      "epoch:28 step:26796 [D loss: 0.251345, acc.: 55.47%] [G loss: 0.430727]\n",
      "epoch:28 step:26797 [D loss: 0.225999, acc.: 60.94%] [G loss: 0.465353]\n",
      "epoch:28 step:26798 [D loss: 0.201229, acc.: 66.41%] [G loss: 0.461446]\n",
      "epoch:28 step:26799 [D loss: 0.185664, acc.: 75.00%] [G loss: 0.484240]\n",
      "epoch:28 step:26800 [D loss: 0.207514, acc.: 69.53%] [G loss: 0.478786]\n",
      "epoch:28 step:26801 [D loss: 0.230071, acc.: 63.28%] [G loss: 0.480143]\n",
      "epoch:28 step:26802 [D loss: 0.272208, acc.: 50.00%] [G loss: 0.458066]\n",
      "epoch:28 step:26803 [D loss: 0.227981, acc.: 61.72%] [G loss: 0.454854]\n",
      "epoch:28 step:26804 [D loss: 0.203864, acc.: 65.62%] [G loss: 0.449873]\n",
      "epoch:28 step:26805 [D loss: 0.225702, acc.: 62.50%] [G loss: 0.402111]\n",
      "epoch:28 step:26806 [D loss: 0.236497, acc.: 61.72%] [G loss: 0.399518]\n",
      "epoch:28 step:26807 [D loss: 0.196745, acc.: 67.19%] [G loss: 0.431867]\n",
      "epoch:28 step:26808 [D loss: 0.240469, acc.: 61.72%] [G loss: 0.414002]\n",
      "epoch:28 step:26809 [D loss: 0.252774, acc.: 54.69%] [G loss: 0.392954]\n",
      "epoch:28 step:26810 [D loss: 0.196755, acc.: 69.53%] [G loss: 0.467347]\n",
      "epoch:28 step:26811 [D loss: 0.223468, acc.: 65.62%] [G loss: 0.466562]\n",
      "epoch:28 step:26812 [D loss: 0.219729, acc.: 67.19%] [G loss: 0.433035]\n",
      "epoch:28 step:26813 [D loss: 0.218771, acc.: 64.84%] [G loss: 0.440669]\n",
      "epoch:28 step:26814 [D loss: 0.240208, acc.: 58.59%] [G loss: 0.389858]\n",
      "epoch:28 step:26815 [D loss: 0.240961, acc.: 55.47%] [G loss: 0.389341]\n",
      "epoch:28 step:26816 [D loss: 0.218556, acc.: 63.28%] [G loss: 0.423703]\n",
      "epoch:28 step:26817 [D loss: 0.203370, acc.: 71.88%] [G loss: 0.467954]\n",
      "epoch:28 step:26818 [D loss: 0.204294, acc.: 65.62%] [G loss: 0.413415]\n",
      "epoch:28 step:26819 [D loss: 0.226025, acc.: 64.06%] [G loss: 0.432046]\n",
      "epoch:28 step:26820 [D loss: 0.246692, acc.: 58.59%] [G loss: 0.412730]\n",
      "epoch:28 step:26821 [D loss: 0.209980, acc.: 67.97%] [G loss: 0.415842]\n",
      "epoch:28 step:26822 [D loss: 0.229122, acc.: 62.50%] [G loss: 0.433251]\n",
      "epoch:28 step:26823 [D loss: 0.231886, acc.: 62.50%] [G loss: 0.462993]\n",
      "epoch:28 step:26824 [D loss: 0.199312, acc.: 67.19%] [G loss: 0.439958]\n",
      "epoch:28 step:26825 [D loss: 0.212541, acc.: 60.94%] [G loss: 0.470149]\n",
      "epoch:28 step:26826 [D loss: 0.233702, acc.: 60.16%] [G loss: 0.479928]\n",
      "epoch:28 step:26827 [D loss: 0.216806, acc.: 63.28%] [G loss: 0.465193]\n",
      "epoch:28 step:26828 [D loss: 0.198327, acc.: 67.97%] [G loss: 0.452257]\n",
      "epoch:28 step:26829 [D loss: 0.219554, acc.: 66.41%] [G loss: 0.435284]\n",
      "epoch:28 step:26830 [D loss: 0.225007, acc.: 61.72%] [G loss: 0.398528]\n",
      "epoch:28 step:26831 [D loss: 0.209749, acc.: 64.06%] [G loss: 0.408271]\n",
      "epoch:28 step:26832 [D loss: 0.213692, acc.: 64.84%] [G loss: 0.433974]\n",
      "epoch:28 step:26833 [D loss: 0.242452, acc.: 54.69%] [G loss: 0.422758]\n",
      "epoch:28 step:26834 [D loss: 0.218780, acc.: 66.41%] [G loss: 0.429398]\n",
      "epoch:28 step:26835 [D loss: 0.199841, acc.: 70.31%] [G loss: 0.432702]\n",
      "epoch:28 step:26836 [D loss: 0.222138, acc.: 60.94%] [G loss: 0.455251]\n",
      "epoch:28 step:26837 [D loss: 0.221741, acc.: 62.50%] [G loss: 0.409750]\n",
      "epoch:28 step:26838 [D loss: 0.237881, acc.: 59.38%] [G loss: 0.422295]\n",
      "epoch:28 step:26839 [D loss: 0.222853, acc.: 67.19%] [G loss: 0.393618]\n",
      "epoch:28 step:26840 [D loss: 0.190800, acc.: 72.66%] [G loss: 0.458095]\n",
      "epoch:28 step:26841 [D loss: 0.222492, acc.: 60.94%] [G loss: 0.431048]\n",
      "epoch:28 step:26842 [D loss: 0.236854, acc.: 58.59%] [G loss: 0.438742]\n",
      "epoch:28 step:26843 [D loss: 0.220273, acc.: 61.72%] [G loss: 0.411040]\n",
      "epoch:28 step:26844 [D loss: 0.222334, acc.: 64.84%] [G loss: 0.403733]\n",
      "epoch:28 step:26845 [D loss: 0.234817, acc.: 59.38%] [G loss: 0.411797]\n",
      "epoch:28 step:26846 [D loss: 0.213711, acc.: 67.19%] [G loss: 0.418263]\n",
      "epoch:28 step:26847 [D loss: 0.211441, acc.: 66.41%] [G loss: 0.417981]\n",
      "epoch:28 step:26848 [D loss: 0.234515, acc.: 58.59%] [G loss: 0.425878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26849 [D loss: 0.230222, acc.: 60.94%] [G loss: 0.438866]\n",
      "epoch:28 step:26850 [D loss: 0.276754, acc.: 50.00%] [G loss: 0.361176]\n",
      "epoch:28 step:26851 [D loss: 0.266254, acc.: 47.66%] [G loss: 0.393017]\n",
      "epoch:28 step:26852 [D loss: 0.219401, acc.: 68.75%] [G loss: 0.443133]\n",
      "epoch:28 step:26853 [D loss: 0.215596, acc.: 67.19%] [G loss: 0.462483]\n",
      "epoch:28 step:26854 [D loss: 0.218732, acc.: 67.19%] [G loss: 0.421285]\n",
      "epoch:28 step:26855 [D loss: 0.234080, acc.: 60.94%] [G loss: 0.444499]\n",
      "epoch:28 step:26856 [D loss: 0.201661, acc.: 68.75%] [G loss: 0.419207]\n",
      "epoch:28 step:26857 [D loss: 0.240111, acc.: 53.12%] [G loss: 0.430746]\n",
      "epoch:28 step:26858 [D loss: 0.231918, acc.: 58.59%] [G loss: 0.420819]\n",
      "epoch:28 step:26859 [D loss: 0.211861, acc.: 65.62%] [G loss: 0.425742]\n",
      "epoch:28 step:26860 [D loss: 0.182232, acc.: 71.88%] [G loss: 0.458983]\n",
      "epoch:28 step:26861 [D loss: 0.224741, acc.: 64.84%] [G loss: 0.443647]\n",
      "epoch:28 step:26862 [D loss: 0.236087, acc.: 60.94%] [G loss: 0.408221]\n",
      "epoch:28 step:26863 [D loss: 0.209589, acc.: 69.53%] [G loss: 0.444745]\n",
      "epoch:28 step:26864 [D loss: 0.210160, acc.: 67.19%] [G loss: 0.413018]\n",
      "epoch:28 step:26865 [D loss: 0.210989, acc.: 65.62%] [G loss: 0.431324]\n",
      "epoch:28 step:26866 [D loss: 0.231243, acc.: 64.06%] [G loss: 0.426139]\n",
      "epoch:28 step:26867 [D loss: 0.196607, acc.: 69.53%] [G loss: 0.407992]\n",
      "epoch:28 step:26868 [D loss: 0.208384, acc.: 67.97%] [G loss: 0.438124]\n",
      "epoch:28 step:26869 [D loss: 0.210098, acc.: 64.06%] [G loss: 0.461605]\n",
      "epoch:28 step:26870 [D loss: 0.183317, acc.: 75.00%] [G loss: 0.463151]\n",
      "epoch:28 step:26871 [D loss: 0.196027, acc.: 68.75%] [G loss: 0.467834]\n",
      "epoch:28 step:26872 [D loss: 0.239625, acc.: 64.84%] [G loss: 0.454564]\n",
      "epoch:28 step:26873 [D loss: 0.212916, acc.: 67.97%] [G loss: 0.449445]\n",
      "epoch:28 step:26874 [D loss: 0.223006, acc.: 64.84%] [G loss: 0.460853]\n",
      "epoch:28 step:26875 [D loss: 0.229381, acc.: 60.94%] [G loss: 0.406958]\n",
      "epoch:28 step:26876 [D loss: 0.222631, acc.: 61.72%] [G loss: 0.429417]\n",
      "epoch:28 step:26877 [D loss: 0.216439, acc.: 61.72%] [G loss: 0.428987]\n",
      "epoch:28 step:26878 [D loss: 0.202624, acc.: 69.53%] [G loss: 0.503757]\n",
      "epoch:28 step:26879 [D loss: 0.232649, acc.: 59.38%] [G loss: 0.460587]\n",
      "epoch:28 step:26880 [D loss: 0.217716, acc.: 66.41%] [G loss: 0.443416]\n",
      "epoch:28 step:26881 [D loss: 0.238989, acc.: 57.03%] [G loss: 0.410843]\n",
      "epoch:28 step:26882 [D loss: 0.222636, acc.: 61.72%] [G loss: 0.429510]\n",
      "epoch:28 step:26883 [D loss: 0.199401, acc.: 69.53%] [G loss: 0.492562]\n",
      "epoch:28 step:26884 [D loss: 0.160741, acc.: 82.03%] [G loss: 0.538577]\n",
      "epoch:28 step:26885 [D loss: 0.201723, acc.: 69.53%] [G loss: 0.505465]\n",
      "epoch:28 step:26886 [D loss: 0.194040, acc.: 68.75%] [G loss: 0.458034]\n",
      "epoch:28 step:26887 [D loss: 0.245072, acc.: 60.94%] [G loss: 0.441607]\n",
      "epoch:28 step:26888 [D loss: 0.202674, acc.: 67.97%] [G loss: 0.452412]\n",
      "epoch:28 step:26889 [D loss: 0.184696, acc.: 75.00%] [G loss: 0.477045]\n",
      "epoch:28 step:26890 [D loss: 0.217958, acc.: 66.41%] [G loss: 0.456496]\n",
      "epoch:28 step:26891 [D loss: 0.234964, acc.: 59.38%] [G loss: 0.436981]\n",
      "epoch:28 step:26892 [D loss: 0.211098, acc.: 65.62%] [G loss: 0.451126]\n",
      "epoch:28 step:26893 [D loss: 0.222926, acc.: 64.06%] [G loss: 0.434329]\n",
      "epoch:28 step:26894 [D loss: 0.239469, acc.: 55.47%] [G loss: 0.421843]\n",
      "epoch:28 step:26895 [D loss: 0.210289, acc.: 67.97%] [G loss: 0.475478]\n",
      "epoch:28 step:26896 [D loss: 0.192316, acc.: 72.66%] [G loss: 0.461687]\n",
      "epoch:28 step:26897 [D loss: 0.199698, acc.: 69.53%] [G loss: 0.435857]\n",
      "epoch:28 step:26898 [D loss: 0.211474, acc.: 63.28%] [G loss: 0.434175]\n",
      "epoch:28 step:26899 [D loss: 0.229375, acc.: 62.50%] [G loss: 0.457935]\n",
      "epoch:28 step:26900 [D loss: 0.241103, acc.: 61.72%] [G loss: 0.420703]\n",
      "epoch:28 step:26901 [D loss: 0.226483, acc.: 64.06%] [G loss: 0.467256]\n",
      "epoch:28 step:26902 [D loss: 0.209193, acc.: 64.84%] [G loss: 0.499202]\n",
      "epoch:28 step:26903 [D loss: 0.233150, acc.: 61.72%] [G loss: 0.413567]\n",
      "epoch:28 step:26904 [D loss: 0.227198, acc.: 62.50%] [G loss: 0.457474]\n",
      "epoch:28 step:26905 [D loss: 0.239916, acc.: 58.59%] [G loss: 0.420662]\n",
      "epoch:28 step:26906 [D loss: 0.224032, acc.: 60.16%] [G loss: 0.386249]\n",
      "epoch:28 step:26907 [D loss: 0.238739, acc.: 62.50%] [G loss: 0.395052]\n",
      "epoch:28 step:26908 [D loss: 0.228832, acc.: 55.47%] [G loss: 0.419418]\n",
      "epoch:28 step:26909 [D loss: 0.225881, acc.: 64.06%] [G loss: 0.431887]\n",
      "epoch:28 step:26910 [D loss: 0.209626, acc.: 68.75%] [G loss: 0.458866]\n",
      "epoch:28 step:26911 [D loss: 0.248010, acc.: 55.47%] [G loss: 0.437422]\n",
      "epoch:28 step:26912 [D loss: 0.209911, acc.: 69.53%] [G loss: 0.436001]\n",
      "epoch:28 step:26913 [D loss: 0.204884, acc.: 67.97%] [G loss: 0.464381]\n",
      "epoch:28 step:26914 [D loss: 0.236343, acc.: 65.62%] [G loss: 0.426182]\n",
      "epoch:28 step:26915 [D loss: 0.201246, acc.: 69.53%] [G loss: 0.463623]\n",
      "epoch:28 step:26916 [D loss: 0.234153, acc.: 61.72%] [G loss: 0.430791]\n",
      "epoch:28 step:26917 [D loss: 0.195547, acc.: 71.09%] [G loss: 0.445251]\n",
      "epoch:28 step:26918 [D loss: 0.233121, acc.: 63.28%] [G loss: 0.417248]\n",
      "epoch:28 step:26919 [D loss: 0.222720, acc.: 58.59%] [G loss: 0.423544]\n",
      "epoch:28 step:26920 [D loss: 0.224423, acc.: 60.16%] [G loss: 0.385507]\n",
      "epoch:28 step:26921 [D loss: 0.200594, acc.: 68.75%] [G loss: 0.448917]\n",
      "epoch:28 step:26922 [D loss: 0.198860, acc.: 68.75%] [G loss: 0.434476]\n",
      "epoch:28 step:26923 [D loss: 0.220268, acc.: 61.72%] [G loss: 0.450025]\n",
      "epoch:28 step:26924 [D loss: 0.222087, acc.: 60.94%] [G loss: 0.416157]\n",
      "epoch:28 step:26925 [D loss: 0.194139, acc.: 66.41%] [G loss: 0.496360]\n",
      "epoch:28 step:26926 [D loss: 0.218861, acc.: 67.19%] [G loss: 0.444660]\n",
      "epoch:28 step:26927 [D loss: 0.221144, acc.: 64.06%] [G loss: 0.421681]\n",
      "epoch:28 step:26928 [D loss: 0.190600, acc.: 71.09%] [G loss: 0.465519]\n",
      "epoch:28 step:26929 [D loss: 0.196193, acc.: 71.09%] [G loss: 0.456944]\n",
      "epoch:28 step:26930 [D loss: 0.173425, acc.: 77.34%] [G loss: 0.473957]\n",
      "epoch:28 step:26931 [D loss: 0.206140, acc.: 72.66%] [G loss: 0.510313]\n",
      "epoch:28 step:26932 [D loss: 0.264726, acc.: 53.12%] [G loss: 0.419036]\n",
      "epoch:28 step:26933 [D loss: 0.254062, acc.: 55.47%] [G loss: 0.402898]\n",
      "epoch:28 step:26934 [D loss: 0.253187, acc.: 57.81%] [G loss: 0.428837]\n",
      "epoch:28 step:26935 [D loss: 0.213646, acc.: 64.06%] [G loss: 0.451747]\n",
      "epoch:28 step:26936 [D loss: 0.217420, acc.: 62.50%] [G loss: 0.441412]\n",
      "epoch:28 step:26937 [D loss: 0.212601, acc.: 64.84%] [G loss: 0.429588]\n",
      "epoch:28 step:26938 [D loss: 0.247788, acc.: 57.03%] [G loss: 0.442835]\n",
      "epoch:28 step:26939 [D loss: 0.242111, acc.: 56.25%] [G loss: 0.411019]\n",
      "epoch:28 step:26940 [D loss: 0.229369, acc.: 59.38%] [G loss: 0.432416]\n",
      "epoch:28 step:26941 [D loss: 0.212161, acc.: 67.19%] [G loss: 0.472969]\n",
      "epoch:28 step:26942 [D loss: 0.203442, acc.: 69.53%] [G loss: 0.441291]\n",
      "epoch:28 step:26943 [D loss: 0.212676, acc.: 66.41%] [G loss: 0.450913]\n",
      "epoch:28 step:26944 [D loss: 0.205808, acc.: 71.09%] [G loss: 0.472013]\n",
      "epoch:28 step:26945 [D loss: 0.223024, acc.: 64.84%] [G loss: 0.413949]\n",
      "epoch:28 step:26946 [D loss: 0.232272, acc.: 61.72%] [G loss: 0.458597]\n",
      "epoch:28 step:26947 [D loss: 0.239725, acc.: 59.38%] [G loss: 0.434250]\n",
      "epoch:28 step:26948 [D loss: 0.205187, acc.: 68.75%] [G loss: 0.427430]\n",
      "epoch:28 step:26949 [D loss: 0.210352, acc.: 63.28%] [G loss: 0.464139]\n",
      "epoch:28 step:26950 [D loss: 0.245416, acc.: 55.47%] [G loss: 0.456746]\n",
      "epoch:28 step:26951 [D loss: 0.220869, acc.: 65.62%] [G loss: 0.441855]\n",
      "epoch:28 step:26952 [D loss: 0.238248, acc.: 56.25%] [G loss: 0.396888]\n",
      "epoch:28 step:26953 [D loss: 0.225318, acc.: 58.59%] [G loss: 0.427314]\n",
      "epoch:28 step:26954 [D loss: 0.200084, acc.: 69.53%] [G loss: 0.427473]\n",
      "epoch:28 step:26955 [D loss: 0.196182, acc.: 67.97%] [G loss: 0.440822]\n",
      "epoch:28 step:26956 [D loss: 0.192838, acc.: 69.53%] [G loss: 0.469859]\n",
      "epoch:28 step:26957 [D loss: 0.241668, acc.: 57.03%] [G loss: 0.439492]\n",
      "epoch:28 step:26958 [D loss: 0.238626, acc.: 57.81%] [G loss: 0.438053]\n",
      "epoch:28 step:26959 [D loss: 0.224987, acc.: 59.38%] [G loss: 0.415354]\n",
      "epoch:28 step:26960 [D loss: 0.209431, acc.: 69.53%] [G loss: 0.460526]\n",
      "epoch:28 step:26961 [D loss: 0.227089, acc.: 60.16%] [G loss: 0.448737]\n",
      "epoch:28 step:26962 [D loss: 0.223856, acc.: 63.28%] [G loss: 0.448890]\n",
      "epoch:28 step:26963 [D loss: 0.227153, acc.: 59.38%] [G loss: 0.423513]\n",
      "epoch:28 step:26964 [D loss: 0.219262, acc.: 66.41%] [G loss: 0.446634]\n",
      "epoch:28 step:26965 [D loss: 0.221930, acc.: 61.72%] [G loss: 0.429089]\n",
      "epoch:28 step:26966 [D loss: 0.219425, acc.: 61.72%] [G loss: 0.417943]\n",
      "epoch:28 step:26967 [D loss: 0.220665, acc.: 68.75%] [G loss: 0.414131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26968 [D loss: 0.206808, acc.: 67.19%] [G loss: 0.456597]\n",
      "epoch:28 step:26969 [D loss: 0.229794, acc.: 58.59%] [G loss: 0.433529]\n",
      "epoch:28 step:26970 [D loss: 0.241602, acc.: 55.47%] [G loss: 0.416897]\n",
      "epoch:28 step:26971 [D loss: 0.226831, acc.: 63.28%] [G loss: 0.414983]\n",
      "epoch:28 step:26972 [D loss: 0.204184, acc.: 69.53%] [G loss: 0.466301]\n",
      "epoch:28 step:26973 [D loss: 0.204207, acc.: 67.19%] [G loss: 0.390916]\n",
      "epoch:28 step:26974 [D loss: 0.241343, acc.: 59.38%] [G loss: 0.394020]\n",
      "epoch:28 step:26975 [D loss: 0.242451, acc.: 54.69%] [G loss: 0.400923]\n",
      "epoch:28 step:26976 [D loss: 0.222999, acc.: 63.28%] [G loss: 0.418865]\n",
      "epoch:28 step:26977 [D loss: 0.240421, acc.: 59.38%] [G loss: 0.396268]\n",
      "epoch:28 step:26978 [D loss: 0.222348, acc.: 63.28%] [G loss: 0.422460]\n",
      "epoch:28 step:26979 [D loss: 0.208863, acc.: 68.75%] [G loss: 0.459060]\n",
      "epoch:28 step:26980 [D loss: 0.225492, acc.: 62.50%] [G loss: 0.460417]\n",
      "epoch:28 step:26981 [D loss: 0.251440, acc.: 50.00%] [G loss: 0.442681]\n",
      "epoch:28 step:26982 [D loss: 0.205263, acc.: 66.41%] [G loss: 0.403242]\n",
      "epoch:28 step:26983 [D loss: 0.211890, acc.: 66.41%] [G loss: 0.439743]\n",
      "epoch:28 step:26984 [D loss: 0.240844, acc.: 57.81%] [G loss: 0.466962]\n",
      "epoch:28 step:26985 [D loss: 0.200864, acc.: 69.53%] [G loss: 0.424977]\n",
      "epoch:28 step:26986 [D loss: 0.220747, acc.: 61.72%] [G loss: 0.418123]\n",
      "epoch:28 step:26987 [D loss: 0.214885, acc.: 67.97%] [G loss: 0.465082]\n",
      "epoch:28 step:26988 [D loss: 0.265542, acc.: 50.00%] [G loss: 0.440651]\n",
      "epoch:28 step:26989 [D loss: 0.228425, acc.: 64.06%] [G loss: 0.423732]\n",
      "epoch:28 step:26990 [D loss: 0.204683, acc.: 68.75%] [G loss: 0.443829]\n",
      "epoch:28 step:26991 [D loss: 0.205640, acc.: 69.53%] [G loss: 0.469687]\n",
      "epoch:28 step:26992 [D loss: 0.234834, acc.: 66.41%] [G loss: 0.453327]\n",
      "epoch:28 step:26993 [D loss: 0.229957, acc.: 64.06%] [G loss: 0.416819]\n",
      "epoch:28 step:26994 [D loss: 0.215377, acc.: 67.97%] [G loss: 0.412469]\n",
      "epoch:28 step:26995 [D loss: 0.231777, acc.: 64.06%] [G loss: 0.417980]\n",
      "epoch:28 step:26996 [D loss: 0.225200, acc.: 64.84%] [G loss: 0.428099]\n",
      "epoch:28 step:26997 [D loss: 0.201953, acc.: 74.22%] [G loss: 0.422035]\n",
      "epoch:28 step:26998 [D loss: 0.224258, acc.: 64.84%] [G loss: 0.412009]\n",
      "epoch:28 step:26999 [D loss: 0.229051, acc.: 64.06%] [G loss: 0.390513]\n",
      "epoch:28 step:27000 [D loss: 0.234333, acc.: 64.84%] [G loss: 0.382677]\n",
      "epoch:28 step:27001 [D loss: 0.236219, acc.: 61.72%] [G loss: 0.408839]\n",
      "epoch:28 step:27002 [D loss: 0.225274, acc.: 56.25%] [G loss: 0.426648]\n",
      "epoch:28 step:27003 [D loss: 0.210597, acc.: 72.66%] [G loss: 0.453546]\n",
      "epoch:28 step:27004 [D loss: 0.231934, acc.: 59.38%] [G loss: 0.469407]\n",
      "epoch:28 step:27005 [D loss: 0.187804, acc.: 75.00%] [G loss: 0.483820]\n",
      "epoch:28 step:27006 [D loss: 0.239333, acc.: 60.94%] [G loss: 0.463700]\n",
      "epoch:28 step:27007 [D loss: 0.210851, acc.: 64.06%] [G loss: 0.431147]\n",
      "epoch:28 step:27008 [D loss: 0.238273, acc.: 65.62%] [G loss: 0.429259]\n",
      "epoch:28 step:27009 [D loss: 0.205239, acc.: 66.41%] [G loss: 0.435898]\n",
      "epoch:28 step:27010 [D loss: 0.208438, acc.: 71.88%] [G loss: 0.462277]\n",
      "epoch:28 step:27011 [D loss: 0.214095, acc.: 71.09%] [G loss: 0.471622]\n",
      "epoch:28 step:27012 [D loss: 0.237845, acc.: 64.84%] [G loss: 0.435722]\n",
      "epoch:28 step:27013 [D loss: 0.225739, acc.: 68.75%] [G loss: 0.461290]\n",
      "epoch:28 step:27014 [D loss: 0.228735, acc.: 57.81%] [G loss: 0.424232]\n",
      "epoch:28 step:27015 [D loss: 0.223911, acc.: 62.50%] [G loss: 0.425560]\n",
      "epoch:28 step:27016 [D loss: 0.208367, acc.: 63.28%] [G loss: 0.470574]\n",
      "epoch:28 step:27017 [D loss: 0.218153, acc.: 65.62%] [G loss: 0.467977]\n",
      "epoch:28 step:27018 [D loss: 0.188387, acc.: 69.53%] [G loss: 0.525449]\n",
      "epoch:28 step:27019 [D loss: 0.230289, acc.: 60.94%] [G loss: 0.460371]\n",
      "epoch:28 step:27020 [D loss: 0.262791, acc.: 49.22%] [G loss: 0.455396]\n",
      "epoch:28 step:27021 [D loss: 0.220150, acc.: 59.38%] [G loss: 0.375520]\n",
      "epoch:28 step:27022 [D loss: 0.185528, acc.: 71.09%] [G loss: 0.457117]\n",
      "epoch:28 step:27023 [D loss: 0.254436, acc.: 51.56%] [G loss: 0.400467]\n",
      "epoch:28 step:27024 [D loss: 0.236915, acc.: 58.59%] [G loss: 0.406498]\n",
      "epoch:28 step:27025 [D loss: 0.211682, acc.: 62.50%] [G loss: 0.439646]\n",
      "epoch:28 step:27026 [D loss: 0.217636, acc.: 69.53%] [G loss: 0.418106]\n",
      "epoch:28 step:27027 [D loss: 0.246353, acc.: 56.25%] [G loss: 0.438193]\n",
      "epoch:28 step:27028 [D loss: 0.203730, acc.: 68.75%] [G loss: 0.459714]\n",
      "epoch:28 step:27029 [D loss: 0.203960, acc.: 68.75%] [G loss: 0.478189]\n",
      "epoch:28 step:27030 [D loss: 0.246512, acc.: 54.69%] [G loss: 0.434182]\n",
      "epoch:28 step:27031 [D loss: 0.266311, acc.: 54.69%] [G loss: 0.466490]\n",
      "epoch:28 step:27032 [D loss: 0.205478, acc.: 64.06%] [G loss: 0.502810]\n",
      "epoch:28 step:27033 [D loss: 0.255779, acc.: 55.47%] [G loss: 0.430242]\n",
      "epoch:28 step:27034 [D loss: 0.237314, acc.: 59.38%] [G loss: 0.434133]\n",
      "epoch:28 step:27035 [D loss: 0.233329, acc.: 56.25%] [G loss: 0.422341]\n",
      "epoch:28 step:27036 [D loss: 0.253951, acc.: 53.12%] [G loss: 0.459990]\n",
      "epoch:28 step:27037 [D loss: 0.212862, acc.: 65.62%] [G loss: 0.458628]\n",
      "epoch:28 step:27038 [D loss: 0.207134, acc.: 70.31%] [G loss: 0.456744]\n",
      "epoch:28 step:27039 [D loss: 0.192584, acc.: 71.88%] [G loss: 0.488313]\n",
      "epoch:28 step:27040 [D loss: 0.256176, acc.: 57.03%] [G loss: 0.407357]\n",
      "epoch:28 step:27041 [D loss: 0.206638, acc.: 66.41%] [G loss: 0.444783]\n",
      "epoch:28 step:27042 [D loss: 0.248101, acc.: 55.47%] [G loss: 0.431060]\n",
      "epoch:28 step:27043 [D loss: 0.211613, acc.: 62.50%] [G loss: 0.432848]\n",
      "epoch:28 step:27044 [D loss: 0.236712, acc.: 55.47%] [G loss: 0.397013]\n",
      "epoch:28 step:27045 [D loss: 0.227019, acc.: 66.41%] [G loss: 0.419494]\n",
      "epoch:28 step:27046 [D loss: 0.242561, acc.: 60.16%] [G loss: 0.419294]\n",
      "epoch:28 step:27047 [D loss: 0.218767, acc.: 64.06%] [G loss: 0.432562]\n",
      "epoch:28 step:27048 [D loss: 0.244405, acc.: 55.47%] [G loss: 0.396966]\n",
      "epoch:28 step:27049 [D loss: 0.225546, acc.: 61.72%] [G loss: 0.398272]\n",
      "epoch:28 step:27050 [D loss: 0.211220, acc.: 64.06%] [G loss: 0.443930]\n",
      "epoch:28 step:27051 [D loss: 0.205361, acc.: 66.41%] [G loss: 0.443089]\n",
      "epoch:28 step:27052 [D loss: 0.201047, acc.: 66.41%] [G loss: 0.498365]\n",
      "epoch:28 step:27053 [D loss: 0.232514, acc.: 57.81%] [G loss: 0.442014]\n",
      "epoch:28 step:27054 [D loss: 0.254373, acc.: 60.16%] [G loss: 0.418788]\n",
      "epoch:28 step:27055 [D loss: 0.217305, acc.: 63.28%] [G loss: 0.428480]\n",
      "epoch:28 step:27056 [D loss: 0.260856, acc.: 51.56%] [G loss: 0.400134]\n",
      "epoch:28 step:27057 [D loss: 0.226325, acc.: 55.47%] [G loss: 0.391025]\n",
      "epoch:28 step:27058 [D loss: 0.221601, acc.: 60.94%] [G loss: 0.415547]\n",
      "epoch:28 step:27059 [D loss: 0.203897, acc.: 69.53%] [G loss: 0.437133]\n",
      "epoch:28 step:27060 [D loss: 0.218969, acc.: 62.50%] [G loss: 0.441718]\n",
      "epoch:28 step:27061 [D loss: 0.219530, acc.: 65.62%] [G loss: 0.416342]\n",
      "epoch:28 step:27062 [D loss: 0.234128, acc.: 60.16%] [G loss: 0.452661]\n",
      "epoch:28 step:27063 [D loss: 0.246762, acc.: 54.69%] [G loss: 0.433427]\n",
      "epoch:28 step:27064 [D loss: 0.270479, acc.: 54.69%] [G loss: 0.409122]\n",
      "epoch:28 step:27065 [D loss: 0.236282, acc.: 59.38%] [G loss: 0.434647]\n",
      "epoch:28 step:27066 [D loss: 0.231559, acc.: 57.81%] [G loss: 0.381228]\n",
      "epoch:28 step:27067 [D loss: 0.211753, acc.: 63.28%] [G loss: 0.456393]\n",
      "epoch:28 step:27068 [D loss: 0.206726, acc.: 71.09%] [G loss: 0.471705]\n",
      "epoch:28 step:27069 [D loss: 0.200223, acc.: 73.44%] [G loss: 0.409980]\n",
      "epoch:28 step:27070 [D loss: 0.236388, acc.: 59.38%] [G loss: 0.407254]\n",
      "epoch:28 step:27071 [D loss: 0.221889, acc.: 64.06%] [G loss: 0.413371]\n",
      "epoch:28 step:27072 [D loss: 0.232748, acc.: 60.94%] [G loss: 0.402176]\n",
      "epoch:28 step:27073 [D loss: 0.221613, acc.: 63.28%] [G loss: 0.443603]\n",
      "epoch:28 step:27074 [D loss: 0.204747, acc.: 71.88%] [G loss: 0.448120]\n",
      "epoch:28 step:27075 [D loss: 0.210396, acc.: 67.97%] [G loss: 0.412771]\n",
      "epoch:28 step:27076 [D loss: 0.227178, acc.: 67.97%] [G loss: 0.431468]\n",
      "epoch:28 step:27077 [D loss: 0.212335, acc.: 72.66%] [G loss: 0.452081]\n",
      "epoch:28 step:27078 [D loss: 0.206944, acc.: 68.75%] [G loss: 0.433297]\n",
      "epoch:28 step:27079 [D loss: 0.224940, acc.: 62.50%] [G loss: 0.437145]\n",
      "epoch:28 step:27080 [D loss: 0.221316, acc.: 63.28%] [G loss: 0.435286]\n",
      "epoch:28 step:27081 [D loss: 0.221864, acc.: 67.97%] [G loss: 0.422583]\n",
      "epoch:28 step:27082 [D loss: 0.244063, acc.: 51.56%] [G loss: 0.446809]\n",
      "epoch:28 step:27083 [D loss: 0.241173, acc.: 57.03%] [G loss: 0.410617]\n",
      "epoch:28 step:27084 [D loss: 0.223993, acc.: 63.28%] [G loss: 0.423174]\n",
      "epoch:28 step:27085 [D loss: 0.215200, acc.: 69.53%] [G loss: 0.402524]\n",
      "epoch:28 step:27086 [D loss: 0.252174, acc.: 53.91%] [G loss: 0.402793]\n",
      "epoch:28 step:27087 [D loss: 0.229418, acc.: 58.59%] [G loss: 0.449414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27088 [D loss: 0.231663, acc.: 59.38%] [G loss: 0.420879]\n",
      "epoch:28 step:27089 [D loss: 0.228087, acc.: 61.72%] [G loss: 0.490924]\n",
      "epoch:28 step:27090 [D loss: 0.230210, acc.: 57.03%] [G loss: 0.438611]\n",
      "epoch:28 step:27091 [D loss: 0.235980, acc.: 59.38%] [G loss: 0.424610]\n",
      "epoch:28 step:27092 [D loss: 0.247913, acc.: 57.03%] [G loss: 0.401819]\n",
      "epoch:28 step:27093 [D loss: 0.220610, acc.: 66.41%] [G loss: 0.416790]\n",
      "epoch:28 step:27094 [D loss: 0.264653, acc.: 50.78%] [G loss: 0.444934]\n",
      "epoch:28 step:27095 [D loss: 0.230773, acc.: 56.25%] [G loss: 0.465714]\n",
      "epoch:28 step:27096 [D loss: 0.187757, acc.: 71.88%] [G loss: 0.484410]\n",
      "epoch:28 step:27097 [D loss: 0.232806, acc.: 60.16%] [G loss: 0.409468]\n",
      "epoch:28 step:27098 [D loss: 0.239145, acc.: 61.72%] [G loss: 0.387936]\n",
      "epoch:28 step:27099 [D loss: 0.214336, acc.: 66.41%] [G loss: 0.403936]\n",
      "epoch:28 step:27100 [D loss: 0.207584, acc.: 63.28%] [G loss: 0.392869]\n",
      "epoch:28 step:27101 [D loss: 0.243786, acc.: 57.03%] [G loss: 0.407205]\n",
      "epoch:28 step:27102 [D loss: 0.221128, acc.: 61.72%] [G loss: 0.400413]\n",
      "epoch:28 step:27103 [D loss: 0.229752, acc.: 64.06%] [G loss: 0.412312]\n",
      "epoch:28 step:27104 [D loss: 0.213170, acc.: 62.50%] [G loss: 0.421392]\n",
      "epoch:28 step:27105 [D loss: 0.238502, acc.: 59.38%] [G loss: 0.423636]\n",
      "epoch:28 step:27106 [D loss: 0.214580, acc.: 64.84%] [G loss: 0.438470]\n",
      "epoch:28 step:27107 [D loss: 0.214275, acc.: 67.19%] [G loss: 0.446681]\n",
      "epoch:28 step:27108 [D loss: 0.232126, acc.: 58.59%] [G loss: 0.451053]\n",
      "epoch:28 step:27109 [D loss: 0.239404, acc.: 62.50%] [G loss: 0.382601]\n",
      "epoch:28 step:27110 [D loss: 0.215144, acc.: 65.62%] [G loss: 0.411906]\n",
      "epoch:28 step:27111 [D loss: 0.196653, acc.: 73.44%] [G loss: 0.460954]\n",
      "epoch:28 step:27112 [D loss: 0.245664, acc.: 58.59%] [G loss: 0.419909]\n",
      "epoch:28 step:27113 [D loss: 0.222088, acc.: 57.03%] [G loss: 0.427402]\n",
      "epoch:28 step:27114 [D loss: 0.222313, acc.: 65.62%] [G loss: 0.412325]\n",
      "epoch:28 step:27115 [D loss: 0.228006, acc.: 59.38%] [G loss: 0.408141]\n",
      "epoch:28 step:27116 [D loss: 0.248927, acc.: 57.81%] [G loss: 0.411868]\n",
      "epoch:28 step:27117 [D loss: 0.224779, acc.: 63.28%] [G loss: 0.417792]\n",
      "epoch:28 step:27118 [D loss: 0.218658, acc.: 67.19%] [G loss: 0.421667]\n",
      "epoch:28 step:27119 [D loss: 0.241504, acc.: 60.16%] [G loss: 0.410426]\n",
      "epoch:28 step:27120 [D loss: 0.217362, acc.: 61.72%] [G loss: 0.402756]\n",
      "epoch:28 step:27121 [D loss: 0.228166, acc.: 65.62%] [G loss: 0.456625]\n",
      "epoch:28 step:27122 [D loss: 0.196115, acc.: 71.88%] [G loss: 0.530611]\n",
      "epoch:28 step:27123 [D loss: 0.226594, acc.: 64.06%] [G loss: 0.496918]\n",
      "epoch:28 step:27124 [D loss: 0.224293, acc.: 61.72%] [G loss: 0.418139]\n",
      "epoch:28 step:27125 [D loss: 0.217548, acc.: 62.50%] [G loss: 0.424039]\n",
      "epoch:28 step:27126 [D loss: 0.197053, acc.: 72.66%] [G loss: 0.433162]\n",
      "epoch:28 step:27127 [D loss: 0.264087, acc.: 50.00%] [G loss: 0.408663]\n",
      "epoch:28 step:27128 [D loss: 0.258853, acc.: 56.25%] [G loss: 0.421521]\n",
      "epoch:28 step:27129 [D loss: 0.202651, acc.: 65.62%] [G loss: 0.413796]\n",
      "epoch:28 step:27130 [D loss: 0.223487, acc.: 70.31%] [G loss: 0.446434]\n",
      "epoch:28 step:27131 [D loss: 0.197841, acc.: 64.84%] [G loss: 0.480601]\n",
      "epoch:28 step:27132 [D loss: 0.212284, acc.: 65.62%] [G loss: 0.458812]\n",
      "epoch:28 step:27133 [D loss: 0.198780, acc.: 71.88%] [G loss: 0.476201]\n",
      "epoch:28 step:27134 [D loss: 0.192281, acc.: 72.66%] [G loss: 0.467113]\n",
      "epoch:28 step:27135 [D loss: 0.192181, acc.: 69.53%] [G loss: 0.473734]\n",
      "epoch:28 step:27136 [D loss: 0.221182, acc.: 63.28%] [G loss: 0.445440]\n",
      "epoch:28 step:27137 [D loss: 0.240751, acc.: 60.16%] [G loss: 0.421229]\n",
      "epoch:28 step:27138 [D loss: 0.249526, acc.: 53.12%] [G loss: 0.391297]\n",
      "epoch:28 step:27139 [D loss: 0.217227, acc.: 66.41%] [G loss: 0.455581]\n",
      "epoch:28 step:27140 [D loss: 0.223885, acc.: 62.50%] [G loss: 0.455836]\n",
      "epoch:28 step:27141 [D loss: 0.195089, acc.: 72.66%] [G loss: 0.454626]\n",
      "epoch:28 step:27142 [D loss: 0.203544, acc.: 71.09%] [G loss: 0.488328]\n",
      "epoch:28 step:27143 [D loss: 0.223967, acc.: 66.41%] [G loss: 0.462530]\n",
      "epoch:28 step:27144 [D loss: 0.205606, acc.: 67.19%] [G loss: 0.438839]\n",
      "epoch:28 step:27145 [D loss: 0.217556, acc.: 70.31%] [G loss: 0.440714]\n",
      "epoch:28 step:27146 [D loss: 0.230319, acc.: 54.69%] [G loss: 0.455463]\n",
      "epoch:28 step:27147 [D loss: 0.214146, acc.: 64.84%] [G loss: 0.433010]\n",
      "epoch:28 step:27148 [D loss: 0.207151, acc.: 71.09%] [G loss: 0.416641]\n",
      "epoch:28 step:27149 [D loss: 0.231294, acc.: 58.59%] [G loss: 0.417268]\n",
      "epoch:28 step:27150 [D loss: 0.208744, acc.: 67.19%] [G loss: 0.471472]\n",
      "epoch:28 step:27151 [D loss: 0.259315, acc.: 56.25%] [G loss: 0.403504]\n",
      "epoch:28 step:27152 [D loss: 0.234203, acc.: 58.59%] [G loss: 0.425645]\n",
      "epoch:28 step:27153 [D loss: 0.232392, acc.: 58.59%] [G loss: 0.435303]\n",
      "epoch:28 step:27154 [D loss: 0.207890, acc.: 64.06%] [G loss: 0.428925]\n",
      "epoch:28 step:27155 [D loss: 0.208363, acc.: 65.62%] [G loss: 0.449123]\n",
      "epoch:28 step:27156 [D loss: 0.285197, acc.: 46.09%] [G loss: 0.397745]\n",
      "epoch:28 step:27157 [D loss: 0.232306, acc.: 59.38%] [G loss: 0.460105]\n",
      "epoch:28 step:27158 [D loss: 0.216849, acc.: 69.53%] [G loss: 0.433894]\n",
      "epoch:28 step:27159 [D loss: 0.218713, acc.: 67.97%] [G loss: 0.450597]\n",
      "epoch:28 step:27160 [D loss: 0.172425, acc.: 78.12%] [G loss: 0.456180]\n",
      "epoch:28 step:27161 [D loss: 0.224531, acc.: 64.84%] [G loss: 0.469983]\n",
      "epoch:28 step:27162 [D loss: 0.192461, acc.: 69.53%] [G loss: 0.507386]\n",
      "epoch:28 step:27163 [D loss: 0.186563, acc.: 72.66%] [G loss: 0.514744]\n",
      "epoch:28 step:27164 [D loss: 0.298166, acc.: 57.81%] [G loss: 0.542950]\n",
      "epoch:28 step:27165 [D loss: 0.235798, acc.: 56.25%] [G loss: 0.588675]\n",
      "epoch:28 step:27166 [D loss: 0.223651, acc.: 64.06%] [G loss: 0.512018]\n",
      "epoch:28 step:27167 [D loss: 0.234002, acc.: 56.25%] [G loss: 0.441995]\n",
      "epoch:28 step:27168 [D loss: 0.247120, acc.: 57.03%] [G loss: 0.420592]\n",
      "epoch:28 step:27169 [D loss: 0.199550, acc.: 69.53%] [G loss: 0.427048]\n",
      "epoch:28 step:27170 [D loss: 0.237709, acc.: 64.06%] [G loss: 0.474523]\n",
      "epoch:28 step:27171 [D loss: 0.215763, acc.: 66.41%] [G loss: 0.494945]\n",
      "epoch:28 step:27172 [D loss: 0.194396, acc.: 66.41%] [G loss: 0.527554]\n",
      "epoch:28 step:27173 [D loss: 0.201872, acc.: 66.41%] [G loss: 0.486977]\n",
      "epoch:29 step:27174 [D loss: 0.200543, acc.: 68.75%] [G loss: 0.490745]\n",
      "epoch:29 step:27175 [D loss: 0.260288, acc.: 59.38%] [G loss: 0.472023]\n",
      "epoch:29 step:27176 [D loss: 0.236105, acc.: 63.28%] [G loss: 0.462519]\n",
      "epoch:29 step:27177 [D loss: 0.261097, acc.: 57.03%] [G loss: 0.450936]\n",
      "epoch:29 step:27178 [D loss: 0.220011, acc.: 63.28%] [G loss: 0.457829]\n",
      "epoch:29 step:27179 [D loss: 0.217208, acc.: 65.62%] [G loss: 0.468665]\n",
      "epoch:29 step:27180 [D loss: 0.207585, acc.: 64.06%] [G loss: 0.455089]\n",
      "epoch:29 step:27181 [D loss: 0.222312, acc.: 62.50%] [G loss: 0.428819]\n",
      "epoch:29 step:27182 [D loss: 0.192778, acc.: 68.75%] [G loss: 0.454463]\n",
      "epoch:29 step:27183 [D loss: 0.204368, acc.: 65.62%] [G loss: 0.464310]\n",
      "epoch:29 step:27184 [D loss: 0.208851, acc.: 64.84%] [G loss: 0.446379]\n",
      "epoch:29 step:27185 [D loss: 0.231469, acc.: 64.84%] [G loss: 0.442983]\n",
      "epoch:29 step:27186 [D loss: 0.208448, acc.: 66.41%] [G loss: 0.461134]\n",
      "epoch:29 step:27187 [D loss: 0.206553, acc.: 67.97%] [G loss: 0.471285]\n",
      "epoch:29 step:27188 [D loss: 0.181538, acc.: 73.44%] [G loss: 0.470368]\n",
      "epoch:29 step:27189 [D loss: 0.186525, acc.: 68.75%] [G loss: 0.458653]\n",
      "epoch:29 step:27190 [D loss: 0.225498, acc.: 64.06%] [G loss: 0.462907]\n",
      "epoch:29 step:27191 [D loss: 0.211476, acc.: 67.97%] [G loss: 0.494491]\n",
      "epoch:29 step:27192 [D loss: 0.249528, acc.: 57.03%] [G loss: 0.405847]\n",
      "epoch:29 step:27193 [D loss: 0.237370, acc.: 54.69%] [G loss: 0.512069]\n",
      "epoch:29 step:27194 [D loss: 0.223824, acc.: 65.62%] [G loss: 0.480837]\n",
      "epoch:29 step:27195 [D loss: 0.179410, acc.: 75.00%] [G loss: 0.571913]\n",
      "epoch:29 step:27196 [D loss: 0.262371, acc.: 49.22%] [G loss: 0.407743]\n",
      "epoch:29 step:27197 [D loss: 0.214231, acc.: 65.62%] [G loss: 0.400644]\n",
      "epoch:29 step:27198 [D loss: 0.198912, acc.: 70.31%] [G loss: 0.430418]\n",
      "epoch:29 step:27199 [D loss: 0.222618, acc.: 63.28%] [G loss: 0.467582]\n",
      "epoch:29 step:27200 [D loss: 0.223662, acc.: 60.94%] [G loss: 0.423296]\n",
      "epoch:29 step:27201 [D loss: 0.215436, acc.: 61.72%] [G loss: 0.498704]\n",
      "epoch:29 step:27202 [D loss: 0.228998, acc.: 64.06%] [G loss: 0.394347]\n",
      "epoch:29 step:27203 [D loss: 0.238144, acc.: 53.91%] [G loss: 0.435748]\n",
      "epoch:29 step:27204 [D loss: 0.237413, acc.: 57.81%] [G loss: 0.425111]\n",
      "epoch:29 step:27205 [D loss: 0.209860, acc.: 74.22%] [G loss: 0.450078]\n",
      "epoch:29 step:27206 [D loss: 0.219559, acc.: 62.50%] [G loss: 0.413614]\n",
      "epoch:29 step:27207 [D loss: 0.246926, acc.: 53.91%] [G loss: 0.385997]\n",
      "epoch:29 step:27208 [D loss: 0.215219, acc.: 69.53%] [G loss: 0.443400]\n",
      "epoch:29 step:27209 [D loss: 0.234227, acc.: 63.28%] [G loss: 0.420132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27210 [D loss: 0.224403, acc.: 62.50%] [G loss: 0.459013]\n",
      "epoch:29 step:27211 [D loss: 0.243766, acc.: 59.38%] [G loss: 0.437495]\n",
      "epoch:29 step:27212 [D loss: 0.221174, acc.: 63.28%] [G loss: 0.431975]\n",
      "epoch:29 step:27213 [D loss: 0.216119, acc.: 59.38%] [G loss: 0.431497]\n",
      "epoch:29 step:27214 [D loss: 0.245435, acc.: 56.25%] [G loss: 0.423247]\n",
      "epoch:29 step:27215 [D loss: 0.212317, acc.: 67.19%] [G loss: 0.431311]\n",
      "epoch:29 step:27216 [D loss: 0.224666, acc.: 64.06%] [G loss: 0.424510]\n",
      "epoch:29 step:27217 [D loss: 0.229798, acc.: 60.94%] [G loss: 0.412906]\n",
      "epoch:29 step:27218 [D loss: 0.224652, acc.: 64.84%] [G loss: 0.416906]\n",
      "epoch:29 step:27219 [D loss: 0.210156, acc.: 64.06%] [G loss: 0.460631]\n",
      "epoch:29 step:27220 [D loss: 0.230388, acc.: 60.94%] [G loss: 0.397112]\n",
      "epoch:29 step:27221 [D loss: 0.198199, acc.: 68.75%] [G loss: 0.418182]\n",
      "epoch:29 step:27222 [D loss: 0.195596, acc.: 70.31%] [G loss: 0.452212]\n",
      "epoch:29 step:27223 [D loss: 0.215975, acc.: 64.84%] [G loss: 0.447526]\n",
      "epoch:29 step:27224 [D loss: 0.235508, acc.: 57.81%] [G loss: 0.433946]\n",
      "epoch:29 step:27225 [D loss: 0.215610, acc.: 60.16%] [G loss: 0.425692]\n",
      "epoch:29 step:27226 [D loss: 0.189268, acc.: 71.88%] [G loss: 0.476278]\n",
      "epoch:29 step:27227 [D loss: 0.202069, acc.: 68.75%] [G loss: 0.457063]\n",
      "epoch:29 step:27228 [D loss: 0.222191, acc.: 62.50%] [G loss: 0.476741]\n",
      "epoch:29 step:27229 [D loss: 0.213083, acc.: 68.75%] [G loss: 0.477915]\n",
      "epoch:29 step:27230 [D loss: 0.233681, acc.: 61.72%] [G loss: 0.462504]\n",
      "epoch:29 step:27231 [D loss: 0.218514, acc.: 68.75%] [G loss: 0.430600]\n",
      "epoch:29 step:27232 [D loss: 0.207752, acc.: 67.97%] [G loss: 0.402384]\n",
      "epoch:29 step:27233 [D loss: 0.218068, acc.: 65.62%] [G loss: 0.414282]\n",
      "epoch:29 step:27234 [D loss: 0.234657, acc.: 59.38%] [G loss: 0.407691]\n",
      "epoch:29 step:27235 [D loss: 0.233096, acc.: 57.81%] [G loss: 0.407238]\n",
      "epoch:29 step:27236 [D loss: 0.213336, acc.: 66.41%] [G loss: 0.429783]\n",
      "epoch:29 step:27237 [D loss: 0.226883, acc.: 60.16%] [G loss: 0.411199]\n",
      "epoch:29 step:27238 [D loss: 0.218997, acc.: 60.16%] [G loss: 0.449049]\n",
      "epoch:29 step:27239 [D loss: 0.217745, acc.: 62.50%] [G loss: 0.415334]\n",
      "epoch:29 step:27240 [D loss: 0.214602, acc.: 65.62%] [G loss: 0.436636]\n",
      "epoch:29 step:27241 [D loss: 0.227749, acc.: 61.72%] [G loss: 0.440628]\n",
      "epoch:29 step:27242 [D loss: 0.206279, acc.: 64.06%] [G loss: 0.423247]\n",
      "epoch:29 step:27243 [D loss: 0.192748, acc.: 73.44%] [G loss: 0.493345]\n",
      "epoch:29 step:27244 [D loss: 0.240953, acc.: 55.47%] [G loss: 0.455822]\n",
      "epoch:29 step:27245 [D loss: 0.243368, acc.: 56.25%] [G loss: 0.417684]\n",
      "epoch:29 step:27246 [D loss: 0.225589, acc.: 66.41%] [G loss: 0.398275]\n",
      "epoch:29 step:27247 [D loss: 0.194874, acc.: 72.66%] [G loss: 0.459279]\n",
      "epoch:29 step:27248 [D loss: 0.198996, acc.: 68.75%] [G loss: 0.431939]\n",
      "epoch:29 step:27249 [D loss: 0.202092, acc.: 64.84%] [G loss: 0.491798]\n",
      "epoch:29 step:27250 [D loss: 0.175948, acc.: 73.44%] [G loss: 0.481249]\n",
      "epoch:29 step:27251 [D loss: 0.269764, acc.: 49.22%] [G loss: 0.381006]\n",
      "epoch:29 step:27252 [D loss: 0.241508, acc.: 55.47%] [G loss: 0.431518]\n",
      "epoch:29 step:27253 [D loss: 0.218593, acc.: 62.50%] [G loss: 0.421101]\n",
      "epoch:29 step:27254 [D loss: 0.253584, acc.: 55.47%] [G loss: 0.418860]\n",
      "epoch:29 step:27255 [D loss: 0.222082, acc.: 65.62%] [G loss: 0.438807]\n",
      "epoch:29 step:27256 [D loss: 0.209121, acc.: 63.28%] [G loss: 0.459070]\n",
      "epoch:29 step:27257 [D loss: 0.219416, acc.: 65.62%] [G loss: 0.440226]\n",
      "epoch:29 step:27258 [D loss: 0.214976, acc.: 64.84%] [G loss: 0.453021]\n",
      "epoch:29 step:27259 [D loss: 0.249384, acc.: 57.81%] [G loss: 0.386940]\n",
      "epoch:29 step:27260 [D loss: 0.225789, acc.: 64.84%] [G loss: 0.406709]\n",
      "epoch:29 step:27261 [D loss: 0.199153, acc.: 75.00%] [G loss: 0.458376]\n",
      "epoch:29 step:27262 [D loss: 0.228590, acc.: 59.38%] [G loss: 0.405084]\n",
      "epoch:29 step:27263 [D loss: 0.185067, acc.: 71.88%] [G loss: 0.456330]\n",
      "epoch:29 step:27264 [D loss: 0.246847, acc.: 54.69%] [G loss: 0.436123]\n",
      "epoch:29 step:27265 [D loss: 0.215424, acc.: 62.50%] [G loss: 0.493041]\n",
      "epoch:29 step:27266 [D loss: 0.213956, acc.: 67.19%] [G loss: 0.471084]\n",
      "epoch:29 step:27267 [D loss: 0.229974, acc.: 59.38%] [G loss: 0.481507]\n",
      "epoch:29 step:27268 [D loss: 0.208797, acc.: 67.97%] [G loss: 0.492062]\n",
      "epoch:29 step:27269 [D loss: 0.203640, acc.: 67.97%] [G loss: 0.420023]\n",
      "epoch:29 step:27270 [D loss: 0.207152, acc.: 71.09%] [G loss: 0.502240]\n",
      "epoch:29 step:27271 [D loss: 0.222733, acc.: 64.06%] [G loss: 0.465026]\n",
      "epoch:29 step:27272 [D loss: 0.230534, acc.: 60.16%] [G loss: 0.434403]\n",
      "epoch:29 step:27273 [D loss: 0.197177, acc.: 67.97%] [G loss: 0.425247]\n",
      "epoch:29 step:27274 [D loss: 0.226274, acc.: 61.72%] [G loss: 0.452627]\n",
      "epoch:29 step:27275 [D loss: 0.242989, acc.: 60.16%] [G loss: 0.415531]\n",
      "epoch:29 step:27276 [D loss: 0.251208, acc.: 57.81%] [G loss: 0.420660]\n",
      "epoch:29 step:27277 [D loss: 0.245535, acc.: 56.25%] [G loss: 0.396051]\n",
      "epoch:29 step:27278 [D loss: 0.260792, acc.: 53.12%] [G loss: 0.386648]\n",
      "epoch:29 step:27279 [D loss: 0.193062, acc.: 69.53%] [G loss: 0.451804]\n",
      "epoch:29 step:27280 [D loss: 0.207561, acc.: 67.97%] [G loss: 0.476822]\n",
      "epoch:29 step:27281 [D loss: 0.235667, acc.: 63.28%] [G loss: 0.474064]\n",
      "epoch:29 step:27282 [D loss: 0.248203, acc.: 57.03%] [G loss: 0.412858]\n",
      "epoch:29 step:27283 [D loss: 0.245164, acc.: 54.69%] [G loss: 0.400128]\n",
      "epoch:29 step:27284 [D loss: 0.210858, acc.: 64.84%] [G loss: 0.408411]\n",
      "epoch:29 step:27285 [D loss: 0.200193, acc.: 70.31%] [G loss: 0.429379]\n",
      "epoch:29 step:27286 [D loss: 0.213171, acc.: 67.19%] [G loss: 0.456762]\n",
      "epoch:29 step:27287 [D loss: 0.207743, acc.: 71.88%] [G loss: 0.475561]\n",
      "epoch:29 step:27288 [D loss: 0.193913, acc.: 72.66%] [G loss: 0.523990]\n",
      "epoch:29 step:27289 [D loss: 0.215007, acc.: 67.19%] [G loss: 0.461613]\n",
      "epoch:29 step:27290 [D loss: 0.192087, acc.: 71.88%] [G loss: 0.406435]\n",
      "epoch:29 step:27291 [D loss: 0.214081, acc.: 72.66%] [G loss: 0.503271]\n",
      "epoch:29 step:27292 [D loss: 0.176515, acc.: 73.44%] [G loss: 0.505361]\n",
      "epoch:29 step:27293 [D loss: 0.252801, acc.: 59.38%] [G loss: 0.470996]\n",
      "epoch:29 step:27294 [D loss: 0.248705, acc.: 54.69%] [G loss: 0.460212]\n",
      "epoch:29 step:27295 [D loss: 0.204932, acc.: 71.09%] [G loss: 0.442842]\n",
      "epoch:29 step:27296 [D loss: 0.225208, acc.: 61.72%] [G loss: 0.441308]\n",
      "epoch:29 step:27297 [D loss: 0.246294, acc.: 53.12%] [G loss: 0.469582]\n",
      "epoch:29 step:27298 [D loss: 0.237319, acc.: 64.06%] [G loss: 0.444418]\n",
      "epoch:29 step:27299 [D loss: 0.220037, acc.: 62.50%] [G loss: 0.411694]\n",
      "epoch:29 step:27300 [D loss: 0.216049, acc.: 67.97%] [G loss: 0.449873]\n",
      "epoch:29 step:27301 [D loss: 0.230493, acc.: 59.38%] [G loss: 0.425951]\n",
      "epoch:29 step:27302 [D loss: 0.236612, acc.: 58.59%] [G loss: 0.416589]\n",
      "epoch:29 step:27303 [D loss: 0.212287, acc.: 64.84%] [G loss: 0.435992]\n",
      "epoch:29 step:27304 [D loss: 0.205647, acc.: 74.22%] [G loss: 0.439613]\n",
      "epoch:29 step:27305 [D loss: 0.223707, acc.: 64.84%] [G loss: 0.426237]\n",
      "epoch:29 step:27306 [D loss: 0.216294, acc.: 63.28%] [G loss: 0.521081]\n",
      "epoch:29 step:27307 [D loss: 0.212534, acc.: 64.84%] [G loss: 0.504060]\n",
      "epoch:29 step:27308 [D loss: 0.218880, acc.: 61.72%] [G loss: 0.447025]\n",
      "epoch:29 step:27309 [D loss: 0.221804, acc.: 63.28%] [G loss: 0.430824]\n",
      "epoch:29 step:27310 [D loss: 0.238584, acc.: 60.16%] [G loss: 0.448284]\n",
      "epoch:29 step:27311 [D loss: 0.236691, acc.: 61.72%] [G loss: 0.381496]\n",
      "epoch:29 step:27312 [D loss: 0.234628, acc.: 59.38%] [G loss: 0.385778]\n",
      "epoch:29 step:27313 [D loss: 0.222999, acc.: 61.72%] [G loss: 0.416278]\n",
      "epoch:29 step:27314 [D loss: 0.216727, acc.: 67.19%] [G loss: 0.474403]\n",
      "epoch:29 step:27315 [D loss: 0.229299, acc.: 60.16%] [G loss: 0.445574]\n",
      "epoch:29 step:27316 [D loss: 0.238735, acc.: 57.81%] [G loss: 0.392961]\n",
      "epoch:29 step:27317 [D loss: 0.212380, acc.: 68.75%] [G loss: 0.421204]\n",
      "epoch:29 step:27318 [D loss: 0.229804, acc.: 60.16%] [G loss: 0.421047]\n",
      "epoch:29 step:27319 [D loss: 0.209910, acc.: 69.53%] [G loss: 0.464511]\n",
      "epoch:29 step:27320 [D loss: 0.226971, acc.: 64.06%] [G loss: 0.418549]\n",
      "epoch:29 step:27321 [D loss: 0.258173, acc.: 58.59%] [G loss: 0.429477]\n",
      "epoch:29 step:27322 [D loss: 0.222657, acc.: 59.38%] [G loss: 0.421388]\n",
      "epoch:29 step:27323 [D loss: 0.244890, acc.: 54.69%] [G loss: 0.434741]\n",
      "epoch:29 step:27324 [D loss: 0.203017, acc.: 70.31%] [G loss: 0.427478]\n",
      "epoch:29 step:27325 [D loss: 0.216524, acc.: 65.62%] [G loss: 0.459307]\n",
      "epoch:29 step:27326 [D loss: 0.247857, acc.: 53.91%] [G loss: 0.452001]\n",
      "epoch:29 step:27327 [D loss: 0.226465, acc.: 62.50%] [G loss: 0.419196]\n",
      "epoch:29 step:27328 [D loss: 0.219355, acc.: 63.28%] [G loss: 0.449946]\n",
      "epoch:29 step:27329 [D loss: 0.191750, acc.: 75.78%] [G loss: 0.446861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27330 [D loss: 0.229877, acc.: 59.38%] [G loss: 0.428242]\n",
      "epoch:29 step:27331 [D loss: 0.211758, acc.: 70.31%] [G loss: 0.445176]\n",
      "epoch:29 step:27332 [D loss: 0.219555, acc.: 65.62%] [G loss: 0.415901]\n",
      "epoch:29 step:27333 [D loss: 0.254828, acc.: 57.03%] [G loss: 0.526387]\n",
      "epoch:29 step:27334 [D loss: 0.235039, acc.: 59.38%] [G loss: 0.540794]\n",
      "epoch:29 step:27335 [D loss: 0.285093, acc.: 48.44%] [G loss: 0.400159]\n",
      "epoch:29 step:27336 [D loss: 0.206478, acc.: 64.84%] [G loss: 0.426899]\n",
      "epoch:29 step:27337 [D loss: 0.221464, acc.: 65.62%] [G loss: 0.408457]\n",
      "epoch:29 step:27338 [D loss: 0.257217, acc.: 57.03%] [G loss: 0.429896]\n",
      "epoch:29 step:27339 [D loss: 0.220358, acc.: 63.28%] [G loss: 0.412218]\n",
      "epoch:29 step:27340 [D loss: 0.213423, acc.: 63.28%] [G loss: 0.426813]\n",
      "epoch:29 step:27341 [D loss: 0.221134, acc.: 60.16%] [G loss: 0.443856]\n",
      "epoch:29 step:27342 [D loss: 0.217284, acc.: 67.19%] [G loss: 0.421361]\n",
      "epoch:29 step:27343 [D loss: 0.253853, acc.: 50.00%] [G loss: 0.391854]\n",
      "epoch:29 step:27344 [D loss: 0.220379, acc.: 66.41%] [G loss: 0.406789]\n",
      "epoch:29 step:27345 [D loss: 0.204174, acc.: 67.19%] [G loss: 0.413157]\n",
      "epoch:29 step:27346 [D loss: 0.195248, acc.: 71.09%] [G loss: 0.480720]\n",
      "epoch:29 step:27347 [D loss: 0.241407, acc.: 59.38%] [G loss: 0.409604]\n",
      "epoch:29 step:27348 [D loss: 0.223960, acc.: 64.06%] [G loss: 0.465329]\n",
      "epoch:29 step:27349 [D loss: 0.223711, acc.: 62.50%] [G loss: 0.415912]\n",
      "epoch:29 step:27350 [D loss: 0.242227, acc.: 54.69%] [G loss: 0.456593]\n",
      "epoch:29 step:27351 [D loss: 0.222258, acc.: 66.41%] [G loss: 0.382630]\n",
      "epoch:29 step:27352 [D loss: 0.233229, acc.: 60.16%] [G loss: 0.392032]\n",
      "epoch:29 step:27353 [D loss: 0.231352, acc.: 60.94%] [G loss: 0.403131]\n",
      "epoch:29 step:27354 [D loss: 0.226388, acc.: 59.38%] [G loss: 0.404474]\n",
      "epoch:29 step:27355 [D loss: 0.228319, acc.: 65.62%] [G loss: 0.402164]\n",
      "epoch:29 step:27356 [D loss: 0.247876, acc.: 60.16%] [G loss: 0.402927]\n",
      "epoch:29 step:27357 [D loss: 0.225861, acc.: 64.84%] [G loss: 0.400459]\n",
      "epoch:29 step:27358 [D loss: 0.216572, acc.: 63.28%] [G loss: 0.408645]\n",
      "epoch:29 step:27359 [D loss: 0.228479, acc.: 60.94%] [G loss: 0.426940]\n",
      "epoch:29 step:27360 [D loss: 0.242289, acc.: 58.59%] [G loss: 0.436532]\n",
      "epoch:29 step:27361 [D loss: 0.233603, acc.: 64.06%] [G loss: 0.451493]\n",
      "epoch:29 step:27362 [D loss: 0.240491, acc.: 60.94%] [G loss: 0.446717]\n",
      "epoch:29 step:27363 [D loss: 0.226222, acc.: 62.50%] [G loss: 0.416355]\n",
      "epoch:29 step:27364 [D loss: 0.223254, acc.: 60.94%] [G loss: 0.402452]\n",
      "epoch:29 step:27365 [D loss: 0.213489, acc.: 67.19%] [G loss: 0.429773]\n",
      "epoch:29 step:27366 [D loss: 0.198721, acc.: 69.53%] [G loss: 0.472999]\n",
      "epoch:29 step:27367 [D loss: 0.199498, acc.: 68.75%] [G loss: 0.424773]\n",
      "epoch:29 step:27368 [D loss: 0.211543, acc.: 69.53%] [G loss: 0.434558]\n",
      "epoch:29 step:27369 [D loss: 0.248769, acc.: 60.94%] [G loss: 0.425236]\n",
      "epoch:29 step:27370 [D loss: 0.218885, acc.: 62.50%] [G loss: 0.413055]\n",
      "epoch:29 step:27371 [D loss: 0.199117, acc.: 68.75%] [G loss: 0.440995]\n",
      "epoch:29 step:27372 [D loss: 0.247744, acc.: 56.25%] [G loss: 0.437477]\n",
      "epoch:29 step:27373 [D loss: 0.260329, acc.: 50.78%] [G loss: 0.403288]\n",
      "epoch:29 step:27374 [D loss: 0.220627, acc.: 66.41%] [G loss: 0.433128]\n",
      "epoch:29 step:27375 [D loss: 0.201458, acc.: 68.75%] [G loss: 0.420002]\n",
      "epoch:29 step:27376 [D loss: 0.261165, acc.: 53.12%] [G loss: 0.428085]\n",
      "epoch:29 step:27377 [D loss: 0.220695, acc.: 64.84%] [G loss: 0.439075]\n",
      "epoch:29 step:27378 [D loss: 0.234006, acc.: 57.81%] [G loss: 0.480524]\n",
      "epoch:29 step:27379 [D loss: 0.225750, acc.: 63.28%] [G loss: 0.469190]\n",
      "epoch:29 step:27380 [D loss: 0.233489, acc.: 61.72%] [G loss: 0.412174]\n",
      "epoch:29 step:27381 [D loss: 0.185384, acc.: 70.31%] [G loss: 0.433648]\n",
      "epoch:29 step:27382 [D loss: 0.180377, acc.: 76.56%] [G loss: 0.449673]\n",
      "epoch:29 step:27383 [D loss: 0.248997, acc.: 56.25%] [G loss: 0.406170]\n",
      "epoch:29 step:27384 [D loss: 0.238023, acc.: 61.72%] [G loss: 0.383798]\n",
      "epoch:29 step:27385 [D loss: 0.226670, acc.: 60.94%] [G loss: 0.405194]\n",
      "epoch:29 step:27386 [D loss: 0.236245, acc.: 59.38%] [G loss: 0.388758]\n",
      "epoch:29 step:27387 [D loss: 0.240415, acc.: 55.47%] [G loss: 0.421569]\n",
      "epoch:29 step:27388 [D loss: 0.232759, acc.: 61.72%] [G loss: 0.394798]\n",
      "epoch:29 step:27389 [D loss: 0.202957, acc.: 68.75%] [G loss: 0.470834]\n",
      "epoch:29 step:27390 [D loss: 0.216850, acc.: 66.41%] [G loss: 0.415920]\n",
      "epoch:29 step:27391 [D loss: 0.174680, acc.: 79.69%] [G loss: 0.458404]\n",
      "epoch:29 step:27392 [D loss: 0.190429, acc.: 69.53%] [G loss: 0.444366]\n",
      "epoch:29 step:27393 [D loss: 0.258439, acc.: 57.81%] [G loss: 0.435401]\n",
      "epoch:29 step:27394 [D loss: 0.232415, acc.: 59.38%] [G loss: 0.441776]\n",
      "epoch:29 step:27395 [D loss: 0.202646, acc.: 62.50%] [G loss: 0.537894]\n",
      "epoch:29 step:27396 [D loss: 0.191116, acc.: 72.66%] [G loss: 0.498695]\n",
      "epoch:29 step:27397 [D loss: 0.257740, acc.: 57.03%] [G loss: 0.402126]\n",
      "epoch:29 step:27398 [D loss: 0.247208, acc.: 56.25%] [G loss: 0.392864]\n",
      "epoch:29 step:27399 [D loss: 0.219803, acc.: 62.50%] [G loss: 0.434589]\n",
      "epoch:29 step:27400 [D loss: 0.209064, acc.: 67.97%] [G loss: 0.447026]\n",
      "epoch:29 step:27401 [D loss: 0.241354, acc.: 61.72%] [G loss: 0.399645]\n",
      "epoch:29 step:27402 [D loss: 0.206038, acc.: 70.31%] [G loss: 0.418834]\n",
      "epoch:29 step:27403 [D loss: 0.201620, acc.: 65.62%] [G loss: 0.454068]\n",
      "epoch:29 step:27404 [D loss: 0.188792, acc.: 72.66%] [G loss: 0.478080]\n",
      "epoch:29 step:27405 [D loss: 0.161642, acc.: 74.22%] [G loss: 0.548628]\n",
      "epoch:29 step:27406 [D loss: 0.266289, acc.: 53.91%] [G loss: 0.439205]\n",
      "epoch:29 step:27407 [D loss: 0.245811, acc.: 55.47%] [G loss: 0.395200]\n",
      "epoch:29 step:27408 [D loss: 0.216728, acc.: 64.84%] [G loss: 0.405881]\n",
      "epoch:29 step:27409 [D loss: 0.222594, acc.: 61.72%] [G loss: 0.418360]\n",
      "epoch:29 step:27410 [D loss: 0.226359, acc.: 66.41%] [G loss: 0.423985]\n",
      "epoch:29 step:27411 [D loss: 0.227781, acc.: 64.06%] [G loss: 0.406132]\n",
      "epoch:29 step:27412 [D loss: 0.195953, acc.: 67.97%] [G loss: 0.432958]\n",
      "epoch:29 step:27413 [D loss: 0.223461, acc.: 62.50%] [G loss: 0.446407]\n",
      "epoch:29 step:27414 [D loss: 0.200956, acc.: 70.31%] [G loss: 0.433970]\n",
      "epoch:29 step:27415 [D loss: 0.200553, acc.: 71.09%] [G loss: 0.423740]\n",
      "epoch:29 step:27416 [D loss: 0.202054, acc.: 68.75%] [G loss: 0.414324]\n",
      "epoch:29 step:27417 [D loss: 0.186975, acc.: 73.44%] [G loss: 0.479499]\n",
      "epoch:29 step:27418 [D loss: 0.189990, acc.: 72.66%] [G loss: 0.438586]\n",
      "epoch:29 step:27419 [D loss: 0.216746, acc.: 63.28%] [G loss: 0.460997]\n",
      "epoch:29 step:27420 [D loss: 0.220552, acc.: 67.19%] [G loss: 0.459492]\n",
      "epoch:29 step:27421 [D loss: 0.205161, acc.: 63.28%] [G loss: 0.515571]\n",
      "epoch:29 step:27422 [D loss: 0.276784, acc.: 53.12%] [G loss: 0.489062]\n",
      "epoch:29 step:27423 [D loss: 0.258739, acc.: 57.81%] [G loss: 0.440402]\n",
      "epoch:29 step:27424 [D loss: 0.239625, acc.: 59.38%] [G loss: 0.431277]\n",
      "epoch:29 step:27425 [D loss: 0.231522, acc.: 60.16%] [G loss: 0.425921]\n",
      "epoch:29 step:27426 [D loss: 0.235198, acc.: 61.72%] [G loss: 0.414196]\n",
      "epoch:29 step:27427 [D loss: 0.234320, acc.: 60.94%] [G loss: 0.408599]\n",
      "epoch:29 step:27428 [D loss: 0.219954, acc.: 64.84%] [G loss: 0.430494]\n",
      "epoch:29 step:27429 [D loss: 0.214758, acc.: 63.28%] [G loss: 0.456834]\n",
      "epoch:29 step:27430 [D loss: 0.233873, acc.: 60.94%] [G loss: 0.436170]\n",
      "epoch:29 step:27431 [D loss: 0.204841, acc.: 65.62%] [G loss: 0.449577]\n",
      "epoch:29 step:27432 [D loss: 0.213252, acc.: 71.09%] [G loss: 0.435641]\n",
      "epoch:29 step:27433 [D loss: 0.232719, acc.: 63.28%] [G loss: 0.434824]\n",
      "epoch:29 step:27434 [D loss: 0.223075, acc.: 67.97%] [G loss: 0.441399]\n",
      "epoch:29 step:27435 [D loss: 0.212124, acc.: 66.41%] [G loss: 0.443460]\n",
      "epoch:29 step:27436 [D loss: 0.225170, acc.: 60.94%] [G loss: 0.426708]\n",
      "epoch:29 step:27437 [D loss: 0.199902, acc.: 67.19%] [G loss: 0.437965]\n",
      "epoch:29 step:27438 [D loss: 0.242427, acc.: 59.38%] [G loss: 0.428383]\n",
      "epoch:29 step:27439 [D loss: 0.225466, acc.: 62.50%] [G loss: 0.434152]\n",
      "epoch:29 step:27440 [D loss: 0.232175, acc.: 58.59%] [G loss: 0.424272]\n",
      "epoch:29 step:27441 [D loss: 0.206883, acc.: 67.19%] [G loss: 0.492731]\n",
      "epoch:29 step:27442 [D loss: 0.218203, acc.: 67.97%] [G loss: 0.513466]\n",
      "epoch:29 step:27443 [D loss: 0.229516, acc.: 67.19%] [G loss: 0.409335]\n",
      "epoch:29 step:27444 [D loss: 0.201552, acc.: 67.97%] [G loss: 0.458997]\n",
      "epoch:29 step:27445 [D loss: 0.239993, acc.: 57.81%] [G loss: 0.426626]\n",
      "epoch:29 step:27446 [D loss: 0.208259, acc.: 67.97%] [G loss: 0.441533]\n",
      "epoch:29 step:27447 [D loss: 0.196594, acc.: 71.09%] [G loss: 0.478738]\n",
      "epoch:29 step:27448 [D loss: 0.204394, acc.: 68.75%] [G loss: 0.442392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27449 [D loss: 0.185195, acc.: 75.00%] [G loss: 0.434749]\n",
      "epoch:29 step:27450 [D loss: 0.228340, acc.: 61.72%] [G loss: 0.443784]\n",
      "epoch:29 step:27451 [D loss: 0.238569, acc.: 60.16%] [G loss: 0.455585]\n",
      "epoch:29 step:27452 [D loss: 0.217923, acc.: 63.28%] [G loss: 0.415463]\n",
      "epoch:29 step:27453 [D loss: 0.210998, acc.: 58.59%] [G loss: 0.450604]\n",
      "epoch:29 step:27454 [D loss: 0.244201, acc.: 57.81%] [G loss: 0.431790]\n",
      "epoch:29 step:27455 [D loss: 0.220387, acc.: 64.84%] [G loss: 0.416377]\n",
      "epoch:29 step:27456 [D loss: 0.191997, acc.: 73.44%] [G loss: 0.445258]\n",
      "epoch:29 step:27457 [D loss: 0.205455, acc.: 70.31%] [G loss: 0.458502]\n",
      "epoch:29 step:27458 [D loss: 0.239670, acc.: 59.38%] [G loss: 0.431670]\n",
      "epoch:29 step:27459 [D loss: 0.196470, acc.: 71.09%] [G loss: 0.460756]\n",
      "epoch:29 step:27460 [D loss: 0.257278, acc.: 54.69%] [G loss: 0.423632]\n",
      "epoch:29 step:27461 [D loss: 0.194476, acc.: 72.66%] [G loss: 0.477083]\n",
      "epoch:29 step:27462 [D loss: 0.184999, acc.: 72.66%] [G loss: 0.489649]\n",
      "epoch:29 step:27463 [D loss: 0.235281, acc.: 62.50%] [G loss: 0.461316]\n",
      "epoch:29 step:27464 [D loss: 0.243833, acc.: 60.16%] [G loss: 0.457340]\n",
      "epoch:29 step:27465 [D loss: 0.216417, acc.: 62.50%] [G loss: 0.414271]\n",
      "epoch:29 step:27466 [D loss: 0.211625, acc.: 69.53%] [G loss: 0.469683]\n",
      "epoch:29 step:27467 [D loss: 0.253421, acc.: 56.25%] [G loss: 0.413102]\n",
      "epoch:29 step:27468 [D loss: 0.224522, acc.: 63.28%] [G loss: 0.438147]\n",
      "epoch:29 step:27469 [D loss: 0.199627, acc.: 71.09%] [G loss: 0.454045]\n",
      "epoch:29 step:27470 [D loss: 0.224305, acc.: 64.06%] [G loss: 0.448947]\n",
      "epoch:29 step:27471 [D loss: 0.199318, acc.: 67.19%] [G loss: 0.422806]\n",
      "epoch:29 step:27472 [D loss: 0.202306, acc.: 69.53%] [G loss: 0.458346]\n",
      "epoch:29 step:27473 [D loss: 0.200726, acc.: 67.97%] [G loss: 0.458745]\n",
      "epoch:29 step:27474 [D loss: 0.241471, acc.: 54.69%] [G loss: 0.464891]\n",
      "epoch:29 step:27475 [D loss: 0.242069, acc.: 60.16%] [G loss: 0.433890]\n",
      "epoch:29 step:27476 [D loss: 0.217906, acc.: 67.97%] [G loss: 0.481530]\n",
      "epoch:29 step:27477 [D loss: 0.239536, acc.: 54.69%] [G loss: 0.421096]\n",
      "epoch:29 step:27478 [D loss: 0.239414, acc.: 56.25%] [G loss: 0.450792]\n",
      "epoch:29 step:27479 [D loss: 0.224974, acc.: 60.94%] [G loss: 0.470168]\n",
      "epoch:29 step:27480 [D loss: 0.221790, acc.: 65.62%] [G loss: 0.480295]\n",
      "epoch:29 step:27481 [D loss: 0.244938, acc.: 55.47%] [G loss: 0.415267]\n",
      "epoch:29 step:27482 [D loss: 0.234999, acc.: 61.72%] [G loss: 0.421571]\n",
      "epoch:29 step:27483 [D loss: 0.216417, acc.: 63.28%] [G loss: 0.405192]\n",
      "epoch:29 step:27484 [D loss: 0.212668, acc.: 67.19%] [G loss: 0.438189]\n",
      "epoch:29 step:27485 [D loss: 0.184554, acc.: 73.44%] [G loss: 0.440959]\n",
      "epoch:29 step:27486 [D loss: 0.187802, acc.: 71.88%] [G loss: 0.471087]\n",
      "epoch:29 step:27487 [D loss: 0.179731, acc.: 71.09%] [G loss: 0.498515]\n",
      "epoch:29 step:27488 [D loss: 0.198543, acc.: 66.41%] [G loss: 0.497486]\n",
      "epoch:29 step:27489 [D loss: 0.251715, acc.: 55.47%] [G loss: 0.468330]\n",
      "epoch:29 step:27490 [D loss: 0.257224, acc.: 55.47%] [G loss: 0.414015]\n",
      "epoch:29 step:27491 [D loss: 0.207647, acc.: 67.19%] [G loss: 0.446871]\n",
      "epoch:29 step:27492 [D loss: 0.218934, acc.: 64.84%] [G loss: 0.446835]\n",
      "epoch:29 step:27493 [D loss: 0.222704, acc.: 64.06%] [G loss: 0.468894]\n",
      "epoch:29 step:27494 [D loss: 0.195564, acc.: 69.53%] [G loss: 0.472249]\n",
      "epoch:29 step:27495 [D loss: 0.202122, acc.: 68.75%] [G loss: 0.425153]\n",
      "epoch:29 step:27496 [D loss: 0.265072, acc.: 58.59%] [G loss: 0.413695]\n",
      "epoch:29 step:27497 [D loss: 0.213044, acc.: 69.53%] [G loss: 0.442110]\n",
      "epoch:29 step:27498 [D loss: 0.209895, acc.: 64.84%] [G loss: 0.444650]\n",
      "epoch:29 step:27499 [D loss: 0.201119, acc.: 68.75%] [G loss: 0.440806]\n",
      "epoch:29 step:27500 [D loss: 0.209447, acc.: 64.06%] [G loss: 0.484020]\n",
      "epoch:29 step:27501 [D loss: 0.207079, acc.: 65.62%] [G loss: 0.410651]\n",
      "epoch:29 step:27502 [D loss: 0.243995, acc.: 64.84%] [G loss: 0.425840]\n",
      "epoch:29 step:27503 [D loss: 0.220070, acc.: 64.84%] [G loss: 0.423269]\n",
      "epoch:29 step:27504 [D loss: 0.233768, acc.: 67.19%] [G loss: 0.405034]\n",
      "epoch:29 step:27505 [D loss: 0.215209, acc.: 66.41%] [G loss: 0.406905]\n",
      "epoch:29 step:27506 [D loss: 0.230258, acc.: 64.06%] [G loss: 0.427143]\n",
      "epoch:29 step:27507 [D loss: 0.229246, acc.: 59.38%] [G loss: 0.435433]\n",
      "epoch:29 step:27508 [D loss: 0.215226, acc.: 64.84%] [G loss: 0.480733]\n",
      "epoch:29 step:27509 [D loss: 0.206723, acc.: 74.22%] [G loss: 0.456183]\n",
      "epoch:29 step:27510 [D loss: 0.230022, acc.: 61.72%] [G loss: 0.400300]\n",
      "epoch:29 step:27511 [D loss: 0.210516, acc.: 67.19%] [G loss: 0.447068]\n",
      "epoch:29 step:27512 [D loss: 0.200878, acc.: 71.09%] [G loss: 0.421604]\n",
      "epoch:29 step:27513 [D loss: 0.206365, acc.: 65.62%] [G loss: 0.441864]\n",
      "epoch:29 step:27514 [D loss: 0.268274, acc.: 50.78%] [G loss: 0.426727]\n",
      "epoch:29 step:27515 [D loss: 0.245006, acc.: 59.38%] [G loss: 0.443663]\n",
      "epoch:29 step:27516 [D loss: 0.245650, acc.: 60.94%] [G loss: 0.420510]\n",
      "epoch:29 step:27517 [D loss: 0.221152, acc.: 67.19%] [G loss: 0.451608]\n",
      "epoch:29 step:27518 [D loss: 0.220818, acc.: 60.16%] [G loss: 0.438328]\n",
      "epoch:29 step:27519 [D loss: 0.192048, acc.: 70.31%] [G loss: 0.467506]\n",
      "epoch:29 step:27520 [D loss: 0.178377, acc.: 75.78%] [G loss: 0.470651]\n",
      "epoch:29 step:27521 [D loss: 0.275496, acc.: 51.56%] [G loss: 0.428752]\n",
      "epoch:29 step:27522 [D loss: 0.247058, acc.: 53.91%] [G loss: 0.379466]\n",
      "epoch:29 step:27523 [D loss: 0.228862, acc.: 62.50%] [G loss: 0.374368]\n",
      "epoch:29 step:27524 [D loss: 0.224530, acc.: 64.06%] [G loss: 0.424257]\n",
      "epoch:29 step:27525 [D loss: 0.225744, acc.: 61.72%] [G loss: 0.404803]\n",
      "epoch:29 step:27526 [D loss: 0.212330, acc.: 67.19%] [G loss: 0.491010]\n",
      "epoch:29 step:27527 [D loss: 0.186995, acc.: 69.53%] [G loss: 0.499200]\n",
      "epoch:29 step:27528 [D loss: 0.245473, acc.: 58.59%] [G loss: 0.414952]\n",
      "epoch:29 step:27529 [D loss: 0.238336, acc.: 60.94%] [G loss: 0.427013]\n",
      "epoch:29 step:27530 [D loss: 0.205912, acc.: 63.28%] [G loss: 0.462836]\n",
      "epoch:29 step:27531 [D loss: 0.204859, acc.: 71.09%] [G loss: 0.451988]\n",
      "epoch:29 step:27532 [D loss: 0.199069, acc.: 72.66%] [G loss: 0.440574]\n",
      "epoch:29 step:27533 [D loss: 0.229774, acc.: 61.72%] [G loss: 0.418618]\n",
      "epoch:29 step:27534 [D loss: 0.223114, acc.: 63.28%] [G loss: 0.431574]\n",
      "epoch:29 step:27535 [D loss: 0.242957, acc.: 59.38%] [G loss: 0.448943]\n",
      "epoch:29 step:27536 [D loss: 0.221573, acc.: 63.28%] [G loss: 0.445911]\n",
      "epoch:29 step:27537 [D loss: 0.203170, acc.: 66.41%] [G loss: 0.442943]\n",
      "epoch:29 step:27538 [D loss: 0.221072, acc.: 65.62%] [G loss: 0.442477]\n",
      "epoch:29 step:27539 [D loss: 0.211671, acc.: 64.84%] [G loss: 0.441148]\n",
      "epoch:29 step:27540 [D loss: 0.193006, acc.: 70.31%] [G loss: 0.473280]\n",
      "epoch:29 step:27541 [D loss: 0.243280, acc.: 57.03%] [G loss: 0.405013]\n",
      "epoch:29 step:27542 [D loss: 0.224518, acc.: 59.38%] [G loss: 0.435285]\n",
      "epoch:29 step:27543 [D loss: 0.201772, acc.: 65.62%] [G loss: 0.398238]\n",
      "epoch:29 step:27544 [D loss: 0.199962, acc.: 67.19%] [G loss: 0.449664]\n",
      "epoch:29 step:27545 [D loss: 0.214653, acc.: 69.53%] [G loss: 0.426979]\n",
      "epoch:29 step:27546 [D loss: 0.222819, acc.: 63.28%] [G loss: 0.444969]\n",
      "epoch:29 step:27547 [D loss: 0.181926, acc.: 72.66%] [G loss: 0.426166]\n",
      "epoch:29 step:27548 [D loss: 0.230496, acc.: 65.62%] [G loss: 0.434186]\n",
      "epoch:29 step:27549 [D loss: 0.251563, acc.: 53.91%] [G loss: 0.437986]\n",
      "epoch:29 step:27550 [D loss: 0.250236, acc.: 61.72%] [G loss: 0.394610]\n",
      "epoch:29 step:27551 [D loss: 0.225362, acc.: 61.72%] [G loss: 0.429843]\n",
      "epoch:29 step:27552 [D loss: 0.213535, acc.: 66.41%] [G loss: 0.449726]\n",
      "epoch:29 step:27553 [D loss: 0.217204, acc.: 64.84%] [G loss: 0.421396]\n",
      "epoch:29 step:27554 [D loss: 0.213275, acc.: 65.62%] [G loss: 0.423927]\n",
      "epoch:29 step:27555 [D loss: 0.229472, acc.: 61.72%] [G loss: 0.403887]\n",
      "epoch:29 step:27556 [D loss: 0.253926, acc.: 58.59%] [G loss: 0.422223]\n",
      "epoch:29 step:27557 [D loss: 0.196383, acc.: 75.00%] [G loss: 0.434024]\n",
      "epoch:29 step:27558 [D loss: 0.191864, acc.: 71.88%] [G loss: 0.436733]\n",
      "epoch:29 step:27559 [D loss: 0.243093, acc.: 54.69%] [G loss: 0.432827]\n",
      "epoch:29 step:27560 [D loss: 0.203499, acc.: 67.97%] [G loss: 0.453732]\n",
      "epoch:29 step:27561 [D loss: 0.227858, acc.: 64.06%] [G loss: 0.416630]\n",
      "epoch:29 step:27562 [D loss: 0.205713, acc.: 67.19%] [G loss: 0.477569]\n",
      "epoch:29 step:27563 [D loss: 0.256003, acc.: 53.91%] [G loss: 0.437465]\n",
      "epoch:29 step:27564 [D loss: 0.219510, acc.: 68.75%] [G loss: 0.438327]\n",
      "epoch:29 step:27565 [D loss: 0.219331, acc.: 64.84%] [G loss: 0.469090]\n",
      "epoch:29 step:27566 [D loss: 0.240970, acc.: 59.38%] [G loss: 0.411966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27567 [D loss: 0.225856, acc.: 60.94%] [G loss: 0.413601]\n",
      "epoch:29 step:27568 [D loss: 0.220078, acc.: 64.06%] [G loss: 0.412569]\n",
      "epoch:29 step:27569 [D loss: 0.270988, acc.: 56.25%] [G loss: 0.441403]\n",
      "epoch:29 step:27570 [D loss: 0.225336, acc.: 60.16%] [G loss: 0.478034]\n",
      "epoch:29 step:27571 [D loss: 0.193721, acc.: 72.66%] [G loss: 0.481294]\n",
      "epoch:29 step:27572 [D loss: 0.210274, acc.: 67.19%] [G loss: 0.451597]\n",
      "epoch:29 step:27573 [D loss: 0.238781, acc.: 63.28%] [G loss: 0.384041]\n",
      "epoch:29 step:27574 [D loss: 0.226528, acc.: 57.03%] [G loss: 0.433788]\n",
      "epoch:29 step:27575 [D loss: 0.193947, acc.: 70.31%] [G loss: 0.431301]\n",
      "epoch:29 step:27576 [D loss: 0.237504, acc.: 53.91%] [G loss: 0.369981]\n",
      "epoch:29 step:27577 [D loss: 0.228868, acc.: 60.16%] [G loss: 0.433146]\n",
      "epoch:29 step:27578 [D loss: 0.200917, acc.: 67.97%] [G loss: 0.420129]\n",
      "epoch:29 step:27579 [D loss: 0.189060, acc.: 74.22%] [G loss: 0.480499]\n",
      "epoch:29 step:27580 [D loss: 0.233725, acc.: 59.38%] [G loss: 0.483953]\n",
      "epoch:29 step:27581 [D loss: 0.222828, acc.: 62.50%] [G loss: 0.482443]\n",
      "epoch:29 step:27582 [D loss: 0.214251, acc.: 68.75%] [G loss: 0.449689]\n",
      "epoch:29 step:27583 [D loss: 0.240714, acc.: 56.25%] [G loss: 0.422890]\n",
      "epoch:29 step:27584 [D loss: 0.257508, acc.: 53.91%] [G loss: 0.414463]\n",
      "epoch:29 step:27585 [D loss: 0.223669, acc.: 64.84%] [G loss: 0.395264]\n",
      "epoch:29 step:27586 [D loss: 0.215087, acc.: 65.62%] [G loss: 0.424699]\n",
      "epoch:29 step:27587 [D loss: 0.215370, acc.: 67.97%] [G loss: 0.431834]\n",
      "epoch:29 step:27588 [D loss: 0.203743, acc.: 69.53%] [G loss: 0.461336]\n",
      "epoch:29 step:27589 [D loss: 0.181538, acc.: 73.44%] [G loss: 0.551546]\n",
      "epoch:29 step:27590 [D loss: 0.240652, acc.: 60.16%] [G loss: 0.492425]\n",
      "epoch:29 step:27591 [D loss: 0.260180, acc.: 50.00%] [G loss: 0.440570]\n",
      "epoch:29 step:27592 [D loss: 0.225184, acc.: 64.84%] [G loss: 0.449806]\n",
      "epoch:29 step:27593 [D loss: 0.221459, acc.: 64.84%] [G loss: 0.433242]\n",
      "epoch:29 step:27594 [D loss: 0.263435, acc.: 53.12%] [G loss: 0.384124]\n",
      "epoch:29 step:27595 [D loss: 0.231256, acc.: 59.38%] [G loss: 0.401797]\n",
      "epoch:29 step:27596 [D loss: 0.226509, acc.: 60.94%] [G loss: 0.393088]\n",
      "epoch:29 step:27597 [D loss: 0.243538, acc.: 60.94%] [G loss: 0.396654]\n",
      "epoch:29 step:27598 [D loss: 0.214211, acc.: 67.19%] [G loss: 0.433373]\n",
      "epoch:29 step:27599 [D loss: 0.211061, acc.: 67.97%] [G loss: 0.414345]\n",
      "epoch:29 step:27600 [D loss: 0.204027, acc.: 67.97%] [G loss: 0.436267]\n",
      "epoch:29 step:27601 [D loss: 0.208565, acc.: 67.19%] [G loss: 0.446493]\n",
      "epoch:29 step:27602 [D loss: 0.202292, acc.: 70.31%] [G loss: 0.439195]\n",
      "epoch:29 step:27603 [D loss: 0.191476, acc.: 69.53%] [G loss: 0.455563]\n",
      "epoch:29 step:27604 [D loss: 0.219456, acc.: 61.72%] [G loss: 0.435109]\n",
      "epoch:29 step:27605 [D loss: 0.230596, acc.: 60.16%] [G loss: 0.436161]\n",
      "epoch:29 step:27606 [D loss: 0.214186, acc.: 64.06%] [G loss: 0.448684]\n",
      "epoch:29 step:27607 [D loss: 0.198920, acc.: 71.88%] [G loss: 0.445298]\n",
      "epoch:29 step:27608 [D loss: 0.202642, acc.: 69.53%] [G loss: 0.471637]\n",
      "epoch:29 step:27609 [D loss: 0.197022, acc.: 69.53%] [G loss: 0.456224]\n",
      "epoch:29 step:27610 [D loss: 0.291864, acc.: 41.41%] [G loss: 0.419172]\n",
      "epoch:29 step:27611 [D loss: 0.229197, acc.: 55.47%] [G loss: 0.442780]\n",
      "epoch:29 step:27612 [D loss: 0.209807, acc.: 64.84%] [G loss: 0.417585]\n",
      "epoch:29 step:27613 [D loss: 0.233417, acc.: 55.47%] [G loss: 0.435613]\n",
      "epoch:29 step:27614 [D loss: 0.216674, acc.: 65.62%] [G loss: 0.440325]\n",
      "epoch:29 step:27615 [D loss: 0.255222, acc.: 56.25%] [G loss: 0.421858]\n",
      "epoch:29 step:27616 [D loss: 0.254324, acc.: 58.59%] [G loss: 0.405852]\n",
      "epoch:29 step:27617 [D loss: 0.218032, acc.: 65.62%] [G loss: 0.428487]\n",
      "epoch:29 step:27618 [D loss: 0.233715, acc.: 57.81%] [G loss: 0.414775]\n",
      "epoch:29 step:27619 [D loss: 0.213249, acc.: 67.19%] [G loss: 0.419678]\n",
      "epoch:29 step:27620 [D loss: 0.207630, acc.: 68.75%] [G loss: 0.418247]\n",
      "epoch:29 step:27621 [D loss: 0.208086, acc.: 66.41%] [G loss: 0.452245]\n",
      "epoch:29 step:27622 [D loss: 0.235526, acc.: 55.47%] [G loss: 0.426531]\n",
      "epoch:29 step:27623 [D loss: 0.203677, acc.: 69.53%] [G loss: 0.444986]\n",
      "epoch:29 step:27624 [D loss: 0.199867, acc.: 67.19%] [G loss: 0.454922]\n",
      "epoch:29 step:27625 [D loss: 0.206398, acc.: 67.19%] [G loss: 0.449449]\n",
      "epoch:29 step:27626 [D loss: 0.209425, acc.: 63.28%] [G loss: 0.465206]\n",
      "epoch:29 step:27627 [D loss: 0.226367, acc.: 61.72%] [G loss: 0.421322]\n",
      "epoch:29 step:27628 [D loss: 0.215035, acc.: 68.75%] [G loss: 0.427832]\n",
      "epoch:29 step:27629 [D loss: 0.213388, acc.: 64.84%] [G loss: 0.436936]\n",
      "epoch:29 step:27630 [D loss: 0.216706, acc.: 60.94%] [G loss: 0.434741]\n",
      "epoch:29 step:27631 [D loss: 0.263342, acc.: 54.69%] [G loss: 0.452438]\n",
      "epoch:29 step:27632 [D loss: 0.218052, acc.: 64.06%] [G loss: 0.438433]\n",
      "epoch:29 step:27633 [D loss: 0.252491, acc.: 60.94%] [G loss: 0.389713]\n",
      "epoch:29 step:27634 [D loss: 0.234424, acc.: 62.50%] [G loss: 0.416616]\n",
      "epoch:29 step:27635 [D loss: 0.239547, acc.: 57.81%] [G loss: 0.373287]\n",
      "epoch:29 step:27636 [D loss: 0.232175, acc.: 60.16%] [G loss: 0.449948]\n",
      "epoch:29 step:27637 [D loss: 0.218735, acc.: 64.06%] [G loss: 0.407957]\n",
      "epoch:29 step:27638 [D loss: 0.239771, acc.: 61.72%] [G loss: 0.405397]\n",
      "epoch:29 step:27639 [D loss: 0.227749, acc.: 64.06%] [G loss: 0.445973]\n",
      "epoch:29 step:27640 [D loss: 0.231631, acc.: 63.28%] [G loss: 0.410715]\n",
      "epoch:29 step:27641 [D loss: 0.215798, acc.: 65.62%] [G loss: 0.441051]\n",
      "epoch:29 step:27642 [D loss: 0.214370, acc.: 65.62%] [G loss: 0.457411]\n",
      "epoch:29 step:27643 [D loss: 0.216764, acc.: 64.06%] [G loss: 0.490106]\n",
      "epoch:29 step:27644 [D loss: 0.187638, acc.: 76.56%] [G loss: 0.512869]\n",
      "epoch:29 step:27645 [D loss: 0.227400, acc.: 60.94%] [G loss: 0.457642]\n",
      "epoch:29 step:27646 [D loss: 0.258328, acc.: 53.91%] [G loss: 0.452139]\n",
      "epoch:29 step:27647 [D loss: 0.202934, acc.: 67.97%] [G loss: 0.498873]\n",
      "epoch:29 step:27648 [D loss: 0.191267, acc.: 71.88%] [G loss: 0.492609]\n",
      "epoch:29 step:27649 [D loss: 0.229293, acc.: 65.62%] [G loss: 0.513953]\n",
      "epoch:29 step:27650 [D loss: 0.265600, acc.: 53.91%] [G loss: 0.400347]\n",
      "epoch:29 step:27651 [D loss: 0.249317, acc.: 58.59%] [G loss: 0.401464]\n",
      "epoch:29 step:27652 [D loss: 0.210227, acc.: 67.19%] [G loss: 0.434532]\n",
      "epoch:29 step:27653 [D loss: 0.235479, acc.: 62.50%] [G loss: 0.441278]\n",
      "epoch:29 step:27654 [D loss: 0.190340, acc.: 72.66%] [G loss: 0.475714]\n",
      "epoch:29 step:27655 [D loss: 0.258303, acc.: 55.47%] [G loss: 0.465168]\n",
      "epoch:29 step:27656 [D loss: 0.219988, acc.: 61.72%] [G loss: 0.442094]\n",
      "epoch:29 step:27657 [D loss: 0.204475, acc.: 67.97%] [G loss: 0.450326]\n",
      "epoch:29 step:27658 [D loss: 0.224383, acc.: 64.06%] [G loss: 0.510263]\n",
      "epoch:29 step:27659 [D loss: 0.241840, acc.: 62.50%] [G loss: 0.443674]\n",
      "epoch:29 step:27660 [D loss: 0.242510, acc.: 57.81%] [G loss: 0.433721]\n",
      "epoch:29 step:27661 [D loss: 0.204177, acc.: 64.84%] [G loss: 0.429185]\n",
      "epoch:29 step:27662 [D loss: 0.237701, acc.: 58.59%] [G loss: 0.403922]\n",
      "epoch:29 step:27663 [D loss: 0.227167, acc.: 60.94%] [G loss: 0.391995]\n",
      "epoch:29 step:27664 [D loss: 0.218327, acc.: 63.28%] [G loss: 0.416386]\n",
      "epoch:29 step:27665 [D loss: 0.206293, acc.: 64.84%] [G loss: 0.448821]\n",
      "epoch:29 step:27666 [D loss: 0.206264, acc.: 71.88%] [G loss: 0.399677]\n",
      "epoch:29 step:27667 [D loss: 0.208223, acc.: 69.53%] [G loss: 0.412798]\n",
      "epoch:29 step:27668 [D loss: 0.201827, acc.: 69.53%] [G loss: 0.468834]\n",
      "epoch:29 step:27669 [D loss: 0.217133, acc.: 64.84%] [G loss: 0.451101]\n",
      "epoch:29 step:27670 [D loss: 0.214558, acc.: 67.19%] [G loss: 0.461883]\n",
      "epoch:29 step:27671 [D loss: 0.212254, acc.: 64.06%] [G loss: 0.476150]\n",
      "epoch:29 step:27672 [D loss: 0.176261, acc.: 78.91%] [G loss: 0.496255]\n",
      "epoch:29 step:27673 [D loss: 0.251655, acc.: 60.16%] [G loss: 0.445630]\n",
      "epoch:29 step:27674 [D loss: 0.262164, acc.: 60.16%] [G loss: 0.413316]\n",
      "epoch:29 step:27675 [D loss: 0.241228, acc.: 57.81%] [G loss: 0.429122]\n",
      "epoch:29 step:27676 [D loss: 0.228234, acc.: 56.25%] [G loss: 0.405460]\n",
      "epoch:29 step:27677 [D loss: 0.196541, acc.: 72.66%] [G loss: 0.438018]\n",
      "epoch:29 step:27678 [D loss: 0.185266, acc.: 71.09%] [G loss: 0.465106]\n",
      "epoch:29 step:27679 [D loss: 0.210512, acc.: 65.62%] [G loss: 0.413260]\n",
      "epoch:29 step:27680 [D loss: 0.201715, acc.: 64.84%] [G loss: 0.524811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27681 [D loss: 0.198882, acc.: 67.97%] [G loss: 0.526363]\n",
      "epoch:29 step:27682 [D loss: 0.257712, acc.: 63.28%] [G loss: 0.440745]\n",
      "epoch:29 step:27683 [D loss: 0.250345, acc.: 55.47%] [G loss: 0.391406]\n",
      "epoch:29 step:27684 [D loss: 0.239046, acc.: 53.12%] [G loss: 0.407963]\n",
      "epoch:29 step:27685 [D loss: 0.217502, acc.: 67.19%] [G loss: 0.427089]\n",
      "epoch:29 step:27686 [D loss: 0.190794, acc.: 66.41%] [G loss: 0.411239]\n",
      "epoch:29 step:27687 [D loss: 0.212869, acc.: 64.84%] [G loss: 0.414352]\n",
      "epoch:29 step:27688 [D loss: 0.203093, acc.: 64.84%] [G loss: 0.421447]\n",
      "epoch:29 step:27689 [D loss: 0.204578, acc.: 71.88%] [G loss: 0.473117]\n",
      "epoch:29 step:27690 [D loss: 0.262829, acc.: 51.56%] [G loss: 0.412332]\n",
      "epoch:29 step:27691 [D loss: 0.224899, acc.: 63.28%] [G loss: 0.444625]\n",
      "epoch:29 step:27692 [D loss: 0.198309, acc.: 67.97%] [G loss: 0.427838]\n",
      "epoch:29 step:27693 [D loss: 0.213409, acc.: 67.19%] [G loss: 0.466761]\n",
      "epoch:29 step:27694 [D loss: 0.201085, acc.: 67.97%] [G loss: 0.481610]\n",
      "epoch:29 step:27695 [D loss: 0.218319, acc.: 63.28%] [G loss: 0.422286]\n",
      "epoch:29 step:27696 [D loss: 0.192047, acc.: 71.88%] [G loss: 0.485210]\n",
      "epoch:29 step:27697 [D loss: 0.243832, acc.: 52.34%] [G loss: 0.413880]\n",
      "epoch:29 step:27698 [D loss: 0.192546, acc.: 73.44%] [G loss: 0.471142]\n",
      "epoch:29 step:27699 [D loss: 0.198390, acc.: 72.66%] [G loss: 0.441679]\n",
      "epoch:29 step:27700 [D loss: 0.213387, acc.: 67.19%] [G loss: 0.417867]\n",
      "epoch:29 step:27701 [D loss: 0.280547, acc.: 51.56%] [G loss: 0.377213]\n",
      "epoch:29 step:27702 [D loss: 0.239270, acc.: 57.81%] [G loss: 0.440451]\n",
      "epoch:29 step:27703 [D loss: 0.231681, acc.: 59.38%] [G loss: 0.481514]\n",
      "epoch:29 step:27704 [D loss: 0.234593, acc.: 57.81%] [G loss: 0.403206]\n",
      "epoch:29 step:27705 [D loss: 0.219537, acc.: 60.94%] [G loss: 0.400288]\n",
      "epoch:29 step:27706 [D loss: 0.221450, acc.: 63.28%] [G loss: 0.424564]\n",
      "epoch:29 step:27707 [D loss: 0.204492, acc.: 64.06%] [G loss: 0.451211]\n",
      "epoch:29 step:27708 [D loss: 0.262722, acc.: 50.78%] [G loss: 0.403951]\n",
      "epoch:29 step:27709 [D loss: 0.227187, acc.: 62.50%] [G loss: 0.417563]\n",
      "epoch:29 step:27710 [D loss: 0.214391, acc.: 64.06%] [G loss: 0.419313]\n",
      "epoch:29 step:27711 [D loss: 0.217918, acc.: 63.28%] [G loss: 0.388409]\n",
      "epoch:29 step:27712 [D loss: 0.229475, acc.: 61.72%] [G loss: 0.410729]\n",
      "epoch:29 step:27713 [D loss: 0.225754, acc.: 64.06%] [G loss: 0.406532]\n",
      "epoch:29 step:27714 [D loss: 0.208887, acc.: 65.62%] [G loss: 0.436058]\n",
      "epoch:29 step:27715 [D loss: 0.248629, acc.: 51.56%] [G loss: 0.402858]\n",
      "epoch:29 step:27716 [D loss: 0.229201, acc.: 61.72%] [G loss: 0.430074]\n",
      "epoch:29 step:27717 [D loss: 0.227549, acc.: 62.50%] [G loss: 0.392029]\n",
      "epoch:29 step:27718 [D loss: 0.209359, acc.: 65.62%] [G loss: 0.430549]\n",
      "epoch:29 step:27719 [D loss: 0.198203, acc.: 71.88%] [G loss: 0.390398]\n",
      "epoch:29 step:27720 [D loss: 0.223519, acc.: 65.62%] [G loss: 0.469691]\n",
      "epoch:29 step:27721 [D loss: 0.185146, acc.: 74.22%] [G loss: 0.431488]\n",
      "epoch:29 step:27722 [D loss: 0.196191, acc.: 67.19%] [G loss: 0.470145]\n",
      "epoch:29 step:27723 [D loss: 0.190396, acc.: 71.88%] [G loss: 0.466788]\n",
      "epoch:29 step:27724 [D loss: 0.196262, acc.: 71.09%] [G loss: 0.481381]\n",
      "epoch:29 step:27725 [D loss: 0.206996, acc.: 64.84%] [G loss: 0.458160]\n",
      "epoch:29 step:27726 [D loss: 0.236646, acc.: 61.72%] [G loss: 0.451647]\n",
      "epoch:29 step:27727 [D loss: 0.200174, acc.: 71.09%] [G loss: 0.454564]\n",
      "epoch:29 step:27728 [D loss: 0.203716, acc.: 66.41%] [G loss: 0.442757]\n",
      "epoch:29 step:27729 [D loss: 0.211439, acc.: 67.19%] [G loss: 0.411802]\n",
      "epoch:29 step:27730 [D loss: 0.206234, acc.: 67.19%] [G loss: 0.440024]\n",
      "epoch:29 step:27731 [D loss: 0.226653, acc.: 62.50%] [G loss: 0.421998]\n",
      "epoch:29 step:27732 [D loss: 0.249628, acc.: 57.81%] [G loss: 0.448175]\n",
      "epoch:29 step:27733 [D loss: 0.249197, acc.: 60.94%] [G loss: 0.460798]\n",
      "epoch:29 step:27734 [D loss: 0.212141, acc.: 64.84%] [G loss: 0.436006]\n",
      "epoch:29 step:27735 [D loss: 0.203022, acc.: 67.19%] [G loss: 0.443971]\n",
      "epoch:29 step:27736 [D loss: 0.195210, acc.: 68.75%] [G loss: 0.479372]\n",
      "epoch:29 step:27737 [D loss: 0.211752, acc.: 68.75%] [G loss: 0.460972]\n",
      "epoch:29 step:27738 [D loss: 0.225523, acc.: 67.19%] [G loss: 0.480608]\n",
      "epoch:29 step:27739 [D loss: 0.272313, acc.: 53.12%] [G loss: 0.444143]\n",
      "epoch:29 step:27740 [D loss: 0.231546, acc.: 60.16%] [G loss: 0.464547]\n",
      "epoch:29 step:27741 [D loss: 0.201540, acc.: 71.88%] [G loss: 0.436613]\n",
      "epoch:29 step:27742 [D loss: 0.250403, acc.: 54.69%] [G loss: 0.422550]\n",
      "epoch:29 step:27743 [D loss: 0.232922, acc.: 57.81%] [G loss: 0.397777]\n",
      "epoch:29 step:27744 [D loss: 0.214070, acc.: 64.84%] [G loss: 0.421201]\n",
      "epoch:29 step:27745 [D loss: 0.234532, acc.: 58.59%] [G loss: 0.436203]\n",
      "epoch:29 step:27746 [D loss: 0.228717, acc.: 66.41%] [G loss: 0.397950]\n",
      "epoch:29 step:27747 [D loss: 0.203901, acc.: 68.75%] [G loss: 0.487792]\n",
      "epoch:29 step:27748 [D loss: 0.219477, acc.: 67.19%] [G loss: 0.453727]\n",
      "epoch:29 step:27749 [D loss: 0.249676, acc.: 57.03%] [G loss: 0.433320]\n",
      "epoch:29 step:27750 [D loss: 0.211807, acc.: 63.28%] [G loss: 0.446853]\n",
      "epoch:29 step:27751 [D loss: 0.235717, acc.: 53.12%] [G loss: 0.423964]\n",
      "epoch:29 step:27752 [D loss: 0.204587, acc.: 69.53%] [G loss: 0.459835]\n",
      "epoch:29 step:27753 [D loss: 0.266714, acc.: 51.56%] [G loss: 0.426808]\n",
      "epoch:29 step:27754 [D loss: 0.185238, acc.: 73.44%] [G loss: 0.456024]\n",
      "epoch:29 step:27755 [D loss: 0.233413, acc.: 64.84%] [G loss: 0.465682]\n",
      "epoch:29 step:27756 [D loss: 0.233346, acc.: 60.94%] [G loss: 0.453091]\n",
      "epoch:29 step:27757 [D loss: 0.216121, acc.: 65.62%] [G loss: 0.437065]\n",
      "epoch:29 step:27758 [D loss: 0.220159, acc.: 63.28%] [G loss: 0.400540]\n",
      "epoch:29 step:27759 [D loss: 0.203911, acc.: 68.75%] [G loss: 0.412976]\n",
      "epoch:29 step:27760 [D loss: 0.217633, acc.: 64.84%] [G loss: 0.394551]\n",
      "epoch:29 step:27761 [D loss: 0.209676, acc.: 66.41%] [G loss: 0.457561]\n",
      "epoch:29 step:27762 [D loss: 0.200267, acc.: 71.88%] [G loss: 0.452437]\n",
      "epoch:29 step:27763 [D loss: 0.247071, acc.: 57.81%] [G loss: 0.441282]\n",
      "epoch:29 step:27764 [D loss: 0.240381, acc.: 58.59%] [G loss: 0.427327]\n",
      "epoch:29 step:27765 [D loss: 0.223895, acc.: 64.84%] [G loss: 0.463485]\n",
      "epoch:29 step:27766 [D loss: 0.193911, acc.: 74.22%] [G loss: 0.425160]\n",
      "epoch:29 step:27767 [D loss: 0.239375, acc.: 56.25%] [G loss: 0.398365]\n",
      "epoch:29 step:27768 [D loss: 0.201925, acc.: 65.62%] [G loss: 0.425700]\n",
      "epoch:29 step:27769 [D loss: 0.223911, acc.: 62.50%] [G loss: 0.427534]\n",
      "epoch:29 step:27770 [D loss: 0.225276, acc.: 64.84%] [G loss: 0.478793]\n",
      "epoch:29 step:27771 [D loss: 0.251637, acc.: 56.25%] [G loss: 0.418462]\n",
      "epoch:29 step:27772 [D loss: 0.206603, acc.: 69.53%] [G loss: 0.455456]\n",
      "epoch:29 step:27773 [D loss: 0.242517, acc.: 57.81%] [G loss: 0.448844]\n",
      "epoch:29 step:27774 [D loss: 0.220901, acc.: 62.50%] [G loss: 0.431524]\n",
      "epoch:29 step:27775 [D loss: 0.252679, acc.: 54.69%] [G loss: 0.409137]\n",
      "epoch:29 step:27776 [D loss: 0.233759, acc.: 62.50%] [G loss: 0.413461]\n",
      "epoch:29 step:27777 [D loss: 0.229519, acc.: 60.16%] [G loss: 0.396426]\n",
      "epoch:29 step:27778 [D loss: 0.205590, acc.: 67.19%] [G loss: 0.448134]\n",
      "epoch:29 step:27779 [D loss: 0.260322, acc.: 57.03%] [G loss: 0.403290]\n",
      "epoch:29 step:27780 [D loss: 0.211343, acc.: 64.84%] [G loss: 0.401649]\n",
      "epoch:29 step:27781 [D loss: 0.215284, acc.: 64.84%] [G loss: 0.416074]\n",
      "epoch:29 step:27782 [D loss: 0.224398, acc.: 58.59%] [G loss: 0.390030]\n",
      "epoch:29 step:27783 [D loss: 0.213320, acc.: 63.28%] [G loss: 0.413135]\n",
      "epoch:29 step:27784 [D loss: 0.205055, acc.: 67.19%] [G loss: 0.421747]\n",
      "epoch:29 step:27785 [D loss: 0.219250, acc.: 60.94%] [G loss: 0.373691]\n",
      "epoch:29 step:27786 [D loss: 0.215835, acc.: 61.72%] [G loss: 0.375507]\n",
      "epoch:29 step:27787 [D loss: 0.265180, acc.: 53.12%] [G loss: 0.395300]\n",
      "epoch:29 step:27788 [D loss: 0.243519, acc.: 53.12%] [G loss: 0.411702]\n",
      "epoch:29 step:27789 [D loss: 0.234288, acc.: 55.47%] [G loss: 0.387637]\n",
      "epoch:29 step:27790 [D loss: 0.217077, acc.: 67.97%] [G loss: 0.441296]\n",
      "epoch:29 step:27791 [D loss: 0.218151, acc.: 66.41%] [G loss: 0.492590]\n",
      "epoch:29 step:27792 [D loss: 0.235949, acc.: 58.59%] [G loss: 0.431296]\n",
      "epoch:29 step:27793 [D loss: 0.203544, acc.: 64.84%] [G loss: 0.453325]\n",
      "epoch:29 step:27794 [D loss: 0.207763, acc.: 62.50%] [G loss: 0.411983]\n",
      "epoch:29 step:27795 [D loss: 0.243735, acc.: 57.03%] [G loss: 0.365798]\n",
      "epoch:29 step:27796 [D loss: 0.214971, acc.: 67.97%] [G loss: 0.407027]\n",
      "epoch:29 step:27797 [D loss: 0.193330, acc.: 70.31%] [G loss: 0.407867]\n",
      "epoch:29 step:27798 [D loss: 0.234773, acc.: 68.75%] [G loss: 0.451501]\n",
      "epoch:29 step:27799 [D loss: 0.236324, acc.: 59.38%] [G loss: 0.432983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27800 [D loss: 0.225724, acc.: 64.06%] [G loss: 0.386138]\n",
      "epoch:29 step:27801 [D loss: 0.216780, acc.: 60.16%] [G loss: 0.418995]\n",
      "epoch:29 step:27802 [D loss: 0.222789, acc.: 64.06%] [G loss: 0.412802]\n",
      "epoch:29 step:27803 [D loss: 0.209332, acc.: 63.28%] [G loss: 0.434282]\n",
      "epoch:29 step:27804 [D loss: 0.194831, acc.: 68.75%] [G loss: 0.446023]\n",
      "epoch:29 step:27805 [D loss: 0.213437, acc.: 68.75%] [G loss: 0.422001]\n",
      "epoch:29 step:27806 [D loss: 0.225049, acc.: 62.50%] [G loss: 0.462868]\n",
      "epoch:29 step:27807 [D loss: 0.204655, acc.: 65.62%] [G loss: 0.451167]\n",
      "epoch:29 step:27808 [D loss: 0.204770, acc.: 69.53%] [G loss: 0.466650]\n",
      "epoch:29 step:27809 [D loss: 0.238359, acc.: 56.25%] [G loss: 0.446737]\n",
      "epoch:29 step:27810 [D loss: 0.214573, acc.: 66.41%] [G loss: 0.442533]\n",
      "epoch:29 step:27811 [D loss: 0.217327, acc.: 64.06%] [G loss: 0.430250]\n",
      "epoch:29 step:27812 [D loss: 0.219210, acc.: 60.16%] [G loss: 0.453955]\n",
      "epoch:29 step:27813 [D loss: 0.224287, acc.: 63.28%] [G loss: 0.426039]\n",
      "epoch:29 step:27814 [D loss: 0.224595, acc.: 64.06%] [G loss: 0.421917]\n",
      "epoch:29 step:27815 [D loss: 0.189617, acc.: 71.09%] [G loss: 0.490669]\n",
      "epoch:29 step:27816 [D loss: 0.235637, acc.: 59.38%] [G loss: 0.479102]\n",
      "epoch:29 step:27817 [D loss: 0.212780, acc.: 64.84%] [G loss: 0.449007]\n",
      "epoch:29 step:27818 [D loss: 0.241680, acc.: 57.81%] [G loss: 0.392167]\n",
      "epoch:29 step:27819 [D loss: 0.222492, acc.: 65.62%] [G loss: 0.437999]\n",
      "epoch:29 step:27820 [D loss: 0.210396, acc.: 68.75%] [G loss: 0.471468]\n",
      "epoch:29 step:27821 [D loss: 0.176996, acc.: 81.25%] [G loss: 0.476197]\n",
      "epoch:29 step:27822 [D loss: 0.198211, acc.: 69.53%] [G loss: 0.484623]\n",
      "epoch:29 step:27823 [D loss: 0.202911, acc.: 69.53%] [G loss: 0.450216]\n",
      "epoch:29 step:27824 [D loss: 0.225656, acc.: 62.50%] [G loss: 0.435470]\n",
      "epoch:29 step:27825 [D loss: 0.228718, acc.: 65.62%] [G loss: 0.475378]\n",
      "epoch:29 step:27826 [D loss: 0.195134, acc.: 70.31%] [G loss: 0.466906]\n",
      "epoch:29 step:27827 [D loss: 0.220010, acc.: 62.50%] [G loss: 0.436889]\n",
      "epoch:29 step:27828 [D loss: 0.245922, acc.: 57.03%] [G loss: 0.410677]\n",
      "epoch:29 step:27829 [D loss: 0.249095, acc.: 57.03%] [G loss: 0.426288]\n",
      "epoch:29 step:27830 [D loss: 0.240235, acc.: 54.69%] [G loss: 0.417248]\n",
      "epoch:29 step:27831 [D loss: 0.214101, acc.: 63.28%] [G loss: 0.437849]\n",
      "epoch:29 step:27832 [D loss: 0.225436, acc.: 65.62%] [G loss: 0.405560]\n",
      "epoch:29 step:27833 [D loss: 0.216370, acc.: 63.28%] [G loss: 0.403320]\n",
      "epoch:29 step:27834 [D loss: 0.204194, acc.: 68.75%] [G loss: 0.449514]\n",
      "epoch:29 step:27835 [D loss: 0.207817, acc.: 67.97%] [G loss: 0.433817]\n",
      "epoch:29 step:27836 [D loss: 0.231860, acc.: 57.03%] [G loss: 0.448177]\n",
      "epoch:29 step:27837 [D loss: 0.241687, acc.: 59.38%] [G loss: 0.437379]\n",
      "epoch:29 step:27838 [D loss: 0.232422, acc.: 57.81%] [G loss: 0.403491]\n",
      "epoch:29 step:27839 [D loss: 0.205882, acc.: 65.62%] [G loss: 0.474308]\n",
      "epoch:29 step:27840 [D loss: 0.222544, acc.: 64.06%] [G loss: 0.444870]\n",
      "epoch:29 step:27841 [D loss: 0.241600, acc.: 60.16%] [G loss: 0.405421]\n",
      "epoch:29 step:27842 [D loss: 0.239914, acc.: 57.03%] [G loss: 0.397296]\n",
      "epoch:29 step:27843 [D loss: 0.238444, acc.: 57.03%] [G loss: 0.407060]\n",
      "epoch:29 step:27844 [D loss: 0.216431, acc.: 63.28%] [G loss: 0.413477]\n",
      "epoch:29 step:27845 [D loss: 0.221264, acc.: 63.28%] [G loss: 0.401403]\n",
      "epoch:29 step:27846 [D loss: 0.231364, acc.: 59.38%] [G loss: 0.425204]\n",
      "epoch:29 step:27847 [D loss: 0.216452, acc.: 64.84%] [G loss: 0.467233]\n",
      "epoch:29 step:27848 [D loss: 0.232915, acc.: 59.38%] [G loss: 0.420089]\n",
      "epoch:29 step:27849 [D loss: 0.200901, acc.: 69.53%] [G loss: 0.421406]\n",
      "epoch:29 step:27850 [D loss: 0.189045, acc.: 72.66%] [G loss: 0.439279]\n",
      "epoch:29 step:27851 [D loss: 0.239057, acc.: 58.59%] [G loss: 0.439280]\n",
      "epoch:29 step:27852 [D loss: 0.206693, acc.: 65.62%] [G loss: 0.446471]\n",
      "epoch:29 step:27853 [D loss: 0.231480, acc.: 60.94%] [G loss: 0.456389]\n",
      "epoch:29 step:27854 [D loss: 0.209790, acc.: 64.06%] [G loss: 0.466859]\n",
      "epoch:29 step:27855 [D loss: 0.223587, acc.: 64.84%] [G loss: 0.458172]\n",
      "epoch:29 step:27856 [D loss: 0.232235, acc.: 60.94%] [G loss: 0.418883]\n",
      "epoch:29 step:27857 [D loss: 0.239153, acc.: 60.16%] [G loss: 0.455380]\n",
      "epoch:29 step:27858 [D loss: 0.206223, acc.: 64.84%] [G loss: 0.409226]\n",
      "epoch:29 step:27859 [D loss: 0.193771, acc.: 76.56%] [G loss: 0.468551]\n",
      "epoch:29 step:27860 [D loss: 0.232541, acc.: 58.59%] [G loss: 0.414278]\n",
      "epoch:29 step:27861 [D loss: 0.190817, acc.: 71.09%] [G loss: 0.446541]\n",
      "epoch:29 step:27862 [D loss: 0.231999, acc.: 62.50%] [G loss: 0.445832]\n",
      "epoch:29 step:27863 [D loss: 0.214841, acc.: 64.84%] [G loss: 0.447854]\n",
      "epoch:29 step:27864 [D loss: 0.187450, acc.: 73.44%] [G loss: 0.467462]\n",
      "epoch:29 step:27865 [D loss: 0.208002, acc.: 68.75%] [G loss: 0.485394]\n",
      "epoch:29 step:27866 [D loss: 0.197821, acc.: 66.41%] [G loss: 0.477627]\n",
      "epoch:29 step:27867 [D loss: 0.201455, acc.: 70.31%] [G loss: 0.455990]\n",
      "epoch:29 step:27868 [D loss: 0.212502, acc.: 67.19%] [G loss: 0.499350]\n",
      "epoch:29 step:27869 [D loss: 0.260247, acc.: 53.91%] [G loss: 0.424066]\n",
      "epoch:29 step:27870 [D loss: 0.216061, acc.: 66.41%] [G loss: 0.432508]\n",
      "epoch:29 step:27871 [D loss: 0.239153, acc.: 58.59%] [G loss: 0.428327]\n",
      "epoch:29 step:27872 [D loss: 0.207281, acc.: 66.41%] [G loss: 0.462484]\n",
      "epoch:29 step:27873 [D loss: 0.211836, acc.: 68.75%] [G loss: 0.496240]\n",
      "epoch:29 step:27874 [D loss: 0.219042, acc.: 61.72%] [G loss: 0.445923]\n",
      "epoch:29 step:27875 [D loss: 0.251870, acc.: 50.78%] [G loss: 0.435797]\n",
      "epoch:29 step:27876 [D loss: 0.239212, acc.: 55.47%] [G loss: 0.462501]\n",
      "epoch:29 step:27877 [D loss: 0.235772, acc.: 57.03%] [G loss: 0.421426]\n",
      "epoch:29 step:27878 [D loss: 0.219159, acc.: 65.62%] [G loss: 0.469433]\n",
      "epoch:29 step:27879 [D loss: 0.215255, acc.: 64.06%] [G loss: 0.401410]\n",
      "epoch:29 step:27880 [D loss: 0.209962, acc.: 64.06%] [G loss: 0.412983]\n",
      "epoch:29 step:27881 [D loss: 0.205410, acc.: 69.53%] [G loss: 0.431651]\n",
      "epoch:29 step:27882 [D loss: 0.173714, acc.: 73.44%] [G loss: 0.497173]\n",
      "epoch:29 step:27883 [D loss: 0.263617, acc.: 53.12%] [G loss: 0.406149]\n",
      "epoch:29 step:27884 [D loss: 0.241575, acc.: 57.03%] [G loss: 0.402186]\n",
      "epoch:29 step:27885 [D loss: 0.227779, acc.: 61.72%] [G loss: 0.440134]\n",
      "epoch:29 step:27886 [D loss: 0.204452, acc.: 66.41%] [G loss: 0.453403]\n",
      "epoch:29 step:27887 [D loss: 0.217400, acc.: 64.06%] [G loss: 0.453881]\n",
      "epoch:29 step:27888 [D loss: 0.212063, acc.: 63.28%] [G loss: 0.458198]\n",
      "epoch:29 step:27889 [D loss: 0.221988, acc.: 61.72%] [G loss: 0.453807]\n",
      "epoch:29 step:27890 [D loss: 0.220689, acc.: 67.19%] [G loss: 0.434525]\n",
      "epoch:29 step:27891 [D loss: 0.208912, acc.: 69.53%] [G loss: 0.474215]\n",
      "epoch:29 step:27892 [D loss: 0.199543, acc.: 73.44%] [G loss: 0.530265]\n",
      "epoch:29 step:27893 [D loss: 0.223003, acc.: 65.62%] [G loss: 0.425466]\n",
      "epoch:29 step:27894 [D loss: 0.238372, acc.: 55.47%] [G loss: 0.419370]\n",
      "epoch:29 step:27895 [D loss: 0.233402, acc.: 63.28%] [G loss: 0.429505]\n",
      "epoch:29 step:27896 [D loss: 0.213508, acc.: 69.53%] [G loss: 0.428983]\n",
      "epoch:29 step:27897 [D loss: 0.193111, acc.: 71.09%] [G loss: 0.446215]\n",
      "epoch:29 step:27898 [D loss: 0.199145, acc.: 71.88%] [G loss: 0.467004]\n",
      "epoch:29 step:27899 [D loss: 0.220244, acc.: 67.19%] [G loss: 0.439342]\n",
      "epoch:29 step:27900 [D loss: 0.229653, acc.: 53.91%] [G loss: 0.445964]\n",
      "epoch:29 step:27901 [D loss: 0.229421, acc.: 57.81%] [G loss: 0.437390]\n",
      "epoch:29 step:27902 [D loss: 0.216924, acc.: 64.84%] [G loss: 0.420096]\n",
      "epoch:29 step:27903 [D loss: 0.219402, acc.: 66.41%] [G loss: 0.436228]\n",
      "epoch:29 step:27904 [D loss: 0.198621, acc.: 70.31%] [G loss: 0.443998]\n",
      "epoch:29 step:27905 [D loss: 0.222950, acc.: 63.28%] [G loss: 0.439844]\n",
      "epoch:29 step:27906 [D loss: 0.211117, acc.: 66.41%] [G loss: 0.473958]\n",
      "epoch:29 step:27907 [D loss: 0.252897, acc.: 57.03%] [G loss: 0.435463]\n",
      "epoch:29 step:27908 [D loss: 0.240957, acc.: 59.38%] [G loss: 0.401108]\n",
      "epoch:29 step:27909 [D loss: 0.216479, acc.: 67.19%] [G loss: 0.407003]\n",
      "epoch:29 step:27910 [D loss: 0.210964, acc.: 65.62%] [G loss: 0.441402]\n",
      "epoch:29 step:27911 [D loss: 0.233051, acc.: 57.81%] [G loss: 0.385865]\n",
      "epoch:29 step:27912 [D loss: 0.240918, acc.: 59.38%] [G loss: 0.411876]\n",
      "epoch:29 step:27913 [D loss: 0.243910, acc.: 59.38%] [G loss: 0.393696]\n",
      "epoch:29 step:27914 [D loss: 0.218691, acc.: 63.28%] [G loss: 0.409817]\n",
      "epoch:29 step:27915 [D loss: 0.233857, acc.: 65.62%] [G loss: 0.403092]\n",
      "epoch:29 step:27916 [D loss: 0.228948, acc.: 60.16%] [G loss: 0.463711]\n",
      "epoch:29 step:27917 [D loss: 0.233754, acc.: 57.81%] [G loss: 0.425583]\n",
      "epoch:29 step:27918 [D loss: 0.224622, acc.: 59.38%] [G loss: 0.437240]\n",
      "epoch:29 step:27919 [D loss: 0.232440, acc.: 61.72%] [G loss: 0.411541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27920 [D loss: 0.212941, acc.: 65.62%] [G loss: 0.417272]\n",
      "epoch:29 step:27921 [D loss: 0.249986, acc.: 56.25%] [G loss: 0.420413]\n",
      "epoch:29 step:27922 [D loss: 0.238108, acc.: 53.91%] [G loss: 0.423784]\n",
      "epoch:29 step:27923 [D loss: 0.216042, acc.: 61.72%] [G loss: 0.409296]\n",
      "epoch:29 step:27924 [D loss: 0.210422, acc.: 67.97%] [G loss: 0.437758]\n",
      "epoch:29 step:27925 [D loss: 0.226534, acc.: 66.41%] [G loss: 0.432364]\n",
      "epoch:29 step:27926 [D loss: 0.231532, acc.: 58.59%] [G loss: 0.401594]\n",
      "epoch:29 step:27927 [D loss: 0.199287, acc.: 71.09%] [G loss: 0.431642]\n",
      "epoch:29 step:27928 [D loss: 0.213453, acc.: 68.75%] [G loss: 0.454759]\n",
      "epoch:29 step:27929 [D loss: 0.212669, acc.: 65.62%] [G loss: 0.418581]\n",
      "epoch:29 step:27930 [D loss: 0.254659, acc.: 59.38%] [G loss: 0.440506]\n",
      "epoch:29 step:27931 [D loss: 0.252250, acc.: 59.38%] [G loss: 0.400354]\n",
      "epoch:29 step:27932 [D loss: 0.230150, acc.: 60.16%] [G loss: 0.423415]\n",
      "epoch:29 step:27933 [D loss: 0.233840, acc.: 62.50%] [G loss: 0.418489]\n",
      "epoch:29 step:27934 [D loss: 0.231350, acc.: 62.50%] [G loss: 0.440177]\n",
      "epoch:29 step:27935 [D loss: 0.225169, acc.: 60.16%] [G loss: 0.390004]\n",
      "epoch:29 step:27936 [D loss: 0.228229, acc.: 64.06%] [G loss: 0.411595]\n",
      "epoch:29 step:27937 [D loss: 0.224331, acc.: 58.59%] [G loss: 0.424006]\n",
      "epoch:29 step:27938 [D loss: 0.255291, acc.: 50.00%] [G loss: 0.433980]\n",
      "epoch:29 step:27939 [D loss: 0.236340, acc.: 54.69%] [G loss: 0.443152]\n",
      "epoch:29 step:27940 [D loss: 0.200686, acc.: 67.19%] [G loss: 0.462162]\n",
      "epoch:29 step:27941 [D loss: 0.243247, acc.: 60.94%] [G loss: 0.460221]\n",
      "epoch:29 step:27942 [D loss: 0.201599, acc.: 69.53%] [G loss: 0.455832]\n",
      "epoch:29 step:27943 [D loss: 0.210358, acc.: 66.41%] [G loss: 0.437643]\n",
      "epoch:29 step:27944 [D loss: 0.205450, acc.: 67.97%] [G loss: 0.433986]\n",
      "epoch:29 step:27945 [D loss: 0.225829, acc.: 60.94%] [G loss: 0.425545]\n",
      "epoch:29 step:27946 [D loss: 0.245738, acc.: 60.94%] [G loss: 0.428394]\n",
      "epoch:29 step:27947 [D loss: 0.220596, acc.: 60.94%] [G loss: 0.457219]\n",
      "epoch:29 step:27948 [D loss: 0.240822, acc.: 60.16%] [G loss: 0.456428]\n",
      "epoch:29 step:27949 [D loss: 0.223702, acc.: 66.41%] [G loss: 0.409771]\n",
      "epoch:29 step:27950 [D loss: 0.222033, acc.: 66.41%] [G loss: 0.444286]\n",
      "epoch:29 step:27951 [D loss: 0.224809, acc.: 61.72%] [G loss: 0.407075]\n",
      "epoch:29 step:27952 [D loss: 0.230790, acc.: 60.94%] [G loss: 0.419942]\n",
      "epoch:29 step:27953 [D loss: 0.244860, acc.: 57.81%] [G loss: 0.382993]\n",
      "epoch:29 step:27954 [D loss: 0.219167, acc.: 61.72%] [G loss: 0.423554]\n",
      "epoch:29 step:27955 [D loss: 0.193175, acc.: 71.09%] [G loss: 0.470205]\n",
      "epoch:29 step:27956 [D loss: 0.244429, acc.: 56.25%] [G loss: 0.471684]\n",
      "epoch:29 step:27957 [D loss: 0.244009, acc.: 63.28%] [G loss: 0.407163]\n",
      "epoch:29 step:27958 [D loss: 0.196351, acc.: 67.97%] [G loss: 0.446469]\n",
      "epoch:29 step:27959 [D loss: 0.206258, acc.: 67.19%] [G loss: 0.434831]\n",
      "epoch:29 step:27960 [D loss: 0.251622, acc.: 53.12%] [G loss: 0.413560]\n",
      "epoch:29 step:27961 [D loss: 0.263749, acc.: 54.69%] [G loss: 0.398277]\n",
      "epoch:29 step:27962 [D loss: 0.210609, acc.: 66.41%] [G loss: 0.457005]\n",
      "epoch:29 step:27963 [D loss: 0.228654, acc.: 60.94%] [G loss: 0.415719]\n",
      "epoch:29 step:27964 [D loss: 0.260943, acc.: 50.00%] [G loss: 0.411167]\n",
      "epoch:29 step:27965 [D loss: 0.194948, acc.: 68.75%] [G loss: 0.428316]\n",
      "epoch:29 step:27966 [D loss: 0.224690, acc.: 60.94%] [G loss: 0.435668]\n",
      "epoch:29 step:27967 [D loss: 0.256789, acc.: 47.66%] [G loss: 0.469086]\n",
      "epoch:29 step:27968 [D loss: 0.235025, acc.: 63.28%] [G loss: 0.484535]\n",
      "epoch:29 step:27969 [D loss: 0.210214, acc.: 67.19%] [G loss: 0.429042]\n",
      "epoch:29 step:27970 [D loss: 0.241848, acc.: 53.12%] [G loss: 0.392212]\n",
      "epoch:29 step:27971 [D loss: 0.235772, acc.: 61.72%] [G loss: 0.410425]\n",
      "epoch:29 step:27972 [D loss: 0.218215, acc.: 66.41%] [G loss: 0.435663]\n",
      "epoch:29 step:27973 [D loss: 0.242363, acc.: 57.81%] [G loss: 0.429090]\n",
      "epoch:29 step:27974 [D loss: 0.213194, acc.: 68.75%] [G loss: 0.432411]\n",
      "epoch:29 step:27975 [D loss: 0.206017, acc.: 72.66%] [G loss: 0.451638]\n",
      "epoch:29 step:27976 [D loss: 0.217941, acc.: 66.41%] [G loss: 0.435379]\n",
      "epoch:29 step:27977 [D loss: 0.219014, acc.: 66.41%] [G loss: 0.431818]\n",
      "epoch:29 step:27978 [D loss: 0.206105, acc.: 67.97%] [G loss: 0.447549]\n",
      "epoch:29 step:27979 [D loss: 0.215660, acc.: 64.84%] [G loss: 0.409093]\n",
      "epoch:29 step:27980 [D loss: 0.220835, acc.: 63.28%] [G loss: 0.396593]\n",
      "epoch:29 step:27981 [D loss: 0.241113, acc.: 54.69%] [G loss: 0.398744]\n",
      "epoch:29 step:27982 [D loss: 0.211118, acc.: 68.75%] [G loss: 0.427761]\n",
      "epoch:29 step:27983 [D loss: 0.234509, acc.: 60.16%] [G loss: 0.434141]\n",
      "epoch:29 step:27984 [D loss: 0.238802, acc.: 62.50%] [G loss: 0.406874]\n",
      "epoch:29 step:27985 [D loss: 0.243274, acc.: 50.78%] [G loss: 0.415410]\n",
      "epoch:29 step:27986 [D loss: 0.217181, acc.: 65.62%] [G loss: 0.420644]\n",
      "epoch:29 step:27987 [D loss: 0.238444, acc.: 57.81%] [G loss: 0.396763]\n",
      "epoch:29 step:27988 [D loss: 0.212348, acc.: 66.41%] [G loss: 0.440808]\n",
      "epoch:29 step:27989 [D loss: 0.236365, acc.: 57.03%] [G loss: 0.464424]\n",
      "epoch:29 step:27990 [D loss: 0.248827, acc.: 57.03%] [G loss: 0.454886]\n",
      "epoch:29 step:27991 [D loss: 0.246039, acc.: 61.72%] [G loss: 0.422276]\n",
      "epoch:29 step:27992 [D loss: 0.215151, acc.: 63.28%] [G loss: 0.440034]\n",
      "epoch:29 step:27993 [D loss: 0.261264, acc.: 51.56%] [G loss: 0.417087]\n",
      "epoch:29 step:27994 [D loss: 0.214888, acc.: 60.16%] [G loss: 0.389854]\n",
      "epoch:29 step:27995 [D loss: 0.215235, acc.: 60.94%] [G loss: 0.406560]\n",
      "epoch:29 step:27996 [D loss: 0.213481, acc.: 67.19%] [G loss: 0.415921]\n",
      "epoch:29 step:27997 [D loss: 0.204546, acc.: 66.41%] [G loss: 0.431439]\n",
      "epoch:29 step:27998 [D loss: 0.213089, acc.: 67.97%] [G loss: 0.439580]\n",
      "epoch:29 step:27999 [D loss: 0.216070, acc.: 66.41%] [G loss: 0.432717]\n",
      "epoch:29 step:28000 [D loss: 0.240477, acc.: 58.59%] [G loss: 0.408128]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class LSGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        # (!!!) Optimize w.r.t. MSE loss instead of crossentropy\n",
    "        self.combined.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        # (!!!) No softmax\n",
    "        model.add(Dense(1))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, global_step,d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch,global_step)\n",
    "\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_lsgan'):\n",
    "            os.mkdir('images_lsgan')\n",
    "        fig.savefig(\"images_lsgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = LSGAN()\n",
    "    gan.train(epochs=30, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
