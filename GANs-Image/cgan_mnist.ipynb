{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 2,175,249\n",
      "Trainable params: 2,174,353\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 25088)             2533888   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,086,785\n",
      "Trainable params: 4,084,993\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 1.159811, acc.: 33.59%] [G loss: 0.593289]\n",
      "epoch:0 step:2 [D loss: 0.586770, acc.: 59.38%] [G loss: 1.058307]\n",
      "epoch:0 step:3 [D loss: 0.392995, acc.: 77.34%] [G loss: 1.868736]\n",
      "epoch:0 step:4 [D loss: 0.269268, acc.: 86.72%] [G loss: 2.396905]\n",
      "epoch:0 step:5 [D loss: 0.285235, acc.: 87.50%] [G loss: 2.770159]\n",
      "epoch:0 step:6 [D loss: 0.224948, acc.: 96.09%] [G loss: 2.796331]\n",
      "epoch:0 step:7 [D loss: 0.209202, acc.: 94.53%] [G loss: 3.706776]\n",
      "epoch:0 step:8 [D loss: 0.344180, acc.: 85.16%] [G loss: 3.701868]\n",
      "epoch:0 step:9 [D loss: 0.650198, acc.: 69.53%] [G loss: 3.814477]\n",
      "epoch:0 step:10 [D loss: 0.801561, acc.: 66.41%] [G loss: 3.672712]\n",
      "epoch:0 step:11 [D loss: 1.561280, acc.: 39.06%] [G loss: 3.504217]\n",
      "epoch:0 step:12 [D loss: 1.592679, acc.: 55.47%] [G loss: 4.143368]\n",
      "epoch:0 step:13 [D loss: 1.051648, acc.: 54.69%] [G loss: 3.840184]\n",
      "epoch:0 step:14 [D loss: 0.895352, acc.: 66.41%] [G loss: 3.824173]\n",
      "epoch:0 step:15 [D loss: 0.657380, acc.: 64.06%] [G loss: 6.277315]\n",
      "epoch:0 step:16 [D loss: 1.059585, acc.: 64.06%] [G loss: 4.474682]\n",
      "epoch:0 step:17 [D loss: 1.431785, acc.: 44.53%] [G loss: 3.062440]\n",
      "epoch:0 step:18 [D loss: 0.906846, acc.: 59.38%] [G loss: 4.286150]\n",
      "epoch:0 step:19 [D loss: 0.385820, acc.: 88.28%] [G loss: 4.568779]\n",
      "epoch:0 step:20 [D loss: 0.610358, acc.: 75.00%] [G loss: 3.462589]\n",
      "epoch:0 step:21 [D loss: 0.385244, acc.: 84.38%] [G loss: 3.066338]\n",
      "epoch:0 step:22 [D loss: 0.582265, acc.: 69.53%] [G loss: 3.419858]\n",
      "epoch:0 step:23 [D loss: 0.474136, acc.: 73.44%] [G loss: 3.860139]\n",
      "epoch:0 step:24 [D loss: 0.502281, acc.: 72.66%] [G loss: 3.599649]\n",
      "epoch:0 step:25 [D loss: 0.465463, acc.: 81.25%] [G loss: 4.366930]\n",
      "epoch:0 step:26 [D loss: 0.415930, acc.: 84.38%] [G loss: 4.540750]\n",
      "epoch:0 step:27 [D loss: 0.314655, acc.: 82.03%] [G loss: 4.594618]\n",
      "epoch:0 step:28 [D loss: 0.448032, acc.: 85.94%] [G loss: 4.085593]\n",
      "epoch:0 step:29 [D loss: 0.501216, acc.: 74.22%] [G loss: 4.422749]\n",
      "epoch:0 step:30 [D loss: 0.550994, acc.: 78.12%] [G loss: 5.497306]\n",
      "epoch:0 step:31 [D loss: 0.440841, acc.: 82.81%] [G loss: 6.288347]\n",
      "epoch:0 step:32 [D loss: 0.443696, acc.: 82.03%] [G loss: 5.326580]\n",
      "epoch:0 step:33 [D loss: 0.525804, acc.: 79.69%] [G loss: 4.340436]\n",
      "epoch:0 step:34 [D loss: 0.270501, acc.: 89.06%] [G loss: 4.731936]\n",
      "epoch:0 step:35 [D loss: 0.226014, acc.: 92.97%] [G loss: 4.643478]\n",
      "epoch:0 step:36 [D loss: 0.105416, acc.: 96.88%] [G loss: 4.608118]\n",
      "epoch:0 step:37 [D loss: 0.221324, acc.: 90.62%] [G loss: 4.426492]\n",
      "epoch:0 step:38 [D loss: 0.277979, acc.: 84.38%] [G loss: 4.676209]\n",
      "epoch:0 step:39 [D loss: 0.172588, acc.: 93.75%] [G loss: 5.284815]\n",
      "epoch:0 step:40 [D loss: 0.128376, acc.: 92.19%] [G loss: 4.651168]\n",
      "epoch:0 step:41 [D loss: 0.202872, acc.: 92.97%] [G loss: 4.439134]\n",
      "epoch:0 step:42 [D loss: 0.678550, acc.: 74.22%] [G loss: 5.404562]\n",
      "epoch:0 step:43 [D loss: 0.501349, acc.: 83.59%] [G loss: 4.464317]\n",
      "epoch:0 step:44 [D loss: 0.747388, acc.: 71.88%] [G loss: 5.671239]\n",
      "epoch:0 step:45 [D loss: 0.538999, acc.: 73.44%] [G loss: 6.865421]\n",
      "epoch:0 step:46 [D loss: 0.610553, acc.: 77.34%] [G loss: 6.522445]\n",
      "epoch:0 step:47 [D loss: 0.604943, acc.: 80.47%] [G loss: 5.691971]\n",
      "epoch:0 step:48 [D loss: 0.310725, acc.: 89.84%] [G loss: 4.495999]\n",
      "epoch:0 step:49 [D loss: 0.191860, acc.: 90.62%] [G loss: 5.245623]\n",
      "epoch:0 step:50 [D loss: 0.102713, acc.: 96.09%] [G loss: 5.997173]\n",
      "epoch:0 step:51 [D loss: 0.247339, acc.: 88.28%] [G loss: 5.108463]\n",
      "epoch:0 step:52 [D loss: 0.290708, acc.: 89.84%] [G loss: 5.657361]\n",
      "epoch:0 step:53 [D loss: 0.152633, acc.: 95.31%] [G loss: 5.371180]\n",
      "epoch:0 step:54 [D loss: 0.110581, acc.: 96.88%] [G loss: 4.525579]\n",
      "epoch:0 step:55 [D loss: 0.402116, acc.: 85.16%] [G loss: 6.237783]\n",
      "epoch:0 step:56 [D loss: 0.440673, acc.: 88.28%] [G loss: 4.087069]\n",
      "epoch:0 step:57 [D loss: 0.542616, acc.: 77.34%] [G loss: 5.376681]\n",
      "epoch:0 step:58 [D loss: 0.382925, acc.: 84.38%] [G loss: 5.258622]\n",
      "epoch:0 step:59 [D loss: 0.253545, acc.: 89.84%] [G loss: 4.346414]\n",
      "epoch:0 step:60 [D loss: 0.154096, acc.: 95.31%] [G loss: 5.646962]\n",
      "epoch:0 step:61 [D loss: 0.047060, acc.: 99.22%] [G loss: 4.234006]\n",
      "epoch:0 step:62 [D loss: 0.207673, acc.: 89.84%] [G loss: 5.548549]\n",
      "epoch:0 step:63 [D loss: 0.305681, acc.: 91.41%] [G loss: 4.988459]\n",
      "epoch:0 step:64 [D loss: 0.198856, acc.: 92.19%] [G loss: 5.095020]\n",
      "epoch:0 step:65 [D loss: 0.151787, acc.: 96.09%] [G loss: 5.197321]\n",
      "epoch:0 step:66 [D loss: 0.099267, acc.: 96.88%] [G loss: 4.997172]\n",
      "epoch:0 step:67 [D loss: 0.048183, acc.: 98.44%] [G loss: 4.245687]\n",
      "epoch:0 step:68 [D loss: 0.099669, acc.: 96.88%] [G loss: 4.229003]\n",
      "epoch:0 step:69 [D loss: 0.049366, acc.: 100.00%] [G loss: 4.404212]\n",
      "epoch:0 step:70 [D loss: 0.150358, acc.: 95.31%] [G loss: 3.747417]\n",
      "epoch:0 step:71 [D loss: 0.218649, acc.: 85.16%] [G loss: 5.367361]\n",
      "epoch:0 step:72 [D loss: 0.187681, acc.: 92.97%] [G loss: 4.719509]\n",
      "epoch:0 step:73 [D loss: 0.242304, acc.: 90.62%] [G loss: 4.490070]\n",
      "epoch:0 step:74 [D loss: 0.175258, acc.: 90.62%] [G loss: 5.134191]\n",
      "epoch:0 step:75 [D loss: 0.624256, acc.: 82.03%] [G loss: 7.137827]\n",
      "epoch:0 step:76 [D loss: 0.317265, acc.: 89.84%] [G loss: 5.278950]\n",
      "epoch:0 step:77 [D loss: 0.198810, acc.: 90.62%] [G loss: 5.420289]\n",
      "epoch:0 step:78 [D loss: 0.079001, acc.: 96.09%] [G loss: 6.115726]\n",
      "epoch:0 step:79 [D loss: 0.093106, acc.: 96.09%] [G loss: 5.156302]\n",
      "epoch:0 step:80 [D loss: 0.164972, acc.: 96.09%] [G loss: 4.762565]\n",
      "epoch:0 step:81 [D loss: 0.128861, acc.: 96.09%] [G loss: 5.654122]\n",
      "epoch:0 step:82 [D loss: 0.039529, acc.: 100.00%] [G loss: 4.251714]\n",
      "epoch:0 step:83 [D loss: 0.199374, acc.: 92.97%] [G loss: 5.125062]\n",
      "epoch:0 step:84 [D loss: 0.567677, acc.: 91.41%] [G loss: 3.893270]\n",
      "epoch:0 step:85 [D loss: 0.213724, acc.: 91.41%] [G loss: 4.997232]\n",
      "epoch:0 step:86 [D loss: 0.186122, acc.: 91.41%] [G loss: 7.626138]\n",
      "epoch:0 step:87 [D loss: 0.180341, acc.: 91.41%] [G loss: 7.104445]\n",
      "epoch:0 step:88 [D loss: 0.146819, acc.: 94.53%] [G loss: 5.261883]\n",
      "epoch:0 step:89 [D loss: 0.236540, acc.: 87.50%] [G loss: 6.928169]\n",
      "epoch:0 step:90 [D loss: 0.468549, acc.: 89.84%] [G loss: 6.914311]\n",
      "epoch:0 step:91 [D loss: 0.091750, acc.: 96.09%] [G loss: 5.541478]\n",
      "epoch:0 step:92 [D loss: 0.106471, acc.: 99.22%] [G loss: 4.665597]\n",
      "epoch:0 step:93 [D loss: 0.053493, acc.: 99.22%] [G loss: 4.346817]\n",
      "epoch:0 step:94 [D loss: 0.043567, acc.: 98.44%] [G loss: 4.908844]\n",
      "epoch:0 step:95 [D loss: 0.078170, acc.: 98.44%] [G loss: 5.571710]\n",
      "epoch:0 step:96 [D loss: 0.022622, acc.: 99.22%] [G loss: 5.042344]\n",
      "epoch:0 step:97 [D loss: 0.042671, acc.: 98.44%] [G loss: 4.712302]\n",
      "epoch:0 step:98 [D loss: 0.045001, acc.: 99.22%] [G loss: 4.784689]\n",
      "epoch:0 step:99 [D loss: 0.370074, acc.: 82.81%] [G loss: 5.796371]\n",
      "epoch:0 step:100 [D loss: 0.314114, acc.: 93.75%] [G loss: 7.582173]\n",
      "epoch:0 step:101 [D loss: 0.544784, acc.: 78.91%] [G loss: 7.763969]\n",
      "epoch:0 step:102 [D loss: 0.301742, acc.: 86.72%] [G loss: 5.148712]\n",
      "epoch:0 step:103 [D loss: 0.464029, acc.: 89.84%] [G loss: 5.198963]\n",
      "epoch:0 step:104 [D loss: 0.566936, acc.: 89.84%] [G loss: 3.839027]\n",
      "epoch:0 step:105 [D loss: 0.102148, acc.: 97.66%] [G loss: 6.404653]\n",
      "epoch:0 step:106 [D loss: 0.146222, acc.: 94.53%] [G loss: 6.060096]\n",
      "epoch:0 step:107 [D loss: 0.338932, acc.: 85.16%] [G loss: 8.301397]\n",
      "epoch:0 step:108 [D loss: 0.198437, acc.: 92.97%] [G loss: 6.627189]\n",
      "epoch:0 step:109 [D loss: 0.451136, acc.: 78.91%] [G loss: 7.174869]\n",
      "epoch:0 step:110 [D loss: 0.484594, acc.: 81.25%] [G loss: 7.087484]\n",
      "epoch:0 step:111 [D loss: 0.366051, acc.: 82.03%] [G loss: 6.707986]\n",
      "epoch:0 step:112 [D loss: 0.593262, acc.: 74.22%] [G loss: 7.615784]\n",
      "epoch:0 step:113 [D loss: 0.275678, acc.: 89.84%] [G loss: 6.032820]\n",
      "epoch:0 step:114 [D loss: 0.578057, acc.: 72.66%] [G loss: 5.922758]\n",
      "epoch:0 step:115 [D loss: 0.067266, acc.: 97.66%] [G loss: 7.126504]\n",
      "epoch:0 step:116 [D loss: 0.116134, acc.: 96.88%] [G loss: 6.736588]\n",
      "epoch:0 step:117 [D loss: 0.065203, acc.: 99.22%] [G loss: 5.439441]\n",
      "epoch:0 step:118 [D loss: 0.114367, acc.: 96.09%] [G loss: 5.302830]\n",
      "epoch:0 step:119 [D loss: 0.033042, acc.: 100.00%] [G loss: 6.002994]\n",
      "epoch:0 step:120 [D loss: 0.115262, acc.: 97.66%] [G loss: 4.575391]\n",
      "epoch:0 step:121 [D loss: 0.048782, acc.: 99.22%] [G loss: 5.919998]\n",
      "epoch:0 step:122 [D loss: 0.060060, acc.: 98.44%] [G loss: 4.477960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:123 [D loss: 0.093927, acc.: 96.09%] [G loss: 5.000240]\n",
      "epoch:0 step:124 [D loss: 0.067237, acc.: 97.66%] [G loss: 5.876561]\n",
      "epoch:0 step:125 [D loss: 0.070229, acc.: 95.31%] [G loss: 7.380005]\n",
      "epoch:0 step:126 [D loss: 0.110799, acc.: 94.53%] [G loss: 5.615582]\n",
      "epoch:0 step:127 [D loss: 0.062514, acc.: 98.44%] [G loss: 5.350888]\n",
      "epoch:0 step:128 [D loss: 0.043432, acc.: 99.22%] [G loss: 4.328786]\n",
      "epoch:0 step:129 [D loss: 0.252891, acc.: 92.19%] [G loss: 4.514294]\n",
      "epoch:0 step:130 [D loss: 0.579946, acc.: 82.03%] [G loss: 6.714489]\n",
      "epoch:0 step:131 [D loss: 0.135614, acc.: 95.31%] [G loss: 6.713301]\n",
      "epoch:0 step:132 [D loss: 0.126807, acc.: 94.53%] [G loss: 6.226234]\n",
      "epoch:0 step:133 [D loss: 0.068900, acc.: 97.66%] [G loss: 7.153761]\n",
      "epoch:0 step:134 [D loss: 0.014945, acc.: 100.00%] [G loss: 7.174509]\n",
      "epoch:0 step:135 [D loss: 0.113048, acc.: 96.09%] [G loss: 5.933729]\n",
      "epoch:0 step:136 [D loss: 0.176514, acc.: 89.84%] [G loss: 6.430767]\n",
      "epoch:0 step:137 [D loss: 0.506813, acc.: 87.50%] [G loss: 5.073813]\n",
      "epoch:0 step:138 [D loss: 0.107888, acc.: 97.66%] [G loss: 4.404458]\n",
      "epoch:0 step:139 [D loss: 1.396650, acc.: 69.53%] [G loss: 6.827739]\n",
      "epoch:0 step:140 [D loss: 0.029983, acc.: 99.22%] [G loss: 8.297394]\n",
      "epoch:0 step:141 [D loss: 0.404482, acc.: 81.25%] [G loss: 6.822898]\n",
      "epoch:0 step:142 [D loss: 0.270537, acc.: 86.72%] [G loss: 6.920483]\n",
      "epoch:0 step:143 [D loss: 0.235275, acc.: 88.28%] [G loss: 4.376768]\n",
      "epoch:0 step:144 [D loss: 0.170390, acc.: 92.97%] [G loss: 5.297438]\n",
      "epoch:0 step:145 [D loss: 0.400915, acc.: 89.06%] [G loss: 6.687342]\n",
      "epoch:0 step:146 [D loss: 0.112550, acc.: 96.09%] [G loss: 6.605405]\n",
      "epoch:0 step:147 [D loss: 0.157195, acc.: 96.09%] [G loss: 7.854040]\n",
      "epoch:0 step:148 [D loss: 0.111853, acc.: 97.66%] [G loss: 5.287346]\n",
      "epoch:0 step:149 [D loss: 0.214028, acc.: 89.06%] [G loss: 5.712816]\n",
      "epoch:0 step:150 [D loss: 0.779078, acc.: 80.47%] [G loss: 7.534038]\n",
      "epoch:0 step:151 [D loss: 0.109127, acc.: 95.31%] [G loss: 6.195736]\n",
      "epoch:0 step:152 [D loss: 0.287826, acc.: 91.41%] [G loss: 5.725838]\n",
      "epoch:0 step:153 [D loss: 0.140068, acc.: 94.53%] [G loss: 5.138863]\n",
      "epoch:0 step:154 [D loss: 0.095358, acc.: 97.66%] [G loss: 6.189397]\n",
      "epoch:0 step:155 [D loss: 0.125251, acc.: 95.31%] [G loss: 4.818581]\n",
      "epoch:0 step:156 [D loss: 0.256089, acc.: 87.50%] [G loss: 5.998065]\n",
      "epoch:0 step:157 [D loss: 0.121008, acc.: 95.31%] [G loss: 7.806262]\n",
      "epoch:0 step:158 [D loss: 0.175298, acc.: 93.75%] [G loss: 4.673118]\n",
      "epoch:0 step:159 [D loss: 0.170670, acc.: 92.19%] [G loss: 8.449142]\n",
      "epoch:0 step:160 [D loss: 0.259867, acc.: 91.41%] [G loss: 5.995527]\n",
      "epoch:0 step:161 [D loss: 0.278746, acc.: 88.28%] [G loss: 6.588786]\n",
      "epoch:0 step:162 [D loss: 0.105857, acc.: 96.09%] [G loss: 7.316866]\n",
      "epoch:0 step:163 [D loss: 0.104685, acc.: 94.53%] [G loss: 6.135863]\n",
      "epoch:0 step:164 [D loss: 0.239014, acc.: 91.41%] [G loss: 4.400712]\n",
      "epoch:0 step:165 [D loss: 0.122797, acc.: 96.88%] [G loss: 5.672721]\n",
      "epoch:0 step:166 [D loss: 0.332811, acc.: 82.03%] [G loss: 9.409264]\n",
      "epoch:0 step:167 [D loss: 2.299831, acc.: 42.19%] [G loss: 7.475577]\n",
      "epoch:0 step:168 [D loss: 0.810900, acc.: 77.34%] [G loss: 6.655224]\n",
      "epoch:0 step:169 [D loss: 0.437494, acc.: 82.81%] [G loss: 7.471807]\n",
      "epoch:0 step:170 [D loss: 0.420580, acc.: 80.47%] [G loss: 9.326798]\n",
      "epoch:0 step:171 [D loss: 0.326543, acc.: 89.06%] [G loss: 6.435097]\n",
      "epoch:0 step:172 [D loss: 0.192792, acc.: 92.19%] [G loss: 2.088158]\n",
      "epoch:0 step:173 [D loss: 0.125291, acc.: 96.09%] [G loss: 4.304314]\n",
      "epoch:0 step:174 [D loss: 0.365997, acc.: 88.28%] [G loss: 1.622841]\n",
      "epoch:0 step:175 [D loss: 0.511024, acc.: 78.12%] [G loss: 7.455861]\n",
      "epoch:0 step:176 [D loss: 0.716652, acc.: 67.97%] [G loss: 7.208390]\n",
      "epoch:0 step:177 [D loss: 0.447080, acc.: 89.06%] [G loss: 7.335110]\n",
      "epoch:0 step:178 [D loss: 1.121313, acc.: 53.12%] [G loss: 5.393751]\n",
      "epoch:0 step:179 [D loss: 0.377921, acc.: 89.06%] [G loss: 6.598851]\n",
      "epoch:0 step:180 [D loss: 0.156195, acc.: 95.31%] [G loss: 4.470077]\n",
      "epoch:0 step:181 [D loss: 0.313321, acc.: 89.06%] [G loss: 5.241789]\n",
      "epoch:0 step:182 [D loss: 0.506855, acc.: 73.44%] [G loss: 6.637428]\n",
      "epoch:0 step:183 [D loss: 0.875916, acc.: 71.88%] [G loss: 5.311409]\n",
      "epoch:0 step:184 [D loss: 0.450501, acc.: 86.72%] [G loss: 7.059593]\n",
      "epoch:0 step:185 [D loss: 0.534214, acc.: 79.69%] [G loss: 3.230784]\n",
      "epoch:0 step:186 [D loss: 0.815743, acc.: 64.84%] [G loss: 8.311494]\n",
      "epoch:0 step:187 [D loss: 0.730786, acc.: 75.00%] [G loss: 7.110155]\n",
      "epoch:0 step:188 [D loss: 0.549745, acc.: 75.00%] [G loss: 5.805160]\n",
      "epoch:0 step:189 [D loss: 0.530973, acc.: 78.12%] [G loss: 5.741488]\n",
      "epoch:0 step:190 [D loss: 0.526529, acc.: 77.34%] [G loss: 3.750149]\n",
      "epoch:0 step:191 [D loss: 0.562417, acc.: 78.91%] [G loss: 3.244887]\n",
      "epoch:0 step:192 [D loss: 0.602051, acc.: 67.19%] [G loss: 7.216868]\n",
      "epoch:0 step:193 [D loss: 1.264174, acc.: 50.00%] [G loss: 6.001693]\n",
      "epoch:0 step:194 [D loss: 1.649561, acc.: 35.94%] [G loss: 6.910089]\n",
      "epoch:0 step:195 [D loss: 1.016205, acc.: 85.16%] [G loss: 6.555089]\n",
      "epoch:0 step:196 [D loss: 1.800310, acc.: 54.69%] [G loss: 5.467531]\n",
      "epoch:0 step:197 [D loss: 1.181689, acc.: 60.16%] [G loss: 3.417623]\n",
      "epoch:0 step:198 [D loss: 0.283680, acc.: 89.06%] [G loss: 1.061249]\n",
      "epoch:0 step:199 [D loss: 0.312461, acc.: 87.50%] [G loss: 3.070426]\n",
      "epoch:0 step:200 [D loss: 0.845096, acc.: 60.16%] [G loss: 3.821527]\n",
      "epoch:0 step:201 [D loss: 1.132071, acc.: 53.91%] [G loss: 5.430153]\n",
      "epoch:0 step:202 [D loss: 0.824182, acc.: 63.28%] [G loss: 4.477967]\n",
      "epoch:0 step:203 [D loss: 1.191736, acc.: 50.00%] [G loss: 5.740277]\n",
      "epoch:0 step:204 [D loss: 0.754004, acc.: 65.62%] [G loss: 3.940397]\n",
      "epoch:0 step:205 [D loss: 0.704739, acc.: 67.97%] [G loss: 2.963012]\n",
      "epoch:0 step:206 [D loss: 0.353204, acc.: 85.94%] [G loss: 4.309312]\n",
      "epoch:0 step:207 [D loss: 0.369920, acc.: 83.59%] [G loss: 5.314521]\n",
      "epoch:0 step:208 [D loss: 0.606290, acc.: 75.78%] [G loss: 2.719927]\n",
      "epoch:0 step:209 [D loss: 0.980482, acc.: 58.59%] [G loss: 4.201977]\n",
      "epoch:0 step:210 [D loss: 0.253121, acc.: 89.84%] [G loss: 2.364522]\n",
      "epoch:0 step:211 [D loss: 0.617974, acc.: 66.41%] [G loss: 4.740163]\n",
      "epoch:0 step:212 [D loss: 0.443335, acc.: 77.34%] [G loss: 4.780684]\n",
      "epoch:0 step:213 [D loss: 0.700619, acc.: 66.41%] [G loss: 5.759399]\n",
      "epoch:0 step:214 [D loss: 1.495350, acc.: 39.84%] [G loss: 3.836373]\n",
      "epoch:0 step:215 [D loss: 1.030636, acc.: 59.38%] [G loss: 3.655546]\n",
      "epoch:0 step:216 [D loss: 0.503135, acc.: 86.72%] [G loss: 4.204449]\n",
      "epoch:0 step:217 [D loss: 1.433464, acc.: 50.78%] [G loss: 5.235683]\n",
      "epoch:0 step:218 [D loss: 1.182238, acc.: 49.22%] [G loss: 2.286303]\n",
      "epoch:0 step:219 [D loss: 1.103506, acc.: 53.91%] [G loss: 2.739783]\n",
      "epoch:0 step:220 [D loss: 1.255227, acc.: 39.84%] [G loss: 3.413691]\n",
      "epoch:0 step:221 [D loss: 0.398304, acc.: 78.12%] [G loss: 4.603466]\n",
      "epoch:0 step:222 [D loss: 0.628967, acc.: 70.31%] [G loss: 2.810202]\n",
      "epoch:0 step:223 [D loss: 1.134623, acc.: 54.69%] [G loss: 5.808118]\n",
      "epoch:0 step:224 [D loss: 1.030082, acc.: 64.84%] [G loss: 3.224086]\n",
      "epoch:0 step:225 [D loss: 0.940865, acc.: 52.34%] [G loss: 2.431098]\n",
      "epoch:0 step:226 [D loss: 0.379420, acc.: 81.25%] [G loss: 3.888911]\n",
      "epoch:0 step:227 [D loss: 0.493605, acc.: 81.25%] [G loss: 4.115804]\n",
      "epoch:0 step:228 [D loss: 0.631024, acc.: 63.28%] [G loss: 3.635879]\n",
      "epoch:0 step:229 [D loss: 1.426791, acc.: 39.06%] [G loss: 2.171279]\n",
      "epoch:0 step:230 [D loss: 1.152479, acc.: 43.75%] [G loss: 2.963213]\n",
      "epoch:0 step:231 [D loss: 0.445887, acc.: 80.47%] [G loss: 2.483525]\n",
      "epoch:0 step:232 [D loss: 0.557084, acc.: 70.31%] [G loss: 2.731503]\n",
      "epoch:0 step:233 [D loss: 0.646236, acc.: 70.31%] [G loss: 4.055419]\n",
      "epoch:0 step:234 [D loss: 0.540275, acc.: 75.78%] [G loss: 3.099380]\n",
      "epoch:0 step:235 [D loss: 0.582758, acc.: 75.00%] [G loss: 3.034436]\n",
      "epoch:0 step:236 [D loss: 0.289289, acc.: 89.84%] [G loss: 2.907902]\n",
      "epoch:0 step:237 [D loss: 0.987873, acc.: 51.56%] [G loss: 1.759197]\n",
      "epoch:0 step:238 [D loss: 0.645798, acc.: 73.44%] [G loss: 4.409844]\n",
      "epoch:0 step:239 [D loss: 0.522565, acc.: 79.69%] [G loss: 3.605545]\n",
      "epoch:0 step:240 [D loss: 0.538548, acc.: 66.41%] [G loss: 4.235526]\n",
      "epoch:0 step:241 [D loss: 0.745107, acc.: 64.84%] [G loss: 2.760902]\n",
      "epoch:0 step:242 [D loss: 0.544016, acc.: 68.75%] [G loss: 3.372790]\n",
      "epoch:0 step:243 [D loss: 0.892849, acc.: 56.25%] [G loss: 3.551186]\n",
      "epoch:0 step:244 [D loss: 0.576444, acc.: 72.66%] [G loss: 3.065125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:245 [D loss: 0.639407, acc.: 63.28%] [G loss: 3.497066]\n",
      "epoch:0 step:246 [D loss: 1.118679, acc.: 39.06%] [G loss: 3.550192]\n",
      "epoch:0 step:247 [D loss: 0.928718, acc.: 55.47%] [G loss: 3.057346]\n",
      "epoch:0 step:248 [D loss: 0.659346, acc.: 65.62%] [G loss: 3.319083]\n",
      "epoch:0 step:249 [D loss: 0.712339, acc.: 67.97%] [G loss: 2.955550]\n",
      "epoch:0 step:250 [D loss: 1.028798, acc.: 60.16%] [G loss: 3.599046]\n",
      "epoch:0 step:251 [D loss: 0.745116, acc.: 62.50%] [G loss: 3.549413]\n",
      "epoch:0 step:252 [D loss: 0.744610, acc.: 61.72%] [G loss: 3.398914]\n",
      "epoch:0 step:253 [D loss: 0.540528, acc.: 71.88%] [G loss: 3.112771]\n",
      "epoch:0 step:254 [D loss: 0.650885, acc.: 68.75%] [G loss: 2.495217]\n",
      "epoch:0 step:255 [D loss: 0.486460, acc.: 78.12%] [G loss: 2.130211]\n",
      "epoch:0 step:256 [D loss: 0.321233, acc.: 87.50%] [G loss: 3.754602]\n",
      "epoch:0 step:257 [D loss: 0.311927, acc.: 87.50%] [G loss: 1.860083]\n",
      "epoch:0 step:258 [D loss: 0.325664, acc.: 87.50%] [G loss: 3.331290]\n",
      "epoch:0 step:259 [D loss: 0.406608, acc.: 81.25%] [G loss: 1.893645]\n",
      "epoch:0 step:260 [D loss: 0.539372, acc.: 71.09%] [G loss: 3.181225]\n",
      "epoch:0 step:261 [D loss: 0.877648, acc.: 51.56%] [G loss: 3.421841]\n",
      "epoch:0 step:262 [D loss: 0.862883, acc.: 57.81%] [G loss: 3.550751]\n",
      "epoch:0 step:263 [D loss: 0.942963, acc.: 53.91%] [G loss: 2.570822]\n",
      "epoch:0 step:264 [D loss: 0.782011, acc.: 56.25%] [G loss: 3.617738]\n",
      "epoch:0 step:265 [D loss: 0.779211, acc.: 57.81%] [G loss: 3.099347]\n",
      "epoch:0 step:266 [D loss: 0.923351, acc.: 54.69%] [G loss: 3.561763]\n",
      "epoch:0 step:267 [D loss: 1.063262, acc.: 44.53%] [G loss: 3.350790]\n",
      "epoch:0 step:268 [D loss: 1.082854, acc.: 50.78%] [G loss: 2.728541]\n",
      "epoch:0 step:269 [D loss: 0.487853, acc.: 78.12%] [G loss: 3.453735]\n",
      "epoch:0 step:270 [D loss: 0.729954, acc.: 64.06%] [G loss: 3.838584]\n",
      "epoch:0 step:271 [D loss: 0.433092, acc.: 82.81%] [G loss: 3.615303]\n",
      "epoch:0 step:272 [D loss: 0.570459, acc.: 76.56%] [G loss: 2.427307]\n",
      "epoch:0 step:273 [D loss: 0.493568, acc.: 71.88%] [G loss: 3.618284]\n",
      "epoch:0 step:274 [D loss: 0.574746, acc.: 76.56%] [G loss: 2.688121]\n",
      "epoch:0 step:275 [D loss: 0.847904, acc.: 55.47%] [G loss: 2.986542]\n",
      "epoch:0 step:276 [D loss: 0.761515, acc.: 63.28%] [G loss: 3.968331]\n",
      "epoch:0 step:277 [D loss: 0.622871, acc.: 66.41%] [G loss: 4.017163]\n",
      "epoch:0 step:278 [D loss: 0.399194, acc.: 85.94%] [G loss: 2.969189]\n",
      "epoch:0 step:279 [D loss: 0.783157, acc.: 66.41%] [G loss: 3.900852]\n",
      "epoch:0 step:280 [D loss: 0.714193, acc.: 62.50%] [G loss: 3.172371]\n",
      "epoch:0 step:281 [D loss: 0.536136, acc.: 73.44%] [G loss: 2.878500]\n",
      "epoch:0 step:282 [D loss: 0.895269, acc.: 62.50%] [G loss: 2.778587]\n",
      "epoch:0 step:283 [D loss: 0.679685, acc.: 67.19%] [G loss: 3.964674]\n",
      "epoch:0 step:284 [D loss: 0.500346, acc.: 77.34%] [G loss: 2.553515]\n",
      "epoch:0 step:285 [D loss: 0.988447, acc.: 54.69%] [G loss: 2.788661]\n",
      "epoch:0 step:286 [D loss: 0.861366, acc.: 55.47%] [G loss: 3.083631]\n",
      "epoch:0 step:287 [D loss: 0.979534, acc.: 50.78%] [G loss: 3.330740]\n",
      "epoch:0 step:288 [D loss: 0.778223, acc.: 52.34%] [G loss: 3.420407]\n",
      "epoch:0 step:289 [D loss: 0.595477, acc.: 75.78%] [G loss: 2.938545]\n",
      "epoch:0 step:290 [D loss: 0.496171, acc.: 77.34%] [G loss: 3.108457]\n",
      "epoch:0 step:291 [D loss: 0.858274, acc.: 54.69%] [G loss: 2.917502]\n",
      "epoch:0 step:292 [D loss: 0.733054, acc.: 59.38%] [G loss: 3.133404]\n",
      "epoch:0 step:293 [D loss: 1.054047, acc.: 50.00%] [G loss: 2.531498]\n",
      "epoch:0 step:294 [D loss: 0.639241, acc.: 63.28%] [G loss: 2.794986]\n",
      "epoch:0 step:295 [D loss: 0.666643, acc.: 64.84%] [G loss: 3.069689]\n",
      "epoch:0 step:296 [D loss: 0.575254, acc.: 75.00%] [G loss: 2.272464]\n",
      "epoch:0 step:297 [D loss: 0.559499, acc.: 71.09%] [G loss: 2.136584]\n",
      "epoch:0 step:298 [D loss: 0.604623, acc.: 70.31%] [G loss: 1.669958]\n",
      "epoch:0 step:299 [D loss: 0.760157, acc.: 57.81%] [G loss: 2.286565]\n",
      "epoch:0 step:300 [D loss: 0.562376, acc.: 72.66%] [G loss: 3.209243]\n",
      "epoch:0 step:301 [D loss: 0.917202, acc.: 57.03%] [G loss: 2.274418]\n",
      "epoch:0 step:302 [D loss: 0.623876, acc.: 63.28%] [G loss: 3.264842]\n",
      "epoch:0 step:303 [D loss: 0.557084, acc.: 67.97%] [G loss: 3.312273]\n",
      "epoch:0 step:304 [D loss: 0.706018, acc.: 70.31%] [G loss: 2.158624]\n",
      "epoch:0 step:305 [D loss: 0.631109, acc.: 70.31%] [G loss: 1.523857]\n",
      "epoch:0 step:306 [D loss: 0.531303, acc.: 71.88%] [G loss: 2.615862]\n",
      "epoch:0 step:307 [D loss: 0.362123, acc.: 89.06%] [G loss: 2.471954]\n",
      "epoch:0 step:308 [D loss: 0.505950, acc.: 77.34%] [G loss: 2.206555]\n",
      "epoch:0 step:309 [D loss: 0.490996, acc.: 77.34%] [G loss: 2.500674]\n",
      "epoch:0 step:310 [D loss: 0.619034, acc.: 66.41%] [G loss: 2.557611]\n",
      "epoch:0 step:311 [D loss: 0.508041, acc.: 78.12%] [G loss: 2.327525]\n",
      "epoch:0 step:312 [D loss: 0.684186, acc.: 62.50%] [G loss: 2.847435]\n",
      "epoch:0 step:313 [D loss: 0.663637, acc.: 64.06%] [G loss: 2.748604]\n",
      "epoch:0 step:314 [D loss: 0.781248, acc.: 72.66%] [G loss: 3.312129]\n",
      "epoch:0 step:315 [D loss: 0.633362, acc.: 67.97%] [G loss: 3.016994]\n",
      "epoch:0 step:316 [D loss: 1.151972, acc.: 39.84%] [G loss: 1.830973]\n",
      "epoch:0 step:317 [D loss: 0.604220, acc.: 75.78%] [G loss: 3.090775]\n",
      "epoch:0 step:318 [D loss: 0.506054, acc.: 75.78%] [G loss: 2.791403]\n",
      "epoch:0 step:319 [D loss: 0.271796, acc.: 88.28%] [G loss: 2.876004]\n",
      "epoch:0 step:320 [D loss: 0.424047, acc.: 82.81%] [G loss: 2.402079]\n",
      "epoch:0 step:321 [D loss: 0.541388, acc.: 75.00%] [G loss: 2.982015]\n",
      "epoch:0 step:322 [D loss: 0.576523, acc.: 71.88%] [G loss: 2.710590]\n",
      "epoch:0 step:323 [D loss: 0.560136, acc.: 66.41%] [G loss: 2.804154]\n",
      "epoch:0 step:324 [D loss: 0.647130, acc.: 73.44%] [G loss: 2.720186]\n",
      "epoch:0 step:325 [D loss: 0.530183, acc.: 78.91%] [G loss: 3.171346]\n",
      "epoch:0 step:326 [D loss: 1.315040, acc.: 47.66%] [G loss: 3.356342]\n",
      "epoch:0 step:327 [D loss: 0.836101, acc.: 68.75%] [G loss: 2.797101]\n",
      "epoch:0 step:328 [D loss: 0.752829, acc.: 60.16%] [G loss: 2.364203]\n",
      "epoch:0 step:329 [D loss: 0.871917, acc.: 53.12%] [G loss: 2.612375]\n",
      "epoch:0 step:330 [D loss: 0.640636, acc.: 65.62%] [G loss: 2.703451]\n",
      "epoch:0 step:331 [D loss: 0.730539, acc.: 60.94%] [G loss: 2.712655]\n",
      "epoch:0 step:332 [D loss: 0.620657, acc.: 71.09%] [G loss: 2.549518]\n",
      "epoch:0 step:333 [D loss: 0.592986, acc.: 72.66%] [G loss: 2.206456]\n",
      "epoch:0 step:334 [D loss: 0.734224, acc.: 67.19%] [G loss: 2.107270]\n",
      "epoch:0 step:335 [D loss: 0.604803, acc.: 66.41%] [G loss: 2.375987]\n",
      "epoch:0 step:336 [D loss: 0.457026, acc.: 73.44%] [G loss: 2.646716]\n",
      "epoch:0 step:337 [D loss: 0.764092, acc.: 58.59%] [G loss: 2.596344]\n",
      "epoch:0 step:338 [D loss: 0.587520, acc.: 66.41%] [G loss: 2.111795]\n",
      "epoch:0 step:339 [D loss: 0.525030, acc.: 74.22%] [G loss: 2.316278]\n",
      "epoch:0 step:340 [D loss: 0.890204, acc.: 53.12%] [G loss: 3.359172]\n",
      "epoch:0 step:341 [D loss: 0.651357, acc.: 64.84%] [G loss: 2.144198]\n",
      "epoch:0 step:342 [D loss: 0.743233, acc.: 57.81%] [G loss: 2.319597]\n",
      "epoch:0 step:343 [D loss: 0.447077, acc.: 78.91%] [G loss: 2.895603]\n",
      "epoch:0 step:344 [D loss: 0.516110, acc.: 79.69%] [G loss: 2.317107]\n",
      "epoch:0 step:345 [D loss: 0.674972, acc.: 64.84%] [G loss: 1.914067]\n",
      "epoch:0 step:346 [D loss: 0.556550, acc.: 72.66%] [G loss: 2.752949]\n",
      "epoch:0 step:347 [D loss: 0.881335, acc.: 60.16%] [G loss: 2.905411]\n",
      "epoch:0 step:348 [D loss: 1.142298, acc.: 47.66%] [G loss: 2.389464]\n",
      "epoch:0 step:349 [D loss: 0.887563, acc.: 58.59%] [G loss: 2.202589]\n",
      "epoch:0 step:350 [D loss: 0.691337, acc.: 67.19%] [G loss: 3.061166]\n",
      "epoch:0 step:351 [D loss: 0.490984, acc.: 72.66%] [G loss: 2.615853]\n",
      "epoch:0 step:352 [D loss: 1.031624, acc.: 48.44%] [G loss: 2.296161]\n",
      "epoch:0 step:353 [D loss: 0.770326, acc.: 59.38%] [G loss: 2.673123]\n",
      "epoch:0 step:354 [D loss: 0.644787, acc.: 67.19%] [G loss: 2.967839]\n",
      "epoch:0 step:355 [D loss: 0.705770, acc.: 61.72%] [G loss: 2.102302]\n",
      "epoch:0 step:356 [D loss: 0.759302, acc.: 64.06%] [G loss: 2.303062]\n",
      "epoch:0 step:357 [D loss: 0.716739, acc.: 62.50%] [G loss: 2.381043]\n",
      "epoch:0 step:358 [D loss: 0.541344, acc.: 75.00%] [G loss: 2.557521]\n",
      "epoch:0 step:359 [D loss: 0.418506, acc.: 78.91%] [G loss: 3.125815]\n",
      "epoch:0 step:360 [D loss: 0.531445, acc.: 75.78%] [G loss: 2.443482]\n",
      "epoch:0 step:361 [D loss: 0.382834, acc.: 88.28%] [G loss: 2.674702]\n",
      "epoch:0 step:362 [D loss: 0.468608, acc.: 82.81%] [G loss: 2.030665]\n",
      "epoch:0 step:363 [D loss: 0.578652, acc.: 69.53%] [G loss: 2.286056]\n",
      "epoch:0 step:364 [D loss: 0.527886, acc.: 68.75%] [G loss: 2.971570]\n",
      "epoch:0 step:365 [D loss: 0.711744, acc.: 57.03%] [G loss: 2.299500]\n",
      "epoch:0 step:366 [D loss: 0.765310, acc.: 58.59%] [G loss: 2.534549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:367 [D loss: 0.458320, acc.: 78.91%] [G loss: 3.332679]\n",
      "epoch:0 step:368 [D loss: 0.477650, acc.: 79.69%] [G loss: 2.475199]\n",
      "epoch:0 step:369 [D loss: 0.782499, acc.: 59.38%] [G loss: 2.483149]\n",
      "epoch:0 step:370 [D loss: 0.673929, acc.: 65.62%] [G loss: 2.382617]\n",
      "epoch:0 step:371 [D loss: 0.520926, acc.: 75.00%] [G loss: 2.225406]\n",
      "epoch:0 step:372 [D loss: 0.612908, acc.: 66.41%] [G loss: 2.283340]\n",
      "epoch:0 step:373 [D loss: 1.006261, acc.: 53.12%] [G loss: 2.187717]\n",
      "epoch:0 step:374 [D loss: 0.368012, acc.: 85.16%] [G loss: 2.235145]\n",
      "epoch:0 step:375 [D loss: 0.498127, acc.: 77.34%] [G loss: 2.562593]\n",
      "epoch:0 step:376 [D loss: 0.747529, acc.: 56.25%] [G loss: 2.493787]\n",
      "epoch:0 step:377 [D loss: 0.496732, acc.: 75.00%] [G loss: 3.107811]\n",
      "epoch:0 step:378 [D loss: 0.647927, acc.: 67.97%] [G loss: 2.969564]\n",
      "epoch:0 step:379 [D loss: 0.516876, acc.: 74.22%] [G loss: 2.567861]\n",
      "epoch:0 step:380 [D loss: 0.775710, acc.: 52.34%] [G loss: 2.519601]\n",
      "epoch:0 step:381 [D loss: 0.513301, acc.: 73.44%] [G loss: 2.650559]\n",
      "epoch:0 step:382 [D loss: 0.848987, acc.: 61.72%] [G loss: 2.448761]\n",
      "epoch:0 step:383 [D loss: 0.794539, acc.: 51.56%] [G loss: 2.400904]\n",
      "epoch:0 step:384 [D loss: 0.524308, acc.: 75.00%] [G loss: 2.631646]\n",
      "epoch:0 step:385 [D loss: 0.523948, acc.: 74.22%] [G loss: 2.378214]\n",
      "epoch:0 step:386 [D loss: 0.651925, acc.: 66.41%] [G loss: 2.356371]\n",
      "epoch:0 step:387 [D loss: 0.518105, acc.: 70.31%] [G loss: 2.484915]\n",
      "epoch:0 step:388 [D loss: 0.578822, acc.: 70.31%] [G loss: 2.110576]\n",
      "epoch:0 step:389 [D loss: 0.588597, acc.: 66.41%] [G loss: 1.909472]\n",
      "epoch:0 step:390 [D loss: 0.404560, acc.: 85.94%] [G loss: 2.661174]\n",
      "epoch:0 step:391 [D loss: 0.592583, acc.: 74.22%] [G loss: 2.547372]\n",
      "epoch:0 step:392 [D loss: 0.471763, acc.: 73.44%] [G loss: 2.072064]\n",
      "epoch:0 step:393 [D loss: 0.750479, acc.: 55.47%] [G loss: 2.210312]\n",
      "epoch:0 step:394 [D loss: 0.711594, acc.: 60.94%] [G loss: 2.682945]\n",
      "epoch:0 step:395 [D loss: 0.614988, acc.: 67.97%] [G loss: 3.698756]\n",
      "epoch:0 step:396 [D loss: 0.770015, acc.: 59.38%] [G loss: 3.345891]\n",
      "epoch:0 step:397 [D loss: 0.852058, acc.: 66.41%] [G loss: 1.821838]\n",
      "epoch:0 step:398 [D loss: 0.804258, acc.: 56.25%] [G loss: 2.324090]\n",
      "epoch:0 step:399 [D loss: 0.837780, acc.: 57.03%] [G loss: 2.024203]\n",
      "epoch:0 step:400 [D loss: 0.761724, acc.: 60.16%] [G loss: 1.772226]\n",
      "epoch:0 step:401 [D loss: 0.666719, acc.: 64.06%] [G loss: 3.052515]\n",
      "epoch:0 step:402 [D loss: 0.475154, acc.: 75.00%] [G loss: 2.539164]\n",
      "epoch:0 step:403 [D loss: 0.375293, acc.: 85.94%] [G loss: 1.815423]\n",
      "epoch:0 step:404 [D loss: 0.512283, acc.: 72.66%] [G loss: 2.131526]\n",
      "epoch:0 step:405 [D loss: 0.516703, acc.: 71.88%] [G loss: 2.427402]\n",
      "epoch:0 step:406 [D loss: 0.395680, acc.: 81.25%] [G loss: 2.491017]\n",
      "epoch:0 step:407 [D loss: 0.626703, acc.: 60.16%] [G loss: 2.193280]\n",
      "epoch:0 step:408 [D loss: 0.668638, acc.: 65.62%] [G loss: 2.197836]\n",
      "epoch:0 step:409 [D loss: 0.681932, acc.: 64.06%] [G loss: 2.365815]\n",
      "epoch:0 step:410 [D loss: 0.721724, acc.: 60.94%] [G loss: 2.377331]\n",
      "epoch:0 step:411 [D loss: 0.722437, acc.: 59.38%] [G loss: 2.217513]\n",
      "epoch:0 step:412 [D loss: 0.762666, acc.: 60.16%] [G loss: 1.781864]\n",
      "epoch:0 step:413 [D loss: 0.923457, acc.: 53.12%] [G loss: 2.284759]\n",
      "epoch:0 step:414 [D loss: 0.773120, acc.: 61.72%] [G loss: 2.024493]\n",
      "epoch:0 step:415 [D loss: 0.591772, acc.: 67.97%] [G loss: 2.160680]\n",
      "epoch:0 step:416 [D loss: 0.584202, acc.: 71.09%] [G loss: 1.950926]\n",
      "epoch:0 step:417 [D loss: 0.892685, acc.: 47.66%] [G loss: 2.296089]\n",
      "epoch:0 step:418 [D loss: 0.724376, acc.: 61.72%] [G loss: 2.551080]\n",
      "epoch:0 step:419 [D loss: 0.591818, acc.: 71.09%] [G loss: 2.383965]\n",
      "epoch:0 step:420 [D loss: 0.777764, acc.: 64.06%] [G loss: 2.301353]\n",
      "epoch:0 step:421 [D loss: 1.104812, acc.: 44.53%] [G loss: 2.113956]\n",
      "epoch:0 step:422 [D loss: 0.441496, acc.: 76.56%] [G loss: 2.096907]\n",
      "epoch:0 step:423 [D loss: 0.550665, acc.: 65.62%] [G loss: 2.112319]\n",
      "epoch:0 step:424 [D loss: 0.822748, acc.: 54.69%] [G loss: 1.792333]\n",
      "epoch:0 step:425 [D loss: 0.874367, acc.: 52.34%] [G loss: 2.070715]\n",
      "epoch:0 step:426 [D loss: 0.733061, acc.: 59.38%] [G loss: 2.310367]\n",
      "epoch:0 step:427 [D loss: 0.711092, acc.: 57.03%] [G loss: 2.056506]\n",
      "epoch:0 step:428 [D loss: 0.584511, acc.: 64.06%] [G loss: 1.986297]\n",
      "epoch:0 step:429 [D loss: 0.751122, acc.: 59.38%] [G loss: 2.198704]\n",
      "epoch:0 step:430 [D loss: 0.510814, acc.: 73.44%] [G loss: 2.052666]\n",
      "epoch:0 step:431 [D loss: 0.644599, acc.: 60.16%] [G loss: 1.903894]\n",
      "epoch:0 step:432 [D loss: 0.462940, acc.: 75.78%] [G loss: 1.982129]\n",
      "epoch:0 step:433 [D loss: 0.421095, acc.: 82.03%] [G loss: 1.870566]\n",
      "epoch:0 step:434 [D loss: 0.484867, acc.: 76.56%] [G loss: 2.157753]\n",
      "epoch:0 step:435 [D loss: 0.668175, acc.: 63.28%] [G loss: 2.287403]\n",
      "epoch:0 step:436 [D loss: 0.742395, acc.: 61.72%] [G loss: 2.119601]\n",
      "epoch:0 step:437 [D loss: 0.800701, acc.: 54.69%] [G loss: 2.318446]\n",
      "epoch:0 step:438 [D loss: 0.393760, acc.: 81.25%] [G loss: 3.276412]\n",
      "epoch:0 step:439 [D loss: 0.443636, acc.: 77.34%] [G loss: 2.369602]\n",
      "epoch:0 step:440 [D loss: 0.354178, acc.: 89.06%] [G loss: 1.933595]\n",
      "epoch:0 step:441 [D loss: 0.517200, acc.: 76.56%] [G loss: 2.078787]\n",
      "epoch:0 step:442 [D loss: 0.620091, acc.: 71.09%] [G loss: 1.803795]\n",
      "epoch:0 step:443 [D loss: 0.757391, acc.: 71.09%] [G loss: 2.848595]\n",
      "epoch:0 step:444 [D loss: 0.715438, acc.: 66.41%] [G loss: 3.564080]\n",
      "epoch:0 step:445 [D loss: 0.717050, acc.: 69.53%] [G loss: 4.799304]\n",
      "epoch:0 step:446 [D loss: 0.537937, acc.: 68.75%] [G loss: 3.613559]\n",
      "epoch:0 step:447 [D loss: 0.774517, acc.: 68.75%] [G loss: 2.549586]\n",
      "epoch:0 step:448 [D loss: 0.887728, acc.: 49.22%] [G loss: 2.143299]\n",
      "epoch:0 step:449 [D loss: 0.782268, acc.: 57.81%] [G loss: 1.620185]\n",
      "epoch:0 step:450 [D loss: 0.791513, acc.: 64.84%] [G loss: 2.852844]\n",
      "epoch:0 step:451 [D loss: 0.742034, acc.: 57.81%] [G loss: 2.087612]\n",
      "epoch:0 step:452 [D loss: 1.108172, acc.: 50.78%] [G loss: 2.011517]\n",
      "epoch:0 step:453 [D loss: 0.608702, acc.: 68.75%] [G loss: 2.460237]\n",
      "epoch:0 step:454 [D loss: 0.691360, acc.: 67.19%] [G loss: 1.889454]\n",
      "epoch:0 step:455 [D loss: 0.791474, acc.: 53.12%] [G loss: 1.808833]\n",
      "epoch:0 step:456 [D loss: 0.707808, acc.: 59.38%] [G loss: 2.365259]\n",
      "epoch:0 step:457 [D loss: 0.673428, acc.: 66.41%] [G loss: 1.905108]\n",
      "epoch:0 step:458 [D loss: 0.710918, acc.: 58.59%] [G loss: 2.034082]\n",
      "epoch:0 step:459 [D loss: 0.587139, acc.: 75.78%] [G loss: 1.926435]\n",
      "epoch:0 step:460 [D loss: 0.658801, acc.: 60.94%] [G loss: 2.179419]\n",
      "epoch:0 step:461 [D loss: 0.569323, acc.: 67.97%] [G loss: 2.074528]\n",
      "epoch:0 step:462 [D loss: 0.501615, acc.: 78.12%] [G loss: 2.238163]\n",
      "epoch:0 step:463 [D loss: 0.613381, acc.: 66.41%] [G loss: 1.885918]\n",
      "epoch:0 step:464 [D loss: 0.625823, acc.: 67.97%] [G loss: 1.938816]\n",
      "epoch:0 step:465 [D loss: 0.715606, acc.: 59.38%] [G loss: 2.148154]\n",
      "epoch:0 step:466 [D loss: 0.534066, acc.: 65.62%] [G loss: 2.053199]\n",
      "epoch:0 step:467 [D loss: 0.521479, acc.: 79.69%] [G loss: 2.001815]\n",
      "epoch:0 step:468 [D loss: 0.417219, acc.: 82.81%] [G loss: 2.252815]\n",
      "epoch:0 step:469 [D loss: 0.510545, acc.: 75.00%] [G loss: 2.072023]\n",
      "epoch:0 step:470 [D loss: 0.543849, acc.: 71.88%] [G loss: 2.141427]\n",
      "epoch:0 step:471 [D loss: 0.527198, acc.: 71.88%] [G loss: 2.369484]\n",
      "epoch:0 step:472 [D loss: 0.662226, acc.: 66.41%] [G loss: 2.376656]\n",
      "epoch:0 step:473 [D loss: 0.970221, acc.: 46.88%] [G loss: 2.719148]\n",
      "epoch:0 step:474 [D loss: 0.846400, acc.: 50.00%] [G loss: 2.826926]\n",
      "epoch:0 step:475 [D loss: 0.366075, acc.: 81.25%] [G loss: 3.502294]\n",
      "epoch:0 step:476 [D loss: 0.409972, acc.: 84.38%] [G loss: 2.412991]\n",
      "epoch:0 step:477 [D loss: 0.467033, acc.: 77.34%] [G loss: 2.267682]\n",
      "epoch:0 step:478 [D loss: 0.827504, acc.: 54.69%] [G loss: 1.550276]\n",
      "epoch:0 step:479 [D loss: 0.674660, acc.: 60.16%] [G loss: 2.286110]\n",
      "epoch:0 step:480 [D loss: 0.660794, acc.: 61.72%] [G loss: 2.815482]\n",
      "epoch:0 step:481 [D loss: 0.661018, acc.: 75.78%] [G loss: 2.092628]\n",
      "epoch:0 step:482 [D loss: 1.205763, acc.: 30.47%] [G loss: 1.476792]\n",
      "epoch:0 step:483 [D loss: 1.118410, acc.: 33.59%] [G loss: 2.569420]\n",
      "epoch:0 step:484 [D loss: 0.655751, acc.: 62.50%] [G loss: 3.684227]\n",
      "epoch:0 step:485 [D loss: 0.694865, acc.: 63.28%] [G loss: 2.946475]\n",
      "epoch:0 step:486 [D loss: 0.615719, acc.: 65.62%] [G loss: 2.433434]\n",
      "epoch:0 step:487 [D loss: 0.691389, acc.: 60.94%] [G loss: 1.855084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:488 [D loss: 0.647641, acc.: 61.72%] [G loss: 2.145068]\n",
      "epoch:0 step:489 [D loss: 0.598035, acc.: 68.75%] [G loss: 1.699981]\n",
      "epoch:0 step:490 [D loss: 0.738887, acc.: 57.81%] [G loss: 1.694697]\n",
      "epoch:0 step:491 [D loss: 0.467077, acc.: 75.78%] [G loss: 1.968251]\n",
      "epoch:0 step:492 [D loss: 0.686393, acc.: 60.94%] [G loss: 1.422028]\n",
      "epoch:0 step:493 [D loss: 0.481788, acc.: 75.78%] [G loss: 1.676827]\n",
      "epoch:0 step:494 [D loss: 0.487598, acc.: 78.12%] [G loss: 2.338187]\n",
      "epoch:0 step:495 [D loss: 0.327884, acc.: 89.06%] [G loss: 2.155365]\n",
      "epoch:0 step:496 [D loss: 0.920439, acc.: 53.12%] [G loss: 1.608557]\n",
      "epoch:0 step:497 [D loss: 0.373674, acc.: 84.38%] [G loss: 2.239888]\n",
      "epoch:0 step:498 [D loss: 0.157875, acc.: 96.88%] [G loss: 2.499609]\n",
      "epoch:0 step:499 [D loss: 0.243835, acc.: 93.75%] [G loss: 2.633406]\n",
      "epoch:0 step:500 [D loss: 0.583103, acc.: 70.31%] [G loss: 1.728128]\n",
      "epoch:0 step:501 [D loss: 0.618740, acc.: 62.50%] [G loss: 2.129960]\n",
      "epoch:0 step:502 [D loss: 0.396732, acc.: 82.03%] [G loss: 2.292972]\n",
      "epoch:0 step:503 [D loss: 0.677966, acc.: 57.03%] [G loss: 3.280578]\n",
      "epoch:0 step:504 [D loss: 0.630410, acc.: 77.34%] [G loss: 2.583399]\n",
      "epoch:0 step:505 [D loss: 0.666522, acc.: 67.19%] [G loss: 1.565663]\n",
      "epoch:0 step:506 [D loss: 0.865335, acc.: 51.56%] [G loss: 1.965469]\n",
      "epoch:0 step:507 [D loss: 0.730611, acc.: 61.72%] [G loss: 2.598449]\n",
      "epoch:0 step:508 [D loss: 0.535213, acc.: 77.34%] [G loss: 2.133428]\n",
      "epoch:0 step:509 [D loss: 0.645790, acc.: 67.19%] [G loss: 2.119726]\n",
      "epoch:0 step:510 [D loss: 0.537151, acc.: 75.78%] [G loss: 1.967865]\n",
      "epoch:0 step:511 [D loss: 0.769004, acc.: 58.59%] [G loss: 1.852238]\n",
      "epoch:0 step:512 [D loss: 0.567815, acc.: 67.19%] [G loss: 1.995368]\n",
      "epoch:0 step:513 [D loss: 0.582725, acc.: 67.97%] [G loss: 1.488866]\n",
      "epoch:0 step:514 [D loss: 0.566921, acc.: 69.53%] [G loss: 3.155054]\n",
      "epoch:0 step:515 [D loss: 0.431560, acc.: 83.59%] [G loss: 2.863272]\n",
      "epoch:0 step:516 [D loss: 0.504821, acc.: 75.78%] [G loss: 2.607503]\n",
      "epoch:0 step:517 [D loss: 0.537828, acc.: 71.88%] [G loss: 2.109114]\n",
      "epoch:0 step:518 [D loss: 0.826907, acc.: 52.34%] [G loss: 2.282291]\n",
      "epoch:0 step:519 [D loss: 0.547646, acc.: 66.41%] [G loss: 2.537456]\n",
      "epoch:0 step:520 [D loss: 0.489228, acc.: 76.56%] [G loss: 2.031724]\n",
      "epoch:0 step:521 [D loss: 0.741842, acc.: 52.34%] [G loss: 2.384929]\n",
      "epoch:0 step:522 [D loss: 0.928288, acc.: 50.78%] [G loss: 1.957010]\n",
      "epoch:0 step:523 [D loss: 0.782830, acc.: 68.75%] [G loss: 3.630524]\n",
      "epoch:0 step:524 [D loss: 1.417579, acc.: 39.84%] [G loss: 3.069310]\n",
      "epoch:0 step:525 [D loss: 1.357896, acc.: 37.50%] [G loss: 3.963599]\n",
      "epoch:0 step:526 [D loss: 1.075077, acc.: 72.66%] [G loss: 2.285549]\n",
      "epoch:0 step:527 [D loss: 0.929823, acc.: 50.00%] [G loss: 1.592354]\n",
      "epoch:0 step:528 [D loss: 0.620950, acc.: 64.06%] [G loss: 2.169691]\n",
      "epoch:0 step:529 [D loss: 0.659437, acc.: 70.31%] [G loss: 2.284926]\n",
      "epoch:0 step:530 [D loss: 0.666479, acc.: 62.50%] [G loss: 2.356637]\n",
      "epoch:0 step:531 [D loss: 0.503099, acc.: 73.44%] [G loss: 1.922585]\n",
      "epoch:0 step:532 [D loss: 0.880442, acc.: 50.00%] [G loss: 2.466546]\n",
      "epoch:0 step:533 [D loss: 0.847153, acc.: 61.72%] [G loss: 2.383245]\n",
      "epoch:0 step:534 [D loss: 0.596090, acc.: 68.75%] [G loss: 1.514940]\n",
      "epoch:0 step:535 [D loss: 1.316244, acc.: 27.34%] [G loss: 1.602160]\n",
      "epoch:0 step:536 [D loss: 0.839551, acc.: 48.44%] [G loss: 1.768970]\n",
      "epoch:0 step:537 [D loss: 0.632346, acc.: 63.28%] [G loss: 1.651876]\n",
      "epoch:0 step:538 [D loss: 0.708869, acc.: 60.16%] [G loss: 2.421780]\n",
      "epoch:0 step:539 [D loss: 0.806402, acc.: 54.69%] [G loss: 3.049173]\n",
      "epoch:0 step:540 [D loss: 0.661649, acc.: 60.94%] [G loss: 1.988700]\n",
      "epoch:0 step:541 [D loss: 0.489035, acc.: 88.28%] [G loss: 2.053419]\n",
      "epoch:0 step:542 [D loss: 1.267505, acc.: 55.47%] [G loss: 2.918885]\n",
      "epoch:0 step:543 [D loss: 0.760522, acc.: 53.12%] [G loss: 2.063838]\n",
      "epoch:0 step:544 [D loss: 0.328053, acc.: 86.72%] [G loss: 3.356230]\n",
      "epoch:0 step:545 [D loss: 0.421132, acc.: 85.16%] [G loss: 3.522337]\n",
      "epoch:0 step:546 [D loss: 0.557810, acc.: 66.41%] [G loss: 2.332074]\n",
      "epoch:0 step:547 [D loss: 0.356126, acc.: 88.28%] [G loss: 2.019606]\n",
      "epoch:0 step:548 [D loss: 0.604413, acc.: 62.50%] [G loss: 1.657462]\n",
      "epoch:0 step:549 [D loss: 0.611068, acc.: 71.09%] [G loss: 1.762945]\n",
      "epoch:0 step:550 [D loss: 0.594505, acc.: 68.75%] [G loss: 1.740736]\n",
      "epoch:0 step:551 [D loss: 0.509830, acc.: 76.56%] [G loss: 1.629487]\n",
      "epoch:0 step:552 [D loss: 0.524325, acc.: 71.09%] [G loss: 2.147507]\n",
      "epoch:0 step:553 [D loss: 0.617118, acc.: 70.31%] [G loss: 2.169538]\n",
      "epoch:0 step:554 [D loss: 0.714324, acc.: 57.03%] [G loss: 2.118745]\n",
      "epoch:0 step:555 [D loss: 0.595269, acc.: 68.75%] [G loss: 2.183778]\n",
      "epoch:0 step:556 [D loss: 0.603949, acc.: 66.41%] [G loss: 2.132264]\n",
      "epoch:0 step:557 [D loss: 0.578554, acc.: 66.41%] [G loss: 2.514177]\n",
      "epoch:0 step:558 [D loss: 0.671837, acc.: 63.28%] [G loss: 2.411492]\n",
      "epoch:0 step:559 [D loss: 0.796014, acc.: 54.69%] [G loss: 2.282550]\n",
      "epoch:0 step:560 [D loss: 0.984821, acc.: 46.09%] [G loss: 2.196953]\n",
      "epoch:0 step:561 [D loss: 0.567670, acc.: 75.78%] [G loss: 1.985073]\n",
      "epoch:0 step:562 [D loss: 0.716511, acc.: 57.81%] [G loss: 1.232440]\n",
      "epoch:0 step:563 [D loss: 0.813329, acc.: 49.22%] [G loss: 1.153015]\n",
      "epoch:0 step:564 [D loss: 0.907327, acc.: 52.34%] [G loss: 2.520036]\n",
      "epoch:0 step:565 [D loss: 0.896734, acc.: 53.12%] [G loss: 2.199449]\n",
      "epoch:0 step:566 [D loss: 1.226633, acc.: 39.84%] [G loss: 1.910080]\n",
      "epoch:0 step:567 [D loss: 0.731160, acc.: 63.28%] [G loss: 1.844102]\n",
      "epoch:0 step:568 [D loss: 0.748513, acc.: 62.50%] [G loss: 1.414188]\n",
      "epoch:0 step:569 [D loss: 0.724206, acc.: 59.38%] [G loss: 1.629659]\n",
      "epoch:0 step:570 [D loss: 0.787754, acc.: 66.41%] [G loss: 1.664898]\n",
      "epoch:0 step:571 [D loss: 0.708521, acc.: 60.16%] [G loss: 1.583673]\n",
      "epoch:0 step:572 [D loss: 0.786956, acc.: 47.66%] [G loss: 1.506689]\n",
      "epoch:0 step:573 [D loss: 0.646731, acc.: 64.84%] [G loss: 1.457089]\n",
      "epoch:0 step:574 [D loss: 0.795859, acc.: 48.44%] [G loss: 1.869343]\n",
      "epoch:0 step:575 [D loss: 0.653738, acc.: 60.16%] [G loss: 1.909019]\n",
      "epoch:0 step:576 [D loss: 0.752198, acc.: 53.91%] [G loss: 1.212713]\n",
      "epoch:0 step:577 [D loss: 0.649255, acc.: 63.28%] [G loss: 1.530608]\n",
      "epoch:0 step:578 [D loss: 0.601545, acc.: 64.06%] [G loss: 1.589425]\n",
      "epoch:0 step:579 [D loss: 0.489136, acc.: 79.69%] [G loss: 1.779713]\n",
      "epoch:0 step:580 [D loss: 0.718700, acc.: 56.25%] [G loss: 1.686692]\n",
      "epoch:0 step:581 [D loss: 0.655373, acc.: 60.94%] [G loss: 1.699277]\n",
      "epoch:0 step:582 [D loss: 0.739646, acc.: 50.78%] [G loss: 2.059858]\n",
      "epoch:0 step:583 [D loss: 0.861005, acc.: 49.22%] [G loss: 1.847594]\n",
      "epoch:0 step:584 [D loss: 0.884237, acc.: 45.31%] [G loss: 1.512800]\n",
      "epoch:0 step:585 [D loss: 0.831583, acc.: 54.69%] [G loss: 1.460394]\n",
      "epoch:0 step:586 [D loss: 0.569538, acc.: 74.22%] [G loss: 1.679817]\n",
      "epoch:0 step:587 [D loss: 0.666654, acc.: 62.50%] [G loss: 1.751109]\n",
      "epoch:0 step:588 [D loss: 0.583877, acc.: 69.53%] [G loss: 1.699080]\n",
      "epoch:0 step:589 [D loss: 0.515602, acc.: 77.34%] [G loss: 1.748364]\n",
      "epoch:0 step:590 [D loss: 0.710693, acc.: 63.28%] [G loss: 1.681457]\n",
      "epoch:0 step:591 [D loss: 0.726112, acc.: 57.03%] [G loss: 1.465568]\n",
      "epoch:0 step:592 [D loss: 0.568909, acc.: 70.31%] [G loss: 1.806589]\n",
      "epoch:0 step:593 [D loss: 0.595480, acc.: 67.19%] [G loss: 1.871717]\n",
      "epoch:0 step:594 [D loss: 0.520137, acc.: 77.34%] [G loss: 1.991977]\n",
      "epoch:0 step:595 [D loss: 0.389305, acc.: 84.38%] [G loss: 2.066584]\n",
      "epoch:0 step:596 [D loss: 0.810426, acc.: 50.00%] [G loss: 1.668713]\n",
      "epoch:0 step:597 [D loss: 0.461237, acc.: 76.56%] [G loss: 1.648554]\n",
      "epoch:0 step:598 [D loss: 0.564916, acc.: 69.53%] [G loss: 1.824780]\n",
      "epoch:0 step:599 [D loss: 0.350932, acc.: 92.97%] [G loss: 1.951552]\n",
      "epoch:0 step:600 [D loss: 0.362364, acc.: 89.06%] [G loss: 1.964625]\n",
      "epoch:0 step:601 [D loss: 0.770571, acc.: 54.69%] [G loss: 1.811942]\n",
      "epoch:0 step:602 [D loss: 0.740957, acc.: 60.94%] [G loss: 2.019109]\n",
      "epoch:0 step:603 [D loss: 0.940597, acc.: 50.00%] [G loss: 2.942645]\n",
      "epoch:0 step:604 [D loss: 1.378516, acc.: 29.69%] [G loss: 2.100255]\n",
      "epoch:0 step:605 [D loss: 1.350887, acc.: 43.75%] [G loss: 2.560972]\n",
      "epoch:0 step:606 [D loss: 0.960069, acc.: 53.91%] [G loss: 2.680897]\n",
      "epoch:0 step:607 [D loss: 0.666420, acc.: 65.62%] [G loss: 1.597774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:608 [D loss: 0.654057, acc.: 63.28%] [G loss: 1.463543]\n",
      "epoch:0 step:609 [D loss: 0.590383, acc.: 68.75%] [G loss: 2.006083]\n",
      "epoch:0 step:610 [D loss: 0.641765, acc.: 65.62%] [G loss: 1.624184]\n",
      "epoch:0 step:611 [D loss: 0.620173, acc.: 73.44%] [G loss: 1.739572]\n",
      "epoch:0 step:612 [D loss: 0.762415, acc.: 63.28%] [G loss: 1.653154]\n",
      "epoch:0 step:613 [D loss: 0.571597, acc.: 78.12%] [G loss: 1.101056]\n",
      "epoch:0 step:614 [D loss: 0.741043, acc.: 63.28%] [G loss: 1.836556]\n",
      "epoch:0 step:615 [D loss: 0.820076, acc.: 46.88%] [G loss: 1.566068]\n",
      "epoch:0 step:616 [D loss: 0.736270, acc.: 60.16%] [G loss: 1.687648]\n",
      "epoch:0 step:617 [D loss: 0.743906, acc.: 55.47%] [G loss: 1.705980]\n",
      "epoch:0 step:618 [D loss: 0.609312, acc.: 64.84%] [G loss: 2.065443]\n",
      "epoch:0 step:619 [D loss: 0.566231, acc.: 77.34%] [G loss: 1.736099]\n",
      "epoch:0 step:620 [D loss: 0.792110, acc.: 48.44%] [G loss: 1.586162]\n",
      "epoch:0 step:621 [D loss: 0.791144, acc.: 56.25%] [G loss: 1.682549]\n",
      "epoch:0 step:622 [D loss: 0.722069, acc.: 59.38%] [G loss: 1.790465]\n",
      "epoch:0 step:623 [D loss: 0.676002, acc.: 63.28%] [G loss: 1.634883]\n",
      "epoch:0 step:624 [D loss: 0.677731, acc.: 61.72%] [G loss: 1.429217]\n",
      "epoch:0 step:625 [D loss: 0.810015, acc.: 59.38%] [G loss: 1.698207]\n",
      "epoch:0 step:626 [D loss: 0.649967, acc.: 63.28%] [G loss: 1.508859]\n",
      "epoch:0 step:627 [D loss: 0.649891, acc.: 67.19%] [G loss: 1.796723]\n",
      "epoch:0 step:628 [D loss: 0.627229, acc.: 64.06%] [G loss: 2.485028]\n",
      "epoch:0 step:629 [D loss: 0.620250, acc.: 62.50%] [G loss: 1.832971]\n",
      "epoch:0 step:630 [D loss: 0.480911, acc.: 79.69%] [G loss: 1.996084]\n",
      "epoch:0 step:631 [D loss: 0.478098, acc.: 78.12%] [G loss: 1.855661]\n",
      "epoch:0 step:632 [D loss: 0.504656, acc.: 76.56%] [G loss: 1.924736]\n",
      "epoch:0 step:633 [D loss: 0.434169, acc.: 79.69%] [G loss: 2.104506]\n",
      "epoch:0 step:634 [D loss: 0.414344, acc.: 79.69%] [G loss: 1.670629]\n",
      "epoch:0 step:635 [D loss: 0.405783, acc.: 84.38%] [G loss: 1.582870]\n",
      "epoch:0 step:636 [D loss: 0.667900, acc.: 61.72%] [G loss: 1.712128]\n",
      "epoch:0 step:637 [D loss: 0.432386, acc.: 82.03%] [G loss: 1.554088]\n",
      "epoch:0 step:638 [D loss: 0.476158, acc.: 74.22%] [G loss: 1.685955]\n",
      "epoch:0 step:639 [D loss: 0.745290, acc.: 57.81%] [G loss: 1.827058]\n",
      "epoch:0 step:640 [D loss: 0.669502, acc.: 61.72%] [G loss: 1.587642]\n",
      "epoch:0 step:641 [D loss: 1.193303, acc.: 32.81%] [G loss: 2.055077]\n",
      "epoch:0 step:642 [D loss: 0.664707, acc.: 64.84%] [G loss: 3.036637]\n",
      "epoch:0 step:643 [D loss: 0.827026, acc.: 64.84%] [G loss: 1.861700]\n",
      "epoch:0 step:644 [D loss: 0.988046, acc.: 50.78%] [G loss: 1.146352]\n",
      "epoch:0 step:645 [D loss: 0.677814, acc.: 60.16%] [G loss: 1.939409]\n",
      "epoch:0 step:646 [D loss: 0.682312, acc.: 60.94%] [G loss: 1.956154]\n",
      "epoch:0 step:647 [D loss: 0.626033, acc.: 68.75%] [G loss: 2.096637]\n",
      "epoch:0 step:648 [D loss: 0.581002, acc.: 74.22%] [G loss: 1.553261]\n",
      "epoch:0 step:649 [D loss: 0.485217, acc.: 74.22%] [G loss: 1.913310]\n",
      "epoch:0 step:650 [D loss: 0.456568, acc.: 80.47%] [G loss: 1.873629]\n",
      "epoch:0 step:651 [D loss: 0.439623, acc.: 83.59%] [G loss: 1.841963]\n",
      "epoch:0 step:652 [D loss: 0.604925, acc.: 64.84%] [G loss: 2.005512]\n",
      "epoch:0 step:653 [D loss: 0.323229, acc.: 90.62%] [G loss: 1.962960]\n",
      "epoch:0 step:654 [D loss: 0.328144, acc.: 92.19%] [G loss: 2.076650]\n",
      "epoch:0 step:655 [D loss: 0.517310, acc.: 77.34%] [G loss: 2.310829]\n",
      "epoch:0 step:656 [D loss: 0.765132, acc.: 59.38%] [G loss: 2.345497]\n",
      "epoch:0 step:657 [D loss: 0.402807, acc.: 82.03%] [G loss: 2.411304]\n",
      "epoch:0 step:658 [D loss: 0.689965, acc.: 67.19%] [G loss: 1.867108]\n",
      "epoch:0 step:659 [D loss: 0.464913, acc.: 76.56%] [G loss: 1.824612]\n",
      "epoch:0 step:660 [D loss: 0.254788, acc.: 93.75%] [G loss: 2.267017]\n",
      "epoch:0 step:661 [D loss: 0.542666, acc.: 74.22%] [G loss: 1.995325]\n",
      "epoch:0 step:662 [D loss: 0.458208, acc.: 79.69%] [G loss: 1.735713]\n",
      "epoch:0 step:663 [D loss: 0.627441, acc.: 68.75%] [G loss: 2.147390]\n",
      "epoch:0 step:664 [D loss: 1.027300, acc.: 40.62%] [G loss: 2.434607]\n",
      "epoch:0 step:665 [D loss: 1.016024, acc.: 40.62%] [G loss: 1.790873]\n",
      "epoch:0 step:666 [D loss: 0.666536, acc.: 63.28%] [G loss: 2.058604]\n",
      "epoch:0 step:667 [D loss: 0.619752, acc.: 60.94%] [G loss: 1.981648]\n",
      "epoch:0 step:668 [D loss: 0.603025, acc.: 64.84%] [G loss: 1.339100]\n",
      "epoch:0 step:669 [D loss: 0.548903, acc.: 70.31%] [G loss: 1.892628]\n",
      "epoch:0 step:670 [D loss: 0.462419, acc.: 78.12%] [G loss: 1.985887]\n",
      "epoch:0 step:671 [D loss: 0.436572, acc.: 79.69%] [G loss: 2.009993]\n",
      "epoch:0 step:672 [D loss: 0.512155, acc.: 77.34%] [G loss: 2.758289]\n",
      "epoch:0 step:673 [D loss: 0.543485, acc.: 69.53%] [G loss: 2.124810]\n",
      "epoch:0 step:674 [D loss: 0.596159, acc.: 64.84%] [G loss: 1.503349]\n",
      "epoch:0 step:675 [D loss: 0.573908, acc.: 71.88%] [G loss: 1.194986]\n",
      "epoch:0 step:676 [D loss: 0.587111, acc.: 71.88%] [G loss: 2.049808]\n",
      "epoch:0 step:677 [D loss: 0.462677, acc.: 75.78%] [G loss: 1.761102]\n",
      "epoch:0 step:678 [D loss: 0.536731, acc.: 71.88%] [G loss: 1.910650]\n",
      "epoch:0 step:679 [D loss: 0.623966, acc.: 61.72%] [G loss: 1.966907]\n",
      "epoch:0 step:680 [D loss: 0.619017, acc.: 67.19%] [G loss: 1.672787]\n",
      "epoch:0 step:681 [D loss: 0.758585, acc.: 53.91%] [G loss: 1.534592]\n",
      "epoch:0 step:682 [D loss: 0.733181, acc.: 63.28%] [G loss: 1.671637]\n",
      "epoch:0 step:683 [D loss: 0.514705, acc.: 78.12%] [G loss: 1.881629]\n",
      "epoch:0 step:684 [D loss: 0.552302, acc.: 69.53%] [G loss: 1.939377]\n",
      "epoch:0 step:685 [D loss: 0.447407, acc.: 77.34%] [G loss: 2.250719]\n",
      "epoch:0 step:686 [D loss: 0.818859, acc.: 49.22%] [G loss: 1.696422]\n",
      "epoch:0 step:687 [D loss: 0.674486, acc.: 55.47%] [G loss: 1.679719]\n",
      "epoch:0 step:688 [D loss: 0.750227, acc.: 58.59%] [G loss: 1.719950]\n",
      "epoch:0 step:689 [D loss: 1.193045, acc.: 34.38%] [G loss: 1.168532]\n",
      "epoch:0 step:690 [D loss: 0.870263, acc.: 42.97%] [G loss: 1.827033]\n",
      "epoch:0 step:691 [D loss: 0.740374, acc.: 56.25%] [G loss: 1.964748]\n",
      "epoch:0 step:692 [D loss: 0.864184, acc.: 42.19%] [G loss: 1.571841]\n",
      "epoch:0 step:693 [D loss: 0.758888, acc.: 58.59%] [G loss: 1.815201]\n",
      "epoch:0 step:694 [D loss: 0.686343, acc.: 60.94%] [G loss: 1.548370]\n",
      "epoch:0 step:695 [D loss: 0.759587, acc.: 66.41%] [G loss: 2.016789]\n",
      "epoch:0 step:696 [D loss: 0.612559, acc.: 60.16%] [G loss: 2.281343]\n",
      "epoch:0 step:697 [D loss: 0.726798, acc.: 57.03%] [G loss: 1.566221]\n",
      "epoch:0 step:698 [D loss: 0.640735, acc.: 60.94%] [G loss: 1.876515]\n",
      "epoch:0 step:699 [D loss: 0.540231, acc.: 75.00%] [G loss: 2.081225]\n",
      "epoch:0 step:700 [D loss: 0.644831, acc.: 64.84%] [G loss: 1.441965]\n",
      "epoch:0 step:701 [D loss: 0.623826, acc.: 67.19%] [G loss: 1.367922]\n",
      "epoch:0 step:702 [D loss: 0.619946, acc.: 63.28%] [G loss: 1.462002]\n",
      "epoch:0 step:703 [D loss: 0.638087, acc.: 61.72%] [G loss: 2.041751]\n",
      "epoch:0 step:704 [D loss: 0.478324, acc.: 80.47%] [G loss: 1.482748]\n",
      "epoch:0 step:705 [D loss: 0.382804, acc.: 87.50%] [G loss: 1.725334]\n",
      "epoch:0 step:706 [D loss: 0.732027, acc.: 54.69%] [G loss: 1.706729]\n",
      "epoch:0 step:707 [D loss: 0.921574, acc.: 52.34%] [G loss: 1.463277]\n",
      "epoch:0 step:708 [D loss: 0.640003, acc.: 58.59%] [G loss: 2.046007]\n",
      "epoch:0 step:709 [D loss: 0.647026, acc.: 60.94%] [G loss: 1.660630]\n",
      "epoch:0 step:710 [D loss: 0.607429, acc.: 67.97%] [G loss: 1.973908]\n",
      "epoch:0 step:711 [D loss: 0.637646, acc.: 67.19%] [G loss: 1.830912]\n",
      "epoch:0 step:712 [D loss: 0.687878, acc.: 62.50%] [G loss: 1.782125]\n",
      "epoch:0 step:713 [D loss: 0.647233, acc.: 60.16%] [G loss: 1.495471]\n",
      "epoch:0 step:714 [D loss: 0.761477, acc.: 57.81%] [G loss: 1.516062]\n",
      "epoch:0 step:715 [D loss: 0.640705, acc.: 63.28%] [G loss: 1.458528]\n",
      "epoch:0 step:716 [D loss: 0.700255, acc.: 61.72%] [G loss: 1.931032]\n",
      "epoch:0 step:717 [D loss: 0.611964, acc.: 63.28%] [G loss: 1.560008]\n",
      "epoch:0 step:718 [D loss: 0.531987, acc.: 73.44%] [G loss: 1.559070]\n",
      "epoch:0 step:719 [D loss: 0.507150, acc.: 78.12%] [G loss: 1.927363]\n",
      "epoch:0 step:720 [D loss: 0.768462, acc.: 47.66%] [G loss: 2.174947]\n",
      "epoch:0 step:721 [D loss: 0.758923, acc.: 59.38%] [G loss: 2.080346]\n",
      "epoch:0 step:722 [D loss: 0.560187, acc.: 68.75%] [G loss: 2.275470]\n",
      "epoch:0 step:723 [D loss: 0.577341, acc.: 69.53%] [G loss: 2.376718]\n",
      "epoch:0 step:724 [D loss: 0.624476, acc.: 68.75%] [G loss: 2.185376]\n",
      "epoch:0 step:725 [D loss: 0.537192, acc.: 72.66%] [G loss: 1.749271]\n",
      "epoch:0 step:726 [D loss: 0.526081, acc.: 71.88%] [G loss: 1.879519]\n",
      "epoch:0 step:727 [D loss: 0.292167, acc.: 92.97%] [G loss: 2.520002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:728 [D loss: 0.360201, acc.: 90.62%] [G loss: 1.809526]\n",
      "epoch:0 step:729 [D loss: 0.579552, acc.: 72.66%] [G loss: 1.111430]\n",
      "epoch:0 step:730 [D loss: 0.455233, acc.: 78.91%] [G loss: 1.506223]\n",
      "epoch:0 step:731 [D loss: 0.641412, acc.: 62.50%] [G loss: 1.768153]\n",
      "epoch:0 step:732 [D loss: 0.667721, acc.: 65.62%] [G loss: 1.186031]\n",
      "epoch:0 step:733 [D loss: 0.760910, acc.: 52.34%] [G loss: 1.579578]\n",
      "epoch:0 step:734 [D loss: 0.760949, acc.: 55.47%] [G loss: 2.078628]\n",
      "epoch:0 step:735 [D loss: 0.910650, acc.: 46.09%] [G loss: 1.476694]\n",
      "epoch:0 step:736 [D loss: 0.544683, acc.: 73.44%] [G loss: 1.633594]\n",
      "epoch:0 step:737 [D loss: 0.695896, acc.: 63.28%] [G loss: 1.774467]\n",
      "epoch:0 step:738 [D loss: 0.490307, acc.: 75.78%] [G loss: 1.597317]\n",
      "epoch:0 step:739 [D loss: 0.638569, acc.: 64.06%] [G loss: 1.578370]\n",
      "epoch:0 step:740 [D loss: 0.653882, acc.: 61.72%] [G loss: 1.189711]\n",
      "epoch:0 step:741 [D loss: 0.394805, acc.: 81.25%] [G loss: 1.463173]\n",
      "epoch:0 step:742 [D loss: 0.732599, acc.: 59.38%] [G loss: 1.195235]\n",
      "epoch:0 step:743 [D loss: 0.732183, acc.: 63.28%] [G loss: 1.697662]\n",
      "epoch:0 step:744 [D loss: 0.867435, acc.: 46.09%] [G loss: 1.701340]\n",
      "epoch:0 step:745 [D loss: 1.279075, acc.: 26.56%] [G loss: 1.414652]\n",
      "epoch:0 step:746 [D loss: 1.093786, acc.: 30.47%] [G loss: 1.629040]\n",
      "epoch:0 step:747 [D loss: 0.681708, acc.: 53.91%] [G loss: 1.726073]\n",
      "epoch:0 step:748 [D loss: 0.748059, acc.: 53.12%] [G loss: 1.326785]\n",
      "epoch:0 step:749 [D loss: 0.657793, acc.: 56.25%] [G loss: 1.630111]\n",
      "epoch:0 step:750 [D loss: 0.566481, acc.: 65.62%] [G loss: 1.900931]\n",
      "epoch:0 step:751 [D loss: 0.879346, acc.: 63.28%] [G loss: 1.793495]\n",
      "epoch:0 step:752 [D loss: 0.780207, acc.: 53.12%] [G loss: 1.314395]\n",
      "epoch:0 step:753 [D loss: 0.623752, acc.: 63.28%] [G loss: 1.233413]\n",
      "epoch:0 step:754 [D loss: 0.543194, acc.: 73.44%] [G loss: 1.437723]\n",
      "epoch:0 step:755 [D loss: 0.624794, acc.: 63.28%] [G loss: 1.488564]\n",
      "epoch:0 step:756 [D loss: 0.688311, acc.: 57.81%] [G loss: 1.639441]\n",
      "epoch:0 step:757 [D loss: 0.566393, acc.: 68.75%] [G loss: 1.492572]\n",
      "epoch:0 step:758 [D loss: 0.977419, acc.: 49.22%] [G loss: 1.148237]\n",
      "epoch:0 step:759 [D loss: 0.533959, acc.: 71.09%] [G loss: 1.321110]\n",
      "epoch:0 step:760 [D loss: 0.474832, acc.: 78.91%] [G loss: 1.475425]\n",
      "epoch:0 step:761 [D loss: 0.581322, acc.: 65.62%] [G loss: 1.397243]\n",
      "epoch:0 step:762 [D loss: 0.597670, acc.: 67.19%] [G loss: 1.337904]\n",
      "epoch:0 step:763 [D loss: 0.805982, acc.: 50.00%] [G loss: 1.264732]\n",
      "epoch:0 step:764 [D loss: 0.803407, acc.: 50.78%] [G loss: 1.336592]\n",
      "epoch:0 step:765 [D loss: 0.677946, acc.: 57.03%] [G loss: 1.736773]\n",
      "epoch:0 step:766 [D loss: 0.650945, acc.: 61.72%] [G loss: 1.697535]\n",
      "epoch:0 step:767 [D loss: 0.501226, acc.: 78.91%] [G loss: 1.575359]\n",
      "epoch:0 step:768 [D loss: 0.553816, acc.: 68.75%] [G loss: 1.465433]\n",
      "epoch:0 step:769 [D loss: 0.616177, acc.: 64.06%] [G loss: 1.806369]\n",
      "epoch:0 step:770 [D loss: 0.777309, acc.: 58.59%] [G loss: 1.372917]\n",
      "epoch:0 step:771 [D loss: 0.933009, acc.: 39.84%] [G loss: 1.469056]\n",
      "epoch:0 step:772 [D loss: 0.538389, acc.: 68.75%] [G loss: 1.547894]\n",
      "epoch:0 step:773 [D loss: 0.746748, acc.: 53.91%] [G loss: 1.534368]\n",
      "epoch:0 step:774 [D loss: 0.629503, acc.: 62.50%] [G loss: 1.479086]\n",
      "epoch:0 step:775 [D loss: 0.517887, acc.: 78.12%] [G loss: 1.867650]\n",
      "epoch:0 step:776 [D loss: 0.528842, acc.: 70.31%] [G loss: 1.853366]\n",
      "epoch:0 step:777 [D loss: 0.468935, acc.: 80.47%] [G loss: 1.742957]\n",
      "epoch:0 step:778 [D loss: 0.621489, acc.: 62.50%] [G loss: 1.536630]\n",
      "epoch:0 step:779 [D loss: 0.521436, acc.: 75.00%] [G loss: 1.436286]\n",
      "epoch:0 step:780 [D loss: 0.906238, acc.: 48.44%] [G loss: 1.593483]\n",
      "epoch:0 step:781 [D loss: 0.665963, acc.: 56.25%] [G loss: 1.906339]\n",
      "epoch:0 step:782 [D loss: 0.557912, acc.: 76.56%] [G loss: 1.004760]\n",
      "epoch:0 step:783 [D loss: 0.806257, acc.: 48.44%] [G loss: 1.283190]\n",
      "epoch:0 step:784 [D loss: 1.215095, acc.: 29.69%] [G loss: 1.216058]\n",
      "epoch:0 step:785 [D loss: 0.923062, acc.: 46.09%] [G loss: 1.495416]\n",
      "epoch:0 step:786 [D loss: 0.760120, acc.: 53.91%] [G loss: 1.185222]\n",
      "epoch:0 step:787 [D loss: 0.681919, acc.: 60.94%] [G loss: 1.158553]\n",
      "epoch:0 step:788 [D loss: 0.682188, acc.: 62.50%] [G loss: 1.087165]\n",
      "epoch:0 step:789 [D loss: 0.545928, acc.: 72.66%] [G loss: 1.153476]\n",
      "epoch:0 step:790 [D loss: 0.650862, acc.: 65.62%] [G loss: 1.048396]\n",
      "epoch:0 step:791 [D loss: 1.024959, acc.: 35.16%] [G loss: 0.883697]\n",
      "epoch:0 step:792 [D loss: 1.035507, acc.: 32.81%] [G loss: 1.650730]\n",
      "epoch:0 step:793 [D loss: 0.782153, acc.: 57.03%] [G loss: 1.292546]\n",
      "epoch:0 step:794 [D loss: 0.853540, acc.: 43.75%] [G loss: 1.357893]\n",
      "epoch:0 step:795 [D loss: 0.804769, acc.: 57.03%] [G loss: 1.296317]\n",
      "epoch:0 step:796 [D loss: 0.669438, acc.: 58.59%] [G loss: 1.382403]\n",
      "epoch:0 step:797 [D loss: 0.841510, acc.: 50.78%] [G loss: 1.057084]\n",
      "epoch:0 step:798 [D loss: 0.687145, acc.: 62.50%] [G loss: 1.236510]\n",
      "epoch:0 step:799 [D loss: 0.721705, acc.: 59.38%] [G loss: 1.042283]\n",
      "epoch:0 step:800 [D loss: 0.747857, acc.: 56.25%] [G loss: 1.229815]\n",
      "epoch:0 step:801 [D loss: 0.641729, acc.: 60.16%] [G loss: 1.202154]\n",
      "epoch:0 step:802 [D loss: 0.522617, acc.: 72.66%] [G loss: 1.129437]\n",
      "epoch:0 step:803 [D loss: 0.761860, acc.: 47.66%] [G loss: 0.811042]\n",
      "epoch:0 step:804 [D loss: 1.098518, acc.: 29.69%] [G loss: 1.077089]\n",
      "epoch:0 step:805 [D loss: 0.793480, acc.: 46.88%] [G loss: 0.997719]\n",
      "epoch:0 step:806 [D loss: 0.852533, acc.: 45.31%] [G loss: 1.073861]\n",
      "epoch:0 step:807 [D loss: 0.584864, acc.: 71.09%] [G loss: 1.378244]\n",
      "epoch:0 step:808 [D loss: 0.771930, acc.: 54.69%] [G loss: 1.316803]\n",
      "epoch:0 step:809 [D loss: 0.756381, acc.: 61.72%] [G loss: 1.128078]\n",
      "epoch:0 step:810 [D loss: 0.875237, acc.: 49.22%] [G loss: 1.200859]\n",
      "epoch:0 step:811 [D loss: 0.833272, acc.: 46.09%] [G loss: 1.095483]\n",
      "epoch:0 step:812 [D loss: 0.741105, acc.: 46.88%] [G loss: 1.111816]\n",
      "epoch:0 step:813 [D loss: 0.672920, acc.: 61.72%] [G loss: 1.106206]\n",
      "epoch:0 step:814 [D loss: 0.783190, acc.: 49.22%] [G loss: 1.206433]\n",
      "epoch:0 step:815 [D loss: 0.700756, acc.: 61.72%] [G loss: 1.159307]\n",
      "epoch:0 step:816 [D loss: 0.752439, acc.: 49.22%] [G loss: 1.156716]\n",
      "epoch:0 step:817 [D loss: 0.684356, acc.: 61.72%] [G loss: 1.221356]\n",
      "epoch:0 step:818 [D loss: 0.864524, acc.: 40.62%] [G loss: 1.058834]\n",
      "epoch:0 step:819 [D loss: 0.683467, acc.: 56.25%] [G loss: 1.011788]\n",
      "epoch:0 step:820 [D loss: 0.711506, acc.: 53.12%] [G loss: 1.212743]\n",
      "epoch:0 step:821 [D loss: 0.497603, acc.: 76.56%] [G loss: 1.234584]\n",
      "epoch:0 step:822 [D loss: 0.530520, acc.: 75.00%] [G loss: 1.315361]\n",
      "epoch:0 step:823 [D loss: 0.732042, acc.: 57.81%] [G loss: 1.256481]\n",
      "epoch:0 step:824 [D loss: 0.727768, acc.: 64.06%] [G loss: 1.118196]\n",
      "epoch:0 step:825 [D loss: 0.747496, acc.: 62.50%] [G loss: 0.998942]\n",
      "epoch:0 step:826 [D loss: 0.837291, acc.: 42.97%] [G loss: 0.848421]\n",
      "epoch:0 step:827 [D loss: 0.806713, acc.: 51.56%] [G loss: 0.960273]\n",
      "epoch:0 step:828 [D loss: 0.628892, acc.: 65.62%] [G loss: 1.007808]\n",
      "epoch:0 step:829 [D loss: 0.648365, acc.: 64.06%] [G loss: 1.176542]\n",
      "epoch:0 step:830 [D loss: 0.724601, acc.: 56.25%] [G loss: 1.272057]\n",
      "epoch:0 step:831 [D loss: 0.618448, acc.: 68.75%] [G loss: 1.465306]\n",
      "epoch:0 step:832 [D loss: 0.643523, acc.: 64.84%] [G loss: 1.096359]\n",
      "epoch:0 step:833 [D loss: 0.733166, acc.: 54.69%] [G loss: 1.266744]\n",
      "epoch:0 step:834 [D loss: 0.711913, acc.: 57.03%] [G loss: 1.234800]\n",
      "epoch:0 step:835 [D loss: 0.593101, acc.: 67.19%] [G loss: 1.010791]\n",
      "epoch:0 step:836 [D loss: 0.670964, acc.: 54.69%] [G loss: 1.053081]\n",
      "epoch:0 step:837 [D loss: 0.717135, acc.: 53.91%] [G loss: 1.107034]\n",
      "epoch:0 step:838 [D loss: 0.628397, acc.: 64.06%] [G loss: 1.121665]\n",
      "epoch:0 step:839 [D loss: 0.808286, acc.: 49.22%] [G loss: 1.022881]\n",
      "epoch:0 step:840 [D loss: 0.798298, acc.: 46.09%] [G loss: 1.029424]\n",
      "epoch:0 step:841 [D loss: 0.699810, acc.: 54.69%] [G loss: 0.940188]\n",
      "epoch:0 step:842 [D loss: 0.623540, acc.: 69.53%] [G loss: 1.193888]\n",
      "epoch:0 step:843 [D loss: 0.800551, acc.: 49.22%] [G loss: 1.045340]\n",
      "epoch:0 step:844 [D loss: 0.737632, acc.: 52.34%] [G loss: 1.168775]\n",
      "epoch:0 step:845 [D loss: 0.771111, acc.: 60.16%] [G loss: 1.136553]\n",
      "epoch:0 step:846 [D loss: 0.606049, acc.: 65.62%] [G loss: 1.080673]\n",
      "epoch:0 step:847 [D loss: 0.736031, acc.: 50.00%] [G loss: 1.019689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:848 [D loss: 0.826794, acc.: 45.31%] [G loss: 1.044151]\n",
      "epoch:0 step:849 [D loss: 0.784956, acc.: 53.91%] [G loss: 1.154779]\n",
      "epoch:0 step:850 [D loss: 0.996601, acc.: 30.47%] [G loss: 1.131415]\n",
      "epoch:0 step:851 [D loss: 0.764283, acc.: 54.69%] [G loss: 0.986563]\n",
      "epoch:0 step:852 [D loss: 0.733229, acc.: 53.91%] [G loss: 1.096460]\n",
      "epoch:0 step:853 [D loss: 0.637939, acc.: 57.03%] [G loss: 1.154354]\n",
      "epoch:0 step:854 [D loss: 0.755187, acc.: 55.47%] [G loss: 1.204392]\n",
      "epoch:0 step:855 [D loss: 0.726974, acc.: 57.81%] [G loss: 1.013527]\n",
      "epoch:0 step:856 [D loss: 0.736919, acc.: 52.34%] [G loss: 1.047877]\n",
      "epoch:0 step:857 [D loss: 0.709777, acc.: 57.81%] [G loss: 0.929563]\n",
      "epoch:0 step:858 [D loss: 0.831060, acc.: 45.31%] [G loss: 0.981935]\n",
      "epoch:0 step:859 [D loss: 0.794400, acc.: 46.09%] [G loss: 0.982554]\n",
      "epoch:0 step:860 [D loss: 0.610793, acc.: 69.53%] [G loss: 1.075948]\n",
      "epoch:0 step:861 [D loss: 0.799784, acc.: 48.44%] [G loss: 0.973050]\n",
      "epoch:0 step:862 [D loss: 0.794402, acc.: 40.62%] [G loss: 0.889053]\n",
      "epoch:0 step:863 [D loss: 0.677816, acc.: 57.03%] [G loss: 0.973969]\n",
      "epoch:0 step:864 [D loss: 0.737037, acc.: 54.69%] [G loss: 0.905147]\n",
      "epoch:0 step:865 [D loss: 0.692517, acc.: 57.81%] [G loss: 1.132116]\n",
      "epoch:0 step:866 [D loss: 0.638401, acc.: 63.28%] [G loss: 0.991087]\n",
      "epoch:0 step:867 [D loss: 0.803577, acc.: 50.78%] [G loss: 0.998249]\n",
      "epoch:0 step:868 [D loss: 0.674217, acc.: 59.38%] [G loss: 1.203405]\n",
      "epoch:0 step:869 [D loss: 0.719013, acc.: 53.91%] [G loss: 1.044257]\n",
      "epoch:0 step:870 [D loss: 0.646183, acc.: 63.28%] [G loss: 1.222831]\n",
      "epoch:0 step:871 [D loss: 0.615724, acc.: 65.62%] [G loss: 1.316169]\n",
      "epoch:0 step:872 [D loss: 0.596601, acc.: 67.19%] [G loss: 1.101246]\n",
      "epoch:0 step:873 [D loss: 0.759514, acc.: 57.81%] [G loss: 0.843606]\n",
      "epoch:0 step:874 [D loss: 0.756661, acc.: 48.44%] [G loss: 0.947518]\n",
      "epoch:0 step:875 [D loss: 0.720718, acc.: 51.56%] [G loss: 1.021299]\n",
      "epoch:0 step:876 [D loss: 0.667028, acc.: 60.16%] [G loss: 1.040498]\n",
      "epoch:0 step:877 [D loss: 0.759975, acc.: 54.69%] [G loss: 1.062704]\n",
      "epoch:0 step:878 [D loss: 0.785272, acc.: 49.22%] [G loss: 1.201903]\n",
      "epoch:0 step:879 [D loss: 0.753523, acc.: 58.59%] [G loss: 1.385347]\n",
      "epoch:0 step:880 [D loss: 0.678820, acc.: 64.06%] [G loss: 1.107197]\n",
      "epoch:0 step:881 [D loss: 0.652909, acc.: 67.97%] [G loss: 1.121599]\n",
      "epoch:0 step:882 [D loss: 0.677758, acc.: 58.59%] [G loss: 1.106191]\n",
      "epoch:0 step:883 [D loss: 0.657377, acc.: 57.81%] [G loss: 1.115666]\n",
      "epoch:0 step:884 [D loss: 0.632964, acc.: 63.28%] [G loss: 1.064479]\n",
      "epoch:0 step:885 [D loss: 0.756932, acc.: 52.34%] [G loss: 1.076215]\n",
      "epoch:0 step:886 [D loss: 0.662498, acc.: 63.28%] [G loss: 1.192762]\n",
      "epoch:0 step:887 [D loss: 0.784778, acc.: 50.78%] [G loss: 1.089627]\n",
      "epoch:0 step:888 [D loss: 0.781364, acc.: 46.09%] [G loss: 0.986941]\n",
      "epoch:0 step:889 [D loss: 0.725277, acc.: 52.34%] [G loss: 1.047868]\n",
      "epoch:0 step:890 [D loss: 0.641754, acc.: 59.38%] [G loss: 1.200413]\n",
      "epoch:0 step:891 [D loss: 0.724180, acc.: 54.69%] [G loss: 1.145357]\n",
      "epoch:0 step:892 [D loss: 0.912271, acc.: 41.41%] [G loss: 1.022498]\n",
      "epoch:0 step:893 [D loss: 0.681287, acc.: 58.59%] [G loss: 1.053383]\n",
      "epoch:0 step:894 [D loss: 0.645304, acc.: 63.28%] [G loss: 0.948945]\n",
      "epoch:0 step:895 [D loss: 0.710820, acc.: 57.03%] [G loss: 1.160390]\n",
      "epoch:0 step:896 [D loss: 0.666537, acc.: 58.59%] [G loss: 0.888350]\n",
      "epoch:0 step:897 [D loss: 0.608652, acc.: 68.75%] [G loss: 1.092257]\n",
      "epoch:0 step:898 [D loss: 0.906327, acc.: 39.84%] [G loss: 1.024126]\n",
      "epoch:0 step:899 [D loss: 0.583812, acc.: 67.19%] [G loss: 0.951769]\n",
      "epoch:0 step:900 [D loss: 0.607541, acc.: 64.06%] [G loss: 1.042111]\n",
      "epoch:0 step:901 [D loss: 0.721251, acc.: 58.59%] [G loss: 1.252140]\n",
      "epoch:0 step:902 [D loss: 0.745127, acc.: 50.78%] [G loss: 1.087501]\n",
      "epoch:0 step:903 [D loss: 0.671165, acc.: 61.72%] [G loss: 1.153308]\n",
      "epoch:0 step:904 [D loss: 0.813542, acc.: 43.75%] [G loss: 1.044442]\n",
      "epoch:0 step:905 [D loss: 0.706125, acc.: 54.69%] [G loss: 1.154751]\n",
      "epoch:0 step:906 [D loss: 0.813666, acc.: 46.09%] [G loss: 0.986064]\n",
      "epoch:0 step:907 [D loss: 0.741387, acc.: 56.25%] [G loss: 0.903171]\n",
      "epoch:0 step:908 [D loss: 0.737818, acc.: 49.22%] [G loss: 1.036197]\n",
      "epoch:0 step:909 [D loss: 0.705585, acc.: 60.16%] [G loss: 1.015347]\n",
      "epoch:0 step:910 [D loss: 0.763312, acc.: 50.00%] [G loss: 0.851569]\n",
      "epoch:0 step:911 [D loss: 0.817467, acc.: 53.12%] [G loss: 1.197140]\n",
      "epoch:0 step:912 [D loss: 0.790280, acc.: 45.31%] [G loss: 0.969794]\n",
      "epoch:0 step:913 [D loss: 0.697834, acc.: 56.25%] [G loss: 1.081401]\n",
      "epoch:0 step:914 [D loss: 0.582883, acc.: 71.09%] [G loss: 1.211905]\n",
      "epoch:0 step:915 [D loss: 0.747982, acc.: 49.22%] [G loss: 1.045566]\n",
      "epoch:0 step:916 [D loss: 0.782032, acc.: 52.34%] [G loss: 0.967203]\n",
      "epoch:0 step:917 [D loss: 0.769332, acc.: 51.56%] [G loss: 0.989800]\n",
      "epoch:0 step:918 [D loss: 0.731277, acc.: 53.12%] [G loss: 1.018736]\n",
      "epoch:0 step:919 [D loss: 0.714652, acc.: 54.69%] [G loss: 1.015701]\n",
      "epoch:0 step:920 [D loss: 0.751922, acc.: 53.91%] [G loss: 0.988486]\n",
      "epoch:0 step:921 [D loss: 0.595569, acc.: 64.84%] [G loss: 1.042260]\n",
      "epoch:0 step:922 [D loss: 0.586934, acc.: 66.41%] [G loss: 0.934530]\n",
      "epoch:0 step:923 [D loss: 0.709628, acc.: 55.47%] [G loss: 1.110753]\n",
      "epoch:0 step:924 [D loss: 0.618536, acc.: 67.19%] [G loss: 0.976990]\n",
      "epoch:0 step:925 [D loss: 0.553114, acc.: 73.44%] [G loss: 0.948226]\n",
      "epoch:0 step:926 [D loss: 0.608453, acc.: 65.62%] [G loss: 1.115850]\n",
      "epoch:0 step:927 [D loss: 0.653876, acc.: 62.50%] [G loss: 1.251556]\n",
      "epoch:0 step:928 [D loss: 0.910137, acc.: 37.50%] [G loss: 1.182034]\n",
      "epoch:0 step:929 [D loss: 0.812203, acc.: 46.09%] [G loss: 1.081014]\n",
      "epoch:0 step:930 [D loss: 0.764825, acc.: 57.81%] [G loss: 1.055940]\n",
      "epoch:0 step:931 [D loss: 0.767677, acc.: 53.91%] [G loss: 1.060645]\n",
      "epoch:0 step:932 [D loss: 0.796796, acc.: 50.00%] [G loss: 1.167025]\n",
      "epoch:0 step:933 [D loss: 0.724795, acc.: 54.69%] [G loss: 1.072783]\n",
      "epoch:0 step:934 [D loss: 0.738802, acc.: 50.00%] [G loss: 1.004924]\n",
      "epoch:0 step:935 [D loss: 0.755820, acc.: 58.59%] [G loss: 1.052340]\n",
      "epoch:0 step:936 [D loss: 0.596065, acc.: 66.41%] [G loss: 1.198721]\n",
      "epoch:0 step:937 [D loss: 0.786644, acc.: 51.56%] [G loss: 1.181058]\n",
      "epoch:1 step:938 [D loss: 0.683540, acc.: 55.47%] [G loss: 1.243089]\n",
      "epoch:1 step:939 [D loss: 0.757979, acc.: 50.78%] [G loss: 1.007835]\n",
      "epoch:1 step:940 [D loss: 0.723160, acc.: 57.03%] [G loss: 1.206308]\n",
      "epoch:1 step:941 [D loss: 0.732255, acc.: 54.69%] [G loss: 1.085919]\n",
      "epoch:1 step:942 [D loss: 0.723757, acc.: 55.47%] [G loss: 1.028765]\n",
      "epoch:1 step:943 [D loss: 0.674571, acc.: 54.69%] [G loss: 1.036320]\n",
      "epoch:1 step:944 [D loss: 0.636118, acc.: 61.72%] [G loss: 1.063413]\n",
      "epoch:1 step:945 [D loss: 0.733795, acc.: 54.69%] [G loss: 1.023539]\n",
      "epoch:1 step:946 [D loss: 0.732765, acc.: 55.47%] [G loss: 0.983569]\n",
      "epoch:1 step:947 [D loss: 0.627921, acc.: 62.50%] [G loss: 0.952234]\n",
      "epoch:1 step:948 [D loss: 0.781657, acc.: 47.66%] [G loss: 0.917662]\n",
      "epoch:1 step:949 [D loss: 0.782273, acc.: 50.78%] [G loss: 1.025513]\n",
      "epoch:1 step:950 [D loss: 0.740795, acc.: 53.91%] [G loss: 1.034767]\n",
      "epoch:1 step:951 [D loss: 0.692969, acc.: 60.16%] [G loss: 1.025732]\n",
      "epoch:1 step:952 [D loss: 0.644200, acc.: 60.16%] [G loss: 1.056592]\n",
      "epoch:1 step:953 [D loss: 0.708217, acc.: 58.59%] [G loss: 0.999167]\n",
      "epoch:1 step:954 [D loss: 0.703573, acc.: 57.03%] [G loss: 1.151378]\n",
      "epoch:1 step:955 [D loss: 0.721531, acc.: 57.03%] [G loss: 0.966074]\n",
      "epoch:1 step:956 [D loss: 0.722664, acc.: 54.69%] [G loss: 1.079411]\n",
      "epoch:1 step:957 [D loss: 0.691828, acc.: 53.91%] [G loss: 0.964399]\n",
      "epoch:1 step:958 [D loss: 0.644823, acc.: 62.50%] [G loss: 1.096525]\n",
      "epoch:1 step:959 [D loss: 0.618488, acc.: 65.62%] [G loss: 1.323221]\n",
      "epoch:1 step:960 [D loss: 0.729368, acc.: 50.78%] [G loss: 1.012148]\n",
      "epoch:1 step:961 [D loss: 0.753966, acc.: 52.34%] [G loss: 1.045207]\n",
      "epoch:1 step:962 [D loss: 0.656098, acc.: 59.38%] [G loss: 1.036128]\n",
      "epoch:1 step:963 [D loss: 0.655977, acc.: 58.59%] [G loss: 1.071981]\n",
      "epoch:1 step:964 [D loss: 0.648530, acc.: 64.06%] [G loss: 1.094579]\n",
      "epoch:1 step:965 [D loss: 0.761176, acc.: 51.56%] [G loss: 1.143664]\n",
      "epoch:1 step:966 [D loss: 0.615635, acc.: 71.09%] [G loss: 1.095874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:967 [D loss: 0.732167, acc.: 50.78%] [G loss: 0.941169]\n",
      "epoch:1 step:968 [D loss: 0.742372, acc.: 50.78%] [G loss: 0.875794]\n",
      "epoch:1 step:969 [D loss: 0.717146, acc.: 54.69%] [G loss: 0.968986]\n",
      "epoch:1 step:970 [D loss: 0.731186, acc.: 53.91%] [G loss: 0.932231]\n",
      "epoch:1 step:971 [D loss: 0.706717, acc.: 53.91%] [G loss: 0.823565]\n",
      "epoch:1 step:972 [D loss: 0.657475, acc.: 60.16%] [G loss: 1.160585]\n",
      "epoch:1 step:973 [D loss: 0.685560, acc.: 56.25%] [G loss: 0.946554]\n",
      "epoch:1 step:974 [D loss: 0.699468, acc.: 60.16%] [G loss: 1.023145]\n",
      "epoch:1 step:975 [D loss: 0.976996, acc.: 31.25%] [G loss: 0.917769]\n",
      "epoch:1 step:976 [D loss: 0.695083, acc.: 58.59%] [G loss: 0.920865]\n",
      "epoch:1 step:977 [D loss: 0.672928, acc.: 57.81%] [G loss: 0.998337]\n",
      "epoch:1 step:978 [D loss: 0.659725, acc.: 64.06%] [G loss: 0.931757]\n",
      "epoch:1 step:979 [D loss: 0.676324, acc.: 60.16%] [G loss: 1.050768]\n",
      "epoch:1 step:980 [D loss: 0.758301, acc.: 52.34%] [G loss: 1.027923]\n",
      "epoch:1 step:981 [D loss: 0.766062, acc.: 47.66%] [G loss: 0.979114]\n",
      "epoch:1 step:982 [D loss: 0.679698, acc.: 56.25%] [G loss: 0.923929]\n",
      "epoch:1 step:983 [D loss: 0.659160, acc.: 58.59%] [G loss: 0.989729]\n",
      "epoch:1 step:984 [D loss: 0.673895, acc.: 57.03%] [G loss: 0.879220]\n",
      "epoch:1 step:985 [D loss: 0.600441, acc.: 69.53%] [G loss: 0.748956]\n",
      "epoch:1 step:986 [D loss: 0.688754, acc.: 61.72%] [G loss: 0.774251]\n",
      "epoch:1 step:987 [D loss: 0.571511, acc.: 70.31%] [G loss: 0.833890]\n",
      "epoch:1 step:988 [D loss: 0.819509, acc.: 42.19%] [G loss: 0.870796]\n",
      "epoch:1 step:989 [D loss: 0.753572, acc.: 43.75%] [G loss: 0.784706]\n",
      "epoch:1 step:990 [D loss: 0.591409, acc.: 70.31%] [G loss: 0.958207]\n",
      "epoch:1 step:991 [D loss: 0.701322, acc.: 53.12%] [G loss: 0.902587]\n",
      "epoch:1 step:992 [D loss: 0.735071, acc.: 50.78%] [G loss: 0.932278]\n",
      "epoch:1 step:993 [D loss: 0.740728, acc.: 48.44%] [G loss: 0.836425]\n",
      "epoch:1 step:994 [D loss: 0.704630, acc.: 57.81%] [G loss: 0.931731]\n",
      "epoch:1 step:995 [D loss: 0.792361, acc.: 50.78%] [G loss: 1.071891]\n",
      "epoch:1 step:996 [D loss: 0.706184, acc.: 56.25%] [G loss: 1.029522]\n",
      "epoch:1 step:997 [D loss: 0.726704, acc.: 51.56%] [G loss: 1.211213]\n",
      "epoch:1 step:998 [D loss: 0.752936, acc.: 48.44%] [G loss: 0.981908]\n",
      "epoch:1 step:999 [D loss: 0.691860, acc.: 60.16%] [G loss: 0.964778]\n",
      "epoch:1 step:1000 [D loss: 0.686959, acc.: 57.81%] [G loss: 1.015553]\n",
      "epoch:1 step:1001 [D loss: 0.777548, acc.: 42.19%] [G loss: 1.084886]\n",
      "epoch:1 step:1002 [D loss: 0.683864, acc.: 57.81%] [G loss: 0.921860]\n",
      "epoch:1 step:1003 [D loss: 0.679409, acc.: 55.47%] [G loss: 1.007901]\n",
      "epoch:1 step:1004 [D loss: 0.708811, acc.: 53.91%] [G loss: 0.873208]\n",
      "epoch:1 step:1005 [D loss: 0.756162, acc.: 47.66%] [G loss: 0.873606]\n",
      "epoch:1 step:1006 [D loss: 0.719400, acc.: 53.91%] [G loss: 0.985058]\n",
      "epoch:1 step:1007 [D loss: 0.677276, acc.: 56.25%] [G loss: 0.917376]\n",
      "epoch:1 step:1008 [D loss: 0.727800, acc.: 49.22%] [G loss: 0.957723]\n",
      "epoch:1 step:1009 [D loss: 0.700881, acc.: 58.59%] [G loss: 1.001101]\n",
      "epoch:1 step:1010 [D loss: 0.696660, acc.: 53.91%] [G loss: 1.050814]\n",
      "epoch:1 step:1011 [D loss: 0.695133, acc.: 56.25%] [G loss: 0.899983]\n",
      "epoch:1 step:1012 [D loss: 0.747254, acc.: 53.12%] [G loss: 0.938715]\n",
      "epoch:1 step:1013 [D loss: 0.661116, acc.: 61.72%] [G loss: 0.888578]\n",
      "epoch:1 step:1014 [D loss: 0.669678, acc.: 59.38%] [G loss: 1.161358]\n",
      "epoch:1 step:1015 [D loss: 0.751622, acc.: 44.53%] [G loss: 1.043840]\n",
      "epoch:1 step:1016 [D loss: 0.679899, acc.: 58.59%] [G loss: 0.955075]\n",
      "epoch:1 step:1017 [D loss: 0.782426, acc.: 45.31%] [G loss: 0.985865]\n",
      "epoch:1 step:1018 [D loss: 0.735966, acc.: 50.78%] [G loss: 0.890076]\n",
      "epoch:1 step:1019 [D loss: 0.726547, acc.: 50.00%] [G loss: 0.969498]\n",
      "epoch:1 step:1020 [D loss: 0.704622, acc.: 50.78%] [G loss: 0.967453]\n",
      "epoch:1 step:1021 [D loss: 0.687111, acc.: 50.00%] [G loss: 0.917235]\n",
      "epoch:1 step:1022 [D loss: 0.756495, acc.: 42.19%] [G loss: 0.971081]\n",
      "epoch:1 step:1023 [D loss: 0.617313, acc.: 71.88%] [G loss: 0.935330]\n",
      "epoch:1 step:1024 [D loss: 0.706853, acc.: 52.34%] [G loss: 1.004242]\n",
      "epoch:1 step:1025 [D loss: 0.654983, acc.: 62.50%] [G loss: 0.819948]\n",
      "epoch:1 step:1026 [D loss: 0.607044, acc.: 67.97%] [G loss: 0.863450]\n",
      "epoch:1 step:1027 [D loss: 0.662533, acc.: 62.50%] [G loss: 1.049160]\n",
      "epoch:1 step:1028 [D loss: 0.652492, acc.: 64.06%] [G loss: 1.037908]\n",
      "epoch:1 step:1029 [D loss: 0.757637, acc.: 40.62%] [G loss: 0.946321]\n",
      "epoch:1 step:1030 [D loss: 0.672685, acc.: 60.16%] [G loss: 0.974542]\n",
      "epoch:1 step:1031 [D loss: 0.649472, acc.: 56.25%] [G loss: 1.085961]\n",
      "epoch:1 step:1032 [D loss: 0.655368, acc.: 58.59%] [G loss: 1.074300]\n",
      "epoch:1 step:1033 [D loss: 0.606276, acc.: 70.31%] [G loss: 0.935919]\n",
      "epoch:1 step:1034 [D loss: 0.595124, acc.: 68.75%] [G loss: 0.996236]\n",
      "epoch:1 step:1035 [D loss: 0.712722, acc.: 59.38%] [G loss: 1.084249]\n",
      "epoch:1 step:1036 [D loss: 0.642535, acc.: 65.62%] [G loss: 1.159289]\n",
      "epoch:1 step:1037 [D loss: 0.684734, acc.: 57.81%] [G loss: 1.019333]\n",
      "epoch:1 step:1038 [D loss: 0.653372, acc.: 60.16%] [G loss: 0.900001]\n",
      "epoch:1 step:1039 [D loss: 0.812513, acc.: 39.84%] [G loss: 0.990894]\n",
      "epoch:1 step:1040 [D loss: 0.765801, acc.: 48.44%] [G loss: 1.003855]\n",
      "epoch:1 step:1041 [D loss: 0.731443, acc.: 49.22%] [G loss: 0.991823]\n",
      "epoch:1 step:1042 [D loss: 0.757751, acc.: 50.78%] [G loss: 0.935897]\n",
      "epoch:1 step:1043 [D loss: 0.655399, acc.: 62.50%] [G loss: 0.966836]\n",
      "epoch:1 step:1044 [D loss: 0.593904, acc.: 67.97%] [G loss: 1.137901]\n",
      "epoch:1 step:1045 [D loss: 0.715552, acc.: 53.91%] [G loss: 1.397304]\n",
      "epoch:1 step:1046 [D loss: 0.772888, acc.: 50.00%] [G loss: 0.999188]\n",
      "epoch:1 step:1047 [D loss: 0.749409, acc.: 52.34%] [G loss: 1.050775]\n",
      "epoch:1 step:1048 [D loss: 0.653053, acc.: 58.59%] [G loss: 0.887479]\n",
      "epoch:1 step:1049 [D loss: 0.677078, acc.: 54.69%] [G loss: 1.008756]\n",
      "epoch:1 step:1050 [D loss: 0.631024, acc.: 60.16%] [G loss: 1.062802]\n",
      "epoch:1 step:1051 [D loss: 0.687007, acc.: 56.25%] [G loss: 0.982181]\n",
      "epoch:1 step:1052 [D loss: 0.689710, acc.: 53.91%] [G loss: 0.979460]\n",
      "epoch:1 step:1053 [D loss: 0.774431, acc.: 44.53%] [G loss: 1.128524]\n",
      "epoch:1 step:1054 [D loss: 0.693208, acc.: 61.72%] [G loss: 1.087687]\n",
      "epoch:1 step:1055 [D loss: 0.710901, acc.: 55.47%] [G loss: 1.074178]\n",
      "epoch:1 step:1056 [D loss: 0.730246, acc.: 51.56%] [G loss: 1.073737]\n",
      "epoch:1 step:1057 [D loss: 0.745731, acc.: 52.34%] [G loss: 1.179929]\n",
      "epoch:1 step:1058 [D loss: 0.646870, acc.: 61.72%] [G loss: 1.248060]\n",
      "epoch:1 step:1059 [D loss: 0.636461, acc.: 69.53%] [G loss: 1.090702]\n",
      "epoch:1 step:1060 [D loss: 0.653888, acc.: 55.47%] [G loss: 1.143597]\n",
      "epoch:1 step:1061 [D loss: 0.668211, acc.: 61.72%] [G loss: 1.170386]\n",
      "epoch:1 step:1062 [D loss: 0.711381, acc.: 56.25%] [G loss: 0.940944]\n",
      "epoch:1 step:1063 [D loss: 0.640855, acc.: 60.16%] [G loss: 0.935246]\n",
      "epoch:1 step:1064 [D loss: 0.664209, acc.: 59.38%] [G loss: 0.898194]\n",
      "epoch:1 step:1065 [D loss: 0.809536, acc.: 42.97%] [G loss: 0.913420]\n",
      "epoch:1 step:1066 [D loss: 0.749499, acc.: 50.78%] [G loss: 0.903183]\n",
      "epoch:1 step:1067 [D loss: 0.628270, acc.: 62.50%] [G loss: 0.923936]\n",
      "epoch:1 step:1068 [D loss: 0.678380, acc.: 57.81%] [G loss: 1.135482]\n",
      "epoch:1 step:1069 [D loss: 0.622344, acc.: 64.84%] [G loss: 1.048217]\n",
      "epoch:1 step:1070 [D loss: 0.803179, acc.: 41.41%] [G loss: 0.996873]\n",
      "epoch:1 step:1071 [D loss: 0.720492, acc.: 53.12%] [G loss: 0.994208]\n",
      "epoch:1 step:1072 [D loss: 0.632084, acc.: 64.06%] [G loss: 0.866991]\n",
      "epoch:1 step:1073 [D loss: 0.709901, acc.: 52.34%] [G loss: 0.914971]\n",
      "epoch:1 step:1074 [D loss: 0.675552, acc.: 60.94%] [G loss: 1.003560]\n",
      "epoch:1 step:1075 [D loss: 0.746544, acc.: 54.69%] [G loss: 0.740467]\n",
      "epoch:1 step:1076 [D loss: 0.649580, acc.: 58.59%] [G loss: 1.038764]\n",
      "epoch:1 step:1077 [D loss: 0.630264, acc.: 66.41%] [G loss: 0.891463]\n",
      "epoch:1 step:1078 [D loss: 0.684146, acc.: 60.16%] [G loss: 0.806396]\n",
      "epoch:1 step:1079 [D loss: 0.727520, acc.: 52.34%] [G loss: 0.885290]\n",
      "epoch:1 step:1080 [D loss: 0.580590, acc.: 69.53%] [G loss: 0.930415]\n",
      "epoch:1 step:1081 [D loss: 0.722652, acc.: 56.25%] [G loss: 0.928619]\n",
      "epoch:1 step:1082 [D loss: 0.730911, acc.: 55.47%] [G loss: 0.997054]\n",
      "epoch:1 step:1083 [D loss: 0.691674, acc.: 57.03%] [G loss: 1.150042]\n",
      "epoch:1 step:1084 [D loss: 0.720118, acc.: 49.22%] [G loss: 1.331583]\n",
      "epoch:1 step:1085 [D loss: 0.704896, acc.: 58.59%] [G loss: 1.097871]\n",
      "epoch:1 step:1086 [D loss: 0.723798, acc.: 58.59%] [G loss: 1.046563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1087 [D loss: 0.715598, acc.: 56.25%] [G loss: 1.047754]\n",
      "epoch:1 step:1088 [D loss: 0.671489, acc.: 61.72%] [G loss: 1.132977]\n",
      "epoch:1 step:1089 [D loss: 0.623838, acc.: 64.84%] [G loss: 1.172678]\n",
      "epoch:1 step:1090 [D loss: 0.653581, acc.: 58.59%] [G loss: 0.989959]\n",
      "epoch:1 step:1091 [D loss: 0.749824, acc.: 50.00%] [G loss: 1.014586]\n",
      "epoch:1 step:1092 [D loss: 0.673583, acc.: 57.81%] [G loss: 1.170264]\n",
      "epoch:1 step:1093 [D loss: 0.642268, acc.: 63.28%] [G loss: 0.888357]\n",
      "epoch:1 step:1094 [D loss: 0.664734, acc.: 60.16%] [G loss: 0.890509]\n",
      "epoch:1 step:1095 [D loss: 0.728323, acc.: 52.34%] [G loss: 0.943220]\n",
      "epoch:1 step:1096 [D loss: 0.730434, acc.: 49.22%] [G loss: 1.013245]\n",
      "epoch:1 step:1097 [D loss: 0.707280, acc.: 53.91%] [G loss: 1.056784]\n",
      "epoch:1 step:1098 [D loss: 0.609920, acc.: 66.41%] [G loss: 1.071038]\n",
      "epoch:1 step:1099 [D loss: 0.689982, acc.: 55.47%] [G loss: 0.983944]\n",
      "epoch:1 step:1100 [D loss: 0.764966, acc.: 48.44%] [G loss: 0.994731]\n",
      "epoch:1 step:1101 [D loss: 0.737581, acc.: 56.25%] [G loss: 0.871971]\n",
      "epoch:1 step:1102 [D loss: 0.717228, acc.: 54.69%] [G loss: 0.896074]\n",
      "epoch:1 step:1103 [D loss: 0.640567, acc.: 58.59%] [G loss: 1.050160]\n",
      "epoch:1 step:1104 [D loss: 0.717728, acc.: 62.50%] [G loss: 0.916851]\n",
      "epoch:1 step:1105 [D loss: 0.635328, acc.: 64.06%] [G loss: 0.842238]\n",
      "epoch:1 step:1106 [D loss: 0.715004, acc.: 58.59%] [G loss: 0.960878]\n",
      "epoch:1 step:1107 [D loss: 0.696589, acc.: 60.16%] [G loss: 0.951131]\n",
      "epoch:1 step:1108 [D loss: 0.699350, acc.: 60.94%] [G loss: 0.884517]\n",
      "epoch:1 step:1109 [D loss: 0.771525, acc.: 47.66%] [G loss: 1.033289]\n",
      "epoch:1 step:1110 [D loss: 0.641928, acc.: 64.84%] [G loss: 1.144326]\n",
      "epoch:1 step:1111 [D loss: 0.672210, acc.: 57.03%] [G loss: 0.972858]\n",
      "epoch:1 step:1112 [D loss: 0.711040, acc.: 53.91%] [G loss: 0.923123]\n",
      "epoch:1 step:1113 [D loss: 0.625873, acc.: 67.19%] [G loss: 0.837527]\n",
      "epoch:1 step:1114 [D loss: 0.719808, acc.: 46.88%] [G loss: 0.923458]\n",
      "epoch:1 step:1115 [D loss: 0.733883, acc.: 48.44%] [G loss: 0.956357]\n",
      "epoch:1 step:1116 [D loss: 0.776809, acc.: 49.22%] [G loss: 0.887248]\n",
      "epoch:1 step:1117 [D loss: 0.747814, acc.: 51.56%] [G loss: 0.943990]\n",
      "epoch:1 step:1118 [D loss: 0.720078, acc.: 51.56%] [G loss: 0.960926]\n",
      "epoch:1 step:1119 [D loss: 0.763956, acc.: 52.34%] [G loss: 0.928045]\n",
      "epoch:1 step:1120 [D loss: 0.638792, acc.: 66.41%] [G loss: 0.950427]\n",
      "epoch:1 step:1121 [D loss: 0.682633, acc.: 60.16%] [G loss: 0.927300]\n",
      "epoch:1 step:1122 [D loss: 0.661179, acc.: 57.81%] [G loss: 1.051207]\n",
      "epoch:1 step:1123 [D loss: 0.714549, acc.: 51.56%] [G loss: 1.088339]\n",
      "epoch:1 step:1124 [D loss: 0.647424, acc.: 63.28%] [G loss: 0.988625]\n",
      "epoch:1 step:1125 [D loss: 0.761818, acc.: 49.22%] [G loss: 1.008121]\n",
      "epoch:1 step:1126 [D loss: 0.675811, acc.: 54.69%] [G loss: 0.960685]\n",
      "epoch:1 step:1127 [D loss: 0.687683, acc.: 54.69%] [G loss: 0.940621]\n",
      "epoch:1 step:1128 [D loss: 0.686384, acc.: 53.91%] [G loss: 1.060819]\n",
      "epoch:1 step:1129 [D loss: 0.697157, acc.: 52.34%] [G loss: 1.036142]\n",
      "epoch:1 step:1130 [D loss: 0.664519, acc.: 60.16%] [G loss: 1.216753]\n",
      "epoch:1 step:1131 [D loss: 0.698919, acc.: 53.12%] [G loss: 1.078972]\n",
      "epoch:1 step:1132 [D loss: 0.702314, acc.: 56.25%] [G loss: 1.090276]\n",
      "epoch:1 step:1133 [D loss: 0.678806, acc.: 56.25%] [G loss: 1.154182]\n",
      "epoch:1 step:1134 [D loss: 0.675289, acc.: 61.72%] [G loss: 0.997448]\n",
      "epoch:1 step:1135 [D loss: 0.659698, acc.: 59.38%] [G loss: 1.071674]\n",
      "epoch:1 step:1136 [D loss: 0.699763, acc.: 55.47%] [G loss: 1.004723]\n",
      "epoch:1 step:1137 [D loss: 0.751577, acc.: 46.09%] [G loss: 1.074969]\n",
      "epoch:1 step:1138 [D loss: 0.715725, acc.: 50.78%] [G loss: 0.941048]\n",
      "epoch:1 step:1139 [D loss: 0.736707, acc.: 50.00%] [G loss: 1.019446]\n",
      "epoch:1 step:1140 [D loss: 0.795973, acc.: 50.00%] [G loss: 0.926918]\n",
      "epoch:1 step:1141 [D loss: 0.748295, acc.: 48.44%] [G loss: 0.853933]\n",
      "epoch:1 step:1142 [D loss: 0.647360, acc.: 62.50%] [G loss: 1.005132]\n",
      "epoch:1 step:1143 [D loss: 0.582167, acc.: 68.75%] [G loss: 1.032485]\n",
      "epoch:1 step:1144 [D loss: 0.643178, acc.: 63.28%] [G loss: 1.108934]\n",
      "epoch:1 step:1145 [D loss: 0.676649, acc.: 62.50%] [G loss: 1.115035]\n",
      "epoch:1 step:1146 [D loss: 0.552022, acc.: 74.22%] [G loss: 1.148385]\n",
      "epoch:1 step:1147 [D loss: 0.670104, acc.: 62.50%] [G loss: 0.908677]\n",
      "epoch:1 step:1148 [D loss: 0.690386, acc.: 62.50%] [G loss: 0.882514]\n",
      "epoch:1 step:1149 [D loss: 0.698365, acc.: 59.38%] [G loss: 0.975764]\n",
      "epoch:1 step:1150 [D loss: 0.666652, acc.: 58.59%] [G loss: 1.107079]\n",
      "epoch:1 step:1151 [D loss: 0.654840, acc.: 64.84%] [G loss: 0.953118]\n",
      "epoch:1 step:1152 [D loss: 0.649892, acc.: 61.72%] [G loss: 0.918822]\n",
      "epoch:1 step:1153 [D loss: 0.693387, acc.: 54.69%] [G loss: 0.924353]\n",
      "epoch:1 step:1154 [D loss: 0.666651, acc.: 56.25%] [G loss: 1.125215]\n",
      "epoch:1 step:1155 [D loss: 0.732743, acc.: 53.91%] [G loss: 0.890060]\n",
      "epoch:1 step:1156 [D loss: 0.578357, acc.: 75.00%] [G loss: 0.945117]\n",
      "epoch:1 step:1157 [D loss: 0.904717, acc.: 37.50%] [G loss: 0.929433]\n",
      "epoch:1 step:1158 [D loss: 0.743737, acc.: 47.66%] [G loss: 1.185240]\n",
      "epoch:1 step:1159 [D loss: 0.697011, acc.: 52.34%] [G loss: 1.231008]\n",
      "epoch:1 step:1160 [D loss: 0.625353, acc.: 62.50%] [G loss: 1.236017]\n",
      "epoch:1 step:1161 [D loss: 0.731255, acc.: 53.91%] [G loss: 1.280673]\n",
      "epoch:1 step:1162 [D loss: 0.818200, acc.: 46.88%] [G loss: 0.913602]\n",
      "epoch:1 step:1163 [D loss: 0.739217, acc.: 53.91%] [G loss: 0.895738]\n",
      "epoch:1 step:1164 [D loss: 0.719831, acc.: 51.56%] [G loss: 0.940957]\n",
      "epoch:1 step:1165 [D loss: 0.728185, acc.: 49.22%] [G loss: 0.919366]\n",
      "epoch:1 step:1166 [D loss: 0.720024, acc.: 59.38%] [G loss: 0.959698]\n",
      "epoch:1 step:1167 [D loss: 0.625068, acc.: 69.53%] [G loss: 1.029352]\n",
      "epoch:1 step:1168 [D loss: 0.576690, acc.: 71.09%] [G loss: 1.072470]\n",
      "epoch:1 step:1169 [D loss: 0.571746, acc.: 74.22%] [G loss: 1.057865]\n",
      "epoch:1 step:1170 [D loss: 0.687004, acc.: 58.59%] [G loss: 1.273424]\n",
      "epoch:1 step:1171 [D loss: 0.666468, acc.: 61.72%] [G loss: 0.992398]\n",
      "epoch:1 step:1172 [D loss: 0.730776, acc.: 46.09%] [G loss: 1.135544]\n",
      "epoch:1 step:1173 [D loss: 0.795420, acc.: 42.97%] [G loss: 0.924585]\n",
      "epoch:1 step:1174 [D loss: 0.711313, acc.: 55.47%] [G loss: 0.996089]\n",
      "epoch:1 step:1175 [D loss: 0.733097, acc.: 46.09%] [G loss: 0.886344]\n",
      "epoch:1 step:1176 [D loss: 0.795137, acc.: 40.62%] [G loss: 0.840695]\n",
      "epoch:1 step:1177 [D loss: 0.728328, acc.: 48.44%] [G loss: 0.880055]\n",
      "epoch:1 step:1178 [D loss: 0.704231, acc.: 56.25%] [G loss: 0.827745]\n",
      "epoch:1 step:1179 [D loss: 0.738372, acc.: 44.53%] [G loss: 0.915412]\n",
      "epoch:1 step:1180 [D loss: 0.664051, acc.: 56.25%] [G loss: 0.944849]\n",
      "epoch:1 step:1181 [D loss: 0.609341, acc.: 64.84%] [G loss: 1.183388]\n",
      "epoch:1 step:1182 [D loss: 0.566550, acc.: 70.31%] [G loss: 0.887561]\n",
      "epoch:1 step:1183 [D loss: 0.725459, acc.: 59.38%] [G loss: 0.836464]\n",
      "epoch:1 step:1184 [D loss: 0.664156, acc.: 59.38%] [G loss: 0.893437]\n",
      "epoch:1 step:1185 [D loss: 0.561805, acc.: 67.19%] [G loss: 0.970203]\n",
      "epoch:1 step:1186 [D loss: 0.709730, acc.: 55.47%] [G loss: 0.916483]\n",
      "epoch:1 step:1187 [D loss: 0.602211, acc.: 69.53%] [G loss: 0.972754]\n",
      "epoch:1 step:1188 [D loss: 0.698544, acc.: 50.78%] [G loss: 0.997069]\n",
      "epoch:1 step:1189 [D loss: 0.671622, acc.: 54.69%] [G loss: 0.887416]\n",
      "epoch:1 step:1190 [D loss: 0.655152, acc.: 62.50%] [G loss: 0.861637]\n",
      "epoch:1 step:1191 [D loss: 0.773276, acc.: 49.22%] [G loss: 0.814449]\n",
      "epoch:1 step:1192 [D loss: 0.742349, acc.: 46.09%] [G loss: 0.763557]\n",
      "epoch:1 step:1193 [D loss: 0.707598, acc.: 49.22%] [G loss: 0.822806]\n",
      "epoch:1 step:1194 [D loss: 0.730458, acc.: 56.25%] [G loss: 1.090605]\n",
      "epoch:1 step:1195 [D loss: 0.659822, acc.: 62.50%] [G loss: 1.122651]\n",
      "epoch:1 step:1196 [D loss: 0.600483, acc.: 72.66%] [G loss: 1.060461]\n",
      "epoch:1 step:1197 [D loss: 0.704438, acc.: 56.25%] [G loss: 1.045342]\n",
      "epoch:1 step:1198 [D loss: 0.673041, acc.: 60.16%] [G loss: 1.101724]\n",
      "epoch:1 step:1199 [D loss: 0.684308, acc.: 53.91%] [G loss: 0.999745]\n",
      "epoch:1 step:1200 [D loss: 0.890117, acc.: 37.50%] [G loss: 0.855070]\n",
      "epoch:1 step:1201 [D loss: 0.689436, acc.: 51.56%] [G loss: 0.832873]\n",
      "epoch:1 step:1202 [D loss: 0.773267, acc.: 50.00%] [G loss: 0.940551]\n",
      "epoch:1 step:1203 [D loss: 0.751307, acc.: 55.47%] [G loss: 0.956522]\n",
      "epoch:1 step:1204 [D loss: 0.712515, acc.: 46.88%] [G loss: 0.939739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1205 [D loss: 0.699807, acc.: 55.47%] [G loss: 1.029599]\n",
      "epoch:1 step:1206 [D loss: 0.682304, acc.: 50.78%] [G loss: 0.968552]\n",
      "epoch:1 step:1207 [D loss: 0.758239, acc.: 46.88%] [G loss: 0.974781]\n",
      "epoch:1 step:1208 [D loss: 0.665599, acc.: 57.03%] [G loss: 0.807819]\n",
      "epoch:1 step:1209 [D loss: 0.756513, acc.: 50.78%] [G loss: 0.977622]\n",
      "epoch:1 step:1210 [D loss: 0.699581, acc.: 58.59%] [G loss: 0.957332]\n",
      "epoch:1 step:1211 [D loss: 0.642357, acc.: 65.62%] [G loss: 1.105134]\n",
      "epoch:1 step:1212 [D loss: 0.686595, acc.: 58.59%] [G loss: 0.925785]\n",
      "epoch:1 step:1213 [D loss: 0.657235, acc.: 61.72%] [G loss: 0.900947]\n",
      "epoch:1 step:1214 [D loss: 0.737745, acc.: 51.56%] [G loss: 1.078948]\n",
      "epoch:1 step:1215 [D loss: 0.711002, acc.: 53.12%] [G loss: 0.938211]\n",
      "epoch:1 step:1216 [D loss: 0.688437, acc.: 53.12%] [G loss: 1.027122]\n",
      "epoch:1 step:1217 [D loss: 0.670969, acc.: 64.84%] [G loss: 1.044795]\n",
      "epoch:1 step:1218 [D loss: 0.777889, acc.: 48.44%] [G loss: 0.945583]\n",
      "epoch:1 step:1219 [D loss: 0.785759, acc.: 43.75%] [G loss: 0.894712]\n",
      "epoch:1 step:1220 [D loss: 0.744211, acc.: 50.00%] [G loss: 0.814937]\n",
      "epoch:1 step:1221 [D loss: 0.679071, acc.: 57.03%] [G loss: 0.745761]\n",
      "epoch:1 step:1222 [D loss: 0.694077, acc.: 57.03%] [G loss: 0.979190]\n",
      "epoch:1 step:1223 [D loss: 0.664045, acc.: 60.16%] [G loss: 0.942226]\n",
      "epoch:1 step:1224 [D loss: 0.676990, acc.: 53.91%] [G loss: 1.123312]\n",
      "epoch:1 step:1225 [D loss: 0.652659, acc.: 60.94%] [G loss: 0.905299]\n",
      "epoch:1 step:1226 [D loss: 0.618927, acc.: 64.06%] [G loss: 0.901736]\n",
      "epoch:1 step:1227 [D loss: 0.692714, acc.: 57.03%] [G loss: 0.937488]\n",
      "epoch:1 step:1228 [D loss: 0.711774, acc.: 54.69%] [G loss: 0.981292]\n",
      "epoch:1 step:1229 [D loss: 0.667668, acc.: 56.25%] [G loss: 0.965687]\n",
      "epoch:1 step:1230 [D loss: 0.721162, acc.: 51.56%] [G loss: 0.918931]\n",
      "epoch:1 step:1231 [D loss: 0.693730, acc.: 58.59%] [G loss: 0.967122]\n",
      "epoch:1 step:1232 [D loss: 0.791742, acc.: 42.19%] [G loss: 0.892168]\n",
      "epoch:1 step:1233 [D loss: 0.689890, acc.: 50.78%] [G loss: 0.832903]\n",
      "epoch:1 step:1234 [D loss: 0.698313, acc.: 50.00%] [G loss: 0.861484]\n",
      "epoch:1 step:1235 [D loss: 0.613854, acc.: 59.38%] [G loss: 0.900795]\n",
      "epoch:1 step:1236 [D loss: 0.660092, acc.: 59.38%] [G loss: 0.896811]\n",
      "epoch:1 step:1237 [D loss: 0.635401, acc.: 61.72%] [G loss: 1.019495]\n",
      "epoch:1 step:1238 [D loss: 0.656675, acc.: 64.06%] [G loss: 0.804770]\n",
      "epoch:1 step:1239 [D loss: 0.607494, acc.: 63.28%] [G loss: 0.909823]\n",
      "epoch:1 step:1240 [D loss: 0.728068, acc.: 50.78%] [G loss: 0.988523]\n",
      "epoch:1 step:1241 [D loss: 0.783538, acc.: 46.88%] [G loss: 0.884958]\n",
      "epoch:1 step:1242 [D loss: 0.706290, acc.: 56.25%] [G loss: 0.970632]\n",
      "epoch:1 step:1243 [D loss: 0.685630, acc.: 52.34%] [G loss: 0.818400]\n",
      "epoch:1 step:1244 [D loss: 0.775468, acc.: 48.44%] [G loss: 0.822593]\n",
      "epoch:1 step:1245 [D loss: 0.732552, acc.: 46.09%] [G loss: 0.908044]\n",
      "epoch:1 step:1246 [D loss: 0.700372, acc.: 53.12%] [G loss: 0.819357]\n",
      "epoch:1 step:1247 [D loss: 0.676018, acc.: 60.16%] [G loss: 0.929525]\n",
      "epoch:1 step:1248 [D loss: 0.633959, acc.: 65.62%] [G loss: 0.985978]\n",
      "epoch:1 step:1249 [D loss: 0.638135, acc.: 63.28%] [G loss: 1.112061]\n",
      "epoch:1 step:1250 [D loss: 0.657934, acc.: 58.59%] [G loss: 1.004425]\n",
      "epoch:1 step:1251 [D loss: 0.643892, acc.: 60.16%] [G loss: 1.134052]\n",
      "epoch:1 step:1252 [D loss: 0.632719, acc.: 64.84%] [G loss: 1.239340]\n",
      "epoch:1 step:1253 [D loss: 0.771842, acc.: 50.78%] [G loss: 0.945609]\n",
      "epoch:1 step:1254 [D loss: 0.750664, acc.: 51.56%] [G loss: 0.991680]\n",
      "epoch:1 step:1255 [D loss: 0.692770, acc.: 52.34%] [G loss: 0.908264]\n",
      "epoch:1 step:1256 [D loss: 0.785959, acc.: 46.88%] [G loss: 1.266202]\n",
      "epoch:1 step:1257 [D loss: 0.739823, acc.: 47.66%] [G loss: 0.968404]\n",
      "epoch:1 step:1258 [D loss: 0.752984, acc.: 52.34%] [G loss: 0.951375]\n",
      "epoch:1 step:1259 [D loss: 0.608886, acc.: 68.75%] [G loss: 0.922564]\n",
      "epoch:1 step:1260 [D loss: 0.645532, acc.: 60.94%] [G loss: 0.945897]\n",
      "epoch:1 step:1261 [D loss: 0.612252, acc.: 67.97%] [G loss: 0.896573]\n",
      "epoch:1 step:1262 [D loss: 0.623355, acc.: 70.31%] [G loss: 1.030035]\n",
      "epoch:1 step:1263 [D loss: 0.708967, acc.: 56.25%] [G loss: 0.849096]\n",
      "epoch:1 step:1264 [D loss: 0.571852, acc.: 71.88%] [G loss: 0.943999]\n",
      "epoch:1 step:1265 [D loss: 0.586814, acc.: 70.31%] [G loss: 0.874148]\n",
      "epoch:1 step:1266 [D loss: 0.636356, acc.: 65.62%] [G loss: 0.854101]\n",
      "epoch:1 step:1267 [D loss: 0.634040, acc.: 66.41%] [G loss: 0.660378]\n",
      "epoch:1 step:1268 [D loss: 0.593985, acc.: 66.41%] [G loss: 0.937063]\n",
      "epoch:1 step:1269 [D loss: 0.758507, acc.: 51.56%] [G loss: 0.879848]\n",
      "epoch:1 step:1270 [D loss: 0.753882, acc.: 49.22%] [G loss: 1.045742]\n",
      "epoch:1 step:1271 [D loss: 0.663090, acc.: 64.84%] [G loss: 1.129103]\n",
      "epoch:1 step:1272 [D loss: 0.721914, acc.: 57.03%] [G loss: 1.063721]\n",
      "epoch:1 step:1273 [D loss: 0.650190, acc.: 62.50%] [G loss: 0.888354]\n",
      "epoch:1 step:1274 [D loss: 0.722510, acc.: 48.44%] [G loss: 0.914686]\n",
      "epoch:1 step:1275 [D loss: 0.713368, acc.: 57.81%] [G loss: 1.041940]\n",
      "epoch:1 step:1276 [D loss: 0.693391, acc.: 56.25%] [G loss: 0.909419]\n",
      "epoch:1 step:1277 [D loss: 0.729727, acc.: 46.88%] [G loss: 1.039549]\n",
      "epoch:1 step:1278 [D loss: 0.688680, acc.: 62.50%] [G loss: 0.864412]\n",
      "epoch:1 step:1279 [D loss: 0.636211, acc.: 64.06%] [G loss: 1.041932]\n",
      "epoch:1 step:1280 [D loss: 0.559579, acc.: 77.34%] [G loss: 1.247228]\n",
      "epoch:1 step:1281 [D loss: 0.558756, acc.: 71.09%] [G loss: 1.078583]\n",
      "epoch:1 step:1282 [D loss: 0.633667, acc.: 60.94%] [G loss: 1.125061]\n",
      "epoch:1 step:1283 [D loss: 0.563111, acc.: 71.09%] [G loss: 1.163489]\n",
      "epoch:1 step:1284 [D loss: 0.569446, acc.: 68.75%] [G loss: 1.164224]\n",
      "epoch:1 step:1285 [D loss: 0.873828, acc.: 45.31%] [G loss: 0.890018]\n",
      "epoch:1 step:1286 [D loss: 0.806782, acc.: 40.62%] [G loss: 0.856265]\n",
      "epoch:1 step:1287 [D loss: 0.793508, acc.: 42.19%] [G loss: 0.906045]\n",
      "epoch:1 step:1288 [D loss: 0.718865, acc.: 53.91%] [G loss: 0.849601]\n",
      "epoch:1 step:1289 [D loss: 0.716125, acc.: 50.78%] [G loss: 0.964103]\n",
      "epoch:1 step:1290 [D loss: 0.693329, acc.: 52.34%] [G loss: 0.911703]\n",
      "epoch:1 step:1291 [D loss: 0.656865, acc.: 57.03%] [G loss: 1.024178]\n",
      "epoch:1 step:1292 [D loss: 0.693352, acc.: 54.69%] [G loss: 0.912116]\n",
      "epoch:1 step:1293 [D loss: 0.736526, acc.: 55.47%] [G loss: 1.047436]\n",
      "epoch:1 step:1294 [D loss: 0.628209, acc.: 69.53%] [G loss: 0.986257]\n",
      "epoch:1 step:1295 [D loss: 0.644515, acc.: 63.28%] [G loss: 0.937221]\n",
      "epoch:1 step:1296 [D loss: 0.639101, acc.: 64.84%] [G loss: 1.041180]\n",
      "epoch:1 step:1297 [D loss: 0.645683, acc.: 57.81%] [G loss: 1.019114]\n",
      "epoch:1 step:1298 [D loss: 0.652033, acc.: 58.59%] [G loss: 1.058559]\n",
      "epoch:1 step:1299 [D loss: 0.667822, acc.: 57.03%] [G loss: 0.949988]\n",
      "epoch:1 step:1300 [D loss: 0.709198, acc.: 55.47%] [G loss: 0.881910]\n",
      "epoch:1 step:1301 [D loss: 0.598245, acc.: 67.19%] [G loss: 0.973242]\n",
      "epoch:1 step:1302 [D loss: 0.665593, acc.: 59.38%] [G loss: 1.017883]\n",
      "epoch:1 step:1303 [D loss: 0.697946, acc.: 57.81%] [G loss: 0.883875]\n",
      "epoch:1 step:1304 [D loss: 0.690017, acc.: 56.25%] [G loss: 0.877925]\n",
      "epoch:1 step:1305 [D loss: 0.791765, acc.: 52.34%] [G loss: 0.836057]\n",
      "epoch:1 step:1306 [D loss: 0.732187, acc.: 57.81%] [G loss: 0.846053]\n",
      "epoch:1 step:1307 [D loss: 0.745019, acc.: 46.09%] [G loss: 0.816348]\n",
      "epoch:1 step:1308 [D loss: 0.703077, acc.: 53.12%] [G loss: 0.882268]\n",
      "epoch:1 step:1309 [D loss: 0.711090, acc.: 53.91%] [G loss: 0.906840]\n",
      "epoch:1 step:1310 [D loss: 0.696633, acc.: 51.56%] [G loss: 0.958578]\n",
      "epoch:1 step:1311 [D loss: 0.649987, acc.: 68.75%] [G loss: 1.021329]\n",
      "epoch:1 step:1312 [D loss: 0.676146, acc.: 60.94%] [G loss: 0.990210]\n",
      "epoch:1 step:1313 [D loss: 0.687055, acc.: 56.25%] [G loss: 0.957949]\n",
      "epoch:1 step:1314 [D loss: 0.723909, acc.: 54.69%] [G loss: 1.044336]\n",
      "epoch:1 step:1315 [D loss: 0.649735, acc.: 61.72%] [G loss: 0.958050]\n",
      "epoch:1 step:1316 [D loss: 0.669005, acc.: 59.38%] [G loss: 0.941940]\n",
      "epoch:1 step:1317 [D loss: 0.710961, acc.: 51.56%] [G loss: 0.868467]\n",
      "epoch:1 step:1318 [D loss: 0.714286, acc.: 47.66%] [G loss: 0.877522]\n",
      "epoch:1 step:1319 [D loss: 0.710579, acc.: 54.69%] [G loss: 0.916452]\n",
      "epoch:1 step:1320 [D loss: 0.735461, acc.: 46.88%] [G loss: 0.954874]\n",
      "epoch:1 step:1321 [D loss: 0.653522, acc.: 58.59%] [G loss: 0.923407]\n",
      "epoch:1 step:1322 [D loss: 0.704789, acc.: 55.47%] [G loss: 0.960299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1323 [D loss: 0.774354, acc.: 43.75%] [G loss: 1.065715]\n",
      "epoch:1 step:1324 [D loss: 0.648678, acc.: 65.62%] [G loss: 0.982953]\n",
      "epoch:1 step:1325 [D loss: 0.659675, acc.: 62.50%] [G loss: 0.983764]\n",
      "epoch:1 step:1326 [D loss: 0.739831, acc.: 53.91%] [G loss: 0.970143]\n",
      "epoch:1 step:1327 [D loss: 0.776464, acc.: 53.12%] [G loss: 1.036978]\n",
      "epoch:1 step:1328 [D loss: 0.706583, acc.: 52.34%] [G loss: 0.960191]\n",
      "epoch:1 step:1329 [D loss: 0.705292, acc.: 55.47%] [G loss: 0.939260]\n",
      "epoch:1 step:1330 [D loss: 0.724076, acc.: 53.91%] [G loss: 0.932397]\n",
      "epoch:1 step:1331 [D loss: 0.737699, acc.: 49.22%] [G loss: 0.903639]\n",
      "epoch:1 step:1332 [D loss: 0.725634, acc.: 49.22%] [G loss: 0.869714]\n",
      "epoch:1 step:1333 [D loss: 0.759517, acc.: 46.09%] [G loss: 0.867683]\n",
      "epoch:1 step:1334 [D loss: 0.758350, acc.: 39.84%] [G loss: 0.883092]\n",
      "epoch:1 step:1335 [D loss: 0.657130, acc.: 64.06%] [G loss: 1.015864]\n",
      "epoch:1 step:1336 [D loss: 0.649848, acc.: 60.94%] [G loss: 1.024685]\n",
      "epoch:1 step:1337 [D loss: 0.678259, acc.: 60.16%] [G loss: 0.946048]\n",
      "epoch:1 step:1338 [D loss: 0.720292, acc.: 44.53%] [G loss: 0.953018]\n",
      "epoch:1 step:1339 [D loss: 0.601829, acc.: 65.62%] [G loss: 0.932298]\n",
      "epoch:1 step:1340 [D loss: 0.654722, acc.: 59.38%] [G loss: 1.151144]\n",
      "epoch:1 step:1341 [D loss: 0.655559, acc.: 59.38%] [G loss: 1.075262]\n",
      "epoch:1 step:1342 [D loss: 0.678287, acc.: 54.69%] [G loss: 0.905937]\n",
      "epoch:1 step:1343 [D loss: 0.595139, acc.: 74.22%] [G loss: 0.926591]\n",
      "epoch:1 step:1344 [D loss: 0.593109, acc.: 69.53%] [G loss: 0.962542]\n",
      "epoch:1 step:1345 [D loss: 0.619718, acc.: 65.62%] [G loss: 0.863766]\n",
      "epoch:1 step:1346 [D loss: 0.620769, acc.: 64.06%] [G loss: 1.017868]\n",
      "epoch:1 step:1347 [D loss: 0.705703, acc.: 58.59%] [G loss: 0.980386]\n",
      "epoch:1 step:1348 [D loss: 0.796155, acc.: 46.88%] [G loss: 0.899444]\n",
      "epoch:1 step:1349 [D loss: 0.731714, acc.: 50.00%] [G loss: 0.894416]\n",
      "epoch:1 step:1350 [D loss: 0.747560, acc.: 46.09%] [G loss: 0.923897]\n",
      "epoch:1 step:1351 [D loss: 0.620963, acc.: 64.84%] [G loss: 0.838042]\n",
      "epoch:1 step:1352 [D loss: 0.599771, acc.: 66.41%] [G loss: 0.872764]\n",
      "epoch:1 step:1353 [D loss: 0.665305, acc.: 60.16%] [G loss: 0.902470]\n",
      "epoch:1 step:1354 [D loss: 0.719381, acc.: 56.25%] [G loss: 1.004887]\n",
      "epoch:1 step:1355 [D loss: 0.710158, acc.: 52.34%] [G loss: 0.969954]\n",
      "epoch:1 step:1356 [D loss: 0.701075, acc.: 53.12%] [G loss: 1.020100]\n",
      "epoch:1 step:1357 [D loss: 0.655938, acc.: 60.16%] [G loss: 0.887937]\n",
      "epoch:1 step:1358 [D loss: 0.687062, acc.: 55.47%] [G loss: 0.920168]\n",
      "epoch:1 step:1359 [D loss: 0.724041, acc.: 51.56%] [G loss: 0.980071]\n",
      "epoch:1 step:1360 [D loss: 0.643951, acc.: 62.50%] [G loss: 1.073507]\n",
      "epoch:1 step:1361 [D loss: 0.732526, acc.: 48.44%] [G loss: 1.035539]\n",
      "epoch:1 step:1362 [D loss: 0.637325, acc.: 61.72%] [G loss: 0.967284]\n",
      "epoch:1 step:1363 [D loss: 0.614342, acc.: 64.84%] [G loss: 0.962710]\n",
      "epoch:1 step:1364 [D loss: 0.667185, acc.: 59.38%] [G loss: 0.994763]\n",
      "epoch:1 step:1365 [D loss: 0.629555, acc.: 59.38%] [G loss: 0.994523]\n",
      "epoch:1 step:1366 [D loss: 0.646475, acc.: 65.62%] [G loss: 0.950751]\n",
      "epoch:1 step:1367 [D loss: 0.667419, acc.: 57.03%] [G loss: 1.046967]\n",
      "epoch:1 step:1368 [D loss: 0.732969, acc.: 57.03%] [G loss: 0.904233]\n",
      "epoch:1 step:1369 [D loss: 0.743007, acc.: 48.44%] [G loss: 0.864152]\n",
      "epoch:1 step:1370 [D loss: 0.755694, acc.: 42.97%] [G loss: 0.900641]\n",
      "epoch:1 step:1371 [D loss: 0.744464, acc.: 53.91%] [G loss: 0.898584]\n",
      "epoch:1 step:1372 [D loss: 0.626056, acc.: 62.50%] [G loss: 0.964615]\n",
      "epoch:1 step:1373 [D loss: 0.587238, acc.: 65.62%] [G loss: 0.977241]\n",
      "epoch:1 step:1374 [D loss: 0.664457, acc.: 60.94%] [G loss: 0.894544]\n",
      "epoch:1 step:1375 [D loss: 0.673304, acc.: 60.16%] [G loss: 0.823891]\n",
      "epoch:1 step:1376 [D loss: 0.692557, acc.: 61.72%] [G loss: 0.855761]\n",
      "epoch:1 step:1377 [D loss: 0.660670, acc.: 62.50%] [G loss: 0.946616]\n",
      "epoch:1 step:1378 [D loss: 0.667434, acc.: 57.03%] [G loss: 0.819929]\n",
      "epoch:1 step:1379 [D loss: 0.637456, acc.: 64.06%] [G loss: 0.882690]\n",
      "epoch:1 step:1380 [D loss: 0.597690, acc.: 67.19%] [G loss: 0.911727]\n",
      "epoch:1 step:1381 [D loss: 0.634489, acc.: 67.19%] [G loss: 0.804857]\n",
      "epoch:1 step:1382 [D loss: 0.718698, acc.: 54.69%] [G loss: 0.843281]\n",
      "epoch:1 step:1383 [D loss: 0.631839, acc.: 63.28%] [G loss: 0.992385]\n",
      "epoch:1 step:1384 [D loss: 0.702215, acc.: 54.69%] [G loss: 1.015129]\n",
      "epoch:1 step:1385 [D loss: 0.668737, acc.: 62.50%] [G loss: 1.050964]\n",
      "epoch:1 step:1386 [D loss: 0.664279, acc.: 61.72%] [G loss: 1.057544]\n",
      "epoch:1 step:1387 [D loss: 0.631691, acc.: 67.97%] [G loss: 1.001239]\n",
      "epoch:1 step:1388 [D loss: 0.663483, acc.: 58.59%] [G loss: 0.850099]\n",
      "epoch:1 step:1389 [D loss: 0.625497, acc.: 66.41%] [G loss: 1.096920]\n",
      "epoch:1 step:1390 [D loss: 0.732959, acc.: 55.47%] [G loss: 0.977837]\n",
      "epoch:1 step:1391 [D loss: 0.684878, acc.: 56.25%] [G loss: 0.936814]\n",
      "epoch:1 step:1392 [D loss: 0.731606, acc.: 55.47%] [G loss: 0.996405]\n",
      "epoch:1 step:1393 [D loss: 0.678893, acc.: 60.16%] [G loss: 0.908163]\n",
      "epoch:1 step:1394 [D loss: 0.680097, acc.: 62.50%] [G loss: 0.916975]\n",
      "epoch:1 step:1395 [D loss: 0.667266, acc.: 59.38%] [G loss: 0.925744]\n",
      "epoch:1 step:1396 [D loss: 0.567266, acc.: 71.88%] [G loss: 1.104595]\n",
      "epoch:1 step:1397 [D loss: 0.592551, acc.: 68.75%] [G loss: 0.888562]\n",
      "epoch:1 step:1398 [D loss: 0.723010, acc.: 56.25%] [G loss: 0.960571]\n",
      "epoch:1 step:1399 [D loss: 0.730915, acc.: 51.56%] [G loss: 1.033366]\n",
      "epoch:1 step:1400 [D loss: 0.709882, acc.: 58.59%] [G loss: 1.118930]\n",
      "epoch:1 step:1401 [D loss: 0.727326, acc.: 52.34%] [G loss: 0.946279]\n",
      "epoch:1 step:1402 [D loss: 0.824139, acc.: 43.75%] [G loss: 0.914738]\n",
      "epoch:1 step:1403 [D loss: 0.697176, acc.: 53.91%] [G loss: 0.991327]\n",
      "epoch:1 step:1404 [D loss: 0.738055, acc.: 52.34%] [G loss: 1.112195]\n",
      "epoch:1 step:1405 [D loss: 0.719649, acc.: 60.16%] [G loss: 1.008336]\n",
      "epoch:1 step:1406 [D loss: 0.608359, acc.: 70.31%] [G loss: 1.205792]\n",
      "epoch:1 step:1407 [D loss: 0.696943, acc.: 58.59%] [G loss: 1.011733]\n",
      "epoch:1 step:1408 [D loss: 0.684922, acc.: 57.81%] [G loss: 1.155173]\n",
      "epoch:1 step:1409 [D loss: 0.735702, acc.: 53.12%] [G loss: 1.022217]\n",
      "epoch:1 step:1410 [D loss: 0.709557, acc.: 50.78%] [G loss: 0.971093]\n",
      "epoch:1 step:1411 [D loss: 0.691962, acc.: 57.03%] [G loss: 0.892818]\n",
      "epoch:1 step:1412 [D loss: 0.713570, acc.: 55.47%] [G loss: 0.925172]\n",
      "epoch:1 step:1413 [D loss: 0.654445, acc.: 69.53%] [G loss: 1.047080]\n",
      "epoch:1 step:1414 [D loss: 0.718989, acc.: 55.47%] [G loss: 1.005810]\n",
      "epoch:1 step:1415 [D loss: 0.675811, acc.: 63.28%] [G loss: 1.175816]\n",
      "epoch:1 step:1416 [D loss: 0.690848, acc.: 53.12%] [G loss: 1.213758]\n",
      "epoch:1 step:1417 [D loss: 0.771885, acc.: 43.75%] [G loss: 0.965966]\n",
      "epoch:1 step:1418 [D loss: 0.734068, acc.: 48.44%] [G loss: 0.876387]\n",
      "epoch:1 step:1419 [D loss: 0.731354, acc.: 50.00%] [G loss: 0.925865]\n",
      "epoch:1 step:1420 [D loss: 0.618487, acc.: 67.19%] [G loss: 0.944431]\n",
      "epoch:1 step:1421 [D loss: 0.669757, acc.: 58.59%] [G loss: 0.912864]\n",
      "epoch:1 step:1422 [D loss: 0.681848, acc.: 57.81%] [G loss: 0.939400]\n",
      "epoch:1 step:1423 [D loss: 0.718061, acc.: 48.44%] [G loss: 0.877745]\n",
      "epoch:1 step:1424 [D loss: 0.723270, acc.: 54.69%] [G loss: 0.821853]\n",
      "epoch:1 step:1425 [D loss: 0.718562, acc.: 50.78%] [G loss: 0.908329]\n",
      "epoch:1 step:1426 [D loss: 0.680410, acc.: 51.56%] [G loss: 0.886146]\n",
      "epoch:1 step:1427 [D loss: 0.680246, acc.: 59.38%] [G loss: 0.839215]\n",
      "epoch:1 step:1428 [D loss: 0.691286, acc.: 55.47%] [G loss: 0.859045]\n",
      "epoch:1 step:1429 [D loss: 0.685876, acc.: 57.03%] [G loss: 0.877168]\n",
      "epoch:1 step:1430 [D loss: 0.725777, acc.: 53.12%] [G loss: 0.889440]\n",
      "epoch:1 step:1431 [D loss: 0.691890, acc.: 55.47%] [G loss: 0.830758]\n",
      "epoch:1 step:1432 [D loss: 0.696855, acc.: 55.47%] [G loss: 0.857570]\n",
      "epoch:1 step:1433 [D loss: 0.662649, acc.: 59.38%] [G loss: 0.895556]\n",
      "epoch:1 step:1434 [D loss: 0.738804, acc.: 49.22%] [G loss: 0.831220]\n",
      "epoch:1 step:1435 [D loss: 0.742135, acc.: 44.53%] [G loss: 0.913438]\n",
      "epoch:1 step:1436 [D loss: 0.657217, acc.: 62.50%] [G loss: 0.949648]\n",
      "epoch:1 step:1437 [D loss: 0.733616, acc.: 47.66%] [G loss: 0.850769]\n",
      "epoch:1 step:1438 [D loss: 0.758121, acc.: 50.00%] [G loss: 0.924804]\n",
      "epoch:1 step:1439 [D loss: 0.663085, acc.: 60.16%] [G loss: 0.879172]\n",
      "epoch:1 step:1440 [D loss: 0.661690, acc.: 57.81%] [G loss: 0.927628]\n",
      "epoch:1 step:1441 [D loss: 0.619620, acc.: 65.62%] [G loss: 0.930633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1442 [D loss: 0.588426, acc.: 67.19%] [G loss: 0.901660]\n",
      "epoch:1 step:1443 [D loss: 0.604407, acc.: 70.31%] [G loss: 1.007752]\n",
      "epoch:1 step:1444 [D loss: 0.618633, acc.: 68.75%] [G loss: 0.933759]\n",
      "epoch:1 step:1445 [D loss: 0.558258, acc.: 75.00%] [G loss: 0.959189]\n",
      "epoch:1 step:1446 [D loss: 0.744044, acc.: 47.66%] [G loss: 0.875231]\n",
      "epoch:1 step:1447 [D loss: 0.728741, acc.: 50.78%] [G loss: 0.884856]\n",
      "epoch:1 step:1448 [D loss: 0.775833, acc.: 39.06%] [G loss: 0.938859]\n",
      "epoch:1 step:1449 [D loss: 0.746370, acc.: 56.25%] [G loss: 0.841207]\n",
      "epoch:1 step:1450 [D loss: 0.704369, acc.: 56.25%] [G loss: 0.839843]\n",
      "epoch:1 step:1451 [D loss: 0.658680, acc.: 60.94%] [G loss: 0.881286]\n",
      "epoch:1 step:1452 [D loss: 0.638098, acc.: 60.94%] [G loss: 0.855625]\n",
      "epoch:1 step:1453 [D loss: 0.665304, acc.: 61.72%] [G loss: 0.921210]\n",
      "epoch:1 step:1454 [D loss: 0.726411, acc.: 52.34%] [G loss: 0.872728]\n",
      "epoch:1 step:1455 [D loss: 0.660463, acc.: 57.81%] [G loss: 0.777547]\n",
      "epoch:1 step:1456 [D loss: 0.713091, acc.: 52.34%] [G loss: 0.806543]\n",
      "epoch:1 step:1457 [D loss: 0.633072, acc.: 65.62%] [G loss: 0.838391]\n",
      "epoch:1 step:1458 [D loss: 0.661408, acc.: 62.50%] [G loss: 0.816563]\n",
      "epoch:1 step:1459 [D loss: 0.665741, acc.: 58.59%] [G loss: 0.913736]\n",
      "epoch:1 step:1460 [D loss: 0.692598, acc.: 57.81%] [G loss: 0.883814]\n",
      "epoch:1 step:1461 [D loss: 0.639883, acc.: 63.28%] [G loss: 0.812487]\n",
      "epoch:1 step:1462 [D loss: 0.757504, acc.: 39.84%] [G loss: 0.863212]\n",
      "epoch:1 step:1463 [D loss: 0.698412, acc.: 57.03%] [G loss: 0.926582]\n",
      "epoch:1 step:1464 [D loss: 0.692501, acc.: 54.69%] [G loss: 0.937205]\n",
      "epoch:1 step:1465 [D loss: 0.719183, acc.: 52.34%] [G loss: 0.961206]\n",
      "epoch:1 step:1466 [D loss: 0.684105, acc.: 55.47%] [G loss: 0.852270]\n",
      "epoch:1 step:1467 [D loss: 0.616779, acc.: 71.88%] [G loss: 0.799609]\n",
      "epoch:1 step:1468 [D loss: 0.664268, acc.: 57.81%] [G loss: 0.926212]\n",
      "epoch:1 step:1469 [D loss: 0.686314, acc.: 56.25%] [G loss: 0.958328]\n",
      "epoch:1 step:1470 [D loss: 0.686598, acc.: 54.69%] [G loss: 0.928559]\n",
      "epoch:1 step:1471 [D loss: 0.650412, acc.: 65.62%] [G loss: 0.915565]\n",
      "epoch:1 step:1472 [D loss: 0.733550, acc.: 50.78%] [G loss: 0.924417]\n",
      "epoch:1 step:1473 [D loss: 0.676151, acc.: 63.28%] [G loss: 0.835287]\n",
      "epoch:1 step:1474 [D loss: 0.660962, acc.: 57.03%] [G loss: 0.858674]\n",
      "epoch:1 step:1475 [D loss: 0.689963, acc.: 54.69%] [G loss: 0.899166]\n",
      "epoch:1 step:1476 [D loss: 0.782347, acc.: 39.84%] [G loss: 0.885885]\n",
      "epoch:1 step:1477 [D loss: 0.696921, acc.: 55.47%] [G loss: 0.895414]\n",
      "epoch:1 step:1478 [D loss: 0.700638, acc.: 57.81%] [G loss: 0.986870]\n",
      "epoch:1 step:1479 [D loss: 0.789410, acc.: 39.06%] [G loss: 0.956616]\n",
      "epoch:1 step:1480 [D loss: 0.677214, acc.: 59.38%] [G loss: 0.948957]\n",
      "epoch:1 step:1481 [D loss: 0.700526, acc.: 57.81%] [G loss: 0.916202]\n",
      "epoch:1 step:1482 [D loss: 0.600752, acc.: 63.28%] [G loss: 0.828279]\n",
      "epoch:1 step:1483 [D loss: 0.612439, acc.: 64.84%] [G loss: 0.836002]\n",
      "epoch:1 step:1484 [D loss: 0.696375, acc.: 51.56%] [G loss: 0.965733]\n",
      "epoch:1 step:1485 [D loss: 0.652242, acc.: 61.72%] [G loss: 0.919845]\n",
      "epoch:1 step:1486 [D loss: 0.649455, acc.: 59.38%] [G loss: 0.908794]\n",
      "epoch:1 step:1487 [D loss: 0.591268, acc.: 68.75%] [G loss: 0.990763]\n",
      "epoch:1 step:1488 [D loss: 0.642160, acc.: 65.62%] [G loss: 0.988234]\n",
      "epoch:1 step:1489 [D loss: 0.638451, acc.: 68.75%] [G loss: 1.095414]\n",
      "epoch:1 step:1490 [D loss: 0.673487, acc.: 58.59%] [G loss: 0.912371]\n",
      "epoch:1 step:1491 [D loss: 0.562413, acc.: 72.66%] [G loss: 0.863549]\n",
      "epoch:1 step:1492 [D loss: 0.631403, acc.: 57.81%] [G loss: 0.944124]\n",
      "epoch:1 step:1493 [D loss: 0.601557, acc.: 67.19%] [G loss: 0.832090]\n",
      "epoch:1 step:1494 [D loss: 0.661891, acc.: 62.50%] [G loss: 0.930361]\n",
      "epoch:1 step:1495 [D loss: 0.657533, acc.: 60.94%] [G loss: 0.922094]\n",
      "epoch:1 step:1496 [D loss: 0.835008, acc.: 35.94%] [G loss: 0.904860]\n",
      "epoch:1 step:1497 [D loss: 0.719354, acc.: 51.56%] [G loss: 0.850620]\n",
      "epoch:1 step:1498 [D loss: 0.688418, acc.: 55.47%] [G loss: 0.830800]\n",
      "epoch:1 step:1499 [D loss: 0.829424, acc.: 37.50%] [G loss: 0.893912]\n",
      "epoch:1 step:1500 [D loss: 0.731125, acc.: 49.22%] [G loss: 0.876165]\n",
      "epoch:1 step:1501 [D loss: 0.695542, acc.: 55.47%] [G loss: 0.997467]\n",
      "epoch:1 step:1502 [D loss: 0.690949, acc.: 52.34%] [G loss: 0.906291]\n",
      "epoch:1 step:1503 [D loss: 0.723205, acc.: 52.34%] [G loss: 0.887494]\n",
      "epoch:1 step:1504 [D loss: 0.669279, acc.: 53.91%] [G loss: 0.896598]\n",
      "epoch:1 step:1505 [D loss: 0.704099, acc.: 46.09%] [G loss: 0.944404]\n",
      "epoch:1 step:1506 [D loss: 0.769333, acc.: 44.53%] [G loss: 0.962074]\n",
      "epoch:1 step:1507 [D loss: 0.687027, acc.: 53.12%] [G loss: 1.069316]\n",
      "epoch:1 step:1508 [D loss: 0.724508, acc.: 53.12%] [G loss: 0.891559]\n",
      "epoch:1 step:1509 [D loss: 0.703047, acc.: 56.25%] [G loss: 0.875762]\n",
      "epoch:1 step:1510 [D loss: 0.665565, acc.: 58.59%] [G loss: 0.937119]\n",
      "epoch:1 step:1511 [D loss: 0.636900, acc.: 60.94%] [G loss: 0.914410]\n",
      "epoch:1 step:1512 [D loss: 0.628547, acc.: 66.41%] [G loss: 0.898000]\n",
      "epoch:1 step:1513 [D loss: 0.757460, acc.: 40.62%] [G loss: 0.807532]\n",
      "epoch:1 step:1514 [D loss: 0.721829, acc.: 47.66%] [G loss: 0.844446]\n",
      "epoch:1 step:1515 [D loss: 0.636368, acc.: 60.94%] [G loss: 0.914566]\n",
      "epoch:1 step:1516 [D loss: 0.635246, acc.: 63.28%] [G loss: 0.996179]\n",
      "epoch:1 step:1517 [D loss: 0.671916, acc.: 57.03%] [G loss: 0.980305]\n",
      "epoch:1 step:1518 [D loss: 0.640049, acc.: 62.50%] [G loss: 0.948570]\n",
      "epoch:1 step:1519 [D loss: 0.684403, acc.: 56.25%] [G loss: 0.969168]\n",
      "epoch:1 step:1520 [D loss: 0.693978, acc.: 57.03%] [G loss: 0.919559]\n",
      "epoch:1 step:1521 [D loss: 0.778518, acc.: 51.56%] [G loss: 0.921250]\n",
      "epoch:1 step:1522 [D loss: 0.635494, acc.: 67.19%] [G loss: 0.882602]\n",
      "epoch:1 step:1523 [D loss: 0.658121, acc.: 60.16%] [G loss: 0.856404]\n",
      "epoch:1 step:1524 [D loss: 0.690935, acc.: 59.38%] [G loss: 0.832252]\n",
      "epoch:1 step:1525 [D loss: 0.692255, acc.: 57.03%] [G loss: 0.846754]\n",
      "epoch:1 step:1526 [D loss: 0.661604, acc.: 64.06%] [G loss: 0.900152]\n",
      "epoch:1 step:1527 [D loss: 0.709283, acc.: 53.91%] [G loss: 0.893021]\n",
      "epoch:1 step:1528 [D loss: 0.719068, acc.: 54.69%] [G loss: 0.863135]\n",
      "epoch:1 step:1529 [D loss: 0.677487, acc.: 60.94%] [G loss: 0.863175]\n",
      "epoch:1 step:1530 [D loss: 0.710039, acc.: 50.00%] [G loss: 0.872264]\n",
      "epoch:1 step:1531 [D loss: 0.699164, acc.: 59.38%] [G loss: 0.898307]\n",
      "epoch:1 step:1532 [D loss: 0.642603, acc.: 64.84%] [G loss: 0.976282]\n",
      "epoch:1 step:1533 [D loss: 0.656278, acc.: 62.50%] [G loss: 0.935500]\n",
      "epoch:1 step:1534 [D loss: 0.745000, acc.: 49.22%] [G loss: 0.870906]\n",
      "epoch:1 step:1535 [D loss: 0.624981, acc.: 65.62%] [G loss: 0.827249]\n",
      "epoch:1 step:1536 [D loss: 0.685753, acc.: 57.03%] [G loss: 0.901631]\n",
      "epoch:1 step:1537 [D loss: 0.799457, acc.: 43.75%] [G loss: 1.046870]\n",
      "epoch:1 step:1538 [D loss: 0.697480, acc.: 57.03%] [G loss: 0.905640]\n",
      "epoch:1 step:1539 [D loss: 0.658552, acc.: 58.59%] [G loss: 0.949736]\n",
      "epoch:1 step:1540 [D loss: 0.656577, acc.: 61.72%] [G loss: 1.139144]\n",
      "epoch:1 step:1541 [D loss: 0.884826, acc.: 41.41%] [G loss: 0.887300]\n",
      "epoch:1 step:1542 [D loss: 0.715612, acc.: 50.78%] [G loss: 0.844103]\n",
      "epoch:1 step:1543 [D loss: 0.642308, acc.: 62.50%] [G loss: 0.916119]\n",
      "epoch:1 step:1544 [D loss: 0.646275, acc.: 60.94%] [G loss: 0.855062]\n",
      "epoch:1 step:1545 [D loss: 0.693758, acc.: 54.69%] [G loss: 0.867458]\n",
      "epoch:1 step:1546 [D loss: 0.747778, acc.: 50.78%] [G loss: 0.827574]\n",
      "epoch:1 step:1547 [D loss: 0.692977, acc.: 54.69%] [G loss: 0.804077]\n",
      "epoch:1 step:1548 [D loss: 0.675280, acc.: 57.81%] [G loss: 0.736033]\n",
      "epoch:1 step:1549 [D loss: 0.711417, acc.: 50.78%] [G loss: 0.809913]\n",
      "epoch:1 step:1550 [D loss: 0.710707, acc.: 55.47%] [G loss: 0.772332]\n",
      "epoch:1 step:1551 [D loss: 0.787334, acc.: 39.84%] [G loss: 0.763062]\n",
      "epoch:1 step:1552 [D loss: 0.714623, acc.: 52.34%] [G loss: 0.810031]\n",
      "epoch:1 step:1553 [D loss: 0.701057, acc.: 54.69%] [G loss: 0.808275]\n",
      "epoch:1 step:1554 [D loss: 0.652499, acc.: 64.06%] [G loss: 0.886380]\n",
      "epoch:1 step:1555 [D loss: 0.665549, acc.: 63.28%] [G loss: 0.935740]\n",
      "epoch:1 step:1556 [D loss: 0.720879, acc.: 53.12%] [G loss: 0.883016]\n",
      "epoch:1 step:1557 [D loss: 0.666431, acc.: 60.94%] [G loss: 0.960978]\n",
      "epoch:1 step:1558 [D loss: 0.678668, acc.: 57.03%] [G loss: 0.942702]\n",
      "epoch:1 step:1559 [D loss: 0.731685, acc.: 49.22%] [G loss: 0.887386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1560 [D loss: 0.791797, acc.: 39.84%] [G loss: 0.883192]\n",
      "epoch:1 step:1561 [D loss: 0.656229, acc.: 57.03%] [G loss: 0.808549]\n",
      "epoch:1 step:1562 [D loss: 0.700256, acc.: 53.12%] [G loss: 0.868106]\n",
      "epoch:1 step:1563 [D loss: 0.701105, acc.: 53.91%] [G loss: 0.832214]\n",
      "epoch:1 step:1564 [D loss: 0.677978, acc.: 57.03%] [G loss: 0.805555]\n",
      "epoch:1 step:1565 [D loss: 0.710700, acc.: 54.69%] [G loss: 0.869718]\n",
      "epoch:1 step:1566 [D loss: 0.690707, acc.: 57.03%] [G loss: 0.756052]\n",
      "epoch:1 step:1567 [D loss: 0.699133, acc.: 55.47%] [G loss: 0.869564]\n",
      "epoch:1 step:1568 [D loss: 0.688945, acc.: 59.38%] [G loss: 0.860737]\n",
      "epoch:1 step:1569 [D loss: 0.663876, acc.: 57.03%] [G loss: 0.822788]\n",
      "epoch:1 step:1570 [D loss: 0.654072, acc.: 66.41%] [G loss: 0.812402]\n",
      "epoch:1 step:1571 [D loss: 0.683373, acc.: 53.91%] [G loss: 0.850512]\n",
      "epoch:1 step:1572 [D loss: 0.657029, acc.: 59.38%] [G loss: 0.871000]\n",
      "epoch:1 step:1573 [D loss: 0.716490, acc.: 50.78%] [G loss: 0.893148]\n",
      "epoch:1 step:1574 [D loss: 0.624491, acc.: 67.19%] [G loss: 0.864349]\n",
      "epoch:1 step:1575 [D loss: 0.712360, acc.: 51.56%] [G loss: 0.813619]\n",
      "epoch:1 step:1576 [D loss: 0.675716, acc.: 52.34%] [G loss: 0.931819]\n",
      "epoch:1 step:1577 [D loss: 0.706287, acc.: 51.56%] [G loss: 0.958747]\n",
      "epoch:1 step:1578 [D loss: 0.700307, acc.: 57.03%] [G loss: 0.917670]\n",
      "epoch:1 step:1579 [D loss: 0.724926, acc.: 46.09%] [G loss: 0.818338]\n",
      "epoch:1 step:1580 [D loss: 0.667148, acc.: 60.16%] [G loss: 0.918977]\n",
      "epoch:1 step:1581 [D loss: 0.728614, acc.: 52.34%] [G loss: 0.861586]\n",
      "epoch:1 step:1582 [D loss: 0.742952, acc.: 42.97%] [G loss: 0.922203]\n",
      "epoch:1 step:1583 [D loss: 0.688410, acc.: 56.25%] [G loss: 0.875490]\n",
      "epoch:1 step:1584 [D loss: 0.691900, acc.: 54.69%] [G loss: 0.879221]\n",
      "epoch:1 step:1585 [D loss: 0.670882, acc.: 60.94%] [G loss: 0.863879]\n",
      "epoch:1 step:1586 [D loss: 0.710992, acc.: 46.09%] [G loss: 0.873671]\n",
      "epoch:1 step:1587 [D loss: 0.678723, acc.: 62.50%] [G loss: 0.880741]\n",
      "epoch:1 step:1588 [D loss: 0.648724, acc.: 66.41%] [G loss: 0.910972]\n",
      "epoch:1 step:1589 [D loss: 0.752601, acc.: 44.53%] [G loss: 0.832652]\n",
      "epoch:1 step:1590 [D loss: 0.681246, acc.: 52.34%] [G loss: 0.788705]\n",
      "epoch:1 step:1591 [D loss: 0.713719, acc.: 53.91%] [G loss: 0.806074]\n",
      "epoch:1 step:1592 [D loss: 0.692745, acc.: 53.12%] [G loss: 0.857598]\n",
      "epoch:1 step:1593 [D loss: 0.675990, acc.: 60.94%] [G loss: 0.869237]\n",
      "epoch:1 step:1594 [D loss: 0.689117, acc.: 61.72%] [G loss: 0.778111]\n",
      "epoch:1 step:1595 [D loss: 0.691840, acc.: 53.12%] [G loss: 0.850139]\n",
      "epoch:1 step:1596 [D loss: 0.668924, acc.: 55.47%] [G loss: 0.785890]\n",
      "epoch:1 step:1597 [D loss: 0.668182, acc.: 63.28%] [G loss: 0.788959]\n",
      "epoch:1 step:1598 [D loss: 0.643688, acc.: 62.50%] [G loss: 0.806929]\n",
      "epoch:1 step:1599 [D loss: 0.693361, acc.: 54.69%] [G loss: 0.806628]\n",
      "epoch:1 step:1600 [D loss: 0.763254, acc.: 42.19%] [G loss: 0.871487]\n",
      "epoch:1 step:1601 [D loss: 0.718839, acc.: 53.91%] [G loss: 0.760832]\n",
      "epoch:1 step:1602 [D loss: 0.690432, acc.: 52.34%] [G loss: 0.864944]\n",
      "epoch:1 step:1603 [D loss: 0.694026, acc.: 51.56%] [G loss: 0.898861]\n",
      "epoch:1 step:1604 [D loss: 0.703760, acc.: 52.34%] [G loss: 0.829329]\n",
      "epoch:1 step:1605 [D loss: 0.694994, acc.: 56.25%] [G loss: 0.861111]\n",
      "epoch:1 step:1606 [D loss: 0.691145, acc.: 50.00%] [G loss: 0.882011]\n",
      "epoch:1 step:1607 [D loss: 0.750757, acc.: 43.75%] [G loss: 0.844201]\n",
      "epoch:1 step:1608 [D loss: 0.733277, acc.: 50.00%] [G loss: 0.817221]\n",
      "epoch:1 step:1609 [D loss: 0.694942, acc.: 53.91%] [G loss: 0.800838]\n",
      "epoch:1 step:1610 [D loss: 0.671550, acc.: 55.47%] [G loss: 0.774638]\n",
      "epoch:1 step:1611 [D loss: 0.652089, acc.: 57.81%] [G loss: 0.804357]\n",
      "epoch:1 step:1612 [D loss: 0.687240, acc.: 50.78%] [G loss: 0.537712]\n",
      "epoch:1 step:1613 [D loss: 0.638620, acc.: 62.50%] [G loss: 0.779494]\n",
      "epoch:1 step:1614 [D loss: 0.631848, acc.: 69.53%] [G loss: 0.894297]\n",
      "epoch:1 step:1615 [D loss: 0.696378, acc.: 58.59%] [G loss: 0.797040]\n",
      "epoch:1 step:1616 [D loss: 0.675706, acc.: 60.94%] [G loss: 0.742307]\n",
      "epoch:1 step:1617 [D loss: 0.656155, acc.: 53.91%] [G loss: 0.806835]\n",
      "epoch:1 step:1618 [D loss: 0.681328, acc.: 61.72%] [G loss: 0.793154]\n",
      "epoch:1 step:1619 [D loss: 0.773936, acc.: 39.84%] [G loss: 0.776821]\n",
      "epoch:1 step:1620 [D loss: 0.723619, acc.: 54.69%] [G loss: 0.791779]\n",
      "epoch:1 step:1621 [D loss: 0.746318, acc.: 44.53%] [G loss: 0.780269]\n",
      "epoch:1 step:1622 [D loss: 0.682766, acc.: 57.81%] [G loss: 0.971889]\n",
      "epoch:1 step:1623 [D loss: 0.684154, acc.: 57.81%] [G loss: 0.817383]\n",
      "epoch:1 step:1624 [D loss: 0.697128, acc.: 53.91%] [G loss: 0.789122]\n",
      "epoch:1 step:1625 [D loss: 0.624903, acc.: 67.97%] [G loss: 0.882046]\n",
      "epoch:1 step:1626 [D loss: 0.669230, acc.: 61.72%] [G loss: 0.874023]\n",
      "epoch:1 step:1627 [D loss: 0.727124, acc.: 48.44%] [G loss: 0.800794]\n",
      "epoch:1 step:1628 [D loss: 0.728541, acc.: 49.22%] [G loss: 0.771838]\n",
      "epoch:1 step:1629 [D loss: 0.704237, acc.: 53.91%] [G loss: 0.930937]\n",
      "epoch:1 step:1630 [D loss: 0.699803, acc.: 52.34%] [G loss: 0.925699]\n",
      "epoch:1 step:1631 [D loss: 0.665050, acc.: 59.38%] [G loss: 0.973560]\n",
      "epoch:1 step:1632 [D loss: 0.701519, acc.: 45.31%] [G loss: 1.081332]\n",
      "epoch:1 step:1633 [D loss: 0.706392, acc.: 42.97%] [G loss: 1.125154]\n",
      "epoch:1 step:1634 [D loss: 0.651486, acc.: 57.03%] [G loss: 0.974021]\n",
      "epoch:1 step:1635 [D loss: 0.713230, acc.: 49.22%] [G loss: 0.971208]\n",
      "epoch:1 step:1636 [D loss: 0.658179, acc.: 63.28%] [G loss: 0.981037]\n",
      "epoch:1 step:1637 [D loss: 0.641340, acc.: 58.59%] [G loss: 0.947889]\n",
      "epoch:1 step:1638 [D loss: 0.619327, acc.: 64.84%] [G loss: 0.953960]\n",
      "epoch:1 step:1639 [D loss: 0.684629, acc.: 57.03%] [G loss: 0.852086]\n",
      "epoch:1 step:1640 [D loss: 0.713281, acc.: 51.56%] [G loss: 0.920601]\n",
      "epoch:1 step:1641 [D loss: 0.698079, acc.: 53.12%] [G loss: 1.113670]\n",
      "epoch:1 step:1642 [D loss: 0.717587, acc.: 49.22%] [G loss: 0.886776]\n",
      "epoch:1 step:1643 [D loss: 0.637280, acc.: 71.09%] [G loss: 0.951548]\n",
      "epoch:1 step:1644 [D loss: 0.666494, acc.: 69.53%] [G loss: 0.912854]\n",
      "epoch:1 step:1645 [D loss: 0.630450, acc.: 64.84%] [G loss: 0.993561]\n",
      "epoch:1 step:1646 [D loss: 0.653414, acc.: 65.62%] [G loss: 1.005507]\n",
      "epoch:1 step:1647 [D loss: 0.805819, acc.: 45.31%] [G loss: 0.875164]\n",
      "epoch:1 step:1648 [D loss: 0.804349, acc.: 38.28%] [G loss: 0.806171]\n",
      "epoch:1 step:1649 [D loss: 0.698823, acc.: 53.91%] [G loss: 0.824409]\n",
      "epoch:1 step:1650 [D loss: 0.691630, acc.: 51.56%] [G loss: 0.777478]\n",
      "epoch:1 step:1651 [D loss: 0.674712, acc.: 57.81%] [G loss: 0.790127]\n",
      "epoch:1 step:1652 [D loss: 0.676770, acc.: 57.03%] [G loss: 0.859413]\n",
      "epoch:1 step:1653 [D loss: 0.677297, acc.: 52.34%] [G loss: 0.824662]\n",
      "epoch:1 step:1654 [D loss: 0.669310, acc.: 56.25%] [G loss: 0.882145]\n",
      "epoch:1 step:1655 [D loss: 0.631966, acc.: 64.06%] [G loss: 0.891292]\n",
      "epoch:1 step:1656 [D loss: 0.695896, acc.: 55.47%] [G loss: 0.848105]\n",
      "epoch:1 step:1657 [D loss: 0.640446, acc.: 63.28%] [G loss: 0.756552]\n",
      "epoch:1 step:1658 [D loss: 0.623036, acc.: 65.62%] [G loss: 0.757851]\n",
      "epoch:1 step:1659 [D loss: 0.646600, acc.: 63.28%] [G loss: 0.804287]\n",
      "epoch:1 step:1660 [D loss: 0.635095, acc.: 60.16%] [G loss: 0.840141]\n",
      "epoch:1 step:1661 [D loss: 0.610095, acc.: 70.31%] [G loss: 0.912704]\n",
      "epoch:1 step:1662 [D loss: 0.751146, acc.: 42.97%] [G loss: 0.900321]\n",
      "epoch:1 step:1663 [D loss: 0.669233, acc.: 54.69%] [G loss: 0.957026]\n",
      "epoch:1 step:1664 [D loss: 0.711231, acc.: 50.00%] [G loss: 0.797601]\n",
      "epoch:1 step:1665 [D loss: 0.739360, acc.: 47.66%] [G loss: 0.687804]\n",
      "epoch:1 step:1666 [D loss: 0.718910, acc.: 47.66%] [G loss: 0.842712]\n",
      "epoch:1 step:1667 [D loss: 0.658216, acc.: 63.28%] [G loss: 0.901195]\n",
      "epoch:1 step:1668 [D loss: 0.687785, acc.: 60.94%] [G loss: 0.876276]\n",
      "epoch:1 step:1669 [D loss: 0.688563, acc.: 58.59%] [G loss: 0.997033]\n",
      "epoch:1 step:1670 [D loss: 0.667062, acc.: 64.06%] [G loss: 1.011333]\n",
      "epoch:1 step:1671 [D loss: 0.732884, acc.: 45.31%] [G loss: 0.837053]\n",
      "epoch:1 step:1672 [D loss: 0.765281, acc.: 46.09%] [G loss: 0.779148]\n",
      "epoch:1 step:1673 [D loss: 0.740501, acc.: 50.00%] [G loss: 0.824912]\n",
      "epoch:1 step:1674 [D loss: 0.714111, acc.: 50.78%] [G loss: 0.786295]\n",
      "epoch:1 step:1675 [D loss: 0.711094, acc.: 53.91%] [G loss: 0.808761]\n",
      "epoch:1 step:1676 [D loss: 0.679636, acc.: 53.91%] [G loss: 0.806032]\n",
      "epoch:1 step:1677 [D loss: 0.728601, acc.: 46.09%] [G loss: 0.778602]\n",
      "epoch:1 step:1678 [D loss: 0.685670, acc.: 59.38%] [G loss: 0.830719]\n",
      "epoch:1 step:1679 [D loss: 0.728953, acc.: 47.66%] [G loss: 0.780405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1680 [D loss: 0.678803, acc.: 55.47%] [G loss: 0.819397]\n",
      "epoch:1 step:1681 [D loss: 0.678558, acc.: 53.91%] [G loss: 0.783916]\n",
      "epoch:1 step:1682 [D loss: 0.721098, acc.: 48.44%] [G loss: 0.832356]\n",
      "epoch:1 step:1683 [D loss: 0.725005, acc.: 44.53%] [G loss: 0.878824]\n",
      "epoch:1 step:1684 [D loss: 0.679598, acc.: 57.81%] [G loss: 0.850232]\n",
      "epoch:1 step:1685 [D loss: 0.722853, acc.: 51.56%] [G loss: 0.948051]\n",
      "epoch:1 step:1686 [D loss: 0.723500, acc.: 51.56%] [G loss: 0.838142]\n",
      "epoch:1 step:1687 [D loss: 0.697076, acc.: 54.69%] [G loss: 0.832764]\n",
      "epoch:1 step:1688 [D loss: 0.694488, acc.: 52.34%] [G loss: 0.836956]\n",
      "epoch:1 step:1689 [D loss: 0.732330, acc.: 50.00%] [G loss: 0.813450]\n",
      "epoch:1 step:1690 [D loss: 0.671479, acc.: 56.25%] [G loss: 0.827538]\n",
      "epoch:1 step:1691 [D loss: 0.656208, acc.: 59.38%] [G loss: 0.843356]\n",
      "epoch:1 step:1692 [D loss: 0.681231, acc.: 56.25%] [G loss: 0.798729]\n",
      "epoch:1 step:1693 [D loss: 0.635700, acc.: 65.62%] [G loss: 0.780054]\n",
      "epoch:1 step:1694 [D loss: 0.670101, acc.: 60.94%] [G loss: 0.828526]\n",
      "epoch:1 step:1695 [D loss: 0.691088, acc.: 51.56%] [G loss: 0.772138]\n",
      "epoch:1 step:1696 [D loss: 0.745534, acc.: 43.75%] [G loss: 0.765817]\n",
      "epoch:1 step:1697 [D loss: 0.776120, acc.: 44.53%] [G loss: 0.803435]\n",
      "epoch:1 step:1698 [D loss: 0.719885, acc.: 49.22%] [G loss: 0.772124]\n",
      "epoch:1 step:1699 [D loss: 0.716315, acc.: 53.91%] [G loss: 0.856986]\n",
      "epoch:1 step:1700 [D loss: 0.692287, acc.: 57.03%] [G loss: 0.884002]\n",
      "epoch:1 step:1701 [D loss: 0.668731, acc.: 63.28%] [G loss: 0.833803]\n",
      "epoch:1 step:1702 [D loss: 0.724560, acc.: 51.56%] [G loss: 0.819825]\n",
      "epoch:1 step:1703 [D loss: 0.644535, acc.: 65.62%] [G loss: 0.865168]\n",
      "epoch:1 step:1704 [D loss: 0.646266, acc.: 63.28%] [G loss: 0.752512]\n",
      "epoch:1 step:1705 [D loss: 0.688582, acc.: 52.34%] [G loss: 0.826048]\n",
      "epoch:1 step:1706 [D loss: 0.693153, acc.: 50.78%] [G loss: 0.824471]\n",
      "epoch:1 step:1707 [D loss: 0.678769, acc.: 55.47%] [G loss: 0.772556]\n",
      "epoch:1 step:1708 [D loss: 0.680203, acc.: 57.03%] [G loss: 0.752998]\n",
      "epoch:1 step:1709 [D loss: 0.717273, acc.: 43.75%] [G loss: 0.744558]\n",
      "epoch:1 step:1710 [D loss: 0.724699, acc.: 46.09%] [G loss: 0.774604]\n",
      "epoch:1 step:1711 [D loss: 0.703431, acc.: 52.34%] [G loss: 0.778964]\n",
      "epoch:1 step:1712 [D loss: 0.636255, acc.: 64.84%] [G loss: 0.775818]\n",
      "epoch:1 step:1713 [D loss: 0.741062, acc.: 45.31%] [G loss: 0.964618]\n",
      "epoch:1 step:1714 [D loss: 0.684132, acc.: 53.12%] [G loss: 0.880551]\n",
      "epoch:1 step:1715 [D loss: 0.714831, acc.: 54.69%] [G loss: 0.916587]\n",
      "epoch:1 step:1716 [D loss: 0.692995, acc.: 54.69%] [G loss: 0.922044]\n",
      "epoch:1 step:1717 [D loss: 0.687316, acc.: 54.69%] [G loss: 0.925999]\n",
      "epoch:1 step:1718 [D loss: 0.657933, acc.: 57.81%] [G loss: 0.901804]\n",
      "epoch:1 step:1719 [D loss: 0.611405, acc.: 67.19%] [G loss: 0.938091]\n",
      "epoch:1 step:1720 [D loss: 0.713727, acc.: 43.75%] [G loss: 0.867442]\n",
      "epoch:1 step:1721 [D loss: 0.729309, acc.: 50.00%] [G loss: 0.817486]\n",
      "epoch:1 step:1722 [D loss: 0.700019, acc.: 48.44%] [G loss: 0.799812]\n",
      "epoch:1 step:1723 [D loss: 0.712716, acc.: 56.25%] [G loss: 0.747769]\n",
      "epoch:1 step:1724 [D loss: 0.789095, acc.: 31.25%] [G loss: 0.715372]\n",
      "epoch:1 step:1725 [D loss: 0.727163, acc.: 50.78%] [G loss: 0.755561]\n",
      "epoch:1 step:1726 [D loss: 0.724948, acc.: 43.75%] [G loss: 0.765643]\n",
      "epoch:1 step:1727 [D loss: 0.683189, acc.: 54.69%] [G loss: 0.782344]\n",
      "epoch:1 step:1728 [D loss: 0.699080, acc.: 53.91%] [G loss: 0.785262]\n",
      "epoch:1 step:1729 [D loss: 0.687924, acc.: 57.03%] [G loss: 0.756698]\n",
      "epoch:1 step:1730 [D loss: 0.688944, acc.: 51.56%] [G loss: 0.841999]\n",
      "epoch:1 step:1731 [D loss: 0.694869, acc.: 53.91%] [G loss: 0.843772]\n",
      "epoch:1 step:1732 [D loss: 0.693736, acc.: 52.34%] [G loss: 0.799478]\n",
      "epoch:1 step:1733 [D loss: 0.654972, acc.: 57.03%] [G loss: 0.856087]\n",
      "epoch:1 step:1734 [D loss: 0.676717, acc.: 53.91%] [G loss: 0.733504]\n",
      "epoch:1 step:1735 [D loss: 0.668595, acc.: 61.72%] [G loss: 0.742925]\n",
      "epoch:1 step:1736 [D loss: 0.654043, acc.: 60.16%] [G loss: 0.795601]\n",
      "epoch:1 step:1737 [D loss: 0.739090, acc.: 46.88%] [G loss: 0.816576]\n",
      "epoch:1 step:1738 [D loss: 0.734138, acc.: 49.22%] [G loss: 0.715773]\n",
      "epoch:1 step:1739 [D loss: 0.613346, acc.: 60.94%] [G loss: 0.825795]\n",
      "epoch:1 step:1740 [D loss: 0.657700, acc.: 64.84%] [G loss: 0.762018]\n",
      "epoch:1 step:1741 [D loss: 0.739794, acc.: 41.41%] [G loss: 0.873288]\n",
      "epoch:1 step:1742 [D loss: 0.683808, acc.: 50.78%] [G loss: 0.822714]\n",
      "epoch:1 step:1743 [D loss: 0.719254, acc.: 49.22%] [G loss: 0.789603]\n",
      "epoch:1 step:1744 [D loss: 0.705132, acc.: 54.69%] [G loss: 0.795884]\n",
      "epoch:1 step:1745 [D loss: 0.725232, acc.: 45.31%] [G loss: 0.858125]\n",
      "epoch:1 step:1746 [D loss: 0.675826, acc.: 53.12%] [G loss: 0.805062]\n",
      "epoch:1 step:1747 [D loss: 0.666106, acc.: 59.38%] [G loss: 0.810844]\n",
      "epoch:1 step:1748 [D loss: 0.726721, acc.: 49.22%] [G loss: 0.809443]\n",
      "epoch:1 step:1749 [D loss: 0.695249, acc.: 54.69%] [G loss: 0.783640]\n",
      "epoch:1 step:1750 [D loss: 0.646388, acc.: 61.72%] [G loss: 0.832187]\n",
      "epoch:1 step:1751 [D loss: 0.687702, acc.: 55.47%] [G loss: 0.802692]\n",
      "epoch:1 step:1752 [D loss: 0.693384, acc.: 52.34%] [G loss: 0.823301]\n",
      "epoch:1 step:1753 [D loss: 0.684940, acc.: 53.12%] [G loss: 0.798667]\n",
      "epoch:1 step:1754 [D loss: 0.685437, acc.: 57.81%] [G loss: 0.869125]\n",
      "epoch:1 step:1755 [D loss: 0.663360, acc.: 59.38%] [G loss: 0.841002]\n",
      "epoch:1 step:1756 [D loss: 0.693824, acc.: 54.69%] [G loss: 0.732492]\n",
      "epoch:1 step:1757 [D loss: 0.740709, acc.: 42.97%] [G loss: 0.766023]\n",
      "epoch:1 step:1758 [D loss: 0.708595, acc.: 49.22%] [G loss: 0.766607]\n",
      "epoch:1 step:1759 [D loss: 0.680875, acc.: 54.69%] [G loss: 0.824419]\n",
      "epoch:1 step:1760 [D loss: 0.676608, acc.: 57.81%] [G loss: 0.805199]\n",
      "epoch:1 step:1761 [D loss: 0.669204, acc.: 57.03%] [G loss: 0.813105]\n",
      "epoch:1 step:1762 [D loss: 0.699131, acc.: 53.91%] [G loss: 0.874061]\n",
      "epoch:1 step:1763 [D loss: 0.698679, acc.: 57.03%] [G loss: 0.829429]\n",
      "epoch:1 step:1764 [D loss: 0.738557, acc.: 49.22%] [G loss: 0.850589]\n",
      "epoch:1 step:1765 [D loss: 0.670550, acc.: 51.56%] [G loss: 0.844617]\n",
      "epoch:1 step:1766 [D loss: 0.662508, acc.: 59.38%] [G loss: 0.802475]\n",
      "epoch:1 step:1767 [D loss: 0.645950, acc.: 62.50%] [G loss: 0.887588]\n",
      "epoch:1 step:1768 [D loss: 0.681667, acc.: 53.12%] [G loss: 0.905522]\n",
      "epoch:1 step:1769 [D loss: 0.699969, acc.: 56.25%] [G loss: 0.908255]\n",
      "epoch:1 step:1770 [D loss: 0.681590, acc.: 55.47%] [G loss: 0.830419]\n",
      "epoch:1 step:1771 [D loss: 0.694486, acc.: 57.03%] [G loss: 0.893108]\n",
      "epoch:1 step:1772 [D loss: 0.702390, acc.: 51.56%] [G loss: 0.779726]\n",
      "epoch:1 step:1773 [D loss: 0.694349, acc.: 52.34%] [G loss: 0.811017]\n",
      "epoch:1 step:1774 [D loss: 0.705281, acc.: 49.22%] [G loss: 0.786006]\n",
      "epoch:1 step:1775 [D loss: 0.685790, acc.: 58.59%] [G loss: 0.800669]\n",
      "epoch:1 step:1776 [D loss: 0.657173, acc.: 65.62%] [G loss: 0.828847]\n",
      "epoch:1 step:1777 [D loss: 0.643771, acc.: 61.72%] [G loss: 0.747138]\n",
      "epoch:1 step:1778 [D loss: 0.691897, acc.: 52.34%] [G loss: 0.757715]\n",
      "epoch:1 step:1779 [D loss: 0.640240, acc.: 60.94%] [G loss: 0.788566]\n",
      "epoch:1 step:1780 [D loss: 0.779656, acc.: 39.06%] [G loss: 0.764526]\n",
      "epoch:1 step:1781 [D loss: 0.752263, acc.: 45.31%] [G loss: 0.748270]\n",
      "epoch:1 step:1782 [D loss: 0.673883, acc.: 61.72%] [G loss: 0.792962]\n",
      "epoch:1 step:1783 [D loss: 0.690530, acc.: 52.34%] [G loss: 0.849499]\n",
      "epoch:1 step:1784 [D loss: 0.702132, acc.: 54.69%] [G loss: 0.816230]\n",
      "epoch:1 step:1785 [D loss: 0.714707, acc.: 46.88%] [G loss: 0.809472]\n",
      "epoch:1 step:1786 [D loss: 0.711455, acc.: 54.69%] [G loss: 0.861825]\n",
      "epoch:1 step:1787 [D loss: 0.707952, acc.: 55.47%] [G loss: 0.973510]\n",
      "epoch:1 step:1788 [D loss: 0.721724, acc.: 46.09%] [G loss: 0.841474]\n",
      "epoch:1 step:1789 [D loss: 0.652133, acc.: 62.50%] [G loss: 0.862668]\n",
      "epoch:1 step:1790 [D loss: 0.693948, acc.: 53.91%] [G loss: 0.863656]\n",
      "epoch:1 step:1791 [D loss: 0.671065, acc.: 60.94%] [G loss: 0.829565]\n",
      "epoch:1 step:1792 [D loss: 0.724093, acc.: 46.09%] [G loss: 0.843501]\n",
      "epoch:1 step:1793 [D loss: 0.733124, acc.: 46.88%] [G loss: 0.845194]\n",
      "epoch:1 step:1794 [D loss: 0.725785, acc.: 51.56%] [G loss: 0.852922]\n",
      "epoch:1 step:1795 [D loss: 0.756189, acc.: 35.94%] [G loss: 0.774574]\n",
      "epoch:1 step:1796 [D loss: 0.730281, acc.: 41.41%] [G loss: 0.769165]\n",
      "epoch:1 step:1797 [D loss: 0.700736, acc.: 45.31%] [G loss: 0.772015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1798 [D loss: 0.684105, acc.: 58.59%] [G loss: 0.783876]\n",
      "epoch:1 step:1799 [D loss: 0.640215, acc.: 67.97%] [G loss: 0.852412]\n",
      "epoch:1 step:1800 [D loss: 0.609640, acc.: 72.66%] [G loss: 0.741759]\n",
      "epoch:1 step:1801 [D loss: 0.701979, acc.: 53.12%] [G loss: 0.785778]\n",
      "epoch:1 step:1802 [D loss: 0.683138, acc.: 53.91%] [G loss: 0.832267]\n",
      "epoch:1 step:1803 [D loss: 0.599871, acc.: 71.88%] [G loss: 0.766483]\n",
      "epoch:1 step:1804 [D loss: 0.827304, acc.: 46.88%] [G loss: 0.833812]\n",
      "epoch:1 step:1805 [D loss: 0.680157, acc.: 53.12%] [G loss: 0.952414]\n",
      "epoch:1 step:1806 [D loss: 0.711759, acc.: 47.66%] [G loss: 0.860100]\n",
      "epoch:1 step:1807 [D loss: 0.735514, acc.: 41.41%] [G loss: 0.849443]\n",
      "epoch:1 step:1808 [D loss: 0.721621, acc.: 45.31%] [G loss: 0.840372]\n",
      "epoch:1 step:1809 [D loss: 0.691555, acc.: 53.91%] [G loss: 0.803332]\n",
      "epoch:1 step:1810 [D loss: 0.696932, acc.: 50.00%] [G loss: 0.808072]\n",
      "epoch:1 step:1811 [D loss: 0.746179, acc.: 38.28%] [G loss: 0.782804]\n",
      "epoch:1 step:1812 [D loss: 0.679216, acc.: 57.81%] [G loss: 0.758850]\n",
      "epoch:1 step:1813 [D loss: 0.719388, acc.: 47.66%] [G loss: 0.751795]\n",
      "epoch:1 step:1814 [D loss: 0.705985, acc.: 48.44%] [G loss: 0.774999]\n",
      "epoch:1 step:1815 [D loss: 0.648615, acc.: 64.84%] [G loss: 0.821844]\n",
      "epoch:1 step:1816 [D loss: 0.740877, acc.: 46.88%] [G loss: 0.752032]\n",
      "epoch:1 step:1817 [D loss: 0.732912, acc.: 42.97%] [G loss: 0.830079]\n",
      "epoch:1 step:1818 [D loss: 0.718184, acc.: 46.09%] [G loss: 0.838728]\n",
      "epoch:1 step:1819 [D loss: 0.742869, acc.: 42.97%] [G loss: 0.831693]\n",
      "epoch:1 step:1820 [D loss: 0.703200, acc.: 50.78%] [G loss: 0.812566]\n",
      "epoch:1 step:1821 [D loss: 0.701049, acc.: 54.69%] [G loss: 0.779238]\n",
      "epoch:1 step:1822 [D loss: 0.693854, acc.: 53.12%] [G loss: 0.814780]\n",
      "epoch:1 step:1823 [D loss: 0.671322, acc.: 58.59%] [G loss: 0.744565]\n",
      "epoch:1 step:1824 [D loss: 0.623426, acc.: 71.09%] [G loss: 0.853168]\n",
      "epoch:1 step:1825 [D loss: 0.687608, acc.: 57.81%] [G loss: 1.213392]\n",
      "epoch:1 step:1826 [D loss: 0.628171, acc.: 68.75%] [G loss: 0.807944]\n",
      "epoch:1 step:1827 [D loss: 0.682730, acc.: 52.34%] [G loss: 0.750576]\n",
      "epoch:1 step:1828 [D loss: 0.707590, acc.: 53.91%] [G loss: 0.829011]\n",
      "epoch:1 step:1829 [D loss: 0.871730, acc.: 23.44%] [G loss: 0.780497]\n",
      "epoch:1 step:1830 [D loss: 0.766781, acc.: 37.50%] [G loss: 0.765177]\n",
      "epoch:1 step:1831 [D loss: 0.695489, acc.: 50.00%] [G loss: 0.756966]\n",
      "epoch:1 step:1832 [D loss: 0.695740, acc.: 48.44%] [G loss: 0.733080]\n",
      "epoch:1 step:1833 [D loss: 0.672023, acc.: 58.59%] [G loss: 0.756092]\n",
      "epoch:1 step:1834 [D loss: 0.667509, acc.: 59.38%] [G loss: 0.809762]\n",
      "epoch:1 step:1835 [D loss: 0.716044, acc.: 54.69%] [G loss: 0.781877]\n",
      "epoch:1 step:1836 [D loss: 0.626861, acc.: 61.72%] [G loss: 0.822360]\n",
      "epoch:1 step:1837 [D loss: 0.592991, acc.: 73.44%] [G loss: 0.737907]\n",
      "epoch:1 step:1838 [D loss: 0.627311, acc.: 67.19%] [G loss: 0.829541]\n",
      "epoch:1 step:1839 [D loss: 0.665200, acc.: 58.59%] [G loss: 0.833003]\n",
      "epoch:1 step:1840 [D loss: 0.673459, acc.: 57.03%] [G loss: 0.841115]\n",
      "epoch:1 step:1841 [D loss: 0.757240, acc.: 39.84%] [G loss: 0.765896]\n",
      "epoch:1 step:1842 [D loss: 0.680136, acc.: 57.03%] [G loss: 0.767355]\n",
      "epoch:1 step:1843 [D loss: 0.767878, acc.: 36.72%] [G loss: 0.731356]\n",
      "epoch:1 step:1844 [D loss: 0.738642, acc.: 46.88%] [G loss: 0.740026]\n",
      "epoch:1 step:1845 [D loss: 0.715161, acc.: 47.66%] [G loss: 0.845566]\n",
      "epoch:1 step:1846 [D loss: 0.671209, acc.: 56.25%] [G loss: 0.799719]\n",
      "epoch:1 step:1847 [D loss: 0.708458, acc.: 51.56%] [G loss: 0.786386]\n",
      "epoch:1 step:1848 [D loss: 0.629812, acc.: 63.28%] [G loss: 0.726785]\n",
      "epoch:1 step:1849 [D loss: 0.496151, acc.: 84.38%] [G loss: 0.835902]\n",
      "epoch:1 step:1850 [D loss: 0.686485, acc.: 53.91%] [G loss: 0.850465]\n",
      "epoch:1 step:1851 [D loss: 0.751083, acc.: 41.41%] [G loss: 0.762986]\n",
      "epoch:1 step:1852 [D loss: 0.844829, acc.: 31.25%] [G loss: 0.834219]\n",
      "epoch:1 step:1853 [D loss: 0.756164, acc.: 39.06%] [G loss: 0.912228]\n",
      "epoch:1 step:1854 [D loss: 0.697280, acc.: 56.25%] [G loss: 0.954710]\n",
      "epoch:1 step:1855 [D loss: 0.682305, acc.: 60.16%] [G loss: 0.846453]\n",
      "epoch:1 step:1856 [D loss: 0.684104, acc.: 54.69%] [G loss: 0.821871]\n",
      "epoch:1 step:1857 [D loss: 0.758979, acc.: 40.62%] [G loss: 0.739511]\n",
      "epoch:1 step:1858 [D loss: 0.692689, acc.: 57.03%] [G loss: 0.759554]\n",
      "epoch:1 step:1859 [D loss: 0.679765, acc.: 59.38%] [G loss: 0.812701]\n",
      "epoch:1 step:1860 [D loss: 0.662737, acc.: 59.38%] [G loss: 0.763750]\n",
      "epoch:1 step:1861 [D loss: 0.653005, acc.: 63.28%] [G loss: 0.782103]\n",
      "epoch:1 step:1862 [D loss: 0.600518, acc.: 66.41%] [G loss: 0.775840]\n",
      "epoch:1 step:1863 [D loss: 0.569543, acc.: 67.19%] [G loss: 0.726546]\n",
      "epoch:1 step:1864 [D loss: 0.812397, acc.: 49.22%] [G loss: 0.837650]\n",
      "epoch:1 step:1865 [D loss: 0.759556, acc.: 43.75%] [G loss: 0.857473]\n",
      "epoch:1 step:1866 [D loss: 0.725914, acc.: 43.75%] [G loss: 1.015383]\n",
      "epoch:1 step:1867 [D loss: 0.630368, acc.: 65.62%] [G loss: 0.923815]\n",
      "epoch:1 step:1868 [D loss: 0.708221, acc.: 57.03%] [G loss: 0.920086]\n",
      "epoch:1 step:1869 [D loss: 0.703260, acc.: 56.25%] [G loss: 0.853737]\n",
      "epoch:1 step:1870 [D loss: 0.686107, acc.: 53.12%] [G loss: 0.756441]\n",
      "epoch:1 step:1871 [D loss: 0.729964, acc.: 53.12%] [G loss: 0.762143]\n",
      "epoch:1 step:1872 [D loss: 0.682298, acc.: 60.94%] [G loss: 0.600483]\n",
      "epoch:1 step:1873 [D loss: 0.652653, acc.: 55.47%] [G loss: 0.807594]\n",
      "epoch:1 step:1874 [D loss: 0.817836, acc.: 49.22%] [G loss: 0.785097]\n",
      "epoch:2 step:1875 [D loss: 0.744177, acc.: 42.19%] [G loss: 1.095495]\n",
      "epoch:2 step:1876 [D loss: 0.711235, acc.: 50.00%] [G loss: 0.907405]\n",
      "epoch:2 step:1877 [D loss: 0.674571, acc.: 53.12%] [G loss: 0.874957]\n",
      "epoch:2 step:1878 [D loss: 0.698897, acc.: 47.66%] [G loss: 0.888622]\n",
      "epoch:2 step:1879 [D loss: 0.668360, acc.: 55.47%] [G loss: 1.004520]\n",
      "epoch:2 step:1880 [D loss: 0.708694, acc.: 46.09%] [G loss: 0.895503]\n",
      "epoch:2 step:1881 [D loss: 0.713451, acc.: 50.78%] [G loss: 0.771015]\n",
      "epoch:2 step:1882 [D loss: 0.748677, acc.: 39.84%] [G loss: 0.919062]\n",
      "epoch:2 step:1883 [D loss: 0.704699, acc.: 54.69%] [G loss: 0.925913]\n",
      "epoch:2 step:1884 [D loss: 0.716809, acc.: 48.44%] [G loss: 0.816092]\n",
      "epoch:2 step:1885 [D loss: 0.696017, acc.: 52.34%] [G loss: 0.800408]\n",
      "epoch:2 step:1886 [D loss: 0.722622, acc.: 50.78%] [G loss: 0.751672]\n",
      "epoch:2 step:1887 [D loss: 0.683122, acc.: 58.59%] [G loss: 0.816740]\n",
      "epoch:2 step:1888 [D loss: 0.671782, acc.: 56.25%] [G loss: 0.805441]\n",
      "epoch:2 step:1889 [D loss: 0.640687, acc.: 67.97%] [G loss: 0.811804]\n",
      "epoch:2 step:1890 [D loss: 0.666496, acc.: 66.41%] [G loss: 0.769325]\n",
      "epoch:2 step:1891 [D loss: 0.663036, acc.: 64.06%] [G loss: 0.819258]\n",
      "epoch:2 step:1892 [D loss: 0.646774, acc.: 62.50%] [G loss: 0.811824]\n",
      "epoch:2 step:1893 [D loss: 0.675902, acc.: 60.16%] [G loss: 0.802682]\n",
      "epoch:2 step:1894 [D loss: 0.728722, acc.: 45.31%] [G loss: 0.701431]\n",
      "epoch:2 step:1895 [D loss: 0.714050, acc.: 53.12%] [G loss: 0.856598]\n",
      "epoch:2 step:1896 [D loss: 0.652991, acc.: 61.72%] [G loss: 0.822232]\n",
      "epoch:2 step:1897 [D loss: 0.693776, acc.: 50.00%] [G loss: 0.882107]\n",
      "epoch:2 step:1898 [D loss: 0.687362, acc.: 56.25%] [G loss: 0.874906]\n",
      "epoch:2 step:1899 [D loss: 0.648138, acc.: 64.06%] [G loss: 0.889909]\n",
      "epoch:2 step:1900 [D loss: 0.689446, acc.: 51.56%] [G loss: 0.793228]\n",
      "epoch:2 step:1901 [D loss: 0.739355, acc.: 43.75%] [G loss: 0.759354]\n",
      "epoch:2 step:1902 [D loss: 0.750142, acc.: 39.84%] [G loss: 0.789844]\n",
      "epoch:2 step:1903 [D loss: 0.715651, acc.: 47.66%] [G loss: 0.833935]\n",
      "epoch:2 step:1904 [D loss: 0.691968, acc.: 51.56%] [G loss: 0.797539]\n",
      "epoch:2 step:1905 [D loss: 0.760841, acc.: 38.28%] [G loss: 0.795101]\n",
      "epoch:2 step:1906 [D loss: 0.698923, acc.: 50.78%] [G loss: 0.767322]\n",
      "epoch:2 step:1907 [D loss: 0.690062, acc.: 52.34%] [G loss: 0.882405]\n",
      "epoch:2 step:1908 [D loss: 0.681425, acc.: 55.47%] [G loss: 0.822415]\n",
      "epoch:2 step:1909 [D loss: 0.640200, acc.: 67.97%] [G loss: 0.868603]\n",
      "epoch:2 step:1910 [D loss: 0.635857, acc.: 61.72%] [G loss: 0.829789]\n",
      "epoch:2 step:1911 [D loss: 0.670305, acc.: 59.38%] [G loss: 0.759393]\n",
      "epoch:2 step:1912 [D loss: 0.771960, acc.: 44.53%] [G loss: 0.867927]\n",
      "epoch:2 step:1913 [D loss: 0.681745, acc.: 57.03%] [G loss: 0.787000]\n",
      "epoch:2 step:1914 [D loss: 0.762757, acc.: 41.41%] [G loss: 0.763385]\n",
      "epoch:2 step:1915 [D loss: 0.675911, acc.: 51.56%] [G loss: 0.710680]\n",
      "epoch:2 step:1916 [D loss: 0.689297, acc.: 52.34%] [G loss: 0.748714]\n",
      "epoch:2 step:1917 [D loss: 0.677941, acc.: 55.47%] [G loss: 0.745759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1918 [D loss: 0.739792, acc.: 46.09%] [G loss: 0.712236]\n",
      "epoch:2 step:1919 [D loss: 0.722834, acc.: 42.19%] [G loss: 0.733154]\n",
      "epoch:2 step:1920 [D loss: 0.713628, acc.: 47.66%] [G loss: 0.717327]\n",
      "epoch:2 step:1921 [D loss: 0.678305, acc.: 62.50%] [G loss: 0.757632]\n",
      "epoch:2 step:1922 [D loss: 0.664967, acc.: 59.38%] [G loss: 0.722554]\n",
      "epoch:2 step:1923 [D loss: 0.677624, acc.: 60.16%] [G loss: 0.717310]\n",
      "epoch:2 step:1924 [D loss: 0.687251, acc.: 53.91%] [G loss: 0.763665]\n",
      "epoch:2 step:1925 [D loss: 0.736340, acc.: 39.06%] [G loss: 0.744523]\n",
      "epoch:2 step:1926 [D loss: 0.699876, acc.: 55.47%] [G loss: 0.789934]\n",
      "epoch:2 step:1927 [D loss: 0.665823, acc.: 57.81%] [G loss: 0.742408]\n",
      "epoch:2 step:1928 [D loss: 0.701722, acc.: 53.91%] [G loss: 0.748214]\n",
      "epoch:2 step:1929 [D loss: 0.683625, acc.: 53.12%] [G loss: 0.757629]\n",
      "epoch:2 step:1930 [D loss: 0.673251, acc.: 60.94%] [G loss: 0.767017]\n",
      "epoch:2 step:1931 [D loss: 0.691628, acc.: 50.78%] [G loss: 0.798142]\n",
      "epoch:2 step:1932 [D loss: 0.759948, acc.: 50.00%] [G loss: 0.792338]\n",
      "epoch:2 step:1933 [D loss: 0.714503, acc.: 48.44%] [G loss: 0.775373]\n",
      "epoch:2 step:1934 [D loss: 0.708534, acc.: 42.19%] [G loss: 0.824198]\n",
      "epoch:2 step:1935 [D loss: 0.682954, acc.: 55.47%] [G loss: 0.802949]\n",
      "epoch:2 step:1936 [D loss: 0.693476, acc.: 52.34%] [G loss: 0.799847]\n",
      "epoch:2 step:1937 [D loss: 0.703114, acc.: 53.12%] [G loss: 0.793928]\n",
      "epoch:2 step:1938 [D loss: 0.671929, acc.: 56.25%] [G loss: 0.736134]\n",
      "epoch:2 step:1939 [D loss: 0.678277, acc.: 58.59%] [G loss: 0.784102]\n",
      "epoch:2 step:1940 [D loss: 0.711111, acc.: 52.34%] [G loss: 0.786381]\n",
      "epoch:2 step:1941 [D loss: 0.668552, acc.: 59.38%] [G loss: 0.750733]\n",
      "epoch:2 step:1942 [D loss: 0.716025, acc.: 48.44%] [G loss: 0.778339]\n",
      "epoch:2 step:1943 [D loss: 0.633319, acc.: 64.84%] [G loss: 0.727109]\n",
      "epoch:2 step:1944 [D loss: 0.654679, acc.: 67.19%] [G loss: 0.792231]\n",
      "epoch:2 step:1945 [D loss: 0.728378, acc.: 39.06%] [G loss: 0.800190]\n",
      "epoch:2 step:1946 [D loss: 0.713154, acc.: 51.56%] [G loss: 0.792840]\n",
      "epoch:2 step:1947 [D loss: 0.726655, acc.: 43.75%] [G loss: 0.750007]\n",
      "epoch:2 step:1948 [D loss: 0.700842, acc.: 49.22%] [G loss: 0.754906]\n",
      "epoch:2 step:1949 [D loss: 0.725359, acc.: 44.53%] [G loss: 0.751732]\n",
      "epoch:2 step:1950 [D loss: 0.709743, acc.: 45.31%] [G loss: 0.762221]\n",
      "epoch:2 step:1951 [D loss: 0.683233, acc.: 55.47%] [G loss: 0.742800]\n",
      "epoch:2 step:1952 [D loss: 0.704103, acc.: 51.56%] [G loss: 0.887065]\n",
      "epoch:2 step:1953 [D loss: 0.692269, acc.: 48.44%] [G loss: 0.811863]\n",
      "epoch:2 step:1954 [D loss: 0.712151, acc.: 47.66%] [G loss: 0.797197]\n",
      "epoch:2 step:1955 [D loss: 0.694589, acc.: 55.47%] [G loss: 0.776750]\n",
      "epoch:2 step:1956 [D loss: 0.745944, acc.: 38.28%] [G loss: 0.798584]\n",
      "epoch:2 step:1957 [D loss: 0.707712, acc.: 45.31%] [G loss: 0.778463]\n",
      "epoch:2 step:1958 [D loss: 0.708160, acc.: 45.31%] [G loss: 0.724354]\n",
      "epoch:2 step:1959 [D loss: 0.701362, acc.: 51.56%] [G loss: 0.723757]\n",
      "epoch:2 step:1960 [D loss: 0.681598, acc.: 60.94%] [G loss: 0.724305]\n",
      "epoch:2 step:1961 [D loss: 0.684256, acc.: 51.56%] [G loss: 0.740629]\n",
      "epoch:2 step:1962 [D loss: 0.683543, acc.: 53.12%] [G loss: 0.751287]\n",
      "epoch:2 step:1963 [D loss: 0.649151, acc.: 63.28%] [G loss: 0.749856]\n",
      "epoch:2 step:1964 [D loss: 0.668321, acc.: 63.28%] [G loss: 0.705540]\n",
      "epoch:2 step:1965 [D loss: 0.663031, acc.: 69.53%] [G loss: 0.755884]\n",
      "epoch:2 step:1966 [D loss: 0.705207, acc.: 53.91%] [G loss: 0.740367]\n",
      "epoch:2 step:1967 [D loss: 0.634551, acc.: 69.53%] [G loss: 0.763989]\n",
      "epoch:2 step:1968 [D loss: 0.670535, acc.: 63.28%] [G loss: 0.790521]\n",
      "epoch:2 step:1969 [D loss: 0.698131, acc.: 52.34%] [G loss: 0.708325]\n",
      "epoch:2 step:1970 [D loss: 0.660933, acc.: 62.50%] [G loss: 0.737209]\n",
      "epoch:2 step:1971 [D loss: 0.671674, acc.: 61.72%] [G loss: 0.726969]\n",
      "epoch:2 step:1972 [D loss: 0.684569, acc.: 57.03%] [G loss: 0.794693]\n",
      "epoch:2 step:1973 [D loss: 0.700702, acc.: 53.91%] [G loss: 0.776565]\n",
      "epoch:2 step:1974 [D loss: 0.676860, acc.: 57.03%] [G loss: 0.722403]\n",
      "epoch:2 step:1975 [D loss: 0.710311, acc.: 47.66%] [G loss: 0.809954]\n",
      "epoch:2 step:1976 [D loss: 0.692398, acc.: 50.78%] [G loss: 0.805662]\n",
      "epoch:2 step:1977 [D loss: 0.666512, acc.: 58.59%] [G loss: 0.802799]\n",
      "epoch:2 step:1978 [D loss: 0.695715, acc.: 52.34%] [G loss: 0.802362]\n",
      "epoch:2 step:1979 [D loss: 0.697728, acc.: 51.56%] [G loss: 0.846948]\n",
      "epoch:2 step:1980 [D loss: 0.654859, acc.: 60.16%] [G loss: 0.877874]\n",
      "epoch:2 step:1981 [D loss: 0.632933, acc.: 67.19%] [G loss: 0.887204]\n",
      "epoch:2 step:1982 [D loss: 0.703922, acc.: 56.25%] [G loss: 0.884508]\n",
      "epoch:2 step:1983 [D loss: 0.724946, acc.: 48.44%] [G loss: 1.029252]\n",
      "epoch:2 step:1984 [D loss: 0.680637, acc.: 57.03%] [G loss: 0.772086]\n",
      "epoch:2 step:1985 [D loss: 0.736420, acc.: 48.44%] [G loss: 0.804847]\n",
      "epoch:2 step:1986 [D loss: 0.704937, acc.: 53.12%] [G loss: 0.732790]\n",
      "epoch:2 step:1987 [D loss: 0.729422, acc.: 39.84%] [G loss: 0.746777]\n",
      "epoch:2 step:1988 [D loss: 0.737455, acc.: 49.22%] [G loss: 0.713900]\n",
      "epoch:2 step:1989 [D loss: 0.678648, acc.: 56.25%] [G loss: 0.719727]\n",
      "epoch:2 step:1990 [D loss: 0.704454, acc.: 54.69%] [G loss: 0.775798]\n",
      "epoch:2 step:1991 [D loss: 0.695156, acc.: 50.78%] [G loss: 0.767865]\n",
      "epoch:2 step:1992 [D loss: 0.706333, acc.: 47.66%] [G loss: 0.785352]\n",
      "epoch:2 step:1993 [D loss: 0.690805, acc.: 54.69%] [G loss: 0.830859]\n",
      "epoch:2 step:1994 [D loss: 0.722084, acc.: 50.78%] [G loss: 0.829746]\n",
      "epoch:2 step:1995 [D loss: 0.676458, acc.: 50.78%] [G loss: 0.886372]\n",
      "epoch:2 step:1996 [D loss: 0.691724, acc.: 55.47%] [G loss: 0.880171]\n",
      "epoch:2 step:1997 [D loss: 0.681358, acc.: 52.34%] [G loss: 0.955173]\n",
      "epoch:2 step:1998 [D loss: 0.650180, acc.: 64.84%] [G loss: 1.116651]\n",
      "epoch:2 step:1999 [D loss: 0.664686, acc.: 57.03%] [G loss: 0.873175]\n",
      "epoch:2 step:2000 [D loss: 0.627355, acc.: 65.62%] [G loss: 0.855487]\n",
      "epoch:2 step:2001 [D loss: 0.660389, acc.: 60.16%] [G loss: 0.823260]\n",
      "epoch:2 step:2002 [D loss: 0.705015, acc.: 51.56%] [G loss: 0.810313]\n",
      "epoch:2 step:2003 [D loss: 0.707663, acc.: 52.34%] [G loss: 0.752485]\n",
      "epoch:2 step:2004 [D loss: 0.641147, acc.: 61.72%] [G loss: 0.755554]\n",
      "epoch:2 step:2005 [D loss: 0.717486, acc.: 50.00%] [G loss: 0.661824]\n",
      "epoch:2 step:2006 [D loss: 0.701803, acc.: 48.44%] [G loss: 0.755365]\n",
      "epoch:2 step:2007 [D loss: 0.693481, acc.: 50.78%] [G loss: 0.711185]\n",
      "epoch:2 step:2008 [D loss: 0.701135, acc.: 49.22%] [G loss: 0.753095]\n",
      "epoch:2 step:2009 [D loss: 0.717277, acc.: 46.09%] [G loss: 0.710401]\n",
      "epoch:2 step:2010 [D loss: 0.695172, acc.: 50.00%] [G loss: 0.713957]\n",
      "epoch:2 step:2011 [D loss: 0.676128, acc.: 53.91%] [G loss: 0.740892]\n",
      "epoch:2 step:2012 [D loss: 0.698425, acc.: 51.56%] [G loss: 0.794235]\n",
      "epoch:2 step:2013 [D loss: 0.686333, acc.: 59.38%] [G loss: 0.869942]\n",
      "epoch:2 step:2014 [D loss: 0.654024, acc.: 57.81%] [G loss: 0.860700]\n",
      "epoch:2 step:2015 [D loss: 0.684732, acc.: 51.56%] [G loss: 0.831216]\n",
      "epoch:2 step:2016 [D loss: 0.717879, acc.: 48.44%] [G loss: 0.909316]\n",
      "epoch:2 step:2017 [D loss: 0.675308, acc.: 57.81%] [G loss: 0.826946]\n",
      "epoch:2 step:2018 [D loss: 0.685327, acc.: 61.72%] [G loss: 0.780210]\n",
      "epoch:2 step:2019 [D loss: 0.677095, acc.: 57.81%] [G loss: 0.779909]\n",
      "epoch:2 step:2020 [D loss: 0.692880, acc.: 53.12%] [G loss: 0.775811]\n",
      "epoch:2 step:2021 [D loss: 0.736196, acc.: 39.84%] [G loss: 0.708012]\n",
      "epoch:2 step:2022 [D loss: 0.746422, acc.: 39.06%] [G loss: 0.734146]\n",
      "epoch:2 step:2023 [D loss: 0.724843, acc.: 46.88%] [G loss: 0.767776]\n",
      "epoch:2 step:2024 [D loss: 0.706993, acc.: 55.47%] [G loss: 0.763176]\n",
      "epoch:2 step:2025 [D loss: 0.688667, acc.: 57.81%] [G loss: 0.798216]\n",
      "epoch:2 step:2026 [D loss: 0.670646, acc.: 61.72%] [G loss: 0.765764]\n",
      "epoch:2 step:2027 [D loss: 0.715108, acc.: 55.47%] [G loss: 0.765280]\n",
      "epoch:2 step:2028 [D loss: 0.704176, acc.: 55.47%] [G loss: 0.761897]\n",
      "epoch:2 step:2029 [D loss: 0.704821, acc.: 46.88%] [G loss: 0.798607]\n",
      "epoch:2 step:2030 [D loss: 0.726842, acc.: 43.75%] [G loss: 0.775394]\n",
      "epoch:2 step:2031 [D loss: 0.685156, acc.: 58.59%] [G loss: 0.810122]\n",
      "epoch:2 step:2032 [D loss: 0.675268, acc.: 55.47%] [G loss: 0.758333]\n",
      "epoch:2 step:2033 [D loss: 0.680651, acc.: 55.47%] [G loss: 0.782727]\n",
      "epoch:2 step:2034 [D loss: 0.716357, acc.: 48.44%] [G loss: 0.763605]\n",
      "epoch:2 step:2035 [D loss: 0.690983, acc.: 50.00%] [G loss: 0.738982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2036 [D loss: 0.679156, acc.: 47.66%] [G loss: 0.749446]\n",
      "epoch:2 step:2037 [D loss: 0.723567, acc.: 43.75%] [G loss: 0.756078]\n",
      "epoch:2 step:2038 [D loss: 0.664820, acc.: 55.47%] [G loss: 0.722632]\n",
      "epoch:2 step:2039 [D loss: 0.707489, acc.: 45.31%] [G loss: 0.711396]\n",
      "epoch:2 step:2040 [D loss: 0.689148, acc.: 53.12%] [G loss: 0.712827]\n",
      "epoch:2 step:2041 [D loss: 0.713256, acc.: 42.97%] [G loss: 0.719524]\n",
      "epoch:2 step:2042 [D loss: 0.705382, acc.: 51.56%] [G loss: 0.774263]\n",
      "epoch:2 step:2043 [D loss: 0.741273, acc.: 47.66%] [G loss: 0.714676]\n",
      "epoch:2 step:2044 [D loss: 0.689258, acc.: 52.34%] [G loss: 0.760519]\n",
      "epoch:2 step:2045 [D loss: 0.674904, acc.: 53.91%] [G loss: 0.776244]\n",
      "epoch:2 step:2046 [D loss: 0.745169, acc.: 46.09%] [G loss: 0.811396]\n",
      "epoch:2 step:2047 [D loss: 0.685676, acc.: 53.91%] [G loss: 0.781050]\n",
      "epoch:2 step:2048 [D loss: 0.701423, acc.: 48.44%] [G loss: 0.833958]\n",
      "epoch:2 step:2049 [D loss: 0.699651, acc.: 50.00%] [G loss: 0.829521]\n",
      "epoch:2 step:2050 [D loss: 0.680152, acc.: 56.25%] [G loss: 0.811581]\n",
      "epoch:2 step:2051 [D loss: 0.687508, acc.: 53.12%] [G loss: 0.874695]\n",
      "epoch:2 step:2052 [D loss: 0.705567, acc.: 49.22%] [G loss: 0.806264]\n",
      "epoch:2 step:2053 [D loss: 0.689085, acc.: 57.81%] [G loss: 0.800456]\n",
      "epoch:2 step:2054 [D loss: 0.702763, acc.: 49.22%] [G loss: 0.789599]\n",
      "epoch:2 step:2055 [D loss: 0.706564, acc.: 53.91%] [G loss: 0.723020]\n",
      "epoch:2 step:2056 [D loss: 0.697557, acc.: 57.81%] [G loss: 0.791729]\n",
      "epoch:2 step:2057 [D loss: 0.693912, acc.: 51.56%] [G loss: 0.748517]\n",
      "epoch:2 step:2058 [D loss: 0.627777, acc.: 68.75%] [G loss: 0.780656]\n",
      "epoch:2 step:2059 [D loss: 0.660703, acc.: 60.94%] [G loss: 0.727591]\n",
      "epoch:2 step:2060 [D loss: 0.685672, acc.: 52.34%] [G loss: 0.707643]\n",
      "epoch:2 step:2061 [D loss: 0.628885, acc.: 60.16%] [G loss: 0.731225]\n",
      "epoch:2 step:2062 [D loss: 0.758711, acc.: 39.84%] [G loss: 0.761883]\n",
      "epoch:2 step:2063 [D loss: 0.687864, acc.: 52.34%] [G loss: 0.755085]\n",
      "epoch:2 step:2064 [D loss: 0.681123, acc.: 50.78%] [G loss: 0.773241]\n",
      "epoch:2 step:2065 [D loss: 0.681071, acc.: 57.81%] [G loss: 0.823756]\n",
      "epoch:2 step:2066 [D loss: 0.668320, acc.: 56.25%] [G loss: 0.825722]\n",
      "epoch:2 step:2067 [D loss: 0.724542, acc.: 46.88%] [G loss: 0.767338]\n",
      "epoch:2 step:2068 [D loss: 0.677569, acc.: 56.25%] [G loss: 0.804495]\n",
      "epoch:2 step:2069 [D loss: 0.752523, acc.: 48.44%] [G loss: 0.934657]\n",
      "epoch:2 step:2070 [D loss: 0.716833, acc.: 47.66%] [G loss: 0.835432]\n",
      "epoch:2 step:2071 [D loss: 0.739006, acc.: 46.88%] [G loss: 0.869992]\n",
      "epoch:2 step:2072 [D loss: 0.688635, acc.: 56.25%] [G loss: 0.784522]\n",
      "epoch:2 step:2073 [D loss: 0.729727, acc.: 42.19%] [G loss: 0.828094]\n",
      "epoch:2 step:2074 [D loss: 0.721888, acc.: 48.44%] [G loss: 0.795287]\n",
      "epoch:2 step:2075 [D loss: 0.715265, acc.: 46.88%] [G loss: 1.141239]\n",
      "epoch:2 step:2076 [D loss: 0.663065, acc.: 55.47%] [G loss: 0.965893]\n",
      "epoch:2 step:2077 [D loss: 0.706376, acc.: 59.38%] [G loss: 0.864511]\n",
      "epoch:2 step:2078 [D loss: 0.726962, acc.: 48.44%] [G loss: 0.804455]\n",
      "epoch:2 step:2079 [D loss: 0.676110, acc.: 58.59%] [G loss: 0.774588]\n",
      "epoch:2 step:2080 [D loss: 0.652110, acc.: 61.72%] [G loss: 0.817206]\n",
      "epoch:2 step:2081 [D loss: 0.678178, acc.: 56.25%] [G loss: 0.796668]\n",
      "epoch:2 step:2082 [D loss: 0.701201, acc.: 60.16%] [G loss: 0.796096]\n",
      "epoch:2 step:2083 [D loss: 0.663049, acc.: 66.41%] [G loss: 0.822865]\n",
      "epoch:2 step:2084 [D loss: 0.694966, acc.: 51.56%] [G loss: 0.794846]\n",
      "epoch:2 step:2085 [D loss: 0.691720, acc.: 50.78%] [G loss: 0.833738]\n",
      "epoch:2 step:2086 [D loss: 0.685574, acc.: 53.91%] [G loss: 0.748863]\n",
      "epoch:2 step:2087 [D loss: 0.711771, acc.: 50.00%] [G loss: 0.755078]\n",
      "epoch:2 step:2088 [D loss: 0.698575, acc.: 53.91%] [G loss: 0.776662]\n",
      "epoch:2 step:2089 [D loss: 0.720844, acc.: 40.62%] [G loss: 0.735991]\n",
      "epoch:2 step:2090 [D loss: 0.653942, acc.: 59.38%] [G loss: 0.741197]\n",
      "epoch:2 step:2091 [D loss: 0.686164, acc.: 53.12%] [G loss: 0.706058]\n",
      "epoch:2 step:2092 [D loss: 0.674329, acc.: 60.94%] [G loss: 0.737369]\n",
      "epoch:2 step:2093 [D loss: 0.721639, acc.: 50.00%] [G loss: 0.744472]\n",
      "epoch:2 step:2094 [D loss: 0.753026, acc.: 32.81%] [G loss: 0.740315]\n",
      "epoch:2 step:2095 [D loss: 0.734022, acc.: 43.75%] [G loss: 0.737345]\n",
      "epoch:2 step:2096 [D loss: 0.696926, acc.: 50.00%] [G loss: 0.856465]\n",
      "epoch:2 step:2097 [D loss: 0.662830, acc.: 56.25%] [G loss: 0.850828]\n",
      "epoch:2 step:2098 [D loss: 0.698465, acc.: 54.69%] [G loss: 0.832716]\n",
      "epoch:2 step:2099 [D loss: 0.734261, acc.: 52.34%] [G loss: 0.863867]\n",
      "epoch:2 step:2100 [D loss: 0.688829, acc.: 54.69%] [G loss: 1.021651]\n",
      "epoch:2 step:2101 [D loss: 0.676283, acc.: 55.47%] [G loss: 0.738637]\n",
      "epoch:2 step:2102 [D loss: 0.703049, acc.: 50.78%] [G loss: 0.789747]\n",
      "epoch:2 step:2103 [D loss: 0.679247, acc.: 60.16%] [G loss: 0.793671]\n",
      "epoch:2 step:2104 [D loss: 0.605416, acc.: 82.81%] [G loss: 0.843741]\n",
      "epoch:2 step:2105 [D loss: 0.621113, acc.: 71.09%] [G loss: 0.805326]\n",
      "epoch:2 step:2106 [D loss: 0.601028, acc.: 73.44%] [G loss: 0.930201]\n",
      "epoch:2 step:2107 [D loss: 0.728069, acc.: 42.97%] [G loss: 0.834947]\n",
      "epoch:2 step:2108 [D loss: 0.712496, acc.: 53.12%] [G loss: 0.773496]\n",
      "epoch:2 step:2109 [D loss: 0.700691, acc.: 51.56%] [G loss: 0.867801]\n",
      "epoch:2 step:2110 [D loss: 0.756630, acc.: 42.19%] [G loss: 0.776254]\n",
      "epoch:2 step:2111 [D loss: 0.691077, acc.: 52.34%] [G loss: 0.723398]\n",
      "epoch:2 step:2112 [D loss: 0.732315, acc.: 44.53%] [G loss: 0.711451]\n",
      "epoch:2 step:2113 [D loss: 0.750619, acc.: 29.69%] [G loss: 0.719697]\n",
      "epoch:2 step:2114 [D loss: 0.714868, acc.: 47.66%] [G loss: 0.781135]\n",
      "epoch:2 step:2115 [D loss: 0.731785, acc.: 42.19%] [G loss: 0.730315]\n",
      "epoch:2 step:2116 [D loss: 0.686499, acc.: 51.56%] [G loss: 0.769803]\n",
      "epoch:2 step:2117 [D loss: 0.672631, acc.: 56.25%] [G loss: 0.770376]\n",
      "epoch:2 step:2118 [D loss: 0.670938, acc.: 61.72%] [G loss: 0.752760]\n",
      "epoch:2 step:2119 [D loss: 0.677297, acc.: 56.25%] [G loss: 0.752758]\n",
      "epoch:2 step:2120 [D loss: 0.696399, acc.: 51.56%] [G loss: 0.772686]\n",
      "epoch:2 step:2121 [D loss: 0.704946, acc.: 48.44%] [G loss: 0.738730]\n",
      "epoch:2 step:2122 [D loss: 0.643170, acc.: 64.06%] [G loss: 0.794501]\n",
      "epoch:2 step:2123 [D loss: 0.701853, acc.: 55.47%] [G loss: 0.773793]\n",
      "epoch:2 step:2124 [D loss: 0.663627, acc.: 64.06%] [G loss: 0.860738]\n",
      "epoch:2 step:2125 [D loss: 0.667051, acc.: 57.81%] [G loss: 0.770123]\n",
      "epoch:2 step:2126 [D loss: 0.643896, acc.: 65.62%] [G loss: 0.816697]\n",
      "epoch:2 step:2127 [D loss: 0.642914, acc.: 62.50%] [G loss: 0.827836]\n",
      "epoch:2 step:2128 [D loss: 0.665526, acc.: 64.06%] [G loss: 0.791668]\n",
      "epoch:2 step:2129 [D loss: 0.670969, acc.: 60.16%] [G loss: 0.854298]\n",
      "epoch:2 step:2130 [D loss: 0.679698, acc.: 53.12%] [G loss: 0.790854]\n",
      "epoch:2 step:2131 [D loss: 0.664705, acc.: 60.16%] [G loss: 0.804359]\n",
      "epoch:2 step:2132 [D loss: 0.671475, acc.: 59.38%] [G loss: 0.715263]\n",
      "epoch:2 step:2133 [D loss: 0.703745, acc.: 52.34%] [G loss: 0.784742]\n",
      "epoch:2 step:2134 [D loss: 0.772853, acc.: 36.72%] [G loss: 0.729363]\n",
      "epoch:2 step:2135 [D loss: 0.722533, acc.: 46.88%] [G loss: 0.534968]\n",
      "epoch:2 step:2136 [D loss: 0.711903, acc.: 50.00%] [G loss: 0.765662]\n",
      "epoch:2 step:2137 [D loss: 0.753558, acc.: 51.56%] [G loss: 0.796652]\n",
      "epoch:2 step:2138 [D loss: 0.632566, acc.: 73.44%] [G loss: 0.893254]\n",
      "epoch:2 step:2139 [D loss: 0.771485, acc.: 39.06%] [G loss: 0.814973]\n",
      "epoch:2 step:2140 [D loss: 0.708590, acc.: 49.22%] [G loss: 0.816228]\n",
      "epoch:2 step:2141 [D loss: 0.701986, acc.: 50.78%] [G loss: 0.800698]\n",
      "epoch:2 step:2142 [D loss: 0.679222, acc.: 50.78%] [G loss: 0.788357]\n",
      "epoch:2 step:2143 [D loss: 0.681760, acc.: 53.12%] [G loss: 0.738233]\n",
      "epoch:2 step:2144 [D loss: 0.698791, acc.: 47.66%] [G loss: 0.757559]\n",
      "epoch:2 step:2145 [D loss: 0.695266, acc.: 56.25%] [G loss: 0.814965]\n",
      "epoch:2 step:2146 [D loss: 0.691197, acc.: 56.25%] [G loss: 0.759471]\n",
      "epoch:2 step:2147 [D loss: 0.663549, acc.: 60.16%] [G loss: 0.732679]\n",
      "epoch:2 step:2148 [D loss: 0.706743, acc.: 54.69%] [G loss: 0.711285]\n",
      "epoch:2 step:2149 [D loss: 0.713593, acc.: 47.66%] [G loss: 0.779369]\n",
      "epoch:2 step:2150 [D loss: 0.690862, acc.: 55.47%] [G loss: 0.795546]\n",
      "epoch:2 step:2151 [D loss: 0.688578, acc.: 50.00%] [G loss: 0.792172]\n",
      "epoch:2 step:2152 [D loss: 0.733113, acc.: 40.62%] [G loss: 0.838142]\n",
      "epoch:2 step:2153 [D loss: 0.726882, acc.: 42.97%] [G loss: 0.824669]\n",
      "epoch:2 step:2154 [D loss: 0.672115, acc.: 54.69%] [G loss: 0.912296]\n",
      "epoch:2 step:2155 [D loss: 0.730689, acc.: 43.75%] [G loss: 0.776135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2156 [D loss: 0.715753, acc.: 42.19%] [G loss: 0.775305]\n",
      "epoch:2 step:2157 [D loss: 0.684574, acc.: 53.12%] [G loss: 0.775252]\n",
      "epoch:2 step:2158 [D loss: 0.676740, acc.: 56.25%] [G loss: 0.752668]\n",
      "epoch:2 step:2159 [D loss: 0.686482, acc.: 52.34%] [G loss: 0.772783]\n",
      "epoch:2 step:2160 [D loss: 0.660687, acc.: 62.50%] [G loss: 0.766548]\n",
      "epoch:2 step:2161 [D loss: 0.679974, acc.: 56.25%] [G loss: 0.779798]\n",
      "epoch:2 step:2162 [D loss: 0.669496, acc.: 60.94%] [G loss: 0.788640]\n",
      "epoch:2 step:2163 [D loss: 0.679531, acc.: 64.84%] [G loss: 0.753180]\n",
      "epoch:2 step:2164 [D loss: 0.695924, acc.: 50.00%] [G loss: 0.799720]\n",
      "epoch:2 step:2165 [D loss: 0.740999, acc.: 46.09%] [G loss: 0.728396]\n",
      "epoch:2 step:2166 [D loss: 0.674017, acc.: 58.59%] [G loss: 0.736897]\n",
      "epoch:2 step:2167 [D loss: 0.672966, acc.: 53.91%] [G loss: 0.813410]\n",
      "epoch:2 step:2168 [D loss: 0.723668, acc.: 42.97%] [G loss: 0.719619]\n",
      "epoch:2 step:2169 [D loss: 0.736140, acc.: 44.53%] [G loss: 0.723683]\n",
      "epoch:2 step:2170 [D loss: 0.717336, acc.: 48.44%] [G loss: 0.758783]\n",
      "epoch:2 step:2171 [D loss: 0.747819, acc.: 39.84%] [G loss: 0.758899]\n",
      "epoch:2 step:2172 [D loss: 0.719035, acc.: 48.44%] [G loss: 0.733214]\n",
      "epoch:2 step:2173 [D loss: 0.693025, acc.: 55.47%] [G loss: 0.712034]\n",
      "epoch:2 step:2174 [D loss: 0.715955, acc.: 41.41%] [G loss: 0.759325]\n",
      "epoch:2 step:2175 [D loss: 0.682881, acc.: 54.69%] [G loss: 0.746377]\n",
      "epoch:2 step:2176 [D loss: 0.676645, acc.: 60.16%] [G loss: 0.767550]\n",
      "epoch:2 step:2177 [D loss: 0.679048, acc.: 59.38%] [G loss: 0.775114]\n",
      "epoch:2 step:2178 [D loss: 0.706816, acc.: 53.12%] [G loss: 0.732227]\n",
      "epoch:2 step:2179 [D loss: 0.676446, acc.: 57.81%] [G loss: 0.792359]\n",
      "epoch:2 step:2180 [D loss: 0.685483, acc.: 51.56%] [G loss: 0.754457]\n",
      "epoch:2 step:2181 [D loss: 0.703454, acc.: 45.31%] [G loss: 0.733207]\n",
      "epoch:2 step:2182 [D loss: 0.675474, acc.: 59.38%] [G loss: 0.780584]\n",
      "epoch:2 step:2183 [D loss: 0.693209, acc.: 50.00%] [G loss: 0.736652]\n",
      "epoch:2 step:2184 [D loss: 0.679699, acc.: 60.16%] [G loss: 0.759463]\n",
      "epoch:2 step:2185 [D loss: 0.688670, acc.: 52.34%] [G loss: 0.744219]\n",
      "epoch:2 step:2186 [D loss: 0.712991, acc.: 45.31%] [G loss: 0.791705]\n",
      "epoch:2 step:2187 [D loss: 0.721364, acc.: 43.75%] [G loss: 0.762227]\n",
      "epoch:2 step:2188 [D loss: 0.717837, acc.: 45.31%] [G loss: 0.754570]\n",
      "epoch:2 step:2189 [D loss: 0.685526, acc.: 53.12%] [G loss: 0.751073]\n",
      "epoch:2 step:2190 [D loss: 0.703251, acc.: 54.69%] [G loss: 0.784979]\n",
      "epoch:2 step:2191 [D loss: 0.683878, acc.: 59.38%] [G loss: 0.770647]\n",
      "epoch:2 step:2192 [D loss: 0.667310, acc.: 59.38%] [G loss: 0.758721]\n",
      "epoch:2 step:2193 [D loss: 0.682211, acc.: 57.81%] [G loss: 0.744680]\n",
      "epoch:2 step:2194 [D loss: 0.683469, acc.: 52.34%] [G loss: 0.773874]\n",
      "epoch:2 step:2195 [D loss: 0.688876, acc.: 48.44%] [G loss: 0.778553]\n",
      "epoch:2 step:2196 [D loss: 0.688031, acc.: 57.03%] [G loss: 0.699846]\n",
      "epoch:2 step:2197 [D loss: 0.656282, acc.: 61.72%] [G loss: 0.718555]\n",
      "epoch:2 step:2198 [D loss: 0.636742, acc.: 64.06%] [G loss: 0.845040]\n",
      "epoch:2 step:2199 [D loss: 0.697115, acc.: 49.22%] [G loss: 0.760257]\n",
      "epoch:2 step:2200 [D loss: 0.708819, acc.: 46.88%] [G loss: 0.713921]\n",
      "epoch:2 step:2201 [D loss: 0.677435, acc.: 60.16%] [G loss: 0.749678]\n",
      "epoch:2 step:2202 [D loss: 0.694567, acc.: 52.34%] [G loss: 0.725772]\n",
      "epoch:2 step:2203 [D loss: 0.698660, acc.: 50.78%] [G loss: 0.778254]\n",
      "epoch:2 step:2204 [D loss: 0.684709, acc.: 53.91%] [G loss: 0.748752]\n",
      "epoch:2 step:2205 [D loss: 0.731492, acc.: 44.53%] [G loss: 0.681039]\n",
      "epoch:2 step:2206 [D loss: 0.706101, acc.: 53.12%] [G loss: 0.776636]\n",
      "epoch:2 step:2207 [D loss: 0.714305, acc.: 52.34%] [G loss: 0.777680]\n",
      "epoch:2 step:2208 [D loss: 0.727610, acc.: 46.88%] [G loss: 0.809404]\n",
      "epoch:2 step:2209 [D loss: 0.705298, acc.: 53.12%] [G loss: 0.811293]\n",
      "epoch:2 step:2210 [D loss: 0.676446, acc.: 54.69%] [G loss: 0.848182]\n",
      "epoch:2 step:2211 [D loss: 0.670651, acc.: 50.78%] [G loss: 0.865952]\n",
      "epoch:2 step:2212 [D loss: 0.624056, acc.: 64.06%] [G loss: 1.079201]\n",
      "epoch:2 step:2213 [D loss: 0.677949, acc.: 56.25%] [G loss: 0.743738]\n",
      "epoch:2 step:2214 [D loss: 0.715205, acc.: 52.34%] [G loss: 0.820978]\n",
      "epoch:2 step:2215 [D loss: 0.688730, acc.: 51.56%] [G loss: 0.864752]\n",
      "epoch:2 step:2216 [D loss: 0.672254, acc.: 63.28%] [G loss: 0.747092]\n",
      "epoch:2 step:2217 [D loss: 0.644278, acc.: 65.62%] [G loss: 0.753266]\n",
      "epoch:2 step:2218 [D loss: 0.675268, acc.: 54.69%] [G loss: 0.728004]\n",
      "epoch:2 step:2219 [D loss: 0.704686, acc.: 50.00%] [G loss: 0.806589]\n",
      "epoch:2 step:2220 [D loss: 0.677210, acc.: 54.69%] [G loss: 0.854835]\n",
      "epoch:2 step:2221 [D loss: 0.665853, acc.: 57.03%] [G loss: 0.828886]\n",
      "epoch:2 step:2222 [D loss: 0.760502, acc.: 45.31%] [G loss: 0.790978]\n",
      "epoch:2 step:2223 [D loss: 0.765080, acc.: 38.28%] [G loss: 0.768383]\n",
      "epoch:2 step:2224 [D loss: 0.707928, acc.: 46.09%] [G loss: 0.755687]\n",
      "epoch:2 step:2225 [D loss: 0.730918, acc.: 50.00%] [G loss: 0.742579]\n",
      "epoch:2 step:2226 [D loss: 0.719377, acc.: 42.19%] [G loss: 0.753270]\n",
      "epoch:2 step:2227 [D loss: 0.715669, acc.: 46.88%] [G loss: 0.738403]\n",
      "epoch:2 step:2228 [D loss: 0.703845, acc.: 49.22%] [G loss: 0.772459]\n",
      "epoch:2 step:2229 [D loss: 0.686512, acc.: 56.25%] [G loss: 0.773230]\n",
      "epoch:2 step:2230 [D loss: 0.669469, acc.: 56.25%] [G loss: 0.741022]\n",
      "epoch:2 step:2231 [D loss: 0.686631, acc.: 58.59%] [G loss: 0.775690]\n",
      "epoch:2 step:2232 [D loss: 0.693429, acc.: 58.59%] [G loss: 0.685844]\n",
      "epoch:2 step:2233 [D loss: 0.692853, acc.: 57.03%] [G loss: 0.673052]\n",
      "epoch:2 step:2234 [D loss: 0.692534, acc.: 51.56%] [G loss: 0.740246]\n",
      "epoch:2 step:2235 [D loss: 0.722819, acc.: 51.56%] [G loss: 0.797993]\n",
      "epoch:2 step:2236 [D loss: 0.707018, acc.: 48.44%] [G loss: 0.791280]\n",
      "epoch:2 step:2237 [D loss: 0.696794, acc.: 53.12%] [G loss: 0.729951]\n",
      "epoch:2 step:2238 [D loss: 0.653342, acc.: 58.59%] [G loss: 0.807476]\n",
      "epoch:2 step:2239 [D loss: 0.717429, acc.: 46.88%] [G loss: 0.728921]\n",
      "epoch:2 step:2240 [D loss: 0.726949, acc.: 39.06%] [G loss: 0.717608]\n",
      "epoch:2 step:2241 [D loss: 0.696186, acc.: 46.09%] [G loss: 0.786342]\n",
      "epoch:2 step:2242 [D loss: 0.696525, acc.: 48.44%] [G loss: 0.843633]\n",
      "epoch:2 step:2243 [D loss: 0.660998, acc.: 61.72%] [G loss: 0.838228]\n",
      "epoch:2 step:2244 [D loss: 0.668660, acc.: 61.72%] [G loss: 0.838033]\n",
      "epoch:2 step:2245 [D loss: 0.632383, acc.: 64.84%] [G loss: 0.870434]\n",
      "epoch:2 step:2246 [D loss: 0.653507, acc.: 62.50%] [G loss: 0.834688]\n",
      "epoch:2 step:2247 [D loss: 0.712167, acc.: 48.44%] [G loss: 0.755946]\n",
      "epoch:2 step:2248 [D loss: 0.692621, acc.: 57.03%] [G loss: 0.810621]\n",
      "epoch:2 step:2249 [D loss: 0.683136, acc.: 60.16%] [G loss: 0.790684]\n",
      "epoch:2 step:2250 [D loss: 0.735501, acc.: 46.09%] [G loss: 0.720105]\n",
      "epoch:2 step:2251 [D loss: 0.759391, acc.: 42.97%] [G loss: 0.711150]\n",
      "epoch:2 step:2252 [D loss: 0.686459, acc.: 53.91%] [G loss: 0.741598]\n",
      "epoch:2 step:2253 [D loss: 0.687606, acc.: 55.47%] [G loss: 0.689729]\n",
      "epoch:2 step:2254 [D loss: 0.691399, acc.: 50.00%] [G loss: 0.726232]\n",
      "epoch:2 step:2255 [D loss: 0.686493, acc.: 64.84%] [G loss: 0.669229]\n",
      "epoch:2 step:2256 [D loss: 0.678360, acc.: 53.12%] [G loss: 0.741192]\n",
      "epoch:2 step:2257 [D loss: 0.724746, acc.: 43.75%] [G loss: 0.599319]\n",
      "epoch:2 step:2258 [D loss: 0.692038, acc.: 51.56%] [G loss: 0.688053]\n",
      "epoch:2 step:2259 [D loss: 0.695383, acc.: 48.44%] [G loss: 0.658225]\n",
      "epoch:2 step:2260 [D loss: 0.692674, acc.: 54.69%] [G loss: 0.820423]\n",
      "epoch:2 step:2261 [D loss: 0.669221, acc.: 60.16%] [G loss: 0.694543]\n",
      "epoch:2 step:2262 [D loss: 0.678028, acc.: 58.59%] [G loss: 0.774867]\n",
      "epoch:2 step:2263 [D loss: 0.708363, acc.: 52.34%] [G loss: 0.773698]\n",
      "epoch:2 step:2264 [D loss: 0.756772, acc.: 32.81%] [G loss: 0.934262]\n",
      "epoch:2 step:2265 [D loss: 0.689175, acc.: 47.66%] [G loss: 0.870468]\n",
      "epoch:2 step:2266 [D loss: 0.701618, acc.: 48.44%] [G loss: 0.910312]\n",
      "epoch:2 step:2267 [D loss: 0.704728, acc.: 50.78%] [G loss: 1.102223]\n",
      "epoch:2 step:2268 [D loss: 0.710281, acc.: 46.88%] [G loss: 0.770066]\n",
      "epoch:2 step:2269 [D loss: 0.704288, acc.: 50.78%] [G loss: 0.977107]\n",
      "epoch:2 step:2270 [D loss: 0.669518, acc.: 56.25%] [G loss: 0.766106]\n",
      "epoch:2 step:2271 [D loss: 0.645781, acc.: 64.06%] [G loss: 0.830102]\n",
      "epoch:2 step:2272 [D loss: 0.651109, acc.: 67.19%] [G loss: 0.835468]\n",
      "epoch:2 step:2273 [D loss: 0.687172, acc.: 54.69%] [G loss: 0.751623]\n",
      "epoch:2 step:2274 [D loss: 0.704040, acc.: 51.56%] [G loss: 0.844970]\n",
      "epoch:2 step:2275 [D loss: 0.681634, acc.: 49.22%] [G loss: 0.753702]\n",
      "epoch:2 step:2276 [D loss: 0.635819, acc.: 67.19%] [G loss: 0.790453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2277 [D loss: 0.704168, acc.: 53.12%] [G loss: 0.789112]\n",
      "epoch:2 step:2278 [D loss: 0.639030, acc.: 69.53%] [G loss: 0.848674]\n",
      "epoch:2 step:2279 [D loss: 0.659604, acc.: 65.62%] [G loss: 0.821750]\n",
      "epoch:2 step:2280 [D loss: 0.645859, acc.: 61.72%] [G loss: 0.823794]\n",
      "epoch:2 step:2281 [D loss: 0.685831, acc.: 58.59%] [G loss: 0.757086]\n",
      "epoch:2 step:2282 [D loss: 0.723635, acc.: 48.44%] [G loss: 0.776517]\n",
      "epoch:2 step:2283 [D loss: 0.671231, acc.: 58.59%] [G loss: 0.861553]\n",
      "epoch:2 step:2284 [D loss: 0.729852, acc.: 50.00%] [G loss: 0.749559]\n",
      "epoch:2 step:2285 [D loss: 0.739768, acc.: 43.75%] [G loss: 0.720188]\n",
      "epoch:2 step:2286 [D loss: 0.693910, acc.: 52.34%] [G loss: 0.731797]\n",
      "epoch:2 step:2287 [D loss: 0.736710, acc.: 50.00%] [G loss: 0.714694]\n",
      "epoch:2 step:2288 [D loss: 0.694158, acc.: 50.00%] [G loss: 0.728151]\n",
      "epoch:2 step:2289 [D loss: 0.688470, acc.: 55.47%] [G loss: 0.741277]\n",
      "epoch:2 step:2290 [D loss: 0.693890, acc.: 53.91%] [G loss: 0.741998]\n",
      "epoch:2 step:2291 [D loss: 0.687218, acc.: 53.91%] [G loss: 0.762835]\n",
      "epoch:2 step:2292 [D loss: 0.706776, acc.: 55.47%] [G loss: 0.778278]\n",
      "epoch:2 step:2293 [D loss: 0.651072, acc.: 64.84%] [G loss: 0.808266]\n",
      "epoch:2 step:2294 [D loss: 0.672983, acc.: 60.16%] [G loss: 0.853319]\n",
      "epoch:2 step:2295 [D loss: 0.679778, acc.: 57.03%] [G loss: 0.906962]\n",
      "epoch:2 step:2296 [D loss: 0.661035, acc.: 57.03%] [G loss: 0.830033]\n",
      "epoch:2 step:2297 [D loss: 0.697663, acc.: 50.78%] [G loss: 0.811571]\n",
      "epoch:2 step:2298 [D loss: 0.710202, acc.: 51.56%] [G loss: 0.787404]\n",
      "epoch:2 step:2299 [D loss: 0.674927, acc.: 54.69%] [G loss: 0.796022]\n",
      "epoch:2 step:2300 [D loss: 0.674012, acc.: 55.47%] [G loss: 0.775835]\n",
      "epoch:2 step:2301 [D loss: 0.707725, acc.: 50.78%] [G loss: 0.783740]\n",
      "epoch:2 step:2302 [D loss: 0.686387, acc.: 53.12%] [G loss: 0.813778]\n",
      "epoch:2 step:2303 [D loss: 0.692599, acc.: 58.59%] [G loss: 0.753968]\n",
      "epoch:2 step:2304 [D loss: 0.717116, acc.: 46.09%] [G loss: 0.754133]\n",
      "epoch:2 step:2305 [D loss: 0.751528, acc.: 44.53%] [G loss: 0.736469]\n",
      "epoch:2 step:2306 [D loss: 0.702171, acc.: 50.00%] [G loss: 0.825523]\n",
      "epoch:2 step:2307 [D loss: 0.678242, acc.: 59.38%] [G loss: 0.738468]\n",
      "epoch:2 step:2308 [D loss: 0.679679, acc.: 62.50%] [G loss: 0.787889]\n",
      "epoch:2 step:2309 [D loss: 0.674859, acc.: 60.16%] [G loss: 0.791317]\n",
      "epoch:2 step:2310 [D loss: 0.642850, acc.: 64.84%] [G loss: 0.835444]\n",
      "epoch:2 step:2311 [D loss: 0.696239, acc.: 54.69%] [G loss: 0.762335]\n",
      "epoch:2 step:2312 [D loss: 0.712427, acc.: 49.22%] [G loss: 0.760697]\n",
      "epoch:2 step:2313 [D loss: 0.695858, acc.: 53.91%] [G loss: 0.793952]\n",
      "epoch:2 step:2314 [D loss: 0.702518, acc.: 47.66%] [G loss: 0.769945]\n",
      "epoch:2 step:2315 [D loss: 0.726751, acc.: 42.19%] [G loss: 0.757100]\n",
      "epoch:2 step:2316 [D loss: 0.707755, acc.: 50.00%] [G loss: 0.754965]\n",
      "epoch:2 step:2317 [D loss: 0.671752, acc.: 60.94%] [G loss: 0.719163]\n",
      "epoch:2 step:2318 [D loss: 0.681800, acc.: 56.25%] [G loss: 0.729879]\n",
      "epoch:2 step:2319 [D loss: 0.662817, acc.: 61.72%] [G loss: 0.736220]\n",
      "epoch:2 step:2320 [D loss: 0.662916, acc.: 64.84%] [G loss: 0.661884]\n",
      "epoch:2 step:2321 [D loss: 0.705438, acc.: 50.78%] [G loss: 0.726579]\n",
      "epoch:2 step:2322 [D loss: 0.725688, acc.: 50.00%] [G loss: 0.731690]\n",
      "epoch:2 step:2323 [D loss: 0.702510, acc.: 53.12%] [G loss: 0.839464]\n",
      "epoch:2 step:2324 [D loss: 0.654192, acc.: 65.62%] [G loss: 0.774737]\n",
      "epoch:2 step:2325 [D loss: 0.668682, acc.: 58.59%] [G loss: 0.783195]\n",
      "epoch:2 step:2326 [D loss: 0.666524, acc.: 60.94%] [G loss: 0.710962]\n",
      "epoch:2 step:2327 [D loss: 0.727541, acc.: 50.00%] [G loss: 0.826546]\n",
      "epoch:2 step:2328 [D loss: 0.692818, acc.: 50.78%] [G loss: 0.762116]\n",
      "epoch:2 step:2329 [D loss: 0.710442, acc.: 47.66%] [G loss: 0.851876]\n",
      "epoch:2 step:2330 [D loss: 0.671283, acc.: 57.03%] [G loss: 0.666797]\n",
      "epoch:2 step:2331 [D loss: 0.620350, acc.: 77.34%] [G loss: 0.850380]\n",
      "epoch:2 step:2332 [D loss: 0.721601, acc.: 42.19%] [G loss: 0.760146]\n",
      "epoch:2 step:2333 [D loss: 0.715391, acc.: 50.78%] [G loss: 0.732516]\n",
      "epoch:2 step:2334 [D loss: 0.741629, acc.: 39.06%] [G loss: 0.815068]\n",
      "epoch:2 step:2335 [D loss: 0.684510, acc.: 55.47%] [G loss: 0.788621]\n",
      "epoch:2 step:2336 [D loss: 0.744614, acc.: 32.03%] [G loss: 0.743968]\n",
      "epoch:2 step:2337 [D loss: 0.713819, acc.: 46.09%] [G loss: 0.778346]\n",
      "epoch:2 step:2338 [D loss: 0.676072, acc.: 60.94%] [G loss: 0.847508]\n",
      "epoch:2 step:2339 [D loss: 0.704434, acc.: 47.66%] [G loss: 0.860727]\n",
      "epoch:2 step:2340 [D loss: 0.720110, acc.: 46.88%] [G loss: 0.856803]\n",
      "epoch:2 step:2341 [D loss: 0.738743, acc.: 50.78%] [G loss: 0.932185]\n",
      "epoch:2 step:2342 [D loss: 0.700651, acc.: 48.44%] [G loss: 0.858216]\n",
      "epoch:2 step:2343 [D loss: 0.666293, acc.: 57.03%] [G loss: 0.875494]\n",
      "epoch:2 step:2344 [D loss: 0.703149, acc.: 55.47%] [G loss: 0.844283]\n",
      "epoch:2 step:2345 [D loss: 0.675653, acc.: 56.25%] [G loss: 0.897265]\n",
      "epoch:2 step:2346 [D loss: 0.695175, acc.: 57.03%] [G loss: 0.774765]\n",
      "epoch:2 step:2347 [D loss: 0.719481, acc.: 46.88%] [G loss: 0.823843]\n",
      "epoch:2 step:2348 [D loss: 0.655532, acc.: 59.38%] [G loss: 0.908007]\n",
      "epoch:2 step:2349 [D loss: 0.638339, acc.: 57.03%] [G loss: 1.062704]\n",
      "epoch:2 step:2350 [D loss: 0.716082, acc.: 53.12%] [G loss: 0.902946]\n",
      "epoch:2 step:2351 [D loss: 0.671281, acc.: 62.50%] [G loss: 0.945792]\n",
      "epoch:2 step:2352 [D loss: 0.698134, acc.: 50.00%] [G loss: 0.784482]\n",
      "epoch:2 step:2353 [D loss: 0.691360, acc.: 50.78%] [G loss: 0.907125]\n",
      "epoch:2 step:2354 [D loss: 0.753944, acc.: 39.06%] [G loss: 0.775835]\n",
      "epoch:2 step:2355 [D loss: 0.726031, acc.: 45.31%] [G loss: 0.731066]\n",
      "epoch:2 step:2356 [D loss: 0.725501, acc.: 48.44%] [G loss: 0.711733]\n",
      "epoch:2 step:2357 [D loss: 0.693451, acc.: 50.78%] [G loss: 0.732394]\n",
      "epoch:2 step:2358 [D loss: 0.680569, acc.: 56.25%] [G loss: 0.738554]\n",
      "epoch:2 step:2359 [D loss: 0.685110, acc.: 51.56%] [G loss: 0.745113]\n",
      "epoch:2 step:2360 [D loss: 0.703017, acc.: 46.88%] [G loss: 0.721111]\n",
      "epoch:2 step:2361 [D loss: 0.710924, acc.: 47.66%] [G loss: 0.718567]\n",
      "epoch:2 step:2362 [D loss: 0.669417, acc.: 60.16%] [G loss: 0.751173]\n",
      "epoch:2 step:2363 [D loss: 0.690653, acc.: 53.91%] [G loss: 0.751061]\n",
      "epoch:2 step:2364 [D loss: 0.649989, acc.: 67.19%] [G loss: 0.740572]\n",
      "epoch:2 step:2365 [D loss: 0.667748, acc.: 59.38%] [G loss: 0.750527]\n",
      "epoch:2 step:2366 [D loss: 0.672624, acc.: 53.91%] [G loss: 0.755493]\n",
      "epoch:2 step:2367 [D loss: 0.681710, acc.: 55.47%] [G loss: 0.700471]\n",
      "epoch:2 step:2368 [D loss: 0.681199, acc.: 56.25%] [G loss: 0.715449]\n",
      "epoch:2 step:2369 [D loss: 0.669671, acc.: 60.94%] [G loss: 0.733563]\n",
      "epoch:2 step:2370 [D loss: 0.688924, acc.: 58.59%] [G loss: 0.758717]\n",
      "epoch:2 step:2371 [D loss: 0.702879, acc.: 53.91%] [G loss: 0.762524]\n",
      "epoch:2 step:2372 [D loss: 0.732769, acc.: 42.97%] [G loss: 0.730404]\n",
      "epoch:2 step:2373 [D loss: 0.714960, acc.: 48.44%] [G loss: 0.743408]\n",
      "epoch:2 step:2374 [D loss: 0.696492, acc.: 51.56%] [G loss: 0.751290]\n",
      "epoch:2 step:2375 [D loss: 0.710569, acc.: 46.88%] [G loss: 0.733687]\n",
      "epoch:2 step:2376 [D loss: 0.692951, acc.: 53.91%] [G loss: 0.721081]\n",
      "epoch:2 step:2377 [D loss: 0.650172, acc.: 57.03%] [G loss: 0.817172]\n",
      "epoch:2 step:2378 [D loss: 0.670562, acc.: 59.38%] [G loss: 0.800152]\n",
      "epoch:2 step:2379 [D loss: 0.624676, acc.: 65.62%] [G loss: 0.819631]\n",
      "epoch:2 step:2380 [D loss: 0.689964, acc.: 57.03%] [G loss: 0.825686]\n",
      "epoch:2 step:2381 [D loss: 0.697929, acc.: 53.91%] [G loss: 0.782136]\n",
      "epoch:2 step:2382 [D loss: 0.664409, acc.: 64.06%] [G loss: 0.757113]\n",
      "epoch:2 step:2383 [D loss: 0.736310, acc.: 39.84%] [G loss: 0.786249]\n",
      "epoch:2 step:2384 [D loss: 0.761943, acc.: 39.84%] [G loss: 0.762453]\n",
      "epoch:2 step:2385 [D loss: 0.838078, acc.: 33.59%] [G loss: 0.793374]\n",
      "epoch:2 step:2386 [D loss: 0.720105, acc.: 52.34%] [G loss: 0.785536]\n",
      "epoch:2 step:2387 [D loss: 0.687333, acc.: 53.91%] [G loss: 0.775797]\n",
      "epoch:2 step:2388 [D loss: 0.680165, acc.: 57.81%] [G loss: 0.777907]\n",
      "epoch:2 step:2389 [D loss: 0.691990, acc.: 55.47%] [G loss: 0.761248]\n",
      "epoch:2 step:2390 [D loss: 0.660040, acc.: 63.28%] [G loss: 0.759807]\n",
      "epoch:2 step:2391 [D loss: 0.689503, acc.: 56.25%] [G loss: 0.781541]\n",
      "epoch:2 step:2392 [D loss: 0.683350, acc.: 57.81%] [G loss: 0.765769]\n",
      "epoch:2 step:2393 [D loss: 0.683812, acc.: 55.47%] [G loss: 0.774647]\n",
      "epoch:2 step:2394 [D loss: 0.686920, acc.: 57.81%] [G loss: 0.870892]\n",
      "epoch:2 step:2395 [D loss: 0.686925, acc.: 55.47%] [G loss: 1.014824]\n",
      "epoch:2 step:2396 [D loss: 0.693782, acc.: 51.56%] [G loss: 0.744028]\n",
      "epoch:2 step:2397 [D loss: 0.694403, acc.: 49.22%] [G loss: 0.762200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2398 [D loss: 0.699055, acc.: 48.44%] [G loss: 0.752808]\n",
      "epoch:2 step:2399 [D loss: 0.702688, acc.: 52.34%] [G loss: 0.776915]\n",
      "epoch:2 step:2400 [D loss: 0.695244, acc.: 49.22%] [G loss: 0.745011]\n",
      "epoch:2 step:2401 [D loss: 0.708699, acc.: 50.78%] [G loss: 0.720159]\n",
      "epoch:2 step:2402 [D loss: 0.706265, acc.: 59.38%] [G loss: 0.707424]\n",
      "epoch:2 step:2403 [D loss: 0.720484, acc.: 44.53%] [G loss: 0.730486]\n",
      "epoch:2 step:2404 [D loss: 0.703925, acc.: 50.78%] [G loss: 0.751262]\n",
      "epoch:2 step:2405 [D loss: 0.690205, acc.: 49.22%] [G loss: 0.725521]\n",
      "epoch:2 step:2406 [D loss: 0.684927, acc.: 56.25%] [G loss: 0.727434]\n",
      "epoch:2 step:2407 [D loss: 0.674218, acc.: 60.16%] [G loss: 0.743661]\n",
      "epoch:2 step:2408 [D loss: 0.661380, acc.: 61.72%] [G loss: 0.777624]\n",
      "epoch:2 step:2409 [D loss: 0.707049, acc.: 48.44%] [G loss: 0.730024]\n",
      "epoch:2 step:2410 [D loss: 0.688628, acc.: 56.25%] [G loss: 0.737600]\n",
      "epoch:2 step:2411 [D loss: 0.688329, acc.: 50.78%] [G loss: 0.728191]\n",
      "epoch:2 step:2412 [D loss: 0.704701, acc.: 49.22%] [G loss: 0.763494]\n",
      "epoch:2 step:2413 [D loss: 0.689777, acc.: 55.47%] [G loss: 0.748839]\n",
      "epoch:2 step:2414 [D loss: 0.678497, acc.: 54.69%] [G loss: 0.769113]\n",
      "epoch:2 step:2415 [D loss: 0.666731, acc.: 60.16%] [G loss: 0.779425]\n",
      "epoch:2 step:2416 [D loss: 0.707911, acc.: 42.97%] [G loss: 0.779462]\n",
      "epoch:2 step:2417 [D loss: 0.658145, acc.: 50.00%] [G loss: 0.771756]\n",
      "epoch:2 step:2418 [D loss: 0.688374, acc.: 53.12%] [G loss: 0.672429]\n",
      "epoch:2 step:2419 [D loss: 0.673505, acc.: 50.78%] [G loss: 0.681775]\n",
      "epoch:2 step:2420 [D loss: 0.665084, acc.: 64.84%] [G loss: 0.705456]\n",
      "epoch:2 step:2421 [D loss: 0.697704, acc.: 52.34%] [G loss: 0.845899]\n",
      "epoch:2 step:2422 [D loss: 0.650593, acc.: 63.28%] [G loss: 0.810183]\n",
      "epoch:2 step:2423 [D loss: 0.708436, acc.: 57.03%] [G loss: 0.755588]\n",
      "epoch:2 step:2424 [D loss: 0.570229, acc.: 71.88%] [G loss: 0.794239]\n",
      "epoch:2 step:2425 [D loss: 0.679655, acc.: 60.94%] [G loss: 0.795403]\n",
      "epoch:2 step:2426 [D loss: 0.668862, acc.: 60.16%] [G loss: 0.759396]\n",
      "epoch:2 step:2427 [D loss: 0.711520, acc.: 46.88%] [G loss: 0.849046]\n",
      "epoch:2 step:2428 [D loss: 0.627876, acc.: 64.84%] [G loss: 0.659292]\n",
      "epoch:2 step:2429 [D loss: 0.729603, acc.: 52.34%] [G loss: 0.763197]\n",
      "epoch:2 step:2430 [D loss: 0.647364, acc.: 64.84%] [G loss: 0.761631]\n",
      "epoch:2 step:2431 [D loss: 0.687979, acc.: 59.38%] [G loss: 0.815673]\n",
      "epoch:2 step:2432 [D loss: 0.658455, acc.: 63.28%] [G loss: 0.764720]\n",
      "epoch:2 step:2433 [D loss: 0.837157, acc.: 26.56%] [G loss: 0.738286]\n",
      "epoch:2 step:2434 [D loss: 0.786090, acc.: 32.03%] [G loss: 0.823324]\n",
      "epoch:2 step:2435 [D loss: 0.716706, acc.: 45.31%] [G loss: 1.029295]\n",
      "epoch:2 step:2436 [D loss: 0.692694, acc.: 50.78%] [G loss: 0.861799]\n",
      "epoch:2 step:2437 [D loss: 0.709534, acc.: 45.31%] [G loss: 0.854122]\n",
      "epoch:2 step:2438 [D loss: 0.694468, acc.: 53.91%] [G loss: 0.921163]\n",
      "epoch:2 step:2439 [D loss: 0.707450, acc.: 50.00%] [G loss: 0.847118]\n",
      "epoch:2 step:2440 [D loss: 0.728330, acc.: 37.50%] [G loss: 0.906766]\n",
      "epoch:2 step:2441 [D loss: 0.690784, acc.: 55.47%] [G loss: 0.816941]\n",
      "epoch:2 step:2442 [D loss: 0.675549, acc.: 58.59%] [G loss: 0.862562]\n",
      "epoch:2 step:2443 [D loss: 0.731469, acc.: 46.88%] [G loss: 0.850227]\n",
      "epoch:2 step:2444 [D loss: 0.654237, acc.: 64.84%] [G loss: 0.827081]\n",
      "epoch:2 step:2445 [D loss: 0.676587, acc.: 54.69%] [G loss: 0.798165]\n",
      "epoch:2 step:2446 [D loss: 0.705752, acc.: 53.91%] [G loss: 0.819401]\n",
      "epoch:2 step:2447 [D loss: 0.659597, acc.: 65.62%] [G loss: 0.850142]\n",
      "epoch:2 step:2448 [D loss: 0.624116, acc.: 67.19%] [G loss: 0.803351]\n",
      "epoch:2 step:2449 [D loss: 0.616217, acc.: 76.56%] [G loss: 0.942622]\n",
      "epoch:2 step:2450 [D loss: 0.676209, acc.: 55.47%] [G loss: 0.771312]\n",
      "epoch:2 step:2451 [D loss: 0.685551, acc.: 55.47%] [G loss: 0.787719]\n",
      "epoch:2 step:2452 [D loss: 0.664734, acc.: 55.47%] [G loss: 0.777825]\n",
      "epoch:2 step:2453 [D loss: 0.698176, acc.: 54.69%] [G loss: 0.754106]\n",
      "epoch:2 step:2454 [D loss: 0.715009, acc.: 42.97%] [G loss: 0.754162]\n",
      "epoch:2 step:2455 [D loss: 0.713900, acc.: 50.00%] [G loss: 0.671294]\n",
      "epoch:2 step:2456 [D loss: 0.712708, acc.: 45.31%] [G loss: 0.674258]\n",
      "epoch:2 step:2457 [D loss: 0.767623, acc.: 39.84%] [G loss: 0.715823]\n",
      "epoch:2 step:2458 [D loss: 0.709467, acc.: 48.44%] [G loss: 0.709362]\n",
      "epoch:2 step:2459 [D loss: 0.682825, acc.: 55.47%] [G loss: 0.766660]\n",
      "epoch:2 step:2460 [D loss: 0.690201, acc.: 50.78%] [G loss: 0.793036]\n",
      "epoch:2 step:2461 [D loss: 0.722824, acc.: 39.06%] [G loss: 0.792833]\n",
      "epoch:2 step:2462 [D loss: 0.673984, acc.: 59.38%] [G loss: 0.815295]\n",
      "epoch:2 step:2463 [D loss: 0.660046, acc.: 60.16%] [G loss: 0.865925]\n",
      "epoch:2 step:2464 [D loss: 0.666829, acc.: 55.47%] [G loss: 0.785326]\n",
      "epoch:2 step:2465 [D loss: 0.653744, acc.: 64.06%] [G loss: 0.775921]\n",
      "epoch:2 step:2466 [D loss: 0.673706, acc.: 60.16%] [G loss: 0.742730]\n",
      "epoch:2 step:2467 [D loss: 0.723720, acc.: 42.97%] [G loss: 0.739935]\n",
      "epoch:2 step:2468 [D loss: 0.700470, acc.: 46.09%] [G loss: 0.730960]\n",
      "epoch:2 step:2469 [D loss: 0.717114, acc.: 48.44%] [G loss: 0.703766]\n",
      "epoch:2 step:2470 [D loss: 0.711899, acc.: 50.00%] [G loss: 0.723565]\n",
      "epoch:2 step:2471 [D loss: 0.728821, acc.: 44.53%] [G loss: 0.712459]\n",
      "epoch:2 step:2472 [D loss: 0.736456, acc.: 39.84%] [G loss: 0.689441]\n",
      "epoch:2 step:2473 [D loss: 0.707320, acc.: 48.44%] [G loss: 0.687815]\n",
      "epoch:2 step:2474 [D loss: 0.720745, acc.: 45.31%] [G loss: 0.719638]\n",
      "epoch:2 step:2475 [D loss: 0.723046, acc.: 44.53%] [G loss: 0.761010]\n",
      "epoch:2 step:2476 [D loss: 0.699243, acc.: 47.66%] [G loss: 0.787444]\n",
      "epoch:2 step:2477 [D loss: 0.685107, acc.: 53.91%] [G loss: 0.831852]\n",
      "epoch:2 step:2478 [D loss: 0.701189, acc.: 50.00%] [G loss: 0.854386]\n",
      "epoch:2 step:2479 [D loss: 0.680275, acc.: 57.03%] [G loss: 0.756109]\n",
      "epoch:2 step:2480 [D loss: 0.689048, acc.: 50.78%] [G loss: 0.785523]\n",
      "epoch:2 step:2481 [D loss: 0.696130, acc.: 48.44%] [G loss: 0.784554]\n",
      "epoch:2 step:2482 [D loss: 0.709422, acc.: 50.78%] [G loss: 0.752919]\n",
      "epoch:2 step:2483 [D loss: 0.696538, acc.: 46.09%] [G loss: 0.781556]\n",
      "epoch:2 step:2484 [D loss: 0.704411, acc.: 49.22%] [G loss: 0.770585]\n",
      "epoch:2 step:2485 [D loss: 0.700747, acc.: 53.91%] [G loss: 0.785206]\n",
      "epoch:2 step:2486 [D loss: 0.672391, acc.: 54.69%] [G loss: 0.768235]\n",
      "epoch:2 step:2487 [D loss: 0.681471, acc.: 54.69%] [G loss: 0.797849]\n",
      "epoch:2 step:2488 [D loss: 0.702696, acc.: 46.88%] [G loss: 0.738444]\n",
      "epoch:2 step:2489 [D loss: 0.697857, acc.: 55.47%] [G loss: 0.778614]\n",
      "epoch:2 step:2490 [D loss: 0.705439, acc.: 46.88%] [G loss: 0.768245]\n",
      "epoch:2 step:2491 [D loss: 0.678946, acc.: 58.59%] [G loss: 0.778013]\n",
      "epoch:2 step:2492 [D loss: 0.711571, acc.: 45.31%] [G loss: 0.742101]\n",
      "epoch:2 step:2493 [D loss: 0.703459, acc.: 46.88%] [G loss: 0.734354]\n",
      "epoch:2 step:2494 [D loss: 0.699189, acc.: 54.69%] [G loss: 0.742176]\n",
      "epoch:2 step:2495 [D loss: 0.681390, acc.: 54.69%] [G loss: 0.743918]\n",
      "epoch:2 step:2496 [D loss: 0.701596, acc.: 50.78%] [G loss: 0.756538]\n",
      "epoch:2 step:2497 [D loss: 0.685323, acc.: 54.69%] [G loss: 0.810344]\n",
      "epoch:2 step:2498 [D loss: 0.689476, acc.: 56.25%] [G loss: 0.769943]\n",
      "epoch:2 step:2499 [D loss: 0.704039, acc.: 44.53%] [G loss: 0.740470]\n",
      "epoch:2 step:2500 [D loss: 0.683415, acc.: 53.91%] [G loss: 0.785653]\n",
      "epoch:2 step:2501 [D loss: 0.664842, acc.: 64.84%] [G loss: 0.878474]\n",
      "epoch:2 step:2502 [D loss: 0.698230, acc.: 56.25%] [G loss: 0.805068]\n",
      "epoch:2 step:2503 [D loss: 0.677928, acc.: 55.47%] [G loss: 0.750815]\n",
      "epoch:2 step:2504 [D loss: 0.693839, acc.: 53.12%] [G loss: 0.735535]\n",
      "epoch:2 step:2505 [D loss: 0.685588, acc.: 53.12%] [G loss: 0.721452]\n",
      "epoch:2 step:2506 [D loss: 0.707628, acc.: 44.53%] [G loss: 0.693975]\n",
      "epoch:2 step:2507 [D loss: 0.697062, acc.: 53.12%] [G loss: 0.729360]\n",
      "epoch:2 step:2508 [D loss: 0.692679, acc.: 53.91%] [G loss: 0.741956]\n",
      "epoch:2 step:2509 [D loss: 0.703200, acc.: 48.44%] [G loss: 0.748214]\n",
      "epoch:2 step:2510 [D loss: 0.680146, acc.: 60.16%] [G loss: 0.761174]\n",
      "epoch:2 step:2511 [D loss: 0.686115, acc.: 61.72%] [G loss: 0.749472]\n",
      "epoch:2 step:2512 [D loss: 0.715019, acc.: 50.00%] [G loss: 0.747023]\n",
      "epoch:2 step:2513 [D loss: 0.715983, acc.: 36.72%] [G loss: 0.752794]\n",
      "epoch:2 step:2514 [D loss: 0.719377, acc.: 46.09%] [G loss: 0.761076]\n",
      "epoch:2 step:2515 [D loss: 0.706824, acc.: 46.09%] [G loss: 0.755806]\n",
      "epoch:2 step:2516 [D loss: 0.683288, acc.: 56.25%] [G loss: 0.777001]\n",
      "epoch:2 step:2517 [D loss: 0.682544, acc.: 61.72%] [G loss: 0.751543]\n",
      "epoch:2 step:2518 [D loss: 0.682703, acc.: 57.81%] [G loss: 0.765717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2519 [D loss: 0.691923, acc.: 60.16%] [G loss: 0.758715]\n",
      "epoch:2 step:2520 [D loss: 0.669627, acc.: 57.03%] [G loss: 0.762314]\n",
      "epoch:2 step:2521 [D loss: 0.679572, acc.: 60.94%] [G loss: 0.743846]\n",
      "epoch:2 step:2522 [D loss: 0.649691, acc.: 61.72%] [G loss: 0.769896]\n",
      "epoch:2 step:2523 [D loss: 0.685169, acc.: 55.47%] [G loss: 0.752854]\n",
      "epoch:2 step:2524 [D loss: 0.660036, acc.: 59.38%] [G loss: 0.781393]\n",
      "epoch:2 step:2525 [D loss: 0.701122, acc.: 52.34%] [G loss: 0.799074]\n",
      "epoch:2 step:2526 [D loss: 0.711826, acc.: 46.09%] [G loss: 0.773342]\n",
      "epoch:2 step:2527 [D loss: 0.720916, acc.: 46.09%] [G loss: 0.765430]\n",
      "epoch:2 step:2528 [D loss: 0.726389, acc.: 42.19%] [G loss: 0.753605]\n",
      "epoch:2 step:2529 [D loss: 0.695616, acc.: 51.56%] [G loss: 0.750095]\n",
      "epoch:2 step:2530 [D loss: 0.680683, acc.: 58.59%] [G loss: 0.705977]\n",
      "epoch:2 step:2531 [D loss: 0.682816, acc.: 57.03%] [G loss: 0.747937]\n",
      "epoch:2 step:2532 [D loss: 0.704974, acc.: 45.31%] [G loss: 0.746420]\n",
      "epoch:2 step:2533 [D loss: 0.651340, acc.: 57.81%] [G loss: 0.739897]\n",
      "epoch:2 step:2534 [D loss: 0.710324, acc.: 52.34%] [G loss: 0.650676]\n",
      "epoch:2 step:2535 [D loss: 0.697413, acc.: 53.91%] [G loss: 0.699764]\n",
      "epoch:2 step:2536 [D loss: 0.689240, acc.: 50.00%] [G loss: 0.710910]\n",
      "epoch:2 step:2537 [D loss: 0.703277, acc.: 45.31%] [G loss: 0.758247]\n",
      "epoch:2 step:2538 [D loss: 0.700629, acc.: 51.56%] [G loss: 0.803346]\n",
      "epoch:2 step:2539 [D loss: 0.708132, acc.: 46.88%] [G loss: 0.791089]\n",
      "epoch:2 step:2540 [D loss: 0.669665, acc.: 59.38%] [G loss: 0.796188]\n",
      "epoch:2 step:2541 [D loss: 0.684821, acc.: 53.91%] [G loss: 0.806170]\n",
      "epoch:2 step:2542 [D loss: 0.670280, acc.: 60.16%] [G loss: 0.803276]\n",
      "epoch:2 step:2543 [D loss: 0.691955, acc.: 50.78%] [G loss: 0.804553]\n",
      "epoch:2 step:2544 [D loss: 0.722138, acc.: 45.31%] [G loss: 0.772902]\n",
      "epoch:2 step:2545 [D loss: 0.684283, acc.: 52.34%] [G loss: 0.787698]\n",
      "epoch:2 step:2546 [D loss: 0.724794, acc.: 42.19%] [G loss: 0.756587]\n",
      "epoch:2 step:2547 [D loss: 0.681525, acc.: 52.34%] [G loss: 0.744162]\n",
      "epoch:2 step:2548 [D loss: 0.688550, acc.: 46.88%] [G loss: 0.759627]\n",
      "epoch:2 step:2549 [D loss: 0.710945, acc.: 47.66%] [G loss: 0.719561]\n",
      "epoch:2 step:2550 [D loss: 0.690667, acc.: 56.25%] [G loss: 0.728185]\n",
      "epoch:2 step:2551 [D loss: 0.653771, acc.: 64.84%] [G loss: 0.686217]\n",
      "epoch:2 step:2552 [D loss: 0.688746, acc.: 51.56%] [G loss: 0.748730]\n",
      "epoch:2 step:2553 [D loss: 0.692618, acc.: 51.56%] [G loss: 0.737256]\n",
      "epoch:2 step:2554 [D loss: 0.672050, acc.: 57.81%] [G loss: 0.710234]\n",
      "epoch:2 step:2555 [D loss: 0.724602, acc.: 46.88%] [G loss: 0.728340]\n",
      "epoch:2 step:2556 [D loss: 0.688251, acc.: 57.81%] [G loss: 0.790020]\n",
      "epoch:2 step:2557 [D loss: 0.688061, acc.: 54.69%] [G loss: 0.771493]\n",
      "epoch:2 step:2558 [D loss: 0.672001, acc.: 57.81%] [G loss: 0.772601]\n",
      "epoch:2 step:2559 [D loss: 0.670007, acc.: 57.03%] [G loss: 0.818773]\n",
      "epoch:2 step:2560 [D loss: 0.708860, acc.: 47.66%] [G loss: 0.786112]\n",
      "epoch:2 step:2561 [D loss: 0.685135, acc.: 59.38%] [G loss: 0.823183]\n",
      "epoch:2 step:2562 [D loss: 0.696606, acc.: 57.03%] [G loss: 0.908574]\n",
      "epoch:2 step:2563 [D loss: 0.736760, acc.: 44.53%] [G loss: 0.812200]\n",
      "epoch:2 step:2564 [D loss: 0.692234, acc.: 53.91%] [G loss: 0.759647]\n",
      "epoch:2 step:2565 [D loss: 0.710814, acc.: 46.88%] [G loss: 0.729797]\n",
      "epoch:2 step:2566 [D loss: 0.714097, acc.: 46.88%] [G loss: 0.748956]\n",
      "epoch:2 step:2567 [D loss: 0.701359, acc.: 53.12%] [G loss: 0.734436]\n",
      "epoch:2 step:2568 [D loss: 0.672729, acc.: 58.59%] [G loss: 0.770180]\n",
      "epoch:2 step:2569 [D loss: 0.709143, acc.: 46.88%] [G loss: 0.739788]\n",
      "epoch:2 step:2570 [D loss: 0.716431, acc.: 42.97%] [G loss: 0.727412]\n",
      "epoch:2 step:2571 [D loss: 0.711594, acc.: 50.78%] [G loss: 0.742269]\n",
      "epoch:2 step:2572 [D loss: 0.695275, acc.: 53.91%] [G loss: 0.725787]\n",
      "epoch:2 step:2573 [D loss: 0.704459, acc.: 46.09%] [G loss: 0.718956]\n",
      "epoch:2 step:2574 [D loss: 0.719927, acc.: 42.97%] [G loss: 0.737320]\n",
      "epoch:2 step:2575 [D loss: 0.696065, acc.: 55.47%] [G loss: 0.707952]\n",
      "epoch:2 step:2576 [D loss: 0.705669, acc.: 45.31%] [G loss: 0.739727]\n",
      "epoch:2 step:2577 [D loss: 0.690155, acc.: 51.56%] [G loss: 0.759698]\n",
      "epoch:2 step:2578 [D loss: 0.691904, acc.: 54.69%] [G loss: 0.744310]\n",
      "epoch:2 step:2579 [D loss: 0.698301, acc.: 42.97%] [G loss: 0.737313]\n",
      "epoch:2 step:2580 [D loss: 0.681598, acc.: 60.94%] [G loss: 0.750403]\n",
      "epoch:2 step:2581 [D loss: 0.662299, acc.: 67.97%] [G loss: 0.801288]\n",
      "epoch:2 step:2582 [D loss: 0.670385, acc.: 61.72%] [G loss: 0.766318]\n",
      "epoch:2 step:2583 [D loss: 0.659859, acc.: 60.94%] [G loss: 0.791751]\n",
      "epoch:2 step:2584 [D loss: 0.726435, acc.: 45.31%] [G loss: 0.904288]\n",
      "epoch:2 step:2585 [D loss: 0.713866, acc.: 50.00%] [G loss: 0.785850]\n",
      "epoch:2 step:2586 [D loss: 0.685747, acc.: 53.91%] [G loss: 0.789054]\n",
      "epoch:2 step:2587 [D loss: 0.667621, acc.: 61.72%] [G loss: 0.808922]\n",
      "epoch:2 step:2588 [D loss: 0.693695, acc.: 56.25%] [G loss: 0.709322]\n",
      "epoch:2 step:2589 [D loss: 0.715836, acc.: 48.44%] [G loss: 0.762202]\n",
      "epoch:2 step:2590 [D loss: 0.702543, acc.: 50.00%] [G loss: 0.728277]\n",
      "epoch:2 step:2591 [D loss: 0.682269, acc.: 57.03%] [G loss: 0.781570]\n",
      "epoch:2 step:2592 [D loss: 0.678862, acc.: 55.47%] [G loss: 0.735045]\n",
      "epoch:2 step:2593 [D loss: 0.686260, acc.: 55.47%] [G loss: 0.744358]\n",
      "epoch:2 step:2594 [D loss: 0.699334, acc.: 48.44%] [G loss: 0.711568]\n",
      "epoch:2 step:2595 [D loss: 0.671359, acc.: 59.38%] [G loss: 0.709393]\n",
      "epoch:2 step:2596 [D loss: 0.726648, acc.: 45.31%] [G loss: 0.724132]\n",
      "epoch:2 step:2597 [D loss: 0.668966, acc.: 59.38%] [G loss: 0.732343]\n",
      "epoch:2 step:2598 [D loss: 0.679300, acc.: 58.59%] [G loss: 0.740283]\n",
      "epoch:2 step:2599 [D loss: 0.698378, acc.: 50.78%] [G loss: 0.730844]\n",
      "epoch:2 step:2600 [D loss: 0.676237, acc.: 58.59%] [G loss: 0.638619]\n",
      "epoch:2 step:2601 [D loss: 0.700810, acc.: 54.69%] [G loss: 0.721999]\n",
      "epoch:2 step:2602 [D loss: 0.720863, acc.: 47.66%] [G loss: 0.736342]\n",
      "epoch:2 step:2603 [D loss: 0.655170, acc.: 60.94%] [G loss: 0.772604]\n",
      "epoch:2 step:2604 [D loss: 0.692635, acc.: 50.00%] [G loss: 0.747828]\n",
      "epoch:2 step:2605 [D loss: 0.715245, acc.: 49.22%] [G loss: 0.784059]\n",
      "epoch:2 step:2606 [D loss: 0.670952, acc.: 61.72%] [G loss: 0.813278]\n",
      "epoch:2 step:2607 [D loss: 0.672096, acc.: 54.69%] [G loss: 0.801584]\n",
      "epoch:2 step:2608 [D loss: 0.705432, acc.: 52.34%] [G loss: 0.862832]\n",
      "epoch:2 step:2609 [D loss: 0.714450, acc.: 50.78%] [G loss: 0.776703]\n",
      "epoch:2 step:2610 [D loss: 0.704051, acc.: 53.91%] [G loss: 0.756449]\n",
      "epoch:2 step:2611 [D loss: 0.708348, acc.: 53.12%] [G loss: 0.757030]\n",
      "epoch:2 step:2612 [D loss: 0.695924, acc.: 51.56%] [G loss: 0.735902]\n",
      "epoch:2 step:2613 [D loss: 0.712445, acc.: 53.12%] [G loss: 0.789443]\n",
      "epoch:2 step:2614 [D loss: 0.705008, acc.: 49.22%] [G loss: 0.731330]\n",
      "epoch:2 step:2615 [D loss: 0.732870, acc.: 38.28%] [G loss: 0.739239]\n",
      "epoch:2 step:2616 [D loss: 0.727802, acc.: 39.06%] [G loss: 0.736129]\n",
      "epoch:2 step:2617 [D loss: 0.703089, acc.: 46.09%] [G loss: 0.742028]\n",
      "epoch:2 step:2618 [D loss: 0.699986, acc.: 53.12%] [G loss: 0.723633]\n",
      "epoch:2 step:2619 [D loss: 0.682285, acc.: 61.72%] [G loss: 0.716569]\n",
      "epoch:2 step:2620 [D loss: 0.685372, acc.: 55.47%] [G loss: 0.762690]\n",
      "epoch:2 step:2621 [D loss: 0.684646, acc.: 64.84%] [G loss: 0.706913]\n",
      "epoch:2 step:2622 [D loss: 0.724169, acc.: 39.84%] [G loss: 0.736691]\n",
      "epoch:2 step:2623 [D loss: 0.716689, acc.: 40.62%] [G loss: 0.744013]\n",
      "epoch:2 step:2624 [D loss: 0.710018, acc.: 43.75%] [G loss: 0.795867]\n",
      "epoch:2 step:2625 [D loss: 0.695205, acc.: 48.44%] [G loss: 0.721138]\n",
      "epoch:2 step:2626 [D loss: 0.700397, acc.: 50.00%] [G loss: 0.736204]\n",
      "epoch:2 step:2627 [D loss: 0.694338, acc.: 52.34%] [G loss: 0.749221]\n",
      "epoch:2 step:2628 [D loss: 0.703477, acc.: 50.00%] [G loss: 0.726429]\n",
      "epoch:2 step:2629 [D loss: 0.676660, acc.: 61.72%] [G loss: 0.720525]\n",
      "epoch:2 step:2630 [D loss: 0.666693, acc.: 64.06%] [G loss: 0.728580]\n",
      "epoch:2 step:2631 [D loss: 0.661797, acc.: 68.75%] [G loss: 0.732048]\n",
      "epoch:2 step:2632 [D loss: 0.692830, acc.: 63.28%] [G loss: 0.761290]\n",
      "epoch:2 step:2633 [D loss: 0.683032, acc.: 53.91%] [G loss: 0.763394]\n",
      "epoch:2 step:2634 [D loss: 0.706172, acc.: 45.31%] [G loss: 0.737129]\n",
      "epoch:2 step:2635 [D loss: 0.687295, acc.: 57.81%] [G loss: 0.703781]\n",
      "epoch:2 step:2636 [D loss: 0.676100, acc.: 50.78%] [G loss: 0.730893]\n",
      "epoch:2 step:2637 [D loss: 0.688610, acc.: 56.25%] [G loss: 0.713908]\n",
      "epoch:2 step:2638 [D loss: 0.706623, acc.: 53.12%] [G loss: 0.749704]\n",
      "epoch:2 step:2639 [D loss: 0.692336, acc.: 53.12%] [G loss: 0.725277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2640 [D loss: 0.707337, acc.: 45.31%] [G loss: 0.755826]\n",
      "epoch:2 step:2641 [D loss: 0.679886, acc.: 57.03%] [G loss: 0.750598]\n",
      "epoch:2 step:2642 [D loss: 0.713442, acc.: 50.78%] [G loss: 0.738380]\n",
      "epoch:2 step:2643 [D loss: 0.690976, acc.: 55.47%] [G loss: 0.762015]\n",
      "epoch:2 step:2644 [D loss: 0.683223, acc.: 56.25%] [G loss: 0.776145]\n",
      "epoch:2 step:2645 [D loss: 0.696204, acc.: 51.56%] [G loss: 0.791617]\n",
      "epoch:2 step:2646 [D loss: 0.689360, acc.: 49.22%] [G loss: 0.722276]\n",
      "epoch:2 step:2647 [D loss: 0.685325, acc.: 54.69%] [G loss: 0.746446]\n",
      "epoch:2 step:2648 [D loss: 0.676779, acc.: 54.69%] [G loss: 0.758911]\n",
      "epoch:2 step:2649 [D loss: 0.653663, acc.: 63.28%] [G loss: 0.752111]\n",
      "epoch:2 step:2650 [D loss: 0.689217, acc.: 55.47%] [G loss: 0.784624]\n",
      "epoch:2 step:2651 [D loss: 0.673017, acc.: 59.38%] [G loss: 0.804408]\n",
      "epoch:2 step:2652 [D loss: 0.673926, acc.: 59.38%] [G loss: 0.796759]\n",
      "epoch:2 step:2653 [D loss: 0.685385, acc.: 55.47%] [G loss: 0.752223]\n",
      "epoch:2 step:2654 [D loss: 0.699655, acc.: 50.00%] [G loss: 0.764819]\n",
      "epoch:2 step:2655 [D loss: 0.667674, acc.: 60.16%] [G loss: 0.798415]\n",
      "epoch:2 step:2656 [D loss: 0.691232, acc.: 53.91%] [G loss: 0.817672]\n",
      "epoch:2 step:2657 [D loss: 0.696875, acc.: 53.12%] [G loss: 0.803796]\n",
      "epoch:2 step:2658 [D loss: 0.735939, acc.: 46.88%] [G loss: 0.814472]\n",
      "epoch:2 step:2659 [D loss: 0.700706, acc.: 48.44%] [G loss: 0.783908]\n",
      "epoch:2 step:2660 [D loss: 0.712181, acc.: 47.66%] [G loss: 0.735752]\n",
      "epoch:2 step:2661 [D loss: 0.730466, acc.: 45.31%] [G loss: 0.733922]\n",
      "epoch:2 step:2662 [D loss: 0.714506, acc.: 44.53%] [G loss: 0.755226]\n",
      "epoch:2 step:2663 [D loss: 0.713497, acc.: 45.31%] [G loss: 0.706753]\n",
      "epoch:2 step:2664 [D loss: 0.681602, acc.: 61.72%] [G loss: 0.725426]\n",
      "epoch:2 step:2665 [D loss: 0.692269, acc.: 50.78%] [G loss: 0.716112]\n",
      "epoch:2 step:2666 [D loss: 0.678828, acc.: 53.12%] [G loss: 0.747965]\n",
      "epoch:2 step:2667 [D loss: 0.670542, acc.: 60.94%] [G loss: 0.734966]\n",
      "epoch:2 step:2668 [D loss: 0.684400, acc.: 53.12%] [G loss: 0.761007]\n",
      "epoch:2 step:2669 [D loss: 0.706550, acc.: 42.19%] [G loss: 0.744240]\n",
      "epoch:2 step:2670 [D loss: 0.694928, acc.: 51.56%] [G loss: 0.767734]\n",
      "epoch:2 step:2671 [D loss: 0.676150, acc.: 56.25%] [G loss: 0.738565]\n",
      "epoch:2 step:2672 [D loss: 0.677259, acc.: 57.03%] [G loss: 0.683020]\n",
      "epoch:2 step:2673 [D loss: 0.665234, acc.: 56.25%] [G loss: 0.734908]\n",
      "epoch:2 step:2674 [D loss: 0.712594, acc.: 48.44%] [G loss: 0.722173]\n",
      "epoch:2 step:2675 [D loss: 0.686944, acc.: 55.47%] [G loss: 0.678666]\n",
      "epoch:2 step:2676 [D loss: 0.594634, acc.: 63.28%] [G loss: 0.782569]\n",
      "epoch:2 step:2677 [D loss: 0.678549, acc.: 60.16%] [G loss: 0.694572]\n",
      "epoch:2 step:2678 [D loss: 0.718109, acc.: 44.53%] [G loss: 0.741002]\n",
      "epoch:2 step:2679 [D loss: 0.712991, acc.: 49.22%] [G loss: 0.728109]\n",
      "epoch:2 step:2680 [D loss: 0.708933, acc.: 50.78%] [G loss: 0.678448]\n",
      "epoch:2 step:2681 [D loss: 0.681577, acc.: 52.34%] [G loss: 0.769882]\n",
      "epoch:2 step:2682 [D loss: 0.691070, acc.: 51.56%] [G loss: 0.735229]\n",
      "epoch:2 step:2683 [D loss: 0.684315, acc.: 52.34%] [G loss: 0.756726]\n",
      "epoch:2 step:2684 [D loss: 0.672608, acc.: 53.12%] [G loss: 0.678515]\n",
      "epoch:2 step:2685 [D loss: 0.714393, acc.: 42.97%] [G loss: 0.749189]\n",
      "epoch:2 step:2686 [D loss: 0.701631, acc.: 45.31%] [G loss: 0.695103]\n",
      "epoch:2 step:2687 [D loss: 0.772320, acc.: 46.88%] [G loss: 0.737387]\n",
      "epoch:2 step:2688 [D loss: 0.707112, acc.: 50.78%] [G loss: 0.809436]\n",
      "epoch:2 step:2689 [D loss: 0.659539, acc.: 68.75%] [G loss: 0.806577]\n",
      "epoch:2 step:2690 [D loss: 0.682386, acc.: 57.81%] [G loss: 0.793028]\n",
      "epoch:2 step:2691 [D loss: 0.718076, acc.: 42.97%] [G loss: 0.755337]\n",
      "epoch:2 step:2692 [D loss: 0.693236, acc.: 57.81%] [G loss: 0.793158]\n",
      "epoch:2 step:2693 [D loss: 0.695711, acc.: 48.44%] [G loss: 0.757435]\n",
      "epoch:2 step:2694 [D loss: 0.728916, acc.: 37.50%] [G loss: 0.745717]\n",
      "epoch:2 step:2695 [D loss: 0.716238, acc.: 46.88%] [G loss: 0.730505]\n",
      "epoch:2 step:2696 [D loss: 0.693926, acc.: 55.47%] [G loss: 0.753537]\n",
      "epoch:2 step:2697 [D loss: 0.700081, acc.: 55.47%] [G loss: 0.739419]\n",
      "epoch:2 step:2698 [D loss: 0.708947, acc.: 46.09%] [G loss: 0.749987]\n",
      "epoch:2 step:2699 [D loss: 0.677341, acc.: 57.03%] [G loss: 0.722850]\n",
      "epoch:2 step:2700 [D loss: 0.675376, acc.: 60.94%] [G loss: 0.722249]\n",
      "epoch:2 step:2701 [D loss: 0.718278, acc.: 44.53%] [G loss: 0.716759]\n",
      "epoch:2 step:2702 [D loss: 0.680347, acc.: 55.47%] [G loss: 0.724716]\n",
      "epoch:2 step:2703 [D loss: 0.700270, acc.: 49.22%] [G loss: 0.784072]\n",
      "epoch:2 step:2704 [D loss: 0.675554, acc.: 56.25%] [G loss: 0.758895]\n",
      "epoch:2 step:2705 [D loss: 0.675039, acc.: 58.59%] [G loss: 0.792292]\n",
      "epoch:2 step:2706 [D loss: 0.693108, acc.: 52.34%] [G loss: 0.769650]\n",
      "epoch:2 step:2707 [D loss: 0.681020, acc.: 57.03%] [G loss: 0.753849]\n",
      "epoch:2 step:2708 [D loss: 0.697258, acc.: 50.00%] [G loss: 0.763511]\n",
      "epoch:2 step:2709 [D loss: 0.701407, acc.: 53.91%] [G loss: 0.739707]\n",
      "epoch:2 step:2710 [D loss: 0.707021, acc.: 47.66%] [G loss: 0.728267]\n",
      "epoch:2 step:2711 [D loss: 0.683048, acc.: 57.03%] [G loss: 0.733283]\n",
      "epoch:2 step:2712 [D loss: 0.672957, acc.: 53.91%] [G loss: 0.744599]\n",
      "epoch:2 step:2713 [D loss: 0.672634, acc.: 57.81%] [G loss: 0.749078]\n",
      "epoch:2 step:2714 [D loss: 0.695920, acc.: 55.47%] [G loss: 0.684888]\n",
      "epoch:2 step:2715 [D loss: 0.666914, acc.: 60.16%] [G loss: 0.686853]\n",
      "epoch:2 step:2716 [D loss: 0.688819, acc.: 50.00%] [G loss: 0.741356]\n",
      "epoch:2 step:2717 [D loss: 0.737332, acc.: 42.19%] [G loss: 0.723464]\n",
      "epoch:2 step:2718 [D loss: 0.710880, acc.: 46.88%] [G loss: 0.769760]\n",
      "epoch:2 step:2719 [D loss: 0.647652, acc.: 56.25%] [G loss: 0.712485]\n",
      "epoch:2 step:2720 [D loss: 0.721501, acc.: 50.78%] [G loss: 0.693388]\n",
      "epoch:2 step:2721 [D loss: 0.736366, acc.: 39.06%] [G loss: 0.729873]\n",
      "epoch:2 step:2722 [D loss: 0.745752, acc.: 42.19%] [G loss: 0.658456]\n",
      "epoch:2 step:2723 [D loss: 0.692709, acc.: 53.91%] [G loss: 0.680109]\n",
      "epoch:2 step:2724 [D loss: 0.741559, acc.: 31.25%] [G loss: 0.727329]\n",
      "epoch:2 step:2725 [D loss: 0.698855, acc.: 53.12%] [G loss: 0.775543]\n",
      "epoch:2 step:2726 [D loss: 0.673642, acc.: 57.03%] [G loss: 0.768815]\n",
      "epoch:2 step:2727 [D loss: 0.698774, acc.: 50.00%] [G loss: 0.793318]\n",
      "epoch:2 step:2728 [D loss: 0.670040, acc.: 57.03%] [G loss: 0.789350]\n",
      "epoch:2 step:2729 [D loss: 0.675003, acc.: 57.81%] [G loss: 0.778457]\n",
      "epoch:2 step:2730 [D loss: 0.679697, acc.: 53.12%] [G loss: 0.754687]\n",
      "epoch:2 step:2731 [D loss: 0.666355, acc.: 60.16%] [G loss: 0.811595]\n",
      "epoch:2 step:2732 [D loss: 0.704540, acc.: 52.34%] [G loss: 0.819842]\n",
      "epoch:2 step:2733 [D loss: 0.690843, acc.: 57.03%] [G loss: 0.799456]\n",
      "epoch:2 step:2734 [D loss: 0.714661, acc.: 49.22%] [G loss: 0.774978]\n",
      "epoch:2 step:2735 [D loss: 0.702493, acc.: 46.09%] [G loss: 0.758976]\n",
      "epoch:2 step:2736 [D loss: 0.702144, acc.: 52.34%] [G loss: 0.808782]\n",
      "epoch:2 step:2737 [D loss: 0.716081, acc.: 47.66%] [G loss: 0.762500]\n",
      "epoch:2 step:2738 [D loss: 0.713885, acc.: 45.31%] [G loss: 0.716924]\n",
      "epoch:2 step:2739 [D loss: 0.703991, acc.: 53.91%] [G loss: 0.727144]\n",
      "epoch:2 step:2740 [D loss: 0.690723, acc.: 57.81%] [G loss: 0.686098]\n",
      "epoch:2 step:2741 [D loss: 0.691251, acc.: 53.91%] [G loss: 0.733599]\n",
      "epoch:2 step:2742 [D loss: 0.710314, acc.: 48.44%] [G loss: 0.714152]\n",
      "epoch:2 step:2743 [D loss: 0.688427, acc.: 56.25%] [G loss: 0.726047]\n",
      "epoch:2 step:2744 [D loss: 0.684169, acc.: 55.47%] [G loss: 0.732725]\n",
      "epoch:2 step:2745 [D loss: 0.695074, acc.: 53.12%] [G loss: 0.728384]\n",
      "epoch:2 step:2746 [D loss: 0.678876, acc.: 57.81%] [G loss: 0.757831]\n",
      "epoch:2 step:2747 [D loss: 0.671559, acc.: 60.16%] [G loss: 0.734451]\n",
      "epoch:2 step:2748 [D loss: 0.704861, acc.: 47.66%] [G loss: 0.725441]\n",
      "epoch:2 step:2749 [D loss: 0.662387, acc.: 64.84%] [G loss: 0.710636]\n",
      "epoch:2 step:2750 [D loss: 0.679731, acc.: 62.50%] [G loss: 0.684918]\n",
      "epoch:2 step:2751 [D loss: 0.686728, acc.: 55.47%] [G loss: 0.711922]\n",
      "epoch:2 step:2752 [D loss: 0.647391, acc.: 62.50%] [G loss: 0.733985]\n",
      "epoch:2 step:2753 [D loss: 0.701617, acc.: 50.00%] [G loss: 0.711699]\n",
      "epoch:2 step:2754 [D loss: 0.694129, acc.: 52.34%] [G loss: 0.756719]\n",
      "epoch:2 step:2755 [D loss: 0.667301, acc.: 59.38%] [G loss: 0.742759]\n",
      "epoch:2 step:2756 [D loss: 0.709985, acc.: 48.44%] [G loss: 0.730252]\n",
      "epoch:2 step:2757 [D loss: 0.701148, acc.: 50.00%] [G loss: 0.788021]\n",
      "epoch:2 step:2758 [D loss: 0.713524, acc.: 51.56%] [G loss: 0.776166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2759 [D loss: 0.684663, acc.: 50.78%] [G loss: 0.805390]\n",
      "epoch:2 step:2760 [D loss: 0.661849, acc.: 69.53%] [G loss: 0.755120]\n",
      "epoch:2 step:2761 [D loss: 0.687187, acc.: 55.47%] [G loss: 0.801198]\n",
      "epoch:2 step:2762 [D loss: 0.703893, acc.: 50.78%] [G loss: 0.780179]\n",
      "epoch:2 step:2763 [D loss: 0.701430, acc.: 48.44%] [G loss: 0.768237]\n",
      "epoch:2 step:2764 [D loss: 0.670595, acc.: 61.72%] [G loss: 0.727600]\n",
      "epoch:2 step:2765 [D loss: 0.733059, acc.: 33.59%] [G loss: 0.747911]\n",
      "epoch:2 step:2766 [D loss: 0.751614, acc.: 39.06%] [G loss: 0.752416]\n",
      "epoch:2 step:2767 [D loss: 0.708553, acc.: 51.56%] [G loss: 0.753262]\n",
      "epoch:2 step:2768 [D loss: 0.702264, acc.: 51.56%] [G loss: 0.706403]\n",
      "epoch:2 step:2769 [D loss: 0.698037, acc.: 47.66%] [G loss: 0.717215]\n",
      "epoch:2 step:2770 [D loss: 0.692655, acc.: 54.69%] [G loss: 0.741427]\n",
      "epoch:2 step:2771 [D loss: 0.664316, acc.: 60.94%] [G loss: 0.759509]\n",
      "epoch:2 step:2772 [D loss: 0.716337, acc.: 43.75%] [G loss: 0.810754]\n",
      "epoch:2 step:2773 [D loss: 0.653414, acc.: 59.38%] [G loss: 0.780094]\n",
      "epoch:2 step:2774 [D loss: 0.662539, acc.: 60.94%] [G loss: 0.751099]\n",
      "epoch:2 step:2775 [D loss: 0.678890, acc.: 62.50%] [G loss: 0.738190]\n",
      "epoch:2 step:2776 [D loss: 0.715025, acc.: 49.22%] [G loss: 0.776183]\n",
      "epoch:2 step:2777 [D loss: 0.680044, acc.: 53.91%] [G loss: 0.749624]\n",
      "epoch:2 step:2778 [D loss: 0.758190, acc.: 28.91%] [G loss: 0.765463]\n",
      "epoch:2 step:2779 [D loss: 0.725853, acc.: 48.44%] [G loss: 0.746376]\n",
      "epoch:2 step:2780 [D loss: 0.722403, acc.: 35.94%] [G loss: 0.742076]\n",
      "epoch:2 step:2781 [D loss: 0.712339, acc.: 44.53%] [G loss: 0.741082]\n",
      "epoch:2 step:2782 [D loss: 0.707044, acc.: 44.53%] [G loss: 0.710072]\n",
      "epoch:2 step:2783 [D loss: 0.683952, acc.: 57.03%] [G loss: 0.717556]\n",
      "epoch:2 step:2784 [D loss: 0.702481, acc.: 47.66%] [G loss: 0.727205]\n",
      "epoch:2 step:2785 [D loss: 0.673169, acc.: 59.38%] [G loss: 0.756967]\n",
      "epoch:2 step:2786 [D loss: 0.501767, acc.: 84.38%] [G loss: 0.744791]\n",
      "epoch:2 step:2787 [D loss: 0.672457, acc.: 58.59%] [G loss: 0.782603]\n",
      "epoch:2 step:2788 [D loss: 0.692177, acc.: 53.91%] [G loss: 0.756555]\n",
      "epoch:2 step:2789 [D loss: 0.807382, acc.: 37.50%] [G loss: 0.723865]\n",
      "epoch:2 step:2790 [D loss: 0.714460, acc.: 46.88%] [G loss: 0.661473]\n",
      "epoch:2 step:2791 [D loss: 0.679538, acc.: 60.16%] [G loss: 0.723495]\n",
      "epoch:2 step:2792 [D loss: 0.655216, acc.: 61.72%] [G loss: 0.728198]\n",
      "epoch:2 step:2793 [D loss: 0.624813, acc.: 66.41%] [G loss: 0.745128]\n",
      "epoch:2 step:2794 [D loss: 0.746233, acc.: 41.41%] [G loss: 0.684879]\n",
      "epoch:2 step:2795 [D loss: 0.682937, acc.: 55.47%] [G loss: 0.679964]\n",
      "epoch:2 step:2796 [D loss: 0.659492, acc.: 57.03%] [G loss: 0.754463]\n",
      "epoch:2 step:2797 [D loss: 0.654302, acc.: 62.50%] [G loss: 0.737246]\n",
      "epoch:2 step:2798 [D loss: 0.563992, acc.: 66.41%] [G loss: 0.763943]\n",
      "epoch:2 step:2799 [D loss: 0.547364, acc.: 67.19%] [G loss: 0.786935]\n",
      "epoch:2 step:2800 [D loss: 0.690767, acc.: 57.03%] [G loss: 0.844849]\n",
      "epoch:2 step:2801 [D loss: 0.611586, acc.: 65.62%] [G loss: 1.061185]\n",
      "epoch:2 step:2802 [D loss: 0.658373, acc.: 52.34%] [G loss: 2.008672]\n",
      "epoch:2 step:2803 [D loss: 0.619260, acc.: 58.59%] [G loss: 1.022479]\n",
      "epoch:2 step:2804 [D loss: 0.757678, acc.: 51.56%] [G loss: 1.241231]\n",
      "epoch:2 step:2805 [D loss: 0.816307, acc.: 39.06%] [G loss: 0.812571]\n",
      "epoch:2 step:2806 [D loss: 0.832569, acc.: 30.47%] [G loss: 0.739593]\n",
      "epoch:2 step:2807 [D loss: 0.741538, acc.: 38.28%] [G loss: 0.776326]\n",
      "epoch:2 step:2808 [D loss: 0.668123, acc.: 52.34%] [G loss: 0.740489]\n",
      "epoch:2 step:2809 [D loss: 0.650864, acc.: 65.62%] [G loss: 0.785669]\n",
      "epoch:2 step:2810 [D loss: 0.478208, acc.: 74.22%] [G loss: 0.749845]\n",
      "epoch:2 step:2811 [D loss: 0.530467, acc.: 74.22%] [G loss: 0.836422]\n",
      "epoch:3 step:2812 [D loss: 0.702283, acc.: 65.62%] [G loss: 0.846519]\n",
      "epoch:3 step:2813 [D loss: 0.716865, acc.: 47.66%] [G loss: 0.784539]\n",
      "epoch:3 step:2814 [D loss: 0.669827, acc.: 60.94%] [G loss: 0.560556]\n",
      "epoch:3 step:2815 [D loss: 0.653107, acc.: 67.97%] [G loss: 0.679797]\n",
      "epoch:3 step:2816 [D loss: 0.590628, acc.: 81.25%] [G loss: 0.832363]\n",
      "epoch:3 step:2817 [D loss: 0.667007, acc.: 64.06%] [G loss: 0.649190]\n",
      "epoch:3 step:2818 [D loss: 0.678039, acc.: 54.69%] [G loss: 0.834876]\n",
      "epoch:3 step:2819 [D loss: 0.653308, acc.: 64.84%] [G loss: 0.724132]\n",
      "epoch:3 step:2820 [D loss: 0.635314, acc.: 64.84%] [G loss: 0.571442]\n",
      "epoch:3 step:2821 [D loss: 0.677321, acc.: 57.81%] [G loss: 0.805766]\n",
      "epoch:3 step:2822 [D loss: 0.733531, acc.: 50.00%] [G loss: 0.793406]\n",
      "epoch:3 step:2823 [D loss: 0.732032, acc.: 55.47%] [G loss: 0.840672]\n",
      "epoch:3 step:2824 [D loss: 0.613639, acc.: 67.19%] [G loss: 0.639323]\n",
      "epoch:3 step:2825 [D loss: 0.696269, acc.: 57.03%] [G loss: 0.790545]\n",
      "epoch:3 step:2826 [D loss: 0.589733, acc.: 76.56%] [G loss: 0.781435]\n",
      "epoch:3 step:2827 [D loss: 0.748276, acc.: 39.84%] [G loss: 0.488781]\n",
      "epoch:3 step:2828 [D loss: 0.774143, acc.: 32.03%] [G loss: 0.933052]\n",
      "epoch:3 step:2829 [D loss: 0.971052, acc.: 24.22%] [G loss: 0.875943]\n",
      "epoch:3 step:2830 [D loss: 0.702782, acc.: 48.44%] [G loss: 1.233100]\n",
      "epoch:3 step:2831 [D loss: 0.662478, acc.: 51.56%] [G loss: 1.246482]\n",
      "epoch:3 step:2832 [D loss: 0.678040, acc.: 53.91%] [G loss: 1.121968]\n",
      "epoch:3 step:2833 [D loss: 0.677056, acc.: 53.91%] [G loss: 1.002348]\n",
      "epoch:3 step:2834 [D loss: 0.669604, acc.: 47.66%] [G loss: 1.084684]\n",
      "epoch:3 step:2835 [D loss: 0.719406, acc.: 53.12%] [G loss: 0.932374]\n",
      "epoch:3 step:2836 [D loss: 0.691105, acc.: 51.56%] [G loss: 0.909408]\n",
      "epoch:3 step:2837 [D loss: 0.714928, acc.: 49.22%] [G loss: 0.833237]\n",
      "epoch:3 step:2838 [D loss: 0.704571, acc.: 46.88%] [G loss: 0.891737]\n",
      "epoch:3 step:2839 [D loss: 0.739462, acc.: 40.62%] [G loss: 0.827832]\n",
      "epoch:3 step:2840 [D loss: 0.680543, acc.: 57.03%] [G loss: 0.838929]\n",
      "epoch:3 step:2841 [D loss: 0.688649, acc.: 47.66%] [G loss: 0.784470]\n",
      "epoch:3 step:2842 [D loss: 0.681295, acc.: 59.38%] [G loss: 0.786398]\n",
      "epoch:3 step:2843 [D loss: 0.677342, acc.: 64.84%] [G loss: 0.827469]\n",
      "epoch:3 step:2844 [D loss: 0.689502, acc.: 56.25%] [G loss: 0.843419]\n",
      "epoch:3 step:2845 [D loss: 0.687725, acc.: 64.84%] [G loss: 0.733289]\n",
      "epoch:3 step:2846 [D loss: 0.684201, acc.: 67.97%] [G loss: 0.789612]\n",
      "epoch:3 step:2847 [D loss: 0.635489, acc.: 61.72%] [G loss: 0.766092]\n",
      "epoch:3 step:2848 [D loss: 0.716057, acc.: 54.69%] [G loss: 0.749321]\n",
      "epoch:3 step:2849 [D loss: 0.786706, acc.: 38.28%] [G loss: 0.814699]\n",
      "epoch:3 step:2850 [D loss: 0.706720, acc.: 53.12%] [G loss: 0.761612]\n",
      "epoch:3 step:2851 [D loss: 0.722461, acc.: 43.75%] [G loss: 0.738798]\n",
      "epoch:3 step:2852 [D loss: 0.683761, acc.: 53.91%] [G loss: 0.700252]\n",
      "epoch:3 step:2853 [D loss: 0.679039, acc.: 55.47%] [G loss: 0.719530]\n",
      "epoch:3 step:2854 [D loss: 0.677274, acc.: 57.03%] [G loss: 0.702053]\n",
      "epoch:3 step:2855 [D loss: 0.702742, acc.: 52.34%] [G loss: 0.722216]\n",
      "epoch:3 step:2856 [D loss: 0.702225, acc.: 60.16%] [G loss: 0.755219]\n",
      "epoch:3 step:2857 [D loss: 0.706506, acc.: 46.88%] [G loss: 0.698907]\n",
      "epoch:3 step:2858 [D loss: 0.698512, acc.: 56.25%] [G loss: 0.720286]\n",
      "epoch:3 step:2859 [D loss: 0.682688, acc.: 52.34%] [G loss: 0.686132]\n",
      "epoch:3 step:2860 [D loss: 0.704903, acc.: 46.88%] [G loss: 0.737544]\n",
      "epoch:3 step:2861 [D loss: 0.678466, acc.: 53.91%] [G loss: 0.679536]\n",
      "epoch:3 step:2862 [D loss: 0.699278, acc.: 46.88%] [G loss: 0.705448]\n",
      "epoch:3 step:2863 [D loss: 0.715821, acc.: 48.44%] [G loss: 0.703619]\n",
      "epoch:3 step:2864 [D loss: 0.700648, acc.: 53.91%] [G loss: 0.745017]\n",
      "epoch:3 step:2865 [D loss: 0.710036, acc.: 49.22%] [G loss: 0.757045]\n",
      "epoch:3 step:2866 [D loss: 0.690169, acc.: 61.72%] [G loss: 0.780418]\n",
      "epoch:3 step:2867 [D loss: 0.679050, acc.: 59.38%] [G loss: 0.769345]\n",
      "epoch:3 step:2868 [D loss: 0.698185, acc.: 51.56%] [G loss: 0.788868]\n",
      "epoch:3 step:2869 [D loss: 0.690480, acc.: 56.25%] [G loss: 0.786033]\n",
      "epoch:3 step:2870 [D loss: 0.700443, acc.: 51.56%] [G loss: 0.749033]\n",
      "epoch:3 step:2871 [D loss: 0.709247, acc.: 45.31%] [G loss: 0.753903]\n",
      "epoch:3 step:2872 [D loss: 0.693232, acc.: 50.00%] [G loss: 0.780027]\n",
      "epoch:3 step:2873 [D loss: 0.700178, acc.: 51.56%] [G loss: 0.729520]\n",
      "epoch:3 step:2874 [D loss: 0.698445, acc.: 49.22%] [G loss: 0.750345]\n",
      "epoch:3 step:2875 [D loss: 0.700927, acc.: 40.62%] [G loss: 0.728982]\n",
      "epoch:3 step:2876 [D loss: 0.696556, acc.: 51.56%] [G loss: 0.732825]\n",
      "epoch:3 step:2877 [D loss: 0.711829, acc.: 49.22%] [G loss: 0.747458]\n",
      "epoch:3 step:2878 [D loss: 0.676270, acc.: 57.81%] [G loss: 0.747939]\n",
      "epoch:3 step:2879 [D loss: 0.678902, acc.: 57.03%] [G loss: 0.780094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2880 [D loss: 0.670822, acc.: 60.94%] [G loss: 0.752700]\n",
      "epoch:3 step:2881 [D loss: 0.710782, acc.: 47.66%] [G loss: 0.719806]\n",
      "epoch:3 step:2882 [D loss: 0.720214, acc.: 41.41%] [G loss: 0.715091]\n",
      "epoch:3 step:2883 [D loss: 0.697717, acc.: 48.44%] [G loss: 0.754598]\n",
      "epoch:3 step:2884 [D loss: 0.713491, acc.: 46.88%] [G loss: 0.725148]\n",
      "epoch:3 step:2885 [D loss: 0.687998, acc.: 57.03%] [G loss: 0.744279]\n",
      "epoch:3 step:2886 [D loss: 0.726622, acc.: 43.75%] [G loss: 0.728716]\n",
      "epoch:3 step:2887 [D loss: 0.675726, acc.: 56.25%] [G loss: 0.722568]\n",
      "epoch:3 step:2888 [D loss: 0.683611, acc.: 56.25%] [G loss: 0.747110]\n",
      "epoch:3 step:2889 [D loss: 0.735708, acc.: 43.75%] [G loss: 0.729769]\n",
      "epoch:3 step:2890 [D loss: 0.705971, acc.: 53.91%] [G loss: 0.743655]\n",
      "epoch:3 step:2891 [D loss: 0.680711, acc.: 54.69%] [G loss: 0.756534]\n",
      "epoch:3 step:2892 [D loss: 0.681826, acc.: 59.38%] [G loss: 0.716399]\n",
      "epoch:3 step:2893 [D loss: 0.684422, acc.: 54.69%] [G loss: 0.698294]\n",
      "epoch:3 step:2894 [D loss: 0.683100, acc.: 54.69%] [G loss: 0.714210]\n",
      "epoch:3 step:2895 [D loss: 0.696730, acc.: 52.34%] [G loss: 0.736251]\n",
      "epoch:3 step:2896 [D loss: 0.683376, acc.: 46.09%] [G loss: 0.717412]\n",
      "epoch:3 step:2897 [D loss: 0.693127, acc.: 53.91%] [G loss: 0.730401]\n",
      "epoch:3 step:2898 [D loss: 0.704558, acc.: 46.09%] [G loss: 0.731673]\n",
      "epoch:3 step:2899 [D loss: 0.723619, acc.: 47.66%] [G loss: 0.722101]\n",
      "epoch:3 step:2900 [D loss: 0.652865, acc.: 67.19%] [G loss: 0.728908]\n",
      "epoch:3 step:2901 [D loss: 0.682074, acc.: 56.25%] [G loss: 0.739045]\n",
      "epoch:3 step:2902 [D loss: 0.707960, acc.: 55.47%] [G loss: 0.773226]\n",
      "epoch:3 step:2903 [D loss: 0.693663, acc.: 50.00%] [G loss: 0.776071]\n",
      "epoch:3 step:2904 [D loss: 0.667117, acc.: 60.94%] [G loss: 0.792847]\n",
      "epoch:3 step:2905 [D loss: 0.681129, acc.: 60.16%] [G loss: 0.781074]\n",
      "epoch:3 step:2906 [D loss: 0.708020, acc.: 46.88%] [G loss: 0.800571]\n",
      "epoch:3 step:2907 [D loss: 0.685235, acc.: 59.38%] [G loss: 0.784113]\n",
      "epoch:3 step:2908 [D loss: 0.677412, acc.: 58.59%] [G loss: 0.762423]\n",
      "epoch:3 step:2909 [D loss: 0.680420, acc.: 57.03%] [G loss: 0.752585]\n",
      "epoch:3 step:2910 [D loss: 0.690988, acc.: 57.03%] [G loss: 0.768937]\n",
      "epoch:3 step:2911 [D loss: 0.683162, acc.: 59.38%] [G loss: 0.750238]\n",
      "epoch:3 step:2912 [D loss: 0.702468, acc.: 50.00%] [G loss: 0.746148]\n",
      "epoch:3 step:2913 [D loss: 0.706014, acc.: 47.66%] [G loss: 0.760965]\n",
      "epoch:3 step:2914 [D loss: 0.709137, acc.: 45.31%] [G loss: 0.725555]\n",
      "epoch:3 step:2915 [D loss: 0.696041, acc.: 57.03%] [G loss: 0.726723]\n",
      "epoch:3 step:2916 [D loss: 0.698558, acc.: 53.12%] [G loss: 0.760393]\n",
      "epoch:3 step:2917 [D loss: 0.707252, acc.: 47.66%] [G loss: 0.753262]\n",
      "epoch:3 step:2918 [D loss: 0.684307, acc.: 58.59%] [G loss: 0.760219]\n",
      "epoch:3 step:2919 [D loss: 0.712503, acc.: 44.53%] [G loss: 0.754668]\n",
      "epoch:3 step:2920 [D loss: 0.696764, acc.: 52.34%] [G loss: 0.763562]\n",
      "epoch:3 step:2921 [D loss: 0.693851, acc.: 50.00%] [G loss: 0.796546]\n",
      "epoch:3 step:2922 [D loss: 0.701057, acc.: 48.44%] [G loss: 0.738411]\n",
      "epoch:3 step:2923 [D loss: 0.691393, acc.: 55.47%] [G loss: 0.750134]\n",
      "epoch:3 step:2924 [D loss: 0.718261, acc.: 41.41%] [G loss: 0.732851]\n",
      "epoch:3 step:2925 [D loss: 0.670390, acc.: 61.72%] [G loss: 0.751204]\n",
      "epoch:3 step:2926 [D loss: 0.684645, acc.: 54.69%] [G loss: 0.729987]\n",
      "epoch:3 step:2927 [D loss: 0.686047, acc.: 56.25%] [G loss: 0.754553]\n",
      "epoch:3 step:2928 [D loss: 0.678075, acc.: 55.47%] [G loss: 0.728545]\n",
      "epoch:3 step:2929 [D loss: 0.689368, acc.: 52.34%] [G loss: 0.753259]\n",
      "epoch:3 step:2930 [D loss: 0.692898, acc.: 55.47%] [G loss: 0.720836]\n",
      "epoch:3 step:2931 [D loss: 0.731801, acc.: 42.97%] [G loss: 0.758086]\n",
      "epoch:3 step:2932 [D loss: 0.676488, acc.: 55.47%] [G loss: 0.756148]\n",
      "epoch:3 step:2933 [D loss: 0.700326, acc.: 47.66%] [G loss: 0.763035]\n",
      "epoch:3 step:2934 [D loss: 0.716585, acc.: 47.66%] [G loss: 0.826177]\n",
      "epoch:3 step:2935 [D loss: 0.681616, acc.: 63.28%] [G loss: 0.810190]\n",
      "epoch:3 step:2936 [D loss: 0.701465, acc.: 56.25%] [G loss: 0.788166]\n",
      "epoch:3 step:2937 [D loss: 0.678970, acc.: 57.81%] [G loss: 0.803699]\n",
      "epoch:3 step:2938 [D loss: 0.675666, acc.: 57.81%] [G loss: 0.796290]\n",
      "epoch:3 step:2939 [D loss: 0.675357, acc.: 55.47%] [G loss: 0.821114]\n",
      "epoch:3 step:2940 [D loss: 0.659662, acc.: 60.94%] [G loss: 0.841960]\n",
      "epoch:3 step:2941 [D loss: 0.629114, acc.: 71.09%] [G loss: 0.809959]\n",
      "epoch:3 step:2942 [D loss: 0.664292, acc.: 62.50%] [G loss: 0.808360]\n",
      "epoch:3 step:2943 [D loss: 0.691656, acc.: 53.12%] [G loss: 0.799176]\n",
      "epoch:3 step:2944 [D loss: 0.685694, acc.: 57.03%] [G loss: 0.749629]\n",
      "epoch:3 step:2945 [D loss: 0.698532, acc.: 54.69%] [G loss: 0.619573]\n",
      "epoch:3 step:2946 [D loss: 0.718384, acc.: 45.31%] [G loss: 0.735737]\n",
      "epoch:3 step:2947 [D loss: 0.716930, acc.: 47.66%] [G loss: 0.632722]\n",
      "epoch:3 step:2948 [D loss: 0.693809, acc.: 53.91%] [G loss: 0.713553]\n",
      "epoch:3 step:2949 [D loss: 0.734369, acc.: 42.19%] [G loss: 0.720178]\n",
      "epoch:3 step:2950 [D loss: 0.767938, acc.: 40.62%] [G loss: 0.735372]\n",
      "epoch:3 step:2951 [D loss: 0.702433, acc.: 53.12%] [G loss: 0.794697]\n",
      "epoch:3 step:2952 [D loss: 0.716720, acc.: 36.72%] [G loss: 0.825725]\n",
      "epoch:3 step:2953 [D loss: 0.703669, acc.: 52.34%] [G loss: 0.825378]\n",
      "epoch:3 step:2954 [D loss: 0.676822, acc.: 57.03%] [G loss: 0.810390]\n",
      "epoch:3 step:2955 [D loss: 0.640662, acc.: 68.75%] [G loss: 0.907584]\n",
      "epoch:3 step:2956 [D loss: 0.642831, acc.: 71.09%] [G loss: 0.793202]\n",
      "epoch:3 step:2957 [D loss: 0.647866, acc.: 64.06%] [G loss: 0.795133]\n",
      "epoch:3 step:2958 [D loss: 0.700262, acc.: 48.44%] [G loss: 0.889824]\n",
      "epoch:3 step:2959 [D loss: 0.716376, acc.: 50.00%] [G loss: 0.826131]\n",
      "epoch:3 step:2960 [D loss: 0.678704, acc.: 59.38%] [G loss: 0.674830]\n",
      "epoch:3 step:2961 [D loss: 0.683568, acc.: 58.59%] [G loss: 0.744193]\n",
      "epoch:3 step:2962 [D loss: 0.694598, acc.: 50.78%] [G loss: 0.733220]\n",
      "epoch:3 step:2963 [D loss: 0.684776, acc.: 55.47%] [G loss: 0.765242]\n",
      "epoch:3 step:2964 [D loss: 0.782470, acc.: 35.16%] [G loss: 0.717857]\n",
      "epoch:3 step:2965 [D loss: 0.728134, acc.: 42.19%] [G loss: 0.711769]\n",
      "epoch:3 step:2966 [D loss: 0.708157, acc.: 48.44%] [G loss: 0.698484]\n",
      "epoch:3 step:2967 [D loss: 0.704092, acc.: 48.44%] [G loss: 0.690228]\n",
      "epoch:3 step:2968 [D loss: 0.709887, acc.: 46.88%] [G loss: 0.720910]\n",
      "epoch:3 step:2969 [D loss: 0.690575, acc.: 54.69%] [G loss: 0.750613]\n",
      "epoch:3 step:2970 [D loss: 0.703989, acc.: 46.09%] [G loss: 0.808802]\n",
      "epoch:3 step:2971 [D loss: 0.687982, acc.: 58.59%] [G loss: 0.790865]\n",
      "epoch:3 step:2972 [D loss: 0.689583, acc.: 55.47%] [G loss: 0.791203]\n",
      "epoch:3 step:2973 [D loss: 0.666548, acc.: 60.94%] [G loss: 0.840787]\n",
      "epoch:3 step:2974 [D loss: 0.680016, acc.: 59.38%] [G loss: 0.859642]\n",
      "epoch:3 step:2975 [D loss: 0.665490, acc.: 62.50%] [G loss: 0.800397]\n",
      "epoch:3 step:2976 [D loss: 0.687462, acc.: 58.59%] [G loss: 0.805330]\n",
      "epoch:3 step:2977 [D loss: 0.671861, acc.: 57.03%] [G loss: 0.774008]\n",
      "epoch:3 step:2978 [D loss: 0.716666, acc.: 47.66%] [G loss: 0.748924]\n",
      "epoch:3 step:2979 [D loss: 0.674167, acc.: 56.25%] [G loss: 0.749807]\n",
      "epoch:3 step:2980 [D loss: 0.699676, acc.: 48.44%] [G loss: 0.744008]\n",
      "epoch:3 step:2981 [D loss: 0.723626, acc.: 39.84%] [G loss: 0.716770]\n",
      "epoch:3 step:2982 [D loss: 0.691058, acc.: 50.00%] [G loss: 0.700814]\n",
      "epoch:3 step:2983 [D loss: 0.690609, acc.: 53.91%] [G loss: 0.708032]\n",
      "epoch:3 step:2984 [D loss: 0.675703, acc.: 52.34%] [G loss: 0.728794]\n",
      "epoch:3 step:2985 [D loss: 0.729278, acc.: 38.28%] [G loss: 0.707687]\n",
      "epoch:3 step:2986 [D loss: 0.700293, acc.: 54.69%] [G loss: 0.705911]\n",
      "epoch:3 step:2987 [D loss: 0.724788, acc.: 44.53%] [G loss: 0.741348]\n",
      "epoch:3 step:2988 [D loss: 0.702876, acc.: 47.66%] [G loss: 0.741294]\n",
      "epoch:3 step:2989 [D loss: 0.683668, acc.: 57.03%] [G loss: 0.749052]\n",
      "epoch:3 step:2990 [D loss: 0.706502, acc.: 45.31%] [G loss: 0.793994]\n",
      "epoch:3 step:2991 [D loss: 0.676471, acc.: 56.25%] [G loss: 0.774021]\n",
      "epoch:3 step:2992 [D loss: 0.677888, acc.: 62.50%] [G loss: 0.746704]\n",
      "epoch:3 step:2993 [D loss: 0.677120, acc.: 59.38%] [G loss: 0.744686]\n",
      "epoch:3 step:2994 [D loss: 0.676438, acc.: 58.59%] [G loss: 0.780379]\n",
      "epoch:3 step:2995 [D loss: 0.625160, acc.: 67.97%] [G loss: 0.801898]\n",
      "epoch:3 step:2996 [D loss: 0.663366, acc.: 56.25%] [G loss: 0.770494]\n",
      "epoch:3 step:2997 [D loss: 0.701094, acc.: 54.69%] [G loss: 0.759084]\n",
      "epoch:3 step:2998 [D loss: 0.638014, acc.: 57.81%] [G loss: 0.573872]\n",
      "epoch:3 step:2999 [D loss: 0.700222, acc.: 54.69%] [G loss: 0.613200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3000 [D loss: 0.722049, acc.: 44.53%] [G loss: 0.656184]\n",
      "epoch:3 step:3001 [D loss: 0.741809, acc.: 37.50%] [G loss: 0.663553]\n",
      "epoch:3 step:3002 [D loss: 0.693625, acc.: 50.00%] [G loss: 0.650352]\n",
      "epoch:3 step:3003 [D loss: 0.685350, acc.: 53.91%] [G loss: 0.674217]\n",
      "epoch:3 step:3004 [D loss: 0.698104, acc.: 46.88%] [G loss: 0.611792]\n",
      "epoch:3 step:3005 [D loss: 0.720579, acc.: 35.94%] [G loss: 0.695871]\n",
      "epoch:3 step:3006 [D loss: 0.772091, acc.: 39.06%] [G loss: 0.764779]\n",
      "epoch:3 step:3007 [D loss: 0.681691, acc.: 55.47%] [G loss: 0.810017]\n",
      "epoch:3 step:3008 [D loss: 0.694725, acc.: 49.22%] [G loss: 0.899196]\n",
      "epoch:3 step:3009 [D loss: 0.679299, acc.: 56.25%] [G loss: 0.848969]\n",
      "epoch:3 step:3010 [D loss: 0.672577, acc.: 53.12%] [G loss: 0.889324]\n",
      "epoch:3 step:3011 [D loss: 0.656457, acc.: 57.81%] [G loss: 0.908420]\n",
      "epoch:3 step:3012 [D loss: 0.658580, acc.: 59.38%] [G loss: 0.970475]\n",
      "epoch:3 step:3013 [D loss: 0.695935, acc.: 52.34%] [G loss: 0.949373]\n",
      "epoch:3 step:3014 [D loss: 0.719520, acc.: 46.09%] [G loss: 0.808569]\n",
      "epoch:3 step:3015 [D loss: 0.736439, acc.: 46.09%] [G loss: 0.787130]\n",
      "epoch:3 step:3016 [D loss: 0.668242, acc.: 67.97%] [G loss: 0.744109]\n",
      "epoch:3 step:3017 [D loss: 0.682007, acc.: 55.47%] [G loss: 0.719803]\n",
      "epoch:3 step:3018 [D loss: 0.734447, acc.: 44.53%] [G loss: 0.757392]\n",
      "epoch:3 step:3019 [D loss: 0.708781, acc.: 44.53%] [G loss: 0.744843]\n",
      "epoch:3 step:3020 [D loss: 0.703582, acc.: 51.56%] [G loss: 0.686254]\n",
      "epoch:3 step:3021 [D loss: 0.709742, acc.: 48.44%] [G loss: 0.742049]\n",
      "epoch:3 step:3022 [D loss: 0.707323, acc.: 50.00%] [G loss: 0.763893]\n",
      "epoch:3 step:3023 [D loss: 0.694632, acc.: 49.22%] [G loss: 0.748796]\n",
      "epoch:3 step:3024 [D loss: 0.696746, acc.: 46.09%] [G loss: 0.743042]\n",
      "epoch:3 step:3025 [D loss: 0.700645, acc.: 48.44%] [G loss: 0.710185]\n",
      "epoch:3 step:3026 [D loss: 0.693206, acc.: 54.69%] [G loss: 0.748804]\n",
      "epoch:3 step:3027 [D loss: 0.706356, acc.: 46.88%] [G loss: 0.605090]\n",
      "epoch:3 step:3028 [D loss: 0.699231, acc.: 47.66%] [G loss: 0.692214]\n",
      "epoch:3 step:3029 [D loss: 0.685471, acc.: 55.47%] [G loss: 0.701503]\n",
      "epoch:3 step:3030 [D loss: 0.657116, acc.: 67.97%] [G loss: 0.737768]\n",
      "epoch:3 step:3031 [D loss: 0.705448, acc.: 46.09%] [G loss: 0.729090]\n",
      "epoch:3 step:3032 [D loss: 0.712930, acc.: 42.97%] [G loss: 0.761097]\n",
      "epoch:3 step:3033 [D loss: 0.670954, acc.: 60.94%] [G loss: 0.739589]\n",
      "epoch:3 step:3034 [D loss: 0.667860, acc.: 61.72%] [G loss: 0.747128]\n",
      "epoch:3 step:3035 [D loss: 0.685423, acc.: 60.94%] [G loss: 0.735419]\n",
      "epoch:3 step:3036 [D loss: 0.693717, acc.: 53.12%] [G loss: 0.739923]\n",
      "epoch:3 step:3037 [D loss: 0.687189, acc.: 53.12%] [G loss: 0.767767]\n",
      "epoch:3 step:3038 [D loss: 0.691116, acc.: 53.91%] [G loss: 0.754011]\n",
      "epoch:3 step:3039 [D loss: 0.678441, acc.: 57.03%] [G loss: 0.727782]\n",
      "epoch:3 step:3040 [D loss: 0.673179, acc.: 64.06%] [G loss: 0.767854]\n",
      "epoch:3 step:3041 [D loss: 0.652528, acc.: 65.62%] [G loss: 0.761183]\n",
      "epoch:3 step:3042 [D loss: 0.651740, acc.: 66.41%] [G loss: 0.753386]\n",
      "epoch:3 step:3043 [D loss: 0.628180, acc.: 72.66%] [G loss: 0.854805]\n",
      "epoch:3 step:3044 [D loss: 0.691428, acc.: 56.25%] [G loss: 0.836772]\n",
      "epoch:3 step:3045 [D loss: 0.701363, acc.: 49.22%] [G loss: 0.823809]\n",
      "epoch:3 step:3046 [D loss: 0.655780, acc.: 59.38%] [G loss: 0.739171]\n",
      "epoch:3 step:3047 [D loss: 0.700570, acc.: 46.88%] [G loss: 0.801600]\n",
      "epoch:3 step:3048 [D loss: 0.651277, acc.: 63.28%] [G loss: 0.778998]\n",
      "epoch:3 step:3049 [D loss: 0.710933, acc.: 46.88%] [G loss: 0.834328]\n",
      "epoch:3 step:3050 [D loss: 0.741282, acc.: 39.06%] [G loss: 0.756424]\n",
      "epoch:3 step:3051 [D loss: 0.732123, acc.: 37.50%] [G loss: 0.907123]\n",
      "epoch:3 step:3052 [D loss: 0.759507, acc.: 34.38%] [G loss: 0.756329]\n",
      "epoch:3 step:3053 [D loss: 0.710260, acc.: 43.75%] [G loss: 0.747192]\n",
      "epoch:3 step:3054 [D loss: 0.689049, acc.: 48.44%] [G loss: 0.739435]\n",
      "epoch:3 step:3055 [D loss: 0.676468, acc.: 53.91%] [G loss: 0.714986]\n",
      "epoch:3 step:3056 [D loss: 0.701401, acc.: 50.00%] [G loss: 0.727821]\n",
      "epoch:3 step:3057 [D loss: 0.707867, acc.: 50.78%] [G loss: 0.738977]\n",
      "epoch:3 step:3058 [D loss: 0.693244, acc.: 52.34%] [G loss: 0.724183]\n",
      "epoch:3 step:3059 [D loss: 0.687869, acc.: 50.78%] [G loss: 0.754086]\n",
      "epoch:3 step:3060 [D loss: 0.696818, acc.: 47.66%] [G loss: 0.757903]\n",
      "epoch:3 step:3061 [D loss: 0.664205, acc.: 62.50%] [G loss: 0.746887]\n",
      "epoch:3 step:3062 [D loss: 0.684175, acc.: 57.81%] [G loss: 0.728070]\n",
      "epoch:3 step:3063 [D loss: 0.664884, acc.: 57.81%] [G loss: 0.695430]\n",
      "epoch:3 step:3064 [D loss: 0.665409, acc.: 62.50%] [G loss: 0.755057]\n",
      "epoch:3 step:3065 [D loss: 0.674188, acc.: 58.59%] [G loss: 0.759529]\n",
      "epoch:3 step:3066 [D loss: 0.706494, acc.: 44.53%] [G loss: 0.745602]\n",
      "epoch:3 step:3067 [D loss: 0.696541, acc.: 54.69%] [G loss: 0.745658]\n",
      "epoch:3 step:3068 [D loss: 0.673717, acc.: 60.94%] [G loss: 0.743760]\n",
      "epoch:3 step:3069 [D loss: 0.679605, acc.: 60.16%] [G loss: 0.750981]\n",
      "epoch:3 step:3070 [D loss: 0.710226, acc.: 44.53%] [G loss: 0.740834]\n",
      "epoch:3 step:3071 [D loss: 0.712666, acc.: 40.62%] [G loss: 0.735647]\n",
      "epoch:3 step:3072 [D loss: 0.690506, acc.: 55.47%] [G loss: 0.731249]\n",
      "epoch:3 step:3073 [D loss: 0.696508, acc.: 46.88%] [G loss: 0.737286]\n",
      "epoch:3 step:3074 [D loss: 0.613074, acc.: 56.25%] [G loss: 0.781345]\n",
      "epoch:3 step:3075 [D loss: 0.632416, acc.: 70.31%] [G loss: 0.758205]\n",
      "epoch:3 step:3076 [D loss: 0.735517, acc.: 46.09%] [G loss: 0.743081]\n",
      "epoch:3 step:3077 [D loss: 0.730030, acc.: 39.84%] [G loss: 0.718577]\n",
      "epoch:3 step:3078 [D loss: 0.720945, acc.: 41.41%] [G loss: 0.760110]\n",
      "epoch:3 step:3079 [D loss: 0.676527, acc.: 64.06%] [G loss: 0.748038]\n",
      "epoch:3 step:3080 [D loss: 0.687015, acc.: 53.12%] [G loss: 0.739582]\n",
      "epoch:3 step:3081 [D loss: 0.681242, acc.: 58.59%] [G loss: 0.797583]\n",
      "epoch:3 step:3082 [D loss: 0.658331, acc.: 64.84%] [G loss: 0.766083]\n",
      "epoch:3 step:3083 [D loss: 0.673275, acc.: 60.94%] [G loss: 0.791421]\n",
      "epoch:3 step:3084 [D loss: 0.669340, acc.: 61.72%] [G loss: 0.798663]\n",
      "epoch:3 step:3085 [D loss: 0.672053, acc.: 59.38%] [G loss: 0.795016]\n",
      "epoch:3 step:3086 [D loss: 0.705573, acc.: 48.44%] [G loss: 0.644078]\n",
      "epoch:3 step:3087 [D loss: 0.679404, acc.: 53.91%] [G loss: 0.575523]\n",
      "epoch:3 step:3088 [D loss: 0.779992, acc.: 34.38%] [G loss: 0.808274]\n",
      "epoch:3 step:3089 [D loss: 0.677199, acc.: 51.56%] [G loss: 0.876713]\n",
      "epoch:3 step:3090 [D loss: 0.715672, acc.: 46.88%] [G loss: 0.908002]\n",
      "epoch:3 step:3091 [D loss: 0.670719, acc.: 53.91%] [G loss: 0.901384]\n",
      "epoch:3 step:3092 [D loss: 0.724564, acc.: 50.78%] [G loss: 0.904033]\n",
      "epoch:3 step:3093 [D loss: 0.709090, acc.: 47.66%] [G loss: 0.862895]\n",
      "epoch:3 step:3094 [D loss: 0.691646, acc.: 52.34%] [G loss: 0.845125]\n",
      "epoch:3 step:3095 [D loss: 0.684368, acc.: 54.69%] [G loss: 0.808358]\n",
      "epoch:3 step:3096 [D loss: 0.676452, acc.: 55.47%] [G loss: 0.768912]\n",
      "epoch:3 step:3097 [D loss: 0.667277, acc.: 59.38%] [G loss: 0.792276]\n",
      "epoch:3 step:3098 [D loss: 0.691183, acc.: 46.09%] [G loss: 0.865117]\n",
      "epoch:3 step:3099 [D loss: 0.676340, acc.: 58.59%] [G loss: 0.766916]\n",
      "epoch:3 step:3100 [D loss: 0.707304, acc.: 50.78%] [G loss: 0.740917]\n",
      "epoch:3 step:3101 [D loss: 0.672259, acc.: 57.81%] [G loss: 0.728048]\n",
      "epoch:3 step:3102 [D loss: 0.714854, acc.: 48.44%] [G loss: 0.778934]\n",
      "epoch:3 step:3103 [D loss: 0.685333, acc.: 56.25%] [G loss: 0.791174]\n",
      "epoch:3 step:3104 [D loss: 0.690032, acc.: 51.56%] [G loss: 0.804770]\n",
      "epoch:3 step:3105 [D loss: 0.699464, acc.: 51.56%] [G loss: 0.719931]\n",
      "epoch:3 step:3106 [D loss: 0.733956, acc.: 39.06%] [G loss: 0.729015]\n",
      "epoch:3 step:3107 [D loss: 0.699578, acc.: 50.00%] [G loss: 0.715162]\n",
      "epoch:3 step:3108 [D loss: 0.718077, acc.: 44.53%] [G loss: 0.736589]\n",
      "epoch:3 step:3109 [D loss: 0.700472, acc.: 52.34%] [G loss: 0.711843]\n",
      "epoch:3 step:3110 [D loss: 0.712438, acc.: 43.75%] [G loss: 0.730101]\n",
      "epoch:3 step:3111 [D loss: 0.699758, acc.: 50.78%] [G loss: 0.737683]\n",
      "epoch:3 step:3112 [D loss: 0.693421, acc.: 50.78%] [G loss: 0.751983]\n",
      "epoch:3 step:3113 [D loss: 0.693905, acc.: 53.12%] [G loss: 0.724714]\n",
      "epoch:3 step:3114 [D loss: 0.694479, acc.: 53.91%] [G loss: 0.720194]\n",
      "epoch:3 step:3115 [D loss: 0.719372, acc.: 48.44%] [G loss: 0.736673]\n",
      "epoch:3 step:3116 [D loss: 0.686688, acc.: 56.25%] [G loss: 0.728756]\n",
      "epoch:3 step:3117 [D loss: 0.694294, acc.: 54.69%] [G loss: 0.736037]\n",
      "epoch:3 step:3118 [D loss: 0.697069, acc.: 53.91%] [G loss: 0.745762]\n",
      "epoch:3 step:3119 [D loss: 0.679402, acc.: 57.81%] [G loss: 0.744433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3120 [D loss: 0.695894, acc.: 51.56%] [G loss: 0.766722]\n",
      "epoch:3 step:3121 [D loss: 0.670321, acc.: 62.50%] [G loss: 0.755416]\n",
      "epoch:3 step:3122 [D loss: 0.677904, acc.: 58.59%] [G loss: 0.751133]\n",
      "epoch:3 step:3123 [D loss: 0.703778, acc.: 53.91%] [G loss: 0.740713]\n",
      "epoch:3 step:3124 [D loss: 0.687835, acc.: 54.69%] [G loss: 0.780828]\n",
      "epoch:3 step:3125 [D loss: 0.666711, acc.: 59.38%] [G loss: 0.765752]\n",
      "epoch:3 step:3126 [D loss: 0.669818, acc.: 58.59%] [G loss: 0.750823]\n",
      "epoch:3 step:3127 [D loss: 0.705145, acc.: 49.22%] [G loss: 0.698298]\n",
      "epoch:3 step:3128 [D loss: 0.678744, acc.: 60.94%] [G loss: 0.790227]\n",
      "epoch:3 step:3129 [D loss: 0.708458, acc.: 48.44%] [G loss: 0.732115]\n",
      "epoch:3 step:3130 [D loss: 0.690912, acc.: 53.12%] [G loss: 0.745182]\n",
      "epoch:3 step:3131 [D loss: 0.712371, acc.: 42.97%] [G loss: 0.697627]\n",
      "epoch:3 step:3132 [D loss: 0.733445, acc.: 48.44%] [G loss: 0.703927]\n",
      "epoch:3 step:3133 [D loss: 0.687382, acc.: 55.47%] [G loss: 0.750439]\n",
      "epoch:3 step:3134 [D loss: 0.692949, acc.: 50.00%] [G loss: 0.761121]\n",
      "epoch:3 step:3135 [D loss: 0.691030, acc.: 52.34%] [G loss: 0.729254]\n",
      "epoch:3 step:3136 [D loss: 0.679839, acc.: 56.25%] [G loss: 0.723910]\n",
      "epoch:3 step:3137 [D loss: 0.709928, acc.: 48.44%] [G loss: 0.757699]\n",
      "epoch:3 step:3138 [D loss: 0.676832, acc.: 57.81%] [G loss: 0.740164]\n",
      "epoch:3 step:3139 [D loss: 0.709554, acc.: 49.22%] [G loss: 0.742689]\n",
      "epoch:3 step:3140 [D loss: 0.694969, acc.: 50.00%] [G loss: 0.730178]\n",
      "epoch:3 step:3141 [D loss: 0.670877, acc.: 63.28%] [G loss: 0.722882]\n",
      "epoch:3 step:3142 [D loss: 0.690606, acc.: 53.91%] [G loss: 0.739806]\n",
      "epoch:3 step:3143 [D loss: 0.715001, acc.: 47.66%] [G loss: 0.714486]\n",
      "epoch:3 step:3144 [D loss: 0.700562, acc.: 45.31%] [G loss: 0.726594]\n",
      "epoch:3 step:3145 [D loss: 0.692112, acc.: 46.09%] [G loss: 0.771680]\n",
      "epoch:3 step:3146 [D loss: 0.697500, acc.: 54.69%] [G loss: 0.745063]\n",
      "epoch:3 step:3147 [D loss: 0.692527, acc.: 53.12%] [G loss: 0.828858]\n",
      "epoch:3 step:3148 [D loss: 0.684192, acc.: 52.34%] [G loss: 0.737335]\n",
      "epoch:3 step:3149 [D loss: 0.690926, acc.: 54.69%] [G loss: 0.741930]\n",
      "epoch:3 step:3150 [D loss: 0.689482, acc.: 53.91%] [G loss: 0.739551]\n",
      "epoch:3 step:3151 [D loss: 0.724322, acc.: 44.53%] [G loss: 0.719242]\n",
      "epoch:3 step:3152 [D loss: 0.710153, acc.: 53.91%] [G loss: 0.740153]\n",
      "epoch:3 step:3153 [D loss: 0.682245, acc.: 54.69%] [G loss: 0.750208]\n",
      "epoch:3 step:3154 [D loss: 0.693436, acc.: 53.91%] [G loss: 0.738122]\n",
      "epoch:3 step:3155 [D loss: 0.678527, acc.: 58.59%] [G loss: 0.751177]\n",
      "epoch:3 step:3156 [D loss: 0.685321, acc.: 52.34%] [G loss: 0.767674]\n",
      "epoch:3 step:3157 [D loss: 0.683020, acc.: 54.69%] [G loss: 0.775737]\n",
      "epoch:3 step:3158 [D loss: 0.667767, acc.: 64.84%] [G loss: 0.773995]\n",
      "epoch:3 step:3159 [D loss: 0.717950, acc.: 49.22%] [G loss: 0.786271]\n",
      "epoch:3 step:3160 [D loss: 0.705570, acc.: 53.12%] [G loss: 0.765241]\n",
      "epoch:3 step:3161 [D loss: 0.709525, acc.: 50.78%] [G loss: 0.766131]\n",
      "epoch:3 step:3162 [D loss: 0.701188, acc.: 48.44%] [G loss: 0.722181]\n",
      "epoch:3 step:3163 [D loss: 0.705367, acc.: 44.53%] [G loss: 0.736608]\n",
      "epoch:3 step:3164 [D loss: 0.686119, acc.: 53.12%] [G loss: 0.743478]\n",
      "epoch:3 step:3165 [D loss: 0.687833, acc.: 56.25%] [G loss: 0.723756]\n",
      "epoch:3 step:3166 [D loss: 0.661617, acc.: 60.94%] [G loss: 0.754869]\n",
      "epoch:3 step:3167 [D loss: 0.683440, acc.: 50.78%] [G loss: 0.733175]\n",
      "epoch:3 step:3168 [D loss: 0.677295, acc.: 57.03%] [G loss: 0.739238]\n",
      "epoch:3 step:3169 [D loss: 0.700842, acc.: 46.09%] [G loss: 0.751912]\n",
      "epoch:3 step:3170 [D loss: 0.675551, acc.: 57.81%] [G loss: 0.737594]\n",
      "epoch:3 step:3171 [D loss: 0.699053, acc.: 53.91%] [G loss: 0.727461]\n",
      "epoch:3 step:3172 [D loss: 0.693025, acc.: 52.34%] [G loss: 0.769135]\n",
      "epoch:3 step:3173 [D loss: 0.707086, acc.: 44.53%] [G loss: 0.717282]\n",
      "epoch:3 step:3174 [D loss: 0.713643, acc.: 46.88%] [G loss: 0.704848]\n",
      "epoch:3 step:3175 [D loss: 0.690784, acc.: 50.00%] [G loss: 0.709691]\n",
      "epoch:3 step:3176 [D loss: 0.690329, acc.: 47.66%] [G loss: 0.752929]\n",
      "epoch:3 step:3177 [D loss: 0.681215, acc.: 57.03%] [G loss: 0.749049]\n",
      "epoch:3 step:3178 [D loss: 0.655507, acc.: 67.19%] [G loss: 0.768876]\n",
      "epoch:3 step:3179 [D loss: 0.695932, acc.: 53.91%] [G loss: 0.743279]\n",
      "epoch:3 step:3180 [D loss: 0.683306, acc.: 44.53%] [G loss: 0.794819]\n",
      "epoch:3 step:3181 [D loss: 0.650095, acc.: 63.28%] [G loss: 0.844568]\n",
      "epoch:3 step:3182 [D loss: 0.625856, acc.: 60.94%] [G loss: 0.801856]\n",
      "epoch:3 step:3183 [D loss: 0.662277, acc.: 65.62%] [G loss: 0.734214]\n",
      "epoch:3 step:3184 [D loss: 0.745396, acc.: 40.62%] [G loss: 0.700689]\n",
      "epoch:3 step:3185 [D loss: 0.674487, acc.: 59.38%] [G loss: 0.707014]\n",
      "epoch:3 step:3186 [D loss: 0.759740, acc.: 41.41%] [G loss: 0.658382]\n",
      "epoch:3 step:3187 [D loss: 0.748537, acc.: 39.84%] [G loss: 0.719188]\n",
      "epoch:3 step:3188 [D loss: 0.740249, acc.: 37.50%] [G loss: 0.674826]\n",
      "epoch:3 step:3189 [D loss: 0.699352, acc.: 48.44%] [G loss: 0.705686]\n",
      "epoch:3 step:3190 [D loss: 0.682480, acc.: 57.81%] [G loss: 0.755491]\n",
      "epoch:3 step:3191 [D loss: 0.684898, acc.: 60.94%] [G loss: 0.738234]\n",
      "epoch:3 step:3192 [D loss: 0.688904, acc.: 52.34%] [G loss: 0.782979]\n",
      "epoch:3 step:3193 [D loss: 0.664364, acc.: 60.94%] [G loss: 0.783757]\n",
      "epoch:3 step:3194 [D loss: 0.660244, acc.: 65.62%] [G loss: 0.848891]\n",
      "epoch:3 step:3195 [D loss: 0.663466, acc.: 60.94%] [G loss: 0.864145]\n",
      "epoch:3 step:3196 [D loss: 0.679549, acc.: 58.59%] [G loss: 0.878418]\n",
      "epoch:3 step:3197 [D loss: 0.673432, acc.: 57.03%] [G loss: 0.801272]\n",
      "epoch:3 step:3198 [D loss: 0.676103, acc.: 60.16%] [G loss: 0.797152]\n",
      "epoch:3 step:3199 [D loss: 0.687907, acc.: 51.56%] [G loss: 0.732084]\n",
      "epoch:3 step:3200 [D loss: 0.720093, acc.: 46.88%] [G loss: 0.691635]\n",
      "epoch:3 step:3201 [D loss: 0.736042, acc.: 35.94%] [G loss: 0.688087]\n",
      "epoch:3 step:3202 [D loss: 0.720429, acc.: 40.62%] [G loss: 0.685153]\n",
      "epoch:3 step:3203 [D loss: 0.728349, acc.: 36.72%] [G loss: 0.719956]\n",
      "epoch:3 step:3204 [D loss: 0.711488, acc.: 42.97%] [G loss: 0.707964]\n",
      "epoch:3 step:3205 [D loss: 0.701863, acc.: 52.34%] [G loss: 0.705837]\n",
      "epoch:3 step:3206 [D loss: 0.700149, acc.: 54.69%] [G loss: 0.732514]\n",
      "epoch:3 step:3207 [D loss: 0.691091, acc.: 58.59%] [G loss: 0.732665]\n",
      "epoch:3 step:3208 [D loss: 0.684061, acc.: 56.25%] [G loss: 0.762993]\n",
      "epoch:3 step:3209 [D loss: 0.670469, acc.: 66.41%] [G loss: 0.735613]\n",
      "epoch:3 step:3210 [D loss: 0.673961, acc.: 61.72%] [G loss: 0.766466]\n",
      "epoch:3 step:3211 [D loss: 0.670081, acc.: 60.16%] [G loss: 0.764554]\n",
      "epoch:3 step:3212 [D loss: 0.667730, acc.: 54.69%] [G loss: 0.837867]\n",
      "epoch:3 step:3213 [D loss: 0.674445, acc.: 54.69%] [G loss: 0.723662]\n",
      "epoch:3 step:3214 [D loss: 0.669187, acc.: 60.94%] [G loss: 0.909127]\n",
      "epoch:3 step:3215 [D loss: 0.668582, acc.: 64.06%] [G loss: 0.796839]\n",
      "epoch:3 step:3216 [D loss: 0.684450, acc.: 60.16%] [G loss: 0.819797]\n",
      "epoch:3 step:3217 [D loss: 0.648779, acc.: 67.19%] [G loss: 0.819116]\n",
      "epoch:3 step:3218 [D loss: 0.681531, acc.: 53.12%] [G loss: 0.857530]\n",
      "epoch:3 step:3219 [D loss: 0.701103, acc.: 50.78%] [G loss: 0.738046]\n",
      "epoch:3 step:3220 [D loss: 0.697605, acc.: 50.00%] [G loss: 0.747722]\n",
      "epoch:3 step:3221 [D loss: 0.733650, acc.: 39.06%] [G loss: 0.776523]\n",
      "epoch:3 step:3222 [D loss: 0.746428, acc.: 36.72%] [G loss: 0.737490]\n",
      "epoch:3 step:3223 [D loss: 0.685197, acc.: 51.56%] [G loss: 0.740779]\n",
      "epoch:3 step:3224 [D loss: 0.696285, acc.: 55.47%] [G loss: 0.724666]\n",
      "epoch:3 step:3225 [D loss: 0.689776, acc.: 54.69%] [G loss: 0.755907]\n",
      "epoch:3 step:3226 [D loss: 0.676835, acc.: 51.56%] [G loss: 0.744193]\n",
      "epoch:3 step:3227 [D loss: 0.698372, acc.: 48.44%] [G loss: 0.716913]\n",
      "epoch:3 step:3228 [D loss: 0.697635, acc.: 53.91%] [G loss: 0.716308]\n",
      "epoch:3 step:3229 [D loss: 0.701354, acc.: 50.78%] [G loss: 0.783012]\n",
      "epoch:3 step:3230 [D loss: 0.686343, acc.: 57.81%] [G loss: 0.723450]\n",
      "epoch:3 step:3231 [D loss: 0.691934, acc.: 53.91%] [G loss: 0.810678]\n",
      "epoch:3 step:3232 [D loss: 0.705598, acc.: 50.00%] [G loss: 0.768862]\n",
      "epoch:3 step:3233 [D loss: 0.699302, acc.: 49.22%] [G loss: 0.811559]\n",
      "epoch:3 step:3234 [D loss: 0.701073, acc.: 48.44%] [G loss: 0.777927]\n",
      "epoch:3 step:3235 [D loss: 0.704462, acc.: 46.09%] [G loss: 0.743671]\n",
      "epoch:3 step:3236 [D loss: 0.668528, acc.: 59.38%] [G loss: 0.777110]\n",
      "epoch:3 step:3237 [D loss: 0.664547, acc.: 58.59%] [G loss: 0.747994]\n",
      "epoch:3 step:3238 [D loss: 0.692462, acc.: 55.47%] [G loss: 0.771063]\n",
      "epoch:3 step:3239 [D loss: 0.684239, acc.: 52.34%] [G loss: 0.818703]\n",
      "epoch:3 step:3240 [D loss: 0.696723, acc.: 43.75%] [G loss: 0.761835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3241 [D loss: 0.673218, acc.: 60.16%] [G loss: 0.761285]\n",
      "epoch:3 step:3242 [D loss: 0.728555, acc.: 40.62%] [G loss: 0.789220]\n",
      "epoch:3 step:3243 [D loss: 0.730602, acc.: 40.62%] [G loss: 0.750795]\n",
      "epoch:3 step:3244 [D loss: 0.711764, acc.: 46.09%] [G loss: 0.750354]\n",
      "epoch:3 step:3245 [D loss: 0.688996, acc.: 57.03%] [G loss: 0.719256]\n",
      "epoch:3 step:3246 [D loss: 0.681289, acc.: 54.69%] [G loss: 0.745747]\n",
      "epoch:3 step:3247 [D loss: 0.658841, acc.: 59.38%] [G loss: 0.755677]\n",
      "epoch:3 step:3248 [D loss: 0.718543, acc.: 46.09%] [G loss: 0.738513]\n",
      "epoch:3 step:3249 [D loss: 0.708708, acc.: 43.75%] [G loss: 0.747861]\n",
      "epoch:3 step:3250 [D loss: 0.699527, acc.: 51.56%] [G loss: 0.743914]\n",
      "epoch:3 step:3251 [D loss: 0.692082, acc.: 54.69%] [G loss: 0.704664]\n",
      "epoch:3 step:3252 [D loss: 0.691811, acc.: 46.09%] [G loss: 0.735577]\n",
      "epoch:3 step:3253 [D loss: 0.685276, acc.: 55.47%] [G loss: 0.731041]\n",
      "epoch:3 step:3254 [D loss: 0.672733, acc.: 59.38%] [G loss: 0.723949]\n",
      "epoch:3 step:3255 [D loss: 0.691474, acc.: 48.44%] [G loss: 0.755158]\n",
      "epoch:3 step:3256 [D loss: 0.686065, acc.: 53.12%] [G loss: 0.764046]\n",
      "epoch:3 step:3257 [D loss: 0.693970, acc.: 53.12%] [G loss: 0.734947]\n",
      "epoch:3 step:3258 [D loss: 0.689638, acc.: 55.47%] [G loss: 0.720026]\n",
      "epoch:3 step:3259 [D loss: 0.691110, acc.: 52.34%] [G loss: 0.687113]\n",
      "epoch:3 step:3260 [D loss: 0.659988, acc.: 59.38%] [G loss: 0.724003]\n",
      "epoch:3 step:3261 [D loss: 0.665310, acc.: 68.75%] [G loss: 0.742132]\n",
      "epoch:3 step:3262 [D loss: 0.675408, acc.: 60.94%] [G loss: 0.739684]\n",
      "epoch:3 step:3263 [D loss: 0.659847, acc.: 60.16%] [G loss: 0.776384]\n",
      "epoch:3 step:3264 [D loss: 0.663307, acc.: 58.59%] [G loss: 0.768746]\n",
      "epoch:3 step:3265 [D loss: 0.664738, acc.: 60.16%] [G loss: 0.767423]\n",
      "epoch:3 step:3266 [D loss: 0.672593, acc.: 60.16%] [G loss: 0.778794]\n",
      "epoch:3 step:3267 [D loss: 0.539834, acc.: 71.09%] [G loss: 0.711596]\n",
      "epoch:3 step:3268 [D loss: 0.627394, acc.: 70.31%] [G loss: 0.334707]\n",
      "epoch:3 step:3269 [D loss: 0.730622, acc.: 42.97%] [G loss: 0.708105]\n",
      "epoch:3 step:3270 [D loss: 0.734817, acc.: 46.88%] [G loss: 0.872985]\n",
      "epoch:3 step:3271 [D loss: 0.673318, acc.: 56.25%] [G loss: 0.845598]\n",
      "epoch:3 step:3272 [D loss: 0.732249, acc.: 42.19%] [G loss: 0.818556]\n",
      "epoch:3 step:3273 [D loss: 0.737532, acc.: 44.53%] [G loss: 0.758093]\n",
      "epoch:3 step:3274 [D loss: 0.703668, acc.: 44.53%] [G loss: 0.848880]\n",
      "epoch:3 step:3275 [D loss: 0.680754, acc.: 57.81%] [G loss: 0.721650]\n",
      "epoch:3 step:3276 [D loss: 0.700889, acc.: 47.66%] [G loss: 0.784874]\n",
      "epoch:3 step:3277 [D loss: 0.712734, acc.: 53.91%] [G loss: 0.786976]\n",
      "epoch:3 step:3278 [D loss: 0.665505, acc.: 62.50%] [G loss: 0.804612]\n",
      "epoch:3 step:3279 [D loss: 0.674067, acc.: 60.16%] [G loss: 0.701266]\n",
      "epoch:3 step:3280 [D loss: 0.690325, acc.: 54.69%] [G loss: 0.776241]\n",
      "epoch:3 step:3281 [D loss: 0.698279, acc.: 52.34%] [G loss: 0.685112]\n",
      "epoch:3 step:3282 [D loss: 0.707778, acc.: 53.12%] [G loss: 0.730028]\n",
      "epoch:3 step:3283 [D loss: 0.728916, acc.: 38.28%] [G loss: 0.756705]\n",
      "epoch:3 step:3284 [D loss: 0.731455, acc.: 41.41%] [G loss: 0.771698]\n",
      "epoch:3 step:3285 [D loss: 0.700765, acc.: 42.97%] [G loss: 0.823518]\n",
      "epoch:3 step:3286 [D loss: 0.688317, acc.: 49.22%] [G loss: 0.811393]\n",
      "epoch:3 step:3287 [D loss: 0.676715, acc.: 55.47%] [G loss: 1.058768]\n",
      "epoch:3 step:3288 [D loss: 0.716249, acc.: 47.66%] [G loss: 0.812007]\n",
      "epoch:3 step:3289 [D loss: 0.683672, acc.: 60.16%] [G loss: 0.828956]\n",
      "epoch:3 step:3290 [D loss: 0.701196, acc.: 48.44%] [G loss: 0.785112]\n",
      "epoch:3 step:3291 [D loss: 0.687329, acc.: 50.00%] [G loss: 0.773262]\n",
      "epoch:3 step:3292 [D loss: 0.739634, acc.: 43.75%] [G loss: 0.748531]\n",
      "epoch:3 step:3293 [D loss: 0.652742, acc.: 66.41%] [G loss: 0.824284]\n",
      "epoch:3 step:3294 [D loss: 0.672648, acc.: 60.94%] [G loss: 0.796819]\n",
      "epoch:3 step:3295 [D loss: 0.649246, acc.: 67.97%] [G loss: 0.802253]\n",
      "epoch:3 step:3296 [D loss: 0.673451, acc.: 61.72%] [G loss: 0.755798]\n",
      "epoch:3 step:3297 [D loss: 0.671703, acc.: 57.81%] [G loss: 0.780601]\n",
      "epoch:3 step:3298 [D loss: 0.710624, acc.: 52.34%] [G loss: 0.714376]\n",
      "epoch:3 step:3299 [D loss: 0.706919, acc.: 43.75%] [G loss: 0.775824]\n",
      "epoch:3 step:3300 [D loss: 0.713822, acc.: 41.41%] [G loss: 0.770934]\n",
      "epoch:3 step:3301 [D loss: 0.708606, acc.: 47.66%] [G loss: 0.770705]\n",
      "epoch:3 step:3302 [D loss: 0.707504, acc.: 49.22%] [G loss: 0.733878]\n",
      "epoch:3 step:3303 [D loss: 0.688837, acc.: 52.34%] [G loss: 0.735074]\n",
      "epoch:3 step:3304 [D loss: 0.694149, acc.: 53.12%] [G loss: 0.742006]\n",
      "epoch:3 step:3305 [D loss: 0.703785, acc.: 44.53%] [G loss: 0.705133]\n",
      "epoch:3 step:3306 [D loss: 0.688097, acc.: 52.34%] [G loss: 0.724538]\n",
      "epoch:3 step:3307 [D loss: 0.697931, acc.: 46.88%] [G loss: 0.753937]\n",
      "epoch:3 step:3308 [D loss: 0.686162, acc.: 53.12%] [G loss: 0.774310]\n",
      "epoch:3 step:3309 [D loss: 0.709594, acc.: 53.12%] [G loss: 0.755573]\n",
      "epoch:3 step:3310 [D loss: 0.686660, acc.: 55.47%] [G loss: 0.763179]\n",
      "epoch:3 step:3311 [D loss: 0.720667, acc.: 42.97%] [G loss: 0.743751]\n",
      "epoch:3 step:3312 [D loss: 0.722022, acc.: 42.97%] [G loss: 0.731421]\n",
      "epoch:3 step:3313 [D loss: 0.704970, acc.: 46.88%] [G loss: 0.726517]\n",
      "epoch:3 step:3314 [D loss: 0.701108, acc.: 50.00%] [G loss: 0.710462]\n",
      "epoch:3 step:3315 [D loss: 0.679613, acc.: 54.69%] [G loss: 0.745980]\n",
      "epoch:3 step:3316 [D loss: 0.667122, acc.: 63.28%] [G loss: 0.743909]\n",
      "epoch:3 step:3317 [D loss: 0.699154, acc.: 55.47%] [G loss: 0.749284]\n",
      "epoch:3 step:3318 [D loss: 0.673819, acc.: 57.81%] [G loss: 0.725049]\n",
      "epoch:3 step:3319 [D loss: 0.644235, acc.: 69.53%] [G loss: 0.775405]\n",
      "epoch:3 step:3320 [D loss: 0.708969, acc.: 45.31%] [G loss: 0.751552]\n",
      "epoch:3 step:3321 [D loss: 0.722707, acc.: 38.28%] [G loss: 0.757840]\n",
      "epoch:3 step:3322 [D loss: 0.710242, acc.: 40.62%] [G loss: 0.753811]\n",
      "epoch:3 step:3323 [D loss: 0.717868, acc.: 40.62%] [G loss: 0.740990]\n",
      "epoch:3 step:3324 [D loss: 0.714795, acc.: 44.53%] [G loss: 0.744018]\n",
      "epoch:3 step:3325 [D loss: 0.703185, acc.: 50.78%] [G loss: 0.736945]\n",
      "epoch:3 step:3326 [D loss: 0.679404, acc.: 55.47%] [G loss: 0.743253]\n",
      "epoch:3 step:3327 [D loss: 0.686813, acc.: 53.12%] [G loss: 0.718198]\n",
      "epoch:3 step:3328 [D loss: 0.674046, acc.: 53.12%] [G loss: 0.733608]\n",
      "epoch:3 step:3329 [D loss: 0.671810, acc.: 57.03%] [G loss: 0.733209]\n",
      "epoch:3 step:3330 [D loss: 0.681381, acc.: 59.38%] [G loss: 0.741050]\n",
      "epoch:3 step:3331 [D loss: 0.667694, acc.: 60.94%] [G loss: 0.756475]\n",
      "epoch:3 step:3332 [D loss: 0.683536, acc.: 56.25%] [G loss: 0.758795]\n",
      "epoch:3 step:3333 [D loss: 0.695193, acc.: 48.44%] [G loss: 0.711759]\n",
      "epoch:3 step:3334 [D loss: 0.695027, acc.: 52.34%] [G loss: 0.756594]\n",
      "epoch:3 step:3335 [D loss: 0.710499, acc.: 39.84%] [G loss: 0.703759]\n",
      "epoch:3 step:3336 [D loss: 0.709171, acc.: 45.31%] [G loss: 0.730592]\n",
      "epoch:3 step:3337 [D loss: 0.713948, acc.: 39.06%] [G loss: 0.731531]\n",
      "epoch:3 step:3338 [D loss: 0.714740, acc.: 45.31%] [G loss: 0.714033]\n",
      "epoch:3 step:3339 [D loss: 0.700722, acc.: 50.78%] [G loss: 0.692208]\n",
      "epoch:3 step:3340 [D loss: 0.683058, acc.: 55.47%] [G loss: 0.712973]\n",
      "epoch:3 step:3341 [D loss: 0.696836, acc.: 49.22%] [G loss: 0.695221]\n",
      "epoch:3 step:3342 [D loss: 0.687713, acc.: 53.12%] [G loss: 0.716607]\n",
      "epoch:3 step:3343 [D loss: 0.692106, acc.: 51.56%] [G loss: 0.716887]\n",
      "epoch:3 step:3344 [D loss: 0.678926, acc.: 57.03%] [G loss: 0.720300]\n",
      "epoch:3 step:3345 [D loss: 0.706738, acc.: 48.44%] [G loss: 0.714857]\n",
      "epoch:3 step:3346 [D loss: 0.709019, acc.: 50.78%] [G loss: 0.754261]\n",
      "epoch:3 step:3347 [D loss: 0.694372, acc.: 56.25%] [G loss: 0.743252]\n",
      "epoch:3 step:3348 [D loss: 0.684781, acc.: 52.34%] [G loss: 0.756449]\n",
      "epoch:3 step:3349 [D loss: 0.681744, acc.: 57.03%] [G loss: 0.741742]\n",
      "epoch:3 step:3350 [D loss: 0.686371, acc.: 54.69%] [G loss: 0.755504]\n",
      "epoch:3 step:3351 [D loss: 0.687488, acc.: 53.91%] [G loss: 0.736681]\n",
      "epoch:3 step:3352 [D loss: 0.648430, acc.: 70.31%] [G loss: 0.764544]\n",
      "epoch:3 step:3353 [D loss: 0.748046, acc.: 43.75%] [G loss: 0.743851]\n",
      "epoch:3 step:3354 [D loss: 0.683434, acc.: 53.12%] [G loss: 0.754963]\n",
      "epoch:3 step:3355 [D loss: 0.689014, acc.: 54.69%] [G loss: 0.688869]\n",
      "epoch:3 step:3356 [D loss: 0.697294, acc.: 45.31%] [G loss: 0.714689]\n",
      "epoch:3 step:3357 [D loss: 0.697521, acc.: 52.34%] [G loss: 0.633794]\n",
      "epoch:3 step:3358 [D loss: 0.771053, acc.: 38.28%] [G loss: 0.724236]\n",
      "epoch:3 step:3359 [D loss: 0.694335, acc.: 56.25%] [G loss: 0.691382]\n",
      "epoch:3 step:3360 [D loss: 0.670652, acc.: 60.94%] [G loss: 0.737399]\n",
      "epoch:3 step:3361 [D loss: 0.594600, acc.: 62.50%] [G loss: 0.630600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3362 [D loss: 0.677470, acc.: 57.81%] [G loss: 0.723100]\n",
      "epoch:3 step:3363 [D loss: 0.664139, acc.: 65.62%] [G loss: 0.719454]\n",
      "epoch:3 step:3364 [D loss: 0.716413, acc.: 41.41%] [G loss: 0.325422]\n",
      "epoch:3 step:3365 [D loss: 0.631433, acc.: 74.22%] [G loss: 0.692117]\n",
      "epoch:3 step:3366 [D loss: 0.668715, acc.: 55.47%] [G loss: 0.632373]\n",
      "epoch:3 step:3367 [D loss: 0.671161, acc.: 60.94%] [G loss: 0.715985]\n",
      "epoch:3 step:3368 [D loss: 0.692828, acc.: 52.34%] [G loss: 0.776215]\n",
      "epoch:3 step:3369 [D loss: 0.773716, acc.: 46.09%] [G loss: 0.490640]\n",
      "epoch:3 step:3370 [D loss: 0.741443, acc.: 38.28%] [G loss: 0.820285]\n",
      "epoch:3 step:3371 [D loss: 0.704160, acc.: 50.00%] [G loss: 0.769810]\n",
      "epoch:3 step:3372 [D loss: 0.730769, acc.: 39.06%] [G loss: 0.903460]\n",
      "epoch:3 step:3373 [D loss: 0.696432, acc.: 44.53%] [G loss: 0.898981]\n",
      "epoch:3 step:3374 [D loss: 0.659119, acc.: 55.47%] [G loss: 0.866583]\n",
      "epoch:3 step:3375 [D loss: 0.678964, acc.: 54.69%] [G loss: 0.936054]\n",
      "epoch:3 step:3376 [D loss: 0.681270, acc.: 54.69%] [G loss: 0.875770]\n",
      "epoch:3 step:3377 [D loss: 0.710302, acc.: 45.31%] [G loss: 0.768018]\n",
      "epoch:3 step:3378 [D loss: 0.661886, acc.: 64.84%] [G loss: 0.735556]\n",
      "epoch:3 step:3379 [D loss: 0.670127, acc.: 60.94%] [G loss: 0.918057]\n",
      "epoch:3 step:3380 [D loss: 0.703260, acc.: 47.66%] [G loss: 0.778450]\n",
      "epoch:3 step:3381 [D loss: 0.705244, acc.: 56.25%] [G loss: 0.887511]\n",
      "epoch:3 step:3382 [D loss: 0.711162, acc.: 44.53%] [G loss: 0.865608]\n",
      "epoch:3 step:3383 [D loss: 0.697764, acc.: 53.12%] [G loss: 0.779572]\n",
      "epoch:3 step:3384 [D loss: 0.671373, acc.: 65.62%] [G loss: 0.771579]\n",
      "epoch:3 step:3385 [D loss: 0.668572, acc.: 59.38%] [G loss: 0.795977]\n",
      "epoch:3 step:3386 [D loss: 0.678385, acc.: 67.19%] [G loss: 0.787045]\n",
      "epoch:3 step:3387 [D loss: 0.678747, acc.: 57.03%] [G loss: 0.743899]\n",
      "epoch:3 step:3388 [D loss: 0.659272, acc.: 64.06%] [G loss: 0.791808]\n",
      "epoch:3 step:3389 [D loss: 0.689042, acc.: 50.78%] [G loss: 0.785312]\n",
      "epoch:3 step:3390 [D loss: 0.659766, acc.: 68.75%] [G loss: 0.770635]\n",
      "epoch:3 step:3391 [D loss: 0.714579, acc.: 55.47%] [G loss: 0.792502]\n",
      "epoch:3 step:3392 [D loss: 0.690697, acc.: 52.34%] [G loss: 0.690716]\n",
      "epoch:3 step:3393 [D loss: 0.701618, acc.: 49.22%] [G loss: 0.782129]\n",
      "epoch:3 step:3394 [D loss: 0.727058, acc.: 44.53%] [G loss: 0.758740]\n",
      "epoch:3 step:3395 [D loss: 0.713650, acc.: 42.97%] [G loss: 0.748726]\n",
      "epoch:3 step:3396 [D loss: 0.685631, acc.: 47.66%] [G loss: 0.729487]\n",
      "epoch:3 step:3397 [D loss: 0.684780, acc.: 53.91%] [G loss: 0.759647]\n",
      "epoch:3 step:3398 [D loss: 0.708072, acc.: 46.09%] [G loss: 0.742358]\n",
      "epoch:3 step:3399 [D loss: 0.681309, acc.: 59.38%] [G loss: 0.759697]\n",
      "epoch:3 step:3400 [D loss: 0.684660, acc.: 52.34%] [G loss: 0.807439]\n",
      "epoch:3 step:3401 [D loss: 0.670574, acc.: 57.03%] [G loss: 0.812324]\n",
      "epoch:3 step:3402 [D loss: 0.635786, acc.: 65.62%] [G loss: 0.825604]\n",
      "epoch:3 step:3403 [D loss: 0.641460, acc.: 69.53%] [G loss: 0.771260]\n",
      "epoch:3 step:3404 [D loss: 0.715019, acc.: 51.56%] [G loss: 0.799354]\n",
      "epoch:3 step:3405 [D loss: 0.695590, acc.: 55.47%] [G loss: 0.773250]\n",
      "epoch:3 step:3406 [D loss: 0.680611, acc.: 57.81%] [G loss: 0.741588]\n",
      "epoch:3 step:3407 [D loss: 0.681556, acc.: 57.81%] [G loss: 0.731644]\n",
      "epoch:3 step:3408 [D loss: 0.728727, acc.: 45.31%] [G loss: 0.734195]\n",
      "epoch:3 step:3409 [D loss: 0.690321, acc.: 53.12%] [G loss: 0.752466]\n",
      "epoch:3 step:3410 [D loss: 0.703478, acc.: 50.00%] [G loss: 0.684995]\n",
      "epoch:3 step:3411 [D loss: 0.719247, acc.: 46.88%] [G loss: 0.694872]\n",
      "epoch:3 step:3412 [D loss: 0.716987, acc.: 42.19%] [G loss: 0.701813]\n",
      "epoch:3 step:3413 [D loss: 0.709681, acc.: 44.53%] [G loss: 0.715945]\n",
      "epoch:3 step:3414 [D loss: 0.711778, acc.: 43.75%] [G loss: 0.704065]\n",
      "epoch:3 step:3415 [D loss: 0.651859, acc.: 49.22%] [G loss: 0.761916]\n",
      "epoch:3 step:3416 [D loss: 0.713016, acc.: 45.31%] [G loss: 0.763791]\n",
      "epoch:3 step:3417 [D loss: 0.704294, acc.: 51.56%] [G loss: 0.714328]\n",
      "epoch:3 step:3418 [D loss: 0.709070, acc.: 43.75%] [G loss: 0.752161]\n",
      "epoch:3 step:3419 [D loss: 0.711752, acc.: 45.31%] [G loss: 0.741780]\n",
      "epoch:3 step:3420 [D loss: 0.695139, acc.: 50.00%] [G loss: 0.755876]\n",
      "epoch:3 step:3421 [D loss: 0.692945, acc.: 55.47%] [G loss: 0.769849]\n",
      "epoch:3 step:3422 [D loss: 0.693811, acc.: 44.53%] [G loss: 0.763710]\n",
      "epoch:3 step:3423 [D loss: 0.674065, acc.: 60.94%] [G loss: 0.776287]\n",
      "epoch:3 step:3424 [D loss: 0.670673, acc.: 60.94%] [G loss: 0.803334]\n",
      "epoch:3 step:3425 [D loss: 0.683158, acc.: 60.94%] [G loss: 0.777968]\n",
      "epoch:3 step:3426 [D loss: 0.713801, acc.: 48.44%] [G loss: 0.772698]\n",
      "epoch:3 step:3427 [D loss: 0.705041, acc.: 51.56%] [G loss: 0.752504]\n",
      "epoch:3 step:3428 [D loss: 0.694773, acc.: 53.91%] [G loss: 0.729311]\n",
      "epoch:3 step:3429 [D loss: 0.710602, acc.: 46.88%] [G loss: 0.716267]\n",
      "epoch:3 step:3430 [D loss: 0.709953, acc.: 39.84%] [G loss: 0.732578]\n",
      "epoch:3 step:3431 [D loss: 0.714288, acc.: 45.31%] [G loss: 0.746774]\n",
      "epoch:3 step:3432 [D loss: 0.699495, acc.: 50.78%] [G loss: 0.752377]\n",
      "epoch:3 step:3433 [D loss: 0.714294, acc.: 40.62%] [G loss: 0.735183]\n",
      "epoch:3 step:3434 [D loss: 0.707443, acc.: 44.53%] [G loss: 0.764743]\n",
      "epoch:3 step:3435 [D loss: 0.689226, acc.: 52.34%] [G loss: 0.760542]\n",
      "epoch:3 step:3436 [D loss: 0.702821, acc.: 48.44%] [G loss: 0.760597]\n",
      "epoch:3 step:3437 [D loss: 0.689717, acc.: 48.44%] [G loss: 0.746998]\n",
      "epoch:3 step:3438 [D loss: 0.675715, acc.: 65.62%] [G loss: 0.746002]\n",
      "epoch:3 step:3439 [D loss: 0.693310, acc.: 51.56%] [G loss: 0.752043]\n",
      "epoch:3 step:3440 [D loss: 0.672727, acc.: 60.94%] [G loss: 0.756440]\n",
      "epoch:3 step:3441 [D loss: 0.668388, acc.: 63.28%] [G loss: 0.780504]\n",
      "epoch:3 step:3442 [D loss: 0.671390, acc.: 64.84%] [G loss: 0.763687]\n",
      "epoch:3 step:3443 [D loss: 0.691261, acc.: 50.00%] [G loss: 0.777553]\n",
      "epoch:3 step:3444 [D loss: 0.709346, acc.: 43.75%] [G loss: 0.751324]\n",
      "epoch:3 step:3445 [D loss: 0.707119, acc.: 46.09%] [G loss: 0.725891]\n",
      "epoch:3 step:3446 [D loss: 0.676337, acc.: 52.34%] [G loss: 0.703848]\n",
      "epoch:3 step:3447 [D loss: 0.708572, acc.: 44.53%] [G loss: 0.703028]\n",
      "epoch:3 step:3448 [D loss: 0.704087, acc.: 50.00%] [G loss: 0.705023]\n",
      "epoch:3 step:3449 [D loss: 0.689078, acc.: 57.81%] [G loss: 0.710322]\n",
      "epoch:3 step:3450 [D loss: 0.699738, acc.: 53.91%] [G loss: 0.742619]\n",
      "epoch:3 step:3451 [D loss: 0.705863, acc.: 41.41%] [G loss: 0.697705]\n",
      "epoch:3 step:3452 [D loss: 0.691926, acc.: 50.78%] [G loss: 0.751879]\n",
      "epoch:3 step:3453 [D loss: 0.700325, acc.: 44.53%] [G loss: 0.742545]\n",
      "epoch:3 step:3454 [D loss: 0.693867, acc.: 53.91%] [G loss: 0.742007]\n",
      "epoch:3 step:3455 [D loss: 0.720756, acc.: 50.78%] [G loss: 0.772793]\n",
      "epoch:3 step:3456 [D loss: 0.680910, acc.: 60.16%] [G loss: 0.769923]\n",
      "epoch:3 step:3457 [D loss: 0.673401, acc.: 61.72%] [G loss: 0.763808]\n",
      "epoch:3 step:3458 [D loss: 0.684160, acc.: 53.12%] [G loss: 0.740964]\n",
      "epoch:3 step:3459 [D loss: 0.662683, acc.: 64.06%] [G loss: 0.761166]\n",
      "epoch:3 step:3460 [D loss: 0.676101, acc.: 60.94%] [G loss: 0.774134]\n",
      "epoch:3 step:3461 [D loss: 0.658511, acc.: 56.25%] [G loss: 0.775277]\n",
      "epoch:3 step:3462 [D loss: 0.683076, acc.: 58.59%] [G loss: 0.795569]\n",
      "epoch:3 step:3463 [D loss: 0.717324, acc.: 42.97%] [G loss: 0.775012]\n",
      "epoch:3 step:3464 [D loss: 0.701679, acc.: 51.56%] [G loss: 0.723136]\n",
      "epoch:3 step:3465 [D loss: 0.706881, acc.: 42.19%] [G loss: 0.725507]\n",
      "epoch:3 step:3466 [D loss: 0.688675, acc.: 52.34%] [G loss: 0.736852]\n",
      "epoch:3 step:3467 [D loss: 0.687075, acc.: 56.25%] [G loss: 0.734822]\n",
      "epoch:3 step:3468 [D loss: 0.678976, acc.: 57.03%] [G loss: 0.730518]\n",
      "epoch:3 step:3469 [D loss: 0.675489, acc.: 55.47%] [G loss: 0.706585]\n",
      "epoch:3 step:3470 [D loss: 0.646794, acc.: 64.06%] [G loss: 0.709933]\n",
      "epoch:3 step:3471 [D loss: 0.684285, acc.: 58.59%] [G loss: 0.708781]\n",
      "epoch:3 step:3472 [D loss: 0.681915, acc.: 53.91%] [G loss: 0.680461]\n",
      "epoch:3 step:3473 [D loss: 0.728249, acc.: 39.06%] [G loss: 0.653599]\n",
      "epoch:3 step:3474 [D loss: 0.746277, acc.: 27.34%] [G loss: 0.708991]\n",
      "epoch:3 step:3475 [D loss: 0.726111, acc.: 32.03%] [G loss: 0.708570]\n",
      "epoch:3 step:3476 [D loss: 0.721822, acc.: 36.72%] [G loss: 0.724619]\n",
      "epoch:3 step:3477 [D loss: 0.703263, acc.: 46.88%] [G loss: 0.720957]\n",
      "epoch:3 step:3478 [D loss: 0.700346, acc.: 50.78%] [G loss: 0.747083]\n",
      "epoch:3 step:3479 [D loss: 0.691355, acc.: 56.25%] [G loss: 0.748422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3480 [D loss: 0.695165, acc.: 47.66%] [G loss: 0.762392]\n",
      "epoch:3 step:3481 [D loss: 0.698047, acc.: 49.22%] [G loss: 0.767776]\n",
      "epoch:3 step:3482 [D loss: 0.686487, acc.: 54.69%] [G loss: 0.762629]\n",
      "epoch:3 step:3483 [D loss: 0.688039, acc.: 53.91%] [G loss: 0.766850]\n",
      "epoch:3 step:3484 [D loss: 0.690126, acc.: 51.56%] [G loss: 0.746067]\n",
      "epoch:3 step:3485 [D loss: 0.677747, acc.: 58.59%] [G loss: 0.789213]\n",
      "epoch:3 step:3486 [D loss: 0.690278, acc.: 53.12%] [G loss: 0.762827]\n",
      "epoch:3 step:3487 [D loss: 0.689824, acc.: 50.78%] [G loss: 0.722378]\n",
      "epoch:3 step:3488 [D loss: 0.683788, acc.: 56.25%] [G loss: 0.717959]\n",
      "epoch:3 step:3489 [D loss: 0.699612, acc.: 47.66%] [G loss: 0.736527]\n",
      "epoch:3 step:3490 [D loss: 0.684893, acc.: 53.91%] [G loss: 0.731733]\n",
      "epoch:3 step:3491 [D loss: 0.688684, acc.: 54.69%] [G loss: 0.740922]\n",
      "epoch:3 step:3492 [D loss: 0.687205, acc.: 55.47%] [G loss: 0.697637]\n",
      "epoch:3 step:3493 [D loss: 0.703845, acc.: 50.78%] [G loss: 0.719210]\n",
      "epoch:3 step:3494 [D loss: 0.709466, acc.: 46.09%] [G loss: 0.745698]\n",
      "epoch:3 step:3495 [D loss: 0.690466, acc.: 57.03%] [G loss: 0.729304]\n",
      "epoch:3 step:3496 [D loss: 0.669526, acc.: 57.81%] [G loss: 0.722199]\n",
      "epoch:3 step:3497 [D loss: 0.703989, acc.: 50.78%] [G loss: 0.762204]\n",
      "epoch:3 step:3498 [D loss: 0.712889, acc.: 50.00%] [G loss: 0.681261]\n",
      "epoch:3 step:3499 [D loss: 0.673972, acc.: 63.28%] [G loss: 0.697068]\n",
      "epoch:3 step:3500 [D loss: 0.735978, acc.: 43.75%] [G loss: 0.752957]\n",
      "epoch:3 step:3501 [D loss: 0.691789, acc.: 51.56%] [G loss: 0.701858]\n",
      "epoch:3 step:3502 [D loss: 0.710698, acc.: 43.75%] [G loss: 0.730474]\n",
      "epoch:3 step:3503 [D loss: 0.713970, acc.: 42.19%] [G loss: 0.715100]\n",
      "epoch:3 step:3504 [D loss: 0.693216, acc.: 57.03%] [G loss: 0.708415]\n",
      "epoch:3 step:3505 [D loss: 0.686325, acc.: 57.81%] [G loss: 0.723260]\n",
      "epoch:3 step:3506 [D loss: 0.696525, acc.: 50.00%] [G loss: 0.708073]\n",
      "epoch:3 step:3507 [D loss: 0.702847, acc.: 48.44%] [G loss: 0.687814]\n",
      "epoch:3 step:3508 [D loss: 0.690938, acc.: 49.22%] [G loss: 0.706451]\n",
      "epoch:3 step:3509 [D loss: 0.682849, acc.: 59.38%] [G loss: 0.724277]\n",
      "epoch:3 step:3510 [D loss: 0.697609, acc.: 46.88%] [G loss: 0.733262]\n",
      "epoch:3 step:3511 [D loss: 0.701445, acc.: 57.81%] [G loss: 0.724207]\n",
      "epoch:3 step:3512 [D loss: 0.670175, acc.: 57.81%] [G loss: 0.714394]\n",
      "epoch:3 step:3513 [D loss: 0.685098, acc.: 57.03%] [G loss: 0.692413]\n",
      "epoch:3 step:3514 [D loss: 0.710374, acc.: 41.41%] [G loss: 0.711111]\n",
      "epoch:3 step:3515 [D loss: 0.700749, acc.: 42.97%] [G loss: 0.745048]\n",
      "epoch:3 step:3516 [D loss: 0.700078, acc.: 53.12%] [G loss: 0.725016]\n",
      "epoch:3 step:3517 [D loss: 0.668156, acc.: 68.75%] [G loss: 0.735426]\n",
      "epoch:3 step:3518 [D loss: 0.681196, acc.: 63.28%] [G loss: 0.695382]\n",
      "epoch:3 step:3519 [D loss: 0.671512, acc.: 62.50%] [G loss: 0.668450]\n",
      "epoch:3 step:3520 [D loss: 0.689881, acc.: 57.03%] [G loss: 0.686093]\n",
      "epoch:3 step:3521 [D loss: 0.763252, acc.: 36.72%] [G loss: 0.686381]\n",
      "epoch:3 step:3522 [D loss: 0.723842, acc.: 39.84%] [G loss: 0.724226]\n",
      "epoch:3 step:3523 [D loss: 0.687156, acc.: 51.56%] [G loss: 0.683616]\n",
      "epoch:3 step:3524 [D loss: 0.685519, acc.: 58.59%] [G loss: 0.691590]\n",
      "epoch:3 step:3525 [D loss: 0.691271, acc.: 58.59%] [G loss: 0.683849]\n",
      "epoch:3 step:3526 [D loss: 0.706243, acc.: 46.88%] [G loss: 0.735415]\n",
      "epoch:3 step:3527 [D loss: 0.697988, acc.: 50.00%] [G loss: 0.755252]\n",
      "epoch:3 step:3528 [D loss: 0.700976, acc.: 46.09%] [G loss: 0.736071]\n",
      "epoch:3 step:3529 [D loss: 0.680018, acc.: 53.12%] [G loss: 0.715528]\n",
      "epoch:3 step:3530 [D loss: 0.683002, acc.: 55.47%] [G loss: 0.719053]\n",
      "epoch:3 step:3531 [D loss: 0.683101, acc.: 50.00%] [G loss: 0.747478]\n",
      "epoch:3 step:3532 [D loss: 0.664714, acc.: 61.72%] [G loss: 0.744028]\n",
      "epoch:3 step:3533 [D loss: 0.695635, acc.: 57.03%] [G loss: 0.753145]\n",
      "epoch:3 step:3534 [D loss: 0.698704, acc.: 47.66%] [G loss: 0.738338]\n",
      "epoch:3 step:3535 [D loss: 0.682706, acc.: 56.25%] [G loss: 0.717488]\n",
      "epoch:3 step:3536 [D loss: 0.697574, acc.: 53.91%] [G loss: 0.733346]\n",
      "epoch:3 step:3537 [D loss: 0.693815, acc.: 48.44%] [G loss: 0.743610]\n",
      "epoch:3 step:3538 [D loss: 0.696220, acc.: 53.91%] [G loss: 0.723308]\n",
      "epoch:3 step:3539 [D loss: 0.701869, acc.: 49.22%] [G loss: 0.700630]\n",
      "epoch:3 step:3540 [D loss: 0.690369, acc.: 46.88%] [G loss: 0.708563]\n",
      "epoch:3 step:3541 [D loss: 0.686392, acc.: 53.12%] [G loss: 0.720731]\n",
      "epoch:3 step:3542 [D loss: 0.692907, acc.: 53.91%] [G loss: 0.738535]\n",
      "epoch:3 step:3543 [D loss: 0.693868, acc.: 50.78%] [G loss: 0.744762]\n",
      "epoch:3 step:3544 [D loss: 0.670171, acc.: 62.50%] [G loss: 0.742039]\n",
      "epoch:3 step:3545 [D loss: 0.695551, acc.: 53.91%] [G loss: 0.738747]\n",
      "epoch:3 step:3546 [D loss: 0.696881, acc.: 52.34%] [G loss: 0.770764]\n",
      "epoch:3 step:3547 [D loss: 0.654466, acc.: 69.53%] [G loss: 0.778382]\n",
      "epoch:3 step:3548 [D loss: 0.686413, acc.: 57.03%] [G loss: 0.730547]\n",
      "epoch:3 step:3549 [D loss: 0.695471, acc.: 47.66%] [G loss: 0.720519]\n",
      "epoch:3 step:3550 [D loss: 0.698420, acc.: 52.34%] [G loss: 0.760161]\n",
      "epoch:3 step:3551 [D loss: 0.701232, acc.: 46.88%] [G loss: 0.736617]\n",
      "epoch:3 step:3552 [D loss: 0.699110, acc.: 59.38%] [G loss: 0.714444]\n",
      "epoch:3 step:3553 [D loss: 0.715618, acc.: 42.97%] [G loss: 0.727180]\n",
      "epoch:3 step:3554 [D loss: 0.676255, acc.: 59.38%] [G loss: 0.736529]\n",
      "epoch:3 step:3555 [D loss: 0.701572, acc.: 45.31%] [G loss: 0.754728]\n",
      "epoch:3 step:3556 [D loss: 0.695110, acc.: 53.12%] [G loss: 0.730126]\n",
      "epoch:3 step:3557 [D loss: 0.711118, acc.: 52.34%] [G loss: 0.704659]\n",
      "epoch:3 step:3558 [D loss: 0.695460, acc.: 56.25%] [G loss: 0.703515]\n",
      "epoch:3 step:3559 [D loss: 0.707748, acc.: 48.44%] [G loss: 0.693083]\n",
      "epoch:3 step:3560 [D loss: 0.698569, acc.: 49.22%] [G loss: 0.519345]\n",
      "epoch:3 step:3561 [D loss: 0.694972, acc.: 51.56%] [G loss: 0.694307]\n",
      "epoch:3 step:3562 [D loss: 0.712139, acc.: 42.97%] [G loss: 0.718899]\n",
      "epoch:3 step:3563 [D loss: 0.717895, acc.: 46.88%] [G loss: 0.715716]\n",
      "epoch:3 step:3564 [D loss: 0.699090, acc.: 46.88%] [G loss: 0.704736]\n",
      "epoch:3 step:3565 [D loss: 0.720295, acc.: 46.88%] [G loss: 0.719056]\n",
      "epoch:3 step:3566 [D loss: 0.700097, acc.: 49.22%] [G loss: 0.700093]\n",
      "epoch:3 step:3567 [D loss: 0.677814, acc.: 59.38%] [G loss: 0.700256]\n",
      "epoch:3 step:3568 [D loss: 0.678120, acc.: 59.38%] [G loss: 0.735097]\n",
      "epoch:3 step:3569 [D loss: 0.693299, acc.: 50.78%] [G loss: 0.744607]\n",
      "epoch:3 step:3570 [D loss: 0.697942, acc.: 50.78%] [G loss: 0.727186]\n",
      "epoch:3 step:3571 [D loss: 0.692890, acc.: 57.81%] [G loss: 0.760592]\n",
      "epoch:3 step:3572 [D loss: 0.686523, acc.: 57.03%] [G loss: 0.766638]\n",
      "epoch:3 step:3573 [D loss: 0.676833, acc.: 62.50%] [G loss: 0.792508]\n",
      "epoch:3 step:3574 [D loss: 0.685868, acc.: 48.44%] [G loss: 0.766133]\n",
      "epoch:3 step:3575 [D loss: 0.675346, acc.: 64.06%] [G loss: 0.806809]\n",
      "epoch:3 step:3576 [D loss: 0.693272, acc.: 57.81%] [G loss: 0.736350]\n",
      "epoch:3 step:3577 [D loss: 0.675959, acc.: 59.38%] [G loss: 0.703745]\n",
      "epoch:3 step:3578 [D loss: 0.693022, acc.: 55.47%] [G loss: 0.728091]\n",
      "epoch:3 step:3579 [D loss: 0.723966, acc.: 42.19%] [G loss: 0.746116]\n",
      "epoch:3 step:3580 [D loss: 0.714516, acc.: 41.41%] [G loss: 0.701969]\n",
      "epoch:3 step:3581 [D loss: 0.705713, acc.: 46.88%] [G loss: 0.727391]\n",
      "epoch:3 step:3582 [D loss: 0.708863, acc.: 46.09%] [G loss: 0.666304]\n",
      "epoch:3 step:3583 [D loss: 0.712504, acc.: 46.88%] [G loss: 0.685652]\n",
      "epoch:3 step:3584 [D loss: 0.694724, acc.: 53.12%] [G loss: 0.724404]\n",
      "epoch:3 step:3585 [D loss: 0.709488, acc.: 40.62%] [G loss: 0.714241]\n",
      "epoch:3 step:3586 [D loss: 0.680711, acc.: 50.78%] [G loss: 0.720003]\n",
      "epoch:3 step:3587 [D loss: 0.706634, acc.: 43.75%] [G loss: 0.743323]\n",
      "epoch:3 step:3588 [D loss: 0.704284, acc.: 43.75%] [G loss: 0.747860]\n",
      "epoch:3 step:3589 [D loss: 0.698612, acc.: 53.12%] [G loss: 0.750236]\n",
      "epoch:3 step:3590 [D loss: 0.687484, acc.: 54.69%] [G loss: 0.765249]\n",
      "epoch:3 step:3591 [D loss: 0.690871, acc.: 54.69%] [G loss: 0.759902]\n",
      "epoch:3 step:3592 [D loss: 0.690108, acc.: 57.03%] [G loss: 0.751780]\n",
      "epoch:3 step:3593 [D loss: 0.681042, acc.: 54.69%] [G loss: 0.761060]\n",
      "epoch:3 step:3594 [D loss: 0.683624, acc.: 58.59%] [G loss: 0.766890]\n",
      "epoch:3 step:3595 [D loss: 0.686681, acc.: 53.91%] [G loss: 0.789886]\n",
      "epoch:3 step:3596 [D loss: 0.683614, acc.: 59.38%] [G loss: 0.798390]\n",
      "epoch:3 step:3597 [D loss: 0.678566, acc.: 57.03%] [G loss: 0.834223]\n",
      "epoch:3 step:3598 [D loss: 0.698811, acc.: 44.53%] [G loss: 0.735121]\n",
      "epoch:3 step:3599 [D loss: 0.699457, acc.: 53.12%] [G loss: 0.770003]\n",
      "epoch:3 step:3600 [D loss: 0.733029, acc.: 35.94%] [G loss: 0.742025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3601 [D loss: 0.711844, acc.: 43.75%] [G loss: 0.726076]\n",
      "epoch:3 step:3602 [D loss: 0.697694, acc.: 47.66%] [G loss: 0.714444]\n",
      "epoch:3 step:3603 [D loss: 0.694566, acc.: 51.56%] [G loss: 0.749657]\n",
      "epoch:3 step:3604 [D loss: 0.683284, acc.: 54.69%] [G loss: 0.694723]\n",
      "epoch:3 step:3605 [D loss: 0.683098, acc.: 60.94%] [G loss: 0.731403]\n",
      "epoch:3 step:3606 [D loss: 0.697021, acc.: 52.34%] [G loss: 0.719808]\n",
      "epoch:3 step:3607 [D loss: 0.680747, acc.: 60.16%] [G loss: 0.711797]\n",
      "epoch:3 step:3608 [D loss: 0.692984, acc.: 52.34%] [G loss: 0.732518]\n",
      "epoch:3 step:3609 [D loss: 0.687436, acc.: 56.25%] [G loss: 0.736234]\n",
      "epoch:3 step:3610 [D loss: 0.688213, acc.: 54.69%] [G loss: 0.706968]\n",
      "epoch:3 step:3611 [D loss: 0.718574, acc.: 44.53%] [G loss: 0.722763]\n",
      "epoch:3 step:3612 [D loss: 0.711683, acc.: 43.75%] [G loss: 0.730257]\n",
      "epoch:3 step:3613 [D loss: 0.613591, acc.: 55.47%] [G loss: 0.747008]\n",
      "epoch:3 step:3614 [D loss: 0.691563, acc.: 57.81%] [G loss: 0.738660]\n",
      "epoch:3 step:3615 [D loss: 0.708540, acc.: 44.53%] [G loss: 0.713339]\n",
      "epoch:3 step:3616 [D loss: 0.697353, acc.: 49.22%] [G loss: 0.725914]\n",
      "epoch:3 step:3617 [D loss: 0.702605, acc.: 54.69%] [G loss: 0.716473]\n",
      "epoch:3 step:3618 [D loss: 0.696248, acc.: 50.00%] [G loss: 0.730268]\n",
      "epoch:3 step:3619 [D loss: 0.687470, acc.: 52.34%] [G loss: 0.756360]\n",
      "epoch:3 step:3620 [D loss: 0.682067, acc.: 57.03%] [G loss: 0.741433]\n",
      "epoch:3 step:3621 [D loss: 0.669425, acc.: 60.94%] [G loss: 0.738043]\n",
      "epoch:3 step:3622 [D loss: 0.704233, acc.: 50.00%] [G loss: 0.705947]\n",
      "epoch:3 step:3623 [D loss: 0.719230, acc.: 40.62%] [G loss: 0.729471]\n",
      "epoch:3 step:3624 [D loss: 0.692342, acc.: 52.34%] [G loss: 0.690951]\n",
      "epoch:3 step:3625 [D loss: 0.699086, acc.: 45.31%] [G loss: 0.714847]\n",
      "epoch:3 step:3626 [D loss: 0.655924, acc.: 67.19%] [G loss: 0.737100]\n",
      "epoch:3 step:3627 [D loss: 0.655134, acc.: 64.06%] [G loss: 0.705311]\n",
      "epoch:3 step:3628 [D loss: 0.717188, acc.: 42.19%] [G loss: 0.672898]\n",
      "epoch:3 step:3629 [D loss: 0.691957, acc.: 50.78%] [G loss: 0.700654]\n",
      "epoch:3 step:3630 [D loss: 0.702924, acc.: 49.22%] [G loss: 0.660033]\n",
      "epoch:3 step:3631 [D loss: 0.749797, acc.: 27.34%] [G loss: 0.659906]\n",
      "epoch:3 step:3632 [D loss: 0.704704, acc.: 41.41%] [G loss: 0.741329]\n",
      "epoch:3 step:3633 [D loss: 0.705803, acc.: 48.44%] [G loss: 0.736575]\n",
      "epoch:3 step:3634 [D loss: 0.702854, acc.: 46.09%] [G loss: 0.714007]\n",
      "epoch:3 step:3635 [D loss: 0.676651, acc.: 57.03%] [G loss: 0.625926]\n",
      "epoch:3 step:3636 [D loss: 0.684062, acc.: 46.88%] [G loss: 0.752398]\n",
      "epoch:3 step:3637 [D loss: 0.674830, acc.: 60.94%] [G loss: 0.755883]\n",
      "epoch:3 step:3638 [D loss: 0.697190, acc.: 48.44%] [G loss: 0.683753]\n",
      "epoch:3 step:3639 [D loss: 0.694242, acc.: 57.03%] [G loss: 0.795552]\n",
      "epoch:3 step:3640 [D loss: 0.687196, acc.: 56.25%] [G loss: 0.749241]\n",
      "epoch:3 step:3641 [D loss: 0.679321, acc.: 60.94%] [G loss: 0.736478]\n",
      "epoch:3 step:3642 [D loss: 0.698870, acc.: 51.56%] [G loss: 0.698150]\n",
      "epoch:3 step:3643 [D loss: 0.713821, acc.: 51.56%] [G loss: 0.757355]\n",
      "epoch:3 step:3644 [D loss: 0.696876, acc.: 51.56%] [G loss: 0.743746]\n",
      "epoch:3 step:3645 [D loss: 0.713338, acc.: 45.31%] [G loss: 0.720604]\n",
      "epoch:3 step:3646 [D loss: 0.703411, acc.: 47.66%] [G loss: 0.702795]\n",
      "epoch:3 step:3647 [D loss: 0.705571, acc.: 46.88%] [G loss: 0.720913]\n",
      "epoch:3 step:3648 [D loss: 0.722589, acc.: 42.97%] [G loss: 0.609444]\n",
      "epoch:3 step:3649 [D loss: 0.699692, acc.: 48.44%] [G loss: 0.732409]\n",
      "epoch:3 step:3650 [D loss: 0.747694, acc.: 39.84%] [G loss: 0.726283]\n",
      "epoch:3 step:3651 [D loss: 0.697958, acc.: 50.78%] [G loss: 0.801320]\n",
      "epoch:3 step:3652 [D loss: 0.666626, acc.: 60.94%] [G loss: 0.786464]\n",
      "epoch:3 step:3653 [D loss: 0.665708, acc.: 63.28%] [G loss: 0.968367]\n",
      "epoch:3 step:3654 [D loss: 0.709448, acc.: 42.97%] [G loss: 0.750814]\n",
      "epoch:3 step:3655 [D loss: 0.701154, acc.: 43.75%] [G loss: 0.787018]\n",
      "epoch:3 step:3656 [D loss: 0.720861, acc.: 38.28%] [G loss: 0.717719]\n",
      "epoch:3 step:3657 [D loss: 0.690762, acc.: 54.69%] [G loss: 0.735933]\n",
      "epoch:3 step:3658 [D loss: 0.694367, acc.: 54.69%] [G loss: 0.703581]\n",
      "epoch:3 step:3659 [D loss: 0.701338, acc.: 54.69%] [G loss: 0.709839]\n",
      "epoch:3 step:3660 [D loss: 0.687997, acc.: 53.12%] [G loss: 0.712676]\n",
      "epoch:3 step:3661 [D loss: 0.696574, acc.: 53.12%] [G loss: 0.741136]\n",
      "epoch:3 step:3662 [D loss: 0.684546, acc.: 57.81%] [G loss: 0.705453]\n",
      "epoch:3 step:3663 [D loss: 0.681964, acc.: 58.59%] [G loss: 0.755265]\n",
      "epoch:3 step:3664 [D loss: 0.679083, acc.: 65.62%] [G loss: 0.770860]\n",
      "epoch:3 step:3665 [D loss: 0.646022, acc.: 72.66%] [G loss: 0.746669]\n",
      "epoch:3 step:3666 [D loss: 0.691203, acc.: 57.03%] [G loss: 0.836329]\n",
      "epoch:3 step:3667 [D loss: 0.673725, acc.: 57.81%] [G loss: 0.745787]\n",
      "epoch:3 step:3668 [D loss: 0.670170, acc.: 60.94%] [G loss: 0.741319]\n",
      "epoch:3 step:3669 [D loss: 0.710952, acc.: 46.88%] [G loss: 0.732996]\n",
      "epoch:3 step:3670 [D loss: 0.725881, acc.: 42.97%] [G loss: 0.756051]\n",
      "epoch:3 step:3671 [D loss: 0.701729, acc.: 50.78%] [G loss: 0.741788]\n",
      "epoch:3 step:3672 [D loss: 0.687762, acc.: 55.47%] [G loss: 0.777816]\n",
      "epoch:3 step:3673 [D loss: 0.713468, acc.: 43.75%] [G loss: 0.756989]\n",
      "epoch:3 step:3674 [D loss: 0.722997, acc.: 39.06%] [G loss: 0.717593]\n",
      "epoch:3 step:3675 [D loss: 0.715582, acc.: 39.06%] [G loss: 0.715370]\n",
      "epoch:3 step:3676 [D loss: 0.703705, acc.: 46.88%] [G loss: 0.676797]\n",
      "epoch:3 step:3677 [D loss: 0.702742, acc.: 42.19%] [G loss: 0.684227]\n",
      "epoch:3 step:3678 [D loss: 0.692056, acc.: 53.91%] [G loss: 0.711869]\n",
      "epoch:3 step:3679 [D loss: 0.711584, acc.: 46.88%] [G loss: 0.704091]\n",
      "epoch:3 step:3680 [D loss: 0.700048, acc.: 46.09%] [G loss: 0.706199]\n",
      "epoch:3 step:3681 [D loss: 0.681344, acc.: 55.47%] [G loss: 0.693619]\n",
      "epoch:3 step:3682 [D loss: 0.680641, acc.: 56.25%] [G loss: 0.718796]\n",
      "epoch:3 step:3683 [D loss: 0.699891, acc.: 51.56%] [G loss: 0.712411]\n",
      "epoch:3 step:3684 [D loss: 0.696156, acc.: 45.31%] [G loss: 0.725830]\n",
      "epoch:3 step:3685 [D loss: 0.719467, acc.: 42.19%] [G loss: 0.716094]\n",
      "epoch:3 step:3686 [D loss: 0.675335, acc.: 56.25%] [G loss: 0.746530]\n",
      "epoch:3 step:3687 [D loss: 0.685013, acc.: 58.59%] [G loss: 0.724251]\n",
      "epoch:3 step:3688 [D loss: 0.678945, acc.: 58.59%] [G loss: 0.721247]\n",
      "epoch:3 step:3689 [D loss: 0.658632, acc.: 63.28%] [G loss: 0.739157]\n",
      "epoch:3 step:3690 [D loss: 0.691089, acc.: 53.12%] [G loss: 0.718282]\n",
      "epoch:3 step:3691 [D loss: 0.698007, acc.: 50.00%] [G loss: 0.722114]\n",
      "epoch:3 step:3692 [D loss: 0.692066, acc.: 56.25%] [G loss: 0.737314]\n",
      "epoch:3 step:3693 [D loss: 0.689243, acc.: 48.44%] [G loss: 0.704835]\n",
      "epoch:3 step:3694 [D loss: 0.691307, acc.: 51.56%] [G loss: 0.714395]\n",
      "epoch:3 step:3695 [D loss: 0.686691, acc.: 48.44%] [G loss: 0.720298]\n",
      "epoch:3 step:3696 [D loss: 0.698430, acc.: 50.00%] [G loss: 0.709211]\n",
      "epoch:3 step:3697 [D loss: 0.678746, acc.: 57.03%] [G loss: 0.734792]\n",
      "epoch:3 step:3698 [D loss: 0.713881, acc.: 39.06%] [G loss: 0.720713]\n",
      "epoch:3 step:3699 [D loss: 0.707491, acc.: 48.44%] [G loss: 0.735545]\n",
      "epoch:3 step:3700 [D loss: 0.694574, acc.: 50.78%] [G loss: 0.744567]\n",
      "epoch:3 step:3701 [D loss: 0.689158, acc.: 55.47%] [G loss: 0.723236]\n",
      "epoch:3 step:3702 [D loss: 0.701055, acc.: 46.09%] [G loss: 0.726274]\n",
      "epoch:3 step:3703 [D loss: 0.721623, acc.: 41.41%] [G loss: 0.740053]\n",
      "epoch:3 step:3704 [D loss: 0.701456, acc.: 46.88%] [G loss: 0.730175]\n",
      "epoch:3 step:3705 [D loss: 0.692987, acc.: 53.12%] [G loss: 0.720649]\n",
      "epoch:3 step:3706 [D loss: 0.686326, acc.: 56.25%] [G loss: 0.730357]\n",
      "epoch:3 step:3707 [D loss: 0.688282, acc.: 53.91%] [G loss: 0.739174]\n",
      "epoch:3 step:3708 [D loss: 0.685583, acc.: 50.78%] [G loss: 0.705719]\n",
      "epoch:3 step:3709 [D loss: 0.686528, acc.: 61.72%] [G loss: 0.720004]\n",
      "epoch:3 step:3710 [D loss: 0.613646, acc.: 72.66%] [G loss: 0.741575]\n",
      "epoch:3 step:3711 [D loss: 0.653468, acc.: 63.28%] [G loss: 0.764387]\n",
      "epoch:3 step:3712 [D loss: 0.669063, acc.: 67.97%] [G loss: 0.716388]\n",
      "epoch:3 step:3713 [D loss: 0.681805, acc.: 57.81%] [G loss: 0.745536]\n",
      "epoch:3 step:3714 [D loss: 0.689281, acc.: 53.12%] [G loss: 0.709497]\n",
      "epoch:3 step:3715 [D loss: 0.718170, acc.: 46.88%] [G loss: 0.736948]\n",
      "epoch:3 step:3716 [D loss: 0.768854, acc.: 34.38%] [G loss: 0.704518]\n",
      "epoch:3 step:3717 [D loss: 0.711457, acc.: 47.66%] [G loss: 0.735740]\n",
      "epoch:3 step:3718 [D loss: 0.692487, acc.: 51.56%] [G loss: 0.690074]\n",
      "epoch:3 step:3719 [D loss: 0.694394, acc.: 57.03%] [G loss: 0.695253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3720 [D loss: 0.709943, acc.: 43.75%] [G loss: 0.771433]\n",
      "epoch:3 step:3721 [D loss: 0.722886, acc.: 44.53%] [G loss: 0.714377]\n",
      "epoch:3 step:3722 [D loss: 0.689497, acc.: 52.34%] [G loss: 0.720386]\n",
      "epoch:3 step:3723 [D loss: 0.496803, acc.: 70.31%] [G loss: 0.700623]\n",
      "epoch:3 step:3724 [D loss: 0.717260, acc.: 48.44%] [G loss: 0.723646]\n",
      "epoch:3 step:3725 [D loss: 0.705211, acc.: 48.44%] [G loss: 0.739521]\n",
      "epoch:3 step:3726 [D loss: 0.820719, acc.: 28.91%] [G loss: 0.728712]\n",
      "epoch:3 step:3727 [D loss: 0.714504, acc.: 45.31%] [G loss: 0.712825]\n",
      "epoch:3 step:3728 [D loss: 0.699646, acc.: 50.78%] [G loss: 0.737288]\n",
      "epoch:3 step:3729 [D loss: 0.684905, acc.: 62.50%] [G loss: 0.696147]\n",
      "epoch:3 step:3730 [D loss: 0.668495, acc.: 60.16%] [G loss: 0.741024]\n",
      "epoch:3 step:3731 [D loss: 0.700501, acc.: 42.19%] [G loss: 0.730447]\n",
      "epoch:3 step:3732 [D loss: 0.683734, acc.: 56.25%] [G loss: 0.733672]\n",
      "epoch:3 step:3733 [D loss: 0.665147, acc.: 62.50%] [G loss: 0.726082]\n",
      "epoch:3 step:3734 [D loss: 0.696160, acc.: 51.56%] [G loss: 0.737286]\n",
      "epoch:3 step:3735 [D loss: 0.658360, acc.: 58.59%] [G loss: 0.719540]\n",
      "epoch:3 step:3736 [D loss: 0.629898, acc.: 59.38%] [G loss: 0.689515]\n",
      "epoch:3 step:3737 [D loss: 0.570666, acc.: 67.19%] [G loss: 0.735083]\n",
      "epoch:3 step:3738 [D loss: 0.533524, acc.: 60.16%] [G loss: 0.777282]\n",
      "epoch:3 step:3739 [D loss: 0.759340, acc.: 44.53%] [G loss: 0.714116]\n",
      "epoch:3 step:3740 [D loss: 0.730575, acc.: 28.91%] [G loss: 0.716578]\n",
      "epoch:3 step:3741 [D loss: 0.691849, acc.: 57.03%] [G loss: 0.769251]\n",
      "epoch:3 step:3742 [D loss: 0.878980, acc.: 41.41%] [G loss: 0.831942]\n",
      "epoch:3 step:3743 [D loss: 0.710488, acc.: 53.91%] [G loss: 0.771458]\n",
      "epoch:3 step:3744 [D loss: 0.718122, acc.: 54.69%] [G loss: 0.771798]\n",
      "epoch:3 step:3745 [D loss: 0.693649, acc.: 54.69%] [G loss: 0.708238]\n",
      "epoch:3 step:3746 [D loss: 0.683291, acc.: 57.81%] [G loss: 0.709486]\n",
      "epoch:3 step:3747 [D loss: 0.565479, acc.: 71.88%] [G loss: 0.652566]\n",
      "epoch:3 step:3748 [D loss: 0.610928, acc.: 54.69%] [G loss: 0.555559]\n",
      "epoch:4 step:3749 [D loss: 0.871508, acc.: 29.69%] [G loss: 0.678240]\n",
      "epoch:4 step:3750 [D loss: 0.737191, acc.: 29.69%] [G loss: 0.686903]\n",
      "epoch:4 step:3751 [D loss: 0.807033, acc.: 19.53%] [G loss: 0.724024]\n",
      "epoch:4 step:3752 [D loss: 0.703462, acc.: 50.00%] [G loss: 0.763297]\n",
      "epoch:4 step:3753 [D loss: 0.682926, acc.: 54.69%] [G loss: 0.785676]\n",
      "epoch:4 step:3754 [D loss: 0.673132, acc.: 46.88%] [G loss: 0.784615]\n",
      "epoch:4 step:3755 [D loss: 0.668760, acc.: 54.69%] [G loss: 0.787385]\n",
      "epoch:4 step:3756 [D loss: 0.694109, acc.: 42.19%] [G loss: 0.786177]\n",
      "epoch:4 step:3757 [D loss: 0.676123, acc.: 56.25%] [G loss: 0.832569]\n",
      "epoch:4 step:3758 [D loss: 0.695520, acc.: 51.56%] [G loss: 0.751299]\n",
      "epoch:4 step:3759 [D loss: 0.681284, acc.: 55.47%] [G loss: 0.754904]\n",
      "epoch:4 step:3760 [D loss: 0.703655, acc.: 48.44%] [G loss: 0.781976]\n",
      "epoch:4 step:3761 [D loss: 0.659705, acc.: 46.09%] [G loss: 0.969583]\n",
      "epoch:4 step:3762 [D loss: 0.712690, acc.: 42.97%] [G loss: 0.690797]\n",
      "epoch:4 step:3763 [D loss: 0.724195, acc.: 40.62%] [G loss: 0.741404]\n",
      "epoch:4 step:3764 [D loss: 0.705919, acc.: 44.53%] [G loss: 0.703292]\n",
      "epoch:4 step:3765 [D loss: 0.717947, acc.: 41.41%] [G loss: 0.740033]\n",
      "epoch:4 step:3766 [D loss: 0.720663, acc.: 40.62%] [G loss: 0.715701]\n",
      "epoch:4 step:3767 [D loss: 0.714916, acc.: 42.19%] [G loss: 0.716722]\n",
      "epoch:4 step:3768 [D loss: 0.697446, acc.: 55.47%] [G loss: 0.730348]\n",
      "epoch:4 step:3769 [D loss: 0.709685, acc.: 45.31%] [G loss: 0.727414]\n",
      "epoch:4 step:3770 [D loss: 0.685180, acc.: 53.91%] [G loss: 0.726464]\n",
      "epoch:4 step:3771 [D loss: 0.696015, acc.: 45.31%] [G loss: 0.737388]\n",
      "epoch:4 step:3772 [D loss: 0.692998, acc.: 47.66%] [G loss: 0.747644]\n",
      "epoch:4 step:3773 [D loss: 0.688983, acc.: 50.78%] [G loss: 0.760195]\n",
      "epoch:4 step:3774 [D loss: 0.707771, acc.: 52.34%] [G loss: 0.711681]\n",
      "epoch:4 step:3775 [D loss: 0.710464, acc.: 42.97%] [G loss: 0.743874]\n",
      "epoch:4 step:3776 [D loss: 0.706127, acc.: 44.53%] [G loss: 0.719112]\n",
      "epoch:4 step:3777 [D loss: 0.693399, acc.: 50.00%] [G loss: 0.724764]\n",
      "epoch:4 step:3778 [D loss: 0.695085, acc.: 50.00%] [G loss: 0.734559]\n",
      "epoch:4 step:3779 [D loss: 0.692306, acc.: 51.56%] [G loss: 0.730123]\n",
      "epoch:4 step:3780 [D loss: 0.696317, acc.: 43.75%] [G loss: 0.723789]\n",
      "epoch:4 step:3781 [D loss: 0.694049, acc.: 53.91%] [G loss: 0.724558]\n",
      "epoch:4 step:3782 [D loss: 0.696524, acc.: 56.25%] [G loss: 0.738660]\n",
      "epoch:4 step:3783 [D loss: 0.683265, acc.: 60.16%] [G loss: 0.739205]\n",
      "epoch:4 step:3784 [D loss: 0.674868, acc.: 67.19%] [G loss: 0.730382]\n",
      "epoch:4 step:3785 [D loss: 0.690172, acc.: 55.47%] [G loss: 0.729046]\n",
      "epoch:4 step:3786 [D loss: 0.698805, acc.: 55.47%] [G loss: 0.742906]\n",
      "epoch:4 step:3787 [D loss: 0.694212, acc.: 53.12%] [G loss: 0.747715]\n",
      "epoch:4 step:3788 [D loss: 0.663495, acc.: 57.81%] [G loss: 0.740840]\n",
      "epoch:4 step:3789 [D loss: 0.678398, acc.: 67.19%] [G loss: 0.747139]\n",
      "epoch:4 step:3790 [D loss: 0.703065, acc.: 49.22%] [G loss: 0.730129]\n",
      "epoch:4 step:3791 [D loss: 0.694138, acc.: 51.56%] [G loss: 0.735692]\n",
      "epoch:4 step:3792 [D loss: 0.706748, acc.: 45.31%] [G loss: 0.733709]\n",
      "epoch:4 step:3793 [D loss: 0.689745, acc.: 53.91%] [G loss: 0.731886]\n",
      "epoch:4 step:3794 [D loss: 0.695511, acc.: 53.91%] [G loss: 0.705309]\n",
      "epoch:4 step:3795 [D loss: 0.706431, acc.: 43.75%] [G loss: 0.718261]\n",
      "epoch:4 step:3796 [D loss: 0.684053, acc.: 50.00%] [G loss: 0.701132]\n",
      "epoch:4 step:3797 [D loss: 0.688670, acc.: 48.44%] [G loss: 0.718309]\n",
      "epoch:4 step:3798 [D loss: 0.665039, acc.: 57.03%] [G loss: 0.751486]\n",
      "epoch:4 step:3799 [D loss: 0.710150, acc.: 38.28%] [G loss: 0.705833]\n",
      "epoch:4 step:3800 [D loss: 0.722837, acc.: 39.84%] [G loss: 0.703802]\n",
      "epoch:4 step:3801 [D loss: 0.680123, acc.: 61.72%] [G loss: 0.705562]\n",
      "epoch:4 step:3802 [D loss: 0.717608, acc.: 42.19%] [G loss: 0.696942]\n",
      "epoch:4 step:3803 [D loss: 0.691198, acc.: 55.47%] [G loss: 0.710014]\n",
      "epoch:4 step:3804 [D loss: 0.684456, acc.: 56.25%] [G loss: 0.736266]\n",
      "epoch:4 step:3805 [D loss: 0.713171, acc.: 40.62%] [G loss: 0.719526]\n",
      "epoch:4 step:3806 [D loss: 0.702601, acc.: 48.44%] [G loss: 0.718845]\n",
      "epoch:4 step:3807 [D loss: 0.689496, acc.: 53.91%] [G loss: 0.697219]\n",
      "epoch:4 step:3808 [D loss: 0.706243, acc.: 43.75%] [G loss: 0.713890]\n",
      "epoch:4 step:3809 [D loss: 0.700033, acc.: 46.09%] [G loss: 0.748315]\n",
      "epoch:4 step:3810 [D loss: 0.691829, acc.: 57.81%] [G loss: 0.753684]\n",
      "epoch:4 step:3811 [D loss: 0.699192, acc.: 43.75%] [G loss: 0.745318]\n",
      "epoch:4 step:3812 [D loss: 0.686029, acc.: 55.47%] [G loss: 0.762471]\n",
      "epoch:4 step:3813 [D loss: 0.693158, acc.: 50.00%] [G loss: 0.731181]\n",
      "epoch:4 step:3814 [D loss: 0.687324, acc.: 50.78%] [G loss: 0.749738]\n",
      "epoch:4 step:3815 [D loss: 0.683365, acc.: 57.03%] [G loss: 0.754559]\n",
      "epoch:4 step:3816 [D loss: 0.681408, acc.: 56.25%] [G loss: 0.758548]\n",
      "epoch:4 step:3817 [D loss: 0.670322, acc.: 61.72%] [G loss: 0.764234]\n",
      "epoch:4 step:3818 [D loss: 0.679183, acc.: 58.59%] [G loss: 0.756947]\n",
      "epoch:4 step:3819 [D loss: 0.708140, acc.: 42.97%] [G loss: 0.766080]\n",
      "epoch:4 step:3820 [D loss: 0.700361, acc.: 50.00%] [G loss: 0.761600]\n",
      "epoch:4 step:3821 [D loss: 0.709340, acc.: 46.09%] [G loss: 0.752735]\n",
      "epoch:4 step:3822 [D loss: 0.691766, acc.: 52.34%] [G loss: 0.747010]\n",
      "epoch:4 step:3823 [D loss: 0.708451, acc.: 40.62%] [G loss: 0.735416]\n",
      "epoch:4 step:3824 [D loss: 0.689077, acc.: 52.34%] [G loss: 0.743679]\n",
      "epoch:4 step:3825 [D loss: 0.674032, acc.: 65.62%] [G loss: 0.714723]\n",
      "epoch:4 step:3826 [D loss: 0.707950, acc.: 49.22%] [G loss: 0.728905]\n",
      "epoch:4 step:3827 [D loss: 0.699671, acc.: 50.78%] [G loss: 0.716677]\n",
      "epoch:4 step:3828 [D loss: 0.692904, acc.: 57.81%] [G loss: 0.747025]\n",
      "epoch:4 step:3829 [D loss: 0.715903, acc.: 42.97%] [G loss: 0.708479]\n",
      "epoch:4 step:3830 [D loss: 0.703753, acc.: 42.19%] [G loss: 0.725643]\n",
      "epoch:4 step:3831 [D loss: 0.691730, acc.: 53.91%] [G loss: 0.722018]\n",
      "epoch:4 step:3832 [D loss: 0.702601, acc.: 53.12%] [G loss: 0.715159]\n",
      "epoch:4 step:3833 [D loss: 0.676532, acc.: 49.22%] [G loss: 0.724485]\n",
      "epoch:4 step:3834 [D loss: 0.685282, acc.: 54.69%] [G loss: 0.731945]\n",
      "epoch:4 step:3835 [D loss: 0.689105, acc.: 55.47%] [G loss: 0.727129]\n",
      "epoch:4 step:3836 [D loss: 0.698581, acc.: 45.31%] [G loss: 0.709902]\n",
      "epoch:4 step:3837 [D loss: 0.662771, acc.: 60.94%] [G loss: 0.716160]\n",
      "epoch:4 step:3838 [D loss: 0.746966, acc.: 41.41%] [G loss: 0.738642]\n",
      "epoch:4 step:3839 [D loss: 0.679699, acc.: 55.47%] [G loss: 0.716723]\n",
      "epoch:4 step:3840 [D loss: 0.693152, acc.: 46.09%] [G loss: 0.709233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3841 [D loss: 0.720376, acc.: 39.06%] [G loss: 0.716498]\n",
      "epoch:4 step:3842 [D loss: 0.690498, acc.: 54.69%] [G loss: 0.695016]\n",
      "epoch:4 step:3843 [D loss: 0.693413, acc.: 53.91%] [G loss: 0.722289]\n",
      "epoch:4 step:3844 [D loss: 0.692297, acc.: 52.34%] [G loss: 0.717645]\n",
      "epoch:4 step:3845 [D loss: 0.703166, acc.: 44.53%] [G loss: 0.726206]\n",
      "epoch:4 step:3846 [D loss: 0.684544, acc.: 55.47%] [G loss: 0.712283]\n",
      "epoch:4 step:3847 [D loss: 0.681011, acc.: 59.38%] [G loss: 0.707570]\n",
      "epoch:4 step:3848 [D loss: 0.669919, acc.: 64.84%] [G loss: 0.726627]\n",
      "epoch:4 step:3849 [D loss: 0.689130, acc.: 52.34%] [G loss: 0.699657]\n",
      "epoch:4 step:3850 [D loss: 0.681594, acc.: 53.91%] [G loss: 0.711893]\n",
      "epoch:4 step:3851 [D loss: 0.700622, acc.: 44.53%] [G loss: 0.707702]\n",
      "epoch:4 step:3852 [D loss: 0.698376, acc.: 52.34%] [G loss: 0.706668]\n",
      "epoch:4 step:3853 [D loss: 0.681355, acc.: 66.41%] [G loss: 0.754043]\n",
      "epoch:4 step:3854 [D loss: 0.669890, acc.: 64.84%] [G loss: 0.747351]\n",
      "epoch:4 step:3855 [D loss: 0.656757, acc.: 65.62%] [G loss: 0.806636]\n",
      "epoch:4 step:3856 [D loss: 0.694875, acc.: 47.66%] [G loss: 0.779039]\n",
      "epoch:4 step:3857 [D loss: 0.695547, acc.: 49.22%] [G loss: 0.779851]\n",
      "epoch:4 step:3858 [D loss: 0.700289, acc.: 48.44%] [G loss: 0.749599]\n",
      "epoch:4 step:3859 [D loss: 0.697513, acc.: 50.00%] [G loss: 0.735775]\n",
      "epoch:4 step:3860 [D loss: 0.686383, acc.: 54.69%] [G loss: 0.722672]\n",
      "epoch:4 step:3861 [D loss: 0.715173, acc.: 41.41%] [G loss: 0.726149]\n",
      "epoch:4 step:3862 [D loss: 0.692799, acc.: 53.91%] [G loss: 0.715175]\n",
      "epoch:4 step:3863 [D loss: 0.676673, acc.: 59.38%] [G loss: 0.729367]\n",
      "epoch:4 step:3864 [D loss: 0.712823, acc.: 47.66%] [G loss: 0.693398]\n",
      "epoch:4 step:3865 [D loss: 0.709701, acc.: 40.62%] [G loss: 0.617656]\n",
      "epoch:4 step:3866 [D loss: 0.717747, acc.: 39.06%] [G loss: 0.689357]\n",
      "epoch:4 step:3867 [D loss: 0.713219, acc.: 41.41%] [G loss: 0.676986]\n",
      "epoch:4 step:3868 [D loss: 0.724795, acc.: 35.16%] [G loss: 0.715558]\n",
      "epoch:4 step:3869 [D loss: 0.706974, acc.: 49.22%] [G loss: 0.721681]\n",
      "epoch:4 step:3870 [D loss: 0.709431, acc.: 44.53%] [G loss: 0.767680]\n",
      "epoch:4 step:3871 [D loss: 0.691591, acc.: 50.00%] [G loss: 0.774022]\n",
      "epoch:4 step:3872 [D loss: 0.671594, acc.: 63.28%] [G loss: 0.801526]\n",
      "epoch:4 step:3873 [D loss: 0.664616, acc.: 64.84%] [G loss: 0.840666]\n",
      "epoch:4 step:3874 [D loss: 0.654820, acc.: 59.38%] [G loss: 0.824924]\n",
      "epoch:4 step:3875 [D loss: 0.662561, acc.: 63.28%] [G loss: 0.849557]\n",
      "epoch:4 step:3876 [D loss: 0.675735, acc.: 56.25%] [G loss: 0.826713]\n",
      "epoch:4 step:3877 [D loss: 0.684698, acc.: 52.34%] [G loss: 0.801813]\n",
      "epoch:4 step:3878 [D loss: 0.650734, acc.: 72.66%] [G loss: 0.780727]\n",
      "epoch:4 step:3879 [D loss: 0.700317, acc.: 53.12%] [G loss: 0.717748]\n",
      "epoch:4 step:3880 [D loss: 0.714803, acc.: 53.12%] [G loss: 0.705974]\n",
      "epoch:4 step:3881 [D loss: 0.690831, acc.: 54.69%] [G loss: 0.736686]\n",
      "epoch:4 step:3882 [D loss: 0.685395, acc.: 56.25%] [G loss: 0.696674]\n",
      "epoch:4 step:3883 [D loss: 0.719071, acc.: 46.09%] [G loss: 0.698819]\n",
      "epoch:4 step:3884 [D loss: 0.688503, acc.: 59.38%] [G loss: 0.677992]\n",
      "epoch:4 step:3885 [D loss: 0.724243, acc.: 42.19%] [G loss: 0.685649]\n",
      "epoch:4 step:3886 [D loss: 0.718762, acc.: 40.62%] [G loss: 0.701267]\n",
      "epoch:4 step:3887 [D loss: 0.691700, acc.: 53.12%] [G loss: 0.723232]\n",
      "epoch:4 step:3888 [D loss: 0.707747, acc.: 43.75%] [G loss: 0.669175]\n",
      "epoch:4 step:3889 [D loss: 0.712124, acc.: 41.41%] [G loss: 0.553110]\n",
      "epoch:4 step:3890 [D loss: 0.726519, acc.: 42.97%] [G loss: 0.726300]\n",
      "epoch:4 step:3891 [D loss: 0.700515, acc.: 49.22%] [G loss: 0.737067]\n",
      "epoch:4 step:3892 [D loss: 0.673760, acc.: 57.03%] [G loss: 0.747442]\n",
      "epoch:4 step:3893 [D loss: 0.657641, acc.: 72.66%] [G loss: 0.767061]\n",
      "epoch:4 step:3894 [D loss: 0.665018, acc.: 64.06%] [G loss: 0.786093]\n",
      "epoch:4 step:3895 [D loss: 0.665155, acc.: 63.28%] [G loss: 0.760842]\n",
      "epoch:4 step:3896 [D loss: 0.678226, acc.: 64.06%] [G loss: 0.759587]\n",
      "epoch:4 step:3897 [D loss: 0.684551, acc.: 58.59%] [G loss: 0.768655]\n",
      "epoch:4 step:3898 [D loss: 0.679564, acc.: 59.38%] [G loss: 0.775469]\n",
      "epoch:4 step:3899 [D loss: 0.692303, acc.: 56.25%] [G loss: 0.745434]\n",
      "epoch:4 step:3900 [D loss: 0.653538, acc.: 69.53%] [G loss: 0.753739]\n",
      "epoch:4 step:3901 [D loss: 0.731826, acc.: 42.19%] [G loss: 0.740406]\n",
      "epoch:4 step:3902 [D loss: 0.709602, acc.: 42.97%] [G loss: 0.684509]\n",
      "epoch:4 step:3903 [D loss: 0.712119, acc.: 46.88%] [G loss: 0.675486]\n",
      "epoch:4 step:3904 [D loss: 0.723836, acc.: 44.53%] [G loss: 0.691187]\n",
      "epoch:4 step:3905 [D loss: 0.713792, acc.: 39.06%] [G loss: 0.683520]\n",
      "epoch:4 step:3906 [D loss: 0.709914, acc.: 46.88%] [G loss: 0.697561]\n",
      "epoch:4 step:3907 [D loss: 0.699961, acc.: 44.53%] [G loss: 0.717504]\n",
      "epoch:4 step:3908 [D loss: 0.728801, acc.: 38.28%] [G loss: 0.713112]\n",
      "epoch:4 step:3909 [D loss: 0.714095, acc.: 35.16%] [G loss: 0.743531]\n",
      "epoch:4 step:3910 [D loss: 0.687044, acc.: 55.47%] [G loss: 0.734301]\n",
      "epoch:4 step:3911 [D loss: 0.693243, acc.: 48.44%] [G loss: 0.748072]\n",
      "epoch:4 step:3912 [D loss: 0.679747, acc.: 57.03%] [G loss: 0.763614]\n",
      "epoch:4 step:3913 [D loss: 0.686054, acc.: 57.03%] [G loss: 0.751218]\n",
      "epoch:4 step:3914 [D loss: 0.675454, acc.: 60.94%] [G loss: 0.750967]\n",
      "epoch:4 step:3915 [D loss: 0.689244, acc.: 53.91%] [G loss: 0.760447]\n",
      "epoch:4 step:3916 [D loss: 0.674893, acc.: 57.81%] [G loss: 0.745172]\n",
      "epoch:4 step:3917 [D loss: 0.685179, acc.: 53.91%] [G loss: 0.708059]\n",
      "epoch:4 step:3918 [D loss: 0.688390, acc.: 56.25%] [G loss: 0.709327]\n",
      "epoch:4 step:3919 [D loss: 0.691333, acc.: 55.47%] [G loss: 0.696219]\n",
      "epoch:4 step:3920 [D loss: 0.677459, acc.: 59.38%] [G loss: 0.684382]\n",
      "epoch:4 step:3921 [D loss: 0.679458, acc.: 52.34%] [G loss: 0.702855]\n",
      "epoch:4 step:3922 [D loss: 0.717489, acc.: 43.75%] [G loss: 0.689568]\n",
      "epoch:4 step:3923 [D loss: 0.692595, acc.: 53.91%] [G loss: 0.691974]\n",
      "epoch:4 step:3924 [D loss: 0.708324, acc.: 48.44%] [G loss: 0.696929]\n",
      "epoch:4 step:3925 [D loss: 0.704344, acc.: 46.88%] [G loss: 0.685900]\n",
      "epoch:4 step:3926 [D loss: 0.692997, acc.: 55.47%] [G loss: 0.705785]\n",
      "epoch:4 step:3927 [D loss: 0.690989, acc.: 53.91%] [G loss: 0.693823]\n",
      "epoch:4 step:3928 [D loss: 0.689808, acc.: 47.66%] [G loss: 0.706100]\n",
      "epoch:4 step:3929 [D loss: 0.682721, acc.: 53.91%] [G loss: 0.702608]\n",
      "epoch:4 step:3930 [D loss: 0.692171, acc.: 52.34%] [G loss: 0.713004]\n",
      "epoch:4 step:3931 [D loss: 0.684789, acc.: 53.91%] [G loss: 0.717499]\n",
      "epoch:4 step:3932 [D loss: 0.657933, acc.: 53.12%] [G loss: 0.664712]\n",
      "epoch:4 step:3933 [D loss: 0.662860, acc.: 53.91%] [G loss: 0.715745]\n",
      "epoch:4 step:3934 [D loss: 0.690696, acc.: 52.34%] [G loss: 0.666787]\n",
      "epoch:4 step:3935 [D loss: 0.624566, acc.: 56.25%] [G loss: 0.692219]\n",
      "epoch:4 step:3936 [D loss: 0.805512, acc.: 42.19%] [G loss: 0.738780]\n",
      "epoch:4 step:3937 [D loss: 0.692764, acc.: 50.00%] [G loss: 0.735397]\n",
      "epoch:4 step:3938 [D loss: 0.707753, acc.: 43.75%] [G loss: 0.716052]\n",
      "epoch:4 step:3939 [D loss: 0.695148, acc.: 49.22%] [G loss: 0.730999]\n",
      "epoch:4 step:3940 [D loss: 0.682904, acc.: 56.25%] [G loss: 0.732085]\n",
      "epoch:4 step:3941 [D loss: 0.876114, acc.: 36.72%] [G loss: 0.775729]\n",
      "epoch:4 step:3942 [D loss: 0.708963, acc.: 46.09%] [G loss: 0.830519]\n",
      "epoch:4 step:3943 [D loss: 0.714865, acc.: 46.09%] [G loss: 0.823566]\n",
      "epoch:4 step:3944 [D loss: 0.706465, acc.: 46.09%] [G loss: 0.792616]\n",
      "epoch:4 step:3945 [D loss: 0.701975, acc.: 46.09%] [G loss: 0.728155]\n",
      "epoch:4 step:3946 [D loss: 0.701718, acc.: 46.88%] [G loss: 0.724177]\n",
      "epoch:4 step:3947 [D loss: 0.685497, acc.: 55.47%] [G loss: 0.768014]\n",
      "epoch:4 step:3948 [D loss: 0.699361, acc.: 51.56%] [G loss: 0.741823]\n",
      "epoch:4 step:3949 [D loss: 0.695909, acc.: 50.00%] [G loss: 0.709449]\n",
      "epoch:4 step:3950 [D loss: 0.695763, acc.: 52.34%] [G loss: 0.688083]\n",
      "epoch:4 step:3951 [D loss: 0.720319, acc.: 34.38%] [G loss: 0.725491]\n",
      "epoch:4 step:3952 [D loss: 0.754509, acc.: 32.81%] [G loss: 0.719032]\n",
      "epoch:4 step:3953 [D loss: 0.685621, acc.: 64.06%] [G loss: 0.716306]\n",
      "epoch:4 step:3954 [D loss: 0.700025, acc.: 53.91%] [G loss: 0.720325]\n",
      "epoch:4 step:3955 [D loss: 0.664859, acc.: 54.69%] [G loss: 0.734484]\n",
      "epoch:4 step:3956 [D loss: 0.684149, acc.: 57.03%] [G loss: 0.729327]\n",
      "epoch:4 step:3957 [D loss: 0.680238, acc.: 61.72%] [G loss: 0.653783]\n",
      "epoch:4 step:3958 [D loss: 0.693864, acc.: 53.12%] [G loss: 0.706463]\n",
      "epoch:4 step:3959 [D loss: 0.680804, acc.: 62.50%] [G loss: 0.727533]\n",
      "epoch:4 step:3960 [D loss: 0.710164, acc.: 47.66%] [G loss: 0.485025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3961 [D loss: 0.700835, acc.: 47.66%] [G loss: 0.698465]\n",
      "epoch:4 step:3962 [D loss: 0.708903, acc.: 46.88%] [G loss: 0.708123]\n",
      "epoch:4 step:3963 [D loss: 0.694928, acc.: 48.44%] [G loss: 0.713508]\n",
      "epoch:4 step:3964 [D loss: 0.638413, acc.: 55.47%] [G loss: 0.707061]\n",
      "epoch:4 step:3965 [D loss: 0.718772, acc.: 42.97%] [G loss: 0.737846]\n",
      "epoch:4 step:3966 [D loss: 0.686786, acc.: 57.81%] [G loss: 0.607776]\n",
      "epoch:4 step:3967 [D loss: 0.678886, acc.: 65.62%] [G loss: 0.590384]\n",
      "epoch:4 step:3968 [D loss: 0.842542, acc.: 14.06%] [G loss: 0.705317]\n",
      "epoch:4 step:3969 [D loss: 0.718947, acc.: 33.59%] [G loss: 0.744542]\n",
      "epoch:4 step:3970 [D loss: 0.696826, acc.: 50.00%] [G loss: 0.746735]\n",
      "epoch:4 step:3971 [D loss: 0.682008, acc.: 55.47%] [G loss: 0.739623]\n",
      "epoch:4 step:3972 [D loss: 0.688728, acc.: 53.91%] [G loss: 0.755649]\n",
      "epoch:4 step:3973 [D loss: 0.689021, acc.: 54.69%] [G loss: 0.745411]\n",
      "epoch:4 step:3974 [D loss: 0.688196, acc.: 47.66%] [G loss: 0.735032]\n",
      "epoch:4 step:3975 [D loss: 0.681216, acc.: 55.47%] [G loss: 0.784868]\n",
      "epoch:4 step:3976 [D loss: 0.687610, acc.: 57.03%] [G loss: 0.753601]\n",
      "epoch:4 step:3977 [D loss: 0.667022, acc.: 57.03%] [G loss: 0.768428]\n",
      "epoch:4 step:3978 [D loss: 0.663215, acc.: 64.84%] [G loss: 0.771210]\n",
      "epoch:4 step:3979 [D loss: 0.646471, acc.: 69.53%] [G loss: 0.836100]\n",
      "epoch:4 step:3980 [D loss: 0.666185, acc.: 61.72%] [G loss: 1.031129]\n",
      "epoch:4 step:3981 [D loss: 0.712982, acc.: 44.53%] [G loss: 0.757408]\n",
      "epoch:4 step:3982 [D loss: 0.709540, acc.: 45.31%] [G loss: 0.751298]\n",
      "epoch:4 step:3983 [D loss: 0.712345, acc.: 41.41%] [G loss: 0.733775]\n",
      "epoch:4 step:3984 [D loss: 0.716891, acc.: 40.62%] [G loss: 0.718836]\n",
      "epoch:4 step:3985 [D loss: 0.702436, acc.: 50.78%] [G loss: 0.775839]\n",
      "epoch:4 step:3986 [D loss: 0.699512, acc.: 53.12%] [G loss: 0.716701]\n",
      "epoch:4 step:3987 [D loss: 0.694670, acc.: 50.78%] [G loss: 0.733201]\n",
      "epoch:4 step:3988 [D loss: 0.707643, acc.: 43.75%] [G loss: 0.761893]\n",
      "epoch:4 step:3989 [D loss: 0.715500, acc.: 40.62%] [G loss: 0.708735]\n",
      "epoch:4 step:3990 [D loss: 0.725753, acc.: 42.19%] [G loss: 0.728648]\n",
      "epoch:4 step:3991 [D loss: 0.697849, acc.: 55.47%] [G loss: 0.744833]\n",
      "epoch:4 step:3992 [D loss: 0.694953, acc.: 50.78%] [G loss: 0.709914]\n",
      "epoch:4 step:3993 [D loss: 0.691988, acc.: 53.12%] [G loss: 0.731401]\n",
      "epoch:4 step:3994 [D loss: 0.701720, acc.: 49.22%] [G loss: 0.722027]\n",
      "epoch:4 step:3995 [D loss: 0.695318, acc.: 50.00%] [G loss: 0.719953]\n",
      "epoch:4 step:3996 [D loss: 0.695323, acc.: 47.66%] [G loss: 0.740109]\n",
      "epoch:4 step:3997 [D loss: 0.690477, acc.: 52.34%] [G loss: 0.745510]\n",
      "epoch:4 step:3998 [D loss: 0.683765, acc.: 57.03%] [G loss: 0.744283]\n",
      "epoch:4 step:3999 [D loss: 0.695532, acc.: 53.12%] [G loss: 0.724067]\n",
      "epoch:4 step:4000 [D loss: 0.672833, acc.: 62.50%] [G loss: 0.738475]\n",
      "epoch:4 step:4001 [D loss: 0.675551, acc.: 58.59%] [G loss: 0.716037]\n",
      "epoch:4 step:4002 [D loss: 0.682973, acc.: 57.03%] [G loss: 0.741763]\n",
      "epoch:4 step:4003 [D loss: 0.698359, acc.: 50.78%] [G loss: 0.731874]\n",
      "epoch:4 step:4004 [D loss: 0.701619, acc.: 49.22%] [G loss: 0.703984]\n",
      "epoch:4 step:4005 [D loss: 0.691650, acc.: 52.34%] [G loss: 0.728319]\n",
      "epoch:4 step:4006 [D loss: 0.686787, acc.: 53.91%] [G loss: 0.706706]\n",
      "epoch:4 step:4007 [D loss: 0.701380, acc.: 50.00%] [G loss: 0.695329]\n",
      "epoch:4 step:4008 [D loss: 0.715524, acc.: 38.28%] [G loss: 0.657380]\n",
      "epoch:4 step:4009 [D loss: 0.716886, acc.: 38.28%] [G loss: 0.691575]\n",
      "epoch:4 step:4010 [D loss: 0.707590, acc.: 45.31%] [G loss: 0.685669]\n",
      "epoch:4 step:4011 [D loss: 0.776866, acc.: 50.00%] [G loss: 0.729881]\n",
      "epoch:4 step:4012 [D loss: 0.669501, acc.: 71.09%] [G loss: 0.731366]\n",
      "epoch:4 step:4013 [D loss: 0.712697, acc.: 35.94%] [G loss: 0.730593]\n",
      "epoch:4 step:4014 [D loss: 0.693310, acc.: 52.34%] [G loss: 0.720003]\n",
      "epoch:4 step:4015 [D loss: 0.689769, acc.: 52.34%] [G loss: 0.736148]\n",
      "epoch:4 step:4016 [D loss: 0.687341, acc.: 60.16%] [G loss: 0.722474]\n",
      "epoch:4 step:4017 [D loss: 0.690960, acc.: 57.03%] [G loss: 0.629283]\n",
      "epoch:4 step:4018 [D loss: 0.681519, acc.: 62.50%] [G loss: 0.721892]\n",
      "epoch:4 step:4019 [D loss: 0.684893, acc.: 53.12%] [G loss: 0.732048]\n",
      "epoch:4 step:4020 [D loss: 0.695271, acc.: 51.56%] [G loss: 0.733513]\n",
      "epoch:4 step:4021 [D loss: 0.685117, acc.: 55.47%] [G loss: 0.757321]\n",
      "epoch:4 step:4022 [D loss: 0.692479, acc.: 55.47%] [G loss: 0.701676]\n",
      "epoch:4 step:4023 [D loss: 0.685367, acc.: 54.69%] [G loss: 0.717903]\n",
      "epoch:4 step:4024 [D loss: 0.679690, acc.: 60.94%] [G loss: 0.756956]\n",
      "epoch:4 step:4025 [D loss: 0.687566, acc.: 53.91%] [G loss: 0.718410]\n",
      "epoch:4 step:4026 [D loss: 0.697716, acc.: 46.88%] [G loss: 0.714096]\n",
      "epoch:4 step:4027 [D loss: 0.711290, acc.: 42.97%] [G loss: 0.712946]\n",
      "epoch:4 step:4028 [D loss: 0.698964, acc.: 48.44%] [G loss: 0.693434]\n",
      "epoch:4 step:4029 [D loss: 0.708294, acc.: 41.41%] [G loss: 0.716590]\n",
      "epoch:4 step:4030 [D loss: 0.702517, acc.: 47.66%] [G loss: 0.726259]\n",
      "epoch:4 step:4031 [D loss: 0.702176, acc.: 41.41%] [G loss: 0.706961]\n",
      "epoch:4 step:4032 [D loss: 0.699196, acc.: 52.34%] [G loss: 0.703241]\n",
      "epoch:4 step:4033 [D loss: 0.694472, acc.: 42.97%] [G loss: 0.704536]\n",
      "epoch:4 step:4034 [D loss: 0.689537, acc.: 57.03%] [G loss: 0.723607]\n",
      "epoch:4 step:4035 [D loss: 0.694730, acc.: 49.22%] [G loss: 0.705200]\n",
      "epoch:4 step:4036 [D loss: 0.692311, acc.: 50.00%] [G loss: 0.716702]\n",
      "epoch:4 step:4037 [D loss: 0.689801, acc.: 50.78%] [G loss: 0.717561]\n",
      "epoch:4 step:4038 [D loss: 0.682657, acc.: 61.72%] [G loss: 0.721331]\n",
      "epoch:4 step:4039 [D loss: 0.693566, acc.: 47.66%] [G loss: 0.737907]\n",
      "epoch:4 step:4040 [D loss: 0.691911, acc.: 49.22%] [G loss: 0.730804]\n",
      "epoch:4 step:4041 [D loss: 0.689035, acc.: 54.69%] [G loss: 0.722746]\n",
      "epoch:4 step:4042 [D loss: 0.680768, acc.: 53.91%] [G loss: 0.735005]\n",
      "epoch:4 step:4043 [D loss: 0.694248, acc.: 53.91%] [G loss: 0.731381]\n",
      "epoch:4 step:4044 [D loss: 0.700186, acc.: 50.00%] [G loss: 0.740358]\n",
      "epoch:4 step:4045 [D loss: 0.712960, acc.: 46.09%] [G loss: 0.735721]\n",
      "epoch:4 step:4046 [D loss: 0.706638, acc.: 44.53%] [G loss: 0.696454]\n",
      "epoch:4 step:4047 [D loss: 0.703677, acc.: 43.75%] [G loss: 0.733546]\n",
      "epoch:4 step:4048 [D loss: 0.698018, acc.: 44.53%] [G loss: 0.731478]\n",
      "epoch:4 step:4049 [D loss: 0.695562, acc.: 48.44%] [G loss: 0.727987]\n",
      "epoch:4 step:4050 [D loss: 0.696679, acc.: 50.78%] [G loss: 0.718125]\n",
      "epoch:4 step:4051 [D loss: 0.690749, acc.: 54.69%] [G loss: 0.714112]\n",
      "epoch:4 step:4052 [D loss: 0.691314, acc.: 50.78%] [G loss: 0.707448]\n",
      "epoch:4 step:4053 [D loss: 0.691081, acc.: 55.47%] [G loss: 0.716416]\n",
      "epoch:4 step:4054 [D loss: 0.683091, acc.: 56.25%] [G loss: 0.700038]\n",
      "epoch:4 step:4055 [D loss: 0.682214, acc.: 59.38%] [G loss: 0.701894]\n",
      "epoch:4 step:4056 [D loss: 0.693434, acc.: 50.78%] [G loss: 0.702685]\n",
      "epoch:4 step:4057 [D loss: 0.696431, acc.: 50.00%] [G loss: 0.718222]\n",
      "epoch:4 step:4058 [D loss: 0.684785, acc.: 57.81%] [G loss: 0.710141]\n",
      "epoch:4 step:4059 [D loss: 0.685144, acc.: 52.34%] [G loss: 0.701838]\n",
      "epoch:4 step:4060 [D loss: 0.704777, acc.: 46.09%] [G loss: 0.736273]\n",
      "epoch:4 step:4061 [D loss: 0.688863, acc.: 50.78%] [G loss: 0.700790]\n",
      "epoch:4 step:4062 [D loss: 0.680731, acc.: 60.94%] [G loss: 0.718820]\n",
      "epoch:4 step:4063 [D loss: 0.691107, acc.: 53.91%] [G loss: 0.715561]\n",
      "epoch:4 step:4064 [D loss: 0.707080, acc.: 41.41%] [G loss: 0.720558]\n",
      "epoch:4 step:4065 [D loss: 0.712344, acc.: 43.75%] [G loss: 0.708591]\n",
      "epoch:4 step:4066 [D loss: 0.703074, acc.: 42.97%] [G loss: 0.720629]\n",
      "epoch:4 step:4067 [D loss: 0.706045, acc.: 40.62%] [G loss: 0.714128]\n",
      "epoch:4 step:4068 [D loss: 0.696843, acc.: 50.78%] [G loss: 0.705261]\n",
      "epoch:4 step:4069 [D loss: 0.691304, acc.: 50.78%] [G loss: 0.707381]\n",
      "epoch:4 step:4070 [D loss: 0.682210, acc.: 56.25%] [G loss: 0.765650]\n",
      "epoch:4 step:4071 [D loss: 0.691974, acc.: 53.91%] [G loss: 0.721994]\n",
      "epoch:4 step:4072 [D loss: 0.690040, acc.: 51.56%] [G loss: 0.731410]\n",
      "epoch:4 step:4073 [D loss: 0.686615, acc.: 53.12%] [G loss: 0.739986]\n",
      "epoch:4 step:4074 [D loss: 0.692208, acc.: 47.66%] [G loss: 0.736906]\n",
      "epoch:4 step:4075 [D loss: 0.696075, acc.: 45.31%] [G loss: 0.729390]\n",
      "epoch:4 step:4076 [D loss: 0.701508, acc.: 50.00%] [G loss: 0.740783]\n",
      "epoch:4 step:4077 [D loss: 0.697839, acc.: 49.22%] [G loss: 0.740925]\n",
      "epoch:4 step:4078 [D loss: 0.684165, acc.: 53.12%] [G loss: 0.710736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4079 [D loss: 0.676829, acc.: 63.28%] [G loss: 0.721461]\n",
      "epoch:4 step:4080 [D loss: 0.693347, acc.: 51.56%] [G loss: 0.712579]\n",
      "epoch:4 step:4081 [D loss: 0.705617, acc.: 45.31%] [G loss: 0.704129]\n",
      "epoch:4 step:4082 [D loss: 0.692822, acc.: 51.56%] [G loss: 0.720487]\n",
      "epoch:4 step:4083 [D loss: 0.700621, acc.: 50.78%] [G loss: 0.712844]\n",
      "epoch:4 step:4084 [D loss: 0.685599, acc.: 56.25%] [G loss: 0.672295]\n",
      "epoch:4 step:4085 [D loss: 0.696278, acc.: 46.09%] [G loss: 0.707837]\n",
      "epoch:4 step:4086 [D loss: 0.686199, acc.: 56.25%] [G loss: 0.703271]\n",
      "epoch:4 step:4087 [D loss: 0.700606, acc.: 48.44%] [G loss: 0.715633]\n",
      "epoch:4 step:4088 [D loss: 0.705693, acc.: 44.53%] [G loss: 0.707489]\n",
      "epoch:4 step:4089 [D loss: 0.700231, acc.: 44.53%] [G loss: 0.699491]\n",
      "epoch:4 step:4090 [D loss: 0.696981, acc.: 45.31%] [G loss: 0.697026]\n",
      "epoch:4 step:4091 [D loss: 0.695361, acc.: 48.44%] [G loss: 0.704305]\n",
      "epoch:4 step:4092 [D loss: 0.682077, acc.: 57.03%] [G loss: 0.738661]\n",
      "epoch:4 step:4093 [D loss: 0.684495, acc.: 53.91%] [G loss: 0.724294]\n",
      "epoch:4 step:4094 [D loss: 0.681763, acc.: 56.25%] [G loss: 0.735257]\n",
      "epoch:4 step:4095 [D loss: 0.675783, acc.: 60.94%] [G loss: 0.702516]\n",
      "epoch:4 step:4096 [D loss: 0.703174, acc.: 49.22%] [G loss: 0.734271]\n",
      "epoch:4 step:4097 [D loss: 0.716453, acc.: 46.09%] [G loss: 0.768488]\n",
      "epoch:4 step:4098 [D loss: 0.705353, acc.: 46.09%] [G loss: 0.690837]\n",
      "epoch:4 step:4099 [D loss: 0.721849, acc.: 39.84%] [G loss: 0.683232]\n",
      "epoch:4 step:4100 [D loss: 0.716461, acc.: 39.06%] [G loss: 0.688101]\n",
      "epoch:4 step:4101 [D loss: 0.707867, acc.: 43.75%] [G loss: 0.719348]\n",
      "epoch:4 step:4102 [D loss: 0.695880, acc.: 53.12%] [G loss: 0.695000]\n",
      "epoch:4 step:4103 [D loss: 0.704796, acc.: 50.78%] [G loss: 0.704789]\n",
      "epoch:4 step:4104 [D loss: 0.699249, acc.: 47.66%] [G loss: 0.708873]\n",
      "epoch:4 step:4105 [D loss: 0.695463, acc.: 53.12%] [G loss: 0.708242]\n",
      "epoch:4 step:4106 [D loss: 0.697347, acc.: 44.53%] [G loss: 0.709201]\n",
      "epoch:4 step:4107 [D loss: 0.685943, acc.: 54.69%] [G loss: 0.704143]\n",
      "epoch:4 step:4108 [D loss: 0.701859, acc.: 43.75%] [G loss: 0.718330]\n",
      "epoch:4 step:4109 [D loss: 0.681568, acc.: 60.16%] [G loss: 0.703392]\n",
      "epoch:4 step:4110 [D loss: 0.689783, acc.: 50.00%] [G loss: 0.703378]\n",
      "epoch:4 step:4111 [D loss: 0.690330, acc.: 49.22%] [G loss: 0.712437]\n",
      "epoch:4 step:4112 [D loss: 0.681492, acc.: 57.81%] [G loss: 0.721862]\n",
      "epoch:4 step:4113 [D loss: 0.688120, acc.: 56.25%] [G loss: 0.713180]\n",
      "epoch:4 step:4114 [D loss: 0.684523, acc.: 59.38%] [G loss: 0.725612]\n",
      "epoch:4 step:4115 [D loss: 0.681842, acc.: 57.81%] [G loss: 0.743309]\n",
      "epoch:4 step:4116 [D loss: 0.692520, acc.: 54.69%] [G loss: 0.743907]\n",
      "epoch:4 step:4117 [D loss: 0.678353, acc.: 64.06%] [G loss: 0.723651]\n",
      "epoch:4 step:4118 [D loss: 0.664441, acc.: 69.53%] [G loss: 0.759339]\n",
      "epoch:4 step:4119 [D loss: 0.640584, acc.: 64.06%] [G loss: 0.765970]\n",
      "epoch:4 step:4120 [D loss: 0.651237, acc.: 64.84%] [G loss: 0.773649]\n",
      "epoch:4 step:4121 [D loss: 0.690899, acc.: 49.22%] [G loss: 0.764717]\n",
      "epoch:4 step:4122 [D loss: 0.668310, acc.: 59.38%] [G loss: 0.697194]\n",
      "epoch:4 step:4123 [D loss: 0.690919, acc.: 50.78%] [G loss: 0.749826]\n",
      "epoch:4 step:4124 [D loss: 0.693348, acc.: 46.88%] [G loss: 0.692971]\n",
      "epoch:4 step:4125 [D loss: 0.732255, acc.: 39.84%] [G loss: 0.673969]\n",
      "epoch:4 step:4126 [D loss: 0.711500, acc.: 50.78%] [G loss: 0.697816]\n",
      "epoch:4 step:4127 [D loss: 0.695656, acc.: 50.00%] [G loss: 0.724037]\n",
      "epoch:4 step:4128 [D loss: 0.678076, acc.: 48.44%] [G loss: 0.723349]\n",
      "epoch:4 step:4129 [D loss: 0.678638, acc.: 55.47%] [G loss: 0.713831]\n",
      "epoch:4 step:4130 [D loss: 0.688338, acc.: 53.12%] [G loss: 0.744239]\n",
      "epoch:4 step:4131 [D loss: 0.692665, acc.: 53.12%] [G loss: 0.754942]\n",
      "epoch:4 step:4132 [D loss: 0.689057, acc.: 50.78%] [G loss: 0.743062]\n",
      "epoch:4 step:4133 [D loss: 0.692050, acc.: 53.12%] [G loss: 0.775159]\n",
      "epoch:4 step:4134 [D loss: 0.667668, acc.: 64.84%] [G loss: 0.773541]\n",
      "epoch:4 step:4135 [D loss: 0.660964, acc.: 61.72%] [G loss: 0.751866]\n",
      "epoch:4 step:4136 [D loss: 0.679423, acc.: 57.03%] [G loss: 0.742824]\n",
      "epoch:4 step:4137 [D loss: 0.707789, acc.: 52.34%] [G loss: 0.727294]\n",
      "epoch:4 step:4138 [D loss: 0.743220, acc.: 37.50%] [G loss: 0.735796]\n",
      "epoch:4 step:4139 [D loss: 0.727687, acc.: 35.94%] [G loss: 0.711469]\n",
      "epoch:4 step:4140 [D loss: 0.715874, acc.: 39.84%] [G loss: 0.666803]\n",
      "epoch:4 step:4141 [D loss: 0.709449, acc.: 46.09%] [G loss: 0.657927]\n",
      "epoch:4 step:4142 [D loss: 0.700149, acc.: 46.88%] [G loss: 0.701271]\n",
      "epoch:4 step:4143 [D loss: 0.704771, acc.: 47.66%] [G loss: 0.705008]\n",
      "epoch:4 step:4144 [D loss: 0.695498, acc.: 45.31%] [G loss: 0.709704]\n",
      "epoch:4 step:4145 [D loss: 0.698416, acc.: 42.19%] [G loss: 0.702424]\n",
      "epoch:4 step:4146 [D loss: 0.699339, acc.: 49.22%] [G loss: 0.721804]\n",
      "epoch:4 step:4147 [D loss: 0.681719, acc.: 61.72%] [G loss: 0.708274]\n",
      "epoch:4 step:4148 [D loss: 0.719751, acc.: 40.62%] [G loss: 0.715198]\n",
      "epoch:4 step:4149 [D loss: 0.701618, acc.: 44.53%] [G loss: 0.711594]\n",
      "epoch:4 step:4150 [D loss: 0.684498, acc.: 57.03%] [G loss: 0.734132]\n",
      "epoch:4 step:4151 [D loss: 0.681033, acc.: 53.91%] [G loss: 0.751456]\n",
      "epoch:4 step:4152 [D loss: 0.682453, acc.: 57.03%] [G loss: 0.744109]\n",
      "epoch:4 step:4153 [D loss: 0.671479, acc.: 62.50%] [G loss: 0.741404]\n",
      "epoch:4 step:4154 [D loss: 0.660433, acc.: 64.06%] [G loss: 0.778211]\n",
      "epoch:4 step:4155 [D loss: 0.677947, acc.: 57.03%] [G loss: 0.767314]\n",
      "epoch:4 step:4156 [D loss: 0.681666, acc.: 54.69%] [G loss: 0.752596]\n",
      "epoch:4 step:4157 [D loss: 0.686579, acc.: 57.03%] [G loss: 0.689689]\n",
      "epoch:4 step:4158 [D loss: 0.681328, acc.: 53.12%] [G loss: 0.738700]\n",
      "epoch:4 step:4159 [D loss: 0.718683, acc.: 44.53%] [G loss: 0.715981]\n",
      "epoch:4 step:4160 [D loss: 0.704290, acc.: 46.09%] [G loss: 0.706413]\n",
      "epoch:4 step:4161 [D loss: 0.688296, acc.: 54.69%] [G loss: 0.680159]\n",
      "epoch:4 step:4162 [D loss: 0.690349, acc.: 53.12%] [G loss: 0.663987]\n",
      "epoch:4 step:4163 [D loss: 0.683419, acc.: 55.47%] [G loss: 0.710517]\n",
      "epoch:4 step:4164 [D loss: 0.686540, acc.: 53.12%] [G loss: 0.697879]\n",
      "epoch:4 step:4165 [D loss: 0.742174, acc.: 44.53%] [G loss: 0.684570]\n",
      "epoch:4 step:4166 [D loss: 0.719476, acc.: 45.31%] [G loss: 0.684083]\n",
      "epoch:4 step:4167 [D loss: 0.703336, acc.: 46.88%] [G loss: 0.705929]\n",
      "epoch:4 step:4168 [D loss: 0.693313, acc.: 50.00%] [G loss: 0.739369]\n",
      "epoch:4 step:4169 [D loss: 0.703914, acc.: 50.00%] [G loss: 0.745607]\n",
      "epoch:4 step:4170 [D loss: 0.687064, acc.: 51.56%] [G loss: 0.748199]\n",
      "epoch:4 step:4171 [D loss: 0.686744, acc.: 52.34%] [G loss: 0.756975]\n",
      "epoch:4 step:4172 [D loss: 0.677009, acc.: 60.16%] [G loss: 0.754113]\n",
      "epoch:4 step:4173 [D loss: 0.682928, acc.: 51.56%] [G loss: 0.753129]\n",
      "epoch:4 step:4174 [D loss: 0.671538, acc.: 62.50%] [G loss: 0.755525]\n",
      "epoch:4 step:4175 [D loss: 0.669286, acc.: 67.97%] [G loss: 0.811920]\n",
      "epoch:4 step:4176 [D loss: 0.671144, acc.: 59.38%] [G loss: 0.759365]\n",
      "epoch:4 step:4177 [D loss: 0.679062, acc.: 58.59%] [G loss: 0.772809]\n",
      "epoch:4 step:4178 [D loss: 0.685339, acc.: 52.34%] [G loss: 0.695666]\n",
      "epoch:4 step:4179 [D loss: 0.708839, acc.: 42.19%] [G loss: 0.714841]\n",
      "epoch:4 step:4180 [D loss: 0.730503, acc.: 37.50%] [G loss: 0.709579]\n",
      "epoch:4 step:4181 [D loss: 0.720898, acc.: 44.53%] [G loss: 0.719962]\n",
      "epoch:4 step:4182 [D loss: 0.701517, acc.: 46.88%] [G loss: 0.713654]\n",
      "epoch:4 step:4183 [D loss: 0.698024, acc.: 53.91%] [G loss: 0.732961]\n",
      "epoch:4 step:4184 [D loss: 0.686469, acc.: 52.34%] [G loss: 0.708043]\n",
      "epoch:4 step:4185 [D loss: 0.708019, acc.: 51.56%] [G loss: 0.753216]\n",
      "epoch:4 step:4186 [D loss: 0.699913, acc.: 48.44%] [G loss: 0.703209]\n",
      "epoch:4 step:4187 [D loss: 0.715643, acc.: 42.19%] [G loss: 0.700113]\n",
      "epoch:4 step:4188 [D loss: 0.695594, acc.: 48.44%] [G loss: 0.709421]\n",
      "epoch:4 step:4189 [D loss: 0.702341, acc.: 46.88%] [G loss: 0.708960]\n",
      "epoch:4 step:4190 [D loss: 0.683431, acc.: 56.25%] [G loss: 0.716702]\n",
      "epoch:4 step:4191 [D loss: 0.696068, acc.: 42.97%] [G loss: 0.706456]\n",
      "epoch:4 step:4192 [D loss: 0.694256, acc.: 53.12%] [G loss: 0.707414]\n",
      "epoch:4 step:4193 [D loss: 0.683128, acc.: 57.03%] [G loss: 0.725568]\n",
      "epoch:4 step:4194 [D loss: 0.687245, acc.: 53.12%] [G loss: 0.707811]\n",
      "epoch:4 step:4195 [D loss: 0.685297, acc.: 55.47%] [G loss: 0.715836]\n",
      "epoch:4 step:4196 [D loss: 0.701057, acc.: 48.44%] [G loss: 0.726893]\n",
      "epoch:4 step:4197 [D loss: 0.682830, acc.: 57.81%] [G loss: 0.730178]\n",
      "epoch:4 step:4198 [D loss: 0.688579, acc.: 57.81%] [G loss: 0.709947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4199 [D loss: 0.705208, acc.: 49.22%] [G loss: 0.728416]\n",
      "epoch:4 step:4200 [D loss: 0.683445, acc.: 55.47%] [G loss: 0.722884]\n",
      "epoch:4 step:4201 [D loss: 0.674172, acc.: 53.91%] [G loss: 0.737018]\n",
      "epoch:4 step:4202 [D loss: 0.697051, acc.: 53.91%] [G loss: 0.735553]\n",
      "epoch:4 step:4203 [D loss: 0.692310, acc.: 56.25%] [G loss: 0.728671]\n",
      "epoch:4 step:4204 [D loss: 0.590744, acc.: 60.16%] [G loss: 0.805281]\n",
      "epoch:4 step:4205 [D loss: 0.659551, acc.: 68.75%] [G loss: 0.764356]\n",
      "epoch:4 step:4206 [D loss: 0.720525, acc.: 48.44%] [G loss: 0.651628]\n",
      "epoch:4 step:4207 [D loss: 0.683981, acc.: 57.03%] [G loss: 0.739511]\n",
      "epoch:4 step:4208 [D loss: 0.698092, acc.: 50.00%] [G loss: 0.734389]\n",
      "epoch:4 step:4209 [D loss: 0.746996, acc.: 30.47%] [G loss: 0.733533]\n",
      "epoch:4 step:4210 [D loss: 0.735193, acc.: 36.72%] [G loss: 0.718370]\n",
      "epoch:4 step:4211 [D loss: 0.696482, acc.: 48.44%] [G loss: 0.680537]\n",
      "epoch:4 step:4212 [D loss: 0.697759, acc.: 47.66%] [G loss: 0.764147]\n",
      "epoch:4 step:4213 [D loss: 0.681497, acc.: 57.81%] [G loss: 0.760141]\n",
      "epoch:4 step:4214 [D loss: 0.676069, acc.: 57.81%] [G loss: 0.719641]\n",
      "epoch:4 step:4215 [D loss: 0.675583, acc.: 60.94%] [G loss: 0.797911]\n",
      "epoch:4 step:4216 [D loss: 0.658468, acc.: 63.28%] [G loss: 0.787006]\n",
      "epoch:4 step:4217 [D loss: 0.695859, acc.: 53.12%] [G loss: 0.750226]\n",
      "epoch:4 step:4218 [D loss: 0.660784, acc.: 67.19%] [G loss: 0.756398]\n",
      "epoch:4 step:4219 [D loss: 0.685009, acc.: 57.81%] [G loss: 0.773554]\n",
      "epoch:4 step:4220 [D loss: 0.701189, acc.: 55.47%] [G loss: 0.779574]\n",
      "epoch:4 step:4221 [D loss: 0.721069, acc.: 47.66%] [G loss: 0.743816]\n",
      "epoch:4 step:4222 [D loss: 0.728642, acc.: 37.50%] [G loss: 0.750228]\n",
      "epoch:4 step:4223 [D loss: 0.684663, acc.: 60.16%] [G loss: 0.759598]\n",
      "epoch:4 step:4224 [D loss: 0.675286, acc.: 57.81%] [G loss: 0.771022]\n",
      "epoch:4 step:4225 [D loss: 0.698621, acc.: 53.91%] [G loss: 0.791523]\n",
      "epoch:4 step:4226 [D loss: 0.709674, acc.: 44.53%] [G loss: 0.769994]\n",
      "epoch:4 step:4227 [D loss: 0.708847, acc.: 44.53%] [G loss: 0.721449]\n",
      "epoch:4 step:4228 [D loss: 0.711207, acc.: 46.88%] [G loss: 0.736443]\n",
      "epoch:4 step:4229 [D loss: 0.694973, acc.: 52.34%] [G loss: 0.698847]\n",
      "epoch:4 step:4230 [D loss: 0.726029, acc.: 38.28%] [G loss: 0.708178]\n",
      "epoch:4 step:4231 [D loss: 0.694044, acc.: 48.44%] [G loss: 0.713530]\n",
      "epoch:4 step:4232 [D loss: 0.711418, acc.: 35.16%] [G loss: 0.715156]\n",
      "epoch:4 step:4233 [D loss: 0.688130, acc.: 58.59%] [G loss: 0.734527]\n",
      "epoch:4 step:4234 [D loss: 0.686911, acc.: 54.69%] [G loss: 0.767032]\n",
      "epoch:4 step:4235 [D loss: 0.694019, acc.: 50.78%] [G loss: 0.729272]\n",
      "epoch:4 step:4236 [D loss: 0.683587, acc.: 57.03%] [G loss: 0.761927]\n",
      "epoch:4 step:4237 [D loss: 0.698238, acc.: 51.56%] [G loss: 0.746236]\n",
      "epoch:4 step:4238 [D loss: 0.689931, acc.: 58.59%] [G loss: 0.744227]\n",
      "epoch:4 step:4239 [D loss: 0.691690, acc.: 53.91%] [G loss: 0.717204]\n",
      "epoch:4 step:4240 [D loss: 0.685007, acc.: 57.03%] [G loss: 0.733283]\n",
      "epoch:4 step:4241 [D loss: 0.695570, acc.: 45.31%] [G loss: 0.720268]\n",
      "epoch:4 step:4242 [D loss: 0.692682, acc.: 54.69%] [G loss: 0.711713]\n",
      "epoch:4 step:4243 [D loss: 0.676557, acc.: 60.16%] [G loss: 0.723583]\n",
      "epoch:4 step:4244 [D loss: 0.671031, acc.: 61.72%] [G loss: 0.718099]\n",
      "epoch:4 step:4245 [D loss: 0.660060, acc.: 68.75%] [G loss: 0.730960]\n",
      "epoch:4 step:4246 [D loss: 0.664973, acc.: 60.94%] [G loss: 0.778000]\n",
      "epoch:4 step:4247 [D loss: 0.624886, acc.: 68.75%] [G loss: 0.715252]\n",
      "epoch:4 step:4248 [D loss: 0.711891, acc.: 44.53%] [G loss: 0.735483]\n",
      "epoch:4 step:4249 [D loss: 0.725733, acc.: 39.84%] [G loss: 0.774394]\n",
      "epoch:4 step:4250 [D loss: 0.711182, acc.: 46.09%] [G loss: 0.731678]\n",
      "epoch:4 step:4251 [D loss: 0.798708, acc.: 34.38%] [G loss: 0.744603]\n",
      "epoch:4 step:4252 [D loss: 0.711034, acc.: 46.88%] [G loss: 0.727348]\n",
      "epoch:4 step:4253 [D loss: 0.682151, acc.: 52.34%] [G loss: 0.760565]\n",
      "epoch:4 step:4254 [D loss: 0.697783, acc.: 44.53%] [G loss: 0.728499]\n",
      "epoch:4 step:4255 [D loss: 0.692449, acc.: 52.34%] [G loss: 0.731672]\n",
      "epoch:4 step:4256 [D loss: 0.675995, acc.: 62.50%] [G loss: 0.734610]\n",
      "epoch:4 step:4257 [D loss: 0.702473, acc.: 56.25%] [G loss: 0.734115]\n",
      "epoch:4 step:4258 [D loss: 0.698595, acc.: 48.44%] [G loss: 0.715594]\n",
      "epoch:4 step:4259 [D loss: 0.708031, acc.: 42.19%] [G loss: 0.739174]\n",
      "epoch:4 step:4260 [D loss: 0.700576, acc.: 46.88%] [G loss: 0.725722]\n",
      "epoch:4 step:4261 [D loss: 0.694877, acc.: 45.31%] [G loss: 0.715110]\n",
      "epoch:4 step:4262 [D loss: 0.702272, acc.: 42.97%] [G loss: 0.732666]\n",
      "epoch:4 step:4263 [D loss: 0.691232, acc.: 51.56%] [G loss: 0.709810]\n",
      "epoch:4 step:4264 [D loss: 0.687672, acc.: 57.81%] [G loss: 0.727603]\n",
      "epoch:4 step:4265 [D loss: 0.684764, acc.: 50.78%] [G loss: 0.720757]\n",
      "epoch:4 step:4266 [D loss: 0.689488, acc.: 56.25%] [G loss: 0.737213]\n",
      "epoch:4 step:4267 [D loss: 0.681967, acc.: 59.38%] [G loss: 0.724643]\n",
      "epoch:4 step:4268 [D loss: 0.667604, acc.: 62.50%] [G loss: 0.735851]\n",
      "epoch:4 step:4269 [D loss: 0.692377, acc.: 53.12%] [G loss: 0.739987]\n",
      "epoch:4 step:4270 [D loss: 0.666136, acc.: 57.81%] [G loss: 0.731339]\n",
      "epoch:4 step:4271 [D loss: 0.697532, acc.: 49.22%] [G loss: 0.751946]\n",
      "epoch:4 step:4272 [D loss: 0.688965, acc.: 42.97%] [G loss: 0.748851]\n",
      "epoch:4 step:4273 [D loss: 0.702852, acc.: 47.66%] [G loss: 0.706488]\n",
      "epoch:4 step:4274 [D loss: 0.710646, acc.: 50.78%] [G loss: 0.731104]\n",
      "epoch:4 step:4275 [D loss: 0.690016, acc.: 53.12%] [G loss: 0.707661]\n",
      "epoch:4 step:4276 [D loss: 0.709985, acc.: 44.53%] [G loss: 0.699442]\n",
      "epoch:4 step:4277 [D loss: 0.701238, acc.: 53.12%] [G loss: 0.705589]\n",
      "epoch:4 step:4278 [D loss: 0.699912, acc.: 42.97%] [G loss: 0.722269]\n",
      "epoch:4 step:4279 [D loss: 0.700916, acc.: 52.34%] [G loss: 0.706319]\n",
      "epoch:4 step:4280 [D loss: 0.683581, acc.: 53.91%] [G loss: 0.718911]\n",
      "epoch:4 step:4281 [D loss: 0.691533, acc.: 50.78%] [G loss: 0.718427]\n",
      "epoch:4 step:4282 [D loss: 0.686977, acc.: 53.91%] [G loss: 0.711031]\n",
      "epoch:4 step:4283 [D loss: 0.690021, acc.: 53.91%] [G loss: 0.735497]\n",
      "epoch:4 step:4284 [D loss: 0.702084, acc.: 45.31%] [G loss: 0.738118]\n",
      "epoch:4 step:4285 [D loss: 0.694234, acc.: 52.34%] [G loss: 0.714591]\n",
      "epoch:4 step:4286 [D loss: 0.694612, acc.: 51.56%] [G loss: 0.729586]\n",
      "epoch:4 step:4287 [D loss: 0.686121, acc.: 54.69%] [G loss: 0.744616]\n",
      "epoch:4 step:4288 [D loss: 0.697245, acc.: 49.22%] [G loss: 0.719733]\n",
      "epoch:4 step:4289 [D loss: 0.695838, acc.: 52.34%] [G loss: 0.716274]\n",
      "epoch:4 step:4290 [D loss: 0.715181, acc.: 40.62%] [G loss: 0.732767]\n",
      "epoch:4 step:4291 [D loss: 0.604755, acc.: 61.72%] [G loss: 0.711564]\n",
      "epoch:4 step:4292 [D loss: 0.691567, acc.: 56.25%] [G loss: 0.728487]\n",
      "epoch:4 step:4293 [D loss: 0.697146, acc.: 54.69%] [G loss: 0.714631]\n",
      "epoch:4 step:4294 [D loss: 0.687070, acc.: 57.81%] [G loss: 0.722351]\n",
      "epoch:4 step:4295 [D loss: 0.707032, acc.: 43.75%] [G loss: 0.709421]\n",
      "epoch:4 step:4296 [D loss: 0.689212, acc.: 57.03%] [G loss: 0.697609]\n",
      "epoch:4 step:4297 [D loss: 0.682233, acc.: 58.59%] [G loss: 0.693522]\n",
      "epoch:4 step:4298 [D loss: 0.532835, acc.: 73.44%] [G loss: 0.680014]\n",
      "epoch:4 step:4299 [D loss: 0.715042, acc.: 50.00%] [G loss: 0.666130]\n",
      "epoch:4 step:4300 [D loss: 0.657518, acc.: 63.28%] [G loss: 0.674266]\n",
      "epoch:4 step:4301 [D loss: 0.700068, acc.: 47.66%] [G loss: 0.611304]\n",
      "epoch:4 step:4302 [D loss: 0.637093, acc.: 74.22%] [G loss: 0.711890]\n",
      "epoch:4 step:4303 [D loss: 0.662839, acc.: 59.38%] [G loss: 0.594609]\n",
      "epoch:4 step:4304 [D loss: 0.687376, acc.: 50.78%] [G loss: 0.742626]\n",
      "epoch:4 step:4305 [D loss: 0.713788, acc.: 49.22%] [G loss: 0.788539]\n",
      "epoch:4 step:4306 [D loss: 0.700850, acc.: 53.91%] [G loss: 0.750224]\n",
      "epoch:4 step:4307 [D loss: 0.734720, acc.: 35.94%] [G loss: 0.728372]\n",
      "epoch:4 step:4308 [D loss: 0.710659, acc.: 40.62%] [G loss: 0.773046]\n",
      "epoch:4 step:4309 [D loss: 0.735831, acc.: 32.03%] [G loss: 0.795708]\n",
      "epoch:4 step:4310 [D loss: 0.709328, acc.: 40.62%] [G loss: 0.775787]\n",
      "epoch:4 step:4311 [D loss: 0.698643, acc.: 55.47%] [G loss: 0.785222]\n",
      "epoch:4 step:4312 [D loss: 0.705133, acc.: 52.34%] [G loss: 0.757816]\n",
      "epoch:4 step:4313 [D loss: 0.678087, acc.: 57.03%] [G loss: 0.770583]\n",
      "epoch:4 step:4314 [D loss: 0.692972, acc.: 46.88%] [G loss: 0.803109]\n",
      "epoch:4 step:4315 [D loss: 0.678518, acc.: 57.81%] [G loss: 0.811044]\n",
      "epoch:4 step:4316 [D loss: 0.686895, acc.: 57.03%] [G loss: 0.777507]\n",
      "epoch:4 step:4317 [D loss: 0.716467, acc.: 47.66%] [G loss: 0.774532]\n",
      "epoch:4 step:4318 [D loss: 0.656793, acc.: 61.72%] [G loss: 0.848826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4319 [D loss: 0.692342, acc.: 52.34%] [G loss: 0.977807]\n",
      "epoch:4 step:4320 [D loss: 0.716273, acc.: 42.19%] [G loss: 0.712767]\n",
      "epoch:4 step:4321 [D loss: 0.696591, acc.: 50.78%] [G loss: 0.738443]\n",
      "epoch:4 step:4322 [D loss: 0.694618, acc.: 50.78%] [G loss: 0.745224]\n",
      "epoch:4 step:4323 [D loss: 0.699639, acc.: 50.78%] [G loss: 0.688941]\n",
      "epoch:4 step:4324 [D loss: 0.696591, acc.: 50.00%] [G loss: 0.705809]\n",
      "epoch:4 step:4325 [D loss: 0.693691, acc.: 57.03%] [G loss: 0.710360]\n",
      "epoch:4 step:4326 [D loss: 0.677230, acc.: 62.50%] [G loss: 0.728056]\n",
      "epoch:4 step:4327 [D loss: 0.691656, acc.: 50.78%] [G loss: 0.715338]\n",
      "epoch:4 step:4328 [D loss: 0.702067, acc.: 46.88%] [G loss: 0.720503]\n",
      "epoch:4 step:4329 [D loss: 0.687296, acc.: 57.03%] [G loss: 0.726528]\n",
      "epoch:4 step:4330 [D loss: 0.691723, acc.: 51.56%] [G loss: 0.718446]\n",
      "epoch:4 step:4331 [D loss: 0.697524, acc.: 46.88%] [G loss: 0.738330]\n",
      "epoch:4 step:4332 [D loss: 0.706018, acc.: 45.31%] [G loss: 0.723328]\n",
      "epoch:4 step:4333 [D loss: 0.679077, acc.: 58.59%] [G loss: 0.712955]\n",
      "epoch:4 step:4334 [D loss: 0.695942, acc.: 52.34%] [G loss: 0.710647]\n",
      "epoch:4 step:4335 [D loss: 0.698957, acc.: 48.44%] [G loss: 0.706848]\n",
      "epoch:4 step:4336 [D loss: 0.689587, acc.: 50.78%] [G loss: 0.703060]\n",
      "epoch:4 step:4337 [D loss: 0.715491, acc.: 35.94%] [G loss: 0.698969]\n",
      "epoch:4 step:4338 [D loss: 0.718111, acc.: 46.88%] [G loss: 0.697322]\n",
      "epoch:4 step:4339 [D loss: 0.696728, acc.: 44.53%] [G loss: 0.717857]\n",
      "epoch:4 step:4340 [D loss: 0.687470, acc.: 54.69%] [G loss: 0.717857]\n",
      "epoch:4 step:4341 [D loss: 0.695975, acc.: 51.56%] [G loss: 0.715771]\n",
      "epoch:4 step:4342 [D loss: 0.701241, acc.: 45.31%] [G loss: 0.718701]\n",
      "epoch:4 step:4343 [D loss: 0.691871, acc.: 43.75%] [G loss: 0.714291]\n",
      "epoch:4 step:4344 [D loss: 0.668029, acc.: 57.81%] [G loss: 0.698133]\n",
      "epoch:4 step:4345 [D loss: 0.694380, acc.: 53.12%] [G loss: 0.699063]\n",
      "epoch:4 step:4346 [D loss: 0.676939, acc.: 58.59%] [G loss: 0.714345]\n",
      "epoch:4 step:4347 [D loss: 0.691571, acc.: 59.38%] [G loss: 0.748671]\n",
      "epoch:4 step:4348 [D loss: 0.693640, acc.: 54.69%] [G loss: 0.681064]\n",
      "epoch:4 step:4349 [D loss: 0.705750, acc.: 47.66%] [G loss: 0.727461]\n",
      "epoch:4 step:4350 [D loss: 0.695075, acc.: 47.66%] [G loss: 0.733238]\n",
      "epoch:4 step:4351 [D loss: 0.698002, acc.: 52.34%] [G loss: 0.730087]\n",
      "epoch:4 step:4352 [D loss: 0.665686, acc.: 47.66%] [G loss: 0.739117]\n",
      "epoch:4 step:4353 [D loss: 0.688526, acc.: 57.81%] [G loss: 0.750000]\n",
      "epoch:4 step:4354 [D loss: 0.686021, acc.: 54.69%] [G loss: 0.661736]\n",
      "epoch:4 step:4355 [D loss: 0.696593, acc.: 46.88%] [G loss: 0.741994]\n",
      "epoch:4 step:4356 [D loss: 0.706056, acc.: 39.84%] [G loss: 0.721120]\n",
      "epoch:4 step:4357 [D loss: 0.721118, acc.: 43.75%] [G loss: 0.712587]\n",
      "epoch:4 step:4358 [D loss: 0.702842, acc.: 49.22%] [G loss: 0.739473]\n",
      "epoch:4 step:4359 [D loss: 0.703102, acc.: 41.41%] [G loss: 0.735956]\n",
      "epoch:4 step:4360 [D loss: 0.698328, acc.: 48.44%] [G loss: 0.720295]\n",
      "epoch:4 step:4361 [D loss: 0.681868, acc.: 60.16%] [G loss: 0.717748]\n",
      "epoch:4 step:4362 [D loss: 0.690850, acc.: 56.25%] [G loss: 0.744666]\n",
      "epoch:4 step:4363 [D loss: 0.734465, acc.: 39.84%] [G loss: 0.740557]\n",
      "epoch:4 step:4364 [D loss: 0.684161, acc.: 54.69%] [G loss: 0.737416]\n",
      "epoch:4 step:4365 [D loss: 0.699109, acc.: 50.78%] [G loss: 0.725217]\n",
      "epoch:4 step:4366 [D loss: 0.694337, acc.: 51.56%] [G loss: 0.708474]\n",
      "epoch:4 step:4367 [D loss: 0.684391, acc.: 53.91%] [G loss: 0.712781]\n",
      "epoch:4 step:4368 [D loss: 0.690337, acc.: 53.12%] [G loss: 0.723436]\n",
      "epoch:4 step:4369 [D loss: 0.702213, acc.: 44.53%] [G loss: 0.740787]\n",
      "epoch:4 step:4370 [D loss: 0.703463, acc.: 44.53%] [G loss: 0.720103]\n",
      "epoch:4 step:4371 [D loss: 0.699761, acc.: 42.97%] [G loss: 0.721001]\n",
      "epoch:4 step:4372 [D loss: 0.699933, acc.: 49.22%] [G loss: 0.756310]\n",
      "epoch:4 step:4373 [D loss: 0.693704, acc.: 53.91%] [G loss: 0.712661]\n",
      "epoch:4 step:4374 [D loss: 0.718534, acc.: 43.75%] [G loss: 0.706542]\n",
      "epoch:4 step:4375 [D loss: 0.696681, acc.: 49.22%] [G loss: 0.731178]\n",
      "epoch:4 step:4376 [D loss: 0.693154, acc.: 53.12%] [G loss: 0.723007]\n",
      "epoch:4 step:4377 [D loss: 0.697014, acc.: 55.47%] [G loss: 0.715852]\n",
      "epoch:4 step:4378 [D loss: 0.693808, acc.: 49.22%] [G loss: 0.719623]\n",
      "epoch:4 step:4379 [D loss: 0.694897, acc.: 54.69%] [G loss: 0.711888]\n",
      "epoch:4 step:4380 [D loss: 0.697595, acc.: 46.09%] [G loss: 0.733653]\n",
      "epoch:4 step:4381 [D loss: 0.694373, acc.: 48.44%] [G loss: 0.738963]\n",
      "epoch:4 step:4382 [D loss: 0.701116, acc.: 50.78%] [G loss: 0.745276]\n",
      "epoch:4 step:4383 [D loss: 0.695542, acc.: 46.88%] [G loss: 0.706637]\n",
      "epoch:4 step:4384 [D loss: 0.694847, acc.: 50.00%] [G loss: 0.732344]\n",
      "epoch:4 step:4385 [D loss: 0.687141, acc.: 57.81%] [G loss: 0.726645]\n",
      "epoch:4 step:4386 [D loss: 0.687504, acc.: 59.38%] [G loss: 0.730418]\n",
      "epoch:4 step:4387 [D loss: 0.696148, acc.: 51.56%] [G loss: 0.723649]\n",
      "epoch:4 step:4388 [D loss: 0.701716, acc.: 42.97%] [G loss: 0.741790]\n",
      "epoch:4 step:4389 [D loss: 0.690303, acc.: 53.91%] [G loss: 0.729936]\n",
      "epoch:4 step:4390 [D loss: 0.682085, acc.: 52.34%] [G loss: 0.744092]\n",
      "epoch:4 step:4391 [D loss: 0.694374, acc.: 47.66%] [G loss: 0.719271]\n",
      "epoch:4 step:4392 [D loss: 0.690610, acc.: 56.25%] [G loss: 0.736125]\n",
      "epoch:4 step:4393 [D loss: 0.702776, acc.: 50.78%] [G loss: 0.707763]\n",
      "epoch:4 step:4394 [D loss: 0.681731, acc.: 59.38%] [G loss: 0.721765]\n",
      "epoch:4 step:4395 [D loss: 0.692326, acc.: 51.56%] [G loss: 0.717264]\n",
      "epoch:4 step:4396 [D loss: 0.678796, acc.: 57.03%] [G loss: 0.746772]\n",
      "epoch:4 step:4397 [D loss: 0.687992, acc.: 45.31%] [G loss: 0.743092]\n",
      "epoch:4 step:4398 [D loss: 0.671690, acc.: 59.38%] [G loss: 0.745767]\n",
      "epoch:4 step:4399 [D loss: 0.687749, acc.: 60.16%] [G loss: 0.752604]\n",
      "epoch:4 step:4400 [D loss: 0.686610, acc.: 57.03%] [G loss: 0.736500]\n",
      "epoch:4 step:4401 [D loss: 0.709807, acc.: 45.31%] [G loss: 0.737536]\n",
      "epoch:4 step:4402 [D loss: 0.704847, acc.: 46.88%] [G loss: 0.728410]\n",
      "epoch:4 step:4403 [D loss: 0.699810, acc.: 46.09%] [G loss: 0.707337]\n",
      "epoch:4 step:4404 [D loss: 0.700053, acc.: 48.44%] [G loss: 0.722651]\n",
      "epoch:4 step:4405 [D loss: 0.698977, acc.: 46.09%] [G loss: 0.708935]\n",
      "epoch:4 step:4406 [D loss: 0.703978, acc.: 48.44%] [G loss: 0.723230]\n",
      "epoch:4 step:4407 [D loss: 0.670813, acc.: 57.81%] [G loss: 0.735897]\n",
      "epoch:4 step:4408 [D loss: 0.688632, acc.: 52.34%] [G loss: 0.729097]\n",
      "epoch:4 step:4409 [D loss: 0.678883, acc.: 57.03%] [G loss: 0.727660]\n",
      "epoch:4 step:4410 [D loss: 0.693358, acc.: 50.78%] [G loss: 0.729295]\n",
      "epoch:4 step:4411 [D loss: 0.713339, acc.: 38.28%] [G loss: 0.727166]\n",
      "epoch:4 step:4412 [D loss: 0.695515, acc.: 57.03%] [G loss: 0.713865]\n",
      "epoch:4 step:4413 [D loss: 0.703606, acc.: 46.88%] [G loss: 0.737833]\n",
      "epoch:4 step:4414 [D loss: 0.682261, acc.: 59.38%] [G loss: 0.721977]\n",
      "epoch:4 step:4415 [D loss: 0.685246, acc.: 56.25%] [G loss: 0.736655]\n",
      "epoch:4 step:4416 [D loss: 0.696467, acc.: 54.69%] [G loss: 0.718517]\n",
      "epoch:4 step:4417 [D loss: 0.698948, acc.: 48.44%] [G loss: 0.727849]\n",
      "epoch:4 step:4418 [D loss: 0.712980, acc.: 42.97%] [G loss: 0.725296]\n",
      "epoch:4 step:4419 [D loss: 0.706716, acc.: 46.09%] [G loss: 0.702087]\n",
      "epoch:4 step:4420 [D loss: 0.713211, acc.: 42.19%] [G loss: 0.696815]\n",
      "epoch:4 step:4421 [D loss: 0.706211, acc.: 47.66%] [G loss: 0.703681]\n",
      "epoch:4 step:4422 [D loss: 0.691896, acc.: 54.69%] [G loss: 0.694041]\n",
      "epoch:4 step:4423 [D loss: 0.697398, acc.: 51.56%] [G loss: 0.705387]\n",
      "epoch:4 step:4424 [D loss: 0.693179, acc.: 52.34%] [G loss: 0.699245]\n",
      "epoch:4 step:4425 [D loss: 0.682188, acc.: 64.06%] [G loss: 0.712423]\n",
      "epoch:4 step:4426 [D loss: 0.690599, acc.: 52.34%] [G loss: 0.724035]\n",
      "epoch:4 step:4427 [D loss: 0.694813, acc.: 50.00%] [G loss: 0.661384]\n",
      "epoch:4 step:4428 [D loss: 0.708641, acc.: 46.88%] [G loss: 0.717556]\n",
      "epoch:4 step:4429 [D loss: 0.674813, acc.: 59.38%] [G loss: 0.729855]\n",
      "epoch:4 step:4430 [D loss: 0.685967, acc.: 57.03%] [G loss: 0.778195]\n",
      "epoch:4 step:4431 [D loss: 0.671211, acc.: 56.25%] [G loss: 0.718165]\n",
      "epoch:4 step:4432 [D loss: 0.673739, acc.: 64.84%] [G loss: 0.809557]\n",
      "epoch:4 step:4433 [D loss: 0.690355, acc.: 53.91%] [G loss: 0.974923]\n",
      "epoch:4 step:4434 [D loss: 0.710396, acc.: 40.62%] [G loss: 0.746371]\n",
      "epoch:4 step:4435 [D loss: 0.720328, acc.: 40.62%] [G loss: 0.672283]\n",
      "epoch:4 step:4436 [D loss: 0.715737, acc.: 39.06%] [G loss: 0.718592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4437 [D loss: 0.729567, acc.: 40.62%] [G loss: 0.694592]\n",
      "epoch:4 step:4438 [D loss: 0.716394, acc.: 42.97%] [G loss: 0.681829]\n",
      "epoch:4 step:4439 [D loss: 0.704233, acc.: 44.53%] [G loss: 0.708627]\n",
      "epoch:4 step:4440 [D loss: 0.711005, acc.: 41.41%] [G loss: 0.701953]\n",
      "epoch:4 step:4441 [D loss: 0.702157, acc.: 43.75%] [G loss: 0.704518]\n",
      "epoch:4 step:4442 [D loss: 0.692841, acc.: 50.00%] [G loss: 0.721323]\n",
      "epoch:4 step:4443 [D loss: 0.693568, acc.: 46.88%] [G loss: 0.714951]\n",
      "epoch:4 step:4444 [D loss: 0.700135, acc.: 43.75%] [G loss: 0.714519]\n",
      "epoch:4 step:4445 [D loss: 0.691257, acc.: 46.88%] [G loss: 0.707440]\n",
      "epoch:4 step:4446 [D loss: 0.688567, acc.: 57.03%] [G loss: 0.716798]\n",
      "epoch:4 step:4447 [D loss: 0.686094, acc.: 55.47%] [G loss: 0.727587]\n",
      "epoch:4 step:4448 [D loss: 0.685563, acc.: 52.34%] [G loss: 0.746522]\n",
      "epoch:4 step:4449 [D loss: 0.688611, acc.: 57.81%] [G loss: 0.722187]\n",
      "epoch:4 step:4450 [D loss: 0.686762, acc.: 55.47%] [G loss: 0.727367]\n",
      "epoch:4 step:4451 [D loss: 0.677515, acc.: 58.59%] [G loss: 0.744138]\n",
      "epoch:4 step:4452 [D loss: 0.675267, acc.: 58.59%] [G loss: 0.729063]\n",
      "epoch:4 step:4453 [D loss: 0.681629, acc.: 61.72%] [G loss: 0.743285]\n",
      "epoch:4 step:4454 [D loss: 0.682460, acc.: 58.59%] [G loss: 0.726670]\n",
      "epoch:4 step:4455 [D loss: 0.677038, acc.: 58.59%] [G loss: 0.644427]\n",
      "epoch:4 step:4456 [D loss: 0.695784, acc.: 53.91%] [G loss: 0.733737]\n",
      "epoch:4 step:4457 [D loss: 0.681310, acc.: 57.03%] [G loss: 0.714178]\n",
      "epoch:4 step:4458 [D loss: 0.726128, acc.: 42.19%] [G loss: 0.741910]\n",
      "epoch:4 step:4459 [D loss: 0.699900, acc.: 46.09%] [G loss: 0.729317]\n",
      "epoch:4 step:4460 [D loss: 0.697334, acc.: 50.00%] [G loss: 0.728273]\n",
      "epoch:4 step:4461 [D loss: 0.695616, acc.: 51.56%] [G loss: 0.722994]\n",
      "epoch:4 step:4462 [D loss: 0.691816, acc.: 56.25%] [G loss: 0.735430]\n",
      "epoch:4 step:4463 [D loss: 0.708571, acc.: 46.09%] [G loss: 0.715318]\n",
      "epoch:4 step:4464 [D loss: 0.694558, acc.: 54.69%] [G loss: 0.735301]\n",
      "epoch:4 step:4465 [D loss: 0.681034, acc.: 55.47%] [G loss: 0.735634]\n",
      "epoch:4 step:4466 [D loss: 0.674229, acc.: 60.16%] [G loss: 0.724050]\n",
      "epoch:4 step:4467 [D loss: 0.684935, acc.: 55.47%] [G loss: 0.741733]\n",
      "epoch:4 step:4468 [D loss: 0.661886, acc.: 61.72%] [G loss: 0.738619]\n",
      "epoch:4 step:4469 [D loss: 0.662452, acc.: 66.41%] [G loss: 0.785360]\n",
      "epoch:4 step:4470 [D loss: 0.697654, acc.: 51.56%] [G loss: 0.737956]\n",
      "epoch:4 step:4471 [D loss: 0.700873, acc.: 50.78%] [G loss: 0.694699]\n",
      "epoch:4 step:4472 [D loss: 0.672206, acc.: 64.06%] [G loss: 0.766190]\n",
      "epoch:4 step:4473 [D loss: 0.695077, acc.: 47.66%] [G loss: 0.775672]\n",
      "epoch:4 step:4474 [D loss: 0.685175, acc.: 53.12%] [G loss: 0.751107]\n",
      "epoch:4 step:4475 [D loss: 0.748926, acc.: 32.03%] [G loss: 0.707891]\n",
      "epoch:4 step:4476 [D loss: 0.710669, acc.: 40.62%] [G loss: 0.688886]\n",
      "epoch:4 step:4477 [D loss: 0.703879, acc.: 52.34%] [G loss: 0.667048]\n",
      "epoch:4 step:4478 [D loss: 0.707841, acc.: 42.19%] [G loss: 0.743087]\n",
      "epoch:4 step:4479 [D loss: 0.698337, acc.: 42.97%] [G loss: 0.743972]\n",
      "epoch:4 step:4480 [D loss: 0.702621, acc.: 42.97%] [G loss: 0.715039]\n",
      "epoch:4 step:4481 [D loss: 0.685942, acc.: 57.03%] [G loss: 0.740681]\n",
      "epoch:4 step:4482 [D loss: 0.691859, acc.: 49.22%] [G loss: 0.744667]\n",
      "epoch:4 step:4483 [D loss: 0.697282, acc.: 54.69%] [G loss: 0.733948]\n",
      "epoch:4 step:4484 [D loss: 0.691426, acc.: 57.81%] [G loss: 0.738868]\n",
      "epoch:4 step:4485 [D loss: 0.688901, acc.: 55.47%] [G loss: 0.736271]\n",
      "epoch:4 step:4486 [D loss: 0.696582, acc.: 45.31%] [G loss: 0.737547]\n",
      "epoch:4 step:4487 [D loss: 0.692981, acc.: 53.91%] [G loss: 0.711634]\n",
      "epoch:4 step:4488 [D loss: 0.696462, acc.: 46.88%] [G loss: 0.718167]\n",
      "epoch:4 step:4489 [D loss: 0.697158, acc.: 50.00%] [G loss: 0.727239]\n",
      "epoch:4 step:4490 [D loss: 0.705512, acc.: 47.66%] [G loss: 0.737509]\n",
      "epoch:4 step:4491 [D loss: 0.687265, acc.: 57.03%] [G loss: 0.720288]\n",
      "epoch:4 step:4492 [D loss: 0.695251, acc.: 53.91%] [G loss: 0.709881]\n",
      "epoch:4 step:4493 [D loss: 0.689744, acc.: 51.56%] [G loss: 0.707947]\n",
      "epoch:4 step:4494 [D loss: 0.692489, acc.: 48.44%] [G loss: 0.734926]\n",
      "epoch:4 step:4495 [D loss: 0.681464, acc.: 58.59%] [G loss: 0.701583]\n",
      "epoch:4 step:4496 [D loss: 0.702864, acc.: 42.97%] [G loss: 0.719516]\n",
      "epoch:4 step:4497 [D loss: 0.707986, acc.: 50.78%] [G loss: 0.715497]\n",
      "epoch:4 step:4498 [D loss: 0.719798, acc.: 36.72%] [G loss: 0.677973]\n",
      "epoch:4 step:4499 [D loss: 0.701643, acc.: 45.31%] [G loss: 0.692840]\n",
      "epoch:4 step:4500 [D loss: 0.700055, acc.: 42.19%] [G loss: 0.680871]\n",
      "epoch:4 step:4501 [D loss: 0.695520, acc.: 49.22%] [G loss: 0.693736]\n",
      "epoch:4 step:4502 [D loss: 0.702096, acc.: 41.41%] [G loss: 0.693033]\n",
      "epoch:4 step:4503 [D loss: 0.694200, acc.: 55.47%] [G loss: 0.702315]\n",
      "epoch:4 step:4504 [D loss: 0.689445, acc.: 54.69%] [G loss: 0.701872]\n",
      "epoch:4 step:4505 [D loss: 0.680438, acc.: 57.03%] [G loss: 0.699288]\n",
      "epoch:4 step:4506 [D loss: 0.695620, acc.: 50.78%] [G loss: 0.719318]\n",
      "epoch:4 step:4507 [D loss: 0.697342, acc.: 50.00%] [G loss: 0.729092]\n",
      "epoch:4 step:4508 [D loss: 0.690104, acc.: 56.25%] [G loss: 0.714907]\n",
      "epoch:4 step:4509 [D loss: 0.679845, acc.: 58.59%] [G loss: 0.741207]\n",
      "epoch:4 step:4510 [D loss: 0.680376, acc.: 54.69%] [G loss: 0.733140]\n",
      "epoch:4 step:4511 [D loss: 0.681663, acc.: 54.69%] [G loss: 0.749395]\n",
      "epoch:4 step:4512 [D loss: 0.680664, acc.: 58.59%] [G loss: 0.741117]\n",
      "epoch:4 step:4513 [D loss: 0.693322, acc.: 57.81%] [G loss: 0.735443]\n",
      "epoch:4 step:4514 [D loss: 0.682626, acc.: 53.91%] [G loss: 0.737109]\n",
      "epoch:4 step:4515 [D loss: 0.677268, acc.: 58.59%] [G loss: 0.753300]\n",
      "epoch:4 step:4516 [D loss: 0.687560, acc.: 50.78%] [G loss: 0.729309]\n",
      "epoch:4 step:4517 [D loss: 0.700436, acc.: 48.44%] [G loss: 0.730850]\n",
      "epoch:4 step:4518 [D loss: 0.691036, acc.: 52.34%] [G loss: 0.740570]\n",
      "epoch:4 step:4519 [D loss: 0.704542, acc.: 43.75%] [G loss: 0.698747]\n",
      "epoch:4 step:4520 [D loss: 0.719562, acc.: 41.41%] [G loss: 0.691976]\n",
      "epoch:4 step:4521 [D loss: 0.698458, acc.: 42.97%] [G loss: 0.698671]\n",
      "epoch:4 step:4522 [D loss: 0.707214, acc.: 41.41%] [G loss: 0.706746]\n",
      "epoch:4 step:4523 [D loss: 0.697205, acc.: 53.12%] [G loss: 0.703454]\n",
      "epoch:4 step:4524 [D loss: 0.702921, acc.: 42.19%] [G loss: 0.702670]\n",
      "epoch:4 step:4525 [D loss: 0.700932, acc.: 46.09%] [G loss: 0.716439]\n",
      "epoch:4 step:4526 [D loss: 0.702401, acc.: 45.31%] [G loss: 0.740552]\n",
      "epoch:4 step:4527 [D loss: 0.691575, acc.: 53.12%] [G loss: 0.730139]\n",
      "epoch:4 step:4528 [D loss: 0.691305, acc.: 52.34%] [G loss: 0.761695]\n",
      "epoch:4 step:4529 [D loss: 0.690293, acc.: 50.78%] [G loss: 0.736998]\n",
      "epoch:4 step:4530 [D loss: 0.651688, acc.: 69.53%] [G loss: 0.787323]\n",
      "epoch:4 step:4531 [D loss: 0.682095, acc.: 57.81%] [G loss: 0.797146]\n",
      "epoch:4 step:4532 [D loss: 0.674823, acc.: 54.69%] [G loss: 0.783532]\n",
      "epoch:4 step:4533 [D loss: 0.679748, acc.: 59.38%] [G loss: 0.756414]\n",
      "epoch:4 step:4534 [D loss: 0.655038, acc.: 64.84%] [G loss: 0.800467]\n",
      "epoch:4 step:4535 [D loss: 0.716047, acc.: 43.75%] [G loss: 0.755423]\n",
      "epoch:4 step:4536 [D loss: 0.722743, acc.: 46.09%] [G loss: 0.753404]\n",
      "epoch:4 step:4537 [D loss: 0.717986, acc.: 39.84%] [G loss: 0.717128]\n",
      "epoch:4 step:4538 [D loss: 0.699837, acc.: 48.44%] [G loss: 0.737407]\n",
      "epoch:4 step:4539 [D loss: 0.700394, acc.: 48.44%] [G loss: 0.712764]\n",
      "epoch:4 step:4540 [D loss: 0.688948, acc.: 52.34%] [G loss: 0.730491]\n",
      "epoch:4 step:4541 [D loss: 0.683570, acc.: 60.16%] [G loss: 0.716126]\n",
      "epoch:4 step:4542 [D loss: 0.691095, acc.: 53.12%] [G loss: 0.704091]\n",
      "epoch:4 step:4543 [D loss: 0.699283, acc.: 45.31%] [G loss: 0.675890]\n",
      "epoch:4 step:4544 [D loss: 0.689797, acc.: 51.56%] [G loss: 0.713038]\n",
      "epoch:4 step:4545 [D loss: 0.694781, acc.: 51.56%] [G loss: 0.701260]\n",
      "epoch:4 step:4546 [D loss: 0.701072, acc.: 47.66%] [G loss: 0.692321]\n",
      "epoch:4 step:4547 [D loss: 0.679041, acc.: 56.25%] [G loss: 0.708189]\n",
      "epoch:4 step:4548 [D loss: 0.696729, acc.: 50.00%] [G loss: 0.701327]\n",
      "epoch:4 step:4549 [D loss: 0.694275, acc.: 53.12%] [G loss: 0.737194]\n",
      "epoch:4 step:4550 [D loss: 0.536868, acc.: 62.50%] [G loss: 0.731620]\n",
      "epoch:4 step:4551 [D loss: 0.692600, acc.: 60.16%] [G loss: 0.705009]\n",
      "epoch:4 step:4552 [D loss: 0.702418, acc.: 56.25%] [G loss: 0.727288]\n",
      "epoch:4 step:4553 [D loss: 0.691427, acc.: 57.81%] [G loss: 0.713405]\n",
      "epoch:4 step:4554 [D loss: 0.693113, acc.: 51.56%] [G loss: 0.693692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4555 [D loss: 0.690325, acc.: 56.25%] [G loss: 0.721453]\n",
      "epoch:4 step:4556 [D loss: 0.687000, acc.: 53.91%] [G loss: 0.698291]\n",
      "epoch:4 step:4557 [D loss: 0.699318, acc.: 44.53%] [G loss: 0.725947]\n",
      "epoch:4 step:4558 [D loss: 0.682522, acc.: 51.56%] [G loss: 0.770059]\n",
      "epoch:4 step:4559 [D loss: 0.703248, acc.: 47.66%] [G loss: 0.732717]\n",
      "epoch:4 step:4560 [D loss: 0.739866, acc.: 32.03%] [G loss: 0.744958]\n",
      "epoch:4 step:4561 [D loss: 0.696751, acc.: 57.03%] [G loss: 0.769798]\n",
      "epoch:4 step:4562 [D loss: 0.702257, acc.: 51.56%] [G loss: 0.761900]\n",
      "epoch:4 step:4563 [D loss: 0.697053, acc.: 49.22%] [G loss: 0.744765]\n",
      "epoch:4 step:4564 [D loss: 0.680936, acc.: 59.38%] [G loss: 0.754961]\n",
      "epoch:4 step:4565 [D loss: 0.704807, acc.: 41.41%] [G loss: 0.740409]\n",
      "epoch:4 step:4566 [D loss: 0.708211, acc.: 50.78%] [G loss: 0.746517]\n",
      "epoch:4 step:4567 [D loss: 0.704149, acc.: 53.91%] [G loss: 0.731778]\n",
      "epoch:4 step:4568 [D loss: 0.694760, acc.: 46.09%] [G loss: 0.741448]\n",
      "epoch:4 step:4569 [D loss: 0.705625, acc.: 41.41%] [G loss: 0.692665]\n",
      "epoch:4 step:4570 [D loss: 0.696441, acc.: 55.47%] [G loss: 0.698218]\n",
      "epoch:4 step:4571 [D loss: 0.689506, acc.: 53.12%] [G loss: 0.746076]\n",
      "epoch:4 step:4572 [D loss: 0.692055, acc.: 55.47%] [G loss: 0.716807]\n",
      "epoch:4 step:4573 [D loss: 0.686554, acc.: 52.34%] [G loss: 0.705880]\n",
      "epoch:4 step:4574 [D loss: 0.672068, acc.: 62.50%] [G loss: 0.684396]\n",
      "epoch:4 step:4575 [D loss: 0.687855, acc.: 57.03%] [G loss: 0.729227]\n",
      "epoch:4 step:4576 [D loss: 0.700111, acc.: 46.09%] [G loss: 0.696150]\n",
      "epoch:4 step:4577 [D loss: 0.676460, acc.: 60.16%] [G loss: 0.707936]\n",
      "epoch:4 step:4578 [D loss: 0.681956, acc.: 56.25%] [G loss: 0.726893]\n",
      "epoch:4 step:4579 [D loss: 0.698959, acc.: 49.22%] [G loss: 0.683724]\n",
      "epoch:4 step:4580 [D loss: 0.701243, acc.: 53.12%] [G loss: 0.738041]\n",
      "epoch:4 step:4581 [D loss: 0.688087, acc.: 50.78%] [G loss: 0.730068]\n",
      "epoch:4 step:4582 [D loss: 0.716854, acc.: 42.19%] [G loss: 0.713357]\n",
      "epoch:4 step:4583 [D loss: 0.717532, acc.: 42.19%] [G loss: 0.716703]\n",
      "epoch:4 step:4584 [D loss: 0.695844, acc.: 53.12%] [G loss: 0.714217]\n",
      "epoch:4 step:4585 [D loss: 0.676702, acc.: 60.94%] [G loss: 0.736742]\n",
      "epoch:4 step:4586 [D loss: 0.692035, acc.: 55.47%] [G loss: 0.734739]\n",
      "epoch:4 step:4587 [D loss: 0.678095, acc.: 58.59%] [G loss: 0.746438]\n",
      "epoch:4 step:4588 [D loss: 0.686238, acc.: 56.25%] [G loss: 0.727699]\n",
      "epoch:4 step:4589 [D loss: 0.675998, acc.: 61.72%] [G loss: 0.744908]\n",
      "epoch:4 step:4590 [D loss: 0.686297, acc.: 50.00%] [G loss: 0.697680]\n",
      "epoch:4 step:4591 [D loss: 0.707950, acc.: 49.22%] [G loss: 0.723976]\n",
      "epoch:4 step:4592 [D loss: 0.710050, acc.: 48.44%] [G loss: 0.709770]\n",
      "epoch:4 step:4593 [D loss: 0.685856, acc.: 50.78%] [G loss: 0.583900]\n",
      "epoch:4 step:4594 [D loss: 0.722085, acc.: 42.97%] [G loss: 0.710477]\n",
      "epoch:4 step:4595 [D loss: 0.740475, acc.: 32.81%] [G loss: 0.706186]\n",
      "epoch:4 step:4596 [D loss: 0.721237, acc.: 39.06%] [G loss: 0.740436]\n",
      "epoch:4 step:4597 [D loss: 0.685551, acc.: 53.12%] [G loss: 0.724518]\n",
      "epoch:4 step:4598 [D loss: 0.694040, acc.: 47.66%] [G loss: 0.761081]\n",
      "epoch:4 step:4599 [D loss: 0.671482, acc.: 57.81%] [G loss: 0.776264]\n",
      "epoch:4 step:4600 [D loss: 0.676043, acc.: 50.00%] [G loss: 0.775457]\n",
      "epoch:4 step:4601 [D loss: 0.680933, acc.: 60.94%] [G loss: 0.754951]\n",
      "epoch:4 step:4602 [D loss: 0.625028, acc.: 68.75%] [G loss: 0.803445]\n",
      "epoch:4 step:4603 [D loss: 0.660049, acc.: 62.50%] [G loss: 0.759039]\n",
      "epoch:4 step:4604 [D loss: 0.703731, acc.: 56.25%] [G loss: 0.791162]\n",
      "epoch:4 step:4605 [D loss: 0.661357, acc.: 71.09%] [G loss: 0.733044]\n",
      "epoch:4 step:4606 [D loss: 0.726450, acc.: 49.22%] [G loss: 0.747380]\n",
      "epoch:4 step:4607 [D loss: 0.721398, acc.: 44.53%] [G loss: 0.759692]\n",
      "epoch:4 step:4608 [D loss: 0.708569, acc.: 46.88%] [G loss: 0.723114]\n",
      "epoch:4 step:4609 [D loss: 0.690857, acc.: 49.22%] [G loss: 0.770169]\n",
      "epoch:4 step:4610 [D loss: 0.719110, acc.: 45.31%] [G loss: 0.700645]\n",
      "epoch:4 step:4611 [D loss: 0.700172, acc.: 44.53%] [G loss: 0.694616]\n",
      "epoch:4 step:4612 [D loss: 0.698160, acc.: 45.31%] [G loss: 0.710729]\n",
      "epoch:4 step:4613 [D loss: 0.704756, acc.: 46.09%] [G loss: 0.691486]\n",
      "epoch:4 step:4614 [D loss: 0.697059, acc.: 47.66%] [G loss: 0.704072]\n",
      "epoch:4 step:4615 [D loss: 0.700318, acc.: 49.22%] [G loss: 0.705989]\n",
      "epoch:4 step:4616 [D loss: 0.683296, acc.: 53.91%] [G loss: 0.710057]\n",
      "epoch:4 step:4617 [D loss: 0.693982, acc.: 52.34%] [G loss: 0.702166]\n",
      "epoch:4 step:4618 [D loss: 0.702210, acc.: 48.44%] [G loss: 0.710431]\n",
      "epoch:4 step:4619 [D loss: 0.683287, acc.: 54.69%] [G loss: 0.716653]\n",
      "epoch:4 step:4620 [D loss: 0.693447, acc.: 55.47%] [G loss: 0.714960]\n",
      "epoch:4 step:4621 [D loss: 0.700736, acc.: 49.22%] [G loss: 0.716000]\n",
      "epoch:4 step:4622 [D loss: 0.703744, acc.: 50.00%] [G loss: 0.721474]\n",
      "epoch:4 step:4623 [D loss: 0.679658, acc.: 58.59%] [G loss: 0.710910]\n",
      "epoch:4 step:4624 [D loss: 0.676661, acc.: 54.69%] [G loss: 0.718406]\n",
      "epoch:4 step:4625 [D loss: 0.686836, acc.: 50.78%] [G loss: 0.728365]\n",
      "epoch:4 step:4626 [D loss: 0.666942, acc.: 60.94%] [G loss: 0.714391]\n",
      "epoch:4 step:4627 [D loss: 0.689341, acc.: 57.03%] [G loss: 0.729700]\n",
      "epoch:4 step:4628 [D loss: 0.685223, acc.: 53.91%] [G loss: 0.736417]\n",
      "epoch:4 step:4629 [D loss: 0.703656, acc.: 46.88%] [G loss: 0.726464]\n",
      "epoch:4 step:4630 [D loss: 0.712434, acc.: 45.31%] [G loss: 0.743601]\n",
      "epoch:4 step:4631 [D loss: 0.702929, acc.: 54.69%] [G loss: 0.716058]\n",
      "epoch:4 step:4632 [D loss: 0.690103, acc.: 54.69%] [G loss: 0.744063]\n",
      "epoch:4 step:4633 [D loss: 0.699760, acc.: 50.78%] [G loss: 0.749253]\n",
      "epoch:4 step:4634 [D loss: 0.691714, acc.: 53.91%] [G loss: 0.723665]\n",
      "epoch:4 step:4635 [D loss: 0.682016, acc.: 57.81%] [G loss: 0.720262]\n",
      "epoch:4 step:4636 [D loss: 0.709162, acc.: 42.19%] [G loss: 0.913370]\n",
      "epoch:4 step:4637 [D loss: 0.673114, acc.: 58.59%] [G loss: 0.728886]\n",
      "epoch:4 step:4638 [D loss: 0.691859, acc.: 58.59%] [G loss: 0.744522]\n",
      "epoch:4 step:4639 [D loss: 0.725663, acc.: 32.03%] [G loss: 0.716646]\n",
      "epoch:4 step:4640 [D loss: 0.763319, acc.: 28.12%] [G loss: 0.705497]\n",
      "epoch:4 step:4641 [D loss: 0.718601, acc.: 41.41%] [G loss: 0.717677]\n",
      "epoch:4 step:4642 [D loss: 0.706778, acc.: 44.53%] [G loss: 0.713226]\n",
      "epoch:4 step:4643 [D loss: 0.701684, acc.: 48.44%] [G loss: 0.706861]\n",
      "epoch:4 step:4644 [D loss: 0.693412, acc.: 48.44%] [G loss: 0.722691]\n",
      "epoch:4 step:4645 [D loss: 0.686654, acc.: 58.59%] [G loss: 0.703759]\n",
      "epoch:4 step:4646 [D loss: 0.703396, acc.: 41.41%] [G loss: 0.725845]\n",
      "epoch:4 step:4647 [D loss: 0.628220, acc.: 74.22%] [G loss: 0.739409]\n",
      "epoch:4 step:4648 [D loss: 0.660963, acc.: 63.28%] [G loss: 0.777228]\n",
      "epoch:4 step:4649 [D loss: 0.681737, acc.: 60.94%] [G loss: 0.741336]\n",
      "epoch:4 step:4650 [D loss: 0.683510, acc.: 60.94%] [G loss: 0.724709]\n",
      "epoch:4 step:4651 [D loss: 0.679928, acc.: 60.94%] [G loss: 0.712666]\n",
      "epoch:4 step:4652 [D loss: 0.713605, acc.: 44.53%] [G loss: 0.746294]\n",
      "epoch:4 step:4653 [D loss: 0.709104, acc.: 46.09%] [G loss: 0.704722]\n",
      "epoch:4 step:4654 [D loss: 0.710327, acc.: 42.97%] [G loss: 0.713745]\n",
      "epoch:4 step:4655 [D loss: 0.695410, acc.: 50.00%] [G loss: 0.675526]\n",
      "epoch:4 step:4656 [D loss: 0.727375, acc.: 37.50%] [G loss: 0.657393]\n",
      "epoch:4 step:4657 [D loss: 0.689056, acc.: 50.78%] [G loss: 0.734363]\n",
      "epoch:4 step:4658 [D loss: 0.717637, acc.: 38.28%] [G loss: 0.726308]\n",
      "epoch:4 step:4659 [D loss: 0.687027, acc.: 52.34%] [G loss: 0.695678]\n",
      "epoch:4 step:4660 [D loss: 0.426351, acc.: 79.69%] [G loss: 0.768515]\n",
      "epoch:4 step:4661 [D loss: 0.689548, acc.: 52.34%] [G loss: 0.717471]\n",
      "epoch:4 step:4662 [D loss: 0.711502, acc.: 35.94%] [G loss: 0.800923]\n",
      "epoch:4 step:4663 [D loss: 0.705511, acc.: 45.31%] [G loss: 0.787967]\n",
      "epoch:4 step:4664 [D loss: 0.715070, acc.: 39.84%] [G loss: 0.758251]\n",
      "epoch:4 step:4665 [D loss: 0.671382, acc.: 60.94%] [G loss: 0.780411]\n",
      "epoch:4 step:4666 [D loss: 0.672935, acc.: 59.38%] [G loss: 0.709803]\n",
      "epoch:4 step:4667 [D loss: 0.646980, acc.: 69.53%] [G loss: 0.712284]\n",
      "epoch:4 step:4668 [D loss: 0.743565, acc.: 39.06%] [G loss: 0.748088]\n",
      "epoch:4 step:4669 [D loss: 0.689814, acc.: 48.44%] [G loss: 0.741156]\n",
      "epoch:4 step:4670 [D loss: 0.660240, acc.: 66.41%] [G loss: 0.756042]\n",
      "epoch:4 step:4671 [D loss: 0.689482, acc.: 53.91%] [G loss: 0.756984]\n",
      "epoch:4 step:4672 [D loss: 0.667493, acc.: 57.81%] [G loss: 0.706693]\n",
      "epoch:4 step:4673 [D loss: 0.632012, acc.: 59.38%] [G loss: 0.664482]\n",
      "epoch:4 step:4674 [D loss: 0.567156, acc.: 57.81%] [G loss: 0.721395]\n",
      "epoch:4 step:4675 [D loss: 1.285982, acc.: 51.56%] [G loss: 1.068454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4676 [D loss: 0.677738, acc.: 48.44%] [G loss: 0.983637]\n",
      "epoch:4 step:4677 [D loss: 0.535495, acc.: 57.81%] [G loss: 1.416689]\n",
      "epoch:4 step:4678 [D loss: 0.745906, acc.: 46.09%] [G loss: 0.751888]\n",
      "epoch:4 step:4679 [D loss: 0.965562, acc.: 2.34%] [G loss: 0.647214]\n",
      "epoch:4 step:4680 [D loss: 0.756631, acc.: 22.66%] [G loss: 0.680135]\n",
      "epoch:4 step:4681 [D loss: 0.763405, acc.: 24.22%] [G loss: 0.744887]\n",
      "epoch:4 step:4682 [D loss: 0.685702, acc.: 54.69%] [G loss: 0.716768]\n",
      "epoch:4 step:4683 [D loss: 0.694927, acc.: 47.66%] [G loss: 0.673269]\n",
      "epoch:4 step:4684 [D loss: 0.545995, acc.: 53.12%] [G loss: 0.743389]\n",
      "epoch:4 step:4685 [D loss: 0.452971, acc.: 57.81%] [G loss: 0.742993]\n",
      "epoch:5 step:4686 [D loss: 0.726692, acc.: 59.38%] [G loss: 0.676071]\n",
      "epoch:5 step:4687 [D loss: 0.703067, acc.: 53.12%] [G loss: 0.594654]\n",
      "epoch:5 step:4688 [D loss: 0.662951, acc.: 57.81%] [G loss: 0.687162]\n",
      "epoch:5 step:4689 [D loss: 0.677339, acc.: 57.81%] [G loss: 0.661094]\n",
      "epoch:5 step:4690 [D loss: 0.613871, acc.: 63.28%] [G loss: 0.679832]\n",
      "epoch:5 step:4691 [D loss: 0.679270, acc.: 59.38%] [G loss: 0.618346]\n",
      "epoch:5 step:4692 [D loss: 0.614294, acc.: 64.84%] [G loss: 0.699283]\n",
      "epoch:5 step:4693 [D loss: 0.627918, acc.: 60.16%] [G loss: 0.668963]\n",
      "epoch:5 step:4694 [D loss: 0.754834, acc.: 49.22%] [G loss: 0.147342]\n",
      "epoch:5 step:4695 [D loss: 0.647633, acc.: 54.69%] [G loss: 0.620083]\n",
      "epoch:5 step:4696 [D loss: 0.995706, acc.: 42.19%] [G loss: 0.804689]\n",
      "epoch:5 step:4697 [D loss: 0.726014, acc.: 41.41%] [G loss: 0.774751]\n",
      "epoch:5 step:4698 [D loss: 0.687416, acc.: 51.56%] [G loss: 0.767182]\n",
      "epoch:5 step:4699 [D loss: 0.717891, acc.: 43.75%] [G loss: 0.781605]\n",
      "epoch:5 step:4700 [D loss: 0.690719, acc.: 52.34%] [G loss: 0.794937]\n",
      "epoch:5 step:4701 [D loss: 0.693177, acc.: 52.34%] [G loss: 0.839809]\n",
      "epoch:5 step:4702 [D loss: 0.705915, acc.: 45.31%] [G loss: 0.798890]\n",
      "epoch:5 step:4703 [D loss: 0.688543, acc.: 52.34%] [G loss: 0.914423]\n",
      "epoch:5 step:4704 [D loss: 0.677670, acc.: 50.00%] [G loss: 0.797085]\n",
      "epoch:5 step:4705 [D loss: 0.699018, acc.: 50.00%] [G loss: 0.815623]\n",
      "epoch:5 step:4706 [D loss: 0.669287, acc.: 55.47%] [G loss: 0.770544]\n",
      "epoch:5 step:4707 [D loss: 0.711686, acc.: 48.44%] [G loss: 0.738914]\n",
      "epoch:5 step:4708 [D loss: 0.715096, acc.: 47.66%] [G loss: 0.740454]\n",
      "epoch:5 step:4709 [D loss: 0.709299, acc.: 50.00%] [G loss: 0.765581]\n",
      "epoch:5 step:4710 [D loss: 0.702175, acc.: 39.06%] [G loss: 0.736100]\n",
      "epoch:5 step:4711 [D loss: 0.708929, acc.: 42.19%] [G loss: 0.732630]\n",
      "epoch:5 step:4712 [D loss: 0.702625, acc.: 41.41%] [G loss: 0.734056]\n",
      "epoch:5 step:4713 [D loss: 0.704149, acc.: 43.75%] [G loss: 0.718634]\n",
      "epoch:5 step:4714 [D loss: 0.695636, acc.: 45.31%] [G loss: 0.709530]\n",
      "epoch:5 step:4715 [D loss: 0.703202, acc.: 39.84%] [G loss: 0.747253]\n",
      "epoch:5 step:4716 [D loss: 0.688202, acc.: 50.78%] [G loss: 0.723858]\n",
      "epoch:5 step:4717 [D loss: 0.694445, acc.: 49.22%] [G loss: 0.726549]\n",
      "epoch:5 step:4718 [D loss: 0.691526, acc.: 47.66%] [G loss: 0.724569]\n",
      "epoch:5 step:4719 [D loss: 0.692317, acc.: 53.12%] [G loss: 0.722133]\n",
      "epoch:5 step:4720 [D loss: 0.676189, acc.: 65.62%] [G loss: 0.700588]\n",
      "epoch:5 step:4721 [D loss: 0.675548, acc.: 55.47%] [G loss: 0.725146]\n",
      "epoch:5 step:4722 [D loss: 0.682296, acc.: 60.16%] [G loss: 0.706459]\n",
      "epoch:5 step:4723 [D loss: 0.760116, acc.: 14.06%] [G loss: 0.706737]\n",
      "epoch:5 step:4724 [D loss: 0.704439, acc.: 42.19%] [G loss: 0.713993]\n",
      "epoch:5 step:4725 [D loss: 0.732292, acc.: 32.03%] [G loss: 0.733265]\n",
      "epoch:5 step:4726 [D loss: 0.695517, acc.: 44.53%] [G loss: 0.714705]\n",
      "epoch:5 step:4727 [D loss: 0.689834, acc.: 46.09%] [G loss: 0.717489]\n",
      "epoch:5 step:4728 [D loss: 0.696438, acc.: 47.66%] [G loss: 0.701678]\n",
      "epoch:5 step:4729 [D loss: 0.693581, acc.: 53.12%] [G loss: 0.711472]\n",
      "epoch:5 step:4730 [D loss: 0.702390, acc.: 49.22%] [G loss: 0.717156]\n",
      "epoch:5 step:4731 [D loss: 0.683770, acc.: 53.12%] [G loss: 0.720618]\n",
      "epoch:5 step:4732 [D loss: 0.692568, acc.: 53.12%] [G loss: 0.708899]\n",
      "epoch:5 step:4733 [D loss: 0.681027, acc.: 61.72%] [G loss: 0.723397]\n",
      "epoch:5 step:4734 [D loss: 0.692393, acc.: 53.91%] [G loss: 0.708016]\n",
      "epoch:5 step:4735 [D loss: 0.665990, acc.: 64.84%] [G loss: 0.716500]\n",
      "epoch:5 step:4736 [D loss: 0.710528, acc.: 37.50%] [G loss: 0.715701]\n",
      "epoch:5 step:4737 [D loss: 0.696854, acc.: 51.56%] [G loss: 0.719797]\n",
      "epoch:5 step:4738 [D loss: 0.691264, acc.: 53.91%] [G loss: 0.712538]\n",
      "epoch:5 step:4739 [D loss: 0.701195, acc.: 51.56%] [G loss: 0.699306]\n",
      "epoch:5 step:4740 [D loss: 0.686829, acc.: 57.81%] [G loss: 0.727085]\n",
      "epoch:5 step:4741 [D loss: 0.698184, acc.: 48.44%] [G loss: 0.699143]\n",
      "epoch:5 step:4742 [D loss: 0.696353, acc.: 53.12%] [G loss: 0.712960]\n",
      "epoch:5 step:4743 [D loss: 0.783996, acc.: 35.16%] [G loss: 0.727931]\n",
      "epoch:5 step:4744 [D loss: 0.694037, acc.: 55.47%] [G loss: 0.728759]\n",
      "epoch:5 step:4745 [D loss: 0.692684, acc.: 53.12%] [G loss: 0.736706]\n",
      "epoch:5 step:4746 [D loss: 0.693954, acc.: 50.00%] [G loss: 0.755074]\n",
      "epoch:5 step:4747 [D loss: 0.698889, acc.: 53.91%] [G loss: 0.732958]\n",
      "epoch:5 step:4748 [D loss: 0.703755, acc.: 49.22%] [G loss: 0.750201]\n",
      "epoch:5 step:4749 [D loss: 0.693752, acc.: 48.44%] [G loss: 0.748596]\n",
      "epoch:5 step:4750 [D loss: 0.688735, acc.: 59.38%] [G loss: 0.758355]\n",
      "epoch:5 step:4751 [D loss: 0.701798, acc.: 54.69%] [G loss: 0.732312]\n",
      "epoch:5 step:4752 [D loss: 0.693766, acc.: 53.91%] [G loss: 0.726311]\n",
      "epoch:5 step:4753 [D loss: 0.688421, acc.: 58.59%] [G loss: 0.746183]\n",
      "epoch:5 step:4754 [D loss: 0.696375, acc.: 57.03%] [G loss: 0.762779]\n",
      "epoch:5 step:4755 [D loss: 0.684080, acc.: 60.16%] [G loss: 0.749769]\n",
      "epoch:5 step:4756 [D loss: 0.727430, acc.: 39.06%] [G loss: 0.712899]\n",
      "epoch:5 step:4757 [D loss: 0.698481, acc.: 53.12%] [G loss: 0.730802]\n",
      "epoch:5 step:4758 [D loss: 0.702983, acc.: 47.66%] [G loss: 0.708957]\n",
      "epoch:5 step:4759 [D loss: 0.695002, acc.: 53.12%] [G loss: 0.709939]\n",
      "epoch:5 step:4760 [D loss: 0.714542, acc.: 33.59%] [G loss: 0.696861]\n",
      "epoch:5 step:4761 [D loss: 0.694259, acc.: 53.91%] [G loss: 0.903305]\n",
      "epoch:5 step:4762 [D loss: 0.691481, acc.: 55.47%] [G loss: 0.693060]\n",
      "epoch:5 step:4763 [D loss: 0.702812, acc.: 45.31%] [G loss: 0.692145]\n",
      "epoch:5 step:4764 [D loss: 0.690966, acc.: 50.00%] [G loss: 0.692035]\n",
      "epoch:5 step:4765 [D loss: 0.702166, acc.: 39.84%] [G loss: 0.696449]\n",
      "epoch:5 step:4766 [D loss: 0.710166, acc.: 39.84%] [G loss: 0.685790]\n",
      "epoch:5 step:4767 [D loss: 0.714056, acc.: 32.81%] [G loss: 0.697055]\n",
      "epoch:5 step:4768 [D loss: 0.702568, acc.: 40.62%] [G loss: 0.696198]\n",
      "epoch:5 step:4769 [D loss: 0.697795, acc.: 43.75%] [G loss: 0.711446]\n",
      "epoch:5 step:4770 [D loss: 0.694619, acc.: 42.19%] [G loss: 0.706270]\n",
      "epoch:5 step:4771 [D loss: 0.697684, acc.: 43.75%] [G loss: 0.702772]\n",
      "epoch:5 step:4772 [D loss: 0.709028, acc.: 39.06%] [G loss: 0.697207]\n",
      "epoch:5 step:4773 [D loss: 0.693936, acc.: 46.88%] [G loss: 0.706535]\n",
      "epoch:5 step:4774 [D loss: 0.681814, acc.: 60.94%] [G loss: 0.694152]\n",
      "epoch:5 step:4775 [D loss: 0.697156, acc.: 45.31%] [G loss: 0.666941]\n",
      "epoch:5 step:4776 [D loss: 0.686233, acc.: 49.22%] [G loss: 0.708406]\n",
      "epoch:5 step:4777 [D loss: 0.696122, acc.: 48.44%] [G loss: 0.695112]\n",
      "epoch:5 step:4778 [D loss: 0.690015, acc.: 51.56%] [G loss: 0.711446]\n",
      "epoch:5 step:4779 [D loss: 0.683483, acc.: 57.81%] [G loss: 0.723037]\n",
      "epoch:5 step:4780 [D loss: 0.695420, acc.: 51.56%] [G loss: 0.714091]\n",
      "epoch:5 step:4781 [D loss: 0.692693, acc.: 50.78%] [G loss: 0.715641]\n",
      "epoch:5 step:4782 [D loss: 0.689463, acc.: 56.25%] [G loss: 0.709350]\n",
      "epoch:5 step:4783 [D loss: 0.700543, acc.: 56.25%] [G loss: 0.717970]\n",
      "epoch:5 step:4784 [D loss: 0.690170, acc.: 55.47%] [G loss: 0.719686]\n",
      "epoch:5 step:4785 [D loss: 0.678852, acc.: 64.06%] [G loss: 0.734149]\n",
      "epoch:5 step:4786 [D loss: 0.681920, acc.: 64.06%] [G loss: 0.725375]\n",
      "epoch:5 step:4787 [D loss: 0.679838, acc.: 59.38%] [G loss: 0.751006]\n",
      "epoch:5 step:4788 [D loss: 0.690140, acc.: 61.72%] [G loss: 0.735834]\n",
      "epoch:5 step:4789 [D loss: 0.672234, acc.: 64.06%] [G loss: 0.731155]\n",
      "epoch:5 step:4790 [D loss: 0.678005, acc.: 62.50%] [G loss: 0.728994]\n",
      "epoch:5 step:4791 [D loss: 0.661721, acc.: 63.28%] [G loss: 0.746322]\n",
      "epoch:5 step:4792 [D loss: 0.667366, acc.: 64.06%] [G loss: 0.774001]\n",
      "epoch:5 step:4793 [D loss: 0.692117, acc.: 52.34%] [G loss: 0.747903]\n",
      "epoch:5 step:4794 [D loss: 0.688841, acc.: 51.56%] [G loss: 0.739900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4795 [D loss: 0.707867, acc.: 44.53%] [G loss: 0.751046]\n",
      "epoch:5 step:4796 [D loss: 0.697030, acc.: 49.22%] [G loss: 0.741345]\n",
      "epoch:5 step:4797 [D loss: 0.688370, acc.: 53.91%] [G loss: 0.731154]\n",
      "epoch:5 step:4798 [D loss: 0.718823, acc.: 45.31%] [G loss: 0.738565]\n",
      "epoch:5 step:4799 [D loss: 0.697929, acc.: 49.22%] [G loss: 0.727250]\n",
      "epoch:5 step:4800 [D loss: 0.694646, acc.: 50.78%] [G loss: 0.716994]\n",
      "epoch:5 step:4801 [D loss: 0.697829, acc.: 47.66%] [G loss: 0.709898]\n",
      "epoch:5 step:4802 [D loss: 0.695032, acc.: 50.78%] [G loss: 0.710238]\n",
      "epoch:5 step:4803 [D loss: 0.694105, acc.: 53.12%] [G loss: 0.724257]\n",
      "epoch:5 step:4804 [D loss: 0.698441, acc.: 50.78%] [G loss: 0.712059]\n",
      "epoch:5 step:4805 [D loss: 0.695154, acc.: 47.66%] [G loss: 0.737052]\n",
      "epoch:5 step:4806 [D loss: 0.704826, acc.: 42.97%] [G loss: 0.745640]\n",
      "epoch:5 step:4807 [D loss: 0.697445, acc.: 50.78%] [G loss: 0.733893]\n",
      "epoch:5 step:4808 [D loss: 0.691647, acc.: 50.78%] [G loss: 0.754904]\n",
      "epoch:5 step:4809 [D loss: 0.690590, acc.: 56.25%] [G loss: 0.768981]\n",
      "epoch:5 step:4810 [D loss: 0.692145, acc.: 52.34%] [G loss: 0.747109]\n",
      "epoch:5 step:4811 [D loss: 0.679116, acc.: 58.59%] [G loss: 0.763871]\n",
      "epoch:5 step:4812 [D loss: 0.696949, acc.: 52.34%] [G loss: 0.739814]\n",
      "epoch:5 step:4813 [D loss: 0.692427, acc.: 52.34%] [G loss: 0.757114]\n",
      "epoch:5 step:4814 [D loss: 0.698802, acc.: 47.66%] [G loss: 0.737487]\n",
      "epoch:5 step:4815 [D loss: 0.682228, acc.: 57.03%] [G loss: 0.728172]\n",
      "epoch:5 step:4816 [D loss: 0.687395, acc.: 57.81%] [G loss: 0.729636]\n",
      "epoch:5 step:4817 [D loss: 0.694541, acc.: 49.22%] [G loss: 0.747661]\n",
      "epoch:5 step:4818 [D loss: 0.685472, acc.: 57.81%] [G loss: 0.723116]\n",
      "epoch:5 step:4819 [D loss: 0.701579, acc.: 45.31%] [G loss: 0.713648]\n",
      "epoch:5 step:4820 [D loss: 0.696097, acc.: 48.44%] [G loss: 0.710811]\n",
      "epoch:5 step:4821 [D loss: 0.681831, acc.: 56.25%] [G loss: 0.732590]\n",
      "epoch:5 step:4822 [D loss: 0.710679, acc.: 42.19%] [G loss: 0.722965]\n",
      "epoch:5 step:4823 [D loss: 0.708886, acc.: 38.28%] [G loss: 0.695661]\n",
      "epoch:5 step:4824 [D loss: 0.697592, acc.: 47.66%] [G loss: 0.739122]\n",
      "epoch:5 step:4825 [D loss: 0.707609, acc.: 43.75%] [G loss: 0.720325]\n",
      "epoch:5 step:4826 [D loss: 0.695829, acc.: 47.66%] [G loss: 0.729373]\n",
      "epoch:5 step:4827 [D loss: 0.698503, acc.: 42.97%] [G loss: 0.734110]\n",
      "epoch:5 step:4828 [D loss: 0.689734, acc.: 47.66%] [G loss: 0.752811]\n",
      "epoch:5 step:4829 [D loss: 0.668484, acc.: 64.06%] [G loss: 0.760032]\n",
      "epoch:5 step:4830 [D loss: 0.665519, acc.: 65.62%] [G loss: 0.765025]\n",
      "epoch:5 step:4831 [D loss: 0.666762, acc.: 61.72%] [G loss: 0.760757]\n",
      "epoch:5 step:4832 [D loss: 0.667744, acc.: 59.38%] [G loss: 0.759154]\n",
      "epoch:5 step:4833 [D loss: 0.689223, acc.: 51.56%] [G loss: 0.764820]\n",
      "epoch:5 step:4834 [D loss: 0.677232, acc.: 59.38%] [G loss: 0.751811]\n",
      "epoch:5 step:4835 [D loss: 0.693807, acc.: 52.34%] [G loss: 0.752934]\n",
      "epoch:5 step:4836 [D loss: 0.695699, acc.: 57.81%] [G loss: 0.736049]\n",
      "epoch:5 step:4837 [D loss: 0.682753, acc.: 61.72%] [G loss: 0.697777]\n",
      "epoch:5 step:4838 [D loss: 0.705351, acc.: 42.97%] [G loss: 0.689444]\n",
      "epoch:5 step:4839 [D loss: 0.710101, acc.: 47.66%] [G loss: 0.710203]\n",
      "epoch:5 step:4840 [D loss: 0.712906, acc.: 40.62%] [G loss: 0.713311]\n",
      "epoch:5 step:4841 [D loss: 0.704700, acc.: 48.44%] [G loss: 0.700861]\n",
      "epoch:5 step:4842 [D loss: 0.708742, acc.: 43.75%] [G loss: 0.712942]\n",
      "epoch:5 step:4843 [D loss: 0.694913, acc.: 51.56%] [G loss: 0.760417]\n",
      "epoch:5 step:4844 [D loss: 0.696800, acc.: 47.66%] [G loss: 0.736865]\n",
      "epoch:5 step:4845 [D loss: 0.706018, acc.: 50.00%] [G loss: 0.770392]\n",
      "epoch:5 step:4846 [D loss: 0.693964, acc.: 51.56%] [G loss: 0.778520]\n",
      "epoch:5 step:4847 [D loss: 0.683007, acc.: 53.12%] [G loss: 0.765132]\n",
      "epoch:5 step:4848 [D loss: 0.697465, acc.: 46.88%] [G loss: 0.762999]\n",
      "epoch:5 step:4849 [D loss: 0.683447, acc.: 59.38%] [G loss: 0.749637]\n",
      "epoch:5 step:4850 [D loss: 0.680470, acc.: 58.59%] [G loss: 0.750172]\n",
      "epoch:5 step:4851 [D loss: 0.668736, acc.: 64.06%] [G loss: 0.777245]\n",
      "epoch:5 step:4852 [D loss: 0.688828, acc.: 49.22%] [G loss: 0.746491]\n",
      "epoch:5 step:4853 [D loss: 0.661578, acc.: 66.41%] [G loss: 0.775743]\n",
      "epoch:5 step:4854 [D loss: 0.754895, acc.: 52.34%] [G loss: 0.783274]\n",
      "epoch:5 step:4855 [D loss: 0.705827, acc.: 55.47%] [G loss: 0.797269]\n",
      "epoch:5 step:4856 [D loss: 0.701621, acc.: 50.78%] [G loss: 0.769952]\n",
      "epoch:5 step:4857 [D loss: 0.713820, acc.: 50.00%] [G loss: 0.754757]\n",
      "epoch:5 step:4858 [D loss: 0.701087, acc.: 50.78%] [G loss: 0.739556]\n",
      "epoch:5 step:4859 [D loss: 0.722300, acc.: 34.38%] [G loss: 0.713882]\n",
      "epoch:5 step:4860 [D loss: 0.702483, acc.: 53.12%] [G loss: 0.707529]\n",
      "epoch:5 step:4861 [D loss: 0.707547, acc.: 45.31%] [G loss: 0.696392]\n",
      "epoch:5 step:4862 [D loss: 0.711330, acc.: 42.19%] [G loss: 0.716511]\n",
      "epoch:5 step:4863 [D loss: 0.695578, acc.: 44.53%] [G loss: 0.688523]\n",
      "epoch:5 step:4864 [D loss: 0.701724, acc.: 47.66%] [G loss: 0.705012]\n",
      "epoch:5 step:4865 [D loss: 0.701549, acc.: 47.66%] [G loss: 0.690452]\n",
      "epoch:5 step:4866 [D loss: 0.704128, acc.: 39.06%] [G loss: 0.693516]\n",
      "epoch:5 step:4867 [D loss: 0.699953, acc.: 47.66%] [G loss: 0.702324]\n",
      "epoch:5 step:4868 [D loss: 0.685674, acc.: 46.09%] [G loss: 0.703292]\n",
      "epoch:5 step:4869 [D loss: 0.672801, acc.: 53.91%] [G loss: 0.694718]\n",
      "epoch:5 step:4870 [D loss: 0.687103, acc.: 46.09%] [G loss: 0.684418]\n",
      "epoch:5 step:4871 [D loss: 0.676166, acc.: 57.81%] [G loss: 0.706641]\n",
      "epoch:5 step:4872 [D loss: 0.677761, acc.: 63.28%] [G loss: 0.718291]\n",
      "epoch:5 step:4873 [D loss: 0.694216, acc.: 53.12%] [G loss: 0.710429]\n",
      "epoch:5 step:4874 [D loss: 0.699231, acc.: 53.12%] [G loss: 0.686393]\n",
      "epoch:5 step:4875 [D loss: 0.697043, acc.: 51.56%] [G loss: 0.704216]\n",
      "epoch:5 step:4876 [D loss: 0.701022, acc.: 55.47%] [G loss: 0.674606]\n",
      "epoch:5 step:4877 [D loss: 0.686046, acc.: 60.16%] [G loss: 0.691382]\n",
      "epoch:5 step:4878 [D loss: 0.700509, acc.: 49.22%] [G loss: 0.717051]\n",
      "epoch:5 step:4879 [D loss: 0.698587, acc.: 53.91%] [G loss: 0.692643]\n",
      "epoch:5 step:4880 [D loss: 0.695484, acc.: 50.78%] [G loss: 0.690291]\n",
      "epoch:5 step:4881 [D loss: 0.693278, acc.: 52.34%] [G loss: 0.701352]\n",
      "epoch:5 step:4882 [D loss: 0.682853, acc.: 64.84%] [G loss: 0.725910]\n",
      "epoch:5 step:4883 [D loss: 0.698173, acc.: 54.69%] [G loss: 0.724069]\n",
      "epoch:5 step:4884 [D loss: 0.688144, acc.: 53.12%] [G loss: 0.730854]\n",
      "epoch:5 step:4885 [D loss: 0.699612, acc.: 43.75%] [G loss: 0.716043]\n",
      "epoch:5 step:4886 [D loss: 0.693136, acc.: 53.12%] [G loss: 0.723951]\n",
      "epoch:5 step:4887 [D loss: 0.690257, acc.: 49.22%] [G loss: 0.715519]\n",
      "epoch:5 step:4888 [D loss: 0.699401, acc.: 43.75%] [G loss: 0.735529]\n",
      "epoch:5 step:4889 [D loss: 0.671519, acc.: 54.69%] [G loss: 0.719929]\n",
      "epoch:5 step:4890 [D loss: 0.685692, acc.: 55.47%] [G loss: 0.760170]\n",
      "epoch:5 step:4891 [D loss: 0.684709, acc.: 56.25%] [G loss: 0.755475]\n",
      "epoch:5 step:4892 [D loss: 0.626605, acc.: 61.72%] [G loss: 0.749033]\n",
      "epoch:5 step:4893 [D loss: 0.706589, acc.: 52.34%] [G loss: 0.730352]\n",
      "epoch:5 step:4894 [D loss: 0.666892, acc.: 64.06%] [G loss: 0.743885]\n",
      "epoch:5 step:4895 [D loss: 0.707337, acc.: 50.78%] [G loss: 0.720555]\n",
      "epoch:5 step:4896 [D loss: 0.689693, acc.: 53.91%] [G loss: 0.740968]\n",
      "epoch:5 step:4897 [D loss: 0.687087, acc.: 53.91%] [G loss: 0.746499]\n",
      "epoch:5 step:4898 [D loss: 0.698644, acc.: 48.44%] [G loss: 0.734035]\n",
      "epoch:5 step:4899 [D loss: 0.689815, acc.: 52.34%] [G loss: 0.736991]\n",
      "epoch:5 step:4900 [D loss: 0.710782, acc.: 50.00%] [G loss: 0.738099]\n",
      "epoch:5 step:4901 [D loss: 0.602387, acc.: 64.06%] [G loss: 0.718174]\n",
      "epoch:5 step:4902 [D loss: 0.701902, acc.: 50.00%] [G loss: 0.735136]\n",
      "epoch:5 step:4903 [D loss: 0.696438, acc.: 43.75%] [G loss: 0.714834]\n",
      "epoch:5 step:4904 [D loss: 0.668223, acc.: 64.84%] [G loss: 0.697678]\n",
      "epoch:5 step:4905 [D loss: 0.712777, acc.: 46.09%] [G loss: 0.746841]\n",
      "epoch:5 step:4906 [D loss: 0.704945, acc.: 42.19%] [G loss: 0.719520]\n",
      "epoch:5 step:4907 [D loss: 0.717307, acc.: 41.41%] [G loss: 0.707883]\n",
      "epoch:5 step:4908 [D loss: 0.722794, acc.: 36.72%] [G loss: 0.720336]\n",
      "epoch:5 step:4909 [D loss: 0.737097, acc.: 42.97%] [G loss: 0.736603]\n",
      "epoch:5 step:4910 [D loss: 0.685677, acc.: 64.06%] [G loss: 0.698699]\n",
      "epoch:5 step:4911 [D loss: 0.700189, acc.: 49.22%] [G loss: 0.755400]\n",
      "epoch:5 step:4912 [D loss: 0.707389, acc.: 42.19%] [G loss: 0.737533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4913 [D loss: 0.718111, acc.: 37.50%] [G loss: 0.757177]\n",
      "epoch:5 step:4914 [D loss: 0.688351, acc.: 55.47%] [G loss: 0.762034]\n",
      "epoch:5 step:4915 [D loss: 0.674201, acc.: 61.72%] [G loss: 0.765224]\n",
      "epoch:5 step:4916 [D loss: 0.655500, acc.: 71.88%] [G loss: 0.775637]\n",
      "epoch:5 step:4917 [D loss: 0.649756, acc.: 76.56%] [G loss: 0.846843]\n",
      "epoch:5 step:4918 [D loss: 0.693150, acc.: 53.91%] [G loss: 0.812091]\n",
      "epoch:5 step:4919 [D loss: 0.681866, acc.: 54.69%] [G loss: 0.810593]\n",
      "epoch:5 step:4920 [D loss: 0.670914, acc.: 56.25%] [G loss: 0.824097]\n",
      "epoch:5 step:4921 [D loss: 0.697836, acc.: 45.31%] [G loss: 0.775766]\n",
      "epoch:5 step:4922 [D loss: 0.668925, acc.: 65.62%] [G loss: 0.762031]\n",
      "epoch:5 step:4923 [D loss: 0.690603, acc.: 50.00%] [G loss: 0.770925]\n",
      "epoch:5 step:4924 [D loss: 0.722904, acc.: 42.97%] [G loss: 0.764077]\n",
      "epoch:5 step:4925 [D loss: 0.698133, acc.: 45.31%] [G loss: 0.752704]\n",
      "epoch:5 step:4926 [D loss: 0.737528, acc.: 33.59%] [G loss: 0.745000]\n",
      "epoch:5 step:4927 [D loss: 0.711922, acc.: 46.88%] [G loss: 0.730523]\n",
      "epoch:5 step:4928 [D loss: 0.728167, acc.: 46.88%] [G loss: 0.735643]\n",
      "epoch:5 step:4929 [D loss: 0.690511, acc.: 54.69%] [G loss: 0.712756]\n",
      "epoch:5 step:4930 [D loss: 0.703637, acc.: 48.44%] [G loss: 0.730190]\n",
      "epoch:5 step:4931 [D loss: 0.693315, acc.: 50.78%] [G loss: 0.734714]\n",
      "epoch:5 step:4932 [D loss: 0.700819, acc.: 48.44%] [G loss: 0.733051]\n",
      "epoch:5 step:4933 [D loss: 0.683009, acc.: 54.69%] [G loss: 0.744452]\n",
      "epoch:5 step:4934 [D loss: 0.699526, acc.: 42.97%] [G loss: 0.742987]\n",
      "epoch:5 step:4935 [D loss: 0.672311, acc.: 64.84%] [G loss: 0.741585]\n",
      "epoch:5 step:4936 [D loss: 0.670306, acc.: 66.41%] [G loss: 0.758032]\n",
      "epoch:5 step:4937 [D loss: 0.672553, acc.: 61.72%] [G loss: 0.766959]\n",
      "epoch:5 step:4938 [D loss: 0.657416, acc.: 61.72%] [G loss: 0.770528]\n",
      "epoch:5 step:4939 [D loss: 0.685041, acc.: 52.34%] [G loss: 0.759616]\n",
      "epoch:5 step:4940 [D loss: 0.688262, acc.: 52.34%] [G loss: 0.772502]\n",
      "epoch:5 step:4941 [D loss: 0.673070, acc.: 57.03%] [G loss: 0.723656]\n",
      "epoch:5 step:4942 [D loss: 0.673757, acc.: 58.59%] [G loss: 0.731284]\n",
      "epoch:5 step:4943 [D loss: 0.691770, acc.: 55.47%] [G loss: 0.731171]\n",
      "epoch:5 step:4944 [D loss: 0.710068, acc.: 44.53%] [G loss: 0.713248]\n",
      "epoch:5 step:4945 [D loss: 0.713838, acc.: 42.19%] [G loss: 0.724927]\n",
      "epoch:5 step:4946 [D loss: 0.701422, acc.: 50.00%] [G loss: 0.693764]\n",
      "epoch:5 step:4947 [D loss: 0.708503, acc.: 48.44%] [G loss: 0.706649]\n",
      "epoch:5 step:4948 [D loss: 0.713985, acc.: 45.31%] [G loss: 0.704813]\n",
      "epoch:5 step:4949 [D loss: 0.704093, acc.: 50.00%] [G loss: 0.734534]\n",
      "epoch:5 step:4950 [D loss: 0.722355, acc.: 42.97%] [G loss: 0.707927]\n",
      "epoch:5 step:4951 [D loss: 0.709599, acc.: 42.97%] [G loss: 0.737348]\n",
      "epoch:5 step:4952 [D loss: 0.697993, acc.: 49.22%] [G loss: 0.728022]\n",
      "epoch:5 step:4953 [D loss: 0.702060, acc.: 45.31%] [G loss: 0.719256]\n",
      "epoch:5 step:4954 [D loss: 0.694017, acc.: 50.78%] [G loss: 0.735419]\n",
      "epoch:5 step:4955 [D loss: 0.696908, acc.: 53.12%] [G loss: 0.690132]\n",
      "epoch:5 step:4956 [D loss: 0.677971, acc.: 56.25%] [G loss: 0.629064]\n",
      "epoch:5 step:4957 [D loss: 0.699008, acc.: 46.09%] [G loss: 0.747815]\n",
      "epoch:5 step:4958 [D loss: 0.681965, acc.: 59.38%] [G loss: 0.746092]\n",
      "epoch:5 step:4959 [D loss: 0.703110, acc.: 39.84%] [G loss: 0.733704]\n",
      "epoch:5 step:4960 [D loss: 0.691082, acc.: 53.91%] [G loss: 0.721411]\n",
      "epoch:5 step:4961 [D loss: 0.674447, acc.: 62.50%] [G loss: 0.719321]\n",
      "epoch:5 step:4962 [D loss: 0.695717, acc.: 44.53%] [G loss: 0.744681]\n",
      "epoch:5 step:4963 [D loss: 0.717002, acc.: 34.38%] [G loss: 0.440751]\n",
      "epoch:5 step:4964 [D loss: 0.706993, acc.: 42.97%] [G loss: 0.728596]\n",
      "epoch:5 step:4965 [D loss: 0.690300, acc.: 42.19%] [G loss: 0.566649]\n",
      "epoch:5 step:4966 [D loss: 0.713096, acc.: 42.97%] [G loss: 0.728723]\n",
      "epoch:5 step:4967 [D loss: 0.718102, acc.: 39.84%] [G loss: 0.745837]\n",
      "epoch:5 step:4968 [D loss: 0.694360, acc.: 46.09%] [G loss: 0.729209]\n",
      "epoch:5 step:4969 [D loss: 0.691390, acc.: 48.44%] [G loss: 0.719740]\n",
      "epoch:5 step:4970 [D loss: 0.680385, acc.: 57.81%] [G loss: 0.733842]\n",
      "epoch:5 step:4971 [D loss: 0.684291, acc.: 60.94%] [G loss: 0.750933]\n",
      "epoch:5 step:4972 [D loss: 0.669146, acc.: 60.94%] [G loss: 0.774755]\n",
      "epoch:5 step:4973 [D loss: 0.656531, acc.: 64.84%] [G loss: 0.799718]\n",
      "epoch:5 step:4974 [D loss: 0.684961, acc.: 58.59%] [G loss: 0.839733]\n",
      "epoch:5 step:4975 [D loss: 0.659779, acc.: 67.19%] [G loss: 0.814064]\n",
      "epoch:5 step:4976 [D loss: 0.691491, acc.: 44.53%] [G loss: 0.848442]\n",
      "epoch:5 step:4977 [D loss: 0.676723, acc.: 63.28%] [G loss: 0.772220]\n",
      "epoch:5 step:4978 [D loss: 0.694156, acc.: 52.34%] [G loss: 0.724202]\n",
      "epoch:5 step:4979 [D loss: 0.706536, acc.: 45.31%] [G loss: 0.709234]\n",
      "epoch:5 step:4980 [D loss: 0.755099, acc.: 28.91%] [G loss: 0.695326]\n",
      "epoch:5 step:4981 [D loss: 0.717532, acc.: 43.75%] [G loss: 0.703115]\n",
      "epoch:5 step:4982 [D loss: 0.733199, acc.: 28.91%] [G loss: 0.724803]\n",
      "epoch:5 step:4983 [D loss: 0.729067, acc.: 23.44%] [G loss: 0.713423]\n",
      "epoch:5 step:4984 [D loss: 0.697193, acc.: 43.75%] [G loss: 0.713141]\n",
      "epoch:5 step:4985 [D loss: 0.695594, acc.: 45.31%] [G loss: 0.719817]\n",
      "epoch:5 step:4986 [D loss: 0.703094, acc.: 46.09%] [G loss: 0.720223]\n",
      "epoch:5 step:4987 [D loss: 0.688791, acc.: 57.03%] [G loss: 0.716236]\n",
      "epoch:5 step:4988 [D loss: 0.693349, acc.: 53.12%] [G loss: 0.723298]\n",
      "epoch:5 step:4989 [D loss: 0.686584, acc.: 57.03%] [G loss: 0.741795]\n",
      "epoch:5 step:4990 [D loss: 0.698511, acc.: 40.62%] [G loss: 0.700591]\n",
      "epoch:5 step:4991 [D loss: 0.691000, acc.: 48.44%] [G loss: 0.738560]\n",
      "epoch:5 step:4992 [D loss: 0.689037, acc.: 53.91%] [G loss: 0.714482]\n",
      "epoch:5 step:4993 [D loss: 0.687862, acc.: 56.25%] [G loss: 0.738241]\n",
      "epoch:5 step:4994 [D loss: 0.691454, acc.: 54.69%] [G loss: 0.716313]\n",
      "epoch:5 step:4995 [D loss: 0.691722, acc.: 60.16%] [G loss: 0.749600]\n",
      "epoch:5 step:4996 [D loss: 0.681146, acc.: 57.03%] [G loss: 0.719079]\n",
      "epoch:5 step:4997 [D loss: 0.705882, acc.: 48.44%] [G loss: 0.714868]\n",
      "epoch:5 step:4998 [D loss: 0.698892, acc.: 46.09%] [G loss: 0.704742]\n",
      "epoch:5 step:4999 [D loss: 0.709625, acc.: 50.78%] [G loss: 0.695685]\n",
      "epoch:5 step:5000 [D loss: 0.678824, acc.: 64.06%] [G loss: 0.695873]\n",
      "epoch:5 step:5001 [D loss: 0.705938, acc.: 44.53%] [G loss: 0.719799]\n",
      "epoch:5 step:5002 [D loss: 0.680554, acc.: 58.59%] [G loss: 0.730089]\n",
      "epoch:5 step:5003 [D loss: 0.684710, acc.: 54.69%] [G loss: 0.728289]\n",
      "epoch:5 step:5004 [D loss: 0.680450, acc.: 53.91%] [G loss: 0.734394]\n",
      "epoch:5 step:5005 [D loss: 0.694782, acc.: 48.44%] [G loss: 0.733106]\n",
      "epoch:5 step:5006 [D loss: 0.725054, acc.: 52.34%] [G loss: 0.759400]\n",
      "epoch:5 step:5007 [D loss: 0.693351, acc.: 55.47%] [G loss: 0.796083]\n",
      "epoch:5 step:5008 [D loss: 0.705625, acc.: 46.88%] [G loss: 0.754383]\n",
      "epoch:5 step:5009 [D loss: 0.694879, acc.: 50.78%] [G loss: 0.734221]\n",
      "epoch:5 step:5010 [D loss: 0.679766, acc.: 61.72%] [G loss: 0.729611]\n",
      "epoch:5 step:5011 [D loss: 0.699557, acc.: 50.00%] [G loss: 0.729486]\n",
      "epoch:5 step:5012 [D loss: 0.679142, acc.: 53.91%] [G loss: 0.763885]\n",
      "epoch:5 step:5013 [D loss: 0.667134, acc.: 63.28%] [G loss: 0.764885]\n",
      "epoch:5 step:5014 [D loss: 0.712459, acc.: 46.09%] [G loss: 0.714359]\n",
      "epoch:5 step:5015 [D loss: 0.714929, acc.: 45.31%] [G loss: 0.717809]\n",
      "epoch:5 step:5016 [D loss: 0.688418, acc.: 48.44%] [G loss: 0.768007]\n",
      "epoch:5 step:5017 [D loss: 0.700287, acc.: 42.19%] [G loss: 0.725247]\n",
      "epoch:5 step:5018 [D loss: 0.758614, acc.: 32.03%] [G loss: 0.698027]\n",
      "epoch:5 step:5019 [D loss: 0.717900, acc.: 36.72%] [G loss: 0.717782]\n",
      "epoch:5 step:5020 [D loss: 0.715758, acc.: 35.16%] [G loss: 0.677587]\n",
      "epoch:5 step:5021 [D loss: 0.708259, acc.: 35.94%] [G loss: 0.686962]\n",
      "epoch:5 step:5022 [D loss: 0.699642, acc.: 45.31%] [G loss: 0.691066]\n",
      "epoch:5 step:5023 [D loss: 0.695428, acc.: 51.56%] [G loss: 0.682538]\n",
      "epoch:5 step:5024 [D loss: 0.692694, acc.: 51.56%] [G loss: 0.691834]\n",
      "epoch:5 step:5025 [D loss: 0.691150, acc.: 50.78%] [G loss: 0.689148]\n",
      "epoch:5 step:5026 [D loss: 0.696444, acc.: 50.78%] [G loss: 0.680736]\n",
      "epoch:5 step:5027 [D loss: 0.693456, acc.: 53.12%] [G loss: 0.681724]\n",
      "epoch:5 step:5028 [D loss: 0.700929, acc.: 44.53%] [G loss: 0.705319]\n",
      "epoch:5 step:5029 [D loss: 0.697911, acc.: 46.88%] [G loss: 0.716538]\n",
      "epoch:5 step:5030 [D loss: 0.690670, acc.: 44.53%] [G loss: 0.707907]\n",
      "epoch:5 step:5031 [D loss: 0.682888, acc.: 57.03%] [G loss: 0.741622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5032 [D loss: 0.676795, acc.: 60.94%] [G loss: 0.716842]\n",
      "epoch:5 step:5033 [D loss: 0.694815, acc.: 57.03%] [G loss: 0.720296]\n",
      "epoch:5 step:5034 [D loss: 0.704751, acc.: 44.53%] [G loss: 0.699231]\n",
      "epoch:5 step:5035 [D loss: 0.698032, acc.: 50.00%] [G loss: 0.700461]\n",
      "epoch:5 step:5036 [D loss: 0.708106, acc.: 42.97%] [G loss: 0.714963]\n",
      "epoch:5 step:5037 [D loss: 0.695512, acc.: 51.56%] [G loss: 0.703938]\n",
      "epoch:5 step:5038 [D loss: 0.704136, acc.: 44.53%] [G loss: 0.710599]\n",
      "epoch:5 step:5039 [D loss: 0.696902, acc.: 52.34%] [G loss: 0.705642]\n",
      "epoch:5 step:5040 [D loss: 0.703360, acc.: 46.09%] [G loss: 0.702689]\n",
      "epoch:5 step:5041 [D loss: 0.688511, acc.: 56.25%] [G loss: 0.710081]\n",
      "epoch:5 step:5042 [D loss: 0.692860, acc.: 52.34%] [G loss: 0.700567]\n",
      "epoch:5 step:5043 [D loss: 0.697173, acc.: 47.66%] [G loss: 0.719840]\n",
      "epoch:5 step:5044 [D loss: 0.680824, acc.: 57.03%] [G loss: 0.703789]\n",
      "epoch:5 step:5045 [D loss: 0.697086, acc.: 49.22%] [G loss: 0.707662]\n",
      "epoch:5 step:5046 [D loss: 0.688612, acc.: 47.66%] [G loss: 0.709050]\n",
      "epoch:5 step:5047 [D loss: 0.686668, acc.: 53.12%] [G loss: 0.704076]\n",
      "epoch:5 step:5048 [D loss: 0.693476, acc.: 56.25%] [G loss: 0.706526]\n",
      "epoch:5 step:5049 [D loss: 0.676778, acc.: 56.25%] [G loss: 0.701567]\n",
      "epoch:5 step:5050 [D loss: 0.686991, acc.: 47.66%] [G loss: 0.684425]\n",
      "epoch:5 step:5051 [D loss: 0.699605, acc.: 50.00%] [G loss: 0.696568]\n",
      "epoch:5 step:5052 [D loss: 0.693590, acc.: 50.00%] [G loss: 0.690580]\n",
      "epoch:5 step:5053 [D loss: 0.707175, acc.: 41.41%] [G loss: 0.694536]\n",
      "epoch:5 step:5054 [D loss: 0.694435, acc.: 46.09%] [G loss: 0.700405]\n",
      "epoch:5 step:5055 [D loss: 0.689996, acc.: 53.91%] [G loss: 0.705203]\n",
      "epoch:5 step:5056 [D loss: 0.688913, acc.: 47.66%] [G loss: 0.703619]\n",
      "epoch:5 step:5057 [D loss: 0.700889, acc.: 46.88%] [G loss: 0.717969]\n",
      "epoch:5 step:5058 [D loss: 0.707032, acc.: 50.78%] [G loss: 0.710551]\n",
      "epoch:5 step:5059 [D loss: 0.693009, acc.: 53.91%] [G loss: 0.715601]\n",
      "epoch:5 step:5060 [D loss: 0.693316, acc.: 56.25%] [G loss: 0.713062]\n",
      "epoch:5 step:5061 [D loss: 0.693793, acc.: 53.12%] [G loss: 0.732349]\n",
      "epoch:5 step:5062 [D loss: 0.697003, acc.: 45.31%] [G loss: 0.712216]\n",
      "epoch:5 step:5063 [D loss: 0.689167, acc.: 56.25%] [G loss: 0.723352]\n",
      "epoch:5 step:5064 [D loss: 0.682422, acc.: 57.03%] [G loss: 0.715769]\n",
      "epoch:5 step:5065 [D loss: 0.673592, acc.: 63.28%] [G loss: 0.730454]\n",
      "epoch:5 step:5066 [D loss: 0.694704, acc.: 53.12%] [G loss: 0.706050]\n",
      "epoch:5 step:5067 [D loss: 0.682841, acc.: 53.12%] [G loss: 0.722179]\n",
      "epoch:5 step:5068 [D loss: 0.681612, acc.: 55.47%] [G loss: 0.729529]\n",
      "epoch:5 step:5069 [D loss: 0.685242, acc.: 57.81%] [G loss: 0.782467]\n",
      "epoch:5 step:5070 [D loss: 0.680908, acc.: 58.59%] [G loss: 0.736110]\n",
      "epoch:5 step:5071 [D loss: 0.677784, acc.: 60.16%] [G loss: 0.697751]\n",
      "epoch:5 step:5072 [D loss: 0.671575, acc.: 56.25%] [G loss: 0.695319]\n",
      "epoch:5 step:5073 [D loss: 0.684385, acc.: 55.47%] [G loss: 0.752771]\n",
      "epoch:5 step:5074 [D loss: 0.698943, acc.: 52.34%] [G loss: 0.732954]\n",
      "epoch:5 step:5075 [D loss: 0.734193, acc.: 36.72%] [G loss: 0.702255]\n",
      "epoch:5 step:5076 [D loss: 0.713487, acc.: 38.28%] [G loss: 0.676312]\n",
      "epoch:5 step:5077 [D loss: 0.706866, acc.: 35.94%] [G loss: 0.702287]\n",
      "epoch:5 step:5078 [D loss: 0.711905, acc.: 38.28%] [G loss: 0.697761]\n",
      "epoch:5 step:5079 [D loss: 0.716155, acc.: 35.16%] [G loss: 0.699311]\n",
      "epoch:5 step:5080 [D loss: 0.706357, acc.: 39.06%] [G loss: 0.688484]\n",
      "epoch:5 step:5081 [D loss: 0.701120, acc.: 42.19%] [G loss: 0.711532]\n",
      "epoch:5 step:5082 [D loss: 0.694458, acc.: 46.88%] [G loss: 0.711021]\n",
      "epoch:5 step:5083 [D loss: 0.696837, acc.: 47.66%] [G loss: 0.700410]\n",
      "epoch:5 step:5084 [D loss: 0.692040, acc.: 53.91%] [G loss: 0.715464]\n",
      "epoch:5 step:5085 [D loss: 0.691761, acc.: 53.12%] [G loss: 0.716331]\n",
      "epoch:5 step:5086 [D loss: 0.689545, acc.: 47.66%] [G loss: 0.724559]\n",
      "epoch:5 step:5087 [D loss: 0.684564, acc.: 53.91%] [G loss: 0.722675]\n",
      "epoch:5 step:5088 [D loss: 0.705175, acc.: 44.53%] [G loss: 0.706860]\n",
      "epoch:5 step:5089 [D loss: 0.699619, acc.: 47.66%] [G loss: 0.706814]\n",
      "epoch:5 step:5090 [D loss: 0.684429, acc.: 53.91%] [G loss: 0.720676]\n",
      "epoch:5 step:5091 [D loss: 0.688754, acc.: 53.91%] [G loss: 0.728398]\n",
      "epoch:5 step:5092 [D loss: 0.677247, acc.: 59.38%] [G loss: 0.720427]\n",
      "epoch:5 step:5093 [D loss: 0.679823, acc.: 60.16%] [G loss: 0.702289]\n",
      "epoch:5 step:5094 [D loss: 0.677135, acc.: 59.38%] [G loss: 0.679910]\n",
      "epoch:5 step:5095 [D loss: 0.673921, acc.: 60.94%] [G loss: 0.742226]\n",
      "epoch:5 step:5096 [D loss: 0.732025, acc.: 40.62%] [G loss: 0.712451]\n",
      "epoch:5 step:5097 [D loss: 0.686584, acc.: 50.78%] [G loss: 0.709242]\n",
      "epoch:5 step:5098 [D loss: 0.696057, acc.: 47.66%] [G loss: 0.713162]\n",
      "epoch:5 step:5099 [D loss: 0.690555, acc.: 50.78%] [G loss: 0.698278]\n",
      "epoch:5 step:5100 [D loss: 0.700227, acc.: 46.88%] [G loss: 0.701190]\n",
      "epoch:5 step:5101 [D loss: 0.682338, acc.: 57.81%] [G loss: 0.721044]\n",
      "epoch:5 step:5102 [D loss: 0.688068, acc.: 59.38%] [G loss: 0.719768]\n",
      "epoch:5 step:5103 [D loss: 0.689093, acc.: 52.34%] [G loss: 0.727034]\n",
      "epoch:5 step:5104 [D loss: 0.686384, acc.: 60.16%] [G loss: 0.714141]\n",
      "epoch:5 step:5105 [D loss: 0.690874, acc.: 53.12%] [G loss: 0.694932]\n",
      "epoch:5 step:5106 [D loss: 0.705486, acc.: 49.22%] [G loss: 0.721093]\n",
      "epoch:5 step:5107 [D loss: 0.705435, acc.: 44.53%] [G loss: 0.712347]\n",
      "epoch:5 step:5108 [D loss: 0.702487, acc.: 52.34%] [G loss: 0.733124]\n",
      "epoch:5 step:5109 [D loss: 0.683033, acc.: 58.59%] [G loss: 0.745816]\n",
      "epoch:5 step:5110 [D loss: 0.683165, acc.: 54.69%] [G loss: 0.724551]\n",
      "epoch:5 step:5111 [D loss: 0.683654, acc.: 55.47%] [G loss: 0.721047]\n",
      "epoch:5 step:5112 [D loss: 0.678773, acc.: 59.38%] [G loss: 0.708386]\n",
      "epoch:5 step:5113 [D loss: 0.660519, acc.: 65.62%] [G loss: 0.729379]\n",
      "epoch:5 step:5114 [D loss: 0.657635, acc.: 64.06%] [G loss: 0.732555]\n",
      "epoch:5 step:5115 [D loss: 0.666550, acc.: 57.81%] [G loss: 0.750179]\n",
      "epoch:5 step:5116 [D loss: 0.696052, acc.: 45.31%] [G loss: 0.740679]\n",
      "epoch:5 step:5117 [D loss: 0.721932, acc.: 39.84%] [G loss: 0.721438]\n",
      "epoch:5 step:5118 [D loss: 0.700793, acc.: 46.09%] [G loss: 0.764648]\n",
      "epoch:5 step:5119 [D loss: 0.659150, acc.: 64.06%] [G loss: 0.761771]\n",
      "epoch:5 step:5120 [D loss: 0.684708, acc.: 57.03%] [G loss: 0.770805]\n",
      "epoch:5 step:5121 [D loss: 0.665408, acc.: 61.72%] [G loss: 0.778485]\n",
      "epoch:5 step:5122 [D loss: 0.726757, acc.: 43.75%] [G loss: 0.769919]\n",
      "epoch:5 step:5123 [D loss: 0.693205, acc.: 48.44%] [G loss: 0.758252]\n",
      "epoch:5 step:5124 [D loss: 0.715489, acc.: 40.62%] [G loss: 0.740780]\n",
      "epoch:5 step:5125 [D loss: 0.702068, acc.: 47.66%] [G loss: 0.750787]\n",
      "epoch:5 step:5126 [D loss: 0.707163, acc.: 45.31%] [G loss: 0.731778]\n",
      "epoch:5 step:5127 [D loss: 0.683179, acc.: 53.12%] [G loss: 0.745612]\n",
      "epoch:5 step:5128 [D loss: 0.694798, acc.: 54.69%] [G loss: 0.732974]\n",
      "epoch:5 step:5129 [D loss: 0.688831, acc.: 55.47%] [G loss: 0.727766]\n",
      "epoch:5 step:5130 [D loss: 0.687624, acc.: 52.34%] [G loss: 0.721579]\n",
      "epoch:5 step:5131 [D loss: 0.678716, acc.: 56.25%] [G loss: 0.715307]\n",
      "epoch:5 step:5132 [D loss: 0.688944, acc.: 51.56%] [G loss: 0.691175]\n",
      "epoch:5 step:5133 [D loss: 0.712886, acc.: 50.00%] [G loss: 0.730510]\n",
      "epoch:5 step:5134 [D loss: 0.697266, acc.: 51.56%] [G loss: 0.715068]\n",
      "epoch:5 step:5135 [D loss: 0.678155, acc.: 58.59%] [G loss: 0.686289]\n",
      "epoch:5 step:5136 [D loss: 0.677582, acc.: 59.38%] [G loss: 0.774389]\n",
      "epoch:5 step:5137 [D loss: 0.680926, acc.: 53.91%] [G loss: 0.700756]\n",
      "epoch:5 step:5138 [D loss: 0.695789, acc.: 51.56%] [G loss: 0.769471]\n",
      "epoch:5 step:5139 [D loss: 0.689031, acc.: 54.69%] [G loss: 0.663121]\n",
      "epoch:5 step:5140 [D loss: 0.712733, acc.: 43.75%] [G loss: 0.738029]\n",
      "epoch:5 step:5141 [D loss: 0.657295, acc.: 52.34%] [G loss: 0.825845]\n",
      "epoch:5 step:5142 [D loss: 0.677904, acc.: 64.06%] [G loss: 0.739020]\n",
      "epoch:5 step:5143 [D loss: 0.724175, acc.: 47.66%] [G loss: 0.714031]\n",
      "epoch:5 step:5144 [D loss: 0.678388, acc.: 57.81%] [G loss: 0.787702]\n",
      "epoch:5 step:5145 [D loss: 0.684277, acc.: 58.59%] [G loss: 0.646508]\n",
      "epoch:5 step:5146 [D loss: 0.702739, acc.: 48.44%] [G loss: 0.712258]\n",
      "epoch:5 step:5147 [D loss: 0.729210, acc.: 42.19%] [G loss: 0.749502]\n",
      "epoch:5 step:5148 [D loss: 0.674910, acc.: 56.25%] [G loss: 0.808546]\n",
      "epoch:5 step:5149 [D loss: 0.691829, acc.: 51.56%] [G loss: 0.772702]\n",
      "epoch:5 step:5150 [D loss: 0.689145, acc.: 64.06%] [G loss: 0.776362]\n",
      "epoch:5 step:5151 [D loss: 0.688971, acc.: 55.47%] [G loss: 0.767193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5152 [D loss: 0.706288, acc.: 50.78%] [G loss: 0.728468]\n",
      "epoch:5 step:5153 [D loss: 0.705816, acc.: 49.22%] [G loss: 0.735202]\n",
      "epoch:5 step:5154 [D loss: 0.698784, acc.: 51.56%] [G loss: 0.752533]\n",
      "epoch:5 step:5155 [D loss: 0.705413, acc.: 46.09%] [G loss: 0.756937]\n",
      "epoch:5 step:5156 [D loss: 0.689330, acc.: 55.47%] [G loss: 0.791022]\n",
      "epoch:5 step:5157 [D loss: 0.693025, acc.: 56.25%] [G loss: 0.776375]\n",
      "epoch:5 step:5158 [D loss: 0.673918, acc.: 62.50%] [G loss: 0.798571]\n",
      "epoch:5 step:5159 [D loss: 0.657904, acc.: 62.50%] [G loss: 0.824646]\n",
      "epoch:5 step:5160 [D loss: 0.649047, acc.: 67.97%] [G loss: 0.887571]\n",
      "epoch:5 step:5161 [D loss: 0.637517, acc.: 68.75%] [G loss: 1.008013]\n",
      "epoch:5 step:5162 [D loss: 0.697547, acc.: 53.91%] [G loss: 0.909397]\n",
      "epoch:5 step:5163 [D loss: 0.715645, acc.: 53.12%] [G loss: 0.742177]\n",
      "epoch:5 step:5164 [D loss: 0.745312, acc.: 29.69%] [G loss: 0.709435]\n",
      "epoch:5 step:5165 [D loss: 0.766662, acc.: 28.91%] [G loss: 0.674856]\n",
      "epoch:5 step:5166 [D loss: 0.740799, acc.: 35.16%] [G loss: 0.692244]\n",
      "epoch:5 step:5167 [D loss: 0.718041, acc.: 37.50%] [G loss: 0.675815]\n",
      "epoch:5 step:5168 [D loss: 0.702219, acc.: 40.62%] [G loss: 0.692756]\n",
      "epoch:5 step:5169 [D loss: 0.695998, acc.: 47.66%] [G loss: 0.695366]\n",
      "epoch:5 step:5170 [D loss: 0.701185, acc.: 42.97%] [G loss: 0.701573]\n",
      "epoch:5 step:5171 [D loss: 0.704888, acc.: 42.97%] [G loss: 0.707838]\n",
      "epoch:5 step:5172 [D loss: 0.701603, acc.: 44.53%] [G loss: 0.717985]\n",
      "epoch:5 step:5173 [D loss: 0.691680, acc.: 44.53%] [G loss: 0.726938]\n",
      "epoch:5 step:5174 [D loss: 0.686416, acc.: 49.22%] [G loss: 0.727472]\n",
      "epoch:5 step:5175 [D loss: 0.675919, acc.: 62.50%] [G loss: 0.750379]\n",
      "epoch:5 step:5176 [D loss: 0.673658, acc.: 59.38%] [G loss: 0.740938]\n",
      "epoch:5 step:5177 [D loss: 0.672767, acc.: 66.41%] [G loss: 0.768248]\n",
      "epoch:5 step:5178 [D loss: 0.677985, acc.: 62.50%] [G loss: 0.765469]\n",
      "epoch:5 step:5179 [D loss: 0.659667, acc.: 73.44%] [G loss: 0.752239]\n",
      "epoch:5 step:5180 [D loss: 0.665932, acc.: 62.50%] [G loss: 0.762176]\n",
      "epoch:5 step:5181 [D loss: 0.669745, acc.: 64.84%] [G loss: 0.769810]\n",
      "epoch:5 step:5182 [D loss: 0.674427, acc.: 63.28%] [G loss: 0.731553]\n",
      "epoch:5 step:5183 [D loss: 0.708369, acc.: 46.09%] [G loss: 0.718358]\n",
      "epoch:5 step:5184 [D loss: 0.708033, acc.: 49.22%] [G loss: 0.693921]\n",
      "epoch:5 step:5185 [D loss: 0.728415, acc.: 42.97%] [G loss: 0.711761]\n",
      "epoch:5 step:5186 [D loss: 0.730340, acc.: 38.28%] [G loss: 0.718640]\n",
      "epoch:5 step:5187 [D loss: 0.709857, acc.: 38.28%] [G loss: 0.723514]\n",
      "epoch:5 step:5188 [D loss: 0.696691, acc.: 52.34%] [G loss: 0.711159]\n",
      "epoch:5 step:5189 [D loss: 0.680280, acc.: 61.72%] [G loss: 0.747932]\n",
      "epoch:5 step:5190 [D loss: 0.675777, acc.: 60.94%] [G loss: 0.742959]\n",
      "epoch:5 step:5191 [D loss: 0.682745, acc.: 53.91%] [G loss: 0.776919]\n",
      "epoch:5 step:5192 [D loss: 0.665046, acc.: 62.50%] [G loss: 0.804541]\n",
      "epoch:5 step:5193 [D loss: 0.641825, acc.: 71.09%] [G loss: 0.811075]\n",
      "epoch:5 step:5194 [D loss: 0.713172, acc.: 46.88%] [G loss: 0.769231]\n",
      "epoch:5 step:5195 [D loss: 0.725944, acc.: 35.94%] [G loss: 0.754305]\n",
      "epoch:5 step:5196 [D loss: 0.715963, acc.: 46.09%] [G loss: 0.745083]\n",
      "epoch:5 step:5197 [D loss: 0.727139, acc.: 39.06%] [G loss: 0.726812]\n",
      "epoch:5 step:5198 [D loss: 0.703897, acc.: 42.97%] [G loss: 0.684870]\n",
      "epoch:5 step:5199 [D loss: 0.709804, acc.: 41.41%] [G loss: 0.716177]\n",
      "epoch:5 step:5200 [D loss: 0.699912, acc.: 43.75%] [G loss: 0.706048]\n",
      "epoch:5 step:5201 [D loss: 0.701797, acc.: 46.09%] [G loss: 0.700030]\n",
      "epoch:5 step:5202 [D loss: 0.701590, acc.: 40.62%] [G loss: 0.704248]\n",
      "epoch:5 step:5203 [D loss: 0.695723, acc.: 43.75%] [G loss: 0.694214]\n",
      "epoch:5 step:5204 [D loss: 0.682996, acc.: 53.91%] [G loss: 0.706038]\n",
      "epoch:5 step:5205 [D loss: 0.679356, acc.: 57.03%] [G loss: 0.692453]\n",
      "epoch:5 step:5206 [D loss: 0.679435, acc.: 60.94%] [G loss: 0.689147]\n",
      "epoch:5 step:5207 [D loss: 0.684619, acc.: 57.81%] [G loss: 0.673709]\n",
      "epoch:5 step:5208 [D loss: 0.685771, acc.: 54.69%] [G loss: 0.708845]\n",
      "epoch:5 step:5209 [D loss: 0.700780, acc.: 39.06%] [G loss: 0.704555]\n",
      "epoch:5 step:5210 [D loss: 0.687925, acc.: 42.19%] [G loss: 0.717194]\n",
      "epoch:5 step:5211 [D loss: 0.673808, acc.: 60.94%] [G loss: 0.731386]\n",
      "epoch:5 step:5212 [D loss: 0.683176, acc.: 57.03%] [G loss: 0.715920]\n",
      "epoch:5 step:5213 [D loss: 0.688177, acc.: 58.59%] [G loss: 0.806136]\n",
      "epoch:5 step:5214 [D loss: 0.711291, acc.: 47.66%] [G loss: 0.700395]\n",
      "epoch:5 step:5215 [D loss: 0.686303, acc.: 53.91%] [G loss: 0.678899]\n",
      "epoch:5 step:5216 [D loss: 0.699785, acc.: 50.00%] [G loss: 0.700407]\n",
      "epoch:5 step:5217 [D loss: 0.692875, acc.: 52.34%] [G loss: 0.700686]\n",
      "epoch:5 step:5218 [D loss: 0.708341, acc.: 41.41%] [G loss: 0.697127]\n",
      "epoch:5 step:5219 [D loss: 0.692483, acc.: 55.47%] [G loss: 0.705450]\n",
      "epoch:5 step:5220 [D loss: 0.694323, acc.: 53.91%] [G loss: 0.695697]\n",
      "epoch:5 step:5221 [D loss: 0.689143, acc.: 57.03%] [G loss: 0.701005]\n",
      "epoch:5 step:5222 [D loss: 0.692630, acc.: 46.09%] [G loss: 0.689548]\n",
      "epoch:5 step:5223 [D loss: 0.707336, acc.: 45.31%] [G loss: 0.685413]\n",
      "epoch:5 step:5224 [D loss: 0.695190, acc.: 45.31%] [G loss: 0.704263]\n",
      "epoch:5 step:5225 [D loss: 0.696114, acc.: 46.09%] [G loss: 0.702790]\n",
      "epoch:5 step:5226 [D loss: 0.693112, acc.: 48.44%] [G loss: 0.706897]\n",
      "epoch:5 step:5227 [D loss: 0.718343, acc.: 39.84%] [G loss: 0.730508]\n",
      "epoch:5 step:5228 [D loss: 0.683344, acc.: 47.66%] [G loss: 0.721019]\n",
      "epoch:5 step:5229 [D loss: 0.707510, acc.: 44.53%] [G loss: 0.725117]\n",
      "epoch:5 step:5230 [D loss: 0.688616, acc.: 53.12%] [G loss: 0.732691]\n",
      "epoch:5 step:5231 [D loss: 0.705853, acc.: 40.62%] [G loss: 0.732972]\n",
      "epoch:5 step:5232 [D loss: 0.700678, acc.: 47.66%] [G loss: 0.728295]\n",
      "epoch:5 step:5233 [D loss: 0.691632, acc.: 54.69%] [G loss: 0.717028]\n",
      "epoch:5 step:5234 [D loss: 0.706685, acc.: 45.31%] [G loss: 0.725715]\n",
      "epoch:5 step:5235 [D loss: 0.567841, acc.: 71.88%] [G loss: 0.735437]\n",
      "epoch:5 step:5236 [D loss: 0.705449, acc.: 53.91%] [G loss: 0.740323]\n",
      "epoch:5 step:5237 [D loss: 0.684680, acc.: 57.03%] [G loss: 0.740124]\n",
      "epoch:5 step:5238 [D loss: 0.691523, acc.: 53.91%] [G loss: 0.725819]\n",
      "epoch:5 step:5239 [D loss: 0.649061, acc.: 71.09%] [G loss: 0.729234]\n",
      "epoch:5 step:5240 [D loss: 0.695568, acc.: 55.47%] [G loss: 0.745923]\n",
      "epoch:5 step:5241 [D loss: 0.693313, acc.: 53.12%] [G loss: 0.749194]\n",
      "epoch:5 step:5242 [D loss: 0.675665, acc.: 57.81%] [G loss: 0.743942]\n",
      "epoch:5 step:5243 [D loss: 0.673024, acc.: 64.84%] [G loss: 0.743604]\n",
      "epoch:5 step:5244 [D loss: 0.720762, acc.: 40.62%] [G loss: 0.737678]\n",
      "epoch:5 step:5245 [D loss: 0.710483, acc.: 44.53%] [G loss: 0.729025]\n",
      "epoch:5 step:5246 [D loss: 0.722006, acc.: 40.62%] [G loss: 0.723516]\n",
      "epoch:5 step:5247 [D loss: 0.708538, acc.: 46.88%] [G loss: 0.727090]\n",
      "epoch:5 step:5248 [D loss: 0.695610, acc.: 53.91%] [G loss: 0.729400]\n",
      "epoch:5 step:5249 [D loss: 0.700098, acc.: 50.78%] [G loss: 0.722184]\n",
      "epoch:5 step:5250 [D loss: 0.705505, acc.: 46.88%] [G loss: 0.732946]\n",
      "epoch:5 step:5251 [D loss: 0.705330, acc.: 39.06%] [G loss: 0.721147]\n",
      "epoch:5 step:5252 [D loss: 0.703517, acc.: 36.72%] [G loss: 0.732132]\n",
      "epoch:5 step:5253 [D loss: 0.691839, acc.: 46.09%] [G loss: 0.722848]\n",
      "epoch:5 step:5254 [D loss: 0.694621, acc.: 50.78%] [G loss: 0.729259]\n",
      "epoch:5 step:5255 [D loss: 0.685298, acc.: 55.47%] [G loss: 0.739075]\n",
      "epoch:5 step:5256 [D loss: 0.685612, acc.: 55.47%] [G loss: 0.753827]\n",
      "epoch:5 step:5257 [D loss: 0.681895, acc.: 53.12%] [G loss: 0.730534]\n",
      "epoch:5 step:5258 [D loss: 0.691623, acc.: 48.44%] [G loss: 0.730231]\n",
      "epoch:5 step:5259 [D loss: 0.676359, acc.: 53.12%] [G loss: 0.727048]\n",
      "epoch:5 step:5260 [D loss: 0.680576, acc.: 56.25%] [G loss: 0.732294]\n",
      "epoch:5 step:5261 [D loss: 0.710147, acc.: 42.19%] [G loss: 0.738606]\n",
      "epoch:5 step:5262 [D loss: 0.682089, acc.: 58.59%] [G loss: 0.740723]\n",
      "epoch:5 step:5263 [D loss: 0.686685, acc.: 56.25%] [G loss: 0.744846]\n",
      "epoch:5 step:5264 [D loss: 0.681736, acc.: 55.47%] [G loss: 0.785377]\n",
      "epoch:5 step:5265 [D loss: 0.694879, acc.: 54.69%] [G loss: 0.698103]\n",
      "epoch:5 step:5266 [D loss: 0.690170, acc.: 51.56%] [G loss: 0.726850]\n",
      "epoch:5 step:5267 [D loss: 0.685717, acc.: 57.81%] [G loss: 0.717554]\n",
      "epoch:5 step:5268 [D loss: 0.707747, acc.: 44.53%] [G loss: 0.504893]\n",
      "epoch:5 step:5269 [D loss: 0.721617, acc.: 41.41%] [G loss: 0.714675]\n",
      "epoch:5 step:5270 [D loss: 0.939228, acc.: 28.91%] [G loss: 0.733979]\n",
      "epoch:5 step:5271 [D loss: 0.699733, acc.: 53.12%] [G loss: 0.753969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5272 [D loss: 0.693879, acc.: 53.91%] [G loss: 0.776388]\n",
      "epoch:5 step:5273 [D loss: 0.693554, acc.: 48.44%] [G loss: 0.786219]\n",
      "epoch:5 step:5274 [D loss: 0.701079, acc.: 46.88%] [G loss: 0.748654]\n",
      "epoch:5 step:5275 [D loss: 0.693876, acc.: 48.44%] [G loss: 0.754316]\n",
      "epoch:5 step:5276 [D loss: 0.724874, acc.: 39.84%] [G loss: 0.730810]\n",
      "epoch:5 step:5277 [D loss: 0.712705, acc.: 51.56%] [G loss: 0.753210]\n",
      "epoch:5 step:5278 [D loss: 0.696354, acc.: 46.88%] [G loss: 0.719066]\n",
      "epoch:5 step:5279 [D loss: 0.688339, acc.: 49.22%] [G loss: 0.701608]\n",
      "epoch:5 step:5280 [D loss: 0.692950, acc.: 51.56%] [G loss: 0.708354]\n",
      "epoch:5 step:5281 [D loss: 0.776755, acc.: 36.72%] [G loss: 0.705647]\n",
      "epoch:5 step:5282 [D loss: 0.684826, acc.: 57.03%] [G loss: 0.695355]\n",
      "epoch:5 step:5283 [D loss: 0.689581, acc.: 57.03%] [G loss: 0.699079]\n",
      "epoch:5 step:5284 [D loss: 0.697601, acc.: 47.66%] [G loss: 0.693981]\n",
      "epoch:5 step:5285 [D loss: 0.697731, acc.: 48.44%] [G loss: 0.681694]\n",
      "epoch:5 step:5286 [D loss: 0.684479, acc.: 57.03%] [G loss: 0.686332]\n",
      "epoch:5 step:5287 [D loss: 0.702175, acc.: 47.66%] [G loss: 0.680609]\n",
      "epoch:5 step:5288 [D loss: 0.709502, acc.: 43.75%] [G loss: 0.687466]\n",
      "epoch:5 step:5289 [D loss: 0.644312, acc.: 48.44%] [G loss: 0.729182]\n",
      "epoch:5 step:5290 [D loss: 0.698968, acc.: 52.34%] [G loss: 0.683342]\n",
      "epoch:5 step:5291 [D loss: 0.694941, acc.: 52.34%] [G loss: 0.688911]\n",
      "epoch:5 step:5292 [D loss: 0.703457, acc.: 46.88%] [G loss: 0.687001]\n",
      "epoch:5 step:5293 [D loss: 0.702118, acc.: 47.66%] [G loss: 0.720269]\n",
      "epoch:5 step:5294 [D loss: 0.685849, acc.: 54.69%] [G loss: 0.728394]\n",
      "epoch:5 step:5295 [D loss: 0.691133, acc.: 52.34%] [G loss: 0.771647]\n",
      "epoch:5 step:5296 [D loss: 0.654537, acc.: 68.75%] [G loss: 0.828131]\n",
      "epoch:5 step:5297 [D loss: 0.662388, acc.: 64.84%] [G loss: 0.818290]\n",
      "epoch:5 step:5298 [D loss: 0.655381, acc.: 64.84%] [G loss: 0.753689]\n",
      "epoch:5 step:5299 [D loss: 0.696061, acc.: 46.88%] [G loss: 0.723115]\n",
      "epoch:5 step:5300 [D loss: 0.753021, acc.: 42.19%] [G loss: 0.721993]\n",
      "epoch:5 step:5301 [D loss: 0.717125, acc.: 45.31%] [G loss: 0.690713]\n",
      "epoch:5 step:5302 [D loss: 0.714742, acc.: 40.62%] [G loss: 0.688229]\n",
      "epoch:5 step:5303 [D loss: 0.696592, acc.: 46.09%] [G loss: 0.694447]\n",
      "epoch:5 step:5304 [D loss: 0.697345, acc.: 46.09%] [G loss: 0.702979]\n",
      "epoch:5 step:5305 [D loss: 0.699146, acc.: 39.84%] [G loss: 0.549672]\n",
      "epoch:5 step:5306 [D loss: 0.701274, acc.: 45.31%] [G loss: 0.718050]\n",
      "epoch:5 step:5307 [D loss: 0.700237, acc.: 44.53%] [G loss: 0.717304]\n",
      "epoch:5 step:5308 [D loss: 0.692069, acc.: 51.56%] [G loss: 0.730847]\n",
      "epoch:5 step:5309 [D loss: 0.684218, acc.: 54.69%] [G loss: 0.744183]\n",
      "epoch:5 step:5310 [D loss: 0.671774, acc.: 64.84%] [G loss: 0.743684]\n",
      "epoch:5 step:5311 [D loss: 0.681604, acc.: 59.38%] [G loss: 0.743980]\n",
      "epoch:5 step:5312 [D loss: 0.680613, acc.: 59.38%] [G loss: 0.731106]\n",
      "epoch:5 step:5313 [D loss: 0.679247, acc.: 63.28%] [G loss: 0.719842]\n",
      "epoch:5 step:5314 [D loss: 0.679542, acc.: 58.59%] [G loss: 0.736025]\n",
      "epoch:5 step:5315 [D loss: 0.680067, acc.: 61.72%] [G loss: 0.717785]\n",
      "epoch:5 step:5316 [D loss: 0.682121, acc.: 59.38%] [G loss: 0.708899]\n",
      "epoch:5 step:5317 [D loss: 0.696363, acc.: 46.88%] [G loss: 0.717028]\n",
      "epoch:5 step:5318 [D loss: 0.710718, acc.: 46.09%] [G loss: 0.726311]\n",
      "epoch:5 step:5319 [D loss: 0.725068, acc.: 39.06%] [G loss: 0.692072]\n",
      "epoch:5 step:5320 [D loss: 0.711052, acc.: 38.28%] [G loss: 0.698359]\n",
      "epoch:5 step:5321 [D loss: 0.707440, acc.: 47.66%] [G loss: 0.690826]\n",
      "epoch:5 step:5322 [D loss: 0.707281, acc.: 39.84%] [G loss: 0.686814]\n",
      "epoch:5 step:5323 [D loss: 0.697336, acc.: 46.88%] [G loss: 0.700959]\n",
      "epoch:5 step:5324 [D loss: 0.704042, acc.: 40.62%] [G loss: 0.704840]\n",
      "epoch:5 step:5325 [D loss: 0.706075, acc.: 42.97%] [G loss: 0.707236]\n",
      "epoch:5 step:5326 [D loss: 0.692451, acc.: 50.78%] [G loss: 0.732990]\n",
      "epoch:5 step:5327 [D loss: 0.684006, acc.: 53.91%] [G loss: 0.740952]\n",
      "epoch:5 step:5328 [D loss: 0.685271, acc.: 59.38%] [G loss: 0.738379]\n",
      "epoch:5 step:5329 [D loss: 0.693816, acc.: 55.47%] [G loss: 0.762223]\n",
      "epoch:5 step:5330 [D loss: 0.698695, acc.: 49.22%] [G loss: 0.757196]\n",
      "epoch:5 step:5331 [D loss: 0.668355, acc.: 66.41%] [G loss: 0.786306]\n",
      "epoch:5 step:5332 [D loss: 0.671174, acc.: 60.94%] [G loss: 0.752410]\n",
      "epoch:5 step:5333 [D loss: 0.670655, acc.: 69.53%] [G loss: 0.773279]\n",
      "epoch:5 step:5334 [D loss: 0.676507, acc.: 54.69%] [G loss: 0.742595]\n",
      "epoch:5 step:5335 [D loss: 0.657355, acc.: 65.62%] [G loss: 0.771804]\n",
      "epoch:5 step:5336 [D loss: 0.667258, acc.: 63.28%] [G loss: 0.779833]\n",
      "epoch:5 step:5337 [D loss: 0.710788, acc.: 45.31%] [G loss: 0.777654]\n",
      "epoch:5 step:5338 [D loss: 0.740588, acc.: 37.50%] [G loss: 0.738779]\n",
      "epoch:5 step:5339 [D loss: 0.714118, acc.: 42.19%] [G loss: 0.728064]\n",
      "epoch:5 step:5340 [D loss: 0.702560, acc.: 50.78%] [G loss: 0.703831]\n",
      "epoch:5 step:5341 [D loss: 0.699883, acc.: 50.00%] [G loss: 0.720419]\n",
      "epoch:5 step:5342 [D loss: 0.685119, acc.: 56.25%] [G loss: 0.729397]\n",
      "epoch:5 step:5343 [D loss: 0.705061, acc.: 49.22%] [G loss: 0.693282]\n",
      "epoch:5 step:5344 [D loss: 0.685535, acc.: 54.69%] [G loss: 0.699739]\n",
      "epoch:5 step:5345 [D loss: 0.684929, acc.: 51.56%] [G loss: 0.706415]\n",
      "epoch:5 step:5346 [D loss: 0.682021, acc.: 56.25%] [G loss: 0.701886]\n",
      "epoch:5 step:5347 [D loss: 0.700015, acc.: 50.78%] [G loss: 0.712510]\n",
      "epoch:5 step:5348 [D loss: 0.710063, acc.: 39.84%] [G loss: 0.714232]\n",
      "epoch:5 step:5349 [D loss: 0.706900, acc.: 48.44%] [G loss: 0.712340]\n",
      "epoch:5 step:5350 [D loss: 0.703795, acc.: 47.66%] [G loss: 0.709442]\n",
      "epoch:5 step:5351 [D loss: 0.693317, acc.: 50.00%] [G loss: 0.702685]\n",
      "epoch:5 step:5352 [D loss: 0.696661, acc.: 45.31%] [G loss: 0.708691]\n",
      "epoch:5 step:5353 [D loss: 0.685349, acc.: 53.91%] [G loss: 0.734754]\n",
      "epoch:5 step:5354 [D loss: 0.689973, acc.: 52.34%] [G loss: 0.731074]\n",
      "epoch:5 step:5355 [D loss: 0.695508, acc.: 50.00%] [G loss: 0.726162]\n",
      "epoch:5 step:5356 [D loss: 0.700006, acc.: 40.62%] [G loss: 0.721148]\n",
      "epoch:5 step:5357 [D loss: 0.689408, acc.: 55.47%] [G loss: 0.705333]\n",
      "epoch:5 step:5358 [D loss: 0.671950, acc.: 60.94%] [G loss: 0.721270]\n",
      "epoch:5 step:5359 [D loss: 0.658419, acc.: 68.75%] [G loss: 0.738803]\n",
      "epoch:5 step:5360 [D loss: 0.691890, acc.: 51.56%] [G loss: 0.719067]\n",
      "epoch:5 step:5361 [D loss: 0.700156, acc.: 49.22%] [G loss: 0.713295]\n",
      "epoch:5 step:5362 [D loss: 0.677524, acc.: 62.50%] [G loss: 0.705875]\n",
      "epoch:5 step:5363 [D loss: 0.697769, acc.: 48.44%] [G loss: 0.693238]\n",
      "epoch:5 step:5364 [D loss: 0.709082, acc.: 42.97%] [G loss: 0.681368]\n",
      "epoch:5 step:5365 [D loss: 0.703362, acc.: 47.66%] [G loss: 0.704298]\n",
      "epoch:5 step:5366 [D loss: 0.693439, acc.: 49.22%] [G loss: 0.690901]\n",
      "epoch:5 step:5367 [D loss: 0.707877, acc.: 42.97%] [G loss: 0.696143]\n",
      "epoch:5 step:5368 [D loss: 0.695471, acc.: 53.91%] [G loss: 0.696796]\n",
      "epoch:5 step:5369 [D loss: 0.690771, acc.: 52.34%] [G loss: 0.693191]\n",
      "epoch:5 step:5370 [D loss: 0.690526, acc.: 53.12%] [G loss: 0.703531]\n",
      "epoch:5 step:5371 [D loss: 0.698089, acc.: 52.34%] [G loss: 0.720039]\n",
      "epoch:5 step:5372 [D loss: 0.687568, acc.: 51.56%] [G loss: 0.727279]\n",
      "epoch:5 step:5373 [D loss: 0.686194, acc.: 53.91%] [G loss: 0.724496]\n",
      "epoch:5 step:5374 [D loss: 0.693599, acc.: 53.12%] [G loss: 0.716329]\n",
      "epoch:5 step:5375 [D loss: 0.697750, acc.: 52.34%] [G loss: 0.718423]\n",
      "epoch:5 step:5376 [D loss: 0.696180, acc.: 50.00%] [G loss: 0.747402]\n",
      "epoch:5 step:5377 [D loss: 0.689465, acc.: 54.69%] [G loss: 0.732748]\n",
      "epoch:5 step:5378 [D loss: 0.677209, acc.: 60.16%] [G loss: 0.733024]\n",
      "epoch:5 step:5379 [D loss: 0.687418, acc.: 54.69%] [G loss: 0.732169]\n",
      "epoch:5 step:5380 [D loss: 0.691751, acc.: 52.34%] [G loss: 0.691072]\n",
      "epoch:5 step:5381 [D loss: 0.702309, acc.: 50.78%] [G loss: 0.720169]\n",
      "epoch:5 step:5382 [D loss: 0.707401, acc.: 49.22%] [G loss: 0.719382]\n",
      "epoch:5 step:5383 [D loss: 0.691052, acc.: 50.78%] [G loss: 0.714443]\n",
      "epoch:5 step:5384 [D loss: 0.686214, acc.: 56.25%] [G loss: 0.724497]\n",
      "epoch:5 step:5385 [D loss: 0.695107, acc.: 54.69%] [G loss: 0.732199]\n",
      "epoch:5 step:5386 [D loss: 0.700634, acc.: 46.09%] [G loss: 0.716583]\n",
      "epoch:5 step:5387 [D loss: 0.686744, acc.: 50.00%] [G loss: 0.733893]\n",
      "epoch:5 step:5388 [D loss: 0.716203, acc.: 39.06%] [G loss: 0.730551]\n",
      "epoch:5 step:5389 [D loss: 0.700585, acc.: 43.75%] [G loss: 0.708404]\n",
      "epoch:5 step:5390 [D loss: 0.713573, acc.: 38.28%] [G loss: 0.686676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5391 [D loss: 0.695483, acc.: 52.34%] [G loss: 0.711137]\n",
      "epoch:5 step:5392 [D loss: 0.679956, acc.: 59.38%] [G loss: 0.685801]\n",
      "epoch:5 step:5393 [D loss: 0.674223, acc.: 67.97%] [G loss: 0.695189]\n",
      "epoch:5 step:5394 [D loss: 0.705318, acc.: 46.09%] [G loss: 0.647479]\n",
      "epoch:5 step:5395 [D loss: 0.725754, acc.: 39.06%] [G loss: 0.734492]\n",
      "epoch:5 step:5396 [D loss: 0.719153, acc.: 33.59%] [G loss: 0.716693]\n",
      "epoch:5 step:5397 [D loss: 0.689884, acc.: 53.91%] [G loss: 0.697995]\n",
      "epoch:5 step:5398 [D loss: 0.678479, acc.: 62.50%] [G loss: 0.700837]\n",
      "epoch:5 step:5399 [D loss: 0.674574, acc.: 62.50%] [G loss: 0.720470]\n",
      "epoch:5 step:5400 [D loss: 0.704374, acc.: 48.44%] [G loss: 0.724913]\n",
      "epoch:5 step:5401 [D loss: 0.698407, acc.: 46.09%] [G loss: 0.698574]\n",
      "epoch:5 step:5402 [D loss: 0.692031, acc.: 53.12%] [G loss: 0.707168]\n",
      "epoch:5 step:5403 [D loss: 0.703220, acc.: 46.88%] [G loss: 0.724700]\n",
      "epoch:5 step:5404 [D loss: 0.696957, acc.: 48.44%] [G loss: 0.738747]\n",
      "epoch:5 step:5405 [D loss: 0.689622, acc.: 49.22%] [G loss: 0.738353]\n",
      "epoch:5 step:5406 [D loss: 0.677099, acc.: 58.59%] [G loss: 0.760201]\n",
      "epoch:5 step:5407 [D loss: 0.708467, acc.: 46.88%] [G loss: 0.732736]\n",
      "epoch:5 step:5408 [D loss: 0.694233, acc.: 52.34%] [G loss: 0.727907]\n",
      "epoch:5 step:5409 [D loss: 0.685041, acc.: 53.12%] [G loss: 0.715261]\n",
      "epoch:5 step:5410 [D loss: 0.685302, acc.: 59.38%] [G loss: 0.777664]\n",
      "epoch:5 step:5411 [D loss: 0.702791, acc.: 44.53%] [G loss: 0.720658]\n",
      "epoch:5 step:5412 [D loss: 0.719914, acc.: 40.62%] [G loss: 0.744554]\n",
      "epoch:5 step:5413 [D loss: 0.704547, acc.: 44.53%] [G loss: 0.717977]\n",
      "epoch:5 step:5414 [D loss: 0.680839, acc.: 62.50%] [G loss: 0.733726]\n",
      "epoch:5 step:5415 [D loss: 0.703426, acc.: 47.66%] [G loss: 0.715660]\n",
      "epoch:5 step:5416 [D loss: 0.700340, acc.: 45.31%] [G loss: 0.728172]\n",
      "epoch:5 step:5417 [D loss: 0.685724, acc.: 55.47%] [G loss: 0.729487]\n",
      "epoch:5 step:5418 [D loss: 0.688081, acc.: 59.38%] [G loss: 0.739713]\n",
      "epoch:5 step:5419 [D loss: 0.688467, acc.: 50.78%] [G loss: 0.722943]\n",
      "epoch:5 step:5420 [D loss: 0.684897, acc.: 58.59%] [G loss: 0.723620]\n",
      "epoch:5 step:5421 [D loss: 0.681623, acc.: 61.72%] [G loss: 0.739475]\n",
      "epoch:5 step:5422 [D loss: 0.691767, acc.: 55.47%] [G loss: 0.730908]\n",
      "epoch:5 step:5423 [D loss: 0.698978, acc.: 50.78%] [G loss: 0.722806]\n",
      "epoch:5 step:5424 [D loss: 0.714341, acc.: 41.41%] [G loss: 0.727742]\n",
      "epoch:5 step:5425 [D loss: 0.705958, acc.: 44.53%] [G loss: 0.700775]\n",
      "epoch:5 step:5426 [D loss: 0.694087, acc.: 53.12%] [G loss: 0.706498]\n",
      "epoch:5 step:5427 [D loss: 0.693923, acc.: 50.00%] [G loss: 0.691710]\n",
      "epoch:5 step:5428 [D loss: 0.693444, acc.: 51.56%] [G loss: 0.696390]\n",
      "epoch:5 step:5429 [D loss: 0.702516, acc.: 43.75%] [G loss: 0.693577]\n",
      "epoch:5 step:5430 [D loss: 0.700843, acc.: 46.09%] [G loss: 0.697993]\n",
      "epoch:5 step:5431 [D loss: 0.694533, acc.: 52.34%] [G loss: 0.704138]\n",
      "epoch:5 step:5432 [D loss: 0.701308, acc.: 51.56%] [G loss: 0.690470]\n",
      "epoch:5 step:5433 [D loss: 0.704197, acc.: 43.75%] [G loss: 0.696106]\n",
      "epoch:5 step:5434 [D loss: 0.692955, acc.: 50.00%] [G loss: 0.696687]\n",
      "epoch:5 step:5435 [D loss: 0.704772, acc.: 47.66%] [G loss: 0.689600]\n",
      "epoch:5 step:5436 [D loss: 0.698721, acc.: 50.00%] [G loss: 0.697182]\n",
      "epoch:5 step:5437 [D loss: 0.705926, acc.: 39.06%] [G loss: 0.698910]\n",
      "epoch:5 step:5438 [D loss: 0.698508, acc.: 43.75%] [G loss: 0.686969]\n",
      "epoch:5 step:5439 [D loss: 0.690795, acc.: 55.47%] [G loss: 0.694671]\n",
      "epoch:5 step:5440 [D loss: 0.691202, acc.: 51.56%] [G loss: 0.698614]\n",
      "epoch:5 step:5441 [D loss: 0.685353, acc.: 57.81%] [G loss: 0.688990]\n",
      "epoch:5 step:5442 [D loss: 0.695382, acc.: 51.56%] [G loss: 0.689320]\n",
      "epoch:5 step:5443 [D loss: 0.691188, acc.: 46.09%] [G loss: 0.709646]\n",
      "epoch:5 step:5444 [D loss: 0.701071, acc.: 45.31%] [G loss: 0.696883]\n",
      "epoch:5 step:5445 [D loss: 0.703949, acc.: 47.66%] [G loss: 0.710125]\n",
      "epoch:5 step:5446 [D loss: 0.685674, acc.: 62.50%] [G loss: 0.719217]\n",
      "epoch:5 step:5447 [D loss: 0.683948, acc.: 60.94%] [G loss: 0.717683]\n",
      "epoch:5 step:5448 [D loss: 0.693424, acc.: 55.47%] [G loss: 0.712583]\n",
      "epoch:5 step:5449 [D loss: 0.695494, acc.: 50.78%] [G loss: 0.732909]\n",
      "epoch:5 step:5450 [D loss: 0.687747, acc.: 57.03%] [G loss: 0.714762]\n",
      "epoch:5 step:5451 [D loss: 0.680176, acc.: 61.72%] [G loss: 0.717011]\n",
      "epoch:5 step:5452 [D loss: 0.677147, acc.: 56.25%] [G loss: 0.745848]\n",
      "epoch:5 step:5453 [D loss: 0.688978, acc.: 52.34%] [G loss: 0.725043]\n",
      "epoch:5 step:5454 [D loss: 0.686014, acc.: 55.47%] [G loss: 0.731969]\n",
      "epoch:5 step:5455 [D loss: 0.685657, acc.: 51.56%] [G loss: 0.746970]\n",
      "epoch:5 step:5456 [D loss: 0.692123, acc.: 52.34%] [G loss: 0.742140]\n",
      "epoch:5 step:5457 [D loss: 0.688772, acc.: 53.12%] [G loss: 0.734864]\n",
      "epoch:5 step:5458 [D loss: 0.690005, acc.: 53.12%] [G loss: 0.720088]\n",
      "epoch:5 step:5459 [D loss: 0.671642, acc.: 60.16%] [G loss: 0.711344]\n",
      "epoch:5 step:5460 [D loss: 0.685734, acc.: 53.12%] [G loss: 0.701088]\n",
      "epoch:5 step:5461 [D loss: 0.708140, acc.: 43.75%] [G loss: 0.706574]\n",
      "epoch:5 step:5462 [D loss: 0.694493, acc.: 53.12%] [G loss: 0.699519]\n",
      "epoch:5 step:5463 [D loss: 0.699834, acc.: 51.56%] [G loss: 0.713591]\n",
      "epoch:5 step:5464 [D loss: 0.704692, acc.: 47.66%] [G loss: 0.726590]\n",
      "epoch:5 step:5465 [D loss: 0.720850, acc.: 37.50%] [G loss: 0.720854]\n",
      "epoch:5 step:5466 [D loss: 0.703719, acc.: 47.66%] [G loss: 0.717485]\n",
      "epoch:5 step:5467 [D loss: 0.689415, acc.: 52.34%] [G loss: 0.709524]\n",
      "epoch:5 step:5468 [D loss: 0.697866, acc.: 50.00%] [G loss: 0.736021]\n",
      "epoch:5 step:5469 [D loss: 0.695766, acc.: 50.00%] [G loss: 0.755774]\n",
      "epoch:5 step:5470 [D loss: 0.679972, acc.: 61.72%] [G loss: 0.749999]\n",
      "epoch:5 step:5471 [D loss: 0.693831, acc.: 55.47%] [G loss: 0.762241]\n",
      "epoch:5 step:5472 [D loss: 0.695720, acc.: 49.22%] [G loss: 0.728947]\n",
      "epoch:5 step:5473 [D loss: 0.698478, acc.: 51.56%] [G loss: 0.718986]\n",
      "epoch:5 step:5474 [D loss: 0.690891, acc.: 52.34%] [G loss: 0.730562]\n",
      "epoch:5 step:5475 [D loss: 0.697785, acc.: 46.88%] [G loss: 0.720799]\n",
      "epoch:5 step:5476 [D loss: 0.704241, acc.: 43.75%] [G loss: 0.717998]\n",
      "epoch:5 step:5477 [D loss: 0.711507, acc.: 40.62%] [G loss: 0.695246]\n",
      "epoch:5 step:5478 [D loss: 0.697072, acc.: 49.22%] [G loss: 0.702171]\n",
      "epoch:5 step:5479 [D loss: 0.690469, acc.: 50.78%] [G loss: 0.705613]\n",
      "epoch:5 step:5480 [D loss: 0.697661, acc.: 45.31%] [G loss: 0.711917]\n",
      "epoch:5 step:5481 [D loss: 0.694806, acc.: 48.44%] [G loss: 0.705244]\n",
      "epoch:5 step:5482 [D loss: 0.704949, acc.: 48.44%] [G loss: 0.696728]\n",
      "epoch:5 step:5483 [D loss: 0.693338, acc.: 53.12%] [G loss: 0.698887]\n",
      "epoch:5 step:5484 [D loss: 0.693695, acc.: 53.91%] [G loss: 0.686632]\n",
      "epoch:5 step:5485 [D loss: 0.703263, acc.: 46.09%] [G loss: 0.688162]\n",
      "epoch:5 step:5486 [D loss: 0.704766, acc.: 46.88%] [G loss: 0.706161]\n",
      "epoch:5 step:5487 [D loss: 0.589930, acc.: 61.72%] [G loss: 0.722771]\n",
      "epoch:5 step:5488 [D loss: 0.693287, acc.: 60.16%] [G loss: 0.719129]\n",
      "epoch:5 step:5489 [D loss: 0.706932, acc.: 50.78%] [G loss: 0.709578]\n",
      "epoch:5 step:5490 [D loss: 0.698416, acc.: 53.91%] [G loss: 0.708681]\n",
      "epoch:5 step:5491 [D loss: 0.687841, acc.: 53.91%] [G loss: 0.697235]\n",
      "epoch:5 step:5492 [D loss: 0.688729, acc.: 53.91%] [G loss: 0.705666]\n",
      "epoch:5 step:5493 [D loss: 0.690731, acc.: 50.00%] [G loss: 0.710767]\n",
      "epoch:5 step:5494 [D loss: 0.689123, acc.: 54.69%] [G loss: 0.711488]\n",
      "epoch:5 step:5495 [D loss: 0.675041, acc.: 66.41%] [G loss: 0.712348]\n",
      "epoch:5 step:5496 [D loss: 0.689488, acc.: 53.91%] [G loss: 0.703822]\n",
      "epoch:5 step:5497 [D loss: 0.679902, acc.: 56.25%] [G loss: 0.715643]\n",
      "epoch:5 step:5498 [D loss: 0.672912, acc.: 61.72%] [G loss: 0.717041]\n",
      "epoch:5 step:5499 [D loss: 0.683812, acc.: 50.78%] [G loss: 0.697410]\n",
      "epoch:5 step:5500 [D loss: 0.665038, acc.: 60.16%] [G loss: 0.695202]\n",
      "epoch:5 step:5501 [D loss: 0.689805, acc.: 50.00%] [G loss: 0.702647]\n",
      "epoch:5 step:5502 [D loss: 0.684351, acc.: 56.25%] [G loss: 0.699407]\n",
      "epoch:5 step:5503 [D loss: 0.686383, acc.: 53.12%] [G loss: 0.674326]\n",
      "epoch:5 step:5504 [D loss: 0.698198, acc.: 46.09%] [G loss: 0.692172]\n",
      "epoch:5 step:5505 [D loss: 0.738157, acc.: 32.03%] [G loss: 0.696720]\n",
      "epoch:5 step:5506 [D loss: 0.720081, acc.: 33.59%] [G loss: 0.696615]\n",
      "epoch:5 step:5507 [D loss: 0.708395, acc.: 38.28%] [G loss: 0.698272]\n",
      "epoch:5 step:5508 [D loss: 0.696867, acc.: 47.66%] [G loss: 0.706316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5509 [D loss: 0.676540, acc.: 58.59%] [G loss: 0.692792]\n",
      "epoch:5 step:5510 [D loss: 0.685773, acc.: 57.03%] [G loss: 0.717432]\n",
      "epoch:5 step:5511 [D loss: 0.679318, acc.: 59.38%] [G loss: 0.732423]\n",
      "epoch:5 step:5512 [D loss: 0.690927, acc.: 47.66%] [G loss: 0.759870]\n",
      "epoch:5 step:5513 [D loss: 0.688482, acc.: 50.78%] [G loss: 0.777504]\n",
      "epoch:5 step:5514 [D loss: 0.667193, acc.: 59.38%] [G loss: 0.790690]\n",
      "epoch:5 step:5515 [D loss: 0.673799, acc.: 58.59%] [G loss: 0.776126]\n",
      "epoch:5 step:5516 [D loss: 0.682136, acc.: 51.56%] [G loss: 0.783882]\n",
      "epoch:5 step:5517 [D loss: 0.686974, acc.: 52.34%] [G loss: 0.741314]\n",
      "epoch:5 step:5518 [D loss: 0.706557, acc.: 48.44%] [G loss: 0.727577]\n",
      "epoch:5 step:5519 [D loss: 0.736821, acc.: 33.59%] [G loss: 0.713999]\n",
      "epoch:5 step:5520 [D loss: 0.718939, acc.: 40.62%] [G loss: 0.693935]\n",
      "epoch:5 step:5521 [D loss: 0.713191, acc.: 42.19%] [G loss: 0.704028]\n",
      "epoch:5 step:5522 [D loss: 0.714577, acc.: 35.94%] [G loss: 0.703496]\n",
      "epoch:5 step:5523 [D loss: 0.686569, acc.: 59.38%] [G loss: 0.738641]\n",
      "epoch:5 step:5524 [D loss: 0.686421, acc.: 53.91%] [G loss: 0.740084]\n",
      "epoch:5 step:5525 [D loss: 0.806916, acc.: 36.72%] [G loss: 1.263863]\n",
      "epoch:5 step:5526 [D loss: 0.677408, acc.: 59.38%] [G loss: 0.790061]\n",
      "epoch:5 step:5527 [D loss: 0.718048, acc.: 50.00%] [G loss: 0.767322]\n",
      "epoch:5 step:5528 [D loss: 0.707110, acc.: 49.22%] [G loss: 0.738898]\n",
      "epoch:5 step:5529 [D loss: 0.685512, acc.: 50.00%] [G loss: 0.726221]\n",
      "epoch:5 step:5530 [D loss: 0.780313, acc.: 37.50%] [G loss: 0.704942]\n",
      "epoch:5 step:5531 [D loss: 0.691673, acc.: 51.56%] [G loss: 0.718670]\n",
      "epoch:5 step:5532 [D loss: 0.706467, acc.: 38.28%] [G loss: 0.694495]\n",
      "epoch:5 step:5533 [D loss: 0.698521, acc.: 45.31%] [G loss: 0.684462]\n",
      "epoch:5 step:5534 [D loss: 0.695333, acc.: 48.44%] [G loss: 0.701662]\n",
      "epoch:5 step:5535 [D loss: 0.715333, acc.: 32.03%] [G loss: 0.687076]\n",
      "epoch:5 step:5536 [D loss: 0.702654, acc.: 45.31%] [G loss: 0.680754]\n",
      "epoch:5 step:5537 [D loss: 0.692753, acc.: 53.91%] [G loss: 0.667152]\n",
      "epoch:5 step:5538 [D loss: 0.700670, acc.: 46.09%] [G loss: 0.696395]\n",
      "epoch:5 step:5539 [D loss: 0.693434, acc.: 53.91%] [G loss: 0.685443]\n",
      "epoch:5 step:5540 [D loss: 0.701580, acc.: 48.44%] [G loss: 0.692854]\n",
      "epoch:5 step:5541 [D loss: 0.707800, acc.: 43.75%] [G loss: 0.716767]\n",
      "epoch:5 step:5542 [D loss: 0.694907, acc.: 44.53%] [G loss: 0.705182]\n",
      "epoch:5 step:5543 [D loss: 0.701207, acc.: 39.84%] [G loss: 0.719890]\n",
      "epoch:5 step:5544 [D loss: 0.686294, acc.: 54.69%] [G loss: 0.707085]\n",
      "epoch:5 step:5545 [D loss: 0.692834, acc.: 57.81%] [G loss: 0.730986]\n",
      "epoch:5 step:5546 [D loss: 0.695249, acc.: 51.56%] [G loss: 0.717421]\n",
      "epoch:5 step:5547 [D loss: 0.681156, acc.: 57.03%] [G loss: 0.718667]\n",
      "epoch:5 step:5548 [D loss: 0.678622, acc.: 57.81%] [G loss: 0.725396]\n",
      "epoch:5 step:5549 [D loss: 0.687485, acc.: 57.03%] [G loss: 0.737185]\n",
      "epoch:5 step:5550 [D loss: 0.695387, acc.: 42.19%] [G loss: 0.727287]\n",
      "epoch:5 step:5551 [D loss: 0.679959, acc.: 57.81%] [G loss: 0.712532]\n",
      "epoch:5 step:5552 [D loss: 0.703779, acc.: 48.44%] [G loss: 0.699599]\n",
      "epoch:5 step:5553 [D loss: 0.704290, acc.: 43.75%] [G loss: 0.713123]\n",
      "epoch:5 step:5554 [D loss: 0.689344, acc.: 55.47%] [G loss: 0.708426]\n",
      "epoch:5 step:5555 [D loss: 0.680419, acc.: 60.16%] [G loss: 0.686867]\n",
      "epoch:5 step:5556 [D loss: 0.699049, acc.: 48.44%] [G loss: 0.672047]\n",
      "epoch:5 step:5557 [D loss: 0.701859, acc.: 46.09%] [G loss: 0.677704]\n",
      "epoch:5 step:5558 [D loss: 0.699648, acc.: 47.66%] [G loss: 0.681641]\n",
      "epoch:5 step:5559 [D loss: 0.703191, acc.: 40.62%] [G loss: 0.700541]\n",
      "epoch:5 step:5560 [D loss: 0.692296, acc.: 48.44%] [G loss: 0.694032]\n",
      "epoch:5 step:5561 [D loss: 0.699213, acc.: 45.31%] [G loss: 0.703719]\n",
      "epoch:5 step:5562 [D loss: 0.703559, acc.: 45.31%] [G loss: 0.692406]\n",
      "epoch:5 step:5563 [D loss: 0.693207, acc.: 50.78%] [G loss: 0.679896]\n",
      "epoch:5 step:5564 [D loss: 0.699393, acc.: 45.31%] [G loss: 0.701561]\n",
      "epoch:5 step:5565 [D loss: 0.702332, acc.: 46.09%] [G loss: 0.677686]\n",
      "epoch:5 step:5566 [D loss: 0.704868, acc.: 47.66%] [G loss: 0.699496]\n",
      "epoch:5 step:5567 [D loss: 0.697523, acc.: 45.31%] [G loss: 0.705118]\n",
      "epoch:5 step:5568 [D loss: 0.697203, acc.: 47.66%] [G loss: 0.698495]\n",
      "epoch:5 step:5569 [D loss: 0.690046, acc.: 60.94%] [G loss: 0.704820]\n",
      "epoch:5 step:5570 [D loss: 0.690595, acc.: 57.03%] [G loss: 0.703068]\n",
      "epoch:5 step:5571 [D loss: 0.681960, acc.: 64.84%] [G loss: 0.711094]\n",
      "epoch:5 step:5572 [D loss: 0.684693, acc.: 56.25%] [G loss: 0.732539]\n",
      "epoch:5 step:5573 [D loss: 0.686267, acc.: 55.47%] [G loss: 0.716830]\n",
      "epoch:5 step:5574 [D loss: 0.674448, acc.: 66.41%] [G loss: 0.731879]\n",
      "epoch:5 step:5575 [D loss: 0.687848, acc.: 57.81%] [G loss: 0.722721]\n",
      "epoch:5 step:5576 [D loss: 0.673141, acc.: 57.03%] [G loss: 0.729340]\n",
      "epoch:5 step:5577 [D loss: 0.688010, acc.: 55.47%] [G loss: 0.692916]\n",
      "epoch:5 step:5578 [D loss: 0.704352, acc.: 46.09%] [G loss: 0.706045]\n",
      "epoch:5 step:5579 [D loss: 0.703782, acc.: 50.00%] [G loss: 0.703020]\n",
      "epoch:5 step:5580 [D loss: 0.690662, acc.: 51.56%] [G loss: 0.721661]\n",
      "epoch:5 step:5581 [D loss: 0.707892, acc.: 40.62%] [G loss: 0.692524]\n",
      "epoch:5 step:5582 [D loss: 0.695092, acc.: 53.91%] [G loss: 0.715006]\n",
      "epoch:5 step:5583 [D loss: 0.703423, acc.: 46.09%] [G loss: 0.703609]\n",
      "epoch:5 step:5584 [D loss: 0.685499, acc.: 53.91%] [G loss: 0.705524]\n",
      "epoch:5 step:5585 [D loss: 0.703298, acc.: 42.19%] [G loss: 0.717254]\n",
      "epoch:5 step:5586 [D loss: 0.696465, acc.: 51.56%] [G loss: 0.707675]\n",
      "epoch:5 step:5587 [D loss: 0.689521, acc.: 50.00%] [G loss: 0.712143]\n",
      "epoch:5 step:5588 [D loss: 0.688889, acc.: 48.44%] [G loss: 0.727496]\n",
      "epoch:5 step:5589 [D loss: 0.701466, acc.: 44.53%] [G loss: 0.722443]\n",
      "epoch:5 step:5590 [D loss: 0.698238, acc.: 37.50%] [G loss: 0.720458]\n",
      "epoch:5 step:5591 [D loss: 0.693703, acc.: 53.12%] [G loss: 0.724218]\n",
      "epoch:5 step:5592 [D loss: 0.697620, acc.: 41.41%] [G loss: 0.725928]\n",
      "epoch:5 step:5593 [D loss: 0.689970, acc.: 51.56%] [G loss: 0.736731]\n",
      "epoch:5 step:5594 [D loss: 0.694692, acc.: 45.31%] [G loss: 0.718329]\n",
      "epoch:5 step:5595 [D loss: 0.688367, acc.: 55.47%] [G loss: 0.725062]\n",
      "epoch:5 step:5596 [D loss: 0.687661, acc.: 57.03%] [G loss: 0.723537]\n",
      "epoch:5 step:5597 [D loss: 0.550897, acc.: 62.50%] [G loss: 0.755491]\n",
      "epoch:5 step:5598 [D loss: 0.707906, acc.: 58.59%] [G loss: 0.722294]\n",
      "epoch:5 step:5599 [D loss: 0.712496, acc.: 52.34%] [G loss: 0.709856]\n",
      "epoch:5 step:5600 [D loss: 0.689963, acc.: 60.16%] [G loss: 0.708241]\n",
      "epoch:5 step:5601 [D loss: 0.712563, acc.: 44.53%] [G loss: 0.713987]\n",
      "epoch:5 step:5602 [D loss: 0.690135, acc.: 52.34%] [G loss: 0.728587]\n",
      "epoch:5 step:5603 [D loss: 0.678917, acc.: 54.69%] [G loss: 0.709478]\n",
      "epoch:5 step:5604 [D loss: 0.667468, acc.: 59.38%] [G loss: 0.714582]\n",
      "epoch:5 step:5605 [D loss: 0.761287, acc.: 28.12%] [G loss: 0.733495]\n",
      "epoch:5 step:5606 [D loss: 0.681845, acc.: 52.34%] [G loss: 0.712467]\n",
      "epoch:5 step:5607 [D loss: 0.683888, acc.: 55.47%] [G loss: 0.723889]\n",
      "epoch:5 step:5608 [D loss: 0.673052, acc.: 58.59%] [G loss: 0.723796]\n",
      "epoch:5 step:5609 [D loss: 0.606946, acc.: 66.41%] [G loss: 0.742797]\n",
      "epoch:5 step:5610 [D loss: 0.589378, acc.: 72.66%] [G loss: 0.655136]\n",
      "epoch:5 step:5611 [D loss: 0.570930, acc.: 57.03%] [G loss: 0.756682]\n",
      "epoch:5 step:5612 [D loss: 0.485534, acc.: 60.16%] [G loss: 0.766669]\n",
      "epoch:5 step:5613 [D loss: 0.788209, acc.: 35.16%] [G loss: 0.684770]\n",
      "epoch:5 step:5614 [D loss: 0.731650, acc.: 30.47%] [G loss: 0.759612]\n",
      "epoch:5 step:5615 [D loss: 0.725438, acc.: 28.12%] [G loss: 0.725232]\n",
      "epoch:5 step:5616 [D loss: 0.694699, acc.: 44.53%] [G loss: 0.753791]\n",
      "epoch:5 step:5617 [D loss: 0.712198, acc.: 39.06%] [G loss: 0.793139]\n",
      "epoch:5 step:5618 [D loss: 0.683017, acc.: 55.47%] [G loss: 0.729034]\n",
      "epoch:5 step:5619 [D loss: 0.710840, acc.: 46.88%] [G loss: 0.758773]\n",
      "epoch:5 step:5620 [D loss: 0.859114, acc.: 23.44%] [G loss: 1.276633]\n",
      "epoch:5 step:5621 [D loss: 0.798458, acc.: 43.75%] [G loss: 0.884714]\n",
      "epoch:5 step:5622 [D loss: 0.776356, acc.: 45.31%] [G loss: 0.804767]\n",
      "epoch:6 step:5623 [D loss: 0.671975, acc.: 47.66%] [G loss: 0.813045]\n",
      "epoch:6 step:5624 [D loss: 0.672023, acc.: 48.44%] [G loss: 0.883072]\n",
      "epoch:6 step:5625 [D loss: 0.664191, acc.: 50.00%] [G loss: 0.837977]\n",
      "epoch:6 step:5626 [D loss: 0.634965, acc.: 57.03%] [G loss: 0.934373]\n",
      "epoch:6 step:5627 [D loss: 0.610722, acc.: 68.75%] [G loss: 1.205572]\n",
      "epoch:6 step:5628 [D loss: 0.635536, acc.: 63.28%] [G loss: 1.006937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5629 [D loss: 0.683154, acc.: 53.91%] [G loss: 0.898461]\n",
      "epoch:6 step:5630 [D loss: 0.713330, acc.: 50.00%] [G loss: 0.851865]\n",
      "epoch:6 step:5631 [D loss: 0.701728, acc.: 56.25%] [G loss: 0.782078]\n",
      "epoch:6 step:5632 [D loss: 0.672519, acc.: 68.75%] [G loss: 0.781095]\n",
      "epoch:6 step:5633 [D loss: 0.697227, acc.: 62.50%] [G loss: 0.714035]\n",
      "epoch:6 step:5634 [D loss: 0.672006, acc.: 66.41%] [G loss: 1.113550]\n",
      "epoch:6 step:5635 [D loss: 0.637821, acc.: 79.69%] [G loss: 1.093426]\n",
      "epoch:6 step:5636 [D loss: 0.613329, acc.: 64.84%] [G loss: 1.443908]\n",
      "epoch:6 step:5637 [D loss: 0.528569, acc.: 77.34%] [G loss: 1.333578]\n",
      "epoch:6 step:5638 [D loss: 0.705125, acc.: 50.00%] [G loss: 1.253958]\n",
      "epoch:6 step:5639 [D loss: 0.635643, acc.: 51.56%] [G loss: 1.108163]\n",
      "epoch:6 step:5640 [D loss: 0.601777, acc.: 80.47%] [G loss: 0.704288]\n",
      "epoch:6 step:5641 [D loss: 0.664058, acc.: 62.50%] [G loss: 1.041069]\n",
      "epoch:6 step:5642 [D loss: 0.937396, acc.: 19.53%] [G loss: 0.584847]\n",
      "epoch:6 step:5643 [D loss: 0.679893, acc.: 50.78%] [G loss: 0.755401]\n",
      "epoch:6 step:5644 [D loss: 0.700663, acc.: 53.91%] [G loss: 0.696688]\n",
      "epoch:6 step:5645 [D loss: 0.741454, acc.: 48.44%] [G loss: 0.662775]\n",
      "epoch:6 step:5646 [D loss: 0.692054, acc.: 55.47%] [G loss: 0.648097]\n",
      "epoch:6 step:5647 [D loss: 0.606324, acc.: 82.81%] [G loss: 0.700394]\n",
      "epoch:6 step:5648 [D loss: 0.675180, acc.: 62.50%] [G loss: 1.090228]\n",
      "epoch:6 step:5649 [D loss: 0.756498, acc.: 45.31%] [G loss: 0.795012]\n",
      "epoch:6 step:5650 [D loss: 0.700642, acc.: 46.09%] [G loss: 0.768880]\n",
      "epoch:6 step:5651 [D loss: 0.688954, acc.: 57.81%] [G loss: 0.774615]\n",
      "epoch:6 step:5652 [D loss: 0.673791, acc.: 55.47%] [G loss: 0.835579]\n",
      "epoch:6 step:5653 [D loss: 0.694048, acc.: 46.09%] [G loss: 0.710703]\n",
      "epoch:6 step:5654 [D loss: 0.694590, acc.: 52.34%] [G loss: 0.691271]\n",
      "epoch:6 step:5655 [D loss: 0.679753, acc.: 54.69%] [G loss: 0.791356]\n",
      "epoch:6 step:5656 [D loss: 0.710297, acc.: 43.75%] [G loss: 0.638332]\n",
      "epoch:6 step:5657 [D loss: 0.725753, acc.: 32.81%] [G loss: 0.729236]\n",
      "epoch:6 step:5658 [D loss: 0.699838, acc.: 46.09%] [G loss: 0.654861]\n",
      "epoch:6 step:5659 [D loss: 0.783286, acc.: 15.62%] [G loss: 0.691416]\n",
      "epoch:6 step:5660 [D loss: 0.756387, acc.: 23.44%] [G loss: 0.676527]\n",
      "epoch:6 step:5661 [D loss: 0.700548, acc.: 43.75%] [G loss: 0.666521]\n",
      "epoch:6 step:5662 [D loss: 0.714787, acc.: 33.59%] [G loss: 0.695294]\n",
      "epoch:6 step:5663 [D loss: 0.685488, acc.: 54.69%] [G loss: 0.683823]\n",
      "epoch:6 step:5664 [D loss: 0.697685, acc.: 50.78%] [G loss: 0.616769]\n",
      "epoch:6 step:5665 [D loss: 0.705888, acc.: 39.06%] [G loss: 0.669754]\n",
      "epoch:6 step:5666 [D loss: 0.709858, acc.: 47.66%] [G loss: 0.680246]\n",
      "epoch:6 step:5667 [D loss: 0.695824, acc.: 51.56%] [G loss: 0.682890]\n",
      "epoch:6 step:5668 [D loss: 0.686681, acc.: 46.88%] [G loss: 0.693835]\n",
      "epoch:6 step:5669 [D loss: 0.687678, acc.: 57.81%] [G loss: 0.711056]\n",
      "epoch:6 step:5670 [D loss: 0.688874, acc.: 53.91%] [G loss: 0.703676]\n",
      "epoch:6 step:5671 [D loss: 0.683509, acc.: 59.38%] [G loss: 0.725240]\n",
      "epoch:6 step:5672 [D loss: 0.679704, acc.: 53.12%] [G loss: 0.692729]\n",
      "epoch:6 step:5673 [D loss: 0.684781, acc.: 55.47%] [G loss: 0.697748]\n",
      "epoch:6 step:5674 [D loss: 0.687093, acc.: 53.12%] [G loss: 0.695238]\n",
      "epoch:6 step:5675 [D loss: 0.701349, acc.: 52.34%] [G loss: 0.695385]\n",
      "epoch:6 step:5676 [D loss: 0.711673, acc.: 41.41%] [G loss: 0.714747]\n",
      "epoch:6 step:5677 [D loss: 0.695913, acc.: 46.88%] [G loss: 0.722683]\n",
      "epoch:6 step:5678 [D loss: 0.689137, acc.: 51.56%] [G loss: 0.731109]\n",
      "epoch:6 step:5679 [D loss: 0.697697, acc.: 53.91%] [G loss: 0.728209]\n",
      "epoch:6 step:5680 [D loss: 0.680952, acc.: 57.81%] [G loss: 0.731174]\n",
      "epoch:6 step:5681 [D loss: 0.682182, acc.: 54.69%] [G loss: 0.679538]\n",
      "epoch:6 step:5682 [D loss: 0.679820, acc.: 54.69%] [G loss: 0.727633]\n",
      "epoch:6 step:5683 [D loss: 0.683921, acc.: 55.47%] [G loss: 0.714604]\n",
      "epoch:6 step:5684 [D loss: 0.692022, acc.: 55.47%] [G loss: 0.726862]\n",
      "epoch:6 step:5685 [D loss: 0.690703, acc.: 49.22%] [G loss: 0.742507]\n",
      "epoch:6 step:5686 [D loss: 0.672418, acc.: 63.28%] [G loss: 0.734958]\n",
      "epoch:6 step:5687 [D loss: 0.681080, acc.: 65.62%] [G loss: 0.738590]\n",
      "epoch:6 step:5688 [D loss: 0.689497, acc.: 55.47%] [G loss: 0.728438]\n",
      "epoch:6 step:5689 [D loss: 0.702947, acc.: 44.53%] [G loss: 0.779443]\n",
      "epoch:6 step:5690 [D loss: 0.689101, acc.: 53.91%] [G loss: 0.727332]\n",
      "epoch:6 step:5691 [D loss: 0.665572, acc.: 63.28%] [G loss: 0.732177]\n",
      "epoch:6 step:5692 [D loss: 0.665673, acc.: 64.06%] [G loss: 0.759267]\n",
      "epoch:6 step:5693 [D loss: 0.699084, acc.: 50.00%] [G loss: 0.706690]\n",
      "epoch:6 step:5694 [D loss: 0.641754, acc.: 71.09%] [G loss: 0.784812]\n",
      "epoch:6 step:5695 [D loss: 0.676877, acc.: 54.69%] [G loss: 0.768543]\n",
      "epoch:6 step:5696 [D loss: 0.712696, acc.: 40.62%] [G loss: 0.738146]\n",
      "epoch:6 step:5697 [D loss: 0.727751, acc.: 38.28%] [G loss: 0.759519]\n",
      "epoch:6 step:5698 [D loss: 0.676543, acc.: 52.34%] [G loss: 0.746431]\n",
      "epoch:6 step:5699 [D loss: 0.677334, acc.: 56.25%] [G loss: 0.761843]\n",
      "epoch:6 step:5700 [D loss: 0.693519, acc.: 53.91%] [G loss: 0.801921]\n",
      "epoch:6 step:5701 [D loss: 0.673618, acc.: 56.25%] [G loss: 0.764622]\n",
      "epoch:6 step:5702 [D loss: 0.703055, acc.: 57.81%] [G loss: 0.734747]\n",
      "epoch:6 step:5703 [D loss: 0.695393, acc.: 50.78%] [G loss: 0.768503]\n",
      "epoch:6 step:5704 [D loss: 0.677611, acc.: 64.06%] [G loss: 0.801012]\n",
      "epoch:6 step:5705 [D loss: 0.657150, acc.: 60.94%] [G loss: 0.801534]\n",
      "epoch:6 step:5706 [D loss: 0.670333, acc.: 59.38%] [G loss: 0.771222]\n",
      "epoch:6 step:5707 [D loss: 0.579925, acc.: 57.81%] [G loss: 0.686706]\n",
      "epoch:6 step:5708 [D loss: 0.763689, acc.: 39.06%] [G loss: 0.717111]\n",
      "epoch:6 step:5709 [D loss: 0.725065, acc.: 42.19%] [G loss: 0.757423]\n",
      "epoch:6 step:5710 [D loss: 0.683774, acc.: 50.00%] [G loss: 0.761718]\n",
      "epoch:6 step:5711 [D loss: 0.638497, acc.: 69.53%] [G loss: 0.830111]\n",
      "epoch:6 step:5712 [D loss: 0.677346, acc.: 57.81%] [G loss: 0.758442]\n",
      "epoch:6 step:5713 [D loss: 0.675876, acc.: 50.78%] [G loss: 0.783195]\n",
      "epoch:6 step:5714 [D loss: 0.693391, acc.: 58.59%] [G loss: 0.796439]\n",
      "epoch:6 step:5715 [D loss: 0.658636, acc.: 63.28%] [G loss: 0.832202]\n",
      "epoch:6 step:5716 [D loss: 0.696931, acc.: 55.47%] [G loss: 0.773939]\n",
      "epoch:6 step:5717 [D loss: 0.703810, acc.: 50.78%] [G loss: 0.789691]\n",
      "epoch:6 step:5718 [D loss: 0.707624, acc.: 45.31%] [G loss: 0.743435]\n",
      "epoch:6 step:5719 [D loss: 0.678407, acc.: 53.91%] [G loss: 0.819689]\n",
      "epoch:6 step:5720 [D loss: 0.656908, acc.: 57.81%] [G loss: 0.811230]\n",
      "epoch:6 step:5721 [D loss: 0.718692, acc.: 49.22%] [G loss: 0.878161]\n",
      "epoch:6 step:5722 [D loss: 0.680604, acc.: 54.69%] [G loss: 0.796917]\n",
      "epoch:6 step:5723 [D loss: 0.690750, acc.: 54.69%] [G loss: 0.796667]\n",
      "epoch:6 step:5724 [D loss: 0.670938, acc.: 58.59%] [G loss: 0.819814]\n",
      "epoch:6 step:5725 [D loss: 0.688473, acc.: 60.16%] [G loss: 0.752246]\n",
      "epoch:6 step:5726 [D loss: 0.616386, acc.: 61.72%] [G loss: 0.800989]\n",
      "epoch:6 step:5727 [D loss: 0.732369, acc.: 48.44%] [G loss: 0.766600]\n",
      "epoch:6 step:5728 [D loss: 0.699438, acc.: 52.34%] [G loss: 0.768203]\n",
      "epoch:6 step:5729 [D loss: 0.680365, acc.: 53.91%] [G loss: 0.779234]\n",
      "epoch:6 step:5730 [D loss: 0.712568, acc.: 42.97%] [G loss: 0.737948]\n",
      "epoch:6 step:5731 [D loss: 0.730590, acc.: 41.41%] [G loss: 0.729728]\n",
      "epoch:6 step:5732 [D loss: 0.696549, acc.: 53.91%] [G loss: 1.713073]\n",
      "epoch:6 step:5733 [D loss: 0.709643, acc.: 47.66%] [G loss: 0.665217]\n",
      "epoch:6 step:5734 [D loss: 0.706804, acc.: 45.31%] [G loss: 0.682956]\n",
      "epoch:6 step:5735 [D loss: 0.682459, acc.: 53.12%] [G loss: 0.676305]\n",
      "epoch:6 step:5736 [D loss: 0.693539, acc.: 52.34%] [G loss: 0.772659]\n",
      "epoch:6 step:5737 [D loss: 0.671862, acc.: 59.38%] [G loss: 0.679032]\n",
      "epoch:6 step:5738 [D loss: 0.694283, acc.: 47.66%] [G loss: 0.787840]\n",
      "epoch:6 step:5739 [D loss: 0.685179, acc.: 53.91%] [G loss: 0.818557]\n",
      "epoch:6 step:5740 [D loss: 0.708843, acc.: 46.88%] [G loss: 0.768586]\n",
      "epoch:6 step:5741 [D loss: 0.699522, acc.: 52.34%] [G loss: 0.722542]\n",
      "epoch:6 step:5742 [D loss: 0.674960, acc.: 59.38%] [G loss: 0.767408]\n",
      "epoch:6 step:5743 [D loss: 0.668835, acc.: 60.94%] [G loss: 0.763256]\n",
      "epoch:6 step:5744 [D loss: 0.667130, acc.: 52.34%] [G loss: 0.736392]\n",
      "epoch:6 step:5745 [D loss: 0.697589, acc.: 50.78%] [G loss: 1.206706]\n",
      "epoch:6 step:5746 [D loss: 0.727564, acc.: 38.28%] [G loss: 0.738180]\n",
      "epoch:6 step:5747 [D loss: 0.703313, acc.: 46.09%] [G loss: 0.691795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5748 [D loss: 0.697191, acc.: 47.66%] [G loss: 0.725396]\n",
      "epoch:6 step:5749 [D loss: 0.664080, acc.: 56.25%] [G loss: 0.788440]\n",
      "epoch:6 step:5750 [D loss: 0.692988, acc.: 53.12%] [G loss: 0.735219]\n",
      "epoch:6 step:5751 [D loss: 0.689511, acc.: 54.69%] [G loss: 0.781864]\n",
      "epoch:6 step:5752 [D loss: 0.670443, acc.: 58.59%] [G loss: 0.720678]\n",
      "epoch:6 step:5753 [D loss: 0.684445, acc.: 59.38%] [G loss: 0.794132]\n",
      "epoch:6 step:5754 [D loss: 0.673975, acc.: 58.59%] [G loss: 0.856267]\n",
      "epoch:6 step:5755 [D loss: 0.706059, acc.: 39.06%] [G loss: 0.743264]\n",
      "epoch:6 step:5756 [D loss: 0.688982, acc.: 44.53%] [G loss: 0.780543]\n",
      "epoch:6 step:5757 [D loss: 0.656228, acc.: 54.69%] [G loss: 0.795493]\n",
      "epoch:6 step:5758 [D loss: 0.673882, acc.: 56.25%] [G loss: 0.782176]\n",
      "epoch:6 step:5759 [D loss: 0.698732, acc.: 50.78%] [G loss: 0.710595]\n",
      "epoch:6 step:5760 [D loss: 0.712868, acc.: 43.75%] [G loss: 0.747253]\n",
      "epoch:6 step:5761 [D loss: 0.677435, acc.: 57.03%] [G loss: 0.707363]\n",
      "epoch:6 step:5762 [D loss: 0.697239, acc.: 59.38%] [G loss: 0.766393]\n",
      "epoch:6 step:5763 [D loss: 0.688097, acc.: 57.81%] [G loss: 0.780551]\n",
      "epoch:6 step:5764 [D loss: 0.683874, acc.: 58.59%] [G loss: 0.753486]\n",
      "epoch:6 step:5765 [D loss: 0.674516, acc.: 53.12%] [G loss: 0.735992]\n",
      "epoch:6 step:5766 [D loss: 0.685727, acc.: 56.25%] [G loss: 0.752206]\n",
      "epoch:6 step:5767 [D loss: 0.676977, acc.: 48.44%] [G loss: 0.764441]\n",
      "epoch:6 step:5768 [D loss: 0.712151, acc.: 46.09%] [G loss: 0.721118]\n",
      "epoch:6 step:5769 [D loss: 0.699698, acc.: 46.09%] [G loss: 0.748588]\n",
      "epoch:6 step:5770 [D loss: 0.735122, acc.: 38.28%] [G loss: 0.730391]\n",
      "epoch:6 step:5771 [D loss: 0.701873, acc.: 53.12%] [G loss: 0.713686]\n",
      "epoch:6 step:5772 [D loss: 0.696790, acc.: 50.78%] [G loss: 0.725052]\n",
      "epoch:6 step:5773 [D loss: 0.669276, acc.: 61.72%] [G loss: 0.770671]\n",
      "epoch:6 step:5774 [D loss: 0.658624, acc.: 68.75%] [G loss: 0.751957]\n",
      "epoch:6 step:5775 [D loss: 0.690231, acc.: 52.34%] [G loss: 0.755947]\n",
      "epoch:6 step:5776 [D loss: 0.703694, acc.: 52.34%] [G loss: 1.293874]\n",
      "epoch:6 step:5777 [D loss: 0.682123, acc.: 54.69%] [G loss: 0.780552]\n",
      "epoch:6 step:5778 [D loss: 0.702739, acc.: 46.09%] [G loss: 0.810099]\n",
      "epoch:6 step:5779 [D loss: 0.672657, acc.: 58.59%] [G loss: 0.758588]\n",
      "epoch:6 step:5780 [D loss: 0.672718, acc.: 53.91%] [G loss: 0.767120]\n",
      "epoch:6 step:5781 [D loss: 0.663529, acc.: 61.72%] [G loss: 0.782540]\n",
      "epoch:6 step:5782 [D loss: 0.691306, acc.: 53.12%] [G loss: 0.775464]\n",
      "epoch:6 step:5783 [D loss: 0.673384, acc.: 63.28%] [G loss: 0.793820]\n",
      "epoch:6 step:5784 [D loss: 0.679888, acc.: 57.03%] [G loss: 0.825076]\n",
      "epoch:6 step:5785 [D loss: 0.683362, acc.: 56.25%] [G loss: 0.785294]\n",
      "epoch:6 step:5786 [D loss: 0.697930, acc.: 47.66%] [G loss: 0.698709]\n",
      "epoch:6 step:5787 [D loss: 0.657778, acc.: 63.28%] [G loss: 0.744029]\n",
      "epoch:6 step:5788 [D loss: 0.679815, acc.: 60.16%] [G loss: 0.751193]\n",
      "epoch:6 step:5789 [D loss: 0.713037, acc.: 49.22%] [G loss: 0.748593]\n",
      "epoch:6 step:5790 [D loss: 0.625884, acc.: 73.44%] [G loss: 0.905817]\n",
      "epoch:6 step:5791 [D loss: 0.664692, acc.: 57.03%] [G loss: 0.957337]\n",
      "epoch:6 step:5792 [D loss: 0.732235, acc.: 50.00%] [G loss: 0.757139]\n",
      "epoch:6 step:5793 [D loss: 0.705530, acc.: 58.59%] [G loss: 0.757276]\n",
      "epoch:6 step:5794 [D loss: 0.705004, acc.: 53.91%] [G loss: 0.719085]\n",
      "epoch:6 step:5795 [D loss: 0.685546, acc.: 55.47%] [G loss: 0.677937]\n",
      "epoch:6 step:5796 [D loss: 0.720201, acc.: 41.41%] [G loss: 0.729358]\n",
      "epoch:6 step:5797 [D loss: 0.717380, acc.: 41.41%] [G loss: 0.710500]\n",
      "epoch:6 step:5798 [D loss: 0.679535, acc.: 61.72%] [G loss: 0.703425]\n",
      "epoch:6 step:5799 [D loss: 0.706765, acc.: 46.09%] [G loss: 0.683334]\n",
      "epoch:6 step:5800 [D loss: 0.696192, acc.: 48.44%] [G loss: 0.729567]\n",
      "epoch:6 step:5801 [D loss: 0.666704, acc.: 65.62%] [G loss: 0.738897]\n",
      "epoch:6 step:5802 [D loss: 0.710394, acc.: 50.00%] [G loss: 0.714714]\n",
      "epoch:6 step:5803 [D loss: 0.681921, acc.: 59.38%] [G loss: 0.746412]\n",
      "epoch:6 step:5804 [D loss: 0.701091, acc.: 46.88%] [G loss: 0.724286]\n",
      "epoch:6 step:5805 [D loss: 0.703560, acc.: 47.66%] [G loss: 0.718180]\n",
      "epoch:6 step:5806 [D loss: 0.668759, acc.: 57.81%] [G loss: 0.726249]\n",
      "epoch:6 step:5807 [D loss: 0.714518, acc.: 46.09%] [G loss: 0.741415]\n",
      "epoch:6 step:5808 [D loss: 0.692070, acc.: 45.31%] [G loss: 0.741046]\n",
      "epoch:6 step:5809 [D loss: 0.663695, acc.: 53.91%] [G loss: 0.746389]\n",
      "epoch:6 step:5810 [D loss: 0.720412, acc.: 50.00%] [G loss: 0.758997]\n",
      "epoch:6 step:5811 [D loss: 0.698193, acc.: 51.56%] [G loss: 0.732392]\n",
      "epoch:6 step:5812 [D loss: 0.685814, acc.: 57.03%] [G loss: 0.732480]\n",
      "epoch:6 step:5813 [D loss: 0.686235, acc.: 52.34%] [G loss: 0.711428]\n",
      "epoch:6 step:5814 [D loss: 0.704066, acc.: 55.47%] [G loss: 0.726549]\n",
      "epoch:6 step:5815 [D loss: 0.691446, acc.: 50.78%] [G loss: 0.746221]\n",
      "epoch:6 step:5816 [D loss: 0.640269, acc.: 69.53%] [G loss: 0.721279]\n",
      "epoch:6 step:5817 [D loss: 0.681231, acc.: 51.56%] [G loss: 0.740463]\n",
      "epoch:6 step:5818 [D loss: 0.705935, acc.: 46.88%] [G loss: 0.780134]\n",
      "epoch:6 step:5819 [D loss: 0.707676, acc.: 52.34%] [G loss: 0.782437]\n",
      "epoch:6 step:5820 [D loss: 0.667596, acc.: 57.81%] [G loss: 0.840157]\n",
      "epoch:6 step:5821 [D loss: 0.683511, acc.: 59.38%] [G loss: 0.806783]\n",
      "epoch:6 step:5822 [D loss: 0.712691, acc.: 50.78%] [G loss: 0.731066]\n",
      "epoch:6 step:5823 [D loss: 0.715499, acc.: 45.31%] [G loss: 0.743834]\n",
      "epoch:6 step:5824 [D loss: 0.700818, acc.: 50.78%] [G loss: 0.732078]\n",
      "epoch:6 step:5825 [D loss: 0.728661, acc.: 52.34%] [G loss: 0.713786]\n",
      "epoch:6 step:5826 [D loss: 0.835921, acc.: 37.50%] [G loss: 0.741176]\n",
      "epoch:6 step:5827 [D loss: 0.677739, acc.: 57.81%] [G loss: 0.733006]\n",
      "epoch:6 step:5828 [D loss: 0.675236, acc.: 65.62%] [G loss: 0.741577]\n",
      "epoch:6 step:5829 [D loss: 0.509776, acc.: 75.78%] [G loss: 0.776732]\n",
      "epoch:6 step:5830 [D loss: 0.678674, acc.: 57.03%] [G loss: 0.766922]\n",
      "epoch:6 step:5831 [D loss: 0.674170, acc.: 60.16%] [G loss: 0.736347]\n",
      "epoch:6 step:5832 [D loss: 0.676934, acc.: 60.94%] [G loss: 0.732922]\n",
      "epoch:6 step:5833 [D loss: 0.681271, acc.: 53.91%] [G loss: 0.751038]\n",
      "epoch:6 step:5834 [D loss: 0.658502, acc.: 58.59%] [G loss: 0.758940]\n",
      "epoch:6 step:5835 [D loss: 0.684282, acc.: 52.34%] [G loss: 0.802827]\n",
      "epoch:6 step:5836 [D loss: 0.671999, acc.: 55.47%] [G loss: 0.786773]\n",
      "epoch:6 step:5837 [D loss: 0.692588, acc.: 40.62%] [G loss: 0.781130]\n",
      "epoch:6 step:5838 [D loss: 0.553437, acc.: 65.62%] [G loss: 0.765178]\n",
      "epoch:6 step:5839 [D loss: 0.676007, acc.: 57.03%] [G loss: 0.754465]\n",
      "epoch:6 step:5840 [D loss: 0.754053, acc.: 35.16%] [G loss: 0.748682]\n",
      "epoch:6 step:5841 [D loss: 0.706254, acc.: 55.47%] [G loss: 0.757269]\n",
      "epoch:6 step:5842 [D loss: 0.707287, acc.: 45.31%] [G loss: 0.749486]\n",
      "epoch:6 step:5843 [D loss: 0.671288, acc.: 60.94%] [G loss: 0.765380]\n",
      "epoch:6 step:5844 [D loss: 0.667266, acc.: 61.72%] [G loss: 0.768103]\n",
      "epoch:6 step:5845 [D loss: 0.652683, acc.: 67.19%] [G loss: 0.761324]\n",
      "epoch:6 step:5846 [D loss: 0.739316, acc.: 39.84%] [G loss: 0.725735]\n",
      "epoch:6 step:5847 [D loss: 0.661849, acc.: 58.59%] [G loss: 0.768618]\n",
      "epoch:6 step:5848 [D loss: 0.692111, acc.: 48.44%] [G loss: 0.744108]\n",
      "epoch:6 step:5849 [D loss: 0.678814, acc.: 56.25%] [G loss: 0.732540]\n",
      "epoch:6 step:5850 [D loss: 0.670442, acc.: 58.59%] [G loss: 0.787592]\n",
      "epoch:6 step:5851 [D loss: 0.657612, acc.: 64.06%] [G loss: 0.806294]\n",
      "epoch:6 step:5852 [D loss: 0.664957, acc.: 64.06%] [G loss: 0.819425]\n",
      "epoch:6 step:5853 [D loss: 0.601498, acc.: 75.78%] [G loss: 0.858386]\n",
      "epoch:6 step:5854 [D loss: 0.649395, acc.: 67.97%] [G loss: 0.779013]\n",
      "epoch:6 step:5855 [D loss: 0.759067, acc.: 38.28%] [G loss: 0.864583]\n",
      "epoch:6 step:5856 [D loss: 0.659474, acc.: 55.47%] [G loss: 0.878654]\n",
      "epoch:6 step:5857 [D loss: 0.662466, acc.: 59.38%] [G loss: 0.880712]\n",
      "epoch:6 step:5858 [D loss: 0.738455, acc.: 48.44%] [G loss: 0.803468]\n",
      "epoch:6 step:5859 [D loss: 0.701443, acc.: 46.09%] [G loss: 0.960859]\n",
      "epoch:6 step:5860 [D loss: 0.714756, acc.: 49.22%] [G loss: 0.862177]\n",
      "epoch:6 step:5861 [D loss: 0.723186, acc.: 44.53%] [G loss: 0.888626]\n",
      "epoch:6 step:5862 [D loss: 0.683791, acc.: 57.81%] [G loss: 0.912727]\n",
      "epoch:6 step:5863 [D loss: 0.650601, acc.: 61.72%] [G loss: 0.943497]\n",
      "epoch:6 step:5864 [D loss: 0.635701, acc.: 66.41%] [G loss: 0.989520]\n",
      "epoch:6 step:5865 [D loss: 0.617210, acc.: 71.09%] [G loss: 1.012585]\n",
      "epoch:6 step:5866 [D loss: 0.622899, acc.: 63.28%] [G loss: 1.050242]\n",
      "epoch:6 step:5867 [D loss: 0.630505, acc.: 65.62%] [G loss: 0.956166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5868 [D loss: 0.792569, acc.: 29.69%] [G loss: 0.781231]\n",
      "epoch:6 step:5869 [D loss: 0.708349, acc.: 50.78%] [G loss: 0.710326]\n",
      "epoch:6 step:5870 [D loss: 0.677898, acc.: 55.47%] [G loss: 0.718415]\n",
      "epoch:6 step:5871 [D loss: 0.702680, acc.: 50.00%] [G loss: 0.699586]\n",
      "epoch:6 step:5872 [D loss: 0.690781, acc.: 60.94%] [G loss: 0.817847]\n",
      "epoch:6 step:5873 [D loss: 0.708995, acc.: 46.88%] [G loss: 0.843126]\n",
      "epoch:6 step:5874 [D loss: 0.666756, acc.: 62.50%] [G loss: 0.795748]\n",
      "epoch:6 step:5875 [D loss: 0.736067, acc.: 51.56%] [G loss: 0.771636]\n",
      "epoch:6 step:5876 [D loss: 0.728745, acc.: 46.09%] [G loss: 0.751751]\n",
      "epoch:6 step:5877 [D loss: 0.717854, acc.: 39.06%] [G loss: 0.796917]\n",
      "epoch:6 step:5878 [D loss: 0.697774, acc.: 42.19%] [G loss: 0.740524]\n",
      "epoch:6 step:5879 [D loss: 0.674791, acc.: 58.59%] [G loss: 0.750399]\n",
      "epoch:6 step:5880 [D loss: 0.695600, acc.: 60.94%] [G loss: 0.792441]\n",
      "epoch:6 step:5881 [D loss: 0.707554, acc.: 44.53%] [G loss: 0.759692]\n",
      "epoch:6 step:5882 [D loss: 0.716147, acc.: 50.78%] [G loss: 0.725415]\n",
      "epoch:6 step:5883 [D loss: 0.708871, acc.: 42.19%] [G loss: 0.733490]\n",
      "epoch:6 step:5884 [D loss: 0.708384, acc.: 51.56%] [G loss: 0.731489]\n",
      "epoch:6 step:5885 [D loss: 0.885195, acc.: 30.47%] [G loss: 0.751772]\n",
      "epoch:6 step:5886 [D loss: 0.685091, acc.: 58.59%] [G loss: 0.769667]\n",
      "epoch:6 step:5887 [D loss: 0.708903, acc.: 52.34%] [G loss: 0.773523]\n",
      "epoch:6 step:5888 [D loss: 0.697118, acc.: 50.00%] [G loss: 0.767297]\n",
      "epoch:6 step:5889 [D loss: 0.679839, acc.: 56.25%] [G loss: 0.774996]\n",
      "epoch:6 step:5890 [D loss: 0.694153, acc.: 47.66%] [G loss: 0.739318]\n",
      "epoch:6 step:5891 [D loss: 0.691399, acc.: 49.22%] [G loss: 0.743847]\n",
      "epoch:6 step:5892 [D loss: 0.690960, acc.: 50.78%] [G loss: 0.745001]\n",
      "epoch:6 step:5893 [D loss: 0.672530, acc.: 52.34%] [G loss: 0.743051]\n",
      "epoch:6 step:5894 [D loss: 0.716067, acc.: 45.31%] [G loss: 0.760088]\n",
      "epoch:6 step:5895 [D loss: 0.685720, acc.: 53.12%] [G loss: 0.750479]\n",
      "epoch:6 step:5896 [D loss: 0.667917, acc.: 67.97%] [G loss: 0.744391]\n",
      "epoch:6 step:5897 [D loss: 0.667854, acc.: 55.47%] [G loss: 0.733958]\n",
      "epoch:6 step:5898 [D loss: 0.642859, acc.: 69.53%] [G loss: 0.769260]\n",
      "epoch:6 step:5899 [D loss: 0.681997, acc.: 54.69%] [G loss: 0.762568]\n",
      "epoch:6 step:5900 [D loss: 0.695415, acc.: 46.09%] [G loss: 0.744244]\n",
      "epoch:6 step:5901 [D loss: 0.690341, acc.: 46.88%] [G loss: 0.768586]\n",
      "epoch:6 step:5902 [D loss: 0.697045, acc.: 52.34%] [G loss: 0.735186]\n",
      "epoch:6 step:5903 [D loss: 0.723496, acc.: 41.41%] [G loss: 0.733154]\n",
      "epoch:6 step:5904 [D loss: 0.704805, acc.: 48.44%] [G loss: 0.698069]\n",
      "epoch:6 step:5905 [D loss: 0.687047, acc.: 52.34%] [G loss: 0.724115]\n",
      "epoch:6 step:5906 [D loss: 0.687326, acc.: 55.47%] [G loss: 0.727221]\n",
      "epoch:6 step:5907 [D loss: 0.694108, acc.: 51.56%] [G loss: 0.787182]\n",
      "epoch:6 step:5908 [D loss: 0.701439, acc.: 55.47%] [G loss: 0.815556]\n",
      "epoch:6 step:5909 [D loss: 0.651570, acc.: 60.16%] [G loss: 0.848662]\n",
      "epoch:6 step:5910 [D loss: 0.647665, acc.: 65.62%] [G loss: 0.860799]\n",
      "epoch:6 step:5911 [D loss: 0.621804, acc.: 68.75%] [G loss: 0.888808]\n",
      "epoch:6 step:5912 [D loss: 0.613247, acc.: 77.34%] [G loss: 0.981406]\n",
      "epoch:6 step:5913 [D loss: 0.708397, acc.: 48.44%] [G loss: 0.788673]\n",
      "epoch:6 step:5914 [D loss: 0.640148, acc.: 62.50%] [G loss: 0.776676]\n",
      "epoch:6 step:5915 [D loss: 0.665564, acc.: 64.06%] [G loss: 0.795745]\n",
      "epoch:6 step:5916 [D loss: 0.609429, acc.: 64.06%] [G loss: 0.910565]\n",
      "epoch:6 step:5917 [D loss: 0.754079, acc.: 46.09%] [G loss: 0.784747]\n",
      "epoch:6 step:5918 [D loss: 0.621473, acc.: 71.88%] [G loss: 0.794286]\n",
      "epoch:6 step:5919 [D loss: 0.830303, acc.: 25.78%] [G loss: 0.691924]\n",
      "epoch:6 step:5920 [D loss: 0.740946, acc.: 40.62%] [G loss: 0.840190]\n",
      "epoch:6 step:5921 [D loss: 0.699903, acc.: 51.56%] [G loss: 0.828687]\n",
      "epoch:6 step:5922 [D loss: 0.651890, acc.: 70.31%] [G loss: 0.766268]\n",
      "epoch:6 step:5923 [D loss: 0.728289, acc.: 46.09%] [G loss: 0.775715]\n",
      "epoch:6 step:5924 [D loss: 0.756023, acc.: 45.31%] [G loss: 0.870417]\n",
      "epoch:6 step:5925 [D loss: 0.691301, acc.: 53.12%] [G loss: 0.867241]\n",
      "epoch:6 step:5926 [D loss: 0.693707, acc.: 53.91%] [G loss: 0.739125]\n",
      "epoch:6 step:5927 [D loss: 0.646419, acc.: 67.97%] [G loss: 0.736603]\n",
      "epoch:6 step:5928 [D loss: 0.696045, acc.: 52.34%] [G loss: 0.830138]\n",
      "epoch:6 step:5929 [D loss: 0.752063, acc.: 40.62%] [G loss: 0.738440]\n",
      "epoch:6 step:5930 [D loss: 0.709372, acc.: 44.53%] [G loss: 0.724418]\n",
      "epoch:6 step:5931 [D loss: 0.693510, acc.: 50.78%] [G loss: 0.766399]\n",
      "epoch:6 step:5932 [D loss: 0.695785, acc.: 54.69%] [G loss: 0.733961]\n",
      "epoch:6 step:5933 [D loss: 0.688898, acc.: 53.12%] [G loss: 0.730965]\n",
      "epoch:6 step:5934 [D loss: 0.677496, acc.: 57.81%] [G loss: 0.749040]\n",
      "epoch:6 step:5935 [D loss: 0.688997, acc.: 50.00%] [G loss: 0.757379]\n",
      "epoch:6 step:5936 [D loss: 0.677540, acc.: 53.12%] [G loss: 0.749602]\n",
      "epoch:6 step:5937 [D loss: 0.662129, acc.: 62.50%] [G loss: 0.798175]\n",
      "epoch:6 step:5938 [D loss: 0.697796, acc.: 46.09%] [G loss: 0.780871]\n",
      "epoch:6 step:5939 [D loss: 0.674068, acc.: 56.25%] [G loss: 0.812404]\n",
      "epoch:6 step:5940 [D loss: 0.667419, acc.: 57.03%] [G loss: 0.841997]\n",
      "epoch:6 step:5941 [D loss: 0.672425, acc.: 50.78%] [G loss: 0.800115]\n",
      "epoch:6 step:5942 [D loss: 0.667803, acc.: 62.50%] [G loss: 0.836354]\n",
      "epoch:6 step:5943 [D loss: 0.695628, acc.: 50.78%] [G loss: 0.814039]\n",
      "epoch:6 step:5944 [D loss: 0.666493, acc.: 69.53%] [G loss: 0.726774]\n",
      "epoch:6 step:5945 [D loss: 0.686362, acc.: 55.47%] [G loss: 0.846585]\n",
      "epoch:6 step:5946 [D loss: 0.674686, acc.: 64.06%] [G loss: 0.776958]\n",
      "epoch:6 step:5947 [D loss: 0.636711, acc.: 68.75%] [G loss: 0.871260]\n",
      "epoch:6 step:5948 [D loss: 0.703557, acc.: 53.12%] [G loss: 0.883243]\n",
      "epoch:6 step:5949 [D loss: 0.626441, acc.: 67.19%] [G loss: 0.751982]\n",
      "epoch:6 step:5950 [D loss: 0.678837, acc.: 53.12%] [G loss: 0.710058]\n",
      "epoch:6 step:5951 [D loss: 0.676543, acc.: 57.81%] [G loss: 0.813294]\n",
      "epoch:6 step:5952 [D loss: 0.714468, acc.: 53.12%] [G loss: 0.834208]\n",
      "epoch:6 step:5953 [D loss: 0.722546, acc.: 42.19%] [G loss: 0.665669]\n",
      "epoch:6 step:5954 [D loss: 0.761266, acc.: 32.03%] [G loss: 0.666409]\n",
      "epoch:6 step:5955 [D loss: 0.713342, acc.: 46.88%] [G loss: 0.738560]\n",
      "epoch:6 step:5956 [D loss: 0.752326, acc.: 40.62%] [G loss: 0.664353]\n",
      "epoch:6 step:5957 [D loss: 0.722599, acc.: 42.19%] [G loss: 0.710053]\n",
      "epoch:6 step:5958 [D loss: 0.683564, acc.: 53.12%] [G loss: 0.737049]\n",
      "epoch:6 step:5959 [D loss: 0.692400, acc.: 51.56%] [G loss: 0.746908]\n",
      "epoch:6 step:5960 [D loss: 0.670583, acc.: 61.72%] [G loss: 0.793073]\n",
      "epoch:6 step:5961 [D loss: 0.688275, acc.: 55.47%] [G loss: 0.740661]\n",
      "epoch:6 step:5962 [D loss: 0.681811, acc.: 55.47%] [G loss: 0.745928]\n",
      "epoch:6 step:5963 [D loss: 0.652322, acc.: 64.84%] [G loss: 0.785834]\n",
      "epoch:6 step:5964 [D loss: 0.675431, acc.: 61.72%] [G loss: 0.779892]\n",
      "epoch:6 step:5965 [D loss: 0.653301, acc.: 58.59%] [G loss: 0.800104]\n",
      "epoch:6 step:5966 [D loss: 0.647692, acc.: 64.84%] [G loss: 0.798959]\n",
      "epoch:6 step:5967 [D loss: 0.690785, acc.: 49.22%] [G loss: 0.801309]\n",
      "epoch:6 step:5968 [D loss: 0.668672, acc.: 61.72%] [G loss: 0.780787]\n",
      "epoch:6 step:5969 [D loss: 0.669571, acc.: 57.81%] [G loss: 0.809409]\n",
      "epoch:6 step:5970 [D loss: 0.757375, acc.: 42.19%] [G loss: 0.743331]\n",
      "epoch:6 step:5971 [D loss: 0.735719, acc.: 37.50%] [G loss: 0.734788]\n",
      "epoch:6 step:5972 [D loss: 0.704780, acc.: 43.75%] [G loss: 0.709807]\n",
      "epoch:6 step:5973 [D loss: 0.711626, acc.: 46.88%] [G loss: 0.705093]\n",
      "epoch:6 step:5974 [D loss: 0.708021, acc.: 49.22%] [G loss: 0.715042]\n",
      "epoch:6 step:5975 [D loss: 0.693649, acc.: 52.34%] [G loss: 0.724709]\n",
      "epoch:6 step:5976 [D loss: 0.685591, acc.: 50.00%] [G loss: 0.754928]\n",
      "epoch:6 step:5977 [D loss: 0.704444, acc.: 51.56%] [G loss: 0.763621]\n",
      "epoch:6 step:5978 [D loss: 0.698461, acc.: 47.66%] [G loss: 0.758627]\n",
      "epoch:6 step:5979 [D loss: 0.672886, acc.: 53.12%] [G loss: 0.762582]\n",
      "epoch:6 step:5980 [D loss: 0.656750, acc.: 61.72%] [G loss: 0.803987]\n",
      "epoch:6 step:5981 [D loss: 0.652690, acc.: 60.94%] [G loss: 0.811921]\n",
      "epoch:6 step:5982 [D loss: 0.664221, acc.: 65.62%] [G loss: 0.733491]\n",
      "epoch:6 step:5983 [D loss: 0.664510, acc.: 62.50%] [G loss: 0.746381]\n",
      "epoch:6 step:5984 [D loss: 0.710860, acc.: 50.78%] [G loss: 0.776762]\n",
      "epoch:6 step:5985 [D loss: 0.738278, acc.: 39.06%] [G loss: 0.782817]\n",
      "epoch:6 step:5986 [D loss: 0.691342, acc.: 63.28%] [G loss: 0.712729]\n",
      "epoch:6 step:5987 [D loss: 0.717113, acc.: 47.66%] [G loss: 0.777878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5988 [D loss: 0.705343, acc.: 44.53%] [G loss: 0.731354]\n",
      "epoch:6 step:5989 [D loss: 0.708282, acc.: 53.91%] [G loss: 0.681840]\n",
      "epoch:6 step:5990 [D loss: 0.705245, acc.: 51.56%] [G loss: 0.732556]\n",
      "epoch:6 step:5991 [D loss: 0.687015, acc.: 51.56%] [G loss: 0.684289]\n",
      "epoch:6 step:5992 [D loss: 0.687064, acc.: 55.47%] [G loss: 0.695276]\n",
      "epoch:6 step:5993 [D loss: 0.664361, acc.: 57.81%] [G loss: 0.661268]\n",
      "epoch:6 step:5994 [D loss: 0.680001, acc.: 56.25%] [G loss: 0.704415]\n",
      "epoch:6 step:5995 [D loss: 0.689463, acc.: 56.25%] [G loss: 0.766361]\n",
      "epoch:6 step:5996 [D loss: 0.676991, acc.: 57.03%] [G loss: 0.720009]\n",
      "epoch:6 step:5997 [D loss: 0.686438, acc.: 53.91%] [G loss: 0.663743]\n",
      "epoch:6 step:5998 [D loss: 0.690679, acc.: 48.44%] [G loss: 0.735734]\n",
      "epoch:6 step:5999 [D loss: 0.725184, acc.: 42.19%] [G loss: 0.689316]\n",
      "epoch:6 step:6000 [D loss: 0.695234, acc.: 49.22%] [G loss: 0.671448]\n",
      "epoch:6 step:6001 [D loss: 0.681460, acc.: 57.03%] [G loss: 0.708913]\n",
      "epoch:6 step:6002 [D loss: 0.692352, acc.: 50.78%] [G loss: 0.665331]\n",
      "epoch:6 step:6003 [D loss: 0.671191, acc.: 65.62%] [G loss: 0.690272]\n",
      "epoch:6 step:6004 [D loss: 0.686918, acc.: 53.91%] [G loss: 0.739872]\n",
      "epoch:6 step:6005 [D loss: 0.704134, acc.: 52.34%] [G loss: 0.709068]\n",
      "epoch:6 step:6006 [D loss: 0.691701, acc.: 53.12%] [G loss: 0.737455]\n",
      "epoch:6 step:6007 [D loss: 0.691602, acc.: 50.00%] [G loss: 0.752091]\n",
      "epoch:6 step:6008 [D loss: 0.679339, acc.: 58.59%] [G loss: 0.739378]\n",
      "epoch:6 step:6009 [D loss: 0.667710, acc.: 65.62%] [G loss: 0.729702]\n",
      "epoch:6 step:6010 [D loss: 0.688470, acc.: 50.00%] [G loss: 0.725768]\n",
      "epoch:6 step:6011 [D loss: 0.681457, acc.: 59.38%] [G loss: 0.704637]\n",
      "epoch:6 step:6012 [D loss: 0.717230, acc.: 46.09%] [G loss: 0.746956]\n",
      "epoch:6 step:6013 [D loss: 0.706931, acc.: 49.22%] [G loss: 0.731375]\n",
      "epoch:6 step:6014 [D loss: 0.707421, acc.: 45.31%] [G loss: 0.706620]\n",
      "epoch:6 step:6015 [D loss: 0.703091, acc.: 44.53%] [G loss: 0.716081]\n",
      "epoch:6 step:6016 [D loss: 0.709048, acc.: 46.88%] [G loss: 0.748936]\n",
      "epoch:6 step:6017 [D loss: 0.699168, acc.: 49.22%] [G loss: 0.745427]\n",
      "epoch:6 step:6018 [D loss: 0.676711, acc.: 50.78%] [G loss: 0.741697]\n",
      "epoch:6 step:6019 [D loss: 0.692089, acc.: 52.34%] [G loss: 0.755583]\n",
      "epoch:6 step:6020 [D loss: 0.677726, acc.: 52.34%] [G loss: 0.782819]\n",
      "epoch:6 step:6021 [D loss: 0.670107, acc.: 59.38%] [G loss: 0.758280]\n",
      "epoch:6 step:6022 [D loss: 0.689510, acc.: 51.56%] [G loss: 0.744634]\n",
      "epoch:6 step:6023 [D loss: 0.720033, acc.: 45.31%] [G loss: 0.743884]\n",
      "epoch:6 step:6024 [D loss: 0.630498, acc.: 71.88%] [G loss: 0.884670]\n",
      "epoch:6 step:6025 [D loss: 0.682448, acc.: 60.16%] [G loss: 0.839223]\n",
      "epoch:6 step:6026 [D loss: 0.639560, acc.: 67.97%] [G loss: 0.996136]\n",
      "epoch:6 step:6027 [D loss: 0.638447, acc.: 67.97%] [G loss: 0.837065]\n",
      "epoch:6 step:6028 [D loss: 0.630629, acc.: 70.31%] [G loss: 0.807449]\n",
      "epoch:6 step:6029 [D loss: 0.710255, acc.: 50.78%] [G loss: 0.777023]\n",
      "epoch:6 step:6030 [D loss: 0.683022, acc.: 56.25%] [G loss: 0.730039]\n",
      "epoch:6 step:6031 [D loss: 0.677067, acc.: 50.78%] [G loss: 0.701204]\n",
      "epoch:6 step:6032 [D loss: 0.713633, acc.: 52.34%] [G loss: 0.693429]\n",
      "epoch:6 step:6033 [D loss: 0.774084, acc.: 30.47%] [G loss: 0.706608]\n",
      "epoch:6 step:6034 [D loss: 0.735201, acc.: 39.06%] [G loss: 0.728828]\n",
      "epoch:6 step:6035 [D loss: 0.738074, acc.: 51.56%] [G loss: 0.793535]\n",
      "epoch:6 step:6036 [D loss: 0.691722, acc.: 56.25%] [G loss: 0.836583]\n",
      "epoch:6 step:6037 [D loss: 0.683823, acc.: 57.03%] [G loss: 0.845752]\n",
      "epoch:6 step:6038 [D loss: 0.684286, acc.: 52.34%] [G loss: 0.785101]\n",
      "epoch:6 step:6039 [D loss: 0.691811, acc.: 48.44%] [G loss: 0.749133]\n",
      "epoch:6 step:6040 [D loss: 0.709911, acc.: 49.22%] [G loss: 0.761807]\n",
      "epoch:6 step:6041 [D loss: 0.670270, acc.: 63.28%] [G loss: 0.776078]\n",
      "epoch:6 step:6042 [D loss: 0.695518, acc.: 55.47%] [G loss: 0.744439]\n",
      "epoch:6 step:6043 [D loss: 0.731584, acc.: 36.72%] [G loss: 0.759372]\n",
      "epoch:6 step:6044 [D loss: 0.698462, acc.: 49.22%] [G loss: 0.715827]\n",
      "epoch:6 step:6045 [D loss: 0.695325, acc.: 50.78%] [G loss: 0.714520]\n",
      "epoch:6 step:6046 [D loss: 0.702463, acc.: 47.66%] [G loss: 0.713243]\n",
      "epoch:6 step:6047 [D loss: 0.701600, acc.: 44.53%] [G loss: 0.709109]\n",
      "epoch:6 step:6048 [D loss: 0.711006, acc.: 45.31%] [G loss: 0.715278]\n",
      "epoch:6 step:6049 [D loss: 0.706045, acc.: 42.19%] [G loss: 0.690912]\n",
      "epoch:6 step:6050 [D loss: 0.682946, acc.: 55.47%] [G loss: 0.719636]\n",
      "epoch:6 step:6051 [D loss: 0.685696, acc.: 55.47%] [G loss: 0.719392]\n",
      "epoch:6 step:6052 [D loss: 0.676180, acc.: 59.38%] [G loss: 0.729137]\n",
      "epoch:6 step:6053 [D loss: 0.682127, acc.: 54.69%] [G loss: 0.723422]\n",
      "epoch:6 step:6054 [D loss: 0.698113, acc.: 44.53%] [G loss: 0.727370]\n",
      "epoch:6 step:6055 [D loss: 0.687238, acc.: 51.56%] [G loss: 0.728000]\n",
      "epoch:6 step:6056 [D loss: 0.678064, acc.: 56.25%] [G loss: 0.722497]\n",
      "epoch:6 step:6057 [D loss: 0.677688, acc.: 60.16%] [G loss: 0.759689]\n",
      "epoch:6 step:6058 [D loss: 0.662763, acc.: 67.97%] [G loss: 0.748399]\n",
      "epoch:6 step:6059 [D loss: 0.716668, acc.: 47.66%] [G loss: 0.738779]\n",
      "epoch:6 step:6060 [D loss: 0.705951, acc.: 47.66%] [G loss: 0.699085]\n",
      "epoch:6 step:6061 [D loss: 0.706169, acc.: 46.88%] [G loss: 0.712529]\n",
      "epoch:6 step:6062 [D loss: 0.711677, acc.: 44.53%] [G loss: 0.694353]\n",
      "epoch:6 step:6063 [D loss: 0.713153, acc.: 40.62%] [G loss: 0.687136]\n",
      "epoch:6 step:6064 [D loss: 0.686866, acc.: 57.81%] [G loss: 0.710942]\n",
      "epoch:6 step:6065 [D loss: 0.697740, acc.: 55.47%] [G loss: 0.704681]\n",
      "epoch:6 step:6066 [D loss: 0.701929, acc.: 46.09%] [G loss: 0.704878]\n",
      "epoch:6 step:6067 [D loss: 0.691914, acc.: 47.66%] [G loss: 0.729195]\n",
      "epoch:6 step:6068 [D loss: 0.687190, acc.: 56.25%] [G loss: 0.731409]\n",
      "epoch:6 step:6069 [D loss: 0.682287, acc.: 57.03%] [G loss: 0.744957]\n",
      "epoch:6 step:6070 [D loss: 0.689202, acc.: 54.69%] [G loss: 0.708861]\n",
      "epoch:6 step:6071 [D loss: 0.689008, acc.: 54.69%] [G loss: 0.738069]\n",
      "epoch:6 step:6072 [D loss: 0.681375, acc.: 56.25%] [G loss: 0.727640]\n",
      "epoch:6 step:6073 [D loss: 0.678529, acc.: 63.28%] [G loss: 0.746372]\n",
      "epoch:6 step:6074 [D loss: 0.667892, acc.: 64.84%] [G loss: 0.759968]\n",
      "epoch:6 step:6075 [D loss: 0.683327, acc.: 53.91%] [G loss: 0.748479]\n",
      "epoch:6 step:6076 [D loss: 0.672887, acc.: 57.81%] [G loss: 0.747300]\n",
      "epoch:6 step:6077 [D loss: 0.691953, acc.: 50.00%] [G loss: 0.737863]\n",
      "epoch:6 step:6078 [D loss: 0.694333, acc.: 42.97%] [G loss: 0.714156]\n",
      "epoch:6 step:6079 [D loss: 0.686893, acc.: 51.56%] [G loss: 0.725086]\n",
      "epoch:6 step:6080 [D loss: 0.716296, acc.: 46.88%] [G loss: 0.697684]\n",
      "epoch:6 step:6081 [D loss: 0.682927, acc.: 55.47%] [G loss: 0.716080]\n",
      "epoch:6 step:6082 [D loss: 0.691002, acc.: 52.34%] [G loss: 0.698204]\n",
      "epoch:6 step:6083 [D loss: 0.713231, acc.: 42.19%] [G loss: 0.724724]\n",
      "epoch:6 step:6084 [D loss: 0.712092, acc.: 46.09%] [G loss: 0.733791]\n",
      "epoch:6 step:6085 [D loss: 0.680359, acc.: 57.81%] [G loss: 0.730383]\n",
      "epoch:6 step:6086 [D loss: 0.689513, acc.: 54.69%] [G loss: 0.719739]\n",
      "epoch:6 step:6087 [D loss: 0.693771, acc.: 50.78%] [G loss: 0.733130]\n",
      "epoch:6 step:6088 [D loss: 0.696165, acc.: 51.56%] [G loss: 0.743741]\n",
      "epoch:6 step:6089 [D loss: 0.678423, acc.: 62.50%] [G loss: 0.763611]\n",
      "epoch:6 step:6090 [D loss: 0.654669, acc.: 64.06%] [G loss: 0.734637]\n",
      "epoch:6 step:6091 [D loss: 0.672305, acc.: 63.28%] [G loss: 0.763435]\n",
      "epoch:6 step:6092 [D loss: 0.633828, acc.: 67.19%] [G loss: 0.701169]\n",
      "epoch:6 step:6093 [D loss: 0.668858, acc.: 64.84%] [G loss: 0.816956]\n",
      "epoch:6 step:6094 [D loss: 0.697088, acc.: 46.09%] [G loss: 0.810004]\n",
      "epoch:6 step:6095 [D loss: 0.722677, acc.: 42.19%] [G loss: 0.715460]\n",
      "epoch:6 step:6096 [D loss: 0.710483, acc.: 43.75%] [G loss: 0.751217]\n",
      "epoch:6 step:6097 [D loss: 0.696927, acc.: 48.44%] [G loss: 0.705664]\n",
      "epoch:6 step:6098 [D loss: 0.715226, acc.: 46.09%] [G loss: 0.771942]\n",
      "epoch:6 step:6099 [D loss: 0.724872, acc.: 46.88%] [G loss: 0.775889]\n",
      "epoch:6 step:6100 [D loss: 0.684570, acc.: 54.69%] [G loss: 0.800418]\n",
      "epoch:6 step:6101 [D loss: 0.662685, acc.: 62.50%] [G loss: 0.850177]\n",
      "epoch:6 step:6102 [D loss: 0.674862, acc.: 61.72%] [G loss: 0.840115]\n",
      "epoch:6 step:6103 [D loss: 0.674493, acc.: 57.81%] [G loss: 0.811158]\n",
      "epoch:6 step:6104 [D loss: 0.687236, acc.: 59.38%] [G loss: 0.790447]\n",
      "epoch:6 step:6105 [D loss: 0.655944, acc.: 64.06%] [G loss: 0.716427]\n",
      "epoch:6 step:6106 [D loss: 0.664060, acc.: 58.59%] [G loss: 0.748971]\n",
      "epoch:6 step:6107 [D loss: 0.659273, acc.: 62.50%] [G loss: 0.802370]\n",
      "epoch:6 step:6108 [D loss: 0.721297, acc.: 42.19%] [G loss: 0.707490]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6109 [D loss: 0.743617, acc.: 32.03%] [G loss: 0.696945]\n",
      "epoch:6 step:6110 [D loss: 0.691072, acc.: 47.66%] [G loss: 0.710269]\n",
      "epoch:6 step:6111 [D loss: 0.696973, acc.: 47.66%] [G loss: 0.713092]\n",
      "epoch:6 step:6112 [D loss: 0.728822, acc.: 44.53%] [G loss: 0.658330]\n",
      "epoch:6 step:6113 [D loss: 0.690617, acc.: 53.12%] [G loss: 0.694567]\n",
      "epoch:6 step:6114 [D loss: 0.688275, acc.: 49.22%] [G loss: 0.688626]\n",
      "epoch:6 step:6115 [D loss: 0.695568, acc.: 46.88%] [G loss: 0.704527]\n",
      "epoch:6 step:6116 [D loss: 0.703972, acc.: 47.66%] [G loss: 0.734897]\n",
      "epoch:6 step:6117 [D loss: 0.680569, acc.: 51.56%] [G loss: 0.720669]\n",
      "epoch:6 step:6118 [D loss: 0.685804, acc.: 50.00%] [G loss: 0.756824]\n",
      "epoch:6 step:6119 [D loss: 0.669780, acc.: 60.94%] [G loss: 0.745817]\n",
      "epoch:6 step:6120 [D loss: 0.691198, acc.: 51.56%] [G loss: 0.783423]\n",
      "epoch:6 step:6121 [D loss: 0.644433, acc.: 67.19%] [G loss: 0.725812]\n",
      "epoch:6 step:6122 [D loss: 0.689927, acc.: 53.12%] [G loss: 0.832217]\n",
      "epoch:6 step:6123 [D loss: 0.696547, acc.: 44.53%] [G loss: 0.776320]\n",
      "epoch:6 step:6124 [D loss: 0.675245, acc.: 53.91%] [G loss: 0.814520]\n",
      "epoch:6 step:6125 [D loss: 0.677678, acc.: 50.78%] [G loss: 0.765749]\n",
      "epoch:6 step:6126 [D loss: 0.697124, acc.: 50.78%] [G loss: 0.783929]\n",
      "epoch:6 step:6127 [D loss: 0.666441, acc.: 59.38%] [G loss: 0.808731]\n",
      "epoch:6 step:6128 [D loss: 0.692926, acc.: 59.38%] [G loss: 0.789511]\n",
      "epoch:6 step:6129 [D loss: 0.663307, acc.: 62.50%] [G loss: 0.816301]\n",
      "epoch:6 step:6130 [D loss: 0.654786, acc.: 64.06%] [G loss: 0.765897]\n",
      "epoch:6 step:6131 [D loss: 0.708769, acc.: 53.12%] [G loss: 0.811785]\n",
      "epoch:6 step:6132 [D loss: 0.714372, acc.: 43.75%] [G loss: 0.782137]\n",
      "epoch:6 step:6133 [D loss: 0.717385, acc.: 42.97%] [G loss: 0.798374]\n",
      "epoch:6 step:6134 [D loss: 0.715839, acc.: 47.66%] [G loss: 0.765141]\n",
      "epoch:6 step:6135 [D loss: 0.673396, acc.: 58.59%] [G loss: 0.757617]\n",
      "epoch:6 step:6136 [D loss: 0.676506, acc.: 53.91%] [G loss: 0.799247]\n",
      "epoch:6 step:6137 [D loss: 0.676087, acc.: 55.47%] [G loss: 0.748270]\n",
      "epoch:6 step:6138 [D loss: 0.682768, acc.: 54.69%] [G loss: 0.761044]\n",
      "epoch:6 step:6139 [D loss: 0.669841, acc.: 59.38%] [G loss: 0.770968]\n",
      "epoch:6 step:6140 [D loss: 0.642897, acc.: 61.72%] [G loss: 0.797369]\n",
      "epoch:6 step:6141 [D loss: 0.684752, acc.: 52.34%] [G loss: 0.781802]\n",
      "epoch:6 step:6142 [D loss: 0.636980, acc.: 60.94%] [G loss: 0.862334]\n",
      "epoch:6 step:6143 [D loss: 0.651834, acc.: 63.28%] [G loss: 1.357071]\n",
      "epoch:6 step:6144 [D loss: 0.657843, acc.: 55.47%] [G loss: 0.775948]\n",
      "epoch:6 step:6145 [D loss: 0.644010, acc.: 57.81%] [G loss: 0.789026]\n",
      "epoch:6 step:6146 [D loss: 0.679968, acc.: 51.56%] [G loss: 0.715348]\n",
      "epoch:6 step:6147 [D loss: 0.705423, acc.: 46.09%] [G loss: 0.868983]\n",
      "epoch:6 step:6148 [D loss: 0.718041, acc.: 64.84%] [G loss: 0.789733]\n",
      "epoch:6 step:6149 [D loss: 0.646513, acc.: 57.03%] [G loss: 0.872192]\n",
      "epoch:6 step:6150 [D loss: 0.717990, acc.: 44.53%] [G loss: 1.199246]\n",
      "epoch:6 step:6151 [D loss: 0.689499, acc.: 54.69%] [G loss: 0.834498]\n",
      "epoch:6 step:6152 [D loss: 0.661177, acc.: 64.06%] [G loss: 0.848786]\n",
      "epoch:6 step:6153 [D loss: 0.646648, acc.: 60.16%] [G loss: 0.856925]\n",
      "epoch:6 step:6154 [D loss: 0.672629, acc.: 60.16%] [G loss: 0.910760]\n",
      "epoch:6 step:6155 [D loss: 0.629007, acc.: 60.16%] [G loss: 0.840389]\n",
      "epoch:6 step:6156 [D loss: 0.641039, acc.: 64.06%] [G loss: 0.844809]\n",
      "epoch:6 step:6157 [D loss: 0.683473, acc.: 53.12%] [G loss: 0.918090]\n",
      "epoch:6 step:6158 [D loss: 0.710823, acc.: 47.66%] [G loss: 0.747689]\n",
      "epoch:6 step:6159 [D loss: 0.704117, acc.: 45.31%] [G loss: 0.796138]\n",
      "epoch:6 step:6160 [D loss: 0.679274, acc.: 50.00%] [G loss: 0.747259]\n",
      "epoch:6 step:6161 [D loss: 0.701426, acc.: 46.88%] [G loss: 0.774485]\n",
      "epoch:6 step:6162 [D loss: 0.732135, acc.: 40.62%] [G loss: 0.719137]\n",
      "epoch:6 step:6163 [D loss: 0.676074, acc.: 52.34%] [G loss: 0.737653]\n",
      "epoch:6 step:6164 [D loss: 0.689682, acc.: 46.09%] [G loss: 0.783798]\n",
      "epoch:6 step:6165 [D loss: 0.605381, acc.: 54.69%] [G loss: 0.833618]\n",
      "epoch:6 step:6166 [D loss: 0.702769, acc.: 50.00%] [G loss: 0.761182]\n",
      "epoch:6 step:6167 [D loss: 0.673201, acc.: 58.59%] [G loss: 0.768969]\n",
      "epoch:6 step:6168 [D loss: 0.658014, acc.: 58.59%] [G loss: 0.754313]\n",
      "epoch:6 step:6169 [D loss: 0.691170, acc.: 47.66%] [G loss: 0.750836]\n",
      "epoch:6 step:6170 [D loss: 0.681844, acc.: 54.69%] [G loss: 0.769214]\n",
      "epoch:6 step:6171 [D loss: 0.652798, acc.: 62.50%] [G loss: 0.704930]\n",
      "epoch:6 step:6172 [D loss: 0.466959, acc.: 73.44%] [G loss: 0.782567]\n",
      "epoch:6 step:6173 [D loss: 0.662294, acc.: 57.81%] [G loss: 0.852028]\n",
      "epoch:6 step:6174 [D loss: 0.617139, acc.: 60.94%] [G loss: 0.777240]\n",
      "epoch:6 step:6175 [D loss: 0.724785, acc.: 43.75%] [G loss: 0.760969]\n",
      "epoch:6 step:6176 [D loss: 0.587096, acc.: 78.12%] [G loss: 0.743745]\n",
      "epoch:6 step:6177 [D loss: 0.655459, acc.: 64.84%] [G loss: 0.796144]\n",
      "epoch:6 step:6178 [D loss: 0.718996, acc.: 47.66%] [G loss: 0.738271]\n",
      "epoch:6 step:6179 [D loss: 0.759644, acc.: 34.38%] [G loss: 0.900590]\n",
      "epoch:6 step:6180 [D loss: 0.642331, acc.: 65.62%] [G loss: 0.924294]\n",
      "epoch:6 step:6181 [D loss: 0.779267, acc.: 42.97%] [G loss: 0.770328]\n",
      "epoch:6 step:6182 [D loss: 0.754091, acc.: 33.59%] [G loss: 0.724117]\n",
      "epoch:6 step:6183 [D loss: 0.750067, acc.: 31.25%] [G loss: 0.775427]\n",
      "epoch:6 step:6184 [D loss: 0.719025, acc.: 50.78%] [G loss: 0.778791]\n",
      "epoch:6 step:6185 [D loss: 0.701995, acc.: 48.44%] [G loss: 0.740585]\n",
      "epoch:6 step:6186 [D loss: 0.694299, acc.: 56.25%] [G loss: 0.638492]\n",
      "epoch:6 step:6187 [D loss: 0.676271, acc.: 52.34%] [G loss: 0.696185]\n",
      "epoch:6 step:6188 [D loss: 0.694880, acc.: 53.91%] [G loss: 0.816446]\n",
      "epoch:6 step:6189 [D loss: 0.655261, acc.: 58.59%] [G loss: 0.869090]\n",
      "epoch:6 step:6190 [D loss: 0.673712, acc.: 52.34%] [G loss: 0.832026]\n",
      "epoch:6 step:6191 [D loss: 0.707806, acc.: 46.88%] [G loss: 0.800851]\n",
      "epoch:6 step:6192 [D loss: 0.674076, acc.: 57.81%] [G loss: 0.837258]\n",
      "epoch:6 step:6193 [D loss: 0.677626, acc.: 57.81%] [G loss: 0.806969]\n",
      "epoch:6 step:6194 [D loss: 0.649553, acc.: 61.72%] [G loss: 0.870147]\n",
      "epoch:6 step:6195 [D loss: 0.631215, acc.: 62.50%] [G loss: 0.893522]\n",
      "epoch:6 step:6196 [D loss: 0.632074, acc.: 67.97%] [G loss: 0.849386]\n",
      "epoch:6 step:6197 [D loss: 0.638632, acc.: 64.84%] [G loss: 0.872480]\n",
      "epoch:6 step:6198 [D loss: 0.690018, acc.: 49.22%] [G loss: 0.832179]\n",
      "epoch:6 step:6199 [D loss: 0.691945, acc.: 51.56%] [G loss: 0.802409]\n",
      "epoch:6 step:6200 [D loss: 0.676031, acc.: 48.44%] [G loss: 0.733615]\n",
      "epoch:6 step:6201 [D loss: 0.706208, acc.: 47.66%] [G loss: 0.774798]\n",
      "epoch:6 step:6202 [D loss: 0.722176, acc.: 48.44%] [G loss: 0.757019]\n",
      "epoch:6 step:6203 [D loss: 0.664171, acc.: 65.62%] [G loss: 0.772795]\n",
      "epoch:6 step:6204 [D loss: 0.654992, acc.: 65.62%] [G loss: 0.760586]\n",
      "epoch:6 step:6205 [D loss: 0.734787, acc.: 46.88%] [G loss: 0.795874]\n",
      "epoch:6 step:6206 [D loss: 0.674782, acc.: 54.69%] [G loss: 0.824402]\n",
      "epoch:6 step:6207 [D loss: 0.632956, acc.: 71.09%] [G loss: 0.967425]\n",
      "epoch:6 step:6208 [D loss: 0.623659, acc.: 72.66%] [G loss: 0.836749]\n",
      "epoch:6 step:6209 [D loss: 0.730287, acc.: 47.66%] [G loss: 0.765584]\n",
      "epoch:6 step:6210 [D loss: 0.702427, acc.: 48.44%] [G loss: 0.787581]\n",
      "epoch:6 step:6211 [D loss: 0.687034, acc.: 56.25%] [G loss: 0.754725]\n",
      "epoch:6 step:6212 [D loss: 0.726712, acc.: 44.53%] [G loss: 0.718750]\n",
      "epoch:6 step:6213 [D loss: 0.731846, acc.: 35.16%] [G loss: 0.742207]\n",
      "epoch:6 step:6214 [D loss: 0.676197, acc.: 52.34%] [G loss: 0.746183]\n",
      "epoch:6 step:6215 [D loss: 0.702221, acc.: 51.56%] [G loss: 0.762111]\n",
      "epoch:6 step:6216 [D loss: 0.682928, acc.: 53.91%] [G loss: 0.777499]\n",
      "epoch:6 step:6217 [D loss: 0.666489, acc.: 57.81%] [G loss: 0.754198]\n",
      "epoch:6 step:6218 [D loss: 0.661412, acc.: 56.25%] [G loss: 0.743214]\n",
      "epoch:6 step:6219 [D loss: 0.660570, acc.: 60.94%] [G loss: 0.802939]\n",
      "epoch:6 step:6220 [D loss: 0.697919, acc.: 60.16%] [G loss: 0.711667]\n",
      "epoch:6 step:6221 [D loss: 0.736820, acc.: 47.66%] [G loss: 0.729124]\n",
      "epoch:6 step:6222 [D loss: 0.743149, acc.: 40.62%] [G loss: 0.726124]\n",
      "epoch:6 step:6223 [D loss: 0.678725, acc.: 57.03%] [G loss: 0.711187]\n",
      "epoch:6 step:6224 [D loss: 0.673127, acc.: 46.88%] [G loss: 0.823454]\n",
      "epoch:6 step:6225 [D loss: 0.705513, acc.: 51.56%] [G loss: 0.811237]\n",
      "epoch:6 step:6226 [D loss: 0.504843, acc.: 65.62%] [G loss: 0.791716]\n",
      "epoch:6 step:6227 [D loss: 0.702666, acc.: 53.91%] [G loss: 0.779467]\n",
      "epoch:6 step:6228 [D loss: 0.671356, acc.: 58.59%] [G loss: 0.754356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6229 [D loss: 0.672609, acc.: 53.12%] [G loss: 0.793378]\n",
      "epoch:6 step:6230 [D loss: 0.668436, acc.: 61.72%] [G loss: 0.807929]\n",
      "epoch:6 step:6231 [D loss: 0.665923, acc.: 62.50%] [G loss: 0.780028]\n",
      "epoch:6 step:6232 [D loss: 0.697690, acc.: 52.34%] [G loss: 0.751845]\n",
      "epoch:6 step:6233 [D loss: 0.681345, acc.: 54.69%] [G loss: 0.735607]\n",
      "epoch:6 step:6234 [D loss: 0.685771, acc.: 57.03%] [G loss: 0.729211]\n",
      "epoch:6 step:6235 [D loss: 0.689855, acc.: 49.22%] [G loss: 0.743571]\n",
      "epoch:6 step:6236 [D loss: 0.712885, acc.: 44.53%] [G loss: 0.722501]\n",
      "epoch:6 step:6237 [D loss: 0.705448, acc.: 49.22%] [G loss: 0.712644]\n",
      "epoch:6 step:6238 [D loss: 0.671485, acc.: 60.16%] [G loss: 0.761521]\n",
      "epoch:6 step:6239 [D loss: 0.679990, acc.: 56.25%] [G loss: 0.783999]\n",
      "epoch:6 step:6240 [D loss: 0.656619, acc.: 61.72%] [G loss: 0.759365]\n",
      "epoch:6 step:6241 [D loss: 0.662633, acc.: 59.38%] [G loss: 0.758058]\n",
      "epoch:6 step:6242 [D loss: 0.662417, acc.: 55.47%] [G loss: 0.757777]\n",
      "epoch:6 step:6243 [D loss: 0.686038, acc.: 51.56%] [G loss: 0.769858]\n",
      "epoch:6 step:6244 [D loss: 0.670675, acc.: 47.66%] [G loss: 0.751095]\n",
      "epoch:6 step:6245 [D loss: 0.693980, acc.: 47.66%] [G loss: 0.757775]\n",
      "epoch:6 step:6246 [D loss: 0.690758, acc.: 53.12%] [G loss: 0.783182]\n",
      "epoch:6 step:6247 [D loss: 0.742546, acc.: 40.62%] [G loss: 0.722483]\n",
      "epoch:6 step:6248 [D loss: 0.718844, acc.: 47.66%] [G loss: 0.710288]\n",
      "epoch:6 step:6249 [D loss: 0.746836, acc.: 35.16%] [G loss: 0.712227]\n",
      "epoch:6 step:6250 [D loss: 0.712053, acc.: 43.75%] [G loss: 0.745538]\n",
      "epoch:6 step:6251 [D loss: 0.702924, acc.: 43.75%] [G loss: 0.757334]\n",
      "epoch:6 step:6252 [D loss: 0.676160, acc.: 48.44%] [G loss: 0.789247]\n",
      "epoch:6 step:6253 [D loss: 0.689463, acc.: 52.34%] [G loss: 0.808138]\n",
      "epoch:6 step:6254 [D loss: 0.685759, acc.: 52.34%] [G loss: 0.943146]\n",
      "epoch:6 step:6255 [D loss: 0.667344, acc.: 58.59%] [G loss: 0.789979]\n",
      "epoch:6 step:6256 [D loss: 0.671720, acc.: 63.28%] [G loss: 0.870980]\n",
      "epoch:6 step:6257 [D loss: 0.718310, acc.: 46.88%] [G loss: 0.869289]\n",
      "epoch:6 step:6258 [D loss: 0.682114, acc.: 57.03%] [G loss: 0.878774]\n",
      "epoch:6 step:6259 [D loss: 0.680576, acc.: 54.69%] [G loss: 0.812628]\n",
      "epoch:6 step:6260 [D loss: 0.707336, acc.: 55.47%] [G loss: 0.782332]\n",
      "epoch:6 step:6261 [D loss: 0.700599, acc.: 39.84%] [G loss: 0.763298]\n",
      "epoch:6 step:6262 [D loss: 0.703882, acc.: 48.44%] [G loss: 0.788290]\n",
      "epoch:6 step:6263 [D loss: 0.717690, acc.: 44.53%] [G loss: 0.735389]\n",
      "epoch:6 step:6264 [D loss: 0.718652, acc.: 41.41%] [G loss: 0.749096]\n",
      "epoch:6 step:6265 [D loss: 0.703561, acc.: 46.09%] [G loss: 0.736387]\n",
      "epoch:6 step:6266 [D loss: 0.732315, acc.: 42.97%] [G loss: 0.739541]\n",
      "epoch:6 step:6267 [D loss: 0.686546, acc.: 57.03%] [G loss: 0.729691]\n",
      "epoch:6 step:6268 [D loss: 0.678805, acc.: 57.81%] [G loss: 0.769406]\n",
      "epoch:6 step:6269 [D loss: 0.675108, acc.: 53.91%] [G loss: 0.761325]\n",
      "epoch:6 step:6270 [D loss: 0.657246, acc.: 66.41%] [G loss: 0.770904]\n",
      "epoch:6 step:6271 [D loss: 0.668320, acc.: 59.38%] [G loss: 0.739763]\n",
      "epoch:6 step:6272 [D loss: 0.683735, acc.: 55.47%] [G loss: 0.761958]\n",
      "epoch:6 step:6273 [D loss: 0.663169, acc.: 58.59%] [G loss: 0.770972]\n",
      "epoch:6 step:6274 [D loss: 0.672532, acc.: 55.47%] [G loss: 0.733319]\n",
      "epoch:6 step:6275 [D loss: 0.682581, acc.: 55.47%] [G loss: 0.777421]\n",
      "epoch:6 step:6276 [D loss: 0.714661, acc.: 50.00%] [G loss: 0.727438]\n",
      "epoch:6 step:6277 [D loss: 0.720080, acc.: 46.88%] [G loss: 0.735150]\n",
      "epoch:6 step:6278 [D loss: 0.726856, acc.: 38.28%] [G loss: 0.730604]\n",
      "epoch:6 step:6279 [D loss: 0.710498, acc.: 42.19%] [G loss: 0.733971]\n",
      "epoch:6 step:6280 [D loss: 0.701393, acc.: 43.75%] [G loss: 0.745065]\n",
      "epoch:6 step:6281 [D loss: 0.683392, acc.: 50.78%] [G loss: 0.738572]\n",
      "epoch:6 step:6282 [D loss: 0.668621, acc.: 63.28%] [G loss: 0.759357]\n",
      "epoch:6 step:6283 [D loss: 0.668380, acc.: 57.03%] [G loss: 0.750346]\n",
      "epoch:6 step:6284 [D loss: 0.682094, acc.: 57.03%] [G loss: 0.765787]\n",
      "epoch:6 step:6285 [D loss: 0.701773, acc.: 54.69%] [G loss: 0.746693]\n",
      "epoch:6 step:6286 [D loss: 0.668499, acc.: 57.03%] [G loss: 0.798713]\n",
      "epoch:6 step:6287 [D loss: 0.687328, acc.: 49.22%] [G loss: 0.782404]\n",
      "epoch:6 step:6288 [D loss: 0.665057, acc.: 61.72%] [G loss: 0.759745]\n",
      "epoch:6 step:6289 [D loss: 0.677346, acc.: 59.38%] [G loss: 0.749881]\n",
      "epoch:6 step:6290 [D loss: 0.687595, acc.: 58.59%] [G loss: 0.731274]\n",
      "epoch:6 step:6291 [D loss: 0.692523, acc.: 49.22%] [G loss: 0.699371]\n",
      "epoch:6 step:6292 [D loss: 0.670315, acc.: 53.91%] [G loss: 0.717723]\n",
      "epoch:6 step:6293 [D loss: 0.707710, acc.: 44.53%] [G loss: 0.737535]\n",
      "epoch:6 step:6294 [D loss: 0.733866, acc.: 42.19%] [G loss: 0.765916]\n",
      "epoch:6 step:6295 [D loss: 0.693960, acc.: 55.47%] [G loss: 0.699768]\n",
      "epoch:6 step:6296 [D loss: 0.689535, acc.: 50.78%] [G loss: 0.712906]\n",
      "epoch:6 step:6297 [D loss: 0.686337, acc.: 49.22%] [G loss: 0.722715]\n",
      "epoch:6 step:6298 [D loss: 0.693882, acc.: 52.34%] [G loss: 0.716515]\n",
      "epoch:6 step:6299 [D loss: 0.690985, acc.: 59.38%] [G loss: 0.747416]\n",
      "epoch:6 step:6300 [D loss: 0.649238, acc.: 63.28%] [G loss: 0.777503]\n",
      "epoch:6 step:6301 [D loss: 0.704539, acc.: 54.69%] [G loss: 0.753914]\n",
      "epoch:6 step:6302 [D loss: 0.682150, acc.: 54.69%] [G loss: 0.754144]\n",
      "epoch:6 step:6303 [D loss: 0.678948, acc.: 68.75%] [G loss: 0.743489]\n",
      "epoch:6 step:6304 [D loss: 0.677518, acc.: 55.47%] [G loss: 0.741786]\n",
      "epoch:6 step:6305 [D loss: 0.730245, acc.: 41.41%] [G loss: 0.695074]\n",
      "epoch:6 step:6306 [D loss: 0.711014, acc.: 44.53%] [G loss: 0.720653]\n",
      "epoch:6 step:6307 [D loss: 0.694559, acc.: 50.78%] [G loss: 0.714204]\n",
      "epoch:6 step:6308 [D loss: 0.687943, acc.: 53.91%] [G loss: 0.714982]\n",
      "epoch:6 step:6309 [D loss: 0.680896, acc.: 57.81%] [G loss: 0.713412]\n",
      "epoch:6 step:6310 [D loss: 0.675243, acc.: 64.84%] [G loss: 0.708612]\n",
      "epoch:6 step:6311 [D loss: 0.705247, acc.: 47.66%] [G loss: 0.703049]\n",
      "epoch:6 step:6312 [D loss: 0.681176, acc.: 53.91%] [G loss: 0.692378]\n",
      "epoch:6 step:6313 [D loss: 0.703174, acc.: 46.09%] [G loss: 0.730595]\n",
      "epoch:6 step:6314 [D loss: 0.677505, acc.: 53.91%] [G loss: 0.702969]\n",
      "epoch:6 step:6315 [D loss: 0.705888, acc.: 43.75%] [G loss: 0.690704]\n",
      "epoch:6 step:6316 [D loss: 0.673561, acc.: 53.12%] [G loss: 0.707932]\n",
      "epoch:6 step:6317 [D loss: 0.709786, acc.: 43.75%] [G loss: 0.701077]\n",
      "epoch:6 step:6318 [D loss: 0.705983, acc.: 44.53%] [G loss: 0.719041]\n",
      "epoch:6 step:6319 [D loss: 0.707949, acc.: 39.84%] [G loss: 0.757383]\n",
      "epoch:6 step:6320 [D loss: 0.691103, acc.: 47.66%] [G loss: 0.728323]\n",
      "epoch:6 step:6321 [D loss: 0.705448, acc.: 49.22%] [G loss: 0.740308]\n",
      "epoch:6 step:6322 [D loss: 0.683940, acc.: 52.34%] [G loss: 0.742974]\n",
      "epoch:6 step:6323 [D loss: 0.688443, acc.: 56.25%] [G loss: 0.761036]\n",
      "epoch:6 step:6324 [D loss: 0.685942, acc.: 53.12%] [G loss: 0.761587]\n",
      "epoch:6 step:6325 [D loss: 0.679389, acc.: 60.16%] [G loss: 0.753409]\n",
      "epoch:6 step:6326 [D loss: 0.697619, acc.: 56.25%] [G loss: 0.754658]\n",
      "epoch:6 step:6327 [D loss: 0.686572, acc.: 55.47%] [G loss: 0.775677]\n",
      "epoch:6 step:6328 [D loss: 0.688970, acc.: 52.34%] [G loss: 0.761221]\n",
      "epoch:6 step:6329 [D loss: 0.664616, acc.: 69.53%] [G loss: 0.760366]\n",
      "epoch:6 step:6330 [D loss: 0.675715, acc.: 63.28%] [G loss: 0.753903]\n",
      "epoch:6 step:6331 [D loss: 0.673994, acc.: 63.28%] [G loss: 0.733565]\n",
      "epoch:6 step:6332 [D loss: 0.723485, acc.: 46.88%] [G loss: 0.743449]\n",
      "epoch:6 step:6333 [D loss: 0.752619, acc.: 38.28%] [G loss: 0.769130]\n",
      "epoch:6 step:6334 [D loss: 0.688143, acc.: 54.69%] [G loss: 0.736412]\n",
      "epoch:6 step:6335 [D loss: 0.664404, acc.: 65.62%] [G loss: 0.752143]\n",
      "epoch:6 step:6336 [D loss: 0.659197, acc.: 66.41%] [G loss: 0.764282]\n",
      "epoch:6 step:6337 [D loss: 0.697298, acc.: 50.78%] [G loss: 0.804393]\n",
      "epoch:6 step:6338 [D loss: 0.711793, acc.: 48.44%] [G loss: 0.765241]\n",
      "epoch:6 step:6339 [D loss: 0.686265, acc.: 57.81%] [G loss: 0.780785]\n",
      "epoch:6 step:6340 [D loss: 0.712259, acc.: 41.41%] [G loss: 0.749073]\n",
      "epoch:6 step:6341 [D loss: 0.684056, acc.: 58.59%] [G loss: 0.743771]\n",
      "epoch:6 step:6342 [D loss: 0.703158, acc.: 47.66%] [G loss: 0.744652]\n",
      "epoch:6 step:6343 [D loss: 0.670111, acc.: 60.16%] [G loss: 0.725465]\n",
      "epoch:6 step:6344 [D loss: 0.697896, acc.: 48.44%] [G loss: 0.736703]\n",
      "epoch:6 step:6345 [D loss: 0.667578, acc.: 56.25%] [G loss: 0.749501]\n",
      "epoch:6 step:6346 [D loss: 0.673387, acc.: 54.69%] [G loss: 0.783071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6347 [D loss: 0.689838, acc.: 53.12%] [G loss: 0.776616]\n",
      "epoch:6 step:6348 [D loss: 0.695553, acc.: 53.91%] [G loss: 0.735466]\n",
      "epoch:6 step:6349 [D loss: 0.701741, acc.: 42.97%] [G loss: 0.736781]\n",
      "epoch:6 step:6350 [D loss: 0.684037, acc.: 50.00%] [G loss: 0.747992]\n",
      "epoch:6 step:6351 [D loss: 0.682201, acc.: 53.12%] [G loss: 0.716817]\n",
      "epoch:6 step:6352 [D loss: 0.684622, acc.: 59.38%] [G loss: 0.763136]\n",
      "epoch:6 step:6353 [D loss: 0.690735, acc.: 55.47%] [G loss: 0.733970]\n",
      "epoch:6 step:6354 [D loss: 0.670607, acc.: 59.38%] [G loss: 0.739962]\n",
      "epoch:6 step:6355 [D loss: 0.665819, acc.: 64.84%] [G loss: 0.802498]\n",
      "epoch:6 step:6356 [D loss: 0.699014, acc.: 51.56%] [G loss: 0.769515]\n",
      "epoch:6 step:6357 [D loss: 0.676280, acc.: 59.38%] [G loss: 0.825558]\n",
      "epoch:6 step:6358 [D loss: 0.683118, acc.: 54.69%] [G loss: 0.747397]\n",
      "epoch:6 step:6359 [D loss: 0.673696, acc.: 57.81%] [G loss: 0.739439]\n",
      "epoch:6 step:6360 [D loss: 0.693662, acc.: 54.69%] [G loss: 0.753419]\n",
      "epoch:6 step:6361 [D loss: 0.707094, acc.: 48.44%] [G loss: 0.727507]\n",
      "epoch:6 step:6362 [D loss: 0.709991, acc.: 47.66%] [G loss: 0.746428]\n",
      "epoch:6 step:6363 [D loss: 0.696755, acc.: 52.34%] [G loss: 0.743541]\n",
      "epoch:6 step:6364 [D loss: 0.709748, acc.: 47.66%] [G loss: 0.734959]\n",
      "epoch:6 step:6365 [D loss: 0.685338, acc.: 52.34%] [G loss: 0.728811]\n",
      "epoch:6 step:6366 [D loss: 0.687132, acc.: 55.47%] [G loss: 0.764660]\n",
      "epoch:6 step:6367 [D loss: 0.693932, acc.: 50.78%] [G loss: 0.773420]\n",
      "epoch:6 step:6368 [D loss: 0.685694, acc.: 46.88%] [G loss: 0.741653]\n",
      "epoch:6 step:6369 [D loss: 0.674052, acc.: 57.03%] [G loss: 0.772393]\n",
      "epoch:6 step:6370 [D loss: 0.708201, acc.: 48.44%] [G loss: 0.760746]\n",
      "epoch:6 step:6371 [D loss: 0.690246, acc.: 44.53%] [G loss: 0.758366]\n",
      "epoch:6 step:6372 [D loss: 0.681505, acc.: 57.03%] [G loss: 0.742405]\n",
      "epoch:6 step:6373 [D loss: 0.706208, acc.: 46.88%] [G loss: 0.752748]\n",
      "epoch:6 step:6374 [D loss: 0.708647, acc.: 53.12%] [G loss: 0.731268]\n",
      "epoch:6 step:6375 [D loss: 0.706107, acc.: 45.31%] [G loss: 0.734666]\n",
      "epoch:6 step:6376 [D loss: 0.703458, acc.: 44.53%] [G loss: 0.725592]\n",
      "epoch:6 step:6377 [D loss: 0.698630, acc.: 48.44%] [G loss: 0.710815]\n",
      "epoch:6 step:6378 [D loss: 0.686022, acc.: 58.59%] [G loss: 0.704664]\n",
      "epoch:6 step:6379 [D loss: 0.703793, acc.: 41.41%] [G loss: 0.716112]\n",
      "epoch:6 step:6380 [D loss: 0.684622, acc.: 50.78%] [G loss: 0.717709]\n",
      "epoch:6 step:6381 [D loss: 0.703413, acc.: 53.12%] [G loss: 0.720292]\n",
      "epoch:6 step:6382 [D loss: 0.691749, acc.: 51.56%] [G loss: 0.725014]\n",
      "epoch:6 step:6383 [D loss: 0.696608, acc.: 54.69%] [G loss: 0.710016]\n",
      "epoch:6 step:6384 [D loss: 0.696517, acc.: 52.34%] [G loss: 0.730815]\n",
      "epoch:6 step:6385 [D loss: 0.687151, acc.: 52.34%] [G loss: 0.714300]\n",
      "epoch:6 step:6386 [D loss: 0.674823, acc.: 60.94%] [G loss: 0.720057]\n",
      "epoch:6 step:6387 [D loss: 0.720734, acc.: 46.09%] [G loss: 0.735828]\n",
      "epoch:6 step:6388 [D loss: 0.706599, acc.: 39.84%] [G loss: 0.744134]\n",
      "epoch:6 step:6389 [D loss: 0.701325, acc.: 52.34%] [G loss: 0.735803]\n",
      "epoch:6 step:6390 [D loss: 0.694607, acc.: 53.12%] [G loss: 0.740300]\n",
      "epoch:6 step:6391 [D loss: 0.682316, acc.: 55.47%] [G loss: 0.722308]\n",
      "epoch:6 step:6392 [D loss: 0.681224, acc.: 60.16%] [G loss: 0.729305]\n",
      "epoch:6 step:6393 [D loss: 0.676467, acc.: 60.16%] [G loss: 0.748261]\n",
      "epoch:6 step:6394 [D loss: 0.677222, acc.: 53.91%] [G loss: 0.723585]\n",
      "epoch:6 step:6395 [D loss: 0.684463, acc.: 54.69%] [G loss: 0.739981]\n",
      "epoch:6 step:6396 [D loss: 0.680100, acc.: 57.03%] [G loss: 0.746316]\n",
      "epoch:6 step:6397 [D loss: 0.672029, acc.: 59.38%] [G loss: 0.757527]\n",
      "epoch:6 step:6398 [D loss: 0.721538, acc.: 44.53%] [G loss: 0.744680]\n",
      "epoch:6 step:6399 [D loss: 0.699860, acc.: 56.25%] [G loss: 0.726499]\n",
      "epoch:6 step:6400 [D loss: 0.700013, acc.: 46.09%] [G loss: 0.725468]\n",
      "epoch:6 step:6401 [D loss: 0.711493, acc.: 42.97%] [G loss: 0.715797]\n",
      "epoch:6 step:6402 [D loss: 0.706762, acc.: 41.41%] [G loss: 0.732439]\n",
      "epoch:6 step:6403 [D loss: 0.694096, acc.: 51.56%] [G loss: 0.725450]\n",
      "epoch:6 step:6404 [D loss: 0.681959, acc.: 56.25%] [G loss: 0.736204]\n",
      "epoch:6 step:6405 [D loss: 0.700153, acc.: 51.56%] [G loss: 0.748769]\n",
      "epoch:6 step:6406 [D loss: 0.701320, acc.: 48.44%] [G loss: 0.749288]\n",
      "epoch:6 step:6407 [D loss: 0.683150, acc.: 56.25%] [G loss: 0.792110]\n",
      "epoch:6 step:6408 [D loss: 0.675842, acc.: 59.38%] [G loss: 0.739836]\n",
      "epoch:6 step:6409 [D loss: 0.690759, acc.: 53.12%] [G loss: 0.737614]\n",
      "epoch:6 step:6410 [D loss: 0.685838, acc.: 52.34%] [G loss: 0.792393]\n",
      "epoch:6 step:6411 [D loss: 0.680095, acc.: 54.69%] [G loss: 0.761260]\n",
      "epoch:6 step:6412 [D loss: 0.677250, acc.: 63.28%] [G loss: 0.762032]\n",
      "epoch:6 step:6413 [D loss: 0.675197, acc.: 57.81%] [G loss: 0.749036]\n",
      "epoch:6 step:6414 [D loss: 0.699717, acc.: 49.22%] [G loss: 0.743869]\n",
      "epoch:6 step:6415 [D loss: 0.669345, acc.: 60.94%] [G loss: 0.712906]\n",
      "epoch:6 step:6416 [D loss: 0.694132, acc.: 50.78%] [G loss: 0.716016]\n",
      "epoch:6 step:6417 [D loss: 0.677749, acc.: 55.47%] [G loss: 0.727255]\n",
      "epoch:6 step:6418 [D loss: 0.698563, acc.: 48.44%] [G loss: 0.711765]\n",
      "epoch:6 step:6419 [D loss: 0.717102, acc.: 46.88%] [G loss: 0.729339]\n",
      "epoch:6 step:6420 [D loss: 0.712898, acc.: 43.75%] [G loss: 0.708284]\n",
      "epoch:6 step:6421 [D loss: 0.700435, acc.: 51.56%] [G loss: 0.711220]\n",
      "epoch:6 step:6422 [D loss: 0.707719, acc.: 45.31%] [G loss: 0.714679]\n",
      "epoch:6 step:6423 [D loss: 0.694394, acc.: 50.78%] [G loss: 0.707227]\n",
      "epoch:6 step:6424 [D loss: 0.517411, acc.: 63.28%] [G loss: 0.699178]\n",
      "epoch:6 step:6425 [D loss: 0.698557, acc.: 57.03%] [G loss: 0.758990]\n",
      "epoch:6 step:6426 [D loss: 0.693452, acc.: 55.47%] [G loss: 0.771337]\n",
      "epoch:6 step:6427 [D loss: 0.676304, acc.: 61.72%] [G loss: 0.806410]\n",
      "epoch:6 step:6428 [D loss: 0.653108, acc.: 68.75%] [G loss: 0.821543]\n",
      "epoch:6 step:6429 [D loss: 0.663788, acc.: 59.38%] [G loss: 0.803488]\n",
      "epoch:6 step:6430 [D loss: 0.684592, acc.: 54.69%] [G loss: 0.759986]\n",
      "epoch:6 step:6431 [D loss: 0.671439, acc.: 60.94%] [G loss: 0.747373]\n",
      "epoch:6 step:6432 [D loss: 0.680432, acc.: 60.16%] [G loss: 0.744269]\n",
      "epoch:6 step:6433 [D loss: 0.762154, acc.: 34.38%] [G loss: 0.706138]\n",
      "epoch:6 step:6434 [D loss: 0.729543, acc.: 38.28%] [G loss: 0.720223]\n",
      "epoch:6 step:6435 [D loss: 0.681558, acc.: 51.56%] [G loss: 0.713494]\n",
      "epoch:6 step:6436 [D loss: 0.716660, acc.: 45.31%] [G loss: 0.676174]\n",
      "epoch:6 step:6437 [D loss: 0.680386, acc.: 54.69%] [G loss: 0.718768]\n",
      "epoch:6 step:6438 [D loss: 0.680883, acc.: 55.47%] [G loss: 0.728678]\n",
      "epoch:6 step:6439 [D loss: 0.717904, acc.: 41.41%] [G loss: 0.693624]\n",
      "epoch:6 step:6440 [D loss: 0.674711, acc.: 58.59%] [G loss: 0.720258]\n",
      "epoch:6 step:6441 [D loss: 0.708384, acc.: 44.53%] [G loss: 0.712251]\n",
      "epoch:6 step:6442 [D loss: 0.720766, acc.: 42.19%] [G loss: 0.669619]\n",
      "epoch:6 step:6443 [D loss: 0.689103, acc.: 57.03%] [G loss: 0.731112]\n",
      "epoch:6 step:6444 [D loss: 0.728793, acc.: 37.50%] [G loss: 0.754217]\n",
      "epoch:6 step:6445 [D loss: 0.684880, acc.: 57.03%] [G loss: 0.706886]\n",
      "epoch:6 step:6446 [D loss: 0.690885, acc.: 50.00%] [G loss: 0.742025]\n",
      "epoch:6 step:6447 [D loss: 0.678862, acc.: 64.06%] [G loss: 0.733533]\n",
      "epoch:6 step:6448 [D loss: 0.647285, acc.: 69.53%] [G loss: 0.709710]\n",
      "epoch:6 step:6449 [D loss: 0.699013, acc.: 53.91%] [G loss: 0.634881]\n",
      "epoch:6 step:6450 [D loss: 0.734285, acc.: 42.19%] [G loss: 0.683241]\n",
      "epoch:6 step:6451 [D loss: 0.702965, acc.: 46.88%] [G loss: 0.721483]\n",
      "epoch:6 step:6452 [D loss: 1.139109, acc.: 37.50%] [G loss: 0.827915]\n",
      "epoch:6 step:6453 [D loss: 0.736725, acc.: 53.12%] [G loss: 0.829715]\n",
      "epoch:6 step:6454 [D loss: 0.701132, acc.: 51.56%] [G loss: 0.983525]\n",
      "epoch:6 step:6455 [D loss: 0.732065, acc.: 53.12%] [G loss: 0.779420]\n",
      "epoch:6 step:6456 [D loss: 0.698353, acc.: 54.69%] [G loss: 0.776497]\n",
      "epoch:6 step:6457 [D loss: 0.682971, acc.: 51.56%] [G loss: 0.789808]\n",
      "epoch:6 step:6458 [D loss: 0.730880, acc.: 37.50%] [G loss: 0.743527]\n",
      "epoch:6 step:6459 [D loss: 0.695442, acc.: 56.25%] [G loss: 0.736639]\n",
      "epoch:6 step:6460 [D loss: 0.693787, acc.: 52.34%] [G loss: 0.729637]\n",
      "epoch:6 step:6461 [D loss: 0.718034, acc.: 39.84%] [G loss: 0.707726]\n",
      "epoch:6 step:6462 [D loss: 0.697400, acc.: 50.78%] [G loss: 0.695382]\n",
      "epoch:6 step:6463 [D loss: 0.703514, acc.: 48.44%] [G loss: 0.704443]\n",
      "epoch:6 step:6464 [D loss: 0.684626, acc.: 56.25%] [G loss: 0.704289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6465 [D loss: 0.707105, acc.: 43.75%] [G loss: 0.729038]\n",
      "epoch:6 step:6466 [D loss: 0.714071, acc.: 46.09%] [G loss: 0.710111]\n",
      "epoch:6 step:6467 [D loss: 0.679214, acc.: 55.47%] [G loss: 0.728686]\n",
      "epoch:6 step:6468 [D loss: 0.710305, acc.: 43.75%] [G loss: 0.681517]\n",
      "epoch:6 step:6469 [D loss: 0.706786, acc.: 43.75%] [G loss: 0.709584]\n",
      "epoch:6 step:6470 [D loss: 0.716606, acc.: 41.41%] [G loss: 0.699489]\n",
      "epoch:6 step:6471 [D loss: 0.694811, acc.: 46.09%] [G loss: 0.689797]\n",
      "epoch:6 step:6472 [D loss: 0.712074, acc.: 35.16%] [G loss: 0.691004]\n",
      "epoch:6 step:6473 [D loss: 0.712115, acc.: 41.41%] [G loss: 0.684686]\n",
      "epoch:6 step:6474 [D loss: 0.695516, acc.: 43.75%] [G loss: 0.695147]\n",
      "epoch:6 step:6475 [D loss: 0.694186, acc.: 50.78%] [G loss: 0.704575]\n",
      "epoch:6 step:6476 [D loss: 0.689251, acc.: 52.34%] [G loss: 0.696406]\n",
      "epoch:6 step:6477 [D loss: 0.690657, acc.: 51.56%] [G loss: 0.705359]\n",
      "epoch:6 step:6478 [D loss: 0.687144, acc.: 53.91%] [G loss: 0.736821]\n",
      "epoch:6 step:6479 [D loss: 0.679795, acc.: 57.03%] [G loss: 0.713569]\n",
      "epoch:6 step:6480 [D loss: 0.689433, acc.: 54.69%] [G loss: 0.723662]\n",
      "epoch:6 step:6481 [D loss: 0.679062, acc.: 57.03%] [G loss: 0.756065]\n",
      "epoch:6 step:6482 [D loss: 0.690507, acc.: 53.12%] [G loss: 0.747678]\n",
      "epoch:6 step:6483 [D loss: 0.694819, acc.: 53.12%] [G loss: 0.725070]\n",
      "epoch:6 step:6484 [D loss: 0.696900, acc.: 53.12%] [G loss: 0.730131]\n",
      "epoch:6 step:6485 [D loss: 0.689592, acc.: 52.34%] [G loss: 0.715669]\n",
      "epoch:6 step:6486 [D loss: 0.686572, acc.: 48.44%] [G loss: 0.728271]\n",
      "epoch:6 step:6487 [D loss: 0.703898, acc.: 49.22%] [G loss: 0.721747]\n",
      "epoch:6 step:6488 [D loss: 0.695145, acc.: 50.78%] [G loss: 0.706434]\n",
      "epoch:6 step:6489 [D loss: 0.700359, acc.: 46.88%] [G loss: 0.735739]\n",
      "epoch:6 step:6490 [D loss: 0.684935, acc.: 51.56%] [G loss: 0.709506]\n",
      "epoch:6 step:6491 [D loss: 0.712795, acc.: 45.31%] [G loss: 0.716387]\n",
      "epoch:6 step:6492 [D loss: 0.677313, acc.: 56.25%] [G loss: 0.715174]\n",
      "epoch:6 step:6493 [D loss: 0.686476, acc.: 57.03%] [G loss: 0.698203]\n",
      "epoch:6 step:6494 [D loss: 0.702233, acc.: 42.97%] [G loss: 0.686526]\n",
      "epoch:6 step:6495 [D loss: 0.699727, acc.: 46.09%] [G loss: 0.704521]\n",
      "epoch:6 step:6496 [D loss: 0.703738, acc.: 42.19%] [G loss: 0.714312]\n",
      "epoch:6 step:6497 [D loss: 0.679036, acc.: 56.25%] [G loss: 0.731775]\n",
      "epoch:6 step:6498 [D loss: 0.689309, acc.: 52.34%] [G loss: 0.716099]\n",
      "epoch:6 step:6499 [D loss: 0.705034, acc.: 42.97%] [G loss: 0.717645]\n",
      "epoch:6 step:6500 [D loss: 0.695548, acc.: 51.56%] [G loss: 0.733335]\n",
      "epoch:6 step:6501 [D loss: 0.690392, acc.: 47.66%] [G loss: 0.721446]\n",
      "epoch:6 step:6502 [D loss: 0.698097, acc.: 50.00%] [G loss: 0.710081]\n",
      "epoch:6 step:6503 [D loss: 0.688691, acc.: 53.12%] [G loss: 0.733895]\n",
      "epoch:6 step:6504 [D loss: 0.689471, acc.: 52.34%] [G loss: 0.736014]\n",
      "epoch:6 step:6505 [D loss: 0.689374, acc.: 50.78%] [G loss: 0.735060]\n",
      "epoch:6 step:6506 [D loss: 0.694594, acc.: 50.00%] [G loss: 0.713131]\n",
      "epoch:6 step:6507 [D loss: 0.689675, acc.: 51.56%] [G loss: 0.723451]\n",
      "epoch:6 step:6508 [D loss: 0.691049, acc.: 53.12%] [G loss: 0.707965]\n",
      "epoch:6 step:6509 [D loss: 0.683312, acc.: 56.25%] [G loss: 0.717874]\n",
      "epoch:6 step:6510 [D loss: 0.693843, acc.: 55.47%] [G loss: 0.733800]\n",
      "epoch:6 step:6511 [D loss: 0.700552, acc.: 50.00%] [G loss: 0.715919]\n",
      "epoch:6 step:6512 [D loss: 0.688748, acc.: 54.69%] [G loss: 0.748292]\n",
      "epoch:6 step:6513 [D loss: 0.711605, acc.: 40.62%] [G loss: 0.711498]\n",
      "epoch:6 step:6514 [D loss: 0.712048, acc.: 51.56%] [G loss: 0.717784]\n",
      "epoch:6 step:6515 [D loss: 0.696174, acc.: 42.97%] [G loss: 0.709956]\n",
      "epoch:6 step:6516 [D loss: 0.710461, acc.: 48.44%] [G loss: 0.710130]\n",
      "epoch:6 step:6517 [D loss: 0.700360, acc.: 48.44%] [G loss: 0.723988]\n",
      "epoch:6 step:6518 [D loss: 0.684821, acc.: 58.59%] [G loss: 0.704512]\n",
      "epoch:6 step:6519 [D loss: 0.691103, acc.: 50.78%] [G loss: 0.721806]\n",
      "epoch:6 step:6520 [D loss: 0.695637, acc.: 53.91%] [G loss: 0.729693]\n",
      "epoch:6 step:6521 [D loss: 0.663605, acc.: 75.78%] [G loss: 0.735724]\n",
      "epoch:6 step:6522 [D loss: 0.664049, acc.: 68.75%] [G loss: 0.737840]\n",
      "epoch:6 step:6523 [D loss: 0.675688, acc.: 64.84%] [G loss: 0.734015]\n",
      "epoch:6 step:6524 [D loss: 0.696383, acc.: 47.66%] [G loss: 0.750321]\n",
      "epoch:6 step:6525 [D loss: 0.677676, acc.: 59.38%] [G loss: 0.751222]\n",
      "epoch:6 step:6526 [D loss: 0.720762, acc.: 32.81%] [G loss: 0.731413]\n",
      "epoch:6 step:6527 [D loss: 0.732522, acc.: 38.28%] [G loss: 0.753446]\n",
      "epoch:6 step:6528 [D loss: 0.697511, acc.: 50.00%] [G loss: 0.758339]\n",
      "epoch:6 step:6529 [D loss: 0.685972, acc.: 49.22%] [G loss: 0.743277]\n",
      "epoch:6 step:6530 [D loss: 0.682220, acc.: 50.78%] [G loss: 0.754764]\n",
      "epoch:6 step:6531 [D loss: 0.687726, acc.: 50.00%] [G loss: 0.727257]\n",
      "epoch:6 step:6532 [D loss: 0.692632, acc.: 57.03%] [G loss: 0.743192]\n",
      "epoch:6 step:6533 [D loss: 0.688231, acc.: 56.25%] [G loss: 0.719611]\n",
      "epoch:6 step:6534 [D loss: 0.538291, acc.: 72.66%] [G loss: 0.737751]\n",
      "epoch:6 step:6535 [D loss: 0.702614, acc.: 53.91%] [G loss: 0.757469]\n",
      "epoch:6 step:6536 [D loss: 0.703957, acc.: 57.03%] [G loss: 0.676935]\n",
      "epoch:6 step:6537 [D loss: 0.705278, acc.: 49.22%] [G loss: 0.722575]\n",
      "epoch:6 step:6538 [D loss: 0.723540, acc.: 42.19%] [G loss: 0.697706]\n",
      "epoch:6 step:6539 [D loss: 0.714757, acc.: 46.88%] [G loss: 0.714425]\n",
      "epoch:6 step:6540 [D loss: 0.684647, acc.: 50.78%] [G loss: 0.709084]\n",
      "epoch:6 step:6541 [D loss: 0.689167, acc.: 60.16%] [G loss: 0.727724]\n",
      "epoch:6 step:6542 [D loss: 0.930533, acc.: 30.47%] [G loss: 0.748738]\n",
      "epoch:6 step:6543 [D loss: 0.685276, acc.: 53.91%] [G loss: 0.773080]\n",
      "epoch:6 step:6544 [D loss: 0.651159, acc.: 64.06%] [G loss: 0.815680]\n",
      "epoch:6 step:6545 [D loss: 0.684665, acc.: 57.81%] [G loss: 0.771935]\n",
      "epoch:6 step:6546 [D loss: 0.719419, acc.: 52.34%] [G loss: 0.739308]\n",
      "epoch:6 step:6547 [D loss: 0.683623, acc.: 57.81%] [G loss: 0.763585]\n",
      "epoch:6 step:6548 [D loss: 0.670892, acc.: 63.28%] [G loss: 0.749822]\n",
      "epoch:6 step:6549 [D loss: 0.688339, acc.: 50.00%] [G loss: 0.794283]\n",
      "epoch:6 step:6550 [D loss: 0.722025, acc.: 47.66%] [G loss: 0.726811]\n",
      "epoch:6 step:6551 [D loss: 0.706716, acc.: 50.78%] [G loss: 0.720751]\n",
      "epoch:6 step:6552 [D loss: 0.683849, acc.: 61.72%] [G loss: 0.722626]\n",
      "epoch:6 step:6553 [D loss: 0.702373, acc.: 49.22%] [G loss: 0.720526]\n",
      "epoch:6 step:6554 [D loss: 0.705705, acc.: 48.44%] [G loss: 0.719879]\n",
      "epoch:6 step:6555 [D loss: 0.679493, acc.: 57.03%] [G loss: 0.698959]\n",
      "epoch:6 step:6556 [D loss: 0.676052, acc.: 60.94%] [G loss: 0.724432]\n",
      "epoch:6 step:6557 [D loss: 0.690379, acc.: 54.69%] [G loss: 0.598348]\n",
      "epoch:6 step:6558 [D loss: 0.607030, acc.: 66.41%] [G loss: 0.718116]\n",
      "epoch:6 step:6559 [D loss: 0.634853, acc.: 59.38%] [G loss: 0.723383]\n",
      "epoch:7 step:6560 [D loss: 0.747504, acc.: 45.31%] [G loss: 0.714716]\n",
      "epoch:7 step:6561 [D loss: 0.733302, acc.: 36.72%] [G loss: 0.708026]\n",
      "epoch:7 step:6562 [D loss: 0.710021, acc.: 43.75%] [G loss: 0.712259]\n",
      "epoch:7 step:6563 [D loss: 0.694327, acc.: 50.00%] [G loss: 0.787517]\n",
      "epoch:7 step:6564 [D loss: 0.665828, acc.: 52.34%] [G loss: 0.813456]\n",
      "epoch:7 step:6565 [D loss: 0.677936, acc.: 57.81%] [G loss: 0.786353]\n",
      "epoch:7 step:6566 [D loss: 0.681421, acc.: 56.25%] [G loss: 0.772059]\n",
      "epoch:7 step:6567 [D loss: 0.671943, acc.: 56.25%] [G loss: 0.776360]\n",
      "epoch:7 step:6568 [D loss: 0.699617, acc.: 46.88%] [G loss: 0.738521]\n",
      "epoch:7 step:6569 [D loss: 0.690411, acc.: 53.12%] [G loss: 0.753032]\n",
      "epoch:7 step:6570 [D loss: 0.716165, acc.: 49.22%] [G loss: 0.725194]\n",
      "epoch:7 step:6571 [D loss: 0.714049, acc.: 45.31%] [G loss: 0.729552]\n",
      "epoch:7 step:6572 [D loss: 0.718132, acc.: 42.19%] [G loss: 0.731889]\n",
      "epoch:7 step:6573 [D loss: 0.701339, acc.: 46.09%] [G loss: 0.720472]\n",
      "epoch:7 step:6574 [D loss: 0.694313, acc.: 62.50%] [G loss: 0.764221]\n",
      "epoch:7 step:6575 [D loss: 0.668536, acc.: 66.41%] [G loss: 0.791831]\n",
      "epoch:7 step:6576 [D loss: 0.688220, acc.: 53.91%] [G loss: 0.841188]\n",
      "epoch:7 step:6577 [D loss: 0.683075, acc.: 52.34%] [G loss: 0.838607]\n",
      "epoch:7 step:6578 [D loss: 0.681125, acc.: 51.56%] [G loss: 0.803437]\n",
      "epoch:7 step:6579 [D loss: 0.676465, acc.: 56.25%] [G loss: 0.839051]\n",
      "epoch:7 step:6580 [D loss: 0.662041, acc.: 56.25%] [G loss: 0.857133]\n",
      "epoch:7 step:6581 [D loss: 0.672061, acc.: 56.25%] [G loss: 0.838139]\n",
      "epoch:7 step:6582 [D loss: 0.657425, acc.: 63.28%] [G loss: 0.844145]\n",
      "epoch:7 step:6583 [D loss: 0.719287, acc.: 50.00%] [G loss: 0.788846]\n",
      "epoch:7 step:6584 [D loss: 0.664403, acc.: 62.50%] [G loss: 0.803871]\n",
      "epoch:7 step:6585 [D loss: 0.730225, acc.: 50.00%] [G loss: 0.777108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6586 [D loss: 0.748092, acc.: 36.72%] [G loss: 0.706530]\n",
      "epoch:7 step:6587 [D loss: 0.728296, acc.: 41.41%] [G loss: 0.717548]\n",
      "epoch:7 step:6588 [D loss: 0.682652, acc.: 56.25%] [G loss: 0.766264]\n",
      "epoch:7 step:6589 [D loss: 0.697061, acc.: 48.44%] [G loss: 0.708652]\n",
      "epoch:7 step:6590 [D loss: 0.702487, acc.: 49.22%] [G loss: 0.699206]\n",
      "epoch:7 step:6591 [D loss: 0.691897, acc.: 53.12%] [G loss: 0.716261]\n",
      "epoch:7 step:6592 [D loss: 0.698154, acc.: 52.34%] [G loss: 0.725824]\n",
      "epoch:7 step:6593 [D loss: 0.691628, acc.: 53.12%] [G loss: 0.710206]\n",
      "epoch:7 step:6594 [D loss: 0.668798, acc.: 62.50%] [G loss: 0.705463]\n",
      "epoch:7 step:6595 [D loss: 0.682743, acc.: 52.34%] [G loss: 0.719460]\n",
      "epoch:7 step:6596 [D loss: 0.667162, acc.: 57.03%] [G loss: 1.046969]\n",
      "epoch:7 step:6597 [D loss: 0.739708, acc.: 34.38%] [G loss: 0.710200]\n",
      "epoch:7 step:6598 [D loss: 0.705269, acc.: 42.19%] [G loss: 0.733805]\n",
      "epoch:7 step:6599 [D loss: 0.696572, acc.: 46.88%] [G loss: 0.715772]\n",
      "epoch:7 step:6600 [D loss: 0.698053, acc.: 42.19%] [G loss: 0.716466]\n",
      "epoch:7 step:6601 [D loss: 0.690301, acc.: 46.09%] [G loss: 0.701721]\n",
      "epoch:7 step:6602 [D loss: 0.680762, acc.: 60.94%] [G loss: 0.687148]\n",
      "epoch:7 step:6603 [D loss: 0.702335, acc.: 46.09%] [G loss: 0.718440]\n",
      "epoch:7 step:6604 [D loss: 0.717342, acc.: 39.84%] [G loss: 0.691528]\n",
      "epoch:7 step:6605 [D loss: 0.700329, acc.: 45.31%] [G loss: 0.693738]\n",
      "epoch:7 step:6606 [D loss: 0.691745, acc.: 52.34%] [G loss: 0.709295]\n",
      "epoch:7 step:6607 [D loss: 0.675146, acc.: 59.38%] [G loss: 0.727647]\n",
      "epoch:7 step:6608 [D loss: 0.699669, acc.: 44.53%] [G loss: 0.706751]\n",
      "epoch:7 step:6609 [D loss: 0.679253, acc.: 57.81%] [G loss: 0.705763]\n",
      "epoch:7 step:6610 [D loss: 0.692899, acc.: 53.91%] [G loss: 0.715418]\n",
      "epoch:7 step:6611 [D loss: 0.687168, acc.: 52.34%] [G loss: 0.714267]\n",
      "epoch:7 step:6612 [D loss: 0.690344, acc.: 53.91%] [G loss: 0.727263]\n",
      "epoch:7 step:6613 [D loss: 0.717925, acc.: 39.84%] [G loss: 0.717989]\n",
      "epoch:7 step:6614 [D loss: 0.686497, acc.: 55.47%] [G loss: 0.728933]\n",
      "epoch:7 step:6615 [D loss: 0.694877, acc.: 47.66%] [G loss: 0.752712]\n",
      "epoch:7 step:6616 [D loss: 0.691101, acc.: 50.00%] [G loss: 0.728985]\n",
      "epoch:7 step:6617 [D loss: 0.701149, acc.: 50.00%] [G loss: 0.744212]\n",
      "epoch:7 step:6618 [D loss: 0.694431, acc.: 49.22%] [G loss: 0.759137]\n",
      "epoch:7 step:6619 [D loss: 0.685467, acc.: 53.91%] [G loss: 0.732638]\n",
      "epoch:7 step:6620 [D loss: 0.688439, acc.: 53.12%] [G loss: 0.707882]\n",
      "epoch:7 step:6621 [D loss: 0.678520, acc.: 60.94%] [G loss: 0.726950]\n",
      "epoch:7 step:6622 [D loss: 0.686473, acc.: 57.03%] [G loss: 0.846938]\n",
      "epoch:7 step:6623 [D loss: 0.693246, acc.: 53.91%] [G loss: 0.740200]\n",
      "epoch:7 step:6624 [D loss: 0.695196, acc.: 48.44%] [G loss: 0.730094]\n",
      "epoch:7 step:6625 [D loss: 0.683105, acc.: 55.47%] [G loss: 0.720682]\n",
      "epoch:7 step:6626 [D loss: 0.690077, acc.: 50.78%] [G loss: 0.729757]\n",
      "epoch:7 step:6627 [D loss: 0.702953, acc.: 50.00%] [G loss: 0.706107]\n",
      "epoch:7 step:6628 [D loss: 0.692378, acc.: 51.56%] [G loss: 0.700519]\n",
      "epoch:7 step:6629 [D loss: 0.691219, acc.: 50.78%] [G loss: 0.710696]\n",
      "epoch:7 step:6630 [D loss: 0.702366, acc.: 47.66%] [G loss: 0.719602]\n",
      "epoch:7 step:6631 [D loss: 0.694897, acc.: 50.78%] [G loss: 0.714086]\n",
      "epoch:7 step:6632 [D loss: 0.701090, acc.: 39.06%] [G loss: 0.701185]\n",
      "epoch:7 step:6633 [D loss: 0.689095, acc.: 50.00%] [G loss: 0.715678]\n",
      "epoch:7 step:6634 [D loss: 0.712528, acc.: 36.72%] [G loss: 0.708415]\n",
      "epoch:7 step:6635 [D loss: 0.688315, acc.: 54.69%] [G loss: 0.704415]\n",
      "epoch:7 step:6636 [D loss: 0.693544, acc.: 51.56%] [G loss: 0.720141]\n",
      "epoch:7 step:6637 [D loss: 0.698655, acc.: 46.09%] [G loss: 0.738265]\n",
      "epoch:7 step:6638 [D loss: 0.680979, acc.: 60.16%] [G loss: 0.718892]\n",
      "epoch:7 step:6639 [D loss: 0.692412, acc.: 46.09%] [G loss: 0.718614]\n",
      "epoch:7 step:6640 [D loss: 0.698465, acc.: 44.53%] [G loss: 0.727393]\n",
      "epoch:7 step:6641 [D loss: 0.689301, acc.: 49.22%] [G loss: 0.732200]\n",
      "epoch:7 step:6642 [D loss: 0.685587, acc.: 53.91%] [G loss: 0.745911]\n",
      "epoch:7 step:6643 [D loss: 0.679982, acc.: 57.81%] [G loss: 0.723688]\n",
      "epoch:7 step:6644 [D loss: 0.683665, acc.: 56.25%] [G loss: 0.735865]\n",
      "epoch:7 step:6645 [D loss: 0.697371, acc.: 46.88%] [G loss: 0.746190]\n",
      "epoch:7 step:6646 [D loss: 0.695326, acc.: 54.69%] [G loss: 0.699005]\n",
      "epoch:7 step:6647 [D loss: 0.693234, acc.: 50.78%] [G loss: 0.722904]\n",
      "epoch:7 step:6648 [D loss: 0.676738, acc.: 56.25%] [G loss: 0.735431]\n",
      "epoch:7 step:6649 [D loss: 0.684442, acc.: 55.47%] [G loss: 0.742181]\n",
      "epoch:7 step:6650 [D loss: 0.677743, acc.: 57.03%] [G loss: 0.706857]\n",
      "epoch:7 step:6651 [D loss: 0.688712, acc.: 53.91%] [G loss: 0.716923]\n",
      "epoch:7 step:6652 [D loss: 0.678041, acc.: 55.47%] [G loss: 0.728169]\n",
      "epoch:7 step:6653 [D loss: 0.670089, acc.: 57.03%] [G loss: 0.749439]\n",
      "epoch:7 step:6654 [D loss: 0.696163, acc.: 50.78%] [G loss: 0.715689]\n",
      "epoch:7 step:6655 [D loss: 0.679593, acc.: 61.72%] [G loss: 0.698592]\n",
      "epoch:7 step:6656 [D loss: 0.688076, acc.: 56.25%] [G loss: 0.715451]\n",
      "epoch:7 step:6657 [D loss: 0.693995, acc.: 54.69%] [G loss: 0.725284]\n",
      "epoch:7 step:6658 [D loss: 0.690848, acc.: 63.28%] [G loss: 0.701340]\n",
      "epoch:7 step:6659 [D loss: 0.671019, acc.: 57.81%] [G loss: 0.721982]\n",
      "epoch:7 step:6660 [D loss: 0.709688, acc.: 40.62%] [G loss: 0.729300]\n",
      "epoch:7 step:6661 [D loss: 0.710028, acc.: 46.88%] [G loss: 0.726009]\n",
      "epoch:7 step:6662 [D loss: 0.685269, acc.: 60.94%] [G loss: 0.729962]\n",
      "epoch:7 step:6663 [D loss: 0.680636, acc.: 47.66%] [G loss: 0.732939]\n",
      "epoch:7 step:6664 [D loss: 0.655272, acc.: 66.41%] [G loss: 0.764878]\n",
      "epoch:7 step:6665 [D loss: 0.660584, acc.: 66.41%] [G loss: 0.721745]\n",
      "epoch:7 step:6666 [D loss: 0.650707, acc.: 63.28%] [G loss: 0.769353]\n",
      "epoch:7 step:6667 [D loss: 0.721809, acc.: 40.62%] [G loss: 0.760084]\n",
      "epoch:7 step:6668 [D loss: 0.721201, acc.: 50.00%] [G loss: 0.712490]\n",
      "epoch:7 step:6669 [D loss: 0.705843, acc.: 43.75%] [G loss: 0.731947]\n",
      "epoch:7 step:6670 [D loss: 0.688930, acc.: 43.75%] [G loss: 0.742302]\n",
      "epoch:7 step:6671 [D loss: 0.702636, acc.: 43.75%] [G loss: 0.709001]\n",
      "epoch:7 step:6672 [D loss: 0.708575, acc.: 46.09%] [G loss: 0.720032]\n",
      "epoch:7 step:6673 [D loss: 0.694105, acc.: 54.69%] [G loss: 0.734210]\n",
      "epoch:7 step:6674 [D loss: 0.696887, acc.: 45.31%] [G loss: 0.748501]\n",
      "epoch:7 step:6675 [D loss: 0.695033, acc.: 50.78%] [G loss: 0.734601]\n",
      "epoch:7 step:6676 [D loss: 0.693023, acc.: 49.22%] [G loss: 0.738345]\n",
      "epoch:7 step:6677 [D loss: 0.670583, acc.: 58.59%] [G loss: 0.762612]\n",
      "epoch:7 step:6678 [D loss: 0.666819, acc.: 62.50%] [G loss: 0.770921]\n",
      "epoch:7 step:6679 [D loss: 0.684282, acc.: 53.12%] [G loss: 0.772722]\n",
      "epoch:7 step:6680 [D loss: 0.678003, acc.: 58.59%] [G loss: 0.778818]\n",
      "epoch:7 step:6681 [D loss: 0.667657, acc.: 57.81%] [G loss: 0.848435]\n",
      "epoch:7 step:6682 [D loss: 0.672772, acc.: 55.47%] [G loss: 0.791710]\n",
      "epoch:7 step:6683 [D loss: 0.686706, acc.: 49.22%] [G loss: 0.797226]\n",
      "epoch:7 step:6684 [D loss: 0.657614, acc.: 68.75%] [G loss: 0.786320]\n",
      "epoch:7 step:6685 [D loss: 0.691479, acc.: 60.16%] [G loss: 0.762250]\n",
      "epoch:7 step:6686 [D loss: 0.704756, acc.: 57.81%] [G loss: 0.770055]\n",
      "epoch:7 step:6687 [D loss: 0.693978, acc.: 53.12%] [G loss: 0.784533]\n",
      "epoch:7 step:6688 [D loss: 0.700928, acc.: 52.34%] [G loss: 0.751113]\n",
      "epoch:7 step:6689 [D loss: 0.669736, acc.: 57.81%] [G loss: 0.767904]\n",
      "epoch:7 step:6690 [D loss: 0.684234, acc.: 56.25%] [G loss: 0.757788]\n",
      "epoch:7 step:6691 [D loss: 0.681694, acc.: 55.47%] [G loss: 0.797356]\n",
      "epoch:7 step:6692 [D loss: 0.672456, acc.: 53.91%] [G loss: 0.752493]\n",
      "epoch:7 step:6693 [D loss: 0.696624, acc.: 49.22%] [G loss: 0.703425]\n",
      "epoch:7 step:6694 [D loss: 0.692510, acc.: 51.56%] [G loss: 0.726857]\n",
      "epoch:7 step:6695 [D loss: 0.680183, acc.: 54.69%] [G loss: 0.701911]\n",
      "epoch:7 step:6696 [D loss: 0.704232, acc.: 50.00%] [G loss: 0.758576]\n",
      "epoch:7 step:6697 [D loss: 0.684125, acc.: 52.34%] [G loss: 0.684743]\n",
      "epoch:7 step:6698 [D loss: 0.659619, acc.: 58.59%] [G loss: 0.724762]\n",
      "epoch:7 step:6699 [D loss: 0.733170, acc.: 37.50%] [G loss: 0.704100]\n",
      "epoch:7 step:6700 [D loss: 0.711371, acc.: 41.41%] [G loss: 0.722491]\n",
      "epoch:7 step:6701 [D loss: 0.699723, acc.: 49.22%] [G loss: 0.746551]\n",
      "epoch:7 step:6702 [D loss: 0.683136, acc.: 49.22%] [G loss: 0.749839]\n",
      "epoch:7 step:6703 [D loss: 0.672568, acc.: 53.91%] [G loss: 0.704818]\n",
      "epoch:7 step:6704 [D loss: 0.679498, acc.: 54.69%] [G loss: 0.671354]\n",
      "epoch:7 step:6705 [D loss: 0.663210, acc.: 58.59%] [G loss: 0.734670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6706 [D loss: 0.689045, acc.: 46.88%] [G loss: 0.754287]\n",
      "epoch:7 step:6707 [D loss: 0.719541, acc.: 42.19%] [G loss: 0.730838]\n",
      "epoch:7 step:6708 [D loss: 0.695459, acc.: 46.09%] [G loss: 0.715048]\n",
      "epoch:7 step:6709 [D loss: 0.691150, acc.: 57.03%] [G loss: 0.704562]\n",
      "epoch:7 step:6710 [D loss: 0.679518, acc.: 59.38%] [G loss: 0.722093]\n",
      "epoch:7 step:6711 [D loss: 0.653044, acc.: 71.88%] [G loss: 0.680920]\n",
      "epoch:7 step:6712 [D loss: 0.697284, acc.: 48.44%] [G loss: 0.749193]\n",
      "epoch:7 step:6713 [D loss: 0.677148, acc.: 60.16%] [G loss: 0.747272]\n",
      "epoch:7 step:6714 [D loss: 0.650131, acc.: 64.06%] [G loss: 0.850643]\n",
      "epoch:7 step:6715 [D loss: 0.714806, acc.: 48.44%] [G loss: 0.806575]\n",
      "epoch:7 step:6716 [D loss: 0.682315, acc.: 52.34%] [G loss: 0.819007]\n",
      "epoch:7 step:6717 [D loss: 0.708879, acc.: 47.66%] [G loss: 0.782103]\n",
      "epoch:7 step:6718 [D loss: 0.716154, acc.: 52.34%] [G loss: 0.826402]\n",
      "epoch:7 step:6719 [D loss: 0.718729, acc.: 46.09%] [G loss: 0.758954]\n",
      "epoch:7 step:6720 [D loss: 0.680954, acc.: 57.03%] [G loss: 0.752907]\n",
      "epoch:7 step:6721 [D loss: 0.680453, acc.: 60.16%] [G loss: 0.769252]\n",
      "epoch:7 step:6722 [D loss: 0.711156, acc.: 46.88%] [G loss: 0.726969]\n",
      "epoch:7 step:6723 [D loss: 0.694270, acc.: 52.34%] [G loss: 0.761876]\n",
      "epoch:7 step:6724 [D loss: 0.704547, acc.: 46.09%] [G loss: 0.753209]\n",
      "epoch:7 step:6725 [D loss: 0.711533, acc.: 46.09%] [G loss: 0.748573]\n",
      "epoch:7 step:6726 [D loss: 0.707900, acc.: 46.88%] [G loss: 0.752415]\n",
      "epoch:7 step:6727 [D loss: 0.672724, acc.: 59.38%] [G loss: 0.772963]\n",
      "epoch:7 step:6728 [D loss: 0.681135, acc.: 55.47%] [G loss: 0.754247]\n",
      "epoch:7 step:6729 [D loss: 0.728286, acc.: 42.97%] [G loss: 0.739767]\n",
      "epoch:7 step:6730 [D loss: 0.687634, acc.: 56.25%] [G loss: 0.740380]\n",
      "epoch:7 step:6731 [D loss: 0.688860, acc.: 51.56%] [G loss: 0.756268]\n",
      "epoch:7 step:6732 [D loss: 0.684849, acc.: 54.69%] [G loss: 0.686702]\n",
      "epoch:7 step:6733 [D loss: 0.701331, acc.: 47.66%] [G loss: 0.695863]\n",
      "epoch:7 step:6734 [D loss: 0.708971, acc.: 45.31%] [G loss: 0.699397]\n",
      "epoch:7 step:6735 [D loss: 0.697105, acc.: 50.78%] [G loss: 0.693968]\n",
      "epoch:7 step:6736 [D loss: 0.702999, acc.: 43.75%] [G loss: 0.696691]\n",
      "epoch:7 step:6737 [D loss: 0.687695, acc.: 49.22%] [G loss: 0.697459]\n",
      "epoch:7 step:6738 [D loss: 0.702173, acc.: 45.31%] [G loss: 0.696111]\n",
      "epoch:7 step:6739 [D loss: 0.680166, acc.: 60.16%] [G loss: 0.694908]\n",
      "epoch:7 step:6740 [D loss: 0.679865, acc.: 50.00%] [G loss: 0.730948]\n",
      "epoch:7 step:6741 [D loss: 0.693925, acc.: 53.91%] [G loss: 0.704785]\n",
      "epoch:7 step:6742 [D loss: 0.691433, acc.: 51.56%] [G loss: 0.669707]\n",
      "epoch:7 step:6743 [D loss: 0.672147, acc.: 56.25%] [G loss: 0.723696]\n",
      "epoch:7 step:6744 [D loss: 0.666373, acc.: 62.50%] [G loss: 0.714562]\n",
      "epoch:7 step:6745 [D loss: 0.699898, acc.: 58.59%] [G loss: 0.713465]\n",
      "epoch:7 step:6746 [D loss: 0.670484, acc.: 63.28%] [G loss: 0.710198]\n",
      "epoch:7 step:6747 [D loss: 0.701180, acc.: 54.69%] [G loss: 0.708034]\n",
      "epoch:7 step:6748 [D loss: 0.704612, acc.: 46.88%] [G loss: 0.704667]\n",
      "epoch:7 step:6749 [D loss: 0.690932, acc.: 50.78%] [G loss: 0.713118]\n",
      "epoch:7 step:6750 [D loss: 0.694156, acc.: 52.34%] [G loss: 0.693183]\n",
      "epoch:7 step:6751 [D loss: 0.699117, acc.: 56.25%] [G loss: 0.714950]\n",
      "epoch:7 step:6752 [D loss: 0.692647, acc.: 55.47%] [G loss: 0.694294]\n",
      "epoch:7 step:6753 [D loss: 0.689362, acc.: 53.12%] [G loss: 0.715312]\n",
      "epoch:7 step:6754 [D loss: 0.693085, acc.: 48.44%] [G loss: 0.744384]\n",
      "epoch:7 step:6755 [D loss: 0.707622, acc.: 42.19%] [G loss: 0.716522]\n",
      "epoch:7 step:6756 [D loss: 0.715846, acc.: 39.06%] [G loss: 0.717577]\n",
      "epoch:7 step:6757 [D loss: 0.690413, acc.: 59.38%] [G loss: 0.725908]\n",
      "epoch:7 step:6758 [D loss: 0.699601, acc.: 49.22%] [G loss: 0.742678]\n",
      "epoch:7 step:6759 [D loss: 0.697671, acc.: 50.78%] [G loss: 0.750140]\n",
      "epoch:7 step:6760 [D loss: 0.693603, acc.: 52.34%] [G loss: 0.776752]\n",
      "epoch:7 step:6761 [D loss: 0.681653, acc.: 58.59%] [G loss: 0.756343]\n",
      "epoch:7 step:6762 [D loss: 0.692947, acc.: 52.34%] [G loss: 0.779736]\n",
      "epoch:7 step:6763 [D loss: 0.648172, acc.: 71.88%] [G loss: 0.762160]\n",
      "epoch:7 step:6764 [D loss: 0.678735, acc.: 59.38%] [G loss: 0.765000]\n",
      "epoch:7 step:6765 [D loss: 0.665843, acc.: 60.16%] [G loss: 0.772269]\n",
      "epoch:7 step:6766 [D loss: 0.550876, acc.: 65.62%] [G loss: 0.770936]\n",
      "epoch:7 step:6767 [D loss: 0.684356, acc.: 61.72%] [G loss: 0.745906]\n",
      "epoch:7 step:6768 [D loss: 0.651148, acc.: 65.62%] [G loss: 0.741459]\n",
      "epoch:7 step:6769 [D loss: 0.683405, acc.: 53.12%] [G loss: 0.758844]\n",
      "epoch:7 step:6770 [D loss: 0.703510, acc.: 41.41%] [G loss: 0.748369]\n",
      "epoch:7 step:6771 [D loss: 0.688223, acc.: 57.03%] [G loss: 0.746007]\n",
      "epoch:7 step:6772 [D loss: 0.679461, acc.: 56.25%] [G loss: 0.750666]\n",
      "epoch:7 step:6773 [D loss: 0.703130, acc.: 56.25%] [G loss: 0.733655]\n",
      "epoch:7 step:6774 [D loss: 0.712389, acc.: 46.09%] [G loss: 0.706538]\n",
      "epoch:7 step:6775 [D loss: 0.625092, acc.: 59.38%] [G loss: 0.678143]\n",
      "epoch:7 step:6776 [D loss: 0.713779, acc.: 42.97%] [G loss: 0.595959]\n",
      "epoch:7 step:6777 [D loss: 0.724273, acc.: 41.41%] [G loss: 0.640362]\n",
      "epoch:7 step:6778 [D loss: 0.704527, acc.: 46.09%] [G loss: 0.333732]\n",
      "epoch:7 step:6779 [D loss: 0.751655, acc.: 30.47%] [G loss: 0.547960]\n",
      "epoch:7 step:6780 [D loss: 1.077989, acc.: 21.09%] [G loss: 0.822555]\n",
      "epoch:7 step:6781 [D loss: 0.532455, acc.: 57.81%] [G loss: 2.266298]\n",
      "epoch:7 step:6782 [D loss: 0.458769, acc.: 59.38%] [G loss: 0.945768]\n",
      "epoch:7 step:6783 [D loss: 0.740288, acc.: 46.09%] [G loss: 1.307118]\n",
      "epoch:7 step:6784 [D loss: 0.862594, acc.: 21.09%] [G loss: 0.723586]\n",
      "epoch:7 step:6785 [D loss: 0.727390, acc.: 52.34%] [G loss: 0.693670]\n",
      "epoch:7 step:6786 [D loss: 0.702100, acc.: 51.56%] [G loss: 0.734820]\n",
      "epoch:7 step:6787 [D loss: 0.691675, acc.: 49.22%] [G loss: 0.760651]\n",
      "epoch:7 step:6788 [D loss: 0.699284, acc.: 50.78%] [G loss: 0.734353]\n",
      "epoch:7 step:6789 [D loss: 0.682733, acc.: 59.38%] [G loss: 0.737369]\n",
      "epoch:7 step:6790 [D loss: 0.682248, acc.: 56.25%] [G loss: 0.765009]\n",
      "epoch:7 step:6791 [D loss: 0.681752, acc.: 60.16%] [G loss: 0.726384]\n",
      "epoch:7 step:6792 [D loss: 0.682079, acc.: 57.03%] [G loss: 0.746275]\n",
      "epoch:7 step:6793 [D loss: 0.664670, acc.: 59.38%] [G loss: 0.748214]\n",
      "epoch:7 step:6794 [D loss: 0.657455, acc.: 63.28%] [G loss: 0.762474]\n",
      "epoch:7 step:6795 [D loss: 0.684108, acc.: 50.78%] [G loss: 0.769867]\n",
      "epoch:7 step:6796 [D loss: 0.668466, acc.: 60.94%] [G loss: 0.783655]\n",
      "epoch:7 step:6797 [D loss: 0.694592, acc.: 46.09%] [G loss: 0.757302]\n",
      "epoch:7 step:6798 [D loss: 0.680306, acc.: 53.91%] [G loss: 0.797083]\n",
      "epoch:7 step:6799 [D loss: 0.651190, acc.: 67.97%] [G loss: 0.793707]\n",
      "epoch:7 step:6800 [D loss: 0.669306, acc.: 64.84%] [G loss: 0.817526]\n",
      "epoch:7 step:6801 [D loss: 0.655506, acc.: 60.16%] [G loss: 0.872759]\n",
      "epoch:7 step:6802 [D loss: 0.665229, acc.: 50.00%] [G loss: 0.795657]\n",
      "epoch:7 step:6803 [D loss: 0.624497, acc.: 67.97%] [G loss: 0.788960]\n",
      "epoch:7 step:6804 [D loss: 0.665471, acc.: 56.25%] [G loss: 0.860344]\n",
      "epoch:7 step:6805 [D loss: 0.711840, acc.: 51.56%] [G loss: 0.793605]\n",
      "epoch:7 step:6806 [D loss: 0.722760, acc.: 49.22%] [G loss: 0.744005]\n",
      "epoch:7 step:6807 [D loss: 0.684455, acc.: 67.19%] [G loss: 0.761564]\n",
      "epoch:7 step:6808 [D loss: 0.762770, acc.: 34.38%] [G loss: 0.679173]\n",
      "epoch:7 step:6809 [D loss: 0.688044, acc.: 57.03%] [G loss: 0.745434]\n",
      "epoch:7 step:6810 [D loss: 0.708589, acc.: 46.09%] [G loss: 0.742050]\n",
      "epoch:7 step:6811 [D loss: 0.679684, acc.: 59.38%] [G loss: 0.743580]\n",
      "epoch:7 step:6812 [D loss: 0.704618, acc.: 53.12%] [G loss: 0.729675]\n",
      "epoch:7 step:6813 [D loss: 0.722101, acc.: 38.28%] [G loss: 0.726079]\n",
      "epoch:7 step:6814 [D loss: 0.708247, acc.: 53.91%] [G loss: 0.736318]\n",
      "epoch:7 step:6815 [D loss: 0.665942, acc.: 64.84%] [G loss: 0.738568]\n",
      "epoch:7 step:6816 [D loss: 0.683237, acc.: 60.16%] [G loss: 0.722318]\n",
      "epoch:7 step:6817 [D loss: 0.695176, acc.: 58.59%] [G loss: 0.745412]\n",
      "epoch:7 step:6818 [D loss: 0.668728, acc.: 57.03%] [G loss: 0.746593]\n",
      "epoch:7 step:6819 [D loss: 0.666644, acc.: 59.38%] [G loss: 0.742181]\n",
      "epoch:7 step:6820 [D loss: 0.654299, acc.: 56.25%] [G loss: 0.766413]\n",
      "epoch:7 step:6821 [D loss: 0.700231, acc.: 56.25%] [G loss: 0.805440]\n",
      "epoch:7 step:6822 [D loss: 0.949639, acc.: 25.78%] [G loss: 0.447872]\n",
      "epoch:7 step:6823 [D loss: 0.675548, acc.: 57.81%] [G loss: 0.762393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6824 [D loss: 0.749698, acc.: 46.09%] [G loss: 0.777624]\n",
      "epoch:7 step:6825 [D loss: 0.703403, acc.: 49.22%] [G loss: 0.742823]\n",
      "epoch:7 step:6826 [D loss: 0.694816, acc.: 53.91%] [G loss: 0.729264]\n",
      "epoch:7 step:6827 [D loss: 0.700323, acc.: 51.56%] [G loss: 0.746618]\n",
      "epoch:7 step:6828 [D loss: 0.706711, acc.: 45.31%] [G loss: 0.617015]\n",
      "epoch:7 step:6829 [D loss: 0.688764, acc.: 55.47%] [G loss: 0.758164]\n",
      "epoch:7 step:6830 [D loss: 0.660431, acc.: 54.69%] [G loss: 0.798699]\n",
      "epoch:7 step:6831 [D loss: 0.709979, acc.: 45.31%] [G loss: 0.783481]\n",
      "epoch:7 step:6832 [D loss: 0.688594, acc.: 57.03%] [G loss: 0.792580]\n",
      "epoch:7 step:6833 [D loss: 0.648222, acc.: 60.94%] [G loss: 0.828002]\n",
      "epoch:7 step:6834 [D loss: 0.670907, acc.: 50.00%] [G loss: 0.914929]\n",
      "epoch:7 step:6835 [D loss: 0.711600, acc.: 47.66%] [G loss: 0.764114]\n",
      "epoch:7 step:6836 [D loss: 0.719781, acc.: 41.41%] [G loss: 0.637718]\n",
      "epoch:7 step:6837 [D loss: 0.723397, acc.: 39.06%] [G loss: 0.633885]\n",
      "epoch:7 step:6838 [D loss: 0.715779, acc.: 40.62%] [G loss: 0.728527]\n",
      "epoch:7 step:6839 [D loss: 0.684834, acc.: 53.12%] [G loss: 0.664660]\n",
      "epoch:7 step:6840 [D loss: 0.827258, acc.: 23.44%] [G loss: 0.766262]\n",
      "epoch:7 step:6841 [D loss: 0.673247, acc.: 53.12%] [G loss: 0.868166]\n",
      "epoch:7 step:6842 [D loss: 0.665423, acc.: 59.38%] [G loss: 0.796323]\n",
      "epoch:7 step:6843 [D loss: 0.656747, acc.: 60.94%] [G loss: 0.821611]\n",
      "epoch:7 step:6844 [D loss: 0.657127, acc.: 64.06%] [G loss: 0.794834]\n",
      "epoch:7 step:6845 [D loss: 0.663173, acc.: 58.59%] [G loss: 0.820955]\n",
      "epoch:7 step:6846 [D loss: 0.653227, acc.: 60.16%] [G loss: 0.846323]\n",
      "epoch:7 step:6847 [D loss: 0.653703, acc.: 60.94%] [G loss: 1.012251]\n",
      "epoch:7 step:6848 [D loss: 0.589852, acc.: 84.38%] [G loss: 0.731680]\n",
      "epoch:7 step:6849 [D loss: 0.622261, acc.: 67.19%] [G loss: 0.714638]\n",
      "epoch:7 step:6850 [D loss: 0.730010, acc.: 37.50%] [G loss: 0.753157]\n",
      "epoch:7 step:6851 [D loss: 0.620243, acc.: 65.62%] [G loss: 0.774445]\n",
      "epoch:7 step:6852 [D loss: 0.736816, acc.: 43.75%] [G loss: 0.648020]\n",
      "epoch:7 step:6853 [D loss: 0.717602, acc.: 50.78%] [G loss: 0.778655]\n",
      "epoch:7 step:6854 [D loss: 0.749594, acc.: 37.50%] [G loss: 0.789159]\n",
      "epoch:7 step:6855 [D loss: 0.682378, acc.: 54.69%] [G loss: 0.721387]\n",
      "epoch:7 step:6856 [D loss: 0.764571, acc.: 31.25%] [G loss: 0.754107]\n",
      "epoch:7 step:6857 [D loss: 0.728271, acc.: 39.84%] [G loss: 0.802562]\n",
      "epoch:7 step:6858 [D loss: 0.737905, acc.: 39.84%] [G loss: 0.766591]\n",
      "epoch:7 step:6859 [D loss: 0.699778, acc.: 46.88%] [G loss: 0.784763]\n",
      "epoch:7 step:6860 [D loss: 0.693854, acc.: 50.00%] [G loss: 0.771666]\n",
      "epoch:7 step:6861 [D loss: 0.676084, acc.: 60.16%] [G loss: 0.794828]\n",
      "epoch:7 step:6862 [D loss: 0.676837, acc.: 56.25%] [G loss: 0.764542]\n",
      "epoch:7 step:6863 [D loss: 0.692111, acc.: 56.25%] [G loss: 0.775909]\n",
      "epoch:7 step:6864 [D loss: 0.669719, acc.: 56.25%] [G loss: 0.772262]\n",
      "epoch:7 step:6865 [D loss: 0.661794, acc.: 65.62%] [G loss: 0.748857]\n",
      "epoch:7 step:6866 [D loss: 0.668029, acc.: 55.47%] [G loss: 0.752640]\n",
      "epoch:7 step:6867 [D loss: 0.682843, acc.: 57.03%] [G loss: 0.753792]\n",
      "epoch:7 step:6868 [D loss: 0.688636, acc.: 53.12%] [G loss: 0.772362]\n",
      "epoch:7 step:6869 [D loss: 0.691159, acc.: 53.91%] [G loss: 0.780727]\n",
      "epoch:7 step:6870 [D loss: 0.708070, acc.: 46.09%] [G loss: 0.710574]\n",
      "epoch:7 step:6871 [D loss: 0.712418, acc.: 43.75%] [G loss: 0.726653]\n",
      "epoch:7 step:6872 [D loss: 0.694775, acc.: 53.12%] [G loss: 0.698081]\n",
      "epoch:7 step:6873 [D loss: 0.697836, acc.: 54.69%] [G loss: 0.717979]\n",
      "epoch:7 step:6874 [D loss: 0.689520, acc.: 53.91%] [G loss: 0.744270]\n",
      "epoch:7 step:6875 [D loss: 0.703965, acc.: 46.88%] [G loss: 0.734229]\n",
      "epoch:7 step:6876 [D loss: 0.698269, acc.: 44.53%] [G loss: 0.773720]\n",
      "epoch:7 step:6877 [D loss: 0.670800, acc.: 54.69%] [G loss: 0.790237]\n",
      "epoch:7 step:6878 [D loss: 0.678517, acc.: 62.50%] [G loss: 0.774841]\n",
      "epoch:7 step:6879 [D loss: 0.668439, acc.: 54.69%] [G loss: 0.794228]\n",
      "epoch:7 step:6880 [D loss: 0.693651, acc.: 49.22%] [G loss: 0.804886]\n",
      "epoch:7 step:6881 [D loss: 0.680179, acc.: 54.69%] [G loss: 0.793485]\n",
      "epoch:7 step:6882 [D loss: 0.688995, acc.: 55.47%] [G loss: 0.773632]\n",
      "epoch:7 step:6883 [D loss: 0.682449, acc.: 57.81%] [G loss: 0.693502]\n",
      "epoch:7 step:6884 [D loss: 0.683474, acc.: 56.25%] [G loss: 0.712211]\n",
      "epoch:7 step:6885 [D loss: 0.718639, acc.: 46.09%] [G loss: 0.726487]\n",
      "epoch:7 step:6886 [D loss: 0.632892, acc.: 72.66%] [G loss: 0.733103]\n",
      "epoch:7 step:6887 [D loss: 0.669673, acc.: 61.72%] [G loss: 0.810253]\n",
      "epoch:7 step:6888 [D loss: 0.694366, acc.: 52.34%] [G loss: 0.689867]\n",
      "epoch:7 step:6889 [D loss: 0.715801, acc.: 47.66%] [G loss: 0.826660]\n",
      "epoch:7 step:6890 [D loss: 0.708863, acc.: 39.84%] [G loss: 0.665504]\n",
      "epoch:7 step:6891 [D loss: 0.742452, acc.: 32.81%] [G loss: 0.639458]\n",
      "epoch:7 step:6892 [D loss: 0.734941, acc.: 28.12%] [G loss: 0.784524]\n",
      "epoch:7 step:6893 [D loss: 0.722610, acc.: 36.72%] [G loss: 0.671152]\n",
      "epoch:7 step:6894 [D loss: 0.713457, acc.: 39.06%] [G loss: 0.683653]\n",
      "epoch:7 step:6895 [D loss: 0.697138, acc.: 43.75%] [G loss: 0.663085]\n",
      "epoch:7 step:6896 [D loss: 0.686439, acc.: 53.91%] [G loss: 0.667186]\n",
      "epoch:7 step:6897 [D loss: 0.691669, acc.: 52.34%] [G loss: 0.685565]\n",
      "epoch:7 step:6898 [D loss: 0.692246, acc.: 54.69%] [G loss: 0.677237]\n",
      "epoch:7 step:6899 [D loss: 0.689438, acc.: 52.34%] [G loss: 0.671899]\n",
      "epoch:7 step:6900 [D loss: 0.688826, acc.: 48.44%] [G loss: 0.696962]\n",
      "epoch:7 step:6901 [D loss: 0.685430, acc.: 46.09%] [G loss: 0.703378]\n",
      "epoch:7 step:6902 [D loss: 0.683811, acc.: 55.47%] [G loss: 0.717348]\n",
      "epoch:7 step:6903 [D loss: 0.667730, acc.: 57.03%] [G loss: 0.683280]\n",
      "epoch:7 step:6904 [D loss: 0.696088, acc.: 50.78%] [G loss: 0.732647]\n",
      "epoch:7 step:6905 [D loss: 0.695466, acc.: 50.00%] [G loss: 0.740579]\n",
      "epoch:7 step:6906 [D loss: 0.665218, acc.: 65.62%] [G loss: 0.773216]\n",
      "epoch:7 step:6907 [D loss: 0.684647, acc.: 64.06%] [G loss: 0.768747]\n",
      "epoch:7 step:6908 [D loss: 0.711268, acc.: 39.84%] [G loss: 0.764491]\n",
      "epoch:7 step:6909 [D loss: 0.697034, acc.: 54.69%] [G loss: 0.708011]\n",
      "epoch:7 step:6910 [D loss: 0.708873, acc.: 42.97%] [G loss: 0.719346]\n",
      "epoch:7 step:6911 [D loss: 0.698942, acc.: 50.00%] [G loss: 0.732638]\n",
      "epoch:7 step:6912 [D loss: 0.703885, acc.: 45.31%] [G loss: 0.765508]\n",
      "epoch:7 step:6913 [D loss: 0.692105, acc.: 51.56%] [G loss: 0.778160]\n",
      "epoch:7 step:6914 [D loss: 0.702989, acc.: 50.78%] [G loss: 0.733520]\n",
      "epoch:7 step:6915 [D loss: 0.685462, acc.: 55.47%] [G loss: 0.727879]\n",
      "epoch:7 step:6916 [D loss: 0.710070, acc.: 40.62%] [G loss: 0.740615]\n",
      "epoch:7 step:6917 [D loss: 0.686262, acc.: 50.00%] [G loss: 0.733201]\n",
      "epoch:7 step:6918 [D loss: 0.684887, acc.: 50.78%] [G loss: 0.746416]\n",
      "epoch:7 step:6919 [D loss: 0.687783, acc.: 50.00%] [G loss: 0.718111]\n",
      "epoch:7 step:6920 [D loss: 0.686821, acc.: 48.44%] [G loss: 0.745713]\n",
      "epoch:7 step:6921 [D loss: 0.676005, acc.: 57.81%] [G loss: 0.744435]\n",
      "epoch:7 step:6922 [D loss: 0.675985, acc.: 62.50%] [G loss: 0.748116]\n",
      "epoch:7 step:6923 [D loss: 0.676841, acc.: 57.81%] [G loss: 0.730841]\n",
      "epoch:7 step:6924 [D loss: 0.671252, acc.: 64.06%] [G loss: 0.749029]\n",
      "epoch:7 step:6925 [D loss: 0.674725, acc.: 60.94%] [G loss: 0.732482]\n",
      "epoch:7 step:6926 [D loss: 0.678008, acc.: 57.81%] [G loss: 0.719992]\n",
      "epoch:7 step:6927 [D loss: 0.687739, acc.: 50.78%] [G loss: 0.727987]\n",
      "epoch:7 step:6928 [D loss: 0.703342, acc.: 49.22%] [G loss: 0.727759]\n",
      "epoch:7 step:6929 [D loss: 0.700274, acc.: 49.22%] [G loss: 0.750689]\n",
      "epoch:7 step:6930 [D loss: 0.659748, acc.: 60.94%] [G loss: 0.725183]\n",
      "epoch:7 step:6931 [D loss: 0.701178, acc.: 57.03%] [G loss: 0.738043]\n",
      "epoch:7 step:6932 [D loss: 0.704480, acc.: 49.22%] [G loss: 0.717046]\n",
      "epoch:7 step:6933 [D loss: 0.685904, acc.: 58.59%] [G loss: 0.732364]\n",
      "epoch:7 step:6934 [D loss: 0.686513, acc.: 58.59%] [G loss: 0.696991]\n",
      "epoch:7 step:6935 [D loss: 0.691155, acc.: 46.88%] [G loss: 0.696563]\n",
      "epoch:7 step:6936 [D loss: 0.721368, acc.: 39.06%] [G loss: 0.723979]\n",
      "epoch:7 step:6937 [D loss: 0.670608, acc.: 59.38%] [G loss: 0.705341]\n",
      "epoch:7 step:6938 [D loss: 0.694596, acc.: 56.25%] [G loss: 0.696721]\n",
      "epoch:7 step:6939 [D loss: 0.713315, acc.: 44.53%] [G loss: 0.715314]\n",
      "epoch:7 step:6940 [D loss: 0.682824, acc.: 51.56%] [G loss: 0.756058]\n",
      "epoch:7 step:6941 [D loss: 0.681728, acc.: 53.12%] [G loss: 0.718314]\n",
      "epoch:7 step:6942 [D loss: 0.681178, acc.: 56.25%] [G loss: 0.752253]\n",
      "epoch:7 step:6943 [D loss: 0.691283, acc.: 54.69%] [G loss: 0.755621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6944 [D loss: 0.692785, acc.: 52.34%] [G loss: 0.714433]\n",
      "epoch:7 step:6945 [D loss: 0.689851, acc.: 49.22%] [G loss: 0.725577]\n",
      "epoch:7 step:6946 [D loss: 0.679888, acc.: 63.28%] [G loss: 0.743925]\n",
      "epoch:7 step:6947 [D loss: 0.675501, acc.: 55.47%] [G loss: 0.738067]\n",
      "epoch:7 step:6948 [D loss: 0.683288, acc.: 60.16%] [G loss: 0.727082]\n",
      "epoch:7 step:6949 [D loss: 0.762459, acc.: 35.16%] [G loss: 0.737063]\n",
      "epoch:7 step:6950 [D loss: 0.685218, acc.: 50.78%] [G loss: 0.734495]\n",
      "epoch:7 step:6951 [D loss: 0.688047, acc.: 50.78%] [G loss: 0.756921]\n",
      "epoch:7 step:6952 [D loss: 0.693734, acc.: 48.44%] [G loss: 0.726493]\n",
      "epoch:7 step:6953 [D loss: 0.714340, acc.: 48.44%] [G loss: 0.745771]\n",
      "epoch:7 step:6954 [D loss: 0.697670, acc.: 45.31%] [G loss: 0.744259]\n",
      "epoch:7 step:6955 [D loss: 0.705073, acc.: 46.88%] [G loss: 0.719015]\n",
      "epoch:7 step:6956 [D loss: 0.703937, acc.: 43.75%] [G loss: 0.721489]\n",
      "epoch:7 step:6957 [D loss: 0.695493, acc.: 48.44%] [G loss: 0.731270]\n",
      "epoch:7 step:6958 [D loss: 0.692796, acc.: 53.91%] [G loss: 0.723616]\n",
      "epoch:7 step:6959 [D loss: 0.698818, acc.: 42.97%] [G loss: 0.710763]\n",
      "epoch:7 step:6960 [D loss: 0.691468, acc.: 49.22%] [G loss: 0.724379]\n",
      "epoch:7 step:6961 [D loss: 0.694349, acc.: 48.44%] [G loss: 0.700620]\n",
      "epoch:7 step:6962 [D loss: 0.725995, acc.: 42.97%] [G loss: 0.720978]\n",
      "epoch:7 step:6963 [D loss: 0.686122, acc.: 53.91%] [G loss: 0.731702]\n",
      "epoch:7 step:6964 [D loss: 0.677807, acc.: 53.12%] [G loss: 0.762449]\n",
      "epoch:7 step:6965 [D loss: 0.672124, acc.: 56.25%] [G loss: 0.741294]\n",
      "epoch:7 step:6966 [D loss: 0.688797, acc.: 51.56%] [G loss: 0.726609]\n",
      "epoch:7 step:6967 [D loss: 0.711561, acc.: 43.75%] [G loss: 0.719097]\n",
      "epoch:7 step:6968 [D loss: 0.682982, acc.: 53.12%] [G loss: 0.731558]\n",
      "epoch:7 step:6969 [D loss: 0.692442, acc.: 53.12%] [G loss: 0.747812]\n",
      "epoch:7 step:6970 [D loss: 0.708870, acc.: 50.78%] [G loss: 0.726477]\n",
      "epoch:7 step:6971 [D loss: 0.689601, acc.: 50.00%] [G loss: 0.710544]\n",
      "epoch:7 step:6972 [D loss: 0.686639, acc.: 50.00%] [G loss: 0.691580]\n",
      "epoch:7 step:6973 [D loss: 0.700553, acc.: 46.88%] [G loss: 0.723184]\n",
      "epoch:7 step:6974 [D loss: 0.676925, acc.: 57.81%] [G loss: 0.719061]\n",
      "epoch:7 step:6975 [D loss: 0.685722, acc.: 53.12%] [G loss: 0.707397]\n",
      "epoch:7 step:6976 [D loss: 0.692563, acc.: 53.12%] [G loss: 0.720743]\n",
      "epoch:7 step:6977 [D loss: 0.688015, acc.: 50.78%] [G loss: 0.706742]\n",
      "epoch:7 step:6978 [D loss: 0.687648, acc.: 59.38%] [G loss: 0.737853]\n",
      "epoch:7 step:6979 [D loss: 0.685408, acc.: 57.03%] [G loss: 0.739529]\n",
      "epoch:7 step:6980 [D loss: 0.683089, acc.: 53.12%] [G loss: 0.751994]\n",
      "epoch:7 step:6981 [D loss: 0.707627, acc.: 42.97%] [G loss: 0.773121]\n",
      "epoch:7 step:6982 [D loss: 0.673695, acc.: 55.47%] [G loss: 0.759917]\n",
      "epoch:7 step:6983 [D loss: 0.689455, acc.: 49.22%] [G loss: 0.757916]\n",
      "epoch:7 step:6984 [D loss: 0.679884, acc.: 59.38%] [G loss: 0.762642]\n",
      "epoch:7 step:6985 [D loss: 0.662572, acc.: 64.84%] [G loss: 0.767404]\n",
      "epoch:7 step:6986 [D loss: 0.675632, acc.: 61.72%] [G loss: 0.777964]\n",
      "epoch:7 step:6987 [D loss: 0.665856, acc.: 58.59%] [G loss: 0.756158]\n",
      "epoch:7 step:6988 [D loss: 0.673176, acc.: 58.59%] [G loss: 0.759408]\n",
      "epoch:7 step:6989 [D loss: 0.681940, acc.: 50.78%] [G loss: 0.743603]\n",
      "epoch:7 step:6990 [D loss: 0.706138, acc.: 43.75%] [G loss: 0.760434]\n",
      "epoch:7 step:6991 [D loss: 0.682673, acc.: 44.53%] [G loss: 0.755575]\n",
      "epoch:7 step:6992 [D loss: 0.680145, acc.: 50.00%] [G loss: 0.772274]\n",
      "epoch:7 step:6993 [D loss: 0.681523, acc.: 53.12%] [G loss: 0.780160]\n",
      "epoch:7 step:6994 [D loss: 0.665861, acc.: 58.59%] [G loss: 0.777760]\n",
      "epoch:7 step:6995 [D loss: 0.656135, acc.: 60.94%] [G loss: 0.768120]\n",
      "epoch:7 step:6996 [D loss: 0.707091, acc.: 46.09%] [G loss: 0.785387]\n",
      "epoch:7 step:6997 [D loss: 0.681362, acc.: 57.81%] [G loss: 0.791125]\n",
      "epoch:7 step:6998 [D loss: 0.693176, acc.: 49.22%] [G loss: 0.778594]\n",
      "epoch:7 step:6999 [D loss: 0.685248, acc.: 57.81%] [G loss: 0.778527]\n",
      "epoch:7 step:7000 [D loss: 0.694002, acc.: 50.00%] [G loss: 0.825576]\n",
      "epoch:7 step:7001 [D loss: 0.682307, acc.: 54.69%] [G loss: 0.760796]\n",
      "epoch:7 step:7002 [D loss: 0.676647, acc.: 52.34%] [G loss: 0.780337]\n",
      "epoch:7 step:7003 [D loss: 0.678588, acc.: 57.81%] [G loss: 0.769059]\n",
      "epoch:7 step:7004 [D loss: 0.684255, acc.: 57.81%] [G loss: 0.733380]\n",
      "epoch:7 step:7005 [D loss: 0.704754, acc.: 45.31%] [G loss: 0.737309]\n",
      "epoch:7 step:7006 [D loss: 0.680659, acc.: 51.56%] [G loss: 0.755580]\n",
      "epoch:7 step:7007 [D loss: 0.682710, acc.: 53.91%] [G loss: 0.754587]\n",
      "epoch:7 step:7008 [D loss: 0.675409, acc.: 58.59%] [G loss: 0.786221]\n",
      "epoch:7 step:7009 [D loss: 0.657782, acc.: 67.97%] [G loss: 0.781632]\n",
      "epoch:7 step:7010 [D loss: 0.651853, acc.: 65.62%] [G loss: 0.815974]\n",
      "epoch:7 step:7011 [D loss: 0.681138, acc.: 57.03%] [G loss: 0.815136]\n",
      "epoch:7 step:7012 [D loss: 0.689463, acc.: 47.66%] [G loss: 0.795403]\n",
      "epoch:7 step:7013 [D loss: 0.680207, acc.: 53.91%] [G loss: 0.791605]\n",
      "epoch:7 step:7014 [D loss: 0.700041, acc.: 57.81%] [G loss: 0.822267]\n",
      "epoch:7 step:7015 [D loss: 0.636915, acc.: 58.59%] [G loss: 0.822888]\n",
      "epoch:7 step:7016 [D loss: 0.670989, acc.: 60.16%] [G loss: 0.753148]\n",
      "epoch:7 step:7017 [D loss: 0.752775, acc.: 37.50%] [G loss: 0.738872]\n",
      "epoch:7 step:7018 [D loss: 0.714886, acc.: 46.88%] [G loss: 0.730577]\n",
      "epoch:7 step:7019 [D loss: 0.700897, acc.: 54.69%] [G loss: 0.704058]\n",
      "epoch:7 step:7020 [D loss: 0.729632, acc.: 40.62%] [G loss: 0.727869]\n",
      "epoch:7 step:7021 [D loss: 0.711206, acc.: 46.88%] [G loss: 0.736530]\n",
      "epoch:7 step:7022 [D loss: 0.684322, acc.: 53.12%] [G loss: 0.697535]\n",
      "epoch:7 step:7023 [D loss: 0.732884, acc.: 48.44%] [G loss: 0.724404]\n",
      "epoch:7 step:7024 [D loss: 0.699499, acc.: 49.22%] [G loss: 0.728131]\n",
      "epoch:7 step:7025 [D loss: 0.681590, acc.: 64.84%] [G loss: 0.754325]\n",
      "epoch:7 step:7026 [D loss: 0.694913, acc.: 56.25%] [G loss: 0.720556]\n",
      "epoch:7 step:7027 [D loss: 0.685126, acc.: 56.25%] [G loss: 0.746947]\n",
      "epoch:7 step:7028 [D loss: 0.672871, acc.: 60.94%] [G loss: 0.758417]\n",
      "epoch:7 step:7029 [D loss: 0.643753, acc.: 67.19%] [G loss: 0.761312]\n",
      "epoch:7 step:7030 [D loss: 0.651337, acc.: 65.62%] [G loss: 0.786845]\n",
      "epoch:7 step:7031 [D loss: 0.654398, acc.: 61.72%] [G loss: 0.778036]\n",
      "epoch:7 step:7032 [D loss: 0.723525, acc.: 44.53%] [G loss: 0.782178]\n",
      "epoch:7 step:7033 [D loss: 0.667644, acc.: 54.69%] [G loss: 0.852327]\n",
      "epoch:7 step:7034 [D loss: 0.667281, acc.: 57.03%] [G loss: 0.808447]\n",
      "epoch:7 step:7035 [D loss: 0.708092, acc.: 51.56%] [G loss: 0.741232]\n",
      "epoch:7 step:7036 [D loss: 0.816152, acc.: 40.62%] [G loss: 0.803706]\n",
      "epoch:7 step:7037 [D loss: 0.721503, acc.: 43.75%] [G loss: 0.745429]\n",
      "epoch:7 step:7038 [D loss: 0.720704, acc.: 41.41%] [G loss: 0.770578]\n",
      "epoch:7 step:7039 [D loss: 0.708713, acc.: 49.22%] [G loss: 0.728694]\n",
      "epoch:7 step:7040 [D loss: 0.700477, acc.: 50.78%] [G loss: 0.758548]\n",
      "epoch:7 step:7041 [D loss: 0.704556, acc.: 45.31%] [G loss: 0.740915]\n",
      "epoch:7 step:7042 [D loss: 0.699508, acc.: 44.53%] [G loss: 0.768323]\n",
      "epoch:7 step:7043 [D loss: 0.673918, acc.: 61.72%] [G loss: 0.753492]\n",
      "epoch:7 step:7044 [D loss: 0.680024, acc.: 60.94%] [G loss: 0.715346]\n",
      "epoch:7 step:7045 [D loss: 0.687985, acc.: 53.91%] [G loss: 0.743190]\n",
      "epoch:7 step:7046 [D loss: 0.694500, acc.: 46.09%] [G loss: 0.749205]\n",
      "epoch:7 step:7047 [D loss: 0.681485, acc.: 54.69%] [G loss: 0.755628]\n",
      "epoch:7 step:7048 [D loss: 0.679932, acc.: 61.72%] [G loss: 0.788518]\n",
      "epoch:7 step:7049 [D loss: 0.711574, acc.: 42.19%] [G loss: 0.733019]\n",
      "epoch:7 step:7050 [D loss: 0.662634, acc.: 66.41%] [G loss: 0.738942]\n",
      "epoch:7 step:7051 [D loss: 0.697937, acc.: 47.66%] [G loss: 0.743252]\n",
      "epoch:7 step:7052 [D loss: 0.692353, acc.: 51.56%] [G loss: 0.711497]\n",
      "epoch:7 step:7053 [D loss: 0.692919, acc.: 53.91%] [G loss: 0.703170]\n",
      "epoch:7 step:7054 [D loss: 0.695431, acc.: 54.69%] [G loss: 0.695598]\n",
      "epoch:7 step:7055 [D loss: 0.706012, acc.: 46.09%] [G loss: 0.696164]\n",
      "epoch:7 step:7056 [D loss: 0.688043, acc.: 55.47%] [G loss: 0.701165]\n",
      "epoch:7 step:7057 [D loss: 0.708765, acc.: 44.53%] [G loss: 0.764032]\n",
      "epoch:7 step:7058 [D loss: 0.678227, acc.: 61.72%] [G loss: 0.728366]\n",
      "epoch:7 step:7059 [D loss: 0.686243, acc.: 50.78%] [G loss: 0.726607]\n",
      "epoch:7 step:7060 [D loss: 0.683279, acc.: 57.03%] [G loss: 0.760448]\n",
      "epoch:7 step:7061 [D loss: 0.684705, acc.: 51.56%] [G loss: 0.742126]\n",
      "epoch:7 step:7062 [D loss: 0.692021, acc.: 52.34%] [G loss: 0.791014]\n",
      "epoch:7 step:7063 [D loss: 0.675243, acc.: 55.47%] [G loss: 0.797236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7064 [D loss: 0.655992, acc.: 60.94%] [G loss: 0.764617]\n",
      "epoch:7 step:7065 [D loss: 0.656975, acc.: 60.16%] [G loss: 0.802978]\n",
      "epoch:7 step:7066 [D loss: 0.651161, acc.: 64.84%] [G loss: 0.820938]\n",
      "epoch:7 step:7067 [D loss: 0.660232, acc.: 66.41%] [G loss: 0.747671]\n",
      "epoch:7 step:7068 [D loss: 0.726889, acc.: 44.53%] [G loss: 0.704672]\n",
      "epoch:7 step:7069 [D loss: 0.718378, acc.: 44.53%] [G loss: 0.728433]\n",
      "epoch:7 step:7070 [D loss: 0.733807, acc.: 33.59%] [G loss: 0.731524]\n",
      "epoch:7 step:7071 [D loss: 0.710422, acc.: 40.62%] [G loss: 0.743319]\n",
      "epoch:7 step:7072 [D loss: 0.703030, acc.: 42.97%] [G loss: 0.742796]\n",
      "epoch:7 step:7073 [D loss: 0.682111, acc.: 60.16%] [G loss: 0.730113]\n",
      "epoch:7 step:7074 [D loss: 0.674983, acc.: 53.91%] [G loss: 0.766039]\n",
      "epoch:7 step:7075 [D loss: 0.659131, acc.: 64.06%] [G loss: 0.762102]\n",
      "epoch:7 step:7076 [D loss: 0.664477, acc.: 62.50%] [G loss: 0.752048]\n",
      "epoch:7 step:7077 [D loss: 0.658306, acc.: 61.72%] [G loss: 0.773983]\n",
      "epoch:7 step:7078 [D loss: 0.671209, acc.: 56.25%] [G loss: 0.794890]\n",
      "epoch:7 step:7079 [D loss: 0.667856, acc.: 57.81%] [G loss: 0.760233]\n",
      "epoch:7 step:7080 [D loss: 0.676292, acc.: 60.16%] [G loss: 0.712515]\n",
      "epoch:7 step:7081 [D loss: 0.669212, acc.: 58.59%] [G loss: 0.740733]\n",
      "epoch:7 step:7082 [D loss: 0.721675, acc.: 53.12%] [G loss: 0.723491]\n",
      "epoch:7 step:7083 [D loss: 0.740222, acc.: 34.38%] [G loss: 0.744663]\n",
      "epoch:7 step:7084 [D loss: 0.714360, acc.: 44.53%] [G loss: 0.726741]\n",
      "epoch:7 step:7085 [D loss: 0.701048, acc.: 51.56%] [G loss: 0.733195]\n",
      "epoch:7 step:7086 [D loss: 0.703697, acc.: 42.97%] [G loss: 0.746842]\n",
      "epoch:7 step:7087 [D loss: 0.717550, acc.: 47.66%] [G loss: 0.741325]\n",
      "epoch:7 step:7088 [D loss: 0.697104, acc.: 60.16%] [G loss: 0.752916]\n",
      "epoch:7 step:7089 [D loss: 0.667057, acc.: 67.19%] [G loss: 0.934386]\n",
      "epoch:7 step:7090 [D loss: 0.665416, acc.: 59.38%] [G loss: 0.721385]\n",
      "epoch:7 step:7091 [D loss: 0.716721, acc.: 50.78%] [G loss: 0.749940]\n",
      "epoch:7 step:7092 [D loss: 0.699008, acc.: 50.00%] [G loss: 0.717606]\n",
      "epoch:7 step:7093 [D loss: 0.681402, acc.: 58.59%] [G loss: 0.711114]\n",
      "epoch:7 step:7094 [D loss: 0.705089, acc.: 45.31%] [G loss: 0.704697]\n",
      "epoch:7 step:7095 [D loss: 0.719977, acc.: 41.41%] [G loss: 0.693216]\n",
      "epoch:7 step:7096 [D loss: 0.701527, acc.: 50.00%] [G loss: 0.703138]\n",
      "epoch:7 step:7097 [D loss: 0.703536, acc.: 47.66%] [G loss: 0.697888]\n",
      "epoch:7 step:7098 [D loss: 0.698900, acc.: 51.56%] [G loss: 0.719921]\n",
      "epoch:7 step:7099 [D loss: 0.698099, acc.: 44.53%] [G loss: 0.696243]\n",
      "epoch:7 step:7100 [D loss: 0.681721, acc.: 60.16%] [G loss: 0.724960]\n",
      "epoch:7 step:7101 [D loss: 0.734916, acc.: 37.50%] [G loss: 0.710246]\n",
      "epoch:7 step:7102 [D loss: 0.631829, acc.: 56.25%] [G loss: 0.667583]\n",
      "epoch:7 step:7103 [D loss: 0.705338, acc.: 54.69%] [G loss: 0.707514]\n",
      "epoch:7 step:7104 [D loss: 0.704657, acc.: 44.53%] [G loss: 0.718596]\n",
      "epoch:7 step:7105 [D loss: 0.705098, acc.: 51.56%] [G loss: 0.697991]\n",
      "epoch:7 step:7106 [D loss: 0.688521, acc.: 60.94%] [G loss: 0.729274]\n",
      "epoch:7 step:7107 [D loss: 0.697329, acc.: 52.34%] [G loss: 0.724585]\n",
      "epoch:7 step:7108 [D loss: 0.688361, acc.: 54.69%] [G loss: 0.733319]\n",
      "epoch:7 step:7109 [D loss: 0.584814, acc.: 60.94%] [G loss: 0.697917]\n",
      "epoch:7 step:7110 [D loss: 0.679859, acc.: 55.47%] [G loss: 0.706758]\n",
      "epoch:7 step:7111 [D loss: 0.684460, acc.: 53.12%] [G loss: 0.708248]\n",
      "epoch:7 step:7112 [D loss: 0.699771, acc.: 52.34%] [G loss: 0.699980]\n",
      "epoch:7 step:7113 [D loss: 0.680975, acc.: 56.25%] [G loss: 0.712173]\n",
      "epoch:7 step:7114 [D loss: 0.695819, acc.: 54.69%] [G loss: 0.728041]\n",
      "epoch:7 step:7115 [D loss: 0.673458, acc.: 62.50%] [G loss: 0.739190]\n",
      "epoch:7 step:7116 [D loss: 0.681249, acc.: 58.59%] [G loss: 0.717249]\n",
      "epoch:7 step:7117 [D loss: 0.691343, acc.: 50.78%] [G loss: 0.734743]\n",
      "epoch:7 step:7118 [D loss: 0.694745, acc.: 50.00%] [G loss: 0.731607]\n",
      "epoch:7 step:7119 [D loss: 0.685649, acc.: 52.34%] [G loss: 0.733507]\n",
      "epoch:7 step:7120 [D loss: 0.697330, acc.: 53.12%] [G loss: 0.723693]\n",
      "epoch:7 step:7121 [D loss: 0.676860, acc.: 53.91%] [G loss: 0.776154]\n",
      "epoch:7 step:7122 [D loss: 0.696532, acc.: 53.91%] [G loss: 0.781818]\n",
      "epoch:7 step:7123 [D loss: 0.693547, acc.: 51.56%] [G loss: 0.736070]\n",
      "epoch:7 step:7124 [D loss: 0.688631, acc.: 51.56%] [G loss: 0.766942]\n",
      "epoch:7 step:7125 [D loss: 0.664144, acc.: 63.28%] [G loss: 0.779029]\n",
      "epoch:7 step:7126 [D loss: 0.650452, acc.: 66.41%] [G loss: 0.817724]\n",
      "epoch:7 step:7127 [D loss: 0.662409, acc.: 64.06%] [G loss: 0.770002]\n",
      "epoch:7 step:7128 [D loss: 0.703987, acc.: 46.88%] [G loss: 0.750123]\n",
      "epoch:7 step:7129 [D loss: 0.663219, acc.: 62.50%] [G loss: 0.794040]\n",
      "epoch:7 step:7130 [D loss: 0.704784, acc.: 50.00%] [G loss: 0.750546]\n",
      "epoch:7 step:7131 [D loss: 0.684613, acc.: 55.47%] [G loss: 0.770321]\n",
      "epoch:7 step:7132 [D loss: 0.666259, acc.: 60.94%] [G loss: 0.727425]\n",
      "epoch:7 step:7133 [D loss: 0.671726, acc.: 58.59%] [G loss: 0.835911]\n",
      "epoch:7 step:7134 [D loss: 0.674172, acc.: 60.16%] [G loss: 0.767553]\n",
      "epoch:7 step:7135 [D loss: 0.677300, acc.: 57.81%] [G loss: 0.783188]\n",
      "epoch:7 step:7136 [D loss: 0.707863, acc.: 48.44%] [G loss: 0.726383]\n",
      "epoch:7 step:7137 [D loss: 0.703520, acc.: 48.44%] [G loss: 0.654367]\n",
      "epoch:7 step:7138 [D loss: 0.703483, acc.: 57.03%] [G loss: 0.728687]\n",
      "epoch:7 step:7139 [D loss: 0.692543, acc.: 52.34%] [G loss: 0.749376]\n",
      "epoch:7 step:7140 [D loss: 0.703655, acc.: 46.09%] [G loss: 0.737300]\n",
      "epoch:7 step:7141 [D loss: 0.687165, acc.: 59.38%] [G loss: 0.735984]\n",
      "epoch:7 step:7142 [D loss: 0.683185, acc.: 53.91%] [G loss: 0.739222]\n",
      "epoch:7 step:7143 [D loss: 0.710736, acc.: 50.78%] [G loss: 0.773021]\n",
      "epoch:7 step:7144 [D loss: 0.648240, acc.: 63.28%] [G loss: 0.804203]\n",
      "epoch:7 step:7145 [D loss: 0.640740, acc.: 67.19%] [G loss: 0.816751]\n",
      "epoch:7 step:7146 [D loss: 0.698327, acc.: 49.22%] [G loss: 0.814886]\n",
      "epoch:7 step:7147 [D loss: 0.653714, acc.: 61.72%] [G loss: 0.815390]\n",
      "epoch:7 step:7148 [D loss: 0.691419, acc.: 51.56%] [G loss: 0.786992]\n",
      "epoch:7 step:7149 [D loss: 0.697840, acc.: 49.22%] [G loss: 0.721403]\n",
      "epoch:7 step:7150 [D loss: 0.706900, acc.: 50.78%] [G loss: 0.741019]\n",
      "epoch:7 step:7151 [D loss: 0.690049, acc.: 59.38%] [G loss: 0.753248]\n",
      "epoch:7 step:7152 [D loss: 0.704326, acc.: 50.00%] [G loss: 0.762270]\n",
      "epoch:7 step:7153 [D loss: 0.710130, acc.: 46.09%] [G loss: 0.766502]\n",
      "epoch:7 step:7154 [D loss: 0.691250, acc.: 54.69%] [G loss: 0.769874]\n",
      "epoch:7 step:7155 [D loss: 0.605597, acc.: 71.09%] [G loss: 0.789945]\n",
      "epoch:7 step:7156 [D loss: 0.668872, acc.: 58.59%] [G loss: 0.812118]\n",
      "epoch:7 step:7157 [D loss: 0.669797, acc.: 62.50%] [G loss: 0.892581]\n",
      "epoch:7 step:7158 [D loss: 0.691545, acc.: 57.03%] [G loss: 0.877556]\n",
      "epoch:7 step:7159 [D loss: 0.732544, acc.: 42.97%] [G loss: 0.806628]\n",
      "epoch:7 step:7160 [D loss: 0.722443, acc.: 45.31%] [G loss: 0.754482]\n",
      "epoch:7 step:7161 [D loss: 0.700345, acc.: 51.56%] [G loss: 0.766774]\n",
      "epoch:7 step:7162 [D loss: 0.708413, acc.: 48.44%] [G loss: 0.747467]\n",
      "epoch:7 step:7163 [D loss: 0.574031, acc.: 60.94%] [G loss: 0.732649]\n",
      "epoch:7 step:7164 [D loss: 0.703065, acc.: 57.81%] [G loss: 0.712869]\n",
      "epoch:7 step:7165 [D loss: 0.694139, acc.: 57.03%] [G loss: 0.723064]\n",
      "epoch:7 step:7166 [D loss: 0.715137, acc.: 42.97%] [G loss: 0.727913]\n",
      "epoch:7 step:7167 [D loss: 0.713435, acc.: 51.56%] [G loss: 0.714969]\n",
      "epoch:7 step:7168 [D loss: 0.683376, acc.: 54.69%] [G loss: 0.731789]\n",
      "epoch:7 step:7169 [D loss: 0.689218, acc.: 50.00%] [G loss: 0.692914]\n",
      "epoch:7 step:7170 [D loss: 0.703313, acc.: 42.19%] [G loss: 0.737381]\n",
      "epoch:7 step:7171 [D loss: 0.700332, acc.: 51.56%] [G loss: 0.708342]\n",
      "epoch:7 step:7172 [D loss: 0.699502, acc.: 50.78%] [G loss: 0.706365]\n",
      "epoch:7 step:7173 [D loss: 0.709986, acc.: 44.53%] [G loss: 0.738066]\n",
      "epoch:7 step:7174 [D loss: 0.697081, acc.: 48.44%] [G loss: 0.723403]\n",
      "epoch:7 step:7175 [D loss: 0.707820, acc.: 44.53%] [G loss: 0.718758]\n",
      "epoch:7 step:7176 [D loss: 0.710376, acc.: 44.53%] [G loss: 0.718282]\n",
      "epoch:7 step:7177 [D loss: 0.685812, acc.: 56.25%] [G loss: 0.649953]\n",
      "epoch:7 step:7178 [D loss: 0.675290, acc.: 57.03%] [G loss: 0.727516]\n",
      "epoch:7 step:7179 [D loss: 0.685266, acc.: 51.56%] [G loss: 0.737304]\n",
      "epoch:7 step:7180 [D loss: 0.685566, acc.: 56.25%] [G loss: 0.750173]\n",
      "epoch:7 step:7181 [D loss: 0.681427, acc.: 52.34%] [G loss: 0.797936]\n",
      "epoch:7 step:7182 [D loss: 0.671549, acc.: 60.16%] [G loss: 0.814948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7183 [D loss: 0.855079, acc.: 36.72%] [G loss: 0.989663]\n",
      "epoch:7 step:7184 [D loss: 0.669934, acc.: 53.91%] [G loss: 0.985434]\n",
      "epoch:7 step:7185 [D loss: 0.715787, acc.: 53.12%] [G loss: 0.944071]\n",
      "epoch:7 step:7186 [D loss: 0.691724, acc.: 52.34%] [G loss: 2.471251]\n",
      "epoch:7 step:7187 [D loss: 0.723874, acc.: 37.50%] [G loss: 0.732718]\n",
      "epoch:7 step:7188 [D loss: 0.745417, acc.: 32.81%] [G loss: 0.722848]\n",
      "epoch:7 step:7189 [D loss: 0.727899, acc.: 34.38%] [G loss: 0.771608]\n",
      "epoch:7 step:7190 [D loss: 0.689804, acc.: 43.75%] [G loss: 0.748915]\n",
      "epoch:7 step:7191 [D loss: 0.721484, acc.: 39.06%] [G loss: 0.767724]\n",
      "epoch:7 step:7192 [D loss: 0.700605, acc.: 56.25%] [G loss: 0.768497]\n",
      "epoch:7 step:7193 [D loss: 0.688638, acc.: 62.50%] [G loss: 0.764880]\n",
      "epoch:7 step:7194 [D loss: 0.686338, acc.: 62.50%] [G loss: 0.796914]\n",
      "epoch:7 step:7195 [D loss: 0.678578, acc.: 65.62%] [G loss: 0.790587]\n",
      "epoch:7 step:7196 [D loss: 0.659569, acc.: 71.09%] [G loss: 0.825358]\n",
      "epoch:7 step:7197 [D loss: 0.661670, acc.: 69.53%] [G loss: 0.830391]\n",
      "epoch:7 step:7198 [D loss: 0.664471, acc.: 63.28%] [G loss: 0.835104]\n",
      "epoch:7 step:7199 [D loss: 0.656992, acc.: 60.94%] [G loss: 0.852415]\n",
      "epoch:7 step:7200 [D loss: 0.719676, acc.: 52.34%] [G loss: 0.745345]\n",
      "epoch:7 step:7201 [D loss: 0.725561, acc.: 48.44%] [G loss: 0.733983]\n",
      "epoch:7 step:7202 [D loss: 0.683150, acc.: 59.38%] [G loss: 0.711588]\n",
      "epoch:7 step:7203 [D loss: 0.664559, acc.: 60.16%] [G loss: 0.738660]\n",
      "epoch:7 step:7204 [D loss: 0.686624, acc.: 53.12%] [G loss: 0.829012]\n",
      "epoch:7 step:7205 [D loss: 0.668216, acc.: 53.91%] [G loss: 0.804293]\n",
      "epoch:7 step:7206 [D loss: 0.679322, acc.: 58.59%] [G loss: 0.841229]\n",
      "epoch:7 step:7207 [D loss: 0.624178, acc.: 71.09%] [G loss: 0.836881]\n",
      "epoch:7 step:7208 [D loss: 0.657561, acc.: 57.81%] [G loss: 0.745352]\n",
      "epoch:7 step:7209 [D loss: 0.594686, acc.: 76.56%] [G loss: 0.834684]\n",
      "epoch:7 step:7210 [D loss: 0.647201, acc.: 53.91%] [G loss: 0.872244]\n",
      "epoch:7 step:7211 [D loss: 0.630160, acc.: 67.97%] [G loss: 0.749370]\n",
      "epoch:7 step:7212 [D loss: 0.693273, acc.: 47.66%] [G loss: 0.878263]\n",
      "epoch:7 step:7213 [D loss: 0.752403, acc.: 39.84%] [G loss: 0.685353]\n",
      "epoch:7 step:7214 [D loss: 0.672136, acc.: 60.16%] [G loss: 0.686304]\n",
      "epoch:7 step:7215 [D loss: 0.702252, acc.: 52.34%] [G loss: 0.730440]\n",
      "epoch:7 step:7216 [D loss: 0.734415, acc.: 37.50%] [G loss: 0.680235]\n",
      "epoch:7 step:7217 [D loss: 0.698926, acc.: 49.22%] [G loss: 0.718808]\n",
      "epoch:7 step:7218 [D loss: 0.677332, acc.: 59.38%] [G loss: 0.701002]\n",
      "epoch:7 step:7219 [D loss: 0.677670, acc.: 55.47%] [G loss: 0.720818]\n",
      "epoch:7 step:7220 [D loss: 0.693048, acc.: 49.22%] [G loss: 0.719469]\n",
      "epoch:7 step:7221 [D loss: 0.712639, acc.: 40.62%] [G loss: 0.696355]\n",
      "epoch:7 step:7222 [D loss: 0.765922, acc.: 25.00%] [G loss: 0.739815]\n",
      "epoch:7 step:7223 [D loss: 0.711014, acc.: 39.06%] [G loss: 0.711690]\n",
      "epoch:7 step:7224 [D loss: 0.670978, acc.: 57.81%] [G loss: 0.731760]\n",
      "epoch:7 step:7225 [D loss: 0.665770, acc.: 60.94%] [G loss: 0.735319]\n",
      "epoch:7 step:7226 [D loss: 0.682638, acc.: 53.91%] [G loss: 0.744847]\n",
      "epoch:7 step:7227 [D loss: 0.688371, acc.: 51.56%] [G loss: 0.726770]\n",
      "epoch:7 step:7228 [D loss: 0.673495, acc.: 55.47%] [G loss: 0.766464]\n",
      "epoch:7 step:7229 [D loss: 0.675029, acc.: 58.59%] [G loss: 0.722038]\n",
      "epoch:7 step:7230 [D loss: 0.659857, acc.: 63.28%] [G loss: 0.743437]\n",
      "epoch:7 step:7231 [D loss: 0.651435, acc.: 57.03%] [G loss: 0.755494]\n",
      "epoch:7 step:7232 [D loss: 0.648950, acc.: 53.91%] [G loss: 0.773152]\n",
      "epoch:7 step:7233 [D loss: 0.674711, acc.: 50.00%] [G loss: 0.803901]\n",
      "epoch:7 step:7234 [D loss: 0.708283, acc.: 46.09%] [G loss: 0.721821]\n",
      "epoch:7 step:7235 [D loss: 0.699521, acc.: 42.19%] [G loss: 0.709103]\n",
      "epoch:7 step:7236 [D loss: 0.697885, acc.: 45.31%] [G loss: 0.712336]\n",
      "epoch:7 step:7237 [D loss: 0.714123, acc.: 45.31%] [G loss: 0.714111]\n",
      "epoch:7 step:7238 [D loss: 0.724139, acc.: 46.88%] [G loss: 0.702569]\n",
      "epoch:7 step:7239 [D loss: 0.670424, acc.: 57.03%] [G loss: 0.737195]\n",
      "epoch:7 step:7240 [D loss: 0.716886, acc.: 50.00%] [G loss: 0.715055]\n",
      "epoch:7 step:7241 [D loss: 0.687499, acc.: 56.25%] [G loss: 0.729538]\n",
      "epoch:7 step:7242 [D loss: 0.685686, acc.: 53.91%] [G loss: 0.737319]\n",
      "epoch:7 step:7243 [D loss: 0.696375, acc.: 49.22%] [G loss: 0.743591]\n",
      "epoch:7 step:7244 [D loss: 0.676060, acc.: 52.34%] [G loss: 0.757620]\n",
      "epoch:7 step:7245 [D loss: 0.687008, acc.: 55.47%] [G loss: 0.718341]\n",
      "epoch:7 step:7246 [D loss: 0.680544, acc.: 50.78%] [G loss: 0.691017]\n",
      "epoch:7 step:7247 [D loss: 0.718054, acc.: 50.00%] [G loss: 0.727867]\n",
      "epoch:7 step:7248 [D loss: 0.685134, acc.: 57.81%] [G loss: 0.736417]\n",
      "epoch:7 step:7249 [D loss: 0.688698, acc.: 58.59%] [G loss: 0.749715]\n",
      "epoch:7 step:7250 [D loss: 0.698577, acc.: 47.66%] [G loss: 0.715053]\n",
      "epoch:7 step:7251 [D loss: 0.674188, acc.: 58.59%] [G loss: 0.752974]\n",
      "epoch:7 step:7252 [D loss: 0.678665, acc.: 61.72%] [G loss: 0.727901]\n",
      "epoch:7 step:7253 [D loss: 0.660951, acc.: 61.72%] [G loss: 0.770250]\n",
      "epoch:7 step:7254 [D loss: 0.690747, acc.: 53.12%] [G loss: 0.752232]\n",
      "epoch:7 step:7255 [D loss: 0.696837, acc.: 50.00%] [G loss: 0.753159]\n",
      "epoch:7 step:7256 [D loss: 0.691380, acc.: 53.12%] [G loss: 0.779299]\n",
      "epoch:7 step:7257 [D loss: 0.698752, acc.: 51.56%] [G loss: 0.753776]\n",
      "epoch:7 step:7258 [D loss: 0.690022, acc.: 57.03%] [G loss: 0.766668]\n",
      "epoch:7 step:7259 [D loss: 0.697009, acc.: 48.44%] [G loss: 0.746065]\n",
      "epoch:7 step:7260 [D loss: 0.683699, acc.: 54.69%] [G loss: 0.777868]\n",
      "epoch:7 step:7261 [D loss: 0.689207, acc.: 55.47%] [G loss: 0.785130]\n",
      "epoch:7 step:7262 [D loss: 0.685132, acc.: 55.47%] [G loss: 0.770496]\n",
      "epoch:7 step:7263 [D loss: 0.679556, acc.: 50.78%] [G loss: 0.773268]\n",
      "epoch:7 step:7264 [D loss: 0.680516, acc.: 55.47%] [G loss: 0.778119]\n",
      "epoch:7 step:7265 [D loss: 0.680490, acc.: 56.25%] [G loss: 0.791395]\n",
      "epoch:7 step:7266 [D loss: 0.671363, acc.: 58.59%] [G loss: 0.768622]\n",
      "epoch:7 step:7267 [D loss: 0.639932, acc.: 68.75%] [G loss: 0.725727]\n",
      "epoch:7 step:7268 [D loss: 0.679602, acc.: 58.59%] [G loss: 0.752078]\n",
      "epoch:7 step:7269 [D loss: 0.749149, acc.: 37.50%] [G loss: 0.737846]\n",
      "epoch:7 step:7270 [D loss: 0.727660, acc.: 38.28%] [G loss: 0.715963]\n",
      "epoch:7 step:7271 [D loss: 0.672848, acc.: 61.72%] [G loss: 0.698689]\n",
      "epoch:7 step:7272 [D loss: 0.682910, acc.: 58.59%] [G loss: 0.732643]\n",
      "epoch:7 step:7273 [D loss: 0.672176, acc.: 59.38%] [G loss: 0.737958]\n",
      "epoch:7 step:7274 [D loss: 0.699830, acc.: 48.44%] [G loss: 0.766171]\n",
      "epoch:7 step:7275 [D loss: 0.683010, acc.: 51.56%] [G loss: 0.751107]\n",
      "epoch:7 step:7276 [D loss: 0.689741, acc.: 55.47%] [G loss: 0.724428]\n",
      "epoch:7 step:7277 [D loss: 0.674058, acc.: 54.69%] [G loss: 0.716472]\n",
      "epoch:7 step:7278 [D loss: 0.667276, acc.: 52.34%] [G loss: 0.739156]\n",
      "epoch:7 step:7279 [D loss: 0.677504, acc.: 54.69%] [G loss: 0.769871]\n",
      "epoch:7 step:7280 [D loss: 0.652710, acc.: 54.69%] [G loss: 0.764838]\n",
      "epoch:7 step:7281 [D loss: 0.677049, acc.: 59.38%] [G loss: 0.822722]\n",
      "epoch:7 step:7282 [D loss: 0.676957, acc.: 61.72%] [G loss: 0.806481]\n",
      "epoch:7 step:7283 [D loss: 0.709787, acc.: 46.88%] [G loss: 0.756137]\n",
      "epoch:7 step:7284 [D loss: 0.680438, acc.: 59.38%] [G loss: 0.830410]\n",
      "epoch:7 step:7285 [D loss: 0.679394, acc.: 59.38%] [G loss: 0.777937]\n",
      "epoch:7 step:7286 [D loss: 0.737578, acc.: 42.19%] [G loss: 0.769357]\n",
      "epoch:7 step:7287 [D loss: 0.736586, acc.: 36.72%] [G loss: 0.759322]\n",
      "epoch:7 step:7288 [D loss: 0.693060, acc.: 54.69%] [G loss: 0.763860]\n",
      "epoch:7 step:7289 [D loss: 0.690180, acc.: 50.00%] [G loss: 0.781318]\n",
      "epoch:7 step:7290 [D loss: 0.695825, acc.: 52.34%] [G loss: 0.773605]\n",
      "epoch:7 step:7291 [D loss: 0.681648, acc.: 60.94%] [G loss: 0.751301]\n",
      "epoch:7 step:7292 [D loss: 0.685060, acc.: 51.56%] [G loss: 0.751731]\n",
      "epoch:7 step:7293 [D loss: 0.702308, acc.: 52.34%] [G loss: 0.733400]\n",
      "epoch:7 step:7294 [D loss: 0.713820, acc.: 49.22%] [G loss: 0.720544]\n",
      "epoch:7 step:7295 [D loss: 0.727137, acc.: 33.59%] [G loss: 0.721492]\n",
      "epoch:7 step:7296 [D loss: 0.713220, acc.: 43.75%] [G loss: 0.712846]\n",
      "epoch:7 step:7297 [D loss: 0.717853, acc.: 42.97%] [G loss: 0.711862]\n",
      "epoch:7 step:7298 [D loss: 0.723613, acc.: 35.16%] [G loss: 0.709374]\n",
      "epoch:7 step:7299 [D loss: 0.698173, acc.: 47.66%] [G loss: 0.717124]\n",
      "epoch:7 step:7300 [D loss: 0.690598, acc.: 56.25%] [G loss: 0.721671]\n",
      "epoch:7 step:7301 [D loss: 0.691630, acc.: 53.12%] [G loss: 0.726845]\n",
      "epoch:7 step:7302 [D loss: 0.684583, acc.: 55.47%] [G loss: 0.729564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7303 [D loss: 0.678814, acc.: 58.59%] [G loss: 0.730231]\n",
      "epoch:7 step:7304 [D loss: 0.687198, acc.: 55.47%] [G loss: 0.721834]\n",
      "epoch:7 step:7305 [D loss: 0.683388, acc.: 52.34%] [G loss: 0.732054]\n",
      "epoch:7 step:7306 [D loss: 0.666867, acc.: 62.50%] [G loss: 0.706088]\n",
      "epoch:7 step:7307 [D loss: 0.694178, acc.: 47.66%] [G loss: 0.739770]\n",
      "epoch:7 step:7308 [D loss: 0.676964, acc.: 53.91%] [G loss: 0.734964]\n",
      "epoch:7 step:7309 [D loss: 0.668559, acc.: 57.03%] [G loss: 0.739120]\n",
      "epoch:7 step:7310 [D loss: 0.688533, acc.: 53.91%] [G loss: 0.731620]\n",
      "epoch:7 step:7311 [D loss: 0.694768, acc.: 46.09%] [G loss: 0.736790]\n",
      "epoch:7 step:7312 [D loss: 0.689871, acc.: 52.34%] [G loss: 0.735504]\n",
      "epoch:7 step:7313 [D loss: 0.685195, acc.: 53.91%] [G loss: 0.698697]\n",
      "epoch:7 step:7314 [D loss: 0.679546, acc.: 56.25%] [G loss: 0.711920]\n",
      "epoch:7 step:7315 [D loss: 0.679959, acc.: 53.91%] [G loss: 0.705403]\n",
      "epoch:7 step:7316 [D loss: 0.675043, acc.: 57.81%] [G loss: 0.711573]\n",
      "epoch:7 step:7317 [D loss: 0.687479, acc.: 53.12%] [G loss: 0.689093]\n",
      "epoch:7 step:7318 [D loss: 0.711811, acc.: 45.31%] [G loss: 0.714241]\n",
      "epoch:7 step:7319 [D loss: 0.701200, acc.: 48.44%] [G loss: 0.715297]\n",
      "epoch:7 step:7320 [D loss: 0.687675, acc.: 53.91%] [G loss: 0.713965]\n",
      "epoch:7 step:7321 [D loss: 0.680474, acc.: 55.47%] [G loss: 0.700021]\n",
      "epoch:7 step:7322 [D loss: 0.764351, acc.: 54.69%] [G loss: 0.697459]\n",
      "epoch:7 step:7323 [D loss: 0.688545, acc.: 54.69%] [G loss: 0.742719]\n",
      "epoch:7 step:7324 [D loss: 0.716102, acc.: 47.66%] [G loss: 0.741386]\n",
      "epoch:7 step:7325 [D loss: 0.711480, acc.: 48.44%] [G loss: 0.747962]\n",
      "epoch:7 step:7326 [D loss: 0.699966, acc.: 48.44%] [G loss: 0.752271]\n",
      "epoch:7 step:7327 [D loss: 0.711711, acc.: 41.41%] [G loss: 0.724510]\n",
      "epoch:7 step:7328 [D loss: 0.690525, acc.: 61.72%] [G loss: 0.738496]\n",
      "epoch:7 step:7329 [D loss: 0.690380, acc.: 55.47%] [G loss: 0.738662]\n",
      "epoch:7 step:7330 [D loss: 0.703494, acc.: 47.66%] [G loss: 0.730052]\n",
      "epoch:7 step:7331 [D loss: 0.696323, acc.: 47.66%] [G loss: 0.732740]\n",
      "epoch:7 step:7332 [D loss: 0.683608, acc.: 57.81%] [G loss: 0.733590]\n",
      "epoch:7 step:7333 [D loss: 0.685360, acc.: 55.47%] [G loss: 0.731871]\n",
      "epoch:7 step:7334 [D loss: 0.672631, acc.: 58.59%] [G loss: 0.753555]\n",
      "epoch:7 step:7335 [D loss: 0.706470, acc.: 43.75%] [G loss: 0.739238]\n",
      "epoch:7 step:7336 [D loss: 0.693085, acc.: 47.66%] [G loss: 0.732204]\n",
      "epoch:7 step:7337 [D loss: 0.708869, acc.: 42.97%] [G loss: 0.733705]\n",
      "epoch:7 step:7338 [D loss: 0.703324, acc.: 49.22%] [G loss: 0.758435]\n",
      "epoch:7 step:7339 [D loss: 0.687484, acc.: 53.91%] [G loss: 0.718733]\n",
      "epoch:7 step:7340 [D loss: 0.687722, acc.: 54.69%] [G loss: 0.730490]\n",
      "epoch:7 step:7341 [D loss: 0.678516, acc.: 60.16%] [G loss: 0.749323]\n",
      "epoch:7 step:7342 [D loss: 0.691515, acc.: 54.69%] [G loss: 0.729622]\n",
      "epoch:7 step:7343 [D loss: 0.708584, acc.: 46.09%] [G loss: 0.717828]\n",
      "epoch:7 step:7344 [D loss: 0.696888, acc.: 48.44%] [G loss: 0.732458]\n",
      "epoch:7 step:7345 [D loss: 0.699352, acc.: 46.88%] [G loss: 0.726941]\n",
      "epoch:7 step:7346 [D loss: 0.713025, acc.: 39.06%] [G loss: 0.720764]\n",
      "epoch:7 step:7347 [D loss: 0.695896, acc.: 43.75%] [G loss: 0.715807]\n",
      "epoch:7 step:7348 [D loss: 0.706650, acc.: 45.31%] [G loss: 0.713030]\n",
      "epoch:7 step:7349 [D loss: 0.704228, acc.: 49.22%] [G loss: 0.714212]\n",
      "epoch:7 step:7350 [D loss: 0.689233, acc.: 57.81%] [G loss: 0.725455]\n",
      "epoch:7 step:7351 [D loss: 0.672987, acc.: 59.38%] [G loss: 0.731968]\n",
      "epoch:7 step:7352 [D loss: 0.684538, acc.: 59.38%] [G loss: 0.712101]\n",
      "epoch:7 step:7353 [D loss: 0.688305, acc.: 50.78%] [G loss: 0.714694]\n",
      "epoch:7 step:7354 [D loss: 0.680842, acc.: 57.03%] [G loss: 0.702187]\n",
      "epoch:7 step:7355 [D loss: 0.699033, acc.: 48.44%] [G loss: 0.695145]\n",
      "epoch:7 step:7356 [D loss: 0.701671, acc.: 47.66%] [G loss: 0.694741]\n",
      "epoch:7 step:7357 [D loss: 0.687327, acc.: 53.91%] [G loss: 0.713065]\n",
      "epoch:7 step:7358 [D loss: 0.692809, acc.: 50.78%] [G loss: 0.712210]\n",
      "epoch:7 step:7359 [D loss: 0.718214, acc.: 39.84%] [G loss: 0.707335]\n",
      "epoch:7 step:7360 [D loss: 0.698279, acc.: 46.88%] [G loss: 0.702753]\n",
      "epoch:7 step:7361 [D loss: 0.642689, acc.: 50.78%] [G loss: 0.730411]\n",
      "epoch:7 step:7362 [D loss: 0.690920, acc.: 64.84%] [G loss: 0.708038]\n",
      "epoch:7 step:7363 [D loss: 0.692893, acc.: 55.47%] [G loss: 0.736562]\n",
      "epoch:7 step:7364 [D loss: 0.706997, acc.: 46.09%] [G loss: 0.710962]\n",
      "epoch:7 step:7365 [D loss: 0.694472, acc.: 53.91%] [G loss: 0.716406]\n",
      "epoch:7 step:7366 [D loss: 0.678446, acc.: 60.16%] [G loss: 0.738197]\n",
      "epoch:7 step:7367 [D loss: 0.682365, acc.: 59.38%] [G loss: 0.735047]\n",
      "epoch:7 step:7368 [D loss: 0.693931, acc.: 52.34%] [G loss: 0.732588]\n",
      "epoch:7 step:7369 [D loss: 0.670850, acc.: 59.38%] [G loss: 0.768605]\n",
      "epoch:7 step:7370 [D loss: 0.686177, acc.: 60.94%] [G loss: 0.769747]\n",
      "epoch:7 step:7371 [D loss: 0.692674, acc.: 53.12%] [G loss: 0.725981]\n",
      "epoch:7 step:7372 [D loss: 0.683058, acc.: 57.03%] [G loss: 0.738270]\n",
      "epoch:7 step:7373 [D loss: 0.689505, acc.: 52.34%] [G loss: 0.753328]\n",
      "epoch:7 step:7374 [D loss: 0.679622, acc.: 62.50%] [G loss: 0.756098]\n",
      "epoch:7 step:7375 [D loss: 0.677530, acc.: 51.56%] [G loss: 0.745089]\n",
      "epoch:7 step:7376 [D loss: 0.688429, acc.: 56.25%] [G loss: 0.772849]\n",
      "epoch:7 step:7377 [D loss: 0.692228, acc.: 50.78%] [G loss: 0.722856]\n",
      "epoch:7 step:7378 [D loss: 0.709644, acc.: 45.31%] [G loss: 0.726486]\n",
      "epoch:7 step:7379 [D loss: 0.733845, acc.: 37.50%] [G loss: 0.699809]\n",
      "epoch:7 step:7380 [D loss: 0.713765, acc.: 42.19%] [G loss: 0.702323]\n",
      "epoch:7 step:7381 [D loss: 0.681404, acc.: 57.81%] [G loss: 0.715886]\n",
      "epoch:7 step:7382 [D loss: 0.681479, acc.: 56.25%] [G loss: 0.749711]\n",
      "epoch:7 step:7383 [D loss: 0.682487, acc.: 58.59%] [G loss: 0.731571]\n",
      "epoch:7 step:7384 [D loss: 0.676292, acc.: 57.81%] [G loss: 0.741658]\n",
      "epoch:7 step:7385 [D loss: 0.688417, acc.: 47.66%] [G loss: 0.740526]\n",
      "epoch:7 step:7386 [D loss: 0.715132, acc.: 39.84%] [G loss: 0.740055]\n",
      "epoch:7 step:7387 [D loss: 0.713479, acc.: 46.09%] [G loss: 0.721255]\n",
      "epoch:7 step:7388 [D loss: 0.699691, acc.: 45.31%] [G loss: 0.717438]\n",
      "epoch:7 step:7389 [D loss: 0.681951, acc.: 53.12%] [G loss: 0.711972]\n",
      "epoch:7 step:7390 [D loss: 0.706529, acc.: 47.66%] [G loss: 0.701756]\n",
      "epoch:7 step:7391 [D loss: 0.708973, acc.: 46.09%] [G loss: 0.705902]\n",
      "epoch:7 step:7392 [D loss: 0.684164, acc.: 54.69%] [G loss: 0.711249]\n",
      "epoch:7 step:7393 [D loss: 0.692581, acc.: 53.12%] [G loss: 0.686168]\n",
      "epoch:7 step:7394 [D loss: 0.680616, acc.: 60.16%] [G loss: 0.656681]\n",
      "epoch:7 step:7395 [D loss: 0.686921, acc.: 56.25%] [G loss: 0.685353]\n",
      "epoch:7 step:7396 [D loss: 0.702978, acc.: 51.56%] [G loss: 0.730575]\n",
      "epoch:7 step:7397 [D loss: 0.674316, acc.: 57.81%] [G loss: 0.687640]\n",
      "epoch:7 step:7398 [D loss: 0.673662, acc.: 57.03%] [G loss: 0.701628]\n",
      "epoch:7 step:7399 [D loss: 0.677869, acc.: 55.47%] [G loss: 0.658967]\n",
      "epoch:7 step:7400 [D loss: 0.694534, acc.: 51.56%] [G loss: 0.735867]\n",
      "epoch:7 step:7401 [D loss: 0.681445, acc.: 51.56%] [G loss: 0.663748]\n",
      "epoch:7 step:7402 [D loss: 0.730371, acc.: 39.06%] [G loss: 0.698526]\n",
      "epoch:7 step:7403 [D loss: 0.810869, acc.: 42.19%] [G loss: 0.760698]\n",
      "epoch:7 step:7404 [D loss: 0.717504, acc.: 49.22%] [G loss: 0.766087]\n",
      "epoch:7 step:7405 [D loss: 0.685114, acc.: 56.25%] [G loss: 0.784257]\n",
      "epoch:7 step:7406 [D loss: 0.690924, acc.: 53.91%] [G loss: 0.757372]\n",
      "epoch:7 step:7407 [D loss: 0.708009, acc.: 48.44%] [G loss: 0.746765]\n",
      "epoch:7 step:7408 [D loss: 0.704495, acc.: 51.56%] [G loss: 0.761841]\n",
      "epoch:7 step:7409 [D loss: 0.709819, acc.: 49.22%] [G loss: 0.738059]\n",
      "epoch:7 step:7410 [D loss: 0.700784, acc.: 47.66%] [G loss: 0.731708]\n",
      "epoch:7 step:7411 [D loss: 0.679307, acc.: 58.59%] [G loss: 0.723618]\n",
      "epoch:7 step:7412 [D loss: 0.681542, acc.: 59.38%] [G loss: 0.764056]\n",
      "epoch:7 step:7413 [D loss: 0.681593, acc.: 64.06%] [G loss: 0.761613]\n",
      "epoch:7 step:7414 [D loss: 0.683373, acc.: 57.81%] [G loss: 0.766791]\n",
      "epoch:7 step:7415 [D loss: 0.706596, acc.: 50.78%] [G loss: 0.752622]\n",
      "epoch:7 step:7416 [D loss: 0.679864, acc.: 54.69%] [G loss: 0.762462]\n",
      "epoch:7 step:7417 [D loss: 0.727283, acc.: 39.84%] [G loss: 0.717918]\n",
      "epoch:7 step:7418 [D loss: 0.711536, acc.: 42.19%] [G loss: 0.755939]\n",
      "epoch:7 step:7419 [D loss: 0.698259, acc.: 49.22%] [G loss: 0.716795]\n",
      "epoch:7 step:7420 [D loss: 0.698410, acc.: 42.97%] [G loss: 0.716578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7421 [D loss: 0.706724, acc.: 43.75%] [G loss: 0.698491]\n",
      "epoch:7 step:7422 [D loss: 0.694394, acc.: 51.56%] [G loss: 0.714818]\n",
      "epoch:7 step:7423 [D loss: 0.692488, acc.: 51.56%] [G loss: 0.699838]\n",
      "epoch:7 step:7424 [D loss: 0.705725, acc.: 46.88%] [G loss: 0.725585]\n",
      "epoch:7 step:7425 [D loss: 0.679541, acc.: 54.69%] [G loss: 0.721335]\n",
      "epoch:7 step:7426 [D loss: 0.721291, acc.: 44.53%] [G loss: 0.708501]\n",
      "epoch:7 step:7427 [D loss: 0.694879, acc.: 48.44%] [G loss: 0.715527]\n",
      "epoch:7 step:7428 [D loss: 0.677834, acc.: 60.16%] [G loss: 0.744028]\n",
      "epoch:7 step:7429 [D loss: 0.700963, acc.: 46.88%] [G loss: 0.759732]\n",
      "epoch:7 step:7430 [D loss: 0.687876, acc.: 52.34%] [G loss: 0.720895]\n",
      "epoch:7 step:7431 [D loss: 0.690225, acc.: 52.34%] [G loss: 0.729910]\n",
      "epoch:7 step:7432 [D loss: 0.688047, acc.: 54.69%] [G loss: 0.741719]\n",
      "epoch:7 step:7433 [D loss: 0.703302, acc.: 45.31%] [G loss: 0.709332]\n",
      "epoch:7 step:7434 [D loss: 0.684787, acc.: 54.69%] [G loss: 0.715681]\n",
      "epoch:7 step:7435 [D loss: 0.705726, acc.: 41.41%] [G loss: 0.701382]\n",
      "epoch:7 step:7436 [D loss: 0.701980, acc.: 46.09%] [G loss: 0.713334]\n",
      "epoch:7 step:7437 [D loss: 0.686364, acc.: 51.56%] [G loss: 0.726362]\n",
      "epoch:7 step:7438 [D loss: 0.685769, acc.: 53.12%] [G loss: 0.700459]\n",
      "epoch:7 step:7439 [D loss: 0.693959, acc.: 47.66%] [G loss: 0.700095]\n",
      "epoch:7 step:7440 [D loss: 0.686273, acc.: 55.47%] [G loss: 0.715237]\n",
      "epoch:7 step:7441 [D loss: 0.693625, acc.: 47.66%] [G loss: 0.708632]\n",
      "epoch:7 step:7442 [D loss: 0.698168, acc.: 47.66%] [G loss: 0.689142]\n",
      "epoch:7 step:7443 [D loss: 0.695891, acc.: 45.31%] [G loss: 0.699818]\n",
      "epoch:7 step:7444 [D loss: 0.700276, acc.: 46.09%] [G loss: 0.713747]\n",
      "epoch:7 step:7445 [D loss: 0.695842, acc.: 47.66%] [G loss: 0.700752]\n",
      "epoch:7 step:7446 [D loss: 0.699051, acc.: 52.34%] [G loss: 0.705462]\n",
      "epoch:7 step:7447 [D loss: 0.701425, acc.: 48.44%] [G loss: 0.700465]\n",
      "epoch:7 step:7448 [D loss: 0.690995, acc.: 55.47%] [G loss: 0.706743]\n",
      "epoch:7 step:7449 [D loss: 0.692877, acc.: 50.78%] [G loss: 0.714138]\n",
      "epoch:7 step:7450 [D loss: 0.695034, acc.: 56.25%] [G loss: 0.712385]\n",
      "epoch:7 step:7451 [D loss: 0.694135, acc.: 46.88%] [G loss: 0.724007]\n",
      "epoch:7 step:7452 [D loss: 0.693890, acc.: 53.91%] [G loss: 0.718279]\n",
      "epoch:7 step:7453 [D loss: 0.694332, acc.: 50.78%] [G loss: 0.730785]\n",
      "epoch:7 step:7454 [D loss: 0.691572, acc.: 53.91%] [G loss: 0.731553]\n",
      "epoch:7 step:7455 [D loss: 0.688079, acc.: 57.03%] [G loss: 0.733462]\n",
      "epoch:7 step:7456 [D loss: 0.675637, acc.: 60.94%] [G loss: 0.728822]\n",
      "epoch:7 step:7457 [D loss: 0.692345, acc.: 51.56%] [G loss: 0.730078]\n",
      "epoch:7 step:7458 [D loss: 0.669077, acc.: 62.50%] [G loss: 0.743156]\n",
      "epoch:7 step:7459 [D loss: 0.657359, acc.: 65.62%] [G loss: 0.749974]\n",
      "epoch:7 step:7460 [D loss: 0.673561, acc.: 60.94%] [G loss: 0.722180]\n",
      "epoch:7 step:7461 [D loss: 0.691792, acc.: 56.25%] [G loss: 0.742168]\n",
      "epoch:7 step:7462 [D loss: 0.683398, acc.: 56.25%] [G loss: 0.711711]\n",
      "epoch:7 step:7463 [D loss: 0.718290, acc.: 39.84%] [G loss: 0.715594]\n",
      "epoch:7 step:7464 [D loss: 0.716893, acc.: 43.75%] [G loss: 0.736834]\n",
      "epoch:7 step:7465 [D loss: 0.695838, acc.: 51.56%] [G loss: 0.714024]\n",
      "epoch:7 step:7466 [D loss: 0.679967, acc.: 59.38%] [G loss: 0.727536]\n",
      "epoch:7 step:7467 [D loss: 0.691415, acc.: 54.69%] [G loss: 0.748692]\n",
      "epoch:7 step:7468 [D loss: 0.681763, acc.: 62.50%] [G loss: 0.735400]\n",
      "epoch:7 step:7469 [D loss: 0.704507, acc.: 46.88%] [G loss: 0.722213]\n",
      "epoch:7 step:7470 [D loss: 0.674513, acc.: 56.25%] [G loss: 0.729026]\n",
      "epoch:7 step:7471 [D loss: 0.515889, acc.: 73.44%] [G loss: 0.735598]\n",
      "epoch:7 step:7472 [D loss: 0.690267, acc.: 52.34%] [G loss: 0.721159]\n",
      "epoch:7 step:7473 [D loss: 0.708319, acc.: 50.00%] [G loss: 0.727078]\n",
      "epoch:7 step:7474 [D loss: 0.736850, acc.: 44.53%] [G loss: 0.719712]\n",
      "epoch:7 step:7475 [D loss: 0.724799, acc.: 36.72%] [G loss: 0.701494]\n",
      "epoch:7 step:7476 [D loss: 0.677357, acc.: 57.81%] [G loss: 0.734916]\n",
      "epoch:7 step:7477 [D loss: 0.668383, acc.: 62.50%] [G loss: 0.745143]\n",
      "epoch:7 step:7478 [D loss: 0.645556, acc.: 69.53%] [G loss: 0.657634]\n",
      "epoch:7 step:7479 [D loss: 0.750772, acc.: 34.38%] [G loss: 0.720231]\n",
      "epoch:7 step:7480 [D loss: 0.725383, acc.: 40.62%] [G loss: 0.735694]\n",
      "epoch:7 step:7481 [D loss: 0.661281, acc.: 65.62%] [G loss: 0.708701]\n",
      "epoch:7 step:7482 [D loss: 0.695158, acc.: 47.66%] [G loss: 0.727844]\n",
      "epoch:7 step:7483 [D loss: 0.609684, acc.: 70.31%] [G loss: 0.717501]\n",
      "epoch:7 step:7484 [D loss: 0.628533, acc.: 61.72%] [G loss: 0.712666]\n",
      "epoch:7 step:7485 [D loss: 0.565673, acc.: 58.59%] [G loss: 0.738773]\n",
      "epoch:7 step:7486 [D loss: 0.511679, acc.: 61.72%] [G loss: 0.661372]\n",
      "epoch:7 step:7487 [D loss: 0.795762, acc.: 32.81%] [G loss: 0.789923]\n",
      "epoch:7 step:7488 [D loss: 0.710116, acc.: 45.31%] [G loss: 0.773228]\n",
      "epoch:7 step:7489 [D loss: 0.676815, acc.: 60.94%] [G loss: 0.686882]\n",
      "epoch:7 step:7490 [D loss: 0.753898, acc.: 46.09%] [G loss: 0.754141]\n",
      "epoch:7 step:7491 [D loss: 0.818808, acc.: 27.34%] [G loss: 0.858694]\n",
      "epoch:7 step:7492 [D loss: 0.702525, acc.: 57.03%] [G loss: 0.933352]\n",
      "epoch:7 step:7493 [D loss: 0.704740, acc.: 53.91%] [G loss: 0.801339]\n",
      "epoch:7 step:7494 [D loss: 0.689523, acc.: 53.91%] [G loss: 0.801572]\n",
      "epoch:7 step:7495 [D loss: 0.650666, acc.: 64.84%] [G loss: 0.790123]\n",
      "epoch:7 step:7496 [D loss: 0.653195, acc.: 55.47%] [G loss: 0.821059]\n",
      "epoch:8 step:7497 [D loss: 0.705876, acc.: 56.25%] [G loss: 0.781214]\n",
      "epoch:8 step:7498 [D loss: 0.690266, acc.: 56.25%] [G loss: 0.734009]\n",
      "epoch:8 step:7499 [D loss: 0.688166, acc.: 49.22%] [G loss: 0.723873]\n",
      "epoch:8 step:7500 [D loss: 0.690336, acc.: 53.91%] [G loss: 0.726273]\n",
      "epoch:8 step:7501 [D loss: 0.659160, acc.: 63.28%] [G loss: 0.737429]\n",
      "epoch:8 step:7502 [D loss: 0.680456, acc.: 54.69%] [G loss: 0.754835]\n",
      "epoch:8 step:7503 [D loss: 0.660073, acc.: 67.19%] [G loss: 0.748187]\n",
      "epoch:8 step:7504 [D loss: 0.692990, acc.: 57.03%] [G loss: 0.721224]\n",
      "epoch:8 step:7505 [D loss: 0.681002, acc.: 53.91%] [G loss: 0.751540]\n",
      "epoch:8 step:7506 [D loss: 0.699315, acc.: 55.47%] [G loss: 0.755287]\n",
      "epoch:8 step:7507 [D loss: 0.688238, acc.: 48.44%] [G loss: 0.764394]\n",
      "epoch:8 step:7508 [D loss: 0.719995, acc.: 46.88%] [G loss: 0.818018]\n",
      "epoch:8 step:7509 [D loss: 0.669476, acc.: 52.34%] [G loss: 0.832729]\n",
      "epoch:8 step:7510 [D loss: 0.668245, acc.: 57.03%] [G loss: 0.821063]\n",
      "epoch:8 step:7511 [D loss: 0.659779, acc.: 61.72%] [G loss: 1.252919]\n",
      "epoch:8 step:7512 [D loss: 0.666964, acc.: 65.62%] [G loss: 0.943387]\n",
      "epoch:8 step:7513 [D loss: 0.712847, acc.: 49.22%] [G loss: 0.867422]\n",
      "epoch:8 step:7514 [D loss: 0.699486, acc.: 57.03%] [G loss: 0.792978]\n",
      "epoch:8 step:7515 [D loss: 0.669320, acc.: 57.81%] [G loss: 0.866034]\n",
      "epoch:8 step:7516 [D loss: 0.716621, acc.: 43.75%] [G loss: 0.781724]\n",
      "epoch:8 step:7517 [D loss: 0.700389, acc.: 43.75%] [G loss: 0.784240]\n",
      "epoch:8 step:7518 [D loss: 0.660877, acc.: 63.28%] [G loss: 0.737871]\n",
      "epoch:8 step:7519 [D loss: 0.655344, acc.: 70.31%] [G loss: 0.813691]\n",
      "epoch:8 step:7520 [D loss: 0.583596, acc.: 84.38%] [G loss: 0.900252]\n",
      "epoch:8 step:7521 [D loss: 0.642391, acc.: 67.19%] [G loss: 0.852958]\n",
      "epoch:8 step:7522 [D loss: 0.751170, acc.: 45.31%] [G loss: 0.902918]\n",
      "epoch:8 step:7523 [D loss: 0.824876, acc.: 44.53%] [G loss: 0.672245]\n",
      "epoch:8 step:7524 [D loss: 0.716888, acc.: 40.62%] [G loss: 0.615922]\n",
      "epoch:8 step:7525 [D loss: 0.695661, acc.: 51.56%] [G loss: 0.666846]\n",
      "epoch:8 step:7526 [D loss: 0.696792, acc.: 47.66%] [G loss: 0.627758]\n",
      "epoch:8 step:7527 [D loss: 0.721970, acc.: 53.91%] [G loss: 0.750479]\n",
      "epoch:8 step:7528 [D loss: 0.680990, acc.: 51.56%] [G loss: 0.731394]\n",
      "epoch:8 step:7529 [D loss: 0.693127, acc.: 52.34%] [G loss: 0.816542]\n",
      "epoch:8 step:7530 [D loss: 0.700486, acc.: 51.56%] [G loss: 0.720423]\n",
      "epoch:8 step:7531 [D loss: 0.677820, acc.: 57.81%] [G loss: 0.753954]\n",
      "epoch:8 step:7532 [D loss: 0.670600, acc.: 63.28%] [G loss: 0.758679]\n",
      "epoch:8 step:7533 [D loss: 0.713941, acc.: 51.56%] [G loss: 0.740659]\n",
      "epoch:8 step:7534 [D loss: 0.702190, acc.: 46.09%] [G loss: 0.746450]\n",
      "epoch:8 step:7535 [D loss: 0.704257, acc.: 41.41%] [G loss: 0.724096]\n",
      "epoch:8 step:7536 [D loss: 0.696799, acc.: 46.09%] [G loss: 0.716516]\n",
      "epoch:8 step:7537 [D loss: 0.701074, acc.: 47.66%] [G loss: 0.724259]\n",
      "epoch:8 step:7538 [D loss: 0.697902, acc.: 49.22%] [G loss: 0.698147]\n",
      "epoch:8 step:7539 [D loss: 0.705089, acc.: 53.12%] [G loss: 0.694560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7540 [D loss: 0.698866, acc.: 50.00%] [G loss: 0.722725]\n",
      "epoch:8 step:7541 [D loss: 0.719216, acc.: 38.28%] [G loss: 0.717899]\n",
      "epoch:8 step:7542 [D loss: 0.690303, acc.: 49.22%] [G loss: 0.695530]\n",
      "epoch:8 step:7543 [D loss: 0.688420, acc.: 56.25%] [G loss: 0.682823]\n",
      "epoch:8 step:7544 [D loss: 0.682072, acc.: 53.12%] [G loss: 0.720837]\n",
      "epoch:8 step:7545 [D loss: 0.688643, acc.: 57.03%] [G loss: 0.719417]\n",
      "epoch:8 step:7546 [D loss: 0.681647, acc.: 53.12%] [G loss: 0.713619]\n",
      "epoch:8 step:7547 [D loss: 0.713565, acc.: 48.44%] [G loss: 0.719853]\n",
      "epoch:8 step:7548 [D loss: 0.767242, acc.: 47.66%] [G loss: 0.726036]\n",
      "epoch:8 step:7549 [D loss: 0.681072, acc.: 64.06%] [G loss: 0.754803]\n",
      "epoch:8 step:7550 [D loss: 0.696143, acc.: 57.81%] [G loss: 0.794372]\n",
      "epoch:8 step:7551 [D loss: 0.686824, acc.: 60.94%] [G loss: 0.784775]\n",
      "epoch:8 step:7552 [D loss: 0.676810, acc.: 59.38%] [G loss: 0.780096]\n",
      "epoch:8 step:7553 [D loss: 0.688969, acc.: 56.25%] [G loss: 0.816472]\n",
      "epoch:8 step:7554 [D loss: 0.711645, acc.: 50.78%] [G loss: 0.764608]\n",
      "epoch:8 step:7555 [D loss: 0.693777, acc.: 54.69%] [G loss: 0.758124]\n",
      "epoch:8 step:7556 [D loss: 0.694740, acc.: 53.12%] [G loss: 0.734516]\n",
      "epoch:8 step:7557 [D loss: 0.698146, acc.: 50.00%] [G loss: 0.742142]\n",
      "epoch:8 step:7558 [D loss: 0.699674, acc.: 50.78%] [G loss: 0.733842]\n",
      "epoch:8 step:7559 [D loss: 0.692758, acc.: 50.00%] [G loss: 0.720722]\n",
      "epoch:8 step:7560 [D loss: 0.694560, acc.: 53.91%] [G loss: 0.743724]\n",
      "epoch:8 step:7561 [D loss: 0.700029, acc.: 50.78%] [G loss: 0.738936]\n",
      "epoch:8 step:7562 [D loss: 0.694969, acc.: 53.91%] [G loss: 0.740097]\n",
      "epoch:8 step:7563 [D loss: 0.688855, acc.: 53.91%] [G loss: 0.724217]\n",
      "epoch:8 step:7564 [D loss: 0.695417, acc.: 57.81%] [G loss: 0.749188]\n",
      "epoch:8 step:7565 [D loss: 0.682568, acc.: 53.91%] [G loss: 0.723724]\n",
      "epoch:8 step:7566 [D loss: 0.680150, acc.: 59.38%] [G loss: 0.727928]\n",
      "epoch:8 step:7567 [D loss: 0.706140, acc.: 48.44%] [G loss: 0.726525]\n",
      "epoch:8 step:7568 [D loss: 0.680107, acc.: 60.16%] [G loss: 0.720602]\n",
      "epoch:8 step:7569 [D loss: 0.688578, acc.: 55.47%] [G loss: 0.733485]\n",
      "epoch:8 step:7570 [D loss: 0.688574, acc.: 56.25%] [G loss: 0.735947]\n",
      "epoch:8 step:7571 [D loss: 0.708824, acc.: 39.06%] [G loss: 0.722091]\n",
      "epoch:8 step:7572 [D loss: 0.694469, acc.: 50.78%] [G loss: 0.993184]\n",
      "epoch:8 step:7573 [D loss: 0.690884, acc.: 51.56%] [G loss: 0.715435]\n",
      "epoch:8 step:7574 [D loss: 0.703876, acc.: 46.88%] [G loss: 0.712157]\n",
      "epoch:8 step:7575 [D loss: 0.682861, acc.: 55.47%] [G loss: 0.714281]\n",
      "epoch:8 step:7576 [D loss: 0.708458, acc.: 43.75%] [G loss: 0.704520]\n",
      "epoch:8 step:7577 [D loss: 0.701250, acc.: 42.97%] [G loss: 0.712322]\n",
      "epoch:8 step:7578 [D loss: 0.690491, acc.: 53.12%] [G loss: 0.715959]\n",
      "epoch:8 step:7579 [D loss: 0.688557, acc.: 52.34%] [G loss: 0.714208]\n",
      "epoch:8 step:7580 [D loss: 0.687445, acc.: 50.00%] [G loss: 0.728892]\n",
      "epoch:8 step:7581 [D loss: 0.678379, acc.: 60.16%] [G loss: 0.729378]\n",
      "epoch:8 step:7582 [D loss: 0.696020, acc.: 49.22%] [G loss: 0.727221]\n",
      "epoch:8 step:7583 [D loss: 0.707481, acc.: 47.66%] [G loss: 0.682261]\n",
      "epoch:8 step:7584 [D loss: 0.692059, acc.: 53.12%] [G loss: 0.735080]\n",
      "epoch:8 step:7585 [D loss: 0.680220, acc.: 60.94%] [G loss: 0.733015]\n",
      "epoch:8 step:7586 [D loss: 0.686930, acc.: 55.47%] [G loss: 0.705078]\n",
      "epoch:8 step:7587 [D loss: 0.667987, acc.: 68.75%] [G loss: 0.725134]\n",
      "epoch:8 step:7588 [D loss: 0.685083, acc.: 62.50%] [G loss: 0.740023]\n",
      "epoch:8 step:7589 [D loss: 0.733076, acc.: 50.00%] [G loss: 0.728060]\n",
      "epoch:8 step:7590 [D loss: 0.682340, acc.: 63.28%] [G loss: 0.747550]\n",
      "epoch:8 step:7591 [D loss: 0.684516, acc.: 53.12%] [G loss: 1.085157]\n",
      "epoch:8 step:7592 [D loss: 0.695456, acc.: 53.91%] [G loss: 1.116527]\n",
      "epoch:8 step:7593 [D loss: 0.685431, acc.: 54.69%] [G loss: 0.729353]\n",
      "epoch:8 step:7594 [D loss: 0.690721, acc.: 50.78%] [G loss: 0.733748]\n",
      "epoch:8 step:7595 [D loss: 0.679425, acc.: 56.25%] [G loss: 0.719726]\n",
      "epoch:8 step:7596 [D loss: 0.682883, acc.: 60.16%] [G loss: 0.736595]\n",
      "epoch:8 step:7597 [D loss: 0.679335, acc.: 59.38%] [G loss: 0.727653]\n",
      "epoch:8 step:7598 [D loss: 0.699076, acc.: 50.78%] [G loss: 0.727579]\n",
      "epoch:8 step:7599 [D loss: 0.692240, acc.: 55.47%] [G loss: 0.794220]\n",
      "epoch:8 step:7600 [D loss: 0.701511, acc.: 42.19%] [G loss: 0.728861]\n",
      "epoch:8 step:7601 [D loss: 0.705301, acc.: 50.00%] [G loss: 0.732633]\n",
      "epoch:8 step:7602 [D loss: 0.675437, acc.: 57.03%] [G loss: 0.743722]\n",
      "epoch:8 step:7603 [D loss: 0.685106, acc.: 52.34%] [G loss: 0.771790]\n",
      "epoch:8 step:7604 [D loss: 0.706976, acc.: 43.75%] [G loss: 0.721324]\n",
      "epoch:8 step:7605 [D loss: 0.683653, acc.: 56.25%] [G loss: 0.728110]\n",
      "epoch:8 step:7606 [D loss: 0.686044, acc.: 50.78%] [G loss: 0.721100]\n",
      "epoch:8 step:7607 [D loss: 0.697888, acc.: 51.56%] [G loss: 0.744011]\n",
      "epoch:8 step:7608 [D loss: 0.680206, acc.: 53.91%] [G loss: 0.774366]\n",
      "epoch:8 step:7609 [D loss: 0.670874, acc.: 57.03%] [G loss: 0.734592]\n",
      "epoch:8 step:7610 [D loss: 0.678982, acc.: 55.47%] [G loss: 0.771449]\n",
      "epoch:8 step:7611 [D loss: 0.658120, acc.: 65.62%] [G loss: 0.781268]\n",
      "epoch:8 step:7612 [D loss: 0.690006, acc.: 46.09%] [G loss: 0.778900]\n",
      "epoch:8 step:7613 [D loss: 0.675242, acc.: 65.62%] [G loss: 0.688331]\n",
      "epoch:8 step:7614 [D loss: 0.685166, acc.: 52.34%] [G loss: 0.721741]\n",
      "epoch:8 step:7615 [D loss: 0.701862, acc.: 51.56%] [G loss: 0.705866]\n",
      "epoch:8 step:7616 [D loss: 0.701978, acc.: 48.44%] [G loss: 0.755255]\n",
      "epoch:8 step:7617 [D loss: 0.668173, acc.: 63.28%] [G loss: 0.744758]\n",
      "epoch:8 step:7618 [D loss: 0.683522, acc.: 56.25%] [G loss: 0.773355]\n",
      "epoch:8 step:7619 [D loss: 0.677138, acc.: 53.12%] [G loss: 0.830843]\n",
      "epoch:8 step:7620 [D loss: 0.701280, acc.: 50.78%] [G loss: 0.795615]\n",
      "epoch:8 step:7621 [D loss: 0.694671, acc.: 53.12%] [G loss: 0.791503]\n",
      "epoch:8 step:7622 [D loss: 0.674718, acc.: 58.59%] [G loss: 0.795554]\n",
      "epoch:8 step:7623 [D loss: 0.684300, acc.: 53.91%] [G loss: 0.770719]\n",
      "epoch:8 step:7624 [D loss: 0.684063, acc.: 50.78%] [G loss: 0.744919]\n",
      "epoch:8 step:7625 [D loss: 0.703606, acc.: 46.88%] [G loss: 0.773775]\n",
      "epoch:8 step:7626 [D loss: 0.691537, acc.: 53.12%] [G loss: 0.714028]\n",
      "epoch:8 step:7627 [D loss: 0.703513, acc.: 47.66%] [G loss: 0.715595]\n",
      "epoch:8 step:7628 [D loss: 0.722188, acc.: 46.09%] [G loss: 0.697812]\n",
      "epoch:8 step:7629 [D loss: 0.696328, acc.: 47.66%] [G loss: 0.713781]\n",
      "epoch:8 step:7630 [D loss: 0.705741, acc.: 50.00%] [G loss: 0.742972]\n",
      "epoch:8 step:7631 [D loss: 0.687755, acc.: 53.91%] [G loss: 0.712422]\n",
      "epoch:8 step:7632 [D loss: 0.697613, acc.: 53.91%] [G loss: 0.722465]\n",
      "epoch:8 step:7633 [D loss: 0.696257, acc.: 46.88%] [G loss: 0.722841]\n",
      "epoch:8 step:7634 [D loss: 0.692616, acc.: 51.56%] [G loss: 0.746831]\n",
      "epoch:8 step:7635 [D loss: 0.667221, acc.: 59.38%] [G loss: 0.730918]\n",
      "epoch:8 step:7636 [D loss: 0.659039, acc.: 64.84%] [G loss: 0.747036]\n",
      "epoch:8 step:7637 [D loss: 0.680427, acc.: 55.47%] [G loss: 0.716935]\n",
      "epoch:8 step:7638 [D loss: 0.682219, acc.: 53.12%] [G loss: 0.755131]\n",
      "epoch:8 step:7639 [D loss: 0.674910, acc.: 54.69%] [G loss: 0.755345]\n",
      "epoch:8 step:7640 [D loss: 0.657785, acc.: 66.41%] [G loss: 0.764986]\n",
      "epoch:8 step:7641 [D loss: 0.681584, acc.: 58.59%] [G loss: 0.704055]\n",
      "epoch:8 step:7642 [D loss: 0.673797, acc.: 55.47%] [G loss: 0.746154]\n",
      "epoch:8 step:7643 [D loss: 0.695760, acc.: 51.56%] [G loss: 0.737747]\n",
      "epoch:8 step:7644 [D loss: 0.693740, acc.: 51.56%] [G loss: 0.719468]\n",
      "epoch:8 step:7645 [D loss: 0.714462, acc.: 47.66%] [G loss: 0.704387]\n",
      "epoch:8 step:7646 [D loss: 0.684243, acc.: 57.81%] [G loss: 0.723170]\n",
      "epoch:8 step:7647 [D loss: 0.695020, acc.: 50.00%] [G loss: 0.722188]\n",
      "epoch:8 step:7648 [D loss: 0.675344, acc.: 64.06%] [G loss: 0.727996]\n",
      "epoch:8 step:7649 [D loss: 0.701890, acc.: 46.09%] [G loss: 0.755199]\n",
      "epoch:8 step:7650 [D loss: 0.682417, acc.: 55.47%] [G loss: 0.763850]\n",
      "epoch:8 step:7651 [D loss: 0.675595, acc.: 59.38%] [G loss: 0.754892]\n",
      "epoch:8 step:7652 [D loss: 0.675412, acc.: 60.94%] [G loss: 0.750467]\n",
      "epoch:8 step:7653 [D loss: 0.648932, acc.: 72.66%] [G loss: 0.765522]\n",
      "epoch:8 step:7654 [D loss: 0.668323, acc.: 60.94%] [G loss: 0.744132]\n",
      "epoch:8 step:7655 [D loss: 0.749494, acc.: 37.50%] [G loss: 0.749014]\n",
      "epoch:8 step:7656 [D loss: 0.693262, acc.: 56.25%] [G loss: 0.746216]\n",
      "epoch:8 step:7657 [D loss: 0.691387, acc.: 50.78%] [G loss: 0.743125]\n",
      "epoch:8 step:7658 [D loss: 0.699354, acc.: 57.03%] [G loss: 0.738287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7659 [D loss: 0.706500, acc.: 46.09%] [G loss: 0.742335]\n",
      "epoch:8 step:7660 [D loss: 0.699398, acc.: 51.56%] [G loss: 0.690752]\n",
      "epoch:8 step:7661 [D loss: 0.693231, acc.: 46.88%] [G loss: 0.692613]\n",
      "epoch:8 step:7662 [D loss: 0.704415, acc.: 51.56%] [G loss: 0.713048]\n",
      "epoch:8 step:7663 [D loss: 0.709822, acc.: 47.66%] [G loss: 0.712028]\n",
      "epoch:8 step:7664 [D loss: 0.702337, acc.: 50.00%] [G loss: 0.719598]\n",
      "epoch:8 step:7665 [D loss: 0.717531, acc.: 45.31%] [G loss: 0.727103]\n",
      "epoch:8 step:7666 [D loss: 0.681318, acc.: 56.25%] [G loss: 0.755442]\n",
      "epoch:8 step:7667 [D loss: 0.685657, acc.: 54.69%] [G loss: 0.768230]\n",
      "epoch:8 step:7668 [D loss: 0.674481, acc.: 57.81%] [G loss: 0.743665]\n",
      "epoch:8 step:7669 [D loss: 0.673715, acc.: 54.69%] [G loss: 0.730958]\n",
      "epoch:8 step:7670 [D loss: 0.679075, acc.: 57.03%] [G loss: 0.749489]\n",
      "epoch:8 step:7671 [D loss: 0.698738, acc.: 46.88%] [G loss: 0.712655]\n",
      "epoch:8 step:7672 [D loss: 0.676508, acc.: 54.69%] [G loss: 0.732703]\n",
      "epoch:8 step:7673 [D loss: 0.705339, acc.: 53.12%] [G loss: 0.733304]\n",
      "epoch:8 step:7674 [D loss: 0.682825, acc.: 53.91%] [G loss: 0.743369]\n",
      "epoch:8 step:7675 [D loss: 0.692384, acc.: 53.12%] [G loss: 0.730778]\n",
      "epoch:8 step:7676 [D loss: 0.678476, acc.: 61.72%] [G loss: 0.730645]\n",
      "epoch:8 step:7677 [D loss: 0.698374, acc.: 47.66%] [G loss: 0.710367]\n",
      "epoch:8 step:7678 [D loss: 0.687210, acc.: 56.25%] [G loss: 0.709241]\n",
      "epoch:8 step:7679 [D loss: 0.683946, acc.: 51.56%] [G loss: 0.705418]\n",
      "epoch:8 step:7680 [D loss: 0.700849, acc.: 49.22%] [G loss: 0.689785]\n",
      "epoch:8 step:7681 [D loss: 0.662775, acc.: 60.94%] [G loss: 0.728048]\n",
      "epoch:8 step:7682 [D loss: 0.692538, acc.: 55.47%] [G loss: 0.755167]\n",
      "epoch:8 step:7683 [D loss: 0.673214, acc.: 58.59%] [G loss: 0.739644]\n",
      "epoch:8 step:7684 [D loss: 0.692155, acc.: 53.91%] [G loss: 0.734590]\n",
      "epoch:8 step:7685 [D loss: 0.698663, acc.: 51.56%] [G loss: 0.740188]\n",
      "epoch:8 step:7686 [D loss: 0.656744, acc.: 64.84%] [G loss: 0.732000]\n",
      "epoch:8 step:7687 [D loss: 0.687316, acc.: 60.16%] [G loss: 0.749990]\n",
      "epoch:8 step:7688 [D loss: 0.674072, acc.: 60.16%] [G loss: 0.751352]\n",
      "epoch:8 step:7689 [D loss: 0.687759, acc.: 49.22%] [G loss: 0.770611]\n",
      "epoch:8 step:7690 [D loss: 0.677655, acc.: 60.94%] [G loss: 0.716186]\n",
      "epoch:8 step:7691 [D loss: 0.679417, acc.: 60.16%] [G loss: 0.781747]\n",
      "epoch:8 step:7692 [D loss: 0.701325, acc.: 50.00%] [G loss: 0.773087]\n",
      "epoch:8 step:7693 [D loss: 0.688431, acc.: 48.44%] [G loss: 0.772949]\n",
      "epoch:8 step:7694 [D loss: 0.672002, acc.: 64.06%] [G loss: 0.785276]\n",
      "epoch:8 step:7695 [D loss: 0.685845, acc.: 52.34%] [G loss: 0.801910]\n",
      "epoch:8 step:7696 [D loss: 0.686725, acc.: 56.25%] [G loss: 0.819350]\n",
      "epoch:8 step:7697 [D loss: 0.701038, acc.: 50.78%] [G loss: 0.778401]\n",
      "epoch:8 step:7698 [D loss: 0.678828, acc.: 57.03%] [G loss: 0.794122]\n",
      "epoch:8 step:7699 [D loss: 0.720289, acc.: 45.31%] [G loss: 0.765615]\n",
      "epoch:8 step:7700 [D loss: 0.659965, acc.: 53.12%] [G loss: 0.724753]\n",
      "epoch:8 step:7701 [D loss: 0.678826, acc.: 57.81%] [G loss: 0.711820]\n",
      "epoch:8 step:7702 [D loss: 0.670532, acc.: 57.81%] [G loss: 0.725536]\n",
      "epoch:8 step:7703 [D loss: 0.561328, acc.: 62.50%] [G loss: 0.753913]\n",
      "epoch:8 step:7704 [D loss: 0.686807, acc.: 55.47%] [G loss: 0.751944]\n",
      "epoch:8 step:7705 [D loss: 0.668114, acc.: 61.72%] [G loss: 0.756941]\n",
      "epoch:8 step:7706 [D loss: 0.718235, acc.: 43.75%] [G loss: 0.719456]\n",
      "epoch:8 step:7707 [D loss: 0.711455, acc.: 44.53%] [G loss: 0.780660]\n",
      "epoch:8 step:7708 [D loss: 0.673238, acc.: 57.03%] [G loss: 0.746920]\n",
      "epoch:8 step:7709 [D loss: 0.656530, acc.: 64.84%] [G loss: 0.770131]\n",
      "epoch:8 step:7710 [D loss: 0.718300, acc.: 45.31%] [G loss: 0.641051]\n",
      "epoch:8 step:7711 [D loss: 0.764649, acc.: 35.16%] [G loss: 0.729543]\n",
      "epoch:8 step:7712 [D loss: 0.621738, acc.: 64.84%] [G loss: 0.760916]\n",
      "epoch:8 step:7713 [D loss: 0.729778, acc.: 48.44%] [G loss: 0.694556]\n",
      "epoch:8 step:7714 [D loss: 0.684756, acc.: 57.03%] [G loss: 0.736287]\n",
      "epoch:8 step:7715 [D loss: 0.691041, acc.: 50.78%] [G loss: 0.743735]\n",
      "epoch:8 step:7716 [D loss: 0.707752, acc.: 43.75%] [G loss: 0.761674]\n",
      "epoch:8 step:7717 [D loss: 0.687285, acc.: 48.44%] [G loss: 0.768538]\n",
      "epoch:8 step:7718 [D loss: 0.684511, acc.: 53.12%] [G loss: 0.770139]\n",
      "epoch:8 step:7719 [D loss: 0.673365, acc.: 64.84%] [G loss: 0.739839]\n",
      "epoch:8 step:7720 [D loss: 0.725026, acc.: 45.31%] [G loss: 0.787002]\n",
      "epoch:8 step:7721 [D loss: 0.686514, acc.: 58.59%] [G loss: 0.800365]\n",
      "epoch:8 step:7722 [D loss: 0.667679, acc.: 67.19%] [G loss: 0.771601]\n",
      "epoch:8 step:7723 [D loss: 0.694059, acc.: 53.91%] [G loss: 0.788324]\n",
      "epoch:8 step:7724 [D loss: 0.706179, acc.: 53.91%] [G loss: 0.770372]\n",
      "epoch:8 step:7725 [D loss: 0.682302, acc.: 55.47%] [G loss: 0.789697]\n",
      "epoch:8 step:7726 [D loss: 0.661494, acc.: 59.38%] [G loss: 0.795286]\n",
      "epoch:8 step:7727 [D loss: 0.647072, acc.: 65.62%] [G loss: 0.795879]\n",
      "epoch:8 step:7728 [D loss: 0.642549, acc.: 62.50%] [G loss: 0.852131]\n",
      "epoch:8 step:7729 [D loss: 0.700692, acc.: 48.44%] [G loss: 0.772591]\n",
      "epoch:8 step:7730 [D loss: 0.705451, acc.: 49.22%] [G loss: 0.812360]\n",
      "epoch:8 step:7731 [D loss: 0.657324, acc.: 60.16%] [G loss: 0.762535]\n",
      "epoch:8 step:7732 [D loss: 0.648549, acc.: 66.41%] [G loss: 0.808341]\n",
      "epoch:8 step:7733 [D loss: 0.651374, acc.: 64.06%] [G loss: 0.805457]\n",
      "epoch:8 step:7734 [D loss: 0.662198, acc.: 61.72%] [G loss: 0.814725]\n",
      "epoch:8 step:7735 [D loss: 0.713671, acc.: 45.31%] [G loss: 0.877138]\n",
      "epoch:8 step:7736 [D loss: 0.682493, acc.: 52.34%] [G loss: 0.763288]\n",
      "epoch:8 step:7737 [D loss: 0.721940, acc.: 50.00%] [G loss: 0.796556]\n",
      "epoch:8 step:7738 [D loss: 0.679130, acc.: 55.47%] [G loss: 0.744790]\n",
      "epoch:8 step:7739 [D loss: 0.706939, acc.: 52.34%] [G loss: 0.741537]\n",
      "epoch:8 step:7740 [D loss: 0.704889, acc.: 50.00%] [G loss: 0.797155]\n",
      "epoch:8 step:7741 [D loss: 0.707847, acc.: 53.91%] [G loss: 0.731471]\n",
      "epoch:8 step:7742 [D loss: 0.721336, acc.: 42.19%] [G loss: 0.728909]\n",
      "epoch:8 step:7743 [D loss: 0.702657, acc.: 46.09%] [G loss: 0.757036]\n",
      "epoch:8 step:7744 [D loss: 0.670891, acc.: 58.59%] [G loss: 0.751657]\n",
      "epoch:8 step:7745 [D loss: 0.701841, acc.: 53.12%] [G loss: 0.738733]\n",
      "epoch:8 step:7746 [D loss: 0.677704, acc.: 58.59%] [G loss: 0.746424]\n",
      "epoch:8 step:7747 [D loss: 0.686362, acc.: 49.22%] [G loss: 0.780368]\n",
      "epoch:8 step:7748 [D loss: 0.692879, acc.: 57.81%] [G loss: 0.709397]\n",
      "epoch:8 step:7749 [D loss: 0.691741, acc.: 56.25%] [G loss: 0.753526]\n",
      "epoch:8 step:7750 [D loss: 0.705210, acc.: 52.34%] [G loss: 0.744983]\n",
      "epoch:8 step:7751 [D loss: 0.703746, acc.: 53.91%] [G loss: 0.727500]\n",
      "epoch:8 step:7752 [D loss: 0.708956, acc.: 48.44%] [G loss: 0.710039]\n",
      "epoch:8 step:7753 [D loss: 0.675866, acc.: 55.47%] [G loss: 0.708170]\n",
      "epoch:8 step:7754 [D loss: 0.689024, acc.: 52.34%] [G loss: 0.718218]\n",
      "epoch:8 step:7755 [D loss: 0.701714, acc.: 52.34%] [G loss: 0.753753]\n",
      "epoch:8 step:7756 [D loss: 0.701188, acc.: 53.91%] [G loss: 0.732072]\n",
      "epoch:8 step:7757 [D loss: 0.679408, acc.: 58.59%] [G loss: 0.734799]\n",
      "epoch:8 step:7758 [D loss: 0.696319, acc.: 53.12%] [G loss: 0.762322]\n",
      "epoch:8 step:7759 [D loss: 0.604139, acc.: 57.81%] [G loss: 0.746297]\n",
      "epoch:8 step:7760 [D loss: 0.682722, acc.: 59.38%] [G loss: 0.616108]\n",
      "epoch:8 step:7761 [D loss: 0.692007, acc.: 53.91%] [G loss: 0.716420]\n",
      "epoch:8 step:7762 [D loss: 0.708615, acc.: 46.88%] [G loss: 0.751251]\n",
      "epoch:8 step:7763 [D loss: 0.675795, acc.: 57.81%] [G loss: 0.773380]\n",
      "epoch:8 step:7764 [D loss: 0.687523, acc.: 56.25%] [G loss: 0.785022]\n",
      "epoch:8 step:7765 [D loss: 0.693292, acc.: 42.19%] [G loss: 0.758155]\n",
      "epoch:8 step:7766 [D loss: 0.694755, acc.: 50.78%] [G loss: 0.812741]\n",
      "epoch:8 step:7767 [D loss: 0.672637, acc.: 58.59%] [G loss: 0.755116]\n",
      "epoch:8 step:7768 [D loss: 0.716636, acc.: 40.62%] [G loss: 0.745959]\n",
      "epoch:8 step:7769 [D loss: 0.714642, acc.: 52.34%] [G loss: 0.758206]\n",
      "epoch:8 step:7770 [D loss: 0.689153, acc.: 57.03%] [G loss: 0.722286]\n",
      "epoch:8 step:7771 [D loss: 0.691471, acc.: 56.25%] [G loss: 0.757015]\n",
      "epoch:8 step:7772 [D loss: 0.701325, acc.: 51.56%] [G loss: 0.750284]\n",
      "epoch:8 step:7773 [D loss: 0.689630, acc.: 53.91%] [G loss: 0.750874]\n",
      "epoch:8 step:7774 [D loss: 0.713401, acc.: 47.66%] [G loss: 0.754081]\n",
      "epoch:8 step:7775 [D loss: 0.698118, acc.: 47.66%] [G loss: 0.752776]\n",
      "epoch:8 step:7776 [D loss: 0.678745, acc.: 55.47%] [G loss: 0.750893]\n",
      "epoch:8 step:7777 [D loss: 0.719545, acc.: 49.22%] [G loss: 0.767394]\n",
      "epoch:8 step:7778 [D loss: 0.710409, acc.: 46.09%] [G loss: 0.733517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7779 [D loss: 0.684505, acc.: 53.12%] [G loss: 0.783531]\n",
      "epoch:8 step:7780 [D loss: 0.674002, acc.: 63.28%] [G loss: 0.744741]\n",
      "epoch:8 step:7781 [D loss: 0.699547, acc.: 54.69%] [G loss: 0.750718]\n",
      "epoch:8 step:7782 [D loss: 0.679035, acc.: 62.50%] [G loss: 0.712762]\n",
      "epoch:8 step:7783 [D loss: 0.667071, acc.: 62.50%] [G loss: 0.754236]\n",
      "epoch:8 step:7784 [D loss: 0.671889, acc.: 63.28%] [G loss: 0.747732]\n",
      "epoch:8 step:7785 [D loss: 0.660284, acc.: 65.62%] [G loss: 0.718828]\n",
      "epoch:8 step:7786 [D loss: 0.652628, acc.: 61.72%] [G loss: 0.794033]\n",
      "epoch:8 step:7787 [D loss: 0.677518, acc.: 53.12%] [G loss: 0.821958]\n",
      "epoch:8 step:7788 [D loss: 0.685477, acc.: 52.34%] [G loss: 0.782872]\n",
      "epoch:8 step:7789 [D loss: 0.667571, acc.: 59.38%] [G loss: 0.782846]\n",
      "epoch:8 step:7790 [D loss: 0.708885, acc.: 45.31%] [G loss: 0.754166]\n",
      "epoch:8 step:7791 [D loss: 0.705922, acc.: 46.88%] [G loss: 0.761021]\n",
      "epoch:8 step:7792 [D loss: 0.702231, acc.: 50.00%] [G loss: 0.734086]\n",
      "epoch:8 step:7793 [D loss: 0.709272, acc.: 41.41%] [G loss: 0.711384]\n",
      "epoch:8 step:7794 [D loss: 0.704913, acc.: 47.66%] [G loss: 0.778583]\n",
      "epoch:8 step:7795 [D loss: 0.710103, acc.: 49.22%] [G loss: 0.765745]\n",
      "epoch:8 step:7796 [D loss: 0.696005, acc.: 53.91%] [G loss: 0.741016]\n",
      "epoch:8 step:7797 [D loss: 0.704266, acc.: 54.69%] [G loss: 0.766206]\n",
      "epoch:8 step:7798 [D loss: 0.692863, acc.: 48.44%] [G loss: 0.763143]\n",
      "epoch:8 step:7799 [D loss: 0.706895, acc.: 47.66%] [G loss: 0.731538]\n",
      "epoch:8 step:7800 [D loss: 0.711914, acc.: 43.75%] [G loss: 0.734244]\n",
      "epoch:8 step:7801 [D loss: 0.687516, acc.: 55.47%] [G loss: 0.733327]\n",
      "epoch:8 step:7802 [D loss: 0.690572, acc.: 50.78%] [G loss: 0.734605]\n",
      "epoch:8 step:7803 [D loss: 0.669972, acc.: 60.94%] [G loss: 0.715751]\n",
      "epoch:8 step:7804 [D loss: 0.681566, acc.: 53.12%] [G loss: 0.763474]\n",
      "epoch:8 step:7805 [D loss: 0.674174, acc.: 60.94%] [G loss: 0.752665]\n",
      "epoch:8 step:7806 [D loss: 0.680611, acc.: 57.81%] [G loss: 0.755096]\n",
      "epoch:8 step:7807 [D loss: 0.668272, acc.: 58.59%] [G loss: 0.771421]\n",
      "epoch:8 step:7808 [D loss: 0.659245, acc.: 64.06%] [G loss: 0.794802]\n",
      "epoch:8 step:7809 [D loss: 0.675424, acc.: 57.03%] [G loss: 0.802624]\n",
      "epoch:8 step:7810 [D loss: 0.683871, acc.: 57.81%] [G loss: 0.720775]\n",
      "epoch:8 step:7811 [D loss: 0.657805, acc.: 66.41%] [G loss: 0.777119]\n",
      "epoch:8 step:7812 [D loss: 0.702643, acc.: 50.00%] [G loss: 0.770087]\n",
      "epoch:8 step:7813 [D loss: 0.705297, acc.: 46.09%] [G loss: 0.703787]\n",
      "epoch:8 step:7814 [D loss: 0.675196, acc.: 58.59%] [G loss: 0.718488]\n",
      "epoch:8 step:7815 [D loss: 0.691799, acc.: 54.69%] [G loss: 0.722233]\n",
      "epoch:8 step:7816 [D loss: 0.695757, acc.: 46.88%] [G loss: 0.726302]\n",
      "epoch:8 step:7817 [D loss: 0.715685, acc.: 40.62%] [G loss: 0.693847]\n",
      "epoch:8 step:7818 [D loss: 0.672259, acc.: 57.03%] [G loss: 0.737178]\n",
      "epoch:8 step:7819 [D loss: 0.675249, acc.: 60.16%] [G loss: 0.718106]\n",
      "epoch:8 step:7820 [D loss: 0.685859, acc.: 52.34%] [G loss: 0.679549]\n",
      "epoch:8 step:7821 [D loss: 0.698811, acc.: 47.66%] [G loss: 0.711869]\n",
      "epoch:8 step:7822 [D loss: 0.697777, acc.: 50.78%] [G loss: 0.687264]\n",
      "epoch:8 step:7823 [D loss: 0.680887, acc.: 58.59%] [G loss: 0.722858]\n",
      "epoch:8 step:7824 [D loss: 0.668671, acc.: 59.38%] [G loss: 0.739255]\n",
      "epoch:8 step:7825 [D loss: 0.693338, acc.: 53.91%] [G loss: 0.758060]\n",
      "epoch:8 step:7826 [D loss: 0.690739, acc.: 50.00%] [G loss: 0.736273]\n",
      "epoch:8 step:7827 [D loss: 0.682700, acc.: 51.56%] [G loss: 0.641335]\n",
      "epoch:8 step:7828 [D loss: 0.684211, acc.: 50.00%] [G loss: 0.716253]\n",
      "epoch:8 step:7829 [D loss: 0.691136, acc.: 62.50%] [G loss: 0.715210]\n",
      "epoch:8 step:7830 [D loss: 0.704630, acc.: 48.44%] [G loss: 0.703516]\n",
      "epoch:8 step:7831 [D loss: 0.700289, acc.: 48.44%] [G loss: 0.698196]\n",
      "epoch:8 step:7832 [D loss: 0.679401, acc.: 60.16%] [G loss: 0.723261]\n",
      "epoch:8 step:7833 [D loss: 0.672079, acc.: 57.03%] [G loss: 0.712245]\n",
      "epoch:8 step:7834 [D loss: 0.679569, acc.: 56.25%] [G loss: 0.752623]\n",
      "epoch:8 step:7835 [D loss: 0.689217, acc.: 57.03%] [G loss: 0.707116]\n",
      "epoch:8 step:7836 [D loss: 0.723489, acc.: 46.88%] [G loss: 0.726231]\n",
      "epoch:8 step:7837 [D loss: 0.706145, acc.: 46.09%] [G loss: 0.729271]\n",
      "epoch:8 step:7838 [D loss: 0.708575, acc.: 42.19%] [G loss: 0.717497]\n",
      "epoch:8 step:7839 [D loss: 0.681425, acc.: 54.69%] [G loss: 0.718065]\n",
      "epoch:8 step:7840 [D loss: 0.675169, acc.: 61.72%] [G loss: 0.764662]\n",
      "epoch:8 step:7841 [D loss: 0.696215, acc.: 50.00%] [G loss: 0.771377]\n",
      "epoch:8 step:7842 [D loss: 0.656271, acc.: 67.19%] [G loss: 0.797107]\n",
      "epoch:8 step:7843 [D loss: 0.642758, acc.: 66.41%] [G loss: 0.812473]\n",
      "epoch:8 step:7844 [D loss: 0.693717, acc.: 56.25%] [G loss: 0.729120]\n",
      "epoch:8 step:7845 [D loss: 0.732451, acc.: 43.75%] [G loss: 0.743758]\n",
      "epoch:8 step:7846 [D loss: 0.719219, acc.: 45.31%] [G loss: 0.672159]\n",
      "epoch:8 step:7847 [D loss: 0.703357, acc.: 43.75%] [G loss: 0.734392]\n",
      "epoch:8 step:7848 [D loss: 0.691443, acc.: 51.56%] [G loss: 0.782143]\n",
      "epoch:8 step:7849 [D loss: 0.712443, acc.: 39.84%] [G loss: 0.750362]\n",
      "epoch:8 step:7850 [D loss: 0.694378, acc.: 50.00%] [G loss: 0.812449]\n",
      "epoch:8 step:7851 [D loss: 0.705809, acc.: 44.53%] [G loss: 0.728034]\n",
      "epoch:8 step:7852 [D loss: 0.691882, acc.: 57.81%] [G loss: 0.736947]\n",
      "epoch:8 step:7853 [D loss: 0.693716, acc.: 44.53%] [G loss: 0.768463]\n",
      "epoch:8 step:7854 [D loss: 0.680629, acc.: 57.03%] [G loss: 0.742092]\n",
      "epoch:8 step:7855 [D loss: 0.701924, acc.: 50.78%] [G loss: 0.725774]\n",
      "epoch:8 step:7856 [D loss: 0.695394, acc.: 45.31%] [G loss: 0.758531]\n",
      "epoch:8 step:7857 [D loss: 0.676806, acc.: 53.91%] [G loss: 0.761060]\n",
      "epoch:8 step:7858 [D loss: 0.702812, acc.: 45.31%] [G loss: 0.743653]\n",
      "epoch:8 step:7859 [D loss: 0.682362, acc.: 60.16%] [G loss: 0.724197]\n",
      "epoch:8 step:7860 [D loss: 0.677325, acc.: 57.03%] [G loss: 0.740935]\n",
      "epoch:8 step:7861 [D loss: 0.694215, acc.: 49.22%] [G loss: 0.766872]\n",
      "epoch:8 step:7862 [D loss: 0.707338, acc.: 52.34%] [G loss: 0.697681]\n",
      "epoch:8 step:7863 [D loss: 0.719991, acc.: 40.62%] [G loss: 0.740109]\n",
      "epoch:8 step:7864 [D loss: 0.707276, acc.: 49.22%] [G loss: 0.777520]\n",
      "epoch:8 step:7865 [D loss: 0.676619, acc.: 55.47%] [G loss: 0.823084]\n",
      "epoch:8 step:7866 [D loss: 0.684622, acc.: 57.81%] [G loss: 0.791420]\n",
      "epoch:8 step:7867 [D loss: 0.669356, acc.: 57.81%] [G loss: 0.769932]\n",
      "epoch:8 step:7868 [D loss: 0.680246, acc.: 59.38%] [G loss: 0.765429]\n",
      "epoch:8 step:7869 [D loss: 0.708029, acc.: 42.97%] [G loss: 0.698764]\n",
      "epoch:8 step:7870 [D loss: 0.694001, acc.: 52.34%] [G loss: 0.703951]\n",
      "epoch:8 step:7871 [D loss: 0.712356, acc.: 46.09%] [G loss: 0.665925]\n",
      "epoch:8 step:7872 [D loss: 0.700880, acc.: 39.06%] [G loss: 0.664410]\n",
      "epoch:8 step:7873 [D loss: 0.732947, acc.: 33.59%] [G loss: 0.690133]\n",
      "epoch:8 step:7874 [D loss: 0.699894, acc.: 50.00%] [G loss: 0.680373]\n",
      "epoch:8 step:7875 [D loss: 0.691452, acc.: 53.12%] [G loss: 0.726979]\n",
      "epoch:8 step:7876 [D loss: 0.660326, acc.: 57.03%] [G loss: 0.745259]\n",
      "epoch:8 step:7877 [D loss: 0.675112, acc.: 56.25%] [G loss: 0.775769]\n",
      "epoch:8 step:7878 [D loss: 0.662998, acc.: 62.50%] [G loss: 0.789169]\n",
      "epoch:8 step:7879 [D loss: 0.678368, acc.: 58.59%] [G loss: 0.754349]\n",
      "epoch:8 step:7880 [D loss: 0.696655, acc.: 50.78%] [G loss: 0.736326]\n",
      "epoch:8 step:7881 [D loss: 0.686140, acc.: 56.25%] [G loss: 0.751395]\n",
      "epoch:8 step:7882 [D loss: 0.688255, acc.: 51.56%] [G loss: 0.754065]\n",
      "epoch:8 step:7883 [D loss: 0.680285, acc.: 51.56%] [G loss: 0.708893]\n",
      "epoch:8 step:7884 [D loss: 0.697158, acc.: 46.88%] [G loss: 0.722099]\n",
      "epoch:8 step:7885 [D loss: 0.713196, acc.: 42.19%] [G loss: 0.697878]\n",
      "epoch:8 step:7886 [D loss: 0.725517, acc.: 33.59%] [G loss: 0.699543]\n",
      "epoch:8 step:7887 [D loss: 0.695706, acc.: 53.91%] [G loss: 0.712858]\n",
      "epoch:8 step:7888 [D loss: 0.717803, acc.: 44.53%] [G loss: 0.703505]\n",
      "epoch:8 step:7889 [D loss: 0.703885, acc.: 39.06%] [G loss: 0.707163]\n",
      "epoch:8 step:7890 [D loss: 0.682937, acc.: 53.12%] [G loss: 0.729657]\n",
      "epoch:8 step:7891 [D loss: 0.684973, acc.: 57.81%] [G loss: 0.723469]\n",
      "epoch:8 step:7892 [D loss: 0.702353, acc.: 46.88%] [G loss: 0.736340]\n",
      "epoch:8 step:7893 [D loss: 0.689600, acc.: 53.12%] [G loss: 0.732758]\n",
      "epoch:8 step:7894 [D loss: 0.674149, acc.: 57.03%] [G loss: 0.711973]\n",
      "epoch:8 step:7895 [D loss: 0.688745, acc.: 47.66%] [G loss: 0.747267]\n",
      "epoch:8 step:7896 [D loss: 0.683293, acc.: 51.56%] [G loss: 0.761523]\n",
      "epoch:8 step:7897 [D loss: 0.672908, acc.: 58.59%] [G loss: 0.770510]\n",
      "epoch:8 step:7898 [D loss: 0.669527, acc.: 57.81%] [G loss: 0.754341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7899 [D loss: 0.687071, acc.: 50.78%] [G loss: 0.730231]\n",
      "epoch:8 step:7900 [D loss: 0.653219, acc.: 63.28%] [G loss: 0.727439]\n",
      "epoch:8 step:7901 [D loss: 0.669407, acc.: 59.38%] [G loss: 0.744765]\n",
      "epoch:8 step:7902 [D loss: 0.676159, acc.: 57.03%] [G loss: 0.764470]\n",
      "epoch:8 step:7903 [D loss: 0.684489, acc.: 54.69%] [G loss: 0.763556]\n",
      "epoch:8 step:7904 [D loss: 0.700952, acc.: 53.12%] [G loss: 0.723072]\n",
      "epoch:8 step:7905 [D loss: 0.704262, acc.: 51.56%] [G loss: 0.740272]\n",
      "epoch:8 step:7906 [D loss: 0.694163, acc.: 58.59%] [G loss: 0.694584]\n",
      "epoch:8 step:7907 [D loss: 0.752486, acc.: 39.06%] [G loss: 0.706559]\n",
      "epoch:8 step:7908 [D loss: 0.701507, acc.: 47.66%] [G loss: 0.740390]\n",
      "epoch:8 step:7909 [D loss: 0.708218, acc.: 40.62%] [G loss: 0.694553]\n",
      "epoch:8 step:7910 [D loss: 0.699355, acc.: 48.44%] [G loss: 0.744849]\n",
      "epoch:8 step:7911 [D loss: 0.683447, acc.: 56.25%] [G loss: 0.736058]\n",
      "epoch:8 step:7912 [D loss: 0.681409, acc.: 55.47%] [G loss: 0.750694]\n",
      "epoch:8 step:7913 [D loss: 0.679150, acc.: 58.59%] [G loss: 0.743763]\n",
      "epoch:8 step:7914 [D loss: 0.691359, acc.: 53.12%] [G loss: 0.748666]\n",
      "epoch:8 step:7915 [D loss: 0.686044, acc.: 52.34%] [G loss: 0.753975]\n",
      "epoch:8 step:7916 [D loss: 0.697169, acc.: 46.09%] [G loss: 0.759400]\n",
      "epoch:8 step:7917 [D loss: 0.699433, acc.: 48.44%] [G loss: 0.755871]\n",
      "epoch:8 step:7918 [D loss: 0.712591, acc.: 44.53%] [G loss: 0.785949]\n",
      "epoch:8 step:7919 [D loss: 0.693820, acc.: 51.56%] [G loss: 0.753060]\n",
      "epoch:8 step:7920 [D loss: 0.689706, acc.: 52.34%] [G loss: 0.744893]\n",
      "epoch:8 step:7921 [D loss: 0.673934, acc.: 64.84%] [G loss: 0.768296]\n",
      "epoch:8 step:7922 [D loss: 0.671917, acc.: 61.72%] [G loss: 0.738558]\n",
      "epoch:8 step:7923 [D loss: 0.672618, acc.: 54.69%] [G loss: 0.746395]\n",
      "epoch:8 step:7924 [D loss: 0.667359, acc.: 60.16%] [G loss: 0.772146]\n",
      "epoch:8 step:7925 [D loss: 0.682682, acc.: 53.91%] [G loss: 0.797427]\n",
      "epoch:8 step:7926 [D loss: 0.681232, acc.: 53.12%] [G loss: 0.728740]\n",
      "epoch:8 step:7927 [D loss: 0.723625, acc.: 42.97%] [G loss: 0.745288]\n",
      "epoch:8 step:7928 [D loss: 0.707449, acc.: 50.00%] [G loss: 0.737902]\n",
      "epoch:8 step:7929 [D loss: 0.699428, acc.: 45.31%] [G loss: 0.724439]\n",
      "epoch:8 step:7930 [D loss: 0.690142, acc.: 56.25%] [G loss: 0.734960]\n",
      "epoch:8 step:7931 [D loss: 0.697366, acc.: 50.00%] [G loss: 0.754775]\n",
      "epoch:8 step:7932 [D loss: 0.671297, acc.: 60.94%] [G loss: 0.726342]\n",
      "epoch:8 step:7933 [D loss: 0.716703, acc.: 39.84%] [G loss: 0.734667]\n",
      "epoch:8 step:7934 [D loss: 0.689112, acc.: 50.00%] [G loss: 0.737386]\n",
      "epoch:8 step:7935 [D loss: 0.703359, acc.: 49.22%] [G loss: 0.739931]\n",
      "epoch:8 step:7936 [D loss: 0.683623, acc.: 58.59%] [G loss: 0.771794]\n",
      "epoch:8 step:7937 [D loss: 0.701017, acc.: 48.44%] [G loss: 0.753626]\n",
      "epoch:8 step:7938 [D loss: 0.688464, acc.: 53.12%] [G loss: 0.751562]\n",
      "epoch:8 step:7939 [D loss: 0.674430, acc.: 57.81%] [G loss: 0.770405]\n",
      "epoch:8 step:7940 [D loss: 0.672447, acc.: 60.16%] [G loss: 0.758157]\n",
      "epoch:8 step:7941 [D loss: 0.671479, acc.: 60.16%] [G loss: 0.736942]\n",
      "epoch:8 step:7942 [D loss: 0.677382, acc.: 54.69%] [G loss: 0.753816]\n",
      "epoch:8 step:7943 [D loss: 0.683981, acc.: 52.34%] [G loss: 0.757518]\n",
      "epoch:8 step:7944 [D loss: 0.697469, acc.: 52.34%] [G loss: 0.724217]\n",
      "epoch:8 step:7945 [D loss: 0.682012, acc.: 53.12%] [G loss: 0.733322]\n",
      "epoch:8 step:7946 [D loss: 0.678244, acc.: 59.38%] [G loss: 0.704226]\n",
      "epoch:8 step:7947 [D loss: 0.678626, acc.: 53.91%] [G loss: 0.703474]\n",
      "epoch:8 step:7948 [D loss: 0.658255, acc.: 62.50%] [G loss: 0.742202]\n",
      "epoch:8 step:7949 [D loss: 0.647833, acc.: 64.84%] [G loss: 0.710142]\n",
      "epoch:8 step:7950 [D loss: 0.680980, acc.: 55.47%] [G loss: 0.850185]\n",
      "epoch:8 step:7951 [D loss: 0.697772, acc.: 51.56%] [G loss: 0.733107]\n",
      "epoch:8 step:7952 [D loss: 0.536355, acc.: 67.19%] [G loss: 0.843539]\n",
      "epoch:8 step:7953 [D loss: 0.675923, acc.: 60.94%] [G loss: 0.710248]\n",
      "epoch:8 step:7954 [D loss: 0.709252, acc.: 44.53%] [G loss: 0.742924]\n",
      "epoch:8 step:7955 [D loss: 0.721971, acc.: 46.88%] [G loss: 0.690226]\n",
      "epoch:8 step:7956 [D loss: 0.724030, acc.: 34.38%] [G loss: 0.677519]\n",
      "epoch:8 step:7957 [D loss: 0.716835, acc.: 46.09%] [G loss: 0.703991]\n",
      "epoch:8 step:7958 [D loss: 0.739017, acc.: 31.25%] [G loss: 0.649375]\n",
      "epoch:8 step:7959 [D loss: 0.688382, acc.: 51.56%] [G loss: 0.729097]\n",
      "epoch:8 step:7960 [D loss: 0.705103, acc.: 46.09%] [G loss: 0.725442]\n",
      "epoch:8 step:7961 [D loss: 0.732594, acc.: 42.19%] [G loss: 0.734495]\n",
      "epoch:8 step:7962 [D loss: 0.692117, acc.: 60.16%] [G loss: 0.727846]\n",
      "epoch:8 step:7963 [D loss: 0.686952, acc.: 52.34%] [G loss: 0.731244]\n",
      "epoch:8 step:7964 [D loss: 0.640868, acc.: 67.97%] [G loss: 0.742427]\n",
      "epoch:8 step:7965 [D loss: 0.672017, acc.: 57.03%] [G loss: 0.775969]\n",
      "epoch:8 step:7966 [D loss: 0.648141, acc.: 69.53%] [G loss: 0.811913]\n",
      "epoch:8 step:7967 [D loss: 0.661584, acc.: 63.28%] [G loss: 0.748574]\n",
      "epoch:8 step:7968 [D loss: 0.693938, acc.: 55.47%] [G loss: 0.746001]\n",
      "epoch:8 step:7969 [D loss: 0.735657, acc.: 41.41%] [G loss: 0.740252]\n",
      "epoch:8 step:7970 [D loss: 0.706078, acc.: 46.09%] [G loss: 0.757971]\n",
      "epoch:8 step:7971 [D loss: 0.676087, acc.: 63.28%] [G loss: 0.736305]\n",
      "epoch:8 step:7972 [D loss: 0.676970, acc.: 56.25%] [G loss: 0.785142]\n",
      "epoch:8 step:7973 [D loss: 0.693065, acc.: 53.12%] [G loss: 0.773217]\n",
      "epoch:8 step:7974 [D loss: 0.714760, acc.: 51.56%] [G loss: 0.758372]\n",
      "epoch:8 step:7975 [D loss: 0.728079, acc.: 37.50%] [G loss: 0.734073]\n",
      "epoch:8 step:7976 [D loss: 0.697227, acc.: 50.00%] [G loss: 0.722088]\n",
      "epoch:8 step:7977 [D loss: 0.650542, acc.: 63.28%] [G loss: 0.721632]\n",
      "epoch:8 step:7978 [D loss: 0.713850, acc.: 47.66%] [G loss: 0.768090]\n",
      "epoch:8 step:7979 [D loss: 0.669897, acc.: 57.03%] [G loss: 0.779754]\n",
      "epoch:8 step:7980 [D loss: 0.671644, acc.: 60.94%] [G loss: 0.788366]\n",
      "epoch:8 step:7981 [D loss: 0.657744, acc.: 57.81%] [G loss: 0.889168]\n",
      "epoch:8 step:7982 [D loss: 0.654644, acc.: 62.50%] [G loss: 0.807961]\n",
      "epoch:8 step:7983 [D loss: 0.707381, acc.: 51.56%] [G loss: 0.825980]\n",
      "epoch:8 step:7984 [D loss: 0.689945, acc.: 55.47%] [G loss: 0.733103]\n",
      "epoch:8 step:7985 [D loss: 0.718233, acc.: 47.66%] [G loss: 0.779341]\n",
      "epoch:8 step:7986 [D loss: 0.710698, acc.: 43.75%] [G loss: 0.739718]\n",
      "epoch:8 step:7987 [D loss: 0.697824, acc.: 51.56%] [G loss: 0.727699]\n",
      "epoch:8 step:7988 [D loss: 0.715178, acc.: 43.75%] [G loss: 0.682028]\n",
      "epoch:8 step:7989 [D loss: 0.703288, acc.: 47.66%] [G loss: 0.714002]\n",
      "epoch:8 step:7990 [D loss: 0.698894, acc.: 49.22%] [G loss: 0.739875]\n",
      "epoch:8 step:7991 [D loss: 0.693809, acc.: 50.78%] [G loss: 0.758972]\n",
      "epoch:8 step:7992 [D loss: 0.691562, acc.: 53.91%] [G loss: 0.744117]\n",
      "epoch:8 step:7993 [D loss: 0.659486, acc.: 65.62%] [G loss: 0.731120]\n",
      "epoch:8 step:7994 [D loss: 0.677507, acc.: 61.72%] [G loss: 0.767723]\n",
      "epoch:8 step:7995 [D loss: 0.642321, acc.: 69.53%] [G loss: 0.776706]\n",
      "epoch:8 step:7996 [D loss: 0.697948, acc.: 49.22%] [G loss: 0.741066]\n",
      "epoch:8 step:7997 [D loss: 0.715392, acc.: 41.41%] [G loss: 0.724060]\n",
      "epoch:8 step:7998 [D loss: 0.697986, acc.: 46.88%] [G loss: 0.765560]\n",
      "epoch:8 step:7999 [D loss: 0.708372, acc.: 45.31%] [G loss: 0.752416]\n",
      "epoch:8 step:8000 [D loss: 0.690321, acc.: 49.22%] [G loss: 0.735253]\n",
      "epoch:8 step:8001 [D loss: 0.680205, acc.: 51.56%] [G loss: 0.752890]\n",
      "epoch:8 step:8002 [D loss: 0.684168, acc.: 57.03%] [G loss: 0.758084]\n",
      "epoch:8 step:8003 [D loss: 0.656326, acc.: 68.75%] [G loss: 0.742010]\n",
      "epoch:8 step:8004 [D loss: 0.661041, acc.: 64.84%] [G loss: 0.743959]\n",
      "epoch:8 step:8005 [D loss: 0.718294, acc.: 48.44%] [G loss: 0.727571]\n",
      "epoch:8 step:8006 [D loss: 0.705860, acc.: 49.22%] [G loss: 0.786011]\n",
      "epoch:8 step:8007 [D loss: 0.713167, acc.: 38.28%] [G loss: 0.722951]\n",
      "epoch:8 step:8008 [D loss: 0.691322, acc.: 50.78%] [G loss: 0.739174]\n",
      "epoch:8 step:8009 [D loss: 0.686788, acc.: 55.47%] [G loss: 0.748668]\n",
      "epoch:8 step:8010 [D loss: 0.674723, acc.: 58.59%] [G loss: 0.772407]\n",
      "epoch:8 step:8011 [D loss: 0.676326, acc.: 58.59%] [G loss: 0.750052]\n",
      "epoch:8 step:8012 [D loss: 0.678644, acc.: 57.03%] [G loss: 0.753246]\n",
      "epoch:8 step:8013 [D loss: 0.676284, acc.: 50.00%] [G loss: 0.716670]\n",
      "epoch:8 step:8014 [D loss: 0.684230, acc.: 53.91%] [G loss: 0.707651]\n",
      "epoch:8 step:8015 [D loss: 0.676801, acc.: 53.91%] [G loss: 0.699375]\n",
      "epoch:8 step:8016 [D loss: 0.668409, acc.: 59.38%] [G loss: 0.696154]\n",
      "epoch:8 step:8017 [D loss: 0.708702, acc.: 48.44%] [G loss: 0.716162]\n",
      "epoch:8 step:8018 [D loss: 0.690985, acc.: 53.91%] [G loss: 0.768492]\n",
      "epoch:8 step:8019 [D loss: 0.681775, acc.: 56.25%] [G loss: 0.736118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8020 [D loss: 0.718585, acc.: 49.22%] [G loss: 0.745002]\n",
      "epoch:8 step:8021 [D loss: 0.713913, acc.: 40.62%] [G loss: 0.710433]\n",
      "epoch:8 step:8022 [D loss: 0.697243, acc.: 50.78%] [G loss: 0.733801]\n",
      "epoch:8 step:8023 [D loss: 0.703954, acc.: 53.12%] [G loss: 0.697922]\n",
      "epoch:8 step:8024 [D loss: 0.696644, acc.: 50.78%] [G loss: 0.729725]\n",
      "epoch:8 step:8025 [D loss: 0.684737, acc.: 53.12%] [G loss: 0.735619]\n",
      "epoch:8 step:8026 [D loss: 0.678629, acc.: 55.47%] [G loss: 0.776383]\n",
      "epoch:8 step:8027 [D loss: 0.687842, acc.: 62.50%] [G loss: 0.673185]\n",
      "epoch:8 step:8028 [D loss: 0.696823, acc.: 50.78%] [G loss: 0.754331]\n",
      "epoch:8 step:8029 [D loss: 0.709098, acc.: 50.00%] [G loss: 0.735329]\n",
      "epoch:8 step:8030 [D loss: 0.680043, acc.: 54.69%] [G loss: 0.714063]\n",
      "epoch:8 step:8031 [D loss: 0.684166, acc.: 53.91%] [G loss: 0.753102]\n",
      "epoch:8 step:8032 [D loss: 0.682122, acc.: 55.47%] [G loss: 0.729408]\n",
      "epoch:8 step:8033 [D loss: 0.685506, acc.: 54.69%] [G loss: 0.765620]\n",
      "epoch:8 step:8034 [D loss: 0.655110, acc.: 61.72%] [G loss: 0.727573]\n",
      "epoch:8 step:8035 [D loss: 0.689578, acc.: 52.34%] [G loss: 0.763612]\n",
      "epoch:8 step:8036 [D loss: 0.658021, acc.: 60.94%] [G loss: 0.702368]\n",
      "epoch:8 step:8037 [D loss: 0.650571, acc.: 62.50%] [G loss: 0.757395]\n",
      "epoch:8 step:8038 [D loss: 0.810219, acc.: 22.66%] [G loss: 0.753139]\n",
      "epoch:8 step:8039 [D loss: 0.685072, acc.: 57.81%] [G loss: 0.793201]\n",
      "epoch:8 step:8040 [D loss: 0.713697, acc.: 50.00%] [G loss: 0.741812]\n",
      "epoch:8 step:8041 [D loss: 0.710499, acc.: 50.00%] [G loss: 0.746028]\n",
      "epoch:8 step:8042 [D loss: 0.685462, acc.: 62.50%] [G loss: 0.755588]\n",
      "epoch:8 step:8043 [D loss: 0.696057, acc.: 51.56%] [G loss: 0.773046]\n",
      "epoch:8 step:8044 [D loss: 0.674411, acc.: 58.59%] [G loss: 0.757885]\n",
      "epoch:8 step:8045 [D loss: 0.675994, acc.: 57.81%] [G loss: 0.747608]\n",
      "epoch:8 step:8046 [D loss: 0.550922, acc.: 68.75%] [G loss: 0.748240]\n",
      "epoch:8 step:8047 [D loss: 0.661621, acc.: 64.84%] [G loss: 0.754910]\n",
      "epoch:8 step:8048 [D loss: 0.661824, acc.: 57.03%] [G loss: 0.739272]\n",
      "epoch:8 step:8049 [D loss: 0.705690, acc.: 47.66%] [G loss: 0.722515]\n",
      "epoch:8 step:8050 [D loss: 0.664960, acc.: 57.81%] [G loss: 0.733082]\n",
      "epoch:8 step:8051 [D loss: 0.672588, acc.: 57.03%] [G loss: 0.688721]\n",
      "epoch:8 step:8052 [D loss: 0.671076, acc.: 62.50%] [G loss: 0.749231]\n",
      "epoch:8 step:8053 [D loss: 0.740300, acc.: 39.06%] [G loss: 0.643156]\n",
      "epoch:8 step:8054 [D loss: 0.653305, acc.: 60.94%] [G loss: 0.675496]\n",
      "epoch:8 step:8055 [D loss: 0.902923, acc.: 21.88%] [G loss: 0.836942]\n",
      "epoch:8 step:8056 [D loss: 0.683920, acc.: 50.78%] [G loss: 0.833842]\n",
      "epoch:8 step:8057 [D loss: 0.660755, acc.: 50.00%] [G loss: 1.221767]\n",
      "epoch:8 step:8058 [D loss: 0.717490, acc.: 50.78%] [G loss: 0.779354]\n",
      "epoch:8 step:8059 [D loss: 0.714023, acc.: 46.09%] [G loss: 0.785904]\n",
      "epoch:8 step:8060 [D loss: 0.705719, acc.: 50.78%] [G loss: 0.817709]\n",
      "epoch:8 step:8061 [D loss: 0.690590, acc.: 51.56%] [G loss: 0.758879]\n",
      "epoch:8 step:8062 [D loss: 0.683254, acc.: 56.25%] [G loss: 0.781376]\n",
      "epoch:8 step:8063 [D loss: 0.679116, acc.: 64.84%] [G loss: 0.764356]\n",
      "epoch:8 step:8064 [D loss: 0.678557, acc.: 54.69%] [G loss: 0.795466]\n",
      "epoch:8 step:8065 [D loss: 0.694078, acc.: 54.69%] [G loss: 0.762572]\n",
      "epoch:8 step:8066 [D loss: 0.664621, acc.: 64.84%] [G loss: 0.777934]\n",
      "epoch:8 step:8067 [D loss: 0.691252, acc.: 52.34%] [G loss: 0.776507]\n",
      "epoch:8 step:8068 [D loss: 0.714455, acc.: 45.31%] [G loss: 0.743036]\n",
      "epoch:8 step:8069 [D loss: 0.687300, acc.: 55.47%] [G loss: 0.770713]\n",
      "epoch:8 step:8070 [D loss: 0.663462, acc.: 60.94%] [G loss: 0.793339]\n",
      "epoch:8 step:8071 [D loss: 0.673215, acc.: 62.50%] [G loss: 1.136714]\n",
      "epoch:8 step:8072 [D loss: 0.712467, acc.: 41.41%] [G loss: 0.757400]\n",
      "epoch:8 step:8073 [D loss: 0.690776, acc.: 51.56%] [G loss: 0.747402]\n",
      "epoch:8 step:8074 [D loss: 0.689690, acc.: 48.44%] [G loss: 0.718222]\n",
      "epoch:8 step:8075 [D loss: 0.700888, acc.: 45.31%] [G loss: 0.704084]\n",
      "epoch:8 step:8076 [D loss: 0.730033, acc.: 39.06%] [G loss: 0.725575]\n",
      "epoch:8 step:8077 [D loss: 0.688460, acc.: 53.91%] [G loss: 0.729284]\n",
      "epoch:8 step:8078 [D loss: 0.688069, acc.: 54.69%] [G loss: 0.736990]\n",
      "epoch:8 step:8079 [D loss: 0.695842, acc.: 47.66%] [G loss: 0.752882]\n",
      "epoch:8 step:8080 [D loss: 0.680972, acc.: 64.06%] [G loss: 0.767770]\n",
      "epoch:8 step:8081 [D loss: 0.667598, acc.: 59.38%] [G loss: 0.763492]\n",
      "epoch:8 step:8082 [D loss: 0.661818, acc.: 62.50%] [G loss: 0.760379]\n",
      "epoch:8 step:8083 [D loss: 0.686216, acc.: 57.03%] [G loss: 0.787695]\n",
      "epoch:8 step:8084 [D loss: 0.676416, acc.: 58.59%] [G loss: 0.762445]\n",
      "epoch:8 step:8085 [D loss: 0.671146, acc.: 57.03%] [G loss: 0.740458]\n",
      "epoch:8 step:8086 [D loss: 0.665412, acc.: 62.50%] [G loss: 0.754347]\n",
      "epoch:8 step:8087 [D loss: 0.663249, acc.: 55.47%] [G loss: 0.742346]\n",
      "epoch:8 step:8088 [D loss: 0.650628, acc.: 63.28%] [G loss: 0.820582]\n",
      "epoch:8 step:8089 [D loss: 0.703144, acc.: 49.22%] [G loss: 0.821481]\n",
      "epoch:8 step:8090 [D loss: 0.704142, acc.: 50.00%] [G loss: 0.713823]\n",
      "epoch:8 step:8091 [D loss: 0.720473, acc.: 50.00%] [G loss: 0.770982]\n",
      "epoch:8 step:8092 [D loss: 0.658359, acc.: 58.59%] [G loss: 0.745180]\n",
      "epoch:8 step:8093 [D loss: 0.690201, acc.: 50.78%] [G loss: 0.743307]\n",
      "epoch:8 step:8094 [D loss: 0.683886, acc.: 55.47%] [G loss: 0.793847]\n",
      "epoch:8 step:8095 [D loss: 0.686261, acc.: 53.12%] [G loss: 0.697276]\n",
      "epoch:8 step:8096 [D loss: 0.714561, acc.: 42.19%] [G loss: 0.717611]\n",
      "epoch:8 step:8097 [D loss: 0.705311, acc.: 46.09%] [G loss: 0.803710]\n",
      "epoch:8 step:8098 [D loss: 0.691288, acc.: 56.25%] [G loss: 0.792520]\n",
      "epoch:8 step:8099 [D loss: 0.696491, acc.: 50.78%] [G loss: 0.857433]\n",
      "epoch:8 step:8100 [D loss: 0.743724, acc.: 42.97%] [G loss: 0.764167]\n",
      "epoch:8 step:8101 [D loss: 0.698117, acc.: 57.03%] [G loss: 0.722285]\n",
      "epoch:8 step:8102 [D loss: 0.697107, acc.: 45.31%] [G loss: 0.748507]\n",
      "epoch:8 step:8103 [D loss: 0.682505, acc.: 54.69%] [G loss: 0.781133]\n",
      "epoch:8 step:8104 [D loss: 0.686904, acc.: 57.03%] [G loss: 0.744597]\n",
      "epoch:8 step:8105 [D loss: 0.697374, acc.: 50.78%] [G loss: 0.752972]\n",
      "epoch:8 step:8106 [D loss: 0.681816, acc.: 61.72%] [G loss: 0.763491]\n",
      "epoch:8 step:8107 [D loss: 0.666312, acc.: 57.81%] [G loss: 0.758918]\n",
      "epoch:8 step:8108 [D loss: 0.677900, acc.: 56.25%] [G loss: 0.748211]\n",
      "epoch:8 step:8109 [D loss: 0.675970, acc.: 53.12%] [G loss: 0.739393]\n",
      "epoch:8 step:8110 [D loss: 0.690136, acc.: 55.47%] [G loss: 0.721081]\n",
      "epoch:8 step:8111 [D loss: 0.691157, acc.: 50.78%] [G loss: 0.718695]\n",
      "epoch:8 step:8112 [D loss: 0.712002, acc.: 45.31%] [G loss: 0.717627]\n",
      "epoch:8 step:8113 [D loss: 0.702662, acc.: 47.66%] [G loss: 0.736559]\n",
      "epoch:8 step:8114 [D loss: 0.675981, acc.: 57.03%] [G loss: 0.746812]\n",
      "epoch:8 step:8115 [D loss: 0.681714, acc.: 53.91%] [G loss: 0.729886]\n",
      "epoch:8 step:8116 [D loss: 0.676840, acc.: 57.03%] [G loss: 0.717585]\n",
      "epoch:8 step:8117 [D loss: 0.708510, acc.: 48.44%] [G loss: 0.717970]\n",
      "epoch:8 step:8118 [D loss: 0.691432, acc.: 51.56%] [G loss: 0.765600]\n",
      "epoch:8 step:8119 [D loss: 0.701117, acc.: 56.25%] [G loss: 0.758048]\n",
      "epoch:8 step:8120 [D loss: 0.667503, acc.: 57.03%] [G loss: 0.745026]\n",
      "epoch:8 step:8121 [D loss: 0.695984, acc.: 49.22%] [G loss: 0.738956]\n",
      "epoch:8 step:8122 [D loss: 0.702460, acc.: 51.56%] [G loss: 0.740458]\n",
      "epoch:8 step:8123 [D loss: 0.677591, acc.: 57.81%] [G loss: 0.753148]\n",
      "epoch:8 step:8124 [D loss: 0.693226, acc.: 54.69%] [G loss: 0.747514]\n",
      "epoch:8 step:8125 [D loss: 0.675408, acc.: 57.03%] [G loss: 0.713866]\n",
      "epoch:8 step:8126 [D loss: 0.699250, acc.: 51.56%] [G loss: 0.711527]\n",
      "epoch:8 step:8127 [D loss: 0.699966, acc.: 44.53%] [G loss: 0.738219]\n",
      "epoch:8 step:8128 [D loss: 0.683826, acc.: 53.12%] [G loss: 0.762768]\n",
      "epoch:8 step:8129 [D loss: 0.701905, acc.: 53.12%] [G loss: 0.753054]\n",
      "epoch:8 step:8130 [D loss: 0.679791, acc.: 54.69%] [G loss: 0.751398]\n",
      "epoch:8 step:8131 [D loss: 0.680356, acc.: 53.91%] [G loss: 0.758079]\n",
      "epoch:8 step:8132 [D loss: 0.712801, acc.: 45.31%] [G loss: 0.735432]\n",
      "epoch:8 step:8133 [D loss: 0.684632, acc.: 56.25%] [G loss: 0.758191]\n",
      "epoch:8 step:8134 [D loss: 0.688546, acc.: 53.91%] [G loss: 0.773328]\n",
      "epoch:8 step:8135 [D loss: 0.691762, acc.: 46.88%] [G loss: 0.760237]\n",
      "epoch:8 step:8136 [D loss: 0.696091, acc.: 48.44%] [G loss: 0.769400]\n",
      "epoch:8 step:8137 [D loss: 0.699126, acc.: 50.78%] [G loss: 0.758825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8138 [D loss: 0.681574, acc.: 56.25%] [G loss: 0.770021]\n",
      "epoch:8 step:8139 [D loss: 0.686264, acc.: 56.25%] [G loss: 0.742692]\n",
      "epoch:8 step:8140 [D loss: 0.688313, acc.: 56.25%] [G loss: 0.761711]\n",
      "epoch:8 step:8141 [D loss: 0.696277, acc.: 49.22%] [G loss: 0.743980]\n",
      "epoch:8 step:8142 [D loss: 0.660849, acc.: 60.16%] [G loss: 0.758805]\n",
      "epoch:8 step:8143 [D loss: 0.687846, acc.: 49.22%] [G loss: 0.743637]\n",
      "epoch:8 step:8144 [D loss: 0.667743, acc.: 64.06%] [G loss: 0.745393]\n",
      "epoch:8 step:8145 [D loss: 0.660156, acc.: 62.50%] [G loss: 0.748349]\n",
      "epoch:8 step:8146 [D loss: 0.662324, acc.: 55.47%] [G loss: 0.767293]\n",
      "epoch:8 step:8147 [D loss: 0.683567, acc.: 51.56%] [G loss: 0.733354]\n",
      "epoch:8 step:8148 [D loss: 0.718624, acc.: 46.09%] [G loss: 0.732960]\n",
      "epoch:8 step:8149 [D loss: 0.694982, acc.: 48.44%] [G loss: 0.693636]\n",
      "epoch:8 step:8150 [D loss: 0.687749, acc.: 57.03%] [G loss: 0.784716]\n",
      "epoch:8 step:8151 [D loss: 0.703419, acc.: 46.88%] [G loss: 0.699027]\n",
      "epoch:8 step:8152 [D loss: 0.683186, acc.: 53.91%] [G loss: 0.767600]\n",
      "epoch:8 step:8153 [D loss: 0.688518, acc.: 55.47%] [G loss: 0.737998]\n",
      "epoch:8 step:8154 [D loss: 0.676325, acc.: 57.81%] [G loss: 0.733819]\n",
      "epoch:8 step:8155 [D loss: 0.678825, acc.: 58.59%] [G loss: 0.716957]\n",
      "epoch:8 step:8156 [D loss: 0.684612, acc.: 57.03%] [G loss: 0.750101]\n",
      "epoch:8 step:8157 [D loss: 0.671843, acc.: 55.47%] [G loss: 0.776412]\n",
      "epoch:8 step:8158 [D loss: 0.685962, acc.: 50.00%] [G loss: 0.772704]\n",
      "epoch:8 step:8159 [D loss: 0.721078, acc.: 37.50%] [G loss: 0.734269]\n",
      "epoch:8 step:8160 [D loss: 0.651810, acc.: 64.06%] [G loss: 0.775179]\n",
      "epoch:8 step:8161 [D loss: 0.678251, acc.: 49.22%] [G loss: 0.721546]\n",
      "epoch:8 step:8162 [D loss: 0.676569, acc.: 57.03%] [G loss: 0.766931]\n",
      "epoch:8 step:8163 [D loss: 0.690357, acc.: 53.91%] [G loss: 0.752468]\n",
      "epoch:8 step:8164 [D loss: 0.687275, acc.: 57.03%] [G loss: 0.767427]\n",
      "epoch:8 step:8165 [D loss: 0.657306, acc.: 57.81%] [G loss: 0.739173]\n",
      "epoch:8 step:8166 [D loss: 0.684712, acc.: 52.34%] [G loss: 0.722725]\n",
      "epoch:8 step:8167 [D loss: 0.701586, acc.: 54.69%] [G loss: 0.516300]\n",
      "epoch:8 step:8168 [D loss: 0.697662, acc.: 50.00%] [G loss: 0.692804]\n",
      "epoch:8 step:8169 [D loss: 0.680228, acc.: 50.00%] [G loss: 0.741119]\n",
      "epoch:8 step:8170 [D loss: 0.658487, acc.: 57.03%] [G loss: 0.706266]\n",
      "epoch:8 step:8171 [D loss: 0.721392, acc.: 49.22%] [G loss: 0.744751]\n",
      "epoch:8 step:8172 [D loss: 0.676132, acc.: 60.16%] [G loss: 0.692248]\n",
      "epoch:8 step:8173 [D loss: 0.643118, acc.: 63.28%] [G loss: 0.740910]\n",
      "epoch:8 step:8174 [D loss: 0.683215, acc.: 57.03%] [G loss: 0.756952]\n",
      "epoch:8 step:8175 [D loss: 0.707186, acc.: 53.91%] [G loss: 0.771106]\n",
      "epoch:8 step:8176 [D loss: 0.676958, acc.: 61.72%] [G loss: 0.828788]\n",
      "epoch:8 step:8177 [D loss: 0.686986, acc.: 60.94%] [G loss: 0.769290]\n",
      "epoch:8 step:8178 [D loss: 0.692759, acc.: 53.91%] [G loss: 0.739130]\n",
      "epoch:8 step:8179 [D loss: 0.699220, acc.: 47.66%] [G loss: 0.747583]\n",
      "epoch:8 step:8180 [D loss: 0.675890, acc.: 53.91%] [G loss: 0.761736]\n",
      "epoch:8 step:8181 [D loss: 0.675384, acc.: 59.38%] [G loss: 0.725596]\n",
      "epoch:8 step:8182 [D loss: 0.690027, acc.: 50.78%] [G loss: 0.769210]\n",
      "epoch:8 step:8183 [D loss: 0.673457, acc.: 57.03%] [G loss: 0.791868]\n",
      "epoch:8 step:8184 [D loss: 0.703249, acc.: 53.12%] [G loss: 0.721426]\n",
      "epoch:8 step:8185 [D loss: 0.732766, acc.: 50.00%] [G loss: 0.741733]\n",
      "epoch:8 step:8186 [D loss: 0.706028, acc.: 46.88%] [G loss: 0.727001]\n",
      "epoch:8 step:8187 [D loss: 0.697554, acc.: 50.00%] [G loss: 0.715422]\n",
      "epoch:8 step:8188 [D loss: 0.700781, acc.: 48.44%] [G loss: 0.732787]\n",
      "epoch:8 step:8189 [D loss: 0.683767, acc.: 59.38%] [G loss: 0.734512]\n",
      "epoch:8 step:8190 [D loss: 0.676469, acc.: 56.25%] [G loss: 0.725427]\n",
      "epoch:8 step:8191 [D loss: 0.715056, acc.: 40.62%] [G loss: 0.709925]\n",
      "epoch:8 step:8192 [D loss: 0.712239, acc.: 40.62%] [G loss: 0.732238]\n",
      "epoch:8 step:8193 [D loss: 0.703474, acc.: 45.31%] [G loss: 0.747660]\n",
      "epoch:8 step:8194 [D loss: 0.690388, acc.: 50.78%] [G loss: 0.735241]\n",
      "epoch:8 step:8195 [D loss: 0.693608, acc.: 46.09%] [G loss: 0.746260]\n",
      "epoch:8 step:8196 [D loss: 0.670933, acc.: 60.16%] [G loss: 0.774344]\n",
      "epoch:8 step:8197 [D loss: 0.686653, acc.: 52.34%] [G loss: 0.751663]\n",
      "epoch:8 step:8198 [D loss: 0.677981, acc.: 54.69%] [G loss: 0.645914]\n",
      "epoch:8 step:8199 [D loss: 0.694638, acc.: 50.00%] [G loss: 0.750394]\n",
      "epoch:8 step:8200 [D loss: 0.683025, acc.: 54.69%] [G loss: 0.755075]\n",
      "epoch:8 step:8201 [D loss: 0.699353, acc.: 48.44%] [G loss: 0.779492]\n",
      "epoch:8 step:8202 [D loss: 0.661525, acc.: 65.62%] [G loss: 0.782560]\n",
      "epoch:8 step:8203 [D loss: 0.649649, acc.: 67.19%] [G loss: 0.753895]\n",
      "epoch:8 step:8204 [D loss: 0.660860, acc.: 62.50%] [G loss: 0.778156]\n",
      "epoch:8 step:8205 [D loss: 0.656329, acc.: 64.06%] [G loss: 0.772288]\n",
      "epoch:8 step:8206 [D loss: 0.736233, acc.: 39.84%] [G loss: 0.741745]\n",
      "epoch:8 step:8207 [D loss: 0.709998, acc.: 48.44%] [G loss: 0.724716]\n",
      "epoch:8 step:8208 [D loss: 0.652420, acc.: 66.41%] [G loss: 0.752053]\n",
      "epoch:8 step:8209 [D loss: 0.657765, acc.: 60.16%] [G loss: 0.726296]\n",
      "epoch:8 step:8210 [D loss: 0.659629, acc.: 64.06%] [G loss: 0.701317]\n",
      "epoch:8 step:8211 [D loss: 0.691256, acc.: 53.91%] [G loss: 0.811435]\n",
      "epoch:8 step:8212 [D loss: 0.684320, acc.: 54.69%] [G loss: 0.753173]\n",
      "epoch:8 step:8213 [D loss: 0.681518, acc.: 55.47%] [G loss: 0.770737]\n",
      "epoch:8 step:8214 [D loss: 0.677511, acc.: 57.81%] [G loss: 0.798715]\n",
      "epoch:8 step:8215 [D loss: 0.686045, acc.: 48.44%] [G loss: 0.746990]\n",
      "epoch:8 step:8216 [D loss: 0.686815, acc.: 55.47%] [G loss: 0.742401]\n",
      "epoch:8 step:8217 [D loss: 0.673736, acc.: 55.47%] [G loss: 0.757062]\n",
      "epoch:8 step:8218 [D loss: 0.711825, acc.: 48.44%] [G loss: 0.757092]\n",
      "epoch:8 step:8219 [D loss: 0.674757, acc.: 56.25%] [G loss: 0.791238]\n",
      "epoch:8 step:8220 [D loss: 0.681555, acc.: 53.91%] [G loss: 0.708546]\n",
      "epoch:8 step:8221 [D loss: 0.708197, acc.: 43.75%] [G loss: 0.746475]\n",
      "epoch:8 step:8222 [D loss: 0.691387, acc.: 48.44%] [G loss: 0.772798]\n",
      "epoch:8 step:8223 [D loss: 0.713077, acc.: 43.75%] [G loss: 0.726961]\n",
      "epoch:8 step:8224 [D loss: 0.687420, acc.: 54.69%] [G loss: 0.750570]\n",
      "epoch:8 step:8225 [D loss: 0.681121, acc.: 53.91%] [G loss: 0.744700]\n",
      "epoch:8 step:8226 [D loss: 0.663696, acc.: 58.59%] [G loss: 0.758685]\n",
      "epoch:8 step:8227 [D loss: 0.674809, acc.: 60.16%] [G loss: 0.773314]\n",
      "epoch:8 step:8228 [D loss: 0.670782, acc.: 59.38%] [G loss: 0.765677]\n",
      "epoch:8 step:8229 [D loss: 0.680512, acc.: 58.59%] [G loss: 0.801637]\n",
      "epoch:8 step:8230 [D loss: 0.690546, acc.: 56.25%] [G loss: 0.761544]\n",
      "epoch:8 step:8231 [D loss: 0.728726, acc.: 42.19%] [G loss: 0.748048]\n",
      "epoch:8 step:8232 [D loss: 0.713223, acc.: 50.00%] [G loss: 0.720898]\n",
      "epoch:8 step:8233 [D loss: 0.691995, acc.: 53.91%] [G loss: 0.725184]\n",
      "epoch:8 step:8234 [D loss: 0.705264, acc.: 50.00%] [G loss: 0.726288]\n",
      "epoch:8 step:8235 [D loss: 0.722287, acc.: 45.31%] [G loss: 0.670729]\n",
      "epoch:8 step:8236 [D loss: 0.687929, acc.: 55.47%] [G loss: 0.728887]\n",
      "epoch:8 step:8237 [D loss: 0.696186, acc.: 48.44%] [G loss: 0.771483]\n",
      "epoch:8 step:8238 [D loss: 0.696726, acc.: 52.34%] [G loss: 0.755030]\n",
      "epoch:8 step:8239 [D loss: 0.685283, acc.: 53.91%] [G loss: 0.784138]\n",
      "epoch:8 step:8240 [D loss: 0.675387, acc.: 57.03%] [G loss: 0.764761]\n",
      "epoch:8 step:8241 [D loss: 0.681136, acc.: 57.03%] [G loss: 0.772750]\n",
      "epoch:8 step:8242 [D loss: 0.670004, acc.: 57.81%] [G loss: 0.765941]\n",
      "epoch:8 step:8243 [D loss: 0.684108, acc.: 52.34%] [G loss: 0.770248]\n",
      "epoch:8 step:8244 [D loss: 0.683583, acc.: 55.47%] [G loss: 0.770511]\n",
      "epoch:8 step:8245 [D loss: 0.678075, acc.: 58.59%] [G loss: 0.769111]\n",
      "epoch:8 step:8246 [D loss: 0.660454, acc.: 58.59%] [G loss: 0.747434]\n",
      "epoch:8 step:8247 [D loss: 0.715977, acc.: 44.53%] [G loss: 0.749377]\n",
      "epoch:8 step:8248 [D loss: 0.755663, acc.: 35.94%] [G loss: 0.730426]\n",
      "epoch:8 step:8249 [D loss: 0.705603, acc.: 46.09%] [G loss: 0.709056]\n",
      "epoch:8 step:8250 [D loss: 0.704335, acc.: 47.66%] [G loss: 0.714975]\n",
      "epoch:8 step:8251 [D loss: 0.709405, acc.: 49.22%] [G loss: 0.736216]\n",
      "epoch:8 step:8252 [D loss: 0.689621, acc.: 55.47%] [G loss: 0.725538]\n",
      "epoch:8 step:8253 [D loss: 0.694677, acc.: 51.56%] [G loss: 0.725963]\n",
      "epoch:8 step:8254 [D loss: 0.701512, acc.: 46.88%] [G loss: 0.722269]\n",
      "epoch:8 step:8255 [D loss: 0.686943, acc.: 57.03%] [G loss: 0.736501]\n",
      "epoch:8 step:8256 [D loss: 0.697609, acc.: 47.66%] [G loss: 0.726014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8257 [D loss: 0.675297, acc.: 59.38%] [G loss: 0.743873]\n",
      "epoch:8 step:8258 [D loss: 0.698961, acc.: 50.78%] [G loss: 0.716789]\n",
      "epoch:8 step:8259 [D loss: 0.687415, acc.: 53.91%] [G loss: 0.719004]\n",
      "epoch:8 step:8260 [D loss: 0.678981, acc.: 57.03%] [G loss: 0.720881]\n",
      "epoch:8 step:8261 [D loss: 0.726373, acc.: 39.06%] [G loss: 0.725102]\n",
      "epoch:8 step:8262 [D loss: 0.721713, acc.: 42.19%] [G loss: 0.716160]\n",
      "epoch:8 step:8263 [D loss: 0.704255, acc.: 47.66%] [G loss: 0.715315]\n",
      "epoch:8 step:8264 [D loss: 0.711498, acc.: 42.19%] [G loss: 0.700185]\n",
      "epoch:8 step:8265 [D loss: 0.700872, acc.: 44.53%] [G loss: 0.731013]\n",
      "epoch:8 step:8266 [D loss: 0.681626, acc.: 54.69%] [G loss: 0.728512]\n",
      "epoch:8 step:8267 [D loss: 0.704668, acc.: 43.75%] [G loss: 0.727878]\n",
      "epoch:8 step:8268 [D loss: 0.693799, acc.: 50.78%] [G loss: 0.723057]\n",
      "epoch:8 step:8269 [D loss: 0.685254, acc.: 52.34%] [G loss: 0.707955]\n",
      "epoch:8 step:8270 [D loss: 0.682752, acc.: 56.25%] [G loss: 0.740043]\n",
      "epoch:8 step:8271 [D loss: 0.655082, acc.: 62.50%] [G loss: 0.738425]\n",
      "epoch:8 step:8272 [D loss: 0.687406, acc.: 50.78%] [G loss: 0.717915]\n",
      "epoch:8 step:8273 [D loss: 0.680872, acc.: 49.22%] [G loss: 0.744005]\n",
      "epoch:8 step:8274 [D loss: 0.692121, acc.: 53.91%] [G loss: 0.757105]\n",
      "epoch:8 step:8275 [D loss: 0.684432, acc.: 57.03%] [G loss: 0.731421]\n",
      "epoch:8 step:8276 [D loss: 0.689197, acc.: 57.03%] [G loss: 0.719341]\n",
      "epoch:8 step:8277 [D loss: 0.669871, acc.: 58.59%] [G loss: 0.740309]\n",
      "epoch:8 step:8278 [D loss: 0.653203, acc.: 64.06%] [G loss: 0.735265]\n",
      "epoch:8 step:8279 [D loss: 0.707959, acc.: 52.34%] [G loss: 0.759659]\n",
      "epoch:8 step:8280 [D loss: 0.726829, acc.: 44.53%] [G loss: 0.704480]\n",
      "epoch:8 step:8281 [D loss: 0.688602, acc.: 56.25%] [G loss: 0.704961]\n",
      "epoch:8 step:8282 [D loss: 0.689628, acc.: 50.00%] [G loss: 0.703408]\n",
      "epoch:8 step:8283 [D loss: 0.707589, acc.: 47.66%] [G loss: 0.696919]\n",
      "epoch:8 step:8284 [D loss: 0.695598, acc.: 55.47%] [G loss: 0.720869]\n",
      "epoch:8 step:8285 [D loss: 0.731749, acc.: 40.62%] [G loss: 0.710230]\n",
      "epoch:8 step:8286 [D loss: 0.693797, acc.: 48.44%] [G loss: 0.720912]\n",
      "epoch:8 step:8287 [D loss: 0.688674, acc.: 54.69%] [G loss: 0.724345]\n",
      "epoch:8 step:8288 [D loss: 0.684459, acc.: 57.81%] [G loss: 0.717635]\n",
      "epoch:8 step:8289 [D loss: 0.671066, acc.: 58.59%] [G loss: 0.736120]\n",
      "epoch:8 step:8290 [D loss: 0.682548, acc.: 54.69%] [G loss: 0.760350]\n",
      "epoch:8 step:8291 [D loss: 0.691979, acc.: 62.50%] [G loss: 0.786957]\n",
      "epoch:8 step:8292 [D loss: 0.673446, acc.: 61.72%] [G loss: 0.737216]\n",
      "epoch:8 step:8293 [D loss: 0.672400, acc.: 65.62%] [G loss: 0.761172]\n",
      "epoch:8 step:8294 [D loss: 0.663571, acc.: 63.28%] [G loss: 0.741064]\n",
      "epoch:8 step:8295 [D loss: 0.669752, acc.: 53.12%] [G loss: 0.804147]\n",
      "epoch:8 step:8296 [D loss: 0.698025, acc.: 46.09%] [G loss: 0.771358]\n",
      "epoch:8 step:8297 [D loss: 0.681650, acc.: 54.69%] [G loss: 0.748132]\n",
      "epoch:8 step:8298 [D loss: 0.519014, acc.: 68.75%] [G loss: 0.780936]\n",
      "epoch:8 step:8299 [D loss: 0.677571, acc.: 60.94%] [G loss: 0.735957]\n",
      "epoch:8 step:8300 [D loss: 0.711646, acc.: 50.00%] [G loss: 0.719341]\n",
      "epoch:8 step:8301 [D loss: 0.714459, acc.: 49.22%] [G loss: 0.704094]\n",
      "epoch:8 step:8302 [D loss: 0.688507, acc.: 56.25%] [G loss: 0.696900]\n",
      "epoch:8 step:8303 [D loss: 0.682975, acc.: 53.12%] [G loss: 0.729545]\n",
      "epoch:8 step:8304 [D loss: 0.708894, acc.: 50.78%] [G loss: 0.730828]\n",
      "epoch:8 step:8305 [D loss: 0.684169, acc.: 53.12%] [G loss: 0.750513]\n",
      "epoch:8 step:8306 [D loss: 0.673959, acc.: 58.59%] [G loss: 0.776172]\n",
      "epoch:8 step:8307 [D loss: 0.691911, acc.: 52.34%] [G loss: 0.742941]\n",
      "epoch:8 step:8308 [D loss: 0.680771, acc.: 59.38%] [G loss: 0.726043]\n",
      "epoch:8 step:8309 [D loss: 0.647323, acc.: 67.19%] [G loss: 0.747244]\n",
      "epoch:8 step:8310 [D loss: 0.692397, acc.: 51.56%] [G loss: 0.747977]\n",
      "epoch:8 step:8311 [D loss: 0.687958, acc.: 53.91%] [G loss: 0.755888]\n",
      "epoch:8 step:8312 [D loss: 0.663547, acc.: 57.81%] [G loss: 0.746149]\n",
      "epoch:8 step:8313 [D loss: 0.703907, acc.: 49.22%] [G loss: 0.709932]\n",
      "epoch:8 step:8314 [D loss: 0.691863, acc.: 48.44%] [G loss: 0.714966]\n",
      "epoch:8 step:8315 [D loss: 0.709486, acc.: 50.00%] [G loss: 0.781900]\n",
      "epoch:8 step:8316 [D loss: 0.759006, acc.: 32.03%] [G loss: 0.710230]\n",
      "epoch:8 step:8317 [D loss: 0.707848, acc.: 46.09%] [G loss: 0.728605]\n",
      "epoch:8 step:8318 [D loss: 0.715330, acc.: 48.44%] [G loss: 0.757960]\n",
      "epoch:8 step:8319 [D loss: 0.706072, acc.: 56.25%] [G loss: 0.754123]\n",
      "epoch:8 step:8320 [D loss: 0.692719, acc.: 53.12%] [G loss: 0.762525]\n",
      "epoch:8 step:8321 [D loss: 0.682544, acc.: 52.34%] [G loss: 0.754301]\n",
      "epoch:8 step:8322 [D loss: 0.675981, acc.: 56.25%] [G loss: 0.756231]\n",
      "epoch:8 step:8323 [D loss: 0.687367, acc.: 54.69%] [G loss: 0.748176]\n",
      "epoch:8 step:8324 [D loss: 0.692454, acc.: 50.78%] [G loss: 0.760993]\n",
      "epoch:8 step:8325 [D loss: 0.668505, acc.: 60.94%] [G loss: 0.759896]\n",
      "epoch:8 step:8326 [D loss: 0.648995, acc.: 66.41%] [G loss: 0.786721]\n",
      "epoch:8 step:8327 [D loss: 0.690711, acc.: 50.00%] [G loss: 0.721028]\n",
      "epoch:8 step:8328 [D loss: 0.686860, acc.: 54.69%] [G loss: 0.777837]\n",
      "epoch:8 step:8329 [D loss: 0.680934, acc.: 56.25%] [G loss: 0.710059]\n",
      "epoch:8 step:8330 [D loss: 0.722457, acc.: 41.41%] [G loss: 0.733079]\n",
      "epoch:8 step:8331 [D loss: 0.717849, acc.: 41.41%] [G loss: 0.740936]\n",
      "epoch:8 step:8332 [D loss: 0.714761, acc.: 47.66%] [G loss: 0.729032]\n",
      "epoch:8 step:8333 [D loss: 0.680477, acc.: 55.47%] [G loss: 0.755653]\n",
      "epoch:8 step:8334 [D loss: 0.676147, acc.: 64.06%] [G loss: 0.740694]\n",
      "epoch:8 step:8335 [D loss: 0.680198, acc.: 57.03%] [G loss: 0.738145]\n",
      "epoch:8 step:8336 [D loss: 0.680939, acc.: 60.16%] [G loss: 0.759498]\n",
      "epoch:8 step:8337 [D loss: 0.681984, acc.: 55.47%] [G loss: 0.718132]\n",
      "epoch:8 step:8338 [D loss: 0.668128, acc.: 52.34%] [G loss: 0.709206]\n",
      "epoch:8 step:8339 [D loss: 0.716095, acc.: 45.31%] [G loss: 0.738530]\n",
      "epoch:8 step:8340 [D loss: 0.694182, acc.: 54.69%] [G loss: 0.684592]\n",
      "epoch:8 step:8341 [D loss: 0.614103, acc.: 71.09%] [G loss: 0.686917]\n",
      "epoch:8 step:8342 [D loss: 0.736574, acc.: 46.88%] [G loss: 0.725555]\n",
      "epoch:8 step:8343 [D loss: 0.719526, acc.: 43.75%] [G loss: 0.686840]\n",
      "epoch:8 step:8344 [D loss: 0.713345, acc.: 39.84%] [G loss: 0.711443]\n",
      "epoch:8 step:8345 [D loss: 0.698157, acc.: 53.12%] [G loss: 0.641526]\n",
      "epoch:8 step:8346 [D loss: 0.725039, acc.: 38.28%] [G loss: 0.717643]\n",
      "epoch:8 step:8347 [D loss: 0.700352, acc.: 53.91%] [G loss: 0.740320]\n",
      "epoch:8 step:8348 [D loss: 0.709231, acc.: 46.09%] [G loss: 0.708388]\n",
      "epoch:8 step:8349 [D loss: 0.693190, acc.: 48.44%] [G loss: 0.732124]\n",
      "epoch:8 step:8350 [D loss: 0.683289, acc.: 53.12%] [G loss: 0.749370]\n",
      "epoch:8 step:8351 [D loss: 0.659669, acc.: 59.38%] [G loss: 0.799695]\n",
      "epoch:8 step:8352 [D loss: 0.666541, acc.: 63.28%] [G loss: 0.771664]\n",
      "epoch:8 step:8353 [D loss: 0.650938, acc.: 68.75%] [G loss: 0.797737]\n",
      "epoch:8 step:8354 [D loss: 0.712042, acc.: 45.31%] [G loss: 0.816932]\n",
      "epoch:8 step:8355 [D loss: 0.707919, acc.: 51.56%] [G loss: 0.800898]\n",
      "epoch:8 step:8356 [D loss: 0.694629, acc.: 49.22%] [G loss: 0.787660]\n",
      "epoch:8 step:8357 [D loss: 0.704823, acc.: 49.22%] [G loss: 0.739578]\n",
      "epoch:8 step:8358 [D loss: 0.703421, acc.: 45.31%] [G loss: 0.752364]\n",
      "epoch:8 step:8359 [D loss: 0.708652, acc.: 46.09%] [G loss: 0.722019]\n",
      "epoch:8 step:8360 [D loss: 0.695855, acc.: 48.44%] [G loss: 0.705578]\n",
      "epoch:8 step:8361 [D loss: 0.686695, acc.: 56.25%] [G loss: 0.725610]\n",
      "epoch:8 step:8362 [D loss: 0.705797, acc.: 47.66%] [G loss: 0.711420]\n",
      "epoch:8 step:8363 [D loss: 0.709268, acc.: 44.53%] [G loss: 0.715043]\n",
      "epoch:8 step:8364 [D loss: 0.683534, acc.: 55.47%] [G loss: 0.727062]\n",
      "epoch:8 step:8365 [D loss: 0.684783, acc.: 57.81%] [G loss: 0.715810]\n",
      "epoch:8 step:8366 [D loss: 0.691477, acc.: 53.91%] [G loss: 0.728055]\n",
      "epoch:8 step:8367 [D loss: 0.682050, acc.: 52.34%] [G loss: 0.721480]\n",
      "epoch:8 step:8368 [D loss: 0.685048, acc.: 62.50%] [G loss: 0.720792]\n",
      "epoch:8 step:8369 [D loss: 0.683057, acc.: 57.03%] [G loss: 0.747292]\n",
      "epoch:8 step:8370 [D loss: 0.703041, acc.: 51.56%] [G loss: 0.725454]\n",
      "epoch:8 step:8371 [D loss: 0.677491, acc.: 60.94%] [G loss: 0.738349]\n",
      "epoch:8 step:8372 [D loss: 0.706478, acc.: 45.31%] [G loss: 0.724640]\n",
      "epoch:8 step:8373 [D loss: 0.691974, acc.: 56.25%] [G loss: 0.733681]\n",
      "epoch:8 step:8374 [D loss: 0.673318, acc.: 53.12%] [G loss: 0.722060]\n",
      "epoch:8 step:8375 [D loss: 0.678444, acc.: 58.59%] [G loss: 0.727432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8376 [D loss: 0.713636, acc.: 45.31%] [G loss: 0.728066]\n",
      "epoch:8 step:8377 [D loss: 0.704706, acc.: 48.44%] [G loss: 0.725599]\n",
      "epoch:8 step:8378 [D loss: 0.695795, acc.: 47.66%] [G loss: 0.733530]\n",
      "epoch:8 step:8379 [D loss: 0.684801, acc.: 53.91%] [G loss: 0.718890]\n",
      "epoch:8 step:8380 [D loss: 0.698699, acc.: 54.69%] [G loss: 0.723842]\n",
      "epoch:8 step:8381 [D loss: 0.675659, acc.: 57.03%] [G loss: 0.712430]\n",
      "epoch:8 step:8382 [D loss: 0.689803, acc.: 54.69%] [G loss: 0.712129]\n",
      "epoch:8 step:8383 [D loss: 0.679829, acc.: 53.91%] [G loss: 0.749181]\n",
      "epoch:8 step:8384 [D loss: 0.707227, acc.: 49.22%] [G loss: 0.719803]\n",
      "epoch:8 step:8385 [D loss: 0.683925, acc.: 60.16%] [G loss: 0.759569]\n",
      "epoch:8 step:8386 [D loss: 0.674679, acc.: 58.59%] [G loss: 0.726886]\n",
      "epoch:8 step:8387 [D loss: 0.705861, acc.: 49.22%] [G loss: 0.762228]\n",
      "epoch:8 step:8388 [D loss: 0.744513, acc.: 42.19%] [G loss: 0.745178]\n",
      "epoch:8 step:8389 [D loss: 0.699593, acc.: 48.44%] [G loss: 0.744137]\n",
      "epoch:8 step:8390 [D loss: 0.693658, acc.: 53.91%] [G loss: 0.742792]\n",
      "epoch:8 step:8391 [D loss: 0.677080, acc.: 59.38%] [G loss: 0.734640]\n",
      "epoch:8 step:8392 [D loss: 0.683344, acc.: 60.16%] [G loss: 0.721243]\n",
      "epoch:8 step:8393 [D loss: 0.662589, acc.: 65.62%] [G loss: 0.735617]\n",
      "epoch:8 step:8394 [D loss: 0.698858, acc.: 51.56%] [G loss: 0.738807]\n",
      "epoch:8 step:8395 [D loss: 0.624010, acc.: 65.62%] [G loss: 0.748128]\n",
      "epoch:8 step:8396 [D loss: 0.646330, acc.: 62.50%] [G loss: 0.757590]\n",
      "epoch:8 step:8397 [D loss: 0.669577, acc.: 60.16%] [G loss: 0.764621]\n",
      "epoch:8 step:8398 [D loss: 0.684765, acc.: 56.25%] [G loss: 0.730017]\n",
      "epoch:8 step:8399 [D loss: 0.700202, acc.: 46.88%] [G loss: 0.767790]\n",
      "epoch:8 step:8400 [D loss: 0.700312, acc.: 49.22%] [G loss: 0.752962]\n",
      "epoch:8 step:8401 [D loss: 0.743108, acc.: 39.84%] [G loss: 0.739487]\n",
      "epoch:8 step:8402 [D loss: 0.700417, acc.: 57.81%] [G loss: 0.731899]\n",
      "epoch:8 step:8403 [D loss: 0.688485, acc.: 52.34%] [G loss: 0.712212]\n",
      "epoch:8 step:8404 [D loss: 0.683367, acc.: 50.78%] [G loss: 0.751158]\n",
      "epoch:8 step:8405 [D loss: 0.700969, acc.: 54.69%] [G loss: 0.708361]\n",
      "epoch:8 step:8406 [D loss: 0.748367, acc.: 35.94%] [G loss: 0.717186]\n",
      "epoch:8 step:8407 [D loss: 0.721897, acc.: 46.88%] [G loss: 0.754306]\n",
      "epoch:8 step:8408 [D loss: 0.401868, acc.: 82.03%] [G loss: 0.777387]\n",
      "epoch:8 step:8409 [D loss: 0.691361, acc.: 52.34%] [G loss: 0.789916]\n",
      "epoch:8 step:8410 [D loss: 0.709883, acc.: 48.44%] [G loss: 0.776741]\n",
      "epoch:8 step:8411 [D loss: 0.710031, acc.: 41.41%] [G loss: 0.770769]\n",
      "epoch:8 step:8412 [D loss: 0.702950, acc.: 45.31%] [G loss: 0.759171]\n",
      "epoch:8 step:8413 [D loss: 0.677312, acc.: 59.38%] [G loss: 0.747243]\n",
      "epoch:8 step:8414 [D loss: 0.650862, acc.: 68.75%] [G loss: 0.766429]\n",
      "epoch:8 step:8415 [D loss: 0.642148, acc.: 67.19%] [G loss: 0.701624]\n",
      "epoch:8 step:8416 [D loss: 0.727774, acc.: 43.75%] [G loss: 0.759504]\n",
      "epoch:8 step:8417 [D loss: 0.673347, acc.: 59.38%] [G loss: 0.755119]\n",
      "epoch:8 step:8418 [D loss: 0.660022, acc.: 61.72%] [G loss: 0.760164]\n",
      "epoch:8 step:8419 [D loss: 0.639422, acc.: 67.97%] [G loss: 0.769597]\n",
      "epoch:8 step:8420 [D loss: 0.621060, acc.: 70.31%] [G loss: 0.761584]\n",
      "epoch:8 step:8421 [D loss: 0.657866, acc.: 57.81%] [G loss: 0.759313]\n",
      "epoch:8 step:8422 [D loss: 0.506470, acc.: 69.53%] [G loss: 0.784364]\n",
      "epoch:8 step:8423 [D loss: 0.787566, acc.: 54.69%] [G loss: 0.829491]\n",
      "epoch:8 step:8424 [D loss: 0.723934, acc.: 47.66%] [G loss: 0.818243]\n",
      "epoch:8 step:8425 [D loss: 0.666121, acc.: 61.72%] [G loss: 0.841415]\n",
      "epoch:8 step:8426 [D loss: 0.698240, acc.: 54.69%] [G loss: 0.823841]\n",
      "epoch:8 step:8427 [D loss: 0.729074, acc.: 46.88%] [G loss: 0.774945]\n",
      "epoch:8 step:8428 [D loss: 0.733795, acc.: 41.41%] [G loss: 0.737281]\n",
      "epoch:8 step:8429 [D loss: 0.698127, acc.: 53.91%] [G loss: 0.723645]\n",
      "epoch:8 step:8430 [D loss: 0.698650, acc.: 55.47%] [G loss: 0.755592]\n",
      "epoch:8 step:8431 [D loss: 0.679762, acc.: 60.16%] [G loss: 0.726104]\n",
      "epoch:8 step:8432 [D loss: 0.507203, acc.: 67.19%] [G loss: 0.691643]\n",
      "epoch:8 step:8433 [D loss: 0.433132, acc.: 67.97%] [G loss: 0.689416]\n",
      "epoch:9 step:8434 [D loss: 0.753928, acc.: 45.31%] [G loss: 0.782300]\n",
      "epoch:9 step:8435 [D loss: 0.713732, acc.: 48.44%] [G loss: 0.787814]\n",
      "epoch:9 step:8436 [D loss: 0.708460, acc.: 42.19%] [G loss: 0.764521]\n",
      "epoch:9 step:8437 [D loss: 0.703873, acc.: 37.50%] [G loss: 0.337942]\n",
      "epoch:9 step:8438 [D loss: 0.741937, acc.: 31.25%] [G loss: 0.374164]\n",
      "epoch:9 step:8439 [D loss: 0.709846, acc.: 35.94%] [G loss: 0.573777]\n",
      "epoch:9 step:8440 [D loss: 0.687053, acc.: 48.44%] [G loss: 0.812337]\n",
      "epoch:9 step:8441 [D loss: 0.683536, acc.: 53.91%] [G loss: 0.833592]\n",
      "epoch:9 step:8442 [D loss: 0.694280, acc.: 43.75%] [G loss: 0.884080]\n",
      "epoch:9 step:8443 [D loss: 0.685412, acc.: 50.00%] [G loss: 0.841484]\n",
      "epoch:9 step:8444 [D loss: 0.691341, acc.: 53.12%] [G loss: 0.847806]\n",
      "epoch:9 step:8445 [D loss: 0.704255, acc.: 43.75%] [G loss: 0.773397]\n",
      "epoch:9 step:8446 [D loss: 0.704839, acc.: 47.66%] [G loss: 0.769940]\n",
      "epoch:9 step:8447 [D loss: 0.697582, acc.: 51.56%] [G loss: 0.822686]\n",
      "epoch:9 step:8448 [D loss: 0.807581, acc.: 31.25%] [G loss: 0.934038]\n",
      "epoch:9 step:8449 [D loss: 0.698978, acc.: 57.81%] [G loss: 0.872962]\n",
      "epoch:9 step:8450 [D loss: 0.717609, acc.: 50.78%] [G loss: 0.932115]\n",
      "epoch:9 step:8451 [D loss: 0.725987, acc.: 48.44%] [G loss: 0.837266]\n",
      "epoch:9 step:8452 [D loss: 0.678838, acc.: 58.59%] [G loss: 0.800745]\n",
      "epoch:9 step:8453 [D loss: 0.675210, acc.: 59.38%] [G loss: 0.799737]\n",
      "epoch:9 step:8454 [D loss: 0.706629, acc.: 53.12%] [G loss: 0.767445]\n",
      "epoch:9 step:8455 [D loss: 0.689403, acc.: 54.69%] [G loss: 0.792050]\n",
      "epoch:9 step:8456 [D loss: 0.719460, acc.: 43.75%] [G loss: 0.721658]\n",
      "epoch:9 step:8457 [D loss: 0.733362, acc.: 33.59%] [G loss: 0.728026]\n",
      "epoch:9 step:8458 [D loss: 0.722931, acc.: 37.50%] [G loss: 0.689723]\n",
      "epoch:9 step:8459 [D loss: 0.691332, acc.: 50.78%] [G loss: 0.710721]\n",
      "epoch:9 step:8460 [D loss: 0.661962, acc.: 67.97%] [G loss: 0.741994]\n",
      "epoch:9 step:8461 [D loss: 0.696701, acc.: 54.69%] [G loss: 0.721817]\n",
      "epoch:9 step:8462 [D loss: 0.688330, acc.: 54.69%] [G loss: 0.753210]\n",
      "epoch:9 step:8463 [D loss: 0.672118, acc.: 59.38%] [G loss: 0.775936]\n",
      "epoch:9 step:8464 [D loss: 0.650706, acc.: 71.09%] [G loss: 0.787539]\n",
      "epoch:9 step:8465 [D loss: 0.676995, acc.: 58.59%] [G loss: 0.731665]\n",
      "epoch:9 step:8466 [D loss: 0.644989, acc.: 67.97%] [G loss: 0.785304]\n",
      "epoch:9 step:8467 [D loss: 0.656126, acc.: 65.62%] [G loss: 0.872142]\n",
      "epoch:9 step:8468 [D loss: 0.619424, acc.: 69.53%] [G loss: 1.123405]\n",
      "epoch:9 step:8469 [D loss: 0.650055, acc.: 64.84%] [G loss: 0.699953]\n",
      "epoch:9 step:8470 [D loss: 0.674262, acc.: 53.91%] [G loss: 0.765706]\n",
      "epoch:9 step:8471 [D loss: 0.778282, acc.: 29.69%] [G loss: 0.771197]\n",
      "epoch:9 step:8472 [D loss: 0.719005, acc.: 34.38%] [G loss: 0.753669]\n",
      "epoch:9 step:8473 [D loss: 0.724085, acc.: 38.28%] [G loss: 0.758764]\n",
      "epoch:9 step:8474 [D loss: 0.678342, acc.: 56.25%] [G loss: 0.793697]\n",
      "epoch:9 step:8475 [D loss: 0.698813, acc.: 46.09%] [G loss: 0.770432]\n",
      "epoch:9 step:8476 [D loss: 0.694374, acc.: 53.12%] [G loss: 0.751980]\n",
      "epoch:9 step:8477 [D loss: 0.680663, acc.: 58.59%] [G loss: 0.809397]\n",
      "epoch:9 step:8478 [D loss: 0.684545, acc.: 57.81%] [G loss: 0.815092]\n",
      "epoch:9 step:8479 [D loss: 0.657750, acc.: 62.50%] [G loss: 0.837861]\n",
      "epoch:9 step:8480 [D loss: 0.696970, acc.: 51.56%] [G loss: 0.769796]\n",
      "epoch:9 step:8481 [D loss: 0.692508, acc.: 53.12%] [G loss: 0.742416]\n",
      "epoch:9 step:8482 [D loss: 0.690970, acc.: 57.81%] [G loss: 0.767209]\n",
      "epoch:9 step:8483 [D loss: 0.652767, acc.: 58.59%] [G loss: 0.769428]\n",
      "epoch:9 step:8484 [D loss: 0.705833, acc.: 50.78%] [G loss: 0.757709]\n",
      "epoch:9 step:8485 [D loss: 0.688291, acc.: 58.59%] [G loss: 0.717655]\n",
      "epoch:9 step:8486 [D loss: 0.678995, acc.: 57.81%] [G loss: 0.738778]\n",
      "epoch:9 step:8487 [D loss: 0.716523, acc.: 46.09%] [G loss: 0.732255]\n",
      "epoch:9 step:8488 [D loss: 0.696996, acc.: 53.12%] [G loss: 0.713262]\n",
      "epoch:9 step:8489 [D loss: 0.678274, acc.: 55.47%] [G loss: 0.736775]\n",
      "epoch:9 step:8490 [D loss: 0.716502, acc.: 45.31%] [G loss: 0.720386]\n",
      "epoch:9 step:8491 [D loss: 0.688175, acc.: 50.78%] [G loss: 0.726455]\n",
      "epoch:9 step:8492 [D loss: 0.672412, acc.: 55.47%] [G loss: 0.804277]\n",
      "epoch:9 step:8493 [D loss: 0.683244, acc.: 51.56%] [G loss: 0.783799]\n",
      "epoch:9 step:8494 [D loss: 0.706005, acc.: 47.66%] [G loss: 0.737529]\n",
      "epoch:9 step:8495 [D loss: 0.681291, acc.: 55.47%] [G loss: 0.735260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8496 [D loss: 0.698423, acc.: 48.44%] [G loss: 0.731912]\n",
      "epoch:9 step:8497 [D loss: 0.682840, acc.: 50.78%] [G loss: 0.738987]\n",
      "epoch:9 step:8498 [D loss: 0.686573, acc.: 54.69%] [G loss: 0.765467]\n",
      "epoch:9 step:8499 [D loss: 0.716232, acc.: 43.75%] [G loss: 0.746676]\n",
      "epoch:9 step:8500 [D loss: 0.691103, acc.: 50.00%] [G loss: 0.729879]\n",
      "epoch:9 step:8501 [D loss: 0.689289, acc.: 52.34%] [G loss: 0.732243]\n",
      "epoch:9 step:8502 [D loss: 0.665675, acc.: 64.06%] [G loss: 0.755960]\n",
      "epoch:9 step:8503 [D loss: 0.676237, acc.: 64.06%] [G loss: 0.734484]\n",
      "epoch:9 step:8504 [D loss: 0.723136, acc.: 50.78%] [G loss: 0.715102]\n",
      "epoch:9 step:8505 [D loss: 0.697512, acc.: 52.34%] [G loss: 0.671568]\n",
      "epoch:9 step:8506 [D loss: 0.691432, acc.: 50.00%] [G loss: 0.783779]\n",
      "epoch:9 step:8507 [D loss: 0.690597, acc.: 51.56%] [G loss: 0.794012]\n",
      "epoch:9 step:8508 [D loss: 0.713032, acc.: 39.84%] [G loss: 0.776891]\n",
      "epoch:9 step:8509 [D loss: 0.693268, acc.: 46.09%] [G loss: 0.758820]\n",
      "epoch:9 step:8510 [D loss: 0.675997, acc.: 55.47%] [G loss: 0.787871]\n",
      "epoch:9 step:8511 [D loss: 0.715170, acc.: 45.31%] [G loss: 0.756079]\n",
      "epoch:9 step:8512 [D loss: 0.690332, acc.: 54.69%] [G loss: 0.753355]\n",
      "epoch:9 step:8513 [D loss: 0.689599, acc.: 48.44%] [G loss: 0.780216]\n",
      "epoch:9 step:8514 [D loss: 0.710649, acc.: 44.53%] [G loss: 0.778952]\n",
      "epoch:9 step:8515 [D loss: 0.685781, acc.: 59.38%] [G loss: 0.738895]\n",
      "epoch:9 step:8516 [D loss: 0.685725, acc.: 55.47%] [G loss: 0.740825]\n",
      "epoch:9 step:8517 [D loss: 0.674652, acc.: 57.81%] [G loss: 0.733230]\n",
      "epoch:9 step:8518 [D loss: 0.667753, acc.: 56.25%] [G loss: 0.754822]\n",
      "epoch:9 step:8519 [D loss: 0.684874, acc.: 55.47%] [G loss: 0.726897]\n",
      "epoch:9 step:8520 [D loss: 0.695427, acc.: 57.03%] [G loss: 0.727040]\n",
      "epoch:9 step:8521 [D loss: 0.696677, acc.: 57.03%] [G loss: 0.736066]\n",
      "epoch:9 step:8522 [D loss: 0.668226, acc.: 68.75%] [G loss: 0.743963]\n",
      "epoch:9 step:8523 [D loss: 0.688045, acc.: 61.72%] [G loss: 0.730180]\n",
      "epoch:9 step:8524 [D loss: 0.688235, acc.: 50.00%] [G loss: 0.760691]\n",
      "epoch:9 step:8525 [D loss: 0.679306, acc.: 54.69%] [G loss: 0.743216]\n",
      "epoch:9 step:8526 [D loss: 0.666786, acc.: 64.84%] [G loss: 0.733653]\n",
      "epoch:9 step:8527 [D loss: 0.682946, acc.: 56.25%] [G loss: 0.723777]\n",
      "epoch:9 step:8528 [D loss: 0.677595, acc.: 52.34%] [G loss: 0.734890]\n",
      "epoch:9 step:8529 [D loss: 0.688103, acc.: 47.66%] [G loss: 0.717639]\n",
      "epoch:9 step:8530 [D loss: 0.679598, acc.: 54.69%] [G loss: 0.745584]\n",
      "epoch:9 step:8531 [D loss: 0.679981, acc.: 59.38%] [G loss: 0.732609]\n",
      "epoch:9 step:8532 [D loss: 0.669312, acc.: 60.16%] [G loss: 0.737865]\n",
      "epoch:9 step:8533 [D loss: 0.658897, acc.: 59.38%] [G loss: 0.731594]\n",
      "epoch:9 step:8534 [D loss: 0.699457, acc.: 49.22%] [G loss: 0.691792]\n",
      "epoch:9 step:8535 [D loss: 0.684937, acc.: 53.12%] [G loss: 0.769329]\n",
      "epoch:9 step:8536 [D loss: 0.705588, acc.: 53.12%] [G loss: 0.725619]\n",
      "epoch:9 step:8537 [D loss: 0.675331, acc.: 50.78%] [G loss: 0.712450]\n",
      "epoch:9 step:8538 [D loss: 0.690984, acc.: 51.56%] [G loss: 0.746893]\n",
      "epoch:9 step:8539 [D loss: 0.663997, acc.: 63.28%] [G loss: 0.775924]\n",
      "epoch:9 step:8540 [D loss: 0.670808, acc.: 57.81%] [G loss: 0.764182]\n",
      "epoch:9 step:8541 [D loss: 0.721395, acc.: 46.88%] [G loss: 0.718186]\n",
      "epoch:9 step:8542 [D loss: 0.696515, acc.: 48.44%] [G loss: 0.756356]\n",
      "epoch:9 step:8543 [D loss: 0.708465, acc.: 54.69%] [G loss: 0.773459]\n",
      "epoch:9 step:8544 [D loss: 0.707375, acc.: 50.00%] [G loss: 0.763524]\n",
      "epoch:9 step:8545 [D loss: 0.677358, acc.: 56.25%] [G loss: 0.779682]\n",
      "epoch:9 step:8546 [D loss: 0.701216, acc.: 47.66%] [G loss: 0.759920]\n",
      "epoch:9 step:8547 [D loss: 0.687656, acc.: 53.91%] [G loss: 0.786633]\n",
      "epoch:9 step:8548 [D loss: 0.689676, acc.: 48.44%] [G loss: 0.796006]\n",
      "epoch:9 step:8549 [D loss: 0.684324, acc.: 52.34%] [G loss: 0.787304]\n",
      "epoch:9 step:8550 [D loss: 0.697258, acc.: 56.25%] [G loss: 0.798219]\n",
      "epoch:9 step:8551 [D loss: 0.672702, acc.: 62.50%] [G loss: 0.786387]\n",
      "epoch:9 step:8552 [D loss: 0.674587, acc.: 60.94%] [G loss: 0.783031]\n",
      "epoch:9 step:8553 [D loss: 0.711278, acc.: 46.88%] [G loss: 0.790700]\n",
      "epoch:9 step:8554 [D loss: 0.696814, acc.: 45.31%] [G loss: 0.778287]\n",
      "epoch:9 step:8555 [D loss: 0.690675, acc.: 55.47%] [G loss: 0.816193]\n",
      "epoch:9 step:8556 [D loss: 0.691463, acc.: 48.44%] [G loss: 0.791928]\n",
      "epoch:9 step:8557 [D loss: 0.716021, acc.: 49.22%] [G loss: 0.747047]\n",
      "epoch:9 step:8558 [D loss: 0.692702, acc.: 53.91%] [G loss: 0.743186]\n",
      "epoch:9 step:8559 [D loss: 0.681228, acc.: 54.69%] [G loss: 0.809527]\n",
      "epoch:9 step:8560 [D loss: 0.677637, acc.: 57.81%] [G loss: 0.786869]\n",
      "epoch:9 step:8561 [D loss: 0.680538, acc.: 56.25%] [G loss: 0.731045]\n",
      "epoch:9 step:8562 [D loss: 0.672225, acc.: 62.50%] [G loss: 0.758930]\n",
      "epoch:9 step:8563 [D loss: 0.650973, acc.: 69.53%] [G loss: 0.743544]\n",
      "epoch:9 step:8564 [D loss: 0.694130, acc.: 53.91%] [G loss: 0.681767]\n",
      "epoch:9 step:8565 [D loss: 0.682180, acc.: 55.47%] [G loss: 0.723128]\n",
      "epoch:9 step:8566 [D loss: 0.735623, acc.: 46.09%] [G loss: 0.673305]\n",
      "epoch:9 step:8567 [D loss: 0.744251, acc.: 34.38%] [G loss: 0.715408]\n",
      "epoch:9 step:8568 [D loss: 0.702501, acc.: 47.66%] [G loss: 0.722175]\n",
      "epoch:9 step:8569 [D loss: 0.719329, acc.: 34.38%] [G loss: 0.701138]\n",
      "epoch:9 step:8570 [D loss: 0.676503, acc.: 57.03%] [G loss: 0.701746]\n",
      "epoch:9 step:8571 [D loss: 0.696299, acc.: 50.00%] [G loss: 0.681917]\n",
      "epoch:9 step:8572 [D loss: 0.652071, acc.: 67.19%] [G loss: 0.717894]\n",
      "epoch:9 step:8573 [D loss: 0.687955, acc.: 50.00%] [G loss: 0.714056]\n",
      "epoch:9 step:8574 [D loss: 0.696920, acc.: 52.34%] [G loss: 0.730362]\n",
      "epoch:9 step:8575 [D loss: 0.702850, acc.: 48.44%] [G loss: 0.707830]\n",
      "epoch:9 step:8576 [D loss: 0.672873, acc.: 62.50%] [G loss: 0.745780]\n",
      "epoch:9 step:8577 [D loss: 0.671408, acc.: 59.38%] [G loss: 0.740700]\n",
      "epoch:9 step:8578 [D loss: 0.656943, acc.: 61.72%] [G loss: 0.778022]\n",
      "epoch:9 step:8579 [D loss: 0.679350, acc.: 54.69%] [G loss: 0.695492]\n",
      "epoch:9 step:8580 [D loss: 0.686740, acc.: 50.00%] [G loss: 0.710152]\n",
      "epoch:9 step:8581 [D loss: 0.693932, acc.: 49.22%] [G loss: 0.768363]\n",
      "epoch:9 step:8582 [D loss: 0.690815, acc.: 54.69%] [G loss: 0.727547]\n",
      "epoch:9 step:8583 [D loss: 0.671535, acc.: 62.50%] [G loss: 0.756726]\n",
      "epoch:9 step:8584 [D loss: 0.662123, acc.: 65.62%] [G loss: 0.725782]\n",
      "epoch:9 step:8585 [D loss: 0.674327, acc.: 60.16%] [G loss: 0.791386]\n",
      "epoch:9 step:8586 [D loss: 0.713519, acc.: 46.88%] [G loss: 0.729717]\n",
      "epoch:9 step:8587 [D loss: 0.693357, acc.: 53.91%] [G loss: 0.786283]\n",
      "epoch:9 step:8588 [D loss: 0.679883, acc.: 53.91%] [G loss: 0.749399]\n",
      "epoch:9 step:8589 [D loss: 0.729023, acc.: 40.62%] [G loss: 0.787003]\n",
      "epoch:9 step:8590 [D loss: 0.674058, acc.: 60.94%] [G loss: 0.754054]\n",
      "epoch:9 step:8591 [D loss: 0.710504, acc.: 43.75%] [G loss: 0.765665]\n",
      "epoch:9 step:8592 [D loss: 0.720098, acc.: 45.31%] [G loss: 0.746265]\n",
      "epoch:9 step:8593 [D loss: 0.710735, acc.: 42.97%] [G loss: 0.744389]\n",
      "epoch:9 step:8594 [D loss: 0.697533, acc.: 51.56%] [G loss: 0.749869]\n",
      "epoch:9 step:8595 [D loss: 0.702884, acc.: 49.22%] [G loss: 0.740595]\n",
      "epoch:9 step:8596 [D loss: 0.698368, acc.: 51.56%] [G loss: 0.743524]\n",
      "epoch:9 step:8597 [D loss: 0.690259, acc.: 51.56%] [G loss: 0.723315]\n",
      "epoch:9 step:8598 [D loss: 0.709938, acc.: 46.88%] [G loss: 0.732256]\n",
      "epoch:9 step:8599 [D loss: 0.706573, acc.: 50.78%] [G loss: 0.748796]\n",
      "epoch:9 step:8600 [D loss: 0.706636, acc.: 45.31%] [G loss: 0.721801]\n",
      "epoch:9 step:8601 [D loss: 0.690390, acc.: 56.25%] [G loss: 0.738674]\n",
      "epoch:9 step:8602 [D loss: 0.689234, acc.: 55.47%] [G loss: 0.716041]\n",
      "epoch:9 step:8603 [D loss: 0.695862, acc.: 52.34%] [G loss: 0.736889]\n",
      "epoch:9 step:8604 [D loss: 0.684806, acc.: 57.03%] [G loss: 0.731905]\n",
      "epoch:9 step:8605 [D loss: 0.675316, acc.: 56.25%] [G loss: 0.740511]\n",
      "epoch:9 step:8606 [D loss: 0.704782, acc.: 49.22%] [G loss: 0.713796]\n",
      "epoch:9 step:8607 [D loss: 0.695756, acc.: 49.22%] [G loss: 0.754432]\n",
      "epoch:9 step:8608 [D loss: 0.680589, acc.: 57.81%] [G loss: 0.746142]\n",
      "epoch:9 step:8609 [D loss: 0.703584, acc.: 50.78%] [G loss: 0.720792]\n",
      "epoch:9 step:8610 [D loss: 0.700320, acc.: 46.88%] [G loss: 0.721817]\n",
      "epoch:9 step:8611 [D loss: 0.684763, acc.: 53.91%] [G loss: 0.717035]\n",
      "epoch:9 step:8612 [D loss: 0.677690, acc.: 55.47%] [G loss: 0.733579]\n",
      "epoch:9 step:8613 [D loss: 0.683592, acc.: 54.69%] [G loss: 0.745943]\n",
      "epoch:9 step:8614 [D loss: 0.663280, acc.: 69.53%] [G loss: 0.730079]\n",
      "epoch:9 step:8615 [D loss: 0.694713, acc.: 51.56%] [G loss: 0.731416]\n",
      "epoch:9 step:8616 [D loss: 0.684547, acc.: 55.47%] [G loss: 0.730324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8617 [D loss: 0.675593, acc.: 53.12%] [G loss: 0.715585]\n",
      "epoch:9 step:8618 [D loss: 0.672237, acc.: 58.59%] [G loss: 0.727509]\n",
      "epoch:9 step:8619 [D loss: 0.675519, acc.: 58.59%] [G loss: 0.727711]\n",
      "epoch:9 step:8620 [D loss: 0.660204, acc.: 62.50%] [G loss: 0.690743]\n",
      "epoch:9 step:8621 [D loss: 0.706480, acc.: 46.88%] [G loss: 0.724185]\n",
      "epoch:9 step:8622 [D loss: 0.690213, acc.: 54.69%] [G loss: 0.739721]\n",
      "epoch:9 step:8623 [D loss: 0.647171, acc.: 67.19%] [G loss: 0.765775]\n",
      "epoch:9 step:8624 [D loss: 0.671306, acc.: 60.16%] [G loss: 0.728146]\n",
      "epoch:9 step:8625 [D loss: 0.677380, acc.: 57.81%] [G loss: 0.759081]\n",
      "epoch:9 step:8626 [D loss: 0.694513, acc.: 54.69%] [G loss: 0.753040]\n",
      "epoch:9 step:8627 [D loss: 0.695325, acc.: 55.47%] [G loss: 0.784868]\n",
      "epoch:9 step:8628 [D loss: 0.673587, acc.: 56.25%] [G loss: 0.748219]\n",
      "epoch:9 step:8629 [D loss: 0.689438, acc.: 55.47%] [G loss: 0.774059]\n",
      "epoch:9 step:8630 [D loss: 0.703114, acc.: 50.00%] [G loss: 0.754544]\n",
      "epoch:9 step:8631 [D loss: 0.692256, acc.: 49.22%] [G loss: 0.741322]\n",
      "epoch:9 step:8632 [D loss: 0.711084, acc.: 49.22%] [G loss: 0.735651]\n",
      "epoch:9 step:8633 [D loss: 0.766046, acc.: 35.16%] [G loss: 0.747560]\n",
      "epoch:9 step:8634 [D loss: 0.711960, acc.: 47.66%] [G loss: 0.734684]\n",
      "epoch:9 step:8635 [D loss: 0.701975, acc.: 43.75%] [G loss: 0.735985]\n",
      "epoch:9 step:8636 [D loss: 0.703074, acc.: 49.22%] [G loss: 0.759339]\n",
      "epoch:9 step:8637 [D loss: 0.647386, acc.: 58.59%] [G loss: 0.779854]\n",
      "epoch:9 step:8638 [D loss: 0.702521, acc.: 44.53%] [G loss: 0.745823]\n",
      "epoch:9 step:8639 [D loss: 0.675351, acc.: 56.25%] [G loss: 0.733369]\n",
      "epoch:9 step:8640 [D loss: 0.485308, acc.: 69.53%] [G loss: 0.759836]\n",
      "epoch:9 step:8641 [D loss: 0.691633, acc.: 61.72%] [G loss: 0.773146]\n",
      "epoch:9 step:8642 [D loss: 0.675548, acc.: 56.25%] [G loss: 0.795271]\n",
      "epoch:9 step:8643 [D loss: 0.698153, acc.: 57.03%] [G loss: 0.778124]\n",
      "epoch:9 step:8644 [D loss: 0.690726, acc.: 57.03%] [G loss: 0.744217]\n",
      "epoch:9 step:8645 [D loss: 0.695295, acc.: 54.69%] [G loss: 0.742032]\n",
      "epoch:9 step:8646 [D loss: 0.683553, acc.: 53.91%] [G loss: 0.762988]\n",
      "epoch:9 step:8647 [D loss: 0.660542, acc.: 64.84%] [G loss: 0.708316]\n",
      "epoch:9 step:8648 [D loss: 0.675769, acc.: 57.81%] [G loss: 0.739042]\n",
      "epoch:9 step:8649 [D loss: 0.643487, acc.: 64.06%] [G loss: 0.682341]\n",
      "epoch:9 step:8650 [D loss: 0.718925, acc.: 46.09%] [G loss: 0.702064]\n",
      "epoch:9 step:8651 [D loss: 0.707736, acc.: 42.97%] [G loss: 0.748391]\n",
      "epoch:9 step:8652 [D loss: 0.694503, acc.: 46.09%] [G loss: 0.690828]\n",
      "epoch:9 step:8653 [D loss: 0.742821, acc.: 30.47%] [G loss: 0.704939]\n",
      "epoch:9 step:8654 [D loss: 0.696573, acc.: 43.75%] [G loss: 0.743457]\n",
      "epoch:9 step:8655 [D loss: 0.698503, acc.: 49.22%] [G loss: 0.764603]\n",
      "epoch:9 step:8656 [D loss: 0.685318, acc.: 56.25%] [G loss: 0.783514]\n",
      "epoch:9 step:8657 [D loss: 0.699038, acc.: 48.44%] [G loss: 0.797435]\n",
      "epoch:9 step:8658 [D loss: 0.681102, acc.: 52.34%] [G loss: 0.840726]\n",
      "epoch:9 step:8659 [D loss: 0.666607, acc.: 53.91%] [G loss: 0.812464]\n",
      "epoch:9 step:8660 [D loss: 0.673401, acc.: 55.47%] [G loss: 0.828214]\n",
      "epoch:9 step:8661 [D loss: 0.707086, acc.: 43.75%] [G loss: 0.802425]\n",
      "epoch:9 step:8662 [D loss: 0.686695, acc.: 56.25%] [G loss: 0.774222]\n",
      "epoch:9 step:8663 [D loss: 0.649577, acc.: 58.59%] [G loss: 0.765498]\n",
      "epoch:9 step:8664 [D loss: 0.657224, acc.: 60.16%] [G loss: 0.798748]\n",
      "epoch:9 step:8665 [D loss: 0.656629, acc.: 59.38%] [G loss: 0.763710]\n",
      "epoch:9 step:8666 [D loss: 0.719263, acc.: 46.88%] [G loss: 0.789298]\n",
      "epoch:9 step:8667 [D loss: 0.677890, acc.: 56.25%] [G loss: 0.768981]\n",
      "epoch:9 step:8668 [D loss: 0.688758, acc.: 64.06%] [G loss: 0.806716]\n",
      "epoch:9 step:8669 [D loss: 0.723846, acc.: 49.22%] [G loss: 0.753758]\n",
      "epoch:9 step:8670 [D loss: 0.686634, acc.: 57.81%] [G loss: 0.793256]\n",
      "epoch:9 step:8671 [D loss: 0.677736, acc.: 53.12%] [G loss: 0.790447]\n",
      "epoch:9 step:8672 [D loss: 0.686247, acc.: 50.78%] [G loss: 0.759114]\n",
      "epoch:9 step:8673 [D loss: 0.692295, acc.: 51.56%] [G loss: 0.775080]\n",
      "epoch:9 step:8674 [D loss: 0.682242, acc.: 53.91%] [G loss: 0.770106]\n",
      "epoch:9 step:8675 [D loss: 0.667809, acc.: 60.16%] [G loss: 0.746851]\n",
      "epoch:9 step:8676 [D loss: 0.674690, acc.: 56.25%] [G loss: 0.725468]\n",
      "epoch:9 step:8677 [D loss: 0.678196, acc.: 54.69%] [G loss: 0.747363]\n",
      "epoch:9 step:8678 [D loss: 0.684894, acc.: 54.69%] [G loss: 0.716109]\n",
      "epoch:9 step:8679 [D loss: 0.714231, acc.: 47.66%] [G loss: 0.716408]\n",
      "epoch:9 step:8680 [D loss: 0.705171, acc.: 50.78%] [G loss: 0.715557]\n",
      "epoch:9 step:8681 [D loss: 0.673409, acc.: 59.38%] [G loss: 0.712933]\n",
      "epoch:9 step:8682 [D loss: 0.709076, acc.: 42.19%] [G loss: 0.728577]\n",
      "epoch:9 step:8683 [D loss: 0.690745, acc.: 52.34%] [G loss: 0.751971]\n",
      "epoch:9 step:8684 [D loss: 0.684599, acc.: 57.81%] [G loss: 0.775157]\n",
      "epoch:9 step:8685 [D loss: 0.683573, acc.: 57.03%] [G loss: 0.773679]\n",
      "epoch:9 step:8686 [D loss: 0.674991, acc.: 60.16%] [G loss: 0.789944]\n",
      "epoch:9 step:8687 [D loss: 0.670842, acc.: 59.38%] [G loss: 0.825007]\n",
      "epoch:9 step:8688 [D loss: 0.684425, acc.: 54.69%] [G loss: 0.752399]\n",
      "epoch:9 step:8689 [D loss: 0.716365, acc.: 42.19%] [G loss: 0.735848]\n",
      "epoch:9 step:8690 [D loss: 0.676645, acc.: 57.81%] [G loss: 0.750583]\n",
      "epoch:9 step:8691 [D loss: 0.701886, acc.: 50.78%] [G loss: 0.709291]\n",
      "epoch:9 step:8692 [D loss: 0.709070, acc.: 46.88%] [G loss: 0.746044]\n",
      "epoch:9 step:8693 [D loss: 0.719702, acc.: 40.62%] [G loss: 0.598377]\n",
      "epoch:9 step:8694 [D loss: 0.687132, acc.: 50.00%] [G loss: 0.730783]\n",
      "epoch:9 step:8695 [D loss: 0.689929, acc.: 58.59%] [G loss: 0.711416]\n",
      "epoch:9 step:8696 [D loss: 0.623024, acc.: 65.62%] [G loss: 0.741090]\n",
      "epoch:9 step:8697 [D loss: 0.694638, acc.: 48.44%] [G loss: 0.738688]\n",
      "epoch:9 step:8698 [D loss: 0.718092, acc.: 48.44%] [G loss: 0.752007]\n",
      "epoch:9 step:8699 [D loss: 0.699229, acc.: 50.00%] [G loss: 0.751308]\n",
      "epoch:9 step:8700 [D loss: 0.693872, acc.: 50.00%] [G loss: 0.745228]\n",
      "epoch:9 step:8701 [D loss: 0.712051, acc.: 48.44%] [G loss: 0.760072]\n",
      "epoch:9 step:8702 [D loss: 0.704680, acc.: 48.44%] [G loss: 0.757228]\n",
      "epoch:9 step:8703 [D loss: 0.688698, acc.: 44.53%] [G loss: 0.799165]\n",
      "epoch:9 step:8704 [D loss: 0.682013, acc.: 49.22%] [G loss: 0.763944]\n",
      "epoch:9 step:8705 [D loss: 0.701149, acc.: 48.44%] [G loss: 0.768173]\n",
      "epoch:9 step:8706 [D loss: 0.691835, acc.: 56.25%] [G loss: 0.784717]\n",
      "epoch:9 step:8707 [D loss: 0.656885, acc.: 67.97%] [G loss: 0.795123]\n",
      "epoch:9 step:8708 [D loss: 0.661875, acc.: 60.94%] [G loss: 0.783551]\n",
      "epoch:9 step:8709 [D loss: 0.654457, acc.: 62.50%] [G loss: 0.799035]\n",
      "epoch:9 step:8710 [D loss: 0.692289, acc.: 53.91%] [G loss: 0.728761]\n",
      "epoch:9 step:8711 [D loss: 0.704886, acc.: 52.34%] [G loss: 0.771124]\n",
      "epoch:9 step:8712 [D loss: 0.715193, acc.: 48.44%] [G loss: 0.746729]\n",
      "epoch:9 step:8713 [D loss: 0.725303, acc.: 48.44%] [G loss: 0.736333]\n",
      "epoch:9 step:8714 [D loss: 0.743971, acc.: 36.72%] [G loss: 0.738032]\n",
      "epoch:9 step:8715 [D loss: 0.713591, acc.: 45.31%] [G loss: 0.715146]\n",
      "epoch:9 step:8716 [D loss: 0.708779, acc.: 47.66%] [G loss: 0.740903]\n",
      "epoch:9 step:8717 [D loss: 0.700279, acc.: 46.88%] [G loss: 0.725799]\n",
      "epoch:9 step:8718 [D loss: 0.700900, acc.: 43.75%] [G loss: 0.762549]\n",
      "epoch:9 step:8719 [D loss: 0.704337, acc.: 50.78%] [G loss: 0.755448]\n",
      "epoch:9 step:8720 [D loss: 0.688242, acc.: 53.12%] [G loss: 0.767697]\n",
      "epoch:9 step:8721 [D loss: 0.689462, acc.: 49.22%] [G loss: 0.765075]\n",
      "epoch:9 step:8722 [D loss: 0.679298, acc.: 56.25%] [G loss: 0.752313]\n",
      "epoch:9 step:8723 [D loss: 0.680775, acc.: 49.22%] [G loss: 0.750990]\n",
      "epoch:9 step:8724 [D loss: 0.739108, acc.: 40.62%] [G loss: 0.761536]\n",
      "epoch:9 step:8725 [D loss: 0.691675, acc.: 59.38%] [G loss: 0.784363]\n",
      "epoch:9 step:8726 [D loss: 0.669454, acc.: 59.38%] [G loss: 0.717422]\n",
      "epoch:9 step:8727 [D loss: 0.702797, acc.: 52.34%] [G loss: 0.749446]\n",
      "epoch:9 step:8728 [D loss: 0.704879, acc.: 46.09%] [G loss: 0.704291]\n",
      "epoch:9 step:8729 [D loss: 0.707592, acc.: 50.00%] [G loss: 0.751910]\n",
      "epoch:9 step:8730 [D loss: 0.708138, acc.: 39.84%] [G loss: 0.749704]\n",
      "epoch:9 step:8731 [D loss: 0.702124, acc.: 44.53%] [G loss: 0.776412]\n",
      "epoch:9 step:8732 [D loss: 0.692311, acc.: 51.56%] [G loss: 0.751082]\n",
      "epoch:9 step:8733 [D loss: 0.680496, acc.: 57.81%] [G loss: 0.748946]\n",
      "epoch:9 step:8734 [D loss: 0.698843, acc.: 53.91%] [G loss: 0.740515]\n",
      "epoch:9 step:8735 [D loss: 0.699697, acc.: 50.78%] [G loss: 0.719374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8736 [D loss: 0.954921, acc.: 38.28%] [G loss: 0.721748]\n",
      "epoch:9 step:8737 [D loss: 0.705262, acc.: 55.47%] [G loss: 0.754642]\n",
      "epoch:9 step:8738 [D loss: 0.659267, acc.: 60.94%] [G loss: 0.737064]\n",
      "epoch:9 step:8739 [D loss: 0.715296, acc.: 45.31%] [G loss: 0.741438]\n",
      "epoch:9 step:8740 [D loss: 0.687445, acc.: 60.94%] [G loss: 0.757946]\n",
      "epoch:9 step:8741 [D loss: 0.701077, acc.: 49.22%] [G loss: 0.720131]\n",
      "epoch:9 step:8742 [D loss: 0.685489, acc.: 54.69%] [G loss: 0.732626]\n",
      "epoch:9 step:8743 [D loss: 0.697932, acc.: 53.12%] [G loss: 0.698369]\n",
      "epoch:9 step:8744 [D loss: 0.694443, acc.: 54.69%] [G loss: 0.719487]\n",
      "epoch:9 step:8745 [D loss: 0.678102, acc.: 57.81%] [G loss: 0.768646]\n",
      "epoch:9 step:8746 [D loss: 0.687090, acc.: 49.22%] [G loss: 0.705869]\n",
      "epoch:9 step:8747 [D loss: 0.675852, acc.: 52.34%] [G loss: 0.727330]\n",
      "epoch:9 step:8748 [D loss: 0.671748, acc.: 57.81%] [G loss: 0.678258]\n",
      "epoch:9 step:8749 [D loss: 0.723668, acc.: 48.44%] [G loss: 0.693756]\n",
      "epoch:9 step:8750 [D loss: 0.718227, acc.: 42.97%] [G loss: 0.742289]\n",
      "epoch:9 step:8751 [D loss: 0.681561, acc.: 60.16%] [G loss: 0.722073]\n",
      "epoch:9 step:8752 [D loss: 0.724917, acc.: 39.06%] [G loss: 0.727625]\n",
      "epoch:9 step:8753 [D loss: 0.695568, acc.: 51.56%] [G loss: 0.733612]\n",
      "epoch:9 step:8754 [D loss: 0.709955, acc.: 40.62%] [G loss: 0.724880]\n",
      "epoch:9 step:8755 [D loss: 0.700828, acc.: 48.44%] [G loss: 0.711107]\n",
      "epoch:9 step:8756 [D loss: 0.709925, acc.: 45.31%] [G loss: 0.708418]\n",
      "epoch:9 step:8757 [D loss: 0.681173, acc.: 58.59%] [G loss: 0.691131]\n",
      "epoch:9 step:8758 [D loss: 0.692940, acc.: 51.56%] [G loss: 0.687768]\n",
      "epoch:9 step:8759 [D loss: 0.690253, acc.: 53.91%] [G loss: 0.702668]\n",
      "epoch:9 step:8760 [D loss: 0.686068, acc.: 53.12%] [G loss: 0.712001]\n",
      "epoch:9 step:8761 [D loss: 0.687720, acc.: 57.81%] [G loss: 0.745517]\n",
      "epoch:9 step:8762 [D loss: 0.685385, acc.: 53.12%] [G loss: 0.736961]\n",
      "epoch:9 step:8763 [D loss: 0.687220, acc.: 47.66%] [G loss: 0.734488]\n",
      "epoch:9 step:8764 [D loss: 0.691411, acc.: 56.25%] [G loss: 0.731322]\n",
      "epoch:9 step:8765 [D loss: 0.698734, acc.: 48.44%] [G loss: 0.716375]\n",
      "epoch:9 step:8766 [D loss: 0.699254, acc.: 47.66%] [G loss: 0.718915]\n",
      "epoch:9 step:8767 [D loss: 0.704636, acc.: 50.00%] [G loss: 0.698788]\n",
      "epoch:9 step:8768 [D loss: 0.700979, acc.: 48.44%] [G loss: 0.704344]\n",
      "epoch:9 step:8769 [D loss: 0.683723, acc.: 59.38%] [G loss: 0.718233]\n",
      "epoch:9 step:8770 [D loss: 0.678581, acc.: 54.69%] [G loss: 0.703280]\n",
      "epoch:9 step:8771 [D loss: 0.681534, acc.: 61.72%] [G loss: 0.703078]\n",
      "epoch:9 step:8772 [D loss: 0.680976, acc.: 57.03%] [G loss: 0.716724]\n",
      "epoch:9 step:8773 [D loss: 0.706985, acc.: 44.53%] [G loss: 0.713741]\n",
      "epoch:9 step:8774 [D loss: 0.710428, acc.: 44.53%] [G loss: 0.717885]\n",
      "epoch:9 step:8775 [D loss: 0.689552, acc.: 52.34%] [G loss: 0.700984]\n",
      "epoch:9 step:8776 [D loss: 0.691204, acc.: 51.56%] [G loss: 0.721213]\n",
      "epoch:9 step:8777 [D loss: 0.684573, acc.: 56.25%] [G loss: 0.704111]\n",
      "epoch:9 step:8778 [D loss: 0.702932, acc.: 46.88%] [G loss: 0.706445]\n",
      "epoch:9 step:8779 [D loss: 0.699418, acc.: 50.00%] [G loss: 0.722345]\n",
      "epoch:9 step:8780 [D loss: 0.684703, acc.: 54.69%] [G loss: 0.725478]\n",
      "epoch:9 step:8781 [D loss: 0.695707, acc.: 50.78%] [G loss: 0.722468]\n",
      "epoch:9 step:8782 [D loss: 0.694907, acc.: 51.56%] [G loss: 0.707753]\n",
      "epoch:9 step:8783 [D loss: 0.691477, acc.: 54.69%] [G loss: 0.735803]\n",
      "epoch:9 step:8784 [D loss: 0.695800, acc.: 47.66%] [G loss: 0.731995]\n",
      "epoch:9 step:8785 [D loss: 0.693992, acc.: 52.34%] [G loss: 0.725617]\n",
      "epoch:9 step:8786 [D loss: 0.689834, acc.: 56.25%] [G loss: 0.717489]\n",
      "epoch:9 step:8787 [D loss: 0.695890, acc.: 50.78%] [G loss: 0.749176]\n",
      "epoch:9 step:8788 [D loss: 0.701011, acc.: 43.75%] [G loss: 0.734164]\n",
      "epoch:9 step:8789 [D loss: 0.688842, acc.: 54.69%] [G loss: 0.724463]\n",
      "epoch:9 step:8790 [D loss: 0.694900, acc.: 50.00%] [G loss: 0.746444]\n",
      "epoch:9 step:8791 [D loss: 0.672228, acc.: 61.72%] [G loss: 0.756307]\n",
      "epoch:9 step:8792 [D loss: 0.688271, acc.: 55.47%] [G loss: 0.752819]\n",
      "epoch:9 step:8793 [D loss: 0.669014, acc.: 60.16%] [G loss: 0.750152]\n",
      "epoch:9 step:8794 [D loss: 0.674998, acc.: 58.59%] [G loss: 0.792687]\n",
      "epoch:9 step:8795 [D loss: 0.688282, acc.: 52.34%] [G loss: 0.753226]\n",
      "epoch:9 step:8796 [D loss: 0.705553, acc.: 47.66%] [G loss: 0.740493]\n",
      "epoch:9 step:8797 [D loss: 0.683613, acc.: 56.25%] [G loss: 0.730166]\n",
      "epoch:9 step:8798 [D loss: 0.705860, acc.: 46.88%] [G loss: 0.680856]\n",
      "epoch:9 step:8799 [D loss: 0.695911, acc.: 51.56%] [G loss: 0.721620]\n",
      "epoch:9 step:8800 [D loss: 0.720123, acc.: 35.16%] [G loss: 0.706381]\n",
      "epoch:9 step:8801 [D loss: 0.703899, acc.: 42.19%] [G loss: 0.688141]\n",
      "epoch:9 step:8802 [D loss: 0.707378, acc.: 45.31%] [G loss: 0.718038]\n",
      "epoch:9 step:8803 [D loss: 0.701687, acc.: 46.88%] [G loss: 0.705339]\n",
      "epoch:9 step:8804 [D loss: 0.704744, acc.: 44.53%] [G loss: 0.732290]\n",
      "epoch:9 step:8805 [D loss: 0.682735, acc.: 55.47%] [G loss: 0.706102]\n",
      "epoch:9 step:8806 [D loss: 0.704605, acc.: 46.88%] [G loss: 0.729843]\n",
      "epoch:9 step:8807 [D loss: 0.680799, acc.: 57.03%] [G loss: 0.724024]\n",
      "epoch:9 step:8808 [D loss: 0.696727, acc.: 47.66%] [G loss: 0.721921]\n",
      "epoch:9 step:8809 [D loss: 0.692894, acc.: 49.22%] [G loss: 0.734090]\n",
      "epoch:9 step:8810 [D loss: 0.719746, acc.: 42.19%] [G loss: 0.716557]\n",
      "epoch:9 step:8811 [D loss: 0.700579, acc.: 42.19%] [G loss: 0.708107]\n",
      "epoch:9 step:8812 [D loss: 0.689221, acc.: 57.03%] [G loss: 0.702798]\n",
      "epoch:9 step:8813 [D loss: 0.670880, acc.: 61.72%] [G loss: 0.715101]\n",
      "epoch:9 step:8814 [D loss: 0.683964, acc.: 51.56%] [G loss: 0.722849]\n",
      "epoch:9 step:8815 [D loss: 0.680166, acc.: 57.81%] [G loss: 0.736353]\n",
      "epoch:9 step:8816 [D loss: 0.706600, acc.: 50.00%] [G loss: 0.713370]\n",
      "epoch:9 step:8817 [D loss: 0.688526, acc.: 53.91%] [G loss: 0.721521]\n",
      "epoch:9 step:8818 [D loss: 0.683370, acc.: 53.91%] [G loss: 0.687639]\n",
      "epoch:9 step:8819 [D loss: 0.693354, acc.: 46.09%] [G loss: 0.707208]\n",
      "epoch:9 step:8820 [D loss: 0.672897, acc.: 62.50%] [G loss: 0.713413]\n",
      "epoch:9 step:8821 [D loss: 0.678853, acc.: 61.72%] [G loss: 0.718063]\n",
      "epoch:9 step:8822 [D loss: 0.689338, acc.: 55.47%] [G loss: 0.732595]\n",
      "epoch:9 step:8823 [D loss: 0.688088, acc.: 53.91%] [G loss: 0.744558]\n",
      "epoch:9 step:8824 [D loss: 0.677563, acc.: 63.28%] [G loss: 0.748684]\n",
      "epoch:9 step:8825 [D loss: 0.702582, acc.: 46.88%] [G loss: 0.763036]\n",
      "epoch:9 step:8826 [D loss: 0.682432, acc.: 49.22%] [G loss: 0.738802]\n",
      "epoch:9 step:8827 [D loss: 0.692704, acc.: 55.47%] [G loss: 0.778682]\n",
      "epoch:9 step:8828 [D loss: 0.697439, acc.: 50.00%] [G loss: 0.738368]\n",
      "epoch:9 step:8829 [D loss: 0.687745, acc.: 56.25%] [G loss: 0.744895]\n",
      "epoch:9 step:8830 [D loss: 0.676259, acc.: 59.38%] [G loss: 0.762653]\n",
      "epoch:9 step:8831 [D loss: 0.667498, acc.: 66.41%] [G loss: 0.767964]\n",
      "epoch:9 step:8832 [D loss: 0.668167, acc.: 57.81%] [G loss: 0.780733]\n",
      "epoch:9 step:8833 [D loss: 0.676544, acc.: 57.81%] [G loss: 0.738871]\n",
      "epoch:9 step:8834 [D loss: 0.696354, acc.: 49.22%] [G loss: 0.705242]\n",
      "epoch:9 step:8835 [D loss: 0.705009, acc.: 50.00%] [G loss: 0.783057]\n",
      "epoch:9 step:8836 [D loss: 0.711316, acc.: 51.56%] [G loss: 0.694470]\n",
      "epoch:9 step:8837 [D loss: 0.687978, acc.: 53.91%] [G loss: 0.713625]\n",
      "epoch:9 step:8838 [D loss: 0.674518, acc.: 57.81%] [G loss: 0.708536]\n",
      "epoch:9 step:8839 [D loss: 0.664366, acc.: 60.94%] [G loss: 0.699868]\n",
      "epoch:9 step:8840 [D loss: 0.679744, acc.: 57.03%] [G loss: 0.684732]\n",
      "epoch:9 step:8841 [D loss: 0.686864, acc.: 52.34%] [G loss: 0.733496]\n",
      "epoch:9 step:8842 [D loss: 0.705785, acc.: 47.66%] [G loss: 0.702414]\n",
      "epoch:9 step:8843 [D loss: 0.695228, acc.: 47.66%] [G loss: 0.679769]\n",
      "epoch:9 step:8844 [D loss: 0.730610, acc.: 40.62%] [G loss: 0.724242]\n",
      "epoch:9 step:8845 [D loss: 0.687608, acc.: 50.78%] [G loss: 0.739220]\n",
      "epoch:9 step:8846 [D loss: 0.698546, acc.: 49.22%] [G loss: 0.739719]\n",
      "epoch:9 step:8847 [D loss: 0.691370, acc.: 50.00%] [G loss: 0.706317]\n",
      "epoch:9 step:8848 [D loss: 0.680752, acc.: 55.47%] [G loss: 0.658701]\n",
      "epoch:9 step:8849 [D loss: 0.677657, acc.: 54.69%] [G loss: 0.742484]\n",
      "epoch:9 step:8850 [D loss: 0.691348, acc.: 51.56%] [G loss: 0.732746]\n",
      "epoch:9 step:8851 [D loss: 0.685293, acc.: 57.03%] [G loss: 0.723994]\n",
      "epoch:9 step:8852 [D loss: 0.707576, acc.: 42.97%] [G loss: 0.689963]\n",
      "epoch:9 step:8853 [D loss: 0.707253, acc.: 42.97%] [G loss: 0.710517]\n",
      "epoch:9 step:8854 [D loss: 0.712350, acc.: 38.28%] [G loss: 0.709438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8855 [D loss: 0.704901, acc.: 46.09%] [G loss: 0.703130]\n",
      "epoch:9 step:8856 [D loss: 0.702398, acc.: 46.09%] [G loss: 0.705157]\n",
      "epoch:9 step:8857 [D loss: 0.696304, acc.: 54.69%] [G loss: 0.723362]\n",
      "epoch:9 step:8858 [D loss: 0.691399, acc.: 52.34%] [G loss: 0.718258]\n",
      "epoch:9 step:8859 [D loss: 0.687291, acc.: 59.38%] [G loss: 0.738668]\n",
      "epoch:9 step:8860 [D loss: 0.684397, acc.: 58.59%] [G loss: 0.718976]\n",
      "epoch:9 step:8861 [D loss: 0.676438, acc.: 57.81%] [G loss: 0.751501]\n",
      "epoch:9 step:8862 [D loss: 0.682931, acc.: 59.38%] [G loss: 0.774367]\n",
      "epoch:9 step:8863 [D loss: 0.673491, acc.: 56.25%] [G loss: 0.736174]\n",
      "epoch:9 step:8864 [D loss: 0.702072, acc.: 53.91%] [G loss: 0.724923]\n",
      "epoch:9 step:8865 [D loss: 0.716278, acc.: 40.62%] [G loss: 0.786820]\n",
      "epoch:9 step:8866 [D loss: 0.692527, acc.: 52.34%] [G loss: 0.771582]\n",
      "epoch:9 step:8867 [D loss: 0.697294, acc.: 50.00%] [G loss: 0.760760]\n",
      "epoch:9 step:8868 [D loss: 0.701239, acc.: 50.00%] [G loss: 0.755715]\n",
      "epoch:9 step:8869 [D loss: 0.672927, acc.: 60.16%] [G loss: 0.745362]\n",
      "epoch:9 step:8870 [D loss: 0.688691, acc.: 56.25%] [G loss: 0.755844]\n",
      "epoch:9 step:8871 [D loss: 0.678673, acc.: 58.59%] [G loss: 0.733786]\n",
      "epoch:9 step:8872 [D loss: 0.685974, acc.: 57.03%] [G loss: 0.733663]\n",
      "epoch:9 step:8873 [D loss: 0.702410, acc.: 54.69%] [G loss: 0.733999]\n",
      "epoch:9 step:8874 [D loss: 0.710802, acc.: 42.19%] [G loss: 0.731957]\n",
      "epoch:9 step:8875 [D loss: 0.701869, acc.: 44.53%] [G loss: 0.747492]\n",
      "epoch:9 step:8876 [D loss: 0.703755, acc.: 48.44%] [G loss: 0.725105]\n",
      "epoch:9 step:8877 [D loss: 0.705938, acc.: 46.88%] [G loss: 0.694168]\n",
      "epoch:9 step:8878 [D loss: 0.685561, acc.: 52.34%] [G loss: 0.726601]\n",
      "epoch:9 step:8879 [D loss: 0.696301, acc.: 48.44%] [G loss: 0.722554]\n",
      "epoch:9 step:8880 [D loss: 0.693962, acc.: 52.34%] [G loss: 0.735019]\n",
      "epoch:9 step:8881 [D loss: 0.702772, acc.: 48.44%] [G loss: 0.730953]\n",
      "epoch:9 step:8882 [D loss: 0.692374, acc.: 50.78%] [G loss: 0.751235]\n",
      "epoch:9 step:8883 [D loss: 0.678836, acc.: 57.03%] [G loss: 0.734456]\n",
      "epoch:9 step:8884 [D loss: 0.674695, acc.: 63.28%] [G loss: 0.748090]\n",
      "epoch:9 step:8885 [D loss: 0.660777, acc.: 64.06%] [G loss: 0.775370]\n",
      "epoch:9 step:8886 [D loss: 0.677935, acc.: 59.38%] [G loss: 0.773968]\n",
      "epoch:9 step:8887 [D loss: 0.659827, acc.: 65.62%] [G loss: 0.784578]\n",
      "epoch:9 step:8888 [D loss: 0.678353, acc.: 64.84%] [G loss: 0.755457]\n",
      "epoch:9 step:8889 [D loss: 0.627795, acc.: 67.19%] [G loss: 0.816538]\n",
      "epoch:9 step:8890 [D loss: 0.656952, acc.: 67.97%] [G loss: 0.793653]\n",
      "epoch:9 step:8891 [D loss: 0.724445, acc.: 43.75%] [G loss: 0.765332]\n",
      "epoch:9 step:8892 [D loss: 0.692819, acc.: 53.12%] [G loss: 0.762159]\n",
      "epoch:9 step:8893 [D loss: 0.691657, acc.: 51.56%] [G loss: 0.701715]\n",
      "epoch:9 step:8894 [D loss: 0.713259, acc.: 44.53%] [G loss: 0.721633]\n",
      "epoch:9 step:8895 [D loss: 0.734134, acc.: 35.16%] [G loss: 0.739466]\n",
      "epoch:9 step:8896 [D loss: 0.717704, acc.: 45.31%] [G loss: 0.721083]\n",
      "epoch:9 step:8897 [D loss: 0.704862, acc.: 46.09%] [G loss: 0.715267]\n",
      "epoch:9 step:8898 [D loss: 0.687977, acc.: 52.34%] [G loss: 0.723309]\n",
      "epoch:9 step:8899 [D loss: 0.692376, acc.: 50.78%] [G loss: 0.700536]\n",
      "epoch:9 step:8900 [D loss: 0.681993, acc.: 56.25%] [G loss: 0.785933]\n",
      "epoch:9 step:8901 [D loss: 0.658665, acc.: 58.59%] [G loss: 0.676384]\n",
      "epoch:9 step:8902 [D loss: 0.660409, acc.: 63.28%] [G loss: 0.730567]\n",
      "epoch:9 step:8903 [D loss: 0.658429, acc.: 62.50%] [G loss: 0.748875]\n",
      "epoch:9 step:8904 [D loss: 0.664397, acc.: 58.59%] [G loss: 0.742741]\n",
      "epoch:9 step:8905 [D loss: 0.734380, acc.: 38.28%] [G loss: 0.744193]\n",
      "epoch:9 step:8906 [D loss: 0.715793, acc.: 42.97%] [G loss: 0.750508]\n",
      "epoch:9 step:8907 [D loss: 0.715050, acc.: 42.19%] [G loss: 0.735526]\n",
      "epoch:9 step:8908 [D loss: 0.686640, acc.: 53.12%] [G loss: 0.689952]\n",
      "epoch:9 step:8909 [D loss: 0.684664, acc.: 57.03%] [G loss: 0.751027]\n",
      "epoch:9 step:8910 [D loss: 0.694117, acc.: 50.78%] [G loss: 0.755873]\n",
      "epoch:9 step:8911 [D loss: 0.703320, acc.: 48.44%] [G loss: 0.743792]\n",
      "epoch:9 step:8912 [D loss: 0.718792, acc.: 42.19%] [G loss: 0.719665]\n",
      "epoch:9 step:8913 [D loss: 0.672220, acc.: 62.50%] [G loss: 0.714215]\n",
      "epoch:9 step:8914 [D loss: 0.671973, acc.: 55.47%] [G loss: 0.729459]\n",
      "epoch:9 step:8915 [D loss: 0.691537, acc.: 50.78%] [G loss: 0.728115]\n",
      "epoch:9 step:8916 [D loss: 0.691088, acc.: 49.22%] [G loss: 0.702010]\n",
      "epoch:9 step:8917 [D loss: 0.652532, acc.: 69.53%] [G loss: 0.738387]\n",
      "epoch:9 step:8918 [D loss: 0.652809, acc.: 69.53%] [G loss: 0.759017]\n",
      "epoch:9 step:8919 [D loss: 0.660886, acc.: 61.72%] [G loss: 0.774690]\n",
      "epoch:9 step:8920 [D loss: 0.676621, acc.: 57.03%] [G loss: 0.766082]\n",
      "epoch:9 step:8921 [D loss: 0.678768, acc.: 51.56%] [G loss: 0.787279]\n",
      "epoch:9 step:8922 [D loss: 0.697887, acc.: 53.12%] [G loss: 0.798349]\n",
      "epoch:9 step:8923 [D loss: 0.686440, acc.: 60.94%] [G loss: 0.755422]\n",
      "epoch:9 step:8924 [D loss: 0.667845, acc.: 60.94%] [G loss: 0.746669]\n",
      "epoch:9 step:8925 [D loss: 0.707502, acc.: 49.22%] [G loss: 0.764296]\n",
      "epoch:9 step:8926 [D loss: 0.727964, acc.: 40.62%] [G loss: 0.709399]\n",
      "epoch:9 step:8927 [D loss: 0.701333, acc.: 46.88%] [G loss: 0.728120]\n",
      "epoch:9 step:8928 [D loss: 0.666154, acc.: 61.72%] [G loss: 0.701377]\n",
      "epoch:9 step:8929 [D loss: 0.716557, acc.: 44.53%] [G loss: 0.673782]\n",
      "epoch:9 step:8930 [D loss: 0.696786, acc.: 53.91%] [G loss: 0.746321]\n",
      "epoch:9 step:8931 [D loss: 0.683736, acc.: 58.59%] [G loss: 0.753797]\n",
      "epoch:9 step:8932 [D loss: 0.653775, acc.: 65.62%] [G loss: 0.812749]\n",
      "epoch:9 step:8933 [D loss: 0.702242, acc.: 50.78%] [G loss: 0.775605]\n",
      "epoch:9 step:8934 [D loss: 0.719836, acc.: 41.41%] [G loss: 0.805430]\n",
      "epoch:9 step:8935 [D loss: 0.695945, acc.: 53.12%] [G loss: 0.778091]\n",
      "epoch:9 step:8936 [D loss: 0.743605, acc.: 42.19%] [G loss: 0.754215]\n",
      "epoch:9 step:8937 [D loss: 0.682162, acc.: 55.47%] [G loss: 0.770186]\n",
      "epoch:9 step:8938 [D loss: 0.647637, acc.: 62.50%] [G loss: 0.774043]\n",
      "epoch:9 step:8939 [D loss: 0.701678, acc.: 47.66%] [G loss: 0.785999]\n",
      "epoch:9 step:8940 [D loss: 0.646863, acc.: 67.97%] [G loss: 0.775428]\n",
      "epoch:9 step:8941 [D loss: 0.660954, acc.: 58.59%] [G loss: 0.784529]\n",
      "epoch:9 step:8942 [D loss: 0.720307, acc.: 45.31%] [G loss: 0.755181]\n",
      "epoch:9 step:8943 [D loss: 0.725559, acc.: 39.06%] [G loss: 0.715025]\n",
      "epoch:9 step:8944 [D loss: 0.730199, acc.: 39.84%] [G loss: 0.722554]\n",
      "epoch:9 step:8945 [D loss: 0.692664, acc.: 50.78%] [G loss: 0.737515]\n",
      "epoch:9 step:8946 [D loss: 0.691614, acc.: 49.22%] [G loss: 0.737249]\n",
      "epoch:9 step:8947 [D loss: 0.700548, acc.: 45.31%] [G loss: 0.735873]\n",
      "epoch:9 step:8948 [D loss: 0.685905, acc.: 50.00%] [G loss: 0.744318]\n",
      "epoch:9 step:8949 [D loss: 0.665777, acc.: 63.28%] [G loss: 0.750650]\n",
      "epoch:9 step:8950 [D loss: 0.672959, acc.: 55.47%] [G loss: 0.761045]\n",
      "epoch:9 step:8951 [D loss: 0.660840, acc.: 56.25%] [G loss: 0.741538]\n",
      "epoch:9 step:8952 [D loss: 0.677881, acc.: 59.38%] [G loss: 0.737033]\n",
      "epoch:9 step:8953 [D loss: 0.660090, acc.: 63.28%] [G loss: 0.749884]\n",
      "epoch:9 step:8954 [D loss: 0.669861, acc.: 64.84%] [G loss: 0.746982]\n",
      "epoch:9 step:8955 [D loss: 0.671638, acc.: 60.94%] [G loss: 0.703008]\n",
      "epoch:9 step:8956 [D loss: 0.660284, acc.: 53.91%] [G loss: 0.735469]\n",
      "epoch:9 step:8957 [D loss: 0.704035, acc.: 43.75%] [G loss: 0.756362]\n",
      "epoch:9 step:8958 [D loss: 0.693073, acc.: 49.22%] [G loss: 0.763014]\n",
      "epoch:9 step:8959 [D loss: 0.713115, acc.: 43.75%] [G loss: 0.697454]\n",
      "epoch:9 step:8960 [D loss: 0.701882, acc.: 51.56%] [G loss: 0.729029]\n",
      "epoch:9 step:8961 [D loss: 0.717092, acc.: 43.75%] [G loss: 0.751516]\n",
      "epoch:9 step:8962 [D loss: 0.699402, acc.: 50.78%] [G loss: 0.719860]\n",
      "epoch:9 step:8963 [D loss: 0.689550, acc.: 49.22%] [G loss: 0.741819]\n",
      "epoch:9 step:8964 [D loss: 0.687247, acc.: 53.91%] [G loss: 0.738952]\n",
      "epoch:9 step:8965 [D loss: 0.666749, acc.: 66.41%] [G loss: 0.733345]\n",
      "epoch:9 step:8966 [D loss: 0.719504, acc.: 46.09%] [G loss: 0.750876]\n",
      "epoch:9 step:8967 [D loss: 0.685857, acc.: 57.81%] [G loss: 0.726884]\n",
      "epoch:9 step:8968 [D loss: 0.690867, acc.: 51.56%] [G loss: 0.754558]\n",
      "epoch:9 step:8969 [D loss: 0.697790, acc.: 52.34%] [G loss: 0.775363]\n",
      "epoch:9 step:8970 [D loss: 0.670676, acc.: 59.38%] [G loss: 0.743730]\n",
      "epoch:9 step:8971 [D loss: 0.686545, acc.: 58.59%] [G loss: 0.770567]\n",
      "epoch:9 step:8972 [D loss: 0.694040, acc.: 57.03%] [G loss: 0.779055]\n",
      "epoch:9 step:8973 [D loss: 0.679256, acc.: 56.25%] [G loss: 0.763444]\n",
      "epoch:9 step:8974 [D loss: 0.686849, acc.: 55.47%] [G loss: 0.757972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8975 [D loss: 0.734211, acc.: 50.78%] [G loss: 0.747898]\n",
      "epoch:9 step:8976 [D loss: 0.598573, acc.: 61.72%] [G loss: 0.740723]\n",
      "epoch:9 step:8977 [D loss: 0.696967, acc.: 58.59%] [G loss: 0.706489]\n",
      "epoch:9 step:8978 [D loss: 0.701779, acc.: 46.88%] [G loss: 0.713645]\n",
      "epoch:9 step:8979 [D loss: 0.679917, acc.: 56.25%] [G loss: 0.698490]\n",
      "epoch:9 step:8980 [D loss: 0.705668, acc.: 57.03%] [G loss: 0.731157]\n",
      "epoch:9 step:8981 [D loss: 0.666573, acc.: 64.84%] [G loss: 0.687134]\n",
      "epoch:9 step:8982 [D loss: 0.665144, acc.: 64.06%] [G loss: 0.720920]\n",
      "epoch:9 step:8983 [D loss: 0.546289, acc.: 71.88%] [G loss: 0.737128]\n",
      "epoch:9 step:8984 [D loss: 0.675570, acc.: 57.81%] [G loss: 0.740199]\n",
      "epoch:9 step:8985 [D loss: 0.688740, acc.: 53.12%] [G loss: 0.734074]\n",
      "epoch:9 step:8986 [D loss: 0.697130, acc.: 47.66%] [G loss: 0.729170]\n",
      "epoch:9 step:8987 [D loss: 0.658106, acc.: 65.62%] [G loss: 0.757430]\n",
      "epoch:9 step:8988 [D loss: 0.777767, acc.: 49.22%] [G loss: 0.758518]\n",
      "epoch:9 step:8989 [D loss: 0.651261, acc.: 64.06%] [G loss: 0.825418]\n",
      "epoch:9 step:8990 [D loss: 0.672973, acc.: 58.59%] [G loss: 0.795166]\n",
      "epoch:9 step:8991 [D loss: 0.666984, acc.: 59.38%] [G loss: 0.816229]\n",
      "epoch:9 step:8992 [D loss: 0.720403, acc.: 46.09%] [G loss: 0.787167]\n",
      "epoch:9 step:8993 [D loss: 0.700456, acc.: 49.22%] [G loss: 0.780450]\n",
      "epoch:9 step:8994 [D loss: 0.703908, acc.: 47.66%] [G loss: 0.783875]\n",
      "epoch:9 step:8995 [D loss: 0.699980, acc.: 47.66%] [G loss: 0.743627]\n",
      "epoch:9 step:8996 [D loss: 0.686630, acc.: 57.03%] [G loss: 0.761410]\n",
      "epoch:9 step:8997 [D loss: 0.675294, acc.: 57.03%] [G loss: 0.744831]\n",
      "epoch:9 step:8998 [D loss: 0.688894, acc.: 50.78%] [G loss: 0.781973]\n",
      "epoch:9 step:8999 [D loss: 0.749824, acc.: 30.47%] [G loss: 0.746444]\n",
      "epoch:9 step:9000 [D loss: 0.708999, acc.: 42.19%] [G loss: 0.721663]\n",
      "epoch:9 step:9001 [D loss: 0.681648, acc.: 60.94%] [G loss: 0.777831]\n",
      "epoch:9 step:9002 [D loss: 0.690543, acc.: 52.34%] [G loss: 0.789793]\n",
      "epoch:9 step:9003 [D loss: 0.663441, acc.: 65.62%] [G loss: 0.816809]\n",
      "epoch:9 step:9004 [D loss: 0.684416, acc.: 54.69%] [G loss: 0.827782]\n",
      "epoch:9 step:9005 [D loss: 0.670497, acc.: 62.50%] [G loss: 0.816314]\n",
      "epoch:9 step:9006 [D loss: 0.643848, acc.: 69.53%] [G loss: 0.788769]\n",
      "epoch:9 step:9007 [D loss: 0.620303, acc.: 73.44%] [G loss: 0.802687]\n",
      "epoch:9 step:9008 [D loss: 0.622846, acc.: 70.31%] [G loss: 0.818157]\n",
      "epoch:9 step:9009 [D loss: 0.696036, acc.: 54.69%] [G loss: 0.790937]\n",
      "epoch:9 step:9010 [D loss: 0.717966, acc.: 52.34%] [G loss: 0.751244]\n",
      "epoch:9 step:9011 [D loss: 0.701917, acc.: 50.78%] [G loss: 0.704674]\n",
      "epoch:9 step:9012 [D loss: 0.744549, acc.: 42.19%] [G loss: 0.718532]\n",
      "epoch:9 step:9013 [D loss: 0.718487, acc.: 46.88%] [G loss: 0.687958]\n",
      "epoch:9 step:9014 [D loss: 0.678116, acc.: 55.47%] [G loss: 0.701757]\n",
      "epoch:9 step:9015 [D loss: 0.691573, acc.: 46.09%] [G loss: 0.734490]\n",
      "epoch:9 step:9016 [D loss: 0.706393, acc.: 50.00%] [G loss: 0.728730]\n",
      "epoch:9 step:9017 [D loss: 0.721354, acc.: 43.75%] [G loss: 0.723153]\n",
      "epoch:9 step:9018 [D loss: 0.664181, acc.: 65.62%] [G loss: 0.795996]\n",
      "epoch:9 step:9019 [D loss: 0.661125, acc.: 66.41%] [G loss: 0.768971]\n",
      "epoch:9 step:9020 [D loss: 0.690325, acc.: 52.34%] [G loss: 0.827181]\n",
      "epoch:9 step:9021 [D loss: 0.663631, acc.: 56.25%] [G loss: 0.797656]\n",
      "epoch:9 step:9022 [D loss: 0.682407, acc.: 51.56%] [G loss: 0.819666]\n",
      "epoch:9 step:9023 [D loss: 0.662448, acc.: 56.25%] [G loss: 0.811622]\n",
      "epoch:9 step:9024 [D loss: 0.675711, acc.: 54.69%] [G loss: 0.775819]\n",
      "epoch:9 step:9025 [D loss: 0.667269, acc.: 66.41%] [G loss: 0.800471]\n",
      "epoch:9 step:9026 [D loss: 0.693111, acc.: 53.91%] [G loss: 0.730939]\n",
      "epoch:9 step:9027 [D loss: 0.689763, acc.: 57.03%] [G loss: 0.769196]\n",
      "epoch:9 step:9028 [D loss: 0.707424, acc.: 46.88%] [G loss: 0.672227]\n",
      "epoch:9 step:9029 [D loss: 0.679620, acc.: 53.12%] [G loss: 0.688091]\n",
      "epoch:9 step:9030 [D loss: 0.712604, acc.: 50.00%] [G loss: 0.715194]\n",
      "epoch:9 step:9031 [D loss: 0.753297, acc.: 48.44%] [G loss: 0.727281]\n",
      "epoch:9 step:9032 [D loss: 0.702664, acc.: 50.78%] [G loss: 0.724025]\n",
      "epoch:9 step:9033 [D loss: 0.709363, acc.: 52.34%] [G loss: 0.722635]\n",
      "epoch:9 step:9034 [D loss: 0.687999, acc.: 52.34%] [G loss: 0.735936]\n",
      "epoch:9 step:9035 [D loss: 0.682511, acc.: 53.91%] [G loss: 0.741388]\n",
      "epoch:9 step:9036 [D loss: 0.705842, acc.: 47.66%] [G loss: 0.754442]\n",
      "epoch:9 step:9037 [D loss: 0.534512, acc.: 67.19%] [G loss: 0.742361]\n",
      "epoch:9 step:9038 [D loss: 0.695725, acc.: 50.78%] [G loss: 0.769073]\n",
      "epoch:9 step:9039 [D loss: 0.689277, acc.: 51.56%] [G loss: 0.758455]\n",
      "epoch:9 step:9040 [D loss: 0.700518, acc.: 53.12%] [G loss: 0.762338]\n",
      "epoch:9 step:9041 [D loss: 0.677690, acc.: 58.59%] [G loss: 0.753875]\n",
      "epoch:9 step:9042 [D loss: 0.681070, acc.: 50.78%] [G loss: 0.753249]\n",
      "epoch:9 step:9043 [D loss: 0.688471, acc.: 50.78%] [G loss: 0.760197]\n",
      "epoch:9 step:9044 [D loss: 0.679776, acc.: 53.91%] [G loss: 0.790100]\n",
      "epoch:9 step:9045 [D loss: 0.674122, acc.: 58.59%] [G loss: 0.759086]\n",
      "epoch:9 step:9046 [D loss: 0.683828, acc.: 56.25%] [G loss: 0.742322]\n",
      "epoch:9 step:9047 [D loss: 0.705625, acc.: 45.31%] [G loss: 0.761651]\n",
      "epoch:9 step:9048 [D loss: 0.708287, acc.: 48.44%] [G loss: 0.727242]\n",
      "epoch:9 step:9049 [D loss: 0.705686, acc.: 51.56%] [G loss: 0.767153]\n",
      "epoch:9 step:9050 [D loss: 0.716130, acc.: 44.53%] [G loss: 0.755762]\n",
      "epoch:9 step:9051 [D loss: 0.689334, acc.: 51.56%] [G loss: 0.765421]\n",
      "epoch:9 step:9052 [D loss: 0.687324, acc.: 56.25%] [G loss: 0.806701]\n",
      "epoch:9 step:9053 [D loss: 0.697128, acc.: 46.88%] [G loss: 0.776759]\n",
      "epoch:9 step:9054 [D loss: 0.694710, acc.: 47.66%] [G loss: 0.738027]\n",
      "epoch:9 step:9055 [D loss: 0.699987, acc.: 50.78%] [G loss: 0.749622]\n",
      "epoch:9 step:9056 [D loss: 0.701840, acc.: 46.09%] [G loss: 0.732333]\n",
      "epoch:9 step:9057 [D loss: 0.689927, acc.: 57.03%] [G loss: 0.785933]\n",
      "epoch:9 step:9058 [D loss: 0.676138, acc.: 50.78%] [G loss: 0.832949]\n",
      "epoch:9 step:9059 [D loss: 0.689119, acc.: 50.78%] [G loss: 0.788875]\n",
      "epoch:9 step:9060 [D loss: 0.678728, acc.: 58.59%] [G loss: 0.786386]\n",
      "epoch:9 step:9061 [D loss: 0.667225, acc.: 59.38%] [G loss: 0.749895]\n",
      "epoch:9 step:9062 [D loss: 0.684515, acc.: 56.25%] [G loss: 0.706013]\n",
      "epoch:9 step:9063 [D loss: 0.664390, acc.: 63.28%] [G loss: 0.755401]\n",
      "epoch:9 step:9064 [D loss: 0.668001, acc.: 59.38%] [G loss: 0.765461]\n",
      "epoch:9 step:9065 [D loss: 0.694395, acc.: 53.12%] [G loss: 0.715186]\n",
      "epoch:9 step:9066 [D loss: 0.709509, acc.: 53.91%] [G loss: 0.715705]\n",
      "epoch:9 step:9067 [D loss: 0.702688, acc.: 55.47%] [G loss: 0.742889]\n",
      "epoch:9 step:9068 [D loss: 0.668635, acc.: 57.81%] [G loss: 0.738647]\n",
      "epoch:9 step:9069 [D loss: 0.700716, acc.: 51.56%] [G loss: 0.738179]\n",
      "epoch:9 step:9070 [D loss: 0.703832, acc.: 53.91%] [G loss: 0.754598]\n",
      "epoch:9 step:9071 [D loss: 0.673687, acc.: 57.03%] [G loss: 0.743973]\n",
      "epoch:9 step:9072 [D loss: 0.701883, acc.: 47.66%] [G loss: 0.742339]\n",
      "epoch:9 step:9073 [D loss: 0.690714, acc.: 57.03%] [G loss: 0.740946]\n",
      "epoch:9 step:9074 [D loss: 0.721735, acc.: 35.94%] [G loss: 0.722051]\n",
      "epoch:9 step:9075 [D loss: 0.687812, acc.: 57.03%] [G loss: 0.740373]\n",
      "epoch:9 step:9076 [D loss: 0.674357, acc.: 57.81%] [G loss: 0.762727]\n",
      "epoch:9 step:9077 [D loss: 0.671411, acc.: 62.50%] [G loss: 0.774021]\n",
      "epoch:9 step:9078 [D loss: 0.693069, acc.: 55.47%] [G loss: 0.728302]\n",
      "epoch:9 step:9079 [D loss: 0.702249, acc.: 53.12%] [G loss: 0.758375]\n",
      "epoch:9 step:9080 [D loss: 0.699987, acc.: 46.88%] [G loss: 0.751764]\n",
      "epoch:9 step:9081 [D loss: 0.654446, acc.: 61.72%] [G loss: 0.773933]\n",
      "epoch:9 step:9082 [D loss: 0.701768, acc.: 52.34%] [G loss: 0.773413]\n",
      "epoch:9 step:9083 [D loss: 0.638740, acc.: 64.84%] [G loss: 0.733769]\n",
      "epoch:9 step:9084 [D loss: 0.654664, acc.: 55.47%] [G loss: 0.746396]\n",
      "epoch:9 step:9085 [D loss: 0.676725, acc.: 57.03%] [G loss: 0.825935]\n",
      "epoch:9 step:9086 [D loss: 0.725189, acc.: 44.53%] [G loss: 0.748669]\n",
      "epoch:9 step:9087 [D loss: 0.770270, acc.: 31.25%] [G loss: 0.700357]\n",
      "epoch:9 step:9088 [D loss: 0.700885, acc.: 49.22%] [G loss: 0.690885]\n",
      "epoch:9 step:9089 [D loss: 0.685912, acc.: 50.00%] [G loss: 0.730486]\n",
      "epoch:9 step:9090 [D loss: 0.701629, acc.: 48.44%] [G loss: 0.698105]\n",
      "epoch:9 step:9091 [D loss: 0.687454, acc.: 54.69%] [G loss: 0.679918]\n",
      "epoch:9 step:9092 [D loss: 0.685976, acc.: 56.25%] [G loss: 0.739157]\n",
      "epoch:9 step:9093 [D loss: 0.702846, acc.: 44.53%] [G loss: 0.672059]\n",
      "epoch:9 step:9094 [D loss: 0.689961, acc.: 53.12%] [G loss: 0.732580]\n",
      "epoch:9 step:9095 [D loss: 0.697717, acc.: 45.31%] [G loss: 0.684056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9096 [D loss: 0.689270, acc.: 49.22%] [G loss: 0.723917]\n",
      "epoch:9 step:9097 [D loss: 0.682601, acc.: 56.25%] [G loss: 0.759548]\n",
      "epoch:9 step:9098 [D loss: 0.692604, acc.: 51.56%] [G loss: 0.732440]\n",
      "epoch:9 step:9099 [D loss: 0.687687, acc.: 50.78%] [G loss: 0.714414]\n",
      "epoch:9 step:9100 [D loss: 0.695083, acc.: 49.22%] [G loss: 0.705549]\n",
      "epoch:9 step:9101 [D loss: 0.679773, acc.: 57.81%] [G loss: 0.705770]\n",
      "epoch:9 step:9102 [D loss: 0.691856, acc.: 49.22%] [G loss: 0.714219]\n",
      "epoch:9 step:9103 [D loss: 0.704992, acc.: 43.75%] [G loss: 0.717057]\n",
      "epoch:9 step:9104 [D loss: 0.709747, acc.: 39.06%] [G loss: 0.726294]\n",
      "epoch:9 step:9105 [D loss: 0.698017, acc.: 46.09%] [G loss: 0.754373]\n",
      "epoch:9 step:9106 [D loss: 0.679326, acc.: 50.00%] [G loss: 0.748401]\n",
      "epoch:9 step:9107 [D loss: 0.664731, acc.: 59.38%] [G loss: 0.752645]\n",
      "epoch:9 step:9108 [D loss: 0.705949, acc.: 46.88%] [G loss: 0.707256]\n",
      "epoch:9 step:9109 [D loss: 0.680870, acc.: 57.81%] [G loss: 0.751304]\n",
      "epoch:9 step:9110 [D loss: 0.671069, acc.: 53.91%] [G loss: 0.739180]\n",
      "epoch:9 step:9111 [D loss: 0.692158, acc.: 50.00%] [G loss: 0.731297]\n",
      "epoch:9 step:9112 [D loss: 0.668512, acc.: 61.72%] [G loss: 0.758208]\n",
      "epoch:9 step:9113 [D loss: 0.670489, acc.: 56.25%] [G loss: 0.738829]\n",
      "epoch:9 step:9114 [D loss: 0.664724, acc.: 65.62%] [G loss: 0.736740]\n",
      "epoch:9 step:9115 [D loss: 0.666975, acc.: 57.03%] [G loss: 0.725174]\n",
      "epoch:9 step:9116 [D loss: 0.657839, acc.: 57.81%] [G loss: 0.752718]\n",
      "epoch:9 step:9117 [D loss: 0.661570, acc.: 61.72%] [G loss: 0.755463]\n",
      "epoch:9 step:9118 [D loss: 0.674177, acc.: 59.38%] [G loss: 0.769017]\n",
      "epoch:9 step:9119 [D loss: 0.672908, acc.: 59.38%] [G loss: 0.756315]\n",
      "epoch:9 step:9120 [D loss: 0.664863, acc.: 57.03%] [G loss: 0.759962]\n",
      "epoch:9 step:9121 [D loss: 0.666150, acc.: 53.91%] [G loss: 0.738781]\n",
      "epoch:9 step:9122 [D loss: 0.676442, acc.: 59.38%] [G loss: 0.736681]\n",
      "epoch:9 step:9123 [D loss: 0.724856, acc.: 49.22%] [G loss: 0.748452]\n",
      "epoch:9 step:9124 [D loss: 0.701259, acc.: 50.00%] [G loss: 0.731356]\n",
      "epoch:9 step:9125 [D loss: 0.718390, acc.: 50.00%] [G loss: 0.702270]\n",
      "epoch:9 step:9126 [D loss: 0.720939, acc.: 48.44%] [G loss: 0.728523]\n",
      "epoch:9 step:9127 [D loss: 0.697516, acc.: 50.00%] [G loss: 0.724930]\n",
      "epoch:9 step:9128 [D loss: 0.695448, acc.: 53.91%] [G loss: 0.737832]\n",
      "epoch:9 step:9129 [D loss: 0.714817, acc.: 46.09%] [G loss: 0.749217]\n",
      "epoch:9 step:9130 [D loss: 0.704669, acc.: 49.22%] [G loss: 0.740356]\n",
      "epoch:9 step:9131 [D loss: 0.681091, acc.: 58.59%] [G loss: 0.747871]\n",
      "epoch:9 step:9132 [D loss: 0.684294, acc.: 57.03%] [G loss: 0.791517]\n",
      "epoch:9 step:9133 [D loss: 0.679723, acc.: 57.81%] [G loss: 0.831794]\n",
      "epoch:9 step:9134 [D loss: 0.684405, acc.: 55.47%] [G loss: 0.835953]\n",
      "epoch:9 step:9135 [D loss: 0.695337, acc.: 50.78%] [G loss: 0.785495]\n",
      "epoch:9 step:9136 [D loss: 0.697584, acc.: 47.66%] [G loss: 0.792844]\n",
      "epoch:9 step:9137 [D loss: 0.672589, acc.: 60.16%] [G loss: 0.803994]\n",
      "epoch:9 step:9138 [D loss: 0.703188, acc.: 45.31%] [G loss: 0.767138]\n",
      "epoch:9 step:9139 [D loss: 0.637744, acc.: 67.97%] [G loss: 0.729689]\n",
      "epoch:9 step:9140 [D loss: 0.641326, acc.: 69.53%] [G loss: 0.747324]\n",
      "epoch:9 step:9141 [D loss: 0.650851, acc.: 66.41%] [G loss: 0.782001]\n",
      "epoch:9 step:9142 [D loss: 0.644618, acc.: 67.19%] [G loss: 0.792113]\n",
      "epoch:9 step:9143 [D loss: 0.772962, acc.: 34.38%] [G loss: 0.731865]\n",
      "epoch:9 step:9144 [D loss: 0.739419, acc.: 42.19%] [G loss: 0.729275]\n",
      "epoch:9 step:9145 [D loss: 0.687863, acc.: 56.25%] [G loss: 0.709973]\n",
      "epoch:9 step:9146 [D loss: 0.678493, acc.: 53.12%] [G loss: 0.747911]\n",
      "epoch:9 step:9147 [D loss: 0.679980, acc.: 53.91%] [G loss: 0.738771]\n",
      "epoch:9 step:9148 [D loss: 0.702827, acc.: 47.66%] [G loss: 0.721149]\n",
      "epoch:9 step:9149 [D loss: 0.714136, acc.: 42.19%] [G loss: 0.732512]\n",
      "epoch:9 step:9150 [D loss: 0.697532, acc.: 53.12%] [G loss: 0.721241]\n",
      "epoch:9 step:9151 [D loss: 0.687922, acc.: 54.69%] [G loss: 0.740684]\n",
      "epoch:9 step:9152 [D loss: 0.688132, acc.: 55.47%] [G loss: 0.742487]\n",
      "epoch:9 step:9153 [D loss: 0.678128, acc.: 56.25%] [G loss: 0.781672]\n",
      "epoch:9 step:9154 [D loss: 0.649916, acc.: 63.28%] [G loss: 0.760665]\n",
      "epoch:9 step:9155 [D loss: 0.678034, acc.: 64.06%] [G loss: 0.784699]\n",
      "epoch:9 step:9156 [D loss: 0.682551, acc.: 63.28%] [G loss: 0.742551]\n",
      "epoch:9 step:9157 [D loss: 0.659243, acc.: 57.81%] [G loss: 0.791369]\n",
      "epoch:9 step:9158 [D loss: 0.683827, acc.: 55.47%] [G loss: 0.694686]\n",
      "epoch:9 step:9159 [D loss: 0.667702, acc.: 57.81%] [G loss: 0.825521]\n",
      "epoch:9 step:9160 [D loss: 0.706906, acc.: 42.19%] [G loss: 0.835008]\n",
      "epoch:9 step:9161 [D loss: 0.693763, acc.: 54.69%] [G loss: 0.742026]\n",
      "epoch:9 step:9162 [D loss: 0.694790, acc.: 51.56%] [G loss: 0.853796]\n",
      "epoch:9 step:9163 [D loss: 0.687128, acc.: 55.47%] [G loss: 0.814881]\n",
      "epoch:9 step:9164 [D loss: 0.697345, acc.: 53.91%] [G loss: 0.751555]\n",
      "epoch:9 step:9165 [D loss: 0.689336, acc.: 57.03%] [G loss: 0.742789]\n",
      "epoch:9 step:9166 [D loss: 0.701155, acc.: 53.12%] [G loss: 0.759993]\n",
      "epoch:9 step:9167 [D loss: 0.706122, acc.: 48.44%] [G loss: 0.518819]\n",
      "epoch:9 step:9168 [D loss: 0.700516, acc.: 49.22%] [G loss: 0.738640]\n",
      "epoch:9 step:9169 [D loss: 0.660848, acc.: 58.59%] [G loss: 0.733450]\n",
      "epoch:9 step:9170 [D loss: 0.684975, acc.: 57.81%] [G loss: 0.715991]\n",
      "epoch:9 step:9171 [D loss: 0.705822, acc.: 49.22%] [G loss: 0.724418]\n",
      "epoch:9 step:9172 [D loss: 0.746807, acc.: 36.72%] [G loss: 0.699239]\n",
      "epoch:9 step:9173 [D loss: 0.723200, acc.: 39.06%] [G loss: 0.711500]\n",
      "epoch:9 step:9174 [D loss: 0.712047, acc.: 39.84%] [G loss: 0.704009]\n",
      "epoch:9 step:9175 [D loss: 0.680560, acc.: 54.69%] [G loss: 0.724277]\n",
      "epoch:9 step:9176 [D loss: 0.685671, acc.: 53.12%] [G loss: 0.627986]\n",
      "epoch:9 step:9177 [D loss: 0.710252, acc.: 45.31%] [G loss: 0.737767]\n",
      "epoch:9 step:9178 [D loss: 0.843157, acc.: 34.38%] [G loss: 0.759746]\n",
      "epoch:9 step:9179 [D loss: 0.683617, acc.: 50.00%] [G loss: 0.786333]\n",
      "epoch:9 step:9180 [D loss: 0.697104, acc.: 53.12%] [G loss: 0.784124]\n",
      "epoch:9 step:9181 [D loss: 0.710052, acc.: 46.88%] [G loss: 0.783825]\n",
      "epoch:9 step:9182 [D loss: 0.711980, acc.: 50.00%] [G loss: 0.765677]\n",
      "epoch:9 step:9183 [D loss: 0.695347, acc.: 53.12%] [G loss: 0.755610]\n",
      "epoch:9 step:9184 [D loss: 0.698975, acc.: 51.56%] [G loss: 0.734287]\n",
      "epoch:9 step:9185 [D loss: 0.695476, acc.: 48.44%] [G loss: 0.730958]\n",
      "epoch:9 step:9186 [D loss: 0.690662, acc.: 47.66%] [G loss: 0.734075]\n",
      "epoch:9 step:9187 [D loss: 0.696561, acc.: 46.09%] [G loss: 0.720332]\n",
      "epoch:9 step:9188 [D loss: 0.670986, acc.: 63.28%] [G loss: 0.741112]\n",
      "epoch:9 step:9189 [D loss: 0.673383, acc.: 59.38%] [G loss: 0.732891]\n",
      "epoch:9 step:9190 [D loss: 0.671813, acc.: 62.50%] [G loss: 0.766043]\n",
      "epoch:9 step:9191 [D loss: 0.699515, acc.: 46.88%] [G loss: 0.714499]\n",
      "epoch:9 step:9192 [D loss: 0.728163, acc.: 35.94%] [G loss: 0.736248]\n",
      "epoch:9 step:9193 [D loss: 0.695583, acc.: 52.34%] [G loss: 0.723921]\n",
      "epoch:9 step:9194 [D loss: 0.680113, acc.: 57.03%] [G loss: 0.723191]\n",
      "epoch:9 step:9195 [D loss: 0.682346, acc.: 61.72%] [G loss: 0.722118]\n",
      "epoch:9 step:9196 [D loss: 0.670234, acc.: 60.94%] [G loss: 0.704515]\n",
      "epoch:9 step:9197 [D loss: 0.659881, acc.: 69.53%] [G loss: 0.721562]\n",
      "epoch:9 step:9198 [D loss: 0.730132, acc.: 35.94%] [G loss: 0.739616]\n",
      "epoch:9 step:9199 [D loss: 0.695565, acc.: 50.78%] [G loss: 0.739964]\n",
      "epoch:9 step:9200 [D loss: 0.696184, acc.: 52.34%] [G loss: 0.724448]\n",
      "epoch:9 step:9201 [D loss: 0.708260, acc.: 46.09%] [G loss: 0.762354]\n",
      "epoch:9 step:9202 [D loss: 0.690901, acc.: 58.59%] [G loss: 0.729379]\n",
      "epoch:9 step:9203 [D loss: 0.677717, acc.: 60.94%] [G loss: 0.742092]\n",
      "epoch:9 step:9204 [D loss: 0.699183, acc.: 50.78%] [G loss: 0.759055]\n",
      "epoch:9 step:9205 [D loss: 0.697104, acc.: 51.56%] [G loss: 0.712474]\n",
      "epoch:9 step:9206 [D loss: 0.700749, acc.: 51.56%] [G loss: 0.717388]\n",
      "epoch:9 step:9207 [D loss: 0.690797, acc.: 55.47%] [G loss: 0.762903]\n",
      "epoch:9 step:9208 [D loss: 0.665889, acc.: 53.91%] [G loss: 0.751002]\n",
      "epoch:9 step:9209 [D loss: 0.686090, acc.: 55.47%] [G loss: 0.736062]\n",
      "epoch:9 step:9210 [D loss: 0.692331, acc.: 48.44%] [G loss: 0.733874]\n",
      "epoch:9 step:9211 [D loss: 0.702390, acc.: 48.44%] [G loss: 0.721359]\n",
      "epoch:9 step:9212 [D loss: 0.683996, acc.: 52.34%] [G loss: 0.726269]\n",
      "epoch:9 step:9213 [D loss: 0.698428, acc.: 47.66%] [G loss: 0.725463]\n",
      "epoch:9 step:9214 [D loss: 0.714782, acc.: 42.97%] [G loss: 0.710593]\n",
      "epoch:9 step:9215 [D loss: 0.691251, acc.: 53.12%] [G loss: 0.739222]\n",
      "epoch:9 step:9216 [D loss: 0.705603, acc.: 49.22%] [G loss: 0.741415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9217 [D loss: 0.693426, acc.: 49.22%] [G loss: 0.719012]\n",
      "epoch:9 step:9218 [D loss: 0.714332, acc.: 42.19%] [G loss: 0.741107]\n",
      "epoch:9 step:9219 [D loss: 0.693703, acc.: 53.12%] [G loss: 0.752157]\n",
      "epoch:9 step:9220 [D loss: 0.687623, acc.: 58.59%] [G loss: 0.741013]\n",
      "epoch:9 step:9221 [D loss: 0.699465, acc.: 53.91%] [G loss: 0.764197]\n",
      "epoch:9 step:9222 [D loss: 0.687075, acc.: 53.91%] [G loss: 0.735038]\n",
      "epoch:9 step:9223 [D loss: 0.682528, acc.: 52.34%] [G loss: 0.761697]\n",
      "epoch:9 step:9224 [D loss: 0.693094, acc.: 47.66%] [G loss: 0.737176]\n",
      "epoch:9 step:9225 [D loss: 0.693224, acc.: 53.12%] [G loss: 0.734928]\n",
      "epoch:9 step:9226 [D loss: 0.683117, acc.: 60.94%] [G loss: 0.746782]\n",
      "epoch:9 step:9227 [D loss: 0.684290, acc.: 57.81%] [G loss: 0.740042]\n",
      "epoch:9 step:9228 [D loss: 0.701377, acc.: 49.22%] [G loss: 0.749059]\n",
      "epoch:9 step:9229 [D loss: 0.675562, acc.: 53.91%] [G loss: 0.718787]\n",
      "epoch:9 step:9230 [D loss: 0.691670, acc.: 57.03%] [G loss: 0.730626]\n",
      "epoch:9 step:9231 [D loss: 0.691090, acc.: 57.03%] [G loss: 0.725156]\n",
      "epoch:9 step:9232 [D loss: 0.690318, acc.: 51.56%] [G loss: 0.747876]\n",
      "epoch:9 step:9233 [D loss: 0.683804, acc.: 53.91%] [G loss: 0.732141]\n",
      "epoch:9 step:9234 [D loss: 0.675633, acc.: 63.28%] [G loss: 0.723007]\n",
      "epoch:9 step:9235 [D loss: 0.551805, acc.: 65.62%] [G loss: 0.814081]\n",
      "epoch:9 step:9236 [D loss: 0.674342, acc.: 59.38%] [G loss: 0.753171]\n",
      "epoch:9 step:9237 [D loss: 0.724072, acc.: 45.31%] [G loss: 0.729294]\n",
      "epoch:9 step:9238 [D loss: 0.711799, acc.: 46.09%] [G loss: 0.772635]\n",
      "epoch:9 step:9239 [D loss: 0.694493, acc.: 49.22%] [G loss: 0.729748]\n",
      "epoch:9 step:9240 [D loss: 0.682168, acc.: 53.91%] [G loss: 0.741280]\n",
      "epoch:9 step:9241 [D loss: 0.681799, acc.: 62.50%] [G loss: 0.749291]\n",
      "epoch:9 step:9242 [D loss: 0.679223, acc.: 57.03%] [G loss: 0.691643]\n",
      "epoch:9 step:9243 [D loss: 0.677686, acc.: 60.94%] [G loss: 0.740971]\n",
      "epoch:9 step:9244 [D loss: 0.719689, acc.: 47.66%] [G loss: 0.777494]\n",
      "epoch:9 step:9245 [D loss: 0.695679, acc.: 50.00%] [G loss: 0.694080]\n",
      "epoch:9 step:9246 [D loss: 0.683364, acc.: 60.16%] [G loss: 0.756632]\n",
      "epoch:9 step:9247 [D loss: 0.682480, acc.: 54.69%] [G loss: 0.714147]\n",
      "epoch:9 step:9248 [D loss: 0.657589, acc.: 58.59%] [G loss: 0.697937]\n",
      "epoch:9 step:9249 [D loss: 0.662804, acc.: 60.16%] [G loss: 0.724195]\n",
      "epoch:9 step:9250 [D loss: 0.734157, acc.: 42.19%] [G loss: 0.685203]\n",
      "epoch:9 step:9251 [D loss: 0.725335, acc.: 49.22%] [G loss: 0.742029]\n",
      "epoch:9 step:9252 [D loss: 0.675362, acc.: 56.25%] [G loss: 0.716857]\n",
      "epoch:9 step:9253 [D loss: 0.705180, acc.: 44.53%] [G loss: 0.729417]\n",
      "epoch:9 step:9254 [D loss: 0.697689, acc.: 45.31%] [G loss: 0.748470]\n",
      "epoch:9 step:9255 [D loss: 0.684967, acc.: 55.47%] [G loss: 0.602867]\n",
      "epoch:9 step:9256 [D loss: 0.671876, acc.: 57.81%] [G loss: 0.758009]\n",
      "epoch:9 step:9257 [D loss: 0.707828, acc.: 47.66%] [G loss: 0.729051]\n",
      "epoch:9 step:9258 [D loss: 0.720921, acc.: 44.53%] [G loss: 0.745188]\n",
      "epoch:9 step:9259 [D loss: 0.696191, acc.: 50.78%] [G loss: 0.726043]\n",
      "epoch:9 step:9260 [D loss: 0.715718, acc.: 49.22%] [G loss: 0.729323]\n",
      "epoch:9 step:9261 [D loss: 0.697632, acc.: 53.91%] [G loss: 0.731272]\n",
      "epoch:9 step:9262 [D loss: 0.678377, acc.: 58.59%] [G loss: 0.724956]\n",
      "epoch:9 step:9263 [D loss: 0.690642, acc.: 53.91%] [G loss: 0.763929]\n",
      "epoch:9 step:9264 [D loss: 0.695558, acc.: 57.03%] [G loss: 0.735099]\n",
      "epoch:9 step:9265 [D loss: 0.703840, acc.: 46.88%] [G loss: 0.746441]\n",
      "epoch:9 step:9266 [D loss: 0.698286, acc.: 50.00%] [G loss: 0.702806]\n",
      "epoch:9 step:9267 [D loss: 0.682324, acc.: 60.94%] [G loss: 0.724002]\n",
      "epoch:9 step:9268 [D loss: 0.690615, acc.: 47.66%] [G loss: 0.703072]\n",
      "epoch:9 step:9269 [D loss: 0.704596, acc.: 47.66%] [G loss: 0.700264]\n",
      "epoch:9 step:9270 [D loss: 0.704823, acc.: 45.31%] [G loss: 0.716315]\n",
      "epoch:9 step:9271 [D loss: 0.713198, acc.: 46.88%] [G loss: 0.733942]\n",
      "epoch:9 step:9272 [D loss: 0.687967, acc.: 56.25%] [G loss: 0.716082]\n",
      "epoch:9 step:9273 [D loss: 0.679126, acc.: 57.81%] [G loss: 0.720344]\n",
      "epoch:9 step:9274 [D loss: 0.692750, acc.: 57.03%] [G loss: 0.760234]\n",
      "epoch:9 step:9275 [D loss: 0.698841, acc.: 50.78%] [G loss: 0.744312]\n",
      "epoch:9 step:9276 [D loss: 0.714829, acc.: 42.19%] [G loss: 0.704733]\n",
      "epoch:9 step:9277 [D loss: 0.697417, acc.: 46.09%] [G loss: 0.705311]\n",
      "epoch:9 step:9278 [D loss: 0.672859, acc.: 57.03%] [G loss: 0.714630]\n",
      "epoch:9 step:9279 [D loss: 0.691754, acc.: 50.78%] [G loss: 0.723339]\n",
      "epoch:9 step:9280 [D loss: 0.694567, acc.: 50.78%] [G loss: 0.726355]\n",
      "epoch:9 step:9281 [D loss: 0.707191, acc.: 46.88%] [G loss: 0.737835]\n",
      "epoch:9 step:9282 [D loss: 0.687067, acc.: 57.03%] [G loss: 0.700417]\n",
      "epoch:9 step:9283 [D loss: 0.704058, acc.: 51.56%] [G loss: 0.696018]\n",
      "epoch:9 step:9284 [D loss: 0.689255, acc.: 54.69%] [G loss: 0.724688]\n",
      "epoch:9 step:9285 [D loss: 0.686357, acc.: 60.16%] [G loss: 0.710311]\n",
      "epoch:9 step:9286 [D loss: 0.685016, acc.: 53.12%] [G loss: 0.726161]\n",
      "epoch:9 step:9287 [D loss: 0.680551, acc.: 56.25%] [G loss: 0.722024]\n",
      "epoch:9 step:9288 [D loss: 0.697371, acc.: 54.69%] [G loss: 0.737553]\n",
      "epoch:9 step:9289 [D loss: 0.704299, acc.: 46.09%] [G loss: 0.730416]\n",
      "epoch:9 step:9290 [D loss: 0.677908, acc.: 57.03%] [G loss: 0.733531]\n",
      "epoch:9 step:9291 [D loss: 0.718162, acc.: 37.50%] [G loss: 0.734329]\n",
      "epoch:9 step:9292 [D loss: 0.685868, acc.: 63.28%] [G loss: 0.717185]\n",
      "epoch:9 step:9293 [D loss: 0.691589, acc.: 46.88%] [G loss: 0.723609]\n",
      "epoch:9 step:9294 [D loss: 0.692648, acc.: 52.34%] [G loss: 0.728931]\n",
      "epoch:9 step:9295 [D loss: 0.701865, acc.: 46.88%] [G loss: 0.729608]\n",
      "epoch:9 step:9296 [D loss: 0.692136, acc.: 52.34%] [G loss: 0.715933]\n",
      "epoch:9 step:9297 [D loss: 0.698480, acc.: 50.00%] [G loss: 0.738392]\n",
      "epoch:9 step:9298 [D loss: 0.692003, acc.: 48.44%] [G loss: 0.719430]\n",
      "epoch:9 step:9299 [D loss: 0.683956, acc.: 55.47%] [G loss: 0.709571]\n",
      "epoch:9 step:9300 [D loss: 0.686531, acc.: 56.25%] [G loss: 0.734126]\n",
      "epoch:9 step:9301 [D loss: 0.697113, acc.: 50.00%] [G loss: 0.704436]\n",
      "epoch:9 step:9302 [D loss: 0.690437, acc.: 57.03%] [G loss: 0.707793]\n",
      "epoch:9 step:9303 [D loss: 0.697751, acc.: 49.22%] [G loss: 0.736001]\n",
      "epoch:9 step:9304 [D loss: 0.683782, acc.: 53.12%] [G loss: 0.719754]\n",
      "epoch:9 step:9305 [D loss: 0.689746, acc.: 50.78%] [G loss: 0.718988]\n",
      "epoch:9 step:9306 [D loss: 0.686948, acc.: 52.34%] [G loss: 0.727361]\n",
      "epoch:9 step:9307 [D loss: 0.708767, acc.: 50.00%] [G loss: 0.711522]\n",
      "epoch:9 step:9308 [D loss: 0.692540, acc.: 54.69%] [G loss: 0.704920]\n",
      "epoch:9 step:9309 [D loss: 0.694632, acc.: 57.81%] [G loss: 0.708440]\n",
      "epoch:9 step:9310 [D loss: 0.678290, acc.: 58.59%] [G loss: 0.707454]\n",
      "epoch:9 step:9311 [D loss: 0.665998, acc.: 62.50%] [G loss: 0.707366]\n",
      "epoch:9 step:9312 [D loss: 0.703552, acc.: 51.56%] [G loss: 0.730674]\n",
      "epoch:9 step:9313 [D loss: 0.718274, acc.: 43.75%] [G loss: 0.675456]\n",
      "epoch:9 step:9314 [D loss: 0.685794, acc.: 56.25%] [G loss: 0.702004]\n",
      "epoch:9 step:9315 [D loss: 0.700593, acc.: 49.22%] [G loss: 0.689201]\n",
      "epoch:9 step:9316 [D loss: 0.690945, acc.: 51.56%] [G loss: 0.697227]\n",
      "epoch:9 step:9317 [D loss: 0.698988, acc.: 49.22%] [G loss: 0.708971]\n",
      "epoch:9 step:9318 [D loss: 0.710314, acc.: 40.62%] [G loss: 0.717292]\n",
      "epoch:9 step:9319 [D loss: 0.693972, acc.: 58.59%] [G loss: 0.744141]\n",
      "epoch:9 step:9320 [D loss: 0.694769, acc.: 51.56%] [G loss: 0.721416]\n",
      "epoch:9 step:9321 [D loss: 0.692566, acc.: 50.78%] [G loss: 0.702658]\n",
      "epoch:9 step:9322 [D loss: 0.679274, acc.: 58.59%] [G loss: 0.733851]\n",
      "epoch:9 step:9323 [D loss: 0.685462, acc.: 55.47%] [G loss: 0.749130]\n",
      "epoch:9 step:9324 [D loss: 0.684413, acc.: 58.59%] [G loss: 0.721089]\n",
      "epoch:9 step:9325 [D loss: 0.694976, acc.: 50.78%] [G loss: 0.750523]\n",
      "epoch:9 step:9326 [D loss: 0.671278, acc.: 57.81%] [G loss: 0.736257]\n",
      "epoch:9 step:9327 [D loss: 0.706778, acc.: 49.22%] [G loss: 0.729346]\n",
      "epoch:9 step:9328 [D loss: 0.709663, acc.: 45.31%] [G loss: 0.713304]\n",
      "epoch:9 step:9329 [D loss: 0.690892, acc.: 57.81%] [G loss: 0.720474]\n",
      "epoch:9 step:9330 [D loss: 0.687839, acc.: 54.69%] [G loss: 0.706467]\n",
      "epoch:9 step:9331 [D loss: 0.694227, acc.: 55.47%] [G loss: 0.715999]\n",
      "epoch:9 step:9332 [D loss: 0.641537, acc.: 64.84%] [G loss: 0.720065]\n",
      "epoch:9 step:9333 [D loss: 0.650155, acc.: 65.62%] [G loss: 0.738522]\n",
      "epoch:9 step:9334 [D loss: 0.677065, acc.: 57.81%] [G loss: 0.592474]\n",
      "epoch:9 step:9335 [D loss: 0.685099, acc.: 53.12%] [G loss: 0.755568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9336 [D loss: 0.702727, acc.: 46.88%] [G loss: 0.728740]\n",
      "epoch:9 step:9337 [D loss: 0.716252, acc.: 39.06%] [G loss: 0.727129]\n",
      "epoch:9 step:9338 [D loss: 0.699838, acc.: 46.88%] [G loss: 0.742386]\n",
      "epoch:9 step:9339 [D loss: 0.713847, acc.: 50.00%] [G loss: 0.761981]\n",
      "epoch:9 step:9340 [D loss: 0.678984, acc.: 54.69%] [G loss: 0.763735]\n",
      "epoch:9 step:9341 [D loss: 0.675963, acc.: 60.16%] [G loss: 0.855992]\n",
      "epoch:9 step:9342 [D loss: 0.709041, acc.: 39.84%] [G loss: 0.711486]\n",
      "epoch:9 step:9343 [D loss: 0.706748, acc.: 47.66%] [G loss: 0.740090]\n",
      "epoch:9 step:9344 [D loss: 0.706971, acc.: 42.97%] [G loss: 0.736683]\n",
      "epoch:9 step:9345 [D loss: 0.499663, acc.: 71.88%] [G loss: 0.778749]\n",
      "epoch:9 step:9346 [D loss: 0.693167, acc.: 54.69%] [G loss: 0.733285]\n",
      "epoch:9 step:9347 [D loss: 0.697944, acc.: 57.03%] [G loss: 0.737008]\n",
      "epoch:9 step:9348 [D loss: 0.707797, acc.: 45.31%] [G loss: 0.725573]\n",
      "epoch:9 step:9349 [D loss: 0.702046, acc.: 47.66%] [G loss: 0.709035]\n",
      "epoch:9 step:9350 [D loss: 0.680929, acc.: 60.94%] [G loss: 0.749093]\n",
      "epoch:9 step:9351 [D loss: 0.702385, acc.: 48.44%] [G loss: 0.729268]\n",
      "epoch:9 step:9352 [D loss: 0.670037, acc.: 59.38%] [G loss: 0.739086]\n",
      "epoch:9 step:9353 [D loss: 0.737490, acc.: 42.19%] [G loss: 0.709024]\n",
      "epoch:9 step:9354 [D loss: 0.680553, acc.: 57.03%] [G loss: 0.723937]\n",
      "epoch:9 step:9355 [D loss: 0.671361, acc.: 60.16%] [G loss: 0.711425]\n",
      "epoch:9 step:9356 [D loss: 0.662812, acc.: 64.84%] [G loss: 0.728853]\n",
      "epoch:9 step:9357 [D loss: 0.640715, acc.: 64.84%] [G loss: 0.711771]\n",
      "epoch:9 step:9358 [D loss: 0.628831, acc.: 61.72%] [G loss: 0.769098]\n",
      "epoch:9 step:9359 [D loss: 0.543351, acc.: 64.06%] [G loss: 0.684583]\n",
      "epoch:9 step:9360 [D loss: 0.416372, acc.: 66.41%] [G loss: 0.810251]\n",
      "epoch:9 step:9361 [D loss: 0.721846, acc.: 40.62%] [G loss: 0.775772]\n",
      "epoch:9 step:9362 [D loss: 0.996072, acc.: 25.78%] [G loss: 0.855004]\n",
      "epoch:9 step:9363 [D loss: 0.658006, acc.: 59.38%] [G loss: 0.853301]\n",
      "epoch:9 step:9364 [D loss: 0.700563, acc.: 46.09%] [G loss: 0.846736]\n",
      "epoch:9 step:9365 [D loss: 0.734571, acc.: 46.09%] [G loss: 0.781346]\n",
      "epoch:9 step:9366 [D loss: 0.738459, acc.: 45.31%] [G loss: 0.753086]\n",
      "epoch:9 step:9367 [D loss: 0.724534, acc.: 46.09%] [G loss: 0.771274]\n",
      "epoch:9 step:9368 [D loss: 0.691280, acc.: 50.78%] [G loss: 0.733008]\n",
      "epoch:9 step:9369 [D loss: 0.681281, acc.: 64.06%] [G loss: 0.766547]\n",
      "epoch:9 step:9370 [D loss: 0.695433, acc.: 47.66%] [G loss: 0.753718]\n",
      "epoch:10 step:9371 [D loss: 0.715691, acc.: 49.22%] [G loss: 0.749599]\n",
      "epoch:10 step:9372 [D loss: 0.735386, acc.: 37.50%] [G loss: 0.737049]\n",
      "epoch:10 step:9373 [D loss: 0.712989, acc.: 41.41%] [G loss: 0.735027]\n",
      "epoch:10 step:9374 [D loss: 0.692627, acc.: 46.09%] [G loss: 0.728693]\n",
      "epoch:10 step:9375 [D loss: 0.697031, acc.: 49.22%] [G loss: 0.729373]\n",
      "epoch:10 step:9376 [D loss: 0.705346, acc.: 39.84%] [G loss: 0.698473]\n",
      "epoch:10 step:9377 [D loss: 0.703142, acc.: 48.44%] [G loss: 0.731123]\n",
      "epoch:10 step:9378 [D loss: 0.703230, acc.: 46.88%] [G loss: 0.716874]\n",
      "epoch:10 step:9379 [D loss: 0.691469, acc.: 58.59%] [G loss: 0.717862]\n",
      "epoch:10 step:9380 [D loss: 0.697498, acc.: 49.22%] [G loss: 0.716860]\n",
      "epoch:10 step:9381 [D loss: 0.700304, acc.: 43.75%] [G loss: 0.712650]\n",
      "epoch:10 step:9382 [D loss: 0.693324, acc.: 50.78%] [G loss: 0.718926]\n",
      "epoch:10 step:9383 [D loss: 0.674491, acc.: 61.72%] [G loss: 0.732539]\n",
      "epoch:10 step:9384 [D loss: 0.677511, acc.: 60.94%] [G loss: 0.735415]\n",
      "epoch:10 step:9385 [D loss: 0.655829, acc.: 71.88%] [G loss: 0.745225]\n",
      "epoch:10 step:9386 [D loss: 0.687627, acc.: 57.03%] [G loss: 0.705672]\n",
      "epoch:10 step:9387 [D loss: 0.682466, acc.: 62.50%] [G loss: 0.712907]\n",
      "epoch:10 step:9388 [D loss: 0.706770, acc.: 53.12%] [G loss: 0.606992]\n",
      "epoch:10 step:9389 [D loss: 0.692763, acc.: 51.56%] [G loss: 0.690213]\n",
      "epoch:10 step:9390 [D loss: 0.743462, acc.: 33.59%] [G loss: 0.689085]\n",
      "epoch:10 step:9391 [D loss: 0.678138, acc.: 59.38%] [G loss: 0.717260]\n",
      "epoch:10 step:9392 [D loss: 0.689465, acc.: 55.47%] [G loss: 0.726280]\n",
      "epoch:10 step:9393 [D loss: 0.686343, acc.: 53.91%] [G loss: 0.744724]\n",
      "epoch:10 step:9394 [D loss: 0.681781, acc.: 50.78%] [G loss: 0.741027]\n",
      "epoch:10 step:9395 [D loss: 0.685165, acc.: 49.22%] [G loss: 0.735692]\n",
      "epoch:10 step:9396 [D loss: 0.678180, acc.: 57.03%] [G loss: 0.729616]\n",
      "epoch:10 step:9397 [D loss: 0.693362, acc.: 52.34%] [G loss: 0.765229]\n",
      "epoch:10 step:9398 [D loss: 0.682393, acc.: 57.03%] [G loss: 0.771608]\n",
      "epoch:10 step:9399 [D loss: 0.676911, acc.: 63.28%] [G loss: 0.754189]\n",
      "epoch:10 step:9400 [D loss: 0.672995, acc.: 61.72%] [G loss: 0.809829]\n",
      "epoch:10 step:9401 [D loss: 0.670920, acc.: 61.72%] [G loss: 0.818660]\n",
      "epoch:10 step:9402 [D loss: 0.666586, acc.: 67.97%] [G loss: 0.834033]\n",
      "epoch:10 step:9403 [D loss: 0.649289, acc.: 70.31%] [G loss: 0.816557]\n",
      "epoch:10 step:9404 [D loss: 0.667889, acc.: 65.62%] [G loss: 0.839801]\n",
      "epoch:10 step:9405 [D loss: 0.653874, acc.: 68.75%] [G loss: 0.820149]\n",
      "epoch:10 step:9406 [D loss: 0.649767, acc.: 67.97%] [G loss: 0.887236]\n",
      "epoch:10 step:9407 [D loss: 0.688195, acc.: 54.69%] [G loss: 0.871208]\n",
      "epoch:10 step:9408 [D loss: 0.749711, acc.: 39.84%] [G loss: 0.805896]\n",
      "epoch:10 step:9409 [D loss: 0.736484, acc.: 39.06%] [G loss: 0.724557]\n",
      "epoch:10 step:9410 [D loss: 0.716349, acc.: 47.66%] [G loss: 0.731458]\n",
      "epoch:10 step:9411 [D loss: 0.712843, acc.: 45.31%] [G loss: 0.727893]\n",
      "epoch:10 step:9412 [D loss: 0.702405, acc.: 47.66%] [G loss: 0.728863]\n",
      "epoch:10 step:9413 [D loss: 0.694411, acc.: 50.78%] [G loss: 0.717533]\n",
      "epoch:10 step:9414 [D loss: 0.688542, acc.: 51.56%] [G loss: 0.712864]\n",
      "epoch:10 step:9415 [D loss: 0.704763, acc.: 42.19%] [G loss: 0.702745]\n",
      "epoch:10 step:9416 [D loss: 0.688012, acc.: 51.56%] [G loss: 0.737462]\n",
      "epoch:10 step:9417 [D loss: 0.697470, acc.: 47.66%] [G loss: 0.751665]\n",
      "epoch:10 step:9418 [D loss: 0.672063, acc.: 60.94%] [G loss: 0.755410]\n",
      "epoch:10 step:9419 [D loss: 0.675594, acc.: 62.50%] [G loss: 0.779249]\n",
      "epoch:10 step:9420 [D loss: 0.658837, acc.: 63.28%] [G loss: 0.766320]\n",
      "epoch:10 step:9421 [D loss: 0.681215, acc.: 53.12%] [G loss: 0.751790]\n",
      "epoch:10 step:9422 [D loss: 0.658681, acc.: 65.62%] [G loss: 0.754216]\n",
      "epoch:10 step:9423 [D loss: 0.652307, acc.: 71.88%] [G loss: 0.749828]\n",
      "epoch:10 step:9424 [D loss: 0.672594, acc.: 64.84%] [G loss: 0.742491]\n",
      "epoch:10 step:9425 [D loss: 0.694209, acc.: 53.12%] [G loss: 0.728608]\n",
      "epoch:10 step:9426 [D loss: 0.683894, acc.: 58.59%] [G loss: 0.687655]\n",
      "epoch:10 step:9427 [D loss: 0.737597, acc.: 38.28%] [G loss: 0.718283]\n",
      "epoch:10 step:9428 [D loss: 0.708065, acc.: 45.31%] [G loss: 0.689068]\n",
      "epoch:10 step:9429 [D loss: 0.718416, acc.: 42.97%] [G loss: 0.695811]\n",
      "epoch:10 step:9430 [D loss: 0.703516, acc.: 46.09%] [G loss: 0.698230]\n",
      "epoch:10 step:9431 [D loss: 0.712287, acc.: 43.75%] [G loss: 0.703104]\n",
      "epoch:10 step:9432 [D loss: 0.711729, acc.: 43.75%] [G loss: 0.730059]\n",
      "epoch:10 step:9433 [D loss: 0.689116, acc.: 54.69%] [G loss: 0.733204]\n",
      "epoch:10 step:9434 [D loss: 0.683578, acc.: 57.81%] [G loss: 0.752102]\n",
      "epoch:10 step:9435 [D loss: 0.686764, acc.: 53.91%] [G loss: 0.750221]\n",
      "epoch:10 step:9436 [D loss: 0.689285, acc.: 53.91%] [G loss: 0.746280]\n",
      "epoch:10 step:9437 [D loss: 0.678972, acc.: 59.38%] [G loss: 0.768021]\n",
      "epoch:10 step:9438 [D loss: 0.691217, acc.: 58.59%] [G loss: 0.733782]\n",
      "epoch:10 step:9439 [D loss: 0.677071, acc.: 60.16%] [G loss: 0.747695]\n",
      "epoch:10 step:9440 [D loss: 0.690546, acc.: 54.69%] [G loss: 0.756989]\n",
      "epoch:10 step:9441 [D loss: 0.697894, acc.: 50.00%] [G loss: 0.743160]\n",
      "epoch:10 step:9442 [D loss: 0.695231, acc.: 46.88%] [G loss: 0.751137]\n",
      "epoch:10 step:9443 [D loss: 0.684388, acc.: 53.91%] [G loss: 0.713941]\n",
      "epoch:10 step:9444 [D loss: 0.694154, acc.: 55.47%] [G loss: 0.702741]\n",
      "epoch:10 step:9445 [D loss: 0.697064, acc.: 49.22%] [G loss: 0.741706]\n",
      "epoch:10 step:9446 [D loss: 0.680397, acc.: 57.81%] [G loss: 0.726265]\n",
      "epoch:10 step:9447 [D loss: 0.669818, acc.: 60.16%] [G loss: 0.759685]\n",
      "epoch:10 step:9448 [D loss: 0.684430, acc.: 50.00%] [G loss: 0.707831]\n",
      "epoch:10 step:9449 [D loss: 0.706643, acc.: 46.09%] [G loss: 0.737929]\n",
      "epoch:10 step:9450 [D loss: 0.699896, acc.: 47.66%] [G loss: 0.741444]\n",
      "epoch:10 step:9451 [D loss: 0.709847, acc.: 42.19%] [G loss: 0.736851]\n",
      "epoch:10 step:9452 [D loss: 0.714790, acc.: 42.19%] [G loss: 0.736684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9453 [D loss: 0.704586, acc.: 45.31%] [G loss: 0.731268]\n",
      "epoch:10 step:9454 [D loss: 0.695590, acc.: 51.56%] [G loss: 0.723249]\n",
      "epoch:10 step:9455 [D loss: 0.675969, acc.: 53.12%] [G loss: 0.714841]\n",
      "epoch:10 step:9456 [D loss: 0.697363, acc.: 51.56%] [G loss: 0.728047]\n",
      "epoch:10 step:9457 [D loss: 0.699111, acc.: 49.22%] [G loss: 0.724498]\n",
      "epoch:10 step:9458 [D loss: 0.688339, acc.: 54.69%] [G loss: 0.715663]\n",
      "epoch:10 step:9459 [D loss: 0.689587, acc.: 50.78%] [G loss: 0.722256]\n",
      "epoch:10 step:9460 [D loss: 0.688691, acc.: 53.91%] [G loss: 0.732449]\n",
      "epoch:10 step:9461 [D loss: 0.683926, acc.: 56.25%] [G loss: 0.705367]\n",
      "epoch:10 step:9462 [D loss: 0.684081, acc.: 50.00%] [G loss: 0.730589]\n",
      "epoch:10 step:9463 [D loss: 0.673240, acc.: 56.25%] [G loss: 0.702990]\n",
      "epoch:10 step:9464 [D loss: 0.685048, acc.: 58.59%] [G loss: 0.742867]\n",
      "epoch:10 step:9465 [D loss: 0.700772, acc.: 45.31%] [G loss: 0.751210]\n",
      "epoch:10 step:9466 [D loss: 0.708160, acc.: 39.84%] [G loss: 0.717848]\n",
      "epoch:10 step:9467 [D loss: 0.679429, acc.: 58.59%] [G loss: 0.719743]\n",
      "epoch:10 step:9468 [D loss: 0.678482, acc.: 58.59%] [G loss: 0.737458]\n",
      "epoch:10 step:9469 [D loss: 0.666403, acc.: 62.50%] [G loss: 0.734317]\n",
      "epoch:10 step:9470 [D loss: 0.686725, acc.: 57.03%] [G loss: 0.723167]\n",
      "epoch:10 step:9471 [D loss: 0.688003, acc.: 57.81%] [G loss: 0.746156]\n",
      "epoch:10 step:9472 [D loss: 0.668483, acc.: 57.81%] [G loss: 0.729163]\n",
      "epoch:10 step:9473 [D loss: 0.697573, acc.: 53.12%] [G loss: 0.736438]\n",
      "epoch:10 step:9474 [D loss: 0.692587, acc.: 53.91%] [G loss: 0.723896]\n",
      "epoch:10 step:9475 [D loss: 0.688069, acc.: 56.25%] [G loss: 0.725791]\n",
      "epoch:10 step:9476 [D loss: 0.682403, acc.: 54.69%] [G loss: 0.745471]\n",
      "epoch:10 step:9477 [D loss: 0.671273, acc.: 64.06%] [G loss: 0.691357]\n",
      "epoch:10 step:9478 [D loss: 0.698720, acc.: 50.78%] [G loss: 0.759396]\n",
      "epoch:10 step:9479 [D loss: 0.673210, acc.: 57.03%] [G loss: 0.687909]\n",
      "epoch:10 step:9480 [D loss: 0.682892, acc.: 53.12%] [G loss: 0.731392]\n",
      "epoch:10 step:9481 [D loss: 0.704577, acc.: 41.41%] [G loss: 0.716847]\n",
      "epoch:10 step:9482 [D loss: 0.684916, acc.: 57.03%] [G loss: 0.749574]\n",
      "epoch:10 step:9483 [D loss: 0.697782, acc.: 49.22%] [G loss: 0.717574]\n",
      "epoch:10 step:9484 [D loss: 0.688337, acc.: 57.03%] [G loss: 0.717729]\n",
      "epoch:10 step:9485 [D loss: 0.678941, acc.: 56.25%] [G loss: 0.723140]\n",
      "epoch:10 step:9486 [D loss: 0.690369, acc.: 54.69%] [G loss: 0.734065]\n",
      "epoch:10 step:9487 [D loss: 0.692559, acc.: 52.34%] [G loss: 0.712154]\n",
      "epoch:10 step:9488 [D loss: 0.694472, acc.: 53.12%] [G loss: 0.732011]\n",
      "epoch:10 step:9489 [D loss: 0.688196, acc.: 54.69%] [G loss: 0.720294]\n",
      "epoch:10 step:9490 [D loss: 0.723241, acc.: 41.41%] [G loss: 0.726603]\n",
      "epoch:10 step:9491 [D loss: 0.702427, acc.: 53.12%] [G loss: 0.735434]\n",
      "epoch:10 step:9492 [D loss: 0.699559, acc.: 53.12%] [G loss: 0.779071]\n",
      "epoch:10 step:9493 [D loss: 0.697045, acc.: 46.88%] [G loss: 0.786524]\n",
      "epoch:10 step:9494 [D loss: 0.682313, acc.: 57.03%] [G loss: 0.792010]\n",
      "epoch:10 step:9495 [D loss: 0.676905, acc.: 56.25%] [G loss: 0.789755]\n",
      "epoch:10 step:9496 [D loss: 0.663523, acc.: 57.03%] [G loss: 0.822974]\n",
      "epoch:10 step:9497 [D loss: 0.673180, acc.: 57.81%] [G loss: 0.794915]\n",
      "epoch:10 step:9498 [D loss: 0.686510, acc.: 53.91%] [G loss: 0.822149]\n",
      "epoch:10 step:9499 [D loss: 0.702672, acc.: 49.22%] [G loss: 0.745573]\n",
      "epoch:10 step:9500 [D loss: 0.674921, acc.: 56.25%] [G loss: 0.767013]\n",
      "epoch:10 step:9501 [D loss: 0.695558, acc.: 50.78%] [G loss: 0.741675]\n",
      "epoch:10 step:9502 [D loss: 0.661891, acc.: 62.50%] [G loss: 0.736894]\n",
      "epoch:10 step:9503 [D loss: 0.693761, acc.: 50.78%] [G loss: 0.726889]\n",
      "epoch:10 step:9504 [D loss: 0.698048, acc.: 48.44%] [G loss: 0.731640]\n",
      "epoch:10 step:9505 [D loss: 0.688662, acc.: 52.34%] [G loss: 0.720557]\n",
      "epoch:10 step:9506 [D loss: 0.695200, acc.: 53.91%] [G loss: 0.715787]\n",
      "epoch:10 step:9507 [D loss: 0.694871, acc.: 56.25%] [G loss: 0.744759]\n",
      "epoch:10 step:9508 [D loss: 0.683232, acc.: 54.69%] [G loss: 0.756553]\n",
      "epoch:10 step:9509 [D loss: 0.639581, acc.: 64.06%] [G loss: 0.763709]\n",
      "epoch:10 step:9510 [D loss: 0.687218, acc.: 48.44%] [G loss: 0.553793]\n",
      "epoch:10 step:9511 [D loss: 0.723632, acc.: 39.84%] [G loss: 0.734081]\n",
      "epoch:10 step:9512 [D loss: 0.690247, acc.: 49.22%] [G loss: 0.741995]\n",
      "epoch:10 step:9513 [D loss: 0.698748, acc.: 53.91%] [G loss: 0.727808]\n",
      "epoch:10 step:9514 [D loss: 0.705139, acc.: 43.75%] [G loss: 0.709113]\n",
      "epoch:10 step:9515 [D loss: 0.696405, acc.: 57.03%] [G loss: 0.697158]\n",
      "epoch:10 step:9516 [D loss: 0.703738, acc.: 47.66%] [G loss: 0.686732]\n",
      "epoch:10 step:9517 [D loss: 0.713586, acc.: 51.56%] [G loss: 0.695616]\n",
      "epoch:10 step:9518 [D loss: 0.697367, acc.: 52.34%] [G loss: 0.740204]\n",
      "epoch:10 step:9519 [D loss: 0.694009, acc.: 55.47%] [G loss: 0.747474]\n",
      "epoch:10 step:9520 [D loss: 0.678208, acc.: 61.72%] [G loss: 0.739624]\n",
      "epoch:10 step:9521 [D loss: 0.687818, acc.: 60.94%] [G loss: 0.715757]\n",
      "epoch:10 step:9522 [D loss: 0.674803, acc.: 59.38%] [G loss: 0.727708]\n",
      "epoch:10 step:9523 [D loss: 0.681491, acc.: 54.69%] [G loss: 0.777092]\n",
      "epoch:10 step:9524 [D loss: 0.675778, acc.: 57.81%] [G loss: 0.742771]\n",
      "epoch:10 step:9525 [D loss: 0.672593, acc.: 57.03%] [G loss: 0.790812]\n",
      "epoch:10 step:9526 [D loss: 0.710700, acc.: 46.09%] [G loss: 0.716694]\n",
      "epoch:10 step:9527 [D loss: 0.683315, acc.: 53.91%] [G loss: 0.757593]\n",
      "epoch:10 step:9528 [D loss: 0.685301, acc.: 58.59%] [G loss: 0.773978]\n",
      "epoch:10 step:9529 [D loss: 0.703039, acc.: 48.44%] [G loss: 0.736112]\n",
      "epoch:10 step:9530 [D loss: 0.708980, acc.: 44.53%] [G loss: 0.717561]\n",
      "epoch:10 step:9531 [D loss: 0.693549, acc.: 52.34%] [G loss: 0.726995]\n",
      "epoch:10 step:9532 [D loss: 0.695341, acc.: 54.69%] [G loss: 0.733912]\n",
      "epoch:10 step:9533 [D loss: 0.682644, acc.: 52.34%] [G loss: 0.734923]\n",
      "epoch:10 step:9534 [D loss: 0.670197, acc.: 55.47%] [G loss: 0.737971]\n",
      "epoch:10 step:9535 [D loss: 0.684812, acc.: 57.81%] [G loss: 0.700824]\n",
      "epoch:10 step:9536 [D loss: 0.698307, acc.: 53.12%] [G loss: 0.720505]\n",
      "epoch:10 step:9537 [D loss: 0.721876, acc.: 46.88%] [G loss: 0.722205]\n",
      "epoch:10 step:9538 [D loss: 0.686803, acc.: 53.91%] [G loss: 0.737376]\n",
      "epoch:10 step:9539 [D loss: 0.700556, acc.: 47.66%] [G loss: 0.729542]\n",
      "epoch:10 step:9540 [D loss: 0.689945, acc.: 50.78%] [G loss: 0.726721]\n",
      "epoch:10 step:9541 [D loss: 0.689534, acc.: 46.88%] [G loss: 0.728481]\n",
      "epoch:10 step:9542 [D loss: 0.693260, acc.: 50.00%] [G loss: 0.738678]\n",
      "epoch:10 step:9543 [D loss: 0.684000, acc.: 56.25%] [G loss: 0.720982]\n",
      "epoch:10 step:9544 [D loss: 0.694376, acc.: 50.00%] [G loss: 0.708450]\n",
      "epoch:10 step:9545 [D loss: 0.676109, acc.: 55.47%] [G loss: 0.715528]\n",
      "epoch:10 step:9546 [D loss: 0.682176, acc.: 47.66%] [G loss: 0.737582]\n",
      "epoch:10 step:9547 [D loss: 0.675026, acc.: 55.47%] [G loss: 0.730795]\n",
      "epoch:10 step:9548 [D loss: 0.687071, acc.: 57.03%] [G loss: 0.736847]\n",
      "epoch:10 step:9549 [D loss: 0.697626, acc.: 49.22%] [G loss: 0.727476]\n",
      "epoch:10 step:9550 [D loss: 0.676903, acc.: 58.59%] [G loss: 0.738141]\n",
      "epoch:10 step:9551 [D loss: 0.700236, acc.: 50.78%] [G loss: 0.745940]\n",
      "epoch:10 step:9552 [D loss: 0.700164, acc.: 46.88%] [G loss: 0.728989]\n",
      "epoch:10 step:9553 [D loss: 0.695695, acc.: 56.25%] [G loss: 0.749601]\n",
      "epoch:10 step:9554 [D loss: 0.671489, acc.: 61.72%] [G loss: 0.729018]\n",
      "epoch:10 step:9555 [D loss: 0.676779, acc.: 54.69%] [G loss: 0.736549]\n",
      "epoch:10 step:9556 [D loss: 0.693147, acc.: 47.66%] [G loss: 0.731891]\n",
      "epoch:10 step:9557 [D loss: 0.660268, acc.: 58.59%] [G loss: 0.758767]\n",
      "epoch:10 step:9558 [D loss: 0.716667, acc.: 46.88%] [G loss: 0.751806]\n",
      "epoch:10 step:9559 [D loss: 0.691340, acc.: 51.56%] [G loss: 0.725288]\n",
      "epoch:10 step:9560 [D loss: 0.690860, acc.: 47.66%] [G loss: 0.735293]\n",
      "epoch:10 step:9561 [D loss: 0.693438, acc.: 49.22%] [G loss: 0.782761]\n",
      "epoch:10 step:9562 [D loss: 0.673082, acc.: 62.50%] [G loss: 0.778514]\n",
      "epoch:10 step:9563 [D loss: 0.673590, acc.: 56.25%] [G loss: 0.762691]\n",
      "epoch:10 step:9564 [D loss: 0.678610, acc.: 54.69%] [G loss: 0.802410]\n",
      "epoch:10 step:9565 [D loss: 0.655689, acc.: 60.16%] [G loss: 0.795722]\n",
      "epoch:10 step:9566 [D loss: 0.689857, acc.: 49.22%] [G loss: 0.750745]\n",
      "epoch:10 step:9567 [D loss: 0.683292, acc.: 56.25%] [G loss: 0.796435]\n",
      "epoch:10 step:9568 [D loss: 0.681852, acc.: 59.38%] [G loss: 0.824033]\n",
      "epoch:10 step:9569 [D loss: 0.698954, acc.: 46.09%] [G loss: 0.754873]\n",
      "epoch:10 step:9570 [D loss: 0.722518, acc.: 49.22%] [G loss: 0.760271]\n",
      "epoch:10 step:9571 [D loss: 0.725127, acc.: 42.19%] [G loss: 0.750746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9572 [D loss: 0.702023, acc.: 47.66%] [G loss: 0.756897]\n",
      "epoch:10 step:9573 [D loss: 0.679436, acc.: 57.81%] [G loss: 0.751145]\n",
      "epoch:10 step:9574 [D loss: 0.644012, acc.: 62.50%] [G loss: 0.749519]\n",
      "epoch:10 step:9575 [D loss: 0.657297, acc.: 59.38%] [G loss: 0.767335]\n",
      "epoch:10 step:9576 [D loss: 0.670904, acc.: 59.38%] [G loss: 0.740036]\n",
      "epoch:10 step:9577 [D loss: 0.437186, acc.: 78.12%] [G loss: 0.772723]\n",
      "epoch:10 step:9578 [D loss: 0.674360, acc.: 63.28%] [G loss: 0.771992]\n",
      "epoch:10 step:9579 [D loss: 0.645101, acc.: 71.09%] [G loss: 0.774300]\n",
      "epoch:10 step:9580 [D loss: 0.722563, acc.: 48.44%] [G loss: 0.781836]\n",
      "epoch:10 step:9581 [D loss: 0.709523, acc.: 46.09%] [G loss: 0.719492]\n",
      "epoch:10 step:9582 [D loss: 0.683951, acc.: 52.34%] [G loss: 0.761744]\n",
      "epoch:10 step:9583 [D loss: 0.706716, acc.: 45.31%] [G loss: 0.754421]\n",
      "epoch:10 step:9584 [D loss: 0.753559, acc.: 41.41%] [G loss: 0.757976]\n",
      "epoch:10 step:9585 [D loss: 0.703829, acc.: 53.12%] [G loss: 0.729562]\n",
      "epoch:10 step:9586 [D loss: 0.908249, acc.: 46.09%] [G loss: 1.014406]\n",
      "epoch:10 step:9587 [D loss: 0.697165, acc.: 54.69%] [G loss: 0.968543]\n",
      "epoch:10 step:9588 [D loss: 0.736852, acc.: 50.00%] [G loss: 0.821973]\n",
      "epoch:10 step:9589 [D loss: 0.721640, acc.: 50.78%] [G loss: 0.774833]\n",
      "epoch:10 step:9590 [D loss: 0.737321, acc.: 35.16%] [G loss: 0.769047]\n",
      "epoch:10 step:9591 [D loss: 0.682933, acc.: 53.91%] [G loss: 0.766891]\n",
      "epoch:10 step:9592 [D loss: 0.693827, acc.: 53.91%] [G loss: 0.758639]\n",
      "epoch:10 step:9593 [D loss: 0.672735, acc.: 60.94%] [G loss: 0.714988]\n",
      "epoch:10 step:9594 [D loss: 0.717701, acc.: 47.66%] [G loss: 0.749369]\n",
      "epoch:10 step:9595 [D loss: 0.727831, acc.: 41.41%] [G loss: 0.772222]\n",
      "epoch:10 step:9596 [D loss: 0.677422, acc.: 57.03%] [G loss: 0.764366]\n",
      "epoch:10 step:9597 [D loss: 0.681997, acc.: 59.38%] [G loss: 0.738323]\n",
      "epoch:10 step:9598 [D loss: 0.686178, acc.: 54.69%] [G loss: 0.744128]\n",
      "epoch:10 step:9599 [D loss: 0.696663, acc.: 53.12%] [G loss: 0.739944]\n",
      "epoch:10 step:9600 [D loss: 0.671871, acc.: 53.91%] [G loss: 0.736748]\n",
      "epoch:10 step:9601 [D loss: 0.661504, acc.: 61.72%] [G loss: 0.744747]\n",
      "epoch:10 step:9602 [D loss: 0.670989, acc.: 53.12%] [G loss: 0.746424]\n",
      "epoch:10 step:9603 [D loss: 0.709242, acc.: 45.31%] [G loss: 0.748620]\n",
      "epoch:10 step:9604 [D loss: 0.710547, acc.: 44.53%] [G loss: 0.719905]\n",
      "epoch:10 step:9605 [D loss: 0.665232, acc.: 64.84%] [G loss: 0.744090]\n",
      "epoch:10 step:9606 [D loss: 0.676705, acc.: 62.50%] [G loss: 0.737496]\n",
      "epoch:10 step:9607 [D loss: 0.673183, acc.: 57.81%] [G loss: 0.687372]\n",
      "epoch:10 step:9608 [D loss: 0.691834, acc.: 46.88%] [G loss: 0.691357]\n",
      "epoch:10 step:9609 [D loss: 0.708189, acc.: 45.31%] [G loss: 0.732532]\n",
      "epoch:10 step:9610 [D loss: 0.709510, acc.: 45.31%] [G loss: 0.692025]\n",
      "epoch:10 step:9611 [D loss: 0.723881, acc.: 47.66%] [G loss: 0.717440]\n",
      "epoch:10 step:9612 [D loss: 0.693726, acc.: 47.66%] [G loss: 0.712658]\n",
      "epoch:10 step:9613 [D loss: 0.665701, acc.: 61.72%] [G loss: 0.707828]\n",
      "epoch:10 step:9614 [D loss: 0.684640, acc.: 57.81%] [G loss: 0.715198]\n",
      "epoch:10 step:9615 [D loss: 0.703753, acc.: 50.78%] [G loss: 0.731257]\n",
      "epoch:10 step:9616 [D loss: 0.690903, acc.: 53.91%] [G loss: 0.703735]\n",
      "epoch:10 step:9617 [D loss: 0.705791, acc.: 50.78%] [G loss: 0.734499]\n",
      "epoch:10 step:9618 [D loss: 0.687077, acc.: 55.47%] [G loss: 0.763945]\n",
      "epoch:10 step:9619 [D loss: 0.701883, acc.: 51.56%] [G loss: 0.752150]\n",
      "epoch:10 step:9620 [D loss: 0.667869, acc.: 59.38%] [G loss: 0.758154]\n",
      "epoch:10 step:9621 [D loss: 0.659684, acc.: 63.28%] [G loss: 0.796911]\n",
      "epoch:10 step:9622 [D loss: 0.680664, acc.: 52.34%] [G loss: 0.781821]\n",
      "epoch:10 step:9623 [D loss: 0.675512, acc.: 51.56%] [G loss: 0.798464]\n",
      "epoch:10 step:9624 [D loss: 0.677318, acc.: 53.91%] [G loss: 0.826916]\n",
      "epoch:10 step:9625 [D loss: 0.685178, acc.: 59.38%] [G loss: 0.809690]\n",
      "epoch:10 step:9626 [D loss: 0.680391, acc.: 53.91%] [G loss: 0.756977]\n",
      "epoch:10 step:9627 [D loss: 0.697704, acc.: 59.38%] [G loss: 0.742287]\n",
      "epoch:10 step:9628 [D loss: 0.691652, acc.: 58.59%] [G loss: 0.751041]\n",
      "epoch:10 step:9629 [D loss: 0.701734, acc.: 50.78%] [G loss: 0.719223]\n",
      "epoch:10 step:9630 [D loss: 0.708692, acc.: 44.53%] [G loss: 0.703650]\n",
      "epoch:10 step:9631 [D loss: 0.690266, acc.: 54.69%] [G loss: 0.697606]\n",
      "epoch:10 step:9632 [D loss: 0.695855, acc.: 54.69%] [G loss: 0.728485]\n",
      "epoch:10 step:9633 [D loss: 0.640265, acc.: 61.72%] [G loss: 0.723799]\n",
      "epoch:10 step:9634 [D loss: 0.679114, acc.: 58.59%] [G loss: 0.752269]\n",
      "epoch:10 step:9635 [D loss: 0.724407, acc.: 42.97%] [G loss: 0.700470]\n",
      "epoch:10 step:9636 [D loss: 0.697050, acc.: 48.44%] [G loss: 0.726320]\n",
      "epoch:10 step:9637 [D loss: 0.698330, acc.: 52.34%] [G loss: 0.709405]\n",
      "epoch:10 step:9638 [D loss: 0.698586, acc.: 51.56%] [G loss: 0.735790]\n",
      "epoch:10 step:9639 [D loss: 0.670283, acc.: 54.69%] [G loss: 0.757761]\n",
      "epoch:10 step:9640 [D loss: 0.699270, acc.: 46.88%] [G loss: 0.705515]\n",
      "epoch:10 step:9641 [D loss: 0.659940, acc.: 64.06%] [G loss: 0.818672]\n",
      "epoch:10 step:9642 [D loss: 0.722635, acc.: 42.97%] [G loss: 0.716090]\n",
      "epoch:10 step:9643 [D loss: 0.686140, acc.: 56.25%] [G loss: 0.731809]\n",
      "epoch:10 step:9644 [D loss: 0.669348, acc.: 60.16%] [G loss: 0.749193]\n",
      "epoch:10 step:9645 [D loss: 0.686288, acc.: 47.66%] [G loss: 0.709402]\n",
      "epoch:10 step:9646 [D loss: 0.656567, acc.: 62.50%] [G loss: 0.730691]\n",
      "epoch:10 step:9647 [D loss: 0.680082, acc.: 55.47%] [G loss: 0.704442]\n",
      "epoch:10 step:9648 [D loss: 0.722165, acc.: 39.06%] [G loss: 0.715754]\n",
      "epoch:10 step:9649 [D loss: 0.716862, acc.: 41.41%] [G loss: 0.742660]\n",
      "epoch:10 step:9650 [D loss: 0.686787, acc.: 51.56%] [G loss: 0.788933]\n",
      "epoch:10 step:9651 [D loss: 0.703905, acc.: 49.22%] [G loss: 0.766303]\n",
      "epoch:10 step:9652 [D loss: 0.705790, acc.: 49.22%] [G loss: 0.690617]\n",
      "epoch:10 step:9653 [D loss: 0.696535, acc.: 56.25%] [G loss: 0.768944]\n",
      "epoch:10 step:9654 [D loss: 0.681234, acc.: 60.94%] [G loss: 0.764079]\n",
      "epoch:10 step:9655 [D loss: 0.689820, acc.: 56.25%] [G loss: 0.744775]\n",
      "epoch:10 step:9656 [D loss: 0.687761, acc.: 54.69%] [G loss: 0.730386]\n",
      "epoch:10 step:9657 [D loss: 0.678251, acc.: 59.38%] [G loss: 0.756247]\n",
      "epoch:10 step:9658 [D loss: 0.705032, acc.: 50.00%] [G loss: 0.734136]\n",
      "epoch:10 step:9659 [D loss: 0.677186, acc.: 56.25%] [G loss: 0.739513]\n",
      "epoch:10 step:9660 [D loss: 0.695326, acc.: 50.78%] [G loss: 0.757796]\n",
      "epoch:10 step:9661 [D loss: 0.704478, acc.: 48.44%] [G loss: 0.735135]\n",
      "epoch:10 step:9662 [D loss: 0.699187, acc.: 48.44%] [G loss: 0.727974]\n",
      "epoch:10 step:9663 [D loss: 0.694122, acc.: 50.78%] [G loss: 0.742814]\n",
      "epoch:10 step:9664 [D loss: 0.693410, acc.: 57.81%] [G loss: 0.728675]\n",
      "epoch:10 step:9665 [D loss: 0.706138, acc.: 44.53%] [G loss: 0.751111]\n",
      "epoch:10 step:9666 [D loss: 0.711875, acc.: 39.84%] [G loss: 0.744323]\n",
      "epoch:10 step:9667 [D loss: 0.706106, acc.: 50.78%] [G loss: 0.735777]\n",
      "epoch:10 step:9668 [D loss: 0.716055, acc.: 41.41%] [G loss: 0.732390]\n",
      "epoch:10 step:9669 [D loss: 0.699640, acc.: 51.56%] [G loss: 0.737469]\n",
      "epoch:10 step:9670 [D loss: 0.690330, acc.: 57.03%] [G loss: 0.732588]\n",
      "epoch:10 step:9671 [D loss: 0.691857, acc.: 55.47%] [G loss: 0.722063]\n",
      "epoch:10 step:9672 [D loss: 0.693825, acc.: 53.12%] [G loss: 0.714487]\n",
      "epoch:10 step:9673 [D loss: 0.695799, acc.: 48.44%] [G loss: 0.733067]\n",
      "epoch:10 step:9674 [D loss: 0.689360, acc.: 51.56%] [G loss: 0.733220]\n",
      "epoch:10 step:9675 [D loss: 0.687704, acc.: 53.12%] [G loss: 0.723513]\n",
      "epoch:10 step:9676 [D loss: 0.684304, acc.: 59.38%] [G loss: 0.719971]\n",
      "epoch:10 step:9677 [D loss: 0.689348, acc.: 52.34%] [G loss: 0.727590]\n",
      "epoch:10 step:9678 [D loss: 0.684125, acc.: 55.47%] [G loss: 0.718101]\n",
      "epoch:10 step:9679 [D loss: 0.672723, acc.: 60.94%] [G loss: 0.761142]\n",
      "epoch:10 step:9680 [D loss: 0.690518, acc.: 50.78%] [G loss: 0.729379]\n",
      "epoch:10 step:9681 [D loss: 0.671391, acc.: 57.81%] [G loss: 0.711646]\n",
      "epoch:10 step:9682 [D loss: 0.670311, acc.: 63.28%] [G loss: 0.726452]\n",
      "epoch:10 step:9683 [D loss: 0.665363, acc.: 62.50%] [G loss: 0.733687]\n",
      "epoch:10 step:9684 [D loss: 0.660496, acc.: 67.19%] [G loss: 0.799217]\n",
      "epoch:10 step:9685 [D loss: 0.660117, acc.: 64.06%] [G loss: 0.817509]\n",
      "epoch:10 step:9686 [D loss: 0.721994, acc.: 50.78%] [G loss: 0.777565]\n",
      "epoch:10 step:9687 [D loss: 0.701953, acc.: 52.34%] [G loss: 0.728588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9688 [D loss: 0.703166, acc.: 44.53%] [G loss: 0.746297]\n",
      "epoch:10 step:9689 [D loss: 0.699816, acc.: 48.44%] [G loss: 0.776078]\n",
      "epoch:10 step:9690 [D loss: 0.704391, acc.: 49.22%] [G loss: 0.733782]\n",
      "epoch:10 step:9691 [D loss: 0.699926, acc.: 50.78%] [G loss: 0.743736]\n",
      "epoch:10 step:9692 [D loss: 0.677009, acc.: 60.94%] [G loss: 0.728062]\n",
      "epoch:10 step:9693 [D loss: 0.692042, acc.: 47.66%] [G loss: 0.691928]\n",
      "epoch:10 step:9694 [D loss: 0.685688, acc.: 55.47%] [G loss: 0.710450]\n",
      "epoch:10 step:9695 [D loss: 0.686205, acc.: 50.00%] [G loss: 0.734720]\n",
      "epoch:10 step:9696 [D loss: 0.694317, acc.: 54.69%] [G loss: 0.696377]\n",
      "epoch:10 step:9697 [D loss: 0.689717, acc.: 56.25%] [G loss: 0.705781]\n",
      "epoch:10 step:9698 [D loss: 0.694189, acc.: 53.91%] [G loss: 0.752179]\n",
      "epoch:10 step:9699 [D loss: 0.708125, acc.: 50.00%] [G loss: 0.728345]\n",
      "epoch:10 step:9700 [D loss: 0.692425, acc.: 53.12%] [G loss: 0.722469]\n",
      "epoch:10 step:9701 [D loss: 0.688785, acc.: 55.47%] [G loss: 0.727665]\n",
      "epoch:10 step:9702 [D loss: 0.691608, acc.: 46.09%] [G loss: 0.729461]\n",
      "epoch:10 step:9703 [D loss: 0.693024, acc.: 53.91%] [G loss: 0.697164]\n",
      "epoch:10 step:9704 [D loss: 0.710629, acc.: 41.41%] [G loss: 0.705006]\n",
      "epoch:10 step:9705 [D loss: 0.700994, acc.: 48.44%] [G loss: 0.706417]\n",
      "epoch:10 step:9706 [D loss: 0.676981, acc.: 54.69%] [G loss: 0.726294]\n",
      "epoch:10 step:9707 [D loss: 0.696407, acc.: 53.12%] [G loss: 0.698059]\n",
      "epoch:10 step:9708 [D loss: 0.697863, acc.: 47.66%] [G loss: 0.715820]\n",
      "epoch:10 step:9709 [D loss: 0.667873, acc.: 60.94%] [G loss: 0.731104]\n",
      "epoch:10 step:9710 [D loss: 0.697601, acc.: 49.22%] [G loss: 0.766082]\n",
      "epoch:10 step:9711 [D loss: 0.670238, acc.: 60.16%] [G loss: 0.784041]\n",
      "epoch:10 step:9712 [D loss: 0.689955, acc.: 53.91%] [G loss: 0.753912]\n",
      "epoch:10 step:9713 [D loss: 0.668438, acc.: 62.50%] [G loss: 0.746889]\n",
      "epoch:10 step:9714 [D loss: 0.645165, acc.: 69.53%] [G loss: 0.743457]\n",
      "epoch:10 step:9715 [D loss: 0.697453, acc.: 50.00%] [G loss: 0.730546]\n",
      "epoch:10 step:9716 [D loss: 0.666358, acc.: 60.16%] [G loss: 0.727489]\n",
      "epoch:10 step:9717 [D loss: 0.684752, acc.: 57.81%] [G loss: 0.766822]\n",
      "epoch:10 step:9718 [D loss: 0.691977, acc.: 50.78%] [G loss: 0.758078]\n",
      "epoch:10 step:9719 [D loss: 0.695431, acc.: 45.31%] [G loss: 0.718842]\n",
      "epoch:10 step:9720 [D loss: 0.705702, acc.: 50.00%] [G loss: 0.741172]\n",
      "epoch:10 step:9721 [D loss: 0.703057, acc.: 46.88%] [G loss: 0.732402]\n",
      "epoch:10 step:9722 [D loss: 0.697450, acc.: 49.22%] [G loss: 0.699786]\n",
      "epoch:10 step:9723 [D loss: 0.700853, acc.: 52.34%] [G loss: 0.721064]\n",
      "epoch:10 step:9724 [D loss: 0.692078, acc.: 54.69%] [G loss: 0.726259]\n",
      "epoch:10 step:9725 [D loss: 0.722899, acc.: 48.44%] [G loss: 0.742981]\n",
      "epoch:10 step:9726 [D loss: 0.674811, acc.: 59.38%] [G loss: 0.733554]\n",
      "epoch:10 step:9727 [D loss: 0.691697, acc.: 51.56%] [G loss: 0.717388]\n",
      "epoch:10 step:9728 [D loss: 0.671045, acc.: 56.25%] [G loss: 0.726937]\n",
      "epoch:10 step:9729 [D loss: 0.678917, acc.: 60.16%] [G loss: 0.762051]\n",
      "epoch:10 step:9730 [D loss: 0.652243, acc.: 59.38%] [G loss: 0.750044]\n",
      "epoch:10 step:9731 [D loss: 0.676164, acc.: 54.69%] [G loss: 0.755104]\n",
      "epoch:10 step:9732 [D loss: 0.697524, acc.: 48.44%] [G loss: 0.726525]\n",
      "epoch:10 step:9733 [D loss: 0.689040, acc.: 54.69%] [G loss: 0.730208]\n",
      "epoch:10 step:9734 [D loss: 0.668444, acc.: 53.91%] [G loss: 0.782762]\n",
      "epoch:10 step:9735 [D loss: 0.712794, acc.: 46.88%] [G loss: 0.723036]\n",
      "epoch:10 step:9736 [D loss: 0.713947, acc.: 41.41%] [G loss: 0.704968]\n",
      "epoch:10 step:9737 [D loss: 0.717501, acc.: 45.31%] [G loss: 0.708416]\n",
      "epoch:10 step:9738 [D loss: 0.713105, acc.: 52.34%] [G loss: 0.716958]\n",
      "epoch:10 step:9739 [D loss: 0.695777, acc.: 51.56%] [G loss: 0.696826]\n",
      "epoch:10 step:9740 [D loss: 0.685950, acc.: 52.34%] [G loss: 0.710319]\n",
      "epoch:10 step:9741 [D loss: 0.632009, acc.: 64.84%] [G loss: 0.711558]\n",
      "epoch:10 step:9742 [D loss: 0.661047, acc.: 57.81%] [G loss: 0.750523]\n",
      "epoch:10 step:9743 [D loss: 0.699891, acc.: 50.78%] [G loss: 0.740159]\n",
      "epoch:10 step:9744 [D loss: 0.699817, acc.: 55.47%] [G loss: 0.731898]\n",
      "epoch:10 step:9745 [D loss: 0.686185, acc.: 55.47%] [G loss: 0.729555]\n",
      "epoch:10 step:9746 [D loss: 0.689490, acc.: 53.91%] [G loss: 0.727559]\n",
      "epoch:10 step:9747 [D loss: 0.718256, acc.: 42.97%] [G loss: 0.699134]\n",
      "epoch:10 step:9748 [D loss: 0.702793, acc.: 47.66%] [G loss: 0.735430]\n",
      "epoch:10 step:9749 [D loss: 0.707287, acc.: 50.00%] [G loss: 0.724084]\n",
      "epoch:10 step:9750 [D loss: 0.684942, acc.: 47.66%] [G loss: 0.724194]\n",
      "epoch:10 step:9751 [D loss: 0.682983, acc.: 52.34%] [G loss: 0.733033]\n",
      "epoch:10 step:9752 [D loss: 0.698257, acc.: 50.00%] [G loss: 0.721013]\n",
      "epoch:10 step:9753 [D loss: 0.692805, acc.: 53.12%] [G loss: 0.760329]\n",
      "epoch:10 step:9754 [D loss: 0.685761, acc.: 50.78%] [G loss: 0.785428]\n",
      "epoch:10 step:9755 [D loss: 0.681369, acc.: 51.56%] [G loss: 0.766782]\n",
      "epoch:10 step:9756 [D loss: 0.665101, acc.: 62.50%] [G loss: 0.777667]\n",
      "epoch:10 step:9757 [D loss: 0.684630, acc.: 52.34%] [G loss: 0.765615]\n",
      "epoch:10 step:9758 [D loss: 0.666366, acc.: 58.59%] [G loss: 0.784518]\n",
      "epoch:10 step:9759 [D loss: 0.686651, acc.: 53.12%] [G loss: 0.738593]\n",
      "epoch:10 step:9760 [D loss: 0.715934, acc.: 45.31%] [G loss: 0.746923]\n",
      "epoch:10 step:9761 [D loss: 0.706323, acc.: 49.22%] [G loss: 0.652701]\n",
      "epoch:10 step:9762 [D loss: 0.716881, acc.: 46.09%] [G loss: 0.725695]\n",
      "epoch:10 step:9763 [D loss: 0.708380, acc.: 44.53%] [G loss: 0.727784]\n",
      "epoch:10 step:9764 [D loss: 0.693066, acc.: 47.66%] [G loss: 0.722871]\n",
      "epoch:10 step:9765 [D loss: 0.694024, acc.: 48.44%] [G loss: 0.735624]\n",
      "epoch:10 step:9766 [D loss: 0.676112, acc.: 63.28%] [G loss: 0.737019]\n",
      "epoch:10 step:9767 [D loss: 0.686768, acc.: 53.91%] [G loss: 0.776166]\n",
      "epoch:10 step:9768 [D loss: 0.662260, acc.: 65.62%] [G loss: 0.780121]\n",
      "epoch:10 step:9769 [D loss: 0.628754, acc.: 75.78%] [G loss: 0.738616]\n",
      "epoch:10 step:9770 [D loss: 0.675053, acc.: 60.16%] [G loss: 0.787317]\n",
      "epoch:10 step:9771 [D loss: 0.675142, acc.: 50.78%] [G loss: 0.754310]\n",
      "epoch:10 step:9772 [D loss: 0.670897, acc.: 63.28%] [G loss: 0.768670]\n",
      "epoch:10 step:9773 [D loss: 0.720278, acc.: 57.03%] [G loss: 0.840866]\n",
      "epoch:10 step:9774 [D loss: 0.622280, acc.: 68.75%] [G loss: 0.792292]\n",
      "epoch:10 step:9775 [D loss: 0.662084, acc.: 58.59%] [G loss: 0.833439]\n",
      "epoch:10 step:9776 [D loss: 0.655713, acc.: 62.50%] [G loss: 0.962812]\n",
      "epoch:10 step:9777 [D loss: 0.694109, acc.: 53.91%] [G loss: 0.806677]\n",
      "epoch:10 step:9778 [D loss: 0.692765, acc.: 51.56%] [G loss: 0.750317]\n",
      "epoch:10 step:9779 [D loss: 0.687314, acc.: 52.34%] [G loss: 0.713487]\n",
      "epoch:10 step:9780 [D loss: 0.722586, acc.: 44.53%] [G loss: 0.711892]\n",
      "epoch:10 step:9781 [D loss: 0.765843, acc.: 32.81%] [G loss: 0.701969]\n",
      "epoch:10 step:9782 [D loss: 0.708937, acc.: 48.44%] [G loss: 0.743535]\n",
      "epoch:10 step:9783 [D loss: 0.708717, acc.: 44.53%] [G loss: 0.693279]\n",
      "epoch:10 step:9784 [D loss: 0.696116, acc.: 47.66%] [G loss: 0.732290]\n",
      "epoch:10 step:9785 [D loss: 0.689955, acc.: 53.12%] [G loss: 0.754006]\n",
      "epoch:10 step:9786 [D loss: 0.686137, acc.: 50.78%] [G loss: 0.730624]\n",
      "epoch:10 step:9787 [D loss: 0.711903, acc.: 51.56%] [G loss: 0.721770]\n",
      "epoch:10 step:9788 [D loss: 0.691602, acc.: 52.34%] [G loss: 0.709647]\n",
      "epoch:10 step:9789 [D loss: 0.689902, acc.: 55.47%] [G loss: 0.733828]\n",
      "epoch:10 step:9790 [D loss: 0.677825, acc.: 55.47%] [G loss: 0.802634]\n",
      "epoch:10 step:9791 [D loss: 0.689680, acc.: 51.56%] [G loss: 0.748201]\n",
      "epoch:10 step:9792 [D loss: 0.687727, acc.: 51.56%] [G loss: 0.793369]\n",
      "epoch:10 step:9793 [D loss: 0.682952, acc.: 53.12%] [G loss: 0.728585]\n",
      "epoch:10 step:9794 [D loss: 0.688585, acc.: 50.00%] [G loss: 0.744034]\n",
      "epoch:10 step:9795 [D loss: 0.704179, acc.: 46.88%] [G loss: 0.745416]\n",
      "epoch:10 step:9796 [D loss: 0.684691, acc.: 54.69%] [G loss: 0.723817]\n",
      "epoch:10 step:9797 [D loss: 0.699390, acc.: 53.91%] [G loss: 0.727556]\n",
      "epoch:10 step:9798 [D loss: 0.696932, acc.: 44.53%] [G loss: 0.740550]\n",
      "epoch:10 step:9799 [D loss: 0.702202, acc.: 46.88%] [G loss: 0.724259]\n",
      "epoch:10 step:9800 [D loss: 0.696298, acc.: 53.91%] [G loss: 0.751993]\n",
      "epoch:10 step:9801 [D loss: 0.689738, acc.: 54.69%] [G loss: 0.738136]\n",
      "epoch:10 step:9802 [D loss: 0.690279, acc.: 50.00%] [G loss: 0.730461]\n",
      "epoch:10 step:9803 [D loss: 0.676901, acc.: 57.81%] [G loss: 0.728966]\n",
      "epoch:10 step:9804 [D loss: 0.680080, acc.: 58.59%] [G loss: 0.742067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9805 [D loss: 0.674914, acc.: 60.16%] [G loss: 0.747138]\n",
      "epoch:10 step:9806 [D loss: 0.659591, acc.: 61.72%] [G loss: 0.732300]\n",
      "epoch:10 step:9807 [D loss: 0.703136, acc.: 42.97%] [G loss: 0.710721]\n",
      "epoch:10 step:9808 [D loss: 0.700414, acc.: 48.44%] [G loss: 0.737169]\n",
      "epoch:10 step:9809 [D loss: 0.693371, acc.: 50.00%] [G loss: 0.737542]\n",
      "epoch:10 step:9810 [D loss: 0.710533, acc.: 42.97%] [G loss: 0.727143]\n",
      "epoch:10 step:9811 [D loss: 0.708401, acc.: 47.66%] [G loss: 0.713596]\n",
      "epoch:10 step:9812 [D loss: 0.702757, acc.: 48.44%] [G loss: 0.740816]\n",
      "epoch:10 step:9813 [D loss: 0.697266, acc.: 51.56%] [G loss: 0.741489]\n",
      "epoch:10 step:9814 [D loss: 0.685574, acc.: 56.25%] [G loss: 0.735055]\n",
      "epoch:10 step:9815 [D loss: 0.695581, acc.: 49.22%] [G loss: 0.736174]\n",
      "epoch:10 step:9816 [D loss: 0.707147, acc.: 47.66%] [G loss: 0.728800]\n",
      "epoch:10 step:9817 [D loss: 0.688751, acc.: 53.12%] [G loss: 0.740011]\n",
      "epoch:10 step:9818 [D loss: 0.692232, acc.: 52.34%] [G loss: 0.730057]\n",
      "epoch:10 step:9819 [D loss: 0.685174, acc.: 55.47%] [G loss: 0.739430]\n",
      "epoch:10 step:9820 [D loss: 0.677969, acc.: 63.28%] [G loss: 0.739080]\n",
      "epoch:10 step:9821 [D loss: 0.675925, acc.: 55.47%] [G loss: 0.720004]\n",
      "epoch:10 step:9822 [D loss: 0.669485, acc.: 59.38%] [G loss: 0.756170]\n",
      "epoch:10 step:9823 [D loss: 0.673311, acc.: 53.12%] [G loss: 0.759061]\n",
      "epoch:10 step:9824 [D loss: 0.684767, acc.: 55.47%] [G loss: 0.799946]\n",
      "epoch:10 step:9825 [D loss: 0.687908, acc.: 52.34%] [G loss: 0.770939]\n",
      "epoch:10 step:9826 [D loss: 0.566885, acc.: 71.88%] [G loss: 0.784202]\n",
      "epoch:10 step:9827 [D loss: 0.635750, acc.: 72.66%] [G loss: 0.753438]\n",
      "epoch:10 step:9828 [D loss: 0.714895, acc.: 51.56%] [G loss: 0.733435]\n",
      "epoch:10 step:9829 [D loss: 0.669053, acc.: 61.72%] [G loss: 0.687447]\n",
      "epoch:10 step:9830 [D loss: 0.723188, acc.: 42.97%] [G loss: 0.737162]\n",
      "epoch:10 step:9831 [D loss: 0.724175, acc.: 50.78%] [G loss: 0.750995]\n",
      "epoch:10 step:9832 [D loss: 0.740726, acc.: 35.16%] [G loss: 0.725811]\n",
      "epoch:10 step:9833 [D loss: 0.694553, acc.: 52.34%] [G loss: 0.691763]\n",
      "epoch:10 step:9834 [D loss: 0.684257, acc.: 59.38%] [G loss: 0.714721]\n",
      "epoch:10 step:9835 [D loss: 0.698088, acc.: 48.44%] [G loss: 0.743832]\n",
      "epoch:10 step:9836 [D loss: 0.714329, acc.: 44.53%] [G loss: 0.723113]\n",
      "epoch:10 step:9837 [D loss: 0.673591, acc.: 53.91%] [G loss: 0.734674]\n",
      "epoch:10 step:9838 [D loss: 0.690187, acc.: 48.44%] [G loss: 0.378502]\n",
      "epoch:10 step:9839 [D loss: 0.691024, acc.: 50.78%] [G loss: 0.749619]\n",
      "epoch:10 step:9840 [D loss: 0.683134, acc.: 54.69%] [G loss: 0.734525]\n",
      "epoch:10 step:9841 [D loss: 0.713782, acc.: 46.09%] [G loss: 0.702303]\n",
      "epoch:10 step:9842 [D loss: 0.928760, acc.: 36.72%] [G loss: 0.862018]\n",
      "epoch:10 step:9843 [D loss: 0.668465, acc.: 57.03%] [G loss: 0.849327]\n",
      "epoch:10 step:9844 [D loss: 0.608539, acc.: 62.50%] [G loss: 0.946028]\n",
      "epoch:10 step:9845 [D loss: 0.662941, acc.: 55.47%] [G loss: 0.973119]\n",
      "epoch:10 step:9846 [D loss: 0.652336, acc.: 62.50%] [G loss: 0.840592]\n",
      "epoch:10 step:9847 [D loss: 0.719503, acc.: 48.44%] [G loss: 0.894816]\n",
      "epoch:10 step:9848 [D loss: 0.734388, acc.: 42.19%] [G loss: 0.744205]\n",
      "epoch:10 step:9849 [D loss: 0.768794, acc.: 32.81%] [G loss: 0.756563]\n",
      "epoch:10 step:9850 [D loss: 0.767941, acc.: 42.97%] [G loss: 0.725731]\n",
      "epoch:10 step:9851 [D loss: 0.723967, acc.: 40.62%] [G loss: 0.720635]\n",
      "epoch:10 step:9852 [D loss: 0.685854, acc.: 54.69%] [G loss: 0.726661]\n",
      "epoch:10 step:9853 [D loss: 0.676730, acc.: 59.38%] [G loss: 0.744674]\n",
      "epoch:10 step:9854 [D loss: 0.682029, acc.: 56.25%] [G loss: 0.721236]\n",
      "epoch:10 step:9855 [D loss: 0.679860, acc.: 56.25%] [G loss: 0.747540]\n",
      "epoch:10 step:9856 [D loss: 0.678543, acc.: 55.47%] [G loss: 0.714784]\n",
      "epoch:10 step:9857 [D loss: 0.671272, acc.: 57.03%] [G loss: 0.759852]\n",
      "epoch:10 step:9858 [D loss: 0.680805, acc.: 52.34%] [G loss: 0.780144]\n",
      "epoch:10 step:9859 [D loss: 0.687838, acc.: 48.44%] [G loss: 0.756619]\n",
      "epoch:10 step:9860 [D loss: 0.682753, acc.: 59.38%] [G loss: 0.752334]\n",
      "epoch:10 step:9861 [D loss: 0.682835, acc.: 51.56%] [G loss: 0.730420]\n",
      "epoch:10 step:9862 [D loss: 0.673772, acc.: 57.03%] [G loss: 0.758478]\n",
      "epoch:10 step:9863 [D loss: 0.683743, acc.: 49.22%] [G loss: 0.742460]\n",
      "epoch:10 step:9864 [D loss: 0.676584, acc.: 57.81%] [G loss: 0.768924]\n",
      "epoch:10 step:9865 [D loss: 0.678046, acc.: 60.16%] [G loss: 0.742414]\n",
      "epoch:10 step:9866 [D loss: 0.673618, acc.: 54.69%] [G loss: 0.759357]\n",
      "epoch:10 step:9867 [D loss: 0.674407, acc.: 57.03%] [G loss: 0.733944]\n",
      "epoch:10 step:9868 [D loss: 0.704445, acc.: 48.44%] [G loss: 0.744400]\n",
      "epoch:10 step:9869 [D loss: 0.690668, acc.: 50.00%] [G loss: 0.721778]\n",
      "epoch:10 step:9870 [D loss: 0.716749, acc.: 43.75%] [G loss: 0.720117]\n",
      "epoch:10 step:9871 [D loss: 0.706912, acc.: 46.88%] [G loss: 0.774456]\n",
      "epoch:10 step:9872 [D loss: 0.694091, acc.: 51.56%] [G loss: 0.763085]\n",
      "epoch:10 step:9873 [D loss: 0.662179, acc.: 57.03%] [G loss: 0.785499]\n",
      "epoch:10 step:9874 [D loss: 0.651183, acc.: 61.72%] [G loss: 0.820781]\n",
      "epoch:10 step:9875 [D loss: 0.631749, acc.: 64.06%] [G loss: 0.813316]\n",
      "epoch:10 step:9876 [D loss: 0.671566, acc.: 65.62%] [G loss: 0.763055]\n",
      "epoch:10 step:9877 [D loss: 0.640450, acc.: 67.97%] [G loss: 0.862335]\n",
      "epoch:10 step:9878 [D loss: 0.650123, acc.: 72.66%] [G loss: 0.825550]\n",
      "epoch:10 step:9879 [D loss: 0.740824, acc.: 40.62%] [G loss: 0.752401]\n",
      "epoch:10 step:9880 [D loss: 0.741928, acc.: 37.50%] [G loss: 0.737189]\n",
      "epoch:10 step:9881 [D loss: 0.712325, acc.: 41.41%] [G loss: 0.686193]\n",
      "epoch:10 step:9882 [D loss: 0.739115, acc.: 37.50%] [G loss: 0.698072]\n",
      "epoch:10 step:9883 [D loss: 0.718535, acc.: 40.62%] [G loss: 0.728397]\n",
      "epoch:10 step:9884 [D loss: 0.705733, acc.: 44.53%] [G loss: 0.716567]\n",
      "epoch:10 step:9885 [D loss: 0.686278, acc.: 57.81%] [G loss: 0.741497]\n",
      "epoch:10 step:9886 [D loss: 0.675863, acc.: 58.59%] [G loss: 0.744008]\n",
      "epoch:10 step:9887 [D loss: 0.669553, acc.: 58.59%] [G loss: 0.731043]\n",
      "epoch:10 step:9888 [D loss: 0.671598, acc.: 60.94%] [G loss: 0.736596]\n",
      "epoch:10 step:9889 [D loss: 0.676986, acc.: 60.16%] [G loss: 0.713682]\n",
      "epoch:10 step:9890 [D loss: 0.650438, acc.: 62.50%] [G loss: 0.720222]\n",
      "epoch:10 step:9891 [D loss: 0.704336, acc.: 46.88%] [G loss: 0.716873]\n",
      "epoch:10 step:9892 [D loss: 0.675032, acc.: 56.25%] [G loss: 0.730801]\n",
      "epoch:10 step:9893 [D loss: 0.663985, acc.: 63.28%] [G loss: 0.770907]\n",
      "epoch:10 step:9894 [D loss: 0.685758, acc.: 50.00%] [G loss: 0.763104]\n",
      "epoch:10 step:9895 [D loss: 0.684965, acc.: 55.47%] [G loss: 0.788414]\n",
      "epoch:10 step:9896 [D loss: 0.682922, acc.: 53.91%] [G loss: 0.763601]\n",
      "epoch:10 step:9897 [D loss: 0.692504, acc.: 46.88%] [G loss: 0.757265]\n",
      "epoch:10 step:9898 [D loss: 0.711767, acc.: 44.53%] [G loss: 0.726304]\n",
      "epoch:10 step:9899 [D loss: 0.710057, acc.: 39.84%] [G loss: 0.760050]\n",
      "epoch:10 step:9900 [D loss: 0.692144, acc.: 51.56%] [G loss: 0.712776]\n",
      "epoch:10 step:9901 [D loss: 0.694764, acc.: 55.47%] [G loss: 0.736902]\n",
      "epoch:10 step:9902 [D loss: 0.684584, acc.: 56.25%] [G loss: 0.725871]\n",
      "epoch:10 step:9903 [D loss: 0.684003, acc.: 50.78%] [G loss: 0.718419]\n",
      "epoch:10 step:9904 [D loss: 0.688846, acc.: 57.03%] [G loss: 0.736087]\n",
      "epoch:10 step:9905 [D loss: 0.699612, acc.: 50.00%] [G loss: 0.711424]\n",
      "epoch:10 step:9906 [D loss: 0.715702, acc.: 46.09%] [G loss: 0.735234]\n",
      "epoch:10 step:9907 [D loss: 0.684500, acc.: 57.03%] [G loss: 0.730234]\n",
      "epoch:10 step:9908 [D loss: 0.685306, acc.: 53.12%] [G loss: 0.759692]\n",
      "epoch:10 step:9909 [D loss: 0.673404, acc.: 60.16%] [G loss: 0.748887]\n",
      "epoch:10 step:9910 [D loss: 0.678300, acc.: 52.34%] [G loss: 0.738081]\n",
      "epoch:10 step:9911 [D loss: 0.663760, acc.: 64.84%] [G loss: 0.777389]\n",
      "epoch:10 step:9912 [D loss: 0.723003, acc.: 46.88%] [G loss: 0.752624]\n",
      "epoch:10 step:9913 [D loss: 0.651150, acc.: 53.91%] [G loss: 0.744238]\n",
      "epoch:10 step:9914 [D loss: 0.684593, acc.: 56.25%] [G loss: 0.695678]\n",
      "epoch:10 step:9915 [D loss: 0.710027, acc.: 55.47%] [G loss: 0.718605]\n",
      "epoch:10 step:9916 [D loss: 0.697715, acc.: 50.78%] [G loss: 0.689794]\n",
      "epoch:10 step:9917 [D loss: 0.703255, acc.: 51.56%] [G loss: 0.743968]\n",
      "epoch:10 step:9918 [D loss: 0.660878, acc.: 58.59%] [G loss: 0.724734]\n",
      "epoch:10 step:9919 [D loss: 0.690053, acc.: 53.91%] [G loss: 0.742122]\n",
      "epoch:10 step:9920 [D loss: 0.590679, acc.: 67.97%] [G loss: 0.726838]\n",
      "epoch:10 step:9921 [D loss: 0.665623, acc.: 63.28%] [G loss: 0.714205]\n",
      "epoch:10 step:9922 [D loss: 0.681492, acc.: 59.38%] [G loss: 0.706468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9923 [D loss: 0.713377, acc.: 46.88%] [G loss: 0.757941]\n",
      "epoch:10 step:9924 [D loss: 0.660719, acc.: 57.81%] [G loss: 0.750673]\n",
      "epoch:10 step:9925 [D loss: 0.669835, acc.: 64.84%] [G loss: 0.733975]\n",
      "epoch:10 step:9926 [D loss: 0.666199, acc.: 60.94%] [G loss: 0.758115]\n",
      "epoch:10 step:9927 [D loss: 0.699288, acc.: 53.12%] [G loss: 0.741845]\n",
      "epoch:10 step:9928 [D loss: 0.723525, acc.: 50.78%] [G loss: 0.741959]\n",
      "epoch:10 step:9929 [D loss: 0.716039, acc.: 44.53%] [G loss: 0.766783]\n",
      "epoch:10 step:9930 [D loss: 0.714073, acc.: 42.97%] [G loss: 0.771598]\n",
      "epoch:10 step:9931 [D loss: 0.709607, acc.: 47.66%] [G loss: 0.742341]\n",
      "epoch:10 step:9932 [D loss: 0.708004, acc.: 46.88%] [G loss: 0.777482]\n",
      "epoch:10 step:9933 [D loss: 0.666638, acc.: 54.69%] [G loss: 0.744787]\n",
      "epoch:10 step:9934 [D loss: 0.670915, acc.: 60.16%] [G loss: 0.769489]\n",
      "epoch:10 step:9935 [D loss: 0.693913, acc.: 53.12%] [G loss: 0.772485]\n",
      "epoch:10 step:9936 [D loss: 0.707553, acc.: 47.66%] [G loss: 0.744316]\n",
      "epoch:10 step:9937 [D loss: 0.682276, acc.: 55.47%] [G loss: 0.789370]\n",
      "epoch:10 step:9938 [D loss: 0.687889, acc.: 53.12%] [G loss: 0.811481]\n",
      "epoch:10 step:9939 [D loss: 0.682223, acc.: 58.59%] [G loss: 0.831807]\n",
      "epoch:10 step:9940 [D loss: 0.661331, acc.: 59.38%] [G loss: 0.881355]\n",
      "epoch:10 step:9941 [D loss: 0.651427, acc.: 60.94%] [G loss: 0.881227]\n",
      "epoch:10 step:9942 [D loss: 0.654374, acc.: 60.94%] [G loss: 0.886285]\n",
      "epoch:10 step:9943 [D loss: 0.660381, acc.: 55.47%] [G loss: 0.812831]\n",
      "epoch:10 step:9944 [D loss: 0.659686, acc.: 58.59%] [G loss: 0.815421]\n",
      "epoch:10 step:9945 [D loss: 0.643189, acc.: 73.44%] [G loss: 0.780834]\n",
      "epoch:10 step:9946 [D loss: 0.686836, acc.: 51.56%] [G loss: 0.702434]\n",
      "epoch:10 step:9947 [D loss: 0.713808, acc.: 46.09%] [G loss: 0.742579]\n",
      "epoch:10 step:9948 [D loss: 0.703259, acc.: 48.44%] [G loss: 0.700866]\n",
      "epoch:10 step:9949 [D loss: 0.730488, acc.: 43.75%] [G loss: 0.702574]\n",
      "epoch:10 step:9950 [D loss: 0.722434, acc.: 41.41%] [G loss: 0.711795]\n",
      "epoch:10 step:9951 [D loss: 0.699962, acc.: 51.56%] [G loss: 0.728219]\n",
      "epoch:10 step:9952 [D loss: 0.697962, acc.: 45.31%] [G loss: 0.718007]\n",
      "epoch:10 step:9953 [D loss: 0.721982, acc.: 42.97%] [G loss: 0.720994]\n",
      "epoch:10 step:9954 [D loss: 0.701988, acc.: 46.88%] [G loss: 0.705836]\n",
      "epoch:10 step:9955 [D loss: 0.681806, acc.: 52.34%] [G loss: 0.753537]\n",
      "epoch:10 step:9956 [D loss: 0.678050, acc.: 63.28%] [G loss: 0.753677]\n",
      "epoch:10 step:9957 [D loss: 0.688807, acc.: 51.56%] [G loss: 0.748213]\n",
      "epoch:10 step:9958 [D loss: 0.694618, acc.: 52.34%] [G loss: 0.746138]\n",
      "epoch:10 step:9959 [D loss: 0.678916, acc.: 57.03%] [G loss: 0.758838]\n",
      "epoch:10 step:9960 [D loss: 0.686810, acc.: 53.91%] [G loss: 0.746708]\n",
      "epoch:10 step:9961 [D loss: 0.664297, acc.: 60.94%] [G loss: 0.755481]\n",
      "epoch:10 step:9962 [D loss: 0.662296, acc.: 61.72%] [G loss: 0.756214]\n",
      "epoch:10 step:9963 [D loss: 0.674059, acc.: 54.69%] [G loss: 0.761517]\n",
      "epoch:10 step:9964 [D loss: 0.678622, acc.: 58.59%] [G loss: 0.775727]\n",
      "epoch:10 step:9965 [D loss: 0.672502, acc.: 61.72%] [G loss: 0.732767]\n",
      "epoch:10 step:9966 [D loss: 0.664555, acc.: 53.12%] [G loss: 0.749924]\n",
      "epoch:10 step:9967 [D loss: 0.697797, acc.: 52.34%] [G loss: 0.769858]\n",
      "epoch:10 step:9968 [D loss: 0.648565, acc.: 62.50%] [G loss: 0.729171]\n",
      "epoch:10 step:9969 [D loss: 0.683466, acc.: 52.34%] [G loss: 0.709780]\n",
      "epoch:10 step:9970 [D loss: 0.677229, acc.: 55.47%] [G loss: 0.726358]\n",
      "epoch:10 step:9971 [D loss: 0.735315, acc.: 46.88%] [G loss: 0.738885]\n",
      "epoch:10 step:9972 [D loss: 0.714844, acc.: 50.78%] [G loss: 0.747993]\n",
      "epoch:10 step:9973 [D loss: 0.714054, acc.: 53.12%] [G loss: 0.735587]\n",
      "epoch:10 step:9974 [D loss: 0.557727, acc.: 61.72%] [G loss: 0.727156]\n",
      "epoch:10 step:9975 [D loss: 0.688339, acc.: 50.78%] [G loss: 0.719894]\n",
      "epoch:10 step:9976 [D loss: 0.679406, acc.: 53.12%] [G loss: 0.715523]\n",
      "epoch:10 step:9977 [D loss: 0.718181, acc.: 43.75%] [G loss: 0.746248]\n",
      "epoch:10 step:9978 [D loss: 0.750881, acc.: 41.41%] [G loss: 0.734542]\n",
      "epoch:10 step:9979 [D loss: 0.701793, acc.: 46.09%] [G loss: 0.762503]\n",
      "epoch:10 step:9980 [D loss: 0.693254, acc.: 50.00%] [G loss: 0.730388]\n",
      "epoch:10 step:9981 [D loss: 0.681287, acc.: 57.03%] [G loss: 0.774478]\n",
      "epoch:10 step:9982 [D loss: 0.681912, acc.: 55.47%] [G loss: 0.778987]\n",
      "epoch:10 step:9983 [D loss: 0.680906, acc.: 50.78%] [G loss: 0.699032]\n",
      "epoch:10 step:9984 [D loss: 0.690718, acc.: 55.47%] [G loss: 0.751005]\n",
      "epoch:10 step:9985 [D loss: 0.694442, acc.: 52.34%] [G loss: 0.773554]\n",
      "epoch:10 step:9986 [D loss: 0.672832, acc.: 56.25%] [G loss: 0.708804]\n",
      "epoch:10 step:9987 [D loss: 0.696111, acc.: 46.88%] [G loss: 0.670568]\n",
      "epoch:10 step:9988 [D loss: 0.694580, acc.: 44.53%] [G loss: 0.703803]\n",
      "epoch:10 step:9989 [D loss: 0.668061, acc.: 56.25%] [G loss: 0.683571]\n",
      "epoch:10 step:9990 [D loss: 0.703504, acc.: 45.31%] [G loss: 0.746264]\n",
      "epoch:10 step:9991 [D loss: 0.694264, acc.: 50.00%] [G loss: 0.726304]\n",
      "epoch:10 step:9992 [D loss: 0.715111, acc.: 46.09%] [G loss: 0.716350]\n",
      "epoch:10 step:9993 [D loss: 0.693828, acc.: 53.91%] [G loss: 0.763826]\n",
      "epoch:10 step:9994 [D loss: 0.666372, acc.: 60.94%] [G loss: 0.801964]\n",
      "epoch:10 step:9995 [D loss: 0.679501, acc.: 52.34%] [G loss: 0.784574]\n",
      "epoch:10 step:9996 [D loss: 0.671489, acc.: 57.81%] [G loss: 0.756242]\n",
      "epoch:10 step:9997 [D loss: 0.667508, acc.: 57.81%] [G loss: 0.761833]\n",
      "epoch:10 step:9998 [D loss: 0.665317, acc.: 57.81%] [G loss: 0.817635]\n",
      "epoch:10 step:9999 [D loss: 0.647820, acc.: 64.84%] [G loss: 0.782563]\n",
      "epoch:10 step:10000 [D loss: 0.697790, acc.: 53.12%] [G loss: 0.785276]\n",
      "epoch:10 step:10001 [D loss: 0.685841, acc.: 57.81%] [G loss: 0.736456]\n",
      "epoch:10 step:10002 [D loss: 0.779353, acc.: 43.75%] [G loss: 0.726513]\n",
      "epoch:10 step:10003 [D loss: 0.692821, acc.: 59.38%] [G loss: 0.728822]\n",
      "epoch:10 step:10004 [D loss: 0.720436, acc.: 44.53%] [G loss: 0.768558]\n",
      "epoch:10 step:10005 [D loss: 0.673972, acc.: 57.81%] [G loss: 0.708871]\n",
      "epoch:10 step:10006 [D loss: 0.697205, acc.: 50.00%] [G loss: 0.746863]\n",
      "epoch:10 step:10007 [D loss: 0.692109, acc.: 58.59%] [G loss: 0.767214]\n",
      "epoch:10 step:10008 [D loss: 0.679394, acc.: 60.16%] [G loss: 0.706960]\n",
      "epoch:10 step:10009 [D loss: 0.681671, acc.: 58.59%] [G loss: 0.728166]\n",
      "epoch:10 step:10010 [D loss: 0.684695, acc.: 52.34%] [G loss: 0.750163]\n",
      "epoch:10 step:10011 [D loss: 0.680099, acc.: 54.69%] [G loss: 0.770928]\n",
      "epoch:10 step:10012 [D loss: 0.676787, acc.: 51.56%] [G loss: 0.809436]\n",
      "epoch:10 step:10013 [D loss: 0.688048, acc.: 48.44%] [G loss: 0.791558]\n",
      "epoch:10 step:10014 [D loss: 0.717283, acc.: 50.00%] [G loss: 0.769943]\n",
      "epoch:10 step:10015 [D loss: 0.694194, acc.: 50.00%] [G loss: 0.746934]\n",
      "epoch:10 step:10016 [D loss: 0.660949, acc.: 64.06%] [G loss: 0.746568]\n",
      "epoch:10 step:10017 [D loss: 0.668708, acc.: 57.81%] [G loss: 0.772554]\n",
      "epoch:10 step:10018 [D loss: 0.662659, acc.: 60.16%] [G loss: 0.752176]\n",
      "epoch:10 step:10019 [D loss: 0.681314, acc.: 55.47%] [G loss: 0.771232]\n",
      "epoch:10 step:10020 [D loss: 0.645118, acc.: 64.06%] [G loss: 0.825853]\n",
      "epoch:10 step:10021 [D loss: 0.674610, acc.: 57.03%] [G loss: 0.788016]\n",
      "epoch:10 step:10022 [D loss: 0.727173, acc.: 46.88%] [G loss: 0.753477]\n",
      "epoch:10 step:10023 [D loss: 0.717914, acc.: 42.97%] [G loss: 0.733631]\n",
      "epoch:10 step:10024 [D loss: 0.706391, acc.: 46.88%] [G loss: 0.735203]\n",
      "epoch:10 step:10025 [D loss: 0.701888, acc.: 51.56%] [G loss: 0.704282]\n",
      "epoch:10 step:10026 [D loss: 0.700890, acc.: 50.78%] [G loss: 0.700715]\n",
      "epoch:10 step:10027 [D loss: 0.697482, acc.: 50.00%] [G loss: 0.692302]\n",
      "epoch:10 step:10028 [D loss: 0.699657, acc.: 44.53%] [G loss: 0.759839]\n",
      "epoch:10 step:10029 [D loss: 0.677234, acc.: 51.56%] [G loss: 0.728128]\n",
      "epoch:10 step:10030 [D loss: 0.667649, acc.: 57.03%] [G loss: 0.673792]\n",
      "epoch:10 step:10031 [D loss: 0.679173, acc.: 50.78%] [G loss: 0.748910]\n",
      "epoch:10 step:10032 [D loss: 0.694596, acc.: 53.12%] [G loss: 0.736836]\n",
      "epoch:10 step:10033 [D loss: 0.712832, acc.: 42.97%] [G loss: 0.749573]\n",
      "epoch:10 step:10034 [D loss: 0.701543, acc.: 46.09%] [G loss: 0.739108]\n",
      "epoch:10 step:10035 [D loss: 0.699387, acc.: 44.53%] [G loss: 0.717670]\n",
      "epoch:10 step:10036 [D loss: 0.674879, acc.: 65.62%] [G loss: 0.770476]\n",
      "epoch:10 step:10037 [D loss: 0.684095, acc.: 57.81%] [G loss: 0.781307]\n",
      "epoch:10 step:10038 [D loss: 0.684283, acc.: 60.94%] [G loss: 0.757990]\n",
      "epoch:10 step:10039 [D loss: 0.661114, acc.: 63.28%] [G loss: 0.792803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10040 [D loss: 0.691564, acc.: 53.12%] [G loss: 0.772114]\n",
      "epoch:10 step:10041 [D loss: 0.686589, acc.: 52.34%] [G loss: 0.721044]\n",
      "epoch:10 step:10042 [D loss: 0.684443, acc.: 53.12%] [G loss: 0.750043]\n",
      "epoch:10 step:10043 [D loss: 0.680460, acc.: 57.03%] [G loss: 0.714712]\n",
      "epoch:10 step:10044 [D loss: 0.665069, acc.: 60.16%] [G loss: 0.730905]\n",
      "epoch:10 step:10045 [D loss: 0.729422, acc.: 48.44%] [G loss: 0.742404]\n",
      "epoch:10 step:10046 [D loss: 0.693558, acc.: 57.03%] [G loss: 0.740666]\n",
      "epoch:10 step:10047 [D loss: 0.701805, acc.: 54.69%] [G loss: 0.734418]\n",
      "epoch:10 step:10048 [D loss: 0.697576, acc.: 50.00%] [G loss: 0.721144]\n",
      "epoch:10 step:10049 [D loss: 0.696721, acc.: 47.66%] [G loss: 0.738872]\n",
      "epoch:10 step:10050 [D loss: 0.689436, acc.: 53.12%] [G loss: 0.734928]\n",
      "epoch:10 step:10051 [D loss: 0.695905, acc.: 51.56%] [G loss: 0.706513]\n",
      "epoch:10 step:10052 [D loss: 0.685442, acc.: 50.00%] [G loss: 0.717064]\n",
      "epoch:10 step:10053 [D loss: 0.670352, acc.: 63.28%] [G loss: 0.737751]\n",
      "epoch:10 step:10054 [D loss: 0.670024, acc.: 65.62%] [G loss: 0.760781]\n",
      "epoch:10 step:10055 [D loss: 0.673472, acc.: 57.03%] [G loss: 0.755428]\n",
      "epoch:10 step:10056 [D loss: 0.678192, acc.: 55.47%] [G loss: 0.762719]\n",
      "epoch:10 step:10057 [D loss: 0.692459, acc.: 49.22%] [G loss: 0.795436]\n",
      "epoch:10 step:10058 [D loss: 0.685922, acc.: 60.16%] [G loss: 0.760969]\n",
      "epoch:10 step:10059 [D loss: 0.721463, acc.: 49.22%] [G loss: 0.735171]\n",
      "epoch:10 step:10060 [D loss: 0.721477, acc.: 45.31%] [G loss: 0.733722]\n",
      "epoch:10 step:10061 [D loss: 0.688392, acc.: 47.66%] [G loss: 0.759329]\n",
      "epoch:10 step:10062 [D loss: 0.723102, acc.: 44.53%] [G loss: 0.715495]\n",
      "epoch:10 step:10063 [D loss: 0.676758, acc.: 55.47%] [G loss: 0.770088]\n",
      "epoch:10 step:10064 [D loss: 0.687598, acc.: 53.12%] [G loss: 0.731200]\n",
      "epoch:10 step:10065 [D loss: 0.694082, acc.: 48.44%] [G loss: 0.735380]\n",
      "epoch:10 step:10066 [D loss: 0.692166, acc.: 57.81%] [G loss: 0.731107]\n",
      "epoch:10 step:10067 [D loss: 0.682587, acc.: 57.03%] [G loss: 0.712845]\n",
      "epoch:10 step:10068 [D loss: 0.698630, acc.: 53.12%] [G loss: 0.734057]\n",
      "epoch:10 step:10069 [D loss: 0.684231, acc.: 51.56%] [G loss: 0.750144]\n",
      "epoch:10 step:10070 [D loss: 0.679489, acc.: 52.34%] [G loss: 0.751209]\n",
      "epoch:10 step:10071 [D loss: 0.673407, acc.: 49.22%] [G loss: 0.754320]\n",
      "epoch:10 step:10072 [D loss: 0.684270, acc.: 55.47%] [G loss: 0.758646]\n",
      "epoch:10 step:10073 [D loss: 0.676053, acc.: 51.56%] [G loss: 0.768040]\n",
      "epoch:10 step:10074 [D loss: 0.679997, acc.: 55.47%] [G loss: 0.778673]\n",
      "epoch:10 step:10075 [D loss: 0.666169, acc.: 60.94%] [G loss: 0.745696]\n",
      "epoch:10 step:10076 [D loss: 0.675179, acc.: 64.06%] [G loss: 0.767157]\n",
      "epoch:10 step:10077 [D loss: 0.662890, acc.: 62.50%] [G loss: 0.741696]\n",
      "epoch:10 step:10078 [D loss: 0.657384, acc.: 61.72%] [G loss: 0.734589]\n",
      "epoch:10 step:10079 [D loss: 0.656245, acc.: 64.06%] [G loss: 0.755019]\n",
      "epoch:10 step:10080 [D loss: 0.732379, acc.: 39.06%] [G loss: 0.725272]\n",
      "epoch:10 step:10081 [D loss: 0.685044, acc.: 53.12%] [G loss: 0.722079]\n",
      "epoch:10 step:10082 [D loss: 0.665838, acc.: 59.38%] [G loss: 0.729861]\n",
      "epoch:10 step:10083 [D loss: 0.680325, acc.: 64.06%] [G loss: 0.757240]\n",
      "epoch:10 step:10084 [D loss: 0.686379, acc.: 58.59%] [G loss: 0.750285]\n",
      "epoch:10 step:10085 [D loss: 0.732205, acc.: 43.75%] [G loss: 0.745214]\n",
      "epoch:10 step:10086 [D loss: 0.701709, acc.: 51.56%] [G loss: 0.711831]\n",
      "epoch:10 step:10087 [D loss: 0.732011, acc.: 50.00%] [G loss: 0.694602]\n",
      "epoch:10 step:10088 [D loss: 0.709160, acc.: 44.53%] [G loss: 0.799763]\n",
      "epoch:10 step:10089 [D loss: 0.688087, acc.: 53.91%] [G loss: 0.746697]\n",
      "epoch:10 step:10090 [D loss: 0.689962, acc.: 52.34%] [G loss: 0.758443]\n",
      "epoch:10 step:10091 [D loss: 0.673265, acc.: 60.16%] [G loss: 0.750025]\n",
      "epoch:10 step:10092 [D loss: 0.718493, acc.: 44.53%] [G loss: 0.779333]\n",
      "epoch:10 step:10093 [D loss: 0.702553, acc.: 53.12%] [G loss: 0.726248]\n",
      "epoch:10 step:10094 [D loss: 0.697926, acc.: 47.66%] [G loss: 0.730074]\n",
      "epoch:10 step:10095 [D loss: 0.698421, acc.: 48.44%] [G loss: 0.759343]\n",
      "epoch:10 step:10096 [D loss: 0.695557, acc.: 46.88%] [G loss: 0.745450]\n",
      "epoch:10 step:10097 [D loss: 0.691994, acc.: 53.12%] [G loss: 0.997212]\n",
      "epoch:10 step:10098 [D loss: 0.696457, acc.: 50.00%] [G loss: 0.740977]\n",
      "epoch:10 step:10099 [D loss: 0.691928, acc.: 48.44%] [G loss: 0.762182]\n",
      "epoch:10 step:10100 [D loss: 0.681973, acc.: 53.12%] [G loss: 0.766295]\n",
      "epoch:10 step:10101 [D loss: 0.674667, acc.: 61.72%] [G loss: 0.795496]\n",
      "epoch:10 step:10102 [D loss: 0.655735, acc.: 67.97%] [G loss: 0.778045]\n",
      "epoch:10 step:10103 [D loss: 0.664434, acc.: 61.72%] [G loss: 0.816302]\n",
      "epoch:10 step:10104 [D loss: 0.667911, acc.: 58.59%] [G loss: 0.805699]\n",
      "epoch:10 step:10105 [D loss: 0.672408, acc.: 61.72%] [G loss: 0.786699]\n",
      "epoch:10 step:10106 [D loss: 0.671692, acc.: 62.50%] [G loss: 0.780914]\n",
      "epoch:10 step:10107 [D loss: 0.692199, acc.: 54.69%] [G loss: 0.771036]\n",
      "epoch:10 step:10108 [D loss: 0.710562, acc.: 49.22%] [G loss: 0.743785]\n",
      "epoch:10 step:10109 [D loss: 0.705935, acc.: 46.88%] [G loss: 0.745795]\n",
      "epoch:10 step:10110 [D loss: 0.712170, acc.: 42.19%] [G loss: 0.736083]\n",
      "epoch:10 step:10111 [D loss: 0.696014, acc.: 46.88%] [G loss: 0.748509]\n",
      "epoch:10 step:10112 [D loss: 0.674169, acc.: 57.03%] [G loss: 0.742672]\n",
      "epoch:10 step:10113 [D loss: 0.663629, acc.: 60.16%] [G loss: 0.817595]\n",
      "epoch:10 step:10114 [D loss: 0.692696, acc.: 49.22%] [G loss: 0.765086]\n",
      "epoch:10 step:10115 [D loss: 0.689449, acc.: 50.78%] [G loss: 0.755994]\n",
      "epoch:10 step:10116 [D loss: 0.709561, acc.: 45.31%] [G loss: 0.819161]\n",
      "epoch:10 step:10117 [D loss: 0.693138, acc.: 50.78%] [G loss: 0.754726]\n",
      "epoch:10 step:10118 [D loss: 0.677873, acc.: 57.81%] [G loss: 0.723178]\n",
      "epoch:10 step:10119 [D loss: 0.667251, acc.: 58.59%] [G loss: 0.702777]\n",
      "epoch:10 step:10120 [D loss: 0.650620, acc.: 62.50%] [G loss: 0.762573]\n",
      "epoch:10 step:10121 [D loss: 0.700327, acc.: 53.12%] [G loss: 0.745215]\n",
      "epoch:10 step:10122 [D loss: 0.737106, acc.: 43.75%] [G loss: 0.715258]\n",
      "epoch:10 step:10123 [D loss: 0.705973, acc.: 47.66%] [G loss: 0.728498]\n",
      "epoch:10 step:10124 [D loss: 0.713405, acc.: 46.09%] [G loss: 0.750793]\n",
      "epoch:10 step:10125 [D loss: 0.697211, acc.: 46.88%] [G loss: 0.695879]\n",
      "epoch:10 step:10126 [D loss: 0.692865, acc.: 50.00%] [G loss: 0.723968]\n",
      "epoch:10 step:10127 [D loss: 0.696820, acc.: 49.22%] [G loss: 0.699244]\n",
      "epoch:10 step:10128 [D loss: 0.701948, acc.: 42.97%] [G loss: 0.731971]\n",
      "epoch:10 step:10129 [D loss: 0.679410, acc.: 54.69%] [G loss: 0.732060]\n",
      "epoch:10 step:10130 [D loss: 0.710441, acc.: 46.88%] [G loss: 0.721326]\n",
      "epoch:10 step:10131 [D loss: 0.701377, acc.: 46.88%] [G loss: 0.708204]\n",
      "epoch:10 step:10132 [D loss: 0.676455, acc.: 57.81%] [G loss: 0.727437]\n",
      "epoch:10 step:10133 [D loss: 0.702083, acc.: 46.88%] [G loss: 0.743284]\n",
      "epoch:10 step:10134 [D loss: 0.691740, acc.: 47.66%] [G loss: 0.722064]\n",
      "epoch:10 step:10135 [D loss: 0.684116, acc.: 55.47%] [G loss: 0.743944]\n",
      "epoch:10 step:10136 [D loss: 0.667790, acc.: 61.72%] [G loss: 0.747751]\n",
      "epoch:10 step:10137 [D loss: 0.663712, acc.: 63.28%] [G loss: 0.728441]\n",
      "epoch:10 step:10138 [D loss: 0.669341, acc.: 59.38%] [G loss: 0.731102]\n",
      "epoch:10 step:10139 [D loss: 0.658517, acc.: 61.72%] [G loss: 0.707490]\n",
      "epoch:10 step:10140 [D loss: 0.686392, acc.: 57.81%] [G loss: 0.732905]\n",
      "epoch:10 step:10141 [D loss: 0.682079, acc.: 58.59%] [G loss: 0.724856]\n",
      "epoch:10 step:10142 [D loss: 0.705199, acc.: 45.31%] [G loss: 0.730615]\n",
      "epoch:10 step:10143 [D loss: 0.688974, acc.: 57.81%] [G loss: 0.724694]\n",
      "epoch:10 step:10144 [D loss: 0.714057, acc.: 46.09%] [G loss: 0.726156]\n",
      "epoch:10 step:10145 [D loss: 0.662584, acc.: 59.38%] [G loss: 0.757933]\n",
      "epoch:10 step:10146 [D loss: 0.728095, acc.: 38.28%] [G loss: 0.762947]\n",
      "epoch:10 step:10147 [D loss: 0.694273, acc.: 51.56%] [G loss: 0.756538]\n",
      "epoch:10 step:10148 [D loss: 0.690782, acc.: 50.78%] [G loss: 0.765312]\n",
      "epoch:10 step:10149 [D loss: 0.682268, acc.: 55.47%] [G loss: 0.761863]\n",
      "epoch:10 step:10150 [D loss: 0.686895, acc.: 54.69%] [G loss: 0.787922]\n",
      "epoch:10 step:10151 [D loss: 0.683403, acc.: 48.44%] [G loss: 0.781366]\n",
      "epoch:10 step:10152 [D loss: 0.662644, acc.: 60.94%] [G loss: 0.779260]\n",
      "epoch:10 step:10153 [D loss: 0.694966, acc.: 54.69%] [G loss: 0.750844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10154 [D loss: 0.688613, acc.: 53.12%] [G loss: 0.778716]\n",
      "epoch:10 step:10155 [D loss: 0.699137, acc.: 50.00%] [G loss: 0.765403]\n",
      "epoch:10 step:10156 [D loss: 0.677793, acc.: 54.69%] [G loss: 0.775961]\n",
      "epoch:10 step:10157 [D loss: 0.703059, acc.: 49.22%] [G loss: 0.738770]\n",
      "epoch:10 step:10158 [D loss: 0.683801, acc.: 50.00%] [G loss: 0.719193]\n",
      "epoch:10 step:10159 [D loss: 0.702002, acc.: 50.00%] [G loss: 0.728675]\n",
      "epoch:10 step:10160 [D loss: 0.698320, acc.: 47.66%] [G loss: 0.710221]\n",
      "epoch:10 step:10161 [D loss: 0.692774, acc.: 47.66%] [G loss: 0.728496]\n",
      "epoch:10 step:10162 [D loss: 0.692194, acc.: 54.69%] [G loss: 0.737471]\n",
      "epoch:10 step:10163 [D loss: 0.720752, acc.: 42.97%] [G loss: 0.704774]\n",
      "epoch:10 step:10164 [D loss: 0.691519, acc.: 55.47%] [G loss: 0.723832]\n",
      "epoch:10 step:10165 [D loss: 0.696338, acc.: 51.56%] [G loss: 0.737053]\n",
      "epoch:10 step:10166 [D loss: 0.673257, acc.: 57.03%] [G loss: 0.726949]\n",
      "epoch:10 step:10167 [D loss: 0.696167, acc.: 53.91%] [G loss: 0.733827]\n",
      "epoch:10 step:10168 [D loss: 0.689617, acc.: 56.25%] [G loss: 0.746069]\n",
      "epoch:10 step:10169 [D loss: 0.686679, acc.: 51.56%] [G loss: 0.746603]\n",
      "epoch:10 step:10170 [D loss: 0.702515, acc.: 53.91%] [G loss: 0.742317]\n",
      "epoch:10 step:10171 [D loss: 0.701388, acc.: 46.88%] [G loss: 0.738849]\n",
      "epoch:10 step:10172 [D loss: 0.528018, acc.: 70.31%] [G loss: 0.775881]\n",
      "epoch:10 step:10173 [D loss: 0.686185, acc.: 62.50%] [G loss: 0.738256]\n",
      "epoch:10 step:10174 [D loss: 0.685000, acc.: 57.03%] [G loss: 0.716482]\n",
      "epoch:10 step:10175 [D loss: 0.677199, acc.: 59.38%] [G loss: 0.712132]\n",
      "epoch:10 step:10176 [D loss: 0.687664, acc.: 54.69%] [G loss: 0.703906]\n",
      "epoch:10 step:10177 [D loss: 0.672701, acc.: 55.47%] [G loss: 0.754995]\n",
      "epoch:10 step:10178 [D loss: 0.672337, acc.: 58.59%] [G loss: 0.732799]\n",
      "epoch:10 step:10179 [D loss: 0.676988, acc.: 58.59%] [G loss: 0.747369]\n",
      "epoch:10 step:10180 [D loss: 0.689196, acc.: 57.81%] [G loss: 0.751265]\n",
      "epoch:10 step:10181 [D loss: 0.694788, acc.: 48.44%] [G loss: 0.782866]\n",
      "epoch:10 step:10182 [D loss: 0.691460, acc.: 50.78%] [G loss: 0.724131]\n",
      "epoch:10 step:10183 [D loss: 0.676103, acc.: 56.25%] [G loss: 0.748272]\n",
      "epoch:10 step:10184 [D loss: 0.682907, acc.: 54.69%] [G loss: 0.724114]\n",
      "epoch:10 step:10185 [D loss: 0.649950, acc.: 58.59%] [G loss: 0.724852]\n",
      "epoch:10 step:10186 [D loss: 0.678151, acc.: 56.25%] [G loss: 0.711891]\n",
      "epoch:10 step:10187 [D loss: 0.686609, acc.: 53.91%] [G loss: 0.742346]\n",
      "epoch:10 step:10188 [D loss: 0.696700, acc.: 48.44%] [G loss: 0.746178]\n",
      "epoch:10 step:10189 [D loss: 0.725135, acc.: 42.97%] [G loss: 0.693116]\n",
      "epoch:10 step:10190 [D loss: 0.704640, acc.: 48.44%] [G loss: 0.783858]\n",
      "epoch:10 step:10191 [D loss: 0.687667, acc.: 53.91%] [G loss: 0.796778]\n",
      "epoch:10 step:10192 [D loss: 0.686995, acc.: 52.34%] [G loss: 0.775778]\n",
      "epoch:10 step:10193 [D loss: 0.674341, acc.: 60.16%] [G loss: 0.766046]\n",
      "epoch:10 step:10194 [D loss: 0.705808, acc.: 46.09%] [G loss: 0.761993]\n",
      "epoch:10 step:10195 [D loss: 0.693339, acc.: 51.56%] [G loss: 0.776998]\n",
      "epoch:10 step:10196 [D loss: 0.681270, acc.: 57.03%] [G loss: 0.734335]\n",
      "epoch:10 step:10197 [D loss: 0.706185, acc.: 48.44%] [G loss: 0.777206]\n",
      "epoch:10 step:10198 [D loss: 0.706900, acc.: 42.97%] [G loss: 0.754130]\n",
      "epoch:10 step:10199 [D loss: 0.677020, acc.: 56.25%] [G loss: 0.754212]\n",
      "epoch:10 step:10200 [D loss: 0.690827, acc.: 46.88%] [G loss: 0.752397]\n",
      "epoch:10 step:10201 [D loss: 0.706287, acc.: 44.53%] [G loss: 0.709053]\n",
      "epoch:10 step:10202 [D loss: 0.670957, acc.: 59.38%] [G loss: 0.767181]\n",
      "epoch:10 step:10203 [D loss: 0.677585, acc.: 58.59%] [G loss: 0.761651]\n",
      "epoch:10 step:10204 [D loss: 0.698524, acc.: 46.88%] [G loss: 0.750527]\n",
      "epoch:10 step:10205 [D loss: 0.680142, acc.: 51.56%] [G loss: 0.779324]\n",
      "epoch:10 step:10206 [D loss: 0.704071, acc.: 47.66%] [G loss: 0.737597]\n",
      "epoch:10 step:10207 [D loss: 0.670498, acc.: 57.81%] [G loss: 0.778894]\n",
      "epoch:10 step:10208 [D loss: 0.669389, acc.: 59.38%] [G loss: 0.749727]\n",
      "epoch:10 step:10209 [D loss: 0.686592, acc.: 53.12%] [G loss: 0.719879]\n",
      "epoch:10 step:10210 [D loss: 0.695759, acc.: 48.44%] [G loss: 0.706776]\n",
      "epoch:10 step:10211 [D loss: 0.721865, acc.: 46.09%] [G loss: 0.731622]\n",
      "epoch:10 step:10212 [D loss: 0.700363, acc.: 46.88%] [G loss: 0.711217]\n",
      "epoch:10 step:10213 [D loss: 0.718388, acc.: 42.19%] [G loss: 0.731327]\n",
      "epoch:10 step:10214 [D loss: 0.688939, acc.: 53.12%] [G loss: 0.729113]\n",
      "epoch:10 step:10215 [D loss: 0.637248, acc.: 63.28%] [G loss: 0.744586]\n",
      "epoch:10 step:10216 [D loss: 0.696356, acc.: 55.47%] [G loss: 0.725526]\n",
      "epoch:10 step:10217 [D loss: 0.706972, acc.: 46.88%] [G loss: 0.712973]\n",
      "epoch:10 step:10218 [D loss: 0.719872, acc.: 46.09%] [G loss: 0.706385]\n",
      "epoch:10 step:10219 [D loss: 0.707400, acc.: 49.22%] [G loss: 0.707283]\n",
      "epoch:10 step:10220 [D loss: 0.701191, acc.: 46.88%] [G loss: 0.721011]\n",
      "epoch:10 step:10221 [D loss: 0.672456, acc.: 62.50%] [G loss: 0.746477]\n",
      "epoch:10 step:10222 [D loss: 0.696565, acc.: 52.34%] [G loss: 0.750675]\n",
      "epoch:10 step:10223 [D loss: 0.687615, acc.: 53.91%] [G loss: 0.733234]\n",
      "epoch:10 step:10224 [D loss: 0.684520, acc.: 56.25%] [G loss: 0.725609]\n",
      "epoch:10 step:10225 [D loss: 0.681231, acc.: 62.50%] [G loss: 0.748278]\n",
      "epoch:10 step:10226 [D loss: 0.685732, acc.: 58.59%] [G loss: 0.739195]\n",
      "epoch:10 step:10227 [D loss: 0.681310, acc.: 51.56%] [G loss: 0.759042]\n",
      "epoch:10 step:10228 [D loss: 0.691695, acc.: 53.91%] [G loss: 0.751202]\n",
      "epoch:10 step:10229 [D loss: 0.702279, acc.: 52.34%] [G loss: 0.756046]\n",
      "epoch:10 step:10230 [D loss: 0.692856, acc.: 56.25%] [G loss: 0.720356]\n",
      "epoch:10 step:10231 [D loss: 0.710212, acc.: 45.31%] [G loss: 0.736499]\n",
      "epoch:10 step:10232 [D loss: 0.704058, acc.: 49.22%] [G loss: 0.715924]\n",
      "epoch:10 step:10233 [D loss: 0.694860, acc.: 47.66%] [G loss: 0.700164]\n",
      "epoch:10 step:10234 [D loss: 0.710479, acc.: 43.75%] [G loss: 0.730359]\n",
      "epoch:10 step:10235 [D loss: 0.722522, acc.: 38.28%] [G loss: 0.694401]\n",
      "epoch:10 step:10236 [D loss: 0.697607, acc.: 49.22%] [G loss: 0.687723]\n",
      "epoch:10 step:10237 [D loss: 0.720399, acc.: 42.97%] [G loss: 0.700314]\n",
      "epoch:10 step:10238 [D loss: 0.691419, acc.: 46.09%] [G loss: 0.713719]\n",
      "epoch:10 step:10239 [D loss: 0.691775, acc.: 46.88%] [G loss: 0.717517]\n",
      "epoch:10 step:10240 [D loss: 0.694777, acc.: 51.56%] [G loss: 0.709917]\n",
      "epoch:10 step:10241 [D loss: 0.689484, acc.: 53.91%] [G loss: 0.733905]\n",
      "epoch:10 step:10242 [D loss: 0.705532, acc.: 50.78%] [G loss: 0.715474]\n",
      "epoch:10 step:10243 [D loss: 0.705859, acc.: 46.09%] [G loss: 0.736740]\n",
      "epoch:10 step:10244 [D loss: 0.695538, acc.: 50.00%] [G loss: 0.718945]\n",
      "epoch:10 step:10245 [D loss: 0.685776, acc.: 58.59%] [G loss: 0.725116]\n",
      "epoch:10 step:10246 [D loss: 0.694679, acc.: 50.00%] [G loss: 0.743941]\n",
      "epoch:10 step:10247 [D loss: 0.686659, acc.: 60.16%] [G loss: 0.732986]\n",
      "epoch:10 step:10248 [D loss: 0.680211, acc.: 57.81%] [G loss: 0.722443]\n",
      "epoch:10 step:10249 [D loss: 0.681071, acc.: 62.50%] [G loss: 0.713094]\n",
      "epoch:10 step:10250 [D loss: 0.688939, acc.: 51.56%] [G loss: 0.722378]\n",
      "epoch:10 step:10251 [D loss: 0.684439, acc.: 55.47%] [G loss: 0.704038]\n",
      "epoch:10 step:10252 [D loss: 0.686460, acc.: 53.12%] [G loss: 0.738727]\n",
      "epoch:10 step:10253 [D loss: 0.697713, acc.: 50.78%] [G loss: 0.695451]\n",
      "epoch:10 step:10254 [D loss: 0.688869, acc.: 53.12%] [G loss: 0.736408]\n",
      "epoch:10 step:10255 [D loss: 0.674630, acc.: 65.62%] [G loss: 0.736587]\n",
      "epoch:10 step:10256 [D loss: 0.668098, acc.: 70.31%] [G loss: 0.697300]\n",
      "epoch:10 step:10257 [D loss: 0.691721, acc.: 52.34%] [G loss: 0.724707]\n",
      "epoch:10 step:10258 [D loss: 0.685443, acc.: 53.91%] [G loss: 0.758738]\n",
      "epoch:10 step:10259 [D loss: 0.675969, acc.: 57.81%] [G loss: 0.765821]\n",
      "epoch:10 step:10260 [D loss: 0.664210, acc.: 65.62%] [G loss: 0.767498]\n",
      "epoch:10 step:10261 [D loss: 0.713395, acc.: 49.22%] [G loss: 0.736028]\n",
      "epoch:10 step:10262 [D loss: 0.723752, acc.: 43.75%] [G loss: 0.750119]\n",
      "epoch:10 step:10263 [D loss: 0.709178, acc.: 53.91%] [G loss: 0.707284]\n",
      "epoch:10 step:10264 [D loss: 0.719004, acc.: 40.62%] [G loss: 0.717277]\n",
      "epoch:10 step:10265 [D loss: 0.701788, acc.: 43.75%] [G loss: 0.711451]\n",
      "epoch:10 step:10266 [D loss: 0.700551, acc.: 46.88%] [G loss: 0.721055]\n",
      "epoch:10 step:10267 [D loss: 0.677602, acc.: 60.94%] [G loss: 0.765459]\n",
      "epoch:10 step:10268 [D loss: 0.697461, acc.: 50.00%] [G loss: 0.731160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10269 [D loss: 0.648860, acc.: 63.28%] [G loss: 0.740139]\n",
      "epoch:10 step:10270 [D loss: 0.671543, acc.: 64.06%] [G loss: 0.708808]\n",
      "epoch:10 step:10271 [D loss: 0.677772, acc.: 60.94%] [G loss: 0.690967]\n",
      "epoch:10 step:10272 [D loss: 0.717968, acc.: 43.75%] [G loss: 0.734018]\n",
      "epoch:10 step:10273 [D loss: 0.713327, acc.: 46.09%] [G loss: 0.724043]\n",
      "epoch:10 step:10274 [D loss: 0.705420, acc.: 42.97%] [G loss: 0.712461]\n",
      "epoch:10 step:10275 [D loss: 0.701887, acc.: 48.44%] [G loss: 0.733014]\n",
      "epoch:10 step:10276 [D loss: 0.698203, acc.: 54.69%] [G loss: 0.702038]\n",
      "epoch:10 step:10277 [D loss: 0.702336, acc.: 47.66%] [G loss: 0.724775]\n",
      "epoch:10 step:10278 [D loss: 0.705186, acc.: 49.22%] [G loss: 0.722727]\n",
      "epoch:10 step:10279 [D loss: 0.695875, acc.: 46.09%] [G loss: 0.717080]\n",
      "epoch:10 step:10280 [D loss: 0.689178, acc.: 53.12%] [G loss: 0.709924]\n",
      "epoch:10 step:10281 [D loss: 0.682691, acc.: 57.03%] [G loss: 0.707883]\n",
      "epoch:10 step:10282 [D loss: 0.409642, acc.: 71.88%] [G loss: 0.764955]\n",
      "epoch:10 step:10283 [D loss: 0.692618, acc.: 55.47%] [G loss: 0.738391]\n",
      "epoch:10 step:10284 [D loss: 0.699594, acc.: 47.66%] [G loss: 0.750268]\n",
      "epoch:10 step:10285 [D loss: 0.756566, acc.: 34.38%] [G loss: 0.732762]\n",
      "epoch:10 step:10286 [D loss: 0.701294, acc.: 45.31%] [G loss: 0.752314]\n",
      "epoch:10 step:10287 [D loss: 0.689611, acc.: 57.03%] [G loss: 0.731062]\n",
      "epoch:10 step:10288 [D loss: 0.686081, acc.: 60.16%] [G loss: 0.749345]\n",
      "epoch:10 step:10289 [D loss: 0.670203, acc.: 62.50%] [G loss: 0.756064]\n",
      "epoch:10 step:10290 [D loss: 0.694724, acc.: 53.12%] [G loss: 0.767106]\n",
      "epoch:10 step:10291 [D loss: 0.681071, acc.: 57.03%] [G loss: 0.749041]\n",
      "epoch:10 step:10292 [D loss: 0.684738, acc.: 61.72%] [G loss: 0.746645]\n",
      "epoch:10 step:10293 [D loss: 0.671707, acc.: 60.94%] [G loss: 0.759676]\n",
      "epoch:10 step:10294 [D loss: 0.639126, acc.: 61.72%] [G loss: 0.743257]\n",
      "epoch:10 step:10295 [D loss: 0.626004, acc.: 65.62%] [G loss: 0.732222]\n",
      "epoch:10 step:10296 [D loss: 0.568767, acc.: 64.84%] [G loss: 0.753816]\n",
      "epoch:10 step:10297 [D loss: 0.474109, acc.: 64.84%] [G loss: 0.701132]\n",
      "epoch:10 step:10298 [D loss: 0.722193, acc.: 50.00%] [G loss: 0.724858]\n",
      "epoch:10 step:10299 [D loss: 0.795050, acc.: 37.50%] [G loss: 0.808255]\n",
      "epoch:10 step:10300 [D loss: 0.659831, acc.: 64.84%] [G loss: 0.791362]\n",
      "epoch:10 step:10301 [D loss: 0.679217, acc.: 55.47%] [G loss: 0.764137]\n",
      "epoch:10 step:10302 [D loss: 0.698576, acc.: 53.91%] [G loss: 0.764108]\n",
      "epoch:10 step:10303 [D loss: 0.642465, acc.: 67.97%] [G loss: 0.751515]\n",
      "epoch:10 step:10304 [D loss: 0.668075, acc.: 55.47%] [G loss: 0.652261]\n",
      "epoch:10 step:10305 [D loss: 0.705178, acc.: 53.12%] [G loss: 0.589548]\n",
      "epoch:10 step:10306 [D loss: 1.926584, acc.: 51.56%] [G loss: 0.847615]\n",
      "epoch:10 step:10307 [D loss: 0.579710, acc.: 66.41%] [G loss: 0.952277]\n",
      "epoch:11 step:10308 [D loss: 0.692429, acc.: 56.25%] [G loss: 0.860625]\n",
      "epoch:11 step:10309 [D loss: 0.727124, acc.: 46.88%] [G loss: 0.803880]\n",
      "epoch:11 step:10310 [D loss: 0.672532, acc.: 62.50%] [G loss: 0.832227]\n",
      "epoch:11 step:10311 [D loss: 0.708561, acc.: 47.66%] [G loss: 0.749893]\n",
      "epoch:11 step:10312 [D loss: 0.702559, acc.: 42.19%] [G loss: 0.765050]\n",
      "epoch:11 step:10313 [D loss: 0.728204, acc.: 42.19%] [G loss: 0.733199]\n",
      "epoch:11 step:10314 [D loss: 0.719983, acc.: 43.75%] [G loss: 0.743934]\n",
      "epoch:11 step:10315 [D loss: 0.721908, acc.: 42.19%] [G loss: 0.720533]\n",
      "epoch:11 step:10316 [D loss: 0.707665, acc.: 44.53%] [G loss: 0.721148]\n",
      "epoch:11 step:10317 [D loss: 0.687496, acc.: 54.69%] [G loss: 0.725458]\n",
      "epoch:11 step:10318 [D loss: 0.694142, acc.: 51.56%] [G loss: 0.722995]\n",
      "epoch:11 step:10319 [D loss: 0.687486, acc.: 52.34%] [G loss: 0.730791]\n",
      "epoch:11 step:10320 [D loss: 0.685563, acc.: 53.91%] [G loss: 0.766276]\n",
      "epoch:11 step:10321 [D loss: 0.664999, acc.: 60.16%] [G loss: 0.737998]\n",
      "epoch:11 step:10322 [D loss: 0.648153, acc.: 64.84%] [G loss: 0.752222]\n",
      "epoch:11 step:10323 [D loss: 0.662236, acc.: 69.53%] [G loss: 0.800936]\n",
      "epoch:11 step:10324 [D loss: 0.684802, acc.: 57.81%] [G loss: 0.718642]\n",
      "epoch:11 step:10325 [D loss: 0.686561, acc.: 56.25%] [G loss: 0.707238]\n",
      "epoch:11 step:10326 [D loss: 0.679974, acc.: 58.59%] [G loss: 0.728780]\n",
      "epoch:11 step:10327 [D loss: 0.723929, acc.: 43.75%] [G loss: 0.824230]\n",
      "epoch:11 step:10328 [D loss: 0.698241, acc.: 51.56%] [G loss: 0.719437]\n",
      "epoch:11 step:10329 [D loss: 0.672649, acc.: 59.38%] [G loss: 0.770564]\n",
      "epoch:11 step:10330 [D loss: 0.664910, acc.: 58.59%] [G loss: 0.801719]\n",
      "epoch:11 step:10331 [D loss: 0.654470, acc.: 67.19%] [G loss: 0.871889]\n",
      "epoch:11 step:10332 [D loss: 0.631682, acc.: 65.62%] [G loss: 0.834855]\n",
      "epoch:11 step:10333 [D loss: 0.712246, acc.: 50.00%] [G loss: 0.745062]\n",
      "epoch:11 step:10334 [D loss: 0.729568, acc.: 51.56%] [G loss: 0.769358]\n",
      "epoch:11 step:10335 [D loss: 0.725857, acc.: 46.88%] [G loss: 0.823985]\n",
      "epoch:11 step:10336 [D loss: 0.702076, acc.: 49.22%] [G loss: 0.826355]\n",
      "epoch:11 step:10337 [D loss: 0.671515, acc.: 60.94%] [G loss: 0.699546]\n",
      "epoch:11 step:10338 [D loss: 0.717407, acc.: 46.88%] [G loss: 0.655032]\n",
      "epoch:11 step:10339 [D loss: 0.697110, acc.: 53.12%] [G loss: 0.666863]\n",
      "epoch:11 step:10340 [D loss: 0.719740, acc.: 49.22%] [G loss: 0.688044]\n",
      "epoch:11 step:10341 [D loss: 0.714589, acc.: 46.09%] [G loss: 0.737419]\n",
      "epoch:11 step:10342 [D loss: 0.709022, acc.: 50.78%] [G loss: 0.815162]\n",
      "epoch:11 step:10343 [D loss: 0.705780, acc.: 52.34%] [G loss: 0.660015]\n",
      "epoch:11 step:10344 [D loss: 0.701006, acc.: 47.66%] [G loss: 0.722701]\n",
      "epoch:11 step:10345 [D loss: 0.681295, acc.: 48.44%] [G loss: 0.690400]\n",
      "epoch:11 step:10346 [D loss: 0.706203, acc.: 46.09%] [G loss: 0.706266]\n",
      "epoch:11 step:10347 [D loss: 0.669511, acc.: 54.69%] [G loss: 0.525264]\n",
      "epoch:11 step:10348 [D loss: 0.741987, acc.: 37.50%] [G loss: 0.736281]\n",
      "epoch:11 step:10349 [D loss: 0.688287, acc.: 58.59%] [G loss: 0.697852]\n",
      "epoch:11 step:10350 [D loss: 0.691713, acc.: 53.12%] [G loss: 0.737242]\n",
      "epoch:11 step:10351 [D loss: 0.692437, acc.: 49.22%] [G loss: 0.744932]\n",
      "epoch:11 step:10352 [D loss: 0.686500, acc.: 59.38%] [G loss: 0.728240]\n",
      "epoch:11 step:10353 [D loss: 0.686465, acc.: 53.12%] [G loss: 0.754963]\n",
      "epoch:11 step:10354 [D loss: 0.678690, acc.: 57.03%] [G loss: 0.757665]\n",
      "epoch:11 step:10355 [D loss: 0.670907, acc.: 63.28%] [G loss: 0.776906]\n",
      "epoch:11 step:10356 [D loss: 0.686227, acc.: 53.91%] [G loss: 0.596112]\n",
      "epoch:11 step:10357 [D loss: 0.671301, acc.: 61.72%] [G loss: 0.743393]\n",
      "epoch:11 step:10358 [D loss: 0.695300, acc.: 50.00%] [G loss: 0.758695]\n",
      "epoch:11 step:10359 [D loss: 0.695923, acc.: 53.12%] [G loss: 0.762537]\n",
      "epoch:11 step:10360 [D loss: 0.659486, acc.: 66.41%] [G loss: 0.742391]\n",
      "epoch:11 step:10361 [D loss: 0.678814, acc.: 59.38%] [G loss: 0.753007]\n",
      "epoch:11 step:10362 [D loss: 0.684154, acc.: 53.91%] [G loss: 0.772903]\n",
      "epoch:11 step:10363 [D loss: 0.684280, acc.: 60.16%] [G loss: 0.758685]\n",
      "epoch:11 step:10364 [D loss: 0.671956, acc.: 57.03%] [G loss: 0.740418]\n",
      "epoch:11 step:10365 [D loss: 0.667266, acc.: 62.50%] [G loss: 0.782182]\n",
      "epoch:11 step:10366 [D loss: 0.643233, acc.: 65.62%] [G loss: 0.829350]\n",
      "epoch:11 step:10367 [D loss: 0.661743, acc.: 67.97%] [G loss: 0.630924]\n",
      "epoch:11 step:10368 [D loss: 0.696331, acc.: 52.34%] [G loss: 0.783543]\n",
      "epoch:11 step:10369 [D loss: 0.711634, acc.: 42.19%] [G loss: 0.778047]\n",
      "epoch:11 step:10370 [D loss: 0.714392, acc.: 45.31%] [G loss: 0.769099]\n",
      "epoch:11 step:10371 [D loss: 0.713596, acc.: 44.53%] [G loss: 0.739657]\n",
      "epoch:11 step:10372 [D loss: 0.694910, acc.: 50.00%] [G loss: 0.780812]\n",
      "epoch:11 step:10373 [D loss: 0.704717, acc.: 48.44%] [G loss: 0.750040]\n",
      "epoch:11 step:10374 [D loss: 0.705976, acc.: 50.78%] [G loss: 0.737621]\n",
      "epoch:11 step:10375 [D loss: 0.715915, acc.: 45.31%] [G loss: 0.753290]\n",
      "epoch:11 step:10376 [D loss: 0.691662, acc.: 54.69%] [G loss: 0.736090]\n",
      "epoch:11 step:10377 [D loss: 0.700109, acc.: 54.69%] [G loss: 0.736160]\n",
      "epoch:11 step:10378 [D loss: 0.685495, acc.: 62.50%] [G loss: 0.716033]\n",
      "epoch:11 step:10379 [D loss: 0.679839, acc.: 53.91%] [G loss: 0.728639]\n",
      "epoch:11 step:10380 [D loss: 0.679497, acc.: 57.81%] [G loss: 0.715275]\n",
      "epoch:11 step:10381 [D loss: 0.659972, acc.: 64.06%] [G loss: 0.730648]\n",
      "epoch:11 step:10382 [D loss: 0.677176, acc.: 53.91%] [G loss: 0.728594]\n",
      "epoch:11 step:10383 [D loss: 0.683553, acc.: 53.91%] [G loss: 0.738998]\n",
      "epoch:11 step:10384 [D loss: 0.677817, acc.: 58.59%] [G loss: 0.724585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10385 [D loss: 0.693418, acc.: 53.12%] [G loss: 0.682425]\n",
      "epoch:11 step:10386 [D loss: 0.701712, acc.: 46.88%] [G loss: 0.721625]\n",
      "epoch:11 step:10387 [D loss: 0.706475, acc.: 45.31%] [G loss: 0.704650]\n",
      "epoch:11 step:10388 [D loss: 0.710616, acc.: 50.78%] [G loss: 0.744041]\n",
      "epoch:11 step:10389 [D loss: 0.709363, acc.: 46.88%] [G loss: 0.723838]\n",
      "epoch:11 step:10390 [D loss: 0.692396, acc.: 53.91%] [G loss: 0.732950]\n",
      "epoch:11 step:10391 [D loss: 0.670116, acc.: 57.03%] [G loss: 0.722330]\n",
      "epoch:11 step:10392 [D loss: 0.640550, acc.: 58.59%] [G loss: 0.743046]\n",
      "epoch:11 step:10393 [D loss: 0.708878, acc.: 50.78%] [G loss: 0.724943]\n",
      "epoch:11 step:10394 [D loss: 0.699376, acc.: 53.91%] [G loss: 0.721926]\n",
      "epoch:11 step:10395 [D loss: 0.695888, acc.: 49.22%] [G loss: 0.715732]\n",
      "epoch:11 step:10396 [D loss: 0.651289, acc.: 71.09%] [G loss: 0.751648]\n",
      "epoch:11 step:10397 [D loss: 0.672559, acc.: 59.38%] [G loss: 0.732088]\n",
      "epoch:11 step:10398 [D loss: 0.692048, acc.: 51.56%] [G loss: 0.728921]\n",
      "epoch:11 step:10399 [D loss: 0.678103, acc.: 56.25%] [G loss: 0.755906]\n",
      "epoch:11 step:10400 [D loss: 0.664843, acc.: 59.38%] [G loss: 0.714261]\n",
      "epoch:11 step:10401 [D loss: 0.679957, acc.: 53.91%] [G loss: 0.725853]\n",
      "epoch:11 step:10402 [D loss: 0.691264, acc.: 50.78%] [G loss: 0.703888]\n",
      "epoch:11 step:10403 [D loss: 0.710670, acc.: 45.31%] [G loss: 0.722072]\n",
      "epoch:11 step:10404 [D loss: 0.685987, acc.: 54.69%] [G loss: 0.768788]\n",
      "epoch:11 step:10405 [D loss: 0.682923, acc.: 60.16%] [G loss: 0.763955]\n",
      "epoch:11 step:10406 [D loss: 0.685390, acc.: 53.12%] [G loss: 0.703744]\n",
      "epoch:11 step:10407 [D loss: 0.678323, acc.: 59.38%] [G loss: 0.734375]\n",
      "epoch:11 step:10408 [D loss: 0.707595, acc.: 46.09%] [G loss: 0.757174]\n",
      "epoch:11 step:10409 [D loss: 0.711567, acc.: 49.22%] [G loss: 0.732080]\n",
      "epoch:11 step:10410 [D loss: 0.697569, acc.: 51.56%] [G loss: 0.750032]\n",
      "epoch:11 step:10411 [D loss: 0.690794, acc.: 47.66%] [G loss: 0.788730]\n",
      "epoch:11 step:10412 [D loss: 0.673839, acc.: 60.94%] [G loss: 0.755207]\n",
      "epoch:11 step:10413 [D loss: 0.687182, acc.: 53.12%] [G loss: 0.772175]\n",
      "epoch:11 step:10414 [D loss: 0.669181, acc.: 60.16%] [G loss: 0.785313]\n",
      "epoch:11 step:10415 [D loss: 0.717599, acc.: 41.41%] [G loss: 0.756518]\n",
      "epoch:11 step:10416 [D loss: 0.676138, acc.: 53.12%] [G loss: 0.763996]\n",
      "epoch:11 step:10417 [D loss: 0.703585, acc.: 56.25%] [G loss: 0.782161]\n",
      "epoch:11 step:10418 [D loss: 0.683196, acc.: 60.16%] [G loss: 0.796508]\n",
      "epoch:11 step:10419 [D loss: 0.672402, acc.: 59.38%] [G loss: 0.753078]\n",
      "epoch:11 step:10420 [D loss: 0.682614, acc.: 54.69%] [G loss: 0.741036]\n",
      "epoch:11 step:10421 [D loss: 0.682889, acc.: 55.47%] [G loss: 0.717138]\n",
      "epoch:11 step:10422 [D loss: 0.681247, acc.: 50.78%] [G loss: 0.721140]\n",
      "epoch:11 step:10423 [D loss: 0.683068, acc.: 59.38%] [G loss: 0.717539]\n",
      "epoch:11 step:10424 [D loss: 0.722694, acc.: 42.97%] [G loss: 0.669435]\n",
      "epoch:11 step:10425 [D loss: 0.711757, acc.: 43.75%] [G loss: 0.737467]\n",
      "epoch:11 step:10426 [D loss: 0.693229, acc.: 57.03%] [G loss: 0.757173]\n",
      "epoch:11 step:10427 [D loss: 0.702666, acc.: 48.44%] [G loss: 0.756800]\n",
      "epoch:11 step:10428 [D loss: 0.701111, acc.: 51.56%] [G loss: 0.775101]\n",
      "epoch:11 step:10429 [D loss: 0.700045, acc.: 49.22%] [G loss: 0.783958]\n",
      "epoch:11 step:10430 [D loss: 0.691301, acc.: 58.59%] [G loss: 0.816550]\n",
      "epoch:11 step:10431 [D loss: 0.671016, acc.: 55.47%] [G loss: 0.872022]\n",
      "epoch:11 step:10432 [D loss: 0.689978, acc.: 50.78%] [G loss: 0.795557]\n",
      "epoch:11 step:10433 [D loss: 0.673990, acc.: 59.38%] [G loss: 0.792277]\n",
      "epoch:11 step:10434 [D loss: 0.688838, acc.: 49.22%] [G loss: 0.816762]\n",
      "epoch:11 step:10435 [D loss: 0.711613, acc.: 42.19%] [G loss: 0.755265]\n",
      "epoch:11 step:10436 [D loss: 0.711451, acc.: 42.97%] [G loss: 0.750152]\n",
      "epoch:11 step:10437 [D loss: 0.693932, acc.: 51.56%] [G loss: 0.756059]\n",
      "epoch:11 step:10438 [D loss: 0.702010, acc.: 46.88%] [G loss: 0.733707]\n",
      "epoch:11 step:10439 [D loss: 0.700481, acc.: 49.22%] [G loss: 0.696201]\n",
      "epoch:11 step:10440 [D loss: 0.705304, acc.: 53.12%] [G loss: 0.714923]\n",
      "epoch:11 step:10441 [D loss: 0.692879, acc.: 52.34%] [G loss: 0.679473]\n",
      "epoch:11 step:10442 [D loss: 0.694743, acc.: 51.56%] [G loss: 0.722519]\n",
      "epoch:11 step:10443 [D loss: 0.681294, acc.: 59.38%] [G loss: 0.719534]\n",
      "epoch:11 step:10444 [D loss: 0.694985, acc.: 53.91%] [G loss: 0.712605]\n",
      "epoch:11 step:10445 [D loss: 0.687311, acc.: 54.69%] [G loss: 0.751788]\n",
      "epoch:11 step:10446 [D loss: 0.645281, acc.: 66.41%] [G loss: 0.738633]\n",
      "epoch:11 step:10447 [D loss: 0.681127, acc.: 61.72%] [G loss: 0.753885]\n",
      "epoch:11 step:10448 [D loss: 0.699199, acc.: 52.34%] [G loss: 0.755576]\n",
      "epoch:11 step:10449 [D loss: 0.675165, acc.: 58.59%] [G loss: 0.722023]\n",
      "epoch:11 step:10450 [D loss: 0.655448, acc.: 70.31%] [G loss: 0.794795]\n",
      "epoch:11 step:10451 [D loss: 0.653382, acc.: 65.62%] [G loss: 0.738453]\n",
      "epoch:11 step:10452 [D loss: 0.640387, acc.: 67.19%] [G loss: 0.713614]\n",
      "epoch:11 step:10453 [D loss: 0.647727, acc.: 64.06%] [G loss: 0.718103]\n",
      "epoch:11 step:10454 [D loss: 0.665757, acc.: 60.16%] [G loss: 0.741627]\n",
      "epoch:11 step:10455 [D loss: 0.701395, acc.: 52.34%] [G loss: 0.684234]\n",
      "epoch:11 step:10456 [D loss: 0.670011, acc.: 59.38%] [G loss: 0.797765]\n",
      "epoch:11 step:10457 [D loss: 0.680958, acc.: 52.34%] [G loss: 0.652731]\n",
      "epoch:11 step:10458 [D loss: 0.671981, acc.: 57.81%] [G loss: 0.812401]\n",
      "epoch:11 step:10459 [D loss: 0.675840, acc.: 60.16%] [G loss: 0.781783]\n",
      "epoch:11 step:10460 [D loss: 0.983622, acc.: 26.56%] [G loss: 0.797583]\n",
      "epoch:11 step:10461 [D loss: 0.713757, acc.: 51.56%] [G loss: 0.797552]\n",
      "epoch:11 step:10462 [D loss: 0.676758, acc.: 55.47%] [G loss: 0.886811]\n",
      "epoch:11 step:10463 [D loss: 0.716915, acc.: 46.88%] [G loss: 0.832414]\n",
      "epoch:11 step:10464 [D loss: 0.706574, acc.: 53.12%] [G loss: 0.853861]\n",
      "epoch:11 step:10465 [D loss: 0.678615, acc.: 60.16%] [G loss: 0.793193]\n",
      "epoch:11 step:10466 [D loss: 0.717073, acc.: 40.62%] [G loss: 0.782701]\n",
      "epoch:11 step:10467 [D loss: 0.695136, acc.: 57.03%] [G loss: 0.803640]\n",
      "epoch:11 step:10468 [D loss: 0.687145, acc.: 49.22%] [G loss: 0.766722]\n",
      "epoch:11 step:10469 [D loss: 0.697956, acc.: 49.22%] [G loss: 0.807011]\n",
      "epoch:11 step:10470 [D loss: 0.698252, acc.: 53.12%] [G loss: 0.748862]\n",
      "epoch:11 step:10471 [D loss: 0.690983, acc.: 50.00%] [G loss: 0.762277]\n",
      "epoch:11 step:10472 [D loss: 0.686804, acc.: 48.44%] [G loss: 0.753651]\n",
      "epoch:11 step:10473 [D loss: 0.684415, acc.: 52.34%] [G loss: 0.749542]\n",
      "epoch:11 step:10474 [D loss: 0.706091, acc.: 49.22%] [G loss: 0.704255]\n",
      "epoch:11 step:10475 [D loss: 0.686669, acc.: 47.66%] [G loss: 0.768835]\n",
      "epoch:11 step:10476 [D loss: 0.703809, acc.: 52.34%] [G loss: 0.715208]\n",
      "epoch:11 step:10477 [D loss: 0.706633, acc.: 52.34%] [G loss: 0.717127]\n",
      "epoch:11 step:10478 [D loss: 0.697073, acc.: 53.12%] [G loss: 0.729441]\n",
      "epoch:11 step:10479 [D loss: 0.687709, acc.: 53.91%] [G loss: 0.726634]\n",
      "epoch:11 step:10480 [D loss: 0.695432, acc.: 46.09%] [G loss: 0.713128]\n",
      "epoch:11 step:10481 [D loss: 0.705876, acc.: 43.75%] [G loss: 0.706282]\n",
      "epoch:11 step:10482 [D loss: 0.695599, acc.: 50.78%] [G loss: 0.745889]\n",
      "epoch:11 step:10483 [D loss: 0.693630, acc.: 48.44%] [G loss: 1.232560]\n",
      "epoch:11 step:10484 [D loss: 0.705137, acc.: 43.75%] [G loss: 0.734050]\n",
      "epoch:11 step:10485 [D loss: 0.682740, acc.: 50.78%] [G loss: 0.746933]\n",
      "epoch:11 step:10486 [D loss: 0.682827, acc.: 50.00%] [G loss: 0.728068]\n",
      "epoch:11 step:10487 [D loss: 0.676441, acc.: 53.12%] [G loss: 0.737935]\n",
      "epoch:11 step:10488 [D loss: 0.712667, acc.: 45.31%] [G loss: 0.722997]\n",
      "epoch:11 step:10489 [D loss: 0.693452, acc.: 53.91%] [G loss: 0.734305]\n",
      "epoch:11 step:10490 [D loss: 0.688683, acc.: 53.12%] [G loss: 0.726841]\n",
      "epoch:11 step:10491 [D loss: 0.691739, acc.: 53.91%] [G loss: 0.737182]\n",
      "epoch:11 step:10492 [D loss: 0.698150, acc.: 46.09%] [G loss: 0.721549]\n",
      "epoch:11 step:10493 [D loss: 0.694767, acc.: 50.78%] [G loss: 0.700143]\n",
      "epoch:11 step:10494 [D loss: 0.663355, acc.: 59.38%] [G loss: 0.688202]\n",
      "epoch:11 step:10495 [D loss: 0.704754, acc.: 48.44%] [G loss: 0.701901]\n",
      "epoch:11 step:10496 [D loss: 0.702582, acc.: 43.75%] [G loss: 0.680971]\n",
      "epoch:11 step:10497 [D loss: 0.679013, acc.: 57.03%] [G loss: 0.699074]\n",
      "epoch:11 step:10498 [D loss: 0.688494, acc.: 54.69%] [G loss: 0.730399]\n",
      "epoch:11 step:10499 [D loss: 0.688473, acc.: 56.25%] [G loss: 0.701124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10500 [D loss: 0.690833, acc.: 57.81%] [G loss: 0.725934]\n",
      "epoch:11 step:10501 [D loss: 0.698730, acc.: 55.47%] [G loss: 0.753323]\n",
      "epoch:11 step:10502 [D loss: 0.677611, acc.: 60.16%] [G loss: 0.751254]\n",
      "epoch:11 step:10503 [D loss: 0.676713, acc.: 61.72%] [G loss: 0.750490]\n",
      "epoch:11 step:10504 [D loss: 0.666275, acc.: 60.94%] [G loss: 0.782882]\n",
      "epoch:11 step:10505 [D loss: 0.667534, acc.: 64.06%] [G loss: 0.766151]\n",
      "epoch:11 step:10506 [D loss: 0.687815, acc.: 57.03%] [G loss: 0.769014]\n",
      "epoch:11 step:10507 [D loss: 0.692534, acc.: 52.34%] [G loss: 0.769763]\n",
      "epoch:11 step:10508 [D loss: 0.695053, acc.: 56.25%] [G loss: 0.770621]\n",
      "epoch:11 step:10509 [D loss: 0.681322, acc.: 54.69%] [G loss: 0.743592]\n",
      "epoch:11 step:10510 [D loss: 0.675880, acc.: 53.12%] [G loss: 0.791970]\n",
      "epoch:11 step:10511 [D loss: 0.642669, acc.: 60.94%] [G loss: 0.755752]\n",
      "epoch:11 step:10512 [D loss: 0.682752, acc.: 57.03%] [G loss: 0.737621]\n",
      "epoch:11 step:10513 [D loss: 0.658226, acc.: 60.94%] [G loss: 0.770431]\n",
      "epoch:11 step:10514 [D loss: 0.529829, acc.: 64.84%] [G loss: 0.766445]\n",
      "epoch:11 step:10515 [D loss: 0.690962, acc.: 57.03%] [G loss: 0.766517]\n",
      "epoch:11 step:10516 [D loss: 0.667590, acc.: 63.28%] [G loss: 0.380009]\n",
      "epoch:11 step:10517 [D loss: 0.703425, acc.: 47.66%] [G loss: 0.744210]\n",
      "epoch:11 step:10518 [D loss: 0.695558, acc.: 49.22%] [G loss: 0.743227]\n",
      "epoch:11 step:10519 [D loss: 0.701169, acc.: 48.44%] [G loss: 0.723615]\n",
      "epoch:11 step:10520 [D loss: 0.699424, acc.: 49.22%] [G loss: 0.670474]\n",
      "epoch:11 step:10521 [D loss: 0.703547, acc.: 48.44%] [G loss: 0.731187]\n",
      "epoch:11 step:10522 [D loss: 0.732010, acc.: 43.75%] [G loss: 0.706712]\n",
      "epoch:11 step:10523 [D loss: 0.631612, acc.: 57.03%] [G loss: 0.775973]\n",
      "epoch:11 step:10524 [D loss: 0.674946, acc.: 60.94%] [G loss: 0.805979]\n",
      "epoch:11 step:10525 [D loss: 0.664900, acc.: 57.03%] [G loss: 0.692099]\n",
      "epoch:11 step:10526 [D loss: 0.670951, acc.: 60.16%] [G loss: 0.790175]\n",
      "epoch:11 step:10527 [D loss: 0.763505, acc.: 35.94%] [G loss: 0.684927]\n",
      "epoch:11 step:10528 [D loss: 0.688359, acc.: 55.47%] [G loss: 0.750689]\n",
      "epoch:11 step:10529 [D loss: 0.742832, acc.: 42.97%] [G loss: 0.799359]\n",
      "epoch:11 step:10530 [D loss: 0.682022, acc.: 55.47%] [G loss: 0.844490]\n",
      "epoch:11 step:10531 [D loss: 0.686956, acc.: 53.91%] [G loss: 0.884367]\n",
      "epoch:11 step:10532 [D loss: 0.711348, acc.: 47.66%] [G loss: 0.931199]\n",
      "epoch:11 step:10533 [D loss: 0.685840, acc.: 47.66%] [G loss: 0.839370]\n",
      "epoch:11 step:10534 [D loss: 0.677614, acc.: 53.12%] [G loss: 0.847875]\n",
      "epoch:11 step:10535 [D loss: 0.706572, acc.: 50.00%] [G loss: 0.818985]\n",
      "epoch:11 step:10536 [D loss: 0.659632, acc.: 65.62%] [G loss: 0.858336]\n",
      "epoch:11 step:10537 [D loss: 0.632617, acc.: 68.75%] [G loss: 0.817170]\n",
      "epoch:11 step:10538 [D loss: 0.618057, acc.: 70.31%] [G loss: 0.811755]\n",
      "epoch:11 step:10539 [D loss: 0.622078, acc.: 67.97%] [G loss: 0.832426]\n",
      "epoch:11 step:10540 [D loss: 0.678766, acc.: 50.00%] [G loss: 0.802047]\n",
      "epoch:11 step:10541 [D loss: 0.706016, acc.: 49.22%] [G loss: 0.792135]\n",
      "epoch:11 step:10542 [D loss: 0.687668, acc.: 58.59%] [G loss: 0.816599]\n",
      "epoch:11 step:10543 [D loss: 0.708055, acc.: 50.00%] [G loss: 0.756505]\n",
      "epoch:11 step:10544 [D loss: 0.702817, acc.: 48.44%] [G loss: 0.809701]\n",
      "epoch:11 step:10545 [D loss: 0.714616, acc.: 47.66%] [G loss: 0.756542]\n",
      "epoch:11 step:10546 [D loss: 0.721452, acc.: 45.31%] [G loss: 0.770023]\n",
      "epoch:11 step:10547 [D loss: 0.701671, acc.: 45.31%] [G loss: 0.782501]\n",
      "epoch:11 step:10548 [D loss: 0.681047, acc.: 50.78%] [G loss: 0.753214]\n",
      "epoch:11 step:10549 [D loss: 0.695549, acc.: 54.69%] [G loss: 0.753653]\n",
      "epoch:11 step:10550 [D loss: 0.664515, acc.: 60.94%] [G loss: 0.763842]\n",
      "epoch:11 step:10551 [D loss: 0.672650, acc.: 56.25%] [G loss: 0.778483]\n",
      "epoch:11 step:10552 [D loss: 0.694304, acc.: 53.12%] [G loss: 0.790862]\n",
      "epoch:11 step:10553 [D loss: 0.666056, acc.: 63.28%] [G loss: 0.777561]\n",
      "epoch:11 step:10554 [D loss: 0.659764, acc.: 64.06%] [G loss: 0.761597]\n",
      "epoch:11 step:10555 [D loss: 0.650926, acc.: 64.06%] [G loss: 0.794356]\n",
      "epoch:11 step:10556 [D loss: 0.704770, acc.: 48.44%] [G loss: 0.771854]\n",
      "epoch:11 step:10557 [D loss: 0.689378, acc.: 50.78%] [G loss: 0.752407]\n",
      "epoch:11 step:10558 [D loss: 0.727317, acc.: 43.75%] [G loss: 0.743494]\n",
      "epoch:11 step:10559 [D loss: 0.708734, acc.: 49.22%] [G loss: 0.710669]\n",
      "epoch:11 step:10560 [D loss: 0.727373, acc.: 42.97%] [G loss: 0.741234]\n",
      "epoch:11 step:10561 [D loss: 0.705859, acc.: 44.53%] [G loss: 0.757757]\n",
      "epoch:11 step:10562 [D loss: 0.686712, acc.: 56.25%] [G loss: 0.741914]\n",
      "epoch:11 step:10563 [D loss: 0.700472, acc.: 46.09%] [G loss: 0.759539]\n",
      "epoch:11 step:10564 [D loss: 0.689711, acc.: 56.25%] [G loss: 0.754292]\n",
      "epoch:11 step:10565 [D loss: 0.684829, acc.: 54.69%] [G loss: 0.754343]\n",
      "epoch:11 step:10566 [D loss: 0.677250, acc.: 59.38%] [G loss: 0.740611]\n",
      "epoch:11 step:10567 [D loss: 0.710220, acc.: 46.09%] [G loss: 0.724282]\n",
      "epoch:11 step:10568 [D loss: 0.699769, acc.: 52.34%] [G loss: 0.715448]\n",
      "epoch:11 step:10569 [D loss: 0.672633, acc.: 62.50%] [G loss: 0.760363]\n",
      "epoch:11 step:10570 [D loss: 0.593556, acc.: 64.84%] [G loss: 0.734799]\n",
      "epoch:11 step:10571 [D loss: 0.687450, acc.: 57.81%] [G loss: 0.756976]\n",
      "epoch:11 step:10572 [D loss: 0.731201, acc.: 45.31%] [G loss: 0.717187]\n",
      "epoch:11 step:10573 [D loss: 0.697137, acc.: 50.00%] [G loss: 0.730612]\n",
      "epoch:11 step:10574 [D loss: 0.676481, acc.: 53.91%] [G loss: 0.748161]\n",
      "epoch:11 step:10575 [D loss: 0.680350, acc.: 57.81%] [G loss: 0.773739]\n",
      "epoch:11 step:10576 [D loss: 0.695612, acc.: 44.53%] [G loss: 0.705611]\n",
      "epoch:11 step:10577 [D loss: 0.707561, acc.: 51.56%] [G loss: 0.751413]\n",
      "epoch:11 step:10578 [D loss: 0.673656, acc.: 58.59%] [G loss: 0.733516]\n",
      "epoch:11 step:10579 [D loss: 0.700828, acc.: 52.34%] [G loss: 0.748082]\n",
      "epoch:11 step:10580 [D loss: 0.696229, acc.: 54.69%] [G loss: 0.758910]\n",
      "epoch:11 step:10581 [D loss: 0.671502, acc.: 61.72%] [G loss: 0.769015]\n",
      "epoch:11 step:10582 [D loss: 0.699769, acc.: 51.56%] [G loss: 0.756359]\n",
      "epoch:11 step:10583 [D loss: 0.640934, acc.: 65.62%] [G loss: 0.743096]\n",
      "epoch:11 step:10584 [D loss: 0.671173, acc.: 59.38%] [G loss: 0.755353]\n",
      "epoch:11 step:10585 [D loss: 0.691363, acc.: 47.66%] [G loss: 0.807808]\n",
      "epoch:11 step:10586 [D loss: 0.695468, acc.: 48.44%] [G loss: 0.816264]\n",
      "epoch:11 step:10587 [D loss: 0.680541, acc.: 58.59%] [G loss: 0.773589]\n",
      "epoch:11 step:10588 [D loss: 0.711478, acc.: 46.09%] [G loss: 0.770050]\n",
      "epoch:11 step:10589 [D loss: 0.700929, acc.: 55.47%] [G loss: 0.736855]\n",
      "epoch:11 step:10590 [D loss: 0.717008, acc.: 48.44%] [G loss: 0.562641]\n",
      "epoch:11 step:10591 [D loss: 0.639213, acc.: 68.75%] [G loss: 0.786444]\n",
      "epoch:11 step:10592 [D loss: 0.645831, acc.: 66.41%] [G loss: 0.800040]\n",
      "epoch:11 step:10593 [D loss: 0.666568, acc.: 62.50%] [G loss: 0.849961]\n",
      "epoch:11 step:10594 [D loss: 0.675037, acc.: 57.03%] [G loss: 0.817682]\n",
      "epoch:11 step:10595 [D loss: 0.676076, acc.: 58.59%] [G loss: 0.762018]\n",
      "epoch:11 step:10596 [D loss: 0.670918, acc.: 64.84%] [G loss: 0.793103]\n",
      "epoch:11 step:10597 [D loss: 0.679938, acc.: 59.38%] [G loss: 0.826311]\n",
      "epoch:11 step:10598 [D loss: 0.713794, acc.: 46.88%] [G loss: 0.736827]\n",
      "epoch:11 step:10599 [D loss: 0.684475, acc.: 53.12%] [G loss: 0.729556]\n",
      "epoch:11 step:10600 [D loss: 0.686009, acc.: 51.56%] [G loss: 0.716760]\n",
      "epoch:11 step:10601 [D loss: 0.698372, acc.: 50.78%] [G loss: 0.746035]\n",
      "epoch:11 step:10602 [D loss: 0.714253, acc.: 43.75%] [G loss: 0.720666]\n",
      "epoch:11 step:10603 [D loss: 0.709847, acc.: 47.66%] [G loss: 0.735551]\n",
      "epoch:11 step:10604 [D loss: 0.726930, acc.: 35.16%] [G loss: 0.740532]\n",
      "epoch:11 step:10605 [D loss: 0.707242, acc.: 41.41%] [G loss: 0.779750]\n",
      "epoch:11 step:10606 [D loss: 0.686678, acc.: 54.69%] [G loss: 0.811874]\n",
      "epoch:11 step:10607 [D loss: 0.692264, acc.: 45.31%] [G loss: 0.758999]\n",
      "epoch:11 step:10608 [D loss: 0.689968, acc.: 60.94%] [G loss: 0.771138]\n",
      "epoch:11 step:10609 [D loss: 0.672855, acc.: 59.38%] [G loss: 0.741894]\n",
      "epoch:11 step:10610 [D loss: 0.692770, acc.: 56.25%] [G loss: 0.730543]\n",
      "epoch:11 step:10611 [D loss: 0.698703, acc.: 51.56%] [G loss: 0.727608]\n",
      "epoch:11 step:10612 [D loss: 0.684510, acc.: 57.81%] [G loss: 0.726628]\n",
      "epoch:11 step:10613 [D loss: 0.697623, acc.: 50.78%] [G loss: 0.743866]\n",
      "epoch:11 step:10614 [D loss: 0.689078, acc.: 58.59%] [G loss: 0.737038]\n",
      "epoch:11 step:10615 [D loss: 0.703892, acc.: 49.22%] [G loss: 0.751370]\n",
      "epoch:11 step:10616 [D loss: 0.680991, acc.: 54.69%] [G loss: 0.732322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10617 [D loss: 0.687087, acc.: 48.44%] [G loss: 0.718182]\n",
      "epoch:11 step:10618 [D loss: 0.687575, acc.: 55.47%] [G loss: 0.712095]\n",
      "epoch:11 step:10619 [D loss: 0.679846, acc.: 64.84%] [G loss: 0.719048]\n",
      "epoch:11 step:10620 [D loss: 0.672135, acc.: 57.81%] [G loss: 0.723738]\n",
      "epoch:11 step:10621 [D loss: 0.657877, acc.: 57.03%] [G loss: 0.727167]\n",
      "epoch:11 step:10622 [D loss: 0.679752, acc.: 60.94%] [G loss: 0.738508]\n",
      "epoch:11 step:10623 [D loss: 0.699300, acc.: 51.56%] [G loss: 0.725447]\n",
      "epoch:11 step:10624 [D loss: 0.708174, acc.: 48.44%] [G loss: 0.735328]\n",
      "epoch:11 step:10625 [D loss: 0.684174, acc.: 56.25%] [G loss: 0.716783]\n",
      "epoch:11 step:10626 [D loss: 0.703455, acc.: 55.47%] [G loss: 0.703936]\n",
      "epoch:11 step:10627 [D loss: 0.700014, acc.: 46.09%] [G loss: 0.719740]\n",
      "epoch:11 step:10628 [D loss: 0.693018, acc.: 50.00%] [G loss: 0.755585]\n",
      "epoch:11 step:10629 [D loss: 0.676504, acc.: 58.59%] [G loss: 0.754058]\n",
      "epoch:11 step:10630 [D loss: 0.692951, acc.: 50.00%] [G loss: 0.740653]\n",
      "epoch:11 step:10631 [D loss: 0.685020, acc.: 50.00%] [G loss: 0.717440]\n",
      "epoch:11 step:10632 [D loss: 0.681763, acc.: 51.56%] [G loss: 0.731076]\n",
      "epoch:11 step:10633 [D loss: 0.694134, acc.: 55.47%] [G loss: 0.692176]\n",
      "epoch:11 step:10634 [D loss: 0.688133, acc.: 61.72%] [G loss: 0.757240]\n",
      "epoch:11 step:10635 [D loss: 0.667713, acc.: 63.28%] [G loss: 0.790449]\n",
      "epoch:11 step:10636 [D loss: 0.692068, acc.: 53.91%] [G loss: 0.645518]\n",
      "epoch:11 step:10637 [D loss: 0.702128, acc.: 47.66%] [G loss: 0.701558]\n",
      "epoch:11 step:10638 [D loss: 0.679483, acc.: 53.91%] [G loss: 0.737037]\n",
      "epoch:11 step:10639 [D loss: 0.726407, acc.: 48.44%] [G loss: 0.723633]\n",
      "epoch:11 step:10640 [D loss: 0.691706, acc.: 53.91%] [G loss: 0.715742]\n",
      "epoch:11 step:10641 [D loss: 0.707143, acc.: 50.78%] [G loss: 0.701062]\n",
      "epoch:11 step:10642 [D loss: 0.686454, acc.: 53.91%] [G loss: 0.722885]\n",
      "epoch:11 step:10643 [D loss: 0.681481, acc.: 64.06%] [G loss: 0.743032]\n",
      "epoch:11 step:10644 [D loss: 0.689758, acc.: 49.22%] [G loss: 0.761769]\n",
      "epoch:11 step:10645 [D loss: 0.686990, acc.: 59.38%] [G loss: 0.752523]\n",
      "epoch:11 step:10646 [D loss: 0.688529, acc.: 56.25%] [G loss: 0.726524]\n",
      "epoch:11 step:10647 [D loss: 0.684595, acc.: 59.38%] [G loss: 0.729458]\n",
      "epoch:11 step:10648 [D loss: 0.701445, acc.: 50.78%] [G loss: 0.726578]\n",
      "epoch:11 step:10649 [D loss: 0.700595, acc.: 53.12%] [G loss: 0.729278]\n",
      "epoch:11 step:10650 [D loss: 0.670309, acc.: 58.59%] [G loss: 0.743181]\n",
      "epoch:11 step:10651 [D loss: 0.674145, acc.: 60.16%] [G loss: 0.771386]\n",
      "epoch:11 step:10652 [D loss: 0.690080, acc.: 53.91%] [G loss: 0.704386]\n",
      "epoch:11 step:10653 [D loss: 0.697031, acc.: 50.00%] [G loss: 0.723790]\n",
      "epoch:11 step:10654 [D loss: 0.659403, acc.: 63.28%] [G loss: 0.703968]\n",
      "epoch:11 step:10655 [D loss: 0.697559, acc.: 50.00%] [G loss: 0.718720]\n",
      "epoch:11 step:10656 [D loss: 0.719270, acc.: 43.75%] [G loss: 0.736607]\n",
      "epoch:11 step:10657 [D loss: 0.710690, acc.: 46.88%] [G loss: 0.701749]\n",
      "epoch:11 step:10658 [D loss: 0.710111, acc.: 46.88%] [G loss: 0.775809]\n",
      "epoch:11 step:10659 [D loss: 0.704451, acc.: 46.09%] [G loss: 0.731567]\n",
      "epoch:11 step:10660 [D loss: 0.707341, acc.: 48.44%] [G loss: 0.756512]\n",
      "epoch:11 step:10661 [D loss: 0.690764, acc.: 50.00%] [G loss: 0.755460]\n",
      "epoch:11 step:10662 [D loss: 0.699227, acc.: 50.00%] [G loss: 0.765462]\n",
      "epoch:11 step:10663 [D loss: 0.679540, acc.: 53.91%] [G loss: 0.749330]\n",
      "epoch:11 step:10664 [D loss: 0.685415, acc.: 52.34%] [G loss: 0.749483]\n",
      "epoch:11 step:10665 [D loss: 0.680611, acc.: 55.47%] [G loss: 0.746452]\n",
      "epoch:11 step:10666 [D loss: 0.679391, acc.: 64.84%] [G loss: 0.747815]\n",
      "epoch:11 step:10667 [D loss: 0.670613, acc.: 53.91%] [G loss: 0.741694]\n",
      "epoch:11 step:10668 [D loss: 0.684873, acc.: 53.91%] [G loss: 0.750068]\n",
      "epoch:11 step:10669 [D loss: 0.688321, acc.: 55.47%] [G loss: 0.779478]\n",
      "epoch:11 step:10670 [D loss: 0.671935, acc.: 58.59%] [G loss: 0.757142]\n",
      "epoch:11 step:10671 [D loss: 0.662132, acc.: 55.47%] [G loss: 0.727400]\n",
      "epoch:11 step:10672 [D loss: 0.708370, acc.: 47.66%] [G loss: 0.718199]\n",
      "epoch:11 step:10673 [D loss: 0.684154, acc.: 54.69%] [G loss: 0.746434]\n",
      "epoch:11 step:10674 [D loss: 0.684001, acc.: 57.81%] [G loss: 0.746357]\n",
      "epoch:11 step:10675 [D loss: 0.695726, acc.: 52.34%] [G loss: 0.727110]\n",
      "epoch:11 step:10676 [D loss: 0.704678, acc.: 46.88%] [G loss: 0.747252]\n",
      "epoch:11 step:10677 [D loss: 0.688068, acc.: 59.38%] [G loss: 0.726409]\n",
      "epoch:11 step:10678 [D loss: 0.641517, acc.: 56.25%] [G loss: 0.757338]\n",
      "epoch:11 step:10679 [D loss: 0.676096, acc.: 54.69%] [G loss: 0.639488]\n",
      "epoch:11 step:10680 [D loss: 0.733930, acc.: 42.19%] [G loss: 0.709373]\n",
      "epoch:11 step:10681 [D loss: 0.707392, acc.: 46.88%] [G loss: 0.739687]\n",
      "epoch:11 step:10682 [D loss: 0.699944, acc.: 50.78%] [G loss: 0.718543]\n",
      "epoch:11 step:10683 [D loss: 0.681220, acc.: 49.22%] [G loss: 0.739262]\n",
      "epoch:11 step:10684 [D loss: 0.720292, acc.: 45.31%] [G loss: 0.734887]\n",
      "epoch:11 step:10685 [D loss: 0.677189, acc.: 53.12%] [G loss: 0.716211]\n",
      "epoch:11 step:10686 [D loss: 0.673670, acc.: 59.38%] [G loss: 0.727133]\n",
      "epoch:11 step:10687 [D loss: 0.677652, acc.: 52.34%] [G loss: 0.754816]\n",
      "epoch:11 step:10688 [D loss: 0.675422, acc.: 60.16%] [G loss: 0.794344]\n",
      "epoch:11 step:10689 [D loss: 0.685877, acc.: 58.59%] [G loss: 0.767179]\n",
      "epoch:11 step:10690 [D loss: 0.678257, acc.: 50.78%] [G loss: 0.752881]\n",
      "epoch:11 step:10691 [D loss: 0.652197, acc.: 61.72%] [G loss: 0.777695]\n",
      "epoch:11 step:10692 [D loss: 0.690791, acc.: 50.78%] [G loss: 0.739470]\n",
      "epoch:11 step:10693 [D loss: 0.672068, acc.: 56.25%] [G loss: 0.775169]\n",
      "epoch:11 step:10694 [D loss: 0.658853, acc.: 59.38%] [G loss: 0.782364]\n",
      "epoch:11 step:10695 [D loss: 0.668257, acc.: 60.94%] [G loss: 0.728797]\n",
      "epoch:11 step:10696 [D loss: 0.691329, acc.: 50.78%] [G loss: 0.733941]\n",
      "epoch:11 step:10697 [D loss: 0.715439, acc.: 49.22%] [G loss: 0.703958]\n",
      "epoch:11 step:10698 [D loss: 0.695216, acc.: 51.56%] [G loss: 0.742348]\n",
      "epoch:11 step:10699 [D loss: 0.696123, acc.: 57.81%] [G loss: 0.717995]\n",
      "epoch:11 step:10700 [D loss: 0.682400, acc.: 53.91%] [G loss: 0.674122]\n",
      "epoch:11 step:10701 [D loss: 0.697087, acc.: 50.00%] [G loss: 0.701680]\n",
      "epoch:11 step:10702 [D loss: 0.713380, acc.: 46.88%] [G loss: 0.763935]\n",
      "epoch:11 step:10703 [D loss: 0.685671, acc.: 51.56%] [G loss: 0.747037]\n",
      "epoch:11 step:10704 [D loss: 0.671833, acc.: 60.94%] [G loss: 0.743761]\n",
      "epoch:11 step:10705 [D loss: 0.678227, acc.: 55.47%] [G loss: 0.747832]\n",
      "epoch:11 step:10706 [D loss: 0.647175, acc.: 63.28%] [G loss: 0.787936]\n",
      "epoch:11 step:10707 [D loss: 0.678896, acc.: 57.81%] [G loss: 0.755286]\n",
      "epoch:11 step:10708 [D loss: 0.700324, acc.: 53.12%] [G loss: 0.707073]\n",
      "epoch:11 step:10709 [D loss: 0.686630, acc.: 53.12%] [G loss: 0.768282]\n",
      "epoch:11 step:10710 [D loss: 0.719238, acc.: 45.31%] [G loss: 0.709740]\n",
      "epoch:11 step:10711 [D loss: 0.642071, acc.: 64.06%] [G loss: 0.754056]\n",
      "epoch:11 step:10712 [D loss: 0.674692, acc.: 58.59%] [G loss: 0.786270]\n",
      "epoch:11 step:10713 [D loss: 0.659052, acc.: 65.62%] [G loss: 0.735672]\n",
      "epoch:11 step:10714 [D loss: 0.680233, acc.: 56.25%] [G loss: 0.707751]\n",
      "epoch:11 step:10715 [D loss: 0.694083, acc.: 49.22%] [G loss: 0.732982]\n",
      "epoch:11 step:10716 [D loss: 0.682658, acc.: 53.91%] [G loss: 0.758974]\n",
      "epoch:11 step:10717 [D loss: 0.691075, acc.: 54.69%] [G loss: 0.809386]\n",
      "epoch:11 step:10718 [D loss: 0.718562, acc.: 40.62%] [G loss: 0.723276]\n",
      "epoch:11 step:10719 [D loss: 0.694694, acc.: 50.00%] [G loss: 0.757613]\n",
      "epoch:11 step:10720 [D loss: 0.688170, acc.: 49.22%] [G loss: 0.775102]\n",
      "epoch:11 step:10721 [D loss: 0.666537, acc.: 61.72%] [G loss: 0.773610]\n",
      "epoch:11 step:10722 [D loss: 0.682531, acc.: 58.59%] [G loss: 0.736846]\n",
      "epoch:11 step:10723 [D loss: 0.684992, acc.: 49.22%] [G loss: 0.749394]\n",
      "epoch:11 step:10724 [D loss: 0.724502, acc.: 48.44%] [G loss: 0.724845]\n",
      "epoch:11 step:10725 [D loss: 0.717741, acc.: 50.78%] [G loss: 0.716745]\n",
      "epoch:11 step:10726 [D loss: 0.732246, acc.: 48.44%] [G loss: 0.722282]\n",
      "epoch:11 step:10727 [D loss: 0.716569, acc.: 37.50%] [G loss: 0.734147]\n",
      "epoch:11 step:10728 [D loss: 0.692237, acc.: 51.56%] [G loss: 0.709349]\n",
      "epoch:11 step:10729 [D loss: 0.706643, acc.: 46.09%] [G loss: 0.779002]\n",
      "epoch:11 step:10730 [D loss: 0.687216, acc.: 55.47%] [G loss: 0.786976]\n",
      "epoch:11 step:10731 [D loss: 0.679977, acc.: 59.38%] [G loss: 0.759275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10732 [D loss: 0.665968, acc.: 67.97%] [G loss: 0.754204]\n",
      "epoch:11 step:10733 [D loss: 0.665297, acc.: 64.06%] [G loss: 0.781735]\n",
      "epoch:11 step:10734 [D loss: 0.672851, acc.: 60.16%] [G loss: 0.780423]\n",
      "epoch:11 step:10735 [D loss: 0.658170, acc.: 60.16%] [G loss: 0.742775]\n",
      "epoch:11 step:10736 [D loss: 0.661092, acc.: 57.03%] [G loss: 0.724061]\n",
      "epoch:11 step:10737 [D loss: 0.701989, acc.: 50.78%] [G loss: 0.708612]\n",
      "epoch:11 step:10738 [D loss: 0.701688, acc.: 51.56%] [G loss: 0.729428]\n",
      "epoch:11 step:10739 [D loss: 0.734481, acc.: 46.88%] [G loss: 0.724755]\n",
      "epoch:11 step:10740 [D loss: 0.714086, acc.: 47.66%] [G loss: 0.743885]\n",
      "epoch:11 step:10741 [D loss: 0.683673, acc.: 57.81%] [G loss: 0.737983]\n",
      "epoch:11 step:10742 [D loss: 0.695648, acc.: 48.44%] [G loss: 0.755979]\n",
      "epoch:11 step:10743 [D loss: 0.664268, acc.: 59.38%] [G loss: 0.765202]\n",
      "epoch:11 step:10744 [D loss: 0.674987, acc.: 55.47%] [G loss: 0.768685]\n",
      "epoch:11 step:10745 [D loss: 0.685470, acc.: 53.12%] [G loss: 0.766059]\n",
      "epoch:11 step:10746 [D loss: 0.696513, acc.: 48.44%] [G loss: 0.768672]\n",
      "epoch:11 step:10747 [D loss: 0.678732, acc.: 58.59%] [G loss: 0.781895]\n",
      "epoch:11 step:10748 [D loss: 0.697519, acc.: 57.81%] [G loss: 0.775192]\n",
      "epoch:11 step:10749 [D loss: 0.678491, acc.: 59.38%] [G loss: 0.736265]\n",
      "epoch:11 step:10750 [D loss: 0.690749, acc.: 48.44%] [G loss: 0.763671]\n",
      "epoch:11 step:10751 [D loss: 0.672419, acc.: 60.94%] [G loss: 0.727461]\n",
      "epoch:11 step:10752 [D loss: 0.664725, acc.: 59.38%] [G loss: 0.781132]\n",
      "epoch:11 step:10753 [D loss: 0.676422, acc.: 57.81%] [G loss: 0.767026]\n",
      "epoch:11 step:10754 [D loss: 0.671083, acc.: 55.47%] [G loss: 0.738389]\n",
      "epoch:11 step:10755 [D loss: 0.711236, acc.: 50.78%] [G loss: 0.761456]\n",
      "epoch:11 step:10756 [D loss: 0.670098, acc.: 57.03%] [G loss: 0.760923]\n",
      "epoch:11 step:10757 [D loss: 0.642905, acc.: 64.06%] [G loss: 0.778305]\n",
      "epoch:11 step:10758 [D loss: 0.665949, acc.: 58.59%] [G loss: 0.786002]\n",
      "epoch:11 step:10759 [D loss: 0.644283, acc.: 64.84%] [G loss: 0.798027]\n",
      "epoch:11 step:10760 [D loss: 0.656799, acc.: 63.28%] [G loss: 0.886824]\n",
      "epoch:11 step:10761 [D loss: 0.646218, acc.: 61.72%] [G loss: 0.811046]\n",
      "epoch:11 step:10762 [D loss: 0.634653, acc.: 70.31%] [G loss: 0.803571]\n",
      "epoch:11 step:10763 [D loss: 0.474190, acc.: 70.31%] [G loss: 1.006757]\n",
      "epoch:11 step:10764 [D loss: 0.620272, acc.: 65.62%] [G loss: 1.009079]\n",
      "epoch:11 step:10765 [D loss: 0.740348, acc.: 44.53%] [G loss: 0.921353]\n",
      "epoch:11 step:10766 [D loss: 0.692155, acc.: 54.69%] [G loss: 0.852699]\n",
      "epoch:11 step:10767 [D loss: 0.672409, acc.: 57.81%] [G loss: 0.856920]\n",
      "epoch:11 step:10768 [D loss: 0.719638, acc.: 51.56%] [G loss: 0.746118]\n",
      "epoch:11 step:10769 [D loss: 0.748585, acc.: 41.41%] [G loss: 0.731346]\n",
      "epoch:11 step:10770 [D loss: 0.697147, acc.: 55.47%] [G loss: 0.763951]\n",
      "epoch:11 step:10771 [D loss: 0.720897, acc.: 49.22%] [G loss: 0.785044]\n",
      "epoch:11 step:10772 [D loss: 0.703094, acc.: 50.78%] [G loss: 0.719223]\n",
      "epoch:11 step:10773 [D loss: 0.654262, acc.: 62.50%] [G loss: 0.787340]\n",
      "epoch:11 step:10774 [D loss: 0.676152, acc.: 57.03%] [G loss: 0.721246]\n",
      "epoch:11 step:10775 [D loss: 0.649019, acc.: 60.16%] [G loss: 0.779471]\n",
      "epoch:11 step:10776 [D loss: 0.702122, acc.: 48.44%] [G loss: 0.680411]\n",
      "epoch:11 step:10777 [D loss: 0.646355, acc.: 57.81%] [G loss: 0.729598]\n",
      "epoch:11 step:10778 [D loss: 0.698642, acc.: 52.34%] [G loss: 0.697469]\n",
      "epoch:11 step:10779 [D loss: 0.761810, acc.: 39.06%] [G loss: 0.721859]\n",
      "epoch:11 step:10780 [D loss: 0.730228, acc.: 39.06%] [G loss: 0.736018]\n",
      "epoch:11 step:10781 [D loss: 0.704687, acc.: 51.56%] [G loss: 0.809625]\n",
      "epoch:11 step:10782 [D loss: 0.806290, acc.: 49.22%] [G loss: 1.996178]\n",
      "epoch:11 step:10783 [D loss: 0.659679, acc.: 68.75%] [G loss: 1.000347]\n",
      "epoch:11 step:10784 [D loss: 0.672251, acc.: 58.59%] [G loss: 0.985071]\n",
      "epoch:11 step:10785 [D loss: 0.685474, acc.: 52.34%] [G loss: 0.944125]\n",
      "epoch:11 step:10786 [D loss: 0.697273, acc.: 53.91%] [G loss: 0.838474]\n",
      "epoch:11 step:10787 [D loss: 0.737692, acc.: 50.00%] [G loss: 0.751430]\n",
      "epoch:11 step:10788 [D loss: 0.700009, acc.: 55.47%] [G loss: 0.834183]\n",
      "epoch:11 step:10789 [D loss: 0.705121, acc.: 52.34%] [G loss: 0.776317]\n",
      "epoch:11 step:10790 [D loss: 0.684372, acc.: 55.47%] [G loss: 0.724672]\n",
      "epoch:11 step:10791 [D loss: 0.638780, acc.: 66.41%] [G loss: 0.725468]\n",
      "epoch:11 step:10792 [D loss: 0.672526, acc.: 58.59%] [G loss: 0.733686]\n",
      "epoch:11 step:10793 [D loss: 0.674932, acc.: 54.69%] [G loss: 0.730048]\n",
      "epoch:11 step:10794 [D loss: 0.696560, acc.: 51.56%] [G loss: 0.685081]\n",
      "epoch:11 step:10795 [D loss: 0.697196, acc.: 48.44%] [G loss: 0.720656]\n",
      "epoch:11 step:10796 [D loss: 0.697248, acc.: 50.78%] [G loss: 0.945976]\n",
      "epoch:11 step:10797 [D loss: 0.691683, acc.: 49.22%] [G loss: 0.765823]\n",
      "epoch:11 step:10798 [D loss: 0.719368, acc.: 41.41%] [G loss: 0.747371]\n",
      "epoch:11 step:10799 [D loss: 0.702380, acc.: 51.56%] [G loss: 0.734704]\n",
      "epoch:11 step:10800 [D loss: 0.693093, acc.: 51.56%] [G loss: 0.732754]\n",
      "epoch:11 step:10801 [D loss: 0.690214, acc.: 54.69%] [G loss: 0.740266]\n",
      "epoch:11 step:10802 [D loss: 0.670403, acc.: 62.50%] [G loss: 0.725075]\n",
      "epoch:11 step:10803 [D loss: 0.682422, acc.: 54.69%] [G loss: 0.732643]\n",
      "epoch:11 step:10804 [D loss: 0.698120, acc.: 55.47%] [G loss: 0.722381]\n",
      "epoch:11 step:10805 [D loss: 0.701115, acc.: 49.22%] [G loss: 0.780298]\n",
      "epoch:11 step:10806 [D loss: 0.674648, acc.: 65.62%] [G loss: 0.758001]\n",
      "epoch:11 step:10807 [D loss: 0.681936, acc.: 57.03%] [G loss: 0.791342]\n",
      "epoch:11 step:10808 [D loss: 0.687899, acc.: 53.91%] [G loss: 0.743408]\n",
      "epoch:11 step:10809 [D loss: 0.676956, acc.: 55.47%] [G loss: 0.784067]\n",
      "epoch:11 step:10810 [D loss: 0.685830, acc.: 57.81%] [G loss: 0.801971]\n",
      "epoch:11 step:10811 [D loss: 0.652040, acc.: 61.72%] [G loss: 0.813525]\n",
      "epoch:11 step:10812 [D loss: 0.638039, acc.: 60.94%] [G loss: 0.916669]\n",
      "epoch:11 step:10813 [D loss: 0.660963, acc.: 61.72%] [G loss: 0.780690]\n",
      "epoch:11 step:10814 [D loss: 0.637451, acc.: 71.09%] [G loss: 0.809795]\n",
      "epoch:11 step:10815 [D loss: 0.635501, acc.: 66.41%] [G loss: 0.851920]\n",
      "epoch:11 step:10816 [D loss: 0.721565, acc.: 59.38%] [G loss: 0.890711]\n",
      "epoch:11 step:10817 [D loss: 0.731649, acc.: 43.75%] [G loss: 0.786152]\n",
      "epoch:11 step:10818 [D loss: 0.710574, acc.: 42.19%] [G loss: 0.754044]\n",
      "epoch:11 step:10819 [D loss: 0.721962, acc.: 43.75%] [G loss: 0.715374]\n",
      "epoch:11 step:10820 [D loss: 0.685642, acc.: 52.34%] [G loss: 0.704825]\n",
      "epoch:11 step:10821 [D loss: 0.710959, acc.: 50.00%] [G loss: 0.763102]\n",
      "epoch:11 step:10822 [D loss: 0.685330, acc.: 53.12%] [G loss: 0.791910]\n",
      "epoch:11 step:10823 [D loss: 0.661829, acc.: 60.16%] [G loss: 0.734248]\n",
      "epoch:11 step:10824 [D loss: 0.655184, acc.: 60.16%] [G loss: 0.709895]\n",
      "epoch:11 step:10825 [D loss: 0.710786, acc.: 46.09%] [G loss: 0.742206]\n",
      "epoch:11 step:10826 [D loss: 0.712633, acc.: 42.97%] [G loss: 0.729393]\n",
      "epoch:11 step:10827 [D loss: 0.649095, acc.: 64.06%] [G loss: 0.733741]\n",
      "epoch:11 step:10828 [D loss: 0.678109, acc.: 60.16%] [G loss: 0.751378]\n",
      "epoch:11 step:10829 [D loss: 0.678396, acc.: 53.91%] [G loss: 0.759427]\n",
      "epoch:11 step:10830 [D loss: 0.679556, acc.: 55.47%] [G loss: 0.705113]\n",
      "epoch:11 step:10831 [D loss: 0.717124, acc.: 43.75%] [G loss: 0.734779]\n",
      "epoch:11 step:10832 [D loss: 0.670567, acc.: 61.72%] [G loss: 0.751169]\n",
      "epoch:11 step:10833 [D loss: 0.668987, acc.: 56.25%] [G loss: 0.747761]\n",
      "epoch:11 step:10834 [D loss: 0.685503, acc.: 56.25%] [G loss: 0.749398]\n",
      "epoch:11 step:10835 [D loss: 0.708758, acc.: 47.66%] [G loss: 0.755231]\n",
      "epoch:11 step:10836 [D loss: 0.720083, acc.: 44.53%] [G loss: 0.721037]\n",
      "epoch:11 step:10837 [D loss: 0.665260, acc.: 61.72%] [G loss: 0.762709]\n",
      "epoch:11 step:10838 [D loss: 0.699060, acc.: 48.44%] [G loss: 0.745859]\n",
      "epoch:11 step:10839 [D loss: 0.697363, acc.: 51.56%] [G loss: 0.741595]\n",
      "epoch:11 step:10840 [D loss: 0.679631, acc.: 55.47%] [G loss: 0.734016]\n",
      "epoch:11 step:10841 [D loss: 0.671975, acc.: 63.28%] [G loss: 0.746546]\n",
      "epoch:11 step:10842 [D loss: 0.709721, acc.: 43.75%] [G loss: 0.732540]\n",
      "epoch:11 step:10843 [D loss: 0.688606, acc.: 50.78%] [G loss: 0.709337]\n",
      "epoch:11 step:10844 [D loss: 0.673230, acc.: 55.47%] [G loss: 0.761552]\n",
      "epoch:11 step:10845 [D loss: 0.702649, acc.: 43.75%] [G loss: 0.704427]\n",
      "epoch:11 step:10846 [D loss: 0.695043, acc.: 53.12%] [G loss: 0.787721]\n",
      "epoch:11 step:10847 [D loss: 0.674032, acc.: 60.16%] [G loss: 0.760640]\n",
      "epoch:11 step:10848 [D loss: 0.686810, acc.: 55.47%] [G loss: 0.738681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10849 [D loss: 0.707705, acc.: 49.22%] [G loss: 0.708374]\n",
      "epoch:11 step:10850 [D loss: 0.588484, acc.: 68.75%] [G loss: 0.737853]\n",
      "epoch:11 step:10851 [D loss: 0.732864, acc.: 47.66%] [G loss: 0.765172]\n",
      "epoch:11 step:10852 [D loss: 0.686543, acc.: 62.50%] [G loss: 0.733019]\n",
      "epoch:11 step:10853 [D loss: 0.689949, acc.: 53.91%] [G loss: 0.722896]\n",
      "epoch:11 step:10854 [D loss: 0.699962, acc.: 53.91%] [G loss: 0.746130]\n",
      "epoch:11 step:10855 [D loss: 0.705549, acc.: 52.34%] [G loss: 0.815043]\n",
      "epoch:11 step:10856 [D loss: 0.657106, acc.: 64.84%] [G loss: 0.774495]\n",
      "epoch:11 step:10857 [D loss: 0.524175, acc.: 75.00%] [G loss: 0.823607]\n",
      "epoch:11 step:10858 [D loss: 0.659569, acc.: 58.59%] [G loss: 0.792435]\n",
      "epoch:11 step:10859 [D loss: 0.615530, acc.: 69.53%] [G loss: 0.731319]\n",
      "epoch:11 step:10860 [D loss: 0.685430, acc.: 57.03%] [G loss: 0.811352]\n",
      "epoch:11 step:10861 [D loss: 0.600751, acc.: 70.31%] [G loss: 0.770515]\n",
      "epoch:11 step:10862 [D loss: 0.660117, acc.: 58.59%] [G loss: 0.686078]\n",
      "epoch:11 step:10863 [D loss: 0.690418, acc.: 62.50%] [G loss: 0.758559]\n",
      "epoch:11 step:10864 [D loss: 0.709615, acc.: 53.91%] [G loss: 0.759923]\n",
      "epoch:11 step:10865 [D loss: 0.659955, acc.: 61.72%] [G loss: 0.797691]\n",
      "epoch:11 step:10866 [D loss: 0.717037, acc.: 46.09%] [G loss: 0.747238]\n",
      "epoch:11 step:10867 [D loss: 0.726620, acc.: 46.09%] [G loss: 0.730203]\n",
      "epoch:11 step:10868 [D loss: 0.739881, acc.: 45.31%] [G loss: 0.752316]\n",
      "epoch:11 step:10869 [D loss: 0.686643, acc.: 51.56%] [G loss: 0.870726]\n",
      "epoch:11 step:10870 [D loss: 0.701417, acc.: 46.88%] [G loss: 0.832498]\n",
      "epoch:11 step:10871 [D loss: 0.648832, acc.: 61.72%] [G loss: 0.826949]\n",
      "epoch:11 step:10872 [D loss: 0.673477, acc.: 54.69%] [G loss: 0.828779]\n",
      "epoch:11 step:10873 [D loss: 0.679868, acc.: 53.12%] [G loss: 0.791350]\n",
      "epoch:11 step:10874 [D loss: 0.672083, acc.: 55.47%] [G loss: 0.819589]\n",
      "epoch:11 step:10875 [D loss: 0.638811, acc.: 63.28%] [G loss: 0.812833]\n",
      "epoch:11 step:10876 [D loss: 0.717996, acc.: 50.78%] [G loss: 0.806272]\n",
      "epoch:11 step:10877 [D loss: 0.698133, acc.: 50.78%] [G loss: 0.819013]\n",
      "epoch:11 step:10878 [D loss: 0.691877, acc.: 53.91%] [G loss: 0.792685]\n",
      "epoch:11 step:10879 [D loss: 0.685497, acc.: 60.16%] [G loss: 0.735917]\n",
      "epoch:11 step:10880 [D loss: 0.670177, acc.: 57.81%] [G loss: 0.776939]\n",
      "epoch:11 step:10881 [D loss: 0.638593, acc.: 66.41%] [G loss: 0.810595]\n",
      "epoch:11 step:10882 [D loss: 0.656543, acc.: 61.72%] [G loss: 0.766018]\n",
      "epoch:11 step:10883 [D loss: 0.701407, acc.: 50.78%] [G loss: 0.573884]\n",
      "epoch:11 step:10884 [D loss: 0.661265, acc.: 58.59%] [G loss: 0.759184]\n",
      "epoch:11 step:10885 [D loss: 0.675305, acc.: 57.81%] [G loss: 0.777703]\n",
      "epoch:11 step:10886 [D loss: 0.650865, acc.: 57.03%] [G loss: 0.779469]\n",
      "epoch:11 step:10887 [D loss: 0.691826, acc.: 52.34%] [G loss: 0.875023]\n",
      "epoch:11 step:10888 [D loss: 0.642220, acc.: 61.72%] [G loss: 0.825968]\n",
      "epoch:11 step:10889 [D loss: 0.672540, acc.: 61.72%] [G loss: 0.835735]\n",
      "epoch:11 step:10890 [D loss: 0.647919, acc.: 59.38%] [G loss: 0.813070]\n",
      "epoch:11 step:10891 [D loss: 0.681640, acc.: 53.12%] [G loss: 0.878056]\n",
      "epoch:11 step:10892 [D loss: 0.632329, acc.: 64.06%] [G loss: 0.828910]\n",
      "epoch:11 step:10893 [D loss: 0.615738, acc.: 71.88%] [G loss: 0.785335]\n",
      "epoch:11 step:10894 [D loss: 0.656022, acc.: 61.72%] [G loss: 0.781997]\n",
      "epoch:11 step:10895 [D loss: 0.678967, acc.: 58.59%] [G loss: 0.731227]\n",
      "epoch:11 step:10896 [D loss: 0.660590, acc.: 60.16%] [G loss: 0.765888]\n",
      "epoch:11 step:10897 [D loss: 0.721711, acc.: 48.44%] [G loss: 0.782760]\n",
      "epoch:11 step:10898 [D loss: 0.766056, acc.: 39.06%] [G loss: 0.643820]\n",
      "epoch:11 step:10899 [D loss: 0.736187, acc.: 46.88%] [G loss: 0.757860]\n",
      "epoch:11 step:10900 [D loss: 0.695306, acc.: 52.34%] [G loss: 0.842259]\n",
      "epoch:11 step:10901 [D loss: 0.689390, acc.: 54.69%] [G loss: 0.861555]\n",
      "epoch:11 step:10902 [D loss: 0.696261, acc.: 48.44%] [G loss: 0.809100]\n",
      "epoch:11 step:10903 [D loss: 0.672989, acc.: 59.38%] [G loss: 0.802915]\n",
      "epoch:11 step:10904 [D loss: 0.695493, acc.: 54.69%] [G loss: 0.733536]\n",
      "epoch:11 step:10905 [D loss: 0.696315, acc.: 55.47%] [G loss: 0.694391]\n",
      "epoch:11 step:10906 [D loss: 0.692381, acc.: 52.34%] [G loss: 0.740473]\n",
      "epoch:11 step:10907 [D loss: 0.673734, acc.: 53.91%] [G loss: 0.829857]\n",
      "epoch:11 step:10908 [D loss: 0.710322, acc.: 48.44%] [G loss: 0.747638]\n",
      "epoch:11 step:10909 [D loss: 0.653163, acc.: 63.28%] [G loss: 0.794231]\n",
      "epoch:11 step:10910 [D loss: 0.743845, acc.: 41.41%] [G loss: 0.805060]\n",
      "epoch:11 step:10911 [D loss: 0.495722, acc.: 72.66%] [G loss: 0.781272]\n",
      "epoch:11 step:10912 [D loss: 0.715126, acc.: 52.34%] [G loss: 0.797088]\n",
      "epoch:11 step:10913 [D loss: 0.694704, acc.: 49.22%] [G loss: 0.773647]\n",
      "epoch:11 step:10914 [D loss: 0.705279, acc.: 46.09%] [G loss: 0.775775]\n",
      "epoch:11 step:10915 [D loss: 0.699982, acc.: 51.56%] [G loss: 0.775636]\n",
      "epoch:11 step:10916 [D loss: 0.694890, acc.: 53.12%] [G loss: 0.752355]\n",
      "epoch:11 step:10917 [D loss: 0.688958, acc.: 50.78%] [G loss: 0.782664]\n",
      "epoch:11 step:10918 [D loss: 0.685793, acc.: 51.56%] [G loss: 0.774181]\n",
      "epoch:11 step:10919 [D loss: 0.682443, acc.: 54.69%] [G loss: 0.767994]\n",
      "epoch:11 step:10920 [D loss: 0.698473, acc.: 50.00%] [G loss: 0.747076]\n",
      "epoch:11 step:10921 [D loss: 0.692477, acc.: 53.91%] [G loss: 0.734087]\n",
      "epoch:11 step:10922 [D loss: 0.687199, acc.: 52.34%] [G loss: 0.735478]\n",
      "epoch:11 step:10923 [D loss: 0.703986, acc.: 47.66%] [G loss: 0.752550]\n",
      "epoch:11 step:10924 [D loss: 0.698959, acc.: 49.22%] [G loss: 0.719689]\n",
      "epoch:11 step:10925 [D loss: 0.681886, acc.: 56.25%] [G loss: 0.687106]\n",
      "epoch:11 step:10926 [D loss: 0.646221, acc.: 64.06%] [G loss: 0.763045]\n",
      "epoch:11 step:10927 [D loss: 0.714702, acc.: 54.69%] [G loss: 0.718647]\n",
      "epoch:11 step:10928 [D loss: 0.690290, acc.: 55.47%] [G loss: 0.724580]\n",
      "epoch:11 step:10929 [D loss: 0.687551, acc.: 53.91%] [G loss: 0.727742]\n",
      "epoch:11 step:10930 [D loss: 0.703392, acc.: 49.22%] [G loss: 0.754648]\n",
      "epoch:11 step:10931 [D loss: 0.664121, acc.: 67.19%] [G loss: 0.760665]\n",
      "epoch:11 step:10932 [D loss: 0.714460, acc.: 48.44%] [G loss: 0.737337]\n",
      "epoch:11 step:10933 [D loss: 0.699872, acc.: 48.44%] [G loss: 0.798219]\n",
      "epoch:11 step:10934 [D loss: 0.723933, acc.: 41.41%] [G loss: 0.738821]\n",
      "epoch:11 step:10935 [D loss: 0.703277, acc.: 48.44%] [G loss: 0.706916]\n",
      "epoch:11 step:10936 [D loss: 0.683992, acc.: 56.25%] [G loss: 0.731938]\n",
      "epoch:11 step:10937 [D loss: 0.703500, acc.: 49.22%] [G loss: 0.757121]\n",
      "epoch:11 step:10938 [D loss: 0.688035, acc.: 57.81%] [G loss: 0.746104]\n",
      "epoch:11 step:10939 [D loss: 0.682147, acc.: 57.03%] [G loss: 0.730177]\n",
      "epoch:11 step:10940 [D loss: 0.659468, acc.: 67.97%] [G loss: 0.744004]\n",
      "epoch:11 step:10941 [D loss: 0.681098, acc.: 54.69%] [G loss: 0.756299]\n",
      "epoch:11 step:10942 [D loss: 0.664820, acc.: 57.81%] [G loss: 0.706645]\n",
      "epoch:11 step:10943 [D loss: 0.692246, acc.: 57.03%] [G loss: 0.748248]\n",
      "epoch:11 step:10944 [D loss: 0.677966, acc.: 57.81%] [G loss: 0.765194]\n",
      "epoch:11 step:10945 [D loss: 0.661696, acc.: 57.81%] [G loss: 0.715506]\n",
      "epoch:11 step:10946 [D loss: 0.698076, acc.: 52.34%] [G loss: 0.735352]\n",
      "epoch:11 step:10947 [D loss: 0.693581, acc.: 52.34%] [G loss: 0.734371]\n",
      "epoch:11 step:10948 [D loss: 0.669321, acc.: 56.25%] [G loss: 0.736583]\n",
      "epoch:11 step:10949 [D loss: 0.676391, acc.: 50.78%] [G loss: 0.786505]\n",
      "epoch:11 step:10950 [D loss: 0.673772, acc.: 62.50%] [G loss: 0.772753]\n",
      "epoch:11 step:10951 [D loss: 0.665036, acc.: 57.81%] [G loss: 0.728102]\n",
      "epoch:11 step:10952 [D loss: 0.693551, acc.: 55.47%] [G loss: 0.743373]\n",
      "epoch:11 step:10953 [D loss: 0.730855, acc.: 43.75%] [G loss: 0.733990]\n",
      "epoch:11 step:10954 [D loss: 0.678611, acc.: 50.00%] [G loss: 0.753626]\n",
      "epoch:11 step:10955 [D loss: 0.687137, acc.: 52.34%] [G loss: 0.821122]\n",
      "epoch:11 step:10956 [D loss: 0.697629, acc.: 53.91%] [G loss: 0.806534]\n",
      "epoch:11 step:10957 [D loss: 0.682369, acc.: 54.69%] [G loss: 0.762681]\n",
      "epoch:11 step:10958 [D loss: 0.666406, acc.: 62.50%] [G loss: 0.863762]\n",
      "epoch:11 step:10959 [D loss: 0.698563, acc.: 54.69%] [G loss: 0.787414]\n",
      "epoch:11 step:10960 [D loss: 0.686524, acc.: 49.22%] [G loss: 0.784904]\n",
      "epoch:11 step:10961 [D loss: 0.685080, acc.: 52.34%] [G loss: 0.748668]\n",
      "epoch:11 step:10962 [D loss: 0.709607, acc.: 51.56%] [G loss: 0.720920]\n",
      "epoch:11 step:10963 [D loss: 0.699563, acc.: 50.00%] [G loss: 0.730136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10964 [D loss: 0.688265, acc.: 53.91%] [G loss: 0.759694]\n",
      "epoch:11 step:10965 [D loss: 0.711718, acc.: 48.44%] [G loss: 0.799288]\n",
      "epoch:11 step:10966 [D loss: 0.683855, acc.: 46.88%] [G loss: 0.768971]\n",
      "epoch:11 step:10967 [D loss: 0.676297, acc.: 57.81%] [G loss: 0.806893]\n",
      "epoch:11 step:10968 [D loss: 0.665027, acc.: 55.47%] [G loss: 0.780131]\n",
      "epoch:11 step:10969 [D loss: 0.659276, acc.: 62.50%] [G loss: 0.775246]\n",
      "epoch:11 step:10970 [D loss: 0.696276, acc.: 48.44%] [G loss: 0.725177]\n",
      "epoch:11 step:10971 [D loss: 0.682379, acc.: 55.47%] [G loss: 0.813951]\n",
      "epoch:11 step:10972 [D loss: 0.690539, acc.: 48.44%] [G loss: 0.807080]\n",
      "epoch:11 step:10973 [D loss: 0.683409, acc.: 57.81%] [G loss: 0.760475]\n",
      "epoch:11 step:10974 [D loss: 0.685231, acc.: 53.91%] [G loss: 0.764001]\n",
      "epoch:11 step:10975 [D loss: 0.691113, acc.: 51.56%] [G loss: 0.728036]\n",
      "epoch:11 step:10976 [D loss: 0.671464, acc.: 56.25%] [G loss: 0.778253]\n",
      "epoch:11 step:10977 [D loss: 0.701871, acc.: 51.56%] [G loss: 0.732532]\n",
      "epoch:11 step:10978 [D loss: 0.695588, acc.: 51.56%] [G loss: 0.760982]\n",
      "epoch:11 step:10979 [D loss: 0.701855, acc.: 48.44%] [G loss: 0.782262]\n",
      "epoch:11 step:10980 [D loss: 0.683599, acc.: 53.91%] [G loss: 0.732105]\n",
      "epoch:11 step:10981 [D loss: 0.647636, acc.: 68.75%] [G loss: 0.712942]\n",
      "epoch:11 step:10982 [D loss: 0.697379, acc.: 46.88%] [G loss: 0.707138]\n",
      "epoch:11 step:10983 [D loss: 0.684983, acc.: 61.72%] [G loss: 0.737848]\n",
      "epoch:11 step:10984 [D loss: 0.704924, acc.: 56.25%] [G loss: 0.741895]\n",
      "epoch:11 step:10985 [D loss: 0.695342, acc.: 47.66%] [G loss: 0.746088]\n",
      "epoch:11 step:10986 [D loss: 0.690184, acc.: 48.44%] [G loss: 0.721148]\n",
      "epoch:11 step:10987 [D loss: 0.659388, acc.: 59.38%] [G loss: 0.774103]\n",
      "epoch:11 step:10988 [D loss: 0.693095, acc.: 50.78%] [G loss: 0.747279]\n",
      "epoch:11 step:10989 [D loss: 0.706168, acc.: 57.03%] [G loss: 0.736441]\n",
      "epoch:11 step:10990 [D loss: 0.678059, acc.: 55.47%] [G loss: 0.797967]\n",
      "epoch:11 step:10991 [D loss: 0.683483, acc.: 53.91%] [G loss: 0.745697]\n",
      "epoch:11 step:10992 [D loss: 0.659884, acc.: 63.28%] [G loss: 0.756698]\n",
      "epoch:11 step:10993 [D loss: 0.673093, acc.: 57.81%] [G loss: 0.733700]\n",
      "epoch:11 step:10994 [D loss: 0.674950, acc.: 59.38%] [G loss: 0.813594]\n",
      "epoch:11 step:10995 [D loss: 0.667565, acc.: 64.84%] [G loss: 0.802127]\n",
      "epoch:11 step:10996 [D loss: 0.704651, acc.: 50.78%] [G loss: 0.751912]\n",
      "epoch:11 step:10997 [D loss: 0.707201, acc.: 51.56%] [G loss: 0.756193]\n",
      "epoch:11 step:10998 [D loss: 0.677033, acc.: 56.25%] [G loss: 0.765831]\n",
      "epoch:11 step:10999 [D loss: 0.703694, acc.: 53.91%] [G loss: 0.745864]\n",
      "epoch:11 step:11000 [D loss: 0.658727, acc.: 63.28%] [G loss: 0.742441]\n",
      "epoch:11 step:11001 [D loss: 0.702187, acc.: 48.44%] [G loss: 0.734468]\n",
      "epoch:11 step:11002 [D loss: 0.689409, acc.: 56.25%] [G loss: 0.725757]\n",
      "epoch:11 step:11003 [D loss: 0.692095, acc.: 63.28%] [G loss: 0.751687]\n",
      "epoch:11 step:11004 [D loss: 0.742083, acc.: 44.53%] [G loss: 0.769033]\n",
      "epoch:11 step:11005 [D loss: 0.669870, acc.: 60.16%] [G loss: 0.809897]\n",
      "epoch:11 step:11006 [D loss: 0.672165, acc.: 64.06%] [G loss: 0.801049]\n",
      "epoch:11 step:11007 [D loss: 0.669337, acc.: 64.06%] [G loss: 0.809366]\n",
      "epoch:11 step:11008 [D loss: 0.673964, acc.: 61.72%] [G loss: 0.830811]\n",
      "epoch:11 step:11009 [D loss: 0.689308, acc.: 54.69%] [G loss: 0.803447]\n",
      "epoch:11 step:11010 [D loss: 0.701106, acc.: 46.88%] [G loss: 0.746154]\n",
      "epoch:11 step:11011 [D loss: 0.663323, acc.: 58.59%] [G loss: 0.791022]\n",
      "epoch:11 step:11012 [D loss: 0.690053, acc.: 46.09%] [G loss: 0.805686]\n",
      "epoch:11 step:11013 [D loss: 0.654870, acc.: 67.19%] [G loss: 0.748193]\n",
      "epoch:11 step:11014 [D loss: 0.642158, acc.: 66.41%] [G loss: 0.823480]\n",
      "epoch:11 step:11015 [D loss: 0.665023, acc.: 60.94%] [G loss: 0.776333]\n",
      "epoch:11 step:11016 [D loss: 0.663924, acc.: 61.72%] [G loss: 0.746131]\n",
      "epoch:11 step:11017 [D loss: 0.746298, acc.: 41.41%] [G loss: 0.719318]\n",
      "epoch:11 step:11018 [D loss: 0.707643, acc.: 47.66%] [G loss: 0.790141]\n",
      "epoch:11 step:11019 [D loss: 0.672805, acc.: 60.94%] [G loss: 0.732379]\n",
      "epoch:11 step:11020 [D loss: 0.672654, acc.: 60.16%] [G loss: 0.735698]\n",
      "epoch:11 step:11021 [D loss: 0.710147, acc.: 50.78%] [G loss: 0.725873]\n",
      "epoch:11 step:11022 [D loss: 0.700110, acc.: 52.34%] [G loss: 0.727620]\n",
      "epoch:11 step:11023 [D loss: 0.688407, acc.: 50.78%] [G loss: 0.739336]\n",
      "epoch:11 step:11024 [D loss: 0.670387, acc.: 60.16%] [G loss: 0.709937]\n",
      "epoch:11 step:11025 [D loss: 0.689644, acc.: 57.81%] [G loss: 0.717537]\n",
      "epoch:11 step:11026 [D loss: 0.671910, acc.: 59.38%] [G loss: 0.759215]\n",
      "epoch:11 step:11027 [D loss: 0.669424, acc.: 59.38%] [G loss: 0.759761]\n",
      "epoch:11 step:11028 [D loss: 0.676549, acc.: 54.69%] [G loss: 0.745280]\n",
      "epoch:11 step:11029 [D loss: 0.736831, acc.: 41.41%] [G loss: 0.779103]\n",
      "epoch:11 step:11030 [D loss: 0.713112, acc.: 50.78%] [G loss: 0.694153]\n",
      "epoch:11 step:11031 [D loss: 0.699589, acc.: 55.47%] [G loss: 0.755360]\n",
      "epoch:11 step:11032 [D loss: 0.695691, acc.: 50.00%] [G loss: 0.721864]\n",
      "epoch:11 step:11033 [D loss: 0.706935, acc.: 51.56%] [G loss: 0.773042]\n",
      "epoch:11 step:11034 [D loss: 0.734221, acc.: 40.62%] [G loss: 0.734665]\n",
      "epoch:11 step:11035 [D loss: 0.713695, acc.: 42.19%] [G loss: 0.772115]\n",
      "epoch:11 step:11036 [D loss: 0.682122, acc.: 54.69%] [G loss: 0.766662]\n",
      "epoch:11 step:11037 [D loss: 0.671522, acc.: 55.47%] [G loss: 0.749064]\n",
      "epoch:11 step:11038 [D loss: 0.679918, acc.: 55.47%] [G loss: 0.758594]\n",
      "epoch:11 step:11039 [D loss: 0.661378, acc.: 59.38%] [G loss: 0.765029]\n",
      "epoch:11 step:11040 [D loss: 0.675350, acc.: 57.03%] [G loss: 0.744852]\n",
      "epoch:11 step:11041 [D loss: 0.702407, acc.: 50.78%] [G loss: 0.773838]\n",
      "epoch:11 step:11042 [D loss: 0.684007, acc.: 57.81%] [G loss: 0.758484]\n",
      "epoch:11 step:11043 [D loss: 0.688701, acc.: 50.78%] [G loss: 0.731628]\n",
      "epoch:11 step:11044 [D loss: 0.683428, acc.: 57.03%] [G loss: 0.727705]\n",
      "epoch:11 step:11045 [D loss: 0.707479, acc.: 46.09%] [G loss: 0.699251]\n",
      "epoch:11 step:11046 [D loss: 0.732308, acc.: 40.62%] [G loss: 0.724351]\n",
      "epoch:11 step:11047 [D loss: 0.694405, acc.: 45.31%] [G loss: 0.730381]\n",
      "epoch:11 step:11048 [D loss: 0.690266, acc.: 51.56%] [G loss: 0.725035]\n",
      "epoch:11 step:11049 [D loss: 0.693994, acc.: 50.00%] [G loss: 0.696362]\n",
      "epoch:11 step:11050 [D loss: 0.687456, acc.: 50.78%] [G loss: 0.695649]\n",
      "epoch:11 step:11051 [D loss: 0.704198, acc.: 46.88%] [G loss: 0.727046]\n",
      "epoch:11 step:11052 [D loss: 0.688493, acc.: 50.00%] [G loss: 0.722625]\n",
      "epoch:11 step:11053 [D loss: 0.677029, acc.: 56.25%] [G loss: 0.697564]\n",
      "epoch:11 step:11054 [D loss: 0.664614, acc.: 64.84%] [G loss: 0.721634]\n",
      "epoch:11 step:11055 [D loss: 0.693607, acc.: 49.22%] [G loss: 0.726203]\n",
      "epoch:11 step:11056 [D loss: 0.702994, acc.: 43.75%] [G loss: 0.713033]\n",
      "epoch:11 step:11057 [D loss: 0.718491, acc.: 47.66%] [G loss: 0.728638]\n",
      "epoch:11 step:11058 [D loss: 0.685767, acc.: 56.25%] [G loss: 0.729809]\n",
      "epoch:11 step:11059 [D loss: 0.692975, acc.: 53.91%] [G loss: 0.727741]\n",
      "epoch:11 step:11060 [D loss: 0.698712, acc.: 48.44%] [G loss: 0.728718]\n",
      "epoch:11 step:11061 [D loss: 0.679862, acc.: 61.72%] [G loss: 0.705366]\n",
      "epoch:11 step:11062 [D loss: 0.674875, acc.: 55.47%] [G loss: 0.720458]\n",
      "epoch:11 step:11063 [D loss: 0.665571, acc.: 61.72%] [G loss: 0.723221]\n",
      "epoch:11 step:11064 [D loss: 0.682566, acc.: 57.03%] [G loss: 0.727829]\n",
      "epoch:11 step:11065 [D loss: 0.669331, acc.: 58.59%] [G loss: 0.757427]\n",
      "epoch:11 step:11066 [D loss: 0.694279, acc.: 56.25%] [G loss: 0.719161]\n",
      "epoch:11 step:11067 [D loss: 0.692030, acc.: 50.78%] [G loss: 0.728947]\n",
      "epoch:11 step:11068 [D loss: 0.699301, acc.: 49.22%] [G loss: 0.729611]\n",
      "epoch:11 step:11069 [D loss: 0.685921, acc.: 53.91%] [G loss: 0.720384]\n",
      "epoch:11 step:11070 [D loss: 0.680441, acc.: 57.03%] [G loss: 0.741169]\n",
      "epoch:11 step:11071 [D loss: 0.682931, acc.: 54.69%] [G loss: 0.736756]\n",
      "epoch:11 step:11072 [D loss: 0.698494, acc.: 49.22%] [G loss: 0.768198]\n",
      "epoch:11 step:11073 [D loss: 0.683274, acc.: 54.69%] [G loss: 0.759803]\n",
      "epoch:11 step:11074 [D loss: 0.659514, acc.: 61.72%] [G loss: 0.787548]\n",
      "epoch:11 step:11075 [D loss: 0.694550, acc.: 50.78%] [G loss: 0.774110]\n",
      "epoch:11 step:11076 [D loss: 0.681248, acc.: 58.59%] [G loss: 0.754006]\n",
      "epoch:11 step:11077 [D loss: 0.657079, acc.: 55.47%] [G loss: 0.733930]\n",
      "epoch:11 step:11078 [D loss: 0.701079, acc.: 57.81%] [G loss: 0.774246]\n",
      "epoch:11 step:11079 [D loss: 0.689180, acc.: 54.69%] [G loss: 0.736113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11080 [D loss: 0.689260, acc.: 50.78%] [G loss: 0.766169]\n",
      "epoch:11 step:11081 [D loss: 0.696197, acc.: 51.56%] [G loss: 0.750383]\n",
      "epoch:11 step:11082 [D loss: 0.638427, acc.: 64.84%] [G loss: 0.729022]\n",
      "epoch:11 step:11083 [D loss: 0.711793, acc.: 48.44%] [G loss: 0.762871]\n",
      "epoch:11 step:11084 [D loss: 0.719136, acc.: 43.75%] [G loss: 0.740458]\n",
      "epoch:11 step:11085 [D loss: 0.706823, acc.: 47.66%] [G loss: 0.739854]\n",
      "epoch:11 step:11086 [D loss: 0.703038, acc.: 52.34%] [G loss: 0.710102]\n",
      "epoch:11 step:11087 [D loss: 0.703253, acc.: 50.00%] [G loss: 0.755635]\n",
      "epoch:11 step:11088 [D loss: 0.717997, acc.: 45.31%] [G loss: 0.735011]\n",
      "epoch:11 step:11089 [D loss: 0.678136, acc.: 59.38%] [G loss: 0.765869]\n",
      "epoch:11 step:11090 [D loss: 0.689595, acc.: 51.56%] [G loss: 0.745970]\n",
      "epoch:11 step:11091 [D loss: 0.684122, acc.: 55.47%] [G loss: 0.736139]\n",
      "epoch:11 step:11092 [D loss: 0.675205, acc.: 56.25%] [G loss: 0.741503]\n",
      "epoch:11 step:11093 [D loss: 0.683347, acc.: 55.47%] [G loss: 0.753446]\n",
      "epoch:11 step:11094 [D loss: 0.693076, acc.: 50.00%] [G loss: 0.703886]\n",
      "epoch:11 step:11095 [D loss: 0.677689, acc.: 53.12%] [G loss: 0.728311]\n",
      "epoch:11 step:11096 [D loss: 0.680915, acc.: 54.69%] [G loss: 0.772402]\n",
      "epoch:11 step:11097 [D loss: 0.697462, acc.: 53.12%] [G loss: 0.729302]\n",
      "epoch:11 step:11098 [D loss: 0.676931, acc.: 50.78%] [G loss: 0.745206]\n",
      "epoch:11 step:11099 [D loss: 0.680523, acc.: 52.34%] [G loss: 0.707607]\n",
      "epoch:11 step:11100 [D loss: 0.676787, acc.: 58.59%] [G loss: 0.734876]\n",
      "epoch:11 step:11101 [D loss: 0.661777, acc.: 64.84%] [G loss: 0.705057]\n",
      "epoch:11 step:11102 [D loss: 0.710145, acc.: 50.00%] [G loss: 0.714653]\n",
      "epoch:11 step:11103 [D loss: 0.654490, acc.: 61.72%] [G loss: 0.757691]\n",
      "epoch:11 step:11104 [D loss: 0.709542, acc.: 43.75%] [G loss: 0.730985]\n",
      "epoch:11 step:11105 [D loss: 0.690477, acc.: 57.81%] [G loss: 0.707000]\n",
      "epoch:11 step:11106 [D loss: 0.694412, acc.: 53.91%] [G loss: 0.715500]\n",
      "epoch:11 step:11107 [D loss: 0.698128, acc.: 52.34%] [G loss: 0.737744]\n",
      "epoch:11 step:11108 [D loss: 0.691433, acc.: 53.91%] [G loss: 0.750917]\n",
      "epoch:11 step:11109 [D loss: 0.449979, acc.: 75.00%] [G loss: 0.799452]\n",
      "epoch:11 step:11110 [D loss: 0.678833, acc.: 57.81%] [G loss: 0.735282]\n",
      "epoch:11 step:11111 [D loss: 0.699494, acc.: 54.69%] [G loss: 0.724460]\n",
      "epoch:11 step:11112 [D loss: 0.726196, acc.: 47.66%] [G loss: 0.715541]\n",
      "epoch:11 step:11113 [D loss: 0.709000, acc.: 45.31%] [G loss: 0.722900]\n",
      "epoch:11 step:11114 [D loss: 0.700724, acc.: 46.09%] [G loss: 0.811999]\n",
      "epoch:11 step:11115 [D loss: 0.688003, acc.: 54.69%] [G loss: 0.747067]\n",
      "epoch:11 step:11116 [D loss: 0.710835, acc.: 43.75%] [G loss: 0.728917]\n",
      "epoch:11 step:11117 [D loss: 0.676937, acc.: 59.38%] [G loss: 0.799299]\n",
      "epoch:11 step:11118 [D loss: 0.684400, acc.: 51.56%] [G loss: 0.772076]\n",
      "epoch:11 step:11119 [D loss: 0.697495, acc.: 51.56%] [G loss: 0.726829]\n",
      "epoch:11 step:11120 [D loss: 0.687077, acc.: 55.47%] [G loss: 0.778901]\n",
      "epoch:11 step:11121 [D loss: 0.693300, acc.: 55.47%] [G loss: 0.791211]\n",
      "epoch:11 step:11122 [D loss: 0.657557, acc.: 66.41%] [G loss: 0.624473]\n",
      "epoch:11 step:11123 [D loss: 0.664626, acc.: 57.03%] [G loss: 0.800483]\n",
      "epoch:11 step:11124 [D loss: 0.668460, acc.: 60.16%] [G loss: 0.795773]\n",
      "epoch:11 step:11125 [D loss: 0.713609, acc.: 48.44%] [G loss: 0.771163]\n",
      "epoch:11 step:11126 [D loss: 0.678722, acc.: 59.38%] [G loss: 0.763192]\n",
      "epoch:11 step:11127 [D loss: 0.709865, acc.: 42.97%] [G loss: 0.800923]\n",
      "epoch:11 step:11128 [D loss: 0.688689, acc.: 52.34%] [G loss: 0.864728]\n",
      "epoch:11 step:11129 [D loss: 0.692398, acc.: 54.69%] [G loss: 0.771114]\n",
      "epoch:11 step:11130 [D loss: 0.703194, acc.: 55.47%] [G loss: 0.757262]\n",
      "epoch:11 step:11131 [D loss: 0.698918, acc.: 47.66%] [G loss: 0.757582]\n",
      "epoch:11 step:11132 [D loss: 0.689562, acc.: 51.56%] [G loss: 0.743275]\n",
      "epoch:11 step:11133 [D loss: 0.685361, acc.: 51.56%] [G loss: 0.733973]\n",
      "epoch:11 step:11134 [D loss: 0.713906, acc.: 46.09%] [G loss: 0.700448]\n",
      "epoch:11 step:11135 [D loss: 0.702334, acc.: 50.78%] [G loss: 0.713478]\n",
      "epoch:11 step:11136 [D loss: 0.682384, acc.: 55.47%] [G loss: 0.720207]\n",
      "epoch:11 step:11137 [D loss: 0.682618, acc.: 53.12%] [G loss: 0.745554]\n",
      "epoch:11 step:11138 [D loss: 0.680618, acc.: 56.25%] [G loss: 0.740483]\n",
      "epoch:11 step:11139 [D loss: 0.669676, acc.: 54.69%] [G loss: 0.703954]\n",
      "epoch:11 step:11140 [D loss: 0.685592, acc.: 49.22%] [G loss: 0.724480]\n",
      "epoch:11 step:11141 [D loss: 0.712172, acc.: 48.44%] [G loss: 0.644948]\n",
      "epoch:11 step:11142 [D loss: 0.690341, acc.: 52.34%] [G loss: 0.703559]\n",
      "epoch:11 step:11143 [D loss: 0.706477, acc.: 44.53%] [G loss: 0.715463]\n",
      "epoch:11 step:11144 [D loss: 0.718333, acc.: 52.34%] [G loss: 0.697252]\n",
      "epoch:11 step:11145 [D loss: 0.677152, acc.: 57.81%] [G loss: 0.722256]\n",
      "epoch:11 step:11146 [D loss: 0.678423, acc.: 60.94%] [G loss: 0.765409]\n",
      "epoch:11 step:11147 [D loss: 0.688402, acc.: 57.03%] [G loss: 0.721038]\n",
      "epoch:11 step:11148 [D loss: 0.674363, acc.: 60.16%] [G loss: 0.724607]\n",
      "epoch:11 step:11149 [D loss: 0.668857, acc.: 57.03%] [G loss: 0.739674]\n",
      "epoch:11 step:11150 [D loss: 0.699368, acc.: 53.12%] [G loss: 0.721882]\n",
      "epoch:11 step:11151 [D loss: 0.700052, acc.: 50.00%] [G loss: 0.693519]\n",
      "epoch:11 step:11152 [D loss: 0.650898, acc.: 56.25%] [G loss: 0.734858]\n",
      "epoch:11 step:11153 [D loss: 0.693572, acc.: 54.69%] [G loss: 0.721835]\n",
      "epoch:11 step:11154 [D loss: 0.691201, acc.: 56.25%] [G loss: 0.645742]\n",
      "epoch:11 step:11155 [D loss: 0.716324, acc.: 48.44%] [G loss: 0.683158]\n",
      "epoch:11 step:11156 [D loss: 0.721461, acc.: 49.22%] [G loss: 0.710781]\n",
      "epoch:11 step:11157 [D loss: 0.693904, acc.: 57.03%] [G loss: 0.741299]\n",
      "epoch:11 step:11158 [D loss: 0.683480, acc.: 51.56%] [G loss: 0.726071]\n",
      "epoch:11 step:11159 [D loss: 0.662298, acc.: 58.59%] [G loss: 0.787238]\n",
      "epoch:11 step:11160 [D loss: 0.669765, acc.: 58.59%] [G loss: 0.779491]\n",
      "epoch:11 step:11161 [D loss: 0.663108, acc.: 64.06%] [G loss: 0.772769]\n",
      "epoch:11 step:11162 [D loss: 0.666230, acc.: 57.03%] [G loss: 0.787592]\n",
      "epoch:11 step:11163 [D loss: 0.681879, acc.: 53.12%] [G loss: 0.768960]\n",
      "epoch:11 step:11164 [D loss: 0.672041, acc.: 57.03%] [G loss: 0.777015]\n",
      "epoch:11 step:11165 [D loss: 0.710925, acc.: 49.22%] [G loss: 0.812329]\n",
      "epoch:11 step:11166 [D loss: 0.715876, acc.: 43.75%] [G loss: 0.733726]\n",
      "epoch:11 step:11167 [D loss: 0.700707, acc.: 53.12%] [G loss: 0.725578]\n",
      "epoch:11 step:11168 [D loss: 0.703036, acc.: 49.22%] [G loss: 0.809177]\n",
      "epoch:11 step:11169 [D loss: 0.668435, acc.: 63.28%] [G loss: 0.776592]\n",
      "epoch:11 step:11170 [D loss: 0.700136, acc.: 47.66%] [G loss: 0.750305]\n",
      "epoch:11 step:11171 [D loss: 0.691471, acc.: 53.12%] [G loss: 0.773746]\n",
      "epoch:11 step:11172 [D loss: 0.700244, acc.: 48.44%] [G loss: 0.743189]\n",
      "epoch:11 step:11173 [D loss: 0.692540, acc.: 51.56%] [G loss: 0.737797]\n",
      "epoch:11 step:11174 [D loss: 0.832881, acc.: 35.16%] [G loss: 0.749159]\n",
      "epoch:11 step:11175 [D loss: 0.685768, acc.: 53.91%] [G loss: 0.766575]\n",
      "epoch:11 step:11176 [D loss: 0.691126, acc.: 50.78%] [G loss: 0.766193]\n",
      "epoch:11 step:11177 [D loss: 0.704205, acc.: 46.88%] [G loss: 0.718569]\n",
      "epoch:11 step:11178 [D loss: 0.712222, acc.: 38.28%] [G loss: 0.757894]\n",
      "epoch:11 step:11179 [D loss: 0.689815, acc.: 48.44%] [G loss: 0.726454]\n",
      "epoch:11 step:11180 [D loss: 0.713413, acc.: 38.28%] [G loss: 0.701574]\n",
      "epoch:11 step:11181 [D loss: 0.675032, acc.: 55.47%] [G loss: 0.741100]\n",
      "epoch:11 step:11182 [D loss: 0.707810, acc.: 39.06%] [G loss: 0.784110]\n",
      "epoch:11 step:11183 [D loss: 0.713150, acc.: 45.31%] [G loss: 0.708225]\n",
      "epoch:11 step:11184 [D loss: 0.702795, acc.: 46.09%] [G loss: 0.705129]\n",
      "epoch:11 step:11185 [D loss: 0.708569, acc.: 50.78%] [G loss: 0.717545]\n",
      "epoch:11 step:11186 [D loss: 0.692667, acc.: 50.78%] [G loss: 0.739346]\n",
      "epoch:11 step:11187 [D loss: 0.696256, acc.: 52.34%] [G loss: 0.778119]\n",
      "epoch:11 step:11188 [D loss: 0.698822, acc.: 50.78%] [G loss: 0.725007]\n",
      "epoch:11 step:11189 [D loss: 0.698844, acc.: 52.34%] [G loss: 0.720730]\n",
      "epoch:11 step:11190 [D loss: 0.698680, acc.: 47.66%] [G loss: 0.721814]\n",
      "epoch:11 step:11191 [D loss: 0.694366, acc.: 47.66%] [G loss: 0.711835]\n",
      "epoch:11 step:11192 [D loss: 0.702338, acc.: 51.56%] [G loss: 0.708777]\n",
      "epoch:11 step:11193 [D loss: 0.677824, acc.: 55.47%] [G loss: 0.719899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11194 [D loss: 0.688374, acc.: 51.56%] [G loss: 0.727305]\n",
      "epoch:11 step:11195 [D loss: 0.697061, acc.: 42.19%] [G loss: 0.730993]\n",
      "epoch:11 step:11196 [D loss: 0.688407, acc.: 53.91%] [G loss: 0.720685]\n",
      "epoch:11 step:11197 [D loss: 0.694186, acc.: 50.78%] [G loss: 0.728769]\n",
      "epoch:11 step:11198 [D loss: 0.716806, acc.: 39.84%] [G loss: 0.712219]\n",
      "epoch:11 step:11199 [D loss: 0.712154, acc.: 42.97%] [G loss: 0.716988]\n",
      "epoch:11 step:11200 [D loss: 0.706472, acc.: 47.66%] [G loss: 0.725290]\n",
      "epoch:11 step:11201 [D loss: 0.698265, acc.: 50.78%] [G loss: 0.715685]\n",
      "epoch:11 step:11202 [D loss: 0.696431, acc.: 52.34%] [G loss: 0.717532]\n",
      "epoch:11 step:11203 [D loss: 0.681967, acc.: 60.16%] [G loss: 0.730880]\n",
      "epoch:11 step:11204 [D loss: 0.676973, acc.: 63.28%] [G loss: 0.743483]\n",
      "epoch:11 step:11205 [D loss: 0.690628, acc.: 57.81%] [G loss: 0.735376]\n",
      "epoch:11 step:11206 [D loss: 0.637246, acc.: 68.75%] [G loss: 0.729971]\n",
      "epoch:11 step:11207 [D loss: 0.656514, acc.: 64.06%] [G loss: 0.747281]\n",
      "epoch:11 step:11208 [D loss: 0.653745, acc.: 75.00%] [G loss: 0.759787]\n",
      "epoch:11 step:11209 [D loss: 0.694989, acc.: 55.47%] [G loss: 0.757243]\n",
      "epoch:11 step:11210 [D loss: 0.669792, acc.: 63.28%] [G loss: 0.739966]\n",
      "epoch:11 step:11211 [D loss: 0.709369, acc.: 47.66%] [G loss: 0.729075]\n",
      "epoch:11 step:11212 [D loss: 0.699497, acc.: 47.66%] [G loss: 0.725430]\n",
      "epoch:11 step:11213 [D loss: 0.715627, acc.: 47.66%] [G loss: 0.763165]\n",
      "epoch:11 step:11214 [D loss: 0.687704, acc.: 56.25%] [G loss: 0.701242]\n",
      "epoch:11 step:11215 [D loss: 0.694324, acc.: 50.78%] [G loss: 0.726336]\n",
      "epoch:11 step:11216 [D loss: 0.651567, acc.: 73.44%] [G loss: 0.728532]\n",
      "epoch:11 step:11217 [D loss: 0.708948, acc.: 42.97%] [G loss: 0.693131]\n",
      "epoch:11 step:11218 [D loss: 0.658817, acc.: 62.50%] [G loss: 0.712178]\n",
      "epoch:11 step:11219 [D loss: 0.375958, acc.: 82.81%] [G loss: 0.755728]\n",
      "epoch:11 step:11220 [D loss: 0.670810, acc.: 59.38%] [G loss: 0.743507]\n",
      "epoch:11 step:11221 [D loss: 0.682906, acc.: 54.69%] [G loss: 0.724214]\n",
      "epoch:11 step:11222 [D loss: 0.711578, acc.: 51.56%] [G loss: 0.741368]\n",
      "epoch:11 step:11223 [D loss: 0.705393, acc.: 47.66%] [G loss: 0.752218]\n",
      "epoch:11 step:11224 [D loss: 0.680842, acc.: 52.34%] [G loss: 0.740729]\n",
      "epoch:11 step:11225 [D loss: 0.675021, acc.: 56.25%] [G loss: 0.714523]\n",
      "epoch:11 step:11226 [D loss: 0.630444, acc.: 69.53%] [G loss: 0.661090]\n",
      "epoch:11 step:11227 [D loss: 0.714769, acc.: 42.19%] [G loss: 0.734202]\n",
      "epoch:11 step:11228 [D loss: 0.691259, acc.: 54.69%] [G loss: 0.723767]\n",
      "epoch:11 step:11229 [D loss: 0.685640, acc.: 55.47%] [G loss: 0.679390]\n",
      "epoch:11 step:11230 [D loss: 0.666411, acc.: 58.59%] [G loss: 0.704729]\n",
      "epoch:11 step:11231 [D loss: 0.604172, acc.: 67.97%] [G loss: 0.712839]\n",
      "epoch:11 step:11232 [D loss: 0.615469, acc.: 64.84%] [G loss: 0.692787]\n",
      "epoch:11 step:11233 [D loss: 0.551728, acc.: 65.62%] [G loss: 0.702037]\n",
      "epoch:11 step:11234 [D loss: 0.413722, acc.: 73.44%] [G loss: 0.764996]\n",
      "epoch:11 step:11235 [D loss: 0.751179, acc.: 46.88%] [G loss: 0.761446]\n",
      "epoch:11 step:11236 [D loss: 0.744994, acc.: 35.94%] [G loss: 0.761847]\n",
      "epoch:11 step:11237 [D loss: 0.674218, acc.: 59.38%] [G loss: 0.771985]\n",
      "epoch:11 step:11238 [D loss: 0.644354, acc.: 64.84%] [G loss: 0.791065]\n",
      "epoch:11 step:11239 [D loss: 0.692671, acc.: 55.47%] [G loss: 0.774571]\n",
      "epoch:11 step:11240 [D loss: 0.594321, acc.: 64.84%] [G loss: 0.728506]\n",
      "epoch:11 step:11241 [D loss: 0.640444, acc.: 58.59%] [G loss: 0.699231]\n",
      "epoch:11 step:11242 [D loss: 1.435552, acc.: 46.09%] [G loss: 0.831748]\n",
      "epoch:11 step:11243 [D loss: 0.529948, acc.: 79.69%] [G loss: 0.856026]\n",
      "epoch:11 step:11244 [D loss: 0.636777, acc.: 64.84%] [G loss: 0.776984]\n",
      "epoch:12 step:11245 [D loss: 0.706387, acc.: 46.09%] [G loss: 0.807377]\n",
      "epoch:12 step:11246 [D loss: 0.737957, acc.: 43.75%] [G loss: 0.748985]\n",
      "epoch:12 step:11247 [D loss: 0.721138, acc.: 43.75%] [G loss: 0.753685]\n",
      "epoch:12 step:11248 [D loss: 0.711294, acc.: 41.41%] [G loss: 0.771996]\n",
      "epoch:12 step:11249 [D loss: 0.795722, acc.: 31.25%] [G loss: 0.762338]\n",
      "epoch:12 step:11250 [D loss: 0.698510, acc.: 48.44%] [G loss: 0.771281]\n",
      "epoch:12 step:11251 [D loss: 0.690684, acc.: 48.44%] [G loss: 0.787587]\n",
      "epoch:12 step:11252 [D loss: 0.710849, acc.: 50.00%] [G loss: 0.803121]\n",
      "epoch:12 step:11253 [D loss: 0.689515, acc.: 54.69%] [G loss: 0.881685]\n",
      "epoch:12 step:11254 [D loss: 0.695893, acc.: 53.12%] [G loss: 0.777605]\n",
      "epoch:12 step:11255 [D loss: 0.698303, acc.: 50.78%] [G loss: 0.780225]\n",
      "epoch:12 step:11256 [D loss: 0.689582, acc.: 49.22%] [G loss: 0.798379]\n",
      "epoch:12 step:11257 [D loss: 0.686040, acc.: 56.25%] [G loss: 0.746699]\n",
      "epoch:12 step:11258 [D loss: 0.684156, acc.: 63.28%] [G loss: 0.738056]\n",
      "epoch:12 step:11259 [D loss: 0.680233, acc.: 57.81%] [G loss: 0.749151]\n",
      "epoch:12 step:11260 [D loss: 0.684814, acc.: 60.94%] [G loss: 0.692360]\n",
      "epoch:12 step:11261 [D loss: 0.714795, acc.: 50.00%] [G loss: 0.780671]\n",
      "epoch:12 step:11262 [D loss: 0.670763, acc.: 67.97%] [G loss: 0.727049]\n",
      "epoch:12 step:11263 [D loss: 0.677432, acc.: 60.16%] [G loss: 0.721726]\n",
      "epoch:12 step:11264 [D loss: 0.689832, acc.: 52.34%] [G loss: 0.730212]\n",
      "epoch:12 step:11265 [D loss: 0.679340, acc.: 58.59%] [G loss: 0.745116]\n",
      "epoch:12 step:11266 [D loss: 0.676122, acc.: 54.69%] [G loss: 0.715014]\n",
      "epoch:12 step:11267 [D loss: 0.668494, acc.: 64.06%] [G loss: 0.811012]\n",
      "epoch:12 step:11268 [D loss: 0.669210, acc.: 61.72%] [G loss: 0.763804]\n",
      "epoch:12 step:11269 [D loss: 0.652328, acc.: 64.84%] [G loss: 0.763579]\n",
      "epoch:12 step:11270 [D loss: 0.717395, acc.: 43.75%] [G loss: 0.714788]\n",
      "epoch:12 step:11271 [D loss: 0.742049, acc.: 35.94%] [G loss: 0.726799]\n",
      "epoch:12 step:11272 [D loss: 0.785195, acc.: 51.56%] [G loss: 0.843355]\n",
      "epoch:12 step:11273 [D loss: 0.685624, acc.: 61.72%] [G loss: 0.853336]\n",
      "epoch:12 step:11274 [D loss: 0.690604, acc.: 57.03%] [G loss: 0.843236]\n",
      "epoch:12 step:11275 [D loss: 0.676378, acc.: 59.38%] [G loss: 0.846075]\n",
      "epoch:12 step:11276 [D loss: 0.604964, acc.: 66.41%] [G loss: 0.920069]\n",
      "epoch:12 step:11277 [D loss: 0.663679, acc.: 60.16%] [G loss: 0.907068]\n",
      "epoch:12 step:11278 [D loss: 0.674418, acc.: 66.41%] [G loss: 0.811081]\n",
      "epoch:12 step:11279 [D loss: 0.673971, acc.: 60.94%] [G loss: 0.747909]\n",
      "epoch:12 step:11280 [D loss: 0.649153, acc.: 61.72%] [G loss: 0.851792]\n",
      "epoch:12 step:11281 [D loss: 0.705323, acc.: 53.12%] [G loss: 0.810637]\n",
      "epoch:12 step:11282 [D loss: 0.874322, acc.: 21.09%] [G loss: 0.745509]\n",
      "epoch:12 step:11283 [D loss: 0.738265, acc.: 34.38%] [G loss: 0.723922]\n",
      "epoch:12 step:11284 [D loss: 0.738856, acc.: 34.38%] [G loss: 0.703195]\n",
      "epoch:12 step:11285 [D loss: 0.720697, acc.: 41.41%] [G loss: 0.706939]\n",
      "epoch:12 step:11286 [D loss: 0.695852, acc.: 44.53%] [G loss: 0.724780]\n",
      "epoch:12 step:11287 [D loss: 0.685291, acc.: 52.34%] [G loss: 0.723284]\n",
      "epoch:12 step:11288 [D loss: 0.690325, acc.: 55.47%] [G loss: 0.723360]\n",
      "epoch:12 step:11289 [D loss: 0.701653, acc.: 46.09%] [G loss: 0.734570]\n",
      "epoch:12 step:11290 [D loss: 0.690962, acc.: 54.69%] [G loss: 0.719378]\n",
      "epoch:12 step:11291 [D loss: 0.690824, acc.: 50.00%] [G loss: 0.747238]\n",
      "epoch:12 step:11292 [D loss: 0.685027, acc.: 57.03%] [G loss: 0.749081]\n",
      "epoch:12 step:11293 [D loss: 0.681510, acc.: 60.94%] [G loss: 0.731358]\n",
      "epoch:12 step:11294 [D loss: 0.692626, acc.: 51.56%] [G loss: 0.734687]\n",
      "epoch:12 step:11295 [D loss: 0.685060, acc.: 54.69%] [G loss: 0.720968]\n",
      "epoch:12 step:11296 [D loss: 0.668583, acc.: 64.06%] [G loss: 0.718091]\n",
      "epoch:12 step:11297 [D loss: 0.680343, acc.: 59.38%] [G loss: 0.717698]\n",
      "epoch:12 step:11298 [D loss: 0.690816, acc.: 60.16%] [G loss: 0.727211]\n",
      "epoch:12 step:11299 [D loss: 0.696452, acc.: 47.66%] [G loss: 0.762531]\n",
      "epoch:12 step:11300 [D loss: 0.679984, acc.: 53.91%] [G loss: 0.739659]\n",
      "epoch:12 step:11301 [D loss: 0.696037, acc.: 50.00%] [G loss: 0.733231]\n",
      "epoch:12 step:11302 [D loss: 0.691057, acc.: 52.34%] [G loss: 0.728800]\n",
      "epoch:12 step:11303 [D loss: 0.684560, acc.: 54.69%] [G loss: 0.728697]\n",
      "epoch:12 step:11304 [D loss: 0.701210, acc.: 45.31%] [G loss: 0.732982]\n",
      "epoch:12 step:11305 [D loss: 0.697699, acc.: 50.00%] [G loss: 0.733366]\n",
      "epoch:12 step:11306 [D loss: 0.687435, acc.: 50.78%] [G loss: 0.755770]\n",
      "epoch:12 step:11307 [D loss: 0.692758, acc.: 51.56%] [G loss: 0.766104]\n",
      "epoch:12 step:11308 [D loss: 0.675527, acc.: 61.72%] [G loss: 0.758850]\n",
      "epoch:12 step:11309 [D loss: 0.680185, acc.: 59.38%] [G loss: 0.783484]\n",
      "epoch:12 step:11310 [D loss: 0.676792, acc.: 58.59%] [G loss: 0.782161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11311 [D loss: 0.681037, acc.: 53.12%] [G loss: 0.758133]\n",
      "epoch:12 step:11312 [D loss: 0.670560, acc.: 65.62%] [G loss: 0.767521]\n",
      "epoch:12 step:11313 [D loss: 0.679172, acc.: 60.94%] [G loss: 0.726069]\n",
      "epoch:12 step:11314 [D loss: 0.683830, acc.: 60.16%] [G loss: 0.744820]\n",
      "epoch:12 step:11315 [D loss: 0.694651, acc.: 50.78%] [G loss: 0.720582]\n",
      "epoch:12 step:11316 [D loss: 0.680511, acc.: 50.78%] [G loss: 0.724021]\n",
      "epoch:12 step:11317 [D loss: 0.681029, acc.: 54.69%] [G loss: 0.740986]\n",
      "epoch:12 step:11318 [D loss: 0.687062, acc.: 53.91%] [G loss: 0.748276]\n",
      "epoch:12 step:11319 [D loss: 0.727711, acc.: 39.84%] [G loss: 0.686730]\n",
      "epoch:12 step:11320 [D loss: 0.700412, acc.: 50.78%] [G loss: 0.734442]\n",
      "epoch:12 step:11321 [D loss: 0.696837, acc.: 49.22%] [G loss: 0.734752]\n",
      "epoch:12 step:11322 [D loss: 0.698821, acc.: 51.56%] [G loss: 0.743430]\n",
      "epoch:12 step:11323 [D loss: 0.692273, acc.: 52.34%] [G loss: 0.722268]\n",
      "epoch:12 step:11324 [D loss: 0.703334, acc.: 46.09%] [G loss: 0.728396]\n",
      "epoch:12 step:11325 [D loss: 0.697267, acc.: 50.78%] [G loss: 0.728754]\n",
      "epoch:12 step:11326 [D loss: 0.686135, acc.: 55.47%] [G loss: 0.723331]\n",
      "epoch:12 step:11327 [D loss: 0.689128, acc.: 53.12%] [G loss: 0.719767]\n",
      "epoch:12 step:11328 [D loss: 0.683008, acc.: 47.66%] [G loss: 0.716738]\n",
      "epoch:12 step:11329 [D loss: 0.665860, acc.: 56.25%] [G loss: 0.729104]\n",
      "epoch:12 step:11330 [D loss: 0.691951, acc.: 52.34%] [G loss: 0.739989]\n",
      "epoch:12 step:11331 [D loss: 0.701196, acc.: 50.78%] [G loss: 0.716434]\n",
      "epoch:12 step:11332 [D loss: 0.689044, acc.: 54.69%] [G loss: 0.689955]\n",
      "epoch:12 step:11333 [D loss: 0.674413, acc.: 61.72%] [G loss: 0.628663]\n",
      "epoch:12 step:11334 [D loss: 0.699720, acc.: 46.09%] [G loss: 0.730819]\n",
      "epoch:12 step:11335 [D loss: 0.701164, acc.: 44.53%] [G loss: 0.706645]\n",
      "epoch:12 step:11336 [D loss: 0.689357, acc.: 49.22%] [G loss: 0.732853]\n",
      "epoch:12 step:11337 [D loss: 0.686173, acc.: 55.47%] [G loss: 0.697989]\n",
      "epoch:12 step:11338 [D loss: 0.696944, acc.: 52.34%] [G loss: 0.713693]\n",
      "epoch:12 step:11339 [D loss: 0.691782, acc.: 50.78%] [G loss: 0.740705]\n",
      "epoch:12 step:11340 [D loss: 0.696670, acc.: 50.78%] [G loss: 0.750885]\n",
      "epoch:12 step:11341 [D loss: 0.682427, acc.: 56.25%] [G loss: 0.751824]\n",
      "epoch:12 step:11342 [D loss: 0.661300, acc.: 63.28%] [G loss: 0.745682]\n",
      "epoch:12 step:11343 [D loss: 0.658158, acc.: 61.72%] [G loss: 0.772080]\n",
      "epoch:12 step:11344 [D loss: 0.665521, acc.: 58.59%] [G loss: 0.738622]\n",
      "epoch:12 step:11345 [D loss: 0.701856, acc.: 46.88%] [G loss: 0.761192]\n",
      "epoch:12 step:11346 [D loss: 0.681654, acc.: 60.94%] [G loss: 0.749895]\n",
      "epoch:12 step:11347 [D loss: 0.705855, acc.: 49.22%] [G loss: 0.730721]\n",
      "epoch:12 step:11348 [D loss: 0.697934, acc.: 51.56%] [G loss: 0.739620]\n",
      "epoch:12 step:11349 [D loss: 0.710993, acc.: 42.97%] [G loss: 0.741183]\n",
      "epoch:12 step:11350 [D loss: 0.680363, acc.: 56.25%] [G loss: 0.750658]\n",
      "epoch:12 step:11351 [D loss: 0.669442, acc.: 56.25%] [G loss: 0.713603]\n",
      "epoch:12 step:11352 [D loss: 0.714745, acc.: 45.31%] [G loss: 0.723550]\n",
      "epoch:12 step:11353 [D loss: 0.680178, acc.: 63.28%] [G loss: 0.756560]\n",
      "epoch:12 step:11354 [D loss: 0.694282, acc.: 53.12%] [G loss: 0.751000]\n",
      "epoch:12 step:11355 [D loss: 0.694735, acc.: 50.78%] [G loss: 0.728101]\n",
      "epoch:12 step:11356 [D loss: 0.672573, acc.: 57.81%] [G loss: 0.719826]\n",
      "epoch:12 step:11357 [D loss: 0.715577, acc.: 45.31%] [G loss: 0.726575]\n",
      "epoch:12 step:11358 [D loss: 0.696942, acc.: 49.22%] [G loss: 0.732193]\n",
      "epoch:12 step:11359 [D loss: 0.688583, acc.: 48.44%] [G loss: 0.728415]\n",
      "epoch:12 step:11360 [D loss: 0.682496, acc.: 56.25%] [G loss: 0.708446]\n",
      "epoch:12 step:11361 [D loss: 0.685104, acc.: 53.91%] [G loss: 0.708971]\n",
      "epoch:12 step:11362 [D loss: 0.675668, acc.: 58.59%] [G loss: 0.715758]\n",
      "epoch:12 step:11363 [D loss: 0.673129, acc.: 61.72%] [G loss: 0.714592]\n",
      "epoch:12 step:11364 [D loss: 0.720946, acc.: 39.84%] [G loss: 0.734928]\n",
      "epoch:12 step:11365 [D loss: 0.719464, acc.: 38.28%] [G loss: 0.713410]\n",
      "epoch:12 step:11366 [D loss: 0.704270, acc.: 48.44%] [G loss: 0.744490]\n",
      "epoch:12 step:11367 [D loss: 0.703135, acc.: 49.22%] [G loss: 0.731240]\n",
      "epoch:12 step:11368 [D loss: 0.685056, acc.: 57.03%] [G loss: 0.750618]\n",
      "epoch:12 step:11369 [D loss: 0.674108, acc.: 54.69%] [G loss: 0.787028]\n",
      "epoch:12 step:11370 [D loss: 0.692994, acc.: 54.69%] [G loss: 0.772579]\n",
      "epoch:12 step:11371 [D loss: 0.682469, acc.: 55.47%] [G loss: 0.769245]\n",
      "epoch:12 step:11372 [D loss: 0.688978, acc.: 53.12%] [G loss: 0.796182]\n",
      "epoch:12 step:11373 [D loss: 0.669958, acc.: 60.94%] [G loss: 0.770870]\n",
      "epoch:12 step:11374 [D loss: 0.652239, acc.: 62.50%] [G loss: 0.778314]\n",
      "epoch:12 step:11375 [D loss: 0.685971, acc.: 56.25%] [G loss: 0.757612]\n",
      "epoch:12 step:11376 [D loss: 0.667413, acc.: 60.16%] [G loss: 0.766457]\n",
      "epoch:12 step:11377 [D loss: 0.677831, acc.: 57.03%] [G loss: 0.745027]\n",
      "epoch:12 step:11378 [D loss: 0.696109, acc.: 54.69%] [G loss: 0.766011]\n",
      "epoch:12 step:11379 [D loss: 0.671208, acc.: 53.91%] [G loss: 0.712949]\n",
      "epoch:12 step:11380 [D loss: 0.694533, acc.: 48.44%] [G loss: 0.713041]\n",
      "epoch:12 step:11381 [D loss: 0.717578, acc.: 46.09%] [G loss: 0.710446]\n",
      "epoch:12 step:11382 [D loss: 0.702502, acc.: 52.34%] [G loss: 0.721906]\n",
      "epoch:12 step:11383 [D loss: 0.676595, acc.: 53.12%] [G loss: 0.776195]\n",
      "epoch:12 step:11384 [D loss: 0.713139, acc.: 43.75%] [G loss: 0.745341]\n",
      "epoch:12 step:11385 [D loss: 0.688433, acc.: 53.91%] [G loss: 0.779216]\n",
      "epoch:12 step:11386 [D loss: 0.686053, acc.: 51.56%] [G loss: 0.806394]\n",
      "epoch:12 step:11387 [D loss: 0.648927, acc.: 65.62%] [G loss: 0.805511]\n",
      "epoch:12 step:11388 [D loss: 0.653058, acc.: 57.81%] [G loss: 0.792086]\n",
      "epoch:12 step:11389 [D loss: 0.641118, acc.: 61.72%] [G loss: 0.853988]\n",
      "epoch:12 step:11390 [D loss: 0.672476, acc.: 54.69%] [G loss: 0.799767]\n",
      "epoch:12 step:11391 [D loss: 0.689530, acc.: 55.47%] [G loss: 0.775338]\n",
      "epoch:12 step:11392 [D loss: 0.707114, acc.: 42.97%] [G loss: 0.715538]\n",
      "epoch:12 step:11393 [D loss: 0.702549, acc.: 53.91%] [G loss: 0.701143]\n",
      "epoch:12 step:11394 [D loss: 0.684354, acc.: 55.47%] [G loss: 0.714190]\n",
      "epoch:12 step:11395 [D loss: 0.692457, acc.: 53.91%] [G loss: 0.726420]\n",
      "epoch:12 step:11396 [D loss: 0.680271, acc.: 57.03%] [G loss: 0.708221]\n",
      "epoch:12 step:11397 [D loss: 0.709785, acc.: 49.22%] [G loss: 0.777996]\n",
      "epoch:12 step:11398 [D loss: 0.700199, acc.: 48.44%] [G loss: 0.752423]\n",
      "epoch:12 step:11399 [D loss: 0.678784, acc.: 53.12%] [G loss: 0.771334]\n",
      "epoch:12 step:11400 [D loss: 0.675574, acc.: 61.72%] [G loss: 0.752297]\n",
      "epoch:12 step:11401 [D loss: 0.677721, acc.: 57.03%] [G loss: 0.789091]\n",
      "epoch:12 step:11402 [D loss: 0.707424, acc.: 50.00%] [G loss: 0.751566]\n",
      "epoch:12 step:11403 [D loss: 0.709625, acc.: 42.19%] [G loss: 0.764437]\n",
      "epoch:12 step:11404 [D loss: 0.689827, acc.: 54.69%] [G loss: 0.756125]\n",
      "epoch:12 step:11405 [D loss: 0.702453, acc.: 49.22%] [G loss: 0.741168]\n",
      "epoch:12 step:11406 [D loss: 0.684313, acc.: 56.25%] [G loss: 0.735715]\n",
      "epoch:12 step:11407 [D loss: 0.690453, acc.: 45.31%] [G loss: 0.740335]\n",
      "epoch:12 step:11408 [D loss: 0.684576, acc.: 53.91%] [G loss: 0.704808]\n",
      "epoch:12 step:11409 [D loss: 0.696053, acc.: 49.22%] [G loss: 0.707203]\n",
      "epoch:12 step:11410 [D loss: 0.686197, acc.: 53.91%] [G loss: 0.732719]\n",
      "epoch:12 step:11411 [D loss: 0.696010, acc.: 50.78%] [G loss: 0.732287]\n",
      "epoch:12 step:11412 [D loss: 0.683117, acc.: 57.81%] [G loss: 0.730950]\n",
      "epoch:12 step:11413 [D loss: 0.678635, acc.: 53.12%] [G loss: 0.717966]\n",
      "epoch:12 step:11414 [D loss: 0.682684, acc.: 50.00%] [G loss: 0.721132]\n",
      "epoch:12 step:11415 [D loss: 0.678440, acc.: 56.25%] [G loss: 0.723873]\n",
      "epoch:12 step:11416 [D loss: 0.664241, acc.: 64.06%] [G loss: 0.722973]\n",
      "epoch:12 step:11417 [D loss: 0.669183, acc.: 57.81%] [G loss: 0.718174]\n",
      "epoch:12 step:11418 [D loss: 0.700153, acc.: 56.25%] [G loss: 0.735921]\n",
      "epoch:12 step:11419 [D loss: 0.707727, acc.: 50.78%] [G loss: 0.731432]\n",
      "epoch:12 step:11420 [D loss: 0.659750, acc.: 64.06%] [G loss: 0.741372]\n",
      "epoch:12 step:11421 [D loss: 0.699595, acc.: 44.53%] [G loss: 0.745287]\n",
      "epoch:12 step:11422 [D loss: 0.694234, acc.: 51.56%] [G loss: 0.732439]\n",
      "epoch:12 step:11423 [D loss: 0.679805, acc.: 58.59%] [G loss: 0.753468]\n",
      "epoch:12 step:11424 [D loss: 0.669879, acc.: 64.06%] [G loss: 0.756342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11425 [D loss: 0.683475, acc.: 53.91%] [G loss: 0.771330]\n",
      "epoch:12 step:11426 [D loss: 0.703729, acc.: 46.88%] [G loss: 0.750246]\n",
      "epoch:12 step:11427 [D loss: 0.673773, acc.: 52.34%] [G loss: 0.735909]\n",
      "epoch:12 step:11428 [D loss: 0.677846, acc.: 57.81%] [G loss: 0.734191]\n",
      "epoch:12 step:11429 [D loss: 0.671075, acc.: 58.59%] [G loss: 0.728419]\n",
      "epoch:12 step:11430 [D loss: 0.697662, acc.: 53.12%] [G loss: 0.737200]\n",
      "epoch:12 step:11431 [D loss: 0.708817, acc.: 46.88%] [G loss: 0.714375]\n",
      "epoch:12 step:11432 [D loss: 0.737277, acc.: 39.84%] [G loss: 0.731683]\n",
      "epoch:12 step:11433 [D loss: 0.689793, acc.: 53.12%] [G loss: 0.718262]\n",
      "epoch:12 step:11434 [D loss: 0.683571, acc.: 51.56%] [G loss: 0.712404]\n",
      "epoch:12 step:11435 [D loss: 0.669740, acc.: 63.28%] [G loss: 0.746121]\n",
      "epoch:12 step:11436 [D loss: 0.685953, acc.: 50.78%] [G loss: 0.735553]\n",
      "epoch:12 step:11437 [D loss: 0.708464, acc.: 48.44%] [G loss: 0.747316]\n",
      "epoch:12 step:11438 [D loss: 0.689982, acc.: 53.12%] [G loss: 0.767900]\n",
      "epoch:12 step:11439 [D loss: 0.687567, acc.: 53.91%] [G loss: 0.762667]\n",
      "epoch:12 step:11440 [D loss: 0.682469, acc.: 55.47%] [G loss: 0.754161]\n",
      "epoch:12 step:11441 [D loss: 0.660649, acc.: 62.50%] [G loss: 0.768410]\n",
      "epoch:12 step:11442 [D loss: 0.657085, acc.: 60.16%] [G loss: 0.794122]\n",
      "epoch:12 step:11443 [D loss: 0.698719, acc.: 50.78%] [G loss: 0.841563]\n",
      "epoch:12 step:11444 [D loss: 0.676891, acc.: 55.47%] [G loss: 0.811233]\n",
      "epoch:12 step:11445 [D loss: 0.707803, acc.: 50.78%] [G loss: 0.787008]\n",
      "epoch:12 step:11446 [D loss: 0.668548, acc.: 63.28%] [G loss: 0.813286]\n",
      "epoch:12 step:11447 [D loss: 0.661361, acc.: 61.72%] [G loss: 0.842326]\n",
      "epoch:12 step:11448 [D loss: 0.626812, acc.: 63.28%] [G loss: 0.681459]\n",
      "epoch:12 step:11449 [D loss: 0.671753, acc.: 61.72%] [G loss: 0.777455]\n",
      "epoch:12 step:11450 [D loss: 0.684723, acc.: 60.16%] [G loss: 0.708113]\n",
      "epoch:12 step:11451 [D loss: 0.495449, acc.: 65.62%] [G loss: 0.735591]\n",
      "epoch:12 step:11452 [D loss: 0.693874, acc.: 54.69%] [G loss: 0.767897]\n",
      "epoch:12 step:11453 [D loss: 0.700604, acc.: 53.12%] [G loss: 0.767239]\n",
      "epoch:12 step:11454 [D loss: 0.731213, acc.: 48.44%] [G loss: 0.786677]\n",
      "epoch:12 step:11455 [D loss: 0.694372, acc.: 50.00%] [G loss: 0.733337]\n",
      "epoch:12 step:11456 [D loss: 0.688449, acc.: 54.69%] [G loss: 0.815896]\n",
      "epoch:12 step:11457 [D loss: 0.665023, acc.: 58.59%] [G loss: 0.786697]\n",
      "epoch:12 step:11458 [D loss: 0.703121, acc.: 50.78%] [G loss: 0.576578]\n",
      "epoch:12 step:11459 [D loss: 0.704540, acc.: 46.09%] [G loss: 0.797749]\n",
      "epoch:12 step:11460 [D loss: 0.652865, acc.: 60.16%] [G loss: 0.748424]\n",
      "epoch:12 step:11461 [D loss: 0.704373, acc.: 50.78%] [G loss: 0.717745]\n",
      "epoch:12 step:11462 [D loss: 0.717992, acc.: 48.44%] [G loss: 0.742071]\n",
      "epoch:12 step:11463 [D loss: 0.734130, acc.: 47.66%] [G loss: 0.718439]\n",
      "epoch:12 step:11464 [D loss: 0.667884, acc.: 60.94%] [G loss: 0.747249]\n",
      "epoch:12 step:11465 [D loss: 0.666173, acc.: 64.06%] [G loss: 0.812498]\n",
      "epoch:12 step:11466 [D loss: 0.679348, acc.: 59.38%] [G loss: 0.795235]\n",
      "epoch:12 step:11467 [D loss: 0.655565, acc.: 65.62%] [G loss: 0.796955]\n",
      "epoch:12 step:11468 [D loss: 0.736926, acc.: 44.53%] [G loss: 0.774249]\n",
      "epoch:12 step:11469 [D loss: 0.741271, acc.: 45.31%] [G loss: 0.811786]\n",
      "epoch:12 step:11470 [D loss: 0.678297, acc.: 52.34%] [G loss: 0.899890]\n",
      "epoch:12 step:11471 [D loss: 0.661432, acc.: 57.03%] [G loss: 0.765215]\n",
      "epoch:12 step:11472 [D loss: 0.685007, acc.: 50.78%] [G loss: 0.811580]\n",
      "epoch:12 step:11473 [D loss: 0.667048, acc.: 63.28%] [G loss: 0.856983]\n",
      "epoch:12 step:11474 [D loss: 0.636521, acc.: 70.31%] [G loss: 0.822567]\n",
      "epoch:12 step:11475 [D loss: 0.643356, acc.: 64.84%] [G loss: 0.728964]\n",
      "epoch:12 step:11476 [D loss: 0.629896, acc.: 60.94%] [G loss: 0.813633]\n",
      "epoch:12 step:11477 [D loss: 0.717391, acc.: 44.53%] [G loss: 0.815091]\n",
      "epoch:12 step:11478 [D loss: 0.712143, acc.: 46.09%] [G loss: 0.801744]\n",
      "epoch:12 step:11479 [D loss: 0.710484, acc.: 53.12%] [G loss: 0.713183]\n",
      "epoch:12 step:11480 [D loss: 0.721234, acc.: 39.84%] [G loss: 0.731127]\n",
      "epoch:12 step:11481 [D loss: 0.702303, acc.: 46.88%] [G loss: 0.767468]\n",
      "epoch:12 step:11482 [D loss: 0.694832, acc.: 54.69%] [G loss: 0.735874]\n",
      "epoch:12 step:11483 [D loss: 0.737739, acc.: 35.94%] [G loss: 0.811556]\n",
      "epoch:12 step:11484 [D loss: 0.687418, acc.: 44.53%] [G loss: 0.816510]\n",
      "epoch:12 step:11485 [D loss: 0.700265, acc.: 53.12%] [G loss: 0.804297]\n",
      "epoch:12 step:11486 [D loss: 0.685061, acc.: 57.03%] [G loss: 0.789079]\n",
      "epoch:12 step:11487 [D loss: 0.669916, acc.: 64.84%] [G loss: 0.807861]\n",
      "epoch:12 step:11488 [D loss: 0.669172, acc.: 61.72%] [G loss: 0.789037]\n",
      "epoch:12 step:11489 [D loss: 0.676180, acc.: 57.03%] [G loss: 0.816027]\n",
      "epoch:12 step:11490 [D loss: 0.671916, acc.: 63.28%] [G loss: 0.829357]\n",
      "epoch:12 step:11491 [D loss: 0.645387, acc.: 70.31%] [G loss: 0.876714]\n",
      "epoch:12 step:11492 [D loss: 0.636253, acc.: 64.84%] [G loss: 0.887984]\n",
      "epoch:12 step:11493 [D loss: 0.683340, acc.: 58.59%] [G loss: 0.865056]\n",
      "epoch:12 step:11494 [D loss: 0.645831, acc.: 60.94%] [G loss: 0.796350]\n",
      "epoch:12 step:11495 [D loss: 0.675675, acc.: 57.03%] [G loss: 0.819379]\n",
      "epoch:12 step:11496 [D loss: 0.672503, acc.: 60.94%] [G loss: 0.794579]\n",
      "epoch:12 step:11497 [D loss: 0.703287, acc.: 51.56%] [G loss: 0.750594]\n",
      "epoch:12 step:11498 [D loss: 0.714969, acc.: 46.09%] [G loss: 0.773950]\n",
      "epoch:12 step:11499 [D loss: 0.722398, acc.: 53.12%] [G loss: 0.794620]\n",
      "epoch:12 step:11500 [D loss: 0.723032, acc.: 44.53%] [G loss: 0.731255]\n",
      "epoch:12 step:11501 [D loss: 0.678116, acc.: 53.12%] [G loss: 0.739881]\n",
      "epoch:12 step:11502 [D loss: 0.672381, acc.: 60.94%] [G loss: 0.782633]\n",
      "epoch:12 step:11503 [D loss: 0.679999, acc.: 53.91%] [G loss: 0.793809]\n",
      "epoch:12 step:11504 [D loss: 0.698065, acc.: 49.22%] [G loss: 0.756215]\n",
      "epoch:12 step:11505 [D loss: 0.675034, acc.: 57.03%] [G loss: 0.766719]\n",
      "epoch:12 step:11506 [D loss: 0.661090, acc.: 60.16%] [G loss: 0.769671]\n",
      "epoch:12 step:11507 [D loss: 0.511416, acc.: 74.22%] [G loss: 0.804752]\n",
      "epoch:12 step:11508 [D loss: 0.678825, acc.: 57.03%] [G loss: 0.822511]\n",
      "epoch:12 step:11509 [D loss: 0.708541, acc.: 46.88%] [G loss: 0.723034]\n",
      "epoch:12 step:11510 [D loss: 0.697132, acc.: 51.56%] [G loss: 0.767570]\n",
      "epoch:12 step:11511 [D loss: 0.708705, acc.: 53.12%] [G loss: 0.811953]\n",
      "epoch:12 step:11512 [D loss: 0.695438, acc.: 53.12%] [G loss: 0.795688]\n",
      "epoch:12 step:11513 [D loss: 0.695394, acc.: 50.78%] [G loss: 0.741293]\n",
      "epoch:12 step:11514 [D loss: 0.714432, acc.: 42.97%] [G loss: 0.788900]\n",
      "epoch:12 step:11515 [D loss: 0.684878, acc.: 53.12%] [G loss: 0.730277]\n",
      "epoch:12 step:11516 [D loss: 0.696262, acc.: 55.47%] [G loss: 0.754440]\n",
      "epoch:12 step:11517 [D loss: 0.699401, acc.: 48.44%] [G loss: 0.718260]\n",
      "epoch:12 step:11518 [D loss: 0.651917, acc.: 59.38%] [G loss: 0.772939]\n",
      "epoch:12 step:11519 [D loss: 0.682244, acc.: 57.03%] [G loss: 0.783458]\n",
      "epoch:12 step:11520 [D loss: 0.654554, acc.: 57.81%] [G loss: 0.815655]\n",
      "epoch:12 step:11521 [D loss: 0.681120, acc.: 51.56%] [G loss: 0.702269]\n",
      "epoch:12 step:11522 [D loss: 0.704136, acc.: 53.91%] [G loss: 0.749744]\n",
      "epoch:12 step:11523 [D loss: 0.732812, acc.: 42.97%] [G loss: 0.739151]\n",
      "epoch:12 step:11524 [D loss: 0.670659, acc.: 60.94%] [G loss: 0.791476]\n",
      "epoch:12 step:11525 [D loss: 0.701789, acc.: 47.66%] [G loss: 0.715730]\n",
      "epoch:12 step:11526 [D loss: 0.709198, acc.: 48.44%] [G loss: 0.732869]\n",
      "epoch:12 step:11527 [D loss: 0.716189, acc.: 50.78%] [G loss: 0.774419]\n",
      "epoch:12 step:11528 [D loss: 0.668862, acc.: 62.50%] [G loss: 0.827158]\n",
      "epoch:12 step:11529 [D loss: 0.662307, acc.: 60.16%] [G loss: 0.803217]\n",
      "epoch:12 step:11530 [D loss: 0.631701, acc.: 67.97%] [G loss: 0.822439]\n",
      "epoch:12 step:11531 [D loss: 0.674050, acc.: 61.72%] [G loss: 0.794117]\n",
      "epoch:12 step:11532 [D loss: 0.639884, acc.: 67.97%] [G loss: 0.845448]\n",
      "epoch:12 step:11533 [D loss: 0.650748, acc.: 64.84%] [G loss: 0.736493]\n",
      "epoch:12 step:11534 [D loss: 0.654291, acc.: 65.62%] [G loss: 0.734493]\n",
      "epoch:12 step:11535 [D loss: 0.691987, acc.: 53.12%] [G loss: 0.822698]\n",
      "epoch:12 step:11536 [D loss: 0.652997, acc.: 65.62%] [G loss: 0.850869]\n",
      "epoch:12 step:11537 [D loss: 0.700532, acc.: 49.22%] [G loss: 0.659764]\n",
      "epoch:12 step:11538 [D loss: 0.697226, acc.: 50.78%] [G loss: 0.759969]\n",
      "epoch:12 step:11539 [D loss: 0.732004, acc.: 46.09%] [G loss: 0.699327]\n",
      "epoch:12 step:11540 [D loss: 0.685224, acc.: 55.47%] [G loss: 0.803144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11541 [D loss: 0.728238, acc.: 40.62%] [G loss: 0.779092]\n",
      "epoch:12 step:11542 [D loss: 0.732197, acc.: 42.19%] [G loss: 0.745010]\n",
      "epoch:12 step:11543 [D loss: 0.716837, acc.: 42.19%] [G loss: 0.779495]\n",
      "epoch:12 step:11544 [D loss: 0.709310, acc.: 47.66%] [G loss: 0.809418]\n",
      "epoch:12 step:11545 [D loss: 0.694796, acc.: 57.03%] [G loss: 0.786029]\n",
      "epoch:12 step:11546 [D loss: 0.697791, acc.: 47.66%] [G loss: 0.753608]\n",
      "epoch:12 step:11547 [D loss: 0.699136, acc.: 52.34%] [G loss: 0.747625]\n",
      "epoch:12 step:11548 [D loss: 0.700543, acc.: 45.31%] [G loss: 0.721527]\n",
      "epoch:12 step:11549 [D loss: 0.703049, acc.: 50.00%] [G loss: 0.722327]\n",
      "epoch:12 step:11550 [D loss: 0.698889, acc.: 46.88%] [G loss: 0.712225]\n",
      "epoch:12 step:11551 [D loss: 0.676887, acc.: 54.69%] [G loss: 0.753647]\n",
      "epoch:12 step:11552 [D loss: 0.698099, acc.: 54.69%] [G loss: 0.738874]\n",
      "epoch:12 step:11553 [D loss: 0.678033, acc.: 57.03%] [G loss: 0.726948]\n",
      "epoch:12 step:11554 [D loss: 0.677682, acc.: 52.34%] [G loss: 0.730376]\n",
      "epoch:12 step:11555 [D loss: 0.690424, acc.: 49.22%] [G loss: 0.735097]\n",
      "epoch:12 step:11556 [D loss: 0.682266, acc.: 58.59%] [G loss: 0.719940]\n",
      "epoch:12 step:11557 [D loss: 0.662578, acc.: 61.72%] [G loss: 0.759662]\n",
      "epoch:12 step:11558 [D loss: 0.651710, acc.: 59.38%] [G loss: 0.743304]\n",
      "epoch:12 step:11559 [D loss: 0.669903, acc.: 61.72%] [G loss: 0.741806]\n",
      "epoch:12 step:11560 [D loss: 0.688503, acc.: 50.00%] [G loss: 0.707021]\n",
      "epoch:12 step:11561 [D loss: 0.704643, acc.: 50.00%] [G loss: 0.762668]\n",
      "epoch:12 step:11562 [D loss: 0.703651, acc.: 49.22%] [G loss: 0.739899]\n",
      "epoch:12 step:11563 [D loss: 0.672986, acc.: 57.03%] [G loss: 0.752866]\n",
      "epoch:12 step:11564 [D loss: 0.706569, acc.: 44.53%] [G loss: 0.739239]\n",
      "epoch:12 step:11565 [D loss: 0.696236, acc.: 57.03%] [G loss: 0.762149]\n",
      "epoch:12 step:11566 [D loss: 0.679773, acc.: 47.66%] [G loss: 0.754757]\n",
      "epoch:12 step:11567 [D loss: 0.680614, acc.: 55.47%] [G loss: 0.774176]\n",
      "epoch:12 step:11568 [D loss: 0.670948, acc.: 55.47%] [G loss: 0.724519]\n",
      "epoch:12 step:11569 [D loss: 0.666513, acc.: 57.81%] [G loss: 0.747977]\n",
      "epoch:12 step:11570 [D loss: 0.682304, acc.: 54.69%] [G loss: 0.730718]\n",
      "epoch:12 step:11571 [D loss: 0.668777, acc.: 62.50%] [G loss: 0.705242]\n",
      "epoch:12 step:11572 [D loss: 0.670574, acc.: 59.38%] [G loss: 0.758407]\n",
      "epoch:12 step:11573 [D loss: 0.677370, acc.: 56.25%] [G loss: 0.673310]\n",
      "epoch:12 step:11574 [D loss: 0.729527, acc.: 45.31%] [G loss: 0.666411]\n",
      "epoch:12 step:11575 [D loss: 0.702779, acc.: 53.12%] [G loss: 0.758354]\n",
      "epoch:12 step:11576 [D loss: 0.725186, acc.: 41.41%] [G loss: 0.720315]\n",
      "epoch:12 step:11577 [D loss: 0.701933, acc.: 50.78%] [G loss: 0.729838]\n",
      "epoch:12 step:11578 [D loss: 0.734402, acc.: 42.97%] [G loss: 0.733503]\n",
      "epoch:12 step:11579 [D loss: 0.692857, acc.: 50.78%] [G loss: 0.729594]\n",
      "epoch:12 step:11580 [D loss: 0.674463, acc.: 60.94%] [G loss: 0.721177]\n",
      "epoch:12 step:11581 [D loss: 0.684500, acc.: 58.59%] [G loss: 0.738815]\n",
      "epoch:12 step:11582 [D loss: 0.677204, acc.: 56.25%] [G loss: 0.726310]\n",
      "epoch:12 step:11583 [D loss: 0.667583, acc.: 59.38%] [G loss: 0.790256]\n",
      "epoch:12 step:11584 [D loss: 0.678536, acc.: 53.91%] [G loss: 0.717692]\n",
      "epoch:12 step:11585 [D loss: 0.689400, acc.: 50.78%] [G loss: 0.725681]\n",
      "epoch:12 step:11586 [D loss: 0.677890, acc.: 57.03%] [G loss: 0.745151]\n",
      "epoch:12 step:11587 [D loss: 0.660751, acc.: 64.06%] [G loss: 0.745295]\n",
      "epoch:12 step:11588 [D loss: 0.658437, acc.: 61.72%] [G loss: 0.776299]\n",
      "epoch:12 step:11589 [D loss: 0.660101, acc.: 66.41%] [G loss: 0.727604]\n",
      "epoch:12 step:11590 [D loss: 0.613413, acc.: 74.22%] [G loss: 0.739828]\n",
      "epoch:12 step:11591 [D loss: 0.663533, acc.: 57.03%] [G loss: 0.751496]\n",
      "epoch:12 step:11592 [D loss: 0.689713, acc.: 45.31%] [G loss: 0.757658]\n",
      "epoch:12 step:11593 [D loss: 0.688676, acc.: 50.78%] [G loss: 0.769079]\n",
      "epoch:12 step:11594 [D loss: 0.683576, acc.: 53.91%] [G loss: 0.728373]\n",
      "epoch:12 step:11595 [D loss: 0.705198, acc.: 48.44%] [G loss: 0.800355]\n",
      "epoch:12 step:11596 [D loss: 0.702200, acc.: 50.00%] [G loss: 0.724234]\n",
      "epoch:12 step:11597 [D loss: 0.718365, acc.: 48.44%] [G loss: 0.685094]\n",
      "epoch:12 step:11598 [D loss: 0.707410, acc.: 52.34%] [G loss: 0.725893]\n",
      "epoch:12 step:11599 [D loss: 0.733635, acc.: 50.78%] [G loss: 0.715972]\n",
      "epoch:12 step:11600 [D loss: 0.703755, acc.: 45.31%] [G loss: 0.739436]\n",
      "epoch:12 step:11601 [D loss: 0.705880, acc.: 42.97%] [G loss: 0.765550]\n",
      "epoch:12 step:11602 [D loss: 0.676359, acc.: 57.03%] [G loss: 0.738906]\n",
      "epoch:12 step:11603 [D loss: 0.674497, acc.: 61.72%] [G loss: 0.727652]\n",
      "epoch:12 step:11604 [D loss: 0.696444, acc.: 47.66%] [G loss: 0.729516]\n",
      "epoch:12 step:11605 [D loss: 0.663036, acc.: 57.81%] [G loss: 0.755377]\n",
      "epoch:12 step:11606 [D loss: 0.685983, acc.: 46.09%] [G loss: 0.746880]\n",
      "epoch:12 step:11607 [D loss: 0.681604, acc.: 57.03%] [G loss: 0.799446]\n",
      "epoch:12 step:11608 [D loss: 0.668206, acc.: 59.38%] [G loss: 0.777304]\n",
      "epoch:12 step:11609 [D loss: 0.707221, acc.: 48.44%] [G loss: 0.724380]\n",
      "epoch:12 step:11610 [D loss: 0.698182, acc.: 52.34%] [G loss: 0.770246]\n",
      "epoch:12 step:11611 [D loss: 0.688483, acc.: 60.16%] [G loss: 0.765557]\n",
      "epoch:12 step:11612 [D loss: 0.696042, acc.: 50.78%] [G loss: 0.731823]\n",
      "epoch:12 step:11613 [D loss: 0.678311, acc.: 55.47%] [G loss: 0.768957]\n",
      "epoch:12 step:11614 [D loss: 0.652092, acc.: 66.41%] [G loss: 0.779326]\n",
      "epoch:12 step:11615 [D loss: 0.601966, acc.: 64.06%] [G loss: 0.811331]\n",
      "epoch:12 step:11616 [D loss: 0.624282, acc.: 69.53%] [G loss: 0.709518]\n",
      "epoch:12 step:11617 [D loss: 0.711909, acc.: 48.44%] [G loss: 0.746926]\n",
      "epoch:12 step:11618 [D loss: 0.679848, acc.: 56.25%] [G loss: 0.708006]\n",
      "epoch:12 step:11619 [D loss: 0.674011, acc.: 58.59%] [G loss: 0.707144]\n",
      "epoch:12 step:11620 [D loss: 0.634918, acc.: 60.16%] [G loss: 0.719740]\n",
      "epoch:12 step:11621 [D loss: 0.735445, acc.: 45.31%] [G loss: 0.773932]\n",
      "epoch:12 step:11622 [D loss: 0.688541, acc.: 57.81%] [G loss: 0.684474]\n",
      "epoch:12 step:11623 [D loss: 0.685510, acc.: 53.12%] [G loss: 0.804616]\n",
      "epoch:12 step:11624 [D loss: 0.646144, acc.: 59.38%] [G loss: 0.711896]\n",
      "epoch:12 step:11625 [D loss: 0.643458, acc.: 67.19%] [G loss: 0.710156]\n",
      "epoch:12 step:11626 [D loss: 0.692313, acc.: 54.69%] [G loss: 0.826189]\n",
      "epoch:12 step:11627 [D loss: 0.676705, acc.: 59.38%] [G loss: 0.763873]\n",
      "epoch:12 step:11628 [D loss: 0.741013, acc.: 45.31%] [G loss: 0.761188]\n",
      "epoch:12 step:11629 [D loss: 0.683262, acc.: 54.69%] [G loss: 0.719255]\n",
      "epoch:12 step:11630 [D loss: 0.668125, acc.: 60.16%] [G loss: 0.771436]\n",
      "epoch:12 step:11631 [D loss: 0.663703, acc.: 62.50%] [G loss: 0.758183]\n",
      "epoch:12 step:11632 [D loss: 0.662240, acc.: 63.28%] [G loss: 0.669361]\n",
      "epoch:12 step:11633 [D loss: 0.693690, acc.: 52.34%] [G loss: 0.743519]\n",
      "epoch:12 step:11634 [D loss: 0.756596, acc.: 35.94%] [G loss: 0.775786]\n",
      "epoch:12 step:11635 [D loss: 0.674438, acc.: 61.72%] [G loss: 0.676877]\n",
      "epoch:12 step:11636 [D loss: 0.735830, acc.: 33.59%] [G loss: 0.742265]\n",
      "epoch:12 step:11637 [D loss: 0.744099, acc.: 38.28%] [G loss: 0.731188]\n",
      "epoch:12 step:11638 [D loss: 0.692775, acc.: 46.88%] [G loss: 0.738173]\n",
      "epoch:12 step:11639 [D loss: 0.698197, acc.: 50.00%] [G loss: 0.788656]\n",
      "epoch:12 step:11640 [D loss: 0.672374, acc.: 63.28%] [G loss: 0.744146]\n",
      "epoch:12 step:11641 [D loss: 0.691891, acc.: 47.66%] [G loss: 0.758766]\n",
      "epoch:12 step:11642 [D loss: 0.648679, acc.: 65.62%] [G loss: 0.786097]\n",
      "epoch:12 step:11643 [D loss: 0.656165, acc.: 62.50%] [G loss: 0.798682]\n",
      "epoch:12 step:11644 [D loss: 0.659663, acc.: 61.72%] [G loss: 0.795936]\n",
      "epoch:12 step:11645 [D loss: 0.701046, acc.: 47.66%] [G loss: 0.773212]\n",
      "epoch:12 step:11646 [D loss: 0.656083, acc.: 63.28%] [G loss: 0.755643]\n",
      "epoch:12 step:11647 [D loss: 0.637062, acc.: 67.19%] [G loss: 0.828208]\n",
      "epoch:12 step:11648 [D loss: 0.645065, acc.: 62.50%] [G loss: 0.781489]\n",
      "epoch:12 step:11649 [D loss: 0.631714, acc.: 64.06%] [G loss: 0.801830]\n",
      "epoch:12 step:11650 [D loss: 0.643771, acc.: 62.50%] [G loss: 0.754134]\n",
      "epoch:12 step:11651 [D loss: 0.663513, acc.: 63.28%] [G loss: 0.751897]\n",
      "epoch:12 step:11652 [D loss: 0.719682, acc.: 48.44%] [G loss: 0.782306]\n",
      "epoch:12 step:11653 [D loss: 0.635377, acc.: 67.97%] [G loss: 0.826607]\n",
      "epoch:12 step:11654 [D loss: 0.713126, acc.: 53.91%] [G loss: 0.810603]\n",
      "epoch:12 step:11655 [D loss: 0.740064, acc.: 43.75%] [G loss: 0.842309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11656 [D loss: 0.684295, acc.: 55.47%] [G loss: 0.779752]\n",
      "epoch:12 step:11657 [D loss: 0.654462, acc.: 58.59%] [G loss: 0.795569]\n",
      "epoch:12 step:11658 [D loss: 0.713968, acc.: 47.66%] [G loss: 0.863976]\n",
      "epoch:12 step:11659 [D loss: 0.671473, acc.: 62.50%] [G loss: 0.813519]\n",
      "epoch:12 step:11660 [D loss: 0.682705, acc.: 51.56%] [G loss: 0.739040]\n",
      "epoch:12 step:11661 [D loss: 0.685999, acc.: 56.25%] [G loss: 0.804212]\n",
      "epoch:12 step:11662 [D loss: 0.706040, acc.: 51.56%] [G loss: 0.731013]\n",
      "epoch:12 step:11663 [D loss: 0.692824, acc.: 57.81%] [G loss: 0.773554]\n",
      "epoch:12 step:11664 [D loss: 0.709174, acc.: 41.41%] [G loss: 0.803674]\n",
      "epoch:12 step:11665 [D loss: 0.715896, acc.: 45.31%] [G loss: 0.795579]\n",
      "epoch:12 step:11666 [D loss: 0.761569, acc.: 32.81%] [G loss: 0.735783]\n",
      "epoch:12 step:11667 [D loss: 0.718561, acc.: 46.88%] [G loss: 0.751573]\n",
      "epoch:12 step:11668 [D loss: 0.668774, acc.: 59.38%] [G loss: 0.757200]\n",
      "epoch:12 step:11669 [D loss: 0.669359, acc.: 55.47%] [G loss: 0.760930]\n",
      "epoch:12 step:11670 [D loss: 0.661780, acc.: 64.06%] [G loss: 0.822352]\n",
      "epoch:12 step:11671 [D loss: 0.665648, acc.: 60.16%] [G loss: 0.722576]\n",
      "epoch:12 step:11672 [D loss: 0.650229, acc.: 60.94%] [G loss: 0.793200]\n",
      "epoch:12 step:11673 [D loss: 0.655897, acc.: 62.50%] [G loss: 0.776475]\n",
      "epoch:12 step:11674 [D loss: 0.659854, acc.: 65.62%] [G loss: 0.786217]\n",
      "epoch:12 step:11675 [D loss: 0.670902, acc.: 57.03%] [G loss: 0.780642]\n",
      "epoch:12 step:11676 [D loss: 0.753050, acc.: 39.84%] [G loss: 0.760386]\n",
      "epoch:12 step:11677 [D loss: 0.673050, acc.: 57.03%] [G loss: 0.749905]\n",
      "epoch:12 step:11678 [D loss: 0.687567, acc.: 58.59%] [G loss: 0.743637]\n",
      "epoch:12 step:11679 [D loss: 0.677831, acc.: 60.16%] [G loss: 0.768461]\n",
      "epoch:12 step:11680 [D loss: 0.652403, acc.: 64.06%] [G loss: 0.756957]\n",
      "epoch:12 step:11681 [D loss: 0.731148, acc.: 42.19%] [G loss: 0.757570]\n",
      "epoch:12 step:11682 [D loss: 0.720196, acc.: 46.09%] [G loss: 0.759337]\n",
      "epoch:12 step:11683 [D loss: 0.739867, acc.: 37.50%] [G loss: 0.733375]\n",
      "epoch:12 step:11684 [D loss: 0.706759, acc.: 52.34%] [G loss: 0.786505]\n",
      "epoch:12 step:11685 [D loss: 0.700119, acc.: 53.91%] [G loss: 0.808275]\n",
      "epoch:12 step:11686 [D loss: 0.672132, acc.: 62.50%] [G loss: 0.807596]\n",
      "epoch:12 step:11687 [D loss: 0.660403, acc.: 60.94%] [G loss: 0.831982]\n",
      "epoch:12 step:11688 [D loss: 0.653868, acc.: 67.97%] [G loss: 0.818577]\n",
      "epoch:12 step:11689 [D loss: 0.635014, acc.: 67.97%] [G loss: 0.792617]\n",
      "epoch:12 step:11690 [D loss: 0.640596, acc.: 65.62%] [G loss: 0.841081]\n",
      "epoch:12 step:11691 [D loss: 0.645224, acc.: 64.84%] [G loss: 0.808781]\n",
      "epoch:12 step:11692 [D loss: 0.691423, acc.: 55.47%] [G loss: 0.857370]\n",
      "epoch:12 step:11693 [D loss: 0.669072, acc.: 60.16%] [G loss: 0.832976]\n",
      "epoch:12 step:11694 [D loss: 0.680460, acc.: 63.28%] [G loss: 0.778800]\n",
      "epoch:12 step:11695 [D loss: 0.660872, acc.: 59.38%] [G loss: 0.815676]\n",
      "epoch:12 step:11696 [D loss: 0.665686, acc.: 60.94%] [G loss: 0.780011]\n",
      "epoch:12 step:11697 [D loss: 0.650170, acc.: 60.94%] [G loss: 0.719061]\n",
      "epoch:12 step:11698 [D loss: 0.681965, acc.: 55.47%] [G loss: 0.680309]\n",
      "epoch:12 step:11699 [D loss: 0.701995, acc.: 45.31%] [G loss: 0.760693]\n",
      "epoch:12 step:11700 [D loss: 0.555121, acc.: 68.75%] [G loss: 0.880844]\n",
      "epoch:12 step:11701 [D loss: 0.599668, acc.: 75.78%] [G loss: 0.763391]\n",
      "epoch:12 step:11702 [D loss: 0.695222, acc.: 54.69%] [G loss: 0.934044]\n",
      "epoch:12 step:11703 [D loss: 0.655837, acc.: 59.38%] [G loss: 0.821250]\n",
      "epoch:12 step:11704 [D loss: 0.713260, acc.: 49.22%] [G loss: 0.760594]\n",
      "epoch:12 step:11705 [D loss: 1.042924, acc.: 26.56%] [G loss: 0.764566]\n",
      "epoch:12 step:11706 [D loss: 0.748252, acc.: 45.31%] [G loss: 0.873064]\n",
      "epoch:12 step:11707 [D loss: 0.691981, acc.: 52.34%] [G loss: 0.831058]\n",
      "epoch:12 step:11708 [D loss: 0.675647, acc.: 50.78%] [G loss: 0.827652]\n",
      "epoch:12 step:11709 [D loss: 0.701779, acc.: 50.78%] [G loss: 0.777218]\n",
      "epoch:12 step:11710 [D loss: 0.704332, acc.: 54.69%] [G loss: 0.755345]\n",
      "epoch:12 step:11711 [D loss: 0.694803, acc.: 47.66%] [G loss: 0.737781]\n",
      "epoch:12 step:11712 [D loss: 0.664352, acc.: 62.50%] [G loss: 0.722245]\n",
      "epoch:12 step:11713 [D loss: 0.716746, acc.: 46.88%] [G loss: 0.729019]\n",
      "epoch:12 step:11714 [D loss: 0.651936, acc.: 54.69%] [G loss: 0.693018]\n",
      "epoch:12 step:11715 [D loss: 0.697411, acc.: 59.38%] [G loss: 0.691120]\n",
      "epoch:12 step:11716 [D loss: 0.730984, acc.: 47.66%] [G loss: 0.661568]\n",
      "epoch:12 step:11717 [D loss: 0.727519, acc.: 35.94%] [G loss: 0.730281]\n",
      "epoch:12 step:11718 [D loss: 0.738992, acc.: 30.47%] [G loss: 0.717181]\n",
      "epoch:12 step:11719 [D loss: 0.693702, acc.: 50.00%] [G loss: 0.733609]\n",
      "epoch:12 step:11720 [D loss: 0.679655, acc.: 57.81%] [G loss: 0.753546]\n",
      "epoch:12 step:11721 [D loss: 0.684436, acc.: 58.59%] [G loss: 0.784760]\n",
      "epoch:12 step:11722 [D loss: 0.666716, acc.: 60.94%] [G loss: 0.778442]\n",
      "epoch:12 step:11723 [D loss: 0.700112, acc.: 56.25%] [G loss: 0.783352]\n",
      "epoch:12 step:11724 [D loss: 0.692823, acc.: 55.47%] [G loss: 0.773199]\n",
      "epoch:12 step:11725 [D loss: 0.689931, acc.: 57.81%] [G loss: 0.747106]\n",
      "epoch:12 step:11726 [D loss: 0.700430, acc.: 53.91%] [G loss: 0.766979]\n",
      "epoch:12 step:11727 [D loss: 0.691759, acc.: 58.59%] [G loss: 0.753827]\n",
      "epoch:12 step:11728 [D loss: 0.668645, acc.: 63.28%] [G loss: 0.768353]\n",
      "epoch:12 step:11729 [D loss: 0.669118, acc.: 64.06%] [G loss: 0.743868]\n",
      "epoch:12 step:11730 [D loss: 0.667311, acc.: 60.94%] [G loss: 0.760388]\n",
      "epoch:12 step:11731 [D loss: 0.679760, acc.: 53.91%] [G loss: 0.830346]\n",
      "epoch:12 step:11732 [D loss: 0.680991, acc.: 53.12%] [G loss: 0.798899]\n",
      "epoch:12 step:11733 [D loss: 0.713171, acc.: 50.00%] [G loss: 0.736785]\n",
      "epoch:12 step:11734 [D loss: 0.688721, acc.: 50.78%] [G loss: 0.740268]\n",
      "epoch:12 step:11735 [D loss: 0.670782, acc.: 57.81%] [G loss: 0.759161]\n",
      "epoch:12 step:11736 [D loss: 0.704927, acc.: 44.53%] [G loss: 0.755484]\n",
      "epoch:12 step:11737 [D loss: 0.713375, acc.: 46.88%] [G loss: 0.755800]\n",
      "epoch:12 step:11738 [D loss: 0.684377, acc.: 54.69%] [G loss: 0.728073]\n",
      "epoch:12 step:11739 [D loss: 0.656803, acc.: 69.53%] [G loss: 0.757595]\n",
      "epoch:12 step:11740 [D loss: 0.685168, acc.: 59.38%] [G loss: 0.745380]\n",
      "epoch:12 step:11741 [D loss: 0.667664, acc.: 59.38%] [G loss: 0.725873]\n",
      "epoch:12 step:11742 [D loss: 0.661418, acc.: 58.59%] [G loss: 0.761242]\n",
      "epoch:12 step:11743 [D loss: 0.643358, acc.: 67.19%] [G loss: 0.791483]\n",
      "epoch:12 step:11744 [D loss: 0.685926, acc.: 55.47%] [G loss: 0.801363]\n",
      "epoch:12 step:11745 [D loss: 0.765651, acc.: 32.81%] [G loss: 0.762709]\n",
      "epoch:12 step:11746 [D loss: 0.691824, acc.: 53.12%] [G loss: 0.737265]\n",
      "epoch:12 step:11747 [D loss: 0.714074, acc.: 42.19%] [G loss: 0.756268]\n",
      "epoch:12 step:11748 [D loss: 0.684301, acc.: 55.47%] [G loss: 0.730864]\n",
      "epoch:12 step:11749 [D loss: 0.669898, acc.: 61.72%] [G loss: 0.745567]\n",
      "epoch:12 step:11750 [D loss: 0.706457, acc.: 47.66%] [G loss: 0.737211]\n",
      "epoch:12 step:11751 [D loss: 0.673215, acc.: 54.69%] [G loss: 0.766931]\n",
      "epoch:12 step:11752 [D loss: 0.659735, acc.: 60.16%] [G loss: 0.746292]\n",
      "epoch:12 step:11753 [D loss: 0.691668, acc.: 57.81%] [G loss: 0.727815]\n",
      "epoch:12 step:11754 [D loss: 0.705336, acc.: 46.09%] [G loss: 0.753997]\n",
      "epoch:12 step:11755 [D loss: 0.904003, acc.: 41.41%] [G loss: 0.786617]\n",
      "epoch:12 step:11756 [D loss: 0.697577, acc.: 55.47%] [G loss: 0.861984]\n",
      "epoch:12 step:11757 [D loss: 0.680592, acc.: 56.25%] [G loss: 0.834983]\n",
      "epoch:12 step:11758 [D loss: 0.694916, acc.: 49.22%] [G loss: 0.766718]\n",
      "epoch:12 step:11759 [D loss: 0.654892, acc.: 62.50%] [G loss: 0.866759]\n",
      "epoch:12 step:11760 [D loss: 0.695470, acc.: 57.03%] [G loss: 0.763744]\n",
      "epoch:12 step:11761 [D loss: 0.730828, acc.: 40.62%] [G loss: 0.723731]\n",
      "epoch:12 step:11762 [D loss: 0.707964, acc.: 46.09%] [G loss: 0.806078]\n",
      "epoch:12 step:11763 [D loss: 0.687584, acc.: 50.00%] [G loss: 0.708952]\n",
      "epoch:12 step:11764 [D loss: 0.693412, acc.: 45.31%] [G loss: 0.746965]\n",
      "epoch:12 step:11765 [D loss: 0.707516, acc.: 47.66%] [G loss: 0.719534]\n",
      "epoch:12 step:11766 [D loss: 0.715782, acc.: 43.75%] [G loss: 0.747932]\n",
      "epoch:12 step:11767 [D loss: 0.691295, acc.: 50.78%] [G loss: 0.728074]\n",
      "epoch:12 step:11768 [D loss: 0.695581, acc.: 51.56%] [G loss: 0.764642]\n",
      "epoch:12 step:11769 [D loss: 0.677895, acc.: 62.50%] [G loss: 0.728253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11770 [D loss: 0.699091, acc.: 50.78%] [G loss: 0.736363]\n",
      "epoch:12 step:11771 [D loss: 0.696199, acc.: 49.22%] [G loss: 0.727967]\n",
      "epoch:12 step:11772 [D loss: 0.703032, acc.: 46.88%] [G loss: 0.706829]\n",
      "epoch:12 step:11773 [D loss: 0.693074, acc.: 53.91%] [G loss: 0.744410]\n",
      "epoch:12 step:11774 [D loss: 0.678042, acc.: 57.03%] [G loss: 0.720336]\n",
      "epoch:12 step:11775 [D loss: 0.700291, acc.: 48.44%] [G loss: 0.755694]\n",
      "epoch:12 step:11776 [D loss: 0.693810, acc.: 50.00%] [G loss: 0.734002]\n",
      "epoch:12 step:11777 [D loss: 0.702387, acc.: 48.44%] [G loss: 0.749691]\n",
      "epoch:12 step:11778 [D loss: 0.681308, acc.: 57.81%] [G loss: 0.740051]\n",
      "epoch:12 step:11779 [D loss: 0.691207, acc.: 54.69%] [G loss: 0.735628]\n",
      "epoch:12 step:11780 [D loss: 0.683905, acc.: 56.25%] [G loss: 0.717510]\n",
      "epoch:12 step:11781 [D loss: 0.703206, acc.: 53.12%] [G loss: 0.726735]\n",
      "epoch:12 step:11782 [D loss: 0.688185, acc.: 53.91%] [G loss: 0.735093]\n",
      "epoch:12 step:11783 [D loss: 0.689261, acc.: 58.59%] [G loss: 0.720661]\n",
      "epoch:12 step:11784 [D loss: 0.695432, acc.: 51.56%] [G loss: 0.747631]\n",
      "epoch:12 step:11785 [D loss: 0.673982, acc.: 57.03%] [G loss: 0.752836]\n",
      "epoch:12 step:11786 [D loss: 0.710314, acc.: 48.44%] [G loss: 0.719345]\n",
      "epoch:12 step:11787 [D loss: 0.664801, acc.: 54.69%] [G loss: 0.799863]\n",
      "epoch:12 step:11788 [D loss: 0.727789, acc.: 50.78%] [G loss: 0.711553]\n",
      "epoch:12 step:11789 [D loss: 0.691321, acc.: 55.47%] [G loss: 0.702376]\n",
      "epoch:12 step:11790 [D loss: 0.696100, acc.: 53.12%] [G loss: 0.758617]\n",
      "epoch:12 step:11791 [D loss: 0.703799, acc.: 53.12%] [G loss: 0.732464]\n",
      "epoch:12 step:11792 [D loss: 0.660683, acc.: 56.25%] [G loss: 0.719728]\n",
      "epoch:12 step:11793 [D loss: 0.668838, acc.: 64.06%] [G loss: 0.689309]\n",
      "epoch:12 step:11794 [D loss: 0.532404, acc.: 71.09%] [G loss: 0.698307]\n",
      "epoch:12 step:11795 [D loss: 0.636928, acc.: 68.75%] [G loss: 0.704645]\n",
      "epoch:12 step:11796 [D loss: 0.665831, acc.: 60.16%] [G loss: 0.738390]\n",
      "epoch:12 step:11797 [D loss: 0.712185, acc.: 46.09%] [G loss: 0.701575]\n",
      "epoch:12 step:11798 [D loss: 0.649408, acc.: 64.06%] [G loss: 0.729459]\n",
      "epoch:12 step:11799 [D loss: 0.669572, acc.: 57.03%] [G loss: 0.749562]\n",
      "epoch:12 step:11800 [D loss: 0.658479, acc.: 55.47%] [G loss: 0.718128]\n",
      "epoch:12 step:11801 [D loss: 0.671126, acc.: 55.47%] [G loss: 0.674198]\n",
      "epoch:12 step:11802 [D loss: 0.659917, acc.: 61.72%] [G loss: 0.705991]\n",
      "epoch:12 step:11803 [D loss: 0.775552, acc.: 28.12%] [G loss: 0.736339]\n",
      "epoch:12 step:11804 [D loss: 0.722177, acc.: 39.06%] [G loss: 0.522452]\n",
      "epoch:12 step:11805 [D loss: 0.710538, acc.: 44.53%] [G loss: 0.744571]\n",
      "epoch:12 step:11806 [D loss: 0.693531, acc.: 46.09%] [G loss: 0.721246]\n",
      "epoch:12 step:11807 [D loss: 1.048291, acc.: 35.94%] [G loss: 0.791912]\n",
      "epoch:12 step:11808 [D loss: 0.678901, acc.: 56.25%] [G loss: 0.815346]\n",
      "epoch:12 step:11809 [D loss: 0.687458, acc.: 53.12%] [G loss: 0.824835]\n",
      "epoch:12 step:11810 [D loss: 0.663701, acc.: 53.91%] [G loss: 0.828468]\n",
      "epoch:12 step:11811 [D loss: 0.665272, acc.: 63.28%] [G loss: 0.920828]\n",
      "epoch:12 step:11812 [D loss: 0.589061, acc.: 71.09%] [G loss: 0.843573]\n",
      "epoch:12 step:11813 [D loss: 0.681514, acc.: 57.81%] [G loss: 0.776504]\n",
      "epoch:12 step:11814 [D loss: 0.692661, acc.: 52.34%] [G loss: 0.860989]\n",
      "epoch:12 step:11815 [D loss: 0.695632, acc.: 49.22%] [G loss: 0.896939]\n",
      "epoch:12 step:11816 [D loss: 0.704557, acc.: 51.56%] [G loss: 0.800405]\n",
      "epoch:12 step:11817 [D loss: 0.681671, acc.: 52.34%] [G loss: 0.837488]\n",
      "epoch:12 step:11818 [D loss: 0.682142, acc.: 54.69%] [G loss: 0.737075]\n",
      "epoch:12 step:11819 [D loss: 0.684068, acc.: 56.25%] [G loss: 0.764446]\n",
      "epoch:12 step:11820 [D loss: 0.683015, acc.: 52.34%] [G loss: 0.755713]\n",
      "epoch:12 step:11821 [D loss: 0.669908, acc.: 58.59%] [G loss: 0.727164]\n",
      "epoch:12 step:11822 [D loss: 0.653299, acc.: 63.28%] [G loss: 0.770277]\n",
      "epoch:12 step:11823 [D loss: 0.667607, acc.: 60.94%] [G loss: 0.729557]\n",
      "epoch:12 step:11824 [D loss: 0.705335, acc.: 50.78%] [G loss: 0.718881]\n",
      "epoch:12 step:11825 [D loss: 0.705786, acc.: 49.22%] [G loss: 0.770803]\n",
      "epoch:12 step:11826 [D loss: 0.683679, acc.: 58.59%] [G loss: 0.734591]\n",
      "epoch:12 step:11827 [D loss: 0.692219, acc.: 55.47%] [G loss: 0.722093]\n",
      "epoch:12 step:11828 [D loss: 0.748987, acc.: 42.19%] [G loss: 0.711033]\n",
      "epoch:12 step:11829 [D loss: 0.683093, acc.: 51.56%] [G loss: 0.749143]\n",
      "epoch:12 step:11830 [D loss: 0.673321, acc.: 54.69%] [G loss: 0.719050]\n",
      "epoch:12 step:11831 [D loss: 0.690911, acc.: 53.12%] [G loss: 0.733089]\n",
      "epoch:12 step:11832 [D loss: 0.679606, acc.: 55.47%] [G loss: 0.726955]\n",
      "epoch:12 step:11833 [D loss: 0.672670, acc.: 57.81%] [G loss: 0.747721]\n",
      "epoch:12 step:11834 [D loss: 0.695780, acc.: 48.44%] [G loss: 0.731270]\n",
      "epoch:12 step:11835 [D loss: 0.671357, acc.: 63.28%] [G loss: 0.750705]\n",
      "epoch:12 step:11836 [D loss: 0.707972, acc.: 49.22%] [G loss: 0.768188]\n",
      "epoch:12 step:11837 [D loss: 0.687505, acc.: 55.47%] [G loss: 0.791850]\n",
      "epoch:12 step:11838 [D loss: 0.680995, acc.: 60.16%] [G loss: 0.746801]\n",
      "epoch:12 step:11839 [D loss: 0.666772, acc.: 60.94%] [G loss: 0.740334]\n",
      "epoch:12 step:11840 [D loss: 0.686480, acc.: 52.34%] [G loss: 0.746974]\n",
      "epoch:12 step:11841 [D loss: 0.685575, acc.: 57.03%] [G loss: 0.752477]\n",
      "epoch:12 step:11842 [D loss: 0.677287, acc.: 54.69%] [G loss: 0.722882]\n",
      "epoch:12 step:11843 [D loss: 0.700967, acc.: 47.66%] [G loss: 0.750093]\n",
      "epoch:12 step:11844 [D loss: 0.695367, acc.: 50.00%] [G loss: 0.762878]\n",
      "epoch:12 step:11845 [D loss: 0.670176, acc.: 57.81%] [G loss: 0.717644]\n",
      "epoch:12 step:11846 [D loss: 0.669292, acc.: 57.03%] [G loss: 0.717074]\n",
      "epoch:12 step:11847 [D loss: 0.702656, acc.: 48.44%] [G loss: 0.724583]\n",
      "epoch:12 step:11848 [D loss: 0.593869, acc.: 64.84%] [G loss: 0.757433]\n",
      "epoch:12 step:11849 [D loss: 0.714466, acc.: 51.56%] [G loss: 0.765091]\n",
      "epoch:12 step:11850 [D loss: 0.692562, acc.: 51.56%] [G loss: 0.789630]\n",
      "epoch:12 step:11851 [D loss: 0.701008, acc.: 51.56%] [G loss: 0.826911]\n",
      "epoch:12 step:11852 [D loss: 0.668567, acc.: 62.50%] [G loss: 0.788957]\n",
      "epoch:12 step:11853 [D loss: 0.685637, acc.: 53.12%] [G loss: 0.770099]\n",
      "epoch:12 step:11854 [D loss: 0.696037, acc.: 50.00%] [G loss: 0.776025]\n",
      "epoch:12 step:11855 [D loss: 0.673456, acc.: 66.41%] [G loss: 0.774575]\n",
      "epoch:12 step:11856 [D loss: 0.679016, acc.: 55.47%] [G loss: 0.753396]\n",
      "epoch:12 step:11857 [D loss: 0.664323, acc.: 58.59%] [G loss: 0.762456]\n",
      "epoch:12 step:11858 [D loss: 0.694849, acc.: 47.66%] [G loss: 0.759197]\n",
      "epoch:12 step:11859 [D loss: 0.700303, acc.: 54.69%] [G loss: 0.763587]\n",
      "epoch:12 step:11860 [D loss: 0.681422, acc.: 57.81%] [G loss: 0.769205]\n",
      "epoch:12 step:11861 [D loss: 0.700902, acc.: 52.34%] [G loss: 0.724117]\n",
      "epoch:12 step:11862 [D loss: 0.694824, acc.: 53.12%] [G loss: 0.746637]\n",
      "epoch:12 step:11863 [D loss: 0.692488, acc.: 55.47%] [G loss: 0.697382]\n",
      "epoch:12 step:11864 [D loss: 0.712848, acc.: 43.75%] [G loss: 0.733092]\n",
      "epoch:12 step:11865 [D loss: 0.718181, acc.: 45.31%] [G loss: 0.703264]\n",
      "epoch:12 step:11866 [D loss: 0.706947, acc.: 43.75%] [G loss: 0.745622]\n",
      "epoch:12 step:11867 [D loss: 0.696972, acc.: 48.44%] [G loss: 0.766415]\n",
      "epoch:12 step:11868 [D loss: 0.670765, acc.: 58.59%] [G loss: 0.790064]\n",
      "epoch:12 step:11869 [D loss: 0.688182, acc.: 55.47%] [G loss: 0.783828]\n",
      "epoch:12 step:11870 [D loss: 0.680594, acc.: 57.81%] [G loss: 0.767109]\n",
      "epoch:12 step:11871 [D loss: 0.683264, acc.: 55.47%] [G loss: 0.786114]\n",
      "epoch:12 step:11872 [D loss: 0.680649, acc.: 58.59%] [G loss: 0.784185]\n",
      "epoch:12 step:11873 [D loss: 0.677790, acc.: 54.69%] [G loss: 0.761319]\n",
      "epoch:12 step:11874 [D loss: 0.657401, acc.: 60.94%] [G loss: 0.750429]\n",
      "epoch:12 step:11875 [D loss: 0.668246, acc.: 60.16%] [G loss: 0.782324]\n",
      "epoch:12 step:11876 [D loss: 0.686577, acc.: 56.25%] [G loss: 0.746869]\n",
      "epoch:12 step:11877 [D loss: 0.706127, acc.: 46.88%] [G loss: 0.699162]\n",
      "epoch:12 step:11878 [D loss: 0.677745, acc.: 59.38%] [G loss: 0.782692]\n",
      "epoch:12 step:11879 [D loss: 0.657677, acc.: 57.81%] [G loss: 0.730991]\n",
      "epoch:12 step:11880 [D loss: 0.692826, acc.: 55.47%] [G loss: 0.695450]\n",
      "epoch:12 step:11881 [D loss: 0.641215, acc.: 64.84%] [G loss: 0.754819]\n",
      "epoch:12 step:11882 [D loss: 0.694221, acc.: 52.34%] [G loss: 0.694036]\n",
      "epoch:12 step:11883 [D loss: 0.719254, acc.: 42.19%] [G loss: 0.810505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11884 [D loss: 0.726232, acc.: 42.19%] [G loss: 0.791559]\n",
      "epoch:12 step:11885 [D loss: 0.684401, acc.: 51.56%] [G loss: 0.752053]\n",
      "epoch:12 step:11886 [D loss: 0.693265, acc.: 45.31%] [G loss: 0.763909]\n",
      "epoch:12 step:11887 [D loss: 0.671710, acc.: 60.94%] [G loss: 0.796713]\n",
      "epoch:12 step:11888 [D loss: 0.653469, acc.: 66.41%] [G loss: 0.789778]\n",
      "epoch:12 step:11889 [D loss: 0.647029, acc.: 63.28%] [G loss: 0.824052]\n",
      "epoch:12 step:11890 [D loss: 0.637640, acc.: 65.62%] [G loss: 0.794424]\n",
      "epoch:12 step:11891 [D loss: 0.695837, acc.: 53.91%] [G loss: 0.772872]\n",
      "epoch:12 step:11892 [D loss: 0.657750, acc.: 67.19%] [G loss: 0.803730]\n",
      "epoch:12 step:11893 [D loss: 0.650821, acc.: 64.06%] [G loss: 0.817908]\n",
      "epoch:12 step:11894 [D loss: 0.647482, acc.: 60.16%] [G loss: 0.819820]\n",
      "epoch:12 step:11895 [D loss: 0.704992, acc.: 50.00%] [G loss: 0.755836]\n",
      "epoch:12 step:11896 [D loss: 0.692945, acc.: 51.56%] [G loss: 0.844060]\n",
      "epoch:12 step:11897 [D loss: 0.693232, acc.: 53.12%] [G loss: 0.750893]\n",
      "epoch:12 step:11898 [D loss: 0.684177, acc.: 59.38%] [G loss: 0.746066]\n",
      "epoch:12 step:11899 [D loss: 0.726262, acc.: 43.75%] [G loss: 0.782315]\n",
      "epoch:12 step:11900 [D loss: 0.690600, acc.: 50.78%] [G loss: 0.754068]\n",
      "epoch:12 step:11901 [D loss: 0.727787, acc.: 42.97%] [G loss: 0.795739]\n",
      "epoch:12 step:11902 [D loss: 0.704918, acc.: 54.69%] [G loss: 0.677183]\n",
      "epoch:12 step:11903 [D loss: 0.738019, acc.: 44.53%] [G loss: 0.724931]\n",
      "epoch:12 step:11904 [D loss: 0.671331, acc.: 61.72%] [G loss: 0.745062]\n",
      "epoch:12 step:11905 [D loss: 0.663520, acc.: 60.94%] [G loss: 0.689494]\n",
      "epoch:12 step:11906 [D loss: 0.681863, acc.: 55.47%] [G loss: 0.708826]\n",
      "epoch:12 step:11907 [D loss: 0.695548, acc.: 48.44%] [G loss: 0.755950]\n",
      "epoch:12 step:11908 [D loss: 0.681339, acc.: 50.78%] [G loss: 0.823858]\n",
      "epoch:12 step:11909 [D loss: 0.687505, acc.: 53.12%] [G loss: 0.794276]\n",
      "epoch:12 step:11910 [D loss: 0.693915, acc.: 57.81%] [G loss: 0.772925]\n",
      "epoch:12 step:11911 [D loss: 0.684336, acc.: 56.25%] [G loss: 0.753495]\n",
      "epoch:12 step:11912 [D loss: 0.683484, acc.: 59.38%] [G loss: 0.772418]\n",
      "epoch:12 step:11913 [D loss: 0.672562, acc.: 59.38%] [G loss: 0.759066]\n",
      "epoch:12 step:11914 [D loss: 0.687024, acc.: 51.56%] [G loss: 0.795585]\n",
      "epoch:12 step:11915 [D loss: 0.660100, acc.: 63.28%] [G loss: 0.784100]\n",
      "epoch:12 step:11916 [D loss: 0.694466, acc.: 54.69%] [G loss: 0.823357]\n",
      "epoch:12 step:11917 [D loss: 0.667117, acc.: 58.59%] [G loss: 0.761182]\n",
      "epoch:12 step:11918 [D loss: 0.654441, acc.: 62.50%] [G loss: 0.781082]\n",
      "epoch:12 step:11919 [D loss: 0.719697, acc.: 46.88%] [G loss: 0.760649]\n",
      "epoch:12 step:11920 [D loss: 0.700549, acc.: 50.00%] [G loss: 0.739975]\n",
      "epoch:12 step:11921 [D loss: 0.694210, acc.: 50.00%] [G loss: 0.753549]\n",
      "epoch:12 step:11922 [D loss: 0.678368, acc.: 54.69%] [G loss: 0.720500]\n",
      "epoch:12 step:11923 [D loss: 0.689355, acc.: 54.69%] [G loss: 0.746988]\n",
      "epoch:12 step:11924 [D loss: 0.679755, acc.: 57.81%] [G loss: 0.763636]\n",
      "epoch:12 step:11925 [D loss: 0.660210, acc.: 61.72%] [G loss: 0.714004]\n",
      "epoch:12 step:11926 [D loss: 0.688981, acc.: 53.91%] [G loss: 0.697558]\n",
      "epoch:12 step:11927 [D loss: 0.680834, acc.: 53.12%] [G loss: 0.761127]\n",
      "epoch:12 step:11928 [D loss: 0.669364, acc.: 57.03%] [G loss: 0.770159]\n",
      "epoch:12 step:11929 [D loss: 0.685834, acc.: 50.00%] [G loss: 0.772152]\n",
      "epoch:12 step:11930 [D loss: 0.689717, acc.: 52.34%] [G loss: 0.804018]\n",
      "epoch:12 step:11931 [D loss: 0.668432, acc.: 60.16%] [G loss: 0.744698]\n",
      "epoch:12 step:11932 [D loss: 0.693814, acc.: 60.94%] [G loss: 0.735558]\n",
      "epoch:12 step:11933 [D loss: 0.648892, acc.: 64.06%] [G loss: 0.811248]\n",
      "epoch:12 step:11934 [D loss: 0.703590, acc.: 52.34%] [G loss: 0.782841]\n",
      "epoch:12 step:11935 [D loss: 0.687273, acc.: 58.59%] [G loss: 0.827890]\n",
      "epoch:12 step:11936 [D loss: 0.655977, acc.: 63.28%] [G loss: 0.748802]\n",
      "epoch:12 step:11937 [D loss: 0.647661, acc.: 64.06%] [G loss: 0.739091]\n",
      "epoch:12 step:11938 [D loss: 0.664624, acc.: 63.28%] [G loss: 0.764914]\n",
      "epoch:12 step:11939 [D loss: 0.688162, acc.: 52.34%] [G loss: 0.756578]\n",
      "epoch:12 step:11940 [D loss: 0.716929, acc.: 50.00%] [G loss: 0.699139]\n",
      "epoch:12 step:11941 [D loss: 0.682386, acc.: 53.91%] [G loss: 0.741259]\n",
      "epoch:12 step:11942 [D loss: 0.713523, acc.: 47.66%] [G loss: 0.764781]\n",
      "epoch:12 step:11943 [D loss: 0.682592, acc.: 50.78%] [G loss: 0.782425]\n",
      "epoch:12 step:11944 [D loss: 0.703313, acc.: 49.22%] [G loss: 0.741163]\n",
      "epoch:12 step:11945 [D loss: 0.703108, acc.: 45.31%] [G loss: 0.794202]\n",
      "epoch:12 step:11946 [D loss: 0.682243, acc.: 60.16%] [G loss: 0.743430]\n",
      "epoch:12 step:11947 [D loss: 0.675315, acc.: 58.59%] [G loss: 0.776777]\n",
      "epoch:12 step:11948 [D loss: 0.689884, acc.: 51.56%] [G loss: 0.739037]\n",
      "epoch:12 step:11949 [D loss: 0.698634, acc.: 53.12%] [G loss: 0.806212]\n",
      "epoch:12 step:11950 [D loss: 0.679902, acc.: 58.59%] [G loss: 0.756886]\n",
      "epoch:12 step:11951 [D loss: 0.671767, acc.: 55.47%] [G loss: 0.765742]\n",
      "epoch:12 step:11952 [D loss: 0.654219, acc.: 64.06%] [G loss: 0.795178]\n",
      "epoch:12 step:11953 [D loss: 0.647390, acc.: 61.72%] [G loss: 0.807022]\n",
      "epoch:12 step:11954 [D loss: 0.731563, acc.: 38.28%] [G loss: 0.767173]\n",
      "epoch:12 step:11955 [D loss: 0.689734, acc.: 46.88%] [G loss: 0.758633]\n",
      "epoch:12 step:11956 [D loss: 0.650813, acc.: 60.16%] [G loss: 0.735132]\n",
      "epoch:12 step:11957 [D loss: 0.675958, acc.: 64.84%] [G loss: 0.739117]\n",
      "epoch:12 step:11958 [D loss: 0.669993, acc.: 57.81%] [G loss: 0.712974]\n",
      "epoch:12 step:11959 [D loss: 0.716006, acc.: 53.91%] [G loss: 0.710916]\n",
      "epoch:12 step:11960 [D loss: 0.687488, acc.: 50.78%] [G loss: 0.719304]\n",
      "epoch:12 step:11961 [D loss: 0.681834, acc.: 52.34%] [G loss: 0.772565]\n",
      "epoch:12 step:11962 [D loss: 0.696304, acc.: 56.25%] [G loss: 0.755901]\n",
      "epoch:12 step:11963 [D loss: 0.710624, acc.: 45.31%] [G loss: 0.732085]\n",
      "epoch:12 step:11964 [D loss: 0.674827, acc.: 56.25%] [G loss: 0.736187]\n",
      "epoch:12 step:11965 [D loss: 0.674458, acc.: 58.59%] [G loss: 0.746527]\n",
      "epoch:12 step:11966 [D loss: 0.701060, acc.: 51.56%] [G loss: 0.746453]\n",
      "epoch:12 step:11967 [D loss: 0.694480, acc.: 53.12%] [G loss: 0.756213]\n",
      "epoch:12 step:11968 [D loss: 0.672559, acc.: 55.47%] [G loss: 0.745624]\n",
      "epoch:12 step:11969 [D loss: 0.673551, acc.: 58.59%] [G loss: 0.766999]\n",
      "epoch:12 step:11970 [D loss: 0.694662, acc.: 48.44%] [G loss: 0.787188]\n",
      "epoch:12 step:11971 [D loss: 0.693007, acc.: 51.56%] [G loss: 0.747271]\n",
      "epoch:12 step:11972 [D loss: 0.668724, acc.: 61.72%] [G loss: 0.773920]\n",
      "epoch:12 step:11973 [D loss: 0.677634, acc.: 56.25%] [G loss: 0.746328]\n",
      "epoch:12 step:11974 [D loss: 0.655445, acc.: 64.06%] [G loss: 0.788951]\n",
      "epoch:12 step:11975 [D loss: 0.677159, acc.: 54.69%] [G loss: 0.795135]\n",
      "epoch:12 step:11976 [D loss: 0.666047, acc.: 59.38%] [G loss: 0.787450]\n",
      "epoch:12 step:11977 [D loss: 0.656607, acc.: 60.94%] [G loss: 0.751639]\n",
      "epoch:12 step:11978 [D loss: 0.675591, acc.: 51.56%] [G loss: 0.731218]\n",
      "epoch:12 step:11979 [D loss: 0.710584, acc.: 46.09%] [G loss: 0.762336]\n",
      "epoch:12 step:11980 [D loss: 0.681223, acc.: 53.91%] [G loss: 0.761124]\n",
      "epoch:12 step:11981 [D loss: 0.697852, acc.: 53.12%] [G loss: 0.719030]\n",
      "epoch:12 step:11982 [D loss: 0.705090, acc.: 52.34%] [G loss: 0.765140]\n",
      "epoch:12 step:11983 [D loss: 0.678191, acc.: 59.38%] [G loss: 0.728027]\n",
      "epoch:12 step:11984 [D loss: 0.684326, acc.: 53.91%] [G loss: 0.729725]\n",
      "epoch:12 step:11985 [D loss: 0.692793, acc.: 54.69%] [G loss: 0.724984]\n",
      "epoch:12 step:11986 [D loss: 0.713673, acc.: 43.75%] [G loss: 0.769502]\n",
      "epoch:12 step:11987 [D loss: 0.696378, acc.: 49.22%] [G loss: 0.741608]\n",
      "epoch:12 step:11988 [D loss: 0.681976, acc.: 53.12%] [G loss: 0.735753]\n",
      "epoch:12 step:11989 [D loss: 0.675987, acc.: 61.72%] [G loss: 0.724453]\n",
      "epoch:12 step:11990 [D loss: 0.703017, acc.: 49.22%] [G loss: 0.724243]\n",
      "epoch:12 step:11991 [D loss: 0.684597, acc.: 54.69%] [G loss: 0.747002]\n",
      "epoch:12 step:11992 [D loss: 0.694582, acc.: 46.88%] [G loss: 0.744046]\n",
      "epoch:12 step:11993 [D loss: 0.697555, acc.: 49.22%] [G loss: 0.728288]\n",
      "epoch:12 step:11994 [D loss: 0.670901, acc.: 57.81%] [G loss: 0.761318]\n",
      "epoch:12 step:11995 [D loss: 0.679777, acc.: 53.91%] [G loss: 0.727622]\n",
      "epoch:12 step:11996 [D loss: 0.692631, acc.: 46.88%] [G loss: 0.739421]\n",
      "epoch:12 step:11997 [D loss: 0.692851, acc.: 52.34%] [G loss: 0.726167]\n",
      "epoch:12 step:11998 [D loss: 0.682573, acc.: 59.38%] [G loss: 0.751606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11999 [D loss: 0.698628, acc.: 57.81%] [G loss: 0.715317]\n",
      "epoch:12 step:12000 [D loss: 0.678309, acc.: 55.47%] [G loss: 0.734784]\n",
      "epoch:12 step:12001 [D loss: 0.684425, acc.: 57.81%] [G loss: 0.746990]\n",
      "epoch:12 step:12002 [D loss: 0.701844, acc.: 49.22%] [G loss: 0.783915]\n",
      "epoch:12 step:12003 [D loss: 0.693582, acc.: 52.34%] [G loss: 0.783951]\n",
      "epoch:12 step:12004 [D loss: 0.721066, acc.: 46.88%] [G loss: 0.728261]\n",
      "epoch:12 step:12005 [D loss: 0.673192, acc.: 59.38%] [G loss: 0.823790]\n",
      "epoch:12 step:12006 [D loss: 0.686844, acc.: 56.25%] [G loss: 0.740670]\n",
      "epoch:12 step:12007 [D loss: 0.694383, acc.: 54.69%] [G loss: 0.713991]\n",
      "epoch:12 step:12008 [D loss: 0.669580, acc.: 58.59%] [G loss: 0.724789]\n",
      "epoch:12 step:12009 [D loss: 0.709719, acc.: 50.00%] [G loss: 0.730370]\n",
      "epoch:12 step:12010 [D loss: 0.697395, acc.: 52.34%] [G loss: 0.741928]\n",
      "epoch:12 step:12011 [D loss: 0.692989, acc.: 48.44%] [G loss: 0.729490]\n",
      "epoch:12 step:12012 [D loss: 0.701901, acc.: 55.47%] [G loss: 0.740468]\n",
      "epoch:12 step:12013 [D loss: 0.676203, acc.: 60.16%] [G loss: 0.744356]\n",
      "epoch:12 step:12014 [D loss: 0.680066, acc.: 50.78%] [G loss: 0.724629]\n",
      "epoch:12 step:12015 [D loss: 0.680550, acc.: 57.81%] [G loss: 0.701883]\n",
      "epoch:12 step:12016 [D loss: 0.695388, acc.: 49.22%] [G loss: 0.743557]\n",
      "epoch:12 step:12017 [D loss: 0.684721, acc.: 62.50%] [G loss: 0.716202]\n",
      "epoch:12 step:12018 [D loss: 0.689094, acc.: 57.81%] [G loss: 0.722182]\n",
      "epoch:12 step:12019 [D loss: 0.664479, acc.: 57.03%] [G loss: 0.759124]\n",
      "epoch:12 step:12020 [D loss: 0.701614, acc.: 47.66%] [G loss: 0.763875]\n",
      "epoch:12 step:12021 [D loss: 0.674055, acc.: 60.94%] [G loss: 0.780625]\n",
      "epoch:12 step:12022 [D loss: 0.706770, acc.: 50.00%] [G loss: 0.777969]\n",
      "epoch:12 step:12023 [D loss: 0.683751, acc.: 57.81%] [G loss: 0.742620]\n",
      "epoch:12 step:12024 [D loss: 0.695732, acc.: 50.00%] [G loss: 0.757066]\n",
      "epoch:12 step:12025 [D loss: 0.690740, acc.: 53.12%] [G loss: 0.712168]\n",
      "epoch:12 step:12026 [D loss: 0.670364, acc.: 64.84%] [G loss: 0.737836]\n",
      "epoch:12 step:12027 [D loss: 0.715479, acc.: 46.88%] [G loss: 0.755338]\n",
      "epoch:12 step:12028 [D loss: 0.698068, acc.: 46.88%] [G loss: 0.758468]\n",
      "epoch:12 step:12029 [D loss: 0.680327, acc.: 53.91%] [G loss: 0.751054]\n",
      "epoch:12 step:12030 [D loss: 0.686834, acc.: 48.44%] [G loss: 0.769705]\n",
      "epoch:12 step:12031 [D loss: 0.714981, acc.: 46.09%] [G loss: 0.750668]\n",
      "epoch:12 step:12032 [D loss: 0.686580, acc.: 52.34%] [G loss: 0.765136]\n",
      "epoch:12 step:12033 [D loss: 0.691325, acc.: 57.03%] [G loss: 0.803140]\n",
      "epoch:12 step:12034 [D loss: 0.682407, acc.: 55.47%] [G loss: 0.715293]\n",
      "epoch:12 step:12035 [D loss: 0.669791, acc.: 61.72%] [G loss: 0.736353]\n",
      "epoch:12 step:12036 [D loss: 0.696328, acc.: 48.44%] [G loss: 0.738761]\n",
      "epoch:12 step:12037 [D loss: 0.693971, acc.: 53.12%] [G loss: 0.754722]\n",
      "epoch:12 step:12038 [D loss: 0.674562, acc.: 56.25%] [G loss: 0.785971]\n",
      "epoch:12 step:12039 [D loss: 0.676491, acc.: 53.12%] [G loss: 0.752221]\n",
      "epoch:12 step:12040 [D loss: 0.663536, acc.: 60.94%] [G loss: 0.747266]\n",
      "epoch:12 step:12041 [D loss: 0.651866, acc.: 60.94%] [G loss: 0.765377]\n",
      "epoch:12 step:12042 [D loss: 0.671021, acc.: 58.59%] [G loss: 0.775182]\n",
      "epoch:12 step:12043 [D loss: 0.688687, acc.: 53.91%] [G loss: 0.734562]\n",
      "epoch:12 step:12044 [D loss: 0.693121, acc.: 53.12%] [G loss: 0.747775]\n",
      "epoch:12 step:12045 [D loss: 0.683447, acc.: 56.25%] [G loss: 0.712824]\n",
      "epoch:12 step:12046 [D loss: 0.528273, acc.: 66.41%] [G loss: 0.754553]\n",
      "epoch:12 step:12047 [D loss: 0.697476, acc.: 55.47%] [G loss: 0.727516]\n",
      "epoch:12 step:12048 [D loss: 0.711309, acc.: 51.56%] [G loss: 0.677887]\n",
      "epoch:12 step:12049 [D loss: 0.696474, acc.: 56.25%] [G loss: 0.773297]\n",
      "epoch:12 step:12050 [D loss: 0.682485, acc.: 55.47%] [G loss: 0.721450]\n",
      "epoch:12 step:12051 [D loss: 0.724858, acc.: 49.22%] [G loss: 0.754841]\n",
      "epoch:12 step:12052 [D loss: 0.712630, acc.: 41.41%] [G loss: 0.745477]\n",
      "epoch:12 step:12053 [D loss: 0.712818, acc.: 46.09%] [G loss: 0.665936]\n",
      "epoch:12 step:12054 [D loss: 0.695264, acc.: 53.12%] [G loss: 0.771722]\n",
      "epoch:12 step:12055 [D loss: 0.697056, acc.: 54.69%] [G loss: 0.760181]\n",
      "epoch:12 step:12056 [D loss: 0.703935, acc.: 49.22%] [G loss: 0.742839]\n",
      "epoch:12 step:12057 [D loss: 0.691630, acc.: 57.81%] [G loss: 0.744912]\n",
      "epoch:12 step:12058 [D loss: 0.671605, acc.: 62.50%] [G loss: 0.742558]\n",
      "epoch:12 step:12059 [D loss: 0.658120, acc.: 61.72%] [G loss: 0.766073]\n",
      "epoch:12 step:12060 [D loss: 0.646874, acc.: 64.84%] [G loss: 0.780501]\n",
      "epoch:12 step:12061 [D loss: 0.656370, acc.: 60.94%] [G loss: 0.776094]\n",
      "epoch:12 step:12062 [D loss: 0.705546, acc.: 55.47%] [G loss: 0.773300]\n",
      "epoch:12 step:12063 [D loss: 0.665351, acc.: 53.91%] [G loss: 0.751011]\n",
      "epoch:12 step:12064 [D loss: 0.687443, acc.: 54.69%] [G loss: 0.748464]\n",
      "epoch:12 step:12065 [D loss: 0.660092, acc.: 57.81%] [G loss: 0.834263]\n",
      "epoch:12 step:12066 [D loss: 0.693431, acc.: 52.34%] [G loss: 0.799171]\n",
      "epoch:12 step:12067 [D loss: 0.667821, acc.: 60.16%] [G loss: 0.758265]\n",
      "epoch:12 step:12068 [D loss: 0.696334, acc.: 54.69%] [G loss: 0.757592]\n",
      "epoch:12 step:12069 [D loss: 0.680039, acc.: 47.66%] [G loss: 0.740110]\n",
      "epoch:12 step:12070 [D loss: 0.735241, acc.: 46.88%] [G loss: 0.735028]\n",
      "epoch:12 step:12071 [D loss: 0.743550, acc.: 43.75%] [G loss: 0.765659]\n",
      "epoch:12 step:12072 [D loss: 0.697661, acc.: 48.44%] [G loss: 0.776794]\n",
      "epoch:12 step:12073 [D loss: 0.651370, acc.: 62.50%] [G loss: 0.835307]\n",
      "epoch:12 step:12074 [D loss: 0.660274, acc.: 62.50%] [G loss: 0.813687]\n",
      "epoch:12 step:12075 [D loss: 0.664722, acc.: 60.16%] [G loss: 0.803533]\n",
      "epoch:12 step:12076 [D loss: 0.656379, acc.: 59.38%] [G loss: 0.832068]\n",
      "epoch:12 step:12077 [D loss: 0.675872, acc.: 56.25%] [G loss: 0.821515]\n",
      "epoch:12 step:12078 [D loss: 0.711935, acc.: 53.12%] [G loss: 0.747714]\n",
      "epoch:12 step:12079 [D loss: 0.665012, acc.: 59.38%] [G loss: 0.772021]\n",
      "epoch:12 step:12080 [D loss: 0.691946, acc.: 52.34%] [G loss: 0.726162]\n",
      "epoch:12 step:12081 [D loss: 0.686483, acc.: 59.38%] [G loss: 0.760721]\n",
      "epoch:12 step:12082 [D loss: 0.686688, acc.: 55.47%] [G loss: 0.761267]\n",
      "epoch:12 step:12083 [D loss: 0.714966, acc.: 50.00%] [G loss: 0.727533]\n",
      "epoch:12 step:12084 [D loss: 0.707523, acc.: 49.22%] [G loss: 0.700665]\n",
      "epoch:12 step:12085 [D loss: 0.714142, acc.: 44.53%] [G loss: 0.667322]\n",
      "epoch:12 step:12086 [D loss: 0.667545, acc.: 53.12%] [G loss: 0.675153]\n",
      "epoch:12 step:12087 [D loss: 0.723508, acc.: 43.75%] [G loss: 0.696816]\n",
      "epoch:12 step:12088 [D loss: 0.692923, acc.: 56.25%] [G loss: 0.693938]\n",
      "epoch:12 step:12089 [D loss: 0.692283, acc.: 57.03%] [G loss: 0.727911]\n",
      "epoch:12 step:12090 [D loss: 0.711209, acc.: 55.47%] [G loss: 0.743438]\n",
      "epoch:12 step:12091 [D loss: 0.697965, acc.: 50.78%] [G loss: 0.764927]\n",
      "epoch:12 step:12092 [D loss: 0.699783, acc.: 53.12%] [G loss: 0.758726]\n",
      "epoch:12 step:12093 [D loss: 0.676313, acc.: 58.59%] [G loss: 0.734406]\n",
      "epoch:12 step:12094 [D loss: 0.689320, acc.: 55.47%] [G loss: 0.751335]\n",
      "epoch:12 step:12095 [D loss: 0.684921, acc.: 53.12%] [G loss: 0.775367]\n",
      "epoch:12 step:12096 [D loss: 0.671886, acc.: 57.03%] [G loss: 0.777452]\n",
      "epoch:12 step:12097 [D loss: 0.650595, acc.: 58.59%] [G loss: 0.774850]\n",
      "epoch:12 step:12098 [D loss: 0.661386, acc.: 63.28%] [G loss: 0.804355]\n",
      "epoch:12 step:12099 [D loss: 0.690081, acc.: 54.69%] [G loss: 0.766555]\n",
      "epoch:12 step:12100 [D loss: 0.684997, acc.: 54.69%] [G loss: 0.763395]\n",
      "epoch:12 step:12101 [D loss: 0.678007, acc.: 58.59%] [G loss: 0.770253]\n",
      "epoch:12 step:12102 [D loss: 0.695290, acc.: 54.69%] [G loss: 0.798106]\n",
      "epoch:12 step:12103 [D loss: 0.696832, acc.: 50.78%] [G loss: 0.806812]\n",
      "epoch:12 step:12104 [D loss: 0.676767, acc.: 57.81%] [G loss: 0.804222]\n",
      "epoch:12 step:12105 [D loss: 0.733021, acc.: 38.28%] [G loss: 0.782165]\n",
      "epoch:12 step:12106 [D loss: 0.699151, acc.: 54.69%] [G loss: 0.753401]\n",
      "epoch:12 step:12107 [D loss: 0.704863, acc.: 53.91%] [G loss: 0.728005]\n",
      "epoch:12 step:12108 [D loss: 0.692604, acc.: 54.69%] [G loss: 0.715636]\n",
      "epoch:12 step:12109 [D loss: 0.700310, acc.: 50.00%] [G loss: 0.711255]\n",
      "epoch:12 step:12110 [D loss: 0.690413, acc.: 49.22%] [G loss: 0.726916]\n",
      "epoch:12 step:12111 [D loss: 0.715969, acc.: 52.34%] [G loss: 0.725587]\n",
      "epoch:12 step:12112 [D loss: 0.706038, acc.: 46.09%] [G loss: 0.727778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12113 [D loss: 0.681342, acc.: 58.59%] [G loss: 0.720527]\n",
      "epoch:12 step:12114 [D loss: 0.673545, acc.: 57.03%] [G loss: 0.759152]\n",
      "epoch:12 step:12115 [D loss: 0.686258, acc.: 56.25%] [G loss: 0.734495]\n",
      "epoch:12 step:12116 [D loss: 0.694709, acc.: 53.91%] [G loss: 0.756663]\n",
      "epoch:12 step:12117 [D loss: 0.693468, acc.: 50.78%] [G loss: 0.727172]\n",
      "epoch:12 step:12118 [D loss: 0.703390, acc.: 52.34%] [G loss: 0.727020]\n",
      "epoch:12 step:12119 [D loss: 0.696743, acc.: 52.34%] [G loss: 0.725725]\n",
      "epoch:12 step:12120 [D loss: 0.693816, acc.: 45.31%] [G loss: 0.718503]\n",
      "epoch:12 step:12121 [D loss: 0.682826, acc.: 56.25%] [G loss: 0.730835]\n",
      "epoch:12 step:12122 [D loss: 0.656563, acc.: 68.75%] [G loss: 0.728567]\n",
      "epoch:12 step:12123 [D loss: 0.685150, acc.: 52.34%] [G loss: 0.733786]\n",
      "epoch:12 step:12124 [D loss: 0.681519, acc.: 53.91%] [G loss: 0.745789]\n",
      "epoch:12 step:12125 [D loss: 0.706879, acc.: 39.84%] [G loss: 0.703792]\n",
      "epoch:12 step:12126 [D loss: 0.706474, acc.: 44.53%] [G loss: 0.719068]\n",
      "epoch:12 step:12127 [D loss: 0.697584, acc.: 47.66%] [G loss: 0.722975]\n",
      "epoch:12 step:12128 [D loss: 0.696818, acc.: 50.00%] [G loss: 0.749507]\n",
      "epoch:12 step:12129 [D loss: 0.690424, acc.: 52.34%] [G loss: 0.751967]\n",
      "epoch:12 step:12130 [D loss: 0.673165, acc.: 60.94%] [G loss: 0.728470]\n",
      "epoch:12 step:12131 [D loss: 0.674232, acc.: 59.38%] [G loss: 0.740361]\n",
      "epoch:12 step:12132 [D loss: 0.667743, acc.: 58.59%] [G loss: 0.744230]\n",
      "epoch:12 step:12133 [D loss: 0.663344, acc.: 57.03%] [G loss: 0.698643]\n",
      "epoch:12 step:12134 [D loss: 0.654355, acc.: 62.50%] [G loss: 0.780558]\n",
      "epoch:12 step:12135 [D loss: 0.718838, acc.: 42.97%] [G loss: 0.733678]\n",
      "epoch:12 step:12136 [D loss: 0.684122, acc.: 56.25%] [G loss: 0.729955]\n",
      "epoch:12 step:12137 [D loss: 0.707376, acc.: 51.56%] [G loss: 0.710043]\n",
      "epoch:12 step:12138 [D loss: 0.671316, acc.: 58.59%] [G loss: 0.719416]\n",
      "epoch:12 step:12139 [D loss: 0.695083, acc.: 50.78%] [G loss: 0.739617]\n",
      "epoch:12 step:12140 [D loss: 0.700204, acc.: 52.34%] [G loss: 0.730503]\n",
      "epoch:12 step:12141 [D loss: 0.691001, acc.: 56.25%] [G loss: 0.714497]\n",
      "epoch:12 step:12142 [D loss: 0.703935, acc.: 47.66%] [G loss: 0.711017]\n",
      "epoch:12 step:12143 [D loss: 0.660151, acc.: 56.25%] [G loss: 0.751705]\n",
      "epoch:12 step:12144 [D loss: 0.647347, acc.: 70.31%] [G loss: 0.730410]\n",
      "epoch:12 step:12145 [D loss: 0.671448, acc.: 59.38%] [G loss: 0.735421]\n",
      "epoch:12 step:12146 [D loss: 0.657377, acc.: 63.28%] [G loss: 0.729924]\n",
      "epoch:12 step:12147 [D loss: 0.679657, acc.: 58.59%] [G loss: 0.712888]\n",
      "epoch:12 step:12148 [D loss: 0.714787, acc.: 40.62%] [G loss: 0.721034]\n",
      "epoch:12 step:12149 [D loss: 0.714618, acc.: 46.88%] [G loss: 0.735625]\n",
      "epoch:12 step:12150 [D loss: 0.714335, acc.: 42.19%] [G loss: 0.745279]\n",
      "epoch:12 step:12151 [D loss: 0.714559, acc.: 50.00%] [G loss: 0.733359]\n",
      "epoch:12 step:12152 [D loss: 0.690879, acc.: 50.78%] [G loss: 0.737229]\n",
      "epoch:12 step:12153 [D loss: 0.682663, acc.: 59.38%] [G loss: 0.759266]\n",
      "epoch:12 step:12154 [D loss: 0.700916, acc.: 50.78%] [G loss: 0.750432]\n",
      "epoch:12 step:12155 [D loss: 0.669753, acc.: 61.72%] [G loss: 0.734828]\n",
      "epoch:12 step:12156 [D loss: 0.377984, acc.: 89.84%] [G loss: 0.713614]\n",
      "epoch:12 step:12157 [D loss: 0.681831, acc.: 56.25%] [G loss: 0.800945]\n",
      "epoch:12 step:12158 [D loss: 0.676623, acc.: 56.25%] [G loss: 0.802834]\n",
      "epoch:12 step:12159 [D loss: 0.711348, acc.: 49.22%] [G loss: 0.798906]\n",
      "epoch:12 step:12160 [D loss: 0.706377, acc.: 49.22%] [G loss: 0.792330]\n",
      "epoch:12 step:12161 [D loss: 0.690307, acc.: 52.34%] [G loss: 0.753036]\n",
      "epoch:12 step:12162 [D loss: 0.679621, acc.: 60.94%] [G loss: 0.777084]\n",
      "epoch:12 step:12163 [D loss: 0.653512, acc.: 62.50%] [G loss: 0.718779]\n",
      "epoch:12 step:12164 [D loss: 0.730155, acc.: 37.50%] [G loss: 0.677261]\n",
      "epoch:12 step:12165 [D loss: 0.694772, acc.: 54.69%] [G loss: 0.756040]\n",
      "epoch:12 step:12166 [D loss: 0.635587, acc.: 67.97%] [G loss: 0.706856]\n",
      "epoch:12 step:12167 [D loss: 0.670646, acc.: 62.50%] [G loss: 0.729430]\n",
      "epoch:12 step:12168 [D loss: 0.682510, acc.: 60.16%] [G loss: 0.728080]\n",
      "epoch:12 step:12169 [D loss: 0.632162, acc.: 61.72%] [G loss: 0.759396]\n",
      "epoch:12 step:12170 [D loss: 0.575555, acc.: 68.75%] [G loss: 0.755815]\n",
      "epoch:12 step:12171 [D loss: 0.995526, acc.: 54.69%] [G loss: 0.832065]\n",
      "epoch:12 step:12172 [D loss: 0.710972, acc.: 54.69%] [G loss: 0.828974]\n",
      "epoch:12 step:12173 [D loss: 0.670474, acc.: 53.91%] [G loss: 0.881759]\n",
      "epoch:12 step:12174 [D loss: 0.682218, acc.: 58.59%] [G loss: 0.909473]\n",
      "epoch:12 step:12175 [D loss: 0.699591, acc.: 50.00%] [G loss: 0.827158]\n",
      "epoch:12 step:12176 [D loss: 0.757814, acc.: 42.19%] [G loss: 0.795409]\n",
      "epoch:12 step:12177 [D loss: 0.752571, acc.: 48.44%] [G loss: 0.791340]\n",
      "epoch:12 step:12178 [D loss: 0.697428, acc.: 57.03%] [G loss: 0.783761]\n",
      "epoch:12 step:12179 [D loss: 0.674249, acc.: 60.94%] [G loss: 0.776271]\n",
      "epoch:12 step:12180 [D loss: 0.591344, acc.: 75.78%] [G loss: 0.783505]\n",
      "epoch:12 step:12181 [D loss: 0.580725, acc.: 67.19%] [G loss: 0.790679]\n",
      "epoch:13 step:12182 [D loss: 0.711753, acc.: 50.00%] [G loss: 0.759247]\n",
      "epoch:13 step:12183 [D loss: 0.699057, acc.: 57.81%] [G loss: 0.741149]\n",
      "epoch:13 step:12184 [D loss: 0.707069, acc.: 52.34%] [G loss: 0.718834]\n",
      "epoch:13 step:12185 [D loss: 0.714458, acc.: 40.62%] [G loss: 0.725702]\n",
      "epoch:13 step:12186 [D loss: 0.693923, acc.: 42.97%] [G loss: 0.764921]\n",
      "epoch:13 step:12187 [D loss: 0.711568, acc.: 45.31%] [G loss: 0.686798]\n",
      "epoch:13 step:12188 [D loss: 0.755242, acc.: 34.38%] [G loss: 0.757277]\n",
      "epoch:13 step:12189 [D loss: 0.699039, acc.: 57.03%] [G loss: 0.742380]\n",
      "epoch:13 step:12190 [D loss: 0.689237, acc.: 53.12%] [G loss: 0.757556]\n",
      "epoch:13 step:12191 [D loss: 0.691675, acc.: 55.47%] [G loss: 0.743668]\n",
      "epoch:13 step:12192 [D loss: 0.685878, acc.: 53.91%] [G loss: 0.698995]\n",
      "epoch:13 step:12193 [D loss: 0.674504, acc.: 59.38%] [G loss: 0.744930]\n",
      "epoch:13 step:12194 [D loss: 0.664538, acc.: 61.72%] [G loss: 0.713953]\n",
      "epoch:13 step:12195 [D loss: 0.713301, acc.: 46.88%] [G loss: 0.772113]\n",
      "epoch:13 step:12196 [D loss: 0.651225, acc.: 67.97%] [G loss: 0.689657]\n",
      "epoch:13 step:12197 [D loss: 0.686835, acc.: 47.66%] [G loss: 0.768808]\n",
      "epoch:13 step:12198 [D loss: 0.692377, acc.: 53.12%] [G loss: 0.730891]\n",
      "epoch:13 step:12199 [D loss: 0.894640, acc.: 44.53%] [G loss: 1.381771]\n",
      "epoch:13 step:12200 [D loss: 0.677088, acc.: 55.47%] [G loss: 0.799704]\n",
      "epoch:13 step:12201 [D loss: 0.691232, acc.: 60.94%] [G loss: 0.867834]\n",
      "epoch:13 step:12202 [D loss: 0.705409, acc.: 57.81%] [G loss: 0.851137]\n",
      "epoch:13 step:12203 [D loss: 0.654685, acc.: 63.28%] [G loss: 0.856395]\n",
      "epoch:13 step:12204 [D loss: 0.697075, acc.: 50.78%] [G loss: 0.819898]\n",
      "epoch:13 step:12205 [D loss: 0.693748, acc.: 52.34%] [G loss: 0.805967]\n",
      "epoch:13 step:12206 [D loss: 0.665170, acc.: 66.41%] [G loss: 0.827003]\n",
      "epoch:13 step:12207 [D loss: 0.685140, acc.: 58.59%] [G loss: 1.526442]\n",
      "epoch:13 step:12208 [D loss: 0.684150, acc.: 56.25%] [G loss: 0.811220]\n",
      "epoch:13 step:12209 [D loss: 0.676639, acc.: 51.56%] [G loss: 0.812576]\n",
      "epoch:13 step:12210 [D loss: 0.679100, acc.: 51.56%] [G loss: 0.799197]\n",
      "epoch:13 step:12211 [D loss: 0.666411, acc.: 58.59%] [G loss: 0.734388]\n",
      "epoch:13 step:12212 [D loss: 0.669862, acc.: 61.72%] [G loss: 1.117248]\n",
      "epoch:13 step:12213 [D loss: 0.670492, acc.: 63.28%] [G loss: 0.770385]\n",
      "epoch:13 step:12214 [D loss: 0.685608, acc.: 53.12%] [G loss: 0.732691]\n",
      "epoch:13 step:12215 [D loss: 0.699406, acc.: 48.44%] [G loss: 0.759807]\n",
      "epoch:13 step:12216 [D loss: 0.667056, acc.: 58.59%] [G loss: 0.737818]\n",
      "epoch:13 step:12217 [D loss: 0.655612, acc.: 64.84%] [G loss: 0.747442]\n",
      "epoch:13 step:12218 [D loss: 0.718234, acc.: 50.00%] [G loss: 0.762471]\n",
      "epoch:13 step:12219 [D loss: 0.750878, acc.: 40.62%] [G loss: 0.751905]\n",
      "epoch:13 step:12220 [D loss: 0.723517, acc.: 46.09%] [G loss: 0.774673]\n",
      "epoch:13 step:12221 [D loss: 0.720109, acc.: 42.19%] [G loss: 0.795826]\n",
      "epoch:13 step:12222 [D loss: 0.697923, acc.: 50.00%] [G loss: 0.750202]\n",
      "epoch:13 step:12223 [D loss: 0.684989, acc.: 53.91%] [G loss: 0.743217]\n",
      "epoch:13 step:12224 [D loss: 0.685602, acc.: 53.12%] [G loss: 0.715269]\n",
      "epoch:13 step:12225 [D loss: 0.679240, acc.: 60.94%] [G loss: 0.729936]\n",
      "epoch:13 step:12226 [D loss: 0.694857, acc.: 49.22%] [G loss: 0.720025]\n",
      "epoch:13 step:12227 [D loss: 0.681160, acc.: 58.59%] [G loss: 0.695288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12228 [D loss: 0.681821, acc.: 52.34%] [G loss: 0.774036]\n",
      "epoch:13 step:12229 [D loss: 0.684133, acc.: 59.38%] [G loss: 0.750907]\n",
      "epoch:13 step:12230 [D loss: 0.666042, acc.: 65.62%] [G loss: 0.774224]\n",
      "epoch:13 step:12231 [D loss: 0.659973, acc.: 57.03%] [G loss: 0.772269]\n",
      "epoch:13 step:12232 [D loss: 0.686474, acc.: 57.81%] [G loss: 0.720633]\n",
      "epoch:13 step:12233 [D loss: 0.705359, acc.: 51.56%] [G loss: 0.720174]\n",
      "epoch:13 step:12234 [D loss: 0.667881, acc.: 66.41%] [G loss: 0.758182]\n",
      "epoch:13 step:12235 [D loss: 0.705467, acc.: 57.81%] [G loss: 0.767541]\n",
      "epoch:13 step:12236 [D loss: 0.681407, acc.: 58.59%] [G loss: 0.745917]\n",
      "epoch:13 step:12237 [D loss: 0.670110, acc.: 60.16%] [G loss: 0.756669]\n",
      "epoch:13 step:12238 [D loss: 0.719322, acc.: 47.66%] [G loss: 0.764229]\n",
      "epoch:13 step:12239 [D loss: 0.706504, acc.: 44.53%] [G loss: 0.774344]\n",
      "epoch:13 step:12240 [D loss: 0.698355, acc.: 50.78%] [G loss: 0.753871]\n",
      "epoch:13 step:12241 [D loss: 0.703294, acc.: 46.09%] [G loss: 0.727683]\n",
      "epoch:13 step:12242 [D loss: 0.675392, acc.: 56.25%] [G loss: 0.762962]\n",
      "epoch:13 step:12243 [D loss: 0.685727, acc.: 55.47%] [G loss: 0.765545]\n",
      "epoch:13 step:12244 [D loss: 0.677412, acc.: 61.72%] [G loss: 0.768489]\n",
      "epoch:13 step:12245 [D loss: 0.662119, acc.: 62.50%] [G loss: 0.787354]\n",
      "epoch:13 step:12246 [D loss: 0.676585, acc.: 56.25%] [G loss: 0.739218]\n",
      "epoch:13 step:12247 [D loss: 0.679739, acc.: 57.81%] [G loss: 0.761859]\n",
      "epoch:13 step:12248 [D loss: 0.699920, acc.: 53.12%] [G loss: 0.742761]\n",
      "epoch:13 step:12249 [D loss: 0.675407, acc.: 54.69%] [G loss: 0.773501]\n",
      "epoch:13 step:12250 [D loss: 0.667908, acc.: 57.03%] [G loss: 0.700966]\n",
      "epoch:13 step:12251 [D loss: 0.716161, acc.: 46.09%] [G loss: 0.727996]\n",
      "epoch:13 step:12252 [D loss: 0.712155, acc.: 43.75%] [G loss: 0.702959]\n",
      "epoch:13 step:12253 [D loss: 0.683462, acc.: 52.34%] [G loss: 0.759975]\n",
      "epoch:13 step:12254 [D loss: 0.717917, acc.: 44.53%] [G loss: 0.757350]\n",
      "epoch:13 step:12255 [D loss: 0.686865, acc.: 51.56%] [G loss: 0.829939]\n",
      "epoch:13 step:12256 [D loss: 0.689190, acc.: 55.47%] [G loss: 0.769644]\n",
      "epoch:13 step:12257 [D loss: 0.677125, acc.: 59.38%] [G loss: 0.758759]\n",
      "epoch:13 step:12258 [D loss: 0.654442, acc.: 64.84%] [G loss: 0.776091]\n",
      "epoch:13 step:12259 [D loss: 0.707740, acc.: 44.53%] [G loss: 0.748978]\n",
      "epoch:13 step:12260 [D loss: 0.692269, acc.: 53.91%] [G loss: 0.783308]\n",
      "epoch:13 step:12261 [D loss: 0.687264, acc.: 60.16%] [G loss: 0.778905]\n",
      "epoch:13 step:12262 [D loss: 0.696557, acc.: 45.31%] [G loss: 0.782256]\n",
      "epoch:13 step:12263 [D loss: 0.690801, acc.: 52.34%] [G loss: 0.756577]\n",
      "epoch:13 step:12264 [D loss: 0.677308, acc.: 57.81%] [G loss: 0.774426]\n",
      "epoch:13 step:12265 [D loss: 0.696139, acc.: 51.56%] [G loss: 0.763305]\n",
      "epoch:13 step:12266 [D loss: 0.643610, acc.: 65.62%] [G loss: 0.724238]\n",
      "epoch:13 step:12267 [D loss: 0.686184, acc.: 55.47%] [G loss: 0.720538]\n",
      "epoch:13 step:12268 [D loss: 0.693543, acc.: 55.47%] [G loss: 0.753874]\n",
      "epoch:13 step:12269 [D loss: 0.691005, acc.: 56.25%] [G loss: 0.735350]\n",
      "epoch:13 step:12270 [D loss: 0.665495, acc.: 63.28%] [G loss: 0.742706]\n",
      "epoch:13 step:12271 [D loss: 0.714622, acc.: 50.78%] [G loss: 0.747777]\n",
      "epoch:13 step:12272 [D loss: 0.728197, acc.: 40.62%] [G loss: 0.744116]\n",
      "epoch:13 step:12273 [D loss: 0.673236, acc.: 60.16%] [G loss: 0.751481]\n",
      "epoch:13 step:12274 [D loss: 0.658293, acc.: 67.97%] [G loss: 0.773617]\n",
      "epoch:13 step:12275 [D loss: 0.637982, acc.: 71.88%] [G loss: 0.856524]\n",
      "epoch:13 step:12276 [D loss: 0.653551, acc.: 58.59%] [G loss: 0.785231]\n",
      "epoch:13 step:12277 [D loss: 0.658454, acc.: 57.81%] [G loss: 0.804572]\n",
      "epoch:13 step:12278 [D loss: 0.666321, acc.: 62.50%] [G loss: 0.799536]\n",
      "epoch:13 step:12279 [D loss: 0.690904, acc.: 56.25%] [G loss: 0.754991]\n",
      "epoch:13 step:12280 [D loss: 0.649872, acc.: 59.38%] [G loss: 0.814467]\n",
      "epoch:13 step:12281 [D loss: 0.655415, acc.: 61.72%] [G loss: 0.774104]\n",
      "epoch:13 step:12282 [D loss: 0.684502, acc.: 53.91%] [G loss: 0.737333]\n",
      "epoch:13 step:12283 [D loss: 0.714081, acc.: 45.31%] [G loss: 0.733983]\n",
      "epoch:13 step:12284 [D loss: 0.722814, acc.: 41.41%] [G loss: 0.734166]\n",
      "epoch:13 step:12285 [D loss: 0.687556, acc.: 55.47%] [G loss: 0.722292]\n",
      "epoch:13 step:12286 [D loss: 0.703567, acc.: 45.31%] [G loss: 0.744901]\n",
      "epoch:13 step:12287 [D loss: 0.701511, acc.: 50.00%] [G loss: 0.744083]\n",
      "epoch:13 step:12288 [D loss: 0.686527, acc.: 52.34%] [G loss: 0.785452]\n",
      "epoch:13 step:12289 [D loss: 0.706459, acc.: 50.78%] [G loss: 0.765283]\n",
      "epoch:13 step:12290 [D loss: 0.692986, acc.: 54.69%] [G loss: 0.757454]\n",
      "epoch:13 step:12291 [D loss: 0.690370, acc.: 53.12%] [G loss: 0.758458]\n",
      "epoch:13 step:12292 [D loss: 0.680198, acc.: 50.78%] [G loss: 0.758616]\n",
      "epoch:13 step:12293 [D loss: 0.669302, acc.: 58.59%] [G loss: 0.801608]\n",
      "epoch:13 step:12294 [D loss: 0.653360, acc.: 60.16%] [G loss: 0.760535]\n",
      "epoch:13 step:12295 [D loss: 0.691484, acc.: 50.00%] [G loss: 0.778832]\n",
      "epoch:13 step:12296 [D loss: 0.681895, acc.: 60.94%] [G loss: 0.756769]\n",
      "epoch:13 step:12297 [D loss: 0.658603, acc.: 51.56%] [G loss: 0.719339]\n",
      "epoch:13 step:12298 [D loss: 0.676466, acc.: 61.72%] [G loss: 0.728110]\n",
      "epoch:13 step:12299 [D loss: 0.709218, acc.: 47.66%] [G loss: 0.743316]\n",
      "epoch:13 step:12300 [D loss: 0.678081, acc.: 52.34%] [G loss: 0.727671]\n",
      "epoch:13 step:12301 [D loss: 0.724018, acc.: 50.78%] [G loss: 0.766384]\n",
      "epoch:13 step:12302 [D loss: 0.715117, acc.: 42.19%] [G loss: 0.763974]\n",
      "epoch:13 step:12303 [D loss: 0.686153, acc.: 60.94%] [G loss: 0.810160]\n",
      "epoch:13 step:12304 [D loss: 0.673773, acc.: 64.06%] [G loss: 0.842899]\n",
      "epoch:13 step:12305 [D loss: 0.645529, acc.: 68.75%] [G loss: 0.921877]\n",
      "epoch:13 step:12306 [D loss: 0.650720, acc.: 64.84%] [G loss: 0.851265]\n",
      "epoch:13 step:12307 [D loss: 0.634065, acc.: 70.31%] [G loss: 0.906771]\n",
      "epoch:13 step:12308 [D loss: 0.651888, acc.: 64.06%] [G loss: 0.929869]\n",
      "epoch:13 step:12309 [D loss: 0.708805, acc.: 47.66%] [G loss: 0.830771]\n",
      "epoch:13 step:12310 [D loss: 0.704643, acc.: 54.69%] [G loss: 0.800154]\n",
      "epoch:13 step:12311 [D loss: 0.673368, acc.: 60.16%] [G loss: 0.758342]\n",
      "epoch:13 step:12312 [D loss: 0.682475, acc.: 57.03%] [G loss: 0.698634]\n",
      "epoch:13 step:12313 [D loss: 0.704815, acc.: 51.56%] [G loss: 0.709028]\n",
      "epoch:13 step:12314 [D loss: 0.723596, acc.: 45.31%] [G loss: 0.727718]\n",
      "epoch:13 step:12315 [D loss: 0.710238, acc.: 50.00%] [G loss: 0.746163]\n",
      "epoch:13 step:12316 [D loss: 0.698574, acc.: 58.59%] [G loss: 0.746560]\n",
      "epoch:13 step:12317 [D loss: 0.695802, acc.: 57.03%] [G loss: 0.732059]\n",
      "epoch:13 step:12318 [D loss: 0.720864, acc.: 41.41%] [G loss: 0.737124]\n",
      "epoch:13 step:12319 [D loss: 0.702962, acc.: 52.34%] [G loss: 0.694160]\n",
      "epoch:13 step:12320 [D loss: 0.687624, acc.: 47.66%] [G loss: 0.720009]\n",
      "epoch:13 step:12321 [D loss: 0.691324, acc.: 52.34%] [G loss: 0.738207]\n",
      "epoch:13 step:12322 [D loss: 0.719846, acc.: 40.62%] [G loss: 0.743388]\n",
      "epoch:13 step:12323 [D loss: 0.703952, acc.: 46.88%] [G loss: 0.740502]\n",
      "epoch:13 step:12324 [D loss: 0.689163, acc.: 56.25%] [G loss: 0.735338]\n",
      "epoch:13 step:12325 [D loss: 0.683405, acc.: 57.81%] [G loss: 0.748367]\n",
      "epoch:13 step:12326 [D loss: 0.670328, acc.: 57.81%] [G loss: 0.748219]\n",
      "epoch:13 step:12327 [D loss: 0.663012, acc.: 55.47%] [G loss: 0.748929]\n",
      "epoch:13 step:12328 [D loss: 0.683419, acc.: 54.69%] [G loss: 0.782926]\n",
      "epoch:13 step:12329 [D loss: 0.688942, acc.: 51.56%] [G loss: 0.798126]\n",
      "epoch:13 step:12330 [D loss: 0.671973, acc.: 55.47%] [G loss: 0.757385]\n",
      "epoch:13 step:12331 [D loss: 0.671171, acc.: 63.28%] [G loss: 0.708977]\n",
      "epoch:13 step:12332 [D loss: 0.633985, acc.: 71.09%] [G loss: 0.731309]\n",
      "epoch:13 step:12333 [D loss: 0.665543, acc.: 63.28%] [G loss: 0.737507]\n",
      "epoch:13 step:12334 [D loss: 0.714835, acc.: 52.34%] [G loss: 0.727823]\n",
      "epoch:13 step:12335 [D loss: 0.707615, acc.: 50.78%] [G loss: 0.721010]\n",
      "epoch:13 step:12336 [D loss: 0.722356, acc.: 46.88%] [G loss: 0.714171]\n",
      "epoch:13 step:12337 [D loss: 0.685823, acc.: 53.12%] [G loss: 0.755191]\n",
      "epoch:13 step:12338 [D loss: 0.695798, acc.: 53.12%] [G loss: 0.749097]\n",
      "epoch:13 step:12339 [D loss: 0.697022, acc.: 57.81%] [G loss: 0.731559]\n",
      "epoch:13 step:12340 [D loss: 0.698648, acc.: 53.91%] [G loss: 0.752787]\n",
      "epoch:13 step:12341 [D loss: 0.716887, acc.: 46.09%] [G loss: 0.757215]\n",
      "epoch:13 step:12342 [D loss: 0.702570, acc.: 53.91%] [G loss: 0.746736]\n",
      "epoch:13 step:12343 [D loss: 0.704555, acc.: 51.56%] [G loss: 0.731176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12344 [D loss: 0.683463, acc.: 56.25%] [G loss: 0.760244]\n",
      "epoch:13 step:12345 [D loss: 0.663893, acc.: 56.25%] [G loss: 0.775696]\n",
      "epoch:13 step:12346 [D loss: 0.687867, acc.: 59.38%] [G loss: 0.787822]\n",
      "epoch:13 step:12347 [D loss: 0.684644, acc.: 48.44%] [G loss: 0.755802]\n",
      "epoch:13 step:12348 [D loss: 0.692920, acc.: 53.12%] [G loss: 0.780329]\n",
      "epoch:13 step:12349 [D loss: 0.665053, acc.: 58.59%] [G loss: 0.753053]\n",
      "epoch:13 step:12350 [D loss: 0.674576, acc.: 59.38%] [G loss: 0.750741]\n",
      "epoch:13 step:12351 [D loss: 0.666509, acc.: 60.16%] [G loss: 0.770657]\n",
      "epoch:13 step:12352 [D loss: 0.683308, acc.: 55.47%] [G loss: 0.751297]\n",
      "epoch:13 step:12353 [D loss: 0.685444, acc.: 56.25%] [G loss: 0.742612]\n",
      "epoch:13 step:12354 [D loss: 0.681182, acc.: 54.69%] [G loss: 0.738746]\n",
      "epoch:13 step:12355 [D loss: 0.703558, acc.: 55.47%] [G loss: 0.737792]\n",
      "epoch:13 step:12356 [D loss: 0.693550, acc.: 50.00%] [G loss: 0.719369]\n",
      "epoch:13 step:12357 [D loss: 0.680912, acc.: 55.47%] [G loss: 0.717152]\n",
      "epoch:13 step:12358 [D loss: 0.686522, acc.: 52.34%] [G loss: 0.745419]\n",
      "epoch:13 step:12359 [D loss: 0.685516, acc.: 59.38%] [G loss: 0.720419]\n",
      "epoch:13 step:12360 [D loss: 0.683141, acc.: 53.91%] [G loss: 0.728579]\n",
      "epoch:13 step:12361 [D loss: 0.672710, acc.: 58.59%] [G loss: 0.746119]\n",
      "epoch:13 step:12362 [D loss: 0.676654, acc.: 58.59%] [G loss: 0.736119]\n",
      "epoch:13 step:12363 [D loss: 0.697667, acc.: 50.00%] [G loss: 0.731098]\n",
      "epoch:13 step:12364 [D loss: 0.692219, acc.: 53.12%] [G loss: 0.728526]\n",
      "epoch:13 step:12365 [D loss: 0.662295, acc.: 63.28%] [G loss: 0.736096]\n",
      "epoch:13 step:12366 [D loss: 0.668495, acc.: 62.50%] [G loss: 0.731042]\n",
      "epoch:13 step:12367 [D loss: 0.678634, acc.: 52.34%] [G loss: 0.758035]\n",
      "epoch:13 step:12368 [D loss: 0.639158, acc.: 61.72%] [G loss: 0.712682]\n",
      "epoch:13 step:12369 [D loss: 0.698435, acc.: 48.44%] [G loss: 0.718115]\n",
      "epoch:13 step:12370 [D loss: 0.687705, acc.: 53.91%] [G loss: 0.734089]\n",
      "epoch:13 step:12371 [D loss: 0.689267, acc.: 53.12%] [G loss: 0.689376]\n",
      "epoch:13 step:12372 [D loss: 0.649443, acc.: 62.50%] [G loss: 0.720682]\n",
      "epoch:13 step:12373 [D loss: 0.638409, acc.: 65.62%] [G loss: 0.688513]\n",
      "epoch:13 step:12374 [D loss: 0.663321, acc.: 58.59%] [G loss: 0.710110]\n",
      "epoch:13 step:12375 [D loss: 0.684137, acc.: 58.59%] [G loss: 0.743269]\n",
      "epoch:13 step:12376 [D loss: 0.711617, acc.: 50.78%] [G loss: 0.774643]\n",
      "epoch:13 step:12377 [D loss: 0.683432, acc.: 56.25%] [G loss: 0.742408]\n",
      "epoch:13 step:12378 [D loss: 0.678774, acc.: 57.81%] [G loss: 0.783679]\n",
      "epoch:13 step:12379 [D loss: 0.665343, acc.: 58.59%] [G loss: 0.726773]\n",
      "epoch:13 step:12380 [D loss: 0.670966, acc.: 60.94%] [G loss: 0.849311]\n",
      "epoch:13 step:12381 [D loss: 0.694753, acc.: 53.12%] [G loss: 0.769028]\n",
      "epoch:13 step:12382 [D loss: 0.696681, acc.: 54.69%] [G loss: 0.791179]\n",
      "epoch:13 step:12383 [D loss: 0.686209, acc.: 60.16%] [G loss: 0.818077]\n",
      "epoch:13 step:12384 [D loss: 0.709687, acc.: 53.12%] [G loss: 0.791389]\n",
      "epoch:13 step:12385 [D loss: 0.635772, acc.: 65.62%] [G loss: 0.755933]\n",
      "epoch:13 step:12386 [D loss: 0.702202, acc.: 49.22%] [G loss: 0.774691]\n",
      "epoch:13 step:12387 [D loss: 0.657037, acc.: 64.06%] [G loss: 0.730989]\n",
      "epoch:13 step:12388 [D loss: 0.508742, acc.: 68.75%] [G loss: 0.726411]\n",
      "epoch:13 step:12389 [D loss: 0.686938, acc.: 59.38%] [G loss: 0.806688]\n",
      "epoch:13 step:12390 [D loss: 0.635344, acc.: 67.97%] [G loss: 0.795752]\n",
      "epoch:13 step:12391 [D loss: 0.720339, acc.: 52.34%] [G loss: 0.746668]\n",
      "epoch:13 step:12392 [D loss: 0.694833, acc.: 49.22%] [G loss: 0.700332]\n",
      "epoch:13 step:12393 [D loss: 0.707708, acc.: 50.00%] [G loss: 0.719990]\n",
      "epoch:13 step:12394 [D loss: 0.728610, acc.: 50.78%] [G loss: 0.641046]\n",
      "epoch:13 step:12395 [D loss: 0.801407, acc.: 30.47%] [G loss: 0.797826]\n",
      "epoch:13 step:12396 [D loss: 0.706555, acc.: 39.06%] [G loss: 0.783516]\n",
      "epoch:13 step:12397 [D loss: 0.952288, acc.: 46.88%] [G loss: 0.788006]\n",
      "epoch:13 step:12398 [D loss: 0.689420, acc.: 51.56%] [G loss: 0.889055]\n",
      "epoch:13 step:12399 [D loss: 0.672934, acc.: 53.91%] [G loss: 0.897027]\n",
      "epoch:13 step:12400 [D loss: 0.643349, acc.: 61.72%] [G loss: 0.986634]\n",
      "epoch:13 step:12401 [D loss: 0.685366, acc.: 53.12%] [G loss: 0.842191]\n",
      "epoch:13 step:12402 [D loss: 0.656230, acc.: 55.47%] [G loss: 0.821817]\n",
      "epoch:13 step:12403 [D loss: 0.671048, acc.: 53.91%] [G loss: 0.817868]\n",
      "epoch:13 step:12404 [D loss: 0.672169, acc.: 50.78%] [G loss: 0.811805]\n",
      "epoch:13 step:12405 [D loss: 0.715889, acc.: 48.44%] [G loss: 1.515113]\n",
      "epoch:13 step:12406 [D loss: 0.747086, acc.: 42.97%] [G loss: 0.787452]\n",
      "epoch:13 step:12407 [D loss: 0.700715, acc.: 51.56%] [G loss: 0.722591]\n",
      "epoch:13 step:12408 [D loss: 0.694615, acc.: 56.25%] [G loss: 0.699512]\n",
      "epoch:13 step:12409 [D loss: 0.707805, acc.: 52.34%] [G loss: 0.751008]\n",
      "epoch:13 step:12410 [D loss: 0.679397, acc.: 62.50%] [G loss: 0.780721]\n",
      "epoch:13 step:12411 [D loss: 0.646528, acc.: 66.41%] [G loss: 0.746978]\n",
      "epoch:13 step:12412 [D loss: 0.647573, acc.: 69.53%] [G loss: 0.786614]\n",
      "epoch:13 step:12413 [D loss: 0.635003, acc.: 67.97%] [G loss: 0.804590]\n",
      "epoch:13 step:12414 [D loss: 0.700130, acc.: 53.91%] [G loss: 0.818872]\n",
      "epoch:13 step:12415 [D loss: 0.683985, acc.: 57.03%] [G loss: 0.822935]\n",
      "epoch:13 step:12416 [D loss: 0.662419, acc.: 65.62%] [G loss: 0.817632]\n",
      "epoch:13 step:12417 [D loss: 0.689818, acc.: 54.69%] [G loss: 0.806780]\n",
      "epoch:13 step:12418 [D loss: 0.712385, acc.: 40.62%] [G loss: 0.802133]\n",
      "epoch:13 step:12419 [D loss: 0.683136, acc.: 59.38%] [G loss: 0.787609]\n",
      "epoch:13 step:12420 [D loss: 0.704121, acc.: 55.47%] [G loss: 0.778915]\n",
      "epoch:13 step:12421 [D loss: 0.697000, acc.: 50.00%] [G loss: 0.831678]\n",
      "epoch:13 step:12422 [D loss: 0.699930, acc.: 50.78%] [G loss: 0.777524]\n",
      "epoch:13 step:12423 [D loss: 0.675427, acc.: 60.94%] [G loss: 0.724448]\n",
      "epoch:13 step:12424 [D loss: 0.657821, acc.: 67.19%] [G loss: 0.780251]\n",
      "epoch:13 step:12425 [D loss: 0.678127, acc.: 57.03%] [G loss: 0.767087]\n",
      "epoch:13 step:12426 [D loss: 0.703901, acc.: 53.12%] [G loss: 0.730341]\n",
      "epoch:13 step:12427 [D loss: 0.692024, acc.: 49.22%] [G loss: 0.736344]\n",
      "epoch:13 step:12428 [D loss: 0.671000, acc.: 54.69%] [G loss: 0.774806]\n",
      "epoch:13 step:12429 [D loss: 0.665749, acc.: 64.06%] [G loss: 0.787570]\n",
      "epoch:13 step:12430 [D loss: 0.683770, acc.: 57.81%] [G loss: 0.758597]\n",
      "epoch:13 step:12431 [D loss: 0.665655, acc.: 60.16%] [G loss: 0.756353]\n",
      "epoch:13 step:12432 [D loss: 0.664331, acc.: 58.59%] [G loss: 0.783915]\n",
      "epoch:13 step:12433 [D loss: 0.684984, acc.: 53.91%] [G loss: 0.762002]\n",
      "epoch:13 step:12434 [D loss: 0.670477, acc.: 53.12%] [G loss: 0.787227]\n",
      "epoch:13 step:12435 [D loss: 0.660871, acc.: 60.16%] [G loss: 0.774494]\n",
      "epoch:13 step:12436 [D loss: 0.698957, acc.: 53.91%] [G loss: 0.770166]\n",
      "epoch:13 step:12437 [D loss: 0.709674, acc.: 53.12%] [G loss: 0.763557]\n",
      "epoch:13 step:12438 [D loss: 0.703781, acc.: 52.34%] [G loss: 0.760617]\n",
      "epoch:13 step:12439 [D loss: 0.711465, acc.: 45.31%] [G loss: 0.756171]\n",
      "epoch:13 step:12440 [D loss: 0.694839, acc.: 50.00%] [G loss: 0.728475]\n",
      "epoch:13 step:12441 [D loss: 0.697823, acc.: 53.12%] [G loss: 0.740897]\n",
      "epoch:13 step:12442 [D loss: 0.667013, acc.: 58.59%] [G loss: 0.760829]\n",
      "epoch:13 step:12443 [D loss: 0.667827, acc.: 60.94%] [G loss: 0.771511]\n",
      "epoch:13 step:12444 [D loss: 0.549565, acc.: 64.84%] [G loss: 0.779585]\n",
      "epoch:13 step:12445 [D loss: 0.646932, acc.: 62.50%] [G loss: 0.886532]\n",
      "epoch:13 step:12446 [D loss: 0.690580, acc.: 53.91%] [G loss: 0.804810]\n",
      "epoch:13 step:12447 [D loss: 0.698997, acc.: 48.44%] [G loss: 0.759583]\n",
      "epoch:13 step:12448 [D loss: 0.689424, acc.: 53.91%] [G loss: 0.748740]\n",
      "epoch:13 step:12449 [D loss: 0.691705, acc.: 52.34%] [G loss: 0.786385]\n",
      "epoch:13 step:12450 [D loss: 0.707729, acc.: 48.44%] [G loss: 0.740695]\n",
      "epoch:13 step:12451 [D loss: 0.689114, acc.: 52.34%] [G loss: 0.788036]\n",
      "epoch:13 step:12452 [D loss: 0.650379, acc.: 60.16%] [G loss: 0.773036]\n",
      "epoch:13 step:12453 [D loss: 0.683346, acc.: 53.91%] [G loss: 0.748817]\n",
      "epoch:13 step:12454 [D loss: 0.712438, acc.: 50.78%] [G loss: 0.768878]\n",
      "epoch:13 step:12455 [D loss: 0.657339, acc.: 54.69%] [G loss: 0.788153]\n",
      "epoch:13 step:12456 [D loss: 0.690409, acc.: 50.78%] [G loss: 0.781201]\n",
      "epoch:13 step:12457 [D loss: 0.639910, acc.: 62.50%] [G loss: 0.848744]\n",
      "epoch:13 step:12458 [D loss: 0.704325, acc.: 47.66%] [G loss: 0.803086]\n",
      "epoch:13 step:12459 [D loss: 0.706395, acc.: 47.66%] [G loss: 0.814178]\n",
      "epoch:13 step:12460 [D loss: 0.707484, acc.: 51.56%] [G loss: 0.763014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12461 [D loss: 0.697810, acc.: 50.78%] [G loss: 0.792183]\n",
      "epoch:13 step:12462 [D loss: 0.697641, acc.: 50.00%] [G loss: 0.817372]\n",
      "epoch:13 step:12463 [D loss: 0.701495, acc.: 53.91%] [G loss: 0.789180]\n",
      "epoch:13 step:12464 [D loss: 0.667022, acc.: 63.28%] [G loss: 0.788055]\n",
      "epoch:13 step:12465 [D loss: 0.708056, acc.: 46.88%] [G loss: 0.785529]\n",
      "epoch:13 step:12466 [D loss: 0.673277, acc.: 54.69%] [G loss: 0.780158]\n",
      "epoch:13 step:12467 [D loss: 0.650877, acc.: 65.62%] [G loss: 0.783007]\n",
      "epoch:13 step:12468 [D loss: 0.661393, acc.: 55.47%] [G loss: 0.761151]\n",
      "epoch:13 step:12469 [D loss: 0.675160, acc.: 53.91%] [G loss: 0.770595]\n",
      "epoch:13 step:12470 [D loss: 0.671708, acc.: 64.06%] [G loss: 0.797038]\n",
      "epoch:13 step:12471 [D loss: 0.668196, acc.: 60.16%] [G loss: 0.757114]\n",
      "epoch:13 step:12472 [D loss: 0.719277, acc.: 50.00%] [G loss: 0.787170]\n",
      "epoch:13 step:12473 [D loss: 0.682266, acc.: 54.69%] [G loss: 0.701515]\n",
      "epoch:13 step:12474 [D loss: 0.680529, acc.: 61.72%] [G loss: 0.754811]\n",
      "epoch:13 step:12475 [D loss: 0.684582, acc.: 60.16%] [G loss: 0.773423]\n",
      "epoch:13 step:12476 [D loss: 0.715986, acc.: 49.22%] [G loss: 0.792644]\n",
      "epoch:13 step:12477 [D loss: 0.700755, acc.: 53.12%] [G loss: 0.779683]\n",
      "epoch:13 step:12478 [D loss: 0.692916, acc.: 56.25%] [G loss: 0.754883]\n",
      "epoch:13 step:12479 [D loss: 0.697938, acc.: 50.00%] [G loss: 0.758057]\n",
      "epoch:13 step:12480 [D loss: 0.692031, acc.: 55.47%] [G loss: 0.772130]\n",
      "epoch:13 step:12481 [D loss: 0.685732, acc.: 56.25%] [G loss: 0.697740]\n",
      "epoch:13 step:12482 [D loss: 0.682227, acc.: 59.38%] [G loss: 0.749071]\n",
      "epoch:13 step:12483 [D loss: 0.690584, acc.: 51.56%] [G loss: 0.727752]\n",
      "epoch:13 step:12484 [D loss: 0.681170, acc.: 57.81%] [G loss: 0.752088]\n",
      "epoch:13 step:12485 [D loss: 0.679616, acc.: 53.91%] [G loss: 0.749555]\n",
      "epoch:13 step:12486 [D loss: 0.675468, acc.: 57.81%] [G loss: 0.736611]\n",
      "epoch:13 step:12487 [D loss: 0.681540, acc.: 52.34%] [G loss: 0.761043]\n",
      "epoch:13 step:12488 [D loss: 0.704906, acc.: 52.34%] [G loss: 0.774733]\n",
      "epoch:13 step:12489 [D loss: 0.692381, acc.: 52.34%] [G loss: 0.701878]\n",
      "epoch:13 step:12490 [D loss: 0.672054, acc.: 59.38%] [G loss: 0.751385]\n",
      "epoch:13 step:12491 [D loss: 0.664287, acc.: 58.59%] [G loss: 0.742758]\n",
      "epoch:13 step:12492 [D loss: 0.689999, acc.: 52.34%] [G loss: 0.738338]\n",
      "epoch:13 step:12493 [D loss: 0.673337, acc.: 57.81%] [G loss: 0.779822]\n",
      "epoch:13 step:12494 [D loss: 0.676742, acc.: 60.16%] [G loss: 0.734331]\n",
      "epoch:13 step:12495 [D loss: 0.648102, acc.: 62.50%] [G loss: 0.803648]\n",
      "epoch:13 step:12496 [D loss: 0.668155, acc.: 57.81%] [G loss: 0.766307]\n",
      "epoch:13 step:12497 [D loss: 0.680391, acc.: 53.91%] [G loss: 0.788192]\n",
      "epoch:13 step:12498 [D loss: 0.675490, acc.: 56.25%] [G loss: 0.806154]\n",
      "epoch:13 step:12499 [D loss: 0.697672, acc.: 47.66%] [G loss: 0.789196]\n",
      "epoch:13 step:12500 [D loss: 0.678997, acc.: 50.78%] [G loss: 0.773630]\n",
      "epoch:13 step:12501 [D loss: 0.715739, acc.: 47.66%] [G loss: 0.721743]\n",
      "epoch:13 step:12502 [D loss: 0.684882, acc.: 58.59%] [G loss: 0.781261]\n",
      "epoch:13 step:12503 [D loss: 0.688774, acc.: 58.59%] [G loss: 0.726421]\n",
      "epoch:13 step:12504 [D loss: 0.708731, acc.: 44.53%] [G loss: 0.722520]\n",
      "epoch:13 step:12505 [D loss: 0.714483, acc.: 47.66%] [G loss: 0.728067]\n",
      "epoch:13 step:12506 [D loss: 0.682890, acc.: 50.78%] [G loss: 0.717340]\n",
      "epoch:13 step:12507 [D loss: 0.717523, acc.: 42.97%] [G loss: 0.695867]\n",
      "epoch:13 step:12508 [D loss: 0.685024, acc.: 57.03%] [G loss: 0.704054]\n",
      "epoch:13 step:12509 [D loss: 0.687306, acc.: 51.56%] [G loss: 0.729725]\n",
      "epoch:13 step:12510 [D loss: 0.706140, acc.: 51.56%] [G loss: 0.715029]\n",
      "epoch:13 step:12511 [D loss: 0.717218, acc.: 41.41%] [G loss: 0.716303]\n",
      "epoch:13 step:12512 [D loss: 0.686778, acc.: 58.59%] [G loss: 0.731452]\n",
      "epoch:13 step:12513 [D loss: 0.690313, acc.: 51.56%] [G loss: 0.753641]\n",
      "epoch:13 step:12514 [D loss: 0.690075, acc.: 52.34%] [G loss: 0.742107]\n",
      "epoch:13 step:12515 [D loss: 0.713454, acc.: 46.88%] [G loss: 0.711033]\n",
      "epoch:13 step:12516 [D loss: 0.695617, acc.: 44.53%] [G loss: 0.732408]\n",
      "epoch:13 step:12517 [D loss: 0.679529, acc.: 57.03%] [G loss: 0.726503]\n",
      "epoch:13 step:12518 [D loss: 0.687233, acc.: 54.69%] [G loss: 0.749746]\n",
      "epoch:13 step:12519 [D loss: 0.684723, acc.: 52.34%] [G loss: 0.745707]\n",
      "epoch:13 step:12520 [D loss: 0.687407, acc.: 57.03%] [G loss: 0.743239]\n",
      "epoch:13 step:12521 [D loss: 0.697624, acc.: 42.19%] [G loss: 0.712742]\n",
      "epoch:13 step:12522 [D loss: 0.694499, acc.: 51.56%] [G loss: 0.719786]\n",
      "epoch:13 step:12523 [D loss: 0.690506, acc.: 53.91%] [G loss: 0.717124]\n",
      "epoch:13 step:12524 [D loss: 0.680958, acc.: 54.69%] [G loss: 0.716968]\n",
      "epoch:13 step:12525 [D loss: 0.671339, acc.: 60.16%] [G loss: 0.712157]\n",
      "epoch:13 step:12526 [D loss: 0.683630, acc.: 58.59%] [G loss: 0.745646]\n",
      "epoch:13 step:12527 [D loss: 0.675309, acc.: 61.72%] [G loss: 0.765921]\n",
      "epoch:13 step:12528 [D loss: 0.655999, acc.: 64.06%] [G loss: 0.778085]\n",
      "epoch:13 step:12529 [D loss: 0.696011, acc.: 53.12%] [G loss: 0.764130]\n",
      "epoch:13 step:12530 [D loss: 0.708643, acc.: 46.88%] [G loss: 0.758960]\n",
      "epoch:13 step:12531 [D loss: 0.694631, acc.: 50.00%] [G loss: 0.770636]\n",
      "epoch:13 step:12532 [D loss: 0.668740, acc.: 63.28%] [G loss: 0.760190]\n",
      "epoch:13 step:12533 [D loss: 0.682557, acc.: 59.38%] [G loss: 0.783206]\n",
      "epoch:13 step:12534 [D loss: 0.667388, acc.: 60.16%] [G loss: 0.786305]\n",
      "epoch:13 step:12535 [D loss: 0.673840, acc.: 64.84%] [G loss: 0.789380]\n",
      "epoch:13 step:12536 [D loss: 0.671572, acc.: 58.59%] [G loss: 0.787611]\n",
      "epoch:13 step:12537 [D loss: 0.669900, acc.: 57.81%] [G loss: 0.746237]\n",
      "epoch:13 step:12538 [D loss: 0.700393, acc.: 47.66%] [G loss: 0.714286]\n",
      "epoch:13 step:12539 [D loss: 0.656761, acc.: 60.16%] [G loss: 0.740822]\n",
      "epoch:13 step:12540 [D loss: 0.692321, acc.: 58.59%] [G loss: 0.761548]\n",
      "epoch:13 step:12541 [D loss: 0.667452, acc.: 57.03%] [G loss: 0.739303]\n",
      "epoch:13 step:12542 [D loss: 0.682930, acc.: 59.38%] [G loss: 0.785611]\n",
      "epoch:13 step:12543 [D loss: 0.687965, acc.: 53.91%] [G loss: 0.755576]\n",
      "epoch:13 step:12544 [D loss: 0.698352, acc.: 53.12%] [G loss: 0.740891]\n",
      "epoch:13 step:12545 [D loss: 0.679244, acc.: 60.94%] [G loss: 0.790754]\n",
      "epoch:13 step:12546 [D loss: 0.675890, acc.: 57.03%] [G loss: 0.748555]\n",
      "epoch:13 step:12547 [D loss: 0.704064, acc.: 47.66%] [G loss: 0.753464]\n",
      "epoch:13 step:12548 [D loss: 0.678405, acc.: 54.69%] [G loss: 0.746922]\n",
      "epoch:13 step:12549 [D loss: 0.697833, acc.: 52.34%] [G loss: 0.771517]\n",
      "epoch:13 step:12550 [D loss: 0.698559, acc.: 47.66%] [G loss: 0.788512]\n",
      "epoch:13 step:12551 [D loss: 0.672315, acc.: 57.03%] [G loss: 0.735016]\n",
      "epoch:13 step:12552 [D loss: 0.655055, acc.: 57.03%] [G loss: 0.744246]\n",
      "epoch:13 step:12553 [D loss: 0.669843, acc.: 54.69%] [G loss: 0.791246]\n",
      "epoch:13 step:12554 [D loss: 0.690341, acc.: 52.34%] [G loss: 0.762160]\n",
      "epoch:13 step:12555 [D loss: 0.694374, acc.: 49.22%] [G loss: 0.760360]\n",
      "epoch:13 step:12556 [D loss: 0.692469, acc.: 49.22%] [G loss: 0.713162]\n",
      "epoch:13 step:12557 [D loss: 0.676400, acc.: 51.56%] [G loss: 0.731170]\n",
      "epoch:13 step:12558 [D loss: 0.698286, acc.: 53.91%] [G loss: 0.706689]\n",
      "epoch:13 step:12559 [D loss: 0.679062, acc.: 53.91%] [G loss: 0.705481]\n",
      "epoch:13 step:12560 [D loss: 0.672582, acc.: 57.81%] [G loss: 0.732404]\n",
      "epoch:13 step:12561 [D loss: 0.686225, acc.: 55.47%] [G loss: 0.754946]\n",
      "epoch:13 step:12562 [D loss: 0.687880, acc.: 57.03%] [G loss: 0.722612]\n",
      "epoch:13 step:12563 [D loss: 0.706435, acc.: 48.44%] [G loss: 0.749856]\n",
      "epoch:13 step:12564 [D loss: 0.694682, acc.: 50.00%] [G loss: 0.731168]\n",
      "epoch:13 step:12565 [D loss: 0.688087, acc.: 57.81%] [G loss: 0.740210]\n",
      "epoch:13 step:12566 [D loss: 0.687784, acc.: 52.34%] [G loss: 0.728719]\n",
      "epoch:13 step:12567 [D loss: 0.650105, acc.: 63.28%] [G loss: 0.731640]\n",
      "epoch:13 step:12568 [D loss: 0.672023, acc.: 56.25%] [G loss: 0.748442]\n",
      "epoch:13 step:12569 [D loss: 0.666210, acc.: 58.59%] [G loss: 0.764980]\n",
      "epoch:13 step:12570 [D loss: 0.709942, acc.: 51.56%] [G loss: 0.756818]\n",
      "epoch:13 step:12571 [D loss: 0.711551, acc.: 46.09%] [G loss: 0.780511]\n",
      "epoch:13 step:12572 [D loss: 0.697022, acc.: 51.56%] [G loss: 0.767160]\n",
      "epoch:13 step:12573 [D loss: 0.693185, acc.: 52.34%] [G loss: 0.790189]\n",
      "epoch:13 step:12574 [D loss: 0.725826, acc.: 46.09%] [G loss: 0.787934]\n",
      "epoch:13 step:12575 [D loss: 0.689695, acc.: 54.69%] [G loss: 0.750085]\n",
      "epoch:13 step:12576 [D loss: 0.701095, acc.: 50.00%] [G loss: 0.750039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12577 [D loss: 0.677512, acc.: 59.38%] [G loss: 0.731740]\n",
      "epoch:13 step:12578 [D loss: 0.679183, acc.: 58.59%] [G loss: 0.749520]\n",
      "epoch:13 step:12579 [D loss: 0.658686, acc.: 68.75%] [G loss: 0.731326]\n",
      "epoch:13 step:12580 [D loss: 0.667663, acc.: 57.03%] [G loss: 0.752969]\n",
      "epoch:13 step:12581 [D loss: 0.700587, acc.: 48.44%] [G loss: 0.754548]\n",
      "epoch:13 step:12582 [D loss: 0.702320, acc.: 49.22%] [G loss: 0.716849]\n",
      "epoch:13 step:12583 [D loss: 0.704784, acc.: 49.22%] [G loss: 0.744252]\n",
      "epoch:13 step:12584 [D loss: 0.708133, acc.: 53.12%] [G loss: 0.770644]\n",
      "epoch:13 step:12585 [D loss: 0.648522, acc.: 68.75%] [G loss: 0.735706]\n",
      "epoch:13 step:12586 [D loss: 0.660720, acc.: 64.84%] [G loss: 0.752193]\n",
      "epoch:13 step:12587 [D loss: 0.633025, acc.: 65.62%] [G loss: 0.719245]\n",
      "epoch:13 step:12588 [D loss: 0.668491, acc.: 53.12%] [G loss: 0.732873]\n",
      "epoch:13 step:12589 [D loss: 0.654202, acc.: 64.84%] [G loss: 0.819541]\n",
      "epoch:13 step:12590 [D loss: 0.673526, acc.: 55.47%] [G loss: 0.731562]\n",
      "epoch:13 step:12591 [D loss: 0.712020, acc.: 50.00%] [G loss: 0.816086]\n",
      "epoch:13 step:12592 [D loss: 0.719964, acc.: 42.19%] [G loss: 0.721625]\n",
      "epoch:13 step:12593 [D loss: 0.690640, acc.: 50.78%] [G loss: 0.751845]\n",
      "epoch:13 step:12594 [D loss: 0.675358, acc.: 58.59%] [G loss: 0.706131]\n",
      "epoch:13 step:12595 [D loss: 0.681406, acc.: 52.34%] [G loss: 0.762399]\n",
      "epoch:13 step:12596 [D loss: 0.659013, acc.: 57.03%] [G loss: 0.708684]\n",
      "epoch:13 step:12597 [D loss: 0.683618, acc.: 55.47%] [G loss: 0.699261]\n",
      "epoch:13 step:12598 [D loss: 0.699666, acc.: 46.88%] [G loss: 0.717324]\n",
      "epoch:13 step:12599 [D loss: 0.689374, acc.: 52.34%] [G loss: 0.757148]\n",
      "epoch:13 step:12600 [D loss: 0.687329, acc.: 56.25%] [G loss: 0.765962]\n",
      "epoch:13 step:12601 [D loss: 0.696523, acc.: 52.34%] [G loss: 0.744066]\n",
      "epoch:13 step:12602 [D loss: 0.708909, acc.: 50.00%] [G loss: 0.756793]\n",
      "epoch:13 step:12603 [D loss: 0.716334, acc.: 46.09%] [G loss: 0.792227]\n",
      "epoch:13 step:12604 [D loss: 0.683778, acc.: 57.03%] [G loss: 0.767694]\n",
      "epoch:13 step:12605 [D loss: 0.661409, acc.: 63.28%] [G loss: 0.759100]\n",
      "epoch:13 step:12606 [D loss: 0.661311, acc.: 64.06%] [G loss: 0.801823]\n",
      "epoch:13 step:12607 [D loss: 0.659778, acc.: 58.59%] [G loss: 0.795200]\n",
      "epoch:13 step:12608 [D loss: 0.654885, acc.: 64.84%] [G loss: 0.753565]\n",
      "epoch:13 step:12609 [D loss: 0.660389, acc.: 56.25%] [G loss: 0.833039]\n",
      "epoch:13 step:12610 [D loss: 0.684704, acc.: 53.91%] [G loss: 0.829406]\n",
      "epoch:13 step:12611 [D loss: 0.661705, acc.: 61.72%] [G loss: 0.773482]\n",
      "epoch:13 step:12612 [D loss: 0.706097, acc.: 49.22%] [G loss: 0.824474]\n",
      "epoch:13 step:12613 [D loss: 0.746276, acc.: 40.62%] [G loss: 0.790807]\n",
      "epoch:13 step:12614 [D loss: 0.706346, acc.: 52.34%] [G loss: 0.748564]\n",
      "epoch:13 step:12615 [D loss: 0.693481, acc.: 50.78%] [G loss: 0.760719]\n",
      "epoch:13 step:12616 [D loss: 0.717753, acc.: 39.06%] [G loss: 0.776875]\n",
      "epoch:13 step:12617 [D loss: 0.679336, acc.: 53.91%] [G loss: 0.774227]\n",
      "epoch:13 step:12618 [D loss: 0.692345, acc.: 56.25%] [G loss: 0.753979]\n",
      "epoch:13 step:12619 [D loss: 0.664903, acc.: 53.91%] [G loss: 0.759908]\n",
      "epoch:13 step:12620 [D loss: 0.704864, acc.: 53.12%] [G loss: 0.765897]\n",
      "epoch:13 step:12621 [D loss: 0.695603, acc.: 44.53%] [G loss: 0.812720]\n",
      "epoch:13 step:12622 [D loss: 0.707174, acc.: 46.88%] [G loss: 0.751748]\n",
      "epoch:13 step:12623 [D loss: 0.677578, acc.: 56.25%] [G loss: 0.802273]\n",
      "epoch:13 step:12624 [D loss: 0.681255, acc.: 53.12%] [G loss: 0.779115]\n",
      "epoch:13 step:12625 [D loss: 0.675267, acc.: 60.94%] [G loss: 0.775826]\n",
      "epoch:13 step:12626 [D loss: 0.668324, acc.: 56.25%] [G loss: 0.798003]\n",
      "epoch:13 step:12627 [D loss: 0.667962, acc.: 61.72%] [G loss: 0.804187]\n",
      "epoch:13 step:12628 [D loss: 0.685592, acc.: 53.91%] [G loss: 0.719604]\n",
      "epoch:13 step:12629 [D loss: 0.701364, acc.: 45.31%] [G loss: 0.782250]\n",
      "epoch:13 step:12630 [D loss: 0.658393, acc.: 59.38%] [G loss: 0.775084]\n",
      "epoch:13 step:12631 [D loss: 0.645873, acc.: 65.62%] [G loss: 0.789363]\n",
      "epoch:13 step:12632 [D loss: 0.632678, acc.: 67.19%] [G loss: 0.834289]\n",
      "epoch:13 step:12633 [D loss: 0.624113, acc.: 68.75%] [G loss: 0.813580]\n",
      "epoch:13 step:12634 [D loss: 0.626516, acc.: 69.53%] [G loss: 0.796975]\n",
      "epoch:13 step:12635 [D loss: 0.664030, acc.: 59.38%] [G loss: 0.875300]\n",
      "epoch:13 step:12636 [D loss: 0.670809, acc.: 53.91%] [G loss: 0.814153]\n",
      "epoch:13 step:12637 [D loss: 0.564759, acc.: 65.62%] [G loss: 0.741280]\n",
      "epoch:13 step:12638 [D loss: 0.594931, acc.: 70.31%] [G loss: 0.838072]\n",
      "epoch:13 step:12639 [D loss: 0.721307, acc.: 46.88%] [G loss: 0.716357]\n",
      "epoch:13 step:12640 [D loss: 0.711040, acc.: 54.69%] [G loss: 0.737618]\n",
      "epoch:13 step:12641 [D loss: 0.673152, acc.: 57.81%] [G loss: 0.811269]\n",
      "epoch:13 step:12642 [D loss: 0.787560, acc.: 33.59%] [G loss: 0.741690]\n",
      "epoch:13 step:12643 [D loss: 0.740017, acc.: 38.28%] [G loss: 0.756554]\n",
      "epoch:13 step:12644 [D loss: 0.679311, acc.: 56.25%] [G loss: 0.779476]\n",
      "epoch:13 step:12645 [D loss: 0.705464, acc.: 54.69%] [G loss: 0.786164]\n",
      "epoch:13 step:12646 [D loss: 0.736461, acc.: 48.44%] [G loss: 0.763132]\n",
      "epoch:13 step:12647 [D loss: 0.707722, acc.: 42.19%] [G loss: 0.779600]\n",
      "epoch:13 step:12648 [D loss: 0.687457, acc.: 50.00%] [G loss: 0.754000]\n",
      "epoch:13 step:12649 [D loss: 0.671825, acc.: 58.59%] [G loss: 0.724500]\n",
      "epoch:13 step:12650 [D loss: 0.685782, acc.: 57.81%] [G loss: 0.736477]\n",
      "epoch:13 step:12651 [D loss: 0.634856, acc.: 67.97%] [G loss: 0.744763]\n",
      "epoch:13 step:12652 [D loss: 0.701285, acc.: 46.88%] [G loss: 0.786592]\n",
      "epoch:13 step:12653 [D loss: 0.672184, acc.: 61.72%] [G loss: 0.758953]\n",
      "epoch:13 step:12654 [D loss: 0.709387, acc.: 49.22%] [G loss: 0.779974]\n",
      "epoch:13 step:12655 [D loss: 0.674494, acc.: 61.72%] [G loss: 0.795889]\n",
      "epoch:13 step:12656 [D loss: 0.683305, acc.: 53.91%] [G loss: 0.920001]\n",
      "epoch:13 step:12657 [D loss: 0.664788, acc.: 63.28%] [G loss: 0.841396]\n",
      "epoch:13 step:12658 [D loss: 0.671017, acc.: 59.38%] [G loss: 0.809865]\n",
      "epoch:13 step:12659 [D loss: 0.673751, acc.: 57.81%] [G loss: 0.808013]\n",
      "epoch:13 step:12660 [D loss: 0.744935, acc.: 42.19%] [G loss: 0.781222]\n",
      "epoch:13 step:12661 [D loss: 0.694586, acc.: 57.81%] [G loss: 0.793431]\n",
      "epoch:13 step:12662 [D loss: 0.730265, acc.: 44.53%] [G loss: 0.785416]\n",
      "epoch:13 step:12663 [D loss: 0.670436, acc.: 57.03%] [G loss: 0.753675]\n",
      "epoch:13 step:12664 [D loss: 0.657127, acc.: 66.41%] [G loss: 0.797116]\n",
      "epoch:13 step:12665 [D loss: 0.637265, acc.: 64.06%] [G loss: 0.876077]\n",
      "epoch:13 step:12666 [D loss: 0.640193, acc.: 64.06%] [G loss: 0.876012]\n",
      "epoch:13 step:12667 [D loss: 0.673943, acc.: 57.03%] [G loss: 0.838567]\n",
      "epoch:13 step:12668 [D loss: 0.656627, acc.: 59.38%] [G loss: 0.811752]\n",
      "epoch:13 step:12669 [D loss: 0.633018, acc.: 63.28%] [G loss: 0.795686]\n",
      "epoch:13 step:12670 [D loss: 0.701463, acc.: 50.78%] [G loss: 0.804856]\n",
      "epoch:13 step:12671 [D loss: 0.723001, acc.: 48.44%] [G loss: 0.771377]\n",
      "epoch:13 step:12672 [D loss: 0.711947, acc.: 53.12%] [G loss: 0.839994]\n",
      "epoch:13 step:12673 [D loss: 0.698642, acc.: 49.22%] [G loss: 0.773806]\n",
      "epoch:13 step:12674 [D loss: 0.663129, acc.: 60.94%] [G loss: 0.756428]\n",
      "epoch:13 step:12675 [D loss: 0.712077, acc.: 49.22%] [G loss: 0.711054]\n",
      "epoch:13 step:12676 [D loss: 0.661425, acc.: 60.16%] [G loss: 0.712917]\n",
      "epoch:13 step:12677 [D loss: 0.686820, acc.: 60.94%] [G loss: 0.739323]\n",
      "epoch:13 step:12678 [D loss: 0.654234, acc.: 64.84%] [G loss: 0.755281]\n",
      "epoch:13 step:12679 [D loss: 0.670604, acc.: 57.03%] [G loss: 0.878780]\n",
      "epoch:13 step:12680 [D loss: 0.646502, acc.: 63.28%] [G loss: 0.845901]\n",
      "epoch:13 step:12681 [D loss: 0.687804, acc.: 53.91%] [G loss: 0.782068]\n",
      "epoch:13 step:12682 [D loss: 0.704780, acc.: 50.00%] [G loss: 0.750882]\n",
      "epoch:13 step:12683 [D loss: 0.696487, acc.: 52.34%] [G loss: 0.781303]\n",
      "epoch:13 step:12684 [D loss: 0.727406, acc.: 47.66%] [G loss: 0.808513]\n",
      "epoch:13 step:12685 [D loss: 0.683469, acc.: 57.81%] [G loss: 0.780495]\n",
      "epoch:13 step:12686 [D loss: 0.644567, acc.: 64.06%] [G loss: 0.802759]\n",
      "epoch:13 step:12687 [D loss: 0.674911, acc.: 60.94%] [G loss: 0.781579]\n",
      "epoch:13 step:12688 [D loss: 0.620853, acc.: 71.09%] [G loss: 0.790542]\n",
      "epoch:13 step:12689 [D loss: 0.638901, acc.: 64.84%] [G loss: 0.801023]\n",
      "epoch:13 step:12690 [D loss: 0.708577, acc.: 50.78%] [G loss: 0.780510]\n",
      "epoch:13 step:12691 [D loss: 0.709927, acc.: 48.44%] [G loss: 0.854970]\n",
      "epoch:13 step:12692 [D loss: 0.718024, acc.: 44.53%] [G loss: 0.764506]\n",
      "epoch:13 step:12693 [D loss: 0.677254, acc.: 54.69%] [G loss: 0.806640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12694 [D loss: 0.663612, acc.: 57.81%] [G loss: 0.789093]\n",
      "epoch:13 step:12695 [D loss: 0.653074, acc.: 61.72%] [G loss: 0.796417]\n",
      "epoch:13 step:12696 [D loss: 0.669111, acc.: 60.16%] [G loss: 0.793414]\n",
      "epoch:13 step:12697 [D loss: 0.666190, acc.: 58.59%] [G loss: 0.799802]\n",
      "epoch:13 step:12698 [D loss: 0.660585, acc.: 60.16%] [G loss: 0.795819]\n",
      "epoch:13 step:12699 [D loss: 0.675466, acc.: 51.56%] [G loss: 0.816679]\n",
      "epoch:13 step:12700 [D loss: 0.688436, acc.: 54.69%] [G loss: 0.843840]\n",
      "epoch:13 step:12701 [D loss: 0.644568, acc.: 64.06%] [G loss: 0.800486]\n",
      "epoch:13 step:12702 [D loss: 0.662476, acc.: 60.16%] [G loss: 0.824742]\n",
      "epoch:13 step:12703 [D loss: 0.666959, acc.: 57.03%] [G loss: 0.883785]\n",
      "epoch:13 step:12704 [D loss: 0.635605, acc.: 65.62%] [G loss: 0.836373]\n",
      "epoch:13 step:12705 [D loss: 0.668039, acc.: 63.28%] [G loss: 0.793631]\n",
      "epoch:13 step:12706 [D loss: 0.670647, acc.: 61.72%] [G loss: 0.763131]\n",
      "epoch:13 step:12707 [D loss: 0.680754, acc.: 53.12%] [G loss: 0.779701]\n",
      "epoch:13 step:12708 [D loss: 0.674092, acc.: 52.34%] [G loss: 0.834658]\n",
      "epoch:13 step:12709 [D loss: 0.706012, acc.: 52.34%] [G loss: 0.749472]\n",
      "epoch:13 step:12710 [D loss: 0.706774, acc.: 48.44%] [G loss: 0.748980]\n",
      "epoch:13 step:12711 [D loss: 0.689830, acc.: 54.69%] [G loss: 0.803427]\n",
      "epoch:13 step:12712 [D loss: 0.691038, acc.: 59.38%] [G loss: 0.836954]\n",
      "epoch:13 step:12713 [D loss: 0.642915, acc.: 60.94%] [G loss: 0.737423]\n",
      "epoch:13 step:12714 [D loss: 0.659705, acc.: 59.38%] [G loss: 0.837076]\n",
      "epoch:13 step:12715 [D loss: 0.655591, acc.: 65.62%] [G loss: 0.805160]\n",
      "epoch:13 step:12716 [D loss: 0.691159, acc.: 50.78%] [G loss: 0.813740]\n",
      "epoch:13 step:12717 [D loss: 0.667983, acc.: 59.38%] [G loss: 0.762561]\n",
      "epoch:13 step:12718 [D loss: 0.686848, acc.: 60.16%] [G loss: 0.819167]\n",
      "epoch:13 step:12719 [D loss: 0.675779, acc.: 60.16%] [G loss: 0.837041]\n",
      "epoch:13 step:12720 [D loss: 0.706237, acc.: 53.12%] [G loss: 0.742844]\n",
      "epoch:13 step:12721 [D loss: 0.680483, acc.: 55.47%] [G loss: 0.744635]\n",
      "epoch:13 step:12722 [D loss: 0.654298, acc.: 61.72%] [G loss: 0.776269]\n",
      "epoch:13 step:12723 [D loss: 0.699024, acc.: 45.31%] [G loss: 0.769072]\n",
      "epoch:13 step:12724 [D loss: 0.609015, acc.: 69.53%] [G loss: 0.744748]\n",
      "epoch:13 step:12725 [D loss: 0.722633, acc.: 50.00%] [G loss: 0.718863]\n",
      "epoch:13 step:12726 [D loss: 0.647901, acc.: 66.41%] [G loss: 0.745127]\n",
      "epoch:13 step:12727 [D loss: 0.669162, acc.: 61.72%] [G loss: 0.769293]\n",
      "epoch:13 step:12728 [D loss: 0.715576, acc.: 44.53%] [G loss: 0.735512]\n",
      "epoch:13 step:12729 [D loss: 0.607356, acc.: 68.75%] [G loss: 0.807977]\n",
      "epoch:13 step:12730 [D loss: 0.704857, acc.: 57.81%] [G loss: 0.826092]\n",
      "epoch:13 step:12731 [D loss: 0.537361, acc.: 76.56%] [G loss: 0.804407]\n",
      "epoch:13 step:12732 [D loss: 0.652308, acc.: 62.50%] [G loss: 0.789772]\n",
      "epoch:13 step:12733 [D loss: 0.685506, acc.: 58.59%] [G loss: 0.764470]\n",
      "epoch:13 step:12734 [D loss: 0.702811, acc.: 56.25%] [G loss: 0.735295]\n",
      "epoch:13 step:12735 [D loss: 0.640516, acc.: 66.41%] [G loss: 0.726056]\n",
      "epoch:13 step:12736 [D loss: 0.649662, acc.: 60.16%] [G loss: 0.813867]\n",
      "epoch:13 step:12737 [D loss: 0.697743, acc.: 53.91%] [G loss: 0.804809]\n",
      "epoch:13 step:12738 [D loss: 0.690111, acc.: 49.22%] [G loss: 0.769569]\n",
      "epoch:13 step:12739 [D loss: 0.655173, acc.: 62.50%] [G loss: 0.753932]\n",
      "epoch:13 step:12740 [D loss: 0.734061, acc.: 42.97%] [G loss: 0.739563]\n",
      "epoch:13 step:12741 [D loss: 0.683882, acc.: 57.03%] [G loss: 0.803988]\n",
      "epoch:13 step:12742 [D loss: 0.696606, acc.: 46.88%] [G loss: 0.791691]\n",
      "epoch:13 step:12743 [D loss: 0.675307, acc.: 52.34%] [G loss: 0.874539]\n",
      "epoch:13 step:12744 [D loss: 0.679337, acc.: 56.25%] [G loss: 0.825937]\n",
      "epoch:13 step:12745 [D loss: 0.649849, acc.: 60.16%] [G loss: 0.749614]\n",
      "epoch:13 step:12746 [D loss: 0.652264, acc.: 65.62%] [G loss: 0.817798]\n",
      "epoch:13 step:12747 [D loss: 0.674466, acc.: 55.47%] [G loss: 0.796132]\n",
      "epoch:13 step:12748 [D loss: 0.655867, acc.: 61.72%] [G loss: 0.855247]\n",
      "epoch:13 step:12749 [D loss: 0.656139, acc.: 61.72%] [G loss: 0.795585]\n",
      "epoch:13 step:12750 [D loss: 0.719659, acc.: 45.31%] [G loss: 0.827177]\n",
      "epoch:13 step:12751 [D loss: 0.673877, acc.: 59.38%] [G loss: 0.895374]\n",
      "epoch:13 step:12752 [D loss: 0.677173, acc.: 54.69%] [G loss: 0.835906]\n",
      "epoch:13 step:12753 [D loss: 0.675613, acc.: 58.59%] [G loss: 0.850599]\n",
      "epoch:13 step:12754 [D loss: 0.645676, acc.: 64.84%] [G loss: 0.779121]\n",
      "epoch:13 step:12755 [D loss: 0.645810, acc.: 61.72%] [G loss: 0.785516]\n",
      "epoch:13 step:12756 [D loss: 0.653467, acc.: 62.50%] [G loss: 0.778070]\n",
      "epoch:13 step:12757 [D loss: 0.689284, acc.: 49.22%] [G loss: 0.811418]\n",
      "epoch:13 step:12758 [D loss: 0.665153, acc.: 60.94%] [G loss: 0.758779]\n",
      "epoch:13 step:12759 [D loss: 0.722465, acc.: 44.53%] [G loss: 0.745943]\n",
      "epoch:13 step:12760 [D loss: 0.716200, acc.: 54.69%] [G loss: 0.771781]\n",
      "epoch:13 step:12761 [D loss: 0.738391, acc.: 39.84%] [G loss: 0.789828]\n",
      "epoch:13 step:12762 [D loss: 0.678068, acc.: 58.59%] [G loss: 0.750703]\n",
      "epoch:13 step:12763 [D loss: 0.707619, acc.: 50.78%] [G loss: 0.791943]\n",
      "epoch:13 step:12764 [D loss: 0.728459, acc.: 44.53%] [G loss: 0.834963]\n",
      "epoch:13 step:12765 [D loss: 0.714159, acc.: 46.88%] [G loss: 0.849285]\n",
      "epoch:13 step:12766 [D loss: 0.642291, acc.: 60.94%] [G loss: 0.793892]\n",
      "epoch:13 step:12767 [D loss: 0.653161, acc.: 57.81%] [G loss: 0.892095]\n",
      "epoch:13 step:12768 [D loss: 0.678155, acc.: 58.59%] [G loss: 0.839514]\n",
      "epoch:13 step:12769 [D loss: 0.648946, acc.: 62.50%] [G loss: 0.901140]\n",
      "epoch:13 step:12770 [D loss: 0.655798, acc.: 61.72%] [G loss: 0.897932]\n",
      "epoch:13 step:12771 [D loss: 0.647675, acc.: 63.28%] [G loss: 0.841445]\n",
      "epoch:13 step:12772 [D loss: 0.654403, acc.: 59.38%] [G loss: 0.848430]\n",
      "epoch:13 step:12773 [D loss: 0.649711, acc.: 65.62%] [G loss: 0.834122]\n",
      "epoch:13 step:12774 [D loss: 0.686383, acc.: 60.16%] [G loss: 0.819187]\n",
      "epoch:13 step:12775 [D loss: 0.681340, acc.: 59.38%] [G loss: 0.830352]\n",
      "epoch:13 step:12776 [D loss: 0.693754, acc.: 53.12%] [G loss: 0.806164]\n",
      "epoch:13 step:12777 [D loss: 0.678449, acc.: 57.03%] [G loss: 0.753953]\n",
      "epoch:13 step:12778 [D loss: 0.675170, acc.: 62.50%] [G loss: 0.784874]\n",
      "epoch:13 step:12779 [D loss: 0.635123, acc.: 66.41%] [G loss: 0.819665]\n",
      "epoch:13 step:12780 [D loss: 0.672509, acc.: 55.47%] [G loss: 0.885257]\n",
      "epoch:13 step:12781 [D loss: 0.671028, acc.: 55.47%] [G loss: 0.875671]\n",
      "epoch:13 step:12782 [D loss: 0.674291, acc.: 61.72%] [G loss: 0.935768]\n",
      "epoch:13 step:12783 [D loss: 0.630353, acc.: 64.84%] [G loss: 0.889595]\n",
      "epoch:13 step:12784 [D loss: 0.675415, acc.: 58.59%] [G loss: 0.880392]\n",
      "epoch:13 step:12785 [D loss: 0.452187, acc.: 73.44%] [G loss: 0.952216]\n",
      "epoch:13 step:12786 [D loss: 0.670722, acc.: 60.16%] [G loss: 0.903536]\n",
      "epoch:13 step:12787 [D loss: 0.698004, acc.: 53.12%] [G loss: 0.834826]\n",
      "epoch:13 step:12788 [D loss: 0.724414, acc.: 52.34%] [G loss: 0.819223]\n",
      "epoch:13 step:12789 [D loss: 0.707534, acc.: 48.44%] [G loss: 0.796033]\n",
      "epoch:13 step:12790 [D loss: 0.690546, acc.: 51.56%] [G loss: 0.778833]\n",
      "epoch:13 step:12791 [D loss: 0.715447, acc.: 46.09%] [G loss: 0.821781]\n",
      "epoch:13 step:12792 [D loss: 0.655841, acc.: 58.59%] [G loss: 0.732311]\n",
      "epoch:13 step:12793 [D loss: 0.697276, acc.: 52.34%] [G loss: 0.773157]\n",
      "epoch:13 step:12794 [D loss: 0.673344, acc.: 53.91%] [G loss: 0.729969]\n",
      "epoch:13 step:12795 [D loss: 0.708390, acc.: 49.22%] [G loss: 0.743985]\n",
      "epoch:13 step:12796 [D loss: 0.695398, acc.: 56.25%] [G loss: 0.721765]\n",
      "epoch:13 step:12797 [D loss: 0.702204, acc.: 48.44%] [G loss: 0.752119]\n",
      "epoch:13 step:12798 [D loss: 0.679228, acc.: 53.12%] [G loss: 0.792988]\n",
      "epoch:13 step:12799 [D loss: 0.706788, acc.: 52.34%] [G loss: 0.778696]\n",
      "epoch:13 step:12800 [D loss: 0.675896, acc.: 60.16%] [G loss: 0.811641]\n",
      "epoch:13 step:12801 [D loss: 0.685919, acc.: 53.91%] [G loss: 0.832685]\n",
      "epoch:13 step:12802 [D loss: 0.667050, acc.: 58.59%] [G loss: 0.825323]\n",
      "epoch:13 step:12803 [D loss: 0.716782, acc.: 51.56%] [G loss: 0.856561]\n",
      "epoch:13 step:12804 [D loss: 0.682027, acc.: 52.34%] [G loss: 0.825170]\n",
      "epoch:13 step:12805 [D loss: 0.638033, acc.: 66.41%] [G loss: 0.847782]\n",
      "epoch:13 step:12806 [D loss: 0.674152, acc.: 51.56%] [G loss: 0.796232]\n",
      "epoch:13 step:12807 [D loss: 0.697153, acc.: 52.34%] [G loss: 0.807005]\n",
      "epoch:13 step:12808 [D loss: 0.656168, acc.: 64.06%] [G loss: 0.811994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12809 [D loss: 0.711749, acc.: 52.34%] [G loss: 0.813577]\n",
      "epoch:13 step:12810 [D loss: 0.683332, acc.: 57.03%] [G loss: 0.810117]\n",
      "epoch:13 step:12811 [D loss: 0.704636, acc.: 50.78%] [G loss: 0.788376]\n",
      "epoch:13 step:12812 [D loss: 0.689541, acc.: 57.81%] [G loss: 0.767637]\n",
      "epoch:13 step:12813 [D loss: 0.688296, acc.: 54.69%] [G loss: 0.750594]\n",
      "epoch:13 step:12814 [D loss: 0.698620, acc.: 57.03%] [G loss: 0.774175]\n",
      "epoch:13 step:12815 [D loss: 0.677725, acc.: 55.47%] [G loss: 0.777754]\n",
      "epoch:13 step:12816 [D loss: 0.666148, acc.: 57.81%] [G loss: 0.761367]\n",
      "epoch:13 step:12817 [D loss: 0.712346, acc.: 50.00%] [G loss: 0.765595]\n",
      "epoch:13 step:12818 [D loss: 0.695685, acc.: 50.00%] [G loss: 0.754286]\n",
      "epoch:13 step:12819 [D loss: 0.675900, acc.: 55.47%] [G loss: 0.780834]\n",
      "epoch:13 step:12820 [D loss: 0.679545, acc.: 50.00%] [G loss: 0.732682]\n",
      "epoch:13 step:12821 [D loss: 0.686580, acc.: 48.44%] [G loss: 0.769046]\n",
      "epoch:13 step:12822 [D loss: 0.677059, acc.: 55.47%] [G loss: 0.720498]\n",
      "epoch:13 step:12823 [D loss: 0.700548, acc.: 53.12%] [G loss: 0.748369]\n",
      "epoch:13 step:12824 [D loss: 0.676116, acc.: 50.78%] [G loss: 0.764897]\n",
      "epoch:13 step:12825 [D loss: 0.629013, acc.: 64.84%] [G loss: 0.776127]\n",
      "epoch:13 step:12826 [D loss: 0.653555, acc.: 64.06%] [G loss: 0.772237]\n",
      "epoch:13 step:12827 [D loss: 0.671299, acc.: 57.81%] [G loss: 0.741694]\n",
      "epoch:13 step:12828 [D loss: 0.703829, acc.: 55.47%] [G loss: 0.760605]\n",
      "epoch:13 step:12829 [D loss: 0.650743, acc.: 64.06%] [G loss: 0.773344]\n",
      "epoch:13 step:12830 [D loss: 0.669557, acc.: 60.16%] [G loss: 0.799033]\n",
      "epoch:13 step:12831 [D loss: 0.647389, acc.: 64.84%] [G loss: 0.829771]\n",
      "epoch:13 step:12832 [D loss: 0.651155, acc.: 59.38%] [G loss: 0.803528]\n",
      "epoch:13 step:12833 [D loss: 0.676222, acc.: 54.69%] [G loss: 0.790419]\n",
      "epoch:13 step:12834 [D loss: 0.683504, acc.: 54.69%] [G loss: 0.790359]\n",
      "epoch:13 step:12835 [D loss: 0.675028, acc.: 64.06%] [G loss: 0.851700]\n",
      "epoch:13 step:12836 [D loss: 0.709178, acc.: 50.78%] [G loss: 0.742793]\n",
      "epoch:13 step:12837 [D loss: 0.694163, acc.: 53.12%] [G loss: 0.780996]\n",
      "epoch:13 step:12838 [D loss: 0.682637, acc.: 50.78%] [G loss: 0.801880]\n",
      "epoch:13 step:12839 [D loss: 0.685076, acc.: 52.34%] [G loss: 0.801660]\n",
      "epoch:13 step:12840 [D loss: 0.660915, acc.: 56.25%] [G loss: 0.807333]\n",
      "epoch:13 step:12841 [D loss: 0.656856, acc.: 67.19%] [G loss: 0.788904]\n",
      "epoch:13 step:12842 [D loss: 0.635432, acc.: 64.06%] [G loss: 0.783899]\n",
      "epoch:13 step:12843 [D loss: 0.644293, acc.: 60.94%] [G loss: 0.902177]\n",
      "epoch:13 step:12844 [D loss: 0.689679, acc.: 53.12%] [G loss: 0.817571]\n",
      "epoch:13 step:12845 [D loss: 0.658379, acc.: 57.03%] [G loss: 0.810159]\n",
      "epoch:13 step:12846 [D loss: 0.698817, acc.: 50.78%] [G loss: 0.768209]\n",
      "epoch:13 step:12847 [D loss: 0.692260, acc.: 57.03%] [G loss: 0.833576]\n",
      "epoch:13 step:12848 [D loss: 0.701887, acc.: 51.56%] [G loss: 0.805582]\n",
      "epoch:13 step:12849 [D loss: 0.661796, acc.: 59.38%] [G loss: 0.774015]\n",
      "epoch:13 step:12850 [D loss: 0.679077, acc.: 55.47%] [G loss: 0.801991]\n",
      "epoch:13 step:12851 [D loss: 0.732577, acc.: 46.09%] [G loss: 0.729527]\n",
      "epoch:13 step:12852 [D loss: 0.740797, acc.: 42.97%] [G loss: 0.691091]\n",
      "epoch:13 step:12853 [D loss: 0.721717, acc.: 48.44%] [G loss: 0.769347]\n",
      "epoch:13 step:12854 [D loss: 0.731448, acc.: 49.22%] [G loss: 0.760994]\n",
      "epoch:13 step:12855 [D loss: 0.657700, acc.: 61.72%] [G loss: 0.747152]\n",
      "epoch:13 step:12856 [D loss: 0.675022, acc.: 58.59%] [G loss: 0.771734]\n",
      "epoch:13 step:12857 [D loss: 0.667911, acc.: 62.50%] [G loss: 0.781403]\n",
      "epoch:13 step:12858 [D loss: 0.718592, acc.: 49.22%] [G loss: 0.764778]\n",
      "epoch:13 step:12859 [D loss: 0.691595, acc.: 57.03%] [G loss: 0.748544]\n",
      "epoch:13 step:12860 [D loss: 0.681806, acc.: 56.25%] [G loss: 0.736183]\n",
      "epoch:13 step:12861 [D loss: 0.659134, acc.: 64.84%] [G loss: 0.763724]\n",
      "epoch:13 step:12862 [D loss: 0.690634, acc.: 57.03%] [G loss: 0.756358]\n",
      "epoch:13 step:12863 [D loss: 0.694194, acc.: 53.91%] [G loss: 0.778463]\n",
      "epoch:13 step:12864 [D loss: 0.675035, acc.: 60.16%] [G loss: 0.795356]\n",
      "epoch:13 step:12865 [D loss: 0.681066, acc.: 55.47%] [G loss: 0.770453]\n",
      "epoch:13 step:12866 [D loss: 0.652208, acc.: 60.16%] [G loss: 0.806097]\n",
      "epoch:13 step:12867 [D loss: 0.646214, acc.: 61.72%] [G loss: 0.786042]\n",
      "epoch:13 step:12868 [D loss: 0.671709, acc.: 58.59%] [G loss: 0.812163]\n",
      "epoch:13 step:12869 [D loss: 0.680300, acc.: 57.81%] [G loss: 0.757525]\n",
      "epoch:13 step:12870 [D loss: 0.665003, acc.: 56.25%] [G loss: 0.756691]\n",
      "epoch:13 step:12871 [D loss: 0.733760, acc.: 46.09%] [G loss: 0.805954]\n",
      "epoch:13 step:12872 [D loss: 0.684088, acc.: 53.91%] [G loss: 0.761922]\n",
      "epoch:13 step:12873 [D loss: 0.637454, acc.: 63.28%] [G loss: 0.792415]\n",
      "epoch:13 step:12874 [D loss: 0.651551, acc.: 63.28%] [G loss: 0.791293]\n",
      "epoch:13 step:12875 [D loss: 0.652228, acc.: 62.50%] [G loss: 0.772402]\n",
      "epoch:13 step:12876 [D loss: 0.680637, acc.: 57.81%] [G loss: 0.782408]\n",
      "epoch:13 step:12877 [D loss: 0.685971, acc.: 56.25%] [G loss: 0.747237]\n",
      "epoch:13 step:12878 [D loss: 0.658750, acc.: 59.38%] [G loss: 0.554859]\n",
      "epoch:13 step:12879 [D loss: 0.666697, acc.: 61.72%] [G loss: 0.841211]\n",
      "epoch:13 step:12880 [D loss: 0.664257, acc.: 58.59%] [G loss: 0.802748]\n",
      "epoch:13 step:12881 [D loss: 0.705863, acc.: 52.34%] [G loss: 0.838427]\n",
      "epoch:13 step:12882 [D loss: 0.694961, acc.: 49.22%] [G loss: 0.772967]\n",
      "epoch:13 step:12883 [D loss: 0.711851, acc.: 58.59%] [G loss: 0.778497]\n",
      "epoch:13 step:12884 [D loss: 0.714684, acc.: 46.88%] [G loss: 0.750258]\n",
      "epoch:13 step:12885 [D loss: 0.688046, acc.: 49.22%] [G loss: 0.861706]\n",
      "epoch:13 step:12886 [D loss: 0.658124, acc.: 63.28%] [G loss: 0.808097]\n",
      "epoch:13 step:12887 [D loss: 0.669343, acc.: 55.47%] [G loss: 0.756207]\n",
      "epoch:13 step:12888 [D loss: 0.634978, acc.: 67.97%] [G loss: 0.704267]\n",
      "epoch:13 step:12889 [D loss: 0.620508, acc.: 67.97%] [G loss: 0.836428]\n",
      "epoch:13 step:12890 [D loss: 0.625844, acc.: 67.19%] [G loss: 0.821696]\n",
      "epoch:13 step:12891 [D loss: 0.730247, acc.: 49.22%] [G loss: 0.777244]\n",
      "epoch:13 step:12892 [D loss: 0.738264, acc.: 42.97%] [G loss: 0.812438]\n",
      "epoch:13 step:12893 [D loss: 0.662685, acc.: 57.81%] [G loss: 0.777939]\n",
      "epoch:13 step:12894 [D loss: 0.642111, acc.: 68.75%] [G loss: 0.788080]\n",
      "epoch:13 step:12895 [D loss: 0.671725, acc.: 60.94%] [G loss: 0.748589]\n",
      "epoch:13 step:12896 [D loss: 0.707266, acc.: 58.59%] [G loss: 0.770800]\n",
      "epoch:13 step:12897 [D loss: 0.691632, acc.: 53.12%] [G loss: 0.799443]\n",
      "epoch:13 step:12898 [D loss: 0.661097, acc.: 60.94%] [G loss: 0.763885]\n",
      "epoch:13 step:12899 [D loss: 0.691225, acc.: 53.91%] [G loss: 0.764615]\n",
      "epoch:13 step:12900 [D loss: 0.707331, acc.: 48.44%] [G loss: 0.728716]\n",
      "epoch:13 step:12901 [D loss: 0.681321, acc.: 59.38%] [G loss: 0.763116]\n",
      "epoch:13 step:12902 [D loss: 0.682661, acc.: 52.34%] [G loss: 0.817823]\n",
      "epoch:13 step:12903 [D loss: 0.700074, acc.: 53.91%] [G loss: 0.764138]\n",
      "epoch:13 step:12904 [D loss: 0.656539, acc.: 62.50%] [G loss: 0.787257]\n",
      "epoch:13 step:12905 [D loss: 0.673777, acc.: 56.25%] [G loss: 0.765944]\n",
      "epoch:13 step:12906 [D loss: 0.692266, acc.: 55.47%] [G loss: 0.779840]\n",
      "epoch:13 step:12907 [D loss: 0.693362, acc.: 51.56%] [G loss: 0.787030]\n",
      "epoch:13 step:12908 [D loss: 0.676874, acc.: 55.47%] [G loss: 0.774022]\n",
      "epoch:13 step:12909 [D loss: 0.648847, acc.: 62.50%] [G loss: 0.728550]\n",
      "epoch:13 step:12910 [D loss: 0.659879, acc.: 61.72%] [G loss: 0.735000]\n",
      "epoch:13 step:12911 [D loss: 0.675947, acc.: 57.03%] [G loss: 0.758337]\n",
      "epoch:13 step:12912 [D loss: 0.674047, acc.: 52.34%] [G loss: 0.744300]\n",
      "epoch:13 step:12913 [D loss: 0.651285, acc.: 64.06%] [G loss: 0.783825]\n",
      "epoch:13 step:12914 [D loss: 0.667975, acc.: 57.81%] [G loss: 0.822139]\n",
      "epoch:13 step:12915 [D loss: 0.666886, acc.: 60.16%] [G loss: 0.834733]\n",
      "epoch:13 step:12916 [D loss: 0.689256, acc.: 57.03%] [G loss: 0.763883]\n",
      "epoch:13 step:12917 [D loss: 0.703035, acc.: 51.56%] [G loss: 0.802294]\n",
      "epoch:13 step:12918 [D loss: 0.689147, acc.: 50.00%] [G loss: 0.783419]\n",
      "epoch:13 step:12919 [D loss: 0.700189, acc.: 53.91%] [G loss: 0.780289]\n",
      "epoch:13 step:12920 [D loss: 0.713911, acc.: 50.78%] [G loss: 0.739063]\n",
      "epoch:13 step:12921 [D loss: 0.708240, acc.: 52.34%] [G loss: 0.798142]\n",
      "epoch:13 step:12922 [D loss: 0.708025, acc.: 44.53%] [G loss: 0.799990]\n",
      "epoch:13 step:12923 [D loss: 0.713068, acc.: 46.09%] [G loss: 0.748168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12924 [D loss: 0.693503, acc.: 54.69%] [G loss: 0.753618]\n",
      "epoch:13 step:12925 [D loss: 0.683934, acc.: 58.59%] [G loss: 0.758750]\n",
      "epoch:13 step:12926 [D loss: 0.671652, acc.: 62.50%] [G loss: 0.783476]\n",
      "epoch:13 step:12927 [D loss: 0.659550, acc.: 64.84%] [G loss: 0.787325]\n",
      "epoch:13 step:12928 [D loss: 0.647696, acc.: 66.41%] [G loss: 0.779818]\n",
      "epoch:13 step:12929 [D loss: 0.693779, acc.: 53.91%] [G loss: 0.743818]\n",
      "epoch:13 step:12930 [D loss: 0.717673, acc.: 49.22%] [G loss: 0.811474]\n",
      "epoch:13 step:12931 [D loss: 0.664077, acc.: 63.28%] [G loss: 0.769936]\n",
      "epoch:13 step:12932 [D loss: 0.663846, acc.: 59.38%] [G loss: 0.791668]\n",
      "epoch:13 step:12933 [D loss: 0.702667, acc.: 49.22%] [G loss: 0.758643]\n",
      "epoch:13 step:12934 [D loss: 0.709985, acc.: 50.00%] [G loss: 0.758446]\n",
      "epoch:13 step:12935 [D loss: 0.675230, acc.: 55.47%] [G loss: 0.785431]\n",
      "epoch:13 step:12936 [D loss: 0.656578, acc.: 60.16%] [G loss: 0.739869]\n",
      "epoch:13 step:12937 [D loss: 0.665363, acc.: 64.06%] [G loss: 0.775837]\n",
      "epoch:13 step:12938 [D loss: 0.681338, acc.: 55.47%] [G loss: 0.764134]\n",
      "epoch:13 step:12939 [D loss: 0.684512, acc.: 50.78%] [G loss: 0.751023]\n",
      "epoch:13 step:12940 [D loss: 0.703755, acc.: 51.56%] [G loss: 0.765558]\n",
      "epoch:13 step:12941 [D loss: 0.710223, acc.: 47.66%] [G loss: 0.793669]\n",
      "epoch:13 step:12942 [D loss: 0.672604, acc.: 59.38%] [G loss: 0.815948]\n",
      "epoch:13 step:12943 [D loss: 0.673953, acc.: 53.91%] [G loss: 0.778725]\n",
      "epoch:13 step:12944 [D loss: 0.671931, acc.: 61.72%] [G loss: 0.760659]\n",
      "epoch:13 step:12945 [D loss: 0.664895, acc.: 59.38%] [G loss: 0.768700]\n",
      "epoch:13 step:12946 [D loss: 0.722008, acc.: 45.31%] [G loss: 0.752674]\n",
      "epoch:13 step:12947 [D loss: 0.706499, acc.: 40.62%] [G loss: 0.785864]\n",
      "epoch:13 step:12948 [D loss: 0.675658, acc.: 53.12%] [G loss: 0.752236]\n",
      "epoch:13 step:12949 [D loss: 0.690967, acc.: 57.03%] [G loss: 0.756126]\n",
      "epoch:13 step:12950 [D loss: 0.673611, acc.: 62.50%] [G loss: 0.777295]\n",
      "epoch:13 step:12951 [D loss: 0.669009, acc.: 57.03%] [G loss: 0.807318]\n",
      "epoch:13 step:12952 [D loss: 0.687445, acc.: 55.47%] [G loss: 0.800359]\n",
      "epoch:13 step:12953 [D loss: 0.678805, acc.: 51.56%] [G loss: 0.802411]\n",
      "epoch:13 step:12954 [D loss: 0.645672, acc.: 67.19%] [G loss: 0.780728]\n",
      "epoch:13 step:12955 [D loss: 0.646993, acc.: 62.50%] [G loss: 0.760684]\n",
      "epoch:13 step:12956 [D loss: 0.599348, acc.: 70.31%] [G loss: 0.840184]\n",
      "epoch:13 step:12957 [D loss: 0.726331, acc.: 54.69%] [G loss: 0.862177]\n",
      "epoch:13 step:12958 [D loss: 0.683941, acc.: 60.94%] [G loss: 0.825390]\n",
      "epoch:13 step:12959 [D loss: 0.672224, acc.: 58.59%] [G loss: 0.814756]\n",
      "epoch:13 step:12960 [D loss: 0.727118, acc.: 43.75%] [G loss: 0.766586]\n",
      "epoch:13 step:12961 [D loss: 0.725283, acc.: 46.09%] [G loss: 0.721589]\n",
      "epoch:13 step:12962 [D loss: 0.677284, acc.: 53.91%] [G loss: 0.762890]\n",
      "epoch:13 step:12963 [D loss: 0.720601, acc.: 48.44%] [G loss: 0.805390]\n",
      "epoch:13 step:12964 [D loss: 0.702640, acc.: 55.47%] [G loss: 0.792289]\n",
      "epoch:13 step:12965 [D loss: 0.725880, acc.: 45.31%] [G loss: 0.783052]\n",
      "epoch:13 step:12966 [D loss: 0.678284, acc.: 51.56%] [G loss: 0.778065]\n",
      "epoch:13 step:12967 [D loss: 0.663213, acc.: 56.25%] [G loss: 0.766684]\n",
      "epoch:13 step:12968 [D loss: 0.686323, acc.: 62.50%] [G loss: 0.759442]\n",
      "epoch:13 step:12969 [D loss: 0.679597, acc.: 57.03%] [G loss: 0.771464]\n",
      "epoch:13 step:12970 [D loss: 0.675380, acc.: 55.47%] [G loss: 0.774188]\n",
      "epoch:13 step:12971 [D loss: 0.706726, acc.: 46.09%] [G loss: 0.753413]\n",
      "epoch:13 step:12972 [D loss: 0.680413, acc.: 51.56%] [G loss: 0.767211]\n",
      "epoch:13 step:12973 [D loss: 0.647203, acc.: 63.28%] [G loss: 0.760400]\n",
      "epoch:13 step:12974 [D loss: 0.676970, acc.: 55.47%] [G loss: 0.727521]\n",
      "epoch:13 step:12975 [D loss: 0.656581, acc.: 57.03%] [G loss: 0.715329]\n",
      "epoch:13 step:12976 [D loss: 0.655139, acc.: 57.81%] [G loss: 0.761790]\n",
      "epoch:13 step:12977 [D loss: 0.640932, acc.: 62.50%] [G loss: 0.768524]\n",
      "epoch:13 step:12978 [D loss: 0.715040, acc.: 47.66%] [G loss: 0.771220]\n",
      "epoch:13 step:12979 [D loss: 0.675794, acc.: 56.25%] [G loss: 0.700170]\n",
      "epoch:13 step:12980 [D loss: 0.695365, acc.: 55.47%] [G loss: 0.747566]\n",
      "epoch:13 step:12981 [D loss: 0.676017, acc.: 61.72%] [G loss: 0.772863]\n",
      "epoch:13 step:12982 [D loss: 0.674891, acc.: 56.25%] [G loss: 0.779701]\n",
      "epoch:13 step:12983 [D loss: 0.414270, acc.: 75.78%] [G loss: 0.799143]\n",
      "epoch:13 step:12984 [D loss: 0.664356, acc.: 60.16%] [G loss: 0.813210]\n",
      "epoch:13 step:12985 [D loss: 0.700814, acc.: 50.78%] [G loss: 0.753871]\n",
      "epoch:13 step:12986 [D loss: 0.677108, acc.: 53.91%] [G loss: 0.745025]\n",
      "epoch:13 step:12987 [D loss: 0.697850, acc.: 50.78%] [G loss: 0.739378]\n",
      "epoch:13 step:12988 [D loss: 0.702144, acc.: 45.31%] [G loss: 0.807444]\n",
      "epoch:13 step:12989 [D loss: 0.688725, acc.: 57.03%] [G loss: 0.811362]\n",
      "epoch:13 step:12990 [D loss: 0.683284, acc.: 50.00%] [G loss: 0.768843]\n",
      "epoch:13 step:12991 [D loss: 0.693617, acc.: 51.56%] [G loss: 0.804288]\n",
      "epoch:13 step:12992 [D loss: 0.679994, acc.: 54.69%] [G loss: 0.812687]\n",
      "epoch:13 step:12993 [D loss: 0.687695, acc.: 51.56%] [G loss: 0.789008]\n",
      "epoch:13 step:12994 [D loss: 0.720747, acc.: 44.53%] [G loss: 0.768455]\n",
      "epoch:13 step:12995 [D loss: 0.681917, acc.: 58.59%] [G loss: 0.821048]\n",
      "epoch:13 step:12996 [D loss: 0.637707, acc.: 63.28%] [G loss: 1.016653]\n",
      "epoch:13 step:12997 [D loss: 0.610043, acc.: 74.22%] [G loss: 0.756815]\n",
      "epoch:13 step:12998 [D loss: 0.719064, acc.: 49.22%] [G loss: 0.817389]\n",
      "epoch:13 step:12999 [D loss: 0.693223, acc.: 53.12%] [G loss: 0.801802]\n",
      "epoch:13 step:13000 [D loss: 0.745795, acc.: 51.56%] [G loss: 0.789909]\n",
      "epoch:13 step:13001 [D loss: 0.745519, acc.: 45.31%] [G loss: 0.770293]\n",
      "epoch:13 step:13002 [D loss: 0.725679, acc.: 40.62%] [G loss: 0.747776]\n",
      "epoch:13 step:13003 [D loss: 0.700125, acc.: 49.22%] [G loss: 0.784483]\n",
      "epoch:13 step:13004 [D loss: 0.708426, acc.: 53.12%] [G loss: 0.796348]\n",
      "epoch:13 step:13005 [D loss: 0.694825, acc.: 52.34%] [G loss: 0.794725]\n",
      "epoch:13 step:13006 [D loss: 0.699225, acc.: 52.34%] [G loss: 0.795568]\n",
      "epoch:13 step:13007 [D loss: 0.664964, acc.: 60.16%] [G loss: 0.782745]\n",
      "epoch:13 step:13008 [D loss: 0.699698, acc.: 50.00%] [G loss: 0.809929]\n",
      "epoch:13 step:13009 [D loss: 0.679277, acc.: 55.47%] [G loss: 0.775251]\n",
      "epoch:13 step:13010 [D loss: 0.671055, acc.: 60.16%] [G loss: 0.762664]\n",
      "epoch:13 step:13011 [D loss: 0.652477, acc.: 64.06%] [G loss: 0.744066]\n",
      "epoch:13 step:13012 [D loss: 0.682717, acc.: 53.12%] [G loss: 0.746772]\n",
      "epoch:13 step:13013 [D loss: 0.642546, acc.: 60.94%] [G loss: 0.776497]\n",
      "epoch:13 step:13014 [D loss: 0.653262, acc.: 59.38%] [G loss: 0.754931]\n",
      "epoch:13 step:13015 [D loss: 0.683208, acc.: 58.59%] [G loss: 0.760489]\n",
      "epoch:13 step:13016 [D loss: 0.652930, acc.: 65.62%] [G loss: 0.757308]\n",
      "epoch:13 step:13017 [D loss: 0.719210, acc.: 52.34%] [G loss: 0.744190]\n",
      "epoch:13 step:13018 [D loss: 0.708124, acc.: 50.78%] [G loss: 0.730234]\n",
      "epoch:13 step:13019 [D loss: 0.701562, acc.: 51.56%] [G loss: 0.719084]\n",
      "epoch:13 step:13020 [D loss: 0.661439, acc.: 61.72%] [G loss: 0.731164]\n",
      "epoch:13 step:13021 [D loss: 0.694274, acc.: 55.47%] [G loss: 0.725272]\n",
      "epoch:13 step:13022 [D loss: 0.683349, acc.: 53.12%] [G loss: 0.707996]\n",
      "epoch:13 step:13023 [D loss: 0.629947, acc.: 63.28%] [G loss: 0.770015]\n",
      "epoch:13 step:13024 [D loss: 0.714762, acc.: 44.53%] [G loss: 0.741550]\n",
      "epoch:13 step:13025 [D loss: 0.676898, acc.: 58.59%] [G loss: 0.729323]\n",
      "epoch:13 step:13026 [D loss: 0.611376, acc.: 61.72%] [G loss: 0.741839]\n",
      "epoch:13 step:13027 [D loss: 0.672869, acc.: 56.25%] [G loss: 0.725459]\n",
      "epoch:13 step:13028 [D loss: 0.680666, acc.: 56.25%] [G loss: 0.705836]\n",
      "epoch:13 step:13029 [D loss: 0.693544, acc.: 52.34%] [G loss: 0.726383]\n",
      "epoch:13 step:13030 [D loss: 0.690851, acc.: 58.59%] [G loss: 0.752122]\n",
      "epoch:13 step:13031 [D loss: 0.696972, acc.: 51.56%] [G loss: 0.745822]\n",
      "epoch:13 step:13032 [D loss: 0.699492, acc.: 44.53%] [G loss: 0.762080]\n",
      "epoch:13 step:13033 [D loss: 0.688819, acc.: 57.81%] [G loss: 0.794545]\n",
      "epoch:13 step:13034 [D loss: 0.688926, acc.: 57.81%] [G loss: 0.727334]\n",
      "epoch:13 step:13035 [D loss: 0.670430, acc.: 57.81%] [G loss: 0.734684]\n",
      "epoch:13 step:13036 [D loss: 0.668919, acc.: 60.16%] [G loss: 0.725152]\n",
      "epoch:13 step:13037 [D loss: 0.698934, acc.: 53.12%] [G loss: 0.713783]\n",
      "epoch:13 step:13038 [D loss: 0.659099, acc.: 63.28%] [G loss: 0.743887]\n",
      "epoch:13 step:13039 [D loss: 0.691041, acc.: 59.38%] [G loss: 0.765539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13040 [D loss: 0.684798, acc.: 53.12%] [G loss: 0.788126]\n",
      "epoch:13 step:13041 [D loss: 0.675547, acc.: 56.25%] [G loss: 0.777925]\n",
      "epoch:13 step:13042 [D loss: 0.684139, acc.: 50.00%] [G loss: 0.729851]\n",
      "epoch:13 step:13043 [D loss: 0.695409, acc.: 50.78%] [G loss: 0.737166]\n",
      "epoch:13 step:13044 [D loss: 0.668050, acc.: 56.25%] [G loss: 0.781725]\n",
      "epoch:13 step:13045 [D loss: 0.703085, acc.: 50.00%] [G loss: 0.754560]\n",
      "epoch:13 step:13046 [D loss: 0.696154, acc.: 51.56%] [G loss: 0.722921]\n",
      "epoch:13 step:13047 [D loss: 0.689825, acc.: 57.03%] [G loss: 0.753962]\n",
      "epoch:13 step:13048 [D loss: 0.669050, acc.: 58.59%] [G loss: 0.784428]\n",
      "epoch:13 step:13049 [D loss: 0.690835, acc.: 50.78%] [G loss: 0.758466]\n",
      "epoch:13 step:13050 [D loss: 0.679547, acc.: 57.03%] [G loss: 0.761055]\n",
      "epoch:13 step:13051 [D loss: 0.692209, acc.: 52.34%] [G loss: 0.744122]\n",
      "epoch:13 step:13052 [D loss: 0.688081, acc.: 46.09%] [G loss: 0.732376]\n",
      "epoch:13 step:13053 [D loss: 0.712328, acc.: 50.00%] [G loss: 0.728501]\n",
      "epoch:13 step:13054 [D loss: 0.699413, acc.: 53.12%] [G loss: 0.713638]\n",
      "epoch:13 step:13055 [D loss: 0.698496, acc.: 53.12%] [G loss: 0.738110]\n",
      "epoch:13 step:13056 [D loss: 0.660016, acc.: 58.59%] [G loss: 0.704099]\n",
      "epoch:13 step:13057 [D loss: 0.669324, acc.: 52.34%] [G loss: 0.705753]\n",
      "epoch:13 step:13058 [D loss: 0.661983, acc.: 57.03%] [G loss: 0.727155]\n",
      "epoch:13 step:13059 [D loss: 0.677658, acc.: 55.47%] [G loss: 0.714225]\n",
      "epoch:13 step:13060 [D loss: 0.696519, acc.: 54.69%] [G loss: 0.807253]\n",
      "epoch:13 step:13061 [D loss: 0.692236, acc.: 53.12%] [G loss: 0.738427]\n",
      "epoch:13 step:13062 [D loss: 0.686202, acc.: 51.56%] [G loss: 0.750802]\n",
      "epoch:13 step:13063 [D loss: 0.692464, acc.: 46.88%] [G loss: 0.732906]\n",
      "epoch:13 step:13064 [D loss: 0.682108, acc.: 55.47%] [G loss: 0.754635]\n",
      "epoch:13 step:13065 [D loss: 0.670146, acc.: 57.03%] [G loss: 0.744826]\n",
      "epoch:13 step:13066 [D loss: 0.662583, acc.: 61.72%] [G loss: 0.789430]\n",
      "epoch:13 step:13067 [D loss: 0.647350, acc.: 69.53%] [G loss: 0.805040]\n",
      "epoch:13 step:13068 [D loss: 0.663923, acc.: 59.38%] [G loss: 0.763412]\n",
      "epoch:13 step:13069 [D loss: 0.698742, acc.: 58.59%] [G loss: 0.783999]\n",
      "epoch:13 step:13070 [D loss: 0.667114, acc.: 60.94%] [G loss: 0.827460]\n",
      "epoch:13 step:13071 [D loss: 0.628837, acc.: 71.09%] [G loss: 0.768200]\n",
      "epoch:13 step:13072 [D loss: 0.739193, acc.: 46.88%] [G loss: 0.819703]\n",
      "epoch:13 step:13073 [D loss: 0.689680, acc.: 52.34%] [G loss: 0.768837]\n",
      "epoch:13 step:13074 [D loss: 0.666970, acc.: 60.94%] [G loss: 0.778179]\n",
      "epoch:13 step:13075 [D loss: 0.695417, acc.: 50.78%] [G loss: 0.729000]\n",
      "epoch:13 step:13076 [D loss: 0.679662, acc.: 56.25%] [G loss: 0.738295]\n",
      "epoch:13 step:13077 [D loss: 0.702490, acc.: 50.78%] [G loss: 0.757482]\n",
      "epoch:13 step:13078 [D loss: 0.684142, acc.: 55.47%] [G loss: 0.748768]\n",
      "epoch:13 step:13079 [D loss: 0.701967, acc.: 46.09%] [G loss: 0.782145]\n",
      "epoch:13 step:13080 [D loss: 0.598290, acc.: 70.31%] [G loss: 0.789577]\n",
      "epoch:13 step:13081 [D loss: 0.618925, acc.: 63.28%] [G loss: 0.854074]\n",
      "epoch:13 step:13082 [D loss: 0.634413, acc.: 64.84%] [G loss: 0.873062]\n",
      "epoch:13 step:13083 [D loss: 0.702506, acc.: 54.69%] [G loss: 0.831511]\n",
      "epoch:13 step:13084 [D loss: 0.676956, acc.: 50.00%] [G loss: 0.834955]\n",
      "epoch:13 step:13085 [D loss: 0.757136, acc.: 36.72%] [G loss: 0.787396]\n",
      "epoch:13 step:13086 [D loss: 0.714463, acc.: 42.97%] [G loss: 0.777368]\n",
      "epoch:13 step:13087 [D loss: 0.712933, acc.: 53.12%] [G loss: 0.807575]\n",
      "epoch:13 step:13088 [D loss: 0.695373, acc.: 50.00%] [G loss: 0.745753]\n",
      "epoch:13 step:13089 [D loss: 0.725771, acc.: 48.44%] [G loss: 0.719483]\n",
      "epoch:13 step:13090 [D loss: 0.712439, acc.: 49.22%] [G loss: 0.699649]\n",
      "epoch:13 step:13091 [D loss: 0.697760, acc.: 51.56%] [G loss: 0.713226]\n",
      "epoch:13 step:13092 [D loss: 0.681411, acc.: 52.34%] [G loss: 0.722644]\n",
      "epoch:13 step:13093 [D loss: 0.482107, acc.: 63.28%] [G loss: 0.751113]\n",
      "epoch:13 step:13094 [D loss: 0.687258, acc.: 53.12%] [G loss: 0.769637]\n",
      "epoch:13 step:13095 [D loss: 0.656338, acc.: 61.72%] [G loss: 0.740633]\n",
      "epoch:13 step:13096 [D loss: 0.713608, acc.: 43.75%] [G loss: 0.738912]\n",
      "epoch:13 step:13097 [D loss: 0.698740, acc.: 51.56%] [G loss: 0.765248]\n",
      "epoch:13 step:13098 [D loss: 0.671667, acc.: 60.94%] [G loss: 0.783172]\n",
      "epoch:13 step:13099 [D loss: 0.628304, acc.: 63.28%] [G loss: 0.761468]\n",
      "epoch:13 step:13100 [D loss: 0.651893, acc.: 58.59%] [G loss: 0.733958]\n",
      "epoch:13 step:13101 [D loss: 0.683723, acc.: 53.12%] [G loss: 0.803166]\n",
      "epoch:13 step:13102 [D loss: 0.613055, acc.: 72.66%] [G loss: 0.848671]\n",
      "epoch:13 step:13103 [D loss: 0.629926, acc.: 69.53%] [G loss: 0.838782]\n",
      "epoch:13 step:13104 [D loss: 0.621351, acc.: 75.00%] [G loss: 0.864262]\n",
      "epoch:13 step:13105 [D loss: 0.543519, acc.: 78.12%] [G loss: 0.898907]\n",
      "epoch:13 step:13106 [D loss: 0.579609, acc.: 71.88%] [G loss: 0.805295]\n",
      "epoch:13 step:13107 [D loss: 0.451497, acc.: 78.12%] [G loss: 0.788551]\n",
      "epoch:13 step:13108 [D loss: 0.481472, acc.: 66.41%] [G loss: 0.929201]\n",
      "epoch:13 step:13109 [D loss: 0.769788, acc.: 51.56%] [G loss: 0.921249]\n",
      "epoch:13 step:13110 [D loss: 0.662014, acc.: 61.72%] [G loss: 0.855752]\n",
      "epoch:13 step:13111 [D loss: 0.632187, acc.: 61.72%] [G loss: 0.933801]\n",
      "epoch:13 step:13112 [D loss: 0.643014, acc.: 67.19%] [G loss: 0.844648]\n",
      "epoch:13 step:13113 [D loss: 0.736881, acc.: 46.09%] [G loss: 0.858286]\n",
      "epoch:13 step:13114 [D loss: 0.594365, acc.: 67.97%] [G loss: 0.794101]\n",
      "epoch:13 step:13115 [D loss: 0.650050, acc.: 64.06%] [G loss: 0.756463]\n",
      "epoch:13 step:13116 [D loss: 0.606652, acc.: 64.06%] [G loss: 0.731603]\n",
      "epoch:13 step:13117 [D loss: 0.439051, acc.: 71.09%] [G loss: 0.848023]\n",
      "epoch:13 step:13118 [D loss: 0.304226, acc.: 86.72%] [G loss: 0.906102]\n",
      "epoch:14 step:13119 [D loss: 0.756910, acc.: 49.22%] [G loss: 0.729609]\n",
      "epoch:14 step:13120 [D loss: 0.794649, acc.: 34.38%] [G loss: 0.917190]\n",
      "epoch:14 step:13121 [D loss: 0.752407, acc.: 42.97%] [G loss: 0.788905]\n",
      "epoch:14 step:13122 [D loss: 0.915863, acc.: 28.12%] [G loss: 1.477005]\n",
      "epoch:14 step:13123 [D loss: 0.708122, acc.: 48.44%] [G loss: 1.104671]\n",
      "epoch:14 step:13124 [D loss: 0.675556, acc.: 50.00%] [G loss: 1.122018]\n",
      "epoch:14 step:13125 [D loss: 0.683881, acc.: 54.69%] [G loss: 0.860408]\n",
      "epoch:14 step:13126 [D loss: 0.749593, acc.: 42.19%] [G loss: 0.837369]\n",
      "epoch:14 step:13127 [D loss: 0.702036, acc.: 50.78%] [G loss: 0.888802]\n",
      "epoch:14 step:13128 [D loss: 0.701714, acc.: 44.53%] [G loss: 0.861513]\n",
      "epoch:14 step:13129 [D loss: 0.727555, acc.: 42.97%] [G loss: 0.819319]\n",
      "epoch:14 step:13130 [D loss: 0.693309, acc.: 51.56%] [G loss: 0.824249]\n",
      "epoch:14 step:13131 [D loss: 0.674488, acc.: 57.81%] [G loss: 0.804629]\n",
      "epoch:14 step:13132 [D loss: 0.680685, acc.: 57.03%] [G loss: 0.777751]\n",
      "epoch:14 step:13133 [D loss: 0.642795, acc.: 76.56%] [G loss: 0.827364]\n",
      "epoch:14 step:13134 [D loss: 0.655057, acc.: 71.09%] [G loss: 0.788570]\n",
      "epoch:14 step:13135 [D loss: 0.659820, acc.: 57.81%] [G loss: 0.832390]\n",
      "epoch:14 step:13136 [D loss: 0.629667, acc.: 76.56%] [G loss: 0.766312]\n",
      "epoch:14 step:13137 [D loss: 0.659081, acc.: 71.09%] [G loss: 0.788144]\n",
      "epoch:14 step:13138 [D loss: 0.677544, acc.: 60.16%] [G loss: 0.735058]\n",
      "epoch:14 step:13139 [D loss: 0.683366, acc.: 52.34%] [G loss: 0.888074]\n",
      "epoch:14 step:13140 [D loss: 0.655476, acc.: 62.50%] [G loss: 0.820972]\n",
      "epoch:14 step:13141 [D loss: 0.663116, acc.: 60.94%] [G loss: 0.846129]\n",
      "epoch:14 step:13142 [D loss: 0.591301, acc.: 78.91%] [G loss: 0.833505]\n",
      "epoch:14 step:13143 [D loss: 0.637975, acc.: 68.75%] [G loss: 0.715561]\n",
      "epoch:14 step:13144 [D loss: 0.654219, acc.: 64.84%] [G loss: 0.727228]\n",
      "epoch:14 step:13145 [D loss: 0.806774, acc.: 34.38%] [G loss: 0.753699]\n",
      "epoch:14 step:13146 [D loss: 0.716454, acc.: 50.78%] [G loss: 0.669698]\n",
      "epoch:14 step:13147 [D loss: 0.658751, acc.: 62.50%] [G loss: 0.677123]\n",
      "epoch:14 step:13148 [D loss: 0.663846, acc.: 57.81%] [G loss: 0.683075]\n",
      "epoch:14 step:13149 [D loss: 0.741434, acc.: 46.09%] [G loss: 0.631959]\n",
      "epoch:14 step:13150 [D loss: 0.711720, acc.: 46.09%] [G loss: 0.676489]\n",
      "epoch:14 step:13151 [D loss: 0.680993, acc.: 53.91%] [G loss: 1.258264]\n",
      "epoch:14 step:13152 [D loss: 0.697021, acc.: 51.56%] [G loss: 0.786997]\n",
      "epoch:14 step:13153 [D loss: 0.668831, acc.: 57.81%] [G loss: 0.832344]\n",
      "epoch:14 step:13154 [D loss: 0.660046, acc.: 66.41%] [G loss: 0.769645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13155 [D loss: 0.675770, acc.: 57.81%] [G loss: 0.962036]\n",
      "epoch:14 step:13156 [D loss: 0.672408, acc.: 56.25%] [G loss: 0.787277]\n",
      "epoch:14 step:13157 [D loss: 0.675611, acc.: 53.91%] [G loss: 0.761813]\n",
      "epoch:14 step:13158 [D loss: 0.650020, acc.: 58.59%] [G loss: 0.770339]\n",
      "epoch:14 step:13159 [D loss: 0.708555, acc.: 49.22%] [G loss: 0.702567]\n",
      "epoch:14 step:13160 [D loss: 0.678304, acc.: 52.34%] [G loss: 0.759170]\n",
      "epoch:14 step:13161 [D loss: 0.682911, acc.: 53.12%] [G loss: 0.730101]\n",
      "epoch:14 step:13162 [D loss: 0.699617, acc.: 54.69%] [G loss: 0.793148]\n",
      "epoch:14 step:13163 [D loss: 0.708522, acc.: 47.66%] [G loss: 0.809542]\n",
      "epoch:14 step:13164 [D loss: 0.707978, acc.: 51.56%] [G loss: 0.743750]\n",
      "epoch:14 step:13165 [D loss: 0.700720, acc.: 54.69%] [G loss: 0.704476]\n",
      "epoch:14 step:13166 [D loss: 0.703505, acc.: 52.34%] [G loss: 0.688003]\n",
      "epoch:14 step:13167 [D loss: 0.685058, acc.: 55.47%] [G loss: 0.722776]\n",
      "epoch:14 step:13168 [D loss: 0.629636, acc.: 65.62%] [G loss: 0.722163]\n",
      "epoch:14 step:13169 [D loss: 0.727752, acc.: 43.75%] [G loss: 0.750302]\n",
      "epoch:14 step:13170 [D loss: 0.695122, acc.: 53.12%] [G loss: 0.757802]\n",
      "epoch:14 step:13171 [D loss: 0.666811, acc.: 58.59%] [G loss: 0.721789]\n",
      "epoch:14 step:13172 [D loss: 0.686311, acc.: 51.56%] [G loss: 0.724515]\n",
      "epoch:14 step:13173 [D loss: 0.688625, acc.: 52.34%] [G loss: 0.771697]\n",
      "epoch:14 step:13174 [D loss: 0.677684, acc.: 54.69%] [G loss: 0.746897]\n",
      "epoch:14 step:13175 [D loss: 0.679272, acc.: 60.94%] [G loss: 0.742975]\n",
      "epoch:14 step:13176 [D loss: 0.702749, acc.: 50.00%] [G loss: 0.765332]\n",
      "epoch:14 step:13177 [D loss: 0.685864, acc.: 49.22%] [G loss: 0.742740]\n",
      "epoch:14 step:13178 [D loss: 0.673520, acc.: 59.38%] [G loss: 0.775764]\n",
      "epoch:14 step:13179 [D loss: 0.707142, acc.: 47.66%] [G loss: 0.743051]\n",
      "epoch:14 step:13180 [D loss: 0.678594, acc.: 56.25%] [G loss: 0.777094]\n",
      "epoch:14 step:13181 [D loss: 0.702670, acc.: 57.81%] [G loss: 0.777567]\n",
      "epoch:14 step:13182 [D loss: 0.682517, acc.: 56.25%] [G loss: 0.768990]\n",
      "epoch:14 step:13183 [D loss: 0.678915, acc.: 56.25%] [G loss: 0.767598]\n",
      "epoch:14 step:13184 [D loss: 0.681034, acc.: 52.34%] [G loss: 0.803168]\n",
      "epoch:14 step:13185 [D loss: 0.695016, acc.: 49.22%] [G loss: 0.767140]\n",
      "epoch:14 step:13186 [D loss: 0.694283, acc.: 52.34%] [G loss: 0.776310]\n",
      "epoch:14 step:13187 [D loss: 0.649410, acc.: 67.19%] [G loss: 0.750978]\n",
      "epoch:14 step:13188 [D loss: 0.682529, acc.: 58.59%] [G loss: 0.771517]\n",
      "epoch:14 step:13189 [D loss: 0.686630, acc.: 53.91%] [G loss: 0.755877]\n",
      "epoch:14 step:13190 [D loss: 0.653735, acc.: 60.94%] [G loss: 0.801506]\n",
      "epoch:14 step:13191 [D loss: 0.651397, acc.: 64.84%] [G loss: 0.786694]\n",
      "epoch:14 step:13192 [D loss: 0.650613, acc.: 57.03%] [G loss: 0.799530]\n",
      "epoch:14 step:13193 [D loss: 0.658288, acc.: 63.28%] [G loss: 0.802330]\n",
      "epoch:14 step:13194 [D loss: 0.634133, acc.: 60.94%] [G loss: 0.762839]\n",
      "epoch:14 step:13195 [D loss: 0.634982, acc.: 67.19%] [G loss: 0.799918]\n",
      "epoch:14 step:13196 [D loss: 0.710349, acc.: 50.78%] [G loss: 0.831906]\n",
      "epoch:14 step:13197 [D loss: 0.703535, acc.: 45.31%] [G loss: 0.779489]\n",
      "epoch:14 step:13198 [D loss: 0.709320, acc.: 52.34%] [G loss: 0.806237]\n",
      "epoch:14 step:13199 [D loss: 0.732054, acc.: 43.75%] [G loss: 0.741387]\n",
      "epoch:14 step:13200 [D loss: 0.678226, acc.: 51.56%] [G loss: 0.753395]\n",
      "epoch:14 step:13201 [D loss: 0.710468, acc.: 50.00%] [G loss: 0.765570]\n",
      "epoch:14 step:13202 [D loss: 0.721445, acc.: 42.97%] [G loss: 0.776565]\n",
      "epoch:14 step:13203 [D loss: 0.608885, acc.: 64.06%] [G loss: 0.733014]\n",
      "epoch:14 step:13204 [D loss: 0.693158, acc.: 54.69%] [G loss: 0.754292]\n",
      "epoch:14 step:13205 [D loss: 0.669773, acc.: 63.28%] [G loss: 0.743809]\n",
      "epoch:14 step:13206 [D loss: 0.663329, acc.: 64.06%] [G loss: 0.747458]\n",
      "epoch:14 step:13207 [D loss: 0.652229, acc.: 62.50%] [G loss: 0.757097]\n",
      "epoch:14 step:13208 [D loss: 0.664663, acc.: 58.59%] [G loss: 0.757478]\n",
      "epoch:14 step:13209 [D loss: 0.679241, acc.: 49.22%] [G loss: 0.765257]\n",
      "epoch:14 step:13210 [D loss: 0.674247, acc.: 56.25%] [G loss: 0.769087]\n",
      "epoch:14 step:13211 [D loss: 0.597110, acc.: 71.09%] [G loss: 0.757166]\n",
      "epoch:14 step:13212 [D loss: 0.666094, acc.: 56.25%] [G loss: 0.764123]\n",
      "epoch:14 step:13213 [D loss: 0.693147, acc.: 52.34%] [G loss: 0.776761]\n",
      "epoch:14 step:13214 [D loss: 0.663390, acc.: 63.28%] [G loss: 0.769779]\n",
      "epoch:14 step:13215 [D loss: 0.666967, acc.: 64.06%] [G loss: 0.801073]\n",
      "epoch:14 step:13216 [D loss: 0.668456, acc.: 58.59%] [G loss: 0.779371]\n",
      "epoch:14 step:13217 [D loss: 0.857884, acc.: 45.31%] [G loss: 0.802581]\n",
      "epoch:14 step:13218 [D loss: 0.656082, acc.: 57.03%] [G loss: 0.811220]\n",
      "epoch:14 step:13219 [D loss: 0.652181, acc.: 61.72%] [G loss: 0.867183]\n",
      "epoch:14 step:13220 [D loss: 0.698381, acc.: 56.25%] [G loss: 0.883158]\n",
      "epoch:14 step:13221 [D loss: 0.668305, acc.: 56.25%] [G loss: 0.829637]\n",
      "epoch:14 step:13222 [D loss: 0.695609, acc.: 44.53%] [G loss: 0.803971]\n",
      "epoch:14 step:13223 [D loss: 0.662873, acc.: 60.94%] [G loss: 0.835091]\n",
      "epoch:14 step:13224 [D loss: 0.650257, acc.: 60.94%] [G loss: 0.865843]\n",
      "epoch:14 step:13225 [D loss: 0.632779, acc.: 67.19%] [G loss: 0.802239]\n",
      "epoch:14 step:13226 [D loss: 0.715425, acc.: 53.91%] [G loss: 0.835922]\n",
      "epoch:14 step:13227 [D loss: 0.695500, acc.: 51.56%] [G loss: 0.796472]\n",
      "epoch:14 step:13228 [D loss: 0.704367, acc.: 51.56%] [G loss: 0.787052]\n",
      "epoch:14 step:13229 [D loss: 0.698048, acc.: 58.59%] [G loss: 0.843204]\n",
      "epoch:14 step:13230 [D loss: 0.680074, acc.: 53.91%] [G loss: 0.792860]\n",
      "epoch:14 step:13231 [D loss: 0.677948, acc.: 57.81%] [G loss: 0.754193]\n",
      "epoch:14 step:13232 [D loss: 0.699437, acc.: 51.56%] [G loss: 0.780305]\n",
      "epoch:14 step:13233 [D loss: 0.694641, acc.: 53.12%] [G loss: 0.775055]\n",
      "epoch:14 step:13234 [D loss: 0.678664, acc.: 58.59%] [G loss: 0.807130]\n",
      "epoch:14 step:13235 [D loss: 0.654433, acc.: 65.62%] [G loss: 0.761158]\n",
      "epoch:14 step:13236 [D loss: 0.654509, acc.: 57.03%] [G loss: 0.776820]\n",
      "epoch:14 step:13237 [D loss: 0.645522, acc.: 67.19%] [G loss: 0.826007]\n",
      "epoch:14 step:13238 [D loss: 0.710156, acc.: 53.12%] [G loss: 0.849509]\n",
      "epoch:14 step:13239 [D loss: 0.690898, acc.: 51.56%] [G loss: 0.804368]\n",
      "epoch:14 step:13240 [D loss: 0.715488, acc.: 48.44%] [G loss: 0.908610]\n",
      "epoch:14 step:13241 [D loss: 0.705896, acc.: 55.47%] [G loss: 0.805684]\n",
      "epoch:14 step:13242 [D loss: 0.663851, acc.: 57.03%] [G loss: 0.864339]\n",
      "epoch:14 step:13243 [D loss: 0.676963, acc.: 56.25%] [G loss: 0.899510]\n",
      "epoch:14 step:13244 [D loss: 0.668164, acc.: 57.81%] [G loss: 0.866802]\n",
      "epoch:14 step:13245 [D loss: 0.662386, acc.: 60.94%] [G loss: 0.819882]\n",
      "epoch:14 step:13246 [D loss: 0.728744, acc.: 47.66%] [G loss: 0.816113]\n",
      "epoch:14 step:13247 [D loss: 0.685452, acc.: 56.25%] [G loss: 0.818580]\n",
      "epoch:14 step:13248 [D loss: 0.656823, acc.: 59.38%] [G loss: 0.826553]\n",
      "epoch:14 step:13249 [D loss: 0.650672, acc.: 61.72%] [G loss: 0.812807]\n",
      "epoch:14 step:13250 [D loss: 0.670660, acc.: 53.91%] [G loss: 0.754698]\n",
      "epoch:14 step:13251 [D loss: 0.673820, acc.: 57.03%] [G loss: 0.814561]\n",
      "epoch:14 step:13252 [D loss: 0.660221, acc.: 64.84%] [G loss: 0.755850]\n",
      "epoch:14 step:13253 [D loss: 0.682921, acc.: 62.50%] [G loss: 0.783125]\n",
      "epoch:14 step:13254 [D loss: 0.672739, acc.: 53.91%] [G loss: 0.749262]\n",
      "epoch:14 step:13255 [D loss: 0.695527, acc.: 50.78%] [G loss: 0.750398]\n",
      "epoch:14 step:13256 [D loss: 0.692113, acc.: 53.91%] [G loss: 0.727647]\n",
      "epoch:14 step:13257 [D loss: 0.665435, acc.: 57.81%] [G loss: 0.729715]\n",
      "epoch:14 step:13258 [D loss: 0.694745, acc.: 52.34%] [G loss: 0.784482]\n",
      "epoch:14 step:13259 [D loss: 0.662757, acc.: 60.16%] [G loss: 0.795769]\n",
      "epoch:14 step:13260 [D loss: 0.692809, acc.: 55.47%] [G loss: 0.769817]\n",
      "epoch:14 step:13261 [D loss: 0.653732, acc.: 67.19%] [G loss: 0.824830]\n",
      "epoch:14 step:13262 [D loss: 0.646560, acc.: 65.62%] [G loss: 0.767972]\n",
      "epoch:14 step:13263 [D loss: 0.616420, acc.: 65.62%] [G loss: 0.824271]\n",
      "epoch:14 step:13264 [D loss: 0.648803, acc.: 56.25%] [G loss: 0.878709]\n",
      "epoch:14 step:13265 [D loss: 0.676417, acc.: 56.25%] [G loss: 0.850221]\n",
      "epoch:14 step:13266 [D loss: 0.677045, acc.: 57.03%] [G loss: 0.777915]\n",
      "epoch:14 step:13267 [D loss: 0.667470, acc.: 58.59%] [G loss: 0.772213]\n",
      "epoch:14 step:13268 [D loss: 0.634807, acc.: 61.72%] [G loss: 0.800131]\n",
      "epoch:14 step:13269 [D loss: 0.629059, acc.: 68.75%] [G loss: 0.733081]\n",
      "epoch:14 step:13270 [D loss: 0.683704, acc.: 54.69%] [G loss: 0.763652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13271 [D loss: 0.759595, acc.: 36.72%] [G loss: 0.787528]\n",
      "epoch:14 step:13272 [D loss: 0.731648, acc.: 49.22%] [G loss: 0.702945]\n",
      "epoch:14 step:13273 [D loss: 0.779283, acc.: 35.16%] [G loss: 0.688542]\n",
      "epoch:14 step:13274 [D loss: 0.719399, acc.: 45.31%] [G loss: 0.702091]\n",
      "epoch:14 step:13275 [D loss: 0.705290, acc.: 46.09%] [G loss: 0.716922]\n",
      "epoch:14 step:13276 [D loss: 0.727101, acc.: 36.72%] [G loss: 0.745221]\n",
      "epoch:14 step:13277 [D loss: 0.705850, acc.: 43.75%] [G loss: 0.729201]\n",
      "epoch:14 step:13278 [D loss: 0.690090, acc.: 53.12%] [G loss: 0.836492]\n",
      "epoch:14 step:13279 [D loss: 0.685338, acc.: 54.69%] [G loss: 0.847126]\n",
      "epoch:14 step:13280 [D loss: 0.652516, acc.: 62.50%] [G loss: 0.825379]\n",
      "epoch:14 step:13281 [D loss: 0.642221, acc.: 70.31%] [G loss: 0.851886]\n",
      "epoch:14 step:13282 [D loss: 0.636119, acc.: 65.62%] [G loss: 0.839841]\n",
      "epoch:14 step:13283 [D loss: 0.676187, acc.: 60.94%] [G loss: 0.823017]\n",
      "epoch:14 step:13284 [D loss: 0.689760, acc.: 50.78%] [G loss: 0.801179]\n",
      "epoch:14 step:13285 [D loss: 0.712687, acc.: 47.66%] [G loss: 0.777078]\n",
      "epoch:14 step:13286 [D loss: 0.702540, acc.: 56.25%] [G loss: 0.781232]\n",
      "epoch:14 step:13287 [D loss: 0.692412, acc.: 52.34%] [G loss: 0.748633]\n",
      "epoch:14 step:13288 [D loss: 0.669215, acc.: 60.16%] [G loss: 0.705716]\n",
      "epoch:14 step:13289 [D loss: 0.689167, acc.: 55.47%] [G loss: 0.743601]\n",
      "epoch:14 step:13290 [D loss: 0.659151, acc.: 57.03%] [G loss: 0.703839]\n",
      "epoch:14 step:13291 [D loss: 0.669524, acc.: 54.69%] [G loss: 0.733191]\n",
      "epoch:14 step:13292 [D loss: 0.716217, acc.: 49.22%] [G loss: 0.648059]\n",
      "epoch:14 step:13293 [D loss: 0.709831, acc.: 46.88%] [G loss: 0.731662]\n",
      "epoch:14 step:13294 [D loss: 0.662849, acc.: 59.38%] [G loss: 0.677251]\n",
      "epoch:14 step:13295 [D loss: 0.720873, acc.: 38.28%] [G loss: 0.681686]\n",
      "epoch:14 step:13296 [D loss: 0.706168, acc.: 54.69%] [G loss: 0.727798]\n",
      "epoch:14 step:13297 [D loss: 0.692428, acc.: 50.00%] [G loss: 0.755851]\n",
      "epoch:14 step:13298 [D loss: 0.680009, acc.: 59.38%] [G loss: 0.756798]\n",
      "epoch:14 step:13299 [D loss: 0.639853, acc.: 64.84%] [G loss: 0.745593]\n",
      "epoch:14 step:13300 [D loss: 0.676849, acc.: 57.03%] [G loss: 0.758441]\n",
      "epoch:14 step:13301 [D loss: 0.669137, acc.: 58.59%] [G loss: 0.735406]\n",
      "epoch:14 step:13302 [D loss: 0.645411, acc.: 62.50%] [G loss: 0.812725]\n",
      "epoch:14 step:13303 [D loss: 0.653153, acc.: 60.94%] [G loss: 0.787481]\n",
      "epoch:14 step:13304 [D loss: 0.679519, acc.: 56.25%] [G loss: 0.772733]\n",
      "epoch:14 step:13305 [D loss: 0.606047, acc.: 64.06%] [G loss: 0.758233]\n",
      "epoch:14 step:13306 [D loss: 0.686778, acc.: 54.69%] [G loss: 0.671363]\n",
      "epoch:14 step:13307 [D loss: 0.702683, acc.: 50.00%] [G loss: 0.735283]\n",
      "epoch:14 step:13308 [D loss: 0.692060, acc.: 54.69%] [G loss: 0.711580]\n",
      "epoch:14 step:13309 [D loss: 0.654863, acc.: 60.94%] [G loss: 0.749453]\n",
      "epoch:14 step:13310 [D loss: 0.699127, acc.: 53.12%] [G loss: 0.743577]\n",
      "epoch:14 step:13311 [D loss: 0.695925, acc.: 53.12%] [G loss: 0.808123]\n",
      "epoch:14 step:13312 [D loss: 0.679482, acc.: 57.81%] [G loss: 0.773870]\n",
      "epoch:14 step:13313 [D loss: 0.685762, acc.: 57.81%] [G loss: 0.789419]\n",
      "epoch:14 step:13314 [D loss: 0.670864, acc.: 60.94%] [G loss: 0.748028]\n",
      "epoch:14 step:13315 [D loss: 0.695328, acc.: 52.34%] [G loss: 0.803787]\n",
      "epoch:14 step:13316 [D loss: 0.647409, acc.: 60.94%] [G loss: 0.833944]\n",
      "epoch:14 step:13317 [D loss: 0.695256, acc.: 53.91%] [G loss: 0.787592]\n",
      "epoch:14 step:13318 [D loss: 0.662061, acc.: 60.94%] [G loss: 0.895853]\n",
      "epoch:14 step:13319 [D loss: 0.668554, acc.: 60.94%] [G loss: 0.844304]\n",
      "epoch:14 step:13320 [D loss: 0.688777, acc.: 53.91%] [G loss: 0.875028]\n",
      "epoch:14 step:13321 [D loss: 0.717336, acc.: 50.78%] [G loss: 0.907036]\n",
      "epoch:14 step:13322 [D loss: 0.621863, acc.: 64.06%] [G loss: 0.856482]\n",
      "epoch:14 step:13323 [D loss: 0.657280, acc.: 60.16%] [G loss: 0.854896]\n",
      "epoch:14 step:13324 [D loss: 0.660063, acc.: 58.59%] [G loss: 0.864352]\n",
      "epoch:14 step:13325 [D loss: 0.766175, acc.: 55.47%] [G loss: 0.914107]\n",
      "epoch:14 step:13326 [D loss: 0.696292, acc.: 55.47%] [G loss: 0.880119]\n",
      "epoch:14 step:13327 [D loss: 0.663643, acc.: 54.69%] [G loss: 0.937706]\n",
      "epoch:14 step:13328 [D loss: 0.718949, acc.: 48.44%] [G loss: 0.883426]\n",
      "epoch:14 step:13329 [D loss: 0.689813, acc.: 51.56%] [G loss: 0.905353]\n",
      "epoch:14 step:13330 [D loss: 0.657840, acc.: 58.59%] [G loss: 0.838658]\n",
      "epoch:14 step:13331 [D loss: 0.676329, acc.: 50.00%] [G loss: 0.910482]\n",
      "epoch:14 step:13332 [D loss: 0.693261, acc.: 54.69%] [G loss: 0.825782]\n",
      "epoch:14 step:13333 [D loss: 0.693360, acc.: 50.78%] [G loss: 0.876237]\n",
      "epoch:14 step:13334 [D loss: 0.660826, acc.: 62.50%] [G loss: 0.810132]\n",
      "epoch:14 step:13335 [D loss: 0.710183, acc.: 49.22%] [G loss: 0.837006]\n",
      "epoch:14 step:13336 [D loss: 0.684573, acc.: 57.03%] [G loss: 0.815213]\n",
      "epoch:14 step:13337 [D loss: 0.661521, acc.: 60.16%] [G loss: 0.799046]\n",
      "epoch:14 step:13338 [D loss: 0.666298, acc.: 59.38%] [G loss: 0.726071]\n",
      "epoch:14 step:13339 [D loss: 0.630327, acc.: 62.50%] [G loss: 0.758955]\n",
      "epoch:14 step:13340 [D loss: 0.652638, acc.: 65.62%] [G loss: 0.759326]\n",
      "epoch:14 step:13341 [D loss: 0.641081, acc.: 64.06%] [G loss: 0.815817]\n",
      "epoch:14 step:13342 [D loss: 0.677496, acc.: 58.59%] [G loss: 0.777229]\n",
      "epoch:14 step:13343 [D loss: 0.742099, acc.: 43.75%] [G loss: 0.833897]\n",
      "epoch:14 step:13344 [D loss: 0.707428, acc.: 50.00%] [G loss: 0.787096]\n",
      "epoch:14 step:13345 [D loss: 0.722246, acc.: 48.44%] [G loss: 0.739419]\n",
      "epoch:14 step:13346 [D loss: 0.695977, acc.: 48.44%] [G loss: 0.747097]\n",
      "epoch:14 step:13347 [D loss: 0.668576, acc.: 61.72%] [G loss: 0.783259]\n",
      "epoch:14 step:13348 [D loss: 0.638060, acc.: 64.06%] [G loss: 0.743658]\n",
      "epoch:14 step:13349 [D loss: 0.617746, acc.: 67.97%] [G loss: 0.763593]\n",
      "epoch:14 step:13350 [D loss: 0.616619, acc.: 64.06%] [G loss: 0.799367]\n",
      "epoch:14 step:13351 [D loss: 0.704718, acc.: 54.69%] [G loss: 0.800383]\n",
      "epoch:14 step:13352 [D loss: 0.659743, acc.: 58.59%] [G loss: 0.782918]\n",
      "epoch:14 step:13353 [D loss: 0.637940, acc.: 65.62%] [G loss: 0.781180]\n",
      "epoch:14 step:13354 [D loss: 0.664366, acc.: 57.03%] [G loss: 0.843490]\n",
      "epoch:14 step:13355 [D loss: 0.614344, acc.: 70.31%] [G loss: 0.914070]\n",
      "epoch:14 step:13356 [D loss: 0.670846, acc.: 57.81%] [G loss: 0.856868]\n",
      "epoch:14 step:13357 [D loss: 0.707171, acc.: 46.09%] [G loss: 0.865987]\n",
      "epoch:14 step:13358 [D loss: 0.675212, acc.: 57.81%] [G loss: 0.864995]\n",
      "epoch:14 step:13359 [D loss: 0.723753, acc.: 46.09%] [G loss: 0.769396]\n",
      "epoch:14 step:13360 [D loss: 0.690745, acc.: 50.78%] [G loss: 0.775581]\n",
      "epoch:14 step:13361 [D loss: 0.663577, acc.: 60.94%] [G loss: 0.765820]\n",
      "epoch:14 step:13362 [D loss: 0.674947, acc.: 51.56%] [G loss: 0.806824]\n",
      "epoch:14 step:13363 [D loss: 0.710991, acc.: 49.22%] [G loss: 0.764343]\n",
      "epoch:14 step:13364 [D loss: 0.703781, acc.: 53.91%] [G loss: 0.799525]\n",
      "epoch:14 step:13365 [D loss: 0.688727, acc.: 50.00%] [G loss: 0.797073]\n",
      "epoch:14 step:13366 [D loss: 0.675633, acc.: 55.47%] [G loss: 0.754973]\n",
      "epoch:14 step:13367 [D loss: 0.659453, acc.: 62.50%] [G loss: 0.841305]\n",
      "epoch:14 step:13368 [D loss: 0.634601, acc.: 62.50%] [G loss: 0.828162]\n",
      "epoch:14 step:13369 [D loss: 0.645463, acc.: 61.72%] [G loss: 0.807184]\n",
      "epoch:14 step:13370 [D loss: 0.677128, acc.: 63.28%] [G loss: 0.833924]\n",
      "epoch:14 step:13371 [D loss: 0.695871, acc.: 57.81%] [G loss: 0.790532]\n",
      "epoch:14 step:13372 [D loss: 0.696266, acc.: 53.91%] [G loss: 0.791331]\n",
      "epoch:14 step:13373 [D loss: 0.701996, acc.: 52.34%] [G loss: 0.756493]\n",
      "epoch:14 step:13374 [D loss: 0.691547, acc.: 52.34%] [G loss: 0.778576]\n",
      "epoch:14 step:13375 [D loss: 0.665530, acc.: 64.06%] [G loss: 0.769502]\n",
      "epoch:14 step:13376 [D loss: 0.663233, acc.: 62.50%] [G loss: 0.763869]\n",
      "epoch:14 step:13377 [D loss: 0.664754, acc.: 62.50%] [G loss: 0.764021]\n",
      "epoch:14 step:13378 [D loss: 0.687081, acc.: 53.91%] [G loss: 0.681854]\n",
      "epoch:14 step:13379 [D loss: 0.698576, acc.: 55.47%] [G loss: 0.809362]\n",
      "epoch:14 step:13380 [D loss: 0.677371, acc.: 58.59%] [G loss: 0.806849]\n",
      "epoch:14 step:13381 [D loss: 0.404709, acc.: 75.78%] [G loss: 0.844415]\n",
      "epoch:14 step:13382 [D loss: 0.688220, acc.: 53.91%] [G loss: 0.753238]\n",
      "epoch:14 step:13383 [D loss: 0.696351, acc.: 54.69%] [G loss: 0.791710]\n",
      "epoch:14 step:13384 [D loss: 0.670935, acc.: 57.03%] [G loss: 0.812702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13385 [D loss: 0.675828, acc.: 57.81%] [G loss: 0.851698]\n",
      "epoch:14 step:13386 [D loss: 0.700305, acc.: 50.00%] [G loss: 0.807509]\n",
      "epoch:14 step:13387 [D loss: 0.747136, acc.: 40.62%] [G loss: 0.791605]\n",
      "epoch:14 step:13388 [D loss: 0.692333, acc.: 53.12%] [G loss: 0.811432]\n",
      "epoch:14 step:13389 [D loss: 0.667368, acc.: 61.72%] [G loss: 0.769855]\n",
      "epoch:14 step:13390 [D loss: 0.676859, acc.: 59.38%] [G loss: 0.780439]\n",
      "epoch:14 step:13391 [D loss: 0.687168, acc.: 60.94%] [G loss: 0.822223]\n",
      "epoch:14 step:13392 [D loss: 0.650336, acc.: 63.28%] [G loss: 0.734366]\n",
      "epoch:14 step:13393 [D loss: 0.682104, acc.: 57.03%] [G loss: 0.750084]\n",
      "epoch:14 step:13394 [D loss: 0.640864, acc.: 65.62%] [G loss: 0.759154]\n",
      "epoch:14 step:13395 [D loss: 0.679080, acc.: 54.69%] [G loss: 0.805118]\n",
      "epoch:14 step:13396 [D loss: 0.724523, acc.: 40.62%] [G loss: 0.835075]\n",
      "epoch:14 step:13397 [D loss: 0.693244, acc.: 50.78%] [G loss: 0.756346]\n",
      "epoch:14 step:13398 [D loss: 0.712121, acc.: 50.00%] [G loss: 0.862159]\n",
      "epoch:14 step:13399 [D loss: 0.708402, acc.: 53.12%] [G loss: 0.769660]\n",
      "epoch:14 step:13400 [D loss: 0.702090, acc.: 57.03%] [G loss: 0.790035]\n",
      "epoch:14 step:13401 [D loss: 0.693170, acc.: 50.78%] [G loss: 0.829613]\n",
      "epoch:14 step:13402 [D loss: 0.664057, acc.: 63.28%] [G loss: 0.808858]\n",
      "epoch:14 step:13403 [D loss: 0.630579, acc.: 65.62%] [G loss: 0.783178]\n",
      "epoch:14 step:13404 [D loss: 0.669699, acc.: 56.25%] [G loss: 0.802128]\n",
      "epoch:14 step:13405 [D loss: 0.658948, acc.: 57.81%] [G loss: 0.791673]\n",
      "epoch:14 step:13406 [D loss: 0.660708, acc.: 60.94%] [G loss: 0.784639]\n",
      "epoch:14 step:13407 [D loss: 0.658367, acc.: 59.38%] [G loss: 0.783941]\n",
      "epoch:14 step:13408 [D loss: 0.657346, acc.: 60.16%] [G loss: 0.792381]\n",
      "epoch:14 step:13409 [D loss: 0.703615, acc.: 52.34%] [G loss: 0.777491]\n",
      "epoch:14 step:13410 [D loss: 0.710758, acc.: 52.34%] [G loss: 0.758407]\n",
      "epoch:14 step:13411 [D loss: 0.703107, acc.: 50.78%] [G loss: 0.778392]\n",
      "epoch:14 step:13412 [D loss: 0.664023, acc.: 63.28%] [G loss: 0.767725]\n",
      "epoch:14 step:13413 [D loss: 0.734800, acc.: 45.31%] [G loss: 0.742427]\n",
      "epoch:14 step:13414 [D loss: 0.696891, acc.: 52.34%] [G loss: 0.791486]\n",
      "epoch:14 step:13415 [D loss: 0.699326, acc.: 50.78%] [G loss: 0.801211]\n",
      "epoch:14 step:13416 [D loss: 0.734314, acc.: 42.19%] [G loss: 0.767162]\n",
      "epoch:14 step:13417 [D loss: 0.705893, acc.: 56.25%] [G loss: 0.795573]\n",
      "epoch:14 step:13418 [D loss: 0.679822, acc.: 58.59%] [G loss: 0.759770]\n",
      "epoch:14 step:13419 [D loss: 0.681286, acc.: 59.38%] [G loss: 0.780554]\n",
      "epoch:14 step:13420 [D loss: 0.685087, acc.: 53.91%] [G loss: 0.782500]\n",
      "epoch:14 step:13421 [D loss: 0.677680, acc.: 57.03%] [G loss: 0.809231]\n",
      "epoch:14 step:13422 [D loss: 0.695538, acc.: 54.69%] [G loss: 0.766963]\n",
      "epoch:14 step:13423 [D loss: 0.678071, acc.: 61.72%] [G loss: 0.785928]\n",
      "epoch:14 step:13424 [D loss: 0.681299, acc.: 55.47%] [G loss: 0.793239]\n",
      "epoch:14 step:13425 [D loss: 0.692782, acc.: 50.00%] [G loss: 0.789043]\n",
      "epoch:14 step:13426 [D loss: 0.704480, acc.: 52.34%] [G loss: 0.763965]\n",
      "epoch:14 step:13427 [D loss: 0.656847, acc.: 64.84%] [G loss: 0.755209]\n",
      "epoch:14 step:13428 [D loss: 0.638484, acc.: 67.97%] [G loss: 0.772149]\n",
      "epoch:14 step:13429 [D loss: 0.631493, acc.: 67.19%] [G loss: 0.784333]\n",
      "epoch:14 step:13430 [D loss: 0.664275, acc.: 55.47%] [G loss: 0.760379]\n",
      "epoch:14 step:13431 [D loss: 0.650250, acc.: 63.28%] [G loss: 0.824857]\n",
      "epoch:14 step:13432 [D loss: 0.642377, acc.: 61.72%] [G loss: 0.810227]\n",
      "epoch:14 step:13433 [D loss: 0.670220, acc.: 58.59%] [G loss: 0.846603]\n",
      "epoch:14 step:13434 [D loss: 0.745879, acc.: 46.09%] [G loss: 0.840902]\n",
      "epoch:14 step:13435 [D loss: 0.725963, acc.: 45.31%] [G loss: 0.771343]\n",
      "epoch:14 step:13436 [D loss: 0.692769, acc.: 53.12%] [G loss: 0.754473]\n",
      "epoch:14 step:13437 [D loss: 0.710538, acc.: 49.22%] [G loss: 0.755403]\n",
      "epoch:14 step:13438 [D loss: 0.694578, acc.: 45.31%] [G loss: 0.739762]\n",
      "epoch:14 step:13439 [D loss: 0.806170, acc.: 40.62%] [G loss: 0.784714]\n",
      "epoch:14 step:13440 [D loss: 0.665462, acc.: 60.94%] [G loss: 0.802278]\n",
      "epoch:14 step:13441 [D loss: 0.685959, acc.: 51.56%] [G loss: 0.806218]\n",
      "epoch:14 step:13442 [D loss: 0.702905, acc.: 56.25%] [G loss: 0.832673]\n",
      "epoch:14 step:13443 [D loss: 0.671922, acc.: 54.69%] [G loss: 0.764816]\n",
      "epoch:14 step:13444 [D loss: 0.684104, acc.: 52.34%] [G loss: 0.767283]\n",
      "epoch:14 step:13445 [D loss: 0.642877, acc.: 65.62%] [G loss: 0.820534]\n",
      "epoch:14 step:13446 [D loss: 0.669261, acc.: 57.03%] [G loss: 0.785367]\n",
      "epoch:14 step:13447 [D loss: 0.705206, acc.: 51.56%] [G loss: 0.756643]\n",
      "epoch:14 step:13448 [D loss: 0.707646, acc.: 47.66%] [G loss: 0.759750]\n",
      "epoch:14 step:13449 [D loss: 0.698631, acc.: 46.88%] [G loss: 0.723105]\n",
      "epoch:14 step:13450 [D loss: 0.686556, acc.: 54.69%] [G loss: 0.758764]\n",
      "epoch:14 step:13451 [D loss: 0.680371, acc.: 56.25%] [G loss: 0.728164]\n",
      "epoch:14 step:13452 [D loss: 0.701230, acc.: 52.34%] [G loss: 0.707054]\n",
      "epoch:14 step:13453 [D loss: 0.696522, acc.: 49.22%] [G loss: 0.727468]\n",
      "epoch:14 step:13454 [D loss: 0.700495, acc.: 47.66%] [G loss: 0.729621]\n",
      "epoch:14 step:13455 [D loss: 0.706187, acc.: 49.22%] [G loss: 0.744388]\n",
      "epoch:14 step:13456 [D loss: 0.659172, acc.: 62.50%] [G loss: 0.723151]\n",
      "epoch:14 step:13457 [D loss: 0.679077, acc.: 53.91%] [G loss: 0.750211]\n",
      "epoch:14 step:13458 [D loss: 0.688891, acc.: 57.03%] [G loss: 0.723505]\n",
      "epoch:14 step:13459 [D loss: 0.692160, acc.: 44.53%] [G loss: 0.729235]\n",
      "epoch:14 step:13460 [D loss: 0.685701, acc.: 54.69%] [G loss: 0.697952]\n",
      "epoch:14 step:13461 [D loss: 0.643903, acc.: 64.06%] [G loss: 0.750556]\n",
      "epoch:14 step:13462 [D loss: 0.665540, acc.: 55.47%] [G loss: 0.744933]\n",
      "epoch:14 step:13463 [D loss: 0.668267, acc.: 57.03%] [G loss: 0.753237]\n",
      "epoch:14 step:13464 [D loss: 0.636909, acc.: 66.41%] [G loss: 0.760681]\n",
      "epoch:14 step:13465 [D loss: 0.654792, acc.: 64.06%] [G loss: 0.771014]\n",
      "epoch:14 step:13466 [D loss: 0.718668, acc.: 49.22%] [G loss: 0.762437]\n",
      "epoch:14 step:13467 [D loss: 0.700399, acc.: 47.66%] [G loss: 0.756464]\n",
      "epoch:14 step:13468 [D loss: 0.660976, acc.: 63.28%] [G loss: 0.730561]\n",
      "epoch:14 step:13469 [D loss: 0.712489, acc.: 45.31%] [G loss: 0.704370]\n",
      "epoch:14 step:13470 [D loss: 0.697812, acc.: 48.44%] [G loss: 0.776610]\n",
      "epoch:14 step:13471 [D loss: 0.691047, acc.: 47.66%] [G loss: 0.743037]\n",
      "epoch:14 step:13472 [D loss: 0.686001, acc.: 57.81%] [G loss: 0.742795]\n",
      "epoch:14 step:13473 [D loss: 0.708418, acc.: 50.78%] [G loss: 0.767010]\n",
      "epoch:14 step:13474 [D loss: 0.670959, acc.: 58.59%] [G loss: 0.729480]\n",
      "epoch:14 step:13475 [D loss: 0.687624, acc.: 53.91%] [G loss: 0.756975]\n",
      "epoch:14 step:13476 [D loss: 0.669367, acc.: 56.25%] [G loss: 0.766508]\n",
      "epoch:14 step:13477 [D loss: 0.650764, acc.: 62.50%] [G loss: 0.769572]\n",
      "epoch:14 step:13478 [D loss: 0.678033, acc.: 53.91%] [G loss: 0.801136]\n",
      "epoch:14 step:13479 [D loss: 0.655994, acc.: 56.25%] [G loss: 0.745157]\n",
      "epoch:14 step:13480 [D loss: 0.691435, acc.: 54.69%] [G loss: 0.789704]\n",
      "epoch:14 step:13481 [D loss: 0.696442, acc.: 44.53%] [G loss: 0.729681]\n",
      "epoch:14 step:13482 [D loss: 0.665751, acc.: 57.81%] [G loss: 0.741161]\n",
      "epoch:14 step:13483 [D loss: 0.665697, acc.: 60.16%] [G loss: 0.762608]\n",
      "epoch:14 step:13484 [D loss: 0.694429, acc.: 50.78%] [G loss: 0.788649]\n",
      "epoch:14 step:13485 [D loss: 0.704462, acc.: 48.44%] [G loss: 0.735359]\n",
      "epoch:14 step:13486 [D loss: 0.704825, acc.: 46.09%] [G loss: 0.772064]\n",
      "epoch:14 step:13487 [D loss: 0.688145, acc.: 53.12%] [G loss: 0.741612]\n",
      "epoch:14 step:13488 [D loss: 0.676599, acc.: 53.12%] [G loss: 0.729653]\n",
      "epoch:14 step:13489 [D loss: 0.598634, acc.: 67.97%] [G loss: 0.751957]\n",
      "epoch:14 step:13490 [D loss: 0.652467, acc.: 60.94%] [G loss: 0.881784]\n",
      "epoch:14 step:13491 [D loss: 0.694210, acc.: 53.12%] [G loss: 0.778999]\n",
      "epoch:14 step:13492 [D loss: 0.663204, acc.: 62.50%] [G loss: 0.752446]\n",
      "epoch:14 step:13493 [D loss: 0.693529, acc.: 49.22%] [G loss: 0.755308]\n",
      "epoch:14 step:13494 [D loss: 0.670037, acc.: 58.59%] [G loss: 0.781670]\n",
      "epoch:14 step:13495 [D loss: 0.713649, acc.: 48.44%] [G loss: 0.749280]\n",
      "epoch:14 step:13496 [D loss: 0.691073, acc.: 53.12%] [G loss: 0.766031]\n",
      "epoch:14 step:13497 [D loss: 0.664806, acc.: 61.72%] [G loss: 0.803737]\n",
      "epoch:14 step:13498 [D loss: 0.671844, acc.: 56.25%] [G loss: 0.787680]\n",
      "epoch:14 step:13499 [D loss: 0.701456, acc.: 51.56%] [G loss: 0.813619]\n",
      "epoch:14 step:13500 [D loss: 0.730547, acc.: 46.88%] [G loss: 0.761775]\n",
      "epoch:14 step:13501 [D loss: 0.718381, acc.: 47.66%] [G loss: 0.764737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13502 [D loss: 0.697802, acc.: 54.69%] [G loss: 0.792190]\n",
      "epoch:14 step:13503 [D loss: 0.667635, acc.: 57.81%] [G loss: 0.798956]\n",
      "epoch:14 step:13504 [D loss: 0.650005, acc.: 61.72%] [G loss: 0.789542]\n",
      "epoch:14 step:13505 [D loss: 0.636141, acc.: 64.84%] [G loss: 0.772559]\n",
      "epoch:14 step:13506 [D loss: 0.647147, acc.: 64.06%] [G loss: 0.780972]\n",
      "epoch:14 step:13507 [D loss: 0.699740, acc.: 49.22%] [G loss: 0.809449]\n",
      "epoch:14 step:13508 [D loss: 0.694987, acc.: 50.00%] [G loss: 0.780652]\n",
      "epoch:14 step:13509 [D loss: 0.666496, acc.: 64.06%] [G loss: 0.790300]\n",
      "epoch:14 step:13510 [D loss: 0.698082, acc.: 53.12%] [G loss: 0.761569]\n",
      "epoch:14 step:13511 [D loss: 0.716048, acc.: 52.34%] [G loss: 0.810387]\n",
      "epoch:14 step:13512 [D loss: 0.707633, acc.: 53.91%] [G loss: 0.730019]\n",
      "epoch:14 step:13513 [D loss: 0.707664, acc.: 46.88%] [G loss: 0.768583]\n",
      "epoch:14 step:13514 [D loss: 0.660441, acc.: 67.19%] [G loss: 0.757748]\n",
      "epoch:14 step:13515 [D loss: 0.649842, acc.: 63.28%] [G loss: 0.809767]\n",
      "epoch:14 step:13516 [D loss: 0.625296, acc.: 71.88%] [G loss: 0.764120]\n",
      "epoch:14 step:13517 [D loss: 0.634274, acc.: 67.19%] [G loss: 0.788855]\n",
      "epoch:14 step:13518 [D loss: 0.713231, acc.: 47.66%] [G loss: 0.774365]\n",
      "epoch:14 step:13519 [D loss: 0.683848, acc.: 55.47%] [G loss: 0.756191]\n",
      "epoch:14 step:13520 [D loss: 0.641906, acc.: 67.19%] [G loss: 0.760845]\n",
      "epoch:14 step:13521 [D loss: 0.677323, acc.: 55.47%] [G loss: 0.745129]\n",
      "epoch:14 step:13522 [D loss: 0.629487, acc.: 61.72%] [G loss: 0.754378]\n",
      "epoch:14 step:13523 [D loss: 0.628110, acc.: 59.38%] [G loss: 0.769932]\n",
      "epoch:14 step:13524 [D loss: 0.601034, acc.: 68.75%] [G loss: 0.816108]\n",
      "epoch:14 step:13525 [D loss: 0.609584, acc.: 72.66%] [G loss: 0.816311]\n",
      "epoch:14 step:13526 [D loss: 0.633744, acc.: 67.97%] [G loss: 0.802050]\n",
      "epoch:14 step:13527 [D loss: 0.611996, acc.: 66.41%] [G loss: 0.818157]\n",
      "epoch:14 step:13528 [D loss: 0.687893, acc.: 56.25%] [G loss: 0.825159]\n",
      "epoch:14 step:13529 [D loss: 0.762682, acc.: 42.97%] [G loss: 0.769949]\n",
      "epoch:14 step:13530 [D loss: 0.670709, acc.: 57.03%] [G loss: 0.809029]\n",
      "epoch:14 step:13531 [D loss: 0.719678, acc.: 50.78%] [G loss: 0.759264]\n",
      "epoch:14 step:13532 [D loss: 0.652278, acc.: 58.59%] [G loss: 0.767840]\n",
      "epoch:14 step:13533 [D loss: 0.649790, acc.: 62.50%] [G loss: 0.722624]\n",
      "epoch:14 step:13534 [D loss: 0.688876, acc.: 53.12%] [G loss: 0.742887]\n",
      "epoch:14 step:13535 [D loss: 0.682043, acc.: 60.16%] [G loss: 0.790612]\n",
      "epoch:14 step:13536 [D loss: 0.673082, acc.: 58.59%] [G loss: 0.737565]\n",
      "epoch:14 step:13537 [D loss: 0.641112, acc.: 62.50%] [G loss: 0.779356]\n",
      "epoch:14 step:13538 [D loss: 0.691885, acc.: 57.81%] [G loss: 0.782687]\n",
      "epoch:14 step:13539 [D loss: 0.731715, acc.: 47.66%] [G loss: 0.743570]\n",
      "epoch:14 step:13540 [D loss: 0.772315, acc.: 35.16%] [G loss: 0.740135]\n",
      "epoch:14 step:13541 [D loss: 0.660302, acc.: 60.16%] [G loss: 0.846655]\n",
      "epoch:14 step:13542 [D loss: 0.672629, acc.: 56.25%] [G loss: 0.783095]\n",
      "epoch:14 step:13543 [D loss: 0.674923, acc.: 56.25%] [G loss: 0.833204]\n",
      "epoch:14 step:13544 [D loss: 0.636388, acc.: 62.50%] [G loss: 0.807632]\n",
      "epoch:14 step:13545 [D loss: 0.667939, acc.: 64.84%] [G loss: 0.826956]\n",
      "epoch:14 step:13546 [D loss: 0.607211, acc.: 70.31%] [G loss: 0.845705]\n",
      "epoch:14 step:13547 [D loss: 0.631815, acc.: 64.84%] [G loss: 0.793088]\n",
      "epoch:14 step:13548 [D loss: 0.649168, acc.: 64.06%] [G loss: 0.790470]\n",
      "epoch:14 step:13549 [D loss: 0.699645, acc.: 48.44%] [G loss: 0.877022]\n",
      "epoch:14 step:13550 [D loss: 0.734678, acc.: 39.84%] [G loss: 0.806269]\n",
      "epoch:14 step:13551 [D loss: 0.678784, acc.: 53.91%] [G loss: 0.800115]\n",
      "epoch:14 step:13552 [D loss: 0.663586, acc.: 61.72%] [G loss: 0.817440]\n",
      "epoch:14 step:13553 [D loss: 0.693954, acc.: 53.91%] [G loss: 0.885032]\n",
      "epoch:14 step:13554 [D loss: 0.648792, acc.: 60.16%] [G loss: 0.819266]\n",
      "epoch:14 step:13555 [D loss: 0.781360, acc.: 46.88%] [G loss: 0.792825]\n",
      "epoch:14 step:13556 [D loss: 0.730464, acc.: 46.09%] [G loss: 0.751389]\n",
      "epoch:14 step:13557 [D loss: 0.724581, acc.: 40.62%] [G loss: 0.775813]\n",
      "epoch:14 step:13558 [D loss: 0.716076, acc.: 45.31%] [G loss: 0.743222]\n",
      "epoch:14 step:13559 [D loss: 0.719901, acc.: 46.09%] [G loss: 0.768359]\n",
      "epoch:14 step:13560 [D loss: 0.697147, acc.: 50.00%] [G loss: 0.770589]\n",
      "epoch:14 step:13561 [D loss: 0.675351, acc.: 60.94%] [G loss: 0.773182]\n",
      "epoch:14 step:13562 [D loss: 0.672264, acc.: 56.25%] [G loss: 0.855466]\n",
      "epoch:14 step:13563 [D loss: 0.652193, acc.: 57.81%] [G loss: 0.878311]\n",
      "epoch:14 step:13564 [D loss: 0.672172, acc.: 55.47%] [G loss: 0.756528]\n",
      "epoch:14 step:13565 [D loss: 0.658099, acc.: 61.72%] [G loss: 0.842120]\n",
      "epoch:14 step:13566 [D loss: 0.670543, acc.: 56.25%] [G loss: 0.779022]\n",
      "epoch:14 step:13567 [D loss: 0.640120, acc.: 64.06%] [G loss: 0.808627]\n",
      "epoch:14 step:13568 [D loss: 0.607294, acc.: 68.75%] [G loss: 0.751445]\n",
      "epoch:14 step:13569 [D loss: 0.609362, acc.: 68.75%] [G loss: 0.800395]\n",
      "epoch:14 step:13570 [D loss: 0.626099, acc.: 70.31%] [G loss: 0.828180]\n",
      "epoch:14 step:13571 [D loss: 0.596772, acc.: 72.66%] [G loss: 0.853549]\n",
      "epoch:14 step:13572 [D loss: 0.649466, acc.: 60.94%] [G loss: 0.851099]\n",
      "epoch:14 step:13573 [D loss: 0.712054, acc.: 49.22%] [G loss: 0.789521]\n",
      "epoch:14 step:13574 [D loss: 0.532218, acc.: 62.50%] [G loss: 0.828683]\n",
      "epoch:14 step:13575 [D loss: 0.613691, acc.: 70.31%] [G loss: 0.861382]\n",
      "epoch:14 step:13576 [D loss: 0.688696, acc.: 54.69%] [G loss: 0.847166]\n",
      "epoch:14 step:13577 [D loss: 0.649233, acc.: 63.28%] [G loss: 0.839158]\n",
      "epoch:14 step:13578 [D loss: 0.688544, acc.: 54.69%] [G loss: 0.830157]\n",
      "epoch:14 step:13579 [D loss: 0.712862, acc.: 48.44%] [G loss: 0.901038]\n",
      "epoch:14 step:13580 [D loss: 0.751135, acc.: 37.50%] [G loss: 0.795295]\n",
      "epoch:14 step:13581 [D loss: 0.693571, acc.: 57.81%] [G loss: 0.873363]\n",
      "epoch:14 step:13582 [D loss: 0.726117, acc.: 53.91%] [G loss: 0.705971]\n",
      "epoch:14 step:13583 [D loss: 0.728710, acc.: 52.34%] [G loss: 0.856007]\n",
      "epoch:14 step:13584 [D loss: 0.687436, acc.: 52.34%] [G loss: 0.732351]\n",
      "epoch:14 step:13585 [D loss: 0.715282, acc.: 55.47%] [G loss: 0.713553]\n",
      "epoch:14 step:13586 [D loss: 0.664812, acc.: 59.38%] [G loss: 0.773324]\n",
      "epoch:14 step:13587 [D loss: 0.671929, acc.: 59.38%] [G loss: 0.867612]\n",
      "epoch:14 step:13588 [D loss: 0.622744, acc.: 60.94%] [G loss: 0.784157]\n",
      "epoch:14 step:13589 [D loss: 0.668586, acc.: 54.69%] [G loss: 0.810405]\n",
      "epoch:14 step:13590 [D loss: 0.701345, acc.: 49.22%] [G loss: 0.894711]\n",
      "epoch:14 step:13591 [D loss: 0.669803, acc.: 60.94%] [G loss: 0.896321]\n",
      "epoch:14 step:13592 [D loss: 0.648853, acc.: 60.16%] [G loss: 0.848331]\n",
      "epoch:14 step:13593 [D loss: 0.638813, acc.: 65.62%] [G loss: 0.880902]\n",
      "epoch:14 step:13594 [D loss: 0.672981, acc.: 64.84%] [G loss: 0.889502]\n",
      "epoch:14 step:13595 [D loss: 0.715052, acc.: 51.56%] [G loss: 0.905427]\n",
      "epoch:14 step:13596 [D loss: 0.685810, acc.: 53.91%] [G loss: 0.898388]\n",
      "epoch:14 step:13597 [D loss: 0.677590, acc.: 53.91%] [G loss: 0.811568]\n",
      "epoch:14 step:13598 [D loss: 0.672157, acc.: 57.03%] [G loss: 0.810520]\n",
      "epoch:14 step:13599 [D loss: 0.699823, acc.: 50.78%] [G loss: 0.702928]\n",
      "epoch:14 step:13600 [D loss: 0.679363, acc.: 57.81%] [G loss: 0.776253]\n",
      "epoch:14 step:13601 [D loss: 0.661612, acc.: 58.59%] [G loss: 0.748425]\n",
      "epoch:14 step:13602 [D loss: 0.616605, acc.: 70.31%] [G loss: 0.879344]\n",
      "epoch:14 step:13603 [D loss: 0.616420, acc.: 75.78%] [G loss: 0.864909]\n",
      "epoch:14 step:13604 [D loss: 0.649809, acc.: 60.94%] [G loss: 0.931502]\n",
      "epoch:14 step:13605 [D loss: 0.613917, acc.: 67.19%] [G loss: 0.833181]\n",
      "epoch:14 step:13606 [D loss: 0.644748, acc.: 58.59%] [G loss: 0.914808]\n",
      "epoch:14 step:13607 [D loss: 0.700178, acc.: 50.00%] [G loss: 0.865245]\n",
      "epoch:14 step:13608 [D loss: 0.709908, acc.: 46.09%] [G loss: 0.878820]\n",
      "epoch:14 step:13609 [D loss: 0.728517, acc.: 51.56%] [G loss: 0.856812]\n",
      "epoch:14 step:13610 [D loss: 0.697984, acc.: 50.78%] [G loss: 0.835286]\n",
      "epoch:14 step:13611 [D loss: 0.722601, acc.: 46.09%] [G loss: 0.777262]\n",
      "epoch:14 step:13612 [D loss: 0.680131, acc.: 57.03%] [G loss: 0.808779]\n",
      "epoch:14 step:13613 [D loss: 0.654281, acc.: 57.03%] [G loss: 0.732532]\n",
      "epoch:14 step:13614 [D loss: 0.695701, acc.: 50.00%] [G loss: 0.829828]\n",
      "epoch:14 step:13615 [D loss: 0.653009, acc.: 68.75%] [G loss: 0.807096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13616 [D loss: 0.685342, acc.: 53.12%] [G loss: 0.795053]\n",
      "epoch:14 step:13617 [D loss: 0.628751, acc.: 67.19%] [G loss: 0.836428]\n",
      "epoch:14 step:13618 [D loss: 0.670939, acc.: 57.81%] [G loss: 0.821668]\n",
      "epoch:14 step:13619 [D loss: 0.676147, acc.: 58.59%] [G loss: 0.825089]\n",
      "epoch:14 step:13620 [D loss: 0.686827, acc.: 52.34%] [G loss: 0.823296]\n",
      "epoch:14 step:13621 [D loss: 0.655193, acc.: 60.16%] [G loss: 0.788857]\n",
      "epoch:14 step:13622 [D loss: 0.643891, acc.: 61.72%] [G loss: 0.809848]\n",
      "epoch:14 step:13623 [D loss: 0.608325, acc.: 71.88%] [G loss: 0.827496]\n",
      "epoch:14 step:13624 [D loss: 0.702110, acc.: 55.47%] [G loss: 0.793168]\n",
      "epoch:14 step:13625 [D loss: 0.664829, acc.: 59.38%] [G loss: 0.838813]\n",
      "epoch:14 step:13626 [D loss: 0.633274, acc.: 65.62%] [G loss: 0.821290]\n",
      "epoch:14 step:13627 [D loss: 0.778139, acc.: 40.62%] [G loss: 0.764038]\n",
      "epoch:14 step:13628 [D loss: 0.735449, acc.: 46.88%] [G loss: 0.780763]\n",
      "epoch:14 step:13629 [D loss: 0.737852, acc.: 45.31%] [G loss: 0.751398]\n",
      "epoch:14 step:13630 [D loss: 0.677821, acc.: 57.03%] [G loss: 0.731959]\n",
      "epoch:14 step:13631 [D loss: 0.670094, acc.: 58.59%] [G loss: 0.749894]\n",
      "epoch:14 step:13632 [D loss: 0.649851, acc.: 64.06%] [G loss: 0.794415]\n",
      "epoch:14 step:13633 [D loss: 0.647717, acc.: 61.72%] [G loss: 0.824275]\n",
      "epoch:14 step:13634 [D loss: 0.642993, acc.: 66.41%] [G loss: 0.795061]\n",
      "epoch:14 step:13635 [D loss: 0.654366, acc.: 58.59%] [G loss: 0.773046]\n",
      "epoch:14 step:13636 [D loss: 0.675990, acc.: 54.69%] [G loss: 0.816237]\n",
      "epoch:14 step:13637 [D loss: 0.696145, acc.: 46.88%] [G loss: 0.760386]\n",
      "epoch:14 step:13638 [D loss: 0.647103, acc.: 62.50%] [G loss: 0.768898]\n",
      "epoch:14 step:13639 [D loss: 0.695359, acc.: 53.91%] [G loss: 0.809190]\n",
      "epoch:14 step:13640 [D loss: 0.684450, acc.: 49.22%] [G loss: 0.818161]\n",
      "epoch:14 step:13641 [D loss: 0.681413, acc.: 53.91%] [G loss: 0.759167]\n",
      "epoch:14 step:13642 [D loss: 0.676944, acc.: 60.16%] [G loss: 0.792268]\n",
      "epoch:14 step:13643 [D loss: 0.705886, acc.: 46.88%] [G loss: 0.777450]\n",
      "epoch:14 step:13644 [D loss: 0.656108, acc.: 64.84%] [G loss: 0.802744]\n",
      "epoch:14 step:13645 [D loss: 0.681285, acc.: 54.69%] [G loss: 0.778180]\n",
      "epoch:14 step:13646 [D loss: 0.711830, acc.: 45.31%] [G loss: 0.761124]\n",
      "epoch:14 step:13647 [D loss: 0.693097, acc.: 57.81%] [G loss: 0.737689]\n",
      "epoch:14 step:13648 [D loss: 0.655275, acc.: 63.28%] [G loss: 0.745696]\n",
      "epoch:14 step:13649 [D loss: 0.699362, acc.: 51.56%] [G loss: 0.771554]\n",
      "epoch:14 step:13650 [D loss: 0.679171, acc.: 54.69%] [G loss: 0.782712]\n",
      "epoch:14 step:13651 [D loss: 0.692887, acc.: 54.69%] [G loss: 0.780121]\n",
      "epoch:14 step:13652 [D loss: 0.662911, acc.: 57.81%] [G loss: 0.723719]\n",
      "epoch:14 step:13653 [D loss: 0.691644, acc.: 60.16%] [G loss: 0.760872]\n",
      "epoch:14 step:13654 [D loss: 0.684532, acc.: 57.03%] [G loss: 0.792038]\n",
      "epoch:14 step:13655 [D loss: 0.666659, acc.: 63.28%] [G loss: 0.781887]\n",
      "epoch:14 step:13656 [D loss: 0.632042, acc.: 69.53%] [G loss: 0.822916]\n",
      "epoch:14 step:13657 [D loss: 0.662549, acc.: 59.38%] [G loss: 0.825307]\n",
      "epoch:14 step:13658 [D loss: 0.627127, acc.: 65.62%] [G loss: 0.866897]\n",
      "epoch:14 step:13659 [D loss: 0.612994, acc.: 70.31%] [G loss: 0.835872]\n",
      "epoch:14 step:13660 [D loss: 0.756152, acc.: 43.75%] [G loss: 0.779537]\n",
      "epoch:14 step:13661 [D loss: 0.462972, acc.: 75.78%] [G loss: 0.842437]\n",
      "epoch:14 step:13662 [D loss: 0.710826, acc.: 55.47%] [G loss: 0.814710]\n",
      "epoch:14 step:13663 [D loss: 0.693715, acc.: 53.12%] [G loss: 0.823274]\n",
      "epoch:14 step:13664 [D loss: 0.640186, acc.: 67.19%] [G loss: 0.783943]\n",
      "epoch:14 step:13665 [D loss: 0.664500, acc.: 61.72%] [G loss: 0.821497]\n",
      "epoch:14 step:13666 [D loss: 0.621264, acc.: 62.50%] [G loss: 0.787246]\n",
      "epoch:14 step:13667 [D loss: 0.614127, acc.: 70.31%] [G loss: 0.827755]\n",
      "epoch:14 step:13668 [D loss: 0.464353, acc.: 73.44%] [G loss: 0.830347]\n",
      "epoch:14 step:13669 [D loss: 0.615808, acc.: 64.84%] [G loss: 0.784327]\n",
      "epoch:14 step:13670 [D loss: 0.644497, acc.: 64.84%] [G loss: 0.799660]\n",
      "epoch:14 step:13671 [D loss: 0.694059, acc.: 52.34%] [G loss: 0.821879]\n",
      "epoch:14 step:13672 [D loss: 0.601968, acc.: 62.50%] [G loss: 0.823093]\n",
      "epoch:14 step:13673 [D loss: 0.687963, acc.: 57.03%] [G loss: 0.834503]\n",
      "epoch:14 step:13674 [D loss: 0.645871, acc.: 60.16%] [G loss: 0.812523]\n",
      "epoch:14 step:13675 [D loss: 0.638776, acc.: 63.28%] [G loss: 0.920588]\n",
      "epoch:14 step:13676 [D loss: 0.624422, acc.: 67.97%] [G loss: 0.848326]\n",
      "epoch:14 step:13677 [D loss: 0.714364, acc.: 55.47%] [G loss: 0.827312]\n",
      "epoch:14 step:13678 [D loss: 0.715129, acc.: 53.91%] [G loss: 0.775588]\n",
      "epoch:14 step:13679 [D loss: 0.739345, acc.: 45.31%] [G loss: 0.793111]\n",
      "epoch:14 step:13680 [D loss: 0.697199, acc.: 56.25%] [G loss: 0.888468]\n",
      "epoch:14 step:13681 [D loss: 0.706603, acc.: 50.78%] [G loss: 0.817308]\n",
      "epoch:14 step:13682 [D loss: 0.668865, acc.: 60.94%] [G loss: 0.861152]\n",
      "epoch:14 step:13683 [D loss: 0.655067, acc.: 59.38%] [G loss: 0.833295]\n",
      "epoch:14 step:13684 [D loss: 0.629072, acc.: 65.62%] [G loss: 0.828849]\n",
      "epoch:14 step:13685 [D loss: 0.580977, acc.: 72.66%] [G loss: 0.913370]\n",
      "epoch:14 step:13686 [D loss: 0.617633, acc.: 69.53%] [G loss: 0.986136]\n",
      "epoch:14 step:13687 [D loss: 0.643465, acc.: 62.50%] [G loss: 1.029347]\n",
      "epoch:14 step:13688 [D loss: 0.658792, acc.: 63.28%] [G loss: 1.029451]\n",
      "epoch:14 step:13689 [D loss: 0.626821, acc.: 62.50%] [G loss: 1.013656]\n",
      "epoch:14 step:13690 [D loss: 0.616803, acc.: 67.97%] [G loss: 0.924598]\n",
      "epoch:14 step:13691 [D loss: 0.667552, acc.: 56.25%] [G loss: 0.948340]\n",
      "epoch:14 step:13692 [D loss: 0.632959, acc.: 70.31%] [G loss: 0.962083]\n",
      "epoch:14 step:13693 [D loss: 0.640485, acc.: 64.06%] [G loss: 1.084354]\n",
      "epoch:14 step:13694 [D loss: 0.695094, acc.: 50.00%] [G loss: 0.938196]\n",
      "epoch:14 step:13695 [D loss: 0.687766, acc.: 53.91%] [G loss: 0.876596]\n",
      "epoch:14 step:13696 [D loss: 0.680179, acc.: 57.03%] [G loss: 0.806006]\n",
      "epoch:14 step:13697 [D loss: 0.722417, acc.: 48.44%] [G loss: 0.894140]\n",
      "epoch:14 step:13698 [D loss: 0.714284, acc.: 48.44%] [G loss: 0.775836]\n",
      "epoch:14 step:13699 [D loss: 0.747227, acc.: 35.94%] [G loss: 0.775484]\n",
      "epoch:14 step:13700 [D loss: 0.723208, acc.: 42.97%] [G loss: 0.843611]\n",
      "epoch:14 step:13701 [D loss: 0.741924, acc.: 46.09%] [G loss: 0.869952]\n",
      "epoch:14 step:13702 [D loss: 0.694473, acc.: 51.56%] [G loss: 0.895031]\n",
      "epoch:14 step:13703 [D loss: 0.680190, acc.: 60.16%] [G loss: 0.867978]\n",
      "epoch:14 step:13704 [D loss: 0.628201, acc.: 64.06%] [G loss: 0.924840]\n",
      "epoch:14 step:13705 [D loss: 0.655804, acc.: 64.84%] [G loss: 0.826693]\n",
      "epoch:14 step:13706 [D loss: 0.622523, acc.: 67.97%] [G loss: 0.917647]\n",
      "epoch:14 step:13707 [D loss: 0.611642, acc.: 72.66%] [G loss: 0.884577]\n",
      "epoch:14 step:13708 [D loss: 0.676647, acc.: 59.38%] [G loss: 0.852868]\n",
      "epoch:14 step:13709 [D loss: 0.673965, acc.: 55.47%] [G loss: 0.835143]\n",
      "epoch:14 step:13710 [D loss: 0.641658, acc.: 64.84%] [G loss: 0.839859]\n",
      "epoch:14 step:13711 [D loss: 0.711108, acc.: 47.66%] [G loss: 0.800669]\n",
      "epoch:14 step:13712 [D loss: 0.733452, acc.: 44.53%] [G loss: 0.778755]\n",
      "epoch:14 step:13713 [D loss: 0.688490, acc.: 52.34%] [G loss: 0.740289]\n",
      "epoch:14 step:13714 [D loss: 0.708860, acc.: 51.56%] [G loss: 0.748094]\n",
      "epoch:14 step:13715 [D loss: 0.679255, acc.: 57.03%] [G loss: 0.735376]\n",
      "epoch:14 step:13716 [D loss: 0.642243, acc.: 66.41%] [G loss: 0.821819]\n",
      "epoch:14 step:13717 [D loss: 0.676322, acc.: 57.81%] [G loss: 0.752840]\n",
      "epoch:14 step:13718 [D loss: 0.714322, acc.: 49.22%] [G loss: 0.796157]\n",
      "epoch:14 step:13719 [D loss: 0.709099, acc.: 46.88%] [G loss: 0.807495]\n",
      "epoch:14 step:13720 [D loss: 0.722420, acc.: 54.69%] [G loss: 0.805348]\n",
      "epoch:14 step:13721 [D loss: 0.701576, acc.: 50.78%] [G loss: 0.802139]\n",
      "epoch:14 step:13722 [D loss: 0.475007, acc.: 68.75%] [G loss: 0.866920]\n",
      "epoch:14 step:13723 [D loss: 0.675372, acc.: 65.62%] [G loss: 0.847500]\n",
      "epoch:14 step:13724 [D loss: 0.652553, acc.: 64.84%] [G loss: 0.796958]\n",
      "epoch:14 step:13725 [D loss: 0.685427, acc.: 57.81%] [G loss: 0.823877]\n",
      "epoch:14 step:13726 [D loss: 0.666148, acc.: 57.03%] [G loss: 0.840155]\n",
      "epoch:14 step:13727 [D loss: 0.674243, acc.: 60.94%] [G loss: 0.807789]\n",
      "epoch:14 step:13728 [D loss: 0.715891, acc.: 47.66%] [G loss: 0.756238]\n",
      "epoch:14 step:13729 [D loss: 0.691815, acc.: 50.78%] [G loss: 0.775683]\n",
      "epoch:14 step:13730 [D loss: 0.662589, acc.: 57.81%] [G loss: 0.758363]\n",
      "epoch:14 step:13731 [D loss: 0.647596, acc.: 66.41%] [G loss: 0.763215]\n",
      "epoch:14 step:13732 [D loss: 0.697642, acc.: 51.56%] [G loss: 0.313180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13733 [D loss: 0.683271, acc.: 57.03%] [G loss: 0.802527]\n",
      "epoch:14 step:13734 [D loss: 0.693239, acc.: 50.00%] [G loss: 0.814891]\n",
      "epoch:14 step:13735 [D loss: 0.666213, acc.: 64.06%] [G loss: 0.779558]\n",
      "epoch:14 step:13736 [D loss: 0.671732, acc.: 57.81%] [G loss: 0.758147]\n",
      "epoch:14 step:13737 [D loss: 0.665087, acc.: 66.41%] [G loss: 0.795802]\n",
      "epoch:14 step:13738 [D loss: 0.672613, acc.: 61.72%] [G loss: 0.786185]\n",
      "epoch:14 step:13739 [D loss: 0.647593, acc.: 62.50%] [G loss: 0.772104]\n",
      "epoch:14 step:13740 [D loss: 0.724156, acc.: 53.91%] [G loss: 0.722372]\n",
      "epoch:14 step:13741 [D loss: 0.650105, acc.: 59.38%] [G loss: 0.841827]\n",
      "epoch:14 step:13742 [D loss: 0.666505, acc.: 62.50%] [G loss: 0.809865]\n",
      "epoch:14 step:13743 [D loss: 0.654840, acc.: 60.94%] [G loss: 0.831773]\n",
      "epoch:14 step:13744 [D loss: 0.670186, acc.: 57.03%] [G loss: 0.809266]\n",
      "epoch:14 step:13745 [D loss: 0.738686, acc.: 50.00%] [G loss: 0.768702]\n",
      "epoch:14 step:13746 [D loss: 0.663625, acc.: 57.03%] [G loss: 0.755782]\n",
      "epoch:14 step:13747 [D loss: 0.686316, acc.: 56.25%] [G loss: 0.782628]\n",
      "epoch:14 step:13748 [D loss: 0.666546, acc.: 57.81%] [G loss: 0.757933]\n",
      "epoch:14 step:13749 [D loss: 0.688945, acc.: 56.25%] [G loss: 0.756635]\n",
      "epoch:14 step:13750 [D loss: 0.689654, acc.: 57.81%] [G loss: 0.730932]\n",
      "epoch:14 step:13751 [D loss: 0.675245, acc.: 60.16%] [G loss: 0.762304]\n",
      "epoch:14 step:13752 [D loss: 0.714970, acc.: 53.12%] [G loss: 0.673226]\n",
      "epoch:14 step:13753 [D loss: 0.696099, acc.: 53.12%] [G loss: 0.742334]\n",
      "epoch:14 step:13754 [D loss: 0.681890, acc.: 59.38%] [G loss: 0.794388]\n",
      "epoch:14 step:13755 [D loss: 0.677984, acc.: 56.25%] [G loss: 0.800129]\n",
      "epoch:14 step:13756 [D loss: 0.650738, acc.: 67.19%] [G loss: 0.771730]\n",
      "epoch:14 step:13757 [D loss: 0.673440, acc.: 59.38%] [G loss: 0.767338]\n",
      "epoch:14 step:13758 [D loss: 0.673362, acc.: 52.34%] [G loss: 0.825992]\n",
      "epoch:14 step:13759 [D loss: 0.644159, acc.: 65.62%] [G loss: 0.853308]\n",
      "epoch:14 step:13760 [D loss: 0.641417, acc.: 64.06%] [G loss: 0.883245]\n",
      "epoch:14 step:13761 [D loss: 0.690118, acc.: 54.69%] [G loss: 0.844093]\n",
      "epoch:14 step:13762 [D loss: 0.643033, acc.: 64.06%] [G loss: 0.860554]\n",
      "epoch:14 step:13763 [D loss: 0.669339, acc.: 56.25%] [G loss: 0.860270]\n",
      "epoch:14 step:13764 [D loss: 0.616258, acc.: 66.41%] [G loss: 0.827629]\n",
      "epoch:14 step:13765 [D loss: 0.704140, acc.: 54.69%] [G loss: 0.816450]\n",
      "epoch:14 step:13766 [D loss: 0.623675, acc.: 65.62%] [G loss: 0.856227]\n",
      "epoch:14 step:13767 [D loss: 0.676484, acc.: 55.47%] [G loss: 0.835892]\n",
      "epoch:14 step:13768 [D loss: 0.645069, acc.: 64.06%] [G loss: 0.827938]\n",
      "epoch:14 step:13769 [D loss: 0.641165, acc.: 60.94%] [G loss: 0.807511]\n",
      "epoch:14 step:13770 [D loss: 0.727103, acc.: 50.00%] [G loss: 0.898078]\n",
      "epoch:14 step:13771 [D loss: 0.698536, acc.: 52.34%] [G loss: 0.786536]\n",
      "epoch:14 step:13772 [D loss: 0.734762, acc.: 47.66%] [G loss: 0.788661]\n",
      "epoch:14 step:13773 [D loss: 0.693831, acc.: 57.81%] [G loss: 0.767785]\n",
      "epoch:14 step:13774 [D loss: 0.661357, acc.: 60.16%] [G loss: 0.820442]\n",
      "epoch:14 step:13775 [D loss: 0.675788, acc.: 57.03%] [G loss: 0.822384]\n",
      "epoch:14 step:13776 [D loss: 0.669232, acc.: 57.81%] [G loss: 0.816134]\n",
      "epoch:14 step:13777 [D loss: 0.678951, acc.: 53.12%] [G loss: 0.806522]\n",
      "epoch:14 step:13778 [D loss: 0.646763, acc.: 65.62%] [G loss: 0.747635]\n",
      "epoch:14 step:13779 [D loss: 0.636090, acc.: 65.62%] [G loss: 0.903980]\n",
      "epoch:14 step:13780 [D loss: 0.707157, acc.: 53.12%] [G loss: 0.746581]\n",
      "epoch:14 step:13781 [D loss: 0.687393, acc.: 60.16%] [G loss: 0.781356]\n",
      "epoch:14 step:13782 [D loss: 0.652554, acc.: 66.41%] [G loss: 0.921775]\n",
      "epoch:14 step:13783 [D loss: 0.671646, acc.: 59.38%] [G loss: 0.822076]\n",
      "epoch:14 step:13784 [D loss: 0.666833, acc.: 63.28%] [G loss: 0.810035]\n",
      "epoch:14 step:13785 [D loss: 0.666783, acc.: 63.28%] [G loss: 0.846156]\n",
      "epoch:14 step:13786 [D loss: 0.695157, acc.: 55.47%] [G loss: 0.836343]\n",
      "epoch:14 step:13787 [D loss: 0.702183, acc.: 55.47%] [G loss: 0.856869]\n",
      "epoch:14 step:13788 [D loss: 0.681910, acc.: 54.69%] [G loss: 0.727835]\n",
      "epoch:14 step:13789 [D loss: 0.664495, acc.: 55.47%] [G loss: 0.847609]\n",
      "epoch:14 step:13790 [D loss: 0.677679, acc.: 49.22%] [G loss: 0.827427]\n",
      "epoch:14 step:13791 [D loss: 0.639059, acc.: 57.81%] [G loss: 0.852569]\n",
      "epoch:14 step:13792 [D loss: 0.601210, acc.: 72.66%] [G loss: 0.825858]\n",
      "epoch:14 step:13793 [D loss: 0.701756, acc.: 51.56%] [G loss: 0.868889]\n",
      "epoch:14 step:13794 [D loss: 0.679147, acc.: 56.25%] [G loss: 0.785139]\n",
      "epoch:14 step:13795 [D loss: 0.651949, acc.: 60.16%] [G loss: 0.783250]\n",
      "epoch:14 step:13796 [D loss: 0.704501, acc.: 50.78%] [G loss: 0.770684]\n",
      "epoch:14 step:13797 [D loss: 0.762580, acc.: 45.31%] [G loss: 0.855443]\n",
      "epoch:14 step:13798 [D loss: 0.701491, acc.: 53.91%] [G loss: 0.776841]\n",
      "epoch:14 step:13799 [D loss: 0.785297, acc.: 39.06%] [G loss: 0.743097]\n",
      "epoch:14 step:13800 [D loss: 0.691725, acc.: 51.56%] [G loss: 0.721559]\n",
      "epoch:14 step:13801 [D loss: 0.686683, acc.: 62.50%] [G loss: 0.779427]\n",
      "epoch:14 step:13802 [D loss: 0.670824, acc.: 58.59%] [G loss: 0.848365]\n",
      "epoch:14 step:13803 [D loss: 0.704329, acc.: 45.31%] [G loss: 0.777842]\n",
      "epoch:14 step:13804 [D loss: 0.622919, acc.: 69.53%] [G loss: 0.789078]\n",
      "epoch:14 step:13805 [D loss: 0.659500, acc.: 60.94%] [G loss: 0.934571]\n",
      "epoch:14 step:13806 [D loss: 0.685530, acc.: 53.12%] [G loss: 0.793013]\n",
      "epoch:14 step:13807 [D loss: 0.725282, acc.: 48.44%] [G loss: 0.863800]\n",
      "epoch:14 step:13808 [D loss: 0.726210, acc.: 41.41%] [G loss: 0.818939]\n",
      "epoch:14 step:13809 [D loss: 0.674488, acc.: 57.03%] [G loss: 0.849147]\n",
      "epoch:14 step:13810 [D loss: 0.702873, acc.: 50.78%] [G loss: 0.802590]\n",
      "epoch:14 step:13811 [D loss: 0.659805, acc.: 57.03%] [G loss: 0.825150]\n",
      "epoch:14 step:13812 [D loss: 0.653692, acc.: 60.94%] [G loss: 0.845363]\n",
      "epoch:14 step:13813 [D loss: 0.665299, acc.: 60.16%] [G loss: 0.838168]\n",
      "epoch:14 step:13814 [D loss: 0.702120, acc.: 53.91%] [G loss: 0.786496]\n",
      "epoch:14 step:13815 [D loss: 0.672911, acc.: 63.28%] [G loss: 0.820983]\n",
      "epoch:14 step:13816 [D loss: 0.670041, acc.: 65.62%] [G loss: 0.841654]\n",
      "epoch:14 step:13817 [D loss: 0.709231, acc.: 46.09%] [G loss: 0.782813]\n",
      "epoch:14 step:13818 [D loss: 0.647080, acc.: 61.72%] [G loss: 0.838487]\n",
      "epoch:14 step:13819 [D loss: 0.657177, acc.: 58.59%] [G loss: 0.765684]\n",
      "epoch:14 step:13820 [D loss: 0.655732, acc.: 55.47%] [G loss: 0.910826]\n",
      "epoch:14 step:13821 [D loss: 0.709976, acc.: 49.22%] [G loss: 0.800758]\n",
      "epoch:14 step:13822 [D loss: 0.689203, acc.: 54.69%] [G loss: 0.872345]\n",
      "epoch:14 step:13823 [D loss: 0.719032, acc.: 42.97%] [G loss: 0.797167]\n",
      "epoch:14 step:13824 [D loss: 0.643824, acc.: 67.19%] [G loss: 0.746614]\n",
      "epoch:14 step:13825 [D loss: 0.587198, acc.: 78.12%] [G loss: 0.823463]\n",
      "epoch:14 step:13826 [D loss: 0.634868, acc.: 67.19%] [G loss: 0.789655]\n",
      "epoch:14 step:13827 [D loss: 0.631247, acc.: 64.06%] [G loss: 0.793008]\n",
      "epoch:14 step:13828 [D loss: 0.740786, acc.: 48.44%] [G loss: 0.906728]\n",
      "epoch:14 step:13829 [D loss: 0.728770, acc.: 44.53%] [G loss: 0.740556]\n",
      "epoch:14 step:13830 [D loss: 0.642736, acc.: 64.84%] [G loss: 0.819929]\n",
      "epoch:14 step:13831 [D loss: 0.621235, acc.: 68.75%] [G loss: 0.808544]\n",
      "epoch:14 step:13832 [D loss: 0.651338, acc.: 61.72%] [G loss: 0.816170]\n",
      "epoch:14 step:13833 [D loss: 0.704021, acc.: 49.22%] [G loss: 0.802095]\n",
      "epoch:14 step:13834 [D loss: 0.733275, acc.: 45.31%] [G loss: 0.781102]\n",
      "epoch:14 step:13835 [D loss: 0.692774, acc.: 53.91%] [G loss: 0.793196]\n",
      "epoch:14 step:13836 [D loss: 0.690528, acc.: 54.69%] [G loss: 0.845939]\n",
      "epoch:14 step:13837 [D loss: 0.673380, acc.: 57.81%] [G loss: 0.830616]\n",
      "epoch:14 step:13838 [D loss: 0.647016, acc.: 65.62%] [G loss: 0.818984]\n",
      "epoch:14 step:13839 [D loss: 0.647377, acc.: 60.94%] [G loss: 0.827566]\n",
      "epoch:14 step:13840 [D loss: 0.710178, acc.: 50.78%] [G loss: 0.766537]\n",
      "epoch:14 step:13841 [D loss: 0.659835, acc.: 60.94%] [G loss: 0.799346]\n",
      "epoch:14 step:13842 [D loss: 0.653934, acc.: 53.12%] [G loss: 0.867825]\n",
      "epoch:14 step:13843 [D loss: 0.659880, acc.: 52.34%] [G loss: 0.820368]\n",
      "epoch:14 step:13844 [D loss: 0.686731, acc.: 50.00%] [G loss: 0.755115]\n",
      "epoch:14 step:13845 [D loss: 0.688288, acc.: 55.47%] [G loss: 0.791856]\n",
      "epoch:14 step:13846 [D loss: 0.664795, acc.: 56.25%] [G loss: 0.777485]\n",
      "epoch:14 step:13847 [D loss: 0.677884, acc.: 62.50%] [G loss: 0.855132]\n",
      "epoch:14 step:13848 [D loss: 0.654255, acc.: 61.72%] [G loss: 0.788865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13849 [D loss: 0.657992, acc.: 55.47%] [G loss: 0.794393]\n",
      "epoch:14 step:13850 [D loss: 0.627942, acc.: 71.09%] [G loss: 0.835535]\n",
      "epoch:14 step:13851 [D loss: 0.622323, acc.: 60.16%] [G loss: 0.785017]\n",
      "epoch:14 step:13852 [D loss: 0.673099, acc.: 58.59%] [G loss: 0.814585]\n",
      "epoch:14 step:13853 [D loss: 0.688293, acc.: 54.69%] [G loss: 0.764840]\n",
      "epoch:14 step:13854 [D loss: 0.657156, acc.: 62.50%] [G loss: 0.823113]\n",
      "epoch:14 step:13855 [D loss: 0.707910, acc.: 46.09%] [G loss: 0.877289]\n",
      "epoch:14 step:13856 [D loss: 0.678466, acc.: 55.47%] [G loss: 0.726367]\n",
      "epoch:14 step:13857 [D loss: 0.717848, acc.: 45.31%] [G loss: 0.782969]\n",
      "epoch:14 step:13858 [D loss: 0.710876, acc.: 49.22%] [G loss: 0.737190]\n",
      "epoch:14 step:13859 [D loss: 0.672625, acc.: 62.50%] [G loss: 0.752932]\n",
      "epoch:14 step:13860 [D loss: 0.704662, acc.: 52.34%] [G loss: 0.776241]\n",
      "epoch:14 step:13861 [D loss: 0.721188, acc.: 51.56%] [G loss: 0.745748]\n",
      "epoch:14 step:13862 [D loss: 0.686531, acc.: 58.59%] [G loss: 0.785925]\n",
      "epoch:14 step:13863 [D loss: 0.671891, acc.: 54.69%] [G loss: 0.791487]\n",
      "epoch:14 step:13864 [D loss: 0.642208, acc.: 64.06%] [G loss: 0.605499]\n",
      "epoch:14 step:13865 [D loss: 0.662909, acc.: 60.94%] [G loss: 0.761446]\n",
      "epoch:14 step:13866 [D loss: 0.697907, acc.: 53.12%] [G loss: 0.799349]\n",
      "epoch:14 step:13867 [D loss: 0.682419, acc.: 48.44%] [G loss: 0.805127]\n",
      "epoch:14 step:13868 [D loss: 0.673629, acc.: 52.34%] [G loss: 0.776900]\n",
      "epoch:14 step:13869 [D loss: 0.672096, acc.: 59.38%] [G loss: 0.826956]\n",
      "epoch:14 step:13870 [D loss: 0.671961, acc.: 55.47%] [G loss: 0.760482]\n",
      "epoch:14 step:13871 [D loss: 0.674217, acc.: 57.81%] [G loss: 0.784531]\n",
      "epoch:14 step:13872 [D loss: 0.669970, acc.: 56.25%] [G loss: 0.773306]\n",
      "epoch:14 step:13873 [D loss: 0.677561, acc.: 57.03%] [G loss: 0.776753]\n",
      "epoch:14 step:13874 [D loss: 0.630417, acc.: 68.75%] [G loss: 0.758674]\n",
      "epoch:14 step:13875 [D loss: 0.678086, acc.: 56.25%] [G loss: 0.798285]\n",
      "epoch:14 step:13876 [D loss: 0.704798, acc.: 50.78%] [G loss: 0.787021]\n",
      "epoch:14 step:13877 [D loss: 0.659698, acc.: 59.38%] [G loss: 0.850910]\n",
      "epoch:14 step:13878 [D loss: 0.723501, acc.: 48.44%] [G loss: 0.791349]\n",
      "epoch:14 step:13879 [D loss: 0.684270, acc.: 61.72%] [G loss: 0.865187]\n",
      "epoch:14 step:13880 [D loss: 0.669755, acc.: 55.47%] [G loss: 0.781713]\n",
      "epoch:14 step:13881 [D loss: 0.673236, acc.: 53.91%] [G loss: 0.802812]\n",
      "epoch:14 step:13882 [D loss: 0.665732, acc.: 57.03%] [G loss: 0.790463]\n",
      "epoch:14 step:13883 [D loss: 0.701530, acc.: 50.00%] [G loss: 0.761317]\n",
      "epoch:14 step:13884 [D loss: 0.670769, acc.: 53.12%] [G loss: 0.789765]\n",
      "epoch:14 step:13885 [D loss: 0.685602, acc.: 53.12%] [G loss: 0.831489]\n",
      "epoch:14 step:13886 [D loss: 0.697324, acc.: 54.69%] [G loss: 0.775212]\n",
      "epoch:14 step:13887 [D loss: 0.661537, acc.: 57.81%] [G loss: 0.750199]\n",
      "epoch:14 step:13888 [D loss: 0.681636, acc.: 58.59%] [G loss: 0.764670]\n",
      "epoch:14 step:13889 [D loss: 0.677931, acc.: 60.16%] [G loss: 0.809773]\n",
      "epoch:14 step:13890 [D loss: 0.714446, acc.: 49.22%] [G loss: 0.757693]\n",
      "epoch:14 step:13891 [D loss: 0.640341, acc.: 62.50%] [G loss: 0.748742]\n",
      "epoch:14 step:13892 [D loss: 0.655939, acc.: 60.94%] [G loss: 0.798120]\n",
      "epoch:14 step:13893 [D loss: 0.604259, acc.: 65.62%] [G loss: 0.834972]\n",
      "epoch:14 step:13894 [D loss: 0.693181, acc.: 56.25%] [G loss: 0.873469]\n",
      "epoch:14 step:13895 [D loss: 0.701043, acc.: 53.91%] [G loss: 0.799235]\n",
      "epoch:14 step:13896 [D loss: 0.698290, acc.: 54.69%] [G loss: 0.747092]\n",
      "epoch:14 step:13897 [D loss: 0.723937, acc.: 49.22%] [G loss: 0.759964]\n",
      "epoch:14 step:13898 [D loss: 0.683393, acc.: 57.81%] [G loss: 0.832509]\n",
      "epoch:14 step:13899 [D loss: 0.667591, acc.: 57.81%] [G loss: 0.835719]\n",
      "epoch:14 step:13900 [D loss: 0.647160, acc.: 65.62%] [G loss: 0.755524]\n",
      "epoch:14 step:13901 [D loss: 0.685709, acc.: 60.94%] [G loss: 0.798120]\n",
      "epoch:14 step:13902 [D loss: 0.696989, acc.: 45.31%] [G loss: 0.823080]\n",
      "epoch:14 step:13903 [D loss: 0.665018, acc.: 54.69%] [G loss: 0.801748]\n",
      "epoch:14 step:13904 [D loss: 0.682448, acc.: 56.25%] [G loss: 0.825743]\n",
      "epoch:14 step:13905 [D loss: 0.700668, acc.: 60.16%] [G loss: 0.813952]\n",
      "epoch:14 step:13906 [D loss: 0.682457, acc.: 57.81%] [G loss: 0.773483]\n",
      "epoch:14 step:13907 [D loss: 0.721582, acc.: 35.94%] [G loss: 0.784726]\n",
      "epoch:14 step:13908 [D loss: 0.671433, acc.: 54.69%] [G loss: 0.804387]\n",
      "epoch:14 step:13909 [D loss: 0.658946, acc.: 58.59%] [G loss: 0.752319]\n",
      "epoch:14 step:13910 [D loss: 0.662348, acc.: 59.38%] [G loss: 0.832401]\n",
      "epoch:14 step:13911 [D loss: 0.705570, acc.: 47.66%] [G loss: 0.741463]\n",
      "epoch:14 step:13912 [D loss: 0.661112, acc.: 57.03%] [G loss: 0.828285]\n",
      "epoch:14 step:13913 [D loss: 0.657232, acc.: 57.03%] [G loss: 0.825540]\n",
      "epoch:14 step:13914 [D loss: 0.645708, acc.: 64.84%] [G loss: 0.745862]\n",
      "epoch:14 step:13915 [D loss: 0.714478, acc.: 47.66%] [G loss: 0.782236]\n",
      "epoch:14 step:13916 [D loss: 0.705357, acc.: 51.56%] [G loss: 0.814484]\n",
      "epoch:14 step:13917 [D loss: 0.696303, acc.: 55.47%] [G loss: 0.726767]\n",
      "epoch:14 step:13918 [D loss: 0.718550, acc.: 46.09%] [G loss: 0.771476]\n",
      "epoch:14 step:13919 [D loss: 0.662343, acc.: 59.38%] [G loss: 0.774568]\n",
      "epoch:14 step:13920 [D loss: 0.391961, acc.: 78.12%] [G loss: 0.835171]\n",
      "epoch:14 step:13921 [D loss: 0.677681, acc.: 61.72%] [G loss: 0.818249]\n",
      "epoch:14 step:13922 [D loss: 0.655040, acc.: 64.06%] [G loss: 0.794276]\n",
      "epoch:14 step:13923 [D loss: 0.678024, acc.: 57.03%] [G loss: 0.772729]\n",
      "epoch:14 step:13924 [D loss: 0.685446, acc.: 53.12%] [G loss: 0.771364]\n",
      "epoch:14 step:13925 [D loss: 0.695228, acc.: 44.53%] [G loss: 0.825466]\n",
      "epoch:14 step:13926 [D loss: 0.715825, acc.: 53.91%] [G loss: 0.801750]\n",
      "epoch:14 step:13927 [D loss: 0.686794, acc.: 53.12%] [G loss: 0.810814]\n",
      "epoch:14 step:13928 [D loss: 0.683277, acc.: 53.12%] [G loss: 0.790984]\n",
      "epoch:14 step:13929 [D loss: 0.671226, acc.: 60.16%] [G loss: 0.837036]\n",
      "epoch:14 step:13930 [D loss: 0.677761, acc.: 53.12%] [G loss: 0.806131]\n",
      "epoch:14 step:13931 [D loss: 0.641272, acc.: 65.62%] [G loss: 0.747042]\n",
      "epoch:14 step:13932 [D loss: 0.671975, acc.: 53.12%] [G loss: 0.733110]\n",
      "epoch:14 step:13933 [D loss: 0.607193, acc.: 62.50%] [G loss: 0.750592]\n",
      "epoch:14 step:13934 [D loss: 0.640242, acc.: 67.19%] [G loss: 0.765122]\n",
      "epoch:14 step:13935 [D loss: 0.700414, acc.: 53.91%] [G loss: 0.724963]\n",
      "epoch:14 step:13936 [D loss: 0.680787, acc.: 55.47%] [G loss: 0.744997]\n",
      "epoch:14 step:13937 [D loss: 0.681850, acc.: 53.91%] [G loss: 0.769527]\n",
      "epoch:14 step:13938 [D loss: 0.744033, acc.: 40.62%] [G loss: 0.761632]\n",
      "epoch:14 step:13939 [D loss: 0.707030, acc.: 54.69%] [G loss: 0.746498]\n",
      "epoch:14 step:13940 [D loss: 0.698235, acc.: 48.44%] [G loss: 0.756343]\n",
      "epoch:14 step:13941 [D loss: 0.680497, acc.: 54.69%] [G loss: 0.756826]\n",
      "epoch:14 step:13942 [D loss: 0.631882, acc.: 65.62%] [G loss: 0.818518]\n",
      "epoch:14 step:13943 [D loss: 0.619435, acc.: 71.09%] [G loss: 0.835407]\n",
      "epoch:14 step:13944 [D loss: 0.601219, acc.: 74.22%] [G loss: 0.866601]\n",
      "epoch:14 step:13945 [D loss: 0.749113, acc.: 46.09%] [G loss: 0.769544]\n",
      "epoch:14 step:13946 [D loss: 0.686581, acc.: 57.81%] [G loss: 0.871163]\n",
      "epoch:14 step:13947 [D loss: 0.658937, acc.: 64.06%] [G loss: 0.780927]\n",
      "epoch:14 step:13948 [D loss: 0.645489, acc.: 64.84%] [G loss: 0.810595]\n",
      "epoch:14 step:13949 [D loss: 0.623320, acc.: 65.62%] [G loss: 0.749595]\n",
      "epoch:14 step:13950 [D loss: 0.651748, acc.: 59.38%] [G loss: 0.761905]\n",
      "epoch:14 step:13951 [D loss: 0.688788, acc.: 50.00%] [G loss: 0.755297]\n",
      "epoch:14 step:13952 [D loss: 0.720751, acc.: 46.09%] [G loss: 0.800555]\n",
      "epoch:14 step:13953 [D loss: 0.704961, acc.: 53.12%] [G loss: 0.770203]\n",
      "epoch:14 step:13954 [D loss: 0.700003, acc.: 53.12%] [G loss: 0.761313]\n",
      "epoch:14 step:13955 [D loss: 0.682052, acc.: 57.03%] [G loss: 0.752412]\n",
      "epoch:14 step:13956 [D loss: 0.677899, acc.: 61.72%] [G loss: 0.722071]\n",
      "epoch:14 step:13957 [D loss: 0.725893, acc.: 49.22%] [G loss: 0.717012]\n",
      "epoch:14 step:13958 [D loss: 0.691154, acc.: 53.12%] [G loss: 0.397484]\n",
      "epoch:14 step:13959 [D loss: 0.674288, acc.: 55.47%] [G loss: 0.739952]\n",
      "epoch:14 step:13960 [D loss: 0.653945, acc.: 62.50%] [G loss: 0.789105]\n",
      "epoch:14 step:13961 [D loss: 0.690309, acc.: 53.91%] [G loss: 0.712372]\n",
      "epoch:14 step:13962 [D loss: 1.438652, acc.: 34.38%] [G loss: 1.004680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13963 [D loss: 0.749980, acc.: 57.81%] [G loss: 1.012517]\n",
      "epoch:14 step:13964 [D loss: 0.685993, acc.: 64.84%] [G loss: 2.719465]\n",
      "epoch:14 step:13965 [D loss: 0.724774, acc.: 56.25%] [G loss: 0.899284]\n",
      "epoch:14 step:13966 [D loss: 0.716962, acc.: 53.12%] [G loss: 0.900950]\n",
      "epoch:14 step:13967 [D loss: 0.710421, acc.: 47.66%] [G loss: 0.902874]\n",
      "epoch:14 step:13968 [D loss: 0.709112, acc.: 54.69%] [G loss: 0.823786]\n",
      "epoch:14 step:13969 [D loss: 0.650510, acc.: 63.28%] [G loss: 0.854248]\n",
      "epoch:14 step:13970 [D loss: 0.617963, acc.: 65.62%] [G loss: 0.883067]\n",
      "epoch:14 step:13971 [D loss: 0.640711, acc.: 67.19%] [G loss: 0.929128]\n",
      "epoch:14 step:13972 [D loss: 0.616502, acc.: 70.31%] [G loss: 0.927219]\n",
      "epoch:14 step:13973 [D loss: 0.663272, acc.: 59.38%] [G loss: 0.914976]\n",
      "epoch:14 step:13974 [D loss: 0.646948, acc.: 68.75%] [G loss: 0.818252]\n",
      "epoch:14 step:13975 [D loss: 0.651111, acc.: 57.81%] [G loss: 0.854621]\n",
      "epoch:14 step:13976 [D loss: 0.751268, acc.: 49.22%] [G loss: 0.831999]\n",
      "epoch:14 step:13977 [D loss: 0.770497, acc.: 37.50%] [G loss: 0.744166]\n",
      "epoch:14 step:13978 [D loss: 0.687384, acc.: 46.88%] [G loss: 0.790094]\n",
      "epoch:14 step:13979 [D loss: 0.672307, acc.: 58.59%] [G loss: 0.750225]\n",
      "epoch:14 step:13980 [D loss: 0.685053, acc.: 53.91%] [G loss: 0.766256]\n",
      "epoch:14 step:13981 [D loss: 0.666289, acc.: 53.12%] [G loss: 0.717215]\n",
      "epoch:14 step:13982 [D loss: 0.723025, acc.: 45.31%] [G loss: 0.812419]\n",
      "epoch:14 step:13983 [D loss: 0.674120, acc.: 55.47%] [G loss: 0.744184]\n",
      "epoch:14 step:13984 [D loss: 0.658111, acc.: 57.81%] [G loss: 0.784308]\n",
      "epoch:14 step:13985 [D loss: 0.668038, acc.: 57.03%] [G loss: 0.772738]\n",
      "epoch:14 step:13986 [D loss: 0.696294, acc.: 49.22%] [G loss: 0.804096]\n",
      "epoch:14 step:13987 [D loss: 0.648814, acc.: 60.94%] [G loss: 0.805501]\n",
      "epoch:14 step:13988 [D loss: 0.685082, acc.: 53.91%] [G loss: 0.796073]\n",
      "epoch:14 step:13989 [D loss: 0.675327, acc.: 53.12%] [G loss: 0.756629]\n",
      "epoch:14 step:13990 [D loss: 0.700840, acc.: 53.91%] [G loss: 0.792189]\n",
      "epoch:14 step:13991 [D loss: 0.690074, acc.: 53.12%] [G loss: 0.729956]\n",
      "epoch:14 step:13992 [D loss: 0.692491, acc.: 57.03%] [G loss: 0.766915]\n",
      "epoch:14 step:13993 [D loss: 0.685859, acc.: 53.12%] [G loss: 0.715601]\n",
      "epoch:14 step:13994 [D loss: 0.701368, acc.: 51.56%] [G loss: 0.681710]\n",
      "epoch:14 step:13995 [D loss: 0.680236, acc.: 50.00%] [G loss: 0.756570]\n",
      "epoch:14 step:13996 [D loss: 0.644172, acc.: 62.50%] [G loss: 0.775937]\n",
      "epoch:14 step:13997 [D loss: 0.680629, acc.: 57.81%] [G loss: 0.807918]\n",
      "epoch:14 step:13998 [D loss: 0.699506, acc.: 53.12%] [G loss: 0.815673]\n",
      "epoch:14 step:13999 [D loss: 0.671527, acc.: 63.28%] [G loss: 0.805710]\n",
      "epoch:14 step:14000 [D loss: 0.677867, acc.: 55.47%] [G loss: 0.755854]\n",
      "epoch:14 step:14001 [D loss: 0.665294, acc.: 63.28%] [G loss: 0.794372]\n",
      "epoch:14 step:14002 [D loss: 0.682067, acc.: 54.69%] [G loss: 0.817622]\n",
      "epoch:14 step:14003 [D loss: 0.685532, acc.: 58.59%] [G loss: 0.762778]\n",
      "epoch:14 step:14004 [D loss: 0.667004, acc.: 59.38%] [G loss: 0.830011]\n",
      "epoch:14 step:14005 [D loss: 0.689974, acc.: 54.69%] [G loss: 0.776997]\n",
      "epoch:14 step:14006 [D loss: 0.652282, acc.: 64.06%] [G loss: 0.784009]\n",
      "epoch:14 step:14007 [D loss: 0.705850, acc.: 53.91%] [G loss: 0.816286]\n",
      "epoch:14 step:14008 [D loss: 0.656003, acc.: 62.50%] [G loss: 0.841951]\n",
      "epoch:14 step:14009 [D loss: 0.725360, acc.: 45.31%] [G loss: 0.764847]\n",
      "epoch:14 step:14010 [D loss: 0.664361, acc.: 58.59%] [G loss: 0.824166]\n",
      "epoch:14 step:14011 [D loss: 0.689013, acc.: 57.03%] [G loss: 0.837824]\n",
      "epoch:14 step:14012 [D loss: 0.687357, acc.: 57.03%] [G loss: 0.782879]\n",
      "epoch:14 step:14013 [D loss: 0.694194, acc.: 55.47%] [G loss: 0.735926]\n",
      "epoch:14 step:14014 [D loss: 0.651193, acc.: 59.38%] [G loss: 0.741919]\n",
      "epoch:14 step:14015 [D loss: 0.645943, acc.: 67.19%] [G loss: 0.783635]\n",
      "epoch:14 step:14016 [D loss: 0.653048, acc.: 65.62%] [G loss: 0.816925]\n",
      "epoch:14 step:14017 [D loss: 0.532442, acc.: 80.47%] [G loss: 0.894490]\n",
      "epoch:14 step:14018 [D loss: 0.603171, acc.: 71.09%] [G loss: 0.814886]\n",
      "epoch:14 step:14019 [D loss: 0.633786, acc.: 72.66%] [G loss: 0.805343]\n",
      "epoch:14 step:14020 [D loss: 0.654653, acc.: 61.72%] [G loss: 0.876069]\n",
      "epoch:14 step:14021 [D loss: 0.638938, acc.: 64.84%] [G loss: 0.753023]\n",
      "epoch:14 step:14022 [D loss: 0.738045, acc.: 44.53%] [G loss: 0.778519]\n",
      "epoch:14 step:14023 [D loss: 0.701027, acc.: 47.66%] [G loss: 0.715378]\n",
      "epoch:14 step:14024 [D loss: 0.721760, acc.: 49.22%] [G loss: 0.760540]\n",
      "epoch:14 step:14025 [D loss: 0.695660, acc.: 51.56%] [G loss: 0.772374]\n",
      "epoch:14 step:14026 [D loss: 0.720474, acc.: 48.44%] [G loss: 0.791715]\n",
      "epoch:14 step:14027 [D loss: 0.632653, acc.: 62.50%] [G loss: 0.781746]\n",
      "epoch:14 step:14028 [D loss: 0.721391, acc.: 42.19%] [G loss: 0.753774]\n",
      "epoch:14 step:14029 [D loss: 0.640868, acc.: 60.16%] [G loss: 0.743595]\n",
      "epoch:14 step:14030 [D loss: 0.397542, acc.: 79.69%] [G loss: 0.843000]\n",
      "epoch:14 step:14031 [D loss: 0.669658, acc.: 57.81%] [G loss: 0.794248]\n",
      "epoch:14 step:14032 [D loss: 0.703230, acc.: 46.88%] [G loss: 0.750681]\n",
      "epoch:14 step:14033 [D loss: 0.684244, acc.: 53.91%] [G loss: 0.830469]\n",
      "epoch:14 step:14034 [D loss: 0.679518, acc.: 56.25%] [G loss: 0.851870]\n",
      "epoch:14 step:14035 [D loss: 0.659827, acc.: 60.94%] [G loss: 0.762347]\n",
      "epoch:14 step:14036 [D loss: 0.639222, acc.: 60.16%] [G loss: 0.776680]\n",
      "epoch:14 step:14037 [D loss: 0.598608, acc.: 67.97%] [G loss: 0.808932]\n",
      "epoch:14 step:14038 [D loss: 0.690013, acc.: 55.47%] [G loss: 0.776771]\n",
      "epoch:14 step:14039 [D loss: 0.620116, acc.: 65.62%] [G loss: 0.759589]\n",
      "epoch:14 step:14040 [D loss: 0.644342, acc.: 60.94%] [G loss: 0.858531]\n",
      "epoch:14 step:14041 [D loss: 0.589889, acc.: 74.22%] [G loss: 0.891575]\n",
      "epoch:14 step:14042 [D loss: 0.534357, acc.: 68.75%] [G loss: 0.832714]\n",
      "epoch:14 step:14043 [D loss: 0.527258, acc.: 75.00%] [G loss: 0.868321]\n",
      "epoch:14 step:14044 [D loss: 0.486398, acc.: 74.22%] [G loss: 0.796597]\n",
      "epoch:14 step:14045 [D loss: 0.411257, acc.: 73.44%] [G loss: 1.042127]\n",
      "epoch:14 step:14046 [D loss: 0.724712, acc.: 50.00%] [G loss: 0.935383]\n",
      "epoch:14 step:14047 [D loss: 0.674491, acc.: 52.34%] [G loss: 1.007836]\n",
      "epoch:14 step:14048 [D loss: 0.584479, acc.: 74.22%] [G loss: 0.942264]\n",
      "epoch:14 step:14049 [D loss: 0.611658, acc.: 68.75%] [G loss: 0.855920]\n",
      "epoch:14 step:14050 [D loss: 0.724209, acc.: 50.78%] [G loss: 0.915602]\n",
      "epoch:14 step:14051 [D loss: 0.593337, acc.: 64.84%] [G loss: 0.917491]\n",
      "epoch:14 step:14052 [D loss: 0.554398, acc.: 75.00%] [G loss: 0.856070]\n",
      "epoch:14 step:14053 [D loss: 0.614019, acc.: 66.41%] [G loss: 0.862056]\n",
      "epoch:14 step:14054 [D loss: 0.427497, acc.: 74.22%] [G loss: 0.849686]\n",
      "epoch:14 step:14055 [D loss: 0.284269, acc.: 86.72%] [G loss: 0.826285]\n",
      "epoch:15 step:14056 [D loss: 0.754299, acc.: 51.56%] [G loss: 0.993303]\n",
      "epoch:15 step:14057 [D loss: 0.818976, acc.: 39.84%] [G loss: 0.990998]\n",
      "epoch:15 step:14058 [D loss: 0.827662, acc.: 34.38%] [G loss: 1.050601]\n",
      "epoch:15 step:14059 [D loss: 0.702530, acc.: 50.00%] [G loss: 0.842465]\n",
      "epoch:15 step:14060 [D loss: 0.741012, acc.: 46.09%] [G loss: 0.923765]\n",
      "epoch:15 step:14061 [D loss: 0.724058, acc.: 43.75%] [G loss: 0.878475]\n",
      "epoch:15 step:14062 [D loss: 0.716277, acc.: 50.00%] [G loss: 0.882266]\n",
      "epoch:15 step:14063 [D loss: 0.696286, acc.: 50.78%] [G loss: 0.908294]\n",
      "epoch:15 step:14064 [D loss: 0.670099, acc.: 59.38%] [G loss: 0.836552]\n",
      "epoch:15 step:14065 [D loss: 0.664463, acc.: 53.12%] [G loss: 0.855558]\n",
      "epoch:15 step:14066 [D loss: 0.707912, acc.: 47.66%] [G loss: 0.784633]\n",
      "epoch:15 step:14067 [D loss: 0.682903, acc.: 54.69%] [G loss: 0.768203]\n",
      "epoch:15 step:14068 [D loss: 0.725601, acc.: 49.22%] [G loss: 0.841359]\n",
      "epoch:15 step:14069 [D loss: 0.682291, acc.: 57.03%] [G loss: 0.712708]\n",
      "epoch:15 step:14070 [D loss: 0.631341, acc.: 68.75%] [G loss: 0.796144]\n",
      "epoch:15 step:14071 [D loss: 0.715401, acc.: 46.88%] [G loss: 0.772897]\n",
      "epoch:15 step:14072 [D loss: 0.710673, acc.: 50.00%] [G loss: 0.797178]\n",
      "epoch:15 step:14073 [D loss: 0.662715, acc.: 59.38%] [G loss: 0.555592]\n",
      "epoch:15 step:14074 [D loss: 0.702712, acc.: 55.47%] [G loss: 0.677238]\n",
      "epoch:15 step:14075 [D loss: 0.737011, acc.: 39.84%] [G loss: 0.733623]\n",
      "epoch:15 step:14076 [D loss: 0.959620, acc.: 43.75%] [G loss: 0.958584]\n",
      "epoch:15 step:14077 [D loss: 0.669580, acc.: 64.06%] [G loss: 1.050547]\n",
      "epoch:15 step:14078 [D loss: 0.684626, acc.: 60.16%] [G loss: 0.948550]\n",
      "epoch:15 step:14079 [D loss: 0.658706, acc.: 57.03%] [G loss: 0.923441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14080 [D loss: 0.680215, acc.: 60.16%] [G loss: 0.887242]\n",
      "epoch:15 step:14081 [D loss: 0.658725, acc.: 63.28%] [G loss: 1.104633]\n",
      "epoch:15 step:14082 [D loss: 0.708225, acc.: 47.66%] [G loss: 0.846355]\n",
      "epoch:15 step:14083 [D loss: 0.714513, acc.: 48.44%] [G loss: 0.859333]\n",
      "epoch:15 step:14084 [D loss: 0.675654, acc.: 54.69%] [G loss: 0.804281]\n",
      "epoch:15 step:14085 [D loss: 0.675376, acc.: 60.94%] [G loss: 0.761414]\n",
      "epoch:15 step:14086 [D loss: 0.656160, acc.: 56.25%] [G loss: 0.829052]\n",
      "epoch:15 step:14087 [D loss: 0.628414, acc.: 67.19%] [G loss: 0.845583]\n",
      "epoch:15 step:14088 [D loss: 0.626137, acc.: 68.75%] [G loss: 0.842367]\n",
      "epoch:15 step:14089 [D loss: 0.630646, acc.: 69.53%] [G loss: 0.826141]\n",
      "epoch:15 step:14090 [D loss: 0.600066, acc.: 67.97%] [G loss: 0.934828]\n",
      "epoch:15 step:14091 [D loss: 0.533317, acc.: 81.25%] [G loss: 0.891896]\n",
      "epoch:15 step:14092 [D loss: 0.710434, acc.: 47.66%] [G loss: 0.794923]\n",
      "epoch:15 step:14093 [D loss: 0.865229, acc.: 35.94%] [G loss: 0.804315]\n",
      "epoch:15 step:14094 [D loss: 0.752600, acc.: 38.28%] [G loss: 0.713133]\n",
      "epoch:15 step:14095 [D loss: 0.742927, acc.: 42.19%] [G loss: 0.783125]\n",
      "epoch:15 step:14096 [D loss: 0.677717, acc.: 53.91%] [G loss: 0.791956]\n",
      "epoch:15 step:14097 [D loss: 0.685008, acc.: 51.56%] [G loss: 0.729203]\n",
      "epoch:15 step:14098 [D loss: 0.649413, acc.: 63.28%] [G loss: 0.698291]\n",
      "epoch:15 step:14099 [D loss: 0.698378, acc.: 52.34%] [G loss: 0.721035]\n",
      "epoch:15 step:14100 [D loss: 0.678311, acc.: 57.81%] [G loss: 0.781549]\n",
      "epoch:15 step:14101 [D loss: 0.644478, acc.: 63.28%] [G loss: 0.716777]\n",
      "epoch:15 step:14102 [D loss: 0.668176, acc.: 57.81%] [G loss: 0.830247]\n",
      "epoch:15 step:14103 [D loss: 0.677083, acc.: 55.47%] [G loss: 0.787035]\n",
      "epoch:15 step:14104 [D loss: 0.666139, acc.: 60.94%] [G loss: 0.781774]\n",
      "epoch:15 step:14105 [D loss: 0.595120, acc.: 71.88%] [G loss: 0.793149]\n",
      "epoch:15 step:14106 [D loss: 0.667608, acc.: 57.81%] [G loss: 0.772915]\n",
      "epoch:15 step:14107 [D loss: 0.660672, acc.: 60.94%] [G loss: 0.733597]\n",
      "epoch:15 step:14108 [D loss: 0.698642, acc.: 54.69%] [G loss: 0.777176]\n",
      "epoch:15 step:14109 [D loss: 0.716608, acc.: 50.00%] [G loss: 0.726168]\n",
      "epoch:15 step:14110 [D loss: 0.719771, acc.: 49.22%] [G loss: 0.795506]\n",
      "epoch:15 step:14111 [D loss: 0.708790, acc.: 50.78%] [G loss: 0.783401]\n",
      "epoch:15 step:14112 [D loss: 0.683671, acc.: 55.47%] [G loss: 0.774483]\n",
      "epoch:15 step:14113 [D loss: 0.721333, acc.: 42.97%] [G loss: 0.777642]\n",
      "epoch:15 step:14114 [D loss: 0.686128, acc.: 57.03%] [G loss: 0.792343]\n",
      "epoch:15 step:14115 [D loss: 0.672872, acc.: 62.50%] [G loss: 0.778555]\n",
      "epoch:15 step:14116 [D loss: 0.711684, acc.: 45.31%] [G loss: 0.838755]\n",
      "epoch:15 step:14117 [D loss: 0.670999, acc.: 58.59%] [G loss: 0.817738]\n",
      "epoch:15 step:14118 [D loss: 0.678824, acc.: 57.03%] [G loss: 0.818116]\n",
      "epoch:15 step:14119 [D loss: 0.662848, acc.: 63.28%] [G loss: 0.835141]\n",
      "epoch:15 step:14120 [D loss: 0.701513, acc.: 50.00%] [G loss: 0.846166]\n",
      "epoch:15 step:14121 [D loss: 0.675514, acc.: 57.81%] [G loss: 0.798684]\n",
      "epoch:15 step:14122 [D loss: 0.668938, acc.: 57.03%] [G loss: 0.830476]\n",
      "epoch:15 step:14123 [D loss: 0.680356, acc.: 57.03%] [G loss: 0.843040]\n",
      "epoch:15 step:14124 [D loss: 0.671937, acc.: 57.03%] [G loss: 0.796101]\n",
      "epoch:15 step:14125 [D loss: 0.702426, acc.: 51.56%] [G loss: 0.814816]\n",
      "epoch:15 step:14126 [D loss: 0.663847, acc.: 62.50%] [G loss: 0.835274]\n",
      "epoch:15 step:14127 [D loss: 0.664585, acc.: 57.81%] [G loss: 0.753225]\n",
      "epoch:15 step:14128 [D loss: 0.694681, acc.: 53.91%] [G loss: 0.787888]\n",
      "epoch:15 step:14129 [D loss: 0.676318, acc.: 56.25%] [G loss: 0.764773]\n",
      "epoch:15 step:14130 [D loss: 0.704714, acc.: 51.56%] [G loss: 0.766740]\n",
      "epoch:15 step:14131 [D loss: 0.657897, acc.: 54.69%] [G loss: 0.768605]\n",
      "epoch:15 step:14132 [D loss: 0.633607, acc.: 66.41%] [G loss: 0.837302]\n",
      "epoch:15 step:14133 [D loss: 0.700914, acc.: 43.75%] [G loss: 0.779487]\n",
      "epoch:15 step:14134 [D loss: 0.721402, acc.: 46.88%] [G loss: 0.825861]\n",
      "epoch:15 step:14135 [D loss: 0.722789, acc.: 47.66%] [G loss: 0.785317]\n",
      "epoch:15 step:14136 [D loss: 0.698132, acc.: 45.31%] [G loss: 0.859667]\n",
      "epoch:15 step:14137 [D loss: 0.682629, acc.: 56.25%] [G loss: 0.831609]\n",
      "epoch:15 step:14138 [D loss: 0.671956, acc.: 60.16%] [G loss: 0.851122]\n",
      "epoch:15 step:14139 [D loss: 0.687492, acc.: 57.81%] [G loss: 0.817357]\n",
      "epoch:15 step:14140 [D loss: 0.681594, acc.: 57.03%] [G loss: 0.794958]\n",
      "epoch:15 step:14141 [D loss: 0.713377, acc.: 49.22%] [G loss: 0.809776]\n",
      "epoch:15 step:14142 [D loss: 0.658417, acc.: 62.50%] [G loss: 0.780246]\n",
      "epoch:15 step:14143 [D loss: 0.650568, acc.: 67.19%] [G loss: 0.849756]\n",
      "epoch:15 step:14144 [D loss: 0.626615, acc.: 64.84%] [G loss: 0.786222]\n",
      "epoch:15 step:14145 [D loss: 0.641307, acc.: 66.41%] [G loss: 0.858623]\n",
      "epoch:15 step:14146 [D loss: 0.637503, acc.: 63.28%] [G loss: 0.860911]\n",
      "epoch:15 step:14147 [D loss: 0.592696, acc.: 75.78%] [G loss: 0.804445]\n",
      "epoch:15 step:14148 [D loss: 0.586546, acc.: 64.84%] [G loss: 0.726413]\n",
      "epoch:15 step:14149 [D loss: 0.630937, acc.: 67.97%] [G loss: 0.868511]\n",
      "epoch:15 step:14150 [D loss: 0.740211, acc.: 44.53%] [G loss: 0.784688]\n",
      "epoch:15 step:14151 [D loss: 0.644039, acc.: 64.84%] [G loss: 0.866414]\n",
      "epoch:15 step:14152 [D loss: 0.693228, acc.: 53.12%] [G loss: 0.810329]\n",
      "epoch:15 step:14153 [D loss: 0.704403, acc.: 50.00%] [G loss: 0.827463]\n",
      "epoch:15 step:14154 [D loss: 0.612310, acc.: 68.75%] [G loss: 0.851168]\n",
      "epoch:15 step:14155 [D loss: 0.634029, acc.: 67.19%] [G loss: 0.826342]\n",
      "epoch:15 step:14156 [D loss: 0.675749, acc.: 59.38%] [G loss: 0.770197]\n",
      "epoch:15 step:14157 [D loss: 0.682867, acc.: 57.81%] [G loss: 0.775903]\n",
      "epoch:15 step:14158 [D loss: 0.725574, acc.: 48.44%] [G loss: 0.853666]\n",
      "epoch:15 step:14159 [D loss: 0.751396, acc.: 47.66%] [G loss: 0.758640]\n",
      "epoch:15 step:14160 [D loss: 0.724271, acc.: 49.22%] [G loss: 0.704374]\n",
      "epoch:15 step:14161 [D loss: 0.694280, acc.: 56.25%] [G loss: 0.704990]\n",
      "epoch:15 step:14162 [D loss: 0.658989, acc.: 63.28%] [G loss: 0.796533]\n",
      "epoch:15 step:14163 [D loss: 0.724578, acc.: 51.56%] [G loss: 0.849971]\n",
      "epoch:15 step:14164 [D loss: 0.679809, acc.: 57.03%] [G loss: 0.873523]\n",
      "epoch:15 step:14165 [D loss: 0.693597, acc.: 51.56%] [G loss: 0.767152]\n",
      "epoch:15 step:14166 [D loss: 0.706059, acc.: 51.56%] [G loss: 0.805011]\n",
      "epoch:15 step:14167 [D loss: 0.661469, acc.: 57.81%] [G loss: 0.817207]\n",
      "epoch:15 step:14168 [D loss: 0.635454, acc.: 64.84%] [G loss: 0.798368]\n",
      "epoch:15 step:14169 [D loss: 0.662759, acc.: 57.03%] [G loss: 0.788810]\n",
      "epoch:15 step:14170 [D loss: 0.617203, acc.: 64.84%] [G loss: 0.803714]\n",
      "epoch:15 step:14171 [D loss: 0.704570, acc.: 54.69%] [G loss: 0.853891]\n",
      "epoch:15 step:14172 [D loss: 0.661898, acc.: 62.50%] [G loss: 0.840750]\n",
      "epoch:15 step:14173 [D loss: 0.649130, acc.: 64.06%] [G loss: 0.855537]\n",
      "epoch:15 step:14174 [D loss: 0.608730, acc.: 67.97%] [G loss: 0.857782]\n",
      "epoch:15 step:14175 [D loss: 0.746384, acc.: 42.97%] [G loss: 0.829770]\n",
      "epoch:15 step:14176 [D loss: 0.728993, acc.: 50.00%] [G loss: 0.801627]\n",
      "epoch:15 step:14177 [D loss: 0.685505, acc.: 54.69%] [G loss: 0.639661]\n",
      "epoch:15 step:14178 [D loss: 0.731714, acc.: 42.19%] [G loss: 0.766946]\n",
      "epoch:15 step:14179 [D loss: 0.748902, acc.: 42.97%] [G loss: 0.765769]\n",
      "epoch:15 step:14180 [D loss: 0.653951, acc.: 60.94%] [G loss: 0.853373]\n",
      "epoch:15 step:14181 [D loss: 0.632544, acc.: 64.84%] [G loss: 0.839650]\n",
      "epoch:15 step:14182 [D loss: 0.650740, acc.: 62.50%] [G loss: 0.850936]\n",
      "epoch:15 step:14183 [D loss: 0.714828, acc.: 48.44%] [G loss: 0.871585]\n",
      "epoch:15 step:14184 [D loss: 0.735014, acc.: 48.44%] [G loss: 0.892327]\n",
      "epoch:15 step:14185 [D loss: 0.640867, acc.: 62.50%] [G loss: 0.852867]\n",
      "epoch:15 step:14186 [D loss: 0.695866, acc.: 56.25%] [G loss: 0.865643]\n",
      "epoch:15 step:14187 [D loss: 0.675771, acc.: 57.03%] [G loss: 0.892869]\n",
      "epoch:15 step:14188 [D loss: 0.635214, acc.: 66.41%] [G loss: 0.859796]\n",
      "epoch:15 step:14189 [D loss: 0.630472, acc.: 68.75%] [G loss: 0.880550]\n",
      "epoch:15 step:14190 [D loss: 0.619714, acc.: 69.53%] [G loss: 0.882514]\n",
      "epoch:15 step:14191 [D loss: 0.675649, acc.: 56.25%] [G loss: 0.810906]\n",
      "epoch:15 step:14192 [D loss: 0.668644, acc.: 57.03%] [G loss: 0.799551]\n",
      "epoch:15 step:14193 [D loss: 0.694948, acc.: 57.81%] [G loss: 0.821175]\n",
      "epoch:15 step:14194 [D loss: 0.699819, acc.: 50.00%] [G loss: 0.815455]\n",
      "epoch:15 step:14195 [D loss: 0.693622, acc.: 48.44%] [G loss: 0.759169]\n",
      "epoch:15 step:14196 [D loss: 0.671762, acc.: 58.59%] [G loss: 0.710412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14197 [D loss: 0.681438, acc.: 59.38%] [G loss: 0.742560]\n",
      "epoch:15 step:14198 [D loss: 0.662214, acc.: 60.94%] [G loss: 0.776348]\n",
      "epoch:15 step:14199 [D loss: 0.635310, acc.: 62.50%] [G loss: 0.746268]\n",
      "epoch:15 step:14200 [D loss: 0.630984, acc.: 60.94%] [G loss: 0.770043]\n",
      "epoch:15 step:14201 [D loss: 0.619876, acc.: 67.19%] [G loss: 0.752847]\n",
      "epoch:15 step:14202 [D loss: 0.699432, acc.: 51.56%] [G loss: 0.849279]\n",
      "epoch:15 step:14203 [D loss: 0.726791, acc.: 45.31%] [G loss: 0.740457]\n",
      "epoch:15 step:14204 [D loss: 0.666997, acc.: 50.00%] [G loss: 0.773872]\n",
      "epoch:15 step:14205 [D loss: 0.588976, acc.: 73.44%] [G loss: 0.861611]\n",
      "epoch:15 step:14206 [D loss: 0.571847, acc.: 72.66%] [G loss: 0.852542]\n",
      "epoch:15 step:14207 [D loss: 0.602277, acc.: 71.88%] [G loss: 0.903533]\n",
      "epoch:15 step:14208 [D loss: 0.702933, acc.: 52.34%] [G loss: 0.839790]\n",
      "epoch:15 step:14209 [D loss: 0.721674, acc.: 52.34%] [G loss: 0.940586]\n",
      "epoch:15 step:14210 [D loss: 0.685020, acc.: 54.69%] [G loss: 0.774343]\n",
      "epoch:15 step:14211 [D loss: 0.707594, acc.: 53.91%] [G loss: 0.931728]\n",
      "epoch:15 step:14212 [D loss: 0.686027, acc.: 52.34%] [G loss: 0.831409]\n",
      "epoch:15 step:14213 [D loss: 0.682173, acc.: 54.69%] [G loss: 0.853974]\n",
      "epoch:15 step:14214 [D loss: 0.740675, acc.: 39.06%] [G loss: 0.800815]\n",
      "epoch:15 step:14215 [D loss: 0.730749, acc.: 50.00%] [G loss: 0.768684]\n",
      "epoch:15 step:14216 [D loss: 0.686411, acc.: 53.91%] [G loss: 0.719935]\n",
      "epoch:15 step:14217 [D loss: 0.686195, acc.: 49.22%] [G loss: 0.726425]\n",
      "epoch:15 step:14218 [D loss: 0.689660, acc.: 53.12%] [G loss: 0.763872]\n",
      "epoch:15 step:14219 [D loss: 0.697635, acc.: 51.56%] [G loss: 0.796636]\n",
      "epoch:15 step:14220 [D loss: 0.690136, acc.: 53.91%] [G loss: 0.779019]\n",
      "epoch:15 step:14221 [D loss: 0.690585, acc.: 53.91%] [G loss: 0.728984]\n",
      "epoch:15 step:14222 [D loss: 0.714164, acc.: 43.75%] [G loss: 0.756829]\n",
      "epoch:15 step:14223 [D loss: 0.653325, acc.: 58.59%] [G loss: 0.756422]\n",
      "epoch:15 step:14224 [D loss: 0.697812, acc.: 55.47%] [G loss: 0.760944]\n",
      "epoch:15 step:14225 [D loss: 0.681940, acc.: 54.69%] [G loss: 0.726280]\n",
      "epoch:15 step:14226 [D loss: 0.689369, acc.: 53.91%] [G loss: 0.769756]\n",
      "epoch:15 step:14227 [D loss: 0.647299, acc.: 59.38%] [G loss: 0.779023]\n",
      "epoch:15 step:14228 [D loss: 0.678262, acc.: 55.47%] [G loss: 0.815996]\n",
      "epoch:15 step:14229 [D loss: 0.721270, acc.: 48.44%] [G loss: 0.761803]\n",
      "epoch:15 step:14230 [D loss: 0.719093, acc.: 46.09%] [G loss: 0.758996]\n",
      "epoch:15 step:14231 [D loss: 0.669112, acc.: 57.81%] [G loss: 0.819649]\n",
      "epoch:15 step:14232 [D loss: 0.708063, acc.: 44.53%] [G loss: 0.782116]\n",
      "epoch:15 step:14233 [D loss: 0.675665, acc.: 64.06%] [G loss: 0.781833]\n",
      "epoch:15 step:14234 [D loss: 0.668538, acc.: 57.03%] [G loss: 0.814615]\n",
      "epoch:15 step:14235 [D loss: 0.687046, acc.: 53.12%] [G loss: 0.803477]\n",
      "epoch:15 step:14236 [D loss: 0.631758, acc.: 67.19%] [G loss: 0.842793]\n",
      "epoch:15 step:14237 [D loss: 0.648945, acc.: 65.62%] [G loss: 0.773320]\n",
      "epoch:15 step:14238 [D loss: 0.666636, acc.: 56.25%] [G loss: 0.802099]\n",
      "epoch:15 step:14239 [D loss: 0.611571, acc.: 66.41%] [G loss: 0.754045]\n",
      "epoch:15 step:14240 [D loss: 0.661818, acc.: 57.81%] [G loss: 0.740436]\n",
      "epoch:15 step:14241 [D loss: 0.719058, acc.: 53.12%] [G loss: 0.845819]\n",
      "epoch:15 step:14242 [D loss: 0.672781, acc.: 57.03%] [G loss: 0.794450]\n",
      "epoch:15 step:14243 [D loss: 0.653871, acc.: 58.59%] [G loss: 0.698241]\n",
      "epoch:15 step:14244 [D loss: 0.718602, acc.: 45.31%] [G loss: 0.740263]\n",
      "epoch:15 step:14245 [D loss: 0.650750, acc.: 60.94%] [G loss: 0.698435]\n",
      "epoch:15 step:14246 [D loss: 0.669864, acc.: 58.59%] [G loss: 0.767211]\n",
      "epoch:15 step:14247 [D loss: 0.623329, acc.: 71.09%] [G loss: 0.779795]\n",
      "epoch:15 step:14248 [D loss: 0.650010, acc.: 62.50%] [G loss: 0.897416]\n",
      "epoch:15 step:14249 [D loss: 0.628361, acc.: 64.84%] [G loss: 0.764068]\n",
      "epoch:15 step:14250 [D loss: 0.666537, acc.: 60.94%] [G loss: 0.889571]\n",
      "epoch:15 step:14251 [D loss: 0.674379, acc.: 60.94%] [G loss: 0.740677]\n",
      "epoch:15 step:14252 [D loss: 0.733680, acc.: 51.56%] [G loss: 0.772912]\n",
      "epoch:15 step:14253 [D loss: 0.655844, acc.: 67.19%] [G loss: 0.888621]\n",
      "epoch:15 step:14254 [D loss: 0.714767, acc.: 52.34%] [G loss: 0.839109]\n",
      "epoch:15 step:14255 [D loss: 0.727132, acc.: 47.66%] [G loss: 0.890591]\n",
      "epoch:15 step:14256 [D loss: 0.710594, acc.: 53.12%] [G loss: 0.844584]\n",
      "epoch:15 step:14257 [D loss: 0.699153, acc.: 49.22%] [G loss: 0.835218]\n",
      "epoch:15 step:14258 [D loss: 0.681772, acc.: 57.03%] [G loss: 0.849401]\n",
      "epoch:15 step:14259 [D loss: 0.568391, acc.: 67.97%] [G loss: 0.863779]\n",
      "epoch:15 step:14260 [D loss: 0.630698, acc.: 69.53%] [G loss: 0.863664]\n",
      "epoch:15 step:14261 [D loss: 0.607148, acc.: 68.75%] [G loss: 0.861343]\n",
      "epoch:15 step:14262 [D loss: 0.465233, acc.: 77.34%] [G loss: 0.859491]\n",
      "epoch:15 step:14263 [D loss: 0.638633, acc.: 69.53%] [G loss: 0.894727]\n",
      "epoch:15 step:14264 [D loss: 0.620202, acc.: 64.84%] [G loss: 0.788422]\n",
      "epoch:15 step:14265 [D loss: 0.687492, acc.: 52.34%] [G loss: 0.844061]\n",
      "epoch:15 step:14266 [D loss: 0.710014, acc.: 52.34%] [G loss: 0.806891]\n",
      "epoch:15 step:14267 [D loss: 0.669174, acc.: 61.72%] [G loss: 0.785349]\n",
      "epoch:15 step:14268 [D loss: 0.660021, acc.: 64.84%] [G loss: 0.790196]\n",
      "epoch:15 step:14269 [D loss: 0.705078, acc.: 53.91%] [G loss: 0.837009]\n",
      "epoch:15 step:14270 [D loss: 0.715962, acc.: 50.00%] [G loss: 0.838076]\n",
      "epoch:15 step:14271 [D loss: 0.537090, acc.: 74.22%] [G loss: 0.823062]\n",
      "epoch:15 step:14272 [D loss: 0.686189, acc.: 55.47%] [G loss: 0.725648]\n",
      "epoch:15 step:14273 [D loss: 0.665895, acc.: 57.03%] [G loss: 0.783190]\n",
      "epoch:15 step:14274 [D loss: 0.585928, acc.: 71.09%] [G loss: 0.827018]\n",
      "epoch:15 step:14275 [D loss: 0.684366, acc.: 53.12%] [G loss: 0.847675]\n",
      "epoch:15 step:14276 [D loss: 0.716548, acc.: 54.69%] [G loss: 0.796233]\n",
      "epoch:15 step:14277 [D loss: 0.636189, acc.: 60.94%] [G loss: 0.816380]\n",
      "epoch:15 step:14278 [D loss: 0.668587, acc.: 63.28%] [G loss: 0.795951]\n",
      "epoch:15 step:14279 [D loss: 0.746452, acc.: 44.53%] [G loss: 0.827974]\n",
      "epoch:15 step:14280 [D loss: 0.690867, acc.: 54.69%] [G loss: 0.794788]\n",
      "epoch:15 step:14281 [D loss: 0.693865, acc.: 56.25%] [G loss: 0.814338]\n",
      "epoch:15 step:14282 [D loss: 0.664847, acc.: 65.62%] [G loss: 0.797147]\n",
      "epoch:15 step:14283 [D loss: 0.678498, acc.: 57.81%] [G loss: 0.862188]\n",
      "epoch:15 step:14284 [D loss: 0.638368, acc.: 60.16%] [G loss: 0.808505]\n",
      "epoch:15 step:14285 [D loss: 0.593022, acc.: 64.84%] [G loss: 0.935992]\n",
      "epoch:15 step:14286 [D loss: 0.556518, acc.: 72.66%] [G loss: 0.983032]\n",
      "epoch:15 step:14287 [D loss: 0.570344, acc.: 71.09%] [G loss: 0.985175]\n",
      "epoch:15 step:14288 [D loss: 0.670966, acc.: 57.03%] [G loss: 0.959812]\n",
      "epoch:15 step:14289 [D loss: 0.621491, acc.: 66.41%] [G loss: 0.956316]\n",
      "epoch:15 step:14290 [D loss: 0.637217, acc.: 64.84%] [G loss: 0.866696]\n",
      "epoch:15 step:14291 [D loss: 0.700382, acc.: 50.78%] [G loss: 0.957859]\n",
      "epoch:15 step:14292 [D loss: 0.629240, acc.: 65.62%] [G loss: 0.944341]\n",
      "epoch:15 step:14293 [D loss: 0.701540, acc.: 56.25%] [G loss: 0.825094]\n",
      "epoch:15 step:14294 [D loss: 0.692377, acc.: 55.47%] [G loss: 0.817470]\n",
      "epoch:15 step:14295 [D loss: 0.785469, acc.: 36.72%] [G loss: 0.801799]\n",
      "epoch:15 step:14296 [D loss: 0.729732, acc.: 43.75%] [G loss: 0.803492]\n",
      "epoch:15 step:14297 [D loss: 0.742207, acc.: 41.41%] [G loss: 0.819118]\n",
      "epoch:15 step:14298 [D loss: 0.680219, acc.: 61.72%] [G loss: 0.846903]\n",
      "epoch:15 step:14299 [D loss: 0.671075, acc.: 54.69%] [G loss: 0.822792]\n",
      "epoch:15 step:14300 [D loss: 0.695041, acc.: 54.69%] [G loss: 0.775869]\n",
      "epoch:15 step:14301 [D loss: 0.711078, acc.: 53.12%] [G loss: 0.817158]\n",
      "epoch:15 step:14302 [D loss: 0.669177, acc.: 53.12%] [G loss: 0.773576]\n",
      "epoch:15 step:14303 [D loss: 0.637044, acc.: 66.41%] [G loss: 0.845871]\n",
      "epoch:15 step:14304 [D loss: 0.674447, acc.: 55.47%] [G loss: 0.822101]\n",
      "epoch:15 step:14305 [D loss: 0.676949, acc.: 60.94%] [G loss: 0.839297]\n",
      "epoch:15 step:14306 [D loss: 0.685536, acc.: 54.69%] [G loss: 0.871771]\n",
      "epoch:15 step:14307 [D loss: 0.693093, acc.: 55.47%] [G loss: 0.807263]\n",
      "epoch:15 step:14308 [D loss: 0.690343, acc.: 58.59%] [G loss: 0.801833]\n",
      "epoch:15 step:14309 [D loss: 0.700000, acc.: 53.91%] [G loss: 0.739201]\n",
      "epoch:15 step:14310 [D loss: 0.675047, acc.: 57.03%] [G loss: 0.761522]\n",
      "epoch:15 step:14311 [D loss: 0.690317, acc.: 55.47%] [G loss: 0.795579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14312 [D loss: 0.660284, acc.: 64.06%] [G loss: 0.818798]\n",
      "epoch:15 step:14313 [D loss: 0.708628, acc.: 53.12%] [G loss: 0.799661]\n",
      "epoch:15 step:14314 [D loss: 0.643884, acc.: 64.06%] [G loss: 0.773876]\n",
      "epoch:15 step:14315 [D loss: 0.654341, acc.: 61.72%] [G loss: 0.785855]\n",
      "epoch:15 step:14316 [D loss: 0.661804, acc.: 57.81%] [G loss: 0.739319]\n",
      "epoch:15 step:14317 [D loss: 0.649150, acc.: 64.06%] [G loss: 0.771066]\n",
      "epoch:15 step:14318 [D loss: 0.485375, acc.: 74.22%] [G loss: 0.872412]\n",
      "epoch:15 step:14319 [D loss: 0.685518, acc.: 53.91%] [G loss: 0.829572]\n",
      "epoch:15 step:14320 [D loss: 0.675667, acc.: 54.69%] [G loss: 0.804884]\n",
      "epoch:15 step:14321 [D loss: 0.715505, acc.: 46.09%] [G loss: 0.786992]\n",
      "epoch:15 step:14322 [D loss: 0.696970, acc.: 53.91%] [G loss: 0.790811]\n",
      "epoch:15 step:14323 [D loss: 0.672296, acc.: 58.59%] [G loss: 0.772215]\n",
      "epoch:15 step:14324 [D loss: 0.674825, acc.: 54.69%] [G loss: 0.797506]\n",
      "epoch:15 step:14325 [D loss: 0.681927, acc.: 53.91%] [G loss: 0.802477]\n",
      "epoch:15 step:14326 [D loss: 0.648724, acc.: 60.16%] [G loss: 0.825150]\n",
      "epoch:15 step:14327 [D loss: 0.671116, acc.: 58.59%] [G loss: 0.846060]\n",
      "epoch:15 step:14328 [D loss: 0.672319, acc.: 60.16%] [G loss: 0.749882]\n",
      "epoch:15 step:14329 [D loss: 0.694999, acc.: 54.69%] [G loss: 0.836406]\n",
      "epoch:15 step:14330 [D loss: 0.670172, acc.: 60.16%] [G loss: 0.844316]\n",
      "epoch:15 step:14331 [D loss: 0.629389, acc.: 61.72%] [G loss: 0.823146]\n",
      "epoch:15 step:14332 [D loss: 0.665254, acc.: 56.25%] [G loss: 0.878163]\n",
      "epoch:15 step:14333 [D loss: 0.715755, acc.: 49.22%] [G loss: 0.878991]\n",
      "epoch:15 step:14334 [D loss: 0.668032, acc.: 60.16%] [G loss: 0.794390]\n",
      "epoch:15 step:14335 [D loss: 0.654009, acc.: 62.50%] [G loss: 0.821413]\n",
      "epoch:15 step:14336 [D loss: 0.733986, acc.: 50.00%] [G loss: 0.821761]\n",
      "epoch:15 step:14337 [D loss: 0.714347, acc.: 45.31%] [G loss: 0.785866]\n",
      "epoch:15 step:14338 [D loss: 0.698688, acc.: 49.22%] [G loss: 0.779934]\n",
      "epoch:15 step:14339 [D loss: 0.674193, acc.: 55.47%] [G loss: 0.820095]\n",
      "epoch:15 step:14340 [D loss: 0.665175, acc.: 60.94%] [G loss: 0.797532]\n",
      "epoch:15 step:14341 [D loss: 0.657504, acc.: 67.19%] [G loss: 0.754721]\n",
      "epoch:15 step:14342 [D loss: 0.652511, acc.: 67.19%] [G loss: 0.806861]\n",
      "epoch:15 step:14343 [D loss: 0.649291, acc.: 57.81%] [G loss: 0.759864]\n",
      "epoch:15 step:14344 [D loss: 0.611905, acc.: 68.75%] [G loss: 0.744260]\n",
      "epoch:15 step:14345 [D loss: 0.637125, acc.: 64.84%] [G loss: 0.854427]\n",
      "epoch:15 step:14346 [D loss: 0.678809, acc.: 58.59%] [G loss: 0.746653]\n",
      "epoch:15 step:14347 [D loss: 0.649636, acc.: 59.38%] [G loss: 0.754308]\n",
      "epoch:15 step:14348 [D loss: 0.664966, acc.: 57.81%] [G loss: 0.781279]\n",
      "epoch:15 step:14349 [D loss: 0.733223, acc.: 50.00%] [G loss: 0.855106]\n",
      "epoch:15 step:14350 [D loss: 0.767129, acc.: 37.50%] [G loss: 0.910644]\n",
      "epoch:15 step:14351 [D loss: 0.769228, acc.: 32.81%] [G loss: 0.847506]\n",
      "epoch:15 step:14352 [D loss: 0.709355, acc.: 46.88%] [G loss: 0.857414]\n",
      "epoch:15 step:14353 [D loss: 0.713034, acc.: 49.22%] [G loss: 0.885184]\n",
      "epoch:15 step:14354 [D loss: 0.667224, acc.: 61.72%] [G loss: 0.898511]\n",
      "epoch:15 step:14355 [D loss: 0.654734, acc.: 57.81%] [G loss: 0.902147]\n",
      "epoch:15 step:14356 [D loss: 0.709437, acc.: 56.25%] [G loss: 0.846251]\n",
      "epoch:15 step:14357 [D loss: 0.672881, acc.: 59.38%] [G loss: 0.866383]\n",
      "epoch:15 step:14358 [D loss: 0.674006, acc.: 52.34%] [G loss: 0.966881]\n",
      "epoch:15 step:14359 [D loss: 0.641640, acc.: 65.62%] [G loss: 0.896222]\n",
      "epoch:15 step:14360 [D loss: 0.649461, acc.: 57.03%] [G loss: 0.865379]\n",
      "epoch:15 step:14361 [D loss: 0.734364, acc.: 44.53%] [G loss: 0.871358]\n",
      "epoch:15 step:14362 [D loss: 0.678904, acc.: 55.47%] [G loss: 0.811931]\n",
      "epoch:15 step:14363 [D loss: 0.726938, acc.: 50.00%] [G loss: 0.817261]\n",
      "epoch:15 step:14364 [D loss: 0.679030, acc.: 50.00%] [G loss: 0.796407]\n",
      "epoch:15 step:14365 [D loss: 0.643568, acc.: 67.19%] [G loss: 0.776072]\n",
      "epoch:15 step:14366 [D loss: 0.652498, acc.: 63.28%] [G loss: 0.800695]\n",
      "epoch:15 step:14367 [D loss: 0.665848, acc.: 60.16%] [G loss: 0.783042]\n",
      "epoch:15 step:14368 [D loss: 0.696440, acc.: 55.47%] [G loss: 0.824804]\n",
      "epoch:15 step:14369 [D loss: 0.621612, acc.: 71.88%] [G loss: 0.800643]\n",
      "epoch:15 step:14370 [D loss: 0.651300, acc.: 62.50%] [G loss: 0.868262]\n",
      "epoch:15 step:14371 [D loss: 0.671933, acc.: 57.03%] [G loss: 0.848335]\n",
      "epoch:15 step:14372 [D loss: 0.694680, acc.: 57.03%] [G loss: 0.820748]\n",
      "epoch:15 step:14373 [D loss: 0.655878, acc.: 62.50%] [G loss: 0.802561]\n",
      "epoch:15 step:14374 [D loss: 0.678951, acc.: 59.38%] [G loss: 0.839034]\n",
      "epoch:15 step:14375 [D loss: 0.680391, acc.: 57.81%] [G loss: 0.764467]\n",
      "epoch:15 step:14376 [D loss: 0.773268, acc.: 56.25%] [G loss: 0.763212]\n",
      "epoch:15 step:14377 [D loss: 0.655843, acc.: 60.16%] [G loss: 0.856813]\n",
      "epoch:15 step:14378 [D loss: 0.723002, acc.: 46.09%] [G loss: 1.146805]\n",
      "epoch:15 step:14379 [D loss: 0.708044, acc.: 57.03%] [G loss: 0.800570]\n",
      "epoch:15 step:14380 [D loss: 0.694713, acc.: 50.78%] [G loss: 0.766339]\n",
      "epoch:15 step:14381 [D loss: 0.691750, acc.: 54.69%] [G loss: 0.818538]\n",
      "epoch:15 step:14382 [D loss: 0.620194, acc.: 74.22%] [G loss: 0.823470]\n",
      "epoch:15 step:14383 [D loss: 0.613547, acc.: 71.09%] [G loss: 0.815244]\n",
      "epoch:15 step:14384 [D loss: 0.679038, acc.: 57.81%] [G loss: 0.784591]\n",
      "epoch:15 step:14385 [D loss: 0.749157, acc.: 43.75%] [G loss: 0.819021]\n",
      "epoch:15 step:14386 [D loss: 0.707773, acc.: 51.56%] [G loss: 0.803806]\n",
      "epoch:15 step:14387 [D loss: 0.734572, acc.: 48.44%] [G loss: 0.786754]\n",
      "epoch:15 step:14388 [D loss: 0.677080, acc.: 51.56%] [G loss: 0.700318]\n",
      "epoch:15 step:14389 [D loss: 0.724478, acc.: 43.75%] [G loss: 0.715627]\n",
      "epoch:15 step:14390 [D loss: 0.666361, acc.: 60.16%] [G loss: 0.780640]\n",
      "epoch:15 step:14391 [D loss: 0.678326, acc.: 59.38%] [G loss: 0.703966]\n",
      "epoch:15 step:14392 [D loss: 0.652052, acc.: 60.94%] [G loss: 0.791607]\n",
      "epoch:15 step:14393 [D loss: 0.673584, acc.: 57.81%] [G loss: 0.680948]\n",
      "epoch:15 step:14394 [D loss: 0.670410, acc.: 58.59%] [G loss: 0.795253]\n",
      "epoch:15 step:14395 [D loss: 0.691728, acc.: 60.16%] [G loss: 0.777405]\n",
      "epoch:15 step:14396 [D loss: 0.672818, acc.: 60.16%] [G loss: 0.765567]\n",
      "epoch:15 step:14397 [D loss: 0.673867, acc.: 60.16%] [G loss: 0.751996]\n",
      "epoch:15 step:14398 [D loss: 0.589338, acc.: 67.97%] [G loss: 0.756434]\n",
      "epoch:15 step:14399 [D loss: 0.575897, acc.: 75.78%] [G loss: 0.746432]\n",
      "epoch:15 step:14400 [D loss: 0.672414, acc.: 56.25%] [G loss: 0.724289]\n",
      "epoch:15 step:14401 [D loss: 0.614942, acc.: 66.41%] [G loss: 0.801098]\n",
      "epoch:15 step:14402 [D loss: 0.587470, acc.: 68.75%] [G loss: 0.726612]\n",
      "epoch:15 step:14403 [D loss: 0.686424, acc.: 59.38%] [G loss: 0.824076]\n",
      "epoch:15 step:14404 [D loss: 0.723366, acc.: 50.78%] [G loss: 0.708791]\n",
      "epoch:15 step:14405 [D loss: 0.644813, acc.: 60.16%] [G loss: 0.826645]\n",
      "epoch:15 step:14406 [D loss: 0.697219, acc.: 51.56%] [G loss: 0.793686]\n",
      "epoch:15 step:14407 [D loss: 0.745594, acc.: 42.97%] [G loss: 0.734441]\n",
      "epoch:15 step:14408 [D loss: 0.684100, acc.: 51.56%] [G loss: 0.847095]\n",
      "epoch:15 step:14409 [D loss: 0.667281, acc.: 58.59%] [G loss: 0.817517]\n",
      "epoch:15 step:14410 [D loss: 0.736526, acc.: 43.75%] [G loss: 0.813586]\n",
      "epoch:15 step:14411 [D loss: 0.683360, acc.: 57.03%] [G loss: 0.832008]\n",
      "epoch:15 step:14412 [D loss: 0.672823, acc.: 58.59%] [G loss: 0.812776]\n",
      "epoch:15 step:14413 [D loss: 0.647512, acc.: 62.50%] [G loss: 0.827420]\n",
      "epoch:15 step:14414 [D loss: 0.632553, acc.: 71.09%] [G loss: 0.888735]\n",
      "epoch:15 step:14415 [D loss: 0.643788, acc.: 60.16%] [G loss: 0.837195]\n",
      "epoch:15 step:14416 [D loss: 0.610184, acc.: 67.19%] [G loss: 0.838853]\n",
      "epoch:15 step:14417 [D loss: 0.686744, acc.: 56.25%] [G loss: 0.826057]\n",
      "epoch:15 step:14418 [D loss: 0.681650, acc.: 55.47%] [G loss: 0.848746]\n",
      "epoch:15 step:14419 [D loss: 0.671811, acc.: 53.91%] [G loss: 0.810181]\n",
      "epoch:15 step:14420 [D loss: 0.711914, acc.: 48.44%] [G loss: 0.797639]\n",
      "epoch:15 step:14421 [D loss: 0.684206, acc.: 54.69%] [G loss: 0.772598]\n",
      "epoch:15 step:14422 [D loss: 0.652336, acc.: 62.50%] [G loss: 0.784290]\n",
      "epoch:15 step:14423 [D loss: 0.690299, acc.: 57.81%] [G loss: 0.728357]\n",
      "epoch:15 step:14424 [D loss: 0.686554, acc.: 50.00%] [G loss: 0.745398]\n",
      "epoch:15 step:14425 [D loss: 0.683021, acc.: 57.81%] [G loss: 0.783187]\n",
      "epoch:15 step:14426 [D loss: 0.597436, acc.: 66.41%] [G loss: 0.782724]\n",
      "epoch:15 step:14427 [D loss: 0.658837, acc.: 62.50%] [G loss: 0.784588]\n",
      "epoch:15 step:14428 [D loss: 0.691996, acc.: 51.56%] [G loss: 0.827083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14429 [D loss: 0.692075, acc.: 53.91%] [G loss: 0.774699]\n",
      "epoch:15 step:14430 [D loss: 0.678510, acc.: 54.69%] [G loss: 0.778415]\n",
      "epoch:15 step:14431 [D loss: 0.659745, acc.: 59.38%] [G loss: 0.697300]\n",
      "epoch:15 step:14432 [D loss: 0.656911, acc.: 60.94%] [G loss: 0.862296]\n",
      "epoch:15 step:14433 [D loss: 0.658413, acc.: 62.50%] [G loss: 0.756596]\n",
      "epoch:15 step:14434 [D loss: 0.714444, acc.: 53.91%] [G loss: 0.684894]\n",
      "epoch:15 step:14435 [D loss: 0.638361, acc.: 62.50%] [G loss: 0.756214]\n",
      "epoch:15 step:14436 [D loss: 0.660193, acc.: 59.38%] [G loss: 0.793761]\n",
      "epoch:15 step:14437 [D loss: 0.665805, acc.: 63.28%] [G loss: 0.706251]\n",
      "epoch:15 step:14438 [D loss: 0.738198, acc.: 46.09%] [G loss: 0.785068]\n",
      "epoch:15 step:14439 [D loss: 0.727993, acc.: 41.41%] [G loss: 0.770100]\n",
      "epoch:15 step:14440 [D loss: 0.680635, acc.: 57.03%] [G loss: 0.819848]\n",
      "epoch:15 step:14441 [D loss: 0.651786, acc.: 64.84%] [G loss: 0.772807]\n",
      "epoch:15 step:14442 [D loss: 0.654136, acc.: 64.06%] [G loss: 0.776763]\n",
      "epoch:15 step:14443 [D loss: 0.658412, acc.: 61.72%] [G loss: 0.791195]\n",
      "epoch:15 step:14444 [D loss: 0.697464, acc.: 54.69%] [G loss: 0.840153]\n",
      "epoch:15 step:14445 [D loss: 0.681164, acc.: 57.03%] [G loss: 0.836522]\n",
      "epoch:15 step:14446 [D loss: 0.687454, acc.: 61.72%] [G loss: 0.784014]\n",
      "epoch:15 step:14447 [D loss: 0.672162, acc.: 59.38%] [G loss: 0.723699]\n",
      "epoch:15 step:14448 [D loss: 0.687796, acc.: 54.69%] [G loss: 0.814122]\n",
      "epoch:15 step:14449 [D loss: 0.678959, acc.: 57.81%] [G loss: 0.774943]\n",
      "epoch:15 step:14450 [D loss: 0.710625, acc.: 48.44%] [G loss: 0.822156]\n",
      "epoch:15 step:14451 [D loss: 0.648234, acc.: 63.28%] [G loss: 0.741069]\n",
      "epoch:15 step:14452 [D loss: 0.591999, acc.: 67.97%] [G loss: 0.824039]\n",
      "epoch:15 step:14453 [D loss: 0.524470, acc.: 76.56%] [G loss: 0.822754]\n",
      "epoch:15 step:14454 [D loss: 0.509530, acc.: 75.00%] [G loss: 0.824336]\n",
      "epoch:15 step:14455 [D loss: 0.589524, acc.: 67.97%] [G loss: 0.832954]\n",
      "epoch:15 step:14456 [D loss: 0.572366, acc.: 73.44%] [G loss: 0.730986]\n",
      "epoch:15 step:14457 [D loss: 0.564887, acc.: 72.66%] [G loss: 0.780913]\n",
      "epoch:15 step:14458 [D loss: 0.657507, acc.: 56.25%] [G loss: 0.975012]\n",
      "epoch:15 step:14459 [D loss: 0.523053, acc.: 76.56%] [G loss: 0.646966]\n",
      "epoch:15 step:14460 [D loss: 0.623626, acc.: 64.84%] [G loss: 0.947172]\n",
      "epoch:15 step:14461 [D loss: 0.613016, acc.: 60.16%] [G loss: 0.835125]\n",
      "epoch:15 step:14462 [D loss: 0.555410, acc.: 74.22%] [G loss: 0.887346]\n",
      "epoch:15 step:14463 [D loss: 0.728133, acc.: 56.25%] [G loss: 0.839443]\n",
      "epoch:15 step:14464 [D loss: 0.700340, acc.: 53.91%] [G loss: 0.808142]\n",
      "epoch:15 step:14465 [D loss: 0.741337, acc.: 39.84%] [G loss: 0.916140]\n",
      "epoch:15 step:14466 [D loss: 0.854964, acc.: 32.03%] [G loss: 0.809061]\n",
      "epoch:15 step:14467 [D loss: 0.764122, acc.: 46.88%] [G loss: 0.893010]\n",
      "epoch:15 step:14468 [D loss: 0.739435, acc.: 49.22%] [G loss: 0.753697]\n",
      "epoch:15 step:14469 [D loss: 0.653094, acc.: 62.50%] [G loss: 0.836781]\n",
      "epoch:15 step:14470 [D loss: 0.696368, acc.: 53.91%] [G loss: 0.786805]\n",
      "epoch:15 step:14471 [D loss: 0.700320, acc.: 55.47%] [G loss: 1.000417]\n",
      "epoch:15 step:14472 [D loss: 0.686576, acc.: 53.91%] [G loss: 0.849713]\n",
      "epoch:15 step:14473 [D loss: 0.684948, acc.: 60.94%] [G loss: 0.840750]\n",
      "epoch:15 step:14474 [D loss: 0.686760, acc.: 59.38%] [G loss: 0.893398]\n",
      "epoch:15 step:14475 [D loss: 0.692442, acc.: 54.69%] [G loss: 0.771509]\n",
      "epoch:15 step:14476 [D loss: 0.725958, acc.: 40.62%] [G loss: 0.738623]\n",
      "epoch:15 step:14477 [D loss: 0.711874, acc.: 39.84%] [G loss: 0.886953]\n",
      "epoch:15 step:14478 [D loss: 0.710764, acc.: 51.56%] [G loss: 0.823666]\n",
      "epoch:15 step:14479 [D loss: 0.670056, acc.: 59.38%] [G loss: 0.867600]\n",
      "epoch:15 step:14480 [D loss: 0.682931, acc.: 54.69%] [G loss: 0.800267]\n",
      "epoch:15 step:14481 [D loss: 0.686806, acc.: 51.56%] [G loss: 0.818222]\n",
      "epoch:15 step:14482 [D loss: 0.695928, acc.: 50.78%] [G loss: 0.783290]\n",
      "epoch:15 step:14483 [D loss: 0.665083, acc.: 64.06%] [G loss: 0.784538]\n",
      "epoch:15 step:14484 [D loss: 0.661647, acc.: 60.16%] [G loss: 0.788599]\n",
      "epoch:15 step:14485 [D loss: 0.672096, acc.: 60.94%] [G loss: 0.805553]\n",
      "epoch:15 step:14486 [D loss: 0.697531, acc.: 55.47%] [G loss: 0.865790]\n",
      "epoch:15 step:14487 [D loss: 0.709186, acc.: 47.66%] [G loss: 0.834834]\n",
      "epoch:15 step:14488 [D loss: 0.626644, acc.: 60.94%] [G loss: 0.931446]\n",
      "epoch:15 step:14489 [D loss: 0.686345, acc.: 54.69%] [G loss: 0.876568]\n",
      "epoch:15 step:14490 [D loss: 0.666422, acc.: 55.47%] [G loss: 0.856951]\n",
      "epoch:15 step:14491 [D loss: 0.619074, acc.: 67.97%] [G loss: 0.877705]\n",
      "epoch:15 step:14492 [D loss: 0.710938, acc.: 46.88%] [G loss: 0.815256]\n",
      "epoch:15 step:14493 [D loss: 0.681697, acc.: 54.69%] [G loss: 0.870958]\n",
      "epoch:15 step:14494 [D loss: 0.687053, acc.: 53.91%] [G loss: 0.877891]\n",
      "epoch:15 step:14495 [D loss: 0.683796, acc.: 53.91%] [G loss: 0.876936]\n",
      "epoch:15 step:14496 [D loss: 0.683953, acc.: 60.16%] [G loss: 0.872356]\n",
      "epoch:15 step:14497 [D loss: 0.630564, acc.: 70.31%] [G loss: 0.982999]\n",
      "epoch:15 step:14498 [D loss: 0.628105, acc.: 63.28%] [G loss: 0.844751]\n",
      "epoch:15 step:14499 [D loss: 0.641574, acc.: 65.62%] [G loss: 0.844661]\n",
      "epoch:15 step:14500 [D loss: 0.636847, acc.: 61.72%] [G loss: 0.901452]\n",
      "epoch:15 step:14501 [D loss: 0.668147, acc.: 57.03%] [G loss: 0.792738]\n",
      "epoch:15 step:14502 [D loss: 0.653397, acc.: 59.38%] [G loss: 0.752394]\n",
      "epoch:15 step:14503 [D loss: 0.610665, acc.: 67.97%] [G loss: 0.853111]\n",
      "epoch:15 step:14504 [D loss: 0.629829, acc.: 66.41%] [G loss: 0.880231]\n",
      "epoch:15 step:14505 [D loss: 0.608110, acc.: 64.06%] [G loss: 0.936481]\n",
      "epoch:15 step:14506 [D loss: 0.558281, acc.: 71.88%] [G loss: 0.905063]\n",
      "epoch:15 step:14507 [D loss: 0.539251, acc.: 75.78%] [G loss: 0.781791]\n",
      "epoch:15 step:14508 [D loss: 0.561662, acc.: 73.44%] [G loss: 1.104232]\n",
      "epoch:15 step:14509 [D loss: 0.634136, acc.: 62.50%] [G loss: 0.861407]\n",
      "epoch:15 step:14510 [D loss: 0.612376, acc.: 64.84%] [G loss: 1.037125]\n",
      "epoch:15 step:14511 [D loss: 0.365875, acc.: 86.72%] [G loss: 1.006656]\n",
      "epoch:15 step:14512 [D loss: 0.567573, acc.: 75.78%] [G loss: 1.117304]\n",
      "epoch:15 step:14513 [D loss: 0.857419, acc.: 35.16%] [G loss: 0.819548]\n",
      "epoch:15 step:14514 [D loss: 0.731305, acc.: 47.66%] [G loss: 0.864045]\n",
      "epoch:15 step:14515 [D loss: 0.792245, acc.: 40.62%] [G loss: 0.800937]\n",
      "epoch:15 step:14516 [D loss: 0.832443, acc.: 24.22%] [G loss: 0.719744]\n",
      "epoch:15 step:14517 [D loss: 0.812068, acc.: 35.16%] [G loss: 0.799464]\n",
      "epoch:15 step:14518 [D loss: 0.751254, acc.: 38.28%] [G loss: 0.795946]\n",
      "epoch:15 step:14519 [D loss: 0.667230, acc.: 59.38%] [G loss: 0.799241]\n",
      "epoch:15 step:14520 [D loss: 0.696265, acc.: 53.91%] [G loss: 0.827648]\n",
      "epoch:15 step:14521 [D loss: 0.693469, acc.: 56.25%] [G loss: 0.757627]\n",
      "epoch:15 step:14522 [D loss: 0.672008, acc.: 61.72%] [G loss: 0.791420]\n",
      "epoch:15 step:14523 [D loss: 0.665794, acc.: 58.59%] [G loss: 0.831956]\n",
      "epoch:15 step:14524 [D loss: 0.679478, acc.: 53.91%] [G loss: 0.839131]\n",
      "epoch:15 step:14525 [D loss: 0.662734, acc.: 57.03%] [G loss: 0.921479]\n",
      "epoch:15 step:14526 [D loss: 0.639832, acc.: 64.06%] [G loss: 1.087276]\n",
      "epoch:15 step:14527 [D loss: 0.630166, acc.: 69.53%] [G loss: 1.031365]\n",
      "epoch:15 step:14528 [D loss: 0.703760, acc.: 49.22%] [G loss: 0.900681]\n",
      "epoch:15 step:14529 [D loss: 0.679120, acc.: 55.47%] [G loss: 0.897806]\n",
      "epoch:15 step:14530 [D loss: 0.630433, acc.: 64.84%] [G loss: 0.989424]\n",
      "epoch:15 step:14531 [D loss: 0.689050, acc.: 60.16%] [G loss: 0.937118]\n",
      "epoch:15 step:14532 [D loss: 0.736355, acc.: 57.03%] [G loss: 0.903983]\n",
      "epoch:15 step:14533 [D loss: 0.682869, acc.: 53.91%] [G loss: 0.898892]\n",
      "epoch:15 step:14534 [D loss: 0.694746, acc.: 57.03%] [G loss: 0.841884]\n",
      "epoch:15 step:14535 [D loss: 0.702049, acc.: 61.72%] [G loss: 0.771915]\n",
      "epoch:15 step:14536 [D loss: 0.677598, acc.: 62.50%] [G loss: 0.773166]\n",
      "epoch:15 step:14537 [D loss: 0.670558, acc.: 57.81%] [G loss: 0.771617]\n",
      "epoch:15 step:14538 [D loss: 0.643366, acc.: 58.59%] [G loss: 0.776408]\n",
      "epoch:15 step:14539 [D loss: 0.641061, acc.: 66.41%] [G loss: 0.786827]\n",
      "epoch:15 step:14540 [D loss: 0.646039, acc.: 62.50%] [G loss: 0.794325]\n",
      "epoch:15 step:14541 [D loss: 0.624672, acc.: 66.41%] [G loss: 0.833840]\n",
      "epoch:15 step:14542 [D loss: 0.664241, acc.: 56.25%] [G loss: 0.852845]\n",
      "epoch:15 step:14543 [D loss: 0.642796, acc.: 60.94%] [G loss: 0.920955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14544 [D loss: 0.685407, acc.: 55.47%] [G loss: 0.812482]\n",
      "epoch:15 step:14545 [D loss: 0.700350, acc.: 54.69%] [G loss: 0.806957]\n",
      "epoch:15 step:14546 [D loss: 0.666596, acc.: 57.03%] [G loss: 0.839802]\n",
      "epoch:15 step:14547 [D loss: 0.730632, acc.: 51.56%] [G loss: 0.739332]\n",
      "epoch:15 step:14548 [D loss: 0.674831, acc.: 56.25%] [G loss: 0.718302]\n",
      "epoch:15 step:14549 [D loss: 0.640959, acc.: 64.84%] [G loss: 0.780680]\n",
      "epoch:15 step:14550 [D loss: 0.684522, acc.: 55.47%] [G loss: 0.801135]\n",
      "epoch:15 step:14551 [D loss: 0.661330, acc.: 66.41%] [G loss: 0.897130]\n",
      "epoch:15 step:14552 [D loss: 0.626837, acc.: 67.19%] [G loss: 0.812515]\n",
      "epoch:15 step:14553 [D loss: 0.637043, acc.: 58.59%] [G loss: 0.815626]\n",
      "epoch:15 step:14554 [D loss: 0.575070, acc.: 70.31%] [G loss: 0.885002]\n",
      "epoch:15 step:14555 [D loss: 0.651048, acc.: 61.72%] [G loss: 0.857473]\n",
      "epoch:15 step:14556 [D loss: 0.675895, acc.: 56.25%] [G loss: 0.772901]\n",
      "epoch:15 step:14557 [D loss: 0.689449, acc.: 55.47%] [G loss: 0.881500]\n",
      "epoch:15 step:14558 [D loss: 0.760340, acc.: 49.22%] [G loss: 0.921810]\n",
      "epoch:15 step:14559 [D loss: 0.682593, acc.: 61.72%] [G loss: 0.928224]\n",
      "epoch:15 step:14560 [D loss: 0.642031, acc.: 60.94%] [G loss: 0.894843]\n",
      "epoch:15 step:14561 [D loss: 0.671716, acc.: 57.03%] [G loss: 0.853714]\n",
      "epoch:15 step:14562 [D loss: 0.614090, acc.: 69.53%] [G loss: 0.893831]\n",
      "epoch:15 step:14563 [D loss: 0.627117, acc.: 64.84%] [G loss: 0.835724]\n",
      "epoch:15 step:14564 [D loss: 0.679687, acc.: 57.03%] [G loss: 0.838369]\n",
      "epoch:15 step:14565 [D loss: 0.748011, acc.: 44.53%] [G loss: 0.820801]\n",
      "epoch:15 step:14566 [D loss: 0.715815, acc.: 47.66%] [G loss: 0.761836]\n",
      "epoch:15 step:14567 [D loss: 0.650035, acc.: 56.25%] [G loss: 0.793302]\n",
      "epoch:15 step:14568 [D loss: 0.633564, acc.: 62.50%] [G loss: 0.837281]\n",
      "epoch:15 step:14569 [D loss: 0.617330, acc.: 64.06%] [G loss: 0.848541]\n",
      "epoch:15 step:14570 [D loss: 0.675735, acc.: 57.03%] [G loss: 0.783897]\n",
      "epoch:15 step:14571 [D loss: 0.631920, acc.: 64.06%] [G loss: 0.843208]\n",
      "epoch:15 step:14572 [D loss: 0.692104, acc.: 54.69%] [G loss: 0.914616]\n",
      "epoch:15 step:14573 [D loss: 0.674355, acc.: 50.78%] [G loss: 0.784889]\n",
      "epoch:15 step:14574 [D loss: 0.690082, acc.: 53.12%] [G loss: 0.802611]\n",
      "epoch:15 step:14575 [D loss: 0.638045, acc.: 62.50%] [G loss: 0.807526]\n",
      "epoch:15 step:14576 [D loss: 0.658319, acc.: 62.50%] [G loss: 0.721389]\n",
      "epoch:15 step:14577 [D loss: 0.732348, acc.: 46.88%] [G loss: 0.741677]\n",
      "epoch:15 step:14578 [D loss: 0.732184, acc.: 49.22%] [G loss: 0.850093]\n",
      "epoch:15 step:14579 [D loss: 0.638819, acc.: 63.28%] [G loss: 0.835521]\n",
      "epoch:15 step:14580 [D loss: 0.674804, acc.: 57.81%] [G loss: 0.896748]\n",
      "epoch:15 step:14581 [D loss: 0.683173, acc.: 58.59%] [G loss: 0.813212]\n",
      "epoch:15 step:14582 [D loss: 0.700172, acc.: 50.00%] [G loss: 0.790820]\n",
      "epoch:15 step:14583 [D loss: 0.747988, acc.: 46.09%] [G loss: 0.800862]\n",
      "epoch:15 step:14584 [D loss: 0.699192, acc.: 52.34%] [G loss: 0.759357]\n",
      "epoch:15 step:14585 [D loss: 0.654644, acc.: 60.16%] [G loss: 0.822761]\n",
      "epoch:15 step:14586 [D loss: 0.704141, acc.: 51.56%] [G loss: 0.805463]\n",
      "epoch:15 step:14587 [D loss: 0.667349, acc.: 57.81%] [G loss: 0.768981]\n",
      "epoch:15 step:14588 [D loss: 0.635065, acc.: 68.75%] [G loss: 0.837640]\n",
      "epoch:15 step:14589 [D loss: 0.631522, acc.: 65.62%] [G loss: 0.856814]\n",
      "epoch:15 step:14590 [D loss: 0.677361, acc.: 57.81%] [G loss: 0.880523]\n",
      "epoch:15 step:14591 [D loss: 0.693635, acc.: 50.78%] [G loss: 0.863555]\n",
      "epoch:15 step:14592 [D loss: 0.689512, acc.: 56.25%] [G loss: 0.860361]\n",
      "epoch:15 step:14593 [D loss: 0.649627, acc.: 64.06%] [G loss: 0.853598]\n",
      "epoch:15 step:14594 [D loss: 0.683941, acc.: 53.91%] [G loss: 0.831560]\n",
      "epoch:15 step:14595 [D loss: 0.649354, acc.: 60.94%] [G loss: 0.846225]\n",
      "epoch:15 step:14596 [D loss: 0.638057, acc.: 65.62%] [G loss: 0.796951]\n",
      "epoch:15 step:14597 [D loss: 0.595792, acc.: 71.09%] [G loss: 0.871544]\n",
      "epoch:15 step:14598 [D loss: 0.451615, acc.: 75.00%] [G loss: 0.899554]\n",
      "epoch:15 step:14599 [D loss: 0.627848, acc.: 64.84%] [G loss: 0.873345]\n",
      "epoch:15 step:14600 [D loss: 0.590952, acc.: 70.31%] [G loss: 0.780196]\n",
      "epoch:15 step:14601 [D loss: 0.656770, acc.: 63.28%] [G loss: 0.934821]\n",
      "epoch:15 step:14602 [D loss: 0.658056, acc.: 60.94%] [G loss: 0.808934]\n",
      "epoch:15 step:14603 [D loss: 0.637792, acc.: 61.72%] [G loss: 0.767058]\n",
      "epoch:15 step:14604 [D loss: 0.584769, acc.: 75.78%] [G loss: 0.789076]\n",
      "epoch:15 step:14605 [D loss: 0.369505, acc.: 85.16%] [G loss: 1.006642]\n",
      "epoch:15 step:14606 [D loss: 0.548385, acc.: 77.34%] [G loss: 1.075397]\n",
      "epoch:15 step:14607 [D loss: 0.622785, acc.: 66.41%] [G loss: 0.932363]\n",
      "epoch:15 step:14608 [D loss: 0.662564, acc.: 60.16%] [G loss: 0.963651]\n",
      "epoch:15 step:14609 [D loss: 0.495708, acc.: 82.81%] [G loss: 0.946028]\n",
      "epoch:15 step:14610 [D loss: 0.651801, acc.: 57.03%] [G loss: 0.972716]\n",
      "epoch:15 step:14611 [D loss: 0.635843, acc.: 64.06%] [G loss: 1.038821]\n",
      "epoch:15 step:14612 [D loss: 0.686449, acc.: 58.59%] [G loss: 0.885585]\n",
      "epoch:15 step:14613 [D loss: 0.622129, acc.: 66.41%] [G loss: 1.007584]\n",
      "epoch:15 step:14614 [D loss: 0.890641, acc.: 31.25%] [G loss: 0.920792]\n",
      "epoch:15 step:14615 [D loss: 0.724607, acc.: 46.88%] [G loss: 0.992500]\n",
      "epoch:15 step:14616 [D loss: 0.676837, acc.: 57.81%] [G loss: 0.934851]\n",
      "epoch:15 step:14617 [D loss: 0.728265, acc.: 49.22%] [G loss: 0.808687]\n",
      "epoch:15 step:14618 [D loss: 0.660072, acc.: 61.72%] [G loss: 0.749452]\n",
      "epoch:15 step:14619 [D loss: 0.678291, acc.: 52.34%] [G loss: 0.773615]\n",
      "epoch:15 step:14620 [D loss: 0.727122, acc.: 47.66%] [G loss: 0.841268]\n",
      "epoch:15 step:14621 [D loss: 0.672428, acc.: 57.81%] [G loss: 0.879579]\n",
      "epoch:15 step:14622 [D loss: 0.642634, acc.: 63.28%] [G loss: 0.945751]\n",
      "epoch:15 step:14623 [D loss: 0.624925, acc.: 64.84%] [G loss: 1.206026]\n",
      "epoch:15 step:14624 [D loss: 0.728088, acc.: 53.91%] [G loss: 1.015273]\n",
      "epoch:15 step:14625 [D loss: 0.686165, acc.: 61.72%] [G loss: 1.012296]\n",
      "epoch:15 step:14626 [D loss: 0.654040, acc.: 62.50%] [G loss: 0.893159]\n",
      "epoch:15 step:14627 [D loss: 0.625217, acc.: 69.53%] [G loss: 0.854081]\n",
      "epoch:15 step:14628 [D loss: 0.599486, acc.: 70.31%] [G loss: 0.963902]\n",
      "epoch:15 step:14629 [D loss: 0.576522, acc.: 67.97%] [G loss: 0.809036]\n",
      "epoch:15 step:14630 [D loss: 0.599002, acc.: 65.62%] [G loss: 0.912404]\n",
      "epoch:15 step:14631 [D loss: 0.644800, acc.: 61.72%] [G loss: 0.771663]\n",
      "epoch:15 step:14632 [D loss: 0.625915, acc.: 64.84%] [G loss: 0.896993]\n",
      "epoch:15 step:14633 [D loss: 0.610629, acc.: 68.75%] [G loss: 0.879230]\n",
      "epoch:15 step:14634 [D loss: 0.704141, acc.: 54.69%] [G loss: 0.762172]\n",
      "epoch:15 step:14635 [D loss: 0.731349, acc.: 48.44%] [G loss: 0.849446]\n",
      "epoch:15 step:14636 [D loss: 0.687528, acc.: 57.81%] [G loss: 0.768221]\n",
      "epoch:15 step:14637 [D loss: 0.707101, acc.: 45.31%] [G loss: 0.874733]\n",
      "epoch:15 step:14638 [D loss: 0.793680, acc.: 36.72%] [G loss: 0.861533]\n",
      "epoch:15 step:14639 [D loss: 0.721783, acc.: 48.44%] [G loss: 0.863191]\n",
      "epoch:15 step:14640 [D loss: 0.665771, acc.: 50.00%] [G loss: 0.964998]\n",
      "epoch:15 step:14641 [D loss: 0.626016, acc.: 58.59%] [G loss: 0.946609]\n",
      "epoch:15 step:14642 [D loss: 0.608415, acc.: 71.09%] [G loss: 0.870292]\n",
      "epoch:15 step:14643 [D loss: 0.597730, acc.: 68.75%] [G loss: 0.933996]\n",
      "epoch:15 step:14644 [D loss: 0.568695, acc.: 75.78%] [G loss: 0.924911]\n",
      "epoch:15 step:14645 [D loss: 0.624691, acc.: 64.84%] [G loss: 0.910367]\n",
      "epoch:15 step:14646 [D loss: 0.657526, acc.: 60.16%] [G loss: 0.947164]\n",
      "epoch:15 step:14647 [D loss: 0.693377, acc.: 51.56%] [G loss: 0.881500]\n",
      "epoch:15 step:14648 [D loss: 0.677840, acc.: 53.12%] [G loss: 0.895372]\n",
      "epoch:15 step:14649 [D loss: 0.697742, acc.: 52.34%] [G loss: 0.909590]\n",
      "epoch:15 step:14650 [D loss: 0.632127, acc.: 62.50%] [G loss: 0.785658]\n",
      "epoch:15 step:14651 [D loss: 0.617795, acc.: 65.62%] [G loss: 0.806991]\n",
      "epoch:15 step:14652 [D loss: 0.706148, acc.: 48.44%] [G loss: 0.841258]\n",
      "epoch:15 step:14653 [D loss: 0.636354, acc.: 63.28%] [G loss: 0.789796]\n",
      "epoch:15 step:14654 [D loss: 0.721907, acc.: 53.12%] [G loss: 0.741809]\n",
      "epoch:15 step:14655 [D loss: 0.664371, acc.: 61.72%] [G loss: 0.780124]\n",
      "epoch:15 step:14656 [D loss: 0.680577, acc.: 53.12%] [G loss: 0.845535]\n",
      "epoch:15 step:14657 [D loss: 0.659846, acc.: 58.59%] [G loss: 0.860329]\n",
      "epoch:15 step:14658 [D loss: 0.680822, acc.: 53.91%] [G loss: 0.874170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14659 [D loss: 0.401477, acc.: 83.59%] [G loss: 0.844224]\n",
      "epoch:15 step:14660 [D loss: 0.644606, acc.: 63.28%] [G loss: 1.016302]\n",
      "epoch:15 step:14661 [D loss: 0.666372, acc.: 58.59%] [G loss: 0.927998]\n",
      "epoch:15 step:14662 [D loss: 0.665810, acc.: 64.06%] [G loss: 0.903070]\n",
      "epoch:15 step:14663 [D loss: 0.692105, acc.: 56.25%] [G loss: 0.829857]\n",
      "epoch:15 step:14664 [D loss: 0.629277, acc.: 60.94%] [G loss: 0.917817]\n",
      "epoch:15 step:14665 [D loss: 0.709730, acc.: 49.22%] [G loss: 0.871444]\n",
      "epoch:15 step:14666 [D loss: 0.639644, acc.: 65.62%] [G loss: 0.815916]\n",
      "epoch:15 step:14667 [D loss: 0.612556, acc.: 68.75%] [G loss: 0.781933]\n",
      "epoch:15 step:14668 [D loss: 0.649777, acc.: 57.81%] [G loss: 0.817981]\n",
      "epoch:15 step:14669 [D loss: 0.735476, acc.: 44.53%] [G loss: 0.798219]\n",
      "epoch:15 step:14670 [D loss: 0.674253, acc.: 57.03%] [G loss: 0.860435]\n",
      "epoch:15 step:14671 [D loss: 0.674391, acc.: 55.47%] [G loss: 0.925134]\n",
      "epoch:15 step:14672 [D loss: 0.671891, acc.: 57.03%] [G loss: 0.839789]\n",
      "epoch:15 step:14673 [D loss: 0.638923, acc.: 60.94%] [G loss: 0.878503]\n",
      "epoch:15 step:14674 [D loss: 0.624863, acc.: 65.62%] [G loss: 0.956542]\n",
      "epoch:15 step:14675 [D loss: 0.693157, acc.: 57.03%] [G loss: 0.768088]\n",
      "epoch:15 step:14676 [D loss: 0.705795, acc.: 57.03%] [G loss: 0.836426]\n",
      "epoch:15 step:14677 [D loss: 0.727829, acc.: 47.66%] [G loss: 0.878170]\n",
      "epoch:15 step:14678 [D loss: 0.655085, acc.: 62.50%] [G loss: 0.970292]\n",
      "epoch:15 step:14679 [D loss: 0.611479, acc.: 68.75%] [G loss: 0.962351]\n",
      "epoch:15 step:14680 [D loss: 0.671406, acc.: 60.16%] [G loss: 0.933074]\n",
      "epoch:15 step:14681 [D loss: 0.650701, acc.: 56.25%] [G loss: 0.905611]\n",
      "epoch:15 step:14682 [D loss: 0.665701, acc.: 57.03%] [G loss: 0.825228]\n",
      "epoch:15 step:14683 [D loss: 0.641505, acc.: 64.06%] [G loss: 0.872495]\n",
      "epoch:15 step:14684 [D loss: 0.662024, acc.: 53.91%] [G loss: 0.860629]\n",
      "epoch:15 step:14685 [D loss: 0.690242, acc.: 51.56%] [G loss: 0.650023]\n",
      "epoch:15 step:14686 [D loss: 0.692445, acc.: 53.12%] [G loss: 0.710789]\n",
      "epoch:15 step:14687 [D loss: 0.740957, acc.: 50.00%] [G loss: 0.642608]\n",
      "epoch:15 step:14688 [D loss: 0.690464, acc.: 53.12%] [G loss: 0.711843]\n",
      "epoch:15 step:14689 [D loss: 0.754258, acc.: 45.31%] [G loss: 0.722336]\n",
      "epoch:15 step:14690 [D loss: 0.682114, acc.: 57.03%] [G loss: 0.768498]\n",
      "epoch:15 step:14691 [D loss: 0.663859, acc.: 59.38%] [G loss: 0.794335]\n",
      "epoch:15 step:14692 [D loss: 0.701757, acc.: 48.44%] [G loss: 0.838948]\n",
      "epoch:15 step:14693 [D loss: 0.668133, acc.: 63.28%] [G loss: 0.856121]\n",
      "epoch:15 step:14694 [D loss: 0.692771, acc.: 50.78%] [G loss: 0.896430]\n",
      "epoch:15 step:14695 [D loss: 0.694680, acc.: 51.56%] [G loss: 0.838687]\n",
      "epoch:15 step:14696 [D loss: 0.660651, acc.: 54.69%] [G loss: 0.903296]\n",
      "epoch:15 step:14697 [D loss: 0.647966, acc.: 59.38%] [G loss: 0.926175]\n",
      "epoch:15 step:14698 [D loss: 0.692048, acc.: 59.38%] [G loss: 0.876214]\n",
      "epoch:15 step:14699 [D loss: 0.632555, acc.: 65.62%] [G loss: 0.892160]\n",
      "epoch:15 step:14700 [D loss: 0.669731, acc.: 56.25%] [G loss: 0.875278]\n",
      "epoch:15 step:14701 [D loss: 0.675661, acc.: 62.50%] [G loss: 0.840012]\n",
      "epoch:15 step:14702 [D loss: 0.679096, acc.: 60.16%] [G loss: 0.793931]\n",
      "epoch:15 step:14703 [D loss: 0.642475, acc.: 64.06%] [G loss: 0.815501]\n",
      "epoch:15 step:14704 [D loss: 0.667748, acc.: 58.59%] [G loss: 0.806761]\n",
      "epoch:15 step:14705 [D loss: 0.616178, acc.: 67.19%] [G loss: 0.821073]\n",
      "epoch:15 step:14706 [D loss: 0.621988, acc.: 63.28%] [G loss: 0.865587]\n",
      "epoch:15 step:14707 [D loss: 0.676804, acc.: 55.47%] [G loss: 0.827368]\n",
      "epoch:15 step:14708 [D loss: 0.669705, acc.: 54.69%] [G loss: 0.779723]\n",
      "epoch:15 step:14709 [D loss: 0.683483, acc.: 59.38%] [G loss: 0.828855]\n",
      "epoch:15 step:14710 [D loss: 0.707496, acc.: 55.47%] [G loss: 0.713338]\n",
      "epoch:15 step:14711 [D loss: 0.655892, acc.: 60.94%] [G loss: 0.850831]\n",
      "epoch:15 step:14712 [D loss: 0.718808, acc.: 49.22%] [G loss: 0.775774]\n",
      "epoch:15 step:14713 [D loss: 0.702224, acc.: 48.44%] [G loss: 0.719207]\n",
      "epoch:15 step:14714 [D loss: 0.649512, acc.: 63.28%] [G loss: 0.748791]\n",
      "epoch:15 step:14715 [D loss: 0.621731, acc.: 75.00%] [G loss: 0.800982]\n",
      "epoch:15 step:14716 [D loss: 0.654414, acc.: 64.84%] [G loss: 0.782991]\n",
      "epoch:15 step:14717 [D loss: 0.712819, acc.: 51.56%] [G loss: 0.822370]\n",
      "epoch:15 step:14718 [D loss: 0.697347, acc.: 51.56%] [G loss: 0.807291]\n",
      "epoch:15 step:14719 [D loss: 0.624682, acc.: 67.19%] [G loss: 0.836703]\n",
      "epoch:15 step:14720 [D loss: 0.616142, acc.: 60.16%] [G loss: 0.846857]\n",
      "epoch:15 step:14721 [D loss: 0.671536, acc.: 57.03%] [G loss: 0.907747]\n",
      "epoch:15 step:14722 [D loss: 0.659581, acc.: 59.38%] [G loss: 0.832306]\n",
      "epoch:15 step:14723 [D loss: 0.684282, acc.: 60.16%] [G loss: 0.851033]\n",
      "epoch:15 step:14724 [D loss: 0.668135, acc.: 55.47%] [G loss: 0.786865]\n",
      "epoch:15 step:14725 [D loss: 0.713379, acc.: 50.78%] [G loss: 0.828404]\n",
      "epoch:15 step:14726 [D loss: 0.661123, acc.: 62.50%] [G loss: 0.750699]\n",
      "epoch:15 step:14727 [D loss: 0.690337, acc.: 52.34%] [G loss: 0.807334]\n",
      "epoch:15 step:14728 [D loss: 0.676225, acc.: 62.50%] [G loss: 0.793702]\n",
      "epoch:15 step:14729 [D loss: 0.633470, acc.: 61.72%] [G loss: 0.822398]\n",
      "epoch:15 step:14730 [D loss: 0.730613, acc.: 44.53%] [G loss: 0.760204]\n",
      "epoch:15 step:14731 [D loss: 0.726226, acc.: 45.31%] [G loss: 0.716340]\n",
      "epoch:15 step:14732 [D loss: 0.710518, acc.: 42.97%] [G loss: 0.761845]\n",
      "epoch:15 step:14733 [D loss: 0.696420, acc.: 52.34%] [G loss: 0.801480]\n",
      "epoch:15 step:14734 [D loss: 0.653700, acc.: 58.59%] [G loss: 0.746229]\n",
      "epoch:15 step:14735 [D loss: 0.640017, acc.: 67.19%] [G loss: 0.801423]\n",
      "epoch:15 step:14736 [D loss: 0.659175, acc.: 57.03%] [G loss: 0.832463]\n",
      "epoch:15 step:14737 [D loss: 0.625528, acc.: 66.41%] [G loss: 0.789986]\n",
      "epoch:15 step:14738 [D loss: 0.653951, acc.: 62.50%] [G loss: 0.780704]\n",
      "epoch:15 step:14739 [D loss: 0.596758, acc.: 70.31%] [G loss: 0.719067]\n",
      "epoch:15 step:14740 [D loss: 0.692526, acc.: 56.25%] [G loss: 0.854732]\n",
      "epoch:15 step:14741 [D loss: 0.590924, acc.: 70.31%] [G loss: 0.848754]\n",
      "epoch:15 step:14742 [D loss: 0.675151, acc.: 57.03%] [G loss: 0.850271]\n",
      "epoch:15 step:14743 [D loss: 0.721909, acc.: 50.00%] [G loss: 0.788837]\n",
      "epoch:15 step:14744 [D loss: 0.730810, acc.: 49.22%] [G loss: 0.771864]\n",
      "epoch:15 step:14745 [D loss: 0.782622, acc.: 36.72%] [G loss: 0.827032]\n",
      "epoch:15 step:14746 [D loss: 0.694163, acc.: 60.16%] [G loss: 0.794494]\n",
      "epoch:15 step:14747 [D loss: 0.690361, acc.: 58.59%] [G loss: 0.796945]\n",
      "epoch:15 step:14748 [D loss: 0.653940, acc.: 60.94%] [G loss: 0.837068]\n",
      "epoch:15 step:14749 [D loss: 0.648703, acc.: 60.16%] [G loss: 0.827918]\n",
      "epoch:15 step:14750 [D loss: 0.698975, acc.: 50.00%] [G loss: 0.804258]\n",
      "epoch:15 step:14751 [D loss: 0.614197, acc.: 67.97%] [G loss: 0.832394]\n",
      "epoch:15 step:14752 [D loss: 0.613115, acc.: 67.97%] [G loss: 0.803184]\n",
      "epoch:15 step:14753 [D loss: 0.625334, acc.: 70.31%] [G loss: 0.850448]\n",
      "epoch:15 step:14754 [D loss: 0.689768, acc.: 53.91%] [G loss: 0.904417]\n",
      "epoch:15 step:14755 [D loss: 0.655862, acc.: 61.72%] [G loss: 0.850361]\n",
      "epoch:15 step:14756 [D loss: 0.667106, acc.: 59.38%] [G loss: 0.880359]\n",
      "epoch:15 step:14757 [D loss: 0.657909, acc.: 60.94%] [G loss: 0.848887]\n",
      "epoch:15 step:14758 [D loss: 0.639795, acc.: 60.16%] [G loss: 0.763634]\n",
      "epoch:15 step:14759 [D loss: 0.664236, acc.: 62.50%] [G loss: 0.892777]\n",
      "epoch:15 step:14760 [D loss: 0.705878, acc.: 52.34%] [G loss: 0.827246]\n",
      "epoch:15 step:14761 [D loss: 0.641403, acc.: 64.06%] [G loss: 0.760519]\n",
      "epoch:15 step:14762 [D loss: 0.587942, acc.: 72.66%] [G loss: 0.825797]\n",
      "epoch:15 step:14763 [D loss: 0.642721, acc.: 66.41%] [G loss: 0.860389]\n",
      "epoch:15 step:14764 [D loss: 0.574608, acc.: 75.78%] [G loss: 0.795982]\n",
      "epoch:15 step:14765 [D loss: 0.682938, acc.: 57.81%] [G loss: 0.799592]\n",
      "epoch:15 step:14766 [D loss: 0.662319, acc.: 60.94%] [G loss: 0.892306]\n",
      "epoch:15 step:14767 [D loss: 0.676788, acc.: 57.81%] [G loss: 0.870901]\n",
      "epoch:15 step:14768 [D loss: 0.641661, acc.: 63.28%] [G loss: 0.875295]\n",
      "epoch:15 step:14769 [D loss: 0.586058, acc.: 70.31%] [G loss: 0.767992]\n",
      "epoch:15 step:14770 [D loss: 0.684827, acc.: 49.22%] [G loss: 0.938024]\n",
      "epoch:15 step:14771 [D loss: 0.782743, acc.: 35.94%] [G loss: 0.944150]\n",
      "epoch:15 step:14772 [D loss: 0.693778, acc.: 57.03%] [G loss: 0.882226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14773 [D loss: 0.698318, acc.: 50.00%] [G loss: 0.799440]\n",
      "epoch:15 step:14774 [D loss: 0.672563, acc.: 54.69%] [G loss: 0.856725]\n",
      "epoch:15 step:14775 [D loss: 0.588766, acc.: 72.66%] [G loss: 0.956011]\n",
      "epoch:15 step:14776 [D loss: 0.612142, acc.: 67.19%] [G loss: 0.844740]\n",
      "epoch:15 step:14777 [D loss: 0.710376, acc.: 53.91%] [G loss: 0.904048]\n",
      "epoch:15 step:14778 [D loss: 0.689371, acc.: 57.03%] [G loss: 0.924991]\n",
      "epoch:15 step:14779 [D loss: 0.590715, acc.: 69.53%] [G loss: 0.960580]\n",
      "epoch:15 step:14780 [D loss: 0.602657, acc.: 69.53%] [G loss: 0.986028]\n",
      "epoch:15 step:14781 [D loss: 0.613956, acc.: 64.06%] [G loss: 0.873884]\n",
      "epoch:15 step:14782 [D loss: 0.752155, acc.: 53.12%] [G loss: 0.859074]\n",
      "epoch:15 step:14783 [D loss: 0.777172, acc.: 40.62%] [G loss: 0.847137]\n",
      "epoch:15 step:14784 [D loss: 0.763694, acc.: 50.00%] [G loss: 0.770777]\n",
      "epoch:15 step:14785 [D loss: 0.758915, acc.: 46.09%] [G loss: 0.878056]\n",
      "epoch:15 step:14786 [D loss: 0.666758, acc.: 62.50%] [G loss: 0.800685]\n",
      "epoch:15 step:14787 [D loss: 0.654384, acc.: 64.06%] [G loss: 0.736518]\n",
      "epoch:15 step:14788 [D loss: 0.641934, acc.: 67.19%] [G loss: 0.899007]\n",
      "epoch:15 step:14789 [D loss: 0.677679, acc.: 58.59%] [G loss: 0.829508]\n",
      "epoch:15 step:14790 [D loss: 0.602190, acc.: 67.19%] [G loss: 0.832777]\n",
      "epoch:15 step:14791 [D loss: 0.613287, acc.: 69.53%] [G loss: 0.770486]\n",
      "epoch:15 step:14792 [D loss: 0.667729, acc.: 56.25%] [G loss: 0.960441]\n",
      "epoch:15 step:14793 [D loss: 0.693309, acc.: 52.34%] [G loss: 0.741681]\n",
      "epoch:15 step:14794 [D loss: 0.737978, acc.: 52.34%] [G loss: 0.830936]\n",
      "epoch:15 step:14795 [D loss: 0.683814, acc.: 48.44%] [G loss: 0.710353]\n",
      "epoch:15 step:14796 [D loss: 0.655668, acc.: 57.81%] [G loss: 0.793903]\n",
      "epoch:15 step:14797 [D loss: 0.680424, acc.: 57.03%] [G loss: 0.801069]\n",
      "epoch:15 step:14798 [D loss: 0.614875, acc.: 68.75%] [G loss: 0.793013]\n",
      "epoch:15 step:14799 [D loss: 0.695395, acc.: 54.69%] [G loss: 0.705031]\n",
      "epoch:15 step:14800 [D loss: 0.709437, acc.: 53.91%] [G loss: 0.803705]\n",
      "epoch:15 step:14801 [D loss: 0.687195, acc.: 53.91%] [G loss: 0.809597]\n",
      "epoch:15 step:14802 [D loss: 0.679242, acc.: 60.16%] [G loss: 0.758446]\n",
      "epoch:15 step:14803 [D loss: 1.379616, acc.: 32.03%] [G loss: 0.880091]\n",
      "epoch:15 step:14804 [D loss: 0.654501, acc.: 57.81%] [G loss: 0.955559]\n",
      "epoch:15 step:14805 [D loss: 0.695264, acc.: 55.47%] [G loss: 1.014480]\n",
      "epoch:15 step:14806 [D loss: 0.676533, acc.: 57.03%] [G loss: 0.907477]\n",
      "epoch:15 step:14807 [D loss: 0.693004, acc.: 64.06%] [G loss: 0.945375]\n",
      "epoch:15 step:14808 [D loss: 0.700365, acc.: 58.59%] [G loss: 0.906622]\n",
      "epoch:15 step:14809 [D loss: 0.644583, acc.: 67.19%] [G loss: 0.780144]\n",
      "epoch:15 step:14810 [D loss: 0.599081, acc.: 67.97%] [G loss: 0.872231]\n",
      "epoch:15 step:14811 [D loss: 0.627088, acc.: 67.19%] [G loss: 0.778891]\n",
      "epoch:15 step:14812 [D loss: 0.631703, acc.: 60.16%] [G loss: 0.774045]\n",
      "epoch:15 step:14813 [D loss: 0.668651, acc.: 54.69%] [G loss: 0.807027]\n",
      "epoch:15 step:14814 [D loss: 0.794454, acc.: 47.66%] [G loss: 0.796519]\n",
      "epoch:15 step:14815 [D loss: 0.805803, acc.: 32.03%] [G loss: 0.690926]\n",
      "epoch:15 step:14816 [D loss: 0.681143, acc.: 55.47%] [G loss: 0.756560]\n",
      "epoch:15 step:14817 [D loss: 0.647815, acc.: 58.59%] [G loss: 0.796616]\n",
      "epoch:15 step:14818 [D loss: 0.671895, acc.: 60.16%] [G loss: 0.734614]\n",
      "epoch:15 step:14819 [D loss: 0.606386, acc.: 71.88%] [G loss: 0.720650]\n",
      "epoch:15 step:14820 [D loss: 0.742279, acc.: 44.53%] [G loss: 0.701958]\n",
      "epoch:15 step:14821 [D loss: 0.698382, acc.: 52.34%] [G loss: 0.839869]\n",
      "epoch:15 step:14822 [D loss: 0.703546, acc.: 51.56%] [G loss: 0.860450]\n",
      "epoch:15 step:14823 [D loss: 0.702971, acc.: 53.91%] [G loss: 0.724248]\n",
      "epoch:15 step:14824 [D loss: 0.722435, acc.: 44.53%] [G loss: 0.812000]\n",
      "epoch:15 step:14825 [D loss: 0.682629, acc.: 46.09%] [G loss: 0.789663]\n",
      "epoch:15 step:14826 [D loss: 0.694407, acc.: 52.34%] [G loss: 0.811948]\n",
      "epoch:15 step:14827 [D loss: 0.674138, acc.: 53.12%] [G loss: 0.768162]\n",
      "epoch:15 step:14828 [D loss: 0.675328, acc.: 57.03%] [G loss: 0.697321]\n",
      "epoch:15 step:14829 [D loss: 0.646037, acc.: 57.81%] [G loss: 0.732933]\n",
      "epoch:15 step:14830 [D loss: 0.644026, acc.: 60.16%] [G loss: 0.770668]\n",
      "epoch:15 step:14831 [D loss: 0.683478, acc.: 55.47%] [G loss: 0.894957]\n",
      "epoch:15 step:14832 [D loss: 0.675704, acc.: 55.47%] [G loss: 0.868726]\n",
      "epoch:15 step:14833 [D loss: 0.702360, acc.: 53.91%] [G loss: 0.823774]\n",
      "epoch:15 step:14834 [D loss: 0.712627, acc.: 51.56%] [G loss: 0.825989]\n",
      "epoch:15 step:14835 [D loss: 0.680838, acc.: 56.25%] [G loss: 0.812973]\n",
      "epoch:15 step:14836 [D loss: 0.660037, acc.: 64.06%] [G loss: 0.794278]\n",
      "epoch:15 step:14837 [D loss: 0.659859, acc.: 57.81%] [G loss: 0.844568]\n",
      "epoch:15 step:14838 [D loss: 0.689106, acc.: 59.38%] [G loss: 0.829980]\n",
      "epoch:15 step:14839 [D loss: 0.713626, acc.: 50.78%] [G loss: 0.849003]\n",
      "epoch:15 step:14840 [D loss: 0.688906, acc.: 56.25%] [G loss: 0.773049]\n",
      "epoch:15 step:14841 [D loss: 0.689497, acc.: 59.38%] [G loss: 0.791182]\n",
      "epoch:15 step:14842 [D loss: 0.708163, acc.: 50.78%] [G loss: 0.800084]\n",
      "epoch:15 step:14843 [D loss: 0.697034, acc.: 53.91%] [G loss: 0.777460]\n",
      "epoch:15 step:14844 [D loss: 0.710353, acc.: 50.78%] [G loss: 0.828715]\n",
      "epoch:15 step:14845 [D loss: 0.693885, acc.: 48.44%] [G loss: 0.858818]\n",
      "epoch:15 step:14846 [D loss: 0.675822, acc.: 58.59%] [G loss: 0.778121]\n",
      "epoch:15 step:14847 [D loss: 0.662810, acc.: 57.03%] [G loss: 0.733655]\n",
      "epoch:15 step:14848 [D loss: 0.673967, acc.: 57.81%] [G loss: 0.780583]\n",
      "epoch:15 step:14849 [D loss: 0.659374, acc.: 63.28%] [G loss: 0.782839]\n",
      "epoch:15 step:14850 [D loss: 0.689180, acc.: 57.03%] [G loss: 0.755633]\n",
      "epoch:15 step:14851 [D loss: 0.633426, acc.: 65.62%] [G loss: 0.774512]\n",
      "epoch:15 step:14852 [D loss: 0.691773, acc.: 59.38%] [G loss: 0.735115]\n",
      "epoch:15 step:14853 [D loss: 0.704701, acc.: 50.78%] [G loss: 0.757405]\n",
      "epoch:15 step:14854 [D loss: 0.679567, acc.: 53.91%] [G loss: 0.740072]\n",
      "epoch:15 step:14855 [D loss: 0.660187, acc.: 53.91%] [G loss: 0.719130]\n",
      "epoch:15 step:14856 [D loss: 0.634051, acc.: 60.94%] [G loss: 0.735535]\n",
      "epoch:15 step:14857 [D loss: 0.520606, acc.: 67.19%] [G loss: 0.807663]\n",
      "epoch:15 step:14858 [D loss: 0.701971, acc.: 50.00%] [G loss: 0.789407]\n",
      "epoch:15 step:14859 [D loss: 0.707110, acc.: 50.00%] [G loss: 0.783374]\n",
      "epoch:15 step:14860 [D loss: 0.661600, acc.: 58.59%] [G loss: 0.773387]\n",
      "epoch:15 step:14861 [D loss: 0.656279, acc.: 64.84%] [G loss: 0.817948]\n",
      "epoch:15 step:14862 [D loss: 0.695582, acc.: 52.34%] [G loss: 0.796860]\n",
      "epoch:15 step:14863 [D loss: 0.634657, acc.: 61.72%] [G loss: 0.584507]\n",
      "epoch:15 step:14864 [D loss: 0.655154, acc.: 63.28%] [G loss: 0.811316]\n",
      "epoch:15 step:14865 [D loss: 0.633825, acc.: 59.38%] [G loss: 0.629379]\n",
      "epoch:15 step:14866 [D loss: 0.770202, acc.: 43.75%] [G loss: 0.700507]\n",
      "epoch:15 step:14867 [D loss: 0.694111, acc.: 49.22%] [G loss: 0.824401]\n",
      "epoch:15 step:14868 [D loss: 0.770330, acc.: 46.09%] [G loss: 0.763052]\n",
      "epoch:15 step:14869 [D loss: 0.664376, acc.: 64.06%] [G loss: 0.766668]\n",
      "epoch:15 step:14870 [D loss: 0.564593, acc.: 78.12%] [G loss: 0.819488]\n",
      "epoch:15 step:14871 [D loss: 0.640367, acc.: 64.84%] [G loss: 0.777312]\n",
      "epoch:15 step:14872 [D loss: 0.686626, acc.: 53.91%] [G loss: 0.778816]\n",
      "epoch:15 step:14873 [D loss: 0.657909, acc.: 60.16%] [G loss: 0.740123]\n",
      "epoch:15 step:14874 [D loss: 0.711153, acc.: 47.66%] [G loss: 0.810618]\n",
      "epoch:15 step:14875 [D loss: 0.711866, acc.: 52.34%] [G loss: 0.809576]\n",
      "epoch:15 step:14876 [D loss: 0.696675, acc.: 57.03%] [G loss: 0.865393]\n",
      "epoch:15 step:14877 [D loss: 0.700715, acc.: 55.47%] [G loss: 0.831350]\n",
      "epoch:15 step:14878 [D loss: 0.673499, acc.: 57.81%] [G loss: 0.814016]\n",
      "epoch:15 step:14879 [D loss: 0.703168, acc.: 53.91%] [G loss: 0.883003]\n",
      "epoch:15 step:14880 [D loss: 0.657797, acc.: 59.38%] [G loss: 0.888892]\n",
      "epoch:15 step:14881 [D loss: 0.637596, acc.: 61.72%] [G loss: 0.826358]\n",
      "epoch:15 step:14882 [D loss: 0.685545, acc.: 52.34%] [G loss: 0.825834]\n",
      "epoch:15 step:14883 [D loss: 0.660208, acc.: 57.03%] [G loss: 0.822767]\n",
      "epoch:15 step:14884 [D loss: 0.655950, acc.: 60.16%] [G loss: 0.787881]\n",
      "epoch:15 step:14885 [D loss: 0.681815, acc.: 57.81%] [G loss: 0.804113]\n",
      "epoch:15 step:14886 [D loss: 0.680422, acc.: 57.03%] [G loss: 0.932021]\n",
      "epoch:15 step:14887 [D loss: 0.649646, acc.: 60.94%] [G loss: 0.823159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14888 [D loss: 0.677968, acc.: 55.47%] [G loss: 0.941710]\n",
      "epoch:15 step:14889 [D loss: 0.679805, acc.: 53.12%] [G loss: 0.752946]\n",
      "epoch:15 step:14890 [D loss: 0.704328, acc.: 44.53%] [G loss: 0.743346]\n",
      "epoch:15 step:14891 [D loss: 0.700522, acc.: 48.44%] [G loss: 0.752811]\n",
      "epoch:15 step:14892 [D loss: 0.711246, acc.: 53.91%] [G loss: 0.753245]\n",
      "epoch:15 step:14893 [D loss: 0.697296, acc.: 51.56%] [G loss: 0.765019]\n",
      "epoch:15 step:14894 [D loss: 0.672172, acc.: 53.12%] [G loss: 0.805779]\n",
      "epoch:15 step:14895 [D loss: 0.681792, acc.: 57.81%] [G loss: 0.751463]\n",
      "epoch:15 step:14896 [D loss: 0.637018, acc.: 64.84%] [G loss: 0.772306]\n",
      "epoch:15 step:14897 [D loss: 0.653390, acc.: 59.38%] [G loss: 0.790371]\n",
      "epoch:15 step:14898 [D loss: 0.715254, acc.: 42.97%] [G loss: 0.771680]\n",
      "epoch:15 step:14899 [D loss: 0.703707, acc.: 50.00%] [G loss: 0.741901]\n",
      "epoch:15 step:14900 [D loss: 0.675826, acc.: 57.81%] [G loss: 0.759498]\n",
      "epoch:15 step:14901 [D loss: 0.687654, acc.: 55.47%] [G loss: 0.764514]\n",
      "epoch:15 step:14902 [D loss: 0.681080, acc.: 54.69%] [G loss: 0.779414]\n",
      "epoch:15 step:14903 [D loss: 0.683092, acc.: 50.00%] [G loss: 0.784201]\n",
      "epoch:15 step:14904 [D loss: 0.676949, acc.: 56.25%] [G loss: 0.716240]\n",
      "epoch:15 step:14905 [D loss: 0.675056, acc.: 60.16%] [G loss: 0.720655]\n",
      "epoch:15 step:14906 [D loss: 0.605101, acc.: 69.53%] [G loss: 0.795259]\n",
      "epoch:15 step:14907 [D loss: 0.620918, acc.: 66.41%] [G loss: 0.798380]\n",
      "epoch:15 step:14908 [D loss: 0.592187, acc.: 74.22%] [G loss: 0.771184]\n",
      "epoch:15 step:14909 [D loss: 0.597079, acc.: 66.41%] [G loss: 0.792715]\n",
      "epoch:15 step:14910 [D loss: 0.707459, acc.: 48.44%] [G loss: 0.782242]\n",
      "epoch:15 step:14911 [D loss: 0.700709, acc.: 55.47%] [G loss: 0.772189]\n",
      "epoch:15 step:14912 [D loss: 0.624872, acc.: 60.16%] [G loss: 0.780808]\n",
      "epoch:15 step:14913 [D loss: 0.748294, acc.: 35.16%] [G loss: 0.750666]\n",
      "epoch:15 step:14914 [D loss: 0.707091, acc.: 50.00%] [G loss: 0.768124]\n",
      "epoch:15 step:14915 [D loss: 0.653137, acc.: 60.94%] [G loss: 0.755424]\n",
      "epoch:15 step:14916 [D loss: 0.722580, acc.: 43.75%] [G loss: 0.781497]\n",
      "epoch:15 step:14917 [D loss: 0.679279, acc.: 49.22%] [G loss: 0.799877]\n",
      "epoch:15 step:14918 [D loss: 0.679336, acc.: 50.00%] [G loss: 0.776491]\n",
      "epoch:15 step:14919 [D loss: 0.690798, acc.: 52.34%] [G loss: 0.884572]\n",
      "epoch:15 step:14920 [D loss: 0.704962, acc.: 46.88%] [G loss: 0.839250]\n",
      "epoch:15 step:14921 [D loss: 0.691707, acc.: 49.22%] [G loss: 0.808793]\n",
      "epoch:15 step:14922 [D loss: 0.678615, acc.: 57.81%] [G loss: 0.858046]\n",
      "epoch:15 step:14923 [D loss: 0.712252, acc.: 45.31%] [G loss: 0.811177]\n",
      "epoch:15 step:14924 [D loss: 0.646851, acc.: 62.50%] [G loss: 0.845617]\n",
      "epoch:15 step:14925 [D loss: 0.661618, acc.: 53.12%] [G loss: 0.826623]\n",
      "epoch:15 step:14926 [D loss: 0.681349, acc.: 57.03%] [G loss: 0.889011]\n",
      "epoch:15 step:14927 [D loss: 0.678470, acc.: 59.38%] [G loss: 0.864934]\n",
      "epoch:15 step:14928 [D loss: 0.684211, acc.: 55.47%] [G loss: 0.814752]\n",
      "epoch:15 step:14929 [D loss: 0.721393, acc.: 50.78%] [G loss: 0.806091]\n",
      "epoch:15 step:14930 [D loss: 0.659721, acc.: 59.38%] [G loss: 0.816220]\n",
      "epoch:15 step:14931 [D loss: 0.643766, acc.: 61.72%] [G loss: 0.829219]\n",
      "epoch:15 step:14932 [D loss: 0.580273, acc.: 70.31%] [G loss: 0.812232]\n",
      "epoch:15 step:14933 [D loss: 0.520552, acc.: 78.91%] [G loss: 0.898972]\n",
      "epoch:15 step:14934 [D loss: 0.687061, acc.: 48.44%] [G loss: 0.859428]\n",
      "epoch:15 step:14935 [D loss: 0.715622, acc.: 47.66%] [G loss: 0.860399]\n",
      "epoch:15 step:14936 [D loss: 0.741047, acc.: 46.09%] [G loss: 0.772814]\n",
      "epoch:15 step:14937 [D loss: 0.735888, acc.: 39.06%] [G loss: 0.686601]\n",
      "epoch:15 step:14938 [D loss: 0.734091, acc.: 44.53%] [G loss: 0.884925]\n",
      "epoch:15 step:14939 [D loss: 0.696363, acc.: 55.47%] [G loss: 0.745543]\n",
      "epoch:15 step:14940 [D loss: 0.697628, acc.: 50.78%] [G loss: 0.770259]\n",
      "epoch:15 step:14941 [D loss: 0.680923, acc.: 55.47%] [G loss: 0.787896]\n",
      "epoch:15 step:14942 [D loss: 0.715644, acc.: 43.75%] [G loss: 0.784932]\n",
      "epoch:15 step:14943 [D loss: 0.704841, acc.: 46.09%] [G loss: 0.754894]\n",
      "epoch:15 step:14944 [D loss: 0.682725, acc.: 58.59%] [G loss: 0.764456]\n",
      "epoch:15 step:14945 [D loss: 0.680859, acc.: 59.38%] [G loss: 0.778464]\n",
      "epoch:15 step:14946 [D loss: 0.704700, acc.: 50.00%] [G loss: 0.770326]\n",
      "epoch:15 step:14947 [D loss: 0.623178, acc.: 67.19%] [G loss: 0.736308]\n",
      "epoch:15 step:14948 [D loss: 0.602205, acc.: 69.53%] [G loss: 0.749305]\n",
      "epoch:15 step:14949 [D loss: 0.690718, acc.: 52.34%] [G loss: 0.689569]\n",
      "epoch:15 step:14950 [D loss: 0.704755, acc.: 46.88%] [G loss: 0.788904]\n",
      "epoch:15 step:14951 [D loss: 0.662100, acc.: 57.03%] [G loss: 0.759313]\n",
      "epoch:15 step:14952 [D loss: 0.632112, acc.: 64.84%] [G loss: 0.828228]\n",
      "epoch:15 step:14953 [D loss: 0.666542, acc.: 60.16%] [G loss: 0.745679]\n",
      "epoch:15 step:14954 [D loss: 0.559146, acc.: 67.97%] [G loss: 0.829432]\n",
      "epoch:15 step:14955 [D loss: 0.601170, acc.: 66.41%] [G loss: 0.705582]\n",
      "epoch:15 step:14956 [D loss: 0.711277, acc.: 50.00%] [G loss: 0.864139]\n",
      "epoch:15 step:14957 [D loss: 0.717690, acc.: 55.47%] [G loss: 0.846568]\n",
      "epoch:15 step:14958 [D loss: 0.699429, acc.: 53.12%] [G loss: 0.851037]\n",
      "epoch:15 step:14959 [D loss: 0.710136, acc.: 54.69%] [G loss: 0.798273]\n",
      "epoch:15 step:14960 [D loss: 0.662425, acc.: 60.94%] [G loss: 0.860886]\n",
      "epoch:15 step:14961 [D loss: 0.677826, acc.: 60.94%] [G loss: 0.797128]\n",
      "epoch:15 step:14962 [D loss: 0.711728, acc.: 40.62%] [G loss: 0.847300]\n",
      "epoch:15 step:14963 [D loss: 0.725005, acc.: 47.66%] [G loss: 0.788972]\n",
      "epoch:15 step:14964 [D loss: 0.681154, acc.: 56.25%] [G loss: 0.838374]\n",
      "epoch:15 step:14965 [D loss: 0.668054, acc.: 62.50%] [G loss: 0.849160]\n",
      "epoch:15 step:14966 [D loss: 0.667329, acc.: 60.16%] [G loss: 0.829013]\n",
      "epoch:15 step:14967 [D loss: 0.410747, acc.: 86.72%] [G loss: 0.821781]\n",
      "epoch:15 step:14968 [D loss: 0.695948, acc.: 57.03%] [G loss: 0.840768]\n",
      "epoch:15 step:14969 [D loss: 0.680350, acc.: 57.81%] [G loss: 0.858348]\n",
      "epoch:15 step:14970 [D loss: 0.722510, acc.: 51.56%] [G loss: 0.769622]\n",
      "epoch:15 step:14971 [D loss: 0.669516, acc.: 70.31%] [G loss: 0.781588]\n",
      "epoch:15 step:14972 [D loss: 0.617020, acc.: 71.88%] [G loss: 0.810538]\n",
      "epoch:15 step:14973 [D loss: 0.654570, acc.: 62.50%] [G loss: 0.735137]\n",
      "epoch:15 step:14974 [D loss: 0.656872, acc.: 64.06%] [G loss: 0.747894]\n",
      "epoch:15 step:14975 [D loss: 0.593640, acc.: 71.88%] [G loss: 0.756293]\n",
      "epoch:15 step:14976 [D loss: 0.559346, acc.: 70.31%] [G loss: 0.796800]\n",
      "epoch:15 step:14977 [D loss: 0.619536, acc.: 73.44%] [G loss: 0.779396]\n",
      "epoch:15 step:14978 [D loss: 0.644588, acc.: 63.28%] [G loss: 0.764085]\n",
      "epoch:15 step:14979 [D loss: 0.610066, acc.: 63.28%] [G loss: 0.755375]\n",
      "epoch:15 step:14980 [D loss: 0.598723, acc.: 67.97%] [G loss: 0.822137]\n",
      "epoch:15 step:14981 [D loss: 0.466702, acc.: 70.31%] [G loss: 0.777436]\n",
      "epoch:15 step:14982 [D loss: 0.360584, acc.: 83.59%] [G loss: 0.864274]\n",
      "epoch:15 step:14983 [D loss: 0.661252, acc.: 66.41%] [G loss: 0.641853]\n",
      "epoch:15 step:14984 [D loss: 0.505072, acc.: 84.38%] [G loss: 0.761167]\n",
      "epoch:15 step:14985 [D loss: 0.573713, acc.: 74.22%] [G loss: 0.896430]\n",
      "epoch:15 step:14986 [D loss: 0.605678, acc.: 68.75%] [G loss: 0.882344]\n",
      "epoch:15 step:14987 [D loss: 0.830972, acc.: 33.59%] [G loss: 0.920234]\n",
      "epoch:15 step:14988 [D loss: 0.519136, acc.: 79.69%] [G loss: 0.841474]\n",
      "epoch:15 step:14989 [D loss: 0.586934, acc.: 70.31%] [G loss: 0.630273]\n",
      "epoch:15 step:14990 [D loss: 0.568140, acc.: 75.00%] [G loss: 0.859406]\n",
      "epoch:15 step:14991 [D loss: 0.716650, acc.: 62.50%] [G loss: 0.879457]\n",
      "epoch:15 step:14992 [D loss: 0.463822, acc.: 74.22%] [G loss: 1.390288]\n",
      "epoch:16 step:14993 [D loss: 0.674506, acc.: 49.22%] [G loss: 1.853543]\n",
      "epoch:16 step:14994 [D loss: 0.775984, acc.: 52.34%] [G loss: 1.276404]\n",
      "epoch:16 step:14995 [D loss: 0.676623, acc.: 55.47%] [G loss: 1.152117]\n",
      "epoch:16 step:14996 [D loss: 0.694293, acc.: 53.91%] [G loss: 1.014216]\n",
      "epoch:16 step:14997 [D loss: 0.736507, acc.: 49.22%] [G loss: 1.041369]\n",
      "epoch:16 step:14998 [D loss: 0.744952, acc.: 50.78%] [G loss: 0.969953]\n",
      "epoch:16 step:14999 [D loss: 0.708857, acc.: 45.31%] [G loss: 0.927103]\n",
      "epoch:16 step:15000 [D loss: 0.707501, acc.: 47.66%] [G loss: 0.900507]\n",
      "epoch:16 step:15001 [D loss: 0.679460, acc.: 53.91%] [G loss: 0.936137]\n",
      "epoch:16 step:15002 [D loss: 0.645159, acc.: 59.38%] [G loss: 0.955284]\n",
      "epoch:16 step:15003 [D loss: 0.693061, acc.: 54.69%] [G loss: 0.868384]\n",
      "epoch:16 step:15004 [D loss: 0.676249, acc.: 57.03%] [G loss: 0.852472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15005 [D loss: 0.668479, acc.: 57.81%] [G loss: 0.837204]\n",
      "epoch:16 step:15006 [D loss: 0.658782, acc.: 61.72%] [G loss: 0.850448]\n",
      "epoch:16 step:15007 [D loss: 0.591701, acc.: 74.22%] [G loss: 0.881357]\n",
      "epoch:16 step:15008 [D loss: 0.608083, acc.: 63.28%] [G loss: 0.943525]\n",
      "epoch:16 step:15009 [D loss: 0.634053, acc.: 64.06%] [G loss: 0.761079]\n",
      "epoch:16 step:15010 [D loss: 0.623200, acc.: 67.19%] [G loss: 0.873366]\n",
      "epoch:16 step:15011 [D loss: 0.679517, acc.: 53.91%] [G loss: 1.052753]\n",
      "epoch:16 step:15012 [D loss: 0.698913, acc.: 57.03%] [G loss: 0.738896]\n",
      "epoch:16 step:15013 [D loss: 0.686907, acc.: 54.69%] [G loss: 0.780771]\n",
      "epoch:16 step:15014 [D loss: 0.675831, acc.: 59.38%] [G loss: 0.825456]\n",
      "epoch:16 step:15015 [D loss: 0.693070, acc.: 52.34%] [G loss: 0.744892]\n",
      "epoch:16 step:15016 [D loss: 0.635430, acc.: 65.62%] [G loss: 0.730929]\n",
      "epoch:16 step:15017 [D loss: 0.629087, acc.: 67.97%] [G loss: 0.680192]\n",
      "epoch:16 step:15018 [D loss: 0.734487, acc.: 44.53%] [G loss: 0.792368]\n",
      "epoch:16 step:15019 [D loss: 0.810056, acc.: 31.25%] [G loss: 0.626731]\n",
      "epoch:16 step:15020 [D loss: 0.738073, acc.: 52.34%] [G loss: 0.798135]\n",
      "epoch:16 step:15021 [D loss: 0.747049, acc.: 41.41%] [G loss: 0.730440]\n",
      "epoch:16 step:15022 [D loss: 0.722527, acc.: 43.75%] [G loss: 0.750176]\n",
      "epoch:16 step:15023 [D loss: 0.710954, acc.: 52.34%] [G loss: 0.744780]\n",
      "epoch:16 step:15024 [D loss: 0.703987, acc.: 52.34%] [G loss: 0.741846]\n",
      "epoch:16 step:15025 [D loss: 0.648781, acc.: 60.16%] [G loss: 0.745103]\n",
      "epoch:16 step:15026 [D loss: 0.649343, acc.: 63.28%] [G loss: 0.780444]\n",
      "epoch:16 step:15027 [D loss: 0.540935, acc.: 82.03%] [G loss: 0.875212]\n",
      "epoch:16 step:15028 [D loss: 0.533385, acc.: 78.91%] [G loss: 0.886270]\n",
      "epoch:16 step:15029 [D loss: 0.670324, acc.: 62.50%] [G loss: 0.886396]\n",
      "epoch:16 step:15030 [D loss: 0.723314, acc.: 53.91%] [G loss: 0.844590]\n",
      "epoch:16 step:15031 [D loss: 0.699127, acc.: 52.34%] [G loss: 1.290212]\n",
      "epoch:16 step:15032 [D loss: 0.701671, acc.: 54.69%] [G loss: 0.831997]\n",
      "epoch:16 step:15033 [D loss: 0.652842, acc.: 59.38%] [G loss: 0.780357]\n",
      "epoch:16 step:15034 [D loss: 0.653440, acc.: 58.59%] [G loss: 0.806135]\n",
      "epoch:16 step:15035 [D loss: 0.601620, acc.: 74.22%] [G loss: 0.835022]\n",
      "epoch:16 step:15036 [D loss: 0.632911, acc.: 64.06%] [G loss: 0.893793]\n",
      "epoch:16 step:15037 [D loss: 0.630388, acc.: 62.50%] [G loss: 0.826703]\n",
      "epoch:16 step:15038 [D loss: 0.632924, acc.: 62.50%] [G loss: 0.802977]\n",
      "epoch:16 step:15039 [D loss: 0.640484, acc.: 63.28%] [G loss: 0.785801]\n",
      "epoch:16 step:15040 [D loss: 0.675076, acc.: 61.72%] [G loss: 0.825865]\n",
      "epoch:16 step:15041 [D loss: 0.684231, acc.: 53.12%] [G loss: 0.793133]\n",
      "epoch:16 step:15042 [D loss: 0.648742, acc.: 63.28%] [G loss: 0.784632]\n",
      "epoch:16 step:15043 [D loss: 0.679003, acc.: 64.06%] [G loss: 0.786986]\n",
      "epoch:16 step:15044 [D loss: 0.648106, acc.: 59.38%] [G loss: 0.759630]\n",
      "epoch:16 step:15045 [D loss: 0.645864, acc.: 61.72%] [G loss: 0.806662]\n",
      "epoch:16 step:15046 [D loss: 0.705346, acc.: 46.09%] [G loss: 0.810082]\n",
      "epoch:16 step:15047 [D loss: 0.684285, acc.: 53.91%] [G loss: 0.776535]\n",
      "epoch:16 step:15048 [D loss: 0.676060, acc.: 56.25%] [G loss: 0.730782]\n",
      "epoch:16 step:15049 [D loss: 0.652944, acc.: 60.16%] [G loss: 0.711141]\n",
      "epoch:16 step:15050 [D loss: 0.661899, acc.: 64.06%] [G loss: 0.662394]\n",
      "epoch:16 step:15051 [D loss: 0.668736, acc.: 54.69%] [G loss: 0.775940]\n",
      "epoch:16 step:15052 [D loss: 0.642357, acc.: 63.28%] [G loss: 0.768908]\n",
      "epoch:16 step:15053 [D loss: 0.718534, acc.: 46.09%] [G loss: 0.758212]\n",
      "epoch:16 step:15054 [D loss: 0.678766, acc.: 58.59%] [G loss: 0.614700]\n",
      "epoch:16 step:15055 [D loss: 0.650448, acc.: 62.50%] [G loss: 0.757950]\n",
      "epoch:16 step:15056 [D loss: 0.738532, acc.: 46.09%] [G loss: 0.776543]\n",
      "epoch:16 step:15057 [D loss: 0.905158, acc.: 21.88%] [G loss: 0.804562]\n",
      "epoch:16 step:15058 [D loss: 0.689541, acc.: 56.25%] [G loss: 0.706367]\n",
      "epoch:16 step:15059 [D loss: 0.715464, acc.: 49.22%] [G loss: 0.818045]\n",
      "epoch:16 step:15060 [D loss: 0.703920, acc.: 57.81%] [G loss: 0.809140]\n",
      "epoch:16 step:15061 [D loss: 0.684841, acc.: 51.56%] [G loss: 0.793355]\n",
      "epoch:16 step:15062 [D loss: 0.724664, acc.: 46.88%] [G loss: 0.816928]\n",
      "epoch:16 step:15063 [D loss: 0.625887, acc.: 73.44%] [G loss: 0.815523]\n",
      "epoch:16 step:15064 [D loss: 0.664117, acc.: 57.81%] [G loss: 0.802603]\n",
      "epoch:16 step:15065 [D loss: 0.652619, acc.: 58.59%] [G loss: 0.810217]\n",
      "epoch:16 step:15066 [D loss: 0.689481, acc.: 52.34%] [G loss: 0.843152]\n",
      "epoch:16 step:15067 [D loss: 0.659849, acc.: 63.28%] [G loss: 0.715091]\n",
      "epoch:16 step:15068 [D loss: 0.591023, acc.: 77.34%] [G loss: 0.763167]\n",
      "epoch:16 step:15069 [D loss: 0.661191, acc.: 62.50%] [G loss: 0.856130]\n",
      "epoch:16 step:15070 [D loss: 0.708863, acc.: 52.34%] [G loss: 0.814282]\n",
      "epoch:16 step:15071 [D loss: 0.785943, acc.: 39.84%] [G loss: 0.786512]\n",
      "epoch:16 step:15072 [D loss: 0.701526, acc.: 49.22%] [G loss: 0.782365]\n",
      "epoch:16 step:15073 [D loss: 0.692406, acc.: 53.91%] [G loss: 0.785392]\n",
      "epoch:16 step:15074 [D loss: 0.642143, acc.: 62.50%] [G loss: 0.863496]\n",
      "epoch:16 step:15075 [D loss: 0.636170, acc.: 62.50%] [G loss: 0.946633]\n",
      "epoch:16 step:15076 [D loss: 0.655592, acc.: 55.47%] [G loss: 0.965566]\n",
      "epoch:16 step:15077 [D loss: 0.600638, acc.: 71.09%] [G loss: 0.906893]\n",
      "epoch:16 step:15078 [D loss: 0.655841, acc.: 62.50%] [G loss: 1.000707]\n",
      "epoch:16 step:15079 [D loss: 0.627161, acc.: 66.41%] [G loss: 0.937756]\n",
      "epoch:16 step:15080 [D loss: 0.594380, acc.: 67.97%] [G loss: 1.049331]\n",
      "epoch:16 step:15081 [D loss: 0.519990, acc.: 76.56%] [G loss: 0.987092]\n",
      "epoch:16 step:15082 [D loss: 0.647310, acc.: 63.28%] [G loss: 0.884555]\n",
      "epoch:16 step:15083 [D loss: 0.643269, acc.: 60.16%] [G loss: 0.892209]\n",
      "epoch:16 step:15084 [D loss: 0.554581, acc.: 74.22%] [G loss: 0.994613]\n",
      "epoch:16 step:15085 [D loss: 0.531702, acc.: 76.56%] [G loss: 0.762634]\n",
      "epoch:16 step:15086 [D loss: 0.639710, acc.: 60.94%] [G loss: 0.844372]\n",
      "epoch:16 step:15087 [D loss: 0.814960, acc.: 34.38%] [G loss: 0.734359]\n",
      "epoch:16 step:15088 [D loss: 0.686159, acc.: 56.25%] [G loss: 0.940116]\n",
      "epoch:16 step:15089 [D loss: 0.694743, acc.: 50.78%] [G loss: 0.791548]\n",
      "epoch:16 step:15090 [D loss: 0.699354, acc.: 53.12%] [G loss: 0.784773]\n",
      "epoch:16 step:15091 [D loss: 0.648284, acc.: 56.25%] [G loss: 0.705398]\n",
      "epoch:16 step:15092 [D loss: 0.712207, acc.: 49.22%] [G loss: 0.525180]\n",
      "epoch:16 step:15093 [D loss: 0.677482, acc.: 53.91%] [G loss: 0.825123]\n",
      "epoch:16 step:15094 [D loss: 0.677424, acc.: 53.91%] [G loss: 0.738100]\n",
      "epoch:16 step:15095 [D loss: 0.730679, acc.: 46.09%] [G loss: 0.733930]\n",
      "epoch:16 step:15096 [D loss: 0.717558, acc.: 46.88%] [G loss: 0.763743]\n",
      "epoch:16 step:15097 [D loss: 0.760992, acc.: 41.41%] [G loss: 0.739457]\n",
      "epoch:16 step:15098 [D loss: 0.750851, acc.: 45.31%] [G loss: 0.762279]\n",
      "epoch:16 step:15099 [D loss: 0.672344, acc.: 59.38%] [G loss: 0.861172]\n",
      "epoch:16 step:15100 [D loss: 0.723204, acc.: 42.97%] [G loss: 0.860811]\n",
      "epoch:16 step:15101 [D loss: 0.719274, acc.: 53.12%] [G loss: 0.885947]\n",
      "epoch:16 step:15102 [D loss: 0.688465, acc.: 53.91%] [G loss: 0.918553]\n",
      "epoch:16 step:15103 [D loss: 0.664280, acc.: 63.28%] [G loss: 0.990781]\n",
      "epoch:16 step:15104 [D loss: 0.640393, acc.: 67.19%] [G loss: 0.892589]\n",
      "epoch:16 step:15105 [D loss: 0.639468, acc.: 70.31%] [G loss: 0.828599]\n",
      "epoch:16 step:15106 [D loss: 0.663069, acc.: 61.72%] [G loss: 0.811285]\n",
      "epoch:16 step:15107 [D loss: 0.628245, acc.: 67.19%] [G loss: 0.855686]\n",
      "epoch:16 step:15108 [D loss: 0.652400, acc.: 61.72%] [G loss: 0.835408]\n",
      "epoch:16 step:15109 [D loss: 0.671774, acc.: 59.38%] [G loss: 0.858345]\n",
      "epoch:16 step:15110 [D loss: 0.635656, acc.: 63.28%] [G loss: 0.892621]\n",
      "epoch:16 step:15111 [D loss: 0.575487, acc.: 71.88%] [G loss: 0.952262]\n",
      "epoch:16 step:15112 [D loss: 0.733785, acc.: 57.03%] [G loss: 0.932269]\n",
      "epoch:16 step:15113 [D loss: 0.702360, acc.: 57.81%] [G loss: 0.876905]\n",
      "epoch:16 step:15114 [D loss: 0.729031, acc.: 53.12%] [G loss: 0.869015]\n",
      "epoch:16 step:15115 [D loss: 0.643803, acc.: 60.94%] [G loss: 0.871649]\n",
      "epoch:16 step:15116 [D loss: 0.612302, acc.: 68.75%] [G loss: 0.962509]\n",
      "epoch:16 step:15117 [D loss: 0.575014, acc.: 75.00%] [G loss: 0.938937]\n",
      "epoch:16 step:15118 [D loss: 0.619752, acc.: 61.72%] [G loss: 0.975266]\n",
      "epoch:16 step:15119 [D loss: 0.637561, acc.: 64.84%] [G loss: 1.059109]\n",
      "epoch:16 step:15120 [D loss: 0.745143, acc.: 51.56%] [G loss: 0.854953]\n",
      "epoch:16 step:15121 [D loss: 0.707491, acc.: 55.47%] [G loss: 0.882357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15122 [D loss: 0.667403, acc.: 60.94%] [G loss: 0.907704]\n",
      "epoch:16 step:15123 [D loss: 0.692889, acc.: 55.47%] [G loss: 0.753644]\n",
      "epoch:16 step:15124 [D loss: 0.706619, acc.: 50.00%] [G loss: 0.799212]\n",
      "epoch:16 step:15125 [D loss: 0.672620, acc.: 57.81%] [G loss: 0.771196]\n",
      "epoch:16 step:15126 [D loss: 0.715903, acc.: 53.12%] [G loss: 0.555981]\n",
      "epoch:16 step:15127 [D loss: 0.645083, acc.: 57.81%] [G loss: 0.858651]\n",
      "epoch:16 step:15128 [D loss: 0.673171, acc.: 53.91%] [G loss: 0.735671]\n",
      "epoch:16 step:15129 [D loss: 0.706538, acc.: 50.78%] [G loss: 0.748958]\n",
      "epoch:16 step:15130 [D loss: 0.698730, acc.: 57.81%] [G loss: 0.732457]\n",
      "epoch:16 step:15131 [D loss: 0.724480, acc.: 49.22%] [G loss: 0.715092]\n",
      "epoch:16 step:15132 [D loss: 0.689327, acc.: 53.12%] [G loss: 0.734402]\n",
      "epoch:16 step:15133 [D loss: 0.635913, acc.: 68.75%] [G loss: 0.784701]\n",
      "epoch:16 step:15134 [D loss: 0.683415, acc.: 58.59%] [G loss: 0.809689]\n",
      "epoch:16 step:15135 [D loss: 0.646943, acc.: 60.16%] [G loss: 0.761260]\n",
      "epoch:16 step:15136 [D loss: 0.604976, acc.: 67.19%] [G loss: 0.824478]\n",
      "epoch:16 step:15137 [D loss: 0.625424, acc.: 70.31%] [G loss: 0.827952]\n",
      "epoch:16 step:15138 [D loss: 0.631038, acc.: 61.72%] [G loss: 0.830294]\n",
      "epoch:16 step:15139 [D loss: 0.679105, acc.: 47.66%] [G loss: 0.828217]\n",
      "epoch:16 step:15140 [D loss: 0.686182, acc.: 57.81%] [G loss: 0.882916]\n",
      "epoch:16 step:15141 [D loss: 0.675584, acc.: 60.94%] [G loss: 0.821453]\n",
      "epoch:16 step:15142 [D loss: 0.564646, acc.: 75.00%] [G loss: 0.863095]\n",
      "epoch:16 step:15143 [D loss: 0.558885, acc.: 74.22%] [G loss: 0.796504]\n",
      "epoch:16 step:15144 [D loss: 0.621111, acc.: 66.41%] [G loss: 0.954070]\n",
      "epoch:16 step:15145 [D loss: 0.692727, acc.: 53.12%] [G loss: 0.786097]\n",
      "epoch:16 step:15146 [D loss: 0.738077, acc.: 46.09%] [G loss: 0.850258]\n",
      "epoch:16 step:15147 [D loss: 0.647810, acc.: 57.81%] [G loss: 0.863020]\n",
      "epoch:16 step:15148 [D loss: 0.706759, acc.: 46.88%] [G loss: 0.838566]\n",
      "epoch:16 step:15149 [D loss: 0.674449, acc.: 54.69%] [G loss: 0.887042]\n",
      "epoch:16 step:15150 [D loss: 0.748729, acc.: 42.97%] [G loss: 0.774169]\n",
      "epoch:16 step:15151 [D loss: 0.696342, acc.: 46.88%] [G loss: 0.897627]\n",
      "epoch:16 step:15152 [D loss: 0.716187, acc.: 53.91%] [G loss: 0.882983]\n",
      "epoch:16 step:15153 [D loss: 0.698261, acc.: 53.12%] [G loss: 0.890955]\n",
      "epoch:16 step:15154 [D loss: 0.668385, acc.: 60.16%] [G loss: 0.911794]\n",
      "epoch:16 step:15155 [D loss: 0.674529, acc.: 56.25%] [G loss: 0.813066]\n",
      "epoch:16 step:15156 [D loss: 0.664770, acc.: 57.81%] [G loss: 0.906953]\n",
      "epoch:16 step:15157 [D loss: 0.689981, acc.: 53.12%] [G loss: 0.878071]\n",
      "epoch:16 step:15158 [D loss: 0.645981, acc.: 64.84%] [G loss: 0.897701]\n",
      "epoch:16 step:15159 [D loss: 0.685461, acc.: 52.34%] [G loss: 0.908959]\n",
      "epoch:16 step:15160 [D loss: 0.602361, acc.: 65.62%] [G loss: 0.903371]\n",
      "epoch:16 step:15161 [D loss: 0.643722, acc.: 63.28%] [G loss: 0.913354]\n",
      "epoch:16 step:15162 [D loss: 0.660234, acc.: 56.25%] [G loss: 0.780881]\n",
      "epoch:16 step:15163 [D loss: 0.673023, acc.: 59.38%] [G loss: 0.808108]\n",
      "epoch:16 step:15164 [D loss: 0.648700, acc.: 66.41%] [G loss: 0.822201]\n",
      "epoch:16 step:15165 [D loss: 0.677600, acc.: 54.69%] [G loss: 0.870707]\n",
      "epoch:16 step:15166 [D loss: 0.751650, acc.: 47.66%] [G loss: 0.792846]\n",
      "epoch:16 step:15167 [D loss: 0.759143, acc.: 48.44%] [G loss: 0.717911]\n",
      "epoch:16 step:15168 [D loss: 0.662718, acc.: 57.81%] [G loss: 0.774613]\n",
      "epoch:16 step:15169 [D loss: 0.714703, acc.: 49.22%] [G loss: 0.727049]\n",
      "epoch:16 step:15170 [D loss: 0.663517, acc.: 60.16%] [G loss: 0.822573]\n",
      "epoch:16 step:15171 [D loss: 0.689706, acc.: 46.09%] [G loss: 0.694521]\n",
      "epoch:16 step:15172 [D loss: 0.677477, acc.: 57.03%] [G loss: 0.741016]\n",
      "epoch:16 step:15173 [D loss: 0.625318, acc.: 60.16%] [G loss: 0.728343]\n",
      "epoch:16 step:15174 [D loss: 0.666489, acc.: 57.03%] [G loss: 0.694288]\n",
      "epoch:16 step:15175 [D loss: 0.700592, acc.: 51.56%] [G loss: 0.714322]\n",
      "epoch:16 step:15176 [D loss: 0.628697, acc.: 62.50%] [G loss: 0.735915]\n",
      "epoch:16 step:15177 [D loss: 0.633454, acc.: 64.06%] [G loss: 0.729091]\n",
      "epoch:16 step:15178 [D loss: 0.704611, acc.: 52.34%] [G loss: 0.773446]\n",
      "epoch:16 step:15179 [D loss: 0.633994, acc.: 64.84%] [G loss: 0.753546]\n",
      "epoch:16 step:15180 [D loss: 0.681357, acc.: 60.94%] [G loss: 0.782996]\n",
      "epoch:16 step:15181 [D loss: 0.731671, acc.: 50.00%] [G loss: 0.777889]\n",
      "epoch:16 step:15182 [D loss: 0.662779, acc.: 60.16%] [G loss: 0.756324]\n",
      "epoch:16 step:15183 [D loss: 0.642989, acc.: 63.28%] [G loss: 0.785647]\n",
      "epoch:16 step:15184 [D loss: 0.645716, acc.: 62.50%] [G loss: 0.703425]\n",
      "epoch:16 step:15185 [D loss: 0.626549, acc.: 67.97%] [G loss: 0.841695]\n",
      "epoch:16 step:15186 [D loss: 0.659620, acc.: 58.59%] [G loss: 0.840802]\n",
      "epoch:16 step:15187 [D loss: 0.678295, acc.: 53.91%] [G loss: 0.886992]\n",
      "epoch:16 step:15188 [D loss: 0.649069, acc.: 60.16%] [G loss: 0.840329]\n",
      "epoch:16 step:15189 [D loss: 0.648174, acc.: 60.16%] [G loss: 0.903633]\n",
      "epoch:16 step:15190 [D loss: 0.641399, acc.: 63.28%] [G loss: 0.918177]\n",
      "epoch:16 step:15191 [D loss: 0.707011, acc.: 52.34%] [G loss: 0.891879]\n",
      "epoch:16 step:15192 [D loss: 0.712881, acc.: 48.44%] [G loss: 0.903486]\n",
      "epoch:16 step:15193 [D loss: 0.668144, acc.: 60.16%] [G loss: 0.948226]\n",
      "epoch:16 step:15194 [D loss: 0.647630, acc.: 64.06%] [G loss: 0.871809]\n",
      "epoch:16 step:15195 [D loss: 0.680270, acc.: 61.72%] [G loss: 0.804719]\n",
      "epoch:16 step:15196 [D loss: 0.582953, acc.: 70.31%] [G loss: 0.784417]\n",
      "epoch:16 step:15197 [D loss: 0.653181, acc.: 64.84%] [G loss: 0.831330]\n",
      "epoch:16 step:15198 [D loss: 0.623346, acc.: 72.66%] [G loss: 0.843168]\n",
      "epoch:16 step:15199 [D loss: 0.362014, acc.: 78.12%] [G loss: 0.924885]\n",
      "epoch:16 step:15200 [D loss: 0.662945, acc.: 64.06%] [G loss: 0.882796]\n",
      "epoch:16 step:15201 [D loss: 0.607866, acc.: 69.53%] [G loss: 0.851309]\n",
      "epoch:16 step:15202 [D loss: 0.695480, acc.: 58.59%] [G loss: 0.897716]\n",
      "epoch:16 step:15203 [D loss: 0.722765, acc.: 51.56%] [G loss: 0.864841]\n",
      "epoch:16 step:15204 [D loss: 0.608850, acc.: 66.41%] [G loss: 0.894615]\n",
      "epoch:16 step:15205 [D loss: 0.631252, acc.: 69.53%] [G loss: 0.846057]\n",
      "epoch:16 step:15206 [D loss: 0.715295, acc.: 48.44%] [G loss: 0.864145]\n",
      "epoch:16 step:15207 [D loss: 0.714643, acc.: 54.69%] [G loss: 0.842795]\n",
      "epoch:16 step:15208 [D loss: 0.579934, acc.: 70.31%] [G loss: 0.800341]\n",
      "epoch:16 step:15209 [D loss: 0.716287, acc.: 50.78%] [G loss: 0.846126]\n",
      "epoch:16 step:15210 [D loss: 1.074704, acc.: 33.59%] [G loss: 0.904874]\n",
      "epoch:16 step:15211 [D loss: 0.615052, acc.: 67.97%] [G loss: 0.871178]\n",
      "epoch:16 step:15212 [D loss: 0.569244, acc.: 79.69%] [G loss: 0.900111]\n",
      "epoch:16 step:15213 [D loss: 0.567725, acc.: 74.22%] [G loss: 0.963596]\n",
      "epoch:16 step:15214 [D loss: 0.556683, acc.: 79.69%] [G loss: 0.936890]\n",
      "epoch:16 step:15215 [D loss: 0.567979, acc.: 75.00%] [G loss: 0.910392]\n",
      "epoch:16 step:15216 [D loss: 0.734482, acc.: 50.78%] [G loss: 0.879595]\n",
      "epoch:16 step:15217 [D loss: 0.755341, acc.: 52.34%] [G loss: 0.786059]\n",
      "epoch:16 step:15218 [D loss: 0.668490, acc.: 57.03%] [G loss: 1.119646]\n",
      "epoch:16 step:15219 [D loss: 0.705775, acc.: 54.69%] [G loss: 0.761366]\n",
      "epoch:16 step:15220 [D loss: 0.693267, acc.: 59.38%] [G loss: 0.851808]\n",
      "epoch:16 step:15221 [D loss: 0.619686, acc.: 67.19%] [G loss: 0.784570]\n",
      "epoch:16 step:15222 [D loss: 0.473352, acc.: 89.84%] [G loss: 0.724452]\n",
      "epoch:16 step:15223 [D loss: 0.562031, acc.: 71.09%] [G loss: 0.897852]\n",
      "epoch:16 step:15224 [D loss: 0.543719, acc.: 70.31%] [G loss: 0.870353]\n",
      "epoch:16 step:15225 [D loss: 0.701549, acc.: 53.91%] [G loss: 0.972680]\n",
      "epoch:16 step:15226 [D loss: 0.688027, acc.: 55.47%] [G loss: 0.967959]\n",
      "epoch:16 step:15227 [D loss: 0.627596, acc.: 67.19%] [G loss: 0.817996]\n",
      "epoch:16 step:15228 [D loss: 0.791426, acc.: 40.62%] [G loss: 0.826047]\n",
      "epoch:16 step:15229 [D loss: 0.660924, acc.: 64.06%] [G loss: 0.795366]\n",
      "epoch:16 step:15230 [D loss: 0.743163, acc.: 42.19%] [G loss: 0.782380]\n",
      "epoch:16 step:15231 [D loss: 0.714761, acc.: 48.44%] [G loss: 0.825470]\n",
      "epoch:16 step:15232 [D loss: 0.729164, acc.: 47.66%] [G loss: 0.860877]\n",
      "epoch:16 step:15233 [D loss: 0.736723, acc.: 46.09%] [G loss: 0.838681]\n",
      "epoch:16 step:15234 [D loss: 0.676796, acc.: 59.38%] [G loss: 0.936714]\n",
      "epoch:16 step:15235 [D loss: 0.678694, acc.: 60.16%] [G loss: 0.833820]\n",
      "epoch:16 step:15236 [D loss: 0.710176, acc.: 47.66%] [G loss: 0.879234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15237 [D loss: 0.732842, acc.: 48.44%] [G loss: 0.786725]\n",
      "epoch:16 step:15238 [D loss: 0.743427, acc.: 43.75%] [G loss: 0.876037]\n",
      "epoch:16 step:15239 [D loss: 0.661328, acc.: 57.81%] [G loss: 0.931237]\n",
      "epoch:16 step:15240 [D loss: 0.647245, acc.: 62.50%] [G loss: 0.883192]\n",
      "epoch:16 step:15241 [D loss: 0.614768, acc.: 71.09%] [G loss: 0.886301]\n",
      "epoch:16 step:15242 [D loss: 0.656918, acc.: 61.72%] [G loss: 0.919863]\n",
      "epoch:16 step:15243 [D loss: 0.633876, acc.: 64.06%] [G loss: 0.981737]\n",
      "epoch:16 step:15244 [D loss: 0.649994, acc.: 57.03%] [G loss: 0.888038]\n",
      "epoch:16 step:15245 [D loss: 0.671245, acc.: 59.38%] [G loss: 0.969423]\n",
      "epoch:16 step:15246 [D loss: 0.690421, acc.: 58.59%] [G loss: 0.876401]\n",
      "epoch:16 step:15247 [D loss: 0.693999, acc.: 53.91%] [G loss: 0.884008]\n",
      "epoch:16 step:15248 [D loss: 0.668758, acc.: 55.47%] [G loss: 0.845203]\n",
      "epoch:16 step:15249 [D loss: 0.684374, acc.: 57.03%] [G loss: 0.836892]\n",
      "epoch:16 step:15250 [D loss: 0.651427, acc.: 59.38%] [G loss: 0.812190]\n",
      "epoch:16 step:15251 [D loss: 0.682862, acc.: 58.59%] [G loss: 0.848845]\n",
      "epoch:16 step:15252 [D loss: 0.668167, acc.: 56.25%] [G loss: 0.854026]\n",
      "epoch:16 step:15253 [D loss: 0.599955, acc.: 65.62%] [G loss: 0.800350]\n",
      "epoch:16 step:15254 [D loss: 0.676273, acc.: 60.16%] [G loss: 0.807401]\n",
      "epoch:16 step:15255 [D loss: 0.410716, acc.: 78.12%] [G loss: 0.817636]\n",
      "epoch:16 step:15256 [D loss: 0.602810, acc.: 69.53%] [G loss: 0.971252]\n",
      "epoch:16 step:15257 [D loss: 0.707655, acc.: 58.59%] [G loss: 0.956956]\n",
      "epoch:16 step:15258 [D loss: 0.673119, acc.: 54.69%] [G loss: 0.908618]\n",
      "epoch:16 step:15259 [D loss: 0.703964, acc.: 50.78%] [G loss: 0.787719]\n",
      "epoch:16 step:15260 [D loss: 0.696476, acc.: 53.12%] [G loss: 0.898601]\n",
      "epoch:16 step:15261 [D loss: 0.663317, acc.: 59.38%] [G loss: 0.850006]\n",
      "epoch:16 step:15262 [D loss: 0.644503, acc.: 58.59%] [G loss: 0.869774]\n",
      "epoch:16 step:15263 [D loss: 0.646285, acc.: 60.16%] [G loss: 0.876390]\n",
      "epoch:16 step:15264 [D loss: 0.651322, acc.: 61.72%] [G loss: 0.854490]\n",
      "epoch:16 step:15265 [D loss: 0.631972, acc.: 72.66%] [G loss: 0.908729]\n",
      "epoch:16 step:15266 [D loss: 0.644134, acc.: 61.72%] [G loss: 0.812761]\n",
      "epoch:16 step:15267 [D loss: 0.620751, acc.: 68.75%] [G loss: 0.859683]\n",
      "epoch:16 step:15268 [D loss: 0.630236, acc.: 61.72%] [G loss: 0.964089]\n",
      "epoch:16 step:15269 [D loss: 0.648575, acc.: 57.03%] [G loss: 0.886749]\n",
      "epoch:16 step:15270 [D loss: 0.731419, acc.: 52.34%] [G loss: 0.855536]\n",
      "epoch:16 step:15271 [D loss: 0.711918, acc.: 54.69%] [G loss: 0.885632]\n",
      "epoch:16 step:15272 [D loss: 0.695029, acc.: 57.81%] [G loss: 0.817054]\n",
      "epoch:16 step:15273 [D loss: 0.704911, acc.: 46.88%] [G loss: 0.771275]\n",
      "epoch:16 step:15274 [D loss: 0.698191, acc.: 53.91%] [G loss: 0.790648]\n",
      "epoch:16 step:15275 [D loss: 0.711424, acc.: 61.72%] [G loss: 0.767140]\n",
      "epoch:16 step:15276 [D loss: 0.631327, acc.: 64.84%] [G loss: 0.826978]\n",
      "epoch:16 step:15277 [D loss: 0.618735, acc.: 67.97%] [G loss: 0.787203]\n",
      "epoch:16 step:15278 [D loss: 0.607609, acc.: 72.66%] [G loss: 0.824749]\n",
      "epoch:16 step:15279 [D loss: 0.680216, acc.: 57.81%] [G loss: 0.839035]\n",
      "epoch:16 step:15280 [D loss: 0.620283, acc.: 60.94%] [G loss: 0.909644]\n",
      "epoch:16 step:15281 [D loss: 0.577214, acc.: 71.09%] [G loss: 0.835205]\n",
      "epoch:16 step:15282 [D loss: 0.638312, acc.: 64.84%] [G loss: 0.855830]\n",
      "epoch:16 step:15283 [D loss: 0.689097, acc.: 57.81%] [G loss: 0.910594]\n",
      "epoch:16 step:15284 [D loss: 0.662433, acc.: 60.16%] [G loss: 0.863950]\n",
      "epoch:16 step:15285 [D loss: 0.579782, acc.: 78.91%] [G loss: 0.808869]\n",
      "epoch:16 step:15286 [D loss: 0.651871, acc.: 64.84%] [G loss: 0.880938]\n",
      "epoch:16 step:15287 [D loss: 0.767041, acc.: 35.16%] [G loss: 0.738743]\n",
      "epoch:16 step:15288 [D loss: 0.719583, acc.: 43.75%] [G loss: 0.790223]\n",
      "epoch:16 step:15289 [D loss: 0.674996, acc.: 55.47%] [G loss: 0.791160]\n",
      "epoch:16 step:15290 [D loss: 0.709083, acc.: 46.09%] [G loss: 0.763598]\n",
      "epoch:16 step:15291 [D loss: 0.685432, acc.: 50.00%] [G loss: 0.727799]\n",
      "epoch:16 step:15292 [D loss: 0.736677, acc.: 44.53%] [G loss: 0.778571]\n",
      "epoch:16 step:15293 [D loss: 0.665107, acc.: 63.28%] [G loss: 0.805893]\n",
      "epoch:16 step:15294 [D loss: 0.696244, acc.: 53.91%] [G loss: 0.784475]\n",
      "epoch:16 step:15295 [D loss: 0.722413, acc.: 47.66%] [G loss: 0.792743]\n",
      "epoch:16 step:15296 [D loss: 0.773477, acc.: 42.19%] [G loss: 0.791555]\n",
      "epoch:16 step:15297 [D loss: 0.664432, acc.: 59.38%] [G loss: 0.853825]\n",
      "epoch:16 step:15298 [D loss: 0.745145, acc.: 48.44%] [G loss: 0.806587]\n",
      "epoch:16 step:15299 [D loss: 0.691188, acc.: 50.78%] [G loss: 0.834883]\n",
      "epoch:16 step:15300 [D loss: 0.645870, acc.: 62.50%] [G loss: 0.832882]\n",
      "epoch:16 step:15301 [D loss: 0.625828, acc.: 61.72%] [G loss: 0.775544]\n",
      "epoch:16 step:15302 [D loss: 0.677030, acc.: 54.69%] [G loss: 0.841269]\n",
      "epoch:16 step:15303 [D loss: 0.633505, acc.: 66.41%] [G loss: 0.856080]\n",
      "epoch:16 step:15304 [D loss: 0.587399, acc.: 76.56%] [G loss: 0.811021]\n",
      "epoch:16 step:15305 [D loss: 0.604857, acc.: 72.66%] [G loss: 0.900873]\n",
      "epoch:16 step:15306 [D loss: 0.593964, acc.: 71.88%] [G loss: 0.857529]\n",
      "epoch:16 step:15307 [D loss: 0.626961, acc.: 68.75%] [G loss: 0.902041]\n",
      "epoch:16 step:15308 [D loss: 0.759721, acc.: 49.22%] [G loss: 0.882876]\n",
      "epoch:16 step:15309 [D loss: 0.765538, acc.: 39.84%] [G loss: 0.906001]\n",
      "epoch:16 step:15310 [D loss: 0.715537, acc.: 44.53%] [G loss: 0.845273]\n",
      "epoch:16 step:15311 [D loss: 0.715212, acc.: 51.56%] [G loss: 0.887062]\n",
      "epoch:16 step:15312 [D loss: 0.743176, acc.: 42.19%] [G loss: 0.813379]\n",
      "epoch:16 step:15313 [D loss: 0.745123, acc.: 47.66%] [G loss: 0.881130]\n",
      "epoch:16 step:15314 [D loss: 0.689900, acc.: 54.69%] [G loss: 0.914050]\n",
      "epoch:16 step:15315 [D loss: 0.728115, acc.: 53.12%] [G loss: 0.859483]\n",
      "epoch:16 step:15316 [D loss: 0.705064, acc.: 50.78%] [G loss: 0.847462]\n",
      "epoch:16 step:15317 [D loss: 0.668969, acc.: 57.81%] [G loss: 0.861997]\n",
      "epoch:16 step:15318 [D loss: 0.686827, acc.: 55.47%] [G loss: 0.815174]\n",
      "epoch:16 step:15319 [D loss: 0.625019, acc.: 70.31%] [G loss: 0.802113]\n",
      "epoch:16 step:15320 [D loss: 0.611466, acc.: 67.19%] [G loss: 0.884552]\n",
      "epoch:16 step:15321 [D loss: 0.674964, acc.: 60.16%] [G loss: 0.778233]\n",
      "epoch:16 step:15322 [D loss: 0.724789, acc.: 43.75%] [G loss: 0.800479]\n",
      "epoch:16 step:15323 [D loss: 0.664816, acc.: 50.78%] [G loss: 0.767690]\n",
      "epoch:16 step:15324 [D loss: 0.682547, acc.: 57.03%] [G loss: 0.857530]\n",
      "epoch:16 step:15325 [D loss: 0.643523, acc.: 67.19%] [G loss: 0.809979]\n",
      "epoch:16 step:15326 [D loss: 0.709312, acc.: 52.34%] [G loss: 0.848567]\n",
      "epoch:16 step:15327 [D loss: 0.688648, acc.: 58.59%] [G loss: 0.800656]\n",
      "epoch:16 step:15328 [D loss: 0.644691, acc.: 65.62%] [G loss: 0.820704]\n",
      "epoch:16 step:15329 [D loss: 0.637834, acc.: 65.62%] [G loss: 0.771585]\n",
      "epoch:16 step:15330 [D loss: 0.714728, acc.: 46.09%] [G loss: 0.842033]\n",
      "epoch:16 step:15331 [D loss: 0.676965, acc.: 56.25%] [G loss: 0.758704]\n",
      "epoch:16 step:15332 [D loss: 0.689397, acc.: 53.91%] [G loss: 0.768888]\n",
      "epoch:16 step:15333 [D loss: 0.678097, acc.: 55.47%] [G loss: 0.727575]\n",
      "epoch:16 step:15334 [D loss: 0.699919, acc.: 53.91%] [G loss: 0.732153]\n",
      "epoch:16 step:15335 [D loss: 0.611363, acc.: 59.38%] [G loss: 0.724818]\n",
      "epoch:16 step:15336 [D loss: 0.608929, acc.: 68.75%] [G loss: 0.758404]\n",
      "epoch:16 step:15337 [D loss: 0.672878, acc.: 57.03%] [G loss: 0.705270]\n",
      "epoch:16 step:15338 [D loss: 0.725019, acc.: 57.81%] [G loss: 0.712298]\n",
      "epoch:16 step:15339 [D loss: 0.552967, acc.: 81.25%] [G loss: 0.793644]\n",
      "epoch:16 step:15340 [D loss: 0.731660, acc.: 46.88%] [G loss: 0.803830]\n",
      "epoch:16 step:15341 [D loss: 0.721262, acc.: 42.97%] [G loss: 0.764425]\n",
      "epoch:16 step:15342 [D loss: 0.674454, acc.: 51.56%] [G loss: 0.796228]\n",
      "epoch:16 step:15343 [D loss: 0.614502, acc.: 59.38%] [G loss: 0.893320]\n",
      "epoch:16 step:15344 [D loss: 0.616063, acc.: 67.97%] [G loss: 0.890073]\n",
      "epoch:16 step:15345 [D loss: 0.603461, acc.: 71.88%] [G loss: 0.850351]\n",
      "epoch:16 step:15346 [D loss: 0.611213, acc.: 62.50%] [G loss: 0.909828]\n",
      "epoch:16 step:15347 [D loss: 0.648154, acc.: 59.38%] [G loss: 0.878915]\n",
      "epoch:16 step:15348 [D loss: 0.644421, acc.: 62.50%] [G loss: 0.828752]\n",
      "epoch:16 step:15349 [D loss: 0.615082, acc.: 62.50%] [G loss: 0.909783]\n",
      "epoch:16 step:15350 [D loss: 0.590737, acc.: 65.62%] [G loss: 0.882686]\n",
      "epoch:16 step:15351 [D loss: 0.635162, acc.: 64.06%] [G loss: 0.895085]\n",
      "epoch:16 step:15352 [D loss: 0.617181, acc.: 70.31%] [G loss: 0.995134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15353 [D loss: 0.596952, acc.: 71.88%] [G loss: 0.938406]\n",
      "epoch:16 step:15354 [D loss: 0.802475, acc.: 35.16%] [G loss: 0.984055]\n",
      "epoch:16 step:15355 [D loss: 0.714734, acc.: 53.91%] [G loss: 0.882639]\n",
      "epoch:16 step:15356 [D loss: 0.737337, acc.: 44.53%] [G loss: 0.881183]\n",
      "epoch:16 step:15357 [D loss: 0.753978, acc.: 46.09%] [G loss: 0.803111]\n",
      "epoch:16 step:15358 [D loss: 0.744253, acc.: 47.66%] [G loss: 0.779989]\n",
      "epoch:16 step:15359 [D loss: 0.690371, acc.: 52.34%] [G loss: 0.793991]\n",
      "epoch:16 step:15360 [D loss: 0.776324, acc.: 41.41%] [G loss: 0.763414]\n",
      "epoch:16 step:15361 [D loss: 0.681833, acc.: 59.38%] [G loss: 0.742804]\n",
      "epoch:16 step:15362 [D loss: 0.641677, acc.: 64.84%] [G loss: 0.739867]\n",
      "epoch:16 step:15363 [D loss: 0.572166, acc.: 65.62%] [G loss: 0.824672]\n",
      "epoch:16 step:15364 [D loss: 0.731202, acc.: 52.34%] [G loss: 0.762979]\n",
      "epoch:16 step:15365 [D loss: 0.735784, acc.: 45.31%] [G loss: 0.815471]\n",
      "epoch:16 step:15366 [D loss: 0.711075, acc.: 57.03%] [G loss: 0.819141]\n",
      "epoch:16 step:15367 [D loss: 0.680421, acc.: 57.03%] [G loss: 0.811462]\n",
      "epoch:16 step:15368 [D loss: 0.682021, acc.: 60.16%] [G loss: 0.793746]\n",
      "epoch:16 step:15369 [D loss: 0.647068, acc.: 58.59%] [G loss: 0.835146]\n",
      "epoch:16 step:15370 [D loss: 0.626790, acc.: 68.75%] [G loss: 0.785146]\n",
      "epoch:16 step:15371 [D loss: 0.650423, acc.: 64.06%] [G loss: 0.838198]\n",
      "epoch:16 step:15372 [D loss: 0.633058, acc.: 64.84%] [G loss: 0.807692]\n",
      "epoch:16 step:15373 [D loss: 0.685355, acc.: 57.81%] [G loss: 0.820744]\n",
      "epoch:16 step:15374 [D loss: 0.702916, acc.: 56.25%] [G loss: 0.788231]\n",
      "epoch:16 step:15375 [D loss: 0.712338, acc.: 52.34%] [G loss: 0.753864]\n",
      "epoch:16 step:15376 [D loss: 0.656983, acc.: 68.75%] [G loss: 0.735266]\n",
      "epoch:16 step:15377 [D loss: 0.649463, acc.: 61.72%] [G loss: 0.778839]\n",
      "epoch:16 step:15378 [D loss: 0.633973, acc.: 64.06%] [G loss: 0.725817]\n",
      "epoch:16 step:15379 [D loss: 0.670888, acc.: 55.47%] [G loss: 0.651272]\n",
      "epoch:16 step:15380 [D loss: 0.655366, acc.: 62.50%] [G loss: 0.745787]\n",
      "epoch:16 step:15381 [D loss: 0.669008, acc.: 63.28%] [G loss: 0.748028]\n",
      "epoch:16 step:15382 [D loss: 0.678502, acc.: 58.59%] [G loss: 0.690472]\n",
      "epoch:16 step:15383 [D loss: 0.662590, acc.: 62.50%] [G loss: 0.761454]\n",
      "epoch:16 step:15384 [D loss: 0.683946, acc.: 57.03%] [G loss: 0.774431]\n",
      "epoch:16 step:15385 [D loss: 0.635582, acc.: 71.09%] [G loss: 0.798999]\n",
      "epoch:16 step:15386 [D loss: 0.633175, acc.: 60.94%] [G loss: 0.848607]\n",
      "epoch:16 step:15387 [D loss: 0.667015, acc.: 62.50%] [G loss: 0.789271]\n",
      "epoch:16 step:15388 [D loss: 0.518603, acc.: 74.22%] [G loss: 0.769871]\n",
      "epoch:16 step:15389 [D loss: 0.493666, acc.: 75.78%] [G loss: 0.825628]\n",
      "epoch:16 step:15390 [D loss: 0.402448, acc.: 80.47%] [G loss: 1.002185]\n",
      "epoch:16 step:15391 [D loss: 0.445657, acc.: 81.25%] [G loss: 0.858853]\n",
      "epoch:16 step:15392 [D loss: 0.443979, acc.: 82.81%] [G loss: 1.092652]\n",
      "epoch:16 step:15393 [D loss: 0.507175, acc.: 81.25%] [G loss: 0.871172]\n",
      "epoch:16 step:15394 [D loss: 0.542538, acc.: 68.75%] [G loss: 0.934934]\n",
      "epoch:16 step:15395 [D loss: 0.579646, acc.: 66.41%] [G loss: 0.846495]\n",
      "epoch:16 step:15396 [D loss: 0.397972, acc.: 86.72%] [G loss: 1.082343]\n",
      "epoch:16 step:15397 [D loss: 0.592100, acc.: 64.06%] [G loss: 1.361522]\n",
      "epoch:16 step:15398 [D loss: 0.476906, acc.: 79.69%] [G loss: 1.423485]\n",
      "epoch:16 step:15399 [D loss: 0.554485, acc.: 70.31%] [G loss: 1.251571]\n",
      "epoch:16 step:15400 [D loss: 0.694948, acc.: 57.81%] [G loss: 1.218103]\n",
      "epoch:16 step:15401 [D loss: 0.519813, acc.: 73.44%] [G loss: 1.017446]\n",
      "epoch:16 step:15402 [D loss: 0.835432, acc.: 40.62%] [G loss: 0.907088]\n",
      "epoch:16 step:15403 [D loss: 1.038075, acc.: 25.00%] [G loss: 0.913637]\n",
      "epoch:16 step:15404 [D loss: 0.691353, acc.: 54.69%] [G loss: 0.711661]\n",
      "epoch:16 step:15405 [D loss: 0.835359, acc.: 34.38%] [G loss: 0.828535]\n",
      "epoch:16 step:15406 [D loss: 0.700361, acc.: 54.69%] [G loss: 0.902337]\n",
      "epoch:16 step:15407 [D loss: 0.756826, acc.: 47.66%] [G loss: 0.958665]\n",
      "epoch:16 step:15408 [D loss: 0.704831, acc.: 50.00%] [G loss: 0.963908]\n",
      "epoch:16 step:15409 [D loss: 0.734505, acc.: 53.12%] [G loss: 0.904089]\n",
      "epoch:16 step:15410 [D loss: 0.735807, acc.: 52.34%] [G loss: 0.887054]\n",
      "epoch:16 step:15411 [D loss: 0.701788, acc.: 53.91%] [G loss: 0.886632]\n",
      "epoch:16 step:15412 [D loss: 0.731516, acc.: 45.31%] [G loss: 0.859808]\n",
      "epoch:16 step:15413 [D loss: 0.732820, acc.: 45.31%] [G loss: 0.873837]\n",
      "epoch:16 step:15414 [D loss: 0.700355, acc.: 50.78%] [G loss: 0.987657]\n",
      "epoch:16 step:15415 [D loss: 0.709469, acc.: 51.56%] [G loss: 0.858058]\n",
      "epoch:16 step:15416 [D loss: 0.694750, acc.: 56.25%] [G loss: 0.933855]\n",
      "epoch:16 step:15417 [D loss: 0.681175, acc.: 54.69%] [G loss: 0.882978]\n",
      "epoch:16 step:15418 [D loss: 0.684951, acc.: 53.91%] [G loss: 0.893219]\n",
      "epoch:16 step:15419 [D loss: 0.678933, acc.: 60.16%] [G loss: 0.856043]\n",
      "epoch:16 step:15420 [D loss: 0.651925, acc.: 57.03%] [G loss: 0.850717]\n",
      "epoch:16 step:15421 [D loss: 0.661426, acc.: 59.38%] [G loss: 0.874591]\n",
      "epoch:16 step:15422 [D loss: 0.695022, acc.: 54.69%] [G loss: 0.878532]\n",
      "epoch:16 step:15423 [D loss: 0.698082, acc.: 53.12%] [G loss: 0.820997]\n",
      "epoch:16 step:15424 [D loss: 0.722489, acc.: 47.66%] [G loss: 0.862809]\n",
      "epoch:16 step:15425 [D loss: 0.711103, acc.: 50.00%] [G loss: 0.881246]\n",
      "epoch:16 step:15426 [D loss: 0.653230, acc.: 65.62%] [G loss: 0.833096]\n",
      "epoch:16 step:15427 [D loss: 0.681832, acc.: 56.25%] [G loss: 0.863263]\n",
      "epoch:16 step:15428 [D loss: 0.634020, acc.: 63.28%] [G loss: 0.885606]\n",
      "epoch:16 step:15429 [D loss: 0.688964, acc.: 53.91%] [G loss: 0.865271]\n",
      "epoch:16 step:15430 [D loss: 0.731193, acc.: 48.44%] [G loss: 0.885033]\n",
      "epoch:16 step:15431 [D loss: 0.684811, acc.: 57.03%] [G loss: 0.808454]\n",
      "epoch:16 step:15432 [D loss: 0.710150, acc.: 53.12%] [G loss: 0.805084]\n",
      "epoch:16 step:15433 [D loss: 0.717806, acc.: 53.12%] [G loss: 0.828506]\n",
      "epoch:16 step:15434 [D loss: 0.680643, acc.: 53.12%] [G loss: 0.774859]\n",
      "epoch:16 step:15435 [D loss: 0.659793, acc.: 59.38%] [G loss: 0.831107]\n",
      "epoch:16 step:15436 [D loss: 0.685064, acc.: 51.56%] [G loss: 0.881609]\n",
      "epoch:16 step:15437 [D loss: 0.686220, acc.: 55.47%] [G loss: 0.904081]\n",
      "epoch:16 step:15438 [D loss: 0.701480, acc.: 51.56%] [G loss: 0.831753]\n",
      "epoch:16 step:15439 [D loss: 0.692415, acc.: 57.81%] [G loss: 0.774997]\n",
      "epoch:16 step:15440 [D loss: 0.636546, acc.: 68.75%] [G loss: 0.897005]\n",
      "epoch:16 step:15441 [D loss: 0.604145, acc.: 71.09%] [G loss: 0.879064]\n",
      "epoch:16 step:15442 [D loss: 0.617082, acc.: 67.19%] [G loss: 0.873141]\n",
      "epoch:16 step:15443 [D loss: 0.539660, acc.: 82.03%] [G loss: 0.946242]\n",
      "epoch:16 step:15444 [D loss: 0.557637, acc.: 71.88%] [G loss: 0.850430]\n",
      "epoch:16 step:15445 [D loss: 0.604205, acc.: 67.19%] [G loss: 0.963726]\n",
      "epoch:16 step:15446 [D loss: 0.582753, acc.: 72.66%] [G loss: 1.008412]\n",
      "epoch:16 step:15447 [D loss: 0.643364, acc.: 57.03%] [G loss: 0.888289]\n",
      "epoch:16 step:15448 [D loss: 0.541062, acc.: 73.44%] [G loss: 0.885761]\n",
      "epoch:16 step:15449 [D loss: 0.581221, acc.: 72.66%] [G loss: 0.852107]\n",
      "epoch:16 step:15450 [D loss: 0.675337, acc.: 57.81%] [G loss: 0.828596]\n",
      "epoch:16 step:15451 [D loss: 0.642117, acc.: 61.72%] [G loss: 0.990017]\n",
      "epoch:16 step:15452 [D loss: 0.684868, acc.: 55.47%] [G loss: 0.798185]\n",
      "epoch:16 step:15453 [D loss: 0.838221, acc.: 32.03%] [G loss: 0.853632]\n",
      "epoch:16 step:15454 [D loss: 0.880716, acc.: 29.69%] [G loss: 0.721098]\n",
      "epoch:16 step:15455 [D loss: 0.761276, acc.: 43.75%] [G loss: 0.767806]\n",
      "epoch:16 step:15456 [D loss: 0.703161, acc.: 50.78%] [G loss: 0.742193]\n",
      "epoch:16 step:15457 [D loss: 0.625427, acc.: 69.53%] [G loss: 0.758732]\n",
      "epoch:16 step:15458 [D loss: 0.654948, acc.: 64.06%] [G loss: 0.830380]\n",
      "epoch:16 step:15459 [D loss: 0.705176, acc.: 51.56%] [G loss: 0.781642]\n",
      "epoch:16 step:15460 [D loss: 0.557966, acc.: 78.91%] [G loss: 0.853015]\n",
      "epoch:16 step:15461 [D loss: 0.622058, acc.: 73.44%] [G loss: 0.739673]\n",
      "epoch:16 step:15462 [D loss: 0.569396, acc.: 72.66%] [G loss: 0.751632]\n",
      "epoch:16 step:15463 [D loss: 0.617101, acc.: 69.53%] [G loss: 0.752045]\n",
      "epoch:16 step:15464 [D loss: 0.625838, acc.: 67.19%] [G loss: 0.710591]\n",
      "epoch:16 step:15465 [D loss: 0.755085, acc.: 44.53%] [G loss: 0.694350]\n",
      "epoch:16 step:15466 [D loss: 0.684544, acc.: 53.12%] [G loss: 0.859508]\n",
      "epoch:16 step:15467 [D loss: 0.653827, acc.: 63.28%] [G loss: 0.901365]\n",
      "epoch:16 step:15468 [D loss: 0.713925, acc.: 51.56%] [G loss: 0.829867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15469 [D loss: 0.776926, acc.: 46.09%] [G loss: 0.855298]\n",
      "epoch:16 step:15470 [D loss: 0.672545, acc.: 57.03%] [G loss: 0.885827]\n",
      "epoch:16 step:15471 [D loss: 0.687980, acc.: 60.16%] [G loss: 0.857967]\n",
      "epoch:16 step:15472 [D loss: 0.631009, acc.: 62.50%] [G loss: 0.887430]\n",
      "epoch:16 step:15473 [D loss: 0.660441, acc.: 58.59%] [G loss: 0.811759]\n",
      "epoch:16 step:15474 [D loss: 0.663318, acc.: 61.72%] [G loss: 0.870963]\n",
      "epoch:16 step:15475 [D loss: 0.652362, acc.: 60.94%] [G loss: 0.919999]\n",
      "epoch:16 step:15476 [D loss: 0.632310, acc.: 65.62%] [G loss: 0.798969]\n",
      "epoch:16 step:15477 [D loss: 0.640603, acc.: 68.75%] [G loss: 0.888187]\n",
      "epoch:16 step:15478 [D loss: 0.679834, acc.: 56.25%] [G loss: 0.935449]\n",
      "epoch:16 step:15479 [D loss: 0.644963, acc.: 65.62%] [G loss: 0.888173]\n",
      "epoch:16 step:15480 [D loss: 0.600430, acc.: 71.88%] [G loss: 0.948662]\n",
      "epoch:16 step:15481 [D loss: 0.711146, acc.: 50.78%] [G loss: 0.770295]\n",
      "epoch:16 step:15482 [D loss: 0.693275, acc.: 59.38%] [G loss: 0.812401]\n",
      "epoch:16 step:15483 [D loss: 0.702681, acc.: 52.34%] [G loss: 0.819351]\n",
      "epoch:16 step:15484 [D loss: 0.747548, acc.: 48.44%] [G loss: 0.845657]\n",
      "epoch:16 step:15485 [D loss: 0.710431, acc.: 57.03%] [G loss: 0.793435]\n",
      "epoch:16 step:15486 [D loss: 0.665579, acc.: 60.16%] [G loss: 0.803273]\n",
      "epoch:16 step:15487 [D loss: 0.615732, acc.: 72.66%] [G loss: 0.813050]\n",
      "epoch:16 step:15488 [D loss: 0.649879, acc.: 67.19%] [G loss: 0.814584]\n",
      "epoch:16 step:15489 [D loss: 0.543180, acc.: 78.91%] [G loss: 0.946076]\n",
      "epoch:16 step:15490 [D loss: 0.527051, acc.: 75.00%] [G loss: 0.994573]\n",
      "epoch:16 step:15491 [D loss: 0.507017, acc.: 78.91%] [G loss: 1.044192]\n",
      "epoch:16 step:15492 [D loss: 0.620291, acc.: 65.62%] [G loss: 1.017476]\n",
      "epoch:16 step:15493 [D loss: 0.728427, acc.: 41.41%] [G loss: 0.864241]\n",
      "epoch:16 step:15494 [D loss: 0.706511, acc.: 55.47%] [G loss: 0.843310]\n",
      "epoch:16 step:15495 [D loss: 0.847304, acc.: 35.16%] [G loss: 0.754127]\n",
      "epoch:16 step:15496 [D loss: 0.765021, acc.: 38.28%] [G loss: 0.893696]\n",
      "epoch:16 step:15497 [D loss: 0.683329, acc.: 52.34%] [G loss: 0.889439]\n",
      "epoch:16 step:15498 [D loss: 0.681447, acc.: 60.16%] [G loss: 0.765184]\n",
      "epoch:16 step:15499 [D loss: 0.673944, acc.: 59.38%] [G loss: 0.845738]\n",
      "epoch:16 step:15500 [D loss: 0.658085, acc.: 60.16%] [G loss: 0.885461]\n",
      "epoch:16 step:15501 [D loss: 0.690665, acc.: 53.91%] [G loss: 0.842255]\n",
      "epoch:16 step:15502 [D loss: 0.645983, acc.: 59.38%] [G loss: 0.872762]\n",
      "epoch:16 step:15503 [D loss: 0.638207, acc.: 59.38%] [G loss: 0.909792]\n",
      "epoch:16 step:15504 [D loss: 0.622485, acc.: 62.50%] [G loss: 0.802548]\n",
      "epoch:16 step:15505 [D loss: 0.575325, acc.: 72.66%] [G loss: 0.840516]\n",
      "epoch:16 step:15506 [D loss: 0.561850, acc.: 75.00%] [G loss: 0.947974]\n",
      "epoch:16 step:15507 [D loss: 0.610276, acc.: 68.75%] [G loss: 0.747881]\n",
      "epoch:16 step:15508 [D loss: 0.683896, acc.: 55.47%] [G loss: 0.701121]\n",
      "epoch:16 step:15509 [D loss: 0.705354, acc.: 57.03%] [G loss: 0.859455]\n",
      "epoch:16 step:15510 [D loss: 0.636817, acc.: 63.28%] [G loss: 0.919325]\n",
      "epoch:16 step:15511 [D loss: 0.673886, acc.: 53.12%] [G loss: 0.926032]\n",
      "epoch:16 step:15512 [D loss: 0.619928, acc.: 67.19%] [G loss: 0.863040]\n",
      "epoch:16 step:15513 [D loss: 0.688966, acc.: 51.56%] [G loss: 0.892099]\n",
      "epoch:16 step:15514 [D loss: 0.672169, acc.: 52.34%] [G loss: 0.864165]\n",
      "epoch:16 step:15515 [D loss: 0.662174, acc.: 58.59%] [G loss: 1.008325]\n",
      "epoch:16 step:15516 [D loss: 0.705290, acc.: 56.25%] [G loss: 0.930115]\n",
      "epoch:16 step:15517 [D loss: 0.713237, acc.: 47.66%] [G loss: 0.820883]\n",
      "epoch:16 step:15518 [D loss: 0.707942, acc.: 52.34%] [G loss: 0.805955]\n",
      "epoch:16 step:15519 [D loss: 0.662042, acc.: 55.47%] [G loss: 0.856714]\n",
      "epoch:16 step:15520 [D loss: 0.709105, acc.: 48.44%] [G loss: 0.820786]\n",
      "epoch:16 step:15521 [D loss: 0.741538, acc.: 42.19%] [G loss: 0.815489]\n",
      "epoch:16 step:15522 [D loss: 0.656096, acc.: 55.47%] [G loss: 0.785311]\n",
      "epoch:16 step:15523 [D loss: 0.693488, acc.: 52.34%] [G loss: 0.900033]\n",
      "epoch:16 step:15524 [D loss: 0.656622, acc.: 58.59%] [G loss: 0.845000]\n",
      "epoch:16 step:15525 [D loss: 0.622624, acc.: 65.62%] [G loss: 0.897278]\n",
      "epoch:16 step:15526 [D loss: 0.646757, acc.: 57.03%] [G loss: 0.830889]\n",
      "epoch:16 step:15527 [D loss: 0.661364, acc.: 60.16%] [G loss: 0.830193]\n",
      "epoch:16 step:15528 [D loss: 0.625706, acc.: 65.62%] [G loss: 0.852880]\n",
      "epoch:16 step:15529 [D loss: 0.680383, acc.: 55.47%] [G loss: 0.861561]\n",
      "epoch:16 step:15530 [D loss: 0.637608, acc.: 67.19%] [G loss: 0.847321]\n",
      "epoch:16 step:15531 [D loss: 0.677731, acc.: 57.03%] [G loss: 0.824934]\n",
      "epoch:16 step:15532 [D loss: 0.612387, acc.: 75.00%] [G loss: 0.842746]\n",
      "epoch:16 step:15533 [D loss: 0.681698, acc.: 52.34%] [G loss: 0.860610]\n",
      "epoch:16 step:15534 [D loss: 0.593620, acc.: 70.31%] [G loss: 0.876058]\n",
      "epoch:16 step:15535 [D loss: 0.415153, acc.: 79.69%] [G loss: 0.921699]\n",
      "epoch:16 step:15536 [D loss: 0.657637, acc.: 64.84%] [G loss: 0.943507]\n",
      "epoch:16 step:15537 [D loss: 0.604027, acc.: 66.41%] [G loss: 0.939881]\n",
      "epoch:16 step:15538 [D loss: 0.652971, acc.: 56.25%] [G loss: 0.859928]\n",
      "epoch:16 step:15539 [D loss: 0.639595, acc.: 65.62%] [G loss: 0.770818]\n",
      "epoch:16 step:15540 [D loss: 0.575894, acc.: 74.22%] [G loss: 0.798095]\n",
      "epoch:16 step:15541 [D loss: 0.563125, acc.: 72.66%] [G loss: 0.947788]\n",
      "epoch:16 step:15542 [D loss: 0.410055, acc.: 81.25%] [G loss: 0.871118]\n",
      "epoch:16 step:15543 [D loss: 0.519932, acc.: 84.38%] [G loss: 0.688672]\n",
      "epoch:16 step:15544 [D loss: 0.564069, acc.: 72.66%] [G loss: 1.061669]\n",
      "epoch:16 step:15545 [D loss: 0.749336, acc.: 43.75%] [G loss: 0.920607]\n",
      "epoch:16 step:15546 [D loss: 0.545734, acc.: 76.56%] [G loss: 0.986668]\n",
      "epoch:16 step:15547 [D loss: 0.639024, acc.: 67.19%] [G loss: 0.868245]\n",
      "epoch:16 step:15548 [D loss: 0.614192, acc.: 64.84%] [G loss: 0.747996]\n",
      "epoch:16 step:15549 [D loss: 0.669113, acc.: 60.94%] [G loss: 0.699367]\n",
      "epoch:16 step:15550 [D loss: 0.722625, acc.: 53.91%] [G loss: 0.950085]\n",
      "epoch:16 step:15551 [D loss: 0.831305, acc.: 39.84%] [G loss: 1.013915]\n",
      "epoch:16 step:15552 [D loss: 0.817055, acc.: 42.97%] [G loss: 0.873717]\n",
      "epoch:16 step:15553 [D loss: 0.733196, acc.: 49.22%] [G loss: 0.965823]\n",
      "epoch:16 step:15554 [D loss: 0.767547, acc.: 45.31%] [G loss: 0.940569]\n",
      "epoch:16 step:15555 [D loss: 0.660585, acc.: 58.59%] [G loss: 0.968255]\n",
      "epoch:16 step:15556 [D loss: 0.621032, acc.: 62.50%] [G loss: 1.000778]\n",
      "epoch:16 step:15557 [D loss: 0.617841, acc.: 67.97%] [G loss: 1.033341]\n",
      "epoch:16 step:15558 [D loss: 0.662431, acc.: 63.28%] [G loss: 0.966073]\n",
      "epoch:16 step:15559 [D loss: 0.567208, acc.: 73.44%] [G loss: 0.958542]\n",
      "epoch:16 step:15560 [D loss: 0.580190, acc.: 73.44%] [G loss: 1.100446]\n",
      "epoch:16 step:15561 [D loss: 0.670954, acc.: 60.94%] [G loss: 1.098036]\n",
      "epoch:16 step:15562 [D loss: 0.666745, acc.: 64.84%] [G loss: 0.961030]\n",
      "epoch:16 step:15563 [D loss: 0.634597, acc.: 64.06%] [G loss: 1.091075]\n",
      "epoch:16 step:15564 [D loss: 0.599774, acc.: 71.09%] [G loss: 1.022594]\n",
      "epoch:16 step:15565 [D loss: 0.510619, acc.: 78.12%] [G loss: 0.880748]\n",
      "epoch:16 step:15566 [D loss: 0.532375, acc.: 75.78%] [G loss: 0.979236]\n",
      "epoch:16 step:15567 [D loss: 0.682631, acc.: 55.47%] [G loss: 0.869565]\n",
      "epoch:16 step:15568 [D loss: 0.616882, acc.: 75.00%] [G loss: 0.988025]\n",
      "epoch:16 step:15569 [D loss: 0.631822, acc.: 69.53%] [G loss: 0.858657]\n",
      "epoch:16 step:15570 [D loss: 0.636811, acc.: 60.16%] [G loss: 0.683673]\n",
      "epoch:16 step:15571 [D loss: 0.605827, acc.: 64.84%] [G loss: 0.987549]\n",
      "epoch:16 step:15572 [D loss: 0.697963, acc.: 57.03%] [G loss: 0.890780]\n",
      "epoch:16 step:15573 [D loss: 0.784337, acc.: 39.06%] [G loss: 0.777317]\n",
      "epoch:16 step:15574 [D loss: 0.744423, acc.: 42.19%] [G loss: 0.839013]\n",
      "epoch:16 step:15575 [D loss: 0.817468, acc.: 32.81%] [G loss: 0.867877]\n",
      "epoch:16 step:15576 [D loss: 0.791803, acc.: 38.28%] [G loss: 0.815347]\n",
      "epoch:16 step:15577 [D loss: 0.639641, acc.: 67.97%] [G loss: 0.905388]\n",
      "epoch:16 step:15578 [D loss: 0.648138, acc.: 54.69%] [G loss: 0.963093]\n",
      "epoch:16 step:15579 [D loss: 0.625084, acc.: 65.62%] [G loss: 0.925735]\n",
      "epoch:16 step:15580 [D loss: 0.552755, acc.: 76.56%] [G loss: 0.973933]\n",
      "epoch:16 step:15581 [D loss: 0.567237, acc.: 75.00%] [G loss: 1.036178]\n",
      "epoch:16 step:15582 [D loss: 0.614949, acc.: 66.41%] [G loss: 1.030247]\n",
      "epoch:16 step:15583 [D loss: 0.651498, acc.: 61.72%] [G loss: 0.893885]\n",
      "epoch:16 step:15584 [D loss: 0.621980, acc.: 62.50%] [G loss: 1.011029]\n",
      "epoch:16 step:15585 [D loss: 0.717782, acc.: 48.44%] [G loss: 0.879588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15586 [D loss: 0.704924, acc.: 51.56%] [G loss: 0.942509]\n",
      "epoch:16 step:15587 [D loss: 0.680873, acc.: 59.38%] [G loss: 0.812470]\n",
      "epoch:16 step:15588 [D loss: 0.593651, acc.: 65.62%] [G loss: 0.916740]\n",
      "epoch:16 step:15589 [D loss: 0.676091, acc.: 60.94%] [G loss: 0.806919]\n",
      "epoch:16 step:15590 [D loss: 0.729280, acc.: 53.12%] [G loss: 0.826479]\n",
      "epoch:16 step:15591 [D loss: 0.660693, acc.: 52.34%] [G loss: 0.875633]\n",
      "epoch:16 step:15592 [D loss: 0.641359, acc.: 62.50%] [G loss: 1.015297]\n",
      "epoch:16 step:15593 [D loss: 0.668173, acc.: 55.47%] [G loss: 1.080520]\n",
      "epoch:16 step:15594 [D loss: 0.642358, acc.: 67.19%] [G loss: 1.007689]\n",
      "epoch:16 step:15595 [D loss: 0.616677, acc.: 60.16%] [G loss: 1.048564]\n",
      "epoch:16 step:15596 [D loss: 0.622466, acc.: 64.84%] [G loss: 1.161496]\n",
      "epoch:16 step:15597 [D loss: 0.609198, acc.: 65.62%] [G loss: 1.063388]\n",
      "epoch:16 step:15598 [D loss: 0.645479, acc.: 64.06%] [G loss: 1.112497]\n",
      "epoch:16 step:15599 [D loss: 0.679216, acc.: 54.69%] [G loss: 1.035746]\n",
      "epoch:16 step:15600 [D loss: 0.688765, acc.: 48.44%] [G loss: 0.968374]\n",
      "epoch:16 step:15601 [D loss: 0.627013, acc.: 71.09%] [G loss: 0.950854]\n",
      "epoch:16 step:15602 [D loss: 0.721125, acc.: 43.75%] [G loss: 0.897758]\n",
      "epoch:16 step:15603 [D loss: 0.628545, acc.: 66.41%] [G loss: 0.884092]\n",
      "epoch:16 step:15604 [D loss: 0.617903, acc.: 64.84%] [G loss: 0.874382]\n",
      "epoch:16 step:15605 [D loss: 0.621992, acc.: 65.62%] [G loss: 0.833513]\n",
      "epoch:16 step:15606 [D loss: 0.720849, acc.: 43.75%] [G loss: 0.814071]\n",
      "epoch:16 step:15607 [D loss: 0.674947, acc.: 50.78%] [G loss: 0.828663]\n",
      "epoch:16 step:15608 [D loss: 0.636254, acc.: 66.41%] [G loss: 0.866652]\n",
      "epoch:16 step:15609 [D loss: 0.620383, acc.: 60.94%] [G loss: 0.902323]\n",
      "epoch:16 step:15610 [D loss: 0.689907, acc.: 57.03%] [G loss: 0.866284]\n",
      "epoch:16 step:15611 [D loss: 0.680267, acc.: 54.69%] [G loss: 0.809424]\n",
      "epoch:16 step:15612 [D loss: 0.705637, acc.: 53.91%] [G loss: 0.860954]\n",
      "epoch:16 step:15613 [D loss: 0.715463, acc.: 48.44%] [G loss: 0.729702]\n",
      "epoch:16 step:15614 [D loss: 0.673603, acc.: 57.03%] [G loss: 0.826676]\n",
      "epoch:16 step:15615 [D loss: 0.634314, acc.: 63.28%] [G loss: 0.806255]\n",
      "epoch:16 step:15616 [D loss: 0.618412, acc.: 64.06%] [G loss: 0.825697]\n",
      "epoch:16 step:15617 [D loss: 0.754528, acc.: 45.31%] [G loss: 0.821166]\n",
      "epoch:16 step:15618 [D loss: 0.689175, acc.: 56.25%] [G loss: 0.793495]\n",
      "epoch:16 step:15619 [D loss: 0.691728, acc.: 56.25%] [G loss: 0.827055]\n",
      "epoch:16 step:15620 [D loss: 0.686784, acc.: 59.38%] [G loss: 0.835433]\n",
      "epoch:16 step:15621 [D loss: 0.668960, acc.: 59.38%] [G loss: 0.784391]\n",
      "epoch:16 step:15622 [D loss: 0.700833, acc.: 58.59%] [G loss: 0.726394]\n",
      "epoch:16 step:15623 [D loss: 0.654336, acc.: 63.28%] [G loss: 0.780975]\n",
      "epoch:16 step:15624 [D loss: 0.666426, acc.: 59.38%] [G loss: 0.802661]\n",
      "epoch:16 step:15625 [D loss: 0.632798, acc.: 67.19%] [G loss: 0.798570]\n",
      "epoch:16 step:15626 [D loss: 0.612490, acc.: 64.84%] [G loss: 0.801888]\n",
      "epoch:16 step:15627 [D loss: 0.619904, acc.: 61.72%] [G loss: 0.785579]\n",
      "epoch:16 step:15628 [D loss: 0.710369, acc.: 52.34%] [G loss: 0.706110]\n",
      "epoch:16 step:15629 [D loss: 0.670115, acc.: 60.16%] [G loss: 0.754278]\n",
      "epoch:16 step:15630 [D loss: 0.687587, acc.: 55.47%] [G loss: 0.871979]\n",
      "epoch:16 step:15631 [D loss: 0.756553, acc.: 43.75%] [G loss: 0.895970]\n",
      "epoch:16 step:15632 [D loss: 0.700095, acc.: 53.91%] [G loss: 0.835197]\n",
      "epoch:16 step:15633 [D loss: 0.659404, acc.: 61.72%] [G loss: 0.826448]\n",
      "epoch:16 step:15634 [D loss: 0.677069, acc.: 57.81%] [G loss: 1.029534]\n",
      "epoch:16 step:15635 [D loss: 0.670508, acc.: 57.03%] [G loss: 0.870768]\n",
      "epoch:16 step:15636 [D loss: 0.695379, acc.: 67.19%] [G loss: 0.818164]\n",
      "epoch:16 step:15637 [D loss: 0.681084, acc.: 59.38%] [G loss: 0.756683]\n",
      "epoch:16 step:15638 [D loss: 0.649160, acc.: 64.84%] [G loss: 0.784490]\n",
      "epoch:16 step:15639 [D loss: 0.693291, acc.: 56.25%] [G loss: 0.882368]\n",
      "epoch:16 step:15640 [D loss: 0.608103, acc.: 72.66%] [G loss: 0.878723]\n",
      "epoch:16 step:15641 [D loss: 0.635117, acc.: 64.84%] [G loss: 0.864583]\n",
      "epoch:16 step:15642 [D loss: 0.612989, acc.: 67.97%] [G loss: 0.914856]\n",
      "epoch:16 step:15643 [D loss: 0.599859, acc.: 71.88%] [G loss: 0.888710]\n",
      "epoch:16 step:15644 [D loss: 0.683823, acc.: 60.16%] [G loss: 0.914006]\n",
      "epoch:16 step:15645 [D loss: 0.656968, acc.: 64.84%] [G loss: 0.980889]\n",
      "epoch:16 step:15646 [D loss: 0.674570, acc.: 61.72%] [G loss: 0.904346]\n",
      "epoch:16 step:15647 [D loss: 0.611838, acc.: 67.19%] [G loss: 0.921905]\n",
      "epoch:16 step:15648 [D loss: 0.663777, acc.: 61.72%] [G loss: 0.956330]\n",
      "epoch:16 step:15649 [D loss: 0.704358, acc.: 47.66%] [G loss: 0.811655]\n",
      "epoch:16 step:15650 [D loss: 0.649265, acc.: 64.84%] [G loss: 0.826650]\n",
      "epoch:16 step:15651 [D loss: 0.607941, acc.: 62.50%] [G loss: 0.805186]\n",
      "epoch:16 step:15652 [D loss: 0.606273, acc.: 71.09%] [G loss: 0.831124]\n",
      "epoch:16 step:15653 [D loss: 0.669940, acc.: 58.59%] [G loss: 0.822405]\n",
      "epoch:16 step:15654 [D loss: 0.679592, acc.: 59.38%] [G loss: 0.884167]\n",
      "epoch:16 step:15655 [D loss: 0.653201, acc.: 60.16%] [G loss: 0.877369]\n",
      "epoch:16 step:15656 [D loss: 0.635227, acc.: 64.06%] [G loss: 0.923469]\n",
      "epoch:16 step:15657 [D loss: 0.575422, acc.: 69.53%] [G loss: 0.941268]\n",
      "epoch:16 step:15658 [D loss: 0.642152, acc.: 60.94%] [G loss: 1.042610]\n",
      "epoch:16 step:15659 [D loss: 0.585370, acc.: 72.66%] [G loss: 0.995618]\n",
      "epoch:16 step:15660 [D loss: 0.698512, acc.: 61.72%] [G loss: 0.965932]\n",
      "epoch:16 step:15661 [D loss: 0.681525, acc.: 53.12%] [G loss: 0.887321]\n",
      "epoch:16 step:15662 [D loss: 0.691871, acc.: 58.59%] [G loss: 0.846979]\n",
      "epoch:16 step:15663 [D loss: 0.695581, acc.: 51.56%] [G loss: 0.794636]\n",
      "epoch:16 step:15664 [D loss: 0.684000, acc.: 49.22%] [G loss: 0.828374]\n",
      "epoch:16 step:15665 [D loss: 0.632188, acc.: 59.38%] [G loss: 0.789780]\n",
      "epoch:16 step:15666 [D loss: 0.557989, acc.: 73.44%] [G loss: 0.884305]\n",
      "epoch:16 step:15667 [D loss: 0.748972, acc.: 47.66%] [G loss: 0.878597]\n",
      "epoch:16 step:15668 [D loss: 0.690453, acc.: 60.16%] [G loss: 0.836604]\n",
      "epoch:16 step:15669 [D loss: 0.642501, acc.: 59.38%] [G loss: 0.895977]\n",
      "epoch:16 step:15670 [D loss: 0.656178, acc.: 59.38%] [G loss: 0.793948]\n",
      "epoch:16 step:15671 [D loss: 0.662279, acc.: 62.50%] [G loss: 0.812992]\n",
      "epoch:16 step:15672 [D loss: 0.664504, acc.: 57.03%] [G loss: 0.912914]\n",
      "epoch:16 step:15673 [D loss: 0.624977, acc.: 62.50%] [G loss: 0.836315]\n",
      "epoch:16 step:15674 [D loss: 0.698938, acc.: 52.34%] [G loss: 0.812383]\n",
      "epoch:16 step:15675 [D loss: 0.683546, acc.: 56.25%] [G loss: 1.010221]\n",
      "epoch:16 step:15676 [D loss: 0.612483, acc.: 71.09%] [G loss: 0.807222]\n",
      "epoch:16 step:15677 [D loss: 0.660911, acc.: 60.94%] [G loss: 0.823425]\n",
      "epoch:16 step:15678 [D loss: 0.728567, acc.: 46.09%] [G loss: 0.771696]\n",
      "epoch:16 step:15679 [D loss: 0.661890, acc.: 58.59%] [G loss: 0.828129]\n",
      "epoch:16 step:15680 [D loss: 0.688186, acc.: 59.38%] [G loss: 0.870538]\n",
      "epoch:16 step:15681 [D loss: 0.678964, acc.: 58.59%] [G loss: 0.787787]\n",
      "epoch:16 step:15682 [D loss: 0.679577, acc.: 57.81%] [G loss: 0.780423]\n",
      "epoch:16 step:15683 [D loss: 0.727071, acc.: 51.56%] [G loss: 0.797061]\n",
      "epoch:16 step:15684 [D loss: 0.676412, acc.: 57.81%] [G loss: 0.857180]\n",
      "epoch:16 step:15685 [D loss: 0.660618, acc.: 57.03%] [G loss: 0.856940]\n",
      "epoch:16 step:15686 [D loss: 0.632647, acc.: 62.50%] [G loss: 0.867432]\n",
      "epoch:16 step:15687 [D loss: 0.715724, acc.: 47.66%] [G loss: 0.919713]\n",
      "epoch:16 step:15688 [D loss: 0.619065, acc.: 67.97%] [G loss: 0.919644]\n",
      "epoch:16 step:15689 [D loss: 0.595656, acc.: 69.53%] [G loss: 0.896259]\n",
      "epoch:16 step:15690 [D loss: 0.569303, acc.: 75.78%] [G loss: 0.924402]\n",
      "epoch:16 step:15691 [D loss: 0.625926, acc.: 67.19%] [G loss: 0.941677]\n",
      "epoch:16 step:15692 [D loss: 0.627835, acc.: 63.28%] [G loss: 0.840931]\n",
      "epoch:16 step:15693 [D loss: 0.602869, acc.: 62.50%] [G loss: 0.922961]\n",
      "epoch:16 step:15694 [D loss: 0.591189, acc.: 71.09%] [G loss: 0.922568]\n",
      "epoch:16 step:15695 [D loss: 0.647705, acc.: 59.38%] [G loss: 0.936344]\n",
      "epoch:16 step:15696 [D loss: 0.591367, acc.: 67.19%] [G loss: 0.833305]\n",
      "epoch:16 step:15697 [D loss: 0.678035, acc.: 50.78%] [G loss: 0.934478]\n",
      "epoch:16 step:15698 [D loss: 0.512365, acc.: 76.56%] [G loss: 0.872761]\n",
      "epoch:16 step:15699 [D loss: 0.521731, acc.: 71.88%] [G loss: 0.868369]\n",
      "epoch:16 step:15700 [D loss: 0.475196, acc.: 79.69%] [G loss: 0.959253]\n",
      "epoch:16 step:15701 [D loss: 0.461425, acc.: 78.12%] [G loss: 0.926823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15702 [D loss: 0.893233, acc.: 28.91%] [G loss: 0.966316]\n",
      "epoch:16 step:15703 [D loss: 0.697064, acc.: 53.91%] [G loss: 0.999790]\n",
      "epoch:16 step:15704 [D loss: 0.625794, acc.: 71.88%] [G loss: 1.046358]\n",
      "epoch:16 step:15705 [D loss: 0.482584, acc.: 83.59%] [G loss: 0.949442]\n",
      "epoch:16 step:15706 [D loss: 0.454450, acc.: 75.00%] [G loss: 1.011920]\n",
      "epoch:16 step:15707 [D loss: 0.732632, acc.: 46.88%] [G loss: 0.970375]\n",
      "epoch:16 step:15708 [D loss: 0.767086, acc.: 38.28%] [G loss: 0.865905]\n",
      "epoch:16 step:15709 [D loss: 0.709909, acc.: 50.78%] [G loss: 0.954421]\n",
      "epoch:16 step:15710 [D loss: 0.749053, acc.: 48.44%] [G loss: 0.877609]\n",
      "epoch:16 step:15711 [D loss: 0.849624, acc.: 41.41%] [G loss: 0.897255]\n",
      "epoch:16 step:15712 [D loss: 0.632342, acc.: 69.53%] [G loss: 0.931201]\n",
      "epoch:16 step:15713 [D loss: 0.775600, acc.: 40.62%] [G loss: 1.087215]\n",
      "epoch:16 step:15714 [D loss: 0.773601, acc.: 39.06%] [G loss: 0.915784]\n",
      "epoch:16 step:15715 [D loss: 0.753151, acc.: 42.97%] [G loss: 0.992251]\n",
      "epoch:16 step:15716 [D loss: 0.648355, acc.: 60.94%] [G loss: 1.003958]\n",
      "epoch:16 step:15717 [D loss: 0.657369, acc.: 60.16%] [G loss: 0.991716]\n",
      "epoch:16 step:15718 [D loss: 0.583708, acc.: 64.84%] [G loss: 0.852983]\n",
      "epoch:16 step:15719 [D loss: 0.677724, acc.: 59.38%] [G loss: 0.990090]\n",
      "epoch:16 step:15720 [D loss: 0.668932, acc.: 57.81%] [G loss: 0.848522]\n",
      "epoch:16 step:15721 [D loss: 0.690647, acc.: 55.47%] [G loss: 0.846938]\n",
      "epoch:16 step:15722 [D loss: 0.663013, acc.: 60.16%] [G loss: 0.925714]\n",
      "epoch:16 step:15723 [D loss: 0.648381, acc.: 64.06%] [G loss: 0.899451]\n",
      "epoch:16 step:15724 [D loss: 0.601325, acc.: 70.31%] [G loss: 0.705324]\n",
      "epoch:16 step:15725 [D loss: 0.641307, acc.: 58.59%] [G loss: 0.885458]\n",
      "epoch:16 step:15726 [D loss: 0.674712, acc.: 57.03%] [G loss: 0.902281]\n",
      "epoch:16 step:15727 [D loss: 0.667450, acc.: 61.72%] [G loss: 0.842808]\n",
      "epoch:16 step:15728 [D loss: 0.635357, acc.: 57.03%] [G loss: 0.828435]\n",
      "epoch:16 step:15729 [D loss: 0.699817, acc.: 53.12%] [G loss: 0.890253]\n",
      "epoch:16 step:15730 [D loss: 0.695457, acc.: 53.12%] [G loss: 0.842021]\n",
      "epoch:16 step:15731 [D loss: 0.769075, acc.: 46.88%] [G loss: 0.790160]\n",
      "epoch:16 step:15732 [D loss: 0.702349, acc.: 57.03%] [G loss: 0.798385]\n",
      "epoch:16 step:15733 [D loss: 0.660073, acc.: 61.72%] [G loss: 0.827266]\n",
      "epoch:16 step:15734 [D loss: 0.663377, acc.: 55.47%] [G loss: 0.814761]\n",
      "epoch:16 step:15735 [D loss: 0.670915, acc.: 52.34%] [G loss: 0.827757]\n",
      "epoch:16 step:15736 [D loss: 0.651880, acc.: 62.50%] [G loss: 0.833602]\n",
      "epoch:16 step:15737 [D loss: 0.654372, acc.: 65.62%] [G loss: 0.801183]\n",
      "epoch:16 step:15738 [D loss: 0.675793, acc.: 60.16%] [G loss: 0.829172]\n",
      "epoch:16 step:15739 [D loss: 0.708287, acc.: 53.91%] [G loss: 0.762031]\n",
      "epoch:16 step:15740 [D loss: 0.688421, acc.: 53.91%] [G loss: 0.829755]\n",
      "epoch:16 step:15741 [D loss: 0.688179, acc.: 54.69%] [G loss: 0.768002]\n",
      "epoch:16 step:15742 [D loss: 0.651686, acc.: 58.59%] [G loss: 0.778761]\n",
      "epoch:16 step:15743 [D loss: 0.688587, acc.: 60.94%] [G loss: 0.770862]\n",
      "epoch:16 step:15744 [D loss: 0.606104, acc.: 70.31%] [G loss: 0.804099]\n",
      "epoch:16 step:15745 [D loss: 0.662935, acc.: 65.62%] [G loss: 0.820338]\n",
      "epoch:16 step:15746 [D loss: 0.565892, acc.: 81.25%] [G loss: 0.802351]\n",
      "epoch:16 step:15747 [D loss: 0.491942, acc.: 80.47%] [G loss: 0.801142]\n",
      "epoch:16 step:15748 [D loss: 0.526952, acc.: 77.34%] [G loss: 0.820495]\n",
      "epoch:16 step:15749 [D loss: 0.511881, acc.: 75.78%] [G loss: 0.869553]\n",
      "epoch:16 step:15750 [D loss: 0.560863, acc.: 78.91%] [G loss: 0.765214]\n",
      "epoch:16 step:15751 [D loss: 0.716319, acc.: 50.00%] [G loss: 0.835111]\n",
      "epoch:16 step:15752 [D loss: 0.729752, acc.: 49.22%] [G loss: 0.819667]\n",
      "epoch:16 step:15753 [D loss: 0.661711, acc.: 59.38%] [G loss: 0.658077]\n",
      "epoch:16 step:15754 [D loss: 0.620982, acc.: 67.97%] [G loss: 0.704770]\n",
      "epoch:16 step:15755 [D loss: 0.564553, acc.: 72.66%] [G loss: 0.888603]\n",
      "epoch:16 step:15756 [D loss: 0.474129, acc.: 82.81%] [G loss: 0.913538]\n",
      "epoch:16 step:15757 [D loss: 0.730496, acc.: 46.88%] [G loss: 0.575414]\n",
      "epoch:16 step:15758 [D loss: 0.868161, acc.: 42.19%] [G loss: 0.559988]\n",
      "epoch:16 step:15759 [D loss: 0.683379, acc.: 57.03%] [G loss: 0.927053]\n",
      "epoch:16 step:15760 [D loss: 0.660683, acc.: 58.59%] [G loss: 1.065709]\n",
      "epoch:16 step:15761 [D loss: 0.761285, acc.: 40.62%] [G loss: 0.899467]\n",
      "epoch:16 step:15762 [D loss: 0.687678, acc.: 51.56%] [G loss: 0.906122]\n",
      "epoch:16 step:15763 [D loss: 0.683389, acc.: 59.38%] [G loss: 0.943061]\n",
      "epoch:16 step:15764 [D loss: 0.808709, acc.: 30.47%] [G loss: 0.922943]\n",
      "epoch:16 step:15765 [D loss: 0.713854, acc.: 46.88%] [G loss: 0.770593]\n",
      "epoch:16 step:15766 [D loss: 0.580841, acc.: 71.09%] [G loss: 0.876276]\n",
      "epoch:16 step:15767 [D loss: 0.588059, acc.: 67.19%] [G loss: 1.043388]\n",
      "epoch:16 step:15768 [D loss: 0.691044, acc.: 59.38%] [G loss: 0.992042]\n",
      "epoch:16 step:15769 [D loss: 0.633729, acc.: 62.50%] [G loss: 1.030686]\n",
      "epoch:16 step:15770 [D loss: 0.635499, acc.: 66.41%] [G loss: 1.095546]\n",
      "epoch:16 step:15771 [D loss: 0.677229, acc.: 58.59%] [G loss: 1.094814]\n",
      "epoch:16 step:15772 [D loss: 0.724962, acc.: 53.91%] [G loss: 1.017269]\n",
      "epoch:16 step:15773 [D loss: 0.675529, acc.: 60.16%] [G loss: 0.919884]\n",
      "epoch:16 step:15774 [D loss: 0.651092, acc.: 64.06%] [G loss: 0.966359]\n",
      "epoch:16 step:15775 [D loss: 0.704779, acc.: 57.03%] [G loss: 0.924605]\n",
      "epoch:16 step:15776 [D loss: 0.701328, acc.: 55.47%] [G loss: 0.912204]\n",
      "epoch:16 step:15777 [D loss: 0.662970, acc.: 57.03%] [G loss: 0.857887]\n",
      "epoch:16 step:15778 [D loss: 0.697337, acc.: 54.69%] [G loss: 0.845191]\n",
      "epoch:16 step:15779 [D loss: 0.652480, acc.: 56.25%] [G loss: 0.914506]\n",
      "epoch:16 step:15780 [D loss: 0.644369, acc.: 60.16%] [G loss: 0.892043]\n",
      "epoch:16 step:15781 [D loss: 0.668855, acc.: 59.38%] [G loss: 0.903866]\n",
      "epoch:16 step:15782 [D loss: 0.717165, acc.: 47.66%] [G loss: 0.847406]\n",
      "epoch:16 step:15783 [D loss: 0.693077, acc.: 53.91%] [G loss: 0.759567]\n",
      "epoch:16 step:15784 [D loss: 0.664460, acc.: 59.38%] [G loss: 0.833001]\n",
      "epoch:16 step:15785 [D loss: 0.682239, acc.: 53.12%] [G loss: 0.776334]\n",
      "epoch:16 step:15786 [D loss: 0.670185, acc.: 57.03%] [G loss: 0.780075]\n",
      "epoch:16 step:15787 [D loss: 0.702579, acc.: 51.56%] [G loss: 0.832302]\n",
      "epoch:16 step:15788 [D loss: 0.608930, acc.: 67.97%] [G loss: 0.744217]\n",
      "epoch:16 step:15789 [D loss: 0.702727, acc.: 54.69%] [G loss: 0.766026]\n",
      "epoch:16 step:15790 [D loss: 0.668863, acc.: 57.03%] [G loss: 0.816008]\n",
      "epoch:16 step:15791 [D loss: 0.678327, acc.: 59.38%] [G loss: 0.807279]\n",
      "epoch:16 step:15792 [D loss: 0.571240, acc.: 73.44%] [G loss: 0.852870]\n",
      "epoch:16 step:15793 [D loss: 0.553773, acc.: 71.88%] [G loss: 0.836742]\n",
      "epoch:16 step:15794 [D loss: 0.345475, acc.: 80.47%] [G loss: 0.887460]\n",
      "epoch:16 step:15795 [D loss: 0.660962, acc.: 64.84%] [G loss: 0.959823]\n",
      "epoch:16 step:15796 [D loss: 0.730652, acc.: 55.47%] [G loss: 1.013991]\n",
      "epoch:16 step:15797 [D loss: 0.707800, acc.: 48.44%] [G loss: 0.933808]\n",
      "epoch:16 step:15798 [D loss: 0.709443, acc.: 51.56%] [G loss: 0.930393]\n",
      "epoch:16 step:15799 [D loss: 0.707384, acc.: 50.78%] [G loss: 1.071328]\n",
      "epoch:16 step:15800 [D loss: 0.636863, acc.: 64.06%] [G loss: 1.012838]\n",
      "epoch:16 step:15801 [D loss: 0.608815, acc.: 67.19%] [G loss: 0.952228]\n",
      "epoch:16 step:15802 [D loss: 0.620381, acc.: 63.28%] [G loss: 0.842879]\n",
      "epoch:16 step:15803 [D loss: 0.690715, acc.: 50.78%] [G loss: 0.956567]\n",
      "epoch:16 step:15804 [D loss: 0.701637, acc.: 53.91%] [G loss: 0.997338]\n",
      "epoch:16 step:15805 [D loss: 0.688579, acc.: 62.50%] [G loss: 0.897475]\n",
      "epoch:16 step:15806 [D loss: 0.689064, acc.: 55.47%] [G loss: 0.751718]\n",
      "epoch:16 step:15807 [D loss: 0.545395, acc.: 73.44%] [G loss: 0.729523]\n",
      "epoch:16 step:15808 [D loss: 0.600185, acc.: 66.41%] [G loss: 0.782088]\n",
      "epoch:16 step:15809 [D loss: 0.706715, acc.: 51.56%] [G loss: 0.775967]\n",
      "epoch:16 step:15810 [D loss: 0.708285, acc.: 53.12%] [G loss: 0.730282]\n",
      "epoch:16 step:15811 [D loss: 0.734662, acc.: 53.12%] [G loss: 0.720336]\n",
      "epoch:16 step:15812 [D loss: 0.777938, acc.: 40.62%] [G loss: 0.745044]\n",
      "epoch:16 step:15813 [D loss: 0.671964, acc.: 57.03%] [G loss: 0.764923]\n",
      "epoch:16 step:15814 [D loss: 0.667967, acc.: 67.19%] [G loss: 0.797640]\n",
      "epoch:16 step:15815 [D loss: 0.651889, acc.: 61.72%] [G loss: 0.771659]\n",
      "epoch:16 step:15816 [D loss: 0.643726, acc.: 60.94%] [G loss: 0.776345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15817 [D loss: 0.642128, acc.: 64.06%] [G loss: 0.730038]\n",
      "epoch:16 step:15818 [D loss: 0.683353, acc.: 51.56%] [G loss: 0.756630]\n",
      "epoch:16 step:15819 [D loss: 0.685332, acc.: 58.59%] [G loss: 0.787359]\n",
      "epoch:16 step:15820 [D loss: 0.682007, acc.: 57.03%] [G loss: 0.850958]\n",
      "epoch:16 step:15821 [D loss: 0.645199, acc.: 62.50%] [G loss: 0.889774]\n",
      "epoch:16 step:15822 [D loss: 0.691421, acc.: 55.47%] [G loss: 0.907174]\n",
      "epoch:16 step:15823 [D loss: 0.648154, acc.: 64.84%] [G loss: 0.848716]\n",
      "epoch:16 step:15824 [D loss: 0.602801, acc.: 66.41%] [G loss: 0.796636]\n",
      "epoch:16 step:15825 [D loss: 0.671196, acc.: 62.50%] [G loss: 0.744169]\n",
      "epoch:16 step:15826 [D loss: 0.657258, acc.: 57.81%] [G loss: 0.860381]\n",
      "epoch:16 step:15827 [D loss: 0.683906, acc.: 51.56%] [G loss: 0.927068]\n",
      "epoch:16 step:15828 [D loss: 0.677533, acc.: 51.56%] [G loss: 0.840934]\n",
      "epoch:16 step:15829 [D loss: 0.710063, acc.: 48.44%] [G loss: 0.731310]\n",
      "epoch:16 step:15830 [D loss: 0.759088, acc.: 39.84%] [G loss: 0.872428]\n",
      "epoch:16 step:15831 [D loss: 0.683044, acc.: 56.25%] [G loss: 0.759522]\n",
      "epoch:16 step:15832 [D loss: 0.672475, acc.: 67.19%] [G loss: 0.775165]\n",
      "epoch:16 step:15833 [D loss: 0.653642, acc.: 62.50%] [G loss: 0.792048]\n",
      "epoch:16 step:15834 [D loss: 0.654272, acc.: 60.94%] [G loss: 0.799489]\n",
      "epoch:16 step:15835 [D loss: 0.701321, acc.: 55.47%] [G loss: 0.744014]\n",
      "epoch:16 step:15836 [D loss: 0.708180, acc.: 46.09%] [G loss: 0.803984]\n",
      "epoch:16 step:15837 [D loss: 0.542291, acc.: 77.34%] [G loss: 0.751979]\n",
      "epoch:16 step:15838 [D loss: 0.686082, acc.: 53.91%] [G loss: 0.670555]\n",
      "epoch:16 step:15839 [D loss: 0.593353, acc.: 64.84%] [G loss: 0.791242]\n",
      "epoch:16 step:15840 [D loss: 0.693078, acc.: 46.88%] [G loss: 0.711359]\n",
      "epoch:16 step:15841 [D loss: 0.643983, acc.: 61.72%] [G loss: 0.754312]\n",
      "epoch:16 step:15842 [D loss: 0.604017, acc.: 69.53%] [G loss: 0.833419]\n",
      "epoch:16 step:15843 [D loss: 0.487958, acc.: 75.78%] [G loss: 0.776628]\n",
      "epoch:16 step:15844 [D loss: 0.464131, acc.: 82.03%] [G loss: 0.938229]\n",
      "epoch:16 step:15845 [D loss: 0.547306, acc.: 65.62%] [G loss: 0.906110]\n",
      "epoch:16 step:15846 [D loss: 0.567004, acc.: 69.53%] [G loss: 0.802892]\n",
      "epoch:16 step:15847 [D loss: 0.639347, acc.: 67.97%] [G loss: 0.912042]\n",
      "epoch:16 step:15848 [D loss: 0.697521, acc.: 60.94%] [G loss: 0.796082]\n",
      "epoch:16 step:15849 [D loss: 0.492456, acc.: 91.41%] [G loss: 0.863848]\n",
      "epoch:16 step:15850 [D loss: 1.022833, acc.: 20.31%] [G loss: 0.900555]\n",
      "epoch:16 step:15851 [D loss: 0.724317, acc.: 50.00%] [G loss: 0.922806]\n",
      "epoch:16 step:15852 [D loss: 0.691059, acc.: 52.34%] [G loss: 0.775521]\n",
      "epoch:16 step:15853 [D loss: 0.689039, acc.: 55.47%] [G loss: 0.982426]\n",
      "epoch:16 step:15854 [D loss: 0.780008, acc.: 37.50%] [G loss: 0.820322]\n",
      "epoch:16 step:15855 [D loss: 0.735629, acc.: 43.75%] [G loss: 0.850402]\n",
      "epoch:16 step:15856 [D loss: 0.652118, acc.: 57.03%] [G loss: 0.915439]\n",
      "epoch:16 step:15857 [D loss: 0.699481, acc.: 53.12%] [G loss: 0.951457]\n",
      "epoch:16 step:15858 [D loss: 0.652556, acc.: 55.47%] [G loss: 0.912125]\n",
      "epoch:16 step:15859 [D loss: 0.718737, acc.: 48.44%] [G loss: 0.849118]\n",
      "epoch:16 step:15860 [D loss: 0.667936, acc.: 62.50%] [G loss: 0.787413]\n",
      "epoch:16 step:15861 [D loss: 0.703786, acc.: 50.78%] [G loss: 0.873106]\n",
      "epoch:16 step:15862 [D loss: 0.639042, acc.: 63.28%] [G loss: 0.879663]\n",
      "epoch:16 step:15863 [D loss: 0.664722, acc.: 53.12%] [G loss: 0.870992]\n",
      "epoch:16 step:15864 [D loss: 0.707491, acc.: 54.69%] [G loss: 0.836406]\n",
      "epoch:16 step:15865 [D loss: 0.711782, acc.: 51.56%] [G loss: 0.826386]\n",
      "epoch:16 step:15866 [D loss: 0.705205, acc.: 57.81%] [G loss: 0.827244]\n",
      "epoch:16 step:15867 [D loss: 0.632729, acc.: 66.41%] [G loss: 0.834010]\n",
      "epoch:16 step:15868 [D loss: 0.694192, acc.: 52.34%] [G loss: 0.759980]\n",
      "epoch:16 step:15869 [D loss: 0.564563, acc.: 80.47%] [G loss: 0.863617]\n",
      "epoch:16 step:15870 [D loss: 0.503317, acc.: 81.25%] [G loss: 0.855617]\n",
      "epoch:16 step:15871 [D loss: 0.727158, acc.: 42.19%] [G loss: 0.859822]\n",
      "epoch:16 step:15872 [D loss: 0.742948, acc.: 39.06%] [G loss: 0.723033]\n",
      "epoch:16 step:15873 [D loss: 0.723176, acc.: 51.56%] [G loss: 0.800003]\n",
      "epoch:16 step:15874 [D loss: 0.716380, acc.: 48.44%] [G loss: 0.812771]\n",
      "epoch:16 step:15875 [D loss: 0.673874, acc.: 52.34%] [G loss: 0.734443]\n",
      "epoch:16 step:15876 [D loss: 0.655221, acc.: 63.28%] [G loss: 0.854180]\n",
      "epoch:16 step:15877 [D loss: 0.593490, acc.: 69.53%] [G loss: 0.857787]\n",
      "epoch:16 step:15878 [D loss: 0.589093, acc.: 71.88%] [G loss: 0.868006]\n",
      "epoch:16 step:15879 [D loss: 0.539605, acc.: 77.34%] [G loss: 0.804260]\n",
      "epoch:16 step:15880 [D loss: 0.692072, acc.: 53.12%] [G loss: 0.858257]\n",
      "epoch:16 step:15881 [D loss: 0.660312, acc.: 64.84%] [G loss: 0.831671]\n",
      "epoch:16 step:15882 [D loss: 0.634006, acc.: 64.84%] [G loss: 0.933681]\n",
      "epoch:16 step:15883 [D loss: 0.716581, acc.: 53.91%] [G loss: 0.857392]\n",
      "epoch:16 step:15884 [D loss: 0.650723, acc.: 60.94%] [G loss: 0.837347]\n",
      "epoch:16 step:15885 [D loss: 0.606405, acc.: 65.62%] [G loss: 0.823287]\n",
      "epoch:16 step:15886 [D loss: 0.669070, acc.: 56.25%] [G loss: 0.806588]\n",
      "epoch:16 step:15887 [D loss: 0.673297, acc.: 53.12%] [G loss: 0.878586]\n",
      "epoch:16 step:15888 [D loss: 0.615806, acc.: 65.62%] [G loss: 0.847343]\n",
      "epoch:16 step:15889 [D loss: 0.586712, acc.: 74.22%] [G loss: 0.821465]\n",
      "epoch:16 step:15890 [D loss: 0.617021, acc.: 67.19%] [G loss: 0.842332]\n",
      "epoch:16 step:15891 [D loss: 0.488497, acc.: 72.66%] [G loss: 0.877640]\n",
      "epoch:16 step:15892 [D loss: 0.536050, acc.: 71.09%] [G loss: 0.895635]\n",
      "epoch:16 step:15893 [D loss: 0.564616, acc.: 78.12%] [G loss: 0.823523]\n",
      "epoch:16 step:15894 [D loss: 0.663116, acc.: 60.94%] [G loss: 0.981152]\n",
      "epoch:16 step:15895 [D loss: 0.732413, acc.: 47.66%] [G loss: 0.832870]\n",
      "epoch:16 step:15896 [D loss: 0.649801, acc.: 67.19%] [G loss: 0.845241]\n",
      "epoch:16 step:15897 [D loss: 0.729520, acc.: 50.00%] [G loss: 0.876227]\n",
      "epoch:16 step:15898 [D loss: 0.663957, acc.: 56.25%] [G loss: 0.802620]\n",
      "epoch:16 step:15899 [D loss: 0.751292, acc.: 43.75%] [G loss: 0.865994]\n",
      "epoch:16 step:15900 [D loss: 0.753837, acc.: 50.00%] [G loss: 0.903512]\n",
      "epoch:16 step:15901 [D loss: 0.682351, acc.: 57.81%] [G loss: 0.904950]\n",
      "epoch:16 step:15902 [D loss: 0.614112, acc.: 71.88%] [G loss: 0.847283]\n",
      "epoch:16 step:15903 [D loss: 0.742607, acc.: 47.66%] [G loss: 0.803189]\n",
      "epoch:16 step:15904 [D loss: 0.324293, acc.: 86.72%] [G loss: 0.897239]\n",
      "epoch:16 step:15905 [D loss: 0.686453, acc.: 56.25%] [G loss: 0.940678]\n",
      "epoch:16 step:15906 [D loss: 0.618005, acc.: 67.19%] [G loss: 0.923848]\n",
      "epoch:16 step:15907 [D loss: 0.691382, acc.: 56.25%] [G loss: 0.855757]\n",
      "epoch:16 step:15908 [D loss: 0.588078, acc.: 71.88%] [G loss: 0.794913]\n",
      "epoch:16 step:15909 [D loss: 0.481673, acc.: 82.81%] [G loss: 0.927292]\n",
      "epoch:16 step:15910 [D loss: 0.628334, acc.: 66.41%] [G loss: 0.891623]\n",
      "epoch:16 step:15911 [D loss: 0.704113, acc.: 50.78%] [G loss: 0.818724]\n",
      "epoch:16 step:15912 [D loss: 0.458738, acc.: 78.91%] [G loss: 0.914646]\n",
      "epoch:16 step:15913 [D loss: 0.458122, acc.: 74.22%] [G loss: 1.026457]\n",
      "epoch:16 step:15914 [D loss: 0.599746, acc.: 73.44%] [G loss: 0.589361]\n",
      "epoch:16 step:15915 [D loss: 0.649348, acc.: 62.50%] [G loss: 0.946057]\n",
      "epoch:16 step:15916 [D loss: 0.584407, acc.: 71.09%] [G loss: 0.883798]\n",
      "epoch:16 step:15917 [D loss: 0.658496, acc.: 53.12%] [G loss: 0.845067]\n",
      "epoch:16 step:15918 [D loss: 0.578270, acc.: 57.81%] [G loss: 0.926995]\n",
      "epoch:16 step:15919 [D loss: 0.297265, acc.: 89.06%] [G loss: 0.984242]\n",
      "epoch:16 step:15920 [D loss: 0.677364, acc.: 60.94%] [G loss: 0.986896]\n",
      "epoch:16 step:15921 [D loss: 0.504056, acc.: 75.78%] [G loss: 1.089654]\n",
      "epoch:16 step:15922 [D loss: 0.501900, acc.: 82.03%] [G loss: 1.118233]\n",
      "epoch:16 step:15923 [D loss: 0.591226, acc.: 71.09%] [G loss: 0.897389]\n",
      "epoch:16 step:15924 [D loss: 0.722932, acc.: 57.81%] [G loss: 0.879355]\n",
      "epoch:16 step:15925 [D loss: 0.508319, acc.: 78.91%] [G loss: 0.930894]\n",
      "epoch:16 step:15926 [D loss: 0.475274, acc.: 80.47%] [G loss: 1.034355]\n",
      "epoch:16 step:15927 [D loss: 0.434332, acc.: 88.28%] [G loss: 1.006282]\n",
      "epoch:16 step:15928 [D loss: 0.217769, acc.: 96.88%] [G loss: 0.997855]\n",
      "epoch:16 step:15929 [D loss: 0.224098, acc.: 93.75%] [G loss: 1.063140]\n",
      "epoch:17 step:15930 [D loss: 0.762122, acc.: 54.69%] [G loss: 1.127068]\n",
      "epoch:17 step:15931 [D loss: 0.736143, acc.: 55.47%] [G loss: 1.028768]\n",
      "epoch:17 step:15932 [D loss: 0.831502, acc.: 39.06%] [G loss: 0.865597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15933 [D loss: 0.715729, acc.: 52.34%] [G loss: 1.170577]\n",
      "epoch:17 step:15934 [D loss: 0.654070, acc.: 58.59%] [G loss: 0.850251]\n",
      "epoch:17 step:15935 [D loss: 0.709647, acc.: 52.34%] [G loss: 0.759263]\n",
      "epoch:17 step:15936 [D loss: 0.660326, acc.: 59.38%] [G loss: 0.795009]\n",
      "epoch:17 step:15937 [D loss: 0.536571, acc.: 75.78%] [G loss: 1.057367]\n",
      "epoch:17 step:15938 [D loss: 0.651716, acc.: 67.19%] [G loss: 0.883946]\n",
      "epoch:17 step:15939 [D loss: 0.800389, acc.: 57.03%] [G loss: 0.809555]\n",
      "epoch:17 step:15940 [D loss: 0.685220, acc.: 59.38%] [G loss: 0.991683]\n",
      "epoch:17 step:15941 [D loss: 0.929048, acc.: 51.56%] [G loss: 1.727850]\n",
      "epoch:17 step:15942 [D loss: 0.636856, acc.: 59.38%] [G loss: 2.086366]\n",
      "epoch:17 step:15943 [D loss: 0.645064, acc.: 60.94%] [G loss: 1.443412]\n",
      "epoch:17 step:15944 [D loss: 0.698245, acc.: 57.03%] [G loss: 0.889112]\n",
      "epoch:17 step:15945 [D loss: 0.712311, acc.: 52.34%] [G loss: 1.020745]\n",
      "epoch:17 step:15946 [D loss: 0.830288, acc.: 34.38%] [G loss: 0.918168]\n",
      "epoch:17 step:15947 [D loss: 0.798243, acc.: 36.72%] [G loss: 0.716622]\n",
      "epoch:17 step:15948 [D loss: 0.845272, acc.: 34.38%] [G loss: 0.824567]\n",
      "epoch:17 step:15949 [D loss: 0.776787, acc.: 45.31%] [G loss: 0.749712]\n",
      "epoch:17 step:15950 [D loss: 0.738818, acc.: 53.91%] [G loss: 1.088896]\n",
      "epoch:17 step:15951 [D loss: 0.748633, acc.: 44.53%] [G loss: 0.779341]\n",
      "epoch:17 step:15952 [D loss: 0.669755, acc.: 57.81%] [G loss: 0.921608]\n",
      "epoch:17 step:15953 [D loss: 0.700610, acc.: 50.78%] [G loss: 0.861551]\n",
      "epoch:17 step:15954 [D loss: 0.642556, acc.: 64.06%] [G loss: 0.967559]\n",
      "epoch:17 step:15955 [D loss: 0.631426, acc.: 65.62%] [G loss: 0.867292]\n",
      "epoch:17 step:15956 [D loss: 0.633784, acc.: 68.75%] [G loss: 2.137109]\n",
      "epoch:17 step:15957 [D loss: 0.634242, acc.: 64.06%] [G loss: 0.908069]\n",
      "epoch:17 step:15958 [D loss: 0.613473, acc.: 69.53%] [G loss: 0.959295]\n",
      "epoch:17 step:15959 [D loss: 0.605211, acc.: 71.88%] [G loss: 0.996726]\n",
      "epoch:17 step:15960 [D loss: 0.574878, acc.: 77.34%] [G loss: 1.027296]\n",
      "epoch:17 step:15961 [D loss: 0.508894, acc.: 82.81%] [G loss: 1.109855]\n",
      "epoch:17 step:15962 [D loss: 0.458825, acc.: 88.28%] [G loss: 1.195527]\n",
      "epoch:17 step:15963 [D loss: 0.501931, acc.: 82.03%] [G loss: 0.983068]\n",
      "epoch:17 step:15964 [D loss: 0.424925, acc.: 85.16%] [G loss: 1.394540]\n",
      "epoch:17 step:15965 [D loss: 0.396984, acc.: 83.59%] [G loss: 1.149650]\n",
      "epoch:17 step:15966 [D loss: 0.805513, acc.: 41.41%] [G loss: 1.202193]\n",
      "epoch:17 step:15967 [D loss: 1.187896, acc.: 35.16%] [G loss: 0.870141]\n",
      "epoch:17 step:15968 [D loss: 0.843865, acc.: 30.47%] [G loss: 0.755442]\n",
      "epoch:17 step:15969 [D loss: 0.746521, acc.: 50.78%] [G loss: 0.670696]\n",
      "epoch:17 step:15970 [D loss: 0.715518, acc.: 47.66%] [G loss: 0.638381]\n",
      "epoch:17 step:15971 [D loss: 0.705643, acc.: 53.12%] [G loss: 0.644094]\n",
      "epoch:17 step:15972 [D loss: 0.642673, acc.: 59.38%] [G loss: 0.664403]\n",
      "epoch:17 step:15973 [D loss: 0.687175, acc.: 53.91%] [G loss: 0.761984]\n",
      "epoch:17 step:15974 [D loss: 0.692828, acc.: 47.66%] [G loss: 0.710381]\n",
      "epoch:17 step:15975 [D loss: 0.638858, acc.: 57.03%] [G loss: 0.756287]\n",
      "epoch:17 step:15976 [D loss: 0.689721, acc.: 47.66%] [G loss: 0.758422]\n",
      "epoch:17 step:15977 [D loss: 0.750008, acc.: 44.53%] [G loss: 0.772487]\n",
      "epoch:17 step:15978 [D loss: 0.711650, acc.: 50.00%] [G loss: 0.816826]\n",
      "epoch:17 step:15979 [D loss: 0.635880, acc.: 67.19%] [G loss: 0.953996]\n",
      "epoch:17 step:15980 [D loss: 0.662161, acc.: 56.25%] [G loss: 0.841788]\n",
      "epoch:17 step:15981 [D loss: 0.656399, acc.: 57.03%] [G loss: 0.837867]\n",
      "epoch:17 step:15982 [D loss: 0.622785, acc.: 68.75%] [G loss: 0.823255]\n",
      "epoch:17 step:15983 [D loss: 0.683757, acc.: 57.81%] [G loss: 0.857696]\n",
      "epoch:17 step:15984 [D loss: 0.699283, acc.: 54.69%] [G loss: 0.871044]\n",
      "epoch:17 step:15985 [D loss: 0.683038, acc.: 60.16%] [G loss: 0.747591]\n",
      "epoch:17 step:15986 [D loss: 0.700747, acc.: 54.69%] [G loss: 0.789056]\n",
      "epoch:17 step:15987 [D loss: 0.720190, acc.: 48.44%] [G loss: 0.817006]\n",
      "epoch:17 step:15988 [D loss: 0.696120, acc.: 50.00%] [G loss: 0.792132]\n",
      "epoch:17 step:15989 [D loss: 0.669584, acc.: 61.72%] [G loss: 0.764621]\n",
      "epoch:17 step:15990 [D loss: 0.670067, acc.: 60.94%] [G loss: 0.824042]\n",
      "epoch:17 step:15991 [D loss: 0.746353, acc.: 45.31%] [G loss: 0.789536]\n",
      "epoch:17 step:15992 [D loss: 0.658248, acc.: 61.72%] [G loss: 0.835561]\n",
      "epoch:17 step:15993 [D loss: 0.644693, acc.: 61.72%] [G loss: 0.840822]\n",
      "epoch:17 step:15994 [D loss: 0.684306, acc.: 58.59%] [G loss: 0.933894]\n",
      "epoch:17 step:15995 [D loss: 0.652528, acc.: 60.16%] [G loss: 0.778578]\n",
      "epoch:17 step:15996 [D loss: 0.681113, acc.: 60.16%] [G loss: 0.903076]\n",
      "epoch:17 step:15997 [D loss: 0.611916, acc.: 68.75%] [G loss: 0.823664]\n",
      "epoch:17 step:15998 [D loss: 0.627683, acc.: 64.84%] [G loss: 0.810610]\n",
      "epoch:17 step:15999 [D loss: 0.615111, acc.: 67.19%] [G loss: 0.851348]\n",
      "epoch:17 step:16000 [D loss: 0.674031, acc.: 64.06%] [G loss: 0.818855]\n",
      "epoch:17 step:16001 [D loss: 0.688727, acc.: 57.81%] [G loss: 0.792445]\n",
      "epoch:17 step:16002 [D loss: 0.659250, acc.: 60.94%] [G loss: 0.750420]\n",
      "epoch:17 step:16003 [D loss: 0.701882, acc.: 49.22%] [G loss: 0.780439]\n",
      "epoch:17 step:16004 [D loss: 0.606803, acc.: 69.53%] [G loss: 0.732052]\n",
      "epoch:17 step:16005 [D loss: 0.559665, acc.: 71.88%] [G loss: 0.833993]\n",
      "epoch:17 step:16006 [D loss: 0.526397, acc.: 84.38%] [G loss: 0.819045]\n",
      "epoch:17 step:16007 [D loss: 0.749142, acc.: 50.00%] [G loss: 0.779677]\n",
      "epoch:17 step:16008 [D loss: 0.686266, acc.: 60.16%] [G loss: 0.781547]\n",
      "epoch:17 step:16009 [D loss: 0.657513, acc.: 64.06%] [G loss: 0.770661]\n",
      "epoch:17 step:16010 [D loss: 0.653595, acc.: 64.06%] [G loss: 0.832846]\n",
      "epoch:17 step:16011 [D loss: 0.621684, acc.: 68.75%] [G loss: 0.811756]\n",
      "epoch:17 step:16012 [D loss: 0.670689, acc.: 61.72%] [G loss: 0.790564]\n",
      "epoch:17 step:16013 [D loss: 0.649983, acc.: 60.16%] [G loss: 0.797838]\n",
      "epoch:17 step:16014 [D loss: 0.567742, acc.: 71.09%] [G loss: 0.714732]\n",
      "epoch:17 step:16015 [D loss: 0.657361, acc.: 61.72%] [G loss: 0.787738]\n",
      "epoch:17 step:16016 [D loss: 0.692683, acc.: 54.69%] [G loss: 0.859278]\n",
      "epoch:17 step:16017 [D loss: 0.653038, acc.: 64.06%] [G loss: 0.828888]\n",
      "epoch:17 step:16018 [D loss: 0.564592, acc.: 82.03%] [G loss: 0.816400]\n",
      "epoch:17 step:16019 [D loss: 0.666549, acc.: 53.91%] [G loss: 0.582543]\n",
      "epoch:17 step:16020 [D loss: 0.710746, acc.: 43.75%] [G loss: 0.727076]\n",
      "epoch:17 step:16021 [D loss: 0.626681, acc.: 66.41%] [G loss: 0.788565]\n",
      "epoch:17 step:16022 [D loss: 0.638963, acc.: 60.94%] [G loss: 0.824849]\n",
      "epoch:17 step:16023 [D loss: 0.575047, acc.: 71.88%] [G loss: 0.870704]\n",
      "epoch:17 step:16024 [D loss: 0.682357, acc.: 57.81%] [G loss: 0.891654]\n",
      "epoch:17 step:16025 [D loss: 0.697196, acc.: 54.69%] [G loss: 0.806398]\n",
      "epoch:17 step:16026 [D loss: 0.655884, acc.: 58.59%] [G loss: 0.824930]\n",
      "epoch:17 step:16027 [D loss: 0.596251, acc.: 75.00%] [G loss: 0.834290]\n",
      "epoch:17 step:16028 [D loss: 0.574923, acc.: 75.00%] [G loss: 0.851113]\n",
      "epoch:17 step:16029 [D loss: 0.530457, acc.: 75.78%] [G loss: 0.898902]\n",
      "epoch:17 step:16030 [D loss: 0.635551, acc.: 66.41%] [G loss: 0.870819]\n",
      "epoch:17 step:16031 [D loss: 0.625532, acc.: 64.06%] [G loss: 0.860827]\n",
      "epoch:17 step:16032 [D loss: 0.636967, acc.: 63.28%] [G loss: 0.792217]\n",
      "epoch:17 step:16033 [D loss: 0.649750, acc.: 61.72%] [G loss: 0.539094]\n",
      "epoch:17 step:16034 [D loss: 0.412060, acc.: 83.59%] [G loss: 0.931422]\n",
      "epoch:17 step:16035 [D loss: 0.549281, acc.: 78.12%] [G loss: 0.976405]\n",
      "epoch:17 step:16036 [D loss: 0.551537, acc.: 69.53%] [G loss: 0.962509]\n",
      "epoch:17 step:16037 [D loss: 0.742637, acc.: 57.03%] [G loss: 1.016866]\n",
      "epoch:17 step:16038 [D loss: 0.643388, acc.: 64.84%] [G loss: 1.016831]\n",
      "epoch:17 step:16039 [D loss: 0.596944, acc.: 71.09%] [G loss: 1.166172]\n",
      "epoch:17 step:16040 [D loss: 0.718242, acc.: 51.56%] [G loss: 0.993263]\n",
      "epoch:17 step:16041 [D loss: 0.557895, acc.: 75.78%] [G loss: 0.949486]\n",
      "epoch:17 step:16042 [D loss: 0.666742, acc.: 56.25%] [G loss: 0.921537]\n",
      "epoch:17 step:16043 [D loss: 0.647396, acc.: 57.03%] [G loss: 0.924223]\n",
      "epoch:17 step:16044 [D loss: 0.621527, acc.: 67.19%] [G loss: 0.787154]\n",
      "epoch:17 step:16045 [D loss: 0.607004, acc.: 71.09%] [G loss: 0.858002]\n",
      "epoch:17 step:16046 [D loss: 0.717670, acc.: 60.16%] [G loss: 0.877419]\n",
      "epoch:17 step:16047 [D loss: 0.445658, acc.: 79.69%] [G loss: 0.942364]\n",
      "epoch:17 step:16048 [D loss: 0.373733, acc.: 85.16%] [G loss: 1.064530]\n",
      "epoch:17 step:16049 [D loss: 0.851291, acc.: 32.03%] [G loss: 0.823384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16050 [D loss: 0.792770, acc.: 41.41%] [G loss: 1.087340]\n",
      "epoch:17 step:16051 [D loss: 0.720381, acc.: 51.56%] [G loss: 1.152921]\n",
      "epoch:17 step:16052 [D loss: 0.724617, acc.: 51.56%] [G loss: 1.114110]\n",
      "epoch:17 step:16053 [D loss: 0.625467, acc.: 61.72%] [G loss: 1.101405]\n",
      "epoch:17 step:16054 [D loss: 0.692463, acc.: 51.56%] [G loss: 1.077073]\n",
      "epoch:17 step:16055 [D loss: 0.599029, acc.: 65.62%] [G loss: 1.165638]\n",
      "epoch:17 step:16056 [D loss: 0.707371, acc.: 57.81%] [G loss: 0.932772]\n",
      "epoch:17 step:16057 [D loss: 0.773700, acc.: 47.66%] [G loss: 1.013225]\n",
      "epoch:17 step:16058 [D loss: 0.603161, acc.: 64.06%] [G loss: 1.001286]\n",
      "epoch:17 step:16059 [D loss: 0.635380, acc.: 63.28%] [G loss: 1.124747]\n",
      "epoch:17 step:16060 [D loss: 0.634321, acc.: 60.16%] [G loss: 1.136414]\n",
      "epoch:17 step:16061 [D loss: 0.668888, acc.: 60.16%] [G loss: 1.004024]\n",
      "epoch:17 step:16062 [D loss: 0.686863, acc.: 57.81%] [G loss: 1.035932]\n",
      "epoch:17 step:16063 [D loss: 0.667666, acc.: 57.81%] [G loss: 1.025689]\n",
      "epoch:17 step:16064 [D loss: 0.672639, acc.: 59.38%] [G loss: 1.010328]\n",
      "epoch:17 step:16065 [D loss: 0.678975, acc.: 57.81%] [G loss: 1.015051]\n",
      "epoch:17 step:16066 [D loss: 0.667013, acc.: 58.59%] [G loss: 0.953007]\n",
      "epoch:17 step:16067 [D loss: 0.702006, acc.: 48.44%] [G loss: 0.932202]\n",
      "epoch:17 step:16068 [D loss: 0.587210, acc.: 68.75%] [G loss: 1.011754]\n",
      "epoch:17 step:16069 [D loss: 0.659243, acc.: 63.28%] [G loss: 0.985202]\n",
      "epoch:17 step:16070 [D loss: 0.771499, acc.: 45.31%] [G loss: 0.872233]\n",
      "epoch:17 step:16071 [D loss: 0.750077, acc.: 46.88%] [G loss: 0.948290]\n",
      "epoch:17 step:16072 [D loss: 0.720407, acc.: 47.66%] [G loss: 0.863609]\n",
      "epoch:17 step:16073 [D loss: 0.661280, acc.: 57.81%] [G loss: 0.916559]\n",
      "epoch:17 step:16074 [D loss: 0.642449, acc.: 58.59%] [G loss: 0.968647]\n",
      "epoch:17 step:16075 [D loss: 0.647548, acc.: 56.25%] [G loss: 0.887112]\n",
      "epoch:17 step:16076 [D loss: 0.644240, acc.: 64.06%] [G loss: 0.892457]\n",
      "epoch:17 step:16077 [D loss: 0.642276, acc.: 62.50%] [G loss: 0.788129]\n",
      "epoch:17 step:16078 [D loss: 0.633839, acc.: 64.84%] [G loss: 0.842948]\n",
      "epoch:17 step:16079 [D loss: 0.561608, acc.: 74.22%] [G loss: 0.850026]\n",
      "epoch:17 step:16080 [D loss: 0.540441, acc.: 73.44%] [G loss: 0.868915]\n",
      "epoch:17 step:16081 [D loss: 0.655861, acc.: 60.94%] [G loss: 0.875463]\n",
      "epoch:17 step:16082 [D loss: 0.722467, acc.: 50.00%] [G loss: 0.772499]\n",
      "epoch:17 step:16083 [D loss: 0.654332, acc.: 59.38%] [G loss: 0.804074]\n",
      "epoch:17 step:16084 [D loss: 0.627332, acc.: 63.28%] [G loss: 0.847526]\n",
      "epoch:17 step:16085 [D loss: 0.631184, acc.: 68.75%] [G loss: 0.798282]\n",
      "epoch:17 step:16086 [D loss: 0.677133, acc.: 59.38%] [G loss: 0.832863]\n",
      "epoch:17 step:16087 [D loss: 0.677243, acc.: 53.91%] [G loss: 0.781625]\n",
      "epoch:17 step:16088 [D loss: 0.618260, acc.: 67.97%] [G loss: 0.925310]\n",
      "epoch:17 step:16089 [D loss: 0.743996, acc.: 48.44%] [G loss: 0.821939]\n",
      "epoch:17 step:16090 [D loss: 0.701522, acc.: 58.59%] [G loss: 0.885130]\n",
      "epoch:17 step:16091 [D loss: 0.691312, acc.: 55.47%] [G loss: 0.772014]\n",
      "epoch:17 step:16092 [D loss: 0.685128, acc.: 54.69%] [G loss: 0.763975]\n",
      "epoch:17 step:16093 [D loss: 0.699651, acc.: 57.81%] [G loss: 0.795474]\n",
      "epoch:17 step:16094 [D loss: 0.689433, acc.: 58.59%] [G loss: 0.799423]\n",
      "epoch:17 step:16095 [D loss: 0.643653, acc.: 64.06%] [G loss: 0.834257]\n",
      "epoch:17 step:16096 [D loss: 0.638875, acc.: 57.81%] [G loss: 0.789653]\n",
      "epoch:17 step:16097 [D loss: 0.571796, acc.: 75.78%] [G loss: 0.766699]\n",
      "epoch:17 step:16098 [D loss: 0.699054, acc.: 53.91%] [G loss: 0.909391]\n",
      "epoch:17 step:16099 [D loss: 0.650065, acc.: 60.94%] [G loss: 0.801823]\n",
      "epoch:17 step:16100 [D loss: 0.658379, acc.: 60.94%] [G loss: 0.876706]\n",
      "epoch:17 step:16101 [D loss: 0.631888, acc.: 69.53%] [G loss: 0.912386]\n",
      "epoch:17 step:16102 [D loss: 0.645145, acc.: 64.84%] [G loss: 0.827333]\n",
      "epoch:17 step:16103 [D loss: 0.745537, acc.: 49.22%] [G loss: 0.870182]\n",
      "epoch:17 step:16104 [D loss: 0.778016, acc.: 46.88%] [G loss: 0.816709]\n",
      "epoch:17 step:16105 [D loss: 0.655749, acc.: 61.72%] [G loss: 0.758274]\n",
      "epoch:17 step:16106 [D loss: 0.710837, acc.: 45.31%] [G loss: 0.726627]\n",
      "epoch:17 step:16107 [D loss: 0.679651, acc.: 59.38%] [G loss: 0.820885]\n",
      "epoch:17 step:16108 [D loss: 0.719952, acc.: 51.56%] [G loss: 0.811678]\n",
      "epoch:17 step:16109 [D loss: 0.688566, acc.: 53.91%] [G loss: 0.745291]\n",
      "epoch:17 step:16110 [D loss: 0.646759, acc.: 60.16%] [G loss: 0.744173]\n",
      "epoch:17 step:16111 [D loss: 0.688030, acc.: 59.38%] [G loss: 0.795779]\n",
      "epoch:17 step:16112 [D loss: 0.679015, acc.: 56.25%] [G loss: 0.804440]\n",
      "epoch:17 step:16113 [D loss: 0.614927, acc.: 67.19%] [G loss: 0.819642]\n",
      "epoch:17 step:16114 [D loss: 0.650249, acc.: 60.16%] [G loss: 0.747452]\n",
      "epoch:17 step:16115 [D loss: 0.765313, acc.: 46.09%] [G loss: 0.809253]\n",
      "epoch:17 step:16116 [D loss: 0.617161, acc.: 63.28%] [G loss: 0.780460]\n",
      "epoch:17 step:16117 [D loss: 0.655357, acc.: 63.28%] [G loss: 0.860128]\n",
      "epoch:17 step:16118 [D loss: 0.698970, acc.: 56.25%] [G loss: 0.822737]\n",
      "epoch:17 step:16119 [D loss: 0.649501, acc.: 64.84%] [G loss: 0.876027]\n",
      "epoch:17 step:16120 [D loss: 0.638577, acc.: 63.28%] [G loss: 0.723249]\n",
      "epoch:17 step:16121 [D loss: 0.640994, acc.: 62.50%] [G loss: 0.868851]\n",
      "epoch:17 step:16122 [D loss: 0.626212, acc.: 64.84%] [G loss: 0.820970]\n",
      "epoch:17 step:16123 [D loss: 0.726020, acc.: 47.66%] [G loss: 0.570157]\n",
      "epoch:17 step:16124 [D loss: 0.660231, acc.: 58.59%] [G loss: 0.782374]\n",
      "epoch:17 step:16125 [D loss: 0.728539, acc.: 45.31%] [G loss: 0.698819]\n",
      "epoch:17 step:16126 [D loss: 0.651922, acc.: 64.06%] [G loss: 0.738887]\n",
      "epoch:17 step:16127 [D loss: 0.749366, acc.: 43.75%] [G loss: 0.870827]\n",
      "epoch:17 step:16128 [D loss: 0.702680, acc.: 53.12%] [G loss: 0.854332]\n",
      "epoch:17 step:16129 [D loss: 0.648979, acc.: 60.16%] [G loss: 0.791039]\n",
      "epoch:17 step:16130 [D loss: 0.565533, acc.: 77.34%] [G loss: 0.829736]\n",
      "epoch:17 step:16131 [D loss: 0.730216, acc.: 53.91%] [G loss: 0.920240]\n",
      "epoch:17 step:16132 [D loss: 0.704573, acc.: 53.12%] [G loss: 0.860613]\n",
      "epoch:17 step:16133 [D loss: 0.590417, acc.: 67.19%] [G loss: 0.894799]\n",
      "epoch:17 step:16134 [D loss: 0.636794, acc.: 67.97%] [G loss: 0.958675]\n",
      "epoch:17 step:16135 [D loss: 0.660009, acc.: 59.38%] [G loss: 0.897031]\n",
      "epoch:17 step:16136 [D loss: 0.414714, acc.: 75.78%] [G loss: 0.964711]\n",
      "epoch:17 step:16137 [D loss: 0.667745, acc.: 59.38%] [G loss: 0.854599]\n",
      "epoch:17 step:16138 [D loss: 0.643701, acc.: 64.06%] [G loss: 0.825897]\n",
      "epoch:17 step:16139 [D loss: 0.685237, acc.: 55.47%] [G loss: 0.614774]\n",
      "epoch:17 step:16140 [D loss: 0.703439, acc.: 53.12%] [G loss: 0.855097]\n",
      "epoch:17 step:16141 [D loss: 0.629917, acc.: 69.53%] [G loss: 0.720228]\n",
      "epoch:17 step:16142 [D loss: 0.624426, acc.: 67.19%] [G loss: 0.865063]\n",
      "epoch:17 step:16143 [D loss: 0.688681, acc.: 56.25%] [G loss: 0.841012]\n",
      "epoch:17 step:16144 [D loss: 0.677129, acc.: 58.59%] [G loss: 1.011591]\n",
      "epoch:17 step:16145 [D loss: 0.553519, acc.: 74.22%] [G loss: 1.022983]\n",
      "epoch:17 step:16146 [D loss: 1.131880, acc.: 36.72%] [G loss: 1.035054]\n",
      "epoch:17 step:16147 [D loss: 0.721071, acc.: 53.12%] [G loss: 1.205714]\n",
      "epoch:17 step:16148 [D loss: 0.750788, acc.: 49.22%] [G loss: 1.074612]\n",
      "epoch:17 step:16149 [D loss: 0.384716, acc.: 93.75%] [G loss: 1.128113]\n",
      "epoch:17 step:16150 [D loss: 0.307742, acc.: 90.62%] [G loss: 1.160129]\n",
      "epoch:17 step:16151 [D loss: 0.372241, acc.: 92.19%] [G loss: 1.440276]\n",
      "epoch:17 step:16152 [D loss: 0.415032, acc.: 85.94%] [G loss: 0.958644]\n",
      "epoch:17 step:16153 [D loss: 0.634572, acc.: 60.94%] [G loss: 1.038854]\n",
      "epoch:17 step:16154 [D loss: 0.792256, acc.: 50.00%] [G loss: 3.339257]\n",
      "epoch:17 step:16155 [D loss: 0.644914, acc.: 64.06%] [G loss: 1.060531]\n",
      "epoch:17 step:16156 [D loss: 0.519437, acc.: 77.34%] [G loss: 0.852809]\n",
      "epoch:17 step:16157 [D loss: 0.594301, acc.: 67.97%] [G loss: 0.991768]\n",
      "epoch:17 step:16158 [D loss: 0.645464, acc.: 65.62%] [G loss: 0.844161]\n",
      "epoch:17 step:16159 [D loss: 0.390667, acc.: 79.69%] [G loss: 1.571796]\n",
      "epoch:17 step:16160 [D loss: 0.362762, acc.: 80.47%] [G loss: 1.078202]\n",
      "epoch:17 step:16161 [D loss: 0.341775, acc.: 86.72%] [G loss: 0.875147]\n",
      "epoch:17 step:16162 [D loss: 0.794166, acc.: 42.19%] [G loss: 1.011484]\n",
      "epoch:17 step:16163 [D loss: 0.641034, acc.: 57.81%] [G loss: 0.986566]\n",
      "epoch:17 step:16164 [D loss: 0.682934, acc.: 57.03%] [G loss: 1.151754]\n",
      "epoch:17 step:16165 [D loss: 0.734562, acc.: 51.56%] [G loss: 1.013013]\n",
      "epoch:17 step:16166 [D loss: 0.715865, acc.: 53.91%] [G loss: 1.130010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16167 [D loss: 0.649950, acc.: 64.84%] [G loss: 1.017730]\n",
      "epoch:17 step:16168 [D loss: 0.805349, acc.: 46.09%] [G loss: 0.927203]\n",
      "epoch:17 step:16169 [D loss: 0.679878, acc.: 56.25%] [G loss: 0.795630]\n",
      "epoch:17 step:16170 [D loss: 0.755611, acc.: 38.28%] [G loss: 0.825513]\n",
      "epoch:17 step:16171 [D loss: 0.655113, acc.: 61.72%] [G loss: 1.034788]\n",
      "epoch:17 step:16172 [D loss: 0.625334, acc.: 64.84%] [G loss: 1.066190]\n",
      "epoch:17 step:16173 [D loss: 0.648552, acc.: 62.50%] [G loss: 0.906979]\n",
      "epoch:17 step:16174 [D loss: 0.618483, acc.: 69.53%] [G loss: 1.105253]\n",
      "epoch:17 step:16175 [D loss: 0.699677, acc.: 50.78%] [G loss: 1.168664]\n",
      "epoch:17 step:16176 [D loss: 0.615813, acc.: 67.97%] [G loss: 1.117401]\n",
      "epoch:17 step:16177 [D loss: 0.565225, acc.: 74.22%] [G loss: 1.092374]\n",
      "epoch:17 step:16178 [D loss: 0.667338, acc.: 57.03%] [G loss: 1.036549]\n",
      "epoch:17 step:16179 [D loss: 0.533451, acc.: 73.44%] [G loss: 1.220311]\n",
      "epoch:17 step:16180 [D loss: 0.667433, acc.: 56.25%] [G loss: 1.136231]\n",
      "epoch:17 step:16181 [D loss: 0.600619, acc.: 64.84%] [G loss: 0.984528]\n",
      "epoch:17 step:16182 [D loss: 0.614009, acc.: 69.53%] [G loss: 1.054285]\n",
      "epoch:17 step:16183 [D loss: 0.750800, acc.: 46.88%] [G loss: 0.815224]\n",
      "epoch:17 step:16184 [D loss: 0.931895, acc.: 31.25%] [G loss: 0.772089]\n",
      "epoch:17 step:16185 [D loss: 0.816675, acc.: 36.72%] [G loss: 0.766853]\n",
      "epoch:17 step:16186 [D loss: 0.645346, acc.: 57.81%] [G loss: 0.800413]\n",
      "epoch:17 step:16187 [D loss: 0.633745, acc.: 61.72%] [G loss: 0.853215]\n",
      "epoch:17 step:16188 [D loss: 0.746133, acc.: 38.28%] [G loss: 0.749159]\n",
      "epoch:17 step:16189 [D loss: 0.702409, acc.: 50.00%] [G loss: 0.725707]\n",
      "epoch:17 step:16190 [D loss: 0.666966, acc.: 57.03%] [G loss: 0.744119]\n",
      "epoch:17 step:16191 [D loss: 0.637040, acc.: 66.41%] [G loss: 0.910091]\n",
      "epoch:17 step:16192 [D loss: 0.627287, acc.: 66.41%] [G loss: 0.814566]\n",
      "epoch:17 step:16193 [D loss: 0.602759, acc.: 74.22%] [G loss: 0.814502]\n",
      "epoch:17 step:16194 [D loss: 0.669638, acc.: 56.25%] [G loss: 0.815170]\n",
      "epoch:17 step:16195 [D loss: 0.663704, acc.: 58.59%] [G loss: 0.801148]\n",
      "epoch:17 step:16196 [D loss: 0.693472, acc.: 48.44%] [G loss: 0.799574]\n",
      "epoch:17 step:16197 [D loss: 0.662318, acc.: 57.03%] [G loss: 0.924712]\n",
      "epoch:17 step:16198 [D loss: 0.610565, acc.: 67.97%] [G loss: 0.873869]\n",
      "epoch:17 step:16199 [D loss: 0.631995, acc.: 64.84%] [G loss: 0.781831]\n",
      "epoch:17 step:16200 [D loss: 0.555095, acc.: 74.22%] [G loss: 0.957241]\n",
      "epoch:17 step:16201 [D loss: 0.604697, acc.: 67.97%] [G loss: 0.982500]\n",
      "epoch:17 step:16202 [D loss: 0.592019, acc.: 76.56%] [G loss: 0.994394]\n",
      "epoch:17 step:16203 [D loss: 0.600666, acc.: 67.97%] [G loss: 0.893044]\n",
      "epoch:17 step:16204 [D loss: 0.604637, acc.: 64.84%] [G loss: 0.932823]\n",
      "epoch:17 step:16205 [D loss: 0.562642, acc.: 73.44%] [G loss: 1.101776]\n",
      "epoch:17 step:16206 [D loss: 0.648004, acc.: 64.06%] [G loss: 0.838604]\n",
      "epoch:17 step:16207 [D loss: 0.737222, acc.: 48.44%] [G loss: 0.704249]\n",
      "epoch:17 step:16208 [D loss: 0.691142, acc.: 60.16%] [G loss: 0.910436]\n",
      "epoch:17 step:16209 [D loss: 0.718937, acc.: 53.12%] [G loss: 0.839909]\n",
      "epoch:17 step:16210 [D loss: 0.743783, acc.: 41.41%] [G loss: 0.717157]\n",
      "epoch:17 step:16211 [D loss: 0.689834, acc.: 58.59%] [G loss: 0.665810]\n",
      "epoch:17 step:16212 [D loss: 0.770992, acc.: 40.62%] [G loss: 0.818040]\n",
      "epoch:17 step:16213 [D loss: 0.643253, acc.: 63.28%] [G loss: 0.808063]\n",
      "epoch:17 step:16214 [D loss: 0.675770, acc.: 61.72%] [G loss: 0.789044]\n",
      "epoch:17 step:16215 [D loss: 0.669713, acc.: 59.38%] [G loss: 0.776659]\n",
      "epoch:17 step:16216 [D loss: 0.701197, acc.: 53.12%] [G loss: 0.798288]\n",
      "epoch:17 step:16217 [D loss: 0.653667, acc.: 55.47%] [G loss: 0.780301]\n",
      "epoch:17 step:16218 [D loss: 0.628120, acc.: 67.19%] [G loss: 0.825857]\n",
      "epoch:17 step:16219 [D loss: 0.652224, acc.: 68.75%] [G loss: 0.822049]\n",
      "epoch:17 step:16220 [D loss: 0.645119, acc.: 64.06%] [G loss: 0.835822]\n",
      "epoch:17 step:16221 [D loss: 0.612987, acc.: 70.31%] [G loss: 0.834433]\n",
      "epoch:17 step:16222 [D loss: 0.632260, acc.: 60.16%] [G loss: 0.812175]\n",
      "epoch:17 step:16223 [D loss: 0.599506, acc.: 67.19%] [G loss: 0.900958]\n",
      "epoch:17 step:16224 [D loss: 0.746776, acc.: 46.88%] [G loss: 0.841193]\n",
      "epoch:17 step:16225 [D loss: 0.740629, acc.: 50.78%] [G loss: 0.833326]\n",
      "epoch:17 step:16226 [D loss: 0.724568, acc.: 46.88%] [G loss: 0.833016]\n",
      "epoch:17 step:16227 [D loss: 0.714216, acc.: 50.78%] [G loss: 0.770753]\n",
      "epoch:17 step:16228 [D loss: 0.697622, acc.: 49.22%] [G loss: 0.834667]\n",
      "epoch:17 step:16229 [D loss: 0.658993, acc.: 57.81%] [G loss: 0.765481]\n",
      "epoch:17 step:16230 [D loss: 0.612263, acc.: 66.41%] [G loss: 0.813349]\n",
      "epoch:17 step:16231 [D loss: 0.668556, acc.: 59.38%] [G loss: 0.827021]\n",
      "epoch:17 step:16232 [D loss: 0.665541, acc.: 60.94%] [G loss: 0.815499]\n",
      "epoch:17 step:16233 [D loss: 0.651809, acc.: 60.16%] [G loss: 0.820508]\n",
      "epoch:17 step:16234 [D loss: 0.578526, acc.: 73.44%] [G loss: 0.804929]\n",
      "epoch:17 step:16235 [D loss: 0.705742, acc.: 49.22%] [G loss: 0.897109]\n",
      "epoch:17 step:16236 [D loss: 0.620319, acc.: 67.97%] [G loss: 0.623965]\n",
      "epoch:17 step:16237 [D loss: 0.676695, acc.: 56.25%] [G loss: 0.803020]\n",
      "epoch:17 step:16238 [D loss: 0.563902, acc.: 71.88%] [G loss: 0.921637]\n",
      "epoch:17 step:16239 [D loss: 0.673050, acc.: 55.47%] [G loss: 0.836382]\n",
      "epoch:17 step:16240 [D loss: 0.724256, acc.: 55.47%] [G loss: 0.749245]\n",
      "epoch:17 step:16241 [D loss: 0.526539, acc.: 76.56%] [G loss: 0.849502]\n",
      "epoch:17 step:16242 [D loss: 0.755747, acc.: 46.09%] [G loss: 0.859245]\n",
      "epoch:17 step:16243 [D loss: 0.472857, acc.: 82.03%] [G loss: 1.005981]\n",
      "epoch:17 step:16244 [D loss: 0.564859, acc.: 78.12%] [G loss: 0.909020]\n",
      "epoch:17 step:16245 [D loss: 0.745903, acc.: 48.44%] [G loss: 1.015291]\n",
      "epoch:17 step:16246 [D loss: 0.798841, acc.: 39.84%] [G loss: 0.881593]\n",
      "epoch:17 step:16247 [D loss: 0.848068, acc.: 39.06%] [G loss: 0.802525]\n",
      "epoch:17 step:16248 [D loss: 0.776435, acc.: 42.97%] [G loss: 0.963530]\n",
      "epoch:17 step:16249 [D loss: 0.704700, acc.: 54.69%] [G loss: 0.901073]\n",
      "epoch:17 step:16250 [D loss: 0.688451, acc.: 59.38%] [G loss: 0.984545]\n",
      "epoch:17 step:16251 [D loss: 0.654017, acc.: 54.69%] [G loss: 0.940744]\n",
      "epoch:17 step:16252 [D loss: 0.708381, acc.: 52.34%] [G loss: 0.912871]\n",
      "epoch:17 step:16253 [D loss: 0.677486, acc.: 56.25%] [G loss: 0.878537]\n",
      "epoch:17 step:16254 [D loss: 0.674361, acc.: 55.47%] [G loss: 0.929523]\n",
      "epoch:17 step:16255 [D loss: 0.730179, acc.: 46.09%] [G loss: 0.840290]\n",
      "epoch:17 step:16256 [D loss: 0.586697, acc.: 68.75%] [G loss: 0.945853]\n",
      "epoch:17 step:16257 [D loss: 0.568603, acc.: 73.44%] [G loss: 0.925126]\n",
      "epoch:17 step:16258 [D loss: 0.653959, acc.: 59.38%] [G loss: 0.956108]\n",
      "epoch:17 step:16259 [D loss: 0.633174, acc.: 62.50%] [G loss: 0.881049]\n",
      "epoch:17 step:16260 [D loss: 0.661907, acc.: 60.94%] [G loss: 0.853926]\n",
      "epoch:17 step:16261 [D loss: 0.699797, acc.: 53.91%] [G loss: 0.841873]\n",
      "epoch:17 step:16262 [D loss: 0.728188, acc.: 47.66%] [G loss: 0.850783]\n",
      "epoch:17 step:16263 [D loss: 0.676692, acc.: 54.69%] [G loss: 0.812088]\n",
      "epoch:17 step:16264 [D loss: 0.703871, acc.: 54.69%] [G loss: 0.803073]\n",
      "epoch:17 step:16265 [D loss: 0.689265, acc.: 60.16%] [G loss: 0.817763]\n",
      "epoch:17 step:16266 [D loss: 0.629675, acc.: 65.62%] [G loss: 0.874590]\n",
      "epoch:17 step:16267 [D loss: 0.648191, acc.: 61.72%] [G loss: 0.862951]\n",
      "epoch:17 step:16268 [D loss: 0.592220, acc.: 71.88%] [G loss: 0.833954]\n",
      "epoch:17 step:16269 [D loss: 0.647205, acc.: 64.06%] [G loss: 0.847639]\n",
      "epoch:17 step:16270 [D loss: 0.657547, acc.: 57.03%] [G loss: 0.872786]\n",
      "epoch:17 step:16271 [D loss: 0.690182, acc.: 57.03%] [G loss: 0.859629]\n",
      "epoch:17 step:16272 [D loss: 0.644326, acc.: 60.94%] [G loss: 0.799784]\n",
      "epoch:17 step:16273 [D loss: 0.594287, acc.: 72.66%] [G loss: 0.844309]\n",
      "epoch:17 step:16274 [D loss: 0.692167, acc.: 57.81%] [G loss: 0.779134]\n",
      "epoch:17 step:16275 [D loss: 0.672505, acc.: 57.03%] [G loss: 0.776146]\n",
      "epoch:17 step:16276 [D loss: 0.607216, acc.: 71.88%] [G loss: 0.841037]\n",
      "epoch:17 step:16277 [D loss: 0.684067, acc.: 57.81%] [G loss: 0.853204]\n",
      "epoch:17 step:16278 [D loss: 0.731715, acc.: 46.88%] [G loss: 0.877133]\n",
      "epoch:17 step:16279 [D loss: 0.688208, acc.: 56.25%] [G loss: 0.844264]\n",
      "epoch:17 step:16280 [D loss: 0.619277, acc.: 67.19%] [G loss: 0.907603]\n",
      "epoch:17 step:16281 [D loss: 0.630765, acc.: 64.06%] [G loss: 0.876662]\n",
      "epoch:17 step:16282 [D loss: 0.636319, acc.: 65.62%] [G loss: 0.936838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16283 [D loss: 0.617139, acc.: 63.28%] [G loss: 0.936522]\n",
      "epoch:17 step:16284 [D loss: 0.584721, acc.: 67.97%] [G loss: 0.980861]\n",
      "epoch:17 step:16285 [D loss: 0.622849, acc.: 66.41%] [G loss: 0.857250]\n",
      "epoch:17 step:16286 [D loss: 0.653400, acc.: 62.50%] [G loss: 0.968434]\n",
      "epoch:17 step:16287 [D loss: 0.578277, acc.: 66.41%] [G loss: 0.818400]\n",
      "epoch:17 step:16288 [D loss: 0.591136, acc.: 70.31%] [G loss: 0.923637]\n",
      "epoch:17 step:16289 [D loss: 0.554568, acc.: 73.44%] [G loss: 0.927571]\n",
      "epoch:17 step:16290 [D loss: 0.562669, acc.: 70.31%] [G loss: 0.874075]\n",
      "epoch:17 step:16291 [D loss: 0.690623, acc.: 54.69%] [G loss: 0.883175]\n",
      "epoch:17 step:16292 [D loss: 0.697074, acc.: 60.94%] [G loss: 0.852234]\n",
      "epoch:17 step:16293 [D loss: 0.681017, acc.: 57.03%] [G loss: 0.744801]\n",
      "epoch:17 step:16294 [D loss: 0.738351, acc.: 44.53%] [G loss: 0.801676]\n",
      "epoch:17 step:16295 [D loss: 0.706413, acc.: 53.12%] [G loss: 0.866649]\n",
      "epoch:17 step:16296 [D loss: 0.704295, acc.: 48.44%] [G loss: 0.819287]\n",
      "epoch:17 step:16297 [D loss: 0.746316, acc.: 49.22%] [G loss: 0.666349]\n",
      "epoch:17 step:16298 [D loss: 0.652927, acc.: 58.59%] [G loss: 0.804589]\n",
      "epoch:17 step:16299 [D loss: 0.556324, acc.: 76.56%] [G loss: 0.811215]\n",
      "epoch:17 step:16300 [D loss: 0.475738, acc.: 78.91%] [G loss: 0.737897]\n",
      "epoch:17 step:16301 [D loss: 0.643150, acc.: 60.94%] [G loss: 0.845568]\n",
      "epoch:17 step:16302 [D loss: 0.741605, acc.: 51.56%] [G loss: 0.802681]\n",
      "epoch:17 step:16303 [D loss: 0.740777, acc.: 44.53%] [G loss: 0.685292]\n",
      "epoch:17 step:16304 [D loss: 0.714103, acc.: 48.44%] [G loss: 0.883396]\n",
      "epoch:17 step:16305 [D loss: 0.738971, acc.: 54.69%] [G loss: 0.798240]\n",
      "epoch:17 step:16306 [D loss: 0.673165, acc.: 53.91%] [G loss: 0.931881]\n",
      "epoch:17 step:16307 [D loss: 0.617634, acc.: 67.19%] [G loss: 0.867576]\n",
      "epoch:17 step:16308 [D loss: 0.698322, acc.: 58.59%] [G loss: 0.932545]\n",
      "epoch:17 step:16309 [D loss: 0.604423, acc.: 71.88%] [G loss: 0.904868]\n",
      "epoch:17 step:16310 [D loss: 0.667228, acc.: 57.81%] [G loss: 0.912147]\n",
      "epoch:17 step:16311 [D loss: 0.683237, acc.: 53.91%] [G loss: 0.901465]\n",
      "epoch:17 step:16312 [D loss: 0.669559, acc.: 58.59%] [G loss: 0.874470]\n",
      "epoch:17 step:16313 [D loss: 0.736406, acc.: 50.78%] [G loss: 0.886308]\n",
      "epoch:17 step:16314 [D loss: 0.673629, acc.: 58.59%] [G loss: 0.853924]\n",
      "epoch:17 step:16315 [D loss: 0.665786, acc.: 53.91%] [G loss: 0.812982]\n",
      "epoch:17 step:16316 [D loss: 0.651713, acc.: 61.72%] [G loss: 0.934328]\n",
      "epoch:17 step:16317 [D loss: 0.598628, acc.: 68.75%] [G loss: 0.888675]\n",
      "epoch:17 step:16318 [D loss: 0.624817, acc.: 64.84%] [G loss: 0.900788]\n",
      "epoch:17 step:16319 [D loss: 0.631725, acc.: 62.50%] [G loss: 0.999790]\n",
      "epoch:17 step:16320 [D loss: 0.657113, acc.: 68.75%] [G loss: 0.817505]\n",
      "epoch:17 step:16321 [D loss: 0.664617, acc.: 64.84%] [G loss: 0.818626]\n",
      "epoch:17 step:16322 [D loss: 0.603727, acc.: 67.97%] [G loss: 0.862033]\n",
      "epoch:17 step:16323 [D loss: 0.655209, acc.: 57.03%] [G loss: 0.959734]\n",
      "epoch:17 step:16324 [D loss: 0.712497, acc.: 52.34%] [G loss: 0.873624]\n",
      "epoch:17 step:16325 [D loss: 0.422471, acc.: 88.28%] [G loss: 1.072932]\n",
      "epoch:17 step:16326 [D loss: 0.464701, acc.: 77.34%] [G loss: 1.040279]\n",
      "epoch:17 step:16327 [D loss: 0.358999, acc.: 83.59%] [G loss: 1.269853]\n",
      "epoch:17 step:16328 [D loss: 0.361454, acc.: 83.59%] [G loss: 1.219697]\n",
      "epoch:17 step:16329 [D loss: 0.372141, acc.: 92.97%] [G loss: 1.208347]\n",
      "epoch:17 step:16330 [D loss: 0.474519, acc.: 81.25%] [G loss: 1.343535]\n",
      "epoch:17 step:16331 [D loss: 0.417973, acc.: 85.16%] [G loss: 1.352680]\n",
      "epoch:17 step:16332 [D loss: 0.420022, acc.: 81.25%] [G loss: 1.249582]\n",
      "epoch:17 step:16333 [D loss: 0.373463, acc.: 89.06%] [G loss: 1.016193]\n",
      "epoch:17 step:16334 [D loss: 0.710617, acc.: 64.06%] [G loss: 1.365004]\n",
      "epoch:17 step:16335 [D loss: 0.448393, acc.: 89.84%] [G loss: 1.397890]\n",
      "epoch:17 step:16336 [D loss: 0.360512, acc.: 92.19%] [G loss: 1.132615]\n",
      "epoch:17 step:16337 [D loss: 0.537221, acc.: 76.56%] [G loss: 0.561171]\n",
      "epoch:17 step:16338 [D loss: 0.460610, acc.: 77.34%] [G loss: 1.096864]\n",
      "epoch:17 step:16339 [D loss: 0.926646, acc.: 32.81%] [G loss: 1.254822]\n",
      "epoch:17 step:16340 [D loss: 1.090495, acc.: 40.62%] [G loss: 1.284175]\n",
      "epoch:17 step:16341 [D loss: 0.923359, acc.: 29.69%] [G loss: 0.754135]\n",
      "epoch:17 step:16342 [D loss: 0.845797, acc.: 43.75%] [G loss: 0.852825]\n",
      "epoch:17 step:16343 [D loss: 0.555211, acc.: 72.66%] [G loss: 0.759162]\n",
      "epoch:17 step:16344 [D loss: 0.758438, acc.: 50.78%] [G loss: 1.396610]\n",
      "epoch:17 step:16345 [D loss: 0.734311, acc.: 54.69%] [G loss: 0.933892]\n",
      "epoch:17 step:16346 [D loss: 0.828225, acc.: 40.62%] [G loss: 0.900915]\n",
      "epoch:17 step:16347 [D loss: 0.732590, acc.: 51.56%] [G loss: 1.028677]\n",
      "epoch:17 step:16348 [D loss: 0.665912, acc.: 58.59%] [G loss: 1.068353]\n",
      "epoch:17 step:16349 [D loss: 0.753399, acc.: 44.53%] [G loss: 1.039028]\n",
      "epoch:17 step:16350 [D loss: 0.780541, acc.: 41.41%] [G loss: 0.897112]\n",
      "epoch:17 step:16351 [D loss: 0.826196, acc.: 31.25%] [G loss: 0.898219]\n",
      "epoch:17 step:16352 [D loss: 0.723079, acc.: 49.22%] [G loss: 0.910186]\n",
      "epoch:17 step:16353 [D loss: 0.697535, acc.: 51.56%] [G loss: 0.896678]\n",
      "epoch:17 step:16354 [D loss: 0.684059, acc.: 58.59%] [G loss: 0.939373]\n",
      "epoch:17 step:16355 [D loss: 0.716158, acc.: 46.88%] [G loss: 0.846154]\n",
      "epoch:17 step:16356 [D loss: 0.720717, acc.: 44.53%] [G loss: 0.888681]\n",
      "epoch:17 step:16357 [D loss: 0.681294, acc.: 54.69%] [G loss: 0.886581]\n",
      "epoch:17 step:16358 [D loss: 0.674904, acc.: 53.12%] [G loss: 0.859522]\n",
      "epoch:17 step:16359 [D loss: 0.661296, acc.: 58.59%] [G loss: 0.915053]\n",
      "epoch:17 step:16360 [D loss: 0.687420, acc.: 51.56%] [G loss: 0.931916]\n",
      "epoch:17 step:16361 [D loss: 0.753363, acc.: 45.31%] [G loss: 0.924460]\n",
      "epoch:17 step:16362 [D loss: 0.660454, acc.: 60.16%] [G loss: 0.898113]\n",
      "epoch:17 step:16363 [D loss: 0.672692, acc.: 58.59%] [G loss: 0.897784]\n",
      "epoch:17 step:16364 [D loss: 0.676930, acc.: 55.47%] [G loss: 0.935992]\n",
      "epoch:17 step:16365 [D loss: 0.620757, acc.: 64.06%] [G loss: 0.893959]\n",
      "epoch:17 step:16366 [D loss: 0.689549, acc.: 51.56%] [G loss: 0.922615]\n",
      "epoch:17 step:16367 [D loss: 0.702575, acc.: 50.00%] [G loss: 0.906922]\n",
      "epoch:17 step:16368 [D loss: 0.716286, acc.: 47.66%] [G loss: 0.896671]\n",
      "epoch:17 step:16369 [D loss: 0.681021, acc.: 56.25%] [G loss: 0.836222]\n",
      "epoch:17 step:16370 [D loss: 0.684999, acc.: 56.25%] [G loss: 0.895861]\n",
      "epoch:17 step:16371 [D loss: 0.673233, acc.: 54.69%] [G loss: 0.887386]\n",
      "epoch:17 step:16372 [D loss: 0.603449, acc.: 67.97%] [G loss: 0.949007]\n",
      "epoch:17 step:16373 [D loss: 0.686819, acc.: 50.78%] [G loss: 0.846288]\n",
      "epoch:17 step:16374 [D loss: 0.677330, acc.: 55.47%] [G loss: 0.918916]\n",
      "epoch:17 step:16375 [D loss: 0.653526, acc.: 60.16%] [G loss: 0.858369]\n",
      "epoch:17 step:16376 [D loss: 0.677814, acc.: 54.69%] [G loss: 0.813986]\n",
      "epoch:17 step:16377 [D loss: 0.649011, acc.: 63.28%] [G loss: 0.847529]\n",
      "epoch:17 step:16378 [D loss: 0.634333, acc.: 69.53%] [G loss: 0.874290]\n",
      "epoch:17 step:16379 [D loss: 0.590257, acc.: 67.19%] [G loss: 0.980304]\n",
      "epoch:17 step:16380 [D loss: 0.523413, acc.: 80.47%] [G loss: 1.053982]\n",
      "epoch:17 step:16381 [D loss: 0.515769, acc.: 77.34%] [G loss: 1.152226]\n",
      "epoch:17 step:16382 [D loss: 0.604589, acc.: 68.75%] [G loss: 1.204494]\n",
      "epoch:17 step:16383 [D loss: 0.614731, acc.: 70.31%] [G loss: 1.386142]\n",
      "epoch:17 step:16384 [D loss: 0.633319, acc.: 63.28%] [G loss: 1.192200]\n",
      "epoch:17 step:16385 [D loss: 0.637438, acc.: 66.41%] [G loss: 0.898243]\n",
      "epoch:17 step:16386 [D loss: 0.521687, acc.: 79.69%] [G loss: 0.968968]\n",
      "epoch:17 step:16387 [D loss: 0.704408, acc.: 56.25%] [G loss: 1.090127]\n",
      "epoch:17 step:16388 [D loss: 0.632658, acc.: 63.28%] [G loss: 1.087606]\n",
      "epoch:17 step:16389 [D loss: 0.669899, acc.: 56.25%] [G loss: 0.830200]\n",
      "epoch:17 step:16390 [D loss: 0.935180, acc.: 37.50%] [G loss: 0.811772]\n",
      "epoch:17 step:16391 [D loss: 0.884875, acc.: 33.59%] [G loss: 0.783854]\n",
      "epoch:17 step:16392 [D loss: 0.747703, acc.: 48.44%] [G loss: 0.774186]\n",
      "epoch:17 step:16393 [D loss: 0.636556, acc.: 64.84%] [G loss: 0.722320]\n",
      "epoch:17 step:16394 [D loss: 0.668436, acc.: 58.59%] [G loss: 0.801198]\n",
      "epoch:17 step:16395 [D loss: 0.649435, acc.: 60.94%] [G loss: 0.852806]\n",
      "epoch:17 step:16396 [D loss: 0.723937, acc.: 49.22%] [G loss: 0.773081]\n",
      "epoch:17 step:16397 [D loss: 0.564264, acc.: 73.44%] [G loss: 0.834624]\n",
      "epoch:17 step:16398 [D loss: 0.583161, acc.: 74.22%] [G loss: 0.884775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16399 [D loss: 0.579246, acc.: 71.09%] [G loss: 0.798594]\n",
      "epoch:17 step:16400 [D loss: 0.568713, acc.: 72.66%] [G loss: 0.912850]\n",
      "epoch:17 step:16401 [D loss: 0.640854, acc.: 57.03%] [G loss: 0.825548]\n",
      "epoch:17 step:16402 [D loss: 0.909961, acc.: 34.38%] [G loss: 0.785657]\n",
      "epoch:17 step:16403 [D loss: 0.877409, acc.: 24.22%] [G loss: 0.796395]\n",
      "epoch:17 step:16404 [D loss: 0.820078, acc.: 37.50%] [G loss: 0.810564]\n",
      "epoch:17 step:16405 [D loss: 0.723791, acc.: 55.47%] [G loss: 0.731275]\n",
      "epoch:17 step:16406 [D loss: 0.719712, acc.: 53.12%] [G loss: 0.799218]\n",
      "epoch:17 step:16407 [D loss: 0.708673, acc.: 45.31%] [G loss: 0.784278]\n",
      "epoch:17 step:16408 [D loss: 0.652866, acc.: 62.50%] [G loss: 0.748458]\n",
      "epoch:17 step:16409 [D loss: 0.649664, acc.: 61.72%] [G loss: 0.747787]\n",
      "epoch:17 step:16410 [D loss: 0.639857, acc.: 65.62%] [G loss: 0.784686]\n",
      "epoch:17 step:16411 [D loss: 0.708643, acc.: 49.22%] [G loss: 0.799381]\n",
      "epoch:17 step:16412 [D loss: 0.705932, acc.: 51.56%] [G loss: 0.807059]\n",
      "epoch:17 step:16413 [D loss: 0.632347, acc.: 64.84%] [G loss: 0.810798]\n",
      "epoch:17 step:16414 [D loss: 0.629247, acc.: 62.50%] [G loss: 0.864803]\n",
      "epoch:17 step:16415 [D loss: 0.636454, acc.: 64.06%] [G loss: 0.902158]\n",
      "epoch:17 step:16416 [D loss: 0.666893, acc.: 60.94%] [G loss: 1.001710]\n",
      "epoch:17 step:16417 [D loss: 0.635963, acc.: 62.50%] [G loss: 0.953197]\n",
      "epoch:17 step:16418 [D loss: 0.667234, acc.: 61.72%] [G loss: 0.884145]\n",
      "epoch:17 step:16419 [D loss: 0.634726, acc.: 70.31%] [G loss: 0.911338]\n",
      "epoch:17 step:16420 [D loss: 0.659589, acc.: 60.94%] [G loss: 0.844820]\n",
      "epoch:17 step:16421 [D loss: 0.700378, acc.: 53.12%] [G loss: 0.818515]\n",
      "epoch:17 step:16422 [D loss: 0.667784, acc.: 60.94%] [G loss: 0.811247]\n",
      "epoch:17 step:16423 [D loss: 0.644606, acc.: 63.28%] [G loss: 0.807634]\n",
      "epoch:17 step:16424 [D loss: 0.665219, acc.: 63.28%] [G loss: 0.868578]\n",
      "epoch:17 step:16425 [D loss: 0.661269, acc.: 60.16%] [G loss: 0.780054]\n",
      "epoch:17 step:16426 [D loss: 0.583178, acc.: 71.88%] [G loss: 0.860325]\n",
      "epoch:17 step:16427 [D loss: 0.545607, acc.: 82.81%] [G loss: 0.813407]\n",
      "epoch:17 step:16428 [D loss: 0.546401, acc.: 77.34%] [G loss: 0.909947]\n",
      "epoch:17 step:16429 [D loss: 0.604714, acc.: 66.41%] [G loss: 0.926674]\n",
      "epoch:17 step:16430 [D loss: 0.698963, acc.: 51.56%] [G loss: 0.893934]\n",
      "epoch:17 step:16431 [D loss: 0.627849, acc.: 63.28%] [G loss: 0.821666]\n",
      "epoch:17 step:16432 [D loss: 0.754714, acc.: 50.00%] [G loss: 0.914383]\n",
      "epoch:17 step:16433 [D loss: 0.682364, acc.: 60.16%] [G loss: 0.923272]\n",
      "epoch:17 step:16434 [D loss: 0.614270, acc.: 67.19%] [G loss: 0.890207]\n",
      "epoch:17 step:16435 [D loss: 0.665747, acc.: 57.81%] [G loss: 0.906997]\n",
      "epoch:17 step:16436 [D loss: 0.653320, acc.: 60.16%] [G loss: 0.909198]\n",
      "epoch:17 step:16437 [D loss: 0.673780, acc.: 56.25%] [G loss: 0.853542]\n",
      "epoch:17 step:16438 [D loss: 0.644198, acc.: 64.06%] [G loss: 0.948046]\n",
      "epoch:17 step:16439 [D loss: 0.634454, acc.: 67.19%] [G loss: 0.856152]\n",
      "epoch:17 step:16440 [D loss: 0.699815, acc.: 57.81%] [G loss: 0.803880]\n",
      "epoch:17 step:16441 [D loss: 0.580120, acc.: 74.22%] [G loss: 0.851878]\n",
      "epoch:17 step:16442 [D loss: 0.622466, acc.: 67.19%] [G loss: 0.923323]\n",
      "epoch:17 step:16443 [D loss: 0.513739, acc.: 85.94%] [G loss: 0.959849]\n",
      "epoch:17 step:16444 [D loss: 0.528008, acc.: 82.03%] [G loss: 0.962047]\n",
      "epoch:17 step:16445 [D loss: 0.723180, acc.: 56.25%] [G loss: 0.889533]\n",
      "epoch:17 step:16446 [D loss: 0.651192, acc.: 62.50%] [G loss: 0.876403]\n",
      "epoch:17 step:16447 [D loss: 0.744994, acc.: 46.09%] [G loss: 0.996675]\n",
      "epoch:17 step:16448 [D loss: 0.597820, acc.: 66.41%] [G loss: 1.062930]\n",
      "epoch:17 step:16449 [D loss: 0.588534, acc.: 69.53%] [G loss: 0.921033]\n",
      "epoch:17 step:16450 [D loss: 0.705804, acc.: 51.56%] [G loss: 1.307172]\n",
      "epoch:17 step:16451 [D loss: 0.670776, acc.: 57.81%] [G loss: 0.897783]\n",
      "epoch:17 step:16452 [D loss: 0.694241, acc.: 55.47%] [G loss: 1.014310]\n",
      "epoch:17 step:16453 [D loss: 0.578638, acc.: 73.44%] [G loss: 0.952420]\n",
      "epoch:17 step:16454 [D loss: 0.728232, acc.: 52.34%] [G loss: 0.879078]\n",
      "epoch:17 step:16455 [D loss: 0.723757, acc.: 50.00%] [G loss: 0.838002]\n",
      "epoch:17 step:16456 [D loss: 0.697730, acc.: 56.25%] [G loss: 0.997291]\n",
      "epoch:17 step:16457 [D loss: 0.783963, acc.: 50.00%] [G loss: 0.814676]\n",
      "epoch:17 step:16458 [D loss: 0.801675, acc.: 39.84%] [G loss: 0.842005]\n",
      "epoch:17 step:16459 [D loss: 0.643560, acc.: 60.94%] [G loss: 0.835804]\n",
      "epoch:17 step:16460 [D loss: 0.726386, acc.: 47.66%] [G loss: 0.836208]\n",
      "epoch:17 step:16461 [D loss: 0.683794, acc.: 53.12%] [G loss: 0.875834]\n",
      "epoch:17 step:16462 [D loss: 0.638513, acc.: 64.06%] [G loss: 0.912076]\n",
      "epoch:17 step:16463 [D loss: 0.607136, acc.: 62.50%] [G loss: 0.857463]\n",
      "epoch:17 step:16464 [D loss: 0.658238, acc.: 69.53%] [G loss: 0.898165]\n",
      "epoch:17 step:16465 [D loss: 0.622405, acc.: 65.62%] [G loss: 0.879015]\n",
      "epoch:17 step:16466 [D loss: 0.657640, acc.: 65.62%] [G loss: 0.920335]\n",
      "epoch:17 step:16467 [D loss: 0.669941, acc.: 54.69%] [G loss: 0.837042]\n",
      "epoch:17 step:16468 [D loss: 0.662501, acc.: 60.94%] [G loss: 0.878122]\n",
      "epoch:17 step:16469 [D loss: 0.674215, acc.: 54.69%] [G loss: 0.810004]\n",
      "epoch:17 step:16470 [D loss: 0.665449, acc.: 62.50%] [G loss: 0.826772]\n",
      "epoch:17 step:16471 [D loss: 0.584432, acc.: 75.00%] [G loss: 0.866080]\n",
      "epoch:17 step:16472 [D loss: 0.473215, acc.: 79.69%] [G loss: 1.004741]\n",
      "epoch:17 step:16473 [D loss: 0.636779, acc.: 57.81%] [G loss: 0.870793]\n",
      "epoch:17 step:16474 [D loss: 0.594266, acc.: 64.06%] [G loss: 0.898698]\n",
      "epoch:17 step:16475 [D loss: 0.675802, acc.: 62.50%] [G loss: 0.839408]\n",
      "epoch:17 step:16476 [D loss: 0.693063, acc.: 54.69%] [G loss: 0.910352]\n",
      "epoch:17 step:16477 [D loss: 0.610072, acc.: 70.31%] [G loss: 0.909477]\n",
      "epoch:17 step:16478 [D loss: 0.596970, acc.: 69.53%] [G loss: 0.797060]\n",
      "epoch:17 step:16479 [D loss: 0.432492, acc.: 85.16%] [G loss: 0.821744]\n",
      "epoch:17 step:16480 [D loss: 0.570790, acc.: 73.44%] [G loss: 0.982282]\n",
      "epoch:17 step:16481 [D loss: 0.658909, acc.: 64.06%] [G loss: 1.016497]\n",
      "epoch:17 step:16482 [D loss: 0.649413, acc.: 58.59%] [G loss: 0.919814]\n",
      "epoch:17 step:16483 [D loss: 0.486960, acc.: 85.94%] [G loss: 0.831261]\n",
      "epoch:17 step:16484 [D loss: 0.545251, acc.: 75.78%] [G loss: 0.928575]\n",
      "epoch:17 step:16485 [D loss: 0.536593, acc.: 78.12%] [G loss: 0.954080]\n",
      "epoch:17 step:16486 [D loss: 0.618173, acc.: 65.62%] [G loss: 1.043137]\n",
      "epoch:17 step:16487 [D loss: 0.569052, acc.: 68.75%] [G loss: 1.006500]\n",
      "epoch:17 step:16488 [D loss: 0.741119, acc.: 50.78%] [G loss: 1.063251]\n",
      "epoch:17 step:16489 [D loss: 0.782318, acc.: 43.75%] [G loss: 0.909067]\n",
      "epoch:17 step:16490 [D loss: 0.652050, acc.: 62.50%] [G loss: 0.847538]\n",
      "epoch:17 step:16491 [D loss: 0.672119, acc.: 50.00%] [G loss: 0.745499]\n",
      "epoch:17 step:16492 [D loss: 0.626933, acc.: 62.50%] [G loss: 0.842863]\n",
      "epoch:17 step:16493 [D loss: 0.675760, acc.: 57.03%] [G loss: 0.741451]\n",
      "epoch:17 step:16494 [D loss: 0.628549, acc.: 62.50%] [G loss: 0.865629]\n",
      "epoch:17 step:16495 [D loss: 0.705319, acc.: 51.56%] [G loss: 0.906848]\n",
      "epoch:17 step:16496 [D loss: 0.552505, acc.: 77.34%] [G loss: 0.900477]\n",
      "epoch:17 step:16497 [D loss: 0.608477, acc.: 64.84%] [G loss: 0.974135]\n",
      "epoch:17 step:16498 [D loss: 0.683592, acc.: 51.56%] [G loss: 0.966477]\n",
      "epoch:17 step:16499 [D loss: 0.627358, acc.: 67.19%] [G loss: 0.891084]\n",
      "epoch:17 step:16500 [D loss: 0.649887, acc.: 64.06%] [G loss: 0.858343]\n",
      "epoch:17 step:16501 [D loss: 0.644368, acc.: 60.16%] [G loss: 0.880414]\n",
      "epoch:17 step:16502 [D loss: 0.601860, acc.: 67.19%] [G loss: 0.933009]\n",
      "epoch:17 step:16503 [D loss: 0.572687, acc.: 67.97%] [G loss: 1.038530]\n",
      "epoch:17 step:16504 [D loss: 0.520857, acc.: 77.34%] [G loss: 0.930039]\n",
      "epoch:17 step:16505 [D loss: 0.506245, acc.: 80.47%] [G loss: 1.114654]\n",
      "epoch:17 step:16506 [D loss: 0.519050, acc.: 73.44%] [G loss: 1.040449]\n",
      "epoch:17 step:16507 [D loss: 0.630809, acc.: 64.06%] [G loss: 1.049153]\n",
      "epoch:17 step:16508 [D loss: 0.537320, acc.: 72.66%] [G loss: 0.980508]\n",
      "epoch:17 step:16509 [D loss: 0.723603, acc.: 54.69%] [G loss: 0.750842]\n",
      "epoch:17 step:16510 [D loss: 0.648183, acc.: 57.81%] [G loss: 0.973617]\n",
      "epoch:17 step:16511 [D loss: 0.665932, acc.: 57.81%] [G loss: 1.087656]\n",
      "epoch:17 step:16512 [D loss: 0.720013, acc.: 54.69%] [G loss: 0.906797]\n",
      "epoch:17 step:16513 [D loss: 0.765555, acc.: 50.00%] [G loss: 0.803601]\n",
      "epoch:17 step:16514 [D loss: 0.680943, acc.: 56.25%] [G loss: 0.700069]\n",
      "epoch:17 step:16515 [D loss: 0.716298, acc.: 50.78%] [G loss: 0.787347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16516 [D loss: 0.588593, acc.: 71.09%] [G loss: 0.884386]\n",
      "epoch:17 step:16517 [D loss: 0.529475, acc.: 73.44%] [G loss: 0.887412]\n",
      "epoch:17 step:16518 [D loss: 0.594318, acc.: 63.28%] [G loss: 0.873562]\n",
      "epoch:17 step:16519 [D loss: 0.693035, acc.: 57.81%] [G loss: 1.005338]\n",
      "epoch:17 step:16520 [D loss: 0.713793, acc.: 50.78%] [G loss: 0.890154]\n",
      "epoch:17 step:16521 [D loss: 0.652328, acc.: 53.12%] [G loss: 0.897601]\n",
      "epoch:17 step:16522 [D loss: 0.732827, acc.: 42.97%] [G loss: 0.912926]\n",
      "epoch:17 step:16523 [D loss: 0.635029, acc.: 65.62%] [G loss: 1.019304]\n",
      "epoch:17 step:16524 [D loss: 0.574067, acc.: 73.44%] [G loss: 1.002995]\n",
      "epoch:17 step:16525 [D loss: 0.666489, acc.: 56.25%] [G loss: 0.939553]\n",
      "epoch:17 step:16526 [D loss: 0.676992, acc.: 58.59%] [G loss: 0.976972]\n",
      "epoch:17 step:16527 [D loss: 0.642105, acc.: 63.28%] [G loss: 0.967940]\n",
      "epoch:17 step:16528 [D loss: 0.654783, acc.: 61.72%] [G loss: 0.855392]\n",
      "epoch:17 step:16529 [D loss: 0.586637, acc.: 74.22%] [G loss: 0.941607]\n",
      "epoch:17 step:16530 [D loss: 0.646818, acc.: 62.50%] [G loss: 1.008705]\n",
      "epoch:17 step:16531 [D loss: 0.643653, acc.: 64.84%] [G loss: 0.764331]\n",
      "epoch:17 step:16532 [D loss: 0.704032, acc.: 51.56%] [G loss: 0.779438]\n",
      "epoch:17 step:16533 [D loss: 0.456567, acc.: 66.41%] [G loss: 1.075486]\n",
      "epoch:17 step:16534 [D loss: 0.610804, acc.: 68.75%] [G loss: 0.914376]\n",
      "epoch:17 step:16535 [D loss: 0.613440, acc.: 65.62%] [G loss: 0.917823]\n",
      "epoch:17 step:16536 [D loss: 0.730459, acc.: 49.22%] [G loss: 0.956298]\n",
      "epoch:17 step:16537 [D loss: 0.740511, acc.: 45.31%] [G loss: 1.007520]\n",
      "epoch:17 step:16538 [D loss: 0.682176, acc.: 59.38%] [G loss: 1.006082]\n",
      "epoch:17 step:16539 [D loss: 0.709882, acc.: 53.12%] [G loss: 1.018677]\n",
      "epoch:17 step:16540 [D loss: 0.709109, acc.: 53.91%] [G loss: 0.852154]\n",
      "epoch:17 step:16541 [D loss: 0.705590, acc.: 53.12%] [G loss: 0.851671]\n",
      "epoch:17 step:16542 [D loss: 0.617069, acc.: 60.16%] [G loss: 0.974366]\n",
      "epoch:17 step:16543 [D loss: 0.679743, acc.: 52.34%] [G loss: 1.040437]\n",
      "epoch:17 step:16544 [D loss: 0.594138, acc.: 67.19%] [G loss: 1.035965]\n",
      "epoch:17 step:16545 [D loss: 0.572196, acc.: 75.00%] [G loss: 0.812701]\n",
      "epoch:17 step:16546 [D loss: 0.530338, acc.: 81.25%] [G loss: 0.993566]\n",
      "epoch:17 step:16547 [D loss: 0.723219, acc.: 52.34%] [G loss: 0.741584]\n",
      "epoch:17 step:16548 [D loss: 0.706117, acc.: 52.34%] [G loss: 0.732838]\n",
      "epoch:17 step:16549 [D loss: 0.692413, acc.: 57.81%] [G loss: 0.862187]\n",
      "epoch:17 step:16550 [D loss: 0.734271, acc.: 52.34%] [G loss: 0.782221]\n",
      "epoch:17 step:16551 [D loss: 0.748168, acc.: 47.66%] [G loss: 0.719251]\n",
      "epoch:17 step:16552 [D loss: 0.634869, acc.: 66.41%] [G loss: 0.765120]\n",
      "epoch:17 step:16553 [D loss: 0.655416, acc.: 57.81%] [G loss: 0.842336]\n",
      "epoch:17 step:16554 [D loss: 0.725091, acc.: 50.00%] [G loss: 0.897068]\n",
      "epoch:17 step:16555 [D loss: 0.672879, acc.: 60.94%] [G loss: 0.756261]\n",
      "epoch:17 step:16556 [D loss: 0.648884, acc.: 57.03%] [G loss: 0.913899]\n",
      "epoch:17 step:16557 [D loss: 0.739010, acc.: 47.66%] [G loss: 0.732378]\n",
      "epoch:17 step:16558 [D loss: 0.703832, acc.: 55.47%] [G loss: 0.834550]\n",
      "epoch:17 step:16559 [D loss: 0.675822, acc.: 57.81%] [G loss: 0.760744]\n",
      "epoch:17 step:16560 [D loss: 0.670718, acc.: 57.03%] [G loss: 0.864017]\n",
      "epoch:17 step:16561 [D loss: 0.653521, acc.: 61.72%] [G loss: 0.851798]\n",
      "epoch:17 step:16562 [D loss: 0.587533, acc.: 71.88%] [G loss: 0.806198]\n",
      "epoch:17 step:16563 [D loss: 0.540881, acc.: 75.78%] [G loss: 0.883333]\n",
      "epoch:17 step:16564 [D loss: 0.571429, acc.: 70.31%] [G loss: 0.860992]\n",
      "epoch:17 step:16565 [D loss: 0.658286, acc.: 61.72%] [G loss: 0.718973]\n",
      "epoch:17 step:16566 [D loss: 0.713713, acc.: 49.22%] [G loss: 0.785634]\n",
      "epoch:17 step:16567 [D loss: 0.649845, acc.: 57.81%] [G loss: 0.757365]\n",
      "epoch:17 step:16568 [D loss: 0.711181, acc.: 50.00%] [G loss: 0.663591]\n",
      "epoch:17 step:16569 [D loss: 0.797506, acc.: 32.81%] [G loss: 0.836218]\n",
      "epoch:17 step:16570 [D loss: 0.604405, acc.: 66.41%] [G loss: 0.875702]\n",
      "epoch:17 step:16571 [D loss: 0.693561, acc.: 57.81%] [G loss: 0.910116]\n",
      "epoch:17 step:16572 [D loss: 0.694623, acc.: 55.47%] [G loss: 0.865663]\n",
      "epoch:17 step:16573 [D loss: 0.592834, acc.: 67.97%] [G loss: 0.831604]\n",
      "epoch:17 step:16574 [D loss: 0.642049, acc.: 57.81%] [G loss: 0.861049]\n",
      "epoch:17 step:16575 [D loss: 0.636128, acc.: 67.97%] [G loss: 0.850776]\n",
      "epoch:17 step:16576 [D loss: 0.674210, acc.: 59.38%] [G loss: 0.719247]\n",
      "epoch:17 step:16577 [D loss: 0.610208, acc.: 63.28%] [G loss: 0.888461]\n",
      "epoch:17 step:16578 [D loss: 0.632735, acc.: 59.38%] [G loss: 0.941994]\n",
      "epoch:17 step:16579 [D loss: 0.584549, acc.: 71.88%] [G loss: 0.894632]\n",
      "epoch:17 step:16580 [D loss: 0.610370, acc.: 69.53%] [G loss: 0.951058]\n",
      "epoch:17 step:16581 [D loss: 0.729860, acc.: 50.00%] [G loss: 0.914644]\n",
      "epoch:17 step:16582 [D loss: 0.683960, acc.: 57.03%] [G loss: 0.897546]\n",
      "epoch:17 step:16583 [D loss: 0.667539, acc.: 58.59%] [G loss: 0.946129]\n",
      "epoch:17 step:16584 [D loss: 0.655498, acc.: 60.16%] [G loss: 0.910926]\n",
      "epoch:17 step:16585 [D loss: 0.705746, acc.: 56.25%] [G loss: 0.892096]\n",
      "epoch:17 step:16586 [D loss: 0.685586, acc.: 55.47%] [G loss: 0.965353]\n",
      "epoch:17 step:16587 [D loss: 0.764010, acc.: 50.78%] [G loss: 0.934362]\n",
      "epoch:17 step:16588 [D loss: 0.684036, acc.: 57.03%] [G loss: 0.873467]\n",
      "epoch:17 step:16589 [D loss: 0.631914, acc.: 67.19%] [G loss: 0.836553]\n",
      "epoch:17 step:16590 [D loss: 0.650337, acc.: 60.16%] [G loss: 0.956693]\n",
      "epoch:17 step:16591 [D loss: 0.640197, acc.: 68.75%] [G loss: 0.999911]\n",
      "epoch:17 step:16592 [D loss: 0.495192, acc.: 79.69%] [G loss: 0.948946]\n",
      "epoch:17 step:16593 [D loss: 0.495916, acc.: 83.59%] [G loss: 1.056037]\n",
      "epoch:17 step:16594 [D loss: 0.437078, acc.: 82.81%] [G loss: 1.261776]\n",
      "epoch:17 step:16595 [D loss: 0.590911, acc.: 73.44%] [G loss: 1.054633]\n",
      "epoch:17 step:16596 [D loss: 0.558473, acc.: 74.22%] [G loss: 0.872536]\n",
      "epoch:17 step:16597 [D loss: 0.715299, acc.: 54.69%] [G loss: 1.141993]\n",
      "epoch:17 step:16598 [D loss: 0.628592, acc.: 64.06%] [G loss: 0.819342]\n",
      "epoch:17 step:16599 [D loss: 0.689021, acc.: 57.81%] [G loss: 0.888311]\n",
      "epoch:17 step:16600 [D loss: 0.616685, acc.: 66.41%] [G loss: 0.671273]\n",
      "epoch:17 step:16601 [D loss: 0.749701, acc.: 57.03%] [G loss: 0.904636]\n",
      "epoch:17 step:16602 [D loss: 0.649038, acc.: 63.28%] [G loss: 0.792921]\n",
      "epoch:17 step:16603 [D loss: 0.545094, acc.: 71.88%] [G loss: 0.743521]\n",
      "epoch:17 step:16604 [D loss: 0.738564, acc.: 52.34%] [G loss: 0.815783]\n",
      "epoch:17 step:16605 [D loss: 0.693038, acc.: 62.50%] [G loss: 0.862971]\n",
      "epoch:17 step:16606 [D loss: 0.858118, acc.: 34.38%] [G loss: 0.876799]\n",
      "epoch:17 step:16607 [D loss: 0.690249, acc.: 57.03%] [G loss: 0.989049]\n",
      "epoch:17 step:16608 [D loss: 0.682729, acc.: 56.25%] [G loss: 0.955471]\n",
      "epoch:17 step:16609 [D loss: 0.656237, acc.: 58.59%] [G loss: 0.981667]\n",
      "epoch:17 step:16610 [D loss: 0.703944, acc.: 53.12%] [G loss: 0.860950]\n",
      "epoch:17 step:16611 [D loss: 0.663071, acc.: 60.16%] [G loss: 0.950131]\n",
      "epoch:17 step:16612 [D loss: 0.639850, acc.: 60.94%] [G loss: 0.905189]\n",
      "epoch:17 step:16613 [D loss: 0.605392, acc.: 67.19%] [G loss: 0.879584]\n",
      "epoch:17 step:16614 [D loss: 0.603063, acc.: 67.19%] [G loss: 0.849429]\n",
      "epoch:17 step:16615 [D loss: 0.586876, acc.: 72.66%] [G loss: 0.897577]\n",
      "epoch:17 step:16616 [D loss: 0.671554, acc.: 53.91%] [G loss: 0.921168]\n",
      "epoch:17 step:16617 [D loss: 0.691622, acc.: 55.47%] [G loss: 0.958807]\n",
      "epoch:17 step:16618 [D loss: 0.666669, acc.: 60.94%] [G loss: 0.933236]\n",
      "epoch:17 step:16619 [D loss: 0.714534, acc.: 54.69%] [G loss: 0.854583]\n",
      "epoch:17 step:16620 [D loss: 0.715584, acc.: 55.47%] [G loss: 0.886752]\n",
      "epoch:17 step:16621 [D loss: 0.683018, acc.: 60.16%] [G loss: 0.860170]\n",
      "epoch:17 step:16622 [D loss: 0.649957, acc.: 59.38%] [G loss: 0.921029]\n",
      "epoch:17 step:16623 [D loss: 0.584184, acc.: 67.19%] [G loss: 0.973541]\n",
      "epoch:17 step:16624 [D loss: 0.723342, acc.: 46.88%] [G loss: 0.955696]\n",
      "epoch:17 step:16625 [D loss: 0.584303, acc.: 71.09%] [G loss: 0.789635]\n",
      "epoch:17 step:16626 [D loss: 0.560241, acc.: 70.31%] [G loss: 0.941842]\n",
      "epoch:17 step:16627 [D loss: 0.655995, acc.: 66.41%] [G loss: 0.884567]\n",
      "epoch:17 step:16628 [D loss: 0.672048, acc.: 58.59%] [G loss: 0.902900]\n",
      "epoch:17 step:16629 [D loss: 0.657270, acc.: 65.62%] [G loss: 0.855819]\n",
      "epoch:17 step:16630 [D loss: 0.591400, acc.: 67.97%] [G loss: 0.939929]\n",
      "epoch:17 step:16631 [D loss: 0.533778, acc.: 78.91%] [G loss: 0.956006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16632 [D loss: 0.748014, acc.: 41.41%] [G loss: 0.952570]\n",
      "epoch:17 step:16633 [D loss: 0.545648, acc.: 81.25%] [G loss: 0.969205]\n",
      "epoch:17 step:16634 [D loss: 0.700877, acc.: 59.38%] [G loss: 0.901603]\n",
      "epoch:17 step:16635 [D loss: 0.466532, acc.: 93.75%] [G loss: 0.965877]\n",
      "epoch:17 step:16636 [D loss: 0.486952, acc.: 79.69%] [G loss: 0.918028]\n",
      "epoch:17 step:16637 [D loss: 0.403109, acc.: 91.41%] [G loss: 0.903751]\n",
      "epoch:17 step:16638 [D loss: 0.391983, acc.: 89.06%] [G loss: 0.950263]\n",
      "epoch:17 step:16639 [D loss: 0.855547, acc.: 34.38%] [G loss: 1.061892]\n",
      "epoch:17 step:16640 [D loss: 0.665816, acc.: 54.69%] [G loss: 1.022350]\n",
      "epoch:17 step:16641 [D loss: 0.560357, acc.: 77.34%] [G loss: 0.922301]\n",
      "epoch:17 step:16642 [D loss: 0.724222, acc.: 57.03%] [G loss: 1.049534]\n",
      "epoch:17 step:16643 [D loss: 0.330379, acc.: 95.31%] [G loss: 1.280842]\n",
      "epoch:17 step:16644 [D loss: 0.740773, acc.: 53.12%] [G loss: 0.906571]\n",
      "epoch:17 step:16645 [D loss: 0.694350, acc.: 57.03%] [G loss: 1.089580]\n",
      "epoch:17 step:16646 [D loss: 0.717712, acc.: 50.00%] [G loss: 0.812290]\n",
      "epoch:17 step:16647 [D loss: 0.788828, acc.: 40.62%] [G loss: 0.914532]\n",
      "epoch:17 step:16648 [D loss: 0.714869, acc.: 49.22%] [G loss: 1.037303]\n",
      "epoch:17 step:16649 [D loss: 0.655926, acc.: 61.72%] [G loss: 1.039415]\n",
      "epoch:17 step:16650 [D loss: 0.770428, acc.: 42.19%] [G loss: 1.021918]\n",
      "epoch:17 step:16651 [D loss: 0.790510, acc.: 46.09%] [G loss: 0.975569]\n",
      "epoch:17 step:16652 [D loss: 0.656862, acc.: 60.16%] [G loss: 0.951060]\n",
      "epoch:17 step:16653 [D loss: 0.658505, acc.: 51.56%] [G loss: 1.036428]\n",
      "epoch:17 step:16654 [D loss: 0.640150, acc.: 57.03%] [G loss: 1.070583]\n",
      "epoch:17 step:16655 [D loss: 0.638295, acc.: 60.94%] [G loss: 0.955383]\n",
      "epoch:17 step:16656 [D loss: 0.657885, acc.: 59.38%] [G loss: 0.998343]\n",
      "epoch:17 step:16657 [D loss: 0.589733, acc.: 67.19%] [G loss: 0.978558]\n",
      "epoch:17 step:16658 [D loss: 0.645227, acc.: 69.53%] [G loss: 0.984883]\n",
      "epoch:17 step:16659 [D loss: 0.670036, acc.: 63.28%] [G loss: 0.914654]\n",
      "epoch:17 step:16660 [D loss: 0.573616, acc.: 72.66%] [G loss: 0.809707]\n",
      "epoch:17 step:16661 [D loss: 0.562403, acc.: 75.00%] [G loss: 0.874449]\n",
      "epoch:17 step:16662 [D loss: 0.537256, acc.: 78.91%] [G loss: 0.862630]\n",
      "epoch:17 step:16663 [D loss: 0.772809, acc.: 42.97%] [G loss: 0.923894]\n",
      "epoch:17 step:16664 [D loss: 0.699933, acc.: 46.88%] [G loss: 0.920052]\n",
      "epoch:17 step:16665 [D loss: 0.716115, acc.: 50.00%] [G loss: 0.902791]\n",
      "epoch:17 step:16666 [D loss: 0.787566, acc.: 35.94%] [G loss: 0.944954]\n",
      "epoch:17 step:16667 [D loss: 0.675239, acc.: 56.25%] [G loss: 0.990458]\n",
      "epoch:17 step:16668 [D loss: 0.817706, acc.: 33.59%] [G loss: 0.997846]\n",
      "epoch:17 step:16669 [D loss: 0.742720, acc.: 50.00%] [G loss: 0.992458]\n",
      "epoch:17 step:16670 [D loss: 0.537059, acc.: 71.09%] [G loss: 0.978789]\n",
      "epoch:17 step:16671 [D loss: 0.576326, acc.: 66.41%] [G loss: 1.050828]\n",
      "epoch:17 step:16672 [D loss: 0.545874, acc.: 75.00%] [G loss: 1.000046]\n",
      "epoch:17 step:16673 [D loss: 0.573390, acc.: 69.53%] [G loss: 1.063287]\n",
      "epoch:17 step:16674 [D loss: 0.691819, acc.: 57.81%] [G loss: 1.047802]\n",
      "epoch:17 step:16675 [D loss: 0.720289, acc.: 47.66%] [G loss: 0.935781]\n",
      "epoch:17 step:16676 [D loss: 0.699698, acc.: 53.12%] [G loss: 0.871811]\n",
      "epoch:17 step:16677 [D loss: 0.640135, acc.: 64.06%] [G loss: 0.899030]\n",
      "epoch:17 step:16678 [D loss: 0.603637, acc.: 73.44%] [G loss: 0.884077]\n",
      "epoch:17 step:16679 [D loss: 0.538180, acc.: 75.78%] [G loss: 0.993853]\n",
      "epoch:17 step:16680 [D loss: 0.682457, acc.: 54.69%] [G loss: 0.794769]\n",
      "epoch:17 step:16681 [D loss: 0.727494, acc.: 52.34%] [G loss: 0.876235]\n",
      "epoch:17 step:16682 [D loss: 0.691512, acc.: 56.25%] [G loss: 0.875175]\n",
      "epoch:17 step:16683 [D loss: 0.759487, acc.: 42.19%] [G loss: 0.811141]\n",
      "epoch:17 step:16684 [D loss: 0.652095, acc.: 62.50%] [G loss: 0.867538]\n",
      "epoch:17 step:16685 [D loss: 0.624748, acc.: 60.94%] [G loss: 0.765317]\n",
      "epoch:17 step:16686 [D loss: 0.645426, acc.: 59.38%] [G loss: 0.810209]\n",
      "epoch:17 step:16687 [D loss: 0.672816, acc.: 60.16%] [G loss: 0.767575]\n",
      "epoch:17 step:16688 [D loss: 0.630503, acc.: 64.06%] [G loss: 0.802052]\n",
      "epoch:17 step:16689 [D loss: 0.672872, acc.: 57.03%] [G loss: 0.847269]\n",
      "epoch:17 step:16690 [D loss: 0.709981, acc.: 53.91%] [G loss: 0.848157]\n",
      "epoch:17 step:16691 [D loss: 0.671876, acc.: 54.69%] [G loss: 0.853471]\n",
      "epoch:17 step:16692 [D loss: 0.650352, acc.: 60.16%] [G loss: 0.860175]\n",
      "epoch:17 step:16693 [D loss: 0.617489, acc.: 59.38%] [G loss: 0.836300]\n",
      "epoch:17 step:16694 [D loss: 0.658337, acc.: 62.50%] [G loss: 0.839857]\n",
      "epoch:17 step:16695 [D loss: 0.618624, acc.: 66.41%] [G loss: 0.787607]\n",
      "epoch:17 step:16696 [D loss: 0.620980, acc.: 64.84%] [G loss: 0.859748]\n",
      "epoch:17 step:16697 [D loss: 0.551380, acc.: 78.91%] [G loss: 0.922014]\n",
      "epoch:17 step:16698 [D loss: 0.554653, acc.: 74.22%] [G loss: 0.962365]\n",
      "epoch:17 step:16699 [D loss: 0.629848, acc.: 63.28%] [G loss: 1.052682]\n",
      "epoch:17 step:16700 [D loss: 0.607768, acc.: 75.00%] [G loss: 0.950748]\n",
      "epoch:17 step:16701 [D loss: 0.673236, acc.: 59.38%] [G loss: 0.939625]\n",
      "epoch:17 step:16702 [D loss: 0.595062, acc.: 67.97%] [G loss: 0.934790]\n",
      "epoch:17 step:16703 [D loss: 0.526062, acc.: 83.59%] [G loss: 0.946044]\n",
      "epoch:17 step:16704 [D loss: 0.503296, acc.: 81.25%] [G loss: 0.970151]\n",
      "epoch:17 step:16705 [D loss: 0.672693, acc.: 62.50%] [G loss: 0.888980]\n",
      "epoch:17 step:16706 [D loss: 0.589220, acc.: 75.00%] [G loss: 0.887898]\n",
      "epoch:17 step:16707 [D loss: 0.734994, acc.: 53.12%] [G loss: 0.916637]\n",
      "epoch:17 step:16708 [D loss: 0.696909, acc.: 51.56%] [G loss: 0.875369]\n",
      "epoch:17 step:16709 [D loss: 0.594478, acc.: 65.62%] [G loss: 1.104604]\n",
      "epoch:17 step:16710 [D loss: 0.533221, acc.: 71.88%] [G loss: 0.968955]\n",
      "epoch:17 step:16711 [D loss: 0.615616, acc.: 64.06%] [G loss: 1.026556]\n",
      "epoch:17 step:16712 [D loss: 0.661413, acc.: 65.62%] [G loss: 0.927170]\n",
      "epoch:17 step:16713 [D loss: 0.636444, acc.: 64.06%] [G loss: 0.977317]\n",
      "epoch:17 step:16714 [D loss: 0.642343, acc.: 61.72%] [G loss: 0.895747]\n",
      "epoch:17 step:16715 [D loss: 0.542757, acc.: 73.44%] [G loss: 0.902533]\n",
      "epoch:17 step:16716 [D loss: 0.699844, acc.: 53.91%] [G loss: 0.771160]\n",
      "epoch:17 step:16717 [D loss: 0.690854, acc.: 57.81%] [G loss: 0.870233]\n",
      "epoch:17 step:16718 [D loss: 0.864525, acc.: 37.50%] [G loss: 0.670292]\n",
      "epoch:17 step:16719 [D loss: 0.694280, acc.: 55.47%] [G loss: 0.777157]\n",
      "epoch:17 step:16720 [D loss: 0.569173, acc.: 60.94%] [G loss: 0.851213]\n",
      "epoch:17 step:16721 [D loss: 0.460005, acc.: 80.47%] [G loss: 0.919226]\n",
      "epoch:17 step:16722 [D loss: 0.535233, acc.: 73.44%] [G loss: 0.882474]\n",
      "epoch:17 step:16723 [D loss: 0.525681, acc.: 71.09%] [G loss: 0.776658]\n",
      "epoch:17 step:16724 [D loss: 0.776244, acc.: 50.00%] [G loss: 0.824072]\n",
      "epoch:17 step:16725 [D loss: 0.565570, acc.: 67.97%] [G loss: 1.277856]\n",
      "epoch:17 step:16726 [D loss: 0.705119, acc.: 60.16%] [G loss: 0.914200]\n",
      "epoch:17 step:16727 [D loss: 0.709578, acc.: 55.47%] [G loss: 0.941965]\n",
      "epoch:17 step:16728 [D loss: 0.818075, acc.: 42.19%] [G loss: 0.907817]\n",
      "epoch:17 step:16729 [D loss: 0.704884, acc.: 47.66%] [G loss: 0.804233]\n",
      "epoch:17 step:16730 [D loss: 0.625830, acc.: 64.06%] [G loss: 0.951970]\n",
      "epoch:17 step:16731 [D loss: 0.352058, acc.: 84.38%] [G loss: 0.946055]\n",
      "epoch:17 step:16732 [D loss: 0.657228, acc.: 59.38%] [G loss: 0.907033]\n",
      "epoch:17 step:16733 [D loss: 0.614664, acc.: 67.19%] [G loss: 0.972418]\n",
      "epoch:17 step:16734 [D loss: 0.688567, acc.: 55.47%] [G loss: 0.869093]\n",
      "epoch:17 step:16735 [D loss: 0.551813, acc.: 74.22%] [G loss: 0.873911]\n",
      "epoch:17 step:16736 [D loss: 0.676581, acc.: 53.91%] [G loss: 0.994799]\n",
      "epoch:17 step:16737 [D loss: 0.576990, acc.: 69.53%] [G loss: 1.143071]\n",
      "epoch:17 step:16738 [D loss: 0.674481, acc.: 56.25%] [G loss: 1.025616]\n",
      "epoch:17 step:16739 [D loss: 0.600685, acc.: 60.16%] [G loss: 1.141679]\n",
      "epoch:17 step:16740 [D loss: 0.762238, acc.: 50.00%] [G loss: 0.995582]\n",
      "epoch:17 step:16741 [D loss: 0.749200, acc.: 41.41%] [G loss: 0.892069]\n",
      "epoch:17 step:16742 [D loss: 0.628854, acc.: 63.28%] [G loss: 0.892027]\n",
      "epoch:17 step:16743 [D loss: 0.623659, acc.: 62.50%] [G loss: 0.906255]\n",
      "epoch:17 step:16744 [D loss: 0.473454, acc.: 78.12%] [G loss: 0.998642]\n",
      "epoch:17 step:16745 [D loss: 0.467604, acc.: 89.06%] [G loss: 1.008693]\n",
      "epoch:17 step:16746 [D loss: 0.752942, acc.: 45.31%] [G loss: 1.092546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16747 [D loss: 0.633442, acc.: 60.94%] [G loss: 0.965608]\n",
      "epoch:17 step:16748 [D loss: 0.572774, acc.: 68.75%] [G loss: 1.018142]\n",
      "epoch:17 step:16749 [D loss: 0.719310, acc.: 53.12%] [G loss: 1.016394]\n",
      "epoch:17 step:16750 [D loss: 0.929488, acc.: 27.34%] [G loss: 0.980397]\n",
      "epoch:17 step:16751 [D loss: 0.776206, acc.: 39.06%] [G loss: 1.000877]\n",
      "epoch:17 step:16752 [D loss: 0.685891, acc.: 57.81%] [G loss: 0.842789]\n",
      "epoch:17 step:16753 [D loss: 0.580480, acc.: 76.56%] [G loss: 1.028272]\n",
      "epoch:17 step:16754 [D loss: 0.598285, acc.: 71.09%] [G loss: 1.001247]\n",
      "epoch:17 step:16755 [D loss: 0.601338, acc.: 75.00%] [G loss: 0.990126]\n",
      "epoch:17 step:16756 [D loss: 0.700514, acc.: 53.91%] [G loss: 0.949441]\n",
      "epoch:17 step:16757 [D loss: 0.877923, acc.: 26.56%] [G loss: 0.948934]\n",
      "epoch:17 step:16758 [D loss: 0.683407, acc.: 57.81%] [G loss: 0.935647]\n",
      "epoch:17 step:16759 [D loss: 0.642635, acc.: 64.06%] [G loss: 0.929697]\n",
      "epoch:17 step:16760 [D loss: 0.572397, acc.: 71.09%] [G loss: 0.966302]\n",
      "epoch:17 step:16761 [D loss: 0.558086, acc.: 70.31%] [G loss: 1.031872]\n",
      "epoch:17 step:16762 [D loss: 0.543064, acc.: 81.25%] [G loss: 0.767852]\n",
      "epoch:17 step:16763 [D loss: 0.818275, acc.: 35.16%] [G loss: 0.764720]\n",
      "epoch:17 step:16764 [D loss: 0.783333, acc.: 37.50%] [G loss: 0.815760]\n",
      "epoch:17 step:16765 [D loss: 0.773136, acc.: 36.72%] [G loss: 0.843197]\n",
      "epoch:17 step:16766 [D loss: 0.695300, acc.: 56.25%] [G loss: 0.848279]\n",
      "epoch:17 step:16767 [D loss: 0.649492, acc.: 63.28%] [G loss: 0.848983]\n",
      "epoch:17 step:16768 [D loss: 0.746966, acc.: 43.75%] [G loss: 0.845067]\n",
      "epoch:17 step:16769 [D loss: 0.684767, acc.: 57.81%] [G loss: 0.819332]\n",
      "epoch:17 step:16770 [D loss: 0.712638, acc.: 49.22%] [G loss: 0.773713]\n",
      "epoch:17 step:16771 [D loss: 0.650349, acc.: 64.06%] [G loss: 0.787871]\n",
      "epoch:17 step:16772 [D loss: 0.778787, acc.: 43.75%] [G loss: 0.844253]\n",
      "epoch:17 step:16773 [D loss: 0.623709, acc.: 65.62%] [G loss: 0.866864]\n",
      "epoch:17 step:16774 [D loss: 0.575696, acc.: 73.44%] [G loss: 0.953063]\n",
      "epoch:17 step:16775 [D loss: 0.673118, acc.: 56.25%] [G loss: 0.718306]\n",
      "epoch:17 step:16776 [D loss: 0.644678, acc.: 59.38%] [G loss: 0.855058]\n",
      "epoch:17 step:16777 [D loss: 0.710179, acc.: 44.53%] [G loss: 0.829892]\n",
      "epoch:17 step:16778 [D loss: 0.746201, acc.: 47.66%] [G loss: 0.850364]\n",
      "epoch:17 step:16779 [D loss: 0.663256, acc.: 55.47%] [G loss: 0.784307]\n",
      "epoch:17 step:16780 [D loss: 0.561188, acc.: 76.56%] [G loss: 0.869756]\n",
      "epoch:17 step:16781 [D loss: 0.537090, acc.: 78.91%] [G loss: 0.951378]\n",
      "epoch:17 step:16782 [D loss: 0.510231, acc.: 81.25%] [G loss: 1.056208]\n",
      "epoch:17 step:16783 [D loss: 0.482145, acc.: 80.47%] [G loss: 1.082694]\n",
      "epoch:17 step:16784 [D loss: 0.581029, acc.: 72.66%] [G loss: 1.074779]\n",
      "epoch:17 step:16785 [D loss: 0.647035, acc.: 68.75%] [G loss: 1.028685]\n",
      "epoch:17 step:16786 [D loss: 0.469903, acc.: 82.81%] [G loss: 1.005389]\n",
      "epoch:17 step:16787 [D loss: 0.737233, acc.: 53.91%] [G loss: 0.945245]\n",
      "epoch:17 step:16788 [D loss: 0.744029, acc.: 48.44%] [G loss: 0.826441]\n",
      "epoch:17 step:16789 [D loss: 0.671761, acc.: 62.50%] [G loss: 0.851341]\n",
      "epoch:17 step:16790 [D loss: 0.635903, acc.: 57.81%] [G loss: 0.745545]\n",
      "epoch:17 step:16791 [D loss: 0.727014, acc.: 49.22%] [G loss: 0.797626]\n",
      "epoch:17 step:16792 [D loss: 0.703609, acc.: 45.31%] [G loss: 0.688228]\n",
      "epoch:17 step:16793 [D loss: 0.712347, acc.: 47.66%] [G loss: 0.821802]\n",
      "epoch:17 step:16794 [D loss: 0.591889, acc.: 74.22%] [G loss: 0.809430]\n",
      "epoch:17 step:16795 [D loss: 0.628324, acc.: 66.41%] [G loss: 0.878009]\n",
      "epoch:17 step:16796 [D loss: 0.615866, acc.: 62.50%] [G loss: 0.773010]\n",
      "epoch:17 step:16797 [D loss: 0.712546, acc.: 48.44%] [G loss: 0.980417]\n",
      "epoch:17 step:16798 [D loss: 0.711476, acc.: 51.56%] [G loss: 0.945370]\n",
      "epoch:17 step:16799 [D loss: 0.698261, acc.: 50.78%] [G loss: 0.822354]\n",
      "epoch:17 step:16800 [D loss: 0.654093, acc.: 60.16%] [G loss: 0.667838]\n",
      "epoch:17 step:16801 [D loss: 0.607345, acc.: 64.06%] [G loss: 0.901865]\n",
      "epoch:17 step:16802 [D loss: 0.579257, acc.: 75.78%] [G loss: 0.778052]\n",
      "epoch:17 step:16803 [D loss: 0.671595, acc.: 57.81%] [G loss: 0.812646]\n",
      "epoch:17 step:16804 [D loss: 0.936729, acc.: 43.75%] [G loss: 0.813985]\n",
      "epoch:17 step:16805 [D loss: 0.705514, acc.: 46.09%] [G loss: 0.834277]\n",
      "epoch:17 step:16806 [D loss: 0.631121, acc.: 62.50%] [G loss: 1.019892]\n",
      "epoch:17 step:16807 [D loss: 0.703861, acc.: 57.03%] [G loss: 0.965166]\n",
      "epoch:17 step:16808 [D loss: 0.662100, acc.: 61.72%] [G loss: 1.024830]\n",
      "epoch:17 step:16809 [D loss: 0.776915, acc.: 35.16%] [G loss: 0.927488]\n",
      "epoch:17 step:16810 [D loss: 0.713841, acc.: 48.44%] [G loss: 0.869058]\n",
      "epoch:17 step:16811 [D loss: 0.599800, acc.: 71.88%] [G loss: 0.808867]\n",
      "epoch:17 step:16812 [D loss: 0.636671, acc.: 62.50%] [G loss: 0.869072]\n",
      "epoch:17 step:16813 [D loss: 0.606966, acc.: 70.31%] [G loss: 0.660760]\n",
      "epoch:17 step:16814 [D loss: 0.496069, acc.: 89.06%] [G loss: 0.964075]\n",
      "epoch:17 step:16815 [D loss: 0.499132, acc.: 82.03%] [G loss: 0.947028]\n",
      "epoch:17 step:16816 [D loss: 0.491245, acc.: 78.12%] [G loss: 0.787060]\n",
      "epoch:17 step:16817 [D loss: 0.733003, acc.: 45.31%] [G loss: 0.916256]\n",
      "epoch:17 step:16818 [D loss: 0.701017, acc.: 59.38%] [G loss: 0.937137]\n",
      "epoch:17 step:16819 [D loss: 0.734912, acc.: 46.09%] [G loss: 0.953216]\n",
      "epoch:17 step:16820 [D loss: 0.761105, acc.: 45.31%] [G loss: 0.955223]\n",
      "epoch:17 step:16821 [D loss: 0.814135, acc.: 38.28%] [G loss: 0.957148]\n",
      "epoch:17 step:16822 [D loss: 0.662984, acc.: 63.28%] [G loss: 0.821187]\n",
      "epoch:17 step:16823 [D loss: 0.691850, acc.: 52.34%] [G loss: 1.029804]\n",
      "epoch:17 step:16824 [D loss: 0.700796, acc.: 51.56%] [G loss: 0.963440]\n",
      "epoch:17 step:16825 [D loss: 0.614965, acc.: 61.72%] [G loss: 1.019039]\n",
      "epoch:17 step:16826 [D loss: 0.592322, acc.: 74.22%] [G loss: 1.094644]\n",
      "epoch:17 step:16827 [D loss: 0.534211, acc.: 75.78%] [G loss: 1.101328]\n",
      "epoch:17 step:16828 [D loss: 0.411078, acc.: 88.28%] [G loss: 1.221905]\n",
      "epoch:17 step:16829 [D loss: 0.448848, acc.: 82.03%] [G loss: 1.241303]\n",
      "epoch:17 step:16830 [D loss: 0.528721, acc.: 74.22%] [G loss: 1.175320]\n",
      "epoch:17 step:16831 [D loss: 0.587528, acc.: 67.97%] [G loss: 1.134907]\n",
      "epoch:17 step:16832 [D loss: 0.561583, acc.: 71.88%] [G loss: 1.091635]\n",
      "epoch:17 step:16833 [D loss: 0.850582, acc.: 42.19%] [G loss: 0.757741]\n",
      "epoch:17 step:16834 [D loss: 0.746091, acc.: 45.31%] [G loss: 0.884831]\n",
      "epoch:17 step:16835 [D loss: 0.744258, acc.: 50.00%] [G loss: 0.871347]\n",
      "epoch:17 step:16836 [D loss: 0.685754, acc.: 60.94%] [G loss: 0.831329]\n",
      "epoch:17 step:16837 [D loss: 0.657796, acc.: 62.50%] [G loss: 0.793200]\n",
      "epoch:17 step:16838 [D loss: 0.624726, acc.: 64.84%] [G loss: 0.912713]\n",
      "epoch:17 step:16839 [D loss: 0.791092, acc.: 33.59%] [G loss: 0.847999]\n",
      "epoch:17 step:16840 [D loss: 0.509403, acc.: 79.69%] [G loss: 0.896212]\n",
      "epoch:17 step:16841 [D loss: 0.336172, acc.: 80.47%] [G loss: 0.872718]\n",
      "epoch:17 step:16842 [D loss: 0.613266, acc.: 71.88%] [G loss: 0.944613]\n",
      "epoch:17 step:16843 [D loss: 0.652033, acc.: 64.06%] [G loss: 0.909913]\n",
      "epoch:17 step:16844 [D loss: 0.712357, acc.: 52.34%] [G loss: 0.833411]\n",
      "epoch:17 step:16845 [D loss: 0.851033, acc.: 41.41%] [G loss: 0.751755]\n",
      "epoch:17 step:16846 [D loss: 0.760622, acc.: 40.62%] [G loss: 0.865212]\n",
      "epoch:17 step:16847 [D loss: 0.634947, acc.: 67.97%] [G loss: 0.746725]\n",
      "epoch:17 step:16848 [D loss: 0.550002, acc.: 76.56%] [G loss: 0.745999]\n",
      "epoch:17 step:16849 [D loss: 0.674864, acc.: 57.03%] [G loss: 0.929241]\n",
      "epoch:17 step:16850 [D loss: 0.636075, acc.: 60.94%] [G loss: 0.819667]\n",
      "epoch:17 step:16851 [D loss: 0.587567, acc.: 73.44%] [G loss: 0.865386]\n",
      "epoch:17 step:16852 [D loss: 0.632496, acc.: 64.06%] [G loss: 0.853981]\n",
      "epoch:17 step:16853 [D loss: 0.490721, acc.: 77.34%] [G loss: 0.886808]\n",
      "epoch:17 step:16854 [D loss: 0.549088, acc.: 71.88%] [G loss: 0.922241]\n",
      "epoch:17 step:16855 [D loss: 0.373061, acc.: 81.25%] [G loss: 0.966941]\n",
      "epoch:17 step:16856 [D loss: 0.320296, acc.: 85.94%] [G loss: 0.931418]\n",
      "epoch:17 step:16857 [D loss: 0.731273, acc.: 53.91%] [G loss: 0.924334]\n",
      "epoch:17 step:16858 [D loss: 0.525583, acc.: 85.16%] [G loss: 0.995666]\n",
      "epoch:17 step:16859 [D loss: 0.513522, acc.: 85.94%] [G loss: 0.955946]\n",
      "epoch:17 step:16860 [D loss: 0.575857, acc.: 72.66%] [G loss: 0.981719]\n",
      "epoch:17 step:16861 [D loss: 0.640419, acc.: 62.50%] [G loss: 0.952815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16862 [D loss: 0.476006, acc.: 76.56%] [G loss: 0.799307]\n",
      "epoch:17 step:16863 [D loss: 0.432332, acc.: 82.03%] [G loss: 0.939717]\n",
      "epoch:17 step:16864 [D loss: 0.503493, acc.: 77.34%] [G loss: 0.959819]\n",
      "epoch:17 step:16865 [D loss: 0.298709, acc.: 89.84%] [G loss: 1.013210]\n",
      "epoch:17 step:16866 [D loss: 0.240189, acc.: 93.75%] [G loss: 1.161885]\n",
      "epoch:18 step:16867 [D loss: 0.811246, acc.: 45.31%] [G loss: 0.835562]\n",
      "epoch:18 step:16868 [D loss: 0.746888, acc.: 47.66%] [G loss: 0.991807]\n",
      "epoch:18 step:16869 [D loss: 0.734039, acc.: 48.44%] [G loss: 1.067162]\n",
      "epoch:18 step:16870 [D loss: 0.811126, acc.: 39.06%] [G loss: 0.970616]\n",
      "epoch:18 step:16871 [D loss: 0.678287, acc.: 60.94%] [G loss: 1.046874]\n",
      "epoch:18 step:16872 [D loss: 0.711949, acc.: 53.91%] [G loss: 1.006823]\n",
      "epoch:18 step:16873 [D loss: 0.679084, acc.: 59.38%] [G loss: 0.902303]\n",
      "epoch:18 step:16874 [D loss: 0.727484, acc.: 47.66%] [G loss: 0.717480]\n",
      "epoch:18 step:16875 [D loss: 0.657393, acc.: 57.03%] [G loss: 0.800608]\n",
      "epoch:18 step:16876 [D loss: 0.851980, acc.: 42.19%] [G loss: 0.897255]\n",
      "epoch:18 step:16877 [D loss: 0.735672, acc.: 50.78%] [G loss: 1.134934]\n",
      "epoch:18 step:16878 [D loss: 0.716145, acc.: 47.66%] [G loss: 0.907037]\n",
      "epoch:18 step:16879 [D loss: 0.693667, acc.: 55.47%] [G loss: 0.856047]\n",
      "epoch:18 step:16880 [D loss: 0.704562, acc.: 52.34%] [G loss: 0.884690]\n",
      "epoch:18 step:16881 [D loss: 0.690316, acc.: 56.25%] [G loss: 1.174615]\n",
      "epoch:18 step:16882 [D loss: 0.698875, acc.: 46.88%] [G loss: 0.924039]\n",
      "epoch:18 step:16883 [D loss: 0.753883, acc.: 41.41%] [G loss: 1.069926]\n",
      "epoch:18 step:16884 [D loss: 0.694301, acc.: 54.69%] [G loss: 0.949563]\n",
      "epoch:18 step:16885 [D loss: 0.690501, acc.: 48.44%] [G loss: 0.893374]\n",
      "epoch:18 step:16886 [D loss: 0.659549, acc.: 59.38%] [G loss: 0.940338]\n",
      "epoch:18 step:16887 [D loss: 0.721412, acc.: 50.00%] [G loss: 0.993456]\n",
      "epoch:18 step:16888 [D loss: 0.679133, acc.: 60.16%] [G loss: 0.830370]\n",
      "epoch:18 step:16889 [D loss: 0.667144, acc.: 57.03%] [G loss: 0.916206]\n",
      "epoch:18 step:16890 [D loss: 0.712104, acc.: 53.12%] [G loss: 1.006230]\n",
      "epoch:18 step:16891 [D loss: 0.709532, acc.: 45.31%] [G loss: 0.866873]\n",
      "epoch:18 step:16892 [D loss: 0.701339, acc.: 56.25%] [G loss: 0.782807]\n",
      "epoch:18 step:16893 [D loss: 0.655922, acc.: 62.50%] [G loss: 0.901140]\n",
      "epoch:18 step:16894 [D loss: 0.658834, acc.: 63.28%] [G loss: 0.951111]\n",
      "epoch:18 step:16895 [D loss: 0.593316, acc.: 71.09%] [G loss: 0.876525]\n",
      "epoch:18 step:16896 [D loss: 0.669834, acc.: 56.25%] [G loss: 0.877347]\n",
      "epoch:18 step:16897 [D loss: 0.641909, acc.: 61.72%] [G loss: 0.856938]\n",
      "epoch:18 step:16898 [D loss: 0.556140, acc.: 75.00%] [G loss: 0.825570]\n",
      "epoch:18 step:16899 [D loss: 0.541064, acc.: 79.69%] [G loss: 0.894384]\n",
      "epoch:18 step:16900 [D loss: 0.483385, acc.: 89.84%] [G loss: 0.956669]\n",
      "epoch:18 step:16901 [D loss: 0.410022, acc.: 83.59%] [G loss: 1.769738]\n",
      "epoch:18 step:16902 [D loss: 0.402775, acc.: 83.59%] [G loss: 0.981170]\n",
      "epoch:18 step:16903 [D loss: 0.670885, acc.: 59.38%] [G loss: 1.484235]\n",
      "epoch:18 step:16904 [D loss: 0.914751, acc.: 45.31%] [G loss: 0.943703]\n",
      "epoch:18 step:16905 [D loss: 0.787092, acc.: 40.62%] [G loss: 0.787400]\n",
      "epoch:18 step:16906 [D loss: 0.687320, acc.: 55.47%] [G loss: 0.804061]\n",
      "epoch:18 step:16907 [D loss: 0.646986, acc.: 60.94%] [G loss: 0.815346]\n",
      "epoch:18 step:16908 [D loss: 0.643078, acc.: 61.72%] [G loss: 0.788932]\n",
      "epoch:18 step:16909 [D loss: 0.562150, acc.: 75.00%] [G loss: 0.814451]\n",
      "epoch:18 step:16910 [D loss: 0.676069, acc.: 57.81%] [G loss: 0.860741]\n",
      "epoch:18 step:16911 [D loss: 0.689441, acc.: 57.81%] [G loss: 0.855789]\n",
      "epoch:18 step:16912 [D loss: 0.604680, acc.: 72.66%] [G loss: 0.948556]\n",
      "epoch:18 step:16913 [D loss: 0.621310, acc.: 63.28%] [G loss: 0.726253]\n",
      "epoch:18 step:16914 [D loss: 0.650632, acc.: 62.50%] [G loss: 0.740949]\n",
      "epoch:18 step:16915 [D loss: 0.703376, acc.: 52.34%] [G loss: 0.696434]\n",
      "epoch:18 step:16916 [D loss: 0.584521, acc.: 69.53%] [G loss: 0.800850]\n",
      "epoch:18 step:16917 [D loss: 0.671702, acc.: 54.69%] [G loss: 0.786016]\n",
      "epoch:18 step:16918 [D loss: 0.719772, acc.: 57.81%] [G loss: 0.840307]\n",
      "epoch:18 step:16919 [D loss: 0.651731, acc.: 66.41%] [G loss: 0.865457]\n",
      "epoch:18 step:16920 [D loss: 0.761612, acc.: 45.31%] [G loss: 0.883871]\n",
      "epoch:18 step:16921 [D loss: 0.762207, acc.: 42.19%] [G loss: 0.810174]\n",
      "epoch:18 step:16922 [D loss: 0.804588, acc.: 36.72%] [G loss: 0.783175]\n",
      "epoch:18 step:16923 [D loss: 0.692006, acc.: 55.47%] [G loss: 0.760959]\n",
      "epoch:18 step:16924 [D loss: 0.607920, acc.: 67.19%] [G loss: 0.939170]\n",
      "epoch:18 step:16925 [D loss: 0.746823, acc.: 42.19%] [G loss: 0.909319]\n",
      "epoch:18 step:16926 [D loss: 0.607754, acc.: 69.53%] [G loss: 0.992594]\n",
      "epoch:18 step:16927 [D loss: 0.688560, acc.: 53.12%] [G loss: 0.958516]\n",
      "epoch:18 step:16928 [D loss: 0.652557, acc.: 57.03%] [G loss: 0.873764]\n",
      "epoch:18 step:16929 [D loss: 0.672064, acc.: 57.81%] [G loss: 0.860948]\n",
      "epoch:18 step:16930 [D loss: 0.654671, acc.: 64.06%] [G loss: 1.044714]\n",
      "epoch:18 step:16931 [D loss: 0.698631, acc.: 51.56%] [G loss: 1.108114]\n",
      "epoch:18 step:16932 [D loss: 0.717030, acc.: 47.66%] [G loss: 0.951424]\n",
      "epoch:18 step:16933 [D loss: 0.608451, acc.: 69.53%] [G loss: 1.034835]\n",
      "epoch:18 step:16934 [D loss: 0.552997, acc.: 75.78%] [G loss: 1.117617]\n",
      "epoch:18 step:16935 [D loss: 0.502884, acc.: 83.59%] [G loss: 1.092244]\n",
      "epoch:18 step:16936 [D loss: 0.577610, acc.: 67.97%] [G loss: 0.975231]\n",
      "epoch:18 step:16937 [D loss: 0.741141, acc.: 57.81%] [G loss: 1.023306]\n",
      "epoch:18 step:16938 [D loss: 0.627688, acc.: 69.53%] [G loss: 0.920699]\n",
      "epoch:18 step:16939 [D loss: 0.667183, acc.: 58.59%] [G loss: 1.019093]\n",
      "epoch:18 step:16940 [D loss: 0.648191, acc.: 60.16%] [G loss: 0.880643]\n",
      "epoch:18 step:16941 [D loss: 0.603634, acc.: 73.44%] [G loss: 0.922479]\n",
      "epoch:18 step:16942 [D loss: 0.668340, acc.: 60.94%] [G loss: 0.805690]\n",
      "epoch:18 step:16943 [D loss: 0.603410, acc.: 71.09%] [G loss: 0.765868]\n",
      "epoch:18 step:16944 [D loss: 0.814187, acc.: 39.06%] [G loss: 0.764740]\n",
      "epoch:18 step:16945 [D loss: 0.751255, acc.: 42.97%] [G loss: 0.914962]\n",
      "epoch:18 step:16946 [D loss: 0.631496, acc.: 64.06%] [G loss: 0.855368]\n",
      "epoch:18 step:16947 [D loss: 0.556315, acc.: 78.12%] [G loss: 0.938888]\n",
      "epoch:18 step:16948 [D loss: 0.483668, acc.: 84.38%] [G loss: 1.059566]\n",
      "epoch:18 step:16949 [D loss: 0.519295, acc.: 78.12%] [G loss: 1.090027]\n",
      "epoch:18 step:16950 [D loss: 0.587980, acc.: 68.75%] [G loss: 1.066026]\n",
      "epoch:18 step:16951 [D loss: 0.340179, acc.: 90.62%] [G loss: 1.112840]\n",
      "epoch:18 step:16952 [D loss: 0.599005, acc.: 71.09%] [G loss: 1.079109]\n",
      "epoch:18 step:16953 [D loss: 0.488542, acc.: 78.12%] [G loss: 0.959641]\n",
      "epoch:18 step:16954 [D loss: 0.440077, acc.: 88.28%] [G loss: 1.197582]\n",
      "epoch:18 step:16955 [D loss: 0.505900, acc.: 76.56%] [G loss: 1.061863]\n",
      "epoch:18 step:16956 [D loss: 0.613541, acc.: 65.62%] [G loss: 0.806382]\n",
      "epoch:18 step:16957 [D loss: 0.627327, acc.: 63.28%] [G loss: 0.871180]\n",
      "epoch:18 step:16958 [D loss: 0.701706, acc.: 60.94%] [G loss: 0.669625]\n",
      "epoch:18 step:16959 [D loss: 0.421353, acc.: 81.25%] [G loss: 0.785582]\n",
      "epoch:18 step:16960 [D loss: 0.726366, acc.: 51.56%] [G loss: 0.896800]\n",
      "epoch:18 step:16961 [D loss: 0.857486, acc.: 37.50%] [G loss: 0.861065]\n",
      "epoch:18 step:16962 [D loss: 0.776910, acc.: 41.41%] [G loss: 1.083838]\n",
      "epoch:18 step:16963 [D loss: 0.660552, acc.: 62.50%] [G loss: 1.022982]\n",
      "epoch:18 step:16964 [D loss: 0.856925, acc.: 36.72%] [G loss: 1.042043]\n",
      "epoch:18 step:16965 [D loss: 0.626328, acc.: 60.16%] [G loss: 1.011929]\n",
      "epoch:18 step:16966 [D loss: 0.798421, acc.: 43.75%] [G loss: 0.804665]\n",
      "epoch:18 step:16967 [D loss: 0.658585, acc.: 61.72%] [G loss: 0.828552]\n",
      "epoch:18 step:16968 [D loss: 0.702374, acc.: 54.69%] [G loss: 0.827039]\n",
      "epoch:18 step:16969 [D loss: 0.713444, acc.: 48.44%] [G loss: 0.899576]\n",
      "epoch:18 step:16970 [D loss: 0.718490, acc.: 47.66%] [G loss: 0.791485]\n",
      "epoch:18 step:16971 [D loss: 0.772309, acc.: 42.19%] [G loss: 0.837803]\n",
      "epoch:18 step:16972 [D loss: 0.677043, acc.: 57.03%] [G loss: 1.052601]\n",
      "epoch:18 step:16973 [D loss: 0.682667, acc.: 54.69%] [G loss: 1.080659]\n",
      "epoch:18 step:16974 [D loss: 0.644659, acc.: 60.94%] [G loss: 2.801118]\n",
      "epoch:18 step:16975 [D loss: 0.662378, acc.: 61.72%] [G loss: 1.153611]\n",
      "epoch:18 step:16976 [D loss: 0.587560, acc.: 71.88%] [G loss: 1.244267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16977 [D loss: 0.706302, acc.: 56.25%] [G loss: 0.908981]\n",
      "epoch:18 step:16978 [D loss: 0.586609, acc.: 74.22%] [G loss: 0.981654]\n",
      "epoch:18 step:16979 [D loss: 0.758786, acc.: 55.47%] [G loss: 0.867058]\n",
      "epoch:18 step:16980 [D loss: 0.661483, acc.: 61.72%] [G loss: 0.986699]\n",
      "epoch:18 step:16981 [D loss: 0.657636, acc.: 61.72%] [G loss: 0.768699]\n",
      "epoch:18 step:16982 [D loss: 0.657309, acc.: 60.94%] [G loss: 0.801399]\n",
      "epoch:18 step:16983 [D loss: 0.526867, acc.: 79.69%] [G loss: 0.958869]\n",
      "epoch:18 step:16984 [D loss: 0.534632, acc.: 79.69%] [G loss: 0.914380]\n",
      "epoch:18 step:16985 [D loss: 0.450816, acc.: 82.81%] [G loss: 1.076035]\n",
      "epoch:18 step:16986 [D loss: 0.777340, acc.: 47.66%] [G loss: 1.198874]\n",
      "epoch:18 step:16987 [D loss: 0.811993, acc.: 47.66%] [G loss: 1.023898]\n",
      "epoch:18 step:16988 [D loss: 0.719933, acc.: 54.69%] [G loss: 0.924231]\n",
      "epoch:18 step:16989 [D loss: 0.705487, acc.: 48.44%] [G loss: 0.874619]\n",
      "epoch:18 step:16990 [D loss: 0.588712, acc.: 74.22%] [G loss: 0.947603]\n",
      "epoch:18 step:16991 [D loss: 0.666656, acc.: 59.38%] [G loss: 0.802944]\n",
      "epoch:18 step:16992 [D loss: 0.649715, acc.: 64.06%] [G loss: 0.851183]\n",
      "epoch:18 step:16993 [D loss: 0.657226, acc.: 56.25%] [G loss: 0.764714]\n",
      "epoch:18 step:16994 [D loss: 0.721056, acc.: 48.44%] [G loss: 0.830724]\n",
      "epoch:18 step:16995 [D loss: 0.667681, acc.: 60.94%] [G loss: 0.830948]\n",
      "epoch:18 step:16996 [D loss: 0.671103, acc.: 58.59%] [G loss: 0.882426]\n",
      "epoch:18 step:16997 [D loss: 0.647827, acc.: 64.84%] [G loss: 0.759756]\n",
      "epoch:18 step:16998 [D loss: 0.630453, acc.: 65.62%] [G loss: 0.865608]\n",
      "epoch:18 step:16999 [D loss: 0.672131, acc.: 54.69%] [G loss: 0.891673]\n",
      "epoch:18 step:17000 [D loss: 0.623116, acc.: 71.09%] [G loss: 0.856818]\n",
      "epoch:18 step:17001 [D loss: 0.613996, acc.: 66.41%] [G loss: 0.828120]\n",
      "epoch:18 step:17002 [D loss: 0.607869, acc.: 66.41%] [G loss: 0.780497]\n",
      "epoch:18 step:17003 [D loss: 0.648053, acc.: 64.06%] [G loss: 0.852647]\n",
      "epoch:18 step:17004 [D loss: 0.681841, acc.: 57.03%] [G loss: 0.783719]\n",
      "epoch:18 step:17005 [D loss: 0.708202, acc.: 57.81%] [G loss: 0.743596]\n",
      "epoch:18 step:17006 [D loss: 0.596663, acc.: 68.75%] [G loss: 0.732351]\n",
      "epoch:18 step:17007 [D loss: 0.639972, acc.: 65.62%] [G loss: 0.813730]\n",
      "epoch:18 step:17008 [D loss: 0.716705, acc.: 45.31%] [G loss: 0.774443]\n",
      "epoch:18 step:17009 [D loss: 0.801038, acc.: 50.78%] [G loss: 0.862900]\n",
      "epoch:18 step:17010 [D loss: 0.559877, acc.: 76.56%] [G loss: 0.838412]\n",
      "epoch:18 step:17011 [D loss: 0.547277, acc.: 67.19%] [G loss: 0.853551]\n",
      "epoch:18 step:17012 [D loss: 0.567268, acc.: 68.75%] [G loss: 1.091782]\n",
      "epoch:18 step:17013 [D loss: 0.602114, acc.: 74.22%] [G loss: 0.919958]\n",
      "epoch:18 step:17014 [D loss: 0.712963, acc.: 57.03%] [G loss: 0.818015]\n",
      "epoch:18 step:17015 [D loss: 0.555009, acc.: 74.22%] [G loss: 0.948947]\n",
      "epoch:18 step:17016 [D loss: 0.451786, acc.: 76.56%] [G loss: 0.901354]\n",
      "epoch:18 step:17017 [D loss: 0.477066, acc.: 74.22%] [G loss: 0.996691]\n",
      "epoch:18 step:17018 [D loss: 0.649557, acc.: 63.28%] [G loss: 1.091085]\n",
      "epoch:18 step:17019 [D loss: 0.721717, acc.: 59.38%] [G loss: 1.005369]\n",
      "epoch:18 step:17020 [D loss: 0.706336, acc.: 54.69%] [G loss: 0.944018]\n",
      "epoch:18 step:17021 [D loss: 0.686286, acc.: 56.25%] [G loss: 0.941266]\n",
      "epoch:18 step:17022 [D loss: 0.754348, acc.: 43.75%] [G loss: 0.726952]\n",
      "epoch:18 step:17023 [D loss: 0.701049, acc.: 53.12%] [G loss: 0.890931]\n",
      "epoch:18 step:17024 [D loss: 0.759211, acc.: 36.72%] [G loss: 0.797778]\n",
      "epoch:18 step:17025 [D loss: 0.757217, acc.: 36.72%] [G loss: 0.906768]\n",
      "epoch:18 step:17026 [D loss: 0.705606, acc.: 52.34%] [G loss: 0.903830]\n",
      "epoch:18 step:17027 [D loss: 0.732173, acc.: 46.88%] [G loss: 0.843217]\n",
      "epoch:18 step:17028 [D loss: 0.672103, acc.: 60.94%] [G loss: 0.833578]\n",
      "epoch:18 step:17029 [D loss: 0.705914, acc.: 53.12%] [G loss: 0.799121]\n",
      "epoch:18 step:17030 [D loss: 0.686142, acc.: 53.12%] [G loss: 0.829094]\n",
      "epoch:18 step:17031 [D loss: 0.719403, acc.: 56.25%] [G loss: 0.844266]\n",
      "epoch:18 step:17032 [D loss: 0.657334, acc.: 50.78%] [G loss: 0.932173]\n",
      "epoch:18 step:17033 [D loss: 0.681885, acc.: 54.69%] [G loss: 0.822374]\n",
      "epoch:18 step:17034 [D loss: 0.608215, acc.: 66.41%] [G loss: 0.903726]\n",
      "epoch:18 step:17035 [D loss: 0.693047, acc.: 52.34%] [G loss: 0.895625]\n",
      "epoch:18 step:17036 [D loss: 0.678665, acc.: 57.03%] [G loss: 0.853051]\n",
      "epoch:18 step:17037 [D loss: 0.626241, acc.: 68.75%] [G loss: 0.852248]\n",
      "epoch:18 step:17038 [D loss: 0.620193, acc.: 69.53%] [G loss: 0.847717]\n",
      "epoch:18 step:17039 [D loss: 0.656105, acc.: 58.59%] [G loss: 0.843079]\n",
      "epoch:18 step:17040 [D loss: 0.691089, acc.: 53.91%] [G loss: 0.890623]\n",
      "epoch:18 step:17041 [D loss: 0.732334, acc.: 53.91%] [G loss: 0.841044]\n",
      "epoch:18 step:17042 [D loss: 0.642775, acc.: 63.28%] [G loss: 0.837931]\n",
      "epoch:18 step:17043 [D loss: 0.683005, acc.: 55.47%] [G loss: 0.832229]\n",
      "epoch:18 step:17044 [D loss: 0.691590, acc.: 50.78%] [G loss: 0.802767]\n",
      "epoch:18 step:17045 [D loss: 0.705350, acc.: 46.88%] [G loss: 0.749947]\n",
      "epoch:18 step:17046 [D loss: 0.678115, acc.: 53.91%] [G loss: 0.766438]\n",
      "epoch:18 step:17047 [D loss: 0.603415, acc.: 66.41%] [G loss: 0.794297]\n",
      "epoch:18 step:17048 [D loss: 0.681864, acc.: 56.25%] [G loss: 0.716265]\n",
      "epoch:18 step:17049 [D loss: 0.686646, acc.: 53.91%] [G loss: 0.756457]\n",
      "epoch:18 step:17050 [D loss: 0.632097, acc.: 65.62%] [G loss: 0.775873]\n",
      "epoch:18 step:17051 [D loss: 0.666545, acc.: 60.16%] [G loss: 0.769469]\n",
      "epoch:18 step:17052 [D loss: 0.696011, acc.: 55.47%] [G loss: 0.825619]\n",
      "epoch:18 step:17053 [D loss: 0.689925, acc.: 59.38%] [G loss: 0.825936]\n",
      "epoch:18 step:17054 [D loss: 0.671424, acc.: 60.94%] [G loss: 0.850079]\n",
      "epoch:18 step:17055 [D loss: 0.685268, acc.: 58.59%] [G loss: 0.782205]\n",
      "epoch:18 step:17056 [D loss: 0.657001, acc.: 62.50%] [G loss: 0.896391]\n",
      "epoch:18 step:17057 [D loss: 0.636580, acc.: 64.06%] [G loss: 0.861828]\n",
      "epoch:18 step:17058 [D loss: 0.576091, acc.: 73.44%] [G loss: 0.893464]\n",
      "epoch:18 step:17059 [D loss: 0.645203, acc.: 63.28%] [G loss: 0.840385]\n",
      "epoch:18 step:17060 [D loss: 0.573904, acc.: 78.12%] [G loss: 0.851757]\n",
      "epoch:18 step:17061 [D loss: 0.642664, acc.: 61.72%] [G loss: 0.841858]\n",
      "epoch:18 step:17062 [D loss: 0.640633, acc.: 59.38%] [G loss: 0.789017]\n",
      "epoch:18 step:17063 [D loss: 0.652463, acc.: 66.41%] [G loss: 0.816670]\n",
      "epoch:18 step:17064 [D loss: 0.624781, acc.: 71.09%] [G loss: 0.833028]\n",
      "epoch:18 step:17065 [D loss: 0.736520, acc.: 48.44%] [G loss: 0.960677]\n",
      "epoch:18 step:17066 [D loss: 0.794111, acc.: 41.41%] [G loss: 0.817051]\n",
      "epoch:18 step:17067 [D loss: 0.701032, acc.: 54.69%] [G loss: 0.782678]\n",
      "epoch:18 step:17068 [D loss: 0.656914, acc.: 57.81%] [G loss: 0.846988]\n",
      "epoch:18 step:17069 [D loss: 0.648296, acc.: 64.06%] [G loss: 0.792963]\n",
      "epoch:18 step:17070 [D loss: 0.444172, acc.: 85.94%] [G loss: 0.802033]\n",
      "epoch:18 step:17071 [D loss: 0.612321, acc.: 69.53%] [G loss: 0.689182]\n",
      "epoch:18 step:17072 [D loss: 0.564613, acc.: 73.44%] [G loss: 0.629310]\n",
      "epoch:18 step:17073 [D loss: 1.310795, acc.: 55.47%] [G loss: 0.990301]\n",
      "epoch:18 step:17074 [D loss: 0.605219, acc.: 64.06%] [G loss: 1.054369]\n",
      "epoch:18 step:17075 [D loss: 0.682219, acc.: 57.81%] [G loss: 1.025355]\n",
      "epoch:18 step:17076 [D loss: 0.760896, acc.: 53.12%] [G loss: 0.863595]\n",
      "epoch:18 step:17077 [D loss: 0.750687, acc.: 53.91%] [G loss: 0.963081]\n",
      "epoch:18 step:17078 [D loss: 0.721790, acc.: 50.78%] [G loss: 0.838513]\n",
      "epoch:18 step:17079 [D loss: 0.714625, acc.: 53.12%] [G loss: 0.906367]\n",
      "epoch:18 step:17080 [D loss: 0.732349, acc.: 53.12%] [G loss: 0.933892]\n",
      "epoch:18 step:17081 [D loss: 0.737959, acc.: 50.78%] [G loss: 1.024452]\n",
      "epoch:18 step:17082 [D loss: 0.771934, acc.: 53.91%] [G loss: 0.765838]\n",
      "epoch:18 step:17083 [D loss: 0.728260, acc.: 45.31%] [G loss: 0.752359]\n",
      "epoch:18 step:17084 [D loss: 0.654511, acc.: 61.72%] [G loss: 0.753020]\n",
      "epoch:18 step:17085 [D loss: 0.635236, acc.: 62.50%] [G loss: 0.759455]\n",
      "epoch:18 step:17086 [D loss: 0.547593, acc.: 80.47%] [G loss: 0.901550]\n",
      "epoch:18 step:17087 [D loss: 0.594429, acc.: 69.53%] [G loss: 0.809423]\n",
      "epoch:18 step:17088 [D loss: 0.586073, acc.: 73.44%] [G loss: 0.817731]\n",
      "epoch:18 step:17089 [D loss: 0.561063, acc.: 73.44%] [G loss: 0.897033]\n",
      "epoch:18 step:17090 [D loss: 0.674546, acc.: 49.22%] [G loss: 0.873762]\n",
      "epoch:18 step:17091 [D loss: 0.651858, acc.: 61.72%] [G loss: 0.926080]\n",
      "epoch:18 step:17092 [D loss: 0.662448, acc.: 60.94%] [G loss: 0.815663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17093 [D loss: 0.661722, acc.: 62.50%] [G loss: 0.793703]\n",
      "epoch:18 step:17094 [D loss: 0.657707, acc.: 60.16%] [G loss: 0.829822]\n",
      "epoch:18 step:17095 [D loss: 0.611214, acc.: 67.19%] [G loss: 0.808907]\n",
      "epoch:18 step:17096 [D loss: 0.441959, acc.: 75.78%] [G loss: 0.817026]\n",
      "epoch:18 step:17097 [D loss: 0.451518, acc.: 81.25%] [G loss: 0.842464]\n",
      "epoch:18 step:17098 [D loss: 0.428192, acc.: 85.16%] [G loss: 0.913351]\n",
      "epoch:18 step:17099 [D loss: 0.646696, acc.: 61.72%] [G loss: 1.025693]\n",
      "epoch:18 step:17100 [D loss: 0.591382, acc.: 67.97%] [G loss: 0.893743]\n",
      "epoch:18 step:17101 [D loss: 0.492234, acc.: 84.38%] [G loss: 0.852275]\n",
      "epoch:18 step:17102 [D loss: 0.661680, acc.: 62.50%] [G loss: 0.558948]\n",
      "epoch:18 step:17103 [D loss: 0.584806, acc.: 70.31%] [G loss: 0.881203]\n",
      "epoch:18 step:17104 [D loss: 0.687388, acc.: 58.59%] [G loss: 0.999102]\n",
      "epoch:18 step:17105 [D loss: 0.703435, acc.: 50.78%] [G loss: 0.823011]\n",
      "epoch:18 step:17106 [D loss: 0.729394, acc.: 52.34%] [G loss: 1.069580]\n",
      "epoch:18 step:17107 [D loss: 0.865757, acc.: 27.34%] [G loss: 0.797739]\n",
      "epoch:18 step:17108 [D loss: 0.670407, acc.: 63.28%] [G loss: 0.984562]\n",
      "epoch:18 step:17109 [D loss: 0.618415, acc.: 65.62%] [G loss: 0.930412]\n",
      "epoch:18 step:17110 [D loss: 0.701486, acc.: 53.12%] [G loss: 0.930522]\n",
      "epoch:18 step:17111 [D loss: 0.749165, acc.: 50.00%] [G loss: 0.925428]\n",
      "epoch:18 step:17112 [D loss: 0.770528, acc.: 45.31%] [G loss: 0.902902]\n",
      "epoch:18 step:17113 [D loss: 0.763252, acc.: 42.97%] [G loss: 0.937415]\n",
      "epoch:18 step:17114 [D loss: 0.631209, acc.: 61.72%] [G loss: 0.919470]\n",
      "epoch:18 step:17115 [D loss: 0.675023, acc.: 55.47%] [G loss: 0.914902]\n",
      "epoch:18 step:17116 [D loss: 0.649979, acc.: 60.16%] [G loss: 0.937397]\n",
      "epoch:18 step:17117 [D loss: 0.704178, acc.: 46.88%] [G loss: 0.973190]\n",
      "epoch:18 step:17118 [D loss: 0.651293, acc.: 62.50%] [G loss: 0.918728]\n",
      "epoch:18 step:17119 [D loss: 0.651735, acc.: 55.47%] [G loss: 0.902812]\n",
      "epoch:18 step:17120 [D loss: 0.669699, acc.: 65.62%] [G loss: 0.955700]\n",
      "epoch:18 step:17121 [D loss: 0.609166, acc.: 62.50%] [G loss: 0.898347]\n",
      "epoch:18 step:17122 [D loss: 0.566057, acc.: 74.22%] [G loss: 0.975484]\n",
      "epoch:18 step:17123 [D loss: 0.618779, acc.: 72.66%] [G loss: 0.894799]\n",
      "epoch:18 step:17124 [D loss: 0.673102, acc.: 60.16%] [G loss: 0.843742]\n",
      "epoch:18 step:17125 [D loss: 0.554835, acc.: 78.91%] [G loss: 0.949840]\n",
      "epoch:18 step:17126 [D loss: 0.582109, acc.: 77.34%] [G loss: 0.846589]\n",
      "epoch:18 step:17127 [D loss: 0.518585, acc.: 73.44%] [G loss: 0.804457]\n",
      "epoch:18 step:17128 [D loss: 0.744982, acc.: 42.97%] [G loss: 0.875848]\n",
      "epoch:18 step:17129 [D loss: 0.602159, acc.: 66.41%] [G loss: 0.938764]\n",
      "epoch:18 step:17130 [D loss: 0.571940, acc.: 69.53%] [G loss: 1.006710]\n",
      "epoch:18 step:17131 [D loss: 0.721168, acc.: 52.34%] [G loss: 0.857488]\n",
      "epoch:18 step:17132 [D loss: 0.723699, acc.: 46.88%] [G loss: 1.035748]\n",
      "epoch:18 step:17133 [D loss: 0.708000, acc.: 53.12%] [G loss: 1.024901]\n",
      "epoch:18 step:17134 [D loss: 0.643693, acc.: 62.50%] [G loss: 1.065184]\n",
      "epoch:18 step:17135 [D loss: 0.597509, acc.: 66.41%] [G loss: 0.939453]\n",
      "epoch:18 step:17136 [D loss: 0.604601, acc.: 60.94%] [G loss: 1.065947]\n",
      "epoch:18 step:17137 [D loss: 0.557508, acc.: 70.31%] [G loss: 1.119003]\n",
      "epoch:18 step:17138 [D loss: 0.577843, acc.: 68.75%] [G loss: 0.995569]\n",
      "epoch:18 step:17139 [D loss: 0.570410, acc.: 75.78%] [G loss: 0.979424]\n",
      "epoch:18 step:17140 [D loss: 0.598952, acc.: 68.75%] [G loss: 1.059417]\n",
      "epoch:18 step:17141 [D loss: 0.616761, acc.: 65.62%] [G loss: 1.099210]\n",
      "epoch:18 step:17142 [D loss: 0.545241, acc.: 70.31%] [G loss: 0.997175]\n",
      "epoch:18 step:17143 [D loss: 0.626989, acc.: 66.41%] [G loss: 0.857125]\n",
      "epoch:18 step:17144 [D loss: 0.724143, acc.: 50.78%] [G loss: 0.990383]\n",
      "epoch:18 step:17145 [D loss: 0.555902, acc.: 72.66%] [G loss: 1.112838]\n",
      "epoch:18 step:17146 [D loss: 0.628422, acc.: 66.41%] [G loss: 0.784126]\n",
      "epoch:18 step:17147 [D loss: 0.734134, acc.: 48.44%] [G loss: 0.879708]\n",
      "epoch:18 step:17148 [D loss: 0.690450, acc.: 55.47%] [G loss: 0.795807]\n",
      "epoch:18 step:17149 [D loss: 0.711037, acc.: 52.34%] [G loss: 0.821466]\n",
      "epoch:18 step:17150 [D loss: 0.552831, acc.: 79.69%] [G loss: 0.862320]\n",
      "epoch:18 step:17151 [D loss: 0.615936, acc.: 64.06%] [G loss: 0.842199]\n",
      "epoch:18 step:17152 [D loss: 0.528869, acc.: 73.44%] [G loss: 0.880347]\n",
      "epoch:18 step:17153 [D loss: 0.575086, acc.: 72.66%] [G loss: 1.036720]\n",
      "epoch:18 step:17154 [D loss: 0.529251, acc.: 74.22%] [G loss: 1.163724]\n",
      "epoch:18 step:17155 [D loss: 0.554038, acc.: 77.34%] [G loss: 0.735156]\n",
      "epoch:18 step:17156 [D loss: 0.482502, acc.: 80.47%] [G loss: 1.036771]\n",
      "epoch:18 step:17157 [D loss: 0.465072, acc.: 78.91%] [G loss: 0.921902]\n",
      "epoch:18 step:17158 [D loss: 0.514984, acc.: 78.91%] [G loss: 0.834578]\n",
      "epoch:18 step:17159 [D loss: 0.395527, acc.: 83.59%] [G loss: 1.046272]\n",
      "epoch:18 step:17160 [D loss: 0.593792, acc.: 67.19%] [G loss: 1.020581]\n",
      "epoch:18 step:17161 [D loss: 0.659613, acc.: 61.72%] [G loss: 0.839435]\n",
      "epoch:18 step:17162 [D loss: 0.741320, acc.: 50.00%] [G loss: 0.952807]\n",
      "epoch:18 step:17163 [D loss: 0.825555, acc.: 38.28%] [G loss: 0.906505]\n",
      "epoch:18 step:17164 [D loss: 0.775719, acc.: 45.31%] [G loss: 0.752961]\n",
      "epoch:18 step:17165 [D loss: 0.689157, acc.: 53.12%] [G loss: 0.875117]\n",
      "epoch:18 step:17166 [D loss: 0.910134, acc.: 37.50%] [G loss: 0.904610]\n",
      "epoch:18 step:17167 [D loss: 0.668330, acc.: 69.53%] [G loss: 0.866859]\n",
      "epoch:18 step:17168 [D loss: 0.804941, acc.: 43.75%] [G loss: 0.884994]\n",
      "epoch:18 step:17169 [D loss: 0.724711, acc.: 48.44%] [G loss: 0.785922]\n",
      "epoch:18 step:17170 [D loss: 0.769315, acc.: 46.09%] [G loss: 0.845908]\n",
      "epoch:18 step:17171 [D loss: 0.694521, acc.: 57.81%] [G loss: 0.884101]\n",
      "epoch:18 step:17172 [D loss: 0.737409, acc.: 53.91%] [G loss: 0.859059]\n",
      "epoch:18 step:17173 [D loss: 0.749834, acc.: 44.53%] [G loss: 0.892630]\n",
      "epoch:18 step:17174 [D loss: 0.688453, acc.: 52.34%] [G loss: 0.867605]\n",
      "epoch:18 step:17175 [D loss: 0.689086, acc.: 51.56%] [G loss: 0.910554]\n",
      "epoch:18 step:17176 [D loss: 0.693135, acc.: 51.56%] [G loss: 0.817353]\n",
      "epoch:18 step:17177 [D loss: 0.672747, acc.: 60.16%] [G loss: 0.837223]\n",
      "epoch:18 step:17178 [D loss: 0.604219, acc.: 71.09%] [G loss: 0.950654]\n",
      "epoch:18 step:17179 [D loss: 0.664384, acc.: 63.28%] [G loss: 0.930311]\n",
      "epoch:18 step:17180 [D loss: 0.572408, acc.: 71.88%] [G loss: 0.896905]\n",
      "epoch:18 step:17181 [D loss: 0.644462, acc.: 67.97%] [G loss: 0.953015]\n",
      "epoch:18 step:17182 [D loss: 0.681894, acc.: 56.25%] [G loss: 0.952377]\n",
      "epoch:18 step:17183 [D loss: 0.656331, acc.: 57.03%] [G loss: 0.878445]\n",
      "epoch:18 step:17184 [D loss: 0.688359, acc.: 56.25%] [G loss: 0.903778]\n",
      "epoch:18 step:17185 [D loss: 0.618618, acc.: 64.84%] [G loss: 1.033821]\n",
      "epoch:18 step:17186 [D loss: 0.630815, acc.: 62.50%] [G loss: 1.023452]\n",
      "epoch:18 step:17187 [D loss: 0.619481, acc.: 63.28%] [G loss: 1.117010]\n",
      "epoch:18 step:17188 [D loss: 0.582504, acc.: 67.19%] [G loss: 1.076136]\n",
      "epoch:18 step:17189 [D loss: 0.710493, acc.: 60.16%] [G loss: 0.964999]\n",
      "epoch:18 step:17190 [D loss: 0.701975, acc.: 50.78%] [G loss: 0.925410]\n",
      "epoch:18 step:17191 [D loss: 0.680112, acc.: 54.69%] [G loss: 0.995040]\n",
      "epoch:18 step:17192 [D loss: 0.597534, acc.: 71.09%] [G loss: 0.968999]\n",
      "epoch:18 step:17193 [D loss: 0.524405, acc.: 85.16%] [G loss: 0.919329]\n",
      "epoch:18 step:17194 [D loss: 0.487220, acc.: 86.72%] [G loss: 0.964339]\n",
      "epoch:18 step:17195 [D loss: 0.607260, acc.: 66.41%] [G loss: 1.041613]\n",
      "epoch:18 step:17196 [D loss: 0.695742, acc.: 58.59%] [G loss: 0.875930]\n",
      "epoch:18 step:17197 [D loss: 0.658801, acc.: 60.16%] [G loss: 0.952574]\n",
      "epoch:18 step:17198 [D loss: 0.752794, acc.: 47.66%] [G loss: 0.804826]\n",
      "epoch:18 step:17199 [D loss: 0.783402, acc.: 40.62%] [G loss: 0.839947]\n",
      "epoch:18 step:17200 [D loss: 0.694434, acc.: 51.56%] [G loss: 0.779082]\n",
      "epoch:18 step:17201 [D loss: 0.716485, acc.: 55.47%] [G loss: 0.805075]\n",
      "epoch:18 step:17202 [D loss: 0.755903, acc.: 40.62%] [G loss: 0.856079]\n",
      "epoch:18 step:17203 [D loss: 0.665099, acc.: 57.81%] [G loss: 0.784075]\n",
      "epoch:18 step:17204 [D loss: 0.675235, acc.: 53.91%] [G loss: 0.789908]\n",
      "epoch:18 step:17205 [D loss: 0.698782, acc.: 54.69%] [G loss: 0.802815]\n",
      "epoch:18 step:17206 [D loss: 0.682227, acc.: 56.25%] [G loss: 0.728847]\n",
      "epoch:18 step:17207 [D loss: 0.734457, acc.: 43.75%] [G loss: 0.804146]\n",
      "epoch:18 step:17208 [D loss: 0.714260, acc.: 42.97%] [G loss: 0.786242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17209 [D loss: 0.626767, acc.: 64.06%] [G loss: 0.922030]\n",
      "epoch:18 step:17210 [D loss: 0.568926, acc.: 76.56%] [G loss: 0.795929]\n",
      "epoch:18 step:17211 [D loss: 0.605568, acc.: 73.44%] [G loss: 0.800891]\n",
      "epoch:18 step:17212 [D loss: 0.610541, acc.: 71.09%] [G loss: 0.910045]\n",
      "epoch:18 step:17213 [D loss: 0.555220, acc.: 77.34%] [G loss: 0.839009]\n",
      "epoch:18 step:17214 [D loss: 0.658889, acc.: 56.25%] [G loss: 0.854903]\n",
      "epoch:18 step:17215 [D loss: 0.747271, acc.: 49.22%] [G loss: 0.905422]\n",
      "epoch:18 step:17216 [D loss: 0.639362, acc.: 65.62%] [G loss: 0.795498]\n",
      "epoch:18 step:17217 [D loss: 0.583883, acc.: 72.66%] [G loss: 0.866093]\n",
      "epoch:18 step:17218 [D loss: 0.600995, acc.: 67.19%] [G loss: 0.814868]\n",
      "epoch:18 step:17219 [D loss: 0.535583, acc.: 82.03%] [G loss: 0.946195]\n",
      "epoch:18 step:17220 [D loss: 0.583424, acc.: 76.56%] [G loss: 0.902228]\n",
      "epoch:18 step:17221 [D loss: 0.589737, acc.: 72.66%] [G loss: 0.932776]\n",
      "epoch:18 step:17222 [D loss: 0.609846, acc.: 67.97%] [G loss: 0.975309]\n",
      "epoch:18 step:17223 [D loss: 0.625487, acc.: 65.62%] [G loss: 0.876419]\n",
      "epoch:18 step:17224 [D loss: 0.522901, acc.: 77.34%] [G loss: 0.902066]\n",
      "epoch:18 step:17225 [D loss: 0.559625, acc.: 76.56%] [G loss: 0.933461]\n",
      "epoch:18 step:17226 [D loss: 0.582503, acc.: 71.09%] [G loss: 0.991814]\n",
      "epoch:18 step:17227 [D loss: 0.554102, acc.: 73.44%] [G loss: 0.993506]\n",
      "epoch:18 step:17228 [D loss: 0.775052, acc.: 46.88%] [G loss: 0.900498]\n",
      "epoch:18 step:17229 [D loss: 0.780171, acc.: 49.22%] [G loss: 0.768349]\n",
      "epoch:18 step:17230 [D loss: 0.618831, acc.: 67.19%] [G loss: 0.868348]\n",
      "epoch:18 step:17231 [D loss: 0.765472, acc.: 45.31%] [G loss: 0.833919]\n",
      "epoch:18 step:17232 [D loss: 0.629373, acc.: 61.72%] [G loss: 1.054825]\n",
      "epoch:18 step:17233 [D loss: 0.609752, acc.: 61.72%] [G loss: 0.948418]\n",
      "epoch:18 step:17234 [D loss: 0.740941, acc.: 47.66%] [G loss: 0.959506]\n",
      "epoch:18 step:17235 [D loss: 0.607473, acc.: 67.97%] [G loss: 1.164770]\n",
      "epoch:18 step:17236 [D loss: 0.559522, acc.: 66.41%] [G loss: 0.974419]\n",
      "epoch:18 step:17237 [D loss: 0.544412, acc.: 67.19%] [G loss: 0.872911]\n",
      "epoch:18 step:17238 [D loss: 0.653469, acc.: 65.62%] [G loss: 0.966288]\n",
      "epoch:18 step:17239 [D loss: 0.698032, acc.: 60.94%] [G loss: 1.018854]\n",
      "epoch:18 step:17240 [D loss: 0.707442, acc.: 55.47%] [G loss: 0.834991]\n",
      "epoch:18 step:17241 [D loss: 0.645007, acc.: 67.97%] [G loss: 0.894159]\n",
      "epoch:18 step:17242 [D loss: 0.708071, acc.: 53.91%] [G loss: 0.896480]\n",
      "epoch:18 step:17243 [D loss: 0.563010, acc.: 71.88%] [G loss: 0.893358]\n",
      "epoch:18 step:17244 [D loss: 0.585815, acc.: 71.88%] [G loss: 0.826674]\n",
      "epoch:18 step:17245 [D loss: 0.678625, acc.: 60.16%] [G loss: 0.853664]\n",
      "epoch:18 step:17246 [D loss: 0.590781, acc.: 71.88%] [G loss: 0.888270]\n",
      "epoch:18 step:17247 [D loss: 0.638903, acc.: 64.06%] [G loss: 0.894941]\n",
      "epoch:18 step:17248 [D loss: 0.738400, acc.: 53.91%] [G loss: 0.776072]\n",
      "epoch:18 step:17249 [D loss: 0.701448, acc.: 58.59%] [G loss: 0.914423]\n",
      "epoch:18 step:17250 [D loss: 0.664452, acc.: 59.38%] [G loss: 0.827128]\n",
      "epoch:18 step:17251 [D loss: 0.670409, acc.: 54.69%] [G loss: 0.891140]\n",
      "epoch:18 step:17252 [D loss: 0.647328, acc.: 57.81%] [G loss: 0.837132]\n",
      "epoch:18 step:17253 [D loss: 0.693139, acc.: 53.12%] [G loss: 0.920253]\n",
      "epoch:18 step:17254 [D loss: 0.613762, acc.: 68.75%] [G loss: 0.908892]\n",
      "epoch:18 step:17255 [D loss: 0.658428, acc.: 64.06%] [G loss: 0.887412]\n",
      "epoch:18 step:17256 [D loss: 0.666986, acc.: 57.03%] [G loss: 0.879729]\n",
      "epoch:18 step:17257 [D loss: 0.654335, acc.: 62.50%] [G loss: 0.832634]\n",
      "epoch:18 step:17258 [D loss: 0.673658, acc.: 58.59%] [G loss: 0.859065]\n",
      "epoch:18 step:17259 [D loss: 0.579830, acc.: 67.97%] [G loss: 0.837339]\n",
      "epoch:18 step:17260 [D loss: 0.614007, acc.: 71.09%] [G loss: 0.867516]\n",
      "epoch:18 step:17261 [D loss: 0.732909, acc.: 50.78%] [G loss: 0.990331]\n",
      "epoch:18 step:17262 [D loss: 0.450422, acc.: 78.91%] [G loss: 0.962687]\n",
      "epoch:18 step:17263 [D loss: 0.362510, acc.: 85.16%] [G loss: 0.979589]\n",
      "epoch:18 step:17264 [D loss: 0.300704, acc.: 96.09%] [G loss: 1.044073]\n",
      "epoch:18 step:17265 [D loss: 0.317611, acc.: 91.41%] [G loss: 1.152357]\n",
      "epoch:18 step:17266 [D loss: 0.445251, acc.: 78.12%] [G loss: 1.141317]\n",
      "epoch:18 step:17267 [D loss: 0.435085, acc.: 89.06%] [G loss: 1.243026]\n",
      "epoch:18 step:17268 [D loss: 0.428896, acc.: 86.72%] [G loss: 0.683370]\n",
      "epoch:18 step:17269 [D loss: 0.451952, acc.: 71.09%] [G loss: 1.234060]\n",
      "epoch:18 step:17270 [D loss: 0.360243, acc.: 86.72%] [G loss: 1.281397]\n",
      "epoch:18 step:17271 [D loss: 0.306468, acc.: 90.62%] [G loss: 1.478886]\n",
      "epoch:18 step:17272 [D loss: 0.490508, acc.: 78.12%] [G loss: 1.292021]\n",
      "epoch:18 step:17273 [D loss: 0.456470, acc.: 81.25%] [G loss: 1.055197]\n",
      "epoch:18 step:17274 [D loss: 0.917928, acc.: 42.97%] [G loss: 1.444315]\n",
      "epoch:18 step:17275 [D loss: 0.522637, acc.: 75.00%] [G loss: 1.040428]\n",
      "epoch:18 step:17276 [D loss: 0.884745, acc.: 46.88%] [G loss: 0.912754]\n",
      "epoch:18 step:17277 [D loss: 1.158860, acc.: 23.44%] [G loss: 1.244467]\n",
      "epoch:18 step:17278 [D loss: 0.759926, acc.: 47.66%] [G loss: 0.917015]\n",
      "epoch:18 step:17279 [D loss: 0.812105, acc.: 49.22%] [G loss: 1.054430]\n",
      "epoch:18 step:17280 [D loss: 0.693591, acc.: 57.81%] [G loss: 0.942791]\n",
      "epoch:18 step:17281 [D loss: 0.638705, acc.: 64.84%] [G loss: 0.996486]\n",
      "epoch:18 step:17282 [D loss: 0.696333, acc.: 55.47%] [G loss: 0.942969]\n",
      "epoch:18 step:17283 [D loss: 0.833044, acc.: 42.97%] [G loss: 1.050541]\n",
      "epoch:18 step:17284 [D loss: 0.773605, acc.: 50.78%] [G loss: 0.874655]\n",
      "epoch:18 step:17285 [D loss: 0.708325, acc.: 53.12%] [G loss: 0.984391]\n",
      "epoch:18 step:17286 [D loss: 0.757489, acc.: 46.09%] [G loss: 0.874094]\n",
      "epoch:18 step:17287 [D loss: 0.761021, acc.: 44.53%] [G loss: 0.942704]\n",
      "epoch:18 step:17288 [D loss: 0.767447, acc.: 42.97%] [G loss: 1.079833]\n",
      "epoch:18 step:17289 [D loss: 0.726875, acc.: 50.00%] [G loss: 1.093367]\n",
      "epoch:18 step:17290 [D loss: 0.653957, acc.: 64.84%] [G loss: 1.002594]\n",
      "epoch:18 step:17291 [D loss: 0.690746, acc.: 59.38%] [G loss: 0.914235]\n",
      "epoch:18 step:17292 [D loss: 0.710582, acc.: 50.00%] [G loss: 1.006141]\n",
      "epoch:18 step:17293 [D loss: 0.716171, acc.: 53.91%] [G loss: 1.050840]\n",
      "epoch:18 step:17294 [D loss: 0.637980, acc.: 64.84%] [G loss: 1.072781]\n",
      "epoch:18 step:17295 [D loss: 0.700501, acc.: 51.56%] [G loss: 0.849571]\n",
      "epoch:18 step:17296 [D loss: 0.760343, acc.: 52.34%] [G loss: 0.932737]\n",
      "epoch:18 step:17297 [D loss: 0.724426, acc.: 50.78%] [G loss: 0.955157]\n",
      "epoch:18 step:17298 [D loss: 0.671984, acc.: 55.47%] [G loss: 1.014813]\n",
      "epoch:18 step:17299 [D loss: 0.674166, acc.: 59.38%] [G loss: 0.968255]\n",
      "epoch:18 step:17300 [D loss: 0.658321, acc.: 60.94%] [G loss: 0.924727]\n",
      "epoch:18 step:17301 [D loss: 0.683948, acc.: 57.81%] [G loss: 1.008368]\n",
      "epoch:18 step:17302 [D loss: 0.585888, acc.: 74.22%] [G loss: 1.019226]\n",
      "epoch:18 step:17303 [D loss: 0.656920, acc.: 56.25%] [G loss: 0.990770]\n",
      "epoch:18 step:17304 [D loss: 0.744408, acc.: 50.00%] [G loss: 0.940781]\n",
      "epoch:18 step:17305 [D loss: 0.679022, acc.: 53.12%] [G loss: 1.032763]\n",
      "epoch:18 step:17306 [D loss: 0.684838, acc.: 56.25%] [G loss: 0.880886]\n",
      "epoch:18 step:17307 [D loss: 0.710959, acc.: 57.81%] [G loss: 0.830921]\n",
      "epoch:18 step:17308 [D loss: 0.681239, acc.: 53.12%] [G loss: 0.835302]\n",
      "epoch:18 step:17309 [D loss: 0.609125, acc.: 68.75%] [G loss: 0.900599]\n",
      "epoch:18 step:17310 [D loss: 0.644287, acc.: 59.38%] [G loss: 0.940544]\n",
      "epoch:18 step:17311 [D loss: 0.652642, acc.: 60.16%] [G loss: 0.862149]\n",
      "epoch:18 step:17312 [D loss: 0.622375, acc.: 66.41%] [G loss: 0.955480]\n",
      "epoch:18 step:17313 [D loss: 0.616877, acc.: 70.31%] [G loss: 0.931585]\n",
      "epoch:18 step:17314 [D loss: 0.564970, acc.: 77.34%] [G loss: 0.942199]\n",
      "epoch:18 step:17315 [D loss: 0.572905, acc.: 75.78%] [G loss: 1.025104]\n",
      "epoch:18 step:17316 [D loss: 0.568405, acc.: 75.00%] [G loss: 0.973749]\n",
      "epoch:18 step:17317 [D loss: 0.494488, acc.: 87.50%] [G loss: 1.130944]\n",
      "epoch:18 step:17318 [D loss: 0.507626, acc.: 84.38%] [G loss: 1.007532]\n",
      "epoch:18 step:17319 [D loss: 0.482208, acc.: 84.38%] [G loss: 1.215958]\n",
      "epoch:18 step:17320 [D loss: 0.592175, acc.: 67.19%] [G loss: 1.443562]\n",
      "epoch:18 step:17321 [D loss: 0.503490, acc.: 80.47%] [G loss: 1.225712]\n",
      "epoch:18 step:17322 [D loss: 0.480445, acc.: 78.91%] [G loss: 1.109051]\n",
      "epoch:18 step:17323 [D loss: 0.594387, acc.: 68.75%] [G loss: 1.154173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17324 [D loss: 0.700557, acc.: 59.38%] [G loss: 1.105650]\n",
      "epoch:18 step:17325 [D loss: 0.615919, acc.: 66.41%] [G loss: 1.050051]\n",
      "epoch:18 step:17326 [D loss: 0.692009, acc.: 57.81%] [G loss: 0.854135]\n",
      "epoch:18 step:17327 [D loss: 1.038903, acc.: 28.12%] [G loss: 0.885480]\n",
      "epoch:18 step:17328 [D loss: 0.982746, acc.: 25.78%] [G loss: 0.862148]\n",
      "epoch:18 step:17329 [D loss: 0.720606, acc.: 49.22%] [G loss: 0.774295]\n",
      "epoch:18 step:17330 [D loss: 0.726636, acc.: 52.34%] [G loss: 0.937745]\n",
      "epoch:18 step:17331 [D loss: 0.671152, acc.: 60.94%] [G loss: 0.932817]\n",
      "epoch:18 step:17332 [D loss: 0.667194, acc.: 57.03%] [G loss: 0.873575]\n",
      "epoch:18 step:17333 [D loss: 0.608265, acc.: 68.75%] [G loss: 0.861822]\n",
      "epoch:18 step:17334 [D loss: 0.577852, acc.: 71.09%] [G loss: 0.916379]\n",
      "epoch:18 step:17335 [D loss: 0.588501, acc.: 78.91%] [G loss: 0.894279]\n",
      "epoch:18 step:17336 [D loss: 0.588944, acc.: 70.31%] [G loss: 0.907808]\n",
      "epoch:18 step:17337 [D loss: 0.580303, acc.: 76.56%] [G loss: 0.975935]\n",
      "epoch:18 step:17338 [D loss: 0.605929, acc.: 75.00%] [G loss: 0.897356]\n",
      "epoch:18 step:17339 [D loss: 0.747342, acc.: 44.53%] [G loss: 0.826988]\n",
      "epoch:18 step:17340 [D loss: 0.750923, acc.: 46.09%] [G loss: 0.977214]\n",
      "epoch:18 step:17341 [D loss: 0.667233, acc.: 61.72%] [G loss: 0.962481]\n",
      "epoch:18 step:17342 [D loss: 0.680127, acc.: 60.16%] [G loss: 0.832343]\n",
      "epoch:18 step:17343 [D loss: 0.728822, acc.: 50.78%] [G loss: 0.946321]\n",
      "epoch:18 step:17344 [D loss: 0.656419, acc.: 57.03%] [G loss: 0.987316]\n",
      "epoch:18 step:17345 [D loss: 0.628158, acc.: 66.41%] [G loss: 0.846332]\n",
      "epoch:18 step:17346 [D loss: 0.629003, acc.: 65.62%] [G loss: 0.894692]\n",
      "epoch:18 step:17347 [D loss: 0.565988, acc.: 72.66%] [G loss: 0.934760]\n",
      "epoch:18 step:17348 [D loss: 0.687716, acc.: 53.12%] [G loss: 0.869032]\n",
      "epoch:18 step:17349 [D loss: 0.648175, acc.: 62.50%] [G loss: 0.963002]\n",
      "epoch:18 step:17350 [D loss: 0.625261, acc.: 67.97%] [G loss: 0.994007]\n",
      "epoch:18 step:17351 [D loss: 0.637278, acc.: 64.84%] [G loss: 0.954759]\n",
      "epoch:18 step:17352 [D loss: 0.602570, acc.: 64.06%] [G loss: 0.979552]\n",
      "epoch:18 step:17353 [D loss: 0.642535, acc.: 64.06%] [G loss: 0.878033]\n",
      "epoch:18 step:17354 [D loss: 0.557048, acc.: 73.44%] [G loss: 0.973000]\n",
      "epoch:18 step:17355 [D loss: 0.743539, acc.: 43.75%] [G loss: 0.852921]\n",
      "epoch:18 step:17356 [D loss: 0.700593, acc.: 51.56%] [G loss: 0.892219]\n",
      "epoch:18 step:17357 [D loss: 0.701013, acc.: 51.56%] [G loss: 0.830842]\n",
      "epoch:18 step:17358 [D loss: 0.729993, acc.: 49.22%] [G loss: 0.611071]\n",
      "epoch:18 step:17359 [D loss: 0.683704, acc.: 60.16%] [G loss: 0.798316]\n",
      "epoch:18 step:17360 [D loss: 0.702901, acc.: 50.78%] [G loss: 0.717030]\n",
      "epoch:18 step:17361 [D loss: 0.725921, acc.: 47.66%] [G loss: 0.771635]\n",
      "epoch:18 step:17362 [D loss: 0.693040, acc.: 58.59%] [G loss: 0.848673]\n",
      "epoch:18 step:17363 [D loss: 0.569399, acc.: 71.09%] [G loss: 0.890984]\n",
      "epoch:18 step:17364 [D loss: 0.615027, acc.: 63.28%] [G loss: 0.861461]\n",
      "epoch:18 step:17365 [D loss: 0.532724, acc.: 78.12%] [G loss: 0.950442]\n",
      "epoch:18 step:17366 [D loss: 0.660950, acc.: 64.06%] [G loss: 0.864185]\n",
      "epoch:18 step:17367 [D loss: 0.776363, acc.: 46.09%] [G loss: 0.890467]\n",
      "epoch:18 step:17368 [D loss: 0.676381, acc.: 58.59%] [G loss: 0.943600]\n",
      "epoch:18 step:17369 [D loss: 0.668636, acc.: 59.38%] [G loss: 0.758528]\n",
      "epoch:18 step:17370 [D loss: 0.625070, acc.: 60.16%] [G loss: 0.857122]\n",
      "epoch:18 step:17371 [D loss: 0.606929, acc.: 71.88%] [G loss: 0.919442]\n",
      "epoch:18 step:17372 [D loss: 0.681694, acc.: 57.03%] [G loss: 0.868177]\n",
      "epoch:18 step:17373 [D loss: 0.604085, acc.: 71.88%] [G loss: 0.928613]\n",
      "epoch:18 step:17374 [D loss: 0.562650, acc.: 79.69%] [G loss: 1.019419]\n",
      "epoch:18 step:17375 [D loss: 0.646627, acc.: 53.91%] [G loss: 1.055576]\n",
      "epoch:18 step:17376 [D loss: 0.674079, acc.: 58.59%] [G loss: 0.909578]\n",
      "epoch:18 step:17377 [D loss: 0.678767, acc.: 57.81%] [G loss: 0.978679]\n",
      "epoch:18 step:17378 [D loss: 0.619880, acc.: 68.75%] [G loss: 0.892345]\n",
      "epoch:18 step:17379 [D loss: 0.602072, acc.: 74.22%] [G loss: 0.944864]\n",
      "epoch:18 step:17380 [D loss: 0.544831, acc.: 75.00%] [G loss: 0.944858]\n",
      "epoch:18 step:17381 [D loss: 0.589107, acc.: 71.88%] [G loss: 1.009607]\n",
      "epoch:18 step:17382 [D loss: 0.640143, acc.: 59.38%] [G loss: 0.979858]\n",
      "epoch:18 step:17383 [D loss: 0.576958, acc.: 67.97%] [G loss: 0.973328]\n",
      "epoch:18 step:17384 [D loss: 0.549461, acc.: 73.44%] [G loss: 1.008101]\n",
      "epoch:18 step:17385 [D loss: 0.594462, acc.: 64.06%] [G loss: 0.987273]\n",
      "epoch:18 step:17386 [D loss: 0.518192, acc.: 70.31%] [G loss: 1.181897]\n",
      "epoch:18 step:17387 [D loss: 0.623354, acc.: 65.62%] [G loss: 1.130842]\n",
      "epoch:18 step:17388 [D loss: 0.637165, acc.: 59.38%] [G loss: 1.004669]\n",
      "epoch:18 step:17389 [D loss: 0.643290, acc.: 62.50%] [G loss: 1.130539]\n",
      "epoch:18 step:17390 [D loss: 0.651945, acc.: 61.72%] [G loss: 0.879735]\n",
      "epoch:18 step:17391 [D loss: 0.655343, acc.: 55.47%] [G loss: 0.981586]\n",
      "epoch:18 step:17392 [D loss: 0.643523, acc.: 66.41%] [G loss: 0.884812]\n",
      "epoch:18 step:17393 [D loss: 0.711725, acc.: 58.59%] [G loss: 0.934222]\n",
      "epoch:18 step:17394 [D loss: 0.762904, acc.: 50.78%] [G loss: 0.929861]\n",
      "epoch:18 step:17395 [D loss: 0.698680, acc.: 53.12%] [G loss: 0.926981]\n",
      "epoch:18 step:17396 [D loss: 0.586913, acc.: 72.66%] [G loss: 0.871164]\n",
      "epoch:18 step:17397 [D loss: 0.733589, acc.: 51.56%] [G loss: 0.895870]\n",
      "epoch:18 step:17398 [D loss: 0.635241, acc.: 60.94%] [G loss: 0.906400]\n",
      "epoch:18 step:17399 [D loss: 0.607387, acc.: 65.62%] [G loss: 0.984208]\n",
      "epoch:18 step:17400 [D loss: 0.590590, acc.: 65.62%] [G loss: 0.972408]\n",
      "epoch:18 step:17401 [D loss: 0.601055, acc.: 71.09%] [G loss: 0.903257]\n",
      "epoch:18 step:17402 [D loss: 0.562928, acc.: 73.44%] [G loss: 0.935485]\n",
      "epoch:18 step:17403 [D loss: 0.662155, acc.: 64.84%] [G loss: 0.900930]\n",
      "epoch:18 step:17404 [D loss: 0.582541, acc.: 71.88%] [G loss: 0.962984]\n",
      "epoch:18 step:17405 [D loss: 0.627053, acc.: 70.31%] [G loss: 0.915799]\n",
      "epoch:18 step:17406 [D loss: 0.576524, acc.: 72.66%] [G loss: 0.908308]\n",
      "epoch:18 step:17407 [D loss: 0.595174, acc.: 71.09%] [G loss: 0.916529]\n",
      "epoch:18 step:17408 [D loss: 0.685473, acc.: 58.59%] [G loss: 0.858549]\n",
      "epoch:18 step:17409 [D loss: 0.410107, acc.: 82.81%] [G loss: 0.927324]\n",
      "epoch:18 step:17410 [D loss: 0.647481, acc.: 57.03%] [G loss: 0.960153]\n",
      "epoch:18 step:17411 [D loss: 0.590252, acc.: 72.66%] [G loss: 1.017926]\n",
      "epoch:18 step:17412 [D loss: 0.770638, acc.: 45.31%] [G loss: 0.956622]\n",
      "epoch:18 step:17413 [D loss: 0.689492, acc.: 56.25%] [G loss: 0.910543]\n",
      "epoch:18 step:17414 [D loss: 0.530731, acc.: 75.00%] [G loss: 0.903158]\n",
      "epoch:18 step:17415 [D loss: 0.565168, acc.: 75.78%] [G loss: 0.844998]\n",
      "epoch:18 step:17416 [D loss: 0.397037, acc.: 83.59%] [G loss: 1.026965]\n",
      "epoch:18 step:17417 [D loss: 0.531213, acc.: 84.38%] [G loss: 1.016637]\n",
      "epoch:18 step:17418 [D loss: 0.551757, acc.: 71.88%] [G loss: 0.861549]\n",
      "epoch:18 step:17419 [D loss: 0.631154, acc.: 65.62%] [G loss: 0.869029]\n",
      "epoch:18 step:17420 [D loss: 0.351986, acc.: 95.31%] [G loss: 0.953660]\n",
      "epoch:18 step:17421 [D loss: 0.489037, acc.: 83.59%] [G loss: 0.983716]\n",
      "epoch:18 step:17422 [D loss: 0.445087, acc.: 86.72%] [G loss: 0.800250]\n",
      "epoch:18 step:17423 [D loss: 0.693819, acc.: 54.69%] [G loss: 0.894070]\n",
      "epoch:18 step:17424 [D loss: 0.571092, acc.: 67.97%] [G loss: 1.045356]\n",
      "epoch:18 step:17425 [D loss: 0.826405, acc.: 36.72%] [G loss: 1.256149]\n",
      "epoch:18 step:17426 [D loss: 0.750397, acc.: 52.34%] [G loss: 1.121182]\n",
      "epoch:18 step:17427 [D loss: 0.640080, acc.: 57.81%] [G loss: 1.194308]\n",
      "epoch:18 step:17428 [D loss: 0.780530, acc.: 46.09%] [G loss: 1.147555]\n",
      "epoch:18 step:17429 [D loss: 0.670416, acc.: 59.38%] [G loss: 1.158207]\n",
      "epoch:18 step:17430 [D loss: 0.590450, acc.: 63.28%] [G loss: 1.030502]\n",
      "epoch:18 step:17431 [D loss: 0.586306, acc.: 70.31%] [G loss: 0.960681]\n",
      "epoch:18 step:17432 [D loss: 0.442524, acc.: 81.25%] [G loss: 0.981554]\n",
      "epoch:18 step:17433 [D loss: 0.431333, acc.: 84.38%] [G loss: 1.096621]\n",
      "epoch:18 step:17434 [D loss: 0.597862, acc.: 66.41%] [G loss: 0.977584]\n",
      "epoch:18 step:17435 [D loss: 0.699006, acc.: 52.34%] [G loss: 1.063280]\n",
      "epoch:18 step:17436 [D loss: 0.570458, acc.: 75.00%] [G loss: 1.035630]\n",
      "epoch:18 step:17437 [D loss: 0.620840, acc.: 64.84%] [G loss: 0.983095]\n",
      "epoch:18 step:17438 [D loss: 0.628245, acc.: 64.84%] [G loss: 0.910029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17439 [D loss: 0.544198, acc.: 72.66%] [G loss: 0.873858]\n",
      "epoch:18 step:17440 [D loss: 0.574451, acc.: 69.53%] [G loss: 0.969279]\n",
      "epoch:18 step:17441 [D loss: 0.558148, acc.: 72.66%] [G loss: 0.916343]\n",
      "epoch:18 step:17442 [D loss: 0.607912, acc.: 62.50%] [G loss: 0.734575]\n",
      "epoch:18 step:17443 [D loss: 0.523356, acc.: 69.53%] [G loss: 1.187790]\n",
      "epoch:18 step:17444 [D loss: 0.638416, acc.: 62.50%] [G loss: 1.164572]\n",
      "epoch:18 step:17445 [D loss: 0.509845, acc.: 75.78%] [G loss: 1.315248]\n",
      "epoch:18 step:17446 [D loss: 0.710213, acc.: 57.03%] [G loss: 0.822962]\n",
      "epoch:18 step:17447 [D loss: 0.712963, acc.: 54.69%] [G loss: 0.772751]\n",
      "epoch:18 step:17448 [D loss: 0.689006, acc.: 60.94%] [G loss: 1.075864]\n",
      "epoch:18 step:17449 [D loss: 0.816062, acc.: 40.62%] [G loss: 1.130735]\n",
      "epoch:18 step:17450 [D loss: 0.767022, acc.: 53.91%] [G loss: 1.198584]\n",
      "epoch:18 step:17451 [D loss: 0.589845, acc.: 66.41%] [G loss: 1.217447]\n",
      "epoch:18 step:17452 [D loss: 0.649424, acc.: 57.03%] [G loss: 1.078443]\n",
      "epoch:18 step:17453 [D loss: 0.689747, acc.: 54.69%] [G loss: 1.079800]\n",
      "epoch:18 step:17454 [D loss: 0.537351, acc.: 73.44%] [G loss: 1.040747]\n",
      "epoch:18 step:17455 [D loss: 0.501982, acc.: 80.47%] [G loss: 1.075411]\n",
      "epoch:18 step:17456 [D loss: 0.809017, acc.: 42.97%] [G loss: 1.049826]\n",
      "epoch:18 step:17457 [D loss: 0.611633, acc.: 67.19%] [G loss: 1.035394]\n",
      "epoch:18 step:17458 [D loss: 0.655923, acc.: 58.59%] [G loss: 1.100216]\n",
      "epoch:18 step:17459 [D loss: 0.653375, acc.: 54.69%] [G loss: 1.231898]\n",
      "epoch:18 step:17460 [D loss: 0.688931, acc.: 50.00%] [G loss: 1.174717]\n",
      "epoch:18 step:17461 [D loss: 0.618045, acc.: 64.84%] [G loss: 1.021031]\n",
      "epoch:18 step:17462 [D loss: 0.604447, acc.: 71.09%] [G loss: 0.961628]\n",
      "epoch:18 step:17463 [D loss: 0.732911, acc.: 47.66%] [G loss: 0.958800]\n",
      "epoch:18 step:17464 [D loss: 0.634685, acc.: 59.38%] [G loss: 1.067811]\n",
      "epoch:18 step:17465 [D loss: 0.675487, acc.: 57.03%] [G loss: 1.070047]\n",
      "epoch:18 step:17466 [D loss: 0.716109, acc.: 55.47%] [G loss: 0.965898]\n",
      "epoch:18 step:17467 [D loss: 0.679003, acc.: 58.59%] [G loss: 0.860234]\n",
      "epoch:18 step:17468 [D loss: 0.727585, acc.: 49.22%] [G loss: 0.698479]\n",
      "epoch:18 step:17469 [D loss: 0.627848, acc.: 64.06%] [G loss: 0.886438]\n",
      "epoch:18 step:17470 [D loss: 0.425412, acc.: 74.22%] [G loss: 0.924759]\n",
      "epoch:18 step:17471 [D loss: 0.647490, acc.: 58.59%] [G loss: 0.910385]\n",
      "epoch:18 step:17472 [D loss: 0.704738, acc.: 53.12%] [G loss: 1.024812]\n",
      "epoch:18 step:17473 [D loss: 0.697897, acc.: 59.38%] [G loss: 0.968694]\n",
      "epoch:18 step:17474 [D loss: 0.738703, acc.: 46.09%] [G loss: 0.962500]\n",
      "epoch:18 step:17475 [D loss: 0.533246, acc.: 82.03%] [G loss: 0.979573]\n",
      "epoch:18 step:17476 [D loss: 0.643961, acc.: 54.69%] [G loss: 0.942242]\n",
      "epoch:18 step:17477 [D loss: 0.559208, acc.: 76.56%] [G loss: 1.073018]\n",
      "epoch:18 step:17478 [D loss: 0.699583, acc.: 56.25%] [G loss: 1.005326]\n",
      "epoch:18 step:17479 [D loss: 0.593529, acc.: 74.22%] [G loss: 0.914246]\n",
      "epoch:18 step:17480 [D loss: 0.718379, acc.: 45.31%] [G loss: 0.943830]\n",
      "epoch:18 step:17481 [D loss: 0.611942, acc.: 62.50%] [G loss: 1.070795]\n",
      "epoch:18 step:17482 [D loss: 0.589667, acc.: 69.53%] [G loss: 0.898574]\n",
      "epoch:18 step:17483 [D loss: 0.580248, acc.: 68.75%] [G loss: 0.834551]\n",
      "epoch:18 step:17484 [D loss: 0.633759, acc.: 67.19%] [G loss: 0.999045]\n",
      "epoch:18 step:17485 [D loss: 0.623635, acc.: 64.06%] [G loss: 0.924297]\n",
      "epoch:18 step:17486 [D loss: 0.625922, acc.: 60.94%] [G loss: 0.947903]\n",
      "epoch:18 step:17487 [D loss: 0.653448, acc.: 57.03%] [G loss: 0.863041]\n",
      "epoch:18 step:17488 [D loss: 0.614770, acc.: 70.31%] [G loss: 0.843668]\n",
      "epoch:18 step:17489 [D loss: 0.570984, acc.: 65.62%] [G loss: 0.830628]\n",
      "epoch:18 step:17490 [D loss: 0.541092, acc.: 78.12%] [G loss: 0.808300]\n",
      "epoch:18 step:17491 [D loss: 0.692365, acc.: 57.81%] [G loss: 0.878253]\n",
      "epoch:18 step:17492 [D loss: 0.665629, acc.: 60.94%] [G loss: 0.869911]\n",
      "epoch:18 step:17493 [D loss: 0.673029, acc.: 58.59%] [G loss: 0.865508]\n",
      "epoch:18 step:17494 [D loss: 0.665693, acc.: 60.16%] [G loss: 0.899567]\n",
      "epoch:18 step:17495 [D loss: 0.521288, acc.: 79.69%] [G loss: 0.937386]\n",
      "epoch:18 step:17496 [D loss: 0.672575, acc.: 59.38%] [G loss: 0.953331]\n",
      "epoch:18 step:17497 [D loss: 0.743718, acc.: 45.31%] [G loss: 0.872072]\n",
      "epoch:18 step:17498 [D loss: 0.538727, acc.: 75.00%] [G loss: 0.818215]\n",
      "epoch:18 step:17499 [D loss: 0.559303, acc.: 64.06%] [G loss: 0.846793]\n",
      "epoch:18 step:17500 [D loss: 0.456797, acc.: 82.81%] [G loss: 0.755984]\n",
      "epoch:18 step:17501 [D loss: 0.559850, acc.: 73.44%] [G loss: 1.194665]\n",
      "epoch:18 step:17502 [D loss: 0.782446, acc.: 49.22%] [G loss: 1.055620]\n",
      "epoch:18 step:17503 [D loss: 0.633714, acc.: 59.38%] [G loss: 1.006834]\n",
      "epoch:18 step:17504 [D loss: 0.831758, acc.: 34.38%] [G loss: 0.436963]\n",
      "epoch:18 step:17505 [D loss: 0.828137, acc.: 32.03%] [G loss: 0.975529]\n",
      "epoch:18 step:17506 [D loss: 0.763339, acc.: 44.53%] [G loss: 0.996710]\n",
      "epoch:18 step:17507 [D loss: 0.567391, acc.: 68.75%] [G loss: 1.039355]\n",
      "epoch:18 step:17508 [D loss: 0.690141, acc.: 52.34%] [G loss: 1.034643]\n",
      "epoch:18 step:17509 [D loss: 0.698212, acc.: 59.38%] [G loss: 0.967710]\n",
      "epoch:18 step:17510 [D loss: 0.589033, acc.: 73.44%] [G loss: 0.795634]\n",
      "epoch:18 step:17511 [D loss: 0.648059, acc.: 57.03%] [G loss: 0.810287]\n",
      "epoch:18 step:17512 [D loss: 0.693483, acc.: 59.38%] [G loss: 0.869120]\n",
      "epoch:18 step:17513 [D loss: 0.714266, acc.: 57.03%] [G loss: 0.847733]\n",
      "epoch:18 step:17514 [D loss: 0.632523, acc.: 63.28%] [G loss: 1.069871]\n",
      "epoch:18 step:17515 [D loss: 0.701327, acc.: 51.56%] [G loss: 0.936184]\n",
      "epoch:18 step:17516 [D loss: 0.660443, acc.: 60.94%] [G loss: 0.939699]\n",
      "epoch:18 step:17517 [D loss: 0.677168, acc.: 53.12%] [G loss: 0.930891]\n",
      "epoch:18 step:17518 [D loss: 0.739037, acc.: 44.53%] [G loss: 0.897420]\n",
      "epoch:18 step:17519 [D loss: 0.695811, acc.: 57.03%] [G loss: 1.020742]\n",
      "epoch:18 step:17520 [D loss: 0.677327, acc.: 59.38%] [G loss: 0.966166]\n",
      "epoch:18 step:17521 [D loss: 0.725563, acc.: 54.69%] [G loss: 0.976240]\n",
      "epoch:18 step:17522 [D loss: 0.711403, acc.: 49.22%] [G loss: 0.913455]\n",
      "epoch:18 step:17523 [D loss: 0.701448, acc.: 52.34%] [G loss: 0.977018]\n",
      "epoch:18 step:17524 [D loss: 0.662401, acc.: 60.16%] [G loss: 0.847954]\n",
      "epoch:18 step:17525 [D loss: 0.644124, acc.: 63.28%] [G loss: 0.871134]\n",
      "epoch:18 step:17526 [D loss: 0.658037, acc.: 57.81%] [G loss: 0.903692]\n",
      "epoch:18 step:17527 [D loss: 0.624675, acc.: 63.28%] [G loss: 0.883737]\n",
      "epoch:18 step:17528 [D loss: 0.645116, acc.: 61.72%] [G loss: 0.865097]\n",
      "epoch:18 step:17529 [D loss: 0.425714, acc.: 78.91%] [G loss: 1.007994]\n",
      "epoch:18 step:17530 [D loss: 0.428988, acc.: 85.94%] [G loss: 1.060246]\n",
      "epoch:18 step:17531 [D loss: 0.383388, acc.: 87.50%] [G loss: 1.149829]\n",
      "epoch:18 step:17532 [D loss: 0.540018, acc.: 77.34%] [G loss: 1.215546]\n",
      "epoch:18 step:17533 [D loss: 0.562337, acc.: 68.75%] [G loss: 1.375739]\n",
      "epoch:18 step:17534 [D loss: 0.697992, acc.: 62.50%] [G loss: 1.071326]\n",
      "epoch:18 step:17535 [D loss: 0.641374, acc.: 61.72%] [G loss: 1.013765]\n",
      "epoch:18 step:17536 [D loss: 0.648016, acc.: 57.03%] [G loss: 0.936435]\n",
      "epoch:18 step:17537 [D loss: 0.535905, acc.: 71.88%] [G loss: 1.005894]\n",
      "epoch:18 step:17538 [D loss: 0.591159, acc.: 67.19%] [G loss: 0.896645]\n",
      "epoch:18 step:17539 [D loss: 0.605761, acc.: 65.62%] [G loss: 0.969042]\n",
      "epoch:18 step:17540 [D loss: 0.585724, acc.: 66.41%] [G loss: 0.539457]\n",
      "epoch:18 step:17541 [D loss: 0.790104, acc.: 45.31%] [G loss: 0.917367]\n",
      "epoch:18 step:17542 [D loss: 0.680234, acc.: 60.94%] [G loss: 0.864915]\n",
      "epoch:18 step:17543 [D loss: 0.733256, acc.: 46.88%] [G loss: 0.759591]\n",
      "epoch:18 step:17544 [D loss: 0.851770, acc.: 39.06%] [G loss: 0.668354]\n",
      "epoch:18 step:17545 [D loss: 0.664166, acc.: 57.81%] [G loss: 0.967592]\n",
      "epoch:18 step:17546 [D loss: 0.669304, acc.: 53.91%] [G loss: 0.846446]\n",
      "epoch:18 step:17547 [D loss: 0.783259, acc.: 45.31%] [G loss: 0.921720]\n",
      "epoch:18 step:17548 [D loss: 0.642235, acc.: 61.72%] [G loss: 0.793741]\n",
      "epoch:18 step:17549 [D loss: 0.649920, acc.: 60.94%] [G loss: 0.953630]\n",
      "epoch:18 step:17550 [D loss: 0.631449, acc.: 62.50%] [G loss: 0.845408]\n",
      "epoch:18 step:17551 [D loss: 0.593159, acc.: 68.75%] [G loss: 0.984215]\n",
      "epoch:18 step:17552 [D loss: 0.586715, acc.: 70.31%] [G loss: 0.946363]\n",
      "epoch:18 step:17553 [D loss: 0.645831, acc.: 65.62%] [G loss: 0.906021]\n",
      "epoch:18 step:17554 [D loss: 0.668786, acc.: 60.94%] [G loss: 0.890091]\n",
      "epoch:18 step:17555 [D loss: 0.715515, acc.: 55.47%] [G loss: 0.891301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17556 [D loss: 0.666640, acc.: 60.94%] [G loss: 0.804050]\n",
      "epoch:18 step:17557 [D loss: 0.673542, acc.: 54.69%] [G loss: 0.901007]\n",
      "epoch:18 step:17558 [D loss: 0.758712, acc.: 42.19%] [G loss: 0.857414]\n",
      "epoch:18 step:17559 [D loss: 0.715917, acc.: 52.34%] [G loss: 1.014672]\n",
      "epoch:18 step:17560 [D loss: 0.624262, acc.: 64.06%] [G loss: 0.967104]\n",
      "epoch:18 step:17561 [D loss: 0.734164, acc.: 46.09%] [G loss: 1.074246]\n",
      "epoch:18 step:17562 [D loss: 0.497901, acc.: 81.25%] [G loss: 1.068068]\n",
      "epoch:18 step:17563 [D loss: 0.410584, acc.: 87.50%] [G loss: 1.005067]\n",
      "epoch:18 step:17564 [D loss: 0.570472, acc.: 72.66%] [G loss: 0.927182]\n",
      "epoch:18 step:17565 [D loss: 0.688621, acc.: 56.25%] [G loss: 0.814075]\n",
      "epoch:18 step:17566 [D loss: 0.654672, acc.: 58.59%] [G loss: 0.948481]\n",
      "epoch:18 step:17567 [D loss: 0.593731, acc.: 71.88%] [G loss: 0.839250]\n",
      "epoch:18 step:17568 [D loss: 0.553255, acc.: 81.25%] [G loss: 0.966664]\n",
      "epoch:18 step:17569 [D loss: 0.699142, acc.: 50.00%] [G loss: 0.869117]\n",
      "epoch:18 step:17570 [D loss: 0.580812, acc.: 69.53%] [G loss: 0.936012]\n",
      "epoch:18 step:17571 [D loss: 0.733106, acc.: 52.34%] [G loss: 0.842375]\n",
      "epoch:18 step:17572 [D loss: 0.678565, acc.: 64.06%] [G loss: 0.754508]\n",
      "epoch:18 step:17573 [D loss: 0.466962, acc.: 78.12%] [G loss: 1.175023]\n",
      "epoch:18 step:17574 [D loss: 0.766773, acc.: 57.81%] [G loss: 1.060076]\n",
      "epoch:18 step:17575 [D loss: 0.470159, acc.: 77.34%] [G loss: 1.338068]\n",
      "epoch:18 step:17576 [D loss: 0.813955, acc.: 47.66%] [G loss: 1.315739]\n",
      "epoch:18 step:17577 [D loss: 0.708168, acc.: 57.03%] [G loss: 1.155442]\n",
      "epoch:18 step:17578 [D loss: 0.682017, acc.: 52.34%] [G loss: 1.064883]\n",
      "epoch:18 step:17579 [D loss: 0.517224, acc.: 79.69%] [G loss: 1.012213]\n",
      "epoch:18 step:17580 [D loss: 0.478917, acc.: 81.25%] [G loss: 1.103921]\n",
      "epoch:18 step:17581 [D loss: 0.785600, acc.: 40.62%] [G loss: 1.010702]\n",
      "epoch:18 step:17582 [D loss: 0.773100, acc.: 35.94%] [G loss: 1.064353]\n",
      "epoch:18 step:17583 [D loss: 0.615132, acc.: 60.94%] [G loss: 1.088907]\n",
      "epoch:18 step:17584 [D loss: 0.726973, acc.: 47.66%] [G loss: 1.090032]\n",
      "epoch:18 step:17585 [D loss: 0.688309, acc.: 51.56%] [G loss: 1.140381]\n",
      "epoch:18 step:17586 [D loss: 0.538739, acc.: 73.44%] [G loss: 1.148079]\n",
      "epoch:18 step:17587 [D loss: 0.563703, acc.: 74.22%] [G loss: 1.215220]\n",
      "epoch:18 step:17588 [D loss: 0.698955, acc.: 57.81%] [G loss: 1.196646]\n",
      "epoch:18 step:17589 [D loss: 0.568745, acc.: 69.53%] [G loss: 0.985130]\n",
      "epoch:18 step:17590 [D loss: 0.518558, acc.: 79.69%] [G loss: 1.083779]\n",
      "epoch:18 step:17591 [D loss: 0.543076, acc.: 71.88%] [G loss: 1.062541]\n",
      "epoch:18 step:17592 [D loss: 0.467040, acc.: 80.47%] [G loss: 1.097945]\n",
      "epoch:18 step:17593 [D loss: 0.719646, acc.: 57.03%] [G loss: 1.141208]\n",
      "epoch:18 step:17594 [D loss: 0.741406, acc.: 53.91%] [G loss: 0.898155]\n",
      "epoch:18 step:17595 [D loss: 0.624444, acc.: 64.06%] [G loss: 1.033341]\n",
      "epoch:18 step:17596 [D loss: 0.702481, acc.: 53.91%] [G loss: 0.852297]\n",
      "epoch:18 step:17597 [D loss: 0.716156, acc.: 54.69%] [G loss: 0.788954]\n",
      "epoch:18 step:17598 [D loss: 0.676434, acc.: 55.47%] [G loss: 0.802912]\n",
      "epoch:18 step:17599 [D loss: 0.674530, acc.: 57.81%] [G loss: 0.842810]\n",
      "epoch:18 step:17600 [D loss: 0.710526, acc.: 56.25%] [G loss: 0.738138]\n",
      "epoch:18 step:17601 [D loss: 0.524032, acc.: 80.47%] [G loss: 1.017265]\n",
      "epoch:18 step:17602 [D loss: 0.558970, acc.: 75.78%] [G loss: 0.999048]\n",
      "epoch:18 step:17603 [D loss: 0.563393, acc.: 72.66%] [G loss: 1.033203]\n",
      "epoch:18 step:17604 [D loss: 0.667966, acc.: 61.72%] [G loss: 1.026727]\n",
      "epoch:18 step:17605 [D loss: 0.764226, acc.: 51.56%] [G loss: 0.986178]\n",
      "epoch:18 step:17606 [D loss: 0.719333, acc.: 54.69%] [G loss: 0.579081]\n",
      "epoch:18 step:17607 [D loss: 0.499055, acc.: 79.69%] [G loss: 0.921040]\n",
      "epoch:18 step:17608 [D loss: 0.588549, acc.: 68.75%] [G loss: 0.894995]\n",
      "epoch:18 step:17609 [D loss: 0.464431, acc.: 89.06%] [G loss: 0.950721]\n",
      "epoch:18 step:17610 [D loss: 0.605397, acc.: 64.06%] [G loss: 0.805879]\n",
      "epoch:18 step:17611 [D loss: 0.803577, acc.: 39.84%] [G loss: 1.116289]\n",
      "epoch:18 step:17612 [D loss: 0.818051, acc.: 37.50%] [G loss: 0.855277]\n",
      "epoch:18 step:17613 [D loss: 0.739424, acc.: 50.00%] [G loss: 0.911785]\n",
      "epoch:18 step:17614 [D loss: 0.659697, acc.: 60.94%] [G loss: 0.872717]\n",
      "epoch:18 step:17615 [D loss: 0.572192, acc.: 67.19%] [G loss: 0.733390]\n",
      "epoch:18 step:17616 [D loss: 0.574252, acc.: 66.41%] [G loss: 0.960582]\n",
      "epoch:18 step:17617 [D loss: 0.676066, acc.: 59.38%] [G loss: 0.785405]\n",
      "epoch:18 step:17618 [D loss: 0.730908, acc.: 53.12%] [G loss: 0.608742]\n",
      "epoch:18 step:17619 [D loss: 0.692498, acc.: 50.78%] [G loss: 0.839312]\n",
      "epoch:18 step:17620 [D loss: 0.650530, acc.: 60.16%] [G loss: 0.863778]\n",
      "epoch:18 step:17621 [D loss: 0.615860, acc.: 63.28%] [G loss: 0.825612]\n",
      "epoch:18 step:17622 [D loss: 0.615647, acc.: 67.19%] [G loss: 0.953508]\n",
      "epoch:18 step:17623 [D loss: 0.551415, acc.: 75.78%] [G loss: 0.872862]\n",
      "epoch:18 step:17624 [D loss: 0.642140, acc.: 62.50%] [G loss: 0.953373]\n",
      "epoch:18 step:17625 [D loss: 0.675415, acc.: 67.19%] [G loss: 0.900207]\n",
      "epoch:18 step:17626 [D loss: 0.648899, acc.: 66.41%] [G loss: 0.779472]\n",
      "epoch:18 step:17627 [D loss: 0.659038, acc.: 60.94%] [G loss: 0.781143]\n",
      "epoch:18 step:17628 [D loss: 0.713951, acc.: 50.78%] [G loss: 0.760189]\n",
      "epoch:18 step:17629 [D loss: 0.645642, acc.: 64.84%] [G loss: 0.851531]\n",
      "epoch:18 step:17630 [D loss: 0.485295, acc.: 82.03%] [G loss: 0.960268]\n",
      "epoch:18 step:17631 [D loss: 0.648927, acc.: 62.50%] [G loss: 0.839471]\n",
      "epoch:18 step:17632 [D loss: 0.582080, acc.: 67.19%] [G loss: 0.840504]\n",
      "epoch:18 step:17633 [D loss: 0.673390, acc.: 58.59%] [G loss: 0.806981]\n",
      "epoch:18 step:17634 [D loss: 0.585293, acc.: 72.66%] [G loss: 1.057537]\n",
      "epoch:18 step:17635 [D loss: 0.587728, acc.: 73.44%] [G loss: 0.886057]\n",
      "epoch:18 step:17636 [D loss: 0.640262, acc.: 65.62%] [G loss: 0.828246]\n",
      "epoch:18 step:17637 [D loss: 0.604524, acc.: 67.97%] [G loss: 0.813909]\n",
      "epoch:18 step:17638 [D loss: 0.674312, acc.: 58.59%] [G loss: 0.734236]\n",
      "epoch:18 step:17639 [D loss: 0.661550, acc.: 57.03%] [G loss: 0.900634]\n",
      "epoch:18 step:17640 [D loss: 0.598546, acc.: 69.53%] [G loss: 0.902734]\n",
      "epoch:18 step:17641 [D loss: 0.634753, acc.: 60.16%] [G loss: 0.864941]\n",
      "epoch:18 step:17642 [D loss: 0.678150, acc.: 53.91%] [G loss: 0.880168]\n",
      "epoch:18 step:17643 [D loss: 0.672376, acc.: 59.38%] [G loss: 0.777854]\n",
      "epoch:18 step:17644 [D loss: 0.792383, acc.: 43.75%] [G loss: 0.889168]\n",
      "epoch:18 step:17645 [D loss: 0.610287, acc.: 68.75%] [G loss: 0.825105]\n",
      "epoch:18 step:17646 [D loss: 0.475830, acc.: 71.88%] [G loss: 0.992784]\n",
      "epoch:18 step:17647 [D loss: 0.339303, acc.: 88.28%] [G loss: 1.049257]\n",
      "epoch:18 step:17648 [D loss: 0.440326, acc.: 80.47%] [G loss: 1.125335]\n",
      "epoch:18 step:17649 [D loss: 0.534500, acc.: 76.56%] [G loss: 1.037945]\n",
      "epoch:18 step:17650 [D loss: 0.663117, acc.: 63.28%] [G loss: 0.945214]\n",
      "epoch:18 step:17651 [D loss: 0.527981, acc.: 78.12%] [G loss: 0.882422]\n",
      "epoch:18 step:17652 [D loss: 0.543286, acc.: 64.84%] [G loss: 1.054177]\n",
      "epoch:18 step:17653 [D loss: 0.785754, acc.: 42.19%] [G loss: 1.130246]\n",
      "epoch:18 step:17654 [D loss: 0.682774, acc.: 61.72%] [G loss: 0.957876]\n",
      "epoch:18 step:17655 [D loss: 1.013020, acc.: 22.66%] [G loss: 0.852418]\n",
      "epoch:18 step:17656 [D loss: 0.726663, acc.: 49.22%] [G loss: 0.931976]\n",
      "epoch:18 step:17657 [D loss: 0.563452, acc.: 67.19%] [G loss: 1.198001]\n",
      "epoch:18 step:17658 [D loss: 0.397906, acc.: 88.28%] [G loss: 1.157341]\n",
      "epoch:18 step:17659 [D loss: 0.590545, acc.: 64.06%] [G loss: 1.062607]\n",
      "epoch:18 step:17660 [D loss: 0.682859, acc.: 58.59%] [G loss: 1.227557]\n",
      "epoch:18 step:17661 [D loss: 0.644977, acc.: 57.03%] [G loss: 1.179891]\n",
      "epoch:18 step:17662 [D loss: 0.530520, acc.: 79.69%] [G loss: 0.915857]\n",
      "epoch:18 step:17663 [D loss: 0.762173, acc.: 46.09%] [G loss: 0.842456]\n",
      "epoch:18 step:17664 [D loss: 0.785284, acc.: 38.28%] [G loss: 0.906820]\n",
      "epoch:18 step:17665 [D loss: 0.806522, acc.: 39.06%] [G loss: 0.770326]\n",
      "epoch:18 step:17666 [D loss: 0.770808, acc.: 47.66%] [G loss: 1.046990]\n",
      "epoch:18 step:17667 [D loss: 0.577260, acc.: 67.97%] [G loss: 1.113759]\n",
      "epoch:18 step:17668 [D loss: 0.339453, acc.: 87.50%] [G loss: 1.205328]\n",
      "epoch:18 step:17669 [D loss: 0.581101, acc.: 68.75%] [G loss: 1.163322]\n",
      "epoch:18 step:17670 [D loss: 0.714166, acc.: 50.78%] [G loss: 1.120338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17671 [D loss: 0.753026, acc.: 49.22%] [G loss: 0.915156]\n",
      "epoch:18 step:17672 [D loss: 0.926633, acc.: 27.34%] [G loss: 1.108135]\n",
      "epoch:18 step:17673 [D loss: 0.697373, acc.: 47.66%] [G loss: 1.614325]\n",
      "epoch:18 step:17674 [D loss: 0.608402, acc.: 66.41%] [G loss: 1.341523]\n",
      "epoch:18 step:17675 [D loss: 0.517712, acc.: 75.78%] [G loss: 1.378706]\n",
      "epoch:18 step:17676 [D loss: 0.459090, acc.: 80.47%] [G loss: 1.385955]\n",
      "epoch:18 step:17677 [D loss: 0.685826, acc.: 57.81%] [G loss: 1.177427]\n",
      "epoch:18 step:17678 [D loss: 0.682311, acc.: 56.25%] [G loss: 1.173122]\n",
      "epoch:18 step:17679 [D loss: 0.563171, acc.: 76.56%] [G loss: 1.205420]\n",
      "epoch:18 step:17680 [D loss: 0.599039, acc.: 71.09%] [G loss: 1.053549]\n",
      "epoch:18 step:17681 [D loss: 0.376589, acc.: 90.62%] [G loss: 1.162405]\n",
      "epoch:18 step:17682 [D loss: 0.423352, acc.: 91.41%] [G loss: 1.280221]\n",
      "epoch:18 step:17683 [D loss: 0.653110, acc.: 60.16%] [G loss: 0.800148]\n",
      "epoch:18 step:17684 [D loss: 0.565941, acc.: 74.22%] [G loss: 0.912705]\n",
      "epoch:18 step:17685 [D loss: 0.595591, acc.: 75.00%] [G loss: 0.928531]\n",
      "epoch:18 step:17686 [D loss: 0.793768, acc.: 38.28%] [G loss: 0.920892]\n",
      "epoch:18 step:17687 [D loss: 0.821834, acc.: 49.22%] [G loss: 0.910188]\n",
      "epoch:18 step:17688 [D loss: 0.701791, acc.: 47.66%] [G loss: 1.016318]\n",
      "epoch:18 step:17689 [D loss: 0.623607, acc.: 67.19%] [G loss: 0.903661]\n",
      "epoch:18 step:17690 [D loss: 0.485070, acc.: 75.00%] [G loss: 0.877623]\n",
      "epoch:18 step:17691 [D loss: 0.573362, acc.: 72.66%] [G loss: 0.796440]\n",
      "epoch:18 step:17692 [D loss: 0.539463, acc.: 75.78%] [G loss: 0.850855]\n",
      "epoch:18 step:17693 [D loss: 0.706167, acc.: 48.44%] [G loss: 0.742923]\n",
      "epoch:18 step:17694 [D loss: 0.690256, acc.: 55.47%] [G loss: 0.903835]\n",
      "epoch:18 step:17695 [D loss: 0.609932, acc.: 67.97%] [G loss: 0.907200]\n",
      "epoch:18 step:17696 [D loss: 0.548246, acc.: 70.31%] [G loss: 1.104274]\n",
      "epoch:18 step:17697 [D loss: 0.493039, acc.: 77.34%] [G loss: 0.750770]\n",
      "epoch:18 step:17698 [D loss: 0.661701, acc.: 66.41%] [G loss: 1.173995]\n",
      "epoch:18 step:17699 [D loss: 0.500238, acc.: 78.12%] [G loss: 1.438523]\n",
      "epoch:18 step:17700 [D loss: 0.778524, acc.: 50.78%] [G loss: 0.889871]\n",
      "epoch:18 step:17701 [D loss: 0.814157, acc.: 44.53%] [G loss: 0.975376]\n",
      "epoch:18 step:17702 [D loss: 0.861265, acc.: 35.94%] [G loss: 0.873909]\n",
      "epoch:18 step:17703 [D loss: 0.870639, acc.: 35.16%] [G loss: 0.792756]\n",
      "epoch:18 step:17704 [D loss: 0.735415, acc.: 40.62%] [G loss: 1.004830]\n",
      "epoch:18 step:17705 [D loss: 0.689434, acc.: 56.25%] [G loss: 0.801285]\n",
      "epoch:18 step:17706 [D loss: 0.704061, acc.: 52.34%] [G loss: 0.759718]\n",
      "epoch:18 step:17707 [D loss: 0.702733, acc.: 54.69%] [G loss: 1.051536]\n",
      "epoch:18 step:17708 [D loss: 0.633002, acc.: 57.81%] [G loss: 0.897589]\n",
      "epoch:18 step:17709 [D loss: 0.653854, acc.: 65.62%] [G loss: 1.001944]\n",
      "epoch:18 step:17710 [D loss: 0.662410, acc.: 61.72%] [G loss: 0.792284]\n",
      "epoch:18 step:17711 [D loss: 0.561762, acc.: 70.31%] [G loss: 0.870860]\n",
      "epoch:18 step:17712 [D loss: 0.636992, acc.: 63.28%] [G loss: 0.905679]\n",
      "epoch:18 step:17713 [D loss: 0.732661, acc.: 47.66%] [G loss: 0.802772]\n",
      "epoch:18 step:17714 [D loss: 0.692979, acc.: 54.69%] [G loss: 0.819622]\n",
      "epoch:18 step:17715 [D loss: 0.673252, acc.: 55.47%] [G loss: 0.912504]\n",
      "epoch:18 step:17716 [D loss: 0.632925, acc.: 71.09%] [G loss: 1.003525]\n",
      "epoch:18 step:17717 [D loss: 0.537214, acc.: 75.00%] [G loss: 0.948899]\n",
      "epoch:18 step:17718 [D loss: 0.534537, acc.: 71.88%] [G loss: 0.996855]\n",
      "epoch:18 step:17719 [D loss: 0.550464, acc.: 74.22%] [G loss: 1.050078]\n",
      "epoch:18 step:17720 [D loss: 0.472173, acc.: 83.59%] [G loss: 1.249683]\n",
      "epoch:18 step:17721 [D loss: 0.563415, acc.: 78.12%] [G loss: 1.050953]\n",
      "epoch:18 step:17722 [D loss: 0.633712, acc.: 73.44%] [G loss: 1.157680]\n",
      "epoch:18 step:17723 [D loss: 0.477609, acc.: 80.47%] [G loss: 1.154121]\n",
      "epoch:18 step:17724 [D loss: 0.753969, acc.: 55.47%] [G loss: 0.927165]\n",
      "epoch:18 step:17725 [D loss: 0.687634, acc.: 55.47%] [G loss: 0.948973]\n",
      "epoch:18 step:17726 [D loss: 0.663216, acc.: 57.81%] [G loss: 0.978146]\n",
      "epoch:18 step:17727 [D loss: 0.620570, acc.: 65.62%] [G loss: 0.899863]\n",
      "epoch:18 step:17728 [D loss: 0.680898, acc.: 57.03%] [G loss: 0.965859]\n",
      "epoch:18 step:17729 [D loss: 0.665703, acc.: 56.25%] [G loss: 0.922398]\n",
      "epoch:18 step:17730 [D loss: 0.671711, acc.: 59.38%] [G loss: 1.022440]\n",
      "epoch:18 step:17731 [D loss: 0.614772, acc.: 62.50%] [G loss: 0.854417]\n",
      "epoch:18 step:17732 [D loss: 0.600982, acc.: 66.41%] [G loss: 1.084245]\n",
      "epoch:18 step:17733 [D loss: 0.667388, acc.: 60.16%] [G loss: 0.846281]\n",
      "epoch:18 step:17734 [D loss: 0.640109, acc.: 62.50%] [G loss: 1.036228]\n",
      "epoch:18 step:17735 [D loss: 0.629440, acc.: 63.28%] [G loss: 1.051136]\n",
      "epoch:18 step:17736 [D loss: 0.823565, acc.: 44.53%] [G loss: 0.891892]\n",
      "epoch:18 step:17737 [D loss: 0.609174, acc.: 67.97%] [G loss: 1.057424]\n",
      "epoch:18 step:17738 [D loss: 0.567385, acc.: 71.88%] [G loss: 0.887510]\n",
      "epoch:18 step:17739 [D loss: 0.577629, acc.: 72.66%] [G loss: 1.041678]\n",
      "epoch:18 step:17740 [D loss: 0.608451, acc.: 69.53%] [G loss: 1.075945]\n",
      "epoch:18 step:17741 [D loss: 0.601633, acc.: 66.41%] [G loss: 0.819834]\n",
      "epoch:18 step:17742 [D loss: 0.632504, acc.: 64.06%] [G loss: 1.019059]\n",
      "epoch:18 step:17743 [D loss: 0.753900, acc.: 47.66%] [G loss: 0.943638]\n",
      "epoch:18 step:17744 [D loss: 0.765285, acc.: 50.78%] [G loss: 0.919572]\n",
      "epoch:18 step:17745 [D loss: 0.638897, acc.: 64.84%] [G loss: 0.843239]\n",
      "epoch:18 step:17746 [D loss: 0.578485, acc.: 73.44%] [G loss: 1.011707]\n",
      "epoch:18 step:17747 [D loss: 0.696651, acc.: 60.16%] [G loss: 0.881699]\n",
      "epoch:18 step:17748 [D loss: 0.495081, acc.: 78.12%] [G loss: 0.868067]\n",
      "epoch:18 step:17749 [D loss: 0.459953, acc.: 82.03%] [G loss: 0.858568]\n",
      "epoch:18 step:17750 [D loss: 0.497555, acc.: 78.12%] [G loss: 0.824773]\n",
      "epoch:18 step:17751 [D loss: 0.470567, acc.: 75.78%] [G loss: 1.071833]\n",
      "epoch:18 step:17752 [D loss: 0.505560, acc.: 72.66%] [G loss: 0.894702]\n",
      "epoch:18 step:17753 [D loss: 0.538526, acc.: 66.41%] [G loss: 1.171846]\n",
      "epoch:18 step:17754 [D loss: 0.797250, acc.: 45.31%] [G loss: 0.982060]\n",
      "epoch:18 step:17755 [D loss: 0.671373, acc.: 60.94%] [G loss: 0.882986]\n",
      "epoch:18 step:17756 [D loss: 0.908891, acc.: 35.94%] [G loss: 1.073922]\n",
      "epoch:18 step:17757 [D loss: 0.922916, acc.: 37.50%] [G loss: 1.043842]\n",
      "epoch:18 step:17758 [D loss: 0.833509, acc.: 42.97%] [G loss: 1.068212]\n",
      "epoch:18 step:17759 [D loss: 0.709178, acc.: 60.16%] [G loss: 1.226998]\n",
      "epoch:18 step:17760 [D loss: 0.753517, acc.: 50.78%] [G loss: 1.047405]\n",
      "epoch:18 step:17761 [D loss: 0.703972, acc.: 55.47%] [G loss: 1.172198]\n",
      "epoch:18 step:17762 [D loss: 0.654874, acc.: 56.25%] [G loss: 1.164476]\n",
      "epoch:18 step:17763 [D loss: 0.581905, acc.: 65.62%] [G loss: 1.204540]\n",
      "epoch:18 step:17764 [D loss: 0.492688, acc.: 76.56%] [G loss: 1.088570]\n",
      "epoch:18 step:17765 [D loss: 0.365523, acc.: 94.53%] [G loss: 1.339118]\n",
      "epoch:18 step:17766 [D loss: 0.412441, acc.: 86.72%] [G loss: 1.300930]\n",
      "epoch:18 step:17767 [D loss: 0.473960, acc.: 77.34%] [G loss: 1.522760]\n",
      "epoch:18 step:17768 [D loss: 0.553564, acc.: 71.09%] [G loss: 1.375446]\n",
      "epoch:18 step:17769 [D loss: 0.481229, acc.: 80.47%] [G loss: 1.186227]\n",
      "epoch:18 step:17770 [D loss: 0.875723, acc.: 50.78%] [G loss: 1.022802]\n",
      "epoch:18 step:17771 [D loss: 0.739938, acc.: 57.03%] [G loss: 1.105304]\n",
      "epoch:18 step:17772 [D loss: 0.700009, acc.: 54.69%] [G loss: 0.836622]\n",
      "epoch:18 step:17773 [D loss: 0.642215, acc.: 67.19%] [G loss: 0.955711]\n",
      "epoch:18 step:17774 [D loss: 0.619471, acc.: 64.84%] [G loss: 0.791469]\n",
      "epoch:18 step:17775 [D loss: 0.572801, acc.: 69.53%] [G loss: 0.814445]\n",
      "epoch:18 step:17776 [D loss: 0.752307, acc.: 46.88%] [G loss: 0.984367]\n",
      "epoch:18 step:17777 [D loss: 0.404904, acc.: 87.50%] [G loss: 0.985665]\n",
      "epoch:18 step:17778 [D loss: 0.270695, acc.: 91.41%] [G loss: 1.141519]\n",
      "epoch:18 step:17779 [D loss: 0.572499, acc.: 71.88%] [G loss: 1.112867]\n",
      "epoch:18 step:17780 [D loss: 0.663122, acc.: 53.91%] [G loss: 1.154793]\n",
      "epoch:18 step:17781 [D loss: 0.808813, acc.: 47.66%] [G loss: 1.047624]\n",
      "epoch:18 step:17782 [D loss: 0.779508, acc.: 53.12%] [G loss: 0.952351]\n",
      "epoch:18 step:17783 [D loss: 0.724600, acc.: 55.47%] [G loss: 0.874058]\n",
      "epoch:18 step:17784 [D loss: 0.501994, acc.: 82.03%] [G loss: 0.939849]\n",
      "epoch:18 step:17785 [D loss: 0.437570, acc.: 83.59%] [G loss: 0.859024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17786 [D loss: 0.886037, acc.: 42.19%] [G loss: 0.887406]\n",
      "epoch:18 step:17787 [D loss: 0.754338, acc.: 43.75%] [G loss: 0.830162]\n",
      "epoch:18 step:17788 [D loss: 0.530744, acc.: 76.56%] [G loss: 0.716267]\n",
      "epoch:18 step:17789 [D loss: 0.583401, acc.: 65.62%] [G loss: 0.937235]\n",
      "epoch:18 step:17790 [D loss: 0.444041, acc.: 74.22%] [G loss: 0.886747]\n",
      "epoch:18 step:17791 [D loss: 0.356857, acc.: 89.06%] [G loss: 0.897493]\n",
      "epoch:18 step:17792 [D loss: 0.432506, acc.: 70.31%] [G loss: 1.136287]\n",
      "epoch:18 step:17793 [D loss: 0.343367, acc.: 80.47%] [G loss: 1.327854]\n",
      "epoch:18 step:17794 [D loss: 0.710498, acc.: 54.69%] [G loss: 1.206167]\n",
      "epoch:18 step:17795 [D loss: 0.504390, acc.: 81.25%] [G loss: 1.125360]\n",
      "epoch:18 step:17796 [D loss: 0.566019, acc.: 73.44%] [G loss: 1.057447]\n",
      "epoch:18 step:17797 [D loss: 0.600090, acc.: 67.97%] [G loss: 1.146933]\n",
      "epoch:18 step:17798 [D loss: 0.556850, acc.: 72.66%] [G loss: 1.041925]\n",
      "epoch:18 step:17799 [D loss: 0.505382, acc.: 75.00%] [G loss: 0.903499]\n",
      "epoch:18 step:17800 [D loss: 0.354435, acc.: 89.84%] [G loss: 1.109285]\n",
      "epoch:18 step:17801 [D loss: 0.437124, acc.: 85.16%] [G loss: 0.998542]\n",
      "epoch:18 step:17802 [D loss: 0.287273, acc.: 88.28%] [G loss: 1.147429]\n",
      "epoch:18 step:17803 [D loss: 0.191685, acc.: 94.53%] [G loss: 1.215640]\n",
      "epoch:19 step:17804 [D loss: 0.763536, acc.: 52.34%] [G loss: 0.790271]\n",
      "epoch:19 step:17805 [D loss: 0.909484, acc.: 28.91%] [G loss: 1.048823]\n",
      "epoch:19 step:17806 [D loss: 0.743136, acc.: 53.12%] [G loss: 0.882488]\n",
      "epoch:19 step:17807 [D loss: 0.761391, acc.: 48.44%] [G loss: 1.009004]\n",
      "epoch:19 step:17808 [D loss: 0.765797, acc.: 50.78%] [G loss: 0.761645]\n",
      "epoch:19 step:17809 [D loss: 0.847632, acc.: 40.62%] [G loss: 0.990334]\n",
      "epoch:19 step:17810 [D loss: 0.789771, acc.: 38.28%] [G loss: 1.008999]\n",
      "epoch:19 step:17811 [D loss: 0.790954, acc.: 38.28%] [G loss: 1.009217]\n",
      "epoch:19 step:17812 [D loss: 0.667772, acc.: 61.72%] [G loss: 1.086454]\n",
      "epoch:19 step:17813 [D loss: 0.721586, acc.: 53.12%] [G loss: 0.967124]\n",
      "epoch:19 step:17814 [D loss: 0.815847, acc.: 39.84%] [G loss: 0.746556]\n",
      "epoch:19 step:17815 [D loss: 0.759268, acc.: 46.09%] [G loss: 0.946627]\n",
      "epoch:19 step:17816 [D loss: 0.690919, acc.: 55.47%] [G loss: 0.932562]\n",
      "epoch:19 step:17817 [D loss: 0.785690, acc.: 42.19%] [G loss: 1.052294]\n",
      "epoch:19 step:17818 [D loss: 0.737895, acc.: 48.44%] [G loss: 0.845071]\n",
      "epoch:19 step:17819 [D loss: 0.661889, acc.: 57.03%] [G loss: 0.857699]\n",
      "epoch:19 step:17820 [D loss: 0.775786, acc.: 37.50%] [G loss: 0.835777]\n",
      "epoch:19 step:17821 [D loss: 0.715267, acc.: 51.56%] [G loss: 0.857402]\n",
      "epoch:19 step:17822 [D loss: 0.811410, acc.: 35.16%] [G loss: 1.077826]\n",
      "epoch:19 step:17823 [D loss: 0.642974, acc.: 61.72%] [G loss: 1.447777]\n",
      "epoch:19 step:17824 [D loss: 0.698283, acc.: 57.03%] [G loss: 1.226412]\n",
      "epoch:19 step:17825 [D loss: 0.624292, acc.: 64.06%] [G loss: 0.949261]\n",
      "epoch:19 step:17826 [D loss: 0.669227, acc.: 53.12%] [G loss: 1.076064]\n",
      "epoch:19 step:17827 [D loss: 0.734744, acc.: 50.78%] [G loss: 0.934728]\n",
      "epoch:19 step:17828 [D loss: 0.681358, acc.: 59.38%] [G loss: 1.022154]\n",
      "epoch:19 step:17829 [D loss: 0.687456, acc.: 50.00%] [G loss: 0.825705]\n",
      "epoch:19 step:17830 [D loss: 0.621004, acc.: 68.75%] [G loss: 0.901000]\n",
      "epoch:19 step:17831 [D loss: 0.671765, acc.: 56.25%] [G loss: 1.120094]\n",
      "epoch:19 step:17832 [D loss: 0.631811, acc.: 63.28%] [G loss: 0.984731]\n",
      "epoch:19 step:17833 [D loss: 0.630763, acc.: 64.06%] [G loss: 0.909381]\n",
      "epoch:19 step:17834 [D loss: 0.603609, acc.: 66.41%] [G loss: 0.868844]\n",
      "epoch:19 step:17835 [D loss: 0.529662, acc.: 75.78%] [G loss: 0.902368]\n",
      "epoch:19 step:17836 [D loss: 0.489274, acc.: 79.69%] [G loss: 1.094799]\n",
      "epoch:19 step:17837 [D loss: 0.491343, acc.: 80.47%] [G loss: 1.041754]\n",
      "epoch:19 step:17838 [D loss: 0.411627, acc.: 87.50%] [G loss: 1.114803]\n",
      "epoch:19 step:17839 [D loss: 0.366846, acc.: 91.41%] [G loss: 1.167347]\n",
      "epoch:19 step:17840 [D loss: 0.670479, acc.: 59.38%] [G loss: 0.996109]\n",
      "epoch:19 step:17841 [D loss: 0.895740, acc.: 45.31%] [G loss: 1.018564]\n",
      "epoch:19 step:17842 [D loss: 0.843254, acc.: 36.72%] [G loss: 0.956351]\n",
      "epoch:19 step:17843 [D loss: 0.732146, acc.: 55.47%] [G loss: 0.875046]\n",
      "epoch:19 step:17844 [D loss: 0.616026, acc.: 73.44%] [G loss: 0.771537]\n",
      "epoch:19 step:17845 [D loss: 0.668293, acc.: 60.16%] [G loss: 0.877055]\n",
      "epoch:19 step:17846 [D loss: 0.569412, acc.: 75.00%] [G loss: 1.014193]\n",
      "epoch:19 step:17847 [D loss: 0.575510, acc.: 75.78%] [G loss: 0.900733]\n",
      "epoch:19 step:17848 [D loss: 0.654019, acc.: 58.59%] [G loss: 0.936263]\n",
      "epoch:19 step:17849 [D loss: 0.670819, acc.: 63.28%] [G loss: 1.042188]\n",
      "epoch:19 step:17850 [D loss: 0.610297, acc.: 73.44%] [G loss: 0.866861]\n",
      "epoch:19 step:17851 [D loss: 0.639019, acc.: 67.19%] [G loss: 0.821364]\n",
      "epoch:19 step:17852 [D loss: 0.673506, acc.: 53.91%] [G loss: 0.751589]\n",
      "epoch:19 step:17853 [D loss: 0.560576, acc.: 75.00%] [G loss: 0.849287]\n",
      "epoch:19 step:17854 [D loss: 0.798835, acc.: 46.09%] [G loss: 0.845272]\n",
      "epoch:19 step:17855 [D loss: 0.630379, acc.: 65.62%] [G loss: 0.752641]\n",
      "epoch:19 step:17856 [D loss: 0.610458, acc.: 65.62%] [G loss: 0.928931]\n",
      "epoch:19 step:17857 [D loss: 0.680055, acc.: 51.56%] [G loss: 0.725343]\n",
      "epoch:19 step:17858 [D loss: 0.743187, acc.: 45.31%] [G loss: 0.875705]\n",
      "epoch:19 step:17859 [D loss: 0.678244, acc.: 60.16%] [G loss: 0.800550]\n",
      "epoch:19 step:17860 [D loss: 0.539430, acc.: 79.69%] [G loss: 0.980315]\n",
      "epoch:19 step:17861 [D loss: 0.619640, acc.: 60.94%] [G loss: 0.911604]\n",
      "epoch:19 step:17862 [D loss: 0.578894, acc.: 75.00%] [G loss: 0.797837]\n",
      "epoch:19 step:17863 [D loss: 0.566230, acc.: 73.44%] [G loss: 1.050128]\n",
      "epoch:19 step:17864 [D loss: 0.674710, acc.: 53.91%] [G loss: 0.875179]\n",
      "epoch:19 step:17865 [D loss: 0.853516, acc.: 35.16%] [G loss: 0.872024]\n",
      "epoch:19 step:17866 [D loss: 0.630224, acc.: 64.84%] [G loss: 1.037803]\n",
      "epoch:19 step:17867 [D loss: 0.697660, acc.: 51.56%] [G loss: 1.087247]\n",
      "epoch:19 step:17868 [D loss: 0.683982, acc.: 53.91%] [G loss: 1.066848]\n",
      "epoch:19 step:17869 [D loss: 0.719576, acc.: 51.56%] [G loss: 0.853890]\n",
      "epoch:19 step:17870 [D loss: 0.687191, acc.: 55.47%] [G loss: 1.029234]\n",
      "epoch:19 step:17871 [D loss: 0.680555, acc.: 57.03%] [G loss: 0.968187]\n",
      "epoch:19 step:17872 [D loss: 0.669253, acc.: 60.94%] [G loss: 0.958110]\n",
      "epoch:19 step:17873 [D loss: 0.620278, acc.: 66.41%] [G loss: 1.109153]\n",
      "epoch:19 step:17874 [D loss: 0.627302, acc.: 65.62%] [G loss: 0.976805]\n",
      "epoch:19 step:17875 [D loss: 0.591893, acc.: 71.88%] [G loss: 1.012246]\n",
      "epoch:19 step:17876 [D loss: 0.585218, acc.: 66.41%] [G loss: 0.995134]\n",
      "epoch:19 step:17877 [D loss: 0.605891, acc.: 64.06%] [G loss: 0.988997]\n",
      "epoch:19 step:17878 [D loss: 0.498034, acc.: 78.91%] [G loss: 0.899940]\n",
      "epoch:19 step:17879 [D loss: 0.472498, acc.: 79.69%] [G loss: 1.010475]\n",
      "epoch:19 step:17880 [D loss: 0.467910, acc.: 82.03%] [G loss: 1.040862]\n",
      "epoch:19 step:17881 [D loss: 0.788746, acc.: 46.09%] [G loss: 0.957313]\n",
      "epoch:19 step:17882 [D loss: 0.710079, acc.: 58.59%] [G loss: 0.909818]\n",
      "epoch:19 step:17883 [D loss: 0.891333, acc.: 34.38%] [G loss: 1.046656]\n",
      "epoch:19 step:17884 [D loss: 0.698113, acc.: 49.22%] [G loss: 1.053207]\n",
      "epoch:19 step:17885 [D loss: 0.686883, acc.: 57.03%] [G loss: 0.964162]\n",
      "epoch:19 step:17886 [D loss: 0.620662, acc.: 62.50%] [G loss: 1.095892]\n",
      "epoch:19 step:17887 [D loss: 0.659289, acc.: 63.28%] [G loss: 1.049501]\n",
      "epoch:19 step:17888 [D loss: 0.629233, acc.: 69.53%] [G loss: 0.932780]\n",
      "epoch:19 step:17889 [D loss: 0.679521, acc.: 60.16%] [G loss: 0.804542]\n",
      "epoch:19 step:17890 [D loss: 0.624353, acc.: 68.75%] [G loss: 0.983736]\n",
      "epoch:19 step:17891 [D loss: 0.594401, acc.: 70.31%] [G loss: 0.974498]\n",
      "epoch:19 step:17892 [D loss: 0.585495, acc.: 69.53%] [G loss: 0.869880]\n",
      "epoch:19 step:17893 [D loss: 0.655630, acc.: 64.84%] [G loss: 0.968305]\n",
      "epoch:19 step:17894 [D loss: 0.618792, acc.: 67.97%] [G loss: 0.812556]\n",
      "epoch:19 step:17895 [D loss: 0.590232, acc.: 72.66%] [G loss: 0.788947]\n",
      "epoch:19 step:17896 [D loss: 0.524704, acc.: 78.91%] [G loss: 0.916808]\n",
      "epoch:19 step:17897 [D loss: 0.559426, acc.: 74.22%] [G loss: 1.023413]\n",
      "epoch:19 step:17898 [D loss: 0.730497, acc.: 56.25%] [G loss: 0.663026]\n",
      "epoch:19 step:17899 [D loss: 0.658761, acc.: 62.50%] [G loss: 0.894107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17900 [D loss: 0.691050, acc.: 55.47%] [G loss: 0.718325]\n",
      "epoch:19 step:17901 [D loss: 0.701029, acc.: 53.91%] [G loss: 0.676368]\n",
      "epoch:19 step:17902 [D loss: 0.617637, acc.: 68.75%] [G loss: 0.773742]\n",
      "epoch:19 step:17903 [D loss: 0.615061, acc.: 67.19%] [G loss: 0.889388]\n",
      "epoch:19 step:17904 [D loss: 0.627798, acc.: 62.50%] [G loss: 0.877599]\n",
      "epoch:19 step:17905 [D loss: 0.739978, acc.: 48.44%] [G loss: 0.888201]\n",
      "epoch:19 step:17906 [D loss: 0.737020, acc.: 40.62%] [G loss: 0.709227]\n",
      "epoch:19 step:17907 [D loss: 0.727270, acc.: 50.00%] [G loss: 0.681405]\n",
      "epoch:19 step:17908 [D loss: 0.630725, acc.: 60.16%] [G loss: 0.863684]\n",
      "epoch:19 step:17909 [D loss: 0.723598, acc.: 53.91%] [G loss: 0.823283]\n",
      "epoch:19 step:17910 [D loss: 0.575786, acc.: 70.31%] [G loss: 0.838436]\n",
      "epoch:19 step:17911 [D loss: 0.674477, acc.: 59.38%] [G loss: 0.971502]\n",
      "epoch:19 step:17912 [D loss: 0.681886, acc.: 58.59%] [G loss: 0.942108]\n",
      "epoch:19 step:17913 [D loss: 0.679471, acc.: 54.69%] [G loss: 0.876198]\n",
      "epoch:19 step:17914 [D loss: 0.637274, acc.: 62.50%] [G loss: 0.811403]\n",
      "epoch:19 step:17915 [D loss: 0.557079, acc.: 75.00%] [G loss: 0.934484]\n",
      "epoch:19 step:17916 [D loss: 0.609556, acc.: 69.53%] [G loss: 0.891109]\n",
      "epoch:19 step:17917 [D loss: 0.635943, acc.: 64.84%] [G loss: 0.903303]\n",
      "epoch:19 step:17918 [D loss: 0.569541, acc.: 73.44%] [G loss: 0.967613]\n",
      "epoch:19 step:17919 [D loss: 0.580467, acc.: 70.31%] [G loss: 0.954737]\n",
      "epoch:19 step:17920 [D loss: 0.568065, acc.: 66.41%] [G loss: 1.036922]\n",
      "epoch:19 step:17921 [D loss: 0.525571, acc.: 71.88%] [G loss: 1.049788]\n",
      "epoch:19 step:17922 [D loss: 0.391507, acc.: 85.94%] [G loss: 1.099995]\n",
      "epoch:19 step:17923 [D loss: 0.746728, acc.: 47.66%] [G loss: 1.055265]\n",
      "epoch:19 step:17924 [D loss: 0.609086, acc.: 66.41%] [G loss: 1.052304]\n",
      "epoch:19 step:17925 [D loss: 0.615671, acc.: 64.84%] [G loss: 0.968161]\n",
      "epoch:19 step:17926 [D loss: 0.651341, acc.: 60.16%] [G loss: 0.987426]\n",
      "epoch:19 step:17927 [D loss: 0.718678, acc.: 53.91%] [G loss: 0.984099]\n",
      "epoch:19 step:17928 [D loss: 0.702227, acc.: 46.88%] [G loss: 0.988370]\n",
      "epoch:19 step:17929 [D loss: 0.652901, acc.: 56.25%] [G loss: 0.980756]\n",
      "epoch:19 step:17930 [D loss: 0.698820, acc.: 59.38%] [G loss: 1.135175]\n",
      "epoch:19 step:17931 [D loss: 0.705085, acc.: 52.34%] [G loss: 0.944062]\n",
      "epoch:19 step:17932 [D loss: 0.619135, acc.: 62.50%] [G loss: 0.962524]\n",
      "epoch:19 step:17933 [D loss: 0.581451, acc.: 71.09%] [G loss: 1.018680]\n",
      "epoch:19 step:17934 [D loss: 0.639469, acc.: 59.38%] [G loss: 0.873937]\n",
      "epoch:19 step:17935 [D loss: 0.639717, acc.: 58.59%] [G loss: 0.932197]\n",
      "epoch:19 step:17936 [D loss: 0.657158, acc.: 62.50%] [G loss: 0.910100]\n",
      "epoch:19 step:17937 [D loss: 0.649025, acc.: 60.94%] [G loss: 0.926812]\n",
      "epoch:19 step:17938 [D loss: 0.548574, acc.: 68.75%] [G loss: 0.956890]\n",
      "epoch:19 step:17939 [D loss: 0.650600, acc.: 58.59%] [G loss: 0.907276]\n",
      "epoch:19 step:17940 [D loss: 0.695927, acc.: 55.47%] [G loss: 0.867419]\n",
      "epoch:19 step:17941 [D loss: 0.749613, acc.: 48.44%] [G loss: 0.820916]\n",
      "epoch:19 step:17942 [D loss: 0.655171, acc.: 60.16%] [G loss: 0.851448]\n",
      "epoch:19 step:17943 [D loss: 0.617170, acc.: 63.28%] [G loss: 0.704777]\n",
      "epoch:19 step:17944 [D loss: 0.649945, acc.: 71.88%] [G loss: 0.822333]\n",
      "epoch:19 step:17945 [D loss: 0.685177, acc.: 53.12%] [G loss: 0.744334]\n",
      "epoch:19 step:17946 [D loss: 0.634341, acc.: 63.28%] [G loss: 0.874170]\n",
      "epoch:19 step:17947 [D loss: 0.572440, acc.: 73.44%] [G loss: 1.000592]\n",
      "epoch:19 step:17948 [D loss: 0.434645, acc.: 78.12%] [G loss: 1.060557]\n",
      "epoch:19 step:17949 [D loss: 0.536535, acc.: 80.47%] [G loss: 0.965874]\n",
      "epoch:19 step:17950 [D loss: 0.687568, acc.: 56.25%] [G loss: 1.027339]\n",
      "epoch:19 step:17951 [D loss: 0.700159, acc.: 53.12%] [G loss: 1.049721]\n",
      "epoch:19 step:17952 [D loss: 0.444944, acc.: 83.59%] [G loss: 0.987677]\n",
      "epoch:19 step:17953 [D loss: 0.375088, acc.: 79.69%] [G loss: 1.198146]\n",
      "epoch:19 step:17954 [D loss: 0.290770, acc.: 89.06%] [G loss: 1.365663]\n",
      "epoch:19 step:17955 [D loss: 0.356182, acc.: 94.53%] [G loss: 1.196999]\n",
      "epoch:19 step:17956 [D loss: 0.745599, acc.: 47.66%] [G loss: 1.083532]\n",
      "epoch:19 step:17957 [D loss: 0.626990, acc.: 67.97%] [G loss: 0.824448]\n",
      "epoch:19 step:17958 [D loss: 0.917170, acc.: 42.97%] [G loss: 0.769018]\n",
      "epoch:19 step:17959 [D loss: 0.884706, acc.: 30.47%] [G loss: 0.963893]\n",
      "epoch:19 step:17960 [D loss: 0.734837, acc.: 51.56%] [G loss: 1.010566]\n",
      "epoch:19 step:17961 [D loss: 0.662217, acc.: 57.03%] [G loss: 1.108354]\n",
      "epoch:19 step:17962 [D loss: 0.752877, acc.: 43.75%] [G loss: 0.974701]\n",
      "epoch:19 step:17963 [D loss: 0.790877, acc.: 53.12%] [G loss: 0.876414]\n",
      "epoch:19 step:17964 [D loss: 0.749164, acc.: 51.56%] [G loss: 0.971570]\n",
      "epoch:19 step:17965 [D loss: 0.743695, acc.: 45.31%] [G loss: 0.839863]\n",
      "epoch:19 step:17966 [D loss: 0.701381, acc.: 52.34%] [G loss: 0.922800]\n",
      "epoch:19 step:17967 [D loss: 0.708886, acc.: 53.12%] [G loss: 0.957749]\n",
      "epoch:19 step:17968 [D loss: 0.651300, acc.: 60.94%] [G loss: 0.669237]\n",
      "epoch:19 step:17969 [D loss: 0.655316, acc.: 58.59%] [G loss: 0.849022]\n",
      "epoch:19 step:17970 [D loss: 0.660007, acc.: 54.69%] [G loss: 0.921410]\n",
      "epoch:19 step:17971 [D loss: 0.572109, acc.: 78.91%] [G loss: 1.041155]\n",
      "epoch:19 step:17972 [D loss: 0.612143, acc.: 63.28%] [G loss: 1.159902]\n",
      "epoch:19 step:17973 [D loss: 0.670256, acc.: 58.59%] [G loss: 0.992757]\n",
      "epoch:19 step:17974 [D loss: 0.632124, acc.: 62.50%] [G loss: 1.038549]\n",
      "epoch:19 step:17975 [D loss: 0.607949, acc.: 67.97%] [G loss: 1.031850]\n",
      "epoch:19 step:17976 [D loss: 0.567994, acc.: 72.66%] [G loss: 1.086154]\n",
      "epoch:19 step:17977 [D loss: 0.698602, acc.: 53.91%] [G loss: 0.938247]\n",
      "epoch:19 step:17978 [D loss: 0.699622, acc.: 56.25%] [G loss: 0.964920]\n",
      "epoch:19 step:17979 [D loss: 0.527143, acc.: 80.47%] [G loss: 1.031326]\n",
      "epoch:19 step:17980 [D loss: 0.676536, acc.: 58.59%] [G loss: 0.894835]\n",
      "epoch:19 step:17981 [D loss: 0.714513, acc.: 54.69%] [G loss: 0.944548]\n",
      "epoch:19 step:17982 [D loss: 0.661848, acc.: 56.25%] [G loss: 0.952155]\n",
      "epoch:19 step:17983 [D loss: 0.660849, acc.: 67.19%] [G loss: 0.887971]\n",
      "epoch:19 step:17984 [D loss: 0.561415, acc.: 69.53%] [G loss: 0.838184]\n",
      "epoch:19 step:17985 [D loss: 0.646651, acc.: 61.72%] [G loss: 0.863662]\n",
      "epoch:19 step:17986 [D loss: 0.662702, acc.: 59.38%] [G loss: 0.819474]\n",
      "epoch:19 step:17987 [D loss: 0.581965, acc.: 71.09%] [G loss: 0.769047]\n",
      "epoch:19 step:17988 [D loss: 0.604796, acc.: 64.84%] [G loss: 0.861457]\n",
      "epoch:19 step:17989 [D loss: 0.700579, acc.: 49.22%] [G loss: 0.722376]\n",
      "epoch:19 step:17990 [D loss: 0.647704, acc.: 60.16%] [G loss: 0.874033]\n",
      "epoch:19 step:17991 [D loss: 0.620147, acc.: 65.62%] [G loss: 0.727318]\n",
      "epoch:19 step:17992 [D loss: 0.716607, acc.: 54.69%] [G loss: 0.926010]\n",
      "epoch:19 step:17993 [D loss: 0.636148, acc.: 64.06%] [G loss: 0.880985]\n",
      "epoch:19 step:17994 [D loss: 0.599983, acc.: 74.22%] [G loss: 0.811870]\n",
      "epoch:19 step:17995 [D loss: 0.538899, acc.: 71.09%] [G loss: 0.877658]\n",
      "epoch:19 step:17996 [D loss: 0.575455, acc.: 75.00%] [G loss: 0.826533]\n",
      "epoch:19 step:17997 [D loss: 0.586387, acc.: 71.88%] [G loss: 0.875050]\n",
      "epoch:19 step:17998 [D loss: 0.610258, acc.: 67.19%] [G loss: 0.885561]\n",
      "epoch:19 step:17999 [D loss: 0.649354, acc.: 59.38%] [G loss: 0.738086]\n",
      "epoch:19 step:18000 [D loss: 0.678548, acc.: 63.28%] [G loss: 0.857484]\n",
      "epoch:19 step:18001 [D loss: 0.699867, acc.: 55.47%] [G loss: 0.767010]\n",
      "epoch:19 step:18002 [D loss: 0.839305, acc.: 27.34%] [G loss: 0.801324]\n",
      "epoch:19 step:18003 [D loss: 0.811624, acc.: 42.19%] [G loss: 0.819917]\n",
      "epoch:19 step:18004 [D loss: 0.631971, acc.: 63.28%] [G loss: 0.938166]\n",
      "epoch:19 step:18005 [D loss: 0.682531, acc.: 61.72%] [G loss: 0.904895]\n",
      "epoch:19 step:18006 [D loss: 0.647165, acc.: 62.50%] [G loss: 0.856448]\n",
      "epoch:19 step:18007 [D loss: 0.700225, acc.: 61.72%] [G loss: 0.918380]\n",
      "epoch:19 step:18008 [D loss: 0.632488, acc.: 69.53%] [G loss: 0.918915]\n",
      "epoch:19 step:18009 [D loss: 0.625965, acc.: 67.19%] [G loss: 0.950486]\n",
      "epoch:19 step:18010 [D loss: 0.727159, acc.: 59.38%] [G loss: 0.891645]\n",
      "epoch:19 step:18011 [D loss: 0.626957, acc.: 70.31%] [G loss: 0.844544]\n",
      "epoch:19 step:18012 [D loss: 0.600597, acc.: 67.97%] [G loss: 0.866737]\n",
      "epoch:19 step:18013 [D loss: 0.695453, acc.: 57.03%] [G loss: 0.818819]\n",
      "epoch:19 step:18014 [D loss: 0.726227, acc.: 47.66%] [G loss: 0.841792]\n",
      "epoch:19 step:18015 [D loss: 0.700355, acc.: 51.56%] [G loss: 0.823504]\n",
      "epoch:19 step:18016 [D loss: 0.637094, acc.: 61.72%] [G loss: 0.781687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18017 [D loss: 0.721937, acc.: 52.34%] [G loss: 1.056553]\n",
      "epoch:19 step:18018 [D loss: 0.734858, acc.: 48.44%] [G loss: 0.784370]\n",
      "epoch:19 step:18019 [D loss: 0.533929, acc.: 67.97%] [G loss: 0.815497]\n",
      "epoch:19 step:18020 [D loss: 0.736180, acc.: 53.12%] [G loss: 0.844374]\n",
      "epoch:19 step:18021 [D loss: 0.662517, acc.: 65.62%] [G loss: 0.806755]\n",
      "epoch:19 step:18022 [D loss: 0.617446, acc.: 69.53%] [G loss: 0.847139]\n",
      "epoch:19 step:18023 [D loss: 0.352027, acc.: 89.84%] [G loss: 0.903380]\n",
      "epoch:19 step:18024 [D loss: 0.430230, acc.: 82.81%] [G loss: 0.968136]\n",
      "epoch:19 step:18025 [D loss: 0.428605, acc.: 81.25%] [G loss: 1.162088]\n",
      "epoch:19 step:18026 [D loss: 0.364652, acc.: 90.62%] [G loss: 1.273824]\n",
      "epoch:19 step:18027 [D loss: 0.708267, acc.: 51.56%] [G loss: 1.153189]\n",
      "epoch:19 step:18028 [D loss: 0.763082, acc.: 47.66%] [G loss: 0.993102]\n",
      "epoch:19 step:18029 [D loss: 0.582094, acc.: 71.09%] [G loss: 0.909958]\n",
      "epoch:19 step:18030 [D loss: 0.543970, acc.: 72.66%] [G loss: 0.940239]\n",
      "epoch:19 step:18031 [D loss: 0.521616, acc.: 82.03%] [G loss: 0.965318]\n",
      "epoch:19 step:18032 [D loss: 0.534384, acc.: 75.78%] [G loss: 0.980740]\n",
      "epoch:19 step:18033 [D loss: 0.305580, acc.: 84.38%] [G loss: 1.081956]\n",
      "epoch:19 step:18034 [D loss: 0.335583, acc.: 85.94%] [G loss: 1.184666]\n",
      "epoch:19 step:18035 [D loss: 0.288123, acc.: 95.31%] [G loss: 1.306598]\n",
      "epoch:19 step:18036 [D loss: 0.638982, acc.: 67.19%] [G loss: 1.364242]\n",
      "epoch:19 step:18037 [D loss: 0.443174, acc.: 85.16%] [G loss: 1.249444]\n",
      "epoch:19 step:18038 [D loss: 0.395291, acc.: 80.47%] [G loss: 1.252120]\n",
      "epoch:19 step:18039 [D loss: 0.545163, acc.: 71.88%] [G loss: 1.118641]\n",
      "epoch:19 step:18040 [D loss: 0.523559, acc.: 78.12%] [G loss: 1.300364]\n",
      "epoch:19 step:18041 [D loss: 0.494477, acc.: 76.56%] [G loss: 0.508691]\n",
      "epoch:19 step:18042 [D loss: 0.707780, acc.: 56.25%] [G loss: 1.603868]\n",
      "epoch:19 step:18043 [D loss: 0.615010, acc.: 61.72%] [G loss: 1.494723]\n",
      "epoch:19 step:18044 [D loss: 0.919665, acc.: 44.53%] [G loss: 1.063355]\n",
      "epoch:19 step:18045 [D loss: 0.899591, acc.: 35.16%] [G loss: 1.289197]\n",
      "epoch:19 step:18046 [D loss: 0.425403, acc.: 85.16%] [G loss: 1.225271]\n",
      "epoch:19 step:18047 [D loss: 0.742098, acc.: 46.88%] [G loss: 1.156142]\n",
      "epoch:19 step:18048 [D loss: 0.894641, acc.: 35.94%] [G loss: 1.076335]\n",
      "epoch:19 step:18049 [D loss: 0.826562, acc.: 41.41%] [G loss: 1.122333]\n",
      "epoch:19 step:18050 [D loss: 0.825191, acc.: 48.44%] [G loss: 0.922008]\n",
      "epoch:19 step:18051 [D loss: 0.759298, acc.: 43.75%] [G loss: 1.007859]\n",
      "epoch:19 step:18052 [D loss: 0.665610, acc.: 56.25%] [G loss: 0.976499]\n",
      "epoch:19 step:18053 [D loss: 0.692616, acc.: 45.31%] [G loss: 1.026499]\n",
      "epoch:19 step:18054 [D loss: 0.720350, acc.: 48.44%] [G loss: 1.012067]\n",
      "epoch:19 step:18055 [D loss: 0.668687, acc.: 58.59%] [G loss: 1.058838]\n",
      "epoch:19 step:18056 [D loss: 0.646630, acc.: 60.16%] [G loss: 1.149678]\n",
      "epoch:19 step:18057 [D loss: 0.699907, acc.: 48.44%] [G loss: 1.058921]\n",
      "epoch:19 step:18058 [D loss: 0.617585, acc.: 67.97%] [G loss: 1.045970]\n",
      "epoch:19 step:18059 [D loss: 0.471998, acc.: 80.47%] [G loss: 0.943852]\n",
      "epoch:19 step:18060 [D loss: 0.630065, acc.: 65.62%] [G loss: 1.056669]\n",
      "epoch:19 step:18061 [D loss: 0.601108, acc.: 69.53%] [G loss: 1.147931]\n",
      "epoch:19 step:18062 [D loss: 0.547957, acc.: 71.88%] [G loss: 0.943111]\n",
      "epoch:19 step:18063 [D loss: 0.589246, acc.: 69.53%] [G loss: 0.969789]\n",
      "epoch:19 step:18064 [D loss: 0.485662, acc.: 78.12%] [G loss: 0.827724]\n",
      "epoch:19 step:18065 [D loss: 0.712547, acc.: 52.34%] [G loss: 1.029246]\n",
      "epoch:19 step:18066 [D loss: 0.480624, acc.: 71.88%] [G loss: 0.945752]\n",
      "epoch:19 step:18067 [D loss: 0.760134, acc.: 52.34%] [G loss: 1.010394]\n",
      "epoch:19 step:18068 [D loss: 0.728910, acc.: 52.34%] [G loss: 0.959857]\n",
      "epoch:19 step:18069 [D loss: 0.711331, acc.: 51.56%] [G loss: 1.164129]\n",
      "epoch:19 step:18070 [D loss: 0.691273, acc.: 57.03%] [G loss: 1.078117]\n",
      "epoch:19 step:18071 [D loss: 0.708303, acc.: 48.44%] [G loss: 1.003054]\n",
      "epoch:19 step:18072 [D loss: 0.626866, acc.: 65.62%] [G loss: 0.885006]\n",
      "epoch:19 step:18073 [D loss: 0.641659, acc.: 58.59%] [G loss: 0.918830]\n",
      "epoch:19 step:18074 [D loss: 0.587987, acc.: 69.53%] [G loss: 1.058539]\n",
      "epoch:19 step:18075 [D loss: 0.595463, acc.: 71.88%] [G loss: 0.912839]\n",
      "epoch:19 step:18076 [D loss: 0.592535, acc.: 71.09%] [G loss: 1.013012]\n",
      "epoch:19 step:18077 [D loss: 0.562527, acc.: 79.69%] [G loss: 1.094508]\n",
      "epoch:19 step:18078 [D loss: 0.681803, acc.: 61.72%] [G loss: 0.962155]\n",
      "epoch:19 step:18079 [D loss: 0.603135, acc.: 68.75%] [G loss: 1.264704]\n",
      "epoch:19 step:18080 [D loss: 0.674183, acc.: 51.56%] [G loss: 1.061154]\n",
      "epoch:19 step:18081 [D loss: 0.793920, acc.: 38.28%] [G loss: 0.884585]\n",
      "epoch:19 step:18082 [D loss: 0.540076, acc.: 76.56%] [G loss: 0.897340]\n",
      "epoch:19 step:18083 [D loss: 0.651161, acc.: 68.75%] [G loss: 0.921590]\n",
      "epoch:19 step:18084 [D loss: 0.730020, acc.: 47.66%] [G loss: 0.891286]\n",
      "epoch:19 step:18085 [D loss: 0.668766, acc.: 58.59%] [G loss: 0.834648]\n",
      "epoch:19 step:18086 [D loss: 0.719309, acc.: 56.25%] [G loss: 0.845667]\n",
      "epoch:19 step:18087 [D loss: 0.628757, acc.: 67.19%] [G loss: 0.841682]\n",
      "epoch:19 step:18088 [D loss: 0.514387, acc.: 81.25%] [G loss: 0.875232]\n",
      "epoch:19 step:18089 [D loss: 0.485877, acc.: 82.81%] [G loss: 0.933338]\n",
      "epoch:19 step:18090 [D loss: 0.596964, acc.: 76.56%] [G loss: 0.899578]\n",
      "epoch:19 step:18091 [D loss: 0.514307, acc.: 81.25%] [G loss: 0.948794]\n",
      "epoch:19 step:18092 [D loss: 0.555037, acc.: 78.12%] [G loss: 0.922656]\n",
      "epoch:19 step:18093 [D loss: 0.506624, acc.: 82.03%] [G loss: 0.924440]\n",
      "epoch:19 step:18094 [D loss: 0.447209, acc.: 82.81%] [G loss: 0.867457]\n",
      "epoch:19 step:18095 [D loss: 0.514803, acc.: 82.03%] [G loss: 0.982200]\n",
      "epoch:19 step:18096 [D loss: 0.442833, acc.: 79.69%] [G loss: 1.099852]\n",
      "epoch:19 step:18097 [D loss: 0.577236, acc.: 69.53%] [G loss: 0.878308]\n",
      "epoch:19 step:18098 [D loss: 0.848357, acc.: 31.25%] [G loss: 0.955773]\n",
      "epoch:19 step:18099 [D loss: 0.902365, acc.: 29.69%] [G loss: 0.984163]\n",
      "epoch:19 step:18100 [D loss: 0.836916, acc.: 32.03%] [G loss: 0.715788]\n",
      "epoch:19 step:18101 [D loss: 0.779030, acc.: 39.06%] [G loss: 1.004329]\n",
      "epoch:19 step:18102 [D loss: 0.697000, acc.: 53.91%] [G loss: 1.021982]\n",
      "epoch:19 step:18103 [D loss: 0.702945, acc.: 46.09%] [G loss: 1.045957]\n",
      "epoch:19 step:18104 [D loss: 0.770881, acc.: 53.91%] [G loss: 1.048050]\n",
      "epoch:19 step:18105 [D loss: 0.695773, acc.: 57.81%] [G loss: 0.920692]\n",
      "epoch:19 step:18106 [D loss: 0.683139, acc.: 57.81%] [G loss: 0.860725]\n",
      "epoch:19 step:18107 [D loss: 0.621359, acc.: 66.41%] [G loss: 0.950681]\n",
      "epoch:19 step:18108 [D loss: 0.697346, acc.: 53.91%] [G loss: 1.031440]\n",
      "epoch:19 step:18109 [D loss: 0.652726, acc.: 63.28%] [G loss: 0.942856]\n",
      "epoch:19 step:18110 [D loss: 0.656786, acc.: 55.47%] [G loss: 0.837712]\n",
      "epoch:19 step:18111 [D loss: 0.687249, acc.: 52.34%] [G loss: 0.959392]\n",
      "epoch:19 step:18112 [D loss: 0.589183, acc.: 65.62%] [G loss: 0.785418]\n",
      "epoch:19 step:18113 [D loss: 0.668534, acc.: 59.38%] [G loss: 0.890801]\n",
      "epoch:19 step:18114 [D loss: 0.591625, acc.: 74.22%] [G loss: 0.889093]\n",
      "epoch:19 step:18115 [D loss: 0.528984, acc.: 71.88%] [G loss: 0.906597]\n",
      "epoch:19 step:18116 [D loss: 0.666175, acc.: 60.94%] [G loss: 0.760859]\n",
      "epoch:19 step:18117 [D loss: 0.472567, acc.: 75.00%] [G loss: 0.969579]\n",
      "epoch:19 step:18118 [D loss: 0.806483, acc.: 51.56%] [G loss: 1.005733]\n",
      "epoch:19 step:18119 [D loss: 0.726847, acc.: 53.12%] [G loss: 1.136191]\n",
      "epoch:19 step:18120 [D loss: 0.697938, acc.: 54.69%] [G loss: 1.065766]\n",
      "epoch:19 step:18121 [D loss: 0.654731, acc.: 59.38%] [G loss: 1.224742]\n",
      "epoch:19 step:18122 [D loss: 0.626687, acc.: 59.38%] [G loss: 0.944978]\n",
      "epoch:19 step:18123 [D loss: 0.630076, acc.: 59.38%] [G loss: 1.268964]\n",
      "epoch:19 step:18124 [D loss: 0.550522, acc.: 78.12%] [G loss: 1.090463]\n",
      "epoch:19 step:18125 [D loss: 0.517649, acc.: 78.91%] [G loss: 1.240617]\n",
      "epoch:19 step:18126 [D loss: 0.733028, acc.: 57.81%] [G loss: 1.058386]\n",
      "epoch:19 step:18127 [D loss: 0.675877, acc.: 57.81%] [G loss: 0.975468]\n",
      "epoch:19 step:18128 [D loss: 0.564676, acc.: 74.22%] [G loss: 0.926410]\n",
      "epoch:19 step:18129 [D loss: 0.637748, acc.: 64.06%] [G loss: 0.985414]\n",
      "epoch:19 step:18130 [D loss: 0.458205, acc.: 88.28%] [G loss: 0.833948]\n",
      "epoch:19 step:18131 [D loss: 0.440005, acc.: 88.28%] [G loss: 0.742159]\n",
      "epoch:19 step:18132 [D loss: 0.656087, acc.: 56.25%] [G loss: 0.926363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18133 [D loss: 0.728176, acc.: 48.44%] [G loss: 0.737577]\n",
      "epoch:19 step:18134 [D loss: 0.744751, acc.: 43.75%] [G loss: 0.627634]\n",
      "epoch:19 step:18135 [D loss: 0.818102, acc.: 33.59%] [G loss: 0.668098]\n",
      "epoch:19 step:18136 [D loss: 0.701400, acc.: 54.69%] [G loss: 0.797183]\n",
      "epoch:19 step:18137 [D loss: 0.765556, acc.: 43.75%] [G loss: 0.694588]\n",
      "epoch:19 step:18138 [D loss: 0.728632, acc.: 49.22%] [G loss: 0.824730]\n",
      "epoch:19 step:18139 [D loss: 0.720468, acc.: 47.66%] [G loss: 0.916927]\n",
      "epoch:19 step:18140 [D loss: 0.657583, acc.: 55.47%] [G loss: 0.713997]\n",
      "epoch:19 step:18141 [D loss: 0.657512, acc.: 62.50%] [G loss: 0.891695]\n",
      "epoch:19 step:18142 [D loss: 0.702409, acc.: 53.12%] [G loss: 0.777367]\n",
      "epoch:19 step:18143 [D loss: 0.661291, acc.: 53.91%] [G loss: 0.710636]\n",
      "epoch:19 step:18144 [D loss: 0.735303, acc.: 44.53%] [G loss: 0.824932]\n",
      "epoch:19 step:18145 [D loss: 0.613832, acc.: 64.84%] [G loss: 0.637362]\n",
      "epoch:19 step:18146 [D loss: 0.429549, acc.: 82.03%] [G loss: 0.920827]\n",
      "epoch:19 step:18147 [D loss: 0.454449, acc.: 85.16%] [G loss: 0.975285]\n",
      "epoch:19 step:18148 [D loss: 0.532359, acc.: 71.09%] [G loss: 1.148418]\n",
      "epoch:19 step:18149 [D loss: 0.430475, acc.: 85.94%] [G loss: 1.363724]\n",
      "epoch:19 step:18150 [D loss: 0.354651, acc.: 96.88%] [G loss: 1.164714]\n",
      "epoch:19 step:18151 [D loss: 0.728838, acc.: 53.91%] [G loss: 1.186627]\n",
      "epoch:19 step:18152 [D loss: 0.745204, acc.: 53.12%] [G loss: 1.122819]\n",
      "epoch:19 step:18153 [D loss: 0.659286, acc.: 61.72%] [G loss: 0.986557]\n",
      "epoch:19 step:18154 [D loss: 0.649321, acc.: 61.72%] [G loss: 0.984430]\n",
      "epoch:19 step:18155 [D loss: 0.619575, acc.: 66.41%] [G loss: 1.067657]\n",
      "epoch:19 step:18156 [D loss: 0.606793, acc.: 65.62%] [G loss: 0.984484]\n",
      "epoch:19 step:18157 [D loss: 0.656968, acc.: 60.16%] [G loss: 0.908864]\n",
      "epoch:19 step:18158 [D loss: 0.663152, acc.: 59.38%] [G loss: 0.909768]\n",
      "epoch:19 step:18159 [D loss: 0.652832, acc.: 59.38%] [G loss: 0.924659]\n",
      "epoch:19 step:18160 [D loss: 0.681455, acc.: 57.03%] [G loss: 0.990718]\n",
      "epoch:19 step:18161 [D loss: 0.637220, acc.: 58.59%] [G loss: 0.823732]\n",
      "epoch:19 step:18162 [D loss: 0.645938, acc.: 64.84%] [G loss: 0.932511]\n",
      "epoch:19 step:18163 [D loss: 0.592818, acc.: 64.84%] [G loss: 0.939908]\n",
      "epoch:19 step:18164 [D loss: 0.861469, acc.: 46.09%] [G loss: 1.076627]\n",
      "epoch:19 step:18165 [D loss: 0.668206, acc.: 60.16%] [G loss: 1.002432]\n",
      "epoch:19 step:18166 [D loss: 0.578460, acc.: 72.66%] [G loss: 1.131112]\n",
      "epoch:19 step:18167 [D loss: 0.646296, acc.: 56.25%] [G loss: 0.886181]\n",
      "epoch:19 step:18168 [D loss: 0.583617, acc.: 70.31%] [G loss: 1.006768]\n",
      "epoch:19 step:18169 [D loss: 0.355901, acc.: 86.72%] [G loss: 1.080621]\n",
      "epoch:19 step:18170 [D loss: 0.448250, acc.: 75.78%] [G loss: 1.086405]\n",
      "epoch:19 step:18171 [D loss: 0.696665, acc.: 59.38%] [G loss: 1.436868]\n",
      "epoch:19 step:18172 [D loss: 0.763114, acc.: 45.31%] [G loss: 0.981901]\n",
      "epoch:19 step:18173 [D loss: 0.746142, acc.: 48.44%] [G loss: 0.939308]\n",
      "epoch:19 step:18174 [D loss: 0.680236, acc.: 64.06%] [G loss: 0.854440]\n",
      "epoch:19 step:18175 [D loss: 0.693048, acc.: 53.91%] [G loss: 0.975915]\n",
      "epoch:19 step:18176 [D loss: 0.684746, acc.: 56.25%] [G loss: 0.930137]\n",
      "epoch:19 step:18177 [D loss: 0.722166, acc.: 52.34%] [G loss: 0.857527]\n",
      "epoch:19 step:18178 [D loss: 0.629607, acc.: 65.62%] [G loss: 0.998930]\n",
      "epoch:19 step:18179 [D loss: 0.633279, acc.: 64.06%] [G loss: 0.864055]\n",
      "epoch:19 step:18180 [D loss: 0.530846, acc.: 73.44%] [G loss: 1.010605]\n",
      "epoch:19 step:18181 [D loss: 0.495385, acc.: 81.25%] [G loss: 0.926133]\n",
      "epoch:19 step:18182 [D loss: 0.634267, acc.: 61.72%] [G loss: 0.969052]\n",
      "epoch:19 step:18183 [D loss: 0.598506, acc.: 65.62%] [G loss: 0.934767]\n",
      "epoch:19 step:18184 [D loss: 0.599306, acc.: 66.41%] [G loss: 0.901435]\n",
      "epoch:19 step:18185 [D loss: 0.666795, acc.: 60.94%] [G loss: 0.980087]\n",
      "epoch:19 step:18186 [D loss: 0.666224, acc.: 64.84%] [G loss: 1.084597]\n",
      "epoch:19 step:18187 [D loss: 0.603683, acc.: 64.84%] [G loss: 0.894412]\n",
      "epoch:19 step:18188 [D loss: 0.618378, acc.: 64.06%] [G loss: 0.842596]\n",
      "epoch:19 step:18189 [D loss: 0.626994, acc.: 62.50%] [G loss: 0.900302]\n",
      "epoch:19 step:18190 [D loss: 0.646940, acc.: 66.41%] [G loss: 0.781311]\n",
      "epoch:19 step:18191 [D loss: 0.697741, acc.: 60.94%] [G loss: 0.832726]\n",
      "epoch:19 step:18192 [D loss: 0.602985, acc.: 68.75%] [G loss: 0.783530]\n",
      "epoch:19 step:18193 [D loss: 0.608721, acc.: 66.41%] [G loss: 0.892008]\n",
      "epoch:19 step:18194 [D loss: 0.619138, acc.: 67.97%] [G loss: 0.872937]\n",
      "epoch:19 step:18195 [D loss: 0.631608, acc.: 64.06%] [G loss: 0.816461]\n",
      "epoch:19 step:18196 [D loss: 0.506621, acc.: 76.56%] [G loss: 0.858540]\n",
      "epoch:19 step:18197 [D loss: 0.648551, acc.: 62.50%] [G loss: 0.790703]\n",
      "epoch:19 step:18198 [D loss: 0.757076, acc.: 50.78%] [G loss: 0.648100]\n",
      "epoch:19 step:18199 [D loss: 0.397372, acc.: 78.91%] [G loss: 0.930185]\n",
      "epoch:19 step:18200 [D loss: 0.284329, acc.: 90.62%] [G loss: 1.130716]\n",
      "epoch:19 step:18201 [D loss: 0.238057, acc.: 98.44%] [G loss: 1.157255]\n",
      "epoch:19 step:18202 [D loss: 0.255334, acc.: 95.31%] [G loss: 1.147103]\n",
      "epoch:19 step:18203 [D loss: 0.311472, acc.: 97.66%] [G loss: 0.809294]\n",
      "epoch:19 step:18204 [D loss: 0.304093, acc.: 93.75%] [G loss: 1.449743]\n",
      "epoch:19 step:18205 [D loss: 0.334464, acc.: 93.75%] [G loss: 1.072607]\n",
      "epoch:19 step:18206 [D loss: 0.299680, acc.: 89.06%] [G loss: 1.261799]\n",
      "epoch:19 step:18207 [D loss: 0.317132, acc.: 86.72%] [G loss: 1.462245]\n",
      "epoch:19 step:18208 [D loss: 0.250355, acc.: 93.75%] [G loss: 1.667903]\n",
      "epoch:19 step:18209 [D loss: 0.485369, acc.: 77.34%] [G loss: 1.373785]\n",
      "epoch:19 step:18210 [D loss: 0.284396, acc.: 94.53%] [G loss: 1.734311]\n",
      "epoch:19 step:18211 [D loss: 0.588593, acc.: 71.88%] [G loss: 1.460146]\n",
      "epoch:19 step:18212 [D loss: 0.322467, acc.: 87.50%] [G loss: 0.780795]\n",
      "epoch:19 step:18213 [D loss: 0.993279, acc.: 32.03%] [G loss: 0.994897]\n",
      "epoch:19 step:18214 [D loss: 1.197923, acc.: 32.81%] [G loss: 0.734866]\n",
      "epoch:19 step:18215 [D loss: 0.918191, acc.: 39.06%] [G loss: 1.061151]\n",
      "epoch:19 step:18216 [D loss: 0.716029, acc.: 60.94%] [G loss: 0.935070]\n",
      "epoch:19 step:18217 [D loss: 0.886334, acc.: 30.47%] [G loss: 0.740466]\n",
      "epoch:19 step:18218 [D loss: 0.955068, acc.: 38.28%] [G loss: 1.053973]\n",
      "epoch:19 step:18219 [D loss: 0.940261, acc.: 31.25%] [G loss: 1.258922]\n",
      "epoch:19 step:18220 [D loss: 0.879722, acc.: 36.72%] [G loss: 1.151237]\n",
      "epoch:19 step:18221 [D loss: 0.731822, acc.: 54.69%] [G loss: 0.985053]\n",
      "epoch:19 step:18222 [D loss: 0.734851, acc.: 50.78%] [G loss: 1.093149]\n",
      "epoch:19 step:18223 [D loss: 0.846514, acc.: 35.16%] [G loss: 1.111013]\n",
      "epoch:19 step:18224 [D loss: 0.778600, acc.: 42.19%] [G loss: 1.033108]\n",
      "epoch:19 step:18225 [D loss: 0.721555, acc.: 50.78%] [G loss: 1.107194]\n",
      "epoch:19 step:18226 [D loss: 0.723892, acc.: 52.34%] [G loss: 1.017985]\n",
      "epoch:19 step:18227 [D loss: 0.707368, acc.: 53.12%] [G loss: 0.994836]\n",
      "epoch:19 step:18228 [D loss: 0.711777, acc.: 52.34%] [G loss: 0.992036]\n",
      "epoch:19 step:18229 [D loss: 0.737547, acc.: 41.41%] [G loss: 1.100297]\n",
      "epoch:19 step:18230 [D loss: 0.707111, acc.: 49.22%] [G loss: 1.025451]\n",
      "epoch:19 step:18231 [D loss: 0.711955, acc.: 52.34%] [G loss: 0.890435]\n",
      "epoch:19 step:18232 [D loss: 0.695096, acc.: 50.78%] [G loss: 1.061317]\n",
      "epoch:19 step:18233 [D loss: 0.688247, acc.: 56.25%] [G loss: 1.069768]\n",
      "epoch:19 step:18234 [D loss: 0.688930, acc.: 52.34%] [G loss: 1.048592]\n",
      "epoch:19 step:18235 [D loss: 0.584687, acc.: 69.53%] [G loss: 1.167147]\n",
      "epoch:19 step:18236 [D loss: 0.596063, acc.: 65.62%] [G loss: 1.025472]\n",
      "epoch:19 step:18237 [D loss: 0.642064, acc.: 63.28%] [G loss: 1.071180]\n",
      "epoch:19 step:18238 [D loss: 0.618196, acc.: 63.28%] [G loss: 1.233913]\n",
      "epoch:19 step:18239 [D loss: 0.548643, acc.: 75.00%] [G loss: 1.198994]\n",
      "epoch:19 step:18240 [D loss: 0.626479, acc.: 63.28%] [G loss: 1.109272]\n",
      "epoch:19 step:18241 [D loss: 0.693746, acc.: 56.25%] [G loss: 1.030787]\n",
      "epoch:19 step:18242 [D loss: 0.641206, acc.: 60.16%] [G loss: 1.134347]\n",
      "epoch:19 step:18243 [D loss: 0.709648, acc.: 54.69%] [G loss: 0.983568]\n",
      "epoch:19 step:18244 [D loss: 0.690775, acc.: 60.16%] [G loss: 0.911902]\n",
      "epoch:19 step:18245 [D loss: 0.646359, acc.: 58.59%] [G loss: 0.971520]\n",
      "epoch:19 step:18246 [D loss: 0.565162, acc.: 78.91%] [G loss: 1.057489]\n",
      "epoch:19 step:18247 [D loss: 0.618921, acc.: 71.88%] [G loss: 0.920394]\n",
      "epoch:19 step:18248 [D loss: 0.662492, acc.: 59.38%] [G loss: 1.022209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18249 [D loss: 0.649357, acc.: 60.16%] [G loss: 0.837617]\n",
      "epoch:19 step:18250 [D loss: 0.687872, acc.: 52.34%] [G loss: 0.771716]\n",
      "epoch:19 step:18251 [D loss: 0.542105, acc.: 78.91%] [G loss: 0.943117]\n",
      "epoch:19 step:18252 [D loss: 0.490096, acc.: 85.16%] [G loss: 0.899430]\n",
      "epoch:19 step:18253 [D loss: 0.514909, acc.: 82.81%] [G loss: 1.358767]\n",
      "epoch:19 step:18254 [D loss: 0.454012, acc.: 89.84%] [G loss: 0.995565]\n",
      "epoch:19 step:18255 [D loss: 0.463933, acc.: 85.94%] [G loss: 1.003135]\n",
      "epoch:19 step:18256 [D loss: 0.460580, acc.: 91.41%] [G loss: 1.326579]\n",
      "epoch:19 step:18257 [D loss: 0.521010, acc.: 79.69%] [G loss: 0.955338]\n",
      "epoch:19 step:18258 [D loss: 0.487584, acc.: 75.00%] [G loss: 0.813016]\n",
      "epoch:19 step:18259 [D loss: 0.421234, acc.: 79.69%] [G loss: 0.994492]\n",
      "epoch:19 step:18260 [D loss: 0.584307, acc.: 67.19%] [G loss: 1.215770]\n",
      "epoch:19 step:18261 [D loss: 0.629931, acc.: 61.72%] [G loss: 0.812378]\n",
      "epoch:19 step:18262 [D loss: 0.739844, acc.: 49.22%] [G loss: 0.981618]\n",
      "epoch:19 step:18263 [D loss: 0.755101, acc.: 52.34%] [G loss: 0.905391]\n",
      "epoch:19 step:18264 [D loss: 1.075812, acc.: 17.97%] [G loss: 0.893855]\n",
      "epoch:19 step:18265 [D loss: 0.971730, acc.: 33.59%] [G loss: 0.909779]\n",
      "epoch:19 step:18266 [D loss: 0.699356, acc.: 53.91%] [G loss: 0.768100]\n",
      "epoch:19 step:18267 [D loss: 0.697728, acc.: 50.78%] [G loss: 0.754160]\n",
      "epoch:19 step:18268 [D loss: 0.639150, acc.: 60.16%] [G loss: 0.760483]\n",
      "epoch:19 step:18269 [D loss: 0.661968, acc.: 66.41%] [G loss: 0.798396]\n",
      "epoch:19 step:18270 [D loss: 0.628285, acc.: 60.94%] [G loss: 0.858133]\n",
      "epoch:19 step:18271 [D loss: 0.526957, acc.: 75.00%] [G loss: 0.837441]\n",
      "epoch:19 step:18272 [D loss: 0.559167, acc.: 71.88%] [G loss: 0.854108]\n",
      "epoch:19 step:18273 [D loss: 0.444334, acc.: 85.94%] [G loss: 1.051886]\n",
      "epoch:19 step:18274 [D loss: 0.501616, acc.: 77.34%] [G loss: 1.096816]\n",
      "epoch:19 step:18275 [D loss: 0.604277, acc.: 66.41%] [G loss: 1.113648]\n",
      "epoch:19 step:18276 [D loss: 0.721161, acc.: 53.91%] [G loss: 1.223515]\n",
      "epoch:19 step:18277 [D loss: 0.753896, acc.: 47.66%] [G loss: 1.151718]\n",
      "epoch:19 step:18278 [D loss: 0.663699, acc.: 60.16%] [G loss: 1.155973]\n",
      "epoch:19 step:18279 [D loss: 0.674173, acc.: 67.19%] [G loss: 0.954730]\n",
      "epoch:19 step:18280 [D loss: 0.684838, acc.: 62.50%] [G loss: 0.886104]\n",
      "epoch:19 step:18281 [D loss: 0.664081, acc.: 65.62%] [G loss: 0.971673]\n",
      "epoch:19 step:18282 [D loss: 0.631421, acc.: 61.72%] [G loss: 0.942765]\n",
      "epoch:19 step:18283 [D loss: 0.710282, acc.: 55.47%] [G loss: 0.938824]\n",
      "epoch:19 step:18284 [D loss: 0.768973, acc.: 50.78%] [G loss: 1.063613]\n",
      "epoch:19 step:18285 [D loss: 0.636567, acc.: 64.06%] [G loss: 1.064051]\n",
      "epoch:19 step:18286 [D loss: 0.570032, acc.: 70.31%] [G loss: 1.096935]\n",
      "epoch:19 step:18287 [D loss: 0.498248, acc.: 78.12%] [G loss: 1.195630]\n",
      "epoch:19 step:18288 [D loss: 0.518301, acc.: 81.25%] [G loss: 1.451921]\n",
      "epoch:19 step:18289 [D loss: 0.559491, acc.: 73.44%] [G loss: 1.080014]\n",
      "epoch:19 step:18290 [D loss: 0.580863, acc.: 68.75%] [G loss: 1.174241]\n",
      "epoch:19 step:18291 [D loss: 0.529852, acc.: 74.22%] [G loss: 1.165816]\n",
      "epoch:19 step:18292 [D loss: 0.694161, acc.: 65.62%] [G loss: 0.970683]\n",
      "epoch:19 step:18293 [D loss: 0.685269, acc.: 57.81%] [G loss: 0.997544]\n",
      "epoch:19 step:18294 [D loss: 0.709052, acc.: 53.91%] [G loss: 1.023147]\n",
      "epoch:19 step:18295 [D loss: 0.591637, acc.: 68.75%] [G loss: 0.909035]\n",
      "epoch:19 step:18296 [D loss: 0.595514, acc.: 73.44%] [G loss: 0.994353]\n",
      "epoch:19 step:18297 [D loss: 0.695832, acc.: 58.59%] [G loss: 0.922847]\n",
      "epoch:19 step:18298 [D loss: 0.657471, acc.: 60.16%] [G loss: 0.944169]\n",
      "epoch:19 step:18299 [D loss: 0.653332, acc.: 67.19%] [G loss: 0.911050]\n",
      "epoch:19 step:18300 [D loss: 0.459561, acc.: 85.16%] [G loss: 0.991241]\n",
      "epoch:19 step:18301 [D loss: 0.508452, acc.: 67.97%] [G loss: 0.954264]\n",
      "epoch:19 step:18302 [D loss: 0.372494, acc.: 85.94%] [G loss: 0.949861]\n",
      "epoch:19 step:18303 [D loss: 0.675449, acc.: 57.81%] [G loss: 1.193255]\n",
      "epoch:19 step:18304 [D loss: 0.637390, acc.: 62.50%] [G loss: 1.051242]\n",
      "epoch:19 step:18305 [D loss: 0.492472, acc.: 78.12%] [G loss: 0.972373]\n",
      "epoch:19 step:18306 [D loss: 0.909223, acc.: 34.38%] [G loss: 0.944994]\n",
      "epoch:19 step:18307 [D loss: 0.741539, acc.: 54.69%] [G loss: 0.974188]\n",
      "epoch:19 step:18308 [D loss: 0.552548, acc.: 72.66%] [G loss: 0.981863]\n",
      "epoch:19 step:18309 [D loss: 0.661537, acc.: 60.16%] [G loss: 0.963006]\n",
      "epoch:19 step:18310 [D loss: 0.565364, acc.: 73.44%] [G loss: 0.961299]\n",
      "epoch:19 step:18311 [D loss: 0.562568, acc.: 70.31%] [G loss: 1.050568]\n",
      "epoch:19 step:18312 [D loss: 0.681067, acc.: 50.78%] [G loss: 0.991117]\n",
      "epoch:19 step:18313 [D loss: 0.661303, acc.: 63.28%] [G loss: 1.011755]\n",
      "epoch:19 step:18314 [D loss: 0.593654, acc.: 63.28%] [G loss: 0.991172]\n",
      "epoch:19 step:18315 [D loss: 0.663550, acc.: 60.94%] [G loss: 1.030856]\n",
      "epoch:19 step:18316 [D loss: 0.507430, acc.: 78.91%] [G loss: 0.957387]\n",
      "epoch:19 step:18317 [D loss: 0.456876, acc.: 82.81%] [G loss: 1.026121]\n",
      "epoch:19 step:18318 [D loss: 0.460534, acc.: 80.47%] [G loss: 1.106580]\n",
      "epoch:19 step:18319 [D loss: 0.726033, acc.: 54.69%] [G loss: 1.038692]\n",
      "epoch:19 step:18320 [D loss: 0.536145, acc.: 70.31%] [G loss: 1.014742]\n",
      "epoch:19 step:18321 [D loss: 0.613484, acc.: 66.41%] [G loss: 1.085441]\n",
      "epoch:19 step:18322 [D loss: 0.599826, acc.: 66.41%] [G loss: 1.129005]\n",
      "epoch:19 step:18323 [D loss: 0.471375, acc.: 81.25%] [G loss: 1.184893]\n",
      "epoch:19 step:18324 [D loss: 0.663863, acc.: 63.28%] [G loss: 1.078905]\n",
      "epoch:19 step:18325 [D loss: 0.620879, acc.: 67.19%] [G loss: 1.166336]\n",
      "epoch:19 step:18326 [D loss: 0.701615, acc.: 52.34%] [G loss: 1.043577]\n",
      "epoch:19 step:18327 [D loss: 0.579450, acc.: 76.56%] [G loss: 1.105220]\n",
      "epoch:19 step:18328 [D loss: 0.614339, acc.: 66.41%] [G loss: 1.093669]\n",
      "epoch:19 step:18329 [D loss: 0.653240, acc.: 63.28%] [G loss: 1.015658]\n",
      "epoch:19 step:18330 [D loss: 0.666699, acc.: 58.59%] [G loss: 1.018002]\n",
      "epoch:19 step:18331 [D loss: 0.747885, acc.: 50.78%] [G loss: 0.889598]\n",
      "epoch:19 step:18332 [D loss: 0.721896, acc.: 51.56%] [G loss: 0.928553]\n",
      "epoch:19 step:18333 [D loss: 0.526210, acc.: 73.44%] [G loss: 0.884008]\n",
      "epoch:19 step:18334 [D loss: 0.764345, acc.: 45.31%] [G loss: 0.884856]\n",
      "epoch:19 step:18335 [D loss: 0.594907, acc.: 70.31%] [G loss: 1.013494]\n",
      "epoch:19 step:18336 [D loss: 0.593430, acc.: 66.41%] [G loss: 0.988733]\n",
      "epoch:19 step:18337 [D loss: 0.601160, acc.: 60.16%] [G loss: 1.144158]\n",
      "epoch:19 step:18338 [D loss: 0.597882, acc.: 71.09%] [G loss: 0.863026]\n",
      "epoch:19 step:18339 [D loss: 0.579911, acc.: 73.44%] [G loss: 1.067081]\n",
      "epoch:19 step:18340 [D loss: 0.684251, acc.: 57.03%] [G loss: 1.028223]\n",
      "epoch:19 step:18341 [D loss: 0.639082, acc.: 66.41%] [G loss: 0.763164]\n",
      "epoch:19 step:18342 [D loss: 0.769333, acc.: 50.78%] [G loss: 0.930930]\n",
      "epoch:19 step:18343 [D loss: 0.588148, acc.: 67.19%] [G loss: 0.971918]\n",
      "epoch:19 step:18344 [D loss: 0.655391, acc.: 66.41%] [G loss: 0.693880]\n",
      "epoch:19 step:18345 [D loss: 0.540564, acc.: 80.47%] [G loss: 0.971867]\n",
      "epoch:19 step:18346 [D loss: 0.343790, acc.: 89.06%] [G loss: 1.119668]\n",
      "epoch:19 step:18347 [D loss: 0.699636, acc.: 54.69%] [G loss: 0.979354]\n",
      "epoch:19 step:18348 [D loss: 0.520496, acc.: 75.78%] [G loss: 1.013473]\n",
      "epoch:19 step:18349 [D loss: 0.654906, acc.: 63.28%] [G loss: 1.043938]\n",
      "epoch:19 step:18350 [D loss: 0.597852, acc.: 65.62%] [G loss: 1.050761]\n",
      "epoch:19 step:18351 [D loss: 0.445112, acc.: 87.50%] [G loss: 1.060982]\n",
      "epoch:19 step:18352 [D loss: 0.402136, acc.: 92.19%] [G loss: 1.043466]\n",
      "epoch:19 step:18353 [D loss: 0.320743, acc.: 91.41%] [G loss: 1.272452]\n",
      "epoch:19 step:18354 [D loss: 0.389670, acc.: 91.41%] [G loss: 1.250535]\n",
      "epoch:19 step:18355 [D loss: 0.497712, acc.: 81.25%] [G loss: 1.369968]\n",
      "epoch:19 step:18356 [D loss: 0.628860, acc.: 64.84%] [G loss: 1.047839]\n",
      "epoch:19 step:18357 [D loss: 0.258708, acc.: 96.09%] [G loss: 1.010729]\n",
      "epoch:19 step:18358 [D loss: 0.439593, acc.: 85.16%] [G loss: 0.812697]\n",
      "epoch:19 step:18359 [D loss: 0.415790, acc.: 80.47%] [G loss: 0.885861]\n",
      "epoch:19 step:18360 [D loss: 0.479902, acc.: 76.56%] [G loss: 1.575527]\n",
      "epoch:19 step:18361 [D loss: 0.459971, acc.: 88.28%] [G loss: 1.670861]\n",
      "epoch:19 step:18362 [D loss: 0.837260, acc.: 47.66%] [G loss: 1.243852]\n",
      "epoch:19 step:18363 [D loss: 0.970395, acc.: 32.03%] [G loss: 1.055449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18364 [D loss: 0.659330, acc.: 57.03%] [G loss: 1.083322]\n",
      "epoch:19 step:18365 [D loss: 0.939397, acc.: 35.16%] [G loss: 1.165877]\n",
      "epoch:19 step:18366 [D loss: 0.742578, acc.: 50.00%] [G loss: 1.028749]\n",
      "epoch:19 step:18367 [D loss: 0.656406, acc.: 60.94%] [G loss: 0.735847]\n",
      "epoch:19 step:18368 [D loss: 0.705304, acc.: 52.34%] [G loss: 1.232650]\n",
      "epoch:19 step:18369 [D loss: 0.385697, acc.: 79.69%] [G loss: 1.118737]\n",
      "epoch:19 step:18370 [D loss: 0.298233, acc.: 89.06%] [G loss: 1.247537]\n",
      "epoch:19 step:18371 [D loss: 0.530541, acc.: 78.91%] [G loss: 1.162132]\n",
      "epoch:19 step:18372 [D loss: 0.631399, acc.: 62.50%] [G loss: 1.164568]\n",
      "epoch:19 step:18373 [D loss: 0.529467, acc.: 77.34%] [G loss: 1.330986]\n",
      "epoch:19 step:18374 [D loss: 0.682682, acc.: 68.75%] [G loss: 1.062589]\n",
      "epoch:19 step:18375 [D loss: 0.577604, acc.: 67.97%] [G loss: 1.042523]\n",
      "epoch:19 step:18376 [D loss: 0.527272, acc.: 75.00%] [G loss: 1.110873]\n",
      "epoch:19 step:18377 [D loss: 0.541436, acc.: 73.44%] [G loss: 1.200145]\n",
      "epoch:19 step:18378 [D loss: 0.453975, acc.: 82.03%] [G loss: 1.232627]\n",
      "epoch:19 step:18379 [D loss: 0.469601, acc.: 73.44%] [G loss: 1.086389]\n",
      "epoch:19 step:18380 [D loss: 0.393228, acc.: 87.50%] [G loss: 1.531822]\n",
      "epoch:19 step:18381 [D loss: 0.439016, acc.: 75.78%] [G loss: 1.737684]\n",
      "epoch:19 step:18382 [D loss: 0.403922, acc.: 75.78%] [G loss: 1.508569]\n",
      "epoch:19 step:18383 [D loss: 0.855135, acc.: 46.88%] [G loss: 1.330505]\n",
      "epoch:19 step:18384 [D loss: 0.691058, acc.: 59.38%] [G loss: 1.700500]\n",
      "epoch:19 step:18385 [D loss: 0.860695, acc.: 46.09%] [G loss: 1.550942]\n",
      "epoch:19 step:18386 [D loss: 0.864502, acc.: 40.62%] [G loss: 1.496617]\n",
      "epoch:19 step:18387 [D loss: 0.886871, acc.: 42.19%] [G loss: 1.088675]\n",
      "epoch:19 step:18388 [D loss: 0.655359, acc.: 59.38%] [G loss: 1.006905]\n",
      "epoch:19 step:18389 [D loss: 0.754193, acc.: 53.12%] [G loss: 1.181711]\n",
      "epoch:19 step:18390 [D loss: 0.493954, acc.: 68.75%] [G loss: 1.250486]\n",
      "epoch:19 step:18391 [D loss: 0.388763, acc.: 87.50%] [G loss: 1.856407]\n",
      "epoch:19 step:18392 [D loss: 0.340824, acc.: 89.06%] [G loss: 1.474637]\n",
      "epoch:19 step:18393 [D loss: 0.725648, acc.: 60.16%] [G loss: 1.118869]\n",
      "epoch:19 step:18394 [D loss: 0.822237, acc.: 48.44%] [G loss: 1.542978]\n",
      "epoch:19 step:18395 [D loss: 0.625327, acc.: 66.41%] [G loss: 1.196046]\n",
      "epoch:19 step:18396 [D loss: 0.647669, acc.: 61.72%] [G loss: 1.098407]\n",
      "epoch:19 step:18397 [D loss: 0.641975, acc.: 62.50%] [G loss: 1.073542]\n",
      "epoch:19 step:18398 [D loss: 0.479164, acc.: 78.91%] [G loss: 1.173427]\n",
      "epoch:19 step:18399 [D loss: 0.645035, acc.: 67.19%] [G loss: 0.962418]\n",
      "epoch:19 step:18400 [D loss: 0.764149, acc.: 53.12%] [G loss: 1.055134]\n",
      "epoch:19 step:18401 [D loss: 0.669057, acc.: 60.94%] [G loss: 0.898757]\n",
      "epoch:19 step:18402 [D loss: 0.748981, acc.: 44.53%] [G loss: 1.047910]\n",
      "epoch:19 step:18403 [D loss: 0.498467, acc.: 78.91%] [G loss: 1.021132]\n",
      "epoch:19 step:18404 [D loss: 0.422541, acc.: 83.59%] [G loss: 1.106519]\n",
      "epoch:19 step:18405 [D loss: 0.633432, acc.: 60.94%] [G loss: 1.041419]\n",
      "epoch:19 step:18406 [D loss: 0.732520, acc.: 48.44%] [G loss: 1.014834]\n",
      "epoch:19 step:18407 [D loss: 0.515233, acc.: 70.31%] [G loss: 1.313949]\n",
      "epoch:19 step:18408 [D loss: 0.607673, acc.: 59.38%] [G loss: 1.269271]\n",
      "epoch:19 step:18409 [D loss: 0.594004, acc.: 68.75%] [G loss: 1.291670]\n",
      "epoch:19 step:18410 [D loss: 0.628849, acc.: 65.62%] [G loss: 1.296805]\n",
      "epoch:19 step:18411 [D loss: 0.614268, acc.: 67.97%] [G loss: 1.053245]\n",
      "epoch:19 step:18412 [D loss: 0.510068, acc.: 79.69%] [G loss: 1.056172]\n",
      "epoch:19 step:18413 [D loss: 0.554736, acc.: 71.88%] [G loss: 1.014644]\n",
      "epoch:19 step:18414 [D loss: 0.569674, acc.: 71.09%] [G loss: 1.037926]\n",
      "epoch:19 step:18415 [D loss: 0.662104, acc.: 57.03%] [G loss: 1.003659]\n",
      "epoch:19 step:18416 [D loss: 0.482645, acc.: 82.03%] [G loss: 0.950063]\n",
      "epoch:19 step:18417 [D loss: 0.589530, acc.: 66.41%] [G loss: 0.904972]\n",
      "epoch:19 step:18418 [D loss: 0.580638, acc.: 72.66%] [G loss: 0.968130]\n",
      "epoch:19 step:18419 [D loss: 0.451981, acc.: 86.72%] [G loss: 1.475384]\n",
      "epoch:19 step:18420 [D loss: 0.494530, acc.: 78.12%] [G loss: 1.370286]\n",
      "epoch:19 step:18421 [D loss: 0.704906, acc.: 57.81%] [G loss: 0.947093]\n",
      "epoch:19 step:18422 [D loss: 0.688481, acc.: 56.25%] [G loss: 1.142327]\n",
      "epoch:19 step:18423 [D loss: 0.664321, acc.: 52.34%] [G loss: 0.732598]\n",
      "epoch:19 step:18424 [D loss: 0.640204, acc.: 64.84%] [G loss: 0.925439]\n",
      "epoch:19 step:18425 [D loss: 0.516573, acc.: 79.69%] [G loss: 1.087471]\n",
      "epoch:19 step:18426 [D loss: 0.468865, acc.: 89.06%] [G loss: 1.383680]\n",
      "epoch:19 step:18427 [D loss: 0.551309, acc.: 70.31%] [G loss: 1.161188]\n",
      "epoch:19 step:18428 [D loss: 0.732794, acc.: 53.12%] [G loss: 0.837736]\n",
      "epoch:19 step:18429 [D loss: 0.582135, acc.: 67.97%] [G loss: 1.256397]\n",
      "epoch:19 step:18430 [D loss: 0.713760, acc.: 51.56%] [G loss: 1.084853]\n",
      "epoch:19 step:18431 [D loss: 0.750383, acc.: 53.12%] [G loss: 1.035015]\n",
      "epoch:19 step:18432 [D loss: 0.682822, acc.: 62.50%] [G loss: 1.236587]\n",
      "epoch:19 step:18433 [D loss: 0.589132, acc.: 67.19%] [G loss: 0.799621]\n",
      "epoch:19 step:18434 [D loss: 0.726637, acc.: 53.91%] [G loss: 1.156725]\n",
      "epoch:19 step:18435 [D loss: 0.662063, acc.: 64.06%] [G loss: 0.942446]\n",
      "epoch:19 step:18436 [D loss: 0.513664, acc.: 68.75%] [G loss: 1.112508]\n",
      "epoch:19 step:18437 [D loss: 0.465520, acc.: 83.59%] [G loss: 1.139978]\n",
      "epoch:19 step:18438 [D loss: 0.574283, acc.: 66.41%] [G loss: 0.940574]\n",
      "epoch:19 step:18439 [D loss: 0.749654, acc.: 56.25%] [G loss: 1.143228]\n",
      "epoch:19 step:18440 [D loss: 0.667111, acc.: 57.03%] [G loss: 0.741837]\n",
      "epoch:19 step:18441 [D loss: 0.885506, acc.: 35.16%] [G loss: 1.020019]\n",
      "epoch:19 step:18442 [D loss: 0.837550, acc.: 39.84%] [G loss: 1.022065]\n",
      "epoch:19 step:18443 [D loss: 0.730247, acc.: 50.78%] [G loss: 1.107361]\n",
      "epoch:19 step:18444 [D loss: 0.750796, acc.: 43.75%] [G loss: 0.994804]\n",
      "epoch:19 step:18445 [D loss: 0.659902, acc.: 53.12%] [G loss: 0.964317]\n",
      "epoch:19 step:18446 [D loss: 0.727296, acc.: 60.94%] [G loss: 1.334918]\n",
      "epoch:19 step:18447 [D loss: 0.757477, acc.: 61.72%] [G loss: 0.918019]\n",
      "epoch:19 step:18448 [D loss: 0.609840, acc.: 67.97%] [G loss: 1.036713]\n",
      "epoch:19 step:18449 [D loss: 0.644022, acc.: 57.81%] [G loss: 0.946359]\n",
      "epoch:19 step:18450 [D loss: 0.553725, acc.: 76.56%] [G loss: 1.013058]\n",
      "epoch:19 step:18451 [D loss: 0.594998, acc.: 66.41%] [G loss: 1.166288]\n",
      "epoch:19 step:18452 [D loss: 0.595873, acc.: 74.22%] [G loss: 0.949107]\n",
      "epoch:19 step:18453 [D loss: 0.647758, acc.: 60.94%] [G loss: 0.920370]\n",
      "epoch:19 step:18454 [D loss: 0.599710, acc.: 68.75%] [G loss: 1.356388]\n",
      "epoch:19 step:18455 [D loss: 0.666730, acc.: 55.47%] [G loss: 1.115351]\n",
      "epoch:19 step:18456 [D loss: 0.564398, acc.: 71.88%] [G loss: 1.067090]\n",
      "epoch:19 step:18457 [D loss: 0.535573, acc.: 82.03%] [G loss: 1.240254]\n",
      "epoch:19 step:18458 [D loss: 0.594301, acc.: 75.78%] [G loss: 1.096453]\n",
      "epoch:19 step:18459 [D loss: 0.686506, acc.: 55.47%] [G loss: 0.972297]\n",
      "epoch:19 step:18460 [D loss: 0.662398, acc.: 58.59%] [G loss: 1.078201]\n",
      "epoch:19 step:18461 [D loss: 0.642993, acc.: 59.38%] [G loss: 1.208848]\n",
      "epoch:19 step:18462 [D loss: 0.660610, acc.: 59.38%] [G loss: 0.972277]\n",
      "epoch:19 step:18463 [D loss: 0.548791, acc.: 77.34%] [G loss: 1.012736]\n",
      "epoch:19 step:18464 [D loss: 0.585962, acc.: 71.88%] [G loss: 0.939396]\n",
      "epoch:19 step:18465 [D loss: 0.608843, acc.: 65.62%] [G loss: 0.921881]\n",
      "epoch:19 step:18466 [D loss: 0.434286, acc.: 78.12%] [G loss: 1.015308]\n",
      "epoch:19 step:18467 [D loss: 0.420964, acc.: 88.28%] [G loss: 1.155882]\n",
      "epoch:19 step:18468 [D loss: 0.391694, acc.: 81.25%] [G loss: 1.254968]\n",
      "epoch:19 step:18469 [D loss: 0.481623, acc.: 80.47%] [G loss: 1.246412]\n",
      "epoch:19 step:18470 [D loss: 0.564019, acc.: 71.88%] [G loss: 1.809983]\n",
      "epoch:19 step:18471 [D loss: 0.659816, acc.: 61.72%] [G loss: 1.060465]\n",
      "epoch:19 step:18472 [D loss: 0.623200, acc.: 63.28%] [G loss: 1.141401]\n",
      "epoch:19 step:18473 [D loss: 0.565299, acc.: 72.66%] [G loss: 0.985058]\n",
      "epoch:19 step:18474 [D loss: 0.484463, acc.: 77.34%] [G loss: 1.014818]\n",
      "epoch:19 step:18475 [D loss: 0.605336, acc.: 63.28%] [G loss: 0.833660]\n",
      "epoch:19 step:18476 [D loss: 0.568469, acc.: 71.09%] [G loss: 1.062246]\n",
      "epoch:19 step:18477 [D loss: 0.585923, acc.: 65.62%] [G loss: 0.825858]\n",
      "epoch:19 step:18478 [D loss: 0.679783, acc.: 53.91%] [G loss: 0.711046]\n",
      "epoch:19 step:18479 [D loss: 0.795607, acc.: 50.00%] [G loss: 0.770234]\n",
      "epoch:19 step:18480 [D loss: 0.642076, acc.: 60.16%] [G loss: 0.827157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18481 [D loss: 0.656273, acc.: 58.59%] [G loss: 0.734999]\n",
      "epoch:19 step:18482 [D loss: 0.702578, acc.: 53.91%] [G loss: 0.912531]\n",
      "epoch:19 step:18483 [D loss: 0.673611, acc.: 56.25%] [G loss: 1.183501]\n",
      "epoch:19 step:18484 [D loss: 0.523817, acc.: 75.78%] [G loss: 0.957935]\n",
      "epoch:19 step:18485 [D loss: 0.667211, acc.: 60.16%] [G loss: 1.313973]\n",
      "epoch:19 step:18486 [D loss: 0.665599, acc.: 60.94%] [G loss: 1.087713]\n",
      "epoch:19 step:18487 [D loss: 0.728236, acc.: 53.12%] [G loss: 1.111995]\n",
      "epoch:19 step:18488 [D loss: 0.550328, acc.: 65.62%] [G loss: 0.996767]\n",
      "epoch:19 step:18489 [D loss: 0.655111, acc.: 64.06%] [G loss: 1.000233]\n",
      "epoch:19 step:18490 [D loss: 0.604216, acc.: 64.84%] [G loss: 0.809432]\n",
      "epoch:19 step:18491 [D loss: 0.575408, acc.: 68.75%] [G loss: 1.091127]\n",
      "epoch:19 step:18492 [D loss: 0.544656, acc.: 73.44%] [G loss: 1.426091]\n",
      "epoch:19 step:18493 [D loss: 0.563827, acc.: 73.44%] [G loss: 0.952992]\n",
      "epoch:19 step:18494 [D loss: 0.507900, acc.: 82.03%] [G loss: 1.105089]\n",
      "epoch:19 step:18495 [D loss: 0.530793, acc.: 78.91%] [G loss: 1.081991]\n",
      "epoch:19 step:18496 [D loss: 0.559420, acc.: 74.22%] [G loss: 0.863225]\n",
      "epoch:19 step:18497 [D loss: 0.498437, acc.: 77.34%] [G loss: 1.304112]\n",
      "epoch:19 step:18498 [D loss: 0.729910, acc.: 53.91%] [G loss: 0.667706]\n",
      "epoch:19 step:18499 [D loss: 0.644961, acc.: 60.94%] [G loss: 1.188007]\n",
      "epoch:19 step:18500 [D loss: 0.479927, acc.: 78.12%] [G loss: 1.097809]\n",
      "epoch:19 step:18501 [D loss: 0.630703, acc.: 67.19%] [G loss: 1.047901]\n",
      "epoch:19 step:18502 [D loss: 0.704337, acc.: 56.25%] [G loss: 0.919905]\n",
      "epoch:19 step:18503 [D loss: 0.722768, acc.: 52.34%] [G loss: 0.917312]\n",
      "epoch:19 step:18504 [D loss: 0.487260, acc.: 81.25%] [G loss: 1.003375]\n",
      "epoch:19 step:18505 [D loss: 0.563373, acc.: 67.97%] [G loss: 1.064463]\n",
      "epoch:19 step:18506 [D loss: 0.652861, acc.: 61.72%] [G loss: 1.139479]\n",
      "epoch:19 step:18507 [D loss: 0.571436, acc.: 70.31%] [G loss: 0.926923]\n",
      "epoch:19 step:18508 [D loss: 0.748523, acc.: 48.44%] [G loss: 1.096522]\n",
      "epoch:19 step:18509 [D loss: 0.471436, acc.: 83.59%] [G loss: 0.957699]\n",
      "epoch:19 step:18510 [D loss: 0.526989, acc.: 78.12%] [G loss: 1.012464]\n",
      "epoch:19 step:18511 [D loss: 0.716165, acc.: 60.94%] [G loss: 0.855559]\n",
      "epoch:19 step:18512 [D loss: 0.377600, acc.: 83.59%] [G loss: 1.010149]\n",
      "epoch:19 step:18513 [D loss: 0.819048, acc.: 44.53%] [G loss: 1.375524]\n",
      "epoch:19 step:18514 [D loss: 0.677714, acc.: 57.81%] [G loss: 1.560545]\n",
      "epoch:19 step:18515 [D loss: 0.674359, acc.: 59.38%] [G loss: 1.369783]\n",
      "epoch:19 step:18516 [D loss: 0.608007, acc.: 68.75%] [G loss: 1.144188]\n",
      "epoch:19 step:18517 [D loss: 0.481457, acc.: 78.91%] [G loss: 1.073193]\n",
      "epoch:19 step:18518 [D loss: 0.745586, acc.: 52.34%] [G loss: 0.760435]\n",
      "epoch:19 step:18519 [D loss: 0.740615, acc.: 54.69%] [G loss: 1.161495]\n",
      "epoch:19 step:18520 [D loss: 0.689960, acc.: 56.25%] [G loss: 1.093523]\n",
      "epoch:19 step:18521 [D loss: 0.777500, acc.: 50.78%] [G loss: 1.154835]\n",
      "epoch:19 step:18522 [D loss: 0.677884, acc.: 52.34%] [G loss: 1.183447]\n",
      "epoch:19 step:18523 [D loss: 0.509049, acc.: 80.47%] [G loss: 1.366003]\n",
      "epoch:19 step:18524 [D loss: 0.556053, acc.: 76.56%] [G loss: 1.354738]\n",
      "epoch:19 step:18525 [D loss: 0.764596, acc.: 59.38%] [G loss: 1.163141]\n",
      "epoch:19 step:18526 [D loss: 0.693001, acc.: 58.59%] [G loss: 1.092244]\n",
      "epoch:19 step:18527 [D loss: 0.516211, acc.: 78.12%] [G loss: 1.117074]\n",
      "epoch:19 step:18528 [D loss: 0.441894, acc.: 86.72%] [G loss: 1.417129]\n",
      "epoch:19 step:18529 [D loss: 0.457672, acc.: 88.28%] [G loss: 1.200203]\n",
      "epoch:19 step:18530 [D loss: 0.711451, acc.: 60.94%] [G loss: 1.049472]\n",
      "epoch:19 step:18531 [D loss: 0.741697, acc.: 51.56%] [G loss: 0.959220]\n",
      "epoch:19 step:18532 [D loss: 0.729548, acc.: 51.56%] [G loss: 1.197846]\n",
      "epoch:19 step:18533 [D loss: 0.712042, acc.: 55.47%] [G loss: 0.917200]\n",
      "epoch:19 step:18534 [D loss: 0.696320, acc.: 57.81%] [G loss: 0.853630]\n",
      "epoch:19 step:18535 [D loss: 0.690868, acc.: 56.25%] [G loss: 0.859840]\n",
      "epoch:19 step:18536 [D loss: 0.638747, acc.: 65.62%] [G loss: 0.990783]\n",
      "epoch:19 step:18537 [D loss: 0.676342, acc.: 54.69%] [G loss: 1.184241]\n",
      "epoch:19 step:18538 [D loss: 0.497781, acc.: 79.69%] [G loss: 1.027496]\n",
      "epoch:19 step:18539 [D loss: 0.469190, acc.: 79.69%] [G loss: 1.219615]\n",
      "epoch:19 step:18540 [D loss: 0.538161, acc.: 68.75%] [G loss: 1.173992]\n",
      "epoch:19 step:18541 [D loss: 0.585240, acc.: 67.19%] [G loss: 1.151288]\n",
      "epoch:19 step:18542 [D loss: 0.762618, acc.: 49.22%] [G loss: 0.995100]\n",
      "epoch:19 step:18543 [D loss: 0.741672, acc.: 48.44%] [G loss: 0.879568]\n",
      "epoch:19 step:18544 [D loss: 0.476557, acc.: 86.72%] [G loss: 1.167862]\n",
      "epoch:19 step:18545 [D loss: 0.461266, acc.: 82.81%] [G loss: 0.773525]\n",
      "epoch:19 step:18546 [D loss: 0.398680, acc.: 89.84%] [G loss: 1.100354]\n",
      "epoch:19 step:18547 [D loss: 0.511012, acc.: 77.34%] [G loss: 1.109759]\n",
      "epoch:19 step:18548 [D loss: 0.679104, acc.: 63.28%] [G loss: 1.137543]\n",
      "epoch:19 step:18549 [D loss: 0.759372, acc.: 49.22%] [G loss: 1.149734]\n",
      "epoch:19 step:18550 [D loss: 0.731373, acc.: 53.91%] [G loss: 0.858674]\n",
      "epoch:19 step:18551 [D loss: 0.687107, acc.: 57.03%] [G loss: 0.805993]\n",
      "epoch:19 step:18552 [D loss: 0.591621, acc.: 68.75%] [G loss: 0.951141]\n",
      "epoch:19 step:18553 [D loss: 0.587528, acc.: 72.66%] [G loss: 1.512250]\n",
      "epoch:19 step:18554 [D loss: 0.701944, acc.: 59.38%] [G loss: 1.012259]\n",
      "epoch:19 step:18555 [D loss: 0.763298, acc.: 47.66%] [G loss: 1.044116]\n",
      "epoch:19 step:18556 [D loss: 0.725986, acc.: 51.56%] [G loss: 1.058297]\n",
      "epoch:19 step:18557 [D loss: 0.569848, acc.: 71.09%] [G loss: 0.737808]\n",
      "epoch:19 step:18558 [D loss: 0.484789, acc.: 78.12%] [G loss: 0.855732]\n",
      "epoch:19 step:18559 [D loss: 0.490073, acc.: 78.91%] [G loss: 0.969877]\n",
      "epoch:19 step:18560 [D loss: 0.581077, acc.: 70.31%] [G loss: 0.867202]\n",
      "epoch:19 step:18561 [D loss: 0.731940, acc.: 54.69%] [G loss: 0.815757]\n",
      "epoch:19 step:18562 [D loss: 0.764638, acc.: 47.66%] [G loss: 0.898250]\n",
      "epoch:19 step:18563 [D loss: 0.682886, acc.: 60.16%] [G loss: 0.833345]\n",
      "epoch:19 step:18564 [D loss: 0.708643, acc.: 52.34%] [G loss: 0.869377]\n",
      "epoch:19 step:18565 [D loss: 0.635213, acc.: 64.84%] [G loss: 0.879030]\n",
      "epoch:19 step:18566 [D loss: 0.608512, acc.: 66.41%] [G loss: 0.862689]\n",
      "epoch:19 step:18567 [D loss: 0.584706, acc.: 65.62%] [G loss: 0.948313]\n",
      "epoch:19 step:18568 [D loss: 0.748623, acc.: 50.78%] [G loss: 0.838396]\n",
      "epoch:19 step:18569 [D loss: 0.711582, acc.: 58.59%] [G loss: 0.889649]\n",
      "epoch:19 step:18570 [D loss: 0.647286, acc.: 62.50%] [G loss: 0.896078]\n",
      "epoch:19 step:18571 [D loss: 0.626710, acc.: 63.28%] [G loss: 0.860689]\n",
      "epoch:19 step:18572 [D loss: 0.589626, acc.: 67.97%] [G loss: 0.928050]\n",
      "epoch:19 step:18573 [D loss: 0.706447, acc.: 50.00%] [G loss: 0.920133]\n",
      "epoch:19 step:18574 [D loss: 0.642924, acc.: 60.94%] [G loss: 0.926188]\n",
      "epoch:19 step:18575 [D loss: 0.707174, acc.: 52.34%] [G loss: 0.869759]\n",
      "epoch:19 step:18576 [D loss: 0.668289, acc.: 60.16%] [G loss: 0.868149]\n",
      "epoch:19 step:18577 [D loss: 0.542465, acc.: 73.44%] [G loss: 0.954783]\n",
      "epoch:19 step:18578 [D loss: 0.515471, acc.: 77.34%] [G loss: 0.984781]\n",
      "epoch:19 step:18579 [D loss: 0.692173, acc.: 55.47%] [G loss: 0.895683]\n",
      "epoch:19 step:18580 [D loss: 0.602791, acc.: 68.75%] [G loss: 0.989184]\n",
      "epoch:19 step:18581 [D loss: 0.689301, acc.: 52.34%] [G loss: 1.034478]\n",
      "epoch:19 step:18582 [D loss: 0.550287, acc.: 72.66%] [G loss: 0.971612]\n",
      "epoch:19 step:18583 [D loss: 0.557899, acc.: 68.75%] [G loss: 0.876700]\n",
      "epoch:19 step:18584 [D loss: 0.426740, acc.: 75.78%] [G loss: 0.977077]\n",
      "epoch:19 step:18585 [D loss: 0.631624, acc.: 70.31%] [G loss: 0.969341]\n",
      "epoch:19 step:18586 [D loss: 0.694773, acc.: 56.25%] [G loss: 1.049241]\n",
      "epoch:19 step:18587 [D loss: 0.713836, acc.: 51.56%] [G loss: 0.946195]\n",
      "epoch:19 step:18588 [D loss: 0.598081, acc.: 71.88%] [G loss: 0.954095]\n",
      "epoch:19 step:18589 [D loss: 0.483569, acc.: 85.16%] [G loss: 1.034087]\n",
      "epoch:19 step:18590 [D loss: 0.750656, acc.: 47.66%] [G loss: 1.054289]\n",
      "epoch:19 step:18591 [D loss: 0.654917, acc.: 62.50%] [G loss: 1.132840]\n",
      "epoch:19 step:18592 [D loss: 0.827106, acc.: 39.84%] [G loss: 0.882012]\n",
      "epoch:19 step:18593 [D loss: 0.696501, acc.: 57.03%] [G loss: 1.041642]\n",
      "epoch:19 step:18594 [D loss: 0.473036, acc.: 83.59%] [G loss: 0.909780]\n",
      "epoch:19 step:18595 [D loss: 0.325751, acc.: 93.75%] [G loss: 1.054132]\n",
      "epoch:19 step:18596 [D loss: 0.434889, acc.: 80.47%] [G loss: 0.877325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18597 [D loss: 0.360214, acc.: 92.19%] [G loss: 1.025500]\n",
      "epoch:19 step:18598 [D loss: 0.554914, acc.: 78.91%] [G loss: 1.214574]\n",
      "epoch:19 step:18599 [D loss: 0.360250, acc.: 93.75%] [G loss: 1.243606]\n",
      "epoch:19 step:18600 [D loss: 0.854925, acc.: 49.22%] [G loss: 1.271297]\n",
      "epoch:19 step:18601 [D loss: 0.504454, acc.: 82.03%] [G loss: 1.160715]\n",
      "epoch:19 step:18602 [D loss: 0.763757, acc.: 50.00%] [G loss: 0.971523]\n",
      "epoch:19 step:18603 [D loss: 0.811845, acc.: 47.66%] [G loss: 1.009040]\n",
      "epoch:19 step:18604 [D loss: 0.566300, acc.: 67.19%] [G loss: 1.029367]\n",
      "epoch:19 step:18605 [D loss: 0.310017, acc.: 90.62%] [G loss: 1.368872]\n",
      "epoch:19 step:18606 [D loss: 0.681900, acc.: 57.81%] [G loss: 1.166986]\n",
      "epoch:19 step:18607 [D loss: 0.572516, acc.: 73.44%] [G loss: 1.383110]\n",
      "epoch:19 step:18608 [D loss: 0.751811, acc.: 52.34%] [G loss: 1.225707]\n",
      "epoch:19 step:18609 [D loss: 0.463542, acc.: 79.69%] [G loss: 0.911618]\n",
      "epoch:19 step:18610 [D loss: 0.693507, acc.: 50.78%] [G loss: 1.207826]\n",
      "epoch:19 step:18611 [D loss: 0.494278, acc.: 78.12%] [G loss: 1.272111]\n",
      "epoch:19 step:18612 [D loss: 0.596502, acc.: 66.41%] [G loss: 1.194170]\n",
      "epoch:19 step:18613 [D loss: 0.437765, acc.: 85.16%] [G loss: 1.419628]\n",
      "epoch:19 step:18614 [D loss: 0.727741, acc.: 52.34%] [G loss: 1.337782]\n",
      "epoch:19 step:18615 [D loss: 0.625744, acc.: 60.94%] [G loss: 1.341488]\n",
      "epoch:19 step:18616 [D loss: 0.477083, acc.: 77.34%] [G loss: 1.314507]\n",
      "epoch:19 step:18617 [D loss: 0.494628, acc.: 72.66%] [G loss: 1.307730]\n",
      "epoch:19 step:18618 [D loss: 0.252692, acc.: 94.53%] [G loss: 1.509515]\n",
      "epoch:19 step:18619 [D loss: 0.281499, acc.: 94.53%] [G loss: 1.488657]\n",
      "epoch:19 step:18620 [D loss: 0.453602, acc.: 79.69%] [G loss: 1.478117]\n",
      "epoch:19 step:18621 [D loss: 0.381380, acc.: 85.16%] [G loss: 1.444289]\n",
      "epoch:19 step:18622 [D loss: 0.309681, acc.: 92.19%] [G loss: 0.847014]\n",
      "epoch:19 step:18623 [D loss: 0.789109, acc.: 43.75%] [G loss: 0.704126]\n",
      "epoch:19 step:18624 [D loss: 0.939892, acc.: 42.19%] [G loss: 1.211252]\n",
      "epoch:19 step:18625 [D loss: 0.714066, acc.: 56.25%] [G loss: 1.220314]\n",
      "epoch:19 step:18626 [D loss: 0.464302, acc.: 79.69%] [G loss: 1.164029]\n",
      "epoch:19 step:18627 [D loss: 0.485521, acc.: 77.34%] [G loss: 1.369383]\n",
      "epoch:19 step:18628 [D loss: 0.713357, acc.: 56.25%] [G loss: 1.414615]\n",
      "epoch:19 step:18629 [D loss: 0.663640, acc.: 65.62%] [G loss: 1.506320]\n",
      "epoch:19 step:18630 [D loss: 0.708220, acc.: 53.12%] [G loss: 1.354799]\n",
      "epoch:19 step:18631 [D loss: 0.716707, acc.: 47.66%] [G loss: 0.645659]\n",
      "epoch:19 step:18632 [D loss: 0.625395, acc.: 66.41%] [G loss: 0.889371]\n",
      "epoch:19 step:18633 [D loss: 0.428952, acc.: 85.94%] [G loss: 1.084646]\n",
      "epoch:19 step:18634 [D loss: 0.407357, acc.: 83.59%] [G loss: 1.000432]\n",
      "epoch:19 step:18635 [D loss: 0.524914, acc.: 66.41%] [G loss: 1.160056]\n",
      "epoch:19 step:18636 [D loss: 0.504889, acc.: 78.12%] [G loss: 1.454124]\n",
      "epoch:19 step:18637 [D loss: 1.197681, acc.: 40.62%] [G loss: 0.956591]\n",
      "epoch:19 step:18638 [D loss: 1.188116, acc.: 24.22%] [G loss: 1.161438]\n",
      "epoch:19 step:18639 [D loss: 0.817132, acc.: 44.53%] [G loss: 0.991638]\n",
      "epoch:19 step:18640 [D loss: 0.764975, acc.: 52.34%] [G loss: 0.927306]\n",
      "epoch:19 step:18641 [D loss: 0.640451, acc.: 68.75%] [G loss: 0.893801]\n",
      "epoch:19 step:18642 [D loss: 0.692420, acc.: 57.03%] [G loss: 0.852566]\n",
      "epoch:19 step:18643 [D loss: 0.658880, acc.: 64.84%] [G loss: 0.987895]\n",
      "epoch:19 step:18644 [D loss: 0.693518, acc.: 54.69%] [G loss: 0.974042]\n",
      "epoch:19 step:18645 [D loss: 0.642842, acc.: 63.28%] [G loss: 0.926458]\n",
      "epoch:19 step:18646 [D loss: 0.688346, acc.: 52.34%] [G loss: 0.833715]\n",
      "epoch:19 step:18647 [D loss: 0.547078, acc.: 74.22%] [G loss: 0.924515]\n",
      "epoch:19 step:18648 [D loss: 0.526943, acc.: 75.78%] [G loss: 0.784554]\n",
      "epoch:19 step:18649 [D loss: 0.671793, acc.: 63.28%] [G loss: 0.813077]\n",
      "epoch:19 step:18650 [D loss: 0.719225, acc.: 46.88%] [G loss: 0.911651]\n",
      "epoch:19 step:18651 [D loss: 0.769828, acc.: 39.84%] [G loss: 0.853916]\n",
      "epoch:19 step:18652 [D loss: 0.776717, acc.: 50.78%] [G loss: 0.917557]\n",
      "epoch:19 step:18653 [D loss: 0.739162, acc.: 42.97%] [G loss: 0.961870]\n",
      "epoch:19 step:18654 [D loss: 0.627386, acc.: 64.06%] [G loss: 0.924194]\n",
      "epoch:19 step:18655 [D loss: 0.569285, acc.: 66.41%] [G loss: 0.953923]\n",
      "epoch:19 step:18656 [D loss: 0.574675, acc.: 71.09%] [G loss: 0.994815]\n",
      "epoch:19 step:18657 [D loss: 0.535087, acc.: 72.66%] [G loss: 1.045942]\n",
      "epoch:19 step:18658 [D loss: 0.644070, acc.: 65.62%] [G loss: 1.104228]\n",
      "epoch:19 step:18659 [D loss: 0.732094, acc.: 60.94%] [G loss: 0.930757]\n",
      "epoch:19 step:18660 [D loss: 0.574859, acc.: 70.31%] [G loss: 1.011756]\n",
      "epoch:19 step:18661 [D loss: 0.799217, acc.: 45.31%] [G loss: 0.903583]\n",
      "epoch:19 step:18662 [D loss: 0.684025, acc.: 57.03%] [G loss: 0.836356]\n",
      "epoch:19 step:18663 [D loss: 0.634375, acc.: 64.06%] [G loss: 0.932441]\n",
      "epoch:19 step:18664 [D loss: 0.682082, acc.: 60.16%] [G loss: 0.840720]\n",
      "epoch:19 step:18665 [D loss: 0.652221, acc.: 64.84%] [G loss: 0.920174]\n",
      "epoch:19 step:18666 [D loss: 0.625293, acc.: 60.94%] [G loss: 0.876041]\n",
      "epoch:19 step:18667 [D loss: 0.656333, acc.: 55.47%] [G loss: 0.783971]\n",
      "epoch:19 step:18668 [D loss: 0.660127, acc.: 57.03%] [G loss: 0.963632]\n",
      "epoch:19 step:18669 [D loss: 0.619299, acc.: 66.41%] [G loss: 0.897700]\n",
      "epoch:19 step:18670 [D loss: 0.679355, acc.: 56.25%] [G loss: 0.836178]\n",
      "epoch:19 step:18671 [D loss: 0.663494, acc.: 60.16%] [G loss: 0.905645]\n",
      "epoch:19 step:18672 [D loss: 0.647966, acc.: 59.38%] [G loss: 0.890149]\n",
      "epoch:19 step:18673 [D loss: 0.662550, acc.: 58.59%] [G loss: 0.832041]\n",
      "epoch:19 step:18674 [D loss: 0.617228, acc.: 64.84%] [G loss: 0.895059]\n",
      "epoch:19 step:18675 [D loss: 0.665679, acc.: 62.50%] [G loss: 0.820492]\n",
      "epoch:19 step:18676 [D loss: 0.629080, acc.: 65.62%] [G loss: 0.872286]\n",
      "epoch:19 step:18677 [D loss: 0.656797, acc.: 64.06%] [G loss: 0.846141]\n",
      "epoch:19 step:18678 [D loss: 0.591946, acc.: 69.53%] [G loss: 0.884230]\n",
      "epoch:19 step:18679 [D loss: 0.659952, acc.: 60.16%] [G loss: 0.999370]\n",
      "epoch:19 step:18680 [D loss: 0.618781, acc.: 67.19%] [G loss: 0.779706]\n",
      "epoch:19 step:18681 [D loss: 0.679667, acc.: 55.47%] [G loss: 0.857520]\n",
      "epoch:19 step:18682 [D loss: 0.630752, acc.: 65.62%] [G loss: 0.865021]\n",
      "epoch:19 step:18683 [D loss: 0.645617, acc.: 59.38%] [G loss: 0.807744]\n",
      "epoch:19 step:18684 [D loss: 0.633867, acc.: 62.50%] [G loss: 0.992922]\n",
      "epoch:19 step:18685 [D loss: 0.510412, acc.: 78.91%] [G loss: 0.912472]\n",
      "epoch:19 step:18686 [D loss: 0.548001, acc.: 71.88%] [G loss: 0.921940]\n",
      "epoch:19 step:18687 [D loss: 0.478002, acc.: 79.69%] [G loss: 0.903866]\n",
      "epoch:19 step:18688 [D loss: 0.373796, acc.: 84.38%] [G loss: 0.909232]\n",
      "epoch:19 step:18689 [D loss: 0.476445, acc.: 75.00%] [G loss: 1.062667]\n",
      "epoch:19 step:18690 [D loss: 0.308401, acc.: 90.62%] [G loss: 1.282845]\n",
      "epoch:19 step:18691 [D loss: 0.610714, acc.: 67.97%] [G loss: 1.208683]\n",
      "epoch:19 step:18692 [D loss: 0.376920, acc.: 86.72%] [G loss: 1.181814]\n",
      "epoch:19 step:18693 [D loss: 0.566895, acc.: 71.09%] [G loss: 1.091386]\n",
      "epoch:19 step:18694 [D loss: 0.820628, acc.: 38.28%] [G loss: 1.116013]\n",
      "epoch:19 step:18695 [D loss: 0.768077, acc.: 53.12%] [G loss: 1.036235]\n",
      "epoch:19 step:18696 [D loss: 0.795244, acc.: 39.84%] [G loss: 0.936990]\n",
      "epoch:19 step:18697 [D loss: 0.884454, acc.: 37.50%] [G loss: 0.932756]\n",
      "epoch:19 step:18698 [D loss: 0.786450, acc.: 48.44%] [G loss: 0.997519]\n",
      "epoch:19 step:18699 [D loss: 0.712876, acc.: 53.91%] [G loss: 0.937118]\n",
      "epoch:19 step:18700 [D loss: 0.622628, acc.: 63.28%] [G loss: 1.119606]\n",
      "epoch:19 step:18701 [D loss: 0.615170, acc.: 61.72%] [G loss: 1.008113]\n",
      "epoch:19 step:18702 [D loss: 0.452602, acc.: 83.59%] [G loss: 1.060052]\n",
      "epoch:19 step:18703 [D loss: 0.562659, acc.: 75.78%] [G loss: 1.154517]\n",
      "epoch:19 step:18704 [D loss: 0.622671, acc.: 64.84%] [G loss: 0.937511]\n",
      "epoch:19 step:18705 [D loss: 0.669284, acc.: 60.94%] [G loss: 0.965709]\n",
      "epoch:19 step:18706 [D loss: 0.703308, acc.: 51.56%] [G loss: 1.209012]\n",
      "epoch:19 step:18707 [D loss: 0.573053, acc.: 73.44%] [G loss: 0.976966]\n",
      "epoch:19 step:18708 [D loss: 0.483670, acc.: 79.69%] [G loss: 0.713261]\n",
      "epoch:19 step:18709 [D loss: 0.402524, acc.: 92.97%] [G loss: 1.108458]\n",
      "epoch:19 step:18710 [D loss: 0.678508, acc.: 57.03%] [G loss: 1.054980]\n",
      "epoch:19 step:18711 [D loss: 0.748448, acc.: 49.22%] [G loss: 0.991797]\n",
      "epoch:19 step:18712 [D loss: 0.705699, acc.: 53.91%] [G loss: 0.801475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18713 [D loss: 0.538378, acc.: 80.47%] [G loss: 0.967734]\n",
      "epoch:19 step:18714 [D loss: 0.652183, acc.: 60.94%] [G loss: 0.943820]\n",
      "epoch:19 step:18715 [D loss: 0.303259, acc.: 90.62%] [G loss: 0.989388]\n",
      "epoch:19 step:18716 [D loss: 0.687870, acc.: 57.03%] [G loss: 1.084031]\n",
      "epoch:19 step:18717 [D loss: 0.669183, acc.: 62.50%] [G loss: 1.015045]\n",
      "epoch:19 step:18718 [D loss: 0.779273, acc.: 44.53%] [G loss: 0.992398]\n",
      "epoch:19 step:18719 [D loss: 0.658600, acc.: 67.19%] [G loss: 0.938092]\n",
      "epoch:19 step:18720 [D loss: 0.595746, acc.: 64.84%] [G loss: 0.921835]\n",
      "epoch:19 step:18721 [D loss: 0.654410, acc.: 59.38%] [G loss: 0.915107]\n",
      "epoch:19 step:18722 [D loss: 0.604129, acc.: 64.84%] [G loss: 1.029876]\n",
      "epoch:19 step:18723 [D loss: 0.451232, acc.: 82.03%] [G loss: 1.071001]\n",
      "epoch:19 step:18724 [D loss: 0.468605, acc.: 81.25%] [G loss: 0.901842]\n",
      "epoch:19 step:18725 [D loss: 0.658582, acc.: 59.38%] [G loss: 0.947872]\n",
      "epoch:19 step:18726 [D loss: 0.679342, acc.: 55.47%] [G loss: 0.961552]\n",
      "epoch:19 step:18727 [D loss: 0.512474, acc.: 80.47%] [G loss: 0.761406]\n",
      "epoch:19 step:18728 [D loss: 0.506109, acc.: 79.69%] [G loss: 1.037840]\n",
      "epoch:19 step:18729 [D loss: 0.505054, acc.: 72.66%] [G loss: 1.127364]\n",
      "epoch:19 step:18730 [D loss: 0.310393, acc.: 84.38%] [G loss: 1.300626]\n",
      "epoch:19 step:18731 [D loss: 0.741165, acc.: 54.69%] [G loss: 1.163453]\n",
      "epoch:19 step:18732 [D loss: 0.314873, acc.: 89.84%] [G loss: 1.273390]\n",
      "epoch:19 step:18733 [D loss: 0.591378, acc.: 67.19%] [G loss: 0.876097]\n",
      "epoch:19 step:18734 [D loss: 0.575059, acc.: 72.66%] [G loss: 1.113387]\n",
      "epoch:19 step:18735 [D loss: 0.573241, acc.: 74.22%] [G loss: 1.014400]\n",
      "epoch:19 step:18736 [D loss: 0.394686, acc.: 88.28%] [G loss: 1.021917]\n",
      "epoch:19 step:18737 [D loss: 0.349362, acc.: 88.28%] [G loss: 1.218381]\n",
      "epoch:19 step:18738 [D loss: 0.425268, acc.: 87.50%] [G loss: 1.011241]\n",
      "epoch:19 step:18739 [D loss: 0.396444, acc.: 80.47%] [G loss: 1.411780]\n",
      "epoch:19 step:18740 [D loss: 0.210746, acc.: 93.75%] [G loss: 1.478583]\n",
      "epoch:20 step:18741 [D loss: 0.734145, acc.: 59.38%] [G loss: 1.492299]\n",
      "epoch:20 step:18742 [D loss: 0.785167, acc.: 50.78%] [G loss: 1.232822]\n",
      "epoch:20 step:18743 [D loss: 0.674718, acc.: 59.38%] [G loss: 1.157249]\n",
      "epoch:20 step:18744 [D loss: 0.761270, acc.: 50.78%] [G loss: 1.198884]\n",
      "epoch:20 step:18745 [D loss: 0.676392, acc.: 60.16%] [G loss: 0.872322]\n",
      "epoch:20 step:18746 [D loss: 0.799491, acc.: 44.53%] [G loss: 1.042257]\n",
      "epoch:20 step:18747 [D loss: 0.569096, acc.: 73.44%] [G loss: 1.064849]\n",
      "epoch:20 step:18748 [D loss: 0.617421, acc.: 61.72%] [G loss: 0.977452]\n",
      "epoch:20 step:18749 [D loss: 0.465265, acc.: 80.47%] [G loss: 1.031319]\n",
      "epoch:20 step:18750 [D loss: 0.881286, acc.: 59.38%] [G loss: 1.716755]\n",
      "epoch:20 step:18751 [D loss: 0.545834, acc.: 71.88%] [G loss: 2.700926]\n",
      "epoch:20 step:18752 [D loss: 0.540001, acc.: 76.56%] [G loss: 1.320391]\n",
      "epoch:20 step:18753 [D loss: 0.632069, acc.: 68.75%] [G loss: 0.965789]\n",
      "epoch:20 step:18754 [D loss: 0.628725, acc.: 67.19%] [G loss: 1.229935]\n",
      "epoch:20 step:18755 [D loss: 0.497080, acc.: 78.91%] [G loss: 0.782932]\n",
      "epoch:20 step:18756 [D loss: 0.563906, acc.: 71.88%] [G loss: 1.085355]\n",
      "epoch:20 step:18757 [D loss: 0.660121, acc.: 56.25%] [G loss: 1.120899]\n",
      "epoch:20 step:18758 [D loss: 0.688027, acc.: 56.25%] [G loss: 0.792163]\n",
      "epoch:20 step:18759 [D loss: 0.662715, acc.: 62.50%] [G loss: 0.477180]\n",
      "epoch:20 step:18760 [D loss: 0.852948, acc.: 43.75%] [G loss: 0.654372]\n",
      "epoch:20 step:18761 [D loss: 0.722888, acc.: 55.47%] [G loss: 0.779883]\n",
      "epoch:20 step:18762 [D loss: 0.796197, acc.: 43.75%] [G loss: 0.706985]\n",
      "epoch:20 step:18763 [D loss: 0.601932, acc.: 70.31%] [G loss: 0.755420]\n",
      "epoch:20 step:18764 [D loss: 0.698376, acc.: 53.12%] [G loss: 0.897401]\n",
      "epoch:20 step:18765 [D loss: 0.589327, acc.: 67.19%] [G loss: 1.321833]\n",
      "epoch:20 step:18766 [D loss: 0.782508, acc.: 42.19%] [G loss: 1.183438]\n",
      "epoch:20 step:18767 [D loss: 0.712874, acc.: 52.34%] [G loss: 1.183575]\n",
      "epoch:20 step:18768 [D loss: 0.780981, acc.: 46.88%] [G loss: 0.991284]\n",
      "epoch:20 step:18769 [D loss: 0.650499, acc.: 58.59%] [G loss: 1.256912]\n",
      "epoch:20 step:18770 [D loss: 0.615123, acc.: 67.97%] [G loss: 1.129212]\n",
      "epoch:20 step:18771 [D loss: 0.619843, acc.: 60.94%] [G loss: 1.290115]\n",
      "epoch:20 step:18772 [D loss: 0.522207, acc.: 82.03%] [G loss: 1.238058]\n",
      "epoch:20 step:18773 [D loss: 0.485467, acc.: 80.47%] [G loss: 1.696463]\n",
      "epoch:20 step:18774 [D loss: 0.386017, acc.: 91.41%] [G loss: 1.365758]\n",
      "epoch:20 step:18775 [D loss: 0.290085, acc.: 92.97%] [G loss: 1.524130]\n",
      "epoch:20 step:18776 [D loss: 0.234196, acc.: 94.53%] [G loss: 1.429142]\n",
      "epoch:20 step:18777 [D loss: 0.615586, acc.: 60.94%] [G loss: 1.326102]\n",
      "epoch:20 step:18778 [D loss: 0.848176, acc.: 51.56%] [G loss: 1.020131]\n",
      "epoch:20 step:18779 [D loss: 0.804394, acc.: 53.12%] [G loss: 0.863960]\n",
      "epoch:20 step:18780 [D loss: 0.809572, acc.: 46.09%] [G loss: 0.757537]\n",
      "epoch:20 step:18781 [D loss: 0.608133, acc.: 66.41%] [G loss: 0.836305]\n",
      "epoch:20 step:18782 [D loss: 0.602026, acc.: 66.41%] [G loss: 0.944581]\n",
      "epoch:20 step:18783 [D loss: 0.501817, acc.: 75.00%] [G loss: 0.834122]\n",
      "epoch:20 step:18784 [D loss: 0.550853, acc.: 69.53%] [G loss: 0.943904]\n",
      "epoch:20 step:18785 [D loss: 0.584601, acc.: 70.31%] [G loss: 1.037385]\n",
      "epoch:20 step:18786 [D loss: 0.587673, acc.: 67.19%] [G loss: 0.910916]\n",
      "epoch:20 step:18787 [D loss: 0.658483, acc.: 59.38%] [G loss: 0.893874]\n",
      "epoch:20 step:18788 [D loss: 0.658169, acc.: 60.16%] [G loss: 0.936173]\n",
      "epoch:20 step:18789 [D loss: 0.687099, acc.: 53.12%] [G loss: 0.866166]\n",
      "epoch:20 step:18790 [D loss: 0.627213, acc.: 60.94%] [G loss: 0.774157]\n",
      "epoch:20 step:18791 [D loss: 0.640342, acc.: 66.41%] [G loss: 0.982358]\n",
      "epoch:20 step:18792 [D loss: 0.627346, acc.: 67.97%] [G loss: 0.860315]\n",
      "epoch:20 step:18793 [D loss: 0.632671, acc.: 61.72%] [G loss: 0.960672]\n",
      "epoch:20 step:18794 [D loss: 0.692567, acc.: 58.59%] [G loss: 0.697248]\n",
      "epoch:20 step:18795 [D loss: 0.675609, acc.: 57.81%] [G loss: 0.894528]\n",
      "epoch:20 step:18796 [D loss: 0.593036, acc.: 70.31%] [G loss: 0.906392]\n",
      "epoch:20 step:18797 [D loss: 0.402698, acc.: 89.06%] [G loss: 0.873736]\n",
      "epoch:20 step:18798 [D loss: 0.579866, acc.: 71.09%] [G loss: 0.765081]\n",
      "epoch:20 step:18799 [D loss: 0.498117, acc.: 78.12%] [G loss: 1.314546]\n",
      "epoch:20 step:18800 [D loss: 0.585209, acc.: 63.28%] [G loss: 1.188777]\n",
      "epoch:20 step:18801 [D loss: 0.654676, acc.: 60.94%] [G loss: 1.153768]\n",
      "epoch:20 step:18802 [D loss: 0.671295, acc.: 60.16%] [G loss: 1.022307]\n",
      "epoch:20 step:18803 [D loss: 0.553751, acc.: 76.56%] [G loss: 0.710273]\n",
      "epoch:20 step:18804 [D loss: 0.780531, acc.: 45.31%] [G loss: 0.530719]\n",
      "epoch:20 step:18805 [D loss: 0.852689, acc.: 36.72%] [G loss: 0.497965]\n",
      "epoch:20 step:18806 [D loss: 0.808605, acc.: 40.62%] [G loss: 1.040484]\n",
      "epoch:20 step:18807 [D loss: 0.852800, acc.: 42.19%] [G loss: 1.180534]\n",
      "epoch:20 step:18808 [D loss: 0.698515, acc.: 60.94%] [G loss: 1.140372]\n",
      "epoch:20 step:18809 [D loss: 0.682222, acc.: 60.16%] [G loss: 1.080009]\n",
      "epoch:20 step:18810 [D loss: 0.686774, acc.: 57.03%] [G loss: 0.953869]\n",
      "epoch:20 step:18811 [D loss: 0.494740, acc.: 81.25%] [G loss: 0.980603]\n",
      "epoch:20 step:18812 [D loss: 0.450713, acc.: 87.50%] [G loss: 0.943872]\n",
      "epoch:20 step:18813 [D loss: 0.590166, acc.: 70.31%] [G loss: 0.895603]\n",
      "epoch:20 step:18814 [D loss: 0.595514, acc.: 68.75%] [G loss: 1.022739]\n",
      "epoch:20 step:18815 [D loss: 0.545747, acc.: 75.00%] [G loss: 0.916083]\n",
      "epoch:20 step:18816 [D loss: 0.430900, acc.: 85.16%] [G loss: 1.014381]\n",
      "epoch:20 step:18817 [D loss: 0.598372, acc.: 70.31%] [G loss: 1.232724]\n",
      "epoch:20 step:18818 [D loss: 0.730595, acc.: 54.69%] [G loss: 1.000218]\n",
      "epoch:20 step:18819 [D loss: 0.755098, acc.: 55.47%] [G loss: 1.002553]\n",
      "epoch:20 step:18820 [D loss: 0.662471, acc.: 59.38%] [G loss: 0.837029]\n",
      "epoch:20 step:18821 [D loss: 0.637027, acc.: 60.16%] [G loss: 0.906628]\n",
      "epoch:20 step:18822 [D loss: 0.693703, acc.: 55.47%] [G loss: 0.955116]\n",
      "epoch:20 step:18823 [D loss: 0.569464, acc.: 70.31%] [G loss: 1.037520]\n",
      "epoch:20 step:18824 [D loss: 0.595043, acc.: 73.44%] [G loss: 1.232694]\n",
      "epoch:20 step:18825 [D loss: 0.460040, acc.: 81.25%] [G loss: 1.075177]\n",
      "epoch:20 step:18826 [D loss: 0.682667, acc.: 62.50%] [G loss: 0.890133]\n",
      "epoch:20 step:18827 [D loss: 0.568302, acc.: 71.88%] [G loss: 1.075123]\n",
      "epoch:20 step:18828 [D loss: 0.476588, acc.: 85.16%] [G loss: 1.165781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18829 [D loss: 0.514111, acc.: 83.59%] [G loss: 0.888565]\n",
      "epoch:20 step:18830 [D loss: 0.642272, acc.: 62.50%] [G loss: 0.930896]\n",
      "epoch:20 step:18831 [D loss: 0.576550, acc.: 68.75%] [G loss: 0.864779]\n",
      "epoch:20 step:18832 [D loss: 0.602063, acc.: 64.84%] [G loss: 0.738517]\n",
      "epoch:20 step:18833 [D loss: 0.551837, acc.: 64.84%] [G loss: 1.009685]\n",
      "epoch:20 step:18834 [D loss: 0.549744, acc.: 75.78%] [G loss: 1.177492]\n",
      "epoch:20 step:18835 [D loss: 0.718101, acc.: 53.12%] [G loss: 0.891101]\n",
      "epoch:20 step:18836 [D loss: 0.714541, acc.: 56.25%] [G loss: 1.184226]\n",
      "epoch:20 step:18837 [D loss: 0.785922, acc.: 42.19%] [G loss: 0.898966]\n",
      "epoch:20 step:18838 [D loss: 0.815224, acc.: 49.22%] [G loss: 1.027361]\n",
      "epoch:20 step:18839 [D loss: 0.706369, acc.: 50.00%] [G loss: 1.076329]\n",
      "epoch:20 step:18840 [D loss: 0.719697, acc.: 49.22%] [G loss: 0.899389]\n",
      "epoch:20 step:18841 [D loss: 0.662778, acc.: 64.06%] [G loss: 0.930217]\n",
      "epoch:20 step:18842 [D loss: 0.727109, acc.: 53.91%] [G loss: 0.927815]\n",
      "epoch:20 step:18843 [D loss: 0.674774, acc.: 60.16%] [G loss: 1.571648]\n",
      "epoch:20 step:18844 [D loss: 0.734856, acc.: 46.88%] [G loss: 1.024835]\n",
      "epoch:20 step:18845 [D loss: 0.659057, acc.: 65.62%] [G loss: 0.918368]\n",
      "epoch:20 step:18846 [D loss: 0.798668, acc.: 42.19%] [G loss: 0.946569]\n",
      "epoch:20 step:18847 [D loss: 0.549701, acc.: 70.31%] [G loss: 1.003959]\n",
      "epoch:20 step:18848 [D loss: 0.740387, acc.: 48.44%] [G loss: 0.914704]\n",
      "epoch:20 step:18849 [D loss: 0.731142, acc.: 48.44%] [G loss: 0.879072]\n",
      "epoch:20 step:18850 [D loss: 0.685304, acc.: 59.38%] [G loss: 0.889234]\n",
      "epoch:20 step:18851 [D loss: 0.664875, acc.: 62.50%] [G loss: 0.940718]\n",
      "epoch:20 step:18852 [D loss: 0.583685, acc.: 70.31%] [G loss: 0.926894]\n",
      "epoch:20 step:18853 [D loss: 0.634673, acc.: 69.53%] [G loss: 0.918517]\n",
      "epoch:20 step:18854 [D loss: 0.582727, acc.: 70.31%] [G loss: 0.973940]\n",
      "epoch:20 step:18855 [D loss: 0.558616, acc.: 73.44%] [G loss: 0.859528]\n",
      "epoch:20 step:18856 [D loss: 0.658913, acc.: 60.16%] [G loss: 0.863861]\n",
      "epoch:20 step:18857 [D loss: 0.568682, acc.: 74.22%] [G loss: 1.002091]\n",
      "epoch:20 step:18858 [D loss: 0.639679, acc.: 64.06%] [G loss: 1.076744]\n",
      "epoch:20 step:18859 [D loss: 0.408019, acc.: 79.69%] [G loss: 1.132687]\n",
      "epoch:20 step:18860 [D loss: 0.644874, acc.: 63.28%] [G loss: 0.998345]\n",
      "epoch:20 step:18861 [D loss: 0.513935, acc.: 72.66%] [G loss: 1.084219]\n",
      "epoch:20 step:18862 [D loss: 0.573355, acc.: 66.41%] [G loss: 1.075514]\n",
      "epoch:20 step:18863 [D loss: 0.679717, acc.: 51.56%] [G loss: 0.940078]\n",
      "epoch:20 step:18864 [D loss: 0.727108, acc.: 53.12%] [G loss: 0.955352]\n",
      "epoch:20 step:18865 [D loss: 0.719561, acc.: 53.12%] [G loss: 1.008009]\n",
      "epoch:20 step:18866 [D loss: 0.736356, acc.: 48.44%] [G loss: 1.072694]\n",
      "epoch:20 step:18867 [D loss: 0.737116, acc.: 52.34%] [G loss: 0.783473]\n",
      "epoch:20 step:18868 [D loss: 0.627994, acc.: 61.72%] [G loss: 0.964824]\n",
      "epoch:20 step:18869 [D loss: 0.592997, acc.: 66.41%] [G loss: 0.972434]\n",
      "epoch:20 step:18870 [D loss: 0.524479, acc.: 75.00%] [G loss: 0.792696]\n",
      "epoch:20 step:18871 [D loss: 0.474111, acc.: 82.81%] [G loss: 1.049107]\n",
      "epoch:20 step:18872 [D loss: 0.540665, acc.: 75.78%] [G loss: 0.875663]\n",
      "epoch:20 step:18873 [D loss: 0.676099, acc.: 60.16%] [G loss: 0.977391]\n",
      "epoch:20 step:18874 [D loss: 0.677531, acc.: 58.59%] [G loss: 1.048228]\n",
      "epoch:20 step:18875 [D loss: 0.578793, acc.: 71.88%] [G loss: 0.666480]\n",
      "epoch:20 step:18876 [D loss: 0.641805, acc.: 63.28%] [G loss: 0.935633]\n",
      "epoch:20 step:18877 [D loss: 0.647193, acc.: 63.28%] [G loss: 0.905707]\n",
      "epoch:20 step:18878 [D loss: 0.550939, acc.: 70.31%] [G loss: 0.988735]\n",
      "epoch:20 step:18879 [D loss: 0.667639, acc.: 65.62%] [G loss: 0.890667]\n",
      "epoch:20 step:18880 [D loss: 0.733063, acc.: 59.38%] [G loss: 0.766093]\n",
      "epoch:20 step:18881 [D loss: 0.655341, acc.: 62.50%] [G loss: 0.853761]\n",
      "epoch:20 step:18882 [D loss: 0.752138, acc.: 44.53%] [G loss: 0.855619]\n",
      "epoch:20 step:18883 [D loss: 0.672881, acc.: 55.47%] [G loss: 0.953161]\n",
      "epoch:20 step:18884 [D loss: 0.724609, acc.: 53.12%] [G loss: 0.873007]\n",
      "epoch:20 step:18885 [D loss: 0.496590, acc.: 73.44%] [G loss: 0.906698]\n",
      "epoch:20 step:18886 [D loss: 0.624786, acc.: 72.66%] [G loss: 1.005465]\n",
      "epoch:20 step:18887 [D loss: 0.654608, acc.: 67.19%] [G loss: 1.186823]\n",
      "epoch:20 step:18888 [D loss: 0.737689, acc.: 45.31%] [G loss: 0.905515]\n",
      "epoch:20 step:18889 [D loss: 0.561041, acc.: 69.53%] [G loss: 0.930847]\n",
      "epoch:20 step:18890 [D loss: 0.425558, acc.: 82.81%] [G loss: 0.985854]\n",
      "epoch:20 step:18891 [D loss: 0.389624, acc.: 86.72%] [G loss: 1.097193]\n",
      "epoch:20 step:18892 [D loss: 0.351940, acc.: 88.28%] [G loss: 1.439409]\n",
      "epoch:20 step:18893 [D loss: 0.801514, acc.: 47.66%] [G loss: 1.114177]\n",
      "epoch:20 step:18894 [D loss: 0.707649, acc.: 53.91%] [G loss: 0.916824]\n",
      "epoch:20 step:18895 [D loss: 0.698903, acc.: 57.81%] [G loss: 1.023296]\n",
      "epoch:20 step:18896 [D loss: 0.741431, acc.: 54.69%] [G loss: 0.946987]\n",
      "epoch:20 step:18897 [D loss: 0.683844, acc.: 54.69%] [G loss: 0.845089]\n",
      "epoch:20 step:18898 [D loss: 0.725639, acc.: 47.66%] [G loss: 0.807781]\n",
      "epoch:20 step:18899 [D loss: 0.718561, acc.: 49.22%] [G loss: 0.957640]\n",
      "epoch:20 step:18900 [D loss: 0.690431, acc.: 57.03%] [G loss: 0.974446]\n",
      "epoch:20 step:18901 [D loss: 0.625229, acc.: 67.19%] [G loss: 0.950525]\n",
      "epoch:20 step:18902 [D loss: 0.638776, acc.: 57.03%] [G loss: 0.878333]\n",
      "epoch:20 step:18903 [D loss: 0.571933, acc.: 71.88%] [G loss: 0.962213]\n",
      "epoch:20 step:18904 [D loss: 0.686319, acc.: 57.81%] [G loss: 0.873561]\n",
      "epoch:20 step:18905 [D loss: 0.604548, acc.: 65.62%] [G loss: 1.044163]\n",
      "epoch:20 step:18906 [D loss: 0.766130, acc.: 42.97%] [G loss: 0.953551]\n",
      "epoch:20 step:18907 [D loss: 0.713485, acc.: 45.31%] [G loss: 0.937627]\n",
      "epoch:20 step:18908 [D loss: 0.582234, acc.: 69.53%] [G loss: 1.115656]\n",
      "epoch:20 step:18909 [D loss: 0.710636, acc.: 52.34%] [G loss: 0.893602]\n",
      "epoch:20 step:18910 [D loss: 0.716064, acc.: 50.78%] [G loss: 0.975291]\n",
      "epoch:20 step:18911 [D loss: 0.682278, acc.: 55.47%] [G loss: 0.934948]\n",
      "epoch:20 step:18912 [D loss: 0.690751, acc.: 60.16%] [G loss: 0.999746]\n",
      "epoch:20 step:18913 [D loss: 0.733434, acc.: 50.78%] [G loss: 0.981749]\n",
      "epoch:20 step:18914 [D loss: 0.716816, acc.: 51.56%] [G loss: 0.922505]\n",
      "epoch:20 step:18915 [D loss: 0.741036, acc.: 49.22%] [G loss: 0.894308]\n",
      "epoch:20 step:18916 [D loss: 0.621355, acc.: 63.28%] [G loss: 0.922228]\n",
      "epoch:20 step:18917 [D loss: 0.679482, acc.: 56.25%] [G loss: 0.868503]\n",
      "epoch:20 step:18918 [D loss: 0.657714, acc.: 64.06%] [G loss: 0.888900]\n",
      "epoch:20 step:18919 [D loss: 0.707274, acc.: 50.00%] [G loss: 0.832610]\n",
      "epoch:20 step:18920 [D loss: 0.687985, acc.: 60.94%] [G loss: 0.808742]\n",
      "epoch:20 step:18921 [D loss: 0.652133, acc.: 61.72%] [G loss: 0.690624]\n",
      "epoch:20 step:18922 [D loss: 0.719616, acc.: 48.44%] [G loss: 0.867618]\n",
      "epoch:20 step:18923 [D loss: 0.705009, acc.: 52.34%] [G loss: 0.639536]\n",
      "epoch:20 step:18924 [D loss: 0.673537, acc.: 52.34%] [G loss: 0.790985]\n",
      "epoch:20 step:18925 [D loss: 0.599097, acc.: 69.53%] [G loss: 0.646404]\n",
      "epoch:20 step:18926 [D loss: 0.661360, acc.: 57.81%] [G loss: 0.767299]\n",
      "epoch:20 step:18927 [D loss: 0.676142, acc.: 54.69%] [G loss: 0.731358]\n",
      "epoch:20 step:18928 [D loss: 0.753197, acc.: 49.22%] [G loss: 0.618889]\n",
      "epoch:20 step:18929 [D loss: 0.698742, acc.: 57.81%] [G loss: 0.860496]\n",
      "epoch:20 step:18930 [D loss: 0.679856, acc.: 60.94%] [G loss: 0.770426]\n",
      "epoch:20 step:18931 [D loss: 0.645286, acc.: 62.50%] [G loss: 0.799184]\n",
      "epoch:20 step:18932 [D loss: 0.598893, acc.: 71.09%] [G loss: 0.840167]\n",
      "epoch:20 step:18933 [D loss: 0.624400, acc.: 66.41%] [G loss: 0.913510]\n",
      "epoch:20 step:18934 [D loss: 0.633761, acc.: 61.72%] [G loss: 0.918016]\n",
      "epoch:20 step:18935 [D loss: 0.631188, acc.: 64.84%] [G loss: 0.915777]\n",
      "epoch:20 step:18936 [D loss: 0.684584, acc.: 57.03%] [G loss: 0.925142]\n",
      "epoch:20 step:18937 [D loss: 0.640819, acc.: 64.06%] [G loss: 0.912895]\n",
      "epoch:20 step:18938 [D loss: 0.614982, acc.: 60.94%] [G loss: 0.989227]\n",
      "epoch:20 step:18939 [D loss: 0.678880, acc.: 53.91%] [G loss: 0.760550]\n",
      "epoch:20 step:18940 [D loss: 0.569280, acc.: 71.09%] [G loss: 0.979034]\n",
      "epoch:20 step:18941 [D loss: 0.434643, acc.: 85.94%] [G loss: 1.046791]\n",
      "epoch:20 step:18942 [D loss: 0.693371, acc.: 56.25%] [G loss: 0.968484]\n",
      "epoch:20 step:18943 [D loss: 0.545895, acc.: 77.34%] [G loss: 0.963572]\n",
      "epoch:20 step:18944 [D loss: 0.410774, acc.: 85.94%] [G loss: 1.032976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18945 [D loss: 0.573586, acc.: 68.75%] [G loss: 0.880401]\n",
      "epoch:20 step:18946 [D loss: 0.493139, acc.: 82.81%] [G loss: 1.098253]\n",
      "epoch:20 step:18947 [D loss: 0.386937, acc.: 82.03%] [G loss: 1.097472]\n",
      "epoch:20 step:18948 [D loss: 0.502173, acc.: 79.69%] [G loss: 1.174185]\n",
      "epoch:20 step:18949 [D loss: 0.409012, acc.: 91.41%] [G loss: 1.005251]\n",
      "epoch:20 step:18950 [D loss: 0.737517, acc.: 55.47%] [G loss: 0.907704]\n",
      "epoch:20 step:18951 [D loss: 0.838695, acc.: 40.62%] [G loss: 0.894320]\n",
      "epoch:20 step:18952 [D loss: 0.698104, acc.: 58.59%] [G loss: 0.968921]\n",
      "epoch:20 step:18953 [D loss: 0.802692, acc.: 43.75%] [G loss: 0.851196]\n",
      "epoch:20 step:18954 [D loss: 0.794303, acc.: 43.75%] [G loss: 0.863451]\n",
      "epoch:20 step:18955 [D loss: 0.783076, acc.: 43.75%] [G loss: 0.975671]\n",
      "epoch:20 step:18956 [D loss: 0.768131, acc.: 48.44%] [G loss: 0.750395]\n",
      "epoch:20 step:18957 [D loss: 0.560351, acc.: 73.44%] [G loss: 0.948945]\n",
      "epoch:20 step:18958 [D loss: 0.559588, acc.: 71.09%] [G loss: 0.692128]\n",
      "epoch:20 step:18959 [D loss: 0.487871, acc.: 85.16%] [G loss: 1.056479]\n",
      "epoch:20 step:18960 [D loss: 0.465831, acc.: 85.16%] [G loss: 0.765312]\n",
      "epoch:20 step:18961 [D loss: 0.541353, acc.: 70.31%] [G loss: 1.028334]\n",
      "epoch:20 step:18962 [D loss: 0.513277, acc.: 84.38%] [G loss: 1.072220]\n",
      "epoch:20 step:18963 [D loss: 0.419665, acc.: 89.06%] [G loss: 1.090451]\n",
      "epoch:20 step:18964 [D loss: 0.673921, acc.: 60.16%] [G loss: 1.161758]\n",
      "epoch:20 step:18965 [D loss: 0.645604, acc.: 59.38%] [G loss: 1.077103]\n",
      "epoch:20 step:18966 [D loss: 0.669534, acc.: 53.91%] [G loss: 1.133943]\n",
      "epoch:20 step:18967 [D loss: 0.579199, acc.: 70.31%] [G loss: 1.013060]\n",
      "epoch:20 step:18968 [D loss: 0.630923, acc.: 68.75%] [G loss: 0.982733]\n",
      "epoch:20 step:18969 [D loss: 0.595777, acc.: 70.31%] [G loss: 1.045770]\n",
      "epoch:20 step:18970 [D loss: 0.302580, acc.: 85.94%] [G loss: 0.963132]\n",
      "epoch:20 step:18971 [D loss: 0.372065, acc.: 89.06%] [G loss: 1.130136]\n",
      "epoch:20 step:18972 [D loss: 0.351759, acc.: 85.94%] [G loss: 1.153683]\n",
      "epoch:20 step:18973 [D loss: 0.685616, acc.: 59.38%] [G loss: 1.170069]\n",
      "epoch:20 step:18974 [D loss: 0.517079, acc.: 77.34%] [G loss: 1.044338]\n",
      "epoch:20 step:18975 [D loss: 0.426550, acc.: 82.81%] [G loss: 1.142874]\n",
      "epoch:20 step:18976 [D loss: 0.593682, acc.: 71.88%] [G loss: 1.228226]\n",
      "epoch:20 step:18977 [D loss: 0.634116, acc.: 63.28%] [G loss: 1.084011]\n",
      "epoch:20 step:18978 [D loss: 0.429206, acc.: 89.06%] [G loss: 1.111284]\n",
      "epoch:20 step:18979 [D loss: 0.624213, acc.: 67.19%] [G loss: 0.879282]\n",
      "epoch:20 step:18980 [D loss: 0.590402, acc.: 64.84%] [G loss: 0.490684]\n",
      "epoch:20 step:18981 [D loss: 0.858358, acc.: 46.09%] [G loss: 0.358000]\n",
      "epoch:20 step:18982 [D loss: 0.830828, acc.: 45.31%] [G loss: 0.882458]\n",
      "epoch:20 step:18983 [D loss: 0.490548, acc.: 74.22%] [G loss: 0.864856]\n",
      "epoch:20 step:18984 [D loss: 0.958465, acc.: 27.34%] [G loss: 0.903236]\n",
      "epoch:20 step:18985 [D loss: 0.867917, acc.: 40.62%] [G loss: 1.107771]\n",
      "epoch:20 step:18986 [D loss: 0.744578, acc.: 50.78%] [G loss: 1.194216]\n",
      "epoch:20 step:18987 [D loss: 0.620122, acc.: 60.94%] [G loss: 0.980419]\n",
      "epoch:20 step:18988 [D loss: 0.639218, acc.: 59.38%] [G loss: 1.067678]\n",
      "epoch:20 step:18989 [D loss: 0.704259, acc.: 53.91%] [G loss: 1.025881]\n",
      "epoch:20 step:18990 [D loss: 0.741316, acc.: 49.22%] [G loss: 1.016180]\n",
      "epoch:20 step:18991 [D loss: 0.676769, acc.: 57.03%] [G loss: 1.115046]\n",
      "epoch:20 step:18992 [D loss: 0.721602, acc.: 52.34%] [G loss: 1.028073]\n",
      "epoch:20 step:18993 [D loss: 0.668886, acc.: 57.81%] [G loss: 0.938107]\n",
      "epoch:20 step:18994 [D loss: 0.678924, acc.: 53.12%] [G loss: 0.973302]\n",
      "epoch:20 step:18995 [D loss: 0.535500, acc.: 82.03%] [G loss: 0.813209]\n",
      "epoch:20 step:18996 [D loss: 0.352886, acc.: 86.72%] [G loss: 0.975789]\n",
      "epoch:20 step:18997 [D loss: 0.586688, acc.: 68.75%] [G loss: 1.094257]\n",
      "epoch:20 step:18998 [D loss: 0.677164, acc.: 54.69%] [G loss: 0.930986]\n",
      "epoch:20 step:18999 [D loss: 0.524007, acc.: 74.22%] [G loss: 1.108821]\n",
      "epoch:20 step:19000 [D loss: 0.566685, acc.: 71.09%] [G loss: 0.877116]\n",
      "epoch:20 step:19001 [D loss: 0.529577, acc.: 70.31%] [G loss: 1.052472]\n",
      "epoch:20 step:19002 [D loss: 0.707329, acc.: 50.78%] [G loss: 1.085763]\n",
      "epoch:20 step:19003 [D loss: 0.296852, acc.: 92.97%] [G loss: 1.362667]\n",
      "epoch:20 step:19004 [D loss: 0.518266, acc.: 75.78%] [G loss: 1.266851]\n",
      "epoch:20 step:19005 [D loss: 0.785795, acc.: 46.09%] [G loss: 1.089939]\n",
      "epoch:20 step:19006 [D loss: 0.706249, acc.: 57.03%] [G loss: 0.971940]\n",
      "epoch:20 step:19007 [D loss: 0.668297, acc.: 57.81%] [G loss: 1.137223]\n",
      "epoch:20 step:19008 [D loss: 0.631265, acc.: 64.84%] [G loss: 0.946999]\n",
      "epoch:20 step:19009 [D loss: 0.515519, acc.: 80.47%] [G loss: 1.029217]\n",
      "epoch:20 step:19010 [D loss: 0.602288, acc.: 67.19%] [G loss: 1.059472]\n",
      "epoch:20 step:19011 [D loss: 0.520538, acc.: 81.25%] [G loss: 0.928864]\n",
      "epoch:20 step:19012 [D loss: 0.552778, acc.: 78.12%] [G loss: 0.783853]\n",
      "epoch:20 step:19013 [D loss: 0.668927, acc.: 61.72%] [G loss: 0.814239]\n",
      "epoch:20 step:19014 [D loss: 0.501066, acc.: 84.38%] [G loss: 0.990578]\n",
      "epoch:20 step:19015 [D loss: 0.617462, acc.: 70.31%] [G loss: 0.879925]\n",
      "epoch:20 step:19016 [D loss: 0.564650, acc.: 75.00%] [G loss: 1.104593]\n",
      "epoch:20 step:19017 [D loss: 0.680273, acc.: 51.56%] [G loss: 1.171487]\n",
      "epoch:20 step:19018 [D loss: 0.687030, acc.: 56.25%] [G loss: 1.097080]\n",
      "epoch:20 step:19019 [D loss: 0.394778, acc.: 78.91%] [G loss: 0.944781]\n",
      "epoch:20 step:19020 [D loss: 0.683287, acc.: 60.94%] [G loss: 0.987517]\n",
      "epoch:20 step:19021 [D loss: 0.906187, acc.: 23.44%] [G loss: 1.099251]\n",
      "epoch:20 step:19022 [D loss: 0.730581, acc.: 45.31%] [G loss: 0.907574]\n",
      "epoch:20 step:19023 [D loss: 0.778056, acc.: 40.62%] [G loss: 0.854410]\n",
      "epoch:20 step:19024 [D loss: 0.490587, acc.: 82.81%] [G loss: 0.878111]\n",
      "epoch:20 step:19025 [D loss: 0.421580, acc.: 79.69%] [G loss: 1.126323]\n",
      "epoch:20 step:19026 [D loss: 0.402107, acc.: 82.03%] [G loss: 0.865936]\n",
      "epoch:20 step:19027 [D loss: 0.543180, acc.: 75.78%] [G loss: 1.055199]\n",
      "epoch:20 step:19028 [D loss: 0.414929, acc.: 82.03%] [G loss: 1.251607]\n",
      "epoch:20 step:19029 [D loss: 0.441897, acc.: 86.72%] [G loss: 1.068617]\n",
      "epoch:20 step:19030 [D loss: 0.358303, acc.: 89.84%] [G loss: 1.543802]\n",
      "epoch:20 step:19031 [D loss: 0.213080, acc.: 95.31%] [G loss: 2.093805]\n",
      "epoch:20 step:19032 [D loss: 0.570490, acc.: 67.97%] [G loss: 1.157631]\n",
      "epoch:20 step:19033 [D loss: 0.312376, acc.: 92.97%] [G loss: 0.970035]\n",
      "epoch:20 step:19034 [D loss: 0.470000, acc.: 80.47%] [G loss: 1.117824]\n",
      "epoch:20 step:19035 [D loss: 0.751868, acc.: 53.12%] [G loss: 0.894392]\n",
      "epoch:20 step:19036 [D loss: 0.755995, acc.: 46.88%] [G loss: 0.619054]\n",
      "epoch:20 step:19037 [D loss: 0.938479, acc.: 29.69%] [G loss: 0.834917]\n",
      "epoch:20 step:19038 [D loss: 0.753392, acc.: 47.66%] [G loss: 1.093909]\n",
      "epoch:20 step:19039 [D loss: 1.190278, acc.: 21.88%] [G loss: 1.458861]\n",
      "epoch:20 step:19040 [D loss: 0.676211, acc.: 61.72%] [G loss: 1.265656]\n",
      "epoch:20 step:19041 [D loss: 0.743256, acc.: 57.03%] [G loss: 1.249193]\n",
      "epoch:20 step:19042 [D loss: 0.672582, acc.: 59.38%] [G loss: 0.877841]\n",
      "epoch:20 step:19043 [D loss: 0.784666, acc.: 42.97%] [G loss: 1.209487]\n",
      "epoch:20 step:19044 [D loss: 0.731781, acc.: 50.78%] [G loss: 1.235459]\n",
      "epoch:20 step:19045 [D loss: 0.522086, acc.: 82.03%] [G loss: 1.070650]\n",
      "epoch:20 step:19046 [D loss: 0.669874, acc.: 60.94%] [G loss: 1.139589]\n",
      "epoch:20 step:19047 [D loss: 0.780006, acc.: 42.97%] [G loss: 0.928358]\n",
      "epoch:20 step:19048 [D loss: 0.547290, acc.: 78.91%] [G loss: 0.992144]\n",
      "epoch:20 step:19049 [D loss: 0.539782, acc.: 76.56%] [G loss: 0.740426]\n",
      "epoch:20 step:19050 [D loss: 0.708610, acc.: 48.44%] [G loss: 1.026670]\n",
      "epoch:20 step:19051 [D loss: 0.634227, acc.: 64.84%] [G loss: 0.906161]\n",
      "epoch:20 step:19052 [D loss: 0.530380, acc.: 71.88%] [G loss: 0.995772]\n",
      "epoch:20 step:19053 [D loss: 0.650471, acc.: 60.94%] [G loss: 0.631884]\n",
      "epoch:20 step:19054 [D loss: 0.460940, acc.: 83.59%] [G loss: 0.992086]\n",
      "epoch:20 step:19055 [D loss: 0.612644, acc.: 67.19%] [G loss: 0.858766]\n",
      "epoch:20 step:19056 [D loss: 0.920844, acc.: 35.94%] [G loss: 1.156705]\n",
      "epoch:20 step:19057 [D loss: 0.680384, acc.: 50.78%] [G loss: 0.983760]\n",
      "epoch:20 step:19058 [D loss: 0.643485, acc.: 60.16%] [G loss: 1.169719]\n",
      "epoch:20 step:19059 [D loss: 0.572230, acc.: 71.88%] [G loss: 1.192771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19060 [D loss: 0.591962, acc.: 65.62%] [G loss: 1.077550]\n",
      "epoch:20 step:19061 [D loss: 0.525681, acc.: 81.25%] [G loss: 1.083202]\n",
      "epoch:20 step:19062 [D loss: 0.506446, acc.: 73.44%] [G loss: 1.243005]\n",
      "epoch:20 step:19063 [D loss: 0.747088, acc.: 60.16%] [G loss: 1.029402]\n",
      "epoch:20 step:19064 [D loss: 0.659922, acc.: 57.03%] [G loss: 1.049708]\n",
      "epoch:20 step:19065 [D loss: 0.568007, acc.: 69.53%] [G loss: 0.925824]\n",
      "epoch:20 step:19066 [D loss: 0.487870, acc.: 80.47%] [G loss: 1.021201]\n",
      "epoch:20 step:19067 [D loss: 0.422550, acc.: 88.28%] [G loss: 1.074315]\n",
      "epoch:20 step:19068 [D loss: 0.411659, acc.: 85.94%] [G loss: 1.233002]\n",
      "epoch:20 step:19069 [D loss: 0.502378, acc.: 79.69%] [G loss: 1.072604]\n",
      "epoch:20 step:19070 [D loss: 0.774037, acc.: 40.62%] [G loss: 0.740973]\n",
      "epoch:20 step:19071 [D loss: 0.721380, acc.: 52.34%] [G loss: 1.083620]\n",
      "epoch:20 step:19072 [D loss: 0.789649, acc.: 51.56%] [G loss: 1.178034]\n",
      "epoch:20 step:19073 [D loss: 0.837803, acc.: 35.94%] [G loss: 0.942775]\n",
      "epoch:20 step:19074 [D loss: 0.815978, acc.: 44.53%] [G loss: 0.728828]\n",
      "epoch:20 step:19075 [D loss: 0.777168, acc.: 45.31%] [G loss: 0.933218]\n",
      "epoch:20 step:19076 [D loss: 0.695160, acc.: 51.56%] [G loss: 0.814133]\n",
      "epoch:20 step:19077 [D loss: 0.644782, acc.: 61.72%] [G loss: 0.916045]\n",
      "epoch:20 step:19078 [D loss: 0.634212, acc.: 62.50%] [G loss: 0.819677]\n",
      "epoch:20 step:19079 [D loss: 0.631114, acc.: 67.19%] [G loss: 0.820596]\n",
      "epoch:20 step:19080 [D loss: 0.660765, acc.: 60.94%] [G loss: 0.785195]\n",
      "epoch:20 step:19081 [D loss: 0.761791, acc.: 48.44%] [G loss: 0.873382]\n",
      "epoch:20 step:19082 [D loss: 0.717363, acc.: 50.78%] [G loss: 0.865084]\n",
      "epoch:20 step:19083 [D loss: 0.454506, acc.: 89.84%] [G loss: 0.986791]\n",
      "epoch:20 step:19084 [D loss: 0.458296, acc.: 89.06%] [G loss: 1.044935]\n",
      "epoch:20 step:19085 [D loss: 0.437907, acc.: 83.59%] [G loss: 0.969387]\n",
      "epoch:20 step:19086 [D loss: 0.482460, acc.: 85.16%] [G loss: 1.008536]\n",
      "epoch:20 step:19087 [D loss: 0.389274, acc.: 92.19%] [G loss: 0.932931]\n",
      "epoch:20 step:19088 [D loss: 0.703114, acc.: 58.59%] [G loss: 0.866841]\n",
      "epoch:20 step:19089 [D loss: 0.643084, acc.: 58.59%] [G loss: 0.989676]\n",
      "epoch:20 step:19090 [D loss: 0.715699, acc.: 52.34%] [G loss: 0.834384]\n",
      "epoch:20 step:19091 [D loss: 0.652164, acc.: 56.25%] [G loss: 0.858116]\n",
      "epoch:20 step:19092 [D loss: 0.634987, acc.: 67.19%] [G loss: 1.057997]\n",
      "epoch:20 step:19093 [D loss: 0.523013, acc.: 71.09%] [G loss: 1.147714]\n",
      "epoch:20 step:19094 [D loss: 0.485199, acc.: 78.12%] [G loss: 1.202276]\n",
      "epoch:20 step:19095 [D loss: 0.581069, acc.: 70.31%] [G loss: 1.038058]\n",
      "epoch:20 step:19096 [D loss: 0.524257, acc.: 78.12%] [G loss: 1.092682]\n",
      "epoch:20 step:19097 [D loss: 0.581693, acc.: 76.56%] [G loss: 1.305848]\n",
      "epoch:20 step:19098 [D loss: 0.461310, acc.: 80.47%] [G loss: 1.120499]\n",
      "epoch:20 step:19099 [D loss: 0.468547, acc.: 81.25%] [G loss: 1.236486]\n",
      "epoch:20 step:19100 [D loss: 0.483335, acc.: 80.47%] [G loss: 0.927905]\n",
      "epoch:20 step:19101 [D loss: 0.562313, acc.: 74.22%] [G loss: 0.948025]\n",
      "epoch:20 step:19102 [D loss: 0.713498, acc.: 57.03%] [G loss: 0.910853]\n",
      "epoch:20 step:19103 [D loss: 0.802213, acc.: 43.75%] [G loss: 0.904153]\n",
      "epoch:20 step:19104 [D loss: 0.647673, acc.: 61.72%] [G loss: 0.801009]\n",
      "epoch:20 step:19105 [D loss: 0.724350, acc.: 54.69%] [G loss: 0.850099]\n",
      "epoch:20 step:19106 [D loss: 0.518892, acc.: 74.22%] [G loss: 0.820223]\n",
      "epoch:20 step:19107 [D loss: 0.502575, acc.: 70.31%] [G loss: 1.012561]\n",
      "epoch:20 step:19108 [D loss: 0.736047, acc.: 56.25%] [G loss: 1.029614]\n",
      "epoch:20 step:19109 [D loss: 0.540673, acc.: 75.00%] [G loss: 0.936874]\n",
      "epoch:20 step:19110 [D loss: 0.481713, acc.: 80.47%] [G loss: 0.824383]\n",
      "epoch:20 step:19111 [D loss: 0.429766, acc.: 78.12%] [G loss: 1.116162]\n",
      "epoch:20 step:19112 [D loss: 0.584355, acc.: 75.00%] [G loss: 0.977895]\n",
      "epoch:20 step:19113 [D loss: 0.745591, acc.: 49.22%] [G loss: 0.871617]\n",
      "epoch:20 step:19114 [D loss: 0.683731, acc.: 63.28%] [G loss: 0.842995]\n",
      "epoch:20 step:19115 [D loss: 0.665685, acc.: 60.16%] [G loss: 0.860075]\n",
      "epoch:20 step:19116 [D loss: 0.749439, acc.: 52.34%] [G loss: 0.795766]\n",
      "epoch:20 step:19117 [D loss: 0.490288, acc.: 78.91%] [G loss: 0.921409]\n",
      "epoch:20 step:19118 [D loss: 0.521349, acc.: 79.69%] [G loss: 0.883047]\n",
      "epoch:20 step:19119 [D loss: 0.749473, acc.: 50.78%] [G loss: 0.785760]\n",
      "epoch:20 step:19120 [D loss: 0.508621, acc.: 75.00%] [G loss: 0.886779]\n",
      "epoch:20 step:19121 [D loss: 0.672909, acc.: 60.16%] [G loss: 1.162281]\n",
      "epoch:20 step:19122 [D loss: 0.718650, acc.: 49.22%] [G loss: 1.085033]\n",
      "epoch:20 step:19123 [D loss: 0.658638, acc.: 66.41%] [G loss: 1.192364]\n",
      "epoch:20 step:19124 [D loss: 0.646951, acc.: 65.62%] [G loss: 0.871319]\n",
      "epoch:20 step:19125 [D loss: 0.672848, acc.: 61.72%] [G loss: 0.938069]\n",
      "epoch:20 step:19126 [D loss: 0.763778, acc.: 49.22%] [G loss: 0.960948]\n",
      "epoch:20 step:19127 [D loss: 0.702949, acc.: 59.38%] [G loss: 0.972420]\n",
      "epoch:20 step:19128 [D loss: 0.700614, acc.: 55.47%] [G loss: 0.832150]\n",
      "epoch:20 step:19129 [D loss: 0.690635, acc.: 60.94%] [G loss: 0.926350]\n",
      "epoch:20 step:19130 [D loss: 0.654335, acc.: 60.94%] [G loss: 0.937498]\n",
      "epoch:20 step:19131 [D loss: 0.606689, acc.: 65.62%] [G loss: 0.787205]\n",
      "epoch:20 step:19132 [D loss: 0.602418, acc.: 66.41%] [G loss: 1.035283]\n",
      "epoch:20 step:19133 [D loss: 0.470859, acc.: 75.78%] [G loss: 1.004113]\n",
      "epoch:20 step:19134 [D loss: 0.554811, acc.: 68.75%] [G loss: 1.019354]\n",
      "epoch:20 step:19135 [D loss: 0.667909, acc.: 53.12%] [G loss: 1.026864]\n",
      "epoch:20 step:19136 [D loss: 0.322520, acc.: 87.50%] [G loss: 1.152075]\n",
      "epoch:20 step:19137 [D loss: 0.259433, acc.: 89.84%] [G loss: 1.278623]\n",
      "epoch:20 step:19138 [D loss: 0.239956, acc.: 93.75%] [G loss: 1.075545]\n",
      "epoch:20 step:19139 [D loss: 0.216588, acc.: 96.88%] [G loss: 1.267909]\n",
      "epoch:20 step:19140 [D loss: 0.226375, acc.: 96.88%] [G loss: 1.485754]\n",
      "epoch:20 step:19141 [D loss: 0.242608, acc.: 100.00%] [G loss: 1.250521]\n",
      "epoch:20 step:19142 [D loss: 0.282890, acc.: 90.62%] [G loss: 1.444120]\n",
      "epoch:20 step:19143 [D loss: 0.182176, acc.: 99.22%] [G loss: 1.350753]\n",
      "epoch:20 step:19144 [D loss: 0.259651, acc.: 89.84%] [G loss: 1.735193]\n",
      "epoch:20 step:19145 [D loss: 0.202787, acc.: 95.31%] [G loss: 1.322335]\n",
      "epoch:20 step:19146 [D loss: 0.302489, acc.: 93.75%] [G loss: 1.970629]\n",
      "epoch:20 step:19147 [D loss: 0.230659, acc.: 96.09%] [G loss: 1.488442]\n",
      "epoch:20 step:19148 [D loss: 0.358976, acc.: 86.72%] [G loss: 0.710893]\n",
      "epoch:20 step:19149 [D loss: 0.288352, acc.: 86.72%] [G loss: 1.803833]\n",
      "epoch:20 step:19150 [D loss: 0.871022, acc.: 53.12%] [G loss: 0.876024]\n",
      "epoch:20 step:19151 [D loss: 1.947360, acc.: 5.47%] [G loss: 1.446298]\n",
      "epoch:20 step:19152 [D loss: 0.840215, acc.: 44.53%] [G loss: 1.470782]\n",
      "epoch:20 step:19153 [D loss: 0.565055, acc.: 73.44%] [G loss: 1.117537]\n",
      "epoch:20 step:19154 [D loss: 1.176924, acc.: 26.56%] [G loss: 1.250382]\n",
      "epoch:20 step:19155 [D loss: 0.596367, acc.: 67.19%] [G loss: 1.483441]\n",
      "epoch:20 step:19156 [D loss: 0.791307, acc.: 52.34%] [G loss: 1.344457]\n",
      "epoch:20 step:19157 [D loss: 0.812858, acc.: 51.56%] [G loss: 1.172833]\n",
      "epoch:20 step:19158 [D loss: 0.752223, acc.: 46.09%] [G loss: 1.047759]\n",
      "epoch:20 step:19159 [D loss: 0.684507, acc.: 58.59%] [G loss: 1.068260]\n",
      "epoch:20 step:19160 [D loss: 0.935032, acc.: 24.22%] [G loss: 1.162895]\n",
      "epoch:20 step:19161 [D loss: 0.880306, acc.: 44.53%] [G loss: 1.053854]\n",
      "epoch:20 step:19162 [D loss: 0.737129, acc.: 48.44%] [G loss: 1.110061]\n",
      "epoch:20 step:19163 [D loss: 0.756626, acc.: 47.66%] [G loss: 1.159019]\n",
      "epoch:20 step:19164 [D loss: 0.725627, acc.: 47.66%] [G loss: 1.092874]\n",
      "epoch:20 step:19165 [D loss: 0.663724, acc.: 57.81%] [G loss: 1.051607]\n",
      "epoch:20 step:19166 [D loss: 0.678887, acc.: 53.91%] [G loss: 1.070155]\n",
      "epoch:20 step:19167 [D loss: 0.688152, acc.: 60.94%] [G loss: 0.988883]\n",
      "epoch:20 step:19168 [D loss: 0.659884, acc.: 59.38%] [G loss: 0.988669]\n",
      "epoch:20 step:19169 [D loss: 0.661812, acc.: 59.38%] [G loss: 1.068297]\n",
      "epoch:20 step:19170 [D loss: 0.718419, acc.: 52.34%] [G loss: 0.994698]\n",
      "epoch:20 step:19171 [D loss: 0.638347, acc.: 64.06%] [G loss: 0.928797]\n",
      "epoch:20 step:19172 [D loss: 0.620356, acc.: 67.97%] [G loss: 1.004420]\n",
      "epoch:20 step:19173 [D loss: 0.552313, acc.: 74.22%] [G loss: 0.987140]\n",
      "epoch:20 step:19174 [D loss: 0.653634, acc.: 56.25%] [G loss: 1.017262]\n",
      "epoch:20 step:19175 [D loss: 0.677388, acc.: 60.94%] [G loss: 1.032267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19176 [D loss: 0.544985, acc.: 73.44%] [G loss: 0.973120]\n",
      "epoch:20 step:19177 [D loss: 0.692601, acc.: 54.69%] [G loss: 1.035561]\n",
      "epoch:20 step:19178 [D loss: 0.704025, acc.: 51.56%] [G loss: 0.989948]\n",
      "epoch:20 step:19179 [D loss: 0.715373, acc.: 47.66%] [G loss: 0.872086]\n",
      "epoch:20 step:19180 [D loss: 0.666507, acc.: 54.69%] [G loss: 1.044653]\n",
      "epoch:20 step:19181 [D loss: 0.710962, acc.: 50.78%] [G loss: 0.893799]\n",
      "epoch:20 step:19182 [D loss: 0.652826, acc.: 55.47%] [G loss: 0.966362]\n",
      "epoch:20 step:19183 [D loss: 0.595565, acc.: 73.44%] [G loss: 1.074747]\n",
      "epoch:20 step:19184 [D loss: 0.617805, acc.: 66.41%] [G loss: 0.975401]\n",
      "epoch:20 step:19185 [D loss: 0.666878, acc.: 59.38%] [G loss: 0.979421]\n",
      "epoch:20 step:19186 [D loss: 0.690329, acc.: 57.03%] [G loss: 0.919146]\n",
      "epoch:20 step:19187 [D loss: 0.653606, acc.: 63.28%] [G loss: 0.998871]\n",
      "epoch:20 step:19188 [D loss: 0.556820, acc.: 77.34%] [G loss: 0.903846]\n",
      "epoch:20 step:19189 [D loss: 0.554207, acc.: 82.03%] [G loss: 1.155636]\n",
      "epoch:20 step:19190 [D loss: 0.545730, acc.: 78.91%] [G loss: 0.993794]\n",
      "epoch:20 step:19191 [D loss: 0.520039, acc.: 82.03%] [G loss: 1.030874]\n",
      "epoch:20 step:19192 [D loss: 0.511233, acc.: 84.38%] [G loss: 1.014131]\n",
      "epoch:20 step:19193 [D loss: 0.535940, acc.: 78.91%] [G loss: 1.185884]\n",
      "epoch:20 step:19194 [D loss: 0.521505, acc.: 82.03%] [G loss: 1.228961]\n",
      "epoch:20 step:19195 [D loss: 0.543856, acc.: 78.12%] [G loss: 1.138427]\n",
      "epoch:20 step:19196 [D loss: 0.435859, acc.: 80.47%] [G loss: 1.157375]\n",
      "epoch:20 step:19197 [D loss: 0.486004, acc.: 84.38%] [G loss: 1.365189]\n",
      "epoch:20 step:19198 [D loss: 0.732889, acc.: 46.88%] [G loss: 1.138753]\n",
      "epoch:20 step:19199 [D loss: 0.781346, acc.: 41.41%] [G loss: 1.067520]\n",
      "epoch:20 step:19200 [D loss: 0.736969, acc.: 45.31%] [G loss: 0.859673]\n",
      "epoch:20 step:19201 [D loss: 0.874622, acc.: 39.06%] [G loss: 0.940232]\n",
      "epoch:20 step:19202 [D loss: 1.043209, acc.: 25.00%] [G loss: 0.758575]\n",
      "epoch:20 step:19203 [D loss: 0.809737, acc.: 37.50%] [G loss: 0.837804]\n",
      "epoch:20 step:19204 [D loss: 0.701998, acc.: 60.94%] [G loss: 0.671931]\n",
      "epoch:20 step:19205 [D loss: 0.650576, acc.: 60.94%] [G loss: 0.786497]\n",
      "epoch:20 step:19206 [D loss: 0.680048, acc.: 59.38%] [G loss: 0.906625]\n",
      "epoch:20 step:19207 [D loss: 0.638854, acc.: 64.84%] [G loss: 0.767356]\n",
      "epoch:20 step:19208 [D loss: 0.561553, acc.: 68.75%] [G loss: 0.883310]\n",
      "epoch:20 step:19209 [D loss: 0.645615, acc.: 58.59%] [G loss: 0.877079]\n",
      "epoch:20 step:19210 [D loss: 0.525766, acc.: 74.22%] [G loss: 0.830344]\n",
      "epoch:20 step:19211 [D loss: 0.565696, acc.: 72.66%] [G loss: 0.955699]\n",
      "epoch:20 step:19212 [D loss: 0.619135, acc.: 64.06%] [G loss: 1.005319]\n",
      "epoch:20 step:19213 [D loss: 0.816496, acc.: 32.81%] [G loss: 1.029686]\n",
      "epoch:20 step:19214 [D loss: 0.759634, acc.: 40.62%] [G loss: 0.940240]\n",
      "epoch:20 step:19215 [D loss: 0.713122, acc.: 53.91%] [G loss: 1.218636]\n",
      "epoch:20 step:19216 [D loss: 0.695539, acc.: 60.16%] [G loss: 1.010656]\n",
      "epoch:20 step:19217 [D loss: 0.684963, acc.: 56.25%] [G loss: 1.022075]\n",
      "epoch:20 step:19218 [D loss: 0.696231, acc.: 60.16%] [G loss: 0.906571]\n",
      "epoch:20 step:19219 [D loss: 0.609148, acc.: 70.31%] [G loss: 0.885907]\n",
      "epoch:20 step:19220 [D loss: 0.570280, acc.: 75.00%] [G loss: 0.944584]\n",
      "epoch:20 step:19221 [D loss: 0.590067, acc.: 65.62%] [G loss: 0.843824]\n",
      "epoch:20 step:19222 [D loss: 0.725409, acc.: 55.47%] [G loss: 0.926359]\n",
      "epoch:20 step:19223 [D loss: 0.584726, acc.: 72.66%] [G loss: 1.085603]\n",
      "epoch:20 step:19224 [D loss: 0.579869, acc.: 70.31%] [G loss: 1.147357]\n",
      "epoch:20 step:19225 [D loss: 0.646285, acc.: 63.28%] [G loss: 1.129491]\n",
      "epoch:20 step:19226 [D loss: 0.621869, acc.: 63.28%] [G loss: 1.177066]\n",
      "epoch:20 step:19227 [D loss: 0.641100, acc.: 60.16%] [G loss: 1.019808]\n",
      "epoch:20 step:19228 [D loss: 0.574775, acc.: 70.31%] [G loss: 1.045146]\n",
      "epoch:20 step:19229 [D loss: 0.730276, acc.: 57.03%] [G loss: 0.981430]\n",
      "epoch:20 step:19230 [D loss: 0.662291, acc.: 61.72%] [G loss: 0.830207]\n",
      "epoch:20 step:19231 [D loss: 0.608454, acc.: 67.19%] [G loss: 0.912763]\n",
      "epoch:20 step:19232 [D loss: 0.685772, acc.: 53.12%] [G loss: 0.926134]\n",
      "epoch:20 step:19233 [D loss: 0.684609, acc.: 57.81%] [G loss: 0.759459]\n",
      "epoch:20 step:19234 [D loss: 0.679989, acc.: 62.50%] [G loss: 0.852521]\n",
      "epoch:20 step:19235 [D loss: 0.641539, acc.: 62.50%] [G loss: 0.914020]\n",
      "epoch:20 step:19236 [D loss: 0.669869, acc.: 57.03%] [G loss: 0.877265]\n",
      "epoch:20 step:19237 [D loss: 0.557263, acc.: 68.75%] [G loss: 0.940309]\n",
      "epoch:20 step:19238 [D loss: 0.558017, acc.: 73.44%] [G loss: 0.978517]\n",
      "epoch:20 step:19239 [D loss: 0.496223, acc.: 81.25%] [G loss: 0.809343]\n",
      "epoch:20 step:19240 [D loss: 0.608673, acc.: 66.41%] [G loss: 0.904247]\n",
      "epoch:20 step:19241 [D loss: 0.697262, acc.: 52.34%] [G loss: 0.867640]\n",
      "epoch:20 step:19242 [D loss: 0.716479, acc.: 51.56%] [G loss: 0.945479]\n",
      "epoch:20 step:19243 [D loss: 0.676126, acc.: 57.81%] [G loss: 0.926248]\n",
      "epoch:20 step:19244 [D loss: 0.672998, acc.: 61.72%] [G loss: 0.904754]\n",
      "epoch:20 step:19245 [D loss: 0.592043, acc.: 70.31%] [G loss: 0.985258]\n",
      "epoch:20 step:19246 [D loss: 0.682174, acc.: 54.69%] [G loss: 0.956624]\n",
      "epoch:20 step:19247 [D loss: 0.557851, acc.: 68.75%] [G loss: 0.858811]\n",
      "epoch:20 step:19248 [D loss: 0.555806, acc.: 69.53%] [G loss: 1.001341]\n",
      "epoch:20 step:19249 [D loss: 0.632301, acc.: 61.72%] [G loss: 1.059921]\n",
      "epoch:20 step:19250 [D loss: 0.674063, acc.: 60.94%] [G loss: 0.866345]\n",
      "epoch:20 step:19251 [D loss: 0.579045, acc.: 68.75%] [G loss: 1.059769]\n",
      "epoch:20 step:19252 [D loss: 0.583962, acc.: 71.88%] [G loss: 1.066182]\n",
      "epoch:20 step:19253 [D loss: 0.472509, acc.: 84.38%] [G loss: 1.060885]\n",
      "epoch:20 step:19254 [D loss: 0.530163, acc.: 73.44%] [G loss: 0.978899]\n",
      "epoch:20 step:19255 [D loss: 0.520467, acc.: 75.78%] [G loss: 1.091735]\n",
      "epoch:20 step:19256 [D loss: 0.663412, acc.: 59.38%] [G loss: 0.989575]\n",
      "epoch:20 step:19257 [D loss: 0.502107, acc.: 75.00%] [G loss: 1.267473]\n",
      "epoch:20 step:19258 [D loss: 0.622712, acc.: 60.94%] [G loss: 0.998731]\n",
      "epoch:20 step:19259 [D loss: 0.662430, acc.: 55.47%] [G loss: 1.161767]\n",
      "epoch:20 step:19260 [D loss: 0.537010, acc.: 73.44%] [G loss: 1.006223]\n",
      "epoch:20 step:19261 [D loss: 0.669796, acc.: 56.25%] [G loss: 1.115375]\n",
      "epoch:20 step:19262 [D loss: 0.591632, acc.: 71.09%] [G loss: 1.158721]\n",
      "epoch:20 step:19263 [D loss: 0.641239, acc.: 55.47%] [G loss: 1.164550]\n",
      "epoch:20 step:19264 [D loss: 0.547961, acc.: 71.88%] [G loss: 1.071414]\n",
      "epoch:20 step:19265 [D loss: 0.658826, acc.: 57.81%] [G loss: 1.028426]\n",
      "epoch:20 step:19266 [D loss: 0.620849, acc.: 64.06%] [G loss: 0.914791]\n",
      "epoch:20 step:19267 [D loss: 0.636690, acc.: 65.62%] [G loss: 1.143508]\n",
      "epoch:20 step:19268 [D loss: 0.671858, acc.: 60.94%] [G loss: 1.051382]\n",
      "epoch:20 step:19269 [D loss: 0.685691, acc.: 58.59%] [G loss: 1.038939]\n",
      "epoch:20 step:19270 [D loss: 0.526000, acc.: 76.56%] [G loss: 1.050967]\n",
      "epoch:20 step:19271 [D loss: 0.733734, acc.: 51.56%] [G loss: 1.043404]\n",
      "epoch:20 step:19272 [D loss: 0.642167, acc.: 61.72%] [G loss: 0.860528]\n",
      "epoch:20 step:19273 [D loss: 0.555097, acc.: 71.09%] [G loss: 1.070933]\n",
      "epoch:20 step:19274 [D loss: 0.584654, acc.: 67.19%] [G loss: 1.040304]\n",
      "epoch:20 step:19275 [D loss: 0.568339, acc.: 75.00%] [G loss: 1.037619]\n",
      "epoch:20 step:19276 [D loss: 0.475701, acc.: 82.03%] [G loss: 1.126041]\n",
      "epoch:20 step:19277 [D loss: 0.567911, acc.: 74.22%] [G loss: 0.783050]\n",
      "epoch:20 step:19278 [D loss: 0.545390, acc.: 77.34%] [G loss: 1.021579]\n",
      "epoch:20 step:19279 [D loss: 0.545888, acc.: 73.44%] [G loss: 0.939856]\n",
      "epoch:20 step:19280 [D loss: 0.547802, acc.: 74.22%] [G loss: 0.968907]\n",
      "epoch:20 step:19281 [D loss: 0.675960, acc.: 57.03%] [G loss: 0.681535]\n",
      "epoch:20 step:19282 [D loss: 0.699352, acc.: 56.25%] [G loss: 1.046980]\n",
      "epoch:20 step:19283 [D loss: 0.396660, acc.: 84.38%] [G loss: 1.143951]\n",
      "epoch:20 step:19284 [D loss: 0.657552, acc.: 55.47%] [G loss: 1.180117]\n",
      "epoch:20 step:19285 [D loss: 0.601388, acc.: 67.19%] [G loss: 1.056016]\n",
      "epoch:20 step:19286 [D loss: 0.776111, acc.: 53.91%] [G loss: 1.105213]\n",
      "epoch:20 step:19287 [D loss: 0.830375, acc.: 42.97%] [G loss: 1.041831]\n",
      "epoch:20 step:19288 [D loss: 0.484258, acc.: 81.25%] [G loss: 1.009396]\n",
      "epoch:20 step:19289 [D loss: 0.420483, acc.: 84.38%] [G loss: 1.173314]\n",
      "epoch:20 step:19290 [D loss: 0.333932, acc.: 88.28%] [G loss: 1.178449]\n",
      "epoch:20 step:19291 [D loss: 0.394528, acc.: 85.16%] [G loss: 1.121501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19292 [D loss: 0.450748, acc.: 84.38%] [G loss: 1.180248]\n",
      "epoch:20 step:19293 [D loss: 0.569804, acc.: 68.75%] [G loss: 1.064744]\n",
      "epoch:20 step:19294 [D loss: 0.257820, acc.: 98.44%] [G loss: 1.481394]\n",
      "epoch:20 step:19295 [D loss: 0.383849, acc.: 92.97%] [G loss: 1.548509]\n",
      "epoch:20 step:19296 [D loss: 0.289414, acc.: 94.53%] [G loss: 1.485289]\n",
      "epoch:20 step:19297 [D loss: 0.275318, acc.: 96.09%] [G loss: 1.479310]\n",
      "epoch:20 step:19298 [D loss: 0.270922, acc.: 96.09%] [G loss: 1.641746]\n",
      "epoch:20 step:19299 [D loss: 0.769360, acc.: 53.91%] [G loss: 1.510497]\n",
      "epoch:20 step:19300 [D loss: 0.796403, acc.: 54.69%] [G loss: 1.079219]\n",
      "epoch:20 step:19301 [D loss: 0.716812, acc.: 50.78%] [G loss: 0.882706]\n",
      "epoch:20 step:19302 [D loss: 0.805780, acc.: 44.53%] [G loss: 1.065315]\n",
      "epoch:20 step:19303 [D loss: 0.508007, acc.: 74.22%] [G loss: 0.983829]\n",
      "epoch:20 step:19304 [D loss: 0.527672, acc.: 74.22%] [G loss: 0.739083]\n",
      "epoch:20 step:19305 [D loss: 0.780235, acc.: 44.53%] [G loss: 0.990797]\n",
      "epoch:20 step:19306 [D loss: 0.658825, acc.: 64.06%] [G loss: 1.125607]\n",
      "epoch:20 step:19307 [D loss: 0.532696, acc.: 72.66%] [G loss: 1.049481]\n",
      "epoch:20 step:19308 [D loss: 0.698292, acc.: 57.03%] [G loss: 1.191862]\n",
      "epoch:20 step:19309 [D loss: 0.663897, acc.: 60.16%] [G loss: 0.985804]\n",
      "epoch:20 step:19310 [D loss: 0.652348, acc.: 62.50%] [G loss: 1.001911]\n",
      "epoch:20 step:19311 [D loss: 0.695092, acc.: 51.56%] [G loss: 0.909746]\n",
      "epoch:20 step:19312 [D loss: 0.800407, acc.: 46.88%] [G loss: 1.156505]\n",
      "epoch:20 step:19313 [D loss: 0.605036, acc.: 67.19%] [G loss: 1.354577]\n",
      "epoch:20 step:19314 [D loss: 0.630428, acc.: 64.06%] [G loss: 1.264775]\n",
      "epoch:20 step:19315 [D loss: 0.460184, acc.: 82.03%] [G loss: 1.040447]\n",
      "epoch:20 step:19316 [D loss: 0.534303, acc.: 74.22%] [G loss: 0.862393]\n",
      "epoch:20 step:19317 [D loss: 0.392184, acc.: 90.62%] [G loss: 1.226609]\n",
      "epoch:20 step:19318 [D loss: 0.419680, acc.: 84.38%] [G loss: 0.993481]\n",
      "epoch:20 step:19319 [D loss: 0.487365, acc.: 78.91%] [G loss: 1.283546]\n",
      "epoch:20 step:19320 [D loss: 0.604413, acc.: 70.31%] [G loss: 0.972077]\n",
      "epoch:20 step:19321 [D loss: 0.715051, acc.: 58.59%] [G loss: 0.759705]\n",
      "epoch:20 step:19322 [D loss: 0.842273, acc.: 46.88%] [G loss: 1.272817]\n",
      "epoch:20 step:19323 [D loss: 0.638475, acc.: 63.28%] [G loss: 0.987797]\n",
      "epoch:20 step:19324 [D loss: 0.732811, acc.: 57.03%] [G loss: 1.308291]\n",
      "epoch:20 step:19325 [D loss: 0.551982, acc.: 75.00%] [G loss: 1.053134]\n",
      "epoch:20 step:19326 [D loss: 0.840053, acc.: 47.66%] [G loss: 0.827371]\n",
      "epoch:20 step:19327 [D loss: 0.492780, acc.: 71.88%] [G loss: 1.313099]\n",
      "epoch:20 step:19328 [D loss: 0.367889, acc.: 92.19%] [G loss: 1.349021]\n",
      "epoch:20 step:19329 [D loss: 0.291415, acc.: 96.09%] [G loss: 1.470884]\n",
      "epoch:20 step:19330 [D loss: 0.718334, acc.: 60.94%] [G loss: 1.404562]\n",
      "epoch:20 step:19331 [D loss: 0.568696, acc.: 69.53%] [G loss: 1.213373]\n",
      "epoch:20 step:19332 [D loss: 0.490214, acc.: 78.91%] [G loss: 0.930526]\n",
      "epoch:20 step:19333 [D loss: 0.594640, acc.: 62.50%] [G loss: 0.714306]\n",
      "epoch:20 step:19334 [D loss: 0.572707, acc.: 71.88%] [G loss: 1.304199]\n",
      "epoch:20 step:19335 [D loss: 0.629547, acc.: 60.16%] [G loss: 1.206173]\n",
      "epoch:20 step:19336 [D loss: 0.482709, acc.: 79.69%] [G loss: 1.372991]\n",
      "epoch:20 step:19337 [D loss: 1.084847, acc.: 27.34%] [G loss: 1.306245]\n",
      "epoch:20 step:19338 [D loss: 0.553058, acc.: 67.19%] [G loss: 1.294695]\n",
      "epoch:20 step:19339 [D loss: 0.730544, acc.: 53.12%] [G loss: 1.350662]\n",
      "epoch:20 step:19340 [D loss: 0.559606, acc.: 70.31%] [G loss: 0.903931]\n",
      "epoch:20 step:19341 [D loss: 0.617738, acc.: 67.19%] [G loss: 0.976014]\n",
      "epoch:20 step:19342 [D loss: 0.788277, acc.: 52.34%] [G loss: 0.837597]\n",
      "epoch:20 step:19343 [D loss: 0.693115, acc.: 60.94%] [G loss: 0.904964]\n",
      "epoch:20 step:19344 [D loss: 0.410728, acc.: 77.34%] [G loss: 1.161267]\n",
      "epoch:20 step:19345 [D loss: 0.599188, acc.: 67.19%] [G loss: 1.356801]\n",
      "epoch:20 step:19346 [D loss: 0.666223, acc.: 64.06%] [G loss: 1.263497]\n",
      "epoch:20 step:19347 [D loss: 0.682517, acc.: 62.50%] [G loss: 0.978299]\n",
      "epoch:20 step:19348 [D loss: 0.722369, acc.: 53.91%] [G loss: 1.096376]\n",
      "epoch:20 step:19349 [D loss: 0.709217, acc.: 55.47%] [G loss: 1.035949]\n",
      "epoch:20 step:19350 [D loss: 0.740225, acc.: 47.66%] [G loss: 1.115016]\n",
      "epoch:20 step:19351 [D loss: 0.636033, acc.: 60.94%] [G loss: 1.059031]\n",
      "epoch:20 step:19352 [D loss: 0.630584, acc.: 59.38%] [G loss: 1.136023]\n",
      "epoch:20 step:19353 [D loss: 0.455858, acc.: 83.59%] [G loss: 1.113467]\n",
      "epoch:20 step:19354 [D loss: 0.606463, acc.: 69.53%] [G loss: 1.123389]\n",
      "epoch:20 step:19355 [D loss: 0.486928, acc.: 79.69%] [G loss: 1.294351]\n",
      "epoch:20 step:19356 [D loss: 0.385118, acc.: 93.75%] [G loss: 1.275714]\n",
      "epoch:20 step:19357 [D loss: 0.440508, acc.: 83.59%] [G loss: 1.035993]\n",
      "epoch:20 step:19358 [D loss: 0.688039, acc.: 60.16%] [G loss: 1.253253]\n",
      "epoch:20 step:19359 [D loss: 0.667723, acc.: 55.47%] [G loss: 1.454355]\n",
      "epoch:20 step:19360 [D loss: 0.575505, acc.: 71.88%] [G loss: 0.931983]\n",
      "epoch:20 step:19361 [D loss: 0.607599, acc.: 66.41%] [G loss: 1.200522]\n",
      "epoch:20 step:19362 [D loss: 0.361962, acc.: 91.41%] [G loss: 1.162423]\n",
      "epoch:20 step:19363 [D loss: 0.344216, acc.: 90.62%] [G loss: 1.220590]\n",
      "epoch:20 step:19364 [D loss: 0.331444, acc.: 89.84%] [G loss: 1.342808]\n",
      "epoch:20 step:19365 [D loss: 0.709010, acc.: 56.25%] [G loss: 1.151517]\n",
      "epoch:20 step:19366 [D loss: 0.434776, acc.: 87.50%] [G loss: 0.830163]\n",
      "epoch:20 step:19367 [D loss: 0.479995, acc.: 85.16%] [G loss: 0.690707]\n",
      "epoch:20 step:19368 [D loss: 0.811686, acc.: 52.34%] [G loss: 1.080148]\n",
      "epoch:20 step:19369 [D loss: 0.361282, acc.: 86.72%] [G loss: 1.015801]\n",
      "epoch:20 step:19370 [D loss: 0.410145, acc.: 84.38%] [G loss: 1.222442]\n",
      "epoch:20 step:19371 [D loss: 0.618187, acc.: 64.84%] [G loss: 0.738380]\n",
      "epoch:20 step:19372 [D loss: 0.274793, acc.: 89.06%] [G loss: 0.435468]\n",
      "epoch:20 step:19373 [D loss: 0.541908, acc.: 64.84%] [G loss: 1.616914]\n",
      "epoch:20 step:19374 [D loss: 0.480732, acc.: 74.22%] [G loss: 1.681951]\n",
      "epoch:20 step:19375 [D loss: 0.684291, acc.: 60.94%] [G loss: 1.634050]\n",
      "epoch:20 step:19376 [D loss: 0.799677, acc.: 51.56%] [G loss: 1.048991]\n",
      "epoch:20 step:19377 [D loss: 0.809215, acc.: 50.00%] [G loss: 1.107926]\n",
      "epoch:20 step:19378 [D loss: 0.670344, acc.: 58.59%] [G loss: 1.097096]\n",
      "epoch:20 step:19379 [D loss: 1.025478, acc.: 29.69%] [G loss: 0.831291]\n",
      "epoch:20 step:19380 [D loss: 1.087129, acc.: 31.25%] [G loss: 1.183334]\n",
      "epoch:20 step:19381 [D loss: 1.076936, acc.: 25.78%] [G loss: 1.127459]\n",
      "epoch:20 step:19382 [D loss: 0.855562, acc.: 37.50%] [G loss: 1.302684]\n",
      "epoch:20 step:19383 [D loss: 0.878996, acc.: 43.75%] [G loss: 0.961607]\n",
      "epoch:20 step:19384 [D loss: 0.844688, acc.: 62.50%] [G loss: 0.989366]\n",
      "epoch:20 step:19385 [D loss: 0.615955, acc.: 71.09%] [G loss: 1.298563]\n",
      "epoch:20 step:19386 [D loss: 0.678671, acc.: 63.28%] [G loss: 1.606667]\n",
      "epoch:20 step:19387 [D loss: 0.545504, acc.: 75.00%] [G loss: 0.895568]\n",
      "epoch:20 step:19388 [D loss: 0.553083, acc.: 78.91%] [G loss: 0.960484]\n",
      "epoch:20 step:19389 [D loss: 0.685740, acc.: 60.16%] [G loss: 1.125288]\n",
      "epoch:20 step:19390 [D loss: 0.546476, acc.: 73.44%] [G loss: 0.889011]\n",
      "epoch:20 step:19391 [D loss: 0.576230, acc.: 75.00%] [G loss: 0.904549]\n",
      "epoch:20 step:19392 [D loss: 0.721357, acc.: 50.78%] [G loss: 0.941938]\n",
      "epoch:20 step:19393 [D loss: 0.632460, acc.: 62.50%] [G loss: 1.054798]\n",
      "epoch:20 step:19394 [D loss: 0.643652, acc.: 62.50%] [G loss: 1.080970]\n",
      "epoch:20 step:19395 [D loss: 0.607258, acc.: 68.75%] [G loss: 1.138688]\n",
      "epoch:20 step:19396 [D loss: 0.640473, acc.: 64.06%] [G loss: 1.056190]\n",
      "epoch:20 step:19397 [D loss: 0.642108, acc.: 62.50%] [G loss: 0.804864]\n",
      "epoch:20 step:19398 [D loss: 0.635889, acc.: 62.50%] [G loss: 1.094233]\n",
      "epoch:20 step:19399 [D loss: 0.643357, acc.: 65.62%] [G loss: 0.909046]\n",
      "epoch:20 step:19400 [D loss: 0.579411, acc.: 71.09%] [G loss: 1.178492]\n",
      "epoch:20 step:19401 [D loss: 0.647201, acc.: 64.06%] [G loss: 0.890872]\n",
      "epoch:20 step:19402 [D loss: 0.592047, acc.: 73.44%] [G loss: 1.116673]\n",
      "epoch:20 step:19403 [D loss: 0.471834, acc.: 82.03%] [G loss: 0.879131]\n",
      "epoch:20 step:19404 [D loss: 0.494191, acc.: 78.12%] [G loss: 1.150873]\n",
      "epoch:20 step:19405 [D loss: 0.368516, acc.: 83.59%] [G loss: 1.319842]\n",
      "epoch:20 step:19406 [D loss: 0.571644, acc.: 75.00%] [G loss: 1.170126]\n",
      "epoch:20 step:19407 [D loss: 0.535083, acc.: 76.56%] [G loss: 1.046219]\n",
      "epoch:20 step:19408 [D loss: 0.658388, acc.: 60.16%] [G loss: 1.049746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19409 [D loss: 0.615852, acc.: 65.62%] [G loss: 1.133814]\n",
      "epoch:20 step:19410 [D loss: 0.578706, acc.: 70.31%] [G loss: 1.239782]\n",
      "epoch:20 step:19411 [D loss: 0.596618, acc.: 69.53%] [G loss: 1.006920]\n",
      "epoch:20 step:19412 [D loss: 0.550018, acc.: 75.00%] [G loss: 0.992159]\n",
      "epoch:20 step:19413 [D loss: 0.703855, acc.: 57.81%] [G loss: 0.970235]\n",
      "epoch:20 step:19414 [D loss: 0.591875, acc.: 67.97%] [G loss: 0.958259]\n",
      "epoch:20 step:19415 [D loss: 0.707886, acc.: 57.03%] [G loss: 1.072822]\n",
      "epoch:20 step:19416 [D loss: 0.714711, acc.: 57.81%] [G loss: 0.988215]\n",
      "epoch:20 step:19417 [D loss: 0.653028, acc.: 62.50%] [G loss: 0.912549]\n",
      "epoch:20 step:19418 [D loss: 0.864490, acc.: 43.75%] [G loss: 0.878938]\n",
      "epoch:20 step:19419 [D loss: 0.722731, acc.: 53.12%] [G loss: 0.763505]\n",
      "epoch:20 step:19420 [D loss: 0.636454, acc.: 63.28%] [G loss: 0.793245]\n",
      "epoch:20 step:19421 [D loss: 0.713193, acc.: 52.34%] [G loss: 0.801816]\n",
      "epoch:20 step:19422 [D loss: 0.661940, acc.: 60.94%] [G loss: 0.738632]\n",
      "epoch:20 step:19423 [D loss: 0.619308, acc.: 63.28%] [G loss: 0.763864]\n",
      "epoch:20 step:19424 [D loss: 0.609869, acc.: 67.19%] [G loss: 0.947067]\n",
      "epoch:20 step:19425 [D loss: 0.602145, acc.: 71.09%] [G loss: 0.840174]\n",
      "epoch:20 step:19426 [D loss: 0.608422, acc.: 67.19%] [G loss: 1.092156]\n",
      "epoch:20 step:19427 [D loss: 0.655175, acc.: 65.62%] [G loss: 0.881168]\n",
      "epoch:20 step:19428 [D loss: 0.770667, acc.: 49.22%] [G loss: 0.966041]\n",
      "epoch:20 step:19429 [D loss: 0.797073, acc.: 45.31%] [G loss: 0.917087]\n",
      "epoch:20 step:19430 [D loss: 0.788914, acc.: 42.97%] [G loss: 0.756296]\n",
      "epoch:20 step:19431 [D loss: 0.731448, acc.: 53.12%] [G loss: 0.886334]\n",
      "epoch:20 step:19432 [D loss: 0.746337, acc.: 53.12%] [G loss: 0.799706]\n",
      "epoch:20 step:19433 [D loss: 0.701355, acc.: 56.25%] [G loss: 0.822308]\n",
      "epoch:20 step:19434 [D loss: 0.608161, acc.: 70.31%] [G loss: 0.947704]\n",
      "epoch:20 step:19435 [D loss: 0.744836, acc.: 43.75%] [G loss: 0.935382]\n",
      "epoch:20 step:19436 [D loss: 0.448370, acc.: 82.81%] [G loss: 1.082243]\n",
      "epoch:20 step:19437 [D loss: 0.384673, acc.: 88.28%] [G loss: 1.021599]\n",
      "epoch:20 step:19438 [D loss: 0.467015, acc.: 90.62%] [G loss: 1.133270]\n",
      "epoch:20 step:19439 [D loss: 0.579186, acc.: 71.88%] [G loss: 1.000941]\n",
      "epoch:20 step:19440 [D loss: 0.637133, acc.: 66.41%] [G loss: 0.918602]\n",
      "epoch:20 step:19441 [D loss: 0.482825, acc.: 79.69%] [G loss: 0.744544]\n",
      "epoch:20 step:19442 [D loss: 0.484830, acc.: 81.25%] [G loss: 1.058098]\n",
      "epoch:20 step:19443 [D loss: 0.743472, acc.: 53.12%] [G loss: 1.113378]\n",
      "epoch:20 step:19444 [D loss: 0.568291, acc.: 75.00%] [G loss: 0.914033]\n",
      "epoch:20 step:19445 [D loss: 0.678322, acc.: 59.38%] [G loss: 0.527157]\n",
      "epoch:20 step:19446 [D loss: 0.563216, acc.: 66.41%] [G loss: 0.921722]\n",
      "epoch:20 step:19447 [D loss: 0.409650, acc.: 85.16%] [G loss: 1.170692]\n",
      "epoch:20 step:19448 [D loss: 0.336925, acc.: 92.19%] [G loss: 1.216929]\n",
      "epoch:20 step:19449 [D loss: 0.423165, acc.: 77.34%] [G loss: 1.427972]\n",
      "epoch:20 step:19450 [D loss: 0.836712, acc.: 55.47%] [G loss: 1.454525]\n",
      "epoch:20 step:19451 [D loss: 0.719449, acc.: 60.16%] [G loss: 0.960167]\n",
      "epoch:20 step:19452 [D loss: 0.992448, acc.: 30.47%] [G loss: 1.236085]\n",
      "epoch:20 step:19453 [D loss: 0.321515, acc.: 96.09%] [G loss: 1.270420]\n",
      "epoch:20 step:19454 [D loss: 0.342332, acc.: 91.41%] [G loss: 1.298460]\n",
      "epoch:20 step:19455 [D loss: 0.790716, acc.: 53.12%] [G loss: 1.144757]\n",
      "epoch:20 step:19456 [D loss: 0.667681, acc.: 60.16%] [G loss: 0.939858]\n",
      "epoch:20 step:19457 [D loss: 0.688104, acc.: 62.50%] [G loss: 1.184168]\n",
      "epoch:20 step:19458 [D loss: 0.794677, acc.: 43.75%] [G loss: 0.898050]\n",
      "epoch:20 step:19459 [D loss: 0.620632, acc.: 63.28%] [G loss: 1.160946]\n",
      "epoch:20 step:19460 [D loss: 0.641397, acc.: 59.38%] [G loss: 1.247299]\n",
      "epoch:20 step:19461 [D loss: 0.673538, acc.: 59.38%] [G loss: 1.248847]\n",
      "epoch:20 step:19462 [D loss: 0.702472, acc.: 59.38%] [G loss: 1.047258]\n",
      "epoch:20 step:19463 [D loss: 0.647181, acc.: 62.50%] [G loss: 1.081257]\n",
      "epoch:20 step:19464 [D loss: 0.496426, acc.: 75.00%] [G loss: 1.312513]\n",
      "epoch:20 step:19465 [D loss: 0.516193, acc.: 72.66%] [G loss: 1.310815]\n",
      "epoch:20 step:19466 [D loss: 0.450717, acc.: 78.91%] [G loss: 1.329971]\n",
      "epoch:20 step:19467 [D loss: 0.650177, acc.: 60.16%] [G loss: 1.233411]\n",
      "epoch:20 step:19468 [D loss: 0.599620, acc.: 64.06%] [G loss: 0.947460]\n",
      "epoch:20 step:19469 [D loss: 0.590708, acc.: 66.41%] [G loss: 1.097739]\n",
      "epoch:20 step:19470 [D loss: 0.622169, acc.: 67.97%] [G loss: 1.145335]\n",
      "epoch:20 step:19471 [D loss: 0.633138, acc.: 64.84%] [G loss: 0.999847]\n",
      "epoch:20 step:19472 [D loss: 0.523768, acc.: 73.44%] [G loss: 0.856234]\n",
      "epoch:20 step:19473 [D loss: 0.473490, acc.: 81.25%] [G loss: 0.863699]\n",
      "epoch:20 step:19474 [D loss: 0.717083, acc.: 50.78%] [G loss: 1.101755]\n",
      "epoch:20 step:19475 [D loss: 0.580909, acc.: 71.09%] [G loss: 0.976735]\n",
      "epoch:20 step:19476 [D loss: 0.592625, acc.: 67.97%] [G loss: 1.090743]\n",
      "epoch:20 step:19477 [D loss: 0.660724, acc.: 54.69%] [G loss: 1.172508]\n",
      "epoch:20 step:19478 [D loss: 0.756230, acc.: 48.44%] [G loss: 0.960037]\n",
      "epoch:20 step:19479 [D loss: 0.742766, acc.: 54.69%] [G loss: 1.041664]\n",
      "epoch:20 step:19480 [D loss: 0.756104, acc.: 51.56%] [G loss: 0.987960]\n",
      "epoch:20 step:19481 [D loss: 0.468887, acc.: 83.59%] [G loss: 1.178356]\n",
      "epoch:20 step:19482 [D loss: 0.465558, acc.: 77.34%] [G loss: 1.052081]\n",
      "epoch:20 step:19483 [D loss: 0.396925, acc.: 90.62%] [G loss: 1.146776]\n",
      "epoch:20 step:19484 [D loss: 0.536733, acc.: 73.44%] [G loss: 1.222730]\n",
      "epoch:20 step:19485 [D loss: 0.689898, acc.: 60.94%] [G loss: 1.057092]\n",
      "epoch:20 step:19486 [D loss: 0.662850, acc.: 60.16%] [G loss: 1.145723]\n",
      "epoch:20 step:19487 [D loss: 0.673184, acc.: 64.06%] [G loss: 1.105767]\n",
      "epoch:20 step:19488 [D loss: 0.517503, acc.: 78.91%] [G loss: 1.100370]\n",
      "epoch:20 step:19489 [D loss: 0.468179, acc.: 85.16%] [G loss: 1.063078]\n",
      "epoch:20 step:19490 [D loss: 0.447222, acc.: 89.84%] [G loss: 1.103617]\n",
      "epoch:20 step:19491 [D loss: 0.775308, acc.: 51.56%] [G loss: 1.153177]\n",
      "epoch:20 step:19492 [D loss: 0.835100, acc.: 46.09%] [G loss: 0.867475]\n",
      "epoch:20 step:19493 [D loss: 0.906376, acc.: 36.72%] [G loss: 0.891397]\n",
      "epoch:20 step:19494 [D loss: 0.693644, acc.: 50.00%] [G loss: 0.950954]\n",
      "epoch:20 step:19495 [D loss: 0.648055, acc.: 61.72%] [G loss: 0.886031]\n",
      "epoch:20 step:19496 [D loss: 0.588127, acc.: 69.53%] [G loss: 0.920442]\n",
      "epoch:20 step:19497 [D loss: 0.694032, acc.: 53.91%] [G loss: 0.807363]\n",
      "epoch:20 step:19498 [D loss: 0.609969, acc.: 66.41%] [G loss: 1.266085]\n",
      "epoch:20 step:19499 [D loss: 0.643790, acc.: 66.41%] [G loss: 0.793520]\n",
      "epoch:20 step:19500 [D loss: 0.548196, acc.: 77.34%] [G loss: 0.927720]\n",
      "epoch:20 step:19501 [D loss: 0.666658, acc.: 58.59%] [G loss: 0.960178]\n",
      "epoch:20 step:19502 [D loss: 0.729309, acc.: 53.12%] [G loss: 0.960972]\n",
      "epoch:20 step:19503 [D loss: 0.669415, acc.: 60.16%] [G loss: 0.844530]\n",
      "epoch:20 step:19504 [D loss: 0.702356, acc.: 50.78%] [G loss: 0.897829]\n",
      "epoch:20 step:19505 [D loss: 0.632988, acc.: 64.84%] [G loss: 0.834229]\n",
      "epoch:20 step:19506 [D loss: 0.612305, acc.: 63.28%] [G loss: 0.860814]\n",
      "epoch:20 step:19507 [D loss: 0.660038, acc.: 57.81%] [G loss: 0.873389]\n",
      "epoch:20 step:19508 [D loss: 0.457317, acc.: 84.38%] [G loss: 0.889000]\n",
      "epoch:20 step:19509 [D loss: 0.441274, acc.: 86.72%] [G loss: 1.004309]\n",
      "epoch:20 step:19510 [D loss: 0.673236, acc.: 55.47%] [G loss: 0.891847]\n",
      "epoch:20 step:19511 [D loss: 0.659999, acc.: 56.25%] [G loss: 0.930651]\n",
      "epoch:20 step:19512 [D loss: 0.733608, acc.: 48.44%] [G loss: 0.785525]\n",
      "epoch:20 step:19513 [D loss: 0.629014, acc.: 68.75%] [G loss: 0.828708]\n",
      "epoch:20 step:19514 [D loss: 0.533202, acc.: 74.22%] [G loss: 0.944038]\n",
      "epoch:20 step:19515 [D loss: 0.428815, acc.: 89.06%] [G loss: 1.081771]\n",
      "epoch:20 step:19516 [D loss: 0.673787, acc.: 57.81%] [G loss: 0.926473]\n",
      "epoch:20 step:19517 [D loss: 0.567685, acc.: 71.88%] [G loss: 0.890102]\n",
      "epoch:20 step:19518 [D loss: 0.725779, acc.: 51.56%] [G loss: 0.935696]\n",
      "epoch:20 step:19519 [D loss: 0.675193, acc.: 54.69%] [G loss: 0.901844]\n",
      "epoch:20 step:19520 [D loss: 0.550472, acc.: 73.44%] [G loss: 0.853941]\n",
      "epoch:20 step:19521 [D loss: 0.445581, acc.: 79.69%] [G loss: 1.012044]\n",
      "epoch:20 step:19522 [D loss: 0.639182, acc.: 62.50%] [G loss: 1.048061]\n",
      "epoch:20 step:19523 [D loss: 0.629309, acc.: 63.28%] [G loss: 0.990551]\n",
      "epoch:20 step:19524 [D loss: 0.696356, acc.: 52.34%] [G loss: 0.870282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19525 [D loss: 0.626165, acc.: 68.75%] [G loss: 0.879231]\n",
      "epoch:20 step:19526 [D loss: 0.498511, acc.: 76.56%] [G loss: 0.984165]\n",
      "epoch:20 step:19527 [D loss: 0.661641, acc.: 63.28%] [G loss: 0.908130]\n",
      "epoch:20 step:19528 [D loss: 0.651511, acc.: 60.94%] [G loss: 0.850052]\n",
      "epoch:20 step:19529 [D loss: 0.701882, acc.: 54.69%] [G loss: 1.064563]\n",
      "epoch:20 step:19530 [D loss: 0.655323, acc.: 63.28%] [G loss: 1.007091]\n",
      "epoch:20 step:19531 [D loss: 0.544311, acc.: 67.97%] [G loss: 1.119247]\n",
      "epoch:20 step:19532 [D loss: 0.337701, acc.: 85.16%] [G loss: 1.102848]\n",
      "epoch:20 step:19533 [D loss: 0.344446, acc.: 89.06%] [G loss: 1.355846]\n",
      "epoch:20 step:19534 [D loss: 0.341396, acc.: 91.41%] [G loss: 1.314517]\n",
      "epoch:20 step:19535 [D loss: 0.551535, acc.: 75.78%] [G loss: 1.148967]\n",
      "epoch:20 step:19536 [D loss: 0.535916, acc.: 71.88%] [G loss: 1.051122]\n",
      "epoch:20 step:19537 [D loss: 0.861620, acc.: 37.50%] [G loss: 1.251823]\n",
      "epoch:20 step:19538 [D loss: 0.512950, acc.: 75.78%] [G loss: 1.260412]\n",
      "epoch:20 step:19539 [D loss: 0.761959, acc.: 50.00%] [G loss: 1.197984]\n",
      "epoch:20 step:19540 [D loss: 0.580447, acc.: 74.22%] [G loss: 0.985599]\n",
      "epoch:20 step:19541 [D loss: 0.560454, acc.: 70.31%] [G loss: 1.133406]\n",
      "epoch:20 step:19542 [D loss: 0.358539, acc.: 89.06%] [G loss: 1.172783]\n",
      "epoch:20 step:19543 [D loss: 0.669178, acc.: 60.16%] [G loss: 1.080811]\n",
      "epoch:20 step:19544 [D loss: 0.379938, acc.: 89.84%] [G loss: 1.029242]\n",
      "epoch:20 step:19545 [D loss: 0.582596, acc.: 67.97%] [G loss: 1.198159]\n",
      "epoch:20 step:19546 [D loss: 0.347264, acc.: 83.59%] [G loss: 0.907821]\n",
      "epoch:20 step:19547 [D loss: 0.936790, acc.: 31.25%] [G loss: 1.342462]\n",
      "epoch:20 step:19548 [D loss: 0.550164, acc.: 70.31%] [G loss: 1.357390]\n",
      "epoch:20 step:19549 [D loss: 0.617287, acc.: 63.28%] [G loss: 1.403350]\n",
      "epoch:20 step:19550 [D loss: 0.538184, acc.: 71.09%] [G loss: 1.311552]\n",
      "epoch:20 step:19551 [D loss: 0.740825, acc.: 49.22%] [G loss: 1.222766]\n",
      "epoch:20 step:19552 [D loss: 0.721487, acc.: 50.00%] [G loss: 0.964938]\n",
      "epoch:20 step:19553 [D loss: 0.622904, acc.: 64.84%] [G loss: 1.043413]\n",
      "epoch:20 step:19554 [D loss: 0.650465, acc.: 54.69%] [G loss: 0.932862]\n",
      "epoch:20 step:19555 [D loss: 0.333608, acc.: 94.53%] [G loss: 1.289805]\n",
      "epoch:20 step:19556 [D loss: 0.386446, acc.: 92.19%] [G loss: 1.085530]\n",
      "epoch:20 step:19557 [D loss: 0.600528, acc.: 64.84%] [G loss: 0.920041]\n",
      "epoch:20 step:19558 [D loss: 0.555023, acc.: 70.31%] [G loss: 0.994251]\n",
      "epoch:20 step:19559 [D loss: 0.503953, acc.: 75.00%] [G loss: 0.920157]\n",
      "epoch:20 step:19560 [D loss: 0.772388, acc.: 45.31%] [G loss: 0.953358]\n",
      "epoch:20 step:19561 [D loss: 0.810679, acc.: 50.00%] [G loss: 1.068963]\n",
      "epoch:20 step:19562 [D loss: 0.774495, acc.: 46.88%] [G loss: 0.723635]\n",
      "epoch:20 step:19563 [D loss: 0.750345, acc.: 44.53%] [G loss: 0.839528]\n",
      "epoch:20 step:19564 [D loss: 0.575649, acc.: 65.62%] [G loss: 0.556403]\n",
      "epoch:20 step:19565 [D loss: 0.496325, acc.: 77.34%] [G loss: 0.808253]\n",
      "epoch:20 step:19566 [D loss: 0.647563, acc.: 61.72%] [G loss: 1.104656]\n",
      "epoch:20 step:19567 [D loss: 0.748129, acc.: 53.12%] [G loss: 0.774647]\n",
      "epoch:20 step:19568 [D loss: 0.716811, acc.: 50.00%] [G loss: 0.777996]\n",
      "epoch:20 step:19569 [D loss: 0.631653, acc.: 58.59%] [G loss: 0.756836]\n",
      "epoch:20 step:19570 [D loss: 0.681572, acc.: 59.38%] [G loss: 0.605925]\n",
      "epoch:20 step:19571 [D loss: 0.559330, acc.: 68.75%] [G loss: 1.060115]\n",
      "epoch:20 step:19572 [D loss: 0.488708, acc.: 71.09%] [G loss: 1.117190]\n",
      "epoch:20 step:19573 [D loss: 0.519299, acc.: 74.22%] [G loss: 1.129753]\n",
      "epoch:20 step:19574 [D loss: 0.729659, acc.: 55.47%] [G loss: 1.237263]\n",
      "epoch:20 step:19575 [D loss: 0.799926, acc.: 38.28%] [G loss: 1.161932]\n",
      "epoch:20 step:19576 [D loss: 0.767429, acc.: 42.19%] [G loss: 1.108164]\n",
      "epoch:20 step:19577 [D loss: 0.740461, acc.: 48.44%] [G loss: 0.956877]\n",
      "epoch:20 step:19578 [D loss: 0.792852, acc.: 45.31%] [G loss: 0.879418]\n",
      "epoch:20 step:19579 [D loss: 0.749812, acc.: 43.75%] [G loss: 0.989342]\n",
      "epoch:20 step:19580 [D loss: 0.719588, acc.: 50.00%] [G loss: 0.992306]\n",
      "epoch:20 step:19581 [D loss: 0.704985, acc.: 50.78%] [G loss: 0.812740]\n",
      "epoch:20 step:19582 [D loss: 0.622426, acc.: 64.84%] [G loss: 0.866599]\n",
      "epoch:20 step:19583 [D loss: 0.641260, acc.: 57.03%] [G loss: 0.964466]\n",
      "epoch:20 step:19584 [D loss: 0.607482, acc.: 63.28%] [G loss: 0.825550]\n",
      "epoch:20 step:19585 [D loss: 0.446345, acc.: 83.59%] [G loss: 0.966073]\n",
      "epoch:20 step:19586 [D loss: 0.687725, acc.: 57.03%] [G loss: 0.818576]\n",
      "epoch:20 step:19587 [D loss: 0.614944, acc.: 62.50%] [G loss: 0.944954]\n",
      "epoch:20 step:19588 [D loss: 0.789458, acc.: 37.50%] [G loss: 0.928686]\n",
      "epoch:20 step:19589 [D loss: 0.637765, acc.: 62.50%] [G loss: 0.957911]\n",
      "epoch:20 step:19590 [D loss: 0.685843, acc.: 56.25%] [G loss: 0.945008]\n",
      "epoch:20 step:19591 [D loss: 0.471014, acc.: 80.47%] [G loss: 0.983992]\n",
      "epoch:20 step:19592 [D loss: 0.473087, acc.: 80.47%] [G loss: 0.988760]\n",
      "epoch:20 step:19593 [D loss: 0.466946, acc.: 84.38%] [G loss: 1.038751]\n",
      "epoch:20 step:19594 [D loss: 0.386734, acc.: 89.84%] [G loss: 1.171067]\n",
      "epoch:20 step:19595 [D loss: 0.541550, acc.: 78.12%] [G loss: 1.064603]\n",
      "epoch:20 step:19596 [D loss: 0.702537, acc.: 61.72%] [G loss: 0.988955]\n",
      "epoch:20 step:19597 [D loss: 0.425320, acc.: 89.06%] [G loss: 1.059377]\n",
      "epoch:20 step:19598 [D loss: 0.663868, acc.: 59.38%] [G loss: 1.207039]\n",
      "epoch:20 step:19599 [D loss: 0.592048, acc.: 71.88%] [G loss: 0.966405]\n",
      "epoch:20 step:19600 [D loss: 0.570430, acc.: 73.44%] [G loss: 0.910995]\n",
      "epoch:20 step:19601 [D loss: 0.716846, acc.: 55.47%] [G loss: 0.966712]\n",
      "epoch:20 step:19602 [D loss: 0.685074, acc.: 57.03%] [G loss: 0.996905]\n",
      "epoch:20 step:19603 [D loss: 0.690131, acc.: 58.59%] [G loss: 1.027201]\n",
      "epoch:20 step:19604 [D loss: 0.805178, acc.: 45.31%] [G loss: 1.077474]\n",
      "epoch:20 step:19605 [D loss: 0.625003, acc.: 67.97%] [G loss: 1.079361]\n",
      "epoch:20 step:19606 [D loss: 0.570976, acc.: 75.78%] [G loss: 0.940277]\n",
      "epoch:20 step:19607 [D loss: 0.453701, acc.: 82.81%] [G loss: 1.013187]\n",
      "epoch:20 step:19608 [D loss: 0.661820, acc.: 56.25%] [G loss: 0.740835]\n",
      "epoch:20 step:19609 [D loss: 0.688405, acc.: 61.72%] [G loss: 0.973624]\n",
      "epoch:20 step:19610 [D loss: 0.679177, acc.: 59.38%] [G loss: 1.038461]\n",
      "epoch:20 step:19611 [D loss: 0.541049, acc.: 75.78%] [G loss: 0.891500]\n",
      "epoch:20 step:19612 [D loss: 0.528469, acc.: 76.56%] [G loss: 0.800721]\n",
      "epoch:20 step:19613 [D loss: 0.614625, acc.: 67.19%] [G loss: 0.921884]\n",
      "epoch:20 step:19614 [D loss: 0.591039, acc.: 71.09%] [G loss: 0.944539]\n",
      "epoch:20 step:19615 [D loss: 0.552311, acc.: 71.88%] [G loss: 0.954748]\n",
      "epoch:20 step:19616 [D loss: 0.749612, acc.: 47.66%] [G loss: 0.980029]\n",
      "epoch:20 step:19617 [D loss: 0.688449, acc.: 58.59%] [G loss: 0.875649]\n",
      "epoch:20 step:19618 [D loss: 0.598563, acc.: 71.88%] [G loss: 1.039157]\n",
      "epoch:20 step:19619 [D loss: 0.652835, acc.: 59.38%] [G loss: 0.956327]\n",
      "epoch:20 step:19620 [D loss: 0.596307, acc.: 67.97%] [G loss: 0.529623]\n",
      "epoch:20 step:19621 [D loss: 0.708960, acc.: 55.47%] [G loss: 0.854197]\n",
      "epoch:20 step:19622 [D loss: 0.391465, acc.: 85.94%] [G loss: 1.007984]\n",
      "epoch:20 step:19623 [D loss: 0.439924, acc.: 81.25%] [G loss: 0.776703]\n",
      "epoch:20 step:19624 [D loss: 0.478114, acc.: 71.09%] [G loss: 1.287222]\n",
      "epoch:20 step:19625 [D loss: 0.258394, acc.: 94.53%] [G loss: 1.280128]\n",
      "epoch:20 step:19626 [D loss: 0.402919, acc.: 81.25%] [G loss: 1.195359]\n",
      "epoch:20 step:19627 [D loss: 0.295884, acc.: 87.50%] [G loss: 1.574359]\n",
      "epoch:20 step:19628 [D loss: 0.785824, acc.: 49.22%] [G loss: 1.680943]\n",
      "epoch:20 step:19629 [D loss: 0.366021, acc.: 87.50%] [G loss: 1.528198]\n",
      "epoch:20 step:19630 [D loss: 0.631227, acc.: 64.06%] [G loss: 1.053870]\n",
      "epoch:20 step:19631 [D loss: 0.860633, acc.: 42.97%] [G loss: 1.388352]\n",
      "epoch:20 step:19632 [D loss: 0.719214, acc.: 57.81%] [G loss: 1.003122]\n",
      "epoch:20 step:19633 [D loss: 0.832461, acc.: 42.97%] [G loss: 0.482425]\n",
      "epoch:20 step:19634 [D loss: 1.224541, acc.: 16.41%] [G loss: 0.588408]\n",
      "epoch:20 step:19635 [D loss: 0.728357, acc.: 53.91%] [G loss: 1.179327]\n",
      "epoch:20 step:19636 [D loss: 0.779449, acc.: 41.41%] [G loss: 0.805834]\n",
      "epoch:20 step:19637 [D loss: 0.556120, acc.: 70.31%] [G loss: 1.181828]\n",
      "epoch:20 step:19638 [D loss: 0.506984, acc.: 74.22%] [G loss: 1.206222]\n",
      "epoch:20 step:19639 [D loss: 0.323034, acc.: 94.53%] [G loss: 1.428231]\n",
      "epoch:20 step:19640 [D loss: 0.362987, acc.: 86.72%] [G loss: 1.315491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19641 [D loss: 0.487210, acc.: 76.56%] [G loss: 1.431950]\n",
      "epoch:20 step:19642 [D loss: 0.597060, acc.: 66.41%] [G loss: 1.131816]\n",
      "epoch:20 step:19643 [D loss: 0.546434, acc.: 68.75%] [G loss: 1.277972]\n",
      "epoch:20 step:19644 [D loss: 0.751273, acc.: 57.81%] [G loss: 1.216103]\n",
      "epoch:20 step:19645 [D loss: 0.604409, acc.: 65.62%] [G loss: 1.067788]\n",
      "epoch:20 step:19646 [D loss: 0.584198, acc.: 69.53%] [G loss: 1.023299]\n",
      "epoch:20 step:19647 [D loss: 0.702349, acc.: 57.81%] [G loss: 0.984141]\n",
      "epoch:20 step:19648 [D loss: 0.643499, acc.: 66.41%] [G loss: 0.995489]\n",
      "epoch:20 step:19649 [D loss: 0.456256, acc.: 83.59%] [G loss: 0.895249]\n",
      "epoch:20 step:19650 [D loss: 0.774423, acc.: 46.88%] [G loss: 0.966576]\n",
      "epoch:20 step:19651 [D loss: 0.439774, acc.: 82.03%] [G loss: 1.031684]\n",
      "epoch:20 step:19652 [D loss: 0.284673, acc.: 89.06%] [G loss: 1.240681]\n",
      "epoch:20 step:19653 [D loss: 0.579661, acc.: 67.19%] [G loss: 1.186131]\n",
      "epoch:20 step:19654 [D loss: 0.712861, acc.: 54.69%] [G loss: 1.152486]\n",
      "epoch:20 step:19655 [D loss: 0.564994, acc.: 71.09%] [G loss: 1.229365]\n",
      "epoch:20 step:19656 [D loss: 0.680072, acc.: 52.34%] [G loss: 1.045594]\n",
      "epoch:20 step:19657 [D loss: 0.635345, acc.: 67.19%] [G loss: 1.187255]\n",
      "epoch:20 step:19658 [D loss: 0.437062, acc.: 83.59%] [G loss: 0.781455]\n",
      "epoch:20 step:19659 [D loss: 0.270646, acc.: 89.84%] [G loss: 0.845123]\n",
      "epoch:20 step:19660 [D loss: 0.791762, acc.: 42.19%] [G loss: 1.054308]\n",
      "epoch:20 step:19661 [D loss: 0.731354, acc.: 54.69%] [G loss: 0.798514]\n",
      "epoch:20 step:19662 [D loss: 0.536352, acc.: 75.00%] [G loss: 1.090387]\n",
      "epoch:20 step:19663 [D loss: 0.403768, acc.: 93.75%] [G loss: 0.771203]\n",
      "epoch:20 step:19664 [D loss: 0.277141, acc.: 88.28%] [G loss: 1.223824]\n",
      "epoch:20 step:19665 [D loss: 0.260833, acc.: 96.88%] [G loss: 1.281606]\n",
      "epoch:20 step:19666 [D loss: 0.188289, acc.: 97.66%] [G loss: 1.305714]\n",
      "epoch:20 step:19667 [D loss: 0.208642, acc.: 93.75%] [G loss: 1.401862]\n",
      "epoch:20 step:19668 [D loss: 0.687830, acc.: 55.47%] [G loss: 1.351601]\n",
      "epoch:20 step:19669 [D loss: 0.466371, acc.: 77.34%] [G loss: 1.283252]\n",
      "epoch:20 step:19670 [D loss: 0.738865, acc.: 50.00%] [G loss: 1.200621]\n",
      "epoch:20 step:19671 [D loss: 0.612083, acc.: 71.09%] [G loss: 1.016850]\n",
      "epoch:20 step:19672 [D loss: 0.382775, acc.: 88.28%] [G loss: 1.121971]\n",
      "epoch:20 step:19673 [D loss: 0.300854, acc.: 89.84%] [G loss: 1.390253]\n",
      "epoch:20 step:19674 [D loss: 0.264862, acc.: 89.06%] [G loss: 1.309562]\n",
      "epoch:20 step:19675 [D loss: 0.264686, acc.: 96.09%] [G loss: 1.436222]\n",
      "epoch:20 step:19676 [D loss: 0.254447, acc.: 89.84%] [G loss: 1.421913]\n",
      "epoch:20 step:19677 [D loss: 0.140078, acc.: 99.22%] [G loss: 1.095434]\n",
      "epoch:21 step:19678 [D loss: 0.623230, acc.: 72.66%] [G loss: 1.720223]\n",
      "epoch:21 step:19679 [D loss: 0.617145, acc.: 66.41%] [G loss: 1.334565]\n",
      "epoch:21 step:19680 [D loss: 0.736752, acc.: 57.81%] [G loss: 0.675606]\n",
      "epoch:21 step:19681 [D loss: 0.822368, acc.: 40.62%] [G loss: 1.259219]\n",
      "epoch:21 step:19682 [D loss: 0.672306, acc.: 60.16%] [G loss: 0.663622]\n",
      "epoch:21 step:19683 [D loss: 0.679428, acc.: 64.06%] [G loss: 0.967013]\n",
      "epoch:21 step:19684 [D loss: 0.543931, acc.: 70.31%] [G loss: 0.580019]\n",
      "epoch:21 step:19685 [D loss: 1.025262, acc.: 45.31%] [G loss: 0.727259]\n",
      "epoch:21 step:19686 [D loss: 0.518356, acc.: 80.47%] [G loss: 1.354386]\n",
      "epoch:21 step:19687 [D loss: 0.445324, acc.: 84.38%] [G loss: 1.592936]\n",
      "epoch:21 step:19688 [D loss: 0.763305, acc.: 53.12%] [G loss: 0.997490]\n",
      "epoch:21 step:19689 [D loss: 0.759292, acc.: 55.47%] [G loss: 1.096602]\n",
      "epoch:21 step:19690 [D loss: 0.723397, acc.: 58.59%] [G loss: 1.057275]\n",
      "epoch:21 step:19691 [D loss: 0.889282, acc.: 46.88%] [G loss: 1.077228]\n",
      "epoch:21 step:19692 [D loss: 0.567854, acc.: 74.22%] [G loss: 1.119593]\n",
      "epoch:21 step:19693 [D loss: 0.704515, acc.: 57.81%] [G loss: 0.399542]\n",
      "epoch:21 step:19694 [D loss: 0.954066, acc.: 26.56%] [G loss: 0.783616]\n",
      "epoch:21 step:19695 [D loss: 0.782578, acc.: 43.75%] [G loss: 0.972061]\n",
      "epoch:21 step:19696 [D loss: 0.853845, acc.: 32.03%] [G loss: 1.115843]\n",
      "epoch:21 step:19697 [D loss: 0.945141, acc.: 28.91%] [G loss: 0.978194]\n",
      "epoch:21 step:19698 [D loss: 0.771448, acc.: 54.69%] [G loss: 1.219754]\n",
      "epoch:21 step:19699 [D loss: 0.751260, acc.: 55.47%] [G loss: 1.212266]\n",
      "epoch:21 step:19700 [D loss: 0.680844, acc.: 58.59%] [G loss: 1.033980]\n",
      "epoch:21 step:19701 [D loss: 0.793296, acc.: 46.09%] [G loss: 1.053483]\n",
      "epoch:21 step:19702 [D loss: 0.741129, acc.: 50.00%] [G loss: 1.132931]\n",
      "epoch:21 step:19703 [D loss: 0.670938, acc.: 50.78%] [G loss: 1.138530]\n",
      "epoch:21 step:19704 [D loss: 0.581656, acc.: 67.97%] [G loss: 1.417954]\n",
      "epoch:21 step:19705 [D loss: 0.653294, acc.: 55.47%] [G loss: 1.823859]\n",
      "epoch:21 step:19706 [D loss: 0.575321, acc.: 71.09%] [G loss: 1.066661]\n",
      "epoch:21 step:19707 [D loss: 0.619697, acc.: 65.62%] [G loss: 1.201546]\n",
      "epoch:21 step:19708 [D loss: 0.575263, acc.: 70.31%] [G loss: 1.326797]\n",
      "epoch:21 step:19709 [D loss: 0.514800, acc.: 72.66%] [G loss: 1.229494]\n",
      "epoch:21 step:19710 [D loss: 0.422797, acc.: 86.72%] [G loss: 1.133190]\n",
      "epoch:21 step:19711 [D loss: 0.435067, acc.: 82.81%] [G loss: 1.098674]\n",
      "epoch:21 step:19712 [D loss: 0.311456, acc.: 92.97%] [G loss: 1.323964]\n",
      "epoch:21 step:19713 [D loss: 0.360053, acc.: 88.28%] [G loss: 1.463059]\n",
      "epoch:21 step:19714 [D loss: 0.698869, acc.: 57.03%] [G loss: 1.180059]\n",
      "epoch:21 step:19715 [D loss: 0.945868, acc.: 53.91%] [G loss: 0.902766]\n",
      "epoch:21 step:19716 [D loss: 0.749274, acc.: 52.34%] [G loss: 1.093505]\n",
      "epoch:21 step:19717 [D loss: 0.667171, acc.: 67.19%] [G loss: 0.842161]\n",
      "epoch:21 step:19718 [D loss: 0.582604, acc.: 69.53%] [G loss: 0.869254]\n",
      "epoch:21 step:19719 [D loss: 0.574407, acc.: 69.53%] [G loss: 0.825190]\n",
      "epoch:21 step:19720 [D loss: 0.462802, acc.: 85.16%] [G loss: 0.943856]\n",
      "epoch:21 step:19721 [D loss: 0.547475, acc.: 74.22%] [G loss: 0.910973]\n",
      "epoch:21 step:19722 [D loss: 0.682166, acc.: 53.91%] [G loss: 0.881678]\n",
      "epoch:21 step:19723 [D loss: 0.662554, acc.: 57.03%] [G loss: 0.921826]\n",
      "epoch:21 step:19724 [D loss: 0.655433, acc.: 57.03%] [G loss: 1.043102]\n",
      "epoch:21 step:19725 [D loss: 0.606900, acc.: 67.97%] [G loss: 0.769528]\n",
      "epoch:21 step:19726 [D loss: 0.647304, acc.: 66.41%] [G loss: 0.900010]\n",
      "epoch:21 step:19727 [D loss: 0.596618, acc.: 66.41%] [G loss: 0.811363]\n",
      "epoch:21 step:19728 [D loss: 0.684533, acc.: 58.59%] [G loss: 0.837794]\n",
      "epoch:21 step:19729 [D loss: 0.892995, acc.: 46.88%] [G loss: 1.068442]\n",
      "epoch:21 step:19730 [D loss: 0.609393, acc.: 67.97%] [G loss: 1.002964]\n",
      "epoch:21 step:19731 [D loss: 0.645431, acc.: 63.28%] [G loss: 1.028059]\n",
      "epoch:21 step:19732 [D loss: 0.657189, acc.: 55.47%] [G loss: 0.924896]\n",
      "epoch:21 step:19733 [D loss: 0.586143, acc.: 71.09%] [G loss: 0.980082]\n",
      "epoch:21 step:19734 [D loss: 0.476777, acc.: 81.25%] [G loss: 0.976020]\n",
      "epoch:21 step:19735 [D loss: 0.517635, acc.: 75.78%] [G loss: 1.038294]\n",
      "epoch:21 step:19736 [D loss: 0.429500, acc.: 84.38%] [G loss: 0.924768]\n",
      "epoch:21 step:19737 [D loss: 0.435168, acc.: 82.03%] [G loss: 1.027692]\n",
      "epoch:21 step:19738 [D loss: 0.590059, acc.: 67.97%] [G loss: 0.922942]\n",
      "epoch:21 step:19739 [D loss: 0.569492, acc.: 69.53%] [G loss: 0.889577]\n",
      "epoch:21 step:19740 [D loss: 0.514681, acc.: 73.44%] [G loss: 0.857894]\n",
      "epoch:21 step:19741 [D loss: 0.788885, acc.: 46.09%] [G loss: 1.100573]\n",
      "epoch:21 step:19742 [D loss: 0.928957, acc.: 32.03%] [G loss: 1.060669]\n",
      "epoch:21 step:19743 [D loss: 0.615588, acc.: 70.31%] [G loss: 1.099535]\n",
      "epoch:21 step:19744 [D loss: 0.836120, acc.: 45.31%] [G loss: 0.990110]\n",
      "epoch:21 step:19745 [D loss: 0.820353, acc.: 49.22%] [G loss: 0.993725]\n",
      "epoch:21 step:19746 [D loss: 0.763380, acc.: 53.12%] [G loss: 0.850116]\n",
      "epoch:21 step:19747 [D loss: 0.711734, acc.: 53.12%] [G loss: 0.951965]\n",
      "epoch:21 step:19748 [D loss: 0.316201, acc.: 92.97%] [G loss: 0.939540]\n",
      "epoch:21 step:19749 [D loss: 0.397086, acc.: 85.16%] [G loss: 0.942009]\n",
      "epoch:21 step:19750 [D loss: 0.479446, acc.: 81.25%] [G loss: 0.940473]\n",
      "epoch:21 step:19751 [D loss: 0.587917, acc.: 74.22%] [G loss: 0.774374]\n",
      "epoch:21 step:19752 [D loss: 0.414608, acc.: 75.78%] [G loss: 1.134987]\n",
      "epoch:21 step:19753 [D loss: 0.328183, acc.: 89.06%] [G loss: 1.479134]\n",
      "epoch:21 step:19754 [D loss: 0.388956, acc.: 89.84%] [G loss: 1.548220]\n",
      "epoch:21 step:19755 [D loss: 0.866139, acc.: 50.78%] [G loss: 1.241106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19756 [D loss: 0.693766, acc.: 60.94%] [G loss: 1.341560]\n",
      "epoch:21 step:19757 [D loss: 0.754819, acc.: 55.47%] [G loss: 1.003945]\n",
      "epoch:21 step:19758 [D loss: 0.827603, acc.: 37.50%] [G loss: 0.998147]\n",
      "epoch:21 step:19759 [D loss: 0.791786, acc.: 46.88%] [G loss: 1.011248]\n",
      "epoch:21 step:19760 [D loss: 0.729802, acc.: 46.88%] [G loss: 1.066932]\n",
      "epoch:21 step:19761 [D loss: 0.712894, acc.: 54.69%] [G loss: 0.897817]\n",
      "epoch:21 step:19762 [D loss: 0.709984, acc.: 57.81%] [G loss: 0.976358]\n",
      "epoch:21 step:19763 [D loss: 0.720514, acc.: 55.47%] [G loss: 0.939431]\n",
      "epoch:21 step:19764 [D loss: 0.815637, acc.: 37.50%] [G loss: 0.734538]\n",
      "epoch:21 step:19765 [D loss: 0.668843, acc.: 57.81%] [G loss: 0.920848]\n",
      "epoch:21 step:19766 [D loss: 0.672702, acc.: 58.59%] [G loss: 1.007356]\n",
      "epoch:21 step:19767 [D loss: 0.661268, acc.: 57.81%] [G loss: 0.982469]\n",
      "epoch:21 step:19768 [D loss: 0.690278, acc.: 52.34%] [G loss: 1.071894]\n",
      "epoch:21 step:19769 [D loss: 0.579901, acc.: 65.62%] [G loss: 1.179910]\n",
      "epoch:21 step:19770 [D loss: 0.542605, acc.: 77.34%] [G loss: 1.082011]\n",
      "epoch:21 step:19771 [D loss: 0.552229, acc.: 73.44%] [G loss: 1.058456]\n",
      "epoch:21 step:19772 [D loss: 0.638487, acc.: 63.28%] [G loss: 0.973328]\n",
      "epoch:21 step:19773 [D loss: 0.633373, acc.: 65.62%] [G loss: 1.057443]\n",
      "epoch:21 step:19774 [D loss: 0.664977, acc.: 57.81%] [G loss: 1.154764]\n",
      "epoch:21 step:19775 [D loss: 0.806326, acc.: 42.19%] [G loss: 1.042566]\n",
      "epoch:21 step:19776 [D loss: 0.577007, acc.: 71.88%] [G loss: 1.162812]\n",
      "epoch:21 step:19777 [D loss: 0.544695, acc.: 76.56%] [G loss: 0.991892]\n",
      "epoch:21 step:19778 [D loss: 0.599410, acc.: 65.62%] [G loss: 1.018209]\n",
      "epoch:21 step:19779 [D loss: 0.665319, acc.: 62.50%] [G loss: 1.046400]\n",
      "epoch:21 step:19780 [D loss: 0.625585, acc.: 61.72%] [G loss: 1.152686]\n",
      "epoch:21 step:19781 [D loss: 0.682455, acc.: 55.47%] [G loss: 1.062110]\n",
      "epoch:21 step:19782 [D loss: 0.714878, acc.: 58.59%] [G loss: 0.900308]\n",
      "epoch:21 step:19783 [D loss: 0.605675, acc.: 64.84%] [G loss: 0.927436]\n",
      "epoch:21 step:19784 [D loss: 0.660576, acc.: 61.72%] [G loss: 1.052414]\n",
      "epoch:21 step:19785 [D loss: 0.709235, acc.: 51.56%] [G loss: 1.050485]\n",
      "epoch:21 step:19786 [D loss: 0.661751, acc.: 58.59%] [G loss: 0.843867]\n",
      "epoch:21 step:19787 [D loss: 0.664322, acc.: 58.59%] [G loss: 1.019723]\n",
      "epoch:21 step:19788 [D loss: 0.590955, acc.: 65.62%] [G loss: 0.904416]\n",
      "epoch:21 step:19789 [D loss: 0.561169, acc.: 73.44%] [G loss: 0.914174]\n",
      "epoch:21 step:19790 [D loss: 0.524519, acc.: 75.78%] [G loss: 0.905029]\n",
      "epoch:21 step:19791 [D loss: 0.563792, acc.: 70.31%] [G loss: 1.039804]\n",
      "epoch:21 step:19792 [D loss: 0.500963, acc.: 81.25%] [G loss: 0.971223]\n",
      "epoch:21 step:19793 [D loss: 0.672729, acc.: 55.47%] [G loss: 0.986898]\n",
      "epoch:21 step:19794 [D loss: 0.764774, acc.: 48.44%] [G loss: 1.002285]\n",
      "epoch:21 step:19795 [D loss: 0.766031, acc.: 48.44%] [G loss: 0.797376]\n",
      "epoch:21 step:19796 [D loss: 0.519146, acc.: 75.00%] [G loss: 0.896563]\n",
      "epoch:21 step:19797 [D loss: 0.585527, acc.: 70.31%] [G loss: 0.795302]\n",
      "epoch:21 step:19798 [D loss: 0.402975, acc.: 85.16%] [G loss: 1.120160]\n",
      "epoch:21 step:19799 [D loss: 0.416105, acc.: 92.19%] [G loss: 1.067372]\n",
      "epoch:21 step:19800 [D loss: 0.575530, acc.: 67.19%] [G loss: 1.086948]\n",
      "epoch:21 step:19801 [D loss: 0.680236, acc.: 59.38%] [G loss: 1.265737]\n",
      "epoch:21 step:19802 [D loss: 0.675407, acc.: 56.25%] [G loss: 1.146728]\n",
      "epoch:21 step:19803 [D loss: 0.622427, acc.: 61.72%] [G loss: 1.019285]\n",
      "epoch:21 step:19804 [D loss: 0.685907, acc.: 57.03%] [G loss: 0.987163]\n",
      "epoch:21 step:19805 [D loss: 0.592162, acc.: 67.97%] [G loss: 0.988411]\n",
      "epoch:21 step:19806 [D loss: 0.416884, acc.: 85.94%] [G loss: 1.065662]\n",
      "epoch:21 step:19807 [D loss: 0.451237, acc.: 72.66%] [G loss: 1.128989]\n",
      "epoch:21 step:19808 [D loss: 0.411356, acc.: 87.50%] [G loss: 0.887092]\n",
      "epoch:21 step:19809 [D loss: 0.465468, acc.: 82.81%] [G loss: 1.038545]\n",
      "epoch:21 step:19810 [D loss: 0.872285, acc.: 33.59%] [G loss: 0.935380]\n",
      "epoch:21 step:19811 [D loss: 0.736936, acc.: 51.56%] [G loss: 1.022973]\n",
      "epoch:21 step:19812 [D loss: 0.642231, acc.: 67.97%] [G loss: 1.147115]\n",
      "epoch:21 step:19813 [D loss: 0.763683, acc.: 49.22%] [G loss: 1.007918]\n",
      "epoch:21 step:19814 [D loss: 0.647120, acc.: 55.47%] [G loss: 0.797293]\n",
      "epoch:21 step:19815 [D loss: 0.616827, acc.: 65.62%] [G loss: 0.789775]\n",
      "epoch:21 step:19816 [D loss: 0.544691, acc.: 72.66%] [G loss: 0.920126]\n",
      "epoch:21 step:19817 [D loss: 0.770156, acc.: 43.75%] [G loss: 0.985979]\n",
      "epoch:21 step:19818 [D loss: 0.768491, acc.: 50.00%] [G loss: 1.054462]\n",
      "epoch:21 step:19819 [D loss: 0.842737, acc.: 33.59%] [G loss: 1.047732]\n",
      "epoch:21 step:19820 [D loss: 0.736649, acc.: 53.12%] [G loss: 0.926502]\n",
      "epoch:21 step:19821 [D loss: 0.634844, acc.: 64.84%] [G loss: 1.100927]\n",
      "epoch:21 step:19822 [D loss: 0.450294, acc.: 80.47%] [G loss: 1.064919]\n",
      "epoch:21 step:19823 [D loss: 0.573459, acc.: 75.00%] [G loss: 1.027305]\n",
      "epoch:21 step:19824 [D loss: 0.597860, acc.: 71.09%] [G loss: 1.119447]\n",
      "epoch:21 step:19825 [D loss: 0.701621, acc.: 61.72%] [G loss: 0.974851]\n",
      "epoch:21 step:19826 [D loss: 0.553703, acc.: 70.31%] [G loss: 1.027643]\n",
      "epoch:21 step:19827 [D loss: 0.286282, acc.: 95.31%] [G loss: 0.947287]\n",
      "epoch:21 step:19828 [D loss: 0.340344, acc.: 89.06%] [G loss: 1.037127]\n",
      "epoch:21 step:19829 [D loss: 0.371053, acc.: 91.41%] [G loss: 1.448311]\n",
      "epoch:21 step:19830 [D loss: 0.819433, acc.: 46.09%] [G loss: 1.107501]\n",
      "epoch:21 step:19831 [D loss: 0.592502, acc.: 71.09%] [G loss: 1.056826]\n",
      "epoch:21 step:19832 [D loss: 0.574101, acc.: 69.53%] [G loss: 0.919401]\n",
      "epoch:21 step:19833 [D loss: 0.734295, acc.: 47.66%] [G loss: 0.805749]\n",
      "epoch:21 step:19834 [D loss: 0.672990, acc.: 63.28%] [G loss: 0.963684]\n",
      "epoch:21 step:19835 [D loss: 0.721061, acc.: 53.12%] [G loss: 0.921974]\n",
      "epoch:21 step:19836 [D loss: 0.832866, acc.: 40.62%] [G loss: 0.898082]\n",
      "epoch:21 step:19837 [D loss: 0.690392, acc.: 58.59%] [G loss: 0.866027]\n",
      "epoch:21 step:19838 [D loss: 0.677226, acc.: 57.03%] [G loss: 0.846596]\n",
      "epoch:21 step:19839 [D loss: 0.627172, acc.: 66.41%] [G loss: 0.825253]\n",
      "epoch:21 step:19840 [D loss: 0.582508, acc.: 75.78%] [G loss: 0.961487]\n",
      "epoch:21 step:19841 [D loss: 0.666087, acc.: 59.38%] [G loss: 0.879465]\n",
      "epoch:21 step:19842 [D loss: 0.607101, acc.: 64.84%] [G loss: 1.042970]\n",
      "epoch:21 step:19843 [D loss: 0.876241, acc.: 31.25%] [G loss: 0.828968]\n",
      "epoch:21 step:19844 [D loss: 0.728866, acc.: 44.53%] [G loss: 0.903716]\n",
      "epoch:21 step:19845 [D loss: 0.660982, acc.: 59.38%] [G loss: 1.164784]\n",
      "epoch:21 step:19846 [D loss: 0.725061, acc.: 46.88%] [G loss: 1.017291]\n",
      "epoch:21 step:19847 [D loss: 0.649494, acc.: 57.81%] [G loss: 0.953195]\n",
      "epoch:21 step:19848 [D loss: 0.701987, acc.: 52.34%] [G loss: 0.870368]\n",
      "epoch:21 step:19849 [D loss: 0.685593, acc.: 52.34%] [G loss: 0.990947]\n",
      "epoch:21 step:19850 [D loss: 0.672395, acc.: 60.94%] [G loss: 1.020961]\n",
      "epoch:21 step:19851 [D loss: 0.683370, acc.: 60.16%] [G loss: 0.915926]\n",
      "epoch:21 step:19852 [D loss: 0.672094, acc.: 58.59%] [G loss: 1.200138]\n",
      "epoch:21 step:19853 [D loss: 0.596603, acc.: 66.41%] [G loss: 0.848251]\n",
      "epoch:21 step:19854 [D loss: 0.649894, acc.: 57.03%] [G loss: 0.960305]\n",
      "epoch:21 step:19855 [D loss: 0.670627, acc.: 59.38%] [G loss: 0.943526]\n",
      "epoch:21 step:19856 [D loss: 0.652498, acc.: 61.72%] [G loss: 0.828041]\n",
      "epoch:21 step:19857 [D loss: 0.658378, acc.: 62.50%] [G loss: 0.848589]\n",
      "epoch:21 step:19858 [D loss: 0.704941, acc.: 54.69%] [G loss: 0.906565]\n",
      "epoch:21 step:19859 [D loss: 0.695252, acc.: 53.91%] [G loss: 0.861547]\n",
      "epoch:21 step:19860 [D loss: 0.694105, acc.: 55.47%] [G loss: 0.820410]\n",
      "epoch:21 step:19861 [D loss: 0.589692, acc.: 64.84%] [G loss: 0.839010]\n",
      "epoch:21 step:19862 [D loss: 0.812172, acc.: 57.03%] [G loss: 0.668758]\n",
      "epoch:21 step:19863 [D loss: 0.670277, acc.: 60.16%] [G loss: 0.974740]\n",
      "epoch:21 step:19864 [D loss: 0.667770, acc.: 55.47%] [G loss: 0.881306]\n",
      "epoch:21 step:19865 [D loss: 0.657489, acc.: 57.81%] [G loss: 0.891261]\n",
      "epoch:21 step:19866 [D loss: 0.717546, acc.: 54.69%] [G loss: 0.863222]\n",
      "epoch:21 step:19867 [D loss: 0.671866, acc.: 57.03%] [G loss: 0.879327]\n",
      "epoch:21 step:19868 [D loss: 0.595058, acc.: 69.53%] [G loss: 0.944625]\n",
      "epoch:21 step:19869 [D loss: 0.504084, acc.: 81.25%] [G loss: 0.899790]\n",
      "epoch:21 step:19870 [D loss: 0.544050, acc.: 75.78%] [G loss: 0.956241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19871 [D loss: 0.569899, acc.: 73.44%] [G loss: 0.954051]\n",
      "epoch:21 step:19872 [D loss: 0.546437, acc.: 71.88%] [G loss: 1.033576]\n",
      "epoch:21 step:19873 [D loss: 0.643341, acc.: 61.72%] [G loss: 1.077956]\n",
      "epoch:21 step:19874 [D loss: 0.571076, acc.: 76.56%] [G loss: 0.821663]\n",
      "epoch:21 step:19875 [D loss: 0.597942, acc.: 71.09%] [G loss: 0.905221]\n",
      "epoch:21 step:19876 [D loss: 0.727805, acc.: 48.44%] [G loss: 0.879845]\n",
      "epoch:21 step:19877 [D loss: 0.633966, acc.: 68.75%] [G loss: 0.871500]\n",
      "epoch:21 step:19878 [D loss: 0.415706, acc.: 85.16%] [G loss: 1.037995]\n",
      "epoch:21 step:19879 [D loss: 0.758294, acc.: 46.88%] [G loss: 0.880748]\n",
      "epoch:21 step:19880 [D loss: 0.551063, acc.: 76.56%] [G loss: 0.899385]\n",
      "epoch:21 step:19881 [D loss: 0.459136, acc.: 77.34%] [G loss: 0.994019]\n",
      "epoch:21 step:19882 [D loss: 0.509509, acc.: 85.16%] [G loss: 1.041992]\n",
      "epoch:21 step:19883 [D loss: 0.478753, acc.: 84.38%] [G loss: 1.095872]\n",
      "epoch:21 step:19884 [D loss: 0.358747, acc.: 83.59%] [G loss: 0.955903]\n",
      "epoch:21 step:19885 [D loss: 0.521075, acc.: 81.25%] [G loss: 0.978906]\n",
      "epoch:21 step:19886 [D loss: 0.410620, acc.: 93.75%] [G loss: 1.118940]\n",
      "epoch:21 step:19887 [D loss: 0.720226, acc.: 53.12%] [G loss: 0.885233]\n",
      "epoch:21 step:19888 [D loss: 0.833245, acc.: 39.06%] [G loss: 0.932653]\n",
      "epoch:21 step:19889 [D loss: 0.763420, acc.: 44.53%] [G loss: 1.017036]\n",
      "epoch:21 step:19890 [D loss: 0.797050, acc.: 47.66%] [G loss: 0.908342]\n",
      "epoch:21 step:19891 [D loss: 0.845088, acc.: 41.41%] [G loss: 0.859353]\n",
      "epoch:21 step:19892 [D loss: 0.754125, acc.: 43.75%] [G loss: 0.872518]\n",
      "epoch:21 step:19893 [D loss: 0.600132, acc.: 66.41%] [G loss: 0.880038]\n",
      "epoch:21 step:19894 [D loss: 0.645691, acc.: 65.62%] [G loss: 0.874656]\n",
      "epoch:21 step:19895 [D loss: 0.511776, acc.: 75.78%] [G loss: 0.863582]\n",
      "epoch:21 step:19896 [D loss: 0.500067, acc.: 83.59%] [G loss: 0.731119]\n",
      "epoch:21 step:19897 [D loss: 0.406940, acc.: 76.56%] [G loss: 1.059275]\n",
      "epoch:21 step:19898 [D loss: 0.434209, acc.: 81.25%] [G loss: 1.052760]\n",
      "epoch:21 step:19899 [D loss: 0.603353, acc.: 64.84%] [G loss: 1.052751]\n",
      "epoch:21 step:19900 [D loss: 0.384153, acc.: 94.53%] [G loss: 1.042478]\n",
      "epoch:21 step:19901 [D loss: 0.648328, acc.: 60.16%] [G loss: 0.942583]\n",
      "epoch:21 step:19902 [D loss: 0.555123, acc.: 75.78%] [G loss: 1.011289]\n",
      "epoch:21 step:19903 [D loss: 0.631807, acc.: 67.19%] [G loss: 1.107165]\n",
      "epoch:21 step:19904 [D loss: 0.610922, acc.: 71.09%] [G loss: 0.893504]\n",
      "epoch:21 step:19905 [D loss: 0.632580, acc.: 62.50%] [G loss: 0.907516]\n",
      "epoch:21 step:19906 [D loss: 0.649353, acc.: 57.81%] [G loss: 0.838930]\n",
      "epoch:21 step:19907 [D loss: 0.283383, acc.: 89.06%] [G loss: 1.111780]\n",
      "epoch:21 step:19908 [D loss: 0.271140, acc.: 97.66%] [G loss: 1.161437]\n",
      "epoch:21 step:19909 [D loss: 0.329280, acc.: 89.06%] [G loss: 1.332221]\n",
      "epoch:21 step:19910 [D loss: 0.620622, acc.: 65.62%] [G loss: 1.074099]\n",
      "epoch:21 step:19911 [D loss: 0.501424, acc.: 76.56%] [G loss: 1.214933]\n",
      "epoch:21 step:19912 [D loss: 0.412330, acc.: 81.25%] [G loss: 1.081523]\n",
      "epoch:21 step:19913 [D loss: 0.560116, acc.: 72.66%] [G loss: 1.197575]\n",
      "epoch:21 step:19914 [D loss: 0.505333, acc.: 77.34%] [G loss: 0.876619]\n",
      "epoch:21 step:19915 [D loss: 0.470219, acc.: 82.03%] [G loss: 1.222513]\n",
      "epoch:21 step:19916 [D loss: 0.657434, acc.: 55.47%] [G loss: 1.035026]\n",
      "epoch:21 step:19917 [D loss: 0.614637, acc.: 67.19%] [G loss: 0.982657]\n",
      "epoch:21 step:19918 [D loss: 0.861209, acc.: 33.59%] [G loss: 0.947406]\n",
      "epoch:21 step:19919 [D loss: 0.947218, acc.: 33.59%] [G loss: 1.056755]\n",
      "epoch:21 step:19920 [D loss: 0.517538, acc.: 73.44%] [G loss: 1.145203]\n",
      "epoch:21 step:19921 [D loss: 0.713292, acc.: 53.91%] [G loss: 0.835550]\n",
      "epoch:21 step:19922 [D loss: 0.733666, acc.: 56.25%] [G loss: 0.840629]\n",
      "epoch:21 step:19923 [D loss: 0.815606, acc.: 38.28%] [G loss: 1.028242]\n",
      "epoch:21 step:19924 [D loss: 0.632941, acc.: 59.38%] [G loss: 1.121713]\n",
      "epoch:21 step:19925 [D loss: 0.635026, acc.: 64.06%] [G loss: 0.973865]\n",
      "epoch:21 step:19926 [D loss: 0.602414, acc.: 69.53%] [G loss: 1.004764]\n",
      "epoch:21 step:19927 [D loss: 0.656042, acc.: 62.50%] [G loss: 0.915839]\n",
      "epoch:21 step:19928 [D loss: 0.721452, acc.: 49.22%] [G loss: 0.962604]\n",
      "epoch:21 step:19929 [D loss: 0.777325, acc.: 39.84%] [G loss: 1.068599]\n",
      "epoch:21 step:19930 [D loss: 0.751208, acc.: 45.31%] [G loss: 1.293856]\n",
      "epoch:21 step:19931 [D loss: 0.691378, acc.: 53.91%] [G loss: 0.899750]\n",
      "epoch:21 step:19932 [D loss: 0.414353, acc.: 87.50%] [G loss: 1.027395]\n",
      "epoch:21 step:19933 [D loss: 0.378751, acc.: 85.16%] [G loss: 1.069875]\n",
      "epoch:21 step:19934 [D loss: 0.758827, acc.: 52.34%] [G loss: 1.144505]\n",
      "epoch:21 step:19935 [D loss: 0.676218, acc.: 59.38%] [G loss: 1.218058]\n",
      "epoch:21 step:19936 [D loss: 0.322032, acc.: 97.66%] [G loss: 1.261596]\n",
      "epoch:21 step:19937 [D loss: 0.516509, acc.: 76.56%] [G loss: 1.212590]\n",
      "epoch:21 step:19938 [D loss: 0.343070, acc.: 90.62%] [G loss: 1.265433]\n",
      "epoch:21 step:19939 [D loss: 0.740486, acc.: 46.88%] [G loss: 1.099600]\n",
      "epoch:21 step:19940 [D loss: 0.466677, acc.: 73.44%] [G loss: 1.224267]\n",
      "epoch:21 step:19941 [D loss: 0.530804, acc.: 71.88%] [G loss: 1.240420]\n",
      "epoch:21 step:19942 [D loss: 0.831485, acc.: 45.31%] [G loss: 1.044144]\n",
      "epoch:21 step:19943 [D loss: 0.751482, acc.: 54.69%] [G loss: 0.988684]\n",
      "epoch:21 step:19944 [D loss: 0.664964, acc.: 61.72%] [G loss: 1.026820]\n",
      "epoch:21 step:19945 [D loss: 0.674621, acc.: 59.38%] [G loss: 0.973425]\n",
      "epoch:21 step:19946 [D loss: 0.628322, acc.: 64.84%] [G loss: 1.056617]\n",
      "epoch:21 step:19947 [D loss: 0.762403, acc.: 46.09%] [G loss: 1.065421]\n",
      "epoch:21 step:19948 [D loss: 0.624270, acc.: 66.41%] [G loss: 0.939275]\n",
      "epoch:21 step:19949 [D loss: 0.542713, acc.: 72.66%] [G loss: 0.938511]\n",
      "epoch:21 step:19950 [D loss: 0.740509, acc.: 46.09%] [G loss: 1.059074]\n",
      "epoch:21 step:19951 [D loss: 0.583760, acc.: 72.66%] [G loss: 1.058510]\n",
      "epoch:21 step:19952 [D loss: 0.615253, acc.: 71.09%] [G loss: 0.960108]\n",
      "epoch:21 step:19953 [D loss: 0.607129, acc.: 63.28%] [G loss: 1.017649]\n",
      "epoch:21 step:19954 [D loss: 0.635539, acc.: 56.25%] [G loss: 0.996418]\n",
      "epoch:21 step:19955 [D loss: 0.532877, acc.: 78.12%] [G loss: 0.977497]\n",
      "epoch:21 step:19956 [D loss: 0.321353, acc.: 84.38%] [G loss: 1.047232]\n",
      "epoch:21 step:19957 [D loss: 0.656470, acc.: 64.06%] [G loss: 1.099178]\n",
      "epoch:21 step:19958 [D loss: 0.720842, acc.: 48.44%] [G loss: 1.144317]\n",
      "epoch:21 step:19959 [D loss: 0.596075, acc.: 67.19%] [G loss: 1.088848]\n",
      "epoch:21 step:19960 [D loss: 0.723349, acc.: 50.00%] [G loss: 1.054920]\n",
      "epoch:21 step:19961 [D loss: 0.406513, acc.: 82.81%] [G loss: 1.180995]\n",
      "epoch:21 step:19962 [D loss: 0.361772, acc.: 85.94%] [G loss: 1.140416]\n",
      "epoch:21 step:19963 [D loss: 0.311630, acc.: 89.84%] [G loss: 1.214873]\n",
      "epoch:21 step:19964 [D loss: 0.450695, acc.: 84.38%] [G loss: 1.112304]\n",
      "epoch:21 step:19965 [D loss: 0.381705, acc.: 84.38%] [G loss: 1.043031]\n",
      "epoch:21 step:19966 [D loss: 0.414904, acc.: 82.03%] [G loss: 1.151534]\n",
      "epoch:21 step:19967 [D loss: 0.504430, acc.: 75.78%] [G loss: 1.156657]\n",
      "epoch:21 step:19968 [D loss: 0.296436, acc.: 89.84%] [G loss: 1.229970]\n",
      "epoch:21 step:19969 [D loss: 0.350172, acc.: 92.97%] [G loss: 1.662769]\n",
      "epoch:21 step:19970 [D loss: 0.230297, acc.: 96.88%] [G loss: 1.245405]\n",
      "epoch:21 step:19971 [D loss: 0.572266, acc.: 66.41%] [G loss: 0.978179]\n",
      "epoch:21 step:19972 [D loss: 0.744359, acc.: 53.12%] [G loss: 1.078315]\n",
      "epoch:21 step:19973 [D loss: 1.136011, acc.: 19.53%] [G loss: 1.177917]\n",
      "epoch:21 step:19974 [D loss: 0.808108, acc.: 53.91%] [G loss: 1.097928]\n",
      "epoch:21 step:19975 [D loss: 0.847732, acc.: 40.62%] [G loss: 0.998554]\n",
      "epoch:21 step:19976 [D loss: 0.621736, acc.: 62.50%] [G loss: 1.012142]\n",
      "epoch:21 step:19977 [D loss: 0.664436, acc.: 57.81%] [G loss: 1.093722]\n",
      "epoch:21 step:19978 [D loss: 0.731851, acc.: 58.59%] [G loss: 1.200637]\n",
      "epoch:21 step:19979 [D loss: 0.723217, acc.: 47.66%] [G loss: 1.192416]\n",
      "epoch:21 step:19980 [D loss: 0.668045, acc.: 53.91%] [G loss: 1.127550]\n",
      "epoch:21 step:19981 [D loss: 0.680637, acc.: 60.94%] [G loss: 1.262127]\n",
      "epoch:21 step:19982 [D loss: 0.595861, acc.: 68.75%] [G loss: 1.049111]\n",
      "epoch:21 step:19983 [D loss: 0.656564, acc.: 60.94%] [G loss: 1.006308]\n",
      "epoch:21 step:19984 [D loss: 0.688642, acc.: 57.03%] [G loss: 1.404033]\n",
      "epoch:21 step:19985 [D loss: 0.646635, acc.: 60.16%] [G loss: 0.835224]\n",
      "epoch:21 step:19986 [D loss: 0.643377, acc.: 61.72%] [G loss: 0.988707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19987 [D loss: 0.739888, acc.: 44.53%] [G loss: 1.063630]\n",
      "epoch:21 step:19988 [D loss: 0.657803, acc.: 66.41%] [G loss: 1.039041]\n",
      "epoch:21 step:19989 [D loss: 0.600800, acc.: 65.62%] [G loss: 0.558155]\n",
      "epoch:21 step:19990 [D loss: 1.156105, acc.: 25.00%] [G loss: 0.746688]\n",
      "epoch:21 step:19991 [D loss: 0.669431, acc.: 62.50%] [G loss: 0.853230]\n",
      "epoch:21 step:19992 [D loss: 0.692936, acc.: 58.59%] [G loss: 0.940027]\n",
      "epoch:21 step:19993 [D loss: 0.570927, acc.: 72.66%] [G loss: 1.108912]\n",
      "epoch:21 step:19994 [D loss: 0.589068, acc.: 69.53%] [G loss: 1.270080]\n",
      "epoch:21 step:19995 [D loss: 0.465955, acc.: 83.59%] [G loss: 1.173301]\n",
      "epoch:21 step:19996 [D loss: 0.485825, acc.: 82.03%] [G loss: 1.262730]\n",
      "epoch:21 step:19997 [D loss: 0.397967, acc.: 92.19%] [G loss: 1.710674]\n",
      "epoch:21 step:19998 [D loss: 0.405721, acc.: 88.28%] [G loss: 1.674381]\n",
      "epoch:21 step:19999 [D loss: 0.346397, acc.: 93.75%] [G loss: 1.554651]\n",
      "epoch:21 step:20000 [D loss: 0.610919, acc.: 67.19%] [G loss: 1.688894]\n",
      "epoch:21 step:20001 [D loss: 0.468424, acc.: 81.25%] [G loss: 1.479453]\n",
      "epoch:21 step:20002 [D loss: 0.404202, acc.: 88.28%] [G loss: 2.104186]\n",
      "epoch:21 step:20003 [D loss: 0.530293, acc.: 74.22%] [G loss: 1.539127]\n",
      "epoch:21 step:20004 [D loss: 0.156516, acc.: 99.22%] [G loss: 2.039402]\n",
      "epoch:21 step:20005 [D loss: 0.284463, acc.: 91.41%] [G loss: 1.707689]\n",
      "epoch:21 step:20006 [D loss: 0.398822, acc.: 89.06%] [G loss: 1.089095]\n",
      "epoch:21 step:20007 [D loss: 0.867242, acc.: 33.59%] [G loss: 0.654259]\n",
      "epoch:21 step:20008 [D loss: 0.782058, acc.: 45.31%] [G loss: 0.930303]\n",
      "epoch:21 step:20009 [D loss: 0.987250, acc.: 27.34%] [G loss: 0.645611]\n",
      "epoch:21 step:20010 [D loss: 0.883335, acc.: 40.62%] [G loss: 0.779894]\n",
      "epoch:21 step:20011 [D loss: 0.896234, acc.: 43.75%] [G loss: 1.205927]\n",
      "epoch:21 step:20012 [D loss: 0.787804, acc.: 39.06%] [G loss: 1.100418]\n",
      "epoch:21 step:20013 [D loss: 0.653452, acc.: 53.12%] [G loss: 0.843805]\n",
      "epoch:21 step:20014 [D loss: 0.726466, acc.: 50.78%] [G loss: 0.856712]\n",
      "epoch:21 step:20015 [D loss: 0.710478, acc.: 57.81%] [G loss: 0.731819]\n",
      "epoch:21 step:20016 [D loss: 0.637044, acc.: 60.94%] [G loss: 0.852692]\n",
      "epoch:21 step:20017 [D loss: 0.639407, acc.: 67.19%] [G loss: 0.767988]\n",
      "epoch:21 step:20018 [D loss: 0.703325, acc.: 52.34%] [G loss: 0.886956]\n",
      "epoch:21 step:20019 [D loss: 0.753837, acc.: 42.97%] [G loss: 0.866952]\n",
      "epoch:21 step:20020 [D loss: 0.645054, acc.: 61.72%] [G loss: 1.091599]\n",
      "epoch:21 step:20021 [D loss: 0.620796, acc.: 60.94%] [G loss: 0.969845]\n",
      "epoch:21 step:20022 [D loss: 0.565206, acc.: 68.75%] [G loss: 1.237026]\n",
      "epoch:21 step:20023 [D loss: 0.541148, acc.: 75.00%] [G loss: 1.157269]\n",
      "epoch:21 step:20024 [D loss: 0.447384, acc.: 83.59%] [G loss: 1.152172]\n",
      "epoch:21 step:20025 [D loss: 0.725208, acc.: 53.91%] [G loss: 0.963766]\n",
      "epoch:21 step:20026 [D loss: 0.694741, acc.: 59.38%] [G loss: 1.306632]\n",
      "epoch:21 step:20027 [D loss: 0.754993, acc.: 50.78%] [G loss: 0.951748]\n",
      "epoch:21 step:20028 [D loss: 0.568464, acc.: 69.53%] [G loss: 0.981202]\n",
      "epoch:21 step:20029 [D loss: 0.524846, acc.: 75.78%] [G loss: 0.979640]\n",
      "epoch:21 step:20030 [D loss: 0.571273, acc.: 77.34%] [G loss: 1.068406]\n",
      "epoch:21 step:20031 [D loss: 0.561905, acc.: 72.66%] [G loss: 1.055596]\n",
      "epoch:21 step:20032 [D loss: 0.686989, acc.: 57.03%] [G loss: 0.970854]\n",
      "epoch:21 step:20033 [D loss: 0.636026, acc.: 67.97%] [G loss: 1.001908]\n",
      "epoch:21 step:20034 [D loss: 0.590454, acc.: 71.09%] [G loss: 0.853504]\n",
      "epoch:21 step:20035 [D loss: 0.498571, acc.: 76.56%] [G loss: 0.879286]\n",
      "epoch:21 step:20036 [D loss: 0.539713, acc.: 75.78%] [G loss: 0.941802]\n",
      "epoch:21 step:20037 [D loss: 0.564391, acc.: 68.75%] [G loss: 0.980865]\n",
      "epoch:21 step:20038 [D loss: 0.612655, acc.: 69.53%] [G loss: 0.938873]\n",
      "epoch:21 step:20039 [D loss: 0.841749, acc.: 43.75%] [G loss: 0.987607]\n",
      "epoch:21 step:20040 [D loss: 0.755000, acc.: 47.66%] [G loss: 1.007003]\n",
      "epoch:21 step:20041 [D loss: 0.659852, acc.: 62.50%] [G loss: 0.812124]\n",
      "epoch:21 step:20042 [D loss: 0.610663, acc.: 67.19%] [G loss: 0.941212]\n",
      "epoch:21 step:20043 [D loss: 0.489830, acc.: 76.56%] [G loss: 0.848517]\n",
      "epoch:21 step:20044 [D loss: 0.521634, acc.: 71.09%] [G loss: 0.974336]\n",
      "epoch:21 step:20045 [D loss: 0.747862, acc.: 47.66%] [G loss: 0.951317]\n",
      "epoch:21 step:20046 [D loss: 0.566406, acc.: 75.00%] [G loss: 1.063767]\n",
      "epoch:21 step:20047 [D loss: 0.500339, acc.: 74.22%] [G loss: 1.038438]\n",
      "epoch:21 step:20048 [D loss: 0.487359, acc.: 75.78%] [G loss: 0.912150]\n",
      "epoch:21 step:20049 [D loss: 0.630992, acc.: 60.94%] [G loss: 0.944240]\n",
      "epoch:21 step:20050 [D loss: 0.790163, acc.: 41.41%] [G loss: 0.685469]\n",
      "epoch:21 step:20051 [D loss: 0.637603, acc.: 61.72%] [G loss: 0.826553]\n",
      "epoch:21 step:20052 [D loss: 0.669329, acc.: 54.69%] [G loss: 0.994203]\n",
      "epoch:21 step:20053 [D loss: 0.673001, acc.: 60.94%] [G loss: 0.819088]\n",
      "epoch:21 step:20054 [D loss: 0.510778, acc.: 78.12%] [G loss: 0.968588]\n",
      "epoch:21 step:20055 [D loss: 0.443829, acc.: 88.28%] [G loss: 0.999987]\n",
      "epoch:21 step:20056 [D loss: 0.638789, acc.: 67.19%] [G loss: 1.009091]\n",
      "epoch:21 step:20057 [D loss: 0.554694, acc.: 71.09%] [G loss: 0.977093]\n",
      "epoch:21 step:20058 [D loss: 0.583694, acc.: 70.31%] [G loss: 0.887477]\n",
      "epoch:21 step:20059 [D loss: 0.746500, acc.: 51.56%] [G loss: 0.906596]\n",
      "epoch:21 step:20060 [D loss: 0.849375, acc.: 38.28%] [G loss: 1.066457]\n",
      "epoch:21 step:20061 [D loss: 0.675807, acc.: 57.81%] [G loss: 0.886233]\n",
      "epoch:21 step:20062 [D loss: 0.688194, acc.: 57.81%] [G loss: 1.033964]\n",
      "epoch:21 step:20063 [D loss: 0.669905, acc.: 60.16%] [G loss: 0.954904]\n",
      "epoch:21 step:20064 [D loss: 0.612200, acc.: 71.09%] [G loss: 0.985304]\n",
      "epoch:21 step:20065 [D loss: 0.630790, acc.: 67.19%] [G loss: 0.870788]\n",
      "epoch:21 step:20066 [D loss: 0.684641, acc.: 57.81%] [G loss: 0.987043]\n",
      "epoch:21 step:20067 [D loss: 0.670695, acc.: 50.00%] [G loss: 0.924023]\n",
      "epoch:21 step:20068 [D loss: 0.650644, acc.: 61.72%] [G loss: 0.958024]\n",
      "epoch:21 step:20069 [D loss: 0.613801, acc.: 73.44%] [G loss: 0.901428]\n",
      "epoch:21 step:20070 [D loss: 0.536740, acc.: 74.22%] [G loss: 0.963863]\n",
      "epoch:21 step:20071 [D loss: 0.663056, acc.: 56.25%] [G loss: 0.933524]\n",
      "epoch:21 step:20072 [D loss: 0.705216, acc.: 54.69%] [G loss: 0.922503]\n",
      "epoch:21 step:20073 [D loss: 0.391058, acc.: 85.94%] [G loss: 0.976553]\n",
      "epoch:21 step:20074 [D loss: 0.276912, acc.: 91.41%] [G loss: 1.134770]\n",
      "epoch:21 step:20075 [D loss: 0.308138, acc.: 88.28%] [G loss: 1.238215]\n",
      "epoch:21 step:20076 [D loss: 0.346560, acc.: 82.03%] [G loss: 1.253923]\n",
      "epoch:21 step:20077 [D loss: 0.305348, acc.: 98.44%] [G loss: 1.307499]\n",
      "epoch:21 step:20078 [D loss: 0.358547, acc.: 89.84%] [G loss: 1.279979]\n",
      "epoch:21 step:20079 [D loss: 0.260547, acc.: 97.66%] [G loss: 1.323718]\n",
      "epoch:21 step:20080 [D loss: 0.220569, acc.: 97.66%] [G loss: 1.419145]\n",
      "epoch:21 step:20081 [D loss: 0.178814, acc.: 100.00%] [G loss: 1.538970]\n",
      "epoch:21 step:20082 [D loss: 0.184418, acc.: 98.44%] [G loss: 1.358330]\n",
      "epoch:21 step:20083 [D loss: 0.193126, acc.: 99.22%] [G loss: 1.532110]\n",
      "epoch:21 step:20084 [D loss: 0.197093, acc.: 97.66%] [G loss: 1.668214]\n",
      "epoch:21 step:20085 [D loss: 0.289262, acc.: 96.09%] [G loss: 1.819967]\n",
      "epoch:21 step:20086 [D loss: 0.153659, acc.: 100.00%] [G loss: 1.541456]\n",
      "epoch:21 step:20087 [D loss: 0.411893, acc.: 80.47%] [G loss: 1.487448]\n",
      "epoch:21 step:20088 [D loss: 0.859892, acc.: 39.06%] [G loss: 1.256652]\n",
      "epoch:21 step:20089 [D loss: 0.617882, acc.: 67.19%] [G loss: 1.511419]\n",
      "epoch:21 step:20090 [D loss: 0.206992, acc.: 96.88%] [G loss: 1.352000]\n",
      "epoch:21 step:20091 [D loss: 0.253666, acc.: 95.31%] [G loss: 1.622358]\n",
      "epoch:21 step:20092 [D loss: 0.302017, acc.: 89.06%] [G loss: 1.636613]\n",
      "epoch:21 step:20093 [D loss: 0.533198, acc.: 75.78%] [G loss: 1.106168]\n",
      "epoch:21 step:20094 [D loss: 0.406718, acc.: 89.06%] [G loss: 1.567914]\n",
      "epoch:21 step:20095 [D loss: 1.010641, acc.: 55.47%] [G loss: 0.356558]\n",
      "epoch:21 step:20096 [D loss: 0.191669, acc.: 96.88%] [G loss: 2.052248]\n",
      "epoch:21 step:20097 [D loss: 0.508217, acc.: 76.56%] [G loss: 1.388070]\n",
      "epoch:21 step:20098 [D loss: 0.839620, acc.: 50.78%] [G loss: 1.145524]\n",
      "epoch:21 step:20099 [D loss: 0.819744, acc.: 49.22%] [G loss: 0.520756]\n",
      "epoch:21 step:20100 [D loss: 1.348992, acc.: 46.09%] [G loss: 0.525452]\n",
      "epoch:21 step:20101 [D loss: 0.319617, acc.: 90.62%] [G loss: 0.662971]\n",
      "epoch:21 step:20102 [D loss: 0.849781, acc.: 52.34%] [G loss: 1.518657]\n",
      "epoch:21 step:20103 [D loss: 0.743004, acc.: 50.00%] [G loss: 1.112481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20104 [D loss: 0.715249, acc.: 57.81%] [G loss: 1.198630]\n",
      "epoch:21 step:20105 [D loss: 0.292368, acc.: 96.09%] [G loss: 1.063352]\n",
      "epoch:21 step:20106 [D loss: 0.706573, acc.: 57.03%] [G loss: 1.084858]\n",
      "epoch:21 step:20107 [D loss: 0.827963, acc.: 54.69%] [G loss: 1.006460]\n",
      "epoch:21 step:20108 [D loss: 1.038766, acc.: 23.44%] [G loss: 1.290207]\n",
      "epoch:21 step:20109 [D loss: 1.247829, acc.: 20.31%] [G loss: 1.060045]\n",
      "epoch:21 step:20110 [D loss: 0.891222, acc.: 46.09%] [G loss: 1.426560]\n",
      "epoch:21 step:20111 [D loss: 0.788056, acc.: 58.59%] [G loss: 1.203884]\n",
      "epoch:21 step:20112 [D loss: 0.906729, acc.: 44.53%] [G loss: 1.144846]\n",
      "epoch:21 step:20113 [D loss: 0.732023, acc.: 56.25%] [G loss: 1.206375]\n",
      "epoch:21 step:20114 [D loss: 0.773191, acc.: 42.97%] [G loss: 1.185078]\n",
      "epoch:21 step:20115 [D loss: 0.718342, acc.: 52.34%] [G loss: 1.105315]\n",
      "epoch:21 step:20116 [D loss: 0.800485, acc.: 39.06%] [G loss: 0.997907]\n",
      "epoch:21 step:20117 [D loss: 0.761456, acc.: 45.31%] [G loss: 1.037106]\n",
      "epoch:21 step:20118 [D loss: 0.769084, acc.: 49.22%] [G loss: 0.959214]\n",
      "epoch:21 step:20119 [D loss: 0.719981, acc.: 53.12%] [G loss: 1.072979]\n",
      "epoch:21 step:20120 [D loss: 0.662265, acc.: 58.59%] [G loss: 1.002938]\n",
      "epoch:21 step:20121 [D loss: 0.683285, acc.: 56.25%] [G loss: 1.014596]\n",
      "epoch:21 step:20122 [D loss: 0.669875, acc.: 60.16%] [G loss: 0.930357]\n",
      "epoch:21 step:20123 [D loss: 0.683834, acc.: 54.69%] [G loss: 0.950984]\n",
      "epoch:21 step:20124 [D loss: 0.657497, acc.: 55.47%] [G loss: 1.010415]\n",
      "epoch:21 step:20125 [D loss: 0.610775, acc.: 65.62%] [G loss: 1.061791]\n",
      "epoch:21 step:20126 [D loss: 0.562808, acc.: 68.75%] [G loss: 1.136092]\n",
      "epoch:21 step:20127 [D loss: 0.553162, acc.: 74.22%] [G loss: 1.218032]\n",
      "epoch:21 step:20128 [D loss: 0.508293, acc.: 80.47%] [G loss: 1.226349]\n",
      "epoch:21 step:20129 [D loss: 0.496620, acc.: 80.47%] [G loss: 1.117518]\n",
      "epoch:21 step:20130 [D loss: 0.498638, acc.: 82.81%] [G loss: 1.315133]\n",
      "epoch:21 step:20131 [D loss: 0.489163, acc.: 81.25%] [G loss: 1.309212]\n",
      "epoch:21 step:20132 [D loss: 0.513012, acc.: 71.09%] [G loss: 1.346473]\n",
      "epoch:21 step:20133 [D loss: 0.442517, acc.: 82.81%] [G loss: 1.430241]\n",
      "epoch:21 step:20134 [D loss: 0.390765, acc.: 86.72%] [G loss: 1.840714]\n",
      "epoch:21 step:20135 [D loss: 0.533651, acc.: 68.75%] [G loss: 1.321181]\n",
      "epoch:21 step:20136 [D loss: 0.506755, acc.: 76.56%] [G loss: 1.168762]\n",
      "epoch:21 step:20137 [D loss: 0.541389, acc.: 69.53%] [G loss: 1.358102]\n",
      "epoch:21 step:20138 [D loss: 0.744955, acc.: 51.56%] [G loss: 1.137027]\n",
      "epoch:21 step:20139 [D loss: 0.874016, acc.: 42.97%] [G loss: 0.884211]\n",
      "epoch:21 step:20140 [D loss: 0.622055, acc.: 64.84%] [G loss: 1.244225]\n",
      "epoch:21 step:20141 [D loss: 0.487962, acc.: 82.03%] [G loss: 1.090955]\n",
      "epoch:21 step:20142 [D loss: 0.547437, acc.: 75.78%] [G loss: 1.090600]\n",
      "epoch:21 step:20143 [D loss: 0.463802, acc.: 78.12%] [G loss: 0.915052]\n",
      "epoch:21 step:20144 [D loss: 0.521087, acc.: 80.47%] [G loss: 1.299726]\n",
      "epoch:21 step:20145 [D loss: 0.297292, acc.: 96.09%] [G loss: 1.567491]\n",
      "epoch:21 step:20146 [D loss: 0.415049, acc.: 91.41%] [G loss: 1.150842]\n",
      "epoch:21 step:20147 [D loss: 0.256310, acc.: 96.09%] [G loss: 0.875766]\n",
      "epoch:21 step:20148 [D loss: 0.298594, acc.: 95.31%] [G loss: 1.267195]\n",
      "epoch:21 step:20149 [D loss: 0.563192, acc.: 72.66%] [G loss: 1.734534]\n",
      "epoch:21 step:20150 [D loss: 1.405167, acc.: 39.84%] [G loss: 0.790212]\n",
      "epoch:21 step:20151 [D loss: 1.174163, acc.: 21.88%] [G loss: 0.703351]\n",
      "epoch:21 step:20152 [D loss: 0.870159, acc.: 35.94%] [G loss: 0.673711]\n",
      "epoch:21 step:20153 [D loss: 0.668617, acc.: 57.81%] [G loss: 0.721235]\n",
      "epoch:21 step:20154 [D loss: 0.665110, acc.: 56.25%] [G loss: 0.642811]\n",
      "epoch:21 step:20155 [D loss: 0.610941, acc.: 70.31%] [G loss: 0.911345]\n",
      "epoch:21 step:20156 [D loss: 0.525441, acc.: 75.78%] [G loss: 0.989209]\n",
      "epoch:21 step:20157 [D loss: 0.549053, acc.: 64.84%] [G loss: 0.918556]\n",
      "epoch:21 step:20158 [D loss: 0.463392, acc.: 79.69%] [G loss: 0.987875]\n",
      "epoch:21 step:20159 [D loss: 1.015147, acc.: 29.69%] [G loss: 0.906029]\n",
      "epoch:21 step:20160 [D loss: 0.731262, acc.: 52.34%] [G loss: 0.830381]\n",
      "epoch:21 step:20161 [D loss: 0.775766, acc.: 35.16%] [G loss: 0.919565]\n",
      "epoch:21 step:20162 [D loss: 0.663993, acc.: 57.81%] [G loss: 0.928633]\n",
      "epoch:21 step:20163 [D loss: 0.721420, acc.: 45.31%] [G loss: 1.032887]\n",
      "epoch:21 step:20164 [D loss: 0.661220, acc.: 57.81%] [G loss: 0.850075]\n",
      "epoch:21 step:20165 [D loss: 0.633604, acc.: 63.28%] [G loss: 0.905745]\n",
      "epoch:21 step:20166 [D loss: 0.643573, acc.: 61.72%] [G loss: 0.861555]\n",
      "epoch:21 step:20167 [D loss: 0.493588, acc.: 80.47%] [G loss: 0.863524]\n",
      "epoch:21 step:20168 [D loss: 0.558147, acc.: 73.44%] [G loss: 1.041993]\n",
      "epoch:21 step:20169 [D loss: 0.660209, acc.: 67.97%] [G loss: 0.952076]\n",
      "epoch:21 step:20170 [D loss: 0.714130, acc.: 50.78%] [G loss: 0.811522]\n",
      "epoch:21 step:20171 [D loss: 0.582896, acc.: 63.28%] [G loss: 0.986179]\n",
      "epoch:21 step:20172 [D loss: 0.598326, acc.: 72.66%] [G loss: 0.849398]\n",
      "epoch:21 step:20173 [D loss: 0.687702, acc.: 53.12%] [G loss: 0.863992]\n",
      "epoch:21 step:20174 [D loss: 0.666666, acc.: 55.47%] [G loss: 0.976282]\n",
      "epoch:21 step:20175 [D loss: 0.629091, acc.: 63.28%] [G loss: 0.940305]\n",
      "epoch:21 step:20176 [D loss: 0.589352, acc.: 66.41%] [G loss: 1.062481]\n",
      "epoch:21 step:20177 [D loss: 0.723696, acc.: 54.69%] [G loss: 0.824955]\n",
      "epoch:21 step:20178 [D loss: 0.711059, acc.: 57.81%] [G loss: 0.911759]\n",
      "epoch:21 step:20179 [D loss: 0.582720, acc.: 68.75%] [G loss: 1.047379]\n",
      "epoch:21 step:20180 [D loss: 0.579816, acc.: 71.09%] [G loss: 0.953731]\n",
      "epoch:21 step:20181 [D loss: 0.492199, acc.: 78.91%] [G loss: 0.894795]\n",
      "epoch:21 step:20182 [D loss: 0.545008, acc.: 73.44%] [G loss: 0.993645]\n",
      "epoch:21 step:20183 [D loss: 0.598268, acc.: 70.31%] [G loss: 1.103962]\n",
      "epoch:21 step:20184 [D loss: 0.533356, acc.: 76.56%] [G loss: 1.069940]\n",
      "epoch:21 step:20185 [D loss: 0.532655, acc.: 75.00%] [G loss: 0.808182]\n",
      "epoch:21 step:20186 [D loss: 0.680361, acc.: 56.25%] [G loss: 0.970637]\n",
      "epoch:21 step:20187 [D loss: 0.727340, acc.: 52.34%] [G loss: 0.914415]\n",
      "epoch:21 step:20188 [D loss: 0.861051, acc.: 42.97%] [G loss: 1.033337]\n",
      "epoch:21 step:20189 [D loss: 0.668222, acc.: 53.91%] [G loss: 1.514159]\n",
      "epoch:21 step:20190 [D loss: 0.576977, acc.: 69.53%] [G loss: 0.948271]\n",
      "epoch:21 step:20191 [D loss: 0.624868, acc.: 65.62%] [G loss: 0.923227]\n",
      "epoch:21 step:20192 [D loss: 0.602269, acc.: 67.19%] [G loss: 1.228764]\n",
      "epoch:21 step:20193 [D loss: 0.700228, acc.: 60.94%] [G loss: 1.007157]\n",
      "epoch:21 step:20194 [D loss: 0.648815, acc.: 68.75%] [G loss: 1.012829]\n",
      "epoch:21 step:20195 [D loss: 0.585837, acc.: 68.75%] [G loss: 1.116054]\n",
      "epoch:21 step:20196 [D loss: 0.555560, acc.: 66.41%] [G loss: 1.065234]\n",
      "epoch:21 step:20197 [D loss: 0.614761, acc.: 64.84%] [G loss: 1.151754]\n",
      "epoch:21 step:20198 [D loss: 0.660851, acc.: 55.47%] [G loss: 0.993021]\n",
      "epoch:21 step:20199 [D loss: 0.602227, acc.: 65.62%] [G loss: 0.967854]\n",
      "epoch:21 step:20200 [D loss: 0.685994, acc.: 55.47%] [G loss: 1.000257]\n",
      "epoch:21 step:20201 [D loss: 0.656293, acc.: 58.59%] [G loss: 1.144231]\n",
      "epoch:21 step:20202 [D loss: 0.701353, acc.: 55.47%] [G loss: 1.172193]\n",
      "epoch:21 step:20203 [D loss: 0.602116, acc.: 69.53%] [G loss: 0.949611]\n",
      "epoch:21 step:20204 [D loss: 0.589291, acc.: 65.62%] [G loss: 1.142732]\n",
      "epoch:21 step:20205 [D loss: 0.679541, acc.: 55.47%] [G loss: 1.231491]\n",
      "epoch:21 step:20206 [D loss: 0.705522, acc.: 57.03%] [G loss: 1.011953]\n",
      "epoch:21 step:20207 [D loss: 0.656866, acc.: 56.25%] [G loss: 1.033258]\n",
      "epoch:21 step:20208 [D loss: 0.715885, acc.: 55.47%] [G loss: 0.868645]\n",
      "epoch:21 step:20209 [D loss: 0.662051, acc.: 58.59%] [G loss: 0.946080]\n",
      "epoch:21 step:20210 [D loss: 0.578587, acc.: 67.97%] [G loss: 0.763464]\n",
      "epoch:21 step:20211 [D loss: 0.672262, acc.: 60.16%] [G loss: 1.056282]\n",
      "epoch:21 step:20212 [D loss: 0.654837, acc.: 66.41%] [G loss: 0.920582]\n",
      "epoch:21 step:20213 [D loss: 0.544418, acc.: 70.31%] [G loss: 0.964389]\n",
      "epoch:21 step:20214 [D loss: 0.564464, acc.: 73.44%] [G loss: 1.123796]\n",
      "epoch:21 step:20215 [D loss: 0.625300, acc.: 67.97%] [G loss: 1.003941]\n",
      "epoch:21 step:20216 [D loss: 0.548632, acc.: 75.00%] [G loss: 1.008275]\n",
      "epoch:21 step:20217 [D loss: 0.634390, acc.: 64.06%] [G loss: 1.124711]\n",
      "epoch:21 step:20218 [D loss: 0.581194, acc.: 76.56%] [G loss: 1.043386]\n",
      "epoch:21 step:20219 [D loss: 0.729508, acc.: 51.56%] [G loss: 0.860832]\n",
      "epoch:21 step:20220 [D loss: 0.595328, acc.: 68.75%] [G loss: 1.036048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20221 [D loss: 0.715466, acc.: 48.44%] [G loss: 1.015682]\n",
      "epoch:21 step:20222 [D loss: 0.655106, acc.: 64.06%] [G loss: 1.068268]\n",
      "epoch:21 step:20223 [D loss: 0.768650, acc.: 51.56%] [G loss: 0.896958]\n",
      "epoch:21 step:20224 [D loss: 0.721890, acc.: 50.00%] [G loss: 0.904657]\n",
      "epoch:21 step:20225 [D loss: 0.700295, acc.: 57.03%] [G loss: 0.926098]\n",
      "epoch:21 step:20226 [D loss: 0.579735, acc.: 71.88%] [G loss: 0.890706]\n",
      "epoch:21 step:20227 [D loss: 0.538732, acc.: 73.44%] [G loss: 0.900849]\n",
      "epoch:21 step:20228 [D loss: 0.647612, acc.: 63.28%] [G loss: 0.965829]\n",
      "epoch:21 step:20229 [D loss: 0.650541, acc.: 56.25%] [G loss: 0.966811]\n",
      "epoch:21 step:20230 [D loss: 0.734401, acc.: 46.88%] [G loss: 0.813632]\n",
      "epoch:21 step:20231 [D loss: 0.563962, acc.: 68.75%] [G loss: 0.964706]\n",
      "epoch:21 step:20232 [D loss: 0.628674, acc.: 67.97%] [G loss: 0.955783]\n",
      "epoch:21 step:20233 [D loss: 0.553241, acc.: 72.66%] [G loss: 0.921743]\n",
      "epoch:21 step:20234 [D loss: 0.617437, acc.: 60.94%] [G loss: 0.777786]\n",
      "epoch:21 step:20235 [D loss: 0.671547, acc.: 60.16%] [G loss: 0.905813]\n",
      "epoch:21 step:20236 [D loss: 0.501746, acc.: 78.91%] [G loss: 1.015469]\n",
      "epoch:21 step:20237 [D loss: 0.555527, acc.: 67.97%] [G loss: 1.039598]\n",
      "epoch:21 step:20238 [D loss: 0.463059, acc.: 81.25%] [G loss: 1.219008]\n",
      "epoch:21 step:20239 [D loss: 0.707149, acc.: 56.25%] [G loss: 1.003416]\n",
      "epoch:21 step:20240 [D loss: 0.751964, acc.: 49.22%] [G loss: 0.983626]\n",
      "epoch:21 step:20241 [D loss: 0.626104, acc.: 66.41%] [G loss: 1.002016]\n",
      "epoch:21 step:20242 [D loss: 0.599102, acc.: 63.28%] [G loss: 0.957085]\n",
      "epoch:21 step:20243 [D loss: 0.453932, acc.: 79.69%] [G loss: 1.024434]\n",
      "epoch:21 step:20244 [D loss: 0.372596, acc.: 92.19%] [G loss: 1.148660]\n",
      "epoch:21 step:20245 [D loss: 0.550407, acc.: 78.91%] [G loss: 1.189911]\n",
      "epoch:21 step:20246 [D loss: 0.687018, acc.: 61.72%] [G loss: 0.908667]\n",
      "epoch:21 step:20247 [D loss: 0.575145, acc.: 70.31%] [G loss: 0.985146]\n",
      "epoch:21 step:20248 [D loss: 0.634215, acc.: 67.97%] [G loss: 0.986914]\n",
      "epoch:21 step:20249 [D loss: 0.536396, acc.: 76.56%] [G loss: 0.966448]\n",
      "epoch:21 step:20250 [D loss: 0.563542, acc.: 71.88%] [G loss: 1.054093]\n",
      "epoch:21 step:20251 [D loss: 0.576787, acc.: 75.78%] [G loss: 0.948503]\n",
      "epoch:21 step:20252 [D loss: 0.527256, acc.: 73.44%] [G loss: 0.927429]\n",
      "epoch:21 step:20253 [D loss: 0.482303, acc.: 78.91%] [G loss: 1.010249]\n",
      "epoch:21 step:20254 [D loss: 0.433074, acc.: 87.50%] [G loss: 1.086054]\n",
      "epoch:21 step:20255 [D loss: 0.436563, acc.: 79.69%] [G loss: 0.985199]\n",
      "epoch:21 step:20256 [D loss: 0.631229, acc.: 63.28%] [G loss: 1.071280]\n",
      "epoch:21 step:20257 [D loss: 0.664153, acc.: 65.62%] [G loss: 1.083456]\n",
      "epoch:21 step:20258 [D loss: 0.779497, acc.: 45.31%] [G loss: 0.962550]\n",
      "epoch:21 step:20259 [D loss: 0.727422, acc.: 53.91%] [G loss: 1.077710]\n",
      "epoch:21 step:20260 [D loss: 0.699198, acc.: 51.56%] [G loss: 0.786530]\n",
      "epoch:21 step:20261 [D loss: 0.889800, acc.: 38.28%] [G loss: 1.108895]\n",
      "epoch:21 step:20262 [D loss: 1.016920, acc.: 29.69%] [G loss: 1.135911]\n",
      "epoch:21 step:20263 [D loss: 0.649746, acc.: 58.59%] [G loss: 1.075154]\n",
      "epoch:21 step:20264 [D loss: 0.421741, acc.: 89.84%] [G loss: 1.229073]\n",
      "epoch:21 step:20265 [D loss: 0.383252, acc.: 94.53%] [G loss: 1.105687]\n",
      "epoch:21 step:20266 [D loss: 0.307774, acc.: 94.53%] [G loss: 1.096337]\n",
      "epoch:21 step:20267 [D loss: 0.613161, acc.: 67.97%] [G loss: 1.019848]\n",
      "epoch:21 step:20268 [D loss: 0.788121, acc.: 46.09%] [G loss: 0.964786]\n",
      "epoch:21 step:20269 [D loss: 0.607568, acc.: 67.97%] [G loss: 1.112828]\n",
      "epoch:21 step:20270 [D loss: 0.691445, acc.: 53.91%] [G loss: 1.155658]\n",
      "epoch:21 step:20271 [D loss: 0.586928, acc.: 65.62%] [G loss: 0.956383]\n",
      "epoch:21 step:20272 [D loss: 0.530255, acc.: 76.56%] [G loss: 0.963578]\n",
      "epoch:21 step:20273 [D loss: 0.678711, acc.: 59.38%] [G loss: 1.031792]\n",
      "epoch:21 step:20274 [D loss: 0.788234, acc.: 45.31%] [G loss: 0.924415]\n",
      "epoch:21 step:20275 [D loss: 0.646396, acc.: 63.28%] [G loss: 1.049713]\n",
      "epoch:21 step:20276 [D loss: 0.796719, acc.: 38.28%] [G loss: 0.954173]\n",
      "epoch:21 step:20277 [D loss: 0.651223, acc.: 61.72%] [G loss: 0.996668]\n",
      "epoch:21 step:20278 [D loss: 0.463407, acc.: 85.94%] [G loss: 1.042677]\n",
      "epoch:21 step:20279 [D loss: 0.694959, acc.: 54.69%] [G loss: 0.926825]\n",
      "epoch:21 step:20280 [D loss: 0.755105, acc.: 44.53%] [G loss: 0.997221]\n",
      "epoch:21 step:20281 [D loss: 0.410367, acc.: 78.91%] [G loss: 0.938654]\n",
      "epoch:21 step:20282 [D loss: 0.650986, acc.: 56.25%] [G loss: 1.043891]\n",
      "epoch:21 step:20283 [D loss: 0.620862, acc.: 69.53%] [G loss: 0.935124]\n",
      "epoch:21 step:20284 [D loss: 0.619468, acc.: 60.94%] [G loss: 0.998524]\n",
      "epoch:21 step:20285 [D loss: 0.760516, acc.: 44.53%] [G loss: 0.965112]\n",
      "epoch:21 step:20286 [D loss: 0.632583, acc.: 63.28%] [G loss: 0.843689]\n",
      "epoch:21 step:20287 [D loss: 0.695784, acc.: 54.69%] [G loss: 1.067623]\n",
      "epoch:21 step:20288 [D loss: 0.756087, acc.: 49.22%] [G loss: 0.991823]\n",
      "epoch:21 step:20289 [D loss: 0.772260, acc.: 50.00%] [G loss: 0.854937]\n",
      "epoch:21 step:20290 [D loss: 0.621064, acc.: 59.38%] [G loss: 1.148355]\n",
      "epoch:21 step:20291 [D loss: 0.655201, acc.: 57.81%] [G loss: 1.072291]\n",
      "epoch:21 step:20292 [D loss: 0.565361, acc.: 75.00%] [G loss: 1.159332]\n",
      "epoch:21 step:20293 [D loss: 0.461201, acc.: 83.59%] [G loss: 1.158488]\n",
      "epoch:21 step:20294 [D loss: 0.450410, acc.: 84.38%] [G loss: 1.436353]\n",
      "epoch:21 step:20295 [D loss: 0.698166, acc.: 60.16%] [G loss: 1.287216]\n",
      "epoch:21 step:20296 [D loss: 0.611757, acc.: 61.72%] [G loss: 1.234782]\n",
      "epoch:21 step:20297 [D loss: 0.623293, acc.: 67.19%] [G loss: 1.138637]\n",
      "epoch:21 step:20298 [D loss: 0.670806, acc.: 61.72%] [G loss: 0.900039]\n",
      "epoch:21 step:20299 [D loss: 0.451408, acc.: 85.94%] [G loss: 1.176057]\n",
      "epoch:21 step:20300 [D loss: 0.454466, acc.: 84.38%] [G loss: 1.006065]\n",
      "epoch:21 step:20301 [D loss: 0.428054, acc.: 83.59%] [G loss: 1.201507]\n",
      "epoch:21 step:20302 [D loss: 0.604457, acc.: 64.06%] [G loss: 1.153421]\n",
      "epoch:21 step:20303 [D loss: 0.440675, acc.: 81.25%] [G loss: 1.247474]\n",
      "epoch:21 step:20304 [D loss: 0.525472, acc.: 76.56%] [G loss: 1.487302]\n",
      "epoch:21 step:20305 [D loss: 0.558804, acc.: 67.19%] [G loss: 0.861723]\n",
      "epoch:21 step:20306 [D loss: 0.663791, acc.: 67.97%] [G loss: 1.149498]\n",
      "epoch:21 step:20307 [D loss: 0.460882, acc.: 83.59%] [G loss: 1.100181]\n",
      "epoch:21 step:20308 [D loss: 0.680219, acc.: 56.25%] [G loss: 1.194842]\n",
      "epoch:21 step:20309 [D loss: 0.334383, acc.: 84.38%] [G loss: 1.100362]\n",
      "epoch:21 step:20310 [D loss: 0.481007, acc.: 72.66%] [G loss: 1.323463]\n",
      "epoch:21 step:20311 [D loss: 0.328508, acc.: 89.06%] [G loss: 1.389230]\n",
      "epoch:21 step:20312 [D loss: 0.440301, acc.: 84.38%] [G loss: 1.133666]\n",
      "epoch:21 step:20313 [D loss: 0.688130, acc.: 62.50%] [G loss: 1.169791]\n",
      "epoch:21 step:20314 [D loss: 0.925599, acc.: 35.94%] [G loss: 1.016191]\n",
      "epoch:21 step:20315 [D loss: 0.640422, acc.: 53.12%] [G loss: 1.042773]\n",
      "epoch:21 step:20316 [D loss: 0.794525, acc.: 43.75%] [G loss: 0.791097]\n",
      "epoch:21 step:20317 [D loss: 0.973713, acc.: 33.59%] [G loss: 1.000114]\n",
      "epoch:21 step:20318 [D loss: 0.866807, acc.: 35.16%] [G loss: 1.099186]\n",
      "epoch:21 step:20319 [D loss: 0.827277, acc.: 46.09%] [G loss: 1.065069]\n",
      "epoch:21 step:20320 [D loss: 0.743697, acc.: 53.12%] [G loss: 0.953363]\n",
      "epoch:21 step:20321 [D loss: 0.588651, acc.: 70.31%] [G loss: 1.048034]\n",
      "epoch:21 step:20322 [D loss: 0.511803, acc.: 76.56%] [G loss: 1.093642]\n",
      "epoch:21 step:20323 [D loss: 0.643633, acc.: 59.38%] [G loss: 1.265738]\n",
      "epoch:21 step:20324 [D loss: 0.545683, acc.: 71.09%] [G loss: 1.311502]\n",
      "epoch:21 step:20325 [D loss: 0.519673, acc.: 75.00%] [G loss: 0.892909]\n",
      "epoch:21 step:20326 [D loss: 0.661823, acc.: 57.81%] [G loss: 1.146560]\n",
      "epoch:21 step:20327 [D loss: 0.498540, acc.: 75.78%] [G loss: 1.067253]\n",
      "epoch:21 step:20328 [D loss: 0.648391, acc.: 61.72%] [G loss: 1.117444]\n",
      "epoch:21 step:20329 [D loss: 0.757945, acc.: 53.12%] [G loss: 1.058403]\n",
      "epoch:21 step:20330 [D loss: 0.714548, acc.: 53.12%] [G loss: 1.606154]\n",
      "epoch:21 step:20331 [D loss: 0.687504, acc.: 55.47%] [G loss: 0.893480]\n",
      "epoch:21 step:20332 [D loss: 0.662690, acc.: 62.50%] [G loss: 1.026705]\n",
      "epoch:21 step:20333 [D loss: 0.708969, acc.: 55.47%] [G loss: 1.000135]\n",
      "epoch:21 step:20334 [D loss: 0.730821, acc.: 47.66%] [G loss: 0.915531]\n",
      "epoch:21 step:20335 [D loss: 0.672206, acc.: 57.81%] [G loss: 0.915760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20336 [D loss: 0.714533, acc.: 60.16%] [G loss: 0.831386]\n",
      "epoch:21 step:20337 [D loss: 0.647968, acc.: 64.06%] [G loss: 0.896429]\n",
      "epoch:21 step:20338 [D loss: 0.672760, acc.: 60.94%] [G loss: 0.919206]\n",
      "epoch:21 step:20339 [D loss: 0.635948, acc.: 64.84%] [G loss: 0.953505]\n",
      "epoch:21 step:20340 [D loss: 0.526487, acc.: 75.00%] [G loss: 1.292483]\n",
      "epoch:21 step:20341 [D loss: 0.475809, acc.: 82.03%] [G loss: 1.128096]\n",
      "epoch:21 step:20342 [D loss: 0.357697, acc.: 89.06%] [G loss: 1.291988]\n",
      "epoch:21 step:20343 [D loss: 0.515903, acc.: 78.91%] [G loss: 1.286164]\n",
      "epoch:21 step:20344 [D loss: 0.496219, acc.: 81.25%] [G loss: 1.514073]\n",
      "epoch:21 step:20345 [D loss: 0.609775, acc.: 63.28%] [G loss: 0.998431]\n",
      "epoch:21 step:20346 [D loss: 0.471819, acc.: 83.59%] [G loss: 1.025959]\n",
      "epoch:21 step:20347 [D loss: 0.585915, acc.: 71.88%] [G loss: 1.147428]\n",
      "epoch:21 step:20348 [D loss: 0.581459, acc.: 67.97%] [G loss: 1.235290]\n",
      "epoch:21 step:20349 [D loss: 0.638430, acc.: 64.06%] [G loss: 1.229013]\n",
      "epoch:21 step:20350 [D loss: 0.649731, acc.: 64.84%] [G loss: 1.198937]\n",
      "epoch:21 step:20351 [D loss: 0.496388, acc.: 76.56%] [G loss: 1.180302]\n",
      "epoch:21 step:20352 [D loss: 0.743964, acc.: 52.34%] [G loss: 1.078548]\n",
      "epoch:21 step:20353 [D loss: 0.755533, acc.: 46.09%] [G loss: 1.092982]\n",
      "epoch:21 step:20354 [D loss: 0.806975, acc.: 48.44%] [G loss: 0.739296]\n",
      "epoch:21 step:20355 [D loss: 0.715679, acc.: 54.69%] [G loss: 0.844696]\n",
      "epoch:21 step:20356 [D loss: 0.785398, acc.: 50.00%] [G loss: 0.600857]\n",
      "epoch:21 step:20357 [D loss: 0.681340, acc.: 57.03%] [G loss: 0.856402]\n",
      "epoch:21 step:20358 [D loss: 0.703587, acc.: 53.12%] [G loss: 0.903173]\n",
      "epoch:21 step:20359 [D loss: 0.605690, acc.: 64.06%] [G loss: 0.989415]\n",
      "epoch:21 step:20360 [D loss: 0.620464, acc.: 67.19%] [G loss: 1.107930]\n",
      "epoch:21 step:20361 [D loss: 0.645127, acc.: 62.50%] [G loss: 0.838902]\n",
      "epoch:21 step:20362 [D loss: 0.635257, acc.: 66.41%] [G loss: 0.886416]\n",
      "epoch:21 step:20363 [D loss: 0.628777, acc.: 60.16%] [G loss: 0.785140]\n",
      "epoch:21 step:20364 [D loss: 0.650993, acc.: 59.38%] [G loss: 0.882434]\n",
      "epoch:21 step:20365 [D loss: 0.654885, acc.: 59.38%] [G loss: 0.989617]\n",
      "epoch:21 step:20366 [D loss: 0.635035, acc.: 60.94%] [G loss: 0.797458]\n",
      "epoch:21 step:20367 [D loss: 0.719159, acc.: 53.91%] [G loss: 1.001137]\n",
      "epoch:21 step:20368 [D loss: 0.693511, acc.: 56.25%] [G loss: 0.745901]\n",
      "epoch:21 step:20369 [D loss: 0.603747, acc.: 66.41%] [G loss: 0.825761]\n",
      "epoch:21 step:20370 [D loss: 0.651024, acc.: 64.06%] [G loss: 0.877209]\n",
      "epoch:21 step:20371 [D loss: 0.671151, acc.: 62.50%] [G loss: 1.030280]\n",
      "epoch:21 step:20372 [D loss: 0.682962, acc.: 56.25%] [G loss: 1.101038]\n",
      "epoch:21 step:20373 [D loss: 0.467139, acc.: 85.16%] [G loss: 0.910451]\n",
      "epoch:21 step:20374 [D loss: 0.484276, acc.: 69.53%] [G loss: 1.124050]\n",
      "epoch:21 step:20375 [D loss: 0.564763, acc.: 74.22%] [G loss: 1.079152]\n",
      "epoch:21 step:20376 [D loss: 0.552292, acc.: 78.91%] [G loss: 1.076521]\n",
      "epoch:21 step:20377 [D loss: 0.624125, acc.: 60.16%] [G loss: 1.003659]\n",
      "epoch:21 step:20378 [D loss: 0.508138, acc.: 76.56%] [G loss: 0.974710]\n",
      "epoch:21 step:20379 [D loss: 0.473926, acc.: 81.25%] [G loss: 1.191331]\n",
      "epoch:21 step:20380 [D loss: 0.577001, acc.: 69.53%] [G loss: 1.120064]\n",
      "epoch:21 step:20381 [D loss: 0.559218, acc.: 78.12%] [G loss: 1.196481]\n",
      "epoch:21 step:20382 [D loss: 0.666052, acc.: 59.38%] [G loss: 1.103572]\n",
      "epoch:21 step:20383 [D loss: 0.439218, acc.: 83.59%] [G loss: 1.053928]\n",
      "epoch:21 step:20384 [D loss: 0.378246, acc.: 87.50%] [G loss: 1.009553]\n",
      "epoch:21 step:20385 [D loss: 0.327393, acc.: 88.28%] [G loss: 1.053352]\n",
      "epoch:21 step:20386 [D loss: 0.258730, acc.: 98.44%] [G loss: 1.282253]\n",
      "epoch:21 step:20387 [D loss: 0.857639, acc.: 50.78%] [G loss: 1.172697]\n",
      "epoch:21 step:20388 [D loss: 0.671058, acc.: 54.69%] [G loss: 1.217016]\n",
      "epoch:21 step:20389 [D loss: 0.573288, acc.: 75.00%] [G loss: 1.093608]\n",
      "epoch:21 step:20390 [D loss: 0.272911, acc.: 91.41%] [G loss: 1.327510]\n",
      "epoch:21 step:20391 [D loss: 0.297059, acc.: 89.06%] [G loss: 1.267942]\n",
      "epoch:21 step:20392 [D loss: 0.690499, acc.: 57.81%] [G loss: 0.950159]\n",
      "epoch:21 step:20393 [D loss: 0.798803, acc.: 47.66%] [G loss: 1.058748]\n",
      "epoch:21 step:20394 [D loss: 0.730487, acc.: 51.56%] [G loss: 0.980308]\n",
      "epoch:21 step:20395 [D loss: 0.708519, acc.: 52.34%] [G loss: 1.046822]\n",
      "epoch:21 step:20396 [D loss: 0.648682, acc.: 57.03%] [G loss: 0.904641]\n",
      "epoch:21 step:20397 [D loss: 0.680073, acc.: 57.81%] [G loss: 0.968549]\n",
      "epoch:21 step:20398 [D loss: 0.734949, acc.: 50.78%] [G loss: 1.118841]\n",
      "epoch:21 step:20399 [D loss: 0.553667, acc.: 77.34%] [G loss: 0.911224]\n",
      "epoch:21 step:20400 [D loss: 0.543777, acc.: 75.78%] [G loss: 0.783261]\n",
      "epoch:21 step:20401 [D loss: 0.707712, acc.: 56.25%] [G loss: 1.055943]\n",
      "epoch:21 step:20402 [D loss: 0.665437, acc.: 56.25%] [G loss: 1.129185]\n",
      "epoch:21 step:20403 [D loss: 0.645426, acc.: 62.50%] [G loss: 1.058968]\n",
      "epoch:21 step:20404 [D loss: 0.457598, acc.: 82.03%] [G loss: 1.094566]\n",
      "epoch:21 step:20405 [D loss: 0.347390, acc.: 88.28%] [G loss: 1.178873]\n",
      "epoch:21 step:20406 [D loss: 0.349917, acc.: 92.97%] [G loss: 1.106726]\n",
      "epoch:21 step:20407 [D loss: 0.370758, acc.: 90.62%] [G loss: 1.249636]\n",
      "epoch:21 step:20408 [D loss: 0.650821, acc.: 66.41%] [G loss: 1.477375]\n",
      "epoch:21 step:20409 [D loss: 0.334402, acc.: 90.62%] [G loss: 1.542320]\n",
      "epoch:21 step:20410 [D loss: 0.333183, acc.: 92.19%] [G loss: 1.454877]\n",
      "epoch:21 step:20411 [D loss: 0.857450, acc.: 47.66%] [G loss: 1.094678]\n",
      "epoch:21 step:20412 [D loss: 0.718316, acc.: 57.03%] [G loss: 1.367838]\n",
      "epoch:21 step:20413 [D loss: 0.625278, acc.: 65.62%] [G loss: 1.204991]\n",
      "epoch:21 step:20414 [D loss: 0.674494, acc.: 58.59%] [G loss: 0.955408]\n",
      "epoch:21 step:20415 [D loss: 0.728407, acc.: 51.56%] [G loss: 1.070599]\n",
      "epoch:21 step:20416 [D loss: 0.725042, acc.: 47.66%] [G loss: 1.030586]\n",
      "epoch:21 step:20417 [D loss: 0.682798, acc.: 57.81%] [G loss: 1.019807]\n",
      "epoch:21 step:20418 [D loss: 0.558816, acc.: 72.66%] [G loss: 1.125590]\n",
      "epoch:21 step:20419 [D loss: 0.564017, acc.: 66.41%] [G loss: 1.074938]\n",
      "epoch:21 step:20420 [D loss: 0.615211, acc.: 64.06%] [G loss: 1.194416]\n",
      "epoch:21 step:20421 [D loss: 0.567521, acc.: 72.66%] [G loss: 1.282391]\n",
      "epoch:21 step:20422 [D loss: 0.519065, acc.: 76.56%] [G loss: 1.144965]\n",
      "epoch:21 step:20423 [D loss: 0.650967, acc.: 60.94%] [G loss: 1.102443]\n",
      "epoch:21 step:20424 [D loss: 0.632426, acc.: 62.50%] [G loss: 1.118997]\n",
      "epoch:21 step:20425 [D loss: 0.586972, acc.: 60.94%] [G loss: 1.072574]\n",
      "epoch:21 step:20426 [D loss: 0.479617, acc.: 82.03%] [G loss: 1.162951]\n",
      "epoch:21 step:20427 [D loss: 0.452225, acc.: 83.59%] [G loss: 1.298661]\n",
      "epoch:21 step:20428 [D loss: 0.738687, acc.: 53.91%] [G loss: 1.081057]\n",
      "epoch:21 step:20429 [D loss: 0.983298, acc.: 35.16%] [G loss: 0.976145]\n",
      "epoch:21 step:20430 [D loss: 0.674323, acc.: 56.25%] [G loss: 0.961158]\n",
      "epoch:21 step:20431 [D loss: 0.651603, acc.: 59.38%] [G loss: 0.856253]\n",
      "epoch:21 step:20432 [D loss: 0.539092, acc.: 77.34%] [G loss: 0.959037]\n",
      "epoch:21 step:20433 [D loss: 0.631835, acc.: 57.81%] [G loss: 0.891170]\n",
      "epoch:21 step:20434 [D loss: 0.613225, acc.: 65.62%] [G loss: 0.947661]\n",
      "epoch:21 step:20435 [D loss: 0.744014, acc.: 56.25%] [G loss: 0.772949]\n",
      "epoch:21 step:20436 [D loss: 0.544667, acc.: 72.66%] [G loss: 1.016332]\n",
      "epoch:21 step:20437 [D loss: 0.473835, acc.: 86.72%] [G loss: 1.030049]\n",
      "epoch:21 step:20438 [D loss: 0.702522, acc.: 48.44%] [G loss: 1.099707]\n",
      "epoch:21 step:20439 [D loss: 0.711132, acc.: 54.69%] [G loss: 1.048389]\n",
      "epoch:21 step:20440 [D loss: 0.790469, acc.: 42.19%] [G loss: 0.845621]\n",
      "epoch:21 step:20441 [D loss: 0.713419, acc.: 53.91%] [G loss: 0.952118]\n",
      "epoch:21 step:20442 [D loss: 0.593439, acc.: 75.00%] [G loss: 1.040160]\n",
      "epoch:21 step:20443 [D loss: 0.513474, acc.: 78.12%] [G loss: 1.008426]\n",
      "epoch:21 step:20444 [D loss: 0.563589, acc.: 70.31%] [G loss: 1.179890]\n",
      "epoch:21 step:20445 [D loss: 0.302485, acc.: 92.19%] [G loss: 1.265595]\n",
      "epoch:21 step:20446 [D loss: 0.290442, acc.: 96.09%] [G loss: 1.219500]\n",
      "epoch:21 step:20447 [D loss: 0.512850, acc.: 75.78%] [G loss: 1.252316]\n",
      "epoch:21 step:20448 [D loss: 0.668450, acc.: 61.72%] [G loss: 0.926000]\n",
      "epoch:21 step:20449 [D loss: 0.774320, acc.: 45.31%] [G loss: 0.907345]\n",
      "epoch:21 step:20450 [D loss: 0.484045, acc.: 83.59%] [G loss: 1.039038]\n",
      "epoch:21 step:20451 [D loss: 0.307792, acc.: 89.06%] [G loss: 1.239391]\n",
      "epoch:21 step:20452 [D loss: 0.327481, acc.: 88.28%] [G loss: 1.274459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20453 [D loss: 0.588986, acc.: 71.09%] [G loss: 1.001794]\n",
      "epoch:21 step:20454 [D loss: 0.558504, acc.: 71.09%] [G loss: 1.083865]\n",
      "epoch:21 step:20455 [D loss: 0.744442, acc.: 50.00%] [G loss: 1.310698]\n",
      "epoch:21 step:20456 [D loss: 1.048099, acc.: 41.41%] [G loss: 0.854996]\n",
      "epoch:21 step:20457 [D loss: 0.833974, acc.: 49.22%] [G loss: 1.037905]\n",
      "epoch:21 step:20458 [D loss: 0.678600, acc.: 54.69%] [G loss: 0.849106]\n",
      "epoch:21 step:20459 [D loss: 0.723774, acc.: 51.56%] [G loss: 0.861145]\n",
      "epoch:21 step:20460 [D loss: 0.715365, acc.: 57.03%] [G loss: 1.218759]\n",
      "epoch:21 step:20461 [D loss: 0.665098, acc.: 64.06%] [G loss: 0.978371]\n",
      "epoch:21 step:20462 [D loss: 0.657003, acc.: 60.16%] [G loss: 1.317029]\n",
      "epoch:21 step:20463 [D loss: 0.519819, acc.: 78.12%] [G loss: 1.075776]\n",
      "epoch:21 step:20464 [D loss: 0.641826, acc.: 67.19%] [G loss: 1.283721]\n",
      "epoch:21 step:20465 [D loss: 0.611768, acc.: 66.41%] [G loss: 1.110393]\n",
      "epoch:21 step:20466 [D loss: 0.645816, acc.: 60.16%] [G loss: 0.972012]\n",
      "epoch:21 step:20467 [D loss: 0.637198, acc.: 60.16%] [G loss: 1.004327]\n",
      "epoch:21 step:20468 [D loss: 0.434057, acc.: 84.38%] [G loss: 1.150243]\n",
      "epoch:21 step:20469 [D loss: 0.339107, acc.: 88.28%] [G loss: 1.333410]\n",
      "epoch:21 step:20470 [D loss: 0.320593, acc.: 90.62%] [G loss: 0.923728]\n",
      "epoch:21 step:20471 [D loss: 0.336423, acc.: 89.84%] [G loss: 1.127408]\n",
      "epoch:21 step:20472 [D loss: 0.491455, acc.: 82.81%] [G loss: 0.945187]\n",
      "epoch:21 step:20473 [D loss: 0.492690, acc.: 75.78%] [G loss: 1.190243]\n",
      "epoch:21 step:20474 [D loss: 0.653631, acc.: 64.06%] [G loss: 1.066922]\n",
      "epoch:21 step:20475 [D loss: 0.468828, acc.: 81.25%] [G loss: 1.103132]\n",
      "epoch:21 step:20476 [D loss: 0.738756, acc.: 50.00%] [G loss: 1.346838]\n",
      "epoch:21 step:20477 [D loss: 0.942465, acc.: 38.28%] [G loss: 1.044977]\n",
      "epoch:21 step:20478 [D loss: 0.637125, acc.: 67.19%] [G loss: 1.078507]\n",
      "epoch:21 step:20479 [D loss: 0.351807, acc.: 87.50%] [G loss: 0.926931]\n",
      "epoch:21 step:20480 [D loss: 0.601822, acc.: 71.09%] [G loss: 1.081245]\n",
      "epoch:21 step:20481 [D loss: 0.464629, acc.: 81.25%] [G loss: 1.182487]\n",
      "epoch:21 step:20482 [D loss: 0.462504, acc.: 89.06%] [G loss: 1.052514]\n",
      "epoch:21 step:20483 [D loss: 0.336603, acc.: 89.06%] [G loss: 0.808262]\n",
      "epoch:21 step:20484 [D loss: 0.698714, acc.: 53.12%] [G loss: 1.113054]\n",
      "epoch:21 step:20485 [D loss: 0.558759, acc.: 68.75%] [G loss: 0.947870]\n",
      "epoch:21 step:20486 [D loss: 0.593446, acc.: 68.75%] [G loss: 1.085575]\n",
      "epoch:21 step:20487 [D loss: 0.642043, acc.: 60.16%] [G loss: 1.178653]\n",
      "epoch:21 step:20488 [D loss: 0.799843, acc.: 46.09%] [G loss: 1.190375]\n",
      "epoch:21 step:20489 [D loss: 0.710314, acc.: 54.69%] [G loss: 1.192908]\n",
      "epoch:21 step:20490 [D loss: 0.622161, acc.: 67.19%] [G loss: 1.199728]\n",
      "epoch:21 step:20491 [D loss: 0.614485, acc.: 60.94%] [G loss: 0.979120]\n",
      "epoch:21 step:20492 [D loss: 0.269374, acc.: 95.31%] [G loss: 1.047409]\n",
      "epoch:21 step:20493 [D loss: 0.378422, acc.: 86.72%] [G loss: 1.292564]\n",
      "epoch:21 step:20494 [D loss: 0.590576, acc.: 62.50%] [G loss: 1.378885]\n",
      "epoch:21 step:20495 [D loss: 0.417195, acc.: 88.28%] [G loss: 1.268033]\n",
      "epoch:21 step:20496 [D loss: 0.467610, acc.: 79.69%] [G loss: 1.671549]\n",
      "epoch:21 step:20497 [D loss: 0.596005, acc.: 65.62%] [G loss: 1.636881]\n",
      "epoch:21 step:20498 [D loss: 0.803310, acc.: 50.78%] [G loss: 1.214185]\n",
      "epoch:21 step:20499 [D loss: 0.649314, acc.: 63.28%] [G loss: 1.046977]\n",
      "epoch:21 step:20500 [D loss: 0.465714, acc.: 83.59%] [G loss: 0.805746]\n",
      "epoch:21 step:20501 [D loss: 0.518092, acc.: 69.53%] [G loss: 0.848608]\n",
      "epoch:21 step:20502 [D loss: 0.266708, acc.: 94.53%] [G loss: 1.893864]\n",
      "epoch:21 step:20503 [D loss: 0.567082, acc.: 71.88%] [G loss: 1.441916]\n",
      "epoch:21 step:20504 [D loss: 0.671327, acc.: 60.94%] [G loss: 0.836533]\n",
      "epoch:21 step:20505 [D loss: 0.733242, acc.: 60.16%] [G loss: 1.335478]\n",
      "epoch:21 step:20506 [D loss: 0.481145, acc.: 80.47%] [G loss: 0.796878]\n",
      "epoch:21 step:20507 [D loss: 0.378598, acc.: 83.59%] [G loss: 1.531168]\n",
      "epoch:21 step:20508 [D loss: 0.197578, acc.: 96.09%] [G loss: 0.874896]\n",
      "epoch:21 step:20509 [D loss: 0.301689, acc.: 83.59%] [G loss: 0.995409]\n",
      "epoch:21 step:20510 [D loss: 0.470885, acc.: 70.31%] [G loss: 1.305943]\n",
      "epoch:21 step:20511 [D loss: 1.216340, acc.: 39.84%] [G loss: 1.008961]\n",
      "epoch:21 step:20512 [D loss: 0.967823, acc.: 43.75%] [G loss: 1.098593]\n",
      "epoch:21 step:20513 [D loss: 0.877237, acc.: 42.97%] [G loss: 1.125235]\n",
      "epoch:21 step:20514 [D loss: 1.423244, acc.: 22.66%] [G loss: 1.132641]\n",
      "epoch:21 step:20515 [D loss: 0.695944, acc.: 57.03%] [G loss: 0.665167]\n",
      "epoch:21 step:20516 [D loss: 0.724645, acc.: 57.81%] [G loss: 1.215536]\n",
      "epoch:21 step:20517 [D loss: 0.776286, acc.: 45.31%] [G loss: 1.005888]\n",
      "epoch:21 step:20518 [D loss: 0.770471, acc.: 32.03%] [G loss: 0.996171]\n",
      "epoch:21 step:20519 [D loss: 0.705401, acc.: 51.56%] [G loss: 1.045993]\n",
      "epoch:21 step:20520 [D loss: 0.553995, acc.: 73.44%] [G loss: 0.841361]\n",
      "epoch:21 step:20521 [D loss: 0.548041, acc.: 70.31%] [G loss: 0.954914]\n",
      "epoch:21 step:20522 [D loss: 0.421614, acc.: 86.72%] [G loss: 0.858110]\n",
      "epoch:21 step:20523 [D loss: 0.845653, acc.: 40.62%] [G loss: 0.847581]\n",
      "epoch:21 step:20524 [D loss: 0.793309, acc.: 35.94%] [G loss: 1.052236]\n",
      "epoch:21 step:20525 [D loss: 0.755639, acc.: 37.50%] [G loss: 0.932787]\n",
      "epoch:21 step:20526 [D loss: 0.721667, acc.: 53.12%] [G loss: 0.943971]\n",
      "epoch:21 step:20527 [D loss: 0.749518, acc.: 36.72%] [G loss: 1.009792]\n",
      "epoch:21 step:20528 [D loss: 0.531940, acc.: 76.56%] [G loss: 1.131702]\n",
      "epoch:21 step:20529 [D loss: 0.556226, acc.: 67.97%] [G loss: 1.087671]\n",
      "epoch:21 step:20530 [D loss: 0.583024, acc.: 70.31%] [G loss: 1.116481]\n",
      "epoch:21 step:20531 [D loss: 0.456942, acc.: 82.03%] [G loss: 1.056335]\n",
      "epoch:21 step:20532 [D loss: 0.614127, acc.: 65.62%] [G loss: 1.130569]\n",
      "epoch:21 step:20533 [D loss: 0.728845, acc.: 46.88%] [G loss: 1.016932]\n",
      "epoch:21 step:20534 [D loss: 0.523459, acc.: 77.34%] [G loss: 1.199811]\n",
      "epoch:21 step:20535 [D loss: 0.771089, acc.: 53.12%] [G loss: 0.983597]\n",
      "epoch:21 step:20536 [D loss: 0.656989, acc.: 57.81%] [G loss: 0.852198]\n",
      "epoch:21 step:20537 [D loss: 0.607054, acc.: 66.41%] [G loss: 0.914880]\n",
      "epoch:21 step:20538 [D loss: 0.681486, acc.: 60.94%] [G loss: 0.875216]\n",
      "epoch:21 step:20539 [D loss: 0.626685, acc.: 68.75%] [G loss: 0.844784]\n",
      "epoch:21 step:20540 [D loss: 0.639596, acc.: 62.50%] [G loss: 0.891871]\n",
      "epoch:21 step:20541 [D loss: 0.683093, acc.: 57.03%] [G loss: 0.840702]\n",
      "epoch:21 step:20542 [D loss: 0.610395, acc.: 68.75%] [G loss: 0.886826]\n",
      "epoch:21 step:20543 [D loss: 0.627884, acc.: 64.84%] [G loss: 0.782444]\n",
      "epoch:21 step:20544 [D loss: 0.588178, acc.: 67.97%] [G loss: 0.880301]\n",
      "epoch:21 step:20545 [D loss: 0.648400, acc.: 61.72%] [G loss: 0.927322]\n",
      "epoch:21 step:20546 [D loss: 0.590622, acc.: 75.00%] [G loss: 0.954041]\n",
      "epoch:21 step:20547 [D loss: 0.682538, acc.: 58.59%] [G loss: 1.069232]\n",
      "epoch:21 step:20548 [D loss: 0.571150, acc.: 75.00%] [G loss: 0.865519]\n",
      "epoch:21 step:20549 [D loss: 0.564505, acc.: 71.09%] [G loss: 0.837553]\n",
      "epoch:21 step:20550 [D loss: 0.645221, acc.: 57.81%] [G loss: 0.855651]\n",
      "epoch:21 step:20551 [D loss: 0.690192, acc.: 57.81%] [G loss: 0.954962]\n",
      "epoch:21 step:20552 [D loss: 0.529801, acc.: 73.44%] [G loss: 0.955042]\n",
      "epoch:21 step:20553 [D loss: 0.698544, acc.: 56.25%] [G loss: 0.910735]\n",
      "epoch:21 step:20554 [D loss: 0.581034, acc.: 67.19%] [G loss: 0.919900]\n",
      "epoch:21 step:20555 [D loss: 0.577725, acc.: 68.75%] [G loss: 0.935870]\n",
      "epoch:21 step:20556 [D loss: 0.710189, acc.: 53.12%] [G loss: 0.783490]\n",
      "epoch:21 step:20557 [D loss: 0.583945, acc.: 72.66%] [G loss: 1.009875]\n",
      "epoch:21 step:20558 [D loss: 0.623658, acc.: 68.75%] [G loss: 0.974611]\n",
      "epoch:21 step:20559 [D loss: 0.531666, acc.: 69.53%] [G loss: 0.915551]\n",
      "epoch:21 step:20560 [D loss: 0.461499, acc.: 86.72%] [G loss: 1.019410]\n",
      "epoch:21 step:20561 [D loss: 0.359125, acc.: 86.72%] [G loss: 1.108569]\n",
      "epoch:21 step:20562 [D loss: 0.297937, acc.: 88.28%] [G loss: 1.162268]\n",
      "epoch:21 step:20563 [D loss: 0.277089, acc.: 98.44%] [G loss: 1.140708]\n",
      "epoch:21 step:20564 [D loss: 0.248013, acc.: 95.31%] [G loss: 1.128000]\n",
      "epoch:21 step:20565 [D loss: 0.549530, acc.: 75.78%] [G loss: 1.046974]\n",
      "epoch:21 step:20566 [D loss: 0.272273, acc.: 98.44%] [G loss: 1.415349]\n",
      "epoch:21 step:20567 [D loss: 0.483694, acc.: 81.25%] [G loss: 1.171879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20568 [D loss: 0.760816, acc.: 52.34%] [G loss: 1.417323]\n",
      "epoch:21 step:20569 [D loss: 1.007227, acc.: 28.91%] [G loss: 1.279235]\n",
      "epoch:21 step:20570 [D loss: 0.756554, acc.: 55.47%] [G loss: 1.012850]\n",
      "epoch:21 step:20571 [D loss: 0.800959, acc.: 38.28%] [G loss: 1.023476]\n",
      "epoch:21 step:20572 [D loss: 0.837252, acc.: 40.62%] [G loss: 0.580253]\n",
      "epoch:21 step:20573 [D loss: 0.680376, acc.: 60.94%] [G loss: 0.987700]\n",
      "epoch:21 step:20574 [D loss: 0.685976, acc.: 58.59%] [G loss: 0.926889]\n",
      "epoch:21 step:20575 [D loss: 0.628422, acc.: 61.72%] [G loss: 0.855657]\n",
      "epoch:21 step:20576 [D loss: 0.554530, acc.: 70.31%] [G loss: 1.134666]\n",
      "epoch:21 step:20577 [D loss: 0.456530, acc.: 84.38%] [G loss: 1.100780]\n",
      "epoch:21 step:20578 [D loss: 0.709714, acc.: 50.78%] [G loss: 1.137546]\n",
      "epoch:21 step:20579 [D loss: 0.620129, acc.: 60.94%] [G loss: 0.953188]\n",
      "epoch:21 step:20580 [D loss: 0.649082, acc.: 55.47%] [G loss: 1.035926]\n",
      "epoch:21 step:20581 [D loss: 0.693632, acc.: 56.25%] [G loss: 1.249489]\n",
      "epoch:21 step:20582 [D loss: 0.462896, acc.: 84.38%] [G loss: 1.256489]\n",
      "epoch:21 step:20583 [D loss: 0.481050, acc.: 84.38%] [G loss: 1.128974]\n",
      "epoch:21 step:20584 [D loss: 0.669184, acc.: 54.69%] [G loss: 1.295979]\n",
      "epoch:21 step:20585 [D loss: 0.700846, acc.: 53.91%] [G loss: 1.103926]\n",
      "epoch:21 step:20586 [D loss: 0.556752, acc.: 73.44%] [G loss: 1.090171]\n",
      "epoch:21 step:20587 [D loss: 0.624422, acc.: 60.16%] [G loss: 1.035477]\n",
      "epoch:21 step:20588 [D loss: 0.492846, acc.: 82.81%] [G loss: 0.915114]\n",
      "epoch:21 step:20589 [D loss: 0.251767, acc.: 92.19%] [G loss: 1.191429]\n",
      "epoch:21 step:20590 [D loss: 0.625484, acc.: 57.81%] [G loss: 0.811276]\n",
      "epoch:21 step:20591 [D loss: 0.731636, acc.: 52.34%] [G loss: 1.095376]\n",
      "epoch:21 step:20592 [D loss: 0.710533, acc.: 52.34%] [G loss: 0.973039]\n",
      "epoch:21 step:20593 [D loss: 0.641926, acc.: 62.50%] [G loss: 1.018388]\n",
      "epoch:21 step:20594 [D loss: 0.549708, acc.: 77.34%] [G loss: 0.936341]\n",
      "epoch:21 step:20595 [D loss: 0.567495, acc.: 78.12%] [G loss: 0.990101]\n",
      "epoch:21 step:20596 [D loss: 0.401641, acc.: 89.84%] [G loss: 0.721390]\n",
      "epoch:21 step:20597 [D loss: 0.556845, acc.: 70.31%] [G loss: 1.134609]\n",
      "epoch:21 step:20598 [D loss: 0.373393, acc.: 85.94%] [G loss: 1.046551]\n",
      "epoch:21 step:20599 [D loss: 0.570901, acc.: 78.91%] [G loss: 0.980716]\n",
      "epoch:21 step:20600 [D loss: 0.562243, acc.: 71.88%] [G loss: 0.820151]\n",
      "epoch:21 step:20601 [D loss: 0.396688, acc.: 84.38%] [G loss: 1.056404]\n",
      "epoch:21 step:20602 [D loss: 0.358052, acc.: 90.62%] [G loss: 1.230539]\n",
      "epoch:21 step:20603 [D loss: 0.348532, acc.: 85.16%] [G loss: 1.201174]\n",
      "epoch:21 step:20604 [D loss: 0.306287, acc.: 85.16%] [G loss: 1.315141]\n",
      "epoch:21 step:20605 [D loss: 0.785112, acc.: 56.25%] [G loss: 1.224837]\n",
      "epoch:21 step:20606 [D loss: 0.305444, acc.: 90.62%] [G loss: 1.439295]\n",
      "epoch:21 step:20607 [D loss: 0.459805, acc.: 85.16%] [G loss: 1.313971]\n",
      "epoch:21 step:20608 [D loss: 0.564868, acc.: 73.44%] [G loss: 1.277311]\n",
      "epoch:21 step:20609 [D loss: 0.601448, acc.: 69.53%] [G loss: 1.271965]\n",
      "epoch:21 step:20610 [D loss: 0.326235, acc.: 93.75%] [G loss: 1.118345]\n",
      "epoch:21 step:20611 [D loss: 0.398091, acc.: 76.56%] [G loss: 1.304991]\n",
      "epoch:21 step:20612 [D loss: 0.378970, acc.: 93.75%] [G loss: 1.049079]\n",
      "epoch:21 step:20613 [D loss: 0.356151, acc.: 78.12%] [G loss: 1.247746]\n",
      "epoch:21 step:20614 [D loss: 0.170852, acc.: 97.66%] [G loss: 1.457747]\n",
      "epoch:22 step:20615 [D loss: 0.673398, acc.: 60.16%] [G loss: 1.149683]\n",
      "epoch:22 step:20616 [D loss: 0.794210, acc.: 48.44%] [G loss: 1.261131]\n",
      "epoch:22 step:20617 [D loss: 0.697480, acc.: 60.16%] [G loss: 1.155435]\n",
      "epoch:22 step:20618 [D loss: 0.868970, acc.: 39.06%] [G loss: 1.469547]\n",
      "epoch:22 step:20619 [D loss: 0.741981, acc.: 50.78%] [G loss: 1.164708]\n",
      "epoch:22 step:20620 [D loss: 0.810038, acc.: 48.44%] [G loss: 1.170817]\n",
      "epoch:22 step:20621 [D loss: 0.653674, acc.: 61.72%] [G loss: 1.296790]\n",
      "epoch:22 step:20622 [D loss: 0.583313, acc.: 68.75%] [G loss: 1.215595]\n",
      "epoch:22 step:20623 [D loss: 0.587080, acc.: 69.53%] [G loss: 1.126535]\n",
      "epoch:22 step:20624 [D loss: 0.646213, acc.: 55.47%] [G loss: 0.737567]\n",
      "epoch:22 step:20625 [D loss: 0.593900, acc.: 71.09%] [G loss: 1.095130]\n",
      "epoch:22 step:20626 [D loss: 0.557136, acc.: 67.97%] [G loss: 1.424411]\n",
      "epoch:22 step:20627 [D loss: 1.107077, acc.: 48.44%] [G loss: 1.334051]\n",
      "epoch:22 step:20628 [D loss: 0.666056, acc.: 61.72%] [G loss: 1.047099]\n",
      "epoch:22 step:20629 [D loss: 0.669855, acc.: 59.38%] [G loss: 0.930347]\n",
      "epoch:22 step:20630 [D loss: 0.720008, acc.: 57.03%] [G loss: 1.223744]\n",
      "epoch:22 step:20631 [D loss: 0.802695, acc.: 41.41%] [G loss: 1.158973]\n",
      "epoch:22 step:20632 [D loss: 0.777087, acc.: 45.31%] [G loss: 0.831399]\n",
      "epoch:22 step:20633 [D loss: 0.832066, acc.: 43.75%] [G loss: 1.204157]\n",
      "epoch:22 step:20634 [D loss: 0.625797, acc.: 68.75%] [G loss: 1.224350]\n",
      "epoch:22 step:20635 [D loss: 0.806249, acc.: 46.88%] [G loss: 1.100728]\n",
      "epoch:22 step:20636 [D loss: 0.720356, acc.: 49.22%] [G loss: 1.018738]\n",
      "epoch:22 step:20637 [D loss: 0.760623, acc.: 46.09%] [G loss: 1.096249]\n",
      "epoch:22 step:20638 [D loss: 0.722213, acc.: 54.69%] [G loss: 1.160893]\n",
      "epoch:22 step:20639 [D loss: 0.650975, acc.: 58.59%] [G loss: 1.001222]\n",
      "epoch:22 step:20640 [D loss: 0.678609, acc.: 53.91%] [G loss: 1.040627]\n",
      "epoch:22 step:20641 [D loss: 0.536763, acc.: 79.69%] [G loss: 1.033201]\n",
      "epoch:22 step:20642 [D loss: 0.584083, acc.: 69.53%] [G loss: 1.063899]\n",
      "epoch:22 step:20643 [D loss: 0.539105, acc.: 75.78%] [G loss: 1.083750]\n",
      "epoch:22 step:20644 [D loss: 0.596416, acc.: 70.31%] [G loss: 1.127375]\n",
      "epoch:22 step:20645 [D loss: 0.594973, acc.: 65.62%] [G loss: 1.023288]\n",
      "epoch:22 step:20646 [D loss: 0.459054, acc.: 77.34%] [G loss: 1.168046]\n",
      "epoch:22 step:20647 [D loss: 0.363028, acc.: 91.41%] [G loss: 1.466939]\n",
      "epoch:22 step:20648 [D loss: 0.416384, acc.: 85.94%] [G loss: 1.267498]\n",
      "epoch:22 step:20649 [D loss: 0.260804, acc.: 93.75%] [G loss: 1.505225]\n",
      "epoch:22 step:20650 [D loss: 0.221223, acc.: 93.75%] [G loss: 1.310192]\n",
      "epoch:22 step:20651 [D loss: 0.696544, acc.: 56.25%] [G loss: 1.058491]\n",
      "epoch:22 step:20652 [D loss: 0.785341, acc.: 59.38%] [G loss: 1.105871]\n",
      "epoch:22 step:20653 [D loss: 0.930403, acc.: 38.28%] [G loss: 1.095598]\n",
      "epoch:22 step:20654 [D loss: 0.667739, acc.: 65.62%] [G loss: 0.893009]\n",
      "epoch:22 step:20655 [D loss: 0.628410, acc.: 65.62%] [G loss: 0.909317]\n",
      "epoch:22 step:20656 [D loss: 0.576527, acc.: 75.00%] [G loss: 1.030745]\n",
      "epoch:22 step:20657 [D loss: 0.523649, acc.: 71.88%] [G loss: 0.805969]\n",
      "epoch:22 step:20658 [D loss: 0.512943, acc.: 85.16%] [G loss: 0.781733]\n",
      "epoch:22 step:20659 [D loss: 0.595320, acc.: 71.09%] [G loss: 1.000599]\n",
      "epoch:22 step:20660 [D loss: 0.816781, acc.: 47.66%] [G loss: 0.752205]\n",
      "epoch:22 step:20661 [D loss: 0.682036, acc.: 56.25%] [G loss: 0.894991]\n",
      "epoch:22 step:20662 [D loss: 0.694595, acc.: 56.25%] [G loss: 1.030878]\n",
      "epoch:22 step:20663 [D loss: 0.670499, acc.: 61.72%] [G loss: 0.817727]\n",
      "epoch:22 step:20664 [D loss: 0.679442, acc.: 55.47%] [G loss: 0.887432]\n",
      "epoch:22 step:20665 [D loss: 0.596611, acc.: 66.41%] [G loss: 0.909490]\n",
      "epoch:22 step:20666 [D loss: 0.602577, acc.: 69.53%] [G loss: 0.713172]\n",
      "epoch:22 step:20667 [D loss: 0.601182, acc.: 68.75%] [G loss: 0.764899]\n",
      "epoch:22 step:20668 [D loss: 0.742474, acc.: 50.00%] [G loss: 0.466430]\n",
      "epoch:22 step:20669 [D loss: 0.794915, acc.: 41.41%] [G loss: 0.895205]\n",
      "epoch:22 step:20670 [D loss: 0.956270, acc.: 28.91%] [G loss: 1.042278]\n",
      "epoch:22 step:20671 [D loss: 0.464686, acc.: 79.69%] [G loss: 0.979233]\n",
      "epoch:22 step:20672 [D loss: 0.734904, acc.: 52.34%] [G loss: 1.172303]\n",
      "epoch:22 step:20673 [D loss: 0.521205, acc.: 77.34%] [G loss: 1.086090]\n",
      "epoch:22 step:20674 [D loss: 0.494352, acc.: 82.81%] [G loss: 1.371693]\n",
      "epoch:22 step:20675 [D loss: 0.895206, acc.: 28.12%] [G loss: 1.075534]\n",
      "epoch:22 step:20676 [D loss: 0.872114, acc.: 35.16%] [G loss: 0.996112]\n",
      "epoch:22 step:20677 [D loss: 0.609681, acc.: 71.09%] [G loss: 0.934794]\n",
      "epoch:22 step:20678 [D loss: 0.618308, acc.: 66.41%] [G loss: 1.034187]\n",
      "epoch:22 step:20679 [D loss: 0.735419, acc.: 46.09%] [G loss: 1.020893]\n",
      "epoch:22 step:20680 [D loss: 0.722739, acc.: 46.09%] [G loss: 0.887781]\n",
      "epoch:22 step:20681 [D loss: 0.683893, acc.: 53.91%] [G loss: 1.001356]\n",
      "epoch:22 step:20682 [D loss: 0.630962, acc.: 68.75%] [G loss: 1.004214]\n",
      "epoch:22 step:20683 [D loss: 0.529571, acc.: 81.25%] [G loss: 0.818288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20684 [D loss: 0.639694, acc.: 61.72%] [G loss: 0.910154]\n",
      "epoch:22 step:20685 [D loss: 0.508747, acc.: 72.66%] [G loss: 0.870910]\n",
      "epoch:22 step:20686 [D loss: 0.471108, acc.: 85.16%] [G loss: 0.985443]\n",
      "epoch:22 step:20687 [D loss: 0.568727, acc.: 71.09%] [G loss: 0.842752]\n",
      "epoch:22 step:20688 [D loss: 0.610568, acc.: 63.28%] [G loss: 0.918586]\n",
      "epoch:22 step:20689 [D loss: 0.340248, acc.: 92.97%] [G loss: 1.161868]\n",
      "epoch:22 step:20690 [D loss: 0.317947, acc.: 95.31%] [G loss: 1.096438]\n",
      "epoch:22 step:20691 [D loss: 0.455428, acc.: 85.16%] [G loss: 1.079415]\n",
      "epoch:22 step:20692 [D loss: 0.781407, acc.: 50.78%] [G loss: 1.057069]\n",
      "epoch:22 step:20693 [D loss: 0.658419, acc.: 64.06%] [G loss: 0.977311]\n",
      "epoch:22 step:20694 [D loss: 0.748541, acc.: 48.44%] [G loss: 0.933846]\n",
      "epoch:22 step:20695 [D loss: 0.583285, acc.: 67.19%] [G loss: 1.081016]\n",
      "epoch:22 step:20696 [D loss: 0.653018, acc.: 62.50%] [G loss: 1.017894]\n",
      "epoch:22 step:20697 [D loss: 0.597784, acc.: 69.53%] [G loss: 0.995979]\n",
      "epoch:22 step:20698 [D loss: 0.639386, acc.: 60.16%] [G loss: 0.977191]\n",
      "epoch:22 step:20699 [D loss: 0.566913, acc.: 71.09%] [G loss: 0.961708]\n",
      "epoch:22 step:20700 [D loss: 0.715014, acc.: 54.69%] [G loss: 0.943846]\n",
      "epoch:22 step:20701 [D loss: 0.682350, acc.: 58.59%] [G loss: 0.920918]\n",
      "epoch:22 step:20702 [D loss: 0.620110, acc.: 60.94%] [G loss: 0.982018]\n",
      "epoch:22 step:20703 [D loss: 0.580812, acc.: 65.62%] [G loss: 0.984297]\n",
      "epoch:22 step:20704 [D loss: 0.638232, acc.: 62.50%] [G loss: 0.997793]\n",
      "epoch:22 step:20705 [D loss: 0.623448, acc.: 61.72%] [G loss: 1.008164]\n",
      "epoch:22 step:20706 [D loss: 0.576064, acc.: 74.22%] [G loss: 0.950529]\n",
      "epoch:22 step:20707 [D loss: 0.603131, acc.: 66.41%] [G loss: 0.983218]\n",
      "epoch:22 step:20708 [D loss: 0.576052, acc.: 68.75%] [G loss: 0.819045]\n",
      "epoch:22 step:20709 [D loss: 0.575819, acc.: 71.88%] [G loss: 1.078674]\n",
      "epoch:22 step:20710 [D loss: 0.686980, acc.: 59.38%] [G loss: 0.731304]\n",
      "epoch:22 step:20711 [D loss: 0.668343, acc.: 60.94%] [G loss: 0.609599]\n",
      "epoch:22 step:20712 [D loss: 0.651733, acc.: 64.06%] [G loss: 0.952583]\n",
      "epoch:22 step:20713 [D loss: 0.634666, acc.: 64.84%] [G loss: 0.779459]\n",
      "epoch:22 step:20714 [D loss: 0.591820, acc.: 68.75%] [G loss: 0.848379]\n",
      "epoch:22 step:20715 [D loss: 0.679785, acc.: 56.25%] [G loss: 0.993204]\n",
      "epoch:22 step:20716 [D loss: 0.790362, acc.: 49.22%] [G loss: 0.778596]\n",
      "epoch:22 step:20717 [D loss: 0.731463, acc.: 48.44%] [G loss: 0.951838]\n",
      "epoch:22 step:20718 [D loss: 0.778707, acc.: 42.97%] [G loss: 0.812594]\n",
      "epoch:22 step:20719 [D loss: 0.411244, acc.: 84.38%] [G loss: 0.985586]\n",
      "epoch:22 step:20720 [D loss: 0.608713, acc.: 74.22%] [G loss: 0.963882]\n",
      "epoch:22 step:20721 [D loss: 0.546659, acc.: 76.56%] [G loss: 1.172425]\n",
      "epoch:22 step:20722 [D loss: 0.633001, acc.: 60.94%] [G loss: 1.117478]\n",
      "epoch:22 step:20723 [D loss: 0.640442, acc.: 57.03%] [G loss: 1.136394]\n",
      "epoch:22 step:20724 [D loss: 0.651795, acc.: 60.16%] [G loss: 0.927057]\n",
      "epoch:22 step:20725 [D loss: 0.668771, acc.: 60.94%] [G loss: 0.905350]\n",
      "epoch:22 step:20726 [D loss: 0.667837, acc.: 55.47%] [G loss: 0.935565]\n",
      "epoch:22 step:20727 [D loss: 0.629342, acc.: 64.84%] [G loss: 1.026169]\n",
      "epoch:22 step:20728 [D loss: 0.554998, acc.: 78.12%] [G loss: 1.095839]\n",
      "epoch:22 step:20729 [D loss: 0.588227, acc.: 71.09%] [G loss: 0.956004]\n",
      "epoch:22 step:20730 [D loss: 0.670086, acc.: 57.81%] [G loss: 1.058967]\n",
      "epoch:22 step:20731 [D loss: 0.438966, acc.: 82.03%] [G loss: 1.061204]\n",
      "epoch:22 step:20732 [D loss: 0.488886, acc.: 76.56%] [G loss: 1.011493]\n",
      "epoch:22 step:20733 [D loss: 0.328455, acc.: 85.94%] [G loss: 1.333985]\n",
      "epoch:22 step:20734 [D loss: 0.571123, acc.: 68.75%] [G loss: 1.370351]\n",
      "epoch:22 step:20735 [D loss: 0.436777, acc.: 82.03%] [G loss: 1.377571]\n",
      "epoch:22 step:20736 [D loss: 0.463837, acc.: 78.12%] [G loss: 1.376101]\n",
      "epoch:22 step:20737 [D loss: 0.559339, acc.: 67.19%] [G loss: 1.128696]\n",
      "epoch:22 step:20738 [D loss: 0.734756, acc.: 52.34%] [G loss: 1.164660]\n",
      "epoch:22 step:20739 [D loss: 0.806479, acc.: 45.31%] [G loss: 1.315463]\n",
      "epoch:22 step:20740 [D loss: 0.631189, acc.: 62.50%] [G loss: 1.209183]\n",
      "epoch:22 step:20741 [D loss: 0.699528, acc.: 52.34%] [G loss: 1.148518]\n",
      "epoch:22 step:20742 [D loss: 0.626982, acc.: 60.94%] [G loss: 1.141730]\n",
      "epoch:22 step:20743 [D loss: 0.412096, acc.: 92.97%] [G loss: 0.972193]\n",
      "epoch:22 step:20744 [D loss: 0.331763, acc.: 90.62%] [G loss: 1.174048]\n",
      "epoch:22 step:20745 [D loss: 0.424042, acc.: 82.81%] [G loss: 1.203951]\n",
      "epoch:22 step:20746 [D loss: 0.447401, acc.: 82.81%] [G loss: 1.381001]\n",
      "epoch:22 step:20747 [D loss: 0.754567, acc.: 46.88%] [G loss: 1.333125]\n",
      "epoch:22 step:20748 [D loss: 0.640636, acc.: 68.75%] [G loss: 1.168755]\n",
      "epoch:22 step:20749 [D loss: 0.632030, acc.: 65.62%] [G loss: 1.212895]\n",
      "epoch:22 step:20750 [D loss: 0.595287, acc.: 65.62%] [G loss: 1.157203]\n",
      "epoch:22 step:20751 [D loss: 0.619153, acc.: 64.06%] [G loss: 0.993564]\n",
      "epoch:22 step:20752 [D loss: 0.593010, acc.: 72.66%] [G loss: 0.941338]\n",
      "epoch:22 step:20753 [D loss: 0.543145, acc.: 68.75%] [G loss: 0.807883]\n",
      "epoch:22 step:20754 [D loss: 0.720836, acc.: 50.00%] [G loss: 1.085644]\n",
      "epoch:22 step:20755 [D loss: 0.720742, acc.: 57.03%] [G loss: 1.011626]\n",
      "epoch:22 step:20756 [D loss: 0.713995, acc.: 51.56%] [G loss: 1.015215]\n",
      "epoch:22 step:20757 [D loss: 0.627897, acc.: 66.41%] [G loss: 1.096877]\n",
      "epoch:22 step:20758 [D loss: 0.496802, acc.: 78.12%] [G loss: 1.029396]\n",
      "epoch:22 step:20759 [D loss: 0.432740, acc.: 80.47%] [G loss: 1.142903]\n",
      "epoch:22 step:20760 [D loss: 0.504935, acc.: 85.16%] [G loss: 1.168203]\n",
      "epoch:22 step:20761 [D loss: 0.711598, acc.: 55.47%] [G loss: 0.988859]\n",
      "epoch:22 step:20762 [D loss: 0.778001, acc.: 49.22%] [G loss: 1.056226]\n",
      "epoch:22 step:20763 [D loss: 0.504019, acc.: 75.00%] [G loss: 0.858708]\n",
      "epoch:22 step:20764 [D loss: 0.325611, acc.: 85.94%] [G loss: 1.140857]\n",
      "epoch:22 step:20765 [D loss: 0.296536, acc.: 94.53%] [G loss: 1.579305]\n",
      "epoch:22 step:20766 [D loss: 0.340955, acc.: 90.62%] [G loss: 1.357767]\n",
      "epoch:22 step:20767 [D loss: 0.759371, acc.: 49.22%] [G loss: 1.385845]\n",
      "epoch:22 step:20768 [D loss: 0.643516, acc.: 61.72%] [G loss: 1.262868]\n",
      "epoch:22 step:20769 [D loss: 0.645787, acc.: 60.16%] [G loss: 1.086410]\n",
      "epoch:22 step:20770 [D loss: 0.677470, acc.: 60.94%] [G loss: 1.043129]\n",
      "epoch:22 step:20771 [D loss: 0.662418, acc.: 56.25%] [G loss: 0.909594]\n",
      "epoch:22 step:20772 [D loss: 0.659920, acc.: 57.81%] [G loss: 0.773483]\n",
      "epoch:22 step:20773 [D loss: 0.817407, acc.: 37.50%] [G loss: 0.870057]\n",
      "epoch:22 step:20774 [D loss: 0.662824, acc.: 57.81%] [G loss: 0.897528]\n",
      "epoch:22 step:20775 [D loss: 0.693054, acc.: 57.03%] [G loss: 1.140193]\n",
      "epoch:22 step:20776 [D loss: 0.525914, acc.: 78.91%] [G loss: 0.860726]\n",
      "epoch:22 step:20777 [D loss: 0.683300, acc.: 57.03%] [G loss: 0.921680]\n",
      "epoch:22 step:20778 [D loss: 0.680948, acc.: 61.72%] [G loss: 0.954045]\n",
      "epoch:22 step:20779 [D loss: 0.541073, acc.: 75.00%] [G loss: 0.841252]\n",
      "epoch:22 step:20780 [D loss: 0.725073, acc.: 49.22%] [G loss: 0.926077]\n",
      "epoch:22 step:20781 [D loss: 0.748946, acc.: 45.31%] [G loss: 0.839801]\n",
      "epoch:22 step:20782 [D loss: 0.590213, acc.: 67.97%] [G loss: 0.997629]\n",
      "epoch:22 step:20783 [D loss: 0.693444, acc.: 57.03%] [G loss: 1.012955]\n",
      "epoch:22 step:20784 [D loss: 0.565686, acc.: 73.44%] [G loss: 0.949371]\n",
      "epoch:22 step:20785 [D loss: 0.662110, acc.: 64.06%] [G loss: 0.954880]\n",
      "epoch:22 step:20786 [D loss: 0.666724, acc.: 61.72%] [G loss: 0.840366]\n",
      "epoch:22 step:20787 [D loss: 0.645279, acc.: 60.94%] [G loss: 0.971753]\n",
      "epoch:22 step:20788 [D loss: 0.657826, acc.: 58.59%] [G loss: 0.817851]\n",
      "epoch:22 step:20789 [D loss: 0.706934, acc.: 57.81%] [G loss: 0.786733]\n",
      "epoch:22 step:20790 [D loss: 0.655282, acc.: 59.38%] [G loss: 0.914577]\n",
      "epoch:22 step:20791 [D loss: 0.634097, acc.: 64.06%] [G loss: 0.918471]\n",
      "epoch:22 step:20792 [D loss: 0.727038, acc.: 53.91%] [G loss: 1.053959]\n",
      "epoch:22 step:20793 [D loss: 0.568920, acc.: 70.31%] [G loss: 1.108998]\n",
      "epoch:22 step:20794 [D loss: 0.594866, acc.: 71.88%] [G loss: 0.996550]\n",
      "epoch:22 step:20795 [D loss: 0.756315, acc.: 52.34%] [G loss: 1.049438]\n",
      "epoch:22 step:20796 [D loss: 0.691512, acc.: 57.03%] [G loss: 1.003391]\n",
      "epoch:22 step:20797 [D loss: 1.100292, acc.: 32.81%] [G loss: 0.943448]\n",
      "epoch:22 step:20798 [D loss: 0.551055, acc.: 74.22%] [G loss: 0.970693]\n",
      "epoch:22 step:20799 [D loss: 0.703947, acc.: 53.12%] [G loss: 0.983559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20800 [D loss: 0.638991, acc.: 63.28%] [G loss: 1.062267]\n",
      "epoch:22 step:20801 [D loss: 0.627681, acc.: 65.62%] [G loss: 0.978324]\n",
      "epoch:22 step:20802 [D loss: 0.583322, acc.: 72.66%] [G loss: 1.008386]\n",
      "epoch:22 step:20803 [D loss: 0.691514, acc.: 61.72%] [G loss: 0.885765]\n",
      "epoch:22 step:20804 [D loss: 0.609208, acc.: 69.53%] [G loss: 1.053982]\n",
      "epoch:22 step:20805 [D loss: 0.555907, acc.: 75.78%] [G loss: 0.856240]\n",
      "epoch:22 step:20806 [D loss: 0.475191, acc.: 75.78%] [G loss: 0.876780]\n",
      "epoch:22 step:20807 [D loss: 0.516428, acc.: 78.91%] [G loss: 0.986457]\n",
      "epoch:22 step:20808 [D loss: 0.587234, acc.: 67.97%] [G loss: 0.968931]\n",
      "epoch:22 step:20809 [D loss: 0.519257, acc.: 79.69%] [G loss: 0.910510]\n",
      "epoch:22 step:20810 [D loss: 0.669160, acc.: 59.38%] [G loss: 1.072059]\n",
      "epoch:22 step:20811 [D loss: 0.485200, acc.: 84.38%] [G loss: 0.943554]\n",
      "epoch:22 step:20812 [D loss: 0.677416, acc.: 58.59%] [G loss: 0.860318]\n",
      "epoch:22 step:20813 [D loss: 0.711225, acc.: 49.22%] [G loss: 0.866024]\n",
      "epoch:22 step:20814 [D loss: 0.573570, acc.: 67.19%] [G loss: 0.949883]\n",
      "epoch:22 step:20815 [D loss: 0.347094, acc.: 90.62%] [G loss: 0.910177]\n",
      "epoch:22 step:20816 [D loss: 0.650793, acc.: 59.38%] [G loss: 1.048653]\n",
      "epoch:22 step:20817 [D loss: 0.588163, acc.: 67.19%] [G loss: 0.887265]\n",
      "epoch:22 step:20818 [D loss: 0.491132, acc.: 70.31%] [G loss: 0.971514]\n",
      "epoch:22 step:20819 [D loss: 0.512492, acc.: 78.91%] [G loss: 1.055882]\n",
      "epoch:22 step:20820 [D loss: 0.448287, acc.: 86.72%] [G loss: 0.882181]\n",
      "epoch:22 step:20821 [D loss: 0.403704, acc.: 72.66%] [G loss: 1.175907]\n",
      "epoch:22 step:20822 [D loss: 0.790732, acc.: 41.41%] [G loss: 1.130459]\n",
      "epoch:22 step:20823 [D loss: 0.422180, acc.: 87.50%] [G loss: 1.283800]\n",
      "epoch:22 step:20824 [D loss: 0.821671, acc.: 49.22%] [G loss: 0.764521]\n",
      "epoch:22 step:20825 [D loss: 0.937835, acc.: 30.47%] [G loss: 1.110351]\n",
      "epoch:22 step:20826 [D loss: 0.818374, acc.: 42.97%] [G loss: 1.122581]\n",
      "epoch:22 step:20827 [D loss: 0.694022, acc.: 57.81%] [G loss: 1.156266]\n",
      "epoch:22 step:20828 [D loss: 0.809605, acc.: 48.44%] [G loss: 1.008798]\n",
      "epoch:22 step:20829 [D loss: 0.752803, acc.: 46.88%] [G loss: 0.896033]\n",
      "epoch:22 step:20830 [D loss: 0.675694, acc.: 58.59%] [G loss: 1.007187]\n",
      "epoch:22 step:20831 [D loss: 0.712860, acc.: 54.69%] [G loss: 0.852862]\n",
      "epoch:22 step:20832 [D loss: 0.633961, acc.: 63.28%] [G loss: 0.774463]\n",
      "epoch:22 step:20833 [D loss: 0.596118, acc.: 68.75%] [G loss: 0.715887]\n",
      "epoch:22 step:20834 [D loss: 0.377837, acc.: 75.00%] [G loss: 0.977333]\n",
      "epoch:22 step:20835 [D loss: 0.307351, acc.: 92.19%] [G loss: 1.108909]\n",
      "epoch:22 step:20836 [D loss: 0.347513, acc.: 88.28%] [G loss: 1.198978]\n",
      "epoch:22 step:20837 [D loss: 0.294433, acc.: 95.31%] [G loss: 1.133459]\n",
      "epoch:22 step:20838 [D loss: 0.756666, acc.: 50.78%] [G loss: 1.075709]\n",
      "epoch:22 step:20839 [D loss: 0.668948, acc.: 56.25%] [G loss: 0.928842]\n",
      "epoch:22 step:20840 [D loss: 0.591463, acc.: 71.09%] [G loss: 0.865775]\n",
      "epoch:22 step:20841 [D loss: 0.546850, acc.: 78.91%] [G loss: 0.854374]\n",
      "epoch:22 step:20842 [D loss: 0.573567, acc.: 75.00%] [G loss: 1.052142]\n",
      "epoch:22 step:20843 [D loss: 0.605122, acc.: 73.44%] [G loss: 1.034409]\n",
      "epoch:22 step:20844 [D loss: 0.219466, acc.: 96.09%] [G loss: 1.005043]\n",
      "epoch:22 step:20845 [D loss: 0.290064, acc.: 89.84%] [G loss: 1.168187]\n",
      "epoch:22 step:20846 [D loss: 0.316930, acc.: 89.06%] [G loss: 1.435445]\n",
      "epoch:22 step:20847 [D loss: 0.697241, acc.: 57.03%] [G loss: 1.324948]\n",
      "epoch:22 step:20848 [D loss: 0.489221, acc.: 79.69%] [G loss: 1.477807]\n",
      "epoch:22 step:20849 [D loss: 0.311788, acc.: 92.19%] [G loss: 1.282112]\n",
      "epoch:22 step:20850 [D loss: 0.492467, acc.: 81.25%] [G loss: 1.365815]\n",
      "epoch:22 step:20851 [D loss: 0.539694, acc.: 77.34%] [G loss: 1.070016]\n",
      "epoch:22 step:20852 [D loss: 0.397965, acc.: 89.06%] [G loss: 0.807925]\n",
      "epoch:22 step:20853 [D loss: 0.639966, acc.: 63.28%] [G loss: 1.414380]\n",
      "epoch:22 step:20854 [D loss: 0.449858, acc.: 82.81%] [G loss: 0.935193]\n",
      "epoch:22 step:20855 [D loss: 0.782109, acc.: 48.44%] [G loss: 1.143298]\n",
      "epoch:22 step:20856 [D loss: 0.676181, acc.: 58.59%] [G loss: 0.937157]\n",
      "epoch:22 step:20857 [D loss: 0.363569, acc.: 89.06%] [G loss: 0.678842]\n",
      "epoch:22 step:20858 [D loss: 1.016222, acc.: 36.72%] [G loss: 1.047948]\n",
      "epoch:22 step:20859 [D loss: 0.791447, acc.: 44.53%] [G loss: 1.004461]\n",
      "epoch:22 step:20860 [D loss: 0.919439, acc.: 32.81%] [G loss: 1.079282]\n",
      "epoch:22 step:20861 [D loss: 0.766288, acc.: 49.22%] [G loss: 1.143236]\n",
      "epoch:22 step:20862 [D loss: 0.656525, acc.: 67.19%] [G loss: 1.061145]\n",
      "epoch:22 step:20863 [D loss: 0.690149, acc.: 57.81%] [G loss: 0.848542]\n",
      "epoch:22 step:20864 [D loss: 0.700302, acc.: 53.91%] [G loss: 0.937251]\n",
      "epoch:22 step:20865 [D loss: 0.801678, acc.: 44.53%] [G loss: 0.836011]\n",
      "epoch:22 step:20866 [D loss: 0.651578, acc.: 61.72%] [G loss: 0.839131]\n",
      "epoch:22 step:20867 [D loss: 0.694257, acc.: 54.69%] [G loss: 0.995752]\n",
      "epoch:22 step:20868 [D loss: 0.678328, acc.: 60.94%] [G loss: 0.855029]\n",
      "epoch:22 step:20869 [D loss: 0.402114, acc.: 88.28%] [G loss: 0.950543]\n",
      "epoch:22 step:20870 [D loss: 0.359444, acc.: 86.72%] [G loss: 1.053756]\n",
      "epoch:22 step:20871 [D loss: 0.427953, acc.: 85.94%] [G loss: 1.069241]\n",
      "epoch:22 step:20872 [D loss: 0.549429, acc.: 80.47%] [G loss: 1.017802]\n",
      "epoch:22 step:20873 [D loss: 0.322782, acc.: 89.84%] [G loss: 1.179279]\n",
      "epoch:22 step:20874 [D loss: 0.450031, acc.: 82.03%] [G loss: 1.242149]\n",
      "epoch:22 step:20875 [D loss: 0.242943, acc.: 96.88%] [G loss: 1.348475]\n",
      "epoch:22 step:20876 [D loss: 0.793350, acc.: 42.97%] [G loss: 1.345026]\n",
      "epoch:22 step:20877 [D loss: 0.248831, acc.: 92.97%] [G loss: 1.415942]\n",
      "epoch:22 step:20878 [D loss: 0.714508, acc.: 50.78%] [G loss: 1.117823]\n",
      "epoch:22 step:20879 [D loss: 0.822434, acc.: 50.78%] [G loss: 1.400916]\n",
      "epoch:22 step:20880 [D loss: 0.736038, acc.: 56.25%] [G loss: 1.071533]\n",
      "epoch:22 step:20881 [D loss: 0.829137, acc.: 34.38%] [G loss: 1.073369]\n",
      "epoch:22 step:20882 [D loss: 0.690380, acc.: 55.47%] [G loss: 0.937169]\n",
      "epoch:22 step:20883 [D loss: 0.543251, acc.: 70.31%] [G loss: 1.102149]\n",
      "epoch:22 step:20884 [D loss: 0.750703, acc.: 50.00%] [G loss: 1.245623]\n",
      "epoch:22 step:20885 [D loss: 0.533165, acc.: 75.78%] [G loss: 1.389886]\n",
      "epoch:22 step:20886 [D loss: 0.465179, acc.: 82.81%] [G loss: 1.174738]\n",
      "epoch:22 step:20887 [D loss: 0.588041, acc.: 63.28%] [G loss: 1.276487]\n",
      "epoch:22 step:20888 [D loss: 0.463513, acc.: 82.03%] [G loss: 1.304260]\n",
      "epoch:22 step:20889 [D loss: 0.513617, acc.: 77.34%] [G loss: 1.181927]\n",
      "epoch:22 step:20890 [D loss: 0.551137, acc.: 69.53%] [G loss: 1.148891]\n",
      "epoch:22 step:20891 [D loss: 0.638954, acc.: 59.38%] [G loss: 1.484251]\n",
      "epoch:22 step:20892 [D loss: 0.748511, acc.: 55.47%] [G loss: 0.949195]\n",
      "epoch:22 step:20893 [D loss: 0.364305, acc.: 92.97%] [G loss: 1.055918]\n",
      "epoch:22 step:20894 [D loss: 0.658712, acc.: 60.16%] [G loss: 0.905119]\n",
      "epoch:22 step:20895 [D loss: 0.630526, acc.: 64.84%] [G loss: 1.037004]\n",
      "epoch:22 step:20896 [D loss: 0.596060, acc.: 60.94%] [G loss: 1.006076]\n",
      "epoch:22 step:20897 [D loss: 0.839440, acc.: 41.41%] [G loss: 1.077866]\n",
      "epoch:22 step:20898 [D loss: 0.638469, acc.: 61.72%] [G loss: 1.035546]\n",
      "epoch:22 step:20899 [D loss: 0.556582, acc.: 74.22%] [G loss: 1.139544]\n",
      "epoch:22 step:20900 [D loss: 0.483163, acc.: 80.47%] [G loss: 0.976430]\n",
      "epoch:22 step:20901 [D loss: 0.653796, acc.: 57.81%] [G loss: 1.046982]\n",
      "epoch:22 step:20902 [D loss: 0.521022, acc.: 78.12%] [G loss: 0.715223]\n",
      "epoch:22 step:20903 [D loss: 0.464533, acc.: 81.25%] [G loss: 1.001395]\n",
      "epoch:22 step:20904 [D loss: 0.499645, acc.: 80.47%] [G loss: 1.109142]\n",
      "epoch:22 step:20905 [D loss: 0.437558, acc.: 81.25%] [G loss: 1.201525]\n",
      "epoch:22 step:20906 [D loss: 0.747482, acc.: 65.62%] [G loss: 1.299600]\n",
      "epoch:22 step:20907 [D loss: 0.486335, acc.: 81.25%] [G loss: 0.837684]\n",
      "epoch:22 step:20908 [D loss: 0.527021, acc.: 75.78%] [G loss: 0.871334]\n",
      "epoch:22 step:20909 [D loss: 0.758322, acc.: 47.66%] [G loss: 1.263405]\n",
      "epoch:22 step:20910 [D loss: 0.640765, acc.: 60.94%] [G loss: 1.075945]\n",
      "epoch:22 step:20911 [D loss: 0.620552, acc.: 65.62%] [G loss: 1.035905]\n",
      "epoch:22 step:20912 [D loss: 0.474079, acc.: 85.16%] [G loss: 0.568709]\n",
      "epoch:22 step:20913 [D loss: 0.471919, acc.: 82.03%] [G loss: 1.016910]\n",
      "epoch:22 step:20914 [D loss: 0.503268, acc.: 77.34%] [G loss: 1.205518]\n",
      "epoch:22 step:20915 [D loss: 0.754972, acc.: 50.00%] [G loss: 1.261716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20916 [D loss: 0.695013, acc.: 53.12%] [G loss: 1.276124]\n",
      "epoch:22 step:20917 [D loss: 0.581152, acc.: 67.97%] [G loss: 1.094721]\n",
      "epoch:22 step:20918 [D loss: 0.698341, acc.: 57.03%] [G loss: 1.179579]\n",
      "epoch:22 step:20919 [D loss: 0.578466, acc.: 72.66%] [G loss: 0.724557]\n",
      "epoch:22 step:20920 [D loss: 0.658043, acc.: 57.81%] [G loss: 1.267459]\n",
      "epoch:22 step:20921 [D loss: 0.587545, acc.: 71.88%] [G loss: 1.159435]\n",
      "epoch:22 step:20922 [D loss: 0.551575, acc.: 75.00%] [G loss: 1.046219]\n",
      "epoch:22 step:20923 [D loss: 0.548230, acc.: 72.66%] [G loss: 0.925933]\n",
      "epoch:22 step:20924 [D loss: 0.554432, acc.: 77.34%] [G loss: 0.933543]\n",
      "epoch:22 step:20925 [D loss: 0.650209, acc.: 69.53%] [G loss: 1.208960]\n",
      "epoch:22 step:20926 [D loss: 0.368200, acc.: 89.06%] [G loss: 1.158392]\n",
      "epoch:22 step:20927 [D loss: 0.846777, acc.: 40.62%] [G loss: 1.022503]\n",
      "epoch:22 step:20928 [D loss: 0.436194, acc.: 85.94%] [G loss: 1.075953]\n",
      "epoch:22 step:20929 [D loss: 0.648825, acc.: 61.72%] [G loss: 0.805290]\n",
      "epoch:22 step:20930 [D loss: 0.569159, acc.: 74.22%] [G loss: 0.564218]\n",
      "epoch:22 step:20931 [D loss: 0.610673, acc.: 73.44%] [G loss: 1.228721]\n",
      "epoch:22 step:20932 [D loss: 0.373571, acc.: 91.41%] [G loss: 1.379959]\n",
      "epoch:22 step:20933 [D loss: 0.391910, acc.: 88.28%] [G loss: 1.239502]\n",
      "epoch:22 step:20934 [D loss: 0.350772, acc.: 87.50%] [G loss: 1.557102]\n",
      "epoch:22 step:20935 [D loss: 0.246134, acc.: 90.62%] [G loss: 1.780550]\n",
      "epoch:22 step:20936 [D loss: 0.251605, acc.: 97.66%] [G loss: 1.462566]\n",
      "epoch:22 step:20937 [D loss: 0.890139, acc.: 51.56%] [G loss: 1.483023]\n",
      "epoch:22 step:20938 [D loss: 0.494329, acc.: 77.34%] [G loss: 0.943176]\n",
      "epoch:22 step:20939 [D loss: 0.619087, acc.: 67.19%] [G loss: 1.083818]\n",
      "epoch:22 step:20940 [D loss: 0.352746, acc.: 89.84%] [G loss: 1.535759]\n",
      "epoch:22 step:20941 [D loss: 0.214566, acc.: 94.53%] [G loss: 1.338958]\n",
      "epoch:22 step:20942 [D loss: 0.167716, acc.: 100.00%] [G loss: 1.337833]\n",
      "epoch:22 step:20943 [D loss: 0.625562, acc.: 65.62%] [G loss: 1.309273]\n",
      "epoch:22 step:20944 [D loss: 0.924936, acc.: 46.09%] [G loss: 1.451757]\n",
      "epoch:22 step:20945 [D loss: 0.641420, acc.: 59.38%] [G loss: 1.173550]\n",
      "epoch:22 step:20946 [D loss: 0.913925, acc.: 43.75%] [G loss: 0.336196]\n",
      "epoch:22 step:20947 [D loss: 0.964093, acc.: 32.81%] [G loss: 0.599251]\n",
      "epoch:22 step:20948 [D loss: 0.982554, acc.: 32.81%] [G loss: 0.744004]\n",
      "epoch:22 step:20949 [D loss: 0.817267, acc.: 44.53%] [G loss: 0.924980]\n",
      "epoch:22 step:20950 [D loss: 0.732216, acc.: 51.56%] [G loss: 1.050608]\n",
      "epoch:22 step:20951 [D loss: 0.792024, acc.: 50.00%] [G loss: 0.905190]\n",
      "epoch:22 step:20952 [D loss: 0.567692, acc.: 69.53%] [G loss: 0.898484]\n",
      "epoch:22 step:20953 [D loss: 0.867226, acc.: 49.22%] [G loss: 1.058914]\n",
      "epoch:22 step:20954 [D loss: 0.662743, acc.: 57.03%] [G loss: 0.924657]\n",
      "epoch:22 step:20955 [D loss: 0.660611, acc.: 59.38%] [G loss: 1.060438]\n",
      "epoch:22 step:20956 [D loss: 0.537695, acc.: 71.09%] [G loss: 1.186324]\n",
      "epoch:22 step:20957 [D loss: 0.380182, acc.: 82.03%] [G loss: 1.517639]\n",
      "epoch:22 step:20958 [D loss: 0.449558, acc.: 79.69%] [G loss: 1.300783]\n",
      "epoch:22 step:20959 [D loss: 0.350928, acc.: 90.62%] [G loss: 1.369126]\n",
      "epoch:22 step:20960 [D loss: 0.394026, acc.: 82.03%] [G loss: 1.643100]\n",
      "epoch:22 step:20961 [D loss: 0.196713, acc.: 98.44%] [G loss: 1.529000]\n",
      "epoch:22 step:20962 [D loss: 0.804838, acc.: 54.69%] [G loss: 1.208014]\n",
      "epoch:22 step:20963 [D loss: 0.736198, acc.: 60.94%] [G loss: 1.185958]\n",
      "epoch:22 step:20964 [D loss: 0.763941, acc.: 52.34%] [G loss: 1.111130]\n",
      "epoch:22 step:20965 [D loss: 0.621059, acc.: 67.19%] [G loss: 0.977163]\n",
      "epoch:22 step:20966 [D loss: 0.640344, acc.: 63.28%] [G loss: 0.985971]\n",
      "epoch:22 step:20967 [D loss: 0.599709, acc.: 64.06%] [G loss: 0.946489]\n",
      "epoch:22 step:20968 [D loss: 0.650045, acc.: 59.38%] [G loss: 0.987773]\n",
      "epoch:22 step:20969 [D loss: 0.764921, acc.: 52.34%] [G loss: 0.964354]\n",
      "epoch:22 step:20970 [D loss: 0.768046, acc.: 46.88%] [G loss: 0.933763]\n",
      "epoch:22 step:20971 [D loss: 0.737182, acc.: 48.44%] [G loss: 0.899598]\n",
      "epoch:22 step:20972 [D loss: 0.687722, acc.: 59.38%] [G loss: 0.877690]\n",
      "epoch:22 step:20973 [D loss: 0.614138, acc.: 65.62%] [G loss: 0.902872]\n",
      "epoch:22 step:20974 [D loss: 0.598242, acc.: 69.53%] [G loss: 0.851446]\n",
      "epoch:22 step:20975 [D loss: 0.692188, acc.: 61.72%] [G loss: 0.938943]\n",
      "epoch:22 step:20976 [D loss: 0.650420, acc.: 61.72%] [G loss: 0.887967]\n",
      "epoch:22 step:20977 [D loss: 0.519651, acc.: 72.66%] [G loss: 0.881313]\n",
      "epoch:22 step:20978 [D loss: 0.541808, acc.: 73.44%] [G loss: 0.996583]\n",
      "epoch:22 step:20979 [D loss: 0.485910, acc.: 78.91%] [G loss: 0.995082]\n",
      "epoch:22 step:20980 [D loss: 0.256423, acc.: 89.84%] [G loss: 1.226646]\n",
      "epoch:22 step:20981 [D loss: 0.320710, acc.: 83.59%] [G loss: 1.457870]\n",
      "epoch:22 step:20982 [D loss: 0.690746, acc.: 60.16%] [G loss: 1.236533]\n",
      "epoch:22 step:20983 [D loss: 0.686099, acc.: 55.47%] [G loss: 1.137097]\n",
      "epoch:22 step:20984 [D loss: 0.707024, acc.: 58.59%] [G loss: 0.955818]\n",
      "epoch:22 step:20985 [D loss: 0.604886, acc.: 64.06%] [G loss: 1.007320]\n",
      "epoch:22 step:20986 [D loss: 0.648122, acc.: 60.94%] [G loss: 0.977310]\n",
      "epoch:22 step:20987 [D loss: 0.697587, acc.: 59.38%] [G loss: 0.830246]\n",
      "epoch:22 step:20988 [D loss: 0.655172, acc.: 60.94%] [G loss: 0.940950]\n",
      "epoch:22 step:20989 [D loss: 0.668035, acc.: 57.81%] [G loss: 0.907722]\n",
      "epoch:22 step:20990 [D loss: 0.537186, acc.: 78.12%] [G loss: 0.987443]\n",
      "epoch:22 step:20991 [D loss: 0.295971, acc.: 89.06%] [G loss: 1.018303]\n",
      "epoch:22 step:20992 [D loss: 0.323578, acc.: 85.16%] [G loss: 1.007417]\n",
      "epoch:22 step:20993 [D loss: 0.747128, acc.: 54.69%] [G loss: 0.828246]\n",
      "epoch:22 step:20994 [D loss: 0.703535, acc.: 59.38%] [G loss: 0.908578]\n",
      "epoch:22 step:20995 [D loss: 0.701256, acc.: 57.03%] [G loss: 0.978074]\n",
      "epoch:22 step:20996 [D loss: 0.683290, acc.: 58.59%] [G loss: 0.996859]\n",
      "epoch:22 step:20997 [D loss: 0.694010, acc.: 58.59%] [G loss: 0.921173]\n",
      "epoch:22 step:20998 [D loss: 0.637259, acc.: 62.50%] [G loss: 0.952462]\n",
      "epoch:22 step:20999 [D loss: 0.593538, acc.: 71.88%] [G loss: 0.906853]\n",
      "epoch:22 step:21000 [D loss: 0.794938, acc.: 50.00%] [G loss: 0.978928]\n",
      "epoch:22 step:21001 [D loss: 0.615922, acc.: 68.75%] [G loss: 0.950582]\n",
      "epoch:22 step:21002 [D loss: 0.682204, acc.: 60.16%] [G loss: 0.936516]\n",
      "epoch:22 step:21003 [D loss: 0.590429, acc.: 69.53%] [G loss: 0.997718]\n",
      "epoch:22 step:21004 [D loss: 0.599727, acc.: 67.97%] [G loss: 1.093966]\n",
      "epoch:22 step:21005 [D loss: 0.532676, acc.: 77.34%] [G loss: 0.907145]\n",
      "epoch:22 step:21006 [D loss: 0.508396, acc.: 81.25%] [G loss: 0.733926]\n",
      "epoch:22 step:21007 [D loss: 0.450232, acc.: 76.56%] [G loss: 0.982585]\n",
      "epoch:22 step:21008 [D loss: 0.489778, acc.: 82.81%] [G loss: 1.112267]\n",
      "epoch:22 step:21009 [D loss: 0.828358, acc.: 39.84%] [G loss: 0.985091]\n",
      "epoch:22 step:21010 [D loss: 0.258747, acc.: 92.19%] [G loss: 0.942036]\n",
      "epoch:22 step:21011 [D loss: 0.257287, acc.: 89.06%] [G loss: 1.170114]\n",
      "epoch:22 step:21012 [D loss: 0.209412, acc.: 94.53%] [G loss: 1.494159]\n",
      "epoch:22 step:21013 [D loss: 0.350676, acc.: 75.00%] [G loss: 1.707948]\n",
      "epoch:22 step:21014 [D loss: 0.297504, acc.: 87.50%] [G loss: 1.603101]\n",
      "epoch:22 step:21015 [D loss: 0.344421, acc.: 92.19%] [G loss: 0.765517]\n",
      "epoch:22 step:21016 [D loss: 0.283911, acc.: 95.31%] [G loss: 1.275744]\n",
      "epoch:22 step:21017 [D loss: 0.813724, acc.: 56.25%] [G loss: 1.667655]\n",
      "epoch:22 step:21018 [D loss: 0.273696, acc.: 92.97%] [G loss: 1.922102]\n",
      "epoch:22 step:21019 [D loss: 0.361071, acc.: 84.38%] [G loss: 0.629535]\n",
      "epoch:22 step:21020 [D loss: 0.524045, acc.: 71.88%] [G loss: 1.091346]\n",
      "epoch:22 step:21021 [D loss: 0.355400, acc.: 88.28%] [G loss: 0.943633]\n",
      "epoch:22 step:21022 [D loss: 1.373542, acc.: 21.88%] [G loss: 1.641973]\n",
      "epoch:22 step:21023 [D loss: 0.406587, acc.: 81.25%] [G loss: 1.606987]\n",
      "epoch:22 step:21024 [D loss: 1.290142, acc.: 22.66%] [G loss: 2.032836]\n",
      "epoch:22 step:21025 [D loss: 1.393231, acc.: 18.75%] [G loss: 1.472968]\n",
      "epoch:22 step:21026 [D loss: 1.037438, acc.: 47.66%] [G loss: 1.460666]\n",
      "epoch:22 step:21027 [D loss: 0.831082, acc.: 51.56%] [G loss: 1.429697]\n",
      "epoch:22 step:21028 [D loss: 0.832846, acc.: 46.09%] [G loss: 1.080331]\n",
      "epoch:22 step:21029 [D loss: 0.782905, acc.: 47.66%] [G loss: 1.154618]\n",
      "epoch:22 step:21030 [D loss: 0.806955, acc.: 47.66%] [G loss: 1.169350]\n",
      "epoch:22 step:21031 [D loss: 0.799993, acc.: 44.53%] [G loss: 1.230178]\n",
      "epoch:22 step:21032 [D loss: 0.790325, acc.: 50.78%] [G loss: 1.178764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21033 [D loss: 0.678610, acc.: 53.12%] [G loss: 1.043498]\n",
      "epoch:22 step:21034 [D loss: 0.706759, acc.: 53.91%] [G loss: 0.924245]\n",
      "epoch:22 step:21035 [D loss: 0.736878, acc.: 49.22%] [G loss: 0.986616]\n",
      "epoch:22 step:21036 [D loss: 0.741131, acc.: 44.53%] [G loss: 1.027768]\n",
      "epoch:22 step:21037 [D loss: 0.726721, acc.: 60.16%] [G loss: 0.951112]\n",
      "epoch:22 step:21038 [D loss: 0.720808, acc.: 53.12%] [G loss: 0.922114]\n",
      "epoch:22 step:21039 [D loss: 0.733681, acc.: 45.31%] [G loss: 0.929900]\n",
      "epoch:22 step:21040 [D loss: 0.720613, acc.: 53.91%] [G loss: 0.986472]\n",
      "epoch:22 step:21041 [D loss: 0.666126, acc.: 57.81%] [G loss: 1.046772]\n",
      "epoch:22 step:21042 [D loss: 0.664122, acc.: 57.81%] [G loss: 0.969134]\n",
      "epoch:22 step:21043 [D loss: 0.628156, acc.: 60.94%] [G loss: 0.996924]\n",
      "epoch:22 step:21044 [D loss: 0.645072, acc.: 62.50%] [G loss: 0.853835]\n",
      "epoch:22 step:21045 [D loss: 0.671009, acc.: 62.50%] [G loss: 1.062852]\n",
      "epoch:22 step:21046 [D loss: 0.602288, acc.: 65.62%] [G loss: 1.059766]\n",
      "epoch:22 step:21047 [D loss: 0.549516, acc.: 75.00%] [G loss: 1.108002]\n",
      "epoch:22 step:21048 [D loss: 0.576466, acc.: 68.75%] [G loss: 1.047376]\n",
      "epoch:22 step:21049 [D loss: 0.599834, acc.: 63.28%] [G loss: 1.195961]\n",
      "epoch:22 step:21050 [D loss: 0.568875, acc.: 73.44%] [G loss: 1.313930]\n",
      "epoch:22 step:21051 [D loss: 0.625003, acc.: 60.16%] [G loss: 1.012929]\n",
      "epoch:22 step:21052 [D loss: 0.669656, acc.: 60.94%] [G loss: 1.072988]\n",
      "epoch:22 step:21053 [D loss: 0.655165, acc.: 60.16%] [G loss: 1.073948]\n",
      "epoch:22 step:21054 [D loss: 0.633866, acc.: 60.16%] [G loss: 0.884484]\n",
      "epoch:22 step:21055 [D loss: 0.647225, acc.: 62.50%] [G loss: 0.874727]\n",
      "epoch:22 step:21056 [D loss: 0.687805, acc.: 49.22%] [G loss: 0.910551]\n",
      "epoch:22 step:21057 [D loss: 0.529807, acc.: 82.03%] [G loss: 1.095883]\n",
      "epoch:22 step:21058 [D loss: 0.630910, acc.: 62.50%] [G loss: 1.053720]\n",
      "epoch:22 step:21059 [D loss: 0.632674, acc.: 61.72%] [G loss: 0.948739]\n",
      "epoch:22 step:21060 [D loss: 0.724654, acc.: 59.38%] [G loss: 0.817801]\n",
      "epoch:22 step:21061 [D loss: 0.725134, acc.: 54.69%] [G loss: 0.974928]\n",
      "epoch:22 step:21062 [D loss: 0.506210, acc.: 82.81%] [G loss: 0.886177]\n",
      "epoch:22 step:21063 [D loss: 0.496438, acc.: 82.03%] [G loss: 1.177180]\n",
      "epoch:22 step:21064 [D loss: 0.521618, acc.: 80.47%] [G loss: 1.322878]\n",
      "epoch:22 step:21065 [D loss: 0.422703, acc.: 93.75%] [G loss: 1.170938]\n",
      "epoch:22 step:21066 [D loss: 0.458431, acc.: 93.75%] [G loss: 1.032347]\n",
      "epoch:22 step:21067 [D loss: 0.368231, acc.: 96.88%] [G loss: 1.277896]\n",
      "epoch:22 step:21068 [D loss: 0.501136, acc.: 77.34%] [G loss: 1.318755]\n",
      "epoch:22 step:21069 [D loss: 0.430948, acc.: 79.69%] [G loss: 1.177828]\n",
      "epoch:22 step:21070 [D loss: 0.413216, acc.: 88.28%] [G loss: 1.162819]\n",
      "epoch:22 step:21071 [D loss: 0.430598, acc.: 87.50%] [G loss: 1.581691]\n",
      "epoch:22 step:21072 [D loss: 0.668849, acc.: 60.94%] [G loss: 1.415351]\n",
      "epoch:22 step:21073 [D loss: 0.678510, acc.: 58.59%] [G loss: 1.047311]\n",
      "epoch:22 step:21074 [D loss: 0.677361, acc.: 54.69%] [G loss: 0.998180]\n",
      "epoch:22 step:21075 [D loss: 0.858192, acc.: 43.75%] [G loss: 1.120163]\n",
      "epoch:22 step:21076 [D loss: 1.051091, acc.: 29.69%] [G loss: 0.810088]\n",
      "epoch:22 step:21077 [D loss: 0.739375, acc.: 46.88%] [G loss: 0.681736]\n",
      "epoch:22 step:21078 [D loss: 0.597219, acc.: 66.41%] [G loss: 0.812656]\n",
      "epoch:22 step:21079 [D loss: 0.583884, acc.: 72.66%] [G loss: 0.819484]\n",
      "epoch:22 step:21080 [D loss: 0.522659, acc.: 78.91%] [G loss: 0.926217]\n",
      "epoch:22 step:21081 [D loss: 0.542796, acc.: 75.78%] [G loss: 0.871681]\n",
      "epoch:22 step:21082 [D loss: 0.392199, acc.: 83.59%] [G loss: 0.905833]\n",
      "epoch:22 step:21083 [D loss: 0.461595, acc.: 79.69%] [G loss: 0.904084]\n",
      "epoch:22 step:21084 [D loss: 0.341778, acc.: 89.06%] [G loss: 1.152380]\n",
      "epoch:22 step:21085 [D loss: 0.372430, acc.: 93.75%] [G loss: 1.233678]\n",
      "epoch:22 step:21086 [D loss: 0.485470, acc.: 88.28%] [G loss: 1.163406]\n",
      "epoch:22 step:21087 [D loss: 0.918993, acc.: 33.59%] [G loss: 1.079707]\n",
      "epoch:22 step:21088 [D loss: 0.940885, acc.: 30.47%] [G loss: 0.993487]\n",
      "epoch:22 step:21089 [D loss: 0.745265, acc.: 50.78%] [G loss: 0.872729]\n",
      "epoch:22 step:21090 [D loss: 0.711409, acc.: 57.03%] [G loss: 0.800169]\n",
      "epoch:22 step:21091 [D loss: 0.535198, acc.: 70.31%] [G loss: 0.909925]\n",
      "epoch:22 step:21092 [D loss: 0.690950, acc.: 56.25%] [G loss: 0.703965]\n",
      "epoch:22 step:21093 [D loss: 0.469351, acc.: 79.69%] [G loss: 0.832455]\n",
      "epoch:22 step:21094 [D loss: 0.399352, acc.: 87.50%] [G loss: 1.064154]\n",
      "epoch:22 step:21095 [D loss: 0.396444, acc.: 85.16%] [G loss: 1.038556]\n",
      "epoch:22 step:21096 [D loss: 0.800318, acc.: 49.22%] [G loss: 0.941158]\n",
      "epoch:22 step:21097 [D loss: 0.749238, acc.: 52.34%] [G loss: 1.006581]\n",
      "epoch:22 step:21098 [D loss: 0.795654, acc.: 36.72%] [G loss: 0.965545]\n",
      "epoch:22 step:21099 [D loss: 0.721476, acc.: 48.44%] [G loss: 0.919420]\n",
      "epoch:22 step:21100 [D loss: 0.726715, acc.: 50.00%] [G loss: 0.882351]\n",
      "epoch:22 step:21101 [D loss: 0.675092, acc.: 56.25%] [G loss: 1.017962]\n",
      "epoch:22 step:21102 [D loss: 0.605973, acc.: 64.84%] [G loss: 0.834235]\n",
      "epoch:22 step:21103 [D loss: 0.574039, acc.: 81.25%] [G loss: 1.029852]\n",
      "epoch:22 step:21104 [D loss: 0.474722, acc.: 82.03%] [G loss: 1.009629]\n",
      "epoch:22 step:21105 [D loss: 0.557702, acc.: 74.22%] [G loss: 1.045186]\n",
      "epoch:22 step:21106 [D loss: 0.744428, acc.: 53.12%] [G loss: 0.915117]\n",
      "epoch:22 step:21107 [D loss: 0.684774, acc.: 54.69%] [G loss: 0.801305]\n",
      "epoch:22 step:21108 [D loss: 0.553785, acc.: 73.44%] [G loss: 0.908541]\n",
      "epoch:22 step:21109 [D loss: 0.595167, acc.: 71.88%] [G loss: 0.956950]\n",
      "epoch:22 step:21110 [D loss: 0.673194, acc.: 61.72%] [G loss: 1.134699]\n",
      "epoch:22 step:21111 [D loss: 0.612409, acc.: 68.75%] [G loss: 1.180859]\n",
      "epoch:22 step:21112 [D loss: 0.559594, acc.: 72.66%] [G loss: 1.211448]\n",
      "epoch:22 step:21113 [D loss: 0.465636, acc.: 84.38%] [G loss: 1.242751]\n",
      "epoch:22 step:21114 [D loss: 0.629036, acc.: 66.41%] [G loss: 1.190888]\n",
      "epoch:22 step:21115 [D loss: 0.745343, acc.: 51.56%] [G loss: 1.062561]\n",
      "epoch:22 step:21116 [D loss: 0.632014, acc.: 65.62%] [G loss: 1.044898]\n",
      "epoch:22 step:21117 [D loss: 0.486374, acc.: 81.25%] [G loss: 1.138246]\n",
      "epoch:22 step:21118 [D loss: 0.485928, acc.: 75.78%] [G loss: 1.125295]\n",
      "epoch:22 step:21119 [D loss: 0.438059, acc.: 85.94%] [G loss: 1.064650]\n",
      "epoch:22 step:21120 [D loss: 0.636349, acc.: 65.62%] [G loss: 1.041759]\n",
      "epoch:22 step:21121 [D loss: 0.535410, acc.: 75.00%] [G loss: 1.134674]\n",
      "epoch:22 step:21122 [D loss: 0.530742, acc.: 74.22%] [G loss: 1.194871]\n",
      "epoch:22 step:21123 [D loss: 0.666072, acc.: 55.47%] [G loss: 1.026783]\n",
      "epoch:22 step:21124 [D loss: 0.689395, acc.: 58.59%] [G loss: 0.975414]\n",
      "epoch:22 step:21125 [D loss: 0.610629, acc.: 67.97%] [G loss: 1.023352]\n",
      "epoch:22 step:21126 [D loss: 0.594766, acc.: 70.31%] [G loss: 1.046095]\n",
      "epoch:22 step:21127 [D loss: 0.492720, acc.: 74.22%] [G loss: 1.173138]\n",
      "epoch:22 step:21128 [D loss: 0.417128, acc.: 82.81%] [G loss: 1.202837]\n",
      "epoch:22 step:21129 [D loss: 0.431804, acc.: 83.59%] [G loss: 1.301468]\n",
      "epoch:22 step:21130 [D loss: 0.775322, acc.: 54.69%] [G loss: 1.005474]\n",
      "epoch:22 step:21131 [D loss: 0.508115, acc.: 78.12%] [G loss: 0.940568]\n",
      "epoch:22 step:21132 [D loss: 0.708379, acc.: 56.25%] [G loss: 1.123022]\n",
      "epoch:22 step:21133 [D loss: 0.567761, acc.: 70.31%] [G loss: 1.187856]\n",
      "epoch:22 step:21134 [D loss: 0.516377, acc.: 75.78%] [G loss: 1.328885]\n",
      "epoch:22 step:21135 [D loss: 0.769913, acc.: 45.31%] [G loss: 1.155047]\n",
      "epoch:22 step:21136 [D loss: 0.612857, acc.: 66.41%] [G loss: 1.210652]\n",
      "epoch:22 step:21137 [D loss: 0.619289, acc.: 64.84%] [G loss: 1.065185]\n",
      "epoch:22 step:21138 [D loss: 0.467227, acc.: 79.69%] [G loss: 1.034978]\n",
      "epoch:22 step:21139 [D loss: 0.586622, acc.: 68.75%] [G loss: 1.082545]\n",
      "epoch:22 step:21140 [D loss: 0.509962, acc.: 79.69%] [G loss: 1.130816]\n",
      "epoch:22 step:21141 [D loss: 0.548711, acc.: 74.22%] [G loss: 0.913997]\n",
      "epoch:22 step:21142 [D loss: 0.750497, acc.: 52.34%] [G loss: 1.146324]\n",
      "epoch:22 step:21143 [D loss: 0.769593, acc.: 47.66%] [G loss: 1.015646]\n",
      "epoch:22 step:21144 [D loss: 0.399997, acc.: 88.28%] [G loss: 1.173648]\n",
      "epoch:22 step:21145 [D loss: 0.716591, acc.: 53.12%] [G loss: 0.919274]\n",
      "epoch:22 step:21146 [D loss: 0.674264, acc.: 67.19%] [G loss: 1.036807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21147 [D loss: 0.648427, acc.: 65.62%] [G loss: 0.985764]\n",
      "epoch:22 step:21148 [D loss: 0.631236, acc.: 59.38%] [G loss: 0.980449]\n",
      "epoch:22 step:21149 [D loss: 0.482052, acc.: 79.69%] [G loss: 1.047805]\n",
      "epoch:22 step:21150 [D loss: 0.349669, acc.: 87.50%] [G loss: 1.090564]\n",
      "epoch:22 step:21151 [D loss: 0.464174, acc.: 80.47%] [G loss: 1.251862]\n",
      "epoch:22 step:21152 [D loss: 0.435889, acc.: 88.28%] [G loss: 1.371987]\n",
      "epoch:22 step:21153 [D loss: 0.511259, acc.: 71.88%] [G loss: 1.278446]\n",
      "epoch:22 step:21154 [D loss: 0.517488, acc.: 76.56%] [G loss: 1.363491]\n",
      "epoch:22 step:21155 [D loss: 0.771632, acc.: 39.84%] [G loss: 0.953790]\n",
      "epoch:22 step:21156 [D loss: 0.635497, acc.: 65.62%] [G loss: 1.280660]\n",
      "epoch:22 step:21157 [D loss: 0.339507, acc.: 87.50%] [G loss: 1.374542]\n",
      "epoch:22 step:21158 [D loss: 0.811474, acc.: 49.22%] [G loss: 1.181888]\n",
      "epoch:22 step:21159 [D loss: 0.623680, acc.: 67.19%] [G loss: 1.220118]\n",
      "epoch:22 step:21160 [D loss: 0.847155, acc.: 39.84%] [G loss: 1.059054]\n",
      "epoch:22 step:21161 [D loss: 0.749382, acc.: 50.00%] [G loss: 1.150036]\n",
      "epoch:22 step:21162 [D loss: 0.600237, acc.: 64.06%] [G loss: 0.974638]\n",
      "epoch:22 step:21163 [D loss: 0.639008, acc.: 67.19%] [G loss: 1.076473]\n",
      "epoch:22 step:21164 [D loss: 0.393712, acc.: 83.59%] [G loss: 1.037785]\n",
      "epoch:22 step:21165 [D loss: 0.573370, acc.: 71.09%] [G loss: 1.167448]\n",
      "epoch:22 step:21166 [D loss: 0.675574, acc.: 53.91%] [G loss: 0.909420]\n",
      "epoch:22 step:21167 [D loss: 0.770806, acc.: 53.12%] [G loss: 1.319832]\n",
      "epoch:22 step:21168 [D loss: 0.459025, acc.: 75.78%] [G loss: 1.002565]\n",
      "epoch:22 step:21169 [D loss: 0.632483, acc.: 66.41%] [G loss: 0.967645]\n",
      "epoch:22 step:21170 [D loss: 0.540800, acc.: 71.09%] [G loss: 1.047611]\n",
      "epoch:22 step:21171 [D loss: 0.654362, acc.: 64.06%] [G loss: 0.839493]\n",
      "epoch:22 step:21172 [D loss: 0.688040, acc.: 57.81%] [G loss: 1.382751]\n",
      "epoch:22 step:21173 [D loss: 0.347275, acc.: 86.72%] [G loss: 1.480702]\n",
      "epoch:22 step:21174 [D loss: 0.422720, acc.: 85.94%] [G loss: 1.339346]\n",
      "epoch:22 step:21175 [D loss: 0.323739, acc.: 89.06%] [G loss: 1.571072]\n",
      "epoch:22 step:21176 [D loss: 0.901758, acc.: 50.00%] [G loss: 1.373226]\n",
      "epoch:22 step:21177 [D loss: 0.708210, acc.: 53.12%] [G loss: 1.122372]\n",
      "epoch:22 step:21178 [D loss: 0.686128, acc.: 53.91%] [G loss: 1.152169]\n",
      "epoch:22 step:21179 [D loss: 0.669503, acc.: 59.38%] [G loss: 1.165516]\n",
      "epoch:22 step:21180 [D loss: 0.368191, acc.: 86.72%] [G loss: 1.089932]\n",
      "epoch:22 step:21181 [D loss: 0.288343, acc.: 89.84%] [G loss: 1.259980]\n",
      "epoch:22 step:21182 [D loss: 0.551434, acc.: 72.66%] [G loss: 1.227129]\n",
      "epoch:22 step:21183 [D loss: 0.621084, acc.: 60.16%] [G loss: 1.174144]\n",
      "epoch:22 step:21184 [D loss: 0.591145, acc.: 69.53%] [G loss: 0.998604]\n",
      "epoch:22 step:21185 [D loss: 0.610047, acc.: 67.97%] [G loss: 1.050790]\n",
      "epoch:22 step:21186 [D loss: 0.580561, acc.: 67.19%] [G loss: 1.097867]\n",
      "epoch:22 step:21187 [D loss: 0.545579, acc.: 76.56%] [G loss: 1.177118]\n",
      "epoch:22 step:21188 [D loss: 0.602842, acc.: 64.84%] [G loss: 0.977580]\n",
      "epoch:22 step:21189 [D loss: 0.487027, acc.: 81.25%] [G loss: 1.041390]\n",
      "epoch:22 step:21190 [D loss: 0.457311, acc.: 79.69%] [G loss: 1.088482]\n",
      "epoch:22 step:21191 [D loss: 0.514332, acc.: 67.19%] [G loss: 1.082545]\n",
      "epoch:22 step:21192 [D loss: 0.438639, acc.: 73.44%] [G loss: 1.146672]\n",
      "epoch:22 step:21193 [D loss: 0.308138, acc.: 96.09%] [G loss: 1.320955]\n",
      "epoch:22 step:21194 [D loss: 0.746712, acc.: 55.47%] [G loss: 1.285041]\n",
      "epoch:22 step:21195 [D loss: 0.694881, acc.: 59.38%] [G loss: 1.209720]\n",
      "epoch:22 step:21196 [D loss: 0.691553, acc.: 58.59%] [G loss: 1.142008]\n",
      "epoch:22 step:21197 [D loss: 0.648840, acc.: 62.50%] [G loss: 1.016674]\n",
      "epoch:22 step:21198 [D loss: 0.806078, acc.: 44.53%] [G loss: 1.003729]\n",
      "epoch:22 step:21199 [D loss: 0.582141, acc.: 71.88%] [G loss: 0.980567]\n",
      "epoch:22 step:21200 [D loss: 0.700678, acc.: 60.16%] [G loss: 0.840966]\n",
      "epoch:22 step:21201 [D loss: 0.292921, acc.: 90.62%] [G loss: 1.160015]\n",
      "epoch:22 step:21202 [D loss: 0.326611, acc.: 85.16%] [G loss: 1.490427]\n",
      "epoch:22 step:21203 [D loss: 0.221700, acc.: 94.53%] [G loss: 1.336277]\n",
      "epoch:22 step:21204 [D loss: 0.673774, acc.: 60.94%] [G loss: 1.217643]\n",
      "epoch:22 step:21205 [D loss: 0.635121, acc.: 65.62%] [G loss: 1.221258]\n",
      "epoch:22 step:21206 [D loss: 0.655140, acc.: 58.59%] [G loss: 1.110862]\n",
      "epoch:22 step:21207 [D loss: 0.679033, acc.: 62.50%] [G loss: 1.348504]\n",
      "epoch:22 step:21208 [D loss: 0.520503, acc.: 80.47%] [G loss: 1.072152]\n",
      "epoch:22 step:21209 [D loss: 0.375879, acc.: 87.50%] [G loss: 1.055095]\n",
      "epoch:22 step:21210 [D loss: 0.591086, acc.: 71.88%] [G loss: 0.839093]\n",
      "epoch:22 step:21211 [D loss: 0.786067, acc.: 57.03%] [G loss: 1.099340]\n",
      "epoch:22 step:21212 [D loss: 0.672277, acc.: 58.59%] [G loss: 0.910856]\n",
      "epoch:22 step:21213 [D loss: 0.756058, acc.: 44.53%] [G loss: 0.963966]\n",
      "epoch:22 step:21214 [D loss: 0.423881, acc.: 71.09%] [G loss: 1.211309]\n",
      "epoch:22 step:21215 [D loss: 0.235612, acc.: 96.88%] [G loss: 1.294253]\n",
      "epoch:22 step:21216 [D loss: 0.539117, acc.: 77.34%] [G loss: 1.083780]\n",
      "epoch:22 step:21217 [D loss: 0.690401, acc.: 57.81%] [G loss: 0.866238]\n",
      "epoch:22 step:21218 [D loss: 0.442738, acc.: 75.78%] [G loss: 1.241928]\n",
      "epoch:22 step:21219 [D loss: 0.651756, acc.: 59.38%] [G loss: 1.223358]\n",
      "epoch:22 step:21220 [D loss: 0.505943, acc.: 72.66%] [G loss: 1.181773]\n",
      "epoch:22 step:21221 [D loss: 0.627983, acc.: 64.06%] [G loss: 1.287801]\n",
      "epoch:22 step:21222 [D loss: 0.749248, acc.: 44.53%] [G loss: 0.944208]\n",
      "epoch:22 step:21223 [D loss: 0.265977, acc.: 90.62%] [G loss: 1.134085]\n",
      "epoch:22 step:21224 [D loss: 0.744988, acc.: 48.44%] [G loss: 1.015093]\n",
      "epoch:22 step:21225 [D loss: 0.371362, acc.: 81.25%] [G loss: 1.161033]\n",
      "epoch:22 step:21226 [D loss: 0.521170, acc.: 73.44%] [G loss: 1.360511]\n",
      "epoch:22 step:21227 [D loss: 0.711310, acc.: 53.12%] [G loss: 1.589334]\n",
      "epoch:22 step:21228 [D loss: 0.807436, acc.: 48.44%] [G loss: 1.149982]\n",
      "epoch:22 step:21229 [D loss: 0.719682, acc.: 53.91%] [G loss: 1.129190]\n",
      "epoch:22 step:21230 [D loss: 0.659645, acc.: 60.16%] [G loss: 1.058231]\n",
      "epoch:22 step:21231 [D loss: 0.599886, acc.: 64.06%] [G loss: 1.049076]\n",
      "epoch:22 step:21232 [D loss: 0.645702, acc.: 64.84%] [G loss: 0.956693]\n",
      "epoch:22 step:21233 [D loss: 0.632574, acc.: 64.06%] [G loss: 0.685887]\n",
      "epoch:22 step:21234 [D loss: 0.610079, acc.: 66.41%] [G loss: 0.786345]\n",
      "epoch:22 step:21235 [D loss: 0.629609, acc.: 67.97%] [G loss: 0.904624]\n",
      "epoch:22 step:21236 [D loss: 0.591679, acc.: 70.31%] [G loss: 0.943167]\n",
      "epoch:22 step:21237 [D loss: 0.596103, acc.: 64.06%] [G loss: 0.990206]\n",
      "epoch:22 step:21238 [D loss: 0.504822, acc.: 80.47%] [G loss: 0.993408]\n",
      "epoch:22 step:21239 [D loss: 0.618324, acc.: 65.62%] [G loss: 0.880679]\n",
      "epoch:22 step:21240 [D loss: 0.674917, acc.: 60.94%] [G loss: 0.626680]\n",
      "epoch:22 step:21241 [D loss: 0.630650, acc.: 61.72%] [G loss: 1.130662]\n",
      "epoch:22 step:21242 [D loss: 0.702865, acc.: 57.03%] [G loss: 0.926262]\n",
      "epoch:22 step:21243 [D loss: 0.513305, acc.: 76.56%] [G loss: 1.068129]\n",
      "epoch:22 step:21244 [D loss: 0.547799, acc.: 75.00%] [G loss: 1.085087]\n",
      "epoch:22 step:21245 [D loss: 0.610833, acc.: 67.19%] [G loss: 0.883813]\n",
      "epoch:22 step:21246 [D loss: 0.367378, acc.: 88.28%] [G loss: 0.985016]\n",
      "epoch:22 step:21247 [D loss: 0.399580, acc.: 78.91%] [G loss: 1.221812]\n",
      "epoch:22 step:21248 [D loss: 0.378356, acc.: 83.59%] [G loss: 1.389342]\n",
      "epoch:22 step:21249 [D loss: 0.311226, acc.: 94.53%] [G loss: 1.286180]\n",
      "epoch:22 step:21250 [D loss: 0.592417, acc.: 69.53%] [G loss: 1.110177]\n",
      "epoch:22 step:21251 [D loss: 0.619512, acc.: 63.28%] [G loss: 1.161333]\n",
      "epoch:22 step:21252 [D loss: 0.554766, acc.: 66.41%] [G loss: 1.341928]\n",
      "epoch:22 step:21253 [D loss: 0.747896, acc.: 47.66%] [G loss: 1.176860]\n",
      "epoch:22 step:21254 [D loss: 0.605699, acc.: 63.28%] [G loss: 1.144423]\n",
      "epoch:22 step:21255 [D loss: 0.358898, acc.: 85.94%] [G loss: 1.095508]\n",
      "epoch:22 step:21256 [D loss: 0.824494, acc.: 44.53%] [G loss: 1.174668]\n",
      "epoch:22 step:21257 [D loss: 0.716946, acc.: 55.47%] [G loss: 1.039645]\n",
      "epoch:22 step:21258 [D loss: 0.391230, acc.: 78.91%] [G loss: 1.406681]\n",
      "epoch:22 step:21259 [D loss: 0.429146, acc.: 84.38%] [G loss: 1.394435]\n",
      "epoch:22 step:21260 [D loss: 0.478530, acc.: 71.09%] [G loss: 1.281588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21261 [D loss: 0.340115, acc.: 95.31%] [G loss: 1.298578]\n",
      "epoch:22 step:21262 [D loss: 0.297628, acc.: 96.09%] [G loss: 1.289362]\n",
      "epoch:22 step:21263 [D loss: 0.660243, acc.: 60.16%] [G loss: 1.286689]\n",
      "epoch:22 step:21264 [D loss: 0.393942, acc.: 80.47%] [G loss: 1.368137]\n",
      "epoch:22 step:21265 [D loss: 0.462761, acc.: 82.03%] [G loss: 1.499284]\n",
      "epoch:22 step:21266 [D loss: 1.153481, acc.: 25.78%] [G loss: 1.356167]\n",
      "epoch:22 step:21267 [D loss: 0.831720, acc.: 46.09%] [G loss: 1.291783]\n",
      "epoch:22 step:21268 [D loss: 0.855543, acc.: 40.62%] [G loss: 1.241380]\n",
      "epoch:22 step:21269 [D loss: 0.797161, acc.: 48.44%] [G loss: 1.045983]\n",
      "epoch:22 step:21270 [D loss: 0.852076, acc.: 42.97%] [G loss: 0.773411]\n",
      "epoch:22 step:21271 [D loss: 0.923455, acc.: 30.47%] [G loss: 0.998921]\n",
      "epoch:22 step:21272 [D loss: 0.752764, acc.: 51.56%] [G loss: 1.055323]\n",
      "epoch:22 step:21273 [D loss: 0.636258, acc.: 67.19%] [G loss: 0.891019]\n",
      "epoch:22 step:21274 [D loss: 0.609824, acc.: 67.19%] [G loss: 1.088939]\n",
      "epoch:22 step:21275 [D loss: 0.661066, acc.: 57.81%] [G loss: 0.971905]\n",
      "epoch:22 step:21276 [D loss: 0.633478, acc.: 57.81%] [G loss: 1.039345]\n",
      "epoch:22 step:21277 [D loss: 0.285857, acc.: 89.06%] [G loss: 1.247363]\n",
      "epoch:22 step:21278 [D loss: 0.402227, acc.: 87.50%] [G loss: 1.230702]\n",
      "epoch:22 step:21279 [D loss: 0.265153, acc.: 86.72%] [G loss: 1.307179]\n",
      "epoch:22 step:21280 [D loss: 0.480300, acc.: 82.81%] [G loss: 1.522152]\n",
      "epoch:22 step:21281 [D loss: 0.524797, acc.: 76.56%] [G loss: 1.340097]\n",
      "epoch:22 step:21282 [D loss: 0.661367, acc.: 62.50%] [G loss: 1.220337]\n",
      "epoch:22 step:21283 [D loss: 0.511218, acc.: 78.12%] [G loss: 1.102137]\n",
      "epoch:22 step:21284 [D loss: 0.611316, acc.: 66.41%] [G loss: 1.287074]\n",
      "epoch:22 step:21285 [D loss: 0.376618, acc.: 85.16%] [G loss: 1.371101]\n",
      "epoch:22 step:21286 [D loss: 0.491995, acc.: 81.25%] [G loss: 1.154675]\n",
      "epoch:22 step:21287 [D loss: 0.641663, acc.: 64.84%] [G loss: 1.116536]\n",
      "epoch:22 step:21288 [D loss: 0.444749, acc.: 80.47%] [G loss: 1.143999]\n",
      "epoch:22 step:21289 [D loss: 0.714240, acc.: 54.69%] [G loss: 0.922580]\n",
      "epoch:22 step:21290 [D loss: 0.692579, acc.: 55.47%] [G loss: 1.445498]\n",
      "epoch:22 step:21291 [D loss: 0.752466, acc.: 52.34%] [G loss: 0.942925]\n",
      "epoch:22 step:21292 [D loss: 0.687867, acc.: 57.81%] [G loss: 0.852848]\n",
      "epoch:22 step:21293 [D loss: 0.676684, acc.: 57.81%] [G loss: 0.829722]\n",
      "epoch:22 step:21294 [D loss: 0.645708, acc.: 59.38%] [G loss: 0.826243]\n",
      "epoch:22 step:21295 [D loss: 0.750672, acc.: 43.75%] [G loss: 0.948164]\n",
      "epoch:22 step:21296 [D loss: 0.499989, acc.: 78.91%] [G loss: 1.113079]\n",
      "epoch:22 step:21297 [D loss: 0.616708, acc.: 65.62%] [G loss: 0.824275]\n",
      "epoch:22 step:21298 [D loss: 0.431258, acc.: 75.00%] [G loss: 0.910558]\n",
      "epoch:22 step:21299 [D loss: 0.461570, acc.: 83.59%] [G loss: 0.943439]\n",
      "epoch:22 step:21300 [D loss: 0.592589, acc.: 71.88%] [G loss: 1.074443]\n",
      "epoch:22 step:21301 [D loss: 0.605048, acc.: 68.75%] [G loss: 0.830742]\n",
      "epoch:22 step:21302 [D loss: 0.741264, acc.: 49.22%] [G loss: 0.953744]\n",
      "epoch:22 step:21303 [D loss: 0.718235, acc.: 59.38%] [G loss: 0.906368]\n",
      "epoch:22 step:21304 [D loss: 0.732037, acc.: 59.38%] [G loss: 0.905981]\n",
      "epoch:22 step:21305 [D loss: 0.774340, acc.: 46.88%] [G loss: 1.122346]\n",
      "epoch:22 step:21306 [D loss: 0.915394, acc.: 35.94%] [G loss: 1.159827]\n",
      "epoch:22 step:21307 [D loss: 0.673256, acc.: 60.94%] [G loss: 0.941282]\n",
      "epoch:22 step:21308 [D loss: 0.535898, acc.: 71.88%] [G loss: 1.235524]\n",
      "epoch:22 step:21309 [D loss: 0.829252, acc.: 40.62%] [G loss: 0.919840]\n",
      "epoch:22 step:21310 [D loss: 0.281373, acc.: 92.97%] [G loss: 1.025981]\n",
      "epoch:22 step:21311 [D loss: 0.266601, acc.: 93.75%] [G loss: 1.070774]\n",
      "epoch:22 step:21312 [D loss: 0.291815, acc.: 94.53%] [G loss: 1.146066]\n",
      "epoch:22 step:21313 [D loss: 0.504315, acc.: 84.38%] [G loss: 0.972388]\n",
      "epoch:22 step:21314 [D loss: 0.606157, acc.: 71.09%] [G loss: 0.999658]\n",
      "epoch:22 step:21315 [D loss: 0.303744, acc.: 85.16%] [G loss: 1.334953]\n",
      "epoch:22 step:21316 [D loss: 0.349122, acc.: 91.41%] [G loss: 1.158921]\n",
      "epoch:22 step:21317 [D loss: 0.740288, acc.: 50.78%] [G loss: 1.334531]\n",
      "epoch:22 step:21318 [D loss: 0.465320, acc.: 85.16%] [G loss: 1.316904]\n",
      "epoch:22 step:21319 [D loss: 0.908111, acc.: 34.38%] [G loss: 1.524595]\n",
      "epoch:22 step:21320 [D loss: 0.207862, acc.: 97.66%] [G loss: 1.434978]\n",
      "epoch:22 step:21321 [D loss: 0.249773, acc.: 97.66%] [G loss: 1.781670]\n",
      "epoch:22 step:21322 [D loss: 0.199634, acc.: 98.44%] [G loss: 1.431092]\n",
      "epoch:22 step:21323 [D loss: 0.121524, acc.: 100.00%] [G loss: 1.636076]\n",
      "epoch:22 step:21324 [D loss: 0.795794, acc.: 54.69%] [G loss: 1.455291]\n",
      "epoch:22 step:21325 [D loss: 0.826612, acc.: 53.91%] [G loss: 0.971719]\n",
      "epoch:22 step:21326 [D loss: 0.554633, acc.: 75.78%] [G loss: 1.155164]\n",
      "epoch:22 step:21327 [D loss: 0.222709, acc.: 94.53%] [G loss: 1.044647]\n",
      "epoch:22 step:21328 [D loss: 0.212945, acc.: 97.66%] [G loss: 1.404746]\n",
      "epoch:22 step:21329 [D loss: 0.801157, acc.: 44.53%] [G loss: 1.170229]\n",
      "epoch:22 step:21330 [D loss: 0.785571, acc.: 50.00%] [G loss: 1.277067]\n",
      "epoch:22 step:21331 [D loss: 0.659914, acc.: 64.84%] [G loss: 0.513764]\n",
      "epoch:22 step:21332 [D loss: 0.760942, acc.: 46.88%] [G loss: 1.168863]\n",
      "epoch:22 step:21333 [D loss: 0.705046, acc.: 54.69%] [G loss: 0.935569]\n",
      "epoch:22 step:21334 [D loss: 0.639908, acc.: 62.50%] [G loss: 1.120410]\n",
      "epoch:22 step:21335 [D loss: 0.658194, acc.: 60.16%] [G loss: 0.744520]\n",
      "epoch:22 step:21336 [D loss: 0.566766, acc.: 76.56%] [G loss: 1.280620]\n",
      "epoch:22 step:21337 [D loss: 0.453688, acc.: 81.25%] [G loss: 1.182371]\n",
      "epoch:22 step:21338 [D loss: 0.636320, acc.: 60.94%] [G loss: 1.271337]\n",
      "epoch:22 step:21339 [D loss: 0.653541, acc.: 56.25%] [G loss: 1.059937]\n",
      "epoch:22 step:21340 [D loss: 0.604782, acc.: 62.50%] [G loss: 1.296702]\n",
      "epoch:22 step:21341 [D loss: 0.232664, acc.: 99.22%] [G loss: 1.269367]\n",
      "epoch:22 step:21342 [D loss: 0.233067, acc.: 94.53%] [G loss: 1.325688]\n",
      "epoch:22 step:21343 [D loss: 0.338846, acc.: 86.72%] [G loss: 1.366238]\n",
      "epoch:22 step:21344 [D loss: 0.229094, acc.: 96.09%] [G loss: 1.224089]\n",
      "epoch:22 step:21345 [D loss: 0.188213, acc.: 97.66%] [G loss: 1.541333]\n",
      "epoch:22 step:21346 [D loss: 0.192792, acc.: 98.44%] [G loss: 1.589545]\n",
      "epoch:22 step:21347 [D loss: 0.323614, acc.: 86.72%] [G loss: 1.193654]\n",
      "epoch:22 step:21348 [D loss: 0.863377, acc.: 54.69%] [G loss: 1.625900]\n",
      "epoch:22 step:21349 [D loss: 0.698979, acc.: 53.12%] [G loss: 1.295578]\n",
      "epoch:22 step:21350 [D loss: 1.283355, acc.: 27.34%] [G loss: 1.177513]\n",
      "epoch:22 step:21351 [D loss: 0.693303, acc.: 57.81%] [G loss: 1.541753]\n",
      "epoch:22 step:21352 [D loss: 0.786384, acc.: 54.69%] [G loss: 1.545912]\n",
      "epoch:22 step:21353 [D loss: 0.866920, acc.: 46.88%] [G loss: 1.329622]\n",
      "epoch:22 step:21354 [D loss: 0.814202, acc.: 49.22%] [G loss: 1.263163]\n",
      "epoch:22 step:21355 [D loss: 0.459938, acc.: 83.59%] [G loss: 1.228364]\n",
      "epoch:22 step:21356 [D loss: 0.501771, acc.: 78.12%] [G loss: 1.351709]\n",
      "epoch:22 step:21357 [D loss: 0.389822, acc.: 91.41%] [G loss: 0.903148]\n",
      "epoch:22 step:21358 [D loss: 0.542903, acc.: 75.78%] [G loss: 1.275293]\n",
      "epoch:22 step:21359 [D loss: 0.542889, acc.: 75.00%] [G loss: 1.346381]\n",
      "epoch:22 step:21360 [D loss: 0.529951, acc.: 75.78%] [G loss: 0.888561]\n",
      "epoch:22 step:21361 [D loss: 0.832482, acc.: 46.88%] [G loss: 1.086680]\n",
      "epoch:22 step:21362 [D loss: 0.513664, acc.: 73.44%] [G loss: 1.185017]\n",
      "epoch:22 step:21363 [D loss: 0.528321, acc.: 75.00%] [G loss: 1.250906]\n",
      "epoch:22 step:21364 [D loss: 0.334711, acc.: 90.62%] [G loss: 1.534183]\n",
      "epoch:22 step:21365 [D loss: 0.689385, acc.: 56.25%] [G loss: 1.568083]\n",
      "epoch:22 step:21366 [D loss: 0.884696, acc.: 47.66%] [G loss: 1.307714]\n",
      "epoch:22 step:21367 [D loss: 0.668098, acc.: 60.94%] [G loss: 1.270430]\n",
      "epoch:22 step:21368 [D loss: 0.672441, acc.: 58.59%] [G loss: 1.289310]\n",
      "epoch:22 step:21369 [D loss: 0.671891, acc.: 57.81%] [G loss: 1.016282]\n",
      "epoch:22 step:21370 [D loss: 0.632382, acc.: 58.59%] [G loss: 0.972585]\n",
      "epoch:22 step:21371 [D loss: 0.594849, acc.: 66.41%] [G loss: 0.858144]\n",
      "epoch:22 step:21372 [D loss: 0.620468, acc.: 64.84%] [G loss: 1.081974]\n",
      "epoch:22 step:21373 [D loss: 0.434989, acc.: 80.47%] [G loss: 1.304103]\n",
      "epoch:22 step:21374 [D loss: 0.341672, acc.: 84.38%] [G loss: 1.458753]\n",
      "epoch:22 step:21375 [D loss: 0.487402, acc.: 79.69%] [G loss: 1.409360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21376 [D loss: 0.656450, acc.: 63.28%] [G loss: 1.267480]\n",
      "epoch:22 step:21377 [D loss: 0.644924, acc.: 57.03%] [G loss: 1.049067]\n",
      "epoch:22 step:21378 [D loss: 0.788895, acc.: 46.88%] [G loss: 1.039978]\n",
      "epoch:22 step:21379 [D loss: 0.536979, acc.: 74.22%] [G loss: 0.938986]\n",
      "epoch:22 step:21380 [D loss: 0.442810, acc.: 85.16%] [G loss: 1.386727]\n",
      "epoch:22 step:21381 [D loss: 0.492400, acc.: 73.44%] [G loss: 1.250881]\n",
      "epoch:22 step:21382 [D loss: 0.237517, acc.: 94.53%] [G loss: 1.359537]\n",
      "epoch:22 step:21383 [D loss: 0.228409, acc.: 94.53%] [G loss: 1.032391]\n",
      "epoch:22 step:21384 [D loss: 0.578300, acc.: 67.97%] [G loss: 1.470585]\n",
      "epoch:22 step:21385 [D loss: 0.897341, acc.: 35.94%] [G loss: 0.853114]\n",
      "epoch:22 step:21386 [D loss: 0.760536, acc.: 49.22%] [G loss: 1.776575]\n",
      "epoch:22 step:21387 [D loss: 0.728658, acc.: 58.59%] [G loss: 0.993922]\n",
      "epoch:22 step:21388 [D loss: 0.288167, acc.: 89.84%] [G loss: 1.241664]\n",
      "epoch:22 step:21389 [D loss: 0.247560, acc.: 96.88%] [G loss: 1.469551]\n",
      "epoch:22 step:21390 [D loss: 0.677490, acc.: 60.16%] [G loss: 1.641823]\n",
      "epoch:22 step:21391 [D loss: 0.531026, acc.: 78.12%] [G loss: 1.204053]\n",
      "epoch:22 step:21392 [D loss: 1.056567, acc.: 30.47%] [G loss: 1.228385]\n",
      "epoch:22 step:21393 [D loss: 0.961316, acc.: 42.19%] [G loss: 0.929299]\n",
      "epoch:22 step:21394 [D loss: 0.888644, acc.: 45.31%] [G loss: 1.455973]\n",
      "epoch:22 step:21395 [D loss: 0.556238, acc.: 69.53%] [G loss: 1.544613]\n",
      "epoch:22 step:21396 [D loss: 0.583544, acc.: 65.62%] [G loss: 1.512458]\n",
      "epoch:22 step:21397 [D loss: 0.596166, acc.: 66.41%] [G loss: 1.510122]\n",
      "epoch:22 step:21398 [D loss: 0.662851, acc.: 57.81%] [G loss: 2.669466]\n",
      "epoch:22 step:21399 [D loss: 0.558721, acc.: 75.78%] [G loss: 1.442235]\n",
      "epoch:22 step:21400 [D loss: 0.396197, acc.: 85.94%] [G loss: 1.422972]\n",
      "epoch:22 step:21401 [D loss: 0.547253, acc.: 72.66%] [G loss: 1.660791]\n",
      "epoch:22 step:21402 [D loss: 0.502529, acc.: 70.31%] [G loss: 1.303454]\n",
      "epoch:22 step:21403 [D loss: 0.641722, acc.: 67.19%] [G loss: 1.066664]\n",
      "epoch:22 step:21404 [D loss: 0.481717, acc.: 81.25%] [G loss: 1.102419]\n",
      "epoch:22 step:21405 [D loss: 0.344950, acc.: 85.94%] [G loss: 1.941843]\n",
      "epoch:22 step:21406 [D loss: 0.256912, acc.: 91.41%] [G loss: 1.460040]\n",
      "epoch:22 step:21407 [D loss: 0.232943, acc.: 93.75%] [G loss: 1.638870]\n",
      "epoch:22 step:21408 [D loss: 0.272293, acc.: 92.97%] [G loss: 2.514412]\n",
      "epoch:22 step:21409 [D loss: 0.446794, acc.: 87.50%] [G loss: 1.759959]\n",
      "epoch:22 step:21410 [D loss: 0.335531, acc.: 86.72%] [G loss: 2.058344]\n",
      "epoch:22 step:21411 [D loss: 0.652364, acc.: 62.50%] [G loss: 0.849726]\n",
      "epoch:22 step:21412 [D loss: 0.496364, acc.: 82.81%] [G loss: 1.515313]\n",
      "epoch:22 step:21413 [D loss: 1.020931, acc.: 30.47%] [G loss: 0.823307]\n",
      "epoch:22 step:21414 [D loss: 1.461716, acc.: 17.97%] [G loss: 0.963012]\n",
      "epoch:22 step:21415 [D loss: 0.760746, acc.: 46.88%] [G loss: 0.936228]\n",
      "epoch:22 step:21416 [D loss: 0.514201, acc.: 72.66%] [G loss: 0.933437]\n",
      "epoch:22 step:21417 [D loss: 0.530346, acc.: 73.44%] [G loss: 1.007034]\n",
      "epoch:22 step:21418 [D loss: 0.356533, acc.: 89.84%] [G loss: 1.088970]\n",
      "epoch:22 step:21419 [D loss: 0.487449, acc.: 82.81%] [G loss: 1.208090]\n",
      "epoch:22 step:21420 [D loss: 0.260844, acc.: 96.09%] [G loss: 1.431698]\n",
      "epoch:22 step:21421 [D loss: 0.610798, acc.: 63.28%] [G loss: 1.052100]\n",
      "epoch:22 step:21422 [D loss: 0.585467, acc.: 72.66%] [G loss: 1.234282]\n",
      "epoch:22 step:21423 [D loss: 0.548448, acc.: 77.34%] [G loss: 1.315271]\n",
      "epoch:22 step:21424 [D loss: 0.531177, acc.: 76.56%] [G loss: 1.305708]\n",
      "epoch:22 step:21425 [D loss: 0.801892, acc.: 48.44%] [G loss: 1.030565]\n",
      "epoch:22 step:21426 [D loss: 0.648914, acc.: 60.16%] [G loss: 1.065180]\n",
      "epoch:22 step:21427 [D loss: 0.695473, acc.: 55.47%] [G loss: 1.036909]\n",
      "epoch:22 step:21428 [D loss: 0.673695, acc.: 59.38%] [G loss: 1.014411]\n",
      "epoch:22 step:21429 [D loss: 0.393361, acc.: 87.50%] [G loss: 1.175791]\n",
      "epoch:22 step:21430 [D loss: 0.494142, acc.: 82.03%] [G loss: 1.139029]\n",
      "epoch:22 step:21431 [D loss: 0.675990, acc.: 61.72%] [G loss: 1.112245]\n",
      "epoch:22 step:21432 [D loss: 0.610213, acc.: 68.75%] [G loss: 1.162317]\n",
      "epoch:22 step:21433 [D loss: 0.595562, acc.: 68.75%] [G loss: 1.075729]\n",
      "epoch:22 step:21434 [D loss: 0.712671, acc.: 57.81%] [G loss: 1.038780]\n",
      "epoch:22 step:21435 [D loss: 0.646282, acc.: 63.28%] [G loss: 1.035150]\n",
      "epoch:22 step:21436 [D loss: 0.764892, acc.: 46.09%] [G loss: 1.072920]\n",
      "epoch:22 step:21437 [D loss: 0.615741, acc.: 65.62%] [G loss: 1.023260]\n",
      "epoch:22 step:21438 [D loss: 0.452280, acc.: 86.72%] [G loss: 1.050861]\n",
      "epoch:22 step:21439 [D loss: 0.470432, acc.: 80.47%] [G loss: 1.230711]\n",
      "epoch:22 step:21440 [D loss: 0.535591, acc.: 78.12%] [G loss: 1.051970]\n",
      "epoch:22 step:21441 [D loss: 0.682843, acc.: 53.91%] [G loss: 0.984622]\n",
      "epoch:22 step:21442 [D loss: 0.663999, acc.: 55.47%] [G loss: 0.899155]\n",
      "epoch:22 step:21443 [D loss: 0.542711, acc.: 75.78%] [G loss: 1.065341]\n",
      "epoch:22 step:21444 [D loss: 0.543554, acc.: 70.31%] [G loss: 0.823552]\n",
      "epoch:22 step:21445 [D loss: 0.357863, acc.: 87.50%] [G loss: 0.949308]\n",
      "epoch:22 step:21446 [D loss: 0.295163, acc.: 91.41%] [G loss: 1.234391]\n",
      "epoch:22 step:21447 [D loss: 0.250202, acc.: 95.31%] [G loss: 1.192404]\n",
      "epoch:22 step:21448 [D loss: 0.999284, acc.: 32.81%] [G loss: 1.086265]\n",
      "epoch:22 step:21449 [D loss: 0.821401, acc.: 42.97%] [G loss: 0.975559]\n",
      "epoch:22 step:21450 [D loss: 0.844255, acc.: 43.75%] [G loss: 1.024836]\n",
      "epoch:22 step:21451 [D loss: 0.739476, acc.: 46.09%] [G loss: 0.995068]\n",
      "epoch:22 step:21452 [D loss: 0.805027, acc.: 43.75%] [G loss: 0.854153]\n",
      "epoch:22 step:21453 [D loss: 0.743879, acc.: 51.56%] [G loss: 1.032329]\n",
      "epoch:22 step:21454 [D loss: 0.702932, acc.: 55.47%] [G loss: 0.767170]\n",
      "epoch:22 step:21455 [D loss: 0.826809, acc.: 34.38%] [G loss: 0.745677]\n",
      "epoch:22 step:21456 [D loss: 0.594342, acc.: 66.41%] [G loss: 0.909872]\n",
      "epoch:22 step:21457 [D loss: 0.535046, acc.: 71.88%] [G loss: 0.798964]\n",
      "epoch:22 step:21458 [D loss: 0.509942, acc.: 74.22%] [G loss: 0.768055]\n",
      "epoch:22 step:21459 [D loss: 0.394621, acc.: 73.44%] [G loss: 0.912288]\n",
      "epoch:22 step:21460 [D loss: 0.850609, acc.: 36.72%] [G loss: 1.090887]\n",
      "epoch:22 step:21461 [D loss: 0.753157, acc.: 50.00%] [G loss: 1.142860]\n",
      "epoch:22 step:21462 [D loss: 0.757441, acc.: 45.31%] [G loss: 1.494753]\n",
      "epoch:22 step:21463 [D loss: 0.601749, acc.: 59.38%] [G loss: 1.079197]\n",
      "epoch:22 step:21464 [D loss: 0.584303, acc.: 70.31%] [G loss: 1.219085]\n",
      "epoch:22 step:21465 [D loss: 0.308437, acc.: 89.06%] [G loss: 1.106948]\n",
      "epoch:22 step:21466 [D loss: 0.326636, acc.: 92.19%] [G loss: 1.319683]\n",
      "epoch:22 step:21467 [D loss: 0.353877, acc.: 92.97%] [G loss: 1.438304]\n",
      "epoch:22 step:21468 [D loss: 0.309809, acc.: 92.19%] [G loss: 1.261517]\n",
      "epoch:22 step:21469 [D loss: 0.503183, acc.: 83.59%] [G loss: 1.201823]\n",
      "epoch:22 step:21470 [D loss: 0.640889, acc.: 61.72%] [G loss: 1.193703]\n",
      "epoch:22 step:21471 [D loss: 0.263530, acc.: 95.31%] [G loss: 1.359893]\n",
      "epoch:22 step:21472 [D loss: 0.698991, acc.: 58.59%] [G loss: 1.103837]\n",
      "epoch:22 step:21473 [D loss: 0.579914, acc.: 71.88%] [G loss: 1.007499]\n",
      "epoch:22 step:21474 [D loss: 0.641138, acc.: 62.50%] [G loss: 1.094221]\n",
      "epoch:22 step:21475 [D loss: 0.616098, acc.: 64.84%] [G loss: 0.986109]\n",
      "epoch:22 step:21476 [D loss: 0.702511, acc.: 56.25%] [G loss: 1.039218]\n",
      "epoch:22 step:21477 [D loss: 0.650887, acc.: 65.62%] [G loss: 0.853283]\n",
      "epoch:22 step:21478 [D loss: 0.671631, acc.: 57.03%] [G loss: 0.881879]\n",
      "epoch:22 step:21479 [D loss: 0.552699, acc.: 73.44%] [G loss: 0.934976]\n",
      "epoch:22 step:21480 [D loss: 0.542566, acc.: 78.12%] [G loss: 1.037632]\n",
      "epoch:22 step:21481 [D loss: 0.415634, acc.: 75.78%] [G loss: 1.039811]\n",
      "epoch:22 step:21482 [D loss: 0.883651, acc.: 42.19%] [G loss: 1.090010]\n",
      "epoch:22 step:21483 [D loss: 0.621298, acc.: 66.41%] [G loss: 1.114769]\n",
      "epoch:22 step:21484 [D loss: 0.689047, acc.: 58.59%] [G loss: 1.131947]\n",
      "epoch:22 step:21485 [D loss: 0.681201, acc.: 61.72%] [G loss: 0.856780]\n",
      "epoch:22 step:21486 [D loss: 0.536232, acc.: 70.31%] [G loss: 0.928692]\n",
      "epoch:22 step:21487 [D loss: 0.613635, acc.: 64.84%] [G loss: 1.090404]\n",
      "epoch:22 step:21488 [D loss: 0.561334, acc.: 73.44%] [G loss: 1.078974]\n",
      "epoch:22 step:21489 [D loss: 0.549509, acc.: 75.00%] [G loss: 1.063488]\n",
      "epoch:22 step:21490 [D loss: 0.958007, acc.: 40.62%] [G loss: 0.995897]\n",
      "epoch:22 step:21491 [D loss: 0.692823, acc.: 50.00%] [G loss: 1.049652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21492 [D loss: 0.513466, acc.: 75.00%] [G loss: 0.924251]\n",
      "epoch:22 step:21493 [D loss: 0.953655, acc.: 32.81%] [G loss: 1.122796]\n",
      "epoch:22 step:21494 [D loss: 0.717789, acc.: 48.44%] [G loss: 0.842902]\n",
      "epoch:22 step:21495 [D loss: 0.726023, acc.: 50.78%] [G loss: 1.051326]\n",
      "epoch:22 step:21496 [D loss: 0.472661, acc.: 78.91%] [G loss: 1.282959]\n",
      "epoch:22 step:21497 [D loss: 0.774659, acc.: 50.00%] [G loss: 1.149432]\n",
      "epoch:22 step:21498 [D loss: 0.284275, acc.: 95.31%] [G loss: 1.318607]\n",
      "epoch:22 step:21499 [D loss: 0.243694, acc.: 97.66%] [G loss: 1.322896]\n",
      "epoch:22 step:21500 [D loss: 0.374219, acc.: 85.94%] [G loss: 1.309926]\n",
      "epoch:22 step:21501 [D loss: 0.301208, acc.: 91.41%] [G loss: 1.583222]\n",
      "epoch:22 step:21502 [D loss: 0.823225, acc.: 46.88%] [G loss: 1.528854]\n",
      "epoch:22 step:21503 [D loss: 0.432531, acc.: 84.38%] [G loss: 1.450063]\n",
      "epoch:22 step:21504 [D loss: 0.698735, acc.: 56.25%] [G loss: 1.393807]\n",
      "epoch:22 step:21505 [D loss: 0.767346, acc.: 50.78%] [G loss: 1.229813]\n",
      "epoch:22 step:21506 [D loss: 0.624130, acc.: 63.28%] [G loss: 0.929661]\n",
      "epoch:22 step:21507 [D loss: 0.681547, acc.: 55.47%] [G loss: 0.840564]\n",
      "epoch:22 step:21508 [D loss: 0.815709, acc.: 41.41%] [G loss: 1.447780]\n",
      "epoch:22 step:21509 [D loss: 0.581577, acc.: 64.84%] [G loss: 1.403858]\n",
      "epoch:22 step:21510 [D loss: 0.550765, acc.: 67.97%] [G loss: 1.153785]\n",
      "epoch:22 step:21511 [D loss: 0.478786, acc.: 77.34%] [G loss: 1.435347]\n",
      "epoch:22 step:21512 [D loss: 0.410361, acc.: 85.94%] [G loss: 1.426810]\n",
      "epoch:22 step:21513 [D loss: 0.232191, acc.: 95.31%] [G loss: 1.433500]\n",
      "epoch:22 step:21514 [D loss: 0.185995, acc.: 98.44%] [G loss: 1.665656]\n",
      "epoch:22 step:21515 [D loss: 0.384779, acc.: 83.59%] [G loss: 1.252895]\n",
      "epoch:22 step:21516 [D loss: 0.628834, acc.: 67.19%] [G loss: 1.397071]\n",
      "epoch:22 step:21517 [D loss: 0.506738, acc.: 78.12%] [G loss: 1.109878]\n",
      "epoch:22 step:21518 [D loss: 0.803155, acc.: 52.34%] [G loss: 0.893795]\n",
      "epoch:22 step:21519 [D loss: 0.630786, acc.: 64.06%] [G loss: 0.972390]\n",
      "epoch:22 step:21520 [D loss: 0.536527, acc.: 74.22%] [G loss: 1.113525]\n",
      "epoch:22 step:21521 [D loss: 0.669481, acc.: 55.47%] [G loss: 1.101979]\n",
      "epoch:22 step:21522 [D loss: 0.654134, acc.: 60.16%] [G loss: 0.878203]\n",
      "epoch:22 step:21523 [D loss: 0.351995, acc.: 91.41%] [G loss: 1.021274]\n",
      "epoch:22 step:21524 [D loss: 0.901228, acc.: 45.31%] [G loss: 0.962594]\n",
      "epoch:22 step:21525 [D loss: 0.354867, acc.: 89.06%] [G loss: 0.889190]\n",
      "epoch:22 step:21526 [D loss: 0.263713, acc.: 85.16%] [G loss: 1.388176]\n",
      "epoch:22 step:21527 [D loss: 0.674350, acc.: 56.25%] [G loss: 1.048322]\n",
      "epoch:22 step:21528 [D loss: 0.774131, acc.: 52.34%] [G loss: 1.282108]\n",
      "epoch:22 step:21529 [D loss: 0.688599, acc.: 58.59%] [G loss: 0.971551]\n",
      "epoch:22 step:21530 [D loss: 0.770932, acc.: 53.12%] [G loss: 0.990539]\n",
      "epoch:22 step:21531 [D loss: 0.635065, acc.: 64.06%] [G loss: 1.155763]\n",
      "epoch:22 step:21532 [D loss: 0.560381, acc.: 69.53%] [G loss: 0.962224]\n",
      "epoch:22 step:21533 [D loss: 0.375253, acc.: 84.38%] [G loss: 1.145466]\n",
      "epoch:22 step:21534 [D loss: 0.379628, acc.: 85.94%] [G loss: 0.852612]\n",
      "epoch:22 step:21535 [D loss: 0.299294, acc.: 89.06%] [G loss: 1.207330]\n",
      "epoch:22 step:21536 [D loss: 0.566244, acc.: 71.88%] [G loss: 1.170999]\n",
      "epoch:22 step:21537 [D loss: 0.486238, acc.: 84.38%] [G loss: 1.147552]\n",
      "epoch:22 step:21538 [D loss: 0.290762, acc.: 91.41%] [G loss: 1.247152]\n",
      "epoch:22 step:21539 [D loss: 0.317439, acc.: 93.75%] [G loss: 1.245099]\n",
      "epoch:22 step:21540 [D loss: 0.234023, acc.: 94.53%] [G loss: 1.175341]\n",
      "epoch:22 step:21541 [D loss: 0.171251, acc.: 96.09%] [G loss: 1.315225]\n",
      "epoch:22 step:21542 [D loss: 0.834188, acc.: 48.44%] [G loss: 1.223292]\n",
      "epoch:22 step:21543 [D loss: 0.565269, acc.: 64.84%] [G loss: 1.118821]\n",
      "epoch:22 step:21544 [D loss: 0.417787, acc.: 85.16%] [G loss: 1.531734]\n",
      "epoch:22 step:21545 [D loss: 0.559119, acc.: 68.75%] [G loss: 1.093084]\n",
      "epoch:22 step:21546 [D loss: 0.693396, acc.: 60.94%] [G loss: 1.232411]\n",
      "epoch:22 step:21547 [D loss: 0.523482, acc.: 68.75%] [G loss: 1.167671]\n",
      "epoch:22 step:21548 [D loss: 0.290364, acc.: 93.75%] [G loss: 1.203762]\n",
      "epoch:22 step:21549 [D loss: 0.438321, acc.: 81.25%] [G loss: 1.163391]\n",
      "epoch:22 step:21550 [D loss: 0.282665, acc.: 90.62%] [G loss: 1.340034]\n",
      "epoch:22 step:21551 [D loss: 0.139602, acc.: 96.09%] [G loss: 0.997213]\n",
      "epoch:23 step:21552 [D loss: 0.848909, acc.: 53.91%] [G loss: 1.447845]\n",
      "epoch:23 step:21553 [D loss: 0.857775, acc.: 41.41%] [G loss: 0.870556]\n",
      "epoch:23 step:21554 [D loss: 0.990281, acc.: 34.38%] [G loss: 1.289132]\n",
      "epoch:23 step:21555 [D loss: 0.765645, acc.: 49.22%] [G loss: 1.093388]\n",
      "epoch:23 step:21556 [D loss: 0.696450, acc.: 56.25%] [G loss: 0.711336]\n",
      "epoch:23 step:21557 [D loss: 0.711104, acc.: 57.81%] [G loss: 1.157051]\n",
      "epoch:23 step:21558 [D loss: 0.669569, acc.: 64.84%] [G loss: 1.047440]\n",
      "epoch:23 step:21559 [D loss: 0.686573, acc.: 56.25%] [G loss: 0.967583]\n",
      "epoch:23 step:21560 [D loss: 0.680274, acc.: 56.25%] [G loss: 1.051598]\n",
      "epoch:23 step:21561 [D loss: 0.604398, acc.: 68.75%] [G loss: 1.179693]\n",
      "epoch:23 step:21562 [D loss: 0.629499, acc.: 61.72%] [G loss: 0.919882]\n",
      "epoch:23 step:21563 [D loss: 0.589904, acc.: 74.22%] [G loss: 0.814430]\n",
      "epoch:23 step:21564 [D loss: 0.732072, acc.: 53.12%] [G loss: 0.876136]\n",
      "epoch:23 step:21565 [D loss: 0.678234, acc.: 60.94%] [G loss: 1.040289]\n",
      "epoch:23 step:21566 [D loss: 0.603753, acc.: 65.62%] [G loss: 0.952564]\n",
      "epoch:23 step:21567 [D loss: 0.587207, acc.: 68.75%] [G loss: 0.896327]\n",
      "epoch:23 step:21568 [D loss: 0.766549, acc.: 44.53%] [G loss: 0.987038]\n",
      "epoch:23 step:21569 [D loss: 0.744987, acc.: 48.44%] [G loss: 1.069196]\n",
      "epoch:23 step:21570 [D loss: 0.709518, acc.: 59.38%] [G loss: 0.911887]\n",
      "epoch:23 step:21571 [D loss: 0.689260, acc.: 55.47%] [G loss: 1.047570]\n",
      "epoch:23 step:21572 [D loss: 0.839090, acc.: 50.78%] [G loss: 1.093614]\n",
      "epoch:23 step:21573 [D loss: 0.764336, acc.: 50.00%] [G loss: 1.273247]\n",
      "epoch:23 step:21574 [D loss: 0.688935, acc.: 58.59%] [G loss: 1.053537]\n",
      "epoch:23 step:21575 [D loss: 0.771178, acc.: 51.56%] [G loss: 1.054321]\n",
      "epoch:23 step:21576 [D loss: 1.172085, acc.: 39.06%] [G loss: 1.110294]\n",
      "epoch:23 step:21577 [D loss: 0.616331, acc.: 61.72%] [G loss: 1.568955]\n",
      "epoch:23 step:21578 [D loss: 0.298477, acc.: 93.75%] [G loss: 1.908367]\n",
      "epoch:23 step:21579 [D loss: 0.497755, acc.: 75.78%] [G loss: 1.536767]\n",
      "epoch:23 step:21580 [D loss: 0.445023, acc.: 84.38%] [G loss: 1.581011]\n",
      "epoch:23 step:21581 [D loss: 0.480698, acc.: 76.56%] [G loss: 1.416610]\n",
      "epoch:23 step:21582 [D loss: 0.510131, acc.: 78.12%] [G loss: 1.307771]\n",
      "epoch:23 step:21583 [D loss: 0.250467, acc.: 96.88%] [G loss: 1.308950]\n",
      "epoch:23 step:21584 [D loss: 0.245583, acc.: 95.31%] [G loss: 1.353972]\n",
      "epoch:23 step:21585 [D loss: 0.210473, acc.: 96.88%] [G loss: 1.454050]\n",
      "epoch:23 step:21586 [D loss: 0.223506, acc.: 96.88%] [G loss: 1.422943]\n",
      "epoch:23 step:21587 [D loss: 0.120655, acc.: 98.44%] [G loss: 1.648587]\n",
      "epoch:23 step:21588 [D loss: 0.724732, acc.: 56.25%] [G loss: 1.355059]\n",
      "epoch:23 step:21589 [D loss: 1.113575, acc.: 41.41%] [G loss: 0.940005]\n",
      "epoch:23 step:21590 [D loss: 0.772363, acc.: 49.22%] [G loss: 0.906058]\n",
      "epoch:23 step:21591 [D loss: 0.794004, acc.: 54.69%] [G loss: 0.816703]\n",
      "epoch:23 step:21592 [D loss: 0.600927, acc.: 71.88%] [G loss: 0.911165]\n",
      "epoch:23 step:21593 [D loss: 0.491602, acc.: 82.81%] [G loss: 0.918499]\n",
      "epoch:23 step:21594 [D loss: 0.420652, acc.: 84.38%] [G loss: 0.940509]\n",
      "epoch:23 step:21595 [D loss: 0.444293, acc.: 85.94%] [G loss: 1.059993]\n",
      "epoch:23 step:21596 [D loss: 0.639542, acc.: 63.28%] [G loss: 0.981462]\n",
      "epoch:23 step:21597 [D loss: 0.549309, acc.: 75.78%] [G loss: 1.201061]\n",
      "epoch:23 step:21598 [D loss: 0.603822, acc.: 65.62%] [G loss: 0.804841]\n",
      "epoch:23 step:21599 [D loss: 0.767755, acc.: 50.78%] [G loss: 1.062372]\n",
      "epoch:23 step:21600 [D loss: 0.686075, acc.: 58.59%] [G loss: 0.986443]\n",
      "epoch:23 step:21601 [D loss: 0.520750, acc.: 75.78%] [G loss: 0.899788]\n",
      "epoch:23 step:21602 [D loss: 0.635477, acc.: 64.84%] [G loss: 0.925672]\n",
      "epoch:23 step:21603 [D loss: 0.604834, acc.: 64.06%] [G loss: 0.446478]\n",
      "epoch:23 step:21604 [D loss: 0.634305, acc.: 60.16%] [G loss: 1.063118]\n",
      "epoch:23 step:21605 [D loss: 0.628898, acc.: 66.41%] [G loss: 1.225204]\n",
      "epoch:23 step:21606 [D loss: 0.715240, acc.: 48.44%] [G loss: 0.990353]\n",
      "epoch:23 step:21607 [D loss: 0.539612, acc.: 74.22%] [G loss: 1.164518]\n",
      "epoch:23 step:21608 [D loss: 0.346594, acc.: 83.59%] [G loss: 1.441172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21609 [D loss: 0.346436, acc.: 87.50%] [G loss: 1.302459]\n",
      "epoch:23 step:21610 [D loss: 0.519066, acc.: 70.31%] [G loss: 1.373595]\n",
      "epoch:23 step:21611 [D loss: 0.280314, acc.: 92.97%] [G loss: 1.495620]\n",
      "epoch:23 step:21612 [D loss: 0.756516, acc.: 50.00%] [G loss: 1.411522]\n",
      "epoch:23 step:21613 [D loss: 0.837640, acc.: 49.22%] [G loss: 1.150035]\n",
      "epoch:23 step:21614 [D loss: 0.421713, acc.: 89.06%] [G loss: 1.164759]\n",
      "epoch:23 step:21615 [D loss: 0.684232, acc.: 56.25%] [G loss: 1.073102]\n",
      "epoch:23 step:21616 [D loss: 0.936983, acc.: 32.03%] [G loss: 0.684542]\n",
      "epoch:23 step:21617 [D loss: 0.831147, acc.: 39.84%] [G loss: 0.798580]\n",
      "epoch:23 step:21618 [D loss: 0.706398, acc.: 53.91%] [G loss: 1.136556]\n",
      "epoch:23 step:21619 [D loss: 0.715281, acc.: 57.81%] [G loss: 1.109680]\n",
      "epoch:23 step:21620 [D loss: 0.743418, acc.: 50.78%] [G loss: 0.769065]\n",
      "epoch:23 step:21621 [D loss: 0.793482, acc.: 42.19%] [G loss: 0.600918]\n",
      "epoch:23 step:21622 [D loss: 0.334586, acc.: 83.59%] [G loss: 1.094305]\n",
      "epoch:23 step:21623 [D loss: 0.330310, acc.: 92.97%] [G loss: 1.171012]\n",
      "epoch:23 step:21624 [D loss: 0.416091, acc.: 87.50%] [G loss: 1.509028]\n",
      "epoch:23 step:21625 [D loss: 0.559982, acc.: 75.00%] [G loss: 0.856953]\n",
      "epoch:23 step:21626 [D loss: 0.327296, acc.: 84.38%] [G loss: 1.132758]\n",
      "epoch:23 step:21627 [D loss: 0.202300, acc.: 98.44%] [G loss: 0.814448]\n",
      "epoch:23 step:21628 [D loss: 1.232566, acc.: 41.41%] [G loss: 1.098269]\n",
      "epoch:23 step:21629 [D loss: 1.008342, acc.: 48.44%] [G loss: 1.389393]\n",
      "epoch:23 step:21630 [D loss: 0.954033, acc.: 39.84%] [G loss: 1.175406]\n",
      "epoch:23 step:21631 [D loss: 0.663747, acc.: 59.38%] [G loss: 1.320053]\n",
      "epoch:23 step:21632 [D loss: 0.586063, acc.: 66.41%] [G loss: 1.419684]\n",
      "epoch:23 step:21633 [D loss: 0.586996, acc.: 65.62%] [G loss: 1.192922]\n",
      "epoch:23 step:21634 [D loss: 0.699129, acc.: 53.91%] [G loss: 1.416374]\n",
      "epoch:23 step:21635 [D loss: 0.670555, acc.: 57.81%] [G loss: 1.341330]\n",
      "epoch:23 step:21636 [D loss: 0.634081, acc.: 62.50%] [G loss: 1.309803]\n",
      "epoch:23 step:21637 [D loss: 0.667001, acc.: 60.16%] [G loss: 1.084585]\n",
      "epoch:23 step:21638 [D loss: 0.534444, acc.: 71.88%] [G loss: 1.039029]\n",
      "epoch:23 step:21639 [D loss: 0.512646, acc.: 76.56%] [G loss: 1.203500]\n",
      "epoch:23 step:21640 [D loss: 0.555610, acc.: 71.09%] [G loss: 1.187311]\n",
      "epoch:23 step:21641 [D loss: 0.551057, acc.: 68.75%] [G loss: 0.857650]\n",
      "epoch:23 step:21642 [D loss: 0.641502, acc.: 62.50%] [G loss: 1.164567]\n",
      "epoch:23 step:21643 [D loss: 0.517312, acc.: 78.12%] [G loss: 1.120746]\n",
      "epoch:23 step:21644 [D loss: 0.379889, acc.: 88.28%] [G loss: 1.279812]\n",
      "epoch:23 step:21645 [D loss: 0.557046, acc.: 78.91%] [G loss: 1.196678]\n",
      "epoch:23 step:21646 [D loss: 0.695297, acc.: 65.62%] [G loss: 0.923941]\n",
      "epoch:23 step:21647 [D loss: 0.647961, acc.: 67.19%] [G loss: 1.146933]\n",
      "epoch:23 step:21648 [D loss: 0.664613, acc.: 59.38%] [G loss: 0.985147]\n",
      "epoch:23 step:21649 [D loss: 0.708347, acc.: 54.69%] [G loss: 0.903990]\n",
      "epoch:23 step:21650 [D loss: 0.612864, acc.: 63.28%] [G loss: 0.953790]\n",
      "epoch:23 step:21651 [D loss: 0.644196, acc.: 63.28%] [G loss: 0.991119]\n",
      "epoch:23 step:21652 [D loss: 0.568399, acc.: 75.00%] [G loss: 0.987380]\n",
      "epoch:23 step:21653 [D loss: 0.660897, acc.: 60.94%] [G loss: 0.884446]\n",
      "epoch:23 step:21654 [D loss: 0.633207, acc.: 66.41%] [G loss: 0.989958]\n",
      "epoch:23 step:21655 [D loss: 0.639742, acc.: 63.28%] [G loss: 0.970699]\n",
      "epoch:23 step:21656 [D loss: 0.864078, acc.: 48.44%] [G loss: 0.867755]\n",
      "epoch:23 step:21657 [D loss: 0.665775, acc.: 62.50%] [G loss: 0.753966]\n",
      "epoch:23 step:21658 [D loss: 0.588784, acc.: 68.75%] [G loss: 0.949934]\n",
      "epoch:23 step:21659 [D loss: 0.632396, acc.: 63.28%] [G loss: 0.874459]\n",
      "epoch:23 step:21660 [D loss: 0.639808, acc.: 62.50%] [G loss: 0.941846]\n",
      "epoch:23 step:21661 [D loss: 0.758224, acc.: 53.12%] [G loss: 1.021252]\n",
      "epoch:23 step:21662 [D loss: 0.548890, acc.: 82.03%] [G loss: 0.940115]\n",
      "epoch:23 step:21663 [D loss: 0.510895, acc.: 83.59%] [G loss: 1.077178]\n",
      "epoch:23 step:21664 [D loss: 0.366706, acc.: 92.19%] [G loss: 1.030976]\n",
      "epoch:23 step:21665 [D loss: 0.456137, acc.: 80.47%] [G loss: 1.106011]\n",
      "epoch:23 step:21666 [D loss: 0.439368, acc.: 85.94%] [G loss: 1.117261]\n",
      "epoch:23 step:21667 [D loss: 0.611827, acc.: 64.06%] [G loss: 0.998483]\n",
      "epoch:23 step:21668 [D loss: 0.665282, acc.: 62.50%] [G loss: 1.016582]\n",
      "epoch:23 step:21669 [D loss: 0.686035, acc.: 59.38%] [G loss: 1.028542]\n",
      "epoch:23 step:21670 [D loss: 0.368835, acc.: 88.28%] [G loss: 1.090367]\n",
      "epoch:23 step:21671 [D loss: 0.445338, acc.: 82.81%] [G loss: 1.083922]\n",
      "epoch:23 step:21672 [D loss: 0.258971, acc.: 89.84%] [G loss: 0.913896]\n",
      "epoch:23 step:21673 [D loss: 0.286600, acc.: 92.97%] [G loss: 1.305057]\n",
      "epoch:23 step:21674 [D loss: 0.529522, acc.: 76.56%] [G loss: 1.183375]\n",
      "epoch:23 step:21675 [D loss: 0.693241, acc.: 56.25%] [G loss: 1.020961]\n",
      "epoch:23 step:21676 [D loss: 0.655563, acc.: 58.59%] [G loss: 1.189202]\n",
      "epoch:23 step:21677 [D loss: 0.666693, acc.: 53.91%] [G loss: 1.009740]\n",
      "epoch:23 step:21678 [D loss: 0.650968, acc.: 63.28%] [G loss: 0.967178]\n",
      "epoch:23 step:21679 [D loss: 0.549250, acc.: 76.56%] [G loss: 0.947339]\n",
      "epoch:23 step:21680 [D loss: 0.439222, acc.: 76.56%] [G loss: 1.199070]\n",
      "epoch:23 step:21681 [D loss: 0.373484, acc.: 81.25%] [G loss: 1.008542]\n",
      "epoch:23 step:21682 [D loss: 0.360898, acc.: 91.41%] [G loss: 1.279495]\n",
      "epoch:23 step:21683 [D loss: 0.390602, acc.: 88.28%] [G loss: 1.098466]\n",
      "epoch:23 step:21684 [D loss: 0.891637, acc.: 44.53%] [G loss: 0.946851]\n",
      "epoch:23 step:21685 [D loss: 0.713909, acc.: 53.91%] [G loss: 0.948998]\n",
      "epoch:23 step:21686 [D loss: 0.714952, acc.: 62.50%] [G loss: 0.938710]\n",
      "epoch:23 step:21687 [D loss: 0.728734, acc.: 46.09%] [G loss: 0.892718]\n",
      "epoch:23 step:21688 [D loss: 0.616114, acc.: 64.06%] [G loss: 1.274317]\n",
      "epoch:23 step:21689 [D loss: 0.451510, acc.: 89.84%] [G loss: 0.805368]\n",
      "epoch:23 step:21690 [D loss: 0.482000, acc.: 75.78%] [G loss: 0.843558]\n",
      "epoch:23 step:21691 [D loss: 0.735170, acc.: 51.56%] [G loss: 1.124703]\n",
      "epoch:23 step:21692 [D loss: 0.672613, acc.: 60.16%] [G loss: 0.698180]\n",
      "epoch:23 step:21693 [D loss: 0.931328, acc.: 25.00%] [G loss: 0.938551]\n",
      "epoch:23 step:21694 [D loss: 0.756572, acc.: 42.97%] [G loss: 0.837846]\n",
      "epoch:23 step:21695 [D loss: 0.660104, acc.: 62.50%] [G loss: 1.067676]\n",
      "epoch:23 step:21696 [D loss: 0.463559, acc.: 80.47%] [G loss: 0.946374]\n",
      "epoch:23 step:21697 [D loss: 0.677084, acc.: 61.72%] [G loss: 1.035636]\n",
      "epoch:23 step:21698 [D loss: 0.681360, acc.: 64.84%] [G loss: 1.077998]\n",
      "epoch:23 step:21699 [D loss: 0.801330, acc.: 44.53%] [G loss: 1.055855]\n",
      "epoch:23 step:21700 [D loss: 0.619262, acc.: 69.53%] [G loss: 1.010762]\n",
      "epoch:23 step:21701 [D loss: 0.386657, acc.: 79.69%] [G loss: 1.112026]\n",
      "epoch:23 step:21702 [D loss: 0.395724, acc.: 83.59%] [G loss: 1.406316]\n",
      "epoch:23 step:21703 [D loss: 0.411562, acc.: 87.50%] [G loss: 1.283396]\n",
      "epoch:23 step:21704 [D loss: 0.704168, acc.: 64.06%] [G loss: 1.118472]\n",
      "epoch:23 step:21705 [D loss: 0.716956, acc.: 51.56%] [G loss: 0.990582]\n",
      "epoch:23 step:21706 [D loss: 0.685432, acc.: 52.34%] [G loss: 1.005168]\n",
      "epoch:23 step:21707 [D loss: 0.657517, acc.: 59.38%] [G loss: 1.066193]\n",
      "epoch:23 step:21708 [D loss: 0.736120, acc.: 47.66%] [G loss: 1.146995]\n",
      "epoch:23 step:21709 [D loss: 0.820205, acc.: 39.84%] [G loss: 0.942945]\n",
      "epoch:23 step:21710 [D loss: 0.678074, acc.: 53.91%] [G loss: 1.013837]\n",
      "epoch:23 step:21711 [D loss: 0.624823, acc.: 71.09%] [G loss: 1.091854]\n",
      "epoch:23 step:21712 [D loss: 0.625954, acc.: 64.84%] [G loss: 0.901374]\n",
      "epoch:23 step:21713 [D loss: 0.645718, acc.: 63.28%] [G loss: 1.160828]\n",
      "epoch:23 step:21714 [D loss: 0.592051, acc.: 71.88%] [G loss: 1.115223]\n",
      "epoch:23 step:21715 [D loss: 0.713169, acc.: 52.34%] [G loss: 0.696238]\n",
      "epoch:23 step:21716 [D loss: 0.542029, acc.: 71.88%] [G loss: 0.934245]\n",
      "epoch:23 step:21717 [D loss: 0.745081, acc.: 46.88%] [G loss: 0.902387]\n",
      "epoch:23 step:21718 [D loss: 0.744097, acc.: 47.66%] [G loss: 0.957168]\n",
      "epoch:23 step:21719 [D loss: 0.582707, acc.: 72.66%] [G loss: 0.915327]\n",
      "epoch:23 step:21720 [D loss: 0.740514, acc.: 46.88%] [G loss: 0.530403]\n",
      "epoch:23 step:21721 [D loss: 0.640560, acc.: 60.94%] [G loss: 0.900473]\n",
      "epoch:23 step:21722 [D loss: 0.693718, acc.: 58.59%] [G loss: 0.957344]\n",
      "epoch:23 step:21723 [D loss: 0.708937, acc.: 54.69%] [G loss: 1.140398]\n",
      "epoch:23 step:21724 [D loss: 0.703662, acc.: 57.81%] [G loss: 1.006939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21725 [D loss: 0.641001, acc.: 62.50%] [G loss: 1.009827]\n",
      "epoch:23 step:21726 [D loss: 0.669459, acc.: 58.59%] [G loss: 0.989484]\n",
      "epoch:23 step:21727 [D loss: 0.655939, acc.: 59.38%] [G loss: 1.050201]\n",
      "epoch:23 step:21728 [D loss: 0.651314, acc.: 56.25%] [G loss: 0.968930]\n",
      "epoch:23 step:21729 [D loss: 0.662107, acc.: 57.81%] [G loss: 1.023397]\n",
      "epoch:23 step:21730 [D loss: 0.586791, acc.: 68.75%] [G loss: 0.877694]\n",
      "epoch:23 step:21731 [D loss: 0.594547, acc.: 76.56%] [G loss: 0.967853]\n",
      "epoch:23 step:21732 [D loss: 0.618010, acc.: 71.09%] [G loss: 0.941491]\n",
      "epoch:23 step:21733 [D loss: 0.661157, acc.: 62.50%] [G loss: 0.975818]\n",
      "epoch:23 step:21734 [D loss: 0.683051, acc.: 60.16%] [G loss: 0.865360]\n",
      "epoch:23 step:21735 [D loss: 0.588532, acc.: 72.66%] [G loss: 0.890126]\n",
      "epoch:23 step:21736 [D loss: 0.604120, acc.: 67.19%] [G loss: 0.886577]\n",
      "epoch:23 step:21737 [D loss: 0.715113, acc.: 50.78%] [G loss: 0.918962]\n",
      "epoch:23 step:21738 [D loss: 0.671494, acc.: 56.25%] [G loss: 0.915671]\n",
      "epoch:23 step:21739 [D loss: 0.699488, acc.: 53.91%] [G loss: 0.908551]\n",
      "epoch:23 step:21740 [D loss: 0.667762, acc.: 60.16%] [G loss: 0.802447]\n",
      "epoch:23 step:21741 [D loss: 0.708171, acc.: 50.78%] [G loss: 0.926366]\n",
      "epoch:23 step:21742 [D loss: 0.610437, acc.: 65.62%] [G loss: 0.917720]\n",
      "epoch:23 step:21743 [D loss: 0.615396, acc.: 65.62%] [G loss: 1.193315]\n",
      "epoch:23 step:21744 [D loss: 0.555960, acc.: 75.78%] [G loss: 0.973698]\n",
      "epoch:23 step:21745 [D loss: 0.572730, acc.: 76.56%] [G loss: 0.873312]\n",
      "epoch:23 step:21746 [D loss: 0.566864, acc.: 75.00%] [G loss: 0.815929]\n",
      "epoch:23 step:21747 [D loss: 0.747955, acc.: 50.78%] [G loss: 1.141672]\n",
      "epoch:23 step:21748 [D loss: 0.593985, acc.: 67.19%] [G loss: 0.980639]\n",
      "epoch:23 step:21749 [D loss: 0.720047, acc.: 54.69%] [G loss: 1.109938]\n",
      "epoch:23 step:21750 [D loss: 0.680811, acc.: 53.91%] [G loss: 0.917433]\n",
      "epoch:23 step:21751 [D loss: 0.410512, acc.: 87.50%] [G loss: 0.964534]\n",
      "epoch:23 step:21752 [D loss: 0.301276, acc.: 92.19%] [G loss: 1.176919]\n",
      "epoch:23 step:21753 [D loss: 0.755217, acc.: 43.75%] [G loss: 0.764958]\n",
      "epoch:23 step:21754 [D loss: 0.629166, acc.: 65.62%] [G loss: 0.938266]\n",
      "epoch:23 step:21755 [D loss: 0.494999, acc.: 75.78%] [G loss: 0.989826]\n",
      "epoch:23 step:21756 [D loss: 0.612839, acc.: 66.41%] [G loss: 0.963376]\n",
      "epoch:23 step:21757 [D loss: 0.548540, acc.: 76.56%] [G loss: 1.104931]\n",
      "epoch:23 step:21758 [D loss: 0.272575, acc.: 92.19%] [G loss: 1.185382]\n",
      "epoch:23 step:21759 [D loss: 0.576745, acc.: 71.09%] [G loss: 0.944158]\n",
      "epoch:23 step:21760 [D loss: 0.404536, acc.: 87.50%] [G loss: 1.205894]\n",
      "epoch:23 step:21761 [D loss: 0.785905, acc.: 45.31%] [G loss: 0.967530]\n",
      "epoch:23 step:21762 [D loss: 0.847691, acc.: 37.50%] [G loss: 0.939841]\n",
      "epoch:23 step:21763 [D loss: 0.746257, acc.: 53.12%] [G loss: 1.265907]\n",
      "epoch:23 step:21764 [D loss: 0.753252, acc.: 54.69%] [G loss: 1.195450]\n",
      "epoch:23 step:21765 [D loss: 0.754723, acc.: 53.12%] [G loss: 0.855790]\n",
      "epoch:23 step:21766 [D loss: 0.798871, acc.: 40.62%] [G loss: 1.028766]\n",
      "epoch:23 step:21767 [D loss: 0.652261, acc.: 65.62%] [G loss: 0.888119]\n",
      "epoch:23 step:21768 [D loss: 0.659145, acc.: 60.16%] [G loss: 0.803547]\n",
      "epoch:23 step:21769 [D loss: 0.606893, acc.: 67.19%] [G loss: 0.906800]\n",
      "epoch:23 step:21770 [D loss: 0.560923, acc.: 73.44%] [G loss: 0.871931]\n",
      "epoch:23 step:21771 [D loss: 0.348906, acc.: 79.69%] [G loss: 1.021641]\n",
      "epoch:23 step:21772 [D loss: 0.366380, acc.: 84.38%] [G loss: 1.083951]\n",
      "epoch:23 step:21773 [D loss: 0.390500, acc.: 86.72%] [G loss: 1.308871]\n",
      "epoch:23 step:21774 [D loss: 0.276266, acc.: 96.09%] [G loss: 1.172111]\n",
      "epoch:23 step:21775 [D loss: 0.721190, acc.: 54.69%] [G loss: 1.171099]\n",
      "epoch:23 step:21776 [D loss: 0.716039, acc.: 57.81%] [G loss: 1.164285]\n",
      "epoch:23 step:21777 [D loss: 0.620270, acc.: 66.41%] [G loss: 0.970428]\n",
      "epoch:23 step:21778 [D loss: 0.451173, acc.: 81.25%] [G loss: 1.023359]\n",
      "epoch:23 step:21779 [D loss: 0.561146, acc.: 75.78%] [G loss: 1.069612]\n",
      "epoch:23 step:21780 [D loss: 0.538077, acc.: 71.09%] [G loss: 0.789265]\n",
      "epoch:23 step:21781 [D loss: 0.220841, acc.: 94.53%] [G loss: 1.036535]\n",
      "epoch:23 step:21782 [D loss: 0.266788, acc.: 90.62%] [G loss: 1.206855]\n",
      "epoch:23 step:21783 [D loss: 0.327729, acc.: 85.94%] [G loss: 1.815731]\n",
      "epoch:23 step:21784 [D loss: 0.611896, acc.: 70.31%] [G loss: 1.231308]\n",
      "epoch:23 step:21785 [D loss: 0.550265, acc.: 74.22%] [G loss: 1.301449]\n",
      "epoch:23 step:21786 [D loss: 0.291328, acc.: 93.75%] [G loss: 1.343821]\n",
      "epoch:23 step:21787 [D loss: 0.545299, acc.: 76.56%] [G loss: 1.205966]\n",
      "epoch:23 step:21788 [D loss: 0.552218, acc.: 71.09%] [G loss: 1.405052]\n",
      "epoch:23 step:21789 [D loss: 0.392363, acc.: 92.97%] [G loss: 1.447331]\n",
      "epoch:23 step:21790 [D loss: 0.512589, acc.: 79.69%] [G loss: 1.379923]\n",
      "epoch:23 step:21791 [D loss: 0.560106, acc.: 67.19%] [G loss: 0.927876]\n",
      "epoch:23 step:21792 [D loss: 1.075555, acc.: 21.88%] [G loss: 1.106836]\n",
      "epoch:23 step:21793 [D loss: 0.784747, acc.: 53.12%] [G loss: 0.830395]\n",
      "epoch:23 step:21794 [D loss: 0.338815, acc.: 92.97%] [G loss: 1.126750]\n",
      "epoch:23 step:21795 [D loss: 1.005315, acc.: 28.12%] [G loss: 1.029749]\n",
      "epoch:23 step:21796 [D loss: 0.825439, acc.: 50.00%] [G loss: 1.067796]\n",
      "epoch:23 step:21797 [D loss: 0.698136, acc.: 56.25%] [G loss: 1.000209]\n",
      "epoch:23 step:21798 [D loss: 0.853283, acc.: 34.38%] [G loss: 1.068329]\n",
      "epoch:23 step:21799 [D loss: 0.659450, acc.: 64.06%] [G loss: 1.037544]\n",
      "epoch:23 step:21800 [D loss: 0.671777, acc.: 59.38%] [G loss: 1.061956]\n",
      "epoch:23 step:21801 [D loss: 0.740763, acc.: 44.53%] [G loss: 0.951708]\n",
      "epoch:23 step:21802 [D loss: 0.686153, acc.: 55.47%] [G loss: 0.912098]\n",
      "epoch:23 step:21803 [D loss: 0.680061, acc.: 54.69%] [G loss: 0.989893]\n",
      "epoch:23 step:21804 [D loss: 0.690340, acc.: 50.78%] [G loss: 0.898788]\n",
      "epoch:23 step:21805 [D loss: 0.627167, acc.: 67.19%] [G loss: 0.969907]\n",
      "epoch:23 step:21806 [D loss: 0.365520, acc.: 82.81%] [G loss: 0.908629]\n",
      "epoch:23 step:21807 [D loss: 0.285234, acc.: 88.28%] [G loss: 1.167958]\n",
      "epoch:23 step:21808 [D loss: 0.300861, acc.: 97.66%] [G loss: 1.259880]\n",
      "epoch:23 step:21809 [D loss: 0.515659, acc.: 81.25%] [G loss: 1.155538]\n",
      "epoch:23 step:21810 [D loss: 0.231369, acc.: 95.31%] [G loss: 1.182648]\n",
      "epoch:23 step:21811 [D loss: 0.290618, acc.: 96.09%] [G loss: 1.186027]\n",
      "epoch:23 step:21812 [D loss: 0.203877, acc.: 98.44%] [G loss: 1.308743]\n",
      "epoch:23 step:21813 [D loss: 0.909777, acc.: 31.25%] [G loss: 1.340517]\n",
      "epoch:23 step:21814 [D loss: 0.340474, acc.: 85.94%] [G loss: 1.164591]\n",
      "epoch:23 step:21815 [D loss: 0.569221, acc.: 62.50%] [G loss: 1.461767]\n",
      "epoch:23 step:21816 [D loss: 0.726841, acc.: 53.12%] [G loss: 1.231467]\n",
      "epoch:23 step:21817 [D loss: 0.752910, acc.: 56.25%] [G loss: 1.121208]\n",
      "epoch:23 step:21818 [D loss: 0.577943, acc.: 73.44%] [G loss: 1.029783]\n",
      "epoch:23 step:21819 [D loss: 0.683649, acc.: 58.59%] [G loss: 0.933868]\n",
      "epoch:23 step:21820 [D loss: 0.607325, acc.: 69.53%] [G loss: 0.918586]\n",
      "epoch:23 step:21821 [D loss: 0.673142, acc.: 57.03%] [G loss: 0.564474]\n",
      "epoch:23 step:21822 [D loss: 0.597754, acc.: 65.62%] [G loss: 1.097386]\n",
      "epoch:23 step:21823 [D loss: 0.641427, acc.: 67.19%] [G loss: 1.163146]\n",
      "epoch:23 step:21824 [D loss: 0.663310, acc.: 54.69%] [G loss: 1.038786]\n",
      "epoch:23 step:21825 [D loss: 0.691385, acc.: 59.38%] [G loss: 0.828205]\n",
      "epoch:23 step:21826 [D loss: 0.644451, acc.: 63.28%] [G loss: 1.037439]\n",
      "epoch:23 step:21827 [D loss: 0.528610, acc.: 79.69%] [G loss: 1.002865]\n",
      "epoch:23 step:21828 [D loss: 0.610854, acc.: 64.06%] [G loss: 0.955373]\n",
      "epoch:23 step:21829 [D loss: 0.339953, acc.: 89.84%] [G loss: 1.150949]\n",
      "epoch:23 step:21830 [D loss: 0.273825, acc.: 89.06%] [G loss: 1.103690]\n",
      "epoch:23 step:21831 [D loss: 0.440424, acc.: 88.28%] [G loss: 1.117614]\n",
      "epoch:23 step:21832 [D loss: 0.878607, acc.: 34.38%] [G loss: 1.120027]\n",
      "epoch:23 step:21833 [D loss: 0.870480, acc.: 37.50%] [G loss: 0.954980]\n",
      "epoch:23 step:21834 [D loss: 0.706972, acc.: 60.16%] [G loss: 0.941861]\n",
      "epoch:23 step:21835 [D loss: 0.369628, acc.: 84.38%] [G loss: 1.041891]\n",
      "epoch:23 step:21836 [D loss: 0.285105, acc.: 89.06%] [G loss: 1.197606]\n",
      "epoch:23 step:21837 [D loss: 0.240770, acc.: 94.53%] [G loss: 1.228107]\n",
      "epoch:23 step:21838 [D loss: 0.444414, acc.: 89.06%] [G loss: 1.309468]\n",
      "epoch:23 step:21839 [D loss: 0.239867, acc.: 96.88%] [G loss: 1.064042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21840 [D loss: 0.283370, acc.: 99.22%] [G loss: 1.480778]\n",
      "epoch:23 step:21841 [D loss: 0.360156, acc.: 93.75%] [G loss: 1.460296]\n",
      "epoch:23 step:21842 [D loss: 0.193479, acc.: 98.44%] [G loss: 1.193319]\n",
      "epoch:23 step:21843 [D loss: 0.263050, acc.: 97.66%] [G loss: 1.434210]\n",
      "epoch:23 step:21844 [D loss: 0.232220, acc.: 95.31%] [G loss: 1.506336]\n",
      "epoch:23 step:21845 [D loss: 0.355151, acc.: 91.41%] [G loss: 1.475600]\n",
      "epoch:23 step:21846 [D loss: 0.800828, acc.: 53.12%] [G loss: 1.512599]\n",
      "epoch:23 step:21847 [D loss: 0.709539, acc.: 56.25%] [G loss: 1.328305]\n",
      "epoch:23 step:21848 [D loss: 1.237684, acc.: 18.75%] [G loss: 1.136046]\n",
      "epoch:23 step:21849 [D loss: 0.788824, acc.: 42.97%] [G loss: 1.348960]\n",
      "epoch:23 step:21850 [D loss: 0.640543, acc.: 57.81%] [G loss: 1.250750]\n",
      "epoch:23 step:21851 [D loss: 0.734368, acc.: 55.47%] [G loss: 1.166331]\n",
      "epoch:23 step:21852 [D loss: 0.727939, acc.: 55.47%] [G loss: 0.866122]\n",
      "epoch:23 step:21853 [D loss: 0.726840, acc.: 48.44%] [G loss: 1.027318]\n",
      "epoch:23 step:21854 [D loss: 0.676026, acc.: 54.69%] [G loss: 0.915353]\n",
      "epoch:23 step:21855 [D loss: 0.432803, acc.: 88.28%] [G loss: 1.105738]\n",
      "epoch:23 step:21856 [D loss: 0.257135, acc.: 88.28%] [G loss: 1.156154]\n",
      "epoch:23 step:21857 [D loss: 0.457500, acc.: 86.72%] [G loss: 1.193594]\n",
      "epoch:23 step:21858 [D loss: 0.511737, acc.: 81.25%] [G loss: 1.233827]\n",
      "epoch:23 step:21859 [D loss: 0.249828, acc.: 92.19%] [G loss: 0.257993]\n",
      "epoch:23 step:21860 [D loss: 0.192396, acc.: 96.09%] [G loss: 1.430476]\n",
      "epoch:23 step:21861 [D loss: 0.377927, acc.: 91.41%] [G loss: 0.810560]\n",
      "epoch:23 step:21862 [D loss: 0.300029, acc.: 91.41%] [G loss: 1.286587]\n",
      "epoch:23 step:21863 [D loss: 0.544236, acc.: 64.84%] [G loss: 1.467375]\n",
      "epoch:23 step:21864 [D loss: 0.293178, acc.: 94.53%] [G loss: 1.206701]\n",
      "epoch:23 step:21865 [D loss: 0.257460, acc.: 92.97%] [G loss: 0.959717]\n",
      "epoch:23 step:21866 [D loss: 0.393787, acc.: 85.94%] [G loss: 1.568788]\n",
      "epoch:23 step:21867 [D loss: 1.595468, acc.: 6.25%] [G loss: 1.858186]\n",
      "epoch:23 step:21868 [D loss: 0.912968, acc.: 51.56%] [G loss: 1.861634]\n",
      "epoch:23 step:21869 [D loss: 1.084435, acc.: 32.03%] [G loss: 1.278811]\n",
      "epoch:23 step:21870 [D loss: 0.769348, acc.: 50.78%] [G loss: 1.326672]\n",
      "epoch:23 step:21871 [D loss: 0.746325, acc.: 48.44%] [G loss: 1.422878]\n",
      "epoch:23 step:21872 [D loss: 0.667110, acc.: 54.69%] [G loss: 0.945977]\n",
      "epoch:23 step:21873 [D loss: 0.712876, acc.: 52.34%] [G loss: 1.273990]\n",
      "epoch:23 step:21874 [D loss: 0.725827, acc.: 57.03%] [G loss: 1.473637]\n",
      "epoch:23 step:21875 [D loss: 0.726152, acc.: 54.69%] [G loss: 1.046664]\n",
      "epoch:23 step:21876 [D loss: 0.631730, acc.: 58.59%] [G loss: 1.293111]\n",
      "epoch:23 step:21877 [D loss: 0.638343, acc.: 57.81%] [G loss: 0.949595]\n",
      "epoch:23 step:21878 [D loss: 0.418346, acc.: 89.84%] [G loss: 1.477525]\n",
      "epoch:23 step:21879 [D loss: 0.448769, acc.: 88.28%] [G loss: 1.250925]\n",
      "epoch:23 step:21880 [D loss: 0.541939, acc.: 69.53%] [G loss: 1.371686]\n",
      "epoch:23 step:21881 [D loss: 0.658177, acc.: 57.81%] [G loss: 1.403310]\n",
      "epoch:23 step:21882 [D loss: 0.672673, acc.: 57.03%] [G loss: 1.280643]\n",
      "epoch:23 step:21883 [D loss: 0.579112, acc.: 70.31%] [G loss: 1.070312]\n",
      "epoch:23 step:21884 [D loss: 0.746941, acc.: 51.56%] [G loss: 0.925594]\n",
      "epoch:23 step:21885 [D loss: 0.742887, acc.: 43.75%] [G loss: 0.994224]\n",
      "epoch:23 step:21886 [D loss: 0.725504, acc.: 50.78%] [G loss: 0.994262]\n",
      "epoch:23 step:21887 [D loss: 0.729786, acc.: 45.31%] [G loss: 0.874649]\n",
      "epoch:23 step:21888 [D loss: 0.713552, acc.: 50.00%] [G loss: 0.859625]\n",
      "epoch:23 step:21889 [D loss: 0.557631, acc.: 75.00%] [G loss: 0.853422]\n",
      "epoch:23 step:21890 [D loss: 0.548944, acc.: 78.91%] [G loss: 0.980293]\n",
      "epoch:23 step:21891 [D loss: 0.636527, acc.: 64.06%] [G loss: 1.094509]\n",
      "epoch:23 step:21892 [D loss: 0.677865, acc.: 48.44%] [G loss: 1.054176]\n",
      "epoch:23 step:21893 [D loss: 0.659239, acc.: 61.72%] [G loss: 0.864635]\n",
      "epoch:23 step:21894 [D loss: 0.552181, acc.: 69.53%] [G loss: 0.970153]\n",
      "epoch:23 step:21895 [D loss: 0.546647, acc.: 80.47%] [G loss: 0.816114]\n",
      "epoch:23 step:21896 [D loss: 0.484564, acc.: 75.00%] [G loss: 0.894089]\n",
      "epoch:23 step:21897 [D loss: 0.405839, acc.: 85.94%] [G loss: 0.962021]\n",
      "epoch:23 step:21898 [D loss: 0.339706, acc.: 93.75%] [G loss: 0.993971]\n",
      "epoch:23 step:21899 [D loss: 0.689741, acc.: 52.34%] [G loss: 0.822237]\n",
      "epoch:23 step:21900 [D loss: 0.578054, acc.: 78.12%] [G loss: 1.044408]\n",
      "epoch:23 step:21901 [D loss: 0.672670, acc.: 54.69%] [G loss: 1.007654]\n",
      "epoch:23 step:21902 [D loss: 0.438705, acc.: 88.28%] [G loss: 0.959718]\n",
      "epoch:23 step:21903 [D loss: 0.404515, acc.: 89.06%] [G loss: 1.149039]\n",
      "epoch:23 step:21904 [D loss: 0.408819, acc.: 89.84%] [G loss: 1.239096]\n",
      "epoch:23 step:21905 [D loss: 0.374208, acc.: 96.09%] [G loss: 1.366855]\n",
      "epoch:23 step:21906 [D loss: 0.469461, acc.: 79.69%] [G loss: 1.704526]\n",
      "epoch:23 step:21907 [D loss: 0.450602, acc.: 83.59%] [G loss: 1.099158]\n",
      "epoch:23 step:21908 [D loss: 0.461671, acc.: 84.38%] [G loss: 1.586690]\n",
      "epoch:23 step:21909 [D loss: 0.375325, acc.: 92.97%] [G loss: 1.732435]\n",
      "epoch:23 step:21910 [D loss: 0.364566, acc.: 92.19%] [G loss: 1.153358]\n",
      "epoch:23 step:21911 [D loss: 0.424254, acc.: 89.84%] [G loss: 1.101034]\n",
      "epoch:23 step:21912 [D loss: 0.468014, acc.: 81.25%] [G loss: 1.817014]\n",
      "epoch:23 step:21913 [D loss: 0.923735, acc.: 50.00%] [G loss: 1.511848]\n",
      "epoch:23 step:21914 [D loss: 0.991653, acc.: 33.59%] [G loss: 1.036367]\n",
      "epoch:23 step:21915 [D loss: 0.622767, acc.: 60.16%] [G loss: 1.236291]\n",
      "epoch:23 step:21916 [D loss: 0.788106, acc.: 53.12%] [G loss: 0.990368]\n",
      "epoch:23 step:21917 [D loss: 0.516848, acc.: 71.09%] [G loss: 1.108417]\n",
      "epoch:23 step:21918 [D loss: 0.436686, acc.: 82.81%] [G loss: 1.149521]\n",
      "epoch:23 step:21919 [D loss: 0.784188, acc.: 47.66%] [G loss: 1.220749]\n",
      "epoch:23 step:21920 [D loss: 0.434085, acc.: 84.38%] [G loss: 1.152955]\n",
      "epoch:23 step:21921 [D loss: 0.345926, acc.: 87.50%] [G loss: 0.800934]\n",
      "epoch:23 step:21922 [D loss: 0.308045, acc.: 89.06%] [G loss: 1.164222]\n",
      "epoch:23 step:21923 [D loss: 0.523911, acc.: 75.78%] [G loss: 1.283396]\n",
      "epoch:23 step:21924 [D loss: 0.693728, acc.: 56.25%] [G loss: 0.949264]\n",
      "epoch:23 step:21925 [D loss: 0.751729, acc.: 51.56%] [G loss: 0.982393]\n",
      "epoch:23 step:21926 [D loss: 0.624796, acc.: 64.06%] [G loss: 0.932804]\n",
      "epoch:23 step:21927 [D loss: 0.800223, acc.: 51.56%] [G loss: 0.994596]\n",
      "epoch:23 step:21928 [D loss: 0.510209, acc.: 83.59%] [G loss: 0.616153]\n",
      "epoch:23 step:21929 [D loss: 0.522775, acc.: 71.09%] [G loss: 1.142313]\n",
      "epoch:23 step:21930 [D loss: 0.635696, acc.: 67.19%] [G loss: 1.078351]\n",
      "epoch:23 step:21931 [D loss: 0.330980, acc.: 92.19%] [G loss: 1.114967]\n",
      "epoch:23 step:21932 [D loss: 0.467524, acc.: 82.03%] [G loss: 0.948037]\n",
      "epoch:23 step:21933 [D loss: 0.656908, acc.: 56.25%] [G loss: 1.054046]\n",
      "epoch:23 step:21934 [D loss: 0.709416, acc.: 51.56%] [G loss: 0.994160]\n",
      "epoch:23 step:21935 [D loss: 0.882217, acc.: 36.72%] [G loss: 1.046039]\n",
      "epoch:23 step:21936 [D loss: 0.742327, acc.: 45.31%] [G loss: 1.181062]\n",
      "epoch:23 step:21937 [D loss: 0.897291, acc.: 39.84%] [G loss: 1.026142]\n",
      "epoch:23 step:21938 [D loss: 0.626666, acc.: 60.16%] [G loss: 1.130086]\n",
      "epoch:23 step:21939 [D loss: 0.734240, acc.: 53.91%] [G loss: 1.081163]\n",
      "epoch:23 step:21940 [D loss: 0.692089, acc.: 56.25%] [G loss: 1.141590]\n",
      "epoch:23 step:21941 [D loss: 0.642351, acc.: 58.59%] [G loss: 1.092339]\n",
      "epoch:23 step:21942 [D loss: 0.648415, acc.: 57.81%] [G loss: 0.948195]\n",
      "epoch:23 step:21943 [D loss: 0.632037, acc.: 69.53%] [G loss: 1.019410]\n",
      "epoch:23 step:21944 [D loss: 0.451043, acc.: 78.91%] [G loss: 1.086738]\n",
      "epoch:23 step:21945 [D loss: 0.623417, acc.: 65.62%] [G loss: 1.217474]\n",
      "epoch:23 step:21946 [D loss: 0.707665, acc.: 55.47%] [G loss: 0.934929]\n",
      "epoch:23 step:21947 [D loss: 0.357601, acc.: 78.91%] [G loss: 1.135051]\n",
      "epoch:23 step:21948 [D loss: 0.219253, acc.: 91.41%] [G loss: 1.312800]\n",
      "epoch:23 step:21949 [D loss: 0.213860, acc.: 94.53%] [G loss: 1.439156]\n",
      "epoch:23 step:21950 [D loss: 0.186649, acc.: 98.44%] [G loss: 1.576479]\n",
      "epoch:23 step:21951 [D loss: 0.247502, acc.: 93.75%] [G loss: 1.602884]\n",
      "epoch:23 step:21952 [D loss: 0.275209, acc.: 93.75%] [G loss: 1.448928]\n",
      "epoch:23 step:21953 [D loss: 0.211553, acc.: 97.66%] [G loss: 1.715914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21954 [D loss: 0.273775, acc.: 96.88%] [G loss: 1.676096]\n",
      "epoch:23 step:21955 [D loss: 0.153460, acc.: 99.22%] [G loss: 1.874768]\n",
      "epoch:23 step:21956 [D loss: 0.112235, acc.: 100.00%] [G loss: 1.691811]\n",
      "epoch:23 step:21957 [D loss: 0.150512, acc.: 99.22%] [G loss: 1.832985]\n",
      "epoch:23 step:21958 [D loss: 0.120529, acc.: 99.22%] [G loss: 1.972398]\n",
      "epoch:23 step:21959 [D loss: 0.298181, acc.: 93.75%] [G loss: 2.398875]\n",
      "epoch:23 step:21960 [D loss: 0.198506, acc.: 96.88%] [G loss: 2.007658]\n",
      "epoch:23 step:21961 [D loss: 0.580643, acc.: 67.19%] [G loss: 1.488584]\n",
      "epoch:23 step:21962 [D loss: 1.051776, acc.: 39.06%] [G loss: 1.421436]\n",
      "epoch:23 step:21963 [D loss: 0.306314, acc.: 91.41%] [G loss: 1.457602]\n",
      "epoch:23 step:21964 [D loss: 0.498810, acc.: 65.62%] [G loss: 1.436257]\n",
      "epoch:23 step:21965 [D loss: 0.188450, acc.: 96.09%] [G loss: 1.654598]\n",
      "epoch:23 step:21966 [D loss: 0.219231, acc.: 97.66%] [G loss: 2.011689]\n",
      "epoch:23 step:21967 [D loss: 0.465784, acc.: 79.69%] [G loss: 0.837769]\n",
      "epoch:23 step:21968 [D loss: 0.576998, acc.: 71.09%] [G loss: 0.955864]\n",
      "epoch:23 step:21969 [D loss: 0.506932, acc.: 64.84%] [G loss: 0.523261]\n",
      "epoch:23 step:21970 [D loss: 0.231139, acc.: 88.28%] [G loss: 2.137086]\n",
      "epoch:23 step:21971 [D loss: 0.584008, acc.: 71.88%] [G loss: 1.009065]\n",
      "epoch:23 step:21972 [D loss: 1.578720, acc.: 7.03%] [G loss: 1.825151]\n",
      "epoch:23 step:21973 [D loss: 1.030918, acc.: 44.53%] [G loss: 1.324482]\n",
      "epoch:23 step:21974 [D loss: 1.181133, acc.: 27.34%] [G loss: 1.203964]\n",
      "epoch:23 step:21975 [D loss: 0.444004, acc.: 79.69%] [G loss: 1.338624]\n",
      "epoch:23 step:21976 [D loss: 0.744264, acc.: 49.22%] [G loss: 0.708537]\n",
      "epoch:23 step:21977 [D loss: 0.993152, acc.: 28.91%] [G loss: 1.099434]\n",
      "epoch:23 step:21978 [D loss: 0.916467, acc.: 41.41%] [G loss: 1.307250]\n",
      "epoch:23 step:21979 [D loss: 0.486331, acc.: 77.34%] [G loss: 1.343209]\n",
      "epoch:23 step:21980 [D loss: 0.887798, acc.: 36.72%] [G loss: 1.435408]\n",
      "epoch:23 step:21981 [D loss: 0.628054, acc.: 68.75%] [G loss: 1.120908]\n",
      "epoch:23 step:21982 [D loss: 0.926257, acc.: 41.41%] [G loss: 1.195677]\n",
      "epoch:23 step:21983 [D loss: 0.899072, acc.: 39.84%] [G loss: 0.890764]\n",
      "epoch:23 step:21984 [D loss: 0.810165, acc.: 47.66%] [G loss: 1.377334]\n",
      "epoch:23 step:21985 [D loss: 0.811350, acc.: 46.09%] [G loss: 1.065052]\n",
      "epoch:23 step:21986 [D loss: 0.714782, acc.: 53.12%] [G loss: 1.182509]\n",
      "epoch:23 step:21987 [D loss: 0.633448, acc.: 59.38%] [G loss: 1.229903]\n",
      "epoch:23 step:21988 [D loss: 0.707062, acc.: 50.00%] [G loss: 1.184806]\n",
      "epoch:23 step:21989 [D loss: 0.710262, acc.: 55.47%] [G loss: 1.207960]\n",
      "epoch:23 step:21990 [D loss: 0.688373, acc.: 53.91%] [G loss: 1.124790]\n",
      "epoch:23 step:21991 [D loss: 0.719121, acc.: 50.78%] [G loss: 1.069703]\n",
      "epoch:23 step:21992 [D loss: 0.742877, acc.: 46.09%] [G loss: 1.076421]\n",
      "epoch:23 step:21993 [D loss: 0.667271, acc.: 57.81%] [G loss: 1.125041]\n",
      "epoch:23 step:21994 [D loss: 0.576213, acc.: 76.56%] [G loss: 1.294704]\n",
      "epoch:23 step:21995 [D loss: 0.607868, acc.: 66.41%] [G loss: 1.224513]\n",
      "epoch:23 step:21996 [D loss: 0.590074, acc.: 71.09%] [G loss: 1.315584]\n",
      "epoch:23 step:21997 [D loss: 0.703908, acc.: 57.03%] [G loss: 0.963245]\n",
      "epoch:23 step:21998 [D loss: 0.626649, acc.: 70.31%] [G loss: 1.154037]\n",
      "epoch:23 step:21999 [D loss: 0.492696, acc.: 85.94%] [G loss: 1.189495]\n",
      "epoch:23 step:22000 [D loss: 0.386307, acc.: 94.53%] [G loss: 1.430432]\n",
      "epoch:23 step:22001 [D loss: 0.419158, acc.: 84.38%] [G loss: 1.180123]\n",
      "epoch:23 step:22002 [D loss: 0.355086, acc.: 96.09%] [G loss: 1.161230]\n",
      "epoch:23 step:22003 [D loss: 0.403125, acc.: 89.06%] [G loss: 1.016768]\n",
      "epoch:23 step:22004 [D loss: 0.388798, acc.: 93.75%] [G loss: 1.472211]\n",
      "epoch:23 step:22005 [D loss: 0.456856, acc.: 91.41%] [G loss: 1.418342]\n",
      "epoch:23 step:22006 [D loss: 0.424391, acc.: 89.06%] [G loss: 1.814289]\n",
      "epoch:23 step:22007 [D loss: 0.262769, acc.: 92.97%] [G loss: 1.527723]\n",
      "epoch:23 step:22008 [D loss: 0.356772, acc.: 93.75%] [G loss: 1.184168]\n",
      "epoch:23 step:22009 [D loss: 0.751830, acc.: 53.12%] [G loss: 1.129646]\n",
      "epoch:23 step:22010 [D loss: 0.566163, acc.: 71.88%] [G loss: 1.018012]\n",
      "epoch:23 step:22011 [D loss: 0.662409, acc.: 66.41%] [G loss: 0.955441]\n",
      "epoch:23 step:22012 [D loss: 0.950931, acc.: 39.84%] [G loss: 0.684327]\n",
      "epoch:23 step:22013 [D loss: 1.239317, acc.: 22.66%] [G loss: 0.710912]\n",
      "epoch:23 step:22014 [D loss: 0.752789, acc.: 53.12%] [G loss: 0.738724]\n",
      "epoch:23 step:22015 [D loss: 0.646825, acc.: 58.59%] [G loss: 0.749503]\n",
      "epoch:23 step:22016 [D loss: 0.551851, acc.: 71.88%] [G loss: 0.810485]\n",
      "epoch:23 step:22017 [D loss: 0.535226, acc.: 75.78%] [G loss: 0.814537]\n",
      "epoch:23 step:22018 [D loss: 0.528914, acc.: 78.12%] [G loss: 0.944428]\n",
      "epoch:23 step:22019 [D loss: 0.373769, acc.: 89.06%] [G loss: 1.133469]\n",
      "epoch:23 step:22020 [D loss: 0.398753, acc.: 89.06%] [G loss: 1.347076]\n",
      "epoch:23 step:22021 [D loss: 0.381219, acc.: 82.03%] [G loss: 1.069489]\n",
      "epoch:23 step:22022 [D loss: 0.373745, acc.: 85.94%] [G loss: 1.297747]\n",
      "epoch:23 step:22023 [D loss: 0.431381, acc.: 83.59%] [G loss: 1.132227]\n",
      "epoch:23 step:22024 [D loss: 1.134287, acc.: 36.72%] [G loss: 0.963344]\n",
      "epoch:23 step:22025 [D loss: 0.977247, acc.: 39.84%] [G loss: 1.140798]\n",
      "epoch:23 step:22026 [D loss: 0.846843, acc.: 39.84%] [G loss: 0.913889]\n",
      "epoch:23 step:22027 [D loss: 0.674646, acc.: 59.38%] [G loss: 0.704618]\n",
      "epoch:23 step:22028 [D loss: 0.580710, acc.: 64.84%] [G loss: 0.647589]\n",
      "epoch:23 step:22029 [D loss: 0.745369, acc.: 53.12%] [G loss: 0.822194]\n",
      "epoch:23 step:22030 [D loss: 0.475673, acc.: 84.38%] [G loss: 1.052601]\n",
      "epoch:23 step:22031 [D loss: 0.483432, acc.: 75.00%] [G loss: 1.131651]\n",
      "epoch:23 step:22032 [D loss: 0.443576, acc.: 83.59%] [G loss: 0.925189]\n",
      "epoch:23 step:22033 [D loss: 0.804465, acc.: 48.44%] [G loss: 1.106384]\n",
      "epoch:23 step:22034 [D loss: 0.735178, acc.: 49.22%] [G loss: 0.954468]\n",
      "epoch:23 step:22035 [D loss: 0.775762, acc.: 40.62%] [G loss: 0.888315]\n",
      "epoch:23 step:22036 [D loss: 0.689297, acc.: 55.47%] [G loss: 1.206725]\n",
      "epoch:23 step:22037 [D loss: 0.756830, acc.: 46.09%] [G loss: 1.031101]\n",
      "epoch:23 step:22038 [D loss: 0.794579, acc.: 41.41%] [G loss: 0.912698]\n",
      "epoch:23 step:22039 [D loss: 0.618578, acc.: 65.62%] [G loss: 1.024090]\n",
      "epoch:23 step:22040 [D loss: 0.696814, acc.: 53.91%] [G loss: 0.951211]\n",
      "epoch:23 step:22041 [D loss: 0.481159, acc.: 79.69%] [G loss: 0.882487]\n",
      "epoch:23 step:22042 [D loss: 0.554291, acc.: 71.88%] [G loss: 0.997869]\n",
      "epoch:23 step:22043 [D loss: 0.624253, acc.: 64.84%] [G loss: 0.896174]\n",
      "epoch:23 step:22044 [D loss: 0.640048, acc.: 65.62%] [G loss: 0.936025]\n",
      "epoch:23 step:22045 [D loss: 0.551036, acc.: 73.44%] [G loss: 0.917498]\n",
      "epoch:23 step:22046 [D loss: 0.618734, acc.: 64.84%] [G loss: 0.859825]\n",
      "epoch:23 step:22047 [D loss: 0.721856, acc.: 51.56%] [G loss: 0.810950]\n",
      "epoch:23 step:22048 [D loss: 0.574521, acc.: 75.00%] [G loss: 0.987698]\n",
      "epoch:23 step:22049 [D loss: 0.583103, acc.: 68.75%] [G loss: 0.913124]\n",
      "epoch:23 step:22050 [D loss: 0.572229, acc.: 65.62%] [G loss: 1.233733]\n",
      "epoch:23 step:22051 [D loss: 0.599564, acc.: 64.84%] [G loss: 0.946891]\n",
      "epoch:23 step:22052 [D loss: 0.727276, acc.: 62.50%] [G loss: 0.904250]\n",
      "epoch:23 step:22053 [D loss: 0.581680, acc.: 67.19%] [G loss: 0.877450]\n",
      "epoch:23 step:22054 [D loss: 0.449628, acc.: 80.47%] [G loss: 0.836435]\n",
      "epoch:23 step:22055 [D loss: 0.397801, acc.: 85.94%] [G loss: 1.002247]\n",
      "epoch:23 step:22056 [D loss: 0.563817, acc.: 71.09%] [G loss: 0.913744]\n",
      "epoch:23 step:22057 [D loss: 0.699216, acc.: 48.44%] [G loss: 1.032089]\n",
      "epoch:23 step:22058 [D loss: 0.564123, acc.: 75.78%] [G loss: 0.992253]\n",
      "epoch:23 step:22059 [D loss: 0.560153, acc.: 73.44%] [G loss: 1.148781]\n",
      "epoch:23 step:22060 [D loss: 0.684851, acc.: 56.25%] [G loss: 1.232166]\n",
      "epoch:23 step:22061 [D loss: 0.658948, acc.: 54.69%] [G loss: 0.927912]\n",
      "epoch:23 step:22062 [D loss: 0.611117, acc.: 68.75%] [G loss: 1.114941]\n",
      "epoch:23 step:22063 [D loss: 0.614353, acc.: 64.06%] [G loss: 1.058989]\n",
      "epoch:23 step:22064 [D loss: 0.400553, acc.: 89.84%] [G loss: 1.005773]\n",
      "epoch:23 step:22065 [D loss: 0.457583, acc.: 84.38%] [G loss: 1.018594]\n",
      "epoch:23 step:22066 [D loss: 0.475184, acc.: 78.12%] [G loss: 1.005462]\n",
      "epoch:23 step:22067 [D loss: 0.774803, acc.: 55.47%] [G loss: 0.927553]\n",
      "epoch:23 step:22068 [D loss: 0.514694, acc.: 73.44%] [G loss: 0.827462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22069 [D loss: 0.578591, acc.: 73.44%] [G loss: 1.064858]\n",
      "epoch:23 step:22070 [D loss: 0.553450, acc.: 75.00%] [G loss: 1.157204]\n",
      "epoch:23 step:22071 [D loss: 0.481071, acc.: 80.47%] [G loss: 1.232502]\n",
      "epoch:23 step:22072 [D loss: 0.554832, acc.: 77.34%] [G loss: 1.347539]\n",
      "epoch:23 step:22073 [D loss: 0.533241, acc.: 73.44%] [G loss: 1.183212]\n",
      "epoch:23 step:22074 [D loss: 0.553482, acc.: 70.31%] [G loss: 1.308813]\n",
      "epoch:23 step:22075 [D loss: 0.529424, acc.: 75.78%] [G loss: 1.169611]\n",
      "epoch:23 step:22076 [D loss: 0.707762, acc.: 56.25%] [G loss: 1.173138]\n",
      "epoch:23 step:22077 [D loss: 0.593462, acc.: 66.41%] [G loss: 1.131691]\n",
      "epoch:23 step:22078 [D loss: 0.575090, acc.: 70.31%] [G loss: 1.038328]\n",
      "epoch:23 step:22079 [D loss: 0.664070, acc.: 57.03%] [G loss: 0.740026]\n",
      "epoch:23 step:22080 [D loss: 0.699215, acc.: 53.91%] [G loss: 1.028055]\n",
      "epoch:23 step:22081 [D loss: 0.484834, acc.: 77.34%] [G loss: 0.876859]\n",
      "epoch:23 step:22082 [D loss: 0.648388, acc.: 63.28%] [G loss: 1.034349]\n",
      "epoch:23 step:22083 [D loss: 0.580674, acc.: 67.97%] [G loss: 0.967136]\n",
      "epoch:23 step:22084 [D loss: 0.445396, acc.: 77.34%] [G loss: 1.167250]\n",
      "epoch:23 step:22085 [D loss: 0.428239, acc.: 89.84%] [G loss: 1.085787]\n",
      "epoch:23 step:22086 [D loss: 0.573351, acc.: 67.19%] [G loss: 1.212952]\n",
      "epoch:23 step:22087 [D loss: 0.346707, acc.: 87.50%] [G loss: 1.169300]\n",
      "epoch:23 step:22088 [D loss: 0.588791, acc.: 62.50%] [G loss: 1.237600]\n",
      "epoch:23 step:22089 [D loss: 0.679899, acc.: 59.38%] [G loss: 1.269888]\n",
      "epoch:23 step:22090 [D loss: 0.581874, acc.: 67.97%] [G loss: 1.311831]\n",
      "epoch:23 step:22091 [D loss: 0.624055, acc.: 63.28%] [G loss: 0.960050]\n",
      "epoch:23 step:22092 [D loss: 0.707614, acc.: 48.44%] [G loss: 1.148306]\n",
      "epoch:23 step:22093 [D loss: 0.562376, acc.: 64.84%] [G loss: 0.958338]\n",
      "epoch:23 step:22094 [D loss: 0.347534, acc.: 82.81%] [G loss: 1.224079]\n",
      "epoch:23 step:22095 [D loss: 0.510475, acc.: 75.00%] [G loss: 1.392669]\n",
      "epoch:23 step:22096 [D loss: 0.432456, acc.: 81.25%] [G loss: 1.621666]\n",
      "epoch:23 step:22097 [D loss: 0.549605, acc.: 69.53%] [G loss: 1.328485]\n",
      "epoch:23 step:22098 [D loss: 0.571581, acc.: 67.19%] [G loss: 1.033936]\n",
      "epoch:23 step:22099 [D loss: 0.370366, acc.: 89.06%] [G loss: 1.232011]\n",
      "epoch:23 step:22100 [D loss: 0.339861, acc.: 89.06%] [G loss: 1.453682]\n",
      "epoch:23 step:22101 [D loss: 0.176854, acc.: 96.88%] [G loss: 1.451032]\n",
      "epoch:23 step:22102 [D loss: 0.288798, acc.: 96.09%] [G loss: 0.959047]\n",
      "epoch:23 step:22103 [D loss: 0.318824, acc.: 92.97%] [G loss: 1.268762]\n",
      "epoch:23 step:22104 [D loss: 0.657995, acc.: 63.28%] [G loss: 1.304155]\n",
      "epoch:23 step:22105 [D loss: 0.205243, acc.: 93.75%] [G loss: 0.977907]\n",
      "epoch:23 step:22106 [D loss: 0.333628, acc.: 85.94%] [G loss: 1.837785]\n",
      "epoch:23 step:22107 [D loss: 0.385279, acc.: 80.47%] [G loss: 1.315020]\n",
      "epoch:23 step:22108 [D loss: 0.356813, acc.: 92.97%] [G loss: 1.485523]\n",
      "epoch:23 step:22109 [D loss: 0.463326, acc.: 82.81%] [G loss: 1.629049]\n",
      "epoch:23 step:22110 [D loss: 0.598680, acc.: 63.28%] [G loss: 1.875113]\n",
      "epoch:23 step:22111 [D loss: 0.975230, acc.: 37.50%] [G loss: 0.860676]\n",
      "epoch:23 step:22112 [D loss: 0.592884, acc.: 65.62%] [G loss: 1.606730]\n",
      "epoch:23 step:22113 [D loss: 1.087106, acc.: 42.19%] [G loss: 1.379027]\n",
      "epoch:23 step:22114 [D loss: 0.746496, acc.: 51.56%] [G loss: 1.676957]\n",
      "epoch:23 step:22115 [D loss: 0.750620, acc.: 53.91%] [G loss: 0.908349]\n",
      "epoch:23 step:22116 [D loss: 0.683312, acc.: 57.03%] [G loss: 1.169474]\n",
      "epoch:23 step:22117 [D loss: 0.473693, acc.: 75.00%] [G loss: 1.018173]\n",
      "epoch:23 step:22118 [D loss: 0.302544, acc.: 82.81%] [G loss: 1.293305]\n",
      "epoch:23 step:22119 [D loss: 0.714762, acc.: 53.91%] [G loss: 1.416103]\n",
      "epoch:23 step:22120 [D loss: 0.736886, acc.: 53.91%] [G loss: 1.484525]\n",
      "epoch:23 step:22121 [D loss: 0.613601, acc.: 60.94%] [G loss: 1.327351]\n",
      "epoch:23 step:22122 [D loss: 0.649531, acc.: 60.94%] [G loss: 1.325558]\n",
      "epoch:23 step:22123 [D loss: 0.496533, acc.: 74.22%] [G loss: 1.321159]\n",
      "epoch:23 step:22124 [D loss: 0.401305, acc.: 89.84%] [G loss: 1.419148]\n",
      "epoch:23 step:22125 [D loss: 0.585279, acc.: 64.06%] [G loss: 1.497587]\n",
      "epoch:23 step:22126 [D loss: 0.370179, acc.: 92.19%] [G loss: 1.288249]\n",
      "epoch:23 step:22127 [D loss: 0.281269, acc.: 94.53%] [G loss: 1.669345]\n",
      "epoch:23 step:22128 [D loss: 0.327746, acc.: 86.72%] [G loss: 1.658139]\n",
      "epoch:23 step:22129 [D loss: 0.215232, acc.: 93.75%] [G loss: 1.602677]\n",
      "epoch:23 step:22130 [D loss: 0.208649, acc.: 97.66%] [G loss: 2.191814]\n",
      "epoch:23 step:22131 [D loss: 0.680086, acc.: 67.97%] [G loss: 1.286186]\n",
      "epoch:23 step:22132 [D loss: 0.586356, acc.: 69.53%] [G loss: 1.594326]\n",
      "epoch:23 step:22133 [D loss: 0.626322, acc.: 67.97%] [G loss: 1.210433]\n",
      "epoch:23 step:22134 [D loss: 0.718647, acc.: 60.16%] [G loss: 0.980824]\n",
      "epoch:23 step:22135 [D loss: 0.750759, acc.: 54.69%] [G loss: 1.169900]\n",
      "epoch:23 step:22136 [D loss: 0.675956, acc.: 60.94%] [G loss: 1.011783]\n",
      "epoch:23 step:22137 [D loss: 0.579208, acc.: 67.19%] [G loss: 1.218071]\n",
      "epoch:23 step:22138 [D loss: 0.268419, acc.: 85.94%] [G loss: 1.114459]\n",
      "epoch:23 step:22139 [D loss: 0.263254, acc.: 88.28%] [G loss: 1.200009]\n",
      "epoch:23 step:22140 [D loss: 0.154780, acc.: 96.09%] [G loss: 1.434453]\n",
      "epoch:23 step:22141 [D loss: 0.396488, acc.: 87.50%] [G loss: 1.165591]\n",
      "epoch:23 step:22142 [D loss: 1.046945, acc.: 44.53%] [G loss: 0.813828]\n",
      "epoch:23 step:22143 [D loss: 1.010363, acc.: 28.12%] [G loss: 1.081832]\n",
      "epoch:23 step:22144 [D loss: 0.642277, acc.: 64.06%] [G loss: 1.103535]\n",
      "epoch:23 step:22145 [D loss: 0.327226, acc.: 88.28%] [G loss: 1.051644]\n",
      "epoch:23 step:22146 [D loss: 0.274400, acc.: 92.97%] [G loss: 1.234041]\n",
      "epoch:23 step:22147 [D loss: 0.932400, acc.: 40.62%] [G loss: 0.676519]\n",
      "epoch:23 step:22148 [D loss: 0.826951, acc.: 54.69%] [G loss: 1.301794]\n",
      "epoch:23 step:22149 [D loss: 0.827896, acc.: 46.09%] [G loss: 1.143745]\n",
      "epoch:23 step:22150 [D loss: 0.864059, acc.: 39.06%] [G loss: 1.139682]\n",
      "epoch:23 step:22151 [D loss: 0.402546, acc.: 76.56%] [G loss: 1.190969]\n",
      "epoch:23 step:22152 [D loss: 0.354593, acc.: 85.94%] [G loss: 1.733557]\n",
      "epoch:23 step:22153 [D loss: 0.754938, acc.: 51.56%] [G loss: 1.395788]\n",
      "epoch:23 step:22154 [D loss: 1.023157, acc.: 27.34%] [G loss: 1.035470]\n",
      "epoch:23 step:22155 [D loss: 0.582235, acc.: 71.88%] [G loss: 1.198468]\n",
      "epoch:23 step:22156 [D loss: 0.722479, acc.: 54.69%] [G loss: 1.603595]\n",
      "epoch:23 step:22157 [D loss: 0.739751, acc.: 54.69%] [G loss: 1.200646]\n",
      "epoch:23 step:22158 [D loss: 0.705859, acc.: 57.81%] [G loss: 1.214029]\n",
      "epoch:23 step:22159 [D loss: 0.733226, acc.: 53.12%] [G loss: 1.519556]\n",
      "epoch:23 step:22160 [D loss: 0.510662, acc.: 78.12%] [G loss: 1.070863]\n",
      "epoch:23 step:22161 [D loss: 0.680306, acc.: 59.38%] [G loss: 0.939581]\n",
      "epoch:23 step:22162 [D loss: 0.690579, acc.: 55.47%] [G loss: 1.091186]\n",
      "epoch:23 step:22163 [D loss: 0.663001, acc.: 60.94%] [G loss: 0.893309]\n",
      "epoch:23 step:22164 [D loss: 0.605690, acc.: 64.06%] [G loss: 1.345912]\n",
      "epoch:23 step:22165 [D loss: 0.686992, acc.: 52.34%] [G loss: 1.204495]\n",
      "epoch:23 step:22166 [D loss: 0.639230, acc.: 61.72%] [G loss: 1.350898]\n",
      "epoch:23 step:22167 [D loss: 0.422847, acc.: 78.91%] [G loss: 1.638913]\n",
      "epoch:23 step:22168 [D loss: 0.437707, acc.: 78.12%] [G loss: 1.569245]\n",
      "epoch:23 step:22169 [D loss: 0.734972, acc.: 53.91%] [G loss: 1.576266]\n",
      "epoch:23 step:22170 [D loss: 0.625465, acc.: 60.16%] [G loss: 1.254583]\n",
      "epoch:23 step:22171 [D loss: 0.609782, acc.: 60.94%] [G loss: 1.255349]\n",
      "epoch:23 step:22172 [D loss: 0.646569, acc.: 59.38%] [G loss: 1.016322]\n",
      "epoch:23 step:22173 [D loss: 0.431008, acc.: 93.75%] [G loss: 1.234942]\n",
      "epoch:23 step:22174 [D loss: 0.470900, acc.: 85.94%] [G loss: 1.097866]\n",
      "epoch:23 step:22175 [D loss: 0.379644, acc.: 92.19%] [G loss: 1.157565]\n",
      "epoch:23 step:22176 [D loss: 0.502698, acc.: 72.66%] [G loss: 1.232077]\n",
      "epoch:23 step:22177 [D loss: 0.593687, acc.: 71.88%] [G loss: 1.040516]\n",
      "epoch:23 step:22178 [D loss: 0.613698, acc.: 62.50%] [G loss: 1.338840]\n",
      "epoch:23 step:22179 [D loss: 0.586888, acc.: 68.75%] [G loss: 1.384481]\n",
      "epoch:23 step:22180 [D loss: 0.412411, acc.: 85.16%] [G loss: 1.107756]\n",
      "epoch:23 step:22181 [D loss: 0.423744, acc.: 89.06%] [G loss: 1.059196]\n",
      "epoch:23 step:22182 [D loss: 0.697586, acc.: 56.25%] [G loss: 0.985152]\n",
      "epoch:23 step:22183 [D loss: 0.305814, acc.: 93.75%] [G loss: 1.278421]\n",
      "epoch:23 step:22184 [D loss: 0.334703, acc.: 91.41%] [G loss: 1.142830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22185 [D loss: 0.359627, acc.: 84.38%] [G loss: 1.321694]\n",
      "epoch:23 step:22186 [D loss: 0.378878, acc.: 87.50%] [G loss: 1.635260]\n",
      "epoch:23 step:22187 [D loss: 0.687540, acc.: 55.47%] [G loss: 1.300284]\n",
      "epoch:23 step:22188 [D loss: 0.714175, acc.: 57.03%] [G loss: 1.334852]\n",
      "epoch:23 step:22189 [D loss: 0.704267, acc.: 57.81%] [G loss: 1.220847]\n",
      "epoch:23 step:22190 [D loss: 0.952247, acc.: 27.34%] [G loss: 1.005080]\n",
      "epoch:23 step:22191 [D loss: 1.044181, acc.: 35.16%] [G loss: 1.167974]\n",
      "epoch:23 step:22192 [D loss: 0.919297, acc.: 41.41%] [G loss: 1.129931]\n",
      "epoch:23 step:22193 [D loss: 0.824929, acc.: 42.19%] [G loss: 0.957949]\n",
      "epoch:23 step:22194 [D loss: 0.685965, acc.: 66.41%] [G loss: 0.852930]\n",
      "epoch:23 step:22195 [D loss: 0.413263, acc.: 84.38%] [G loss: 0.936214]\n",
      "epoch:23 step:22196 [D loss: 0.472516, acc.: 79.69%] [G loss: 1.001397]\n",
      "epoch:23 step:22197 [D loss: 0.359913, acc.: 87.50%] [G loss: 1.075887]\n",
      "epoch:23 step:22198 [D loss: 0.379219, acc.: 84.38%] [G loss: 1.099553]\n",
      "epoch:23 step:22199 [D loss: 0.372071, acc.: 89.06%] [G loss: 0.857535]\n",
      "epoch:23 step:22200 [D loss: 0.447545, acc.: 81.25%] [G loss: 1.245110]\n",
      "epoch:23 step:22201 [D loss: 0.354032, acc.: 89.06%] [G loss: 1.206426]\n",
      "epoch:23 step:22202 [D loss: 0.487073, acc.: 85.16%] [G loss: 1.138858]\n",
      "epoch:23 step:22203 [D loss: 0.978168, acc.: 43.75%] [G loss: 0.690112]\n",
      "epoch:23 step:22204 [D loss: 0.776736, acc.: 42.19%] [G loss: 1.058059]\n",
      "epoch:23 step:22205 [D loss: 0.892056, acc.: 28.91%] [G loss: 0.892606]\n",
      "epoch:23 step:22206 [D loss: 0.573927, acc.: 71.09%] [G loss: 0.784263]\n",
      "epoch:23 step:22207 [D loss: 0.784001, acc.: 41.41%] [G loss: 0.889940]\n",
      "epoch:23 step:22208 [D loss: 0.754522, acc.: 43.75%] [G loss: 0.776913]\n",
      "epoch:23 step:22209 [D loss: 0.756030, acc.: 49.22%] [G loss: 1.068109]\n",
      "epoch:23 step:22210 [D loss: 0.657335, acc.: 63.28%] [G loss: 1.024259]\n",
      "epoch:23 step:22211 [D loss: 0.563085, acc.: 72.66%] [G loss: 1.208495]\n",
      "epoch:23 step:22212 [D loss: 0.556748, acc.: 75.00%] [G loss: 1.203131]\n",
      "epoch:23 step:22213 [D loss: 0.825560, acc.: 42.19%] [G loss: 1.190806]\n",
      "epoch:23 step:22214 [D loss: 0.581179, acc.: 69.53%] [G loss: 1.414009]\n",
      "epoch:23 step:22215 [D loss: 0.621478, acc.: 59.38%] [G loss: 1.317957]\n",
      "epoch:23 step:22216 [D loss: 0.423034, acc.: 80.47%] [G loss: 1.502288]\n",
      "epoch:23 step:22217 [D loss: 0.558612, acc.: 69.53%] [G loss: 1.469810]\n",
      "epoch:23 step:22218 [D loss: 0.587416, acc.: 70.31%] [G loss: 1.310345]\n",
      "epoch:23 step:22219 [D loss: 0.591384, acc.: 75.78%] [G loss: 1.117970]\n",
      "epoch:23 step:22220 [D loss: 0.631901, acc.: 61.72%] [G loss: 1.216240]\n",
      "epoch:23 step:22221 [D loss: 0.574180, acc.: 71.09%] [G loss: 1.108335]\n",
      "epoch:23 step:22222 [D loss: 0.531028, acc.: 75.78%] [G loss: 1.236394]\n",
      "epoch:23 step:22223 [D loss: 0.478166, acc.: 77.34%] [G loss: 1.225528]\n",
      "epoch:23 step:22224 [D loss: 0.616155, acc.: 66.41%] [G loss: 1.080453]\n",
      "epoch:23 step:22225 [D loss: 0.628233, acc.: 61.72%] [G loss: 1.101453]\n",
      "epoch:23 step:22226 [D loss: 0.914607, acc.: 51.56%] [G loss: 0.882867]\n",
      "epoch:23 step:22227 [D loss: 0.749484, acc.: 48.44%] [G loss: 1.005299]\n",
      "epoch:23 step:22228 [D loss: 0.682918, acc.: 59.38%] [G loss: 0.907245]\n",
      "epoch:23 step:22229 [D loss: 0.734571, acc.: 57.03%] [G loss: 0.963368]\n",
      "epoch:23 step:22230 [D loss: 0.652165, acc.: 64.84%] [G loss: 0.866669]\n",
      "epoch:23 step:22231 [D loss: 0.601293, acc.: 63.28%] [G loss: 1.055329]\n",
      "epoch:23 step:22232 [D loss: 0.561527, acc.: 71.88%] [G loss: 1.005706]\n",
      "epoch:23 step:22233 [D loss: 0.637435, acc.: 66.41%] [G loss: 0.835679]\n",
      "epoch:23 step:22234 [D loss: 0.694056, acc.: 57.81%] [G loss: 0.896567]\n",
      "epoch:23 step:22235 [D loss: 0.552957, acc.: 65.62%] [G loss: 1.172834]\n",
      "epoch:23 step:22236 [D loss: 0.534396, acc.: 75.00%] [G loss: 0.974307]\n",
      "epoch:23 step:22237 [D loss: 0.611637, acc.: 69.53%] [G loss: 1.013026]\n",
      "epoch:23 step:22238 [D loss: 0.542827, acc.: 75.78%] [G loss: 1.416409]\n",
      "epoch:23 step:22239 [D loss: 0.618249, acc.: 67.19%] [G loss: 0.850190]\n",
      "epoch:23 step:22240 [D loss: 0.860976, acc.: 39.06%] [G loss: 1.099851]\n",
      "epoch:23 step:22241 [D loss: 0.598138, acc.: 67.19%] [G loss: 0.945366]\n",
      "epoch:23 step:22242 [D loss: 0.664694, acc.: 58.59%] [G loss: 1.057048]\n",
      "epoch:23 step:22243 [D loss: 0.621339, acc.: 63.28%] [G loss: 0.988011]\n",
      "epoch:23 step:22244 [D loss: 0.610527, acc.: 67.97%] [G loss: 1.058235]\n",
      "epoch:23 step:22245 [D loss: 0.542218, acc.: 76.56%] [G loss: 0.936690]\n",
      "epoch:23 step:22246 [D loss: 0.748529, acc.: 52.34%] [G loss: 0.737657]\n",
      "epoch:23 step:22247 [D loss: 0.425800, acc.: 85.16%] [G loss: 1.113120]\n",
      "epoch:23 step:22248 [D loss: 0.314810, acc.: 91.41%] [G loss: 1.316692]\n",
      "epoch:23 step:22249 [D loss: 0.503860, acc.: 79.69%] [G loss: 1.185551]\n",
      "epoch:23 step:22250 [D loss: 0.487751, acc.: 85.16%] [G loss: 1.258248]\n",
      "epoch:23 step:22251 [D loss: 0.546790, acc.: 70.31%] [G loss: 1.322204]\n",
      "epoch:23 step:22252 [D loss: 0.374472, acc.: 85.16%] [G loss: 1.302844]\n",
      "epoch:23 step:22253 [D loss: 0.415236, acc.: 86.72%] [G loss: 1.343122]\n",
      "epoch:23 step:22254 [D loss: 0.490941, acc.: 78.12%] [G loss: 1.607983]\n",
      "epoch:23 step:22255 [D loss: 0.438144, acc.: 84.38%] [G loss: 1.382056]\n",
      "epoch:23 step:22256 [D loss: 0.559045, acc.: 69.53%] [G loss: 1.723505]\n",
      "epoch:23 step:22257 [D loss: 0.255764, acc.: 92.97%] [G loss: 1.679974]\n",
      "epoch:23 step:22258 [D loss: 0.176991, acc.: 96.88%] [G loss: 1.551825]\n",
      "epoch:23 step:22259 [D loss: 0.218142, acc.: 93.75%] [G loss: 1.678291]\n",
      "epoch:23 step:22260 [D loss: 0.315462, acc.: 85.16%] [G loss: 1.923114]\n",
      "epoch:23 step:22261 [D loss: 1.109745, acc.: 44.53%] [G loss: 1.587480]\n",
      "epoch:23 step:22262 [D loss: 0.904454, acc.: 45.31%] [G loss: 1.219668]\n",
      "epoch:23 step:22263 [D loss: 0.455843, acc.: 77.34%] [G loss: 1.459016]\n",
      "epoch:23 step:22264 [D loss: 0.207612, acc.: 96.09%] [G loss: 1.704291]\n",
      "epoch:23 step:22265 [D loss: 0.192178, acc.: 97.66%] [G loss: 1.577099]\n",
      "epoch:23 step:22266 [D loss: 0.740888, acc.: 51.56%] [G loss: 1.050722]\n",
      "epoch:23 step:22267 [D loss: 1.153562, acc.: 17.19%] [G loss: 1.401574]\n",
      "epoch:23 step:22268 [D loss: 0.736378, acc.: 55.47%] [G loss: 1.011368]\n",
      "epoch:23 step:22269 [D loss: 0.822303, acc.: 49.22%] [G loss: 1.215611]\n",
      "epoch:23 step:22270 [D loss: 0.703113, acc.: 55.47%] [G loss: 1.058061]\n",
      "epoch:23 step:22271 [D loss: 0.642260, acc.: 59.38%] [G loss: 1.065088]\n",
      "epoch:23 step:22272 [D loss: 0.758058, acc.: 51.56%] [G loss: 1.112041]\n",
      "epoch:23 step:22273 [D loss: 0.454140, acc.: 80.47%] [G loss: 1.120125]\n",
      "epoch:23 step:22274 [D loss: 0.426093, acc.: 84.38%] [G loss: 1.089578]\n",
      "epoch:23 step:22275 [D loss: 0.909198, acc.: 28.12%] [G loss: 1.172778]\n",
      "epoch:23 step:22276 [D loss: 0.718473, acc.: 56.25%] [G loss: 1.145812]\n",
      "epoch:23 step:22277 [D loss: 0.671420, acc.: 62.50%] [G loss: 1.151789]\n",
      "epoch:23 step:22278 [D loss: 0.345144, acc.: 91.41%] [G loss: 1.077248]\n",
      "epoch:23 step:22279 [D loss: 0.287339, acc.: 90.62%] [G loss: 0.946736]\n",
      "epoch:23 step:22280 [D loss: 0.210121, acc.: 96.09%] [G loss: 1.325164]\n",
      "epoch:23 step:22281 [D loss: 0.318686, acc.: 90.62%] [G loss: 1.437021]\n",
      "epoch:23 step:22282 [D loss: 0.250956, acc.: 97.66%] [G loss: 1.394091]\n",
      "epoch:23 step:22283 [D loss: 0.420788, acc.: 75.78%] [G loss: 1.330879]\n",
      "epoch:23 step:22284 [D loss: 0.203635, acc.: 99.22%] [G loss: 1.796946]\n",
      "epoch:23 step:22285 [D loss: 0.774654, acc.: 51.56%] [G loss: 1.648358]\n",
      "epoch:23 step:22286 [D loss: 0.802137, acc.: 54.69%] [G loss: 1.465812]\n",
      "epoch:23 step:22287 [D loss: 0.661007, acc.: 60.94%] [G loss: 1.216636]\n",
      "epoch:23 step:22288 [D loss: 0.719177, acc.: 51.56%] [G loss: 1.224123]\n",
      "epoch:23 step:22289 [D loss: 0.528596, acc.: 77.34%] [G loss: 1.329898]\n",
      "epoch:23 step:22290 [D loss: 0.639159, acc.: 64.84%] [G loss: 1.073548]\n",
      "epoch:23 step:22291 [D loss: 0.462414, acc.: 87.50%] [G loss: 0.811419]\n",
      "epoch:23 step:22292 [D loss: 0.726590, acc.: 50.00%] [G loss: 1.074295]\n",
      "epoch:23 step:22293 [D loss: 0.734010, acc.: 53.12%] [G loss: 1.042648]\n",
      "epoch:23 step:22294 [D loss: 0.750013, acc.: 47.66%] [G loss: 0.939455]\n",
      "epoch:23 step:22295 [D loss: 0.624163, acc.: 64.84%] [G loss: 0.905490]\n",
      "epoch:23 step:22296 [D loss: 0.329668, acc.: 94.53%] [G loss: 1.057998]\n",
      "epoch:23 step:22297 [D loss: 0.461935, acc.: 84.38%] [G loss: 1.202510]\n",
      "epoch:23 step:22298 [D loss: 0.492121, acc.: 82.03%] [G loss: 1.006100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22299 [D loss: 0.753294, acc.: 50.78%] [G loss: 0.765874]\n",
      "epoch:23 step:22300 [D loss: 0.718547, acc.: 55.47%] [G loss: 1.028680]\n",
      "epoch:23 step:22301 [D loss: 0.715076, acc.: 54.69%] [G loss: 0.858854]\n",
      "epoch:23 step:22302 [D loss: 0.747726, acc.: 51.56%] [G loss: 1.011576]\n",
      "epoch:23 step:22303 [D loss: 0.687762, acc.: 54.69%] [G loss: 1.078161]\n",
      "epoch:23 step:22304 [D loss: 0.627065, acc.: 67.19%] [G loss: 1.132114]\n",
      "epoch:23 step:22305 [D loss: 0.329388, acc.: 91.41%] [G loss: 1.058029]\n",
      "epoch:23 step:22306 [D loss: 0.256793, acc.: 92.97%] [G loss: 1.259771]\n",
      "epoch:23 step:22307 [D loss: 0.293349, acc.: 96.88%] [G loss: 1.268564]\n",
      "epoch:23 step:22308 [D loss: 0.304721, acc.: 96.09%] [G loss: 1.323326]\n",
      "epoch:23 step:22309 [D loss: 0.639642, acc.: 63.28%] [G loss: 1.092533]\n",
      "epoch:23 step:22310 [D loss: 0.823869, acc.: 50.78%] [G loss: 0.990049]\n",
      "epoch:23 step:22311 [D loss: 0.895282, acc.: 28.91%] [G loss: 0.934761]\n",
      "epoch:23 step:22312 [D loss: 0.687836, acc.: 60.94%] [G loss: 1.006494]\n",
      "epoch:23 step:22313 [D loss: 0.641420, acc.: 60.94%] [G loss: 0.711016]\n",
      "epoch:23 step:22314 [D loss: 0.536449, acc.: 77.34%] [G loss: 0.456653]\n",
      "epoch:23 step:22315 [D loss: 0.789348, acc.: 60.16%] [G loss: 0.833844]\n",
      "epoch:23 step:22316 [D loss: 0.848014, acc.: 39.84%] [G loss: 0.925987]\n",
      "epoch:23 step:22317 [D loss: 0.843444, acc.: 40.62%] [G loss: 0.914524]\n",
      "epoch:23 step:22318 [D loss: 0.736630, acc.: 53.91%] [G loss: 0.972631]\n",
      "epoch:23 step:22319 [D loss: 0.556450, acc.: 75.00%] [G loss: 1.283118]\n",
      "epoch:23 step:22320 [D loss: 0.632809, acc.: 59.38%] [G loss: 1.318084]\n",
      "epoch:23 step:22321 [D loss: 0.654280, acc.: 57.81%] [G loss: 1.171513]\n",
      "epoch:23 step:22322 [D loss: 0.743108, acc.: 54.69%] [G loss: 1.258722]\n",
      "epoch:23 step:22323 [D loss: 0.864354, acc.: 30.47%] [G loss: 1.150067]\n",
      "epoch:23 step:22324 [D loss: 0.601830, acc.: 68.75%] [G loss: 1.249629]\n",
      "epoch:23 step:22325 [D loss: 0.330332, acc.: 97.66%] [G loss: 1.135272]\n",
      "epoch:23 step:22326 [D loss: 0.318250, acc.: 94.53%] [G loss: 1.190533]\n",
      "epoch:23 step:22327 [D loss: 0.536440, acc.: 67.97%] [G loss: 1.282598]\n",
      "epoch:23 step:22328 [D loss: 0.461850, acc.: 88.28%] [G loss: 1.314904]\n",
      "epoch:23 step:22329 [D loss: 0.587766, acc.: 64.84%] [G loss: 1.216142]\n",
      "epoch:23 step:22330 [D loss: 0.732568, acc.: 56.25%] [G loss: 1.042850]\n",
      "epoch:23 step:22331 [D loss: 0.524664, acc.: 75.00%] [G loss: 1.121457]\n",
      "epoch:23 step:22332 [D loss: 0.398995, acc.: 89.06%] [G loss: 1.103319]\n",
      "epoch:23 step:22333 [D loss: 0.555833, acc.: 71.88%] [G loss: 0.959399]\n",
      "epoch:23 step:22334 [D loss: 0.667614, acc.: 59.38%] [G loss: 0.982898]\n",
      "epoch:23 step:22335 [D loss: 0.668350, acc.: 61.72%] [G loss: 0.894409]\n",
      "epoch:23 step:22336 [D loss: 0.640171, acc.: 60.16%] [G loss: 0.934222]\n",
      "epoch:23 step:22337 [D loss: 0.803345, acc.: 50.00%] [G loss: 1.042158]\n",
      "epoch:23 step:22338 [D loss: 0.671516, acc.: 66.41%] [G loss: 1.052980]\n",
      "epoch:23 step:22339 [D loss: 0.653298, acc.: 67.97%] [G loss: 1.089943]\n",
      "epoch:23 step:22340 [D loss: 0.654882, acc.: 63.28%] [G loss: 0.989719]\n",
      "epoch:23 step:22341 [D loss: 0.747295, acc.: 43.75%] [G loss: 0.948793]\n",
      "epoch:23 step:22342 [D loss: 0.467676, acc.: 77.34%] [G loss: 0.988493]\n",
      "epoch:23 step:22343 [D loss: 0.350458, acc.: 90.62%] [G loss: 1.027632]\n",
      "epoch:23 step:22344 [D loss: 0.546429, acc.: 70.31%] [G loss: 1.132963]\n",
      "epoch:23 step:22345 [D loss: 0.386279, acc.: 91.41%] [G loss: 0.936309]\n",
      "epoch:23 step:22346 [D loss: 0.686021, acc.: 58.59%] [G loss: 1.112173]\n",
      "epoch:23 step:22347 [D loss: 0.480066, acc.: 81.25%] [G loss: 1.090726]\n",
      "epoch:23 step:22348 [D loss: 0.549550, acc.: 75.00%] [G loss: 1.205057]\n",
      "epoch:23 step:22349 [D loss: 0.497887, acc.: 81.25%] [G loss: 1.088702]\n",
      "epoch:23 step:22350 [D loss: 0.611941, acc.: 65.62%] [G loss: 1.187197]\n",
      "epoch:23 step:22351 [D loss: 0.574044, acc.: 69.53%] [G loss: 1.080794]\n",
      "epoch:23 step:22352 [D loss: 0.468425, acc.: 85.16%] [G loss: 1.038010]\n",
      "epoch:23 step:22353 [D loss: 0.266756, acc.: 88.28%] [G loss: 1.280563]\n",
      "epoch:23 step:22354 [D loss: 0.479869, acc.: 78.91%] [G loss: 1.305618]\n",
      "epoch:23 step:22355 [D loss: 0.352388, acc.: 89.84%] [G loss: 1.240446]\n",
      "epoch:23 step:22356 [D loss: 0.446447, acc.: 85.94%] [G loss: 1.271301]\n",
      "epoch:23 step:22357 [D loss: 0.360572, acc.: 84.38%] [G loss: 1.178861]\n",
      "epoch:23 step:22358 [D loss: 0.715005, acc.: 56.25%] [G loss: 1.239533]\n",
      "epoch:23 step:22359 [D loss: 0.451248, acc.: 85.94%] [G loss: 1.218395]\n",
      "epoch:23 step:22360 [D loss: 0.482537, acc.: 82.03%] [G loss: 1.211856]\n",
      "epoch:23 step:22361 [D loss: 0.503480, acc.: 83.59%] [G loss: 1.197413]\n",
      "epoch:23 step:22362 [D loss: 0.681159, acc.: 60.94%] [G loss: 1.027953]\n",
      "epoch:23 step:22363 [D loss: 0.802365, acc.: 42.19%] [G loss: 0.965481]\n",
      "epoch:23 step:22364 [D loss: 0.672053, acc.: 55.47%] [G loss: 0.881257]\n",
      "epoch:23 step:22365 [D loss: 0.668956, acc.: 58.59%] [G loss: 0.936267]\n",
      "epoch:23 step:22366 [D loss: 0.346474, acc.: 85.16%] [G loss: 0.996962]\n",
      "epoch:23 step:22367 [D loss: 0.421817, acc.: 89.84%] [G loss: 1.041644]\n",
      "epoch:23 step:22368 [D loss: 0.667446, acc.: 56.25%] [G loss: 1.363324]\n",
      "epoch:23 step:22369 [D loss: 0.605207, acc.: 64.84%] [G loss: 0.946596]\n",
      "epoch:23 step:22370 [D loss: 0.564678, acc.: 71.09%] [G loss: 0.996647]\n",
      "epoch:23 step:22371 [D loss: 0.931892, acc.: 29.69%] [G loss: 0.856663]\n",
      "epoch:23 step:22372 [D loss: 0.666269, acc.: 65.62%] [G loss: 0.961077]\n",
      "epoch:23 step:22373 [D loss: 0.835772, acc.: 44.53%] [G loss: 1.116357]\n",
      "epoch:23 step:22374 [D loss: 0.699175, acc.: 53.91%] [G loss: 0.858558]\n",
      "epoch:23 step:22375 [D loss: 0.596007, acc.: 69.53%] [G loss: 0.898139]\n",
      "epoch:23 step:22376 [D loss: 0.565526, acc.: 68.75%] [G loss: 1.067404]\n",
      "epoch:23 step:22377 [D loss: 0.769474, acc.: 47.66%] [G loss: 1.206430]\n",
      "epoch:23 step:22378 [D loss: 0.708345, acc.: 54.69%] [G loss: 0.984905]\n",
      "epoch:23 step:22379 [D loss: 0.682303, acc.: 57.81%] [G loss: 0.852784]\n",
      "epoch:23 step:22380 [D loss: 0.646892, acc.: 58.59%] [G loss: 1.180356]\n",
      "epoch:23 step:22381 [D loss: 0.477243, acc.: 82.03%] [G loss: 1.212592]\n",
      "epoch:23 step:22382 [D loss: 0.445284, acc.: 82.03%] [G loss: 1.047685]\n",
      "epoch:23 step:22383 [D loss: 0.438970, acc.: 72.66%] [G loss: 1.239613]\n",
      "epoch:23 step:22384 [D loss: 0.360919, acc.: 83.59%] [G loss: 1.223250]\n",
      "epoch:23 step:22385 [D loss: 0.745524, acc.: 55.47%] [G loss: 1.350985]\n",
      "epoch:23 step:22386 [D loss: 0.654418, acc.: 59.38%] [G loss: 1.298646]\n",
      "epoch:23 step:22387 [D loss: 0.787533, acc.: 39.84%] [G loss: 1.138144]\n",
      "epoch:23 step:22388 [D loss: 0.964256, acc.: 28.91%] [G loss: 1.065845]\n",
      "epoch:23 step:22389 [D loss: 0.697521, acc.: 51.56%] [G loss: 1.013609]\n",
      "epoch:23 step:22390 [D loss: 0.590110, acc.: 68.75%] [G loss: 0.857471]\n",
      "epoch:23 step:22391 [D loss: 0.744072, acc.: 52.34%] [G loss: 1.159620]\n",
      "epoch:23 step:22392 [D loss: 0.610297, acc.: 67.19%] [G loss: 1.136449]\n",
      "epoch:23 step:22393 [D loss: 0.389222, acc.: 87.50%] [G loss: 1.063934]\n",
      "epoch:23 step:22394 [D loss: 0.624905, acc.: 64.84%] [G loss: 0.975063]\n",
      "epoch:23 step:22395 [D loss: 0.507818, acc.: 76.56%] [G loss: 1.046616]\n",
      "epoch:23 step:22396 [D loss: 0.436923, acc.: 76.56%] [G loss: 1.316939]\n",
      "epoch:23 step:22397 [D loss: 0.734916, acc.: 55.47%] [G loss: 1.009550]\n",
      "epoch:23 step:22398 [D loss: 0.474694, acc.: 78.91%] [G loss: 0.994814]\n",
      "epoch:23 step:22399 [D loss: 0.718477, acc.: 50.78%] [G loss: 0.949376]\n",
      "epoch:23 step:22400 [D loss: 0.536137, acc.: 75.00%] [G loss: 0.942954]\n",
      "epoch:23 step:22401 [D loss: 0.536598, acc.: 75.00%] [G loss: 0.967905]\n",
      "epoch:23 step:22402 [D loss: 0.382709, acc.: 77.34%] [G loss: 1.084880]\n",
      "epoch:23 step:22403 [D loss: 0.382787, acc.: 72.66%] [G loss: 1.169486]\n",
      "epoch:23 step:22404 [D loss: 0.394011, acc.: 85.94%] [G loss: 1.223758]\n",
      "epoch:23 step:22405 [D loss: 0.244253, acc.: 95.31%] [G loss: 1.423437]\n",
      "epoch:23 step:22406 [D loss: 0.394234, acc.: 89.06%] [G loss: 1.467347]\n",
      "epoch:23 step:22407 [D loss: 0.778619, acc.: 53.12%] [G loss: 1.153157]\n",
      "epoch:23 step:22408 [D loss: 0.312452, acc.: 93.75%] [G loss: 1.199017]\n",
      "epoch:23 step:22409 [D loss: 0.579334, acc.: 64.84%] [G loss: 1.242997]\n",
      "epoch:23 step:22410 [D loss: 0.408287, acc.: 89.84%] [G loss: 1.335466]\n",
      "epoch:23 step:22411 [D loss: 0.410090, acc.: 84.38%] [G loss: 1.262074]\n",
      "epoch:23 step:22412 [D loss: 0.678729, acc.: 56.25%] [G loss: 1.234662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22413 [D loss: 0.762008, acc.: 46.09%] [G loss: 1.113060]\n",
      "epoch:23 step:22414 [D loss: 0.698424, acc.: 53.12%] [G loss: 1.122045]\n",
      "epoch:23 step:22415 [D loss: 0.635710, acc.: 57.03%] [G loss: 1.238075]\n",
      "epoch:23 step:22416 [D loss: 0.721921, acc.: 56.25%] [G loss: 1.241112]\n",
      "epoch:23 step:22417 [D loss: 0.594410, acc.: 69.53%] [G loss: 1.191953]\n",
      "epoch:23 step:22418 [D loss: 0.541050, acc.: 74.22%] [G loss: 1.081408]\n",
      "epoch:23 step:22419 [D loss: 0.705262, acc.: 55.47%] [G loss: 0.698154]\n",
      "epoch:23 step:22420 [D loss: 0.667404, acc.: 61.72%] [G loss: 1.029246]\n",
      "epoch:23 step:22421 [D loss: 0.635920, acc.: 61.72%] [G loss: 1.047050]\n",
      "epoch:23 step:22422 [D loss: 0.667579, acc.: 58.59%] [G loss: 1.147102]\n",
      "epoch:23 step:22423 [D loss: 0.699487, acc.: 55.47%] [G loss: 1.222590]\n",
      "epoch:23 step:22424 [D loss: 0.847571, acc.: 39.06%] [G loss: 0.879604]\n",
      "epoch:23 step:22425 [D loss: 0.748574, acc.: 53.12%] [G loss: 1.302467]\n",
      "epoch:23 step:22426 [D loss: 0.694095, acc.: 54.69%] [G loss: 1.081087]\n",
      "epoch:23 step:22427 [D loss: 0.618269, acc.: 64.84%] [G loss: 1.074331]\n",
      "epoch:23 step:22428 [D loss: 0.575645, acc.: 71.09%] [G loss: 1.329855]\n",
      "epoch:23 step:22429 [D loss: 0.267007, acc.: 92.19%] [G loss: 1.361882]\n",
      "epoch:23 step:22430 [D loss: 0.589696, acc.: 68.75%] [G loss: 1.402949]\n",
      "epoch:23 step:22431 [D loss: 0.750483, acc.: 53.12%] [G loss: 1.230623]\n",
      "epoch:23 step:22432 [D loss: 0.730434, acc.: 47.66%] [G loss: 1.067994]\n",
      "epoch:23 step:22433 [D loss: 0.733696, acc.: 47.66%] [G loss: 1.033235]\n",
      "epoch:23 step:22434 [D loss: 0.776391, acc.: 46.88%] [G loss: 0.973037]\n",
      "epoch:23 step:22435 [D loss: 0.480283, acc.: 78.12%] [G loss: 1.087628]\n",
      "epoch:23 step:22436 [D loss: 0.416803, acc.: 89.84%] [G loss: 1.151857]\n",
      "epoch:23 step:22437 [D loss: 0.572416, acc.: 71.88%] [G loss: 0.887326]\n",
      "epoch:23 step:22438 [D loss: 0.349434, acc.: 87.50%] [G loss: 0.989197]\n",
      "epoch:23 step:22439 [D loss: 0.816806, acc.: 38.28%] [G loss: 0.890991]\n",
      "epoch:23 step:22440 [D loss: 0.688321, acc.: 57.81%] [G loss: 0.971995]\n",
      "epoch:23 step:22441 [D loss: 0.750800, acc.: 46.09%] [G loss: 0.740154]\n",
      "epoch:23 step:22442 [D loss: 0.666168, acc.: 56.25%] [G loss: 1.009526]\n",
      "epoch:23 step:22443 [D loss: 0.359980, acc.: 85.94%] [G loss: 1.230415]\n",
      "epoch:23 step:22444 [D loss: 0.314508, acc.: 97.66%] [G loss: 1.299664]\n",
      "epoch:23 step:22445 [D loss: 0.447911, acc.: 82.03%] [G loss: 1.482703]\n",
      "epoch:23 step:22446 [D loss: 0.268917, acc.: 96.88%] [G loss: 1.689235]\n",
      "epoch:23 step:22447 [D loss: 0.254493, acc.: 97.66%] [G loss: 1.701655]\n",
      "epoch:23 step:22448 [D loss: 0.235550, acc.: 96.09%] [G loss: 1.757174]\n",
      "epoch:23 step:22449 [D loss: 0.142786, acc.: 99.22%] [G loss: 2.054414]\n",
      "epoch:23 step:22450 [D loss: 0.086585, acc.: 99.22%] [G loss: 1.899000]\n",
      "epoch:23 step:22451 [D loss: 0.124315, acc.: 99.22%] [G loss: 2.471282]\n",
      "epoch:23 step:22452 [D loss: 0.145199, acc.: 99.22%] [G loss: 2.233674]\n",
      "epoch:23 step:22453 [D loss: 0.425917, acc.: 82.81%] [G loss: 1.539877]\n",
      "epoch:23 step:22454 [D loss: 0.165455, acc.: 97.66%] [G loss: 1.688003]\n",
      "epoch:23 step:22455 [D loss: 1.313349, acc.: 33.59%] [G loss: 1.341560]\n",
      "epoch:23 step:22456 [D loss: 1.084942, acc.: 31.25%] [G loss: 1.033799]\n",
      "epoch:23 step:22457 [D loss: 0.796779, acc.: 39.84%] [G loss: 0.713210]\n",
      "epoch:23 step:22458 [D loss: 0.647489, acc.: 61.72%] [G loss: 0.841543]\n",
      "epoch:23 step:22459 [D loss: 0.523896, acc.: 68.75%] [G loss: 1.325351]\n",
      "epoch:23 step:22460 [D loss: 0.263411, acc.: 89.06%] [G loss: 1.477069]\n",
      "epoch:23 step:22461 [D loss: 0.997845, acc.: 37.50%] [G loss: 1.214227]\n",
      "epoch:23 step:22462 [D loss: 0.202628, acc.: 96.09%] [G loss: 1.345256]\n",
      "epoch:23 step:22463 [D loss: 0.221921, acc.: 96.09%] [G loss: 1.139416]\n",
      "epoch:23 step:22464 [D loss: 0.439497, acc.: 84.38%] [G loss: 1.272817]\n",
      "epoch:23 step:22465 [D loss: 0.654198, acc.: 64.06%] [G loss: 1.400586]\n",
      "epoch:23 step:22466 [D loss: 0.778841, acc.: 54.69%] [G loss: 1.285570]\n",
      "epoch:23 step:22467 [D loss: 0.832214, acc.: 44.53%] [G loss: 1.254622]\n",
      "epoch:23 step:22468 [D loss: 0.835552, acc.: 40.62%] [G loss: 1.162017]\n",
      "epoch:23 step:22469 [D loss: 0.478748, acc.: 78.12%] [G loss: 1.133358]\n",
      "epoch:23 step:22470 [D loss: 0.300314, acc.: 89.06%] [G loss: 0.932323]\n",
      "epoch:23 step:22471 [D loss: 0.761953, acc.: 48.44%] [G loss: 0.690059]\n",
      "epoch:23 step:22472 [D loss: 0.658347, acc.: 59.38%] [G loss: 0.873963]\n",
      "epoch:23 step:22473 [D loss: 0.526017, acc.: 78.12%] [G loss: 1.048412]\n",
      "epoch:23 step:22474 [D loss: 0.412188, acc.: 87.50%] [G loss: 1.315548]\n",
      "epoch:23 step:22475 [D loss: 0.380670, acc.: 78.91%] [G loss: 1.269925]\n",
      "epoch:23 step:22476 [D loss: 0.320143, acc.: 89.06%] [G loss: 1.451537]\n",
      "epoch:23 step:22477 [D loss: 0.203877, acc.: 93.75%] [G loss: 1.467597]\n",
      "epoch:23 step:22478 [D loss: 0.277899, acc.: 83.59%] [G loss: 1.620242]\n",
      "epoch:23 step:22479 [D loss: 0.678175, acc.: 62.50%] [G loss: 1.207404]\n",
      "epoch:23 step:22480 [D loss: 0.358214, acc.: 88.28%] [G loss: 1.213530]\n",
      "epoch:23 step:22481 [D loss: 0.637365, acc.: 59.38%] [G loss: 1.295720]\n",
      "epoch:23 step:22482 [D loss: 0.631357, acc.: 65.62%] [G loss: 1.142586]\n",
      "epoch:23 step:22483 [D loss: 0.699001, acc.: 57.03%] [G loss: 1.191518]\n",
      "epoch:23 step:22484 [D loss: 0.458247, acc.: 75.00%] [G loss: 1.488319]\n",
      "epoch:23 step:22485 [D loss: 0.259127, acc.: 89.84%] [G loss: 1.426165]\n",
      "epoch:23 step:22486 [D loss: 0.501118, acc.: 78.12%] [G loss: 1.352843]\n",
      "epoch:23 step:22487 [D loss: 0.259179, acc.: 90.62%] [G loss: 1.658282]\n",
      "epoch:23 step:22488 [D loss: 0.133311, acc.: 98.44%] [G loss: 1.453291]\n",
      "epoch:24 step:22489 [D loss: 0.862207, acc.: 51.56%] [G loss: 1.375402]\n",
      "epoch:24 step:22490 [D loss: 0.796379, acc.: 51.56%] [G loss: 0.912522]\n",
      "epoch:24 step:22491 [D loss: 1.319231, acc.: 35.94%] [G loss: 1.358585]\n",
      "epoch:24 step:22492 [D loss: 0.766351, acc.: 44.53%] [G loss: 1.387119]\n",
      "epoch:24 step:22493 [D loss: 0.775946, acc.: 49.22%] [G loss: 1.492871]\n",
      "epoch:24 step:22494 [D loss: 0.690015, acc.: 62.50%] [G loss: 1.048634]\n",
      "epoch:24 step:22495 [D loss: 0.703487, acc.: 57.03%] [G loss: 1.389868]\n",
      "epoch:24 step:22496 [D loss: 0.679974, acc.: 56.25%] [G loss: 1.240516]\n",
      "epoch:24 step:22497 [D loss: 0.658085, acc.: 65.62%] [G loss: 0.875992]\n",
      "epoch:24 step:22498 [D loss: 0.700799, acc.: 57.81%] [G loss: 0.988328]\n",
      "epoch:24 step:22499 [D loss: 0.584390, acc.: 71.88%] [G loss: 0.912978]\n",
      "epoch:24 step:22500 [D loss: 0.664068, acc.: 67.19%] [G loss: 0.881455]\n",
      "epoch:24 step:22501 [D loss: 0.657276, acc.: 61.72%] [G loss: 0.845549]\n",
      "epoch:24 step:22502 [D loss: 0.631434, acc.: 63.28%] [G loss: 0.815879]\n",
      "epoch:24 step:22503 [D loss: 0.779813, acc.: 49.22%] [G loss: 0.845892]\n",
      "epoch:24 step:22504 [D loss: 0.895622, acc.: 46.88%] [G loss: 1.694301]\n",
      "epoch:24 step:22505 [D loss: 0.731579, acc.: 46.09%] [G loss: 1.198740]\n",
      "epoch:24 step:22506 [D loss: 0.723587, acc.: 46.88%] [G loss: 1.001291]\n",
      "epoch:24 step:22507 [D loss: 0.706431, acc.: 56.25%] [G loss: 1.014611]\n",
      "epoch:24 step:22508 [D loss: 0.679742, acc.: 57.03%] [G loss: 1.108683]\n",
      "epoch:24 step:22509 [D loss: 0.809636, acc.: 44.53%] [G loss: 1.262708]\n",
      "epoch:24 step:22510 [D loss: 0.743480, acc.: 50.00%] [G loss: 1.039409]\n",
      "epoch:24 step:22511 [D loss: 0.740989, acc.: 50.78%] [G loss: 1.061874]\n",
      "epoch:24 step:22512 [D loss: 0.667434, acc.: 56.25%] [G loss: 1.415819]\n",
      "epoch:24 step:22513 [D loss: 0.654812, acc.: 59.38%] [G loss: 0.995018]\n",
      "epoch:24 step:22514 [D loss: 0.635708, acc.: 64.06%] [G loss: 0.930746]\n",
      "epoch:24 step:22515 [D loss: 0.435379, acc.: 83.59%] [G loss: 1.088787]\n",
      "epoch:24 step:22516 [D loss: 0.684160, acc.: 53.91%] [G loss: 1.005903]\n",
      "epoch:24 step:22517 [D loss: 0.581662, acc.: 68.75%] [G loss: 0.989176]\n",
      "epoch:24 step:22518 [D loss: 0.557128, acc.: 71.09%] [G loss: 1.305948]\n",
      "epoch:24 step:22519 [D loss: 0.496955, acc.: 78.91%] [G loss: 1.140455]\n",
      "epoch:24 step:22520 [D loss: 0.376865, acc.: 92.97%] [G loss: 1.610526]\n",
      "epoch:24 step:22521 [D loss: 0.370255, acc.: 92.97%] [G loss: 1.480673]\n",
      "epoch:24 step:22522 [D loss: 0.418557, acc.: 85.94%] [G loss: 1.318323]\n",
      "epoch:24 step:22523 [D loss: 0.333615, acc.: 94.53%] [G loss: 1.920109]\n",
      "epoch:24 step:22524 [D loss: 0.354659, acc.: 89.06%] [G loss: 1.077851]\n",
      "epoch:24 step:22525 [D loss: 0.781446, acc.: 49.22%] [G loss: 0.986246]\n",
      "epoch:24 step:22526 [D loss: 1.184952, acc.: 37.50%] [G loss: 1.117478]\n",
      "epoch:24 step:22527 [D loss: 0.905347, acc.: 39.84%] [G loss: 0.924954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22528 [D loss: 0.648561, acc.: 60.94%] [G loss: 0.851750]\n",
      "epoch:24 step:22529 [D loss: 0.680010, acc.: 56.25%] [G loss: 0.985180]\n",
      "epoch:24 step:22530 [D loss: 0.597604, acc.: 73.44%] [G loss: 0.981399]\n",
      "epoch:24 step:22531 [D loss: 0.543950, acc.: 82.81%] [G loss: 0.971447]\n",
      "epoch:24 step:22532 [D loss: 0.597964, acc.: 71.88%] [G loss: 0.826470]\n",
      "epoch:24 step:22533 [D loss: 0.644534, acc.: 65.62%] [G loss: 0.959180]\n",
      "epoch:24 step:22534 [D loss: 0.682856, acc.: 64.06%] [G loss: 0.929673]\n",
      "epoch:24 step:22535 [D loss: 0.650254, acc.: 61.72%] [G loss: 0.825275]\n",
      "epoch:24 step:22536 [D loss: 0.638378, acc.: 60.94%] [G loss: 0.964135]\n",
      "epoch:24 step:22537 [D loss: 0.627548, acc.: 69.53%] [G loss: 0.879472]\n",
      "epoch:24 step:22538 [D loss: 0.543258, acc.: 77.34%] [G loss: 0.871408]\n",
      "epoch:24 step:22539 [D loss: 0.764104, acc.: 46.88%] [G loss: 0.892535]\n",
      "epoch:24 step:22540 [D loss: 0.657395, acc.: 62.50%] [G loss: 0.869413]\n",
      "epoch:24 step:22541 [D loss: 0.595324, acc.: 69.53%] [G loss: 1.004709]\n",
      "epoch:24 step:22542 [D loss: 0.718459, acc.: 50.00%] [G loss: 0.912812]\n",
      "epoch:24 step:22543 [D loss: 0.579827, acc.: 68.75%] [G loss: 0.933413]\n",
      "epoch:24 step:22544 [D loss: 0.600378, acc.: 71.09%] [G loss: 1.022541]\n",
      "epoch:24 step:22545 [D loss: 0.416732, acc.: 87.50%] [G loss: 0.882484]\n",
      "epoch:24 step:22546 [D loss: 0.638097, acc.: 62.50%] [G loss: 1.028449]\n",
      "epoch:24 step:22547 [D loss: 0.519290, acc.: 75.78%] [G loss: 0.954847]\n",
      "epoch:24 step:22548 [D loss: 0.602355, acc.: 75.00%] [G loss: 1.062980]\n",
      "epoch:24 step:22549 [D loss: 0.660011, acc.: 60.94%] [G loss: 1.055709]\n",
      "epoch:24 step:22550 [D loss: 0.646521, acc.: 67.97%] [G loss: 0.926739]\n",
      "epoch:24 step:22551 [D loss: 0.576591, acc.: 69.53%] [G loss: 0.780852]\n",
      "epoch:24 step:22552 [D loss: 0.747237, acc.: 50.78%] [G loss: 0.994644]\n",
      "epoch:24 step:22553 [D loss: 0.718255, acc.: 50.00%] [G loss: 0.865240]\n",
      "epoch:24 step:22554 [D loss: 0.637894, acc.: 63.28%] [G loss: 0.833955]\n",
      "epoch:24 step:22555 [D loss: 0.685410, acc.: 58.59%] [G loss: 0.926841]\n",
      "epoch:24 step:22556 [D loss: 0.615526, acc.: 67.19%] [G loss: 0.996699]\n",
      "epoch:24 step:22557 [D loss: 0.508109, acc.: 77.34%] [G loss: 0.926015]\n",
      "epoch:24 step:22558 [D loss: 0.601477, acc.: 69.53%] [G loss: 0.953210]\n",
      "epoch:24 step:22559 [D loss: 0.348134, acc.: 78.12%] [G loss: 1.064753]\n",
      "epoch:24 step:22560 [D loss: 0.393326, acc.: 85.16%] [G loss: 1.061515]\n",
      "epoch:24 step:22561 [D loss: 0.468800, acc.: 84.38%] [G loss: 1.034212]\n",
      "epoch:24 step:22562 [D loss: 0.618501, acc.: 64.84%] [G loss: 1.134911]\n",
      "epoch:24 step:22563 [D loss: 0.265877, acc.: 93.75%] [G loss: 1.169093]\n",
      "epoch:24 step:22564 [D loss: 0.231652, acc.: 95.31%] [G loss: 1.240591]\n",
      "epoch:24 step:22565 [D loss: 0.336569, acc.: 92.97%] [G loss: 1.266132]\n",
      "epoch:24 step:22566 [D loss: 0.842323, acc.: 48.44%] [G loss: 1.169602]\n",
      "epoch:24 step:22567 [D loss: 0.706008, acc.: 53.91%] [G loss: 1.180764]\n",
      "epoch:24 step:22568 [D loss: 0.719465, acc.: 57.03%] [G loss: 1.208861]\n",
      "epoch:24 step:22569 [D loss: 0.684875, acc.: 55.47%] [G loss: 1.087194]\n",
      "epoch:24 step:22570 [D loss: 0.697881, acc.: 53.12%] [G loss: 1.187880]\n",
      "epoch:24 step:22571 [D loss: 0.664754, acc.: 57.81%] [G loss: 0.964653]\n",
      "epoch:24 step:22572 [D loss: 0.616890, acc.: 69.53%] [G loss: 1.039639]\n",
      "epoch:24 step:22573 [D loss: 0.548491, acc.: 72.66%] [G loss: 1.004091]\n",
      "epoch:24 step:22574 [D loss: 0.718855, acc.: 58.59%] [G loss: 1.165005]\n",
      "epoch:24 step:22575 [D loss: 0.666554, acc.: 62.50%] [G loss: 0.944355]\n",
      "epoch:24 step:22576 [D loss: 0.673829, acc.: 55.47%] [G loss: 0.860126]\n",
      "epoch:24 step:22577 [D loss: 0.572252, acc.: 74.22%] [G loss: 0.796976]\n",
      "epoch:24 step:22578 [D loss: 0.740641, acc.: 50.78%] [G loss: 0.910327]\n",
      "epoch:24 step:22579 [D loss: 0.688974, acc.: 55.47%] [G loss: 1.082541]\n",
      "epoch:24 step:22580 [D loss: 0.623744, acc.: 67.19%] [G loss: 0.890061]\n",
      "epoch:24 step:22581 [D loss: 0.564452, acc.: 75.78%] [G loss: 1.124492]\n",
      "epoch:24 step:22582 [D loss: 0.703887, acc.: 58.59%] [G loss: 0.843149]\n",
      "epoch:24 step:22583 [D loss: 0.502081, acc.: 77.34%] [G loss: 0.960460]\n",
      "epoch:24 step:22584 [D loss: 0.986878, acc.: 55.47%] [G loss: 1.259922]\n",
      "epoch:24 step:22585 [D loss: 0.622732, acc.: 62.50%] [G loss: 0.835145]\n",
      "epoch:24 step:22586 [D loss: 0.444323, acc.: 83.59%] [G loss: 1.200240]\n",
      "epoch:24 step:22587 [D loss: 0.443260, acc.: 86.72%] [G loss: 0.997531]\n",
      "epoch:24 step:22588 [D loss: 0.407237, acc.: 87.50%] [G loss: 1.449726]\n",
      "epoch:24 step:22589 [D loss: 0.801029, acc.: 49.22%] [G loss: 1.030337]\n",
      "epoch:24 step:22590 [D loss: 0.803640, acc.: 43.75%] [G loss: 0.998198]\n",
      "epoch:24 step:22591 [D loss: 0.588421, acc.: 72.66%] [G loss: 0.754516]\n",
      "epoch:24 step:22592 [D loss: 0.832978, acc.: 38.28%] [G loss: 0.923151]\n",
      "epoch:24 step:22593 [D loss: 0.371539, acc.: 76.56%] [G loss: 0.911714]\n",
      "epoch:24 step:22594 [D loss: 0.540027, acc.: 77.34%] [G loss: 0.882018]\n",
      "epoch:24 step:22595 [D loss: 0.486972, acc.: 74.22%] [G loss: 1.012933]\n",
      "epoch:24 step:22596 [D loss: 0.626635, acc.: 64.84%] [G loss: 0.838303]\n",
      "epoch:24 step:22597 [D loss: 0.934402, acc.: 37.50%] [G loss: 1.414575]\n",
      "epoch:24 step:22598 [D loss: 0.646578, acc.: 59.38%] [G loss: 0.869138]\n",
      "epoch:24 step:22599 [D loss: 1.042498, acc.: 17.19%] [G loss: 0.969632]\n",
      "epoch:24 step:22600 [D loss: 0.688936, acc.: 57.81%] [G loss: 1.076547]\n",
      "epoch:24 step:22601 [D loss: 0.645624, acc.: 64.84%] [G loss: 1.400434]\n",
      "epoch:24 step:22602 [D loss: 0.665853, acc.: 60.94%] [G loss: 0.915265]\n",
      "epoch:24 step:22603 [D loss: 0.628675, acc.: 64.84%] [G loss: 1.085310]\n",
      "epoch:24 step:22604 [D loss: 0.741646, acc.: 51.56%] [G loss: 1.028648]\n",
      "epoch:24 step:22605 [D loss: 0.410073, acc.: 86.72%] [G loss: 0.994457]\n",
      "epoch:24 step:22606 [D loss: 0.410749, acc.: 87.50%] [G loss: 1.004028]\n",
      "epoch:24 step:22607 [D loss: 0.394350, acc.: 71.09%] [G loss: 1.206406]\n",
      "epoch:24 step:22608 [D loss: 0.557504, acc.: 69.53%] [G loss: 1.186225]\n",
      "epoch:24 step:22609 [D loss: 0.452477, acc.: 82.81%] [G loss: 1.364586]\n",
      "epoch:24 step:22610 [D loss: 0.376638, acc.: 87.50%] [G loss: 1.479631]\n",
      "epoch:24 step:22611 [D loss: 0.595862, acc.: 64.06%] [G loss: 1.310703]\n",
      "epoch:24 step:22612 [D loss: 0.636738, acc.: 57.03%] [G loss: 1.369098]\n",
      "epoch:24 step:22613 [D loss: 0.699950, acc.: 56.25%] [G loss: 1.469377]\n",
      "epoch:24 step:22614 [D loss: 0.633692, acc.: 59.38%] [G loss: 1.185176]\n",
      "epoch:24 step:22615 [D loss: 0.729194, acc.: 55.47%] [G loss: 1.173322]\n",
      "epoch:24 step:22616 [D loss: 0.655007, acc.: 64.06%] [G loss: 0.821213]\n",
      "epoch:24 step:22617 [D loss: 0.497207, acc.: 78.91%] [G loss: 0.913801]\n",
      "epoch:24 step:22618 [D loss: 0.307739, acc.: 92.97%] [G loss: 1.091782]\n",
      "epoch:24 step:22619 [D loss: 0.381370, acc.: 89.84%] [G loss: 1.539024]\n",
      "epoch:24 step:22620 [D loss: 0.371632, acc.: 90.62%] [G loss: 1.367011]\n",
      "epoch:24 step:22621 [D loss: 0.702643, acc.: 53.91%] [G loss: 1.552012]\n",
      "epoch:24 step:22622 [D loss: 0.758879, acc.: 51.56%] [G loss: 1.283042]\n",
      "epoch:24 step:22623 [D loss: 0.636754, acc.: 63.28%] [G loss: 1.383874]\n",
      "epoch:24 step:22624 [D loss: 0.565944, acc.: 71.88%] [G loss: 1.298628]\n",
      "epoch:24 step:22625 [D loss: 0.451518, acc.: 85.16%] [G loss: 1.486800]\n",
      "epoch:24 step:22626 [D loss: 0.375711, acc.: 92.19%] [G loss: 1.398950]\n",
      "epoch:24 step:22627 [D loss: 0.293443, acc.: 90.62%] [G loss: 1.503187]\n",
      "epoch:24 step:22628 [D loss: 0.614276, acc.: 64.84%] [G loss: 1.117308]\n",
      "epoch:24 step:22629 [D loss: 0.895790, acc.: 42.97%] [G loss: 1.067483]\n",
      "epoch:24 step:22630 [D loss: 0.793038, acc.: 51.56%] [G loss: 0.962573]\n",
      "epoch:24 step:22631 [D loss: 0.740061, acc.: 48.44%] [G loss: 0.955646]\n",
      "epoch:24 step:22632 [D loss: 0.760091, acc.: 48.44%] [G loss: 0.934085]\n",
      "epoch:24 step:22633 [D loss: 0.611619, acc.: 60.94%] [G loss: 0.811334]\n",
      "epoch:24 step:22634 [D loss: 0.662517, acc.: 60.94%] [G loss: 1.212351]\n",
      "epoch:24 step:22635 [D loss: 0.662672, acc.: 60.16%] [G loss: 0.843276]\n",
      "epoch:24 step:22636 [D loss: 0.701813, acc.: 60.16%] [G loss: 0.881665]\n",
      "epoch:24 step:22637 [D loss: 0.850380, acc.: 42.97%] [G loss: 0.966026]\n",
      "epoch:24 step:22638 [D loss: 0.519124, acc.: 76.56%] [G loss: 0.934531]\n",
      "epoch:24 step:22639 [D loss: 0.554193, acc.: 74.22%] [G loss: 1.244273]\n",
      "epoch:24 step:22640 [D loss: 0.529168, acc.: 77.34%] [G loss: 1.073846]\n",
      "epoch:24 step:22641 [D loss: 0.579694, acc.: 71.09%] [G loss: 1.047482]\n",
      "epoch:24 step:22642 [D loss: 0.657385, acc.: 62.50%] [G loss: 1.055048]\n",
      "epoch:24 step:22643 [D loss: 0.615998, acc.: 66.41%] [G loss: 0.818490]\n",
      "epoch:24 step:22644 [D loss: 0.460053, acc.: 80.47%] [G loss: 0.936309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22645 [D loss: 0.628497, acc.: 61.72%] [G loss: 1.047516]\n",
      "epoch:24 step:22646 [D loss: 0.608629, acc.: 67.19%] [G loss: 1.026764]\n",
      "epoch:24 step:22647 [D loss: 0.411310, acc.: 88.28%] [G loss: 1.160037]\n",
      "epoch:24 step:22648 [D loss: 0.627579, acc.: 60.16%] [G loss: 1.085493]\n",
      "epoch:24 step:22649 [D loss: 0.712134, acc.: 60.16%] [G loss: 1.110243]\n",
      "epoch:24 step:22650 [D loss: 0.754088, acc.: 46.88%] [G loss: 1.016767]\n",
      "epoch:24 step:22651 [D loss: 0.783706, acc.: 45.31%] [G loss: 0.988919]\n",
      "epoch:24 step:22652 [D loss: 0.807139, acc.: 40.62%] [G loss: 0.930872]\n",
      "epoch:24 step:22653 [D loss: 0.713478, acc.: 50.78%] [G loss: 1.073313]\n",
      "epoch:24 step:22654 [D loss: 0.535076, acc.: 82.81%] [G loss: 1.076037]\n",
      "epoch:24 step:22655 [D loss: 0.563223, acc.: 70.31%] [G loss: 1.023142]\n",
      "epoch:24 step:22656 [D loss: 0.453417, acc.: 71.88%] [G loss: 0.923854]\n",
      "epoch:24 step:22657 [D loss: 1.051111, acc.: 56.25%] [G loss: 0.950010]\n",
      "epoch:24 step:22658 [D loss: 0.648498, acc.: 58.59%] [G loss: 1.083933]\n",
      "epoch:24 step:22659 [D loss: 0.639998, acc.: 62.50%] [G loss: 1.160509]\n",
      "epoch:24 step:22660 [D loss: 0.685451, acc.: 62.50%] [G loss: 1.042161]\n",
      "epoch:24 step:22661 [D loss: 0.692645, acc.: 57.03%] [G loss: 0.919817]\n",
      "epoch:24 step:22662 [D loss: 0.783808, acc.: 46.88%] [G loss: 1.008435]\n",
      "epoch:24 step:22663 [D loss: 0.766809, acc.: 46.09%] [G loss: 0.900892]\n",
      "epoch:24 step:22664 [D loss: 0.584247, acc.: 71.09%] [G loss: 1.090980]\n",
      "epoch:24 step:22665 [D loss: 0.723288, acc.: 51.56%] [G loss: 1.097582]\n",
      "epoch:24 step:22666 [D loss: 0.729750, acc.: 45.31%] [G loss: 0.975217]\n",
      "epoch:24 step:22667 [D loss: 0.693709, acc.: 50.78%] [G loss: 0.936309]\n",
      "epoch:24 step:22668 [D loss: 0.731544, acc.: 47.66%] [G loss: 0.898609]\n",
      "epoch:24 step:22669 [D loss: 0.696882, acc.: 56.25%] [G loss: 0.833725]\n",
      "epoch:24 step:22670 [D loss: 0.648042, acc.: 64.84%] [G loss: 0.980051]\n",
      "epoch:24 step:22671 [D loss: 0.652724, acc.: 60.16%] [G loss: 0.809052]\n",
      "epoch:24 step:22672 [D loss: 0.615684, acc.: 65.62%] [G loss: 0.786772]\n",
      "epoch:24 step:22673 [D loss: 0.716589, acc.: 57.03%] [G loss: 0.840266]\n",
      "epoch:24 step:22674 [D loss: 0.746569, acc.: 43.75%] [G loss: 0.695542]\n",
      "epoch:24 step:22675 [D loss: 0.841678, acc.: 42.97%] [G loss: 0.846803]\n",
      "epoch:24 step:22676 [D loss: 0.617504, acc.: 66.41%] [G loss: 0.938472]\n",
      "epoch:24 step:22677 [D loss: 0.709559, acc.: 57.03%] [G loss: 0.864748]\n",
      "epoch:24 step:22678 [D loss: 0.684093, acc.: 57.81%] [G loss: 0.872895]\n",
      "epoch:24 step:22679 [D loss: 0.634918, acc.: 66.41%] [G loss: 0.845725]\n",
      "epoch:24 step:22680 [D loss: 0.485577, acc.: 74.22%] [G loss: 0.870881]\n",
      "epoch:24 step:22681 [D loss: 0.598061, acc.: 75.00%] [G loss: 0.932401]\n",
      "epoch:24 step:22682 [D loss: 0.544802, acc.: 73.44%] [G loss: 0.911353]\n",
      "epoch:24 step:22683 [D loss: 0.607321, acc.: 63.28%] [G loss: 0.982174]\n",
      "epoch:24 step:22684 [D loss: 0.604495, acc.: 70.31%] [G loss: 0.995757]\n",
      "epoch:24 step:22685 [D loss: 0.555296, acc.: 75.00%] [G loss: 0.908982]\n",
      "epoch:24 step:22686 [D loss: 0.610334, acc.: 67.97%] [G loss: 0.708476]\n",
      "epoch:24 step:22687 [D loss: 0.653425, acc.: 53.12%] [G loss: 0.746872]\n",
      "epoch:24 step:22688 [D loss: 0.635043, acc.: 64.84%] [G loss: 0.842850]\n",
      "epoch:24 step:22689 [D loss: 0.355285, acc.: 86.72%] [G loss: 1.041509]\n",
      "epoch:24 step:22690 [D loss: 0.655409, acc.: 57.03%] [G loss: 1.052846]\n",
      "epoch:24 step:22691 [D loss: 0.567647, acc.: 68.75%] [G loss: 0.533083]\n",
      "epoch:24 step:22692 [D loss: 0.555000, acc.: 68.75%] [G loss: 1.165023]\n",
      "epoch:24 step:22693 [D loss: 0.616064, acc.: 67.19%] [G loss: 0.887488]\n",
      "epoch:24 step:22694 [D loss: 0.462031, acc.: 85.94%] [G loss: 0.629124]\n",
      "epoch:24 step:22695 [D loss: 0.334947, acc.: 83.59%] [G loss: 1.178391]\n",
      "epoch:24 step:22696 [D loss: 0.545102, acc.: 77.34%] [G loss: 1.003304]\n",
      "epoch:24 step:22697 [D loss: 0.475750, acc.: 79.69%] [G loss: 0.956378]\n",
      "epoch:24 step:22698 [D loss: 0.926531, acc.: 35.94%] [G loss: 1.052252]\n",
      "epoch:24 step:22699 [D loss: 0.907968, acc.: 34.38%] [G loss: 0.888793]\n",
      "epoch:24 step:22700 [D loss: 0.718688, acc.: 55.47%] [G loss: 1.009819]\n",
      "epoch:24 step:22701 [D loss: 0.787570, acc.: 42.19%] [G loss: 0.910468]\n",
      "epoch:24 step:22702 [D loss: 0.714508, acc.: 54.69%] [G loss: 1.067078]\n",
      "epoch:24 step:22703 [D loss: 0.632405, acc.: 66.41%] [G loss: 1.087060]\n",
      "epoch:24 step:22704 [D loss: 0.687713, acc.: 61.72%] [G loss: 0.725247]\n",
      "epoch:24 step:22705 [D loss: 0.762234, acc.: 48.44%] [G loss: 1.017965]\n",
      "epoch:24 step:22706 [D loss: 0.626749, acc.: 65.62%] [G loss: 0.935945]\n",
      "epoch:24 step:22707 [D loss: 0.560931, acc.: 76.56%] [G loss: 0.994069]\n",
      "epoch:24 step:22708 [D loss: 0.328901, acc.: 82.81%] [G loss: 1.069234]\n",
      "epoch:24 step:22709 [D loss: 0.272499, acc.: 92.97%] [G loss: 1.414951]\n",
      "epoch:24 step:22710 [D loss: 0.315731, acc.: 94.53%] [G loss: 1.277179]\n",
      "epoch:24 step:22711 [D loss: 0.229498, acc.: 99.22%] [G loss: 1.371653]\n",
      "epoch:24 step:22712 [D loss: 0.823749, acc.: 42.97%] [G loss: 1.415860]\n",
      "epoch:24 step:22713 [D loss: 0.729453, acc.: 57.03%] [G loss: 1.204822]\n",
      "epoch:24 step:22714 [D loss: 0.563451, acc.: 75.00%] [G loss: 1.173333]\n",
      "epoch:24 step:22715 [D loss: 0.545595, acc.: 73.44%] [G loss: 1.263961]\n",
      "epoch:24 step:22716 [D loss: 0.404513, acc.: 91.41%] [G loss: 1.276927]\n",
      "epoch:24 step:22717 [D loss: 0.461378, acc.: 83.59%] [G loss: 1.313724]\n",
      "epoch:24 step:22718 [D loss: 0.237833, acc.: 94.53%] [G loss: 1.284884]\n",
      "epoch:24 step:22719 [D loss: 0.168933, acc.: 99.22%] [G loss: 1.470754]\n",
      "epoch:24 step:22720 [D loss: 0.212339, acc.: 93.75%] [G loss: 2.059514]\n",
      "epoch:24 step:22721 [D loss: 0.707372, acc.: 59.38%] [G loss: 1.630507]\n",
      "epoch:24 step:22722 [D loss: 0.427247, acc.: 88.28%] [G loss: 1.724054]\n",
      "epoch:24 step:22723 [D loss: 0.281177, acc.: 95.31%] [G loss: 1.388749]\n",
      "epoch:24 step:22724 [D loss: 0.449636, acc.: 82.81%] [G loss: 1.415560]\n",
      "epoch:24 step:22725 [D loss: 0.479642, acc.: 81.25%] [G loss: 0.901509]\n",
      "epoch:24 step:22726 [D loss: 0.286039, acc.: 95.31%] [G loss: 1.359028]\n",
      "epoch:24 step:22727 [D loss: 0.566802, acc.: 71.88%] [G loss: 1.256904]\n",
      "epoch:24 step:22728 [D loss: 0.669032, acc.: 64.84%] [G loss: 1.232314]\n",
      "epoch:24 step:22729 [D loss: 1.023440, acc.: 34.38%] [G loss: 1.017051]\n",
      "epoch:24 step:22730 [D loss: 0.571225, acc.: 75.00%] [G loss: 0.904813]\n",
      "epoch:24 step:22731 [D loss: 0.339229, acc.: 90.62%] [G loss: 1.202568]\n",
      "epoch:24 step:22732 [D loss: 0.723003, acc.: 53.12%] [G loss: 0.646884]\n",
      "epoch:24 step:22733 [D loss: 0.955527, acc.: 35.94%] [G loss: 0.905198]\n",
      "epoch:24 step:22734 [D loss: 0.880066, acc.: 39.06%] [G loss: 1.164795]\n",
      "epoch:24 step:22735 [D loss: 0.908522, acc.: 28.12%] [G loss: 1.269938]\n",
      "epoch:24 step:22736 [D loss: 0.675465, acc.: 53.12%] [G loss: 1.343008]\n",
      "epoch:24 step:22737 [D loss: 0.677473, acc.: 61.72%] [G loss: 1.449867]\n",
      "epoch:24 step:22738 [D loss: 0.663341, acc.: 57.03%] [G loss: 1.365670]\n",
      "epoch:24 step:22739 [D loss: 0.707946, acc.: 53.12%] [G loss: 1.145488]\n",
      "epoch:24 step:22740 [D loss: 0.583370, acc.: 69.53%] [G loss: 1.037925]\n",
      "epoch:24 step:22741 [D loss: 0.823294, acc.: 39.84%] [G loss: 1.247557]\n",
      "epoch:24 step:22742 [D loss: 0.625585, acc.: 60.16%] [G loss: 1.189662]\n",
      "epoch:24 step:22743 [D loss: 0.618977, acc.: 63.28%] [G loss: 1.339328]\n",
      "epoch:24 step:22744 [D loss: 0.354579, acc.: 92.19%] [G loss: 1.187030]\n",
      "epoch:24 step:22745 [D loss: 0.601218, acc.: 62.50%] [G loss: 0.619465]\n",
      "epoch:24 step:22746 [D loss: 0.675140, acc.: 54.69%] [G loss: 1.010760]\n",
      "epoch:24 step:22747 [D loss: 0.493391, acc.: 75.00%] [G loss: 0.977783]\n",
      "epoch:24 step:22748 [D loss: 0.716765, acc.: 57.81%] [G loss: 0.999475]\n",
      "epoch:24 step:22749 [D loss: 0.421163, acc.: 83.59%] [G loss: 1.032068]\n",
      "epoch:24 step:22750 [D loss: 0.811987, acc.: 41.41%] [G loss: 1.068630]\n",
      "epoch:24 step:22751 [D loss: 0.501893, acc.: 74.22%] [G loss: 1.160513]\n",
      "epoch:24 step:22752 [D loss: 0.565547, acc.: 75.78%] [G loss: 1.308572]\n",
      "epoch:24 step:22753 [D loss: 0.803067, acc.: 46.09%] [G loss: 1.225597]\n",
      "epoch:24 step:22754 [D loss: 0.663487, acc.: 54.69%] [G loss: 1.507876]\n",
      "epoch:24 step:22755 [D loss: 0.673516, acc.: 50.78%] [G loss: 1.432926]\n",
      "epoch:24 step:22756 [D loss: 0.608847, acc.: 58.59%] [G loss: 1.327849]\n",
      "epoch:24 step:22757 [D loss: 0.438916, acc.: 84.38%] [G loss: 1.469511]\n",
      "epoch:24 step:22758 [D loss: 0.456425, acc.: 77.34%] [G loss: 1.313983]\n",
      "epoch:24 step:22759 [D loss: 0.406716, acc.: 90.62%] [G loss: 1.427763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22760 [D loss: 0.373343, acc.: 94.53%] [G loss: 1.586446]\n",
      "epoch:24 step:22761 [D loss: 0.437955, acc.: 91.41%] [G loss: 1.602498]\n",
      "epoch:24 step:22762 [D loss: 0.394947, acc.: 89.06%] [G loss: 1.250046]\n",
      "epoch:24 step:22763 [D loss: 0.396785, acc.: 82.03%] [G loss: 1.586568]\n",
      "epoch:24 step:22764 [D loss: 0.481096, acc.: 84.38%] [G loss: 1.688503]\n",
      "epoch:24 step:22765 [D loss: 0.504987, acc.: 70.31%] [G loss: 1.162359]\n",
      "epoch:24 step:22766 [D loss: 1.010716, acc.: 45.31%] [G loss: 1.154066]\n",
      "epoch:24 step:22767 [D loss: 0.829511, acc.: 49.22%] [G loss: 0.887254]\n",
      "epoch:24 step:22768 [D loss: 0.683948, acc.: 58.59%] [G loss: 1.182382]\n",
      "epoch:24 step:22769 [D loss: 0.539138, acc.: 79.69%] [G loss: 1.114137]\n",
      "epoch:24 step:22770 [D loss: 0.389989, acc.: 83.59%] [G loss: 1.157665]\n",
      "epoch:24 step:22771 [D loss: 0.530989, acc.: 78.91%] [G loss: 1.051933]\n",
      "epoch:24 step:22772 [D loss: 0.730867, acc.: 55.47%] [G loss: 1.034515]\n",
      "epoch:24 step:22773 [D loss: 0.633688, acc.: 64.84%] [G loss: 1.368960]\n",
      "epoch:24 step:22774 [D loss: 0.545280, acc.: 72.66%] [G loss: 0.942148]\n",
      "epoch:24 step:22775 [D loss: 0.592305, acc.: 67.97%] [G loss: 1.037551]\n",
      "epoch:24 step:22776 [D loss: 0.724352, acc.: 54.69%] [G loss: 0.930668]\n",
      "epoch:24 step:22777 [D loss: 0.518499, acc.: 78.91%] [G loss: 0.980993]\n",
      "epoch:24 step:22778 [D loss: 0.670863, acc.: 62.50%] [G loss: 1.140761]\n",
      "epoch:24 step:22779 [D loss: 0.735056, acc.: 57.81%] [G loss: 0.985519]\n",
      "epoch:24 step:22780 [D loss: 0.486917, acc.: 79.69%] [G loss: 1.057028]\n",
      "epoch:24 step:22781 [D loss: 0.545292, acc.: 76.56%] [G loss: 0.756472]\n",
      "epoch:24 step:22782 [D loss: 0.518386, acc.: 78.12%] [G loss: 0.943377]\n",
      "epoch:24 step:22783 [D loss: 0.472070, acc.: 84.38%] [G loss: 1.228111]\n",
      "epoch:24 step:22784 [D loss: 0.621677, acc.: 66.41%] [G loss: 1.007025]\n",
      "epoch:24 step:22785 [D loss: 0.512155, acc.: 78.12%] [G loss: 0.968375]\n",
      "epoch:24 step:22786 [D loss: 0.396603, acc.: 90.62%] [G loss: 1.033203]\n",
      "epoch:24 step:22787 [D loss: 0.423970, acc.: 86.72%] [G loss: 1.181718]\n",
      "epoch:24 step:22788 [D loss: 0.437318, acc.: 85.94%] [G loss: 1.363046]\n",
      "epoch:24 step:22789 [D loss: 0.660497, acc.: 64.06%] [G loss: 1.256757]\n",
      "epoch:24 step:22790 [D loss: 0.562378, acc.: 69.53%] [G loss: 1.138604]\n",
      "epoch:24 step:22791 [D loss: 0.762059, acc.: 53.91%] [G loss: 1.165619]\n",
      "epoch:24 step:22792 [D loss: 0.641306, acc.: 57.03%] [G loss: 1.213413]\n",
      "epoch:24 step:22793 [D loss: 0.595898, acc.: 69.53%] [G loss: 1.278023]\n",
      "epoch:24 step:22794 [D loss: 0.651295, acc.: 62.50%] [G loss: 1.028875]\n",
      "epoch:24 step:22795 [D loss: 0.454933, acc.: 85.16%] [G loss: 0.955439]\n",
      "epoch:24 step:22796 [D loss: 0.860581, acc.: 36.72%] [G loss: 1.164021]\n",
      "epoch:24 step:22797 [D loss: 0.510837, acc.: 78.91%] [G loss: 1.036420]\n",
      "epoch:24 step:22798 [D loss: 0.733091, acc.: 51.56%] [G loss: 0.903978]\n",
      "epoch:24 step:22799 [D loss: 0.714093, acc.: 55.47%] [G loss: 0.913092]\n",
      "epoch:24 step:22800 [D loss: 0.453685, acc.: 79.69%] [G loss: 0.986507]\n",
      "epoch:24 step:22801 [D loss: 0.571552, acc.: 69.53%] [G loss: 0.964044]\n",
      "epoch:24 step:22802 [D loss: 0.400383, acc.: 79.69%] [G loss: 0.952305]\n",
      "epoch:24 step:22803 [D loss: 0.604982, acc.: 65.62%] [G loss: 0.896713]\n",
      "epoch:24 step:22804 [D loss: 0.605602, acc.: 67.97%] [G loss: 1.139448]\n",
      "epoch:24 step:22805 [D loss: 0.671372, acc.: 54.69%] [G loss: 0.795434]\n",
      "epoch:24 step:22806 [D loss: 0.574716, acc.: 69.53%] [G loss: 1.172047]\n",
      "epoch:24 step:22807 [D loss: 0.613368, acc.: 70.31%] [G loss: 1.105032]\n",
      "epoch:24 step:22808 [D loss: 0.512711, acc.: 78.91%] [G loss: 1.149603]\n",
      "epoch:24 step:22809 [D loss: 0.486834, acc.: 77.34%] [G loss: 1.188674]\n",
      "epoch:24 step:22810 [D loss: 0.437425, acc.: 89.06%] [G loss: 1.190034]\n",
      "epoch:24 step:22811 [D loss: 0.684606, acc.: 60.94%] [G loss: 1.273660]\n",
      "epoch:24 step:22812 [D loss: 0.595007, acc.: 64.84%] [G loss: 1.121240]\n",
      "epoch:24 step:22813 [D loss: 0.677935, acc.: 57.81%] [G loss: 0.980204]\n",
      "epoch:24 step:22814 [D loss: 0.629422, acc.: 64.84%] [G loss: 1.136863]\n",
      "epoch:24 step:22815 [D loss: 0.288230, acc.: 93.75%] [G loss: 1.011864]\n",
      "epoch:24 step:22816 [D loss: 0.405664, acc.: 76.56%] [G loss: 1.394400]\n",
      "epoch:24 step:22817 [D loss: 0.698031, acc.: 53.12%] [G loss: 1.082457]\n",
      "epoch:24 step:22818 [D loss: 0.939827, acc.: 25.78%] [G loss: 1.402335]\n",
      "epoch:24 step:22819 [D loss: 0.725212, acc.: 49.22%] [G loss: 1.091209]\n",
      "epoch:24 step:22820 [D loss: 0.632550, acc.: 61.72%] [G loss: 0.979427]\n",
      "epoch:24 step:22821 [D loss: 0.578382, acc.: 67.19%] [G loss: 1.118938]\n",
      "epoch:24 step:22822 [D loss: 0.700533, acc.: 55.47%] [G loss: 1.174562]\n",
      "epoch:24 step:22823 [D loss: 0.505495, acc.: 78.91%] [G loss: 1.212931]\n",
      "epoch:24 step:22824 [D loss: 0.435250, acc.: 88.28%] [G loss: 1.249581]\n",
      "epoch:24 step:22825 [D loss: 0.520292, acc.: 74.22%] [G loss: 1.226460]\n",
      "epoch:24 step:22826 [D loss: 0.499733, acc.: 78.12%] [G loss: 1.098207]\n",
      "epoch:24 step:22827 [D loss: 0.527947, acc.: 70.31%] [G loss: 1.266134]\n",
      "epoch:24 step:22828 [D loss: 0.734579, acc.: 49.22%] [G loss: 1.255802]\n",
      "epoch:24 step:22829 [D loss: 0.697948, acc.: 57.03%] [G loss: 1.135510]\n",
      "epoch:24 step:22830 [D loss: 0.420410, acc.: 77.34%] [G loss: 1.111621]\n",
      "epoch:24 step:22831 [D loss: 0.243984, acc.: 92.97%] [G loss: 1.223390]\n",
      "epoch:24 step:22832 [D loss: 0.410533, acc.: 82.81%] [G loss: 1.442528]\n",
      "epoch:24 step:22833 [D loss: 0.182441, acc.: 98.44%] [G loss: 1.352384]\n",
      "epoch:24 step:22834 [D loss: 0.219970, acc.: 97.66%] [G loss: 1.325331]\n",
      "epoch:24 step:22835 [D loss: 0.146841, acc.: 98.44%] [G loss: 1.693593]\n",
      "epoch:24 step:22836 [D loss: 0.939157, acc.: 50.00%] [G loss: 1.493131]\n",
      "epoch:24 step:22837 [D loss: 0.725016, acc.: 53.91%] [G loss: 1.210406]\n",
      "epoch:24 step:22838 [D loss: 0.840363, acc.: 46.09%] [G loss: 1.278889]\n",
      "epoch:24 step:22839 [D loss: 0.608996, acc.: 66.41%] [G loss: 1.343357]\n",
      "epoch:24 step:22840 [D loss: 0.485041, acc.: 80.47%] [G loss: 1.370335]\n",
      "epoch:24 step:22841 [D loss: 0.461788, acc.: 78.12%] [G loss: 1.281592]\n",
      "epoch:24 step:22842 [D loss: 0.484744, acc.: 82.03%] [G loss: 1.389299]\n",
      "epoch:24 step:22843 [D loss: 0.604941, acc.: 67.19%] [G loss: 1.092852]\n",
      "epoch:24 step:22844 [D loss: 0.637146, acc.: 61.72%] [G loss: 1.266503]\n",
      "epoch:24 step:22845 [D loss: 0.575538, acc.: 70.31%] [G loss: 1.004054]\n",
      "epoch:24 step:22846 [D loss: 0.426002, acc.: 81.25%] [G loss: 1.387445]\n",
      "epoch:24 step:22847 [D loss: 0.459886, acc.: 85.16%] [G loss: 1.294969]\n",
      "epoch:24 step:22848 [D loss: 0.497194, acc.: 77.34%] [G loss: 0.884469]\n",
      "epoch:24 step:22849 [D loss: 0.608307, acc.: 66.41%] [G loss: 1.599711]\n",
      "epoch:24 step:22850 [D loss: 0.785361, acc.: 48.44%] [G loss: 1.223931]\n",
      "epoch:24 step:22851 [D loss: 0.729157, acc.: 52.34%] [G loss: 0.842925]\n",
      "epoch:24 step:22852 [D loss: 0.661365, acc.: 56.25%] [G loss: 0.811348]\n",
      "epoch:24 step:22853 [D loss: 0.589293, acc.: 67.97%] [G loss: 0.886274]\n",
      "epoch:24 step:22854 [D loss: 0.369178, acc.: 81.25%] [G loss: 0.564242]\n",
      "epoch:24 step:22855 [D loss: 0.366294, acc.: 82.03%] [G loss: 1.249249]\n",
      "epoch:24 step:22856 [D loss: 0.842892, acc.: 46.09%] [G loss: 0.958670]\n",
      "epoch:24 step:22857 [D loss: 0.505988, acc.: 82.81%] [G loss: 0.789900]\n",
      "epoch:24 step:22858 [D loss: 0.470678, acc.: 81.25%] [G loss: 1.088094]\n",
      "epoch:24 step:22859 [D loss: 0.361756, acc.: 83.59%] [G loss: 1.008286]\n",
      "epoch:24 step:22860 [D loss: 0.599036, acc.: 64.84%] [G loss: 1.000878]\n",
      "epoch:24 step:22861 [D loss: 0.695358, acc.: 59.38%] [G loss: 1.079111]\n",
      "epoch:24 step:22862 [D loss: 0.809618, acc.: 42.19%] [G loss: 1.155632]\n",
      "epoch:24 step:22863 [D loss: 0.704567, acc.: 54.69%] [G loss: 0.917940]\n",
      "epoch:24 step:22864 [D loss: 0.609449, acc.: 66.41%] [G loss: 0.861454]\n",
      "epoch:24 step:22865 [D loss: 0.307600, acc.: 92.19%] [G loss: 0.995683]\n",
      "epoch:24 step:22866 [D loss: 0.279295, acc.: 89.06%] [G loss: 1.364201]\n",
      "epoch:24 step:22867 [D loss: 0.717422, acc.: 53.91%] [G loss: 1.331753]\n",
      "epoch:24 step:22868 [D loss: 0.562876, acc.: 68.75%] [G loss: 0.699370]\n",
      "epoch:24 step:22869 [D loss: 0.683079, acc.: 59.38%] [G loss: 0.987490]\n",
      "epoch:24 step:22870 [D loss: 0.854757, acc.: 36.72%] [G loss: 0.918413]\n",
      "epoch:24 step:22871 [D loss: 0.647839, acc.: 64.84%] [G loss: 1.184047]\n",
      "epoch:24 step:22872 [D loss: 0.688300, acc.: 55.47%] [G loss: 1.148599]\n",
      "epoch:24 step:22873 [D loss: 0.623827, acc.: 64.84%] [G loss: 1.135729]\n",
      "epoch:24 step:22874 [D loss: 0.639656, acc.: 58.59%] [G loss: 0.993157]\n",
      "epoch:24 step:22875 [D loss: 0.632047, acc.: 64.84%] [G loss: 1.010191]\n",
      "epoch:24 step:22876 [D loss: 0.527695, acc.: 78.91%] [G loss: 0.916073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22877 [D loss: 0.465001, acc.: 80.47%] [G loss: 1.231578]\n",
      "epoch:24 step:22878 [D loss: 0.450484, acc.: 80.47%] [G loss: 1.251964]\n",
      "epoch:24 step:22879 [D loss: 0.493841, acc.: 82.03%] [G loss: 1.350755]\n",
      "epoch:24 step:22880 [D loss: 0.391585, acc.: 92.97%] [G loss: 1.289128]\n",
      "epoch:24 step:22881 [D loss: 0.225789, acc.: 90.62%] [G loss: 1.383215]\n",
      "epoch:24 step:22882 [D loss: 0.330012, acc.: 91.41%] [G loss: 1.447616]\n",
      "epoch:24 step:22883 [D loss: 0.584400, acc.: 68.75%] [G loss: 1.499364]\n",
      "epoch:24 step:22884 [D loss: 0.194234, acc.: 93.75%] [G loss: 1.476577]\n",
      "epoch:24 step:22885 [D loss: 0.129965, acc.: 97.66%] [G loss: 2.683418]\n",
      "epoch:24 step:22886 [D loss: 0.188798, acc.: 96.09%] [G loss: 1.868200]\n",
      "epoch:24 step:22887 [D loss: 0.139893, acc.: 98.44%] [G loss: 1.817157]\n",
      "epoch:24 step:22888 [D loss: 0.169133, acc.: 96.88%] [G loss: 1.856621]\n",
      "epoch:24 step:22889 [D loss: 0.116917, acc.: 96.88%] [G loss: 1.566515]\n",
      "epoch:24 step:22890 [D loss: 0.136302, acc.: 98.44%] [G loss: 2.770792]\n",
      "epoch:24 step:22891 [D loss: 0.147868, acc.: 98.44%] [G loss: 1.054249]\n",
      "epoch:24 step:22892 [D loss: 0.097511, acc.: 100.00%] [G loss: 2.337683]\n",
      "epoch:24 step:22893 [D loss: 0.105737, acc.: 100.00%] [G loss: 2.430000]\n",
      "epoch:24 step:22894 [D loss: 0.111711, acc.: 100.00%] [G loss: 4.130175]\n",
      "epoch:24 step:22895 [D loss: 0.096544, acc.: 100.00%] [G loss: 1.876643]\n",
      "epoch:24 step:22896 [D loss: 0.136917, acc.: 96.88%] [G loss: 2.218971]\n",
      "epoch:24 step:22897 [D loss: 0.431327, acc.: 74.22%] [G loss: 2.706447]\n",
      "epoch:24 step:22898 [D loss: 0.645856, acc.: 64.06%] [G loss: 1.676386]\n",
      "epoch:24 step:22899 [D loss: 1.451570, acc.: 50.00%] [G loss: 0.844059]\n",
      "epoch:24 step:22900 [D loss: 0.502918, acc.: 71.88%] [G loss: 1.016798]\n",
      "epoch:24 step:22901 [D loss: 0.387876, acc.: 81.25%] [G loss: 0.803747]\n",
      "epoch:24 step:22902 [D loss: 1.119634, acc.: 54.69%] [G loss: 2.863963]\n",
      "epoch:24 step:22903 [D loss: 0.537847, acc.: 73.44%] [G loss: 2.203017]\n",
      "epoch:24 step:22904 [D loss: 0.783756, acc.: 57.03%] [G loss: 1.889715]\n",
      "epoch:24 step:22905 [D loss: 0.653168, acc.: 61.72%] [G loss: 1.294459]\n",
      "epoch:24 step:22906 [D loss: 0.794460, acc.: 57.03%] [G loss: 1.266419]\n",
      "epoch:24 step:22907 [D loss: 0.289320, acc.: 93.75%] [G loss: 1.882799]\n",
      "epoch:24 step:22908 [D loss: 0.839660, acc.: 53.12%] [G loss: 1.343006]\n",
      "epoch:24 step:22909 [D loss: 1.168205, acc.: 23.44%] [G loss: 0.913654]\n",
      "epoch:24 step:22910 [D loss: 0.950550, acc.: 48.44%] [G loss: 1.362749]\n",
      "epoch:24 step:22911 [D loss: 0.891254, acc.: 39.84%] [G loss: 1.549937]\n",
      "epoch:24 step:22912 [D loss: 0.693735, acc.: 60.16%] [G loss: 1.684705]\n",
      "epoch:24 step:22913 [D loss: 0.704220, acc.: 56.25%] [G loss: 1.358791]\n",
      "epoch:24 step:22914 [D loss: 0.670219, acc.: 57.03%] [G loss: 1.133275]\n",
      "epoch:24 step:22915 [D loss: 0.639968, acc.: 63.28%] [G loss: 0.934062]\n",
      "epoch:24 step:22916 [D loss: 0.533403, acc.: 76.56%] [G loss: 1.291588]\n",
      "epoch:24 step:22917 [D loss: 0.788568, acc.: 51.56%] [G loss: 1.137263]\n",
      "epoch:24 step:22918 [D loss: 0.635179, acc.: 64.84%] [G loss: 1.285296]\n",
      "epoch:24 step:22919 [D loss: 0.683144, acc.: 61.72%] [G loss: 1.559358]\n",
      "epoch:24 step:22920 [D loss: 0.693609, acc.: 56.25%] [G loss: 1.344969]\n",
      "epoch:24 step:22921 [D loss: 0.489977, acc.: 72.66%] [G loss: 1.520331]\n",
      "epoch:24 step:22922 [D loss: 0.591577, acc.: 66.41%] [G loss: 1.566063]\n",
      "epoch:24 step:22923 [D loss: 0.594444, acc.: 66.41%] [G loss: 1.342899]\n",
      "epoch:24 step:22924 [D loss: 0.561203, acc.: 72.66%] [G loss: 0.944358]\n",
      "epoch:24 step:22925 [D loss: 0.850949, acc.: 38.28%] [G loss: 1.229050]\n",
      "epoch:24 step:22926 [D loss: 0.767869, acc.: 51.56%] [G loss: 0.985315]\n",
      "epoch:24 step:22927 [D loss: 0.750677, acc.: 50.00%] [G loss: 1.218907]\n",
      "epoch:24 step:22928 [D loss: 0.696940, acc.: 50.78%] [G loss: 1.413823]\n",
      "epoch:24 step:22929 [D loss: 0.726553, acc.: 53.91%] [G loss: 1.132511]\n",
      "epoch:24 step:22930 [D loss: 0.697091, acc.: 56.25%] [G loss: 0.920843]\n",
      "epoch:24 step:22931 [D loss: 0.605309, acc.: 70.31%] [G loss: 1.394549]\n",
      "epoch:24 step:22932 [D loss: 0.615524, acc.: 67.97%] [G loss: 1.181781]\n",
      "epoch:24 step:22933 [D loss: 0.704208, acc.: 50.00%] [G loss: 1.140886]\n",
      "epoch:24 step:22934 [D loss: 0.654183, acc.: 62.50%] [G loss: 1.256751]\n",
      "epoch:24 step:22935 [D loss: 0.590413, acc.: 67.19%] [G loss: 1.245300]\n",
      "epoch:24 step:22936 [D loss: 0.563179, acc.: 71.09%] [G loss: 1.202507]\n",
      "epoch:24 step:22937 [D loss: 0.519192, acc.: 77.34%] [G loss: 1.534079]\n",
      "epoch:24 step:22938 [D loss: 0.443625, acc.: 84.38%] [G loss: 1.501752]\n",
      "epoch:24 step:22939 [D loss: 0.392967, acc.: 92.97%] [G loss: 1.633304]\n",
      "epoch:24 step:22940 [D loss: 0.380174, acc.: 90.62%] [G loss: 1.403091]\n",
      "epoch:24 step:22941 [D loss: 0.432991, acc.: 87.50%] [G loss: 1.460614]\n",
      "epoch:24 step:22942 [D loss: 0.439029, acc.: 84.38%] [G loss: 1.873369]\n",
      "epoch:24 step:22943 [D loss: 0.354140, acc.: 92.19%] [G loss: 1.944818]\n",
      "epoch:24 step:22944 [D loss: 0.435175, acc.: 82.03%] [G loss: 1.370921]\n",
      "epoch:24 step:22945 [D loss: 0.407859, acc.: 81.25%] [G loss: 1.431246]\n",
      "epoch:24 step:22946 [D loss: 0.722199, acc.: 53.91%] [G loss: 1.164953]\n",
      "epoch:24 step:22947 [D loss: 0.588769, acc.: 71.09%] [G loss: 1.223532]\n",
      "epoch:24 step:22948 [D loss: 0.622801, acc.: 67.97%] [G loss: 0.745402]\n",
      "epoch:24 step:22949 [D loss: 1.073789, acc.: 30.47%] [G loss: 0.916905]\n",
      "epoch:24 step:22950 [D loss: 0.950835, acc.: 32.03%] [G loss: 0.880942]\n",
      "epoch:24 step:22951 [D loss: 0.774464, acc.: 48.44%] [G loss: 0.692840]\n",
      "epoch:24 step:22952 [D loss: 0.587898, acc.: 66.41%] [G loss: 0.686835]\n",
      "epoch:24 step:22953 [D loss: 0.616619, acc.: 65.62%] [G loss: 0.751434]\n",
      "epoch:24 step:22954 [D loss: 0.485930, acc.: 82.03%] [G loss: 0.795179]\n",
      "epoch:24 step:22955 [D loss: 0.604441, acc.: 66.41%] [G loss: 1.047415]\n",
      "epoch:24 step:22956 [D loss: 0.454798, acc.: 79.69%] [G loss: 0.903245]\n",
      "epoch:24 step:22957 [D loss: 0.531976, acc.: 72.66%] [G loss: 1.372490]\n",
      "epoch:24 step:22958 [D loss: 0.473134, acc.: 77.34%] [G loss: 1.092604]\n",
      "epoch:24 step:22959 [D loss: 0.481779, acc.: 79.69%] [G loss: 1.183585]\n",
      "epoch:24 step:22960 [D loss: 0.598168, acc.: 66.41%] [G loss: 1.276571]\n",
      "epoch:24 step:22961 [D loss: 1.035425, acc.: 39.84%] [G loss: 1.047529]\n",
      "epoch:24 step:22962 [D loss: 0.912881, acc.: 39.84%] [G loss: 1.257553]\n",
      "epoch:24 step:22963 [D loss: 0.774693, acc.: 44.53%] [G loss: 0.953816]\n",
      "epoch:24 step:22964 [D loss: 0.603595, acc.: 69.53%] [G loss: 2.165221]\n",
      "epoch:24 step:22965 [D loss: 0.612490, acc.: 61.72%] [G loss: 0.911947]\n",
      "epoch:24 step:22966 [D loss: 0.578840, acc.: 73.44%] [G loss: 1.272523]\n",
      "epoch:24 step:22967 [D loss: 0.562237, acc.: 71.09%] [G loss: 1.012818]\n",
      "epoch:24 step:22968 [D loss: 0.464559, acc.: 80.47%] [G loss: 0.907832]\n",
      "epoch:24 step:22969 [D loss: 0.561095, acc.: 67.19%] [G loss: 1.106744]\n",
      "epoch:24 step:22970 [D loss: 0.730332, acc.: 53.91%] [G loss: 1.036550]\n",
      "epoch:24 step:22971 [D loss: 0.670788, acc.: 59.38%] [G loss: 1.006364]\n",
      "epoch:24 step:22972 [D loss: 0.665565, acc.: 64.84%] [G loss: 1.112276]\n",
      "epoch:24 step:22973 [D loss: 0.575739, acc.: 66.41%] [G loss: 0.847834]\n",
      "epoch:24 step:22974 [D loss: 0.634236, acc.: 57.81%] [G loss: 1.119657]\n",
      "epoch:24 step:22975 [D loss: 0.705542, acc.: 50.00%] [G loss: 1.153251]\n",
      "epoch:24 step:22976 [D loss: 0.611875, acc.: 70.31%] [G loss: 0.993483]\n",
      "epoch:24 step:22977 [D loss: 0.641843, acc.: 59.38%] [G loss: 1.083504]\n",
      "epoch:24 step:22978 [D loss: 0.574741, acc.: 71.09%] [G loss: 1.119750]\n",
      "epoch:24 step:22979 [D loss: 0.622437, acc.: 66.41%] [G loss: 1.022999]\n",
      "epoch:24 step:22980 [D loss: 0.617817, acc.: 70.31%] [G loss: 1.232309]\n",
      "epoch:24 step:22981 [D loss: 0.680827, acc.: 59.38%] [G loss: 0.934430]\n",
      "epoch:24 step:22982 [D loss: 0.578919, acc.: 69.53%] [G loss: 0.955212]\n",
      "epoch:24 step:22983 [D loss: 0.671867, acc.: 60.94%] [G loss: 1.085038]\n",
      "epoch:24 step:22984 [D loss: 0.711346, acc.: 49.22%] [G loss: 0.927366]\n",
      "epoch:24 step:22985 [D loss: 0.565913, acc.: 68.75%] [G loss: 1.083386]\n",
      "epoch:24 step:22986 [D loss: 0.602695, acc.: 73.44%] [G loss: 1.197711]\n",
      "epoch:24 step:22987 [D loss: 0.554307, acc.: 72.66%] [G loss: 1.130569]\n",
      "epoch:24 step:22988 [D loss: 0.765154, acc.: 47.66%] [G loss: 1.115024]\n",
      "epoch:24 step:22989 [D loss: 0.794408, acc.: 49.22%] [G loss: 1.046314]\n",
      "epoch:24 step:22990 [D loss: 0.572550, acc.: 70.31%] [G loss: 0.921728]\n",
      "epoch:24 step:22991 [D loss: 0.528059, acc.: 67.97%] [G loss: 1.118068]\n",
      "epoch:24 step:22992 [D loss: 0.445906, acc.: 82.81%] [G loss: 1.029044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22993 [D loss: 0.437846, acc.: 87.50%] [G loss: 1.122973]\n",
      "epoch:24 step:22994 [D loss: 0.662981, acc.: 59.38%] [G loss: 1.125298]\n",
      "epoch:24 step:22995 [D loss: 0.524996, acc.: 75.78%] [G loss: 1.090494]\n",
      "epoch:24 step:22996 [D loss: 0.458852, acc.: 87.50%] [G loss: 1.158792]\n",
      "epoch:24 step:22997 [D loss: 0.650272, acc.: 57.81%] [G loss: 1.146370]\n",
      "epoch:24 step:22998 [D loss: 0.686657, acc.: 61.72%] [G loss: 1.123164]\n",
      "epoch:24 step:22999 [D loss: 0.618743, acc.: 60.16%] [G loss: 1.073709]\n",
      "epoch:24 step:23000 [D loss: 0.582616, acc.: 68.75%] [G loss: 1.103442]\n",
      "epoch:24 step:23001 [D loss: 0.472894, acc.: 79.69%] [G loss: 1.058207]\n",
      "epoch:24 step:23002 [D loss: 0.489051, acc.: 78.91%] [G loss: 1.366791]\n",
      "epoch:24 step:23003 [D loss: 0.514347, acc.: 71.88%] [G loss: 1.103106]\n",
      "epoch:24 step:23004 [D loss: 0.665080, acc.: 59.38%] [G loss: 1.157365]\n",
      "epoch:24 step:23005 [D loss: 0.446721, acc.: 79.69%] [G loss: 1.109275]\n",
      "epoch:24 step:23006 [D loss: 0.563598, acc.: 71.09%] [G loss: 1.091943]\n",
      "epoch:24 step:23007 [D loss: 0.538653, acc.: 73.44%] [G loss: 1.168042]\n",
      "epoch:24 step:23008 [D loss: 0.470385, acc.: 85.16%] [G loss: 1.429810]\n",
      "epoch:24 step:23009 [D loss: 0.595960, acc.: 73.44%] [G loss: 1.231370]\n",
      "epoch:24 step:23010 [D loss: 0.493326, acc.: 78.91%] [G loss: 1.120744]\n",
      "epoch:24 step:23011 [D loss: 0.611093, acc.: 62.50%] [G loss: 1.135802]\n",
      "epoch:24 step:23012 [D loss: 0.505446, acc.: 75.78%] [G loss: 1.117491]\n",
      "epoch:24 step:23013 [D loss: 0.626301, acc.: 63.28%] [G loss: 1.225988]\n",
      "epoch:24 step:23014 [D loss: 0.634104, acc.: 63.28%] [G loss: 1.114772]\n",
      "epoch:24 step:23015 [D loss: 0.596252, acc.: 69.53%] [G loss: 1.179494]\n",
      "epoch:24 step:23016 [D loss: 0.566521, acc.: 75.78%] [G loss: 1.163975]\n",
      "epoch:24 step:23017 [D loss: 0.648185, acc.: 63.28%] [G loss: 1.174583]\n",
      "epoch:24 step:23018 [D loss: 0.503823, acc.: 72.66%] [G loss: 1.149802]\n",
      "epoch:24 step:23019 [D loss: 0.674180, acc.: 57.03%] [G loss: 1.228656]\n",
      "epoch:24 step:23020 [D loss: 0.627794, acc.: 64.84%] [G loss: 1.133594]\n",
      "epoch:24 step:23021 [D loss: 0.503873, acc.: 79.69%] [G loss: 0.967234]\n",
      "epoch:24 step:23022 [D loss: 0.586712, acc.: 65.62%] [G loss: 1.375562]\n",
      "epoch:24 step:23023 [D loss: 0.410432, acc.: 88.28%] [G loss: 1.211169]\n",
      "epoch:24 step:23024 [D loss: 0.334001, acc.: 84.38%] [G loss: 0.910437]\n",
      "epoch:24 step:23025 [D loss: 0.460462, acc.: 85.94%] [G loss: 1.076717]\n",
      "epoch:24 step:23026 [D loss: 0.458318, acc.: 83.59%] [G loss: 1.313191]\n",
      "epoch:24 step:23027 [D loss: 0.430221, acc.: 79.69%] [G loss: 1.308667]\n",
      "epoch:24 step:23028 [D loss: 0.537887, acc.: 71.09%] [G loss: 1.179349]\n",
      "epoch:24 step:23029 [D loss: 0.555301, acc.: 77.34%] [G loss: 1.390380]\n",
      "epoch:24 step:23030 [D loss: 0.802613, acc.: 48.44%] [G loss: 1.113948]\n",
      "epoch:24 step:23031 [D loss: 0.426227, acc.: 80.47%] [G loss: 1.326997]\n",
      "epoch:24 step:23032 [D loss: 0.634469, acc.: 60.94%] [G loss: 1.282584]\n",
      "epoch:24 step:23033 [D loss: 0.570317, acc.: 68.75%] [G loss: 1.235937]\n",
      "epoch:24 step:23034 [D loss: 0.806810, acc.: 50.78%] [G loss: 1.259342]\n",
      "epoch:24 step:23035 [D loss: 0.549904, acc.: 74.22%] [G loss: 1.248537]\n",
      "epoch:24 step:23036 [D loss: 0.390562, acc.: 87.50%] [G loss: 1.127793]\n",
      "epoch:24 step:23037 [D loss: 0.432127, acc.: 80.47%] [G loss: 0.723787]\n",
      "epoch:24 step:23038 [D loss: 0.260613, acc.: 91.41%] [G loss: 1.679759]\n",
      "epoch:24 step:23039 [D loss: 0.475421, acc.: 75.78%] [G loss: 1.509578]\n",
      "epoch:24 step:23040 [D loss: 0.406689, acc.: 88.28%] [G loss: 1.759904]\n",
      "epoch:24 step:23041 [D loss: 0.603955, acc.: 69.53%] [G loss: 1.524416]\n",
      "epoch:24 step:23042 [D loss: 0.218124, acc.: 95.31%] [G loss: 1.759908]\n",
      "epoch:24 step:23043 [D loss: 0.338040, acc.: 89.06%] [G loss: 1.097687]\n",
      "epoch:24 step:23044 [D loss: 0.189523, acc.: 96.09%] [G loss: 1.249866]\n",
      "epoch:24 step:23045 [D loss: 0.175322, acc.: 99.22%] [G loss: 1.352167]\n",
      "epoch:24 step:23046 [D loss: 0.271474, acc.: 96.88%] [G loss: 1.146516]\n",
      "epoch:24 step:23047 [D loss: 1.068435, acc.: 42.19%] [G loss: 1.633434]\n",
      "epoch:24 step:23048 [D loss: 0.598480, acc.: 68.75%] [G loss: 1.482823]\n",
      "epoch:24 step:23049 [D loss: 0.256583, acc.: 94.53%] [G loss: 1.586652]\n",
      "epoch:24 step:23050 [D loss: 0.865294, acc.: 49.22%] [G loss: 1.493138]\n",
      "epoch:24 step:23051 [D loss: 0.915702, acc.: 43.75%] [G loss: 1.072229]\n",
      "epoch:24 step:23052 [D loss: 0.898330, acc.: 37.50%] [G loss: 1.382106]\n",
      "epoch:24 step:23053 [D loss: 0.756201, acc.: 42.19%] [G loss: 1.357828]\n",
      "epoch:24 step:23054 [D loss: 0.355044, acc.: 88.28%] [G loss: 1.351784]\n",
      "epoch:24 step:23055 [D loss: 0.216210, acc.: 96.09%] [G loss: 1.558885]\n",
      "epoch:24 step:23056 [D loss: 0.655645, acc.: 64.06%] [G loss: 1.690662]\n",
      "epoch:24 step:23057 [D loss: 0.744251, acc.: 55.47%] [G loss: 1.457165]\n",
      "epoch:24 step:23058 [D loss: 0.534619, acc.: 76.56%] [G loss: 1.312815]\n",
      "epoch:24 step:23059 [D loss: 0.740906, acc.: 53.12%] [G loss: 1.323661]\n",
      "epoch:24 step:23060 [D loss: 0.459707, acc.: 85.16%] [G loss: 1.287017]\n",
      "epoch:24 step:23061 [D loss: 0.453100, acc.: 83.59%] [G loss: 1.252402]\n",
      "epoch:24 step:23062 [D loss: 0.620781, acc.: 65.62%] [G loss: 1.219593]\n",
      "epoch:24 step:23063 [D loss: 0.397973, acc.: 85.16%] [G loss: 1.429502]\n",
      "epoch:24 step:23064 [D loss: 0.330931, acc.: 86.72%] [G loss: 1.355761]\n",
      "epoch:24 step:23065 [D loss: 0.312717, acc.: 88.28%] [G loss: 1.286447]\n",
      "epoch:24 step:23066 [D loss: 0.298269, acc.: 89.06%] [G loss: 1.555910]\n",
      "epoch:24 step:23067 [D loss: 0.250148, acc.: 94.53%] [G loss: 1.776384]\n",
      "epoch:24 step:23068 [D loss: 0.712033, acc.: 59.38%] [G loss: 1.867453]\n",
      "epoch:24 step:23069 [D loss: 0.662694, acc.: 58.59%] [G loss: 1.342793]\n",
      "epoch:24 step:23070 [D loss: 0.673412, acc.: 57.81%] [G loss: 1.152742]\n",
      "epoch:24 step:23071 [D loss: 0.635221, acc.: 63.28%] [G loss: 1.207904]\n",
      "epoch:24 step:23072 [D loss: 0.806060, acc.: 47.66%] [G loss: 1.010463]\n",
      "epoch:24 step:23073 [D loss: 0.661697, acc.: 58.59%] [G loss: 1.036332]\n",
      "epoch:24 step:23074 [D loss: 0.664209, acc.: 59.38%] [G loss: 1.184892]\n",
      "epoch:24 step:23075 [D loss: 0.319528, acc.: 82.03%] [G loss: 1.170700]\n",
      "epoch:24 step:23076 [D loss: 0.244605, acc.: 89.84%] [G loss: 1.750505]\n",
      "epoch:24 step:23077 [D loss: 0.189801, acc.: 92.97%] [G loss: 1.862216]\n",
      "epoch:24 step:23078 [D loss: 0.497403, acc.: 78.12%] [G loss: 1.716052]\n",
      "epoch:24 step:23079 [D loss: 0.670561, acc.: 66.41%] [G loss: 1.382234]\n",
      "epoch:24 step:23080 [D loss: 0.710479, acc.: 57.03%] [G loss: 1.317477]\n",
      "epoch:24 step:23081 [D loss: 0.664893, acc.: 60.94%] [G loss: 1.266539]\n",
      "epoch:24 step:23082 [D loss: 0.324950, acc.: 91.41%] [G loss: 1.389245]\n",
      "epoch:24 step:23083 [D loss: 0.275482, acc.: 93.75%] [G loss: 1.386870]\n",
      "epoch:24 step:23084 [D loss: 0.544753, acc.: 75.00%] [G loss: 1.184601]\n",
      "epoch:24 step:23085 [D loss: 0.853291, acc.: 46.09%] [G loss: 1.187205]\n",
      "epoch:24 step:23086 [D loss: 0.732424, acc.: 51.56%] [G loss: 0.845231]\n",
      "epoch:24 step:23087 [D loss: 0.666233, acc.: 58.59%] [G loss: 0.912952]\n",
      "epoch:24 step:23088 [D loss: 0.322093, acc.: 81.25%] [G loss: 0.856654]\n",
      "epoch:24 step:23089 [D loss: 0.346086, acc.: 81.25%] [G loss: 1.059040]\n",
      "epoch:24 step:23090 [D loss: 0.419983, acc.: 84.38%] [G loss: 1.197255]\n",
      "epoch:24 step:23091 [D loss: 0.848669, acc.: 47.66%] [G loss: 1.161458]\n",
      "epoch:24 step:23092 [D loss: 0.430858, acc.: 82.03%] [G loss: 1.043194]\n",
      "epoch:24 step:23093 [D loss: 0.803856, acc.: 45.31%] [G loss: 0.901838]\n",
      "epoch:24 step:23094 [D loss: 0.418245, acc.: 84.38%] [G loss: 1.286897]\n",
      "epoch:24 step:23095 [D loss: 0.472448, acc.: 74.22%] [G loss: 1.227726]\n",
      "epoch:24 step:23096 [D loss: 0.623300, acc.: 56.25%] [G loss: 1.175862]\n",
      "epoch:24 step:23097 [D loss: 0.245307, acc.: 92.19%] [G loss: 1.317240]\n",
      "epoch:24 step:23098 [D loss: 0.518309, acc.: 68.75%] [G loss: 0.997873]\n",
      "epoch:24 step:23099 [D loss: 0.315292, acc.: 82.81%] [G loss: 1.528637]\n",
      "epoch:24 step:23100 [D loss: 0.195491, acc.: 98.44%] [G loss: 1.685572]\n",
      "epoch:24 step:23101 [D loss: 1.095208, acc.: 23.44%] [G loss: 1.531484]\n",
      "epoch:24 step:23102 [D loss: 0.892218, acc.: 46.09%] [G loss: 0.977250]\n",
      "epoch:24 step:23103 [D loss: 0.873222, acc.: 45.31%] [G loss: 0.875068]\n",
      "epoch:24 step:23104 [D loss: 0.876301, acc.: 45.31%] [G loss: 0.837817]\n",
      "epoch:24 step:23105 [D loss: 0.722630, acc.: 53.12%] [G loss: 1.144375]\n",
      "epoch:24 step:23106 [D loss: 0.554318, acc.: 74.22%] [G loss: 1.221992]\n",
      "epoch:24 step:23107 [D loss: 0.715198, acc.: 61.72%] [G loss: 0.797778]\n",
      "epoch:24 step:23108 [D loss: 0.620909, acc.: 64.84%] [G loss: 1.242326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23109 [D loss: 0.742822, acc.: 51.56%] [G loss: 0.977686]\n",
      "epoch:24 step:23110 [D loss: 0.646044, acc.: 57.03%] [G loss: 1.066433]\n",
      "epoch:24 step:23111 [D loss: 0.690350, acc.: 55.47%] [G loss: 1.166268]\n",
      "epoch:24 step:23112 [D loss: 0.666810, acc.: 54.69%] [G loss: 1.255031]\n",
      "epoch:24 step:23113 [D loss: 0.694958, acc.: 59.38%] [G loss: 1.467797]\n",
      "epoch:24 step:23114 [D loss: 0.639543, acc.: 59.38%] [G loss: 0.893009]\n",
      "epoch:24 step:23115 [D loss: 0.670383, acc.: 56.25%] [G loss: 0.832059]\n",
      "epoch:24 step:23116 [D loss: 0.775141, acc.: 47.66%] [G loss: 0.932239]\n",
      "epoch:24 step:23117 [D loss: 0.661883, acc.: 60.94%] [G loss: 1.316530]\n",
      "epoch:24 step:23118 [D loss: 0.508619, acc.: 71.09%] [G loss: 1.401355]\n",
      "epoch:24 step:23119 [D loss: 0.618708, acc.: 63.28%] [G loss: 1.510918]\n",
      "epoch:24 step:23120 [D loss: 0.411035, acc.: 85.94%] [G loss: 1.399673]\n",
      "epoch:24 step:23121 [D loss: 0.308185, acc.: 90.62%] [G loss: 1.364941]\n",
      "epoch:24 step:23122 [D loss: 0.303764, acc.: 91.41%] [G loss: 1.648012]\n",
      "epoch:24 step:23123 [D loss: 0.236293, acc.: 99.22%] [G loss: 1.801224]\n",
      "epoch:24 step:23124 [D loss: 0.520216, acc.: 70.31%] [G loss: 1.595542]\n",
      "epoch:24 step:23125 [D loss: 0.464574, acc.: 76.56%] [G loss: 1.730554]\n",
      "epoch:24 step:23126 [D loss: 0.360790, acc.: 86.72%] [G loss: 1.689494]\n",
      "epoch:24 step:23127 [D loss: 0.640330, acc.: 56.25%] [G loss: 1.174468]\n",
      "epoch:24 step:23128 [D loss: 0.745437, acc.: 54.69%] [G loss: 1.127752]\n",
      "epoch:24 step:23129 [D loss: 0.843533, acc.: 50.78%] [G loss: 0.794134]\n",
      "epoch:24 step:23130 [D loss: 0.713980, acc.: 54.69%] [G loss: 1.006068]\n",
      "epoch:24 step:23131 [D loss: 0.554993, acc.: 68.75%] [G loss: 0.959890]\n",
      "epoch:24 step:23132 [D loss: 0.295589, acc.: 87.50%] [G loss: 1.293244]\n",
      "epoch:24 step:23133 [D loss: 0.331362, acc.: 87.50%] [G loss: 1.383880]\n",
      "epoch:24 step:23134 [D loss: 0.177123, acc.: 97.66%] [G loss: 1.139526]\n",
      "epoch:24 step:23135 [D loss: 0.283256, acc.: 92.19%] [G loss: 1.179787]\n",
      "epoch:24 step:23136 [D loss: 0.158547, acc.: 100.00%] [G loss: 1.766439]\n",
      "epoch:24 step:23137 [D loss: 0.352765, acc.: 91.41%] [G loss: 1.330933]\n",
      "epoch:24 step:23138 [D loss: 0.170436, acc.: 98.44%] [G loss: 1.688254]\n",
      "epoch:24 step:23139 [D loss: 0.307352, acc.: 96.88%] [G loss: 1.867399]\n",
      "epoch:24 step:23140 [D loss: 0.738114, acc.: 60.16%] [G loss: 1.685512]\n",
      "epoch:24 step:23141 [D loss: 1.009279, acc.: 35.16%] [G loss: 1.252376]\n",
      "epoch:24 step:23142 [D loss: 0.820531, acc.: 45.31%] [G loss: 1.378170]\n",
      "epoch:24 step:23143 [D loss: 0.545468, acc.: 75.78%] [G loss: 1.010252]\n",
      "epoch:24 step:23144 [D loss: 0.577361, acc.: 69.53%] [G loss: 1.186546]\n",
      "epoch:24 step:23145 [D loss: 0.656484, acc.: 57.03%] [G loss: 1.251953]\n",
      "epoch:24 step:23146 [D loss: 0.857605, acc.: 42.97%] [G loss: 1.317262]\n",
      "epoch:24 step:23147 [D loss: 0.304156, acc.: 93.75%] [G loss: 1.305140]\n",
      "epoch:24 step:23148 [D loss: 0.336394, acc.: 94.53%] [G loss: 0.808549]\n",
      "epoch:24 step:23149 [D loss: 0.406506, acc.: 82.03%] [G loss: 1.380388]\n",
      "epoch:24 step:23150 [D loss: 0.675803, acc.: 55.47%] [G loss: 1.127289]\n",
      "epoch:24 step:23151 [D loss: 0.660001, acc.: 60.94%] [G loss: 1.009293]\n",
      "epoch:24 step:23152 [D loss: 0.678747, acc.: 56.25%] [G loss: 0.912308]\n",
      "epoch:24 step:23153 [D loss: 0.637727, acc.: 62.50%] [G loss: 1.697486]\n",
      "epoch:24 step:23154 [D loss: 0.721913, acc.: 61.72%] [G loss: 1.384087]\n",
      "epoch:24 step:23155 [D loss: 0.756861, acc.: 49.22%] [G loss: 1.116238]\n",
      "epoch:24 step:23156 [D loss: 0.708688, acc.: 54.69%] [G loss: 1.353625]\n",
      "epoch:24 step:23157 [D loss: 0.683690, acc.: 58.59%] [G loss: 1.007473]\n",
      "epoch:24 step:23158 [D loss: 0.686266, acc.: 57.81%] [G loss: 0.812741]\n",
      "epoch:24 step:23159 [D loss: 0.605819, acc.: 61.72%] [G loss: 1.182517]\n",
      "epoch:24 step:23160 [D loss: 0.656346, acc.: 61.72%] [G loss: 1.407530]\n",
      "epoch:24 step:23161 [D loss: 0.789485, acc.: 53.12%] [G loss: 0.973529]\n",
      "epoch:24 step:23162 [D loss: 0.485763, acc.: 76.56%] [G loss: 1.021490]\n",
      "epoch:24 step:23163 [D loss: 0.695592, acc.: 58.59%] [G loss: 0.985550]\n",
      "epoch:24 step:23164 [D loss: 0.680294, acc.: 57.81%] [G loss: 0.586923]\n",
      "epoch:24 step:23165 [D loss: 0.591554, acc.: 66.41%] [G loss: 0.941844]\n",
      "epoch:24 step:23166 [D loss: 0.572595, acc.: 69.53%] [G loss: 0.798038]\n",
      "epoch:24 step:23167 [D loss: 0.640255, acc.: 60.94%] [G loss: 1.042594]\n",
      "epoch:24 step:23168 [D loss: 0.615458, acc.: 65.62%] [G loss: 0.969487]\n",
      "epoch:24 step:23169 [D loss: 0.667979, acc.: 64.06%] [G loss: 1.027914]\n",
      "epoch:24 step:23170 [D loss: 0.747828, acc.: 43.75%] [G loss: 0.983207]\n",
      "epoch:24 step:23171 [D loss: 0.609742, acc.: 66.41%] [G loss: 1.228078]\n",
      "epoch:24 step:23172 [D loss: 0.628001, acc.: 59.38%] [G loss: 0.849831]\n",
      "epoch:24 step:23173 [D loss: 0.541546, acc.: 72.66%] [G loss: 1.102503]\n",
      "epoch:24 step:23174 [D loss: 0.565186, acc.: 73.44%] [G loss: 1.097296]\n",
      "epoch:24 step:23175 [D loss: 0.614240, acc.: 61.72%] [G loss: 1.186709]\n",
      "epoch:24 step:23176 [D loss: 0.735064, acc.: 55.47%] [G loss: 1.107356]\n",
      "epoch:24 step:23177 [D loss: 0.673281, acc.: 61.72%] [G loss: 1.261741]\n",
      "epoch:24 step:23178 [D loss: 0.531468, acc.: 74.22%] [G loss: 0.956090]\n",
      "epoch:24 step:23179 [D loss: 0.528601, acc.: 77.34%] [G loss: 1.049438]\n",
      "epoch:24 step:23180 [D loss: 0.626181, acc.: 67.97%] [G loss: 0.971423]\n",
      "epoch:24 step:23181 [D loss: 0.646942, acc.: 63.28%] [G loss: 0.986796]\n",
      "epoch:24 step:23182 [D loss: 0.462807, acc.: 80.47%] [G loss: 1.020556]\n",
      "epoch:24 step:23183 [D loss: 0.713714, acc.: 57.81%] [G loss: 1.072497]\n",
      "epoch:24 step:23184 [D loss: 0.387810, acc.: 75.78%] [G loss: 1.246509]\n",
      "epoch:24 step:23185 [D loss: 0.252270, acc.: 89.84%] [G loss: 0.838840]\n",
      "epoch:24 step:23186 [D loss: 0.287478, acc.: 94.53%] [G loss: 1.256442]\n",
      "epoch:24 step:23187 [D loss: 0.437587, acc.: 87.50%] [G loss: 1.474736]\n",
      "epoch:24 step:23188 [D loss: 0.467468, acc.: 81.25%] [G loss: 1.314631]\n",
      "epoch:24 step:23189 [D loss: 0.252044, acc.: 93.75%] [G loss: 1.660645]\n",
      "epoch:24 step:23190 [D loss: 0.242249, acc.: 94.53%] [G loss: 1.756251]\n",
      "epoch:24 step:23191 [D loss: 0.575993, acc.: 72.66%] [G loss: 1.511318]\n",
      "epoch:24 step:23192 [D loss: 0.410495, acc.: 85.94%] [G loss: 1.415233]\n",
      "epoch:24 step:23193 [D loss: 0.617764, acc.: 67.19%] [G loss: 1.395083]\n",
      "epoch:24 step:23194 [D loss: 0.249423, acc.: 96.88%] [G loss: 1.356216]\n",
      "epoch:24 step:23195 [D loss: 0.203624, acc.: 94.53%] [G loss: 1.528360]\n",
      "epoch:24 step:23196 [D loss: 0.144270, acc.: 98.44%] [G loss: 1.939903]\n",
      "epoch:24 step:23197 [D loss: 0.148120, acc.: 95.31%] [G loss: 1.497233]\n",
      "epoch:24 step:23198 [D loss: 1.095692, acc.: 51.56%] [G loss: 1.622775]\n",
      "epoch:24 step:23199 [D loss: 0.816628, acc.: 55.47%] [G loss: 1.027743]\n",
      "epoch:24 step:23200 [D loss: 0.486242, acc.: 82.81%] [G loss: 1.127850]\n",
      "epoch:24 step:23201 [D loss: 0.242561, acc.: 89.84%] [G loss: 1.248930]\n",
      "epoch:24 step:23202 [D loss: 0.192787, acc.: 96.09%] [G loss: 1.265923]\n",
      "epoch:24 step:23203 [D loss: 0.713922, acc.: 58.59%] [G loss: 1.080628]\n",
      "epoch:24 step:23204 [D loss: 0.662897, acc.: 57.03%] [G loss: 0.893604]\n",
      "epoch:24 step:23205 [D loss: 0.618925, acc.: 71.09%] [G loss: 1.144372]\n",
      "epoch:24 step:23206 [D loss: 0.664514, acc.: 60.16%] [G loss: 0.919241]\n",
      "epoch:24 step:23207 [D loss: 0.701322, acc.: 58.59%] [G loss: 1.032772]\n",
      "epoch:24 step:23208 [D loss: 0.797484, acc.: 47.66%] [G loss: 0.754406]\n",
      "epoch:24 step:23209 [D loss: 0.684518, acc.: 56.25%] [G loss: 1.005099]\n",
      "epoch:24 step:23210 [D loss: 0.534986, acc.: 64.84%] [G loss: 1.344690]\n",
      "epoch:24 step:23211 [D loss: 0.240825, acc.: 96.09%] [G loss: 1.485392]\n",
      "epoch:24 step:23212 [D loss: 0.824911, acc.: 50.78%] [G loss: 1.696541]\n",
      "epoch:24 step:23213 [D loss: 0.874436, acc.: 51.56%] [G loss: 1.272915]\n",
      "epoch:24 step:23214 [D loss: 0.762107, acc.: 50.78%] [G loss: 0.925648]\n",
      "epoch:24 step:23215 [D loss: 0.312173, acc.: 83.59%] [G loss: 1.223770]\n",
      "epoch:24 step:23216 [D loss: 0.227181, acc.: 95.31%] [G loss: 1.267068]\n",
      "epoch:24 step:23217 [D loss: 0.268306, acc.: 87.50%] [G loss: 1.709315]\n",
      "epoch:24 step:23218 [D loss: 0.321185, acc.: 85.94%] [G loss: 1.662419]\n",
      "epoch:24 step:23219 [D loss: 0.196594, acc.: 94.53%] [G loss: 1.946340]\n",
      "epoch:24 step:23220 [D loss: 0.139721, acc.: 99.22%] [G loss: 2.163309]\n",
      "epoch:24 step:23221 [D loss: 0.132683, acc.: 100.00%] [G loss: 1.803384]\n",
      "epoch:24 step:23222 [D loss: 0.763658, acc.: 53.91%] [G loss: 1.605430]\n",
      "epoch:24 step:23223 [D loss: 0.886966, acc.: 51.56%] [G loss: 1.112593]\n",
      "epoch:24 step:23224 [D loss: 0.754461, acc.: 53.91%] [G loss: 1.189949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23225 [D loss: 0.712266, acc.: 54.69%] [G loss: 1.114260]\n",
      "epoch:24 step:23226 [D loss: 0.465643, acc.: 85.16%] [G loss: 1.390843]\n",
      "epoch:24 step:23227 [D loss: 0.586123, acc.: 67.19%] [G loss: 0.911847]\n",
      "epoch:24 step:23228 [D loss: 0.417488, acc.: 85.94%] [G loss: 0.856905]\n",
      "epoch:24 step:23229 [D loss: 1.025794, acc.: 21.09%] [G loss: 0.445543]\n",
      "epoch:24 step:23230 [D loss: 0.762994, acc.: 59.38%] [G loss: 1.035015]\n",
      "epoch:24 step:23231 [D loss: 0.849630, acc.: 37.50%] [G loss: 0.943255]\n",
      "epoch:24 step:23232 [D loss: 0.930734, acc.: 29.69%] [G loss: 1.450380]\n",
      "epoch:24 step:23233 [D loss: 0.278830, acc.: 96.09%] [G loss: 1.241053]\n",
      "epoch:24 step:23234 [D loss: 0.472335, acc.: 83.59%] [G loss: 1.590298]\n",
      "epoch:24 step:23235 [D loss: 0.606184, acc.: 64.06%] [G loss: 1.489449]\n",
      "epoch:24 step:23236 [D loss: 0.706573, acc.: 57.03%] [G loss: 1.089538]\n",
      "epoch:24 step:23237 [D loss: 0.739485, acc.: 52.34%] [G loss: 1.196755]\n",
      "epoch:24 step:23238 [D loss: 1.101713, acc.: 36.72%] [G loss: 1.349808]\n",
      "epoch:24 step:23239 [D loss: 0.754342, acc.: 57.81%] [G loss: 1.425989]\n",
      "epoch:24 step:23240 [D loss: 0.781856, acc.: 50.00%] [G loss: 0.945906]\n",
      "epoch:24 step:23241 [D loss: 0.673572, acc.: 61.72%] [G loss: 1.162445]\n",
      "epoch:24 step:23242 [D loss: 0.442007, acc.: 84.38%] [G loss: 1.201767]\n",
      "epoch:24 step:23243 [D loss: 0.402006, acc.: 85.16%] [G loss: 1.095541]\n",
      "epoch:24 step:23244 [D loss: 0.467915, acc.: 82.03%] [G loss: 1.100631]\n",
      "epoch:24 step:23245 [D loss: 0.499238, acc.: 79.69%] [G loss: 1.048811]\n",
      "epoch:24 step:23246 [D loss: 0.857280, acc.: 39.06%] [G loss: 1.027225]\n",
      "epoch:24 step:23247 [D loss: 0.596208, acc.: 69.53%] [G loss: 1.240388]\n",
      "epoch:24 step:23248 [D loss: 0.636364, acc.: 56.25%] [G loss: 1.228414]\n",
      "epoch:24 step:23249 [D loss: 0.701262, acc.: 57.03%] [G loss: 0.920023]\n",
      "epoch:24 step:23250 [D loss: 0.711942, acc.: 61.72%] [G loss: 1.101453]\n",
      "epoch:24 step:23251 [D loss: 0.594513, acc.: 67.19%] [G loss: 0.958287]\n",
      "epoch:24 step:23252 [D loss: 0.598834, acc.: 67.19%] [G loss: 1.042710]\n",
      "epoch:24 step:23253 [D loss: 0.674253, acc.: 48.44%] [G loss: 1.185063]\n",
      "epoch:24 step:23254 [D loss: 0.623369, acc.: 64.06%] [G loss: 1.205253]\n",
      "epoch:24 step:23255 [D loss: 0.635494, acc.: 63.28%] [G loss: 1.109172]\n",
      "epoch:24 step:23256 [D loss: 0.393339, acc.: 90.62%] [G loss: 1.481125]\n",
      "epoch:24 step:23257 [D loss: 0.379352, acc.: 90.62%] [G loss: 1.607552]\n",
      "epoch:24 step:23258 [D loss: 0.518620, acc.: 68.75%] [G loss: 1.335159]\n",
      "epoch:24 step:23259 [D loss: 0.726519, acc.: 54.69%] [G loss: 1.189706]\n",
      "epoch:24 step:23260 [D loss: 0.641477, acc.: 58.59%] [G loss: 0.935324]\n",
      "epoch:24 step:23261 [D loss: 0.467033, acc.: 82.03%] [G loss: 1.079902]\n",
      "epoch:24 step:23262 [D loss: 0.286514, acc.: 94.53%] [G loss: 1.360838]\n",
      "epoch:24 step:23263 [D loss: 0.318454, acc.: 95.31%] [G loss: 1.404425]\n",
      "epoch:24 step:23264 [D loss: 0.464440, acc.: 78.91%] [G loss: 1.794287]\n",
      "epoch:24 step:23265 [D loss: 0.344168, acc.: 97.66%] [G loss: 1.159851]\n",
      "epoch:24 step:23266 [D loss: 0.538515, acc.: 74.22%] [G loss: 1.470078]\n",
      "epoch:24 step:23267 [D loss: 0.964272, acc.: 39.06%] [G loss: 0.903046]\n",
      "epoch:24 step:23268 [D loss: 0.900001, acc.: 44.53%] [G loss: 0.916126]\n",
      "epoch:24 step:23269 [D loss: 0.639708, acc.: 64.06%] [G loss: 0.875270]\n",
      "epoch:24 step:23270 [D loss: 0.600579, acc.: 61.72%] [G loss: 0.849264]\n",
      "epoch:24 step:23271 [D loss: 0.953580, acc.: 41.41%] [G loss: 0.980553]\n",
      "epoch:24 step:23272 [D loss: 0.642486, acc.: 64.84%] [G loss: 1.054859]\n",
      "epoch:24 step:23273 [D loss: 0.607291, acc.: 64.84%] [G loss: 1.009993]\n",
      "epoch:24 step:23274 [D loss: 0.658511, acc.: 64.06%] [G loss: 0.829055]\n",
      "epoch:24 step:23275 [D loss: 0.640346, acc.: 65.62%] [G loss: 0.865869]\n",
      "epoch:24 step:23276 [D loss: 0.556787, acc.: 71.09%] [G loss: 1.054502]\n",
      "epoch:24 step:23277 [D loss: 0.751654, acc.: 50.00%] [G loss: 1.042800]\n",
      "epoch:24 step:23278 [D loss: 0.640247, acc.: 64.06%] [G loss: 0.919036]\n",
      "epoch:24 step:23279 [D loss: 0.661116, acc.: 53.91%] [G loss: 0.895603]\n",
      "epoch:24 step:23280 [D loss: 0.524789, acc.: 75.78%] [G loss: 0.791907]\n",
      "epoch:24 step:23281 [D loss: 0.470023, acc.: 79.69%] [G loss: 0.824522]\n",
      "epoch:24 step:23282 [D loss: 0.462109, acc.: 83.59%] [G loss: 1.082720]\n",
      "epoch:24 step:23283 [D loss: 0.627928, acc.: 64.06%] [G loss: 1.125608]\n",
      "epoch:24 step:23284 [D loss: 0.469467, acc.: 79.69%] [G loss: 1.284575]\n",
      "epoch:24 step:23285 [D loss: 0.597189, acc.: 68.75%] [G loss: 0.967877]\n",
      "epoch:24 step:23286 [D loss: 0.536038, acc.: 71.09%] [G loss: 0.563889]\n",
      "epoch:24 step:23287 [D loss: 0.633057, acc.: 67.19%] [G loss: 1.111816]\n",
      "epoch:24 step:23288 [D loss: 0.487043, acc.: 68.75%] [G loss: 1.118924]\n",
      "epoch:24 step:23289 [D loss: 0.399406, acc.: 81.25%] [G loss: 1.077529]\n",
      "epoch:24 step:23290 [D loss: 0.274197, acc.: 90.62%] [G loss: 1.382898]\n",
      "epoch:24 step:23291 [D loss: 0.446166, acc.: 84.38%] [G loss: 1.463419]\n",
      "epoch:24 step:23292 [D loss: 0.590416, acc.: 67.97%] [G loss: 0.894405]\n",
      "epoch:24 step:23293 [D loss: 0.556269, acc.: 74.22%] [G loss: 1.251796]\n",
      "epoch:24 step:23294 [D loss: 0.477035, acc.: 72.66%] [G loss: 1.209053]\n",
      "epoch:24 step:23295 [D loss: 0.794432, acc.: 48.44%] [G loss: 1.214435]\n",
      "epoch:24 step:23296 [D loss: 0.399601, acc.: 78.91%] [G loss: 1.127645]\n",
      "epoch:24 step:23297 [D loss: 0.413988, acc.: 86.72%] [G loss: 1.172338]\n",
      "epoch:24 step:23298 [D loss: 0.448012, acc.: 85.94%] [G loss: 1.167171]\n",
      "epoch:24 step:23299 [D loss: 0.626362, acc.: 64.06%] [G loss: 1.094559]\n",
      "epoch:24 step:23300 [D loss: 0.664633, acc.: 61.72%] [G loss: 0.992625]\n",
      "epoch:24 step:23301 [D loss: 0.624167, acc.: 59.38%] [G loss: 0.971569]\n",
      "epoch:24 step:23302 [D loss: 0.637892, acc.: 58.59%] [G loss: 0.959765]\n",
      "epoch:24 step:23303 [D loss: 0.261201, acc.: 92.97%] [G loss: 1.139783]\n",
      "epoch:24 step:23304 [D loss: 0.398722, acc.: 86.72%] [G loss: 1.245671]\n",
      "epoch:24 step:23305 [D loss: 0.561536, acc.: 74.22%] [G loss: 1.293309]\n",
      "epoch:24 step:23306 [D loss: 0.475744, acc.: 81.25%] [G loss: 1.129811]\n",
      "epoch:24 step:23307 [D loss: 0.508685, acc.: 77.34%] [G loss: 0.843135]\n",
      "epoch:24 step:23308 [D loss: 0.877022, acc.: 32.81%] [G loss: 0.680408]\n",
      "epoch:24 step:23309 [D loss: 0.827006, acc.: 43.75%] [G loss: 1.147826]\n",
      "epoch:24 step:23310 [D loss: 0.691117, acc.: 60.16%] [G loss: 0.881012]\n",
      "epoch:24 step:23311 [D loss: 0.688620, acc.: 52.34%] [G loss: 1.173003]\n",
      "epoch:24 step:23312 [D loss: 0.524995, acc.: 75.00%] [G loss: 0.982560]\n",
      "epoch:24 step:23313 [D loss: 0.569169, acc.: 65.62%] [G loss: 1.446908]\n",
      "epoch:24 step:23314 [D loss: 0.544772, acc.: 78.12%] [G loss: 0.931170]\n",
      "epoch:24 step:23315 [D loss: 0.728513, acc.: 55.47%] [G loss: 0.632119]\n",
      "epoch:24 step:23316 [D loss: 0.670169, acc.: 58.59%] [G loss: 0.954615]\n",
      "epoch:24 step:23317 [D loss: 0.563669, acc.: 71.09%] [G loss: 0.843739]\n",
      "epoch:24 step:23318 [D loss: 0.848375, acc.: 55.47%] [G loss: 0.911420]\n",
      "epoch:24 step:23319 [D loss: 0.330386, acc.: 93.75%] [G loss: 1.212278]\n",
      "epoch:24 step:23320 [D loss: 0.703959, acc.: 64.06%] [G loss: 1.567565]\n",
      "epoch:24 step:23321 [D loss: 0.374571, acc.: 85.94%] [G loss: 1.422464]\n",
      "epoch:24 step:23322 [D loss: 0.741852, acc.: 58.59%] [G loss: 1.319698]\n",
      "epoch:24 step:23323 [D loss: 0.665167, acc.: 58.59%] [G loss: 1.273215]\n",
      "epoch:24 step:23324 [D loss: 0.744144, acc.: 51.56%] [G loss: 1.068381]\n",
      "epoch:24 step:23325 [D loss: 0.854202, acc.: 35.16%] [G loss: 1.010159]\n",
      "epoch:24 step:23326 [D loss: 0.778570, acc.: 38.28%] [G loss: 0.976507]\n",
      "epoch:24 step:23327 [D loss: 0.613477, acc.: 65.62%] [G loss: 1.156989]\n",
      "epoch:24 step:23328 [D loss: 0.687365, acc.: 62.50%] [G loss: 1.122478]\n",
      "epoch:24 step:23329 [D loss: 0.576204, acc.: 67.97%] [G loss: 1.042970]\n",
      "epoch:24 step:23330 [D loss: 0.417703, acc.: 81.25%] [G loss: 1.257712]\n",
      "epoch:24 step:23331 [D loss: 0.657367, acc.: 60.16%] [G loss: 1.138010]\n",
      "epoch:24 step:23332 [D loss: 0.591152, acc.: 70.31%] [G loss: 1.024574]\n",
      "epoch:24 step:23333 [D loss: 0.447603, acc.: 78.91%] [G loss: 1.133277]\n",
      "epoch:24 step:23334 [D loss: 0.754256, acc.: 52.34%] [G loss: 1.030045]\n",
      "epoch:24 step:23335 [D loss: 0.420710, acc.: 86.72%] [G loss: 1.091085]\n",
      "epoch:24 step:23336 [D loss: 0.760674, acc.: 47.66%] [G loss: 0.970532]\n",
      "epoch:24 step:23337 [D loss: 0.551068, acc.: 70.31%] [G loss: 0.997699]\n",
      "epoch:24 step:23338 [D loss: 0.592287, acc.: 69.53%] [G loss: 1.149666]\n",
      "epoch:24 step:23339 [D loss: 0.325953, acc.: 84.38%] [G loss: 1.364627]\n",
      "epoch:24 step:23340 [D loss: 0.382402, acc.: 82.03%] [G loss: 1.333141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23341 [D loss: 0.377707, acc.: 89.84%] [G loss: 1.505779]\n",
      "epoch:24 step:23342 [D loss: 0.319163, acc.: 85.94%] [G loss: 1.487415]\n",
      "epoch:24 step:23343 [D loss: 0.363273, acc.: 92.97%] [G loss: 1.363487]\n",
      "epoch:24 step:23344 [D loss: 0.659580, acc.: 61.72%] [G loss: 1.204187]\n",
      "epoch:24 step:23345 [D loss: 0.376807, acc.: 81.25%] [G loss: 1.266369]\n",
      "epoch:24 step:23346 [D loss: 0.658644, acc.: 62.50%] [G loss: 1.309753]\n",
      "epoch:24 step:23347 [D loss: 0.601632, acc.: 64.84%] [G loss: 1.191444]\n",
      "epoch:24 step:23348 [D loss: 0.489502, acc.: 75.78%] [G loss: 1.195533]\n",
      "epoch:24 step:23349 [D loss: 0.576554, acc.: 72.66%] [G loss: 1.125039]\n",
      "epoch:24 step:23350 [D loss: 0.737158, acc.: 57.81%] [G loss: 1.050221]\n",
      "epoch:24 step:23351 [D loss: 0.850111, acc.: 39.84%] [G loss: 1.053190]\n",
      "epoch:24 step:23352 [D loss: 0.721091, acc.: 47.66%] [G loss: 1.005927]\n",
      "epoch:24 step:23353 [D loss: 0.628566, acc.: 65.62%] [G loss: 1.147637]\n",
      "epoch:24 step:23354 [D loss: 0.610904, acc.: 66.41%] [G loss: 1.020806]\n",
      "epoch:24 step:23355 [D loss: 0.416246, acc.: 82.81%] [G loss: 1.143736]\n",
      "epoch:24 step:23356 [D loss: 0.665481, acc.: 58.59%] [G loss: 1.265531]\n",
      "epoch:24 step:23357 [D loss: 0.642087, acc.: 62.50%] [G loss: 1.107290]\n",
      "epoch:24 step:23358 [D loss: 0.648612, acc.: 60.94%] [G loss: 1.028461]\n",
      "epoch:24 step:23359 [D loss: 0.539790, acc.: 76.56%] [G loss: 0.932539]\n",
      "epoch:24 step:23360 [D loss: 0.430785, acc.: 85.94%] [G loss: 0.729571]\n",
      "epoch:24 step:23361 [D loss: 0.595766, acc.: 77.34%] [G loss: 1.074181]\n",
      "epoch:24 step:23362 [D loss: 0.591473, acc.: 69.53%] [G loss: 0.763330]\n",
      "epoch:24 step:23363 [D loss: 0.558710, acc.: 70.31%] [G loss: 0.926486]\n",
      "epoch:24 step:23364 [D loss: 0.888120, acc.: 35.16%] [G loss: 0.996464]\n",
      "epoch:24 step:23365 [D loss: 0.695605, acc.: 57.03%] [G loss: 0.839307]\n",
      "epoch:24 step:23366 [D loss: 0.477712, acc.: 82.03%] [G loss: 1.166687]\n",
      "epoch:24 step:23367 [D loss: 0.694588, acc.: 56.25%] [G loss: 1.115284]\n",
      "epoch:24 step:23368 [D loss: 0.539937, acc.: 74.22%] [G loss: 0.710425]\n",
      "epoch:24 step:23369 [D loss: 0.563978, acc.: 78.12%] [G loss: 1.238042]\n",
      "epoch:24 step:23370 [D loss: 0.326278, acc.: 82.81%] [G loss: 1.228307]\n",
      "epoch:24 step:23371 [D loss: 0.353162, acc.: 94.53%] [G loss: 1.285099]\n",
      "epoch:24 step:23372 [D loss: 0.348132, acc.: 78.91%] [G loss: 1.182525]\n",
      "epoch:24 step:23373 [D loss: 0.184065, acc.: 96.88%] [G loss: 0.633509]\n",
      "epoch:24 step:23374 [D loss: 0.260198, acc.: 95.31%] [G loss: 1.638657]\n",
      "epoch:24 step:23375 [D loss: 0.340955, acc.: 81.25%] [G loss: 0.983166]\n",
      "epoch:24 step:23376 [D loss: 0.691265, acc.: 57.81%] [G loss: 1.728897]\n",
      "epoch:24 step:23377 [D loss: 0.410610, acc.: 82.81%] [G loss: 1.852212]\n",
      "epoch:24 step:23378 [D loss: 0.545745, acc.: 67.19%] [G loss: 1.086739]\n",
      "epoch:24 step:23379 [D loss: 1.333917, acc.: 12.50%] [G loss: 1.430865]\n",
      "epoch:24 step:23380 [D loss: 0.694615, acc.: 57.81%] [G loss: 1.429260]\n",
      "epoch:24 step:23381 [D loss: 0.766301, acc.: 52.34%] [G loss: 1.533658]\n",
      "epoch:24 step:23382 [D loss: 0.642827, acc.: 64.84%] [G loss: 0.689207]\n",
      "epoch:24 step:23383 [D loss: 0.583602, acc.: 64.84%] [G loss: 1.315419]\n",
      "epoch:24 step:23384 [D loss: 0.555106, acc.: 71.88%] [G loss: 1.568572]\n",
      "epoch:24 step:23385 [D loss: 0.487062, acc.: 79.69%] [G loss: 1.469992]\n",
      "epoch:24 step:23386 [D loss: 0.279326, acc.: 96.09%] [G loss: 1.890615]\n",
      "epoch:24 step:23387 [D loss: 0.108723, acc.: 99.22%] [G loss: 2.201836]\n",
      "epoch:24 step:23388 [D loss: 0.183992, acc.: 95.31%] [G loss: 1.957980]\n",
      "epoch:24 step:23389 [D loss: 0.329875, acc.: 85.94%] [G loss: 2.187904]\n",
      "epoch:24 step:23390 [D loss: 0.512506, acc.: 69.53%] [G loss: 1.634174]\n",
      "epoch:24 step:23391 [D loss: 0.332899, acc.: 92.19%] [G loss: 1.710055]\n",
      "epoch:24 step:23392 [D loss: 1.120062, acc.: 46.88%] [G loss: 1.358768]\n",
      "epoch:24 step:23393 [D loss: 0.686877, acc.: 61.72%] [G loss: 1.212216]\n",
      "epoch:24 step:23394 [D loss: 0.616910, acc.: 62.50%] [G loss: 0.965853]\n",
      "epoch:24 step:23395 [D loss: 0.629234, acc.: 66.41%] [G loss: 0.754329]\n",
      "epoch:24 step:23396 [D loss: 0.521215, acc.: 75.78%] [G loss: 1.093772]\n",
      "epoch:24 step:23397 [D loss: 0.284560, acc.: 92.19%] [G loss: 1.285642]\n",
      "epoch:24 step:23398 [D loss: 0.898048, acc.: 45.31%] [G loss: 1.190576]\n",
      "epoch:24 step:23399 [D loss: 0.270689, acc.: 89.84%] [G loss: 1.246966]\n",
      "epoch:24 step:23400 [D loss: 0.192618, acc.: 96.09%] [G loss: 1.361598]\n",
      "epoch:24 step:23401 [D loss: 0.414782, acc.: 90.62%] [G loss: 1.070894]\n",
      "epoch:24 step:23402 [D loss: 0.660947, acc.: 59.38%] [G loss: 1.249624]\n",
      "epoch:24 step:23403 [D loss: 0.466420, acc.: 83.59%] [G loss: 1.274759]\n",
      "epoch:24 step:23404 [D loss: 0.773266, acc.: 55.47%] [G loss: 0.996645]\n",
      "epoch:24 step:23405 [D loss: 0.669147, acc.: 55.47%] [G loss: 0.991302]\n",
      "epoch:24 step:23406 [D loss: 0.415370, acc.: 82.03%] [G loss: 0.935696]\n",
      "epoch:24 step:23407 [D loss: 0.290360, acc.: 85.94%] [G loss: 1.186430]\n",
      "epoch:24 step:23408 [D loss: 1.151816, acc.: 17.19%] [G loss: 1.189458]\n",
      "epoch:24 step:23409 [D loss: 0.594445, acc.: 68.75%] [G loss: 1.247108]\n",
      "epoch:24 step:23410 [D loss: 0.438783, acc.: 84.38%] [G loss: 1.116360]\n",
      "epoch:24 step:23411 [D loss: 0.356617, acc.: 92.19%] [G loss: 1.239193]\n",
      "epoch:24 step:23412 [D loss: 0.167681, acc.: 97.66%] [G loss: 1.165014]\n",
      "epoch:24 step:23413 [D loss: 0.224259, acc.: 96.88%] [G loss: 1.445471]\n",
      "epoch:24 step:23414 [D loss: 0.173841, acc.: 97.66%] [G loss: 1.425467]\n",
      "epoch:24 step:23415 [D loss: 0.163211, acc.: 95.31%] [G loss: 2.020099]\n",
      "epoch:24 step:23416 [D loss: 0.726945, acc.: 59.38%] [G loss: 1.626675]\n",
      "epoch:24 step:23417 [D loss: 0.397590, acc.: 86.72%] [G loss: 1.481253]\n",
      "epoch:24 step:23418 [D loss: 0.512433, acc.: 75.00%] [G loss: 1.144131]\n",
      "epoch:24 step:23419 [D loss: 0.319990, acc.: 89.84%] [G loss: 1.473407]\n",
      "epoch:24 step:23420 [D loss: 0.261676, acc.: 93.75%] [G loss: 1.355151]\n",
      "epoch:24 step:23421 [D loss: 0.206531, acc.: 92.19%] [G loss: 1.256443]\n",
      "epoch:24 step:23422 [D loss: 0.292132, acc.: 84.38%] [G loss: 1.213628]\n",
      "epoch:24 step:23423 [D loss: 0.237025, acc.: 95.31%] [G loss: 1.854689]\n",
      "epoch:24 step:23424 [D loss: 0.139773, acc.: 98.44%] [G loss: 1.317464]\n",
      "epoch:24 step:23425 [D loss: 0.188973, acc.: 93.75%] [G loss: 1.372814]\n",
      "epoch:25 step:23426 [D loss: 0.488252, acc.: 78.91%] [G loss: 1.993006]\n",
      "epoch:25 step:23427 [D loss: 0.665492, acc.: 60.94%] [G loss: 1.114626]\n",
      "epoch:25 step:23428 [D loss: 0.548008, acc.: 73.44%] [G loss: 1.679734]\n",
      "epoch:25 step:23429 [D loss: 0.729118, acc.: 54.69%] [G loss: 1.658958]\n",
      "epoch:25 step:23430 [D loss: 0.636527, acc.: 65.62%] [G loss: 1.034777]\n",
      "epoch:25 step:23431 [D loss: 0.617233, acc.: 67.19%] [G loss: 1.435350]\n",
      "epoch:25 step:23432 [D loss: 0.397831, acc.: 79.69%] [G loss: 0.632591]\n",
      "epoch:25 step:23433 [D loss: 0.342826, acc.: 93.75%] [G loss: 0.580911]\n",
      "epoch:25 step:23434 [D loss: 0.196124, acc.: 98.44%] [G loss: 0.822083]\n",
      "epoch:25 step:23435 [D loss: 0.670680, acc.: 60.94%] [G loss: 1.872941]\n",
      "epoch:25 step:23436 [D loss: 1.108769, acc.: 49.22%] [G loss: 2.192758]\n",
      "epoch:25 step:23437 [D loss: 1.029674, acc.: 46.09%] [G loss: 1.992623]\n",
      "epoch:25 step:23438 [D loss: 0.870669, acc.: 50.00%] [G loss: 1.229296]\n",
      "epoch:25 step:23439 [D loss: 1.106422, acc.: 32.81%] [G loss: 0.977614]\n",
      "epoch:25 step:23440 [D loss: 0.418546, acc.: 82.03%] [G loss: 1.175609]\n",
      "epoch:25 step:23441 [D loss: 0.736347, acc.: 56.25%] [G loss: 1.336191]\n",
      "epoch:25 step:23442 [D loss: 0.974326, acc.: 36.72%] [G loss: 1.045564]\n",
      "epoch:25 step:23443 [D loss: 1.162176, acc.: 42.97%] [G loss: 2.165635]\n",
      "epoch:25 step:23444 [D loss: 0.992608, acc.: 40.62%] [G loss: 1.567691]\n",
      "epoch:25 step:23445 [D loss: 0.837653, acc.: 50.00%] [G loss: 1.253301]\n",
      "epoch:25 step:23446 [D loss: 0.920582, acc.: 42.19%] [G loss: 1.756730]\n",
      "epoch:25 step:23447 [D loss: 0.801521, acc.: 45.31%] [G loss: 1.639178]\n",
      "epoch:25 step:23448 [D loss: 0.737495, acc.: 56.25%] [G loss: 1.144886]\n",
      "epoch:25 step:23449 [D loss: 0.937983, acc.: 39.84%] [G loss: 1.093744]\n",
      "epoch:25 step:23450 [D loss: 0.684648, acc.: 58.59%] [G loss: 1.549243]\n",
      "epoch:25 step:23451 [D loss: 0.686014, acc.: 52.34%] [G loss: 1.051161]\n",
      "epoch:25 step:23452 [D loss: 0.640321, acc.: 64.06%] [G loss: 1.365393]\n",
      "epoch:25 step:23453 [D loss: 0.709323, acc.: 50.00%] [G loss: 1.163625]\n",
      "epoch:25 step:23454 [D loss: 0.579306, acc.: 67.97%] [G loss: 1.160811]\n",
      "epoch:25 step:23455 [D loss: 0.582636, acc.: 76.56%] [G loss: 0.953707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23456 [D loss: 0.540013, acc.: 71.09%] [G loss: 1.274064]\n",
      "epoch:25 step:23457 [D loss: 0.399326, acc.: 92.97%] [G loss: 1.094564]\n",
      "epoch:25 step:23458 [D loss: 0.366401, acc.: 92.19%] [G loss: 1.936683]\n",
      "epoch:25 step:23459 [D loss: 0.386875, acc.: 93.75%] [G loss: 1.600599]\n",
      "epoch:25 step:23460 [D loss: 0.304803, acc.: 95.31%] [G loss: 1.991025]\n",
      "epoch:25 step:23461 [D loss: 0.248467, acc.: 98.44%] [G loss: 1.987194]\n",
      "epoch:25 step:23462 [D loss: 0.871732, acc.: 37.50%] [G loss: 2.083113]\n",
      "epoch:25 step:23463 [D loss: 1.214369, acc.: 28.12%] [G loss: 0.938637]\n",
      "epoch:25 step:23464 [D loss: 0.886682, acc.: 34.38%] [G loss: 0.679302]\n",
      "epoch:25 step:23465 [D loss: 0.777181, acc.: 40.62%] [G loss: 0.689796]\n",
      "epoch:25 step:23466 [D loss: 0.565150, acc.: 67.97%] [G loss: 0.781963]\n",
      "epoch:25 step:23467 [D loss: 0.525876, acc.: 71.09%] [G loss: 0.789347]\n",
      "epoch:25 step:23468 [D loss: 0.541654, acc.: 67.97%] [G loss: 0.914809]\n",
      "epoch:25 step:23469 [D loss: 0.477475, acc.: 81.25%] [G loss: 1.001765]\n",
      "epoch:25 step:23470 [D loss: 0.645158, acc.: 57.81%] [G loss: 0.904340]\n",
      "epoch:25 step:23471 [D loss: 0.527166, acc.: 79.69%] [G loss: 0.881184]\n",
      "epoch:25 step:23472 [D loss: 0.549966, acc.: 76.56%] [G loss: 1.288367]\n",
      "epoch:25 step:23473 [D loss: 0.591624, acc.: 67.97%] [G loss: 0.908128]\n",
      "epoch:25 step:23474 [D loss: 0.518382, acc.: 77.34%] [G loss: 0.856715]\n",
      "epoch:25 step:23475 [D loss: 0.498381, acc.: 73.44%] [G loss: 0.926217]\n",
      "epoch:25 step:23476 [D loss: 0.547148, acc.: 75.00%] [G loss: 1.066473]\n",
      "epoch:25 step:23477 [D loss: 0.543656, acc.: 73.44%] [G loss: 1.036031]\n",
      "epoch:25 step:23478 [D loss: 0.591563, acc.: 64.06%] [G loss: 0.794543]\n",
      "epoch:25 step:23479 [D loss: 0.688610, acc.: 51.56%] [G loss: 0.874875]\n",
      "epoch:25 step:23480 [D loss: 0.556948, acc.: 71.09%] [G loss: 0.922568]\n",
      "epoch:25 step:23481 [D loss: 0.615576, acc.: 65.62%] [G loss: 0.975627]\n",
      "epoch:25 step:23482 [D loss: 0.402219, acc.: 82.03%] [G loss: 0.977842]\n",
      "epoch:25 step:23483 [D loss: 0.471027, acc.: 79.69%] [G loss: 0.952832]\n",
      "epoch:25 step:23484 [D loss: 0.327258, acc.: 92.97%] [G loss: 1.153614]\n",
      "epoch:25 step:23485 [D loss: 0.340110, acc.: 92.19%] [G loss: 1.387587]\n",
      "epoch:25 step:23486 [D loss: 0.556386, acc.: 73.44%] [G loss: 1.241869]\n",
      "epoch:25 step:23487 [D loss: 0.504151, acc.: 77.34%] [G loss: 1.032128]\n",
      "epoch:25 step:23488 [D loss: 0.404495, acc.: 85.16%] [G loss: 0.952699]\n",
      "epoch:25 step:23489 [D loss: 0.623019, acc.: 65.62%] [G loss: 0.899007]\n",
      "epoch:25 step:23490 [D loss: 0.727957, acc.: 52.34%] [G loss: 0.984029]\n",
      "epoch:25 step:23491 [D loss: 0.893451, acc.: 51.56%] [G loss: 1.118151]\n",
      "epoch:25 step:23492 [D loss: 0.492825, acc.: 78.91%] [G loss: 1.116713]\n",
      "epoch:25 step:23493 [D loss: 0.748583, acc.: 54.69%] [G loss: 0.877183]\n",
      "epoch:25 step:23494 [D loss: 0.671769, acc.: 66.41%] [G loss: 1.016738]\n",
      "epoch:25 step:23495 [D loss: 0.911991, acc.: 43.75%] [G loss: 0.868855]\n",
      "epoch:25 step:23496 [D loss: 0.360474, acc.: 80.47%] [G loss: 1.096188]\n",
      "epoch:25 step:23497 [D loss: 0.284479, acc.: 87.50%] [G loss: 1.245668]\n",
      "epoch:25 step:23498 [D loss: 0.498023, acc.: 75.78%] [G loss: 1.388992]\n",
      "epoch:25 step:23499 [D loss: 0.469282, acc.: 80.47%] [G loss: 1.491729]\n",
      "epoch:25 step:23500 [D loss: 0.250195, acc.: 93.75%] [G loss: 1.429336]\n",
      "epoch:25 step:23501 [D loss: 0.206959, acc.: 95.31%] [G loss: 1.707255]\n",
      "epoch:25 step:23502 [D loss: 0.258440, acc.: 94.53%] [G loss: 1.822643]\n",
      "epoch:25 step:23503 [D loss: 0.897649, acc.: 46.09%] [G loss: 1.308728]\n",
      "epoch:25 step:23504 [D loss: 0.611848, acc.: 67.19%] [G loss: 1.093118]\n",
      "epoch:25 step:23505 [D loss: 0.765293, acc.: 57.03%] [G loss: 1.158987]\n",
      "epoch:25 step:23506 [D loss: 0.794574, acc.: 47.66%] [G loss: 1.205577]\n",
      "epoch:25 step:23507 [D loss: 0.906625, acc.: 33.59%] [G loss: 0.963333]\n",
      "epoch:25 step:23508 [D loss: 0.737180, acc.: 52.34%] [G loss: 1.026234]\n",
      "epoch:25 step:23509 [D loss: 0.658329, acc.: 61.72%] [G loss: 0.753010]\n",
      "epoch:25 step:23510 [D loss: 0.679704, acc.: 57.81%] [G loss: 0.999657]\n",
      "epoch:25 step:23511 [D loss: 0.772943, acc.: 50.00%] [G loss: 0.918631]\n",
      "epoch:25 step:23512 [D loss: 0.697792, acc.: 52.34%] [G loss: 1.096448]\n",
      "epoch:25 step:23513 [D loss: 0.699155, acc.: 53.91%] [G loss: 1.010281]\n",
      "epoch:25 step:23514 [D loss: 0.583227, acc.: 75.78%] [G loss: 0.977224]\n",
      "epoch:25 step:23515 [D loss: 0.670684, acc.: 64.84%] [G loss: 0.977157]\n",
      "epoch:25 step:23516 [D loss: 0.676224, acc.: 62.50%] [G loss: 0.888544]\n",
      "epoch:25 step:23517 [D loss: 0.668708, acc.: 60.94%] [G loss: 1.022457]\n",
      "epoch:25 step:23518 [D loss: 0.697699, acc.: 60.94%] [G loss: 0.940138]\n",
      "epoch:25 step:23519 [D loss: 0.637824, acc.: 62.50%] [G loss: 0.960551]\n",
      "epoch:25 step:23520 [D loss: 0.479272, acc.: 79.69%] [G loss: 1.218764]\n",
      "epoch:25 step:23521 [D loss: 0.610049, acc.: 61.72%] [G loss: 0.974507]\n",
      "epoch:25 step:23522 [D loss: 0.512598, acc.: 80.47%] [G loss: 1.275320]\n",
      "epoch:25 step:23523 [D loss: 0.429531, acc.: 82.81%] [G loss: 0.855738]\n",
      "epoch:25 step:23524 [D loss: 0.449559, acc.: 85.16%] [G loss: 1.215989]\n",
      "epoch:25 step:23525 [D loss: 0.540410, acc.: 70.31%] [G loss: 1.103667]\n",
      "epoch:25 step:23526 [D loss: 0.745867, acc.: 51.56%] [G loss: 1.043731]\n",
      "epoch:25 step:23527 [D loss: 0.725922, acc.: 51.56%] [G loss: 1.059195]\n",
      "epoch:25 step:23528 [D loss: 0.679479, acc.: 58.59%] [G loss: 1.050549]\n",
      "epoch:25 step:23529 [D loss: 0.859029, acc.: 31.25%] [G loss: 1.000300]\n",
      "epoch:25 step:23530 [D loss: 0.462315, acc.: 76.56%] [G loss: 0.860545]\n",
      "epoch:25 step:23531 [D loss: 0.578347, acc.: 71.09%] [G loss: 0.984495]\n",
      "epoch:25 step:23532 [D loss: 0.681380, acc.: 55.47%] [G loss: 0.986730]\n",
      "epoch:25 step:23533 [D loss: 0.655083, acc.: 60.94%] [G loss: 0.889974]\n",
      "epoch:25 step:23534 [D loss: 0.606272, acc.: 74.22%] [G loss: 0.883089]\n",
      "epoch:25 step:23535 [D loss: 0.751397, acc.: 47.66%] [G loss: 1.001696]\n",
      "epoch:25 step:23536 [D loss: 0.929406, acc.: 32.03%] [G loss: 0.977444]\n",
      "epoch:25 step:23537 [D loss: 0.769169, acc.: 45.31%] [G loss: 0.998125]\n",
      "epoch:25 step:23538 [D loss: 0.616918, acc.: 67.19%] [G loss: 0.950209]\n",
      "epoch:25 step:23539 [D loss: 0.541863, acc.: 78.91%] [G loss: 1.105613]\n",
      "epoch:25 step:23540 [D loss: 0.561761, acc.: 68.75%] [G loss: 1.110118]\n",
      "epoch:25 step:23541 [D loss: 0.608404, acc.: 67.19%] [G loss: 1.068459]\n",
      "epoch:25 step:23542 [D loss: 0.348858, acc.: 89.06%] [G loss: 1.053383]\n",
      "epoch:25 step:23543 [D loss: 0.414983, acc.: 84.38%] [G loss: 1.005675]\n",
      "epoch:25 step:23544 [D loss: 0.329910, acc.: 79.69%] [G loss: 1.186969]\n",
      "epoch:25 step:23545 [D loss: 0.512800, acc.: 75.78%] [G loss: 1.403375]\n",
      "epoch:25 step:23546 [D loss: 0.371792, acc.: 86.72%] [G loss: 1.320488]\n",
      "epoch:25 step:23547 [D loss: 0.364305, acc.: 89.84%] [G loss: 1.212304]\n",
      "epoch:25 step:23548 [D loss: 0.657391, acc.: 56.25%] [G loss: 1.376273]\n",
      "epoch:25 step:23549 [D loss: 0.702610, acc.: 59.38%] [G loss: 1.152143]\n",
      "epoch:25 step:23550 [D loss: 0.904430, acc.: 35.94%] [G loss: 0.893313]\n",
      "epoch:25 step:23551 [D loss: 0.686930, acc.: 59.38%] [G loss: 1.301100]\n",
      "epoch:25 step:23552 [D loss: 0.768258, acc.: 45.31%] [G loss: 0.932268]\n",
      "epoch:25 step:23553 [D loss: 0.608415, acc.: 61.72%] [G loss: 0.891146]\n",
      "epoch:25 step:23554 [D loss: 0.386484, acc.: 84.38%] [G loss: 1.147240]\n",
      "epoch:25 step:23555 [D loss: 0.293139, acc.: 92.97%] [G loss: 1.420177]\n",
      "epoch:25 step:23556 [D loss: 0.312973, acc.: 94.53%] [G loss: 1.414855]\n",
      "epoch:25 step:23557 [D loss: 0.374931, acc.: 87.50%] [G loss: 1.512267]\n",
      "epoch:25 step:23558 [D loss: 0.831030, acc.: 49.22%] [G loss: 1.349119]\n",
      "epoch:25 step:23559 [D loss: 0.768994, acc.: 55.47%] [G loss: 1.135528]\n",
      "epoch:25 step:23560 [D loss: 0.589388, acc.: 67.97%] [G loss: 1.263709]\n",
      "epoch:25 step:23561 [D loss: 0.629286, acc.: 63.28%] [G loss: 1.116116]\n",
      "epoch:25 step:23562 [D loss: 0.454290, acc.: 79.69%] [G loss: 0.866957]\n",
      "epoch:25 step:23563 [D loss: 0.483661, acc.: 82.03%] [G loss: 1.287102]\n",
      "epoch:25 step:23564 [D loss: 0.345015, acc.: 87.50%] [G loss: 1.624563]\n",
      "epoch:25 step:23565 [D loss: 0.929994, acc.: 44.53%] [G loss: 1.302594]\n",
      "epoch:25 step:23566 [D loss: 0.733427, acc.: 57.81%] [G loss: 1.400511]\n",
      "epoch:25 step:23567 [D loss: 0.755597, acc.: 53.12%] [G loss: 1.372591]\n",
      "epoch:25 step:23568 [D loss: 0.598264, acc.: 67.97%] [G loss: 1.171584]\n",
      "epoch:25 step:23569 [D loss: 0.534606, acc.: 72.66%] [G loss: 1.203060]\n",
      "epoch:25 step:23570 [D loss: 0.344957, acc.: 87.50%] [G loss: 1.197840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23571 [D loss: 0.511194, acc.: 77.34%] [G loss: 1.189984]\n",
      "epoch:25 step:23572 [D loss: 0.639343, acc.: 67.19%] [G loss: 0.983950]\n",
      "epoch:25 step:23573 [D loss: 0.695236, acc.: 51.56%] [G loss: 0.967465]\n",
      "epoch:25 step:23574 [D loss: 0.720846, acc.: 56.25%] [G loss: 1.048599]\n",
      "epoch:25 step:23575 [D loss: 0.289837, acc.: 90.62%] [G loss: 0.877008]\n",
      "epoch:25 step:23576 [D loss: 0.297394, acc.: 89.84%] [G loss: 1.113452]\n",
      "epoch:25 step:23577 [D loss: 0.301861, acc.: 90.62%] [G loss: 1.332037]\n",
      "epoch:25 step:23578 [D loss: 0.645017, acc.: 66.41%] [G loss: 1.047963]\n",
      "epoch:25 step:23579 [D loss: 0.856713, acc.: 41.41%] [G loss: 1.052436]\n",
      "epoch:25 step:23580 [D loss: 0.716116, acc.: 51.56%] [G loss: 1.202546]\n",
      "epoch:25 step:23581 [D loss: 0.571506, acc.: 72.66%] [G loss: 1.668537]\n",
      "epoch:25 step:23582 [D loss: 0.611433, acc.: 67.19%] [G loss: 1.294506]\n",
      "epoch:25 step:23583 [D loss: 0.698957, acc.: 52.34%] [G loss: 1.081508]\n",
      "epoch:25 step:23584 [D loss: 0.603144, acc.: 69.53%] [G loss: 0.959415]\n",
      "epoch:25 step:23585 [D loss: 0.738271, acc.: 54.69%] [G loss: 0.832001]\n",
      "epoch:25 step:23586 [D loss: 0.681660, acc.: 58.59%] [G loss: 1.021124]\n",
      "epoch:25 step:23587 [D loss: 0.614308, acc.: 67.19%] [G loss: 0.984096]\n",
      "epoch:25 step:23588 [D loss: 0.819341, acc.: 44.53%] [G loss: 1.030519]\n",
      "epoch:25 step:23589 [D loss: 0.649247, acc.: 58.59%] [G loss: 1.033896]\n",
      "epoch:25 step:23590 [D loss: 0.699491, acc.: 55.47%] [G loss: 0.897953]\n",
      "epoch:25 step:23591 [D loss: 0.683678, acc.: 57.81%] [G loss: 0.764391]\n",
      "epoch:25 step:23592 [D loss: 0.704632, acc.: 50.78%] [G loss: 0.926142]\n",
      "epoch:25 step:23593 [D loss: 0.431995, acc.: 85.94%] [G loss: 0.978548]\n",
      "epoch:25 step:23594 [D loss: 0.569397, acc.: 70.31%] [G loss: 1.045658]\n",
      "epoch:25 step:23595 [D loss: 0.646023, acc.: 61.72%] [G loss: 1.068275]\n",
      "epoch:25 step:23596 [D loss: 0.658731, acc.: 62.50%] [G loss: 0.897137]\n",
      "epoch:25 step:23597 [D loss: 0.520902, acc.: 72.66%] [G loss: 1.172440]\n",
      "epoch:25 step:23598 [D loss: 0.607233, acc.: 68.75%] [G loss: 1.117625]\n",
      "epoch:25 step:23599 [D loss: 0.697723, acc.: 57.03%] [G loss: 1.029857]\n",
      "epoch:25 step:23600 [D loss: 0.667150, acc.: 59.38%] [G loss: 0.930020]\n",
      "epoch:25 step:23601 [D loss: 0.458318, acc.: 82.03%] [G loss: 1.155668]\n",
      "epoch:25 step:23602 [D loss: 0.781228, acc.: 45.31%] [G loss: 1.128193]\n",
      "epoch:25 step:23603 [D loss: 0.700567, acc.: 52.34%] [G loss: 1.110093]\n",
      "epoch:25 step:23604 [D loss: 0.658458, acc.: 62.50%] [G loss: 1.074932]\n",
      "epoch:25 step:23605 [D loss: 0.775752, acc.: 50.00%] [G loss: 0.871791]\n",
      "epoch:25 step:23606 [D loss: 0.483893, acc.: 82.03%] [G loss: 0.895585]\n",
      "epoch:25 step:23607 [D loss: 0.556834, acc.: 75.00%] [G loss: 0.943895]\n",
      "epoch:25 step:23608 [D loss: 0.586742, acc.: 66.41%] [G loss: 0.736676]\n",
      "epoch:25 step:23609 [D loss: 0.515158, acc.: 71.88%] [G loss: 1.017575]\n",
      "epoch:25 step:23610 [D loss: 0.618781, acc.: 63.28%] [G loss: 1.065589]\n",
      "epoch:25 step:23611 [D loss: 0.803911, acc.: 39.06%] [G loss: 0.745108]\n",
      "epoch:25 step:23612 [D loss: 0.738666, acc.: 56.25%] [G loss: 0.892301]\n",
      "epoch:25 step:23613 [D loss: 0.453591, acc.: 87.50%] [G loss: 1.115435]\n",
      "epoch:25 step:23614 [D loss: 0.731929, acc.: 56.25%] [G loss: 1.026229]\n",
      "epoch:25 step:23615 [D loss: 0.581443, acc.: 69.53%] [G loss: 0.763446]\n",
      "epoch:25 step:23616 [D loss: 0.577800, acc.: 74.22%] [G loss: 0.659537]\n",
      "epoch:25 step:23617 [D loss: 0.355642, acc.: 78.91%] [G loss: 1.135410]\n",
      "epoch:25 step:23618 [D loss: 0.484324, acc.: 82.81%] [G loss: 1.193898]\n",
      "epoch:25 step:23619 [D loss: 0.354678, acc.: 92.19%] [G loss: 1.344605]\n",
      "epoch:25 step:23620 [D loss: 0.626997, acc.: 61.72%] [G loss: 1.394316]\n",
      "epoch:25 step:23621 [D loss: 0.601207, acc.: 68.75%] [G loss: 1.053816]\n",
      "epoch:25 step:23622 [D loss: 0.589198, acc.: 67.97%] [G loss: 0.718040]\n",
      "epoch:25 step:23623 [D loss: 0.822886, acc.: 39.84%] [G loss: 1.368130]\n",
      "epoch:25 step:23624 [D loss: 0.970559, acc.: 27.34%] [G loss: 1.196443]\n",
      "epoch:25 step:23625 [D loss: 0.593892, acc.: 66.41%] [G loss: 0.989929]\n",
      "epoch:25 step:23626 [D loss: 0.305246, acc.: 96.09%] [G loss: 1.340239]\n",
      "epoch:25 step:23627 [D loss: 0.767185, acc.: 49.22%] [G loss: 1.101768]\n",
      "epoch:25 step:23628 [D loss: 0.470794, acc.: 84.38%] [G loss: 1.103657]\n",
      "epoch:25 step:23629 [D loss: 0.305323, acc.: 91.41%] [G loss: 0.820647]\n",
      "epoch:25 step:23630 [D loss: 0.647845, acc.: 64.06%] [G loss: 1.372175]\n",
      "epoch:25 step:23631 [D loss: 0.283123, acc.: 96.09%] [G loss: 0.802335]\n",
      "epoch:25 step:23632 [D loss: 0.233309, acc.: 92.19%] [G loss: 1.216118]\n",
      "epoch:25 step:23633 [D loss: 0.533731, acc.: 71.09%] [G loss: 0.629545]\n",
      "epoch:25 step:23634 [D loss: 0.530615, acc.: 68.75%] [G loss: 0.829891]\n",
      "epoch:25 step:23635 [D loss: 0.901138, acc.: 51.56%] [G loss: 1.193787]\n",
      "epoch:25 step:23636 [D loss: 0.847381, acc.: 45.31%] [G loss: 1.013348]\n",
      "epoch:25 step:23637 [D loss: 1.015369, acc.: 24.22%] [G loss: 1.202133]\n",
      "epoch:25 step:23638 [D loss: 0.771454, acc.: 53.12%] [G loss: 0.777064]\n",
      "epoch:25 step:23639 [D loss: 0.892636, acc.: 41.41%] [G loss: 1.470219]\n",
      "epoch:25 step:23640 [D loss: 0.782042, acc.: 49.22%] [G loss: 1.188381]\n",
      "epoch:25 step:23641 [D loss: 0.714869, acc.: 57.81%] [G loss: 1.233458]\n",
      "epoch:25 step:23642 [D loss: 0.671300, acc.: 64.84%] [G loss: 0.989576]\n",
      "epoch:25 step:23643 [D loss: 0.538273, acc.: 80.47%] [G loss: 0.930451]\n",
      "epoch:25 step:23644 [D loss: 0.463784, acc.: 89.06%] [G loss: 0.917053]\n",
      "epoch:25 step:23645 [D loss: 0.331699, acc.: 86.72%] [G loss: 0.960351]\n",
      "epoch:25 step:23646 [D loss: 0.288219, acc.: 93.75%] [G loss: 1.262907]\n",
      "epoch:25 step:23647 [D loss: 0.455782, acc.: 78.91%] [G loss: 1.218081]\n",
      "epoch:25 step:23648 [D loss: 0.234737, acc.: 97.66%] [G loss: 1.458166]\n",
      "epoch:25 step:23649 [D loss: 0.785677, acc.: 57.03%] [G loss: 1.424010]\n",
      "epoch:25 step:23650 [D loss: 0.631899, acc.: 66.41%] [G loss: 1.358618]\n",
      "epoch:25 step:23651 [D loss: 0.589918, acc.: 66.41%] [G loss: 1.224394]\n",
      "epoch:25 step:23652 [D loss: 0.519686, acc.: 72.66%] [G loss: 1.156213]\n",
      "epoch:25 step:23653 [D loss: 0.422769, acc.: 87.50%] [G loss: 1.189074]\n",
      "epoch:25 step:23654 [D loss: 0.510549, acc.: 78.91%] [G loss: 1.435293]\n",
      "epoch:25 step:23655 [D loss: 0.145713, acc.: 98.44%] [G loss: 1.531349]\n",
      "epoch:25 step:23656 [D loss: 0.178367, acc.: 98.44%] [G loss: 1.222762]\n",
      "epoch:25 step:23657 [D loss: 0.222442, acc.: 97.66%] [G loss: 1.430094]\n",
      "epoch:25 step:23658 [D loss: 0.588840, acc.: 66.41%] [G loss: 3.316923]\n",
      "epoch:25 step:23659 [D loss: 0.404573, acc.: 87.50%] [G loss: 1.691302]\n",
      "epoch:25 step:23660 [D loss: 0.213053, acc.: 96.88%] [G loss: 1.654768]\n",
      "epoch:25 step:23661 [D loss: 0.416467, acc.: 87.50%] [G loss: 1.723822]\n",
      "epoch:25 step:23662 [D loss: 0.596238, acc.: 67.97%] [G loss: 1.504094]\n",
      "epoch:25 step:23663 [D loss: 0.465599, acc.: 76.56%] [G loss: 2.070677]\n",
      "epoch:25 step:23664 [D loss: 0.450047, acc.: 81.25%] [G loss: 1.462754]\n",
      "epoch:25 step:23665 [D loss: 0.505865, acc.: 76.56%] [G loss: 1.138655]\n",
      "epoch:25 step:23666 [D loss: 0.941542, acc.: 39.06%] [G loss: 1.557600]\n",
      "epoch:25 step:23667 [D loss: 0.503012, acc.: 82.81%] [G loss: 0.952245]\n",
      "epoch:25 step:23668 [D loss: 0.752501, acc.: 53.91%] [G loss: 1.151517]\n",
      "epoch:25 step:23669 [D loss: 0.589743, acc.: 62.50%] [G loss: 1.140564]\n",
      "epoch:25 step:23670 [D loss: 0.668412, acc.: 58.59%] [G loss: 1.041192]\n",
      "epoch:25 step:23671 [D loss: 0.722039, acc.: 54.69%] [G loss: 0.348609]\n",
      "epoch:25 step:23672 [D loss: 0.679913, acc.: 58.59%] [G loss: 1.094279]\n",
      "epoch:25 step:23673 [D loss: 0.960993, acc.: 42.19%] [G loss: 1.073739]\n",
      "epoch:25 step:23674 [D loss: 0.512051, acc.: 75.78%] [G loss: 1.355514]\n",
      "epoch:25 step:23675 [D loss: 0.676704, acc.: 57.81%] [G loss: 1.133732]\n",
      "epoch:25 step:23676 [D loss: 0.655108, acc.: 60.16%] [G loss: 1.258062]\n",
      "epoch:25 step:23677 [D loss: 0.519112, acc.: 70.31%] [G loss: 1.297699]\n",
      "epoch:25 step:23678 [D loss: 0.563706, acc.: 70.31%] [G loss: 1.238485]\n",
      "epoch:25 step:23679 [D loss: 0.487707, acc.: 78.91%] [G loss: 1.101183]\n",
      "epoch:25 step:23680 [D loss: 0.326063, acc.: 89.84%] [G loss: 1.163631]\n",
      "epoch:25 step:23681 [D loss: 0.217860, acc.: 98.44%] [G loss: 1.348352]\n",
      "epoch:25 step:23682 [D loss: 0.334002, acc.: 89.06%] [G loss: 1.465766]\n",
      "epoch:25 step:23683 [D loss: 0.435789, acc.: 82.03%] [G loss: 1.230757]\n",
      "epoch:25 step:23684 [D loss: 0.260457, acc.: 94.53%] [G loss: 1.382039]\n",
      "epoch:25 step:23685 [D loss: 0.411178, acc.: 81.25%] [G loss: 1.539614]\n",
      "epoch:25 step:23686 [D loss: 0.219877, acc.: 96.88%] [G loss: 1.200307]\n",
      "epoch:25 step:23687 [D loss: 0.688018, acc.: 63.28%] [G loss: 1.157134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23688 [D loss: 0.303572, acc.: 88.28%] [G loss: 0.970501]\n",
      "epoch:25 step:23689 [D loss: 0.540499, acc.: 70.31%] [G loss: 1.291169]\n",
      "epoch:25 step:23690 [D loss: 0.726115, acc.: 52.34%] [G loss: 1.251816]\n",
      "epoch:25 step:23691 [D loss: 0.764283, acc.: 48.44%] [G loss: 0.926832]\n",
      "epoch:25 step:23692 [D loss: 0.796719, acc.: 59.38%] [G loss: 1.164240]\n",
      "epoch:25 step:23693 [D loss: 0.671373, acc.: 57.81%] [G loss: 0.890360]\n",
      "epoch:25 step:23694 [D loss: 0.648444, acc.: 64.06%] [G loss: 1.219996]\n",
      "epoch:25 step:23695 [D loss: 0.747668, acc.: 47.66%] [G loss: 1.191140]\n",
      "epoch:25 step:23696 [D loss: 0.523501, acc.: 75.78%] [G loss: 0.834219]\n",
      "epoch:25 step:23697 [D loss: 0.648277, acc.: 63.28%] [G loss: 0.994859]\n",
      "epoch:25 step:23698 [D loss: 0.652015, acc.: 61.72%] [G loss: 0.741513]\n",
      "epoch:25 step:23699 [D loss: 0.684594, acc.: 58.59%] [G loss: 1.079178]\n",
      "epoch:25 step:23700 [D loss: 0.614407, acc.: 64.84%] [G loss: 1.133909]\n",
      "epoch:25 step:23701 [D loss: 0.549730, acc.: 77.34%] [G loss: 1.134179]\n",
      "epoch:25 step:23702 [D loss: 0.612485, acc.: 63.28%] [G loss: 1.015008]\n",
      "epoch:25 step:23703 [D loss: 0.368830, acc.: 82.81%] [G loss: 1.039931]\n",
      "epoch:25 step:23704 [D loss: 0.285582, acc.: 86.72%] [G loss: 1.064337]\n",
      "epoch:25 step:23705 [D loss: 0.404824, acc.: 91.41%] [G loss: 0.949729]\n",
      "epoch:25 step:23706 [D loss: 0.842327, acc.: 43.75%] [G loss: 1.166734]\n",
      "epoch:25 step:23707 [D loss: 0.732216, acc.: 53.12%] [G loss: 0.960414]\n",
      "epoch:25 step:23708 [D loss: 0.868416, acc.: 39.06%] [G loss: 0.787550]\n",
      "epoch:25 step:23709 [D loss: 0.351071, acc.: 80.47%] [G loss: 0.866930]\n",
      "epoch:25 step:23710 [D loss: 0.296479, acc.: 87.50%] [G loss: 1.016353]\n",
      "epoch:25 step:23711 [D loss: 0.326941, acc.: 85.16%] [G loss: 1.097088]\n",
      "epoch:25 step:23712 [D loss: 0.483954, acc.: 82.03%] [G loss: 1.113880]\n",
      "epoch:25 step:23713 [D loss: 0.350547, acc.: 91.41%] [G loss: 1.324365]\n",
      "epoch:25 step:23714 [D loss: 0.337561, acc.: 89.84%] [G loss: 1.278784]\n",
      "epoch:25 step:23715 [D loss: 0.453875, acc.: 85.94%] [G loss: 1.355522]\n",
      "epoch:25 step:23716 [D loss: 0.311705, acc.: 87.50%] [G loss: 1.557743]\n",
      "epoch:25 step:23717 [D loss: 0.207222, acc.: 96.09%] [G loss: 1.472413]\n",
      "epoch:25 step:23718 [D loss: 0.248522, acc.: 95.31%] [G loss: 1.576392]\n",
      "epoch:25 step:23719 [D loss: 0.347789, acc.: 96.88%] [G loss: 1.618318]\n",
      "epoch:25 step:23720 [D loss: 0.725239, acc.: 60.16%] [G loss: 1.389652]\n",
      "epoch:25 step:23721 [D loss: 0.644898, acc.: 62.50%] [G loss: 1.053890]\n",
      "epoch:25 step:23722 [D loss: 0.783381, acc.: 49.22%] [G loss: 1.156232]\n",
      "epoch:25 step:23723 [D loss: 0.726385, acc.: 53.12%] [G loss: 0.925643]\n",
      "epoch:25 step:23724 [D loss: 0.709260, acc.: 55.47%] [G loss: 1.274694]\n",
      "epoch:25 step:23725 [D loss: 0.621081, acc.: 65.62%] [G loss: 1.144944]\n",
      "epoch:25 step:23726 [D loss: 0.578320, acc.: 70.31%] [G loss: 1.013865]\n",
      "epoch:25 step:23727 [D loss: 0.654166, acc.: 60.94%] [G loss: 1.100460]\n",
      "epoch:25 step:23728 [D loss: 0.704124, acc.: 57.03%] [G loss: 1.138537]\n",
      "epoch:25 step:23729 [D loss: 0.312589, acc.: 89.84%] [G loss: 1.112831]\n",
      "epoch:25 step:23730 [D loss: 0.563742, acc.: 66.41%] [G loss: 1.435345]\n",
      "epoch:25 step:23731 [D loss: 0.426724, acc.: 85.94%] [G loss: 1.602330]\n",
      "epoch:25 step:23732 [D loss: 0.492831, acc.: 82.81%] [G loss: 1.365428]\n",
      "epoch:25 step:23733 [D loss: 0.173222, acc.: 97.66%] [G loss: 1.493503]\n",
      "epoch:25 step:23734 [D loss: 0.159549, acc.: 100.00%] [G loss: 1.578652]\n",
      "epoch:25 step:23735 [D loss: 0.256590, acc.: 96.09%] [G loss: 1.571139]\n",
      "epoch:25 step:23736 [D loss: 0.189799, acc.: 99.22%] [G loss: 1.450702]\n",
      "epoch:25 step:23737 [D loss: 0.174528, acc.: 95.31%] [G loss: 1.475351]\n",
      "epoch:25 step:23738 [D loss: 0.318304, acc.: 92.97%] [G loss: 1.475080]\n",
      "epoch:25 step:23739 [D loss: 0.166842, acc.: 96.88%] [G loss: 1.793909]\n",
      "epoch:25 step:23740 [D loss: 0.198663, acc.: 96.88%] [G loss: 1.943998]\n",
      "epoch:25 step:23741 [D loss: 0.972804, acc.: 48.44%] [G loss: 1.479733]\n",
      "epoch:25 step:23742 [D loss: 0.913884, acc.: 41.41%] [G loss: 1.247683]\n",
      "epoch:25 step:23743 [D loss: 0.766172, acc.: 54.69%] [G loss: 1.271032]\n",
      "epoch:25 step:23744 [D loss: 0.886939, acc.: 42.19%] [G loss: 1.065446]\n",
      "epoch:25 step:23745 [D loss: 1.012005, acc.: 23.44%] [G loss: 1.109086]\n",
      "epoch:25 step:23746 [D loss: 0.760222, acc.: 52.34%] [G loss: 1.003343]\n",
      "epoch:25 step:23747 [D loss: 0.868921, acc.: 39.06%] [G loss: 1.130361]\n",
      "epoch:25 step:23748 [D loss: 0.455118, acc.: 76.56%] [G loss: 0.698943]\n",
      "epoch:25 step:23749 [D loss: 0.382357, acc.: 93.75%] [G loss: 1.265568]\n",
      "epoch:25 step:23750 [D loss: 0.655760, acc.: 64.84%] [G loss: 1.031896]\n",
      "epoch:25 step:23751 [D loss: 0.776169, acc.: 52.34%] [G loss: 1.153583]\n",
      "epoch:25 step:23752 [D loss: 0.834727, acc.: 36.72%] [G loss: 1.073814]\n",
      "epoch:25 step:23753 [D loss: 0.676105, acc.: 54.69%] [G loss: 0.745607]\n",
      "epoch:25 step:23754 [D loss: 0.705336, acc.: 54.69%] [G loss: 1.249775]\n",
      "epoch:25 step:23755 [D loss: 0.953071, acc.: 30.47%] [G loss: 1.152927]\n",
      "epoch:25 step:23756 [D loss: 0.526800, acc.: 79.69%] [G loss: 1.407850]\n",
      "epoch:25 step:23757 [D loss: 0.358684, acc.: 94.53%] [G loss: 1.161412]\n",
      "epoch:25 step:23758 [D loss: 0.440861, acc.: 79.69%] [G loss: 1.016857]\n",
      "epoch:25 step:23759 [D loss: 0.581740, acc.: 64.06%] [G loss: 1.178539]\n",
      "epoch:25 step:23760 [D loss: 0.317300, acc.: 88.28%] [G loss: 1.147596]\n",
      "epoch:25 step:23761 [D loss: 0.425873, acc.: 78.91%] [G loss: 1.086777]\n",
      "epoch:25 step:23762 [D loss: 0.438064, acc.: 83.59%] [G loss: 1.379631]\n",
      "epoch:25 step:23763 [D loss: 0.951129, acc.: 35.94%] [G loss: 1.002091]\n",
      "epoch:25 step:23764 [D loss: 0.866721, acc.: 32.81%] [G loss: 1.369777]\n",
      "epoch:25 step:23765 [D loss: 1.295266, acc.: 12.50%] [G loss: 0.535779]\n",
      "epoch:25 step:23766 [D loss: 0.775565, acc.: 51.56%] [G loss: 1.135216]\n",
      "epoch:25 step:23767 [D loss: 0.709799, acc.: 55.47%] [G loss: 1.290415]\n",
      "epoch:25 step:23768 [D loss: 0.321010, acc.: 95.31%] [G loss: 1.089761]\n",
      "epoch:25 step:23769 [D loss: 0.876314, acc.: 35.16%] [G loss: 1.400702]\n",
      "epoch:25 step:23770 [D loss: 0.421923, acc.: 84.38%] [G loss: 1.353437]\n",
      "epoch:25 step:23771 [D loss: 0.561612, acc.: 68.75%] [G loss: 1.096330]\n",
      "epoch:25 step:23772 [D loss: 0.428193, acc.: 83.59%] [G loss: 1.258261]\n",
      "epoch:25 step:23773 [D loss: 0.917053, acc.: 42.97%] [G loss: 1.619936]\n",
      "epoch:25 step:23774 [D loss: 0.704635, acc.: 53.91%] [G loss: 1.278215]\n",
      "epoch:25 step:23775 [D loss: 0.881876, acc.: 42.97%] [G loss: 1.509885]\n",
      "epoch:25 step:23776 [D loss: 0.472341, acc.: 74.22%] [G loss: 1.547882]\n",
      "epoch:25 step:23777 [D loss: 0.393149, acc.: 85.94%] [G loss: 1.784316]\n",
      "epoch:25 step:23778 [D loss: 0.391436, acc.: 82.81%] [G loss: 2.091623]\n",
      "epoch:25 step:23779 [D loss: 0.369533, acc.: 82.81%] [G loss: 2.343097]\n",
      "epoch:25 step:23780 [D loss: 0.503355, acc.: 68.75%] [G loss: 1.883584]\n",
      "epoch:25 step:23781 [D loss: 0.447529, acc.: 71.09%] [G loss: 2.309709]\n",
      "epoch:25 step:23782 [D loss: 0.443281, acc.: 72.66%] [G loss: 2.072666]\n",
      "epoch:25 step:23783 [D loss: 0.253524, acc.: 92.97%] [G loss: 2.435617]\n",
      "epoch:25 step:23784 [D loss: 0.207091, acc.: 98.44%] [G loss: 2.095332]\n",
      "epoch:25 step:23785 [D loss: 0.236984, acc.: 95.31%] [G loss: 1.913618]\n",
      "epoch:25 step:23786 [D loss: 0.341925, acc.: 91.41%] [G loss: 2.455430]\n",
      "epoch:25 step:23787 [D loss: 0.694060, acc.: 57.03%] [G loss: 1.055974]\n",
      "epoch:25 step:23788 [D loss: 0.782161, acc.: 54.69%] [G loss: 1.579107]\n",
      "epoch:25 step:23789 [D loss: 0.416370, acc.: 84.38%] [G loss: 1.203354]\n",
      "epoch:25 step:23790 [D loss: 0.741472, acc.: 60.16%] [G loss: 0.998273]\n",
      "epoch:25 step:23791 [D loss: 0.964524, acc.: 45.31%] [G loss: 0.761639]\n",
      "epoch:25 step:23792 [D loss: 0.611534, acc.: 67.97%] [G loss: 1.004537]\n",
      "epoch:25 step:23793 [D loss: 0.510052, acc.: 72.66%] [G loss: 1.362955]\n",
      "epoch:25 step:23794 [D loss: 0.221683, acc.: 91.41%] [G loss: 1.229755]\n",
      "epoch:25 step:23795 [D loss: 0.227329, acc.: 93.75%] [G loss: 1.315377]\n",
      "epoch:25 step:23796 [D loss: 0.205870, acc.: 95.31%] [G loss: 1.902107]\n",
      "epoch:25 step:23797 [D loss: 0.260666, acc.: 98.44%] [G loss: 1.759204]\n",
      "epoch:25 step:23798 [D loss: 0.619722, acc.: 67.97%] [G loss: 1.557743]\n",
      "epoch:25 step:23799 [D loss: 0.475967, acc.: 80.47%] [G loss: 1.385784]\n",
      "epoch:25 step:23800 [D loss: 0.443190, acc.: 85.94%] [G loss: 1.268827]\n",
      "epoch:25 step:23801 [D loss: 0.385837, acc.: 85.94%] [G loss: 1.297175]\n",
      "epoch:25 step:23802 [D loss: 0.736137, acc.: 54.69%] [G loss: 1.341415]\n",
      "epoch:25 step:23803 [D loss: 0.602611, acc.: 67.19%] [G loss: 1.305813]\n",
      "epoch:25 step:23804 [D loss: 0.290618, acc.: 90.62%] [G loss: 1.358321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23805 [D loss: 0.307138, acc.: 81.25%] [G loss: 1.464933]\n",
      "epoch:25 step:23806 [D loss: 0.239512, acc.: 94.53%] [G loss: 1.414210]\n",
      "epoch:25 step:23807 [D loss: 0.332128, acc.: 90.62%] [G loss: 1.598498]\n",
      "epoch:25 step:23808 [D loss: 0.533303, acc.: 76.56%] [G loss: 1.467554]\n",
      "epoch:25 step:23809 [D loss: 0.633556, acc.: 61.72%] [G loss: 1.280839]\n",
      "epoch:25 step:23810 [D loss: 0.466878, acc.: 82.03%] [G loss: 1.326677]\n",
      "epoch:25 step:23811 [D loss: 0.356088, acc.: 85.16%] [G loss: 1.124125]\n",
      "epoch:25 step:23812 [D loss: 0.250507, acc.: 96.09%] [G loss: 1.561987]\n",
      "epoch:25 step:23813 [D loss: 0.322962, acc.: 91.41%] [G loss: 1.534522]\n",
      "epoch:25 step:23814 [D loss: 0.604514, acc.: 68.75%] [G loss: 1.400581]\n",
      "epoch:25 step:23815 [D loss: 0.662689, acc.: 57.03%] [G loss: 1.194261]\n",
      "epoch:25 step:23816 [D loss: 0.535278, acc.: 71.09%] [G loss: 1.189947]\n",
      "epoch:25 step:23817 [D loss: 0.574347, acc.: 71.88%] [G loss: 0.927223]\n",
      "epoch:25 step:23818 [D loss: 0.710122, acc.: 57.81%] [G loss: 0.712972]\n",
      "epoch:25 step:23819 [D loss: 0.603022, acc.: 71.09%] [G loss: 0.691790]\n",
      "epoch:25 step:23820 [D loss: 0.464614, acc.: 81.25%] [G loss: 0.651761]\n",
      "epoch:25 step:23821 [D loss: 1.029155, acc.: 34.38%] [G loss: 0.901225]\n",
      "epoch:25 step:23822 [D loss: 0.845781, acc.: 45.31%] [G loss: 0.890473]\n",
      "epoch:25 step:23823 [D loss: 0.723237, acc.: 57.03%] [G loss: 0.801302]\n",
      "epoch:25 step:23824 [D loss: 0.670728, acc.: 53.12%] [G loss: 0.870212]\n",
      "epoch:25 step:23825 [D loss: 0.792533, acc.: 51.56%] [G loss: 0.952117]\n",
      "epoch:25 step:23826 [D loss: 0.944265, acc.: 42.19%] [G loss: 0.931919]\n",
      "epoch:25 step:23827 [D loss: 0.652657, acc.: 65.62%] [G loss: 1.031145]\n",
      "epoch:25 step:23828 [D loss: 0.519488, acc.: 74.22%] [G loss: 1.438443]\n",
      "epoch:25 step:23829 [D loss: 0.577632, acc.: 69.53%] [G loss: 1.126389]\n",
      "epoch:25 step:23830 [D loss: 0.407612, acc.: 78.91%] [G loss: 1.304404]\n",
      "epoch:25 step:23831 [D loss: 0.352717, acc.: 89.06%] [G loss: 1.360788]\n",
      "epoch:25 step:23832 [D loss: 0.377514, acc.: 83.59%] [G loss: 1.642773]\n",
      "epoch:25 step:23833 [D loss: 0.621367, acc.: 70.31%] [G loss: 1.128208]\n",
      "epoch:25 step:23834 [D loss: 0.351782, acc.: 85.16%] [G loss: 1.348610]\n",
      "epoch:25 step:23835 [D loss: 0.608356, acc.: 67.19%] [G loss: 1.215666]\n",
      "epoch:25 step:23836 [D loss: 0.729286, acc.: 60.16%] [G loss: 1.264117]\n",
      "epoch:25 step:23837 [D loss: 0.527112, acc.: 74.22%] [G loss: 1.006448]\n",
      "epoch:25 step:23838 [D loss: 0.447447, acc.: 74.22%] [G loss: 1.066767]\n",
      "epoch:25 step:23839 [D loss: 0.453257, acc.: 81.25%] [G loss: 1.241005]\n",
      "epoch:25 step:23840 [D loss: 0.317776, acc.: 89.84%] [G loss: 1.220021]\n",
      "epoch:25 step:23841 [D loss: 0.570077, acc.: 71.09%] [G loss: 1.098849]\n",
      "epoch:25 step:23842 [D loss: 0.688352, acc.: 59.38%] [G loss: 1.342059]\n",
      "epoch:25 step:23843 [D loss: 0.326969, acc.: 85.16%] [G loss: 1.258497]\n",
      "epoch:25 step:23844 [D loss: 0.295331, acc.: 91.41%] [G loss: 2.283134]\n",
      "epoch:25 step:23845 [D loss: 0.587048, acc.: 68.75%] [G loss: 1.571261]\n",
      "epoch:25 step:23846 [D loss: 1.275167, acc.: 17.19%] [G loss: 0.851288]\n",
      "epoch:25 step:23847 [D loss: 1.023443, acc.: 39.06%] [G loss: 1.476820]\n",
      "epoch:25 step:23848 [D loss: 0.784617, acc.: 46.09%] [G loss: 1.034116]\n",
      "epoch:25 step:23849 [D loss: 0.625111, acc.: 64.06%] [G loss: 1.588815]\n",
      "epoch:25 step:23850 [D loss: 0.708904, acc.: 57.81%] [G loss: 0.850682]\n",
      "epoch:25 step:23851 [D loss: 0.788896, acc.: 46.88%] [G loss: 1.278258]\n",
      "epoch:25 step:23852 [D loss: 0.652205, acc.: 63.28%] [G loss: 1.847556]\n",
      "epoch:25 step:23853 [D loss: 0.449326, acc.: 82.03%] [G loss: 1.296665]\n",
      "epoch:25 step:23854 [D loss: 0.662015, acc.: 57.81%] [G loss: 1.243937]\n",
      "epoch:25 step:23855 [D loss: 0.804548, acc.: 54.69%] [G loss: 1.660464]\n",
      "epoch:25 step:23856 [D loss: 1.001275, acc.: 36.72%] [G loss: 1.297861]\n",
      "epoch:25 step:23857 [D loss: 0.813006, acc.: 52.34%] [G loss: 1.017634]\n",
      "epoch:25 step:23858 [D loss: 0.810697, acc.: 48.44%] [G loss: 1.615340]\n",
      "epoch:25 step:23859 [D loss: 0.718650, acc.: 57.03%] [G loss: 1.280299]\n",
      "epoch:25 step:23860 [D loss: 0.616433, acc.: 63.28%] [G loss: 1.088375]\n",
      "epoch:25 step:23861 [D loss: 0.741251, acc.: 55.47%] [G loss: 1.084635]\n",
      "epoch:25 step:23862 [D loss: 0.659247, acc.: 57.81%] [G loss: 1.329000]\n",
      "epoch:25 step:23863 [D loss: 0.651932, acc.: 60.94%] [G loss: 1.068712]\n",
      "epoch:25 step:23864 [D loss: 0.667793, acc.: 57.03%] [G loss: 1.105372]\n",
      "epoch:25 step:23865 [D loss: 0.684752, acc.: 53.12%] [G loss: 1.152540]\n",
      "epoch:25 step:23866 [D loss: 0.682364, acc.: 53.91%] [G loss: 1.041842]\n",
      "epoch:25 step:23867 [D loss: 0.626392, acc.: 63.28%] [G loss: 0.977858]\n",
      "epoch:25 step:23868 [D loss: 0.557794, acc.: 72.66%] [G loss: 0.973511]\n",
      "epoch:25 step:23869 [D loss: 0.650961, acc.: 63.28%] [G loss: 1.082334]\n",
      "epoch:25 step:23870 [D loss: 0.663228, acc.: 60.16%] [G loss: 0.972618]\n",
      "epoch:25 step:23871 [D loss: 0.652999, acc.: 54.69%] [G loss: 1.124782]\n",
      "epoch:25 step:23872 [D loss: 0.642728, acc.: 59.38%] [G loss: 1.137630]\n",
      "epoch:25 step:23873 [D loss: 0.443453, acc.: 81.25%] [G loss: 1.144033]\n",
      "epoch:25 step:23874 [D loss: 0.367721, acc.: 87.50%] [G loss: 1.344163]\n",
      "epoch:25 step:23875 [D loss: 0.319051, acc.: 97.66%] [G loss: 1.060535]\n",
      "epoch:25 step:23876 [D loss: 0.205418, acc.: 98.44%] [G loss: 1.405779]\n",
      "epoch:25 step:23877 [D loss: 0.183510, acc.: 96.88%] [G loss: 1.417632]\n",
      "epoch:25 step:23878 [D loss: 0.270540, acc.: 96.09%] [G loss: 1.492892]\n",
      "epoch:25 step:23879 [D loss: 0.272029, acc.: 96.88%] [G loss: 1.659329]\n",
      "epoch:25 step:23880 [D loss: 0.315304, acc.: 92.19%] [G loss: 1.683977]\n",
      "epoch:25 step:23881 [D loss: 0.257029, acc.: 88.28%] [G loss: 2.009224]\n",
      "epoch:25 step:23882 [D loss: 0.174450, acc.: 99.22%] [G loss: 1.670117]\n",
      "epoch:25 step:23883 [D loss: 0.693463, acc.: 55.47%] [G loss: 1.785602]\n",
      "epoch:25 step:23884 [D loss: 0.595641, acc.: 67.97%] [G loss: 1.732336]\n",
      "epoch:25 step:23885 [D loss: 0.700870, acc.: 47.66%] [G loss: 1.348660]\n",
      "epoch:25 step:23886 [D loss: 0.861760, acc.: 48.44%] [G loss: 1.243667]\n",
      "epoch:25 step:23887 [D loss: 0.874786, acc.: 40.62%] [G loss: 1.096268]\n",
      "epoch:25 step:23888 [D loss: 0.551517, acc.: 70.31%] [G loss: 1.034489]\n",
      "epoch:25 step:23889 [D loss: 0.563238, acc.: 71.09%] [G loss: 1.438101]\n",
      "epoch:25 step:23890 [D loss: 0.326958, acc.: 89.06%] [G loss: 1.275360]\n",
      "epoch:25 step:23891 [D loss: 0.388246, acc.: 89.06%] [G loss: 0.843958]\n",
      "epoch:25 step:23892 [D loss: 0.505414, acc.: 71.09%] [G loss: 1.412521]\n",
      "epoch:25 step:23893 [D loss: 0.255809, acc.: 94.53%] [G loss: 1.409000]\n",
      "epoch:25 step:23894 [D loss: 0.221069, acc.: 98.44%] [G loss: 1.286097]\n",
      "epoch:25 step:23895 [D loss: 0.124183, acc.: 99.22%] [G loss: 1.176641]\n",
      "epoch:25 step:23896 [D loss: 0.221827, acc.: 94.53%] [G loss: 1.257175]\n",
      "epoch:25 step:23897 [D loss: 0.240289, acc.: 98.44%] [G loss: 1.484284]\n",
      "epoch:25 step:23898 [D loss: 1.449703, acc.: 32.03%] [G loss: 1.554528]\n",
      "epoch:25 step:23899 [D loss: 1.273833, acc.: 28.91%] [G loss: 1.097253]\n",
      "epoch:25 step:23900 [D loss: 1.004622, acc.: 26.56%] [G loss: 1.209661]\n",
      "epoch:25 step:23901 [D loss: 0.592857, acc.: 69.53%] [G loss: 0.898667]\n",
      "epoch:25 step:23902 [D loss: 0.559991, acc.: 69.53%] [G loss: 1.105229]\n",
      "epoch:25 step:23903 [D loss: 0.492136, acc.: 78.91%] [G loss: 1.292982]\n",
      "epoch:25 step:23904 [D loss: 0.439351, acc.: 80.47%] [G loss: 1.042493]\n",
      "epoch:25 step:23905 [D loss: 0.394605, acc.: 81.25%] [G loss: 1.150930]\n",
      "epoch:25 step:23906 [D loss: 0.313617, acc.: 88.28%] [G loss: 1.492907]\n",
      "epoch:25 step:23907 [D loss: 0.886684, acc.: 45.31%] [G loss: 1.370628]\n",
      "epoch:25 step:23908 [D loss: 0.733019, acc.: 57.03%] [G loss: 1.353953]\n",
      "epoch:25 step:23909 [D loss: 0.780911, acc.: 51.56%] [G loss: 1.407560]\n",
      "epoch:25 step:23910 [D loss: 0.659300, acc.: 57.81%] [G loss: 1.326506]\n",
      "epoch:25 step:23911 [D loss: 0.723045, acc.: 55.47%] [G loss: 1.305054]\n",
      "epoch:25 step:23912 [D loss: 0.631268, acc.: 61.72%] [G loss: 1.118849]\n",
      "epoch:25 step:23913 [D loss: 0.611784, acc.: 66.41%] [G loss: 1.164224]\n",
      "epoch:25 step:23914 [D loss: 0.555967, acc.: 73.44%] [G loss: 0.992325]\n",
      "epoch:25 step:23915 [D loss: 0.465427, acc.: 82.81%] [G loss: 0.985126]\n",
      "epoch:25 step:23916 [D loss: 0.514989, acc.: 72.66%] [G loss: 1.028385]\n",
      "epoch:25 step:23917 [D loss: 0.701020, acc.: 52.34%] [G loss: 1.113034]\n",
      "epoch:25 step:23918 [D loss: 0.608870, acc.: 66.41%] [G loss: 1.053182]\n",
      "epoch:25 step:23919 [D loss: 0.642907, acc.: 66.41%] [G loss: 0.886091]\n",
      "epoch:25 step:23920 [D loss: 0.502698, acc.: 80.47%] [G loss: 1.131926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23921 [D loss: 0.678650, acc.: 51.56%] [G loss: 1.013242]\n",
      "epoch:25 step:23922 [D loss: 0.507460, acc.: 81.25%] [G loss: 1.172267]\n",
      "epoch:25 step:23923 [D loss: 0.427698, acc.: 88.28%] [G loss: 1.262275]\n",
      "epoch:25 step:23924 [D loss: 0.331372, acc.: 90.62%] [G loss: 1.400691]\n",
      "epoch:25 step:23925 [D loss: 0.808451, acc.: 52.34%] [G loss: 1.098600]\n",
      "epoch:25 step:23926 [D loss: 0.809944, acc.: 46.09%] [G loss: 1.201178]\n",
      "epoch:25 step:23927 [D loss: 0.670211, acc.: 64.06%] [G loss: 1.089918]\n",
      "epoch:25 step:23928 [D loss: 0.376614, acc.: 85.16%] [G loss: 1.104517]\n",
      "epoch:25 step:23929 [D loss: 0.384616, acc.: 79.69%] [G loss: 1.284717]\n",
      "epoch:25 step:23930 [D loss: 0.458585, acc.: 85.16%] [G loss: 1.192939]\n",
      "epoch:25 step:23931 [D loss: 0.604592, acc.: 70.31%] [G loss: 1.090860]\n",
      "epoch:25 step:23932 [D loss: 0.539943, acc.: 75.78%] [G loss: 0.866730]\n",
      "epoch:25 step:23933 [D loss: 0.474952, acc.: 82.03%] [G loss: 1.199286]\n",
      "epoch:25 step:23934 [D loss: 0.749622, acc.: 48.44%] [G loss: 0.990411]\n",
      "epoch:25 step:23935 [D loss: 0.560889, acc.: 75.78%] [G loss: 0.888970]\n",
      "epoch:25 step:23936 [D loss: 0.397088, acc.: 85.16%] [G loss: 1.177449]\n",
      "epoch:25 step:23937 [D loss: 0.581629, acc.: 72.66%] [G loss: 1.185762]\n",
      "epoch:25 step:23938 [D loss: 0.396369, acc.: 82.81%] [G loss: 1.349443]\n",
      "epoch:25 step:23939 [D loss: 0.382509, acc.: 89.84%] [G loss: 1.500654]\n",
      "epoch:25 step:23940 [D loss: 0.338454, acc.: 91.41%] [G loss: 1.448738]\n",
      "epoch:25 step:23941 [D loss: 0.682282, acc.: 59.38%] [G loss: 1.384253]\n",
      "epoch:25 step:23942 [D loss: 0.484876, acc.: 78.12%] [G loss: 1.213626]\n",
      "epoch:25 step:23943 [D loss: 0.558436, acc.: 70.31%] [G loss: 1.410694]\n",
      "epoch:25 step:23944 [D loss: 0.492462, acc.: 76.56%] [G loss: 1.290212]\n",
      "epoch:25 step:23945 [D loss: 0.618892, acc.: 64.84%] [G loss: 1.220988]\n",
      "epoch:25 step:23946 [D loss: 0.681593, acc.: 62.50%] [G loss: 1.000618]\n",
      "epoch:25 step:23947 [D loss: 0.609271, acc.: 67.97%] [G loss: 0.899816]\n",
      "epoch:25 step:23948 [D loss: 0.622252, acc.: 67.97%] [G loss: 1.215120]\n",
      "epoch:25 step:23949 [D loss: 0.500208, acc.: 77.34%] [G loss: 1.155908]\n",
      "epoch:25 step:23950 [D loss: 0.644237, acc.: 57.81%] [G loss: 1.036601]\n",
      "epoch:25 step:23951 [D loss: 0.442137, acc.: 88.28%] [G loss: 1.070728]\n",
      "epoch:25 step:23952 [D loss: 0.463037, acc.: 83.59%] [G loss: 1.250618]\n",
      "epoch:25 step:23953 [D loss: 0.559654, acc.: 71.09%] [G loss: 1.153208]\n",
      "epoch:25 step:23954 [D loss: 0.576981, acc.: 71.09%] [G loss: 1.237447]\n",
      "epoch:25 step:23955 [D loss: 0.304257, acc.: 92.19%] [G loss: 1.387309]\n",
      "epoch:25 step:23956 [D loss: 0.659721, acc.: 61.72%] [G loss: 1.260239]\n",
      "epoch:25 step:23957 [D loss: 0.610055, acc.: 63.28%] [G loss: 1.168493]\n",
      "epoch:25 step:23958 [D loss: 0.529143, acc.: 73.44%] [G loss: 1.139321]\n",
      "epoch:25 step:23959 [D loss: 0.742763, acc.: 51.56%] [G loss: 0.861820]\n",
      "epoch:25 step:23960 [D loss: 0.387050, acc.: 83.59%] [G loss: 1.216113]\n",
      "epoch:25 step:23961 [D loss: 0.211081, acc.: 94.53%] [G loss: 1.527614]\n",
      "epoch:25 step:23962 [D loss: 0.321843, acc.: 90.62%] [G loss: 1.525645]\n",
      "epoch:25 step:23963 [D loss: 0.364420, acc.: 88.28%] [G loss: 1.878723]\n",
      "epoch:25 step:23964 [D loss: 0.304952, acc.: 92.19%] [G loss: 1.870622]\n",
      "epoch:25 step:23965 [D loss: 0.360662, acc.: 92.19%] [G loss: 1.497103]\n",
      "epoch:25 step:23966 [D loss: 0.430398, acc.: 85.16%] [G loss: 1.600396]\n",
      "epoch:25 step:23967 [D loss: 0.883624, acc.: 54.69%] [G loss: 1.125272]\n",
      "epoch:25 step:23968 [D loss: 0.660651, acc.: 66.41%] [G loss: 1.073973]\n",
      "epoch:25 step:23969 [D loss: 0.850360, acc.: 50.00%] [G loss: 0.846734]\n",
      "epoch:25 step:23970 [D loss: 0.677417, acc.: 62.50%] [G loss: 0.957876]\n",
      "epoch:25 step:23971 [D loss: 0.663603, acc.: 57.03%] [G loss: 0.879654]\n",
      "epoch:25 step:23972 [D loss: 0.837374, acc.: 42.97%] [G loss: 0.925871]\n",
      "epoch:25 step:23973 [D loss: 0.773217, acc.: 50.00%] [G loss: 0.903733]\n",
      "epoch:25 step:23974 [D loss: 0.683922, acc.: 56.25%] [G loss: 1.069676]\n",
      "epoch:25 step:23975 [D loss: 0.412199, acc.: 83.59%] [G loss: 0.887798]\n",
      "epoch:25 step:23976 [D loss: 0.553376, acc.: 69.53%] [G loss: 1.113345]\n",
      "epoch:25 step:23977 [D loss: 0.649907, acc.: 60.94%] [G loss: 1.066069]\n",
      "epoch:25 step:23978 [D loss: 0.776270, acc.: 56.25%] [G loss: 0.918931]\n",
      "epoch:25 step:23979 [D loss: 0.569414, acc.: 69.53%] [G loss: 1.059642]\n",
      "epoch:25 step:23980 [D loss: 0.739900, acc.: 48.44%] [G loss: 1.072310]\n",
      "epoch:25 step:23981 [D loss: 0.679430, acc.: 61.72%] [G loss: 1.278839]\n",
      "epoch:25 step:23982 [D loss: 0.588489, acc.: 68.75%] [G loss: 1.306877]\n",
      "epoch:25 step:23983 [D loss: 0.666796, acc.: 57.81%] [G loss: 0.802419]\n",
      "epoch:25 step:23984 [D loss: 0.295037, acc.: 85.94%] [G loss: 1.057642]\n",
      "epoch:25 step:23985 [D loss: 0.191610, acc.: 97.66%] [G loss: 1.077304]\n",
      "epoch:25 step:23986 [D loss: 0.166805, acc.: 96.09%] [G loss: 1.595724]\n",
      "epoch:25 step:23987 [D loss: 0.785553, acc.: 49.22%] [G loss: 1.371912]\n",
      "epoch:25 step:23988 [D loss: 0.850590, acc.: 41.41%] [G loss: 1.376626]\n",
      "epoch:25 step:23989 [D loss: 0.574744, acc.: 67.97%] [G loss: 0.959874]\n",
      "epoch:25 step:23990 [D loss: 0.547761, acc.: 74.22%] [G loss: 1.331133]\n",
      "epoch:25 step:23991 [D loss: 0.394087, acc.: 75.00%] [G loss: 1.235159]\n",
      "epoch:25 step:23992 [D loss: 0.245666, acc.: 88.28%] [G loss: 1.502498]\n",
      "epoch:25 step:23993 [D loss: 0.460059, acc.: 82.03%] [G loss: 1.566953]\n",
      "epoch:25 step:23994 [D loss: 0.567813, acc.: 67.97%] [G loss: 1.538465]\n",
      "epoch:25 step:23995 [D loss: 0.463599, acc.: 82.81%] [G loss: 1.558658]\n",
      "epoch:25 step:23996 [D loss: 0.540917, acc.: 74.22%] [G loss: 1.392850]\n",
      "epoch:25 step:23997 [D loss: 0.341437, acc.: 91.41%] [G loss: 1.266366]\n",
      "epoch:25 step:23998 [D loss: 0.367467, acc.: 88.28%] [G loss: 1.539809]\n",
      "epoch:25 step:23999 [D loss: 0.760024, acc.: 51.56%] [G loss: 1.288194]\n",
      "epoch:25 step:24000 [D loss: 0.332738, acc.: 89.06%] [G loss: 1.429119]\n",
      "epoch:25 step:24001 [D loss: 0.230456, acc.: 96.09%] [G loss: 1.682484]\n",
      "epoch:25 step:24002 [D loss: 0.299477, acc.: 89.06%] [G loss: 1.603660]\n",
      "epoch:25 step:24003 [D loss: 0.224979, acc.: 97.66%] [G loss: 1.078340]\n",
      "epoch:25 step:24004 [D loss: 0.189209, acc.: 95.31%] [G loss: 2.220650]\n",
      "epoch:25 step:24005 [D loss: 0.809052, acc.: 53.91%] [G loss: 1.210585]\n",
      "epoch:25 step:24006 [D loss: 0.900437, acc.: 40.62%] [G loss: 1.309556]\n",
      "epoch:25 step:24007 [D loss: 0.858637, acc.: 46.09%] [G loss: 2.170095]\n",
      "epoch:25 step:24008 [D loss: 0.909135, acc.: 46.09%] [G loss: 0.935253]\n",
      "epoch:25 step:24009 [D loss: 0.775272, acc.: 46.09%] [G loss: 1.152332]\n",
      "epoch:25 step:24010 [D loss: 0.732260, acc.: 54.69%] [G loss: 0.853281]\n",
      "epoch:25 step:24011 [D loss: 0.591090, acc.: 62.50%] [G loss: 1.281174]\n",
      "epoch:25 step:24012 [D loss: 0.231030, acc.: 92.19%] [G loss: 1.115926]\n",
      "epoch:25 step:24013 [D loss: 0.626171, acc.: 60.16%] [G loss: 1.768728]\n",
      "epoch:25 step:24014 [D loss: 0.240523, acc.: 89.06%] [G loss: 1.985978]\n",
      "epoch:25 step:24015 [D loss: 0.628640, acc.: 64.06%] [G loss: 1.310455]\n",
      "epoch:25 step:24016 [D loss: 0.748949, acc.: 61.72%] [G loss: 1.843769]\n",
      "epoch:25 step:24017 [D loss: 0.602848, acc.: 69.53%] [G loss: 1.523348]\n",
      "epoch:25 step:24018 [D loss: 0.771879, acc.: 54.69%] [G loss: 1.295558]\n",
      "epoch:25 step:24019 [D loss: 0.479366, acc.: 78.12%] [G loss: 1.330777]\n",
      "epoch:25 step:24020 [D loss: 0.519793, acc.: 78.12%] [G loss: 1.317258]\n",
      "epoch:25 step:24021 [D loss: 0.622879, acc.: 65.62%] [G loss: 1.349766]\n",
      "epoch:25 step:24022 [D loss: 0.806650, acc.: 50.00%] [G loss: 1.189193]\n",
      "epoch:25 step:24023 [D loss: 0.817565, acc.: 42.97%] [G loss: 0.832761]\n",
      "epoch:25 step:24024 [D loss: 0.645225, acc.: 62.50%] [G loss: 0.745298]\n",
      "epoch:25 step:24025 [D loss: 0.563195, acc.: 65.62%] [G loss: 0.980934]\n",
      "epoch:25 step:24026 [D loss: 0.313302, acc.: 89.84%] [G loss: 0.983023]\n",
      "epoch:25 step:24027 [D loss: 0.649750, acc.: 62.50%] [G loss: 1.042886]\n",
      "epoch:25 step:24028 [D loss: 0.632003, acc.: 59.38%] [G loss: 0.882902]\n",
      "epoch:25 step:24029 [D loss: 0.434220, acc.: 82.03%] [G loss: 1.188480]\n",
      "epoch:25 step:24030 [D loss: 0.835651, acc.: 39.06%] [G loss: 1.526977]\n",
      "epoch:25 step:24031 [D loss: 0.615700, acc.: 64.06%] [G loss: 1.349817]\n",
      "epoch:25 step:24032 [D loss: 0.652473, acc.: 64.06%] [G loss: 0.976258]\n",
      "epoch:25 step:24033 [D loss: 0.598225, acc.: 70.31%] [G loss: 0.615880]\n",
      "epoch:25 step:24034 [D loss: 0.381711, acc.: 82.03%] [G loss: 1.126748]\n",
      "epoch:25 step:24035 [D loss: 0.695880, acc.: 57.03%] [G loss: 1.075549]\n",
      "epoch:25 step:24036 [D loss: 0.293137, acc.: 90.62%] [G loss: 1.224876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24037 [D loss: 0.706673, acc.: 57.81%] [G loss: 0.937289]\n",
      "epoch:25 step:24038 [D loss: 0.642683, acc.: 60.16%] [G loss: 1.563113]\n",
      "epoch:25 step:24039 [D loss: 0.747944, acc.: 49.22%] [G loss: 0.966339]\n",
      "epoch:25 step:24040 [D loss: 0.617728, acc.: 62.50%] [G loss: 1.257238]\n",
      "epoch:25 step:24041 [D loss: 0.787633, acc.: 41.41%] [G loss: 0.667309]\n",
      "epoch:25 step:24042 [D loss: 0.505074, acc.: 69.53%] [G loss: 1.302318]\n",
      "epoch:25 step:24043 [D loss: 0.771798, acc.: 57.03%] [G loss: 1.106803]\n",
      "epoch:25 step:24044 [D loss: 0.742155, acc.: 55.47%] [G loss: 1.229700]\n",
      "epoch:25 step:24045 [D loss: 0.535815, acc.: 74.22%] [G loss: 1.159868]\n",
      "epoch:25 step:24046 [D loss: 0.628468, acc.: 61.72%] [G loss: 1.253368]\n",
      "epoch:25 step:24047 [D loss: 0.512824, acc.: 77.34%] [G loss: 1.466743]\n",
      "epoch:25 step:24048 [D loss: 0.559571, acc.: 73.44%] [G loss: 1.188946]\n",
      "epoch:25 step:24049 [D loss: 0.401194, acc.: 92.19%] [G loss: 1.109427]\n",
      "epoch:25 step:24050 [D loss: 0.673743, acc.: 59.38%] [G loss: 1.150603]\n",
      "epoch:25 step:24051 [D loss: 0.448296, acc.: 80.47%] [G loss: 1.345721]\n",
      "epoch:25 step:24052 [D loss: 0.581871, acc.: 67.19%] [G loss: 1.301669]\n",
      "epoch:25 step:24053 [D loss: 0.662290, acc.: 64.06%] [G loss: 1.072361]\n",
      "epoch:25 step:24054 [D loss: 0.367060, acc.: 89.84%] [G loss: 1.386594]\n",
      "epoch:25 step:24055 [D loss: 0.495424, acc.: 78.12%] [G loss: 1.319994]\n",
      "epoch:25 step:24056 [D loss: 0.729182, acc.: 52.34%] [G loss: 1.355606]\n",
      "epoch:25 step:24057 [D loss: 0.358399, acc.: 90.62%] [G loss: 1.494313]\n",
      "epoch:25 step:24058 [D loss: 0.252954, acc.: 92.19%] [G loss: 1.522354]\n",
      "epoch:25 step:24059 [D loss: 0.252623, acc.: 92.97%] [G loss: 1.992662]\n",
      "epoch:25 step:24060 [D loss: 0.330434, acc.: 94.53%] [G loss: 1.557486]\n",
      "epoch:25 step:24061 [D loss: 0.587485, acc.: 71.09%] [G loss: 1.501486]\n",
      "epoch:25 step:24062 [D loss: 0.558281, acc.: 71.09%] [G loss: 1.452068]\n",
      "epoch:25 step:24063 [D loss: 0.411293, acc.: 85.16%] [G loss: 1.828984]\n",
      "epoch:25 step:24064 [D loss: 0.712874, acc.: 52.34%] [G loss: 1.062510]\n",
      "epoch:25 step:24065 [D loss: 0.740957, acc.: 57.81%] [G loss: 1.530171]\n",
      "epoch:25 step:24066 [D loss: 0.700616, acc.: 60.94%] [G loss: 1.093927]\n",
      "epoch:25 step:24067 [D loss: 0.797611, acc.: 47.66%] [G loss: 0.996462]\n",
      "epoch:25 step:24068 [D loss: 0.554033, acc.: 69.53%] [G loss: 0.783350]\n",
      "epoch:25 step:24069 [D loss: 0.295626, acc.: 87.50%] [G loss: 0.902580]\n",
      "epoch:25 step:24070 [D loss: 0.312341, acc.: 89.84%] [G loss: 1.569163]\n",
      "epoch:25 step:24071 [D loss: 0.258784, acc.: 88.28%] [G loss: 1.129479]\n",
      "epoch:25 step:24072 [D loss: 0.231398, acc.: 96.09%] [G loss: 0.975134]\n",
      "epoch:25 step:24073 [D loss: 0.251982, acc.: 95.31%] [G loss: 1.623175]\n",
      "epoch:25 step:24074 [D loss: 0.304673, acc.: 92.19%] [G loss: 1.152080]\n",
      "epoch:25 step:24075 [D loss: 0.204755, acc.: 97.66%] [G loss: 1.900247]\n",
      "epoch:25 step:24076 [D loss: 0.313240, acc.: 93.75%] [G loss: 1.614971]\n",
      "epoch:25 step:24077 [D loss: 0.681484, acc.: 62.50%] [G loss: 0.660911]\n",
      "epoch:25 step:24078 [D loss: 0.806054, acc.: 50.00%] [G loss: 0.949838]\n",
      "epoch:25 step:24079 [D loss: 0.834908, acc.: 44.53%] [G loss: 1.214375]\n",
      "epoch:25 step:24080 [D loss: 0.801171, acc.: 54.69%] [G loss: 0.688315]\n",
      "epoch:25 step:24081 [D loss: 0.996432, acc.: 44.53%] [G loss: 1.255167]\n",
      "epoch:25 step:24082 [D loss: 0.737371, acc.: 49.22%] [G loss: 1.573918]\n",
      "epoch:25 step:24083 [D loss: 0.603828, acc.: 65.62%] [G loss: 1.447164]\n",
      "epoch:25 step:24084 [D loss: 0.420669, acc.: 82.81%] [G loss: 1.103327]\n",
      "epoch:25 step:24085 [D loss: 0.434967, acc.: 83.59%] [G loss: 1.338687]\n",
      "epoch:25 step:24086 [D loss: 0.498428, acc.: 78.91%] [G loss: 1.465335]\n",
      "epoch:25 step:24087 [D loss: 0.795700, acc.: 50.00%] [G loss: 0.980326]\n",
      "epoch:25 step:24088 [D loss: 0.442921, acc.: 85.16%] [G loss: 1.289097]\n",
      "epoch:25 step:24089 [D loss: 0.471775, acc.: 81.25%] [G loss: 1.401923]\n",
      "epoch:25 step:24090 [D loss: 0.471191, acc.: 71.88%] [G loss: 1.500767]\n",
      "epoch:25 step:24091 [D loss: 0.763261, acc.: 54.69%] [G loss: 1.498207]\n",
      "epoch:25 step:24092 [D loss: 0.719450, acc.: 57.81%] [G loss: 1.437219]\n",
      "epoch:25 step:24093 [D loss: 0.703393, acc.: 60.94%] [G loss: 1.378226]\n",
      "epoch:25 step:24094 [D loss: 0.632389, acc.: 63.28%] [G loss: 1.158796]\n",
      "epoch:25 step:24095 [D loss: 0.610069, acc.: 64.84%] [G loss: 0.992661]\n",
      "epoch:25 step:24096 [D loss: 0.503176, acc.: 76.56%] [G loss: 1.327562]\n",
      "epoch:25 step:24097 [D loss: 0.610562, acc.: 64.06%] [G loss: 1.089369]\n",
      "epoch:25 step:24098 [D loss: 0.660650, acc.: 59.38%] [G loss: 0.875849]\n",
      "epoch:25 step:24099 [D loss: 0.511351, acc.: 74.22%] [G loss: 1.057706]\n",
      "epoch:25 step:24100 [D loss: 0.754334, acc.: 57.03%] [G loss: 0.913257]\n",
      "epoch:25 step:24101 [D loss: 0.653895, acc.: 60.94%] [G loss: 0.814377]\n",
      "epoch:25 step:24102 [D loss: 0.574600, acc.: 70.31%] [G loss: 0.992690]\n",
      "epoch:25 step:24103 [D loss: 0.630845, acc.: 61.72%] [G loss: 0.891880]\n",
      "epoch:25 step:24104 [D loss: 0.663961, acc.: 60.16%] [G loss: 1.021671]\n",
      "epoch:25 step:24105 [D loss: 0.584696, acc.: 71.88%] [G loss: 0.930224]\n",
      "epoch:25 step:24106 [D loss: 0.618499, acc.: 62.50%] [G loss: 0.805521]\n",
      "epoch:25 step:24107 [D loss: 0.755358, acc.: 52.34%] [G loss: 0.969727]\n",
      "epoch:25 step:24108 [D loss: 0.582184, acc.: 67.97%] [G loss: 1.244419]\n",
      "epoch:25 step:24109 [D loss: 0.472563, acc.: 83.59%] [G loss: 0.903011]\n",
      "epoch:25 step:24110 [D loss: 0.599148, acc.: 71.88%] [G loss: 1.245165]\n",
      "epoch:25 step:24111 [D loss: 0.473643, acc.: 80.47%] [G loss: 1.196094]\n",
      "epoch:25 step:24112 [D loss: 0.543102, acc.: 75.78%] [G loss: 1.289596]\n",
      "epoch:25 step:24113 [D loss: 0.725894, acc.: 53.12%] [G loss: 1.252056]\n",
      "epoch:25 step:24114 [D loss: 0.773733, acc.: 55.47%] [G loss: 1.043649]\n",
      "epoch:25 step:24115 [D loss: 0.549434, acc.: 72.66%] [G loss: 1.174133]\n",
      "epoch:25 step:24116 [D loss: 0.643736, acc.: 60.94%] [G loss: 0.917702]\n",
      "epoch:25 step:24117 [D loss: 0.801499, acc.: 46.88%] [G loss: 0.971403]\n",
      "epoch:25 step:24118 [D loss: 0.649047, acc.: 63.28%] [G loss: 1.091613]\n",
      "epoch:25 step:24119 [D loss: 0.472799, acc.: 78.91%] [G loss: 0.949647]\n",
      "epoch:25 step:24120 [D loss: 0.707706, acc.: 55.47%] [G loss: 0.913218]\n",
      "epoch:25 step:24121 [D loss: 0.576876, acc.: 69.53%] [G loss: 1.008938]\n",
      "epoch:25 step:24122 [D loss: 0.204093, acc.: 94.53%] [G loss: 1.459337]\n",
      "epoch:25 step:24123 [D loss: 0.364786, acc.: 90.62%] [G loss: 1.616331]\n",
      "epoch:25 step:24124 [D loss: 0.388148, acc.: 90.62%] [G loss: 1.564931]\n",
      "epoch:25 step:24125 [D loss: 0.523506, acc.: 72.66%] [G loss: 1.311876]\n",
      "epoch:25 step:24126 [D loss: 0.267843, acc.: 93.75%] [G loss: 1.711096]\n",
      "epoch:25 step:24127 [D loss: 0.301596, acc.: 92.97%] [G loss: 1.649786]\n",
      "epoch:25 step:24128 [D loss: 0.548411, acc.: 70.31%] [G loss: 1.450110]\n",
      "epoch:25 step:24129 [D loss: 0.398286, acc.: 86.72%] [G loss: 1.162685]\n",
      "epoch:25 step:24130 [D loss: 0.744197, acc.: 53.91%] [G loss: 1.280554]\n",
      "epoch:25 step:24131 [D loss: 0.247926, acc.: 96.88%] [G loss: 1.805077]\n",
      "epoch:25 step:24132 [D loss: 0.201978, acc.: 96.09%] [G loss: 1.162504]\n",
      "epoch:25 step:24133 [D loss: 0.261490, acc.: 87.50%] [G loss: 1.479738]\n",
      "epoch:25 step:24134 [D loss: 0.380749, acc.: 76.56%] [G loss: 1.878600]\n",
      "epoch:25 step:24135 [D loss: 0.915469, acc.: 53.12%] [G loss: 1.872147]\n",
      "epoch:25 step:24136 [D loss: 0.807837, acc.: 50.78%] [G loss: 1.181586]\n",
      "epoch:25 step:24137 [D loss: 0.648670, acc.: 61.72%] [G loss: 1.164174]\n",
      "epoch:25 step:24138 [D loss: 0.219188, acc.: 94.53%] [G loss: 1.406334]\n",
      "epoch:25 step:24139 [D loss: 0.250027, acc.: 91.41%] [G loss: 1.519452]\n",
      "epoch:25 step:24140 [D loss: 0.794360, acc.: 53.91%] [G loss: 1.461754]\n",
      "epoch:25 step:24141 [D loss: 0.878776, acc.: 45.31%] [G loss: 1.362115]\n",
      "epoch:25 step:24142 [D loss: 0.701330, acc.: 60.94%] [G loss: 1.171396]\n",
      "epoch:25 step:24143 [D loss: 0.736991, acc.: 52.34%] [G loss: 0.658027]\n",
      "epoch:25 step:24144 [D loss: 0.725454, acc.: 46.88%] [G loss: 1.212141]\n",
      "epoch:25 step:24145 [D loss: 0.670125, acc.: 58.59%] [G loss: 1.107345]\n",
      "epoch:25 step:24146 [D loss: 0.642453, acc.: 64.84%] [G loss: 1.109065]\n",
      "epoch:25 step:24147 [D loss: 0.479556, acc.: 80.47%] [G loss: 0.982840]\n",
      "epoch:25 step:24148 [D loss: 0.363737, acc.: 89.84%] [G loss: 1.009332]\n",
      "epoch:25 step:24149 [D loss: 0.753701, acc.: 43.75%] [G loss: 1.369042]\n",
      "epoch:25 step:24150 [D loss: 0.720553, acc.: 53.91%] [G loss: 1.091778]\n",
      "epoch:25 step:24151 [D loss: 0.582215, acc.: 64.84%] [G loss: 1.221043]\n",
      "epoch:25 step:24152 [D loss: 0.287989, acc.: 93.75%] [G loss: 1.316938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24153 [D loss: 0.234917, acc.: 92.19%] [G loss: 1.245836]\n",
      "epoch:25 step:24154 [D loss: 0.201943, acc.: 97.66%] [G loss: 1.343135]\n",
      "epoch:25 step:24155 [D loss: 0.208324, acc.: 96.09%] [G loss: 1.381938]\n",
      "epoch:25 step:24156 [D loss: 0.209694, acc.: 96.88%] [G loss: 1.082064]\n",
      "epoch:25 step:24157 [D loss: 0.175850, acc.: 99.22%] [G loss: 1.528048]\n",
      "epoch:25 step:24158 [D loss: 0.191471, acc.: 97.66%] [G loss: 1.609289]\n",
      "epoch:25 step:24159 [D loss: 0.831499, acc.: 48.44%] [G loss: 1.565865]\n",
      "epoch:25 step:24160 [D loss: 0.675918, acc.: 54.69%] [G loss: 1.357291]\n",
      "epoch:25 step:24161 [D loss: 0.704406, acc.: 52.34%] [G loss: 1.131017]\n",
      "epoch:25 step:24162 [D loss: 0.687609, acc.: 58.59%] [G loss: 0.929342]\n",
      "epoch:25 step:24163 [D loss: 0.538099, acc.: 75.00%] [G loss: 1.237955]\n",
      "epoch:25 step:24164 [D loss: 0.563376, acc.: 72.66%] [G loss: 1.102314]\n",
      "epoch:25 step:24165 [D loss: 0.460136, acc.: 81.25%] [G loss: 1.166797]\n",
      "epoch:25 step:24166 [D loss: 0.668189, acc.: 58.59%] [G loss: 1.130412]\n",
      "epoch:25 step:24167 [D loss: 0.546362, acc.: 68.75%] [G loss: 1.236613]\n",
      "epoch:25 step:24168 [D loss: 0.560147, acc.: 69.53%] [G loss: 1.035864]\n",
      "epoch:25 step:24169 [D loss: 0.706353, acc.: 52.34%] [G loss: 1.016212]\n",
      "epoch:25 step:24170 [D loss: 0.244270, acc.: 93.75%] [G loss: 1.332304]\n",
      "epoch:25 step:24171 [D loss: 0.415866, acc.: 86.72%] [G loss: 1.666199]\n",
      "epoch:25 step:24172 [D loss: 0.595481, acc.: 71.88%] [G loss: 0.464408]\n",
      "epoch:25 step:24173 [D loss: 0.768410, acc.: 50.78%] [G loss: 1.279684]\n",
      "epoch:25 step:24174 [D loss: 0.581182, acc.: 67.97%] [G loss: 1.256286]\n",
      "epoch:25 step:24175 [D loss: 0.501846, acc.: 78.12%] [G loss: 1.601092]\n",
      "epoch:25 step:24176 [D loss: 0.803013, acc.: 48.44%] [G loss: 1.294434]\n",
      "epoch:25 step:24177 [D loss: 0.787664, acc.: 53.12%] [G loss: 1.170195]\n",
      "epoch:25 step:24178 [D loss: 0.592776, acc.: 68.75%] [G loss: 1.152194]\n",
      "epoch:25 step:24179 [D loss: 0.379790, acc.: 82.81%] [G loss: 1.157489]\n",
      "epoch:25 step:24180 [D loss: 0.245118, acc.: 92.19%] [G loss: 1.283384]\n",
      "epoch:25 step:24181 [D loss: 0.360444, acc.: 85.94%] [G loss: 1.430498]\n",
      "epoch:25 step:24182 [D loss: 0.507499, acc.: 69.53%] [G loss: 1.125996]\n",
      "epoch:25 step:24183 [D loss: 0.751373, acc.: 53.12%] [G loss: 0.419641]\n",
      "epoch:25 step:24184 [D loss: 0.619136, acc.: 66.41%] [G loss: 1.157974]\n",
      "epoch:25 step:24185 [D loss: 0.506267, acc.: 79.69%] [G loss: 0.950609]\n",
      "epoch:25 step:24186 [D loss: 0.652483, acc.: 65.62%] [G loss: 1.252343]\n",
      "epoch:25 step:24187 [D loss: 0.689247, acc.: 59.38%] [G loss: 1.112746]\n",
      "epoch:25 step:24188 [D loss: 0.729386, acc.: 55.47%] [G loss: 1.199523]\n",
      "epoch:25 step:24189 [D loss: 0.335571, acc.: 90.62%] [G loss: 0.865891]\n",
      "epoch:25 step:24190 [D loss: 0.592470, acc.: 66.41%] [G loss: 0.853314]\n",
      "epoch:25 step:24191 [D loss: 0.735103, acc.: 50.78%] [G loss: 0.912077]\n",
      "epoch:25 step:24192 [D loss: 0.609759, acc.: 64.06%] [G loss: 1.327344]\n",
      "epoch:25 step:24193 [D loss: 0.247474, acc.: 93.75%] [G loss: 1.399518]\n",
      "epoch:25 step:24194 [D loss: 0.299770, acc.: 88.28%] [G loss: 1.524363]\n",
      "epoch:25 step:24195 [D loss: 0.387985, acc.: 85.94%] [G loss: 1.854486]\n",
      "epoch:25 step:24196 [D loss: 0.677115, acc.: 61.72%] [G loss: 1.072195]\n",
      "epoch:25 step:24197 [D loss: 0.623347, acc.: 58.59%] [G loss: 1.463344]\n",
      "epoch:25 step:24198 [D loss: 0.499974, acc.: 76.56%] [G loss: 1.159654]\n",
      "epoch:25 step:24199 [D loss: 0.334450, acc.: 86.72%] [G loss: 1.204169]\n",
      "epoch:25 step:24200 [D loss: 0.191376, acc.: 98.44%] [G loss: 1.394621]\n",
      "epoch:25 step:24201 [D loss: 0.502444, acc.: 78.12%] [G loss: 1.199901]\n",
      "epoch:25 step:24202 [D loss: 0.282416, acc.: 95.31%] [G loss: 1.288827]\n",
      "epoch:25 step:24203 [D loss: 0.457724, acc.: 77.34%] [G loss: 1.565528]\n",
      "epoch:25 step:24204 [D loss: 0.848653, acc.: 52.34%] [G loss: 0.863283]\n",
      "epoch:25 step:24205 [D loss: 0.682714, acc.: 55.47%] [G loss: 0.914622]\n",
      "epoch:25 step:24206 [D loss: 0.505162, acc.: 65.62%] [G loss: 1.022485]\n",
      "epoch:25 step:24207 [D loss: 0.397390, acc.: 85.94%] [G loss: 1.258186]\n",
      "epoch:25 step:24208 [D loss: 0.667189, acc.: 62.50%] [G loss: 1.072129]\n",
      "epoch:25 step:24209 [D loss: 0.707941, acc.: 61.72%] [G loss: 1.014564]\n",
      "epoch:25 step:24210 [D loss: 0.568617, acc.: 64.84%] [G loss: 1.103788]\n",
      "epoch:25 step:24211 [D loss: 0.542500, acc.: 67.97%] [G loss: 1.098633]\n",
      "epoch:25 step:24212 [D loss: 0.742985, acc.: 47.66%] [G loss: 1.198730]\n",
      "epoch:25 step:24213 [D loss: 0.717144, acc.: 57.03%] [G loss: 0.820559]\n",
      "epoch:25 step:24214 [D loss: 0.826820, acc.: 44.53%] [G loss: 0.967531]\n",
      "epoch:25 step:24215 [D loss: 0.829073, acc.: 43.75%] [G loss: 1.418551]\n",
      "epoch:25 step:24216 [D loss: 0.298892, acc.: 95.31%] [G loss: 1.095481]\n",
      "epoch:25 step:24217 [D loss: 0.214918, acc.: 98.44%] [G loss: 1.435507]\n",
      "epoch:25 step:24218 [D loss: 0.324097, acc.: 88.28%] [G loss: 1.292789]\n",
      "epoch:25 step:24219 [D loss: 0.280005, acc.: 90.62%] [G loss: 1.633986]\n",
      "epoch:25 step:24220 [D loss: 0.623016, acc.: 60.94%] [G loss: 1.441788]\n",
      "epoch:25 step:24221 [D loss: 0.243095, acc.: 94.53%] [G loss: 1.491299]\n",
      "epoch:25 step:24222 [D loss: 0.627433, acc.: 60.94%] [G loss: 1.276728]\n",
      "epoch:25 step:24223 [D loss: 0.432604, acc.: 87.50%] [G loss: 1.282881]\n",
      "epoch:25 step:24224 [D loss: 0.806501, acc.: 43.75%] [G loss: 1.453296]\n",
      "epoch:25 step:24225 [D loss: 0.487521, acc.: 78.91%] [G loss: 1.355667]\n",
      "epoch:25 step:24226 [D loss: 0.585195, acc.: 68.75%] [G loss: 0.876048]\n",
      "epoch:25 step:24227 [D loss: 0.348051, acc.: 82.81%] [G loss: 1.264770]\n",
      "epoch:25 step:24228 [D loss: 0.596557, acc.: 67.97%] [G loss: 1.346155]\n",
      "epoch:25 step:24229 [D loss: 0.284178, acc.: 86.72%] [G loss: 0.877494]\n",
      "epoch:25 step:24230 [D loss: 0.370547, acc.: 88.28%] [G loss: 1.282615]\n",
      "epoch:25 step:24231 [D loss: 0.199040, acc.: 94.53%] [G loss: 1.550251]\n",
      "epoch:25 step:24232 [D loss: 0.900775, acc.: 48.44%] [G loss: 1.238992]\n",
      "epoch:25 step:24233 [D loss: 0.508367, acc.: 75.00%] [G loss: 1.265594]\n",
      "epoch:25 step:24234 [D loss: 0.598836, acc.: 67.19%] [G loss: 1.004980]\n",
      "epoch:25 step:24235 [D loss: 0.532136, acc.: 71.09%] [G loss: 1.046966]\n",
      "epoch:25 step:24236 [D loss: 0.639346, acc.: 63.28%] [G loss: 1.109452]\n",
      "epoch:25 step:24237 [D loss: 0.631456, acc.: 67.19%] [G loss: 0.558274]\n",
      "epoch:25 step:24238 [D loss: 0.641431, acc.: 58.59%] [G loss: 1.246240]\n",
      "epoch:25 step:24239 [D loss: 0.708944, acc.: 53.12%] [G loss: 1.050142]\n",
      "epoch:25 step:24240 [D loss: 0.347329, acc.: 79.69%] [G loss: 1.188208]\n",
      "epoch:25 step:24241 [D loss: 0.454896, acc.: 86.72%] [G loss: 1.251592]\n",
      "epoch:25 step:24242 [D loss: 0.616325, acc.: 63.28%] [G loss: 1.106641]\n",
      "epoch:25 step:24243 [D loss: 0.659351, acc.: 60.94%] [G loss: 1.101623]\n",
      "epoch:25 step:24244 [D loss: 0.657951, acc.: 60.16%] [G loss: 1.183844]\n",
      "epoch:25 step:24245 [D loss: 0.731459, acc.: 48.44%] [G loss: 1.202142]\n",
      "epoch:25 step:24246 [D loss: 0.356219, acc.: 89.84%] [G loss: 1.346171]\n",
      "epoch:25 step:24247 [D loss: 0.640754, acc.: 57.81%] [G loss: 0.895680]\n",
      "epoch:25 step:24248 [D loss: 0.584529, acc.: 68.75%] [G loss: 1.037356]\n",
      "epoch:25 step:24249 [D loss: 0.642612, acc.: 65.62%] [G loss: 1.039544]\n",
      "epoch:25 step:24250 [D loss: 0.477814, acc.: 79.69%] [G loss: 1.178288]\n",
      "epoch:25 step:24251 [D loss: 0.610533, acc.: 67.19%] [G loss: 1.294705]\n",
      "epoch:25 step:24252 [D loss: 0.700679, acc.: 62.50%] [G loss: 1.151738]\n",
      "epoch:25 step:24253 [D loss: 0.573473, acc.: 67.19%] [G loss: 1.133477]\n",
      "epoch:25 step:24254 [D loss: 0.737745, acc.: 50.78%] [G loss: 1.150399]\n",
      "epoch:25 step:24255 [D loss: 0.519315, acc.: 81.25%] [G loss: 1.175725]\n",
      "epoch:25 step:24256 [D loss: 0.503251, acc.: 75.78%] [G loss: 1.138078]\n",
      "epoch:25 step:24257 [D loss: 0.313899, acc.: 89.84%] [G loss: 1.105227]\n",
      "epoch:25 step:24258 [D loss: 0.386685, acc.: 86.72%] [G loss: 1.018694]\n",
      "epoch:25 step:24259 [D loss: 0.328648, acc.: 91.41%] [G loss: 1.226589]\n",
      "epoch:25 step:24260 [D loss: 0.506240, acc.: 75.00%] [G loss: 1.215809]\n",
      "epoch:25 step:24261 [D loss: 0.662279, acc.: 57.03%] [G loss: 1.203901]\n",
      "epoch:25 step:24262 [D loss: 0.747144, acc.: 49.22%] [G loss: 1.222591]\n",
      "epoch:25 step:24263 [D loss: 0.690771, acc.: 58.59%] [G loss: 1.054288]\n",
      "epoch:25 step:24264 [D loss: 0.502291, acc.: 81.25%] [G loss: 1.170945]\n",
      "epoch:25 step:24265 [D loss: 0.589463, acc.: 71.88%] [G loss: 1.041686]\n",
      "epoch:25 step:24266 [D loss: 0.357720, acc.: 86.72%] [G loss: 0.959791]\n",
      "epoch:25 step:24267 [D loss: 0.285715, acc.: 87.50%] [G loss: 1.185203]\n",
      "epoch:25 step:24268 [D loss: 0.503674, acc.: 78.12%] [G loss: 1.232435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24269 [D loss: 0.501673, acc.: 75.78%] [G loss: 1.302819]\n",
      "epoch:25 step:24270 [D loss: 0.210981, acc.: 95.31%] [G loss: 1.423731]\n",
      "epoch:25 step:24271 [D loss: 0.778404, acc.: 50.00%] [G loss: 1.355700]\n",
      "epoch:25 step:24272 [D loss: 0.315852, acc.: 88.28%] [G loss: 1.513930]\n",
      "epoch:25 step:24273 [D loss: 0.778188, acc.: 47.66%] [G loss: 0.582075]\n",
      "epoch:25 step:24274 [D loss: 0.468871, acc.: 79.69%] [G loss: 1.572460]\n",
      "epoch:25 step:24275 [D loss: 0.510926, acc.: 75.00%] [G loss: 1.493426]\n",
      "epoch:25 step:24276 [D loss: 0.204118, acc.: 96.88%] [G loss: 1.309477]\n",
      "epoch:25 step:24277 [D loss: 0.164537, acc.: 96.09%] [G loss: 1.795807]\n",
      "epoch:25 step:24278 [D loss: 0.161555, acc.: 99.22%] [G loss: 1.487505]\n",
      "epoch:25 step:24279 [D loss: 0.134279, acc.: 98.44%] [G loss: 1.654569]\n",
      "epoch:25 step:24280 [D loss: 0.385003, acc.: 82.81%] [G loss: 1.235088]\n",
      "epoch:25 step:24281 [D loss: 0.855855, acc.: 52.34%] [G loss: 1.626276]\n",
      "epoch:25 step:24282 [D loss: 0.223463, acc.: 96.09%] [G loss: 1.489037]\n",
      "epoch:25 step:24283 [D loss: 0.567951, acc.: 71.88%] [G loss: 1.534702]\n",
      "epoch:25 step:24284 [D loss: 0.272803, acc.: 97.66%] [G loss: 1.575748]\n",
      "epoch:25 step:24285 [D loss: 0.325415, acc.: 92.19%] [G loss: 1.607241]\n",
      "epoch:25 step:24286 [D loss: 0.575605, acc.: 73.44%] [G loss: 1.303150]\n",
      "epoch:25 step:24287 [D loss: 0.894320, acc.: 47.66%] [G loss: 0.838629]\n",
      "epoch:25 step:24288 [D loss: 0.653474, acc.: 60.94%] [G loss: 0.871530]\n",
      "epoch:25 step:24289 [D loss: 0.594373, acc.: 68.75%] [G loss: 1.188103]\n",
      "epoch:25 step:24290 [D loss: 0.707790, acc.: 60.94%] [G loss: 0.091489]\n",
      "epoch:25 step:24291 [D loss: 0.691301, acc.: 52.34%] [G loss: 0.332845]\n",
      "epoch:25 step:24292 [D loss: 0.534693, acc.: 68.75%] [G loss: 1.004578]\n",
      "epoch:25 step:24293 [D loss: 0.628854, acc.: 67.97%] [G loss: 1.310757]\n",
      "epoch:25 step:24294 [D loss: 1.168463, acc.: 17.97%] [G loss: 1.555173]\n",
      "epoch:25 step:24295 [D loss: 0.456125, acc.: 78.91%] [G loss: 1.434591]\n",
      "epoch:25 step:24296 [D loss: 0.675226, acc.: 63.28%] [G loss: 1.428783]\n",
      "epoch:25 step:24297 [D loss: 0.682738, acc.: 57.81%] [G loss: 0.905118]\n",
      "epoch:25 step:24298 [D loss: 0.734344, acc.: 55.47%] [G loss: 1.362901]\n",
      "epoch:25 step:24299 [D loss: 0.565943, acc.: 72.66%] [G loss: 0.812103]\n",
      "epoch:25 step:24300 [D loss: 0.571796, acc.: 70.31%] [G loss: 1.101485]\n",
      "epoch:25 step:24301 [D loss: 0.542979, acc.: 74.22%] [G loss: 0.976880]\n",
      "epoch:25 step:24302 [D loss: 0.524783, acc.: 78.91%] [G loss: 1.358972]\n",
      "epoch:25 step:24303 [D loss: 0.162770, acc.: 95.31%] [G loss: 1.438596]\n",
      "epoch:25 step:24304 [D loss: 0.364528, acc.: 88.28%] [G loss: 1.827921]\n",
      "epoch:25 step:24305 [D loss: 0.943705, acc.: 43.75%] [G loss: 1.030325]\n",
      "epoch:25 step:24306 [D loss: 0.767154, acc.: 44.53%] [G loss: 1.511258]\n",
      "epoch:25 step:24307 [D loss: 0.810336, acc.: 54.69%] [G loss: 1.183440]\n",
      "epoch:25 step:24308 [D loss: 0.748878, acc.: 50.00%] [G loss: 1.386062]\n",
      "epoch:25 step:24309 [D loss: 0.834071, acc.: 48.44%] [G loss: 0.821921]\n",
      "epoch:25 step:24310 [D loss: 0.515210, acc.: 77.34%] [G loss: 1.137504]\n",
      "epoch:25 step:24311 [D loss: 0.597609, acc.: 70.31%] [G loss: 1.339284]\n",
      "epoch:25 step:24312 [D loss: 0.602153, acc.: 71.09%] [G loss: 1.175652]\n",
      "epoch:25 step:24313 [D loss: 0.813386, acc.: 40.62%] [G loss: 1.295274]\n",
      "epoch:25 step:24314 [D loss: 0.799976, acc.: 42.97%] [G loss: 1.009937]\n",
      "epoch:25 step:24315 [D loss: 0.706945, acc.: 56.25%] [G loss: 1.118836]\n",
      "epoch:25 step:24316 [D loss: 0.308285, acc.: 93.75%] [G loss: 1.285428]\n",
      "epoch:25 step:24317 [D loss: 0.210145, acc.: 94.53%] [G loss: 0.962773]\n",
      "epoch:25 step:24318 [D loss: 0.193843, acc.: 96.88%] [G loss: 1.683959]\n",
      "epoch:25 step:24319 [D loss: 0.179665, acc.: 98.44%] [G loss: 1.405453]\n",
      "epoch:25 step:24320 [D loss: 0.146584, acc.: 99.22%] [G loss: 0.959083]\n",
      "epoch:25 step:24321 [D loss: 0.169664, acc.: 99.22%] [G loss: 1.394530]\n",
      "epoch:25 step:24322 [D loss: 0.122634, acc.: 99.22%] [G loss: 1.608150]\n",
      "epoch:25 step:24323 [D loss: 0.252963, acc.: 91.41%] [G loss: 1.842047]\n",
      "epoch:25 step:24324 [D loss: 0.227739, acc.: 89.84%] [G loss: 1.708579]\n",
      "epoch:25 step:24325 [D loss: 0.646984, acc.: 64.06%] [G loss: 1.415811]\n",
      "epoch:25 step:24326 [D loss: 0.462065, acc.: 77.34%] [G loss: 2.066455]\n",
      "epoch:25 step:24327 [D loss: 0.961397, acc.: 40.62%] [G loss: 0.651017]\n",
      "epoch:25 step:24328 [D loss: 0.563880, acc.: 71.88%] [G loss: 1.041790]\n",
      "epoch:25 step:24329 [D loss: 1.229460, acc.: 39.84%] [G loss: 1.837840]\n",
      "epoch:25 step:24330 [D loss: 0.904439, acc.: 43.75%] [G loss: 1.015689]\n",
      "epoch:25 step:24331 [D loss: 0.485130, acc.: 75.00%] [G loss: 1.640193]\n",
      "epoch:25 step:24332 [D loss: 0.978087, acc.: 35.16%] [G loss: 1.393337]\n",
      "epoch:25 step:24333 [D loss: 0.889599, acc.: 37.50%] [G loss: 1.698886]\n",
      "epoch:25 step:24334 [D loss: 0.578222, acc.: 64.84%] [G loss: 1.427457]\n",
      "epoch:25 step:24335 [D loss: 0.695694, acc.: 59.38%] [G loss: 1.335548]\n",
      "epoch:25 step:24336 [D loss: 0.480066, acc.: 77.34%] [G loss: 1.699637]\n",
      "epoch:25 step:24337 [D loss: 0.169732, acc.: 98.44%] [G loss: 0.982217]\n",
      "epoch:25 step:24338 [D loss: 0.807980, acc.: 46.88%] [G loss: 1.346863]\n",
      "epoch:25 step:24339 [D loss: 0.724934, acc.: 50.00%] [G loss: 1.926463]\n",
      "epoch:25 step:24340 [D loss: 0.843207, acc.: 45.31%] [G loss: 1.808744]\n",
      "epoch:25 step:24341 [D loss: 0.430305, acc.: 85.16%] [G loss: 1.353693]\n",
      "epoch:25 step:24342 [D loss: 0.304922, acc.: 94.53%] [G loss: 1.571730]\n",
      "epoch:25 step:24343 [D loss: 0.587994, acc.: 71.09%] [G loss: 1.416205]\n",
      "epoch:25 step:24344 [D loss: 0.774865, acc.: 60.16%] [G loss: 1.073968]\n",
      "epoch:25 step:24345 [D loss: 0.255329, acc.: 89.06%] [G loss: 1.382082]\n",
      "epoch:25 step:24346 [D loss: 0.285956, acc.: 93.75%] [G loss: 1.404814]\n",
      "epoch:25 step:24347 [D loss: 0.630349, acc.: 64.06%] [G loss: 1.185372]\n",
      "epoch:25 step:24348 [D loss: 0.705643, acc.: 54.69%] [G loss: 1.252653]\n",
      "epoch:25 step:24349 [D loss: 0.644105, acc.: 69.53%] [G loss: 1.087805]\n",
      "epoch:25 step:24350 [D loss: 0.686070, acc.: 57.81%] [G loss: 0.987848]\n",
      "epoch:25 step:24351 [D loss: 0.699708, acc.: 57.81%] [G loss: 0.889228]\n",
      "epoch:25 step:24352 [D loss: 0.527748, acc.: 71.09%] [G loss: 0.901006]\n",
      "epoch:25 step:24353 [D loss: 0.668968, acc.: 59.38%] [G loss: 0.876325]\n",
      "epoch:25 step:24354 [D loss: 0.251602, acc.: 92.19%] [G loss: 0.975338]\n",
      "epoch:25 step:24355 [D loss: 0.430436, acc.: 85.94%] [G loss: 1.034426]\n",
      "epoch:25 step:24356 [D loss: 0.467403, acc.: 82.03%] [G loss: 1.071118]\n",
      "epoch:25 step:24357 [D loss: 0.604636, acc.: 69.53%] [G loss: 1.161260]\n",
      "epoch:25 step:24358 [D loss: 0.578562, acc.: 70.31%] [G loss: 0.854213]\n",
      "epoch:25 step:24359 [D loss: 0.471458, acc.: 74.22%] [G loss: 1.000122]\n",
      "epoch:25 step:24360 [D loss: 0.506263, acc.: 80.47%] [G loss: 1.118301]\n",
      "epoch:25 step:24361 [D loss: 0.467900, acc.: 79.69%] [G loss: 1.091314]\n",
      "epoch:25 step:24362 [D loss: 0.257996, acc.: 89.06%] [G loss: 1.156522]\n",
      "epoch:26 step:24363 [D loss: 0.760392, acc.: 63.28%] [G loss: 1.040783]\n",
      "epoch:26 step:24364 [D loss: 0.696162, acc.: 64.06%] [G loss: 1.020940]\n",
      "epoch:26 step:24365 [D loss: 0.699984, acc.: 58.59%] [G loss: 0.883622]\n",
      "epoch:26 step:24366 [D loss: 0.668393, acc.: 59.38%] [G loss: 0.784317]\n",
      "epoch:26 step:24367 [D loss: 0.661125, acc.: 57.03%] [G loss: 0.636641]\n",
      "epoch:26 step:24368 [D loss: 0.582095, acc.: 71.88%] [G loss: 0.816223]\n",
      "epoch:26 step:24369 [D loss: 0.610922, acc.: 71.88%] [G loss: 0.575108]\n",
      "epoch:26 step:24370 [D loss: 0.567203, acc.: 71.88%] [G loss: 0.769705]\n",
      "epoch:26 step:24371 [D loss: 0.453943, acc.: 87.50%] [G loss: 0.872496]\n",
      "epoch:26 step:24372 [D loss: 0.890297, acc.: 53.91%] [G loss: 0.931801]\n",
      "epoch:26 step:24373 [D loss: 0.499724, acc.: 77.34%] [G loss: 1.022244]\n",
      "epoch:26 step:24374 [D loss: 0.537068, acc.: 75.00%] [G loss: 0.937272]\n",
      "epoch:26 step:24375 [D loss: 0.500191, acc.: 78.12%] [G loss: 0.859099]\n",
      "epoch:26 step:24376 [D loss: 0.566428, acc.: 74.22%] [G loss: 1.041516]\n",
      "epoch:26 step:24377 [D loss: 0.451362, acc.: 79.69%] [G loss: 1.317611]\n",
      "epoch:26 step:24378 [D loss: 0.662152, acc.: 64.84%] [G loss: 0.868683]\n",
      "epoch:26 step:24379 [D loss: 0.737491, acc.: 45.31%] [G loss: 1.342560]\n",
      "epoch:26 step:24380 [D loss: 0.576849, acc.: 67.97%] [G loss: 0.256323]\n",
      "epoch:26 step:24381 [D loss: 0.912629, acc.: 33.59%] [G loss: 0.615070]\n",
      "epoch:26 step:24382 [D loss: 0.485942, acc.: 78.91%] [G loss: 1.343931]\n",
      "epoch:26 step:24383 [D loss: 0.680712, acc.: 58.59%] [G loss: 0.998540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24384 [D loss: 0.638709, acc.: 63.28%] [G loss: 1.359306]\n",
      "epoch:26 step:24385 [D loss: 0.586503, acc.: 65.62%] [G loss: 1.225929]\n",
      "epoch:26 step:24386 [D loss: 0.647865, acc.: 67.19%] [G loss: 1.102125]\n",
      "epoch:26 step:24387 [D loss: 1.177206, acc.: 50.00%] [G loss: 1.010095]\n",
      "epoch:26 step:24388 [D loss: 0.835362, acc.: 37.50%] [G loss: 1.527516]\n",
      "epoch:26 step:24389 [D loss: 0.206881, acc.: 99.22%] [G loss: 1.676547]\n",
      "epoch:26 step:24390 [D loss: 0.463669, acc.: 77.34%] [G loss: 2.023013]\n",
      "epoch:26 step:24391 [D loss: 0.365606, acc.: 88.28%] [G loss: 1.610928]\n",
      "epoch:26 step:24392 [D loss: 0.449296, acc.: 86.72%] [G loss: 1.966566]\n",
      "epoch:26 step:24393 [D loss: 0.413508, acc.: 87.50%] [G loss: 1.428662]\n",
      "epoch:26 step:24394 [D loss: 0.273688, acc.: 89.84%] [G loss: 1.460502]\n",
      "epoch:26 step:24395 [D loss: 0.184427, acc.: 98.44%] [G loss: 2.681058]\n",
      "epoch:26 step:24396 [D loss: 0.204000, acc.: 96.09%] [G loss: 1.572769]\n",
      "epoch:26 step:24397 [D loss: 0.151696, acc.: 98.44%] [G loss: 1.704710]\n",
      "epoch:26 step:24398 [D loss: 0.119152, acc.: 100.00%] [G loss: 2.314808]\n",
      "epoch:26 step:24399 [D loss: 0.844345, acc.: 48.44%] [G loss: 1.740396]\n",
      "epoch:26 step:24400 [D loss: 0.959525, acc.: 43.75%] [G loss: 1.177109]\n",
      "epoch:26 step:24401 [D loss: 0.848127, acc.: 51.56%] [G loss: 0.997090]\n",
      "epoch:26 step:24402 [D loss: 0.718609, acc.: 64.06%] [G loss: 0.853585]\n",
      "epoch:26 step:24403 [D loss: 0.554223, acc.: 73.44%] [G loss: 1.086458]\n",
      "epoch:26 step:24404 [D loss: 0.585763, acc.: 65.62%] [G loss: 0.897697]\n",
      "epoch:26 step:24405 [D loss: 0.330747, acc.: 91.41%] [G loss: 1.404614]\n",
      "epoch:26 step:24406 [D loss: 0.585719, acc.: 68.75%] [G loss: 1.256246]\n",
      "epoch:26 step:24407 [D loss: 0.577629, acc.: 67.97%] [G loss: 0.909085]\n",
      "epoch:26 step:24408 [D loss: 0.477394, acc.: 82.03%] [G loss: 1.140102]\n",
      "epoch:26 step:24409 [D loss: 0.642739, acc.: 66.41%] [G loss: 1.033308]\n",
      "epoch:26 step:24410 [D loss: 0.755542, acc.: 48.44%] [G loss: 0.415635]\n",
      "epoch:26 step:24411 [D loss: 0.620993, acc.: 71.09%] [G loss: 0.880953]\n",
      "epoch:26 step:24412 [D loss: 0.629600, acc.: 64.06%] [G loss: 0.643979]\n",
      "epoch:26 step:24413 [D loss: 0.549244, acc.: 72.66%] [G loss: 0.812958]\n",
      "epoch:26 step:24414 [D loss: 0.511851, acc.: 75.00%] [G loss: 1.030153]\n",
      "epoch:26 step:24415 [D loss: 0.774900, acc.: 50.78%] [G loss: 0.955391]\n",
      "epoch:26 step:24416 [D loss: 0.722476, acc.: 50.78%] [G loss: 1.189139]\n",
      "epoch:26 step:24417 [D loss: 0.710794, acc.: 51.56%] [G loss: 1.283160]\n",
      "epoch:26 step:24418 [D loss: 0.570594, acc.: 64.84%] [G loss: 1.319477]\n",
      "epoch:26 step:24419 [D loss: 0.398881, acc.: 83.59%] [G loss: 1.272562]\n",
      "epoch:26 step:24420 [D loss: 0.549691, acc.: 74.22%] [G loss: 1.181815]\n",
      "epoch:26 step:24421 [D loss: 0.870808, acc.: 53.12%] [G loss: 1.815926]\n",
      "epoch:26 step:24422 [D loss: 0.629898, acc.: 64.84%] [G loss: 1.141805]\n",
      "epoch:26 step:24423 [D loss: 0.624487, acc.: 65.62%] [G loss: 1.217454]\n",
      "epoch:26 step:24424 [D loss: 0.891170, acc.: 45.31%] [G loss: 1.157569]\n",
      "epoch:26 step:24425 [D loss: 0.651456, acc.: 61.72%] [G loss: 1.097652]\n",
      "epoch:26 step:24426 [D loss: 0.560410, acc.: 70.31%] [G loss: 0.763907]\n",
      "epoch:26 step:24427 [D loss: 0.655132, acc.: 53.91%] [G loss: 1.028041]\n",
      "epoch:26 step:24428 [D loss: 0.729958, acc.: 46.09%] [G loss: 0.877203]\n",
      "epoch:26 step:24429 [D loss: 0.705010, acc.: 56.25%] [G loss: 1.104406]\n",
      "epoch:26 step:24430 [D loss: 0.668578, acc.: 61.72%] [G loss: 1.187255]\n",
      "epoch:26 step:24431 [D loss: 0.460949, acc.: 78.91%] [G loss: 1.269908]\n",
      "epoch:26 step:24432 [D loss: 0.457287, acc.: 76.56%] [G loss: 1.298112]\n",
      "epoch:26 step:24433 [D loss: 0.463143, acc.: 80.47%] [G loss: 0.962776]\n",
      "epoch:26 step:24434 [D loss: 0.544441, acc.: 72.66%] [G loss: 1.737868]\n",
      "epoch:26 step:24435 [D loss: 0.589397, acc.: 67.19%] [G loss: 0.921647]\n",
      "epoch:26 step:24436 [D loss: 0.658165, acc.: 60.94%] [G loss: 0.676579]\n",
      "epoch:26 step:24437 [D loss: 0.498330, acc.: 70.31%] [G loss: 1.325721]\n",
      "epoch:26 step:24438 [D loss: 0.377549, acc.: 78.91%] [G loss: 1.016901]\n",
      "epoch:26 step:24439 [D loss: 0.508783, acc.: 77.34%] [G loss: 1.559500]\n",
      "epoch:26 step:24440 [D loss: 0.859639, acc.: 49.22%] [G loss: 1.362879]\n",
      "epoch:26 step:24441 [D loss: 1.012809, acc.: 31.25%] [G loss: 1.726004]\n",
      "epoch:26 step:24442 [D loss: 0.495057, acc.: 80.47%] [G loss: 1.035160]\n",
      "epoch:26 step:24443 [D loss: 0.521284, acc.: 78.91%] [G loss: 1.093911]\n",
      "epoch:26 step:24444 [D loss: 0.446672, acc.: 83.59%] [G loss: 1.267436]\n",
      "epoch:26 step:24445 [D loss: 0.359106, acc.: 92.19%] [G loss: 1.305146]\n",
      "epoch:26 step:24446 [D loss: 0.557743, acc.: 74.22%] [G loss: 1.533801]\n",
      "epoch:26 step:24447 [D loss: 0.601582, acc.: 68.75%] [G loss: 1.317967]\n",
      "epoch:26 step:24448 [D loss: 0.643769, acc.: 57.03%] [G loss: 0.900015]\n",
      "epoch:26 step:24449 [D loss: 0.445089, acc.: 83.59%] [G loss: 1.240338]\n",
      "epoch:26 step:24450 [D loss: 0.377671, acc.: 92.19%] [G loss: 1.192911]\n",
      "epoch:26 step:24451 [D loss: 0.481092, acc.: 82.81%] [G loss: 1.718357]\n",
      "epoch:26 step:24452 [D loss: 0.470005, acc.: 80.47%] [G loss: 1.094212]\n",
      "epoch:26 step:24453 [D loss: 0.560532, acc.: 73.44%] [G loss: 1.258340]\n",
      "epoch:26 step:24454 [D loss: 0.297564, acc.: 96.09%] [G loss: 0.835127]\n",
      "epoch:26 step:24455 [D loss: 0.308261, acc.: 94.53%] [G loss: 1.109247]\n",
      "epoch:26 step:24456 [D loss: 0.486671, acc.: 83.59%] [G loss: 1.163879]\n",
      "epoch:26 step:24457 [D loss: 0.685851, acc.: 60.16%] [G loss: 0.761600]\n",
      "epoch:26 step:24458 [D loss: 0.640123, acc.: 60.16%] [G loss: 0.814215]\n",
      "epoch:26 step:24459 [D loss: 0.752845, acc.: 48.44%] [G loss: 0.917657]\n",
      "epoch:26 step:24460 [D loss: 0.804410, acc.: 54.69%] [G loss: 0.949204]\n",
      "epoch:26 step:24461 [D loss: 0.618737, acc.: 66.41%] [G loss: 0.927878]\n",
      "epoch:26 step:24462 [D loss: 0.674256, acc.: 58.59%] [G loss: 0.729288]\n",
      "epoch:26 step:24463 [D loss: 0.572209, acc.: 69.53%] [G loss: 1.022259]\n",
      "epoch:26 step:24464 [D loss: 0.609322, acc.: 66.41%] [G loss: 0.829991]\n",
      "epoch:26 step:24465 [D loss: 0.705003, acc.: 56.25%] [G loss: 0.995393]\n",
      "epoch:26 step:24466 [D loss: 0.646452, acc.: 61.72%] [G loss: 0.938913]\n",
      "epoch:26 step:24467 [D loss: 0.731444, acc.: 58.59%] [G loss: 0.883740]\n",
      "epoch:26 step:24468 [D loss: 0.702960, acc.: 51.56%] [G loss: 0.681747]\n",
      "epoch:26 step:24469 [D loss: 0.530914, acc.: 72.66%] [G loss: 0.852226]\n",
      "epoch:26 step:24470 [D loss: 0.703307, acc.: 59.38%] [G loss: 0.892006]\n",
      "epoch:26 step:24471 [D loss: 0.612448, acc.: 63.28%] [G loss: 0.811799]\n",
      "epoch:26 step:24472 [D loss: 0.678281, acc.: 54.69%] [G loss: 1.152057]\n",
      "epoch:26 step:24473 [D loss: 0.493333, acc.: 81.25%] [G loss: 0.990605]\n",
      "epoch:26 step:24474 [D loss: 0.543116, acc.: 75.78%] [G loss: 1.028824]\n",
      "epoch:26 step:24475 [D loss: 0.422444, acc.: 82.03%] [G loss: 1.274995]\n",
      "epoch:26 step:24476 [D loss: 0.499300, acc.: 71.88%] [G loss: 1.299110]\n",
      "epoch:26 step:24477 [D loss: 0.474700, acc.: 75.78%] [G loss: 1.353904]\n",
      "epoch:26 step:24478 [D loss: 0.595513, acc.: 71.88%] [G loss: 1.521946]\n",
      "epoch:26 step:24479 [D loss: 0.583502, acc.: 71.09%] [G loss: 1.435229]\n",
      "epoch:26 step:24480 [D loss: 0.453223, acc.: 79.69%] [G loss: 1.359208]\n",
      "epoch:26 step:24481 [D loss: 0.261408, acc.: 88.28%] [G loss: 1.286344]\n",
      "epoch:26 step:24482 [D loss: 0.421768, acc.: 86.72%] [G loss: 0.936770]\n",
      "epoch:26 step:24483 [D loss: 0.260589, acc.: 89.84%] [G loss: 1.228793]\n",
      "epoch:26 step:24484 [D loss: 0.240656, acc.: 96.09%] [G loss: 1.550681]\n",
      "epoch:26 step:24485 [D loss: 0.765441, acc.: 53.91%] [G loss: 1.226344]\n",
      "epoch:26 step:24486 [D loss: 0.847307, acc.: 50.00%] [G loss: 1.120885]\n",
      "epoch:26 step:24487 [D loss: 0.908228, acc.: 35.16%] [G loss: 0.992021]\n",
      "epoch:26 step:24488 [D loss: 0.770814, acc.: 47.66%] [G loss: 0.901965]\n",
      "epoch:26 step:24489 [D loss: 0.773787, acc.: 55.47%] [G loss: 0.684263]\n",
      "epoch:26 step:24490 [D loss: 0.610594, acc.: 63.28%] [G loss: 0.970633]\n",
      "epoch:26 step:24491 [D loss: 0.422785, acc.: 78.12%] [G loss: 0.790480]\n",
      "epoch:26 step:24492 [D loss: 0.328443, acc.: 86.72%] [G loss: 1.260264]\n",
      "epoch:26 step:24493 [D loss: 0.421741, acc.: 85.16%] [G loss: 1.158608]\n",
      "epoch:26 step:24494 [D loss: 0.426089, acc.: 85.94%] [G loss: 1.118358]\n",
      "epoch:26 step:24495 [D loss: 0.886325, acc.: 42.97%] [G loss: 1.277407]\n",
      "epoch:26 step:24496 [D loss: 0.681645, acc.: 62.50%] [G loss: 1.157643]\n",
      "epoch:26 step:24497 [D loss: 0.406785, acc.: 84.38%] [G loss: 1.252351]\n",
      "epoch:26 step:24498 [D loss: 0.626568, acc.: 66.41%] [G loss: 1.220565]\n",
      "epoch:26 step:24499 [D loss: 0.640384, acc.: 63.28%] [G loss: 1.327444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24500 [D loss: 0.737993, acc.: 53.91%] [G loss: 1.192998]\n",
      "epoch:26 step:24501 [D loss: 0.687479, acc.: 57.81%] [G loss: 1.144802]\n",
      "epoch:26 step:24502 [D loss: 0.579400, acc.: 71.09%] [G loss: 1.233776]\n",
      "epoch:26 step:24503 [D loss: 0.376903, acc.: 90.62%] [G loss: 1.458750]\n",
      "epoch:26 step:24504 [D loss: 0.547018, acc.: 69.53%] [G loss: 1.334639]\n",
      "epoch:26 step:24505 [D loss: 0.257486, acc.: 92.97%] [G loss: 1.465758]\n",
      "epoch:26 step:24506 [D loss: 0.353522, acc.: 89.06%] [G loss: 1.343614]\n",
      "epoch:26 step:24507 [D loss: 0.212037, acc.: 92.97%] [G loss: 1.459314]\n",
      "epoch:26 step:24508 [D loss: 0.283228, acc.: 95.31%] [G loss: 1.411007]\n",
      "epoch:26 step:24509 [D loss: 0.584124, acc.: 69.53%] [G loss: 1.315477]\n",
      "epoch:26 step:24510 [D loss: 0.814249, acc.: 54.69%] [G loss: 1.018765]\n",
      "epoch:26 step:24511 [D loss: 0.420290, acc.: 84.38%] [G loss: 1.230811]\n",
      "epoch:26 step:24512 [D loss: 0.203947, acc.: 95.31%] [G loss: 1.351293]\n",
      "epoch:26 step:24513 [D loss: 0.212019, acc.: 96.09%] [G loss: 1.382283]\n",
      "epoch:26 step:24514 [D loss: 0.239911, acc.: 95.31%] [G loss: 1.736436]\n",
      "epoch:26 step:24515 [D loss: 0.783018, acc.: 56.25%] [G loss: 1.478471]\n",
      "epoch:26 step:24516 [D loss: 0.849893, acc.: 40.62%] [G loss: 1.469794]\n",
      "epoch:26 step:24517 [D loss: 0.731505, acc.: 52.34%] [G loss: 1.293126]\n",
      "epoch:26 step:24518 [D loss: 0.735515, acc.: 58.59%] [G loss: 1.120625]\n",
      "epoch:26 step:24519 [D loss: 0.695523, acc.: 57.03%] [G loss: 1.158380]\n",
      "epoch:26 step:24520 [D loss: 0.678173, acc.: 62.50%] [G loss: 0.895705]\n",
      "epoch:26 step:24521 [D loss: 0.627001, acc.: 67.19%] [G loss: 1.070166]\n",
      "epoch:26 step:24522 [D loss: 0.576008, acc.: 72.66%] [G loss: 0.812978]\n",
      "epoch:26 step:24523 [D loss: 0.555550, acc.: 72.66%] [G loss: 1.121860]\n",
      "epoch:26 step:24524 [D loss: 0.358845, acc.: 86.72%] [G loss: 1.025674]\n",
      "epoch:26 step:24525 [D loss: 0.488026, acc.: 74.22%] [G loss: 1.330052]\n",
      "epoch:26 step:24526 [D loss: 0.603336, acc.: 72.66%] [G loss: 1.190003]\n",
      "epoch:26 step:24527 [D loss: 0.505900, acc.: 75.78%] [G loss: 0.888894]\n",
      "epoch:26 step:24528 [D loss: 0.788864, acc.: 45.31%] [G loss: 1.117482]\n",
      "epoch:26 step:24529 [D loss: 0.785955, acc.: 42.97%] [G loss: 0.630931]\n",
      "epoch:26 step:24530 [D loss: 0.690651, acc.: 60.94%] [G loss: 0.838655]\n",
      "epoch:26 step:24531 [D loss: 0.814264, acc.: 50.00%] [G loss: 0.973469]\n",
      "epoch:26 step:24532 [D loss: 0.562981, acc.: 73.44%] [G loss: 1.137163]\n",
      "epoch:26 step:24533 [D loss: 0.680072, acc.: 57.81%] [G loss: 1.047587]\n",
      "epoch:26 step:24534 [D loss: 0.567480, acc.: 70.31%] [G loss: 1.017588]\n",
      "epoch:26 step:24535 [D loss: 0.657276, acc.: 63.28%] [G loss: 0.926573]\n",
      "epoch:26 step:24536 [D loss: 0.631539, acc.: 63.28%] [G loss: 1.026875]\n",
      "epoch:26 step:24537 [D loss: 0.584244, acc.: 68.75%] [G loss: 1.075165]\n",
      "epoch:26 step:24538 [D loss: 0.618843, acc.: 67.97%] [G loss: 0.912451]\n",
      "epoch:26 step:24539 [D loss: 0.559297, acc.: 75.00%] [G loss: 1.030965]\n",
      "epoch:26 step:24540 [D loss: 0.596764, acc.: 64.06%] [G loss: 1.320073]\n",
      "epoch:26 step:24541 [D loss: 0.332762, acc.: 87.50%] [G loss: 1.293345]\n",
      "epoch:26 step:24542 [D loss: 0.469232, acc.: 80.47%] [G loss: 1.089597]\n",
      "epoch:26 step:24543 [D loss: 0.696712, acc.: 56.25%] [G loss: 0.820203]\n",
      "epoch:26 step:24544 [D loss: 0.705709, acc.: 56.25%] [G loss: 0.805910]\n",
      "epoch:26 step:24545 [D loss: 0.649843, acc.: 61.72%] [G loss: 0.887699]\n",
      "epoch:26 step:24546 [D loss: 0.785785, acc.: 52.34%] [G loss: 0.941821]\n",
      "epoch:26 step:24547 [D loss: 0.357411, acc.: 82.81%] [G loss: 1.254083]\n",
      "epoch:26 step:24548 [D loss: 0.530984, acc.: 71.88%] [G loss: 1.092458]\n",
      "epoch:26 step:24549 [D loss: 0.698444, acc.: 57.03%] [G loss: 1.174377]\n",
      "epoch:26 step:24550 [D loss: 0.840620, acc.: 42.97%] [G loss: 0.970426]\n",
      "epoch:26 step:24551 [D loss: 0.597884, acc.: 67.97%] [G loss: 1.153959]\n",
      "epoch:26 step:24552 [D loss: 0.662609, acc.: 58.59%] [G loss: 1.081585]\n",
      "epoch:26 step:24553 [D loss: 0.736437, acc.: 51.56%] [G loss: 1.390214]\n",
      "epoch:26 step:24554 [D loss: 0.570504, acc.: 70.31%] [G loss: 1.201353]\n",
      "epoch:26 step:24555 [D loss: 0.558998, acc.: 71.88%] [G loss: 1.139881]\n",
      "epoch:26 step:24556 [D loss: 0.542573, acc.: 68.75%] [G loss: 1.082338]\n",
      "epoch:26 step:24557 [D loss: 0.534031, acc.: 72.66%] [G loss: 1.335916]\n",
      "epoch:26 step:24558 [D loss: 0.683094, acc.: 57.03%] [G loss: 1.073714]\n",
      "epoch:26 step:24559 [D loss: 0.618091, acc.: 63.28%] [G loss: 1.228829]\n",
      "epoch:26 step:24560 [D loss: 0.643956, acc.: 60.94%] [G loss: 1.068806]\n",
      "epoch:26 step:24561 [D loss: 0.680026, acc.: 57.03%] [G loss: 1.020986]\n",
      "epoch:26 step:24562 [D loss: 0.272843, acc.: 96.09%] [G loss: 1.008992]\n",
      "epoch:26 step:24563 [D loss: 0.244395, acc.: 89.06%] [G loss: 0.689376]\n",
      "epoch:26 step:24564 [D loss: 0.718170, acc.: 55.47%] [G loss: 1.369022]\n",
      "epoch:26 step:24565 [D loss: 0.562376, acc.: 72.66%] [G loss: 1.151078]\n",
      "epoch:26 step:24566 [D loss: 0.299598, acc.: 93.75%] [G loss: 1.177641]\n",
      "epoch:26 step:24567 [D loss: 0.423337, acc.: 85.94%] [G loss: 1.288324]\n",
      "epoch:26 step:24568 [D loss: 0.294002, acc.: 93.75%] [G loss: 1.670786]\n",
      "epoch:26 step:24569 [D loss: 0.231888, acc.: 92.97%] [G loss: 1.587636]\n",
      "epoch:26 step:24570 [D loss: 0.330382, acc.: 96.09%] [G loss: 1.535872]\n",
      "epoch:26 step:24571 [D loss: 0.200378, acc.: 99.22%] [G loss: 1.476040]\n",
      "epoch:26 step:24572 [D loss: 0.850602, acc.: 52.34%] [G loss: 1.092128]\n",
      "epoch:26 step:24573 [D loss: 0.880899, acc.: 40.62%] [G loss: 1.280520]\n",
      "epoch:26 step:24574 [D loss: 0.679639, acc.: 56.25%] [G loss: 0.963268]\n",
      "epoch:26 step:24575 [D loss: 0.774322, acc.: 53.91%] [G loss: 1.033090]\n",
      "epoch:26 step:24576 [D loss: 0.768878, acc.: 53.91%] [G loss: 0.481207]\n",
      "epoch:26 step:24577 [D loss: 0.736115, acc.: 58.59%] [G loss: 0.981681]\n",
      "epoch:26 step:24578 [D loss: 0.689009, acc.: 53.91%] [G loss: 0.890837]\n",
      "epoch:26 step:24579 [D loss: 0.405202, acc.: 85.16%] [G loss: 0.855427]\n",
      "epoch:26 step:24580 [D loss: 0.453460, acc.: 71.88%] [G loss: 1.290643]\n",
      "epoch:26 step:24581 [D loss: 0.285476, acc.: 92.19%] [G loss: 1.199261]\n",
      "epoch:26 step:24582 [D loss: 0.345256, acc.: 82.03%] [G loss: 1.280866]\n",
      "epoch:26 step:24583 [D loss: 0.220680, acc.: 98.44%] [G loss: 1.292681]\n",
      "epoch:26 step:24584 [D loss: 0.311752, acc.: 92.97%] [G loss: 1.445525]\n",
      "epoch:26 step:24585 [D loss: 0.171287, acc.: 100.00%] [G loss: 1.470159]\n",
      "epoch:26 step:24586 [D loss: 0.637048, acc.: 61.72%] [G loss: 1.317524]\n",
      "epoch:26 step:24587 [D loss: 0.357559, acc.: 92.97%] [G loss: 1.383778]\n",
      "epoch:26 step:24588 [D loss: 0.812397, acc.: 48.44%] [G loss: 1.319987]\n",
      "epoch:26 step:24589 [D loss: 0.571546, acc.: 71.09%] [G loss: 1.352621]\n",
      "epoch:26 step:24590 [D loss: 0.497070, acc.: 81.25%] [G loss: 1.237510]\n",
      "epoch:26 step:24591 [D loss: 0.688100, acc.: 63.28%] [G loss: 1.101842]\n",
      "epoch:26 step:24592 [D loss: 0.309451, acc.: 82.81%] [G loss: 1.182306]\n",
      "epoch:26 step:24593 [D loss: 0.237654, acc.: 92.97%] [G loss: 1.079002]\n",
      "epoch:26 step:24594 [D loss: 0.285374, acc.: 89.06%] [G loss: 1.320374]\n",
      "epoch:26 step:24595 [D loss: 0.698428, acc.: 58.59%] [G loss: 1.434140]\n",
      "epoch:26 step:24596 [D loss: 0.558941, acc.: 75.78%] [G loss: 1.115067]\n",
      "epoch:26 step:24597 [D loss: 0.275427, acc.: 89.84%] [G loss: 1.202079]\n",
      "epoch:26 step:24598 [D loss: 0.526889, acc.: 76.56%] [G loss: 1.241605]\n",
      "epoch:26 step:24599 [D loss: 0.566171, acc.: 74.22%] [G loss: 1.023222]\n",
      "epoch:26 step:24600 [D loss: 0.453063, acc.: 79.69%] [G loss: 0.932544]\n",
      "epoch:26 step:24601 [D loss: 0.424958, acc.: 85.94%] [G loss: 1.234920]\n",
      "epoch:26 step:24602 [D loss: 0.325923, acc.: 91.41%] [G loss: 1.480431]\n",
      "epoch:26 step:24603 [D loss: 0.709736, acc.: 57.81%] [G loss: 1.168949]\n",
      "epoch:26 step:24604 [D loss: 0.958230, acc.: 44.53%] [G loss: 1.195552]\n",
      "epoch:26 step:24605 [D loss: 0.553526, acc.: 74.22%] [G loss: 1.346496]\n",
      "epoch:26 step:24606 [D loss: 0.675072, acc.: 60.94%] [G loss: 1.228717]\n",
      "epoch:26 step:24607 [D loss: 0.744084, acc.: 54.69%] [G loss: 1.021366]\n",
      "epoch:26 step:24608 [D loss: 0.694243, acc.: 60.94%] [G loss: 0.675768]\n",
      "epoch:26 step:24609 [D loss: 0.907823, acc.: 50.00%] [G loss: 1.104624]\n",
      "epoch:26 step:24610 [D loss: 0.490183, acc.: 78.91%] [G loss: 1.424118]\n",
      "epoch:26 step:24611 [D loss: 0.688758, acc.: 58.59%] [G loss: 1.309801]\n",
      "epoch:26 step:24612 [D loss: 0.719904, acc.: 52.34%] [G loss: 1.229446]\n",
      "epoch:26 step:24613 [D loss: 0.731036, acc.: 50.78%] [G loss: 1.349859]\n",
      "epoch:26 step:24614 [D loss: 0.866833, acc.: 42.19%] [G loss: 1.006449]\n",
      "epoch:26 step:24615 [D loss: 0.779293, acc.: 46.88%] [G loss: 1.174648]\n",
      "epoch:26 step:24616 [D loss: 0.664381, acc.: 57.03%] [G loss: 1.009011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24617 [D loss: 0.364579, acc.: 92.97%] [G loss: 1.198009]\n",
      "epoch:26 step:24618 [D loss: 0.237256, acc.: 96.88%] [G loss: 1.230201]\n",
      "epoch:26 step:24619 [D loss: 0.294539, acc.: 92.97%] [G loss: 1.322685]\n",
      "epoch:26 step:24620 [D loss: 0.625318, acc.: 64.06%] [G loss: 1.264263]\n",
      "epoch:26 step:24621 [D loss: 0.260649, acc.: 91.41%] [G loss: 1.214571]\n",
      "epoch:26 step:24622 [D loss: 0.378720, acc.: 89.84%] [G loss: 0.516628]\n",
      "epoch:26 step:24623 [D loss: 0.149477, acc.: 99.22%] [G loss: 1.290761]\n",
      "epoch:26 step:24624 [D loss: 0.907080, acc.: 29.69%] [G loss: 1.558328]\n",
      "epoch:26 step:24625 [D loss: 0.203535, acc.: 93.75%] [G loss: 1.532233]\n",
      "epoch:26 step:24626 [D loss: 0.304468, acc.: 95.31%] [G loss: 1.733608]\n",
      "epoch:26 step:24627 [D loss: 1.188050, acc.: 21.09%] [G loss: 1.984204]\n",
      "epoch:26 step:24628 [D loss: 0.631176, acc.: 56.25%] [G loss: 1.719380]\n",
      "epoch:26 step:24629 [D loss: 0.629426, acc.: 58.59%] [G loss: 1.546783]\n",
      "epoch:26 step:24630 [D loss: 0.623728, acc.: 62.50%] [G loss: 1.435666]\n",
      "epoch:26 step:24631 [D loss: 0.273354, acc.: 94.53%] [G loss: 1.386415]\n",
      "epoch:26 step:24632 [D loss: 0.576986, acc.: 70.31%] [G loss: 1.332361]\n",
      "epoch:26 step:24633 [D loss: 0.491255, acc.: 77.34%] [G loss: 1.101400]\n",
      "epoch:26 step:24634 [D loss: 0.299193, acc.: 96.88%] [G loss: 1.849087]\n",
      "epoch:26 step:24635 [D loss: 0.439253, acc.: 82.81%] [G loss: 0.923709]\n",
      "epoch:26 step:24636 [D loss: 0.388702, acc.: 90.62%] [G loss: 0.836823]\n",
      "epoch:26 step:24637 [D loss: 0.837137, acc.: 51.56%] [G loss: 1.165905]\n",
      "epoch:26 step:24638 [D loss: 0.466091, acc.: 78.91%] [G loss: 0.686873]\n",
      "epoch:26 step:24639 [D loss: 1.045745, acc.: 32.81%] [G loss: 1.262664]\n",
      "epoch:26 step:24640 [D loss: 0.513751, acc.: 72.66%] [G loss: 0.885932]\n",
      "epoch:26 step:24641 [D loss: 0.228956, acc.: 92.97%] [G loss: 1.726017]\n",
      "epoch:26 step:24642 [D loss: 0.665963, acc.: 61.72%] [G loss: 1.464337]\n",
      "epoch:26 step:24643 [D loss: 1.003509, acc.: 32.03%] [G loss: 1.552189]\n",
      "epoch:26 step:24644 [D loss: 0.768783, acc.: 57.03%] [G loss: 1.356611]\n",
      "epoch:26 step:24645 [D loss: 0.791026, acc.: 55.47%] [G loss: 1.214597]\n",
      "epoch:26 step:24646 [D loss: 0.296082, acc.: 85.16%] [G loss: 0.987714]\n",
      "epoch:26 step:24647 [D loss: 0.239151, acc.: 92.97%] [G loss: 1.600683]\n",
      "epoch:26 step:24648 [D loss: 0.209004, acc.: 96.88%] [G loss: 1.341282]\n",
      "epoch:26 step:24649 [D loss: 0.560732, acc.: 71.88%] [G loss: 1.636527]\n",
      "epoch:26 step:24650 [D loss: 0.314042, acc.: 93.75%] [G loss: 1.558769]\n",
      "epoch:26 step:24651 [D loss: 0.257778, acc.: 89.84%] [G loss: 1.502255]\n",
      "epoch:26 step:24652 [D loss: 0.333180, acc.: 92.97%] [G loss: 1.763139]\n",
      "epoch:26 step:24653 [D loss: 0.184972, acc.: 96.88%] [G loss: 1.602500]\n",
      "epoch:26 step:24654 [D loss: 0.287369, acc.: 96.88%] [G loss: 1.660103]\n",
      "epoch:26 step:24655 [D loss: 0.168767, acc.: 99.22%] [G loss: 1.560451]\n",
      "epoch:26 step:24656 [D loss: 0.287923, acc.: 96.88%] [G loss: 1.725100]\n",
      "epoch:26 step:24657 [D loss: 0.889702, acc.: 51.56%] [G loss: 1.333506]\n",
      "epoch:26 step:24658 [D loss: 0.612221, acc.: 67.19%] [G loss: 1.306201]\n",
      "epoch:26 step:24659 [D loss: 0.856339, acc.: 48.44%] [G loss: 1.022227]\n",
      "epoch:26 step:24660 [D loss: 0.696920, acc.: 58.59%] [G loss: 1.006858]\n",
      "epoch:26 step:24661 [D loss: 0.741160, acc.: 53.12%] [G loss: 1.165148]\n",
      "epoch:26 step:24662 [D loss: 0.737752, acc.: 50.00%] [G loss: 1.155187]\n",
      "epoch:26 step:24663 [D loss: 0.590567, acc.: 69.53%] [G loss: 1.032671]\n",
      "epoch:26 step:24664 [D loss: 0.628845, acc.: 60.94%] [G loss: 0.915596]\n",
      "epoch:26 step:24665 [D loss: 0.550883, acc.: 75.78%] [G loss: 0.941952]\n",
      "epoch:26 step:24666 [D loss: 0.415057, acc.: 68.75%] [G loss: 1.141186]\n",
      "epoch:26 step:24667 [D loss: 0.241246, acc.: 92.97%] [G loss: 1.134623]\n",
      "epoch:26 step:24668 [D loss: 0.335425, acc.: 96.09%] [G loss: 1.315902]\n",
      "epoch:26 step:24669 [D loss: 0.393802, acc.: 90.62%] [G loss: 1.342702]\n",
      "epoch:26 step:24670 [D loss: 0.227871, acc.: 89.84%] [G loss: 1.274106]\n",
      "epoch:26 step:24671 [D loss: 0.169376, acc.: 99.22%] [G loss: 1.614536]\n",
      "epoch:26 step:24672 [D loss: 0.229894, acc.: 98.44%] [G loss: 1.545847]\n",
      "epoch:26 step:24673 [D loss: 0.155863, acc.: 99.22%] [G loss: 1.810668]\n",
      "epoch:26 step:24674 [D loss: 0.158313, acc.: 97.66%] [G loss: 1.432606]\n",
      "epoch:26 step:24675 [D loss: 0.196502, acc.: 94.53%] [G loss: 1.885975]\n",
      "epoch:26 step:24676 [D loss: 0.114612, acc.: 99.22%] [G loss: 1.899235]\n",
      "epoch:26 step:24677 [D loss: 0.116949, acc.: 100.00%] [G loss: 1.739092]\n",
      "epoch:26 step:24678 [D loss: 1.011370, acc.: 50.00%] [G loss: 1.450987]\n",
      "epoch:26 step:24679 [D loss: 0.860732, acc.: 50.78%] [G loss: 0.871497]\n",
      "epoch:26 step:24680 [D loss: 1.431796, acc.: 14.84%] [G loss: 1.474963]\n",
      "epoch:26 step:24681 [D loss: 0.820911, acc.: 52.34%] [G loss: 1.179489]\n",
      "epoch:26 step:24682 [D loss: 0.805253, acc.: 50.78%] [G loss: 1.232243]\n",
      "epoch:26 step:24683 [D loss: 0.865514, acc.: 47.66%] [G loss: 1.017981]\n",
      "epoch:26 step:24684 [D loss: 0.761491, acc.: 54.69%] [G loss: 0.952834]\n",
      "epoch:26 step:24685 [D loss: 0.318896, acc.: 90.62%] [G loss: 1.111083]\n",
      "epoch:26 step:24686 [D loss: 0.433882, acc.: 87.50%] [G loss: 1.157030]\n",
      "epoch:26 step:24687 [D loss: 0.464400, acc.: 79.69%] [G loss: 1.110726]\n",
      "epoch:26 step:24688 [D loss: 0.902976, acc.: 35.16%] [G loss: 0.646008]\n",
      "epoch:26 step:24689 [D loss: 0.722248, acc.: 54.69%] [G loss: 1.279019]\n",
      "epoch:26 step:24690 [D loss: 0.753972, acc.: 50.78%] [G loss: 0.951988]\n",
      "epoch:26 step:24691 [D loss: 0.741513, acc.: 52.34%] [G loss: 0.904631]\n",
      "epoch:26 step:24692 [D loss: 0.597160, acc.: 67.97%] [G loss: 0.896165]\n",
      "epoch:26 step:24693 [D loss: 0.545066, acc.: 69.53%] [G loss: 1.174799]\n",
      "epoch:26 step:24694 [D loss: 0.599609, acc.: 60.16%] [G loss: 1.026978]\n",
      "epoch:26 step:24695 [D loss: 0.356897, acc.: 92.97%] [G loss: 0.374666]\n",
      "epoch:26 step:24696 [D loss: 0.598148, acc.: 64.84%] [G loss: 0.912486]\n",
      "epoch:26 step:24697 [D loss: 0.444197, acc.: 78.91%] [G loss: 1.359041]\n",
      "epoch:26 step:24698 [D loss: 0.408595, acc.: 82.81%] [G loss: 1.280092]\n",
      "epoch:26 step:24699 [D loss: 0.764642, acc.: 53.91%] [G loss: 1.812165]\n",
      "epoch:26 step:24700 [D loss: 1.425458, acc.: 10.94%] [G loss: 0.445162]\n",
      "epoch:26 step:24701 [D loss: 0.737330, acc.: 57.03%] [G loss: 1.446747]\n",
      "epoch:26 step:24702 [D loss: 0.695342, acc.: 53.91%] [G loss: 1.331731]\n",
      "epoch:26 step:24703 [D loss: 0.673258, acc.: 55.47%] [G loss: 1.146862]\n",
      "epoch:26 step:24704 [D loss: 0.377530, acc.: 96.09%] [G loss: 1.233249]\n",
      "epoch:26 step:24705 [D loss: 0.512413, acc.: 65.62%] [G loss: 0.935113]\n",
      "epoch:26 step:24706 [D loss: 0.350441, acc.: 89.06%] [G loss: 1.652423]\n",
      "epoch:26 step:24707 [D loss: 0.248309, acc.: 96.88%] [G loss: 1.591144]\n",
      "epoch:26 step:24708 [D loss: 0.377769, acc.: 82.81%] [G loss: 1.540962]\n",
      "epoch:26 step:24709 [D loss: 0.264533, acc.: 94.53%] [G loss: 1.339144]\n",
      "epoch:26 step:24710 [D loss: 0.820675, acc.: 52.34%] [G loss: 1.521181]\n",
      "epoch:26 step:24711 [D loss: 0.618084, acc.: 63.28%] [G loss: 0.843651]\n",
      "epoch:26 step:24712 [D loss: 0.829728, acc.: 42.19%] [G loss: 1.318065]\n",
      "epoch:26 step:24713 [D loss: 0.450832, acc.: 84.38%] [G loss: 1.727473]\n",
      "epoch:26 step:24714 [D loss: 0.432461, acc.: 78.91%] [G loss: 1.607113]\n",
      "epoch:26 step:24715 [D loss: 0.433757, acc.: 81.25%] [G loss: 2.512678]\n",
      "epoch:26 step:24716 [D loss: 0.364686, acc.: 88.28%] [G loss: 2.349233]\n",
      "epoch:26 step:24717 [D loss: 0.517504, acc.: 66.41%] [G loss: 2.641756]\n",
      "epoch:26 step:24718 [D loss: 0.417366, acc.: 79.69%] [G loss: 2.167843]\n",
      "epoch:26 step:24719 [D loss: 0.403787, acc.: 80.47%] [G loss: 2.629466]\n",
      "epoch:26 step:24720 [D loss: 0.170906, acc.: 97.66%] [G loss: 2.455242]\n",
      "epoch:26 step:24721 [D loss: 0.159441, acc.: 99.22%] [G loss: 2.594665]\n",
      "epoch:26 step:24722 [D loss: 0.282117, acc.: 94.53%] [G loss: 3.186795]\n",
      "epoch:26 step:24723 [D loss: 0.305555, acc.: 94.53%] [G loss: 2.440699]\n",
      "epoch:26 step:24724 [D loss: 0.735766, acc.: 57.03%] [G loss: 2.350926]\n",
      "epoch:26 step:24725 [D loss: 0.830741, acc.: 52.34%] [G loss: 1.357581]\n",
      "epoch:26 step:24726 [D loss: 0.361835, acc.: 91.41%] [G loss: 1.339282]\n",
      "epoch:26 step:24727 [D loss: 0.689913, acc.: 60.94%] [G loss: 1.130146]\n",
      "epoch:26 step:24728 [D loss: 1.081517, acc.: 37.50%] [G loss: 0.988573]\n",
      "epoch:26 step:24729 [D loss: 0.721161, acc.: 55.47%] [G loss: 1.044546]\n",
      "epoch:26 step:24730 [D loss: 0.464310, acc.: 85.94%] [G loss: 1.214665]\n",
      "epoch:26 step:24731 [D loss: 0.252803, acc.: 89.84%] [G loss: 1.251683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24732 [D loss: 0.253007, acc.: 88.28%] [G loss: 1.406237]\n",
      "epoch:26 step:24733 [D loss: 0.192603, acc.: 95.31%] [G loss: 1.823710]\n",
      "epoch:26 step:24734 [D loss: 0.312815, acc.: 95.31%] [G loss: 1.320233]\n",
      "epoch:26 step:24735 [D loss: 0.621628, acc.: 61.72%] [G loss: 1.760309]\n",
      "epoch:26 step:24736 [D loss: 0.577206, acc.: 71.88%] [G loss: 1.565033]\n",
      "epoch:26 step:24737 [D loss: 0.478648, acc.: 82.81%] [G loss: 1.459664]\n",
      "epoch:26 step:24738 [D loss: 0.470620, acc.: 78.91%] [G loss: 1.215097]\n",
      "epoch:26 step:24739 [D loss: 0.931442, acc.: 52.34%] [G loss: 1.044646]\n",
      "epoch:26 step:24740 [D loss: 0.824394, acc.: 48.44%] [G loss: 0.897236]\n",
      "epoch:26 step:24741 [D loss: 0.352743, acc.: 81.25%] [G loss: 1.248290]\n",
      "epoch:26 step:24742 [D loss: 0.206507, acc.: 92.19%] [G loss: 0.970026]\n",
      "epoch:26 step:24743 [D loss: 0.182016, acc.: 96.88%] [G loss: 1.332305]\n",
      "epoch:26 step:24744 [D loss: 0.407544, acc.: 84.38%] [G loss: 1.433900]\n",
      "epoch:26 step:24745 [D loss: 0.746331, acc.: 55.47%] [G loss: 1.450434]\n",
      "epoch:26 step:24746 [D loss: 0.628071, acc.: 64.84%] [G loss: 1.309321]\n",
      "epoch:26 step:24747 [D loss: 0.569906, acc.: 71.88%] [G loss: 1.487382]\n",
      "epoch:26 step:24748 [D loss: 0.379332, acc.: 78.12%] [G loss: 1.515476]\n",
      "epoch:26 step:24749 [D loss: 0.291782, acc.: 92.19%] [G loss: 1.050804]\n",
      "epoch:26 step:24750 [D loss: 0.446503, acc.: 80.47%] [G loss: 0.711173]\n",
      "epoch:26 step:24751 [D loss: 0.686918, acc.: 57.81%] [G loss: 1.313507]\n",
      "epoch:26 step:24752 [D loss: 0.777316, acc.: 49.22%] [G loss: 1.185911]\n",
      "epoch:26 step:24753 [D loss: 0.861423, acc.: 36.72%] [G loss: 1.212067]\n",
      "epoch:26 step:24754 [D loss: 0.806446, acc.: 46.09%] [G loss: 0.635491]\n",
      "epoch:26 step:24755 [D loss: 1.281852, acc.: 26.56%] [G loss: 0.720318]\n",
      "epoch:26 step:24756 [D loss: 0.899749, acc.: 30.47%] [G loss: 0.507515]\n",
      "epoch:26 step:24757 [D loss: 0.640477, acc.: 58.59%] [G loss: 1.029962]\n",
      "epoch:26 step:24758 [D loss: 0.823906, acc.: 37.50%] [G loss: 0.509881]\n",
      "epoch:26 step:24759 [D loss: 0.713844, acc.: 48.44%] [G loss: 1.195789]\n",
      "epoch:26 step:24760 [D loss: 0.526942, acc.: 76.56%] [G loss: 1.060577]\n",
      "epoch:26 step:24761 [D loss: 0.485151, acc.: 76.56%] [G loss: 1.259015]\n",
      "epoch:26 step:24762 [D loss: 0.565842, acc.: 67.97%] [G loss: 0.894490]\n",
      "epoch:26 step:24763 [D loss: 0.703169, acc.: 56.25%] [G loss: 1.253653]\n",
      "epoch:26 step:24764 [D loss: 0.528530, acc.: 74.22%] [G loss: 1.101512]\n",
      "epoch:26 step:24765 [D loss: 0.454251, acc.: 83.59%] [G loss: 1.214416]\n",
      "epoch:26 step:24766 [D loss: 0.366738, acc.: 88.28%] [G loss: 1.414441]\n",
      "epoch:26 step:24767 [D loss: 0.279203, acc.: 92.19%] [G loss: 1.439980]\n",
      "epoch:26 step:24768 [D loss: 0.280928, acc.: 93.75%] [G loss: 1.276484]\n",
      "epoch:26 step:24769 [D loss: 0.239101, acc.: 92.97%] [G loss: 1.781197]\n",
      "epoch:26 step:24770 [D loss: 0.430898, acc.: 80.47%] [G loss: 1.902692]\n",
      "epoch:26 step:24771 [D loss: 0.197788, acc.: 98.44%] [G loss: 1.991031]\n",
      "epoch:26 step:24772 [D loss: 0.443830, acc.: 82.03%] [G loss: 1.786198]\n",
      "epoch:26 step:24773 [D loss: 0.768951, acc.: 54.69%] [G loss: 1.254192]\n",
      "epoch:26 step:24774 [D loss: 0.385202, acc.: 87.50%] [G loss: 1.566242]\n",
      "epoch:26 step:24775 [D loss: 0.249879, acc.: 89.84%] [G loss: 1.774177]\n",
      "epoch:26 step:24776 [D loss: 0.289440, acc.: 92.97%] [G loss: 1.579326]\n",
      "epoch:26 step:24777 [D loss: 0.206589, acc.: 98.44%] [G loss: 1.744314]\n",
      "epoch:26 step:24778 [D loss: 0.313402, acc.: 92.97%] [G loss: 1.831742]\n",
      "epoch:26 step:24779 [D loss: 0.436718, acc.: 85.16%] [G loss: 1.833828]\n",
      "epoch:26 step:24780 [D loss: 0.137578, acc.: 99.22%] [G loss: 2.100767]\n",
      "epoch:26 step:24781 [D loss: 0.131935, acc.: 100.00%] [G loss: 1.388355]\n",
      "epoch:26 step:24782 [D loss: 0.184343, acc.: 99.22%] [G loss: 2.633949]\n",
      "epoch:26 step:24783 [D loss: 0.505737, acc.: 75.78%] [G loss: 1.497905]\n",
      "epoch:26 step:24784 [D loss: 0.733502, acc.: 60.16%] [G loss: 1.212912]\n",
      "epoch:26 step:24785 [D loss: 0.477440, acc.: 73.44%] [G loss: 1.316682]\n",
      "epoch:26 step:24786 [D loss: 0.408385, acc.: 76.56%] [G loss: 1.858068]\n",
      "epoch:26 step:24787 [D loss: 0.328124, acc.: 87.50%] [G loss: 1.681769]\n",
      "epoch:26 step:24788 [D loss: 0.473912, acc.: 77.34%] [G loss: 0.758210]\n",
      "epoch:26 step:24789 [D loss: 0.316949, acc.: 86.72%] [G loss: 0.980095]\n",
      "epoch:26 step:24790 [D loss: 0.467844, acc.: 74.22%] [G loss: 2.157694]\n",
      "epoch:26 step:24791 [D loss: 0.344263, acc.: 88.28%] [G loss: 2.809309]\n",
      "epoch:26 step:24792 [D loss: 0.337239, acc.: 82.81%] [G loss: 2.084742]\n",
      "epoch:26 step:24793 [D loss: 0.934954, acc.: 55.47%] [G loss: 1.870946]\n",
      "epoch:26 step:24794 [D loss: 1.477409, acc.: 26.56%] [G loss: 0.757515]\n",
      "epoch:26 step:24795 [D loss: 1.172564, acc.: 33.59%] [G loss: 1.634222]\n",
      "epoch:26 step:24796 [D loss: 0.851258, acc.: 43.75%] [G loss: 1.425647]\n",
      "epoch:26 step:24797 [D loss: 0.705750, acc.: 56.25%] [G loss: 1.283343]\n",
      "epoch:26 step:24798 [D loss: 0.829414, acc.: 39.06%] [G loss: 1.256893]\n",
      "epoch:26 step:24799 [D loss: 0.657824, acc.: 61.72%] [G loss: 1.287222]\n",
      "epoch:26 step:24800 [D loss: 0.315615, acc.: 93.75%] [G loss: 0.985594]\n",
      "epoch:26 step:24801 [D loss: 0.781155, acc.: 46.88%] [G loss: 1.301415]\n",
      "epoch:26 step:24802 [D loss: 0.794171, acc.: 46.09%] [G loss: 0.674836]\n",
      "epoch:26 step:24803 [D loss: 0.901978, acc.: 40.62%] [G loss: 0.974527]\n",
      "epoch:26 step:24804 [D loss: 0.863201, acc.: 47.66%] [G loss: 1.067461]\n",
      "epoch:26 step:24805 [D loss: 0.821070, acc.: 39.84%] [G loss: 1.503122]\n",
      "epoch:26 step:24806 [D loss: 0.665737, acc.: 61.72%] [G loss: 1.623508]\n",
      "epoch:26 step:24807 [D loss: 0.617686, acc.: 63.28%] [G loss: 0.871853]\n",
      "epoch:26 step:24808 [D loss: 0.886768, acc.: 43.75%] [G loss: 1.111080]\n",
      "epoch:26 step:24809 [D loss: 0.613735, acc.: 65.62%] [G loss: 1.108666]\n",
      "epoch:26 step:24810 [D loss: 0.754921, acc.: 51.56%] [G loss: 1.036841]\n",
      "epoch:26 step:24811 [D loss: 0.687014, acc.: 58.59%] [G loss: 1.263045]\n",
      "epoch:26 step:24812 [D loss: 0.549400, acc.: 71.09%] [G loss: 1.651289]\n",
      "epoch:26 step:24813 [D loss: 0.440179, acc.: 83.59%] [G loss: 1.467944]\n",
      "epoch:26 step:24814 [D loss: 0.476696, acc.: 82.81%] [G loss: 1.451335]\n",
      "epoch:26 step:24815 [D loss: 0.407026, acc.: 81.25%] [G loss: 1.470997]\n",
      "epoch:26 step:24816 [D loss: 0.439149, acc.: 80.47%] [G loss: 1.221693]\n",
      "epoch:26 step:24817 [D loss: 0.525828, acc.: 78.91%] [G loss: 1.165122]\n",
      "epoch:26 step:24818 [D loss: 0.261467, acc.: 90.62%] [G loss: 1.706844]\n",
      "epoch:26 step:24819 [D loss: 0.378693, acc.: 89.06%] [G loss: 1.468743]\n",
      "epoch:26 step:24820 [D loss: 0.693753, acc.: 54.69%] [G loss: 1.302156]\n",
      "epoch:26 step:24821 [D loss: 0.578152, acc.: 70.31%] [G loss: 1.122991]\n",
      "epoch:26 step:24822 [D loss: 0.613631, acc.: 68.75%] [G loss: 1.110716]\n",
      "epoch:26 step:24823 [D loss: 0.849207, acc.: 38.28%] [G loss: 1.033304]\n",
      "epoch:26 step:24824 [D loss: 0.753196, acc.: 46.88%] [G loss: 1.025140]\n",
      "epoch:26 step:24825 [D loss: 0.699695, acc.: 52.34%] [G loss: 0.982048]\n",
      "epoch:26 step:24826 [D loss: 0.587802, acc.: 70.31%] [G loss: 0.877791]\n",
      "epoch:26 step:24827 [D loss: 0.381145, acc.: 90.62%] [G loss: 1.245519]\n",
      "epoch:26 step:24828 [D loss: 0.469809, acc.: 82.81%] [G loss: 1.134354]\n",
      "epoch:26 step:24829 [D loss: 0.388595, acc.: 92.19%] [G loss: 1.213149]\n",
      "epoch:26 step:24830 [D loss: 0.285598, acc.: 92.19%] [G loss: 1.356005]\n",
      "epoch:26 step:24831 [D loss: 0.288585, acc.: 97.66%] [G loss: 1.371157]\n",
      "epoch:26 step:24832 [D loss: 0.211031, acc.: 98.44%] [G loss: 1.759975]\n",
      "epoch:26 step:24833 [D loss: 0.200902, acc.: 97.66%] [G loss: 1.382841]\n",
      "epoch:26 step:24834 [D loss: 0.315125, acc.: 92.97%] [G loss: 1.278094]\n",
      "epoch:26 step:24835 [D loss: 1.051086, acc.: 39.06%] [G loss: 1.303229]\n",
      "epoch:26 step:24836 [D loss: 0.867101, acc.: 47.66%] [G loss: 1.232190]\n",
      "epoch:26 step:24837 [D loss: 0.714240, acc.: 49.22%] [G loss: 1.265911]\n",
      "epoch:26 step:24838 [D loss: 0.677306, acc.: 60.16%] [G loss: 1.242251]\n",
      "epoch:26 step:24839 [D loss: 0.428816, acc.: 85.16%] [G loss: 1.130253]\n",
      "epoch:26 step:24840 [D loss: 0.550098, acc.: 74.22%] [G loss: 0.896082]\n",
      "epoch:26 step:24841 [D loss: 0.263751, acc.: 92.97%] [G loss: 1.492582]\n",
      "epoch:26 step:24842 [D loss: 0.295219, acc.: 92.19%] [G loss: 1.084623]\n",
      "epoch:26 step:24843 [D loss: 0.278269, acc.: 90.62%] [G loss: 1.534854]\n",
      "epoch:26 step:24844 [D loss: 0.804185, acc.: 54.69%] [G loss: 1.341825]\n",
      "epoch:26 step:24845 [D loss: 0.739659, acc.: 53.91%] [G loss: 1.123859]\n",
      "epoch:26 step:24846 [D loss: 0.641305, acc.: 64.84%] [G loss: 1.043012]\n",
      "epoch:26 step:24847 [D loss: 0.666385, acc.: 67.19%] [G loss: 1.067674]\n",
      "epoch:26 step:24848 [D loss: 0.709016, acc.: 50.78%] [G loss: 1.113717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24849 [D loss: 0.632990, acc.: 60.16%] [G loss: 1.233406]\n",
      "epoch:26 step:24850 [D loss: 0.559301, acc.: 77.34%] [G loss: 1.021353]\n",
      "epoch:26 step:24851 [D loss: 0.448403, acc.: 85.94%] [G loss: 1.124236]\n",
      "epoch:26 step:24852 [D loss: 0.310346, acc.: 89.84%] [G loss: 1.306290]\n",
      "epoch:26 step:24853 [D loss: 0.351243, acc.: 92.19%] [G loss: 1.236944]\n",
      "epoch:26 step:24854 [D loss: 0.567192, acc.: 67.97%] [G loss: 1.196704]\n",
      "epoch:26 step:24855 [D loss: 0.672254, acc.: 57.03%] [G loss: 0.886448]\n",
      "epoch:26 step:24856 [D loss: 0.501820, acc.: 75.00%] [G loss: 0.908612]\n",
      "epoch:26 step:24857 [D loss: 0.421053, acc.: 87.50%] [G loss: 1.282255]\n",
      "epoch:26 step:24858 [D loss: 0.855242, acc.: 47.66%] [G loss: 1.125027]\n",
      "epoch:26 step:24859 [D loss: 0.679967, acc.: 56.25%] [G loss: 1.328675]\n",
      "epoch:26 step:24860 [D loss: 0.550115, acc.: 75.00%] [G loss: 1.280849]\n",
      "epoch:26 step:24861 [D loss: 0.379077, acc.: 85.16%] [G loss: 1.446164]\n",
      "epoch:26 step:24862 [D loss: 0.776450, acc.: 53.91%] [G loss: 1.264046]\n",
      "epoch:26 step:24863 [D loss: 0.742088, acc.: 53.91%] [G loss: 1.167191]\n",
      "epoch:26 step:24864 [D loss: 0.480337, acc.: 80.47%] [G loss: 1.094657]\n",
      "epoch:26 step:24865 [D loss: 0.237765, acc.: 95.31%] [G loss: 1.424500]\n",
      "epoch:26 step:24866 [D loss: 0.182906, acc.: 96.88%] [G loss: 1.619938]\n",
      "epoch:26 step:24867 [D loss: 0.295813, acc.: 88.28%] [G loss: 1.351475]\n",
      "epoch:26 step:24868 [D loss: 0.580833, acc.: 71.09%] [G loss: 1.436837]\n",
      "epoch:26 step:24869 [D loss: 0.373804, acc.: 89.06%] [G loss: 1.111325]\n",
      "epoch:26 step:24870 [D loss: 0.309987, acc.: 90.62%] [G loss: 1.122300]\n",
      "epoch:26 step:24871 [D loss: 0.729917, acc.: 53.12%] [G loss: 0.817753]\n",
      "epoch:26 step:24872 [D loss: 0.686652, acc.: 63.28%] [G loss: 1.232793]\n",
      "epoch:26 step:24873 [D loss: 1.076189, acc.: 46.88%] [G loss: 1.612590]\n",
      "epoch:26 step:24874 [D loss: 0.726667, acc.: 51.56%] [G loss: 1.547705]\n",
      "epoch:26 step:24875 [D loss: 0.332158, acc.: 89.84%] [G loss: 1.513097]\n",
      "epoch:26 step:24876 [D loss: 0.321308, acc.: 89.84%] [G loss: 1.546570]\n",
      "epoch:26 step:24877 [D loss: 0.461840, acc.: 78.12%] [G loss: 1.643098]\n",
      "epoch:26 step:24878 [D loss: 0.824604, acc.: 54.69%] [G loss: 1.635069]\n",
      "epoch:26 step:24879 [D loss: 0.400574, acc.: 86.72%] [G loss: 1.383634]\n",
      "epoch:26 step:24880 [D loss: 0.678775, acc.: 62.50%] [G loss: 1.283172]\n",
      "epoch:26 step:24881 [D loss: 0.507101, acc.: 77.34%] [G loss: 1.197103]\n",
      "epoch:26 step:24882 [D loss: 0.520698, acc.: 72.66%] [G loss: 1.271927]\n",
      "epoch:26 step:24883 [D loss: 0.655217, acc.: 66.41%] [G loss: 1.139657]\n",
      "epoch:26 step:24884 [D loss: 0.482866, acc.: 81.25%] [G loss: 1.188919]\n",
      "epoch:26 step:24885 [D loss: 0.643690, acc.: 62.50%] [G loss: 1.329229]\n",
      "epoch:26 step:24886 [D loss: 0.390418, acc.: 82.81%] [G loss: 1.222286]\n",
      "epoch:26 step:24887 [D loss: 0.509316, acc.: 77.34%] [G loss: 1.206638]\n",
      "epoch:26 step:24888 [D loss: 0.420084, acc.: 85.16%] [G loss: 1.586970]\n",
      "epoch:26 step:24889 [D loss: 0.410152, acc.: 84.38%] [G loss: 1.231045]\n",
      "epoch:26 step:24890 [D loss: 0.492381, acc.: 78.12%] [G loss: 1.391460]\n",
      "epoch:26 step:24891 [D loss: 0.428856, acc.: 85.94%] [G loss: 1.359257]\n",
      "epoch:26 step:24892 [D loss: 0.284391, acc.: 90.62%] [G loss: 1.419590]\n",
      "epoch:26 step:24893 [D loss: 0.690952, acc.: 58.59%] [G loss: 1.633465]\n",
      "epoch:26 step:24894 [D loss: 0.653587, acc.: 57.03%] [G loss: 1.312900]\n",
      "epoch:26 step:24895 [D loss: 0.651865, acc.: 60.94%] [G loss: 1.299709]\n",
      "epoch:26 step:24896 [D loss: 0.654585, acc.: 60.94%] [G loss: 1.112060]\n",
      "epoch:26 step:24897 [D loss: 0.278588, acc.: 88.28%] [G loss: 1.254922]\n",
      "epoch:26 step:24898 [D loss: 0.192592, acc.: 93.75%] [G loss: 1.730028]\n",
      "epoch:26 step:24899 [D loss: 0.300366, acc.: 92.19%] [G loss: 1.716778]\n",
      "epoch:26 step:24900 [D loss: 0.325660, acc.: 89.84%] [G loss: 1.611508]\n",
      "epoch:26 step:24901 [D loss: 0.256223, acc.: 96.88%] [G loss: 1.633978]\n",
      "epoch:26 step:24902 [D loss: 0.373125, acc.: 89.06%] [G loss: 1.703375]\n",
      "epoch:26 step:24903 [D loss: 0.514320, acc.: 76.56%] [G loss: 1.298888]\n",
      "epoch:26 step:24904 [D loss: 0.760113, acc.: 54.69%] [G loss: 1.210962]\n",
      "epoch:26 step:24905 [D loss: 0.413993, acc.: 81.25%] [G loss: 1.332345]\n",
      "epoch:26 step:24906 [D loss: 0.651772, acc.: 62.50%] [G loss: 1.233134]\n",
      "epoch:26 step:24907 [D loss: 0.569446, acc.: 67.97%] [G loss: 1.313614]\n",
      "epoch:26 step:24908 [D loss: 0.701333, acc.: 57.03%] [G loss: 1.011245]\n",
      "epoch:26 step:24909 [D loss: 0.803402, acc.: 47.66%] [G loss: 0.922890]\n",
      "epoch:26 step:24910 [D loss: 0.566451, acc.: 67.19%] [G loss: 0.854277]\n",
      "epoch:26 step:24911 [D loss: 0.462085, acc.: 78.91%] [G loss: 0.923746]\n",
      "epoch:26 step:24912 [D loss: 0.313552, acc.: 84.38%] [G loss: 1.079529]\n",
      "epoch:26 step:24913 [D loss: 0.393890, acc.: 85.94%] [G loss: 1.195567]\n",
      "epoch:26 step:24914 [D loss: 0.665222, acc.: 64.06%] [G loss: 1.136985]\n",
      "epoch:26 step:24915 [D loss: 0.757060, acc.: 51.56%] [G loss: 1.337906]\n",
      "epoch:26 step:24916 [D loss: 0.577967, acc.: 60.94%] [G loss: 1.208775]\n",
      "epoch:26 step:24917 [D loss: 0.490564, acc.: 80.47%] [G loss: 1.592483]\n",
      "epoch:26 step:24918 [D loss: 0.361810, acc.: 91.41%] [G loss: 1.006686]\n",
      "epoch:26 step:24919 [D loss: 0.485680, acc.: 85.94%] [G loss: 1.055790]\n",
      "epoch:26 step:24920 [D loss: 0.535718, acc.: 75.78%] [G loss: 1.399077]\n",
      "epoch:26 step:24921 [D loss: 0.487583, acc.: 73.44%] [G loss: 1.302704]\n",
      "epoch:26 step:24922 [D loss: 0.208150, acc.: 95.31%] [G loss: 2.087042]\n",
      "epoch:26 step:24923 [D loss: 0.128929, acc.: 99.22%] [G loss: 2.135764]\n",
      "epoch:26 step:24924 [D loss: 0.963162, acc.: 51.56%] [G loss: 1.562964]\n",
      "epoch:26 step:24925 [D loss: 0.840275, acc.: 53.12%] [G loss: 1.388397]\n",
      "epoch:26 step:24926 [D loss: 0.853358, acc.: 46.88%] [G loss: 1.196798]\n",
      "epoch:26 step:24927 [D loss: 0.693896, acc.: 57.03%] [G loss: 1.213329]\n",
      "epoch:26 step:24928 [D loss: 0.500347, acc.: 72.66%] [G loss: 1.686771]\n",
      "epoch:26 step:24929 [D loss: 0.167765, acc.: 95.31%] [G loss: 2.091105]\n",
      "epoch:26 step:24930 [D loss: 0.546756, acc.: 75.00%] [G loss: 2.126005]\n",
      "epoch:26 step:24931 [D loss: 0.660344, acc.: 60.94%] [G loss: 1.326445]\n",
      "epoch:26 step:24932 [D loss: 0.465227, acc.: 82.03%] [G loss: 1.388383]\n",
      "epoch:26 step:24933 [D loss: 0.620267, acc.: 64.84%] [G loss: 1.051675]\n",
      "epoch:26 step:24934 [D loss: 0.412973, acc.: 82.03%] [G loss: 1.697056]\n",
      "epoch:26 step:24935 [D loss: 0.313410, acc.: 94.53%] [G loss: 1.350049]\n",
      "epoch:26 step:24936 [D loss: 0.502057, acc.: 70.31%] [G loss: 1.171939]\n",
      "epoch:26 step:24937 [D loss: 0.410837, acc.: 85.16%] [G loss: 1.923939]\n",
      "epoch:26 step:24938 [D loss: 0.432508, acc.: 78.91%] [G loss: 0.980593]\n",
      "epoch:26 step:24939 [D loss: 0.280527, acc.: 89.06%] [G loss: 1.138927]\n",
      "epoch:26 step:24940 [D loss: 0.212370, acc.: 96.88%] [G loss: 1.092076]\n",
      "epoch:26 step:24941 [D loss: 0.320908, acc.: 92.19%] [G loss: 0.961253]\n",
      "epoch:26 step:24942 [D loss: 0.800705, acc.: 50.00%] [G loss: 1.423417]\n",
      "epoch:26 step:24943 [D loss: 0.768571, acc.: 53.12%] [G loss: 1.089312]\n",
      "epoch:26 step:24944 [D loss: 1.071740, acc.: 35.94%] [G loss: 0.964403]\n",
      "epoch:26 step:24945 [D loss: 0.858088, acc.: 48.44%] [G loss: 1.267982]\n",
      "epoch:26 step:24946 [D loss: 1.016011, acc.: 37.50%] [G loss: 1.365608]\n",
      "epoch:26 step:24947 [D loss: 0.722730, acc.: 58.59%] [G loss: 1.036003]\n",
      "epoch:26 step:24948 [D loss: 0.669414, acc.: 60.94%] [G loss: 1.532884]\n",
      "epoch:26 step:24949 [D loss: 0.243441, acc.: 96.09%] [G loss: 1.462348]\n",
      "epoch:26 step:24950 [D loss: 0.226457, acc.: 93.75%] [G loss: 1.194024]\n",
      "epoch:26 step:24951 [D loss: 0.223309, acc.: 94.53%] [G loss: 1.361747]\n",
      "epoch:26 step:24952 [D loss: 0.616548, acc.: 67.97%] [G loss: 1.384567]\n",
      "epoch:26 step:24953 [D loss: 0.686655, acc.: 62.50%] [G loss: 1.070810]\n",
      "epoch:26 step:24954 [D loss: 0.547613, acc.: 71.88%] [G loss: 1.645857]\n",
      "epoch:26 step:24955 [D loss: 0.779274, acc.: 52.34%] [G loss: 0.892788]\n",
      "epoch:26 step:24956 [D loss: 0.609895, acc.: 67.19%] [G loss: 1.264241]\n",
      "epoch:26 step:24957 [D loss: 0.411951, acc.: 87.50%] [G loss: 1.114751]\n",
      "epoch:26 step:24958 [D loss: 0.629803, acc.: 68.75%] [G loss: 1.191206]\n",
      "epoch:26 step:24959 [D loss: 0.806148, acc.: 48.44%] [G loss: 0.484380]\n",
      "epoch:26 step:24960 [D loss: 0.753010, acc.: 52.34%] [G loss: 0.907923]\n",
      "epoch:26 step:24961 [D loss: 0.689594, acc.: 55.47%] [G loss: 1.089158]\n",
      "epoch:26 step:24962 [D loss: 0.520285, acc.: 66.41%] [G loss: 0.993980]\n",
      "epoch:26 step:24963 [D loss: 0.257563, acc.: 93.75%] [G loss: 1.373792]\n",
      "epoch:26 step:24964 [D loss: 0.495286, acc.: 78.91%] [G loss: 1.280941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24965 [D loss: 0.801020, acc.: 41.41%] [G loss: 1.027945]\n",
      "epoch:26 step:24966 [D loss: 0.801755, acc.: 53.12%] [G loss: 1.275083]\n",
      "epoch:26 step:24967 [D loss: 0.630594, acc.: 59.38%] [G loss: 1.336082]\n",
      "epoch:26 step:24968 [D loss: 0.648742, acc.: 67.97%] [G loss: 1.175474]\n",
      "epoch:26 step:24969 [D loss: 0.686320, acc.: 60.16%] [G loss: 1.142033]\n",
      "epoch:26 step:24970 [D loss: 0.555124, acc.: 72.66%] [G loss: 1.317924]\n",
      "epoch:26 step:24971 [D loss: 0.294647, acc.: 93.75%] [G loss: 0.277219]\n",
      "epoch:26 step:24972 [D loss: 0.695447, acc.: 54.69%] [G loss: 1.305360]\n",
      "epoch:26 step:24973 [D loss: 0.355488, acc.: 85.94%] [G loss: 1.345384]\n",
      "epoch:26 step:24974 [D loss: 0.354447, acc.: 90.62%] [G loss: 1.509847]\n",
      "epoch:26 step:24975 [D loss: 0.588486, acc.: 67.19%] [G loss: 0.967027]\n",
      "epoch:26 step:24976 [D loss: 0.874882, acc.: 31.25%] [G loss: 1.280029]\n",
      "epoch:26 step:24977 [D loss: 0.736922, acc.: 57.03%] [G loss: 0.912060]\n",
      "epoch:26 step:24978 [D loss: 0.456959, acc.: 78.12%] [G loss: 1.342666]\n",
      "epoch:26 step:24979 [D loss: 0.590894, acc.: 66.41%] [G loss: 1.141306]\n",
      "epoch:26 step:24980 [D loss: 0.991690, acc.: 49.22%] [G loss: 1.191570]\n",
      "epoch:26 step:24981 [D loss: 0.832498, acc.: 49.22%] [G loss: 1.046091]\n",
      "epoch:26 step:24982 [D loss: 0.623999, acc.: 64.84%] [G loss: 0.932300]\n",
      "epoch:26 step:24983 [D loss: 0.628413, acc.: 62.50%] [G loss: 0.976612]\n",
      "epoch:26 step:24984 [D loss: 0.529869, acc.: 78.91%] [G loss: 1.032694]\n",
      "epoch:26 step:24985 [D loss: 0.531443, acc.: 82.03%] [G loss: 0.895122]\n",
      "epoch:26 step:24986 [D loss: 0.430550, acc.: 89.84%] [G loss: 1.096851]\n",
      "epoch:26 step:24987 [D loss: 0.698350, acc.: 56.25%] [G loss: 0.923783]\n",
      "epoch:26 step:24988 [D loss: 0.557517, acc.: 75.78%] [G loss: 1.068641]\n",
      "epoch:26 step:24989 [D loss: 0.580940, acc.: 68.75%] [G loss: 1.029885]\n",
      "epoch:26 step:24990 [D loss: 0.656020, acc.: 60.16%] [G loss: 1.262416]\n",
      "epoch:26 step:24991 [D loss: 0.368547, acc.: 91.41%] [G loss: 1.021075]\n",
      "epoch:26 step:24992 [D loss: 0.420954, acc.: 86.72%] [G loss: 1.282747]\n",
      "epoch:26 step:24993 [D loss: 0.529570, acc.: 70.31%] [G loss: 1.185203]\n",
      "epoch:26 step:24994 [D loss: 0.282899, acc.: 89.06%] [G loss: 1.273933]\n",
      "epoch:26 step:24995 [D loss: 0.217680, acc.: 96.09%] [G loss: 1.383215]\n",
      "epoch:26 step:24996 [D loss: 0.183358, acc.: 99.22%] [G loss: 1.455661]\n",
      "epoch:26 step:24997 [D loss: 0.227488, acc.: 96.88%] [G loss: 1.389408]\n",
      "epoch:26 step:24998 [D loss: 0.419526, acc.: 82.81%] [G loss: 1.797239]\n",
      "epoch:26 step:24999 [D loss: 0.506351, acc.: 76.56%] [G loss: 1.627113]\n",
      "epoch:26 step:25000 [D loss: 0.289464, acc.: 93.75%] [G loss: 1.628848]\n",
      "epoch:26 step:25001 [D loss: 0.566089, acc.: 60.94%] [G loss: 1.494298]\n",
      "epoch:26 step:25002 [D loss: 0.765362, acc.: 54.69%] [G loss: 1.085361]\n",
      "epoch:26 step:25003 [D loss: 0.850890, acc.: 44.53%] [G loss: 0.919724]\n",
      "epoch:26 step:25004 [D loss: 0.913804, acc.: 35.16%] [G loss: 0.962435]\n",
      "epoch:26 step:25005 [D loss: 0.470651, acc.: 77.34%] [G loss: 1.043141]\n",
      "epoch:26 step:25006 [D loss: 0.237603, acc.: 92.19%] [G loss: 1.303348]\n",
      "epoch:26 step:25007 [D loss: 0.287057, acc.: 91.41%] [G loss: 1.654244]\n",
      "epoch:26 step:25008 [D loss: 0.175375, acc.: 97.66%] [G loss: 1.503224]\n",
      "epoch:26 step:25009 [D loss: 0.221295, acc.: 94.53%] [G loss: 0.807559]\n",
      "epoch:26 step:25010 [D loss: 0.152591, acc.: 99.22%] [G loss: 1.527190]\n",
      "epoch:26 step:25011 [D loss: 0.259767, acc.: 96.09%] [G loss: 1.160848]\n",
      "epoch:26 step:25012 [D loss: 0.151605, acc.: 97.66%] [G loss: 1.855153]\n",
      "epoch:26 step:25013 [D loss: 0.234362, acc.: 96.88%] [G loss: 2.016339]\n",
      "epoch:26 step:25014 [D loss: 0.948961, acc.: 37.50%] [G loss: 1.684561]\n",
      "epoch:26 step:25015 [D loss: 0.801082, acc.: 53.91%] [G loss: 1.244322]\n",
      "epoch:26 step:25016 [D loss: 0.818724, acc.: 44.53%] [G loss: 1.523066]\n",
      "epoch:26 step:25017 [D loss: 0.503351, acc.: 77.34%] [G loss: 0.724723]\n",
      "epoch:26 step:25018 [D loss: 0.566568, acc.: 68.75%] [G loss: 0.783576]\n",
      "epoch:26 step:25019 [D loss: 0.594812, acc.: 67.97%] [G loss: 0.719829]\n",
      "epoch:26 step:25020 [D loss: 0.619870, acc.: 64.84%] [G loss: 1.185314]\n",
      "epoch:26 step:25021 [D loss: 0.248502, acc.: 91.41%] [G loss: 0.910563]\n",
      "epoch:26 step:25022 [D loss: 0.398540, acc.: 80.47%] [G loss: 1.294225]\n",
      "epoch:26 step:25023 [D loss: 0.270898, acc.: 96.88%] [G loss: 1.245035]\n",
      "epoch:26 step:25024 [D loss: 0.763483, acc.: 55.47%] [G loss: 1.784198]\n",
      "epoch:26 step:25025 [D loss: 0.711537, acc.: 53.12%] [G loss: 1.378484]\n",
      "epoch:26 step:25026 [D loss: 0.849473, acc.: 46.09%] [G loss: 1.588622]\n",
      "epoch:26 step:25027 [D loss: 0.421931, acc.: 78.12%] [G loss: 1.545342]\n",
      "epoch:26 step:25028 [D loss: 0.816595, acc.: 44.53%] [G loss: 1.400743]\n",
      "epoch:26 step:25029 [D loss: 0.733092, acc.: 53.12%] [G loss: 1.591890]\n",
      "epoch:26 step:25030 [D loss: 0.716255, acc.: 50.78%] [G loss: 1.224946]\n",
      "epoch:26 step:25031 [D loss: 0.644071, acc.: 61.72%] [G loss: 1.108622]\n",
      "epoch:26 step:25032 [D loss: 0.709067, acc.: 56.25%] [G loss: 1.101287]\n",
      "epoch:26 step:25033 [D loss: 0.561684, acc.: 71.88%] [G loss: 1.174107]\n",
      "epoch:26 step:25034 [D loss: 0.579583, acc.: 75.00%] [G loss: 0.988097]\n",
      "epoch:26 step:25035 [D loss: 0.594167, acc.: 68.75%] [G loss: 1.211348]\n",
      "epoch:26 step:25036 [D loss: 0.545207, acc.: 70.31%] [G loss: 1.064064]\n",
      "epoch:26 step:25037 [D loss: 0.778424, acc.: 52.34%] [G loss: 1.040820]\n",
      "epoch:26 step:25038 [D loss: 0.735964, acc.: 51.56%] [G loss: 0.962216]\n",
      "epoch:26 step:25039 [D loss: 0.493362, acc.: 80.47%] [G loss: 1.037764]\n",
      "epoch:26 step:25040 [D loss: 0.654360, acc.: 60.16%] [G loss: 1.112304]\n",
      "epoch:26 step:25041 [D loss: 0.683436, acc.: 59.38%] [G loss: 1.135828]\n",
      "epoch:26 step:25042 [D loss: 0.550983, acc.: 78.12%] [G loss: 0.868037]\n",
      "epoch:26 step:25043 [D loss: 0.624332, acc.: 67.97%] [G loss: 0.550665]\n",
      "epoch:26 step:25044 [D loss: 0.821537, acc.: 42.97%] [G loss: 0.806800]\n",
      "epoch:26 step:25045 [D loss: 0.607278, acc.: 64.84%] [G loss: 0.838059]\n",
      "epoch:26 step:25046 [D loss: 0.605673, acc.: 67.19%] [G loss: 1.065825]\n",
      "epoch:26 step:25047 [D loss: 0.606649, acc.: 67.97%] [G loss: 1.028184]\n",
      "epoch:26 step:25048 [D loss: 0.546307, acc.: 71.09%] [G loss: 1.421817]\n",
      "epoch:26 step:25049 [D loss: 0.525723, acc.: 78.12%] [G loss: 1.360033]\n",
      "epoch:26 step:25050 [D loss: 0.723449, acc.: 55.47%] [G loss: 0.971785]\n",
      "epoch:26 step:25051 [D loss: 0.732645, acc.: 57.03%] [G loss: 1.102799]\n",
      "epoch:26 step:25052 [D loss: 0.508944, acc.: 76.56%] [G loss: 0.881793]\n",
      "epoch:26 step:25053 [D loss: 0.484429, acc.: 83.59%] [G loss: 0.974140]\n",
      "epoch:26 step:25054 [D loss: 0.792302, acc.: 46.88%] [G loss: 0.780463]\n",
      "epoch:26 step:25055 [D loss: 0.529564, acc.: 73.44%] [G loss: 0.978252]\n",
      "epoch:26 step:25056 [D loss: 0.400483, acc.: 81.25%] [G loss: 1.357556]\n",
      "epoch:26 step:25057 [D loss: 0.706848, acc.: 52.34%] [G loss: 0.783804]\n",
      "epoch:26 step:25058 [D loss: 0.280549, acc.: 89.06%] [G loss: 1.255722]\n",
      "epoch:26 step:25059 [D loss: 0.335435, acc.: 78.91%] [G loss: 1.074779]\n",
      "epoch:26 step:25060 [D loss: 0.400151, acc.: 84.38%] [G loss: 1.512077]\n",
      "epoch:26 step:25061 [D loss: 0.313094, acc.: 95.31%] [G loss: 1.421657]\n",
      "epoch:26 step:25062 [D loss: 0.531306, acc.: 73.44%] [G loss: 1.639352]\n",
      "epoch:26 step:25063 [D loss: 0.215667, acc.: 96.88%] [G loss: 1.657817]\n",
      "epoch:26 step:25064 [D loss: 0.191368, acc.: 96.09%] [G loss: 1.980615]\n",
      "epoch:26 step:25065 [D loss: 0.598086, acc.: 72.66%] [G loss: 1.581673]\n",
      "epoch:26 step:25066 [D loss: 0.346359, acc.: 91.41%] [G loss: 1.452940]\n",
      "epoch:26 step:25067 [D loss: 0.737576, acc.: 54.69%] [G loss: 1.562209]\n",
      "epoch:26 step:25068 [D loss: 0.172457, acc.: 97.66%] [G loss: 1.497674]\n",
      "epoch:26 step:25069 [D loss: 0.179324, acc.: 96.09%] [G loss: 1.671688]\n",
      "epoch:26 step:25070 [D loss: 0.121961, acc.: 97.66%] [G loss: 1.833534]\n",
      "epoch:26 step:25071 [D loss: 0.116936, acc.: 99.22%] [G loss: 1.946862]\n",
      "epoch:26 step:25072 [D loss: 1.003665, acc.: 53.12%] [G loss: 1.804412]\n",
      "epoch:26 step:25073 [D loss: 0.741292, acc.: 59.38%] [G loss: 1.354883]\n",
      "epoch:26 step:25074 [D loss: 0.491240, acc.: 84.38%] [G loss: 1.154376]\n",
      "epoch:26 step:25075 [D loss: 0.273409, acc.: 84.38%] [G loss: 1.431237]\n",
      "epoch:26 step:25076 [D loss: 0.275928, acc.: 85.16%] [G loss: 1.337469]\n",
      "epoch:26 step:25077 [D loss: 0.755062, acc.: 62.50%] [G loss: 1.468720]\n",
      "epoch:26 step:25078 [D loss: 0.711164, acc.: 54.69%] [G loss: 0.880619]\n",
      "epoch:26 step:25079 [D loss: 0.716679, acc.: 53.91%] [G loss: 0.929248]\n",
      "epoch:26 step:25080 [D loss: 0.626703, acc.: 64.84%] [G loss: 0.877856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25081 [D loss: 0.737330, acc.: 50.00%] [G loss: 1.140879]\n",
      "epoch:26 step:25082 [D loss: 0.715757, acc.: 58.59%] [G loss: 1.158728]\n",
      "epoch:26 step:25083 [D loss: 0.537998, acc.: 70.31%] [G loss: 1.194081]\n",
      "epoch:26 step:25084 [D loss: 0.310406, acc.: 86.72%] [G loss: 1.445548]\n",
      "epoch:26 step:25085 [D loss: 0.240196, acc.: 94.53%] [G loss: 1.155365]\n",
      "epoch:26 step:25086 [D loss: 0.697744, acc.: 57.81%] [G loss: 1.335444]\n",
      "epoch:26 step:25087 [D loss: 1.221292, acc.: 23.44%] [G loss: 1.354511]\n",
      "epoch:26 step:25088 [D loss: 0.635938, acc.: 63.28%] [G loss: 1.269902]\n",
      "epoch:26 step:25089 [D loss: 0.169943, acc.: 98.44%] [G loss: 1.364678]\n",
      "epoch:26 step:25090 [D loss: 0.201520, acc.: 92.97%] [G loss: 1.562434]\n",
      "epoch:26 step:25091 [D loss: 0.197923, acc.: 95.31%] [G loss: 1.762806]\n",
      "epoch:26 step:25092 [D loss: 0.152669, acc.: 98.44%] [G loss: 1.902916]\n",
      "epoch:26 step:25093 [D loss: 0.136749, acc.: 98.44%] [G loss: 1.730355]\n",
      "epoch:26 step:25094 [D loss: 0.143346, acc.: 99.22%] [G loss: 1.931220]\n",
      "epoch:26 step:25095 [D loss: 0.130368, acc.: 100.00%] [G loss: 1.855489]\n",
      "epoch:26 step:25096 [D loss: 0.784289, acc.: 52.34%] [G loss: 1.980154]\n",
      "epoch:26 step:25097 [D loss: 0.823905, acc.: 49.22%] [G loss: 1.354407]\n",
      "epoch:26 step:25098 [D loss: 0.777970, acc.: 53.12%] [G loss: 1.328616]\n",
      "epoch:26 step:25099 [D loss: 0.690670, acc.: 57.81%] [G loss: 1.197652]\n",
      "epoch:26 step:25100 [D loss: 0.434116, acc.: 88.28%] [G loss: 1.324715]\n",
      "epoch:26 step:25101 [D loss: 0.361815, acc.: 89.84%] [G loss: 1.194566]\n",
      "epoch:26 step:25102 [D loss: 0.336382, acc.: 90.62%] [G loss: 1.177143]\n",
      "epoch:26 step:25103 [D loss: 0.846060, acc.: 41.41%] [G loss: 1.255561]\n",
      "epoch:26 step:25104 [D loss: 0.759621, acc.: 53.12%] [G loss: 0.876931]\n",
      "epoch:26 step:25105 [D loss: 0.748654, acc.: 53.91%] [G loss: 1.029217]\n",
      "epoch:26 step:25106 [D loss: 0.650051, acc.: 59.38%] [G loss: 1.302706]\n",
      "epoch:26 step:25107 [D loss: 0.245371, acc.: 91.41%] [G loss: 0.912031]\n",
      "epoch:26 step:25108 [D loss: 0.245059, acc.: 90.62%] [G loss: 1.350039]\n",
      "epoch:26 step:25109 [D loss: 0.319147, acc.: 93.75%] [G loss: 1.192041]\n",
      "epoch:26 step:25110 [D loss: 0.701177, acc.: 56.25%] [G loss: 1.071215]\n",
      "epoch:26 step:25111 [D loss: 0.707993, acc.: 56.25%] [G loss: 0.880681]\n",
      "epoch:26 step:25112 [D loss: 0.652466, acc.: 63.28%] [G loss: 0.988436]\n",
      "epoch:26 step:25113 [D loss: 0.477700, acc.: 75.00%] [G loss: 1.077859]\n",
      "epoch:26 step:25114 [D loss: 0.269571, acc.: 94.53%] [G loss: 1.112778]\n",
      "epoch:26 step:25115 [D loss: 0.301669, acc.: 93.75%] [G loss: 1.142040]\n",
      "epoch:26 step:25116 [D loss: 0.232374, acc.: 91.41%] [G loss: 1.377855]\n",
      "epoch:26 step:25117 [D loss: 0.144429, acc.: 98.44%] [G loss: 1.181340]\n",
      "epoch:26 step:25118 [D loss: 0.175727, acc.: 98.44%] [G loss: 1.508212]\n",
      "epoch:26 step:25119 [D loss: 0.176089, acc.: 96.09%] [G loss: 1.622015]\n",
      "epoch:26 step:25120 [D loss: 0.338973, acc.: 94.53%] [G loss: 1.614073]\n",
      "epoch:26 step:25121 [D loss: 0.866851, acc.: 53.12%] [G loss: 1.577330]\n",
      "epoch:26 step:25122 [D loss: 1.256603, acc.: 14.84%] [G loss: 1.292130]\n",
      "epoch:26 step:25123 [D loss: 0.506845, acc.: 76.56%] [G loss: 1.267358]\n",
      "epoch:26 step:25124 [D loss: 0.216873, acc.: 97.66%] [G loss: 1.216360]\n",
      "epoch:26 step:25125 [D loss: 0.283352, acc.: 93.75%] [G loss: 1.318214]\n",
      "epoch:26 step:25126 [D loss: 0.158527, acc.: 97.66%] [G loss: 1.356966]\n",
      "epoch:26 step:25127 [D loss: 0.693684, acc.: 59.38%] [G loss: 1.086805]\n",
      "epoch:26 step:25128 [D loss: 0.717463, acc.: 60.16%] [G loss: 1.409462]\n",
      "epoch:26 step:25129 [D loss: 0.788772, acc.: 46.88%] [G loss: 1.131591]\n",
      "epoch:26 step:25130 [D loss: 0.799094, acc.: 41.41%] [G loss: 1.083964]\n",
      "epoch:26 step:25131 [D loss: 0.618655, acc.: 70.31%] [G loss: 1.104901]\n",
      "epoch:26 step:25132 [D loss: 0.659094, acc.: 62.50%] [G loss: 1.068032]\n",
      "epoch:26 step:25133 [D loss: 0.511606, acc.: 67.97%] [G loss: 1.300279]\n",
      "epoch:26 step:25134 [D loss: 0.505256, acc.: 78.91%] [G loss: 1.056770]\n",
      "epoch:26 step:25135 [D loss: 0.804484, acc.: 46.09%] [G loss: 1.125976]\n",
      "epoch:26 step:25136 [D loss: 0.468325, acc.: 85.94%] [G loss: 0.897641]\n",
      "epoch:26 step:25137 [D loss: 0.544484, acc.: 70.31%] [G loss: 0.953648]\n",
      "epoch:26 step:25138 [D loss: 0.801544, acc.: 42.97%] [G loss: 1.366724]\n",
      "epoch:26 step:25139 [D loss: 0.750793, acc.: 46.09%] [G loss: 1.313661]\n",
      "epoch:26 step:25140 [D loss: 0.673268, acc.: 60.16%] [G loss: 0.837981]\n",
      "epoch:26 step:25141 [D loss: 0.318187, acc.: 89.06%] [G loss: 1.034738]\n",
      "epoch:26 step:25142 [D loss: 0.284016, acc.: 86.72%] [G loss: 1.134654]\n",
      "epoch:26 step:25143 [D loss: 0.224903, acc.: 94.53%] [G loss: 0.907654]\n",
      "epoch:26 step:25144 [D loss: 0.167961, acc.: 96.09%] [G loss: 1.507169]\n",
      "epoch:26 step:25145 [D loss: 0.727726, acc.: 59.38%] [G loss: 1.129295]\n",
      "epoch:26 step:25146 [D loss: 0.698258, acc.: 61.72%] [G loss: 1.254039]\n",
      "epoch:26 step:25147 [D loss: 0.555598, acc.: 72.66%] [G loss: 1.569786]\n",
      "epoch:26 step:25148 [D loss: 0.180272, acc.: 96.88%] [G loss: 1.757387]\n",
      "epoch:26 step:25149 [D loss: 0.783469, acc.: 52.34%] [G loss: 1.054960]\n",
      "epoch:26 step:25150 [D loss: 0.744055, acc.: 53.12%] [G loss: 1.149195]\n",
      "epoch:26 step:25151 [D loss: 0.887188, acc.: 35.16%] [G loss: 0.692788]\n",
      "epoch:26 step:25152 [D loss: 0.657311, acc.: 55.47%] [G loss: 1.119798]\n",
      "epoch:26 step:25153 [D loss: 0.221574, acc.: 95.31%] [G loss: 1.336053]\n",
      "epoch:26 step:25154 [D loss: 0.214980, acc.: 94.53%] [G loss: 0.795894]\n",
      "epoch:26 step:25155 [D loss: 0.148584, acc.: 100.00%] [G loss: 0.776516]\n",
      "epoch:26 step:25156 [D loss: 0.293442, acc.: 85.94%] [G loss: 1.697169]\n",
      "epoch:26 step:25157 [D loss: 0.650770, acc.: 63.28%] [G loss: 1.763271]\n",
      "epoch:26 step:25158 [D loss: 0.608611, acc.: 64.84%] [G loss: 0.951601]\n",
      "epoch:26 step:25159 [D loss: 0.795473, acc.: 56.25%] [G loss: 1.964294]\n",
      "epoch:26 step:25160 [D loss: 0.505183, acc.: 75.00%] [G loss: 0.804155]\n",
      "epoch:26 step:25161 [D loss: 0.860355, acc.: 50.78%] [G loss: 1.069890]\n",
      "epoch:26 step:25162 [D loss: 1.409531, acc.: 14.84%] [G loss: 1.123496]\n",
      "epoch:26 step:25163 [D loss: 0.643563, acc.: 61.72%] [G loss: 1.515292]\n",
      "epoch:26 step:25164 [D loss: 0.327356, acc.: 89.06%] [G loss: 1.421297]\n",
      "epoch:26 step:25165 [D loss: 0.630670, acc.: 63.28%] [G loss: 1.684069]\n",
      "epoch:26 step:25166 [D loss: 0.432053, acc.: 82.03%] [G loss: 0.502973]\n",
      "epoch:26 step:25167 [D loss: 0.438881, acc.: 79.69%] [G loss: 0.839767]\n",
      "epoch:26 step:25168 [D loss: 0.318839, acc.: 88.28%] [G loss: 0.884840]\n",
      "epoch:26 step:25169 [D loss: 0.701880, acc.: 57.03%] [G loss: 0.996538]\n",
      "epoch:26 step:25170 [D loss: 0.759282, acc.: 56.25%] [G loss: 1.778668]\n",
      "epoch:26 step:25171 [D loss: 0.330272, acc.: 91.41%] [G loss: 1.132765]\n",
      "epoch:26 step:25172 [D loss: 0.681709, acc.: 60.94%] [G loss: 1.533042]\n",
      "epoch:26 step:25173 [D loss: 0.915448, acc.: 49.22%] [G loss: 1.715482]\n",
      "epoch:26 step:25174 [D loss: 0.847527, acc.: 47.66%] [G loss: 1.059842]\n",
      "epoch:26 step:25175 [D loss: 0.633439, acc.: 62.50%] [G loss: 1.658121]\n",
      "epoch:26 step:25176 [D loss: 0.652488, acc.: 58.59%] [G loss: 1.853037]\n",
      "epoch:26 step:25177 [D loss: 0.139540, acc.: 96.09%] [G loss: 2.060046]\n",
      "epoch:26 step:25178 [D loss: 0.152014, acc.: 97.66%] [G loss: 2.094859]\n",
      "epoch:26 step:25179 [D loss: 0.306328, acc.: 87.50%] [G loss: 2.331562]\n",
      "epoch:26 step:25180 [D loss: 0.278683, acc.: 92.19%] [G loss: 2.279438]\n",
      "epoch:26 step:25181 [D loss: 0.175399, acc.: 97.66%] [G loss: 2.219381]\n",
      "epoch:26 step:25182 [D loss: 0.544279, acc.: 67.19%] [G loss: 2.196167]\n",
      "epoch:26 step:25183 [D loss: 0.737680, acc.: 54.69%] [G loss: 1.371871]\n",
      "epoch:26 step:25184 [D loss: 0.327835, acc.: 92.97%] [G loss: 1.427827]\n",
      "epoch:26 step:25185 [D loss: 0.356253, acc.: 87.50%] [G loss: 1.182018]\n",
      "epoch:26 step:25186 [D loss: 0.189433, acc.: 96.09%] [G loss: 1.236749]\n",
      "epoch:26 step:25187 [D loss: 0.141648, acc.: 96.88%] [G loss: 1.843184]\n",
      "epoch:26 step:25188 [D loss: 0.258324, acc.: 93.75%] [G loss: 1.475161]\n",
      "epoch:26 step:25189 [D loss: 0.308472, acc.: 92.19%] [G loss: 2.428415]\n",
      "epoch:26 step:25190 [D loss: 0.338775, acc.: 91.41%] [G loss: 0.707471]\n",
      "epoch:26 step:25191 [D loss: 0.389605, acc.: 82.03%] [G loss: 1.654528]\n",
      "epoch:26 step:25192 [D loss: 0.225813, acc.: 92.97%] [G loss: 2.529389]\n",
      "epoch:26 step:25193 [D loss: 0.105392, acc.: 100.00%] [G loss: 2.262745]\n",
      "epoch:26 step:25194 [D loss: 0.116804, acc.: 96.88%] [G loss: 2.215547]\n",
      "epoch:26 step:25195 [D loss: 0.135700, acc.: 96.09%] [G loss: 2.439466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25196 [D loss: 2.016890, acc.: 31.25%] [G loss: 1.698408]\n",
      "epoch:26 step:25197 [D loss: 0.831541, acc.: 54.69%] [G loss: 1.397074]\n",
      "epoch:26 step:25198 [D loss: 0.953002, acc.: 39.06%] [G loss: 1.236695]\n",
      "epoch:26 step:25199 [D loss: 0.556038, acc.: 65.62%] [G loss: 1.191846]\n",
      "epoch:26 step:25200 [D loss: 0.464093, acc.: 78.12%] [G loss: 1.933049]\n",
      "epoch:26 step:25201 [D loss: 1.100969, acc.: 39.06%] [G loss: 1.278902]\n",
      "epoch:26 step:25202 [D loss: 0.702516, acc.: 58.59%] [G loss: 1.907301]\n",
      "epoch:26 step:25203 [D loss: 0.608184, acc.: 62.50%] [G loss: 1.762705]\n",
      "epoch:26 step:25204 [D loss: 0.476760, acc.: 73.44%] [G loss: 1.934347]\n",
      "epoch:26 step:25205 [D loss: 0.260725, acc.: 96.09%] [G loss: 1.476972]\n",
      "epoch:26 step:25206 [D loss: 0.248674, acc.: 91.41%] [G loss: 1.568954]\n",
      "epoch:26 step:25207 [D loss: 0.208221, acc.: 93.75%] [G loss: 1.748014]\n",
      "epoch:26 step:25208 [D loss: 0.622057, acc.: 71.09%] [G loss: 1.670898]\n",
      "epoch:26 step:25209 [D loss: 0.738802, acc.: 55.47%] [G loss: 1.109705]\n",
      "epoch:26 step:25210 [D loss: 0.679158, acc.: 58.59%] [G loss: 1.411502]\n",
      "epoch:26 step:25211 [D loss: 0.689665, acc.: 57.81%] [G loss: 1.424586]\n",
      "epoch:26 step:25212 [D loss: 0.721863, acc.: 55.47%] [G loss: 1.437831]\n",
      "epoch:26 step:25213 [D loss: 0.579121, acc.: 64.84%] [G loss: 1.203954]\n",
      "epoch:26 step:25214 [D loss: 0.436191, acc.: 81.25%] [G loss: 1.231677]\n",
      "epoch:26 step:25215 [D loss: 0.432971, acc.: 82.03%] [G loss: 1.481222]\n",
      "epoch:26 step:25216 [D loss: 0.389074, acc.: 85.94%] [G loss: 1.432769]\n",
      "epoch:26 step:25217 [D loss: 0.431098, acc.: 81.25%] [G loss: 1.400355]\n",
      "epoch:26 step:25218 [D loss: 0.663360, acc.: 64.06%] [G loss: 1.051296]\n",
      "epoch:26 step:25219 [D loss: 0.399076, acc.: 81.25%] [G loss: 1.558622]\n",
      "epoch:26 step:25220 [D loss: 0.759062, acc.: 54.69%] [G loss: 1.145284]\n",
      "epoch:26 step:25221 [D loss: 0.547587, acc.: 67.97%] [G loss: 1.110601]\n",
      "epoch:26 step:25222 [D loss: 0.466973, acc.: 77.34%] [G loss: 0.964555]\n",
      "epoch:26 step:25223 [D loss: 0.648078, acc.: 60.94%] [G loss: 1.045614]\n",
      "epoch:26 step:25224 [D loss: 0.556454, acc.: 71.88%] [G loss: 0.876150]\n",
      "epoch:26 step:25225 [D loss: 0.489475, acc.: 78.12%] [G loss: 1.045566]\n",
      "epoch:26 step:25226 [D loss: 0.698863, acc.: 57.03%] [G loss: 1.120902]\n",
      "epoch:26 step:25227 [D loss: 0.663462, acc.: 64.84%] [G loss: 0.972034]\n",
      "epoch:26 step:25228 [D loss: 0.566476, acc.: 68.75%] [G loss: 1.124270]\n",
      "epoch:26 step:25229 [D loss: 0.733960, acc.: 57.03%] [G loss: 0.857903]\n",
      "epoch:26 step:25230 [D loss: 0.618541, acc.: 67.19%] [G loss: 1.269431]\n",
      "epoch:26 step:25231 [D loss: 0.805637, acc.: 44.53%] [G loss: 0.957577]\n",
      "epoch:26 step:25232 [D loss: 0.676780, acc.: 56.25%] [G loss: 1.057323]\n",
      "epoch:26 step:25233 [D loss: 0.691869, acc.: 55.47%] [G loss: 1.081834]\n",
      "epoch:26 step:25234 [D loss: 0.735879, acc.: 53.12%] [G loss: 1.116163]\n",
      "epoch:26 step:25235 [D loss: 0.687899, acc.: 56.25%] [G loss: 0.947007]\n",
      "epoch:26 step:25236 [D loss: 0.697537, acc.: 60.94%] [G loss: 0.859011]\n",
      "epoch:26 step:25237 [D loss: 0.585987, acc.: 69.53%] [G loss: 0.941145]\n",
      "epoch:26 step:25238 [D loss: 0.449466, acc.: 87.50%] [G loss: 0.979966]\n",
      "epoch:26 step:25239 [D loss: 0.607043, acc.: 66.41%] [G loss: 0.965612]\n",
      "epoch:26 step:25240 [D loss: 0.349359, acc.: 78.91%] [G loss: 1.233540]\n",
      "epoch:26 step:25241 [D loss: 0.791148, acc.: 53.12%] [G loss: 1.070385]\n",
      "epoch:26 step:25242 [D loss: 0.655918, acc.: 59.38%] [G loss: 0.991588]\n",
      "epoch:26 step:25243 [D loss: 0.664473, acc.: 61.72%] [G loss: 1.346640]\n",
      "epoch:26 step:25244 [D loss: 0.456624, acc.: 82.03%] [G loss: 1.439169]\n",
      "epoch:26 step:25245 [D loss: 0.560672, acc.: 75.00%] [G loss: 1.297529]\n",
      "epoch:26 step:25246 [D loss: 0.432391, acc.: 75.78%] [G loss: 1.139540]\n",
      "epoch:26 step:25247 [D loss: 0.293762, acc.: 90.62%] [G loss: 1.525672]\n",
      "epoch:26 step:25248 [D loss: 0.407966, acc.: 86.72%] [G loss: 1.583023]\n",
      "epoch:26 step:25249 [D loss: 0.239278, acc.: 96.09%] [G loss: 1.547181]\n",
      "epoch:26 step:25250 [D loss: 0.612302, acc.: 71.88%] [G loss: 1.339777]\n",
      "epoch:26 step:25251 [D loss: 0.352035, acc.: 89.84%] [G loss: 1.068610]\n",
      "epoch:26 step:25252 [D loss: 0.507003, acc.: 75.00%] [G loss: 1.114673]\n",
      "epoch:26 step:25253 [D loss: 0.806072, acc.: 53.91%] [G loss: 1.321676]\n",
      "epoch:26 step:25254 [D loss: 0.823159, acc.: 59.38%] [G loss: 0.998343]\n",
      "epoch:26 step:25255 [D loss: 0.706647, acc.: 60.94%] [G loss: 1.041142]\n",
      "epoch:26 step:25256 [D loss: 0.608716, acc.: 69.53%] [G loss: 1.022347]\n",
      "epoch:26 step:25257 [D loss: 0.606726, acc.: 67.19%] [G loss: 0.794415]\n",
      "epoch:26 step:25258 [D loss: 0.612536, acc.: 62.50%] [G loss: 0.755687]\n",
      "epoch:26 step:25259 [D loss: 0.573434, acc.: 66.41%] [G loss: 1.029073]\n",
      "epoch:26 step:25260 [D loss: 0.461214, acc.: 75.78%] [G loss: 1.094208]\n",
      "epoch:26 step:25261 [D loss: 0.375240, acc.: 76.56%] [G loss: 1.567697]\n",
      "epoch:26 step:25262 [D loss: 0.243507, acc.: 96.09%] [G loss: 1.409483]\n",
      "epoch:26 step:25263 [D loss: 0.521727, acc.: 78.12%] [G loss: 1.250940]\n",
      "epoch:26 step:25264 [D loss: 0.631936, acc.: 65.62%] [G loss: 0.970679]\n",
      "epoch:26 step:25265 [D loss: 0.625454, acc.: 67.19%] [G loss: 0.898640]\n",
      "epoch:26 step:25266 [D loss: 0.517195, acc.: 78.12%] [G loss: 1.134678]\n",
      "epoch:26 step:25267 [D loss: 0.460751, acc.: 76.56%] [G loss: 1.346081]\n",
      "epoch:26 step:25268 [D loss: 0.255033, acc.: 96.88%] [G loss: 1.172923]\n",
      "epoch:26 step:25269 [D loss: 0.717931, acc.: 55.47%] [G loss: 1.221964]\n",
      "epoch:26 step:25270 [D loss: 0.804020, acc.: 44.53%] [G loss: 1.305386]\n",
      "epoch:26 step:25271 [D loss: 0.598971, acc.: 65.62%] [G loss: 1.063546]\n",
      "epoch:26 step:25272 [D loss: 0.419709, acc.: 82.03%] [G loss: 1.270238]\n",
      "epoch:26 step:25273 [D loss: 0.517819, acc.: 73.44%] [G loss: 1.656593]\n",
      "epoch:26 step:25274 [D loss: 0.215986, acc.: 93.75%] [G loss: 1.479765]\n",
      "epoch:26 step:25275 [D loss: 0.875906, acc.: 46.09%] [G loss: 1.289491]\n",
      "epoch:26 step:25276 [D loss: 0.592819, acc.: 67.97%] [G loss: 1.261491]\n",
      "epoch:26 step:25277 [D loss: 0.834283, acc.: 46.88%] [G loss: 1.254304]\n",
      "epoch:26 step:25278 [D loss: 0.381039, acc.: 84.38%] [G loss: 1.134467]\n",
      "epoch:26 step:25279 [D loss: 0.251765, acc.: 92.97%] [G loss: 1.375745]\n",
      "epoch:26 step:25280 [D loss: 0.556122, acc.: 74.22%] [G loss: 1.342464]\n",
      "epoch:26 step:25281 [D loss: 0.558346, acc.: 70.31%] [G loss: 1.245246]\n",
      "epoch:26 step:25282 [D loss: 0.299376, acc.: 89.84%] [G loss: 1.043253]\n",
      "epoch:26 step:25283 [D loss: 0.276291, acc.: 90.62%] [G loss: 1.038598]\n",
      "epoch:26 step:25284 [D loss: 0.763760, acc.: 51.56%] [G loss: 1.439291]\n",
      "epoch:26 step:25285 [D loss: 0.625919, acc.: 66.41%] [G loss: 1.156954]\n",
      "epoch:26 step:25286 [D loss: 0.433054, acc.: 81.25%] [G loss: 1.025570]\n",
      "epoch:26 step:25287 [D loss: 0.451783, acc.: 85.16%] [G loss: 1.053674]\n",
      "epoch:26 step:25288 [D loss: 0.380683, acc.: 85.16%] [G loss: 1.212450]\n",
      "epoch:26 step:25289 [D loss: 0.353174, acc.: 82.81%] [G loss: 1.081697]\n",
      "epoch:26 step:25290 [D loss: 0.668234, acc.: 63.28%] [G loss: 1.037953]\n",
      "epoch:26 step:25291 [D loss: 0.290395, acc.: 86.72%] [G loss: 1.515170]\n",
      "epoch:26 step:25292 [D loss: 0.414745, acc.: 91.41%] [G loss: 1.390150]\n",
      "epoch:26 step:25293 [D loss: 0.493177, acc.: 76.56%] [G loss: 1.499940]\n",
      "epoch:26 step:25294 [D loss: 0.633650, acc.: 70.31%] [G loss: 1.044998]\n",
      "epoch:26 step:25295 [D loss: 0.512556, acc.: 73.44%] [G loss: 1.054261]\n",
      "epoch:26 step:25296 [D loss: 0.459848, acc.: 71.88%] [G loss: 1.233585]\n",
      "epoch:26 step:25297 [D loss: 0.476282, acc.: 79.69%] [G loss: 1.171699]\n",
      "epoch:26 step:25298 [D loss: 0.230293, acc.: 95.31%] [G loss: 1.259856]\n",
      "epoch:26 step:25299 [D loss: 0.151682, acc.: 96.88%] [G loss: 1.809219]\n",
      "epoch:27 step:25300 [D loss: 0.825802, acc.: 49.22%] [G loss: 1.502389]\n",
      "epoch:27 step:25301 [D loss: 0.729727, acc.: 55.47%] [G loss: 1.307775]\n",
      "epoch:27 step:25302 [D loss: 0.737349, acc.: 56.25%] [G loss: 1.558869]\n",
      "epoch:27 step:25303 [D loss: 0.769144, acc.: 46.09%] [G loss: 1.209868]\n",
      "epoch:27 step:25304 [D loss: 0.694364, acc.: 59.38%] [G loss: 0.965919]\n",
      "epoch:27 step:25305 [D loss: 0.681142, acc.: 60.94%] [G loss: 0.997994]\n",
      "epoch:27 step:25306 [D loss: 0.590132, acc.: 68.75%] [G loss: 1.261958]\n",
      "epoch:27 step:25307 [D loss: 0.619914, acc.: 67.19%] [G loss: 0.924759]\n",
      "epoch:27 step:25308 [D loss: 0.388107, acc.: 90.62%] [G loss: 1.259221]\n",
      "epoch:27 step:25309 [D loss: 0.944407, acc.: 55.47%] [G loss: 1.552338]\n",
      "epoch:27 step:25310 [D loss: 0.573604, acc.: 72.66%] [G loss: 1.170514]\n",
      "epoch:27 step:25311 [D loss: 0.502590, acc.: 77.34%] [G loss: 0.959251]\n",
      "epoch:27 step:25312 [D loss: 0.500664, acc.: 76.56%] [G loss: 1.291774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25313 [D loss: 0.543192, acc.: 74.22%] [G loss: 1.071790]\n",
      "epoch:27 step:25314 [D loss: 0.463094, acc.: 75.78%] [G loss: 1.666537]\n",
      "epoch:27 step:25315 [D loss: 0.593014, acc.: 71.88%] [G loss: 0.891369]\n",
      "epoch:27 step:25316 [D loss: 0.714447, acc.: 60.16%] [G loss: 0.740780]\n",
      "epoch:27 step:25317 [D loss: 1.893649, acc.: 42.19%] [G loss: 1.737622]\n",
      "epoch:27 step:25318 [D loss: 0.868772, acc.: 47.66%] [G loss: 1.803597]\n",
      "epoch:27 step:25319 [D loss: 0.447251, acc.: 75.78%] [G loss: 1.547171]\n",
      "epoch:27 step:25320 [D loss: 0.886117, acc.: 50.00%] [G loss: 1.414090]\n",
      "epoch:27 step:25321 [D loss: 0.739074, acc.: 55.47%] [G loss: 1.535282]\n",
      "epoch:27 step:25322 [D loss: 0.770596, acc.: 47.66%] [G loss: 1.380706]\n",
      "epoch:27 step:25323 [D loss: 0.840429, acc.: 43.75%] [G loss: 1.315890]\n",
      "epoch:27 step:25324 [D loss: 0.792013, acc.: 49.22%] [G loss: 1.229487]\n",
      "epoch:27 step:25325 [D loss: 0.498921, acc.: 80.47%] [G loss: 1.135034]\n",
      "epoch:27 step:25326 [D loss: 0.256855, acc.: 95.31%] [G loss: 1.324691]\n",
      "epoch:27 step:25327 [D loss: 0.438546, acc.: 80.47%] [G loss: 1.310751]\n",
      "epoch:27 step:25328 [D loss: 0.326478, acc.: 90.62%] [G loss: 1.458639]\n",
      "epoch:27 step:25329 [D loss: 0.483906, acc.: 79.69%] [G loss: 1.905407]\n",
      "epoch:27 step:25330 [D loss: 0.513178, acc.: 78.91%] [G loss: 1.045919]\n",
      "epoch:27 step:25331 [D loss: 0.210639, acc.: 99.22%] [G loss: 1.339088]\n",
      "epoch:27 step:25332 [D loss: 0.210131, acc.: 96.88%] [G loss: 1.213254]\n",
      "epoch:27 step:25333 [D loss: 0.203475, acc.: 98.44%] [G loss: 1.612291]\n",
      "epoch:27 step:25334 [D loss: 0.159462, acc.: 98.44%] [G loss: 2.062890]\n",
      "epoch:27 step:25335 [D loss: 0.096169, acc.: 100.00%] [G loss: 1.839642]\n",
      "epoch:27 step:25336 [D loss: 0.662672, acc.: 60.94%] [G loss: 1.776530]\n",
      "epoch:27 step:25337 [D loss: 0.964603, acc.: 46.88%] [G loss: 1.231899]\n",
      "epoch:27 step:25338 [D loss: 0.881038, acc.: 49.22%] [G loss: 0.926459]\n",
      "epoch:27 step:25339 [D loss: 0.715839, acc.: 58.59%] [G loss: 0.906019]\n",
      "epoch:27 step:25340 [D loss: 0.465462, acc.: 79.69%] [G loss: 0.738007]\n",
      "epoch:27 step:25341 [D loss: 0.409331, acc.: 91.41%] [G loss: 0.883403]\n",
      "epoch:27 step:25342 [D loss: 0.321133, acc.: 88.28%] [G loss: 0.766613]\n",
      "epoch:27 step:25343 [D loss: 0.530888, acc.: 69.53%] [G loss: 1.273530]\n",
      "epoch:27 step:25344 [D loss: 0.582878, acc.: 67.97%] [G loss: 1.213589]\n",
      "epoch:27 step:25345 [D loss: 0.493948, acc.: 77.34%] [G loss: 1.247016]\n",
      "epoch:27 step:25346 [D loss: 0.695139, acc.: 59.38%] [G loss: 1.145740]\n",
      "epoch:27 step:25347 [D loss: 0.898253, acc.: 39.84%] [G loss: 1.173901]\n",
      "epoch:27 step:25348 [D loss: 0.672075, acc.: 57.03%] [G loss: 1.116020]\n",
      "epoch:27 step:25349 [D loss: 0.572651, acc.: 69.53%] [G loss: 1.019610]\n",
      "epoch:27 step:25350 [D loss: 0.512580, acc.: 74.22%] [G loss: 0.760373]\n",
      "epoch:27 step:25351 [D loss: 0.508874, acc.: 79.69%] [G loss: 1.152408]\n",
      "epoch:27 step:25352 [D loss: 0.673762, acc.: 57.81%] [G loss: 1.025062]\n",
      "epoch:27 step:25353 [D loss: 0.704550, acc.: 55.47%] [G loss: 0.754688]\n",
      "epoch:27 step:25354 [D loss: 0.838973, acc.: 39.84%] [G loss: 0.511825]\n",
      "epoch:27 step:25355 [D loss: 0.611103, acc.: 65.62%] [G loss: 1.274952]\n",
      "epoch:27 step:25356 [D loss: 0.244007, acc.: 95.31%] [G loss: 1.283074]\n",
      "epoch:27 step:25357 [D loss: 0.595432, acc.: 71.09%] [G loss: 1.034879]\n",
      "epoch:27 step:25358 [D loss: 0.207452, acc.: 99.22%] [G loss: 1.508438]\n",
      "epoch:27 step:25359 [D loss: 0.268269, acc.: 95.31%] [G loss: 0.670185]\n",
      "epoch:27 step:25360 [D loss: 0.800972, acc.: 45.31%] [G loss: 1.629965]\n",
      "epoch:27 step:25361 [D loss: 0.752681, acc.: 57.03%] [G loss: 1.163900]\n",
      "epoch:27 step:25362 [D loss: 0.417802, acc.: 86.72%] [G loss: 1.073524]\n",
      "epoch:27 step:25363 [D loss: 0.558721, acc.: 64.84%] [G loss: 0.851931]\n",
      "epoch:27 step:25364 [D loss: 0.798167, acc.: 42.19%] [G loss: 1.270356]\n",
      "epoch:27 step:25365 [D loss: 0.858371, acc.: 43.75%] [G loss: 0.903287]\n",
      "epoch:27 step:25366 [D loss: 0.620902, acc.: 66.41%] [G loss: 1.163083]\n",
      "epoch:27 step:25367 [D loss: 0.624398, acc.: 62.50%] [G loss: 1.460165]\n",
      "epoch:27 step:25368 [D loss: 0.828125, acc.: 42.97%] [G loss: 0.937279]\n",
      "epoch:27 step:25369 [D loss: 0.789079, acc.: 51.56%] [G loss: 1.156595]\n",
      "epoch:27 step:25370 [D loss: 0.196947, acc.: 96.09%] [G loss: 1.118676]\n",
      "epoch:27 step:25371 [D loss: 0.324463, acc.: 89.84%] [G loss: 0.642910]\n",
      "epoch:27 step:25372 [D loss: 0.575931, acc.: 70.31%] [G loss: 1.130495]\n",
      "epoch:27 step:25373 [D loss: 0.578338, acc.: 71.09%] [G loss: 1.667680]\n",
      "epoch:27 step:25374 [D loss: 0.320042, acc.: 83.59%] [G loss: 1.512593]\n",
      "epoch:27 step:25375 [D loss: 0.188104, acc.: 98.44%] [G loss: 1.657879]\n",
      "epoch:27 step:25376 [D loss: 0.669387, acc.: 60.94%] [G loss: 1.811839]\n",
      "epoch:27 step:25377 [D loss: 1.309151, acc.: 23.44%] [G loss: 1.682768]\n",
      "epoch:27 step:25378 [D loss: 1.003712, acc.: 48.44%] [G loss: 1.692631]\n",
      "epoch:27 step:25379 [D loss: 0.725313, acc.: 50.00%] [G loss: 1.332977]\n",
      "epoch:27 step:25380 [D loss: 0.558967, acc.: 68.75%] [G loss: 1.440450]\n",
      "epoch:27 step:25381 [D loss: 0.638310, acc.: 63.28%] [G loss: 1.325737]\n",
      "epoch:27 step:25382 [D loss: 0.442560, acc.: 82.81%] [G loss: 1.250419]\n",
      "epoch:27 step:25383 [D loss: 0.649729, acc.: 63.28%] [G loss: 1.446074]\n",
      "epoch:27 step:25384 [D loss: 0.721929, acc.: 55.47%] [G loss: 1.330300]\n",
      "epoch:27 step:25385 [D loss: 0.782472, acc.: 49.22%] [G loss: 1.218347]\n",
      "epoch:27 step:25386 [D loss: 0.521625, acc.: 75.78%] [G loss: 1.371311]\n",
      "epoch:27 step:25387 [D loss: 0.553993, acc.: 70.31%] [G loss: 1.525274]\n",
      "epoch:27 step:25388 [D loss: 0.536350, acc.: 75.78%] [G loss: 1.398006]\n",
      "epoch:27 step:25389 [D loss: 0.566313, acc.: 72.66%] [G loss: 1.178375]\n",
      "epoch:27 step:25390 [D loss: 0.603977, acc.: 64.06%] [G loss: 1.180550]\n",
      "epoch:27 step:25391 [D loss: 0.508506, acc.: 81.25%] [G loss: 1.439599]\n",
      "epoch:27 step:25392 [D loss: 0.378759, acc.: 90.62%] [G loss: 1.174703]\n",
      "epoch:27 step:25393 [D loss: 0.542756, acc.: 74.22%] [G loss: 1.612324]\n",
      "epoch:27 step:25394 [D loss: 0.706891, acc.: 57.81%] [G loss: 1.334685]\n",
      "epoch:27 step:25395 [D loss: 0.631831, acc.: 66.41%] [G loss: 0.918585]\n",
      "epoch:27 step:25396 [D loss: 0.552696, acc.: 72.66%] [G loss: 0.879629]\n",
      "epoch:27 step:25397 [D loss: 0.780195, acc.: 43.75%] [G loss: 0.991431]\n",
      "epoch:27 step:25398 [D loss: 0.540253, acc.: 72.66%] [G loss: 1.021370]\n",
      "epoch:27 step:25399 [D loss: 0.696295, acc.: 57.03%] [G loss: 0.918270]\n",
      "epoch:27 step:25400 [D loss: 0.611129, acc.: 68.75%] [G loss: 0.958347]\n",
      "epoch:27 step:25401 [D loss: 0.689238, acc.: 50.78%] [G loss: 1.017925]\n",
      "epoch:27 step:25402 [D loss: 0.755639, acc.: 50.00%] [G loss: 1.070998]\n",
      "epoch:27 step:25403 [D loss: 0.573123, acc.: 75.78%] [G loss: 0.965886]\n",
      "epoch:27 step:25404 [D loss: 0.739517, acc.: 56.25%] [G loss: 0.843937]\n",
      "epoch:27 step:25405 [D loss: 0.740431, acc.: 52.34%] [G loss: 0.855352]\n",
      "epoch:27 step:25406 [D loss: 0.613495, acc.: 66.41%] [G loss: 0.917755]\n",
      "epoch:27 step:25407 [D loss: 0.673242, acc.: 62.50%] [G loss: 0.882748]\n",
      "epoch:27 step:25408 [D loss: 0.637379, acc.: 62.50%] [G loss: 0.894140]\n",
      "epoch:27 step:25409 [D loss: 0.702728, acc.: 56.25%] [G loss: 0.964838]\n",
      "epoch:27 step:25410 [D loss: 0.506124, acc.: 78.12%] [G loss: 1.049881]\n",
      "epoch:27 step:25411 [D loss: 0.578222, acc.: 71.88%] [G loss: 1.169979]\n",
      "epoch:27 step:25412 [D loss: 0.405988, acc.: 90.62%] [G loss: 1.035954]\n",
      "epoch:27 step:25413 [D loss: 0.380841, acc.: 85.16%] [G loss: 1.117789]\n",
      "epoch:27 step:25414 [D loss: 0.382311, acc.: 91.41%] [G loss: 1.029695]\n",
      "epoch:27 step:25415 [D loss: 0.601949, acc.: 65.62%] [G loss: 1.197820]\n",
      "epoch:27 step:25416 [D loss: 0.604600, acc.: 69.53%] [G loss: 1.163060]\n",
      "epoch:27 step:25417 [D loss: 0.592819, acc.: 68.75%] [G loss: 1.077226]\n",
      "epoch:27 step:25418 [D loss: 0.316396, acc.: 86.72%] [G loss: 1.362080]\n",
      "epoch:27 step:25419 [D loss: 0.324720, acc.: 92.19%] [G loss: 1.482152]\n",
      "epoch:27 step:25420 [D loss: 0.307833, acc.: 81.25%] [G loss: 1.423591]\n",
      "epoch:27 step:25421 [D loss: 0.248915, acc.: 89.06%] [G loss: 1.516948]\n",
      "epoch:27 step:25422 [D loss: 0.480244, acc.: 81.25%] [G loss: 1.387254]\n",
      "epoch:27 step:25423 [D loss: 0.764798, acc.: 53.91%] [G loss: 1.559865]\n",
      "epoch:27 step:25424 [D loss: 0.754547, acc.: 53.12%] [G loss: 0.927242]\n",
      "epoch:27 step:25425 [D loss: 0.531873, acc.: 72.66%] [G loss: 1.371415]\n",
      "epoch:27 step:25426 [D loss: 0.663277, acc.: 59.38%] [G loss: 1.212388]\n",
      "epoch:27 step:25427 [D loss: 0.428915, acc.: 84.38%] [G loss: 1.022394]\n",
      "epoch:27 step:25428 [D loss: 0.278207, acc.: 86.72%] [G loss: 0.804365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25429 [D loss: 0.258091, acc.: 89.06%] [G loss: 1.535065]\n",
      "epoch:27 step:25430 [D loss: 0.208404, acc.: 97.66%] [G loss: 1.370761]\n",
      "epoch:27 step:25431 [D loss: 0.220204, acc.: 96.88%] [G loss: 1.678504]\n",
      "epoch:27 step:25432 [D loss: 0.910722, acc.: 48.44%] [G loss: 1.326734]\n",
      "epoch:27 step:25433 [D loss: 0.744418, acc.: 53.91%] [G loss: 1.254883]\n",
      "epoch:27 step:25434 [D loss: 0.760554, acc.: 53.12%] [G loss: 0.875587]\n",
      "epoch:27 step:25435 [D loss: 0.643232, acc.: 65.62%] [G loss: 0.834428]\n",
      "epoch:27 step:25436 [D loss: 0.604163, acc.: 67.97%] [G loss: 1.339432]\n",
      "epoch:27 step:25437 [D loss: 0.373957, acc.: 92.19%] [G loss: 1.250804]\n",
      "epoch:27 step:25438 [D loss: 0.340934, acc.: 85.94%] [G loss: 1.293998]\n",
      "epoch:27 step:25439 [D loss: 0.718729, acc.: 53.12%] [G loss: 1.058909]\n",
      "epoch:27 step:25440 [D loss: 0.766483, acc.: 50.78%] [G loss: 0.770897]\n",
      "epoch:27 step:25441 [D loss: 0.834465, acc.: 35.94%] [G loss: 0.789961]\n",
      "epoch:27 step:25442 [D loss: 0.659511, acc.: 57.03%] [G loss: 0.906994]\n",
      "epoch:27 step:25443 [D loss: 0.564789, acc.: 75.00%] [G loss: 1.011425]\n",
      "epoch:27 step:25444 [D loss: 0.453248, acc.: 78.12%] [G loss: 1.351804]\n",
      "epoch:27 step:25445 [D loss: 0.591565, acc.: 71.09%] [G loss: 0.975174]\n",
      "epoch:27 step:25446 [D loss: 0.725482, acc.: 53.12%] [G loss: 1.051399]\n",
      "epoch:27 step:25447 [D loss: 0.745173, acc.: 48.44%] [G loss: 1.084094]\n",
      "epoch:27 step:25448 [D loss: 0.544244, acc.: 75.00%] [G loss: 1.132875]\n",
      "epoch:27 step:25449 [D loss: 0.314905, acc.: 89.84%] [G loss: 1.135960]\n",
      "epoch:27 step:25450 [D loss: 0.388675, acc.: 85.16%] [G loss: 1.031026]\n",
      "epoch:27 step:25451 [D loss: 0.339727, acc.: 91.41%] [G loss: 1.191414]\n",
      "epoch:27 step:25452 [D loss: 0.711023, acc.: 61.72%] [G loss: 0.959257]\n",
      "epoch:27 step:25453 [D loss: 0.680784, acc.: 57.81%] [G loss: 1.128390]\n",
      "epoch:27 step:25454 [D loss: 0.606406, acc.: 67.19%] [G loss: 0.997199]\n",
      "epoch:27 step:25455 [D loss: 0.692859, acc.: 64.06%] [G loss: 1.359551]\n",
      "epoch:27 step:25456 [D loss: 0.730714, acc.: 53.91%] [G loss: 1.343910]\n",
      "epoch:27 step:25457 [D loss: 0.693230, acc.: 62.50%] [G loss: 1.070716]\n",
      "epoch:27 step:25458 [D loss: 0.620464, acc.: 65.62%] [G loss: 1.069366]\n",
      "epoch:27 step:25459 [D loss: 0.631891, acc.: 62.50%] [G loss: 1.126810]\n",
      "epoch:27 step:25460 [D loss: 0.631977, acc.: 64.06%] [G loss: 1.147213]\n",
      "epoch:27 step:25461 [D loss: 0.556750, acc.: 70.31%] [G loss: 1.023021]\n",
      "epoch:27 step:25462 [D loss: 0.596696, acc.: 64.06%] [G loss: 0.947550]\n",
      "epoch:27 step:25463 [D loss: 0.676868, acc.: 54.69%] [G loss: 1.023098]\n",
      "epoch:27 step:25464 [D loss: 0.537251, acc.: 72.66%] [G loss: 1.065669]\n",
      "epoch:27 step:25465 [D loss: 0.753415, acc.: 47.66%] [G loss: 0.928756]\n",
      "epoch:27 step:25466 [D loss: 0.694090, acc.: 51.56%] [G loss: 1.015759]\n",
      "epoch:27 step:25467 [D loss: 0.526571, acc.: 77.34%] [G loss: 1.007390]\n",
      "epoch:27 step:25468 [D loss: 0.691315, acc.: 58.59%] [G loss: 0.793882]\n",
      "epoch:27 step:25469 [D loss: 0.707597, acc.: 60.16%] [G loss: 0.969571]\n",
      "epoch:27 step:25470 [D loss: 0.595312, acc.: 68.75%] [G loss: 0.977355]\n",
      "epoch:27 step:25471 [D loss: 0.691099, acc.: 52.34%] [G loss: 1.090256]\n",
      "epoch:27 step:25472 [D loss: 0.688461, acc.: 53.91%] [G loss: 0.940202]\n",
      "epoch:27 step:25473 [D loss: 0.643603, acc.: 66.41%] [G loss: 1.010323]\n",
      "epoch:27 step:25474 [D loss: 0.661822, acc.: 60.94%] [G loss: 0.892698]\n",
      "epoch:27 step:25475 [D loss: 0.627521, acc.: 62.50%] [G loss: 1.024805]\n",
      "epoch:27 step:25476 [D loss: 0.734170, acc.: 53.12%] [G loss: 0.888919]\n",
      "epoch:27 step:25477 [D loss: 0.587362, acc.: 72.66%] [G loss: 1.149555]\n",
      "epoch:27 step:25478 [D loss: 0.503432, acc.: 80.47%] [G loss: 0.950524]\n",
      "epoch:27 step:25479 [D loss: 0.580120, acc.: 70.31%] [G loss: 1.156635]\n",
      "epoch:27 step:25480 [D loss: 0.684166, acc.: 50.00%] [G loss: 1.300233]\n",
      "epoch:27 step:25481 [D loss: 0.675106, acc.: 59.38%] [G loss: 0.986289]\n",
      "epoch:27 step:25482 [D loss: 0.650961, acc.: 58.59%] [G loss: 0.732705]\n",
      "epoch:27 step:25483 [D loss: 0.635155, acc.: 63.28%] [G loss: 0.900648]\n",
      "epoch:27 step:25484 [D loss: 0.425549, acc.: 84.38%] [G loss: 0.915580]\n",
      "epoch:27 step:25485 [D loss: 0.606370, acc.: 64.06%] [G loss: 0.989395]\n",
      "epoch:27 step:25486 [D loss: 0.725109, acc.: 52.34%] [G loss: 1.083455]\n",
      "epoch:27 step:25487 [D loss: 0.804767, acc.: 42.97%] [G loss: 0.794557]\n",
      "epoch:27 step:25488 [D loss: 0.575505, acc.: 71.88%] [G loss: 0.838850]\n",
      "epoch:27 step:25489 [D loss: 0.641387, acc.: 66.41%] [G loss: 0.860744]\n",
      "epoch:27 step:25490 [D loss: 0.604246, acc.: 67.19%] [G loss: 1.028143]\n",
      "epoch:27 step:25491 [D loss: 0.504254, acc.: 82.03%] [G loss: 1.224190]\n",
      "epoch:27 step:25492 [D loss: 0.553339, acc.: 73.44%] [G loss: 1.034240]\n",
      "epoch:27 step:25493 [D loss: 0.617750, acc.: 65.62%] [G loss: 1.056680]\n",
      "epoch:27 step:25494 [D loss: 0.553922, acc.: 73.44%] [G loss: 0.978466]\n",
      "epoch:27 step:25495 [D loss: 0.671930, acc.: 64.06%] [G loss: 1.261768]\n",
      "epoch:27 step:25496 [D loss: 0.595066, acc.: 71.09%] [G loss: 1.108303]\n",
      "epoch:27 step:25497 [D loss: 0.533492, acc.: 72.66%] [G loss: 1.125727]\n",
      "epoch:27 step:25498 [D loss: 0.656102, acc.: 59.38%] [G loss: 0.845810]\n",
      "epoch:27 step:25499 [D loss: 0.331190, acc.: 88.28%] [G loss: 1.139629]\n",
      "epoch:27 step:25500 [D loss: 0.241939, acc.: 93.75%] [G loss: 1.461772]\n",
      "epoch:27 step:25501 [D loss: 0.704554, acc.: 50.00%] [G loss: 1.395399]\n",
      "epoch:27 step:25502 [D loss: 0.592557, acc.: 72.66%] [G loss: 1.067975]\n",
      "epoch:27 step:25503 [D loss: 0.434601, acc.: 85.94%] [G loss: 1.414586]\n",
      "epoch:27 step:25504 [D loss: 0.441736, acc.: 79.69%] [G loss: 1.282247]\n",
      "epoch:27 step:25505 [D loss: 0.307157, acc.: 96.09%] [G loss: 1.273965]\n",
      "epoch:27 step:25506 [D loss: 0.255904, acc.: 89.84%] [G loss: 1.443982]\n",
      "epoch:27 step:25507 [D loss: 0.373980, acc.: 91.41%] [G loss: 1.078571]\n",
      "epoch:27 step:25508 [D loss: 0.272645, acc.: 96.88%] [G loss: 1.688447]\n",
      "epoch:27 step:25509 [D loss: 0.911999, acc.: 49.22%] [G loss: 1.054555]\n",
      "epoch:27 step:25510 [D loss: 0.739976, acc.: 53.91%] [G loss: 0.952053]\n",
      "epoch:27 step:25511 [D loss: 0.794970, acc.: 46.09%] [G loss: 0.810750]\n",
      "epoch:27 step:25512 [D loss: 0.791832, acc.: 50.00%] [G loss: 0.987503]\n",
      "epoch:27 step:25513 [D loss: 0.773076, acc.: 46.88%] [G loss: 0.999837]\n",
      "epoch:27 step:25514 [D loss: 0.677794, acc.: 52.34%] [G loss: 1.179877]\n",
      "epoch:27 step:25515 [D loss: 0.679128, acc.: 60.94%] [G loss: 0.908640]\n",
      "epoch:27 step:25516 [D loss: 0.498418, acc.: 77.34%] [G loss: 1.015817]\n",
      "epoch:27 step:25517 [D loss: 0.357263, acc.: 85.94%] [G loss: 1.038289]\n",
      "epoch:27 step:25518 [D loss: 0.409415, acc.: 84.38%] [G loss: 1.012726]\n",
      "epoch:27 step:25519 [D loss: 0.230382, acc.: 92.97%] [G loss: 1.466234]\n",
      "epoch:27 step:25520 [D loss: 0.229139, acc.: 92.97%] [G loss: 1.256784]\n",
      "epoch:27 step:25521 [D loss: 0.273567, acc.: 92.97%] [G loss: 1.520151]\n",
      "epoch:27 step:25522 [D loss: 0.200958, acc.: 96.88%] [G loss: 1.258248]\n",
      "epoch:27 step:25523 [D loss: 0.675931, acc.: 59.38%] [G loss: 1.323511]\n",
      "epoch:27 step:25524 [D loss: 0.494903, acc.: 78.91%] [G loss: 1.353310]\n",
      "epoch:27 step:25525 [D loss: 0.669043, acc.: 60.16%] [G loss: 1.157112]\n",
      "epoch:27 step:25526 [D loss: 0.561027, acc.: 73.44%] [G loss: 1.329608]\n",
      "epoch:27 step:25527 [D loss: 0.534410, acc.: 80.47%] [G loss: 1.010520]\n",
      "epoch:27 step:25528 [D loss: 0.677308, acc.: 59.38%] [G loss: 1.098650]\n",
      "epoch:27 step:25529 [D loss: 0.270563, acc.: 85.94%] [G loss: 1.151513]\n",
      "epoch:27 step:25530 [D loss: 0.293434, acc.: 85.94%] [G loss: 1.228631]\n",
      "epoch:27 step:25531 [D loss: 0.243866, acc.: 94.53%] [G loss: 1.457149]\n",
      "epoch:27 step:25532 [D loss: 0.698378, acc.: 61.72%] [G loss: 1.410699]\n",
      "epoch:27 step:25533 [D loss: 0.529762, acc.: 76.56%] [G loss: 1.119469]\n",
      "epoch:27 step:25534 [D loss: 0.259515, acc.: 92.97%] [G loss: 1.554670]\n",
      "epoch:27 step:25535 [D loss: 0.488473, acc.: 77.34%] [G loss: 1.360255]\n",
      "epoch:27 step:25536 [D loss: 0.524544, acc.: 75.00%] [G loss: 1.371686]\n",
      "epoch:27 step:25537 [D loss: 0.376019, acc.: 87.50%] [G loss: 1.146052]\n",
      "epoch:27 step:25538 [D loss: 0.457463, acc.: 82.03%] [G loss: 1.082690]\n",
      "epoch:27 step:25539 [D loss: 0.458032, acc.: 82.81%] [G loss: 0.898419]\n",
      "epoch:27 step:25540 [D loss: 0.773304, acc.: 57.81%] [G loss: 1.341434]\n",
      "epoch:27 step:25541 [D loss: 0.509886, acc.: 77.34%] [G loss: 1.010153]\n",
      "epoch:27 step:25542 [D loss: 0.362752, acc.: 83.59%] [G loss: 1.182238]\n",
      "epoch:27 step:25543 [D loss: 0.993046, acc.: 42.19%] [G loss: 1.183302]\n",
      "epoch:27 step:25544 [D loss: 0.866257, acc.: 40.62%] [G loss: 1.283702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25545 [D loss: 0.682432, acc.: 57.03%] [G loss: 1.131960]\n",
      "epoch:27 step:25546 [D loss: 0.561471, acc.: 69.53%] [G loss: 0.888509]\n",
      "epoch:27 step:25547 [D loss: 0.679883, acc.: 57.03%] [G loss: 1.094470]\n",
      "epoch:27 step:25548 [D loss: 0.759064, acc.: 50.78%] [G loss: 1.156447]\n",
      "epoch:27 step:25549 [D loss: 0.785406, acc.: 48.44%] [G loss: 1.005691]\n",
      "epoch:27 step:25550 [D loss: 0.724255, acc.: 54.69%] [G loss: 0.943068]\n",
      "epoch:27 step:25551 [D loss: 0.549011, acc.: 75.00%] [G loss: 1.131324]\n",
      "epoch:27 step:25552 [D loss: 0.862261, acc.: 41.41%] [G loss: 1.081824]\n",
      "epoch:27 step:25553 [D loss: 0.502305, acc.: 76.56%] [G loss: 1.248280]\n",
      "epoch:27 step:25554 [D loss: 0.270749, acc.: 93.75%] [G loss: 1.310403]\n",
      "epoch:27 step:25555 [D loss: 0.193061, acc.: 98.44%] [G loss: 1.269818]\n",
      "epoch:27 step:25556 [D loss: 0.314698, acc.: 88.28%] [G loss: 1.151805]\n",
      "epoch:27 step:25557 [D loss: 0.503370, acc.: 71.88%] [G loss: 1.454387]\n",
      "epoch:27 step:25558 [D loss: 0.198301, acc.: 96.88%] [G loss: 1.264497]\n",
      "epoch:27 step:25559 [D loss: 0.196960, acc.: 99.22%] [G loss: 1.425492]\n",
      "epoch:27 step:25560 [D loss: 0.170580, acc.: 98.44%] [G loss: 1.495178]\n",
      "epoch:27 step:25561 [D loss: 0.672388, acc.: 62.50%] [G loss: 1.186328]\n",
      "epoch:27 step:25562 [D loss: 0.280031, acc.: 90.62%] [G loss: 1.330284]\n",
      "epoch:27 step:25563 [D loss: 0.729258, acc.: 58.59%] [G loss: 1.411123]\n",
      "epoch:27 step:25564 [D loss: 0.729424, acc.: 53.12%] [G loss: 1.662036]\n",
      "epoch:27 step:25565 [D loss: 0.753749, acc.: 48.44%] [G loss: 1.373941]\n",
      "epoch:27 step:25566 [D loss: 0.740401, acc.: 50.78%] [G loss: 1.373940]\n",
      "epoch:27 step:25567 [D loss: 0.680633, acc.: 59.38%] [G loss: 1.443380]\n",
      "epoch:27 step:25568 [D loss: 0.451737, acc.: 82.03%] [G loss: 1.327427]\n",
      "epoch:27 step:25569 [D loss: 0.621244, acc.: 60.16%] [G loss: 1.202364]\n",
      "epoch:27 step:25570 [D loss: 0.456633, acc.: 85.94%] [G loss: 0.971701]\n",
      "epoch:27 step:25571 [D loss: 0.457314, acc.: 83.59%] [G loss: 1.126457]\n",
      "epoch:27 step:25572 [D loss: 0.620179, acc.: 65.62%] [G loss: 1.033917]\n",
      "epoch:27 step:25573 [D loss: 0.488097, acc.: 79.69%] [G loss: 1.128385]\n",
      "epoch:27 step:25574 [D loss: 0.450625, acc.: 85.94%] [G loss: 1.159742]\n",
      "epoch:27 step:25575 [D loss: 0.402520, acc.: 86.72%] [G loss: 1.066824]\n",
      "epoch:27 step:25576 [D loss: 0.543532, acc.: 71.88%] [G loss: 1.254932]\n",
      "epoch:27 step:25577 [D loss: 0.306140, acc.: 85.16%] [G loss: 1.375010]\n",
      "epoch:27 step:25578 [D loss: 0.245622, acc.: 92.19%] [G loss: 1.436384]\n",
      "epoch:27 step:25579 [D loss: 0.361603, acc.: 89.84%] [G loss: 1.442912]\n",
      "epoch:27 step:25580 [D loss: 0.854396, acc.: 44.53%] [G loss: 1.383072]\n",
      "epoch:27 step:25581 [D loss: 0.757667, acc.: 53.12%] [G loss: 1.211949]\n",
      "epoch:27 step:25582 [D loss: 0.887301, acc.: 49.22%] [G loss: 0.799308]\n",
      "epoch:27 step:25583 [D loss: 0.288440, acc.: 83.59%] [G loss: 1.288281]\n",
      "epoch:27 step:25584 [D loss: 0.311579, acc.: 84.38%] [G loss: 1.178756]\n",
      "epoch:27 step:25585 [D loss: 0.240915, acc.: 92.97%] [G loss: 0.575896]\n",
      "epoch:27 step:25586 [D loss: 0.493874, acc.: 77.34%] [G loss: 1.112181]\n",
      "epoch:27 step:25587 [D loss: 0.236656, acc.: 98.44%] [G loss: 1.061356]\n",
      "epoch:27 step:25588 [D loss: 0.252727, acc.: 92.19%] [G loss: 1.394636]\n",
      "epoch:27 step:25589 [D loss: 0.399767, acc.: 90.62%] [G loss: 1.438223]\n",
      "epoch:27 step:25590 [D loss: 0.292799, acc.: 87.50%] [G loss: 1.229675]\n",
      "epoch:27 step:25591 [D loss: 0.260587, acc.: 89.06%] [G loss: 1.609617]\n",
      "epoch:27 step:25592 [D loss: 0.128688, acc.: 99.22%] [G loss: 1.834999]\n",
      "epoch:27 step:25593 [D loss: 0.461229, acc.: 81.25%] [G loss: 1.116778]\n",
      "epoch:27 step:25594 [D loss: 0.902513, acc.: 53.12%] [G loss: 1.553264]\n",
      "epoch:27 step:25595 [D loss: 0.776173, acc.: 48.44%] [G loss: 1.401751]\n",
      "epoch:27 step:25596 [D loss: 0.851942, acc.: 43.75%] [G loss: 1.412906]\n",
      "epoch:27 step:25597 [D loss: 0.707483, acc.: 53.12%] [G loss: 1.030712]\n",
      "epoch:27 step:25598 [D loss: 0.720242, acc.: 53.91%] [G loss: 1.143110]\n",
      "epoch:27 step:25599 [D loss: 0.863779, acc.: 35.94%] [G loss: 1.097225]\n",
      "epoch:27 step:25600 [D loss: 0.368758, acc.: 90.62%] [G loss: 1.392701]\n",
      "epoch:27 step:25601 [D loss: 0.538224, acc.: 74.22%] [G loss: 1.334722]\n",
      "epoch:27 step:25602 [D loss: 0.468829, acc.: 82.81%] [G loss: 1.253887]\n",
      "epoch:27 step:25603 [D loss: 0.231382, acc.: 94.53%] [G loss: 1.639392]\n",
      "epoch:27 step:25604 [D loss: 0.229259, acc.: 92.19%] [G loss: 1.713423]\n",
      "epoch:27 step:25605 [D loss: 0.286466, acc.: 92.19%] [G loss: 1.865857]\n",
      "epoch:27 step:25606 [D loss: 0.231340, acc.: 98.44%] [G loss: 1.752120]\n",
      "epoch:27 step:25607 [D loss: 0.150610, acc.: 96.09%] [G loss: 1.729942]\n",
      "epoch:27 step:25608 [D loss: 0.153850, acc.: 98.44%] [G loss: 1.988121]\n",
      "epoch:27 step:25609 [D loss: 0.100165, acc.: 100.00%] [G loss: 1.986388]\n",
      "epoch:27 step:25610 [D loss: 0.145177, acc.: 98.44%] [G loss: 2.242368]\n",
      "epoch:27 step:25611 [D loss: 0.095223, acc.: 100.00%] [G loss: 2.771157]\n",
      "epoch:27 step:25612 [D loss: 0.107565, acc.: 99.22%] [G loss: 1.839173]\n",
      "epoch:27 step:25613 [D loss: 0.079428, acc.: 100.00%] [G loss: 2.272797]\n",
      "epoch:27 step:25614 [D loss: 0.111963, acc.: 100.00%] [G loss: 1.532368]\n",
      "epoch:27 step:25615 [D loss: 0.935415, acc.: 53.12%] [G loss: 1.130726]\n",
      "epoch:27 step:25616 [D loss: 2.754215, acc.: 7.81%] [G loss: 1.981394]\n",
      "epoch:27 step:25617 [D loss: 0.961445, acc.: 50.00%] [G loss: 1.676078]\n",
      "epoch:27 step:25618 [D loss: 0.963360, acc.: 41.41%] [G loss: 1.509792]\n",
      "epoch:27 step:25619 [D loss: 0.748449, acc.: 57.03%] [G loss: 1.174413]\n",
      "epoch:27 step:25620 [D loss: 0.903665, acc.: 51.56%] [G loss: 1.250336]\n",
      "epoch:27 step:25621 [D loss: 0.980762, acc.: 27.34%] [G loss: 1.039388]\n",
      "epoch:27 step:25622 [D loss: 0.436374, acc.: 81.25%] [G loss: 1.345261]\n",
      "epoch:27 step:25623 [D loss: 0.464628, acc.: 80.47%] [G loss: 1.019360]\n",
      "epoch:27 step:25624 [D loss: 1.616494, acc.: 30.47%] [G loss: 1.451938]\n",
      "epoch:27 step:25625 [D loss: 0.897222, acc.: 42.19%] [G loss: 1.396923]\n",
      "epoch:27 step:25626 [D loss: 0.657132, acc.: 57.81%] [G loss: 1.598962]\n",
      "epoch:27 step:25627 [D loss: 0.647569, acc.: 57.03%] [G loss: 1.425969]\n",
      "epoch:27 step:25628 [D loss: 0.718987, acc.: 57.03%] [G loss: 1.323941]\n",
      "epoch:27 step:25629 [D loss: 0.532108, acc.: 71.88%] [G loss: 1.253136]\n",
      "epoch:27 step:25630 [D loss: 0.510033, acc.: 76.56%] [G loss: 1.042548]\n",
      "epoch:27 step:25631 [D loss: 0.345475, acc.: 91.41%] [G loss: 1.101857]\n",
      "epoch:27 step:25632 [D loss: 0.381284, acc.: 94.53%] [G loss: 1.194244]\n",
      "epoch:27 step:25633 [D loss: 0.550736, acc.: 69.53%] [G loss: 1.074898]\n",
      "epoch:27 step:25634 [D loss: 0.345644, acc.: 87.50%] [G loss: 1.508408]\n",
      "epoch:27 step:25635 [D loss: 0.330975, acc.: 93.75%] [G loss: 1.232854]\n",
      "epoch:27 step:25636 [D loss: 0.408827, acc.: 92.19%] [G loss: 0.992030]\n",
      "epoch:27 step:25637 [D loss: 0.614140, acc.: 66.41%] [G loss: 0.897770]\n",
      "epoch:27 step:25638 [D loss: 0.575195, acc.: 67.97%] [G loss: 0.524125]\n",
      "epoch:27 step:25639 [D loss: 0.646233, acc.: 60.16%] [G loss: 0.843904]\n",
      "epoch:27 step:25640 [D loss: 0.449787, acc.: 85.94%] [G loss: 0.997761]\n",
      "epoch:27 step:25641 [D loss: 0.518469, acc.: 65.62%] [G loss: 1.066679]\n",
      "epoch:27 step:25642 [D loss: 0.505275, acc.: 67.97%] [G loss: 1.107570]\n",
      "epoch:27 step:25643 [D loss: 0.380593, acc.: 89.84%] [G loss: 1.506629]\n",
      "epoch:27 step:25644 [D loss: 0.162579, acc.: 98.44%] [G loss: 1.004346]\n",
      "epoch:27 step:25645 [D loss: 0.172815, acc.: 97.66%] [G loss: 1.928065]\n",
      "epoch:27 step:25646 [D loss: 0.314739, acc.: 89.06%] [G loss: 2.016689]\n",
      "epoch:27 step:25647 [D loss: 0.956714, acc.: 52.34%] [G loss: 1.563320]\n",
      "epoch:27 step:25648 [D loss: 0.790930, acc.: 52.34%] [G loss: 1.184667]\n",
      "epoch:27 step:25649 [D loss: 0.825414, acc.: 47.66%] [G loss: 1.178091]\n",
      "epoch:27 step:25650 [D loss: 0.617849, acc.: 60.94%] [G loss: 1.473609]\n",
      "epoch:27 step:25651 [D loss: 0.613925, acc.: 67.97%] [G loss: 1.419350]\n",
      "epoch:27 step:25652 [D loss: 0.608774, acc.: 62.50%] [G loss: 1.212930]\n",
      "epoch:27 step:25653 [D loss: 0.454623, acc.: 76.56%] [G loss: 1.505559]\n",
      "epoch:27 step:25654 [D loss: 0.623739, acc.: 58.59%] [G loss: 1.796874]\n",
      "epoch:27 step:25655 [D loss: 0.536655, acc.: 69.53%] [G loss: 1.440695]\n",
      "epoch:27 step:25656 [D loss: 0.507875, acc.: 63.28%] [G loss: 1.625085]\n",
      "epoch:27 step:25657 [D loss: 0.354509, acc.: 90.62%] [G loss: 1.716490]\n",
      "epoch:27 step:25658 [D loss: 0.359172, acc.: 85.16%] [G loss: 1.493347]\n",
      "epoch:27 step:25659 [D loss: 0.395612, acc.: 87.50%] [G loss: 1.598497]\n",
      "epoch:27 step:25660 [D loss: 0.430976, acc.: 85.94%] [G loss: 1.663059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25661 [D loss: 0.707364, acc.: 52.34%] [G loss: 1.382418]\n",
      "epoch:27 step:25662 [D loss: 0.829119, acc.: 51.56%] [G loss: 1.546259]\n",
      "epoch:27 step:25663 [D loss: 0.636276, acc.: 66.41%] [G loss: 0.968585]\n",
      "epoch:27 step:25664 [D loss: 0.755443, acc.: 46.88%] [G loss: 0.876400]\n",
      "epoch:27 step:25665 [D loss: 0.584937, acc.: 65.62%] [G loss: 0.992258]\n",
      "epoch:27 step:25666 [D loss: 0.503092, acc.: 71.88%] [G loss: 0.780042]\n",
      "epoch:27 step:25667 [D loss: 0.636982, acc.: 65.62%] [G loss: 1.024391]\n",
      "epoch:27 step:25668 [D loss: 0.294526, acc.: 95.31%] [G loss: 1.200712]\n",
      "epoch:27 step:25669 [D loss: 0.300278, acc.: 91.41%] [G loss: 1.158383]\n",
      "epoch:27 step:25670 [D loss: 0.251234, acc.: 94.53%] [G loss: 1.471056]\n",
      "epoch:27 step:25671 [D loss: 0.398903, acc.: 92.97%] [G loss: 1.320801]\n",
      "epoch:27 step:25672 [D loss: 0.742045, acc.: 57.81%] [G loss: 1.240606]\n",
      "epoch:27 step:25673 [D loss: 0.592378, acc.: 69.53%] [G loss: 1.332774]\n",
      "epoch:27 step:25674 [D loss: 0.604331, acc.: 62.50%] [G loss: 1.153530]\n",
      "epoch:27 step:25675 [D loss: 0.605476, acc.: 68.75%] [G loss: 0.994365]\n",
      "epoch:27 step:25676 [D loss: 0.777281, acc.: 60.94%] [G loss: 0.989431]\n",
      "epoch:27 step:25677 [D loss: 0.712498, acc.: 57.03%] [G loss: 0.985575]\n",
      "epoch:27 step:25678 [D loss: 0.393674, acc.: 85.16%] [G loss: 0.977395]\n",
      "epoch:27 step:25679 [D loss: 0.304292, acc.: 86.72%] [G loss: 1.065423]\n",
      "epoch:27 step:25680 [D loss: 0.327673, acc.: 92.97%] [G loss: 1.371262]\n",
      "epoch:27 step:25681 [D loss: 0.577477, acc.: 74.22%] [G loss: 1.059885]\n",
      "epoch:27 step:25682 [D loss: 0.694077, acc.: 54.69%] [G loss: 1.340129]\n",
      "epoch:27 step:25683 [D loss: 0.623043, acc.: 64.06%] [G loss: 1.087094]\n",
      "epoch:27 step:25684 [D loss: 0.572475, acc.: 75.78%] [G loss: 1.119077]\n",
      "epoch:27 step:25685 [D loss: 0.350243, acc.: 92.19%] [G loss: 1.058191]\n",
      "epoch:27 step:25686 [D loss: 0.398287, acc.: 92.19%] [G loss: 1.187607]\n",
      "epoch:27 step:25687 [D loss: 0.394505, acc.: 92.97%] [G loss: 1.003451]\n",
      "epoch:27 step:25688 [D loss: 0.657658, acc.: 68.75%] [G loss: 1.213632]\n",
      "epoch:27 step:25689 [D loss: 0.684173, acc.: 59.38%] [G loss: 1.082788]\n",
      "epoch:27 step:25690 [D loss: 0.745427, acc.: 42.19%] [G loss: 0.850774]\n",
      "epoch:27 step:25691 [D loss: 0.775357, acc.: 46.88%] [G loss: 0.521080]\n",
      "epoch:27 step:25692 [D loss: 0.918425, acc.: 38.28%] [G loss: 0.832057]\n",
      "epoch:27 step:25693 [D loss: 0.751105, acc.: 50.00%] [G loss: 1.135356]\n",
      "epoch:27 step:25694 [D loss: 0.584254, acc.: 69.53%] [G loss: 0.915251]\n",
      "epoch:27 step:25695 [D loss: 0.542803, acc.: 71.09%] [G loss: 1.011285]\n",
      "epoch:27 step:25696 [D loss: 0.538012, acc.: 72.66%] [G loss: 0.921527]\n",
      "epoch:27 step:25697 [D loss: 0.407306, acc.: 76.56%] [G loss: 1.247315]\n",
      "epoch:27 step:25698 [D loss: 0.471490, acc.: 82.81%] [G loss: 1.352456]\n",
      "epoch:27 step:25699 [D loss: 0.438074, acc.: 82.03%] [G loss: 1.336695]\n",
      "epoch:27 step:25700 [D loss: 0.531909, acc.: 68.75%] [G loss: 1.427329]\n",
      "epoch:27 step:25701 [D loss: 0.356212, acc.: 89.84%] [G loss: 1.318958]\n",
      "epoch:27 step:25702 [D loss: 0.327945, acc.: 94.53%] [G loss: 1.487652]\n",
      "epoch:27 step:25703 [D loss: 0.357177, acc.: 79.69%] [G loss: 1.510481]\n",
      "epoch:27 step:25704 [D loss: 0.231783, acc.: 95.31%] [G loss: 1.485430]\n",
      "epoch:27 step:25705 [D loss: 0.229957, acc.: 92.97%] [G loss: 1.758503]\n",
      "epoch:27 step:25706 [D loss: 0.205987, acc.: 95.31%] [G loss: 1.958734]\n",
      "epoch:27 step:25707 [D loss: 0.405736, acc.: 82.81%] [G loss: 1.265965]\n",
      "epoch:27 step:25708 [D loss: 0.175508, acc.: 98.44%] [G loss: 1.427203]\n",
      "epoch:27 step:25709 [D loss: 0.519068, acc.: 78.91%] [G loss: 1.510996]\n",
      "epoch:27 step:25710 [D loss: 0.968680, acc.: 46.88%] [G loss: 0.809495]\n",
      "epoch:27 step:25711 [D loss: 0.350810, acc.: 88.28%] [G loss: 0.484407]\n",
      "epoch:27 step:25712 [D loss: 0.323437, acc.: 84.38%] [G loss: 1.757715]\n",
      "epoch:27 step:25713 [D loss: 0.249145, acc.: 97.66%] [G loss: 1.378909]\n",
      "epoch:27 step:25714 [D loss: 0.280118, acc.: 91.41%] [G loss: 0.933102]\n",
      "epoch:27 step:25715 [D loss: 0.525452, acc.: 77.34%] [G loss: 0.954240]\n",
      "epoch:27 step:25716 [D loss: 0.772928, acc.: 50.78%] [G loss: 1.169234]\n",
      "epoch:27 step:25717 [D loss: 0.703573, acc.: 60.94%] [G loss: 1.430331]\n",
      "epoch:27 step:25718 [D loss: 0.159164, acc.: 99.22%] [G loss: 2.389033]\n",
      "epoch:27 step:25719 [D loss: 0.442684, acc.: 79.69%] [G loss: 2.302683]\n",
      "epoch:27 step:25720 [D loss: 0.818026, acc.: 48.44%] [G loss: 1.621162]\n",
      "epoch:27 step:25721 [D loss: 0.823090, acc.: 46.88%] [G loss: 0.787852]\n",
      "epoch:27 step:25722 [D loss: 0.919290, acc.: 42.19%] [G loss: 1.306469]\n",
      "epoch:27 step:25723 [D loss: 0.319867, acc.: 88.28%] [G loss: 1.582881]\n",
      "epoch:27 step:25724 [D loss: 0.481323, acc.: 78.12%] [G loss: 1.580266]\n",
      "epoch:27 step:25725 [D loss: 1.112645, acc.: 29.69%] [G loss: 1.611238]\n",
      "epoch:27 step:25726 [D loss: 0.262141, acc.: 96.88%] [G loss: 1.800378]\n",
      "epoch:27 step:25727 [D loss: 0.276608, acc.: 92.19%] [G loss: 1.307321]\n",
      "epoch:27 step:25728 [D loss: 0.421714, acc.: 85.16%] [G loss: 1.915034]\n",
      "epoch:27 step:25729 [D loss: 0.677961, acc.: 65.62%] [G loss: 1.887292]\n",
      "epoch:27 step:25730 [D loss: 0.892292, acc.: 40.62%] [G loss: 1.230323]\n",
      "epoch:27 step:25731 [D loss: 1.085682, acc.: 35.94%] [G loss: 1.226263]\n",
      "epoch:27 step:25732 [D loss: 1.071793, acc.: 30.47%] [G loss: 1.484287]\n",
      "epoch:27 step:25733 [D loss: 0.817664, acc.: 55.47%] [G loss: 1.170484]\n",
      "epoch:27 step:25734 [D loss: 0.712369, acc.: 55.47%] [G loss: 1.263299]\n",
      "epoch:27 step:25735 [D loss: 0.763842, acc.: 50.00%] [G loss: 1.239654]\n",
      "epoch:27 step:25736 [D loss: 0.767749, acc.: 46.09%] [G loss: 0.910265]\n",
      "epoch:27 step:25737 [D loss: 0.689906, acc.: 52.34%] [G loss: 1.020442]\n",
      "epoch:27 step:25738 [D loss: 0.674339, acc.: 51.56%] [G loss: 1.152614]\n",
      "epoch:27 step:25739 [D loss: 0.747273, acc.: 50.00%] [G loss: 0.940997]\n",
      "epoch:27 step:25740 [D loss: 0.877609, acc.: 32.03%] [G loss: 1.171660]\n",
      "epoch:27 step:25741 [D loss: 0.713364, acc.: 52.34%] [G loss: 1.281778]\n",
      "epoch:27 step:25742 [D loss: 0.765759, acc.: 46.09%] [G loss: 1.588886]\n",
      "epoch:27 step:25743 [D loss: 0.674216, acc.: 61.72%] [G loss: 1.314791]\n",
      "epoch:27 step:25744 [D loss: 0.630549, acc.: 64.84%] [G loss: 0.992653]\n",
      "epoch:27 step:25745 [D loss: 0.671049, acc.: 56.25%] [G loss: 1.422222]\n",
      "epoch:27 step:25746 [D loss: 0.595251, acc.: 64.06%] [G loss: 1.174402]\n",
      "epoch:27 step:25747 [D loss: 0.469893, acc.: 86.72%] [G loss: 1.221188]\n",
      "epoch:27 step:25748 [D loss: 0.355586, acc.: 92.97%] [G loss: 1.534510]\n",
      "epoch:27 step:25749 [D loss: 0.349866, acc.: 96.09%] [G loss: 1.586251]\n",
      "epoch:27 step:25750 [D loss: 0.316775, acc.: 95.31%] [G loss: 1.644998]\n",
      "epoch:27 step:25751 [D loss: 0.293758, acc.: 94.53%] [G loss: 2.337378]\n",
      "epoch:27 step:25752 [D loss: 0.244473, acc.: 96.09%] [G loss: 2.179521]\n",
      "epoch:27 step:25753 [D loss: 0.292243, acc.: 93.75%] [G loss: 1.786523]\n",
      "epoch:27 step:25754 [D loss: 0.272320, acc.: 97.66%] [G loss: 1.882591]\n",
      "epoch:27 step:25755 [D loss: 0.152519, acc.: 99.22%] [G loss: 2.477788]\n",
      "epoch:27 step:25756 [D loss: 0.206210, acc.: 99.22%] [G loss: 2.104755]\n",
      "epoch:27 step:25757 [D loss: 0.515519, acc.: 71.88%] [G loss: 2.456654]\n",
      "epoch:27 step:25758 [D loss: 0.598919, acc.: 75.00%] [G loss: 1.281353]\n",
      "epoch:27 step:25759 [D loss: 0.513153, acc.: 67.97%] [G loss: 1.348118]\n",
      "epoch:27 step:25760 [D loss: 0.886145, acc.: 46.88%] [G loss: 0.727759]\n",
      "epoch:27 step:25761 [D loss: 1.005471, acc.: 25.78%] [G loss: 0.716965]\n",
      "epoch:27 step:25762 [D loss: 0.626548, acc.: 62.50%] [G loss: 0.793642]\n",
      "epoch:27 step:25763 [D loss: 0.597957, acc.: 60.16%] [G loss: 0.950535]\n",
      "epoch:27 step:25764 [D loss: 0.408275, acc.: 77.34%] [G loss: 1.193330]\n",
      "epoch:27 step:25765 [D loss: 0.391427, acc.: 91.41%] [G loss: 1.396111]\n",
      "epoch:27 step:25766 [D loss: 0.397433, acc.: 88.28%] [G loss: 1.140534]\n",
      "epoch:27 step:25767 [D loss: 0.291597, acc.: 90.62%] [G loss: 1.420235]\n",
      "epoch:27 step:25768 [D loss: 0.164196, acc.: 100.00%] [G loss: 1.782102]\n",
      "epoch:27 step:25769 [D loss: 0.195914, acc.: 96.88%] [G loss: 1.749399]\n",
      "epoch:27 step:25770 [D loss: 0.138385, acc.: 100.00%] [G loss: 1.759560]\n",
      "epoch:27 step:25771 [D loss: 0.183765, acc.: 98.44%] [G loss: 1.500977]\n",
      "epoch:27 step:25772 [D loss: 1.358728, acc.: 46.09%] [G loss: 1.444363]\n",
      "epoch:27 step:25773 [D loss: 1.066421, acc.: 37.50%] [G loss: 0.788756]\n",
      "epoch:27 step:25774 [D loss: 0.842392, acc.: 41.41%] [G loss: 0.965665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25775 [D loss: 0.640029, acc.: 59.38%] [G loss: 0.855847]\n",
      "epoch:27 step:25776 [D loss: 0.573638, acc.: 69.53%] [G loss: 1.062136]\n",
      "epoch:27 step:25777 [D loss: 0.641103, acc.: 63.28%] [G loss: 1.229489]\n",
      "epoch:27 step:25778 [D loss: 0.289258, acc.: 93.75%] [G loss: 1.268101]\n",
      "epoch:27 step:25779 [D loss: 0.325366, acc.: 89.84%] [G loss: 1.507871]\n",
      "epoch:27 step:25780 [D loss: 0.317013, acc.: 88.28%] [G loss: 1.997568]\n",
      "epoch:27 step:25781 [D loss: 0.917870, acc.: 41.41%] [G loss: 2.031298]\n",
      "epoch:27 step:25782 [D loss: 0.745798, acc.: 51.56%] [G loss: 1.537342]\n",
      "epoch:27 step:25783 [D loss: 0.615609, acc.: 64.84%] [G loss: 1.435125]\n",
      "epoch:27 step:25784 [D loss: 0.538209, acc.: 71.88%] [G loss: 1.244810]\n",
      "epoch:27 step:25785 [D loss: 0.700142, acc.: 57.03%] [G loss: 1.332366]\n",
      "epoch:27 step:25786 [D loss: 0.532048, acc.: 75.00%] [G loss: 1.331450]\n",
      "epoch:27 step:25787 [D loss: 0.692516, acc.: 64.84%] [G loss: 1.357426]\n",
      "epoch:27 step:25788 [D loss: 0.518937, acc.: 77.34%] [G loss: 1.509249]\n",
      "epoch:27 step:25789 [D loss: 0.415728, acc.: 87.50%] [G loss: 1.292789]\n",
      "epoch:27 step:25790 [D loss: 0.539566, acc.: 76.56%] [G loss: 1.159561]\n",
      "epoch:27 step:25791 [D loss: 0.502364, acc.: 75.78%] [G loss: 1.000832]\n",
      "epoch:27 step:25792 [D loss: 0.654289, acc.: 57.81%] [G loss: 1.282378]\n",
      "epoch:27 step:25793 [D loss: 0.512851, acc.: 73.44%] [G loss: 1.090927]\n",
      "epoch:27 step:25794 [D loss: 0.440683, acc.: 85.94%] [G loss: 1.184367]\n",
      "epoch:27 step:25795 [D loss: 0.671914, acc.: 59.38%] [G loss: 1.031501]\n",
      "epoch:27 step:25796 [D loss: 0.436666, acc.: 83.59%] [G loss: 1.278963]\n",
      "epoch:27 step:25797 [D loss: 0.398762, acc.: 85.94%] [G loss: 1.599226]\n",
      "epoch:27 step:25798 [D loss: 0.405639, acc.: 83.59%] [G loss: 1.319477]\n",
      "epoch:27 step:25799 [D loss: 0.650242, acc.: 68.75%] [G loss: 1.158597]\n",
      "epoch:27 step:25800 [D loss: 0.674276, acc.: 62.50%] [G loss: 1.374546]\n",
      "epoch:27 step:25801 [D loss: 0.550351, acc.: 78.12%] [G loss: 1.147778]\n",
      "epoch:27 step:25802 [D loss: 0.361348, acc.: 84.38%] [G loss: 1.247108]\n",
      "epoch:27 step:25803 [D loss: 0.313198, acc.: 87.50%] [G loss: 1.282149]\n",
      "epoch:27 step:25804 [D loss: 0.470313, acc.: 73.44%] [G loss: 1.345033]\n",
      "epoch:27 step:25805 [D loss: 0.694546, acc.: 53.91%] [G loss: 1.093144]\n",
      "epoch:27 step:25806 [D loss: 0.528624, acc.: 76.56%] [G loss: 1.051559]\n",
      "epoch:27 step:25807 [D loss: 0.385342, acc.: 89.06%] [G loss: 1.243966]\n",
      "epoch:27 step:25808 [D loss: 0.650726, acc.: 54.69%] [G loss: 1.201965]\n",
      "epoch:27 step:25809 [D loss: 0.528205, acc.: 74.22%] [G loss: 1.100348]\n",
      "epoch:27 step:25810 [D loss: 0.341690, acc.: 84.38%] [G loss: 1.200233]\n",
      "epoch:27 step:25811 [D loss: 0.511370, acc.: 76.56%] [G loss: 1.167687]\n",
      "epoch:27 step:25812 [D loss: 0.276585, acc.: 93.75%] [G loss: 1.383440]\n",
      "epoch:27 step:25813 [D loss: 0.299965, acc.: 92.97%] [G loss: 1.567212]\n",
      "epoch:27 step:25814 [D loss: 0.328216, acc.: 88.28%] [G loss: 1.598622]\n",
      "epoch:27 step:25815 [D loss: 0.716572, acc.: 60.94%] [G loss: 1.504633]\n",
      "epoch:27 step:25816 [D loss: 0.388404, acc.: 81.25%] [G loss: 1.476410]\n",
      "epoch:27 step:25817 [D loss: 0.551745, acc.: 71.88%] [G loss: 1.407342]\n",
      "epoch:27 step:25818 [D loss: 0.357333, acc.: 86.72%] [G loss: 1.617825]\n",
      "epoch:27 step:25819 [D loss: 0.425205, acc.: 83.59%] [G loss: 1.396963]\n",
      "epoch:27 step:25820 [D loss: 0.383137, acc.: 89.84%] [G loss: 1.583343]\n",
      "epoch:27 step:25821 [D loss: 0.373125, acc.: 90.62%] [G loss: 1.735134]\n",
      "epoch:27 step:25822 [D loss: 0.478265, acc.: 78.91%] [G loss: 1.521289]\n",
      "epoch:27 step:25823 [D loss: 0.433476, acc.: 84.38%] [G loss: 1.476827]\n",
      "epoch:27 step:25824 [D loss: 0.742886, acc.: 59.38%] [G loss: 1.350283]\n",
      "epoch:27 step:25825 [D loss: 0.575104, acc.: 70.31%] [G loss: 1.163058]\n",
      "epoch:27 step:25826 [D loss: 0.565493, acc.: 70.31%] [G loss: 1.403087]\n",
      "epoch:27 step:25827 [D loss: 0.627725, acc.: 67.97%] [G loss: 0.819943]\n",
      "epoch:27 step:25828 [D loss: 0.804426, acc.: 53.91%] [G loss: 1.149730]\n",
      "epoch:27 step:25829 [D loss: 0.313542, acc.: 90.62%] [G loss: 1.366202]\n",
      "epoch:27 step:25830 [D loss: 0.642488, acc.: 58.59%] [G loss: 1.146021]\n",
      "epoch:27 step:25831 [D loss: 0.558702, acc.: 68.75%] [G loss: 1.317156]\n",
      "epoch:27 step:25832 [D loss: 0.280903, acc.: 89.06%] [G loss: 1.292764]\n",
      "epoch:27 step:25833 [D loss: 0.437430, acc.: 88.28%] [G loss: 1.464328]\n",
      "epoch:27 step:25834 [D loss: 0.454941, acc.: 80.47%] [G loss: 1.344463]\n",
      "epoch:27 step:25835 [D loss: 0.208836, acc.: 96.09%] [G loss: 1.647737]\n",
      "epoch:27 step:25836 [D loss: 0.374427, acc.: 87.50%] [G loss: 1.850830]\n",
      "epoch:27 step:25837 [D loss: 0.482784, acc.: 78.91%] [G loss: 1.563166]\n",
      "epoch:27 step:25838 [D loss: 0.300307, acc.: 87.50%] [G loss: 1.742357]\n",
      "epoch:27 step:25839 [D loss: 0.410063, acc.: 80.47%] [G loss: 1.079949]\n",
      "epoch:27 step:25840 [D loss: 0.581270, acc.: 66.41%] [G loss: 1.581150]\n",
      "epoch:27 step:25841 [D loss: 0.654385, acc.: 59.38%] [G loss: 1.323424]\n",
      "epoch:27 step:25842 [D loss: 0.178227, acc.: 93.75%] [G loss: 0.979417]\n",
      "epoch:27 step:25843 [D loss: 0.519131, acc.: 75.78%] [G loss: 1.505616]\n",
      "epoch:27 step:25844 [D loss: 0.480471, acc.: 75.78%] [G loss: 1.502534]\n",
      "epoch:27 step:25845 [D loss: 0.541741, acc.: 75.00%] [G loss: 1.784552]\n",
      "epoch:27 step:25846 [D loss: 0.382809, acc.: 84.38%] [G loss: 1.362643]\n",
      "epoch:27 step:25847 [D loss: 0.330491, acc.: 89.06%] [G loss: 1.447739]\n",
      "epoch:27 step:25848 [D loss: 0.177485, acc.: 97.66%] [G loss: 1.815176]\n",
      "epoch:27 step:25849 [D loss: 0.194186, acc.: 93.75%] [G loss: 1.884869]\n",
      "epoch:27 step:25850 [D loss: 0.179657, acc.: 97.66%] [G loss: 2.212385]\n",
      "epoch:27 step:25851 [D loss: 0.310030, acc.: 94.53%] [G loss: 2.057956]\n",
      "epoch:27 step:25852 [D loss: 0.486760, acc.: 74.22%] [G loss: 1.861915]\n",
      "epoch:27 step:25853 [D loss: 0.123979, acc.: 98.44%] [G loss: 2.100194]\n",
      "epoch:27 step:25854 [D loss: 0.187093, acc.: 96.88%] [G loss: 2.041502]\n",
      "epoch:27 step:25855 [D loss: 0.094611, acc.: 99.22%] [G loss: 0.981824]\n",
      "epoch:27 step:25856 [D loss: 0.087158, acc.: 99.22%] [G loss: 2.157756]\n",
      "epoch:27 step:25857 [D loss: 0.281530, acc.: 89.84%] [G loss: 2.103277]\n",
      "epoch:27 step:25858 [D loss: 0.167871, acc.: 96.88%] [G loss: 2.087371]\n",
      "epoch:27 step:25859 [D loss: 0.365107, acc.: 80.47%] [G loss: 2.450576]\n",
      "epoch:27 step:25860 [D loss: 0.252359, acc.: 91.41%] [G loss: 1.487153]\n",
      "epoch:27 step:25861 [D loss: 1.066479, acc.: 39.06%] [G loss: 2.178563]\n",
      "epoch:27 step:25862 [D loss: 0.417146, acc.: 85.16%] [G loss: 1.744380]\n",
      "epoch:27 step:25863 [D loss: 0.754030, acc.: 53.91%] [G loss: 1.163025]\n",
      "epoch:27 step:25864 [D loss: 0.749754, acc.: 55.47%] [G loss: 1.408258]\n",
      "epoch:27 step:25865 [D loss: 0.754752, acc.: 59.38%] [G loss: 1.961365]\n",
      "epoch:27 step:25866 [D loss: 0.223087, acc.: 92.97%] [G loss: 1.544087]\n",
      "epoch:27 step:25867 [D loss: 0.796911, acc.: 53.91%] [G loss: 1.622146]\n",
      "epoch:27 step:25868 [D loss: 0.827414, acc.: 57.03%] [G loss: 1.632645]\n",
      "epoch:27 step:25869 [D loss: 0.680552, acc.: 64.06%] [G loss: 1.456951]\n",
      "epoch:27 step:25870 [D loss: 0.577006, acc.: 71.88%] [G loss: 1.947361]\n",
      "epoch:27 step:25871 [D loss: 0.670322, acc.: 61.72%] [G loss: 1.892044]\n",
      "epoch:27 step:25872 [D loss: 0.281578, acc.: 92.19%] [G loss: 1.875682]\n",
      "epoch:27 step:25873 [D loss: 0.564033, acc.: 69.53%] [G loss: 1.462187]\n",
      "epoch:27 step:25874 [D loss: 0.389822, acc.: 81.25%] [G loss: 1.810137]\n",
      "epoch:27 step:25875 [D loss: 0.227639, acc.: 92.19%] [G loss: 1.211889]\n",
      "epoch:27 step:25876 [D loss: 0.216163, acc.: 92.19%] [G loss: 1.682315]\n",
      "epoch:27 step:25877 [D loss: 0.217935, acc.: 88.28%] [G loss: 1.441422]\n",
      "epoch:27 step:25878 [D loss: 0.465463, acc.: 74.22%] [G loss: 2.422718]\n",
      "epoch:27 step:25879 [D loss: 0.740172, acc.: 61.72%] [G loss: 1.569639]\n",
      "epoch:27 step:25880 [D loss: 0.757041, acc.: 57.03%] [G loss: 1.515072]\n",
      "epoch:27 step:25881 [D loss: 1.094024, acc.: 31.25%] [G loss: 1.467793]\n",
      "epoch:27 step:25882 [D loss: 0.713681, acc.: 59.38%] [G loss: 1.363541]\n",
      "epoch:27 step:25883 [D loss: 1.088242, acc.: 31.25%] [G loss: 1.570939]\n",
      "epoch:27 step:25884 [D loss: 0.647536, acc.: 64.06%] [G loss: 1.680190]\n",
      "epoch:27 step:25885 [D loss: 0.627297, acc.: 64.06%] [G loss: 1.176006]\n",
      "epoch:27 step:25886 [D loss: 0.270080, acc.: 86.72%] [G loss: 1.227985]\n",
      "epoch:27 step:25887 [D loss: 0.213549, acc.: 93.75%] [G loss: 1.481972]\n",
      "epoch:27 step:25888 [D loss: 0.157878, acc.: 96.09%] [G loss: 1.632563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25889 [D loss: 0.765731, acc.: 51.56%] [G loss: 1.597547]\n",
      "epoch:27 step:25890 [D loss: 0.567954, acc.: 71.88%] [G loss: 1.559616]\n",
      "epoch:27 step:25891 [D loss: 0.756170, acc.: 54.69%] [G loss: 1.246477]\n",
      "epoch:27 step:25892 [D loss: 0.731806, acc.: 57.03%] [G loss: 1.519396]\n",
      "epoch:27 step:25893 [D loss: 0.460571, acc.: 79.69%] [G loss: 1.279747]\n",
      "epoch:27 step:25894 [D loss: 0.423187, acc.: 83.59%] [G loss: 1.646569]\n",
      "epoch:27 step:25895 [D loss: 0.481767, acc.: 80.47%] [G loss: 1.280617]\n",
      "epoch:27 step:25896 [D loss: 0.716596, acc.: 56.25%] [G loss: 1.405568]\n",
      "epoch:27 step:25897 [D loss: 0.994557, acc.: 48.44%] [G loss: 1.007151]\n",
      "epoch:27 step:25898 [D loss: 0.682567, acc.: 60.94%] [G loss: 1.260477]\n",
      "epoch:27 step:25899 [D loss: 0.383988, acc.: 86.72%] [G loss: 1.158615]\n",
      "epoch:27 step:25900 [D loss: 0.218910, acc.: 98.44%] [G loss: 1.454170]\n",
      "epoch:27 step:25901 [D loss: 0.695555, acc.: 61.72%] [G loss: 1.185863]\n",
      "epoch:27 step:25902 [D loss: 0.581164, acc.: 67.97%] [G loss: 1.309311]\n",
      "epoch:27 step:25903 [D loss: 0.280383, acc.: 89.06%] [G loss: 1.353416]\n",
      "epoch:27 step:25904 [D loss: 0.565044, acc.: 68.75%] [G loss: 1.421604]\n",
      "epoch:27 step:25905 [D loss: 0.505726, acc.: 75.78%] [G loss: 1.526392]\n",
      "epoch:27 step:25906 [D loss: 0.489798, acc.: 76.56%] [G loss: 1.240304]\n",
      "epoch:27 step:25907 [D loss: 0.616676, acc.: 66.41%] [G loss: 1.565401]\n",
      "epoch:27 step:25908 [D loss: 0.169225, acc.: 99.22%] [G loss: 1.330409]\n",
      "epoch:27 step:25909 [D loss: 0.641880, acc.: 63.28%] [G loss: 1.101026]\n",
      "epoch:27 step:25910 [D loss: 0.261673, acc.: 93.75%] [G loss: 0.926726]\n",
      "epoch:27 step:25911 [D loss: 0.333641, acc.: 86.72%] [G loss: 1.341607]\n",
      "epoch:27 step:25912 [D loss: 0.625025, acc.: 61.72%] [G loss: 1.127095]\n",
      "epoch:27 step:25913 [D loss: 0.789666, acc.: 46.88%] [G loss: 1.086295]\n",
      "epoch:27 step:25914 [D loss: 0.642537, acc.: 62.50%] [G loss: 0.948355]\n",
      "epoch:27 step:25915 [D loss: 0.418342, acc.: 85.94%] [G loss: 1.386876]\n",
      "epoch:27 step:25916 [D loss: 0.592464, acc.: 70.31%] [G loss: 1.041564]\n",
      "epoch:27 step:25917 [D loss: 0.655678, acc.: 61.72%] [G loss: 0.961326]\n",
      "epoch:27 step:25918 [D loss: 0.740429, acc.: 50.78%] [G loss: 0.914586]\n",
      "epoch:27 step:25919 [D loss: 0.605317, acc.: 67.97%] [G loss: 1.172341]\n",
      "epoch:27 step:25920 [D loss: 0.487839, acc.: 77.34%] [G loss: 1.013612]\n",
      "epoch:27 step:25921 [D loss: 0.533431, acc.: 77.34%] [G loss: 0.997784]\n",
      "epoch:27 step:25922 [D loss: 0.611575, acc.: 74.22%] [G loss: 1.210745]\n",
      "epoch:27 step:25923 [D loss: 0.572157, acc.: 67.19%] [G loss: 1.309813]\n",
      "epoch:27 step:25924 [D loss: 0.913935, acc.: 36.72%] [G loss: 1.500765]\n",
      "epoch:27 step:25925 [D loss: 0.641152, acc.: 63.28%] [G loss: 0.973833]\n",
      "epoch:27 step:25926 [D loss: 0.585050, acc.: 64.84%] [G loss: 1.302516]\n",
      "epoch:27 step:25927 [D loss: 0.656641, acc.: 62.50%] [G loss: 0.814587]\n",
      "epoch:27 step:25928 [D loss: 0.499648, acc.: 74.22%] [G loss: 0.941253]\n",
      "epoch:27 step:25929 [D loss: 0.461068, acc.: 83.59%] [G loss: 1.427534]\n",
      "epoch:27 step:25930 [D loss: 0.741421, acc.: 49.22%] [G loss: 0.952677]\n",
      "epoch:27 step:25931 [D loss: 0.357039, acc.: 84.38%] [G loss: 1.443566]\n",
      "epoch:27 step:25932 [D loss: 0.320850, acc.: 81.25%] [G loss: 1.711970]\n",
      "epoch:27 step:25933 [D loss: 0.220810, acc.: 95.31%] [G loss: 1.974292]\n",
      "epoch:27 step:25934 [D loss: 0.260975, acc.: 92.97%] [G loss: 1.871209]\n",
      "epoch:27 step:25935 [D loss: 0.596609, acc.: 65.62%] [G loss: 1.569581]\n",
      "epoch:27 step:25936 [D loss: 0.650176, acc.: 63.28%] [G loss: 1.559551]\n",
      "epoch:27 step:25937 [D loss: 0.627987, acc.: 67.19%] [G loss: 1.185322]\n",
      "epoch:27 step:25938 [D loss: 0.873906, acc.: 44.53%] [G loss: 0.707227]\n",
      "epoch:27 step:25939 [D loss: 0.572801, acc.: 71.88%] [G loss: 1.387361]\n",
      "epoch:27 step:25940 [D loss: 0.388658, acc.: 77.34%] [G loss: 1.722966]\n",
      "epoch:27 step:25941 [D loss: 0.844231, acc.: 46.09%] [G loss: 1.469851]\n",
      "epoch:27 step:25942 [D loss: 0.792753, acc.: 45.31%] [G loss: 1.553682]\n",
      "epoch:27 step:25943 [D loss: 0.234087, acc.: 92.97%] [G loss: 1.624522]\n",
      "epoch:27 step:25944 [D loss: 0.355203, acc.: 85.94%] [G loss: 1.718193]\n",
      "epoch:27 step:25945 [D loss: 0.143061, acc.: 99.22%] [G loss: 1.945239]\n",
      "epoch:27 step:25946 [D loss: 0.185639, acc.: 99.22%] [G loss: 1.523148]\n",
      "epoch:27 step:25947 [D loss: 0.214766, acc.: 97.66%] [G loss: 1.093424]\n",
      "epoch:27 step:25948 [D loss: 0.290927, acc.: 92.97%] [G loss: 1.359161]\n",
      "epoch:27 step:25949 [D loss: 0.137736, acc.: 100.00%] [G loss: 1.538986]\n",
      "epoch:27 step:25950 [D loss: 0.390081, acc.: 89.06%] [G loss: 1.823240]\n",
      "epoch:27 step:25951 [D loss: 0.815825, acc.: 54.69%] [G loss: 1.475274]\n",
      "epoch:27 step:25952 [D loss: 0.688795, acc.: 60.16%] [G loss: 1.467785]\n",
      "epoch:27 step:25953 [D loss: 1.064923, acc.: 23.44%] [G loss: 1.601968]\n",
      "epoch:27 step:25954 [D loss: 0.590630, acc.: 66.41%] [G loss: 0.837062]\n",
      "epoch:27 step:25955 [D loss: 0.572292, acc.: 69.53%] [G loss: 1.003050]\n",
      "epoch:27 step:25956 [D loss: 0.734533, acc.: 47.66%] [G loss: 0.714455]\n",
      "epoch:27 step:25957 [D loss: 0.839832, acc.: 42.97%] [G loss: 0.667886]\n",
      "epoch:27 step:25958 [D loss: 0.500259, acc.: 71.88%] [G loss: 1.793510]\n",
      "epoch:27 step:25959 [D loss: 0.328322, acc.: 94.53%] [G loss: 0.923849]\n",
      "epoch:27 step:25960 [D loss: 0.627413, acc.: 64.06%] [G loss: 0.664990]\n",
      "epoch:27 step:25961 [D loss: 0.656850, acc.: 60.16%] [G loss: 1.052846]\n",
      "epoch:27 step:25962 [D loss: 0.191874, acc.: 98.44%] [G loss: 0.666067]\n",
      "epoch:27 step:25963 [D loss: 0.335692, acc.: 84.38%] [G loss: 1.208203]\n",
      "epoch:27 step:25964 [D loss: 0.310677, acc.: 85.94%] [G loss: 1.696523]\n",
      "epoch:27 step:25965 [D loss: 0.982372, acc.: 35.94%] [G loss: 1.646881]\n",
      "epoch:27 step:25966 [D loss: 0.810501, acc.: 52.34%] [G loss: 1.247196]\n",
      "epoch:27 step:25967 [D loss: 0.810130, acc.: 52.34%] [G loss: 1.292066]\n",
      "epoch:27 step:25968 [D loss: 0.865826, acc.: 36.72%] [G loss: 2.167231]\n",
      "epoch:27 step:25969 [D loss: 0.668563, acc.: 59.38%] [G loss: 1.494622]\n",
      "epoch:27 step:25970 [D loss: 0.332562, acc.: 89.06%] [G loss: 1.778267]\n",
      "epoch:27 step:25971 [D loss: 0.434205, acc.: 77.34%] [G loss: 1.622458]\n",
      "epoch:27 step:25972 [D loss: 0.583823, acc.: 69.53%] [G loss: 1.516042]\n",
      "epoch:27 step:25973 [D loss: 1.371148, acc.: 64.06%] [G loss: 2.823122]\n",
      "epoch:27 step:25974 [D loss: 0.936443, acc.: 50.00%] [G loss: 1.669250]\n",
      "epoch:27 step:25975 [D loss: 0.700081, acc.: 56.25%] [G loss: 1.393196]\n",
      "epoch:27 step:25976 [D loss: 0.666880, acc.: 61.72%] [G loss: 1.245102]\n",
      "epoch:27 step:25977 [D loss: 0.620570, acc.: 62.50%] [G loss: 1.429457]\n",
      "epoch:27 step:25978 [D loss: 0.536958, acc.: 72.66%] [G loss: 0.973880]\n",
      "epoch:27 step:25979 [D loss: 0.652675, acc.: 61.72%] [G loss: 1.153570]\n",
      "epoch:27 step:25980 [D loss: 0.645980, acc.: 62.50%] [G loss: 1.165771]\n",
      "epoch:27 step:25981 [D loss: 0.455350, acc.: 75.78%] [G loss: 1.318191]\n",
      "epoch:27 step:25982 [D loss: 0.515968, acc.: 69.53%] [G loss: 1.040990]\n",
      "epoch:27 step:25983 [D loss: 0.337282, acc.: 86.72%] [G loss: 1.417882]\n",
      "epoch:27 step:25984 [D loss: 0.605149, acc.: 64.84%] [G loss: 1.182458]\n",
      "epoch:27 step:25985 [D loss: 0.324781, acc.: 92.19%] [G loss: 1.343915]\n",
      "epoch:27 step:25986 [D loss: 0.379455, acc.: 89.06%] [G loss: 0.974282]\n",
      "epoch:27 step:25987 [D loss: 0.725847, acc.: 54.69%] [G loss: 1.077752]\n",
      "epoch:27 step:25988 [D loss: 0.892352, acc.: 59.38%] [G loss: 1.030033]\n",
      "epoch:27 step:25989 [D loss: 0.751333, acc.: 58.59%] [G loss: 0.980987]\n",
      "epoch:27 step:25990 [D loss: 0.691132, acc.: 60.16%] [G loss: 1.195438]\n",
      "epoch:27 step:25991 [D loss: 0.751538, acc.: 53.91%] [G loss: 0.987051]\n",
      "epoch:27 step:25992 [D loss: 0.646430, acc.: 66.41%] [G loss: 1.437606]\n",
      "epoch:27 step:25993 [D loss: 0.529762, acc.: 75.00%] [G loss: 1.119284]\n",
      "epoch:27 step:25994 [D loss: 0.758939, acc.: 49.22%] [G loss: 0.966094]\n",
      "epoch:27 step:25995 [D loss: 0.284504, acc.: 89.06%] [G loss: 1.043476]\n",
      "epoch:27 step:25996 [D loss: 0.264096, acc.: 86.72%] [G loss: 1.188291]\n",
      "epoch:27 step:25997 [D loss: 0.213949, acc.: 96.09%] [G loss: 1.393363]\n",
      "epoch:27 step:25998 [D loss: 0.289513, acc.: 93.75%] [G loss: 1.131356]\n",
      "epoch:27 step:25999 [D loss: 0.374798, acc.: 91.41%] [G loss: 1.579806]\n",
      "epoch:27 step:26000 [D loss: 0.170765, acc.: 97.66%] [G loss: 1.540584]\n",
      "epoch:27 step:26001 [D loss: 0.184477, acc.: 97.66%] [G loss: 1.430978]\n",
      "epoch:27 step:26002 [D loss: 0.363858, acc.: 89.06%] [G loss: 1.666373]\n",
      "epoch:27 step:26003 [D loss: 0.574070, acc.: 70.31%] [G loss: 1.508133]\n",
      "epoch:27 step:26004 [D loss: 0.578046, acc.: 70.31%] [G loss: 1.341449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26005 [D loss: 0.173623, acc.: 96.88%] [G loss: 1.687426]\n",
      "epoch:27 step:26006 [D loss: 0.122834, acc.: 100.00%] [G loss: 1.693587]\n",
      "epoch:27 step:26007 [D loss: 0.128566, acc.: 97.66%] [G loss: 1.723855]\n",
      "epoch:27 step:26008 [D loss: 0.167224, acc.: 93.75%] [G loss: 1.994285]\n",
      "epoch:27 step:26009 [D loss: 0.948303, acc.: 55.47%] [G loss: 1.565701]\n",
      "epoch:27 step:26010 [D loss: 0.808411, acc.: 57.03%] [G loss: 1.137399]\n",
      "epoch:27 step:26011 [D loss: 0.474252, acc.: 82.81%] [G loss: 0.920035]\n",
      "epoch:27 step:26012 [D loss: 0.222816, acc.: 92.97%] [G loss: 1.344694]\n",
      "epoch:27 step:26013 [D loss: 0.183171, acc.: 94.53%] [G loss: 1.681201]\n",
      "epoch:27 step:26014 [D loss: 0.749044, acc.: 51.56%] [G loss: 1.485274]\n",
      "epoch:27 step:26015 [D loss: 0.805578, acc.: 50.00%] [G loss: 1.212245]\n",
      "epoch:27 step:26016 [D loss: 0.637764, acc.: 64.06%] [G loss: 1.060763]\n",
      "epoch:27 step:26017 [D loss: 0.587793, acc.: 66.41%] [G loss: 1.127391]\n",
      "epoch:27 step:26018 [D loss: 0.765013, acc.: 50.00%] [G loss: 1.047380]\n",
      "epoch:27 step:26019 [D loss: 0.664807, acc.: 63.28%] [G loss: 1.299631]\n",
      "epoch:27 step:26020 [D loss: 0.632207, acc.: 64.84%] [G loss: 1.016906]\n",
      "epoch:27 step:26021 [D loss: 0.272367, acc.: 89.84%] [G loss: 1.346063]\n",
      "epoch:27 step:26022 [D loss: 0.308970, acc.: 85.16%] [G loss: 1.197726]\n",
      "epoch:27 step:26023 [D loss: 0.737339, acc.: 57.03%] [G loss: 1.248801]\n",
      "epoch:27 step:26024 [D loss: 1.260269, acc.: 21.09%] [G loss: 1.439851]\n",
      "epoch:27 step:26025 [D loss: 0.598641, acc.: 64.06%] [G loss: 1.475266]\n",
      "epoch:27 step:26026 [D loss: 0.210788, acc.: 95.31%] [G loss: 1.404249]\n",
      "epoch:27 step:26027 [D loss: 0.234707, acc.: 92.19%] [G loss: 2.032590]\n",
      "epoch:27 step:26028 [D loss: 0.159485, acc.: 99.22%] [G loss: 1.685373]\n",
      "epoch:27 step:26029 [D loss: 0.227013, acc.: 95.31%] [G loss: 1.711534]\n",
      "epoch:27 step:26030 [D loss: 0.148645, acc.: 99.22%] [G loss: 1.761088]\n",
      "epoch:27 step:26031 [D loss: 0.150585, acc.: 98.44%] [G loss: 1.757562]\n",
      "epoch:27 step:26032 [D loss: 0.158193, acc.: 97.66%] [G loss: 1.939187]\n",
      "epoch:27 step:26033 [D loss: 0.998896, acc.: 49.22%] [G loss: 1.763050]\n",
      "epoch:27 step:26034 [D loss: 0.807126, acc.: 55.47%] [G loss: 1.472708]\n",
      "epoch:27 step:26035 [D loss: 0.708200, acc.: 55.47%] [G loss: 1.484305]\n",
      "epoch:27 step:26036 [D loss: 0.750142, acc.: 56.25%] [G loss: 1.102813]\n",
      "epoch:27 step:26037 [D loss: 0.605679, acc.: 64.84%] [G loss: 1.120143]\n",
      "epoch:27 step:26038 [D loss: 0.493009, acc.: 80.47%] [G loss: 1.299820]\n",
      "epoch:27 step:26039 [D loss: 0.433213, acc.: 89.06%] [G loss: 1.107699]\n",
      "epoch:27 step:26040 [D loss: 0.618976, acc.: 62.50%] [G loss: 1.409746]\n",
      "epoch:27 step:26041 [D loss: 0.485881, acc.: 78.91%] [G loss: 1.239624]\n",
      "epoch:27 step:26042 [D loss: 0.704238, acc.: 56.25%] [G loss: 1.045336]\n",
      "epoch:27 step:26043 [D loss: 0.566181, acc.: 69.53%] [G loss: 1.212825]\n",
      "epoch:27 step:26044 [D loss: 0.237712, acc.: 97.66%] [G loss: 1.271395]\n",
      "epoch:27 step:26045 [D loss: 0.323950, acc.: 89.84%] [G loss: 1.075163]\n",
      "epoch:27 step:26046 [D loss: 0.422761, acc.: 87.50%] [G loss: 1.148441]\n",
      "epoch:27 step:26047 [D loss: 0.766694, acc.: 50.78%] [G loss: 1.381814]\n",
      "epoch:27 step:26048 [D loss: 0.629484, acc.: 67.19%] [G loss: 1.159274]\n",
      "epoch:27 step:26049 [D loss: 0.538203, acc.: 75.00%] [G loss: 1.311240]\n",
      "epoch:27 step:26050 [D loss: 0.400924, acc.: 85.16%] [G loss: 0.949465]\n",
      "epoch:27 step:26051 [D loss: 0.404516, acc.: 85.94%] [G loss: 0.953122]\n",
      "epoch:27 step:26052 [D loss: 0.394356, acc.: 85.16%] [G loss: 0.768143]\n",
      "epoch:27 step:26053 [D loss: 0.253028, acc.: 90.62%] [G loss: 1.378952]\n",
      "epoch:27 step:26054 [D loss: 0.520737, acc.: 65.62%] [G loss: 1.341094]\n",
      "epoch:27 step:26055 [D loss: 0.173027, acc.: 96.09%] [G loss: 1.795529]\n",
      "epoch:27 step:26056 [D loss: 0.404581, acc.: 86.72%] [G loss: 1.864108]\n",
      "epoch:27 step:26057 [D loss: 0.649401, acc.: 63.28%] [G loss: 1.646885]\n",
      "epoch:27 step:26058 [D loss: 0.982547, acc.: 41.41%] [G loss: 1.427734]\n",
      "epoch:27 step:26059 [D loss: 0.669827, acc.: 57.81%] [G loss: 1.465595]\n",
      "epoch:27 step:26060 [D loss: 0.683616, acc.: 57.03%] [G loss: 1.303912]\n",
      "epoch:27 step:26061 [D loss: 0.517212, acc.: 79.69%] [G loss: 1.016484]\n",
      "epoch:27 step:26062 [D loss: 0.700331, acc.: 56.25%] [G loss: 0.493643]\n",
      "epoch:27 step:26063 [D loss: 0.191671, acc.: 98.44%] [G loss: 1.431244]\n",
      "epoch:27 step:26064 [D loss: 0.791371, acc.: 50.00%] [G loss: 1.460084]\n",
      "epoch:27 step:26065 [D loss: 0.653349, acc.: 63.28%] [G loss: 1.369622]\n",
      "epoch:27 step:26066 [D loss: 0.776339, acc.: 55.47%] [G loss: 1.269320]\n",
      "epoch:27 step:26067 [D loss: 0.382524, acc.: 89.06%] [G loss: 1.084447]\n",
      "epoch:27 step:26068 [D loss: 0.292765, acc.: 96.09%] [G loss: 1.283080]\n",
      "epoch:27 step:26069 [D loss: 0.621968, acc.: 60.16%] [G loss: 1.366739]\n",
      "epoch:27 step:26070 [D loss: 0.686775, acc.: 54.69%] [G loss: 1.094364]\n",
      "epoch:27 step:26071 [D loss: 0.827380, acc.: 42.19%] [G loss: 1.111866]\n",
      "epoch:27 step:26072 [D loss: 0.734297, acc.: 49.22%] [G loss: 0.749910]\n",
      "epoch:27 step:26073 [D loss: 0.246645, acc.: 93.75%] [G loss: 0.956529]\n",
      "epoch:27 step:26074 [D loss: 0.211145, acc.: 96.88%] [G loss: 1.360549]\n",
      "epoch:27 step:26075 [D loss: 0.642932, acc.: 62.50%] [G loss: 0.639448]\n",
      "epoch:27 step:26076 [D loss: 0.375606, acc.: 89.06%] [G loss: 0.911399]\n",
      "epoch:27 step:26077 [D loss: 1.116482, acc.: 27.34%] [G loss: 1.357250]\n",
      "epoch:27 step:26078 [D loss: 0.761251, acc.: 53.12%] [G loss: 0.839218]\n",
      "epoch:27 step:26079 [D loss: 0.317453, acc.: 87.50%] [G loss: 1.423561]\n",
      "epoch:27 step:26080 [D loss: 0.196949, acc.: 95.31%] [G loss: 1.443147]\n",
      "epoch:27 step:26081 [D loss: 0.238923, acc.: 92.97%] [G loss: 1.775164]\n",
      "epoch:27 step:26082 [D loss: 0.769151, acc.: 55.47%] [G loss: 1.466286]\n",
      "epoch:27 step:26083 [D loss: 0.789758, acc.: 55.47%] [G loss: 1.028863]\n",
      "epoch:27 step:26084 [D loss: 0.679524, acc.: 53.12%] [G loss: 1.228419]\n",
      "epoch:27 step:26085 [D loss: 0.479814, acc.: 75.00%] [G loss: 1.112613]\n",
      "epoch:27 step:26086 [D loss: 0.715092, acc.: 49.22%] [G loss: 1.196539]\n",
      "epoch:27 step:26087 [D loss: 0.649069, acc.: 60.16%] [G loss: 1.235055]\n",
      "epoch:27 step:26088 [D loss: 0.765377, acc.: 47.66%] [G loss: 0.821660]\n",
      "epoch:27 step:26089 [D loss: 0.790007, acc.: 46.88%] [G loss: 1.036425]\n",
      "epoch:27 step:26090 [D loss: 0.381718, acc.: 84.38%] [G loss: 1.050384]\n",
      "epoch:27 step:26091 [D loss: 0.316644, acc.: 91.41%] [G loss: 0.970142]\n",
      "epoch:27 step:26092 [D loss: 0.415166, acc.: 87.50%] [G loss: 1.322590]\n",
      "epoch:27 step:26093 [D loss: 0.220678, acc.: 94.53%] [G loss: 1.130780]\n",
      "epoch:27 step:26094 [D loss: 0.768068, acc.: 48.44%] [G loss: 0.249920]\n",
      "epoch:27 step:26095 [D loss: 0.757549, acc.: 57.81%] [G loss: 1.667765]\n",
      "epoch:27 step:26096 [D loss: 0.665327, acc.: 60.94%] [G loss: 1.423032]\n",
      "epoch:27 step:26097 [D loss: 0.678716, acc.: 57.03%] [G loss: 1.277394]\n",
      "epoch:27 step:26098 [D loss: 0.694329, acc.: 53.12%] [G loss: 1.111737]\n",
      "epoch:27 step:26099 [D loss: 0.264636, acc.: 94.53%] [G loss: 1.328307]\n",
      "epoch:27 step:26100 [D loss: 0.241742, acc.: 95.31%] [G loss: 1.482174]\n",
      "epoch:27 step:26101 [D loss: 0.218597, acc.: 95.31%] [G loss: 1.499061]\n",
      "epoch:27 step:26102 [D loss: 0.336547, acc.: 91.41%] [G loss: 1.843852]\n",
      "epoch:27 step:26103 [D loss: 0.255073, acc.: 97.66%] [G loss: 1.409299]\n",
      "epoch:27 step:26104 [D loss: 0.442476, acc.: 79.69%] [G loss: 1.298234]\n",
      "epoch:27 step:26105 [D loss: 0.223259, acc.: 93.75%] [G loss: 1.635056]\n",
      "epoch:27 step:26106 [D loss: 0.792633, acc.: 48.44%] [G loss: 1.536535]\n",
      "epoch:27 step:26107 [D loss: 0.304570, acc.: 86.72%] [G loss: 1.701800]\n",
      "epoch:27 step:26108 [D loss: 0.219987, acc.: 96.09%] [G loss: 1.763004]\n",
      "epoch:27 step:26109 [D loss: 0.323009, acc.: 94.53%] [G loss: 1.920671]\n",
      "epoch:27 step:26110 [D loss: 0.803021, acc.: 50.78%] [G loss: 1.916463]\n",
      "epoch:27 step:26111 [D loss: 0.761703, acc.: 48.44%] [G loss: 1.514393]\n",
      "epoch:27 step:26112 [D loss: 0.395439, acc.: 87.50%] [G loss: 1.433105]\n",
      "epoch:27 step:26113 [D loss: 0.430650, acc.: 82.81%] [G loss: 1.417371]\n",
      "epoch:27 step:26114 [D loss: 0.177044, acc.: 96.88%] [G loss: 1.641247]\n",
      "epoch:27 step:26115 [D loss: 0.160862, acc.: 99.22%] [G loss: 1.688213]\n",
      "epoch:27 step:26116 [D loss: 0.370730, acc.: 91.41%] [G loss: 1.598691]\n",
      "epoch:27 step:26117 [D loss: 0.301975, acc.: 94.53%] [G loss: 1.834526]\n",
      "epoch:27 step:26118 [D loss: 0.436234, acc.: 81.25%] [G loss: 1.727237]\n",
      "epoch:27 step:26119 [D loss: 0.772973, acc.: 53.91%] [G loss: 1.746617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26120 [D loss: 0.959929, acc.: 47.66%] [G loss: 0.940455]\n",
      "epoch:27 step:26121 [D loss: 0.741876, acc.: 50.78%] [G loss: 0.760211]\n",
      "epoch:27 step:26122 [D loss: 0.635658, acc.: 64.84%] [G loss: 0.495419]\n",
      "epoch:27 step:26123 [D loss: 0.277745, acc.: 92.97%] [G loss: 1.248483]\n",
      "epoch:27 step:26124 [D loss: 0.574058, acc.: 63.28%] [G loss: 1.329865]\n",
      "epoch:27 step:26125 [D loss: 0.561156, acc.: 69.53%] [G loss: 0.969744]\n",
      "epoch:27 step:26126 [D loss: 0.677837, acc.: 59.38%] [G loss: 0.871189]\n",
      "epoch:27 step:26127 [D loss: 0.806728, acc.: 44.53%] [G loss: 1.108247]\n",
      "epoch:27 step:26128 [D loss: 0.843071, acc.: 51.56%] [G loss: 0.603985]\n",
      "epoch:27 step:26129 [D loss: 0.728867, acc.: 50.78%] [G loss: 1.396677]\n",
      "epoch:27 step:26130 [D loss: 0.157733, acc.: 97.66%] [G loss: 1.564860]\n",
      "epoch:27 step:26131 [D loss: 0.214540, acc.: 96.09%] [G loss: 2.155569]\n",
      "epoch:27 step:26132 [D loss: 0.149606, acc.: 99.22%] [G loss: 1.507656]\n",
      "epoch:27 step:26133 [D loss: 1.007737, acc.: 45.31%] [G loss: 1.546791]\n",
      "epoch:27 step:26134 [D loss: 0.888480, acc.: 48.44%] [G loss: 1.741537]\n",
      "epoch:27 step:26135 [D loss: 0.767216, acc.: 50.00%] [G loss: 1.609383]\n",
      "epoch:27 step:26136 [D loss: 0.910062, acc.: 31.25%] [G loss: 1.257025]\n",
      "epoch:27 step:26137 [D loss: 0.755089, acc.: 49.22%] [G loss: 1.233029]\n",
      "epoch:27 step:26138 [D loss: 0.793791, acc.: 51.56%] [G loss: 0.761755]\n",
      "epoch:27 step:26139 [D loss: 0.670200, acc.: 57.81%] [G loss: 1.230705]\n",
      "epoch:27 step:26140 [D loss: 0.662059, acc.: 57.81%] [G loss: 1.048813]\n",
      "epoch:27 step:26141 [D loss: 0.322786, acc.: 92.97%] [G loss: 1.227217]\n",
      "epoch:27 step:26142 [D loss: 0.469912, acc.: 82.03%] [G loss: 1.301093]\n",
      "epoch:27 step:26143 [D loss: 0.440093, acc.: 82.81%] [G loss: 1.154775]\n",
      "epoch:27 step:26144 [D loss: 0.393429, acc.: 78.91%] [G loss: 0.977881]\n",
      "epoch:27 step:26145 [D loss: 0.793110, acc.: 41.41%] [G loss: 1.286613]\n",
      "epoch:27 step:26146 [D loss: 0.448409, acc.: 83.59%] [G loss: 1.515283]\n",
      "epoch:27 step:26147 [D loss: 0.647888, acc.: 59.38%] [G loss: 1.460708]\n",
      "epoch:27 step:26148 [D loss: 0.451231, acc.: 81.25%] [G loss: 1.186013]\n",
      "epoch:27 step:26149 [D loss: 0.493244, acc.: 82.03%] [G loss: 1.208511]\n",
      "epoch:27 step:26150 [D loss: 0.273761, acc.: 85.94%] [G loss: 1.327701]\n",
      "epoch:27 step:26151 [D loss: 0.203376, acc.: 96.09%] [G loss: 1.405338]\n",
      "epoch:27 step:26152 [D loss: 0.300498, acc.: 95.31%] [G loss: 1.526244]\n",
      "epoch:27 step:26153 [D loss: 0.164588, acc.: 96.88%] [G loss: 1.843318]\n",
      "epoch:27 step:26154 [D loss: 0.249781, acc.: 95.31%] [G loss: 1.573935]\n",
      "epoch:27 step:26155 [D loss: 0.738545, acc.: 57.81%] [G loss: 1.426013]\n",
      "epoch:27 step:26156 [D loss: 0.207346, acc.: 98.44%] [G loss: 1.395122]\n",
      "epoch:27 step:26157 [D loss: 0.497091, acc.: 79.69%] [G loss: 1.340787]\n",
      "epoch:27 step:26158 [D loss: 0.521056, acc.: 80.47%] [G loss: 1.150500]\n",
      "epoch:27 step:26159 [D loss: 0.460382, acc.: 81.25%] [G loss: 1.159104]\n",
      "epoch:27 step:26160 [D loss: 0.480786, acc.: 79.69%] [G loss: 1.022142]\n",
      "epoch:27 step:26161 [D loss: 0.738307, acc.: 52.34%] [G loss: 1.112292]\n",
      "epoch:27 step:26162 [D loss: 0.693118, acc.: 60.16%] [G loss: 0.803325]\n",
      "epoch:27 step:26163 [D loss: 0.783722, acc.: 46.09%] [G loss: 0.990400]\n",
      "epoch:27 step:26164 [D loss: 0.455622, acc.: 85.16%] [G loss: 0.877563]\n",
      "epoch:27 step:26165 [D loss: 0.498697, acc.: 75.78%] [G loss: 0.992316]\n",
      "epoch:27 step:26166 [D loss: 0.303111, acc.: 86.72%] [G loss: 1.320913]\n",
      "epoch:27 step:26167 [D loss: 0.598409, acc.: 67.19%] [G loss: 1.198248]\n",
      "epoch:27 step:26168 [D loss: 0.660931, acc.: 54.69%] [G loss: 1.284620]\n",
      "epoch:27 step:26169 [D loss: 0.771151, acc.: 42.97%] [G loss: 1.244411]\n",
      "epoch:27 step:26170 [D loss: 0.536331, acc.: 71.09%] [G loss: 1.197255]\n",
      "epoch:27 step:26171 [D loss: 0.403307, acc.: 90.62%] [G loss: 1.104718]\n",
      "epoch:27 step:26172 [D loss: 0.451393, acc.: 83.59%] [G loss: 1.232628]\n",
      "epoch:27 step:26173 [D loss: 0.821354, acc.: 62.50%] [G loss: 1.341447]\n",
      "epoch:27 step:26174 [D loss: 0.307284, acc.: 89.06%] [G loss: 1.407359]\n",
      "epoch:27 step:26175 [D loss: 0.753977, acc.: 60.16%] [G loss: 1.326155]\n",
      "epoch:27 step:26176 [D loss: 0.521287, acc.: 76.56%] [G loss: 1.214157]\n",
      "epoch:27 step:26177 [D loss: 0.731005, acc.: 59.38%] [G loss: 0.794558]\n",
      "epoch:27 step:26178 [D loss: 0.508930, acc.: 73.44%] [G loss: 1.043297]\n",
      "epoch:27 step:26179 [D loss: 0.345230, acc.: 88.28%] [G loss: 1.176418]\n",
      "epoch:27 step:26180 [D loss: 0.492626, acc.: 77.34%] [G loss: 0.909987]\n",
      "epoch:27 step:26181 [D loss: 0.165195, acc.: 97.66%] [G loss: 0.737569]\n",
      "epoch:27 step:26182 [D loss: 0.194986, acc.: 94.53%] [G loss: 1.460099]\n",
      "epoch:27 step:26183 [D loss: 0.122306, acc.: 98.44%] [G loss: 1.772510]\n",
      "epoch:27 step:26184 [D loss: 0.526333, acc.: 68.75%] [G loss: 2.383691]\n",
      "epoch:27 step:26185 [D loss: 0.110158, acc.: 98.44%] [G loss: 2.140497]\n",
      "epoch:27 step:26186 [D loss: 0.132237, acc.: 96.09%] [G loss: 2.917922]\n",
      "epoch:27 step:26187 [D loss: 0.736387, acc.: 59.38%] [G loss: 2.083603]\n",
      "epoch:27 step:26188 [D loss: 0.109973, acc.: 100.00%] [G loss: 2.272753]\n",
      "epoch:27 step:26189 [D loss: 0.351626, acc.: 91.41%] [G loss: 1.457757]\n",
      "epoch:27 step:26190 [D loss: 0.994270, acc.: 51.56%] [G loss: 1.776350]\n",
      "epoch:27 step:26191 [D loss: 1.035428, acc.: 50.00%] [G loss: 0.893420]\n",
      "epoch:27 step:26192 [D loss: 0.733767, acc.: 57.03%] [G loss: 0.868416]\n",
      "epoch:27 step:26193 [D loss: 0.755333, acc.: 53.12%] [G loss: 0.952921]\n",
      "epoch:27 step:26194 [D loss: 0.868174, acc.: 35.94%] [G loss: 0.522777]\n",
      "epoch:27 step:26195 [D loss: 0.839241, acc.: 34.38%] [G loss: 0.511523]\n",
      "epoch:27 step:26196 [D loss: 0.658097, acc.: 57.81%] [G loss: 0.944456]\n",
      "epoch:27 step:26197 [D loss: 0.756375, acc.: 50.00%] [G loss: 0.513360]\n",
      "epoch:27 step:26198 [D loss: 0.319714, acc.: 90.62%] [G loss: 1.069833]\n",
      "epoch:27 step:26199 [D loss: 0.308114, acc.: 92.19%] [G loss: 1.500642]\n",
      "epoch:27 step:26200 [D loss: 0.531678, acc.: 73.44%] [G loss: 0.754969]\n",
      "epoch:27 step:26201 [D loss: 0.631695, acc.: 64.06%] [G loss: 0.555732]\n",
      "epoch:27 step:26202 [D loss: 0.511945, acc.: 76.56%] [G loss: 0.869362]\n",
      "epoch:27 step:26203 [D loss: 0.357085, acc.: 90.62%] [G loss: 1.368961]\n",
      "epoch:27 step:26204 [D loss: 0.204575, acc.: 98.44%] [G loss: 1.123492]\n",
      "epoch:27 step:26205 [D loss: 0.214363, acc.: 93.75%] [G loss: 1.542543]\n",
      "epoch:27 step:26206 [D loss: 0.806488, acc.: 43.75%] [G loss: 1.473368]\n",
      "epoch:27 step:26207 [D loss: 0.856947, acc.: 41.41%] [G loss: 1.526635]\n",
      "epoch:27 step:26208 [D loss: 0.427309, acc.: 86.72%] [G loss: 1.176118]\n",
      "epoch:27 step:26209 [D loss: 0.467689, acc.: 82.81%] [G loss: 1.293805]\n",
      "epoch:27 step:26210 [D loss: 0.511175, acc.: 71.09%] [G loss: 1.364612]\n",
      "epoch:27 step:26211 [D loss: 0.142621, acc.: 96.88%] [G loss: 1.775330]\n",
      "epoch:27 step:26212 [D loss: 0.629430, acc.: 60.94%] [G loss: 1.669784]\n",
      "epoch:27 step:26213 [D loss: 0.989383, acc.: 35.16%] [G loss: 1.519686]\n",
      "epoch:27 step:26214 [D loss: 0.625334, acc.: 64.06%] [G loss: 1.552203]\n",
      "epoch:27 step:26215 [D loss: 0.667686, acc.: 60.94%] [G loss: 1.396247]\n",
      "epoch:27 step:26216 [D loss: 0.453811, acc.: 83.59%] [G loss: 1.338938]\n",
      "epoch:27 step:26217 [D loss: 0.456676, acc.: 85.94%] [G loss: 1.060417]\n",
      "epoch:27 step:26218 [D loss: 0.273593, acc.: 89.84%] [G loss: 1.234590]\n",
      "epoch:27 step:26219 [D loss: 0.565982, acc.: 71.09%] [G loss: 0.915974]\n",
      "epoch:27 step:26220 [D loss: 0.298482, acc.: 90.62%] [G loss: 0.932084]\n",
      "epoch:27 step:26221 [D loss: 0.422240, acc.: 87.50%] [G loss: 1.409114]\n",
      "epoch:27 step:26222 [D loss: 0.359081, acc.: 89.84%] [G loss: 1.510611]\n",
      "epoch:27 step:26223 [D loss: 0.188186, acc.: 94.53%] [G loss: 1.082451]\n",
      "epoch:27 step:26224 [D loss: 0.136780, acc.: 100.00%] [G loss: 1.730678]\n",
      "epoch:27 step:26225 [D loss: 0.088931, acc.: 100.00%] [G loss: 1.643399]\n",
      "epoch:27 step:26226 [D loss: 0.150395, acc.: 97.66%] [G loss: 1.831434]\n",
      "epoch:27 step:26227 [D loss: 0.815681, acc.: 57.03%] [G loss: 1.467223]\n",
      "epoch:27 step:26228 [D loss: 0.193121, acc.: 92.19%] [G loss: 1.973930]\n",
      "epoch:27 step:26229 [D loss: 0.584436, acc.: 70.31%] [G loss: 1.546084]\n",
      "epoch:27 step:26230 [D loss: 0.407280, acc.: 84.38%] [G loss: 1.114612]\n",
      "epoch:27 step:26231 [D loss: 0.211987, acc.: 96.09%] [G loss: 1.345301]\n",
      "epoch:27 step:26232 [D loss: 0.202160, acc.: 94.53%] [G loss: 1.459641]\n",
      "epoch:27 step:26233 [D loss: 0.083516, acc.: 100.00%] [G loss: 1.625664]\n",
      "epoch:27 step:26234 [D loss: 0.094692, acc.: 100.00%] [G loss: 2.012157]\n",
      "epoch:27 step:26235 [D loss: 0.100155, acc.: 99.22%] [G loss: 1.932180]\n",
      "epoch:27 step:26236 [D loss: 0.288524, acc.: 86.72%] [G loss: 2.159875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26237 [D loss: 0.226069, acc.: 94.53%] [G loss: 2.197584]\n",
      "epoch:28 step:26238 [D loss: 0.410749, acc.: 84.38%] [G loss: 1.898704]\n",
      "epoch:28 step:26239 [D loss: 0.213205, acc.: 96.88%] [G loss: 1.218664]\n",
      "epoch:28 step:26240 [D loss: 0.495889, acc.: 70.31%] [G loss: 1.780570]\n",
      "epoch:28 step:26241 [D loss: 0.580825, acc.: 67.97%] [G loss: 0.860023]\n",
      "epoch:28 step:26242 [D loss: 0.389464, acc.: 82.03%] [G loss: 1.695931]\n",
      "epoch:28 step:26243 [D loss: 0.305029, acc.: 87.50%] [G loss: 2.164203]\n",
      "epoch:28 step:26244 [D loss: 0.192393, acc.: 96.88%] [G loss: 1.532308]\n",
      "epoch:28 step:26245 [D loss: 0.152943, acc.: 97.66%] [G loss: 2.836629]\n",
      "epoch:28 step:26246 [D loss: 0.375920, acc.: 75.00%] [G loss: 1.312111]\n",
      "epoch:28 step:26247 [D loss: 0.208513, acc.: 94.53%] [G loss: 2.219173]\n",
      "epoch:28 step:26248 [D loss: 0.259404, acc.: 91.41%] [G loss: 1.691181]\n",
      "epoch:28 step:26249 [D loss: 0.282714, acc.: 90.62%] [G loss: 1.893693]\n",
      "epoch:28 step:26250 [D loss: 0.405181, acc.: 85.16%] [G loss: 1.825896]\n",
      "epoch:28 step:26251 [D loss: 0.136293, acc.: 98.44%] [G loss: 1.412666]\n",
      "epoch:28 step:26252 [D loss: 0.373615, acc.: 86.72%] [G loss: 0.401698]\n",
      "epoch:28 step:26253 [D loss: 1.518381, acc.: 23.44%] [G loss: 2.025694]\n",
      "epoch:28 step:26254 [D loss: 0.940517, acc.: 48.44%] [G loss: 2.756662]\n",
      "epoch:28 step:26255 [D loss: 1.281442, acc.: 42.19%] [G loss: 2.746498]\n",
      "epoch:28 step:26256 [D loss: 1.292544, acc.: 50.00%] [G loss: 2.227710]\n",
      "epoch:28 step:26257 [D loss: 0.982347, acc.: 49.22%] [G loss: 1.817789]\n",
      "epoch:28 step:26258 [D loss: 1.191261, acc.: 32.81%] [G loss: 1.415325]\n",
      "epoch:28 step:26259 [D loss: 0.718295, acc.: 58.59%] [G loss: 2.574380]\n",
      "epoch:28 step:26260 [D loss: 0.906364, acc.: 49.22%] [G loss: 1.011410]\n",
      "epoch:28 step:26261 [D loss: 0.898628, acc.: 41.41%] [G loss: 1.174101]\n",
      "epoch:28 step:26262 [D loss: 0.819674, acc.: 50.78%] [G loss: 1.396556]\n",
      "epoch:28 step:26263 [D loss: 0.567207, acc.: 72.66%] [G loss: 1.547048]\n",
      "epoch:28 step:26264 [D loss: 0.738584, acc.: 47.66%] [G loss: 1.226449]\n",
      "epoch:28 step:26265 [D loss: 0.603812, acc.: 64.84%] [G loss: 1.519970]\n",
      "epoch:28 step:26266 [D loss: 0.517024, acc.: 72.66%] [G loss: 1.835198]\n",
      "epoch:28 step:26267 [D loss: 0.516063, acc.: 65.62%] [G loss: 2.195294]\n",
      "epoch:28 step:26268 [D loss: 0.279572, acc.: 94.53%] [G loss: 1.991323]\n",
      "epoch:28 step:26269 [D loss: 0.204935, acc.: 96.09%] [G loss: 1.631238]\n",
      "epoch:28 step:26270 [D loss: 0.238631, acc.: 96.88%] [G loss: 1.657148]\n",
      "epoch:28 step:26271 [D loss: 0.139238, acc.: 100.00%] [G loss: 1.961136]\n",
      "epoch:28 step:26272 [D loss: 0.116242, acc.: 100.00%] [G loss: 2.278024]\n",
      "epoch:28 step:26273 [D loss: 0.646509, acc.: 64.06%] [G loss: 1.631507]\n",
      "epoch:28 step:26274 [D loss: 0.811997, acc.: 53.91%] [G loss: 1.284911]\n",
      "epoch:28 step:26275 [D loss: 0.694670, acc.: 60.94%] [G loss: 1.296726]\n",
      "epoch:28 step:26276 [D loss: 0.650828, acc.: 64.84%] [G loss: 1.040371]\n",
      "epoch:28 step:26277 [D loss: 0.389833, acc.: 89.84%] [G loss: 1.217186]\n",
      "epoch:28 step:26278 [D loss: 0.450357, acc.: 78.91%] [G loss: 1.319163]\n",
      "epoch:28 step:26279 [D loss: 0.324295, acc.: 94.53%] [G loss: 1.573816]\n",
      "epoch:28 step:26280 [D loss: 0.323776, acc.: 92.97%] [G loss: 1.719091]\n",
      "epoch:28 step:26281 [D loss: 0.470669, acc.: 82.03%] [G loss: 1.186650]\n",
      "epoch:28 step:26282 [D loss: 0.434516, acc.: 78.91%] [G loss: 1.214979]\n",
      "epoch:28 step:26283 [D loss: 0.530515, acc.: 72.66%] [G loss: 1.541436]\n",
      "epoch:28 step:26284 [D loss: 0.604855, acc.: 67.97%] [G loss: 1.090676]\n",
      "epoch:28 step:26285 [D loss: 0.662747, acc.: 59.38%] [G loss: 1.342245]\n",
      "epoch:28 step:26286 [D loss: 0.450121, acc.: 82.03%] [G loss: 1.034121]\n",
      "epoch:28 step:26287 [D loss: 0.441218, acc.: 82.81%] [G loss: 1.277361]\n",
      "epoch:28 step:26288 [D loss: 0.460838, acc.: 79.69%] [G loss: 1.237527]\n",
      "epoch:28 step:26289 [D loss: 0.396791, acc.: 90.62%] [G loss: 1.563128]\n",
      "epoch:28 step:26290 [D loss: 0.751959, acc.: 53.91%] [G loss: 1.130739]\n",
      "epoch:28 step:26291 [D loss: 0.579601, acc.: 68.75%] [G loss: 1.245680]\n",
      "epoch:28 step:26292 [D loss: 0.463872, acc.: 82.81%] [G loss: 1.239463]\n",
      "epoch:28 step:26293 [D loss: 0.234308, acc.: 91.41%] [G loss: 0.977821]\n",
      "epoch:28 step:26294 [D loss: 0.280794, acc.: 90.62%] [G loss: 1.083805]\n",
      "epoch:28 step:26295 [D loss: 0.232217, acc.: 92.97%] [G loss: 1.106703]\n",
      "epoch:28 step:26296 [D loss: 0.122361, acc.: 99.22%] [G loss: 1.385617]\n",
      "epoch:28 step:26297 [D loss: 0.502356, acc.: 78.12%] [G loss: 1.641507]\n",
      "epoch:28 step:26298 [D loss: 0.421504, acc.: 82.81%] [G loss: 1.377486]\n",
      "epoch:28 step:26299 [D loss: 0.267941, acc.: 87.50%] [G loss: 0.827016]\n",
      "epoch:28 step:26300 [D loss: 1.468102, acc.: 28.12%] [G loss: 0.492813]\n",
      "epoch:28 step:26301 [D loss: 1.519977, acc.: 13.28%] [G loss: 1.341293]\n",
      "epoch:28 step:26302 [D loss: 0.760629, acc.: 58.59%] [G loss: 1.865574]\n",
      "epoch:28 step:26303 [D loss: 0.637526, acc.: 65.62%] [G loss: 1.383157]\n",
      "epoch:28 step:26304 [D loss: 0.758252, acc.: 53.12%] [G loss: 1.481651]\n",
      "epoch:28 step:26305 [D loss: 0.993184, acc.: 33.59%] [G loss: 1.331108]\n",
      "epoch:28 step:26306 [D loss: 0.550977, acc.: 75.00%] [G loss: 1.342285]\n",
      "epoch:28 step:26307 [D loss: 0.270096, acc.: 89.84%] [G loss: 1.384272]\n",
      "epoch:28 step:26308 [D loss: 0.210083, acc.: 96.09%] [G loss: 1.910045]\n",
      "epoch:28 step:26309 [D loss: 0.409850, acc.: 85.16%] [G loss: 1.853308]\n",
      "epoch:28 step:26310 [D loss: 0.482600, acc.: 78.12%] [G loss: 1.416219]\n",
      "epoch:28 step:26311 [D loss: 0.154255, acc.: 100.00%] [G loss: 1.315237]\n",
      "epoch:28 step:26312 [D loss: 0.180630, acc.: 96.88%] [G loss: 1.012807]\n",
      "epoch:28 step:26313 [D loss: 0.421738, acc.: 85.16%] [G loss: 1.520121]\n",
      "epoch:28 step:26314 [D loss: 1.052495, acc.: 42.97%] [G loss: 1.201785]\n",
      "epoch:28 step:26315 [D loss: 0.830281, acc.: 46.09%] [G loss: 0.832361]\n",
      "epoch:28 step:26316 [D loss: 0.691386, acc.: 54.69%] [G loss: 0.077271]\n",
      "epoch:28 step:26317 [D loss: 0.722504, acc.: 48.44%] [G loss: 0.536910]\n",
      "epoch:28 step:26318 [D loss: 0.892706, acc.: 36.72%] [G loss: 1.181658]\n",
      "epoch:28 step:26319 [D loss: 0.716042, acc.: 53.12%] [G loss: 1.551133]\n",
      "epoch:28 step:26320 [D loss: 0.721040, acc.: 54.69%] [G loss: 1.369972]\n",
      "epoch:28 step:26321 [D loss: 0.582159, acc.: 73.44%] [G loss: 1.115126]\n",
      "epoch:28 step:26322 [D loss: 0.828842, acc.: 48.44%] [G loss: 1.088988]\n",
      "epoch:28 step:26323 [D loss: 0.615055, acc.: 70.31%] [G loss: 1.077117]\n",
      "epoch:28 step:26324 [D loss: 0.568813, acc.: 71.09%] [G loss: 0.990432]\n",
      "epoch:28 step:26325 [D loss: 0.567312, acc.: 69.53%] [G loss: 0.961429]\n",
      "epoch:28 step:26326 [D loss: 0.733923, acc.: 53.12%] [G loss: 1.029151]\n",
      "epoch:28 step:26327 [D loss: 0.662397, acc.: 60.16%] [G loss: 1.146719]\n",
      "epoch:28 step:26328 [D loss: 0.499746, acc.: 83.59%] [G loss: 0.943206]\n",
      "epoch:28 step:26329 [D loss: 0.480702, acc.: 75.78%] [G loss: 0.952660]\n",
      "epoch:28 step:26330 [D loss: 0.651301, acc.: 59.38%] [G loss: 1.120678]\n",
      "epoch:28 step:26331 [D loss: 0.673994, acc.: 60.16%] [G loss: 0.938226]\n",
      "epoch:28 step:26332 [D loss: 0.737131, acc.: 47.66%] [G loss: 0.974980]\n",
      "epoch:28 step:26333 [D loss: 0.725355, acc.: 53.12%] [G loss: 0.917584]\n",
      "epoch:28 step:26334 [D loss: 0.648352, acc.: 60.94%] [G loss: 0.940247]\n",
      "epoch:28 step:26335 [D loss: 0.669025, acc.: 51.56%] [G loss: 0.930152]\n",
      "epoch:28 step:26336 [D loss: 0.479833, acc.: 80.47%] [G loss: 1.119072]\n",
      "epoch:28 step:26337 [D loss: 0.637262, acc.: 62.50%] [G loss: 0.942116]\n",
      "epoch:28 step:26338 [D loss: 0.664725, acc.: 54.69%] [G loss: 1.091303]\n",
      "epoch:28 step:26339 [D loss: 0.715039, acc.: 54.69%] [G loss: 0.970546]\n",
      "epoch:28 step:26340 [D loss: 0.611946, acc.: 64.84%] [G loss: 1.035549]\n",
      "epoch:28 step:26341 [D loss: 0.502650, acc.: 71.09%] [G loss: 1.017806]\n",
      "epoch:28 step:26342 [D loss: 0.577931, acc.: 69.53%] [G loss: 0.519246]\n",
      "epoch:28 step:26343 [D loss: 0.983715, acc.: 42.19%] [G loss: 0.959062]\n",
      "epoch:28 step:26344 [D loss: 0.657141, acc.: 59.38%] [G loss: 0.946254]\n",
      "epoch:28 step:26345 [D loss: 0.712469, acc.: 53.12%] [G loss: 1.120383]\n",
      "epoch:28 step:26346 [D loss: 0.660167, acc.: 57.03%] [G loss: 1.047118]\n",
      "epoch:28 step:26347 [D loss: 0.539904, acc.: 75.00%] [G loss: 1.040072]\n",
      "epoch:28 step:26348 [D loss: 0.517851, acc.: 79.69%] [G loss: 1.125512]\n",
      "epoch:28 step:26349 [D loss: 0.467153, acc.: 83.59%] [G loss: 1.260719]\n",
      "epoch:28 step:26350 [D loss: 0.406168, acc.: 92.19%] [G loss: 1.061785]\n",
      "epoch:28 step:26351 [D loss: 0.444095, acc.: 87.50%] [G loss: 1.130367]\n",
      "epoch:28 step:26352 [D loss: 0.591946, acc.: 72.66%] [G loss: 1.112826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26353 [D loss: 0.405485, acc.: 85.16%] [G loss: 0.983407]\n",
      "epoch:28 step:26354 [D loss: 0.527718, acc.: 82.81%] [G loss: 1.179653]\n",
      "epoch:28 step:26355 [D loss: 0.248486, acc.: 92.97%] [G loss: 1.149472]\n",
      "epoch:28 step:26356 [D loss: 0.331746, acc.: 92.97%] [G loss: 1.292243]\n",
      "epoch:28 step:26357 [D loss: 0.255434, acc.: 95.31%] [G loss: 1.074583]\n",
      "epoch:28 step:26358 [D loss: 0.302012, acc.: 91.41%] [G loss: 1.369614]\n",
      "epoch:28 step:26359 [D loss: 0.504208, acc.: 75.00%] [G loss: 1.517465]\n",
      "epoch:28 step:26360 [D loss: 0.684784, acc.: 57.03%] [G loss: 1.387594]\n",
      "epoch:28 step:26361 [D loss: 0.718810, acc.: 51.56%] [G loss: 1.122652]\n",
      "epoch:28 step:26362 [D loss: 0.651920, acc.: 63.28%] [G loss: 1.057573]\n",
      "epoch:28 step:26363 [D loss: 0.745347, acc.: 50.78%] [G loss: 0.940332]\n",
      "epoch:28 step:26364 [D loss: 0.490992, acc.: 85.16%] [G loss: 1.126020]\n",
      "epoch:28 step:26365 [D loss: 0.358694, acc.: 84.38%] [G loss: 1.298365]\n",
      "epoch:28 step:26366 [D loss: 0.326861, acc.: 82.03%] [G loss: 1.358236]\n",
      "epoch:28 step:26367 [D loss: 0.276833, acc.: 92.97%] [G loss: 1.352473]\n",
      "epoch:28 step:26368 [D loss: 0.311629, acc.: 92.19%] [G loss: 1.683704]\n",
      "epoch:28 step:26369 [D loss: 0.740923, acc.: 55.47%] [G loss: 1.287998]\n",
      "epoch:28 step:26370 [D loss: 0.691925, acc.: 64.06%] [G loss: 1.136121]\n",
      "epoch:28 step:26371 [D loss: 0.398512, acc.: 85.16%] [G loss: 1.250662]\n",
      "epoch:28 step:26372 [D loss: 0.552601, acc.: 72.66%] [G loss: 1.179394]\n",
      "epoch:28 step:26373 [D loss: 0.442485, acc.: 83.59%] [G loss: 0.939360]\n",
      "epoch:28 step:26374 [D loss: 0.526333, acc.: 76.56%] [G loss: 0.843862]\n",
      "epoch:28 step:26375 [D loss: 0.460516, acc.: 78.91%] [G loss: 1.127150]\n",
      "epoch:28 step:26376 [D loss: 0.838260, acc.: 36.72%] [G loss: 1.587241]\n",
      "epoch:28 step:26377 [D loss: 0.757828, acc.: 57.81%] [G loss: 1.219257]\n",
      "epoch:28 step:26378 [D loss: 0.844099, acc.: 42.97%] [G loss: 1.152234]\n",
      "epoch:28 step:26379 [D loss: 0.571573, acc.: 68.75%] [G loss: 1.378578]\n",
      "epoch:28 step:26380 [D loss: 0.406687, acc.: 85.16%] [G loss: 1.367177]\n",
      "epoch:28 step:26381 [D loss: 0.311419, acc.: 89.84%] [G loss: 1.322490]\n",
      "epoch:28 step:26382 [D loss: 0.496480, acc.: 80.47%] [G loss: 1.462033]\n",
      "epoch:28 step:26383 [D loss: 0.669932, acc.: 60.94%] [G loss: 1.481086]\n",
      "epoch:28 step:26384 [D loss: 0.737615, acc.: 57.81%] [G loss: 1.158151]\n",
      "epoch:28 step:26385 [D loss: 0.545834, acc.: 72.66%] [G loss: 1.153522]\n",
      "epoch:28 step:26386 [D loss: 0.237943, acc.: 91.41%] [G loss: 1.224055]\n",
      "epoch:28 step:26387 [D loss: 0.213007, acc.: 95.31%] [G loss: 1.350166]\n",
      "epoch:28 step:26388 [D loss: 0.193484, acc.: 97.66%] [G loss: 1.671062]\n",
      "epoch:28 step:26389 [D loss: 0.724051, acc.: 54.69%] [G loss: 1.423679]\n",
      "epoch:28 step:26390 [D loss: 0.565560, acc.: 67.97%] [G loss: 1.314376]\n",
      "epoch:28 step:26391 [D loss: 0.609949, acc.: 67.97%] [G loss: 1.244351]\n",
      "epoch:28 step:26392 [D loss: 0.505552, acc.: 78.91%] [G loss: 1.305960]\n",
      "epoch:28 step:26393 [D loss: 0.739666, acc.: 49.22%] [G loss: 2.181960]\n",
      "epoch:28 step:26394 [D loss: 0.623581, acc.: 60.94%] [G loss: 1.175201]\n",
      "epoch:28 step:26395 [D loss: 0.562947, acc.: 68.75%] [G loss: 1.328955]\n",
      "epoch:28 step:26396 [D loss: 0.512478, acc.: 76.56%] [G loss: 1.219041]\n",
      "epoch:28 step:26397 [D loss: 0.612715, acc.: 64.84%] [G loss: 1.203222]\n",
      "epoch:28 step:26398 [D loss: 0.565705, acc.: 72.66%] [G loss: 1.177752]\n",
      "epoch:28 step:26399 [D loss: 0.735530, acc.: 57.81%] [G loss: 1.314005]\n",
      "epoch:28 step:26400 [D loss: 0.703479, acc.: 56.25%] [G loss: 1.187865]\n",
      "epoch:28 step:26401 [D loss: 0.684086, acc.: 57.81%] [G loss: 1.165006]\n",
      "epoch:28 step:26402 [D loss: 0.621770, acc.: 68.75%] [G loss: 1.235554]\n",
      "epoch:28 step:26403 [D loss: 0.550888, acc.: 71.09%] [G loss: 1.152628]\n",
      "epoch:28 step:26404 [D loss: 0.396036, acc.: 81.25%] [G loss: 1.062789]\n",
      "epoch:28 step:26405 [D loss: 0.519343, acc.: 74.22%] [G loss: 1.342368]\n",
      "epoch:28 step:26406 [D loss: 0.713483, acc.: 56.25%] [G loss: 1.180104]\n",
      "epoch:28 step:26407 [D loss: 0.570948, acc.: 67.97%] [G loss: 1.248998]\n",
      "epoch:28 step:26408 [D loss: 0.580576, acc.: 75.00%] [G loss: 1.245947]\n",
      "epoch:28 step:26409 [D loss: 0.673798, acc.: 57.81%] [G loss: 1.019262]\n",
      "epoch:28 step:26410 [D loss: 0.646638, acc.: 57.03%] [G loss: 1.309180]\n",
      "epoch:28 step:26411 [D loss: 0.653138, acc.: 64.84%] [G loss: 1.066520]\n",
      "epoch:28 step:26412 [D loss: 0.501723, acc.: 78.12%] [G loss: 0.949537]\n",
      "epoch:28 step:26413 [D loss: 0.647409, acc.: 60.16%] [G loss: 1.032926]\n",
      "epoch:28 step:26414 [D loss: 0.629917, acc.: 63.28%] [G loss: 1.230519]\n",
      "epoch:28 step:26415 [D loss: 0.590834, acc.: 70.31%] [G loss: 0.939087]\n",
      "epoch:28 step:26416 [D loss: 0.653358, acc.: 67.19%] [G loss: 0.991303]\n",
      "epoch:28 step:26417 [D loss: 0.558091, acc.: 72.66%] [G loss: 1.069056]\n",
      "epoch:28 step:26418 [D loss: 0.691186, acc.: 61.72%] [G loss: 0.944816]\n",
      "epoch:28 step:26419 [D loss: 0.704848, acc.: 52.34%] [G loss: 0.840205]\n",
      "epoch:28 step:26420 [D loss: 0.496273, acc.: 75.00%] [G loss: 1.131771]\n",
      "epoch:28 step:26421 [D loss: 0.492048, acc.: 75.78%] [G loss: 1.310532]\n",
      "epoch:28 step:26422 [D loss: 0.682798, acc.: 57.81%] [G loss: 1.128644]\n",
      "epoch:28 step:26423 [D loss: 0.690199, acc.: 57.81%] [G loss: 0.908318]\n",
      "epoch:28 step:26424 [D loss: 0.659598, acc.: 61.72%] [G loss: 0.791927]\n",
      "epoch:28 step:26425 [D loss: 0.822930, acc.: 52.34%] [G loss: 0.720859]\n",
      "epoch:28 step:26426 [D loss: 0.609666, acc.: 69.53%] [G loss: 1.031931]\n",
      "epoch:28 step:26427 [D loss: 0.611271, acc.: 66.41%] [G loss: 1.120166]\n",
      "epoch:28 step:26428 [D loss: 0.358546, acc.: 85.94%] [G loss: 1.021389]\n",
      "epoch:28 step:26429 [D loss: 0.432444, acc.: 82.03%] [G loss: 1.140734]\n",
      "epoch:28 step:26430 [D loss: 0.388397, acc.: 92.97%] [G loss: 0.978992]\n",
      "epoch:28 step:26431 [D loss: 0.674471, acc.: 60.16%] [G loss: 1.397111]\n",
      "epoch:28 step:26432 [D loss: 0.699262, acc.: 54.69%] [G loss: 0.917461]\n",
      "epoch:28 step:26433 [D loss: 0.480293, acc.: 75.00%] [G loss: 1.175148]\n",
      "epoch:28 step:26434 [D loss: 0.582723, acc.: 68.75%] [G loss: 1.344505]\n",
      "epoch:28 step:26435 [D loss: 1.080657, acc.: 31.25%] [G loss: 1.461066]\n",
      "epoch:28 step:26436 [D loss: 0.267588, acc.: 96.88%] [G loss: 1.470542]\n",
      "epoch:28 step:26437 [D loss: 0.170896, acc.: 93.75%] [G loss: 1.702634]\n",
      "epoch:28 step:26438 [D loss: 0.752056, acc.: 51.56%] [G loss: 1.341917]\n",
      "epoch:28 step:26439 [D loss: 0.613543, acc.: 71.88%] [G loss: 1.227219]\n",
      "epoch:28 step:26440 [D loss: 0.459537, acc.: 80.47%] [G loss: 1.220130]\n",
      "epoch:28 step:26441 [D loss: 0.600798, acc.: 68.75%] [G loss: 0.938238]\n",
      "epoch:28 step:26442 [D loss: 0.343222, acc.: 94.53%] [G loss: 1.104596]\n",
      "epoch:28 step:26443 [D loss: 0.482955, acc.: 68.75%] [G loss: 0.875041]\n",
      "epoch:28 step:26444 [D loss: 0.442705, acc.: 84.38%] [G loss: 1.287042]\n",
      "epoch:28 step:26445 [D loss: 0.368565, acc.: 85.94%] [G loss: 1.490698]\n",
      "epoch:28 step:26446 [D loss: 0.855131, acc.: 48.44%] [G loss: 1.311617]\n",
      "epoch:28 step:26447 [D loss: 0.900173, acc.: 41.41%] [G loss: 1.330597]\n",
      "epoch:28 step:26448 [D loss: 0.726523, acc.: 57.03%] [G loss: 1.041635]\n",
      "epoch:28 step:26449 [D loss: 0.590987, acc.: 69.53%] [G loss: 1.486606]\n",
      "epoch:28 step:26450 [D loss: 0.834261, acc.: 47.66%] [G loss: 1.268746]\n",
      "epoch:28 step:26451 [D loss: 0.619505, acc.: 62.50%] [G loss: 1.247653]\n",
      "epoch:28 step:26452 [D loss: 0.525853, acc.: 72.66%] [G loss: 1.311444]\n",
      "epoch:28 step:26453 [D loss: 0.636416, acc.: 66.41%] [G loss: 1.107703]\n",
      "epoch:28 step:26454 [D loss: 0.452452, acc.: 78.12%] [G loss: 1.090366]\n",
      "epoch:28 step:26455 [D loss: 0.413043, acc.: 87.50%] [G loss: 1.084305]\n",
      "epoch:28 step:26456 [D loss: 0.317663, acc.: 85.94%] [G loss: 1.310637]\n",
      "epoch:28 step:26457 [D loss: 0.216572, acc.: 93.75%] [G loss: 1.767462]\n",
      "epoch:28 step:26458 [D loss: 0.151220, acc.: 97.66%] [G loss: 1.534130]\n",
      "epoch:28 step:26459 [D loss: 0.152298, acc.: 98.44%] [G loss: 1.688193]\n",
      "epoch:28 step:26460 [D loss: 0.776156, acc.: 53.12%] [G loss: 1.533242]\n",
      "epoch:28 step:26461 [D loss: 0.714257, acc.: 60.16%] [G loss: 1.537461]\n",
      "epoch:28 step:26462 [D loss: 0.434961, acc.: 82.03%] [G loss: 1.556874]\n",
      "epoch:28 step:26463 [D loss: 0.384286, acc.: 87.50%] [G loss: 1.324159]\n",
      "epoch:28 step:26464 [D loss: 0.327124, acc.: 89.84%] [G loss: 1.616249]\n",
      "epoch:28 step:26465 [D loss: 0.464561, acc.: 81.25%] [G loss: 1.633224]\n",
      "epoch:28 step:26466 [D loss: 0.159556, acc.: 95.31%] [G loss: 1.738922]\n",
      "epoch:28 step:26467 [D loss: 0.180653, acc.: 100.00%] [G loss: 1.303968]\n",
      "epoch:28 step:26468 [D loss: 0.146203, acc.: 100.00%] [G loss: 1.649685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26469 [D loss: 0.551852, acc.: 73.44%] [G loss: 1.492477]\n",
      "epoch:28 step:26470 [D loss: 0.295060, acc.: 96.09%] [G loss: 1.829347]\n",
      "epoch:28 step:26471 [D loss: 0.185125, acc.: 96.09%] [G loss: 1.608187]\n",
      "epoch:28 step:26472 [D loss: 0.417068, acc.: 85.94%] [G loss: 1.682277]\n",
      "epoch:28 step:26473 [D loss: 0.532869, acc.: 76.56%] [G loss: 1.339554]\n",
      "epoch:28 step:26474 [D loss: 0.233483, acc.: 92.19%] [G loss: 1.531684]\n",
      "epoch:28 step:26475 [D loss: 0.425152, acc.: 83.59%] [G loss: 1.715931]\n",
      "epoch:28 step:26476 [D loss: 0.392093, acc.: 84.38%] [G loss: 1.597576]\n",
      "epoch:28 step:26477 [D loss: 1.174290, acc.: 28.12%] [G loss: 1.382144]\n",
      "epoch:28 step:26478 [D loss: 0.684115, acc.: 59.38%] [G loss: 1.301335]\n",
      "epoch:28 step:26479 [D loss: 0.347425, acc.: 84.38%] [G loss: 1.447886]\n",
      "epoch:28 step:26480 [D loss: 0.957301, acc.: 32.03%] [G loss: 1.634915]\n",
      "epoch:28 step:26481 [D loss: 0.922693, acc.: 48.44%] [G loss: 0.987125]\n",
      "epoch:28 step:26482 [D loss: 0.842871, acc.: 47.66%] [G loss: 1.435157]\n",
      "epoch:28 step:26483 [D loss: 0.720192, acc.: 53.12%] [G loss: 1.338283]\n",
      "epoch:28 step:26484 [D loss: 0.568826, acc.: 70.31%] [G loss: 1.300043]\n",
      "epoch:28 step:26485 [D loss: 0.647014, acc.: 61.72%] [G loss: 1.432271]\n",
      "epoch:28 step:26486 [D loss: 0.707550, acc.: 60.16%] [G loss: 1.009216]\n",
      "epoch:28 step:26487 [D loss: 0.643956, acc.: 60.94%] [G loss: 0.941126]\n",
      "epoch:28 step:26488 [D loss: 0.625324, acc.: 62.50%] [G loss: 1.097615]\n",
      "epoch:28 step:26489 [D loss: 0.656563, acc.: 62.50%] [G loss: 0.840609]\n",
      "epoch:28 step:26490 [D loss: 0.568376, acc.: 65.62%] [G loss: 1.172752]\n",
      "epoch:28 step:26491 [D loss: 0.384319, acc.: 78.12%] [G loss: 0.994032]\n",
      "epoch:28 step:26492 [D loss: 0.232212, acc.: 91.41%] [G loss: 0.803269]\n",
      "epoch:28 step:26493 [D loss: 0.292611, acc.: 86.72%] [G loss: 1.787675]\n",
      "epoch:28 step:26494 [D loss: 0.454033, acc.: 79.69%] [G loss: 1.492761]\n",
      "epoch:28 step:26495 [D loss: 0.288438, acc.: 83.59%] [G loss: 1.432451]\n",
      "epoch:28 step:26496 [D loss: 0.238016, acc.: 95.31%] [G loss: 1.749374]\n",
      "epoch:28 step:26497 [D loss: 0.548855, acc.: 66.41%] [G loss: 2.543006]\n",
      "epoch:28 step:26498 [D loss: 0.732775, acc.: 56.25%] [G loss: 2.043950]\n",
      "epoch:28 step:26499 [D loss: 0.309229, acc.: 85.94%] [G loss: 1.514934]\n",
      "epoch:28 step:26500 [D loss: 0.539075, acc.: 72.66%] [G loss: 1.128541]\n",
      "epoch:28 step:26501 [D loss: 0.834131, acc.: 51.56%] [G loss: 1.091255]\n",
      "epoch:28 step:26502 [D loss: 0.907197, acc.: 40.62%] [G loss: 1.480236]\n",
      "epoch:28 step:26503 [D loss: 0.648344, acc.: 57.81%] [G loss: 1.741757]\n",
      "epoch:28 step:26504 [D loss: 0.664672, acc.: 60.16%] [G loss: 1.529998]\n",
      "epoch:28 step:26505 [D loss: 0.413273, acc.: 79.69%] [G loss: 1.245051]\n",
      "epoch:28 step:26506 [D loss: 0.703777, acc.: 58.59%] [G loss: 1.007607]\n",
      "epoch:28 step:26507 [D loss: 0.449515, acc.: 82.81%] [G loss: 0.982337]\n",
      "epoch:28 step:26508 [D loss: 0.500627, acc.: 81.25%] [G loss: 0.709709]\n",
      "epoch:28 step:26509 [D loss: 0.471245, acc.: 75.00%] [G loss: 1.678037]\n",
      "epoch:28 step:26510 [D loss: 0.341093, acc.: 93.75%] [G loss: 1.247813]\n",
      "epoch:28 step:26511 [D loss: 0.281577, acc.: 93.75%] [G loss: 1.866236]\n",
      "epoch:28 step:26512 [D loss: 0.260646, acc.: 92.97%] [G loss: 1.369269]\n",
      "epoch:28 step:26513 [D loss: 0.395866, acc.: 78.12%] [G loss: 1.879295]\n",
      "epoch:28 step:26514 [D loss: 0.781291, acc.: 60.16%] [G loss: 1.081410]\n",
      "epoch:28 step:26515 [D loss: 0.719493, acc.: 62.50%] [G loss: 1.378508]\n",
      "epoch:28 step:26516 [D loss: 0.763978, acc.: 53.12%] [G loss: 1.698575]\n",
      "epoch:28 step:26517 [D loss: 0.540390, acc.: 75.78%] [G loss: 1.828737]\n",
      "epoch:28 step:26518 [D loss: 0.233756, acc.: 96.09%] [G loss: 1.745827]\n",
      "epoch:28 step:26519 [D loss: 0.598560, acc.: 65.62%] [G loss: 1.500047]\n",
      "epoch:28 step:26520 [D loss: 1.096112, acc.: 38.28%] [G loss: 1.347875]\n",
      "epoch:28 step:26521 [D loss: 0.858872, acc.: 44.53%] [G loss: 0.881683]\n",
      "epoch:28 step:26522 [D loss: 0.702449, acc.: 60.16%] [G loss: 1.135468]\n",
      "epoch:28 step:26523 [D loss: 0.776435, acc.: 50.78%] [G loss: 1.178459]\n",
      "epoch:28 step:26524 [D loss: 0.819137, acc.: 47.66%] [G loss: 1.082881]\n",
      "epoch:28 step:26525 [D loss: 0.650639, acc.: 57.81%] [G loss: 0.929288]\n",
      "epoch:28 step:26526 [D loss: 0.575937, acc.: 70.31%] [G loss: 1.259581]\n",
      "epoch:28 step:26527 [D loss: 0.792302, acc.: 45.31%] [G loss: 1.160078]\n",
      "epoch:28 step:26528 [D loss: 0.567659, acc.: 70.31%] [G loss: 1.029762]\n",
      "epoch:28 step:26529 [D loss: 0.712796, acc.: 57.81%] [G loss: 1.089706]\n",
      "epoch:28 step:26530 [D loss: 0.534992, acc.: 75.78%] [G loss: 1.172413]\n",
      "epoch:28 step:26531 [D loss: 0.410272, acc.: 78.91%] [G loss: 1.361269]\n",
      "epoch:28 step:26532 [D loss: 0.391630, acc.: 88.28%] [G loss: 1.245883]\n",
      "epoch:28 step:26533 [D loss: 0.215814, acc.: 94.53%] [G loss: 1.472319]\n",
      "epoch:28 step:26534 [D loss: 0.210820, acc.: 95.31%] [G loss: 1.663580]\n",
      "epoch:28 step:26535 [D loss: 0.141110, acc.: 100.00%] [G loss: 1.649336]\n",
      "epoch:28 step:26536 [D loss: 0.291418, acc.: 92.97%] [G loss: 1.607079]\n",
      "epoch:28 step:26537 [D loss: 0.511657, acc.: 75.00%] [G loss: 1.273725]\n",
      "epoch:28 step:26538 [D loss: 0.510483, acc.: 71.09%] [G loss: 1.049889]\n",
      "epoch:28 step:26539 [D loss: 0.456736, acc.: 82.03%] [G loss: 1.627817]\n",
      "epoch:28 step:26540 [D loss: 0.932555, acc.: 44.53%] [G loss: 0.855643]\n",
      "epoch:28 step:26541 [D loss: 0.807918, acc.: 51.56%] [G loss: 0.936219]\n",
      "epoch:28 step:26542 [D loss: 0.604077, acc.: 67.97%] [G loss: 1.490977]\n",
      "epoch:28 step:26543 [D loss: 0.383440, acc.: 89.06%] [G loss: 1.680381]\n",
      "epoch:28 step:26544 [D loss: 0.841185, acc.: 50.78%] [G loss: 1.156807]\n",
      "epoch:28 step:26545 [D loss: 0.917008, acc.: 44.53%] [G loss: 0.795598]\n",
      "epoch:28 step:26546 [D loss: 0.664455, acc.: 57.81%] [G loss: 0.797265]\n",
      "epoch:28 step:26547 [D loss: 0.680972, acc.: 60.94%] [G loss: 0.991476]\n",
      "epoch:28 step:26548 [D loss: 0.887156, acc.: 44.53%] [G loss: 1.083592]\n",
      "epoch:28 step:26549 [D loss: 0.738876, acc.: 53.91%] [G loss: 1.051401]\n",
      "epoch:28 step:26550 [D loss: 0.521882, acc.: 70.31%] [G loss: 1.040981]\n",
      "epoch:28 step:26551 [D loss: 0.662513, acc.: 59.38%] [G loss: 1.225628]\n",
      "epoch:28 step:26552 [D loss: 0.544364, acc.: 70.31%] [G loss: 1.249756]\n",
      "epoch:28 step:26553 [D loss: 0.566012, acc.: 65.62%] [G loss: 1.088661]\n",
      "epoch:28 step:26554 [D loss: 0.581664, acc.: 67.19%] [G loss: 0.928704]\n",
      "epoch:28 step:26555 [D loss: 0.564943, acc.: 71.88%] [G loss: 1.159259]\n",
      "epoch:28 step:26556 [D loss: 0.453625, acc.: 83.59%] [G loss: 1.204029]\n",
      "epoch:28 step:26557 [D loss: 0.390825, acc.: 82.03%] [G loss: 1.188399]\n",
      "epoch:28 step:26558 [D loss: 0.429031, acc.: 86.72%] [G loss: 1.190659]\n",
      "epoch:28 step:26559 [D loss: 0.586660, acc.: 64.84%] [G loss: 1.060543]\n",
      "epoch:28 step:26560 [D loss: 0.717374, acc.: 54.69%] [G loss: 0.941405]\n",
      "epoch:28 step:26561 [D loss: 0.595564, acc.: 68.75%] [G loss: 1.040925]\n",
      "epoch:28 step:26562 [D loss: 0.540851, acc.: 72.66%] [G loss: 1.203667]\n",
      "epoch:28 step:26563 [D loss: 0.318070, acc.: 85.94%] [G loss: 1.152840]\n",
      "epoch:28 step:26564 [D loss: 0.246034, acc.: 96.09%] [G loss: 1.289445]\n",
      "epoch:28 step:26565 [D loss: 0.470868, acc.: 79.69%] [G loss: 1.026497]\n",
      "epoch:28 step:26566 [D loss: 0.899022, acc.: 42.97%] [G loss: 0.972420]\n",
      "epoch:28 step:26567 [D loss: 0.582693, acc.: 72.66%] [G loss: 0.942902]\n",
      "epoch:28 step:26568 [D loss: 0.689844, acc.: 52.34%] [G loss: 0.766508]\n",
      "epoch:28 step:26569 [D loss: 0.582960, acc.: 69.53%] [G loss: 1.103029]\n",
      "epoch:28 step:26570 [D loss: 0.711835, acc.: 50.78%] [G loss: 0.771315]\n",
      "epoch:28 step:26571 [D loss: 0.491838, acc.: 79.69%] [G loss: 1.168249]\n",
      "epoch:28 step:26572 [D loss: 0.498003, acc.: 78.91%] [G loss: 1.256034]\n",
      "epoch:28 step:26573 [D loss: 0.538437, acc.: 74.22%] [G loss: 1.178523]\n",
      "epoch:28 step:26574 [D loss: 0.497920, acc.: 78.91%] [G loss: 1.184138]\n",
      "epoch:28 step:26575 [D loss: 0.664865, acc.: 61.72%] [G loss: 1.196322]\n",
      "epoch:28 step:26576 [D loss: 0.624555, acc.: 63.28%] [G loss: 0.936219]\n",
      "epoch:28 step:26577 [D loss: 0.683660, acc.: 59.38%] [G loss: 1.203048]\n",
      "epoch:28 step:26578 [D loss: 0.441023, acc.: 76.56%] [G loss: 1.067027]\n",
      "epoch:28 step:26579 [D loss: 0.302796, acc.: 83.59%] [G loss: 1.338017]\n",
      "epoch:28 step:26580 [D loss: 0.306134, acc.: 89.06%] [G loss: 1.590767]\n",
      "epoch:28 step:26581 [D loss: 0.237164, acc.: 94.53%] [G loss: 1.520542]\n",
      "epoch:28 step:26582 [D loss: 0.237994, acc.: 90.62%] [G loss: 1.700350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26583 [D loss: 0.152733, acc.: 98.44%] [G loss: 1.603238]\n",
      "epoch:28 step:26584 [D loss: 0.883389, acc.: 48.44%] [G loss: 1.440194]\n",
      "epoch:28 step:26585 [D loss: 0.689270, acc.: 57.03%] [G loss: 1.292424]\n",
      "epoch:28 step:26586 [D loss: 0.695216, acc.: 53.91%] [G loss: 1.216307]\n",
      "epoch:28 step:26587 [D loss: 0.525577, acc.: 77.34%] [G loss: 1.262369]\n",
      "epoch:28 step:26588 [D loss: 0.530059, acc.: 72.66%] [G loss: 1.174805]\n",
      "epoch:28 step:26589 [D loss: 0.542864, acc.: 72.66%] [G loss: 1.184190]\n",
      "epoch:28 step:26590 [D loss: 0.435120, acc.: 82.81%] [G loss: 1.355744]\n",
      "epoch:28 step:26591 [D loss: 0.758813, acc.: 57.03%] [G loss: 1.170419]\n",
      "epoch:28 step:26592 [D loss: 0.673650, acc.: 63.28%] [G loss: 1.191255]\n",
      "epoch:28 step:26593 [D loss: 0.668226, acc.: 59.38%] [G loss: 1.003608]\n",
      "epoch:28 step:26594 [D loss: 0.448895, acc.: 83.59%] [G loss: 1.157005]\n",
      "epoch:28 step:26595 [D loss: 0.392416, acc.: 89.06%] [G loss: 1.044798]\n",
      "epoch:28 step:26596 [D loss: 0.515698, acc.: 80.47%] [G loss: 0.968817]\n",
      "epoch:28 step:26597 [D loss: 0.685069, acc.: 59.38%] [G loss: 1.070929]\n",
      "epoch:28 step:26598 [D loss: 0.635098, acc.: 61.72%] [G loss: 1.375360]\n",
      "epoch:28 step:26599 [D loss: 0.562369, acc.: 71.09%] [G loss: 1.207624]\n",
      "epoch:28 step:26600 [D loss: 0.576948, acc.: 75.78%] [G loss: 1.006415]\n",
      "epoch:28 step:26601 [D loss: 0.457334, acc.: 82.03%] [G loss: 1.148895]\n",
      "epoch:28 step:26602 [D loss: 0.230069, acc.: 92.19%] [G loss: 0.730353]\n",
      "epoch:28 step:26603 [D loss: 0.325079, acc.: 82.81%] [G loss: 1.348112]\n",
      "epoch:28 step:26604 [D loss: 0.801161, acc.: 55.47%] [G loss: 1.201530]\n",
      "epoch:28 step:26605 [D loss: 0.522042, acc.: 74.22%] [G loss: 1.198204]\n",
      "epoch:28 step:26606 [D loss: 0.413465, acc.: 85.94%] [G loss: 1.358383]\n",
      "epoch:28 step:26607 [D loss: 0.422609, acc.: 78.91%] [G loss: 1.349231]\n",
      "epoch:28 step:26608 [D loss: 0.710241, acc.: 57.81%] [G loss: 1.298917]\n",
      "epoch:28 step:26609 [D loss: 0.748933, acc.: 50.78%] [G loss: 0.546847]\n",
      "epoch:28 step:26610 [D loss: 0.720124, acc.: 56.25%] [G loss: 1.143611]\n",
      "epoch:28 step:26611 [D loss: 0.717602, acc.: 53.91%] [G loss: 0.962090]\n",
      "epoch:28 step:26612 [D loss: 0.816954, acc.: 53.12%] [G loss: 1.055494]\n",
      "epoch:28 step:26613 [D loss: 0.349546, acc.: 85.94%] [G loss: 1.401489]\n",
      "epoch:28 step:26614 [D loss: 0.259371, acc.: 86.72%] [G loss: 1.652462]\n",
      "epoch:28 step:26615 [D loss: 0.857046, acc.: 49.22%] [G loss: 1.378127]\n",
      "epoch:28 step:26616 [D loss: 0.948121, acc.: 42.19%] [G loss: 1.439136]\n",
      "epoch:28 step:26617 [D loss: 0.768827, acc.: 49.22%] [G loss: 1.477345]\n",
      "epoch:28 step:26618 [D loss: 0.688699, acc.: 54.69%] [G loss: 1.287315]\n",
      "epoch:28 step:26619 [D loss: 0.471696, acc.: 81.25%] [G loss: 1.027896]\n",
      "epoch:28 step:26620 [D loss: 0.742727, acc.: 57.03%] [G loss: 1.294467]\n",
      "epoch:28 step:26621 [D loss: 0.523147, acc.: 73.44%] [G loss: 1.236956]\n",
      "epoch:28 step:26622 [D loss: 0.703137, acc.: 64.06%] [G loss: 1.399143]\n",
      "epoch:28 step:26623 [D loss: 0.595370, acc.: 68.75%] [G loss: 1.600081]\n",
      "epoch:28 step:26624 [D loss: 0.585331, acc.: 72.66%] [G loss: 1.219310]\n",
      "epoch:28 step:26625 [D loss: 0.396785, acc.: 87.50%] [G loss: 1.087375]\n",
      "epoch:28 step:26626 [D loss: 0.375319, acc.: 88.28%] [G loss: 1.516214]\n",
      "epoch:28 step:26627 [D loss: 0.380203, acc.: 90.62%] [G loss: 1.060039]\n",
      "epoch:28 step:26628 [D loss: 0.367425, acc.: 91.41%] [G loss: 1.345419]\n",
      "epoch:28 step:26629 [D loss: 0.382117, acc.: 79.69%] [G loss: 1.743290]\n",
      "epoch:28 step:26630 [D loss: 0.288301, acc.: 92.19%] [G loss: 1.269298]\n",
      "epoch:28 step:26631 [D loss: 0.872858, acc.: 37.50%] [G loss: 1.629303]\n",
      "epoch:28 step:26632 [D loss: 0.189061, acc.: 97.66%] [G loss: 1.799992]\n",
      "epoch:28 step:26633 [D loss: 0.115391, acc.: 99.22%] [G loss: 1.404764]\n",
      "epoch:28 step:26634 [D loss: 0.121542, acc.: 99.22%] [G loss: 1.591231]\n",
      "epoch:28 step:26635 [D loss: 0.080290, acc.: 100.00%] [G loss: 1.072983]\n",
      "epoch:28 step:26636 [D loss: 0.122238, acc.: 100.00%] [G loss: 2.249494]\n",
      "epoch:28 step:26637 [D loss: 0.107802, acc.: 98.44%] [G loss: 1.649174]\n",
      "epoch:28 step:26638 [D loss: 0.274662, acc.: 83.59%] [G loss: 2.481287]\n",
      "epoch:28 step:26639 [D loss: 0.176770, acc.: 94.53%] [G loss: 2.339378]\n",
      "epoch:28 step:26640 [D loss: 0.104689, acc.: 99.22%] [G loss: 1.883492]\n",
      "epoch:28 step:26641 [D loss: 0.150064, acc.: 96.88%] [G loss: 2.002310]\n",
      "epoch:28 step:26642 [D loss: 0.099306, acc.: 100.00%] [G loss: 2.254840]\n",
      "epoch:28 step:26643 [D loss: 0.053256, acc.: 100.00%] [G loss: 0.806849]\n",
      "epoch:28 step:26644 [D loss: 0.881230, acc.: 58.59%] [G loss: 2.504390]\n",
      "epoch:28 step:26645 [D loss: 0.150380, acc.: 95.31%] [G loss: 1.786778]\n",
      "epoch:28 step:26646 [D loss: 1.309178, acc.: 33.59%] [G loss: 1.776620]\n",
      "epoch:28 step:26647 [D loss: 1.609504, acc.: 28.12%] [G loss: 1.599374]\n",
      "epoch:28 step:26648 [D loss: 0.719688, acc.: 57.03%] [G loss: 1.124509]\n",
      "epoch:28 step:26649 [D loss: 0.389320, acc.: 83.59%] [G loss: 1.740268]\n",
      "epoch:28 step:26650 [D loss: 0.664503, acc.: 67.97%] [G loss: 1.763843]\n",
      "epoch:28 step:26651 [D loss: 0.378395, acc.: 85.16%] [G loss: 1.261009]\n",
      "epoch:28 step:26652 [D loss: 0.503274, acc.: 78.12%] [G loss: 0.819459]\n",
      "epoch:28 step:26653 [D loss: 0.940377, acc.: 43.75%] [G loss: 0.932950]\n",
      "epoch:28 step:26654 [D loss: 0.659045, acc.: 60.94%] [G loss: 1.554908]\n",
      "epoch:28 step:26655 [D loss: 0.468614, acc.: 77.34%] [G loss: 1.955784]\n",
      "epoch:28 step:26656 [D loss: 0.760950, acc.: 55.47%] [G loss: 1.870923]\n",
      "epoch:28 step:26657 [D loss: 1.061241, acc.: 28.12%] [G loss: 1.371675]\n",
      "epoch:28 step:26658 [D loss: 0.997777, acc.: 34.38%] [G loss: 1.521824]\n",
      "epoch:28 step:26659 [D loss: 0.927395, acc.: 45.31%] [G loss: 2.360537]\n",
      "epoch:28 step:26660 [D loss: 0.777700, acc.: 57.03%] [G loss: 1.219634]\n",
      "epoch:28 step:26661 [D loss: 0.754473, acc.: 51.56%] [G loss: 1.433599]\n",
      "epoch:28 step:26662 [D loss: 0.621925, acc.: 63.28%] [G loss: 1.020296]\n",
      "epoch:28 step:26663 [D loss: 0.566715, acc.: 76.56%] [G loss: 1.253898]\n",
      "epoch:28 step:26664 [D loss: 0.481511, acc.: 75.00%] [G loss: 1.133309]\n",
      "epoch:28 step:26665 [D loss: 0.824963, acc.: 46.88%] [G loss: 0.906976]\n",
      "epoch:28 step:26666 [D loss: 0.552537, acc.: 76.56%] [G loss: 1.431558]\n",
      "epoch:28 step:26667 [D loss: 0.778363, acc.: 46.88%] [G loss: 1.139662]\n",
      "epoch:28 step:26668 [D loss: 0.794325, acc.: 43.75%] [G loss: 1.385957]\n",
      "epoch:28 step:26669 [D loss: 0.727551, acc.: 55.47%] [G loss: 1.482300]\n",
      "epoch:28 step:26670 [D loss: 0.708014, acc.: 58.59%] [G loss: 1.334390]\n",
      "epoch:28 step:26671 [D loss: 0.681475, acc.: 57.03%] [G loss: 1.356186]\n",
      "epoch:28 step:26672 [D loss: 0.604638, acc.: 67.19%] [G loss: 1.439869]\n",
      "epoch:28 step:26673 [D loss: 0.674652, acc.: 54.69%] [G loss: 1.407039]\n",
      "epoch:28 step:26674 [D loss: 0.709480, acc.: 54.69%] [G loss: 1.334412]\n",
      "epoch:28 step:26675 [D loss: 0.715551, acc.: 53.12%] [G loss: 1.300190]\n",
      "epoch:28 step:26676 [D loss: 0.682507, acc.: 58.59%] [G loss: 1.183492]\n",
      "epoch:28 step:26677 [D loss: 0.582289, acc.: 69.53%] [G loss: 1.124034]\n",
      "epoch:28 step:26678 [D loss: 0.647399, acc.: 58.59%] [G loss: 1.211923]\n",
      "epoch:28 step:26679 [D loss: 0.560157, acc.: 73.44%] [G loss: 1.358327]\n",
      "epoch:28 step:26680 [D loss: 0.669521, acc.: 59.38%] [G loss: 1.080062]\n",
      "epoch:28 step:26681 [D loss: 0.664016, acc.: 62.50%] [G loss: 1.156877]\n",
      "epoch:28 step:26682 [D loss: 0.649467, acc.: 65.62%] [G loss: 0.968726]\n",
      "epoch:28 step:26683 [D loss: 0.605182, acc.: 73.44%] [G loss: 1.486882]\n",
      "epoch:28 step:26684 [D loss: 0.604226, acc.: 67.97%] [G loss: 1.108271]\n",
      "epoch:28 step:26685 [D loss: 0.462540, acc.: 85.16%] [G loss: 1.591280]\n",
      "epoch:28 step:26686 [D loss: 0.419097, acc.: 87.50%] [G loss: 2.569521]\n",
      "epoch:28 step:26687 [D loss: 0.453526, acc.: 87.50%] [G loss: 1.866199]\n",
      "epoch:28 step:26688 [D loss: 0.354093, acc.: 89.84%] [G loss: 1.517217]\n",
      "epoch:28 step:26689 [D loss: 0.377287, acc.: 90.62%] [G loss: 1.712507]\n",
      "epoch:28 step:26690 [D loss: 0.385604, acc.: 87.50%] [G loss: 1.524087]\n",
      "epoch:28 step:26691 [D loss: 0.445604, acc.: 85.94%] [G loss: 1.577080]\n",
      "epoch:28 step:26692 [D loss: 0.503134, acc.: 79.69%] [G loss: 1.080960]\n",
      "epoch:28 step:26693 [D loss: 0.423129, acc.: 88.28%] [G loss: 1.286325]\n",
      "epoch:28 step:26694 [D loss: 0.498842, acc.: 77.34%] [G loss: 1.419081]\n",
      "epoch:28 step:26695 [D loss: 0.609052, acc.: 71.09%] [G loss: 1.199831]\n",
      "epoch:28 step:26696 [D loss: 0.632556, acc.: 58.59%] [G loss: 1.326735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26697 [D loss: 1.042476, acc.: 25.78%] [G loss: 0.794426]\n",
      "epoch:28 step:26698 [D loss: 1.081235, acc.: 17.97%] [G loss: 0.844324]\n",
      "epoch:28 step:26699 [D loss: 0.680226, acc.: 62.50%] [G loss: 0.800625]\n",
      "epoch:28 step:26700 [D loss: 0.656224, acc.: 63.28%] [G loss: 0.826180]\n",
      "epoch:28 step:26701 [D loss: 0.534198, acc.: 71.88%] [G loss: 1.022933]\n",
      "epoch:28 step:26702 [D loss: 0.540214, acc.: 71.88%] [G loss: 1.184371]\n",
      "epoch:28 step:26703 [D loss: 0.509329, acc.: 80.47%] [G loss: 0.803837]\n",
      "epoch:28 step:26704 [D loss: 0.434866, acc.: 85.94%] [G loss: 1.150497]\n",
      "epoch:28 step:26705 [D loss: 0.405873, acc.: 89.06%] [G loss: 1.223575]\n",
      "epoch:28 step:26706 [D loss: 0.458277, acc.: 78.12%] [G loss: 1.632629]\n",
      "epoch:28 step:26707 [D loss: 0.301714, acc.: 91.41%] [G loss: 1.080064]\n",
      "epoch:28 step:26708 [D loss: 0.421065, acc.: 92.19%] [G loss: 0.966438]\n",
      "epoch:28 step:26709 [D loss: 1.255113, acc.: 38.28%] [G loss: 0.983916]\n",
      "epoch:28 step:26710 [D loss: 0.869330, acc.: 40.62%] [G loss: 0.855558]\n",
      "epoch:28 step:26711 [D loss: 0.793582, acc.: 50.00%] [G loss: 0.936080]\n",
      "epoch:28 step:26712 [D loss: 0.576422, acc.: 67.97%] [G loss: 0.913808]\n",
      "epoch:28 step:26713 [D loss: 0.597973, acc.: 64.06%] [G loss: 0.919807]\n",
      "epoch:28 step:26714 [D loss: 0.576000, acc.: 70.31%] [G loss: 0.942003]\n",
      "epoch:28 step:26715 [D loss: 0.445087, acc.: 75.78%] [G loss: 1.072473]\n",
      "epoch:28 step:26716 [D loss: 0.434566, acc.: 82.81%] [G loss: 1.153217]\n",
      "epoch:28 step:26717 [D loss: 0.427664, acc.: 86.72%] [G loss: 1.142257]\n",
      "epoch:28 step:26718 [D loss: 0.764872, acc.: 54.69%] [G loss: 1.227245]\n",
      "epoch:28 step:26719 [D loss: 0.599150, acc.: 64.06%] [G loss: 1.129205]\n",
      "epoch:28 step:26720 [D loss: 0.676535, acc.: 58.59%] [G loss: 1.021609]\n",
      "epoch:28 step:26721 [D loss: 0.641863, acc.: 62.50%] [G loss: 1.033764]\n",
      "epoch:28 step:26722 [D loss: 0.704369, acc.: 56.25%] [G loss: 1.026688]\n",
      "epoch:28 step:26723 [D loss: 0.599061, acc.: 65.62%] [G loss: 1.100285]\n",
      "epoch:28 step:26724 [D loss: 0.605713, acc.: 64.84%] [G loss: 1.028620]\n",
      "epoch:28 step:26725 [D loss: 0.531370, acc.: 77.34%] [G loss: 1.106851]\n",
      "epoch:28 step:26726 [D loss: 0.541572, acc.: 69.53%] [G loss: 0.905594]\n",
      "epoch:28 step:26727 [D loss: 0.500723, acc.: 81.25%] [G loss: 1.066753]\n",
      "epoch:28 step:26728 [D loss: 0.618362, acc.: 67.97%] [G loss: 1.008374]\n",
      "epoch:28 step:26729 [D loss: 0.617702, acc.: 64.84%] [G loss: 1.170857]\n",
      "epoch:28 step:26730 [D loss: 0.480947, acc.: 78.12%] [G loss: 1.081657]\n",
      "epoch:28 step:26731 [D loss: 0.561240, acc.: 70.31%] [G loss: 1.037648]\n",
      "epoch:28 step:26732 [D loss: 0.715573, acc.: 53.12%] [G loss: 1.026959]\n",
      "epoch:28 step:26733 [D loss: 0.615005, acc.: 58.59%] [G loss: 1.139072]\n",
      "epoch:28 step:26734 [D loss: 0.612581, acc.: 69.53%] [G loss: 1.408444]\n",
      "epoch:28 step:26735 [D loss: 0.524707, acc.: 78.12%] [G loss: 0.932876]\n",
      "epoch:28 step:26736 [D loss: 0.712941, acc.: 63.28%] [G loss: 1.142075]\n",
      "epoch:28 step:26737 [D loss: 0.759608, acc.: 52.34%] [G loss: 1.561808]\n",
      "epoch:28 step:26738 [D loss: 0.576379, acc.: 72.66%] [G loss: 0.900422]\n",
      "epoch:28 step:26739 [D loss: 0.464182, acc.: 78.91%] [G loss: 1.053201]\n",
      "epoch:28 step:26740 [D loss: 0.291063, acc.: 92.19%] [G loss: 1.193938]\n",
      "epoch:28 step:26741 [D loss: 0.355686, acc.: 86.72%] [G loss: 1.336922]\n",
      "epoch:28 step:26742 [D loss: 0.593609, acc.: 71.88%] [G loss: 1.327338]\n",
      "epoch:28 step:26743 [D loss: 0.479772, acc.: 82.03%] [G loss: 1.299656]\n",
      "epoch:28 step:26744 [D loss: 0.412292, acc.: 89.84%] [G loss: 1.395308]\n",
      "epoch:28 step:26745 [D loss: 0.696896, acc.: 50.78%] [G loss: 1.230144]\n",
      "epoch:28 step:26746 [D loss: 0.599208, acc.: 64.06%] [G loss: 1.057375]\n",
      "epoch:28 step:26747 [D loss: 0.544964, acc.: 68.75%] [G loss: 1.068899]\n",
      "epoch:28 step:26748 [D loss: 0.599546, acc.: 69.53%] [G loss: 1.394089]\n",
      "epoch:28 step:26749 [D loss: 0.461681, acc.: 79.69%] [G loss: 1.272567]\n",
      "epoch:28 step:26750 [D loss: 0.512731, acc.: 75.00%] [G loss: 1.277438]\n",
      "epoch:28 step:26751 [D loss: 0.491185, acc.: 78.12%] [G loss: 1.335271]\n",
      "epoch:28 step:26752 [D loss: 0.662192, acc.: 58.59%] [G loss: 1.096993]\n",
      "epoch:28 step:26753 [D loss: 0.370858, acc.: 83.59%] [G loss: 1.244752]\n",
      "epoch:28 step:26754 [D loss: 0.558708, acc.: 77.34%] [G loss: 1.166482]\n",
      "epoch:28 step:26755 [D loss: 0.434787, acc.: 85.16%] [G loss: 1.148409]\n",
      "epoch:28 step:26756 [D loss: 0.368357, acc.: 88.28%] [G loss: 1.430025]\n",
      "epoch:28 step:26757 [D loss: 0.583338, acc.: 75.78%] [G loss: 1.267457]\n",
      "epoch:28 step:26758 [D loss: 0.366824, acc.: 93.75%] [G loss: 1.206402]\n",
      "epoch:28 step:26759 [D loss: 0.485139, acc.: 78.12%] [G loss: 1.295874]\n",
      "epoch:28 step:26760 [D loss: 0.440962, acc.: 82.81%] [G loss: 1.443502]\n",
      "epoch:28 step:26761 [D loss: 0.622031, acc.: 66.41%] [G loss: 1.424909]\n",
      "epoch:28 step:26762 [D loss: 0.553605, acc.: 69.53%] [G loss: 1.169509]\n",
      "epoch:28 step:26763 [D loss: 0.607381, acc.: 64.06%] [G loss: 1.455279]\n",
      "epoch:28 step:26764 [D loss: 0.621307, acc.: 60.94%] [G loss: 1.562888]\n",
      "epoch:28 step:26765 [D loss: 0.730245, acc.: 48.44%] [G loss: 1.136324]\n",
      "epoch:28 step:26766 [D loss: 0.494968, acc.: 71.88%] [G loss: 1.099563]\n",
      "epoch:28 step:26767 [D loss: 0.641786, acc.: 64.84%] [G loss: 1.215937]\n",
      "epoch:28 step:26768 [D loss: 0.426442, acc.: 85.16%] [G loss: 1.387249]\n",
      "epoch:28 step:26769 [D loss: 0.287748, acc.: 88.28%] [G loss: 1.493782]\n",
      "epoch:28 step:26770 [D loss: 0.334282, acc.: 92.97%] [G loss: 1.420143]\n",
      "epoch:28 step:26771 [D loss: 0.428125, acc.: 82.81%] [G loss: 1.443470]\n",
      "epoch:28 step:26772 [D loss: 0.320280, acc.: 90.62%] [G loss: 1.518770]\n",
      "epoch:28 step:26773 [D loss: 0.513233, acc.: 77.34%] [G loss: 1.486491]\n",
      "epoch:28 step:26774 [D loss: 0.548413, acc.: 78.91%] [G loss: 1.261178]\n",
      "epoch:28 step:26775 [D loss: 0.475675, acc.: 79.69%] [G loss: 1.373647]\n",
      "epoch:28 step:26776 [D loss: 0.543637, acc.: 70.31%] [G loss: 1.446321]\n",
      "epoch:28 step:26777 [D loss: 0.633330, acc.: 64.84%] [G loss: 1.216361]\n",
      "epoch:28 step:26778 [D loss: 0.517598, acc.: 72.66%] [G loss: 1.488486]\n",
      "epoch:28 step:26779 [D loss: 0.194593, acc.: 93.75%] [G loss: 1.089664]\n",
      "epoch:28 step:26780 [D loss: 0.404206, acc.: 89.84%] [G loss: 1.476448]\n",
      "epoch:28 step:26781 [D loss: 0.222718, acc.: 96.88%] [G loss: 1.621355]\n",
      "epoch:28 step:26782 [D loss: 0.491715, acc.: 75.78%] [G loss: 1.835581]\n",
      "epoch:28 step:26783 [D loss: 0.487077, acc.: 82.03%] [G loss: 1.277181]\n",
      "epoch:28 step:26784 [D loss: 0.389927, acc.: 78.12%] [G loss: 1.549424]\n",
      "epoch:28 step:26785 [D loss: 0.173165, acc.: 97.66%] [G loss: 1.526357]\n",
      "epoch:28 step:26786 [D loss: 0.193956, acc.: 96.09%] [G loss: 2.094606]\n",
      "epoch:28 step:26787 [D loss: 0.260017, acc.: 89.84%] [G loss: 1.912219]\n",
      "epoch:28 step:26788 [D loss: 0.380462, acc.: 89.84%] [G loss: 1.924357]\n",
      "epoch:28 step:26789 [D loss: 0.796475, acc.: 50.00%] [G loss: 1.234996]\n",
      "epoch:28 step:26790 [D loss: 0.145099, acc.: 96.09%] [G loss: 2.209424]\n",
      "epoch:28 step:26791 [D loss: 0.175371, acc.: 99.22%] [G loss: 1.744006]\n",
      "epoch:28 step:26792 [D loss: 0.384544, acc.: 78.12%] [G loss: 1.718798]\n",
      "epoch:28 step:26793 [D loss: 0.236680, acc.: 97.66%] [G loss: 2.353186]\n",
      "epoch:28 step:26794 [D loss: 0.783804, acc.: 54.69%] [G loss: 1.963855]\n",
      "epoch:28 step:26795 [D loss: 0.312973, acc.: 89.06%] [G loss: 1.469989]\n",
      "epoch:28 step:26796 [D loss: 0.809465, acc.: 48.44%] [G loss: 0.992300]\n",
      "epoch:28 step:26797 [D loss: 0.222120, acc.: 95.31%] [G loss: 0.917237]\n",
      "epoch:28 step:26798 [D loss: 0.986107, acc.: 50.00%] [G loss: 0.612612]\n",
      "epoch:28 step:26799 [D loss: 0.625685, acc.: 63.28%] [G loss: 0.517919]\n",
      "epoch:28 step:26800 [D loss: 0.715084, acc.: 55.47%] [G loss: 1.531480]\n",
      "epoch:28 step:26801 [D loss: 0.731787, acc.: 50.78%] [G loss: 1.033321]\n",
      "epoch:28 step:26802 [D loss: 0.324098, acc.: 85.16%] [G loss: 2.003608]\n",
      "epoch:28 step:26803 [D loss: 0.122441, acc.: 100.00%] [G loss: 0.919583]\n",
      "epoch:28 step:26804 [D loss: 0.674535, acc.: 67.97%] [G loss: 1.593760]\n",
      "epoch:28 step:26805 [D loss: 0.690921, acc.: 58.59%] [G loss: 1.226948]\n",
      "epoch:28 step:26806 [D loss: 0.528847, acc.: 73.44%] [G loss: 1.679549]\n",
      "epoch:28 step:26807 [D loss: 0.559404, acc.: 69.53%] [G loss: 1.615359]\n",
      "epoch:28 step:26808 [D loss: 0.731960, acc.: 56.25%] [G loss: 1.948228]\n",
      "epoch:28 step:26809 [D loss: 0.272102, acc.: 92.19%] [G loss: 1.982440]\n",
      "epoch:28 step:26810 [D loss: 0.531384, acc.: 68.75%] [G loss: 1.613802]\n",
      "epoch:28 step:26811 [D loss: 0.307088, acc.: 89.06%] [G loss: 2.166260]\n",
      "epoch:28 step:26812 [D loss: 0.248654, acc.: 91.41%] [G loss: 2.173982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26813 [D loss: 0.227127, acc.: 95.31%] [G loss: 1.979857]\n",
      "epoch:28 step:26814 [D loss: 0.221985, acc.: 92.19%] [G loss: 2.103430]\n",
      "epoch:28 step:26815 [D loss: 0.292909, acc.: 88.28%] [G loss: 1.951619]\n",
      "epoch:28 step:26816 [D loss: 0.718374, acc.: 60.94%] [G loss: 1.963988]\n",
      "epoch:28 step:26817 [D loss: 0.664988, acc.: 58.59%] [G loss: 1.235781]\n",
      "epoch:28 step:26818 [D loss: 0.640315, acc.: 53.91%] [G loss: 1.666503]\n",
      "epoch:28 step:26819 [D loss: 0.709555, acc.: 57.81%] [G loss: 0.979638]\n",
      "epoch:28 step:26820 [D loss: 0.777027, acc.: 49.22%] [G loss: 1.297687]\n",
      "epoch:28 step:26821 [D loss: 0.595987, acc.: 66.41%] [G loss: 1.369487]\n",
      "epoch:28 step:26822 [D loss: 0.588906, acc.: 65.62%] [G loss: 1.469008]\n",
      "epoch:28 step:26823 [D loss: 0.311243, acc.: 80.47%] [G loss: 1.351056]\n",
      "epoch:28 step:26824 [D loss: 0.147844, acc.: 96.09%] [G loss: 1.963093]\n",
      "epoch:28 step:26825 [D loss: 0.178276, acc.: 95.31%] [G loss: 1.392166]\n",
      "epoch:28 step:26826 [D loss: 0.353928, acc.: 86.72%] [G loss: 1.949722]\n",
      "epoch:28 step:26827 [D loss: 0.737797, acc.: 64.06%] [G loss: 1.717567]\n",
      "epoch:28 step:26828 [D loss: 0.710683, acc.: 51.56%] [G loss: 1.489288]\n",
      "epoch:28 step:26829 [D loss: 0.667045, acc.: 57.81%] [G loss: 1.346648]\n",
      "epoch:28 step:26830 [D loss: 0.240133, acc.: 96.09%] [G loss: 1.568646]\n",
      "epoch:28 step:26831 [D loss: 0.218727, acc.: 93.75%] [G loss: 1.630490]\n",
      "epoch:28 step:26832 [D loss: 0.641563, acc.: 65.62%] [G loss: 1.690087]\n",
      "epoch:28 step:26833 [D loss: 0.652355, acc.: 64.06%] [G loss: 1.233293]\n",
      "epoch:28 step:26834 [D loss: 0.932310, acc.: 46.09%] [G loss: 1.117807]\n",
      "epoch:28 step:26835 [D loss: 0.861604, acc.: 42.97%] [G loss: 1.468336]\n",
      "epoch:28 step:26836 [D loss: 0.253523, acc.: 90.62%] [G loss: 1.535256]\n",
      "epoch:28 step:26837 [D loss: 0.329244, acc.: 86.72%] [G loss: 2.055664]\n",
      "epoch:28 step:26838 [D loss: 0.340201, acc.: 88.28%] [G loss: 2.291382]\n",
      "epoch:28 step:26839 [D loss: 0.760395, acc.: 56.25%] [G loss: 1.473516]\n",
      "epoch:28 step:26840 [D loss: 0.623887, acc.: 69.53%] [G loss: 1.371353]\n",
      "epoch:28 step:26841 [D loss: 0.645526, acc.: 63.28%] [G loss: 1.255923]\n",
      "epoch:28 step:26842 [D loss: 0.466816, acc.: 82.03%] [G loss: 1.202463]\n",
      "epoch:28 step:26843 [D loss: 0.355258, acc.: 87.50%] [G loss: 1.325397]\n",
      "epoch:28 step:26844 [D loss: 0.531729, acc.: 73.44%] [G loss: 1.322946]\n",
      "epoch:28 step:26845 [D loss: 0.155455, acc.: 98.44%] [G loss: 1.736104]\n",
      "epoch:28 step:26846 [D loss: 0.641348, acc.: 66.41%] [G loss: 1.163017]\n",
      "epoch:28 step:26847 [D loss: 0.183569, acc.: 96.09%] [G loss: 1.300026]\n",
      "epoch:28 step:26848 [D loss: 0.299479, acc.: 87.50%] [G loss: 1.499708]\n",
      "epoch:28 step:26849 [D loss: 0.713915, acc.: 61.72%] [G loss: 1.596892]\n",
      "epoch:28 step:26850 [D loss: 0.935558, acc.: 48.44%] [G loss: 1.307339]\n",
      "epoch:28 step:26851 [D loss: 0.922574, acc.: 43.75%] [G loss: 1.079739]\n",
      "epoch:28 step:26852 [D loss: 0.667813, acc.: 57.81%] [G loss: 1.116023]\n",
      "epoch:28 step:26853 [D loss: 0.653691, acc.: 63.28%] [G loss: 1.045339]\n",
      "epoch:28 step:26854 [D loss: 0.505539, acc.: 80.47%] [G loss: 1.098335]\n",
      "epoch:28 step:26855 [D loss: 0.580348, acc.: 71.88%] [G loss: 1.244653]\n",
      "epoch:28 step:26856 [D loss: 0.440054, acc.: 82.03%] [G loss: 1.053913]\n",
      "epoch:28 step:26857 [D loss: 0.458794, acc.: 82.03%] [G loss: 1.029123]\n",
      "epoch:28 step:26858 [D loss: 0.675648, acc.: 58.59%] [G loss: 1.109513]\n",
      "epoch:28 step:26859 [D loss: 0.548448, acc.: 75.00%] [G loss: 1.115544]\n",
      "epoch:28 step:26860 [D loss: 0.590881, acc.: 64.84%] [G loss: 0.842661]\n",
      "epoch:28 step:26861 [D loss: 0.676279, acc.: 60.16%] [G loss: 0.720647]\n",
      "epoch:28 step:26862 [D loss: 0.782344, acc.: 46.09%] [G loss: 1.135322]\n",
      "epoch:28 step:26863 [D loss: 0.559510, acc.: 71.88%] [G loss: 0.990382]\n",
      "epoch:28 step:26864 [D loss: 0.721056, acc.: 57.81%] [G loss: 1.074326]\n",
      "epoch:28 step:26865 [D loss: 0.765330, acc.: 48.44%] [G loss: 1.177785]\n",
      "epoch:28 step:26866 [D loss: 0.718365, acc.: 61.72%] [G loss: 0.793548]\n",
      "epoch:28 step:26867 [D loss: 0.445436, acc.: 82.81%] [G loss: 1.223755]\n",
      "epoch:28 step:26868 [D loss: 0.555290, acc.: 73.44%] [G loss: 0.912030]\n",
      "epoch:28 step:26869 [D loss: 0.396173, acc.: 85.16%] [G loss: 1.343955]\n",
      "epoch:28 step:26870 [D loss: 0.525356, acc.: 74.22%] [G loss: 1.277558]\n",
      "epoch:28 step:26871 [D loss: 0.429165, acc.: 82.81%] [G loss: 1.332018]\n",
      "epoch:28 step:26872 [D loss: 0.733038, acc.: 54.69%] [G loss: 1.365834]\n",
      "epoch:28 step:26873 [D loss: 0.719370, acc.: 56.25%] [G loss: 1.247791]\n",
      "epoch:28 step:26874 [D loss: 0.626085, acc.: 65.62%] [G loss: 1.122585]\n",
      "epoch:28 step:26875 [D loss: 0.840432, acc.: 42.97%] [G loss: 1.164732]\n",
      "epoch:28 step:26876 [D loss: 0.302599, acc.: 95.31%] [G loss: 1.273569]\n",
      "epoch:28 step:26877 [D loss: 0.294352, acc.: 88.28%] [G loss: 1.381697]\n",
      "epoch:28 step:26878 [D loss: 0.623512, acc.: 62.50%] [G loss: 1.230579]\n",
      "epoch:28 step:26879 [D loss: 0.617986, acc.: 62.50%] [G loss: 1.396477]\n",
      "epoch:28 step:26880 [D loss: 0.261142, acc.: 93.75%] [G loss: 1.234534]\n",
      "epoch:28 step:26881 [D loss: 0.297268, acc.: 96.09%] [G loss: 1.091531]\n",
      "epoch:28 step:26882 [D loss: 0.211777, acc.: 99.22%] [G loss: 1.346467]\n",
      "epoch:28 step:26883 [D loss: 0.271371, acc.: 90.62%] [G loss: 1.314303]\n",
      "epoch:28 step:26884 [D loss: 0.210370, acc.: 96.09%] [G loss: 1.589595]\n",
      "epoch:28 step:26885 [D loss: 0.313906, acc.: 93.75%] [G loss: 1.343100]\n",
      "epoch:28 step:26886 [D loss: 0.170048, acc.: 99.22%] [G loss: 1.842166]\n",
      "epoch:28 step:26887 [D loss: 0.306846, acc.: 95.31%] [G loss: 1.538246]\n",
      "epoch:28 step:26888 [D loss: 0.669821, acc.: 59.38%] [G loss: 1.184127]\n",
      "epoch:28 step:26889 [D loss: 0.748193, acc.: 59.38%] [G loss: 1.102289]\n",
      "epoch:28 step:26890 [D loss: 0.600608, acc.: 72.66%] [G loss: 1.328330]\n",
      "epoch:28 step:26891 [D loss: 0.509895, acc.: 78.12%] [G loss: 1.127791]\n",
      "epoch:28 step:26892 [D loss: 0.486607, acc.: 80.47%] [G loss: 0.689176]\n",
      "epoch:28 step:26893 [D loss: 0.953331, acc.: 32.03%] [G loss: 1.299452]\n",
      "epoch:28 step:26894 [D loss: 0.635046, acc.: 59.38%] [G loss: 1.407942]\n",
      "epoch:28 step:26895 [D loss: 0.349334, acc.: 82.03%] [G loss: 1.392190]\n",
      "epoch:28 step:26896 [D loss: 0.309218, acc.: 93.75%] [G loss: 1.088403]\n",
      "epoch:28 step:26897 [D loss: 0.316706, acc.: 93.75%] [G loss: 1.502482]\n",
      "epoch:28 step:26898 [D loss: 0.843296, acc.: 46.09%] [G loss: 0.843953]\n",
      "epoch:28 step:26899 [D loss: 0.187983, acc.: 96.88%] [G loss: 1.518321]\n",
      "epoch:28 step:26900 [D loss: 0.321823, acc.: 92.19%] [G loss: 1.239580]\n",
      "epoch:28 step:26901 [D loss: 0.225386, acc.: 92.97%] [G loss: 1.583677]\n",
      "epoch:28 step:26902 [D loss: 0.796296, acc.: 53.91%] [G loss: 1.579164]\n",
      "epoch:28 step:26903 [D loss: 0.655095, acc.: 68.75%] [G loss: 1.271842]\n",
      "epoch:28 step:26904 [D loss: 0.758955, acc.: 46.09%] [G loss: 1.303570]\n",
      "epoch:28 step:26905 [D loss: 0.746767, acc.: 49.22%] [G loss: 1.154058]\n",
      "epoch:28 step:26906 [D loss: 0.668000, acc.: 64.06%] [G loss: 1.061132]\n",
      "epoch:28 step:26907 [D loss: 0.337364, acc.: 92.97%] [G loss: 1.404868]\n",
      "epoch:28 step:26908 [D loss: 0.565654, acc.: 67.19%] [G loss: 1.088069]\n",
      "epoch:28 step:26909 [D loss: 0.681098, acc.: 57.81%] [G loss: 1.275591]\n",
      "epoch:28 step:26910 [D loss: 0.400800, acc.: 85.16%] [G loss: 1.336081]\n",
      "epoch:28 step:26911 [D loss: 0.883690, acc.: 41.41%] [G loss: 1.328108]\n",
      "epoch:28 step:26912 [D loss: 0.755554, acc.: 50.78%] [G loss: 1.048766]\n",
      "epoch:28 step:26913 [D loss: 0.605728, acc.: 72.66%] [G loss: 1.127285]\n",
      "epoch:28 step:26914 [D loss: 0.686173, acc.: 56.25%] [G loss: 1.174152]\n",
      "epoch:28 step:26915 [D loss: 0.732197, acc.: 55.47%] [G loss: 0.980388]\n",
      "epoch:28 step:26916 [D loss: 0.528522, acc.: 71.88%] [G loss: 1.262453]\n",
      "epoch:28 step:26917 [D loss: 0.631217, acc.: 64.06%] [G loss: 0.997578]\n",
      "epoch:28 step:26918 [D loss: 0.772312, acc.: 57.03%] [G loss: 1.120923]\n",
      "epoch:28 step:26919 [D loss: 0.493067, acc.: 79.69%] [G loss: 1.082307]\n",
      "epoch:28 step:26920 [D loss: 0.380130, acc.: 79.69%] [G loss: 1.445378]\n",
      "epoch:28 step:26921 [D loss: 0.457034, acc.: 78.91%] [G loss: 1.623244]\n",
      "epoch:28 step:26922 [D loss: 0.308193, acc.: 89.84%] [G loss: 1.934619]\n",
      "epoch:28 step:26923 [D loss: 0.284248, acc.: 92.97%] [G loss: 0.902295]\n",
      "epoch:28 step:26924 [D loss: 0.729871, acc.: 61.72%] [G loss: 1.355488]\n",
      "epoch:28 step:26925 [D loss: 0.791643, acc.: 53.12%] [G loss: 1.257652]\n",
      "epoch:28 step:26926 [D loss: 0.588526, acc.: 68.75%] [G loss: 0.927257]\n",
      "epoch:28 step:26927 [D loss: 0.587550, acc.: 72.66%] [G loss: 1.254509]\n",
      "epoch:28 step:26928 [D loss: 0.567414, acc.: 68.75%] [G loss: 1.085868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26929 [D loss: 0.612109, acc.: 67.19%] [G loss: 0.947666]\n",
      "epoch:28 step:26930 [D loss: 0.414006, acc.: 82.03%] [G loss: 0.958523]\n",
      "epoch:28 step:26931 [D loss: 0.745897, acc.: 57.81%] [G loss: 1.017705]\n",
      "epoch:28 step:26932 [D loss: 0.241027, acc.: 90.62%] [G loss: 1.232513]\n",
      "epoch:28 step:26933 [D loss: 0.321261, acc.: 82.03%] [G loss: 1.179007]\n",
      "epoch:28 step:26934 [D loss: 0.203048, acc.: 100.00%] [G loss: 1.492364]\n",
      "epoch:28 step:26935 [D loss: 0.221753, acc.: 99.22%] [G loss: 1.524919]\n",
      "epoch:28 step:26936 [D loss: 0.400272, acc.: 85.16%] [G loss: 1.483512]\n",
      "epoch:28 step:26937 [D loss: 0.167091, acc.: 96.88%] [G loss: 1.777137]\n",
      "epoch:28 step:26938 [D loss: 0.218249, acc.: 96.09%] [G loss: 1.535487]\n",
      "epoch:28 step:26939 [D loss: 0.537717, acc.: 76.56%] [G loss: 1.674095]\n",
      "epoch:28 step:26940 [D loss: 0.354879, acc.: 89.84%] [G loss: 0.823962]\n",
      "epoch:28 step:26941 [D loss: 0.686017, acc.: 60.94%] [G loss: 1.290788]\n",
      "epoch:28 step:26942 [D loss: 0.241016, acc.: 92.19%] [G loss: 1.668947]\n",
      "epoch:28 step:26943 [D loss: 0.160635, acc.: 97.66%] [G loss: 0.717229]\n",
      "epoch:28 step:26944 [D loss: 0.164891, acc.: 96.88%] [G loss: 1.421161]\n",
      "epoch:28 step:26945 [D loss: 0.152668, acc.: 96.88%] [G loss: 1.117466]\n",
      "epoch:28 step:26946 [D loss: 0.703836, acc.: 63.28%] [G loss: 2.077705]\n",
      "epoch:28 step:26947 [D loss: 0.715060, acc.: 60.94%] [G loss: 1.485032]\n",
      "epoch:28 step:26948 [D loss: 0.807508, acc.: 52.34%] [G loss: 1.769909]\n",
      "epoch:28 step:26949 [D loss: 0.126583, acc.: 97.66%] [G loss: 1.646619]\n",
      "epoch:28 step:26950 [D loss: 0.111899, acc.: 98.44%] [G loss: 0.527085]\n",
      "epoch:28 step:26951 [D loss: 0.970697, acc.: 46.88%] [G loss: 1.040190]\n",
      "epoch:28 step:26952 [D loss: 1.049333, acc.: 33.59%] [G loss: 0.958912]\n",
      "epoch:28 step:26953 [D loss: 0.639430, acc.: 63.28%] [G loss: 1.108181]\n",
      "epoch:28 step:26954 [D loss: 0.921526, acc.: 38.28%] [G loss: 1.729114]\n",
      "epoch:28 step:26955 [D loss: 0.908269, acc.: 40.62%] [G loss: 1.883849]\n",
      "epoch:28 step:26956 [D loss: 0.427066, acc.: 80.47%] [G loss: 2.273572]\n",
      "epoch:28 step:26957 [D loss: 0.695817, acc.: 57.03%] [G loss: 2.169980]\n",
      "epoch:28 step:26958 [D loss: 0.881521, acc.: 56.25%] [G loss: 1.656983]\n",
      "epoch:28 step:26959 [D loss: 0.574898, acc.: 65.62%] [G loss: 1.722190]\n",
      "epoch:28 step:26960 [D loss: 0.438513, acc.: 84.38%] [G loss: 1.309051]\n",
      "epoch:28 step:26961 [D loss: 0.435732, acc.: 85.16%] [G loss: 2.073021]\n",
      "epoch:28 step:26962 [D loss: 0.360515, acc.: 85.94%] [G loss: 2.012754]\n",
      "epoch:28 step:26963 [D loss: 0.710304, acc.: 60.16%] [G loss: 1.620959]\n",
      "epoch:28 step:26964 [D loss: 0.651038, acc.: 69.53%] [G loss: 1.871204]\n",
      "epoch:28 step:26965 [D loss: 0.541507, acc.: 68.75%] [G loss: 1.461660]\n",
      "epoch:28 step:26966 [D loss: 0.447093, acc.: 83.59%] [G loss: 1.702718]\n",
      "epoch:28 step:26967 [D loss: 0.614565, acc.: 67.97%] [G loss: 1.608420]\n",
      "epoch:28 step:26968 [D loss: 0.583350, acc.: 70.31%] [G loss: 1.221360]\n",
      "epoch:28 step:26969 [D loss: 0.462333, acc.: 78.91%] [G loss: 1.192233]\n",
      "epoch:28 step:26970 [D loss: 0.844989, acc.: 46.09%] [G loss: 1.686098]\n",
      "epoch:28 step:26971 [D loss: 0.358505, acc.: 89.84%] [G loss: 1.355449]\n",
      "epoch:28 step:26972 [D loss: 0.304385, acc.: 95.31%] [G loss: 1.573030]\n",
      "epoch:28 step:26973 [D loss: 0.459085, acc.: 77.34%] [G loss: 2.108335]\n",
      "epoch:28 step:26974 [D loss: 0.747239, acc.: 53.91%] [G loss: 1.845873]\n",
      "epoch:28 step:26975 [D loss: 0.803795, acc.: 45.31%] [G loss: 1.521644]\n",
      "epoch:28 step:26976 [D loss: 0.816775, acc.: 44.53%] [G loss: 1.414107]\n",
      "epoch:28 step:26977 [D loss: 0.223485, acc.: 96.88%] [G loss: 1.679538]\n",
      "epoch:28 step:26978 [D loss: 0.170600, acc.: 96.09%] [G loss: 2.049857]\n",
      "epoch:28 step:26979 [D loss: 0.144810, acc.: 98.44%] [G loss: 1.934287]\n",
      "epoch:28 step:26980 [D loss: 0.247035, acc.: 93.75%] [G loss: 2.104790]\n",
      "epoch:28 step:26981 [D loss: 0.765396, acc.: 59.38%] [G loss: 1.509637]\n",
      "epoch:28 step:26982 [D loss: 0.612448, acc.: 62.50%] [G loss: 1.530144]\n",
      "epoch:28 step:26983 [D loss: 0.599660, acc.: 65.62%] [G loss: 1.349598]\n",
      "epoch:28 step:26984 [D loss: 0.363412, acc.: 89.06%] [G loss: 1.260090]\n",
      "epoch:28 step:26985 [D loss: 0.250006, acc.: 92.97%] [G loss: 1.442725]\n",
      "epoch:28 step:26986 [D loss: 0.192443, acc.: 99.22%] [G loss: 1.395109]\n",
      "epoch:28 step:26987 [D loss: 0.980983, acc.: 48.44%] [G loss: 1.909119]\n",
      "epoch:28 step:26988 [D loss: 0.992974, acc.: 46.88%] [G loss: 1.272347]\n",
      "epoch:28 step:26989 [D loss: 0.795749, acc.: 46.09%] [G loss: 1.106476]\n",
      "epoch:28 step:26990 [D loss: 0.657852, acc.: 60.94%] [G loss: 0.947204]\n",
      "epoch:28 step:26991 [D loss: 0.680567, acc.: 62.50%] [G loss: 0.971318]\n",
      "epoch:28 step:26992 [D loss: 0.711560, acc.: 57.81%] [G loss: 0.760246]\n",
      "epoch:28 step:26993 [D loss: 0.536901, acc.: 75.78%] [G loss: 1.065460]\n",
      "epoch:28 step:26994 [D loss: 0.565986, acc.: 71.09%] [G loss: 1.152468]\n",
      "epoch:28 step:26995 [D loss: 0.325325, acc.: 90.62%] [G loss: 1.141254]\n",
      "epoch:28 step:26996 [D loss: 0.362113, acc.: 85.94%] [G loss: 1.498684]\n",
      "epoch:28 step:26997 [D loss: 0.491979, acc.: 76.56%] [G loss: 1.036834]\n",
      "epoch:28 step:26998 [D loss: 0.675615, acc.: 62.50%] [G loss: 1.199464]\n",
      "epoch:28 step:26999 [D loss: 0.687629, acc.: 62.50%] [G loss: 1.256130]\n",
      "epoch:28 step:27000 [D loss: 0.744296, acc.: 51.56%] [G loss: 0.690187]\n",
      "epoch:28 step:27001 [D loss: 0.442765, acc.: 87.50%] [G loss: 0.967787]\n",
      "epoch:28 step:27002 [D loss: 0.418743, acc.: 82.81%] [G loss: 1.272360]\n",
      "epoch:28 step:27003 [D loss: 0.448417, acc.: 82.03%] [G loss: 0.949226]\n",
      "epoch:28 step:27004 [D loss: 0.250076, acc.: 89.06%] [G loss: 1.530491]\n",
      "epoch:28 step:27005 [D loss: 0.219668, acc.: 91.41%] [G loss: 1.345890]\n",
      "epoch:28 step:27006 [D loss: 0.448583, acc.: 84.38%] [G loss: 1.178956]\n",
      "epoch:28 step:27007 [D loss: 0.712505, acc.: 52.34%] [G loss: 1.729073]\n",
      "epoch:28 step:27008 [D loss: 0.620638, acc.: 62.50%] [G loss: 1.424506]\n",
      "epoch:28 step:27009 [D loss: 0.733136, acc.: 57.03%] [G loss: 1.015080]\n",
      "epoch:28 step:27010 [D loss: 0.210644, acc.: 93.75%] [G loss: 1.625026]\n",
      "epoch:28 step:27011 [D loss: 0.152323, acc.: 98.44%] [G loss: 1.667476]\n",
      "epoch:28 step:27012 [D loss: 0.557786, acc.: 72.66%] [G loss: 1.742117]\n",
      "epoch:28 step:27013 [D loss: 0.247540, acc.: 96.88%] [G loss: 1.475768]\n",
      "epoch:28 step:27014 [D loss: 0.767524, acc.: 53.91%] [G loss: 1.313043]\n",
      "epoch:28 step:27015 [D loss: 0.805603, acc.: 54.69%] [G loss: 1.430138]\n",
      "epoch:28 step:27016 [D loss: 0.975662, acc.: 41.41%] [G loss: 1.179087]\n",
      "epoch:28 step:27017 [D loss: 0.503827, acc.: 77.34%] [G loss: 1.511786]\n",
      "epoch:28 step:27018 [D loss: 0.661248, acc.: 59.38%] [G loss: 1.415301]\n",
      "epoch:28 step:27019 [D loss: 0.692898, acc.: 63.28%] [G loss: 1.090276]\n",
      "epoch:28 step:27020 [D loss: 0.741510, acc.: 53.12%] [G loss: 1.137131]\n",
      "epoch:28 step:27021 [D loss: 0.668432, acc.: 53.12%] [G loss: 1.378277]\n",
      "epoch:28 step:27022 [D loss: 0.380607, acc.: 89.06%] [G loss: 2.182675]\n",
      "epoch:28 step:27023 [D loss: 0.603086, acc.: 70.31%] [G loss: 1.373433]\n",
      "epoch:28 step:27024 [D loss: 0.546268, acc.: 75.78%] [G loss: 1.124259]\n",
      "epoch:28 step:27025 [D loss: 0.767494, acc.: 53.12%] [G loss: 1.072137]\n",
      "epoch:28 step:27026 [D loss: 0.689015, acc.: 52.34%] [G loss: 1.226655]\n",
      "epoch:28 step:27027 [D loss: 0.320722, acc.: 86.72%] [G loss: 1.305417]\n",
      "epoch:28 step:27028 [D loss: 0.265293, acc.: 85.94%] [G loss: 1.136446]\n",
      "epoch:28 step:27029 [D loss: 0.390854, acc.: 85.16%] [G loss: 1.451360]\n",
      "epoch:28 step:27030 [D loss: 0.193949, acc.: 98.44%] [G loss: 1.725586]\n",
      "epoch:28 step:27031 [D loss: 0.571048, acc.: 65.62%] [G loss: 1.850300]\n",
      "epoch:28 step:27032 [D loss: 0.356318, acc.: 89.06%] [G loss: 1.682895]\n",
      "epoch:28 step:27033 [D loss: 0.524382, acc.: 74.22%] [G loss: 1.584100]\n",
      "epoch:28 step:27034 [D loss: 0.365485, acc.: 92.19%] [G loss: 1.888520]\n",
      "epoch:28 step:27035 [D loss: 0.654475, acc.: 62.50%] [G loss: 1.420688]\n",
      "epoch:28 step:27036 [D loss: 0.458217, acc.: 80.47%] [G loss: 1.162283]\n",
      "epoch:28 step:27037 [D loss: 0.462496, acc.: 78.91%] [G loss: 1.382168]\n",
      "epoch:28 step:27038 [D loss: 0.354193, acc.: 83.59%] [G loss: 1.260435]\n",
      "epoch:28 step:27039 [D loss: 0.555675, acc.: 75.78%] [G loss: 1.157295]\n",
      "epoch:28 step:27040 [D loss: 0.237447, acc.: 92.19%] [G loss: 1.517149]\n",
      "epoch:28 step:27041 [D loss: 0.317577, acc.: 89.84%] [G loss: 1.762205]\n",
      "epoch:28 step:27042 [D loss: 0.238568, acc.: 90.62%] [G loss: 1.478784]\n",
      "epoch:28 step:27043 [D loss: 0.869734, acc.: 51.56%] [G loss: 1.712597]\n",
      "epoch:28 step:27044 [D loss: 0.391903, acc.: 83.59%] [G loss: 1.271185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27045 [D loss: 0.554125, acc.: 67.97%] [G loss: 1.263285]\n",
      "epoch:28 step:27046 [D loss: 0.682455, acc.: 57.03%] [G loss: 1.190124]\n",
      "epoch:28 step:27047 [D loss: 0.723051, acc.: 56.25%] [G loss: 1.060240]\n",
      "epoch:28 step:27048 [D loss: 0.695192, acc.: 56.25%] [G loss: 1.078065]\n",
      "epoch:28 step:27049 [D loss: 0.772203, acc.: 47.66%] [G loss: 1.037674]\n",
      "epoch:28 step:27050 [D loss: 0.705599, acc.: 53.91%] [G loss: 1.195692]\n",
      "epoch:28 step:27051 [D loss: 0.271272, acc.: 87.50%] [G loss: 0.990373]\n",
      "epoch:28 step:27052 [D loss: 0.493620, acc.: 78.91%] [G loss: 1.088002]\n",
      "epoch:28 step:27053 [D loss: 0.717304, acc.: 57.81%] [G loss: 0.677055]\n",
      "epoch:28 step:27054 [D loss: 0.686585, acc.: 57.03%] [G loss: 1.163221]\n",
      "epoch:28 step:27055 [D loss: 0.673110, acc.: 55.47%] [G loss: 0.733106]\n",
      "epoch:28 step:27056 [D loss: 0.636402, acc.: 62.50%] [G loss: 0.821333]\n",
      "epoch:28 step:27057 [D loss: 0.300126, acc.: 92.97%] [G loss: 1.203862]\n",
      "epoch:28 step:27058 [D loss: 0.566359, acc.: 70.31%] [G loss: 0.867654]\n",
      "epoch:28 step:27059 [D loss: 0.508492, acc.: 76.56%] [G loss: 1.038742]\n",
      "epoch:28 step:27060 [D loss: 0.746410, acc.: 54.69%] [G loss: 1.180828]\n",
      "epoch:28 step:27061 [D loss: 0.521158, acc.: 72.66%] [G loss: 0.716589]\n",
      "epoch:28 step:27062 [D loss: 0.700549, acc.: 57.81%] [G loss: 1.252197]\n",
      "epoch:28 step:27063 [D loss: 0.522600, acc.: 75.00%] [G loss: 1.022415]\n",
      "epoch:28 step:27064 [D loss: 0.683872, acc.: 61.72%] [G loss: 1.196244]\n",
      "epoch:28 step:27065 [D loss: 0.604009, acc.: 68.75%] [G loss: 1.245655]\n",
      "epoch:28 step:27066 [D loss: 0.675040, acc.: 60.16%] [G loss: 1.355826]\n",
      "epoch:28 step:27067 [D loss: 0.685437, acc.: 56.25%] [G loss: 0.989667]\n",
      "epoch:28 step:27068 [D loss: 0.579408, acc.: 65.62%] [G loss: 1.164530]\n",
      "epoch:28 step:27069 [D loss: 0.491598, acc.: 80.47%] [G loss: 1.147863]\n",
      "epoch:28 step:27070 [D loss: 0.234749, acc.: 92.97%] [G loss: 1.431405]\n",
      "epoch:28 step:27071 [D loss: 0.235319, acc.: 96.09%] [G loss: 1.171947]\n",
      "epoch:28 step:27072 [D loss: 0.433046, acc.: 81.25%] [G loss: 1.322332]\n",
      "epoch:28 step:27073 [D loss: 0.569579, acc.: 72.66%] [G loss: 1.189386]\n",
      "epoch:28 step:27074 [D loss: 0.719172, acc.: 56.25%] [G loss: 1.256333]\n",
      "epoch:28 step:27075 [D loss: 0.240541, acc.: 93.75%] [G loss: 1.599952]\n",
      "epoch:28 step:27076 [D loss: 0.348245, acc.: 91.41%] [G loss: 1.256672]\n",
      "epoch:28 step:27077 [D loss: 0.224042, acc.: 95.31%] [G loss: 1.473167]\n",
      "epoch:28 step:27078 [D loss: 0.153012, acc.: 95.31%] [G loss: 1.787081]\n",
      "epoch:28 step:27079 [D loss: 0.845320, acc.: 52.34%] [G loss: 1.391063]\n",
      "epoch:28 step:27080 [D loss: 0.632431, acc.: 70.31%] [G loss: 1.024932]\n",
      "epoch:28 step:27081 [D loss: 0.446460, acc.: 76.56%] [G loss: 1.182302]\n",
      "epoch:28 step:27082 [D loss: 0.861522, acc.: 44.53%] [G loss: 1.123132]\n",
      "epoch:28 step:27083 [D loss: 0.255869, acc.: 89.06%] [G loss: 1.395820]\n",
      "epoch:28 step:27084 [D loss: 0.594509, acc.: 67.97%] [G loss: 1.293218]\n",
      "epoch:28 step:27085 [D loss: 0.221107, acc.: 96.09%] [G loss: 1.558098]\n",
      "epoch:28 step:27086 [D loss: 0.258064, acc.: 90.62%] [G loss: 1.497409]\n",
      "epoch:28 step:27087 [D loss: 0.345139, acc.: 81.25%] [G loss: 2.091836]\n",
      "epoch:28 step:27088 [D loss: 0.110483, acc.: 99.22%] [G loss: 2.430624]\n",
      "epoch:28 step:27089 [D loss: 0.132708, acc.: 98.44%] [G loss: 2.110209]\n",
      "epoch:28 step:27090 [D loss: 0.137113, acc.: 96.88%] [G loss: 2.537323]\n",
      "epoch:28 step:27091 [D loss: 0.174616, acc.: 97.66%] [G loss: 2.271485]\n",
      "epoch:28 step:27092 [D loss: 0.955979, acc.: 50.78%] [G loss: 2.141019]\n",
      "epoch:28 step:27093 [D loss: 0.170216, acc.: 96.88%] [G loss: 1.736113]\n",
      "epoch:28 step:27094 [D loss: 0.459890, acc.: 81.25%] [G loss: 1.830372]\n",
      "epoch:28 step:27095 [D loss: 0.359439, acc.: 90.62%] [G loss: 1.582757]\n",
      "epoch:28 step:27096 [D loss: 0.297840, acc.: 92.19%] [G loss: 1.230924]\n",
      "epoch:28 step:27097 [D loss: 0.291779, acc.: 92.19%] [G loss: 1.551977]\n",
      "epoch:28 step:27098 [D loss: 0.818856, acc.: 53.91%] [G loss: 1.413223]\n",
      "epoch:28 step:27099 [D loss: 0.727057, acc.: 51.56%] [G loss: 1.169010]\n",
      "epoch:28 step:27100 [D loss: 0.682736, acc.: 55.47%] [G loss: 1.229925]\n",
      "epoch:28 step:27101 [D loss: 0.379671, acc.: 83.59%] [G loss: 1.367013]\n",
      "epoch:28 step:27102 [D loss: 0.507256, acc.: 77.34%] [G loss: 1.358462]\n",
      "epoch:28 step:27103 [D loss: 0.279728, acc.: 87.50%] [G loss: 1.692433]\n",
      "epoch:28 step:27104 [D loss: 0.876585, acc.: 44.53%] [G loss: 1.362075]\n",
      "epoch:28 step:27105 [D loss: 0.603609, acc.: 62.50%] [G loss: 1.857635]\n",
      "epoch:28 step:27106 [D loss: 0.892039, acc.: 36.72%] [G loss: 1.406653]\n",
      "epoch:28 step:27107 [D loss: 0.594503, acc.: 63.28%] [G loss: 1.821768]\n",
      "epoch:28 step:27108 [D loss: 0.390231, acc.: 88.28%] [G loss: 1.368481]\n",
      "epoch:28 step:27109 [D loss: 0.617537, acc.: 65.62%] [G loss: 1.108956]\n",
      "epoch:28 step:27110 [D loss: 0.558806, acc.: 69.53%] [G loss: 1.073537]\n",
      "epoch:28 step:27111 [D loss: 0.339733, acc.: 87.50%] [G loss: 0.970462]\n",
      "epoch:28 step:27112 [D loss: 0.821125, acc.: 42.97%] [G loss: 1.206509]\n",
      "epoch:28 step:27113 [D loss: 1.947877, acc.: 21.09%] [G loss: 1.586259]\n",
      "epoch:28 step:27114 [D loss: 0.196601, acc.: 94.53%] [G loss: 1.726857]\n",
      "epoch:28 step:27115 [D loss: 0.698419, acc.: 57.81%] [G loss: 1.584318]\n",
      "epoch:28 step:27116 [D loss: 0.654926, acc.: 60.16%] [G loss: 1.376658]\n",
      "epoch:28 step:27117 [D loss: 0.765211, acc.: 51.56%] [G loss: 0.962503]\n",
      "epoch:28 step:27118 [D loss: 0.231034, acc.: 95.31%] [G loss: 1.354601]\n",
      "epoch:28 step:27119 [D loss: 0.471466, acc.: 78.12%] [G loss: 0.922201]\n",
      "epoch:28 step:27120 [D loss: 0.258651, acc.: 91.41%] [G loss: 0.994590]\n",
      "epoch:28 step:27121 [D loss: 0.383407, acc.: 81.25%] [G loss: 1.720896]\n",
      "epoch:28 step:27122 [D loss: 0.260864, acc.: 96.09%] [G loss: 1.628964]\n",
      "epoch:28 step:27123 [D loss: 0.276888, acc.: 89.84%] [G loss: 1.799748]\n",
      "epoch:28 step:27124 [D loss: 1.228544, acc.: 22.66%] [G loss: 1.517452]\n",
      "epoch:28 step:27125 [D loss: 0.316247, acc.: 90.62%] [G loss: 2.020794]\n",
      "epoch:28 step:27126 [D loss: 0.936690, acc.: 32.81%] [G loss: 1.846544]\n",
      "epoch:28 step:27127 [D loss: 0.873075, acc.: 47.66%] [G loss: 1.811751]\n",
      "epoch:28 step:27128 [D loss: 0.396649, acc.: 82.03%] [G loss: 1.680179]\n",
      "epoch:28 step:27129 [D loss: 0.592322, acc.: 70.31%] [G loss: 1.773246]\n",
      "epoch:28 step:27130 [D loss: 0.604080, acc.: 65.62%] [G loss: 2.047987]\n",
      "epoch:28 step:27131 [D loss: 0.293109, acc.: 93.75%] [G loss: 2.033421]\n",
      "epoch:28 step:27132 [D loss: 0.258888, acc.: 94.53%] [G loss: 1.955645]\n",
      "epoch:28 step:27133 [D loss: 0.163297, acc.: 98.44%] [G loss: 2.025163]\n",
      "epoch:28 step:27134 [D loss: 0.107793, acc.: 99.22%] [G loss: 2.142436]\n",
      "epoch:28 step:27135 [D loss: 0.076547, acc.: 99.22%] [G loss: 2.221499]\n",
      "epoch:28 step:27136 [D loss: 0.068128, acc.: 100.00%] [G loss: 2.400278]\n",
      "epoch:28 step:27137 [D loss: 0.121262, acc.: 100.00%] [G loss: 2.147477]\n",
      "epoch:28 step:27138 [D loss: 0.394839, acc.: 82.03%] [G loss: 2.099441]\n",
      "epoch:28 step:27139 [D loss: 0.156736, acc.: 96.88%] [G loss: 1.991833]\n",
      "epoch:28 step:27140 [D loss: 1.139260, acc.: 49.22%] [G loss: 1.532240]\n",
      "epoch:28 step:27141 [D loss: 0.695297, acc.: 57.81%] [G loss: 1.648801]\n",
      "epoch:28 step:27142 [D loss: 0.560993, acc.: 64.06%] [G loss: 1.400554]\n",
      "epoch:28 step:27143 [D loss: 0.773245, acc.: 52.34%] [G loss: 1.466159]\n",
      "epoch:28 step:27144 [D loss: 0.388105, acc.: 89.06%] [G loss: 1.493073]\n",
      "epoch:28 step:27145 [D loss: 0.303781, acc.: 84.38%] [G loss: 1.787345]\n",
      "epoch:28 step:27146 [D loss: 0.684441, acc.: 64.06%] [G loss: 1.463647]\n",
      "epoch:28 step:27147 [D loss: 0.182854, acc.: 95.31%] [G loss: 1.541625]\n",
      "epoch:28 step:27148 [D loss: 0.134257, acc.: 98.44%] [G loss: 1.556882]\n",
      "epoch:28 step:27149 [D loss: 0.488571, acc.: 79.69%] [G loss: 1.802191]\n",
      "epoch:28 step:27150 [D loss: 0.744835, acc.: 58.59%] [G loss: 1.431630]\n",
      "epoch:28 step:27151 [D loss: 0.689826, acc.: 57.81%] [G loss: 0.829875]\n",
      "epoch:28 step:27152 [D loss: 0.695107, acc.: 63.28%] [G loss: 1.418440]\n",
      "epoch:28 step:27153 [D loss: 0.430861, acc.: 80.47%] [G loss: 1.063948]\n",
      "epoch:28 step:27154 [D loss: 0.705365, acc.: 59.38%] [G loss: 1.452360]\n",
      "epoch:28 step:27155 [D loss: 0.190090, acc.: 95.31%] [G loss: 1.125359]\n",
      "epoch:28 step:27156 [D loss: 0.366443, acc.: 83.59%] [G loss: 1.526218]\n",
      "epoch:28 step:27157 [D loss: 0.263965, acc.: 98.44%] [G loss: 1.596563]\n",
      "epoch:28 step:27158 [D loss: 0.696317, acc.: 55.47%] [G loss: 1.939102]\n",
      "epoch:28 step:27159 [D loss: 0.450184, acc.: 84.38%] [G loss: 1.592802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27160 [D loss: 0.179804, acc.: 99.22%] [G loss: 1.562904]\n",
      "epoch:28 step:27161 [D loss: 0.302549, acc.: 92.19%] [G loss: 0.932887]\n",
      "epoch:28 step:27162 [D loss: 0.202300, acc.: 89.84%] [G loss: 0.478963]\n",
      "epoch:28 step:27163 [D loss: 0.534885, acc.: 71.09%] [G loss: 1.981467]\n",
      "epoch:28 step:27164 [D loss: 0.935539, acc.: 56.25%] [G loss: 1.492925]\n",
      "epoch:28 step:27165 [D loss: 0.152643, acc.: 100.00%] [G loss: 1.295870]\n",
      "epoch:28 step:27166 [D loss: 0.679114, acc.: 58.59%] [G loss: 1.372287]\n",
      "epoch:28 step:27167 [D loss: 0.365261, acc.: 85.94%] [G loss: 1.578788]\n",
      "epoch:28 step:27168 [D loss: 0.639630, acc.: 67.19%] [G loss: 1.601541]\n",
      "epoch:28 step:27169 [D loss: 0.372726, acc.: 88.28%] [G loss: 1.437873]\n",
      "epoch:28 step:27170 [D loss: 0.261074, acc.: 90.62%] [G loss: 1.514195]\n",
      "epoch:28 step:27171 [D loss: 0.383345, acc.: 86.72%] [G loss: 1.595670]\n",
      "epoch:28 step:27172 [D loss: 0.155208, acc.: 99.22%] [G loss: 1.470532]\n",
      "epoch:28 step:27173 [D loss: 0.464130, acc.: 67.19%] [G loss: 2.024551]\n",
      "epoch:29 step:27174 [D loss: 0.626606, acc.: 66.41%] [G loss: 1.435908]\n",
      "epoch:29 step:27175 [D loss: 0.800281, acc.: 50.00%] [G loss: 1.149463]\n",
      "epoch:29 step:27176 [D loss: 0.728974, acc.: 55.47%] [G loss: 1.265776]\n",
      "epoch:29 step:27177 [D loss: 0.930409, acc.: 37.50%] [G loss: 1.168805]\n",
      "epoch:29 step:27178 [D loss: 0.715384, acc.: 57.81%] [G loss: 0.985409]\n",
      "epoch:29 step:27179 [D loss: 0.798949, acc.: 45.31%] [G loss: 0.387395]\n",
      "epoch:29 step:27180 [D loss: 0.655163, acc.: 55.47%] [G loss: 1.245045]\n",
      "epoch:29 step:27181 [D loss: 0.720130, acc.: 54.69%] [G loss: 0.723379]\n",
      "epoch:29 step:27182 [D loss: 0.539311, acc.: 72.66%] [G loss: 0.559710]\n",
      "epoch:29 step:27183 [D loss: 0.466602, acc.: 78.12%] [G loss: 0.585942]\n",
      "epoch:29 step:27184 [D loss: 0.656678, acc.: 59.38%] [G loss: 1.133020]\n",
      "epoch:29 step:27185 [D loss: 0.454706, acc.: 82.03%] [G loss: 0.519210]\n",
      "epoch:29 step:27186 [D loss: 1.090492, acc.: 45.31%] [G loss: 1.242615]\n",
      "epoch:29 step:27187 [D loss: 0.976454, acc.: 32.03%] [G loss: 1.489323]\n",
      "epoch:29 step:27188 [D loss: 0.639247, acc.: 71.09%] [G loss: 1.375314]\n",
      "epoch:29 step:27189 [D loss: 0.902872, acc.: 38.28%] [G loss: 1.322679]\n",
      "epoch:29 step:27190 [D loss: 0.744996, acc.: 48.44%] [G loss: 1.318341]\n",
      "epoch:29 step:27191 [D loss: 0.729410, acc.: 53.12%] [G loss: 1.205716]\n",
      "epoch:29 step:27192 [D loss: 1.117083, acc.: 27.34%] [G loss: 1.350090]\n",
      "epoch:29 step:27193 [D loss: 0.523925, acc.: 71.88%] [G loss: 1.570496]\n",
      "epoch:29 step:27194 [D loss: 0.750470, acc.: 53.91%] [G loss: 1.644916]\n",
      "epoch:29 step:27195 [D loss: 0.751357, acc.: 50.00%] [G loss: 1.417754]\n",
      "epoch:29 step:27196 [D loss: 0.662083, acc.: 58.59%] [G loss: 1.022347]\n",
      "epoch:29 step:27197 [D loss: 0.905456, acc.: 42.19%] [G loss: 1.171985]\n",
      "epoch:29 step:27198 [D loss: 0.654835, acc.: 60.16%] [G loss: 1.046165]\n",
      "epoch:29 step:27199 [D loss: 0.502999, acc.: 76.56%] [G loss: 1.330929]\n",
      "epoch:29 step:27200 [D loss: 0.239600, acc.: 96.09%] [G loss: 1.518133]\n",
      "epoch:29 step:27201 [D loss: 0.441027, acc.: 80.47%] [G loss: 1.856547]\n",
      "epoch:29 step:27202 [D loss: 0.302965, acc.: 93.75%] [G loss: 1.791132]\n",
      "epoch:29 step:27203 [D loss: 0.370199, acc.: 89.84%] [G loss: 1.391795]\n",
      "epoch:29 step:27204 [D loss: 0.520927, acc.: 73.44%] [G loss: 1.677687]\n",
      "epoch:29 step:27205 [D loss: 0.220512, acc.: 96.09%] [G loss: 2.031010]\n",
      "epoch:29 step:27206 [D loss: 0.149512, acc.: 100.00%] [G loss: 1.577049]\n",
      "epoch:29 step:27207 [D loss: 0.169481, acc.: 99.22%] [G loss: 1.892007]\n",
      "epoch:29 step:27208 [D loss: 0.093855, acc.: 100.00%] [G loss: 2.823713]\n",
      "epoch:29 step:27209 [D loss: 0.076225, acc.: 100.00%] [G loss: 1.895444]\n",
      "epoch:29 step:27210 [D loss: 0.779433, acc.: 56.25%] [G loss: 1.437795]\n",
      "epoch:29 step:27211 [D loss: 0.925876, acc.: 50.78%] [G loss: 1.305811]\n",
      "epoch:29 step:27212 [D loss: 0.952364, acc.: 38.28%] [G loss: 1.047135]\n",
      "epoch:29 step:27213 [D loss: 0.648485, acc.: 64.06%] [G loss: 0.932896]\n",
      "epoch:29 step:27214 [D loss: 0.516843, acc.: 74.22%] [G loss: 0.892653]\n",
      "epoch:29 step:27215 [D loss: 0.447637, acc.: 78.91%] [G loss: 1.090639]\n",
      "epoch:29 step:27216 [D loss: 0.422637, acc.: 81.25%] [G loss: 1.023301]\n",
      "epoch:29 step:27217 [D loss: 0.326991, acc.: 95.31%] [G loss: 1.384112]\n",
      "epoch:29 step:27218 [D loss: 0.466215, acc.: 85.16%] [G loss: 1.224537]\n",
      "epoch:29 step:27219 [D loss: 0.473594, acc.: 84.38%] [G loss: 1.134908]\n",
      "epoch:29 step:27220 [D loss: 0.582816, acc.: 66.41%] [G loss: 1.098006]\n",
      "epoch:29 step:27221 [D loss: 0.756217, acc.: 53.91%] [G loss: 0.788637]\n",
      "epoch:29 step:27222 [D loss: 0.601950, acc.: 68.75%] [G loss: 1.114184]\n",
      "epoch:29 step:27223 [D loss: 0.400132, acc.: 89.84%] [G loss: 1.105902]\n",
      "epoch:29 step:27224 [D loss: 0.431801, acc.: 83.59%] [G loss: 0.963939]\n",
      "epoch:29 step:27225 [D loss: 0.393686, acc.: 85.16%] [G loss: 1.418105]\n",
      "epoch:29 step:27226 [D loss: 0.447183, acc.: 83.59%] [G loss: 1.568513]\n",
      "epoch:29 step:27227 [D loss: 0.675458, acc.: 55.47%] [G loss: 0.884526]\n",
      "epoch:29 step:27228 [D loss: 0.623775, acc.: 62.50%] [G loss: 0.953600]\n",
      "epoch:29 step:27229 [D loss: 0.594872, acc.: 68.75%] [G loss: 1.359598]\n",
      "epoch:29 step:27230 [D loss: 0.244268, acc.: 91.41%] [G loss: 1.150353]\n",
      "epoch:29 step:27231 [D loss: 0.346449, acc.: 84.38%] [G loss: 1.614526]\n",
      "epoch:29 step:27232 [D loss: 0.164886, acc.: 98.44%] [G loss: 1.588505]\n",
      "epoch:29 step:27233 [D loss: 0.178573, acc.: 96.09%] [G loss: 2.120228]\n",
      "epoch:29 step:27234 [D loss: 0.410407, acc.: 82.03%] [G loss: 1.798317]\n",
      "epoch:29 step:27235 [D loss: 0.482759, acc.: 81.25%] [G loss: 0.858019]\n",
      "epoch:29 step:27236 [D loss: 0.368620, acc.: 85.94%] [G loss: 2.083513]\n",
      "epoch:29 step:27237 [D loss: 0.556136, acc.: 71.09%] [G loss: 1.618286]\n",
      "epoch:29 step:27238 [D loss: 0.803437, acc.: 51.56%] [G loss: 1.694014]\n",
      "epoch:29 step:27239 [D loss: 0.851262, acc.: 50.00%] [G loss: 1.308646]\n",
      "epoch:29 step:27240 [D loss: 0.410107, acc.: 84.38%] [G loss: 1.755583]\n",
      "epoch:29 step:27241 [D loss: 0.720420, acc.: 59.38%] [G loss: 1.321729]\n",
      "epoch:29 step:27242 [D loss: 1.271464, acc.: 21.09%] [G loss: 1.191093]\n",
      "epoch:29 step:27243 [D loss: 0.718157, acc.: 57.03%] [G loss: 0.767777]\n",
      "epoch:29 step:27244 [D loss: 0.427215, acc.: 72.66%] [G loss: 1.448985]\n",
      "epoch:29 step:27245 [D loss: 0.251649, acc.: 87.50%] [G loss: 1.924659]\n",
      "epoch:29 step:27246 [D loss: 0.239011, acc.: 96.09%] [G loss: 1.544237]\n",
      "epoch:29 step:27247 [D loss: 0.641276, acc.: 67.97%] [G loss: 1.720845]\n",
      "epoch:29 step:27248 [D loss: 0.124301, acc.: 100.00%] [G loss: 1.810904]\n",
      "epoch:29 step:27249 [D loss: 0.104539, acc.: 98.44%] [G loss: 2.340805]\n",
      "epoch:29 step:27250 [D loss: 0.195420, acc.: 97.66%] [G loss: 2.020879]\n",
      "epoch:29 step:27251 [D loss: 1.193285, acc.: 45.31%] [G loss: 1.315491]\n",
      "epoch:29 step:27252 [D loss: 0.848464, acc.: 50.00%] [G loss: 1.459086]\n",
      "epoch:29 step:27253 [D loss: 0.779945, acc.: 53.12%] [G loss: 0.477619]\n",
      "epoch:29 step:27254 [D loss: 0.721762, acc.: 57.81%] [G loss: 1.275169]\n",
      "epoch:29 step:27255 [D loss: 0.680762, acc.: 64.06%] [G loss: 1.029990]\n",
      "epoch:29 step:27256 [D loss: 0.814279, acc.: 42.19%] [G loss: 1.111370]\n",
      "epoch:29 step:27257 [D loss: 0.729273, acc.: 60.16%] [G loss: 0.960202]\n",
      "epoch:29 step:27258 [D loss: 0.528850, acc.: 80.47%] [G loss: 1.172073]\n",
      "epoch:29 step:27259 [D loss: 0.683093, acc.: 64.06%] [G loss: 0.926524]\n",
      "epoch:29 step:27260 [D loss: 0.726205, acc.: 51.56%] [G loss: 1.181942]\n",
      "epoch:29 step:27261 [D loss: 0.606005, acc.: 71.09%] [G loss: 1.007123]\n",
      "epoch:29 step:27262 [D loss: 0.552503, acc.: 78.12%] [G loss: 1.002241]\n",
      "epoch:29 step:27263 [D loss: 0.645561, acc.: 64.84%] [G loss: 0.733762]\n",
      "epoch:29 step:27264 [D loss: 0.669590, acc.: 56.25%] [G loss: 0.869770]\n",
      "epoch:29 step:27265 [D loss: 0.836009, acc.: 41.41%] [G loss: 0.665096]\n",
      "epoch:29 step:27266 [D loss: 0.530772, acc.: 78.91%] [G loss: 0.939455]\n",
      "epoch:29 step:27267 [D loss: 0.684327, acc.: 57.03%] [G loss: 0.729979]\n",
      "epoch:29 step:27268 [D loss: 0.500834, acc.: 78.91%] [G loss: 1.097970]\n",
      "epoch:29 step:27269 [D loss: 0.729524, acc.: 47.66%] [G loss: 1.266664]\n",
      "epoch:29 step:27270 [D loss: 0.573705, acc.: 71.09%] [G loss: 1.188768]\n",
      "epoch:29 step:27271 [D loss: 0.590586, acc.: 67.19%] [G loss: 1.148304]\n",
      "epoch:29 step:27272 [D loss: 0.541733, acc.: 74.22%] [G loss: 0.926607]\n",
      "epoch:29 step:27273 [D loss: 0.437344, acc.: 79.69%] [G loss: 0.915850]\n",
      "epoch:29 step:27274 [D loss: 0.915173, acc.: 37.50%] [G loss: 0.623190]\n",
      "epoch:29 step:27275 [D loss: 0.833423, acc.: 42.19%] [G loss: 1.207562]\n",
      "epoch:29 step:27276 [D loss: 0.748629, acc.: 53.12%] [G loss: 1.244116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27277 [D loss: 0.638265, acc.: 61.72%] [G loss: 1.006644]\n",
      "epoch:29 step:27278 [D loss: 0.653122, acc.: 66.41%] [G loss: 1.152275]\n",
      "epoch:29 step:27279 [D loss: 0.612773, acc.: 67.19%] [G loss: 0.748274]\n",
      "epoch:29 step:27280 [D loss: 0.632124, acc.: 64.06%] [G loss: 0.698557]\n",
      "epoch:29 step:27281 [D loss: 0.961077, acc.: 32.81%] [G loss: 1.076697]\n",
      "epoch:29 step:27282 [D loss: 0.655448, acc.: 58.59%] [G loss: 1.072674]\n",
      "epoch:29 step:27283 [D loss: 0.719717, acc.: 51.56%] [G loss: 1.160696]\n",
      "epoch:29 step:27284 [D loss: 0.496837, acc.: 79.69%] [G loss: 1.259096]\n",
      "epoch:29 step:27285 [D loss: 0.482919, acc.: 75.00%] [G loss: 1.227531]\n",
      "epoch:29 step:27286 [D loss: 0.356997, acc.: 89.06%] [G loss: 1.514301]\n",
      "epoch:29 step:27287 [D loss: 0.346070, acc.: 93.75%] [G loss: 1.791803]\n",
      "epoch:29 step:27288 [D loss: 0.382250, acc.: 90.62%] [G loss: 1.731913]\n",
      "epoch:29 step:27289 [D loss: 0.580568, acc.: 67.19%] [G loss: 1.575063]\n",
      "epoch:29 step:27290 [D loss: 0.621189, acc.: 64.06%] [G loss: 1.082368]\n",
      "epoch:29 step:27291 [D loss: 0.639305, acc.: 69.53%] [G loss: 0.970556]\n",
      "epoch:29 step:27292 [D loss: 0.415026, acc.: 75.78%] [G loss: 1.100547]\n",
      "epoch:29 step:27293 [D loss: 0.336452, acc.: 90.62%] [G loss: 1.259525]\n",
      "epoch:29 step:27294 [D loss: 0.250011, acc.: 89.06%] [G loss: 1.561227]\n",
      "epoch:29 step:27295 [D loss: 0.172685, acc.: 98.44%] [G loss: 1.531337]\n",
      "epoch:29 step:27296 [D loss: 0.421010, acc.: 81.25%] [G loss: 1.607385]\n",
      "epoch:29 step:27297 [D loss: 0.649219, acc.: 57.81%] [G loss: 1.307489]\n",
      "epoch:29 step:27298 [D loss: 0.747513, acc.: 53.12%] [G loss: 1.320873]\n",
      "epoch:29 step:27299 [D loss: 0.620653, acc.: 63.28%] [G loss: 1.135520]\n",
      "epoch:29 step:27300 [D loss: 0.654950, acc.: 61.72%] [G loss: 0.922360]\n",
      "epoch:29 step:27301 [D loss: 0.570708, acc.: 75.78%] [G loss: 0.945740]\n",
      "epoch:29 step:27302 [D loss: 0.261688, acc.: 91.41%] [G loss: 1.199051]\n",
      "epoch:29 step:27303 [D loss: 0.290670, acc.: 89.06%] [G loss: 1.631185]\n",
      "epoch:29 step:27304 [D loss: 0.218320, acc.: 96.88%] [G loss: 1.136905]\n",
      "epoch:29 step:27305 [D loss: 0.282249, acc.: 93.75%] [G loss: 1.031996]\n",
      "epoch:29 step:27306 [D loss: 0.788253, acc.: 51.56%] [G loss: 1.404373]\n",
      "epoch:29 step:27307 [D loss: 0.808689, acc.: 46.88%] [G loss: 1.285429]\n",
      "epoch:29 step:27308 [D loss: 0.778805, acc.: 57.03%] [G loss: 0.868841]\n",
      "epoch:29 step:27309 [D loss: 0.658928, acc.: 62.50%] [G loss: 1.165487]\n",
      "epoch:29 step:27310 [D loss: 0.526312, acc.: 74.22%] [G loss: 1.123907]\n",
      "epoch:29 step:27311 [D loss: 0.449903, acc.: 84.38%] [G loss: 1.226647]\n",
      "epoch:29 step:27312 [D loss: 0.401322, acc.: 86.72%] [G loss: 1.021701]\n",
      "epoch:29 step:27313 [D loss: 0.627650, acc.: 67.19%] [G loss: 1.260807]\n",
      "epoch:29 step:27314 [D loss: 0.829086, acc.: 53.91%] [G loss: 1.379043]\n",
      "epoch:29 step:27315 [D loss: 0.760885, acc.: 46.88%] [G loss: 1.066855]\n",
      "epoch:29 step:27316 [D loss: 0.669000, acc.: 56.25%] [G loss: 1.274225]\n",
      "epoch:29 step:27317 [D loss: 0.517892, acc.: 71.88%] [G loss: 1.018789]\n",
      "epoch:29 step:27318 [D loss: 0.430443, acc.: 75.00%] [G loss: 1.096926]\n",
      "epoch:29 step:27319 [D loss: 0.587704, acc.: 71.09%] [G loss: 1.313988]\n",
      "epoch:29 step:27320 [D loss: 0.775298, acc.: 48.44%] [G loss: 1.251950]\n",
      "epoch:29 step:27321 [D loss: 0.699944, acc.: 60.16%] [G loss: 1.130529]\n",
      "epoch:29 step:27322 [D loss: 0.625821, acc.: 64.06%] [G loss: 1.104355]\n",
      "epoch:29 step:27323 [D loss: 0.263327, acc.: 89.84%] [G loss: 1.209069]\n",
      "epoch:29 step:27324 [D loss: 0.299459, acc.: 89.06%] [G loss: 1.510798]\n",
      "epoch:29 step:27325 [D loss: 0.383315, acc.: 87.50%] [G loss: 1.373230]\n",
      "epoch:29 step:27326 [D loss: 0.677793, acc.: 67.97%] [G loss: 1.341165]\n",
      "epoch:29 step:27327 [D loss: 0.663902, acc.: 60.94%] [G loss: 1.265976]\n",
      "epoch:29 step:27328 [D loss: 0.604576, acc.: 64.84%] [G loss: 1.235297]\n",
      "epoch:29 step:27329 [D loss: 0.497514, acc.: 76.56%] [G loss: 1.226122]\n",
      "epoch:29 step:27330 [D loss: 0.716797, acc.: 53.91%] [G loss: 1.023097]\n",
      "epoch:29 step:27331 [D loss: 0.724395, acc.: 59.38%] [G loss: 1.233117]\n",
      "epoch:29 step:27332 [D loss: 0.486463, acc.: 78.12%] [G loss: 1.187654]\n",
      "epoch:29 step:27333 [D loss: 0.581739, acc.: 65.62%] [G loss: 1.325820]\n",
      "epoch:29 step:27334 [D loss: 0.623182, acc.: 68.75%] [G loss: 0.947042]\n",
      "epoch:29 step:27335 [D loss: 0.614331, acc.: 65.62%] [G loss: 1.105104]\n",
      "epoch:29 step:27336 [D loss: 0.677860, acc.: 60.94%] [G loss: 1.024122]\n",
      "epoch:29 step:27337 [D loss: 0.811685, acc.: 43.75%] [G loss: 1.054800]\n",
      "epoch:29 step:27338 [D loss: 0.613612, acc.: 69.53%] [G loss: 0.875414]\n",
      "epoch:29 step:27339 [D loss: 0.618277, acc.: 67.19%] [G loss: 1.000471]\n",
      "epoch:29 step:27340 [D loss: 0.629537, acc.: 66.41%] [G loss: 0.815255]\n",
      "epoch:29 step:27341 [D loss: 0.504000, acc.: 71.88%] [G loss: 1.050647]\n",
      "epoch:29 step:27342 [D loss: 0.652862, acc.: 61.72%] [G loss: 1.010656]\n",
      "epoch:29 step:27343 [D loss: 0.651165, acc.: 58.59%] [G loss: 1.163439]\n",
      "epoch:29 step:27344 [D loss: 0.665921, acc.: 60.94%] [G loss: 0.967088]\n",
      "epoch:29 step:27345 [D loss: 0.514717, acc.: 77.34%] [G loss: 1.364704]\n",
      "epoch:29 step:27346 [D loss: 0.623349, acc.: 67.97%] [G loss: 0.957637]\n",
      "epoch:29 step:27347 [D loss: 0.616745, acc.: 68.75%] [G loss: 1.051320]\n",
      "epoch:29 step:27348 [D loss: 0.669969, acc.: 58.59%] [G loss: 0.771194]\n",
      "epoch:29 step:27349 [D loss: 0.680874, acc.: 58.59%] [G loss: 0.752457]\n",
      "epoch:29 step:27350 [D loss: 0.628684, acc.: 64.84%] [G loss: 1.079416]\n",
      "epoch:29 step:27351 [D loss: 0.610558, acc.: 70.31%] [G loss: 1.017476]\n",
      "epoch:29 step:27352 [D loss: 0.586209, acc.: 71.09%] [G loss: 0.859216]\n",
      "epoch:29 step:27353 [D loss: 0.573950, acc.: 75.00%] [G loss: 1.161010]\n",
      "epoch:29 step:27354 [D loss: 0.594999, acc.: 65.62%] [G loss: 1.153734]\n",
      "epoch:29 step:27355 [D loss: 0.635392, acc.: 66.41%] [G loss: 1.101820]\n",
      "epoch:29 step:27356 [D loss: 0.668802, acc.: 62.50%] [G loss: 1.153559]\n",
      "epoch:29 step:27357 [D loss: 0.585285, acc.: 67.19%] [G loss: 0.974551]\n",
      "epoch:29 step:27358 [D loss: 0.428463, acc.: 80.47%] [G loss: 1.082258]\n",
      "epoch:29 step:27359 [D loss: 0.629676, acc.: 62.50%] [G loss: 1.130800]\n",
      "epoch:29 step:27360 [D loss: 0.713343, acc.: 59.38%] [G loss: 1.063755]\n",
      "epoch:29 step:27361 [D loss: 0.737586, acc.: 53.12%] [G loss: 1.043528]\n",
      "epoch:29 step:27362 [D loss: 0.596332, acc.: 66.41%] [G loss: 1.171458]\n",
      "epoch:29 step:27363 [D loss: 0.709966, acc.: 56.25%] [G loss: 1.088717]\n",
      "epoch:29 step:27364 [D loss: 0.626760, acc.: 63.28%] [G loss: 1.011703]\n",
      "epoch:29 step:27365 [D loss: 0.375594, acc.: 86.72%] [G loss: 1.005899]\n",
      "epoch:29 step:27366 [D loss: 0.467197, acc.: 82.03%] [G loss: 1.025545]\n",
      "epoch:29 step:27367 [D loss: 0.522373, acc.: 79.69%] [G loss: 1.089202]\n",
      "epoch:29 step:27368 [D loss: 0.496411, acc.: 72.66%] [G loss: 1.038011]\n",
      "epoch:29 step:27369 [D loss: 0.657951, acc.: 58.59%] [G loss: 1.161054]\n",
      "epoch:29 step:27370 [D loss: 0.588854, acc.: 67.97%] [G loss: 1.264482]\n",
      "epoch:29 step:27371 [D loss: 0.612202, acc.: 64.84%] [G loss: 1.154626]\n",
      "epoch:29 step:27372 [D loss: 0.699250, acc.: 53.12%] [G loss: 1.454801]\n",
      "epoch:29 step:27373 [D loss: 0.269731, acc.: 93.75%] [G loss: 1.380211]\n",
      "epoch:29 step:27374 [D loss: 0.167897, acc.: 100.00%] [G loss: 1.459637]\n",
      "epoch:29 step:27375 [D loss: 0.794201, acc.: 48.44%] [G loss: 0.724538]\n",
      "epoch:29 step:27376 [D loss: 0.478180, acc.: 78.91%] [G loss: 1.182369]\n",
      "epoch:29 step:27377 [D loss: 0.248427, acc.: 94.53%] [G loss: 1.305466]\n",
      "epoch:29 step:27378 [D loss: 0.488313, acc.: 82.81%] [G loss: 1.484524]\n",
      "epoch:29 step:27379 [D loss: 0.261844, acc.: 96.88%] [G loss: 1.116602]\n",
      "epoch:29 step:27380 [D loss: 0.263987, acc.: 89.84%] [G loss: 1.526192]\n",
      "epoch:29 step:27381 [D loss: 0.371243, acc.: 92.19%] [G loss: 1.536746]\n",
      "epoch:29 step:27382 [D loss: 0.274233, acc.: 94.53%] [G loss: 1.405055]\n",
      "epoch:29 step:27383 [D loss: 0.850267, acc.: 49.22%] [G loss: 1.228645]\n",
      "epoch:29 step:27384 [D loss: 0.881695, acc.: 45.31%] [G loss: 1.217985]\n",
      "epoch:29 step:27385 [D loss: 0.709001, acc.: 56.25%] [G loss: 1.133647]\n",
      "epoch:29 step:27386 [D loss: 0.773367, acc.: 53.12%] [G loss: 1.030084]\n",
      "epoch:29 step:27387 [D loss: 0.974078, acc.: 32.03%] [G loss: 1.285989]\n",
      "epoch:29 step:27388 [D loss: 0.795208, acc.: 47.66%] [G loss: 1.161774]\n",
      "epoch:29 step:27389 [D loss: 0.743545, acc.: 53.91%] [G loss: 1.249834]\n",
      "epoch:29 step:27390 [D loss: 0.629947, acc.: 61.72%] [G loss: 1.054519]\n",
      "epoch:29 step:27391 [D loss: 0.323666, acc.: 91.41%] [G loss: 1.092802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27392 [D loss: 0.390981, acc.: 87.50%] [G loss: 1.226643]\n",
      "epoch:29 step:27393 [D loss: 0.277323, acc.: 89.84%] [G loss: 1.825513]\n",
      "epoch:29 step:27394 [D loss: 0.266269, acc.: 91.41%] [G loss: 1.022864]\n",
      "epoch:29 step:27395 [D loss: 0.392565, acc.: 83.59%] [G loss: 1.772857]\n",
      "epoch:29 step:27396 [D loss: 0.206602, acc.: 95.31%] [G loss: 1.611487]\n",
      "epoch:29 step:27397 [D loss: 0.686430, acc.: 52.34%] [G loss: 1.797147]\n",
      "epoch:29 step:27398 [D loss: 0.651872, acc.: 67.19%] [G loss: 1.435722]\n",
      "epoch:29 step:27399 [D loss: 0.585655, acc.: 67.97%] [G loss: 1.294906]\n",
      "epoch:29 step:27400 [D loss: 0.514670, acc.: 77.34%] [G loss: 1.383501]\n",
      "epoch:29 step:27401 [D loss: 0.488579, acc.: 85.94%] [G loss: 1.238329]\n",
      "epoch:29 step:27402 [D loss: 0.636795, acc.: 63.28%] [G loss: 1.137698]\n",
      "epoch:29 step:27403 [D loss: 0.233739, acc.: 91.41%] [G loss: 0.998146]\n",
      "epoch:29 step:27404 [D loss: 0.203184, acc.: 96.09%] [G loss: 1.421261]\n",
      "epoch:29 step:27405 [D loss: 0.195244, acc.: 95.31%] [G loss: 1.362351]\n",
      "epoch:29 step:27406 [D loss: 0.559501, acc.: 72.66%] [G loss: 1.327206]\n",
      "epoch:29 step:27407 [D loss: 0.398875, acc.: 92.97%] [G loss: 1.644360]\n",
      "epoch:29 step:27408 [D loss: 0.219390, acc.: 94.53%] [G loss: 1.651473]\n",
      "epoch:29 step:27409 [D loss: 0.511797, acc.: 77.34%] [G loss: 1.458127]\n",
      "epoch:29 step:27410 [D loss: 0.497369, acc.: 75.78%] [G loss: 1.889139]\n",
      "epoch:29 step:27411 [D loss: 0.263460, acc.: 93.75%] [G loss: 1.179291]\n",
      "epoch:29 step:27412 [D loss: 0.354668, acc.: 90.62%] [G loss: 1.395947]\n",
      "epoch:29 step:27413 [D loss: 0.464931, acc.: 81.25%] [G loss: 1.445724]\n",
      "epoch:29 step:27414 [D loss: 0.863156, acc.: 46.09%] [G loss: 0.994026]\n",
      "epoch:29 step:27415 [D loss: 0.590923, acc.: 64.06%] [G loss: 0.583313]\n",
      "epoch:29 step:27416 [D loss: 0.365180, acc.: 81.25%] [G loss: 1.435511]\n",
      "epoch:29 step:27417 [D loss: 0.631885, acc.: 64.06%] [G loss: 0.963409]\n",
      "epoch:29 step:27418 [D loss: 0.932342, acc.: 43.75%] [G loss: 1.098859]\n",
      "epoch:29 step:27419 [D loss: 0.749730, acc.: 52.34%] [G loss: 0.928890]\n",
      "epoch:29 step:27420 [D loss: 0.790735, acc.: 46.88%] [G loss: 1.199183]\n",
      "epoch:29 step:27421 [D loss: 0.695476, acc.: 60.16%] [G loss: 1.071553]\n",
      "epoch:29 step:27422 [D loss: 0.693254, acc.: 60.16%] [G loss: 1.371668]\n",
      "epoch:29 step:27423 [D loss: 0.713888, acc.: 60.16%] [G loss: 1.145984]\n",
      "epoch:29 step:27424 [D loss: 0.703749, acc.: 57.81%] [G loss: 1.151315]\n",
      "epoch:29 step:27425 [D loss: 0.670852, acc.: 57.03%] [G loss: 1.013060]\n",
      "epoch:29 step:27426 [D loss: 0.888382, acc.: 39.06%] [G loss: 1.022207]\n",
      "epoch:29 step:27427 [D loss: 0.648233, acc.: 66.41%] [G loss: 1.066367]\n",
      "epoch:29 step:27428 [D loss: 0.242336, acc.: 92.97%] [G loss: 0.987037]\n",
      "epoch:29 step:27429 [D loss: 0.190247, acc.: 95.31%] [G loss: 1.212961]\n",
      "epoch:29 step:27430 [D loss: 0.280690, acc.: 89.84%] [G loss: 1.424396]\n",
      "epoch:29 step:27431 [D loss: 0.459593, acc.: 78.91%] [G loss: 1.358234]\n",
      "epoch:29 step:27432 [D loss: 0.254373, acc.: 87.50%] [G loss: 1.638608]\n",
      "epoch:29 step:27433 [D loss: 0.215505, acc.: 97.66%] [G loss: 1.529029]\n",
      "epoch:29 step:27434 [D loss: 0.225979, acc.: 93.75%] [G loss: 1.277137]\n",
      "epoch:29 step:27435 [D loss: 0.667197, acc.: 58.59%] [G loss: 1.475928]\n",
      "epoch:29 step:27436 [D loss: 0.230333, acc.: 90.62%] [G loss: 1.564043]\n",
      "epoch:29 step:27437 [D loss: 0.510895, acc.: 75.00%] [G loss: 1.689573]\n",
      "epoch:29 step:27438 [D loss: 0.736216, acc.: 53.12%] [G loss: 1.485861]\n",
      "epoch:29 step:27439 [D loss: 0.764573, acc.: 51.56%] [G loss: 1.657166]\n",
      "epoch:29 step:27440 [D loss: 0.631048, acc.: 64.06%] [G loss: 1.347523]\n",
      "epoch:29 step:27441 [D loss: 0.639345, acc.: 62.50%] [G loss: 1.076541]\n",
      "epoch:29 step:27442 [D loss: 0.452448, acc.: 83.59%] [G loss: 0.344237]\n",
      "epoch:29 step:27443 [D loss: 0.781185, acc.: 47.66%] [G loss: 1.002012]\n",
      "epoch:29 step:27444 [D loss: 0.365377, acc.: 88.28%] [G loss: 0.961979]\n",
      "epoch:29 step:27445 [D loss: 0.427944, acc.: 85.94%] [G loss: 1.452326]\n",
      "epoch:29 step:27446 [D loss: 0.516702, acc.: 74.22%] [G loss: 1.494929]\n",
      "epoch:29 step:27447 [D loss: 0.378091, acc.: 88.28%] [G loss: 1.904369]\n",
      "epoch:29 step:27448 [D loss: 0.344053, acc.: 91.41%] [G loss: 1.555328]\n",
      "epoch:29 step:27449 [D loss: 0.335832, acc.: 92.19%] [G loss: 1.677826]\n",
      "epoch:29 step:27450 [D loss: 0.443349, acc.: 76.56%] [G loss: 1.446399]\n",
      "epoch:29 step:27451 [D loss: 0.370715, acc.: 85.16%] [G loss: 1.727367]\n",
      "epoch:29 step:27452 [D loss: 0.127197, acc.: 99.22%] [G loss: 1.566754]\n",
      "epoch:29 step:27453 [D loss: 0.609451, acc.: 70.31%] [G loss: 1.527812]\n",
      "epoch:29 step:27454 [D loss: 1.059586, acc.: 32.03%] [G loss: 1.441940]\n",
      "epoch:29 step:27455 [D loss: 0.344431, acc.: 89.06%] [G loss: 1.664586]\n",
      "epoch:29 step:27456 [D loss: 0.757652, acc.: 53.91%] [G loss: 1.536096]\n",
      "epoch:29 step:27457 [D loss: 0.690547, acc.: 57.03%] [G loss: 1.230169]\n",
      "epoch:29 step:27458 [D loss: 0.476808, acc.: 80.47%] [G loss: 1.028396]\n",
      "epoch:29 step:27459 [D loss: 0.522351, acc.: 72.66%] [G loss: 1.398188]\n",
      "epoch:29 step:27460 [D loss: 0.692568, acc.: 57.81%] [G loss: 1.380625]\n",
      "epoch:29 step:27461 [D loss: 0.814283, acc.: 55.47%] [G loss: 1.409938]\n",
      "epoch:29 step:27462 [D loss: 0.571227, acc.: 66.41%] [G loss: 1.156502]\n",
      "epoch:29 step:27463 [D loss: 0.730952, acc.: 59.38%] [G loss: 1.116823]\n",
      "epoch:29 step:27464 [D loss: 0.559377, acc.: 68.75%] [G loss: 1.314163]\n",
      "epoch:29 step:27465 [D loss: 0.703278, acc.: 60.94%] [G loss: 0.692814]\n",
      "epoch:29 step:27466 [D loss: 0.724147, acc.: 52.34%] [G loss: 1.739140]\n",
      "epoch:29 step:27467 [D loss: 0.801116, acc.: 49.22%] [G loss: 0.960837]\n",
      "epoch:29 step:27468 [D loss: 0.563915, acc.: 78.12%] [G loss: 1.254797]\n",
      "epoch:29 step:27469 [D loss: 0.591043, acc.: 71.88%] [G loss: 0.558570]\n",
      "epoch:29 step:27470 [D loss: 0.584633, acc.: 67.97%] [G loss: 0.854223]\n",
      "epoch:29 step:27471 [D loss: 0.276485, acc.: 89.06%] [G loss: 1.415361]\n",
      "epoch:29 step:27472 [D loss: 0.199010, acc.: 93.75%] [G loss: 1.398608]\n",
      "epoch:29 step:27473 [D loss: 0.463377, acc.: 80.47%] [G loss: 1.179743]\n",
      "epoch:29 step:27474 [D loss: 0.637180, acc.: 62.50%] [G loss: 1.678960]\n",
      "epoch:29 step:27475 [D loss: 0.650660, acc.: 54.69%] [G loss: 1.538920]\n",
      "epoch:29 step:27476 [D loss: 0.460870, acc.: 81.25%] [G loss: 1.666511]\n",
      "epoch:29 step:27477 [D loss: 0.759113, acc.: 54.69%] [G loss: 1.309333]\n",
      "epoch:29 step:27478 [D loss: 0.786048, acc.: 48.44%] [G loss: 0.995822]\n",
      "epoch:29 step:27479 [D loss: 0.573973, acc.: 65.62%] [G loss: 1.271509]\n",
      "epoch:29 step:27480 [D loss: 0.401551, acc.: 91.41%] [G loss: 1.089175]\n",
      "epoch:29 step:27481 [D loss: 0.720120, acc.: 56.25%] [G loss: 0.831927]\n",
      "epoch:29 step:27482 [D loss: 0.667614, acc.: 54.69%] [G loss: 0.998206]\n",
      "epoch:29 step:27483 [D loss: 0.665287, acc.: 57.03%] [G loss: 1.147627]\n",
      "epoch:29 step:27484 [D loss: 0.685710, acc.: 60.16%] [G loss: 0.962484]\n",
      "epoch:29 step:27485 [D loss: 0.463921, acc.: 75.00%] [G loss: 0.669268]\n",
      "epoch:29 step:27486 [D loss: 0.740672, acc.: 42.97%] [G loss: 0.728051]\n",
      "epoch:29 step:27487 [D loss: 0.374049, acc.: 78.91%] [G loss: 0.935721]\n",
      "epoch:29 step:27488 [D loss: 0.661303, acc.: 57.03%] [G loss: 0.856423]\n",
      "epoch:29 step:27489 [D loss: 0.397460, acc.: 85.94%] [G loss: 1.184714]\n",
      "epoch:29 step:27490 [D loss: 0.442521, acc.: 86.72%] [G loss: 1.042657]\n",
      "epoch:29 step:27491 [D loss: 0.360501, acc.: 85.94%] [G loss: 1.268718]\n",
      "epoch:29 step:27492 [D loss: 0.404153, acc.: 88.28%] [G loss: 0.888098]\n",
      "epoch:29 step:27493 [D loss: 0.287057, acc.: 95.31%] [G loss: 1.151841]\n",
      "epoch:29 step:27494 [D loss: 0.317587, acc.: 84.38%] [G loss: 1.699659]\n",
      "epoch:29 step:27495 [D loss: 0.292592, acc.: 95.31%] [G loss: 1.542032]\n",
      "epoch:29 step:27496 [D loss: 0.753571, acc.: 56.25%] [G loss: 1.108978]\n",
      "epoch:29 step:27497 [D loss: 0.692314, acc.: 53.91%] [G loss: 1.352227]\n",
      "epoch:29 step:27498 [D loss: 0.541241, acc.: 74.22%] [G loss: 1.232573]\n",
      "epoch:29 step:27499 [D loss: 0.410939, acc.: 79.69%] [G loss: 1.068137]\n",
      "epoch:29 step:27500 [D loss: 0.195637, acc.: 97.66%] [G loss: 1.617078]\n",
      "epoch:29 step:27501 [D loss: 0.178158, acc.: 96.88%] [G loss: 1.482085]\n",
      "epoch:29 step:27502 [D loss: 0.492295, acc.: 77.34%] [G loss: 1.644216]\n",
      "epoch:29 step:27503 [D loss: 0.830106, acc.: 53.12%] [G loss: 1.673161]\n",
      "epoch:29 step:27504 [D loss: 0.600171, acc.: 64.84%] [G loss: 1.009690]\n",
      "epoch:29 step:27505 [D loss: 0.624926, acc.: 59.38%] [G loss: 1.065075]\n",
      "epoch:29 step:27506 [D loss: 0.675183, acc.: 53.91%] [G loss: 0.868890]\n",
      "epoch:29 step:27507 [D loss: 0.816936, acc.: 39.84%] [G loss: 1.184879]\n",
      "epoch:29 step:27508 [D loss: 0.703273, acc.: 55.47%] [G loss: 1.191842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27509 [D loss: 0.528143, acc.: 75.00%] [G loss: 0.679264]\n",
      "epoch:29 step:27510 [D loss: 0.705183, acc.: 52.34%] [G loss: 1.250865]\n",
      "epoch:29 step:27511 [D loss: 0.482732, acc.: 84.38%] [G loss: 1.212166]\n",
      "epoch:29 step:27512 [D loss: 0.464833, acc.: 79.69%] [G loss: 0.956429]\n",
      "epoch:29 step:27513 [D loss: 0.714336, acc.: 55.47%] [G loss: 1.034007]\n",
      "epoch:29 step:27514 [D loss: 0.639760, acc.: 57.03%] [G loss: 0.971047]\n",
      "epoch:29 step:27515 [D loss: 0.488299, acc.: 74.22%] [G loss: 1.183112]\n",
      "epoch:29 step:27516 [D loss: 0.237159, acc.: 93.75%] [G loss: 1.250573]\n",
      "epoch:29 step:27517 [D loss: 0.348476, acc.: 90.62%] [G loss: 1.266120]\n",
      "epoch:29 step:27518 [D loss: 0.337906, acc.: 83.59%] [G loss: 1.474055]\n",
      "epoch:29 step:27519 [D loss: 0.236852, acc.: 98.44%] [G loss: 1.516575]\n",
      "epoch:29 step:27520 [D loss: 0.260942, acc.: 90.62%] [G loss: 1.533380]\n",
      "epoch:29 step:27521 [D loss: 0.887334, acc.: 50.78%] [G loss: 1.202694]\n",
      "epoch:29 step:27522 [D loss: 0.482092, acc.: 83.59%] [G loss: 1.332823]\n",
      "epoch:29 step:27523 [D loss: 0.653731, acc.: 61.72%] [G loss: 1.059703]\n",
      "epoch:29 step:27524 [D loss: 0.320909, acc.: 90.62%] [G loss: 0.554841]\n",
      "epoch:29 step:27525 [D loss: 0.312072, acc.: 90.62%] [G loss: 1.292297]\n",
      "epoch:29 step:27526 [D loss: 0.289066, acc.: 91.41%] [G loss: 1.704100]\n",
      "epoch:29 step:27527 [D loss: 0.302246, acc.: 92.97%] [G loss: 1.949362]\n",
      "epoch:29 step:27528 [D loss: 0.698149, acc.: 54.69%] [G loss: 0.777720]\n",
      "epoch:29 step:27529 [D loss: 0.738265, acc.: 55.47%] [G loss: 1.081811]\n",
      "epoch:29 step:27530 [D loss: 0.615418, acc.: 68.75%] [G loss: 1.347255]\n",
      "epoch:29 step:27531 [D loss: 0.506611, acc.: 71.09%] [G loss: 1.110424]\n",
      "epoch:29 step:27532 [D loss: 0.337277, acc.: 94.53%] [G loss: 1.043024]\n",
      "epoch:29 step:27533 [D loss: 0.463102, acc.: 81.25%] [G loss: 0.641208]\n",
      "epoch:29 step:27534 [D loss: 0.814865, acc.: 47.66%] [G loss: 1.279086]\n",
      "epoch:29 step:27535 [D loss: 0.977654, acc.: 35.16%] [G loss: 1.536159]\n",
      "epoch:29 step:27536 [D loss: 0.688266, acc.: 60.94%] [G loss: 0.920319]\n",
      "epoch:29 step:27537 [D loss: 1.038070, acc.: 27.34%] [G loss: 1.230109]\n",
      "epoch:29 step:27538 [D loss: 0.472945, acc.: 82.03%] [G loss: 1.656610]\n",
      "epoch:29 step:27539 [D loss: 0.168078, acc.: 96.88%] [G loss: 2.054675]\n",
      "epoch:29 step:27540 [D loss: 0.162420, acc.: 96.88%] [G loss: 1.542895]\n",
      "epoch:29 step:27541 [D loss: 0.880994, acc.: 53.12%] [G loss: 1.805569]\n",
      "epoch:29 step:27542 [D loss: 0.878803, acc.: 50.00%] [G loss: 1.361816]\n",
      "epoch:29 step:27543 [D loss: 0.440667, acc.: 84.38%] [G loss: 1.417055]\n",
      "epoch:29 step:27544 [D loss: 0.696968, acc.: 66.41%] [G loss: 1.148057]\n",
      "epoch:29 step:27545 [D loss: 1.016592, acc.: 36.72%] [G loss: 1.005567]\n",
      "epoch:29 step:27546 [D loss: 0.582589, acc.: 71.09%] [G loss: 1.266573]\n",
      "epoch:29 step:27547 [D loss: 0.717999, acc.: 56.25%] [G loss: 1.473365]\n",
      "epoch:29 step:27548 [D loss: 0.631217, acc.: 59.38%] [G loss: 1.348876]\n",
      "epoch:29 step:27549 [D loss: 0.826342, acc.: 52.34%] [G loss: 1.387531]\n",
      "epoch:29 step:27550 [D loss: 0.323255, acc.: 85.16%] [G loss: 1.233914]\n",
      "epoch:29 step:27551 [D loss: 0.234552, acc.: 94.53%] [G loss: 1.533472]\n",
      "epoch:29 step:27552 [D loss: 0.787197, acc.: 48.44%] [G loss: 1.392062]\n",
      "epoch:29 step:27553 [D loss: 0.599828, acc.: 67.97%] [G loss: 1.101935]\n",
      "epoch:29 step:27554 [D loss: 0.607188, acc.: 71.09%] [G loss: 1.177595]\n",
      "epoch:29 step:27555 [D loss: 0.736416, acc.: 50.00%] [G loss: 1.192854]\n",
      "epoch:29 step:27556 [D loss: 0.515611, acc.: 81.25%] [G loss: 0.939074]\n",
      "epoch:29 step:27557 [D loss: 0.618337, acc.: 65.62%] [G loss: 1.139505]\n",
      "epoch:29 step:27558 [D loss: 0.581300, acc.: 70.31%] [G loss: 1.141499]\n",
      "epoch:29 step:27559 [D loss: 0.691558, acc.: 57.81%] [G loss: 1.360482]\n",
      "epoch:29 step:27560 [D loss: 0.583946, acc.: 71.09%] [G loss: 1.102186]\n",
      "epoch:29 step:27561 [D loss: 0.586919, acc.: 67.97%] [G loss: 1.208302]\n",
      "epoch:29 step:27562 [D loss: 0.440651, acc.: 84.38%] [G loss: 1.098244]\n",
      "epoch:29 step:27563 [D loss: 0.442858, acc.: 85.16%] [G loss: 1.145762]\n",
      "epoch:29 step:27564 [D loss: 0.555686, acc.: 71.88%] [G loss: 1.322571]\n",
      "epoch:29 step:27565 [D loss: 0.475820, acc.: 82.81%] [G loss: 1.329145]\n",
      "epoch:29 step:27566 [D loss: 0.284997, acc.: 92.97%] [G loss: 1.390051]\n",
      "epoch:29 step:27567 [D loss: 0.311117, acc.: 94.53%] [G loss: 1.345715]\n",
      "epoch:29 step:27568 [D loss: 0.710856, acc.: 56.25%] [G loss: 1.211458]\n",
      "epoch:29 step:27569 [D loss: 0.184379, acc.: 97.66%] [G loss: 1.320686]\n",
      "epoch:29 step:27570 [D loss: 0.148456, acc.: 96.88%] [G loss: 1.239628]\n",
      "epoch:29 step:27571 [D loss: 0.225173, acc.: 92.97%] [G loss: 1.778919]\n",
      "epoch:29 step:27572 [D loss: 0.157278, acc.: 97.66%] [G loss: 1.652671]\n",
      "epoch:29 step:27573 [D loss: 0.183431, acc.: 95.31%] [G loss: 2.314155]\n",
      "epoch:29 step:27574 [D loss: 0.102768, acc.: 98.44%] [G loss: 1.852132]\n",
      "epoch:29 step:27575 [D loss: 0.164773, acc.: 96.09%] [G loss: 1.945756]\n",
      "epoch:29 step:27576 [D loss: 0.141611, acc.: 96.88%] [G loss: 1.790333]\n",
      "epoch:29 step:27577 [D loss: 0.177187, acc.: 96.09%] [G loss: 2.640078]\n",
      "epoch:29 step:27578 [D loss: 0.103150, acc.: 99.22%] [G loss: 2.665493]\n",
      "epoch:29 step:27579 [D loss: 0.082331, acc.: 100.00%] [G loss: 2.662640]\n",
      "epoch:29 step:27580 [D loss: 0.060456, acc.: 100.00%] [G loss: 2.541202]\n",
      "epoch:29 step:27581 [D loss: 0.269099, acc.: 92.19%] [G loss: 2.114353]\n",
      "epoch:29 step:27582 [D loss: 0.056979, acc.: 100.00%] [G loss: 2.553243]\n",
      "epoch:29 step:27583 [D loss: 0.224396, acc.: 97.66%] [G loss: 2.190044]\n",
      "epoch:29 step:27584 [D loss: 1.109504, acc.: 49.22%] [G loss: 1.964040]\n",
      "epoch:29 step:27585 [D loss: 0.137755, acc.: 100.00%] [G loss: 1.594891]\n",
      "epoch:29 step:27586 [D loss: 0.888578, acc.: 57.81%] [G loss: 1.591694]\n",
      "epoch:29 step:27587 [D loss: 0.239345, acc.: 89.06%] [G loss: 1.773135]\n",
      "epoch:29 step:27588 [D loss: 0.215478, acc.: 92.19%] [G loss: 2.845905]\n",
      "epoch:29 step:27589 [D loss: 0.446119, acc.: 78.91%] [G loss: 1.827083]\n",
      "epoch:29 step:27590 [D loss: 0.343243, acc.: 89.06%] [G loss: 1.656657]\n",
      "epoch:29 step:27591 [D loss: 0.453438, acc.: 78.12%] [G loss: 2.443547]\n",
      "epoch:29 step:27592 [D loss: 0.082520, acc.: 100.00%] [G loss: 1.612716]\n",
      "epoch:29 step:27593 [D loss: 0.585476, acc.: 66.41%] [G loss: 2.758863]\n",
      "epoch:29 step:27594 [D loss: 0.776093, acc.: 56.25%] [G loss: 1.841785]\n",
      "epoch:29 step:27595 [D loss: 1.920476, acc.: 8.59%] [G loss: 1.480218]\n",
      "epoch:29 step:27596 [D loss: 1.754699, acc.: 12.50%] [G loss: 1.614057]\n",
      "epoch:29 step:27597 [D loss: 0.272036, acc.: 92.19%] [G loss: 1.767970]\n",
      "epoch:29 step:27598 [D loss: 0.513981, acc.: 75.78%] [G loss: 1.832118]\n",
      "epoch:29 step:27599 [D loss: 0.762528, acc.: 47.66%] [G loss: 1.418232]\n",
      "epoch:29 step:27600 [D loss: 0.339655, acc.: 91.41%] [G loss: 0.974543]\n",
      "epoch:29 step:27601 [D loss: 0.426234, acc.: 77.34%] [G loss: 1.523195]\n",
      "epoch:29 step:27602 [D loss: 0.695587, acc.: 57.03%] [G loss: 1.958803]\n",
      "epoch:29 step:27603 [D loss: 0.408486, acc.: 86.72%] [G loss: 1.171058]\n",
      "epoch:29 step:27604 [D loss: 1.199859, acc.: 24.22%] [G loss: 1.322349]\n",
      "epoch:29 step:27605 [D loss: 1.048058, acc.: 48.44%] [G loss: 1.535235]\n",
      "epoch:29 step:27606 [D loss: 0.698093, acc.: 59.38%] [G loss: 1.465337]\n",
      "epoch:29 step:27607 [D loss: 0.797382, acc.: 47.66%] [G loss: 1.024338]\n",
      "epoch:29 step:27608 [D loss: 0.777531, acc.: 47.66%] [G loss: 1.129657]\n",
      "epoch:29 step:27609 [D loss: 0.670819, acc.: 59.38%] [G loss: 1.369454]\n",
      "epoch:29 step:27610 [D loss: 0.791522, acc.: 49.22%] [G loss: 1.044124]\n",
      "epoch:29 step:27611 [D loss: 0.647028, acc.: 64.84%] [G loss: 0.911056]\n",
      "epoch:29 step:27612 [D loss: 0.751232, acc.: 47.66%] [G loss: 1.070441]\n",
      "epoch:29 step:27613 [D loss: 0.712842, acc.: 53.91%] [G loss: 1.256209]\n",
      "epoch:29 step:27614 [D loss: 0.739798, acc.: 46.88%] [G loss: 1.090680]\n",
      "epoch:29 step:27615 [D loss: 0.653155, acc.: 59.38%] [G loss: 1.144680]\n",
      "epoch:29 step:27616 [D loss: 0.648445, acc.: 57.81%] [G loss: 1.261372]\n",
      "epoch:29 step:27617 [D loss: 0.730382, acc.: 53.12%] [G loss: 1.002819]\n",
      "epoch:29 step:27618 [D loss: 0.706878, acc.: 56.25%] [G loss: 1.414067]\n",
      "epoch:29 step:27619 [D loss: 0.624671, acc.: 70.31%] [G loss: 1.150676]\n",
      "epoch:29 step:27620 [D loss: 0.650125, acc.: 60.94%] [G loss: 1.219880]\n",
      "epoch:29 step:27621 [D loss: 0.591471, acc.: 66.41%] [G loss: 1.165004]\n",
      "epoch:29 step:27622 [D loss: 0.527281, acc.: 74.22%] [G loss: 1.306180]\n",
      "epoch:29 step:27623 [D loss: 0.458383, acc.: 87.50%] [G loss: 1.435496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27624 [D loss: 0.417432, acc.: 89.06%] [G loss: 1.253079]\n",
      "epoch:29 step:27625 [D loss: 0.509247, acc.: 82.03%] [G loss: 1.224497]\n",
      "epoch:29 step:27626 [D loss: 0.381210, acc.: 86.72%] [G loss: 1.247600]\n",
      "epoch:29 step:27627 [D loss: 0.441881, acc.: 83.59%] [G loss: 1.396441]\n",
      "epoch:29 step:27628 [D loss: 0.398689, acc.: 84.38%] [G loss: 1.553655]\n",
      "epoch:29 step:27629 [D loss: 0.397955, acc.: 86.72%] [G loss: 1.988000]\n",
      "epoch:29 step:27630 [D loss: 0.434083, acc.: 88.28%] [G loss: 1.371949]\n",
      "epoch:29 step:27631 [D loss: 0.529716, acc.: 68.75%] [G loss: 1.021946]\n",
      "epoch:29 step:27632 [D loss: 0.664009, acc.: 60.16%] [G loss: 0.942414]\n",
      "epoch:29 step:27633 [D loss: 0.594985, acc.: 71.09%] [G loss: 2.073890]\n",
      "epoch:29 step:27634 [D loss: 0.784834, acc.: 46.09%] [G loss: 1.301138]\n",
      "epoch:29 step:27635 [D loss: 0.904146, acc.: 33.59%] [G loss: 0.910096]\n",
      "epoch:29 step:27636 [D loss: 0.579394, acc.: 67.97%] [G loss: 0.793295]\n",
      "epoch:29 step:27637 [D loss: 0.529377, acc.: 75.78%] [G loss: 0.830095]\n",
      "epoch:29 step:27638 [D loss: 0.559758, acc.: 68.75%] [G loss: 1.020561]\n",
      "epoch:29 step:27639 [D loss: 0.549708, acc.: 73.44%] [G loss: 1.760185]\n",
      "epoch:29 step:27640 [D loss: 0.473774, acc.: 82.81%] [G loss: 1.160760]\n",
      "epoch:29 step:27641 [D loss: 0.337148, acc.: 90.62%] [G loss: 1.328892]\n",
      "epoch:29 step:27642 [D loss: 0.248235, acc.: 98.44%] [G loss: 1.291892]\n",
      "epoch:29 step:27643 [D loss: 0.238655, acc.: 97.66%] [G loss: 1.553777]\n",
      "epoch:29 step:27644 [D loss: 0.250769, acc.: 98.44%] [G loss: 1.495901]\n",
      "epoch:29 step:27645 [D loss: 0.350011, acc.: 96.88%] [G loss: 1.728850]\n",
      "epoch:29 step:27646 [D loss: 1.298214, acc.: 43.75%] [G loss: 1.125043]\n",
      "epoch:29 step:27647 [D loss: 0.875753, acc.: 46.88%] [G loss: 0.842179]\n",
      "epoch:29 step:27648 [D loss: 0.811995, acc.: 48.44%] [G loss: 0.899683]\n",
      "epoch:29 step:27649 [D loss: 0.592310, acc.: 64.84%] [G loss: 1.173787]\n",
      "epoch:29 step:27650 [D loss: 0.489294, acc.: 79.69%] [G loss: 1.352512]\n",
      "epoch:29 step:27651 [D loss: 0.518513, acc.: 73.44%] [G loss: 1.157889]\n",
      "epoch:29 step:27652 [D loss: 0.347970, acc.: 85.94%] [G loss: 1.296600]\n",
      "epoch:29 step:27653 [D loss: 0.445803, acc.: 78.91%] [G loss: 1.255446]\n",
      "epoch:29 step:27654 [D loss: 0.254073, acc.: 93.75%] [G loss: 1.337085]\n",
      "epoch:29 step:27655 [D loss: 0.723271, acc.: 58.59%] [G loss: 1.376539]\n",
      "epoch:29 step:27656 [D loss: 0.637366, acc.: 58.59%] [G loss: 1.151061]\n",
      "epoch:29 step:27657 [D loss: 0.657448, acc.: 62.50%] [G loss: 0.965971]\n",
      "epoch:29 step:27658 [D loss: 0.558573, acc.: 71.09%] [G loss: 1.069090]\n",
      "epoch:29 step:27659 [D loss: 0.670941, acc.: 60.16%] [G loss: 1.161526]\n",
      "epoch:29 step:27660 [D loss: 0.695066, acc.: 61.72%] [G loss: 0.980649]\n",
      "epoch:29 step:27661 [D loss: 0.507688, acc.: 78.91%] [G loss: 0.954741]\n",
      "epoch:29 step:27662 [D loss: 0.406602, acc.: 85.16%] [G loss: 1.173969]\n",
      "epoch:29 step:27663 [D loss: 0.319262, acc.: 86.72%] [G loss: 1.228589]\n",
      "epoch:29 step:27664 [D loss: 0.394337, acc.: 89.06%] [G loss: 1.246248]\n",
      "epoch:29 step:27665 [D loss: 0.490238, acc.: 82.03%] [G loss: 1.064402]\n",
      "epoch:29 step:27666 [D loss: 0.645518, acc.: 62.50%] [G loss: 1.227289]\n",
      "epoch:29 step:27667 [D loss: 0.438577, acc.: 80.47%] [G loss: 1.461483]\n",
      "epoch:29 step:27668 [D loss: 0.400871, acc.: 89.06%] [G loss: 1.346944]\n",
      "epoch:29 step:27669 [D loss: 0.710736, acc.: 58.59%] [G loss: 1.078233]\n",
      "epoch:29 step:27670 [D loss: 0.743056, acc.: 56.25%] [G loss: 0.973379]\n",
      "epoch:29 step:27671 [D loss: 0.609437, acc.: 65.62%] [G loss: 1.224563]\n",
      "epoch:29 step:27672 [D loss: 0.651752, acc.: 57.03%] [G loss: 1.271076]\n",
      "epoch:29 step:27673 [D loss: 0.609985, acc.: 69.53%] [G loss: 1.178111]\n",
      "epoch:29 step:27674 [D loss: 0.737743, acc.: 53.91%] [G loss: 1.134200]\n",
      "epoch:29 step:27675 [D loss: 0.454061, acc.: 84.38%] [G loss: 0.925959]\n",
      "epoch:29 step:27676 [D loss: 0.198010, acc.: 94.53%] [G loss: 0.909533]\n",
      "epoch:29 step:27677 [D loss: 0.241396, acc.: 87.50%] [G loss: 1.344800]\n",
      "epoch:29 step:27678 [D loss: 0.278651, acc.: 89.06%] [G loss: 1.730542]\n",
      "epoch:29 step:27679 [D loss: 0.500915, acc.: 79.69%] [G loss: 1.464060]\n",
      "epoch:29 step:27680 [D loss: 0.242395, acc.: 96.88%] [G loss: 1.529047]\n",
      "epoch:29 step:27681 [D loss: 0.253773, acc.: 96.09%] [G loss: 1.780794]\n",
      "epoch:29 step:27682 [D loss: 0.812182, acc.: 48.44%] [G loss: 1.309718]\n",
      "epoch:29 step:27683 [D loss: 0.764391, acc.: 53.91%] [G loss: 0.884812]\n",
      "epoch:29 step:27684 [D loss: 0.594153, acc.: 68.75%] [G loss: 1.328457]\n",
      "epoch:29 step:27685 [D loss: 0.978233, acc.: 31.25%] [G loss: 1.075781]\n",
      "epoch:29 step:27686 [D loss: 0.493825, acc.: 78.12%] [G loss: 1.197166]\n",
      "epoch:29 step:27687 [D loss: 0.496101, acc.: 76.56%] [G loss: 1.263060]\n",
      "epoch:29 step:27688 [D loss: 0.462954, acc.: 79.69%] [G loss: 1.307398]\n",
      "epoch:29 step:27689 [D loss: 0.666900, acc.: 62.50%] [G loss: 1.371118]\n",
      "epoch:29 step:27690 [D loss: 0.270285, acc.: 92.19%] [G loss: 1.293253]\n",
      "epoch:29 step:27691 [D loss: 0.322827, acc.: 93.75%] [G loss: 1.057668]\n",
      "epoch:29 step:27692 [D loss: 0.370338, acc.: 86.72%] [G loss: 1.323905]\n",
      "epoch:29 step:27693 [D loss: 0.294211, acc.: 93.75%] [G loss: 1.372956]\n",
      "epoch:29 step:27694 [D loss: 0.384052, acc.: 92.19%] [G loss: 1.562850]\n",
      "epoch:29 step:27695 [D loss: 0.385829, acc.: 92.19%] [G loss: 1.174158]\n",
      "epoch:29 step:27696 [D loss: 0.532080, acc.: 78.12%] [G loss: 1.256841]\n",
      "epoch:29 step:27697 [D loss: 0.492099, acc.: 76.56%] [G loss: 1.363715]\n",
      "epoch:29 step:27698 [D loss: 0.620854, acc.: 66.41%] [G loss: 1.295202]\n",
      "epoch:29 step:27699 [D loss: 0.511745, acc.: 80.47%] [G loss: 1.089018]\n",
      "epoch:29 step:27700 [D loss: 0.462568, acc.: 82.03%] [G loss: 1.149346]\n",
      "epoch:29 step:27701 [D loss: 0.635381, acc.: 66.41%] [G loss: 1.249805]\n",
      "epoch:29 step:27702 [D loss: 0.626215, acc.: 65.62%] [G loss: 1.401837]\n",
      "epoch:29 step:27703 [D loss: 0.307938, acc.: 92.19%] [G loss: 1.669053]\n",
      "epoch:29 step:27704 [D loss: 0.639182, acc.: 67.19%] [G loss: 1.375827]\n",
      "epoch:29 step:27705 [D loss: 0.629399, acc.: 65.62%] [G loss: 1.168118]\n",
      "epoch:29 step:27706 [D loss: 0.264734, acc.: 93.75%] [G loss: 1.570377]\n",
      "epoch:29 step:27707 [D loss: 0.385679, acc.: 86.72%] [G loss: 1.320091]\n",
      "epoch:29 step:27708 [D loss: 0.415445, acc.: 82.03%] [G loss: 1.333750]\n",
      "epoch:29 step:27709 [D loss: 0.179516, acc.: 92.97%] [G loss: 1.486979]\n",
      "epoch:29 step:27710 [D loss: 0.383114, acc.: 88.28%] [G loss: 1.872295]\n",
      "epoch:29 step:27711 [D loss: 0.387398, acc.: 88.28%] [G loss: 1.541186]\n",
      "epoch:29 step:27712 [D loss: 0.302413, acc.: 89.06%] [G loss: 1.874201]\n",
      "epoch:29 step:27713 [D loss: 0.374690, acc.: 86.72%] [G loss: 1.698680]\n",
      "epoch:29 step:27714 [D loss: 0.787502, acc.: 51.56%] [G loss: 1.446047]\n",
      "epoch:29 step:27715 [D loss: 0.609735, acc.: 66.41%] [G loss: 1.530836]\n",
      "epoch:29 step:27716 [D loss: 0.240413, acc.: 92.19%] [G loss: 1.279940]\n",
      "epoch:29 step:27717 [D loss: 0.625295, acc.: 59.38%] [G loss: 1.452279]\n",
      "epoch:29 step:27718 [D loss: 0.325315, acc.: 90.62%] [G loss: 1.494193]\n",
      "epoch:29 step:27719 [D loss: 0.633134, acc.: 64.06%] [G loss: 1.209148]\n",
      "epoch:29 step:27720 [D loss: 0.542165, acc.: 74.22%] [G loss: 1.000570]\n",
      "epoch:29 step:27721 [D loss: 0.504170, acc.: 72.66%] [G loss: 1.761372]\n",
      "epoch:29 step:27722 [D loss: 0.461102, acc.: 78.91%] [G loss: 1.717253]\n",
      "epoch:29 step:27723 [D loss: 0.186773, acc.: 96.88%] [G loss: 1.477003]\n",
      "epoch:29 step:27724 [D loss: 0.330170, acc.: 92.19%] [G loss: 1.713084]\n",
      "epoch:29 step:27725 [D loss: 0.818306, acc.: 53.91%] [G loss: 1.305430]\n",
      "epoch:29 step:27726 [D loss: 0.739741, acc.: 60.16%] [G loss: 1.281637]\n",
      "epoch:29 step:27727 [D loss: 0.187076, acc.: 96.88%] [G loss: 1.389501]\n",
      "epoch:29 step:27728 [D loss: 0.447345, acc.: 86.72%] [G loss: 1.078265]\n",
      "epoch:29 step:27729 [D loss: 0.347820, acc.: 80.47%] [G loss: 2.015433]\n",
      "epoch:29 step:27730 [D loss: 0.367603, acc.: 89.06%] [G loss: 1.074828]\n",
      "epoch:29 step:27731 [D loss: 0.543883, acc.: 72.66%] [G loss: 0.880637]\n",
      "epoch:29 step:27732 [D loss: 0.219544, acc.: 92.19%] [G loss: 1.642289]\n",
      "epoch:29 step:27733 [D loss: 0.259507, acc.: 91.41%] [G loss: 2.251593]\n",
      "epoch:29 step:27734 [D loss: 0.150982, acc.: 96.88%] [G loss: 1.345181]\n",
      "epoch:29 step:27735 [D loss: 1.327421, acc.: 28.91%] [G loss: 1.834428]\n",
      "epoch:29 step:27736 [D loss: 0.999673, acc.: 42.19%] [G loss: 2.075653]\n",
      "epoch:29 step:27737 [D loss: 0.875419, acc.: 43.75%] [G loss: 1.962846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27738 [D loss: 0.585261, acc.: 63.28%] [G loss: 1.668743]\n",
      "epoch:29 step:27739 [D loss: 0.309632, acc.: 85.16%] [G loss: 1.998192]\n",
      "epoch:29 step:27740 [D loss: 0.089059, acc.: 97.66%] [G loss: 3.092885]\n",
      "epoch:29 step:27741 [D loss: 0.457212, acc.: 78.12%] [G loss: 2.304647]\n",
      "epoch:29 step:27742 [D loss: 0.732156, acc.: 58.59%] [G loss: 2.260274]\n",
      "epoch:29 step:27743 [D loss: 0.528419, acc.: 75.00%] [G loss: 2.034586]\n",
      "epoch:29 step:27744 [D loss: 0.566212, acc.: 67.19%] [G loss: 1.979021]\n",
      "epoch:29 step:27745 [D loss: 0.243014, acc.: 91.41%] [G loss: 1.852776]\n",
      "epoch:29 step:27746 [D loss: 0.219571, acc.: 94.53%] [G loss: 1.814567]\n",
      "epoch:29 step:27747 [D loss: 0.463940, acc.: 81.25%] [G loss: 1.916081]\n",
      "epoch:29 step:27748 [D loss: 0.229707, acc.: 92.19%] [G loss: 2.087037]\n",
      "epoch:29 step:27749 [D loss: 0.145652, acc.: 98.44%] [G loss: 3.189979]\n",
      "epoch:29 step:27750 [D loss: 0.163961, acc.: 95.31%] [G loss: 1.738885]\n",
      "epoch:29 step:27751 [D loss: 0.109130, acc.: 100.00%] [G loss: 2.294561]\n",
      "epoch:29 step:27752 [D loss: 0.151481, acc.: 96.88%] [G loss: 2.320002]\n",
      "epoch:29 step:27753 [D loss: 0.518965, acc.: 71.88%] [G loss: 1.831730]\n",
      "epoch:29 step:27754 [D loss: 0.536607, acc.: 71.88%] [G loss: 1.725796]\n",
      "epoch:29 step:27755 [D loss: 0.477763, acc.: 78.91%] [G loss: 1.441373]\n",
      "epoch:29 step:27756 [D loss: 0.674116, acc.: 65.62%] [G loss: 1.350666]\n",
      "epoch:29 step:27757 [D loss: 0.564822, acc.: 75.78%] [G loss: 1.219864]\n",
      "epoch:29 step:27758 [D loss: 0.677066, acc.: 56.25%] [G loss: 1.029726]\n",
      "epoch:29 step:27759 [D loss: 0.493402, acc.: 74.22%] [G loss: 1.036791]\n",
      "epoch:29 step:27760 [D loss: 0.983921, acc.: 53.91%] [G loss: 1.403781]\n",
      "epoch:29 step:27761 [D loss: 0.144634, acc.: 96.09%] [G loss: 2.014211]\n",
      "epoch:29 step:27762 [D loss: 0.107560, acc.: 99.22%] [G loss: 2.309006]\n",
      "epoch:29 step:27763 [D loss: 0.390750, acc.: 83.59%] [G loss: 1.747219]\n",
      "epoch:29 step:27764 [D loss: 0.993022, acc.: 51.56%] [G loss: 1.518561]\n",
      "epoch:29 step:27765 [D loss: 0.958064, acc.: 39.84%] [G loss: 1.264265]\n",
      "epoch:29 step:27766 [D loss: 0.603071, acc.: 67.97%] [G loss: 1.359951]\n",
      "epoch:29 step:27767 [D loss: 0.217736, acc.: 91.41%] [G loss: 1.089179]\n",
      "epoch:29 step:27768 [D loss: 0.190277, acc.: 95.31%] [G loss: 1.660292]\n",
      "epoch:29 step:27769 [D loss: 0.561290, acc.: 78.12%] [G loss: 0.877892]\n",
      "epoch:29 step:27770 [D loss: 0.839272, acc.: 44.53%] [G loss: 0.697787]\n",
      "epoch:29 step:27771 [D loss: 1.094590, acc.: 29.69%] [G loss: 0.826652]\n",
      "epoch:29 step:27772 [D loss: 0.764705, acc.: 49.22%] [G loss: 1.247319]\n",
      "epoch:29 step:27773 [D loss: 0.179549, acc.: 96.09%] [G loss: 1.124765]\n",
      "epoch:29 step:27774 [D loss: 0.174041, acc.: 95.31%] [G loss: 1.862782]\n",
      "epoch:29 step:27775 [D loss: 0.273081, acc.: 91.41%] [G loss: 1.572386]\n",
      "epoch:29 step:27776 [D loss: 1.014862, acc.: 32.03%] [G loss: 1.518198]\n",
      "epoch:29 step:27777 [D loss: 0.782628, acc.: 56.25%] [G loss: 1.307626]\n",
      "epoch:29 step:27778 [D loss: 0.665031, acc.: 60.16%] [G loss: 0.996823]\n",
      "epoch:29 step:27779 [D loss: 0.428220, acc.: 82.81%] [G loss: 1.162747]\n",
      "epoch:29 step:27780 [D loss: 0.423795, acc.: 82.81%] [G loss: 0.849942]\n",
      "epoch:29 step:27781 [D loss: 0.414387, acc.: 84.38%] [G loss: 1.377325]\n",
      "epoch:29 step:27782 [D loss: 0.779163, acc.: 56.25%] [G loss: 1.482861]\n",
      "epoch:29 step:27783 [D loss: 0.647802, acc.: 66.41%] [G loss: 1.656719]\n",
      "epoch:29 step:27784 [D loss: 0.316539, acc.: 88.28%] [G loss: 1.028463]\n",
      "epoch:29 step:27785 [D loss: 0.562789, acc.: 67.97%] [G loss: 1.591841]\n",
      "epoch:29 step:27786 [D loss: 0.890696, acc.: 39.84%] [G loss: 1.160374]\n",
      "epoch:29 step:27787 [D loss: 0.924879, acc.: 45.31%] [G loss: 0.670095]\n",
      "epoch:29 step:27788 [D loss: 1.258662, acc.: 22.66%] [G loss: 1.810726]\n",
      "epoch:29 step:27789 [D loss: 0.577462, acc.: 64.84%] [G loss: 1.656831]\n",
      "epoch:29 step:27790 [D loss: 0.543939, acc.: 67.97%] [G loss: 1.564699]\n",
      "epoch:29 step:27791 [D loss: 0.845131, acc.: 56.25%] [G loss: 1.560179]\n",
      "epoch:29 step:27792 [D loss: 0.962210, acc.: 36.72%] [G loss: 0.893733]\n",
      "epoch:29 step:27793 [D loss: 0.686278, acc.: 58.59%] [G loss: 0.989760]\n",
      "epoch:29 step:27794 [D loss: 0.636284, acc.: 61.72%] [G loss: 1.028391]\n",
      "epoch:29 step:27795 [D loss: 0.536305, acc.: 78.91%] [G loss: 1.170299]\n",
      "epoch:29 step:27796 [D loss: 0.552707, acc.: 68.75%] [G loss: 1.445784]\n",
      "epoch:29 step:27797 [D loss: 0.444287, acc.: 85.16%] [G loss: 1.272970]\n",
      "epoch:29 step:27798 [D loss: 0.626912, acc.: 66.41%] [G loss: 1.187850]\n",
      "epoch:29 step:27799 [D loss: 0.521260, acc.: 75.78%] [G loss: 1.653709]\n",
      "epoch:29 step:27800 [D loss: 0.614709, acc.: 63.28%] [G loss: 1.107313]\n",
      "epoch:29 step:27801 [D loss: 0.635914, acc.: 66.41%] [G loss: 1.296411]\n",
      "epoch:29 step:27802 [D loss: 0.477577, acc.: 80.47%] [G loss: 1.050887]\n",
      "epoch:29 step:27803 [D loss: 0.366140, acc.: 88.28%] [G loss: 1.647126]\n",
      "epoch:29 step:27804 [D loss: 0.638662, acc.: 62.50%] [G loss: 1.255452]\n",
      "epoch:29 step:27805 [D loss: 0.409267, acc.: 78.91%] [G loss: 1.167983]\n",
      "epoch:29 step:27806 [D loss: 0.280419, acc.: 95.31%] [G loss: 1.346382]\n",
      "epoch:29 step:27807 [D loss: 0.277161, acc.: 96.88%] [G loss: 1.617039]\n",
      "epoch:29 step:27808 [D loss: 0.312660, acc.: 97.66%] [G loss: 1.236136]\n",
      "epoch:29 step:27809 [D loss: 0.583670, acc.: 69.53%] [G loss: 1.424314]\n",
      "epoch:29 step:27810 [D loss: 0.510709, acc.: 73.44%] [G loss: 1.366629]\n",
      "epoch:29 step:27811 [D loss: 0.476741, acc.: 77.34%] [G loss: 1.125192]\n",
      "epoch:29 step:27812 [D loss: 0.749047, acc.: 45.31%] [G loss: 1.161953]\n",
      "epoch:29 step:27813 [D loss: 1.042537, acc.: 42.97%] [G loss: 0.910821]\n",
      "epoch:29 step:27814 [D loss: 0.666737, acc.: 64.06%] [G loss: 1.191541]\n",
      "epoch:29 step:27815 [D loss: 0.718437, acc.: 57.03%] [G loss: 1.087023]\n",
      "epoch:29 step:27816 [D loss: 0.515670, acc.: 75.00%] [G loss: 0.961127]\n",
      "epoch:29 step:27817 [D loss: 0.337576, acc.: 80.47%] [G loss: 1.015999]\n",
      "epoch:29 step:27818 [D loss: 0.352420, acc.: 84.38%] [G loss: 1.209742]\n",
      "epoch:29 step:27819 [D loss: 0.246487, acc.: 92.19%] [G loss: 1.393864]\n",
      "epoch:29 step:27820 [D loss: 0.215851, acc.: 96.88%] [G loss: 1.184918]\n",
      "epoch:29 step:27821 [D loss: 0.270385, acc.: 94.53%] [G loss: 1.164056]\n",
      "epoch:29 step:27822 [D loss: 0.298091, acc.: 96.88%] [G loss: 1.752694]\n",
      "epoch:29 step:27823 [D loss: 0.261827, acc.: 92.19%] [G loss: 1.323343]\n",
      "epoch:29 step:27824 [D loss: 0.318838, acc.: 94.53%] [G loss: 1.498500]\n",
      "epoch:29 step:27825 [D loss: 0.660171, acc.: 61.72%] [G loss: 1.246802]\n",
      "epoch:29 step:27826 [D loss: 0.647149, acc.: 60.16%] [G loss: 1.159755]\n",
      "epoch:29 step:27827 [D loss: 0.680395, acc.: 57.03%] [G loss: 1.239044]\n",
      "epoch:29 step:27828 [D loss: 0.493293, acc.: 77.34%] [G loss: 1.450214]\n",
      "epoch:29 step:27829 [D loss: 0.489152, acc.: 78.91%] [G loss: 1.517887]\n",
      "epoch:29 step:27830 [D loss: 0.593101, acc.: 64.06%] [G loss: 1.136549]\n",
      "epoch:29 step:27831 [D loss: 0.553571, acc.: 70.31%] [G loss: 1.009838]\n",
      "epoch:29 step:27832 [D loss: 0.321071, acc.: 85.94%] [G loss: 1.464471]\n",
      "epoch:29 step:27833 [D loss: 0.596003, acc.: 64.84%] [G loss: 1.677746]\n",
      "epoch:29 step:27834 [D loss: 0.318687, acc.: 92.97%] [G loss: 1.524555]\n",
      "epoch:29 step:27835 [D loss: 0.633876, acc.: 65.62%] [G loss: 1.448130]\n",
      "epoch:29 step:27836 [D loss: 0.529795, acc.: 78.12%] [G loss: 0.752022]\n",
      "epoch:29 step:27837 [D loss: 0.502554, acc.: 79.69%] [G loss: 1.468487]\n",
      "epoch:29 step:27838 [D loss: 0.355304, acc.: 89.84%] [G loss: 1.409076]\n",
      "epoch:29 step:27839 [D loss: 0.707166, acc.: 60.94%] [G loss: 1.279937]\n",
      "epoch:29 step:27840 [D loss: 0.862609, acc.: 41.41%] [G loss: 1.327232]\n",
      "epoch:29 step:27841 [D loss: 0.555804, acc.: 74.22%] [G loss: 1.269146]\n",
      "epoch:29 step:27842 [D loss: 0.661568, acc.: 61.72%] [G loss: 1.050170]\n",
      "epoch:29 step:27843 [D loss: 0.645116, acc.: 64.84%] [G loss: 1.038563]\n",
      "epoch:29 step:27844 [D loss: 0.531709, acc.: 72.66%] [G loss: 1.091695]\n",
      "epoch:29 step:27845 [D loss: 0.538932, acc.: 75.78%] [G loss: 1.473642]\n",
      "epoch:29 step:27846 [D loss: 0.566743, acc.: 69.53%] [G loss: 1.195132]\n",
      "epoch:29 step:27847 [D loss: 0.547460, acc.: 72.66%] [G loss: 1.145045]\n",
      "epoch:29 step:27848 [D loss: 0.907087, acc.: 52.34%] [G loss: 0.761209]\n",
      "epoch:29 step:27849 [D loss: 0.704484, acc.: 61.72%] [G loss: 0.990533]\n",
      "epoch:29 step:27850 [D loss: 0.623005, acc.: 67.97%] [G loss: 0.848275]\n",
      "epoch:29 step:27851 [D loss: 0.517628, acc.: 75.78%] [G loss: 1.216127]\n",
      "epoch:29 step:27852 [D loss: 0.653120, acc.: 61.72%] [G loss: 1.304852]\n",
      "epoch:29 step:27853 [D loss: 0.487332, acc.: 77.34%] [G loss: 1.191087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27854 [D loss: 0.475790, acc.: 84.38%] [G loss: 1.130550]\n",
      "epoch:29 step:27855 [D loss: 0.757329, acc.: 52.34%] [G loss: 0.987153]\n",
      "epoch:29 step:27856 [D loss: 0.561877, acc.: 69.53%] [G loss: 0.698081]\n",
      "epoch:29 step:27857 [D loss: 0.620557, acc.: 62.50%] [G loss: 1.041022]\n",
      "epoch:29 step:27858 [D loss: 0.553499, acc.: 68.75%] [G loss: 1.017331]\n",
      "epoch:29 step:27859 [D loss: 0.534498, acc.: 77.34%] [G loss: 1.057580]\n",
      "epoch:29 step:27860 [D loss: 0.513904, acc.: 75.78%] [G loss: 1.335413]\n",
      "epoch:29 step:27861 [D loss: 0.764967, acc.: 48.44%] [G loss: 1.089604]\n",
      "epoch:29 step:27862 [D loss: 0.627362, acc.: 68.75%] [G loss: 0.839404]\n",
      "epoch:29 step:27863 [D loss: 0.431734, acc.: 82.03%] [G loss: 1.061780]\n",
      "epoch:29 step:27864 [D loss: 0.522731, acc.: 77.34%] [G loss: 1.169403]\n",
      "epoch:29 step:27865 [D loss: 0.495103, acc.: 74.22%] [G loss: 0.607679]\n",
      "epoch:29 step:27866 [D loss: 0.540144, acc.: 68.75%] [G loss: 1.298022]\n",
      "epoch:29 step:27867 [D loss: 0.490200, acc.: 70.31%] [G loss: 0.824043]\n",
      "epoch:29 step:27868 [D loss: 0.871976, acc.: 46.09%] [G loss: 1.317019]\n",
      "epoch:29 step:27869 [D loss: 0.216283, acc.: 96.88%] [G loss: 1.511385]\n",
      "epoch:29 step:27870 [D loss: 0.197589, acc.: 94.53%] [G loss: 1.620416]\n",
      "epoch:29 step:27871 [D loss: 0.274832, acc.: 92.97%] [G loss: 1.646117]\n",
      "epoch:29 step:27872 [D loss: 0.277825, acc.: 95.31%] [G loss: 1.578040]\n",
      "epoch:29 step:27873 [D loss: 0.423895, acc.: 85.16%] [G loss: 1.340881]\n",
      "epoch:29 step:27874 [D loss: 0.224207, acc.: 92.97%] [G loss: 1.545992]\n",
      "epoch:29 step:27875 [D loss: 0.277709, acc.: 92.97%] [G loss: 1.794953]\n",
      "epoch:29 step:27876 [D loss: 0.481236, acc.: 78.91%] [G loss: 1.728140]\n",
      "epoch:29 step:27877 [D loss: 0.381571, acc.: 87.50%] [G loss: 1.468219]\n",
      "epoch:29 step:27878 [D loss: 0.594004, acc.: 64.84%] [G loss: 1.057688]\n",
      "epoch:29 step:27879 [D loss: 0.277516, acc.: 89.06%] [G loss: 0.948837]\n",
      "epoch:29 step:27880 [D loss: 0.178811, acc.: 96.88%] [G loss: 1.766766]\n",
      "epoch:29 step:27881 [D loss: 0.157192, acc.: 96.88%] [G loss: 1.744761]\n",
      "epoch:29 step:27882 [D loss: 0.124567, acc.: 99.22%] [G loss: 1.587878]\n",
      "epoch:29 step:27883 [D loss: 0.977054, acc.: 50.00%] [G loss: 1.602409]\n",
      "epoch:29 step:27884 [D loss: 0.802695, acc.: 51.56%] [G loss: 1.506072]\n",
      "epoch:29 step:27885 [D loss: 0.533925, acc.: 70.31%] [G loss: 1.458811]\n",
      "epoch:29 step:27886 [D loss: 0.215095, acc.: 90.62%] [G loss: 1.417208]\n",
      "epoch:29 step:27887 [D loss: 0.148984, acc.: 98.44%] [G loss: 1.052264]\n",
      "epoch:29 step:27888 [D loss: 0.869503, acc.: 44.53%] [G loss: 2.025214]\n",
      "epoch:29 step:27889 [D loss: 0.790532, acc.: 50.78%] [G loss: 1.352716]\n",
      "epoch:29 step:27890 [D loss: 0.555211, acc.: 72.66%] [G loss: 1.347716]\n",
      "epoch:29 step:27891 [D loss: 0.582224, acc.: 69.53%] [G loss: 1.287786]\n",
      "epoch:29 step:27892 [D loss: 0.624849, acc.: 60.94%] [G loss: 1.288504]\n",
      "epoch:29 step:27893 [D loss: 0.652041, acc.: 67.19%] [G loss: 1.524614]\n",
      "epoch:29 step:27894 [D loss: 0.584683, acc.: 67.19%] [G loss: 1.234704]\n",
      "epoch:29 step:27895 [D loss: 0.290207, acc.: 95.31%] [G loss: 1.197918]\n",
      "epoch:29 step:27896 [D loss: 0.284890, acc.: 91.41%] [G loss: 1.327770]\n",
      "epoch:29 step:27897 [D loss: 0.681738, acc.: 60.16%] [G loss: 1.834908]\n",
      "epoch:29 step:27898 [D loss: 0.704490, acc.: 55.47%] [G loss: 0.935632]\n",
      "epoch:29 step:27899 [D loss: 0.590120, acc.: 67.19%] [G loss: 1.177537]\n",
      "epoch:29 step:27900 [D loss: 0.223533, acc.: 92.19%] [G loss: 1.606299]\n",
      "epoch:29 step:27901 [D loss: 0.241614, acc.: 88.28%] [G loss: 1.480650]\n",
      "epoch:29 step:27902 [D loss: 0.363779, acc.: 85.16%] [G loss: 1.195025]\n",
      "epoch:29 step:27903 [D loss: 0.157530, acc.: 97.66%] [G loss: 1.918119]\n",
      "epoch:29 step:27904 [D loss: 0.125568, acc.: 97.66%] [G loss: 2.404978]\n",
      "epoch:29 step:27905 [D loss: 0.157565, acc.: 98.44%] [G loss: 2.012860]\n",
      "epoch:29 step:27906 [D loss: 0.100751, acc.: 99.22%] [G loss: 2.439295]\n",
      "epoch:29 step:27907 [D loss: 0.989300, acc.: 45.31%] [G loss: 1.833092]\n",
      "epoch:29 step:27908 [D loss: 0.706710, acc.: 57.03%] [G loss: 1.561788]\n",
      "epoch:29 step:27909 [D loss: 0.735213, acc.: 53.12%] [G loss: 1.303888]\n",
      "epoch:29 step:27910 [D loss: 0.715659, acc.: 58.59%] [G loss: 1.470849]\n",
      "epoch:29 step:27911 [D loss: 0.353473, acc.: 88.28%] [G loss: 1.611867]\n",
      "epoch:29 step:27912 [D loss: 0.361835, acc.: 90.62%] [G loss: 1.352311]\n",
      "epoch:29 step:27913 [D loss: 0.466009, acc.: 78.91%] [G loss: 1.498961]\n",
      "epoch:29 step:27914 [D loss: 0.838312, acc.: 44.53%] [G loss: 1.075634]\n",
      "epoch:29 step:27915 [D loss: 0.604098, acc.: 66.41%] [G loss: 1.328033]\n",
      "epoch:29 step:27916 [D loss: 0.648664, acc.: 66.41%] [G loss: 1.282302]\n",
      "epoch:29 step:27917 [D loss: 0.650855, acc.: 66.41%] [G loss: 1.134557]\n",
      "epoch:29 step:27918 [D loss: 0.227780, acc.: 95.31%] [G loss: 1.503407]\n",
      "epoch:29 step:27919 [D loss: 0.261390, acc.: 91.41%] [G loss: 1.403417]\n",
      "epoch:29 step:27920 [D loss: 0.349794, acc.: 92.97%] [G loss: 1.487674]\n",
      "epoch:29 step:27921 [D loss: 0.744100, acc.: 46.09%] [G loss: 1.122500]\n",
      "epoch:29 step:27922 [D loss: 0.633830, acc.: 62.50%] [G loss: 1.382959]\n",
      "epoch:29 step:27923 [D loss: 0.638443, acc.: 64.84%] [G loss: 1.177108]\n",
      "epoch:29 step:27924 [D loss: 0.386208, acc.: 85.94%] [G loss: 1.179768]\n",
      "epoch:29 step:27925 [D loss: 0.432263, acc.: 75.78%] [G loss: 1.396558]\n",
      "epoch:29 step:27926 [D loss: 0.245659, acc.: 95.31%] [G loss: 2.078808]\n",
      "epoch:29 step:27927 [D loss: 0.217192, acc.: 95.31%] [G loss: 1.632753]\n",
      "epoch:29 step:27928 [D loss: 0.142648, acc.: 99.22%] [G loss: 1.559351]\n",
      "epoch:29 step:27929 [D loss: 0.138143, acc.: 96.88%] [G loss: 2.346523]\n",
      "epoch:29 step:27930 [D loss: 0.121079, acc.: 99.22%] [G loss: 1.859642]\n",
      "epoch:29 step:27931 [D loss: 0.408192, acc.: 83.59%] [G loss: 1.803203]\n",
      "epoch:29 step:27932 [D loss: 0.948740, acc.: 53.12%] [G loss: 1.169179]\n",
      "epoch:29 step:27933 [D loss: 0.930295, acc.: 50.00%] [G loss: 1.449601]\n",
      "epoch:29 step:27934 [D loss: 0.446830, acc.: 85.16%] [G loss: 1.340282]\n",
      "epoch:29 step:27935 [D loss: 0.341472, acc.: 80.47%] [G loss: 1.149332]\n",
      "epoch:29 step:27936 [D loss: 0.200099, acc.: 97.66%] [G loss: 1.743008]\n",
      "epoch:29 step:27937 [D loss: 0.097477, acc.: 99.22%] [G loss: 1.549543]\n",
      "epoch:29 step:27938 [D loss: 0.688610, acc.: 57.81%] [G loss: 1.485859]\n",
      "epoch:29 step:27939 [D loss: 0.576906, acc.: 71.09%] [G loss: 1.517093]\n",
      "epoch:29 step:27940 [D loss: 0.662511, acc.: 64.84%] [G loss: 1.648024]\n",
      "epoch:29 step:27941 [D loss: 1.346762, acc.: 21.09%] [G loss: 0.920520]\n",
      "epoch:29 step:27942 [D loss: 0.602810, acc.: 64.06%] [G loss: 1.275297]\n",
      "epoch:29 step:27943 [D loss: 0.719109, acc.: 58.59%] [G loss: 1.278327]\n",
      "epoch:29 step:27944 [D loss: 0.366459, acc.: 87.50%] [G loss: 1.420837]\n",
      "epoch:29 step:27945 [D loss: 0.513668, acc.: 78.12%] [G loss: 1.379985]\n",
      "epoch:29 step:27946 [D loss: 0.794669, acc.: 50.00%] [G loss: 1.250153]\n",
      "epoch:29 step:27947 [D loss: 0.391556, acc.: 88.28%] [G loss: 1.311769]\n",
      "epoch:29 step:27948 [D loss: 0.468314, acc.: 78.12%] [G loss: 1.588506]\n",
      "epoch:29 step:27949 [D loss: 0.996589, acc.: 31.25%] [G loss: 1.289406]\n",
      "epoch:29 step:27950 [D loss: 0.661857, acc.: 61.72%] [G loss: 1.302988]\n",
      "epoch:29 step:27951 [D loss: 0.763678, acc.: 52.34%] [G loss: 1.133859]\n",
      "epoch:29 step:27952 [D loss: 0.327081, acc.: 95.31%] [G loss: 1.316695]\n",
      "epoch:29 step:27953 [D loss: 0.259202, acc.: 93.75%] [G loss: 1.359930]\n",
      "epoch:29 step:27954 [D loss: 0.148618, acc.: 97.66%] [G loss: 1.398333]\n",
      "epoch:29 step:27955 [D loss: 0.146737, acc.: 98.44%] [G loss: 1.792210]\n",
      "epoch:29 step:27956 [D loss: 0.307668, acc.: 93.75%] [G loss: 1.683818]\n",
      "epoch:29 step:27957 [D loss: 0.510103, acc.: 75.00%] [G loss: 1.812850]\n",
      "epoch:29 step:27958 [D loss: 0.275833, acc.: 96.09%] [G loss: 1.382899]\n",
      "epoch:29 step:27959 [D loss: 0.232580, acc.: 93.75%] [G loss: 1.520424]\n",
      "epoch:29 step:27960 [D loss: 0.627470, acc.: 64.06%] [G loss: 1.354503]\n",
      "epoch:29 step:27961 [D loss: 0.503962, acc.: 75.00%] [G loss: 0.892524]\n",
      "epoch:29 step:27962 [D loss: 0.580575, acc.: 70.31%] [G loss: 1.068557]\n",
      "epoch:29 step:27963 [D loss: 0.385583, acc.: 90.62%] [G loss: 0.655769]\n",
      "epoch:29 step:27964 [D loss: 0.553734, acc.: 64.06%] [G loss: 0.829454]\n",
      "epoch:29 step:27965 [D loss: 0.197763, acc.: 93.75%] [G loss: 1.415030]\n",
      "epoch:29 step:27966 [D loss: 0.104429, acc.: 99.22%] [G loss: 1.398909]\n",
      "epoch:29 step:27967 [D loss: 0.125177, acc.: 96.88%] [G loss: 2.193250]\n",
      "epoch:29 step:27968 [D loss: 0.497329, acc.: 78.12%] [G loss: 1.568745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27969 [D loss: 0.360189, acc.: 81.25%] [G loss: 1.069861]\n",
      "epoch:29 step:27970 [D loss: 1.044299, acc.: 36.72%] [G loss: 2.421162]\n",
      "epoch:29 step:27971 [D loss: 0.880241, acc.: 54.69%] [G loss: 1.656352]\n",
      "epoch:29 step:27972 [D loss: 1.086072, acc.: 50.78%] [G loss: 1.591732]\n",
      "epoch:29 step:27973 [D loss: 0.743186, acc.: 57.81%] [G loss: 2.186439]\n",
      "epoch:29 step:27974 [D loss: 0.675343, acc.: 59.38%] [G loss: 2.274911]\n",
      "epoch:29 step:27975 [D loss: 0.296218, acc.: 87.50%] [G loss: 2.105376]\n",
      "epoch:29 step:27976 [D loss: 0.497107, acc.: 71.88%] [G loss: 2.089083]\n",
      "epoch:29 step:27977 [D loss: 0.230331, acc.: 95.31%] [G loss: 1.888317]\n",
      "epoch:29 step:27978 [D loss: 0.294240, acc.: 92.19%] [G loss: 1.747784]\n",
      "epoch:29 step:27979 [D loss: 0.117186, acc.: 99.22%] [G loss: 1.501822]\n",
      "epoch:29 step:27980 [D loss: 0.824915, acc.: 53.12%] [G loss: 0.552280]\n",
      "epoch:29 step:27981 [D loss: 0.437738, acc.: 80.47%] [G loss: 1.678262]\n",
      "epoch:29 step:27982 [D loss: 0.600305, acc.: 64.84%] [G loss: 1.863984]\n",
      "epoch:29 step:27983 [D loss: 0.405222, acc.: 83.59%] [G loss: 1.648552]\n",
      "epoch:29 step:27984 [D loss: 0.893941, acc.: 50.78%] [G loss: 1.336104]\n",
      "epoch:29 step:27985 [D loss: 0.883595, acc.: 41.41%] [G loss: 1.456750]\n",
      "epoch:29 step:27986 [D loss: 0.672092, acc.: 57.81%] [G loss: 1.578982]\n",
      "epoch:29 step:27987 [D loss: 0.572558, acc.: 67.97%] [G loss: 1.569146]\n",
      "epoch:29 step:27988 [D loss: 0.130427, acc.: 98.44%] [G loss: 1.890458]\n",
      "epoch:29 step:27989 [D loss: 0.154862, acc.: 97.66%] [G loss: 1.861520]\n",
      "epoch:29 step:27990 [D loss: 0.465841, acc.: 75.00%] [G loss: 1.929788]\n",
      "epoch:29 step:27991 [D loss: 0.277143, acc.: 95.31%] [G loss: 1.703655]\n",
      "epoch:29 step:27992 [D loss: 0.298440, acc.: 93.75%] [G loss: 1.812290]\n",
      "epoch:29 step:27993 [D loss: 0.627783, acc.: 60.94%] [G loss: 1.551212]\n",
      "epoch:29 step:27994 [D loss: 0.855263, acc.: 51.56%] [G loss: 1.472993]\n",
      "epoch:29 step:27995 [D loss: 0.632880, acc.: 61.72%] [G loss: 1.198589]\n",
      "epoch:29 step:27996 [D loss: 0.559741, acc.: 70.31%] [G loss: 1.147959]\n",
      "epoch:29 step:27997 [D loss: 0.189895, acc.: 96.88%] [G loss: 1.646175]\n",
      "epoch:29 step:27998 [D loss: 0.274710, acc.: 90.62%] [G loss: 1.165047]\n",
      "epoch:29 step:27999 [D loss: 0.375550, acc.: 87.50%] [G loss: 1.687478]\n",
      "epoch:29 step:28000 [D loss: 0.453811, acc.: 77.34%] [G loss: 1.113081]\n",
      "epoch:29 step:28001 [D loss: 0.390655, acc.: 84.38%] [G loss: 0.806782]\n",
      "epoch:29 step:28002 [D loss: 0.621307, acc.: 69.53%] [G loss: 0.862150]\n",
      "epoch:29 step:28003 [D loss: 0.259287, acc.: 93.75%] [G loss: 1.268315]\n",
      "epoch:29 step:28004 [D loss: 0.220616, acc.: 93.75%] [G loss: 0.595015]\n",
      "epoch:29 step:28005 [D loss: 0.127389, acc.: 99.22%] [G loss: 1.244483]\n",
      "epoch:29 step:28006 [D loss: 0.143112, acc.: 97.66%] [G loss: 1.100903]\n",
      "epoch:29 step:28007 [D loss: 1.218920, acc.: 50.78%] [G loss: 1.886809]\n",
      "epoch:29 step:28008 [D loss: 1.375517, acc.: 12.50%] [G loss: 1.470953]\n",
      "epoch:29 step:28009 [D loss: 0.957085, acc.: 35.16%] [G loss: 0.787661]\n",
      "epoch:29 step:28010 [D loss: 0.879300, acc.: 38.28%] [G loss: 0.911242]\n",
      "epoch:29 step:28011 [D loss: 0.653201, acc.: 56.25%] [G loss: 0.741784]\n",
      "epoch:29 step:28012 [D loss: 1.461452, acc.: 26.56%] [G loss: 1.121059]\n",
      "epoch:29 step:28013 [D loss: 0.743326, acc.: 50.00%] [G loss: 1.250149]\n",
      "epoch:29 step:28014 [D loss: 0.750683, acc.: 51.56%] [G loss: 1.281636]\n",
      "epoch:29 step:28015 [D loss: 0.540829, acc.: 75.78%] [G loss: 1.100504]\n",
      "epoch:29 step:28016 [D loss: 0.347981, acc.: 88.28%] [G loss: 0.697718]\n",
      "epoch:29 step:28017 [D loss: 0.295333, acc.: 89.06%] [G loss: 1.100751]\n",
      "epoch:29 step:28018 [D loss: 0.241075, acc.: 92.97%] [G loss: 1.538136]\n",
      "epoch:29 step:28019 [D loss: 0.705674, acc.: 57.81%] [G loss: 1.354705]\n",
      "epoch:29 step:28020 [D loss: 0.487618, acc.: 75.00%] [G loss: 1.392983]\n",
      "epoch:29 step:28021 [D loss: 0.695556, acc.: 56.25%] [G loss: 1.262580]\n",
      "epoch:29 step:28022 [D loss: 0.778892, acc.: 44.53%] [G loss: 1.297129]\n",
      "epoch:29 step:28023 [D loss: 0.651930, acc.: 58.59%] [G loss: 1.206045]\n",
      "epoch:29 step:28024 [D loss: 0.385997, acc.: 82.81%] [G loss: 1.154353]\n",
      "epoch:29 step:28025 [D loss: 0.289621, acc.: 96.09%] [G loss: 1.201403]\n",
      "epoch:29 step:28026 [D loss: 0.408273, acc.: 84.38%] [G loss: 1.420341]\n",
      "epoch:29 step:28027 [D loss: 0.258110, acc.: 96.09%] [G loss: 1.394590]\n",
      "epoch:29 step:28028 [D loss: 0.363840, acc.: 92.97%] [G loss: 1.612237]\n",
      "epoch:29 step:28029 [D loss: 0.798260, acc.: 45.31%] [G loss: 1.241890]\n",
      "epoch:29 step:28030 [D loss: 0.268477, acc.: 97.66%] [G loss: 1.962432]\n",
      "epoch:29 step:28031 [D loss: 0.332023, acc.: 93.75%] [G loss: 1.488644]\n",
      "epoch:29 step:28032 [D loss: 0.283321, acc.: 92.19%] [G loss: 1.233276]\n",
      "epoch:29 step:28033 [D loss: 0.353809, acc.: 87.50%] [G loss: 1.297944]\n",
      "epoch:29 step:28034 [D loss: 0.519576, acc.: 74.22%] [G loss: 1.340515]\n",
      "epoch:29 step:28035 [D loss: 0.786659, acc.: 45.31%] [G loss: 1.307558]\n",
      "epoch:29 step:28036 [D loss: 0.628835, acc.: 63.28%] [G loss: 1.242901]\n",
      "epoch:29 step:28037 [D loss: 0.651176, acc.: 59.38%] [G loss: 1.213959]\n",
      "epoch:29 step:28038 [D loss: 0.526441, acc.: 76.56%] [G loss: 0.906566]\n",
      "epoch:29 step:28039 [D loss: 0.537574, acc.: 82.03%] [G loss: 1.226303]\n",
      "epoch:29 step:28040 [D loss: 0.471648, acc.: 75.00%] [G loss: 1.418466]\n",
      "epoch:29 step:28041 [D loss: 0.764407, acc.: 48.44%] [G loss: 1.300346]\n",
      "epoch:29 step:28042 [D loss: 0.681417, acc.: 58.59%] [G loss: 1.359471]\n",
      "epoch:29 step:28043 [D loss: 0.658020, acc.: 64.06%] [G loss: 1.117656]\n",
      "epoch:29 step:28044 [D loss: 0.593719, acc.: 66.41%] [G loss: 1.020553]\n",
      "epoch:29 step:28045 [D loss: 0.560876, acc.: 73.44%] [G loss: 0.961985]\n",
      "epoch:29 step:28046 [D loss: 0.728364, acc.: 53.12%] [G loss: 1.102702]\n",
      "epoch:29 step:28047 [D loss: 0.684336, acc.: 64.84%] [G loss: 0.898638]\n",
      "epoch:29 step:28048 [D loss: 0.475269, acc.: 82.81%] [G loss: 1.136847]\n",
      "epoch:29 step:28049 [D loss: 0.621522, acc.: 63.28%] [G loss: 1.091128]\n",
      "epoch:29 step:28050 [D loss: 0.624722, acc.: 57.03%] [G loss: 1.161837]\n",
      "epoch:29 step:28051 [D loss: 0.280142, acc.: 91.41%] [G loss: 1.318145]\n",
      "epoch:29 step:28052 [D loss: 0.650245, acc.: 64.06%] [G loss: 1.127164]\n",
      "epoch:29 step:28053 [D loss: 0.484064, acc.: 77.34%] [G loss: 1.205015]\n",
      "epoch:29 step:28054 [D loss: 0.599931, acc.: 67.97%] [G loss: 1.077617]\n",
      "epoch:29 step:28055 [D loss: 0.274400, acc.: 95.31%] [G loss: 1.181080]\n",
      "epoch:29 step:28056 [D loss: 0.412560, acc.: 88.28%] [G loss: 1.372741]\n",
      "epoch:29 step:28057 [D loss: 0.225891, acc.: 95.31%] [G loss: 1.417733]\n",
      "epoch:29 step:28058 [D loss: 0.328079, acc.: 78.91%] [G loss: 1.605765]\n",
      "epoch:29 step:28059 [D loss: 0.198720, acc.: 95.31%] [G loss: 1.661153]\n",
      "epoch:29 step:28060 [D loss: 0.149313, acc.: 99.22%] [G loss: 1.750332]\n",
      "epoch:29 step:28061 [D loss: 0.656842, acc.: 60.94%] [G loss: 1.575829]\n",
      "epoch:29 step:28062 [D loss: 0.226165, acc.: 93.75%] [G loss: 1.651200]\n",
      "epoch:29 step:28063 [D loss: 0.451829, acc.: 85.94%] [G loss: 1.272241]\n",
      "epoch:29 step:28064 [D loss: 0.788826, acc.: 51.56%] [G loss: 1.750173]\n",
      "epoch:29 step:28065 [D loss: 0.820251, acc.: 50.78%] [G loss: 1.092801]\n",
      "epoch:29 step:28066 [D loss: 0.719794, acc.: 61.72%] [G loss: 1.258797]\n",
      "epoch:29 step:28067 [D loss: 0.625004, acc.: 59.38%] [G loss: 1.128510]\n",
      "epoch:29 step:28068 [D loss: 0.536616, acc.: 77.34%] [G loss: 1.107193]\n",
      "epoch:29 step:28069 [D loss: 0.483947, acc.: 84.38%] [G loss: 0.962864]\n",
      "epoch:29 step:28070 [D loss: 0.420451, acc.: 88.28%] [G loss: 1.053317]\n",
      "epoch:29 step:28071 [D loss: 0.288454, acc.: 89.84%] [G loss: 1.036373]\n",
      "epoch:29 step:28072 [D loss: 0.262436, acc.: 88.28%] [G loss: 1.384989]\n",
      "epoch:29 step:28073 [D loss: 0.192489, acc.: 97.66%] [G loss: 1.480646]\n",
      "epoch:29 step:28074 [D loss: 0.594368, acc.: 67.19%] [G loss: 1.696118]\n",
      "epoch:29 step:28075 [D loss: 0.737604, acc.: 50.00%] [G loss: 1.618305]\n",
      "epoch:29 step:28076 [D loss: 0.493575, acc.: 75.78%] [G loss: 1.928155]\n",
      "epoch:29 step:28077 [D loss: 0.445308, acc.: 85.94%] [G loss: 1.436443]\n",
      "epoch:29 step:28078 [D loss: 0.248481, acc.: 92.97%] [G loss: 1.390086]\n",
      "epoch:29 step:28079 [D loss: 0.160628, acc.: 99.22%] [G loss: 1.377234]\n",
      "epoch:29 step:28080 [D loss: 0.792234, acc.: 50.78%] [G loss: 1.639183]\n",
      "epoch:29 step:28081 [D loss: 0.664066, acc.: 59.38%] [G loss: 1.437915]\n",
      "epoch:29 step:28082 [D loss: 0.402167, acc.: 86.72%] [G loss: 1.527725]\n",
      "epoch:29 step:28083 [D loss: 0.362737, acc.: 89.06%] [G loss: 1.421017]\n",
      "epoch:29 step:28084 [D loss: 0.223519, acc.: 97.66%] [G loss: 1.201126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28085 [D loss: 0.136549, acc.: 100.00%] [G loss: 1.914384]\n",
      "epoch:29 step:28086 [D loss: 0.740362, acc.: 53.12%] [G loss: 1.513388]\n",
      "epoch:29 step:28087 [D loss: 0.747407, acc.: 57.03%] [G loss: 1.243421]\n",
      "epoch:29 step:28088 [D loss: 0.951154, acc.: 35.16%] [G loss: 1.172137]\n",
      "epoch:29 step:28089 [D loss: 0.662386, acc.: 64.06%] [G loss: 1.292299]\n",
      "epoch:29 step:28090 [D loss: 0.340367, acc.: 85.16%] [G loss: 1.480267]\n",
      "epoch:29 step:28091 [D loss: 0.756401, acc.: 46.09%] [G loss: 1.229297]\n",
      "epoch:29 step:28092 [D loss: 0.341574, acc.: 91.41%] [G loss: 1.482868]\n",
      "epoch:29 step:28093 [D loss: 0.196378, acc.: 94.53%] [G loss: 1.379364]\n",
      "epoch:29 step:28094 [D loss: 0.257433, acc.: 90.62%] [G loss: 1.331200]\n",
      "epoch:29 step:28095 [D loss: 0.803379, acc.: 50.00%] [G loss: 1.533815]\n",
      "epoch:29 step:28096 [D loss: 0.570679, acc.: 69.53%] [G loss: 1.052172]\n",
      "epoch:29 step:28097 [D loss: 0.692455, acc.: 61.72%] [G loss: 1.280609]\n",
      "epoch:29 step:28098 [D loss: 0.299978, acc.: 92.97%] [G loss: 1.588603]\n",
      "epoch:29 step:28099 [D loss: 0.201039, acc.: 96.09%] [G loss: 1.586997]\n",
      "epoch:29 step:28100 [D loss: 0.110986, acc.: 99.22%] [G loss: 1.714532]\n",
      "epoch:29 step:28101 [D loss: 0.881016, acc.: 47.66%] [G loss: 1.806732]\n",
      "epoch:29 step:28102 [D loss: 0.166514, acc.: 99.22%] [G loss: 1.823802]\n",
      "epoch:29 step:28103 [D loss: 0.448382, acc.: 85.16%] [G loss: 1.539684]\n",
      "epoch:29 step:28104 [D loss: 0.490825, acc.: 78.12%] [G loss: 1.437414]\n",
      "epoch:29 step:28105 [D loss: 0.709296, acc.: 59.38%] [G loss: 1.316540]\n",
      "epoch:29 step:28106 [D loss: 0.324621, acc.: 89.84%] [G loss: 1.183581]\n",
      "epoch:29 step:28107 [D loss: 0.199572, acc.: 94.53%] [G loss: 1.542753]\n",
      "epoch:29 step:28108 [D loss: 0.265944, acc.: 95.31%] [G loss: 1.989851]\n",
      "epoch:29 step:28109 [D loss: 0.179530, acc.: 94.53%] [G loss: 1.576829]\n",
      "epoch:29 step:28110 [D loss: 0.183822, acc.: 95.31%] [G loss: 1.760071]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512 * 7 * 7, input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7,7, 512)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3,strides=1,padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3,strides=1, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(self.channels, strides=2,kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.img_rows*self.img_cols*self.channels, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(Reshape((self.img_rows,self.img_cols,self.channels)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2,padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "                # Generate a half batch of new images\n",
    "                gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on labels\n",
    "                sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if  global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch,global_step)\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch,global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        if not os.path.isdir('images_cgan'):\n",
    "            os.mkdir('images_cgan')\n",
    "        fig.savefig(\"images_cgan/epoch_%d_step_%d.png\" % (epoch,global_step))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cgan = CGAN()\n",
    "    cgan.train(epochs=30, batch_size=64, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
