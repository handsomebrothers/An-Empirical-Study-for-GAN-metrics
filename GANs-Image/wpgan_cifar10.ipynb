{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         3075      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,224,643\n",
      "Trainable params: 1,224,259\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,385\n",
      "Trainable params: 99,937\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5 [D loss: 41.168491] [G loss: -0.069504]\n",
      "epoch0 step10 [D loss: 49.962944] [G loss: -0.136793]\n",
      "epoch0 step15 [D loss: 44.444565] [G loss: -0.071928]\n",
      "epoch0 step20 [D loss: 37.074509] [G loss: -0.222208]\n",
      "epoch0 step25 [D loss: 39.464947] [G loss: -0.109974]\n",
      "epoch0 step30 [D loss: 30.682512] [G loss: -0.155986]\n",
      "epoch0 step35 [D loss: 23.939909] [G loss: -0.219287]\n",
      "epoch0 step40 [D loss: 25.078129] [G loss: -0.033152]\n",
      "epoch0 step45 [D loss: 18.928408] [G loss: -0.104180]\n",
      "epoch0 step50 [D loss: 18.227310] [G loss: -0.146719]\n",
      "epoch0 step55 [D loss: 18.945900] [G loss: -0.206374]\n",
      "epoch0 step60 [D loss: 13.453578] [G loss: -0.111615]\n",
      "epoch0 step65 [D loss: 13.019513] [G loss: -0.155081]\n",
      "epoch0 step70 [D loss: 10.912840] [G loss: -0.089241]\n",
      "epoch0 step75 [D loss: 11.780775] [G loss: -0.049562]\n",
      "epoch0 step80 [D loss: 8.191308] [G loss: 0.056165]\n",
      "epoch0 step85 [D loss: 8.831063] [G loss: 0.048138]\n",
      "epoch0 step90 [D loss: 8.791668] [G loss: 0.149269]\n",
      "epoch0 step95 [D loss: 6.804173] [G loss: 0.155899]\n",
      "epoch0 step100 [D loss: 5.293365] [G loss: 0.225061]\n",
      "epoch0 step105 [D loss: 5.001334] [G loss: 0.193485]\n",
      "epoch0 step110 [D loss: 5.068064] [G loss: 0.342826]\n",
      "epoch0 step115 [D loss: 2.668462] [G loss: 0.135659]\n",
      "epoch0 step120 [D loss: 6.112779] [G loss: 0.322335]\n",
      "epoch0 step125 [D loss: 3.082567] [G loss: 0.156092]\n",
      "epoch0 step130 [D loss: 2.695549] [G loss: 0.404987]\n",
      "epoch0 step135 [D loss: 2.789024] [G loss: 0.276561]\n",
      "epoch0 step140 [D loss: 1.210490] [G loss: 0.553889]\n",
      "epoch0 step145 [D loss: 3.085897] [G loss: 0.550436]\n",
      "epoch0 step150 [D loss: 1.278870] [G loss: 0.451390]\n",
      "epoch0 step155 [D loss: 1.144232] [G loss: 0.397844]\n",
      "epoch0 step160 [D loss: 1.896180] [G loss: 0.427644]\n",
      "epoch0 step165 [D loss: 0.666955] [G loss: 0.376312]\n",
      "epoch0 step170 [D loss: 0.508092] [G loss: 0.617514]\n",
      "epoch0 step175 [D loss: -0.110704] [G loss: 0.639948]\n",
      "epoch0 step180 [D loss: 0.255557] [G loss: 0.543935]\n",
      "epoch0 step185 [D loss: 0.217487] [G loss: 0.790570]\n",
      "epoch0 step190 [D loss: 0.215200] [G loss: 0.995088]\n",
      "epoch0 step195 [D loss: 0.243139] [G loss: 0.766379]\n",
      "epoch0 step200 [D loss: -0.682078] [G loss: 1.202917]\n",
      "epoch0 step205 [D loss: -0.107725] [G loss: 0.883375]\n",
      "epoch0 step210 [D loss: -0.464233] [G loss: 1.120477]\n",
      "epoch0 step215 [D loss: -0.561317] [G loss: 1.277585]\n",
      "epoch0 step220 [D loss: -0.600129] [G loss: 1.219126]\n",
      "epoch0 step225 [D loss: -0.833595] [G loss: 1.285649]\n",
      "epoch0 step230 [D loss: -1.097072] [G loss: 1.253905]\n",
      "epoch0 step235 [D loss: -0.677997] [G loss: 1.447308]\n",
      "epoch0 step240 [D loss: -0.783609] [G loss: 1.501454]\n",
      "epoch0 step245 [D loss: -0.873247] [G loss: 1.578554]\n",
      "epoch0 step250 [D loss: -0.970515] [G loss: 1.574455]\n",
      "epoch0 step255 [D loss: -1.217182] [G loss: 1.718698]\n",
      "epoch0 step260 [D loss: -1.018804] [G loss: 1.841941]\n",
      "epoch0 step265 [D loss: -1.267688] [G loss: 1.908555]\n",
      "epoch0 step270 [D loss: -1.150462] [G loss: 2.111311]\n",
      "epoch0 step275 [D loss: -1.021432] [G loss: 2.232579]\n",
      "epoch0 step280 [D loss: -1.320347] [G loss: 2.529619]\n",
      "epoch0 step285 [D loss: -1.553560] [G loss: 2.330627]\n",
      "epoch0 step290 [D loss: -1.140829] [G loss: 2.550137]\n",
      "epoch0 step295 [D loss: -1.400113] [G loss: 2.456314]\n",
      "epoch0 step300 [D loss: -0.780951] [G loss: 2.354649]\n",
      "epoch0 step305 [D loss: -0.548479] [G loss: 1.790432]\n",
      "epoch0 step310 [D loss: -0.971466] [G loss: 1.825474]\n",
      "epoch0 step315 [D loss: -0.581164] [G loss: 1.686678]\n",
      "epoch0 step320 [D loss: -0.467325] [G loss: 1.580706]\n",
      "epoch0 step325 [D loss: -0.920793] [G loss: 2.135539]\n",
      "epoch0 step330 [D loss: -1.181222] [G loss: 2.280498]\n",
      "epoch0 step335 [D loss: -1.923653] [G loss: 2.664177]\n",
      "epoch0 step340 [D loss: -1.545431] [G loss: 3.065363]\n",
      "epoch0 step345 [D loss: -2.065047] [G loss: 2.847769]\n",
      "epoch0 step350 [D loss: -2.761861] [G loss: 3.257158]\n",
      "epoch0 step355 [D loss: -2.743578] [G loss: 3.138679]\n",
      "epoch0 step360 [D loss: -2.179876] [G loss: 3.200572]\n",
      "epoch0 step365 [D loss: -2.467035] [G loss: 3.390698]\n",
      "epoch0 step370 [D loss: -2.369406] [G loss: 3.044569]\n",
      "epoch0 step375 [D loss: -2.057285] [G loss: 2.795624]\n",
      "epoch0 step380 [D loss: -1.282821] [G loss: 1.824390]\n",
      "epoch0 step385 [D loss: -0.309015] [G loss: 1.324787]\n",
      "epoch0 step390 [D loss: -0.275116] [G loss: 1.040501]\n",
      "epoch0 step395 [D loss: 0.481978] [G loss: 0.687645]\n",
      "epoch0 step400 [D loss: 0.509901] [G loss: 0.662810]\n",
      "epoch0 step405 [D loss: 0.257083] [G loss: 0.924607]\n",
      "epoch0 step410 [D loss: -0.408722] [G loss: 1.041410]\n",
      "epoch0 step415 [D loss: -0.662354] [G loss: 1.647761]\n",
      "epoch0 step420 [D loss: -0.647481] [G loss: 2.078997]\n",
      "epoch0 step425 [D loss: -1.486539] [G loss: 2.365215]\n",
      "epoch0 step430 [D loss: -1.208669] [G loss: 2.666629]\n",
      "epoch0 step435 [D loss: -1.392051] [G loss: 2.736214]\n",
      "epoch0 step440 [D loss: -2.014168] [G loss: 3.097133]\n",
      "epoch0 step445 [D loss: -2.352123] [G loss: 3.632609]\n",
      "epoch0 step450 [D loss: -2.572627] [G loss: 3.877342]\n",
      "epoch0 step455 [D loss: -2.699356] [G loss: 3.599998]\n",
      "epoch0 step460 [D loss: -2.561101] [G loss: 4.200726]\n",
      "epoch0 step465 [D loss: -2.740611] [G loss: 3.656822]\n",
      "epoch0 step470 [D loss: -2.478173] [G loss: 3.973852]\n",
      "epoch0 step475 [D loss: -2.178735] [G loss: 3.800403]\n",
      "epoch0 step480 [D loss: -2.266814] [G loss: 3.571625]\n",
      "epoch0 step485 [D loss: -1.677958] [G loss: 2.727704]\n",
      "epoch0 step490 [D loss: -1.148216] [G loss: 1.973280]\n",
      "epoch0 step495 [D loss: -0.464924] [G loss: 1.521287]\n",
      "epoch0 step500 [D loss: 0.637329] [G loss: 0.900380]\n",
      "epoch0 step505 [D loss: 0.287624] [G loss: 0.913657]\n",
      "epoch0 step510 [D loss: 0.202942] [G loss: 0.805100]\n",
      "epoch0 step515 [D loss: 0.515307] [G loss: 1.177631]\n",
      "epoch0 step520 [D loss: 0.181952] [G loss: 1.049359]\n",
      "epoch0 step525 [D loss: -0.298399] [G loss: 1.595848]\n",
      "epoch0 step530 [D loss: -0.570645] [G loss: 1.915789]\n",
      "epoch0 step535 [D loss: -1.215041] [G loss: 2.491923]\n",
      "epoch0 step540 [D loss: -1.730533] [G loss: 2.658353]\n",
      "epoch0 step545 [D loss: -1.637615] [G loss: 3.146856]\n",
      "epoch0 step550 [D loss: -2.790698] [G loss: 3.471933]\n",
      "epoch0 step555 [D loss: -2.274918] [G loss: 3.561874]\n",
      "epoch0 step560 [D loss: -1.303939] [G loss: 3.416453]\n",
      "epoch0 step565 [D loss: -2.244124] [G loss: 3.292952]\n",
      "epoch0 step570 [D loss: -3.063235] [G loss: 3.713515]\n",
      "epoch0 step575 [D loss: -1.951410] [G loss: 3.200583]\n",
      "epoch0 step580 [D loss: -1.585647] [G loss: 2.775607]\n",
      "epoch0 step585 [D loss: -1.213490] [G loss: 2.618106]\n",
      "epoch0 step590 [D loss: -1.049563] [G loss: 2.097728]\n",
      "epoch0 step595 [D loss: -1.193206] [G loss: 2.197115]\n",
      "epoch0 step600 [D loss: -0.544204] [G loss: 1.934618]\n",
      "epoch0 step605 [D loss: -1.015629] [G loss: 2.059653]\n",
      "epoch0 step610 [D loss: -0.799730] [G loss: 1.945107]\n",
      "epoch0 step615 [D loss: -0.426435] [G loss: 2.154936]\n",
      "epoch0 step620 [D loss: -0.760975] [G loss: 2.126385]\n",
      "epoch0 step625 [D loss: -0.906847] [G loss: 2.412508]\n",
      "epoch0 step630 [D loss: -0.722175] [G loss: 2.286637]\n",
      "epoch0 step635 [D loss: -1.392937] [G loss: 2.937460]\n",
      "epoch0 step640 [D loss: -1.317827] [G loss: 2.979740]\n",
      "epoch0 step645 [D loss: -1.991431] [G loss: 3.071391]\n",
      "epoch0 step650 [D loss: -0.847151] [G loss: 2.677293]\n",
      "epoch0 step655 [D loss: -0.903412] [G loss: 2.495000]\n",
      "epoch0 step660 [D loss: -0.526026] [G loss: 2.308799]\n",
      "epoch0 step665 [D loss: -0.146565] [G loss: 1.982327]\n",
      "epoch0 step670 [D loss: -1.214231] [G loss: 2.322519]\n",
      "epoch0 step675 [D loss: -0.632116] [G loss: 1.972747]\n",
      "epoch0 step680 [D loss: -1.305657] [G loss: 2.134786]\n",
      "epoch0 step685 [D loss: -0.205711] [G loss: 2.332654]\n",
      "epoch0 step690 [D loss: -0.893175] [G loss: 2.177732]\n",
      "epoch0 step695 [D loss: -0.957485] [G loss: 2.401768]\n",
      "epoch0 step700 [D loss: -0.962649] [G loss: 2.722686]\n",
      "epoch0 step705 [D loss: -1.413997] [G loss: 2.352832]\n",
      "epoch0 step710 [D loss: -1.691485] [G loss: 2.701381]\n",
      "epoch0 step715 [D loss: -2.129035] [G loss: 2.572990]\n",
      "epoch0 step720 [D loss: -1.428868] [G loss: 2.641758]\n",
      "epoch0 step725 [D loss: -1.519281] [G loss: 2.579086]\n",
      "epoch0 step730 [D loss: -1.063011] [G loss: 2.584165]\n",
      "epoch0 step735 [D loss: -0.666257] [G loss: 2.275990]\n",
      "epoch0 step740 [D loss: -0.791668] [G loss: 2.507607]\n",
      "epoch0 step745 [D loss: -0.647958] [G loss: 2.007378]\n",
      "epoch0 step750 [D loss: -0.359012] [G loss: 2.007089]\n",
      "epoch0 step755 [D loss: 0.143616] [G loss: 1.537697]\n",
      "epoch0 step760 [D loss: -0.838202] [G loss: 1.756205]\n",
      "epoch0 step765 [D loss: -0.170577] [G loss: 1.630640]\n",
      "epoch0 step770 [D loss: -0.765452] [G loss: 2.107362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step775 [D loss: -1.080407] [G loss: 2.180385]\n",
      "epoch0 step780 [D loss: -0.800211] [G loss: 2.417128]\n",
      "epoch0 step785 [D loss: -0.933736] [G loss: 2.175747]\n",
      "epoch0 step790 [D loss: -1.253410] [G loss: 2.617570]\n",
      "epoch0 step795 [D loss: -0.592680] [G loss: 2.708334]\n",
      "epoch0 step800 [D loss: -1.330419] [G loss: 3.125541]\n",
      "epoch0 step805 [D loss: -1.418691] [G loss: 2.875823]\n",
      "epoch0 step810 [D loss: -1.213320] [G loss: 3.304039]\n",
      "epoch0 step815 [D loss: -1.496240] [G loss: 3.121229]\n",
      "epoch0 step820 [D loss: -1.319165] [G loss: 3.229015]\n",
      "epoch0 step825 [D loss: 0.032796] [G loss: 2.722104]\n",
      "epoch0 step830 [D loss: -1.064786] [G loss: 3.251639]\n",
      "epoch0 step835 [D loss: -0.714844] [G loss: 2.630995]\n",
      "epoch0 step840 [D loss: -0.900309] [G loss: 3.109566]\n",
      "epoch0 step845 [D loss: -0.438599] [G loss: 2.361563]\n",
      "epoch0 step850 [D loss: -0.116286] [G loss: 2.341780]\n",
      "epoch0 step855 [D loss: -0.062834] [G loss: 2.456864]\n",
      "epoch0 step860 [D loss: -0.804647] [G loss: 2.394067]\n",
      "epoch0 step865 [D loss: -0.843578] [G loss: 2.735829]\n",
      "epoch0 step870 [D loss: -0.371426] [G loss: 2.536220]\n",
      "epoch0 step875 [D loss: -0.373259] [G loss: 2.358998]\n",
      "epoch0 step880 [D loss: -0.513109] [G loss: 2.736083]\n",
      "epoch0 step885 [D loss: -0.830494] [G loss: 2.490095]\n",
      "epoch0 step890 [D loss: -1.318702] [G loss: 2.703093]\n",
      "epoch0 step895 [D loss: -0.280146] [G loss: 2.692252]\n",
      "epoch0 step900 [D loss: -0.486389] [G loss: 2.616906]\n",
      "epoch0 step905 [D loss: -0.909159] [G loss: 2.773795]\n",
      "epoch0 step910 [D loss: -0.706708] [G loss: 2.988282]\n",
      "epoch0 step915 [D loss: -0.598660] [G loss: 2.699989]\n",
      "epoch0 step920 [D loss: -1.032682] [G loss: 2.619250]\n",
      "epoch0 step925 [D loss: -1.052449] [G loss: 3.330122]\n",
      "epoch0 step930 [D loss: -0.666967] [G loss: 2.735756]\n",
      "epoch0 step935 [D loss: -0.658884] [G loss: 2.974638]\n",
      "epoch0 step940 [D loss: -1.176826] [G loss: 2.901063]\n",
      "epoch0 step945 [D loss: -0.599607] [G loss: 2.698140]\n",
      "epoch0 step950 [D loss: -0.567840] [G loss: 2.355247]\n",
      "epoch0 step955 [D loss: -0.934831] [G loss: 2.562991]\n",
      "epoch0 step960 [D loss: -0.253367] [G loss: 2.487709]\n",
      "epoch0 step965 [D loss: -0.075943] [G loss: 2.674863]\n",
      "epoch0 step970 [D loss: -0.340744] [G loss: 2.518728]\n",
      "epoch0 step975 [D loss: -0.736968] [G loss: 3.194184]\n",
      "epoch0 step980 [D loss: -0.527205] [G loss: 2.750349]\n",
      "epoch0 step985 [D loss: -0.879555] [G loss: 2.914055]\n",
      "epoch0 step990 [D loss: -0.931244] [G loss: 3.191458]\n",
      "epoch0 step995 [D loss: -0.465910] [G loss: 3.262462]\n",
      "epoch0 step1000 [D loss: -1.291834] [G loss: 3.254703]\n",
      "epoch0 step1005 [D loss: -1.172586] [G loss: 3.196820]\n",
      "epoch0 step1010 [D loss: -0.671886] [G loss: 3.024159]\n",
      "epoch0 step1015 [D loss: -1.028210] [G loss: 2.893825]\n",
      "epoch0 step1020 [D loss: -0.730375] [G loss: 3.321150]\n",
      "epoch0 step1025 [D loss: -0.821426] [G loss: 3.020107]\n",
      "epoch0 step1030 [D loss: -0.262197] [G loss: 2.570638]\n",
      "epoch0 step1035 [D loss: -0.922843] [G loss: 2.904936]\n",
      "epoch0 step1040 [D loss: 0.216647] [G loss: 2.828256]\n",
      "epoch0 step1045 [D loss: -0.234845] [G loss: 2.657317]\n",
      "epoch0 step1050 [D loss: -0.802011] [G loss: 2.901206]\n",
      "epoch0 step1055 [D loss: -0.404383] [G loss: 2.893839]\n",
      "epoch0 step1060 [D loss: -0.440343] [G loss: 2.986938]\n",
      "epoch0 step1065 [D loss: -0.368492] [G loss: 2.874745]\n",
      "epoch0 step1070 [D loss: -0.991530] [G loss: 3.437578]\n",
      "epoch0 step1075 [D loss: -0.678847] [G loss: 3.200460]\n",
      "epoch0 step1080 [D loss: -1.547535] [G loss: 3.425851]\n",
      "epoch0 step1085 [D loss: -1.108197] [G loss: 3.290448]\n",
      "epoch0 step1090 [D loss: -0.679658] [G loss: 3.251247]\n",
      "epoch0 step1095 [D loss: -0.773719] [G loss: 2.893930]\n",
      "epoch0 step1100 [D loss: -0.765019] [G loss: 2.737481]\n",
      "epoch0 step1105 [D loss: -0.421506] [G loss: 3.063550]\n",
      "epoch0 step1110 [D loss: -0.348895] [G loss: 3.041234]\n",
      "epoch0 step1115 [D loss: -0.517868] [G loss: 3.177699]\n",
      "epoch0 step1120 [D loss: -0.549785] [G loss: 3.279121]\n",
      "epoch0 step1125 [D loss: -0.649016] [G loss: 3.333132]\n",
      "epoch0 step1130 [D loss: -0.521365] [G loss: 3.309141]\n",
      "epoch0 step1135 [D loss: -1.058186] [G loss: 3.447450]\n",
      "epoch0 step1140 [D loss: -0.852408] [G loss: 3.030119]\n",
      "epoch0 step1145 [D loss: -0.788763] [G loss: 3.501726]\n",
      "epoch0 step1150 [D loss: -0.729722] [G loss: 3.303109]\n",
      "epoch0 step1155 [D loss: -0.807921] [G loss: 3.414388]\n",
      "epoch0 step1160 [D loss: -0.703488] [G loss: 3.953537]\n",
      "epoch0 step1165 [D loss: -1.007693] [G loss: 3.800941]\n",
      "epoch0 step1170 [D loss: -0.771227] [G loss: 3.386264]\n",
      "epoch0 step1175 [D loss: -0.686184] [G loss: 3.358703]\n",
      "epoch0 step1180 [D loss: -1.001568] [G loss: 3.619600]\n",
      "epoch0 step1185 [D loss: -0.617482] [G loss: 3.511556]\n",
      "epoch0 step1190 [D loss: -0.797994] [G loss: 3.408941]\n",
      "epoch0 step1195 [D loss: -0.923052] [G loss: 3.234270]\n",
      "epoch0 step1200 [D loss: -0.067325] [G loss: 3.395800]\n",
      "epoch0 step1205 [D loss: -0.990267] [G loss: 3.571787]\n",
      "epoch0 step1210 [D loss: -0.650752] [G loss: 3.268534]\n",
      "epoch0 step1215 [D loss: -0.818369] [G loss: 3.476947]\n",
      "epoch0 step1220 [D loss: -1.215531] [G loss: 3.461404]\n",
      "epoch0 step1225 [D loss: -0.361767] [G loss: 3.329014]\n",
      "epoch0 step1230 [D loss: -1.404084] [G loss: 3.115079]\n",
      "epoch0 step1235 [D loss: -0.444109] [G loss: 2.853499]\n",
      "epoch0 step1240 [D loss: -0.420626] [G loss: 3.048828]\n",
      "epoch0 step1245 [D loss: -0.905033] [G loss: 3.740235]\n",
      "epoch0 step1250 [D loss: -0.652136] [G loss: 3.859270]\n",
      "epoch0 step1255 [D loss: -0.547971] [G loss: 3.648417]\n",
      "epoch0 step1260 [D loss: -0.579197] [G loss: 3.494878]\n",
      "epoch0 step1265 [D loss: -0.198261] [G loss: 3.174959]\n",
      "epoch0 step1270 [D loss: -1.263957] [G loss: 3.831438]\n",
      "epoch0 step1275 [D loss: -0.416427] [G loss: 3.770025]\n",
      "epoch0 step1280 [D loss: -0.410832] [G loss: 3.561781]\n",
      "epoch0 step1285 [D loss: -0.978096] [G loss: 3.834906]\n",
      "epoch0 step1290 [D loss: 0.224857] [G loss: 3.477274]\n",
      "epoch0 step1295 [D loss: -0.589375] [G loss: 3.693686]\n",
      "epoch0 step1300 [D loss: 0.054457] [G loss: 3.382610]\n",
      "epoch0 step1305 [D loss: -0.130451] [G loss: 3.594700]\n",
      "epoch0 step1310 [D loss: -1.108291] [G loss: 3.436466]\n",
      "epoch0 step1315 [D loss: -0.703758] [G loss: 3.594621]\n",
      "epoch0 step1320 [D loss: -0.451050] [G loss: 3.416687]\n",
      "epoch0 step1325 [D loss: -0.524340] [G loss: 3.375302]\n",
      "epoch0 step1330 [D loss: -1.162513] [G loss: 3.613333]\n",
      "epoch0 step1335 [D loss: -0.495988] [G loss: 3.488239]\n",
      "epoch0 step1340 [D loss: 0.127667] [G loss: 3.177424]\n",
      "epoch0 step1345 [D loss: -0.700584] [G loss: 3.876490]\n",
      "epoch0 step1350 [D loss: -0.946044] [G loss: 3.357873]\n",
      "epoch0 step1355 [D loss: 0.142994] [G loss: 3.455502]\n",
      "epoch0 step1360 [D loss: -0.823586] [G loss: 3.427893]\n",
      "epoch0 step1365 [D loss: -0.735720] [G loss: 3.613558]\n",
      "epoch0 step1370 [D loss: -0.202964] [G loss: 3.644090]\n",
      "epoch0 step1375 [D loss: -0.607121] [G loss: 3.857056]\n",
      "epoch0 step1380 [D loss: -0.436187] [G loss: 3.350633]\n",
      "epoch0 step1385 [D loss: -0.803763] [G loss: 3.663596]\n",
      "epoch0 step1390 [D loss: -0.726003] [G loss: 3.420218]\n",
      "epoch0 step1395 [D loss: -0.839253] [G loss: 3.607265]\n",
      "epoch0 step1400 [D loss: -0.677841] [G loss: 3.591117]\n",
      "epoch0 step1405 [D loss: -0.603727] [G loss: 3.298879]\n",
      "epoch0 step1410 [D loss: -0.829883] [G loss: 3.787838]\n",
      "epoch0 step1415 [D loss: -0.488718] [G loss: 3.587349]\n",
      "epoch0 step1420 [D loss: -0.521849] [G loss: 3.814914]\n",
      "epoch0 step1425 [D loss: -0.172802] [G loss: 3.690860]\n",
      "epoch0 step1430 [D loss: -0.633601] [G loss: 3.770383]\n",
      "epoch0 step1435 [D loss: -0.649308] [G loss: 3.815667]\n",
      "epoch0 step1440 [D loss: -0.427379] [G loss: 3.593260]\n",
      "epoch0 step1445 [D loss: -0.194595] [G loss: 3.366437]\n",
      "epoch0 step1450 [D loss: -0.309983] [G loss: 3.226226]\n",
      "epoch0 step1455 [D loss: -0.713169] [G loss: 3.405361]\n",
      "epoch0 step1460 [D loss: -0.344628] [G loss: 3.572053]\n",
      "epoch0 step1465 [D loss: -0.454104] [G loss: 3.480840]\n",
      "epoch0 step1470 [D loss: -0.565009] [G loss: 3.599108]\n",
      "epoch0 step1475 [D loss: -0.881018] [G loss: 3.385312]\n",
      "epoch0 step1480 [D loss: -0.926999] [G loss: 3.444552]\n",
      "epoch0 step1485 [D loss: -0.603824] [G loss: 3.521062]\n",
      "epoch0 step1490 [D loss: -0.998706] [G loss: 3.771416]\n",
      "epoch0 step1495 [D loss: -0.342667] [G loss: 3.308869]\n",
      "epoch0 step1500 [D loss: -0.659200] [G loss: 3.628681]\n",
      "epoch0 step1505 [D loss: -0.664643] [G loss: 3.403214]\n",
      "epoch0 step1510 [D loss: -0.407182] [G loss: 3.467463]\n",
      "epoch0 step1515 [D loss: -0.159167] [G loss: 3.649947]\n",
      "epoch0 step1520 [D loss: -0.450026] [G loss: 3.472294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step1525 [D loss: -1.019260] [G loss: 3.812845]\n",
      "epoch0 step1530 [D loss: -0.671171] [G loss: 3.470428]\n",
      "epoch0 step1535 [D loss: 0.047803] [G loss: 3.259905]\n",
      "epoch0 step1540 [D loss: -1.076370] [G loss: 3.288440]\n",
      "epoch0 step1545 [D loss: -0.486315] [G loss: 3.575661]\n",
      "epoch0 step1550 [D loss: -0.436766] [G loss: 3.360230]\n",
      "epoch0 step1555 [D loss: -1.320002] [G loss: 3.548975]\n",
      "epoch0 step1560 [D loss: -0.793537] [G loss: 3.411624]\n",
      "epoch0 step1565 [D loss: -0.474861] [G loss: 3.704412]\n",
      "epoch0 step1570 [D loss: -1.019269] [G loss: 3.504222]\n",
      "epoch0 step1575 [D loss: -0.422171] [G loss: 3.521278]\n",
      "epoch0 step1580 [D loss: -0.766873] [G loss: 3.488610]\n",
      "epoch0 step1585 [D loss: -0.560620] [G loss: 3.328619]\n",
      "epoch0 step1590 [D loss: -0.481189] [G loss: 3.410769]\n",
      "epoch0 step1595 [D loss: -1.141312] [G loss: 3.667972]\n",
      "epoch0 step1600 [D loss: -1.421110] [G loss: 3.554756]\n",
      "epoch0 step1605 [D loss: 0.140138] [G loss: 3.218200]\n",
      "epoch0 step1610 [D loss: -0.438427] [G loss: 3.263301]\n",
      "epoch0 step1615 [D loss: -0.287622] [G loss: 3.005261]\n",
      "epoch0 step1620 [D loss: -0.650158] [G loss: 3.316076]\n",
      "epoch0 step1625 [D loss: -0.666771] [G loss: 3.021062]\n",
      "epoch0 step1630 [D loss: -0.479585] [G loss: 3.021086]\n",
      "epoch0 step1635 [D loss: -0.517112] [G loss: 3.691071]\n",
      "epoch0 step1640 [D loss: -0.553136] [G loss: 3.203260]\n",
      "epoch0 step1645 [D loss: -0.425213] [G loss: 2.986819]\n",
      "epoch0 step1650 [D loss: -0.098459] [G loss: 2.808578]\n",
      "epoch0 step1655 [D loss: -0.701721] [G loss: 3.352468]\n",
      "epoch0 step1660 [D loss: -0.529722] [G loss: 3.093008]\n",
      "epoch0 step1665 [D loss: -0.645255] [G loss: 3.143060]\n",
      "epoch0 step1670 [D loss: -0.267945] [G loss: 3.082654]\n",
      "epoch0 step1675 [D loss: -0.879012] [G loss: 3.233653]\n",
      "epoch0 step1680 [D loss: -0.629953] [G loss: 3.018368]\n",
      "epoch0 step1685 [D loss: -0.437424] [G loss: 3.089830]\n",
      "epoch0 step1690 [D loss: -0.518201] [G loss: 2.941019]\n",
      "epoch0 step1695 [D loss: -0.846430] [G loss: 3.226249]\n",
      "epoch0 step1700 [D loss: -0.262793] [G loss: 2.765323]\n",
      "epoch0 step1705 [D loss: -0.535867] [G loss: 2.716269]\n",
      "epoch0 step1710 [D loss: -0.606053] [G loss: 3.078625]\n",
      "epoch0 step1715 [D loss: 0.357018] [G loss: 2.703964]\n",
      "epoch0 step1720 [D loss: -0.959196] [G loss: 3.182516]\n",
      "epoch0 step1725 [D loss: -0.846651] [G loss: 3.302424]\n",
      "epoch0 step1730 [D loss: -0.292859] [G loss: 3.181726]\n",
      "epoch0 step1735 [D loss: -0.616745] [G loss: 2.738811]\n",
      "epoch0 step1740 [D loss: -0.971327] [G loss: 3.302004]\n",
      "epoch0 step1745 [D loss: 0.000579] [G loss: 3.157756]\n",
      "epoch0 step1750 [D loss: -1.010156] [G loss: 3.209426]\n",
      "epoch0 step1755 [D loss: -0.908629] [G loss: 3.453436]\n",
      "epoch0 step1760 [D loss: -0.183002] [G loss: 3.066955]\n",
      "epoch0 step1765 [D loss: -1.105189] [G loss: 3.248958]\n",
      "epoch0 step1770 [D loss: -0.470446] [G loss: 3.432785]\n",
      "epoch0 step1775 [D loss: -0.648283] [G loss: 2.963222]\n",
      "epoch0 step1780 [D loss: -0.704143] [G loss: 3.319812]\n",
      "epoch0 step1785 [D loss: -0.153249] [G loss: 3.073985]\n",
      "epoch0 step1790 [D loss: -0.555453] [G loss: 3.205481]\n",
      "epoch0 step1795 [D loss: -0.998562] [G loss: 3.488049]\n",
      "epoch0 step1800 [D loss: -0.430131] [G loss: 3.117389]\n",
      "epoch0 step1805 [D loss: -0.384527] [G loss: 3.180038]\n",
      "epoch0 step1810 [D loss: -0.919508] [G loss: 3.186535]\n",
      "epoch0 step1815 [D loss: -0.278837] [G loss: 2.914912]\n",
      "epoch0 step1820 [D loss: -0.800374] [G loss: 3.105018]\n",
      "epoch0 step1825 [D loss: -0.463388] [G loss: 3.114148]\n",
      "epoch0 step1830 [D loss: -0.492739] [G loss: 2.905502]\n",
      "epoch0 step1835 [D loss: -0.446761] [G loss: 2.957892]\n",
      "epoch0 step1840 [D loss: -0.843610] [G loss: 3.097504]\n",
      "epoch0 step1845 [D loss: -0.836031] [G loss: 2.963346]\n",
      "epoch0 step1850 [D loss: -1.218052] [G loss: 3.155876]\n",
      "epoch0 step1855 [D loss: -0.909459] [G loss: 2.964334]\n",
      "epoch0 step1860 [D loss: -0.694762] [G loss: 2.998209]\n",
      "epoch0 step1865 [D loss: -0.528202] [G loss: 2.822424]\n",
      "epoch0 step1870 [D loss: -0.979492] [G loss: 3.170086]\n",
      "epoch0 step1875 [D loss: -0.445000] [G loss: 3.097478]\n",
      "epoch0 step1880 [D loss: -0.545899] [G loss: 3.037410]\n",
      "epoch0 step1885 [D loss: 0.320136] [G loss: 2.629294]\n",
      "epoch0 step1890 [D loss: -0.388869] [G loss: 2.578923]\n",
      "epoch0 step1895 [D loss: -0.772021] [G loss: 2.592591]\n",
      "epoch0 step1900 [D loss: -0.614107] [G loss: 2.554061]\n",
      "epoch0 step1905 [D loss: -0.063144] [G loss: 2.916101]\n",
      "epoch0 step1910 [D loss: -0.637579] [G loss: 2.857827]\n",
      "epoch0 step1915 [D loss: -0.655621] [G loss: 2.890840]\n",
      "epoch0 step1920 [D loss: -0.460986] [G loss: 2.862616]\n",
      "epoch0 step1925 [D loss: -0.386190] [G loss: 2.673362]\n",
      "epoch0 step1930 [D loss: -0.786038] [G loss: 2.760943]\n",
      "epoch0 step1935 [D loss: -0.844594] [G loss: 3.123434]\n",
      "epoch0 step1940 [D loss: -0.025608] [G loss: 2.764377]\n",
      "epoch0 step1945 [D loss: -0.753624] [G loss: 2.709635]\n",
      "epoch0 step1950 [D loss: -1.263451] [G loss: 2.945612]\n",
      "epoch0 step1955 [D loss: -0.567659] [G loss: 2.452529]\n",
      "epoch0 step1960 [D loss: -0.896174] [G loss: 2.596447]\n",
      "epoch0 step1965 [D loss: -0.785899] [G loss: 2.748106]\n",
      "epoch0 step1970 [D loss: -0.541623] [G loss: 2.530414]\n",
      "epoch0 step1975 [D loss: -0.942481] [G loss: 3.023673]\n",
      "epoch0 step1980 [D loss: -0.472115] [G loss: 2.624309]\n",
      "epoch0 step1985 [D loss: -1.000893] [G loss: 2.609198]\n",
      "epoch0 step1990 [D loss: 0.159562] [G loss: 2.066667]\n",
      "epoch0 step1995 [D loss: -0.330540] [G loss: 2.503984]\n",
      "epoch0 step2000 [D loss: -0.253345] [G loss: 2.667848]\n",
      "epoch0 step2005 [D loss: -0.431204] [G loss: 2.553035]\n",
      "epoch0 step2010 [D loss: -0.494914] [G loss: 2.348392]\n",
      "epoch0 step2015 [D loss: -0.678098] [G loss: 2.661080]\n",
      "epoch0 step2020 [D loss: -0.903646] [G loss: 2.557279]\n",
      "epoch0 step2025 [D loss: -0.562779] [G loss: 2.557859]\n",
      "epoch0 step2030 [D loss: -1.196199] [G loss: 2.739354]\n",
      "epoch0 step2035 [D loss: -1.328552] [G loss: 2.663590]\n",
      "epoch0 step2040 [D loss: -0.423564] [G loss: 2.913694]\n",
      "epoch0 step2045 [D loss: 0.142931] [G loss: 2.386869]\n",
      "epoch0 step2050 [D loss: -0.241959] [G loss: 2.430341]\n",
      "epoch0 step2055 [D loss: -0.609330] [G loss: 2.575387]\n",
      "epoch0 step2060 [D loss: -0.537145] [G loss: 2.495267]\n",
      "epoch0 step2065 [D loss: -0.662505] [G loss: 2.374273]\n",
      "epoch0 step2070 [D loss: -0.564150] [G loss: 2.671600]\n",
      "epoch0 step2075 [D loss: -0.281146] [G loss: 2.529530]\n",
      "epoch0 step2080 [D loss: -0.526173] [G loss: 2.456226]\n",
      "epoch0 step2085 [D loss: -0.686962] [G loss: 2.737310]\n",
      "epoch0 step2090 [D loss: -0.880598] [G loss: 2.662699]\n",
      "epoch0 step2095 [D loss: -0.511778] [G loss: 2.445691]\n",
      "epoch0 step2100 [D loss: -0.657026] [G loss: 2.734255]\n",
      "epoch0 step2105 [D loss: -0.426849] [G loss: 2.021595]\n",
      "epoch0 step2110 [D loss: -1.330944] [G loss: 2.587056]\n",
      "epoch0 step2115 [D loss: -1.093464] [G loss: 2.814201]\n",
      "epoch0 step2120 [D loss: -0.806524] [G loss: 2.709762]\n",
      "epoch0 step2125 [D loss: -0.180738] [G loss: 2.418827]\n",
      "epoch0 step2130 [D loss: -0.997264] [G loss: 2.704720]\n",
      "epoch0 step2135 [D loss: -0.092446] [G loss: 2.209315]\n",
      "epoch0 step2140 [D loss: -0.407259] [G loss: 2.342644]\n",
      "epoch0 step2145 [D loss: -0.509474] [G loss: 2.719192]\n",
      "epoch0 step2150 [D loss: -0.467299] [G loss: 2.303929]\n",
      "epoch0 step2155 [D loss: -0.592827] [G loss: 2.308785]\n",
      "epoch0 step2160 [D loss: -0.819001] [G loss: 2.478938]\n",
      "epoch0 step2165 [D loss: -1.548399] [G loss: 2.747837]\n",
      "epoch0 step2170 [D loss: -0.901008] [G loss: 2.611007]\n",
      "epoch0 step2175 [D loss: -0.436869] [G loss: 2.223401]\n",
      "epoch0 step2180 [D loss: -0.516010] [G loss: 2.267889]\n",
      "epoch0 step2185 [D loss: -0.580205] [G loss: 2.577335]\n",
      "epoch0 step2190 [D loss: -0.864904] [G loss: 2.496150]\n",
      "epoch0 step2195 [D loss: -0.195992] [G loss: 2.223344]\n",
      "epoch0 step2200 [D loss: -0.855762] [G loss: 2.443172]\n",
      "epoch0 step2205 [D loss: -0.639245] [G loss: 2.306398]\n",
      "epoch0 step2210 [D loss: -0.638583] [G loss: 2.445676]\n",
      "epoch0 step2215 [D loss: -1.285769] [G loss: 2.497418]\n",
      "epoch0 step2220 [D loss: -1.104023] [G loss: 2.558623]\n",
      "epoch0 step2225 [D loss: -0.405944] [G loss: 2.524165]\n",
      "epoch0 step2230 [D loss: -0.863602] [G loss: 2.644032]\n",
      "epoch0 step2235 [D loss: -0.810859] [G loss: 2.085035]\n",
      "epoch0 step2240 [D loss: -0.423896] [G loss: 2.581125]\n",
      "epoch0 step2245 [D loss: -0.629495] [G loss: 2.289271]\n",
      "epoch0 step2250 [D loss: -0.032085] [G loss: 2.141335]\n",
      "epoch0 step2255 [D loss: -0.299360] [G loss: 2.274363]\n",
      "epoch0 step2260 [D loss: -0.516086] [G loss: 2.035319]\n",
      "epoch0 step2265 [D loss: -0.407778] [G loss: 2.451430]\n",
      "epoch0 step2270 [D loss: -0.418975] [G loss: 2.090809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step2275 [D loss: -0.156843] [G loss: 2.527041]\n",
      "epoch0 step2280 [D loss: -0.091926] [G loss: 2.251328]\n",
      "epoch0 step2285 [D loss: -1.105471] [G loss: 2.419216]\n",
      "epoch0 step2290 [D loss: -0.289869] [G loss: 2.606262]\n",
      "epoch0 step2295 [D loss: -0.893969] [G loss: 2.300898]\n",
      "epoch0 step2300 [D loss: -0.763500] [G loss: 2.395870]\n",
      "epoch0 step2305 [D loss: -0.208432] [G loss: 2.114815]\n",
      "epoch0 step2310 [D loss: -0.891182] [G loss: 2.459882]\n",
      "epoch0 step2315 [D loss: -0.953890] [G loss: 2.373465]\n",
      "epoch0 step2320 [D loss: -0.041622] [G loss: 1.958317]\n",
      "epoch0 step2325 [D loss: -0.600181] [G loss: 1.944183]\n",
      "epoch0 step2330 [D loss: -0.367847] [G loss: 2.043087]\n",
      "epoch0 step2335 [D loss: -0.328305] [G loss: 2.157202]\n",
      "epoch0 step2340 [D loss: -1.100953] [G loss: 1.972070]\n",
      "epoch0 step2345 [D loss: -0.452039] [G loss: 1.991190]\n",
      "epoch0 step2350 [D loss: -0.028933] [G loss: 2.050884]\n",
      "epoch0 step2355 [D loss: -0.374932] [G loss: 1.987786]\n",
      "epoch0 step2360 [D loss: -0.751090] [G loss: 2.138400]\n",
      "epoch0 step2365 [D loss: -0.654980] [G loss: 2.005135]\n",
      "epoch0 step2370 [D loss: -0.433135] [G loss: 2.367756]\n",
      "epoch0 step2375 [D loss: -0.574870] [G loss: 2.069646]\n",
      "epoch0 step2380 [D loss: -0.392633] [G loss: 2.195495]\n",
      "epoch0 step2385 [D loss: -1.077185] [G loss: 1.986664]\n",
      "epoch0 step2390 [D loss: -0.528448] [G loss: 2.301721]\n",
      "epoch0 step2395 [D loss: -0.627002] [G loss: 1.986860]\n",
      "epoch0 step2400 [D loss: -0.629223] [G loss: 2.053363]\n",
      "epoch0 step2405 [D loss: -0.034616] [G loss: 1.950910]\n",
      "epoch0 step2410 [D loss: -0.676177] [G loss: 2.185860]\n",
      "epoch0 step2415 [D loss: -0.400860] [G loss: 2.299988]\n",
      "epoch0 step2420 [D loss: -0.754766] [G loss: 2.000651]\n",
      "epoch0 step2425 [D loss: -0.449056] [G loss: 1.688983]\n",
      "epoch0 step2430 [D loss: -0.741751] [G loss: 2.066470]\n",
      "epoch0 step2435 [D loss: -0.646996] [G loss: 1.898782]\n",
      "epoch0 step2440 [D loss: -1.234112] [G loss: 2.365530]\n",
      "epoch0 step2445 [D loss: -0.587208] [G loss: 1.780299]\n",
      "epoch0 step2450 [D loss: -0.888439] [G loss: 2.024728]\n",
      "epoch0 step2455 [D loss: -0.741510] [G loss: 1.712205]\n",
      "epoch0 step2460 [D loss: -0.144799] [G loss: 1.877543]\n",
      "epoch0 step2465 [D loss: -0.853724] [G loss: 2.100911]\n",
      "epoch0 step2470 [D loss: -1.106635] [G loss: 2.018645]\n",
      "epoch0 step2475 [D loss: -0.335832] [G loss: 1.786561]\n",
      "epoch0 step2480 [D loss: -0.045445] [G loss: 1.794950]\n",
      "epoch0 step2485 [D loss: -0.392714] [G loss: 2.260786]\n",
      "epoch0 step2490 [D loss: -0.944066] [G loss: 2.332550]\n",
      "epoch0 step2495 [D loss: -0.007768] [G loss: 2.394057]\n",
      "epoch0 step2500 [D loss: -0.400447] [G loss: 2.005502]\n",
      "epoch0 step2505 [D loss: -0.985950] [G loss: 2.150649]\n",
      "epoch0 step2510 [D loss: 0.079336] [G loss: 1.955769]\n",
      "epoch0 step2515 [D loss: -0.398062] [G loss: 2.363501]\n",
      "epoch0 step2520 [D loss: -0.087626] [G loss: 1.731864]\n",
      "epoch0 step2525 [D loss: -0.340458] [G loss: 2.342893]\n",
      "epoch0 step2530 [D loss: -1.062703] [G loss: 2.349435]\n",
      "epoch0 step2535 [D loss: -0.792590] [G loss: 2.199645]\n",
      "epoch0 step2540 [D loss: -0.622832] [G loss: 1.915348]\n",
      "epoch0 step2545 [D loss: -0.409056] [G loss: 2.112873]\n",
      "epoch0 step2550 [D loss: -0.050469] [G loss: 2.145681]\n",
      "epoch0 step2555 [D loss: -0.967662] [G loss: 2.036169]\n",
      "epoch0 step2560 [D loss: -0.909240] [G loss: 2.357594]\n",
      "epoch0 step2565 [D loss: -0.349871] [G loss: 2.038573]\n",
      "epoch0 step2570 [D loss: -1.069062] [G loss: 2.271347]\n",
      "epoch0 step2575 [D loss: -0.953998] [G loss: 2.226467]\n",
      "epoch0 step2580 [D loss: -1.038185] [G loss: 2.293297]\n",
      "epoch0 step2585 [D loss: -0.163169] [G loss: 1.835218]\n",
      "epoch0 step2590 [D loss: -0.274864] [G loss: 1.795161]\n",
      "epoch0 step2595 [D loss: -0.515123] [G loss: 2.061234]\n",
      "epoch0 step2600 [D loss: -1.027173] [G loss: 2.033610]\n",
      "epoch0 step2605 [D loss: -0.269508] [G loss: 1.879747]\n",
      "epoch0 step2610 [D loss: -1.153967] [G loss: 1.862309]\n",
      "epoch0 step2615 [D loss: -0.236501] [G loss: 1.591880]\n",
      "epoch0 step2620 [D loss: -0.715817] [G loss: 2.038930]\n",
      "epoch0 step2625 [D loss: -0.437659] [G loss: 1.948602]\n",
      "epoch0 step2630 [D loss: -0.338345] [G loss: 1.769089]\n",
      "epoch0 step2635 [D loss: -0.071614] [G loss: 2.106907]\n",
      "epoch0 step2640 [D loss: -0.503978] [G loss: 1.666167]\n",
      "epoch0 step2645 [D loss: -0.329828] [G loss: 1.779142]\n",
      "epoch0 step2650 [D loss: -0.175089] [G loss: 1.589100]\n",
      "epoch0 step2655 [D loss: 0.075499] [G loss: 1.432714]\n",
      "epoch0 step2660 [D loss: -0.557629] [G loss: 1.621329]\n",
      "epoch0 step2665 [D loss: -0.042013] [G loss: 1.390299]\n",
      "epoch0 step2670 [D loss: -0.457853] [G loss: 1.486454]\n",
      "epoch0 step2675 [D loss: -0.142629] [G loss: 1.262699]\n",
      "epoch0 step2680 [D loss: -0.815775] [G loss: 1.506528]\n",
      "epoch0 step2685 [D loss: -1.047577] [G loss: 1.656612]\n",
      "epoch0 step2690 [D loss: -0.250781] [G loss: 1.346762]\n",
      "epoch0 step2695 [D loss: -0.434734] [G loss: 1.258516]\n",
      "epoch0 step2700 [D loss: -0.286224] [G loss: 1.631670]\n",
      "epoch0 step2705 [D loss: -0.840531] [G loss: 1.388460]\n",
      "epoch0 step2710 [D loss: -0.238970] [G loss: 1.049540]\n",
      "epoch0 step2715 [D loss: -0.427608] [G loss: 1.204329]\n",
      "epoch0 step2720 [D loss: -0.213818] [G loss: 1.005247]\n",
      "epoch0 step2725 [D loss: -0.321607] [G loss: 1.358010]\n",
      "epoch0 step2730 [D loss: -0.274116] [G loss: 1.201839]\n",
      "epoch0 step2735 [D loss: -0.374445] [G loss: 0.698110]\n",
      "epoch0 step2740 [D loss: -0.778525] [G loss: 1.386283]\n",
      "epoch0 step2745 [D loss: -0.279954] [G loss: 0.932454]\n",
      "epoch0 step2750 [D loss: -0.455531] [G loss: 1.288876]\n",
      "epoch0 step2755 [D loss: -0.242231] [G loss: 1.312606]\n",
      "epoch0 step2760 [D loss: 0.228018] [G loss: 0.894660]\n",
      "epoch0 step2765 [D loss: -0.619459] [G loss: 1.070210]\n",
      "epoch0 step2770 [D loss: -0.509957] [G loss: 1.083002]\n",
      "epoch0 step2775 [D loss: -0.307337] [G loss: 0.853744]\n",
      "epoch0 step2780 [D loss: -0.320555] [G loss: 0.969758]\n",
      "epoch0 step2785 [D loss: -0.832283] [G loss: 0.943267]\n",
      "epoch0 step2790 [D loss: -0.534292] [G loss: 1.040710]\n",
      "epoch0 step2795 [D loss: -0.049368] [G loss: 0.997172]\n",
      "epoch0 step2800 [D loss: 0.247408] [G loss: 0.798526]\n",
      "epoch0 step2805 [D loss: -0.361554] [G loss: 0.639379]\n",
      "epoch0 step2810 [D loss: -0.759368] [G loss: 0.730360]\n",
      "epoch0 step2815 [D loss: -0.741740] [G loss: 1.348629]\n",
      "epoch0 step2820 [D loss: -0.415089] [G loss: 0.936272]\n",
      "epoch0 step2825 [D loss: -0.502122] [G loss: 1.198232]\n",
      "epoch0 step2830 [D loss: -0.350507] [G loss: 0.735261]\n",
      "epoch0 step2835 [D loss: 0.005748] [G loss: 1.114438]\n",
      "epoch0 step2840 [D loss: -0.511460] [G loss: 0.972102]\n",
      "epoch0 step2845 [D loss: -0.848837] [G loss: 0.877124]\n",
      "epoch0 step2850 [D loss: -0.217429] [G loss: 0.785611]\n",
      "epoch0 step2855 [D loss: -0.425184] [G loss: 0.896934]\n",
      "epoch0 step2860 [D loss: -0.310250] [G loss: 0.863785]\n",
      "epoch0 step2865 [D loss: -0.614288] [G loss: 0.658043]\n",
      "epoch0 step2870 [D loss: -0.327499] [G loss: 0.769245]\n",
      "epoch0 step2875 [D loss: -0.310175] [G loss: 0.892190]\n",
      "epoch0 step2880 [D loss: -0.359286] [G loss: 1.070504]\n",
      "epoch0 step2885 [D loss: 0.260407] [G loss: 0.663422]\n",
      "epoch0 step2890 [D loss: -0.455299] [G loss: 0.746338]\n",
      "epoch0 step2895 [D loss: -0.831596] [G loss: 0.994815]\n",
      "epoch0 step2900 [D loss: -0.779782] [G loss: 0.660597]\n",
      "epoch0 step2905 [D loss: -0.107522] [G loss: 0.610268]\n",
      "epoch0 step2910 [D loss: -0.422750] [G loss: 0.477459]\n",
      "epoch0 step2915 [D loss: -0.890986] [G loss: 0.816698]\n",
      "epoch0 step2920 [D loss: -0.890277] [G loss: 0.798330]\n",
      "epoch0 step2925 [D loss: -0.138263] [G loss: 0.326100]\n",
      "epoch0 step2930 [D loss: 0.089915] [G loss: 0.731957]\n",
      "epoch0 step2935 [D loss: -0.248814] [G loss: 0.517377]\n",
      "epoch0 step2940 [D loss: 0.241229] [G loss: 0.440891]\n",
      "epoch0 step2945 [D loss: -0.509630] [G loss: 0.391707]\n",
      "epoch0 step2950 [D loss: -0.314379] [G loss: 0.730343]\n",
      "epoch0 step2955 [D loss: -0.294037] [G loss: 0.671281]\n",
      "epoch0 step2960 [D loss: -0.212272] [G loss: 0.525537]\n",
      "epoch0 step2965 [D loss: -0.259485] [G loss: 0.449728]\n",
      "epoch0 step2970 [D loss: -0.249754] [G loss: 0.412582]\n",
      "epoch0 step2975 [D loss: -0.142356] [G loss: 0.534227]\n",
      "epoch0 step2980 [D loss: 0.272216] [G loss: 0.404560]\n",
      "epoch0 step2985 [D loss: 0.107741] [G loss: 0.089862]\n",
      "epoch0 step2990 [D loss: -0.116657] [G loss: 0.376078]\n",
      "epoch0 step2995 [D loss: -0.387104] [G loss: 0.581630]\n",
      "epoch0 step3000 [D loss: -0.529343] [G loss: 0.508871]\n",
      "epoch0 step3005 [D loss: -0.364814] [G loss: 0.359701]\n",
      "epoch0 step3010 [D loss: 0.149294] [G loss: 0.360283]\n",
      "epoch0 step3015 [D loss: 0.013649] [G loss: 0.107582]\n",
      "epoch0 step3020 [D loss: -0.316102] [G loss: 0.157189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step3025 [D loss: -0.336161] [G loss: 0.465812]\n",
      "epoch0 step3030 [D loss: -0.087379] [G loss: 0.226630]\n",
      "epoch0 step3035 [D loss: -0.782759] [G loss: 0.347807]\n",
      "epoch0 step3040 [D loss: -0.529027] [G loss: 0.069789]\n",
      "epoch0 step3045 [D loss: -0.052320] [G loss: -0.093552]\n",
      "epoch0 step3050 [D loss: 0.318911] [G loss: -0.091327]\n",
      "epoch0 step3055 [D loss: 0.222485] [G loss: -0.208774]\n",
      "epoch0 step3060 [D loss: 0.269570] [G loss: -0.371372]\n",
      "epoch0 step3065 [D loss: -0.295271] [G loss: -0.093684]\n",
      "epoch0 step3070 [D loss: 0.140880] [G loss: -0.025983]\n",
      "epoch0 step3075 [D loss: -0.711925] [G loss: -0.205260]\n",
      "epoch0 step3080 [D loss: -0.092216] [G loss: -0.285240]\n",
      "epoch0 step3085 [D loss: -0.036269] [G loss: -0.160486]\n",
      "epoch0 step3090 [D loss: 0.028907] [G loss: -0.207712]\n",
      "epoch0 step3095 [D loss: -0.138446] [G loss: -0.399044]\n",
      "epoch0 step3100 [D loss: -0.696311] [G loss: -0.195518]\n",
      "epoch0 step3105 [D loss: 0.286277] [G loss: -0.314579]\n",
      "epoch0 step3110 [D loss: 0.020984] [G loss: -0.240073]\n",
      "epoch0 step3115 [D loss: 0.189816] [G loss: -0.060386]\n",
      "epoch0 step3120 [D loss: -0.283901] [G loss: -0.442107]\n",
      "epoch0 step3125 [D loss: 0.268857] [G loss: -1.015229]\n",
      "epoch0 step3130 [D loss: -0.071148] [G loss: -0.776835]\n",
      "epoch0 step3135 [D loss: -0.276390] [G loss: -0.442351]\n",
      "epoch0 step3140 [D loss: -0.079675] [G loss: -0.474640]\n",
      "epoch0 step3145 [D loss: 0.008561] [G loss: -0.163429]\n",
      "epoch0 step3150 [D loss: -0.405034] [G loss: -0.176353]\n",
      "epoch0 step3155 [D loss: -0.498730] [G loss: -0.325166]\n",
      "epoch0 step3160 [D loss: -0.232098] [G loss: -0.359845]\n",
      "epoch0 step3165 [D loss: -0.321714] [G loss: -0.355395]\n",
      "epoch0 step3170 [D loss: -0.293214] [G loss: -0.345259]\n",
      "epoch0 step3175 [D loss: -0.434556] [G loss: -0.412660]\n",
      "epoch0 step3180 [D loss: -0.199422] [G loss: -0.278648]\n",
      "epoch0 step3185 [D loss: -0.236139] [G loss: -0.417862]\n",
      "epoch0 step3190 [D loss: -0.279971] [G loss: -0.090278]\n",
      "epoch0 step3195 [D loss: -0.222084] [G loss: -0.359227]\n",
      "epoch0 step3200 [D loss: -0.116904] [G loss: -0.358018]\n",
      "epoch0 step3205 [D loss: -0.489105] [G loss: -0.553859]\n",
      "epoch0 step3210 [D loss: -0.733309] [G loss: -0.362442]\n",
      "epoch0 step3215 [D loss: -0.259485] [G loss: -0.376925]\n",
      "epoch0 step3220 [D loss: -0.605721] [G loss: -0.417123]\n",
      "epoch0 step3225 [D loss: -0.241380] [G loss: -0.459660]\n",
      "epoch0 step3230 [D loss: -0.157220] [G loss: -0.487609]\n",
      "epoch0 step3235 [D loss: 0.087629] [G loss: -0.421577]\n",
      "epoch0 step3240 [D loss: -0.169074] [G loss: -0.319181]\n",
      "epoch0 step3245 [D loss: -0.320712] [G loss: -0.552248]\n",
      "epoch0 step3250 [D loss: -0.473202] [G loss: -0.226184]\n",
      "epoch0 step3255 [D loss: 0.014986] [G loss: -0.776423]\n",
      "epoch0 step3260 [D loss: 0.006877] [G loss: -0.679345]\n",
      "epoch0 step3265 [D loss: 0.435968] [G loss: -0.793244]\n",
      "epoch0 step3270 [D loss: -0.376046] [G loss: -0.753681]\n",
      "epoch0 step3275 [D loss: -0.239901] [G loss: -0.712648]\n",
      "epoch0 step3280 [D loss: 0.242680] [G loss: -0.667828]\n",
      "epoch0 step3285 [D loss: -0.059825] [G loss: -0.574396]\n",
      "epoch0 step3290 [D loss: -0.192462] [G loss: -0.740094]\n",
      "epoch0 step3295 [D loss: -0.300529] [G loss: -0.598733]\n",
      "epoch0 step3300 [D loss: -0.547942] [G loss: -0.851013]\n",
      "epoch0 step3305 [D loss: 0.155109] [G loss: -1.080151]\n",
      "epoch0 step3310 [D loss: -0.107011] [G loss: -0.687426]\n",
      "epoch0 step3315 [D loss: -0.136245] [G loss: -0.984944]\n",
      "epoch0 step3320 [D loss: -0.100476] [G loss: -0.987689]\n",
      "epoch0 step3325 [D loss: -0.470804] [G loss: -0.930995]\n",
      "epoch0 step3330 [D loss: -0.247308] [G loss: -0.858300]\n",
      "epoch0 step3335 [D loss: -0.188470] [G loss: -0.810369]\n",
      "epoch0 step3340 [D loss: 0.089326] [G loss: -0.920923]\n",
      "epoch0 step3345 [D loss: -0.243404] [G loss: -0.842837]\n",
      "epoch0 step3350 [D loss: -0.289185] [G loss: -1.011226]\n",
      "epoch0 step3355 [D loss: -0.264853] [G loss: -0.858558]\n",
      "epoch0 step3360 [D loss: -0.278421] [G loss: -1.076688]\n",
      "epoch0 step3365 [D loss: -0.228325] [G loss: -1.105278]\n",
      "epoch0 step3370 [D loss: -0.037878] [G loss: -1.204188]\n",
      "epoch0 step3375 [D loss: -0.561840] [G loss: -0.891760]\n",
      "epoch0 step3380 [D loss: -1.029338] [G loss: -0.623743]\n",
      "epoch0 step3385 [D loss: -0.106896] [G loss: -1.266295]\n",
      "epoch0 step3390 [D loss: -0.313554] [G loss: -1.084070]\n",
      "epoch0 step3395 [D loss: -0.014900] [G loss: -1.072847]\n",
      "epoch0 step3400 [D loss: -0.530603] [G loss: -0.757644]\n",
      "epoch0 step3405 [D loss: -0.592004] [G loss: -1.165951]\n",
      "epoch0 step3410 [D loss: -0.050219] [G loss: -1.218077]\n",
      "epoch0 step3415 [D loss: -0.004042] [G loss: -1.070580]\n",
      "epoch0 step3420 [D loss: -0.233100] [G loss: -0.939250]\n",
      "epoch0 step3425 [D loss: -0.453484] [G loss: -1.201503]\n",
      "epoch0 step3430 [D loss: -0.089214] [G loss: -1.167181]\n",
      "epoch0 step3435 [D loss: 0.073436] [G loss: -1.372170]\n",
      "epoch0 step3440 [D loss: -0.028477] [G loss: -0.922225]\n",
      "epoch0 step3445 [D loss: -0.018975] [G loss: -1.240487]\n",
      "epoch0 step3450 [D loss: 0.004319] [G loss: -1.136099]\n",
      "epoch0 step3455 [D loss: -0.265246] [G loss: -1.160774]\n",
      "epoch0 step3460 [D loss: 0.026030] [G loss: -1.431020]\n",
      "epoch0 step3465 [D loss: -0.265649] [G loss: -1.358041]\n",
      "epoch0 step3470 [D loss: -0.123613] [G loss: -1.074146]\n",
      "epoch0 step3475 [D loss: 0.099116] [G loss: -1.229975]\n",
      "epoch0 step3480 [D loss: -0.460957] [G loss: -1.187436]\n",
      "epoch0 step3485 [D loss: -0.095183] [G loss: -1.147674]\n",
      "epoch0 step3490 [D loss: -0.187081] [G loss: -1.120261]\n",
      "epoch0 step3495 [D loss: -0.307536] [G loss: -1.154044]\n",
      "epoch0 step3500 [D loss: -0.185483] [G loss: -1.335963]\n",
      "epoch0 step3505 [D loss: 0.030038] [G loss: -1.284084]\n",
      "epoch0 step3510 [D loss: 0.006303] [G loss: -1.061815]\n",
      "epoch0 step3515 [D loss: -0.163016] [G loss: -1.202886]\n",
      "epoch0 step3520 [D loss: -0.351832] [G loss: -1.349277]\n",
      "epoch0 step3525 [D loss: -0.408299] [G loss: -1.340209]\n",
      "epoch0 step3530 [D loss: -0.350321] [G loss: -1.160359]\n",
      "epoch0 step3535 [D loss: 0.135063] [G loss: -1.350969]\n",
      "epoch0 step3540 [D loss: -0.080744] [G loss: -1.357565]\n",
      "epoch0 step3545 [D loss: 0.016259] [G loss: -1.304876]\n",
      "epoch0 step3550 [D loss: -0.036729] [G loss: -1.415862]\n",
      "epoch0 step3555 [D loss: -0.753316] [G loss: -1.338803]\n",
      "epoch0 step3560 [D loss: -0.206139] [G loss: -1.345635]\n",
      "epoch0 step3565 [D loss: -0.282377] [G loss: -1.359899]\n",
      "epoch0 step3570 [D loss: -0.357354] [G loss: -1.229714]\n",
      "epoch0 step3575 [D loss: -0.552139] [G loss: -1.162581]\n",
      "epoch0 step3580 [D loss: -0.460896] [G loss: -0.987083]\n",
      "epoch0 step3585 [D loss: -0.015144] [G loss: -1.229663]\n",
      "epoch0 step3590 [D loss: 0.124542] [G loss: -1.182903]\n",
      "epoch0 step3595 [D loss: -0.052195] [G loss: -1.220478]\n",
      "epoch0 step3600 [D loss: -0.671689] [G loss: -1.314272]\n",
      "epoch0 step3605 [D loss: -0.505401] [G loss: -1.317569]\n",
      "epoch0 step3610 [D loss: -0.552004] [G loss: -1.774502]\n",
      "epoch0 step3615 [D loss: -0.202466] [G loss: -1.603967]\n",
      "epoch0 step3620 [D loss: -0.428134] [G loss: -1.403015]\n",
      "epoch0 step3625 [D loss: -0.111311] [G loss: -1.467207]\n",
      "epoch0 step3630 [D loss: -0.441189] [G loss: -1.126881]\n",
      "epoch0 step3635 [D loss: -0.123652] [G loss: -1.811367]\n",
      "epoch0 step3640 [D loss: -0.283035] [G loss: -1.794049]\n",
      "epoch0 step3645 [D loss: -0.171342] [G loss: -1.669918]\n",
      "epoch0 step3650 [D loss: -0.540957] [G loss: -1.660557]\n",
      "epoch0 step3655 [D loss: -0.461935] [G loss: -1.996573]\n",
      "epoch0 step3660 [D loss: -0.395894] [G loss: -1.822425]\n",
      "epoch0 step3665 [D loss: 0.197267] [G loss: -1.867236]\n",
      "epoch0 step3670 [D loss: 0.080901] [G loss: -1.520799]\n",
      "epoch0 step3675 [D loss: -0.363697] [G loss: -1.535593]\n",
      "epoch0 step3680 [D loss: 0.341506] [G loss: -2.063080]\n",
      "epoch0 step3685 [D loss: -0.311299] [G loss: -1.810408]\n",
      "epoch0 step3690 [D loss: -0.297987] [G loss: -1.600198]\n",
      "epoch0 step3695 [D loss: -0.128113] [G loss: -1.969707]\n",
      "epoch0 step3700 [D loss: -0.032586] [G loss: -1.857570]\n",
      "epoch0 step3705 [D loss: -0.245458] [G loss: -1.502862]\n",
      "epoch0 step3710 [D loss: -0.019343] [G loss: -1.553216]\n",
      "epoch0 step3715 [D loss: 0.096990] [G loss: -1.676250]\n",
      "epoch0 step3720 [D loss: 0.165712] [G loss: -1.864539]\n",
      "epoch0 step3725 [D loss: -0.063989] [G loss: -2.026935]\n",
      "epoch0 step3730 [D loss: -0.655852] [G loss: -1.559880]\n",
      "epoch0 step3735 [D loss: -0.103626] [G loss: -1.853041]\n",
      "epoch0 step3740 [D loss: -0.386370] [G loss: -1.881106]\n",
      "epoch0 step3745 [D loss: -0.211221] [G loss: -1.759790]\n",
      "epoch0 step3750 [D loss: -0.103527] [G loss: -1.648394]\n",
      "epoch0 step3755 [D loss: -0.601406] [G loss: -1.626972]\n",
      "epoch0 step3760 [D loss: -0.374448] [G loss: -1.544622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step3765 [D loss: -0.085440] [G loss: -1.717983]\n",
      "epoch0 step3770 [D loss: -0.085278] [G loss: -1.607753]\n",
      "epoch0 step3775 [D loss: 0.000101] [G loss: -1.857635]\n",
      "epoch0 step3780 [D loss: -0.542862] [G loss: -1.467809]\n",
      "epoch0 step3785 [D loss: 0.094393] [G loss: -1.830379]\n",
      "epoch0 step3790 [D loss: -0.032757] [G loss: -1.747108]\n",
      "epoch0 step3795 [D loss: -0.704578] [G loss: -1.594292]\n",
      "epoch0 step3800 [D loss: -0.543513] [G loss: -1.488929]\n",
      "epoch0 step3805 [D loss: -0.488649] [G loss: -1.890603]\n",
      "epoch0 step3810 [D loss: -0.575777] [G loss: -1.535429]\n",
      "epoch0 step3815 [D loss: -0.053275] [G loss: -1.548684]\n",
      "epoch0 step3820 [D loss: -0.244687] [G loss: -1.950466]\n",
      "epoch0 step3825 [D loss: -0.201075] [G loss: -1.630630]\n",
      "epoch0 step3830 [D loss: -0.880425] [G loss: -1.641693]\n",
      "epoch0 step3835 [D loss: -0.231224] [G loss: -1.695246]\n",
      "epoch0 step3840 [D loss: -0.717911] [G loss: -1.689179]\n",
      "epoch0 step3845 [D loss: -0.027027] [G loss: -2.194410]\n",
      "epoch0 step3850 [D loss: -0.098091] [G loss: -1.511981]\n",
      "epoch0 step3855 [D loss: -0.299292] [G loss: -1.597702]\n",
      "epoch0 step3860 [D loss: -0.082773] [G loss: -1.604894]\n",
      "epoch0 step3865 [D loss: 0.137001] [G loss: -2.105801]\n",
      "epoch0 step3870 [D loss: -0.520258] [G loss: -1.872465]\n",
      "epoch0 step3875 [D loss: -0.363783] [G loss: -1.916880]\n",
      "epoch0 step3880 [D loss: 0.118017] [G loss: -2.040857]\n",
      "epoch0 step3885 [D loss: 0.001125] [G loss: -1.696830]\n",
      "epoch0 step3890 [D loss: 0.034906] [G loss: -1.891317]\n",
      "epoch0 step3895 [D loss: -0.131421] [G loss: -1.891464]\n",
      "epoch0 step3900 [D loss: -0.583121] [G loss: -1.971859]\n",
      "epoch0 step3905 [D loss: -0.402826] [G loss: -2.117208]\n",
      "epoch0 step3910 [D loss: -0.253985] [G loss: -1.885644]\n",
      "epoch0 step3915 [D loss: -0.771066] [G loss: -1.762376]\n",
      "epoch0 step3920 [D loss: -0.038056] [G loss: -2.022572]\n",
      "epoch0 step3925 [D loss: -0.580463] [G loss: -1.803087]\n",
      "epoch0 step3930 [D loss: -0.457520] [G loss: -1.521910]\n",
      "epoch0 step3935 [D loss: 0.058847] [G loss: -1.768826]\n",
      "epoch0 step3940 [D loss: -0.156327] [G loss: -1.962839]\n",
      "epoch0 step3945 [D loss: -0.399355] [G loss: -2.021748]\n",
      "epoch0 step3950 [D loss: -0.152905] [G loss: -1.976729]\n",
      "epoch0 step3955 [D loss: -0.346290] [G loss: -1.740972]\n",
      "epoch0 step3960 [D loss: -0.171537] [G loss: -1.909726]\n",
      "epoch0 step3965 [D loss: -0.767463] [G loss: -1.657735]\n",
      "epoch0 step3970 [D loss: -0.233763] [G loss: -1.915610]\n",
      "epoch0 step3975 [D loss: -0.162895] [G loss: -2.363372]\n",
      "epoch0 step3980 [D loss: -0.239927] [G loss: -2.148172]\n",
      "epoch0 step3985 [D loss: -0.361738] [G loss: -1.573733]\n",
      "epoch0 step3990 [D loss: -0.238525] [G loss: -2.017077]\n",
      "epoch0 step3995 [D loss: -0.429781] [G loss: -1.827482]\n",
      "epoch0 step4000 [D loss: 0.049816] [G loss: -1.904493]\n",
      "epoch0 step4005 [D loss: -0.250493] [G loss: -2.200858]\n",
      "epoch0 step4010 [D loss: -0.220860] [G loss: -1.712737]\n",
      "epoch0 step4015 [D loss: -0.046613] [G loss: -1.787643]\n",
      "epoch0 step4020 [D loss: -0.262402] [G loss: -1.877785]\n",
      "epoch0 step4025 [D loss: 0.073490] [G loss: -1.883024]\n",
      "epoch0 step4030 [D loss: -0.240704] [G loss: -2.195156]\n",
      "epoch0 step4035 [D loss: 0.081847] [G loss: -2.004451]\n",
      "epoch0 step4040 [D loss: -0.302663] [G loss: -1.859745]\n",
      "epoch0 step4045 [D loss: -0.144167] [G loss: -1.876052]\n",
      "epoch0 step4050 [D loss: 0.090380] [G loss: -1.700050]\n",
      "epoch0 step4055 [D loss: -0.058332] [G loss: -2.095915]\n",
      "epoch0 step4060 [D loss: -0.439476] [G loss: -1.940837]\n",
      "epoch0 step4065 [D loss: -0.028152] [G loss: -2.147345]\n",
      "epoch0 step4070 [D loss: 0.231902] [G loss: -2.019579]\n",
      "epoch0 step4075 [D loss: -0.461960] [G loss: -1.903326]\n",
      "epoch0 step4080 [D loss: -0.485291] [G loss: -1.832854]\n",
      "epoch0 step4085 [D loss: -0.083863] [G loss: -1.927905]\n",
      "epoch0 step4090 [D loss: -0.000243] [G loss: -2.151749]\n",
      "epoch0 step4095 [D loss: -0.469700] [G loss: -1.930501]\n",
      "epoch0 step4100 [D loss: 0.221087] [G loss: -2.171067]\n",
      "epoch0 step4105 [D loss: 0.157192] [G loss: -2.071890]\n",
      "epoch0 step4110 [D loss: -0.290019] [G loss: -2.189902]\n",
      "epoch0 step4115 [D loss: -0.133292] [G loss: -2.393592]\n",
      "epoch0 step4120 [D loss: -0.094552] [G loss: -2.218847]\n",
      "epoch0 step4125 [D loss: -0.152831] [G loss: -2.071353]\n",
      "epoch0 step4130 [D loss: -0.400843] [G loss: -2.267120]\n",
      "epoch0 step4135 [D loss: -0.037163] [G loss: -2.280060]\n",
      "epoch0 step4140 [D loss: 0.201082] [G loss: -2.196978]\n",
      "epoch0 step4145 [D loss: -0.011139] [G loss: -2.072237]\n",
      "epoch0 step4150 [D loss: -0.450713] [G loss: -1.997598]\n",
      "epoch0 step4155 [D loss: -0.083197] [G loss: -2.107900]\n",
      "epoch0 step4160 [D loss: -0.510716] [G loss: -2.261686]\n",
      "epoch0 step4165 [D loss: -0.697867] [G loss: -1.965935]\n",
      "epoch0 step4170 [D loss: -0.019198] [G loss: -2.039009]\n",
      "epoch0 step4175 [D loss: 0.118826] [G loss: -2.170002]\n",
      "epoch0 step4180 [D loss: -0.468116] [G loss: -2.227140]\n",
      "epoch0 step4185 [D loss: -0.316466] [G loss: -1.919382]\n",
      "epoch0 step4190 [D loss: -0.512368] [G loss: -2.148373]\n",
      "epoch0 step4195 [D loss: -0.260544] [G loss: -1.856259]\n",
      "epoch0 step4200 [D loss: -0.309835] [G loss: -2.027320]\n",
      "epoch0 step4205 [D loss: -0.655811] [G loss: -1.784828]\n",
      "epoch0 step4210 [D loss: -0.271639] [G loss: -2.238102]\n",
      "epoch0 step4215 [D loss: -0.235968] [G loss: -1.914306]\n",
      "epoch0 step4220 [D loss: -0.723128] [G loss: -1.966440]\n",
      "epoch0 step4225 [D loss: -0.223929] [G loss: -1.942146]\n",
      "epoch0 step4230 [D loss: -0.488563] [G loss: -2.019461]\n",
      "epoch0 step4235 [D loss: -0.100034] [G loss: -1.853084]\n",
      "epoch0 step4240 [D loss: -0.286686] [G loss: -1.739806]\n",
      "epoch0 step4245 [D loss: 0.023260] [G loss: -2.257156]\n",
      "epoch0 step4250 [D loss: -0.409906] [G loss: -1.984401]\n",
      "epoch0 step4255 [D loss: -0.596435] [G loss: -1.733567]\n",
      "epoch0 step4260 [D loss: -0.238573] [G loss: -1.852608]\n",
      "epoch0 step4265 [D loss: -0.075674] [G loss: -2.143422]\n",
      "epoch0 step4270 [D loss: 0.033348] [G loss: -1.908633]\n",
      "epoch0 step4275 [D loss: -0.044699] [G loss: -1.771782]\n",
      "epoch0 step4280 [D loss: -0.294079] [G loss: -2.050654]\n",
      "epoch0 step4285 [D loss: -0.157148] [G loss: -1.972594]\n",
      "epoch0 step4290 [D loss: -0.388332] [G loss: -1.865169]\n",
      "epoch0 step4295 [D loss: -0.171229] [G loss: -1.937804]\n",
      "epoch0 step4300 [D loss: -0.320724] [G loss: -1.824999]\n",
      "epoch0 step4305 [D loss: -0.371422] [G loss: -2.019420]\n",
      "epoch0 step4310 [D loss: 0.206197] [G loss: -1.910493]\n",
      "epoch0 step4315 [D loss: -0.397043] [G loss: -1.887955]\n",
      "epoch0 step4320 [D loss: 0.158222] [G loss: -2.089957]\n",
      "epoch0 step4325 [D loss: -0.267667] [G loss: -1.568866]\n",
      "epoch0 step4330 [D loss: -0.411539] [G loss: -1.869370]\n",
      "epoch0 step4335 [D loss: -0.366396] [G loss: -2.007150]\n",
      "epoch0 step4340 [D loss: -0.358646] [G loss: -1.769078]\n",
      "epoch0 step4345 [D loss: -0.449328] [G loss: -1.678856]\n",
      "epoch0 step4350 [D loss: -0.439615] [G loss: -1.852469]\n",
      "epoch0 step4355 [D loss: -0.428157] [G loss: -1.532032]\n",
      "epoch0 step4360 [D loss: -0.587798] [G loss: -1.284211]\n",
      "epoch0 step4365 [D loss: -0.451021] [G loss: -1.534758]\n",
      "epoch0 step4370 [D loss: 0.135656] [G loss: -1.658949]\n",
      "epoch0 step4375 [D loss: -0.111396] [G loss: -1.546370]\n",
      "epoch0 step4380 [D loss: -0.278925] [G loss: -1.547895]\n",
      "epoch0 step4385 [D loss: -0.049335] [G loss: -1.794008]\n",
      "epoch0 step4390 [D loss: -0.127484] [G loss: -2.087842]\n",
      "epoch0 step4395 [D loss: -0.107755] [G loss: -1.722577]\n",
      "epoch0 step4400 [D loss: -0.316262] [G loss: -1.798167]\n",
      "epoch0 step4405 [D loss: -0.002795] [G loss: -1.896372]\n",
      "epoch0 step4410 [D loss: -0.487062] [G loss: -1.628128]\n",
      "epoch0 step4415 [D loss: 0.132933] [G loss: -1.744559]\n",
      "epoch0 step4420 [D loss: -0.560030] [G loss: -1.846648]\n",
      "epoch0 step4425 [D loss: 0.390879] [G loss: -1.972062]\n",
      "epoch0 step4430 [D loss: -0.345914] [G loss: -1.714451]\n",
      "epoch0 step4435 [D loss: -0.381720] [G loss: -1.841122]\n",
      "epoch0 step4440 [D loss: 0.058899] [G loss: -1.940753]\n",
      "epoch0 step4445 [D loss: -0.224093] [G loss: -1.865831]\n",
      "epoch0 step4450 [D loss: -0.007626] [G loss: -1.694142]\n",
      "epoch0 step4455 [D loss: -0.085928] [G loss: -1.868671]\n",
      "epoch0 step4460 [D loss: -0.548480] [G loss: -1.707208]\n",
      "epoch0 step4465 [D loss: -0.320485] [G loss: -1.695303]\n",
      "epoch0 step4470 [D loss: -0.287393] [G loss: -1.933781]\n",
      "epoch0 step4475 [D loss: 0.055224] [G loss: -1.950800]\n",
      "epoch0 step4480 [D loss: -0.198800] [G loss: -2.079879]\n",
      "epoch0 step4485 [D loss: -0.532465] [G loss: -2.186803]\n",
      "epoch0 step4490 [D loss: -0.456939] [G loss: -1.613203]\n",
      "epoch0 step4495 [D loss: -0.438982] [G loss: -2.221673]\n",
      "epoch0 step4500 [D loss: -0.475594] [G loss: -1.932639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step4505 [D loss: -0.145877] [G loss: -1.458639]\n",
      "epoch0 step4510 [D loss: -0.139714] [G loss: -1.977121]\n",
      "epoch0 step4515 [D loss: -0.160969] [G loss: -2.039949]\n",
      "epoch0 step4520 [D loss: -0.145268] [G loss: -2.357624]\n",
      "epoch0 step4525 [D loss: -0.278503] [G loss: -1.870299]\n",
      "epoch0 step4530 [D loss: -0.099159] [G loss: -2.164296]\n",
      "epoch0 step4535 [D loss: -0.056294] [G loss: -1.950606]\n",
      "epoch0 step4540 [D loss: -0.504692] [G loss: -1.743777]\n",
      "epoch0 step4545 [D loss: -0.479386] [G loss: -2.135588]\n",
      "epoch0 step4550 [D loss: -0.348934] [G loss: -1.740752]\n",
      "epoch0 step4555 [D loss: -0.593523] [G loss: -1.610087]\n",
      "epoch0 step4560 [D loss: -0.275230] [G loss: -1.904528]\n",
      "epoch0 step4565 [D loss: -0.155144] [G loss: -2.281294]\n",
      "epoch0 step4570 [D loss: -0.011424] [G loss: -1.827559]\n",
      "epoch0 step4575 [D loss: -0.694403] [G loss: -2.025375]\n",
      "epoch0 step4580 [D loss: 0.187780] [G loss: -2.165179]\n",
      "epoch0 step4585 [D loss: -0.079834] [G loss: -1.938635]\n",
      "epoch0 step4590 [D loss: 0.020452] [G loss: -2.283483]\n",
      "epoch0 step4595 [D loss: 0.186034] [G loss: -2.038549]\n",
      "epoch0 step4600 [D loss: -0.075474] [G loss: -1.998309]\n",
      "epoch0 step4605 [D loss: -0.339830] [G loss: -1.912962]\n",
      "epoch0 step4610 [D loss: -0.263115] [G loss: -1.906957]\n",
      "epoch0 step4615 [D loss: 0.122944] [G loss: -2.071058]\n",
      "epoch0 step4620 [D loss: 0.074983] [G loss: -1.960802]\n",
      "epoch0 step4625 [D loss: -0.222597] [G loss: -1.819337]\n",
      "epoch0 step4630 [D loss: -0.242908] [G loss: -2.104762]\n",
      "epoch0 step4635 [D loss: -0.085873] [G loss: -2.154049]\n",
      "epoch0 step4640 [D loss: 0.002842] [G loss: -1.958620]\n",
      "epoch0 step4645 [D loss: -0.075121] [G loss: -2.030881]\n",
      "epoch0 step4650 [D loss: -0.527435] [G loss: -1.929896]\n",
      "epoch0 step4655 [D loss: -0.434439] [G loss: -1.913247]\n",
      "epoch0 step4660 [D loss: -0.453488] [G loss: -1.917458]\n",
      "epoch0 step4665 [D loss: 0.143099] [G loss: -1.958414]\n",
      "epoch0 step4670 [D loss: -0.405079] [G loss: -1.820994]\n",
      "epoch0 step4675 [D loss: -0.066067] [G loss: -2.135788]\n",
      "epoch0 step4680 [D loss: -0.244870] [G loss: -2.267246]\n",
      "epoch0 step4685 [D loss: -0.187757] [G loss: -2.125122]\n",
      "epoch0 step4690 [D loss: 0.457804] [G loss: -1.936517]\n",
      "epoch0 step4695 [D loss: -0.258733] [G loss: -1.919708]\n",
      "epoch0 step4700 [D loss: -0.066812] [G loss: -2.137386]\n",
      "epoch0 step4705 [D loss: -0.246239] [G loss: -1.895492]\n",
      "epoch0 step4710 [D loss: 0.161677] [G loss: -1.985608]\n",
      "epoch0 step4715 [D loss: -0.281164] [G loss: -1.999597]\n",
      "epoch0 step4720 [D loss: 0.064239] [G loss: -2.020937]\n",
      "epoch0 step4725 [D loss: 0.017847] [G loss: -2.014469]\n",
      "epoch0 step4730 [D loss: -0.297456] [G loss: -1.758566]\n",
      "epoch0 step4735 [D loss: -0.224748] [G loss: -1.706115]\n",
      "epoch0 step4740 [D loss: -0.119010] [G loss: -1.643131]\n",
      "epoch0 step4745 [D loss: -0.326388] [G loss: -1.761346]\n",
      "epoch0 step4750 [D loss: -0.428746] [G loss: -1.877016]\n",
      "epoch0 step4755 [D loss: -0.105409] [G loss: -1.883869]\n",
      "epoch0 step4760 [D loss: 0.514464] [G loss: -1.915753]\n",
      "epoch0 step4765 [D loss: -0.535454] [G loss: -2.042762]\n",
      "epoch0 step4770 [D loss: -0.670105] [G loss: -2.184366]\n",
      "epoch0 step4775 [D loss: -0.504486] [G loss: -1.929554]\n",
      "epoch0 step4780 [D loss: -0.036928] [G loss: -1.903562]\n",
      "epoch0 step4785 [D loss: -0.293162] [G loss: -1.954540]\n",
      "epoch0 step4790 [D loss: -0.278679] [G loss: -1.732811]\n",
      "epoch0 step4795 [D loss: -0.011945] [G loss: -1.622494]\n",
      "epoch0 step4800 [D loss: -0.238288] [G loss: -1.538365]\n",
      "epoch0 step4805 [D loss: -0.171977] [G loss: -1.725782]\n",
      "epoch0 step4810 [D loss: -0.605320] [G loss: -1.742951]\n",
      "epoch0 step4815 [D loss: -0.471713] [G loss: -1.907304]\n",
      "epoch0 step4820 [D loss: -0.280984] [G loss: -1.612993]\n",
      "epoch0 step4825 [D loss: -0.132275] [G loss: -1.709356]\n",
      "epoch0 step4830 [D loss: -0.498696] [G loss: -1.761525]\n",
      "epoch0 step4835 [D loss: -0.282549] [G loss: -1.817546]\n",
      "epoch0 step4840 [D loss: 0.019265] [G loss: -1.856286]\n",
      "epoch0 step4845 [D loss: 0.343285] [G loss: -1.722538]\n",
      "epoch0 step4850 [D loss: -0.083459] [G loss: -1.738174]\n",
      "epoch0 step4855 [D loss: -0.227445] [G loss: -1.609114]\n",
      "epoch0 step4860 [D loss: -0.453977] [G loss: -1.646373]\n",
      "epoch0 step4865 [D loss: 0.102908] [G loss: -1.807164]\n",
      "epoch0 step4870 [D loss: -0.242380] [G loss: -1.552922]\n",
      "epoch0 step4875 [D loss: 0.221558] [G loss: -1.853175]\n",
      "epoch0 step4880 [D loss: -0.659406] [G loss: -1.440132]\n",
      "epoch0 step4885 [D loss: 0.025653] [G loss: -1.861412]\n",
      "epoch0 step4890 [D loss: 0.062028] [G loss: -1.740350]\n",
      "epoch0 step4895 [D loss: 0.470972] [G loss: -2.156718]\n",
      "epoch0 step4900 [D loss: 0.200159] [G loss: -1.794538]\n",
      "epoch0 step4905 [D loss: 0.188569] [G loss: -1.830548]\n",
      "epoch0 step4910 [D loss: 0.274394] [G loss: -1.491908]\n",
      "epoch0 step4915 [D loss: -0.072019] [G loss: -1.493105]\n",
      "epoch0 step4920 [D loss: -0.349729] [G loss: -1.560032]\n",
      "epoch0 step4925 [D loss: -0.194852] [G loss: -1.505695]\n",
      "epoch0 step4930 [D loss: -0.311714] [G loss: -1.696855]\n",
      "epoch0 step4935 [D loss: -0.758852] [G loss: -1.195277]\n",
      "epoch0 step4940 [D loss: -0.262561] [G loss: -1.548862]\n",
      "epoch0 step4945 [D loss: -0.440079] [G loss: -1.459558]\n",
      "epoch0 step4950 [D loss: -0.255010] [G loss: -1.758833]\n",
      "epoch0 step4955 [D loss: -0.194300] [G loss: -1.704518]\n",
      "epoch0 step4960 [D loss: -0.262771] [G loss: -1.754493]\n",
      "epoch0 step4965 [D loss: -0.643049] [G loss: -1.835720]\n",
      "epoch0 step4970 [D loss: 0.276222] [G loss: -1.573693]\n",
      "epoch0 step4975 [D loss: -0.297570] [G loss: -1.508719]\n",
      "epoch0 step4980 [D loss: 0.084346] [G loss: -1.529505]\n",
      "epoch0 step4985 [D loss: -0.462676] [G loss: -1.316898]\n",
      "epoch0 step4990 [D loss: -0.159184] [G loss: -1.607244]\n",
      "epoch0 step4995 [D loss: -0.462787] [G loss: -1.233914]\n",
      "epoch0 step5000 [D loss: -0.371165] [G loss: -1.632582]\n",
      "epoch0 step5005 [D loss: -0.067861] [G loss: -1.298563]\n",
      "epoch0 step5010 [D loss: -0.508413] [G loss: -1.366321]\n",
      "epoch0 step5015 [D loss: 0.190412] [G loss: -1.500846]\n",
      "epoch0 step5020 [D loss: -0.056867] [G loss: -1.441229]\n",
      "epoch0 step5025 [D loss: -0.483246] [G loss: -1.312264]\n",
      "epoch0 step5030 [D loss: -0.469333] [G loss: -1.592641]\n",
      "epoch0 step5035 [D loss: 0.174584] [G loss: -1.791641]\n",
      "epoch0 step5040 [D loss: -0.371041] [G loss: -1.483800]\n",
      "epoch0 step5045 [D loss: -0.145405] [G loss: -1.510365]\n",
      "epoch0 step5050 [D loss: -0.138157] [G loss: -1.568265]\n",
      "epoch0 step5055 [D loss: -0.318201] [G loss: -1.553212]\n",
      "epoch0 step5060 [D loss: -0.005913] [G loss: -1.094587]\n",
      "epoch0 step5065 [D loss: 0.112127] [G loss: -1.544906]\n",
      "epoch0 step5070 [D loss: -0.074181] [G loss: -1.524325]\n",
      "epoch0 step5075 [D loss: -0.386225] [G loss: -0.949738]\n",
      "epoch0 step5080 [D loss: -0.285380] [G loss: -1.295310]\n",
      "epoch0 step5085 [D loss: 0.586045] [G loss: -1.516217]\n",
      "epoch0 step5090 [D loss: -0.167954] [G loss: -1.413593]\n",
      "epoch0 step5095 [D loss: -0.157066] [G loss: -1.473906]\n",
      "epoch0 step5100 [D loss: 0.096499] [G loss: -1.795112]\n",
      "epoch0 step5105 [D loss: -0.031595] [G loss: -1.506140]\n",
      "epoch0 step5110 [D loss: -0.314198] [G loss: -1.411607]\n",
      "epoch0 step5115 [D loss: -0.075261] [G loss: -1.569383]\n",
      "epoch0 step5120 [D loss: 0.263450] [G loss: -1.555949]\n",
      "epoch0 step5125 [D loss: 0.035117] [G loss: -1.354785]\n",
      "epoch0 step5130 [D loss: -0.341105] [G loss: -1.358865]\n",
      "epoch0 step5135 [D loss: -0.210327] [G loss: -1.713524]\n",
      "epoch0 step5140 [D loss: -0.065041] [G loss: -1.597395]\n",
      "epoch0 step5145 [D loss: -0.274235] [G loss: -1.210810]\n",
      "epoch0 step5150 [D loss: -0.043209] [G loss: -1.372666]\n",
      "epoch0 step5155 [D loss: -0.230046] [G loss: -1.227567]\n",
      "epoch0 step5160 [D loss: -0.111611] [G loss: -1.339130]\n",
      "epoch0 step5165 [D loss: -0.241708] [G loss: -1.419277]\n",
      "epoch0 step5170 [D loss: -0.131833] [G loss: -1.096386]\n",
      "epoch0 step5175 [D loss: -0.145460] [G loss: -0.949837]\n",
      "epoch0 step5180 [D loss: -0.161449] [G loss: -1.186409]\n",
      "epoch0 step5185 [D loss: -0.045540] [G loss: -1.398376]\n",
      "epoch0 step5190 [D loss: -0.245891] [G loss: -1.140452]\n",
      "epoch0 step5195 [D loss: -0.263974] [G loss: -1.252545]\n",
      "epoch0 step5200 [D loss: -0.161042] [G loss: -1.167320]\n",
      "epoch0 step5205 [D loss: -0.114329] [G loss: -1.285356]\n",
      "epoch0 step5210 [D loss: 0.027517] [G loss: -1.191388]\n",
      "epoch0 step5215 [D loss: -0.219185] [G loss: -1.136693]\n",
      "epoch0 step5220 [D loss: -0.408126] [G loss: -1.185269]\n",
      "epoch0 step5225 [D loss: 0.010697] [G loss: -1.163365]\n",
      "epoch0 step5230 [D loss: -0.486589] [G loss: -1.157709]\n",
      "epoch0 step5235 [D loss: -0.082550] [G loss: -0.980905]\n",
      "epoch0 step5240 [D loss: 0.287357] [G loss: -1.492614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5245 [D loss: -0.341113] [G loss: -1.317727]\n",
      "epoch0 step5250 [D loss: -0.379674] [G loss: -1.164053]\n",
      "epoch0 step5255 [D loss: -0.440046] [G loss: -1.236574]\n",
      "epoch0 step5260 [D loss: -0.399386] [G loss: -1.211040]\n",
      "epoch0 step5265 [D loss: -0.459688] [G loss: -1.052474]\n",
      "epoch0 step5270 [D loss: -0.609574] [G loss: -1.353676]\n",
      "epoch0 step5275 [D loss: -0.253089] [G loss: -1.589852]\n",
      "epoch0 step5280 [D loss: -0.173335] [G loss: -1.604503]\n",
      "epoch0 step5285 [D loss: -0.414321] [G loss: -1.038835]\n",
      "epoch0 step5290 [D loss: 0.066809] [G loss: -1.610586]\n",
      "epoch0 step5295 [D loss: -0.612112] [G loss: -1.630437]\n",
      "epoch0 step5300 [D loss: -0.275422] [G loss: -1.626422]\n",
      "epoch0 step5305 [D loss: -0.715269] [G loss: -1.724496]\n",
      "epoch0 step5310 [D loss: -0.301648] [G loss: -1.936186]\n",
      "epoch0 step5315 [D loss: -0.119241] [G loss: -1.649339]\n",
      "epoch0 step5320 [D loss: -0.019439] [G loss: -1.573244]\n",
      "epoch0 step5325 [D loss: -0.339486] [G loss: -1.587160]\n",
      "epoch0 step5330 [D loss: -0.316604] [G loss: -1.853853]\n",
      "epoch0 step5335 [D loss: -0.170404] [G loss: -1.722373]\n",
      "epoch0 step5340 [D loss: -0.364165] [G loss: -1.764431]\n",
      "epoch0 step5345 [D loss: -0.038063] [G loss: -2.366428]\n",
      "epoch0 step5350 [D loss: 0.058323] [G loss: -2.161753]\n",
      "epoch0 step5355 [D loss: 0.186614] [G loss: -1.690418]\n",
      "epoch0 step5360 [D loss: -0.069653] [G loss: -1.853759]\n",
      "epoch0 step5365 [D loss: -0.272661] [G loss: -1.509903]\n",
      "epoch0 step5370 [D loss: -0.128914] [G loss: -1.840082]\n",
      "epoch0 step5375 [D loss: -0.390252] [G loss: -1.514225]\n",
      "epoch0 step5380 [D loss: 0.121765] [G loss: -1.771701]\n",
      "epoch0 step5385 [D loss: -0.128132] [G loss: -1.518259]\n",
      "epoch0 step5390 [D loss: -0.101972] [G loss: -1.897520]\n",
      "epoch0 step5395 [D loss: -0.141971] [G loss: -1.656586]\n",
      "epoch0 step5400 [D loss: -0.769751] [G loss: -1.110497]\n",
      "epoch0 step5405 [D loss: -0.409401] [G loss: -1.451582]\n",
      "epoch0 step5410 [D loss: -0.478525] [G loss: -1.293293]\n",
      "epoch0 step5415 [D loss: -0.633444] [G loss: -1.144088]\n",
      "epoch0 step5420 [D loss: 0.097289] [G loss: -1.593672]\n",
      "epoch0 step5425 [D loss: -0.362219] [G loss: -0.832017]\n",
      "epoch0 step5430 [D loss: -0.252568] [G loss: -1.124483]\n",
      "epoch0 step5435 [D loss: -0.036628] [G loss: -1.173925]\n",
      "epoch0 step5440 [D loss: -0.043987] [G loss: -1.178151]\n",
      "epoch0 step5445 [D loss: -0.177026] [G loss: -1.140220]\n",
      "epoch0 step5450 [D loss: -0.147591] [G loss: -1.198194]\n",
      "epoch0 step5455 [D loss: -0.058069] [G loss: -1.393883]\n",
      "epoch0 step5460 [D loss: -0.674949] [G loss: -0.971286]\n",
      "epoch0 step5465 [D loss: 0.046708] [G loss: -1.577778]\n",
      "epoch0 step5470 [D loss: 0.239482] [G loss: -1.375445]\n",
      "epoch0 step5475 [D loss: -0.667847] [G loss: -1.238238]\n",
      "epoch0 step5480 [D loss: 0.078540] [G loss: -1.453633]\n",
      "epoch0 step5485 [D loss: -0.283355] [G loss: -0.986059]\n",
      "epoch0 step5490 [D loss: 0.124124] [G loss: -1.162245]\n",
      "epoch0 step5495 [D loss: -0.070535] [G loss: -1.481699]\n",
      "epoch0 step5500 [D loss: -0.123898] [G loss: -1.227931]\n",
      "epoch0 step5505 [D loss: 0.024361] [G loss: -1.288843]\n",
      "epoch0 step5510 [D loss: -0.709902] [G loss: -1.275576]\n",
      "epoch0 step5515 [D loss: 0.175701] [G loss: -1.323225]\n",
      "epoch0 step5520 [D loss: -0.041129] [G loss: -1.341531]\n",
      "epoch0 step5525 [D loss: -0.342643] [G loss: -1.487148]\n",
      "epoch0 step5530 [D loss: -0.456338] [G loss: -1.820156]\n",
      "epoch0 step5535 [D loss: 0.235517] [G loss: -1.583325]\n",
      "epoch0 step5540 [D loss: -0.364981] [G loss: -1.421500]\n",
      "epoch0 step5545 [D loss: -0.736244] [G loss: -1.224324]\n",
      "epoch0 step5550 [D loss: -0.136936] [G loss: -1.428270]\n",
      "epoch0 step5555 [D loss: -0.231564] [G loss: -1.465903]\n",
      "epoch0 step5560 [D loss: -0.400807] [G loss: -1.376791]\n",
      "epoch0 step5565 [D loss: -0.440861] [G loss: -1.753685]\n",
      "epoch0 step5570 [D loss: -0.259120] [G loss: -1.686105]\n",
      "epoch0 step5575 [D loss: -0.144738] [G loss: -1.432173]\n",
      "epoch0 step5580 [D loss: -0.064506] [G loss: -1.409541]\n",
      "epoch0 step5585 [D loss: 0.095782] [G loss: -1.709081]\n",
      "epoch0 step5590 [D loss: -0.807434] [G loss: -1.226170]\n",
      "epoch0 step5595 [D loss: 0.117377] [G loss: -1.431406]\n",
      "epoch0 step5600 [D loss: -0.502919] [G loss: -1.094951]\n",
      "epoch0 step5605 [D loss: 0.119016] [G loss: -1.247706]\n",
      "epoch0 step5610 [D loss: -0.262545] [G loss: -1.726813]\n",
      "epoch0 step5615 [D loss: -0.131572] [G loss: -1.208549]\n",
      "epoch0 step5620 [D loss: -0.067476] [G loss: -1.606359]\n",
      "epoch0 step5625 [D loss: -0.578732] [G loss: -1.308113]\n",
      "epoch0 step5630 [D loss: -0.687764] [G loss: -1.380803]\n",
      "epoch0 step5635 [D loss: -0.292538] [G loss: -1.384540]\n",
      "epoch0 step5640 [D loss: 0.110134] [G loss: -1.516836]\n",
      "epoch0 step5645 [D loss: -0.400600] [G loss: -1.168495]\n",
      "epoch0 step5650 [D loss: -0.597392] [G loss: -1.114384]\n",
      "epoch0 step5655 [D loss: -0.294246] [G loss: -1.446911]\n",
      "epoch0 step5660 [D loss: -0.362391] [G loss: -1.183795]\n",
      "epoch0 step5665 [D loss: -0.821655] [G loss: -1.144593]\n",
      "epoch0 step5670 [D loss: -0.286969] [G loss: -1.352336]\n",
      "epoch0 step5675 [D loss: -0.540572] [G loss: -1.069192]\n",
      "epoch0 step5680 [D loss: -0.313791] [G loss: -0.966879]\n",
      "epoch0 step5685 [D loss: -0.339782] [G loss: -1.128715]\n",
      "epoch0 step5690 [D loss: -0.280498] [G loss: -1.310681]\n",
      "epoch0 step5695 [D loss: -0.311936] [G loss: -1.291048]\n",
      "epoch0 step5700 [D loss: 0.159533] [G loss: -1.300306]\n",
      "epoch0 step5705 [D loss: -0.226970] [G loss: -1.348705]\n",
      "epoch0 step5710 [D loss: -0.231289] [G loss: -1.357853]\n",
      "epoch0 step5715 [D loss: -0.599479] [G loss: -1.545190]\n",
      "epoch0 step5720 [D loss: -0.030561] [G loss: -1.584399]\n",
      "epoch0 step5725 [D loss: 0.229377] [G loss: -1.280585]\n",
      "epoch0 step5730 [D loss: -0.321955] [G loss: -1.069458]\n",
      "epoch0 step5735 [D loss: -0.624953] [G loss: -1.160676]\n",
      "epoch0 step5740 [D loss: -0.452239] [G loss: -1.159868]\n",
      "epoch0 step5745 [D loss: -0.018797] [G loss: -1.188956]\n",
      "epoch0 step5750 [D loss: -0.040406] [G loss: -1.194335]\n",
      "epoch0 step5755 [D loss: -0.719076] [G loss: -0.509042]\n",
      "epoch0 step5760 [D loss: -0.293923] [G loss: -1.117219]\n",
      "epoch0 step5765 [D loss: -0.300725] [G loss: -1.124150]\n",
      "epoch0 step5770 [D loss: -0.264326] [G loss: -1.168998]\n",
      "epoch0 step5775 [D loss: -0.526517] [G loss: -1.104293]\n",
      "epoch0 step5780 [D loss: -0.434960] [G loss: -1.057154]\n",
      "epoch0 step5785 [D loss: -0.278984] [G loss: -1.450325]\n",
      "epoch0 step5790 [D loss: -0.325093] [G loss: -0.783520]\n",
      "epoch0 step5795 [D loss: -0.402182] [G loss: -1.258560]\n",
      "epoch0 step5800 [D loss: -0.057023] [G loss: -0.982012]\n",
      "epoch0 step5805 [D loss: -0.347487] [G loss: -1.309694]\n",
      "epoch0 step5810 [D loss: -0.355595] [G loss: -1.051355]\n",
      "epoch0 step5815 [D loss: -0.392449] [G loss: -1.162827]\n",
      "epoch0 step5820 [D loss: -0.418637] [G loss: -0.970514]\n",
      "epoch0 step5825 [D loss: -0.251606] [G loss: -0.881926]\n",
      "epoch0 step5830 [D loss: -0.412840] [G loss: -0.816210]\n",
      "epoch0 step5835 [D loss: -0.303405] [G loss: -1.066837]\n",
      "epoch0 step5840 [D loss: -0.523123] [G loss: -0.469618]\n",
      "epoch0 step5845 [D loss: 0.022200] [G loss: -0.705460]\n",
      "epoch0 step5850 [D loss: -0.249211] [G loss: -0.942028]\n",
      "epoch0 step5855 [D loss: -0.160791] [G loss: -0.722039]\n",
      "epoch0 step5860 [D loss: -0.516760] [G loss: -0.566517]\n",
      "epoch0 step5865 [D loss: -0.205721] [G loss: -0.673167]\n",
      "epoch0 step5870 [D loss: -0.140551] [G loss: -0.803007]\n",
      "epoch0 step5875 [D loss: -0.823414] [G loss: -0.723106]\n",
      "epoch0 step5880 [D loss: -0.252987] [G loss: -0.834764]\n",
      "epoch0 step5885 [D loss: -0.598334] [G loss: -0.724918]\n",
      "epoch0 step5890 [D loss: -0.027051] [G loss: -0.887244]\n",
      "epoch0 step5895 [D loss: -0.228998] [G loss: -0.554520]\n",
      "epoch0 step5900 [D loss: -0.035918] [G loss: -0.599926]\n",
      "epoch0 step5905 [D loss: -0.454693] [G loss: -0.367614]\n",
      "epoch0 step5910 [D loss: -0.694962] [G loss: -0.757424]\n",
      "epoch0 step5915 [D loss: -0.173854] [G loss: -1.020205]\n",
      "epoch0 step5920 [D loss: -0.090355] [G loss: -0.795331]\n",
      "epoch0 step5925 [D loss: -0.123613] [G loss: -1.173517]\n",
      "epoch0 step5930 [D loss: 0.138315] [G loss: -1.095464]\n",
      "epoch0 step5935 [D loss: -0.350989] [G loss: -0.529185]\n",
      "epoch0 step5940 [D loss: -0.413818] [G loss: -0.758658]\n",
      "epoch0 step5945 [D loss: -0.121409] [G loss: -0.707084]\n",
      "epoch0 step5950 [D loss: -0.090355] [G loss: -0.560405]\n",
      "epoch0 step5955 [D loss: -0.516958] [G loss: -0.525122]\n",
      "epoch0 step5960 [D loss: -0.753673] [G loss: -0.591270]\n",
      "epoch0 step5965 [D loss: -0.389759] [G loss: -0.641296]\n",
      "epoch0 step5970 [D loss: -0.281542] [G loss: -0.852453]\n",
      "epoch0 step5975 [D loss: -0.638767] [G loss: -0.460726]\n",
      "epoch0 step5980 [D loss: -0.447159] [G loss: -0.710673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step5985 [D loss: 0.155000] [G loss: -0.973584]\n",
      "epoch0 step5990 [D loss: 0.087700] [G loss: -1.092164]\n",
      "epoch0 step5995 [D loss: -0.305308] [G loss: -0.758475]\n",
      "epoch0 step6000 [D loss: -0.301471] [G loss: -0.833776]\n",
      "epoch0 step6005 [D loss: 0.073884] [G loss: -1.215194]\n",
      "epoch0 step6010 [D loss: -0.194795] [G loss: -1.033840]\n",
      "epoch0 step6015 [D loss: -0.156231] [G loss: -1.127858]\n",
      "epoch0 step6020 [D loss: -0.303498] [G loss: -0.931473]\n",
      "epoch0 step6025 [D loss: -0.338674] [G loss: -0.894928]\n",
      "epoch0 step6030 [D loss: -0.250591] [G loss: -0.717338]\n",
      "epoch0 step6035 [D loss: -0.263037] [G loss: -0.622985]\n",
      "epoch0 step6040 [D loss: -0.633303] [G loss: -0.719292]\n",
      "epoch0 step6045 [D loss: -0.151769] [G loss: -0.706909]\n",
      "epoch0 step6050 [D loss: -0.099392] [G loss: -0.898215]\n",
      "epoch0 step6055 [D loss: -0.414622] [G loss: -1.324175]\n",
      "epoch0 step6060 [D loss: -0.211668] [G loss: -0.786038]\n",
      "epoch0 step6065 [D loss: 0.114503] [G loss: -1.012776]\n",
      "epoch0 step6070 [D loss: -0.263571] [G loss: -0.975779]\n",
      "epoch0 step6075 [D loss: -0.198161] [G loss: -0.779030]\n",
      "epoch0 step6080 [D loss: -0.483736] [G loss: -0.855647]\n",
      "epoch0 step6085 [D loss: -0.185692] [G loss: -0.768865]\n",
      "epoch0 step6090 [D loss: -0.183471] [G loss: -0.838462]\n",
      "epoch0 step6095 [D loss: -0.206658] [G loss: -1.027904]\n",
      "epoch0 step6100 [D loss: 0.062644] [G loss: -0.846666]\n",
      "epoch0 step6105 [D loss: -0.226136] [G loss: -0.921452]\n",
      "epoch0 step6110 [D loss: 0.182088] [G loss: -0.875402]\n",
      "epoch0 step6115 [D loss: -0.486539] [G loss: -0.851082]\n",
      "epoch0 step6120 [D loss: -0.396677] [G loss: -0.626039]\n",
      "epoch0 step6125 [D loss: -0.102761] [G loss: -0.928705]\n",
      "epoch0 step6130 [D loss: -0.362538] [G loss: -0.598700]\n",
      "epoch0 step6135 [D loss: -0.331283] [G loss: -0.621900]\n",
      "epoch0 step6140 [D loss: -0.522997] [G loss: -0.697230]\n",
      "epoch0 step6145 [D loss: -0.103825] [G loss: -1.088669]\n",
      "epoch0 step6150 [D loss: -0.198452] [G loss: -0.299589]\n",
      "epoch0 step6155 [D loss: 0.154192] [G loss: -0.969046]\n",
      "epoch0 step6160 [D loss: -0.874143] [G loss: -0.619417]\n",
      "epoch0 step6165 [D loss: 0.054343] [G loss: -0.961543]\n",
      "epoch0 step6170 [D loss: 0.288984] [G loss: -0.599150]\n",
      "epoch0 step6175 [D loss: -0.220239] [G loss: -0.401715]\n",
      "epoch0 step6180 [D loss: 0.109539] [G loss: -0.614148]\n",
      "epoch0 step6185 [D loss: -0.136122] [G loss: -0.647736]\n",
      "epoch0 step6190 [D loss: -0.548797] [G loss: -0.543246]\n",
      "epoch0 step6195 [D loss: -0.276027] [G loss: -0.139106]\n",
      "epoch0 step6200 [D loss: 0.190860] [G loss: -0.580800]\n",
      "epoch0 step6205 [D loss: -0.040659] [G loss: -0.558045]\n",
      "epoch0 step6210 [D loss: -0.250816] [G loss: -0.544900]\n",
      "epoch0 step6215 [D loss: -0.350334] [G loss: -0.811478]\n",
      "epoch0 step6220 [D loss: -0.013427] [G loss: -0.812921]\n",
      "epoch0 step6225 [D loss: -0.508734] [G loss: -0.727236]\n",
      "epoch0 step6230 [D loss: 0.134622] [G loss: -0.880121]\n",
      "epoch0 step6235 [D loss: -0.458005] [G loss: -1.029935]\n",
      "epoch0 step6240 [D loss: -0.312350] [G loss: -0.794543]\n",
      "epoch0 step6245 [D loss: 0.383459] [G loss: -0.817326]\n",
      "epoch0 step6250 [D loss: -0.248490] [G loss: -0.772388]\n",
      "epoch0 step6255 [D loss: -0.224354] [G loss: -0.908036]\n",
      "epoch0 step6260 [D loss: -0.210533] [G loss: -0.668595]\n",
      "epoch0 step6265 [D loss: -0.234709] [G loss: -0.605833]\n",
      "epoch0 step6270 [D loss: -0.041753] [G loss: -1.226368]\n",
      "epoch0 step6275 [D loss: -0.752644] [G loss: -0.824849]\n",
      "epoch0 step6280 [D loss: -0.820003] [G loss: -0.902514]\n",
      "epoch0 step6285 [D loss: 0.000852] [G loss: -0.870487]\n",
      "epoch0 step6290 [D loss: -0.034576] [G loss: -0.817598]\n",
      "epoch0 step6295 [D loss: -0.299736] [G loss: -0.848667]\n",
      "epoch0 step6300 [D loss: -0.167877] [G loss: -1.037402]\n",
      "epoch0 step6305 [D loss: -0.156934] [G loss: -0.864460]\n",
      "epoch0 step6310 [D loss: -0.004234] [G loss: -0.816538]\n",
      "epoch0 step6315 [D loss: -0.311660] [G loss: -0.807905]\n",
      "epoch0 step6320 [D loss: -0.078967] [G loss: -0.955594]\n",
      "epoch0 step6325 [D loss: 0.059613] [G loss: -1.271182]\n",
      "epoch0 step6330 [D loss: -0.659311] [G loss: -0.906334]\n",
      "epoch0 step6335 [D loss: -0.000425] [G loss: -1.346628]\n",
      "epoch0 step6340 [D loss: -0.066500] [G loss: -1.036491]\n",
      "epoch0 step6345 [D loss: -0.114790] [G loss: -0.852084]\n",
      "epoch0 step6350 [D loss: -0.697310] [G loss: -1.100427]\n",
      "epoch0 step6355 [D loss: -0.820859] [G loss: -1.088741]\n",
      "epoch0 step6360 [D loss: -0.037383] [G loss: -1.197607]\n",
      "epoch0 step6365 [D loss: -0.121585] [G loss: -1.054080]\n",
      "epoch0 step6370 [D loss: -0.129610] [G loss: -0.848334]\n",
      "epoch0 step6375 [D loss: 0.104961] [G loss: -1.288772]\n",
      "epoch0 step6380 [D loss: -0.266391] [G loss: -0.880555]\n",
      "epoch0 step6385 [D loss: 0.111388] [G loss: -0.601395]\n",
      "epoch0 step6390 [D loss: -0.147881] [G loss: -0.881037]\n",
      "epoch0 step6395 [D loss: -0.006420] [G loss: -1.058900]\n",
      "epoch0 step6400 [D loss: -0.107133] [G loss: -1.026197]\n",
      "epoch0 step6405 [D loss: -0.078896] [G loss: -1.313028]\n",
      "epoch0 step6410 [D loss: -0.197213] [G loss: -1.133201]\n",
      "epoch0 step6415 [D loss: -0.574226] [G loss: -1.107705]\n",
      "epoch0 step6420 [D loss: -0.138266] [G loss: -1.191877]\n",
      "epoch0 step6425 [D loss: -0.098195] [G loss: -1.315444]\n",
      "epoch0 step6430 [D loss: -0.279850] [G loss: -0.853154]\n",
      "epoch0 step6435 [D loss: -0.183845] [G loss: -0.876903]\n",
      "epoch0 step6440 [D loss: -0.481459] [G loss: -1.016363]\n",
      "epoch0 step6445 [D loss: -0.226582] [G loss: -1.025848]\n",
      "epoch0 step6450 [D loss: -0.305328] [G loss: -1.044962]\n",
      "epoch0 step6455 [D loss: -0.034363] [G loss: -1.193090]\n",
      "epoch0 step6460 [D loss: 0.351055] [G loss: -1.095498]\n",
      "epoch0 step6465 [D loss: 0.097753] [G loss: -1.255267]\n",
      "epoch0 step6470 [D loss: 0.002929] [G loss: -0.966455]\n",
      "epoch0 step6475 [D loss: -0.327379] [G loss: -0.966866]\n",
      "epoch0 step6480 [D loss: -0.383827] [G loss: -1.120167]\n",
      "epoch0 step6485 [D loss: -0.100306] [G loss: -1.293629]\n",
      "epoch0 step6490 [D loss: 0.254649] [G loss: -1.016557]\n",
      "epoch0 step6495 [D loss: -0.050770] [G loss: -0.963523]\n",
      "epoch0 step6500 [D loss: 0.028338] [G loss: -1.196888]\n",
      "epoch0 step6505 [D loss: -0.155509] [G loss: -1.147024]\n",
      "epoch0 step6510 [D loss: -0.692124] [G loss: -1.031645]\n",
      "epoch0 step6515 [D loss: -0.218646] [G loss: -1.410293]\n",
      "epoch0 step6520 [D loss: -0.178500] [G loss: -1.029438]\n",
      "epoch0 step6525 [D loss: 0.171890] [G loss: -0.757035]\n",
      "epoch0 step6530 [D loss: -0.100660] [G loss: -1.114194]\n",
      "epoch0 step6535 [D loss: -0.359504] [G loss: -0.991263]\n",
      "epoch0 step6540 [D loss: -0.141392] [G loss: -0.860163]\n",
      "epoch0 step6545 [D loss: -0.036066] [G loss: -1.087373]\n",
      "epoch0 step6550 [D loss: -0.714002] [G loss: -0.976035]\n",
      "epoch0 step6555 [D loss: -0.444497] [G loss: -1.108931]\n",
      "epoch0 step6560 [D loss: -0.577514] [G loss: -1.033273]\n",
      "epoch0 step6565 [D loss: -0.550523] [G loss: -0.863330]\n",
      "epoch0 step6570 [D loss: -0.035820] [G loss: -1.372236]\n",
      "epoch0 step6575 [D loss: -0.142599] [G loss: -0.906434]\n",
      "epoch0 step6580 [D loss: -0.429436] [G loss: -0.930342]\n",
      "epoch0 step6585 [D loss: 0.291636] [G loss: -1.331527]\n",
      "epoch0 step6590 [D loss: -0.359801] [G loss: -0.911577]\n",
      "epoch0 step6595 [D loss: -0.297431] [G loss: -1.126302]\n",
      "epoch0 step6600 [D loss: -0.453057] [G loss: -1.205970]\n",
      "epoch0 step6605 [D loss: -0.397623] [G loss: -0.873621]\n",
      "epoch0 step6610 [D loss: 0.276879] [G loss: -0.769055]\n",
      "epoch0 step6615 [D loss: 0.052845] [G loss: -0.814764]\n",
      "epoch0 step6620 [D loss: -0.469481] [G loss: -0.708921]\n",
      "epoch0 step6625 [D loss: -0.156935] [G loss: -0.882398]\n",
      "epoch0 step6630 [D loss: 0.008272] [G loss: -0.922504]\n",
      "epoch0 step6635 [D loss: 0.166212] [G loss: -0.869190]\n",
      "epoch0 step6640 [D loss: -0.152136] [G loss: -0.887547]\n",
      "epoch0 step6645 [D loss: -0.004006] [G loss: -0.908454]\n",
      "epoch0 step6650 [D loss: -0.360162] [G loss: -0.953299]\n",
      "epoch0 step6655 [D loss: -0.066145] [G loss: -1.130986]\n",
      "epoch0 step6660 [D loss: -0.067970] [G loss: -0.630102]\n",
      "epoch0 step6665 [D loss: 0.038102] [G loss: -0.585404]\n",
      "epoch0 step6670 [D loss: -0.372070] [G loss: -0.678719]\n",
      "epoch0 step6675 [D loss: 0.325920] [G loss: -0.576075]\n",
      "epoch0 step6680 [D loss: -0.198850] [G loss: -0.753205]\n",
      "epoch0 step6685 [D loss: -0.293963] [G loss: -0.649756]\n",
      "epoch0 step6690 [D loss: -0.816253] [G loss: -0.901783]\n",
      "epoch0 step6695 [D loss: -0.338980] [G loss: -0.834945]\n",
      "epoch0 step6700 [D loss: -0.274898] [G loss: -0.827777]\n",
      "epoch0 step6705 [D loss: -0.035351] [G loss: -0.853500]\n",
      "epoch0 step6710 [D loss: 0.203899] [G loss: -0.972279]\n",
      "epoch0 step6715 [D loss: -0.280191] [G loss: -0.594681]\n",
      "epoch0 step6720 [D loss: -0.408582] [G loss: -0.756279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step6725 [D loss: -0.287615] [G loss: -0.509419]\n",
      "epoch0 step6730 [D loss: -0.457576] [G loss: -0.585997]\n",
      "epoch0 step6735 [D loss: -0.356813] [G loss: -0.835922]\n",
      "epoch0 step6740 [D loss: -0.241127] [G loss: -0.808784]\n",
      "epoch0 step6745 [D loss: -0.273240] [G loss: -0.937057]\n",
      "epoch0 step6750 [D loss: -0.331293] [G loss: -0.932573]\n",
      "epoch0 step6755 [D loss: -0.058704] [G loss: -0.808592]\n",
      "epoch0 step6760 [D loss: -0.112678] [G loss: -1.035462]\n",
      "epoch0 step6765 [D loss: -0.125395] [G loss: -0.956971]\n",
      "epoch0 step6770 [D loss: -0.398749] [G loss: -0.732470]\n",
      "epoch0 step6775 [D loss: -0.424680] [G loss: -1.057407]\n",
      "epoch0 step6780 [D loss: 0.137958] [G loss: -1.160282]\n",
      "epoch0 step6785 [D loss: -0.050046] [G loss: -0.832711]\n",
      "epoch0 step6790 [D loss: -0.099866] [G loss: -0.844220]\n",
      "epoch0 step6795 [D loss: -0.549812] [G loss: -0.659320]\n",
      "epoch0 step6800 [D loss: -0.678856] [G loss: -0.645835]\n",
      "epoch0 step6805 [D loss: -0.521921] [G loss: -0.852073]\n",
      "epoch0 step6810 [D loss: 0.176753] [G loss: -0.889374]\n",
      "epoch0 step6815 [D loss: -0.582315] [G loss: -0.709823]\n",
      "epoch0 step6820 [D loss: -0.617566] [G loss: -0.903325]\n",
      "epoch0 step6825 [D loss: -0.411325] [G loss: -0.732678]\n",
      "epoch0 step6830 [D loss: -0.496530] [G loss: -0.847621]\n",
      "epoch0 step6835 [D loss: -0.115680] [G loss: -1.032696]\n",
      "epoch0 step6840 [D loss: -0.627456] [G loss: -0.929376]\n",
      "epoch0 step6845 [D loss: 0.132132] [G loss: -0.968773]\n",
      "epoch0 step6850 [D loss: 0.239536] [G loss: -1.214908]\n",
      "epoch0 step6855 [D loss: -0.304793] [G loss: -0.837859]\n",
      "epoch0 step6860 [D loss: -0.049079] [G loss: -0.945212]\n",
      "epoch0 step6865 [D loss: 0.126908] [G loss: -1.035273]\n",
      "epoch0 step6870 [D loss: 0.001868] [G loss: -0.773042]\n",
      "epoch0 step6875 [D loss: -0.567649] [G loss: -0.733860]\n",
      "epoch0 step6880 [D loss: -0.179707] [G loss: -0.864640]\n",
      "epoch0 step6885 [D loss: -0.383377] [G loss: -0.607088]\n",
      "epoch0 step6890 [D loss: 0.013433] [G loss: -0.750893]\n",
      "epoch0 step6895 [D loss: -0.556192] [G loss: -0.638762]\n",
      "epoch0 step6900 [D loss: -0.347803] [G loss: -1.039539]\n",
      "epoch0 step6905 [D loss: -0.374884] [G loss: -0.723443]\n",
      "epoch0 step6910 [D loss: -0.104933] [G loss: -0.428655]\n",
      "epoch0 step6915 [D loss: -0.243389] [G loss: -0.658867]\n",
      "epoch0 step6920 [D loss: -0.267100] [G loss: -0.726317]\n",
      "epoch0 step6925 [D loss: -0.168296] [G loss: -0.478326]\n",
      "epoch0 step6930 [D loss: 0.059359] [G loss: -0.538315]\n",
      "epoch0 step6935 [D loss: -0.141289] [G loss: -0.645188]\n",
      "epoch0 step6940 [D loss: -0.057629] [G loss: -0.788391]\n",
      "epoch0 step6945 [D loss: -0.303775] [G loss: -0.701612]\n",
      "epoch0 step6950 [D loss: 0.115956] [G loss: -0.886213]\n",
      "epoch0 step6955 [D loss: -0.333099] [G loss: -0.897832]\n",
      "epoch0 step6960 [D loss: -0.100437] [G loss: -1.103011]\n",
      "epoch0 step6965 [D loss: -0.354741] [G loss: -0.730271]\n",
      "epoch0 step6970 [D loss: -1.118319] [G loss: -0.509855]\n",
      "epoch0 step6975 [D loss: 0.074663] [G loss: -0.696033]\n",
      "epoch0 step6980 [D loss: -0.700412] [G loss: -0.739965]\n",
      "epoch0 step6985 [D loss: -0.369101] [G loss: -0.440171]\n",
      "epoch0 step6990 [D loss: -0.104025] [G loss: -0.419219]\n",
      "epoch0 step6995 [D loss: -0.349622] [G loss: -0.851310]\n",
      "epoch0 step7000 [D loss: -0.052419] [G loss: -1.431078]\n",
      "epoch0 step7005 [D loss: -0.340708] [G loss: -1.043172]\n",
      "epoch0 step7010 [D loss: -0.221067] [G loss: -0.653335]\n",
      "epoch0 step7015 [D loss: 0.086453] [G loss: -1.025942]\n",
      "epoch0 step7020 [D loss: 0.069065] [G loss: -0.864731]\n",
      "epoch0 step7025 [D loss: 0.307092] [G loss: -1.227163]\n",
      "epoch0 step7030 [D loss: -0.098929] [G loss: -0.740597]\n",
      "epoch0 step7035 [D loss: -0.568327] [G loss: -0.655555]\n",
      "epoch0 step7040 [D loss: 0.353469] [G loss: -1.073299]\n",
      "epoch0 step7045 [D loss: -0.501591] [G loss: -0.821399]\n",
      "epoch0 step7050 [D loss: -0.262372] [G loss: -0.769905]\n",
      "epoch0 step7055 [D loss: -0.456757] [G loss: -0.568509]\n",
      "epoch0 step7060 [D loss: 0.932519] [G loss: -0.692392]\n",
      "epoch0 step7065 [D loss: 0.399302] [G loss: -0.595271]\n",
      "epoch0 step7070 [D loss: -0.229692] [G loss: -0.511886]\n",
      "epoch0 step7075 [D loss: 0.240488] [G loss: -0.858167]\n",
      "epoch0 step7080 [D loss: 0.001667] [G loss: -0.660568]\n",
      "epoch0 step7085 [D loss: -0.151367] [G loss: -0.737880]\n",
      "epoch0 step7090 [D loss: -0.312746] [G loss: -0.502914]\n",
      "epoch0 step7095 [D loss: -0.129767] [G loss: -0.451857]\n",
      "epoch0 step7100 [D loss: 0.295481] [G loss: -0.668124]\n",
      "epoch0 step7105 [D loss: -0.606485] [G loss: -0.302364]\n",
      "epoch0 step7110 [D loss: -0.142724] [G loss: -0.777407]\n",
      "epoch0 step7115 [D loss: -0.439246] [G loss: -0.680378]\n",
      "epoch0 step7120 [D loss: -0.401714] [G loss: -0.424186]\n",
      "epoch0 step7125 [D loss: 0.054253] [G loss: -0.519239]\n",
      "epoch0 step7130 [D loss: -0.053670] [G loss: -0.566049]\n",
      "epoch0 step7135 [D loss: -0.390733] [G loss: -0.653079]\n",
      "epoch0 step7140 [D loss: 0.098846] [G loss: -0.512940]\n",
      "epoch0 step7145 [D loss: -0.125514] [G loss: -0.616740]\n",
      "epoch0 step7150 [D loss: -0.316655] [G loss: -0.362565]\n",
      "epoch0 step7155 [D loss: -0.220119] [G loss: -0.764878]\n",
      "epoch0 step7160 [D loss: 0.411828] [G loss: -0.521708]\n",
      "epoch0 step7165 [D loss: -0.109769] [G loss: -0.640888]\n",
      "epoch0 step7170 [D loss: -0.708039] [G loss: -0.527478]\n",
      "epoch0 step7175 [D loss: -0.332757] [G loss: -0.388161]\n",
      "epoch0 step7180 [D loss: -0.553854] [G loss: 0.100833]\n",
      "epoch0 step7185 [D loss: -0.403618] [G loss: -0.232006]\n",
      "epoch0 step7190 [D loss: -0.249641] [G loss: -0.261108]\n",
      "epoch0 step7195 [D loss: -0.660729] [G loss: -0.359518]\n",
      "epoch0 step7200 [D loss: -0.328816] [G loss: -0.129408]\n",
      "epoch0 step7205 [D loss: -0.297766] [G loss: -0.326731]\n",
      "epoch0 step7210 [D loss: -0.572823] [G loss: -0.018753]\n",
      "epoch0 step7215 [D loss: -0.119648] [G loss: -0.426058]\n",
      "epoch0 step7220 [D loss: -0.280041] [G loss: -0.627410]\n",
      "epoch0 step7225 [D loss: 0.135371] [G loss: -0.442336]\n",
      "epoch0 step7230 [D loss: -0.794364] [G loss: -0.568644]\n",
      "epoch0 step7235 [D loss: -0.318398] [G loss: -0.441386]\n",
      "epoch0 step7240 [D loss: -0.393280] [G loss: -0.742963]\n",
      "epoch0 step7245 [D loss: -0.310763] [G loss: -0.470418]\n",
      "epoch0 step7250 [D loss: -0.274571] [G loss: -0.439621]\n",
      "epoch0 step7255 [D loss: -0.866317] [G loss: -0.305581]\n",
      "epoch0 step7260 [D loss: 0.009122] [G loss: -0.916982]\n",
      "epoch0 step7265 [D loss: -0.162704] [G loss: -0.732831]\n",
      "epoch0 step7270 [D loss: -0.070896] [G loss: -0.921624]\n",
      "epoch0 step7275 [D loss: 0.089516] [G loss: -0.920743]\n",
      "epoch0 step7280 [D loss: -0.572589] [G loss: -0.775731]\n",
      "epoch0 step7285 [D loss: -0.123195] [G loss: -0.917976]\n",
      "epoch0 step7290 [D loss: -0.043501] [G loss: -1.018341]\n",
      "epoch0 step7295 [D loss: 0.368116] [G loss: -0.925664]\n",
      "epoch0 step7300 [D loss: -0.043623] [G loss: -0.794485]\n",
      "epoch0 step7305 [D loss: -0.427940] [G loss: -1.133037]\n",
      "epoch0 step7310 [D loss: -0.214242] [G loss: -0.975413]\n",
      "epoch0 step7315 [D loss: -0.115324] [G loss: -1.070288]\n",
      "epoch0 step7320 [D loss: -0.147460] [G loss: -1.258976]\n",
      "epoch0 step7325 [D loss: 0.170788] [G loss: -1.230792]\n",
      "epoch0 step7330 [D loss: -0.435338] [G loss: -1.479907]\n",
      "epoch0 step7335 [D loss: -0.536693] [G loss: -1.254654]\n",
      "epoch0 step7340 [D loss: 0.107389] [G loss: -1.261385]\n",
      "epoch0 step7345 [D loss: -0.154106] [G loss: -1.165016]\n",
      "epoch0 step7350 [D loss: -0.207028] [G loss: -1.395849]\n",
      "epoch0 step7355 [D loss: -0.279943] [G loss: -1.385926]\n",
      "epoch0 step7360 [D loss: -0.183623] [G loss: -1.532552]\n",
      "epoch0 step7365 [D loss: -0.194553] [G loss: -1.164273]\n",
      "epoch0 step7370 [D loss: -0.325452] [G loss: -1.471488]\n",
      "epoch0 step7375 [D loss: 0.158826] [G loss: -1.821542]\n",
      "epoch0 step7380 [D loss: -0.263487] [G loss: -1.360629]\n",
      "epoch0 step7385 [D loss: -0.135552] [G loss: -1.300084]\n",
      "epoch0 step7390 [D loss: 0.300712] [G loss: -1.697727]\n",
      "epoch0 step7395 [D loss: -0.593678] [G loss: -1.534078]\n",
      "epoch0 step7400 [D loss: -0.319296] [G loss: -1.381279]\n",
      "epoch0 step7405 [D loss: 0.355590] [G loss: -1.495211]\n",
      "epoch0 step7410 [D loss: -0.124461] [G loss: -1.444115]\n",
      "epoch0 step7415 [D loss: 0.189495] [G loss: -1.378572]\n",
      "epoch0 step7420 [D loss: -0.258571] [G loss: -1.163292]\n",
      "epoch0 step7425 [D loss: -0.187165] [G loss: -1.378402]\n",
      "epoch0 step7430 [D loss: -0.050375] [G loss: -1.450615]\n",
      "epoch0 step7435 [D loss: 0.088716] [G loss: -1.541144]\n",
      "epoch0 step7440 [D loss: -0.234762] [G loss: -1.398128]\n",
      "epoch0 step7445 [D loss: -0.435581] [G loss: -1.338049]\n",
      "epoch0 step7450 [D loss: -0.511399] [G loss: -1.276358]\n",
      "epoch0 step7455 [D loss: -0.421049] [G loss: -1.197687]\n",
      "epoch0 step7460 [D loss: -0.403984] [G loss: -1.203028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 step7465 [D loss: 0.313492] [G loss: -1.897905]\n",
      "epoch0 step7470 [D loss: -0.047513] [G loss: -0.873109]\n",
      "epoch0 step7475 [D loss: -0.542154] [G loss: -1.219758]\n",
      "epoch0 step7480 [D loss: 0.129246] [G loss: -1.297243]\n",
      "epoch0 step7485 [D loss: -0.503991] [G loss: -1.308601]\n",
      "epoch0 step7490 [D loss: 0.125978] [G loss: -1.441039]\n",
      "epoch0 step7495 [D loss: -0.088082] [G loss: -1.265430]\n",
      "epoch0 step7500 [D loss: -0.446752] [G loss: -1.182612]\n",
      "epoch0 step7505 [D loss: -0.110044] [G loss: -1.220025]\n",
      "epoch0 step7510 [D loss: -0.332442] [G loss: -1.227359]\n",
      "epoch0 step7515 [D loss: -0.779337] [G loss: -1.076911]\n",
      "epoch0 step7520 [D loss: -0.127947] [G loss: -1.311455]\n",
      "epoch0 step7525 [D loss: -0.078102] [G loss: -1.163535]\n",
      "epoch0 step7530 [D loss: -0.595728] [G loss: -1.458513]\n",
      "epoch0 step7535 [D loss: -0.189830] [G loss: -1.347316]\n",
      "epoch0 step7540 [D loss: -0.213199] [G loss: -1.135034]\n",
      "epoch0 step7545 [D loss: -0.661975] [G loss: -0.882772]\n",
      "epoch0 step7550 [D loss: -0.198022] [G loss: -1.009686]\n",
      "epoch0 step7555 [D loss: -0.385341] [G loss: -1.010829]\n",
      "epoch0 step7560 [D loss: 0.021545] [G loss: -1.256744]\n",
      "epoch0 step7565 [D loss: 0.119221] [G loss: -1.514506]\n",
      "epoch0 step7570 [D loss: 0.000883] [G loss: -1.310250]\n",
      "epoch0 step7575 [D loss: 0.190138] [G loss: -1.730271]\n",
      "epoch0 step7580 [D loss: 0.289136] [G loss: -1.472873]\n",
      "epoch0 step7585 [D loss: -0.306386] [G loss: -1.423072]\n",
      "epoch0 step7590 [D loss: 0.610774] [G loss: -1.196256]\n",
      "epoch0 step7595 [D loss: -0.300165] [G loss: -1.408963]\n",
      "epoch0 step7600 [D loss: -0.217403] [G loss: -1.523744]\n",
      "epoch0 step7605 [D loss: -0.165554] [G loss: -1.335491]\n",
      "epoch0 step7610 [D loss: -0.195939] [G loss: -1.430747]\n",
      "epoch0 step7615 [D loss: -0.071570] [G loss: -1.555839]\n",
      "epoch0 step7620 [D loss: -0.236249] [G loss: -1.566458]\n",
      "epoch0 step7625 [D loss: -0.153273] [G loss: -1.663284]\n",
      "epoch0 step7630 [D loss: 0.485543] [G loss: -1.689046]\n",
      "epoch0 step7635 [D loss: 0.091858] [G loss: -1.568367]\n",
      "epoch0 step7640 [D loss: 0.530803] [G loss: -1.605198]\n",
      "epoch0 step7645 [D loss: -0.559949] [G loss: -1.341299]\n",
      "epoch0 step7650 [D loss: -0.215295] [G loss: -1.198734]\n",
      "epoch0 step7655 [D loss: -0.263003] [G loss: -1.389111]\n",
      "epoch0 step7660 [D loss: 0.439666] [G loss: -1.589006]\n",
      "epoch0 step7665 [D loss: 0.067251] [G loss: -1.298765]\n",
      "epoch0 step7670 [D loss: 0.148639] [G loss: -1.274383]\n",
      "epoch0 step7675 [D loss: -0.024620] [G loss: -1.191828]\n",
      "epoch0 step7680 [D loss: 0.043205] [G loss: -1.236494]\n",
      "epoch0 step7685 [D loss: 0.464244] [G loss: -1.201409]\n",
      "epoch0 step7690 [D loss: -0.153386] [G loss: -1.265289]\n",
      "epoch0 step7695 [D loss: 0.253301] [G loss: -1.221693]\n",
      "epoch0 step7700 [D loss: 0.245147] [G loss: -1.172482]\n",
      "epoch0 step7705 [D loss: 0.073460] [G loss: -1.155712]\n",
      "epoch0 step7710 [D loss: -0.367990] [G loss: -1.066412]\n",
      "epoch0 step7715 [D loss: 0.090565] [G loss: -1.097848]\n",
      "epoch0 step7720 [D loss: 0.113083] [G loss: -1.105699]\n",
      "epoch0 step7725 [D loss: 0.179250] [G loss: -1.263938]\n",
      "epoch0 step7730 [D loss: 0.371059] [G loss: -0.944939]\n",
      "epoch0 step7735 [D loss: 0.304659] [G loss: -0.753748]\n",
      "epoch0 step7740 [D loss: -0.097701] [G loss: -0.874886]\n",
      "epoch0 step7745 [D loss: -0.025151] [G loss: -0.842699]\n",
      "epoch0 step7750 [D loss: -0.307519] [G loss: -1.076056]\n",
      "epoch0 step7755 [D loss: 0.163686] [G loss: -0.998685]\n",
      "epoch0 step7760 [D loss: -0.095692] [G loss: -0.721028]\n",
      "epoch0 step7765 [D loss: -0.364019] [G loss: -1.000405]\n",
      "epoch0 step7770 [D loss: 0.630945] [G loss: -0.884796]\n",
      "epoch0 step7775 [D loss: -0.302000] [G loss: -0.800485]\n",
      "epoch0 step7780 [D loss: -0.370750] [G loss: -0.915799]\n",
      "epoch0 step7785 [D loss: -0.258544] [G loss: -0.952954]\n",
      "epoch0 step7790 [D loss: 0.050332] [G loss: -1.141483]\n",
      "epoch0 step7795 [D loss: -0.270867] [G loss: -0.985983]\n",
      "epoch0 step7800 [D loss: 0.093384] [G loss: -0.961349]\n",
      "epoch0 step7805 [D loss: -0.030533] [G loss: -1.221991]\n",
      "epoch0 step7810 [D loss: 0.105432] [G loss: -1.008727]\n",
      "epoch1 step7815 [D loss: -0.030976] [G loss: -1.136808]\n",
      "epoch1 step7820 [D loss: 0.224026] [G loss: -0.869820]\n",
      "epoch1 step7825 [D loss: 0.346525] [G loss: -1.400068]\n",
      "epoch1 step7830 [D loss: -0.397412] [G loss: -1.148585]\n",
      "epoch1 step7835 [D loss: 0.325966] [G loss: -1.413297]\n",
      "epoch1 step7840 [D loss: 0.046944] [G loss: -1.581770]\n",
      "epoch1 step7845 [D loss: 0.091984] [G loss: -1.061313]\n",
      "epoch1 step7850 [D loss: 0.278269] [G loss: -1.255267]\n",
      "epoch1 step7855 [D loss: 0.503289] [G loss: -1.516311]\n",
      "epoch1 step7860 [D loss: -0.107179] [G loss: -1.800783]\n",
      "epoch1 step7865 [D loss: -0.116260] [G loss: -1.385900]\n",
      "epoch1 step7870 [D loss: -0.076741] [G loss: -1.531085]\n",
      "epoch1 step7875 [D loss: 0.444757] [G loss: -1.175652]\n",
      "epoch1 step7880 [D loss: 0.367052] [G loss: -1.431124]\n",
      "epoch1 step7885 [D loss: 0.103913] [G loss: -1.285099]\n",
      "epoch1 step7890 [D loss: 0.409795] [G loss: -1.178517]\n",
      "epoch1 step7895 [D loss: -0.251712] [G loss: -1.282015]\n",
      "epoch1 step7900 [D loss: -0.021217] [G loss: -1.560491]\n",
      "epoch1 step7905 [D loss: -0.453087] [G loss: -0.914010]\n",
      "epoch1 step7910 [D loss: -0.563685] [G loss: -0.882971]\n",
      "epoch1 step7915 [D loss: -0.573106] [G loss: -1.010582]\n",
      "epoch1 step7920 [D loss: -0.262181] [G loss: -1.229502]\n",
      "epoch1 step7925 [D loss: -0.214482] [G loss: -1.062474]\n",
      "epoch1 step7930 [D loss: -0.618393] [G loss: -0.956965]\n",
      "epoch1 step7935 [D loss: -0.235218] [G loss: -1.029721]\n",
      "epoch1 step7940 [D loss: -0.119827] [G loss: -0.975499]\n",
      "epoch1 step7945 [D loss: -0.473214] [G loss: -1.113794]\n",
      "epoch1 step7950 [D loss: -0.715711] [G loss: -1.067511]\n",
      "epoch1 step7955 [D loss: -0.461020] [G loss: -0.955913]\n",
      "epoch1 step7960 [D loss: -0.602645] [G loss: -0.566715]\n",
      "epoch1 step7965 [D loss: -0.251939] [G loss: -0.648905]\n",
      "epoch1 step7970 [D loss: -0.187083] [G loss: -1.138753]\n",
      "epoch1 step7975 [D loss: -0.446525] [G loss: -1.094239]\n",
      "epoch1 step7980 [D loss: -0.466877] [G loss: -0.821738]\n",
      "epoch1 step7985 [D loss: -0.636445] [G loss: -0.646213]\n",
      "epoch1 step7990 [D loss: -0.100105] [G loss: -0.793624]\n",
      "epoch1 step7995 [D loss: -0.271898] [G loss: -0.692519]\n",
      "epoch1 step8000 [D loss: -0.465838] [G loss: -0.716175]\n",
      "epoch1 step8005 [D loss: -0.201646] [G loss: -0.461582]\n",
      "epoch1 step8010 [D loss: -0.691829] [G loss: -0.479836]\n",
      "epoch1 step8015 [D loss: -0.443023] [G loss: -0.450002]\n",
      "epoch1 step8020 [D loss: -0.119242] [G loss: -0.411322]\n",
      "epoch1 step8025 [D loss: -0.258376] [G loss: -0.532170]\n",
      "epoch1 step8030 [D loss: -0.004723] [G loss: -0.244445]\n",
      "epoch1 step8035 [D loss: -0.068525] [G loss: -0.687703]\n",
      "epoch1 step8040 [D loss: -0.123069] [G loss: -0.517043]\n",
      "epoch1 step8045 [D loss: -0.033859] [G loss: -0.506714]\n",
      "epoch1 step8050 [D loss: -0.353563] [G loss: -0.617641]\n",
      "epoch1 step8055 [D loss: -0.192439] [G loss: -0.687583]\n",
      "epoch1 step8060 [D loss: 0.017365] [G loss: -0.756249]\n",
      "epoch1 step8065 [D loss: 0.228334] [G loss: -0.757341]\n",
      "epoch1 step8070 [D loss: -0.087218] [G loss: -0.855045]\n",
      "epoch1 step8075 [D loss: -0.007620] [G loss: -0.365180]\n",
      "epoch1 step8080 [D loss: -0.376372] [G loss: -0.815517]\n",
      "epoch1 step8085 [D loss: -0.123432] [G loss: -0.319565]\n",
      "epoch1 step8090 [D loss: -0.242889] [G loss: -0.397079]\n",
      "epoch1 step8095 [D loss: 0.297012] [G loss: -0.681245]\n",
      "epoch1 step8100 [D loss: -0.216299] [G loss: -0.610293]\n",
      "epoch1 step8105 [D loss: 0.089897] [G loss: -0.262400]\n",
      "epoch1 step8110 [D loss: -0.142293] [G loss: -0.270916]\n",
      "epoch1 step8115 [D loss: 0.337289] [G loss: -0.589864]\n",
      "epoch1 step8120 [D loss: 0.096166] [G loss: -0.329790]\n",
      "epoch1 step8125 [D loss: 0.200985] [G loss: -0.444640]\n",
      "epoch1 step8130 [D loss: 0.192027] [G loss: -0.199237]\n",
      "epoch1 step8135 [D loss: -0.113220] [G loss: -0.430472]\n",
      "epoch1 step8140 [D loss: -0.279542] [G loss: -0.292384]\n",
      "epoch1 step8145 [D loss: 0.225184] [G loss: -0.667576]\n",
      "epoch1 step8150 [D loss: -0.175360] [G loss: -0.492568]\n",
      "epoch1 step8155 [D loss: 0.358101] [G loss: -0.187806]\n",
      "epoch1 step8160 [D loss: -0.591489] [G loss: -0.393731]\n",
      "epoch1 step8165 [D loss: -0.027605] [G loss: -0.201981]\n",
      "epoch1 step8170 [D loss: 0.007458] [G loss: -0.186995]\n",
      "epoch1 step8175 [D loss: -0.233918] [G loss: -0.421464]\n",
      "epoch1 step8180 [D loss: -0.353816] [G loss: -0.278198]\n",
      "epoch1 step8185 [D loss: -0.129334] [G loss: -0.536181]\n",
      "epoch1 step8190 [D loss: -0.205365] [G loss: 0.119287]\n",
      "epoch1 step8195 [D loss: -0.683015] [G loss: 0.029079]\n",
      "epoch1 step8200 [D loss: 0.018382] [G loss: -0.418001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step8205 [D loss: 0.331918] [G loss: -0.423637]\n",
      "epoch1 step8210 [D loss: -0.303592] [G loss: 0.014118]\n",
      "epoch1 step8215 [D loss: 0.161020] [G loss: -0.246421]\n",
      "epoch1 step8220 [D loss: -0.703441] [G loss: -0.007701]\n",
      "epoch1 step8225 [D loss: -0.255947] [G loss: 0.060777]\n",
      "epoch1 step8230 [D loss: -0.524431] [G loss: -0.438638]\n",
      "epoch1 step8235 [D loss: -0.182232] [G loss: -0.678396]\n",
      "epoch1 step8240 [D loss: -0.153359] [G loss: -0.384436]\n",
      "epoch1 step8245 [D loss: -0.289836] [G loss: -0.067043]\n",
      "epoch1 step8250 [D loss: -0.084157] [G loss: -0.475114]\n",
      "epoch1 step8255 [D loss: -0.565926] [G loss: -0.239981]\n",
      "epoch1 step8260 [D loss: -0.592564] [G loss: -0.424987]\n",
      "epoch1 step8265 [D loss: 0.136190] [G loss: -0.547070]\n",
      "epoch1 step8270 [D loss: -0.061171] [G loss: -0.552514]\n",
      "epoch1 step8275 [D loss: -0.022507] [G loss: -0.480561]\n",
      "epoch1 step8280 [D loss: -0.089986] [G loss: -0.401364]\n",
      "epoch1 step8285 [D loss: -0.188394] [G loss: -0.473681]\n",
      "epoch1 step8290 [D loss: 0.263973] [G loss: -0.476078]\n",
      "epoch1 step8295 [D loss: -0.268975] [G loss: -0.259241]\n",
      "epoch1 step8300 [D loss: 0.477681] [G loss: -0.526320]\n",
      "epoch1 step8305 [D loss: 0.301419] [G loss: -0.298731]\n",
      "epoch1 step8310 [D loss: -0.145878] [G loss: -0.428936]\n",
      "epoch1 step8315 [D loss: -0.129042] [G loss: -0.176041]\n",
      "epoch1 step8320 [D loss: -0.202867] [G loss: -0.522504]\n",
      "epoch1 step8325 [D loss: 0.041516] [G loss: -0.271401]\n",
      "epoch1 step8330 [D loss: -0.240316] [G loss: -0.235032]\n",
      "epoch1 step8335 [D loss: 0.598427] [G loss: -0.436280]\n",
      "epoch1 step8340 [D loss: 0.336207] [G loss: -0.530355]\n",
      "epoch1 step8345 [D loss: 0.010401] [G loss: -0.079075]\n",
      "epoch1 step8350 [D loss: 0.444954] [G loss: -0.455199]\n",
      "epoch1 step8355 [D loss: -0.000763] [G loss: -0.411580]\n",
      "epoch1 step8360 [D loss: -0.024168] [G loss: -0.068638]\n",
      "epoch1 step8365 [D loss: 0.250944] [G loss: -0.054759]\n",
      "epoch1 step8370 [D loss: 0.172355] [G loss: -0.412808]\n",
      "epoch1 step8375 [D loss: -0.254673] [G loss: 0.132507]\n",
      "epoch1 step8380 [D loss: 0.302341] [G loss: -0.305039]\n",
      "epoch1 step8385 [D loss: -0.157074] [G loss: -0.318566]\n",
      "epoch1 step8390 [D loss: -0.404003] [G loss: -0.543735]\n",
      "epoch1 step8395 [D loss: -0.214603] [G loss: -0.000034]\n",
      "epoch1 step8400 [D loss: -0.540261] [G loss: -0.415912]\n",
      "epoch1 step8405 [D loss: -0.308737] [G loss: 0.049435]\n",
      "epoch1 step8410 [D loss: -0.220222] [G loss: -0.247797]\n",
      "epoch1 step8415 [D loss: -0.001237] [G loss: -0.031953]\n",
      "epoch1 step8420 [D loss: -0.596073] [G loss: 0.015692]\n",
      "epoch1 step8425 [D loss: 0.176345] [G loss: -0.175769]\n",
      "epoch1 step8430 [D loss: -0.129529] [G loss: -0.180119]\n",
      "epoch1 step8435 [D loss: -0.253854] [G loss: -0.342839]\n",
      "epoch1 step8440 [D loss: -0.121636] [G loss: -0.311181]\n",
      "epoch1 step8445 [D loss: -0.456562] [G loss: -0.424106]\n",
      "epoch1 step8450 [D loss: 0.013407] [G loss: -0.065153]\n",
      "epoch1 step8455 [D loss: -0.253304] [G loss: -0.460342]\n",
      "epoch1 step8460 [D loss: -0.014124] [G loss: -0.220501]\n",
      "epoch1 step8465 [D loss: -0.004345] [G loss: -0.432488]\n",
      "epoch1 step8470 [D loss: 0.076336] [G loss: -0.051893]\n",
      "epoch1 step8475 [D loss: 0.378087] [G loss: -0.508955]\n",
      "epoch1 step8480 [D loss: -0.305116] [G loss: 0.038812]\n",
      "epoch1 step8485 [D loss: -0.501713] [G loss: -0.292777]\n",
      "epoch1 step8490 [D loss: 0.054189] [G loss: -0.851140]\n",
      "epoch1 step8495 [D loss: -0.116868] [G loss: -0.169730]\n",
      "epoch1 step8500 [D loss: 0.180653] [G loss: -0.455130]\n",
      "epoch1 step8505 [D loss: -0.276678] [G loss: -0.064374]\n",
      "epoch1 step8510 [D loss: -0.303731] [G loss: -0.506759]\n",
      "epoch1 step8515 [D loss: -0.105593] [G loss: -0.265785]\n",
      "epoch1 step8520 [D loss: -0.035212] [G loss: -0.280427]\n",
      "epoch1 step8525 [D loss: -0.186334] [G loss: -0.316096]\n",
      "epoch1 step8530 [D loss: 0.131175] [G loss: -0.338393]\n",
      "epoch1 step8535 [D loss: 0.046976] [G loss: -0.605285]\n",
      "epoch1 step8540 [D loss: -0.038690] [G loss: -0.305985]\n",
      "epoch1 step8545 [D loss: -0.187816] [G loss: -0.218915]\n",
      "epoch1 step8550 [D loss: 0.232372] [G loss: -0.938804]\n",
      "epoch1 step8555 [D loss: 0.175193] [G loss: -0.255185]\n",
      "epoch1 step8560 [D loss: 0.141968] [G loss: -0.643715]\n",
      "epoch1 step8565 [D loss: -0.131449] [G loss: -0.333642]\n",
      "epoch1 step8570 [D loss: -0.110048] [G loss: -0.176105]\n",
      "epoch1 step8575 [D loss: -0.285566] [G loss: -0.066107]\n",
      "epoch1 step8580 [D loss: -0.274285] [G loss: -0.525587]\n",
      "epoch1 step8585 [D loss: -0.084815] [G loss: -0.441733]\n",
      "epoch1 step8590 [D loss: 0.013889] [G loss: -0.148274]\n",
      "epoch1 step8595 [D loss: -0.260445] [G loss: -0.014003]\n",
      "epoch1 step8600 [D loss: 0.170413] [G loss: -0.074342]\n",
      "epoch1 step8605 [D loss: -0.103147] [G loss: -0.336475]\n",
      "epoch1 step8610 [D loss: -0.061853] [G loss: -0.231415]\n",
      "epoch1 step8615 [D loss: 0.212524] [G loss: -0.277528]\n",
      "epoch1 step8620 [D loss: -0.148113] [G loss: -0.112991]\n",
      "epoch1 step8625 [D loss: -0.146599] [G loss: -0.202713]\n",
      "epoch1 step8630 [D loss: -0.290744] [G loss: -0.011347]\n",
      "epoch1 step8635 [D loss: 0.121454] [G loss: -0.119847]\n",
      "epoch1 step8640 [D loss: 0.163392] [G loss: -0.207869]\n",
      "epoch1 step8645 [D loss: -0.558160] [G loss: -0.163430]\n",
      "epoch1 step8650 [D loss: -0.289078] [G loss: -0.140578]\n",
      "epoch1 step8655 [D loss: -0.332310] [G loss: -0.122367]\n",
      "epoch1 step8660 [D loss: -0.174322] [G loss: -0.215639]\n",
      "epoch1 step8665 [D loss: -0.194363] [G loss: -0.286221]\n",
      "epoch1 step8670 [D loss: -0.499184] [G loss: -0.114664]\n",
      "epoch1 step8675 [D loss: -0.114198] [G loss: -0.147911]\n",
      "epoch1 step8680 [D loss: -0.179790] [G loss: -0.590981]\n",
      "epoch1 step8685 [D loss: -0.117267] [G loss: -0.267520]\n",
      "epoch1 step8690 [D loss: -0.447051] [G loss: 0.143617]\n",
      "epoch1 step8695 [D loss: -0.174705] [G loss: -0.257793]\n",
      "epoch1 step8700 [D loss: -0.291193] [G loss: 0.012408]\n",
      "epoch1 step8705 [D loss: -0.401806] [G loss: 0.045520]\n",
      "epoch1 step8710 [D loss: 0.084869] [G loss: -0.129698]\n",
      "epoch1 step8715 [D loss: 0.056418] [G loss: -0.031685]\n",
      "epoch1 step8720 [D loss: 0.059695] [G loss: -0.032379]\n",
      "epoch1 step8725 [D loss: 0.056022] [G loss: 0.067020]\n",
      "epoch1 step8730 [D loss: -0.098169] [G loss: -0.314939]\n",
      "epoch1 step8735 [D loss: 0.086830] [G loss: -0.189734]\n",
      "epoch1 step8740 [D loss: 0.022387] [G loss: -0.346882]\n",
      "epoch1 step8745 [D loss: -0.613769] [G loss: -0.241719]\n",
      "epoch1 step8750 [D loss: -0.227461] [G loss: -0.261776]\n",
      "epoch1 step8755 [D loss: -0.458711] [G loss: -0.069928]\n",
      "epoch1 step8760 [D loss: -0.484321] [G loss: 0.070442]\n",
      "epoch1 step8765 [D loss: 0.231745] [G loss: -0.209999]\n",
      "epoch1 step8770 [D loss: 0.229923] [G loss: -0.209842]\n",
      "epoch1 step8775 [D loss: -0.434457] [G loss: -0.209716]\n",
      "epoch1 step8780 [D loss: -0.164374] [G loss: 0.008440]\n",
      "epoch1 step8785 [D loss: -0.087474] [G loss: -0.109401]\n",
      "epoch1 step8790 [D loss: -0.238411] [G loss: -0.072992]\n",
      "epoch1 step8795 [D loss: -0.289128] [G loss: -0.191337]\n",
      "epoch1 step8800 [D loss: -0.134819] [G loss: 0.132240]\n",
      "epoch1 step8805 [D loss: -0.144819] [G loss: 0.059972]\n",
      "epoch1 step8810 [D loss: -0.506356] [G loss: 0.120339]\n",
      "epoch1 step8815 [D loss: -0.303824] [G loss: 0.226346]\n",
      "epoch1 step8820 [D loss: -0.089344] [G loss: 0.536198]\n",
      "epoch1 step8825 [D loss: -0.396302] [G loss: 0.356228]\n",
      "epoch1 step8830 [D loss: -0.340191] [G loss: 0.441110]\n",
      "epoch1 step8835 [D loss: -0.171353] [G loss: 0.184833]\n",
      "epoch1 step8840 [D loss: -0.417898] [G loss: 0.299456]\n",
      "epoch1 step8845 [D loss: 0.042494] [G loss: 0.567599]\n",
      "epoch1 step8850 [D loss: 0.131652] [G loss: 0.166113]\n",
      "epoch1 step8855 [D loss: 0.077971] [G loss: 0.485111]\n",
      "epoch1 step8860 [D loss: 0.280057] [G loss: -0.167366]\n",
      "epoch1 step8865 [D loss: -0.317536] [G loss: 0.047557]\n",
      "epoch1 step8870 [D loss: -0.337606] [G loss: 0.401624]\n",
      "epoch1 step8875 [D loss: -0.495750] [G loss: 0.531663]\n",
      "epoch1 step8880 [D loss: -0.062788] [G loss: 0.315414]\n",
      "epoch1 step8885 [D loss: -0.648420] [G loss: 0.003709]\n",
      "epoch1 step8890 [D loss: -0.368981] [G loss: 0.308455]\n",
      "epoch1 step8895 [D loss: -0.307656] [G loss: 0.184699]\n",
      "epoch1 step8900 [D loss: -0.147936] [G loss: -0.102877]\n",
      "epoch1 step8905 [D loss: -0.012605] [G loss: -0.096533]\n",
      "epoch1 step8910 [D loss: -0.174371] [G loss: -0.220176]\n",
      "epoch1 step8915 [D loss: -0.133228] [G loss: -0.025836]\n",
      "epoch1 step8920 [D loss: -0.433192] [G loss: -0.397879]\n",
      "epoch1 step8925 [D loss: 0.383013] [G loss: -0.185993]\n",
      "epoch1 step8930 [D loss: 0.266350] [G loss: 0.044900]\n",
      "epoch1 step8935 [D loss: -0.047355] [G loss: 0.046109]\n",
      "epoch1 step8940 [D loss: 0.166970] [G loss: 0.203965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step8945 [D loss: 0.091238] [G loss: -0.122638]\n",
      "epoch1 step8950 [D loss: -0.093836] [G loss: -0.177146]\n",
      "epoch1 step8955 [D loss: 0.231214] [G loss: 0.006482]\n",
      "epoch1 step8960 [D loss: -0.017997] [G loss: 0.270263]\n",
      "epoch1 step8965 [D loss: -0.392325] [G loss: 0.243251]\n",
      "epoch1 step8970 [D loss: 0.230841] [G loss: 0.163967]\n",
      "epoch1 step8975 [D loss: 0.166825] [G loss: 0.322588]\n",
      "epoch1 step8980 [D loss: -0.160921] [G loss: 0.083602]\n",
      "epoch1 step8985 [D loss: -0.115959] [G loss: 0.102656]\n",
      "epoch1 step8990 [D loss: -0.148289] [G loss: 0.118559]\n",
      "epoch1 step8995 [D loss: -0.056183] [G loss: 0.381457]\n",
      "epoch1 step9000 [D loss: -0.296450] [G loss: 0.219114]\n",
      "epoch1 step9005 [D loss: -0.134670] [G loss: -0.015798]\n",
      "epoch1 step9010 [D loss: -0.085003] [G loss: 0.384225]\n",
      "epoch1 step9015 [D loss: -0.636599] [G loss: 0.264357]\n",
      "epoch1 step9020 [D loss: -0.913792] [G loss: 0.011100]\n",
      "epoch1 step9025 [D loss: -0.246690] [G loss: 0.249076]\n",
      "epoch1 step9030 [D loss: -0.562148] [G loss: 0.074903]\n",
      "epoch1 step9035 [D loss: 0.290901] [G loss: -0.180408]\n",
      "epoch1 step9040 [D loss: -0.032263] [G loss: -0.100818]\n",
      "epoch1 step9045 [D loss: 0.311566] [G loss: -0.499254]\n",
      "epoch1 step9050 [D loss: -0.124103] [G loss: 0.056086]\n",
      "epoch1 step9055 [D loss: -0.177117] [G loss: 0.226175]\n",
      "epoch1 step9060 [D loss: -0.012579] [G loss: 0.069480]\n",
      "epoch1 step9065 [D loss: 0.139719] [G loss: -0.285657]\n",
      "epoch1 step9070 [D loss: -0.161953] [G loss: 0.165502]\n",
      "epoch1 step9075 [D loss: -0.016433] [G loss: 0.152925]\n",
      "epoch1 step9080 [D loss: -0.250045] [G loss: -0.143363]\n",
      "epoch1 step9085 [D loss: 0.115447] [G loss: -0.103358]\n",
      "epoch1 step9090 [D loss: -0.154709] [G loss: 0.117718]\n",
      "epoch1 step9095 [D loss: -0.132678] [G loss: 0.158492]\n",
      "epoch1 step9100 [D loss: -0.035022] [G loss: 0.149755]\n",
      "epoch1 step9105 [D loss: -0.274179] [G loss: 0.054875]\n",
      "epoch1 step9110 [D loss: 0.025995] [G loss: 0.108046]\n",
      "epoch1 step9115 [D loss: -0.283060] [G loss: 0.009799]\n",
      "epoch1 step9120 [D loss: 0.210225] [G loss: -0.084950]\n",
      "epoch1 step9125 [D loss: -0.081161] [G loss: 0.029366]\n",
      "epoch1 step9130 [D loss: -0.569811] [G loss: 0.121019]\n",
      "epoch1 step9135 [D loss: 0.194160] [G loss: 0.082086]\n",
      "epoch1 step9140 [D loss: -0.355756] [G loss: -0.289331]\n",
      "epoch1 step9145 [D loss: 0.376736] [G loss: -0.248705]\n",
      "epoch1 step9150 [D loss: -0.244907] [G loss: -0.089509]\n",
      "epoch1 step9155 [D loss: -0.599761] [G loss: -0.069505]\n",
      "epoch1 step9160 [D loss: -0.023305] [G loss: 0.025964]\n",
      "epoch1 step9165 [D loss: -0.433324] [G loss: -0.429762]\n",
      "epoch1 step9170 [D loss: -0.458596] [G loss: -0.685484]\n",
      "epoch1 step9175 [D loss: -0.287519] [G loss: -0.005927]\n",
      "epoch1 step9180 [D loss: 0.079028] [G loss: -0.194407]\n",
      "epoch1 step9185 [D loss: 0.117443] [G loss: -0.214147]\n",
      "epoch1 step9190 [D loss: -0.098655] [G loss: -0.133771]\n",
      "epoch1 step9195 [D loss: -0.314501] [G loss: -0.281348]\n",
      "epoch1 step9200 [D loss: 0.231986] [G loss: -0.413383]\n",
      "epoch1 step9205 [D loss: 0.442465] [G loss: -0.100699]\n",
      "epoch1 step9210 [D loss: 0.160433] [G loss: -0.463089]\n",
      "epoch1 step9215 [D loss: -0.062213] [G loss: -0.308909]\n",
      "epoch1 step9220 [D loss: -0.136641] [G loss: -0.400357]\n",
      "epoch1 step9225 [D loss: 0.089361] [G loss: -0.276532]\n",
      "epoch1 step9230 [D loss: -0.079091] [G loss: -0.262695]\n",
      "epoch1 step9235 [D loss: -0.110678] [G loss: -0.081486]\n",
      "epoch1 step9240 [D loss: 0.289781] [G loss: -0.213260]\n",
      "epoch1 step9245 [D loss: 0.078314] [G loss: -0.209960]\n",
      "epoch1 step9250 [D loss: 0.334173] [G loss: -0.162506]\n",
      "epoch1 step9255 [D loss: -0.029269] [G loss: -0.449818]\n",
      "epoch1 step9260 [D loss: -0.121804] [G loss: -0.071527]\n",
      "epoch1 step9265 [D loss: -0.193175] [G loss: -0.240486]\n",
      "epoch1 step9270 [D loss: -0.090822] [G loss: 0.060442]\n",
      "epoch1 step9275 [D loss: 0.051062] [G loss: -0.267427]\n",
      "epoch1 step9280 [D loss: 0.351498] [G loss: -0.456734]\n",
      "epoch1 step9285 [D loss: 0.195166] [G loss: -0.112090]\n",
      "epoch1 step9290 [D loss: 0.078197] [G loss: 0.002847]\n",
      "epoch1 step9295 [D loss: 0.048950] [G loss: 0.133113]\n",
      "epoch1 step9300 [D loss: 0.130454] [G loss: 0.127434]\n",
      "epoch1 step9305 [D loss: -0.061636] [G loss: 0.368230]\n",
      "epoch1 step9310 [D loss: -0.386908] [G loss: 0.304082]\n",
      "epoch1 step9315 [D loss: -0.472829] [G loss: 0.402475]\n",
      "epoch1 step9320 [D loss: -0.228718] [G loss: 0.097940]\n",
      "epoch1 step9325 [D loss: -0.731558] [G loss: 0.729588]\n",
      "epoch1 step9330 [D loss: -0.408097] [G loss: 0.514471]\n",
      "epoch1 step9335 [D loss: -0.104993] [G loss: 0.199712]\n",
      "epoch1 step9340 [D loss: -0.327920] [G loss: 0.440837]\n",
      "epoch1 step9345 [D loss: -0.416790] [G loss: 0.646427]\n",
      "epoch1 step9350 [D loss: -0.999867] [G loss: 0.614414]\n",
      "epoch1 step9355 [D loss: -0.258897] [G loss: 0.260424]\n",
      "epoch1 step9360 [D loss: -0.527313] [G loss: 0.588799]\n",
      "epoch1 step9365 [D loss: -0.371064] [G loss: 0.256950]\n",
      "epoch1 step9370 [D loss: -0.391510] [G loss: 0.483145]\n",
      "epoch1 step9375 [D loss: -0.031728] [G loss: 0.571142]\n",
      "epoch1 step9380 [D loss: -0.394391] [G loss: 0.705373]\n",
      "epoch1 step9385 [D loss: -0.262122] [G loss: 0.517004]\n",
      "epoch1 step9390 [D loss: 0.020612] [G loss: 0.457237]\n",
      "epoch1 step9395 [D loss: -0.124522] [G loss: 0.425591]\n",
      "epoch1 step9400 [D loss: -0.380311] [G loss: 0.587455]\n",
      "epoch1 step9405 [D loss: 0.142322] [G loss: 0.617661]\n",
      "epoch1 step9410 [D loss: -0.876479] [G loss: 0.907911]\n",
      "epoch1 step9415 [D loss: 0.237571] [G loss: 0.386078]\n",
      "epoch1 step9420 [D loss: -0.387189] [G loss: 0.224870]\n",
      "epoch1 step9425 [D loss: 0.177533] [G loss: 0.223625]\n",
      "epoch1 step9430 [D loss: -0.187776] [G loss: 0.259563]\n",
      "epoch1 step9435 [D loss: -0.350114] [G loss: 0.074246]\n",
      "epoch1 step9440 [D loss: -0.193063] [G loss: 0.379477]\n",
      "epoch1 step9445 [D loss: -0.028589] [G loss: 0.224660]\n",
      "epoch1 step9450 [D loss: -0.113471] [G loss: 0.179674]\n",
      "epoch1 step9455 [D loss: -0.149337] [G loss: 0.385644]\n",
      "epoch1 step9460 [D loss: 0.358055] [G loss: 0.258788]\n",
      "epoch1 step9465 [D loss: 0.230324] [G loss: -0.120629]\n",
      "epoch1 step9470 [D loss: 0.522744] [G loss: 0.106954]\n",
      "epoch1 step9475 [D loss: 0.032394] [G loss: 0.025245]\n",
      "epoch1 step9480 [D loss: -0.079856] [G loss: 0.196867]\n",
      "epoch1 step9485 [D loss: -0.093774] [G loss: 0.008693]\n",
      "epoch1 step9490 [D loss: -0.387268] [G loss: 0.238740]\n",
      "epoch1 step9495 [D loss: -0.083063] [G loss: 0.212029]\n",
      "epoch1 step9500 [D loss: -0.451474] [G loss: 0.418355]\n",
      "epoch1 step9505 [D loss: 0.327884] [G loss: -0.197232]\n",
      "epoch1 step9510 [D loss: -0.369416] [G loss: 0.166022]\n",
      "epoch1 step9515 [D loss: 0.208027] [G loss: 0.047980]\n",
      "epoch1 step9520 [D loss: -0.282950] [G loss: 0.273261]\n",
      "epoch1 step9525 [D loss: -0.025923] [G loss: 0.141255]\n",
      "epoch1 step9530 [D loss: -0.128028] [G loss: 0.371959]\n",
      "epoch1 step9535 [D loss: -0.235924] [G loss: 0.297809]\n",
      "epoch1 step9540 [D loss: 0.218970] [G loss: 0.285051]\n",
      "epoch1 step9545 [D loss: -0.002205] [G loss: 0.151809]\n",
      "epoch1 step9550 [D loss: -0.077197] [G loss: 0.353142]\n",
      "epoch1 step9555 [D loss: 0.381022] [G loss: 0.048888]\n",
      "epoch1 step9560 [D loss: 0.125869] [G loss: 0.152687]\n",
      "epoch1 step9565 [D loss: -0.080880] [G loss: 0.574555]\n",
      "epoch1 step9570 [D loss: -0.532777] [G loss: 0.305670]\n",
      "epoch1 step9575 [D loss: -0.423178] [G loss: 0.484046]\n",
      "epoch1 step9580 [D loss: -0.091861] [G loss: 0.387840]\n",
      "epoch1 step9585 [D loss: -0.151721] [G loss: 0.664989]\n",
      "epoch1 step9590 [D loss: -0.375066] [G loss: 0.517876]\n",
      "epoch1 step9595 [D loss: -0.835141] [G loss: 0.409954]\n",
      "epoch1 step9600 [D loss: -0.038834] [G loss: 0.063464]\n",
      "epoch1 step9605 [D loss: -0.156063] [G loss: -0.058713]\n",
      "epoch1 step9610 [D loss: 0.491734] [G loss: -0.266896]\n",
      "epoch1 step9615 [D loss: 0.299874] [G loss: 0.127889]\n",
      "epoch1 step9620 [D loss: -0.284397] [G loss: 0.161391]\n",
      "epoch1 step9625 [D loss: -0.069795] [G loss: 0.268843]\n",
      "epoch1 step9630 [D loss: -0.641289] [G loss: 0.123769]\n",
      "epoch1 step9635 [D loss: -0.362861] [G loss: 0.128823]\n",
      "epoch1 step9640 [D loss: 0.047417] [G loss: -0.231271]\n",
      "epoch1 step9645 [D loss: -0.240218] [G loss: -0.247214]\n",
      "epoch1 step9650 [D loss: -0.364442] [G loss: -0.292296]\n",
      "epoch1 step9655 [D loss: 0.298829] [G loss: -0.163149]\n",
      "epoch1 step9660 [D loss: 0.058159] [G loss: -0.205080]\n",
      "epoch1 step9665 [D loss: 0.141577] [G loss: -0.437314]\n",
      "epoch1 step9670 [D loss: 0.103962] [G loss: -0.440746]\n",
      "epoch1 step9675 [D loss: -0.193101] [G loss: -0.326556]\n",
      "epoch1 step9680 [D loss: 0.084563] [G loss: -0.570759]\n",
      "epoch1 step9685 [D loss: 0.160667] [G loss: -0.124025]\n",
      "epoch1 step9690 [D loss: 0.197976] [G loss: -0.634695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step9695 [D loss: 0.223626] [G loss: -0.465400]\n",
      "epoch1 step9700 [D loss: -0.008276] [G loss: -0.339854]\n",
      "epoch1 step9705 [D loss: 0.394283] [G loss: -0.160406]\n",
      "epoch1 step9710 [D loss: 0.218073] [G loss: -0.516750]\n",
      "epoch1 step9715 [D loss: 0.599400] [G loss: -0.427951]\n",
      "epoch1 step9720 [D loss: -0.199517] [G loss: -0.590253]\n",
      "epoch1 step9725 [D loss: 0.295872] [G loss: -0.229820]\n",
      "epoch1 step9730 [D loss: 0.089333] [G loss: -0.384933]\n",
      "epoch1 step9735 [D loss: 0.060792] [G loss: -0.471160]\n",
      "epoch1 step9740 [D loss: 0.195532] [G loss: -0.333054]\n",
      "epoch1 step9745 [D loss: 0.361291] [G loss: -0.147155]\n",
      "epoch1 step9750 [D loss: -0.465633] [G loss: -0.314656]\n",
      "epoch1 step9755 [D loss: -0.232215] [G loss: -0.604742]\n",
      "epoch1 step9760 [D loss: -0.296929] [G loss: -0.275197]\n",
      "epoch1 step9765 [D loss: 0.055413] [G loss: -0.665891]\n",
      "epoch1 step9770 [D loss: 0.173016] [G loss: -0.439224]\n",
      "epoch1 step9775 [D loss: -0.087675] [G loss: -0.246248]\n",
      "epoch1 step9780 [D loss: -0.228628] [G loss: -0.168516]\n",
      "epoch1 step9785 [D loss: 0.269798] [G loss: -0.427305]\n",
      "epoch1 step9790 [D loss: -0.332442] [G loss: 0.205005]\n",
      "epoch1 step9795 [D loss: -0.167407] [G loss: -0.300328]\n",
      "epoch1 step9800 [D loss: 0.078005] [G loss: 0.006343]\n",
      "epoch1 step9805 [D loss: 0.088187] [G loss: -0.167476]\n",
      "epoch1 step9810 [D loss: -0.381695] [G loss: -0.091910]\n",
      "epoch1 step9815 [D loss: -0.209056] [G loss: -0.132523]\n",
      "epoch1 step9820 [D loss: 0.070958] [G loss: -0.368035]\n",
      "epoch1 step9825 [D loss: -0.095718] [G loss: -0.110099]\n",
      "epoch1 step9830 [D loss: -0.433256] [G loss: -0.029226]\n",
      "epoch1 step9835 [D loss: -0.141289] [G loss: -0.082553]\n",
      "epoch1 step9840 [D loss: -0.068365] [G loss: -0.434977]\n",
      "epoch1 step9845 [D loss: 0.157201] [G loss: 0.070966]\n",
      "epoch1 step9850 [D loss: -0.014634] [G loss: -0.163826]\n",
      "epoch1 step9855 [D loss: 0.043523] [G loss: 0.272903]\n",
      "epoch1 step9860 [D loss: -0.303547] [G loss: 0.227952]\n",
      "epoch1 step9865 [D loss: -0.186409] [G loss: -0.299236]\n",
      "epoch1 step9870 [D loss: -0.040194] [G loss: 0.339299]\n",
      "epoch1 step9875 [D loss: -0.275812] [G loss: 0.356807]\n",
      "epoch1 step9880 [D loss: 0.546499] [G loss: 0.135711]\n",
      "epoch1 step9885 [D loss: 0.061626] [G loss: 0.295342]\n",
      "epoch1 step9890 [D loss: 0.168916] [G loss: 0.372334]\n",
      "epoch1 step9895 [D loss: -0.179962] [G loss: 0.319017]\n",
      "epoch1 step9900 [D loss: -0.149883] [G loss: 0.247587]\n",
      "epoch1 step9905 [D loss: 0.039366] [G loss: 0.414928]\n",
      "epoch1 step9910 [D loss: 0.188488] [G loss: 0.799876]\n",
      "epoch1 step9915 [D loss: 0.091036] [G loss: 0.331499]\n",
      "epoch1 step9920 [D loss: -0.086369] [G loss: 0.705025]\n",
      "epoch1 step9925 [D loss: 0.109356] [G loss: 0.705937]\n",
      "epoch1 step9930 [D loss: -0.524401] [G loss: 0.645621]\n",
      "epoch1 step9935 [D loss: 0.189490] [G loss: 0.442819]\n",
      "epoch1 step9940 [D loss: -0.065592] [G loss: 0.620733]\n",
      "epoch1 step9945 [D loss: -0.061778] [G loss: 0.473234]\n",
      "epoch1 step9950 [D loss: 0.035635] [G loss: 0.719000]\n",
      "epoch1 step9955 [D loss: -0.244592] [G loss: 0.732092]\n",
      "epoch1 step9960 [D loss: -0.417344] [G loss: 0.784816]\n",
      "epoch1 step9965 [D loss: -0.186243] [G loss: 0.978139]\n",
      "epoch1 step9970 [D loss: -0.380236] [G loss: 0.655135]\n",
      "epoch1 step9975 [D loss: 0.068973] [G loss: 0.528375]\n",
      "epoch1 step9980 [D loss: -0.413460] [G loss: 0.562831]\n",
      "epoch1 step9985 [D loss: 0.151527] [G loss: 0.381200]\n",
      "epoch1 step9990 [D loss: -0.349299] [G loss: 0.506061]\n",
      "epoch1 step9995 [D loss: -0.200307] [G loss: 0.539876]\n",
      "epoch1 step10000 [D loss: 0.619242] [G loss: 0.585957]\n",
      "epoch1 step10005 [D loss: 0.295410] [G loss: 0.491562]\n",
      "epoch1 step10010 [D loss: 0.187495] [G loss: 0.461939]\n",
      "epoch1 step10015 [D loss: -0.121979] [G loss: 0.647411]\n",
      "epoch1 step10020 [D loss: -0.453482] [G loss: 0.475219]\n",
      "epoch1 step10025 [D loss: 0.151992] [G loss: 0.520424]\n",
      "epoch1 step10030 [D loss: 0.333963] [G loss: 0.292904]\n",
      "epoch1 step10035 [D loss: -0.135648] [G loss: 0.168244]\n",
      "epoch1 step10040 [D loss: -0.189866] [G loss: 0.333004]\n",
      "epoch1 step10045 [D loss: 0.311741] [G loss: -0.127539]\n",
      "epoch1 step10050 [D loss: -0.280219] [G loss: 0.308737]\n",
      "epoch1 step10055 [D loss: -0.440077] [G loss: 0.568574]\n",
      "epoch1 step10060 [D loss: -0.181647] [G loss: 0.140850]\n",
      "epoch1 step10065 [D loss: -0.149888] [G loss: 0.319586]\n",
      "epoch1 step10070 [D loss: 0.109000] [G loss: 0.198447]\n",
      "epoch1 step10075 [D loss: 0.154769] [G loss: 0.367457]\n",
      "epoch1 step10080 [D loss: 0.112894] [G loss: 0.069105]\n",
      "epoch1 step10085 [D loss: 0.211466] [G loss: 0.038098]\n",
      "epoch1 step10090 [D loss: -0.317664] [G loss: 0.265909]\n",
      "epoch1 step10095 [D loss: -0.188771] [G loss: 0.107363]\n",
      "epoch1 step10100 [D loss: -0.095194] [G loss: 0.220705]\n",
      "epoch1 step10105 [D loss: 0.059844] [G loss: 0.436636]\n",
      "epoch1 step10110 [D loss: -0.542915] [G loss: 0.394773]\n",
      "epoch1 step10115 [D loss: -0.161127] [G loss: 0.053359]\n",
      "epoch1 step10120 [D loss: -0.291088] [G loss: 0.571163]\n",
      "epoch1 step10125 [D loss: -0.270107] [G loss: 0.456035]\n",
      "epoch1 step10130 [D loss: -0.373134] [G loss: 0.347771]\n",
      "epoch1 step10135 [D loss: -0.286320] [G loss: 0.339576]\n",
      "epoch1 step10140 [D loss: 0.097567] [G loss: 0.497878]\n",
      "epoch1 step10145 [D loss: -0.741076] [G loss: 0.297207]\n",
      "epoch1 step10150 [D loss: -0.106920] [G loss: 0.221998]\n",
      "epoch1 step10155 [D loss: -0.227522] [G loss: 0.567288]\n",
      "epoch1 step10160 [D loss: 0.152585] [G loss: 0.362846]\n",
      "epoch1 step10165 [D loss: -0.015481] [G loss: 0.286219]\n",
      "epoch1 step10170 [D loss: -0.123769] [G loss: 0.349608]\n",
      "epoch1 step10175 [D loss: 0.209334] [G loss: 0.240767]\n",
      "epoch1 step10180 [D loss: 0.100974] [G loss: 0.123672]\n",
      "epoch1 step10185 [D loss: -0.281158] [G loss: -0.028108]\n",
      "epoch1 step10190 [D loss: 0.105046] [G loss: 0.061218]\n",
      "epoch1 step10195 [D loss: -0.204752] [G loss: 0.400161]\n",
      "epoch1 step10200 [D loss: -0.108744] [G loss: 0.126411]\n",
      "epoch1 step10205 [D loss: 0.109838] [G loss: 0.379122]\n",
      "epoch1 step10210 [D loss: -0.370045] [G loss: 0.114721]\n",
      "epoch1 step10215 [D loss: -0.294382] [G loss: -0.081638]\n",
      "epoch1 step10220 [D loss: 0.124747] [G loss: 0.427462]\n",
      "epoch1 step10225 [D loss: -0.135495] [G loss: 0.282048]\n",
      "epoch1 step10230 [D loss: -0.098973] [G loss: -0.172696]\n",
      "epoch1 step10235 [D loss: -0.012278] [G loss: 0.226357]\n",
      "epoch1 step10240 [D loss: 0.233744] [G loss: 0.281286]\n",
      "epoch1 step10245 [D loss: -0.074418] [G loss: 0.094505]\n",
      "epoch1 step10250 [D loss: -0.402564] [G loss: 0.488962]\n",
      "epoch1 step10255 [D loss: -0.107270] [G loss: -0.021353]\n",
      "epoch1 step10260 [D loss: 0.254303] [G loss: 0.489237]\n",
      "epoch1 step10265 [D loss: -0.081979] [G loss: 0.154404]\n",
      "epoch1 step10270 [D loss: -0.043424] [G loss: 0.315988]\n",
      "epoch1 step10275 [D loss: -0.089194] [G loss: 0.565767]\n",
      "epoch1 step10280 [D loss: -0.203704] [G loss: 0.498043]\n",
      "epoch1 step10285 [D loss: 0.115853] [G loss: 0.184598]\n",
      "epoch1 step10290 [D loss: 0.073793] [G loss: 0.594667]\n",
      "epoch1 step10295 [D loss: 0.315087] [G loss: 0.274882]\n",
      "epoch1 step10300 [D loss: 0.065212] [G loss: 0.651291]\n",
      "epoch1 step10305 [D loss: -0.017167] [G loss: 0.719117]\n",
      "epoch1 step10310 [D loss: -0.145679] [G loss: 0.578877]\n",
      "epoch1 step10315 [D loss: -0.455035] [G loss: 0.556407]\n",
      "epoch1 step10320 [D loss: -0.296153] [G loss: 0.174234]\n",
      "epoch1 step10325 [D loss: -0.656900] [G loss: 0.569140]\n",
      "epoch1 step10330 [D loss: -0.114953] [G loss: 0.566027]\n",
      "epoch1 step10335 [D loss: -0.136515] [G loss: 0.656209]\n",
      "epoch1 step10340 [D loss: -0.439198] [G loss: 0.602801]\n",
      "epoch1 step10345 [D loss: 0.105534] [G loss: -0.027063]\n",
      "epoch1 step10350 [D loss: -0.203385] [G loss: 0.716426]\n",
      "epoch1 step10355 [D loss: -0.078374] [G loss: 0.546817]\n",
      "epoch1 step10360 [D loss: -0.276376] [G loss: 0.494992]\n",
      "epoch1 step10365 [D loss: 0.252022] [G loss: 0.322925]\n",
      "epoch1 step10370 [D loss: -0.224776] [G loss: 0.448416]\n",
      "epoch1 step10375 [D loss: -0.319853] [G loss: 0.511534]\n",
      "epoch1 step10380 [D loss: -0.003500] [G loss: 0.016907]\n",
      "epoch1 step10385 [D loss: -0.105785] [G loss: 0.527161]\n",
      "epoch1 step10390 [D loss: -0.341391] [G loss: 0.238108]\n",
      "epoch1 step10395 [D loss: 0.431947] [G loss: 0.468552]\n",
      "epoch1 step10400 [D loss: 0.320416] [G loss: 0.476582]\n",
      "epoch1 step10405 [D loss: 0.250747] [G loss: 0.523217]\n",
      "epoch1 step10410 [D loss: 0.094042] [G loss: 0.379047]\n",
      "epoch1 step10415 [D loss: 0.290146] [G loss: 0.626199]\n",
      "epoch1 step10420 [D loss: -0.238169] [G loss: 0.499273]\n",
      "epoch1 step10425 [D loss: -0.393204] [G loss: 0.203629]\n",
      "epoch1 step10430 [D loss: 0.316122] [G loss: 0.360657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step10435 [D loss: -0.359355] [G loss: 0.631212]\n",
      "epoch1 step10440 [D loss: 0.218397] [G loss: 0.303617]\n",
      "epoch1 step10445 [D loss: -0.225797] [G loss: 0.635032]\n",
      "epoch1 step10450 [D loss: 0.001089] [G loss: 0.390198]\n",
      "epoch1 step10455 [D loss: -0.160046] [G loss: 0.303515]\n",
      "epoch1 step10460 [D loss: 0.038889] [G loss: 0.340164]\n",
      "epoch1 step10465 [D loss: 0.022088] [G loss: -0.037280]\n",
      "epoch1 step10470 [D loss: -0.100979] [G loss: 0.175457]\n",
      "epoch1 step10475 [D loss: -0.164648] [G loss: 0.072913]\n",
      "epoch1 step10480 [D loss: -0.014782] [G loss: 0.157876]\n",
      "epoch1 step10485 [D loss: -0.108585] [G loss: -0.101924]\n",
      "epoch1 step10490 [D loss: 0.180084] [G loss: -0.186166]\n",
      "epoch1 step10495 [D loss: -0.030482] [G loss: -0.284638]\n",
      "epoch1 step10500 [D loss: 0.029952] [G loss: -0.006108]\n",
      "epoch1 step10505 [D loss: -0.213767] [G loss: -0.124400]\n",
      "epoch1 step10510 [D loss: -0.432139] [G loss: 0.075621]\n",
      "epoch1 step10515 [D loss: -0.406087] [G loss: 0.217530]\n",
      "epoch1 step10520 [D loss: 0.190867] [G loss: -0.360101]\n",
      "epoch1 step10525 [D loss: -0.051670] [G loss: -0.186525]\n",
      "epoch1 step10530 [D loss: 0.212710] [G loss: -0.015581]\n",
      "epoch1 step10535 [D loss: -0.325110] [G loss: -0.643339]\n",
      "epoch1 step10540 [D loss: 0.103162] [G loss: -0.291693]\n",
      "epoch1 step10545 [D loss: 0.007724] [G loss: -0.368327]\n",
      "epoch1 step10550 [D loss: 0.197203] [G loss: 0.159010]\n",
      "epoch1 step10555 [D loss: -0.210906] [G loss: -0.085869]\n",
      "epoch1 step10560 [D loss: -0.447182] [G loss: 0.138027]\n",
      "epoch1 step10565 [D loss: 0.088194] [G loss: -0.452112]\n",
      "epoch1 step10570 [D loss: 0.011817] [G loss: -0.343319]\n",
      "epoch1 step10575 [D loss: -0.488198] [G loss: -0.065083]\n",
      "epoch1 step10580 [D loss: 0.268329] [G loss: -0.297010]\n",
      "epoch1 step10585 [D loss: -0.029537] [G loss: -0.158528]\n",
      "epoch1 step10590 [D loss: 0.095511] [G loss: -0.285770]\n",
      "epoch1 step10595 [D loss: 0.152464] [G loss: -0.282485]\n",
      "epoch1 step10600 [D loss: -0.125483] [G loss: -0.194980]\n",
      "epoch1 step10605 [D loss: 0.294088] [G loss: -0.286829]\n",
      "epoch1 step10610 [D loss: 0.079459] [G loss: -0.419570]\n",
      "epoch1 step10615 [D loss: 0.187308] [G loss: -0.071635]\n",
      "epoch1 step10620 [D loss: -0.335197] [G loss: 0.020126]\n",
      "epoch1 step10625 [D loss: -0.089221] [G loss: -0.257091]\n",
      "epoch1 step10630 [D loss: 0.190248] [G loss: -0.252169]\n",
      "epoch1 step10635 [D loss: 0.270791] [G loss: -0.113932]\n",
      "epoch1 step10640 [D loss: -0.380448] [G loss: -0.022339]\n",
      "epoch1 step10645 [D loss: -0.104653] [G loss: 0.142910]\n",
      "epoch1 step10650 [D loss: -0.452090] [G loss: -0.076752]\n",
      "epoch1 step10655 [D loss: -0.760685] [G loss: 0.028454]\n",
      "epoch1 step10660 [D loss: -0.000634] [G loss: -0.103993]\n",
      "epoch1 step10665 [D loss: -0.067022] [G loss: -0.274993]\n",
      "epoch1 step10670 [D loss: 0.152643] [G loss: -0.237588]\n",
      "epoch1 step10675 [D loss: -0.285511] [G loss: -0.064224]\n",
      "epoch1 step10680 [D loss: -0.249003] [G loss: 0.116130]\n",
      "epoch1 step10685 [D loss: 0.010010] [G loss: 0.475582]\n",
      "epoch1 step10690 [D loss: 0.044106] [G loss: 0.193895]\n",
      "epoch1 step10695 [D loss: -0.300503] [G loss: 0.226497]\n",
      "epoch1 step10700 [D loss: -0.558168] [G loss: 0.166968]\n",
      "epoch1 step10705 [D loss: 0.100058] [G loss: 0.275737]\n",
      "epoch1 step10710 [D loss: 0.239259] [G loss: 0.434703]\n",
      "epoch1 step10715 [D loss: -0.134045] [G loss: 0.230824]\n",
      "epoch1 step10720 [D loss: -0.277513] [G loss: 0.472232]\n",
      "epoch1 step10725 [D loss: -0.599046] [G loss: 0.043239]\n",
      "epoch1 step10730 [D loss: 0.085950] [G loss: 0.044163]\n",
      "epoch1 step10735 [D loss: -0.147741] [G loss: 0.016163]\n",
      "epoch1 step10740 [D loss: 0.472137] [G loss: 0.157602]\n",
      "epoch1 step10745 [D loss: 0.175747] [G loss: 0.188806]\n",
      "epoch1 step10750 [D loss: -0.201211] [G loss: 0.423692]\n",
      "epoch1 step10755 [D loss: -0.038639] [G loss: 0.615267]\n",
      "epoch1 step10760 [D loss: -0.385114] [G loss: 0.415356]\n",
      "epoch1 step10765 [D loss: -0.258703] [G loss: 0.454238]\n",
      "epoch1 step10770 [D loss: -0.314427] [G loss: 0.859151]\n",
      "epoch1 step10775 [D loss: -0.181227] [G loss: 0.739611]\n",
      "epoch1 step10780 [D loss: -0.257484] [G loss: 0.362472]\n",
      "epoch1 step10785 [D loss: 0.000460] [G loss: 0.011821]\n",
      "epoch1 step10790 [D loss: 0.165710] [G loss: 0.054625]\n",
      "epoch1 step10795 [D loss: 0.006074] [G loss: 0.129681]\n",
      "epoch1 step10800 [D loss: 0.662794] [G loss: 0.013514]\n",
      "epoch1 step10805 [D loss: -0.105707] [G loss: 0.160055]\n",
      "epoch1 step10810 [D loss: -0.126450] [G loss: 0.165442]\n",
      "epoch1 step10815 [D loss: 0.451600] [G loss: 0.226600]\n",
      "epoch1 step10820 [D loss: 0.092728] [G loss: -0.355925]\n",
      "epoch1 step10825 [D loss: -0.058384] [G loss: 0.227076]\n",
      "epoch1 step10830 [D loss: 0.232181] [G loss: -0.051316]\n",
      "epoch1 step10835 [D loss: -0.167508] [G loss: 0.486317]\n",
      "epoch1 step10840 [D loss: 0.132384] [G loss: 0.031560]\n",
      "epoch1 step10845 [D loss: -0.506215] [G loss: 0.099701]\n",
      "epoch1 step10850 [D loss: -0.482897] [G loss: 0.083162]\n",
      "epoch1 step10855 [D loss: -0.145772] [G loss: 0.324018]\n",
      "epoch1 step10860 [D loss: 0.218645] [G loss: -0.220438]\n",
      "epoch1 step10865 [D loss: -0.181460] [G loss: 0.345332]\n",
      "epoch1 step10870 [D loss: 0.108189] [G loss: -0.353213]\n",
      "epoch1 step10875 [D loss: -0.203321] [G loss: 0.033851]\n",
      "epoch1 step10880 [D loss: 0.321236] [G loss: -0.371787]\n",
      "epoch1 step10885 [D loss: -0.134060] [G loss: 0.154869]\n",
      "epoch1 step10890 [D loss: -0.003559] [G loss: -0.142125]\n",
      "epoch1 step10895 [D loss: -0.606191] [G loss: -0.061676]\n",
      "epoch1 step10900 [D loss: -0.360048] [G loss: 0.149666]\n",
      "epoch1 step10905 [D loss: -0.086324] [G loss: -0.158668]\n",
      "epoch1 step10910 [D loss: -0.563730] [G loss: -0.095343]\n",
      "epoch1 step10915 [D loss: 0.026465] [G loss: 0.000672]\n",
      "epoch1 step10920 [D loss: 0.363363] [G loss: -0.358202]\n",
      "epoch1 step10925 [D loss: 0.209694] [G loss: -0.027650]\n",
      "epoch1 step10930 [D loss: -0.018892] [G loss: 0.048203]\n",
      "epoch1 step10935 [D loss: -0.073975] [G loss: 0.279403]\n",
      "epoch1 step10940 [D loss: -0.545609] [G loss: -0.047286]\n",
      "epoch1 step10945 [D loss: 0.255412] [G loss: 0.060125]\n",
      "epoch1 step10950 [D loss: 0.221938] [G loss: -0.061870]\n",
      "epoch1 step10955 [D loss: -0.218616] [G loss: 0.489235]\n",
      "epoch1 step10960 [D loss: -0.306366] [G loss: 0.388665]\n",
      "epoch1 step10965 [D loss: -0.097880] [G loss: 0.701982]\n",
      "epoch1 step10970 [D loss: 0.061426] [G loss: 0.157720]\n",
      "epoch1 step10975 [D loss: -0.256124] [G loss: 0.576672]\n",
      "epoch1 step10980 [D loss: -0.139299] [G loss: 0.575752]\n",
      "epoch1 step10985 [D loss: -0.411959] [G loss: 0.396249]\n",
      "epoch1 step10990 [D loss: 0.054874] [G loss: 0.567888]\n",
      "epoch1 step10995 [D loss: 0.217981] [G loss: 0.589310]\n",
      "epoch1 step11000 [D loss: 0.050348] [G loss: 0.499713]\n",
      "epoch1 step11005 [D loss: -0.133330] [G loss: 0.619501]\n",
      "epoch1 step11010 [D loss: 0.080225] [G loss: 0.652447]\n",
      "epoch1 step11015 [D loss: 0.072060] [G loss: 0.679884]\n",
      "epoch1 step11020 [D loss: -0.451631] [G loss: 0.961174]\n",
      "epoch1 step11025 [D loss: 0.384268] [G loss: 0.614136]\n",
      "epoch1 step11030 [D loss: -0.282478] [G loss: 0.693171]\n",
      "epoch1 step11035 [D loss: -0.499059] [G loss: 0.902334]\n",
      "epoch1 step11040 [D loss: 0.224124] [G loss: 0.842172]\n",
      "epoch1 step11045 [D loss: -0.507772] [G loss: 1.195528]\n",
      "epoch1 step11050 [D loss: 0.353703] [G loss: 0.793626]\n",
      "epoch1 step11055 [D loss: -0.083243] [G loss: 1.135816]\n",
      "epoch1 step11060 [D loss: -0.111140] [G loss: 1.070726]\n",
      "epoch1 step11065 [D loss: 0.075961] [G loss: 0.764105]\n",
      "epoch1 step11070 [D loss: -0.221874] [G loss: 0.709348]\n",
      "epoch1 step11075 [D loss: -0.316839] [G loss: 1.034675]\n",
      "epoch1 step11080 [D loss: 0.207941] [G loss: 0.881885]\n",
      "epoch1 step11085 [D loss: 0.403584] [G loss: 0.781064]\n",
      "epoch1 step11090 [D loss: -0.329741] [G loss: 1.240773]\n",
      "epoch1 step11095 [D loss: -0.079546] [G loss: 0.914421]\n",
      "epoch1 step11100 [D loss: -0.324229] [G loss: 0.850646]\n",
      "epoch1 step11105 [D loss: 0.239059] [G loss: 0.598693]\n",
      "epoch1 step11110 [D loss: 0.044838] [G loss: 0.860278]\n",
      "epoch1 step11115 [D loss: -0.056931] [G loss: 0.747855]\n",
      "epoch1 step11120 [D loss: -0.321542] [G loss: 0.831550]\n",
      "epoch1 step11125 [D loss: 0.061011] [G loss: 0.702133]\n",
      "epoch1 step11130 [D loss: 0.381814] [G loss: 0.588482]\n",
      "epoch1 step11135 [D loss: -0.033230] [G loss: 0.433368]\n",
      "epoch1 step11140 [D loss: -0.327598] [G loss: 0.893653]\n",
      "epoch1 step11145 [D loss: -0.006407] [G loss: 0.755648]\n",
      "epoch1 step11150 [D loss: -0.067558] [G loss: 0.875919]\n",
      "epoch1 step11155 [D loss: -0.430035] [G loss: 0.814900]\n",
      "epoch1 step11160 [D loss: -0.269619] [G loss: 0.584010]\n",
      "epoch1 step11165 [D loss: 0.423579] [G loss: 0.746701]\n",
      "epoch1 step11170 [D loss: -0.214676] [G loss: 0.591962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step11175 [D loss: -0.200207] [G loss: 0.687563]\n",
      "epoch1 step11180 [D loss: -0.440985] [G loss: 0.532723]\n",
      "epoch1 step11185 [D loss: 0.759753] [G loss: 0.470516]\n",
      "epoch1 step11190 [D loss: 0.055857] [G loss: 0.185114]\n",
      "epoch1 step11195 [D loss: -0.230807] [G loss: 0.645355]\n",
      "epoch1 step11200 [D loss: -0.472232] [G loss: 0.478953]\n",
      "epoch1 step11205 [D loss: -0.437323] [G loss: 0.391967]\n",
      "epoch1 step11210 [D loss: -0.188804] [G loss: 0.411917]\n",
      "epoch1 step11215 [D loss: 0.109425] [G loss: 0.066749]\n",
      "epoch1 step11220 [D loss: 0.059192] [G loss: 0.369758]\n",
      "epoch1 step11225 [D loss: -0.181839] [G loss: 0.242964]\n",
      "epoch1 step11230 [D loss: -0.205926] [G loss: 0.362205]\n",
      "epoch1 step11235 [D loss: 0.645394] [G loss: 0.125419]\n",
      "epoch1 step11240 [D loss: -0.276848] [G loss: 0.227021]\n",
      "epoch1 step11245 [D loss: 0.139968] [G loss: 0.257481]\n",
      "epoch1 step11250 [D loss: -0.096808] [G loss: 0.348555]\n",
      "epoch1 step11255 [D loss: -0.443122] [G loss: 0.574144]\n",
      "epoch1 step11260 [D loss: -0.098873] [G loss: 0.334440]\n",
      "epoch1 step11265 [D loss: -0.565191] [G loss: 0.619116]\n",
      "epoch1 step11270 [D loss: 0.001397] [G loss: 0.254230]\n",
      "epoch1 step11275 [D loss: -0.121643] [G loss: 0.320006]\n",
      "epoch1 step11280 [D loss: 0.195983] [G loss: 0.476318]\n",
      "epoch1 step11285 [D loss: 0.179237] [G loss: 0.113337]\n",
      "epoch1 step11290 [D loss: 0.294862] [G loss: 0.286529]\n",
      "epoch1 step11295 [D loss: 0.053049] [G loss: 0.335010]\n",
      "epoch1 step11300 [D loss: -0.233205] [G loss: 0.625403]\n",
      "epoch1 step11305 [D loss: -0.380051] [G loss: 0.505961]\n",
      "epoch1 step11310 [D loss: -0.141682] [G loss: 0.354772]\n",
      "epoch1 step11315 [D loss: -0.010630] [G loss: 0.626551]\n",
      "epoch1 step11320 [D loss: 0.313474] [G loss: 0.293356]\n",
      "epoch1 step11325 [D loss: 0.055624] [G loss: 0.141661]\n",
      "epoch1 step11330 [D loss: 0.058022] [G loss: -0.025673]\n",
      "epoch1 step11335 [D loss: 0.255130] [G loss: 0.060234]\n",
      "epoch1 step11340 [D loss: -0.130447] [G loss: 0.262530]\n",
      "epoch1 step11345 [D loss: 0.208836] [G loss: 0.219034]\n",
      "epoch1 step11350 [D loss: -0.075272] [G loss: -0.178380]\n",
      "epoch1 step11355 [D loss: 0.007765] [G loss: 0.223375]\n",
      "epoch1 step11360 [D loss: -0.041642] [G loss: 0.234188]\n",
      "epoch1 step11365 [D loss: 0.207070] [G loss: -0.281772]\n",
      "epoch1 step11370 [D loss: -0.231099] [G loss: 0.059236]\n",
      "epoch1 step11375 [D loss: 0.102117] [G loss: 0.121349]\n",
      "epoch1 step11380 [D loss: -0.178405] [G loss: -0.091943]\n",
      "epoch1 step11385 [D loss: -0.029058] [G loss: -0.246046]\n",
      "epoch1 step11390 [D loss: -0.075140] [G loss: 0.041221]\n",
      "epoch1 step11395 [D loss: -0.053595] [G loss: -0.134883]\n",
      "epoch1 step11400 [D loss: -0.123784] [G loss: 0.015535]\n",
      "epoch1 step11405 [D loss: -0.067131] [G loss: 0.072953]\n",
      "epoch1 step11410 [D loss: 0.104111] [G loss: 0.043405]\n",
      "epoch1 step11415 [D loss: -0.243391] [G loss: -0.074088]\n",
      "epoch1 step11420 [D loss: -0.089887] [G loss: -0.172187]\n",
      "epoch1 step11425 [D loss: -0.217627] [G loss: -0.267786]\n",
      "epoch1 step11430 [D loss: -0.198415] [G loss: -0.269602]\n",
      "epoch1 step11435 [D loss: -0.521963] [G loss: -0.016921]\n",
      "epoch1 step11440 [D loss: -0.068356] [G loss: -0.185936]\n",
      "epoch1 step11445 [D loss: -0.058380] [G loss: -0.131878]\n",
      "epoch1 step11450 [D loss: -0.222075] [G loss: -0.407029]\n",
      "epoch1 step11455 [D loss: -0.523225] [G loss: -0.107561]\n",
      "epoch1 step11460 [D loss: -0.175384] [G loss: -0.252476]\n",
      "epoch1 step11465 [D loss: 0.028118] [G loss: -0.205171]\n",
      "epoch1 step11470 [D loss: 0.184664] [G loss: -0.271149]\n",
      "epoch1 step11475 [D loss: -0.058553] [G loss: -0.184977]\n",
      "epoch1 step11480 [D loss: 0.050374] [G loss: -0.212333]\n",
      "epoch1 step11485 [D loss: 0.279047] [G loss: -0.276063]\n",
      "epoch1 step11490 [D loss: 0.010295] [G loss: -0.140877]\n",
      "epoch1 step11495 [D loss: -0.186671] [G loss: -0.150807]\n",
      "epoch1 step11500 [D loss: 0.110634] [G loss: 0.223297]\n",
      "epoch1 step11505 [D loss: 0.347037] [G loss: 0.074713]\n",
      "epoch1 step11510 [D loss: -0.056244] [G loss: -0.005904]\n",
      "epoch1 step11515 [D loss: -0.110745] [G loss: -0.297247]\n",
      "epoch1 step11520 [D loss: -0.014296] [G loss: 0.002849]\n",
      "epoch1 step11525 [D loss: 0.061822] [G loss: 0.074322]\n",
      "epoch1 step11530 [D loss: 0.240044] [G loss: -0.309689]\n",
      "epoch1 step11535 [D loss: -0.584822] [G loss: 0.428628]\n",
      "epoch1 step11540 [D loss: -0.200062] [G loss: 0.062677]\n",
      "epoch1 step11545 [D loss: -0.062134] [G loss: 0.288011]\n",
      "epoch1 step11550 [D loss: 0.071025] [G loss: 0.010395]\n",
      "epoch1 step11555 [D loss: -0.319675] [G loss: 0.703107]\n",
      "epoch1 step11560 [D loss: 0.146992] [G loss: 0.174320]\n",
      "epoch1 step11565 [D loss: -0.041832] [G loss: 0.202550]\n",
      "epoch1 step11570 [D loss: 0.080463] [G loss: 0.236925]\n",
      "epoch1 step11575 [D loss: -0.229528] [G loss: 0.262036]\n",
      "epoch1 step11580 [D loss: -0.154124] [G loss: 0.101951]\n",
      "epoch1 step11585 [D loss: 0.200245] [G loss: 0.532012]\n",
      "epoch1 step11590 [D loss: -0.098353] [G loss: 0.347345]\n",
      "epoch1 step11595 [D loss: -0.196770] [G loss: 0.449073]\n",
      "epoch1 step11600 [D loss: 0.247288] [G loss: -0.035125]\n",
      "epoch1 step11605 [D loss: 0.505401] [G loss: 0.250501]\n",
      "epoch1 step11610 [D loss: -0.125244] [G loss: 0.332619]\n",
      "epoch1 step11615 [D loss: -0.101352] [G loss: 0.699448]\n",
      "epoch1 step11620 [D loss: -0.353655] [G loss: 0.425826]\n",
      "epoch1 step11625 [D loss: 0.159939] [G loss: 0.426789]\n",
      "epoch1 step11630 [D loss: -0.561720] [G loss: 0.363202]\n",
      "epoch1 step11635 [D loss: 0.392747] [G loss: 0.466575]\n",
      "epoch1 step11640 [D loss: -0.514512] [G loss: 0.564572]\n",
      "epoch1 step11645 [D loss: 0.137862] [G loss: 0.409440]\n",
      "epoch1 step11650 [D loss: 0.090253] [G loss: 0.471848]\n",
      "epoch1 step11655 [D loss: -0.185457] [G loss: 0.467744]\n",
      "epoch1 step11660 [D loss: 0.065896] [G loss: 0.390147]\n",
      "epoch1 step11665 [D loss: -0.256475] [G loss: 0.537282]\n",
      "epoch1 step11670 [D loss: -0.451921] [G loss: 0.703683]\n",
      "epoch1 step11675 [D loss: -0.004755] [G loss: 0.414315]\n",
      "epoch1 step11680 [D loss: -0.123608] [G loss: 0.572334]\n",
      "epoch1 step11685 [D loss: 0.151304] [G loss: 0.766892]\n",
      "epoch1 step11690 [D loss: 0.275303] [G loss: 0.511283]\n",
      "epoch1 step11695 [D loss: 0.027843] [G loss: 0.626237]\n",
      "epoch1 step11700 [D loss: 0.007761] [G loss: 0.278688]\n",
      "epoch1 step11705 [D loss: 0.341008] [G loss: 0.694454]\n",
      "epoch1 step11710 [D loss: -0.193214] [G loss: 0.590007]\n",
      "epoch1 step11715 [D loss: -0.276294] [G loss: 0.626005]\n",
      "epoch1 step11720 [D loss: -0.032421] [G loss: 0.170404]\n",
      "epoch1 step11725 [D loss: -0.158725] [G loss: 0.554651]\n",
      "epoch1 step11730 [D loss: -0.247932] [G loss: 0.381277]\n",
      "epoch1 step11735 [D loss: -0.169959] [G loss: 0.666086]\n",
      "epoch1 step11740 [D loss: 0.095266] [G loss: 0.176793]\n",
      "epoch1 step11745 [D loss: 0.086263] [G loss: 0.381683]\n",
      "epoch1 step11750 [D loss: -0.052650] [G loss: 0.175056]\n",
      "epoch1 step11755 [D loss: 0.009149] [G loss: 0.356037]\n",
      "epoch1 step11760 [D loss: 0.171334] [G loss: -0.040000]\n",
      "epoch1 step11765 [D loss: -0.162751] [G loss: 0.524965]\n",
      "epoch1 step11770 [D loss: -0.217489] [G loss: 0.321006]\n",
      "epoch1 step11775 [D loss: -0.055434] [G loss: 0.288037]\n",
      "epoch1 step11780 [D loss: 0.222714] [G loss: 0.241108]\n",
      "epoch1 step11785 [D loss: 0.021213] [G loss: 0.167967]\n",
      "epoch1 step11790 [D loss: -0.208695] [G loss: 0.135719]\n",
      "epoch1 step11795 [D loss: -0.427209] [G loss: 0.359336]\n",
      "epoch1 step11800 [D loss: -0.256160] [G loss: -0.074189]\n",
      "epoch1 step11805 [D loss: -0.073666] [G loss: 0.172780]\n",
      "epoch1 step11810 [D loss: 0.285127] [G loss: 0.430811]\n",
      "epoch1 step11815 [D loss: -0.350700] [G loss: 0.123276]\n",
      "epoch1 step11820 [D loss: 0.053196] [G loss: 0.167411]\n",
      "epoch1 step11825 [D loss: 0.078706] [G loss: -0.026453]\n",
      "epoch1 step11830 [D loss: -0.149102] [G loss: 0.196499]\n",
      "epoch1 step11835 [D loss: 0.071826] [G loss: 0.020838]\n",
      "epoch1 step11840 [D loss: 0.266566] [G loss: 0.057638]\n",
      "epoch1 step11845 [D loss: -0.167671] [G loss: 0.044088]\n",
      "epoch1 step11850 [D loss: 0.284936] [G loss: 0.158523]\n",
      "epoch1 step11855 [D loss: 0.163173] [G loss: 0.134925]\n",
      "epoch1 step11860 [D loss: -0.260732] [G loss: 0.164868]\n",
      "epoch1 step11865 [D loss: -0.263817] [G loss: 0.575670]\n",
      "epoch1 step11870 [D loss: 0.126662] [G loss: 0.433584]\n",
      "epoch1 step11875 [D loss: 0.119334] [G loss: 0.176911]\n",
      "epoch1 step11880 [D loss: -0.051227] [G loss: 0.282484]\n",
      "epoch1 step11885 [D loss: -0.282566] [G loss: 0.191403]\n",
      "epoch1 step11890 [D loss: -0.462061] [G loss: 0.185205]\n",
      "epoch1 step11895 [D loss: 0.006100] [G loss: 0.228966]\n",
      "epoch1 step11900 [D loss: 0.098645] [G loss: 0.138276]\n",
      "epoch1 step11905 [D loss: -0.197555] [G loss: 0.318779]\n",
      "epoch1 step11910 [D loss: -0.400621] [G loss: 0.105952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step11915 [D loss: -0.169862] [G loss: 0.695388]\n",
      "epoch1 step11920 [D loss: -0.038537] [G loss: 0.363125]\n",
      "epoch1 step11925 [D loss: -0.379986] [G loss: 0.395783]\n",
      "epoch1 step11930 [D loss: -0.244927] [G loss: 0.349663]\n",
      "epoch1 step11935 [D loss: 0.316746] [G loss: 0.183834]\n",
      "epoch1 step11940 [D loss: 0.118016] [G loss: 0.356261]\n",
      "epoch1 step11945 [D loss: -0.486341] [G loss: 0.157343]\n",
      "epoch1 step11950 [D loss: -0.089848] [G loss: 0.439586]\n",
      "epoch1 step11955 [D loss: -0.668231] [G loss: 0.430424]\n",
      "epoch1 step11960 [D loss: -0.150993] [G loss: 0.361301]\n",
      "epoch1 step11965 [D loss: 0.404255] [G loss: 0.251383]\n",
      "epoch1 step11970 [D loss: -0.139913] [G loss: 0.470203]\n",
      "epoch1 step11975 [D loss: -0.268001] [G loss: -0.077815]\n",
      "epoch1 step11980 [D loss: 0.183590] [G loss: 0.312270]\n",
      "epoch1 step11985 [D loss: -0.105073] [G loss: 0.371153]\n",
      "epoch1 step11990 [D loss: 0.031888] [G loss: 0.292621]\n",
      "epoch1 step11995 [D loss: -0.332709] [G loss: 0.060121]\n",
      "epoch1 step12000 [D loss: 0.002106] [G loss: 0.334716]\n",
      "epoch1 step12005 [D loss: -0.093791] [G loss: 0.321051]\n",
      "epoch1 step12010 [D loss: -0.075555] [G loss: 0.172748]\n",
      "epoch1 step12015 [D loss: -0.223541] [G loss: 0.257556]\n",
      "epoch1 step12020 [D loss: 0.279764] [G loss: 0.437270]\n",
      "epoch1 step12025 [D loss: 0.098125] [G loss: 0.262323]\n",
      "epoch1 step12030 [D loss: -0.101621] [G loss: 0.324862]\n",
      "epoch1 step12035 [D loss: 0.291131] [G loss: 0.430373]\n",
      "epoch1 step12040 [D loss: -0.107928] [G loss: 0.596103]\n",
      "epoch1 step12045 [D loss: -0.065205] [G loss: 0.433109]\n",
      "epoch1 step12050 [D loss: 0.245984] [G loss: 0.424562]\n",
      "epoch1 step12055 [D loss: -0.395146] [G loss: 0.355706]\n",
      "epoch1 step12060 [D loss: -0.090685] [G loss: 0.330152]\n",
      "epoch1 step12065 [D loss: 0.190956] [G loss: 0.689122]\n",
      "epoch1 step12070 [D loss: -0.064044] [G loss: 0.331195]\n",
      "epoch1 step12075 [D loss: 0.065486] [G loss: 0.461189]\n",
      "epoch1 step12080 [D loss: 0.224792] [G loss: 0.595060]\n",
      "epoch1 step12085 [D loss: 0.102958] [G loss: 0.560896]\n",
      "epoch1 step12090 [D loss: -0.605393] [G loss: 0.652094]\n",
      "epoch1 step12095 [D loss: -0.080488] [G loss: 0.447821]\n",
      "epoch1 step12100 [D loss: 0.161161] [G loss: 0.799090]\n",
      "epoch1 step12105 [D loss: 0.134690] [G loss: 0.543740]\n",
      "epoch1 step12110 [D loss: -0.343049] [G loss: 0.675756]\n",
      "epoch1 step12115 [D loss: -0.218218] [G loss: 0.591076]\n",
      "epoch1 step12120 [D loss: -0.003584] [G loss: 0.332977]\n",
      "epoch1 step12125 [D loss: -0.564559] [G loss: 0.466488]\n",
      "epoch1 step12130 [D loss: -0.138668] [G loss: 0.488951]\n",
      "epoch1 step12135 [D loss: -0.104214] [G loss: 0.622077]\n",
      "epoch1 step12140 [D loss: 0.186687] [G loss: 0.645251]\n",
      "epoch1 step12145 [D loss: 0.167457] [G loss: 0.838574]\n",
      "epoch1 step12150 [D loss: -0.137924] [G loss: 0.880263]\n",
      "epoch1 step12155 [D loss: 0.384145] [G loss: 0.585155]\n",
      "epoch1 step12160 [D loss: -0.299390] [G loss: 0.918625]\n",
      "epoch1 step12165 [D loss: -0.207391] [G loss: 0.969036]\n",
      "epoch1 step12170 [D loss: -0.012022] [G loss: 0.981532]\n",
      "epoch1 step12175 [D loss: -0.009276] [G loss: 0.891554]\n",
      "epoch1 step12180 [D loss: 0.412499] [G loss: 0.587816]\n",
      "epoch1 step12185 [D loss: 0.348623] [G loss: 0.612002]\n",
      "epoch1 step12190 [D loss: -0.141094] [G loss: 0.724075]\n",
      "epoch1 step12195 [D loss: 0.232176] [G loss: 0.781599]\n",
      "epoch1 step12200 [D loss: -0.035419] [G loss: 0.568394]\n",
      "epoch1 step12205 [D loss: -0.125772] [G loss: 0.458220]\n",
      "epoch1 step12210 [D loss: -0.143658] [G loss: 0.321365]\n",
      "epoch1 step12215 [D loss: -0.006006] [G loss: 0.490966]\n",
      "epoch1 step12220 [D loss: -0.170059] [G loss: 0.482186]\n",
      "epoch1 step12225 [D loss: -0.174578] [G loss: 0.306278]\n",
      "epoch1 step12230 [D loss: -0.032962] [G loss: 0.327509]\n",
      "epoch1 step12235 [D loss: -0.034278] [G loss: 0.623788]\n",
      "epoch1 step12240 [D loss: -0.319016] [G loss: 0.363301]\n",
      "epoch1 step12245 [D loss: 0.067829] [G loss: 0.300051]\n",
      "epoch1 step12250 [D loss: 0.357279] [G loss: 0.212613]\n",
      "epoch1 step12255 [D loss: -0.115763] [G loss: 0.603526]\n",
      "epoch1 step12260 [D loss: 0.286451] [G loss: 0.180712]\n",
      "epoch1 step12265 [D loss: 0.521389] [G loss: 0.563486]\n",
      "epoch1 step12270 [D loss: -0.310582] [G loss: 0.384749]\n",
      "epoch1 step12275 [D loss: 0.316138] [G loss: 0.272216]\n",
      "epoch1 step12280 [D loss: 0.250463] [G loss: 0.189237]\n",
      "epoch1 step12285 [D loss: -0.264671] [G loss: 0.343776]\n",
      "epoch1 step12290 [D loss: 0.223153] [G loss: 0.464781]\n",
      "epoch1 step12295 [D loss: 0.175962] [G loss: 0.458816]\n",
      "epoch1 step12300 [D loss: -0.277456] [G loss: 0.188558]\n",
      "epoch1 step12305 [D loss: -0.113440] [G loss: 0.280889]\n",
      "epoch1 step12310 [D loss: -0.460810] [G loss: 0.342896]\n",
      "epoch1 step12315 [D loss: -0.003928] [G loss: 0.389996]\n",
      "epoch1 step12320 [D loss: -0.250630] [G loss: 0.296154]\n",
      "epoch1 step12325 [D loss: -0.391604] [G loss: 0.349376]\n",
      "epoch1 step12330 [D loss: 0.084504] [G loss: 0.336582]\n",
      "epoch1 step12335 [D loss: 0.266044] [G loss: 0.150499]\n",
      "epoch1 step12340 [D loss: -0.101537] [G loss: 0.164732]\n",
      "epoch1 step12345 [D loss: 0.079654] [G loss: 0.197274]\n",
      "epoch1 step12350 [D loss: -0.379832] [G loss: 0.232098]\n",
      "epoch1 step12355 [D loss: -0.282314] [G loss: 0.278343]\n",
      "epoch1 step12360 [D loss: -0.012869] [G loss: 0.264984]\n",
      "epoch1 step12365 [D loss: -0.130425] [G loss: 0.415001]\n",
      "epoch1 step12370 [D loss: -0.217654] [G loss: 0.379857]\n",
      "epoch1 step12375 [D loss: -0.120505] [G loss: 0.361956]\n",
      "epoch1 step12380 [D loss: 0.239821] [G loss: 0.194901]\n",
      "epoch1 step12385 [D loss: 0.221442] [G loss: 0.047979]\n",
      "epoch1 step12390 [D loss: -0.370667] [G loss: 0.263485]\n",
      "epoch1 step12395 [D loss: -0.222004] [G loss: 0.232351]\n",
      "epoch1 step12400 [D loss: 0.172989] [G loss: 0.367604]\n",
      "epoch1 step12405 [D loss: 0.017324] [G loss: -0.014819]\n",
      "epoch1 step12410 [D loss: -0.210100] [G loss: -0.092050]\n",
      "epoch1 step12415 [D loss: -0.374479] [G loss: 0.432441]\n",
      "epoch1 step12420 [D loss: 0.016160] [G loss: 0.397736]\n",
      "epoch1 step12425 [D loss: -0.066220] [G loss: 0.260502]\n",
      "epoch1 step12430 [D loss: 0.147277] [G loss: 0.141615]\n",
      "epoch1 step12435 [D loss: 0.083510] [G loss: 0.210276]\n",
      "epoch1 step12440 [D loss: 0.033747] [G loss: 0.126027]\n",
      "epoch1 step12445 [D loss: 0.390838] [G loss: 0.233835]\n",
      "epoch1 step12450 [D loss: 0.133037] [G loss: -0.059340]\n",
      "epoch1 step12455 [D loss: -0.128460] [G loss: 0.020174]\n",
      "epoch1 step12460 [D loss: -0.376324] [G loss: -0.177247]\n",
      "epoch1 step12465 [D loss: 0.342613] [G loss: 0.100599]\n",
      "epoch1 step12470 [D loss: -0.040344] [G loss: -0.117570]\n",
      "epoch1 step12475 [D loss: -0.115236] [G loss: 0.047608]\n",
      "epoch1 step12480 [D loss: -0.307422] [G loss: 0.096736]\n",
      "epoch1 step12485 [D loss: -0.225868] [G loss: 0.244332]\n",
      "epoch1 step12490 [D loss: -0.639050] [G loss: 0.230262]\n",
      "epoch1 step12495 [D loss: 0.400666] [G loss: 0.136929]\n",
      "epoch1 step12500 [D loss: 0.206759] [G loss: -0.046889]\n",
      "epoch1 step12505 [D loss: 0.213470] [G loss: -0.107071]\n",
      "epoch1 step12510 [D loss: 0.007265] [G loss: 0.000958]\n",
      "epoch1 step12515 [D loss: 0.120332] [G loss: 0.075447]\n",
      "epoch1 step12520 [D loss: 0.256554] [G loss: 0.004872]\n",
      "epoch1 step12525 [D loss: 0.107410] [G loss: 0.304575]\n",
      "epoch1 step12530 [D loss: -0.310701] [G loss: 0.222987]\n",
      "epoch1 step12535 [D loss: 0.032361] [G loss: 0.062376]\n",
      "epoch1 step12540 [D loss: 0.026746] [G loss: 0.033208]\n",
      "epoch1 step12545 [D loss: -0.263831] [G loss: 0.189481]\n",
      "epoch1 step12550 [D loss: -0.079072] [G loss: 0.037914]\n",
      "epoch1 step12555 [D loss: -0.060109] [G loss: 0.197251]\n",
      "epoch1 step12560 [D loss: -0.195039] [G loss: -0.042417]\n",
      "epoch1 step12565 [D loss: -0.546232] [G loss: 0.149889]\n",
      "epoch1 step12570 [D loss: -0.032249] [G loss: -0.318603]\n",
      "epoch1 step12575 [D loss: -0.140477] [G loss: -0.196149]\n",
      "epoch1 step12580 [D loss: 0.112762] [G loss: -0.038287]\n",
      "epoch1 step12585 [D loss: 0.338105] [G loss: 0.130058]\n",
      "epoch1 step12590 [D loss: -0.197048] [G loss: 0.177829]\n",
      "epoch1 step12595 [D loss: -0.422949] [G loss: 0.160166]\n",
      "epoch1 step12600 [D loss: -0.109936] [G loss: -0.019195]\n",
      "epoch1 step12605 [D loss: -0.369755] [G loss: 0.163855]\n",
      "epoch1 step12610 [D loss: -0.147928] [G loss: 0.052212]\n",
      "epoch1 step12615 [D loss: -0.287166] [G loss: 0.074778]\n",
      "epoch1 step12620 [D loss: -0.278095] [G loss: -0.070327]\n",
      "epoch1 step12625 [D loss: -0.087076] [G loss: 0.235410]\n",
      "epoch1 step12630 [D loss: -0.162698] [G loss: 0.292960]\n",
      "epoch1 step12635 [D loss: 0.383361] [G loss: -0.171709]\n",
      "epoch1 step12640 [D loss: -0.139018] [G loss: 0.165402]\n",
      "epoch1 step12645 [D loss: 0.230546] [G loss: 0.351283]\n",
      "epoch1 step12650 [D loss: 0.069015] [G loss: 0.285757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step12655 [D loss: -0.019326] [G loss: 0.336907]\n",
      "epoch1 step12660 [D loss: -0.133447] [G loss: 0.364998]\n",
      "epoch1 step12665 [D loss: -0.121904] [G loss: 0.217107]\n",
      "epoch1 step12670 [D loss: 0.086353] [G loss: 0.222179]\n",
      "epoch1 step12675 [D loss: -0.282026] [G loss: 0.379174]\n",
      "epoch1 step12680 [D loss: -0.186550] [G loss: 0.512591]\n",
      "epoch1 step12685 [D loss: 0.174330] [G loss: -0.231506]\n",
      "epoch1 step12690 [D loss: -0.446369] [G loss: 0.282594]\n",
      "epoch1 step12695 [D loss: -0.311898] [G loss: 0.086133]\n",
      "epoch1 step12700 [D loss: 0.328388] [G loss: 0.533194]\n",
      "epoch1 step12705 [D loss: -0.068472] [G loss: 0.492869]\n",
      "epoch1 step12710 [D loss: 0.615374] [G loss: 0.119171]\n",
      "epoch1 step12715 [D loss: 0.121122] [G loss: 0.180212]\n",
      "epoch1 step12720 [D loss: -0.451524] [G loss: 0.308768]\n",
      "epoch1 step12725 [D loss: -0.136208] [G loss: 0.168062]\n",
      "epoch1 step12730 [D loss: 0.088289] [G loss: 0.419282]\n",
      "epoch1 step12735 [D loss: -0.082484] [G loss: 0.355963]\n",
      "epoch1 step12740 [D loss: 0.107379] [G loss: 0.524783]\n",
      "epoch1 step12745 [D loss: 0.400481] [G loss: 0.130318]\n",
      "epoch1 step12750 [D loss: -0.581579] [G loss: 0.281047]\n",
      "epoch1 step12755 [D loss: -0.041990] [G loss: 0.533191]\n",
      "epoch1 step12760 [D loss: -0.065953] [G loss: 0.653527]\n",
      "epoch1 step12765 [D loss: 0.015415] [G loss: 0.561010]\n",
      "epoch1 step12770 [D loss: -0.261685] [G loss: 0.300540]\n",
      "epoch1 step12775 [D loss: -0.090514] [G loss: 0.472077]\n",
      "epoch1 step12780 [D loss: 0.129181] [G loss: 0.154080]\n",
      "epoch1 step12785 [D loss: 0.154584] [G loss: 0.280029]\n",
      "epoch1 step12790 [D loss: -0.152848] [G loss: 0.647235]\n",
      "epoch1 step12795 [D loss: 0.011140] [G loss: 0.347623]\n",
      "epoch1 step12800 [D loss: -0.292904] [G loss: 0.763085]\n",
      "epoch1 step12805 [D loss: -0.143334] [G loss: 0.873505]\n",
      "epoch1 step12810 [D loss: -0.353418] [G loss: 0.644093]\n",
      "epoch1 step12815 [D loss: 0.140465] [G loss: 0.427341]\n",
      "epoch1 step12820 [D loss: -0.151311] [G loss: 0.387743]\n",
      "epoch1 step12825 [D loss: 0.072091] [G loss: 0.397666]\n",
      "epoch1 step12830 [D loss: -0.288650] [G loss: 0.524693]\n",
      "epoch1 step12835 [D loss: -0.156562] [G loss: 0.574314]\n",
      "epoch1 step12840 [D loss: -0.190146] [G loss: 0.595729]\n",
      "epoch1 step12845 [D loss: 0.328213] [G loss: 0.253171]\n",
      "epoch1 step12850 [D loss: 0.005654] [G loss: 0.406966]\n",
      "epoch1 step12855 [D loss: -0.364534] [G loss: 0.759695]\n",
      "epoch1 step12860 [D loss: -0.088643] [G loss: 0.537905]\n",
      "epoch1 step12865 [D loss: -0.181574] [G loss: 0.605472]\n",
      "epoch1 step12870 [D loss: -0.132313] [G loss: 0.609579]\n",
      "epoch1 step12875 [D loss: -0.257406] [G loss: 0.564788]\n",
      "epoch1 step12880 [D loss: 0.311575] [G loss: 0.311203]\n",
      "epoch1 step12885 [D loss: 0.361724] [G loss: 0.404448]\n",
      "epoch1 step12890 [D loss: 0.118944] [G loss: 0.702080]\n",
      "epoch1 step12895 [D loss: -0.193910] [G loss: 0.634704]\n",
      "epoch1 step12900 [D loss: -0.001214] [G loss: 0.426687]\n",
      "epoch1 step12905 [D loss: 0.155868] [G loss: 0.493657]\n",
      "epoch1 step12910 [D loss: 0.047925] [G loss: 0.226120]\n",
      "epoch1 step12915 [D loss: -0.299668] [G loss: 0.448353]\n",
      "epoch1 step12920 [D loss: -0.198152] [G loss: 0.328117]\n",
      "epoch1 step12925 [D loss: 0.142196] [G loss: 0.217420]\n",
      "epoch1 step12930 [D loss: 0.147387] [G loss: 0.134308]\n",
      "epoch1 step12935 [D loss: -0.115459] [G loss: 0.330634]\n",
      "epoch1 step12940 [D loss: 0.102051] [G loss: 0.063665]\n",
      "epoch1 step12945 [D loss: 0.035018] [G loss: 0.449593]\n",
      "epoch1 step12950 [D loss: 0.380599] [G loss: 0.090734]\n",
      "epoch1 step12955 [D loss: 0.065968] [G loss: 0.081075]\n",
      "epoch1 step12960 [D loss: -0.108222] [G loss: 0.290737]\n",
      "epoch1 step12965 [D loss: 0.048228] [G loss: -0.027375]\n",
      "epoch1 step12970 [D loss: -0.022763] [G loss: -0.102779]\n",
      "epoch1 step12975 [D loss: 0.148614] [G loss: 0.298181]\n",
      "epoch1 step12980 [D loss: 0.554497] [G loss: 0.098438]\n",
      "epoch1 step12985 [D loss: -0.026594] [G loss: 0.523112]\n",
      "epoch1 step12990 [D loss: 0.147370] [G loss: 0.370487]\n",
      "epoch1 step12995 [D loss: 0.113356] [G loss: 0.104299]\n",
      "epoch1 step13000 [D loss: -0.172739] [G loss: 0.578127]\n",
      "epoch1 step13005 [D loss: -0.281748] [G loss: 0.418934]\n",
      "epoch1 step13010 [D loss: -0.346419] [G loss: 0.602639]\n",
      "epoch1 step13015 [D loss: -0.079237] [G loss: 0.782869]\n",
      "epoch1 step13020 [D loss: -0.345630] [G loss: 0.715916]\n",
      "epoch1 step13025 [D loss: -0.281957] [G loss: 0.522981]\n",
      "epoch1 step13030 [D loss: 0.185255] [G loss: 0.983349]\n",
      "epoch1 step13035 [D loss: 0.029801] [G loss: 0.904121]\n",
      "epoch1 step13040 [D loss: 0.081735] [G loss: 0.593498]\n",
      "epoch1 step13045 [D loss: -0.312532] [G loss: 0.772569]\n",
      "epoch1 step13050 [D loss: -0.499141] [G loss: 0.589238]\n",
      "epoch1 step13055 [D loss: -0.203134] [G loss: 0.914114]\n",
      "epoch1 step13060 [D loss: -0.228391] [G loss: 0.756172]\n",
      "epoch1 step13065 [D loss: 0.073495] [G loss: 0.539307]\n",
      "epoch1 step13070 [D loss: -0.115583] [G loss: 0.793903]\n",
      "epoch1 step13075 [D loss: 0.169608] [G loss: 0.503879]\n",
      "epoch1 step13080 [D loss: -0.210307] [G loss: 0.527378]\n",
      "epoch1 step13085 [D loss: 0.074635] [G loss: 0.641159]\n",
      "epoch1 step13090 [D loss: -0.268880] [G loss: 0.667616]\n",
      "epoch1 step13095 [D loss: 0.543575] [G loss: 0.426964]\n",
      "epoch1 step13100 [D loss: -0.073269] [G loss: 0.343347]\n",
      "epoch1 step13105 [D loss: 0.413864] [G loss: 0.186676]\n",
      "epoch1 step13110 [D loss: -0.338339] [G loss: 0.186916]\n",
      "epoch1 step13115 [D loss: 0.119062] [G loss: 0.151235]\n",
      "epoch1 step13120 [D loss: 0.368022] [G loss: 0.001931]\n",
      "epoch1 step13125 [D loss: -0.447482] [G loss: 0.356644]\n",
      "epoch1 step13130 [D loss: -0.127382] [G loss: 0.079009]\n",
      "epoch1 step13135 [D loss: -0.346223] [G loss: 0.304960]\n",
      "epoch1 step13140 [D loss: -0.047817] [G loss: 0.069224]\n",
      "epoch1 step13145 [D loss: 0.371196] [G loss: -0.062993]\n",
      "epoch1 step13150 [D loss: 0.028192] [G loss: -0.127840]\n",
      "epoch1 step13155 [D loss: -0.039826] [G loss: 0.264303]\n",
      "epoch1 step13160 [D loss: 0.706155] [G loss: 0.008933]\n",
      "epoch1 step13165 [D loss: 0.162233] [G loss: 0.125039]\n",
      "epoch1 step13170 [D loss: 0.352390] [G loss: -0.223557]\n",
      "epoch1 step13175 [D loss: 0.446728] [G loss: 0.083738]\n",
      "epoch1 step13180 [D loss: 0.177868] [G loss: -0.109869]\n",
      "epoch1 step13185 [D loss: -0.460025] [G loss: 0.344580]\n",
      "epoch1 step13190 [D loss: -0.079775] [G loss: 0.138573]\n",
      "epoch1 step13195 [D loss: -0.120602] [G loss: 0.254242]\n",
      "epoch1 step13200 [D loss: 0.012485] [G loss: 0.217303]\n",
      "epoch1 step13205 [D loss: -0.238700] [G loss: 0.365494]\n",
      "epoch1 step13210 [D loss: -0.246281] [G loss: 0.126892]\n",
      "epoch1 step13215 [D loss: 0.178349] [G loss: 0.358432]\n",
      "epoch1 step13220 [D loss: 0.023429] [G loss: 0.353950]\n",
      "epoch1 step13225 [D loss: 0.126908] [G loss: 0.467322]\n",
      "epoch1 step13230 [D loss: 0.324532] [G loss: 0.666579]\n",
      "epoch1 step13235 [D loss: -0.310368] [G loss: 0.712705]\n",
      "epoch1 step13240 [D loss: -0.210445] [G loss: 1.059948]\n",
      "epoch1 step13245 [D loss: -0.293977] [G loss: 0.957840]\n",
      "epoch1 step13250 [D loss: -0.113585] [G loss: 0.928020]\n",
      "epoch1 step13255 [D loss: -0.591245] [G loss: 1.112061]\n",
      "epoch1 step13260 [D loss: 0.106435] [G loss: 1.445285]\n",
      "epoch1 step13265 [D loss: -0.184350] [G loss: 1.297678]\n",
      "epoch1 step13270 [D loss: -0.335405] [G loss: 1.101795]\n",
      "epoch1 step13275 [D loss: 0.067158] [G loss: 1.125370]\n",
      "epoch1 step13280 [D loss: 0.247763] [G loss: 0.937364]\n",
      "epoch1 step13285 [D loss: 0.064448] [G loss: 0.766715]\n",
      "epoch1 step13290 [D loss: -0.061365] [G loss: 1.025941]\n",
      "epoch1 step13295 [D loss: -0.042113] [G loss: 0.882452]\n",
      "epoch1 step13300 [D loss: -0.516904] [G loss: 1.016924]\n",
      "epoch1 step13305 [D loss: 0.640316] [G loss: 1.117191]\n",
      "epoch1 step13310 [D loss: -0.003765] [G loss: 1.047968]\n",
      "epoch1 step13315 [D loss: -0.153962] [G loss: 1.356001]\n",
      "epoch1 step13320 [D loss: -0.096339] [G loss: 1.244417]\n",
      "epoch1 step13325 [D loss: -0.328547] [G loss: 1.389262]\n",
      "epoch1 step13330 [D loss: 0.375685] [G loss: 1.204022]\n",
      "epoch1 step13335 [D loss: -0.125633] [G loss: 0.836615]\n",
      "epoch1 step13340 [D loss: 0.420579] [G loss: 0.676844]\n",
      "epoch1 step13345 [D loss: 0.489507] [G loss: 0.620563]\n",
      "epoch1 step13350 [D loss: -0.180186] [G loss: 0.756582]\n",
      "epoch1 step13355 [D loss: -0.299439] [G loss: 0.972207]\n",
      "epoch1 step13360 [D loss: 0.080454] [G loss: 0.957229]\n",
      "epoch1 step13365 [D loss: 0.143936] [G loss: 0.788591]\n",
      "epoch1 step13370 [D loss: -0.181320] [G loss: 0.977177]\n",
      "epoch1 step13375 [D loss: 0.254991] [G loss: 0.487988]\n",
      "epoch1 step13380 [D loss: -0.132513] [G loss: 0.870018]\n",
      "epoch1 step13385 [D loss: 0.104385] [G loss: 1.013121]\n",
      "epoch1 step13390 [D loss: 0.065857] [G loss: 0.806989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step13395 [D loss: 0.263810] [G loss: 0.904095]\n",
      "epoch1 step13400 [D loss: -0.064240] [G loss: 0.848189]\n",
      "epoch1 step13405 [D loss: 0.292688] [G loss: 0.481312]\n",
      "epoch1 step13410 [D loss: 0.199147] [G loss: 0.632427]\n",
      "epoch1 step13415 [D loss: 0.090689] [G loss: 0.682345]\n",
      "epoch1 step13420 [D loss: 0.003211] [G loss: 0.748729]\n",
      "epoch1 step13425 [D loss: -0.331586] [G loss: 0.839651]\n",
      "epoch1 step13430 [D loss: -0.298461] [G loss: 0.701497]\n",
      "epoch1 step13435 [D loss: 0.298706] [G loss: 0.740006]\n",
      "epoch1 step13440 [D loss: -0.117592] [G loss: 0.793784]\n",
      "epoch1 step13445 [D loss: 0.248021] [G loss: 0.843449]\n",
      "epoch1 step13450 [D loss: -0.039553] [G loss: 0.926311]\n",
      "epoch1 step13455 [D loss: -0.090849] [G loss: 0.909897]\n",
      "epoch1 step13460 [D loss: -0.381328] [G loss: 0.861309]\n",
      "epoch1 step13465 [D loss: -0.161142] [G loss: 0.981361]\n",
      "epoch1 step13470 [D loss: -0.126927] [G loss: 0.831979]\n",
      "epoch1 step13475 [D loss: -0.214177] [G loss: 1.209188]\n",
      "epoch1 step13480 [D loss: -0.120861] [G loss: 0.836966]\n",
      "epoch1 step13485 [D loss: -0.417886] [G loss: 0.673774]\n",
      "epoch1 step13490 [D loss: 0.191376] [G loss: 0.672102]\n",
      "epoch1 step13495 [D loss: -0.067674] [G loss: 0.817109]\n",
      "epoch1 step13500 [D loss: -0.033025] [G loss: 0.520960]\n",
      "epoch1 step13505 [D loss: -0.139044] [G loss: 0.843779]\n",
      "epoch1 step13510 [D loss: 0.179673] [G loss: 0.616325]\n",
      "epoch1 step13515 [D loss: -0.348702] [G loss: 1.008056]\n",
      "epoch1 step13520 [D loss: 0.076079] [G loss: 0.583513]\n",
      "epoch1 step13525 [D loss: 0.075662] [G loss: 0.566127]\n",
      "epoch1 step13530 [D loss: -0.341451] [G loss: 0.804598]\n",
      "epoch1 step13535 [D loss: -0.068781] [G loss: 0.632024]\n",
      "epoch1 step13540 [D loss: -0.346493] [G loss: 0.387577]\n",
      "epoch1 step13545 [D loss: 0.092119] [G loss: 0.966277]\n",
      "epoch1 step13550 [D loss: -0.505292] [G loss: 1.032042]\n",
      "epoch1 step13555 [D loss: -0.228483] [G loss: 0.638778]\n",
      "epoch1 step13560 [D loss: -0.289216] [G loss: 0.429908]\n",
      "epoch1 step13565 [D loss: 0.216515] [G loss: 0.726813]\n",
      "epoch1 step13570 [D loss: -0.169885] [G loss: 0.788845]\n",
      "epoch1 step13575 [D loss: -0.093445] [G loss: 0.909541]\n",
      "epoch1 step13580 [D loss: 0.068168] [G loss: 0.764105]\n",
      "epoch1 step13585 [D loss: -0.041784] [G loss: 0.697414]\n",
      "epoch1 step13590 [D loss: -0.124255] [G loss: 0.646259]\n",
      "epoch1 step13595 [D loss: -0.205815] [G loss: 0.774615]\n",
      "epoch1 step13600 [D loss: 0.132684] [G loss: 0.731140]\n",
      "epoch1 step13605 [D loss: 0.169462] [G loss: 0.659131]\n",
      "epoch1 step13610 [D loss: 0.237888] [G loss: 0.694762]\n",
      "epoch1 step13615 [D loss: -0.276541] [G loss: 0.594856]\n",
      "epoch1 step13620 [D loss: 0.014525] [G loss: 1.158718]\n",
      "epoch1 step13625 [D loss: 0.286837] [G loss: 0.654457]\n",
      "epoch1 step13630 [D loss: -0.202461] [G loss: 1.013287]\n",
      "epoch1 step13635 [D loss: -0.147044] [G loss: 0.842663]\n",
      "epoch1 step13640 [D loss: 0.111216] [G loss: 1.078822]\n",
      "epoch1 step13645 [D loss: -0.064868] [G loss: 0.862018]\n",
      "epoch1 step13650 [D loss: -0.278533] [G loss: 1.036182]\n",
      "epoch1 step13655 [D loss: 0.067037] [G loss: 0.998663]\n",
      "epoch1 step13660 [D loss: -0.043153] [G loss: 1.125595]\n",
      "epoch1 step13665 [D loss: -0.435148] [G loss: 1.042573]\n",
      "epoch1 step13670 [D loss: 0.342225] [G loss: 0.985663]\n",
      "epoch1 step13675 [D loss: 0.087182] [G loss: 0.695222]\n",
      "epoch1 step13680 [D loss: 0.307977] [G loss: 0.886643]\n",
      "epoch1 step13685 [D loss: -0.342618] [G loss: 1.009233]\n",
      "epoch1 step13690 [D loss: -0.418402] [G loss: 1.138406]\n",
      "epoch1 step13695 [D loss: -0.056306] [G loss: 1.177855]\n",
      "epoch1 step13700 [D loss: -0.406698] [G loss: 0.806870]\n",
      "epoch1 step13705 [D loss: 0.307914] [G loss: 0.832199]\n",
      "epoch1 step13710 [D loss: -0.100950] [G loss: 0.870001]\n",
      "epoch1 step13715 [D loss: -0.130655] [G loss: 0.912870]\n",
      "epoch1 step13720 [D loss: -0.310694] [G loss: 0.632762]\n",
      "epoch1 step13725 [D loss: 0.096757] [G loss: 0.854671]\n",
      "epoch1 step13730 [D loss: -0.040060] [G loss: 0.725410]\n",
      "epoch1 step13735 [D loss: -0.278379] [G loss: 0.990629]\n",
      "epoch1 step13740 [D loss: 0.088739] [G loss: 0.628708]\n",
      "epoch1 step13745 [D loss: 0.058670] [G loss: 0.625444]\n",
      "epoch1 step13750 [D loss: -0.265716] [G loss: 0.841926]\n",
      "epoch1 step13755 [D loss: 0.323632] [G loss: 0.488978]\n",
      "epoch1 step13760 [D loss: 0.150672] [G loss: 0.524360]\n",
      "epoch1 step13765 [D loss: -0.095081] [G loss: 0.671525]\n",
      "epoch1 step13770 [D loss: 0.268652] [G loss: 0.753561]\n",
      "epoch1 step13775 [D loss: 0.141065] [G loss: 0.855263]\n",
      "epoch1 step13780 [D loss: -0.155347] [G loss: 0.747150]\n",
      "epoch1 step13785 [D loss: -0.534658] [G loss: 0.965394]\n",
      "epoch1 step13790 [D loss: -0.023920] [G loss: 0.617582]\n",
      "epoch1 step13795 [D loss: -0.149386] [G loss: 1.065782]\n",
      "epoch1 step13800 [D loss: -0.304671] [G loss: 0.573138]\n",
      "epoch1 step13805 [D loss: -0.163777] [G loss: 0.614430]\n",
      "epoch1 step13810 [D loss: -0.295561] [G loss: 0.353914]\n",
      "epoch1 step13815 [D loss: -0.529330] [G loss: 0.517265]\n",
      "epoch1 step13820 [D loss: -0.643608] [G loss: 0.411466]\n",
      "epoch1 step13825 [D loss: -0.119022] [G loss: 0.987606]\n",
      "epoch1 step13830 [D loss: -0.208357] [G loss: 0.572539]\n",
      "epoch1 step13835 [D loss: -0.054382] [G loss: 0.577220]\n",
      "epoch1 step13840 [D loss: -0.170619] [G loss: 0.693706]\n",
      "epoch1 step13845 [D loss: -0.053464] [G loss: 0.334524]\n",
      "epoch1 step13850 [D loss: -0.344371] [G loss: 0.533036]\n",
      "epoch1 step13855 [D loss: 0.010037] [G loss: 0.381381]\n",
      "epoch1 step13860 [D loss: -0.041683] [G loss: 0.755003]\n",
      "epoch1 step13865 [D loss: -0.310527] [G loss: 0.301242]\n",
      "epoch1 step13870 [D loss: -0.094572] [G loss: 0.639206]\n",
      "epoch1 step13875 [D loss: -0.085642] [G loss: 0.711809]\n",
      "epoch1 step13880 [D loss: -0.308019] [G loss: 0.644697]\n",
      "epoch1 step13885 [D loss: -0.367575] [G loss: 0.507961]\n",
      "epoch1 step13890 [D loss: 0.102882] [G loss: 0.416560]\n",
      "epoch1 step13895 [D loss: -0.183428] [G loss: 0.453370]\n",
      "epoch1 step13900 [D loss: -0.095302] [G loss: 0.611836]\n",
      "epoch1 step13905 [D loss: -0.112954] [G loss: 0.580864]\n",
      "epoch1 step13910 [D loss: -0.308342] [G loss: 0.502146]\n",
      "epoch1 step13915 [D loss: 0.162525] [G loss: 0.741092]\n",
      "epoch1 step13920 [D loss: -0.018724] [G loss: 0.577294]\n",
      "epoch1 step13925 [D loss: -0.041014] [G loss: 0.923703]\n",
      "epoch1 step13930 [D loss: -0.053859] [G loss: 0.819999]\n",
      "epoch1 step13935 [D loss: 0.004285] [G loss: 0.761780]\n",
      "epoch1 step13940 [D loss: -0.100499] [G loss: 0.604712]\n",
      "epoch1 step13945 [D loss: -0.266436] [G loss: 0.536522]\n",
      "epoch1 step13950 [D loss: 0.208600] [G loss: 0.877611]\n",
      "epoch1 step13955 [D loss: -0.372691] [G loss: 0.689989]\n",
      "epoch1 step13960 [D loss: -0.023284] [G loss: 0.783196]\n",
      "epoch1 step13965 [D loss: 0.232050] [G loss: 1.233371]\n",
      "epoch1 step13970 [D loss: -0.386767] [G loss: 0.615911]\n",
      "epoch1 step13975 [D loss: -0.354322] [G loss: 0.871145]\n",
      "epoch1 step13980 [D loss: -0.082572] [G loss: 0.677965]\n",
      "epoch1 step13985 [D loss: -0.056855] [G loss: 0.555222]\n",
      "epoch1 step13990 [D loss: -0.103304] [G loss: 0.504180]\n",
      "epoch1 step13995 [D loss: 0.480373] [G loss: 0.311379]\n",
      "epoch1 step14000 [D loss: 0.155696] [G loss: 0.811756]\n",
      "epoch1 step14005 [D loss: -0.350728] [G loss: 0.820292]\n",
      "epoch1 step14010 [D loss: 0.006942] [G loss: 0.696584]\n",
      "epoch1 step14015 [D loss: -0.115704] [G loss: 0.808470]\n",
      "epoch1 step14020 [D loss: 0.211204] [G loss: 0.614999]\n",
      "epoch1 step14025 [D loss: -0.103786] [G loss: 0.725779]\n",
      "epoch1 step14030 [D loss: 0.116516] [G loss: 0.626609]\n",
      "epoch1 step14035 [D loss: 0.010354] [G loss: 0.769323]\n",
      "epoch1 step14040 [D loss: -0.082473] [G loss: 0.545186]\n",
      "epoch1 step14045 [D loss: 0.151905] [G loss: 0.501061]\n",
      "epoch1 step14050 [D loss: -0.029988] [G loss: 0.852253]\n",
      "epoch1 step14055 [D loss: -0.282327] [G loss: 0.613726]\n",
      "epoch1 step14060 [D loss: -0.267221] [G loss: 0.748410]\n",
      "epoch1 step14065 [D loss: 0.066682] [G loss: 0.780397]\n",
      "epoch1 step14070 [D loss: 0.090764] [G loss: 1.207396]\n",
      "epoch1 step14075 [D loss: 0.253903] [G loss: 0.785423]\n",
      "epoch1 step14080 [D loss: -0.342895] [G loss: 0.865174]\n",
      "epoch1 step14085 [D loss: -0.205866] [G loss: 0.912752]\n",
      "epoch1 step14090 [D loss: -0.092312] [G loss: 0.838375]\n",
      "epoch1 step14095 [D loss: -0.204987] [G loss: 0.935862]\n",
      "epoch1 step14100 [D loss: -0.146106] [G loss: 0.911012]\n",
      "epoch1 step14105 [D loss: -0.196894] [G loss: 0.906578]\n",
      "epoch1 step14110 [D loss: -0.134666] [G loss: 0.747662]\n",
      "epoch1 step14115 [D loss: -0.223817] [G loss: 1.128211]\n",
      "epoch1 step14120 [D loss: -0.322954] [G loss: 0.803991]\n",
      "epoch1 step14125 [D loss: 0.170717] [G loss: 0.710661]\n",
      "epoch1 step14130 [D loss: 0.159019] [G loss: 0.867277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step14135 [D loss: 0.154221] [G loss: 0.833196]\n",
      "epoch1 step14140 [D loss: -0.319270] [G loss: 1.044888]\n",
      "epoch1 step14145 [D loss: -0.182495] [G loss: 1.134319]\n",
      "epoch1 step14150 [D loss: 0.317904] [G loss: 1.009721]\n",
      "epoch1 step14155 [D loss: 0.044642] [G loss: 0.740513]\n",
      "epoch1 step14160 [D loss: -0.339576] [G loss: 0.884305]\n",
      "epoch1 step14165 [D loss: -0.299690] [G loss: 0.715337]\n",
      "epoch1 step14170 [D loss: -0.122721] [G loss: 0.910521]\n",
      "epoch1 step14175 [D loss: -0.191619] [G loss: 0.783660]\n",
      "epoch1 step14180 [D loss: -0.284680] [G loss: 1.479005]\n",
      "epoch1 step14185 [D loss: -0.174870] [G loss: 0.951103]\n",
      "epoch1 step14190 [D loss: -0.033102] [G loss: 0.890541]\n",
      "epoch1 step14195 [D loss: -0.558154] [G loss: 0.801191]\n",
      "epoch1 step14200 [D loss: -0.179760] [G loss: 1.177257]\n",
      "epoch1 step14205 [D loss: 0.202885] [G loss: 1.172535]\n",
      "epoch1 step14210 [D loss: -0.132218] [G loss: 0.529544]\n",
      "epoch1 step14215 [D loss: -0.450443] [G loss: 0.943795]\n",
      "epoch1 step14220 [D loss: 0.399832] [G loss: 0.908982]\n",
      "epoch1 step14225 [D loss: -0.439941] [G loss: 0.945430]\n",
      "epoch1 step14230 [D loss: 0.506503] [G loss: 0.926443]\n",
      "epoch1 step14235 [D loss: -0.216346] [G loss: 0.955007]\n",
      "epoch1 step14240 [D loss: -0.129233] [G loss: 0.882078]\n",
      "epoch1 step14245 [D loss: -0.024349] [G loss: 0.841776]\n",
      "epoch1 step14250 [D loss: -0.027673] [G loss: 1.113623]\n",
      "epoch1 step14255 [D loss: 0.201216] [G loss: 1.061473]\n",
      "epoch1 step14260 [D loss: 0.000696] [G loss: 0.990292]\n",
      "epoch1 step14265 [D loss: -0.170301] [G loss: 1.361574]\n",
      "epoch1 step14270 [D loss: 0.151353] [G loss: 1.103466]\n",
      "epoch1 step14275 [D loss: 0.344309] [G loss: 0.930675]\n",
      "epoch1 step14280 [D loss: 0.066254] [G loss: 1.071629]\n",
      "epoch1 step14285 [D loss: 0.506243] [G loss: 0.886792]\n",
      "epoch1 step14290 [D loss: 0.112020] [G loss: 1.345445]\n",
      "epoch1 step14295 [D loss: -0.112036] [G loss: 1.150697]\n",
      "epoch1 step14300 [D loss: 0.051460] [G loss: 0.869262]\n",
      "epoch1 step14305 [D loss: 0.162673] [G loss: 1.353988]\n",
      "epoch1 step14310 [D loss: -0.040229] [G loss: 1.199852]\n",
      "epoch1 step14315 [D loss: -0.560356] [G loss: 1.319014]\n",
      "epoch1 step14320 [D loss: -0.477109] [G loss: 1.487203]\n",
      "epoch1 step14325 [D loss: -0.000160] [G loss: 1.400782]\n",
      "epoch1 step14330 [D loss: -0.573650] [G loss: 1.472644]\n",
      "epoch1 step14335 [D loss: -0.059922] [G loss: 1.508085]\n",
      "epoch1 step14340 [D loss: 0.013553] [G loss: 1.346128]\n",
      "epoch1 step14345 [D loss: 0.037465] [G loss: 1.116009]\n",
      "epoch1 step14350 [D loss: 0.196621] [G loss: 1.077863]\n",
      "epoch1 step14355 [D loss: 0.241239] [G loss: 1.420953]\n",
      "epoch1 step14360 [D loss: 0.041823] [G loss: 1.350669]\n",
      "epoch1 step14365 [D loss: -0.097016] [G loss: 1.245910]\n",
      "epoch1 step14370 [D loss: 0.169225] [G loss: 1.135852]\n",
      "epoch1 step14375 [D loss: -0.147297] [G loss: 1.244896]\n",
      "epoch1 step14380 [D loss: -0.277088] [G loss: 1.446842]\n",
      "epoch1 step14385 [D loss: 0.268298] [G loss: 1.060911]\n",
      "epoch1 step14390 [D loss: -0.052442] [G loss: 1.430666]\n",
      "epoch1 step14395 [D loss: -0.135766] [G loss: 1.263001]\n",
      "epoch1 step14400 [D loss: -0.270780] [G loss: 1.121272]\n",
      "epoch1 step14405 [D loss: -0.456993] [G loss: 1.504808]\n",
      "epoch1 step14410 [D loss: 0.165034] [G loss: 0.928027]\n",
      "epoch1 step14415 [D loss: 0.044921] [G loss: 0.939812]\n",
      "epoch1 step14420 [D loss: -0.173854] [G loss: 0.754840]\n",
      "epoch1 step14425 [D loss: -0.139398] [G loss: 1.127090]\n",
      "epoch1 step14430 [D loss: 0.143972] [G loss: 0.946018]\n",
      "epoch1 step14435 [D loss: -0.024313] [G loss: 1.063684]\n",
      "epoch1 step14440 [D loss: -0.395207] [G loss: 0.895143]\n",
      "epoch1 step14445 [D loss: 0.104593] [G loss: 0.797080]\n",
      "epoch1 step14450 [D loss: -0.245706] [G loss: 0.954062]\n",
      "epoch1 step14455 [D loss: 0.353193] [G loss: 1.066308]\n",
      "epoch1 step14460 [D loss: 0.096593] [G loss: 0.956727]\n",
      "epoch1 step14465 [D loss: -0.073520] [G loss: 0.900487]\n",
      "epoch1 step14470 [D loss: -0.177513] [G loss: 1.000895]\n",
      "epoch1 step14475 [D loss: -0.123722] [G loss: 0.993474]\n",
      "epoch1 step14480 [D loss: -0.294051] [G loss: 0.992197]\n",
      "epoch1 step14485 [D loss: -0.314502] [G loss: 0.706857]\n",
      "epoch1 step14490 [D loss: -0.177626] [G loss: 0.728534]\n",
      "epoch1 step14495 [D loss: -0.213736] [G loss: 0.742707]\n",
      "epoch1 step14500 [D loss: 0.232310] [G loss: 0.805938]\n",
      "epoch1 step14505 [D loss: 0.097795] [G loss: 0.696929]\n",
      "epoch1 step14510 [D loss: -0.279219] [G loss: 0.873480]\n",
      "epoch1 step14515 [D loss: -0.007035] [G loss: 0.855413]\n",
      "epoch1 step14520 [D loss: 0.447697] [G loss: 0.679344]\n",
      "epoch1 step14525 [D loss: -0.103323] [G loss: 0.823751]\n",
      "epoch1 step14530 [D loss: -0.231943] [G loss: 0.809142]\n",
      "epoch1 step14535 [D loss: -0.071803] [G loss: 1.250487]\n",
      "epoch1 step14540 [D loss: -0.320979] [G loss: 0.810118]\n",
      "epoch1 step14545 [D loss: 0.070585] [G loss: 0.969127]\n",
      "epoch1 step14550 [D loss: -0.372554] [G loss: 1.191690]\n",
      "epoch1 step14555 [D loss: -0.384410] [G loss: 0.663825]\n",
      "epoch1 step14560 [D loss: -0.177564] [G loss: 0.795002]\n",
      "epoch1 step14565 [D loss: 0.162782] [G loss: 0.634344]\n",
      "epoch1 step14570 [D loss: 0.375283] [G loss: 0.594659]\n",
      "epoch1 step14575 [D loss: -0.049441] [G loss: 0.557775]\n",
      "epoch1 step14580 [D loss: 0.035018] [G loss: 0.657822]\n",
      "epoch1 step14585 [D loss: 0.233393] [G loss: 0.514072]\n",
      "epoch1 step14590 [D loss: -0.290622] [G loss: 0.746504]\n",
      "epoch1 step14595 [D loss: 0.042841] [G loss: 0.455499]\n",
      "epoch1 step14600 [D loss: -0.285939] [G loss: 0.926270]\n",
      "epoch1 step14605 [D loss: 0.109319] [G loss: 0.712685]\n",
      "epoch1 step14610 [D loss: -0.215344] [G loss: 0.429756]\n",
      "epoch1 step14615 [D loss: 0.216247] [G loss: 0.709197]\n",
      "epoch1 step14620 [D loss: -0.141607] [G loss: 0.458783]\n",
      "epoch1 step14625 [D loss: 0.155276] [G loss: 0.603484]\n",
      "epoch1 step14630 [D loss: -0.002193] [G loss: 0.250449]\n",
      "epoch1 step14635 [D loss: 0.295523] [G loss: 0.179441]\n",
      "epoch1 step14640 [D loss: -0.249898] [G loss: 0.298405]\n",
      "epoch1 step14645 [D loss: -0.082918] [G loss: 0.412326]\n",
      "epoch1 step14650 [D loss: -0.318487] [G loss: 0.649205]\n",
      "epoch1 step14655 [D loss: -0.212391] [G loss: 0.486587]\n",
      "epoch1 step14660 [D loss: -0.105532] [G loss: 0.417247]\n",
      "epoch1 step14665 [D loss: -0.081281] [G loss: 0.335139]\n",
      "epoch1 step14670 [D loss: 0.090964] [G loss: -0.044784]\n",
      "epoch1 step14675 [D loss: -0.201138] [G loss: 0.515078]\n",
      "epoch1 step14680 [D loss: -0.414449] [G loss: 0.099188]\n",
      "epoch1 step14685 [D loss: 0.324478] [G loss: -0.025424]\n",
      "epoch1 step14690 [D loss: 0.018969] [G loss: 0.200062]\n",
      "epoch1 step14695 [D loss: 0.115670] [G loss: 0.329287]\n",
      "epoch1 step14700 [D loss: -0.110455] [G loss: 0.317078]\n",
      "epoch1 step14705 [D loss: 0.252724] [G loss: 0.447633]\n",
      "epoch1 step14710 [D loss: -0.083319] [G loss: 0.070210]\n",
      "epoch1 step14715 [D loss: -0.026254] [G loss: 0.264725]\n",
      "epoch1 step14720 [D loss: -0.181916] [G loss: 0.384987]\n",
      "epoch1 step14725 [D loss: 0.356519] [G loss: 0.260020]\n",
      "epoch1 step14730 [D loss: 0.090503] [G loss: 0.538794]\n",
      "epoch1 step14735 [D loss: -0.025105] [G loss: 0.677340]\n",
      "epoch1 step14740 [D loss: 0.607261] [G loss: 0.676021]\n",
      "epoch1 step14745 [D loss: -0.039554] [G loss: 0.712201]\n",
      "epoch1 step14750 [D loss: -0.451797] [G loss: 0.915579]\n",
      "epoch1 step14755 [D loss: -0.147898] [G loss: 0.507053]\n",
      "epoch1 step14760 [D loss: -0.009467] [G loss: 0.438722]\n",
      "epoch1 step14765 [D loss: -0.136718] [G loss: 0.822466]\n",
      "epoch1 step14770 [D loss: -0.181214] [G loss: 0.689265]\n",
      "epoch1 step14775 [D loss: 0.124994] [G loss: 0.963982]\n",
      "epoch1 step14780 [D loss: -0.048068] [G loss: 0.917889]\n",
      "epoch1 step14785 [D loss: -0.299716] [G loss: 0.892698]\n",
      "epoch1 step14790 [D loss: 0.004834] [G loss: 0.610465]\n",
      "epoch1 step14795 [D loss: 0.262248] [G loss: 0.793779]\n",
      "epoch1 step14800 [D loss: -0.248665] [G loss: 0.393443]\n",
      "epoch1 step14805 [D loss: -0.096868] [G loss: 0.516576]\n",
      "epoch1 step14810 [D loss: 0.159079] [G loss: 0.361964]\n",
      "epoch1 step14815 [D loss: -0.225383] [G loss: 0.829288]\n",
      "epoch1 step14820 [D loss: 0.107582] [G loss: 0.670661]\n",
      "epoch1 step14825 [D loss: -0.107741] [G loss: 1.025412]\n",
      "epoch1 step14830 [D loss: -0.208598] [G loss: 1.100505]\n",
      "epoch1 step14835 [D loss: 0.065149] [G loss: 0.549444]\n",
      "epoch1 step14840 [D loss: -0.441463] [G loss: 1.058803]\n",
      "epoch1 step14845 [D loss: -0.358160] [G loss: 0.505248]\n",
      "epoch1 step14850 [D loss: 0.048380] [G loss: 0.862065]\n",
      "epoch1 step14855 [D loss: -0.165926] [G loss: 0.871678]\n",
      "epoch1 step14860 [D loss: -0.624303] [G loss: 0.950724]\n",
      "epoch1 step14865 [D loss: -0.231603] [G loss: 0.733033]\n",
      "epoch1 step14870 [D loss: 0.071405] [G loss: 1.036682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step14875 [D loss: 0.066551] [G loss: 1.339233]\n",
      "epoch1 step14880 [D loss: -0.209024] [G loss: 0.998579]\n",
      "epoch1 step14885 [D loss: -0.273563] [G loss: 1.208723]\n",
      "epoch1 step14890 [D loss: -0.190919] [G loss: 1.083254]\n",
      "epoch1 step14895 [D loss: -0.159877] [G loss: 1.362438]\n",
      "epoch1 step14900 [D loss: -0.132255] [G loss: 1.596350]\n",
      "epoch1 step14905 [D loss: 0.111141] [G loss: 1.355851]\n",
      "epoch1 step14910 [D loss: 0.075108] [G loss: 1.149224]\n",
      "epoch1 step14915 [D loss: -0.070551] [G loss: 1.491223]\n",
      "epoch1 step14920 [D loss: -0.118214] [G loss: 1.573441]\n",
      "epoch1 step14925 [D loss: -0.188396] [G loss: 1.638493]\n",
      "epoch1 step14930 [D loss: -0.167452] [G loss: 1.712200]\n",
      "epoch1 step14935 [D loss: -0.274654] [G loss: 1.600156]\n",
      "epoch1 step14940 [D loss: -0.167675] [G loss: 1.649835]\n",
      "epoch1 step14945 [D loss: -0.455719] [G loss: 1.786809]\n",
      "epoch1 step14950 [D loss: 0.070493] [G loss: 1.619649]\n",
      "epoch1 step14955 [D loss: 0.047376] [G loss: 1.885321]\n",
      "epoch1 step14960 [D loss: -0.398693] [G loss: 2.175232]\n",
      "epoch1 step14965 [D loss: -0.536533] [G loss: 1.771323]\n",
      "epoch1 step14970 [D loss: 0.308896] [G loss: 1.762199]\n",
      "epoch1 step14975 [D loss: -0.021021] [G loss: 1.373249]\n",
      "epoch1 step14980 [D loss: -0.123240] [G loss: 1.616611]\n",
      "epoch1 step14985 [D loss: -0.570579] [G loss: 1.375367]\n",
      "epoch1 step14990 [D loss: 0.038913] [G loss: 1.617991]\n",
      "epoch1 step14995 [D loss: -0.208692] [G loss: 1.385133]\n",
      "epoch1 step15000 [D loss: -0.512174] [G loss: 1.819602]\n",
      "epoch1 step15005 [D loss: 0.175573] [G loss: 1.226702]\n",
      "epoch1 step15010 [D loss: 0.436368] [G loss: 1.504270]\n",
      "epoch1 step15015 [D loss: 0.255949] [G loss: 1.558345]\n",
      "epoch1 step15020 [D loss: 0.185950] [G loss: 1.939280]\n",
      "epoch1 step15025 [D loss: -0.062770] [G loss: 1.611220]\n",
      "epoch1 step15030 [D loss: -0.066502] [G loss: 1.365623]\n",
      "epoch1 step15035 [D loss: 0.094407] [G loss: 1.540939]\n",
      "epoch1 step15040 [D loss: -0.150018] [G loss: 1.730667]\n",
      "epoch1 step15045 [D loss: -0.976691] [G loss: 1.759877]\n",
      "epoch1 step15050 [D loss: 0.088402] [G loss: 1.433257]\n",
      "epoch1 step15055 [D loss: -0.218637] [G loss: 1.497576]\n",
      "epoch1 step15060 [D loss: -0.205648] [G loss: 1.710680]\n",
      "epoch1 step15065 [D loss: -0.265721] [G loss: 1.187929]\n",
      "epoch1 step15070 [D loss: 0.148378] [G loss: 1.078588]\n",
      "epoch1 step15075 [D loss: 0.398957] [G loss: 1.308179]\n",
      "epoch1 step15080 [D loss: 0.082498] [G loss: 1.401225]\n",
      "epoch1 step15085 [D loss: 0.414275] [G loss: 1.251450]\n",
      "epoch1 step15090 [D loss: 0.147120] [G loss: 1.721632]\n",
      "epoch1 step15095 [D loss: 0.022605] [G loss: 1.491904]\n",
      "epoch1 step15100 [D loss: -0.322803] [G loss: 1.195867]\n",
      "epoch1 step15105 [D loss: 0.056554] [G loss: 1.161958]\n",
      "epoch1 step15110 [D loss: -0.669103] [G loss: 1.255782]\n",
      "epoch1 step15115 [D loss: -0.300022] [G loss: 1.163756]\n",
      "epoch1 step15120 [D loss: -0.156715] [G loss: 0.858245]\n",
      "epoch1 step15125 [D loss: -0.447960] [G loss: 1.164069]\n",
      "epoch1 step15130 [D loss: 0.159762] [G loss: 0.820011]\n",
      "epoch1 step15135 [D loss: -0.321857] [G loss: 1.037254]\n",
      "epoch1 step15140 [D loss: -0.067240] [G loss: 0.842791]\n",
      "epoch1 step15145 [D loss: -0.119644] [G loss: 1.018017]\n",
      "epoch1 step15150 [D loss: 0.302451] [G loss: 0.835782]\n",
      "epoch1 step15155 [D loss: -0.165249] [G loss: 0.869775]\n",
      "epoch1 step15160 [D loss: -0.022466] [G loss: 0.761257]\n",
      "epoch1 step15165 [D loss: 0.018798] [G loss: 0.579779]\n",
      "epoch1 step15170 [D loss: -0.142143] [G loss: 0.582174]\n",
      "epoch1 step15175 [D loss: -0.478152] [G loss: 1.080698]\n",
      "epoch1 step15180 [D loss: 0.172231] [G loss: 0.386735]\n",
      "epoch1 step15185 [D loss: -0.019114] [G loss: 0.867113]\n",
      "epoch1 step15190 [D loss: -0.033800] [G loss: 0.449604]\n",
      "epoch1 step15195 [D loss: -0.219374] [G loss: 0.397142]\n",
      "epoch1 step15200 [D loss: -0.083162] [G loss: 0.783445]\n",
      "epoch1 step15205 [D loss: -0.124223] [G loss: 0.520957]\n",
      "epoch1 step15210 [D loss: 0.050898] [G loss: 0.940443]\n",
      "epoch1 step15215 [D loss: 0.385615] [G loss: 0.355196]\n",
      "epoch1 step15220 [D loss: 0.006497] [G loss: 0.651231]\n",
      "epoch1 step15225 [D loss: 0.262582] [G loss: 0.760444]\n",
      "epoch1 step15230 [D loss: 0.089584] [G loss: 0.670149]\n",
      "epoch1 step15235 [D loss: -0.169339] [G loss: 0.596098]\n",
      "epoch1 step15240 [D loss: -0.383150] [G loss: 0.938540]\n",
      "epoch1 step15245 [D loss: 0.367656] [G loss: 0.371874]\n",
      "epoch1 step15250 [D loss: -0.072933] [G loss: 0.872827]\n",
      "epoch1 step15255 [D loss: 0.282291] [G loss: 0.434091]\n",
      "epoch1 step15260 [D loss: 0.137568] [G loss: 0.341020]\n",
      "epoch1 step15265 [D loss: 0.024713] [G loss: 0.561871]\n",
      "epoch1 step15270 [D loss: 0.164007] [G loss: 0.334372]\n",
      "epoch1 step15275 [D loss: -0.481073] [G loss: 0.909312]\n",
      "epoch1 step15280 [D loss: 0.326480] [G loss: 0.448916]\n",
      "epoch1 step15285 [D loss: 0.197519] [G loss: 0.257901]\n",
      "epoch1 step15290 [D loss: 0.276283] [G loss: 0.117805]\n",
      "epoch1 step15295 [D loss: 0.102556] [G loss: 0.603280]\n",
      "epoch1 step15300 [D loss: 0.220818] [G loss: 0.477253]\n",
      "epoch1 step15305 [D loss: -0.012072] [G loss: 0.500224]\n",
      "epoch1 step15310 [D loss: 0.115467] [G loss: 0.638961]\n",
      "epoch1 step15315 [D loss: 0.282531] [G loss: 0.574263]\n",
      "epoch1 step15320 [D loss: -0.138063] [G loss: 0.525747]\n",
      "epoch1 step15325 [D loss: -0.220505] [G loss: 0.735384]\n",
      "epoch1 step15330 [D loss: -0.165275] [G loss: 0.892632]\n",
      "epoch1 step15335 [D loss: 0.206433] [G loss: 0.864048]\n",
      "epoch1 step15340 [D loss: 0.039334] [G loss: 0.460325]\n",
      "epoch1 step15345 [D loss: -0.058650] [G loss: 0.801761]\n",
      "epoch1 step15350 [D loss: -0.484842] [G loss: 0.907331]\n",
      "epoch1 step15355 [D loss: 0.142574] [G loss: 0.683405]\n",
      "epoch1 step15360 [D loss: 0.008958] [G loss: 0.809099]\n",
      "epoch1 step15365 [D loss: -0.561086] [G loss: 0.536770]\n",
      "epoch1 step15370 [D loss: 0.130952] [G loss: 0.407726]\n",
      "epoch1 step15375 [D loss: -0.269169] [G loss: 0.535088]\n",
      "epoch1 step15380 [D loss: 0.246667] [G loss: 0.669797]\n",
      "epoch1 step15385 [D loss: 0.179861] [G loss: 0.373170]\n",
      "epoch1 step15390 [D loss: -0.265030] [G loss: 0.638008]\n",
      "epoch1 step15395 [D loss: -0.034537] [G loss: 0.583371]\n",
      "epoch1 step15400 [D loss: 0.225845] [G loss: 0.698982]\n",
      "epoch1 step15405 [D loss: -0.078384] [G loss: 0.612460]\n",
      "epoch1 step15410 [D loss: -0.276853] [G loss: 0.570910]\n",
      "epoch1 step15415 [D loss: -0.214193] [G loss: 0.364641]\n",
      "epoch1 step15420 [D loss: 0.133851] [G loss: 0.646373]\n",
      "epoch1 step15425 [D loss: 0.549593] [G loss: 0.807790]\n",
      "epoch1 step15430 [D loss: 0.127983] [G loss: 0.704627]\n",
      "epoch1 step15435 [D loss: -0.170429] [G loss: 0.385596]\n",
      "epoch1 step15440 [D loss: -0.148586] [G loss: 0.377537]\n",
      "epoch1 step15445 [D loss: 0.068316] [G loss: 0.368390]\n",
      "epoch1 step15450 [D loss: -0.074567] [G loss: 0.630902]\n",
      "epoch1 step15455 [D loss: -0.256157] [G loss: 0.779109]\n",
      "epoch1 step15460 [D loss: -0.296245] [G loss: 0.626194]\n",
      "epoch1 step15465 [D loss: -0.182319] [G loss: 0.679391]\n",
      "epoch1 step15470 [D loss: -0.183141] [G loss: 0.811683]\n",
      "epoch1 step15475 [D loss: -0.162559] [G loss: 0.696408]\n",
      "epoch1 step15480 [D loss: -0.037869] [G loss: 0.747672]\n",
      "epoch1 step15485 [D loss: -0.006956] [G loss: 0.969517]\n",
      "epoch1 step15490 [D loss: -0.559894] [G loss: 0.953528]\n",
      "epoch1 step15495 [D loss: -0.300716] [G loss: 0.589937]\n",
      "epoch1 step15500 [D loss: -0.139849] [G loss: 0.525266]\n",
      "epoch1 step15505 [D loss: 0.086753] [G loss: 0.736831]\n",
      "epoch1 step15510 [D loss: 0.053699] [G loss: 0.862018]\n",
      "epoch1 step15515 [D loss: 0.303936] [G loss: 0.715802]\n",
      "epoch1 step15520 [D loss: 0.051594] [G loss: 0.735857]\n",
      "epoch1 step15525 [D loss: -0.195763] [G loss: 0.810959]\n",
      "epoch1 step15530 [D loss: 0.018892] [G loss: 0.726715]\n",
      "epoch1 step15535 [D loss: -0.487073] [G loss: 0.634552]\n",
      "epoch1 step15540 [D loss: 0.111294] [G loss: 0.558879]\n",
      "epoch1 step15545 [D loss: -0.175842] [G loss: 0.889815]\n",
      "epoch1 step15550 [D loss: 0.196885] [G loss: 0.880215]\n",
      "epoch1 step15555 [D loss: -0.189268] [G loss: 0.829702]\n",
      "epoch1 step15560 [D loss: -0.106556] [G loss: 0.532073]\n",
      "epoch1 step15565 [D loss: -0.103381] [G loss: 1.179783]\n",
      "epoch1 step15570 [D loss: -0.210325] [G loss: 0.765986]\n",
      "epoch1 step15575 [D loss: -0.102166] [G loss: 0.625593]\n",
      "epoch1 step15580 [D loss: 0.009053] [G loss: 1.012779]\n",
      "epoch1 step15585 [D loss: 0.344469] [G loss: 0.913428]\n",
      "epoch1 step15590 [D loss: 0.005235] [G loss: 0.945188]\n",
      "epoch1 step15595 [D loss: 0.101974] [G loss: 1.130684]\n",
      "epoch1 step15600 [D loss: -0.142986] [G loss: 0.844138]\n",
      "epoch1 step15605 [D loss: -0.563719] [G loss: 0.842576]\n",
      "epoch1 step15610 [D loss: 0.214530] [G loss: 0.785574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 step15615 [D loss: 0.141272] [G loss: 1.062735]\n",
      "epoch1 step15620 [D loss: 0.132101] [G loss: 0.995916]\n",
      "epoch2 step15625 [D loss: -0.169267] [G loss: 0.864760]\n",
      "epoch2 step15630 [D loss: 0.396851] [G loss: 0.867807]\n",
      "epoch2 step15635 [D loss: 0.371319] [G loss: 0.842570]\n",
      "epoch2 step15640 [D loss: -0.156321] [G loss: 0.841383]\n",
      "epoch2 step15645 [D loss: 0.472179] [G loss: 1.043307]\n",
      "epoch2 step15650 [D loss: 0.333164] [G loss: 1.175673]\n",
      "epoch2 step15655 [D loss: -0.146393] [G loss: 1.138987]\n",
      "epoch2 step15660 [D loss: 0.107303] [G loss: 0.502041]\n",
      "epoch2 step15665 [D loss: 0.017970] [G loss: 1.034958]\n",
      "epoch2 step15670 [D loss: 0.099084] [G loss: 1.159620]\n",
      "epoch2 step15675 [D loss: -0.271117] [G loss: 1.054074]\n",
      "epoch2 step15680 [D loss: -0.173208] [G loss: 0.981142]\n",
      "epoch2 step15685 [D loss: -0.336624] [G loss: 1.023591]\n",
      "epoch2 step15690 [D loss: -0.026271] [G loss: 1.020261]\n",
      "epoch2 step15695 [D loss: 0.101606] [G loss: 0.737261]\n",
      "epoch2 step15700 [D loss: -0.241176] [G loss: 1.189095]\n",
      "epoch2 step15705 [D loss: 0.205505] [G loss: 1.085092]\n",
      "epoch2 step15710 [D loss: -0.130641] [G loss: 1.201042]\n",
      "epoch2 step15715 [D loss: 0.094156] [G loss: 1.022879]\n",
      "epoch2 step15720 [D loss: -0.066229] [G loss: 1.102624]\n",
      "epoch2 step15725 [D loss: 0.066197] [G loss: 1.222729]\n",
      "epoch2 step15730 [D loss: 0.088027] [G loss: 0.876016]\n",
      "epoch2 step15735 [D loss: -0.085341] [G loss: 1.033484]\n",
      "epoch2 step15740 [D loss: -0.025151] [G loss: 1.112799]\n",
      "epoch2 step15745 [D loss: -0.212501] [G loss: 0.874914]\n",
      "epoch2 step15750 [D loss: 0.172570] [G loss: 1.269349]\n",
      "epoch2 step15755 [D loss: 0.035713] [G loss: 1.049201]\n",
      "epoch2 step15760 [D loss: 0.493838] [G loss: 0.911083]\n",
      "epoch2 step15765 [D loss: -0.077345] [G loss: 1.035156]\n",
      "epoch2 step15770 [D loss: -0.426598] [G loss: 1.215530]\n",
      "epoch2 step15775 [D loss: 0.273031] [G loss: 0.927113]\n",
      "epoch2 step15780 [D loss: 0.248601] [G loss: 0.776274]\n",
      "epoch2 step15785 [D loss: -0.431253] [G loss: 0.855685]\n",
      "epoch2 step15790 [D loss: -0.002744] [G loss: 0.860951]\n",
      "epoch2 step15795 [D loss: -0.140465] [G loss: 0.889637]\n",
      "epoch2 step15800 [D loss: 0.020308] [G loss: 1.094762]\n",
      "epoch2 step15805 [D loss: -0.216868] [G loss: 0.980882]\n",
      "epoch2 step15810 [D loss: 0.121412] [G loss: 0.723753]\n",
      "epoch2 step15815 [D loss: 0.144334] [G loss: 1.152415]\n",
      "epoch2 step15820 [D loss: -0.087621] [G loss: 0.947060]\n",
      "epoch2 step15825 [D loss: 0.318219] [G loss: 0.612418]\n",
      "epoch2 step15830 [D loss: 0.108667] [G loss: 1.082471]\n",
      "epoch2 step15835 [D loss: 0.024782] [G loss: 1.079928]\n",
      "epoch2 step15840 [D loss: 0.420051] [G loss: 1.028060]\n",
      "epoch2 step15845 [D loss: -0.132387] [G loss: 0.737151]\n",
      "epoch2 step15850 [D loss: -0.160124] [G loss: 0.794746]\n",
      "epoch2 step15855 [D loss: -0.120529] [G loss: 0.696188]\n",
      "epoch2 step15860 [D loss: -0.155425] [G loss: 0.645377]\n",
      "epoch2 step15865 [D loss: 0.206026] [G loss: 0.899771]\n",
      "epoch2 step15870 [D loss: -0.245499] [G loss: 0.826078]\n",
      "epoch2 step15875 [D loss: -0.001566] [G loss: 0.822952]\n",
      "epoch2 step15880 [D loss: 0.065498] [G loss: 0.638959]\n",
      "epoch2 step15885 [D loss: -0.309417] [G loss: 1.080438]\n",
      "epoch2 step15890 [D loss: -0.238128] [G loss: 0.749611]\n",
      "epoch2 step15895 [D loss: 0.407832] [G loss: 0.983773]\n",
      "epoch2 step15900 [D loss: -0.232692] [G loss: 0.717076]\n",
      "epoch2 step15905 [D loss: -0.229327] [G loss: 1.014299]\n",
      "epoch2 step15910 [D loss: 0.083323] [G loss: 0.802547]\n",
      "epoch2 step15915 [D loss: 0.152314] [G loss: 0.858807]\n",
      "epoch2 step15920 [D loss: -0.069033] [G loss: 0.643605]\n",
      "epoch2 step15925 [D loss: 0.419245] [G loss: 0.623975]\n",
      "epoch2 step15930 [D loss: -0.161813] [G loss: 1.016288]\n",
      "epoch2 step15935 [D loss: 0.013164] [G loss: 1.034142]\n",
      "epoch2 step15940 [D loss: -0.055788] [G loss: 0.523451]\n",
      "epoch2 step15945 [D loss: 0.170163] [G loss: 0.778781]\n",
      "epoch2 step15950 [D loss: -0.004221] [G loss: 0.858974]\n",
      "epoch2 step15955 [D loss: 0.286135] [G loss: 0.948222]\n",
      "epoch2 step15960 [D loss: 0.352110] [G loss: 0.585285]\n",
      "epoch2 step15965 [D loss: 0.131965] [G loss: 0.994124]\n",
      "epoch2 step15970 [D loss: 0.115269] [G loss: 0.747648]\n",
      "epoch2 step15975 [D loss: -0.573248] [G loss: 0.693869]\n",
      "epoch2 step15980 [D loss: 0.178683] [G loss: 0.749344]\n",
      "epoch2 step15985 [D loss: -0.225739] [G loss: 0.788408]\n",
      "epoch2 step15990 [D loss: -0.098079] [G loss: 0.691694]\n",
      "epoch2 step15995 [D loss: -0.301421] [G loss: 0.888853]\n",
      "epoch2 step16000 [D loss: -0.229168] [G loss: 0.807061]\n",
      "epoch2 step16005 [D loss: 0.116579] [G loss: 0.947245]\n",
      "epoch2 step16010 [D loss: -0.033303] [G loss: 0.819988]\n",
      "epoch2 step16015 [D loss: -0.018710] [G loss: 0.737033]\n",
      "epoch2 step16020 [D loss: -0.548490] [G loss: 1.106003]\n",
      "epoch2 step16025 [D loss: 0.318895] [G loss: 0.852821]\n",
      "epoch2 step16030 [D loss: -0.143641] [G loss: 0.936520]\n",
      "epoch2 step16035 [D loss: 0.196681] [G loss: 0.609148]\n",
      "epoch2 step16040 [D loss: -0.233586] [G loss: 1.128127]\n",
      "epoch2 step16045 [D loss: -0.374421] [G loss: 0.877057]\n",
      "epoch2 step16050 [D loss: 0.039039] [G loss: 0.803506]\n",
      "epoch2 step16055 [D loss: -0.005769] [G loss: 1.099118]\n",
      "epoch2 step16060 [D loss: -0.260211] [G loss: 1.038528]\n",
      "epoch2 step16065 [D loss: -0.403177] [G loss: 1.340250]\n",
      "epoch2 step16070 [D loss: -0.094950] [G loss: 0.954952]\n",
      "epoch2 step16075 [D loss: -0.143981] [G loss: 1.011936]\n",
      "epoch2 step16080 [D loss: 0.219630] [G loss: 1.157065]\n",
      "epoch2 step16085 [D loss: -0.047204] [G loss: 0.767540]\n",
      "epoch2 step16090 [D loss: -0.253409] [G loss: 1.132671]\n",
      "epoch2 step16095 [D loss: -0.173621] [G loss: 1.080531]\n",
      "epoch2 step16100 [D loss: 0.080072] [G loss: 1.306093]\n",
      "epoch2 step16105 [D loss: -0.171822] [G loss: 1.144302]\n",
      "epoch2 step16110 [D loss: -0.301036] [G loss: 1.318248]\n",
      "epoch2 step16115 [D loss: 0.020806] [G loss: 0.957345]\n",
      "epoch2 step16120 [D loss: -0.063971] [G loss: 1.076849]\n",
      "epoch2 step16125 [D loss: -0.345906] [G loss: 1.758699]\n",
      "epoch2 step16130 [D loss: 0.010570] [G loss: 1.456479]\n",
      "epoch2 step16135 [D loss: -0.204176] [G loss: 1.585622]\n",
      "epoch2 step16140 [D loss: -0.344921] [G loss: 1.585820]\n",
      "epoch2 step16145 [D loss: -0.116586] [G loss: 1.643180]\n",
      "epoch2 step16150 [D loss: -0.039598] [G loss: 1.755728]\n",
      "epoch2 step16155 [D loss: -0.027961] [G loss: 1.509544]\n",
      "epoch2 step16160 [D loss: -0.041366] [G loss: 1.280973]\n",
      "epoch2 step16165 [D loss: -0.277688] [G loss: 1.435640]\n",
      "epoch2 step16170 [D loss: 0.015300] [G loss: 1.622917]\n",
      "epoch2 step16175 [D loss: -0.039317] [G loss: 1.604903]\n",
      "epoch2 step16180 [D loss: -0.353319] [G loss: 1.825922]\n",
      "epoch2 step16185 [D loss: -0.186418] [G loss: 1.011697]\n",
      "epoch2 step16190 [D loss: -0.085091] [G loss: 1.310102]\n",
      "epoch2 step16195 [D loss: -0.251347] [G loss: 1.323325]\n",
      "epoch2 step16200 [D loss: -0.511738] [G loss: 1.530487]\n",
      "epoch2 step16205 [D loss: -0.072563] [G loss: 1.458421]\n",
      "epoch2 step16210 [D loss: -0.309715] [G loss: 1.562749]\n",
      "epoch2 step16215 [D loss: -0.366277] [G loss: 1.498845]\n",
      "epoch2 step16220 [D loss: -0.472208] [G loss: 1.618265]\n",
      "epoch2 step16225 [D loss: -0.300433] [G loss: 1.355221]\n",
      "epoch2 step16230 [D loss: -0.012633] [G loss: 1.324497]\n",
      "epoch2 step16235 [D loss: 0.330841] [G loss: 1.203840]\n",
      "epoch2 step16240 [D loss: 0.254135] [G loss: 1.332145]\n",
      "epoch2 step16245 [D loss: 0.108079] [G loss: 1.284602]\n",
      "epoch2 step16250 [D loss: -0.545655] [G loss: 0.950232]\n",
      "epoch2 step16255 [D loss: -0.323615] [G loss: 0.970966]\n",
      "epoch2 step16260 [D loss: -0.023297] [G loss: 1.150870]\n",
      "epoch2 step16265 [D loss: -0.168564] [G loss: 1.041364]\n",
      "epoch2 step16270 [D loss: -0.108413] [G loss: 1.191615]\n",
      "epoch2 step16275 [D loss: -0.194263] [G loss: 1.189698]\n",
      "epoch2 step16280 [D loss: 0.258331] [G loss: 1.136804]\n",
      "epoch2 step16285 [D loss: -0.207125] [G loss: 0.875704]\n",
      "epoch2 step16290 [D loss: -0.051795] [G loss: 0.847259]\n",
      "epoch2 step16295 [D loss: 0.165696] [G loss: 0.998904]\n",
      "epoch2 step16300 [D loss: -0.277490] [G loss: 0.861028]\n",
      "epoch2 step16305 [D loss: 0.047816] [G loss: 0.841572]\n",
      "epoch2 step16310 [D loss: -0.450442] [G loss: 0.919909]\n",
      "epoch2 step16315 [D loss: 0.126412] [G loss: 0.630874]\n",
      "epoch2 step16320 [D loss: 0.309232] [G loss: 1.066824]\n",
      "epoch2 step16325 [D loss: -0.262403] [G loss: 0.778326]\n",
      "epoch2 step16330 [D loss: -0.206969] [G loss: 0.927597]\n",
      "epoch2 step16335 [D loss: -0.342615] [G loss: 0.928743]\n",
      "epoch2 step16340 [D loss: 0.033232] [G loss: 0.733703]\n",
      "epoch2 step16345 [D loss: -0.177066] [G loss: 0.961630]\n",
      "epoch2 step16350 [D loss: -0.473257] [G loss: 0.852664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step16355 [D loss: 0.204132] [G loss: 0.458074]\n",
      "epoch2 step16360 [D loss: -0.203968] [G loss: 0.998310]\n",
      "epoch2 step16365 [D loss: -0.189359] [G loss: 0.798762]\n",
      "epoch2 step16370 [D loss: -0.264378] [G loss: 0.720530]\n",
      "epoch2 step16375 [D loss: 0.075750] [G loss: 0.984839]\n",
      "epoch2 step16380 [D loss: -0.040656] [G loss: 0.736215]\n",
      "epoch2 step16385 [D loss: -0.151875] [G loss: 0.907076]\n",
      "epoch2 step16390 [D loss: 0.038031] [G loss: 0.820791]\n",
      "epoch2 step16395 [D loss: -0.400562] [G loss: 1.041426]\n",
      "epoch2 step16400 [D loss: -0.105819] [G loss: 0.543328]\n",
      "epoch2 step16405 [D loss: -0.407150] [G loss: 0.811686]\n",
      "epoch2 step16410 [D loss: 0.184570] [G loss: 1.069662]\n",
      "epoch2 step16415 [D loss: 0.054571] [G loss: 1.160670]\n",
      "epoch2 step16420 [D loss: 0.149417] [G loss: 0.965947]\n",
      "epoch2 step16425 [D loss: -0.011067] [G loss: 0.835195]\n",
      "epoch2 step16430 [D loss: 0.117308] [G loss: 1.067258]\n",
      "epoch2 step16435 [D loss: 0.198113] [G loss: 1.079347]\n",
      "epoch2 step16440 [D loss: 0.135365] [G loss: 0.971168]\n",
      "epoch2 step16445 [D loss: 0.259488] [G loss: 1.135636]\n",
      "epoch2 step16450 [D loss: -0.434537] [G loss: 0.852516]\n",
      "epoch2 step16455 [D loss: -0.155049] [G loss: 0.886494]\n",
      "epoch2 step16460 [D loss: -0.056685] [G loss: 1.162334]\n",
      "epoch2 step16465 [D loss: -0.295545] [G loss: 0.956325]\n",
      "epoch2 step16470 [D loss: -0.336214] [G loss: 0.966332]\n",
      "epoch2 step16475 [D loss: -0.059991] [G loss: 0.978814]\n",
      "epoch2 step16480 [D loss: -0.374055] [G loss: 0.910958]\n",
      "epoch2 step16485 [D loss: -0.088862] [G loss: 0.680990]\n",
      "epoch2 step16490 [D loss: -0.277726] [G loss: 0.936892]\n",
      "epoch2 step16495 [D loss: -0.256200] [G loss: 1.071724]\n",
      "epoch2 step16500 [D loss: -0.417657] [G loss: 0.880714]\n",
      "epoch2 step16505 [D loss: -0.500327] [G loss: 0.724674]\n",
      "epoch2 step16510 [D loss: 0.124458] [G loss: 0.682223]\n",
      "epoch2 step16515 [D loss: 0.225973] [G loss: 1.118101]\n",
      "epoch2 step16520 [D loss: 0.003629] [G loss: 0.890615]\n",
      "epoch2 step16525 [D loss: -0.427299] [G loss: 1.166234]\n",
      "epoch2 step16530 [D loss: -0.082928] [G loss: 0.838026]\n",
      "epoch2 step16535 [D loss: -0.222739] [G loss: 0.761704]\n",
      "epoch2 step16540 [D loss: -0.177051] [G loss: 0.705278]\n",
      "epoch2 step16545 [D loss: 0.175255] [G loss: 0.766165]\n",
      "epoch2 step16550 [D loss: 0.037770] [G loss: 0.902380]\n",
      "epoch2 step16555 [D loss: -0.053111] [G loss: 0.860067]\n",
      "epoch2 step16560 [D loss: 0.286059] [G loss: 0.882139]\n",
      "epoch2 step16565 [D loss: 0.194488] [G loss: 0.682534]\n",
      "epoch2 step16570 [D loss: -0.067476] [G loss: 0.523744]\n",
      "epoch2 step16575 [D loss: -0.066931] [G loss: 1.002121]\n",
      "epoch2 step16580 [D loss: 0.151799] [G loss: 0.913905]\n",
      "epoch2 step16585 [D loss: -0.007093] [G loss: 0.975244]\n",
      "epoch2 step16590 [D loss: 0.035181] [G loss: 1.095388]\n",
      "epoch2 step16595 [D loss: -0.156148] [G loss: 1.026088]\n",
      "epoch2 step16600 [D loss: 0.061004] [G loss: 1.009850]\n",
      "epoch2 step16605 [D loss: -0.189439] [G loss: 1.072098]\n",
      "epoch2 step16610 [D loss: -0.249479] [G loss: 0.628114]\n",
      "epoch2 step16615 [D loss: 0.034029] [G loss: 1.094640]\n",
      "epoch2 step16620 [D loss: 0.007120] [G loss: 0.735000]\n",
      "epoch2 step16625 [D loss: 0.095495] [G loss: 0.673028]\n",
      "epoch2 step16630 [D loss: -0.303418] [G loss: 0.745458]\n",
      "epoch2 step16635 [D loss: -0.277879] [G loss: 0.837033]\n",
      "epoch2 step16640 [D loss: -0.048699] [G loss: 0.804721]\n",
      "epoch2 step16645 [D loss: 0.264033] [G loss: 0.531379]\n",
      "epoch2 step16650 [D loss: -0.117484] [G loss: 1.105811]\n",
      "epoch2 step16655 [D loss: 0.166840] [G loss: 0.898752]\n",
      "epoch2 step16660 [D loss: -0.190554] [G loss: 1.044636]\n",
      "epoch2 step16665 [D loss: -0.204018] [G loss: 0.631328]\n",
      "epoch2 step16670 [D loss: 0.021410] [G loss: 0.899420]\n",
      "epoch2 step16675 [D loss: -0.224508] [G loss: 0.705308]\n",
      "epoch2 step16680 [D loss: -0.183441] [G loss: 0.672999]\n",
      "epoch2 step16685 [D loss: 0.101266] [G loss: 0.396781]\n",
      "epoch2 step16690 [D loss: -0.386618] [G loss: 0.718725]\n",
      "epoch2 step16695 [D loss: -0.080084] [G loss: 0.535808]\n",
      "epoch2 step16700 [D loss: -0.059836] [G loss: 0.669324]\n",
      "epoch2 step16705 [D loss: -0.033091] [G loss: 0.814759]\n",
      "epoch2 step16710 [D loss: -0.018001] [G loss: 0.627082]\n",
      "epoch2 step16715 [D loss: -0.205958] [G loss: 0.566389]\n",
      "epoch2 step16720 [D loss: 0.190172] [G loss: 0.745600]\n",
      "epoch2 step16725 [D loss: 0.088571] [G loss: 0.856750]\n",
      "epoch2 step16730 [D loss: -0.292865] [G loss: 0.658368]\n",
      "epoch2 step16735 [D loss: -0.577594] [G loss: 0.937745]\n",
      "epoch2 step16740 [D loss: -0.189749] [G loss: 0.953330]\n",
      "epoch2 step16745 [D loss: -0.268981] [G loss: 0.741629]\n",
      "epoch2 step16750 [D loss: -0.262020] [G loss: 0.865805]\n",
      "epoch2 step16755 [D loss: 0.017507] [G loss: 0.639190]\n",
      "epoch2 step16760 [D loss: 0.235973] [G loss: 0.921326]\n",
      "epoch2 step16765 [D loss: -0.224362] [G loss: 0.899187]\n",
      "epoch2 step16770 [D loss: -0.054129] [G loss: 1.116551]\n",
      "epoch2 step16775 [D loss: -0.503404] [G loss: 1.107864]\n",
      "epoch2 step16780 [D loss: 0.016227] [G loss: 1.156159]\n",
      "epoch2 step16785 [D loss: -0.201754] [G loss: 1.189841]\n",
      "epoch2 step16790 [D loss: -0.342675] [G loss: 1.451257]\n",
      "epoch2 step16795 [D loss: 0.285936] [G loss: 1.324239]\n",
      "epoch2 step16800 [D loss: -0.223188] [G loss: 1.393447]\n",
      "epoch2 step16805 [D loss: 0.392091] [G loss: 1.208871]\n",
      "epoch2 step16810 [D loss: -0.006397] [G loss: 1.390023]\n",
      "epoch2 step16815 [D loss: 0.040463] [G loss: 1.424201]\n",
      "epoch2 step16820 [D loss: -0.404959] [G loss: 1.756636]\n",
      "epoch2 step16825 [D loss: 0.372967] [G loss: 1.364767]\n",
      "epoch2 step16830 [D loss: -0.083023] [G loss: 1.330773]\n",
      "epoch2 step16835 [D loss: -0.100644] [G loss: 1.049746]\n",
      "epoch2 step16840 [D loss: 0.225279] [G loss: 1.305723]\n",
      "epoch2 step16845 [D loss: 0.096029] [G loss: 1.119624]\n",
      "epoch2 step16850 [D loss: -0.281416] [G loss: 1.250312]\n",
      "epoch2 step16855 [D loss: -0.155405] [G loss: 1.351249]\n",
      "epoch2 step16860 [D loss: 0.189844] [G loss: 1.096792]\n",
      "epoch2 step16865 [D loss: 0.111485] [G loss: 1.451675]\n",
      "epoch2 step16870 [D loss: 0.084286] [G loss: 1.315471]\n",
      "epoch2 step16875 [D loss: 0.029809] [G loss: 1.402917]\n",
      "epoch2 step16880 [D loss: -0.101762] [G loss: 1.401303]\n",
      "epoch2 step16885 [D loss: -0.433740] [G loss: 1.085040]\n",
      "epoch2 step16890 [D loss: 0.177160] [G loss: 1.009005]\n",
      "epoch2 step16895 [D loss: 0.178873] [G loss: 1.105853]\n",
      "epoch2 step16900 [D loss: 0.122370] [G loss: 1.113230]\n",
      "epoch2 step16905 [D loss: 0.189857] [G loss: 0.847949]\n",
      "epoch2 step16910 [D loss: 0.126594] [G loss: 1.015393]\n",
      "epoch2 step16915 [D loss: -0.144700] [G loss: 0.982404]\n",
      "epoch2 step16920 [D loss: -0.366991] [G loss: 0.877413]\n",
      "epoch2 step16925 [D loss: -0.218280] [G loss: 0.733696]\n",
      "epoch2 step16930 [D loss: 0.052154] [G loss: 1.148804]\n",
      "epoch2 step16935 [D loss: 0.255520] [G loss: 0.970859]\n",
      "epoch2 step16940 [D loss: 0.179233] [G loss: 0.605329]\n",
      "epoch2 step16945 [D loss: 0.117201] [G loss: 0.559227]\n",
      "epoch2 step16950 [D loss: -0.102903] [G loss: 0.791782]\n",
      "epoch2 step16955 [D loss: 0.265481] [G loss: 0.844466]\n",
      "epoch2 step16960 [D loss: -0.345333] [G loss: 0.442151]\n",
      "epoch2 step16965 [D loss: 0.181729] [G loss: 0.594951]\n",
      "epoch2 step16970 [D loss: 0.080927] [G loss: 0.521918]\n",
      "epoch2 step16975 [D loss: -0.537419] [G loss: 0.746143]\n",
      "epoch2 step16980 [D loss: 0.373082] [G loss: 0.776498]\n",
      "epoch2 step16985 [D loss: 0.021300] [G loss: 0.742556]\n",
      "epoch2 step16990 [D loss: 0.178207] [G loss: 0.505815]\n",
      "epoch2 step16995 [D loss: -0.012463] [G loss: 0.436079]\n",
      "epoch2 step17000 [D loss: 0.376575] [G loss: 0.575349]\n",
      "epoch2 step17005 [D loss: -0.296260] [G loss: 0.601604]\n",
      "epoch2 step17010 [D loss: -0.042674] [G loss: 0.501286]\n",
      "epoch2 step17015 [D loss: 0.238831] [G loss: 0.306142]\n",
      "epoch2 step17020 [D loss: -0.386572] [G loss: 0.502622]\n",
      "epoch2 step17025 [D loss: -0.763173] [G loss: 0.474753]\n",
      "epoch2 step17030 [D loss: 0.239350] [G loss: 0.587005]\n",
      "epoch2 step17035 [D loss: -0.323958] [G loss: 0.528375]\n",
      "epoch2 step17040 [D loss: -0.352521] [G loss: 0.533499]\n",
      "epoch2 step17045 [D loss: 0.028310] [G loss: 0.674430]\n",
      "epoch2 step17050 [D loss: 0.033953] [G loss: 0.360207]\n",
      "epoch2 step17055 [D loss: 0.060192] [G loss: 0.709355]\n",
      "epoch2 step17060 [D loss: 0.043259] [G loss: 0.268888]\n",
      "epoch2 step17065 [D loss: -0.184486] [G loss: 0.238677]\n",
      "epoch2 step17070 [D loss: -0.264083] [G loss: 0.246555]\n",
      "epoch2 step17075 [D loss: -0.332085] [G loss: 0.348010]\n",
      "epoch2 step17080 [D loss: -0.132767] [G loss: 0.277622]\n",
      "epoch2 step17085 [D loss: -0.110102] [G loss: 0.265108]\n",
      "epoch2 step17090 [D loss: 0.078418] [G loss: 0.383756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step17095 [D loss: -0.296246] [G loss: 0.378961]\n",
      "epoch2 step17100 [D loss: -0.095767] [G loss: 0.431739]\n",
      "epoch2 step17105 [D loss: -0.038099] [G loss: 0.272049]\n",
      "epoch2 step17110 [D loss: -0.496859] [G loss: 0.166726]\n",
      "epoch2 step17115 [D loss: 0.206260] [G loss: 0.219239]\n",
      "epoch2 step17120 [D loss: 0.317225] [G loss: 0.368446]\n",
      "epoch2 step17125 [D loss: 0.009196] [G loss: 0.233067]\n",
      "epoch2 step17130 [D loss: -0.298909] [G loss: 0.339464]\n",
      "epoch2 step17135 [D loss: 0.021764] [G loss: 0.349263]\n",
      "epoch2 step17140 [D loss: -0.650696] [G loss: 0.842078]\n",
      "epoch2 step17145 [D loss: 0.184167] [G loss: 0.478865]\n",
      "epoch2 step17150 [D loss: 0.046937] [G loss: 0.302454]\n",
      "epoch2 step17155 [D loss: -0.024176] [G loss: 0.555489]\n",
      "epoch2 step17160 [D loss: 0.008862] [G loss: 0.646838]\n",
      "epoch2 step17165 [D loss: -0.083294] [G loss: 0.271331]\n",
      "epoch2 step17170 [D loss: -0.447587] [G loss: 0.454187]\n",
      "epoch2 step17175 [D loss: 0.163539] [G loss: 0.212411]\n",
      "epoch2 step17180 [D loss: -0.182755] [G loss: 0.850559]\n",
      "epoch2 step17185 [D loss: -0.201315] [G loss: 0.698241]\n",
      "epoch2 step17190 [D loss: -0.495451] [G loss: 0.697364]\n",
      "epoch2 step17195 [D loss: -0.293589] [G loss: 0.562152]\n",
      "epoch2 step17200 [D loss: -0.638475] [G loss: 0.722335]\n",
      "epoch2 step17205 [D loss: -0.553830] [G loss: 0.879412]\n",
      "epoch2 step17210 [D loss: -0.150268] [G loss: 0.497888]\n",
      "epoch2 step17215 [D loss: -0.541787] [G loss: 0.698324]\n",
      "epoch2 step17220 [D loss: 0.001970] [G loss: 0.886181]\n",
      "epoch2 step17225 [D loss: -0.244836] [G loss: 0.996480]\n",
      "epoch2 step17230 [D loss: -0.087233] [G loss: 0.695461]\n",
      "epoch2 step17235 [D loss: 0.039972] [G loss: 0.559041]\n",
      "epoch2 step17240 [D loss: -0.038430] [G loss: 0.356753]\n",
      "epoch2 step17245 [D loss: -0.050027] [G loss: 0.398908]\n",
      "epoch2 step17250 [D loss: -0.297541] [G loss: 0.580203]\n",
      "epoch2 step17255 [D loss: 0.007065] [G loss: 0.734309]\n",
      "epoch2 step17260 [D loss: -0.454900] [G loss: 0.647453]\n",
      "epoch2 step17265 [D loss: -0.526853] [G loss: 0.532660]\n",
      "epoch2 step17270 [D loss: -0.476435] [G loss: 0.908535]\n",
      "epoch2 step17275 [D loss: -0.040513] [G loss: 0.724500]\n",
      "epoch2 step17280 [D loss: 0.607351] [G loss: 0.675640]\n",
      "epoch2 step17285 [D loss: 0.030526] [G loss: 0.787484]\n",
      "epoch2 step17290 [D loss: 0.403826] [G loss: 0.667890]\n",
      "epoch2 step17295 [D loss: -0.385218] [G loss: 0.950944]\n",
      "epoch2 step17300 [D loss: 0.460044] [G loss: 0.710098]\n",
      "epoch2 step17305 [D loss: 0.153908] [G loss: 0.923744]\n",
      "epoch2 step17310 [D loss: 0.067959] [G loss: 0.625869]\n",
      "epoch2 step17315 [D loss: -0.446552] [G loss: 0.894373]\n",
      "epoch2 step17320 [D loss: -0.194297] [G loss: 0.763075]\n",
      "epoch2 step17325 [D loss: -0.205181] [G loss: 1.234776]\n",
      "epoch2 step17330 [D loss: -0.249739] [G loss: 0.909283]\n",
      "epoch2 step17335 [D loss: -0.431521] [G loss: 1.048382]\n",
      "epoch2 step17340 [D loss: 0.262482] [G loss: 0.940592]\n",
      "epoch2 step17345 [D loss: -0.242791] [G loss: 1.106104]\n",
      "epoch2 step17350 [D loss: 0.224641] [G loss: 1.058567]\n",
      "epoch2 step17355 [D loss: -0.032160] [G loss: 0.936613]\n",
      "epoch2 step17360 [D loss: -0.074963] [G loss: 1.219538]\n",
      "epoch2 step17365 [D loss: 0.502349] [G loss: 1.140865]\n",
      "epoch2 step17370 [D loss: -0.265433] [G loss: 1.097657]\n",
      "epoch2 step17375 [D loss: -0.155250] [G loss: 0.913733]\n",
      "epoch2 step17380 [D loss: -0.590127] [G loss: 1.195422]\n",
      "epoch2 step17385 [D loss: -0.086391] [G loss: 1.336426]\n",
      "epoch2 step17390 [D loss: 0.279260] [G loss: 1.430256]\n",
      "epoch2 step17395 [D loss: -0.434146] [G loss: 1.350689]\n",
      "epoch2 step17400 [D loss: 0.055597] [G loss: 1.349877]\n",
      "epoch2 step17405 [D loss: 0.081313] [G loss: 0.830437]\n",
      "epoch2 step17410 [D loss: -0.239304] [G loss: 0.724908]\n",
      "epoch2 step17415 [D loss: -0.285338] [G loss: 1.284889]\n",
      "epoch2 step17420 [D loss: -0.431049] [G loss: 1.253239]\n",
      "epoch2 step17425 [D loss: -0.532841] [G loss: 1.146587]\n",
      "epoch2 step17430 [D loss: -0.034714] [G loss: 1.297467]\n",
      "epoch2 step17435 [D loss: -0.103883] [G loss: 1.132051]\n",
      "epoch2 step17440 [D loss: -0.059692] [G loss: 0.967496]\n",
      "epoch2 step17445 [D loss: -0.666444] [G loss: 1.140062]\n",
      "epoch2 step17450 [D loss: -0.173832] [G loss: 1.200348]\n",
      "epoch2 step17455 [D loss: -0.231601] [G loss: 0.833941]\n",
      "epoch2 step17460 [D loss: -0.134018] [G loss: 1.049944]\n",
      "epoch2 step17465 [D loss: -0.053801] [G loss: 1.022121]\n",
      "epoch2 step17470 [D loss: 0.511446] [G loss: 0.735759]\n",
      "epoch2 step17475 [D loss: -0.409099] [G loss: 1.194612]\n",
      "epoch2 step17480 [D loss: 0.317154] [G loss: 1.082392]\n",
      "epoch2 step17485 [D loss: -0.246673] [G loss: 0.891674]\n",
      "epoch2 step17490 [D loss: 0.109525] [G loss: 1.003566]\n",
      "epoch2 step17495 [D loss: 0.139176] [G loss: 1.232774]\n",
      "epoch2 step17500 [D loss: -0.169187] [G loss: 0.950894]\n",
      "epoch2 step17505 [D loss: 0.012699] [G loss: 1.270057]\n",
      "epoch2 step17510 [D loss: 0.040402] [G loss: 1.081874]\n",
      "epoch2 step17515 [D loss: -0.158940] [G loss: 0.837581]\n",
      "epoch2 step17520 [D loss: 0.074997] [G loss: 0.843320]\n",
      "epoch2 step17525 [D loss: 0.020694] [G loss: 0.766422]\n",
      "epoch2 step17530 [D loss: -0.133286] [G loss: 0.886444]\n",
      "epoch2 step17535 [D loss: 0.234766] [G loss: 0.990390]\n",
      "epoch2 step17540 [D loss: 0.097999] [G loss: 0.935614]\n",
      "epoch2 step17545 [D loss: -0.139277] [G loss: 0.959869]\n",
      "epoch2 step17550 [D loss: -0.243650] [G loss: 1.220572]\n",
      "epoch2 step17555 [D loss: 0.281820] [G loss: 1.007408]\n",
      "epoch2 step17560 [D loss: 0.048478] [G loss: 1.103383]\n",
      "epoch2 step17565 [D loss: -0.381216] [G loss: 1.080876]\n",
      "epoch2 step17570 [D loss: -0.095100] [G loss: 1.358019]\n",
      "epoch2 step17575 [D loss: 0.020368] [G loss: 1.046428]\n",
      "epoch2 step17580 [D loss: -0.114538] [G loss: 1.269661]\n",
      "epoch2 step17585 [D loss: 0.423613] [G loss: 1.268367]\n",
      "epoch2 step17590 [D loss: 0.143697] [G loss: 1.128611]\n",
      "epoch2 step17595 [D loss: -0.226782] [G loss: 1.437338]\n",
      "epoch2 step17600 [D loss: -0.344297] [G loss: 1.163461]\n",
      "epoch2 step17605 [D loss: 0.167928] [G loss: 1.313611]\n",
      "epoch2 step17610 [D loss: -0.396502] [G loss: 1.219648]\n",
      "epoch2 step17615 [D loss: -0.052079] [G loss: 1.364287]\n",
      "epoch2 step17620 [D loss: 0.355245] [G loss: 0.926881]\n",
      "epoch2 step17625 [D loss: -0.384515] [G loss: 1.154148]\n",
      "epoch2 step17630 [D loss: -0.357462] [G loss: 1.461764]\n",
      "epoch2 step17635 [D loss: 0.123270] [G loss: 1.168985]\n",
      "epoch2 step17640 [D loss: -0.149868] [G loss: 0.931788]\n",
      "epoch2 step17645 [D loss: -0.483516] [G loss: 0.949675]\n",
      "epoch2 step17650 [D loss: -0.019639] [G loss: 0.937804]\n",
      "epoch2 step17655 [D loss: -0.063280] [G loss: 0.731071]\n",
      "epoch2 step17660 [D loss: -0.013613] [G loss: 0.456283]\n",
      "epoch2 step17665 [D loss: -0.157223] [G loss: 0.649066]\n",
      "epoch2 step17670 [D loss: 0.000469] [G loss: 0.653819]\n",
      "epoch2 step17675 [D loss: 0.083650] [G loss: 0.527599]\n",
      "epoch2 step17680 [D loss: -0.349687] [G loss: 0.491656]\n",
      "epoch2 step17685 [D loss: -0.590306] [G loss: 0.903876]\n",
      "epoch2 step17690 [D loss: 0.018912] [G loss: 0.751310]\n",
      "epoch2 step17695 [D loss: 0.211458] [G loss: 0.563332]\n",
      "epoch2 step17700 [D loss: -0.163119] [G loss: 0.866999]\n",
      "epoch2 step17705 [D loss: 0.088917] [G loss: 0.392999]\n",
      "epoch2 step17710 [D loss: 0.376710] [G loss: 0.625108]\n",
      "epoch2 step17715 [D loss: -0.218234] [G loss: 0.474150]\n",
      "epoch2 step17720 [D loss: 0.261695] [G loss: 0.821792]\n",
      "epoch2 step17725 [D loss: -0.334381] [G loss: 0.548977]\n",
      "epoch2 step17730 [D loss: 0.400838] [G loss: 0.740366]\n",
      "epoch2 step17735 [D loss: -0.235745] [G loss: 0.624280]\n",
      "epoch2 step17740 [D loss: -0.216989] [G loss: 0.890231]\n",
      "epoch2 step17745 [D loss: 0.141600] [G loss: 0.605392]\n",
      "epoch2 step17750 [D loss: -0.071478] [G loss: 0.360946]\n",
      "epoch2 step17755 [D loss: 0.212679] [G loss: 0.617758]\n",
      "epoch2 step17760 [D loss: -0.252400] [G loss: 0.680450]\n",
      "epoch2 step17765 [D loss: -0.233710] [G loss: 0.449600]\n",
      "epoch2 step17770 [D loss: 0.528463] [G loss: 0.735449]\n",
      "epoch2 step17775 [D loss: 0.074081] [G loss: 0.627114]\n",
      "epoch2 step17780 [D loss: -0.067593] [G loss: 0.863837]\n",
      "epoch2 step17785 [D loss: -0.343436] [G loss: 1.190592]\n",
      "epoch2 step17790 [D loss: -0.271663] [G loss: 1.020155]\n",
      "epoch2 step17795 [D loss: 0.005422] [G loss: 0.654262]\n",
      "epoch2 step17800 [D loss: 0.108912] [G loss: 0.963035]\n",
      "epoch2 step17805 [D loss: -0.399798] [G loss: 1.034471]\n",
      "epoch2 step17810 [D loss: 0.069134] [G loss: 1.315078]\n",
      "epoch2 step17815 [D loss: -0.109242] [G loss: 1.088479]\n",
      "epoch2 step17820 [D loss: -0.096198] [G loss: 1.161414]\n",
      "epoch2 step17825 [D loss: -0.173397] [G loss: 0.892406]\n",
      "epoch2 step17830 [D loss: -0.119703] [G loss: 0.980501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step17835 [D loss: -0.405794] [G loss: 1.142493]\n",
      "epoch2 step17840 [D loss: 0.157537] [G loss: 0.691920]\n",
      "epoch2 step17845 [D loss: -0.176006] [G loss: 1.167035]\n",
      "epoch2 step17850 [D loss: -0.360500] [G loss: 1.215738]\n",
      "epoch2 step17855 [D loss: -0.170050] [G loss: 1.121438]\n",
      "epoch2 step17860 [D loss: -0.273517] [G loss: 1.128100]\n",
      "epoch2 step17865 [D loss: 0.015851] [G loss: 1.384211]\n",
      "epoch2 step17870 [D loss: -0.532804] [G loss: 1.009493]\n",
      "epoch2 step17875 [D loss: -0.110928] [G loss: 1.337228]\n",
      "epoch2 step17880 [D loss: -0.592199] [G loss: 0.967174]\n",
      "epoch2 step17885 [D loss: 0.034082] [G loss: 1.137642]\n",
      "epoch2 step17890 [D loss: -0.066208] [G loss: 0.753408]\n",
      "epoch2 step17895 [D loss: -0.245129] [G loss: 0.900827]\n",
      "epoch2 step17900 [D loss: 0.076651] [G loss: 0.885052]\n",
      "epoch2 step17905 [D loss: -0.159933] [G loss: 1.104578]\n",
      "epoch2 step17910 [D loss: -0.158005] [G loss: 0.792880]\n",
      "epoch2 step17915 [D loss: -0.476996] [G loss: 1.172808]\n",
      "epoch2 step17920 [D loss: -0.121987] [G loss: 1.060414]\n",
      "epoch2 step17925 [D loss: -0.362061] [G loss: 1.101037]\n",
      "epoch2 step17930 [D loss: -0.198410] [G loss: 1.236573]\n",
      "epoch2 step17935 [D loss: 0.151286] [G loss: 1.073672]\n",
      "epoch2 step17940 [D loss: -0.305467] [G loss: 1.119860]\n",
      "epoch2 step17945 [D loss: -0.004345] [G loss: 0.770139]\n",
      "epoch2 step17950 [D loss: 0.212236] [G loss: 0.800835]\n",
      "epoch2 step17955 [D loss: -0.056419] [G loss: 0.797606]\n",
      "epoch2 step17960 [D loss: 0.233213] [G loss: 0.960942]\n",
      "epoch2 step17965 [D loss: 0.010682] [G loss: 1.062934]\n",
      "epoch2 step17970 [D loss: 0.272886] [G loss: 0.925206]\n",
      "epoch2 step17975 [D loss: -0.086061] [G loss: 0.700958]\n",
      "epoch2 step17980 [D loss: -0.145033] [G loss: 0.918856]\n",
      "epoch2 step17985 [D loss: 0.071438] [G loss: 0.943269]\n",
      "epoch2 step17990 [D loss: -0.031614] [G loss: 0.818104]\n",
      "epoch2 step17995 [D loss: 0.147158] [G loss: 1.028531]\n",
      "epoch2 step18000 [D loss: 0.044794] [G loss: 0.816351]\n",
      "epoch2 step18005 [D loss: -0.301171] [G loss: 0.720918]\n",
      "epoch2 step18010 [D loss: 0.022174] [G loss: 0.915331]\n",
      "epoch2 step18015 [D loss: -0.042780] [G loss: 1.140272]\n",
      "epoch2 step18020 [D loss: -0.172259] [G loss: 0.785694]\n",
      "epoch2 step18025 [D loss: -0.023784] [G loss: 0.939023]\n",
      "epoch2 step18030 [D loss: 0.115854] [G loss: 1.159984]\n",
      "epoch2 step18035 [D loss: -0.125545] [G loss: 1.019122]\n",
      "epoch2 step18040 [D loss: -0.214295] [G loss: 0.808729]\n",
      "epoch2 step18045 [D loss: 0.050382] [G loss: 0.892045]\n",
      "epoch2 step18050 [D loss: -0.290646] [G loss: 1.021851]\n",
      "epoch2 step18055 [D loss: 0.018678] [G loss: 0.694152]\n",
      "epoch2 step18060 [D loss: 0.455204] [G loss: 0.925134]\n",
      "epoch2 step18065 [D loss: -0.153004] [G loss: 0.985949]\n",
      "epoch2 step18070 [D loss: -0.006790] [G loss: 0.813169]\n",
      "epoch2 step18075 [D loss: -0.080792] [G loss: 0.810584]\n",
      "epoch2 step18080 [D loss: 0.055599] [G loss: 1.022042]\n",
      "epoch2 step18085 [D loss: 0.444025] [G loss: 1.110271]\n",
      "epoch2 step18090 [D loss: -0.038986] [G loss: 0.840387]\n",
      "epoch2 step18095 [D loss: 0.132549] [G loss: 1.478659]\n",
      "epoch2 step18100 [D loss: 0.141848] [G loss: 1.047314]\n",
      "epoch2 step18105 [D loss: -0.248639] [G loss: 1.172374]\n",
      "epoch2 step18110 [D loss: -0.146283] [G loss: 1.070376]\n",
      "epoch2 step18115 [D loss: -0.211180] [G loss: 1.197140]\n",
      "epoch2 step18120 [D loss: -0.283277] [G loss: 1.403755]\n",
      "epoch2 step18125 [D loss: -0.164647] [G loss: 1.382567]\n",
      "epoch2 step18130 [D loss: -0.086762] [G loss: 1.184062]\n",
      "epoch2 step18135 [D loss: -0.160570] [G loss: 1.420776]\n",
      "epoch2 step18140 [D loss: -0.171500] [G loss: 1.129750]\n",
      "epoch2 step18145 [D loss: -0.131917] [G loss: 1.015015]\n",
      "epoch2 step18150 [D loss: -0.451407] [G loss: 0.971219]\n",
      "epoch2 step18155 [D loss: -0.395906] [G loss: 0.977916]\n",
      "epoch2 step18160 [D loss: -0.014558] [G loss: 1.345329]\n",
      "epoch2 step18165 [D loss: -0.094062] [G loss: 1.168332]\n",
      "epoch2 step18170 [D loss: 0.123663] [G loss: 1.097969]\n",
      "epoch2 step18175 [D loss: -0.097357] [G loss: 1.087139]\n",
      "epoch2 step18180 [D loss: 0.128092] [G loss: 0.915315]\n",
      "epoch2 step18185 [D loss: -0.506975] [G loss: 1.474655]\n",
      "epoch2 step18190 [D loss: -0.192299] [G loss: 1.046600]\n",
      "epoch2 step18195 [D loss: -0.060720] [G loss: 1.181163]\n",
      "epoch2 step18200 [D loss: -0.226020] [G loss: 1.078653]\n",
      "epoch2 step18205 [D loss: -0.229931] [G loss: 0.868777]\n",
      "epoch2 step18210 [D loss: 0.014137] [G loss: 0.896708]\n",
      "epoch2 step18215 [D loss: -0.176186] [G loss: 0.796912]\n",
      "epoch2 step18220 [D loss: 0.294257] [G loss: 0.831715]\n",
      "epoch2 step18225 [D loss: -0.297603] [G loss: 0.923874]\n",
      "epoch2 step18230 [D loss: -0.020150] [G loss: 1.020219]\n",
      "epoch2 step18235 [D loss: -0.573453] [G loss: 0.971904]\n",
      "epoch2 step18240 [D loss: -0.056562] [G loss: 0.697730]\n",
      "epoch2 step18245 [D loss: -0.948298] [G loss: 0.802083]\n",
      "epoch2 step18250 [D loss: 0.110571] [G loss: 0.874349]\n",
      "epoch2 step18255 [D loss: -0.441345] [G loss: 0.457280]\n",
      "epoch2 step18260 [D loss: 0.294501] [G loss: 0.551012]\n",
      "epoch2 step18265 [D loss: -0.362128] [G loss: 0.336678]\n",
      "epoch2 step18270 [D loss: -0.170727] [G loss: 0.638571]\n",
      "epoch2 step18275 [D loss: -0.148795] [G loss: 0.331539]\n",
      "epoch2 step18280 [D loss: -0.179475] [G loss: 0.309478]\n",
      "epoch2 step18285 [D loss: -0.019087] [G loss: 0.378827]\n",
      "epoch2 step18290 [D loss: -0.187382] [G loss: 0.175002]\n",
      "epoch2 step18295 [D loss: -0.259352] [G loss: 0.060155]\n",
      "epoch2 step18300 [D loss: -0.448237] [G loss: 0.260768]\n",
      "epoch2 step18305 [D loss: 0.035682] [G loss: 0.124809]\n",
      "epoch2 step18310 [D loss: -0.103791] [G loss: 0.139913]\n",
      "epoch2 step18315 [D loss: -0.526437] [G loss: 0.255061]\n",
      "epoch2 step18320 [D loss: -0.201609] [G loss: 0.027153]\n",
      "epoch2 step18325 [D loss: -0.459953] [G loss: 0.360650]\n",
      "epoch2 step18330 [D loss: 0.423729] [G loss: -0.408989]\n",
      "epoch2 step18335 [D loss: -0.147469] [G loss: -0.328595]\n",
      "epoch2 step18340 [D loss: -0.136879] [G loss: 0.048177]\n",
      "epoch2 step18345 [D loss: 0.625891] [G loss: -0.252572]\n",
      "epoch2 step18350 [D loss: -0.182691] [G loss: 0.310719]\n",
      "epoch2 step18355 [D loss: 0.089900] [G loss: 0.302311]\n",
      "epoch2 step18360 [D loss: 0.020696] [G loss: -0.162441]\n",
      "epoch2 step18365 [D loss: -0.144244] [G loss: 0.141899]\n",
      "epoch2 step18370 [D loss: -0.264476] [G loss: 0.246579]\n",
      "epoch2 step18375 [D loss: -0.050884] [G loss: 0.385970]\n",
      "epoch2 step18380 [D loss: -0.324760] [G loss: 0.156549]\n",
      "epoch2 step18385 [D loss: -0.011730] [G loss: 0.173847]\n",
      "epoch2 step18390 [D loss: 0.125842] [G loss: 0.228847]\n",
      "epoch2 step18395 [D loss: -0.479131] [G loss: 0.096071]\n",
      "epoch2 step18400 [D loss: 0.148943] [G loss: 0.200864]\n",
      "epoch2 step18405 [D loss: -0.229945] [G loss: 0.606053]\n",
      "epoch2 step18410 [D loss: -0.164648] [G loss: 0.819158]\n",
      "epoch2 step18415 [D loss: -0.355510] [G loss: 0.672200]\n",
      "epoch2 step18420 [D loss: -0.212448] [G loss: 0.669186]\n",
      "epoch2 step18425 [D loss: 0.139647] [G loss: 0.756948]\n",
      "epoch2 step18430 [D loss: -0.234323] [G loss: 0.522447]\n",
      "epoch2 step18435 [D loss: -0.240529] [G loss: 0.759567]\n",
      "epoch2 step18440 [D loss: -0.284525] [G loss: 0.771847]\n",
      "epoch2 step18445 [D loss: -0.147115] [G loss: 1.023986]\n",
      "epoch2 step18450 [D loss: -0.094944] [G loss: 1.034209]\n",
      "epoch2 step18455 [D loss: 0.010703] [G loss: 1.093348]\n",
      "epoch2 step18460 [D loss: -0.636496] [G loss: 1.235527]\n",
      "epoch2 step18465 [D loss: -0.212253] [G loss: 1.460426]\n",
      "epoch2 step18470 [D loss: -0.465574] [G loss: 1.447011]\n",
      "epoch2 step18475 [D loss: 0.218648] [G loss: 1.190130]\n",
      "epoch2 step18480 [D loss: -0.263268] [G loss: 1.491038]\n",
      "epoch2 step18485 [D loss: -0.128517] [G loss: 1.102440]\n",
      "epoch2 step18490 [D loss: -0.418912] [G loss: 1.913005]\n",
      "epoch2 step18495 [D loss: -0.266606] [G loss: 1.373652]\n",
      "epoch2 step18500 [D loss: -0.242539] [G loss: 1.364905]\n",
      "epoch2 step18505 [D loss: 0.013106] [G loss: 1.276645]\n",
      "epoch2 step18510 [D loss: 0.001954] [G loss: 1.333966]\n",
      "epoch2 step18515 [D loss: -0.277171] [G loss: 1.380242]\n",
      "epoch2 step18520 [D loss: -0.050553] [G loss: 1.520091]\n",
      "epoch2 step18525 [D loss: 0.276408] [G loss: 1.610780]\n",
      "epoch2 step18530 [D loss: -0.498138] [G loss: 1.310472]\n",
      "epoch2 step18535 [D loss: 0.214393] [G loss: 1.879997]\n",
      "epoch2 step18540 [D loss: -0.231564] [G loss: 1.485728]\n",
      "epoch2 step18545 [D loss: -0.257709] [G loss: 1.779610]\n",
      "epoch2 step18550 [D loss: -0.134029] [G loss: 1.720165]\n",
      "epoch2 step18555 [D loss: 0.465865] [G loss: 1.506804]\n",
      "epoch2 step18560 [D loss: -0.102644] [G loss: 1.855671]\n",
      "epoch2 step18565 [D loss: -0.195027] [G loss: 1.432518]\n",
      "epoch2 step18570 [D loss: -0.550129] [G loss: 1.804840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step18575 [D loss: -0.229743] [G loss: 1.947159]\n",
      "epoch2 step18580 [D loss: -0.040798] [G loss: 1.485908]\n",
      "epoch2 step18585 [D loss: -0.432265] [G loss: 1.663598]\n",
      "epoch2 step18590 [D loss: 0.231577] [G loss: 1.688530]\n",
      "epoch2 step18595 [D loss: -0.194717] [G loss: 1.257276]\n",
      "epoch2 step18600 [D loss: -0.123191] [G loss: 1.834736]\n",
      "epoch2 step18605 [D loss: 0.135315] [G loss: 1.932824]\n",
      "epoch2 step18610 [D loss: -0.031829] [G loss: 1.637654]\n",
      "epoch2 step18615 [D loss: 0.130749] [G loss: 1.572031]\n",
      "epoch2 step18620 [D loss: 0.091579] [G loss: 1.702277]\n",
      "epoch2 step18625 [D loss: 0.093596] [G loss: 1.763953]\n",
      "epoch2 step18630 [D loss: 0.459424] [G loss: 1.505130]\n",
      "epoch2 step18635 [D loss: -0.163704] [G loss: 1.632936]\n",
      "epoch2 step18640 [D loss: -0.140429] [G loss: 1.287290]\n",
      "epoch2 step18645 [D loss: 0.000477] [G loss: 1.517251]\n",
      "epoch2 step18650 [D loss: -0.508624] [G loss: 1.636286]\n",
      "epoch2 step18655 [D loss: -0.277944] [G loss: 1.654824]\n",
      "epoch2 step18660 [D loss: -0.408514] [G loss: 1.139240]\n",
      "epoch2 step18665 [D loss: -0.001628] [G loss: 1.375304]\n",
      "epoch2 step18670 [D loss: 0.229863] [G loss: 1.543054]\n",
      "epoch2 step18675 [D loss: -0.262715] [G loss: 1.124278]\n",
      "epoch2 step18680 [D loss: 0.026767] [G loss: 1.974984]\n",
      "epoch2 step18685 [D loss: 0.119190] [G loss: 1.246607]\n",
      "epoch2 step18690 [D loss: -0.113016] [G loss: 1.712283]\n",
      "epoch2 step18695 [D loss: -0.175088] [G loss: 1.542416]\n",
      "epoch2 step18700 [D loss: 0.201938] [G loss: 1.366987]\n",
      "epoch2 step18705 [D loss: 0.202794] [G loss: 1.638772]\n",
      "epoch2 step18710 [D loss: 0.089004] [G loss: 1.607983]\n",
      "epoch2 step18715 [D loss: 0.399763] [G loss: 1.464578]\n",
      "epoch2 step18720 [D loss: -0.470801] [G loss: 1.677119]\n",
      "epoch2 step18725 [D loss: -0.183730] [G loss: 1.533066]\n",
      "epoch2 step18730 [D loss: 0.029602] [G loss: 1.244834]\n",
      "epoch2 step18735 [D loss: -0.772376] [G loss: 1.588822]\n",
      "epoch2 step18740 [D loss: -0.064166] [G loss: 1.093632]\n",
      "epoch2 step18745 [D loss: -0.365713] [G loss: 1.536620]\n",
      "epoch2 step18750 [D loss: -0.015737] [G loss: 1.374742]\n",
      "epoch2 step18755 [D loss: -0.080673] [G loss: 1.361790]\n",
      "epoch2 step18760 [D loss: 0.289003] [G loss: 1.949944]\n",
      "epoch2 step18765 [D loss: -0.018103] [G loss: 1.570670]\n",
      "epoch2 step18770 [D loss: -0.389291] [G loss: 1.561844]\n",
      "epoch2 step18775 [D loss: -0.481217] [G loss: 1.755873]\n",
      "epoch2 step18780 [D loss: -0.223183] [G loss: 1.442399]\n",
      "epoch2 step18785 [D loss: 0.028886] [G loss: 1.437154]\n",
      "epoch2 step18790 [D loss: -0.228641] [G loss: 1.577520]\n",
      "epoch2 step18795 [D loss: 0.091315] [G loss: 1.396333]\n",
      "epoch2 step18800 [D loss: -0.702133] [G loss: 1.472641]\n",
      "epoch2 step18805 [D loss: -0.635335] [G loss: 1.357023]\n",
      "epoch2 step18810 [D loss: 0.382111] [G loss: 0.933753]\n",
      "epoch2 step18815 [D loss: -0.381620] [G loss: 1.445015]\n",
      "epoch2 step18820 [D loss: 0.222612] [G loss: 1.060082]\n",
      "epoch2 step18825 [D loss: -0.135640] [G loss: 1.157092]\n",
      "epoch2 step18830 [D loss: -0.031768] [G loss: 0.988177]\n",
      "epoch2 step18835 [D loss: 0.162655] [G loss: 1.141537]\n",
      "epoch2 step18840 [D loss: -0.302825] [G loss: 1.347839]\n",
      "epoch2 step18845 [D loss: -0.425331] [G loss: 0.792096]\n",
      "epoch2 step18850 [D loss: 0.196312] [G loss: 0.959603]\n",
      "epoch2 step18855 [D loss: 0.026560] [G loss: 0.733692]\n",
      "epoch2 step18860 [D loss: -0.416371] [G loss: 1.176588]\n",
      "epoch2 step18865 [D loss: -0.040361] [G loss: 1.227070]\n",
      "epoch2 step18870 [D loss: -0.034036] [G loss: 0.564677]\n",
      "epoch2 step18875 [D loss: -0.461984] [G loss: 0.766972]\n",
      "epoch2 step18880 [D loss: -0.030572] [G loss: 0.314229]\n",
      "epoch2 step18885 [D loss: -0.029842] [G loss: 0.692457]\n",
      "epoch2 step18890 [D loss: 0.183324] [G loss: 0.659787]\n",
      "epoch2 step18895 [D loss: -0.119618] [G loss: 0.908952]\n",
      "epoch2 step18900 [D loss: -0.193684] [G loss: 0.393496]\n",
      "epoch2 step18905 [D loss: 0.060267] [G loss: 0.589546]\n",
      "epoch2 step18910 [D loss: -0.027874] [G loss: 0.451155]\n",
      "epoch2 step18915 [D loss: 0.022124] [G loss: 0.653523]\n",
      "epoch2 step18920 [D loss: 0.055068] [G loss: 0.385766]\n",
      "epoch2 step18925 [D loss: 0.172254] [G loss: 0.489848]\n",
      "epoch2 step18930 [D loss: -0.159834] [G loss: 0.267575]\n",
      "epoch2 step18935 [D loss: 0.229687] [G loss: 0.447234]\n",
      "epoch2 step18940 [D loss: -0.087091] [G loss: 0.579239]\n",
      "epoch2 step18945 [D loss: -0.111515] [G loss: 0.352555]\n",
      "epoch2 step18950 [D loss: -0.040257] [G loss: 0.633779]\n",
      "epoch2 step18955 [D loss: 0.021568] [G loss: 0.538521]\n",
      "epoch2 step18960 [D loss: 0.153300] [G loss: 0.559394]\n",
      "epoch2 step18965 [D loss: -0.147293] [G loss: 0.571172]\n",
      "epoch2 step18970 [D loss: -0.220174] [G loss: 0.824013]\n",
      "epoch2 step18975 [D loss: -0.620989] [G loss: 0.918372]\n",
      "epoch2 step18980 [D loss: 0.058962] [G loss: 0.484762]\n",
      "epoch2 step18985 [D loss: 0.067447] [G loss: 0.861566]\n",
      "epoch2 step18990 [D loss: 0.202484] [G loss: 0.500044]\n",
      "epoch2 step18995 [D loss: 0.107182] [G loss: 0.669191]\n",
      "epoch2 step19000 [D loss: -0.282882] [G loss: 0.752175]\n",
      "epoch2 step19005 [D loss: -0.315860] [G loss: 1.019260]\n",
      "epoch2 step19010 [D loss: -0.519133] [G loss: 0.826798]\n",
      "epoch2 step19015 [D loss: -0.218778] [G loss: 1.264838]\n",
      "epoch2 step19020 [D loss: -0.205838] [G loss: 0.897209]\n",
      "epoch2 step19025 [D loss: -0.064270] [G loss: 1.046381]\n",
      "epoch2 step19030 [D loss: 0.254705] [G loss: 1.274395]\n",
      "epoch2 step19035 [D loss: 0.009578] [G loss: 0.964614]\n",
      "epoch2 step19040 [D loss: -0.561090] [G loss: 0.960128]\n",
      "epoch2 step19045 [D loss: 0.210133] [G loss: 0.684625]\n",
      "epoch2 step19050 [D loss: 0.058894] [G loss: 1.015833]\n",
      "epoch2 step19055 [D loss: 0.191660] [G loss: 1.305874]\n",
      "epoch2 step19060 [D loss: -0.196631] [G loss: 1.269964]\n",
      "epoch2 step19065 [D loss: -0.644490] [G loss: 1.026180]\n",
      "epoch2 step19070 [D loss: -0.431887] [G loss: 1.261049]\n",
      "epoch2 step19075 [D loss: -0.531632] [G loss: 1.374735]\n",
      "epoch2 step19080 [D loss: -0.354159] [G loss: 1.420107]\n",
      "epoch2 step19085 [D loss: -0.072432] [G loss: 1.421296]\n",
      "epoch2 step19090 [D loss: -0.167660] [G loss: 1.277809]\n",
      "epoch2 step19095 [D loss: 0.056213] [G loss: 1.190548]\n",
      "epoch2 step19100 [D loss: -0.041314] [G loss: 1.614097]\n",
      "epoch2 step19105 [D loss: -0.081932] [G loss: 1.450999]\n",
      "epoch2 step19110 [D loss: 0.243299] [G loss: 1.330712]\n",
      "epoch2 step19115 [D loss: 0.114122] [G loss: 1.270400]\n",
      "epoch2 step19120 [D loss: -0.010517] [G loss: 1.395092]\n",
      "epoch2 step19125 [D loss: -0.354291] [G loss: 1.749481]\n",
      "epoch2 step19130 [D loss: -0.331112] [G loss: 1.232501]\n",
      "epoch2 step19135 [D loss: -0.567366] [G loss: 1.488362]\n",
      "epoch2 step19140 [D loss: 0.317663] [G loss: 1.322793]\n",
      "epoch2 step19145 [D loss: -0.200840] [G loss: 1.303229]\n",
      "epoch2 step19150 [D loss: -0.143481] [G loss: 1.419873]\n",
      "epoch2 step19155 [D loss: -0.075419] [G loss: 1.140483]\n",
      "epoch2 step19160 [D loss: -0.186518] [G loss: 1.334511]\n",
      "epoch2 step19165 [D loss: -0.171396] [G loss: 1.249303]\n",
      "epoch2 step19170 [D loss: -0.555889] [G loss: 0.774236]\n",
      "epoch2 step19175 [D loss: -0.157240] [G loss: 1.221461]\n",
      "epoch2 step19180 [D loss: 0.100706] [G loss: 0.896229]\n",
      "epoch2 step19185 [D loss: -0.285991] [G loss: 1.186336]\n",
      "epoch2 step19190 [D loss: -0.597604] [G loss: 1.159501]\n",
      "epoch2 step19195 [D loss: 0.143700] [G loss: 0.938617]\n",
      "epoch2 step19200 [D loss: -0.434264] [G loss: 1.050711]\n",
      "epoch2 step19205 [D loss: -0.301960] [G loss: 1.146837]\n",
      "epoch2 step19210 [D loss: -0.473975] [G loss: 0.975373]\n",
      "epoch2 step19215 [D loss: -0.013772] [G loss: 0.771347]\n",
      "epoch2 step19220 [D loss: 0.250815] [G loss: 0.843978]\n",
      "epoch2 step19225 [D loss: -0.006970] [G loss: 0.828432]\n",
      "epoch2 step19230 [D loss: -0.141006] [G loss: 1.028460]\n",
      "epoch2 step19235 [D loss: -0.174297] [G loss: 0.597349]\n",
      "epoch2 step19240 [D loss: -0.241648] [G loss: 0.711240]\n",
      "epoch2 step19245 [D loss: 0.284352] [G loss: 0.870820]\n",
      "epoch2 step19250 [D loss: -0.219272] [G loss: 0.657899]\n",
      "epoch2 step19255 [D loss: 0.030318] [G loss: 0.641508]\n",
      "epoch2 step19260 [D loss: 0.307754] [G loss: 0.524780]\n",
      "epoch2 step19265 [D loss: 0.239985] [G loss: 0.576827]\n",
      "epoch2 step19270 [D loss: 0.128056] [G loss: 0.655990]\n",
      "epoch2 step19275 [D loss: 0.136907] [G loss: 0.368716]\n",
      "epoch2 step19280 [D loss: 0.012273] [G loss: 0.908582]\n",
      "epoch2 step19285 [D loss: 0.503964] [G loss: 0.652429]\n",
      "epoch2 step19290 [D loss: -0.250548] [G loss: 0.784250]\n",
      "epoch2 step19295 [D loss: -0.103818] [G loss: 0.689849]\n",
      "epoch2 step19300 [D loss: 0.044452] [G loss: 0.601071]\n",
      "epoch2 step19305 [D loss: -0.075950] [G loss: 0.620045]\n",
      "epoch2 step19310 [D loss: 0.201171] [G loss: 0.601378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step19315 [D loss: -0.074881] [G loss: 0.731292]\n",
      "epoch2 step19320 [D loss: -0.074767] [G loss: 0.702855]\n",
      "epoch2 step19325 [D loss: -0.228834] [G loss: 0.780606]\n",
      "epoch2 step19330 [D loss: 0.112718] [G loss: 0.522947]\n",
      "epoch2 step19335 [D loss: -0.051722] [G loss: 0.739139]\n",
      "epoch2 step19340 [D loss: 0.007473] [G loss: 1.095922]\n",
      "epoch2 step19345 [D loss: -0.135749] [G loss: 0.624443]\n",
      "epoch2 step19350 [D loss: -0.057628] [G loss: 0.961199]\n",
      "epoch2 step19355 [D loss: -0.182832] [G loss: 0.687830]\n",
      "epoch2 step19360 [D loss: 0.143357] [G loss: 0.817995]\n",
      "epoch2 step19365 [D loss: -0.364809] [G loss: 0.947596]\n",
      "epoch2 step19370 [D loss: -0.080669] [G loss: 0.801261]\n",
      "epoch2 step19375 [D loss: 0.000650] [G loss: 0.752551]\n",
      "epoch2 step19380 [D loss: -0.408015] [G loss: 0.763511]\n",
      "epoch2 step19385 [D loss: -0.326301] [G loss: 1.145441]\n",
      "epoch2 step19390 [D loss: -0.231899] [G loss: 1.270577]\n",
      "epoch2 step19395 [D loss: -0.153835] [G loss: 1.135476]\n",
      "epoch2 step19400 [D loss: 0.063367] [G loss: 1.071549]\n",
      "epoch2 step19405 [D loss: -0.261671] [G loss: 1.065206]\n",
      "epoch2 step19410 [D loss: 0.198010] [G loss: 1.133324]\n",
      "epoch2 step19415 [D loss: -0.303784] [G loss: 1.110461]\n",
      "epoch2 step19420 [D loss: -0.045466] [G loss: 0.787113]\n",
      "epoch2 step19425 [D loss: 0.205366] [G loss: 1.183112]\n",
      "epoch2 step19430 [D loss: -0.415958] [G loss: 0.772026]\n",
      "epoch2 step19435 [D loss: -0.566203] [G loss: 0.930811]\n",
      "epoch2 step19440 [D loss: -0.025936] [G loss: 1.327420]\n",
      "epoch2 step19445 [D loss: 0.054173] [G loss: 1.259373]\n",
      "epoch2 step19450 [D loss: 0.121728] [G loss: 1.071150]\n",
      "epoch2 step19455 [D loss: -0.082897] [G loss: 1.330782]\n",
      "epoch2 step19460 [D loss: -0.202871] [G loss: 1.285428]\n",
      "epoch2 step19465 [D loss: -0.564345] [G loss: 1.365331]\n",
      "epoch2 step19470 [D loss: -0.237290] [G loss: 1.205735]\n",
      "epoch2 step19475 [D loss: 0.007290] [G loss: 1.136328]\n",
      "epoch2 step19480 [D loss: 0.619061] [G loss: 1.216653]\n",
      "epoch2 step19485 [D loss: 0.153207] [G loss: 1.244917]\n",
      "epoch2 step19490 [D loss: 0.072753] [G loss: 1.001107]\n",
      "epoch2 step19495 [D loss: -0.544124] [G loss: 1.391631]\n",
      "epoch2 step19500 [D loss: -0.703118] [G loss: 1.327180]\n",
      "epoch2 step19505 [D loss: -0.266071] [G loss: 1.232551]\n",
      "epoch2 step19510 [D loss: -0.299842] [G loss: 1.365756]\n",
      "epoch2 step19515 [D loss: -0.779394] [G loss: 1.409411]\n",
      "epoch2 step19520 [D loss: 0.096574] [G loss: 1.227414]\n",
      "epoch2 step19525 [D loss: -0.235195] [G loss: 1.330400]\n",
      "epoch2 step19530 [D loss: -0.011617] [G loss: 1.333908]\n",
      "epoch2 step19535 [D loss: -0.104612] [G loss: 1.075763]\n",
      "epoch2 step19540 [D loss: -0.179007] [G loss: 1.092278]\n",
      "epoch2 step19545 [D loss: -0.092101] [G loss: 0.788971]\n",
      "epoch2 step19550 [D loss: 0.086397] [G loss: 1.341689]\n",
      "epoch2 step19555 [D loss: -0.175490] [G loss: 0.959519]\n",
      "epoch2 step19560 [D loss: -0.012765] [G loss: 1.104647]\n",
      "epoch2 step19565 [D loss: 0.105319] [G loss: 0.880488]\n",
      "epoch2 step19570 [D loss: -0.029321] [G loss: 0.843607]\n",
      "epoch2 step19575 [D loss: -0.466762] [G loss: 0.934838]\n",
      "epoch2 step19580 [D loss: -0.371014] [G loss: 0.897156]\n",
      "epoch2 step19585 [D loss: 0.294708] [G loss: 0.951051]\n",
      "epoch2 step19590 [D loss: -0.039562] [G loss: 0.750670]\n",
      "epoch2 step19595 [D loss: -0.164125] [G loss: 0.658782]\n",
      "epoch2 step19600 [D loss: -0.187506] [G loss: 0.641103]\n",
      "epoch2 step19605 [D loss: -0.011402] [G loss: 1.286595]\n",
      "epoch2 step19610 [D loss: -0.284524] [G loss: 0.629352]\n",
      "epoch2 step19615 [D loss: 0.191933] [G loss: 0.485013]\n",
      "epoch2 step19620 [D loss: 0.234872] [G loss: 0.722554]\n",
      "epoch2 step19625 [D loss: -0.165476] [G loss: 0.503609]\n",
      "epoch2 step19630 [D loss: 0.656631] [G loss: 0.284540]\n",
      "epoch2 step19635 [D loss: 0.141714] [G loss: 0.831694]\n",
      "epoch2 step19640 [D loss: -0.005718] [G loss: 0.525801]\n",
      "epoch2 step19645 [D loss: -0.280527] [G loss: 0.447982]\n",
      "epoch2 step19650 [D loss: -0.120572] [G loss: 0.031592]\n",
      "epoch2 step19655 [D loss: -0.211809] [G loss: 0.218216]\n",
      "epoch2 step19660 [D loss: 0.271457] [G loss: 0.075025]\n",
      "epoch2 step19665 [D loss: -0.028710] [G loss: 0.289352]\n",
      "epoch2 step19670 [D loss: 0.039818] [G loss: 0.611519]\n",
      "epoch2 step19675 [D loss: -0.187154] [G loss: 0.251465]\n",
      "epoch2 step19680 [D loss: -0.178465] [G loss: 0.630291]\n",
      "epoch2 step19685 [D loss: -0.117292] [G loss: 0.396006]\n",
      "epoch2 step19690 [D loss: -0.155992] [G loss: 0.480141]\n",
      "epoch2 step19695 [D loss: 0.128087] [G loss: 0.239241]\n",
      "epoch2 step19700 [D loss: 0.212961] [G loss: 0.304264]\n",
      "epoch2 step19705 [D loss: 0.079910] [G loss: 0.389137]\n",
      "epoch2 step19710 [D loss: -0.007307] [G loss: 0.399529]\n",
      "epoch2 step19715 [D loss: 0.101548] [G loss: 0.276559]\n",
      "epoch2 step19720 [D loss: 0.169085] [G loss: 0.632118]\n",
      "epoch2 step19725 [D loss: 0.420436] [G loss: 0.521567]\n",
      "epoch2 step19730 [D loss: -0.035841] [G loss: 0.697987]\n",
      "epoch2 step19735 [D loss: -0.486385] [G loss: 0.502909]\n",
      "epoch2 step19740 [D loss: 0.204612] [G loss: 0.745337]\n",
      "epoch2 step19745 [D loss: -0.182633] [G loss: 0.558782]\n",
      "epoch2 step19750 [D loss: -0.175987] [G loss: 0.588680]\n",
      "epoch2 step19755 [D loss: -0.326860] [G loss: 0.497709]\n",
      "epoch2 step19760 [D loss: -0.192834] [G loss: 0.652075]\n",
      "epoch2 step19765 [D loss: -0.307402] [G loss: 0.412837]\n",
      "epoch2 step19770 [D loss: 0.254092] [G loss: 0.827357]\n",
      "epoch2 step19775 [D loss: 0.283939] [G loss: 0.470302]\n",
      "epoch2 step19780 [D loss: 0.037400] [G loss: 0.700608]\n",
      "epoch2 step19785 [D loss: -0.220743] [G loss: 0.688980]\n",
      "epoch2 step19790 [D loss: -0.286318] [G loss: 0.934369]\n",
      "epoch2 step19795 [D loss: 0.002296] [G loss: 0.689384]\n",
      "epoch2 step19800 [D loss: -0.039622] [G loss: 0.804589]\n",
      "epoch2 step19805 [D loss: 0.142199] [G loss: 0.701425]\n",
      "epoch2 step19810 [D loss: -0.326351] [G loss: 0.864648]\n",
      "epoch2 step19815 [D loss: -0.312818] [G loss: 0.547374]\n",
      "epoch2 step19820 [D loss: -0.286365] [G loss: 0.964572]\n",
      "epoch2 step19825 [D loss: -0.150173] [G loss: 0.911894]\n",
      "epoch2 step19830 [D loss: 0.019309] [G loss: 0.871715]\n",
      "epoch2 step19835 [D loss: 0.156210] [G loss: 0.934860]\n",
      "epoch2 step19840 [D loss: -0.228407] [G loss: 0.955907]\n",
      "epoch2 step19845 [D loss: -0.154750] [G loss: 1.158499]\n",
      "epoch2 step19850 [D loss: -0.188305] [G loss: 1.044796]\n",
      "epoch2 step19855 [D loss: -0.409428] [G loss: 0.960342]\n",
      "epoch2 step19860 [D loss: -0.311163] [G loss: 1.374753]\n",
      "epoch2 step19865 [D loss: -0.226370] [G loss: 1.298580]\n",
      "epoch2 step19870 [D loss: -0.384588] [G loss: 1.491928]\n",
      "epoch2 step19875 [D loss: 0.018268] [G loss: 1.203449]\n",
      "epoch2 step19880 [D loss: 0.412071] [G loss: 1.304159]\n",
      "epoch2 step19885 [D loss: 0.005731] [G loss: 1.021123]\n",
      "epoch2 step19890 [D loss: 0.105757] [G loss: 1.307823]\n",
      "epoch2 step19895 [D loss: 0.266365] [G loss: 1.481287]\n",
      "epoch2 step19900 [D loss: -0.153122] [G loss: 1.028047]\n",
      "epoch2 step19905 [D loss: -0.167767] [G loss: 1.019586]\n",
      "epoch2 step19910 [D loss: 0.279614] [G loss: 1.133625]\n",
      "epoch2 step19915 [D loss: 0.076098] [G loss: 1.341732]\n",
      "epoch2 step19920 [D loss: -0.476544] [G loss: 1.426604]\n",
      "epoch2 step19925 [D loss: 0.122065] [G loss: 1.246978]\n",
      "epoch2 step19930 [D loss: -0.333586] [G loss: 1.297982]\n",
      "epoch2 step19935 [D loss: -0.537215] [G loss: 1.289083]\n",
      "epoch2 step19940 [D loss: 0.085119] [G loss: 1.448928]\n",
      "epoch2 step19945 [D loss: -0.264476] [G loss: 1.511315]\n",
      "epoch2 step19950 [D loss: -0.322616] [G loss: 1.252002]\n",
      "epoch2 step19955 [D loss: 0.132695] [G loss: 1.274510]\n",
      "epoch2 step19960 [D loss: -0.153290] [G loss: 1.620249]\n",
      "epoch2 step19965 [D loss: -0.195652] [G loss: 1.485826]\n",
      "epoch2 step19970 [D loss: -0.152435] [G loss: 1.446864]\n",
      "epoch2 step19975 [D loss: 0.213079] [G loss: 1.481400]\n",
      "epoch2 step19980 [D loss: -0.210265] [G loss: 1.534743]\n",
      "epoch2 step19985 [D loss: 0.008153] [G loss: 1.714005]\n",
      "epoch2 step19990 [D loss: 0.368464] [G loss: 1.385835]\n",
      "epoch2 step19995 [D loss: 0.094623] [G loss: 1.282399]\n",
      "epoch2 step20000 [D loss: -0.116450] [G loss: 1.251134]\n",
      "epoch2 step20005 [D loss: -0.128553] [G loss: 1.379249]\n",
      "epoch2 step20010 [D loss: 0.163554] [G loss: 0.937332]\n",
      "epoch2 step20015 [D loss: 0.032318] [G loss: 1.081579]\n",
      "epoch2 step20020 [D loss: -0.407186] [G loss: 1.101248]\n",
      "epoch2 step20025 [D loss: -0.153807] [G loss: 1.068809]\n",
      "epoch2 step20030 [D loss: -0.864647] [G loss: 0.962791]\n",
      "epoch2 step20035 [D loss: -0.637398] [G loss: 1.053926]\n",
      "epoch2 step20040 [D loss: -0.345753] [G loss: 0.723513]\n",
      "epoch2 step20045 [D loss: 0.178407] [G loss: 0.665190]\n",
      "epoch2 step20050 [D loss: -0.315389] [G loss: 0.565355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step20055 [D loss: -0.328487] [G loss: 0.794960]\n",
      "epoch2 step20060 [D loss: -0.152338] [G loss: 0.891314]\n",
      "epoch2 step20065 [D loss: 0.064487] [G loss: 0.977482]\n",
      "epoch2 step20070 [D loss: 0.204944] [G loss: 0.893504]\n",
      "epoch2 step20075 [D loss: 0.159826] [G loss: 0.905803]\n",
      "epoch2 step20080 [D loss: 0.145391] [G loss: 0.854095]\n",
      "epoch2 step20085 [D loss: 0.101038] [G loss: 0.719439]\n",
      "epoch2 step20090 [D loss: 0.034623] [G loss: 0.872367]\n",
      "epoch2 step20095 [D loss: -0.310201] [G loss: 0.630062]\n",
      "epoch2 step20100 [D loss: -0.192100] [G loss: 0.790680]\n",
      "epoch2 step20105 [D loss: -0.139660] [G loss: 0.667749]\n",
      "epoch2 step20110 [D loss: 0.177008] [G loss: 0.711335]\n",
      "epoch2 step20115 [D loss: -0.361481] [G loss: 0.523343]\n",
      "epoch2 step20120 [D loss: -0.115589] [G loss: 0.544248]\n",
      "epoch2 step20125 [D loss: 0.135899] [G loss: 0.736648]\n",
      "epoch2 step20130 [D loss: 0.147726] [G loss: 0.971211]\n",
      "epoch2 step20135 [D loss: -0.598630] [G loss: 0.794904]\n",
      "epoch2 step20140 [D loss: -0.239344] [G loss: 0.672434]\n",
      "epoch2 step20145 [D loss: -0.172649] [G loss: 1.001375]\n",
      "epoch2 step20150 [D loss: -0.245677] [G loss: 0.817717]\n",
      "epoch2 step20155 [D loss: 0.008534] [G loss: 0.754077]\n",
      "epoch2 step20160 [D loss: 0.142923] [G loss: 0.793254]\n",
      "epoch2 step20165 [D loss: -0.217780] [G loss: 0.742356]\n",
      "epoch2 step20170 [D loss: -0.104386] [G loss: 0.688568]\n",
      "epoch2 step20175 [D loss: -0.082760] [G loss: 0.698029]\n",
      "epoch2 step20180 [D loss: 0.256914] [G loss: 0.816116]\n",
      "epoch2 step20185 [D loss: -0.468843] [G loss: 0.982091]\n",
      "epoch2 step20190 [D loss: -0.085189] [G loss: 0.541412]\n",
      "epoch2 step20195 [D loss: -0.083605] [G loss: 0.720971]\n",
      "epoch2 step20200 [D loss: 0.131665] [G loss: 0.855761]\n",
      "epoch2 step20205 [D loss: -0.280579] [G loss: 0.595647]\n",
      "epoch2 step20210 [D loss: 0.151557] [G loss: 0.706709]\n",
      "epoch2 step20215 [D loss: 0.036577] [G loss: 0.897482]\n",
      "epoch2 step20220 [D loss: -0.311110] [G loss: 0.726797]\n",
      "epoch2 step20225 [D loss: -0.368967] [G loss: 0.657787]\n",
      "epoch2 step20230 [D loss: -0.172845] [G loss: 0.573302]\n",
      "epoch2 step20235 [D loss: -0.292413] [G loss: 0.789354]\n",
      "epoch2 step20240 [D loss: 0.192278] [G loss: 0.542391]\n",
      "epoch2 step20245 [D loss: 0.363812] [G loss: 0.679647]\n",
      "epoch2 step20250 [D loss: 0.041415] [G loss: 0.891349]\n",
      "epoch2 step20255 [D loss: -0.374081] [G loss: 0.620721]\n",
      "epoch2 step20260 [D loss: 0.036701] [G loss: 0.891961]\n",
      "epoch2 step20265 [D loss: 0.014031] [G loss: 0.749188]\n",
      "epoch2 step20270 [D loss: -0.722291] [G loss: 0.736804]\n",
      "epoch2 step20275 [D loss: 0.050748] [G loss: 0.451179]\n",
      "epoch2 step20280 [D loss: -0.178741] [G loss: 0.532487]\n",
      "epoch2 step20285 [D loss: 0.169396] [G loss: 0.607393]\n",
      "epoch2 step20290 [D loss: -0.326764] [G loss: 0.608162]\n",
      "epoch2 step20295 [D loss: 0.067575] [G loss: 1.010861]\n",
      "epoch2 step20300 [D loss: -0.652542] [G loss: 0.631915]\n",
      "epoch2 step20305 [D loss: -0.385823] [G loss: 0.858469]\n",
      "epoch2 step20310 [D loss: 0.114343] [G loss: 1.014240]\n",
      "epoch2 step20315 [D loss: -0.542453] [G loss: 0.804001]\n",
      "epoch2 step20320 [D loss: 0.011415] [G loss: 0.963776]\n",
      "epoch2 step20325 [D loss: -0.111080] [G loss: 0.931051]\n",
      "epoch2 step20330 [D loss: -0.085486] [G loss: 0.656987]\n",
      "epoch2 step20335 [D loss: 0.010220] [G loss: 0.547261]\n",
      "epoch2 step20340 [D loss: 0.275397] [G loss: 0.855210]\n",
      "epoch2 step20345 [D loss: 0.026834] [G loss: 0.935501]\n",
      "epoch2 step20350 [D loss: -0.382245] [G loss: 0.898066]\n",
      "epoch2 step20355 [D loss: -0.031501] [G loss: 0.801350]\n",
      "epoch2 step20360 [D loss: -0.214805] [G loss: 0.917481]\n",
      "epoch2 step20365 [D loss: 0.157550] [G loss: 0.777743]\n",
      "epoch2 step20370 [D loss: -0.191845] [G loss: 0.795765]\n",
      "epoch2 step20375 [D loss: 0.069007] [G loss: 0.906354]\n",
      "epoch2 step20380 [D loss: -0.116312] [G loss: 0.975708]\n",
      "epoch2 step20385 [D loss: -0.189026] [G loss: 0.914634]\n",
      "epoch2 step20390 [D loss: 0.063721] [G loss: 1.036205]\n",
      "epoch2 step20395 [D loss: 0.249974] [G loss: 0.851454]\n",
      "epoch2 step20400 [D loss: -0.182710] [G loss: 0.880443]\n",
      "epoch2 step20405 [D loss: -0.028410] [G loss: 1.018741]\n",
      "epoch2 step20410 [D loss: -0.257376] [G loss: 1.315683]\n",
      "epoch2 step20415 [D loss: -0.387136] [G loss: 1.187075]\n",
      "epoch2 step20420 [D loss: -0.233548] [G loss: 1.120180]\n",
      "epoch2 step20425 [D loss: 0.004880] [G loss: 1.123563]\n",
      "epoch2 step20430 [D loss: -0.051396] [G loss: 1.436588]\n",
      "epoch2 step20435 [D loss: 0.017651] [G loss: 1.353216]\n",
      "epoch2 step20440 [D loss: -0.043393] [G loss: 1.507725]\n",
      "epoch2 step20445 [D loss: -0.036427] [G loss: 1.476293]\n",
      "epoch2 step20450 [D loss: -0.213622] [G loss: 1.787310]\n",
      "epoch2 step20455 [D loss: -0.453804] [G loss: 1.488075]\n",
      "epoch2 step20460 [D loss: 0.118483] [G loss: 1.391780]\n",
      "epoch2 step20465 [D loss: -0.221638] [G loss: 1.572165]\n",
      "epoch2 step20470 [D loss: -0.011005] [G loss: 1.774006]\n",
      "epoch2 step20475 [D loss: -0.570643] [G loss: 1.536184]\n",
      "epoch2 step20480 [D loss: -0.291566] [G loss: 1.814742]\n",
      "epoch2 step20485 [D loss: -0.058625] [G loss: 1.335155]\n",
      "epoch2 step20490 [D loss: -0.254777] [G loss: 1.767739]\n",
      "epoch2 step20495 [D loss: -0.428266] [G loss: 1.475984]\n",
      "epoch2 step20500 [D loss: -0.068229] [G loss: 1.576191]\n",
      "epoch2 step20505 [D loss: 0.093648] [G loss: 1.348814]\n",
      "epoch2 step20510 [D loss: 0.270279] [G loss: 1.401071]\n",
      "epoch2 step20515 [D loss: -0.208946] [G loss: 1.492832]\n",
      "epoch2 step20520 [D loss: -0.218529] [G loss: 1.248147]\n",
      "epoch2 step20525 [D loss: -0.084728] [G loss: 1.262514]\n",
      "epoch2 step20530 [D loss: 0.136574] [G loss: 1.364041]\n",
      "epoch2 step20535 [D loss: 0.079743] [G loss: 1.201941]\n",
      "epoch2 step20540 [D loss: 0.047466] [G loss: 1.161149]\n",
      "epoch2 step20545 [D loss: -0.712393] [G loss: 1.410024]\n",
      "epoch2 step20550 [D loss: -0.013504] [G loss: 1.473582]\n",
      "epoch2 step20555 [D loss: 0.617763] [G loss: 1.405993]\n",
      "epoch2 step20560 [D loss: -0.032404] [G loss: 1.373698]\n",
      "epoch2 step20565 [D loss: -0.366056] [G loss: 1.124822]\n",
      "epoch2 step20570 [D loss: 0.062951] [G loss: 1.058881]\n",
      "epoch2 step20575 [D loss: 0.088520] [G loss: 0.994884]\n",
      "epoch2 step20580 [D loss: -0.060528] [G loss: 1.082185]\n",
      "epoch2 step20585 [D loss: 0.015933] [G loss: 0.957411]\n",
      "epoch2 step20590 [D loss: -0.005347] [G loss: 1.393211]\n",
      "epoch2 step20595 [D loss: -0.062394] [G loss: 1.060638]\n",
      "epoch2 step20600 [D loss: 0.103140] [G loss: 1.042492]\n",
      "epoch2 step20605 [D loss: -0.500727] [G loss: 0.734825]\n",
      "epoch2 step20610 [D loss: -0.124404] [G loss: 1.017264]\n",
      "epoch2 step20615 [D loss: 0.066289] [G loss: 0.876058]\n",
      "epoch2 step20620 [D loss: -0.030865] [G loss: 0.730030]\n",
      "epoch2 step20625 [D loss: 0.458231] [G loss: 0.648808]\n",
      "epoch2 step20630 [D loss: -0.234996] [G loss: 0.694214]\n",
      "epoch2 step20635 [D loss: 0.192616] [G loss: 0.708006]\n",
      "epoch2 step20640 [D loss: -0.109237] [G loss: 1.159401]\n",
      "epoch2 step20645 [D loss: -0.200651] [G loss: 0.704397]\n",
      "epoch2 step20650 [D loss: -0.207660] [G loss: 0.741357]\n",
      "epoch2 step20655 [D loss: 0.126254] [G loss: 0.693601]\n",
      "epoch2 step20660 [D loss: 0.198040] [G loss: 0.814385]\n",
      "epoch2 step20665 [D loss: 0.003094] [G loss: 0.756275]\n",
      "epoch2 step20670 [D loss: -0.120387] [G loss: 0.993904]\n",
      "epoch2 step20675 [D loss: 0.139441] [G loss: 0.675824]\n",
      "epoch2 step20680 [D loss: 0.101915] [G loss: 0.417383]\n",
      "epoch2 step20685 [D loss: -0.094497] [G loss: 0.938952]\n",
      "epoch2 step20690 [D loss: 0.081994] [G loss: 1.067189]\n",
      "epoch2 step20695 [D loss: 0.001430] [G loss: 1.302916]\n",
      "epoch2 step20700 [D loss: -0.330134] [G loss: 1.037943]\n",
      "epoch2 step20705 [D loss: -0.072938] [G loss: 1.284337]\n",
      "epoch2 step20710 [D loss: 0.404225] [G loss: 0.792793]\n",
      "epoch2 step20715 [D loss: -0.314113] [G loss: 1.055270]\n",
      "epoch2 step20720 [D loss: -0.423600] [G loss: 1.080562]\n",
      "epoch2 step20725 [D loss: -0.384685] [G loss: 0.871614]\n",
      "epoch2 step20730 [D loss: -0.202582] [G loss: 0.760810]\n",
      "epoch2 step20735 [D loss: -0.587947] [G loss: 0.965463]\n",
      "epoch2 step20740 [D loss: -0.460566] [G loss: 1.374161]\n",
      "epoch2 step20745 [D loss: -0.037326] [G loss: 1.455500]\n",
      "epoch2 step20750 [D loss: -0.047565] [G loss: 1.408737]\n",
      "epoch2 step20755 [D loss: -0.149195] [G loss: 0.815093]\n",
      "epoch2 step20760 [D loss: -0.076779] [G loss: 1.213916]\n",
      "epoch2 step20765 [D loss: 0.376142] [G loss: 1.616843]\n",
      "epoch2 step20770 [D loss: -0.318406] [G loss: 1.380558]\n",
      "epoch2 step20775 [D loss: 0.329024] [G loss: 1.246868]\n",
      "epoch2 step20780 [D loss: -0.205542] [G loss: 1.075676]\n",
      "epoch2 step20785 [D loss: -0.261305] [G loss: 1.465928]\n",
      "epoch2 step20790 [D loss: -0.153381] [G loss: 1.436196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step20795 [D loss: 0.412742] [G loss: 1.308807]\n",
      "epoch2 step20800 [D loss: -0.204220] [G loss: 1.428875]\n",
      "epoch2 step20805 [D loss: -0.032051] [G loss: 1.771362]\n",
      "epoch2 step20810 [D loss: -0.507066] [G loss: 1.821566]\n",
      "epoch2 step20815 [D loss: -0.290740] [G loss: 1.664977]\n",
      "epoch2 step20820 [D loss: -0.370232] [G loss: 1.538873]\n",
      "epoch2 step20825 [D loss: -0.095989] [G loss: 1.728120]\n",
      "epoch2 step20830 [D loss: -0.093974] [G loss: 1.365080]\n",
      "epoch2 step20835 [D loss: -0.207347] [G loss: 1.575714]\n",
      "epoch2 step20840 [D loss: -0.231324] [G loss: 1.685008]\n",
      "epoch2 step20845 [D loss: -0.215998] [G loss: 1.392922]\n",
      "epoch2 step20850 [D loss: -0.032270] [G loss: 1.624820]\n",
      "epoch2 step20855 [D loss: 0.166032] [G loss: 1.372416]\n",
      "epoch2 step20860 [D loss: 0.155630] [G loss: 1.497801]\n",
      "epoch2 step20865 [D loss: -0.446656] [G loss: 1.587332]\n",
      "epoch2 step20870 [D loss: -0.728985] [G loss: 1.630227]\n",
      "epoch2 step20875 [D loss: 0.381978] [G loss: 1.458191]\n",
      "epoch2 step20880 [D loss: 0.122235] [G loss: 1.477354]\n",
      "epoch2 step20885 [D loss: -0.284772] [G loss: 1.847170]\n",
      "epoch2 step20890 [D loss: 0.123997] [G loss: 1.484956]\n",
      "epoch2 step20895 [D loss: 0.174656] [G loss: 1.517612]\n",
      "epoch2 step20900 [D loss: -0.506348] [G loss: 1.382217]\n",
      "epoch2 step20905 [D loss: -0.005080] [G loss: 1.219203]\n",
      "epoch2 step20910 [D loss: -0.056948] [G loss: 1.222884]\n",
      "epoch2 step20915 [D loss: -0.351505] [G loss: 1.190111]\n",
      "epoch2 step20920 [D loss: 0.077643] [G loss: 1.116675]\n",
      "epoch2 step20925 [D loss: -0.106463] [G loss: 1.089505]\n",
      "epoch2 step20930 [D loss: 0.152683] [G loss: 0.769174]\n",
      "epoch2 step20935 [D loss: -0.020498] [G loss: 0.816701]\n",
      "epoch2 step20940 [D loss: -0.704054] [G loss: 0.661597]\n",
      "epoch2 step20945 [D loss: -0.157773] [G loss: 0.418846]\n",
      "epoch2 step20950 [D loss: 0.131054] [G loss: 0.301437]\n",
      "epoch2 step20955 [D loss: -0.233407] [G loss: 0.664609]\n",
      "epoch2 step20960 [D loss: -0.459528] [G loss: 0.473450]\n",
      "epoch2 step20965 [D loss: 0.087724] [G loss: 0.485113]\n",
      "epoch2 step20970 [D loss: 0.345955] [G loss: 0.603540]\n",
      "epoch2 step20975 [D loss: -0.019778] [G loss: 0.656700]\n",
      "epoch2 step20980 [D loss: -0.172327] [G loss: 0.393727]\n",
      "epoch2 step20985 [D loss: 0.149154] [G loss: 0.273609]\n",
      "epoch2 step20990 [D loss: -0.314897] [G loss: 0.551345]\n",
      "epoch2 step20995 [D loss: 0.189768] [G loss: 0.461920]\n",
      "epoch2 step21000 [D loss: 0.334199] [G loss: 0.584459]\n",
      "epoch2 step21005 [D loss: -0.101209] [G loss: 0.924369]\n",
      "epoch2 step21010 [D loss: -0.472258] [G loss: 0.856786]\n",
      "epoch2 step21015 [D loss: -0.320831] [G loss: 0.732008]\n",
      "epoch2 step21020 [D loss: -0.354963] [G loss: 0.661340]\n",
      "epoch2 step21025 [D loss: -0.271519] [G loss: 1.042442]\n",
      "epoch2 step21030 [D loss: -0.167937] [G loss: 0.616176]\n",
      "epoch2 step21035 [D loss: -0.461800] [G loss: 0.680032]\n",
      "epoch2 step21040 [D loss: -0.168376] [G loss: 0.802640]\n",
      "epoch2 step21045 [D loss: -0.070863] [G loss: 0.917878]\n",
      "epoch2 step21050 [D loss: -0.275001] [G loss: 0.965304]\n",
      "epoch2 step21055 [D loss: -0.736652] [G loss: 1.219244]\n",
      "epoch2 step21060 [D loss: -0.240293] [G loss: 1.033099]\n",
      "epoch2 step21065 [D loss: -0.826596] [G loss: 1.343663]\n",
      "epoch2 step21070 [D loss: 0.024398] [G loss: 1.493463]\n",
      "epoch2 step21075 [D loss: -0.219206] [G loss: 1.544148]\n",
      "epoch2 step21080 [D loss: -0.206317] [G loss: 1.296537]\n",
      "epoch2 step21085 [D loss: -0.176042] [G loss: 1.262063]\n",
      "epoch2 step21090 [D loss: -0.008124] [G loss: 1.532376]\n",
      "epoch2 step21095 [D loss: 0.036678] [G loss: 1.629480]\n",
      "epoch2 step21100 [D loss: -0.097852] [G loss: 1.257620]\n",
      "epoch2 step21105 [D loss: -0.130584] [G loss: 1.090062]\n",
      "epoch2 step21110 [D loss: 0.035435] [G loss: 1.069108]\n",
      "epoch2 step21115 [D loss: -0.186849] [G loss: 1.402792]\n",
      "epoch2 step21120 [D loss: 0.012444] [G loss: 1.427591]\n",
      "epoch2 step21125 [D loss: -0.499674] [G loss: 1.407920]\n",
      "epoch2 step21130 [D loss: -0.022071] [G loss: 1.111576]\n",
      "epoch2 step21135 [D loss: -0.149373] [G loss: 1.370230]\n",
      "epoch2 step21140 [D loss: -0.051160] [G loss: 1.181212]\n",
      "epoch2 step21145 [D loss: 0.136062] [G loss: 1.179546]\n",
      "epoch2 step21150 [D loss: 0.247175] [G loss: 1.131485]\n",
      "epoch2 step21155 [D loss: -0.377294] [G loss: 1.290519]\n",
      "epoch2 step21160 [D loss: 0.069776] [G loss: 1.252337]\n",
      "epoch2 step21165 [D loss: -0.410401] [G loss: 0.994095]\n",
      "epoch2 step21170 [D loss: -0.247292] [G loss: 1.126992]\n",
      "epoch2 step21175 [D loss: -0.109344] [G loss: 1.117473]\n",
      "epoch2 step21180 [D loss: 0.292728] [G loss: 1.183780]\n",
      "epoch2 step21185 [D loss: -0.099906] [G loss: 1.060267]\n",
      "epoch2 step21190 [D loss: 0.000243] [G loss: 0.855254]\n",
      "epoch2 step21195 [D loss: -0.061993] [G loss: 0.760742]\n",
      "epoch2 step21200 [D loss: -0.072335] [G loss: 1.127070]\n",
      "epoch2 step21205 [D loss: -0.136873] [G loss: 1.275097]\n",
      "epoch2 step21210 [D loss: 0.299913] [G loss: 0.973559]\n",
      "epoch2 step21215 [D loss: -0.061992] [G loss: 0.892493]\n",
      "epoch2 step21220 [D loss: -0.370193] [G loss: 1.046502]\n",
      "epoch2 step21225 [D loss: -0.439325] [G loss: 1.244340]\n",
      "epoch2 step21230 [D loss: 0.166995] [G loss: 1.150712]\n",
      "epoch2 step21235 [D loss: 0.085592] [G loss: 0.898059]\n",
      "epoch2 step21240 [D loss: -0.012319] [G loss: 1.071784]\n",
      "epoch2 step21245 [D loss: -0.195848] [G loss: 0.851615]\n",
      "epoch2 step21250 [D loss: 0.018097] [G loss: 0.991809]\n",
      "epoch2 step21255 [D loss: 0.112157] [G loss: 0.908206]\n",
      "epoch2 step21260 [D loss: 0.016895] [G loss: 0.901026]\n",
      "epoch2 step21265 [D loss: 0.127384] [G loss: 1.064172]\n",
      "epoch2 step21270 [D loss: -0.174061] [G loss: 0.814917]\n",
      "epoch2 step21275 [D loss: -0.109486] [G loss: 0.621910]\n",
      "epoch2 step21280 [D loss: -0.265576] [G loss: 1.107309]\n",
      "epoch2 step21285 [D loss: -0.150274] [G loss: 0.846408]\n",
      "epoch2 step21290 [D loss: 0.166504] [G loss: 1.152198]\n",
      "epoch2 step21295 [D loss: -0.019075] [G loss: 0.858796]\n",
      "epoch2 step21300 [D loss: -0.348216] [G loss: 1.061918]\n",
      "epoch2 step21305 [D loss: 0.065996] [G loss: 1.141814]\n",
      "epoch2 step21310 [D loss: -0.153302] [G loss: 0.864337]\n",
      "epoch2 step21315 [D loss: -0.039501] [G loss: 1.413388]\n",
      "epoch2 step21320 [D loss: -0.163488] [G loss: 0.805445]\n",
      "epoch2 step21325 [D loss: -0.017324] [G loss: 1.372524]\n",
      "epoch2 step21330 [D loss: 0.036824] [G loss: 1.139292]\n",
      "epoch2 step21335 [D loss: -0.633199] [G loss: 1.188180]\n",
      "epoch2 step21340 [D loss: -0.326391] [G loss: 1.169392]\n",
      "epoch2 step21345 [D loss: -0.037274] [G loss: 1.226753]\n",
      "epoch2 step21350 [D loss: -0.230528] [G loss: 1.052665]\n",
      "epoch2 step21355 [D loss: -0.276224] [G loss: 0.915599]\n",
      "epoch2 step21360 [D loss: 0.168134] [G loss: 1.156314]\n",
      "epoch2 step21365 [D loss: -0.038447] [G loss: 1.102721]\n",
      "epoch2 step21370 [D loss: -0.412337] [G loss: 1.228639]\n",
      "epoch2 step21375 [D loss: 0.020976] [G loss: 1.408808]\n",
      "epoch2 step21380 [D loss: -0.050832] [G loss: 1.497578]\n",
      "epoch2 step21385 [D loss: -0.430810] [G loss: 1.292051]\n",
      "epoch2 step21390 [D loss: 0.250403] [G loss: 1.295779]\n",
      "epoch2 step21395 [D loss: -0.358222] [G loss: 1.317204]\n",
      "epoch2 step21400 [D loss: -0.138791] [G loss: 1.674916]\n",
      "epoch2 step21405 [D loss: 0.071617] [G loss: 1.426947]\n",
      "epoch2 step21410 [D loss: -0.132404] [G loss: 1.195871]\n",
      "epoch2 step21415 [D loss: -0.164610] [G loss: 1.444726]\n",
      "epoch2 step21420 [D loss: 0.339549] [G loss: 1.165957]\n",
      "epoch2 step21425 [D loss: -0.247091] [G loss: 1.189867]\n",
      "epoch2 step21430 [D loss: 0.033223] [G loss: 1.222141]\n",
      "epoch2 step21435 [D loss: -0.115677] [G loss: 1.196337]\n",
      "epoch2 step21440 [D loss: -0.200568] [G loss: 1.300483]\n",
      "epoch2 step21445 [D loss: -0.259494] [G loss: 1.129342]\n",
      "epoch2 step21450 [D loss: -0.266501] [G loss: 1.196212]\n",
      "epoch2 step21455 [D loss: -0.674124] [G loss: 1.149478]\n",
      "epoch2 step21460 [D loss: -0.743617] [G loss: 1.367294]\n",
      "epoch2 step21465 [D loss: -0.166575] [G loss: 1.665931]\n",
      "epoch2 step21470 [D loss: 0.400496] [G loss: 0.987878]\n",
      "epoch2 step21475 [D loss: 0.193751] [G loss: 0.874681]\n",
      "epoch2 step21480 [D loss: -0.123582] [G loss: 1.109891]\n",
      "epoch2 step21485 [D loss: -0.384847] [G loss: 1.093913]\n",
      "epoch2 step21490 [D loss: 0.112869] [G loss: 1.063962]\n",
      "epoch2 step21495 [D loss: -0.158011] [G loss: 1.337815]\n",
      "epoch2 step21500 [D loss: -0.184085] [G loss: 1.181853]\n",
      "epoch2 step21505 [D loss: -0.333714] [G loss: 1.000123]\n",
      "epoch2 step21510 [D loss: -0.171367] [G loss: 1.082602]\n",
      "epoch2 step21515 [D loss: -0.412050] [G loss: 1.198599]\n",
      "epoch2 step21520 [D loss: -0.107339] [G loss: 1.065067]\n",
      "epoch2 step21525 [D loss: -0.104016] [G loss: 1.091187]\n",
      "epoch2 step21530 [D loss: 0.038729] [G loss: 0.763830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step21535 [D loss: -0.154658] [G loss: 0.647275]\n",
      "epoch2 step21540 [D loss: 0.205332] [G loss: 0.896995]\n",
      "epoch2 step21545 [D loss: 0.132755] [G loss: 0.899617]\n",
      "epoch2 step21550 [D loss: -0.100650] [G loss: 0.612297]\n",
      "epoch2 step21555 [D loss: -0.099032] [G loss: 0.969739]\n",
      "epoch2 step21560 [D loss: -0.220063] [G loss: 0.948731]\n",
      "epoch2 step21565 [D loss: 0.003204] [G loss: 1.283689]\n",
      "epoch2 step21570 [D loss: -0.236163] [G loss: 1.073081]\n",
      "epoch2 step21575 [D loss: -0.562928] [G loss: 1.257023]\n",
      "epoch2 step21580 [D loss: 0.116458] [G loss: 0.835610]\n",
      "epoch2 step21585 [D loss: -0.402525] [G loss: 0.951529]\n",
      "epoch2 step21590 [D loss: 0.041245] [G loss: 1.159224]\n",
      "epoch2 step21595 [D loss: -0.079800] [G loss: 0.914127]\n",
      "epoch2 step21600 [D loss: -0.355361] [G loss: 0.947720]\n",
      "epoch2 step21605 [D loss: -0.194002] [G loss: 0.849826]\n",
      "epoch2 step21610 [D loss: -0.302427] [G loss: 0.984982]\n",
      "epoch2 step21615 [D loss: 0.189926] [G loss: 1.020581]\n",
      "epoch2 step21620 [D loss: 0.217802] [G loss: 0.925105]\n",
      "epoch2 step21625 [D loss: -0.128231] [G loss: 1.055545]\n",
      "epoch2 step21630 [D loss: -0.374113] [G loss: 0.821160]\n",
      "epoch2 step21635 [D loss: 0.129690] [G loss: 0.926660]\n",
      "epoch2 step21640 [D loss: -0.303580] [G loss: 0.917126]\n",
      "epoch2 step21645 [D loss: -0.161215] [G loss: 0.929970]\n",
      "epoch2 step21650 [D loss: -0.451152] [G loss: 0.774964]\n",
      "epoch2 step21655 [D loss: -0.320060] [G loss: 1.000325]\n",
      "epoch2 step21660 [D loss: -0.347915] [G loss: 0.998721]\n",
      "epoch2 step21665 [D loss: -0.073341] [G loss: 1.159813]\n",
      "epoch2 step21670 [D loss: -0.261536] [G loss: 0.932253]\n",
      "epoch2 step21675 [D loss: 0.017421] [G loss: 0.842872]\n",
      "epoch2 step21680 [D loss: 0.083844] [G loss: 1.143466]\n",
      "epoch2 step21685 [D loss: -0.353101] [G loss: 0.817867]\n",
      "epoch2 step21690 [D loss: -0.490579] [G loss: 1.114492]\n",
      "epoch2 step21695 [D loss: 0.292598] [G loss: 0.763838]\n",
      "epoch2 step21700 [D loss: -0.122916] [G loss: 1.161405]\n",
      "epoch2 step21705 [D loss: -0.135618] [G loss: 1.045974]\n",
      "epoch2 step21710 [D loss: 0.303517] [G loss: 0.708051]\n",
      "epoch2 step21715 [D loss: -0.098325] [G loss: 1.103501]\n",
      "epoch2 step21720 [D loss: -0.153963] [G loss: 1.154369]\n",
      "epoch2 step21725 [D loss: -0.558203] [G loss: 0.960064]\n",
      "epoch2 step21730 [D loss: 0.195181] [G loss: 0.885621]\n",
      "epoch2 step21735 [D loss: -0.303474] [G loss: 1.202576]\n",
      "epoch2 step21740 [D loss: 0.229424] [G loss: 1.031367]\n",
      "epoch2 step21745 [D loss: 0.201438] [G loss: 0.748978]\n",
      "epoch2 step21750 [D loss: 0.248367] [G loss: 1.068467]\n",
      "epoch2 step21755 [D loss: -0.085836] [G loss: 0.772288]\n",
      "epoch2 step21760 [D loss: -0.356784] [G loss: 0.682758]\n",
      "epoch2 step21765 [D loss: -0.434737] [G loss: 1.239472]\n",
      "epoch2 step21770 [D loss: -0.279093] [G loss: 1.323940]\n",
      "epoch2 step21775 [D loss: 0.585018] [G loss: 0.952722]\n",
      "epoch2 step21780 [D loss: 0.460524] [G loss: 0.922868]\n",
      "epoch2 step21785 [D loss: 0.376164] [G loss: 0.956817]\n",
      "epoch2 step21790 [D loss: -0.143970] [G loss: 1.510127]\n",
      "epoch2 step21795 [D loss: 0.088008] [G loss: 1.300073]\n",
      "epoch2 step21800 [D loss: -0.242943] [G loss: 1.571009]\n",
      "epoch2 step21805 [D loss: -0.442816] [G loss: 1.251673]\n",
      "epoch2 step21810 [D loss: 0.356234] [G loss: 1.387366]\n",
      "epoch2 step21815 [D loss: -0.326690] [G loss: 1.163079]\n",
      "epoch2 step21820 [D loss: -0.051293] [G loss: 1.384773]\n",
      "epoch2 step21825 [D loss: -0.048875] [G loss: 1.295721]\n",
      "epoch2 step21830 [D loss: -0.282636] [G loss: 1.254921]\n",
      "epoch2 step21835 [D loss: 0.033661] [G loss: 1.156483]\n",
      "epoch2 step21840 [D loss: -0.017587] [G loss: 1.135700]\n",
      "epoch2 step21845 [D loss: 0.152104] [G loss: 0.874680]\n",
      "epoch2 step21850 [D loss: -0.214530] [G loss: 1.157318]\n",
      "epoch2 step21855 [D loss: 0.237574] [G loss: 1.027289]\n",
      "epoch2 step21860 [D loss: -0.209125] [G loss: 1.174099]\n",
      "epoch2 step21865 [D loss: -0.614673] [G loss: 1.303075]\n",
      "epoch2 step21870 [D loss: -0.133295] [G loss: 1.335748]\n",
      "epoch2 step21875 [D loss: -0.295083] [G loss: 1.045767]\n",
      "epoch2 step21880 [D loss: -0.183045] [G loss: 1.015903]\n",
      "epoch2 step21885 [D loss: -0.521284] [G loss: 1.319239]\n",
      "epoch2 step21890 [D loss: 0.242651] [G loss: 1.068247]\n",
      "epoch2 step21895 [D loss: -0.024899] [G loss: 1.139735]\n",
      "epoch2 step21900 [D loss: -0.142406] [G loss: 1.409481]\n",
      "epoch2 step21905 [D loss: 0.004507] [G loss: 1.049140]\n",
      "epoch2 step21910 [D loss: -0.344258] [G loss: 1.249752]\n",
      "epoch2 step21915 [D loss: -0.195577] [G loss: 1.412263]\n",
      "epoch2 step21920 [D loss: -0.156519] [G loss: 1.439041]\n",
      "epoch2 step21925 [D loss: 0.033904] [G loss: 1.292023]\n",
      "epoch2 step21930 [D loss: -0.430946] [G loss: 1.046450]\n",
      "epoch2 step21935 [D loss: 0.093797] [G loss: 1.337669]\n",
      "epoch2 step21940 [D loss: 0.581362] [G loss: 1.135914]\n",
      "epoch2 step21945 [D loss: -0.221745] [G loss: 1.219256]\n",
      "epoch2 step21950 [D loss: -0.261635] [G loss: 1.202682]\n",
      "epoch2 step21955 [D loss: 0.021216] [G loss: 1.089810]\n",
      "epoch2 step21960 [D loss: -0.396092] [G loss: 0.886132]\n",
      "epoch2 step21965 [D loss: 0.471594] [G loss: 0.908310]\n",
      "epoch2 step21970 [D loss: -0.223199] [G loss: 1.153371]\n",
      "epoch2 step21975 [D loss: 0.241205] [G loss: 0.970475]\n",
      "epoch2 step21980 [D loss: 0.028906] [G loss: 1.064779]\n",
      "epoch2 step21985 [D loss: 0.178660] [G loss: 1.115698]\n",
      "epoch2 step21990 [D loss: -0.639000] [G loss: 1.370856]\n",
      "epoch2 step21995 [D loss: -0.131211] [G loss: 1.501107]\n",
      "epoch2 step22000 [D loss: -0.079897] [G loss: 1.420759]\n",
      "epoch2 step22005 [D loss: -0.810974] [G loss: 1.540924]\n",
      "epoch2 step22010 [D loss: -0.359244] [G loss: 1.172570]\n",
      "epoch2 step22015 [D loss: -0.114231] [G loss: 1.561068]\n",
      "epoch2 step22020 [D loss: -0.342101] [G loss: 1.297834]\n",
      "epoch2 step22025 [D loss: 0.854514] [G loss: 0.842281]\n",
      "epoch2 step22030 [D loss: 0.424992] [G loss: 1.294811]\n",
      "epoch2 step22035 [D loss: 0.486567] [G loss: 0.957174]\n",
      "epoch2 step22040 [D loss: 0.053913] [G loss: 0.921554]\n",
      "epoch2 step22045 [D loss: 0.141011] [G loss: 1.031923]\n",
      "epoch2 step22050 [D loss: 0.188542] [G loss: 0.854069]\n",
      "epoch2 step22055 [D loss: -0.025764] [G loss: 1.087506]\n",
      "epoch2 step22060 [D loss: 0.136484] [G loss: 1.025236]\n",
      "epoch2 step22065 [D loss: 0.142350] [G loss: 0.950051]\n",
      "epoch2 step22070 [D loss: -0.555123] [G loss: 0.994802]\n",
      "epoch2 step22075 [D loss: -0.244171] [G loss: 0.988670]\n",
      "epoch2 step22080 [D loss: -0.216607] [G loss: 0.971840]\n",
      "epoch2 step22085 [D loss: -0.417473] [G loss: 1.213208]\n",
      "epoch2 step22090 [D loss: -0.312268] [G loss: 0.877338]\n",
      "epoch2 step22095 [D loss: 0.023911] [G loss: 1.156817]\n",
      "epoch2 step22100 [D loss: 0.065001] [G loss: 1.338030]\n",
      "epoch2 step22105 [D loss: -0.276198] [G loss: 1.211602]\n",
      "epoch2 step22110 [D loss: -0.469707] [G loss: 1.037387]\n",
      "epoch2 step22115 [D loss: 0.250201] [G loss: 1.075278]\n",
      "epoch2 step22120 [D loss: -0.366613] [G loss: 1.281418]\n",
      "epoch2 step22125 [D loss: -0.261000] [G loss: 1.161715]\n",
      "epoch2 step22130 [D loss: -0.073418] [G loss: 1.415903]\n",
      "epoch2 step22135 [D loss: -0.373586] [G loss: 0.974936]\n",
      "epoch2 step22140 [D loss: 0.044652] [G loss: 1.071371]\n",
      "epoch2 step22145 [D loss: 0.195585] [G loss: 1.307247]\n",
      "epoch2 step22150 [D loss: -0.752470] [G loss: 1.250937]\n",
      "epoch2 step22155 [D loss: -0.674015] [G loss: 1.263553]\n",
      "epoch2 step22160 [D loss: 0.188187] [G loss: 1.276158]\n",
      "epoch2 step22165 [D loss: 0.611993] [G loss: 1.378575]\n",
      "epoch2 step22170 [D loss: -0.100590] [G loss: 1.575835]\n",
      "epoch2 step22175 [D loss: -0.219954] [G loss: 1.764916]\n",
      "epoch2 step22180 [D loss: 0.104292] [G loss: 1.656399]\n",
      "epoch2 step22185 [D loss: -0.148582] [G loss: 1.686893]\n",
      "epoch2 step22190 [D loss: -0.134429] [G loss: 1.864113]\n",
      "epoch2 step22195 [D loss: -0.199905] [G loss: 2.103930]\n",
      "epoch2 step22200 [D loss: -0.010094] [G loss: 1.921098]\n",
      "epoch2 step22205 [D loss: -0.331135] [G loss: 2.133956]\n",
      "epoch2 step22210 [D loss: -0.712969] [G loss: 2.028038]\n",
      "epoch2 step22215 [D loss: -0.507585] [G loss: 2.135911]\n",
      "epoch2 step22220 [D loss: -0.144018] [G loss: 2.178386]\n",
      "epoch2 step22225 [D loss: -0.060366] [G loss: 1.881966]\n",
      "epoch2 step22230 [D loss: -0.283749] [G loss: 2.015769]\n",
      "epoch2 step22235 [D loss: 0.426397] [G loss: 2.055267]\n",
      "epoch2 step22240 [D loss: -0.012319] [G loss: 2.308508]\n",
      "epoch2 step22245 [D loss: -0.139576] [G loss: 2.417426]\n",
      "epoch2 step22250 [D loss: -0.290326] [G loss: 2.041343]\n",
      "epoch2 step22255 [D loss: 0.254890] [G loss: 2.243067]\n",
      "epoch2 step22260 [D loss: -0.135975] [G loss: 1.936140]\n",
      "epoch2 step22265 [D loss: -0.510709] [G loss: 2.109888]\n",
      "epoch2 step22270 [D loss: -0.313998] [G loss: 2.191430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step22275 [D loss: -0.071647] [G loss: 1.902100]\n",
      "epoch2 step22280 [D loss: -0.652674] [G loss: 2.181193]\n",
      "epoch2 step22285 [D loss: -0.284384] [G loss: 2.269153]\n",
      "epoch2 step22290 [D loss: 0.164413] [G loss: 2.056991]\n",
      "epoch2 step22295 [D loss: 0.131509] [G loss: 1.885848]\n",
      "epoch2 step22300 [D loss: -0.506147] [G loss: 2.334369]\n",
      "epoch2 step22305 [D loss: -0.392450] [G loss: 2.477420]\n",
      "epoch2 step22310 [D loss: 0.020081] [G loss: 2.456945]\n",
      "epoch2 step22315 [D loss: -0.159594] [G loss: 2.345990]\n",
      "epoch2 step22320 [D loss: -0.006607] [G loss: 2.121205]\n",
      "epoch2 step22325 [D loss: -0.116213] [G loss: 2.208574]\n",
      "epoch2 step22330 [D loss: -0.541910] [G loss: 2.433750]\n",
      "epoch2 step22335 [D loss: 0.191102] [G loss: 2.036324]\n",
      "epoch2 step22340 [D loss: 0.197751] [G loss: 2.179334]\n",
      "epoch2 step22345 [D loss: 0.041159] [G loss: 2.391490]\n",
      "epoch2 step22350 [D loss: -0.384024] [G loss: 2.091746]\n",
      "epoch2 step22355 [D loss: 0.094761] [G loss: 1.610330]\n",
      "epoch2 step22360 [D loss: -0.015180] [G loss: 2.166046]\n",
      "epoch2 step22365 [D loss: -0.026117] [G loss: 1.474594]\n",
      "epoch2 step22370 [D loss: -0.044155] [G loss: 2.085469]\n",
      "epoch2 step22375 [D loss: -0.191181] [G loss: 1.832153]\n",
      "epoch2 step22380 [D loss: -0.016806] [G loss: 1.628940]\n",
      "epoch2 step22385 [D loss: 0.038366] [G loss: 1.791955]\n",
      "epoch2 step22390 [D loss: -0.159710] [G loss: 1.729942]\n",
      "epoch2 step22395 [D loss: 0.637725] [G loss: 1.645079]\n",
      "epoch2 step22400 [D loss: -0.341325] [G loss: 1.972720]\n",
      "epoch2 step22405 [D loss: -0.026246] [G loss: 1.636096]\n",
      "epoch2 step22410 [D loss: -0.459254] [G loss: 2.115691]\n",
      "epoch2 step22415 [D loss: -0.151614] [G loss: 1.820276]\n",
      "epoch2 step22420 [D loss: -0.326074] [G loss: 1.693549]\n",
      "epoch2 step22425 [D loss: 0.142625] [G loss: 1.918137]\n",
      "epoch2 step22430 [D loss: -0.112647] [G loss: 1.798758]\n",
      "epoch2 step22435 [D loss: -0.191147] [G loss: 1.507732]\n",
      "epoch2 step22440 [D loss: -0.069483] [G loss: 1.434168]\n",
      "epoch2 step22445 [D loss: 0.512879] [G loss: 1.778129]\n",
      "epoch2 step22450 [D loss: -0.271571] [G loss: 1.634407]\n",
      "epoch2 step22455 [D loss: -0.326756] [G loss: 1.283374]\n",
      "epoch2 step22460 [D loss: -0.027923] [G loss: 1.386976]\n",
      "epoch2 step22465 [D loss: -0.295747] [G loss: 1.542253]\n",
      "epoch2 step22470 [D loss: -0.099617] [G loss: 1.046172]\n",
      "epoch2 step22475 [D loss: 0.257302] [G loss: 1.017416]\n",
      "epoch2 step22480 [D loss: -0.021657] [G loss: 1.229731]\n",
      "epoch2 step22485 [D loss: -0.323712] [G loss: 1.546212]\n",
      "epoch2 step22490 [D loss: -0.395899] [G loss: 1.502954]\n",
      "epoch2 step22495 [D loss: -0.416003] [G loss: 1.114773]\n",
      "epoch2 step22500 [D loss: 0.244750] [G loss: 1.138881]\n",
      "epoch2 step22505 [D loss: -0.112854] [G loss: 0.843461]\n",
      "epoch2 step22510 [D loss: -0.068600] [G loss: 1.300858]\n",
      "epoch2 step22515 [D loss: -0.107002] [G loss: 1.140462]\n",
      "epoch2 step22520 [D loss: -0.631241] [G loss: 1.383942]\n",
      "epoch2 step22525 [D loss: 0.228919] [G loss: 1.263255]\n",
      "epoch2 step22530 [D loss: -0.260740] [G loss: 1.112470]\n",
      "epoch2 step22535 [D loss: -0.050343] [G loss: 1.101547]\n",
      "epoch2 step22540 [D loss: 0.093665] [G loss: 1.320632]\n",
      "epoch2 step22545 [D loss: -0.004118] [G loss: 1.100331]\n",
      "epoch2 step22550 [D loss: -0.356611] [G loss: 0.934530]\n",
      "epoch2 step22555 [D loss: -0.459303] [G loss: 1.210939]\n",
      "epoch2 step22560 [D loss: -0.656539] [G loss: 1.085690]\n",
      "epoch2 step22565 [D loss: -0.643197] [G loss: 1.255506]\n",
      "epoch2 step22570 [D loss: -0.555589] [G loss: 0.914620]\n",
      "epoch2 step22575 [D loss: -0.462559] [G loss: 1.358629]\n",
      "epoch2 step22580 [D loss: 0.150426] [G loss: 0.856384]\n",
      "epoch2 step22585 [D loss: -0.272614] [G loss: 0.926999]\n",
      "epoch2 step22590 [D loss: -0.443019] [G loss: 0.730536]\n",
      "epoch2 step22595 [D loss: -0.180913] [G loss: 0.712715]\n",
      "epoch2 step22600 [D loss: -0.025713] [G loss: 0.807670]\n",
      "epoch2 step22605 [D loss: -0.146969] [G loss: 1.352118]\n",
      "epoch2 step22610 [D loss: -1.084626] [G loss: 1.084015]\n",
      "epoch2 step22615 [D loss: -0.000363] [G loss: 0.443877]\n",
      "epoch2 step22620 [D loss: -0.415551] [G loss: 0.655253]\n",
      "epoch2 step22625 [D loss: -0.140027] [G loss: 0.663382]\n",
      "epoch2 step22630 [D loss: 0.274209] [G loss: 0.934369]\n",
      "epoch2 step22635 [D loss: -0.516546] [G loss: 0.746125]\n",
      "epoch2 step22640 [D loss: -0.106953] [G loss: 0.879098]\n",
      "epoch2 step22645 [D loss: -0.037562] [G loss: 0.670373]\n",
      "epoch2 step22650 [D loss: -0.683502] [G loss: 0.811396]\n",
      "epoch2 step22655 [D loss: 0.071451] [G loss: 0.506902]\n",
      "epoch2 step22660 [D loss: 0.211507] [G loss: 0.773273]\n",
      "epoch2 step22665 [D loss: -0.470805] [G loss: 0.806460]\n",
      "epoch2 step22670 [D loss: -0.742696] [G loss: 1.052467]\n",
      "epoch2 step22675 [D loss: 0.387292] [G loss: 0.523003]\n",
      "epoch2 step22680 [D loss: 0.020447] [G loss: 0.377758]\n",
      "epoch2 step22685 [D loss: 0.521480] [G loss: 0.587474]\n",
      "epoch2 step22690 [D loss: 0.251810] [G loss: 0.640598]\n",
      "epoch2 step22695 [D loss: -0.055781] [G loss: 0.837285]\n",
      "epoch2 step22700 [D loss: 0.066836] [G loss: 0.876024]\n",
      "epoch2 step22705 [D loss: -0.401390] [G loss: 0.808651]\n",
      "epoch2 step22710 [D loss: 0.005807] [G loss: 0.759023]\n",
      "epoch2 step22715 [D loss: -0.235736] [G loss: 0.710080]\n",
      "epoch2 step22720 [D loss: -0.291806] [G loss: 0.980126]\n",
      "epoch2 step22725 [D loss: -0.210065] [G loss: 0.785984]\n",
      "epoch2 step22730 [D loss: 0.058031] [G loss: 1.001801]\n",
      "epoch2 step22735 [D loss: -0.241883] [G loss: 0.847479]\n",
      "epoch2 step22740 [D loss: -0.088217] [G loss: 1.047876]\n",
      "epoch2 step22745 [D loss: -0.201652] [G loss: 1.092219]\n",
      "epoch2 step22750 [D loss: 0.169897] [G loss: 0.930362]\n",
      "epoch2 step22755 [D loss: -0.157954] [G loss: 0.902829]\n",
      "epoch2 step22760 [D loss: 0.045510] [G loss: 1.216320]\n",
      "epoch2 step22765 [D loss: 0.262900] [G loss: 0.942476]\n",
      "epoch2 step22770 [D loss: -0.243339] [G loss: 0.912294]\n",
      "epoch2 step22775 [D loss: -0.314335] [G loss: 0.795205]\n",
      "epoch2 step22780 [D loss: -0.117308] [G loss: 0.777725]\n",
      "epoch2 step22785 [D loss: -0.314880] [G loss: 0.775604]\n",
      "epoch2 step22790 [D loss: -0.499231] [G loss: 0.975720]\n",
      "epoch2 step22795 [D loss: -0.202463] [G loss: 1.068025]\n",
      "epoch2 step22800 [D loss: 0.085376] [G loss: 0.828105]\n",
      "epoch2 step22805 [D loss: -0.194969] [G loss: 0.695515]\n",
      "epoch2 step22810 [D loss: 0.127608] [G loss: 0.761997]\n",
      "epoch2 step22815 [D loss: -0.038596] [G loss: 0.379041]\n",
      "epoch2 step22820 [D loss: 0.194276] [G loss: 0.802650]\n",
      "epoch2 step22825 [D loss: -0.178772] [G loss: 0.848388]\n",
      "epoch2 step22830 [D loss: -0.334076] [G loss: 1.092010]\n",
      "epoch2 step22835 [D loss: -0.156810] [G loss: 0.261486]\n",
      "epoch2 step22840 [D loss: 0.080015] [G loss: 0.712682]\n",
      "epoch2 step22845 [D loss: 0.354100] [G loss: 0.371666]\n",
      "epoch2 step22850 [D loss: -0.421561] [G loss: 0.919641]\n",
      "epoch2 step22855 [D loss: -0.160904] [G loss: 0.954316]\n",
      "epoch2 step22860 [D loss: 0.049760] [G loss: 1.429516]\n",
      "epoch2 step22865 [D loss: -0.197668] [G loss: 0.810423]\n",
      "epoch2 step22870 [D loss: -0.042356] [G loss: 1.037886]\n",
      "epoch2 step22875 [D loss: -0.475110] [G loss: 0.900659]\n",
      "epoch2 step22880 [D loss: 0.167227] [G loss: 1.125015]\n",
      "epoch2 step22885 [D loss: -0.179632] [G loss: 0.999405]\n",
      "epoch2 step22890 [D loss: 0.326901] [G loss: 1.194517]\n",
      "epoch2 step22895 [D loss: -0.266753] [G loss: 1.163607]\n",
      "epoch2 step22900 [D loss: -0.164839] [G loss: 1.478391]\n",
      "epoch2 step22905 [D loss: -0.246930] [G loss: 1.319960]\n",
      "epoch2 step22910 [D loss: -0.423644] [G loss: 1.303491]\n",
      "epoch2 step22915 [D loss: 0.404704] [G loss: 1.053665]\n",
      "epoch2 step22920 [D loss: -0.800288] [G loss: 1.536779]\n",
      "epoch2 step22925 [D loss: -0.445204] [G loss: 1.323098]\n",
      "epoch2 step22930 [D loss: 0.005206] [G loss: 1.044633]\n",
      "epoch2 step22935 [D loss: 0.023228] [G loss: 1.213410]\n",
      "epoch2 step22940 [D loss: -0.572506] [G loss: 0.767677]\n",
      "epoch2 step22945 [D loss: 0.169365] [G loss: 0.915148]\n",
      "epoch2 step22950 [D loss: 0.102942] [G loss: 1.256879]\n",
      "epoch2 step22955 [D loss: -0.597355] [G loss: 1.077023]\n",
      "epoch2 step22960 [D loss: -0.251705] [G loss: 0.954495]\n",
      "epoch2 step22965 [D loss: -0.329567] [G loss: 1.149413]\n",
      "epoch2 step22970 [D loss: -0.043404] [G loss: 0.980609]\n",
      "epoch2 step22975 [D loss: -0.330427] [G loss: 0.716692]\n",
      "epoch2 step22980 [D loss: -0.464424] [G loss: 0.456642]\n",
      "epoch2 step22985 [D loss: -0.065418] [G loss: 1.050107]\n",
      "epoch2 step22990 [D loss: -0.026259] [G loss: 0.607408]\n",
      "epoch2 step22995 [D loss: -0.072761] [G loss: 0.617845]\n",
      "epoch2 step23000 [D loss: 0.356380] [G loss: 0.234856]\n",
      "epoch2 step23005 [D loss: -0.131074] [G loss: 0.595749]\n",
      "epoch2 step23010 [D loss: 0.139681] [G loss: 0.561637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2 step23015 [D loss: 0.134893] [G loss: 0.396273]\n",
      "epoch2 step23020 [D loss: 0.414730] [G loss: 0.218170]\n",
      "epoch2 step23025 [D loss: -0.275144] [G loss: 0.438491]\n",
      "epoch2 step23030 [D loss: 0.066464] [G loss: 0.517557]\n",
      "epoch2 step23035 [D loss: -0.043964] [G loss: 0.461970]\n",
      "epoch2 step23040 [D loss: 0.487344] [G loss: 0.450511]\n",
      "epoch2 step23045 [D loss: 0.146358] [G loss: 0.348639]\n",
      "epoch2 step23050 [D loss: 0.188448] [G loss: 0.831284]\n",
      "epoch2 step23055 [D loss: -0.183737] [G loss: 0.765623]\n",
      "epoch2 step23060 [D loss: 0.001044] [G loss: 0.963241]\n",
      "epoch2 step23065 [D loss: -0.014666] [G loss: 0.701320]\n",
      "epoch2 step23070 [D loss: -0.207297] [G loss: 0.696276]\n",
      "epoch2 step23075 [D loss: -0.306148] [G loss: 0.706884]\n",
      "epoch2 step23080 [D loss: 0.124519] [G loss: 0.904264]\n",
      "epoch2 step23085 [D loss: -0.006225] [G loss: 1.077920]\n",
      "epoch2 step23090 [D loss: -0.109183] [G loss: 1.051814]\n",
      "epoch2 step23095 [D loss: -0.222659] [G loss: 1.383841]\n",
      "epoch2 step23100 [D loss: -0.885818] [G loss: 1.430663]\n",
      "epoch2 step23105 [D loss: -0.188951] [G loss: 1.316913]\n",
      "epoch2 step23110 [D loss: 0.019717] [G loss: 0.889940]\n",
      "epoch2 step23115 [D loss: -0.324665] [G loss: 1.561016]\n",
      "epoch2 step23120 [D loss: -0.264763] [G loss: 1.550748]\n",
      "epoch2 step23125 [D loss: -0.493015] [G loss: 1.732345]\n",
      "epoch2 step23130 [D loss: 0.016356] [G loss: 1.464046]\n",
      "epoch2 step23135 [D loss: -0.147602] [G loss: 1.683710]\n",
      "epoch2 step23140 [D loss: -0.354971] [G loss: 2.085411]\n",
      "epoch2 step23145 [D loss: -0.531413] [G loss: 2.028381]\n",
      "epoch2 step23150 [D loss: -0.483260] [G loss: 1.866380]\n",
      "epoch2 step23155 [D loss: -0.296747] [G loss: 1.653745]\n",
      "epoch2 step23160 [D loss: -0.376266] [G loss: 1.762943]\n",
      "epoch2 step23165 [D loss: 0.259422] [G loss: 1.678196]\n",
      "epoch2 step23170 [D loss: -0.019492] [G loss: 1.592379]\n",
      "epoch2 step23175 [D loss: -0.164424] [G loss: 1.647113]\n",
      "epoch2 step23180 [D loss: -0.061599] [G loss: 1.493493]\n",
      "epoch2 step23185 [D loss: -0.435492] [G loss: 1.506831]\n",
      "epoch2 step23190 [D loss: 0.034695] [G loss: 1.197865]\n",
      "epoch2 step23195 [D loss: 0.192505] [G loss: 0.914824]\n",
      "epoch2 step23200 [D loss: -0.134440] [G loss: 1.413495]\n",
      "epoch2 step23205 [D loss: 0.161204] [G loss: 1.120716]\n",
      "epoch2 step23210 [D loss: -0.186949] [G loss: 1.148011]\n",
      "epoch2 step23215 [D loss: -0.172722] [G loss: 0.718070]\n",
      "epoch2 step23220 [D loss: -0.092259] [G loss: 0.826965]\n",
      "epoch2 step23225 [D loss: -0.134701] [G loss: 0.866266]\n",
      "epoch2 step23230 [D loss: 0.145924] [G loss: 0.339123]\n",
      "epoch2 step23235 [D loss: -0.172122] [G loss: 0.792374]\n",
      "epoch2 step23240 [D loss: -0.026516] [G loss: 0.746540]\n",
      "epoch2 step23245 [D loss: 0.083405] [G loss: 0.869504]\n",
      "epoch2 step23250 [D loss: -0.423415] [G loss: 0.782044]\n",
      "epoch2 step23255 [D loss: 0.104017] [G loss: 0.645009]\n",
      "epoch2 step23260 [D loss: 0.712189] [G loss: 0.186968]\n",
      "epoch2 step23265 [D loss: 0.254682] [G loss: 0.472095]\n",
      "epoch2 step23270 [D loss: 0.065611] [G loss: 0.559546]\n",
      "epoch2 step23275 [D loss: -0.003224] [G loss: 0.352929]\n",
      "epoch2 step23280 [D loss: 0.138366] [G loss: 0.397989]\n",
      "epoch2 step23285 [D loss: 0.097063] [G loss: 0.342547]\n",
      "epoch2 step23290 [D loss: -0.062758] [G loss: 0.382419]\n",
      "epoch2 step23295 [D loss: -0.000012] [G loss: 0.441372]\n",
      "epoch2 step23300 [D loss: -0.132530] [G loss: 0.481115]\n",
      "epoch2 step23305 [D loss: -0.055732] [G loss: 0.194022]\n",
      "epoch2 step23310 [D loss: 0.003529] [G loss: 0.477101]\n",
      "epoch2 step23315 [D loss: -0.396907] [G loss: 0.377254]\n",
      "epoch2 step23320 [D loss: -0.152264] [G loss: 0.371278]\n",
      "epoch2 step23325 [D loss: 0.169470] [G loss: 0.360159]\n",
      "epoch2 step23330 [D loss: 0.245374] [G loss: 0.553376]\n",
      "epoch2 step23335 [D loss: -0.029892] [G loss: 0.245603]\n",
      "epoch2 step23340 [D loss: 0.084909] [G loss: 0.277629]\n",
      "epoch2 step23345 [D loss: -0.399888] [G loss: 0.541487]\n",
      "epoch2 step23350 [D loss: 0.064188] [G loss: 0.497090]\n",
      "epoch2 step23355 [D loss: 0.244770] [G loss: 0.367677]\n",
      "epoch2 step23360 [D loss: 0.045409] [G loss: 0.660684]\n",
      "epoch2 step23365 [D loss: 0.035386] [G loss: 0.823905]\n",
      "epoch2 step23370 [D loss: -0.320655] [G loss: 0.659026]\n",
      "epoch2 step23375 [D loss: -0.012644] [G loss: 0.715160]\n",
      "epoch2 step23380 [D loss: -0.140612] [G loss: 0.987204]\n",
      "epoch2 step23385 [D loss: -0.465211] [G loss: 0.911808]\n",
      "epoch2 step23390 [D loss: 0.160334] [G loss: 0.976705]\n",
      "epoch2 step23395 [D loss: -0.298854] [G loss: 1.072594]\n",
      "epoch2 step23400 [D loss: -0.225258] [G loss: 1.211332]\n",
      "epoch2 step23405 [D loss: -0.128067] [G loss: 1.044858]\n",
      "epoch2 step23410 [D loss: -0.156901] [G loss: 1.085713]\n",
      "epoch2 step23415 [D loss: 0.095419] [G loss: 0.953327]\n",
      "epoch2 step23420 [D loss: -0.199321] [G loss: 1.215772]\n",
      "epoch2 step23425 [D loss: 0.031262] [G loss: 1.110549]\n",
      "epoch2 step23430 [D loss: -0.108909] [G loss: 1.199592]\n",
      "epoch3 step23435 [D loss: 0.279577] [G loss: 1.130157]\n",
      "epoch3 step23440 [D loss: 0.377917] [G loss: 1.224165]\n",
      "epoch3 step23445 [D loss: 0.125524] [G loss: 1.602780]\n",
      "epoch3 step23450 [D loss: 0.362100] [G loss: 1.251285]\n",
      "epoch3 step23455 [D loss: -0.276861] [G loss: 1.453915]\n",
      "epoch3 step23460 [D loss: 0.130508] [G loss: 1.674142]\n",
      "epoch3 step23465 [D loss: -0.284426] [G loss: 1.599916]\n",
      "epoch3 step23470 [D loss: 0.148699] [G loss: 1.854306]\n",
      "epoch3 step23475 [D loss: 0.379646] [G loss: 1.872931]\n",
      "epoch3 step23480 [D loss: 0.013115] [G loss: 1.889137]\n",
      "epoch3 step23485 [D loss: 0.058908] [G loss: 1.736324]\n",
      "epoch3 step23490 [D loss: -0.617629] [G loss: 2.099293]\n",
      "epoch3 step23495 [D loss: 0.073811] [G loss: 1.903986]\n",
      "epoch3 step23500 [D loss: -0.158851] [G loss: 1.996376]\n",
      "epoch3 step23505 [D loss: -0.291188] [G loss: 2.169306]\n",
      "epoch3 step23510 [D loss: 0.430490] [G loss: 2.076973]\n",
      "epoch3 step23515 [D loss: 0.086411] [G loss: 1.971499]\n",
      "epoch3 step23520 [D loss: 0.659785] [G loss: 1.945329]\n",
      "epoch3 step23525 [D loss: 0.328521] [G loss: 2.401959]\n",
      "epoch3 step23530 [D loss: 0.260563] [G loss: 2.179326]\n",
      "epoch3 step23535 [D loss: -0.401121] [G loss: 1.952564]\n",
      "epoch3 step23540 [D loss: -0.293502] [G loss: 1.996525]\n",
      "epoch3 step23545 [D loss: 0.156401] [G loss: 1.924848]\n",
      "epoch3 step23550 [D loss: -0.053276] [G loss: 2.212948]\n",
      "epoch3 step23555 [D loss: -0.217307] [G loss: 2.151730]\n",
      "epoch3 step23560 [D loss: 0.116904] [G loss: 1.924139]\n",
      "epoch3 step23565 [D loss: -0.397538] [G loss: 1.626072]\n",
      "epoch3 step23570 [D loss: -0.098768] [G loss: 1.841396]\n",
      "epoch3 step23575 [D loss: 0.018475] [G loss: 1.609236]\n",
      "epoch3 step23580 [D loss: 0.039171] [G loss: 1.836486]\n",
      "epoch3 step23585 [D loss: 0.050234] [G loss: 2.028964]\n",
      "epoch3 step23590 [D loss: 0.010482] [G loss: 1.597992]\n",
      "epoch3 step23595 [D loss: -0.436847] [G loss: 1.945848]\n",
      "epoch3 step23600 [D loss: 0.078038] [G loss: 1.937025]\n",
      "epoch3 step23605 [D loss: -0.222559] [G loss: 1.590159]\n",
      "epoch3 step23610 [D loss: -0.308527] [G loss: 1.831868]\n",
      "epoch3 step23615 [D loss: -0.331019] [G loss: 1.820366]\n",
      "epoch3 step23620 [D loss: 0.377040] [G loss: 1.636734]\n",
      "epoch3 step23625 [D loss: -0.134668] [G loss: 1.716007]\n",
      "epoch3 step23630 [D loss: 0.343572] [G loss: 1.746194]\n",
      "epoch3 step23635 [D loss: 0.266738] [G loss: 1.392370]\n",
      "epoch3 step23640 [D loss: -0.086897] [G loss: 1.439484]\n",
      "epoch3 step23645 [D loss: 0.240500] [G loss: 1.659266]\n",
      "epoch3 step23650 [D loss: 0.092075] [G loss: 1.558589]\n",
      "epoch3 step23655 [D loss: -0.140718] [G loss: 1.548356]\n",
      "epoch3 step23660 [D loss: -0.539003] [G loss: 1.754705]\n",
      "epoch3 step23665 [D loss: -0.017619] [G loss: 1.642975]\n",
      "epoch3 step23670 [D loss: -0.404997] [G loss: 1.517670]\n",
      "epoch3 step23675 [D loss: 0.285043] [G loss: 1.882948]\n",
      "epoch3 step23680 [D loss: -0.023666] [G loss: 1.785641]\n",
      "epoch3 step23685 [D loss: -0.083177] [G loss: 1.311119]\n",
      "epoch3 step23690 [D loss: -0.509569] [G loss: 1.827061]\n",
      "epoch3 step23695 [D loss: -0.061301] [G loss: 1.446299]\n",
      "epoch3 step23700 [D loss: -0.060665] [G loss: 1.212786]\n",
      "epoch3 step23705 [D loss: -0.402268] [G loss: 1.146253]\n",
      "epoch3 step23710 [D loss: -0.204428] [G loss: 1.323827]\n",
      "epoch3 step23715 [D loss: -0.240606] [G loss: 1.582960]\n",
      "epoch3 step23720 [D loss: -0.039074] [G loss: 1.588928]\n",
      "epoch3 step23725 [D loss: 0.186961] [G loss: 1.198438]\n",
      "epoch3 step23730 [D loss: -0.066510] [G loss: 1.425133]\n",
      "epoch3 step23735 [D loss: 0.291196] [G loss: 1.191644]\n",
      "epoch3 step23740 [D loss: 0.170611] [G loss: 1.345790]\n",
      "epoch3 step23745 [D loss: -0.312457] [G loss: 1.139359]\n",
      "epoch3 step23750 [D loss: 0.119687] [G loss: 1.302660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step23755 [D loss: -0.483911] [G loss: 1.404436]\n",
      "epoch3 step23760 [D loss: -0.062030] [G loss: 0.919403]\n",
      "epoch3 step23765 [D loss: 0.389087] [G loss: 0.757599]\n",
      "epoch3 step23770 [D loss: 0.305419] [G loss: 0.621580]\n",
      "epoch3 step23775 [D loss: -0.096697] [G loss: 0.888237]\n",
      "epoch3 step23780 [D loss: -0.089909] [G loss: 1.085982]\n",
      "epoch3 step23785 [D loss: -0.419276] [G loss: 0.739843]\n",
      "epoch3 step23790 [D loss: -0.404760] [G loss: 0.777317]\n",
      "epoch3 step23795 [D loss: -0.040826] [G loss: 0.900837]\n",
      "epoch3 step23800 [D loss: 0.322003] [G loss: 0.443856]\n",
      "epoch3 step23805 [D loss: 0.006959] [G loss: 0.355649]\n",
      "epoch3 step23810 [D loss: 0.099213] [G loss: 0.585913]\n",
      "epoch3 step23815 [D loss: -0.119797] [G loss: 0.573692]\n",
      "epoch3 step23820 [D loss: -0.177287] [G loss: 0.471837]\n",
      "epoch3 step23825 [D loss: 0.075047] [G loss: 0.265979]\n",
      "epoch3 step23830 [D loss: -0.176131] [G loss: 0.614797]\n",
      "epoch3 step23835 [D loss: 0.301218] [G loss: 0.691059]\n",
      "epoch3 step23840 [D loss: -0.125840] [G loss: 0.148231]\n",
      "epoch3 step23845 [D loss: -0.296702] [G loss: 0.391620]\n",
      "epoch3 step23850 [D loss: -0.383758] [G loss: 0.214022]\n",
      "epoch3 step23855 [D loss: 0.029459] [G loss: 0.236325]\n",
      "epoch3 step23860 [D loss: 0.525832] [G loss: 0.582955]\n",
      "epoch3 step23865 [D loss: 0.116869] [G loss: 0.323015]\n",
      "epoch3 step23870 [D loss: 0.026252] [G loss: 0.349517]\n",
      "epoch3 step23875 [D loss: -0.197231] [G loss: 0.214658]\n",
      "epoch3 step23880 [D loss: 0.350778] [G loss: 0.525668]\n",
      "epoch3 step23885 [D loss: 0.447713] [G loss: 0.441712]\n",
      "epoch3 step23890 [D loss: -0.016290] [G loss: 0.568099]\n",
      "epoch3 step23895 [D loss: 0.231801] [G loss: 0.663864]\n",
      "epoch3 step23900 [D loss: -0.252547] [G loss: 0.699316]\n",
      "epoch3 step23905 [D loss: -0.195312] [G loss: 0.800747]\n",
      "epoch3 step23910 [D loss: 0.362978] [G loss: 0.792600]\n",
      "epoch3 step23915 [D loss: 0.057139] [G loss: 0.849226]\n",
      "epoch3 step23920 [D loss: 0.058119] [G loss: 0.646440]\n",
      "epoch3 step23925 [D loss: 0.164677] [G loss: 0.898121]\n",
      "epoch3 step23930 [D loss: -0.112272] [G loss: 0.791052]\n",
      "epoch3 step23935 [D loss: -0.473213] [G loss: 1.259990]\n",
      "epoch3 step23940 [D loss: -0.619408] [G loss: 0.974923]\n",
      "epoch3 step23945 [D loss: -0.049683] [G loss: 1.128898]\n",
      "epoch3 step23950 [D loss: 0.381935] [G loss: 0.962707]\n",
      "epoch3 step23955 [D loss: -0.088526] [G loss: 1.324777]\n",
      "epoch3 step23960 [D loss: -0.107717] [G loss: 1.185538]\n",
      "epoch3 step23965 [D loss: -0.104397] [G loss: 1.009143]\n",
      "epoch3 step23970 [D loss: 0.249908] [G loss: 1.242864]\n",
      "epoch3 step23975 [D loss: 0.159924] [G loss: 1.064250]\n",
      "epoch3 step23980 [D loss: -0.149456] [G loss: 0.987392]\n",
      "epoch3 step23985 [D loss: -0.103766] [G loss: 0.740548]\n",
      "epoch3 step23990 [D loss: -0.089725] [G loss: 0.896312]\n",
      "epoch3 step23995 [D loss: 0.226568] [G loss: 1.172918]\n",
      "epoch3 step24000 [D loss: -0.568248] [G loss: 0.968039]\n",
      "epoch3 step24005 [D loss: -0.469613] [G loss: 0.832910]\n",
      "epoch3 step24010 [D loss: 0.095921] [G loss: 0.752386]\n",
      "epoch3 step24015 [D loss: 0.182611] [G loss: 0.689835]\n",
      "epoch3 step24020 [D loss: -0.213424] [G loss: 0.736201]\n",
      "epoch3 step24025 [D loss: 0.109494] [G loss: 0.914535]\n",
      "epoch3 step24030 [D loss: -0.339575] [G loss: 0.722894]\n",
      "epoch3 step24035 [D loss: -0.188832] [G loss: 0.922644]\n",
      "epoch3 step24040 [D loss: -0.129654] [G loss: 0.788584]\n",
      "epoch3 step24045 [D loss: -0.119979] [G loss: 1.110793]\n",
      "epoch3 step24050 [D loss: -0.253695] [G loss: 1.089926]\n",
      "epoch3 step24055 [D loss: -0.191935] [G loss: 1.107627]\n",
      "epoch3 step24060 [D loss: 0.055140] [G loss: 1.005442]\n",
      "epoch3 step24065 [D loss: 0.210344] [G loss: 1.111452]\n",
      "epoch3 step24070 [D loss: -0.122634] [G loss: 0.748373]\n",
      "epoch3 step24075 [D loss: 0.000625] [G loss: 1.143656]\n",
      "epoch3 step24080 [D loss: -0.034742] [G loss: 1.121574]\n",
      "epoch3 step24085 [D loss: 0.025071] [G loss: 1.186070]\n",
      "epoch3 step24090 [D loss: -0.262564] [G loss: 1.298944]\n",
      "epoch3 step24095 [D loss: -0.446755] [G loss: 0.992058]\n",
      "epoch3 step24100 [D loss: -0.545461] [G loss: 0.906209]\n",
      "epoch3 step24105 [D loss: -0.126476] [G loss: 1.091504]\n",
      "epoch3 step24110 [D loss: -0.290314] [G loss: 1.470322]\n",
      "epoch3 step24115 [D loss: 0.411624] [G loss: 0.978925]\n",
      "epoch3 step24120 [D loss: -0.102892] [G loss: 1.075589]\n",
      "epoch3 step24125 [D loss: -0.451594] [G loss: 1.432906]\n",
      "epoch3 step24130 [D loss: -0.453911] [G loss: 1.401655]\n",
      "epoch3 step24135 [D loss: -0.282202] [G loss: 1.291324]\n",
      "epoch3 step24140 [D loss: -0.384651] [G loss: 1.402352]\n",
      "epoch3 step24145 [D loss: -0.424659] [G loss: 1.567771]\n",
      "epoch3 step24150 [D loss: 0.489500] [G loss: 1.273818]\n",
      "epoch3 step24155 [D loss: 0.141728] [G loss: 1.110180]\n",
      "epoch3 step24160 [D loss: 0.411616] [G loss: 1.348297]\n",
      "epoch3 step24165 [D loss: -0.196113] [G loss: 1.380791]\n",
      "epoch3 step24170 [D loss: -0.406599] [G loss: 1.638922]\n",
      "epoch3 step24175 [D loss: -0.423643] [G loss: 1.585353]\n",
      "epoch3 step24180 [D loss: -0.062558] [G loss: 1.256734]\n",
      "epoch3 step24185 [D loss: -0.034079] [G loss: 1.637646]\n",
      "epoch3 step24190 [D loss: -0.265674] [G loss: 1.441257]\n",
      "epoch3 step24195 [D loss: 0.225506] [G loss: 1.620656]\n",
      "epoch3 step24200 [D loss: -0.242984] [G loss: 1.413597]\n",
      "epoch3 step24205 [D loss: -0.067067] [G loss: 1.278066]\n",
      "epoch3 step24210 [D loss: -0.172635] [G loss: 1.169785]\n",
      "epoch3 step24215 [D loss: -0.161599] [G loss: 1.158839]\n",
      "epoch3 step24220 [D loss: -0.040882] [G loss: 1.159413]\n",
      "epoch3 step24225 [D loss: 0.109227] [G loss: 1.269754]\n",
      "epoch3 step24230 [D loss: -0.067909] [G loss: 0.901492]\n",
      "epoch3 step24235 [D loss: -0.128778] [G loss: 1.031260]\n",
      "epoch3 step24240 [D loss: -0.052283] [G loss: 1.302113]\n",
      "epoch3 step24245 [D loss: -0.361192] [G loss: 1.253983]\n",
      "epoch3 step24250 [D loss: 0.080118] [G loss: 1.510198]\n",
      "epoch3 step24255 [D loss: -0.074998] [G loss: 1.237191]\n",
      "epoch3 step24260 [D loss: 0.073738] [G loss: 1.523755]\n",
      "epoch3 step24265 [D loss: -0.760899] [G loss: 1.601465]\n",
      "epoch3 step24270 [D loss: -0.244474] [G loss: 1.546323]\n",
      "epoch3 step24275 [D loss: -0.266278] [G loss: 1.438288]\n",
      "epoch3 step24280 [D loss: -0.136204] [G loss: 1.409542]\n",
      "epoch3 step24285 [D loss: -0.326103] [G loss: 1.234637]\n",
      "epoch3 step24290 [D loss: -0.395965] [G loss: 1.227348]\n",
      "epoch3 step24295 [D loss: -0.748958] [G loss: 1.457672]\n",
      "epoch3 step24300 [D loss: -0.109019] [G loss: 1.501181]\n",
      "epoch3 step24305 [D loss: -0.320492] [G loss: 1.428166]\n",
      "epoch3 step24310 [D loss: -0.008457] [G loss: 1.492454]\n",
      "epoch3 step24315 [D loss: 0.037534] [G loss: 1.454594]\n",
      "epoch3 step24320 [D loss: -0.363071] [G loss: 1.397863]\n",
      "epoch3 step24325 [D loss: 0.010765] [G loss: 1.274642]\n",
      "epoch3 step24330 [D loss: 0.116460] [G loss: 1.519299]\n",
      "epoch3 step24335 [D loss: -0.006181] [G loss: 1.301438]\n",
      "epoch3 step24340 [D loss: 0.107652] [G loss: 1.492989]\n",
      "epoch3 step24345 [D loss: 0.055502] [G loss: 1.595242]\n",
      "epoch3 step24350 [D loss: -0.172809] [G loss: 1.349057]\n",
      "epoch3 step24355 [D loss: 0.313802] [G loss: 1.328671]\n",
      "epoch3 step24360 [D loss: -0.391320] [G loss: 1.466388]\n",
      "epoch3 step24365 [D loss: -0.169211] [G loss: 1.668502]\n",
      "epoch3 step24370 [D loss: -0.107311] [G loss: 1.369676]\n",
      "epoch3 step24375 [D loss: -0.309694] [G loss: 1.678799]\n",
      "epoch3 step24380 [D loss: -0.115141] [G loss: 1.541526]\n",
      "epoch3 step24385 [D loss: -0.335605] [G loss: 1.536440]\n",
      "epoch3 step24390 [D loss: -0.433139] [G loss: 1.504341]\n",
      "epoch3 step24395 [D loss: -0.325362] [G loss: 1.511452]\n",
      "epoch3 step24400 [D loss: -0.323220] [G loss: 1.213717]\n",
      "epoch3 step24405 [D loss: -0.016420] [G loss: 1.083417]\n",
      "epoch3 step24410 [D loss: -0.526872] [G loss: 1.427461]\n",
      "epoch3 step24415 [D loss: -0.533896] [G loss: 1.055866]\n",
      "epoch3 step24420 [D loss: 0.013537] [G loss: 1.103020]\n",
      "epoch3 step24425 [D loss: -0.220575] [G loss: 0.907886]\n",
      "epoch3 step24430 [D loss: -0.007506] [G loss: 1.104489]\n",
      "epoch3 step24435 [D loss: -0.560487] [G loss: 1.295844]\n",
      "epoch3 step24440 [D loss: -0.194680] [G loss: 0.932420]\n",
      "epoch3 step24445 [D loss: 0.112556] [G loss: 0.910600]\n",
      "epoch3 step24450 [D loss: -0.037484] [G loss: 0.930215]\n",
      "epoch3 step24455 [D loss: -0.352341] [G loss: 0.969459]\n",
      "epoch3 step24460 [D loss: -0.287895] [G loss: 0.817216]\n",
      "epoch3 step24465 [D loss: -0.124387] [G loss: 0.677134]\n",
      "epoch3 step24470 [D loss: -0.439943] [G loss: 0.937486]\n",
      "epoch3 step24475 [D loss: 0.196659] [G loss: 0.731860]\n",
      "epoch3 step24480 [D loss: -0.293686] [G loss: 0.873125]\n",
      "epoch3 step24485 [D loss: -0.360207] [G loss: 0.677610]\n",
      "epoch3 step24490 [D loss: -0.545268] [G loss: 0.737090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step24495 [D loss: -0.411303] [G loss: 0.658352]\n",
      "epoch3 step24500 [D loss: -0.355292] [G loss: 0.523957]\n",
      "epoch3 step24505 [D loss: -0.570110] [G loss: 0.465222]\n",
      "epoch3 step24510 [D loss: -0.281433] [G loss: 0.331572]\n",
      "epoch3 step24515 [D loss: 0.006698] [G loss: 0.472994]\n",
      "epoch3 step24520 [D loss: -0.051317] [G loss: 0.789074]\n",
      "epoch3 step24525 [D loss: -0.281024] [G loss: 0.151199]\n",
      "epoch3 step24530 [D loss: -0.187460] [G loss: 0.342525]\n",
      "epoch3 step24535 [D loss: 0.464902] [G loss: -0.129976]\n",
      "epoch3 step24540 [D loss: -0.100244] [G loss: 0.016844]\n",
      "epoch3 step24545 [D loss: -0.304499] [G loss: 0.429493]\n",
      "epoch3 step24550 [D loss: 0.024789] [G loss: 0.502377]\n",
      "epoch3 step24555 [D loss: -0.127352] [G loss: 0.454887]\n",
      "epoch3 step24560 [D loss: 0.392043] [G loss: 0.486576]\n",
      "epoch3 step24565 [D loss: -0.041831] [G loss: 0.372987]\n",
      "epoch3 step24570 [D loss: 0.422034] [G loss: 0.511797]\n",
      "epoch3 step24575 [D loss: -0.061917] [G loss: 0.547293]\n",
      "epoch3 step24580 [D loss: -0.351882] [G loss: 0.379330]\n",
      "epoch3 step24585 [D loss: -0.413894] [G loss: 0.692547]\n",
      "epoch3 step24590 [D loss: -0.109467] [G loss: 0.228303]\n",
      "epoch3 step24595 [D loss: -0.672810] [G loss: 0.640625]\n",
      "epoch3 step24600 [D loss: 0.055325] [G loss: 0.710841]\n",
      "epoch3 step24605 [D loss: 0.102002] [G loss: 0.939518]\n",
      "epoch3 step24610 [D loss: -0.100759] [G loss: 0.835202]\n",
      "epoch3 step24615 [D loss: -0.075369] [G loss: 0.812522]\n",
      "epoch3 step24620 [D loss: -0.302953] [G loss: 0.886083]\n",
      "epoch3 step24625 [D loss: -0.223349] [G loss: 1.222791]\n",
      "epoch3 step24630 [D loss: -0.061555] [G loss: 1.077062]\n",
      "epoch3 step24635 [D loss: -0.241182] [G loss: 0.949248]\n",
      "epoch3 step24640 [D loss: 0.021135] [G loss: 1.041771]\n",
      "epoch3 step24645 [D loss: -0.101721] [G loss: 1.496319]\n",
      "epoch3 step24650 [D loss: -0.393949] [G loss: 1.077351]\n",
      "epoch3 step24655 [D loss: -0.085798] [G loss: 0.847229]\n",
      "epoch3 step24660 [D loss: -0.051435] [G loss: 1.089374]\n",
      "epoch3 step24665 [D loss: -0.137682] [G loss: 1.060091]\n",
      "epoch3 step24670 [D loss: 0.077625] [G loss: 1.140105]\n",
      "epoch3 step24675 [D loss: 0.120162] [G loss: 1.144530]\n",
      "epoch3 step24680 [D loss: -0.476318] [G loss: 1.269925]\n",
      "epoch3 step24685 [D loss: -0.310205] [G loss: 1.083912]\n",
      "epoch3 step24690 [D loss: -0.630693] [G loss: 1.373819]\n",
      "epoch3 step24695 [D loss: 0.251451] [G loss: 1.125331]\n",
      "epoch3 step24700 [D loss: -0.137782] [G loss: 1.099429]\n",
      "epoch3 step24705 [D loss: 0.118854] [G loss: 0.949722]\n",
      "epoch3 step24710 [D loss: -0.054442] [G loss: 1.574527]\n",
      "epoch3 step24715 [D loss: 0.440536] [G loss: 1.629890]\n",
      "epoch3 step24720 [D loss: 0.080846] [G loss: 1.528524]\n",
      "epoch3 step24725 [D loss: -0.094735] [G loss: 1.201745]\n",
      "epoch3 step24730 [D loss: -0.187253] [G loss: 1.072592]\n",
      "epoch3 step24735 [D loss: -0.096249] [G loss: 1.414851]\n",
      "epoch3 step24740 [D loss: 0.394681] [G loss: 0.920110]\n",
      "epoch3 step24745 [D loss: -0.072264] [G loss: 1.182017]\n",
      "epoch3 step24750 [D loss: 0.085756] [G loss: 1.376254]\n",
      "epoch3 step24755 [D loss: -0.238967] [G loss: 1.280372]\n",
      "epoch3 step24760 [D loss: -0.209461] [G loss: 1.474765]\n",
      "epoch3 step24765 [D loss: -0.084668] [G loss: 0.978467]\n",
      "epoch3 step24770 [D loss: 0.020890] [G loss: 1.248203]\n",
      "epoch3 step24775 [D loss: 0.179826] [G loss: 1.280098]\n",
      "epoch3 step24780 [D loss: 0.087993] [G loss: 1.208676]\n",
      "epoch3 step24785 [D loss: -0.242724] [G loss: 1.200045]\n",
      "epoch3 step24790 [D loss: -0.222679] [G loss: 1.387459]\n",
      "epoch3 step24795 [D loss: 0.126416] [G loss: 1.533548]\n",
      "epoch3 step24800 [D loss: 0.117311] [G loss: 1.332930]\n",
      "epoch3 step24805 [D loss: 0.289769] [G loss: 1.537404]\n",
      "epoch3 step24810 [D loss: -0.145899] [G loss: 1.531579]\n",
      "epoch3 step24815 [D loss: 0.072589] [G loss: 1.348262]\n",
      "epoch3 step24820 [D loss: 0.136962] [G loss: 1.403730]\n",
      "epoch3 step24825 [D loss: -0.126445] [G loss: 1.450656]\n",
      "epoch3 step24830 [D loss: 0.080970] [G loss: 1.375247]\n",
      "epoch3 step24835 [D loss: 0.229125] [G loss: 1.455701]\n",
      "epoch3 step24840 [D loss: -0.236434] [G loss: 1.667696]\n",
      "epoch3 step24845 [D loss: -0.525080] [G loss: 1.388281]\n",
      "epoch3 step24850 [D loss: 0.135592] [G loss: 1.455777]\n",
      "epoch3 step24855 [D loss: -0.091608] [G loss: 1.722878]\n",
      "epoch3 step24860 [D loss: -0.228150] [G loss: 1.487995]\n",
      "epoch3 step24865 [D loss: -0.185468] [G loss: 1.546170]\n",
      "epoch3 step24870 [D loss: -0.004190] [G loss: 1.543657]\n",
      "epoch3 step24875 [D loss: -0.094051] [G loss: 1.514812]\n",
      "epoch3 step24880 [D loss: -0.292050] [G loss: 1.606950]\n",
      "epoch3 step24885 [D loss: -0.239295] [G loss: 1.560679]\n",
      "epoch3 step24890 [D loss: -0.042258] [G loss: 1.461998]\n",
      "epoch3 step24895 [D loss: -0.155825] [G loss: 1.734715]\n",
      "epoch3 step24900 [D loss: 0.000067] [G loss: 1.525747]\n",
      "epoch3 step24905 [D loss: 0.027061] [G loss: 1.690067]\n",
      "epoch3 step24910 [D loss: -0.177107] [G loss: 1.698727]\n",
      "epoch3 step24915 [D loss: -0.151042] [G loss: 1.993248]\n",
      "epoch3 step24920 [D loss: -0.427760] [G loss: 1.904728]\n",
      "epoch3 step24925 [D loss: -0.191664] [G loss: 1.650846]\n",
      "epoch3 step24930 [D loss: 0.064023] [G loss: 1.969796]\n",
      "epoch3 step24935 [D loss: -0.375956] [G loss: 2.349719]\n",
      "epoch3 step24940 [D loss: -0.199947] [G loss: 2.297461]\n",
      "epoch3 step24945 [D loss: 0.016556] [G loss: 2.012781]\n",
      "epoch3 step24950 [D loss: -0.182188] [G loss: 2.073844]\n",
      "epoch3 step24955 [D loss: 0.185673] [G loss: 1.979032]\n",
      "epoch3 step24960 [D loss: 0.150183] [G loss: 2.034267]\n",
      "epoch3 step24965 [D loss: -0.008093] [G loss: 1.890393]\n",
      "epoch3 step24970 [D loss: -0.349658] [G loss: 1.564970]\n",
      "epoch3 step24975 [D loss: 0.129614] [G loss: 2.053246]\n",
      "epoch3 step24980 [D loss: 0.018290] [G loss: 1.649734]\n",
      "epoch3 step24985 [D loss: -0.268869] [G loss: 1.886240]\n",
      "epoch3 step24990 [D loss: 0.448586] [G loss: 1.919766]\n",
      "epoch3 step24995 [D loss: 0.225710] [G loss: 1.497488]\n",
      "epoch3 step25000 [D loss: -0.130197] [G loss: 1.852826]\n",
      "epoch3 step25005 [D loss: -0.574911] [G loss: 1.926130]\n",
      "epoch3 step25010 [D loss: 0.122668] [G loss: 1.788025]\n",
      "epoch3 step25015 [D loss: -0.233674] [G loss: 1.726597]\n",
      "epoch3 step25020 [D loss: 0.298060] [G loss: 1.859841]\n",
      "epoch3 step25025 [D loss: 0.114123] [G loss: 1.825890]\n",
      "epoch3 step25030 [D loss: 0.002107] [G loss: 1.581082]\n",
      "epoch3 step25035 [D loss: 0.072288] [G loss: 1.454726]\n",
      "epoch3 step25040 [D loss: -0.364728] [G loss: 1.488571]\n",
      "epoch3 step25045 [D loss: -0.096856] [G loss: 1.641520]\n",
      "epoch3 step25050 [D loss: 0.096177] [G loss: 1.666246]\n",
      "epoch3 step25055 [D loss: -0.168224] [G loss: 1.089222]\n",
      "epoch3 step25060 [D loss: -0.481524] [G loss: 1.689811]\n",
      "epoch3 step25065 [D loss: -0.254380] [G loss: 1.522351]\n",
      "epoch3 step25070 [D loss: -0.537959] [G loss: 1.363652]\n",
      "epoch3 step25075 [D loss: -0.105732] [G loss: 1.471919]\n",
      "epoch3 step25080 [D loss: -0.034371] [G loss: 1.229551]\n",
      "epoch3 step25085 [D loss: -0.051098] [G loss: 1.466084]\n",
      "epoch3 step25090 [D loss: -0.237791] [G loss: 1.335203]\n",
      "epoch3 step25095 [D loss: 0.266928] [G loss: 1.276948]\n",
      "epoch3 step25100 [D loss: -0.118677] [G loss: 1.345485]\n",
      "epoch3 step25105 [D loss: -0.215504] [G loss: 1.395760]\n",
      "epoch3 step25110 [D loss: -0.193583] [G loss: 1.104181]\n",
      "epoch3 step25115 [D loss: 0.265588] [G loss: 1.186415]\n",
      "epoch3 step25120 [D loss: -0.114578] [G loss: 1.276363]\n",
      "epoch3 step25125 [D loss: -0.025637] [G loss: 1.224143]\n",
      "epoch3 step25130 [D loss: -0.046575] [G loss: 1.030696]\n",
      "epoch3 step25135 [D loss: -0.635882] [G loss: 1.268573]\n",
      "epoch3 step25140 [D loss: -0.091246] [G loss: 0.875794]\n",
      "epoch3 step25145 [D loss: 0.267903] [G loss: 0.719791]\n",
      "epoch3 step25150 [D loss: -0.295460] [G loss: 0.751614]\n",
      "epoch3 step25155 [D loss: -0.500268] [G loss: 1.279347]\n",
      "epoch3 step25160 [D loss: -0.003041] [G loss: 1.305380]\n",
      "epoch3 step25165 [D loss: 0.121255] [G loss: 1.126657]\n",
      "epoch3 step25170 [D loss: -0.223392] [G loss: 1.386955]\n",
      "epoch3 step25175 [D loss: -0.173831] [G loss: 0.963353]\n",
      "epoch3 step25180 [D loss: 0.332618] [G loss: 0.773583]\n",
      "epoch3 step25185 [D loss: -0.138285] [G loss: 1.002642]\n",
      "epoch3 step25190 [D loss: -0.152372] [G loss: 0.981361]\n",
      "epoch3 step25195 [D loss: -0.142378] [G loss: 1.299314]\n",
      "epoch3 step25200 [D loss: 0.010916] [G loss: 0.427445]\n",
      "epoch3 step25205 [D loss: -0.256350] [G loss: 0.913583]\n",
      "epoch3 step25210 [D loss: -0.394461] [G loss: 1.111952]\n",
      "epoch3 step25215 [D loss: -0.071746] [G loss: 0.956561]\n",
      "epoch3 step25220 [D loss: 0.427630] [G loss: 0.895520]\n",
      "epoch3 step25225 [D loss: -0.648661] [G loss: 0.679302]\n",
      "epoch3 step25230 [D loss: 0.305398] [G loss: 0.779995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step25235 [D loss: -0.307118] [G loss: 0.667108]\n",
      "epoch3 step25240 [D loss: -0.046147] [G loss: 1.062960]\n",
      "epoch3 step25245 [D loss: 0.103181] [G loss: 0.747271]\n",
      "epoch3 step25250 [D loss: -0.047102] [G loss: 0.718001]\n",
      "epoch3 step25255 [D loss: -0.604092] [G loss: 0.993542]\n",
      "epoch3 step25260 [D loss: -0.140339] [G loss: 0.886199]\n",
      "epoch3 step25265 [D loss: 0.132685] [G loss: 0.397830]\n",
      "epoch3 step25270 [D loss: 0.378038] [G loss: 0.745405]\n",
      "epoch3 step25275 [D loss: -0.373086] [G loss: 0.824370]\n",
      "epoch3 step25280 [D loss: 0.216608] [G loss: 1.153775]\n",
      "epoch3 step25285 [D loss: 0.371846] [G loss: 1.141555]\n",
      "epoch3 step25290 [D loss: 0.003632] [G loss: 1.185949]\n",
      "epoch3 step25295 [D loss: -0.522705] [G loss: 1.150368]\n",
      "epoch3 step25300 [D loss: -0.029587] [G loss: 1.105600]\n",
      "epoch3 step25305 [D loss: 0.102076] [G loss: 1.223387]\n",
      "epoch3 step25310 [D loss: -0.493846] [G loss: 1.376479]\n",
      "epoch3 step25315 [D loss: 0.002150] [G loss: 1.029757]\n",
      "epoch3 step25320 [D loss: -0.430816] [G loss: 1.299896]\n",
      "epoch3 step25325 [D loss: -0.000693] [G loss: 1.116852]\n",
      "epoch3 step25330 [D loss: 0.220035] [G loss: 0.813908]\n",
      "epoch3 step25335 [D loss: 0.277327] [G loss: 0.712850]\n",
      "epoch3 step25340 [D loss: 0.163968] [G loss: 1.132323]\n",
      "epoch3 step25345 [D loss: -0.105521] [G loss: 1.346640]\n",
      "epoch3 step25350 [D loss: -0.166985] [G loss: 1.221413]\n",
      "epoch3 step25355 [D loss: 0.219791] [G loss: 1.279699]\n",
      "epoch3 step25360 [D loss: -0.626161] [G loss: 1.187966]\n",
      "epoch3 step25365 [D loss: -0.078805] [G loss: 1.533096]\n",
      "epoch3 step25370 [D loss: 0.155299] [G loss: 1.161804]\n",
      "epoch3 step25375 [D loss: -0.277915] [G loss: 1.162341]\n",
      "epoch3 step25380 [D loss: -0.051002] [G loss: 1.597220]\n",
      "epoch3 step25385 [D loss: -0.545513] [G loss: 1.332550]\n",
      "epoch3 step25390 [D loss: -0.361035] [G loss: 1.336781]\n",
      "epoch3 step25395 [D loss: -0.114352] [G loss: 1.370205]\n",
      "epoch3 step25400 [D loss: -0.052341] [G loss: 1.448825]\n",
      "epoch3 step25405 [D loss: -0.283723] [G loss: 1.561946]\n",
      "epoch3 step25410 [D loss: -0.525753] [G loss: 1.537590]\n",
      "epoch3 step25415 [D loss: -0.061096] [G loss: 1.952373]\n",
      "epoch3 step25420 [D loss: -0.573469] [G loss: 1.550492]\n",
      "epoch3 step25425 [D loss: -0.149063] [G loss: 1.649386]\n",
      "epoch3 step25430 [D loss: -0.436786] [G loss: 1.618199]\n",
      "epoch3 step25435 [D loss: -0.315867] [G loss: 1.609887]\n",
      "epoch3 step25440 [D loss: 0.016174] [G loss: 1.604763]\n",
      "epoch3 step25445 [D loss: -0.670269] [G loss: 1.825999]\n",
      "epoch3 step25450 [D loss: -0.258484] [G loss: 1.208397]\n",
      "epoch3 step25455 [D loss: -0.354617] [G loss: 1.576063]\n",
      "epoch3 step25460 [D loss: -0.557026] [G loss: 1.293805]\n",
      "epoch3 step25465 [D loss: -0.405796] [G loss: 1.570805]\n",
      "epoch3 step25470 [D loss: -0.342588] [G loss: 1.621507]\n",
      "epoch3 step25475 [D loss: 0.299985] [G loss: 1.299543]\n",
      "epoch3 step25480 [D loss: -0.464767] [G loss: 1.602072]\n",
      "epoch3 step25485 [D loss: -0.303516] [G loss: 1.401366]\n",
      "epoch3 step25490 [D loss: 0.184986] [G loss: 1.512349]\n",
      "epoch3 step25495 [D loss: -0.050745] [G loss: 1.143270]\n",
      "epoch3 step25500 [D loss: -0.021667] [G loss: 1.212270]\n",
      "epoch3 step25505 [D loss: 0.395835] [G loss: 1.417887]\n",
      "epoch3 step25510 [D loss: 0.203079] [G loss: 1.280596]\n",
      "epoch3 step25515 [D loss: -0.115959] [G loss: 1.173105]\n",
      "epoch3 step25520 [D loss: -0.294709] [G loss: 1.455054]\n",
      "epoch3 step25525 [D loss: -0.341462] [G loss: 1.356269]\n",
      "epoch3 step25530 [D loss: -0.248765] [G loss: 1.602268]\n",
      "epoch3 step25535 [D loss: -0.289168] [G loss: 1.776910]\n",
      "epoch3 step25540 [D loss: 0.217007] [G loss: 1.503954]\n",
      "epoch3 step25545 [D loss: -0.188897] [G loss: 1.576768]\n",
      "epoch3 step25550 [D loss: 0.010212] [G loss: 1.605381]\n",
      "epoch3 step25555 [D loss: -0.019657] [G loss: 1.362443]\n",
      "epoch3 step25560 [D loss: 0.240187] [G loss: 1.545555]\n",
      "epoch3 step25565 [D loss: 0.380501] [G loss: 1.316301]\n",
      "epoch3 step25570 [D loss: -0.027260] [G loss: 1.714271]\n",
      "epoch3 step25575 [D loss: 0.097784] [G loss: 1.697391]\n",
      "epoch3 step25580 [D loss: 0.114653] [G loss: 1.790067]\n",
      "epoch3 step25585 [D loss: -0.104320] [G loss: 1.934819]\n",
      "epoch3 step25590 [D loss: -0.218771] [G loss: 1.695666]\n",
      "epoch3 step25595 [D loss: -0.208418] [G loss: 1.743683]\n",
      "epoch3 step25600 [D loss: -0.173934] [G loss: 2.199612]\n",
      "epoch3 step25605 [D loss: -0.188271] [G loss: 2.189080]\n",
      "epoch3 step25610 [D loss: -0.218423] [G loss: 1.843368]\n",
      "epoch3 step25615 [D loss: -0.019951] [G loss: 1.646740]\n",
      "epoch3 step25620 [D loss: 0.116669] [G loss: 1.664225]\n",
      "epoch3 step25625 [D loss: -0.164425] [G loss: 1.847046]\n",
      "epoch3 step25630 [D loss: -0.178876] [G loss: 2.119435]\n",
      "epoch3 step25635 [D loss: 0.159225] [G loss: 1.470682]\n",
      "epoch3 step25640 [D loss: -0.425552] [G loss: 1.707439]\n",
      "epoch3 step25645 [D loss: 0.359726] [G loss: 1.625838]\n",
      "epoch3 step25650 [D loss: -0.173982] [G loss: 1.207897]\n",
      "epoch3 step25655 [D loss: -0.112562] [G loss: 1.397254]\n",
      "epoch3 step25660 [D loss: 0.417485] [G loss: 1.321539]\n",
      "epoch3 step25665 [D loss: 0.014819] [G loss: 1.413062]\n",
      "epoch3 step25670 [D loss: 0.704627] [G loss: 1.040327]\n",
      "epoch3 step25675 [D loss: 0.012553] [G loss: 1.278525]\n",
      "epoch3 step25680 [D loss: -0.291237] [G loss: 1.182496]\n",
      "epoch3 step25685 [D loss: -0.438694] [G loss: 0.980734]\n",
      "epoch3 step25690 [D loss: -0.425376] [G loss: 1.132720]\n",
      "epoch3 step25695 [D loss: 0.022228] [G loss: 0.732157]\n",
      "epoch3 step25700 [D loss: -0.248753] [G loss: 0.818406]\n",
      "epoch3 step25705 [D loss: 0.220721] [G loss: 1.029053]\n",
      "epoch3 step25710 [D loss: -0.241746] [G loss: 0.935810]\n",
      "epoch3 step25715 [D loss: -0.171849] [G loss: 0.866343]\n",
      "epoch3 step25720 [D loss: 0.175798] [G loss: 0.970139]\n",
      "epoch3 step25725 [D loss: -0.028152] [G loss: 0.999453]\n",
      "epoch3 step25730 [D loss: -0.165612] [G loss: 0.925777]\n",
      "epoch3 step25735 [D loss: -0.466903] [G loss: 0.924499]\n",
      "epoch3 step25740 [D loss: -0.173011] [G loss: 0.691457]\n",
      "epoch3 step25745 [D loss: -0.519964] [G loss: 0.612170]\n",
      "epoch3 step25750 [D loss: -0.683036] [G loss: 0.573576]\n",
      "epoch3 step25755 [D loss: -0.358786] [G loss: 0.668910]\n",
      "epoch3 step25760 [D loss: -0.550758] [G loss: 1.065509]\n",
      "epoch3 step25765 [D loss: 0.067537] [G loss: 0.382269]\n",
      "epoch3 step25770 [D loss: -0.193454] [G loss: 0.863113]\n",
      "epoch3 step25775 [D loss: 0.522823] [G loss: 0.665258]\n",
      "epoch3 step25780 [D loss: 0.158366] [G loss: 0.947358]\n",
      "epoch3 step25785 [D loss: 0.090197] [G loss: 0.517899]\n",
      "epoch3 step25790 [D loss: -0.117048] [G loss: 0.800717]\n",
      "epoch3 step25795 [D loss: 0.450452] [G loss: 0.452202]\n",
      "epoch3 step25800 [D loss: -0.642007] [G loss: 0.783158]\n",
      "epoch3 step25805 [D loss: -0.182987] [G loss: 0.661678]\n",
      "epoch3 step25810 [D loss: -0.139757] [G loss: 0.791965]\n",
      "epoch3 step25815 [D loss: -0.505387] [G loss: 1.026484]\n",
      "epoch3 step25820 [D loss: -0.208137] [G loss: 1.049079]\n",
      "epoch3 step25825 [D loss: 0.095060] [G loss: 0.912680]\n",
      "epoch3 step25830 [D loss: 0.062085] [G loss: 0.516668]\n",
      "epoch3 step25835 [D loss: 0.295276] [G loss: 0.929442]\n",
      "epoch3 step25840 [D loss: -0.054888] [G loss: 0.868526]\n",
      "epoch3 step25845 [D loss: -0.267533] [G loss: 0.419398]\n",
      "epoch3 step25850 [D loss: -0.203760] [G loss: 0.909092]\n",
      "epoch3 step25855 [D loss: -0.046975] [G loss: 1.014289]\n",
      "epoch3 step25860 [D loss: -0.121935] [G loss: 0.877851]\n",
      "epoch3 step25865 [D loss: -0.094289] [G loss: 1.259954]\n",
      "epoch3 step25870 [D loss: 0.206096] [G loss: 1.266219]\n",
      "epoch3 step25875 [D loss: 0.109635] [G loss: 0.928780]\n",
      "epoch3 step25880 [D loss: -0.064293] [G loss: 1.211306]\n",
      "epoch3 step25885 [D loss: -0.256842] [G loss: 1.964818]\n",
      "epoch3 step25890 [D loss: -0.268357] [G loss: 1.214528]\n",
      "epoch3 step25895 [D loss: -0.309880] [G loss: 1.552666]\n",
      "epoch3 step25900 [D loss: -0.107704] [G loss: 1.916881]\n",
      "epoch3 step25905 [D loss: 0.143278] [G loss: 1.668965]\n",
      "epoch3 step25910 [D loss: 0.178233] [G loss: 1.630117]\n",
      "epoch3 step25915 [D loss: -0.067036] [G loss: 1.738853]\n",
      "epoch3 step25920 [D loss: -0.187877] [G loss: 1.836914]\n",
      "epoch3 step25925 [D loss: -0.271831] [G loss: 1.803923]\n",
      "epoch3 step25930 [D loss: -0.543984] [G loss: 1.840563]\n",
      "epoch3 step25935 [D loss: -0.167134] [G loss: 2.010159]\n",
      "epoch3 step25940 [D loss: 0.118803] [G loss: 1.985939]\n",
      "epoch3 step25945 [D loss: -0.733350] [G loss: 1.631536]\n",
      "epoch3 step25950 [D loss: -0.047255] [G loss: 1.721462]\n",
      "epoch3 step25955 [D loss: -0.334589] [G loss: 1.927417]\n",
      "epoch3 step25960 [D loss: -0.533877] [G loss: 1.959919]\n",
      "epoch3 step25965 [D loss: -0.169936] [G loss: 1.705866]\n",
      "epoch3 step25970 [D loss: -0.028273] [G loss: 2.035230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step25975 [D loss: -0.103300] [G loss: 1.540978]\n",
      "epoch3 step25980 [D loss: 0.405800] [G loss: 1.924025]\n",
      "epoch3 step25985 [D loss: 0.202770] [G loss: 1.910116]\n",
      "epoch3 step25990 [D loss: 0.281148] [G loss: 1.996360]\n",
      "epoch3 step25995 [D loss: 0.490629] [G loss: 1.676645]\n",
      "epoch3 step26000 [D loss: 0.360325] [G loss: 2.034712]\n",
      "epoch3 step26005 [D loss: -0.220118] [G loss: 2.268011]\n",
      "epoch3 step26010 [D loss: -0.237414] [G loss: 2.219559]\n",
      "epoch3 step26015 [D loss: 0.135453] [G loss: 1.990074]\n",
      "epoch3 step26020 [D loss: 0.022851] [G loss: 2.138317]\n",
      "epoch3 step26025 [D loss: -0.333962] [G loss: 1.823399]\n",
      "epoch3 step26030 [D loss: 0.453699] [G loss: 1.936519]\n",
      "epoch3 step26035 [D loss: 0.002238] [G loss: 1.933251]\n",
      "epoch3 step26040 [D loss: -0.591151] [G loss: 2.395193]\n",
      "epoch3 step26045 [D loss: 0.296119] [G loss: 2.047916]\n",
      "epoch3 step26050 [D loss: -0.033387] [G loss: 1.955620]\n",
      "epoch3 step26055 [D loss: -0.062222] [G loss: 1.986399]\n",
      "epoch3 step26060 [D loss: -0.002729] [G loss: 1.921084]\n",
      "epoch3 step26065 [D loss: -0.065969] [G loss: 2.207464]\n",
      "epoch3 step26070 [D loss: 0.179415] [G loss: 2.030407]\n",
      "epoch3 step26075 [D loss: 0.130847] [G loss: 1.885331]\n",
      "epoch3 step26080 [D loss: -0.096709] [G loss: 2.110135]\n",
      "epoch3 step26085 [D loss: -0.251730] [G loss: 2.184233]\n",
      "epoch3 step26090 [D loss: -0.977258] [G loss: 1.761991]\n",
      "epoch3 step26095 [D loss: 0.334398] [G loss: 1.659956]\n",
      "epoch3 step26100 [D loss: -0.447259] [G loss: 1.658067]\n",
      "epoch3 step26105 [D loss: -0.138955] [G loss: 1.600427]\n",
      "epoch3 step26110 [D loss: -0.080503] [G loss: 1.778751]\n",
      "epoch3 step26115 [D loss: -0.157875] [G loss: 1.539878]\n",
      "epoch3 step26120 [D loss: -0.182563] [G loss: 1.487578]\n",
      "epoch3 step26125 [D loss: -0.353845] [G loss: 1.449364]\n",
      "epoch3 step26130 [D loss: -0.317346] [G loss: 1.634356]\n",
      "epoch3 step26135 [D loss: 0.162998] [G loss: 1.443679]\n",
      "epoch3 step26140 [D loss: -0.297222] [G loss: 1.107378]\n",
      "epoch3 step26145 [D loss: -0.701816] [G loss: 1.146832]\n",
      "epoch3 step26150 [D loss: 0.452007] [G loss: 0.749044]\n",
      "epoch3 step26155 [D loss: -0.037890] [G loss: 0.765977]\n",
      "epoch3 step26160 [D loss: -0.510674] [G loss: 1.290866]\n",
      "epoch3 step26165 [D loss: -0.374629] [G loss: 1.642827]\n",
      "epoch3 step26170 [D loss: -0.070331] [G loss: 1.205244]\n",
      "epoch3 step26175 [D loss: -0.409799] [G loss: 0.903419]\n",
      "epoch3 step26180 [D loss: 0.076824] [G loss: 1.477926]\n",
      "epoch3 step26185 [D loss: 0.026044] [G loss: 1.018268]\n",
      "epoch3 step26190 [D loss: -0.030407] [G loss: 0.690146]\n",
      "epoch3 step26195 [D loss: 0.020817] [G loss: 1.205714]\n",
      "epoch3 step26200 [D loss: -0.028094] [G loss: 0.830616]\n",
      "epoch3 step26205 [D loss: -0.245604] [G loss: 0.872549]\n",
      "epoch3 step26210 [D loss: -0.035588] [G loss: 0.877809]\n",
      "epoch3 step26215 [D loss: 0.048611] [G loss: 0.967664]\n",
      "epoch3 step26220 [D loss: -0.314053] [G loss: 0.922095]\n",
      "epoch3 step26225 [D loss: 0.262320] [G loss: 0.704923]\n",
      "epoch3 step26230 [D loss: 0.078573] [G loss: 1.084641]\n",
      "epoch3 step26235 [D loss: -0.377271] [G loss: 1.088724]\n",
      "epoch3 step26240 [D loss: 0.192321] [G loss: 1.103586]\n",
      "epoch3 step26245 [D loss: 0.102557] [G loss: 1.185678]\n",
      "epoch3 step26250 [D loss: 0.533848] [G loss: 0.930378]\n",
      "epoch3 step26255 [D loss: -0.336171] [G loss: 1.167946]\n",
      "epoch3 step26260 [D loss: -0.058106] [G loss: 0.946071]\n",
      "epoch3 step26265 [D loss: 0.046263] [G loss: 1.500566]\n",
      "epoch3 step26270 [D loss: 0.054749] [G loss: 1.057746]\n",
      "epoch3 step26275 [D loss: -0.259188] [G loss: 1.413290]\n",
      "epoch3 step26280 [D loss: 0.083940] [G loss: 1.395712]\n",
      "epoch3 step26285 [D loss: -0.028475] [G loss: 1.431876]\n",
      "epoch3 step26290 [D loss: 0.388391] [G loss: 0.886057]\n",
      "epoch3 step26295 [D loss: -0.071210] [G loss: 1.315443]\n",
      "epoch3 step26300 [D loss: 0.317723] [G loss: 1.487265]\n",
      "epoch3 step26305 [D loss: 0.137202] [G loss: 1.423869]\n",
      "epoch3 step26310 [D loss: -0.401097] [G loss: 1.635310]\n",
      "epoch3 step26315 [D loss: -0.418197] [G loss: 1.438936]\n",
      "epoch3 step26320 [D loss: 0.140525] [G loss: 1.580219]\n",
      "epoch3 step26325 [D loss: -0.258421] [G loss: 1.447186]\n",
      "epoch3 step26330 [D loss: 0.406548] [G loss: 1.420536]\n",
      "epoch3 step26335 [D loss: -0.029243] [G loss: 1.190037]\n",
      "epoch3 step26340 [D loss: -0.255240] [G loss: 1.573711]\n",
      "epoch3 step26345 [D loss: -0.167170] [G loss: 1.337528]\n",
      "epoch3 step26350 [D loss: -0.894603] [G loss: 1.447312]\n",
      "epoch3 step26355 [D loss: -0.802474] [G loss: 1.667111]\n",
      "epoch3 step26360 [D loss: -0.354134] [G loss: 1.193448]\n",
      "epoch3 step26365 [D loss: -0.132726] [G loss: 1.256968]\n",
      "epoch3 step26370 [D loss: 0.074027] [G loss: 0.955532]\n",
      "epoch3 step26375 [D loss: -0.509359] [G loss: 1.025895]\n",
      "epoch3 step26380 [D loss: -0.783477] [G loss: 0.905012]\n",
      "epoch3 step26385 [D loss: -0.226762] [G loss: 1.317268]\n",
      "epoch3 step26390 [D loss: -0.089808] [G loss: 0.899781]\n",
      "epoch3 step26395 [D loss: 0.213483] [G loss: 0.836538]\n",
      "epoch3 step26400 [D loss: 0.041807] [G loss: 0.883726]\n",
      "epoch3 step26405 [D loss: -0.123645] [G loss: 1.022147]\n",
      "epoch3 step26410 [D loss: 0.076092] [G loss: 0.847422]\n",
      "epoch3 step26415 [D loss: -0.265723] [G loss: 0.538513]\n",
      "epoch3 step26420 [D loss: 0.214767] [G loss: 0.599569]\n",
      "epoch3 step26425 [D loss: 0.055232] [G loss: 0.165369]\n",
      "epoch3 step26430 [D loss: -0.282204] [G loss: 0.852397]\n",
      "epoch3 step26435 [D loss: -0.168536] [G loss: 0.386645]\n",
      "epoch3 step26440 [D loss: -0.342837] [G loss: 0.475177]\n",
      "epoch3 step26445 [D loss: -0.177573] [G loss: 0.458894]\n",
      "epoch3 step26450 [D loss: -0.022387] [G loss: 0.343295]\n",
      "epoch3 step26455 [D loss: -0.125486] [G loss: 0.396957]\n",
      "epoch3 step26460 [D loss: -0.090512] [G loss: 0.495126]\n",
      "epoch3 step26465 [D loss: -0.020316] [G loss: 0.194855]\n",
      "epoch3 step26470 [D loss: -0.093753] [G loss: 0.327282]\n",
      "epoch3 step26475 [D loss: -0.159805] [G loss: 0.214192]\n",
      "epoch3 step26480 [D loss: 0.310247] [G loss: 0.382053]\n",
      "epoch3 step26485 [D loss: -0.520639] [G loss: 0.469634]\n",
      "epoch3 step26490 [D loss: 0.115401] [G loss: 0.191921]\n",
      "epoch3 step26495 [D loss: -0.141944] [G loss: 0.360358]\n",
      "epoch3 step26500 [D loss: -0.137873] [G loss: 0.430319]\n",
      "epoch3 step26505 [D loss: -0.555482] [G loss: 0.390655]\n",
      "epoch3 step26510 [D loss: 0.093010] [G loss: 0.262577]\n",
      "epoch3 step26515 [D loss: -0.066651] [G loss: 0.083978]\n",
      "epoch3 step26520 [D loss: -0.050864] [G loss: 0.279619]\n",
      "epoch3 step26525 [D loss: -0.503037] [G loss: 0.687018]\n",
      "epoch3 step26530 [D loss: 0.144931] [G loss: 0.047775]\n",
      "epoch3 step26535 [D loss: -0.012100] [G loss: 0.200173]\n",
      "epoch3 step26540 [D loss: 0.381120] [G loss: 0.276642]\n",
      "epoch3 step26545 [D loss: -0.424036] [G loss: 0.702486]\n",
      "epoch3 step26550 [D loss: 0.122956] [G loss: 0.591388]\n",
      "epoch3 step26555 [D loss: -0.334326] [G loss: 0.364590]\n",
      "epoch3 step26560 [D loss: 0.001966] [G loss: 0.435194]\n",
      "epoch3 step26565 [D loss: -0.035815] [G loss: 0.721763]\n",
      "epoch3 step26570 [D loss: 0.624265] [G loss: 0.588306]\n",
      "epoch3 step26575 [D loss: 0.232154] [G loss: 0.988039]\n",
      "epoch3 step26580 [D loss: 0.054100] [G loss: 0.946643]\n",
      "epoch3 step26585 [D loss: 0.130097] [G loss: 1.027548]\n",
      "epoch3 step26590 [D loss: 0.065415] [G loss: 1.023447]\n",
      "epoch3 step26595 [D loss: -0.746508] [G loss: 1.537009]\n",
      "epoch3 step26600 [D loss: -0.547167] [G loss: 1.252064]\n",
      "epoch3 step26605 [D loss: -0.373848] [G loss: 1.027760]\n",
      "epoch3 step26610 [D loss: 0.006864] [G loss: 1.656210]\n",
      "epoch3 step26615 [D loss: 0.280900] [G loss: 1.651121]\n",
      "epoch3 step26620 [D loss: 0.220737] [G loss: 1.462811]\n",
      "epoch3 step26625 [D loss: -0.324156] [G loss: 1.437121]\n",
      "epoch3 step26630 [D loss: 0.173035] [G loss: 1.230239]\n",
      "epoch3 step26635 [D loss: 0.304459] [G loss: 1.329389]\n",
      "epoch3 step26640 [D loss: -0.122249] [G loss: 1.512940]\n",
      "epoch3 step26645 [D loss: 0.372978] [G loss: 1.204258]\n",
      "epoch3 step26650 [D loss: 0.643396] [G loss: 1.075094]\n",
      "epoch3 step26655 [D loss: 0.099339] [G loss: 1.511174]\n",
      "epoch3 step26660 [D loss: 0.449016] [G loss: 1.279055]\n",
      "epoch3 step26665 [D loss: -0.242375] [G loss: 1.686284]\n",
      "epoch3 step26670 [D loss: 0.377565] [G loss: 1.779445]\n",
      "epoch3 step26675 [D loss: -0.282105] [G loss: 1.865367]\n",
      "epoch3 step26680 [D loss: -0.069148] [G loss: 1.770793]\n",
      "epoch3 step26685 [D loss: -0.223720] [G loss: 1.603503]\n",
      "epoch3 step26690 [D loss: -0.374893] [G loss: 1.822611]\n",
      "epoch3 step26695 [D loss: -0.058404] [G loss: 1.735112]\n",
      "epoch3 step26700 [D loss: -0.663021] [G loss: 1.821484]\n",
      "epoch3 step26705 [D loss: -0.065396] [G loss: 1.498951]\n",
      "epoch3 step26710 [D loss: -0.092603] [G loss: 1.802684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step26715 [D loss: -0.310151] [G loss: 1.806727]\n",
      "epoch3 step26720 [D loss: 0.271198] [G loss: 2.039255]\n",
      "epoch3 step26725 [D loss: -0.042670] [G loss: 1.677684]\n",
      "epoch3 step26730 [D loss: 0.260224] [G loss: 1.546078]\n",
      "epoch3 step26735 [D loss: -0.618062] [G loss: 1.656621]\n",
      "epoch3 step26740 [D loss: -0.397564] [G loss: 2.127865]\n",
      "epoch3 step26745 [D loss: -0.155320] [G loss: 1.832814]\n",
      "epoch3 step26750 [D loss: -0.022894] [G loss: 1.841394]\n",
      "epoch3 step26755 [D loss: -0.172085] [G loss: 1.686990]\n",
      "epoch3 step26760 [D loss: -0.479250] [G loss: 1.789860]\n",
      "epoch3 step26765 [D loss: -0.366596] [G loss: 1.624377]\n",
      "epoch3 step26770 [D loss: -0.457560] [G loss: 1.821275]\n",
      "epoch3 step26775 [D loss: -0.251488] [G loss: 1.725536]\n",
      "epoch3 step26780 [D loss: 0.167714] [G loss: 1.423964]\n",
      "epoch3 step26785 [D loss: -0.552916] [G loss: 1.915249]\n",
      "epoch3 step26790 [D loss: -0.800683] [G loss: 2.063350]\n",
      "epoch3 step26795 [D loss: -0.049900] [G loss: 1.574387]\n",
      "epoch3 step26800 [D loss: -0.196863] [G loss: 1.641600]\n",
      "epoch3 step26805 [D loss: -0.265757] [G loss: 1.749903]\n",
      "epoch3 step26810 [D loss: -0.187429] [G loss: 1.789540]\n",
      "epoch3 step26815 [D loss: -0.128755] [G loss: 1.887741]\n",
      "epoch3 step26820 [D loss: -0.682322] [G loss: 1.589927]\n",
      "epoch3 step26825 [D loss: -0.195053] [G loss: 1.637820]\n",
      "epoch3 step26830 [D loss: -0.037533] [G loss: 1.405778]\n",
      "epoch3 step26835 [D loss: -0.237008] [G loss: 1.458525]\n",
      "epoch3 step26840 [D loss: 0.528725] [G loss: 1.201796]\n",
      "epoch3 step26845 [D loss: 0.248213] [G loss: 1.526974]\n",
      "epoch3 step26850 [D loss: -0.454483] [G loss: 2.002939]\n",
      "epoch3 step26855 [D loss: -0.098690] [G loss: 1.959858]\n",
      "epoch3 step26860 [D loss: -0.350399] [G loss: 1.570315]\n",
      "epoch3 step26865 [D loss: 0.561718] [G loss: 1.276985]\n",
      "epoch3 step26870 [D loss: 0.015297] [G loss: 1.646380]\n",
      "epoch3 step26875 [D loss: 0.176100] [G loss: 1.865734]\n",
      "epoch3 step26880 [D loss: -0.348906] [G loss: 1.752684]\n",
      "epoch3 step26885 [D loss: -0.012267] [G loss: 1.712608]\n",
      "epoch3 step26890 [D loss: 0.049349] [G loss: 1.776862]\n",
      "epoch3 step26895 [D loss: 0.171549] [G loss: 1.491082]\n",
      "epoch3 step26900 [D loss: 0.094908] [G loss: 1.433926]\n",
      "epoch3 step26905 [D loss: 0.268615] [G loss: 1.339275]\n",
      "epoch3 step26910 [D loss: 0.088345] [G loss: 1.302712]\n",
      "epoch3 step26915 [D loss: -0.407964] [G loss: 1.836660]\n",
      "epoch3 step26920 [D loss: -0.275541] [G loss: 1.505142]\n",
      "epoch3 step26925 [D loss: 0.174690] [G loss: 1.657677]\n",
      "epoch3 step26930 [D loss: -0.130823] [G loss: 1.589610]\n",
      "epoch3 step26935 [D loss: -0.106656] [G loss: 1.438136]\n",
      "epoch3 step26940 [D loss: -0.039000] [G loss: 1.502442]\n",
      "epoch3 step26945 [D loss: -0.352208] [G loss: 1.482645]\n",
      "epoch3 step26950 [D loss: 0.111025] [G loss: 1.479351]\n",
      "epoch3 step26955 [D loss: -0.041427] [G loss: 1.421916]\n",
      "epoch3 step26960 [D loss: -0.472454] [G loss: 1.035535]\n",
      "epoch3 step26965 [D loss: -0.066418] [G loss: 1.429638]\n",
      "epoch3 step26970 [D loss: -0.116579] [G loss: 1.488401]\n",
      "epoch3 step26975 [D loss: -0.257780] [G loss: 1.006906]\n",
      "epoch3 step26980 [D loss: -0.166764] [G loss: 1.181902]\n",
      "epoch3 step26985 [D loss: -0.039850] [G loss: 1.167589]\n",
      "epoch3 step26990 [D loss: -0.047477] [G loss: 1.140694]\n",
      "epoch3 step26995 [D loss: -0.132715] [G loss: 1.211889]\n",
      "epoch3 step27000 [D loss: -0.025934] [G loss: 1.302085]\n",
      "epoch3 step27005 [D loss: 0.149360] [G loss: 0.787620]\n",
      "epoch3 step27010 [D loss: -0.097295] [G loss: 0.957482]\n",
      "epoch3 step27015 [D loss: -0.206302] [G loss: 1.128253]\n",
      "epoch3 step27020 [D loss: -0.175548] [G loss: 1.276471]\n",
      "epoch3 step27025 [D loss: -0.156617] [G loss: 1.224130]\n",
      "epoch3 step27030 [D loss: -0.172524] [G loss: 0.974468]\n",
      "epoch3 step27035 [D loss: -0.073457] [G loss: 0.865195]\n",
      "epoch3 step27040 [D loss: -0.281101] [G loss: 0.764889]\n",
      "epoch3 step27045 [D loss: 0.162779] [G loss: 1.155155]\n",
      "epoch3 step27050 [D loss: 0.060791] [G loss: 0.366052]\n",
      "epoch3 step27055 [D loss: -0.165522] [G loss: 1.011721]\n",
      "epoch3 step27060 [D loss: -0.186035] [G loss: 0.639025]\n",
      "epoch3 step27065 [D loss: -0.573378] [G loss: 0.508185]\n",
      "epoch3 step27070 [D loss: -0.367099] [G loss: 0.500363]\n",
      "epoch3 step27075 [D loss: -0.142872] [G loss: 0.535932]\n",
      "epoch3 step27080 [D loss: 0.060207] [G loss: 0.406913]\n",
      "epoch3 step27085 [D loss: 0.381481] [G loss: 0.581268]\n",
      "epoch3 step27090 [D loss: -0.058765] [G loss: 0.379736]\n",
      "epoch3 step27095 [D loss: -0.335343] [G loss: 0.216004]\n",
      "epoch3 step27100 [D loss: -0.426946] [G loss: 0.576347]\n",
      "epoch3 step27105 [D loss: -0.245549] [G loss: 0.583624]\n",
      "epoch3 step27110 [D loss: -0.159187] [G loss: 0.418950]\n",
      "epoch3 step27115 [D loss: -0.043148] [G loss: 0.401438]\n",
      "epoch3 step27120 [D loss: 0.394702] [G loss: 0.684163]\n",
      "epoch3 step27125 [D loss: -0.320559] [G loss: 0.364407]\n",
      "epoch3 step27130 [D loss: -0.215903] [G loss: 0.306113]\n",
      "epoch3 step27135 [D loss: -0.006220] [G loss: 0.201807]\n",
      "epoch3 step27140 [D loss: -0.247399] [G loss: 0.145657]\n",
      "epoch3 step27145 [D loss: -0.080817] [G loss: 0.576337]\n",
      "epoch3 step27150 [D loss: -0.151782] [G loss: 0.682671]\n",
      "epoch3 step27155 [D loss: -0.185097] [G loss: 0.242295]\n",
      "epoch3 step27160 [D loss: -0.446104] [G loss: 0.555185]\n",
      "epoch3 step27165 [D loss: -0.020426] [G loss: 0.542542]\n",
      "epoch3 step27170 [D loss: 0.023335] [G loss: 0.698372]\n",
      "epoch3 step27175 [D loss: 0.138566] [G loss: 0.486454]\n",
      "epoch3 step27180 [D loss: 0.210826] [G loss: 0.600468]\n",
      "epoch3 step27185 [D loss: -0.036031] [G loss: 0.611597]\n",
      "epoch3 step27190 [D loss: -0.188070] [G loss: 0.999635]\n",
      "epoch3 step27195 [D loss: 0.134400] [G loss: 0.517228]\n",
      "epoch3 step27200 [D loss: -0.058633] [G loss: 1.057319]\n",
      "epoch3 step27205 [D loss: -0.031856] [G loss: 0.721171]\n",
      "epoch3 step27210 [D loss: -0.116488] [G loss: 0.827591]\n",
      "epoch3 step27215 [D loss: 0.429251] [G loss: 0.977761]\n",
      "epoch3 step27220 [D loss: -0.374497] [G loss: 0.796440]\n",
      "epoch3 step27225 [D loss: -0.215360] [G loss: 1.066913]\n",
      "epoch3 step27230 [D loss: -0.335257] [G loss: 1.100169]\n",
      "epoch3 step27235 [D loss: -0.956279] [G loss: 1.398779]\n",
      "epoch3 step27240 [D loss: -0.583586] [G loss: 1.235479]\n",
      "epoch3 step27245 [D loss: -0.724391] [G loss: 1.536983]\n",
      "epoch3 step27250 [D loss: -0.423968] [G loss: 1.300121]\n",
      "epoch3 step27255 [D loss: -0.511320] [G loss: 1.090242]\n",
      "epoch3 step27260 [D loss: -0.551540] [G loss: 1.286997]\n",
      "epoch3 step27265 [D loss: 0.091940] [G loss: 1.471160]\n",
      "epoch3 step27270 [D loss: -0.144083] [G loss: 0.983586]\n",
      "epoch3 step27275 [D loss: 0.074753] [G loss: 1.693533]\n",
      "epoch3 step27280 [D loss: -0.612149] [G loss: 1.253659]\n",
      "epoch3 step27285 [D loss: 0.077137] [G loss: 1.552845]\n",
      "epoch3 step27290 [D loss: -0.439581] [G loss: 1.194080]\n",
      "epoch3 step27295 [D loss: 0.154517] [G loss: 1.801691]\n",
      "epoch3 step27300 [D loss: -0.352197] [G loss: 1.722304]\n",
      "epoch3 step27305 [D loss: -0.199148] [G loss: 1.061160]\n",
      "epoch3 step27310 [D loss: 0.512414] [G loss: 1.270601]\n",
      "epoch3 step27315 [D loss: 0.059743] [G loss: 1.266220]\n",
      "epoch3 step27320 [D loss: -0.013917] [G loss: 1.255157]\n",
      "epoch3 step27325 [D loss: -0.112188] [G loss: 1.413036]\n",
      "epoch3 step27330 [D loss: -0.138650] [G loss: 1.557056]\n",
      "epoch3 step27335 [D loss: 0.030858] [G loss: 1.488929]\n",
      "epoch3 step27340 [D loss: -0.191628] [G loss: 1.558814]\n",
      "epoch3 step27345 [D loss: 0.055848] [G loss: 1.184590]\n",
      "epoch3 step27350 [D loss: 0.225628] [G loss: 1.020049]\n",
      "epoch3 step27355 [D loss: 0.061829] [G loss: 0.876589]\n",
      "epoch3 step27360 [D loss: -0.095567] [G loss: 1.402454]\n",
      "epoch3 step27365 [D loss: -0.118015] [G loss: 1.445899]\n",
      "epoch3 step27370 [D loss: -0.239568] [G loss: 1.178947]\n",
      "epoch3 step27375 [D loss: -0.023220] [G loss: 1.090594]\n",
      "epoch3 step27380 [D loss: 0.507440] [G loss: 0.958512]\n",
      "epoch3 step27385 [D loss: -0.678011] [G loss: 1.025770]\n",
      "epoch3 step27390 [D loss: 0.287234] [G loss: 0.770036]\n",
      "epoch3 step27395 [D loss: 0.324623] [G loss: 0.643400]\n",
      "epoch3 step27400 [D loss: -0.281264] [G loss: 1.133390]\n",
      "epoch3 step27405 [D loss: 0.175888] [G loss: 0.674437]\n",
      "epoch3 step27410 [D loss: 0.410959] [G loss: 1.251632]\n",
      "epoch3 step27415 [D loss: -0.057564] [G loss: 1.005940]\n",
      "epoch3 step27420 [D loss: 0.214738] [G loss: 0.946874]\n",
      "epoch3 step27425 [D loss: -0.112135] [G loss: 0.975696]\n",
      "epoch3 step27430 [D loss: -0.085577] [G loss: 0.836808]\n",
      "epoch3 step27435 [D loss: -0.293238] [G loss: 0.876524]\n",
      "epoch3 step27440 [D loss: -0.041239] [G loss: 0.796991]\n",
      "epoch3 step27445 [D loss: -0.460978] [G loss: 1.095879]\n",
      "epoch3 step27450 [D loss: -0.112533] [G loss: 0.799778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step27455 [D loss: -0.134565] [G loss: 0.949981]\n",
      "epoch3 step27460 [D loss: -0.003261] [G loss: 0.768677]\n",
      "epoch3 step27465 [D loss: 0.022833] [G loss: 0.742897]\n",
      "epoch3 step27470 [D loss: -0.276212] [G loss: 0.868855]\n",
      "epoch3 step27475 [D loss: 0.017972] [G loss: 0.664955]\n",
      "epoch3 step27480 [D loss: 0.041610] [G loss: 0.494756]\n",
      "epoch3 step27485 [D loss: 0.030982] [G loss: 0.665542]\n",
      "epoch3 step27490 [D loss: -0.564464] [G loss: 0.664735]\n",
      "epoch3 step27495 [D loss: 0.025845] [G loss: 0.884526]\n",
      "epoch3 step27500 [D loss: 0.105089] [G loss: 0.790646]\n",
      "epoch3 step27505 [D loss: 0.108761] [G loss: 0.558402]\n",
      "epoch3 step27510 [D loss: 0.008619] [G loss: 0.901411]\n",
      "epoch3 step27515 [D loss: -0.115143] [G loss: 0.714192]\n",
      "epoch3 step27520 [D loss: -0.032719] [G loss: 0.579636]\n",
      "epoch3 step27525 [D loss: 0.190628] [G loss: 0.712208]\n",
      "epoch3 step27530 [D loss: -0.041597] [G loss: 0.829953]\n",
      "epoch3 step27535 [D loss: 0.177275] [G loss: 0.798221]\n",
      "epoch3 step27540 [D loss: 0.056591] [G loss: 0.766665]\n",
      "epoch3 step27545 [D loss: 0.024006] [G loss: 0.909981]\n",
      "epoch3 step27550 [D loss: 0.271826] [G loss: 0.959086]\n",
      "epoch3 step27555 [D loss: 0.157890] [G loss: 0.711501]\n",
      "epoch3 step27560 [D loss: -0.171157] [G loss: 1.021276]\n",
      "epoch3 step27565 [D loss: -0.271674] [G loss: 0.897830]\n",
      "epoch3 step27570 [D loss: 0.476393] [G loss: 0.656455]\n",
      "epoch3 step27575 [D loss: -0.185992] [G loss: 0.842878]\n",
      "epoch3 step27580 [D loss: -0.059354] [G loss: 0.798953]\n",
      "epoch3 step27585 [D loss: -0.214510] [G loss: 0.834971]\n",
      "epoch3 step27590 [D loss: -0.094163] [G loss: 0.946874]\n",
      "epoch3 step27595 [D loss: -0.256000] [G loss: 0.747724]\n",
      "epoch3 step27600 [D loss: -0.231071] [G loss: 0.845681]\n",
      "epoch3 step27605 [D loss: -0.036443] [G loss: 0.858861]\n",
      "epoch3 step27610 [D loss: -0.072082] [G loss: 0.835826]\n",
      "epoch3 step27615 [D loss: -0.133342] [G loss: 0.874657]\n",
      "epoch3 step27620 [D loss: 0.356535] [G loss: 0.927586]\n",
      "epoch3 step27625 [D loss: 0.160739] [G loss: 0.656834]\n",
      "epoch3 step27630 [D loss: 0.089076] [G loss: 0.661802]\n",
      "epoch3 step27635 [D loss: -0.234211] [G loss: 0.589880]\n",
      "epoch3 step27640 [D loss: -0.455226] [G loss: 0.934803]\n",
      "epoch3 step27645 [D loss: -0.107575] [G loss: 0.881000]\n",
      "epoch3 step27650 [D loss: -0.269917] [G loss: 0.934182]\n",
      "epoch3 step27655 [D loss: -0.188382] [G loss: 1.226486]\n",
      "epoch3 step27660 [D loss: -0.427706] [G loss: 1.033814]\n",
      "epoch3 step27665 [D loss: -0.428854] [G loss: 1.181657]\n",
      "epoch3 step27670 [D loss: -0.183814] [G loss: 1.381466]\n",
      "epoch3 step27675 [D loss: -0.168254] [G loss: 1.318531]\n",
      "epoch3 step27680 [D loss: 0.238395] [G loss: 1.123498]\n",
      "epoch3 step27685 [D loss: -0.187111] [G loss: 1.295850]\n",
      "epoch3 step27690 [D loss: -0.134942] [G loss: 1.092801]\n",
      "epoch3 step27695 [D loss: -0.422282] [G loss: 1.306540]\n",
      "epoch3 step27700 [D loss: -0.165361] [G loss: 1.195693]\n",
      "epoch3 step27705 [D loss: 0.200120] [G loss: 1.353326]\n",
      "epoch3 step27710 [D loss: -0.199465] [G loss: 1.231364]\n",
      "epoch3 step27715 [D loss: 0.074869] [G loss: 1.440353]\n",
      "epoch3 step27720 [D loss: 0.109268] [G loss: 1.175209]\n",
      "epoch3 step27725 [D loss: 0.129963] [G loss: 1.354704]\n",
      "epoch3 step27730 [D loss: -0.178417] [G loss: 1.111339]\n",
      "epoch3 step27735 [D loss: -0.056783] [G loss: 1.170007]\n",
      "epoch3 step27740 [D loss: -0.290958] [G loss: 1.324417]\n",
      "epoch3 step27745 [D loss: -0.061078] [G loss: 1.105637]\n",
      "epoch3 step27750 [D loss: -0.498405] [G loss: 1.152117]\n",
      "epoch3 step27755 [D loss: 0.309717] [G loss: 1.017210]\n",
      "epoch3 step27760 [D loss: 0.248969] [G loss: 1.296856]\n",
      "epoch3 step27765 [D loss: 0.148804] [G loss: 1.271324]\n",
      "epoch3 step27770 [D loss: 0.019158] [G loss: 1.380330]\n",
      "epoch3 step27775 [D loss: -0.224384] [G loss: 1.282321]\n",
      "epoch3 step27780 [D loss: -0.218853] [G loss: 1.683737]\n",
      "epoch3 step27785 [D loss: 0.005580] [G loss: 1.280388]\n",
      "epoch3 step27790 [D loss: -0.151285] [G loss: 1.538340]\n",
      "epoch3 step27795 [D loss: 0.093758] [G loss: 1.354107]\n",
      "epoch3 step27800 [D loss: -0.184310] [G loss: 1.324968]\n",
      "epoch3 step27805 [D loss: -0.178271] [G loss: 1.420099]\n",
      "epoch3 step27810 [D loss: -0.354543] [G loss: 1.173046]\n",
      "epoch3 step27815 [D loss: -0.267561] [G loss: 1.376865]\n",
      "epoch3 step27820 [D loss: -0.433554] [G loss: 1.647028]\n",
      "epoch3 step27825 [D loss: 0.189034] [G loss: 1.520958]\n",
      "epoch3 step27830 [D loss: -0.011572] [G loss: 1.383479]\n",
      "epoch3 step27835 [D loss: -0.403495] [G loss: 1.481347]\n",
      "epoch3 step27840 [D loss: -0.078330] [G loss: 1.342146]\n",
      "epoch3 step27845 [D loss: -0.409021] [G loss: 1.393116]\n",
      "epoch3 step27850 [D loss: 0.029949] [G loss: 1.160060]\n",
      "epoch3 step27855 [D loss: 0.000754] [G loss: 1.691668]\n",
      "epoch3 step27860 [D loss: 0.280517] [G loss: 1.383322]\n",
      "epoch3 step27865 [D loss: -0.073416] [G loss: 1.087529]\n",
      "epoch3 step27870 [D loss: 0.107639] [G loss: 1.073287]\n",
      "epoch3 step27875 [D loss: 0.011393] [G loss: 1.334011]\n",
      "epoch3 step27880 [D loss: -0.121062] [G loss: 1.025648]\n",
      "epoch3 step27885 [D loss: -0.010636] [G loss: 1.388238]\n",
      "epoch3 step27890 [D loss: 0.045881] [G loss: 1.217060]\n",
      "epoch3 step27895 [D loss: 0.005250] [G loss: 0.977966]\n",
      "epoch3 step27900 [D loss: -0.055369] [G loss: 1.120985]\n",
      "epoch3 step27905 [D loss: -0.475091] [G loss: 1.301944]\n",
      "epoch3 step27910 [D loss: -0.162365] [G loss: 0.923638]\n",
      "epoch3 step27915 [D loss: -0.320358] [G loss: 1.188870]\n",
      "epoch3 step27920 [D loss: -0.408519] [G loss: 1.332206]\n",
      "epoch3 step27925 [D loss: -0.257238] [G loss: 1.242516]\n",
      "epoch3 step27930 [D loss: -0.008251] [G loss: 0.934804]\n",
      "epoch3 step27935 [D loss: -0.347591] [G loss: 1.087913]\n",
      "epoch3 step27940 [D loss: -0.465765] [G loss: 1.044316]\n",
      "epoch3 step27945 [D loss: -0.818808] [G loss: 1.079612]\n",
      "epoch3 step27950 [D loss: -0.179348] [G loss: 1.389008]\n",
      "epoch3 step27955 [D loss: -0.236214] [G loss: 0.837789]\n",
      "epoch3 step27960 [D loss: 0.018765] [G loss: 1.232719]\n",
      "epoch3 step27965 [D loss: 0.004746] [G loss: 1.208859]\n",
      "epoch3 step27970 [D loss: -0.009505] [G loss: 1.221399]\n",
      "epoch3 step27975 [D loss: 0.246857] [G loss: 1.269124]\n",
      "epoch3 step27980 [D loss: 0.146308] [G loss: 1.067704]\n",
      "epoch3 step27985 [D loss: -0.417706] [G loss: 0.882285]\n",
      "epoch3 step27990 [D loss: -0.221066] [G loss: 1.007318]\n",
      "epoch3 step27995 [D loss: -0.239967] [G loss: 1.328180]\n",
      "epoch3 step28000 [D loss: -0.048673] [G loss: 0.831659]\n",
      "epoch3 step28005 [D loss: -0.036183] [G loss: 0.881998]\n",
      "epoch3 step28010 [D loss: -0.341262] [G loss: 0.627718]\n",
      "epoch3 step28015 [D loss: -0.411541] [G loss: 0.914487]\n",
      "epoch3 step28020 [D loss: -0.296500] [G loss: 0.637732]\n",
      "epoch3 step28025 [D loss: -0.383906] [G loss: 0.681674]\n",
      "epoch3 step28030 [D loss: -0.347317] [G loss: 1.022129]\n",
      "epoch3 step28035 [D loss: -0.477176] [G loss: 1.198216]\n",
      "epoch3 step28040 [D loss: 0.111344] [G loss: 1.130347]\n",
      "epoch3 step28045 [D loss: -0.052628] [G loss: 1.013095]\n",
      "epoch3 step28050 [D loss: -0.289913] [G loss: 1.128297]\n",
      "epoch3 step28055 [D loss: 0.247307] [G loss: 0.848038]\n",
      "epoch3 step28060 [D loss: -0.101801] [G loss: 0.980803]\n",
      "epoch3 step28065 [D loss: -0.429486] [G loss: 0.851680]\n",
      "epoch3 step28070 [D loss: -0.108742] [G loss: 0.937164]\n",
      "epoch3 step28075 [D loss: 0.328688] [G loss: 0.885697]\n",
      "epoch3 step28080 [D loss: -0.300452] [G loss: 0.753694]\n",
      "epoch3 step28085 [D loss: -0.275335] [G loss: 1.273873]\n",
      "epoch3 step28090 [D loss: 0.416866] [G loss: 0.499143]\n",
      "epoch3 step28095 [D loss: -0.482417] [G loss: 0.947354]\n",
      "epoch3 step28100 [D loss: 0.575465] [G loss: 1.005436]\n",
      "epoch3 step28105 [D loss: -0.620483] [G loss: 1.017163]\n",
      "epoch3 step28110 [D loss: -0.312214] [G loss: 0.877986]\n",
      "epoch3 step28115 [D loss: -0.127065] [G loss: 0.566382]\n",
      "epoch3 step28120 [D loss: 0.314157] [G loss: 0.624857]\n",
      "epoch3 step28125 [D loss: -0.030418] [G loss: 0.694232]\n",
      "epoch3 step28130 [D loss: -0.169170] [G loss: 0.293070]\n",
      "epoch3 step28135 [D loss: -0.028933] [G loss: 0.591456]\n",
      "epoch3 step28140 [D loss: -0.195802] [G loss: 0.762749]\n",
      "epoch3 step28145 [D loss: -0.494022] [G loss: 0.619697]\n",
      "epoch3 step28150 [D loss: -0.065941] [G loss: 0.601105]\n",
      "epoch3 step28155 [D loss: 0.033264] [G loss: 0.177626]\n",
      "epoch3 step28160 [D loss: -0.364740] [G loss: 0.544338]\n",
      "epoch3 step28165 [D loss: -0.573532] [G loss: 0.804397]\n",
      "epoch3 step28170 [D loss: -0.070385] [G loss: 0.455311]\n",
      "epoch3 step28175 [D loss: 0.222919] [G loss: 0.698130]\n",
      "epoch3 step28180 [D loss: 0.106416] [G loss: 0.440629]\n",
      "epoch3 step28185 [D loss: 0.319707] [G loss: 0.180906]\n",
      "epoch3 step28190 [D loss: -0.394361] [G loss: 0.414109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step28195 [D loss: 0.245466] [G loss: 0.345601]\n",
      "epoch3 step28200 [D loss: -0.295279] [G loss: 0.547131]\n",
      "epoch3 step28205 [D loss: 0.434750] [G loss: 0.374294]\n",
      "epoch3 step28210 [D loss: -0.055064] [G loss: 0.564395]\n",
      "epoch3 step28215 [D loss: 0.215751] [G loss: 0.560119]\n",
      "epoch3 step28220 [D loss: -0.297598] [G loss: 1.012596]\n",
      "epoch3 step28225 [D loss: 0.199718] [G loss: 0.817675]\n",
      "epoch3 step28230 [D loss: -0.096189] [G loss: 0.471121]\n",
      "epoch3 step28235 [D loss: 0.567075] [G loss: 0.695677]\n",
      "epoch3 step28240 [D loss: 0.128245] [G loss: 0.803288]\n",
      "epoch3 step28245 [D loss: -0.257702] [G loss: 0.747558]\n",
      "epoch3 step28250 [D loss: -0.052146] [G loss: 1.041696]\n",
      "epoch3 step28255 [D loss: -0.284749] [G loss: 1.196612]\n",
      "epoch3 step28260 [D loss: 0.394284] [G loss: 0.968221]\n",
      "epoch3 step28265 [D loss: 0.124042] [G loss: 1.284804]\n",
      "epoch3 step28270 [D loss: 0.120432] [G loss: 0.776222]\n",
      "epoch3 step28275 [D loss: -0.209887] [G loss: 1.317731]\n",
      "epoch3 step28280 [D loss: -0.381854] [G loss: 1.215343]\n",
      "epoch3 step28285 [D loss: 0.137370] [G loss: 1.042511]\n",
      "epoch3 step28290 [D loss: -0.102738] [G loss: 1.480891]\n",
      "epoch3 step28295 [D loss: -0.263811] [G loss: 1.551850]\n",
      "epoch3 step28300 [D loss: -0.563428] [G loss: 1.451259]\n",
      "epoch3 step28305 [D loss: -0.517845] [G loss: 1.525848]\n",
      "epoch3 step28310 [D loss: -0.412494] [G loss: 1.523354]\n",
      "epoch3 step28315 [D loss: 0.474473] [G loss: 1.168107]\n",
      "epoch3 step28320 [D loss: 0.204127] [G loss: 1.536218]\n",
      "epoch3 step28325 [D loss: 0.194856] [G loss: 1.270537]\n",
      "epoch3 step28330 [D loss: 0.040171] [G loss: 1.478391]\n",
      "epoch3 step28335 [D loss: 0.262401] [G loss: 1.727184]\n",
      "epoch3 step28340 [D loss: 0.329501] [G loss: 1.284493]\n",
      "epoch3 step28345 [D loss: -0.248846] [G loss: 1.474885]\n",
      "epoch3 step28350 [D loss: -0.137419] [G loss: 1.426028]\n",
      "epoch3 step28355 [D loss: -0.278350] [G loss: 1.471517]\n",
      "epoch3 step28360 [D loss: -0.153702] [G loss: 1.624168]\n",
      "epoch3 step28365 [D loss: -0.009913] [G loss: 1.688539]\n",
      "epoch3 step28370 [D loss: 0.046167] [G loss: 1.573044]\n",
      "epoch3 step28375 [D loss: -0.310405] [G loss: 1.418642]\n",
      "epoch3 step28380 [D loss: -0.399376] [G loss: 1.544939]\n",
      "epoch3 step28385 [D loss: -0.150239] [G loss: 1.401117]\n",
      "epoch3 step28390 [D loss: -0.001485] [G loss: 1.474215]\n",
      "epoch3 step28395 [D loss: 0.153761] [G loss: 1.539876]\n",
      "epoch3 step28400 [D loss: 0.274855] [G loss: 1.356983]\n",
      "epoch3 step28405 [D loss: -0.392303] [G loss: 1.398270]\n",
      "epoch3 step28410 [D loss: -0.047473] [G loss: 1.248646]\n",
      "epoch3 step28415 [D loss: -0.157123] [G loss: 1.717751]\n",
      "epoch3 step28420 [D loss: -0.044304] [G loss: 1.444308]\n",
      "epoch3 step28425 [D loss: -0.238106] [G loss: 1.596662]\n",
      "epoch3 step28430 [D loss: -0.287650] [G loss: 1.233109]\n",
      "epoch3 step28435 [D loss: -0.355307] [G loss: 1.524798]\n",
      "epoch3 step28440 [D loss: -0.345994] [G loss: 1.328807]\n",
      "epoch3 step28445 [D loss: -0.255336] [G loss: 1.230787]\n",
      "epoch3 step28450 [D loss: 0.068357] [G loss: 1.280522]\n",
      "epoch3 step28455 [D loss: 0.328006] [G loss: 1.556031]\n",
      "epoch3 step28460 [D loss: 0.091994] [G loss: 1.224838]\n",
      "epoch3 step28465 [D loss: 0.197032] [G loss: 1.280784]\n",
      "epoch3 step28470 [D loss: -0.128738] [G loss: 1.020434]\n",
      "epoch3 step28475 [D loss: -0.080557] [G loss: 1.638833]\n",
      "epoch3 step28480 [D loss: -0.416296] [G loss: 1.531929]\n",
      "epoch3 step28485 [D loss: -0.433192] [G loss: 1.747963]\n",
      "epoch3 step28490 [D loss: -0.407008] [G loss: 1.387203]\n",
      "epoch3 step28495 [D loss: -0.354898] [G loss: 1.532582]\n",
      "epoch3 step28500 [D loss: 0.152364] [G loss: 1.592520]\n",
      "epoch3 step28505 [D loss: 0.004616] [G loss: 1.487547]\n",
      "epoch3 step28510 [D loss: -0.001479] [G loss: 1.169445]\n",
      "epoch3 step28515 [D loss: 0.183408] [G loss: 1.174146]\n",
      "epoch3 step28520 [D loss: -0.184798] [G loss: 1.359070]\n",
      "epoch3 step28525 [D loss: -0.328230] [G loss: 1.597371]\n",
      "epoch3 step28530 [D loss: -0.293666] [G loss: 1.371876]\n",
      "epoch3 step28535 [D loss: -0.387360] [G loss: 1.382845]\n",
      "epoch3 step28540 [D loss: -0.253769] [G loss: 1.241540]\n",
      "epoch3 step28545 [D loss: 0.250472] [G loss: 0.870292]\n",
      "epoch3 step28550 [D loss: -0.176468] [G loss: 1.518639]\n",
      "epoch3 step28555 [D loss: -0.293339] [G loss: 0.857355]\n",
      "epoch3 step28560 [D loss: 0.428319] [G loss: 0.917567]\n",
      "epoch3 step28565 [D loss: 0.070501] [G loss: 1.128999]\n",
      "epoch3 step28570 [D loss: 0.048983] [G loss: 0.919836]\n",
      "epoch3 step28575 [D loss: 0.107296] [G loss: 1.257290]\n",
      "epoch3 step28580 [D loss: 0.131731] [G loss: 1.145197]\n",
      "epoch3 step28585 [D loss: -0.145298] [G loss: 1.104234]\n",
      "epoch3 step28590 [D loss: 0.494897] [G loss: 1.098016]\n",
      "epoch3 step28595 [D loss: -0.230093] [G loss: 1.096330]\n",
      "epoch3 step28600 [D loss: 0.102014] [G loss: 1.312805]\n",
      "epoch3 step28605 [D loss: -0.007015] [G loss: 1.014298]\n",
      "epoch3 step28610 [D loss: -0.033894] [G loss: 1.166626]\n",
      "epoch3 step28615 [D loss: 0.171122] [G loss: 1.496963]\n",
      "epoch3 step28620 [D loss: -0.397576] [G loss: 1.510826]\n",
      "epoch3 step28625 [D loss: -0.388838] [G loss: 1.498114]\n",
      "epoch3 step28630 [D loss: -0.487160] [G loss: 1.523342]\n",
      "epoch3 step28635 [D loss: 0.100120] [G loss: 1.589551]\n",
      "epoch3 step28640 [D loss: -0.101275] [G loss: 1.173277]\n",
      "epoch3 step28645 [D loss: -0.090323] [G loss: 1.430779]\n",
      "epoch3 step28650 [D loss: -0.343122] [G loss: 1.395813]\n",
      "epoch3 step28655 [D loss: -0.112345] [G loss: 1.581322]\n",
      "epoch3 step28660 [D loss: -0.474598] [G loss: 1.577497]\n",
      "epoch3 step28665 [D loss: -0.215007] [G loss: 1.552548]\n",
      "epoch3 step28670 [D loss: -0.099379] [G loss: 1.583528]\n",
      "epoch3 step28675 [D loss: -0.035068] [G loss: 1.622872]\n",
      "epoch3 step28680 [D loss: -0.577496] [G loss: 1.326834]\n",
      "epoch3 step28685 [D loss: -0.032460] [G loss: 1.511083]\n",
      "epoch3 step28690 [D loss: -0.422337] [G loss: 1.250879]\n",
      "epoch3 step28695 [D loss: -0.313522] [G loss: 1.767767]\n",
      "epoch3 step28700 [D loss: -0.041359] [G loss: 1.573357]\n",
      "epoch3 step28705 [D loss: 0.348192] [G loss: 1.586468]\n",
      "epoch3 step28710 [D loss: 0.151336] [G loss: 1.264090]\n",
      "epoch3 step28715 [D loss: -0.068627] [G loss: 1.248422]\n",
      "epoch3 step28720 [D loss: 0.081374] [G loss: 1.307452]\n",
      "epoch3 step28725 [D loss: -0.263131] [G loss: 1.301348]\n",
      "epoch3 step28730 [D loss: -0.050024] [G loss: 0.713989]\n",
      "epoch3 step28735 [D loss: -0.153431] [G loss: 0.887527]\n",
      "epoch3 step28740 [D loss: 0.089158] [G loss: 1.270021]\n",
      "epoch3 step28745 [D loss: -0.747801] [G loss: 1.453923]\n",
      "epoch3 step28750 [D loss: -0.530077] [G loss: 1.105142]\n",
      "epoch3 step28755 [D loss: 0.260226] [G loss: 0.880399]\n",
      "epoch3 step28760 [D loss: -0.235920] [G loss: 0.586200]\n",
      "epoch3 step28765 [D loss: -0.571495] [G loss: 0.837447]\n",
      "epoch3 step28770 [D loss: -0.222002] [G loss: 0.755484]\n",
      "epoch3 step28775 [D loss: -0.048263] [G loss: 0.797053]\n",
      "epoch3 step28780 [D loss: 0.029948] [G loss: 0.790035]\n",
      "epoch3 step28785 [D loss: 0.003124] [G loss: 0.653030]\n",
      "epoch3 step28790 [D loss: 0.235340] [G loss: 0.609494]\n",
      "epoch3 step28795 [D loss: -0.331134] [G loss: 0.962997]\n",
      "epoch3 step28800 [D loss: 0.253508] [G loss: 0.864217]\n",
      "epoch3 step28805 [D loss: 0.040430] [G loss: 0.952918]\n",
      "epoch3 step28810 [D loss: -0.327951] [G loss: 0.774041]\n",
      "epoch3 step28815 [D loss: 0.167334] [G loss: 1.252488]\n",
      "epoch3 step28820 [D loss: -0.066252] [G loss: 1.155769]\n",
      "epoch3 step28825 [D loss: -0.257098] [G loss: 1.179183]\n",
      "epoch3 step28830 [D loss: 0.183936] [G loss: 0.890316]\n",
      "epoch3 step28835 [D loss: -0.120384] [G loss: 1.413518]\n",
      "epoch3 step28840 [D loss: -0.150601] [G loss: 1.251280]\n",
      "epoch3 step28845 [D loss: 0.007929] [G loss: 1.205035]\n",
      "epoch3 step28850 [D loss: -0.156687] [G loss: 1.528334]\n",
      "epoch3 step28855 [D loss: -0.506813] [G loss: 1.473228]\n",
      "epoch3 step28860 [D loss: 0.034681] [G loss: 1.493187]\n",
      "epoch3 step28865 [D loss: -0.602735] [G loss: 1.988117]\n",
      "epoch3 step28870 [D loss: -0.265423] [G loss: 1.584149]\n",
      "epoch3 step28875 [D loss: -0.381961] [G loss: 1.923976]\n",
      "epoch3 step28880 [D loss: -0.320064] [G loss: 1.916722]\n",
      "epoch3 step28885 [D loss: -0.166217] [G loss: 2.026266]\n",
      "epoch3 step28890 [D loss: -0.608982] [G loss: 1.849193]\n",
      "epoch3 step28895 [D loss: -0.201060] [G loss: 1.765851]\n",
      "epoch3 step28900 [D loss: -0.311788] [G loss: 1.825486]\n",
      "epoch3 step28905 [D loss: -0.126425] [G loss: 1.836652]\n",
      "epoch3 step28910 [D loss: -0.390299] [G loss: 1.828119]\n",
      "epoch3 step28915 [D loss: 0.058519] [G loss: 1.719939]\n",
      "epoch3 step28920 [D loss: 0.404335] [G loss: 1.581553]\n",
      "epoch3 step28925 [D loss: 0.004850] [G loss: 1.629525]\n",
      "epoch3 step28930 [D loss: 0.083009] [G loss: 2.042010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step28935 [D loss: -0.524680] [G loss: 1.579189]\n",
      "epoch3 step28940 [D loss: 0.149556] [G loss: 1.801645]\n",
      "epoch3 step28945 [D loss: -0.336146] [G loss: 1.724075]\n",
      "epoch3 step28950 [D loss: -0.177160] [G loss: 1.706712]\n",
      "epoch3 step28955 [D loss: 0.169182] [G loss: 1.454691]\n",
      "epoch3 step28960 [D loss: -0.023799] [G loss: 1.400007]\n",
      "epoch3 step28965 [D loss: 0.123373] [G loss: 1.358809]\n",
      "epoch3 step28970 [D loss: 0.084907] [G loss: 1.553014]\n",
      "epoch3 step28975 [D loss: -0.242592] [G loss: 1.373566]\n",
      "epoch3 step28980 [D loss: 0.275939] [G loss: 1.237156]\n",
      "epoch3 step28985 [D loss: -0.110078] [G loss: 1.329759]\n",
      "epoch3 step28990 [D loss: -0.110469] [G loss: 1.517898]\n",
      "epoch3 step28995 [D loss: 0.188905] [G loss: 1.659976]\n",
      "epoch3 step29000 [D loss: -0.099419] [G loss: 1.778439]\n",
      "epoch3 step29005 [D loss: 0.153046] [G loss: 1.660961]\n",
      "epoch3 step29010 [D loss: -0.083796] [G loss: 1.530182]\n",
      "epoch3 step29015 [D loss: -0.441077] [G loss: 1.704717]\n",
      "epoch3 step29020 [D loss: 0.327254] [G loss: 1.558552]\n",
      "epoch3 step29025 [D loss: -0.088576] [G loss: 1.811591]\n",
      "epoch3 step29030 [D loss: -0.014977] [G loss: 1.389164]\n",
      "epoch3 step29035 [D loss: 0.066008] [G loss: 1.658280]\n",
      "epoch3 step29040 [D loss: -0.116732] [G loss: 1.477180]\n",
      "epoch3 step29045 [D loss: -0.172934] [G loss: 1.595610]\n",
      "epoch3 step29050 [D loss: -0.333868] [G loss: 1.843279]\n",
      "epoch3 step29055 [D loss: -0.058807] [G loss: 1.301215]\n",
      "epoch3 step29060 [D loss: -0.299665] [G loss: 1.647363]\n",
      "epoch3 step29065 [D loss: -0.066387] [G loss: 1.417471]\n",
      "epoch3 step29070 [D loss: -0.009990] [G loss: 1.616721]\n",
      "epoch3 step29075 [D loss: -0.295847] [G loss: 1.539618]\n",
      "epoch3 step29080 [D loss: 0.493949] [G loss: 1.506219]\n",
      "epoch3 step29085 [D loss: 0.084504] [G loss: 1.437175]\n",
      "epoch3 step29090 [D loss: -0.110424] [G loss: 1.285337]\n",
      "epoch3 step29095 [D loss: 0.022819] [G loss: 1.378672]\n",
      "epoch3 step29100 [D loss: -0.237331] [G loss: 1.361932]\n",
      "epoch3 step29105 [D loss: 0.063840] [G loss: 1.534592]\n",
      "epoch3 step29110 [D loss: -0.326854] [G loss: 1.344616]\n",
      "epoch3 step29115 [D loss: -0.444062] [G loss: 1.238592]\n",
      "epoch3 step29120 [D loss: 0.267014] [G loss: 1.156887]\n",
      "epoch3 step29125 [D loss: -0.098549] [G loss: 1.434325]\n",
      "epoch3 step29130 [D loss: 0.044241] [G loss: 0.973120]\n",
      "epoch3 step29135 [D loss: -0.334461] [G loss: 1.337168]\n",
      "epoch3 step29140 [D loss: -0.000698] [G loss: 1.139436]\n",
      "epoch3 step29145 [D loss: -0.177973] [G loss: 1.367131]\n",
      "epoch3 step29150 [D loss: -0.142901] [G loss: 1.237118]\n",
      "epoch3 step29155 [D loss: -0.101525] [G loss: 1.069545]\n",
      "epoch3 step29160 [D loss: 0.231830] [G loss: 0.995412]\n",
      "epoch3 step29165 [D loss: -0.292801] [G loss: 1.059890]\n",
      "epoch3 step29170 [D loss: 0.065959] [G loss: 1.102487]\n",
      "epoch3 step29175 [D loss: -0.032248] [G loss: 1.237067]\n",
      "epoch3 step29180 [D loss: -0.313412] [G loss: 1.185841]\n",
      "epoch3 step29185 [D loss: -0.123610] [G loss: 1.412103]\n",
      "epoch3 step29190 [D loss: 0.410645] [G loss: 1.096579]\n",
      "epoch3 step29195 [D loss: -0.285576] [G loss: 1.312761]\n",
      "epoch3 step29200 [D loss: -0.195510] [G loss: 1.035859]\n",
      "epoch3 step29205 [D loss: -0.148114] [G loss: 1.293340]\n",
      "epoch3 step29210 [D loss: -0.015492] [G loss: 1.181782]\n",
      "epoch3 step29215 [D loss: -0.434243] [G loss: 1.292650]\n",
      "epoch3 step29220 [D loss: -0.282065] [G loss: 0.826703]\n",
      "epoch3 step29225 [D loss: -0.172677] [G loss: 1.330160]\n",
      "epoch3 step29230 [D loss: -0.007868] [G loss: 1.230442]\n",
      "epoch3 step29235 [D loss: -0.169286] [G loss: 1.117429]\n",
      "epoch3 step29240 [D loss: -0.153457] [G loss: 1.133527]\n",
      "epoch3 step29245 [D loss: -0.013388] [G loss: 1.201878]\n",
      "epoch3 step29250 [D loss: 0.413605] [G loss: 0.820748]\n",
      "epoch3 step29255 [D loss: -0.278311] [G loss: 1.033592]\n",
      "epoch3 step29260 [D loss: 0.116810] [G loss: 0.876156]\n",
      "epoch3 step29265 [D loss: -0.035347] [G loss: 0.587563]\n",
      "epoch3 step29270 [D loss: -0.098830] [G loss: 1.156701]\n",
      "epoch3 step29275 [D loss: -0.439977] [G loss: 1.151118]\n",
      "epoch3 step29280 [D loss: 0.369405] [G loss: 1.112072]\n",
      "epoch3 step29285 [D loss: -0.062359] [G loss: 1.428846]\n",
      "epoch3 step29290 [D loss: 0.274692] [G loss: 1.174760]\n",
      "epoch3 step29295 [D loss: 0.078550] [G loss: 1.416560]\n",
      "epoch3 step29300 [D loss: -0.075983] [G loss: 1.147793]\n",
      "epoch3 step29305 [D loss: -0.327374] [G loss: 1.294253]\n",
      "epoch3 step29310 [D loss: -0.257210] [G loss: 1.627348]\n",
      "epoch3 step29315 [D loss: -0.220887] [G loss: 1.448317]\n",
      "epoch3 step29320 [D loss: -0.468328] [G loss: 1.324661]\n",
      "epoch3 step29325 [D loss: 0.015684] [G loss: 1.200001]\n",
      "epoch3 step29330 [D loss: 0.024474] [G loss: 1.439412]\n",
      "epoch3 step29335 [D loss: -0.389123] [G loss: 1.964676]\n",
      "epoch3 step29340 [D loss: -0.298222] [G loss: 1.658821]\n",
      "epoch3 step29345 [D loss: -0.330763] [G loss: 1.585741]\n",
      "epoch3 step29350 [D loss: 0.145974] [G loss: 1.663806]\n",
      "epoch3 step29355 [D loss: -0.192213] [G loss: 1.456167]\n",
      "epoch3 step29360 [D loss: 0.017851] [G loss: 1.794785]\n",
      "epoch3 step29365 [D loss: 0.084379] [G loss: 1.637899]\n",
      "epoch3 step29370 [D loss: -0.006614] [G loss: 1.757778]\n",
      "epoch3 step29375 [D loss: -0.351734] [G loss: 1.751241]\n",
      "epoch3 step29380 [D loss: -0.065486] [G loss: 2.038067]\n",
      "epoch3 step29385 [D loss: -0.275194] [G loss: 1.876014]\n",
      "epoch3 step29390 [D loss: -0.173254] [G loss: 2.128016]\n",
      "epoch3 step29395 [D loss: 0.002350] [G loss: 2.086663]\n",
      "epoch3 step29400 [D loss: -0.129044] [G loss: 1.847871]\n",
      "epoch3 step29405 [D loss: -0.317808] [G loss: 1.709757]\n",
      "epoch3 step29410 [D loss: 0.397206] [G loss: 1.977622]\n",
      "epoch3 step29415 [D loss: -0.296226] [G loss: 2.124979]\n",
      "epoch3 step29420 [D loss: -0.282525] [G loss: 2.252782]\n",
      "epoch3 step29425 [D loss: -0.140713] [G loss: 1.861220]\n",
      "epoch3 step29430 [D loss: -0.074029] [G loss: 1.548067]\n",
      "epoch3 step29435 [D loss: 0.079022] [G loss: 1.729373]\n",
      "epoch3 step29440 [D loss: 0.234087] [G loss: 1.855803]\n",
      "epoch3 step29445 [D loss: 0.196359] [G loss: 1.489172]\n",
      "epoch3 step29450 [D loss: -0.246061] [G loss: 1.665870]\n",
      "epoch3 step29455 [D loss: -0.197353] [G loss: 1.755194]\n",
      "epoch3 step29460 [D loss: -0.171370] [G loss: 1.378662]\n",
      "epoch3 step29465 [D loss: -0.081535] [G loss: 1.825838]\n",
      "epoch3 step29470 [D loss: 0.166453] [G loss: 1.547622]\n",
      "epoch3 step29475 [D loss: -0.436501] [G loss: 1.852960]\n",
      "epoch3 step29480 [D loss: -0.256725] [G loss: 1.686294]\n",
      "epoch3 step29485 [D loss: 0.258583] [G loss: 1.322145]\n",
      "epoch3 step29490 [D loss: -0.130511] [G loss: 1.527372]\n",
      "epoch3 step29495 [D loss: -0.137769] [G loss: 1.578066]\n",
      "epoch3 step29500 [D loss: -0.111961] [G loss: 1.492521]\n",
      "epoch3 step29505 [D loss: -0.413229] [G loss: 1.580557]\n",
      "epoch3 step29510 [D loss: 0.228271] [G loss: 1.598889]\n",
      "epoch3 step29515 [D loss: 0.384908] [G loss: 1.407349]\n",
      "epoch3 step29520 [D loss: 0.233800] [G loss: 1.399603]\n",
      "epoch3 step29525 [D loss: 0.286679] [G loss: 1.458367]\n",
      "epoch3 step29530 [D loss: 0.091042] [G loss: 1.388777]\n",
      "epoch3 step29535 [D loss: -0.064000] [G loss: 1.620101]\n",
      "epoch3 step29540 [D loss: -0.196262] [G loss: 1.432947]\n",
      "epoch3 step29545 [D loss: -0.076508] [G loss: 1.527436]\n",
      "epoch3 step29550 [D loss: -0.267657] [G loss: 1.534359]\n",
      "epoch3 step29555 [D loss: -0.285586] [G loss: 1.464985]\n",
      "epoch3 step29560 [D loss: 0.210254] [G loss: 1.338685]\n",
      "epoch3 step29565 [D loss: -0.371376] [G loss: 1.302619]\n",
      "epoch3 step29570 [D loss: -0.139315] [G loss: 1.353599]\n",
      "epoch3 step29575 [D loss: -0.276895] [G loss: 1.209701]\n",
      "epoch3 step29580 [D loss: -0.043243] [G loss: 1.504151]\n",
      "epoch3 step29585 [D loss: -0.155661] [G loss: 1.540020]\n",
      "epoch3 step29590 [D loss: -0.220967] [G loss: 1.032840]\n",
      "epoch3 step29595 [D loss: 0.024849] [G loss: 1.130296]\n",
      "epoch3 step29600 [D loss: -0.488211] [G loss: 1.665234]\n",
      "epoch3 step29605 [D loss: 0.147132] [G loss: 1.009634]\n",
      "epoch3 step29610 [D loss: -0.254203] [G loss: 1.525476]\n",
      "epoch3 step29615 [D loss: 0.159772] [G loss: 1.115334]\n",
      "epoch3 step29620 [D loss: -0.380106] [G loss: 1.510813]\n",
      "epoch3 step29625 [D loss: -0.228213] [G loss: 1.367844]\n",
      "epoch3 step29630 [D loss: -0.133027] [G loss: 1.220629]\n",
      "epoch3 step29635 [D loss: -0.066542] [G loss: 1.409830]\n",
      "epoch3 step29640 [D loss: -0.264054] [G loss: 1.241109]\n",
      "epoch3 step29645 [D loss: -0.323379] [G loss: 0.924466]\n",
      "epoch3 step29650 [D loss: -0.231510] [G loss: 1.118397]\n",
      "epoch3 step29655 [D loss: 0.081111] [G loss: 0.687813]\n",
      "epoch3 step29660 [D loss: -0.160550] [G loss: 1.174477]\n",
      "epoch3 step29665 [D loss: 0.156599] [G loss: 0.952446]\n",
      "epoch3 step29670 [D loss: -0.042144] [G loss: 0.543402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step29675 [D loss: 0.174120] [G loss: 1.136488]\n",
      "epoch3 step29680 [D loss: 0.179858] [G loss: 1.130411]\n",
      "epoch3 step29685 [D loss: 0.017025] [G loss: 1.520589]\n",
      "epoch3 step29690 [D loss: -0.007490] [G loss: 1.219341]\n",
      "epoch3 step29695 [D loss: -0.006015] [G loss: 1.370637]\n",
      "epoch3 step29700 [D loss: -0.398100] [G loss: 1.434911]\n",
      "epoch3 step29705 [D loss: -0.307004] [G loss: 1.144528]\n",
      "epoch3 step29710 [D loss: 0.085312] [G loss: 1.279135]\n",
      "epoch3 step29715 [D loss: -0.214442] [G loss: 1.673526]\n",
      "epoch3 step29720 [D loss: -0.476356] [G loss: 1.860212]\n",
      "epoch3 step29725 [D loss: -0.411925] [G loss: 1.771103]\n",
      "epoch3 step29730 [D loss: -0.123708] [G loss: 1.809452]\n",
      "epoch3 step29735 [D loss: -0.248314] [G loss: 1.607590]\n",
      "epoch3 step29740 [D loss: -0.150472] [G loss: 1.599600]\n",
      "epoch3 step29745 [D loss: -0.063420] [G loss: 1.548770]\n",
      "epoch3 step29750 [D loss: -0.143794] [G loss: 1.576941]\n",
      "epoch3 step29755 [D loss: -0.065766] [G loss: 1.733328]\n",
      "epoch3 step29760 [D loss: 0.215678] [G loss: 1.788083]\n",
      "epoch3 step29765 [D loss: -0.214156] [G loss: 1.326395]\n",
      "epoch3 step29770 [D loss: 0.235861] [G loss: 1.455217]\n",
      "epoch3 step29775 [D loss: 0.170832] [G loss: 1.729825]\n",
      "epoch3 step29780 [D loss: -0.384677] [G loss: 1.739583]\n",
      "epoch3 step29785 [D loss: 0.182405] [G loss: 1.728610]\n",
      "epoch3 step29790 [D loss: 0.222737] [G loss: 1.598196]\n",
      "epoch3 step29795 [D loss: -0.236521] [G loss: 1.393353]\n",
      "epoch3 step29800 [D loss: -0.452967] [G loss: 1.555434]\n",
      "epoch3 step29805 [D loss: 0.590848] [G loss: 1.172049]\n",
      "epoch3 step29810 [D loss: 0.247940] [G loss: 1.619055]\n",
      "epoch3 step29815 [D loss: -0.292285] [G loss: 1.497734]\n",
      "epoch3 step29820 [D loss: -0.217507] [G loss: 1.550453]\n",
      "epoch3 step29825 [D loss: -0.100119] [G loss: 1.702532]\n",
      "epoch3 step29830 [D loss: -0.293647] [G loss: 1.605228]\n",
      "epoch3 step29835 [D loss: 0.412005] [G loss: 1.257419]\n",
      "epoch3 step29840 [D loss: 0.449017] [G loss: 1.232028]\n",
      "epoch3 step29845 [D loss: -0.097654] [G loss: 1.350478]\n",
      "epoch3 step29850 [D loss: 0.230512] [G loss: 1.984063]\n",
      "epoch3 step29855 [D loss: 0.841511] [G loss: 1.168080]\n",
      "epoch3 step29860 [D loss: 0.216127] [G loss: 1.278398]\n",
      "epoch3 step29865 [D loss: 0.043069] [G loss: 1.315304]\n",
      "epoch3 step29870 [D loss: 0.159850] [G loss: 1.303871]\n",
      "epoch3 step29875 [D loss: 0.143293] [G loss: 1.405839]\n",
      "epoch3 step29880 [D loss: 0.163816] [G loss: 1.619133]\n",
      "epoch3 step29885 [D loss: -0.382714] [G loss: 1.213464]\n",
      "epoch3 step29890 [D loss: -0.057885] [G loss: 1.465788]\n",
      "epoch3 step29895 [D loss: -0.694619] [G loss: 1.669938]\n",
      "epoch3 step29900 [D loss: -0.242813] [G loss: 1.276712]\n",
      "epoch3 step29905 [D loss: -0.452057] [G loss: 1.449540]\n",
      "epoch3 step29910 [D loss: 0.029084] [G loss: 1.614745]\n",
      "epoch3 step29915 [D loss: 0.118885] [G loss: 1.426425]\n",
      "epoch3 step29920 [D loss: -0.224733] [G loss: 1.593070]\n",
      "epoch3 step29925 [D loss: 0.235369] [G loss: 1.034373]\n",
      "epoch3 step29930 [D loss: -0.100273] [G loss: 1.275341]\n",
      "epoch3 step29935 [D loss: -0.267277] [G loss: 1.280599]\n",
      "epoch3 step29940 [D loss: 0.174368] [G loss: 1.265404]\n",
      "epoch3 step29945 [D loss: -0.206232] [G loss: 1.392480]\n",
      "epoch3 step29950 [D loss: -0.183260] [G loss: 1.401381]\n",
      "epoch3 step29955 [D loss: -0.252228] [G loss: 1.325658]\n",
      "epoch3 step29960 [D loss: -0.336325] [G loss: 1.364172]\n",
      "epoch3 step29965 [D loss: 0.038011] [G loss: 1.228039]\n",
      "epoch3 step29970 [D loss: 0.713214] [G loss: 1.411539]\n",
      "epoch3 step29975 [D loss: 0.099383] [G loss: 1.236817]\n",
      "epoch3 step29980 [D loss: -0.337801] [G loss: 1.149722]\n",
      "epoch3 step29985 [D loss: -0.520425] [G loss: 1.791335]\n",
      "epoch3 step29990 [D loss: 0.143018] [G loss: 1.419064]\n",
      "epoch3 step29995 [D loss: 0.154166] [G loss: 1.402719]\n",
      "epoch3 step30000 [D loss: -0.279893] [G loss: 1.460911]\n",
      "epoch3 step30005 [D loss: -0.439650] [G loss: 1.321695]\n",
      "epoch3 step30010 [D loss: 0.033142] [G loss: 1.167610]\n",
      "epoch3 step30015 [D loss: -0.267943] [G loss: 1.175249]\n",
      "epoch3 step30020 [D loss: -0.293463] [G loss: 1.237249]\n",
      "epoch3 step30025 [D loss: 0.025411] [G loss: 1.164261]\n",
      "epoch3 step30030 [D loss: -0.458675] [G loss: 1.496225]\n",
      "epoch3 step30035 [D loss: 0.187583] [G loss: 1.093048]\n",
      "epoch3 step30040 [D loss: -0.446898] [G loss: 1.633005]\n",
      "epoch3 step30045 [D loss: -0.051017] [G loss: 1.586840]\n",
      "epoch3 step30050 [D loss: -0.150232] [G loss: 1.425979]\n",
      "epoch3 step30055 [D loss: -0.044317] [G loss: 1.361660]\n",
      "epoch3 step30060 [D loss: -0.151238] [G loss: 1.417228]\n",
      "epoch3 step30065 [D loss: 0.184715] [G loss: 1.202739]\n",
      "epoch3 step30070 [D loss: -0.021223] [G loss: 1.190933]\n",
      "epoch3 step30075 [D loss: -0.609469] [G loss: 1.474002]\n",
      "epoch3 step30080 [D loss: -0.145915] [G loss: 1.459964]\n",
      "epoch3 step30085 [D loss: -0.004688] [G loss: 1.407448]\n",
      "epoch3 step30090 [D loss: -0.074841] [G loss: 1.527056]\n",
      "epoch3 step30095 [D loss: -0.091974] [G loss: 1.256143]\n",
      "epoch3 step30100 [D loss: 0.068891] [G loss: 1.680632]\n",
      "epoch3 step30105 [D loss: -0.039473] [G loss: 1.564520]\n",
      "epoch3 step30110 [D loss: 0.013894] [G loss: 1.341304]\n",
      "epoch3 step30115 [D loss: -0.321295] [G loss: 1.686847]\n",
      "epoch3 step30120 [D loss: 0.003020] [G loss: 1.439587]\n",
      "epoch3 step30125 [D loss: -0.114594] [G loss: 1.583055]\n",
      "epoch3 step30130 [D loss: -0.138405] [G loss: 1.639520]\n",
      "epoch3 step30135 [D loss: -0.806135] [G loss: 1.342925]\n",
      "epoch3 step30140 [D loss: 0.137419] [G loss: 1.657201]\n",
      "epoch3 step30145 [D loss: -0.049686] [G loss: 1.704045]\n",
      "epoch3 step30150 [D loss: -0.279117] [G loss: 1.556675]\n",
      "epoch3 step30155 [D loss: 0.136651] [G loss: 1.616332]\n",
      "epoch3 step30160 [D loss: 0.392884] [G loss: 1.348535]\n",
      "epoch3 step30165 [D loss: 0.410830] [G loss: 0.976818]\n",
      "epoch3 step30170 [D loss: -0.126887] [G loss: 1.570981]\n",
      "epoch3 step30175 [D loss: -0.059283] [G loss: 1.593364]\n",
      "epoch3 step30180 [D loss: 0.079718] [G loss: 1.386162]\n",
      "epoch3 step30185 [D loss: 0.171070] [G loss: 1.259262]\n",
      "epoch3 step30190 [D loss: -0.254871] [G loss: 1.162313]\n",
      "epoch3 step30195 [D loss: -0.107196] [G loss: 1.318716]\n",
      "epoch3 step30200 [D loss: 0.026874] [G loss: 1.320177]\n",
      "epoch3 step30205 [D loss: -0.095269] [G loss: 1.279967]\n",
      "epoch3 step30210 [D loss: -0.128081] [G loss: 1.215671]\n",
      "epoch3 step30215 [D loss: -0.035562] [G loss: 1.096328]\n",
      "epoch3 step30220 [D loss: -0.176344] [G loss: 1.015154]\n",
      "epoch3 step30225 [D loss: -0.166486] [G loss: 1.278121]\n",
      "epoch3 step30230 [D loss: 0.027737] [G loss: 1.264580]\n",
      "epoch3 step30235 [D loss: -0.489523] [G loss: 1.084948]\n",
      "epoch3 step30240 [D loss: 0.108500] [G loss: 1.175462]\n",
      "epoch3 step30245 [D loss: -0.217974] [G loss: 1.137774]\n",
      "epoch3 step30250 [D loss: 0.124774] [G loss: 0.841676]\n",
      "epoch3 step30255 [D loss: -0.156998] [G loss: 0.787075]\n",
      "epoch3 step30260 [D loss: -0.182435] [G loss: 1.422158]\n",
      "epoch3 step30265 [D loss: -0.442424] [G loss: 1.321564]\n",
      "epoch3 step30270 [D loss: -0.526818] [G loss: 1.181451]\n",
      "epoch3 step30275 [D loss: 0.136329] [G loss: 0.897854]\n",
      "epoch3 step30280 [D loss: 0.071983] [G loss: 1.124620]\n",
      "epoch3 step30285 [D loss: 0.400885] [G loss: 0.923813]\n",
      "epoch3 step30290 [D loss: 0.003293] [G loss: 0.897342]\n",
      "epoch3 step30295 [D loss: 0.183786] [G loss: 0.909373]\n",
      "epoch3 step30300 [D loss: 0.089977] [G loss: 0.878579]\n",
      "epoch3 step30305 [D loss: -0.120343] [G loss: 0.676007]\n",
      "epoch3 step30310 [D loss: -0.107185] [G loss: 0.898143]\n",
      "epoch3 step30315 [D loss: 0.112888] [G loss: 0.794878]\n",
      "epoch3 step30320 [D loss: -0.024285] [G loss: 0.550061]\n",
      "epoch3 step30325 [D loss: 0.024979] [G loss: 0.986460]\n",
      "epoch3 step30330 [D loss: -0.042319] [G loss: 0.927083]\n",
      "epoch3 step30335 [D loss: -0.060640] [G loss: 0.760834]\n",
      "epoch3 step30340 [D loss: -0.056877] [G loss: 0.937524]\n",
      "epoch3 step30345 [D loss: -0.030238] [G loss: 0.825999]\n",
      "epoch3 step30350 [D loss: -0.467290] [G loss: 0.515466]\n",
      "epoch3 step30355 [D loss: -0.002737] [G loss: 0.571035]\n",
      "epoch3 step30360 [D loss: 0.286312] [G loss: 0.690032]\n",
      "epoch3 step30365 [D loss: -0.384399] [G loss: 0.689712]\n",
      "epoch3 step30370 [D loss: 0.015417] [G loss: 0.767983]\n",
      "epoch3 step30375 [D loss: -0.495297] [G loss: 0.611783]\n",
      "epoch3 step30380 [D loss: -0.574877] [G loss: 0.661925]\n",
      "epoch3 step30385 [D loss: -0.243315] [G loss: 0.533043]\n",
      "epoch3 step30390 [D loss: 0.232121] [G loss: 0.172103]\n",
      "epoch3 step30395 [D loss: -0.225936] [G loss: 0.240836]\n",
      "epoch3 step30400 [D loss: -0.037977] [G loss: 0.521097]\n",
      "epoch3 step30405 [D loss: -0.239412] [G loss: 0.477358]\n",
      "epoch3 step30410 [D loss: -0.003415] [G loss: 0.179417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step30415 [D loss: -0.159599] [G loss: 0.351781]\n",
      "epoch3 step30420 [D loss: -0.684277] [G loss: 0.520146]\n",
      "epoch3 step30425 [D loss: -0.596501] [G loss: 0.161892]\n",
      "epoch3 step30430 [D loss: -0.394564] [G loss: 0.330125]\n",
      "epoch3 step30435 [D loss: -0.001350] [G loss: -0.020702]\n",
      "epoch3 step30440 [D loss: 0.470614] [G loss: 0.312581]\n",
      "epoch3 step30445 [D loss: -0.173564] [G loss: 0.398790]\n",
      "epoch3 step30450 [D loss: -0.343149] [G loss: 0.552515]\n",
      "epoch3 step30455 [D loss: 0.317653] [G loss: 0.525434]\n",
      "epoch3 step30460 [D loss: -0.028624] [G loss: 0.503010]\n",
      "epoch3 step30465 [D loss: -0.033749] [G loss: 0.420990]\n",
      "epoch3 step30470 [D loss: 0.218274] [G loss: 0.439901]\n",
      "epoch3 step30475 [D loss: -0.084512] [G loss: 0.484236]\n",
      "epoch3 step30480 [D loss: -0.196170] [G loss: 0.384724]\n",
      "epoch3 step30485 [D loss: 0.062069] [G loss: 0.623851]\n",
      "epoch3 step30490 [D loss: 0.250595] [G loss: 0.718256]\n",
      "epoch3 step30495 [D loss: 0.383037] [G loss: 0.855378]\n",
      "epoch3 step30500 [D loss: 0.521808] [G loss: 0.551757]\n",
      "epoch3 step30505 [D loss: -0.065745] [G loss: 1.071389]\n",
      "epoch3 step30510 [D loss: -0.277876] [G loss: 1.353836]\n",
      "epoch3 step30515 [D loss: 0.051195] [G loss: 1.194504]\n",
      "epoch3 step30520 [D loss: -0.043881] [G loss: 1.130896]\n",
      "epoch3 step30525 [D loss: -0.345092] [G loss: 1.257181]\n",
      "epoch3 step30530 [D loss: -0.444725] [G loss: 1.266207]\n",
      "epoch3 step30535 [D loss: -0.085703] [G loss: 1.387179]\n",
      "epoch3 step30540 [D loss: -0.517448] [G loss: 1.542217]\n",
      "epoch3 step30545 [D loss: 0.031921] [G loss: 1.332607]\n",
      "epoch3 step30550 [D loss: -0.356770] [G loss: 1.701823]\n",
      "epoch3 step30555 [D loss: -0.443671] [G loss: 1.978469]\n",
      "epoch3 step30560 [D loss: 0.042362] [G loss: 1.724434]\n",
      "epoch3 step30565 [D loss: -0.099180] [G loss: 1.323496]\n",
      "epoch3 step30570 [D loss: -0.185067] [G loss: 2.014916]\n",
      "epoch3 step30575 [D loss: 0.116054] [G loss: 1.891026]\n",
      "epoch3 step30580 [D loss: -0.199809] [G loss: 1.591371]\n",
      "epoch3 step30585 [D loss: -0.365293] [G loss: 1.474545]\n",
      "epoch3 step30590 [D loss: -0.105211] [G loss: 1.663950]\n",
      "epoch3 step30595 [D loss: -0.166195] [G loss: 1.369630]\n",
      "epoch3 step30600 [D loss: -0.125575] [G loss: 1.845545]\n",
      "epoch3 step30605 [D loss: -0.227113] [G loss: 1.676760]\n",
      "epoch3 step30610 [D loss: -0.470629] [G loss: 1.555789]\n",
      "epoch3 step30615 [D loss: -0.394989] [G loss: 1.295448]\n",
      "epoch3 step30620 [D loss: 0.207635] [G loss: 1.399243]\n",
      "epoch3 step30625 [D loss: -0.137702] [G loss: 1.530156]\n",
      "epoch3 step30630 [D loss: -0.387928] [G loss: 1.410458]\n",
      "epoch3 step30635 [D loss: -0.052394] [G loss: 1.418306]\n",
      "epoch3 step30640 [D loss: 0.296475] [G loss: 1.328709]\n",
      "epoch3 step30645 [D loss: 0.801215] [G loss: 1.318340]\n",
      "epoch3 step30650 [D loss: -0.519043] [G loss: 1.681778]\n",
      "epoch3 step30655 [D loss: -0.167065] [G loss: 1.538400]\n",
      "epoch3 step30660 [D loss: 0.118362] [G loss: 1.652834]\n",
      "epoch3 step30665 [D loss: -0.074487] [G loss: 1.253289]\n",
      "epoch3 step30670 [D loss: -0.686438] [G loss: 1.778214]\n",
      "epoch3 step30675 [D loss: -0.505489] [G loss: 1.861511]\n",
      "epoch3 step30680 [D loss: 0.057404] [G loss: 1.656127]\n",
      "epoch3 step30685 [D loss: -0.780964] [G loss: 1.748500]\n",
      "epoch3 step30690 [D loss: -0.045321] [G loss: 1.863520]\n",
      "epoch3 step30695 [D loss: 0.106050] [G loss: 1.166894]\n",
      "epoch3 step30700 [D loss: 0.390168] [G loss: 1.634424]\n",
      "epoch3 step30705 [D loss: -0.265845] [G loss: 1.626997]\n",
      "epoch3 step30710 [D loss: 0.219815] [G loss: 1.531735]\n",
      "epoch3 step30715 [D loss: -0.132196] [G loss: 1.256710]\n",
      "epoch3 step30720 [D loss: -0.473174] [G loss: 1.179662]\n",
      "epoch3 step30725 [D loss: 0.104898] [G loss: 1.272637]\n",
      "epoch3 step30730 [D loss: -0.280471] [G loss: 1.290906]\n",
      "epoch3 step30735 [D loss: -0.290174] [G loss: 1.352828]\n",
      "epoch3 step30740 [D loss: -0.057389] [G loss: 0.831318]\n",
      "epoch3 step30745 [D loss: 0.359833] [G loss: 0.767086]\n",
      "epoch3 step30750 [D loss: -0.267454] [G loss: 1.297894]\n",
      "epoch3 step30755 [D loss: -0.176758] [G loss: 0.621736]\n",
      "epoch3 step30760 [D loss: 0.213838] [G loss: 1.033570]\n",
      "epoch3 step30765 [D loss: -0.570185] [G loss: 0.922337]\n",
      "epoch3 step30770 [D loss: 0.421041] [G loss: 0.845458]\n",
      "epoch3 step30775 [D loss: -0.174596] [G loss: 0.653094]\n",
      "epoch3 step30780 [D loss: -0.475704] [G loss: 0.657397]\n",
      "epoch3 step30785 [D loss: -0.495421] [G loss: 0.618753]\n",
      "epoch3 step30790 [D loss: -0.351070] [G loss: 0.745819]\n",
      "epoch3 step30795 [D loss: 0.192366] [G loss: 0.396646]\n",
      "epoch3 step30800 [D loss: -0.094353] [G loss: 0.881621]\n",
      "epoch3 step30805 [D loss: -0.122745] [G loss: 0.663090]\n",
      "epoch3 step30810 [D loss: 0.222786] [G loss: 0.822021]\n",
      "epoch3 step30815 [D loss: -0.178447] [G loss: 0.690093]\n",
      "epoch3 step30820 [D loss: -0.569834] [G loss: 0.893282]\n",
      "epoch3 step30825 [D loss: -0.102546] [G loss: 0.769241]\n",
      "epoch3 step30830 [D loss: -0.078676] [G loss: 0.839813]\n",
      "epoch3 step30835 [D loss: -0.422961] [G loss: 1.025308]\n",
      "epoch3 step30840 [D loss: -0.047989] [G loss: 1.029733]\n",
      "epoch3 step30845 [D loss: -0.562896] [G loss: 1.214667]\n",
      "epoch3 step30850 [D loss: -0.322627] [G loss: 0.702055]\n",
      "epoch3 step30855 [D loss: -0.137258] [G loss: 1.357579]\n",
      "epoch3 step30860 [D loss: -0.128610] [G loss: 0.975997]\n",
      "epoch3 step30865 [D loss: -0.036025] [G loss: 1.201229]\n",
      "epoch3 step30870 [D loss: 0.084623] [G loss: 0.967370]\n",
      "epoch3 step30875 [D loss: 0.241090] [G loss: 1.356323]\n",
      "epoch3 step30880 [D loss: -0.359379] [G loss: 1.493312]\n",
      "epoch3 step30885 [D loss: -0.041177] [G loss: 1.217669]\n",
      "epoch3 step30890 [D loss: -0.081561] [G loss: 1.238905]\n",
      "epoch3 step30895 [D loss: 0.006192] [G loss: 0.876715]\n",
      "epoch3 step30900 [D loss: 0.253575] [G loss: 1.414071]\n",
      "epoch3 step30905 [D loss: 0.022430] [G loss: 1.311027]\n",
      "epoch3 step30910 [D loss: 0.223038] [G loss: 1.550828]\n",
      "epoch3 step30915 [D loss: -0.050275] [G loss: 1.246609]\n",
      "epoch3 step30920 [D loss: 0.060851] [G loss: 1.630444]\n",
      "epoch3 step30925 [D loss: -0.443203] [G loss: 1.382188]\n",
      "epoch3 step30930 [D loss: 0.175476] [G loss: 1.399812]\n",
      "epoch3 step30935 [D loss: -0.256027] [G loss: 1.611401]\n",
      "epoch3 step30940 [D loss: -0.029979] [G loss: 1.862108]\n",
      "epoch3 step30945 [D loss: 0.059701] [G loss: 1.558910]\n",
      "epoch3 step30950 [D loss: -0.347592] [G loss: 1.379983]\n",
      "epoch3 step30955 [D loss: -0.405613] [G loss: 1.737722]\n",
      "epoch3 step30960 [D loss: -0.222397] [G loss: 1.377303]\n",
      "epoch3 step30965 [D loss: -0.577107] [G loss: 1.821033]\n",
      "epoch3 step30970 [D loss: -0.001233] [G loss: 1.690244]\n",
      "epoch3 step30975 [D loss: -0.014558] [G loss: 1.640912]\n",
      "epoch3 step30980 [D loss: 0.311876] [G loss: 1.738893]\n",
      "epoch3 step30985 [D loss: 0.066780] [G loss: 1.488119]\n",
      "epoch3 step30990 [D loss: -0.100994] [G loss: 1.264235]\n",
      "epoch3 step30995 [D loss: -0.070751] [G loss: 1.600513]\n",
      "epoch3 step31000 [D loss: -0.173586] [G loss: 1.439039]\n",
      "epoch3 step31005 [D loss: 0.011222] [G loss: 1.209993]\n",
      "epoch3 step31010 [D loss: 0.393924] [G loss: 1.201244]\n",
      "epoch3 step31015 [D loss: -0.396391] [G loss: 1.672424]\n",
      "epoch3 step31020 [D loss: 0.324589] [G loss: 1.256551]\n",
      "epoch3 step31025 [D loss: 0.538196] [G loss: 1.116729]\n",
      "epoch3 step31030 [D loss: -0.783658] [G loss: 1.565240]\n",
      "epoch3 step31035 [D loss: 0.336079] [G loss: 1.423235]\n",
      "epoch3 step31040 [D loss: -0.123848] [G loss: 1.186826]\n",
      "epoch3 step31045 [D loss: -0.431568] [G loss: 1.158705]\n",
      "epoch3 step31050 [D loss: -0.273961] [G loss: 1.157151]\n",
      "epoch3 step31055 [D loss: 0.112981] [G loss: 1.181366]\n",
      "epoch3 step31060 [D loss: -0.436574] [G loss: 0.827807]\n",
      "epoch3 step31065 [D loss: -0.466806] [G loss: 1.130322]\n",
      "epoch3 step31070 [D loss: 0.129689] [G loss: 0.972249]\n",
      "epoch3 step31075 [D loss: 0.112969] [G loss: 0.989730]\n",
      "epoch3 step31080 [D loss: 0.080939] [G loss: 0.988277]\n",
      "epoch3 step31085 [D loss: 0.007839] [G loss: 0.826567]\n",
      "epoch3 step31090 [D loss: -0.299389] [G loss: 1.046544]\n",
      "epoch3 step31095 [D loss: -0.402178] [G loss: 0.611228]\n",
      "epoch3 step31100 [D loss: -0.287923] [G loss: 0.982784]\n",
      "epoch3 step31105 [D loss: -0.374538] [G loss: 1.214562]\n",
      "epoch3 step31110 [D loss: -0.221537] [G loss: 0.774058]\n",
      "epoch3 step31115 [D loss: -0.016110] [G loss: 0.594887]\n",
      "epoch3 step31120 [D loss: -0.044574] [G loss: 0.586741]\n",
      "epoch3 step31125 [D loss: 0.395849] [G loss: 0.631103]\n",
      "epoch3 step31130 [D loss: -0.542553] [G loss: 1.189478]\n",
      "epoch3 step31135 [D loss: -0.015895] [G loss: 1.226136]\n",
      "epoch3 step31140 [D loss: -0.219952] [G loss: 0.840024]\n",
      "epoch3 step31145 [D loss: -0.081773] [G loss: 0.915321]\n",
      "epoch3 step31150 [D loss: 0.182644] [G loss: 0.795176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3 step31155 [D loss: -0.320621] [G loss: 0.889327]\n",
      "epoch3 step31160 [D loss: -0.077069] [G loss: 0.777921]\n",
      "epoch3 step31165 [D loss: -0.155006] [G loss: 1.123452]\n",
      "epoch3 step31170 [D loss: -0.203639] [G loss: 0.963466]\n",
      "epoch3 step31175 [D loss: 0.164035] [G loss: 1.040994]\n",
      "epoch3 step31180 [D loss: -0.289638] [G loss: 1.229525]\n",
      "epoch3 step31185 [D loss: -0.105830] [G loss: 0.889551]\n",
      "epoch3 step31190 [D loss: -0.097753] [G loss: 0.900912]\n",
      "epoch3 step31195 [D loss: -0.329407] [G loss: 1.098355]\n",
      "epoch3 step31200 [D loss: -0.211242] [G loss: 1.110758]\n",
      "epoch3 step31205 [D loss: -0.350787] [G loss: 1.181329]\n",
      "epoch3 step31210 [D loss: -0.195422] [G loss: 1.222248]\n",
      "epoch3 step31215 [D loss: -0.169330] [G loss: 1.134945]\n",
      "epoch3 step31220 [D loss: 0.049073] [G loss: 1.228386]\n",
      "epoch3 step31225 [D loss: 0.169870] [G loss: 1.146011]\n",
      "epoch3 step31230 [D loss: -0.011771] [G loss: 1.069944]\n",
      "epoch3 step31235 [D loss: -0.238807] [G loss: 1.092206]\n",
      "epoch3 step31240 [D loss: -0.337128] [G loss: 1.074021]\n",
      "epoch4 step31245 [D loss: -0.369135] [G loss: 1.346743]\n",
      "epoch4 step31250 [D loss: -0.112389] [G loss: 1.186232]\n",
      "epoch4 step31255 [D loss: 0.021511] [G loss: 1.132036]\n",
      "epoch4 step31260 [D loss: -0.106329] [G loss: 1.384634]\n",
      "epoch4 step31265 [D loss: -0.218349] [G loss: 1.316061]\n",
      "epoch4 step31270 [D loss: -0.082993] [G loss: 1.362675]\n",
      "epoch4 step31275 [D loss: 0.436516] [G loss: 0.979029]\n",
      "epoch4 step31280 [D loss: -0.192248] [G loss: 1.410210]\n",
      "epoch4 step31285 [D loss: 0.346852] [G loss: 1.103725]\n",
      "epoch4 step31290 [D loss: -0.095504] [G loss: 0.988726]\n",
      "epoch4 step31295 [D loss: 0.165121] [G loss: 0.960602]\n",
      "epoch4 step31300 [D loss: -0.276923] [G loss: 1.252599]\n",
      "epoch4 step31305 [D loss: 0.105065] [G loss: 1.221751]\n",
      "epoch4 step31310 [D loss: 0.040831] [G loss: 1.200059]\n",
      "epoch4 step31315 [D loss: 0.110325] [G loss: 1.083522]\n",
      "epoch4 step31320 [D loss: 0.033876] [G loss: 1.132160]\n",
      "epoch4 step31325 [D loss: 0.210708] [G loss: 0.885446]\n",
      "epoch4 step31330 [D loss: 0.036335] [G loss: 0.906948]\n",
      "epoch4 step31335 [D loss: -0.039521] [G loss: 1.045181]\n",
      "epoch4 step31340 [D loss: 0.226051] [G loss: 0.571825]\n",
      "epoch4 step31345 [D loss: 0.427571] [G loss: 1.022336]\n",
      "epoch4 step31350 [D loss: -0.203878] [G loss: 0.818701]\n",
      "epoch4 step31355 [D loss: 0.001925] [G loss: 0.771639]\n",
      "epoch4 step31360 [D loss: -0.239773] [G loss: 0.932475]\n",
      "epoch4 step31365 [D loss: -0.075460] [G loss: 0.460950]\n",
      "epoch4 step31370 [D loss: 0.237601] [G loss: 0.668884]\n",
      "epoch4 step31375 [D loss: -0.420686] [G loss: 1.021079]\n",
      "epoch4 step31380 [D loss: -0.076988] [G loss: 0.846049]\n",
      "epoch4 step31385 [D loss: 0.064739] [G loss: 0.404986]\n",
      "epoch4 step31390 [D loss: -0.132101] [G loss: 0.887059]\n",
      "epoch4 step31395 [D loss: -0.263709] [G loss: 0.579332]\n",
      "epoch4 step31400 [D loss: -0.199095] [G loss: 0.758509]\n",
      "epoch4 step31405 [D loss: 0.357289] [G loss: 0.574110]\n",
      "epoch4 step31410 [D loss: 0.216263] [G loss: 0.415799]\n",
      "epoch4 step31415 [D loss: -0.307221] [G loss: 0.829261]\n",
      "epoch4 step31420 [D loss: -0.183983] [G loss: 0.921305]\n",
      "epoch4 step31425 [D loss: -0.031998] [G loss: 0.932182]\n",
      "epoch4 step31430 [D loss: -0.106410] [G loss: 0.793419]\n",
      "epoch4 step31435 [D loss: 0.056871] [G loss: 0.526975]\n",
      "epoch4 step31440 [D loss: 0.094413] [G loss: 0.529659]\n",
      "epoch4 step31445 [D loss: 0.036955] [G loss: 0.477584]\n",
      "epoch4 step31450 [D loss: 0.276370] [G loss: 0.781335]\n",
      "epoch4 step31455 [D loss: 0.072353] [G loss: 0.546400]\n",
      "epoch4 step31460 [D loss: -0.390493] [G loss: 0.721077]\n",
      "epoch4 step31465 [D loss: 0.015847] [G loss: 0.873455]\n",
      "epoch4 step31470 [D loss: -0.616901] [G loss: 0.553519]\n",
      "epoch4 step31475 [D loss: 0.388476] [G loss: 0.609601]\n",
      "epoch4 step31480 [D loss: 0.391946] [G loss: 0.309491]\n",
      "epoch4 step31485 [D loss: -0.180857] [G loss: 0.369995]\n",
      "epoch4 step31490 [D loss: -0.456606] [G loss: 0.364579]\n",
      "epoch4 step31495 [D loss: 0.089202] [G loss: 0.440395]\n",
      "epoch4 step31500 [D loss: -0.014552] [G loss: 0.403688]\n",
      "epoch4 step31505 [D loss: 0.016409] [G loss: 0.565532]\n",
      "epoch4 step31510 [D loss: -0.075016] [G loss: 0.411465]\n",
      "epoch4 step31515 [D loss: 0.308756] [G loss: 0.488595]\n",
      "epoch4 step31520 [D loss: -0.305201] [G loss: 0.615171]\n",
      "epoch4 step31525 [D loss: -0.213655] [G loss: 0.766618]\n",
      "epoch4 step31530 [D loss: -0.244124] [G loss: 0.624624]\n",
      "epoch4 step31535 [D loss: -0.106158] [G loss: 0.677849]\n",
      "epoch4 step31540 [D loss: 0.016851] [G loss: 0.938353]\n",
      "epoch4 step31545 [D loss: 0.078548] [G loss: 1.039499]\n",
      "epoch4 step31550 [D loss: 0.079382] [G loss: 1.095521]\n",
      "epoch4 step31555 [D loss: -0.193427] [G loss: 0.992466]\n",
      "epoch4 step31560 [D loss: 0.205083] [G loss: 0.818050]\n",
      "epoch4 step31565 [D loss: -0.404173] [G loss: 1.256859]\n",
      "epoch4 step31570 [D loss: -0.486045] [G loss: 0.884966]\n",
      "epoch4 step31575 [D loss: -0.236279] [G loss: 0.867355]\n",
      "epoch4 step31580 [D loss: 0.360790] [G loss: 1.270098]\n",
      "epoch4 step31585 [D loss: -0.087183] [G loss: 0.726762]\n",
      "epoch4 step31590 [D loss: -0.040778] [G loss: 1.014721]\n",
      "epoch4 step31595 [D loss: -0.487094] [G loss: 1.138910]\n",
      "epoch4 step31600 [D loss: -0.392804] [G loss: 1.267603]\n",
      "epoch4 step31605 [D loss: 0.058840] [G loss: 1.042222]\n",
      "epoch4 step31610 [D loss: -0.081446] [G loss: 1.067589]\n",
      "epoch4 step31615 [D loss: -0.190854] [G loss: 1.072130]\n",
      "epoch4 step31620 [D loss: -0.059518] [G loss: 1.182621]\n",
      "epoch4 step31625 [D loss: 0.313079] [G loss: 1.110665]\n",
      "epoch4 step31630 [D loss: -0.001407] [G loss: 1.026626]\n",
      "epoch4 step31635 [D loss: -0.109854] [G loss: 1.254108]\n",
      "epoch4 step31640 [D loss: -0.518380] [G loss: 1.245179]\n",
      "epoch4 step31645 [D loss: -0.019153] [G loss: 1.262223]\n",
      "epoch4 step31650 [D loss: -0.182075] [G loss: 1.131349]\n",
      "epoch4 step31655 [D loss: -0.419510] [G loss: 1.197377]\n",
      "epoch4 step31660 [D loss: 0.246465] [G loss: 0.849061]\n",
      "epoch4 step31665 [D loss: 0.333478] [G loss: 1.129611]\n",
      "epoch4 step31670 [D loss: 0.064396] [G loss: 0.975428]\n",
      "epoch4 step31675 [D loss: -0.101284] [G loss: 1.007292]\n",
      "epoch4 step31680 [D loss: 0.008999] [G loss: 0.912622]\n",
      "epoch4 step31685 [D loss: -0.213025] [G loss: 1.055701]\n",
      "epoch4 step31690 [D loss: 0.122981] [G loss: 1.166819]\n",
      "epoch4 step31695 [D loss: -0.223756] [G loss: 1.261822]\n",
      "epoch4 step31700 [D loss: -0.204244] [G loss: 1.250441]\n",
      "epoch4 step31705 [D loss: 0.118528] [G loss: 1.250819]\n",
      "epoch4 step31710 [D loss: -0.198430] [G loss: 1.311546]\n",
      "epoch4 step31715 [D loss: -0.255344] [G loss: 1.373014]\n",
      "epoch4 step31720 [D loss: -0.356082] [G loss: 1.507110]\n",
      "epoch4 step31725 [D loss: -0.101931] [G loss: 1.378169]\n",
      "epoch4 step31730 [D loss: -0.229047] [G loss: 1.612864]\n",
      "epoch4 step31735 [D loss: -0.650198] [G loss: 1.558721]\n",
      "epoch4 step31740 [D loss: 0.081172] [G loss: 1.534287]\n",
      "epoch4 step31745 [D loss: -0.254616] [G loss: 1.665163]\n",
      "epoch4 step31750 [D loss: -0.418675] [G loss: 1.424981]\n",
      "epoch4 step31755 [D loss: 0.227528] [G loss: 1.672992]\n",
      "epoch4 step31760 [D loss: -0.102211] [G loss: 1.586359]\n",
      "epoch4 step31765 [D loss: -0.550144] [G loss: 1.819081]\n",
      "epoch4 step31770 [D loss: -0.213516] [G loss: 1.513827]\n",
      "epoch4 step31775 [D loss: -0.327403] [G loss: 1.879812]\n",
      "epoch4 step31780 [D loss: -0.278565] [G loss: 1.925756]\n",
      "epoch4 step31785 [D loss: -0.148350] [G loss: 1.634718]\n",
      "epoch4 step31790 [D loss: -0.371323] [G loss: 1.963252]\n",
      "epoch4 step31795 [D loss: 0.063724] [G loss: 1.573915]\n",
      "epoch4 step31800 [D loss: 0.053230] [G loss: 1.780089]\n",
      "epoch4 step31805 [D loss: 0.186703] [G loss: 1.484665]\n",
      "epoch4 step31810 [D loss: 0.065944] [G loss: 1.532640]\n",
      "epoch4 step31815 [D loss: -0.367889] [G loss: 1.578135]\n",
      "epoch4 step31820 [D loss: -0.097837] [G loss: 1.500656]\n",
      "epoch4 step31825 [D loss: -0.320729] [G loss: 1.317973]\n",
      "epoch4 step31830 [D loss: 0.070032] [G loss: 1.215716]\n",
      "epoch4 step31835 [D loss: -0.371208] [G loss: 1.911425]\n",
      "epoch4 step31840 [D loss: -0.195045] [G loss: 1.376580]\n",
      "epoch4 step31845 [D loss: -0.407786] [G loss: 1.505443]\n",
      "epoch4 step31850 [D loss: -0.085127] [G loss: 1.379427]\n",
      "epoch4 step31855 [D loss: 0.040316] [G loss: 1.550149]\n",
      "epoch4 step31860 [D loss: -0.256252] [G loss: 1.653918]\n",
      "epoch4 step31865 [D loss: -0.124312] [G loss: 1.364030]\n",
      "epoch4 step31870 [D loss: 0.348328] [G loss: 1.348110]\n",
      "epoch4 step31875 [D loss: -0.373381] [G loss: 1.321294]\n",
      "epoch4 step31880 [D loss: -0.028451] [G loss: 1.607456]\n",
      "epoch4 step31885 [D loss: -0.304833] [G loss: 1.258033]\n",
      "epoch4 step31890 [D loss: -0.448293] [G loss: 1.319594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step31895 [D loss: -0.803977] [G loss: 1.442038]\n",
      "epoch4 step31900 [D loss: -0.149926] [G loss: 1.380001]\n",
      "epoch4 step31905 [D loss: -0.613637] [G loss: 1.337434]\n",
      "epoch4 step31910 [D loss: -0.055939] [G loss: 1.433994]\n",
      "epoch4 step31915 [D loss: -0.469345] [G loss: 1.447723]\n",
      "epoch4 step31920 [D loss: -0.091668] [G loss: 1.361229]\n",
      "epoch4 step31925 [D loss: -0.035073] [G loss: 1.072672]\n",
      "epoch4 step31930 [D loss: -0.185796] [G loss: 1.429108]\n",
      "epoch4 step31935 [D loss: -0.044352] [G loss: 1.458923]\n",
      "epoch4 step31940 [D loss: 0.235962] [G loss: 1.460259]\n",
      "epoch4 step31945 [D loss: -0.120443] [G loss: 1.000745]\n",
      "epoch4 step31950 [D loss: 0.233025] [G loss: 1.398021]\n",
      "epoch4 step31955 [D loss: 0.100351] [G loss: 1.240321]\n",
      "epoch4 step31960 [D loss: -0.072492] [G loss: 1.192998]\n",
      "epoch4 step31965 [D loss: 0.007754] [G loss: 0.953885]\n",
      "epoch4 step31970 [D loss: -0.270923] [G loss: 1.327253]\n",
      "epoch4 step31975 [D loss: -0.233526] [G loss: 1.391775]\n",
      "epoch4 step31980 [D loss: -0.259388] [G loss: 1.373150]\n",
      "epoch4 step31985 [D loss: 0.226709] [G loss: 1.222605]\n",
      "epoch4 step31990 [D loss: -0.299605] [G loss: 1.271293]\n",
      "epoch4 step31995 [D loss: -0.539967] [G loss: 1.236816]\n",
      "epoch4 step32000 [D loss: -0.073818] [G loss: 0.926983]\n",
      "epoch4 step32005 [D loss: 0.017896] [G loss: 1.115867]\n",
      "epoch4 step32010 [D loss: 0.081941] [G loss: 1.154252]\n",
      "epoch4 step32015 [D loss: -0.037539] [G loss: 1.184557]\n",
      "epoch4 step32020 [D loss: -0.229213] [G loss: 1.253641]\n",
      "epoch4 step32025 [D loss: 0.148998] [G loss: 1.183857]\n",
      "epoch4 step32030 [D loss: -0.304105] [G loss: 1.183732]\n",
      "epoch4 step32035 [D loss: 0.121590] [G loss: 1.046888]\n",
      "epoch4 step32040 [D loss: -0.291692] [G loss: 1.032062]\n",
      "epoch4 step32045 [D loss: 0.104742] [G loss: 1.056903]\n",
      "epoch4 step32050 [D loss: -0.099808] [G loss: 1.027336]\n",
      "epoch4 step32055 [D loss: -0.187426] [G loss: 1.087481]\n",
      "epoch4 step32060 [D loss: 0.221925] [G loss: 1.034976]\n",
      "epoch4 step32065 [D loss: 0.224900] [G loss: 0.911349]\n",
      "epoch4 step32070 [D loss: 0.096588] [G loss: 1.099015]\n",
      "epoch4 step32075 [D loss: -0.209203] [G loss: 1.249203]\n",
      "epoch4 step32080 [D loss: -0.224537] [G loss: 1.072402]\n",
      "epoch4 step32085 [D loss: 0.133980] [G loss: 1.085335]\n",
      "epoch4 step32090 [D loss: 0.138412] [G loss: 1.063515]\n",
      "epoch4 step32095 [D loss: -0.098031] [G loss: 1.002227]\n",
      "epoch4 step32100 [D loss: -0.415582] [G loss: 0.884196]\n",
      "epoch4 step32105 [D loss: -0.337020] [G loss: 1.100562]\n",
      "epoch4 step32110 [D loss: -0.193857] [G loss: 1.018001]\n",
      "epoch4 step32115 [D loss: 0.170000] [G loss: 0.773186]\n",
      "epoch4 step32120 [D loss: -0.086002] [G loss: 1.029389]\n",
      "epoch4 step32125 [D loss: -0.432256] [G loss: 1.041659]\n",
      "epoch4 step32130 [D loss: -0.171699] [G loss: 0.841179]\n",
      "epoch4 step32135 [D loss: -0.359851] [G loss: 1.001880]\n",
      "epoch4 step32140 [D loss: -0.208584] [G loss: 1.087721]\n",
      "epoch4 step32145 [D loss: -0.195481] [G loss: 1.058511]\n",
      "epoch4 step32150 [D loss: -0.164222] [G loss: 0.673958]\n",
      "epoch4 step32155 [D loss: -0.032105] [G loss: 0.998477]\n",
      "epoch4 step32160 [D loss: -0.511929] [G loss: 0.990464]\n",
      "epoch4 step32165 [D loss: 0.068208] [G loss: 0.811383]\n",
      "epoch4 step32170 [D loss: -0.274204] [G loss: 0.943272]\n",
      "epoch4 step32175 [D loss: -0.112192] [G loss: 0.923953]\n",
      "epoch4 step32180 [D loss: -0.145634] [G loss: 0.983571]\n",
      "epoch4 step32185 [D loss: -0.166175] [G loss: 0.902142]\n",
      "epoch4 step32190 [D loss: -0.185164] [G loss: 1.126908]\n",
      "epoch4 step32195 [D loss: 0.326972] [G loss: 1.099408]\n",
      "epoch4 step32200 [D loss: -0.247680] [G loss: 1.383606]\n",
      "epoch4 step32205 [D loss: -0.026786] [G loss: 0.886344]\n",
      "epoch4 step32210 [D loss: 0.229140] [G loss: 0.901380]\n",
      "epoch4 step32215 [D loss: 0.143818] [G loss: 1.226650]\n",
      "epoch4 step32220 [D loss: -0.285293] [G loss: 1.236573]\n",
      "epoch4 step32225 [D loss: -0.359692] [G loss: 0.923701]\n",
      "epoch4 step32230 [D loss: -0.259408] [G loss: 1.321007]\n",
      "epoch4 step32235 [D loss: 0.496165] [G loss: 0.937700]\n",
      "epoch4 step32240 [D loss: 0.137095] [G loss: 0.994378]\n",
      "epoch4 step32245 [D loss: -0.446634] [G loss: 1.239850]\n",
      "epoch4 step32250 [D loss: 0.055006] [G loss: 1.299770]\n",
      "epoch4 step32255 [D loss: -0.262749] [G loss: 1.394430]\n",
      "epoch4 step32260 [D loss: -0.378149] [G loss: 1.302796]\n",
      "epoch4 step32265 [D loss: 0.020197] [G loss: 1.214291]\n",
      "epoch4 step32270 [D loss: -0.513729] [G loss: 1.208745]\n",
      "epoch4 step32275 [D loss: -0.082780] [G loss: 1.365112]\n",
      "epoch4 step32280 [D loss: 0.096832] [G loss: 1.098379]\n",
      "epoch4 step32285 [D loss: -0.046595] [G loss: 1.021607]\n",
      "epoch4 step32290 [D loss: 0.068768] [G loss: 1.221694]\n",
      "epoch4 step32295 [D loss: -0.097528] [G loss: 1.094889]\n",
      "epoch4 step32300 [D loss: -0.765732] [G loss: 0.775027]\n",
      "epoch4 step32305 [D loss: 0.301878] [G loss: 0.892181]\n",
      "epoch4 step32310 [D loss: -0.069247] [G loss: 1.211292]\n",
      "epoch4 step32315 [D loss: -0.359236] [G loss: 0.866891]\n",
      "epoch4 step32320 [D loss: 0.450475] [G loss: 0.929126]\n",
      "epoch4 step32325 [D loss: -0.194723] [G loss: 0.688423]\n",
      "epoch4 step32330 [D loss: -0.265144] [G loss: 1.392663]\n",
      "epoch4 step32335 [D loss: -0.169279] [G loss: 0.756240]\n",
      "epoch4 step32340 [D loss: 0.087772] [G loss: 0.943484]\n",
      "epoch4 step32345 [D loss: -0.262095] [G loss: 0.939158]\n",
      "epoch4 step32350 [D loss: -0.151115] [G loss: 1.024885]\n",
      "epoch4 step32355 [D loss: -0.171423] [G loss: 0.993376]\n",
      "epoch4 step32360 [D loss: -0.361124] [G loss: 1.220574]\n",
      "epoch4 step32365 [D loss: -0.167116] [G loss: 1.575957]\n",
      "epoch4 step32370 [D loss: -0.471349] [G loss: 1.480078]\n",
      "epoch4 step32375 [D loss: 0.382200] [G loss: 0.956265]\n",
      "epoch4 step32380 [D loss: 0.169837] [G loss: 1.141506]\n",
      "epoch4 step32385 [D loss: 0.219479] [G loss: 1.144073]\n",
      "epoch4 step32390 [D loss: 0.481965] [G loss: 0.842699]\n",
      "epoch4 step32395 [D loss: -0.359738] [G loss: 0.931642]\n",
      "epoch4 step32400 [D loss: -0.148131] [G loss: 1.443376]\n",
      "epoch4 step32405 [D loss: 0.196872] [G loss: 1.057583]\n",
      "epoch4 step32410 [D loss: 0.028752] [G loss: 1.012602]\n",
      "epoch4 step32415 [D loss: -0.329975] [G loss: 0.980201]\n",
      "epoch4 step32420 [D loss: 0.232327] [G loss: 0.979856]\n",
      "epoch4 step32425 [D loss: -0.025983] [G loss: 0.881112]\n",
      "epoch4 step32430 [D loss: 0.027995] [G loss: 1.148074]\n",
      "epoch4 step32435 [D loss: -0.297904] [G loss: 1.044382]\n",
      "epoch4 step32440 [D loss: -0.272539] [G loss: 0.958979]\n",
      "epoch4 step32445 [D loss: -0.219306] [G loss: 0.848939]\n",
      "epoch4 step32450 [D loss: -0.392379] [G loss: 0.883912]\n",
      "epoch4 step32455 [D loss: -0.191676] [G loss: 0.780949]\n",
      "epoch4 step32460 [D loss: -0.462006] [G loss: 0.509464]\n",
      "epoch4 step32465 [D loss: -0.027438] [G loss: 0.717047]\n",
      "epoch4 step32470 [D loss: -0.358794] [G loss: 0.746547]\n",
      "epoch4 step32475 [D loss: -0.132080] [G loss: 1.036858]\n",
      "epoch4 step32480 [D loss: 0.227259] [G loss: 0.355628]\n",
      "epoch4 step32485 [D loss: -0.011780] [G loss: 0.713997]\n",
      "epoch4 step32490 [D loss: -0.115533] [G loss: 0.657043]\n",
      "epoch4 step32495 [D loss: 0.054630] [G loss: 0.642406]\n",
      "epoch4 step32500 [D loss: -0.053234] [G loss: 0.910007]\n",
      "epoch4 step32505 [D loss: -0.165330] [G loss: 0.782384]\n",
      "epoch4 step32510 [D loss: -0.037716] [G loss: 0.910784]\n",
      "epoch4 step32515 [D loss: -0.260975] [G loss: 0.823240]\n",
      "epoch4 step32520 [D loss: -0.197020] [G loss: 0.427916]\n",
      "epoch4 step32525 [D loss: -0.131474] [G loss: 0.746194]\n",
      "epoch4 step32530 [D loss: -0.125459] [G loss: 0.219856]\n",
      "epoch4 step32535 [D loss: -0.803940] [G loss: 0.793904]\n",
      "epoch4 step32540 [D loss: 0.240268] [G loss: 0.412722]\n",
      "epoch4 step32545 [D loss: -0.284791] [G loss: 0.790781]\n",
      "epoch4 step32550 [D loss: -0.039933] [G loss: 0.654810]\n",
      "epoch4 step32555 [D loss: -0.055753] [G loss: 0.714323]\n",
      "epoch4 step32560 [D loss: -0.487800] [G loss: 0.680793]\n",
      "epoch4 step32565 [D loss: 0.083691] [G loss: 0.721593]\n",
      "epoch4 step32570 [D loss: -0.153143] [G loss: 0.795294]\n",
      "epoch4 step32575 [D loss: 0.085889] [G loss: 0.776867]\n",
      "epoch4 step32580 [D loss: 0.361546] [G loss: 0.964703]\n",
      "epoch4 step32585 [D loss: 0.006779] [G loss: 0.288996]\n",
      "epoch4 step32590 [D loss: -0.545761] [G loss: 0.894070]\n",
      "epoch4 step32595 [D loss: -0.399450] [G loss: 0.930789]\n",
      "epoch4 step32600 [D loss: -0.005420] [G loss: 0.941637]\n",
      "epoch4 step32605 [D loss: -0.205497] [G loss: 0.533622]\n",
      "epoch4 step32610 [D loss: -0.040548] [G loss: 0.899069]\n",
      "epoch4 step32615 [D loss: -0.054478] [G loss: 0.589397]\n",
      "epoch4 step32620 [D loss: 0.074185] [G loss: 0.779279]\n",
      "epoch4 step32625 [D loss: 0.004467] [G loss: 0.761081]\n",
      "epoch4 step32630 [D loss: 0.211961] [G loss: 1.189344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step32635 [D loss: 0.157337] [G loss: 0.954984]\n",
      "epoch4 step32640 [D loss: -0.014878] [G loss: 0.903561]\n",
      "epoch4 step32645 [D loss: 0.092360] [G loss: 1.056424]\n",
      "epoch4 step32650 [D loss: -0.621684] [G loss: 1.273156]\n",
      "epoch4 step32655 [D loss: 0.308889] [G loss: 0.909918]\n",
      "epoch4 step32660 [D loss: -0.381465] [G loss: 1.032458]\n",
      "epoch4 step32665 [D loss: -0.222819] [G loss: 1.079007]\n",
      "epoch4 step32670 [D loss: -0.012300] [G loss: 1.116051]\n",
      "epoch4 step32675 [D loss: 0.057501] [G loss: 1.160677]\n",
      "epoch4 step32680 [D loss: 0.236965] [G loss: 0.950282]\n",
      "epoch4 step32685 [D loss: -0.016383] [G loss: 0.931824]\n",
      "epoch4 step32690 [D loss: 0.084563] [G loss: 0.985367]\n",
      "epoch4 step32695 [D loss: 0.038981] [G loss: 1.109386]\n",
      "epoch4 step32700 [D loss: -0.059946] [G loss: 1.298029]\n",
      "epoch4 step32705 [D loss: -0.467090] [G loss: 1.275977]\n",
      "epoch4 step32710 [D loss: -0.144560] [G loss: 1.017174]\n",
      "epoch4 step32715 [D loss: -0.253557] [G loss: 1.217534]\n",
      "epoch4 step32720 [D loss: 0.046167] [G loss: 1.120755]\n",
      "epoch4 step32725 [D loss: 0.213712] [G loss: 1.120894]\n",
      "epoch4 step32730 [D loss: -0.396956] [G loss: 1.091656]\n",
      "epoch4 step32735 [D loss: 0.161517] [G loss: 1.099590]\n",
      "epoch4 step32740 [D loss: -0.174286] [G loss: 1.058412]\n",
      "epoch4 step32745 [D loss: -0.426844] [G loss: 1.596018]\n",
      "epoch4 step32750 [D loss: -0.351855] [G loss: 1.248065]\n",
      "epoch4 step32755 [D loss: -0.111481] [G loss: 1.359583]\n",
      "epoch4 step32760 [D loss: -0.256845] [G loss: 1.351083]\n",
      "epoch4 step32765 [D loss: -0.185634] [G loss: 1.595953]\n",
      "epoch4 step32770 [D loss: 0.209986] [G loss: 1.627226]\n",
      "epoch4 step32775 [D loss: -0.212625] [G loss: 1.500229]\n",
      "epoch4 step32780 [D loss: -0.596141] [G loss: 1.598572]\n",
      "epoch4 step32785 [D loss: -0.710717] [G loss: 1.715078]\n",
      "epoch4 step32790 [D loss: -0.214133] [G loss: 1.557064]\n",
      "epoch4 step32795 [D loss: -0.615158] [G loss: 1.412911]\n",
      "epoch4 step32800 [D loss: -0.033433] [G loss: 1.612761]\n",
      "epoch4 step32805 [D loss: -0.039768] [G loss: 1.781194]\n",
      "epoch4 step32810 [D loss: 0.282894] [G loss: 1.477173]\n",
      "epoch4 step32815 [D loss: -0.072833] [G loss: 1.270042]\n",
      "epoch4 step32820 [D loss: -0.197760] [G loss: 1.599758]\n",
      "epoch4 step32825 [D loss: -0.132440] [G loss: 1.605961]\n",
      "epoch4 step32830 [D loss: -0.421380] [G loss: 1.502748]\n",
      "epoch4 step32835 [D loss: -0.026568] [G loss: 1.618202]\n",
      "epoch4 step32840 [D loss: -0.294207] [G loss: 1.515194]\n",
      "epoch4 step32845 [D loss: -0.256834] [G loss: 1.701781]\n",
      "epoch4 step32850 [D loss: -0.021487] [G loss: 1.431170]\n",
      "epoch4 step32855 [D loss: -0.255137] [G loss: 1.514932]\n",
      "epoch4 step32860 [D loss: 0.070859] [G loss: 1.538399]\n",
      "epoch4 step32865 [D loss: 0.097268] [G loss: 1.293732]\n",
      "epoch4 step32870 [D loss: -0.036817] [G loss: 1.611427]\n",
      "epoch4 step32875 [D loss: -0.144016] [G loss: 1.373201]\n",
      "epoch4 step32880 [D loss: 0.369813] [G loss: 1.493711]\n",
      "epoch4 step32885 [D loss: -0.037555] [G loss: 1.378705]\n",
      "epoch4 step32890 [D loss: -0.055964] [G loss: 1.745783]\n",
      "epoch4 step32895 [D loss: -0.612745] [G loss: 1.602746]\n",
      "epoch4 step32900 [D loss: -0.132737] [G loss: 1.752709]\n",
      "epoch4 step32905 [D loss: 0.034482] [G loss: 1.611022]\n",
      "epoch4 step32910 [D loss: -0.371983] [G loss: 1.706560]\n",
      "epoch4 step32915 [D loss: -0.058198] [G loss: 1.262305]\n",
      "epoch4 step32920 [D loss: 0.095663] [G loss: 1.283657]\n",
      "epoch4 step32925 [D loss: -0.482752] [G loss: 1.660742]\n",
      "epoch4 step32930 [D loss: -0.027472] [G loss: 1.643702]\n",
      "epoch4 step32935 [D loss: -0.403895] [G loss: 1.403680]\n",
      "epoch4 step32940 [D loss: -0.631912] [G loss: 1.661434]\n",
      "epoch4 step32945 [D loss: 0.014226] [G loss: 1.228512]\n",
      "epoch4 step32950 [D loss: -0.133594] [G loss: 1.384805]\n",
      "epoch4 step32955 [D loss: 0.396513] [G loss: 1.196386]\n",
      "epoch4 step32960 [D loss: 0.058847] [G loss: 1.472309]\n",
      "epoch4 step32965 [D loss: -0.256705] [G loss: 1.214699]\n",
      "epoch4 step32970 [D loss: 0.391086] [G loss: 1.384516]\n",
      "epoch4 step32975 [D loss: -0.014824] [G loss: 1.443118]\n",
      "epoch4 step32980 [D loss: 0.017458] [G loss: 1.519225]\n",
      "epoch4 step32985 [D loss: 0.122129] [G loss: 1.407906]\n",
      "epoch4 step32990 [D loss: 0.083069] [G loss: 1.458045]\n",
      "epoch4 step32995 [D loss: -0.104896] [G loss: 1.236860]\n",
      "epoch4 step33000 [D loss: 0.253934] [G loss: 1.201820]\n",
      "epoch4 step33005 [D loss: 0.000764] [G loss: 1.245542]\n",
      "epoch4 step33010 [D loss: 0.053278] [G loss: 1.221268]\n",
      "epoch4 step33015 [D loss: -0.152903] [G loss: 1.228722]\n",
      "epoch4 step33020 [D loss: -0.212546] [G loss: 1.390309]\n",
      "epoch4 step33025 [D loss: -0.318170] [G loss: 1.588442]\n",
      "epoch4 step33030 [D loss: 0.565320] [G loss: 0.846618]\n",
      "epoch4 step33035 [D loss: -0.241364] [G loss: 1.352950]\n",
      "epoch4 step33040 [D loss: 0.071057] [G loss: 1.252004]\n",
      "epoch4 step33045 [D loss: -0.143687] [G loss: 0.769061]\n",
      "epoch4 step33050 [D loss: -0.101899] [G loss: 0.980595]\n",
      "epoch4 step33055 [D loss: -0.199046] [G loss: 0.858521]\n",
      "epoch4 step33060 [D loss: -0.269074] [G loss: 0.941870]\n",
      "epoch4 step33065 [D loss: -0.195382] [G loss: 0.582974]\n",
      "epoch4 step33070 [D loss: -0.017991] [G loss: 0.273878]\n",
      "epoch4 step33075 [D loss: -0.196458] [G loss: 0.700509]\n",
      "epoch4 step33080 [D loss: 0.400011] [G loss: 0.685706]\n",
      "epoch4 step33085 [D loss: -0.231178] [G loss: 0.524456]\n",
      "epoch4 step33090 [D loss: -0.049174] [G loss: 0.664676]\n",
      "epoch4 step33095 [D loss: -0.069611] [G loss: 0.544952]\n",
      "epoch4 step33100 [D loss: -0.171488] [G loss: 0.544449]\n",
      "epoch4 step33105 [D loss: -0.344335] [G loss: 0.455416]\n",
      "epoch4 step33110 [D loss: -0.078963] [G loss: 0.864091]\n",
      "epoch4 step33115 [D loss: -0.170017] [G loss: 0.831079]\n",
      "epoch4 step33120 [D loss: -0.266185] [G loss: 0.629369]\n",
      "epoch4 step33125 [D loss: -0.521055] [G loss: 0.865896]\n",
      "epoch4 step33130 [D loss: -0.373956] [G loss: 0.588933]\n",
      "epoch4 step33135 [D loss: -0.689603] [G loss: 0.815839]\n",
      "epoch4 step33140 [D loss: -0.143224] [G loss: 0.905334]\n",
      "epoch4 step33145 [D loss: -0.139709] [G loss: 0.673938]\n",
      "epoch4 step33150 [D loss: -0.064762] [G loss: 0.505207]\n",
      "epoch4 step33155 [D loss: -0.017474] [G loss: 0.628360]\n",
      "epoch4 step33160 [D loss: -0.625502] [G loss: 0.868988]\n",
      "epoch4 step33165 [D loss: 0.242905] [G loss: 0.666416]\n",
      "epoch4 step33170 [D loss: -0.137704] [G loss: 0.777751]\n",
      "epoch4 step33175 [D loss: 0.090964] [G loss: 0.850635]\n",
      "epoch4 step33180 [D loss: -0.137067] [G loss: 1.080836]\n",
      "epoch4 step33185 [D loss: -0.521909] [G loss: 0.909987]\n",
      "epoch4 step33190 [D loss: 0.263260] [G loss: 0.894879]\n",
      "epoch4 step33195 [D loss: 0.081102] [G loss: 1.171668]\n",
      "epoch4 step33200 [D loss: -0.588569] [G loss: 1.126810]\n",
      "epoch4 step33205 [D loss: -0.377602] [G loss: 1.418700]\n",
      "epoch4 step33210 [D loss: 0.086055] [G loss: 1.256869]\n",
      "epoch4 step33215 [D loss: -0.068702] [G loss: 1.406937]\n",
      "epoch4 step33220 [D loss: -0.300832] [G loss: 1.365215]\n",
      "epoch4 step33225 [D loss: 0.220902] [G loss: 1.230947]\n",
      "epoch4 step33230 [D loss: -0.081460] [G loss: 1.231524]\n",
      "epoch4 step33235 [D loss: 0.496358] [G loss: 1.389140]\n",
      "epoch4 step33240 [D loss: 0.221544] [G loss: 1.460547]\n",
      "epoch4 step33245 [D loss: -0.460902] [G loss: 1.165112]\n",
      "epoch4 step33250 [D loss: -0.171317] [G loss: 1.653663]\n",
      "epoch4 step33255 [D loss: -0.157049] [G loss: 1.077152]\n",
      "epoch4 step33260 [D loss: 0.050799] [G loss: 1.291329]\n",
      "epoch4 step33265 [D loss: -0.088278] [G loss: 1.945630]\n",
      "epoch4 step33270 [D loss: 0.236300] [G loss: 1.442356]\n",
      "epoch4 step33275 [D loss: -0.328826] [G loss: 1.823611]\n",
      "epoch4 step33280 [D loss: -0.386472] [G loss: 1.677213]\n",
      "epoch4 step33285 [D loss: -0.490870] [G loss: 2.385208]\n",
      "epoch4 step33290 [D loss: -0.143430] [G loss: 1.975785]\n",
      "epoch4 step33295 [D loss: -0.477623] [G loss: 2.025069]\n",
      "epoch4 step33300 [D loss: 0.226510] [G loss: 1.625988]\n",
      "epoch4 step33305 [D loss: -0.491586] [G loss: 1.923896]\n",
      "epoch4 step33310 [D loss: -0.175948] [G loss: 1.937460]\n",
      "epoch4 step33315 [D loss: 0.092847] [G loss: 2.346834]\n",
      "epoch4 step33320 [D loss: -0.041615] [G loss: 1.679850]\n",
      "epoch4 step33325 [D loss: -0.417493] [G loss: 2.383710]\n",
      "epoch4 step33330 [D loss: -0.021013] [G loss: 1.951634]\n",
      "epoch4 step33335 [D loss: 0.366280] [G loss: 2.139119]\n",
      "epoch4 step33340 [D loss: 0.482932] [G loss: 1.896364]\n",
      "epoch4 step33345 [D loss: 0.017333] [G loss: 2.090246]\n",
      "epoch4 step33350 [D loss: 0.064521] [G loss: 2.109444]\n",
      "epoch4 step33355 [D loss: 0.149317] [G loss: 2.220014]\n",
      "epoch4 step33360 [D loss: -0.622434] [G loss: 2.258291]\n",
      "epoch4 step33365 [D loss: -0.022687] [G loss: 1.917989]\n",
      "epoch4 step33370 [D loss: -0.192794] [G loss: 2.333647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step33375 [D loss: -0.209443] [G loss: 2.315510]\n",
      "epoch4 step33380 [D loss: -0.207753] [G loss: 2.203169]\n",
      "epoch4 step33385 [D loss: 0.051366] [G loss: 2.044296]\n",
      "epoch4 step33390 [D loss: 0.028090] [G loss: 2.076331]\n",
      "epoch4 step33395 [D loss: 0.577300] [G loss: 2.163620]\n",
      "epoch4 step33400 [D loss: 0.096059] [G loss: 1.532699]\n",
      "epoch4 step33405 [D loss: -0.573686] [G loss: 1.891919]\n",
      "epoch4 step33410 [D loss: -0.086791] [G loss: 2.075466]\n",
      "epoch4 step33415 [D loss: -0.016981] [G loss: 1.617549]\n",
      "epoch4 step33420 [D loss: 0.411389] [G loss: 2.243605]\n",
      "epoch4 step33425 [D loss: -0.492068] [G loss: 1.898305]\n",
      "epoch4 step33430 [D loss: -0.155028] [G loss: 1.719755]\n",
      "epoch4 step33435 [D loss: 0.192932] [G loss: 1.715218]\n",
      "epoch4 step33440 [D loss: -0.244418] [G loss: 1.521636]\n",
      "epoch4 step33445 [D loss: -0.323309] [G loss: 1.564298]\n",
      "epoch4 step33450 [D loss: -0.118672] [G loss: 1.575016]\n",
      "epoch4 step33455 [D loss: 0.052971] [G loss: 1.566661]\n",
      "epoch4 step33460 [D loss: 0.124973] [G loss: 1.673731]\n",
      "epoch4 step33465 [D loss: -0.173028] [G loss: 1.375009]\n",
      "epoch4 step33470 [D loss: 0.290523] [G loss: 1.241457]\n",
      "epoch4 step33475 [D loss: 0.334577] [G loss: 1.160509]\n",
      "epoch4 step33480 [D loss: -0.177247] [G loss: 1.604846]\n",
      "epoch4 step33485 [D loss: 0.166344] [G loss: 1.416266]\n",
      "epoch4 step33490 [D loss: -0.259785] [G loss: 1.472903]\n",
      "epoch4 step33495 [D loss: -0.626655] [G loss: 1.418217]\n",
      "epoch4 step33500 [D loss: -0.123136] [G loss: 1.160078]\n",
      "epoch4 step33505 [D loss: 0.229220] [G loss: 1.077719]\n",
      "epoch4 step33510 [D loss: -0.102054] [G loss: 1.073750]\n",
      "epoch4 step33515 [D loss: -0.232731] [G loss: 1.396870]\n",
      "epoch4 step33520 [D loss: 0.065520] [G loss: 1.039369]\n",
      "epoch4 step33525 [D loss: 0.281409] [G loss: 0.920521]\n",
      "epoch4 step33530 [D loss: 0.260884] [G loss: 1.087530]\n",
      "epoch4 step33535 [D loss: 0.159271] [G loss: 1.182102]\n",
      "epoch4 step33540 [D loss: -0.153587] [G loss: 1.127777]\n",
      "epoch4 step33545 [D loss: -0.170537] [G loss: 1.348687]\n",
      "epoch4 step33550 [D loss: -0.392089] [G loss: 1.133336]\n",
      "epoch4 step33555 [D loss: -0.147022] [G loss: 1.110017]\n",
      "epoch4 step33560 [D loss: -0.459152] [G loss: 0.831478]\n",
      "epoch4 step33565 [D loss: 0.088889] [G loss: 0.869993]\n",
      "epoch4 step33570 [D loss: -0.048476] [G loss: 1.060640]\n",
      "epoch4 step33575 [D loss: -0.119814] [G loss: 0.934005]\n",
      "epoch4 step33580 [D loss: -0.156716] [G loss: 1.079811]\n",
      "epoch4 step33585 [D loss: -0.151582] [G loss: 0.926069]\n",
      "epoch4 step33590 [D loss: -0.138856] [G loss: 0.819022]\n",
      "epoch4 step33595 [D loss: 0.215563] [G loss: 0.886238]\n",
      "epoch4 step33600 [D loss: -0.171583] [G loss: 1.163254]\n",
      "epoch4 step33605 [D loss: -0.577959] [G loss: 1.101095]\n",
      "epoch4 step33610 [D loss: -0.103232] [G loss: 0.799573]\n",
      "epoch4 step33615 [D loss: -0.142747] [G loss: 0.649553]\n",
      "epoch4 step33620 [D loss: 0.196229] [G loss: 0.951018]\n",
      "epoch4 step33625 [D loss: 0.046231] [G loss: 0.722730]\n",
      "epoch4 step33630 [D loss: -0.164361] [G loss: 0.553197]\n",
      "epoch4 step33635 [D loss: 0.086679] [G loss: 0.714091]\n",
      "epoch4 step33640 [D loss: 0.416893] [G loss: 0.899194]\n",
      "epoch4 step33645 [D loss: -0.629597] [G loss: 0.861051]\n",
      "epoch4 step33650 [D loss: -0.093902] [G loss: 0.738539]\n",
      "epoch4 step33655 [D loss: -0.264970] [G loss: 0.525112]\n",
      "epoch4 step33660 [D loss: 0.043672] [G loss: 0.809830]\n",
      "epoch4 step33665 [D loss: 0.138001] [G loss: 0.755792]\n",
      "epoch4 step33670 [D loss: -0.359665] [G loss: 0.928154]\n",
      "epoch4 step33675 [D loss: 0.021485] [G loss: 0.900401]\n",
      "epoch4 step33680 [D loss: 0.051293] [G loss: 0.780366]\n",
      "epoch4 step33685 [D loss: 0.023147] [G loss: 0.828077]\n",
      "epoch4 step33690 [D loss: -0.104260] [G loss: 1.037658]\n",
      "epoch4 step33695 [D loss: -0.047853] [G loss: 1.013445]\n",
      "epoch4 step33700 [D loss: 0.207632] [G loss: 0.902508]\n",
      "epoch4 step33705 [D loss: -0.714450] [G loss: 1.248294]\n",
      "epoch4 step33710 [D loss: -0.282653] [G loss: 1.382008]\n",
      "epoch4 step33715 [D loss: 0.163208] [G loss: 1.005873]\n",
      "epoch4 step33720 [D loss: -0.055368] [G loss: 1.202577]\n",
      "epoch4 step33725 [D loss: -0.671002] [G loss: 1.407793]\n",
      "epoch4 step33730 [D loss: 0.092748] [G loss: 1.369246]\n",
      "epoch4 step33735 [D loss: -0.309373] [G loss: 1.056821]\n",
      "epoch4 step33740 [D loss: -0.081411] [G loss: 1.170702]\n",
      "epoch4 step33745 [D loss: -0.043569] [G loss: 1.197977]\n",
      "epoch4 step33750 [D loss: -0.186361] [G loss: 1.288261]\n",
      "epoch4 step33755 [D loss: -0.298606] [G loss: 1.326684]\n",
      "epoch4 step33760 [D loss: -0.344614] [G loss: 1.142753]\n",
      "epoch4 step33765 [D loss: -0.187066] [G loss: 0.704703]\n",
      "epoch4 step33770 [D loss: -0.807538] [G loss: 1.311169]\n",
      "epoch4 step33775 [D loss: -0.130006] [G loss: 0.907335]\n",
      "epoch4 step33780 [D loss: 0.033019] [G loss: 1.227089]\n",
      "epoch4 step33785 [D loss: -0.003701] [G loss: 1.265258]\n",
      "epoch4 step33790 [D loss: -0.110041] [G loss: 1.025964]\n",
      "epoch4 step33795 [D loss: -0.408637] [G loss: 1.029856]\n",
      "epoch4 step33800 [D loss: 0.070947] [G loss: 1.055831]\n",
      "epoch4 step33805 [D loss: -0.243868] [G loss: 1.097008]\n",
      "epoch4 step33810 [D loss: -0.418220] [G loss: 0.965405]\n",
      "epoch4 step33815 [D loss: -0.068313] [G loss: 0.736429]\n",
      "epoch4 step33820 [D loss: 0.066729] [G loss: 0.674209]\n",
      "epoch4 step33825 [D loss: -0.785048] [G loss: 0.954586]\n",
      "epoch4 step33830 [D loss: -0.010672] [G loss: 1.000573]\n",
      "epoch4 step33835 [D loss: -0.106807] [G loss: 0.866009]\n",
      "epoch4 step33840 [D loss: -0.117659] [G loss: 1.126955]\n",
      "epoch4 step33845 [D loss: -0.391635] [G loss: 0.571115]\n",
      "epoch4 step33850 [D loss: -0.119197] [G loss: 1.136453]\n",
      "epoch4 step33855 [D loss: -0.287860] [G loss: 0.914057]\n",
      "epoch4 step33860 [D loss: 0.053618] [G loss: 0.922702]\n",
      "epoch4 step33865 [D loss: 0.054347] [G loss: 1.331962]\n",
      "epoch4 step33870 [D loss: -0.239858] [G loss: 0.965912]\n",
      "epoch4 step33875 [D loss: -0.156360] [G loss: 1.136460]\n",
      "epoch4 step33880 [D loss: -0.170076] [G loss: 0.956432]\n",
      "epoch4 step33885 [D loss: -0.138954] [G loss: 0.987375]\n",
      "epoch4 step33890 [D loss: 0.018952] [G loss: 1.101978]\n",
      "epoch4 step33895 [D loss: -0.387466] [G loss: 1.329159]\n",
      "epoch4 step33900 [D loss: -0.273683] [G loss: 0.858606]\n",
      "epoch4 step33905 [D loss: -0.364155] [G loss: 0.894289]\n",
      "epoch4 step33910 [D loss: -0.362266] [G loss: 0.642723]\n",
      "epoch4 step33915 [D loss: -0.176942] [G loss: 0.909240]\n",
      "epoch4 step33920 [D loss: -0.223008] [G loss: 0.918319]\n",
      "epoch4 step33925 [D loss: -0.127077] [G loss: 1.168933]\n",
      "epoch4 step33930 [D loss: -0.516229] [G loss: 0.550581]\n",
      "epoch4 step33935 [D loss: -0.362489] [G loss: 0.782646]\n",
      "epoch4 step33940 [D loss: -0.432985] [G loss: 0.724392]\n",
      "epoch4 step33945 [D loss: -0.416051] [G loss: 0.593565]\n",
      "epoch4 step33950 [D loss: -0.336613] [G loss: 0.930501]\n",
      "epoch4 step33955 [D loss: -0.548983] [G loss: 0.407299]\n",
      "epoch4 step33960 [D loss: -0.086916] [G loss: 0.507822]\n",
      "epoch4 step33965 [D loss: -0.388342] [G loss: 1.307527]\n",
      "epoch4 step33970 [D loss: -0.097300] [G loss: 0.834922]\n",
      "epoch4 step33975 [D loss: 0.093000] [G loss: 0.792346]\n",
      "epoch4 step33980 [D loss: -0.350053] [G loss: 0.899217]\n",
      "epoch4 step33985 [D loss: -0.053193] [G loss: 0.953800]\n",
      "epoch4 step33990 [D loss: -0.216668] [G loss: 0.898917]\n",
      "epoch4 step33995 [D loss: -0.692330] [G loss: 0.904840]\n",
      "epoch4 step34000 [D loss: 0.215044] [G loss: 1.182452]\n",
      "epoch4 step34005 [D loss: -0.386627] [G loss: 1.085996]\n",
      "epoch4 step34010 [D loss: 0.091959] [G loss: 0.842981]\n",
      "epoch4 step34015 [D loss: -0.488061] [G loss: 1.080773]\n",
      "epoch4 step34020 [D loss: 0.300092] [G loss: 1.259134]\n",
      "epoch4 step34025 [D loss: 0.232746] [G loss: 1.426062]\n",
      "epoch4 step34030 [D loss: 0.072585] [G loss: 1.437823]\n",
      "epoch4 step34035 [D loss: -0.018927] [G loss: 1.202698]\n",
      "epoch4 step34040 [D loss: -0.202400] [G loss: 1.467816]\n",
      "epoch4 step34045 [D loss: -0.294216] [G loss: 1.654449]\n",
      "epoch4 step34050 [D loss: -0.281938] [G loss: 1.658259]\n",
      "epoch4 step34055 [D loss: 0.106887] [G loss: 1.697037]\n",
      "epoch4 step34060 [D loss: -0.155944] [G loss: 1.712971]\n",
      "epoch4 step34065 [D loss: -0.172333] [G loss: 1.930593]\n",
      "epoch4 step34070 [D loss: 0.125791] [G loss: 1.932452]\n",
      "epoch4 step34075 [D loss: -0.036916] [G loss: 1.699661]\n",
      "epoch4 step34080 [D loss: 0.181635] [G loss: 1.589744]\n",
      "epoch4 step34085 [D loss: -0.272806] [G loss: 1.900478]\n",
      "epoch4 step34090 [D loss: -0.378535] [G loss: 2.043452]\n",
      "epoch4 step34095 [D loss: 0.166257] [G loss: 2.076374]\n",
      "epoch4 step34100 [D loss: -0.187562] [G loss: 2.029361]\n",
      "epoch4 step34105 [D loss: 0.143670] [G loss: 1.942068]\n",
      "epoch4 step34110 [D loss: -0.107670] [G loss: 1.514170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step34115 [D loss: 0.155988] [G loss: 2.037706]\n",
      "epoch4 step34120 [D loss: 0.227356] [G loss: 2.112308]\n",
      "epoch4 step34125 [D loss: 0.218575] [G loss: 1.795271]\n",
      "epoch4 step34130 [D loss: -0.070874] [G loss: 1.836344]\n",
      "epoch4 step34135 [D loss: -0.500707] [G loss: 1.977349]\n",
      "epoch4 step34140 [D loss: 0.078584] [G loss: 1.842562]\n",
      "epoch4 step34145 [D loss: 0.212776] [G loss: 1.645920]\n",
      "epoch4 step34150 [D loss: -0.084335] [G loss: 1.324965]\n",
      "epoch4 step34155 [D loss: -0.260092] [G loss: 1.659268]\n",
      "epoch4 step34160 [D loss: -0.525700] [G loss: 1.470599]\n",
      "epoch4 step34165 [D loss: -0.027466] [G loss: 1.540093]\n",
      "epoch4 step34170 [D loss: 0.053124] [G loss: 1.187976]\n",
      "epoch4 step34175 [D loss: -0.293308] [G loss: 1.249194]\n",
      "epoch4 step34180 [D loss: 0.012275] [G loss: 1.202865]\n",
      "epoch4 step34185 [D loss: 0.298550] [G loss: 1.344635]\n",
      "epoch4 step34190 [D loss: -0.239963] [G loss: 1.046302]\n",
      "epoch4 step34195 [D loss: -0.192271] [G loss: 1.088864]\n",
      "epoch4 step34200 [D loss: 0.334179] [G loss: 1.240093]\n",
      "epoch4 step34205 [D loss: -0.376521] [G loss: 1.571754]\n",
      "epoch4 step34210 [D loss: -0.482044] [G loss: 1.730263]\n",
      "epoch4 step34215 [D loss: -0.660777] [G loss: 1.095160]\n",
      "epoch4 step34220 [D loss: -0.167757] [G loss: 1.085375]\n",
      "epoch4 step34225 [D loss: -0.428477] [G loss: 0.998420]\n",
      "epoch4 step34230 [D loss: -0.263937] [G loss: 0.945374]\n",
      "epoch4 step34235 [D loss: 0.007306] [G loss: 0.808482]\n",
      "epoch4 step34240 [D loss: 0.111315] [G loss: 0.978614]\n",
      "epoch4 step34245 [D loss: -0.068018] [G loss: 1.197987]\n",
      "epoch4 step34250 [D loss: -0.008374] [G loss: 0.875676]\n",
      "epoch4 step34255 [D loss: -0.031681] [G loss: 0.974962]\n",
      "epoch4 step34260 [D loss: -0.330162] [G loss: 0.888959]\n",
      "epoch4 step34265 [D loss: 0.074083] [G loss: 0.774707]\n",
      "epoch4 step34270 [D loss: -0.097450] [G loss: 0.648287]\n",
      "epoch4 step34275 [D loss: 0.299240] [G loss: 0.866681]\n",
      "epoch4 step34280 [D loss: -0.155724] [G loss: 0.465000]\n",
      "epoch4 step34285 [D loss: -0.554901] [G loss: 0.788907]\n",
      "epoch4 step34290 [D loss: -0.076022] [G loss: 0.421683]\n",
      "epoch4 step34295 [D loss: -0.211732] [G loss: 0.299414]\n",
      "epoch4 step34300 [D loss: -0.106119] [G loss: 0.526972]\n",
      "epoch4 step34305 [D loss: -0.390109] [G loss: 0.816283]\n",
      "epoch4 step34310 [D loss: -0.037930] [G loss: 0.300574]\n",
      "epoch4 step34315 [D loss: -0.069079] [G loss: 0.276068]\n",
      "epoch4 step34320 [D loss: -0.326325] [G loss: 0.377623]\n",
      "epoch4 step34325 [D loss: -0.459489] [G loss: 0.390203]\n",
      "epoch4 step34330 [D loss: 0.277805] [G loss: 0.429071]\n",
      "epoch4 step34335 [D loss: -0.131526] [G loss: 0.151789]\n",
      "epoch4 step34340 [D loss: -0.341557] [G loss: 0.796440]\n",
      "epoch4 step34345 [D loss: -0.496198] [G loss: 0.141599]\n",
      "epoch4 step34350 [D loss: -0.394896] [G loss: 0.401459]\n",
      "epoch4 step34355 [D loss: -0.418789] [G loss: 0.516110]\n",
      "epoch4 step34360 [D loss: 0.305789] [G loss: 0.583474]\n",
      "epoch4 step34365 [D loss: -0.181567] [G loss: 0.694179]\n",
      "epoch4 step34370 [D loss: -0.541525] [G loss: 0.918021]\n",
      "epoch4 step34375 [D loss: -0.007784] [G loss: 1.203423]\n",
      "epoch4 step34380 [D loss: 0.081934] [G loss: 1.047030]\n",
      "epoch4 step34385 [D loss: -0.101004] [G loss: 1.268078]\n",
      "epoch4 step34390 [D loss: -0.548343] [G loss: 1.135478]\n",
      "epoch4 step34395 [D loss: -0.403343] [G loss: 1.500946]\n",
      "epoch4 step34400 [D loss: -0.078861] [G loss: 1.171880]\n",
      "epoch4 step34405 [D loss: -0.413922] [G loss: 1.138120]\n",
      "epoch4 step34410 [D loss: -0.788592] [G loss: 1.533873]\n",
      "epoch4 step34415 [D loss: -0.142175] [G loss: 1.584119]\n",
      "epoch4 step34420 [D loss: -0.401321] [G loss: 1.430072]\n",
      "epoch4 step34425 [D loss: -0.224079] [G loss: 1.859922]\n",
      "epoch4 step34430 [D loss: 0.370871] [G loss: 1.059023]\n",
      "epoch4 step34435 [D loss: -0.147001] [G loss: 1.611767]\n",
      "epoch4 step34440 [D loss: 0.300086] [G loss: 1.312557]\n",
      "epoch4 step34445 [D loss: -0.547064] [G loss: 1.462398]\n",
      "epoch4 step34450 [D loss: -0.354191] [G loss: 1.574141]\n",
      "epoch4 step34455 [D loss: -0.086714] [G loss: 1.673012]\n",
      "epoch4 step34460 [D loss: -0.412529] [G loss: 2.083361]\n",
      "epoch4 step34465 [D loss: -0.048894] [G loss: 1.766092]\n",
      "epoch4 step34470 [D loss: -0.344461] [G loss: 1.783251]\n",
      "epoch4 step34475 [D loss: 0.160730] [G loss: 1.747461]\n",
      "epoch4 step34480 [D loss: -0.045610] [G loss: 1.638373]\n",
      "epoch4 step34485 [D loss: 0.186956] [G loss: 1.502804]\n",
      "epoch4 step34490 [D loss: -0.000662] [G loss: 1.321895]\n",
      "epoch4 step34495 [D loss: 0.206831] [G loss: 1.535534]\n",
      "epoch4 step34500 [D loss: 0.330476] [G loss: 1.370414]\n",
      "epoch4 step34505 [D loss: 0.256109] [G loss: 1.485846]\n",
      "epoch4 step34510 [D loss: 0.293249] [G loss: 1.310318]\n",
      "epoch4 step34515 [D loss: -0.066854] [G loss: 1.460185]\n",
      "epoch4 step34520 [D loss: -0.189911] [G loss: 1.391478]\n",
      "epoch4 step34525 [D loss: -0.293786] [G loss: 1.844883]\n",
      "epoch4 step34530 [D loss: -0.408924] [G loss: 1.305081]\n",
      "epoch4 step34535 [D loss: -0.105095] [G loss: 1.322445]\n",
      "epoch4 step34540 [D loss: 0.240082] [G loss: 1.457457]\n",
      "epoch4 step34545 [D loss: -0.134930] [G loss: 1.196641]\n",
      "epoch4 step34550 [D loss: -0.255251] [G loss: 1.237493]\n",
      "epoch4 step34555 [D loss: 0.328338] [G loss: 1.428229]\n",
      "epoch4 step34560 [D loss: -0.244665] [G loss: 1.288278]\n",
      "epoch4 step34565 [D loss: -0.229491] [G loss: 1.469311]\n",
      "epoch4 step34570 [D loss: 0.074185] [G loss: 1.197041]\n",
      "epoch4 step34575 [D loss: 0.302844] [G loss: 0.851554]\n",
      "epoch4 step34580 [D loss: 0.069973] [G loss: 1.156355]\n",
      "epoch4 step34585 [D loss: -0.509644] [G loss: 1.713887]\n",
      "epoch4 step34590 [D loss: -0.524570] [G loss: 1.155997]\n",
      "epoch4 step34595 [D loss: -0.310933] [G loss: 1.387337]\n",
      "epoch4 step34600 [D loss: -0.037882] [G loss: 1.076931]\n",
      "epoch4 step34605 [D loss: 0.048173] [G loss: 0.913438]\n",
      "epoch4 step34610 [D loss: -0.278235] [G loss: 1.245573]\n",
      "epoch4 step34615 [D loss: -0.501848] [G loss: 1.323302]\n",
      "epoch4 step34620 [D loss: -0.053124] [G loss: 1.021005]\n",
      "epoch4 step34625 [D loss: -0.086274] [G loss: 0.878261]\n",
      "epoch4 step34630 [D loss: -0.557214] [G loss: 1.293080]\n",
      "epoch4 step34635 [D loss: -0.086380] [G loss: 1.357484]\n",
      "epoch4 step34640 [D loss: 0.309235] [G loss: 1.198844]\n",
      "epoch4 step34645 [D loss: -0.016836] [G loss: 1.168722]\n",
      "epoch4 step34650 [D loss: 0.356822] [G loss: 1.359349]\n",
      "epoch4 step34655 [D loss: -0.146581] [G loss: 0.813596]\n",
      "epoch4 step34660 [D loss: 0.233305] [G loss: 0.763953]\n",
      "epoch4 step34665 [D loss: 0.200597] [G loss: 1.209970]\n",
      "epoch4 step34670 [D loss: -0.385489] [G loss: 1.039618]\n",
      "epoch4 step34675 [D loss: 0.362012] [G loss: 0.932032]\n",
      "epoch4 step34680 [D loss: 0.060843] [G loss: 0.870086]\n",
      "epoch4 step34685 [D loss: 0.176859] [G loss: 0.744151]\n",
      "epoch4 step34690 [D loss: 0.089589] [G loss: 0.790835]\n",
      "epoch4 step34695 [D loss: 0.197302] [G loss: 0.948052]\n",
      "epoch4 step34700 [D loss: -0.021925] [G loss: 1.180737]\n",
      "epoch4 step34705 [D loss: -0.344830] [G loss: 0.842749]\n",
      "epoch4 step34710 [D loss: 0.162257] [G loss: 1.236553]\n",
      "epoch4 step34715 [D loss: -0.338808] [G loss: 0.869803]\n",
      "epoch4 step34720 [D loss: -0.151643] [G loss: 1.051354]\n",
      "epoch4 step34725 [D loss: -0.286279] [G loss: 1.456935]\n",
      "epoch4 step34730 [D loss: -0.414042] [G loss: 1.289753]\n",
      "epoch4 step34735 [D loss: -0.145787] [G loss: 1.272071]\n",
      "epoch4 step34740 [D loss: -0.111108] [G loss: 1.248900]\n",
      "epoch4 step34745 [D loss: -0.480668] [G loss: 1.318096]\n",
      "epoch4 step34750 [D loss: 0.106428] [G loss: 1.377996]\n",
      "epoch4 step34755 [D loss: -0.496688] [G loss: 1.614170]\n",
      "epoch4 step34760 [D loss: -0.258710] [G loss: 1.428652]\n",
      "epoch4 step34765 [D loss: 0.012331] [G loss: 1.113657]\n",
      "epoch4 step34770 [D loss: -0.480629] [G loss: 1.027148]\n",
      "epoch4 step34775 [D loss: 0.234667] [G loss: 0.984242]\n",
      "epoch4 step34780 [D loss: 0.241209] [G loss: 1.515546]\n",
      "epoch4 step34785 [D loss: -0.683626] [G loss: 1.139434]\n",
      "epoch4 step34790 [D loss: 0.257144] [G loss: 1.165484]\n",
      "epoch4 step34795 [D loss: -0.734331] [G loss: 1.286778]\n",
      "epoch4 step34800 [D loss: 0.098059] [G loss: 0.772953]\n",
      "epoch4 step34805 [D loss: -0.277671] [G loss: 0.679246]\n",
      "epoch4 step34810 [D loss: -0.283334] [G loss: 1.369475]\n",
      "epoch4 step34815 [D loss: -0.050412] [G loss: 1.192747]\n",
      "epoch4 step34820 [D loss: -0.641332] [G loss: 1.451159]\n",
      "epoch4 step34825 [D loss: 0.213440] [G loss: 1.047950]\n",
      "epoch4 step34830 [D loss: -0.592367] [G loss: 1.349800]\n",
      "epoch4 step34835 [D loss: 0.079012] [G loss: 0.786736]\n",
      "epoch4 step34840 [D loss: -0.232446] [G loss: 0.823351]\n",
      "epoch4 step34845 [D loss: -0.146178] [G loss: 1.012315]\n",
      "epoch4 step34850 [D loss: 0.002748] [G loss: 0.989935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step34855 [D loss: 0.817997] [G loss: 0.663414]\n",
      "epoch4 step34860 [D loss: 0.103549] [G loss: 0.969776]\n",
      "epoch4 step34865 [D loss: 0.130633] [G loss: 0.893370]\n",
      "epoch4 step34870 [D loss: -0.049448] [G loss: 0.935884]\n",
      "epoch4 step34875 [D loss: -0.170043] [G loss: 0.847839]\n",
      "epoch4 step34880 [D loss: -0.190243] [G loss: 0.785417]\n",
      "epoch4 step34885 [D loss: 0.106952] [G loss: 0.833975]\n",
      "epoch4 step34890 [D loss: -0.075894] [G loss: 0.293906]\n",
      "epoch4 step34895 [D loss: 0.147210] [G loss: 0.551874]\n",
      "epoch4 step34900 [D loss: 0.124266] [G loss: 0.305458]\n",
      "epoch4 step34905 [D loss: -0.049948] [G loss: 0.301368]\n",
      "epoch4 step34910 [D loss: 0.042813] [G loss: 0.035246]\n",
      "epoch4 step34915 [D loss: -0.000476] [G loss: 0.486612]\n",
      "epoch4 step34920 [D loss: -0.017956] [G loss: 0.219273]\n",
      "epoch4 step34925 [D loss: -0.324375] [G loss: 0.232813]\n",
      "epoch4 step34930 [D loss: -0.178928] [G loss: 0.116398]\n",
      "epoch4 step34935 [D loss: 0.055680] [G loss: 0.434540]\n",
      "epoch4 step34940 [D loss: -0.385532] [G loss: 0.153027]\n",
      "epoch4 step34945 [D loss: 0.323635] [G loss: 0.384993]\n",
      "epoch4 step34950 [D loss: 0.377085] [G loss: -0.146712]\n",
      "epoch4 step34955 [D loss: -0.087887] [G loss: -0.085974]\n",
      "epoch4 step34960 [D loss: -0.173657] [G loss: 0.137255]\n",
      "epoch4 step34965 [D loss: -0.280770] [G loss: -0.235574]\n",
      "epoch4 step34970 [D loss: -0.255816] [G loss: -0.265845]\n",
      "epoch4 step34975 [D loss: -0.347928] [G loss: 0.195651]\n",
      "epoch4 step34980 [D loss: -0.017915] [G loss: -0.052603]\n",
      "epoch4 step34985 [D loss: 0.427754] [G loss: 0.162789]\n",
      "epoch4 step34990 [D loss: 0.192789] [G loss: -0.133649]\n",
      "epoch4 step34995 [D loss: -0.128623] [G loss: -0.021302]\n",
      "epoch4 step35000 [D loss: 0.056058] [G loss: -0.062939]\n",
      "epoch4 step35005 [D loss: 0.161315] [G loss: 0.292598]\n",
      "epoch4 step35010 [D loss: -0.351073] [G loss: 0.124380]\n",
      "epoch4 step35015 [D loss: -0.453402] [G loss: 0.076361]\n",
      "epoch4 step35020 [D loss: -0.287209] [G loss: 0.361564]\n",
      "epoch4 step35025 [D loss: -0.053032] [G loss: 0.554970]\n",
      "epoch4 step35030 [D loss: -0.080414] [G loss: 0.352072]\n",
      "epoch4 step35035 [D loss: -0.536688] [G loss: 1.138399]\n",
      "epoch4 step35040 [D loss: -0.474933] [G loss: 0.679315]\n",
      "epoch4 step35045 [D loss: -0.535557] [G loss: 0.777436]\n",
      "epoch4 step35050 [D loss: 0.010551] [G loss: 0.882572]\n",
      "epoch4 step35055 [D loss: -0.521939] [G loss: 0.768004]\n",
      "epoch4 step35060 [D loss: -0.885281] [G loss: 1.440041]\n",
      "epoch4 step35065 [D loss: -0.525292] [G loss: 1.389945]\n",
      "epoch4 step35070 [D loss: -0.776099] [G loss: 1.081189]\n",
      "epoch4 step35075 [D loss: -0.053714] [G loss: 1.258122]\n",
      "epoch4 step35080 [D loss: -0.056701] [G loss: 1.100544]\n",
      "epoch4 step35085 [D loss: -0.084047] [G loss: 1.244165]\n",
      "epoch4 step35090 [D loss: -0.222692] [G loss: 1.401597]\n",
      "epoch4 step35095 [D loss: -0.235946] [G loss: 1.274820]\n",
      "epoch4 step35100 [D loss: -0.307918] [G loss: 0.881951]\n",
      "epoch4 step35105 [D loss: -0.134082] [G loss: 1.218596]\n",
      "epoch4 step35110 [D loss: -0.357411] [G loss: 1.156544]\n",
      "epoch4 step35115 [D loss: -0.041264] [G loss: 1.334570]\n",
      "epoch4 step35120 [D loss: 0.135218] [G loss: 0.928436]\n",
      "epoch4 step35125 [D loss: 0.584962] [G loss: 1.431782]\n",
      "epoch4 step35130 [D loss: -0.485368] [G loss: 1.528756]\n",
      "epoch4 step35135 [D loss: 0.095520] [G loss: 1.160824]\n",
      "epoch4 step35140 [D loss: -0.403752] [G loss: 1.399590]\n",
      "epoch4 step35145 [D loss: 0.065083] [G loss: 1.186993]\n",
      "epoch4 step35150 [D loss: 0.154044] [G loss: 1.013392]\n",
      "epoch4 step35155 [D loss: -0.427342] [G loss: 1.162712]\n",
      "epoch4 step35160 [D loss: -0.105772] [G loss: 0.969641]\n",
      "epoch4 step35165 [D loss: -0.232709] [G loss: 0.821467]\n",
      "epoch4 step35170 [D loss: -0.024697] [G loss: 0.494946]\n",
      "epoch4 step35175 [D loss: 0.126303] [G loss: 0.976343]\n",
      "epoch4 step35180 [D loss: 0.145208] [G loss: 0.999750]\n",
      "epoch4 step35185 [D loss: 0.576004] [G loss: 0.832079]\n",
      "epoch4 step35190 [D loss: -0.242783] [G loss: 0.900013]\n",
      "epoch4 step35195 [D loss: -0.025163] [G loss: 0.691238]\n",
      "epoch4 step35200 [D loss: -0.166734] [G loss: 0.627458]\n",
      "epoch4 step35205 [D loss: -0.475406] [G loss: 0.635141]\n",
      "epoch4 step35210 [D loss: 0.001583] [G loss: 0.740472]\n",
      "epoch4 step35215 [D loss: -0.325926] [G loss: 0.677639]\n",
      "epoch4 step35220 [D loss: -0.495030] [G loss: 0.602789]\n",
      "epoch4 step35225 [D loss: 0.269446] [G loss: 0.418991]\n",
      "epoch4 step35230 [D loss: -0.484828] [G loss: 0.478265]\n",
      "epoch4 step35235 [D loss: -0.098114] [G loss: 0.255181]\n",
      "epoch4 step35240 [D loss: 0.234039] [G loss: 0.148870]\n",
      "epoch4 step35245 [D loss: -0.519484] [G loss: 0.510416]\n",
      "epoch4 step35250 [D loss: 0.054066] [G loss: 0.222523]\n",
      "epoch4 step35255 [D loss: 0.279764] [G loss: 0.521377]\n",
      "epoch4 step35260 [D loss: -0.215958] [G loss: 0.523793]\n",
      "epoch4 step35265 [D loss: -0.280225] [G loss: 0.298345]\n",
      "epoch4 step35270 [D loss: 0.347153] [G loss: 0.236702]\n",
      "epoch4 step35275 [D loss: -0.133254] [G loss: 0.314255]\n",
      "epoch4 step35280 [D loss: -0.146531] [G loss: 0.298364]\n",
      "epoch4 step35285 [D loss: -0.415368] [G loss: 0.556316]\n",
      "epoch4 step35290 [D loss: -0.028946] [G loss: 0.583788]\n",
      "epoch4 step35295 [D loss: -0.276904] [G loss: 0.603192]\n",
      "epoch4 step35300 [D loss: 0.052652] [G loss: 0.302105]\n",
      "epoch4 step35305 [D loss: -0.134196] [G loss: 0.551443]\n",
      "epoch4 step35310 [D loss: -0.315034] [G loss: 0.621983]\n",
      "epoch4 step35315 [D loss: -0.128555] [G loss: 0.533495]\n",
      "epoch4 step35320 [D loss: -0.293235] [G loss: 0.288198]\n",
      "epoch4 step35325 [D loss: 0.331475] [G loss: 0.363884]\n",
      "epoch4 step35330 [D loss: 0.177432] [G loss: 0.641433]\n",
      "epoch4 step35335 [D loss: -0.293548] [G loss: 0.503158]\n",
      "epoch4 step35340 [D loss: -0.071105] [G loss: 0.484691]\n",
      "epoch4 step35345 [D loss: 0.310897] [G loss: 0.514706]\n",
      "epoch4 step35350 [D loss: -0.452202] [G loss: 0.490105]\n",
      "epoch4 step35355 [D loss: -0.084135] [G loss: 0.356227]\n",
      "epoch4 step35360 [D loss: -0.447030] [G loss: 0.345366]\n",
      "epoch4 step35365 [D loss: 0.008774] [G loss: 0.486672]\n",
      "epoch4 step35370 [D loss: -0.165593] [G loss: 0.541144]\n",
      "epoch4 step35375 [D loss: -0.125537] [G loss: 0.605035]\n",
      "epoch4 step35380 [D loss: 0.168799] [G loss: 0.564183]\n",
      "epoch4 step35385 [D loss: -0.024816] [G loss: 0.550116]\n",
      "epoch4 step35390 [D loss: -0.305282] [G loss: 0.781344]\n",
      "epoch4 step35395 [D loss: 0.216248] [G loss: 0.479455]\n",
      "epoch4 step35400 [D loss: -0.320603] [G loss: 0.228240]\n",
      "epoch4 step35405 [D loss: -0.313269] [G loss: 0.639285]\n",
      "epoch4 step35410 [D loss: 0.339115] [G loss: 0.306161]\n",
      "epoch4 step35415 [D loss: 0.500177] [G loss: 0.429587]\n",
      "epoch4 step35420 [D loss: 0.284150] [G loss: 0.553186]\n",
      "epoch4 step35425 [D loss: 0.100752] [G loss: 0.625111]\n",
      "epoch4 step35430 [D loss: -0.310663] [G loss: 0.787749]\n",
      "epoch4 step35435 [D loss: -0.596997] [G loss: 0.817338]\n",
      "epoch4 step35440 [D loss: -0.420477] [G loss: 0.812691]\n",
      "epoch4 step35445 [D loss: -0.198785] [G loss: 1.002961]\n",
      "epoch4 step35450 [D loss: -0.171194] [G loss: 0.743679]\n",
      "epoch4 step35455 [D loss: 0.220950] [G loss: 0.633041]\n",
      "epoch4 step35460 [D loss: -0.222970] [G loss: 0.605429]\n",
      "epoch4 step35465 [D loss: -0.243133] [G loss: 0.664079]\n",
      "epoch4 step35470 [D loss: 0.255637] [G loss: 0.538661]\n",
      "epoch4 step35475 [D loss: -0.093417] [G loss: 0.597905]\n",
      "epoch4 step35480 [D loss: -0.070038] [G loss: 0.839933]\n",
      "epoch4 step35485 [D loss: 0.007490] [G loss: 0.752880]\n",
      "epoch4 step35490 [D loss: -0.273952] [G loss: 0.867224]\n",
      "epoch4 step35495 [D loss: -0.137368] [G loss: 0.696929]\n",
      "epoch4 step35500 [D loss: -0.354814] [G loss: 0.768690]\n",
      "epoch4 step35505 [D loss: -0.268089] [G loss: 0.642859]\n",
      "epoch4 step35510 [D loss: -0.447299] [G loss: 0.859794]\n",
      "epoch4 step35515 [D loss: -0.350278] [G loss: 1.078319]\n",
      "epoch4 step35520 [D loss: -0.127937] [G loss: 0.584120]\n",
      "epoch4 step35525 [D loss: -0.731146] [G loss: 0.907498]\n",
      "epoch4 step35530 [D loss: -0.229934] [G loss: 0.704099]\n",
      "epoch4 step35535 [D loss: -0.118695] [G loss: 0.654990]\n",
      "epoch4 step35540 [D loss: -0.356010] [G loss: 0.893183]\n",
      "epoch4 step35545 [D loss: -0.039926] [G loss: 0.676051]\n",
      "epoch4 step35550 [D loss: -0.238543] [G loss: 0.884407]\n",
      "epoch4 step35555 [D loss: 0.054099] [G loss: 1.091050]\n",
      "epoch4 step35560 [D loss: -0.222901] [G loss: 0.569330]\n",
      "epoch4 step35565 [D loss: 0.029916] [G loss: 0.590533]\n",
      "epoch4 step35570 [D loss: 0.072805] [G loss: 0.599995]\n",
      "epoch4 step35575 [D loss: 0.162909] [G loss: 0.578408]\n",
      "epoch4 step35580 [D loss: -0.216976] [G loss: 0.837348]\n",
      "epoch4 step35585 [D loss: -0.134543] [G loss: 0.798496]\n",
      "epoch4 step35590 [D loss: -0.286273] [G loss: 0.911775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step35595 [D loss: -0.431700] [G loss: 0.895551]\n",
      "epoch4 step35600 [D loss: -0.160423] [G loss: 0.636524]\n",
      "epoch4 step35605 [D loss: -0.042016] [G loss: 1.113409]\n",
      "epoch4 step35610 [D loss: -0.083842] [G loss: 0.853398]\n",
      "epoch4 step35615 [D loss: -0.499781] [G loss: 0.839914]\n",
      "epoch4 step35620 [D loss: -0.294572] [G loss: 0.962733]\n",
      "epoch4 step35625 [D loss: 0.005567] [G loss: 0.597882]\n",
      "epoch4 step35630 [D loss: 0.285682] [G loss: 0.936744]\n",
      "epoch4 step35635 [D loss: -0.165460] [G loss: 0.925750]\n",
      "epoch4 step35640 [D loss: -0.145628] [G loss: 0.647181]\n",
      "epoch4 step35645 [D loss: -0.408040] [G loss: 1.063059]\n",
      "epoch4 step35650 [D loss: -0.339793] [G loss: 0.626551]\n",
      "epoch4 step35655 [D loss: -0.223793] [G loss: 0.838629]\n",
      "epoch4 step35660 [D loss: -0.091083] [G loss: 0.408647]\n",
      "epoch4 step35665 [D loss: 0.086868] [G loss: 0.406705]\n",
      "epoch4 step35670 [D loss: -0.091921] [G loss: 0.396307]\n",
      "epoch4 step35675 [D loss: 0.092301] [G loss: 0.423945]\n",
      "epoch4 step35680 [D loss: -0.437431] [G loss: 0.640476]\n",
      "epoch4 step35685 [D loss: -0.097844] [G loss: 0.451761]\n",
      "epoch4 step35690 [D loss: 0.064862] [G loss: 0.402260]\n",
      "epoch4 step35695 [D loss: -0.184463] [G loss: 0.585096]\n",
      "epoch4 step35700 [D loss: -0.264106] [G loss: 0.573441]\n",
      "epoch4 step35705 [D loss: 0.006641] [G loss: 0.672737]\n",
      "epoch4 step35710 [D loss: 0.236125] [G loss: 0.206212]\n",
      "epoch4 step35715 [D loss: -0.396984] [G loss: 0.358178]\n",
      "epoch4 step35720 [D loss: 0.139316] [G loss: 0.536458]\n",
      "epoch4 step35725 [D loss: 0.139255] [G loss: 0.731860]\n",
      "epoch4 step35730 [D loss: -0.307572] [G loss: 0.991717]\n",
      "epoch4 step35735 [D loss: 0.049696] [G loss: 0.619018]\n",
      "epoch4 step35740 [D loss: -0.024174] [G loss: 0.750998]\n",
      "epoch4 step35745 [D loss: 0.227629] [G loss: 0.700329]\n",
      "epoch4 step35750 [D loss: -0.334502] [G loss: 0.885720]\n",
      "epoch4 step35755 [D loss: -0.355000] [G loss: 0.855505]\n",
      "epoch4 step35760 [D loss: -0.251293] [G loss: 0.816405]\n",
      "epoch4 step35765 [D loss: -0.684741] [G loss: 0.869557]\n",
      "epoch4 step35770 [D loss: -0.091057] [G loss: 0.728178]\n",
      "epoch4 step35775 [D loss: -0.280373] [G loss: 0.590748]\n",
      "epoch4 step35780 [D loss: 0.010488] [G loss: 0.684590]\n",
      "epoch4 step35785 [D loss: -0.214279] [G loss: 0.433286]\n",
      "epoch4 step35790 [D loss: -0.055615] [G loss: 1.045683]\n",
      "epoch4 step35795 [D loss: -0.158510] [G loss: 0.823771]\n",
      "epoch4 step35800 [D loss: -0.031959] [G loss: 0.752747]\n",
      "epoch4 step35805 [D loss: -0.342708] [G loss: 0.746609]\n",
      "epoch4 step35810 [D loss: -0.365795] [G loss: 0.491957]\n",
      "epoch4 step35815 [D loss: -0.690872] [G loss: 0.928109]\n",
      "epoch4 step35820 [D loss: 0.031500] [G loss: 0.486274]\n",
      "epoch4 step35825 [D loss: 0.158830] [G loss: 0.713123]\n",
      "epoch4 step35830 [D loss: 0.140102] [G loss: 0.759632]\n",
      "epoch4 step35835 [D loss: 0.019741] [G loss: 0.346512]\n",
      "epoch4 step35840 [D loss: 0.228422] [G loss: 0.460530]\n",
      "epoch4 step35845 [D loss: -0.628498] [G loss: 0.790061]\n",
      "epoch4 step35850 [D loss: -0.217757] [G loss: 0.920417]\n",
      "epoch4 step35855 [D loss: 0.563697] [G loss: 0.514191]\n",
      "epoch4 step35860 [D loss: -0.004799] [G loss: 0.584117]\n",
      "epoch4 step35865 [D loss: 0.022254] [G loss: 0.711201]\n",
      "epoch4 step35870 [D loss: -0.545501] [G loss: 0.886464]\n",
      "epoch4 step35875 [D loss: 0.134695] [G loss: 0.724280]\n",
      "epoch4 step35880 [D loss: -0.315507] [G loss: 0.927916]\n",
      "epoch4 step35885 [D loss: -0.106339] [G loss: 0.589931]\n",
      "epoch4 step35890 [D loss: -0.300453] [G loss: 0.901656]\n",
      "epoch4 step35895 [D loss: -0.360215] [G loss: 0.768163]\n",
      "epoch4 step35900 [D loss: 0.065628] [G loss: 0.655095]\n",
      "epoch4 step35905 [D loss: -0.489621] [G loss: 0.956918]\n",
      "epoch4 step35910 [D loss: -0.133114] [G loss: 0.722260]\n",
      "epoch4 step35915 [D loss: -0.618682] [G loss: 0.762192]\n",
      "epoch4 step35920 [D loss: -0.252601] [G loss: 0.525542]\n",
      "epoch4 step35925 [D loss: 0.263792] [G loss: 0.823252]\n",
      "epoch4 step35930 [D loss: -0.123263] [G loss: 0.550091]\n",
      "epoch4 step35935 [D loss: -0.032652] [G loss: 0.754932]\n",
      "epoch4 step35940 [D loss: -0.388939] [G loss: 0.820885]\n",
      "epoch4 step35945 [D loss: 0.098364] [G loss: 0.495957]\n",
      "epoch4 step35950 [D loss: -0.443568] [G loss: 0.899940]\n",
      "epoch4 step35955 [D loss: -0.029525] [G loss: 0.509001]\n",
      "epoch4 step35960 [D loss: -0.089045] [G loss: 0.813600]\n",
      "epoch4 step35965 [D loss: 0.079684] [G loss: 0.275282]\n",
      "epoch4 step35970 [D loss: -0.152549] [G loss: 0.357840]\n",
      "epoch4 step35975 [D loss: -0.101803] [G loss: 0.557101]\n",
      "epoch4 step35980 [D loss: 0.354326] [G loss: 0.599237]\n",
      "epoch4 step35985 [D loss: -0.010399] [G loss: 0.456800]\n",
      "epoch4 step35990 [D loss: -0.034275] [G loss: 0.566919]\n",
      "epoch4 step35995 [D loss: -0.086501] [G loss: 0.666332]\n",
      "epoch4 step36000 [D loss: 0.422691] [G loss: 0.338891]\n",
      "epoch4 step36005 [D loss: 0.171469] [G loss: 1.037749]\n",
      "epoch4 step36010 [D loss: -0.397529] [G loss: 0.667614]\n",
      "epoch4 step36015 [D loss: -0.305487] [G loss: 0.715632]\n",
      "epoch4 step36020 [D loss: 0.044281] [G loss: 0.630006]\n",
      "epoch4 step36025 [D loss: 0.169405] [G loss: 0.751224]\n",
      "epoch4 step36030 [D loss: -0.367270] [G loss: 1.215612]\n",
      "epoch4 step36035 [D loss: -0.155985] [G loss: 0.734625]\n",
      "epoch4 step36040 [D loss: -0.020153] [G loss: 1.135803]\n",
      "epoch4 step36045 [D loss: 0.246146] [G loss: 0.614840]\n",
      "epoch4 step36050 [D loss: -0.307078] [G loss: 0.942630]\n",
      "epoch4 step36055 [D loss: -0.253465] [G loss: 0.946722]\n",
      "epoch4 step36060 [D loss: 0.230494] [G loss: 0.620232]\n",
      "epoch4 step36065 [D loss: -0.149862] [G loss: 0.979665]\n",
      "epoch4 step36070 [D loss: -0.205573] [G loss: 0.947078]\n",
      "epoch4 step36075 [D loss: 0.147676] [G loss: 0.743881]\n",
      "epoch4 step36080 [D loss: -0.076423] [G loss: 0.753750]\n",
      "epoch4 step36085 [D loss: -0.088840] [G loss: 1.036148]\n",
      "epoch4 step36090 [D loss: -0.543164] [G loss: 1.123202]\n",
      "epoch4 step36095 [D loss: -0.167999] [G loss: 0.944264]\n",
      "epoch4 step36100 [D loss: 0.104300] [G loss: 0.707299]\n",
      "epoch4 step36105 [D loss: -0.341309] [G loss: 0.947650]\n",
      "epoch4 step36110 [D loss: -0.001915] [G loss: 1.048641]\n",
      "epoch4 step36115 [D loss: -0.200590] [G loss: 1.018114]\n",
      "epoch4 step36120 [D loss: -0.519833] [G loss: 0.887244]\n",
      "epoch4 step36125 [D loss: -0.672846] [G loss: 0.899276]\n",
      "epoch4 step36130 [D loss: 0.222882] [G loss: 1.034120]\n",
      "epoch4 step36135 [D loss: 0.022054] [G loss: 0.930651]\n",
      "epoch4 step36140 [D loss: -0.053592] [G loss: 1.019654]\n",
      "epoch4 step36145 [D loss: -0.199379] [G loss: 1.165158]\n",
      "epoch4 step36150 [D loss: 0.092703] [G loss: 0.893613]\n",
      "epoch4 step36155 [D loss: -0.554580] [G loss: 1.211337]\n",
      "epoch4 step36160 [D loss: -0.461206] [G loss: 1.141326]\n",
      "epoch4 step36165 [D loss: -0.125614] [G loss: 1.431741]\n",
      "epoch4 step36170 [D loss: -0.108606] [G loss: 1.060624]\n",
      "epoch4 step36175 [D loss: -0.391790] [G loss: 0.823086]\n",
      "epoch4 step36180 [D loss: 0.220402] [G loss: 1.093761]\n",
      "epoch4 step36185 [D loss: -0.367890] [G loss: 1.111373]\n",
      "epoch4 step36190 [D loss: 0.321081] [G loss: 0.993196]\n",
      "epoch4 step36195 [D loss: 0.184429] [G loss: 1.056226]\n",
      "epoch4 step36200 [D loss: -0.179150] [G loss: 0.963360]\n",
      "epoch4 step36205 [D loss: -0.112975] [G loss: 0.829480]\n",
      "epoch4 step36210 [D loss: 0.009876] [G loss: 0.932754]\n",
      "epoch4 step36215 [D loss: -0.310892] [G loss: 1.075772]\n",
      "epoch4 step36220 [D loss: 0.370014] [G loss: 1.017016]\n",
      "epoch4 step36225 [D loss: 0.224837] [G loss: 0.711490]\n",
      "epoch4 step36230 [D loss: 0.106768] [G loss: 0.831736]\n",
      "epoch4 step36235 [D loss: -0.035642] [G loss: 0.948192]\n",
      "epoch4 step36240 [D loss: 0.014239] [G loss: 0.579426]\n",
      "epoch4 step36245 [D loss: 0.395464] [G loss: 0.902930]\n",
      "epoch4 step36250 [D loss: -0.592838] [G loss: 1.118785]\n",
      "epoch4 step36255 [D loss: -0.148727] [G loss: 0.928933]\n",
      "epoch4 step36260 [D loss: 0.063921] [G loss: 0.851760]\n",
      "epoch4 step36265 [D loss: -0.245095] [G loss: 0.887249]\n",
      "epoch4 step36270 [D loss: -0.305211] [G loss: 0.713522]\n",
      "epoch4 step36275 [D loss: 0.123176] [G loss: 0.515558]\n",
      "epoch4 step36280 [D loss: 0.371622] [G loss: 0.985057]\n",
      "epoch4 step36285 [D loss: -0.559046] [G loss: 1.041181]\n",
      "epoch4 step36290 [D loss: -0.553752] [G loss: 0.898785]\n",
      "epoch4 step36295 [D loss: -0.130452] [G loss: 1.153574]\n",
      "epoch4 step36300 [D loss: 0.185442] [G loss: 0.785413]\n",
      "epoch4 step36305 [D loss: 0.056182] [G loss: 1.030782]\n",
      "epoch4 step36310 [D loss: 0.230362] [G loss: 0.653989]\n",
      "epoch4 step36315 [D loss: -0.496926] [G loss: 0.725450]\n",
      "epoch4 step36320 [D loss: -0.373815] [G loss: 1.374050]\n",
      "epoch4 step36325 [D loss: -0.095486] [G loss: 0.989323]\n",
      "epoch4 step36330 [D loss: 0.148805] [G loss: 1.289679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step36335 [D loss: -0.380937] [G loss: 0.853069]\n",
      "epoch4 step36340 [D loss: -0.093480] [G loss: 0.798173]\n",
      "epoch4 step36345 [D loss: 0.193640] [G loss: 0.752423]\n",
      "epoch4 step36350 [D loss: 0.186204] [G loss: 0.862245]\n",
      "epoch4 step36355 [D loss: 0.039675] [G loss: 0.625690]\n",
      "epoch4 step36360 [D loss: 0.151244] [G loss: 0.636455]\n",
      "epoch4 step36365 [D loss: -0.356279] [G loss: 0.308135]\n",
      "epoch4 step36370 [D loss: 0.115589] [G loss: 0.795565]\n",
      "epoch4 step36375 [D loss: -0.186415] [G loss: 0.678340]\n",
      "epoch4 step36380 [D loss: -0.251449] [G loss: 0.627706]\n",
      "epoch4 step36385 [D loss: 0.501432] [G loss: 0.685793]\n",
      "epoch4 step36390 [D loss: -0.123092] [G loss: 0.691468]\n",
      "epoch4 step36395 [D loss: -0.486893] [G loss: 0.777780]\n",
      "epoch4 step36400 [D loss: 0.247485] [G loss: 1.147723]\n",
      "epoch4 step36405 [D loss: -0.465867] [G loss: 0.828417]\n",
      "epoch4 step36410 [D loss: -0.456058] [G loss: 0.897758]\n",
      "epoch4 step36415 [D loss: 0.027640] [G loss: 1.187590]\n",
      "epoch4 step36420 [D loss: -0.005819] [G loss: 1.035987]\n",
      "epoch4 step36425 [D loss: -0.320648] [G loss: 1.213488]\n",
      "epoch4 step36430 [D loss: -0.441583] [G loss: 1.173399]\n",
      "epoch4 step36435 [D loss: -0.093587] [G loss: 1.529195]\n",
      "epoch4 step36440 [D loss: 0.034440] [G loss: 1.341460]\n",
      "epoch4 step36445 [D loss: -0.512742] [G loss: 1.724935]\n",
      "epoch4 step36450 [D loss: -0.148087] [G loss: 1.317663]\n",
      "epoch4 step36455 [D loss: -0.174102] [G loss: 1.316427]\n",
      "epoch4 step36460 [D loss: 0.147922] [G loss: 1.685610]\n",
      "epoch4 step36465 [D loss: -0.128201] [G loss: 1.294767]\n",
      "epoch4 step36470 [D loss: -0.056181] [G loss: 1.456655]\n",
      "epoch4 step36475 [D loss: -0.401075] [G loss: 1.747858]\n",
      "epoch4 step36480 [D loss: -0.163177] [G loss: 1.124629]\n",
      "epoch4 step36485 [D loss: 0.192643] [G loss: 1.480955]\n",
      "epoch4 step36490 [D loss: -0.323951] [G loss: 1.398936]\n",
      "epoch4 step36495 [D loss: 0.281637] [G loss: 1.228360]\n",
      "epoch4 step36500 [D loss: 0.461514] [G loss: 1.204988]\n",
      "epoch4 step36505 [D loss: 0.190609] [G loss: 0.878433]\n",
      "epoch4 step36510 [D loss: -0.485417] [G loss: 1.078402]\n",
      "epoch4 step36515 [D loss: -0.029654] [G loss: 1.158307]\n",
      "epoch4 step36520 [D loss: -0.110197] [G loss: 1.086880]\n",
      "epoch4 step36525 [D loss: -0.144325] [G loss: 0.902779]\n",
      "epoch4 step36530 [D loss: -0.238849] [G loss: 0.574241]\n",
      "epoch4 step36535 [D loss: 0.180954] [G loss: 0.257736]\n",
      "epoch4 step36540 [D loss: -0.106538] [G loss: 1.000734]\n",
      "epoch4 step36545 [D loss: -0.113385] [G loss: 0.512056]\n",
      "epoch4 step36550 [D loss: -0.177130] [G loss: 0.633002]\n",
      "epoch4 step36555 [D loss: -0.740023] [G loss: 0.420433]\n",
      "epoch4 step36560 [D loss: -0.250764] [G loss: 0.322539]\n",
      "epoch4 step36565 [D loss: -0.096324] [G loss: 0.033799]\n",
      "epoch4 step36570 [D loss: -0.380918] [G loss: -0.255263]\n",
      "epoch4 step36575 [D loss: -0.071792] [G loss: 0.182656]\n",
      "epoch4 step36580 [D loss: 0.032812] [G loss: 0.184075]\n",
      "epoch4 step36585 [D loss: -0.335034] [G loss: 0.101792]\n",
      "epoch4 step36590 [D loss: 0.036528] [G loss: 0.126200]\n",
      "epoch4 step36595 [D loss: 0.001565] [G loss: 0.110406]\n",
      "epoch4 step36600 [D loss: 0.449150] [G loss: 0.166583]\n",
      "epoch4 step36605 [D loss: -0.014515] [G loss: 0.137590]\n",
      "epoch4 step36610 [D loss: -0.178713] [G loss: -0.084077]\n",
      "epoch4 step36615 [D loss: -0.106665] [G loss: 0.273075]\n",
      "epoch4 step36620 [D loss: -0.339665] [G loss: 0.555317]\n",
      "epoch4 step36625 [D loss: 0.028427] [G loss: 0.513723]\n",
      "epoch4 step36630 [D loss: -0.692138] [G loss: 0.185211]\n",
      "epoch4 step36635 [D loss: 0.073131] [G loss: 0.320056]\n",
      "epoch4 step36640 [D loss: 0.191888] [G loss: 0.289672]\n",
      "epoch4 step36645 [D loss: -0.544080] [G loss: 0.402694]\n",
      "epoch4 step36650 [D loss: -0.171792] [G loss: 0.676938]\n",
      "epoch4 step36655 [D loss: -0.182668] [G loss: 0.439905]\n",
      "epoch4 step36660 [D loss: -0.178672] [G loss: 0.718451]\n",
      "epoch4 step36665 [D loss: -0.202711] [G loss: 0.445777]\n",
      "epoch4 step36670 [D loss: -0.061692] [G loss: 0.934893]\n",
      "epoch4 step36675 [D loss: -0.668652] [G loss: 0.731050]\n",
      "epoch4 step36680 [D loss: -0.386243] [G loss: 0.848115]\n",
      "epoch4 step36685 [D loss: -0.837468] [G loss: 0.989719]\n",
      "epoch4 step36690 [D loss: -0.147702] [G loss: 0.468536]\n",
      "epoch4 step36695 [D loss: -0.128455] [G loss: 1.108591]\n",
      "epoch4 step36700 [D loss: -0.482610] [G loss: 0.820058]\n",
      "epoch4 step36705 [D loss: 0.004707] [G loss: 0.732051]\n",
      "epoch4 step36710 [D loss: -0.272024] [G loss: 1.286720]\n",
      "epoch4 step36715 [D loss: 0.002137] [G loss: 0.591547]\n",
      "epoch4 step36720 [D loss: -0.545781] [G loss: 0.913537]\n",
      "epoch4 step36725 [D loss: 0.205030] [G loss: 0.758440]\n",
      "epoch4 step36730 [D loss: 0.426856] [G loss: 0.786574]\n",
      "epoch4 step36735 [D loss: -0.029698] [G loss: 0.653949]\n",
      "epoch4 step36740 [D loss: -0.422957] [G loss: 1.127823]\n",
      "epoch4 step36745 [D loss: -0.615387] [G loss: 1.285149]\n",
      "epoch4 step36750 [D loss: -0.253344] [G loss: 1.070732]\n",
      "epoch4 step36755 [D loss: -0.261134] [G loss: 0.932532]\n",
      "epoch4 step36760 [D loss: 0.194537] [G loss: 0.620926]\n",
      "epoch4 step36765 [D loss: -0.093466] [G loss: 0.915242]\n",
      "epoch4 step36770 [D loss: 0.226020] [G loss: 0.533071]\n",
      "epoch4 step36775 [D loss: -0.412539] [G loss: 0.604314]\n",
      "epoch4 step36780 [D loss: 0.142531] [G loss: 0.653038]\n",
      "epoch4 step36785 [D loss: 0.043921] [G loss: 0.741935]\n",
      "epoch4 step36790 [D loss: 0.121531] [G loss: 0.591184]\n",
      "epoch4 step36795 [D loss: -0.166722] [G loss: 1.098149]\n",
      "epoch4 step36800 [D loss: 0.038345] [G loss: 0.830998]\n",
      "epoch4 step36805 [D loss: -0.125155] [G loss: 0.724317]\n",
      "epoch4 step36810 [D loss: 0.161114] [G loss: 0.924509]\n",
      "epoch4 step36815 [D loss: -0.186238] [G loss: 0.780788]\n",
      "epoch4 step36820 [D loss: -0.210641] [G loss: 0.939006]\n",
      "epoch4 step36825 [D loss: -0.162033] [G loss: 1.154793]\n",
      "epoch4 step36830 [D loss: 0.128465] [G loss: 0.870269]\n",
      "epoch4 step36835 [D loss: -0.194668] [G loss: 1.268095]\n",
      "epoch4 step36840 [D loss: 0.009748] [G loss: 0.697228]\n",
      "epoch4 step36845 [D loss: 0.001693] [G loss: 0.740596]\n",
      "epoch4 step36850 [D loss: 0.208667] [G loss: 1.016343]\n",
      "epoch4 step36855 [D loss: -0.280513] [G loss: 1.006201]\n",
      "epoch4 step36860 [D loss: 0.259900] [G loss: 0.851598]\n",
      "epoch4 step36865 [D loss: -0.056639] [G loss: 0.855458]\n",
      "epoch4 step36870 [D loss: -0.593303] [G loss: 1.081076]\n",
      "epoch4 step36875 [D loss: -0.219790] [G loss: 1.325403]\n",
      "epoch4 step36880 [D loss: -0.309874] [G loss: 1.119106]\n",
      "epoch4 step36885 [D loss: 0.291805] [G loss: 0.940389]\n",
      "epoch4 step36890 [D loss: 0.395343] [G loss: 1.240085]\n",
      "epoch4 step36895 [D loss: -0.651311] [G loss: 1.144322]\n",
      "epoch4 step36900 [D loss: 0.135378] [G loss: 1.325190]\n",
      "epoch4 step36905 [D loss: -0.368043] [G loss: 1.026815]\n",
      "epoch4 step36910 [D loss: -0.069947] [G loss: 1.035404]\n",
      "epoch4 step36915 [D loss: 0.234935] [G loss: 1.118491]\n",
      "epoch4 step36920 [D loss: -0.134817] [G loss: 1.164938]\n",
      "epoch4 step36925 [D loss: -0.039207] [G loss: 0.971379]\n",
      "epoch4 step36930 [D loss: -0.166204] [G loss: 1.001215]\n",
      "epoch4 step36935 [D loss: 0.203606] [G loss: 1.310651]\n",
      "epoch4 step36940 [D loss: -0.053407] [G loss: 1.234886]\n",
      "epoch4 step36945 [D loss: -0.107754] [G loss: 1.216266]\n",
      "epoch4 step36950 [D loss: 0.340042] [G loss: 0.929556]\n",
      "epoch4 step36955 [D loss: -0.351593] [G loss: 1.102572]\n",
      "epoch4 step36960 [D loss: 0.227722] [G loss: 1.041417]\n",
      "epoch4 step36965 [D loss: -0.011809] [G loss: 1.075409]\n",
      "epoch4 step36970 [D loss: 0.354308] [G loss: 1.171316]\n",
      "epoch4 step36975 [D loss: -0.382250] [G loss: 0.951367]\n",
      "epoch4 step36980 [D loss: 0.229194] [G loss: 1.074760]\n",
      "epoch4 step36985 [D loss: -0.083090] [G loss: 1.013438]\n",
      "epoch4 step36990 [D loss: -0.472638] [G loss: 1.291611]\n",
      "epoch4 step36995 [D loss: -0.093683] [G loss: 1.217194]\n",
      "epoch4 step37000 [D loss: -0.120065] [G loss: 0.909011]\n",
      "epoch4 step37005 [D loss: -0.494466] [G loss: 1.134247]\n",
      "epoch4 step37010 [D loss: 0.060502] [G loss: 1.019322]\n",
      "epoch4 step37015 [D loss: 0.153054] [G loss: 0.867029]\n",
      "epoch4 step37020 [D loss: 0.494726] [G loss: 1.012176]\n",
      "epoch4 step37025 [D loss: 0.071794] [G loss: 0.859225]\n",
      "epoch4 step37030 [D loss: 0.028778] [G loss: 0.963638]\n",
      "epoch4 step37035 [D loss: 0.119010] [G loss: 0.682619]\n",
      "epoch4 step37040 [D loss: 0.026931] [G loss: 0.924988]\n",
      "epoch4 step37045 [D loss: -0.015730] [G loss: 0.946680]\n",
      "epoch4 step37050 [D loss: -0.208675] [G loss: 0.892629]\n",
      "epoch4 step37055 [D loss: -0.180394] [G loss: 0.738228]\n",
      "epoch4 step37060 [D loss: 0.247874] [G loss: 0.724918]\n",
      "epoch4 step37065 [D loss: 0.124357] [G loss: 0.692487]\n",
      "epoch4 step37070 [D loss: -0.042414] [G loss: 0.721957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step37075 [D loss: -0.211221] [G loss: 0.653542]\n",
      "epoch4 step37080 [D loss: 0.338107] [G loss: 0.736075]\n",
      "epoch4 step37085 [D loss: -0.076202] [G loss: 0.603188]\n",
      "epoch4 step37090 [D loss: -0.060205] [G loss: 0.678612]\n",
      "epoch4 step37095 [D loss: -0.545941] [G loss: 0.554384]\n",
      "epoch4 step37100 [D loss: -0.430456] [G loss: 0.642081]\n",
      "epoch4 step37105 [D loss: 0.122169] [G loss: 0.560860]\n",
      "epoch4 step37110 [D loss: -0.100994] [G loss: 0.452176]\n",
      "epoch4 step37115 [D loss: -0.387877] [G loss: 0.549486]\n",
      "epoch4 step37120 [D loss: -0.185332] [G loss: 0.913887]\n",
      "epoch4 step37125 [D loss: -0.422657] [G loss: 0.933444]\n",
      "epoch4 step37130 [D loss: -0.054110] [G loss: 0.904587]\n",
      "epoch4 step37135 [D loss: 0.031661] [G loss: 0.525540]\n",
      "epoch4 step37140 [D loss: -0.087816] [G loss: 1.018529]\n",
      "epoch4 step37145 [D loss: 0.146113] [G loss: 0.620977]\n",
      "epoch4 step37150 [D loss: -0.156498] [G loss: 0.561127]\n",
      "epoch4 step37155 [D loss: -0.188548] [G loss: 0.706710]\n",
      "epoch4 step37160 [D loss: -0.310908] [G loss: 0.546706]\n",
      "epoch4 step37165 [D loss: 0.002987] [G loss: 0.722320]\n",
      "epoch4 step37170 [D loss: -0.199877] [G loss: 0.723465]\n",
      "epoch4 step37175 [D loss: -0.105439] [G loss: 0.788874]\n",
      "epoch4 step37180 [D loss: 0.040110] [G loss: 0.768720]\n",
      "epoch4 step37185 [D loss: 0.355828] [G loss: 0.683764]\n",
      "epoch4 step37190 [D loss: -0.577719] [G loss: 1.010822]\n",
      "epoch4 step37195 [D loss: -0.320847] [G loss: 0.920031]\n",
      "epoch4 step37200 [D loss: 0.001551] [G loss: 0.874079]\n",
      "epoch4 step37205 [D loss: -0.179859] [G loss: 0.708108]\n",
      "epoch4 step37210 [D loss: -0.267363] [G loss: 1.079708]\n",
      "epoch4 step37215 [D loss: -0.157463] [G loss: 0.797857]\n",
      "epoch4 step37220 [D loss: -0.614694] [G loss: 0.692528]\n",
      "epoch4 step37225 [D loss: -0.016474] [G loss: 0.526463]\n",
      "epoch4 step37230 [D loss: 0.039673] [G loss: 0.771203]\n",
      "epoch4 step37235 [D loss: -0.272208] [G loss: 0.696264]\n",
      "epoch4 step37240 [D loss: 0.406486] [G loss: 0.600965]\n",
      "epoch4 step37245 [D loss: -0.074005] [G loss: 0.633299]\n",
      "epoch4 step37250 [D loss: -0.366530] [G loss: 0.275872]\n",
      "epoch4 step37255 [D loss: 0.054394] [G loss: 0.670850]\n",
      "epoch4 step37260 [D loss: 0.284230] [G loss: 0.337628]\n",
      "epoch4 step37265 [D loss: 0.112163] [G loss: 0.343024]\n",
      "epoch4 step37270 [D loss: 0.051200] [G loss: 0.669854]\n",
      "epoch4 step37275 [D loss: -0.278104] [G loss: 0.683080]\n",
      "epoch4 step37280 [D loss: -0.254696] [G loss: 0.800057]\n",
      "epoch4 step37285 [D loss: -1.025993] [G loss: 0.569956]\n",
      "epoch4 step37290 [D loss: -0.044760] [G loss: 0.486126]\n",
      "epoch4 step37295 [D loss: -0.692992] [G loss: 0.304829]\n",
      "epoch4 step37300 [D loss: 0.065172] [G loss: 0.382176]\n",
      "epoch4 step37305 [D loss: -0.122604] [G loss: 0.512718]\n",
      "epoch4 step37310 [D loss: 0.149666] [G loss: 0.752888]\n",
      "epoch4 step37315 [D loss: 0.014350] [G loss: 0.553156]\n",
      "epoch4 step37320 [D loss: -0.255028] [G loss: 0.856985]\n",
      "epoch4 step37325 [D loss: -0.003256] [G loss: 0.749329]\n",
      "epoch4 step37330 [D loss: -0.886530] [G loss: 0.744963]\n",
      "epoch4 step37335 [D loss: 0.101564] [G loss: 1.041880]\n",
      "epoch4 step37340 [D loss: -0.658312] [G loss: 1.107080]\n",
      "epoch4 step37345 [D loss: -0.458260] [G loss: 1.128487]\n",
      "epoch4 step37350 [D loss: -0.496733] [G loss: 0.707951]\n",
      "epoch4 step37355 [D loss: -0.185664] [G loss: 1.232537]\n",
      "epoch4 step37360 [D loss: -0.234969] [G loss: 0.918893]\n",
      "epoch4 step37365 [D loss: -0.231879] [G loss: 0.917346]\n",
      "epoch4 step37370 [D loss: 0.210750] [G loss: 1.103116]\n",
      "epoch4 step37375 [D loss: -0.763945] [G loss: 1.008951]\n",
      "epoch4 step37380 [D loss: 0.045217] [G loss: 0.813817]\n",
      "epoch4 step37385 [D loss: -0.322686] [G loss: 0.691989]\n",
      "epoch4 step37390 [D loss: -0.146837] [G loss: 1.019531]\n",
      "epoch4 step37395 [D loss: -0.347472] [G loss: 1.305302]\n",
      "epoch4 step37400 [D loss: -0.229334] [G loss: 0.864934]\n",
      "epoch4 step37405 [D loss: 0.108519] [G loss: 0.758492]\n",
      "epoch4 step37410 [D loss: 0.426949] [G loss: 0.762935]\n",
      "epoch4 step37415 [D loss: -0.015171] [G loss: 0.789764]\n",
      "epoch4 step37420 [D loss: -0.220298] [G loss: 1.004229]\n",
      "epoch4 step37425 [D loss: -0.517033] [G loss: 1.264009]\n",
      "epoch4 step37430 [D loss: -0.231050] [G loss: 1.014398]\n",
      "epoch4 step37435 [D loss: -0.122716] [G loss: 0.872344]\n",
      "epoch4 step37440 [D loss: 0.351369] [G loss: 1.111548]\n",
      "epoch4 step37445 [D loss: 0.008882] [G loss: 1.231252]\n",
      "epoch4 step37450 [D loss: -0.121815] [G loss: 1.169857]\n",
      "epoch4 step37455 [D loss: -0.350843] [G loss: 1.013842]\n",
      "epoch4 step37460 [D loss: -0.857901] [G loss: 0.952046]\n",
      "epoch4 step37465 [D loss: -0.146500] [G loss: 0.946530]\n",
      "epoch4 step37470 [D loss: 0.232580] [G loss: 0.948039]\n",
      "epoch4 step37475 [D loss: -0.162213] [G loss: 1.196977]\n",
      "epoch4 step37480 [D loss: -0.314280] [G loss: 0.944729]\n",
      "epoch4 step37485 [D loss: -0.771309] [G loss: 1.068218]\n",
      "epoch4 step37490 [D loss: 0.061189] [G loss: 1.565864]\n",
      "epoch4 step37495 [D loss: 0.119897] [G loss: 1.241562]\n",
      "epoch4 step37500 [D loss: 0.085192] [G loss: 1.646839]\n",
      "epoch4 step37505 [D loss: -0.575309] [G loss: 1.657046]\n",
      "epoch4 step37510 [D loss: -0.163233] [G loss: 1.342517]\n",
      "epoch4 step37515 [D loss: -0.208792] [G loss: 1.903782]\n",
      "epoch4 step37520 [D loss: -0.040253] [G loss: 1.452038]\n",
      "epoch4 step37525 [D loss: 0.111378] [G loss: 1.352910]\n",
      "epoch4 step37530 [D loss: -0.390014] [G loss: 1.338155]\n",
      "epoch4 step37535 [D loss: -0.179477] [G loss: 1.685290]\n",
      "epoch4 step37540 [D loss: -0.370400] [G loss: 1.633715]\n",
      "epoch4 step37545 [D loss: -0.054195] [G loss: 1.755349]\n",
      "epoch4 step37550 [D loss: 0.246207] [G loss: 1.538167]\n",
      "epoch4 step37555 [D loss: 0.341177] [G loss: 1.542364]\n",
      "epoch4 step37560 [D loss: 0.470671] [G loss: 1.412943]\n",
      "epoch4 step37565 [D loss: -0.117260] [G loss: 1.473157]\n",
      "epoch4 step37570 [D loss: -0.169494] [G loss: 1.135272]\n",
      "epoch4 step37575 [D loss: 0.158837] [G loss: 1.377339]\n",
      "epoch4 step37580 [D loss: 0.082905] [G loss: 1.337206]\n",
      "epoch4 step37585 [D loss: -0.013225] [G loss: 1.557643]\n",
      "epoch4 step37590 [D loss: -0.407722] [G loss: 1.479526]\n",
      "epoch4 step37595 [D loss: 0.069891] [G loss: 1.404799]\n",
      "epoch4 step37600 [D loss: 0.049697] [G loss: 1.707657]\n",
      "epoch4 step37605 [D loss: 0.143864] [G loss: 1.305306]\n",
      "epoch4 step37610 [D loss: -0.507739] [G loss: 1.503991]\n",
      "epoch4 step37615 [D loss: -0.092954] [G loss: 1.786393]\n",
      "epoch4 step37620 [D loss: 0.168021] [G loss: 1.767748]\n",
      "epoch4 step37625 [D loss: -0.259202] [G loss: 1.785090]\n",
      "epoch4 step37630 [D loss: 0.214260] [G loss: 1.464050]\n",
      "epoch4 step37635 [D loss: -0.485970] [G loss: 1.212525]\n",
      "epoch4 step37640 [D loss: -0.211801] [G loss: 1.436998]\n",
      "epoch4 step37645 [D loss: 0.018619] [G loss: 1.414065]\n",
      "epoch4 step37650 [D loss: 0.170630] [G loss: 1.178467]\n",
      "epoch4 step37655 [D loss: -0.189171] [G loss: 1.197986]\n",
      "epoch4 step37660 [D loss: 0.117279] [G loss: 1.018613]\n",
      "epoch4 step37665 [D loss: -0.411816] [G loss: 1.305692]\n",
      "epoch4 step37670 [D loss: 0.039008] [G loss: 1.562314]\n",
      "epoch4 step37675 [D loss: -0.577033] [G loss: 1.082502]\n",
      "epoch4 step37680 [D loss: -0.228755] [G loss: 0.798405]\n",
      "epoch4 step37685 [D loss: -0.343904] [G loss: 1.069447]\n",
      "epoch4 step37690 [D loss: -0.304107] [G loss: 1.191442]\n",
      "epoch4 step37695 [D loss: -0.135910] [G loss: 0.806394]\n",
      "epoch4 step37700 [D loss: -0.091399] [G loss: 0.957628]\n",
      "epoch4 step37705 [D loss: -0.288422] [G loss: 0.998677]\n",
      "epoch4 step37710 [D loss: -0.447454] [G loss: 1.150944]\n",
      "epoch4 step37715 [D loss: -0.134073] [G loss: 0.990542]\n",
      "epoch4 step37720 [D loss: -0.235615] [G loss: 0.785605]\n",
      "epoch4 step37725 [D loss: -0.317625] [G loss: 0.822091]\n",
      "epoch4 step37730 [D loss: -0.045912] [G loss: 0.665790]\n",
      "epoch4 step37735 [D loss: -0.024976] [G loss: 0.688294]\n",
      "epoch4 step37740 [D loss: -0.261866] [G loss: 0.624556]\n",
      "epoch4 step37745 [D loss: 0.367338] [G loss: 0.673786]\n",
      "epoch4 step37750 [D loss: -0.058356] [G loss: 0.763140]\n",
      "epoch4 step37755 [D loss: -0.450090] [G loss: 0.727030]\n",
      "epoch4 step37760 [D loss: -0.362166] [G loss: 0.855803]\n",
      "epoch4 step37765 [D loss: -0.467515] [G loss: 0.645655]\n",
      "epoch4 step37770 [D loss: -0.446793] [G loss: 0.971944]\n",
      "epoch4 step37775 [D loss: 0.021844] [G loss: 0.576465]\n",
      "epoch4 step37780 [D loss: -0.008410] [G loss: 0.727528]\n",
      "epoch4 step37785 [D loss: -0.387806] [G loss: 0.294316]\n",
      "epoch4 step37790 [D loss: -0.510200] [G loss: 0.665206]\n",
      "epoch4 step37795 [D loss: -0.203999] [G loss: 0.670495]\n",
      "epoch4 step37800 [D loss: 0.199850] [G loss: 0.139606]\n",
      "epoch4 step37805 [D loss: 0.088757] [G loss: 0.686891]\n",
      "epoch4 step37810 [D loss: 0.047729] [G loss: 0.450171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step37815 [D loss: -0.069944] [G loss: 0.458210]\n",
      "epoch4 step37820 [D loss: 0.013834] [G loss: 0.720084]\n",
      "epoch4 step37825 [D loss: 0.138619] [G loss: 0.807902]\n",
      "epoch4 step37830 [D loss: -0.056085] [G loss: 0.820207]\n",
      "epoch4 step37835 [D loss: -0.348457] [G loss: 1.040308]\n",
      "epoch4 step37840 [D loss: -0.173391] [G loss: 1.075661]\n",
      "epoch4 step37845 [D loss: 0.157216] [G loss: 0.857625]\n",
      "epoch4 step37850 [D loss: -0.044242] [G loss: 1.110566]\n",
      "epoch4 step37855 [D loss: -0.240162] [G loss: 1.071152]\n",
      "epoch4 step37860 [D loss: -0.387965] [G loss: 1.110341]\n",
      "epoch4 step37865 [D loss: -0.288330] [G loss: 1.589249]\n",
      "epoch4 step37870 [D loss: -0.503307] [G loss: 1.591746]\n",
      "epoch4 step37875 [D loss: -0.356906] [G loss: 1.603257]\n",
      "epoch4 step37880 [D loss: -0.391661] [G loss: 1.293912]\n",
      "epoch4 step37885 [D loss: -0.783920] [G loss: 1.701603]\n",
      "epoch4 step37890 [D loss: -0.046526] [G loss: 1.058304]\n",
      "epoch4 step37895 [D loss: -0.041886] [G loss: 1.426856]\n",
      "epoch4 step37900 [D loss: -0.238178] [G loss: 1.255391]\n",
      "epoch4 step37905 [D loss: 0.005979] [G loss: 1.544187]\n",
      "epoch4 step37910 [D loss: -0.309814] [G loss: 1.152065]\n",
      "epoch4 step37915 [D loss: -0.190822] [G loss: 1.348917]\n",
      "epoch4 step37920 [D loss: -0.443065] [G loss: 1.246859]\n",
      "epoch4 step37925 [D loss: 0.031160] [G loss: 1.229655]\n",
      "epoch4 step37930 [D loss: -0.512768] [G loss: 1.121500]\n",
      "epoch4 step37935 [D loss: -0.175793] [G loss: 0.853773]\n",
      "epoch4 step37940 [D loss: 0.040264] [G loss: 0.803508]\n",
      "epoch4 step37945 [D loss: 0.493496] [G loss: 0.748544]\n",
      "epoch4 step37950 [D loss: -0.046379] [G loss: 0.957879]\n",
      "epoch4 step37955 [D loss: -0.071509] [G loss: 1.142784]\n",
      "epoch4 step37960 [D loss: -0.076002] [G loss: 0.688441]\n",
      "epoch4 step37965 [D loss: 0.076968] [G loss: 0.733281]\n",
      "epoch4 step37970 [D loss: 0.217563] [G loss: 0.761235]\n",
      "epoch4 step37975 [D loss: 0.047764] [G loss: 0.854282]\n",
      "epoch4 step37980 [D loss: 0.094267] [G loss: 0.736055]\n",
      "epoch4 step37985 [D loss: -0.078542] [G loss: 0.792953]\n",
      "epoch4 step37990 [D loss: -0.349985] [G loss: 0.826158]\n",
      "epoch4 step37995 [D loss: -0.177780] [G loss: 0.789507]\n",
      "epoch4 step38000 [D loss: -0.009501] [G loss: 0.736236]\n",
      "epoch4 step38005 [D loss: 0.041141] [G loss: 0.852449]\n",
      "epoch4 step38010 [D loss: -0.311276] [G loss: 0.809139]\n",
      "epoch4 step38015 [D loss: -0.037323] [G loss: 0.919773]\n",
      "epoch4 step38020 [D loss: 0.049488] [G loss: 0.722660]\n",
      "epoch4 step38025 [D loss: -0.090529] [G loss: 0.728405]\n",
      "epoch4 step38030 [D loss: -0.148383] [G loss: 0.590735]\n",
      "epoch4 step38035 [D loss: -0.336398] [G loss: 0.769114]\n",
      "epoch4 step38040 [D loss: -0.071896] [G loss: 0.671248]\n",
      "epoch4 step38045 [D loss: -0.474968] [G loss: 0.424658]\n",
      "epoch4 step38050 [D loss: -0.263023] [G loss: 0.862628]\n",
      "epoch4 step38055 [D loss: -0.420218] [G loss: 0.606227]\n",
      "epoch4 step38060 [D loss: -0.313377] [G loss: 0.468390]\n",
      "epoch4 step38065 [D loss: -0.550918] [G loss: 0.387143]\n",
      "epoch4 step38070 [D loss: -0.404661] [G loss: 0.544142]\n",
      "epoch4 step38075 [D loss: -0.401082] [G loss: 0.635972]\n",
      "epoch4 step38080 [D loss: -0.063555] [G loss: 0.874636]\n",
      "epoch4 step38085 [D loss: 0.071749] [G loss: 0.166503]\n",
      "epoch4 step38090 [D loss: -0.103442] [G loss: 0.845980]\n",
      "epoch4 step38095 [D loss: -0.365162] [G loss: 0.780734]\n",
      "epoch4 step38100 [D loss: 0.039347] [G loss: 0.795225]\n",
      "epoch4 step38105 [D loss: -0.196474] [G loss: 0.775828]\n",
      "epoch4 step38110 [D loss: 0.181777] [G loss: 0.557511]\n",
      "epoch4 step38115 [D loss: 0.297854] [G loss: 0.669369]\n",
      "epoch4 step38120 [D loss: 0.301964] [G loss: 0.611486]\n",
      "epoch4 step38125 [D loss: -0.207812] [G loss: 0.562095]\n",
      "epoch4 step38130 [D loss: 0.503494] [G loss: 0.527527]\n",
      "epoch4 step38135 [D loss: -0.160778] [G loss: 1.031808]\n",
      "epoch4 step38140 [D loss: -0.530398] [G loss: 0.951405]\n",
      "epoch4 step38145 [D loss: -0.333414] [G loss: 0.837592]\n",
      "epoch4 step38150 [D loss: -0.290828] [G loss: 1.062388]\n",
      "epoch4 step38155 [D loss: -0.018946] [G loss: 0.869934]\n",
      "epoch4 step38160 [D loss: 0.025094] [G loss: 0.965937]\n",
      "epoch4 step38165 [D loss: -0.517648] [G loss: 0.928129]\n",
      "epoch4 step38170 [D loss: -0.212059] [G loss: 1.017130]\n",
      "epoch4 step38175 [D loss: -0.478331] [G loss: 0.888854]\n",
      "epoch4 step38180 [D loss: -0.112315] [G loss: 1.141297]\n",
      "epoch4 step38185 [D loss: -0.155572] [G loss: 0.844827]\n",
      "epoch4 step38190 [D loss: -0.502000] [G loss: 0.862355]\n",
      "epoch4 step38195 [D loss: 0.178733] [G loss: 1.297579]\n",
      "epoch4 step38200 [D loss: -0.488431] [G loss: 1.476352]\n",
      "epoch4 step38205 [D loss: -0.296262] [G loss: 0.942171]\n",
      "epoch4 step38210 [D loss: 0.055549] [G loss: 1.215777]\n",
      "epoch4 step38215 [D loss: 0.144383] [G loss: 1.085330]\n",
      "epoch4 step38220 [D loss: -0.205878] [G loss: 1.225570]\n",
      "epoch4 step38225 [D loss: 0.051053] [G loss: 1.351498]\n",
      "epoch4 step38230 [D loss: -0.373962] [G loss: 1.142251]\n",
      "epoch4 step38235 [D loss: -0.093910] [G loss: 1.000022]\n",
      "epoch4 step38240 [D loss: -0.053704] [G loss: 1.355125]\n",
      "epoch4 step38245 [D loss: -0.723059] [G loss: 1.096899]\n",
      "epoch4 step38250 [D loss: 0.055868] [G loss: 1.235242]\n",
      "epoch4 step38255 [D loss: -0.016999] [G loss: 1.416646]\n",
      "epoch4 step38260 [D loss: 0.268172] [G loss: 1.811894]\n",
      "epoch4 step38265 [D loss: 0.034209] [G loss: 1.437271]\n",
      "epoch4 step38270 [D loss: -0.813624] [G loss: 1.046429]\n",
      "epoch4 step38275 [D loss: 0.454085] [G loss: 1.196817]\n",
      "epoch4 step38280 [D loss: -0.373860] [G loss: 1.124311]\n",
      "epoch4 step38285 [D loss: 0.109284] [G loss: 0.952111]\n",
      "epoch4 step38290 [D loss: -0.597668] [G loss: 1.319087]\n",
      "epoch4 step38295 [D loss: -0.366350] [G loss: 1.033954]\n",
      "epoch4 step38300 [D loss: 0.185582] [G loss: 1.217307]\n",
      "epoch4 step38305 [D loss: -0.041651] [G loss: 0.753941]\n",
      "epoch4 step38310 [D loss: 0.147028] [G loss: 1.269484]\n",
      "epoch4 step38315 [D loss: -0.199751] [G loss: 1.146850]\n",
      "epoch4 step38320 [D loss: 0.021285] [G loss: 1.318915]\n",
      "epoch4 step38325 [D loss: -0.696722] [G loss: 1.273559]\n",
      "epoch4 step38330 [D loss: -0.014100] [G loss: 1.006971]\n",
      "epoch4 step38335 [D loss: 0.132579] [G loss: 1.036517]\n",
      "epoch4 step38340 [D loss: 0.032107] [G loss: 1.024394]\n",
      "epoch4 step38345 [D loss: -0.181265] [G loss: 0.986577]\n",
      "epoch4 step38350 [D loss: -0.380841] [G loss: 1.087425]\n",
      "epoch4 step38355 [D loss: -0.138407] [G loss: 0.997015]\n",
      "epoch4 step38360 [D loss: -0.021590] [G loss: 0.929587]\n",
      "epoch4 step38365 [D loss: -0.197951] [G loss: 0.855290]\n",
      "epoch4 step38370 [D loss: -0.131623] [G loss: 0.702701]\n",
      "epoch4 step38375 [D loss: -0.204697] [G loss: 0.816524]\n",
      "epoch4 step38380 [D loss: -0.394669] [G loss: 0.838057]\n",
      "epoch4 step38385 [D loss: -0.393898] [G loss: 0.952822]\n",
      "epoch4 step38390 [D loss: 0.155096] [G loss: 0.430942]\n",
      "epoch4 step38395 [D loss: -0.234029] [G loss: 0.756381]\n",
      "epoch4 step38400 [D loss: 0.137116] [G loss: 0.923052]\n",
      "epoch4 step38405 [D loss: -0.035858] [G loss: 0.453788]\n",
      "epoch4 step38410 [D loss: -0.088185] [G loss: 1.113087]\n",
      "epoch4 step38415 [D loss: 0.297302] [G loss: 0.502564]\n",
      "epoch4 step38420 [D loss: 0.039832] [G loss: 0.968955]\n",
      "epoch4 step38425 [D loss: -0.341849] [G loss: 0.878672]\n",
      "epoch4 step38430 [D loss: -0.011033] [G loss: 0.646642]\n",
      "epoch4 step38435 [D loss: -0.318041] [G loss: 0.446508]\n",
      "epoch4 step38440 [D loss: -0.324458] [G loss: 0.704796]\n",
      "epoch4 step38445 [D loss: 0.166105] [G loss: 0.474598]\n",
      "epoch4 step38450 [D loss: -0.133679] [G loss: 0.630232]\n",
      "epoch4 step38455 [D loss: 0.317913] [G loss: 0.432633]\n",
      "epoch4 step38460 [D loss: -0.484511] [G loss: 0.523120]\n",
      "epoch4 step38465 [D loss: -0.232025] [G loss: 0.389066]\n",
      "epoch4 step38470 [D loss: 0.061012] [G loss: 0.421283]\n",
      "epoch4 step38475 [D loss: -0.259690] [G loss: 0.516379]\n",
      "epoch4 step38480 [D loss: -0.778935] [G loss: 0.864083]\n",
      "epoch4 step38485 [D loss: -0.318198] [G loss: 0.357289]\n",
      "epoch4 step38490 [D loss: -0.006677] [G loss: 0.410272]\n",
      "epoch4 step38495 [D loss: -0.399491] [G loss: 0.392354]\n",
      "epoch4 step38500 [D loss: -0.022378] [G loss: 0.564821]\n",
      "epoch4 step38505 [D loss: 0.118593] [G loss: 0.535317]\n",
      "epoch4 step38510 [D loss: -0.221850] [G loss: 0.466570]\n",
      "epoch4 step38515 [D loss: -0.265687] [G loss: 0.618801]\n",
      "epoch4 step38520 [D loss: 0.156121] [G loss: 0.592858]\n",
      "epoch4 step38525 [D loss: -0.241932] [G loss: 0.819139]\n",
      "epoch4 step38530 [D loss: -0.244704] [G loss: 0.488535]\n",
      "epoch4 step38535 [D loss: 0.177172] [G loss: 0.493168]\n",
      "epoch4 step38540 [D loss: -0.039050] [G loss: 0.447251]\n",
      "epoch4 step38545 [D loss: -0.005635] [G loss: 0.410558]\n",
      "epoch4 step38550 [D loss: 0.247743] [G loss: 0.748411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4 step38555 [D loss: -0.101032] [G loss: 0.586159]\n",
      "epoch4 step38560 [D loss: 0.204348] [G loss: 0.249862]\n",
      "epoch4 step38565 [D loss: 0.024698] [G loss: 0.348972]\n",
      "epoch4 step38570 [D loss: -0.223584] [G loss: 0.345269]\n",
      "epoch4 step38575 [D loss: 0.033021] [G loss: 0.903093]\n",
      "epoch4 step38580 [D loss: -0.150962] [G loss: 0.312235]\n",
      "epoch4 step38585 [D loss: -0.178772] [G loss: 0.061702]\n",
      "epoch4 step38590 [D loss: -0.396254] [G loss: 0.377465]\n",
      "epoch4 step38595 [D loss: -0.324062] [G loss: 0.192193]\n",
      "epoch4 step38600 [D loss: -0.044659] [G loss: 0.111903]\n",
      "epoch4 step38605 [D loss: -0.299494] [G loss: 0.303929]\n",
      "epoch4 step38610 [D loss: -0.263431] [G loss: 0.360504]\n",
      "epoch4 step38615 [D loss: 0.335315] [G loss: 0.526120]\n",
      "epoch4 step38620 [D loss: 0.028594] [G loss: 0.464843]\n",
      "epoch4 step38625 [D loss: -0.025432] [G loss: 0.185295]\n",
      "epoch4 step38630 [D loss: -0.148510] [G loss: 0.250841]\n",
      "epoch4 step38635 [D loss: 0.020103] [G loss: 0.375394]\n",
      "epoch4 step38640 [D loss: 0.009393] [G loss: 0.176363]\n",
      "epoch4 step38645 [D loss: -0.101497] [G loss: 0.499520]\n",
      "epoch4 step38650 [D loss: 0.128206] [G loss: 0.199675]\n",
      "epoch4 step38655 [D loss: 0.336936] [G loss: 0.440083]\n",
      "epoch4 step38660 [D loss: -0.237644] [G loss: 0.441008]\n",
      "epoch4 step38665 [D loss: -0.087011] [G loss: 0.817121]\n",
      "epoch4 step38670 [D loss: 0.086509] [G loss: 0.527076]\n",
      "epoch4 step38675 [D loss: 0.293768] [G loss: 0.197427]\n",
      "epoch4 step38680 [D loss: 0.362459] [G loss: 0.344754]\n",
      "epoch4 step38685 [D loss: 0.092052] [G loss: 0.415952]\n",
      "epoch4 step38690 [D loss: -0.588015] [G loss: 0.716311]\n",
      "epoch4 step38695 [D loss: -0.095696] [G loss: 0.949182]\n",
      "epoch4 step38700 [D loss: -0.141069] [G loss: 0.705941]\n",
      "epoch4 step38705 [D loss: -0.458648] [G loss: 0.493114]\n",
      "epoch4 step38710 [D loss: -0.154641] [G loss: 0.870361]\n",
      "epoch4 step38715 [D loss: 0.075539] [G loss: 1.027798]\n",
      "epoch4 step38720 [D loss: -0.011003] [G loss: 0.870811]\n",
      "epoch4 step38725 [D loss: -0.106571] [G loss: 0.515452]\n",
      "epoch4 step38730 [D loss: -0.245742] [G loss: 0.808589]\n",
      "epoch4 step38735 [D loss: -0.856881] [G loss: 0.659700]\n",
      "epoch4 step38740 [D loss: -0.507917] [G loss: 1.112059]\n",
      "epoch4 step38745 [D loss: -0.409638] [G loss: 0.972812]\n",
      "epoch4 step38750 [D loss: -0.087039] [G loss: 1.045831]\n",
      "epoch4 step38755 [D loss: -0.192872] [G loss: 0.857588]\n",
      "epoch4 step38760 [D loss: 0.005865] [G loss: 1.426026]\n",
      "epoch4 step38765 [D loss: -0.184081] [G loss: 1.178993]\n",
      "epoch4 step38770 [D loss: 0.082548] [G loss: 0.827941]\n",
      "epoch4 step38775 [D loss: -0.579089] [G loss: 0.895044]\n",
      "epoch4 step38780 [D loss: -0.353867] [G loss: 1.228911]\n",
      "epoch4 step38785 [D loss: -0.311145] [G loss: 1.112124]\n",
      "epoch4 step38790 [D loss: 0.012552] [G loss: 1.065448]\n",
      "epoch4 step38795 [D loss: -0.162361] [G loss: 0.522742]\n",
      "epoch4 step38800 [D loss: -0.087315] [G loss: 1.066364]\n",
      "epoch4 step38805 [D loss: -0.443493] [G loss: 1.062714]\n",
      "epoch4 step38810 [D loss: 0.268468] [G loss: 0.840122]\n",
      "epoch4 step38815 [D loss: 0.056470] [G loss: 0.838018]\n",
      "epoch4 step38820 [D loss: 0.013218] [G loss: 0.916811]\n",
      "epoch4 step38825 [D loss: -0.321233] [G loss: 1.185294]\n",
      "epoch4 step38830 [D loss: -0.011100] [G loss: 1.017377]\n",
      "epoch4 step38835 [D loss: 0.026006] [G loss: 0.388022]\n",
      "epoch4 step38840 [D loss: 0.034526] [G loss: 0.359932]\n",
      "epoch4 step38845 [D loss: -0.251857] [G loss: 1.128790]\n",
      "epoch4 step38850 [D loss: 0.133351] [G loss: 0.435670]\n",
      "epoch4 step38855 [D loss: 0.366824] [G loss: 0.772007]\n",
      "epoch4 step38860 [D loss: -0.337599] [G loss: 0.746770]\n",
      "epoch4 step38865 [D loss: -0.593736] [G loss: 0.711387]\n",
      "epoch4 step38870 [D loss: 0.140692] [G loss: 0.295975]\n",
      "epoch4 step38875 [D loss: 0.002679] [G loss: 0.372201]\n",
      "epoch4 step38880 [D loss: 0.150911] [G loss: 0.534743]\n",
      "epoch4 step38885 [D loss: 0.033103] [G loss: 0.930106]\n",
      "epoch4 step38890 [D loss: -0.315674] [G loss: 0.465992]\n",
      "epoch4 step38895 [D loss: -0.095384] [G loss: 0.642028]\n",
      "epoch4 step38900 [D loss: -0.435815] [G loss: 0.376541]\n",
      "epoch4 step38905 [D loss: -0.696919] [G loss: 0.633649]\n",
      "epoch4 step38910 [D loss: -0.120185] [G loss: 0.393942]\n",
      "epoch4 step38915 [D loss: -0.237055] [G loss: 0.682665]\n",
      "epoch4 step38920 [D loss: -0.268818] [G loss: 0.782471]\n",
      "epoch4 step38925 [D loss: 0.198203] [G loss: 0.444463]\n",
      "epoch4 step38930 [D loss: -0.008023] [G loss: 0.505085]\n",
      "epoch4 step38935 [D loss: -0.375752] [G loss: 0.515465]\n",
      "epoch4 step38940 [D loss: -0.152754] [G loss: 0.117904]\n",
      "epoch4 step38945 [D loss: 0.051486] [G loss: 0.464849]\n",
      "epoch4 step38950 [D loss: 0.360030] [G loss: 0.662513]\n",
      "epoch4 step38955 [D loss: -0.497344] [G loss: 0.730023]\n",
      "epoch4 step38960 [D loss: -0.015249] [G loss: 0.731572]\n",
      "epoch4 step38965 [D loss: -0.585811] [G loss: 0.892555]\n",
      "epoch4 step38970 [D loss: -0.238014] [G loss: 0.740890]\n",
      "epoch4 step38975 [D loss: -0.046215] [G loss: 0.501039]\n",
      "epoch4 step38980 [D loss: -0.341909] [G loss: 0.810096]\n",
      "epoch4 step38985 [D loss: -0.493018] [G loss: 0.696849]\n",
      "epoch4 step38990 [D loss: -0.216032] [G loss: 0.351414]\n",
      "epoch4 step38995 [D loss: -0.292641] [G loss: 0.626809]\n",
      "epoch4 step39000 [D loss: -0.428547] [G loss: 0.662441]\n",
      "epoch4 step39005 [D loss: -0.009601] [G loss: 0.712980]\n",
      "epoch4 step39010 [D loss: 0.272679] [G loss: 0.564441]\n",
      "epoch4 step39015 [D loss: -0.044320] [G loss: 0.940276]\n",
      "epoch4 step39020 [D loss: 0.172730] [G loss: 0.389356]\n",
      "epoch4 step39025 [D loss: 0.161737] [G loss: 0.554784]\n",
      "epoch4 step39030 [D loss: -0.540073] [G loss: 0.396750]\n",
      "epoch4 step39035 [D loss: -0.107739] [G loss: 0.766360]\n",
      "epoch4 step39040 [D loss: 0.413314] [G loss: 0.205461]\n",
      "epoch4 step39045 [D loss: -0.218962] [G loss: 0.338155]\n",
      "epoch4 step39050 [D loss: 0.048223] [G loss: 0.673382]\n",
      "epoch5 step39055 [D loss: 0.177365] [G loss: 0.510561]\n",
      "epoch5 step39060 [D loss: -0.000738] [G loss: 0.613439]\n",
      "epoch5 step39065 [D loss: 0.049881] [G loss: 0.622937]\n",
      "epoch5 step39070 [D loss: -0.185095] [G loss: 0.600434]\n",
      "epoch5 step39075 [D loss: -0.123926] [G loss: 0.902632]\n",
      "epoch5 step39080 [D loss: -0.119527] [G loss: 0.513401]\n",
      "epoch5 step39085 [D loss: -0.224885] [G loss: 0.657230]\n",
      "epoch5 step39090 [D loss: 0.249351] [G loss: 0.822211]\n",
      "epoch5 step39095 [D loss: 0.384100] [G loss: 0.748721]\n",
      "epoch5 step39100 [D loss: -0.110414] [G loss: 0.409508]\n",
      "epoch5 step39105 [D loss: 0.288780] [G loss: 0.599367]\n",
      "epoch5 step39110 [D loss: 0.015389] [G loss: 0.751751]\n",
      "epoch5 step39115 [D loss: -0.288274] [G loss: 0.391347]\n",
      "epoch5 step39120 [D loss: 0.000179] [G loss: 0.946753]\n",
      "epoch5 step39125 [D loss: -0.350269] [G loss: 0.527901]\n",
      "epoch5 step39130 [D loss: -0.243725] [G loss: 0.735029]\n",
      "epoch5 step39135 [D loss: 0.247218] [G loss: 0.621206]\n",
      "epoch5 step39140 [D loss: -0.066562] [G loss: 0.807365]\n",
      "epoch5 step39145 [D loss: -0.401388] [G loss: 0.788901]\n",
      "epoch5 step39150 [D loss: 0.091348] [G loss: 0.793732]\n",
      "epoch5 step39155 [D loss: -0.312092] [G loss: 1.210978]\n",
      "epoch5 step39160 [D loss: -0.596578] [G loss: 0.944708]\n",
      "epoch5 step39165 [D loss: 0.042064] [G loss: 0.925412]\n",
      "epoch5 step39170 [D loss: -0.055942] [G loss: 0.899523]\n",
      "epoch5 step39175 [D loss: 0.453923] [G loss: 0.673761]\n",
      "epoch5 step39180 [D loss: -0.245406] [G loss: 0.735355]\n",
      "epoch5 step39185 [D loss: -0.111268] [G loss: 0.822652]\n",
      "epoch5 step39190 [D loss: -0.271317] [G loss: 0.878522]\n",
      "epoch5 step39195 [D loss: -0.274037] [G loss: 1.034158]\n",
      "epoch5 step39200 [D loss: -0.082622] [G loss: 0.949301]\n",
      "epoch5 step39205 [D loss: -0.003867] [G loss: 0.619344]\n",
      "epoch5 step39210 [D loss: 0.374809] [G loss: 0.920447]\n",
      "epoch5 step39215 [D loss: 0.227150] [G loss: 1.007160]\n",
      "epoch5 step39220 [D loss: -0.351771] [G loss: 1.078743]\n",
      "epoch5 step39225 [D loss: 0.103494] [G loss: 1.095131]\n",
      "epoch5 step39230 [D loss: 0.096294] [G loss: 0.814603]\n",
      "epoch5 step39235 [D loss: -0.230990] [G loss: 1.001576]\n",
      "epoch5 step39240 [D loss: -0.281096] [G loss: 1.181100]\n",
      "epoch5 step39245 [D loss: -0.205400] [G loss: 1.092244]\n",
      "epoch5 step39250 [D loss: 0.081975] [G loss: 1.275838]\n",
      "epoch5 step39255 [D loss: -0.229763] [G loss: 1.232123]\n",
      "epoch5 step39260 [D loss: -0.184551] [G loss: 1.131432]\n",
      "epoch5 step39265 [D loss: -0.365739] [G loss: 1.465836]\n",
      "epoch5 step39270 [D loss: -0.588351] [G loss: 1.370272]\n",
      "epoch5 step39275 [D loss: -0.160343] [G loss: 0.890290]\n",
      "epoch5 step39280 [D loss: -0.165385] [G loss: 0.712087]\n",
      "epoch5 step39285 [D loss: -0.313905] [G loss: 1.251887]\n",
      "epoch5 step39290 [D loss: 0.148452] [G loss: 1.009601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step39295 [D loss: -0.149123] [G loss: 1.465499]\n",
      "epoch5 step39300 [D loss: -0.023333] [G loss: 1.248358]\n",
      "epoch5 step39305 [D loss: -0.490337] [G loss: 1.154733]\n",
      "epoch5 step39310 [D loss: 0.043640] [G loss: 1.142454]\n",
      "epoch5 step39315 [D loss: 0.138959] [G loss: 1.015935]\n",
      "epoch5 step39320 [D loss: -0.069970] [G loss: 1.387911]\n",
      "epoch5 step39325 [D loss: -0.123117] [G loss: 0.594997]\n",
      "epoch5 step39330 [D loss: -0.396979] [G loss: 0.506799]\n",
      "epoch5 step39335 [D loss: -0.005090] [G loss: 0.845592]\n",
      "epoch5 step39340 [D loss: 0.210339] [G loss: 0.685536]\n",
      "epoch5 step39345 [D loss: -0.313554] [G loss: 0.599249]\n",
      "epoch5 step39350 [D loss: 0.075970] [G loss: 0.868477]\n",
      "epoch5 step39355 [D loss: -0.125197] [G loss: 0.884977]\n",
      "epoch5 step39360 [D loss: -0.266079] [G loss: 1.011150]\n",
      "epoch5 step39365 [D loss: -0.608320] [G loss: 0.919484]\n",
      "epoch5 step39370 [D loss: -0.170787] [G loss: 0.854211]\n",
      "epoch5 step39375 [D loss: -0.209797] [G loss: 0.685134]\n",
      "epoch5 step39380 [D loss: -0.329776] [G loss: 0.497278]\n",
      "epoch5 step39385 [D loss: -0.521593] [G loss: 0.590841]\n",
      "epoch5 step39390 [D loss: 0.444798] [G loss: 0.674161]\n",
      "epoch5 step39395 [D loss: -0.037045] [G loss: 0.650022]\n",
      "epoch5 step39400 [D loss: 0.531330] [G loss: 0.517206]\n",
      "epoch5 step39405 [D loss: -0.653155] [G loss: 1.052004]\n",
      "epoch5 step39410 [D loss: -0.287417] [G loss: 0.932837]\n",
      "epoch5 step39415 [D loss: -0.113025] [G loss: 0.714504]\n",
      "epoch5 step39420 [D loss: -0.050157] [G loss: 0.858273]\n",
      "epoch5 step39425 [D loss: 0.443569] [G loss: 0.256455]\n",
      "epoch5 step39430 [D loss: -0.139127] [G loss: 0.584114]\n",
      "epoch5 step39435 [D loss: -0.086960] [G loss: 0.658689]\n",
      "epoch5 step39440 [D loss: -0.214626] [G loss: 0.903463]\n",
      "epoch5 step39445 [D loss: 0.286254] [G loss: 0.864738]\n",
      "epoch5 step39450 [D loss: -0.079391] [G loss: 1.156433]\n",
      "epoch5 step39455 [D loss: 0.128834] [G loss: 0.846317]\n",
      "epoch5 step39460 [D loss: -0.726943] [G loss: 0.881461]\n",
      "epoch5 step39465 [D loss: -0.714058] [G loss: 0.958814]\n",
      "epoch5 step39470 [D loss: -0.567150] [G loss: 1.058334]\n",
      "epoch5 step39475 [D loss: -0.203892] [G loss: 0.863633]\n",
      "epoch5 step39480 [D loss: -0.369900] [G loss: 0.882703]\n",
      "epoch5 step39485 [D loss: 0.173083] [G loss: 0.811779]\n",
      "epoch5 step39490 [D loss: -0.203579] [G loss: 1.092203]\n",
      "epoch5 step39495 [D loss: -0.534108] [G loss: 1.313169]\n",
      "epoch5 step39500 [D loss: -0.095979] [G loss: 1.029961]\n",
      "epoch5 step39505 [D loss: -0.477874] [G loss: 1.049523]\n",
      "epoch5 step39510 [D loss: -0.378543] [G loss: 1.188401]\n",
      "epoch5 step39515 [D loss: 0.322326] [G loss: 1.120623]\n",
      "epoch5 step39520 [D loss: -0.233167] [G loss: 1.054579]\n",
      "epoch5 step39525 [D loss: -0.350961] [G loss: 1.166217]\n",
      "epoch5 step39530 [D loss: -0.075888] [G loss: 1.061720]\n",
      "epoch5 step39535 [D loss: -0.031411] [G loss: 1.023463]\n",
      "epoch5 step39540 [D loss: 0.091059] [G loss: 0.498864]\n",
      "epoch5 step39545 [D loss: -0.302439] [G loss: 1.237588]\n",
      "epoch5 step39550 [D loss: -0.131959] [G loss: 0.623860]\n",
      "epoch5 step39555 [D loss: -0.245266] [G loss: 0.989596]\n",
      "epoch5 step39560 [D loss: -0.176813] [G loss: 1.063794]\n",
      "epoch5 step39565 [D loss: 0.564927] [G loss: 0.714051]\n",
      "epoch5 step39570 [D loss: -0.399268] [G loss: 1.134320]\n",
      "epoch5 step39575 [D loss: 0.005917] [G loss: 1.072695]\n",
      "epoch5 step39580 [D loss: -0.033013] [G loss: 0.997081]\n",
      "epoch5 step39585 [D loss: 0.230899] [G loss: 0.737233]\n",
      "epoch5 step39590 [D loss: 0.233788] [G loss: 0.804359]\n",
      "epoch5 step39595 [D loss: 0.060531] [G loss: 1.147509]\n",
      "epoch5 step39600 [D loss: -0.057112] [G loss: 0.804335]\n",
      "epoch5 step39605 [D loss: 0.104390] [G loss: 0.833595]\n",
      "epoch5 step39610 [D loss: -0.335635] [G loss: 0.793520]\n",
      "epoch5 step39615 [D loss: -0.420086] [G loss: 0.920958]\n",
      "epoch5 step39620 [D loss: 0.014178] [G loss: 0.641685]\n",
      "epoch5 step39625 [D loss: -0.418903] [G loss: 0.820145]\n",
      "epoch5 step39630 [D loss: -0.513478] [G loss: 1.038230]\n",
      "epoch5 step39635 [D loss: -0.433144] [G loss: 0.642350]\n",
      "epoch5 step39640 [D loss: -0.300066] [G loss: 0.784840]\n",
      "epoch5 step39645 [D loss: -0.332324] [G loss: 0.534777]\n",
      "epoch5 step39650 [D loss: -0.188206] [G loss: 0.885724]\n",
      "epoch5 step39655 [D loss: 0.009633] [G loss: 0.836673]\n",
      "epoch5 step39660 [D loss: 0.006552] [G loss: 0.531784]\n",
      "epoch5 step39665 [D loss: 0.004495] [G loss: 0.461118]\n",
      "epoch5 step39670 [D loss: -0.118326] [G loss: 0.622154]\n",
      "epoch5 step39675 [D loss: -0.230920] [G loss: 0.823505]\n",
      "epoch5 step39680 [D loss: -0.486967] [G loss: 0.737384]\n",
      "epoch5 step39685 [D loss: -0.253145] [G loss: 0.212417]\n",
      "epoch5 step39690 [D loss: -0.287956] [G loss: 0.697114]\n",
      "epoch5 step39695 [D loss: -0.363839] [G loss: 0.472689]\n",
      "epoch5 step39700 [D loss: -0.403652] [G loss: 0.341418]\n",
      "epoch5 step39705 [D loss: 0.075785] [G loss: 0.249319]\n",
      "epoch5 step39710 [D loss: -0.485476] [G loss: 1.193063]\n",
      "epoch5 step39715 [D loss: -0.433995] [G loss: 0.507822]\n",
      "epoch5 step39720 [D loss: -0.024261] [G loss: 0.681463]\n",
      "epoch5 step39725 [D loss: -0.126555] [G loss: 0.490430]\n",
      "epoch5 step39730 [D loss: -0.066256] [G loss: 0.615232]\n",
      "epoch5 step39735 [D loss: -0.529337] [G loss: 0.908032]\n",
      "epoch5 step39740 [D loss: -0.788449] [G loss: 0.943872]\n",
      "epoch5 step39745 [D loss: -0.118532] [G loss: 0.624981]\n",
      "epoch5 step39750 [D loss: 0.158161] [G loss: 0.720136]\n",
      "epoch5 step39755 [D loss: 0.074169] [G loss: 0.615251]\n",
      "epoch5 step39760 [D loss: 0.199049] [G loss: 0.788552]\n",
      "epoch5 step39765 [D loss: 0.011411] [G loss: 0.354829]\n",
      "epoch5 step39770 [D loss: -0.517048] [G loss: 0.734509]\n",
      "epoch5 step39775 [D loss: -0.049871] [G loss: 0.503453]\n",
      "epoch5 step39780 [D loss: 0.072076] [G loss: 0.516884]\n",
      "epoch5 step39785 [D loss: -0.604260] [G loss: 0.355014]\n",
      "epoch5 step39790 [D loss: -0.135012] [G loss: 0.373428]\n",
      "epoch5 step39795 [D loss: -0.171041] [G loss: 0.433627]\n",
      "epoch5 step39800 [D loss: 0.066222] [G loss: 0.245712]\n",
      "epoch5 step39805 [D loss: 0.401890] [G loss: 0.651822]\n",
      "epoch5 step39810 [D loss: -0.007813] [G loss: 0.437045]\n",
      "epoch5 step39815 [D loss: 0.145557] [G loss: 0.506301]\n",
      "epoch5 step39820 [D loss: -0.248288] [G loss: 0.832847]\n",
      "epoch5 step39825 [D loss: -0.219938] [G loss: 0.450910]\n",
      "epoch5 step39830 [D loss: -0.569945] [G loss: 0.816113]\n",
      "epoch5 step39835 [D loss: -0.090822] [G loss: 0.414479]\n",
      "epoch5 step39840 [D loss: -0.090378] [G loss: 0.625676]\n",
      "epoch5 step39845 [D loss: 0.041082] [G loss: 0.709893]\n",
      "epoch5 step39850 [D loss: 0.286924] [G loss: 0.536310]\n",
      "epoch5 step39855 [D loss: 0.005446] [G loss: 0.295273]\n",
      "epoch5 step39860 [D loss: -0.123329] [G loss: 0.319071]\n",
      "epoch5 step39865 [D loss: -0.344108] [G loss: 0.938315]\n",
      "epoch5 step39870 [D loss: -0.382246] [G loss: 0.859334]\n",
      "epoch5 step39875 [D loss: 0.177009] [G loss: 0.140950]\n",
      "epoch5 step39880 [D loss: -0.374210] [G loss: 0.697422]\n",
      "epoch5 step39885 [D loss: -0.159042] [G loss: 0.742272]\n",
      "epoch5 step39890 [D loss: 0.165562] [G loss: 0.732530]\n",
      "epoch5 step39895 [D loss: 0.325774] [G loss: 0.613415]\n",
      "epoch5 step39900 [D loss: -0.408550] [G loss: 0.574952]\n",
      "epoch5 step39905 [D loss: -0.044876] [G loss: 0.819206]\n",
      "epoch5 step39910 [D loss: -0.203408] [G loss: 1.144564]\n",
      "epoch5 step39915 [D loss: 0.114893] [G loss: 0.694257]\n",
      "epoch5 step39920 [D loss: -0.138837] [G loss: 1.052075]\n",
      "epoch5 step39925 [D loss: -0.159062] [G loss: 1.023475]\n",
      "epoch5 step39930 [D loss: -0.221364] [G loss: 1.020298]\n",
      "epoch5 step39935 [D loss: -0.442698] [G loss: 0.686554]\n",
      "epoch5 step39940 [D loss: 0.165594] [G loss: 0.901717]\n",
      "epoch5 step39945 [D loss: -0.202710] [G loss: 1.038989]\n",
      "epoch5 step39950 [D loss: -0.292612] [G loss: 1.072285]\n",
      "epoch5 step39955 [D loss: -0.890536] [G loss: 1.128614]\n",
      "epoch5 step39960 [D loss: -0.319829] [G loss: 1.013161]\n",
      "epoch5 step39965 [D loss: 0.064341] [G loss: 0.846519]\n",
      "epoch5 step39970 [D loss: -0.098238] [G loss: 0.794501]\n",
      "epoch5 step39975 [D loss: -0.007495] [G loss: 1.124262]\n",
      "epoch5 step39980 [D loss: 0.038390] [G loss: 1.045612]\n",
      "epoch5 step39985 [D loss: 0.041100] [G loss: 1.083003]\n",
      "epoch5 step39990 [D loss: 0.047062] [G loss: 0.983946]\n",
      "epoch5 step39995 [D loss: -0.024028] [G loss: 1.068367]\n",
      "epoch5 step40000 [D loss: 0.482864] [G loss: 1.014511]\n",
      "epoch5 step40005 [D loss: -0.612970] [G loss: 1.134750]\n",
      "epoch5 step40010 [D loss: 0.038618] [G loss: 1.301316]\n",
      "epoch5 step40015 [D loss: -0.512159] [G loss: 1.367754]\n",
      "epoch5 step40020 [D loss: -0.420347] [G loss: 1.010302]\n",
      "epoch5 step40025 [D loss: -0.002261] [G loss: 0.919935]\n",
      "epoch5 step40030 [D loss: -0.226063] [G loss: 1.187284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step40035 [D loss: -0.487138] [G loss: 0.970481]\n",
      "epoch5 step40040 [D loss: 0.371774] [G loss: 0.593079]\n",
      "epoch5 step40045 [D loss: -0.233217] [G loss: 0.590872]\n",
      "epoch5 step40050 [D loss: -0.430027] [G loss: 0.640157]\n",
      "epoch5 step40055 [D loss: -0.313490] [G loss: 0.895253]\n",
      "epoch5 step40060 [D loss: 0.258189] [G loss: 0.160898]\n",
      "epoch5 step40065 [D loss: -0.455206] [G loss: 0.929784]\n",
      "epoch5 step40070 [D loss: -0.233934] [G loss: 0.847616]\n",
      "epoch5 step40075 [D loss: -0.399845] [G loss: 0.793692]\n",
      "epoch5 step40080 [D loss: -0.395065] [G loss: 0.993490]\n",
      "epoch5 step40085 [D loss: -0.077175] [G loss: 0.692849]\n",
      "epoch5 step40090 [D loss: -0.316945] [G loss: 0.582817]\n",
      "epoch5 step40095 [D loss: 0.082722] [G loss: 0.378549]\n",
      "epoch5 step40100 [D loss: -0.277425] [G loss: 0.317604]\n",
      "epoch5 step40105 [D loss: -0.459789] [G loss: 0.413793]\n",
      "epoch5 step40110 [D loss: -0.150013] [G loss: 0.561805]\n",
      "epoch5 step40115 [D loss: -0.265191] [G loss: 0.494882]\n",
      "epoch5 step40120 [D loss: -0.268272] [G loss: 0.664123]\n",
      "epoch5 step40125 [D loss: 0.451838] [G loss: 0.422457]\n",
      "epoch5 step40130 [D loss: -0.119252] [G loss: 0.139538]\n",
      "epoch5 step40135 [D loss: -0.571357] [G loss: 0.309805]\n",
      "epoch5 step40140 [D loss: -0.092104] [G loss: 0.227284]\n",
      "epoch5 step40145 [D loss: -0.407013] [G loss: 0.000287]\n",
      "epoch5 step40150 [D loss: -0.410057] [G loss: -0.278575]\n",
      "epoch5 step40155 [D loss: -0.144784] [G loss: 0.455636]\n",
      "epoch5 step40160 [D loss: 0.383306] [G loss: -0.087599]\n",
      "epoch5 step40165 [D loss: -0.304777] [G loss: 0.124526]\n",
      "epoch5 step40170 [D loss: -0.360245] [G loss: 0.271836]\n",
      "epoch5 step40175 [D loss: 0.288663] [G loss: 0.001686]\n",
      "epoch5 step40180 [D loss: -0.235765] [G loss: 0.447933]\n",
      "epoch5 step40185 [D loss: -0.086822] [G loss: 0.171261]\n",
      "epoch5 step40190 [D loss: 0.158476] [G loss: 0.427078]\n",
      "epoch5 step40195 [D loss: -0.082248] [G loss: 0.497162]\n",
      "epoch5 step40200 [D loss: 0.107822] [G loss: 0.616409]\n",
      "epoch5 step40205 [D loss: -0.438640] [G loss: 0.475845]\n",
      "epoch5 step40210 [D loss: -0.359179] [G loss: 0.403120]\n",
      "epoch5 step40215 [D loss: 0.102138] [G loss: 0.308018]\n",
      "epoch5 step40220 [D loss: -0.257978] [G loss: 0.556719]\n",
      "epoch5 step40225 [D loss: -0.037256] [G loss: 0.553140]\n",
      "epoch5 step40230 [D loss: -0.429595] [G loss: 0.664949]\n",
      "epoch5 step40235 [D loss: -0.231285] [G loss: 0.656292]\n",
      "epoch5 step40240 [D loss: -0.224589] [G loss: 0.716427]\n",
      "epoch5 step40245 [D loss: -0.023349] [G loss: 0.861207]\n",
      "epoch5 step40250 [D loss: -0.269301] [G loss: 1.119321]\n",
      "epoch5 step40255 [D loss: -0.365195] [G loss: 0.825730]\n",
      "epoch5 step40260 [D loss: -0.305462] [G loss: 0.758727]\n",
      "epoch5 step40265 [D loss: -0.418919] [G loss: 1.083284]\n",
      "epoch5 step40270 [D loss: 0.033830] [G loss: 0.888841]\n",
      "epoch5 step40275 [D loss: 0.369187] [G loss: 1.158957]\n",
      "epoch5 step40280 [D loss: -0.014227] [G loss: 1.086192]\n",
      "epoch5 step40285 [D loss: -0.138425] [G loss: 0.708721]\n",
      "epoch5 step40290 [D loss: -0.105103] [G loss: 0.565014]\n",
      "epoch5 step40295 [D loss: -0.308219] [G loss: 0.789495]\n",
      "epoch5 step40300 [D loss: -0.469001] [G loss: 1.057362]\n",
      "epoch5 step40305 [D loss: -0.070829] [G loss: 1.142254]\n",
      "epoch5 step40310 [D loss: 0.346332] [G loss: 0.945830]\n",
      "epoch5 step40315 [D loss: -0.047370] [G loss: 1.006716]\n",
      "epoch5 step40320 [D loss: -0.071735] [G loss: 1.110889]\n",
      "epoch5 step40325 [D loss: 0.300079] [G loss: 0.915832]\n",
      "epoch5 step40330 [D loss: 0.084702] [G loss: 0.901585]\n",
      "epoch5 step40335 [D loss: -0.347024] [G loss: 1.148934]\n",
      "epoch5 step40340 [D loss: -0.170695] [G loss: 0.872475]\n",
      "epoch5 step40345 [D loss: 0.265469] [G loss: 0.973395]\n",
      "epoch5 step40350 [D loss: 0.063247] [G loss: 0.769514]\n",
      "epoch5 step40355 [D loss: -0.040324] [G loss: 0.943261]\n",
      "epoch5 step40360 [D loss: -0.384317] [G loss: 0.915268]\n",
      "epoch5 step40365 [D loss: -0.114965] [G loss: 0.933736]\n",
      "epoch5 step40370 [D loss: -0.373859] [G loss: 1.046493]\n",
      "epoch5 step40375 [D loss: -0.583202] [G loss: 0.783778]\n",
      "epoch5 step40380 [D loss: -0.307574] [G loss: 0.843498]\n",
      "epoch5 step40385 [D loss: -0.214834] [G loss: 0.895888]\n",
      "epoch5 step40390 [D loss: 0.042111] [G loss: 1.014811]\n",
      "epoch5 step40395 [D loss: -0.031044] [G loss: 1.033593]\n",
      "epoch5 step40400 [D loss: -0.116524] [G loss: 0.586104]\n",
      "epoch5 step40405 [D loss: -0.078375] [G loss: 0.857182]\n",
      "epoch5 step40410 [D loss: -0.315657] [G loss: 0.908760]\n",
      "epoch5 step40415 [D loss: -0.224815] [G loss: 0.978065]\n",
      "epoch5 step40420 [D loss: -0.281723] [G loss: 0.536839]\n",
      "epoch5 step40425 [D loss: 0.108930] [G loss: 1.015712]\n",
      "epoch5 step40430 [D loss: 0.091591] [G loss: 0.771017]\n",
      "epoch5 step40435 [D loss: -0.525514] [G loss: 1.047557]\n",
      "epoch5 step40440 [D loss: -0.166237] [G loss: 0.881665]\n",
      "epoch5 step40445 [D loss: 0.287522] [G loss: 1.170679]\n",
      "epoch5 step40450 [D loss: 0.083225] [G loss: 0.619856]\n",
      "epoch5 step40455 [D loss: 0.178454] [G loss: 1.088240]\n",
      "epoch5 step40460 [D loss: -0.280886] [G loss: 0.846691]\n",
      "epoch5 step40465 [D loss: -0.047446] [G loss: 0.752157]\n",
      "epoch5 step40470 [D loss: -0.443128] [G loss: 0.904516]\n",
      "epoch5 step40475 [D loss: 0.542061] [G loss: 0.711058]\n",
      "epoch5 step40480 [D loss: 0.225447] [G loss: 0.886640]\n",
      "epoch5 step40485 [D loss: -0.083635] [G loss: 0.983725]\n",
      "epoch5 step40490 [D loss: -0.598811] [G loss: 0.844559]\n",
      "epoch5 step40495 [D loss: -0.411875] [G loss: 1.077384]\n",
      "epoch5 step40500 [D loss: -0.234320] [G loss: 0.831305]\n",
      "epoch5 step40505 [D loss: 0.348305] [G loss: 0.690466]\n",
      "epoch5 step40510 [D loss: -0.186525] [G loss: 0.797466]\n",
      "epoch5 step40515 [D loss: -0.049922] [G loss: 0.950767]\n",
      "epoch5 step40520 [D loss: -0.210396] [G loss: 1.006063]\n",
      "epoch5 step40525 [D loss: -0.227035] [G loss: 0.804891]\n",
      "epoch5 step40530 [D loss: 0.134054] [G loss: 0.880532]\n",
      "epoch5 step40535 [D loss: -0.395701] [G loss: 1.244969]\n",
      "epoch5 step40540 [D loss: -0.327121] [G loss: 0.882178]\n",
      "epoch5 step40545 [D loss: 0.021260] [G loss: 0.915655]\n",
      "epoch5 step40550 [D loss: -0.275757] [G loss: 0.823965]\n",
      "epoch5 step40555 [D loss: -0.293009] [G loss: 1.058172]\n",
      "epoch5 step40560 [D loss: 0.020662] [G loss: 0.877360]\n",
      "epoch5 step40565 [D loss: -0.053959] [G loss: 0.710081]\n",
      "epoch5 step40570 [D loss: -0.018728] [G loss: 0.581436]\n",
      "epoch5 step40575 [D loss: 0.009106] [G loss: 0.595825]\n",
      "epoch5 step40580 [D loss: 0.031657] [G loss: 0.773082]\n",
      "epoch5 step40585 [D loss: 0.274748] [G loss: 0.799997]\n",
      "epoch5 step40590 [D loss: -0.252146] [G loss: 0.783138]\n",
      "epoch5 step40595 [D loss: -0.575691] [G loss: 0.794141]\n",
      "epoch5 step40600 [D loss: 0.107921] [G loss: 0.612515]\n",
      "epoch5 step40605 [D loss: -0.748173] [G loss: 0.836006]\n",
      "epoch5 step40610 [D loss: -0.399349] [G loss: 0.682963]\n",
      "epoch5 step40615 [D loss: -0.222904] [G loss: 0.752199]\n",
      "epoch5 step40620 [D loss: -0.209363] [G loss: 0.543568]\n",
      "epoch5 step40625 [D loss: -0.076699] [G loss: 0.817818]\n",
      "epoch5 step40630 [D loss: -0.200494] [G loss: 0.878424]\n",
      "epoch5 step40635 [D loss: -0.321937] [G loss: 0.425621]\n",
      "epoch5 step40640 [D loss: 0.161296] [G loss: 0.889507]\n",
      "epoch5 step40645 [D loss: -0.389180] [G loss: 0.959173]\n",
      "epoch5 step40650 [D loss: -0.164458] [G loss: 0.437131]\n",
      "epoch5 step40655 [D loss: 0.152811] [G loss: 0.305967]\n",
      "epoch5 step40660 [D loss: -0.556926] [G loss: 0.811274]\n",
      "epoch5 step40665 [D loss: -0.437593] [G loss: 0.497726]\n",
      "epoch5 step40670 [D loss: -0.125515] [G loss: 0.456758]\n",
      "epoch5 step40675 [D loss: -0.462926] [G loss: 0.297081]\n",
      "epoch5 step40680 [D loss: -0.218727] [G loss: 0.555290]\n",
      "epoch5 step40685 [D loss: -0.205023] [G loss: 0.353483]\n",
      "epoch5 step40690 [D loss: 0.044709] [G loss: 0.428167]\n",
      "epoch5 step40695 [D loss: 0.190953] [G loss: 0.546919]\n",
      "epoch5 step40700 [D loss: -0.376536] [G loss: 0.388441]\n",
      "epoch5 step40705 [D loss: -0.051253] [G loss: 0.283853]\n",
      "epoch5 step40710 [D loss: 0.080691] [G loss: 0.024238]\n",
      "epoch5 step40715 [D loss: 0.085400] [G loss: 0.597491]\n",
      "epoch5 step40720 [D loss: -0.164512] [G loss: 0.429011]\n",
      "epoch5 step40725 [D loss: 0.163474] [G loss: 0.541006]\n",
      "epoch5 step40730 [D loss: -0.480537] [G loss: 0.412971]\n",
      "epoch5 step40735 [D loss: -0.133901] [G loss: 0.291434]\n",
      "epoch5 step40740 [D loss: -0.102816] [G loss: 0.381934]\n",
      "epoch5 step40745 [D loss: 0.098635] [G loss: 0.651460]\n",
      "epoch5 step40750 [D loss: -0.236602] [G loss: 0.236779]\n",
      "epoch5 step40755 [D loss: -0.217483] [G loss: 0.487862]\n",
      "epoch5 step40760 [D loss: -0.546694] [G loss: 0.569607]\n",
      "epoch5 step40765 [D loss: 0.247443] [G loss: 0.592310]\n",
      "epoch5 step40770 [D loss: -0.038361] [G loss: 0.105845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step40775 [D loss: -0.500259] [G loss: 0.415915]\n",
      "epoch5 step40780 [D loss: -0.295765] [G loss: 0.381652]\n",
      "epoch5 step40785 [D loss: 0.187036] [G loss: 0.388742]\n",
      "epoch5 step40790 [D loss: -0.005148] [G loss: 0.433021]\n",
      "epoch5 step40795 [D loss: 0.299028] [G loss: 0.360101]\n",
      "epoch5 step40800 [D loss: 0.024986] [G loss: 0.599509]\n",
      "epoch5 step40805 [D loss: 0.169883] [G loss: 0.381654]\n",
      "epoch5 step40810 [D loss: 0.146162] [G loss: 0.203332]\n",
      "epoch5 step40815 [D loss: 0.062629] [G loss: 0.117472]\n",
      "epoch5 step40820 [D loss: -0.141205] [G loss: 0.130471]\n",
      "epoch5 step40825 [D loss: 0.014222] [G loss: 0.476474]\n",
      "epoch5 step40830 [D loss: -0.180434] [G loss: 0.348124]\n",
      "epoch5 step40835 [D loss: 0.336572] [G loss: 0.375485]\n",
      "epoch5 step40840 [D loss: -0.050739] [G loss: 0.250279]\n",
      "epoch5 step40845 [D loss: -0.061381] [G loss: 0.297464]\n",
      "epoch5 step40850 [D loss: -0.317419] [G loss: 0.213750]\n",
      "epoch5 step40855 [D loss: -0.521963] [G loss: 0.187689]\n",
      "epoch5 step40860 [D loss: -0.259361] [G loss: 0.237692]\n",
      "epoch5 step40865 [D loss: -0.030545] [G loss: 0.255237]\n",
      "epoch5 step40870 [D loss: -0.288979] [G loss: 0.127262]\n",
      "epoch5 step40875 [D loss: -0.729345] [G loss: 0.540423]\n",
      "epoch5 step40880 [D loss: -0.166425] [G loss: 0.109821]\n",
      "epoch5 step40885 [D loss: -0.441053] [G loss: 0.373925]\n",
      "epoch5 step40890 [D loss: 0.223555] [G loss: 0.132908]\n",
      "epoch5 step40895 [D loss: -0.235005] [G loss: 0.313642]\n",
      "epoch5 step40900 [D loss: -0.357816] [G loss: 0.462738]\n",
      "epoch5 step40905 [D loss: 0.182473] [G loss: 0.277959]\n",
      "epoch5 step40910 [D loss: 0.190488] [G loss: -0.218390]\n",
      "epoch5 step40915 [D loss: -0.214725] [G loss: 0.080840]\n",
      "epoch5 step40920 [D loss: -0.192838] [G loss: 0.311765]\n",
      "epoch5 step40925 [D loss: 0.329835] [G loss: 0.190045]\n",
      "epoch5 step40930 [D loss: -0.121476] [G loss: 0.291858]\n",
      "epoch5 step40935 [D loss: -0.130296] [G loss: 0.203533]\n",
      "epoch5 step40940 [D loss: -0.213192] [G loss: 0.136989]\n",
      "epoch5 step40945 [D loss: -0.066279] [G loss: 0.407835]\n",
      "epoch5 step40950 [D loss: -0.713986] [G loss: 0.641639]\n",
      "epoch5 step40955 [D loss: 0.084357] [G loss: 0.212010]\n",
      "epoch5 step40960 [D loss: -0.481403] [G loss: 0.516174]\n",
      "epoch5 step40965 [D loss: -0.363423] [G loss: 0.378456]\n",
      "epoch5 step40970 [D loss: -0.227102] [G loss: 0.428919]\n",
      "epoch5 step40975 [D loss: 0.053536] [G loss: 0.388049]\n",
      "epoch5 step40980 [D loss: -0.528302] [G loss: 0.287968]\n",
      "epoch5 step40985 [D loss: -0.000495] [G loss: 0.134555]\n",
      "epoch5 step40990 [D loss: -0.168969] [G loss: 0.110913]\n",
      "epoch5 step40995 [D loss: -0.132832] [G loss: 0.671011]\n",
      "epoch5 step41000 [D loss: 0.240955] [G loss: 0.317511]\n",
      "epoch5 step41005 [D loss: -0.319074] [G loss: 0.855594]\n",
      "epoch5 step41010 [D loss: -0.437552] [G loss: 0.902364]\n",
      "epoch5 step41015 [D loss: -0.241808] [G loss: 1.003246]\n",
      "epoch5 step41020 [D loss: -0.536526] [G loss: 0.952712]\n",
      "epoch5 step41025 [D loss: -1.131784] [G loss: 1.037234]\n",
      "epoch5 step41030 [D loss: -0.287620] [G loss: 0.767019]\n",
      "epoch5 step41035 [D loss: -0.582078] [G loss: 1.113312]\n",
      "epoch5 step41040 [D loss: -0.072147] [G loss: 0.862311]\n",
      "epoch5 step41045 [D loss: 0.309581] [G loss: 0.721280]\n",
      "epoch5 step41050 [D loss: -0.090669] [G loss: 0.443405]\n",
      "epoch5 step41055 [D loss: -0.436354] [G loss: 0.818878]\n",
      "epoch5 step41060 [D loss: 0.143417] [G loss: 0.804232]\n",
      "epoch5 step41065 [D loss: 0.206740] [G loss: 0.528212]\n",
      "epoch5 step41070 [D loss: -0.480923] [G loss: 0.863922]\n",
      "epoch5 step41075 [D loss: -0.474447] [G loss: 0.649764]\n",
      "epoch5 step41080 [D loss: -0.180877] [G loss: 0.351874]\n",
      "epoch5 step41085 [D loss: -0.158894] [G loss: 0.421535]\n",
      "epoch5 step41090 [D loss: -0.191393] [G loss: 0.238875]\n",
      "epoch5 step41095 [D loss: -0.074019] [G loss: 0.493440]\n",
      "epoch5 step41100 [D loss: -0.241670] [G loss: 0.260175]\n",
      "epoch5 step41105 [D loss: 0.157797] [G loss: 0.232116]\n",
      "epoch5 step41110 [D loss: 0.431705] [G loss: 0.382786]\n",
      "epoch5 step41115 [D loss: 0.180931] [G loss: 0.297451]\n",
      "epoch5 step41120 [D loss: -0.068045] [G loss: 0.438095]\n",
      "epoch5 step41125 [D loss: 0.156034] [G loss: 0.198067]\n",
      "epoch5 step41130 [D loss: -0.099232] [G loss: 0.353904]\n",
      "epoch5 step41135 [D loss: -0.275801] [G loss: 0.183390]\n",
      "epoch5 step41140 [D loss: -0.281679] [G loss: 0.359259]\n",
      "epoch5 step41145 [D loss: -0.491974] [G loss: 0.657256]\n",
      "epoch5 step41150 [D loss: 0.337550] [G loss: 0.563586]\n",
      "epoch5 step41155 [D loss: -0.334676] [G loss: 0.557669]\n",
      "epoch5 step41160 [D loss: -0.158317] [G loss: 1.058859]\n",
      "epoch5 step41165 [D loss: -0.205168] [G loss: 0.580786]\n",
      "epoch5 step41170 [D loss: -0.246938] [G loss: 0.880479]\n",
      "epoch5 step41175 [D loss: 0.490740] [G loss: 0.825550]\n",
      "epoch5 step41180 [D loss: -0.125560] [G loss: 1.040229]\n",
      "epoch5 step41185 [D loss: -0.160471] [G loss: 1.032507]\n",
      "epoch5 step41190 [D loss: -0.322331] [G loss: 1.064317]\n",
      "epoch5 step41195 [D loss: 0.505839] [G loss: 1.221201]\n",
      "epoch5 step41200 [D loss: -0.463048] [G loss: 1.248652]\n",
      "epoch5 step41205 [D loss: -0.836410] [G loss: 1.133699]\n",
      "epoch5 step41210 [D loss: -0.640382] [G loss: 1.305302]\n",
      "epoch5 step41215 [D loss: -0.315268] [G loss: 1.225036]\n",
      "epoch5 step41220 [D loss: 0.027963] [G loss: 1.214102]\n",
      "epoch5 step41225 [D loss: -0.111661] [G loss: 1.021854]\n",
      "epoch5 step41230 [D loss: 0.048420] [G loss: 1.277827]\n",
      "epoch5 step41235 [D loss: -0.118244] [G loss: 1.386734]\n",
      "epoch5 step41240 [D loss: -0.073417] [G loss: 0.841416]\n",
      "epoch5 step41245 [D loss: -0.252690] [G loss: 0.989478]\n",
      "epoch5 step41250 [D loss: -0.324921] [G loss: 1.034445]\n",
      "epoch5 step41255 [D loss: 0.055707] [G loss: 1.030905]\n",
      "epoch5 step41260 [D loss: 0.291507] [G loss: 1.111416]\n",
      "epoch5 step41265 [D loss: -0.265659] [G loss: 1.256066]\n",
      "epoch5 step41270 [D loss: -0.301490] [G loss: 0.878058]\n",
      "epoch5 step41275 [D loss: -0.287193] [G loss: 1.142785]\n",
      "epoch5 step41280 [D loss: -0.437636] [G loss: 0.847901]\n",
      "epoch5 step41285 [D loss: 0.081343] [G loss: 0.607470]\n",
      "epoch5 step41290 [D loss: -0.208909] [G loss: 0.716644]\n",
      "epoch5 step41295 [D loss: -0.004239] [G loss: 0.959357]\n",
      "epoch5 step41300 [D loss: -0.114935] [G loss: 0.842926]\n",
      "epoch5 step41305 [D loss: 0.140302] [G loss: 0.485413]\n",
      "epoch5 step41310 [D loss: 0.340719] [G loss: 0.865709]\n",
      "epoch5 step41315 [D loss: -0.066347] [G loss: 0.794422]\n",
      "epoch5 step41320 [D loss: -0.288759] [G loss: 1.172776]\n",
      "epoch5 step41325 [D loss: -0.072643] [G loss: 0.866157]\n",
      "epoch5 step41330 [D loss: -0.120287] [G loss: 0.370647]\n",
      "epoch5 step41335 [D loss: -0.233968] [G loss: 0.659916]\n",
      "epoch5 step41340 [D loss: 0.155897] [G loss: 0.716035]\n",
      "epoch5 step41345 [D loss: 0.206988] [G loss: 0.702171]\n",
      "epoch5 step41350 [D loss: -0.130120] [G loss: 0.748721]\n",
      "epoch5 step41355 [D loss: -0.100349] [G loss: 0.557779]\n",
      "epoch5 step41360 [D loss: -0.212418] [G loss: 0.811901]\n",
      "epoch5 step41365 [D loss: 0.130391] [G loss: 0.049957]\n",
      "epoch5 step41370 [D loss: 0.312887] [G loss: 0.361954]\n",
      "epoch5 step41375 [D loss: -0.299046] [G loss: 0.337074]\n",
      "epoch5 step41380 [D loss: -0.225853] [G loss: 0.359408]\n",
      "epoch5 step41385 [D loss: -0.312710] [G loss: 0.589132]\n",
      "epoch5 step41390 [D loss: 0.065626] [G loss: 0.420093]\n",
      "epoch5 step41395 [D loss: 0.452701] [G loss: 0.405435]\n",
      "epoch5 step41400 [D loss: -0.288658] [G loss: 0.320224]\n",
      "epoch5 step41405 [D loss: -0.066667] [G loss: 0.220463]\n",
      "epoch5 step41410 [D loss: 0.153211] [G loss: 0.060567]\n",
      "epoch5 step41415 [D loss: -0.111858] [G loss: 0.386359]\n",
      "epoch5 step41420 [D loss: -0.289072] [G loss: 0.173995]\n",
      "epoch5 step41425 [D loss: 0.062449] [G loss: 0.082447]\n",
      "epoch5 step41430 [D loss: 0.074663] [G loss: 0.292280]\n",
      "epoch5 step41435 [D loss: -0.372283] [G loss: 0.318117]\n",
      "epoch5 step41440 [D loss: -0.568768] [G loss: 0.250713]\n",
      "epoch5 step41445 [D loss: -0.352538] [G loss: 0.553404]\n",
      "epoch5 step41450 [D loss: 0.115799] [G loss: 0.407975]\n",
      "epoch5 step41455 [D loss: 0.115855] [G loss: 0.212747]\n",
      "epoch5 step41460 [D loss: -0.500807] [G loss: 0.466861]\n",
      "epoch5 step41465 [D loss: -0.366218] [G loss: 0.200840]\n",
      "epoch5 step41470 [D loss: 0.120804] [G loss: 0.405732]\n",
      "epoch5 step41475 [D loss: -0.087009] [G loss: 0.486537]\n",
      "epoch5 step41480 [D loss: 0.043034] [G loss: 0.219460]\n",
      "epoch5 step41485 [D loss: -0.080456] [G loss: 0.497454]\n",
      "epoch5 step41490 [D loss: -0.713589] [G loss: 0.484954]\n",
      "epoch5 step41495 [D loss: 0.061642] [G loss: 0.327006]\n",
      "epoch5 step41500 [D loss: 0.161165] [G loss: 0.332954]\n",
      "epoch5 step41505 [D loss: -0.456318] [G loss: 0.272911]\n",
      "epoch5 step41510 [D loss: -0.078623] [G loss: 0.577171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step41515 [D loss: -0.142326] [G loss: 0.585944]\n",
      "epoch5 step41520 [D loss: -0.201297] [G loss: 0.362299]\n",
      "epoch5 step41525 [D loss: -0.057677] [G loss: 0.621522]\n",
      "epoch5 step41530 [D loss: 0.232545] [G loss: 0.847895]\n",
      "epoch5 step41535 [D loss: -0.373653] [G loss: 0.730768]\n",
      "epoch5 step41540 [D loss: 0.189254] [G loss: 0.550223]\n",
      "epoch5 step41545 [D loss: -0.181336] [G loss: 0.378506]\n",
      "epoch5 step41550 [D loss: -0.106108] [G loss: 0.353761]\n",
      "epoch5 step41555 [D loss: 0.084175] [G loss: 0.529585]\n",
      "epoch5 step41560 [D loss: -0.011988] [G loss: 0.779472]\n",
      "epoch5 step41565 [D loss: -0.480636] [G loss: 0.480897]\n",
      "epoch5 step41570 [D loss: -0.232404] [G loss: 0.675557]\n",
      "epoch5 step41575 [D loss: -0.305305] [G loss: 0.480832]\n",
      "epoch5 step41580 [D loss: -0.598055] [G loss: 0.725480]\n",
      "epoch5 step41585 [D loss: -0.179698] [G loss: 0.618471]\n",
      "epoch5 step41590 [D loss: -0.010902] [G loss: 0.544455]\n",
      "epoch5 step41595 [D loss: -0.220846] [G loss: 0.372941]\n",
      "epoch5 step41600 [D loss: -0.219988] [G loss: 0.643223]\n",
      "epoch5 step41605 [D loss: 0.137770] [G loss: 0.675729]\n",
      "epoch5 step41610 [D loss: 0.151455] [G loss: 0.383835]\n",
      "epoch5 step41615 [D loss: -0.365475] [G loss: 0.343568]\n",
      "epoch5 step41620 [D loss: -0.188660] [G loss: 0.745735]\n",
      "epoch5 step41625 [D loss: -0.135558] [G loss: 0.627727]\n",
      "epoch5 step41630 [D loss: -0.261737] [G loss: 0.374243]\n",
      "epoch5 step41635 [D loss: -0.084966] [G loss: 0.029365]\n",
      "epoch5 step41640 [D loss: 0.138670] [G loss: 0.312777]\n",
      "epoch5 step41645 [D loss: 0.047787] [G loss: 0.339749]\n",
      "epoch5 step41650 [D loss: -0.206095] [G loss: 0.379890]\n",
      "epoch5 step41655 [D loss: -0.114195] [G loss: 0.324317]\n",
      "epoch5 step41660 [D loss: -0.183725] [G loss: 0.394355]\n",
      "epoch5 step41665 [D loss: 0.109115] [G loss: 0.382911]\n",
      "epoch5 step41670 [D loss: -0.375495] [G loss: 0.554620]\n",
      "epoch5 step41675 [D loss: -0.562056] [G loss: 0.581255]\n",
      "epoch5 step41680 [D loss: -0.072854] [G loss: 0.425637]\n",
      "epoch5 step41685 [D loss: -0.010030] [G loss: 0.369257]\n",
      "epoch5 step41690 [D loss: 0.004910] [G loss: 0.370691]\n",
      "epoch5 step41695 [D loss: 0.145223] [G loss: 0.245394]\n",
      "epoch5 step41700 [D loss: -0.152662] [G loss: 0.157055]\n",
      "epoch5 step41705 [D loss: -0.428463] [G loss: 0.435036]\n",
      "epoch5 step41710 [D loss: 0.146140] [G loss: -0.136509]\n",
      "epoch5 step41715 [D loss: 0.124593] [G loss: 0.040428]\n",
      "epoch5 step41720 [D loss: -0.385963] [G loss: 0.091877]\n",
      "epoch5 step41725 [D loss: -0.511301] [G loss: -0.184476]\n",
      "epoch5 step41730 [D loss: -0.110065] [G loss: 0.181188]\n",
      "epoch5 step41735 [D loss: -0.138221] [G loss: -0.118870]\n",
      "epoch5 step41740 [D loss: 0.017239] [G loss: -0.235546]\n",
      "epoch5 step41745 [D loss: -0.119906] [G loss: 0.014915]\n",
      "epoch5 step41750 [D loss: -0.438766] [G loss: 0.090062]\n",
      "epoch5 step41755 [D loss: -0.056699] [G loss: -0.357698]\n",
      "epoch5 step41760 [D loss: -0.290267] [G loss: -0.044874]\n",
      "epoch5 step41765 [D loss: 0.221731] [G loss: -0.259887]\n",
      "epoch5 step41770 [D loss: 0.003754] [G loss: -0.016242]\n",
      "epoch5 step41775 [D loss: -0.496245] [G loss: -0.017903]\n",
      "epoch5 step41780 [D loss: 0.282817] [G loss: -0.086734]\n",
      "epoch5 step41785 [D loss: 0.456845] [G loss: -0.313821]\n",
      "epoch5 step41790 [D loss: -0.278941] [G loss: 0.284678]\n",
      "epoch5 step41795 [D loss: -0.202232] [G loss: 0.411846]\n",
      "epoch5 step41800 [D loss: -0.071480] [G loss: 0.186834]\n",
      "epoch5 step41805 [D loss: -0.135135] [G loss: 0.119932]\n",
      "epoch5 step41810 [D loss: -0.561387] [G loss: 0.675579]\n",
      "epoch5 step41815 [D loss: -0.495793] [G loss: 0.677709]\n",
      "epoch5 step41820 [D loss: -0.578839] [G loss: 0.426199]\n",
      "epoch5 step41825 [D loss: -0.113944] [G loss: 0.653655]\n",
      "epoch5 step41830 [D loss: -0.071188] [G loss: 0.747301]\n",
      "epoch5 step41835 [D loss: -0.107615] [G loss: 0.604578]\n",
      "epoch5 step41840 [D loss: -0.375522] [G loss: 0.657301]\n",
      "epoch5 step41845 [D loss: -0.226911] [G loss: 0.942540]\n",
      "epoch5 step41850 [D loss: -0.001845] [G loss: 0.784661]\n",
      "epoch5 step41855 [D loss: -0.868494] [G loss: 1.268637]\n",
      "epoch5 step41860 [D loss: -0.108132] [G loss: 0.962411]\n",
      "epoch5 step41865 [D loss: -0.207883] [G loss: 0.897769]\n",
      "epoch5 step41870 [D loss: 0.246221] [G loss: 0.868590]\n",
      "epoch5 step41875 [D loss: -0.256565] [G loss: 1.235608]\n",
      "epoch5 step41880 [D loss: -0.629325] [G loss: 1.245184]\n",
      "epoch5 step41885 [D loss: -0.480733] [G loss: 1.373319]\n",
      "epoch5 step41890 [D loss: 0.056944] [G loss: 0.990050]\n",
      "epoch5 step41895 [D loss: -0.330631] [G loss: 1.435168]\n",
      "epoch5 step41900 [D loss: -0.182085] [G loss: 1.036219]\n",
      "epoch5 step41905 [D loss: -0.569795] [G loss: 1.454491]\n",
      "epoch5 step41910 [D loss: 0.224525] [G loss: 0.977362]\n",
      "epoch5 step41915 [D loss: 0.266062] [G loss: 1.217886]\n",
      "epoch5 step41920 [D loss: -0.555558] [G loss: 1.121051]\n",
      "epoch5 step41925 [D loss: 0.264698] [G loss: 0.995566]\n",
      "epoch5 step41930 [D loss: 0.202252] [G loss: 1.234089]\n",
      "epoch5 step41935 [D loss: -0.102760] [G loss: 1.411296]\n",
      "epoch5 step41940 [D loss: 0.301598] [G loss: 1.059691]\n",
      "epoch5 step41945 [D loss: 0.089698] [G loss: 1.381222]\n",
      "epoch5 step41950 [D loss: 0.298366] [G loss: 0.908061]\n",
      "epoch5 step41955 [D loss: -0.048874] [G loss: 0.939045]\n",
      "epoch5 step41960 [D loss: -0.395525] [G loss: 1.039025]\n",
      "epoch5 step41965 [D loss: 0.358343] [G loss: 0.928016]\n",
      "epoch5 step41970 [D loss: -0.289149] [G loss: 1.308310]\n",
      "epoch5 step41975 [D loss: -0.402351] [G loss: 0.783995]\n",
      "epoch5 step41980 [D loss: -0.301648] [G loss: 1.202130]\n",
      "epoch5 step41985 [D loss: 0.158251] [G loss: 0.577045]\n",
      "epoch5 step41990 [D loss: 0.053145] [G loss: 0.920614]\n",
      "epoch5 step41995 [D loss: 0.079337] [G loss: 0.641409]\n",
      "epoch5 step42000 [D loss: -0.016643] [G loss: 0.929347]\n",
      "epoch5 step42005 [D loss: -0.168493] [G loss: 1.144588]\n",
      "epoch5 step42010 [D loss: -0.312410] [G loss: 0.879549]\n",
      "epoch5 step42015 [D loss: -0.358498] [G loss: 0.755995]\n",
      "epoch5 step42020 [D loss: -0.419572] [G loss: 0.551530]\n",
      "epoch5 step42025 [D loss: 0.031003] [G loss: 0.812503]\n",
      "epoch5 step42030 [D loss: -0.383047] [G loss: 0.871096]\n",
      "epoch5 step42035 [D loss: 0.320055] [G loss: 0.453363]\n",
      "epoch5 step42040 [D loss: -0.505571] [G loss: 0.399030]\n",
      "epoch5 step42045 [D loss: -0.119490] [G loss: 0.358901]\n",
      "epoch5 step42050 [D loss: 0.017153] [G loss: 0.386719]\n",
      "epoch5 step42055 [D loss: 0.292817] [G loss: 0.493445]\n",
      "epoch5 step42060 [D loss: -0.065044] [G loss: 0.274751]\n",
      "epoch5 step42065 [D loss: -0.080545] [G loss: 0.290838]\n",
      "epoch5 step42070 [D loss: -0.279538] [G loss: 0.303509]\n",
      "epoch5 step42075 [D loss: -0.566055] [G loss: 0.290846]\n",
      "epoch5 step42080 [D loss: 0.146453] [G loss: 0.424031]\n",
      "epoch5 step42085 [D loss: -0.054282] [G loss: 0.170145]\n",
      "epoch5 step42090 [D loss: -0.108976] [G loss: 0.419913]\n",
      "epoch5 step42095 [D loss: -0.380091] [G loss: 0.476877]\n",
      "epoch5 step42100 [D loss: -0.036707] [G loss: 0.137340]\n",
      "epoch5 step42105 [D loss: 0.096576] [G loss: -0.207853]\n",
      "epoch5 step42110 [D loss: 0.425039] [G loss: -0.022452]\n",
      "epoch5 step42115 [D loss: -0.070041] [G loss: -0.015794]\n",
      "epoch5 step42120 [D loss: -0.391216] [G loss: -0.073348]\n",
      "epoch5 step42125 [D loss: -0.596421] [G loss: -0.233349]\n",
      "epoch5 step42130 [D loss: -0.291519] [G loss: 0.213034]\n",
      "epoch5 step42135 [D loss: -0.760952] [G loss: -0.222407]\n",
      "epoch5 step42140 [D loss: -0.107857] [G loss: 0.154677]\n",
      "epoch5 step42145 [D loss: -0.443432] [G loss: 0.291341]\n",
      "epoch5 step42150 [D loss: -0.443718] [G loss: 0.069961]\n",
      "epoch5 step42155 [D loss: -0.199159] [G loss: 0.058434]\n",
      "epoch5 step42160 [D loss: 0.211451] [G loss: -0.040441]\n",
      "epoch5 step42165 [D loss: -0.158331] [G loss: -0.265551]\n",
      "epoch5 step42170 [D loss: -0.554877] [G loss: -0.017566]\n",
      "epoch5 step42175 [D loss: -0.186042] [G loss: -0.006719]\n",
      "epoch5 step42180 [D loss: -0.025189] [G loss: 0.303634]\n",
      "epoch5 step42185 [D loss: -0.121763] [G loss: 0.067187]\n",
      "epoch5 step42190 [D loss: -0.360611] [G loss: 0.480022]\n",
      "epoch5 step42195 [D loss: -0.130316] [G loss: 0.680531]\n",
      "epoch5 step42200 [D loss: -0.450187] [G loss: 0.584403]\n",
      "epoch5 step42205 [D loss: -0.378305] [G loss: 0.392365]\n",
      "epoch5 step42210 [D loss: -0.544783] [G loss: 0.781296]\n",
      "epoch5 step42215 [D loss: -0.055668] [G loss: 0.593831]\n",
      "epoch5 step42220 [D loss: -0.294873] [G loss: 0.743497]\n",
      "epoch5 step42225 [D loss: -0.146843] [G loss: 0.672544]\n",
      "epoch5 step42230 [D loss: -0.248778] [G loss: 0.591689]\n",
      "epoch5 step42235 [D loss: -0.429618] [G loss: 0.696971]\n",
      "epoch5 step42240 [D loss: -0.485883] [G loss: 1.223285]\n",
      "epoch5 step42245 [D loss: -0.239628] [G loss: 0.982610]\n",
      "epoch5 step42250 [D loss: -0.151242] [G loss: 0.781196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step42255 [D loss: 0.514424] [G loss: 0.468390]\n",
      "epoch5 step42260 [D loss: -0.422660] [G loss: 1.320966]\n",
      "epoch5 step42265 [D loss: -0.172812] [G loss: 0.975672]\n",
      "epoch5 step42270 [D loss: -0.021215] [G loss: 0.572884]\n",
      "epoch5 step42275 [D loss: -0.426893] [G loss: 0.822401]\n",
      "epoch5 step42280 [D loss: 0.042519] [G loss: 0.885463]\n",
      "epoch5 step42285 [D loss: -0.253449] [G loss: 0.632361]\n",
      "epoch5 step42290 [D loss: 0.356592] [G loss: 0.464367]\n",
      "epoch5 step42295 [D loss: -0.004187] [G loss: 0.685444]\n",
      "epoch5 step42300 [D loss: 0.333203] [G loss: 0.283958]\n",
      "epoch5 step42305 [D loss: 0.025585] [G loss: 0.638337]\n",
      "epoch5 step42310 [D loss: 0.086939] [G loss: 0.658264]\n",
      "epoch5 step42315 [D loss: -0.096502] [G loss: 0.735133]\n",
      "epoch5 step42320 [D loss: 0.077485] [G loss: 0.449834]\n",
      "epoch5 step42325 [D loss: -0.352925] [G loss: 0.608025]\n",
      "epoch5 step42330 [D loss: -0.449651] [G loss: 0.568911]\n",
      "epoch5 step42335 [D loss: -0.608481] [G loss: 0.374889]\n",
      "epoch5 step42340 [D loss: -0.404159] [G loss: 0.682521]\n",
      "epoch5 step42345 [D loss: -0.632173] [G loss: 0.350877]\n",
      "epoch5 step42350 [D loss: -0.617052] [G loss: 0.310074]\n",
      "epoch5 step42355 [D loss: 0.328057] [G loss: 0.327958]\n",
      "epoch5 step42360 [D loss: -0.276364] [G loss: 0.244659]\n",
      "epoch5 step42365 [D loss: -0.228509] [G loss: 0.831087]\n",
      "epoch5 step42370 [D loss: -0.399649] [G loss: 0.484879]\n",
      "epoch5 step42375 [D loss: -0.453545] [G loss: 0.460344]\n",
      "epoch5 step42380 [D loss: -0.201131] [G loss: 0.754348]\n",
      "epoch5 step42385 [D loss: 0.071117] [G loss: 0.169604]\n",
      "epoch5 step42390 [D loss: 0.180446] [G loss: 0.730214]\n",
      "epoch5 step42395 [D loss: -0.438142] [G loss: 0.551785]\n",
      "epoch5 step42400 [D loss: -0.050955] [G loss: 0.964098]\n",
      "epoch5 step42405 [D loss: 0.227750] [G loss: 0.366889]\n",
      "epoch5 step42410 [D loss: -0.275934] [G loss: 0.196782]\n",
      "epoch5 step42415 [D loss: -0.101879] [G loss: 0.562594]\n",
      "epoch5 step42420 [D loss: -0.446715] [G loss: 0.678085]\n",
      "epoch5 step42425 [D loss: -0.368243] [G loss: 0.588355]\n",
      "epoch5 step42430 [D loss: -0.363348] [G loss: 0.465850]\n",
      "epoch5 step42435 [D loss: -0.043432] [G loss: 0.359845]\n",
      "epoch5 step42440 [D loss: -0.098343] [G loss: 0.227360]\n",
      "epoch5 step42445 [D loss: -0.210740] [G loss: 0.559451]\n",
      "epoch5 step42450 [D loss: 0.328298] [G loss: 0.224102]\n",
      "epoch5 step42455 [D loss: -0.170847] [G loss: 0.564696]\n",
      "epoch5 step42460 [D loss: 0.138528] [G loss: 0.360423]\n",
      "epoch5 step42465 [D loss: 0.319118] [G loss: 0.055581]\n",
      "epoch5 step42470 [D loss: -0.333944] [G loss: 0.544023]\n",
      "epoch5 step42475 [D loss: -0.511019] [G loss: 0.266456]\n",
      "epoch5 step42480 [D loss: 0.033402] [G loss: 0.422338]\n",
      "epoch5 step42485 [D loss: 0.062548] [G loss: 0.273459]\n",
      "epoch5 step42490 [D loss: -0.124227] [G loss: 0.032330]\n",
      "epoch5 step42495 [D loss: -0.197967] [G loss: 0.561102]\n",
      "epoch5 step42500 [D loss: 0.028854] [G loss: 0.420214]\n",
      "epoch5 step42505 [D loss: -0.480895] [G loss: 0.312652]\n",
      "epoch5 step42510 [D loss: -0.321230] [G loss: 0.415760]\n",
      "epoch5 step42515 [D loss: -0.286751] [G loss: 0.411122]\n",
      "epoch5 step42520 [D loss: -0.031205] [G loss: 0.605817]\n",
      "epoch5 step42525 [D loss: -0.053104] [G loss: 0.175251]\n",
      "epoch5 step42530 [D loss: -0.111751] [G loss: 0.078483]\n",
      "epoch5 step42535 [D loss: 0.415864] [G loss: 0.188964]\n",
      "epoch5 step42540 [D loss: 0.119068] [G loss: 0.218884]\n",
      "epoch5 step42545 [D loss: -0.278305] [G loss: 0.248824]\n",
      "epoch5 step42550 [D loss: -0.025692] [G loss: 0.290742]\n",
      "epoch5 step42555 [D loss: 0.150642] [G loss: 0.203104]\n",
      "epoch5 step42560 [D loss: -0.073570] [G loss: 0.425155]\n",
      "epoch5 step42565 [D loss: -0.251056] [G loss: 0.297112]\n",
      "epoch5 step42570 [D loss: 0.151747] [G loss: 0.128903]\n",
      "epoch5 step42575 [D loss: 0.134492] [G loss: -0.102441]\n",
      "epoch5 step42580 [D loss: -0.349886] [G loss: 0.234641]\n",
      "epoch5 step42585 [D loss: 0.434895] [G loss: 0.128831]\n",
      "epoch5 step42590 [D loss: -0.185153] [G loss: 0.172634]\n",
      "epoch5 step42595 [D loss: -0.530985] [G loss: 0.094361]\n",
      "epoch5 step42600 [D loss: 0.163644] [G loss: 0.034539]\n",
      "epoch5 step42605 [D loss: -0.055420] [G loss: 0.203722]\n",
      "epoch5 step42610 [D loss: -0.602038] [G loss: -0.065660]\n",
      "epoch5 step42615 [D loss: -0.250528] [G loss: -0.190872]\n",
      "epoch5 step42620 [D loss: -0.606217] [G loss: 0.340968]\n",
      "epoch5 step42625 [D loss: -0.278242] [G loss: 0.264043]\n",
      "epoch5 step42630 [D loss: -0.205007] [G loss: 0.287627]\n",
      "epoch5 step42635 [D loss: 0.001147] [G loss: -0.097063]\n",
      "epoch5 step42640 [D loss: -0.514650] [G loss: 0.105078]\n",
      "epoch5 step42645 [D loss: -0.249421] [G loss: 0.157558]\n",
      "epoch5 step42650 [D loss: -0.071011] [G loss: 0.055801]\n",
      "epoch5 step42655 [D loss: -0.140091] [G loss: -0.357549]\n",
      "epoch5 step42660 [D loss: 0.244498] [G loss: -0.695314]\n",
      "epoch5 step42665 [D loss: -0.366960] [G loss: -0.297897]\n",
      "epoch5 step42670 [D loss: 0.070752] [G loss: 0.129775]\n",
      "epoch5 step42675 [D loss: -0.128256] [G loss: -0.493648]\n",
      "epoch5 step42680 [D loss: 0.239126] [G loss: -0.403450]\n",
      "epoch5 step42685 [D loss: -0.248833] [G loss: -0.306741]\n",
      "epoch5 step42690 [D loss: -0.347727] [G loss: -0.198127]\n",
      "epoch5 step42695 [D loss: -0.819382] [G loss: -0.285931]\n",
      "epoch5 step42700 [D loss: 0.361921] [G loss: -0.845060]\n",
      "epoch5 step42705 [D loss: 0.170496] [G loss: -0.625462]\n",
      "epoch5 step42710 [D loss: 0.177428] [G loss: -0.524430]\n",
      "epoch5 step42715 [D loss: -0.053406] [G loss: -0.773431]\n",
      "epoch5 step42720 [D loss: -0.236184] [G loss: -0.442078]\n",
      "epoch5 step42725 [D loss: 0.184223] [G loss: -0.186642]\n",
      "epoch5 step42730 [D loss: -0.254872] [G loss: -0.243426]\n",
      "epoch5 step42735 [D loss: -0.171322] [G loss: -0.556956]\n",
      "epoch5 step42740 [D loss: -0.236762] [G loss: -0.557183]\n",
      "epoch5 step42745 [D loss: -0.235834] [G loss: -0.493254]\n",
      "epoch5 step42750 [D loss: -0.492552] [G loss: -0.563264]\n",
      "epoch5 step42755 [D loss: -0.510787] [G loss: -0.520096]\n",
      "epoch5 step42760 [D loss: -0.300979] [G loss: -0.370947]\n",
      "epoch5 step42765 [D loss: -0.162591] [G loss: -0.516000]\n",
      "epoch5 step42770 [D loss: 0.432133] [G loss: -0.556947]\n",
      "epoch5 step42775 [D loss: -0.086371] [G loss: -0.593226]\n",
      "epoch5 step42780 [D loss: -0.757125] [G loss: -0.586209]\n",
      "epoch5 step42785 [D loss: -0.634874] [G loss: -0.385127]\n",
      "epoch5 step42790 [D loss: -0.282590] [G loss: -0.326468]\n",
      "epoch5 step42795 [D loss: 0.019362] [G loss: -0.204246]\n",
      "epoch5 step42800 [D loss: 0.211278] [G loss: 0.154899]\n",
      "epoch5 step42805 [D loss: 0.055342] [G loss: -0.219233]\n",
      "epoch5 step42810 [D loss: -0.177145] [G loss: -0.112355]\n",
      "epoch5 step42815 [D loss: 0.499569] [G loss: -0.184396]\n",
      "epoch5 step42820 [D loss: 0.171891] [G loss: 0.278234]\n",
      "epoch5 step42825 [D loss: -0.093655] [G loss: 0.232439]\n",
      "epoch5 step42830 [D loss: -0.351564] [G loss: 0.241443]\n",
      "epoch5 step42835 [D loss: -0.039020] [G loss: 0.589592]\n",
      "epoch5 step42840 [D loss: -0.490986] [G loss: 0.828292]\n",
      "epoch5 step42845 [D loss: 0.257698] [G loss: 0.625310]\n",
      "epoch5 step42850 [D loss: -0.283574] [G loss: 0.909858]\n",
      "epoch5 step42855 [D loss: -0.542275] [G loss: 1.181707]\n",
      "epoch5 step42860 [D loss: 0.053850] [G loss: 0.589403]\n",
      "epoch5 step42865 [D loss: -0.509152] [G loss: 1.024634]\n",
      "epoch5 step42870 [D loss: -0.386274] [G loss: 0.959859]\n",
      "epoch5 step42875 [D loss: -0.265891] [G loss: 1.414352]\n",
      "epoch5 step42880 [D loss: 0.263946] [G loss: 0.885583]\n",
      "epoch5 step42885 [D loss: -0.017641] [G loss: 1.266518]\n",
      "epoch5 step42890 [D loss: -0.030937] [G loss: 1.053085]\n",
      "epoch5 step42895 [D loss: -0.393684] [G loss: 0.759609]\n",
      "epoch5 step42900 [D loss: -0.057109] [G loss: 1.007932]\n",
      "epoch5 step42905 [D loss: 0.474132] [G loss: 1.056020]\n",
      "epoch5 step42910 [D loss: 0.330878] [G loss: 0.795820]\n",
      "epoch5 step42915 [D loss: 0.271660] [G loss: 0.647373]\n",
      "epoch5 step42920 [D loss: -0.041484] [G loss: 0.888436]\n",
      "epoch5 step42925 [D loss: -0.325586] [G loss: 0.811405]\n",
      "epoch5 step42930 [D loss: 0.438996] [G loss: 1.202664]\n",
      "epoch5 step42935 [D loss: 0.039368] [G loss: 0.924139]\n",
      "epoch5 step42940 [D loss: -0.339562] [G loss: 0.876055]\n",
      "epoch5 step42945 [D loss: -0.045184] [G loss: 1.118290]\n",
      "epoch5 step42950 [D loss: -0.385470] [G loss: 1.001637]\n",
      "epoch5 step42955 [D loss: 0.465278] [G loss: 0.907760]\n",
      "epoch5 step42960 [D loss: -0.024709] [G loss: 0.866517]\n",
      "epoch5 step42965 [D loss: -0.263999] [G loss: 0.729699]\n",
      "epoch5 step42970 [D loss: -0.115050] [G loss: 0.705021]\n",
      "epoch5 step42975 [D loss: -0.190355] [G loss: 0.420707]\n",
      "epoch5 step42980 [D loss: -0.301339] [G loss: 0.575984]\n",
      "epoch5 step42985 [D loss: 0.394577] [G loss: 0.267132]\n",
      "epoch5 step42990 [D loss: -0.805739] [G loss: 0.989694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step42995 [D loss: 0.072460] [G loss: 0.390094]\n",
      "epoch5 step43000 [D loss: 0.494148] [G loss: -0.174842]\n",
      "epoch5 step43005 [D loss: -0.570133] [G loss: 0.044582]\n",
      "epoch5 step43010 [D loss: -0.312762] [G loss: 0.060326]\n",
      "epoch5 step43015 [D loss: -0.306339] [G loss: 0.120962]\n",
      "epoch5 step43020 [D loss: -0.308220] [G loss: 0.045121]\n",
      "epoch5 step43025 [D loss: -0.093294] [G loss: -0.112770]\n",
      "epoch5 step43030 [D loss: -0.194176] [G loss: -0.044435]\n",
      "epoch5 step43035 [D loss: -0.149443] [G loss: -0.070684]\n",
      "epoch5 step43040 [D loss: 0.176449] [G loss: -0.138040]\n",
      "epoch5 step43045 [D loss: -0.053318] [G loss: -0.020765]\n",
      "epoch5 step43050 [D loss: 0.036197] [G loss: 0.090948]\n",
      "epoch5 step43055 [D loss: 0.090371] [G loss: -0.418225]\n",
      "epoch5 step43060 [D loss: 0.374555] [G loss: -0.539917]\n",
      "epoch5 step43065 [D loss: -0.304661] [G loss: -0.590248]\n",
      "epoch5 step43070 [D loss: -0.048904] [G loss: -0.557672]\n",
      "epoch5 step43075 [D loss: -0.442844] [G loss: -0.234747]\n",
      "epoch5 step43080 [D loss: -0.401782] [G loss: -0.551305]\n",
      "epoch5 step43085 [D loss: 0.014750] [G loss: -0.672802]\n",
      "epoch5 step43090 [D loss: 0.067228] [G loss: -0.100468]\n",
      "epoch5 step43095 [D loss: -0.508091] [G loss: -0.766232]\n",
      "epoch5 step43100 [D loss: 0.079709] [G loss: -0.424288]\n",
      "epoch5 step43105 [D loss: 0.038361] [G loss: -0.715784]\n",
      "epoch5 step43110 [D loss: -0.233524] [G loss: -0.243565]\n",
      "epoch5 step43115 [D loss: -0.232257] [G loss: -0.610395]\n",
      "epoch5 step43120 [D loss: -0.316285] [G loss: -0.405844]\n",
      "epoch5 step43125 [D loss: 0.049687] [G loss: -0.293942]\n",
      "epoch5 step43130 [D loss: -0.133227] [G loss: -0.255352]\n",
      "epoch5 step43135 [D loss: -0.195830] [G loss: -0.577977]\n",
      "epoch5 step43140 [D loss: -0.319829] [G loss: -0.746699]\n",
      "epoch5 step43145 [D loss: -0.153144] [G loss: -0.275461]\n",
      "epoch5 step43150 [D loss: -0.188206] [G loss: -0.426434]\n",
      "epoch5 step43155 [D loss: 0.415181] [G loss: -0.061653]\n",
      "epoch5 step43160 [D loss: -0.345003] [G loss: -0.002652]\n",
      "epoch5 step43165 [D loss: -0.413329] [G loss: -0.232474]\n",
      "epoch5 step43170 [D loss: -0.002067] [G loss: 0.029792]\n",
      "epoch5 step43175 [D loss: -0.157242] [G loss: -0.268589]\n",
      "epoch5 step43180 [D loss: 0.172017] [G loss: -0.297134]\n",
      "epoch5 step43185 [D loss: -0.441528] [G loss: 0.452533]\n",
      "epoch5 step43190 [D loss: -0.029004] [G loss: -0.038807]\n",
      "epoch5 step43195 [D loss: -0.239297] [G loss: -0.406606]\n",
      "epoch5 step43200 [D loss: -0.396643] [G loss: 0.078795]\n",
      "epoch5 step43205 [D loss: -0.386522] [G loss: 0.056597]\n",
      "epoch5 step43210 [D loss: -0.423902] [G loss: 0.330618]\n",
      "epoch5 step43215 [D loss: -0.039706] [G loss: 0.098734]\n",
      "epoch5 step43220 [D loss: -0.057198] [G loss: 0.117696]\n",
      "epoch5 step43225 [D loss: -0.318215] [G loss: 0.252722]\n",
      "epoch5 step43230 [D loss: -0.032728] [G loss: -0.070439]\n",
      "epoch5 step43235 [D loss: 0.075742] [G loss: -0.054776]\n",
      "epoch5 step43240 [D loss: 0.092130] [G loss: 0.377799]\n",
      "epoch5 step43245 [D loss: -0.217473] [G loss: -0.147635]\n",
      "epoch5 step43250 [D loss: -0.184704] [G loss: 0.276710]\n",
      "epoch5 step43255 [D loss: -0.422347] [G loss: -0.119078]\n",
      "epoch5 step43260 [D loss: 0.212434] [G loss: 0.176743]\n",
      "epoch5 step43265 [D loss: 0.188798] [G loss: 0.033577]\n",
      "epoch5 step43270 [D loss: -0.221147] [G loss: 0.111064]\n",
      "epoch5 step43275 [D loss: -0.401714] [G loss: 0.142785]\n",
      "epoch5 step43280 [D loss: -0.283761] [G loss: 0.276362]\n",
      "epoch5 step43285 [D loss: -0.134127] [G loss: 0.127946]\n",
      "epoch5 step43290 [D loss: -0.001163] [G loss: 0.388545]\n",
      "epoch5 step43295 [D loss: 0.050437] [G loss: -0.087804]\n",
      "epoch5 step43300 [D loss: -0.470423] [G loss: 0.309321]\n",
      "epoch5 step43305 [D loss: 0.066710] [G loss: 0.050605]\n",
      "epoch5 step43310 [D loss: 0.080494] [G loss: -0.017660]\n",
      "epoch5 step43315 [D loss: -0.674681] [G loss: 0.125147]\n",
      "epoch5 step43320 [D loss: 0.108785] [G loss: -0.017010]\n",
      "epoch5 step43325 [D loss: 0.479568] [G loss: -0.006332]\n",
      "epoch5 step43330 [D loss: 0.181026] [G loss: -0.001971]\n",
      "epoch5 step43335 [D loss: -0.030226] [G loss: 0.217469]\n",
      "epoch5 step43340 [D loss: 0.297374] [G loss: -0.001922]\n",
      "epoch5 step43345 [D loss: -0.496631] [G loss: 0.263209]\n",
      "epoch5 step43350 [D loss: -0.465504] [G loss: 0.560871]\n",
      "epoch5 step43355 [D loss: 0.501911] [G loss: 0.095998]\n",
      "epoch5 step43360 [D loss: -0.066365] [G loss: 0.477355]\n",
      "epoch5 step43365 [D loss: -0.379924] [G loss: 0.237063]\n",
      "epoch5 step43370 [D loss: 0.033937] [G loss: 0.464721]\n",
      "epoch5 step43375 [D loss: -0.252073] [G loss: 0.156718]\n",
      "epoch5 step43380 [D loss: -0.337961] [G loss: 0.305330]\n",
      "epoch5 step43385 [D loss: -0.207427] [G loss: 0.123645]\n",
      "epoch5 step43390 [D loss: -0.755502] [G loss: 0.572477]\n",
      "epoch5 step43395 [D loss: 0.027233] [G loss: 0.732925]\n",
      "epoch5 step43400 [D loss: -0.733229] [G loss: 0.563349]\n",
      "epoch5 step43405 [D loss: -0.009663] [G loss: 0.189117]\n",
      "epoch5 step43410 [D loss: -0.275450] [G loss: 0.710632]\n",
      "epoch5 step43415 [D loss: -0.320859] [G loss: 0.524041]\n",
      "epoch5 step43420 [D loss: -0.483852] [G loss: 0.392100]\n",
      "epoch5 step43425 [D loss: -0.082246] [G loss: 0.054119]\n",
      "epoch5 step43430 [D loss: -0.155040] [G loss: 0.130189]\n",
      "epoch5 step43435 [D loss: -0.291830] [G loss: 0.031736]\n",
      "epoch5 step43440 [D loss: -0.035759] [G loss: -0.107757]\n",
      "epoch5 step43445 [D loss: 0.246366] [G loss: -0.251701]\n",
      "epoch5 step43450 [D loss: 0.063122] [G loss: -0.216541]\n",
      "epoch5 step43455 [D loss: 0.016536] [G loss: 0.239074]\n",
      "epoch5 step43460 [D loss: 0.194681] [G loss: -0.248329]\n",
      "epoch5 step43465 [D loss: -0.327951] [G loss: -0.566340]\n",
      "epoch5 step43470 [D loss: -0.285298] [G loss: -0.402421]\n",
      "epoch5 step43475 [D loss: 0.136310] [G loss: -0.112131]\n",
      "epoch5 step43480 [D loss: -0.176107] [G loss: -0.397660]\n",
      "epoch5 step43485 [D loss: 0.151737] [G loss: -0.394640]\n",
      "epoch5 step43490 [D loss: -0.006094] [G loss: -0.279474]\n",
      "epoch5 step43495 [D loss: -0.065591] [G loss: -0.151590]\n",
      "epoch5 step43500 [D loss: -0.171230] [G loss: -0.163469]\n",
      "epoch5 step43505 [D loss: -0.310398] [G loss: 0.033629]\n",
      "epoch5 step43510 [D loss: -0.419554] [G loss: -0.165524]\n",
      "epoch5 step43515 [D loss: -0.263319] [G loss: -0.485768]\n",
      "epoch5 step43520 [D loss: -0.376614] [G loss: -0.146701]\n",
      "epoch5 step43525 [D loss: -0.004208] [G loss: -0.158363]\n",
      "epoch5 step43530 [D loss: 0.132095] [G loss: -0.399768]\n",
      "epoch5 step43535 [D loss: -0.239939] [G loss: -0.259433]\n",
      "epoch5 step43540 [D loss: -0.714418] [G loss: 0.205858]\n",
      "epoch5 step43545 [D loss: -0.007490] [G loss: -0.244886]\n",
      "epoch5 step43550 [D loss: -0.417995] [G loss: 0.030096]\n",
      "epoch5 step43555 [D loss: -0.470602] [G loss: 0.015121]\n",
      "epoch5 step43560 [D loss: -0.739138] [G loss: 0.287330]\n",
      "epoch5 step43565 [D loss: 0.390980] [G loss: 0.001040]\n",
      "epoch5 step43570 [D loss: -0.308126] [G loss: 0.110089]\n",
      "epoch5 step43575 [D loss: -0.105291] [G loss: 0.122987]\n",
      "epoch5 step43580 [D loss: -0.216936] [G loss: -0.147145]\n",
      "epoch5 step43585 [D loss: 0.374146] [G loss: -0.066586]\n",
      "epoch5 step43590 [D loss: -0.380000] [G loss: 0.195591]\n",
      "epoch5 step43595 [D loss: 0.187721] [G loss: 0.367051]\n",
      "epoch5 step43600 [D loss: 0.103098] [G loss: 0.153907]\n",
      "epoch5 step43605 [D loss: -0.295972] [G loss: 0.013788]\n",
      "epoch5 step43610 [D loss: -0.692720] [G loss: 0.356073]\n",
      "epoch5 step43615 [D loss: 0.150413] [G loss: 0.341974]\n",
      "epoch5 step43620 [D loss: 0.018024] [G loss: 0.090024]\n",
      "epoch5 step43625 [D loss: -0.359619] [G loss: 0.355096]\n",
      "epoch5 step43630 [D loss: -0.347110] [G loss: 0.532471]\n",
      "epoch5 step43635 [D loss: -0.038239] [G loss: 0.356828]\n",
      "epoch5 step43640 [D loss: -0.364512] [G loss: 0.422995]\n",
      "epoch5 step43645 [D loss: -0.476407] [G loss: -0.133307]\n",
      "epoch5 step43650 [D loss: -0.984190] [G loss: 0.320129]\n",
      "epoch5 step43655 [D loss: 0.433874] [G loss: 0.008255]\n",
      "epoch5 step43660 [D loss: 0.112660] [G loss: 0.254347]\n",
      "epoch5 step43665 [D loss: -0.453707] [G loss: 0.491000]\n",
      "epoch5 step43670 [D loss: -0.269151] [G loss: -0.030767]\n",
      "epoch5 step43675 [D loss: 0.334204] [G loss: -0.213200]\n",
      "epoch5 step43680 [D loss: -0.547435] [G loss: 0.317131]\n",
      "epoch5 step43685 [D loss: 0.246039] [G loss: 0.218565]\n",
      "epoch5 step43690 [D loss: 0.151743] [G loss: -0.203356]\n",
      "epoch5 step43695 [D loss: -0.055578] [G loss: 0.063925]\n",
      "epoch5 step43700 [D loss: -0.021494] [G loss: -0.038955]\n",
      "epoch5 step43705 [D loss: -0.622526] [G loss: 0.160801]\n",
      "epoch5 step43710 [D loss: 0.045095] [G loss: 0.154841]\n",
      "epoch5 step43715 [D loss: -0.387817] [G loss: 0.018792]\n",
      "epoch5 step43720 [D loss: -0.011682] [G loss: -0.169166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step43725 [D loss: -0.190341] [G loss: -0.238250]\n",
      "epoch5 step43730 [D loss: -0.837626] [G loss: -0.504356]\n",
      "epoch5 step43735 [D loss: -0.156436] [G loss: -0.285622]\n",
      "epoch5 step43740 [D loss: -0.585113] [G loss: -0.260094]\n",
      "epoch5 step43745 [D loss: -0.540407] [G loss: 0.269318]\n",
      "epoch5 step43750 [D loss: -0.656779] [G loss: -0.052268]\n",
      "epoch5 step43755 [D loss: -0.011998] [G loss: 0.181916]\n",
      "epoch5 step43760 [D loss: -0.205909] [G loss: 0.124759]\n",
      "epoch5 step43765 [D loss: -0.404709] [G loss: -0.143362]\n",
      "epoch5 step43770 [D loss: -0.097006] [G loss: 0.104661]\n",
      "epoch5 step43775 [D loss: 0.243311] [G loss: -0.114429]\n",
      "epoch5 step43780 [D loss: -0.170275] [G loss: 0.009051]\n",
      "epoch5 step43785 [D loss: -0.232366] [G loss: -0.032238]\n",
      "epoch5 step43790 [D loss: -0.429837] [G loss: -0.103089]\n",
      "epoch5 step43795 [D loss: -0.340778] [G loss: -0.007919]\n",
      "epoch5 step43800 [D loss: 0.359839] [G loss: -0.193307]\n",
      "epoch5 step43805 [D loss: 0.087484] [G loss: -0.049508]\n",
      "epoch5 step43810 [D loss: 0.160673] [G loss: -0.376599]\n",
      "epoch5 step43815 [D loss: 0.904175] [G loss: -0.299424]\n",
      "epoch5 step43820 [D loss: -0.255824] [G loss: 0.248214]\n",
      "epoch5 step43825 [D loss: -0.254559] [G loss: 0.439572]\n",
      "epoch5 step43830 [D loss: 0.145492] [G loss: -0.133027]\n",
      "epoch5 step43835 [D loss: 0.162254] [G loss: 0.297996]\n",
      "epoch5 step43840 [D loss: -0.298950] [G loss: 0.479453]\n",
      "epoch5 step43845 [D loss: -0.288010] [G loss: 0.667071]\n",
      "epoch5 step43850 [D loss: 0.226553] [G loss: 0.406838]\n",
      "epoch5 step43855 [D loss: -0.214483] [G loss: 0.361383]\n",
      "epoch5 step43860 [D loss: -0.202320] [G loss: 0.247938]\n",
      "epoch5 step43865 [D loss: -0.008957] [G loss: 0.090806]\n",
      "epoch5 step43870 [D loss: -0.298026] [G loss: 0.430014]\n",
      "epoch5 step43875 [D loss: -0.110936] [G loss: 0.338152]\n",
      "epoch5 step43880 [D loss: 0.023385] [G loss: 0.432806]\n",
      "epoch5 step43885 [D loss: -0.228091] [G loss: 0.680170]\n",
      "epoch5 step43890 [D loss: -0.111623] [G loss: 0.807666]\n",
      "epoch5 step43895 [D loss: -0.252756] [G loss: 0.601149]\n",
      "epoch5 step43900 [D loss: -0.110239] [G loss: 0.413370]\n",
      "epoch5 step43905 [D loss: -0.394962] [G loss: 0.832250]\n",
      "epoch5 step43910 [D loss: -0.724187] [G loss: 0.608513]\n",
      "epoch5 step43915 [D loss: -0.473629] [G loss: 0.881060]\n",
      "epoch5 step43920 [D loss: -0.042613] [G loss: 0.799859]\n",
      "epoch5 step43925 [D loss: 0.021582] [G loss: 0.584755]\n",
      "epoch5 step43930 [D loss: -0.120378] [G loss: 0.624449]\n",
      "epoch5 step43935 [D loss: -0.487777] [G loss: 0.122680]\n",
      "epoch5 step43940 [D loss: -0.100310] [G loss: 0.476225]\n",
      "epoch5 step43945 [D loss: -0.438715] [G loss: 0.890791]\n",
      "epoch5 step43950 [D loss: -0.397880] [G loss: 0.732364]\n",
      "epoch5 step43955 [D loss: -0.028689] [G loss: 0.326058]\n",
      "epoch5 step43960 [D loss: 0.602612] [G loss: 0.243507]\n",
      "epoch5 step43965 [D loss: -0.420581] [G loss: 0.516848]\n",
      "epoch5 step43970 [D loss: -0.279011] [G loss: 0.637218]\n",
      "epoch5 step43975 [D loss: 0.099042] [G loss: 0.230182]\n",
      "epoch5 step43980 [D loss: -0.301304] [G loss: 0.349973]\n",
      "epoch5 step43985 [D loss: -0.117126] [G loss: 0.367861]\n",
      "epoch5 step43990 [D loss: -0.021518] [G loss: 0.326482]\n",
      "epoch5 step43995 [D loss: 0.285756] [G loss: -0.049521]\n",
      "epoch5 step44000 [D loss: -0.453644] [G loss: 0.176009]\n",
      "epoch5 step44005 [D loss: 0.346099] [G loss: -0.023065]\n",
      "epoch5 step44010 [D loss: -0.157887] [G loss: 0.104955]\n",
      "epoch5 step44015 [D loss: 0.014344] [G loss: -0.215386]\n",
      "epoch5 step44020 [D loss: -0.509927] [G loss: -0.104918]\n",
      "epoch5 step44025 [D loss: -0.091614] [G loss: 0.164886]\n",
      "epoch5 step44030 [D loss: -0.014499] [G loss: -0.037520]\n",
      "epoch5 step44035 [D loss: -0.182173] [G loss: -0.157168]\n",
      "epoch5 step44040 [D loss: -0.470871] [G loss: -0.090498]\n",
      "epoch5 step44045 [D loss: 0.157789] [G loss: -0.254569]\n",
      "epoch5 step44050 [D loss: 0.227087] [G loss: -0.228231]\n",
      "epoch5 step44055 [D loss: -0.081265] [G loss: -0.156939]\n",
      "epoch5 step44060 [D loss: 0.183582] [G loss: -0.564195]\n",
      "epoch5 step44065 [D loss: -0.254354] [G loss: 0.076124]\n",
      "epoch5 step44070 [D loss: 0.248799] [G loss: -0.280514]\n",
      "epoch5 step44075 [D loss: -0.635767] [G loss: 0.009008]\n",
      "epoch5 step44080 [D loss: -0.654386] [G loss: -0.661837]\n",
      "epoch5 step44085 [D loss: 0.106473] [G loss: -0.477488]\n",
      "epoch5 step44090 [D loss: -0.095241] [G loss: -0.733841]\n",
      "epoch5 step44095 [D loss: -0.034059] [G loss: -0.403114]\n",
      "epoch5 step44100 [D loss: -0.309883] [G loss: -0.254702]\n",
      "epoch5 step44105 [D loss: 0.399468] [G loss: 0.103094]\n",
      "epoch5 step44110 [D loss: -0.474358] [G loss: -0.093077]\n",
      "epoch5 step44115 [D loss: 0.128985] [G loss: -0.639171]\n",
      "epoch5 step44120 [D loss: -0.422883] [G loss: -0.168628]\n",
      "epoch5 step44125 [D loss: 0.303040] [G loss: -0.339092]\n",
      "epoch5 step44130 [D loss: -0.020421] [G loss: -0.269584]\n",
      "epoch5 step44135 [D loss: -0.179849] [G loss: -0.063768]\n",
      "epoch5 step44140 [D loss: -0.385380] [G loss: 0.051376]\n",
      "epoch5 step44145 [D loss: -0.356592] [G loss: 0.147044]\n",
      "epoch5 step44150 [D loss: -0.050915] [G loss: -0.107832]\n",
      "epoch5 step44155 [D loss: 0.103251] [G loss: -0.492967]\n",
      "epoch5 step44160 [D loss: -0.159816] [G loss: -0.314977]\n",
      "epoch5 step44165 [D loss: -0.287129] [G loss: 0.008454]\n",
      "epoch5 step44170 [D loss: 0.229790] [G loss: -0.143009]\n",
      "epoch5 step44175 [D loss: 0.036928] [G loss: 0.161505]\n",
      "epoch5 step44180 [D loss: 0.087337] [G loss: -0.116363]\n",
      "epoch5 step44185 [D loss: -0.082764] [G loss: 0.075896]\n",
      "epoch5 step44190 [D loss: -0.454734] [G loss: 0.086794]\n",
      "epoch5 step44195 [D loss: 0.235602] [G loss: 0.115450]\n",
      "epoch5 step44200 [D loss: -0.541404] [G loss: 0.187647]\n",
      "epoch5 step44205 [D loss: -0.182621] [G loss: 0.123049]\n",
      "epoch5 step44210 [D loss: 0.189494] [G loss: 0.189436]\n",
      "epoch5 step44215 [D loss: -0.303311] [G loss: 0.249962]\n",
      "epoch5 step44220 [D loss: -0.121691] [G loss: 0.025573]\n",
      "epoch5 step44225 [D loss: -0.194395] [G loss: 0.740137]\n",
      "epoch5 step44230 [D loss: -0.220424] [G loss: 0.202503]\n",
      "epoch5 step44235 [D loss: -0.518246] [G loss: 0.538919]\n",
      "epoch5 step44240 [D loss: -0.566403] [G loss: 0.385962]\n",
      "epoch5 step44245 [D loss: 0.278051] [G loss: 0.171386]\n",
      "epoch5 step44250 [D loss: -0.229951] [G loss: 0.226693]\n",
      "epoch5 step44255 [D loss: 0.236408] [G loss: 0.551169]\n",
      "epoch5 step44260 [D loss: -0.095135] [G loss: 0.605246]\n",
      "epoch5 step44265 [D loss: 0.156044] [G loss: 0.722127]\n",
      "epoch5 step44270 [D loss: 0.091309] [G loss: 0.433729]\n",
      "epoch5 step44275 [D loss: -0.118937] [G loss: 0.735806]\n",
      "epoch5 step44280 [D loss: -0.076793] [G loss: 0.583965]\n",
      "epoch5 step44285 [D loss: -0.315712] [G loss: 0.511482]\n",
      "epoch5 step44290 [D loss: -0.289973] [G loss: 0.434093]\n",
      "epoch5 step44295 [D loss: -0.270784] [G loss: 0.377305]\n",
      "epoch5 step44300 [D loss: -0.119034] [G loss: 0.283258]\n",
      "epoch5 step44305 [D loss: -0.417711] [G loss: 0.735119]\n",
      "epoch5 step44310 [D loss: -0.361095] [G loss: 0.341276]\n",
      "epoch5 step44315 [D loss: 0.548216] [G loss: 0.576897]\n",
      "epoch5 step44320 [D loss: -0.278417] [G loss: 0.624239]\n",
      "epoch5 step44325 [D loss: 0.283261] [G loss: 0.565704]\n",
      "epoch5 step44330 [D loss: 0.143068] [G loss: 0.073588]\n",
      "epoch5 step44335 [D loss: 0.381058] [G loss: 0.454727]\n",
      "epoch5 step44340 [D loss: -0.122286] [G loss: 0.429997]\n",
      "epoch5 step44345 [D loss: 0.135807] [G loss: -0.103335]\n",
      "epoch5 step44350 [D loss: -0.025114] [G loss: 0.027522]\n",
      "epoch5 step44355 [D loss: -0.293864] [G loss: 0.217115]\n",
      "epoch5 step44360 [D loss: 0.150572] [G loss: 0.018278]\n",
      "epoch5 step44365 [D loss: -0.555934] [G loss: -0.240266]\n",
      "epoch5 step44370 [D loss: 0.027906] [G loss: -0.298661]\n",
      "epoch5 step44375 [D loss: -0.391647] [G loss: -0.243177]\n",
      "epoch5 step44380 [D loss: -0.495048] [G loss: -0.752220]\n",
      "epoch5 step44385 [D loss: -0.402157] [G loss: -0.288473]\n",
      "epoch5 step44390 [D loss: -0.269222] [G loss: -0.243754]\n",
      "epoch5 step44395 [D loss: -0.076741] [G loss: -0.599015]\n",
      "epoch5 step44400 [D loss: -0.132594] [G loss: -0.467382]\n",
      "epoch5 step44405 [D loss: 0.076982] [G loss: -0.656890]\n",
      "epoch5 step44410 [D loss: -0.685472] [G loss: -0.381301]\n",
      "epoch5 step44415 [D loss: 0.267090] [G loss: -0.752703]\n",
      "epoch5 step44420 [D loss: 0.314041] [G loss: -0.321184]\n",
      "epoch5 step44425 [D loss: -0.145892] [G loss: -0.568694]\n",
      "epoch5 step44430 [D loss: 0.453310] [G loss: -0.623802]\n",
      "epoch5 step44435 [D loss: -0.015090] [G loss: -0.028541]\n",
      "epoch5 step44440 [D loss: -0.016322] [G loss: -0.039317]\n",
      "epoch5 step44445 [D loss: -0.045103] [G loss: -0.151449]\n",
      "epoch5 step44450 [D loss: 0.212797] [G loss: -0.155133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step44455 [D loss: -0.006671] [G loss: -0.248305]\n",
      "epoch5 step44460 [D loss: -0.237249] [G loss: -0.063169]\n",
      "epoch5 step44465 [D loss: 0.035724] [G loss: -0.326248]\n",
      "epoch5 step44470 [D loss: 0.075697] [G loss: -0.152445]\n",
      "epoch5 step44475 [D loss: 0.157179] [G loss: -0.042839]\n",
      "epoch5 step44480 [D loss: 0.122759] [G loss: -0.027818]\n",
      "epoch5 step44485 [D loss: -0.608148] [G loss: 0.435152]\n",
      "epoch5 step44490 [D loss: -0.091165] [G loss: 0.112572]\n",
      "epoch5 step44495 [D loss: 0.037931] [G loss: 0.143020]\n",
      "epoch5 step44500 [D loss: 0.100674] [G loss: 0.089018]\n",
      "epoch5 step44505 [D loss: -0.237496] [G loss: 0.115499]\n",
      "epoch5 step44510 [D loss: -0.348308] [G loss: 0.166187]\n",
      "epoch5 step44515 [D loss: 0.098304] [G loss: 0.270553]\n",
      "epoch5 step44520 [D loss: -0.460869] [G loss: -0.091123]\n",
      "epoch5 step44525 [D loss: -0.184029] [G loss: 0.062451]\n",
      "epoch5 step44530 [D loss: -0.377502] [G loss: 0.115536]\n",
      "epoch5 step44535 [D loss: -0.094958] [G loss: -0.238212]\n",
      "epoch5 step44540 [D loss: -0.119787] [G loss: -0.304443]\n",
      "epoch5 step44545 [D loss: 0.041445] [G loss: 0.503679]\n",
      "epoch5 step44550 [D loss: 0.021766] [G loss: -0.128435]\n",
      "epoch5 step44555 [D loss: 0.007482] [G loss: 0.226806]\n",
      "epoch5 step44560 [D loss: -0.392563] [G loss: 0.313191]\n",
      "epoch5 step44565 [D loss: 0.195466] [G loss: -0.097151]\n",
      "epoch5 step44570 [D loss: -0.294059] [G loss: 0.233061]\n",
      "epoch5 step44575 [D loss: -0.101227] [G loss: 0.150521]\n",
      "epoch5 step44580 [D loss: -0.183831] [G loss: 0.077148]\n",
      "epoch5 step44585 [D loss: 0.141802] [G loss: 0.196155]\n",
      "epoch5 step44590 [D loss: -0.011153] [G loss: 0.219879]\n",
      "epoch5 step44595 [D loss: -0.432781] [G loss: 0.181493]\n",
      "epoch5 step44600 [D loss: 0.076610] [G loss: 0.096930]\n",
      "epoch5 step44605 [D loss: 0.027489] [G loss: 0.169304]\n",
      "epoch5 step44610 [D loss: 0.040641] [G loss: 0.209129]\n",
      "epoch5 step44615 [D loss: 0.121104] [G loss: 0.252853]\n",
      "epoch5 step44620 [D loss: 0.215876] [G loss: 0.048725]\n",
      "epoch5 step44625 [D loss: 0.131209] [G loss: 0.175776]\n",
      "epoch5 step44630 [D loss: -0.399949] [G loss: 0.115945]\n",
      "epoch5 step44635 [D loss: -0.826679] [G loss: 0.032276]\n",
      "epoch5 step44640 [D loss: -0.161244] [G loss: 0.176964]\n",
      "epoch5 step44645 [D loss: -0.058704] [G loss: 0.212439]\n",
      "epoch5 step44650 [D loss: 0.022393] [G loss: 0.529907]\n",
      "epoch5 step44655 [D loss: -0.425490] [G loss: 0.132473]\n",
      "epoch5 step44660 [D loss: -0.012496] [G loss: 0.399377]\n",
      "epoch5 step44665 [D loss: -0.088317] [G loss: 0.501242]\n",
      "epoch5 step44670 [D loss: -0.130776] [G loss: 0.257288]\n",
      "epoch5 step44675 [D loss: -0.331059] [G loss: 0.437888]\n",
      "epoch5 step44680 [D loss: 0.175209] [G loss: 0.154940]\n",
      "epoch5 step44685 [D loss: 0.149076] [G loss: 0.329077]\n",
      "epoch5 step44690 [D loss: -0.235209] [G loss: 0.435390]\n",
      "epoch5 step44695 [D loss: -0.284242] [G loss: 0.179778]\n",
      "epoch5 step44700 [D loss: 0.048662] [G loss: 0.275262]\n",
      "epoch5 step44705 [D loss: -0.091063] [G loss: 0.315550]\n",
      "epoch5 step44710 [D loss: 0.139003] [G loss: 0.384642]\n",
      "epoch5 step44715 [D loss: -0.273139] [G loss: 0.167519]\n",
      "epoch5 step44720 [D loss: -0.559766] [G loss: 0.557607]\n",
      "epoch5 step44725 [D loss: -0.248307] [G loss: 0.527824]\n",
      "epoch5 step44730 [D loss: 0.255535] [G loss: 0.337636]\n",
      "epoch5 step44735 [D loss: 0.382516] [G loss: 0.257920]\n",
      "epoch5 step44740 [D loss: 0.037865] [G loss: 0.143953]\n",
      "epoch5 step44745 [D loss: -0.184733] [G loss: 0.583674]\n",
      "epoch5 step44750 [D loss: -0.224985] [G loss: 0.564529]\n",
      "epoch5 step44755 [D loss: -0.046316] [G loss: 0.519032]\n",
      "epoch5 step44760 [D loss: -0.638872] [G loss: 0.262604]\n",
      "epoch5 step44765 [D loss: 0.040202] [G loss: 0.601846]\n",
      "epoch5 step44770 [D loss: -0.201761] [G loss: 0.327552]\n",
      "epoch5 step44775 [D loss: -0.549680] [G loss: 0.355013]\n",
      "epoch5 step44780 [D loss: 0.038967] [G loss: 0.441621]\n",
      "epoch5 step44785 [D loss: -0.093885] [G loss: 0.419363]\n",
      "epoch5 step44790 [D loss: -0.212723] [G loss: 0.459527]\n",
      "epoch5 step44795 [D loss: -0.440299] [G loss: 0.383045]\n",
      "epoch5 step44800 [D loss: -0.086737] [G loss: 0.183454]\n",
      "epoch5 step44805 [D loss: -0.066027] [G loss: 0.335682]\n",
      "epoch5 step44810 [D loss: -0.119451] [G loss: 0.085423]\n",
      "epoch5 step44815 [D loss: -0.295205] [G loss: 0.635804]\n",
      "epoch5 step44820 [D loss: 0.036435] [G loss: 0.382597]\n",
      "epoch5 step44825 [D loss: 0.297776] [G loss: 0.271532]\n",
      "epoch5 step44830 [D loss: -0.275989] [G loss: 0.366281]\n",
      "epoch5 step44835 [D loss: -0.161718] [G loss: 0.013842]\n",
      "epoch5 step44840 [D loss: -0.441514] [G loss: 0.270465]\n",
      "epoch5 step44845 [D loss: -0.024433] [G loss: 0.144020]\n",
      "epoch5 step44850 [D loss: -0.063215] [G loss: 0.173845]\n",
      "epoch5 step44855 [D loss: -0.187760] [G loss: 0.168290]\n",
      "epoch5 step44860 [D loss: 0.018849] [G loss: 0.027218]\n",
      "epoch5 step44865 [D loss: -0.415404] [G loss: 0.010379]\n",
      "epoch5 step44870 [D loss: -0.213432] [G loss: 0.304202]\n",
      "epoch5 step44875 [D loss: -0.153538] [G loss: 0.019062]\n",
      "epoch5 step44880 [D loss: 0.055454] [G loss: -0.063655]\n",
      "epoch5 step44885 [D loss: 0.173238] [G loss: 0.101200]\n",
      "epoch5 step44890 [D loss: -0.592570] [G loss: 0.319473]\n",
      "epoch5 step44895 [D loss: -0.158620] [G loss: 0.539392]\n",
      "epoch5 step44900 [D loss: 0.021986] [G loss: 0.319760]\n",
      "epoch5 step44905 [D loss: -0.051463] [G loss: 0.342318]\n",
      "epoch5 step44910 [D loss: -0.223996] [G loss: 0.343795]\n",
      "epoch5 step44915 [D loss: 0.432121] [G loss: 0.294779]\n",
      "epoch5 step44920 [D loss: -0.033711] [G loss: 0.062299]\n",
      "epoch5 step44925 [D loss: -0.287706] [G loss: 0.063198]\n",
      "epoch5 step44930 [D loss: 0.032291] [G loss: 0.272878]\n",
      "epoch5 step44935 [D loss: 0.018029] [G loss: 0.306646]\n",
      "epoch5 step44940 [D loss: 0.056613] [G loss: 0.102618]\n",
      "epoch5 step44945 [D loss: -0.283745] [G loss: 0.169683]\n",
      "epoch5 step44950 [D loss: -0.791683] [G loss: 0.346343]\n",
      "epoch5 step44955 [D loss: -0.069714] [G loss: 0.145932]\n",
      "epoch5 step44960 [D loss: -0.420280] [G loss: -0.032468]\n",
      "epoch5 step44965 [D loss: 0.005586] [G loss: 0.041953]\n",
      "epoch5 step44970 [D loss: -0.450286] [G loss: 0.277573]\n",
      "epoch5 step44975 [D loss: -0.594966] [G loss: -0.263761]\n",
      "epoch5 step44980 [D loss: 0.002540] [G loss: 0.215544]\n",
      "epoch5 step44985 [D loss: 0.212797] [G loss: 0.431527]\n",
      "epoch5 step44990 [D loss: -0.059477] [G loss: 0.023534]\n",
      "epoch5 step44995 [D loss: 0.058880] [G loss: 0.133693]\n",
      "epoch5 step45000 [D loss: -0.288605] [G loss: 0.062950]\n",
      "epoch5 step45005 [D loss: -0.512317] [G loss: 0.146167]\n",
      "epoch5 step45010 [D loss: -0.077323] [G loss: 0.206348]\n",
      "epoch5 step45015 [D loss: -0.333967] [G loss: 0.335409]\n",
      "epoch5 step45020 [D loss: -0.144710] [G loss: 0.252968]\n",
      "epoch5 step45025 [D loss: -0.146530] [G loss: 0.335250]\n",
      "epoch5 step45030 [D loss: -0.121655] [G loss: -0.113409]\n",
      "epoch5 step45035 [D loss: -0.325453] [G loss: 0.196182]\n",
      "epoch5 step45040 [D loss: -0.300802] [G loss: 0.011993]\n",
      "epoch5 step45045 [D loss: -0.391126] [G loss: -0.274147]\n",
      "epoch5 step45050 [D loss: -0.180546] [G loss: -0.040726]\n",
      "epoch5 step45055 [D loss: -0.310250] [G loss: 0.171214]\n",
      "epoch5 step45060 [D loss: -0.114811] [G loss: -0.162664]\n",
      "epoch5 step45065 [D loss: -0.433638] [G loss: -0.042931]\n",
      "epoch5 step45070 [D loss: 0.283753] [G loss: -0.450427]\n",
      "epoch5 step45075 [D loss: -0.051986] [G loss: -0.220660]\n",
      "epoch5 step45080 [D loss: -0.505824] [G loss: -0.117566]\n",
      "epoch5 step45085 [D loss: -0.163005] [G loss: 0.142293]\n",
      "epoch5 step45090 [D loss: -0.128693] [G loss: 0.003789]\n",
      "epoch5 step45095 [D loss: 0.100870] [G loss: -0.157025]\n",
      "epoch5 step45100 [D loss: -0.229544] [G loss: -0.039713]\n",
      "epoch5 step45105 [D loss: 0.003153] [G loss: -0.085671]\n",
      "epoch5 step45110 [D loss: -0.213232] [G loss: -0.004162]\n",
      "epoch5 step45115 [D loss: 0.200116] [G loss: 0.016355]\n",
      "epoch5 step45120 [D loss: -0.033035] [G loss: -0.438342]\n",
      "epoch5 step45125 [D loss: -0.122838] [G loss: -0.186499]\n",
      "epoch5 step45130 [D loss: 0.069923] [G loss: -0.079019]\n",
      "epoch5 step45135 [D loss: -0.446760] [G loss: 0.424912]\n",
      "epoch5 step45140 [D loss: -0.087988] [G loss: -0.088634]\n",
      "epoch5 step45145 [D loss: 0.411552] [G loss: -0.149576]\n",
      "epoch5 step45150 [D loss: -0.563352] [G loss: 0.347464]\n",
      "epoch5 step45155 [D loss: -0.106631] [G loss: 0.238232]\n",
      "epoch5 step45160 [D loss: -0.475405] [G loss: -0.019122]\n",
      "epoch5 step45165 [D loss: -0.002054] [G loss: 0.129244]\n",
      "epoch5 step45170 [D loss: -0.155473] [G loss: 0.201812]\n",
      "epoch5 step45175 [D loss: 0.048328] [G loss: 0.205456]\n",
      "epoch5 step45180 [D loss: 0.339231] [G loss: -0.073292]\n",
      "epoch5 step45185 [D loss: 0.248339] [G loss: 0.363891]\n",
      "epoch5 step45190 [D loss: -0.071737] [G loss: -0.220037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step45195 [D loss: -0.703640] [G loss: 0.307393]\n",
      "epoch5 step45200 [D loss: -0.284382] [G loss: 0.426360]\n",
      "epoch5 step45205 [D loss: -0.200279] [G loss: 0.181790]\n",
      "epoch5 step45210 [D loss: 0.025574] [G loss: 0.190424]\n",
      "epoch5 step45215 [D loss: 0.049250] [G loss: 0.293521]\n",
      "epoch5 step45220 [D loss: 0.268897] [G loss: 0.294864]\n",
      "epoch5 step45225 [D loss: -0.383450] [G loss: 0.467235]\n",
      "epoch5 step45230 [D loss: 0.391313] [G loss: 0.061186]\n",
      "epoch5 step45235 [D loss: 0.325054] [G loss: 0.321844]\n",
      "epoch5 step45240 [D loss: -0.201729] [G loss: 0.158089]\n",
      "epoch5 step45245 [D loss: -0.540886] [G loss: 0.124572]\n",
      "epoch5 step45250 [D loss: -0.168907] [G loss: 0.609521]\n",
      "epoch5 step45255 [D loss: -0.055452] [G loss: 0.274472]\n",
      "epoch5 step45260 [D loss: -0.012507] [G loss: 0.161754]\n",
      "epoch5 step45265 [D loss: -0.449627] [G loss: 0.065217]\n",
      "epoch5 step45270 [D loss: 0.322214] [G loss: 0.502404]\n",
      "epoch5 step45275 [D loss: -0.322452] [G loss: 0.448789]\n",
      "epoch5 step45280 [D loss: -0.117200] [G loss: 0.588136]\n",
      "epoch5 step45285 [D loss: -0.016394] [G loss: 0.644851]\n",
      "epoch5 step45290 [D loss: -0.313601] [G loss: 0.656126]\n",
      "epoch5 step45295 [D loss: -0.376719] [G loss: 0.844299]\n",
      "epoch5 step45300 [D loss: -0.109509] [G loss: 0.926313]\n",
      "epoch5 step45305 [D loss: -0.219402] [G loss: 1.165957]\n",
      "epoch5 step45310 [D loss: -0.203885] [G loss: 1.100366]\n",
      "epoch5 step45315 [D loss: -0.017180] [G loss: 0.954503]\n",
      "epoch5 step45320 [D loss: -0.470091] [G loss: 1.078001]\n",
      "epoch5 step45325 [D loss: -0.530853] [G loss: 1.219201]\n",
      "epoch5 step45330 [D loss: -0.564605] [G loss: 1.125127]\n",
      "epoch5 step45335 [D loss: -0.124263] [G loss: 1.138205]\n",
      "epoch5 step45340 [D loss: -0.369962] [G loss: 1.219842]\n",
      "epoch5 step45345 [D loss: -0.263554] [G loss: 0.886803]\n",
      "epoch5 step45350 [D loss: -0.284365] [G loss: 1.154801]\n",
      "epoch5 step45355 [D loss: 0.136429] [G loss: 0.753934]\n",
      "epoch5 step45360 [D loss: -0.260403] [G loss: 0.727066]\n",
      "epoch5 step45365 [D loss: 0.654880] [G loss: 0.854100]\n",
      "epoch5 step45370 [D loss: -0.201638] [G loss: 0.924353]\n",
      "epoch5 step45375 [D loss: -0.129179] [G loss: 0.768773]\n",
      "epoch5 step45380 [D loss: -0.012869] [G loss: 1.067869]\n",
      "epoch5 step45385 [D loss: 0.026044] [G loss: 0.861359]\n",
      "epoch5 step45390 [D loss: 0.012852] [G loss: 1.066198]\n",
      "epoch5 step45395 [D loss: -0.413728] [G loss: 0.688762]\n",
      "epoch5 step45400 [D loss: -0.112153] [G loss: 1.025895]\n",
      "epoch5 step45405 [D loss: -0.484788] [G loss: 0.218535]\n",
      "epoch5 step45410 [D loss: -0.084107] [G loss: 0.542714]\n",
      "epoch5 step45415 [D loss: -0.239703] [G loss: 0.861269]\n",
      "epoch5 step45420 [D loss: -0.445091] [G loss: 0.931690]\n",
      "epoch5 step45425 [D loss: 0.126744] [G loss: 0.514686]\n",
      "epoch5 step45430 [D loss: -0.212103] [G loss: 0.840652]\n",
      "epoch5 step45435 [D loss: -0.064945] [G loss: 0.898625]\n",
      "epoch5 step45440 [D loss: -0.260503] [G loss: 0.626551]\n",
      "epoch5 step45445 [D loss: -0.634392] [G loss: 0.453786]\n",
      "epoch5 step45450 [D loss: -0.176932] [G loss: 0.333814]\n",
      "epoch5 step45455 [D loss: -0.151613] [G loss: 0.485740]\n",
      "epoch5 step45460 [D loss: 0.420801] [G loss: 0.243616]\n",
      "epoch5 step45465 [D loss: -0.192833] [G loss: 0.289839]\n",
      "epoch5 step45470 [D loss: -0.269632] [G loss: 0.361796]\n",
      "epoch5 step45475 [D loss: 0.275673] [G loss: 0.446647]\n",
      "epoch5 step45480 [D loss: -0.202579] [G loss: 0.154546]\n",
      "epoch5 step45485 [D loss: -0.029176] [G loss: 0.016758]\n",
      "epoch5 step45490 [D loss: 0.282959] [G loss: 0.156104]\n",
      "epoch5 step45495 [D loss: -0.388557] [G loss: 0.288838]\n",
      "epoch5 step45500 [D loss: -0.300406] [G loss: -0.141256]\n",
      "epoch5 step45505 [D loss: -0.816927] [G loss: -0.335174]\n",
      "epoch5 step45510 [D loss: 0.148473] [G loss: -0.197501]\n",
      "epoch5 step45515 [D loss: 0.228864] [G loss: -0.525267]\n",
      "epoch5 step45520 [D loss: -0.132222] [G loss: 0.020468]\n",
      "epoch5 step45525 [D loss: -0.073750] [G loss: -0.220469]\n",
      "epoch5 step45530 [D loss: 0.253455] [G loss: -0.046622]\n",
      "epoch5 step45535 [D loss: -0.345750] [G loss: 0.356959]\n",
      "epoch5 step45540 [D loss: -0.334763] [G loss: 0.136731]\n",
      "epoch5 step45545 [D loss: 0.273296] [G loss: -0.179548]\n",
      "epoch5 step45550 [D loss: 0.049686] [G loss: 0.023396]\n",
      "epoch5 step45555 [D loss: -0.100719] [G loss: -0.458993]\n",
      "epoch5 step45560 [D loss: 0.046810] [G loss: -0.146842]\n",
      "epoch5 step45565 [D loss: -0.400618] [G loss: 0.088249]\n",
      "epoch5 step45570 [D loss: 0.395148] [G loss: -0.066299]\n",
      "epoch5 step45575 [D loss: -0.271085] [G loss: -0.187426]\n",
      "epoch5 step45580 [D loss: -0.292495] [G loss: -0.053156]\n",
      "epoch5 step45585 [D loss: -0.373911] [G loss: 0.162661]\n",
      "epoch5 step45590 [D loss: 0.135427] [G loss: 0.052759]\n",
      "epoch5 step45595 [D loss: 0.166439] [G loss: -0.053511]\n",
      "epoch5 step45600 [D loss: 0.163355] [G loss: 0.104221]\n",
      "epoch5 step45605 [D loss: 0.168644] [G loss: 0.281831]\n",
      "epoch5 step45610 [D loss: -0.132022] [G loss: 0.373663]\n",
      "epoch5 step45615 [D loss: 0.074126] [G loss: 0.099072]\n",
      "epoch5 step45620 [D loss: -0.648235] [G loss: 0.782418]\n",
      "epoch5 step45625 [D loss: -0.100534] [G loss: 0.053761]\n",
      "epoch5 step45630 [D loss: 0.440954] [G loss: 0.399149]\n",
      "epoch5 step45635 [D loss: -0.357581] [G loss: 0.286812]\n",
      "epoch5 step45640 [D loss: -0.409478] [G loss: 0.782791]\n",
      "epoch5 step45645 [D loss: -0.350733] [G loss: 0.386724]\n",
      "epoch5 step45650 [D loss: -0.530844] [G loss: 0.291445]\n",
      "epoch5 step45655 [D loss: -0.221273] [G loss: 0.576602]\n",
      "epoch5 step45660 [D loss: 0.201968] [G loss: 0.320226]\n",
      "epoch5 step45665 [D loss: 0.397014] [G loss: 0.340797]\n",
      "epoch5 step45670 [D loss: 0.039976] [G loss: 0.279469]\n",
      "epoch5 step45675 [D loss: 0.162085] [G loss: 0.845587]\n",
      "epoch5 step45680 [D loss: -0.183151] [G loss: 0.782835]\n",
      "epoch5 step45685 [D loss: -0.047187] [G loss: 0.753058]\n",
      "epoch5 step45690 [D loss: -0.143006] [G loss: 0.465075]\n",
      "epoch5 step45695 [D loss: -0.468879] [G loss: 0.723699]\n",
      "epoch5 step45700 [D loss: 0.030653] [G loss: 0.506029]\n",
      "epoch5 step45705 [D loss: -0.360676] [G loss: 0.376348]\n",
      "epoch5 step45710 [D loss: 0.142415] [G loss: 0.569518]\n",
      "epoch5 step45715 [D loss: -0.795888] [G loss: 0.510353]\n",
      "epoch5 step45720 [D loss: -0.254271] [G loss: 0.357615]\n",
      "epoch5 step45725 [D loss: 0.001660] [G loss: 0.506989]\n",
      "epoch5 step45730 [D loss: 0.106530] [G loss: 0.453034]\n",
      "epoch5 step45735 [D loss: -0.257329] [G loss: 0.390097]\n",
      "epoch5 step45740 [D loss: 0.239867] [G loss: 0.275308]\n",
      "epoch5 step45745 [D loss: -0.163942] [G loss: 0.120973]\n",
      "epoch5 step45750 [D loss: -0.286355] [G loss: 0.413208]\n",
      "epoch5 step45755 [D loss: 0.106503] [G loss: 0.171430]\n",
      "epoch5 step45760 [D loss: -0.354942] [G loss: 0.415734]\n",
      "epoch5 step45765 [D loss: -0.140645] [G loss: 0.343330]\n",
      "epoch5 step45770 [D loss: -0.199311] [G loss: 0.484716]\n",
      "epoch5 step45775 [D loss: 0.407657] [G loss: -0.004797]\n",
      "epoch5 step45780 [D loss: -0.391802] [G loss: 0.362964]\n",
      "epoch5 step45785 [D loss: 0.098414] [G loss: 0.228072]\n",
      "epoch5 step45790 [D loss: -0.359100] [G loss: 0.038927]\n",
      "epoch5 step45795 [D loss: -0.095886] [G loss: 0.299566]\n",
      "epoch5 step45800 [D loss: -0.349252] [G loss: 0.152847]\n",
      "epoch5 step45805 [D loss: -0.595968] [G loss: 0.289415]\n",
      "epoch5 step45810 [D loss: -0.200438] [G loss: 0.754562]\n",
      "epoch5 step45815 [D loss: -0.465548] [G loss: 0.385047]\n",
      "epoch5 step45820 [D loss: -0.428815] [G loss: 0.029378]\n",
      "epoch5 step45825 [D loss: 0.012604] [G loss: -0.120328]\n",
      "epoch5 step45830 [D loss: -0.217423] [G loss: 0.193921]\n",
      "epoch5 step45835 [D loss: -0.373930] [G loss: 0.205976]\n",
      "epoch5 step45840 [D loss: -0.510216] [G loss: 0.647030]\n",
      "epoch5 step45845 [D loss: -0.524833] [G loss: -0.185023]\n",
      "epoch5 step45850 [D loss: -0.650171] [G loss: 0.266906]\n",
      "epoch5 step45855 [D loss: -0.639006] [G loss: 0.137942]\n",
      "epoch5 step45860 [D loss: -0.550195] [G loss: -0.178693]\n",
      "epoch5 step45865 [D loss: -0.513928] [G loss: -0.136523]\n",
      "epoch5 step45870 [D loss: -0.523486] [G loss: -0.223960]\n",
      "epoch5 step45875 [D loss: -0.288881] [G loss: 0.178764]\n",
      "epoch5 step45880 [D loss: -0.502724] [G loss: 0.173060]\n",
      "epoch5 step45885 [D loss: -0.035122] [G loss: -0.081080]\n",
      "epoch5 step45890 [D loss: -0.694788] [G loss: 0.290240]\n",
      "epoch5 step45895 [D loss: -0.505885] [G loss: 0.119427]\n",
      "epoch5 step45900 [D loss: -0.121362] [G loss: -0.207276]\n",
      "epoch5 step45905 [D loss: -0.332886] [G loss: -0.273462]\n",
      "epoch5 step45910 [D loss: 0.011550] [G loss: 0.139530]\n",
      "epoch5 step45915 [D loss: -0.452408] [G loss: -0.408525]\n",
      "epoch5 step45920 [D loss: 0.166010] [G loss: -0.082300]\n",
      "epoch5 step45925 [D loss: -0.527812] [G loss: -0.337362]\n",
      "epoch5 step45930 [D loss: -0.284186] [G loss: -0.322019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step45935 [D loss: 0.188859] [G loss: 0.065450]\n",
      "epoch5 step45940 [D loss: 0.177150] [G loss: -0.344118]\n",
      "epoch5 step45945 [D loss: 0.144427] [G loss: -0.379648]\n",
      "epoch5 step45950 [D loss: -0.301037] [G loss: -0.189436]\n",
      "epoch5 step45955 [D loss: -0.121482] [G loss: 0.299920]\n",
      "epoch5 step45960 [D loss: -0.708152] [G loss: -0.029003]\n",
      "epoch5 step45965 [D loss: 0.182780] [G loss: -0.327316]\n",
      "epoch5 step45970 [D loss: 0.167439] [G loss: -0.071468]\n",
      "epoch5 step45975 [D loss: -0.206908] [G loss: -0.200299]\n",
      "epoch5 step45980 [D loss: 0.149705] [G loss: -0.118084]\n",
      "epoch5 step45985 [D loss: 0.020164] [G loss: -0.218120]\n",
      "epoch5 step45990 [D loss: -0.281746] [G loss: 0.205059]\n",
      "epoch5 step45995 [D loss: -0.192306] [G loss: -0.421671]\n",
      "epoch5 step46000 [D loss: -0.065876] [G loss: -0.185771]\n",
      "epoch5 step46005 [D loss: 0.047160] [G loss: 0.213282]\n",
      "epoch5 step46010 [D loss: -0.071820] [G loss: -0.169018]\n",
      "epoch5 step46015 [D loss: -0.256207] [G loss: -0.145164]\n",
      "epoch5 step46020 [D loss: -0.306241] [G loss: -0.202484]\n",
      "epoch5 step46025 [D loss: -0.051112] [G loss: -0.607971]\n",
      "epoch5 step46030 [D loss: 0.071705] [G loss: -0.123094]\n",
      "epoch5 step46035 [D loss: 0.270974] [G loss: -0.314801]\n",
      "epoch5 step46040 [D loss: -0.336025] [G loss: -0.485922]\n",
      "epoch5 step46045 [D loss: -0.492088] [G loss: -0.279643]\n",
      "epoch5 step46050 [D loss: -0.190657] [G loss: -0.489191]\n",
      "epoch5 step46055 [D loss: -0.205410] [G loss: -0.212105]\n",
      "epoch5 step46060 [D loss: -0.007253] [G loss: -0.479084]\n",
      "epoch5 step46065 [D loss: -0.245171] [G loss: -0.310433]\n",
      "epoch5 step46070 [D loss: -0.124339] [G loss: -0.248141]\n",
      "epoch5 step46075 [D loss: 0.053977] [G loss: -0.247469]\n",
      "epoch5 step46080 [D loss: -0.287076] [G loss: -0.448270]\n",
      "epoch5 step46085 [D loss: 0.105645] [G loss: -0.430999]\n",
      "epoch5 step46090 [D loss: -0.194710] [G loss: -0.350671]\n",
      "epoch5 step46095 [D loss: -0.838163] [G loss: -0.311255]\n",
      "epoch5 step46100 [D loss: -0.262739] [G loss: -0.420541]\n",
      "epoch5 step46105 [D loss: 0.002437] [G loss: -0.472084]\n",
      "epoch5 step46110 [D loss: -0.294603] [G loss: -0.040196]\n",
      "epoch5 step46115 [D loss: 0.180458] [G loss: -0.704378]\n",
      "epoch5 step46120 [D loss: 0.509573] [G loss: -0.296130]\n",
      "epoch5 step46125 [D loss: -0.192754] [G loss: -0.612021]\n",
      "epoch5 step46130 [D loss: -0.125671] [G loss: -0.390824]\n",
      "epoch5 step46135 [D loss: -0.326394] [G loss: -0.458554]\n",
      "epoch5 step46140 [D loss: -0.043768] [G loss: -0.421125]\n",
      "epoch5 step46145 [D loss: 0.031795] [G loss: -0.580163]\n",
      "epoch5 step46150 [D loss: -0.114830] [G loss: -0.509773]\n",
      "epoch5 step46155 [D loss: 0.230400] [G loss: -0.247593]\n",
      "epoch5 step46160 [D loss: 0.245836] [G loss: -0.139368]\n",
      "epoch5 step46165 [D loss: -0.224901] [G loss: -0.371258]\n",
      "epoch5 step46170 [D loss: -0.451280] [G loss: 0.010869]\n",
      "epoch5 step46175 [D loss: -0.329444] [G loss: -0.087816]\n",
      "epoch5 step46180 [D loss: -0.172062] [G loss: -0.451109]\n",
      "epoch5 step46185 [D loss: -0.123453] [G loss: -0.281461]\n",
      "epoch5 step46190 [D loss: -0.573292] [G loss: -0.298372]\n",
      "epoch5 step46195 [D loss: -0.355031] [G loss: -0.042194]\n",
      "epoch5 step46200 [D loss: -0.051015] [G loss: -0.045977]\n",
      "epoch5 step46205 [D loss: -0.226027] [G loss: -0.052296]\n",
      "epoch5 step46210 [D loss: 0.069806] [G loss: -0.241049]\n",
      "epoch5 step46215 [D loss: -0.339161] [G loss: -0.454779]\n",
      "epoch5 step46220 [D loss: -0.003872] [G loss: -0.503556]\n",
      "epoch5 step46225 [D loss: 0.278857] [G loss: -0.300820]\n",
      "epoch5 step46230 [D loss: 0.085751] [G loss: -0.532395]\n",
      "epoch5 step46235 [D loss: -0.342623] [G loss: 0.105493]\n",
      "epoch5 step46240 [D loss: -0.349060] [G loss: -0.216187]\n",
      "epoch5 step46245 [D loss: -0.599092] [G loss: -0.312219]\n",
      "epoch5 step46250 [D loss: -0.131951] [G loss: -0.487945]\n",
      "epoch5 step46255 [D loss: -0.011635] [G loss: -0.205555]\n",
      "epoch5 step46260 [D loss: 0.258020] [G loss: 0.025829]\n",
      "epoch5 step46265 [D loss: -0.182866] [G loss: -0.188629]\n",
      "epoch5 step46270 [D loss: -0.423292] [G loss: 0.197998]\n",
      "epoch5 step46275 [D loss: -0.001415] [G loss: -0.111968]\n",
      "epoch5 step46280 [D loss: 0.157789] [G loss: -0.146125]\n",
      "epoch5 step46285 [D loss: -0.018793] [G loss: -0.163853]\n",
      "epoch5 step46290 [D loss: -0.358421] [G loss: 0.145606]\n",
      "epoch5 step46295 [D loss: -0.088012] [G loss: 0.021981]\n",
      "epoch5 step46300 [D loss: -0.158479] [G loss: 0.035451]\n",
      "epoch5 step46305 [D loss: -0.909765] [G loss: 0.405533]\n",
      "epoch5 step46310 [D loss: 0.046968] [G loss: -0.263225]\n",
      "epoch5 step46315 [D loss: -0.388801] [G loss: 0.270908]\n",
      "epoch5 step46320 [D loss: -0.028380] [G loss: 0.250502]\n",
      "epoch5 step46325 [D loss: -0.555719] [G loss: 0.512711]\n",
      "epoch5 step46330 [D loss: -0.191720] [G loss: -0.165955]\n",
      "epoch5 step46335 [D loss: -0.832698] [G loss: 0.419068]\n",
      "epoch5 step46340 [D loss: -0.223013] [G loss: 0.067232]\n",
      "epoch5 step46345 [D loss: 0.251463] [G loss: 0.110924]\n",
      "epoch5 step46350 [D loss: -0.178494] [G loss: -0.111115]\n",
      "epoch5 step46355 [D loss: -0.372638] [G loss: -0.214377]\n",
      "epoch5 step46360 [D loss: -0.297821] [G loss: -0.251363]\n",
      "epoch5 step46365 [D loss: -0.363722] [G loss: -0.391869]\n",
      "epoch5 step46370 [D loss: -0.219822] [G loss: -0.104920]\n",
      "epoch5 step46375 [D loss: -0.076025] [G loss: -0.426955]\n",
      "epoch5 step46380 [D loss: -0.496363] [G loss: -0.120535]\n",
      "epoch5 step46385 [D loss: -0.480551] [G loss: -0.200657]\n",
      "epoch5 step46390 [D loss: -0.017611] [G loss: -0.098703]\n",
      "epoch5 step46395 [D loss: -0.385270] [G loss: -0.325304]\n",
      "epoch5 step46400 [D loss: 0.465821] [G loss: -0.645222]\n",
      "epoch5 step46405 [D loss: -0.247055] [G loss: -0.485581]\n",
      "epoch5 step46410 [D loss: -0.733779] [G loss: -0.527563]\n",
      "epoch5 step46415 [D loss: 0.055003] [G loss: -0.538015]\n",
      "epoch5 step46420 [D loss: 0.214441] [G loss: -0.355471]\n",
      "epoch5 step46425 [D loss: -0.150826] [G loss: -0.347616]\n",
      "epoch5 step46430 [D loss: 0.485963] [G loss: -0.622120]\n",
      "epoch5 step46435 [D loss: 0.288873] [G loss: -0.475175]\n",
      "epoch5 step46440 [D loss: -0.120202] [G loss: -0.314267]\n",
      "epoch5 step46445 [D loss: -0.015900] [G loss: -0.279846]\n",
      "epoch5 step46450 [D loss: 0.459668] [G loss: -0.683824]\n",
      "epoch5 step46455 [D loss: -0.209515] [G loss: -0.296768]\n",
      "epoch5 step46460 [D loss: -0.216787] [G loss: -0.099061]\n",
      "epoch5 step46465 [D loss: -0.252354] [G loss: -0.098348]\n",
      "epoch5 step46470 [D loss: -0.379137] [G loss: -0.227581]\n",
      "epoch5 step46475 [D loss: -0.210162] [G loss: 0.112516]\n",
      "epoch5 step46480 [D loss: 0.397865] [G loss: -0.195017]\n",
      "epoch5 step46485 [D loss: -0.327715] [G loss: -0.018598]\n",
      "epoch5 step46490 [D loss: -0.349712] [G loss: 0.105768]\n",
      "epoch5 step46495 [D loss: 0.199114] [G loss: 0.137345]\n",
      "epoch5 step46500 [D loss: -0.044513] [G loss: 0.120015]\n",
      "epoch5 step46505 [D loss: -0.348496] [G loss: 0.038713]\n",
      "epoch5 step46510 [D loss: -0.078259] [G loss: 0.334134]\n",
      "epoch5 step46515 [D loss: -0.190682] [G loss: 0.234631]\n",
      "epoch5 step46520 [D loss: -0.361274] [G loss: 0.491974]\n",
      "epoch5 step46525 [D loss: 0.050330] [G loss: 0.253551]\n",
      "epoch5 step46530 [D loss: -0.548779] [G loss: 0.300322]\n",
      "epoch5 step46535 [D loss: 0.103840] [G loss: 0.697201]\n",
      "epoch5 step46540 [D loss: 0.612824] [G loss: 0.546288]\n",
      "epoch5 step46545 [D loss: -0.419849] [G loss: 0.498667]\n",
      "epoch5 step46550 [D loss: -0.254584] [G loss: 0.644793]\n",
      "epoch5 step46555 [D loss: -0.501658] [G loss: 0.571975]\n",
      "epoch5 step46560 [D loss: -0.157736] [G loss: 0.448086]\n",
      "epoch5 step46565 [D loss: -0.398722] [G loss: 0.600539]\n",
      "epoch5 step46570 [D loss: -0.076346] [G loss: 0.780276]\n",
      "epoch5 step46575 [D loss: 0.226878] [G loss: 0.641583]\n",
      "epoch5 step46580 [D loss: 0.073639] [G loss: 0.727116]\n",
      "epoch5 step46585 [D loss: -0.829442] [G loss: 0.781012]\n",
      "epoch5 step46590 [D loss: -0.096598] [G loss: 0.822702]\n",
      "epoch5 step46595 [D loss: 0.184220] [G loss: 0.441152]\n",
      "epoch5 step46600 [D loss: 0.120679] [G loss: 0.199998]\n",
      "epoch5 step46605 [D loss: -0.090063] [G loss: 0.747582]\n",
      "epoch5 step46610 [D loss: -0.464103] [G loss: 0.364747]\n",
      "epoch5 step46615 [D loss: 0.056631] [G loss: -0.341894]\n",
      "epoch5 step46620 [D loss: 0.059910] [G loss: 0.161092]\n",
      "epoch5 step46625 [D loss: -0.467273] [G loss: 0.268503]\n",
      "epoch5 step46630 [D loss: -0.398285] [G loss: 0.208440]\n",
      "epoch5 step46635 [D loss: -0.302825] [G loss: 0.460532]\n",
      "epoch5 step46640 [D loss: 0.394096] [G loss: -0.020784]\n",
      "epoch5 step46645 [D loss: -0.157920] [G loss: 0.011314]\n",
      "epoch5 step46650 [D loss: -0.328362] [G loss: 0.233099]\n",
      "epoch5 step46655 [D loss: -0.310443] [G loss: 0.163480]\n",
      "epoch5 step46660 [D loss: 0.002105] [G loss: 0.006424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5 step46665 [D loss: -0.282734] [G loss: -0.341722]\n",
      "epoch5 step46670 [D loss: 0.039419] [G loss: -0.493546]\n",
      "epoch5 step46675 [D loss: -0.347897] [G loss: -0.059847]\n",
      "epoch5 step46680 [D loss: -0.098969] [G loss: -0.087935]\n",
      "epoch5 step46685 [D loss: -0.781369] [G loss: -0.058820]\n",
      "epoch5 step46690 [D loss: -0.614604] [G loss: -0.142609]\n",
      "epoch5 step46695 [D loss: -0.544882] [G loss: -0.294284]\n",
      "epoch5 step46700 [D loss: -0.192834] [G loss: -0.646765]\n",
      "epoch5 step46705 [D loss: 0.224282] [G loss: -0.669056]\n",
      "epoch5 step46710 [D loss: 0.006020] [G loss: -0.358902]\n",
      "epoch5 step46715 [D loss: 0.104346] [G loss: -0.462142]\n",
      "epoch5 step46720 [D loss: 0.469642] [G loss: -0.430021]\n",
      "epoch5 step46725 [D loss: 0.148900] [G loss: -0.313066]\n",
      "epoch5 step46730 [D loss: -0.365663] [G loss: -0.207957]\n",
      "epoch5 step46735 [D loss: -0.716139] [G loss: -0.464513]\n",
      "epoch5 step46740 [D loss: 0.003888] [G loss: -0.404566]\n",
      "epoch5 step46745 [D loss: -0.496946] [G loss: -1.001874]\n",
      "epoch5 step46750 [D loss: -0.427844] [G loss: -0.146530]\n",
      "epoch5 step46755 [D loss: -0.278108] [G loss: -0.289731]\n",
      "epoch5 step46760 [D loss: 0.250130] [G loss: -0.246687]\n",
      "epoch5 step46765 [D loss: -0.297479] [G loss: -0.386187]\n",
      "epoch5 step46770 [D loss: -0.414795] [G loss: -0.315573]\n",
      "epoch5 step46775 [D loss: -0.833997] [G loss: 0.119603]\n",
      "epoch5 step46780 [D loss: -0.060267] [G loss: -0.178232]\n",
      "epoch5 step46785 [D loss: 0.359028] [G loss: -0.120467]\n",
      "epoch5 step46790 [D loss: -0.167796] [G loss: 0.047878]\n",
      "epoch5 step46795 [D loss: -0.107630] [G loss: -0.052493]\n",
      "epoch5 step46800 [D loss: -0.058963] [G loss: 0.067761]\n",
      "epoch5 step46805 [D loss: -0.190848] [G loss: -0.325090]\n",
      "epoch5 step46810 [D loss: -0.071175] [G loss: -0.042537]\n",
      "epoch5 step46815 [D loss: -0.173943] [G loss: -0.035135]\n",
      "epoch5 step46820 [D loss: 0.111944] [G loss: 0.341858]\n",
      "epoch5 step46825 [D loss: -0.574076] [G loss: 0.256100]\n",
      "epoch5 step46830 [D loss: -0.433636] [G loss: -0.134786]\n",
      "epoch5 step46835 [D loss: 0.113535] [G loss: 0.200364]\n",
      "epoch5 step46840 [D loss: 0.273289] [G loss: 0.699635]\n",
      "epoch5 step46845 [D loss: -0.620836] [G loss: 0.427499]\n",
      "epoch5 step46850 [D loss: 0.085720] [G loss: 0.436740]\n",
      "epoch5 step46855 [D loss: -0.281996] [G loss: 0.367562]\n",
      "epoch5 step46860 [D loss: -0.248317] [G loss: 0.469626]\n",
      "epoch6 step46865 [D loss: 0.257211] [G loss: 0.466628]\n",
      "epoch6 step46870 [D loss: -0.267377] [G loss: 0.395434]\n",
      "epoch6 step46875 [D loss: -0.242288] [G loss: 0.319483]\n",
      "epoch6 step46880 [D loss: -0.179276] [G loss: 0.354132]\n",
      "epoch6 step46885 [D loss: -0.616946] [G loss: 0.998944]\n",
      "epoch6 step46890 [D loss: 0.235595] [G loss: 0.555120]\n",
      "epoch6 step46895 [D loss: -0.582988] [G loss: 0.829246]\n",
      "epoch6 step46900 [D loss: -0.089974] [G loss: 0.094825]\n",
      "epoch6 step46905 [D loss: 0.282885] [G loss: 0.511467]\n",
      "epoch6 step46910 [D loss: -0.193242] [G loss: 0.368170]\n",
      "epoch6 step46915 [D loss: 0.202986] [G loss: 0.123384]\n",
      "epoch6 step46920 [D loss: -0.003557] [G loss: 0.157563]\n",
      "epoch6 step46925 [D loss: -0.108679] [G loss: 0.215152]\n",
      "epoch6 step46930 [D loss: -0.823773] [G loss: 0.505078]\n",
      "epoch6 step46935 [D loss: -0.442431] [G loss: 0.132802]\n",
      "epoch6 step46940 [D loss: -0.302620] [G loss: 0.768781]\n",
      "epoch6 step46945 [D loss: -0.305922] [G loss: -0.047487]\n",
      "epoch6 step46950 [D loss: -0.083859] [G loss: 0.051706]\n",
      "epoch6 step46955 [D loss: -0.029370] [G loss: -0.333476]\n",
      "epoch6 step46960 [D loss: 0.272353] [G loss: -0.033337]\n",
      "epoch6 step46965 [D loss: 0.008031] [G loss: -0.194808]\n",
      "epoch6 step46970 [D loss: -0.128248] [G loss: -0.281330]\n",
      "epoch6 step46975 [D loss: 0.102009] [G loss: -0.392628]\n",
      "epoch6 step46980 [D loss: -0.023625] [G loss: -0.356512]\n",
      "epoch6 step46985 [D loss: -0.312643] [G loss: -0.156559]\n",
      "epoch6 step46990 [D loss: -0.126007] [G loss: -0.643424]\n",
      "epoch6 step46995 [D loss: -0.310447] [G loss: -0.291588]\n",
      "epoch6 step47000 [D loss: -0.059392] [G loss: -0.459986]\n",
      "epoch6 step47005 [D loss: -0.300442] [G loss: -0.391608]\n",
      "epoch6 step47010 [D loss: -0.343969] [G loss: -0.885378]\n",
      "epoch6 step47015 [D loss: -0.012238] [G loss: -0.456773]\n",
      "epoch6 step47020 [D loss: -0.049611] [G loss: -0.809147]\n",
      "epoch6 step47025 [D loss: 0.288777] [G loss: -0.960628]\n",
      "epoch6 step47030 [D loss: -0.173430] [G loss: -0.505795]\n",
      "epoch6 step47035 [D loss: -0.187725] [G loss: -0.710462]\n",
      "epoch6 step47040 [D loss: 0.209095] [G loss: -0.997495]\n",
      "epoch6 step47045 [D loss: -0.041536] [G loss: -0.541698]\n",
      "epoch6 step47050 [D loss: -0.238817] [G loss: -0.632891]\n",
      "epoch6 step47055 [D loss: -0.075574] [G loss: -0.780642]\n",
      "epoch6 step47060 [D loss: 0.307172] [G loss: -0.884944]\n",
      "epoch6 step47065 [D loss: 0.167206] [G loss: -0.663188]\n",
      "epoch6 step47070 [D loss: -0.472109] [G loss: -0.591853]\n",
      "epoch6 step47075 [D loss: -0.390165] [G loss: -0.722809]\n",
      "epoch6 step47080 [D loss: 0.255374] [G loss: -0.738910]\n",
      "epoch6 step47085 [D loss: 0.047459] [G loss: -0.764183]\n",
      "epoch6 step47090 [D loss: -0.436449] [G loss: -0.452367]\n",
      "epoch6 step47095 [D loss: -0.232699] [G loss: -0.569948]\n",
      "epoch6 step47100 [D loss: -0.449648] [G loss: -0.625180]\n",
      "epoch6 step47105 [D loss: 0.339816] [G loss: -0.797631]\n",
      "epoch6 step47110 [D loss: 0.039885] [G loss: -0.646894]\n",
      "epoch6 step47115 [D loss: 0.396438] [G loss: -0.916745]\n",
      "epoch6 step47120 [D loss: -0.141924] [G loss: -0.921042]\n",
      "epoch6 step47125 [D loss: -0.079037] [G loss: -0.919213]\n",
      "epoch6 step47130 [D loss: -0.316357] [G loss: -0.958459]\n",
      "epoch6 step47135 [D loss: 0.123624] [G loss: -0.723268]\n",
      "epoch6 step47140 [D loss: -0.392036] [G loss: -0.369936]\n",
      "epoch6 step47145 [D loss: 0.211213] [G loss: -0.395917]\n",
      "epoch6 step47150 [D loss: -0.061580] [G loss: -0.817238]\n",
      "epoch6 step47155 [D loss: -0.318995] [G loss: -0.574477]\n",
      "epoch6 step47160 [D loss: 0.099884] [G loss: -0.324224]\n",
      "epoch6 step47165 [D loss: -0.262862] [G loss: -0.070197]\n",
      "epoch6 step47170 [D loss: -0.044556] [G loss: -0.372893]\n",
      "epoch6 step47175 [D loss: 0.259372] [G loss: -0.192391]\n",
      "epoch6 step47180 [D loss: -0.429695] [G loss: -0.651162]\n",
      "epoch6 step47185 [D loss: -0.352349] [G loss: -0.143094]\n",
      "epoch6 step47190 [D loss: -0.231637] [G loss: -0.233503]\n",
      "epoch6 step47195 [D loss: 0.203555] [G loss: -0.195318]\n",
      "epoch6 step47200 [D loss: -0.112582] [G loss: -0.225343]\n",
      "epoch6 step47205 [D loss: -0.027167] [G loss: -0.327767]\n",
      "epoch6 step47210 [D loss: -0.071073] [G loss: -0.097582]\n",
      "epoch6 step47215 [D loss: -0.340802] [G loss: -0.476581]\n",
      "epoch6 step47220 [D loss: 0.130172] [G loss: -0.254435]\n",
      "epoch6 step47225 [D loss: -0.434500] [G loss: 0.093367]\n",
      "epoch6 step47230 [D loss: -0.078601] [G loss: 0.374009]\n",
      "epoch6 step47235 [D loss: -0.244011] [G loss: -0.090190]\n",
      "epoch6 step47240 [D loss: -0.678447] [G loss: 0.157997]\n",
      "epoch6 step47245 [D loss: 0.347746] [G loss: -0.473542]\n",
      "epoch6 step47250 [D loss: -0.288882] [G loss: -0.035371]\n",
      "epoch6 step47255 [D loss: -0.091408] [G loss: -0.344574]\n",
      "epoch6 step47260 [D loss: -0.549602] [G loss: -0.123488]\n",
      "epoch6 step47265 [D loss: -0.421905] [G loss: 0.333938]\n",
      "epoch6 step47270 [D loss: -0.542358] [G loss: 0.319120]\n",
      "epoch6 step47275 [D loss: -0.226105] [G loss: 0.163336]\n",
      "epoch6 step47280 [D loss: 0.446064] [G loss: -0.088295]\n",
      "epoch6 step47285 [D loss: -0.425933] [G loss: 0.078320]\n",
      "epoch6 step47290 [D loss: 0.169470] [G loss: -0.082693]\n",
      "epoch6 step47295 [D loss: -0.376975] [G loss: -0.119940]\n",
      "epoch6 step47300 [D loss: -0.130655] [G loss: -0.153359]\n",
      "epoch6 step47305 [D loss: 0.055605] [G loss: -0.046915]\n",
      "epoch6 step47310 [D loss: -0.182153] [G loss: -0.174942]\n",
      "epoch6 step47315 [D loss: 0.436474] [G loss: 0.257705]\n",
      "epoch6 step47320 [D loss: 0.056909] [G loss: 0.098743]\n",
      "epoch6 step47325 [D loss: -0.198008] [G loss: 0.567433]\n",
      "epoch6 step47330 [D loss: -0.705625] [G loss: 0.356377]\n",
      "epoch6 step47335 [D loss: -0.331317] [G loss: 0.581341]\n",
      "epoch6 step47340 [D loss: 0.319662] [G loss: 0.475879]\n",
      "epoch6 step47345 [D loss: 0.086736] [G loss: 0.690132]\n",
      "epoch6 step47350 [D loss: -0.360520] [G loss: 0.664510]\n",
      "epoch6 step47355 [D loss: -0.394357] [G loss: 0.833985]\n",
      "epoch6 step47360 [D loss: -0.378388] [G loss: 0.841843]\n",
      "epoch6 step47365 [D loss: 0.024943] [G loss: 0.380336]\n",
      "epoch6 step47370 [D loss: -0.318754] [G loss: 0.477705]\n",
      "epoch6 step47375 [D loss: 0.140232] [G loss: 0.582973]\n",
      "epoch6 step47380 [D loss: -0.277107] [G loss: 0.553220]\n",
      "epoch6 step47385 [D loss: -0.733202] [G loss: 0.671732]\n",
      "epoch6 step47390 [D loss: -0.218675] [G loss: 0.653476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step47395 [D loss: -0.608803] [G loss: 0.457316]\n",
      "epoch6 step47400 [D loss: -0.094613] [G loss: 0.648038]\n",
      "epoch6 step47405 [D loss: -0.053687] [G loss: 0.581958]\n",
      "epoch6 step47410 [D loss: 0.299065] [G loss: 0.380485]\n",
      "epoch6 step47415 [D loss: -0.036603] [G loss: 0.552513]\n",
      "epoch6 step47420 [D loss: 0.167521] [G loss: 0.140247]\n",
      "epoch6 step47425 [D loss: 0.359673] [G loss: 0.238972]\n",
      "epoch6 step47430 [D loss: -0.380618] [G loss: -0.005156]\n",
      "epoch6 step47435 [D loss: -0.650259] [G loss: 0.226290]\n",
      "epoch6 step47440 [D loss: -0.223310] [G loss: 0.142841]\n",
      "epoch6 step47445 [D loss: -0.038368] [G loss: -0.070895]\n",
      "epoch6 step47450 [D loss: -0.748268] [G loss: 0.026268]\n",
      "epoch6 step47455 [D loss: -0.279650] [G loss: 0.103421]\n",
      "epoch6 step47460 [D loss: -0.651640] [G loss: 0.066827]\n",
      "epoch6 step47465 [D loss: -0.190138] [G loss: 0.046257]\n",
      "epoch6 step47470 [D loss: -0.167302] [G loss: -0.163630]\n",
      "epoch6 step47475 [D loss: 0.057566] [G loss: -0.102010]\n",
      "epoch6 step47480 [D loss: 0.164568] [G loss: -0.450818]\n",
      "epoch6 step47485 [D loss: 0.290462] [G loss: -0.102164]\n",
      "epoch6 step47490 [D loss: 0.115356] [G loss: -0.338452]\n",
      "epoch6 step47495 [D loss: 0.225952] [G loss: -0.121391]\n",
      "epoch6 step47500 [D loss: 0.069053] [G loss: -0.282445]\n",
      "epoch6 step47505 [D loss: -0.291559] [G loss: -0.124650]\n",
      "epoch6 step47510 [D loss: -0.040623] [G loss: -0.285919]\n",
      "epoch6 step47515 [D loss: -0.089933] [G loss: -0.116533]\n",
      "epoch6 step47520 [D loss: -0.165930] [G loss: -0.021412]\n",
      "epoch6 step47525 [D loss: -0.175290] [G loss: -0.259242]\n",
      "epoch6 step47530 [D loss: 0.212583] [G loss: -0.235112]\n",
      "epoch6 step47535 [D loss: -0.272894] [G loss: -0.182960]\n",
      "epoch6 step47540 [D loss: -0.038840] [G loss: -0.333516]\n",
      "epoch6 step47545 [D loss: 0.424295] [G loss: -0.342015]\n",
      "epoch6 step47550 [D loss: -0.222782] [G loss: -0.175148]\n",
      "epoch6 step47555 [D loss: 0.615300] [G loss: -0.140807]\n",
      "epoch6 step47560 [D loss: -0.564005] [G loss: -0.301052]\n",
      "epoch6 step47565 [D loss: 0.361155] [G loss: -0.383993]\n",
      "epoch6 step47570 [D loss: -0.210165] [G loss: -0.511497]\n",
      "epoch6 step47575 [D loss: -0.134465] [G loss: -0.363921]\n",
      "epoch6 step47580 [D loss: -0.079695] [G loss: -0.499296]\n",
      "epoch6 step47585 [D loss: 0.292693] [G loss: -0.123176]\n",
      "epoch6 step47590 [D loss: 0.047337] [G loss: -0.809860]\n",
      "epoch6 step47595 [D loss: -0.163508] [G loss: -0.421614]\n",
      "epoch6 step47600 [D loss: -0.217105] [G loss: -0.505559]\n",
      "epoch6 step47605 [D loss: -0.318048] [G loss: -0.301283]\n",
      "epoch6 step47610 [D loss: -0.279378] [G loss: -0.315463]\n",
      "epoch6 step47615 [D loss: -0.107508] [G loss: -0.508697]\n",
      "epoch6 step47620 [D loss: -0.057951] [G loss: -0.220079]\n",
      "epoch6 step47625 [D loss: -0.120985] [G loss: -0.307395]\n",
      "epoch6 step47630 [D loss: -0.307698] [G loss: -0.436659]\n",
      "epoch6 step47635 [D loss: -0.273464] [G loss: -0.037049]\n",
      "epoch6 step47640 [D loss: -0.606437] [G loss: -0.235356]\n",
      "epoch6 step47645 [D loss: 0.110023] [G loss: -0.349858]\n",
      "epoch6 step47650 [D loss: -0.654087] [G loss: -0.372684]\n",
      "epoch6 step47655 [D loss: 0.244244] [G loss: -0.450995]\n",
      "epoch6 step47660 [D loss: 0.102489] [G loss: -0.411909]\n",
      "epoch6 step47665 [D loss: -0.243353] [G loss: -0.550126]\n",
      "epoch6 step47670 [D loss: -0.010754] [G loss: -0.349979]\n",
      "epoch6 step47675 [D loss: -0.433287] [G loss: -0.257574]\n",
      "epoch6 step47680 [D loss: 0.164923] [G loss: -0.799182]\n",
      "epoch6 step47685 [D loss: -0.028079] [G loss: -0.778468]\n",
      "epoch6 step47690 [D loss: -0.484117] [G loss: -0.614560]\n",
      "epoch6 step47695 [D loss: -0.383050] [G loss: -0.456685]\n",
      "epoch6 step47700 [D loss: -0.154984] [G loss: -0.317192]\n",
      "epoch6 step47705 [D loss: 0.289248] [G loss: -0.615861]\n",
      "epoch6 step47710 [D loss: 0.170886] [G loss: -0.353449]\n",
      "epoch6 step47715 [D loss: 0.008007] [G loss: -0.773215]\n",
      "epoch6 step47720 [D loss: 0.621213] [G loss: -0.490622]\n",
      "epoch6 step47725 [D loss: -0.037827] [G loss: -0.358372]\n",
      "epoch6 step47730 [D loss: 0.493540] [G loss: -0.775055]\n",
      "epoch6 step47735 [D loss: 0.349650] [G loss: -0.676055]\n",
      "epoch6 step47740 [D loss: 0.026020] [G loss: -0.184546]\n",
      "epoch6 step47745 [D loss: -0.074370] [G loss: -0.220659]\n",
      "epoch6 step47750 [D loss: -0.372251] [G loss: -0.332671]\n",
      "epoch6 step47755 [D loss: 0.824913] [G loss: -0.352894]\n",
      "epoch6 step47760 [D loss: 0.077579] [G loss: -0.310335]\n",
      "epoch6 step47765 [D loss: -0.363008] [G loss: -0.151912]\n",
      "epoch6 step47770 [D loss: -0.204196] [G loss: -0.242787]\n",
      "epoch6 step47775 [D loss: -0.145258] [G loss: -0.293210]\n",
      "epoch6 step47780 [D loss: -0.033027] [G loss: -0.012372]\n",
      "epoch6 step47785 [D loss: 0.087122] [G loss: -0.225254]\n",
      "epoch6 step47790 [D loss: -0.024482] [G loss: -0.116831]\n",
      "epoch6 step47795 [D loss: 0.013848] [G loss: -0.000174]\n",
      "epoch6 step47800 [D loss: -0.269095] [G loss: -0.023267]\n",
      "epoch6 step47805 [D loss: -0.508796] [G loss: 0.538997]\n",
      "epoch6 step47810 [D loss: -0.052075] [G loss: 0.286395]\n",
      "epoch6 step47815 [D loss: -0.871654] [G loss: 0.811896]\n",
      "epoch6 step47820 [D loss: -0.149056] [G loss: 0.518999]\n",
      "epoch6 step47825 [D loss: -0.141580] [G loss: 0.135115]\n",
      "epoch6 step47830 [D loss: -0.396536] [G loss: 0.421288]\n",
      "epoch6 step47835 [D loss: -0.796812] [G loss: 0.286252]\n",
      "epoch6 step47840 [D loss: -0.258766] [G loss: 0.778424]\n",
      "epoch6 step47845 [D loss: -0.534550] [G loss: 0.062329]\n",
      "epoch6 step47850 [D loss: -0.458382] [G loss: 0.434514]\n",
      "epoch6 step47855 [D loss: -0.237089] [G loss: 0.425028]\n",
      "epoch6 step47860 [D loss: -0.136059] [G loss: 0.105722]\n",
      "epoch6 step47865 [D loss: -0.209093] [G loss: 0.594420]\n",
      "epoch6 step47870 [D loss: -0.155138] [G loss: 0.198864]\n",
      "epoch6 step47875 [D loss: -0.594055] [G loss: 0.266918]\n",
      "epoch6 step47880 [D loss: -0.373467] [G loss: 0.370605]\n",
      "epoch6 step47885 [D loss: -0.289322] [G loss: 0.790732]\n",
      "epoch6 step47890 [D loss: 0.311632] [G loss: 0.097070]\n",
      "epoch6 step47895 [D loss: -0.206046] [G loss: 0.569168]\n",
      "epoch6 step47900 [D loss: -0.491399] [G loss: 0.396892]\n",
      "epoch6 step47905 [D loss: -0.179633] [G loss: 0.409647]\n",
      "epoch6 step47910 [D loss: -0.167057] [G loss: 0.399840]\n",
      "epoch6 step47915 [D loss: -0.466817] [G loss: 0.439119]\n",
      "epoch6 step47920 [D loss: -0.752325] [G loss: 0.365925]\n",
      "epoch6 step47925 [D loss: -0.398581] [G loss: 0.292908]\n",
      "epoch6 step47930 [D loss: -0.303750] [G loss: 0.157031]\n",
      "epoch6 step47935 [D loss: -0.065390] [G loss: 0.126942]\n",
      "epoch6 step47940 [D loss: -0.369304] [G loss: 0.386218]\n",
      "epoch6 step47945 [D loss: -0.244683] [G loss: 0.256416]\n",
      "epoch6 step47950 [D loss: -0.070787] [G loss: -0.259536]\n",
      "epoch6 step47955 [D loss: -0.262687] [G loss: 0.235605]\n",
      "epoch6 step47960 [D loss: -0.042770] [G loss: 0.190216]\n",
      "epoch6 step47965 [D loss: -0.433598] [G loss: 0.201021]\n",
      "epoch6 step47970 [D loss: -0.095042] [G loss: 0.139519]\n",
      "epoch6 step47975 [D loss: -0.061513] [G loss: 0.037623]\n",
      "epoch6 step47980 [D loss: -0.463193] [G loss: 0.171613]\n",
      "epoch6 step47985 [D loss: -0.077292] [G loss: -0.011051]\n",
      "epoch6 step47990 [D loss: -0.465382] [G loss: 0.135767]\n",
      "epoch6 step47995 [D loss: 0.024896] [G loss: -0.252980]\n",
      "epoch6 step48000 [D loss: 0.102498] [G loss: -0.302954]\n",
      "epoch6 step48005 [D loss: -0.243458] [G loss: -0.038653]\n",
      "epoch6 step48010 [D loss: 0.009362] [G loss: -0.245686]\n",
      "epoch6 step48015 [D loss: -0.136893] [G loss: -0.340231]\n",
      "epoch6 step48020 [D loss: -0.073017] [G loss: 0.019695]\n",
      "epoch6 step48025 [D loss: 0.131778] [G loss: -0.211510]\n",
      "epoch6 step48030 [D loss: -0.380303] [G loss: -0.142342]\n",
      "epoch6 step48035 [D loss: 0.240176] [G loss: -0.167546]\n",
      "epoch6 step48040 [D loss: -0.059834] [G loss: -0.043794]\n",
      "epoch6 step48045 [D loss: -0.230580] [G loss: 0.007440]\n",
      "epoch6 step48050 [D loss: -0.335852] [G loss: -0.215002]\n",
      "epoch6 step48055 [D loss: -0.048965] [G loss: -0.073967]\n",
      "epoch6 step48060 [D loss: -0.200347] [G loss: 0.036931]\n",
      "epoch6 step48065 [D loss: -0.617289] [G loss: 0.472339]\n",
      "epoch6 step48070 [D loss: -0.568339] [G loss: 0.116381]\n",
      "epoch6 step48075 [D loss: -0.320200] [G loss: -0.270113]\n",
      "epoch6 step48080 [D loss: -0.076661] [G loss: -0.357444]\n",
      "epoch6 step48085 [D loss: 0.040555] [G loss: -0.114579]\n",
      "epoch6 step48090 [D loss: -0.016930] [G loss: -0.077964]\n",
      "epoch6 step48095 [D loss: -0.139007] [G loss: 0.156651]\n",
      "epoch6 step48100 [D loss: -0.302915] [G loss: 0.112447]\n",
      "epoch6 step48105 [D loss: -0.139093] [G loss: 0.325156]\n",
      "epoch6 step48110 [D loss: -0.036056] [G loss: 0.010157]\n",
      "epoch6 step48115 [D loss: 0.389669] [G loss: -0.048771]\n",
      "epoch6 step48120 [D loss: 0.122510] [G loss: -0.186074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step48125 [D loss: -0.488889] [G loss: 0.402996]\n",
      "epoch6 step48130 [D loss: 0.335603] [G loss: -0.235156]\n",
      "epoch6 step48135 [D loss: -0.243718] [G loss: 0.292857]\n",
      "epoch6 step48140 [D loss: -0.585955] [G loss: 0.321468]\n",
      "epoch6 step48145 [D loss: -1.054215] [G loss: 0.341158]\n",
      "epoch6 step48150 [D loss: -0.220655] [G loss: 0.140171]\n",
      "epoch6 step48155 [D loss: -0.218883] [G loss: 0.166577]\n",
      "epoch6 step48160 [D loss: 0.248285] [G loss: 0.287974]\n",
      "epoch6 step48165 [D loss: 0.026539] [G loss: 0.200708]\n",
      "epoch6 step48170 [D loss: -0.164477] [G loss: 0.118514]\n",
      "epoch6 step48175 [D loss: 0.057407] [G loss: 0.709049]\n",
      "epoch6 step48180 [D loss: -0.133573] [G loss: 0.282145]\n",
      "epoch6 step48185 [D loss: -0.255443] [G loss: 0.050539]\n",
      "epoch6 step48190 [D loss: -0.034223] [G loss: 0.304101]\n",
      "epoch6 step48195 [D loss: -0.437149] [G loss: 0.226050]\n",
      "epoch6 step48200 [D loss: -0.090813] [G loss: 0.082043]\n",
      "epoch6 step48205 [D loss: 0.114468] [G loss: -0.075501]\n",
      "epoch6 step48210 [D loss: 0.187567] [G loss: -0.419958]\n",
      "epoch6 step48215 [D loss: 0.277630] [G loss: -0.195412]\n",
      "epoch6 step48220 [D loss: -0.020690] [G loss: -0.113566]\n",
      "epoch6 step48225 [D loss: -0.435298] [G loss: -0.190059]\n",
      "epoch6 step48230 [D loss: 0.107413] [G loss: -0.171135]\n",
      "epoch6 step48235 [D loss: -0.322675] [G loss: 0.179436]\n",
      "epoch6 step48240 [D loss: 0.439570] [G loss: 0.018178]\n",
      "epoch6 step48245 [D loss: 0.133679] [G loss: -0.237602]\n",
      "epoch6 step48250 [D loss: -0.067869] [G loss: -0.310708]\n",
      "epoch6 step48255 [D loss: -0.050223] [G loss: -0.187344]\n",
      "epoch6 step48260 [D loss: 0.295596] [G loss: -0.174079]\n",
      "epoch6 step48265 [D loss: -0.245513] [G loss: -0.138556]\n",
      "epoch6 step48270 [D loss: -0.133202] [G loss: -0.004034]\n",
      "epoch6 step48275 [D loss: -0.165174] [G loss: -0.450614]\n",
      "epoch6 step48280 [D loss: -0.319559] [G loss: -0.484862]\n",
      "epoch6 step48285 [D loss: -0.397057] [G loss: -0.279297]\n",
      "epoch6 step48290 [D loss: -0.198600] [G loss: -0.346878]\n",
      "epoch6 step48295 [D loss: -0.041019] [G loss: -0.492935]\n",
      "epoch6 step48300 [D loss: -0.144053] [G loss: -0.209519]\n",
      "epoch6 step48305 [D loss: -0.312347] [G loss: -0.284366]\n",
      "epoch6 step48310 [D loss: -0.243000] [G loss: -0.467058]\n",
      "epoch6 step48315 [D loss: -0.272170] [G loss: -0.408380]\n",
      "epoch6 step48320 [D loss: -0.355599] [G loss: -0.559327]\n",
      "epoch6 step48325 [D loss: -0.407075] [G loss: -0.773225]\n",
      "epoch6 step48330 [D loss: -0.793084] [G loss: 0.029075]\n",
      "epoch6 step48335 [D loss: 0.589624] [G loss: -0.485586]\n",
      "epoch6 step48340 [D loss: -0.176443] [G loss: -0.413411]\n",
      "epoch6 step48345 [D loss: -0.191788] [G loss: -0.305362]\n",
      "epoch6 step48350 [D loss: -0.209160] [G loss: -0.107035]\n",
      "epoch6 step48355 [D loss: 0.130698] [G loss: -0.376230]\n",
      "epoch6 step48360 [D loss: -0.097955] [G loss: -0.557778]\n",
      "epoch6 step48365 [D loss: -0.202794] [G loss: -0.155491]\n",
      "epoch6 step48370 [D loss: -0.247470] [G loss: -0.345735]\n",
      "epoch6 step48375 [D loss: -0.221182] [G loss: -0.009872]\n",
      "epoch6 step48380 [D loss: 0.328801] [G loss: -0.361602]\n",
      "epoch6 step48385 [D loss: -0.355819] [G loss: -0.368311]\n",
      "epoch6 step48390 [D loss: 0.124220] [G loss: -0.115865]\n",
      "epoch6 step48395 [D loss: -0.231791] [G loss: -0.179013]\n",
      "epoch6 step48400 [D loss: 0.098894] [G loss: -0.118130]\n",
      "epoch6 step48405 [D loss: -0.145250] [G loss: -0.052048]\n",
      "epoch6 step48410 [D loss: -0.101721] [G loss: -0.208776]\n",
      "epoch6 step48415 [D loss: -0.229382] [G loss: -0.171968]\n",
      "epoch6 step48420 [D loss: 0.165676] [G loss: -0.359940]\n",
      "epoch6 step48425 [D loss: -0.117810] [G loss: -0.211902]\n",
      "epoch6 step48430 [D loss: -0.020932] [G loss: -0.255631]\n",
      "epoch6 step48435 [D loss: -0.576159] [G loss: 0.134831]\n",
      "epoch6 step48440 [D loss: -0.556298] [G loss: -0.159589]\n",
      "epoch6 step48445 [D loss: -0.515985] [G loss: -0.202344]\n",
      "epoch6 step48450 [D loss: -0.711645] [G loss: -0.049924]\n",
      "epoch6 step48455 [D loss: -0.138555] [G loss: -0.123321]\n",
      "epoch6 step48460 [D loss: -0.461402] [G loss: 0.030566]\n",
      "epoch6 step48465 [D loss: -0.728035] [G loss: 0.050739]\n",
      "epoch6 step48470 [D loss: 0.020799] [G loss: -0.050253]\n",
      "epoch6 step48475 [D loss: -0.300636] [G loss: 0.181477]\n",
      "epoch6 step48480 [D loss: -0.085640] [G loss: -0.323122]\n",
      "epoch6 step48485 [D loss: -0.438514] [G loss: -0.119950]\n",
      "epoch6 step48490 [D loss: -0.620270] [G loss: 0.126765]\n",
      "epoch6 step48495 [D loss: -0.705476] [G loss: -0.415103]\n",
      "epoch6 step48500 [D loss: 0.014861] [G loss: -0.337363]\n",
      "epoch6 step48505 [D loss: -0.031774] [G loss: -0.367962]\n",
      "epoch6 step48510 [D loss: -0.178941] [G loss: -0.276905]\n",
      "epoch6 step48515 [D loss: -0.272906] [G loss: -0.112397]\n",
      "epoch6 step48520 [D loss: -0.111096] [G loss: -0.156647]\n",
      "epoch6 step48525 [D loss: -0.111745] [G loss: -0.193672]\n",
      "epoch6 step48530 [D loss: -0.167838] [G loss: -0.380506]\n",
      "epoch6 step48535 [D loss: -0.299393] [G loss: 0.205314]\n",
      "epoch6 step48540 [D loss: 0.360907] [G loss: -0.160945]\n",
      "epoch6 step48545 [D loss: -0.101389] [G loss: -0.386398]\n",
      "epoch6 step48550 [D loss: -0.116054] [G loss: -0.117260]\n",
      "epoch6 step48555 [D loss: 0.195778] [G loss: -0.513477]\n",
      "epoch6 step48560 [D loss: -0.292619] [G loss: -0.312109]\n",
      "epoch6 step48565 [D loss: 0.024899] [G loss: -0.469267]\n",
      "epoch6 step48570 [D loss: -0.494090] [G loss: -0.327970]\n",
      "epoch6 step48575 [D loss: -0.159079] [G loss: -0.487324]\n",
      "epoch6 step48580 [D loss: -0.072080] [G loss: -0.496368]\n",
      "epoch6 step48585 [D loss: -0.918047] [G loss: -0.196325]\n",
      "epoch6 step48590 [D loss: -0.275272] [G loss: -0.678337]\n",
      "epoch6 step48595 [D loss: 0.055405] [G loss: -0.303496]\n",
      "epoch6 step48600 [D loss: -0.251543] [G loss: -0.139608]\n",
      "epoch6 step48605 [D loss: 0.285377] [G loss: -0.331833]\n",
      "epoch6 step48610 [D loss: -0.172975] [G loss: -0.561637]\n",
      "epoch6 step48615 [D loss: -0.344264] [G loss: -0.358101]\n",
      "epoch6 step48620 [D loss: 0.165524] [G loss: -0.538997]\n",
      "epoch6 step48625 [D loss: -0.187369] [G loss: -0.221580]\n",
      "epoch6 step48630 [D loss: -0.322927] [G loss: -0.377291]\n",
      "epoch6 step48635 [D loss: -0.100196] [G loss: -0.198282]\n",
      "epoch6 step48640 [D loss: -0.061791] [G loss: -0.426199]\n",
      "epoch6 step48645 [D loss: -0.156076] [G loss: -0.469127]\n",
      "epoch6 step48650 [D loss: -0.605628] [G loss: -0.189745]\n",
      "epoch6 step48655 [D loss: -0.389523] [G loss: -0.395328]\n",
      "epoch6 step48660 [D loss: -0.081740] [G loss: -0.556450]\n",
      "epoch6 step48665 [D loss: -0.524727] [G loss: -0.301217]\n",
      "epoch6 step48670 [D loss: -0.066039] [G loss: -0.141777]\n",
      "epoch6 step48675 [D loss: -0.682219] [G loss: -0.255983]\n",
      "epoch6 step48680 [D loss: -0.129163] [G loss: -0.147312]\n",
      "epoch6 step48685 [D loss: -0.224760] [G loss: -0.497489]\n",
      "epoch6 step48690 [D loss: -0.459778] [G loss: -0.266893]\n",
      "epoch6 step48695 [D loss: -0.100021] [G loss: -0.724141]\n",
      "epoch6 step48700 [D loss: -0.200078] [G loss: -0.423426]\n",
      "epoch6 step48705 [D loss: -0.121416] [G loss: -0.338496]\n",
      "epoch6 step48710 [D loss: 0.089187] [G loss: -0.243562]\n",
      "epoch6 step48715 [D loss: -0.221876] [G loss: -0.386824]\n",
      "epoch6 step48720 [D loss: -0.020975] [G loss: -0.183812]\n",
      "epoch6 step48725 [D loss: -0.451713] [G loss: -0.366880]\n",
      "epoch6 step48730 [D loss: 0.181684] [G loss: -0.168406]\n",
      "epoch6 step48735 [D loss: 0.401461] [G loss: -0.477911]\n",
      "epoch6 step48740 [D loss: 0.045241] [G loss: -0.457986]\n",
      "epoch6 step48745 [D loss: 0.165806] [G loss: -0.281372]\n",
      "epoch6 step48750 [D loss: 0.175894] [G loss: -0.236899]\n",
      "epoch6 step48755 [D loss: 0.195278] [G loss: 0.171287]\n",
      "epoch6 step48760 [D loss: -0.641145] [G loss: -0.068160]\n",
      "epoch6 step48765 [D loss: -0.352277] [G loss: -0.262398]\n",
      "epoch6 step48770 [D loss: -0.228229] [G loss: -0.029902]\n",
      "epoch6 step48775 [D loss: 0.132340] [G loss: -0.221645]\n",
      "epoch6 step48780 [D loss: -0.323124] [G loss: -0.240967]\n",
      "epoch6 step48785 [D loss: -0.210451] [G loss: -0.054162]\n",
      "epoch6 step48790 [D loss: -0.124594] [G loss: -0.038367]\n",
      "epoch6 step48795 [D loss: -0.147800] [G loss: -0.193331]\n",
      "epoch6 step48800 [D loss: -0.095918] [G loss: -0.026432]\n",
      "epoch6 step48805 [D loss: 0.078158] [G loss: -0.054177]\n",
      "epoch6 step48810 [D loss: 0.607139] [G loss: -0.333643]\n",
      "epoch6 step48815 [D loss: -0.295015] [G loss: 0.038967]\n",
      "epoch6 step48820 [D loss: -0.662961] [G loss: -0.022783]\n",
      "epoch6 step48825 [D loss: 0.278254] [G loss: 0.211124]\n",
      "epoch6 step48830 [D loss: 0.296210] [G loss: -0.223686]\n",
      "epoch6 step48835 [D loss: -0.600327] [G loss: 0.028851]\n",
      "epoch6 step48840 [D loss: 0.061336] [G loss: 0.330632]\n",
      "epoch6 step48845 [D loss: -0.211012] [G loss: 0.132962]\n",
      "epoch6 step48850 [D loss: -0.252975] [G loss: -0.022549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step48855 [D loss: -0.227618] [G loss: 0.132281]\n",
      "epoch6 step48860 [D loss: -0.619289] [G loss: 0.126007]\n",
      "epoch6 step48865 [D loss: -0.191006] [G loss: 0.234570]\n",
      "epoch6 step48870 [D loss: -0.224472] [G loss: 0.021442]\n",
      "epoch6 step48875 [D loss: -0.041534] [G loss: -0.299483]\n",
      "epoch6 step48880 [D loss: -0.303080] [G loss: -0.272498]\n",
      "epoch6 step48885 [D loss: 0.125645] [G loss: -0.109786]\n",
      "epoch6 step48890 [D loss: -0.743557] [G loss: -0.377566]\n",
      "epoch6 step48895 [D loss: -0.357652] [G loss: -0.376129]\n",
      "epoch6 step48900 [D loss: -0.144061] [G loss: -0.166258]\n",
      "epoch6 step48905 [D loss: -0.245701] [G loss: -0.345217]\n",
      "epoch6 step48910 [D loss: -0.437512] [G loss: -0.440551]\n",
      "epoch6 step48915 [D loss: -0.204302] [G loss: -0.374877]\n",
      "epoch6 step48920 [D loss: -0.090874] [G loss: -0.612850]\n",
      "epoch6 step48925 [D loss: -0.055177] [G loss: -0.592963]\n",
      "epoch6 step48930 [D loss: -0.220421] [G loss: -0.432253]\n",
      "epoch6 step48935 [D loss: -0.031203] [G loss: -0.582616]\n",
      "epoch6 step48940 [D loss: -0.047363] [G loss: -0.503454]\n",
      "epoch6 step48945 [D loss: -0.270569] [G loss: -0.753529]\n",
      "epoch6 step48950 [D loss: -0.431628] [G loss: -0.242879]\n",
      "epoch6 step48955 [D loss: -0.015278] [G loss: -0.377874]\n",
      "epoch6 step48960 [D loss: 0.286444] [G loss: -0.670546]\n",
      "epoch6 step48965 [D loss: -0.104079] [G loss: -0.712804]\n",
      "epoch6 step48970 [D loss: 0.064562] [G loss: -0.330302]\n",
      "epoch6 step48975 [D loss: -0.079160] [G loss: 0.151697]\n",
      "epoch6 step48980 [D loss: -0.024951] [G loss: -0.081508]\n",
      "epoch6 step48985 [D loss: 0.293902] [G loss: -0.292632]\n",
      "epoch6 step48990 [D loss: 0.322160] [G loss: -0.247049]\n",
      "epoch6 step48995 [D loss: -0.017599] [G loss: -0.142641]\n",
      "epoch6 step49000 [D loss: -0.475418] [G loss: 0.107809]\n",
      "epoch6 step49005 [D loss: -0.271478] [G loss: 0.164110]\n",
      "epoch6 step49010 [D loss: -0.310124] [G loss: -0.139293]\n",
      "epoch6 step49015 [D loss: -0.345016] [G loss: 0.264167]\n",
      "epoch6 step49020 [D loss: -0.034904] [G loss: 0.247565]\n",
      "epoch6 step49025 [D loss: -0.214287] [G loss: 0.522795]\n",
      "epoch6 step49030 [D loss: -0.062418] [G loss: 0.401954]\n",
      "epoch6 step49035 [D loss: 0.018534] [G loss: 0.369855]\n",
      "epoch6 step49040 [D loss: 0.113686] [G loss: 0.016345]\n",
      "epoch6 step49045 [D loss: -0.510701] [G loss: 0.292591]\n",
      "epoch6 step49050 [D loss: -0.244171] [G loss: 0.458918]\n",
      "epoch6 step49055 [D loss: -0.151316] [G loss: 0.168523]\n",
      "epoch6 step49060 [D loss: -0.603583] [G loss: 0.601689]\n",
      "epoch6 step49065 [D loss: -0.038064] [G loss: 0.295160]\n",
      "epoch6 step49070 [D loss: -0.550050] [G loss: 0.272039]\n",
      "epoch6 step49075 [D loss: -0.015350] [G loss: 0.448197]\n",
      "epoch6 step49080 [D loss: 0.223514] [G loss: 0.562071]\n",
      "epoch6 step49085 [D loss: -0.126236] [G loss: 0.138697]\n",
      "epoch6 step49090 [D loss: 0.061593] [G loss: 0.199384]\n",
      "epoch6 step49095 [D loss: -0.087887] [G loss: 0.478535]\n",
      "epoch6 step49100 [D loss: -0.001176] [G loss: 0.150632]\n",
      "epoch6 step49105 [D loss: -0.068236] [G loss: -0.184441]\n",
      "epoch6 step49110 [D loss: -0.018051] [G loss: -0.454179]\n",
      "epoch6 step49115 [D loss: -0.115390] [G loss: -0.272407]\n",
      "epoch6 step49120 [D loss: 0.003105] [G loss: -0.034076]\n",
      "epoch6 step49125 [D loss: -0.185233] [G loss: -0.014737]\n",
      "epoch6 step49130 [D loss: -0.187643] [G loss: 0.081595]\n",
      "epoch6 step49135 [D loss: -0.274759] [G loss: -0.159285]\n",
      "epoch6 step49140 [D loss: 0.071257] [G loss: -0.009987]\n",
      "epoch6 step49145 [D loss: -0.403059] [G loss: 0.225240]\n",
      "epoch6 step49150 [D loss: -0.453031] [G loss: -0.339038]\n",
      "epoch6 step49155 [D loss: 0.328867] [G loss: -0.153972]\n",
      "epoch6 step49160 [D loss: -0.727974] [G loss: -0.168464]\n",
      "epoch6 step49165 [D loss: -0.095430] [G loss: -0.407895]\n",
      "epoch6 step49170 [D loss: -0.341264] [G loss: -0.551998]\n",
      "epoch6 step49175 [D loss: -0.137666] [G loss: -0.421426]\n",
      "epoch6 step49180 [D loss: -0.333174] [G loss: -0.336189]\n",
      "epoch6 step49185 [D loss: -0.298550] [G loss: -0.071399]\n",
      "epoch6 step49190 [D loss: -0.451863] [G loss: -0.254899]\n",
      "epoch6 step49195 [D loss: -0.342630] [G loss: -0.577769]\n",
      "epoch6 step49200 [D loss: -0.337979] [G loss: -0.489015]\n",
      "epoch6 step49205 [D loss: -0.094377] [G loss: -0.498826]\n",
      "epoch6 step49210 [D loss: -0.066242] [G loss: -0.509619]\n",
      "epoch6 step49215 [D loss: -0.132307] [G loss: -0.636953]\n",
      "epoch6 step49220 [D loss: 0.333767] [G loss: -0.999428]\n",
      "epoch6 step49225 [D loss: -0.040303] [G loss: -0.134125]\n",
      "epoch6 step49230 [D loss: -0.420929] [G loss: -0.633559]\n",
      "epoch6 step49235 [D loss: -0.121484] [G loss: -0.576729]\n",
      "epoch6 step49240 [D loss: -0.181053] [G loss: -0.681562]\n",
      "epoch6 step49245 [D loss: -0.009558] [G loss: -0.484410]\n",
      "epoch6 step49250 [D loss: 0.169184] [G loss: -0.686563]\n",
      "epoch6 step49255 [D loss: -0.127538] [G loss: -0.454477]\n",
      "epoch6 step49260 [D loss: -0.180412] [G loss: -0.414231]\n",
      "epoch6 step49265 [D loss: -0.229584] [G loss: -0.494894]\n",
      "epoch6 step49270 [D loss: -0.298842] [G loss: -0.608428]\n",
      "epoch6 step49275 [D loss: -0.203127] [G loss: -0.707524]\n",
      "epoch6 step49280 [D loss: 0.101961] [G loss: -0.480733]\n",
      "epoch6 step49285 [D loss: -0.066864] [G loss: -0.066087]\n",
      "epoch6 step49290 [D loss: -0.074105] [G loss: -0.316845]\n",
      "epoch6 step49295 [D loss: -0.132753] [G loss: -0.207787]\n",
      "epoch6 step49300 [D loss: -0.273201] [G loss: 0.088092]\n",
      "epoch6 step49305 [D loss: -0.505582] [G loss: 0.042805]\n",
      "epoch6 step49310 [D loss: 0.226058] [G loss: 0.357640]\n",
      "epoch6 step49315 [D loss: -0.348662] [G loss: 0.129324]\n",
      "epoch6 step49320 [D loss: -0.146126] [G loss: 0.044458]\n",
      "epoch6 step49325 [D loss: -0.164261] [G loss: 0.303970]\n",
      "epoch6 step49330 [D loss: 0.045585] [G loss: -0.047108]\n",
      "epoch6 step49335 [D loss: -0.644397] [G loss: 0.217993]\n",
      "epoch6 step49340 [D loss: -0.855952] [G loss: 0.250022]\n",
      "epoch6 step49345 [D loss: -0.386774] [G loss: 0.605936]\n",
      "epoch6 step49350 [D loss: -0.176211] [G loss: 0.501180]\n",
      "epoch6 step49355 [D loss: -0.184971] [G loss: 0.404986]\n",
      "epoch6 step49360 [D loss: -0.036795] [G loss: 0.011471]\n",
      "epoch6 step49365 [D loss: -0.381815] [G loss: 0.266244]\n",
      "epoch6 step49370 [D loss: -0.403480] [G loss: 0.285128]\n",
      "epoch6 step49375 [D loss: -0.504439] [G loss: 0.011107]\n",
      "epoch6 step49380 [D loss: -0.561290] [G loss: 0.308899]\n",
      "epoch6 step49385 [D loss: -0.041645] [G loss: 0.005188]\n",
      "epoch6 step49390 [D loss: -0.684845] [G loss: 0.218625]\n",
      "epoch6 step49395 [D loss: -0.311330] [G loss: -0.055615]\n",
      "epoch6 step49400 [D loss: -0.194380] [G loss: -0.021843]\n",
      "epoch6 step49405 [D loss: -0.178348] [G loss: -0.254189]\n",
      "epoch6 step49410 [D loss: -0.106610] [G loss: -0.230100]\n",
      "epoch6 step49415 [D loss: 0.585168] [G loss: -0.092221]\n",
      "epoch6 step49420 [D loss: 0.384050] [G loss: -0.102268]\n",
      "epoch6 step49425 [D loss: 0.036164] [G loss: -0.192302]\n",
      "epoch6 step49430 [D loss: -0.215964] [G loss: 0.026653]\n",
      "epoch6 step49435 [D loss: 0.100599] [G loss: -0.201855]\n",
      "epoch6 step49440 [D loss: -0.210178] [G loss: -0.372558]\n",
      "epoch6 step49445 [D loss: -0.108507] [G loss: 0.089415]\n",
      "epoch6 step49450 [D loss: -0.102090] [G loss: -0.236219]\n",
      "epoch6 step49455 [D loss: 0.526042] [G loss: -0.803466]\n",
      "epoch6 step49460 [D loss: -0.300281] [G loss: -0.220847]\n",
      "epoch6 step49465 [D loss: -0.115807] [G loss: -0.695833]\n",
      "epoch6 step49470 [D loss: -0.468059] [G loss: -0.299256]\n",
      "epoch6 step49475 [D loss: 0.161310] [G loss: -0.646676]\n",
      "epoch6 step49480 [D loss: -0.136865] [G loss: -0.335819]\n",
      "epoch6 step49485 [D loss: -0.198323] [G loss: -0.056290]\n",
      "epoch6 step49490 [D loss: 0.143981] [G loss: -0.394203]\n",
      "epoch6 step49495 [D loss: -0.059966] [G loss: -0.585189]\n",
      "epoch6 step49500 [D loss: -0.448033] [G loss: -0.286962]\n",
      "epoch6 step49505 [D loss: -0.373630] [G loss: -0.148898]\n",
      "epoch6 step49510 [D loss: 0.037228] [G loss: -0.468836]\n",
      "epoch6 step49515 [D loss: -0.067481] [G loss: -0.676592]\n",
      "epoch6 step49520 [D loss: -0.229559] [G loss: -0.234648]\n",
      "epoch6 step49525 [D loss: -0.086295] [G loss: -0.671413]\n",
      "epoch6 step49530 [D loss: -0.073830] [G loss: -0.410383]\n",
      "epoch6 step49535 [D loss: -0.466781] [G loss: -0.258862]\n",
      "epoch6 step49540 [D loss: -0.380329] [G loss: -0.157881]\n",
      "epoch6 step49545 [D loss: -0.186033] [G loss: -0.412799]\n",
      "epoch6 step49550 [D loss: 0.069658] [G loss: -0.499426]\n",
      "epoch6 step49555 [D loss: -0.091347] [G loss: -0.626090]\n",
      "epoch6 step49560 [D loss: -0.056696] [G loss: -0.822944]\n",
      "epoch6 step49565 [D loss: -0.499157] [G loss: -0.520877]\n",
      "epoch6 step49570 [D loss: -0.063631] [G loss: -0.738018]\n",
      "epoch6 step49575 [D loss: 0.103169] [G loss: -1.030734]\n",
      "epoch6 step49580 [D loss: -0.158138] [G loss: -0.990435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step49585 [D loss: -0.081524] [G loss: -0.605859]\n",
      "epoch6 step49590 [D loss: 0.221149] [G loss: -1.006444]\n",
      "epoch6 step49595 [D loss: 0.280164] [G loss: -0.944778]\n",
      "epoch6 step49600 [D loss: -0.113897] [G loss: -0.633260]\n",
      "epoch6 step49605 [D loss: -0.289826] [G loss: -0.410660]\n",
      "epoch6 step49610 [D loss: 0.520464] [G loss: -0.443062]\n",
      "epoch6 step49615 [D loss: 0.020392] [G loss: -0.793464]\n",
      "epoch6 step49620 [D loss: -0.471168] [G loss: -0.418678]\n",
      "epoch6 step49625 [D loss: -0.004057] [G loss: -0.621192]\n",
      "epoch6 step49630 [D loss: -0.234760] [G loss: -0.673351]\n",
      "epoch6 step49635 [D loss: -0.377138] [G loss: -0.255117]\n",
      "epoch6 step49640 [D loss: 0.412868] [G loss: -0.361824]\n",
      "epoch6 step49645 [D loss: -0.668051] [G loss: 0.171695]\n",
      "epoch6 step49650 [D loss: -0.131266] [G loss: -0.338796]\n",
      "epoch6 step49655 [D loss: -0.484571] [G loss: -0.146616]\n",
      "epoch6 step49660 [D loss: 0.203873] [G loss: -0.349781]\n",
      "epoch6 step49665 [D loss: -0.577784] [G loss: -0.059398]\n",
      "epoch6 step49670 [D loss: 0.237738] [G loss: -0.105288]\n",
      "epoch6 step49675 [D loss: -0.066536] [G loss: -0.221566]\n",
      "epoch6 step49680 [D loss: -0.170841] [G loss: -0.049411]\n",
      "epoch6 step49685 [D loss: -0.139712] [G loss: -0.114248]\n",
      "epoch6 step49690 [D loss: -0.507386] [G loss: 0.208774]\n",
      "epoch6 step49695 [D loss: 0.178153] [G loss: -0.049293]\n",
      "epoch6 step49700 [D loss: -0.020740] [G loss: -0.254522]\n",
      "epoch6 step49705 [D loss: -0.469056] [G loss: 0.222835]\n",
      "epoch6 step49710 [D loss: -0.133757] [G loss: -0.173641]\n",
      "epoch6 step49715 [D loss: -0.050869] [G loss: -0.203526]\n",
      "epoch6 step49720 [D loss: 0.373851] [G loss: -0.029541]\n",
      "epoch6 step49725 [D loss: 0.177263] [G loss: -0.179919]\n",
      "epoch6 step49730 [D loss: -0.177442] [G loss: 0.157581]\n",
      "epoch6 step49735 [D loss: -0.134002] [G loss: -0.030740]\n",
      "epoch6 step49740 [D loss: -0.208841] [G loss: -0.058053]\n",
      "epoch6 step49745 [D loss: -0.146850] [G loss: -0.143809]\n",
      "epoch6 step49750 [D loss: 0.132917] [G loss: 0.244681]\n",
      "epoch6 step49755 [D loss: 0.182169] [G loss: 0.028919]\n",
      "epoch6 step49760 [D loss: 0.127208] [G loss: -0.114962]\n",
      "epoch6 step49765 [D loss: -0.017727] [G loss: -0.139352]\n",
      "epoch6 step49770 [D loss: -0.124747] [G loss: -0.176218]\n",
      "epoch6 step49775 [D loss: -0.549973] [G loss: 0.008666]\n",
      "epoch6 step49780 [D loss: -0.928755] [G loss: 0.130628]\n",
      "epoch6 step49785 [D loss: 0.187695] [G loss: -0.358697]\n",
      "epoch6 step49790 [D loss: -0.382129] [G loss: -0.091400]\n",
      "epoch6 step49795 [D loss: -0.134504] [G loss: 0.061760]\n",
      "epoch6 step49800 [D loss: -0.031715] [G loss: -0.229813]\n",
      "epoch6 step49805 [D loss: -0.474239] [G loss: -0.370080]\n",
      "epoch6 step49810 [D loss: -0.101272] [G loss: -0.111419]\n",
      "epoch6 step49815 [D loss: -0.263425] [G loss: -0.054718]\n",
      "epoch6 step49820 [D loss: -0.356701] [G loss: -0.173448]\n",
      "epoch6 step49825 [D loss: 0.268910] [G loss: -0.140602]\n",
      "epoch6 step49830 [D loss: -0.316708] [G loss: -0.279576]\n",
      "epoch6 step49835 [D loss: -0.149434] [G loss: 0.076818]\n",
      "epoch6 step49840 [D loss: -0.288556] [G loss: -0.214005]\n",
      "epoch6 step49845 [D loss: -0.446018] [G loss: -0.556244]\n",
      "epoch6 step49850 [D loss: -0.462768] [G loss: 0.231453]\n",
      "epoch6 step49855 [D loss: -0.141591] [G loss: -0.003270]\n",
      "epoch6 step49860 [D loss: -0.372181] [G loss: -0.274279]\n",
      "epoch6 step49865 [D loss: 0.047180] [G loss: -0.277775]\n",
      "epoch6 step49870 [D loss: -0.426818] [G loss: -0.514076]\n",
      "epoch6 step49875 [D loss: 0.154513] [G loss: -0.601803]\n",
      "epoch6 step49880 [D loss: -0.776679] [G loss: -0.461376]\n",
      "epoch6 step49885 [D loss: 0.382148] [G loss: -0.686171]\n",
      "epoch6 step49890 [D loss: 0.764716] [G loss: -0.950733]\n",
      "epoch6 step49895 [D loss: -0.410958] [G loss: -0.755408]\n",
      "epoch6 step49900 [D loss: 0.310816] [G loss: -0.517866]\n",
      "epoch6 step49905 [D loss: -0.139004] [G loss: -0.747427]\n",
      "epoch6 step49910 [D loss: -0.126988] [G loss: -0.707579]\n",
      "epoch6 step49915 [D loss: -0.032234] [G loss: -0.711396]\n",
      "epoch6 step49920 [D loss: -0.227093] [G loss: -0.779967]\n",
      "epoch6 step49925 [D loss: 0.411531] [G loss: -0.814615]\n",
      "epoch6 step49930 [D loss: 0.123324] [G loss: -0.546718]\n",
      "epoch6 step49935 [D loss: -0.095339] [G loss: -0.713952]\n",
      "epoch6 step49940 [D loss: -0.276381] [G loss: -0.713003]\n",
      "epoch6 step49945 [D loss: -0.210947] [G loss: -0.531548]\n",
      "epoch6 step49950 [D loss: 0.110673] [G loss: -0.350600]\n",
      "epoch6 step49955 [D loss: -0.556940] [G loss: -0.283483]\n",
      "epoch6 step49960 [D loss: -0.399887] [G loss: -0.146952]\n",
      "epoch6 step49965 [D loss: -0.337617] [G loss: -0.370444]\n",
      "epoch6 step49970 [D loss: -0.088398] [G loss: -0.229513]\n",
      "epoch6 step49975 [D loss: -0.071334] [G loss: -0.106058]\n",
      "epoch6 step49980 [D loss: -0.638097] [G loss: -0.159564]\n",
      "epoch6 step49985 [D loss: -0.223325] [G loss: -0.518164]\n",
      "epoch6 step49990 [D loss: -0.340115] [G loss: -0.026200]\n",
      "epoch6 step49995 [D loss: -0.016515] [G loss: -0.032665]\n",
      "epoch6 step50000 [D loss: -0.102743] [G loss: 0.185420]\n",
      "epoch6 step50005 [D loss: -0.886083] [G loss: 0.634663]\n",
      "epoch6 step50010 [D loss: -0.462856] [G loss: 0.218507]\n",
      "epoch6 step50015 [D loss: -0.266077] [G loss: 0.002356]\n",
      "epoch6 step50020 [D loss: -0.527281] [G loss: 0.327764]\n",
      "epoch6 step50025 [D loss: -0.240517] [G loss: 0.138391]\n",
      "epoch6 step50030 [D loss: -0.837532] [G loss: 0.477386]\n",
      "epoch6 step50035 [D loss: 0.400929] [G loss: 0.176872]\n",
      "epoch6 step50040 [D loss: -0.482098] [G loss: 0.182995]\n",
      "epoch6 step50045 [D loss: 0.370450] [G loss: 0.507902]\n",
      "epoch6 step50050 [D loss: 0.031785] [G loss: 0.074704]\n",
      "epoch6 step50055 [D loss: -0.683993] [G loss: 0.379140]\n",
      "epoch6 step50060 [D loss: 0.123476] [G loss: -0.230447]\n",
      "epoch6 step50065 [D loss: 0.211146] [G loss: 0.365398]\n",
      "epoch6 step50070 [D loss: -0.581287] [G loss: 0.040509]\n",
      "epoch6 step50075 [D loss: 0.112879] [G loss: -0.127122]\n",
      "epoch6 step50080 [D loss: 0.175194] [G loss: 0.195210]\n",
      "epoch6 step50085 [D loss: -0.204912] [G loss: 0.125020]\n",
      "epoch6 step50090 [D loss: 0.036708] [G loss: 0.221409]\n",
      "epoch6 step50095 [D loss: 0.227709] [G loss: 0.118932]\n",
      "epoch6 step50100 [D loss: 0.331260] [G loss: 0.162516]\n",
      "epoch6 step50105 [D loss: 0.010593] [G loss: -0.206670]\n",
      "epoch6 step50110 [D loss: 0.196807] [G loss: 0.222511]\n",
      "epoch6 step50115 [D loss: -0.258648] [G loss: -0.178889]\n",
      "epoch6 step50120 [D loss: 0.370720] [G loss: -0.270303]\n",
      "epoch6 step50125 [D loss: -0.127092] [G loss: -0.091808]\n",
      "epoch6 step50130 [D loss: -0.423299] [G loss: -0.147661]\n",
      "epoch6 step50135 [D loss: 0.000369] [G loss: -0.076364]\n",
      "epoch6 step50140 [D loss: -0.253393] [G loss: -0.155215]\n",
      "epoch6 step50145 [D loss: -0.232715] [G loss: 0.074989]\n",
      "epoch6 step50150 [D loss: -0.000802] [G loss: 0.133496]\n",
      "epoch6 step50155 [D loss: -0.313750] [G loss: -0.261812]\n",
      "epoch6 step50160 [D loss: -0.343135] [G loss: -0.246292]\n",
      "epoch6 step50165 [D loss: -0.472216] [G loss: -0.304327]\n",
      "epoch6 step50170 [D loss: -0.335237] [G loss: 0.181183]\n",
      "epoch6 step50175 [D loss: 0.061370] [G loss: -0.079782]\n",
      "epoch6 step50180 [D loss: -0.315287] [G loss: -0.129603]\n",
      "epoch6 step50185 [D loss: -0.560844] [G loss: -0.067705]\n",
      "epoch6 step50190 [D loss: -0.225317] [G loss: -0.086848]\n",
      "epoch6 step50195 [D loss: -0.436134] [G loss: -0.124725]\n",
      "epoch6 step50200 [D loss: 0.105049] [G loss: -0.292616]\n",
      "epoch6 step50205 [D loss: -0.408861] [G loss: 0.090506]\n",
      "epoch6 step50210 [D loss: 0.079787] [G loss: -0.101995]\n",
      "epoch6 step50215 [D loss: -0.113458] [G loss: -0.255274]\n",
      "epoch6 step50220 [D loss: 0.195612] [G loss: -0.106097]\n",
      "epoch6 step50225 [D loss: -0.350071] [G loss: 0.006094]\n",
      "epoch6 step50230 [D loss: -0.298887] [G loss: 0.199184]\n",
      "epoch6 step50235 [D loss: -0.363454] [G loss: -0.135143]\n",
      "epoch6 step50240 [D loss: -0.249435] [G loss: -0.233148]\n",
      "epoch6 step50245 [D loss: -0.658713] [G loss: 0.198051]\n",
      "epoch6 step50250 [D loss: -0.068840] [G loss: -0.086890]\n",
      "epoch6 step50255 [D loss: -0.150665] [G loss: -0.370344]\n",
      "epoch6 step50260 [D loss: 0.239341] [G loss: -0.295721]\n",
      "epoch6 step50265 [D loss: -0.168947] [G loss: 0.072700]\n",
      "epoch6 step50270 [D loss: -0.152868] [G loss: 0.008528]\n",
      "epoch6 step50275 [D loss: -0.225709] [G loss: -0.073409]\n",
      "epoch6 step50280 [D loss: 0.018287] [G loss: 0.355220]\n",
      "epoch6 step50285 [D loss: -0.163437] [G loss: 0.152775]\n",
      "epoch6 step50290 [D loss: -0.093466] [G loss: 0.222352]\n",
      "epoch6 step50295 [D loss: -0.078191] [G loss: 0.410540]\n",
      "epoch6 step50300 [D loss: -0.481642] [G loss: 0.720370]\n",
      "epoch6 step50305 [D loss: -0.040540] [G loss: 0.483425]\n",
      "epoch6 step50310 [D loss: -0.053612] [G loss: 0.660552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step50315 [D loss: -0.245980] [G loss: 0.379608]\n",
      "epoch6 step50320 [D loss: -0.493768] [G loss: 0.793393]\n",
      "epoch6 step50325 [D loss: -0.562333] [G loss: 0.742682]\n",
      "epoch6 step50330 [D loss: 0.421361] [G loss: 0.313082]\n",
      "epoch6 step50335 [D loss: -0.596322] [G loss: 0.622316]\n",
      "epoch6 step50340 [D loss: -0.410585] [G loss: 0.908497]\n",
      "epoch6 step50345 [D loss: 0.146362] [G loss: 0.791992]\n",
      "epoch6 step50350 [D loss: -0.212678] [G loss: 0.304520]\n",
      "epoch6 step50355 [D loss: 0.103636] [G loss: 0.586161]\n",
      "epoch6 step50360 [D loss: -0.140970] [G loss: 0.827256]\n",
      "epoch6 step50365 [D loss: -0.160138] [G loss: 0.405611]\n",
      "epoch6 step50370 [D loss: 0.608129] [G loss: 1.025413]\n",
      "epoch6 step50375 [D loss: 0.364152] [G loss: 0.642747]\n",
      "epoch6 step50380 [D loss: -0.429960] [G loss: 0.265144]\n",
      "epoch6 step50385 [D loss: -0.147763] [G loss: 0.554552]\n",
      "epoch6 step50390 [D loss: 0.187640] [G loss: 0.770866]\n",
      "epoch6 step50395 [D loss: -0.370188] [G loss: 0.614280]\n",
      "epoch6 step50400 [D loss: -0.191537] [G loss: 0.522048]\n",
      "epoch6 step50405 [D loss: -0.421361] [G loss: 0.496553]\n",
      "epoch6 step50410 [D loss: 0.033086] [G loss: 0.022391]\n",
      "epoch6 step50415 [D loss: -0.200377] [G loss: 0.188273]\n",
      "epoch6 step50420 [D loss: -0.183708] [G loss: 0.140634]\n",
      "epoch6 step50425 [D loss: -0.921928] [G loss: 0.225902]\n",
      "epoch6 step50430 [D loss: -0.393134] [G loss: 0.396833]\n",
      "epoch6 step50435 [D loss: -0.491827] [G loss: 0.057435]\n",
      "epoch6 step50440 [D loss: -0.202192] [G loss: 0.375432]\n",
      "epoch6 step50445 [D loss: -0.150084] [G loss: 0.128315]\n",
      "epoch6 step50450 [D loss: -0.009067] [G loss: 0.103467]\n",
      "epoch6 step50455 [D loss: -0.320054] [G loss: -0.159878]\n",
      "epoch6 step50460 [D loss: 0.201052] [G loss: 0.155485]\n",
      "epoch6 step50465 [D loss: -0.437778] [G loss: -0.244613]\n",
      "epoch6 step50470 [D loss: 0.124508] [G loss: -0.197695]\n",
      "epoch6 step50475 [D loss: -0.093454] [G loss: -0.291881]\n",
      "epoch6 step50480 [D loss: -0.095407] [G loss: -0.181875]\n",
      "epoch6 step50485 [D loss: 0.238331] [G loss: -0.126809]\n",
      "epoch6 step50490 [D loss: -1.096724] [G loss: -0.303855]\n",
      "epoch6 step50495 [D loss: -0.342250] [G loss: -0.522133]\n",
      "epoch6 step50500 [D loss: -0.100643] [G loss: -0.335363]\n",
      "epoch6 step50505 [D loss: -0.043638] [G loss: -0.579009]\n",
      "epoch6 step50510 [D loss: -0.124941] [G loss: -1.137861]\n",
      "epoch6 step50515 [D loss: -0.447859] [G loss: -0.803658]\n",
      "epoch6 step50520 [D loss: -0.222697] [G loss: -0.697042]\n",
      "epoch6 step50525 [D loss: -0.117867] [G loss: -0.799491]\n",
      "epoch6 step50530 [D loss: -0.224486] [G loss: -0.810917]\n",
      "epoch6 step50535 [D loss: -0.553949] [G loss: -0.551200]\n",
      "epoch6 step50540 [D loss: -0.505977] [G loss: -0.967654]\n",
      "epoch6 step50545 [D loss: -0.164051] [G loss: -0.633156]\n",
      "epoch6 step50550 [D loss: -0.255196] [G loss: -0.709367]\n",
      "epoch6 step50555 [D loss: -0.815115] [G loss: -0.859980]\n",
      "epoch6 step50560 [D loss: -0.158778] [G loss: -0.797010]\n",
      "epoch6 step50565 [D loss: -0.008922] [G loss: -0.785521]\n",
      "epoch6 step50570 [D loss: 0.299230] [G loss: -1.322781]\n",
      "epoch6 step50575 [D loss: -0.003184] [G loss: -1.088297]\n",
      "epoch6 step50580 [D loss: -0.335827] [G loss: -0.669435]\n",
      "epoch6 step50585 [D loss: 0.305281] [G loss: -0.934644]\n",
      "epoch6 step50590 [D loss: 0.009441] [G loss: -0.816622]\n",
      "epoch6 step50595 [D loss: -0.291133] [G loss: -0.683767]\n",
      "epoch6 step50600 [D loss: -0.384085] [G loss: -0.916245]\n",
      "epoch6 step50605 [D loss: 0.292954] [G loss: -0.724702]\n",
      "epoch6 step50610 [D loss: -0.581722] [G loss: -0.611288]\n",
      "epoch6 step50615 [D loss: 0.360641] [G loss: -0.832813]\n",
      "epoch6 step50620 [D loss: -0.249373] [G loss: -0.537693]\n",
      "epoch6 step50625 [D loss: 0.176682] [G loss: -0.688949]\n",
      "epoch6 step50630 [D loss: -0.439106] [G loss: -0.273200]\n",
      "epoch6 step50635 [D loss: -0.063105] [G loss: -0.606874]\n",
      "epoch6 step50640 [D loss: -0.129607] [G loss: -0.057975]\n",
      "epoch6 step50645 [D loss: -0.291947] [G loss: 0.286899]\n",
      "epoch6 step50650 [D loss: -0.085468] [G loss: -0.084802]\n",
      "epoch6 step50655 [D loss: 0.068097] [G loss: -0.242624]\n",
      "epoch6 step50660 [D loss: -0.403018] [G loss: -0.154698]\n",
      "epoch6 step50665 [D loss: -0.653484] [G loss: 0.005249]\n",
      "epoch6 step50670 [D loss: 0.255257] [G loss: -0.204215]\n",
      "epoch6 step50675 [D loss: -0.202510] [G loss: 0.208701]\n",
      "epoch6 step50680 [D loss: -0.561040] [G loss: -0.233689]\n",
      "epoch6 step50685 [D loss: -0.224135] [G loss: -0.491031]\n",
      "epoch6 step50690 [D loss: -0.493933] [G loss: 0.118112]\n",
      "epoch6 step50695 [D loss: -0.362391] [G loss: 0.288936]\n",
      "epoch6 step50700 [D loss: -0.259183] [G loss: 0.015897]\n",
      "epoch6 step50705 [D loss: 0.778830] [G loss: -0.396841]\n",
      "epoch6 step50710 [D loss: -0.844842] [G loss: -0.357584]\n",
      "epoch6 step50715 [D loss: -0.015226] [G loss: -0.391384]\n",
      "epoch6 step50720 [D loss: -0.371513] [G loss: -0.446746]\n",
      "epoch6 step50725 [D loss: -0.179230] [G loss: -0.615555]\n",
      "epoch6 step50730 [D loss: -0.753510] [G loss: -0.508998]\n",
      "epoch6 step50735 [D loss: 0.045660] [G loss: -0.606321]\n",
      "epoch6 step50740 [D loss: 0.126053] [G loss: -0.378280]\n",
      "epoch6 step50745 [D loss: -0.299504] [G loss: -0.434834]\n",
      "epoch6 step50750 [D loss: -0.102294] [G loss: -0.378743]\n",
      "epoch6 step50755 [D loss: -0.127132] [G loss: -0.666527]\n",
      "epoch6 step50760 [D loss: 0.057212] [G loss: -0.507309]\n",
      "epoch6 step50765 [D loss: -0.056844] [G loss: -0.355415]\n",
      "epoch6 step50770 [D loss: 0.041186] [G loss: -1.002295]\n",
      "epoch6 step50775 [D loss: -0.286495] [G loss: -0.404080]\n",
      "epoch6 step50780 [D loss: -0.162487] [G loss: -0.642459]\n",
      "epoch6 step50785 [D loss: -0.323237] [G loss: -0.321705]\n",
      "epoch6 step50790 [D loss: -0.120712] [G loss: -0.848904]\n",
      "epoch6 step50795 [D loss: -0.763416] [G loss: -0.391950]\n",
      "epoch6 step50800 [D loss: -0.458948] [G loss: -0.741236]\n",
      "epoch6 step50805 [D loss: -0.379820] [G loss: -0.437663]\n",
      "epoch6 step50810 [D loss: -0.269264] [G loss: -0.606332]\n",
      "epoch6 step50815 [D loss: -0.349507] [G loss: -0.572961]\n",
      "epoch6 step50820 [D loss: -0.415750] [G loss: -0.701028]\n",
      "epoch6 step50825 [D loss: -0.022494] [G loss: -0.438194]\n",
      "epoch6 step50830 [D loss: -0.225672] [G loss: -0.457592]\n",
      "epoch6 step50835 [D loss: -0.526679] [G loss: -0.399129]\n",
      "epoch6 step50840 [D loss: -0.332917] [G loss: -0.755556]\n",
      "epoch6 step50845 [D loss: -0.546570] [G loss: -0.468143]\n",
      "epoch6 step50850 [D loss: 0.318257] [G loss: -0.943026]\n",
      "epoch6 step50855 [D loss: 0.381120] [G loss: -0.756348]\n",
      "epoch6 step50860 [D loss: 0.294756] [G loss: -0.712913]\n",
      "epoch6 step50865 [D loss: -0.647455] [G loss: -0.682803]\n",
      "epoch6 step50870 [D loss: 0.079689] [G loss: -0.716137]\n",
      "epoch6 step50875 [D loss: 0.076429] [G loss: -0.760111]\n",
      "epoch6 step50880 [D loss: -0.326868] [G loss: -0.445881]\n",
      "epoch6 step50885 [D loss: -0.280679] [G loss: -0.627534]\n",
      "epoch6 step50890 [D loss: -0.036494] [G loss: -0.796907]\n",
      "epoch6 step50895 [D loss: -0.131856] [G loss: -0.613956]\n",
      "epoch6 step50900 [D loss: -0.233293] [G loss: -0.325416]\n",
      "epoch6 step50905 [D loss: 0.075283] [G loss: -0.647814]\n",
      "epoch6 step50910 [D loss: -0.655643] [G loss: -0.420776]\n",
      "epoch6 step50915 [D loss: 0.014774] [G loss: -0.190750]\n",
      "epoch6 step50920 [D loss: 0.090834] [G loss: -0.320503]\n",
      "epoch6 step50925 [D loss: -0.485709] [G loss: -0.470188]\n",
      "epoch6 step50930 [D loss: -0.580816] [G loss: -0.500061]\n",
      "epoch6 step50935 [D loss: -0.113414] [G loss: -0.485231]\n",
      "epoch6 step50940 [D loss: -0.394150] [G loss: -0.190912]\n",
      "epoch6 step50945 [D loss: -0.047754] [G loss: -0.268866]\n",
      "epoch6 step50950 [D loss: -0.531170] [G loss: -0.323891]\n",
      "epoch6 step50955 [D loss: -0.628446] [G loss: -0.577486]\n",
      "epoch6 step50960 [D loss: -0.223597] [G loss: -0.706323]\n",
      "epoch6 step50965 [D loss: -0.203118] [G loss: -0.147143]\n",
      "epoch6 step50970 [D loss: -0.108291] [G loss: -0.419563]\n",
      "epoch6 step50975 [D loss: -0.085531] [G loss: -0.857237]\n",
      "epoch6 step50980 [D loss: -0.162261] [G loss: -0.723820]\n",
      "epoch6 step50985 [D loss: -0.663852] [G loss: -0.595892]\n",
      "epoch6 step50990 [D loss: -0.021980] [G loss: -0.487817]\n",
      "epoch6 step50995 [D loss: 0.120536] [G loss: -0.877816]\n",
      "epoch6 step51000 [D loss: -0.166939] [G loss: -0.078234]\n",
      "epoch6 step51005 [D loss: -0.568250] [G loss: -0.447803]\n",
      "epoch6 step51010 [D loss: -0.149160] [G loss: -0.664140]\n",
      "epoch6 step51015 [D loss: 0.145231] [G loss: -0.604617]\n",
      "epoch6 step51020 [D loss: -0.115080] [G loss: -0.473520]\n",
      "epoch6 step51025 [D loss: -0.226988] [G loss: -0.668517]\n",
      "epoch6 step51030 [D loss: -0.103218] [G loss: -0.703335]\n",
      "epoch6 step51035 [D loss: 0.562337] [G loss: -0.610414]\n",
      "epoch6 step51040 [D loss: -0.096948] [G loss: -0.423500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step51045 [D loss: -0.244826] [G loss: -0.562611]\n",
      "epoch6 step51050 [D loss: -0.153872] [G loss: -0.626823]\n",
      "epoch6 step51055 [D loss: -0.403395] [G loss: -0.618496]\n",
      "epoch6 step51060 [D loss: -0.034406] [G loss: -0.601649]\n",
      "epoch6 step51065 [D loss: -0.013224] [G loss: -0.547905]\n",
      "epoch6 step51070 [D loss: -0.174511] [G loss: -0.165257]\n",
      "epoch6 step51075 [D loss: 0.019680] [G loss: -0.654804]\n",
      "epoch6 step51080 [D loss: -0.394781] [G loss: -0.582703]\n",
      "epoch6 step51085 [D loss: -0.423985] [G loss: -0.539892]\n",
      "epoch6 step51090 [D loss: -0.295442] [G loss: -0.697195]\n",
      "epoch6 step51095 [D loss: -0.289838] [G loss: -0.595441]\n",
      "epoch6 step51100 [D loss: -0.037255] [G loss: -0.607435]\n",
      "epoch6 step51105 [D loss: -0.110236] [G loss: -0.461742]\n",
      "epoch6 step51110 [D loss: -0.248036] [G loss: -0.097623]\n",
      "epoch6 step51115 [D loss: 0.238393] [G loss: -0.636214]\n",
      "epoch6 step51120 [D loss: -0.472803] [G loss: -0.174321]\n",
      "epoch6 step51125 [D loss: -0.411451] [G loss: -0.544190]\n",
      "epoch6 step51130 [D loss: -0.248827] [G loss: -0.671936]\n",
      "epoch6 step51135 [D loss: 0.271958] [G loss: -0.600151]\n",
      "epoch6 step51140 [D loss: 0.392080] [G loss: -0.784742]\n",
      "epoch6 step51145 [D loss: -0.021752] [G loss: -0.417596]\n",
      "epoch6 step51150 [D loss: 0.198442] [G loss: -0.554957]\n",
      "epoch6 step51155 [D loss: -0.097602] [G loss: -0.525922]\n",
      "epoch6 step51160 [D loss: -0.115822] [G loss: -0.629477]\n",
      "epoch6 step51165 [D loss: 0.029081] [G loss: -0.611634]\n",
      "epoch6 step51170 [D loss: -0.169426] [G loss: -0.807669]\n",
      "epoch6 step51175 [D loss: -0.236418] [G loss: -0.590862]\n",
      "epoch6 step51180 [D loss: 0.462577] [G loss: -0.832433]\n",
      "epoch6 step51185 [D loss: -0.112719] [G loss: -0.306008]\n",
      "epoch6 step51190 [D loss: -0.268412] [G loss: -0.332621]\n",
      "epoch6 step51195 [D loss: -0.363927] [G loss: -0.226552]\n",
      "epoch6 step51200 [D loss: -0.209760] [G loss: -0.191364]\n",
      "epoch6 step51205 [D loss: -0.073840] [G loss: -0.041846]\n",
      "epoch6 step51210 [D loss: -1.087735] [G loss: -0.031915]\n",
      "epoch6 step51215 [D loss: -0.041843] [G loss: 0.052591]\n",
      "epoch6 step51220 [D loss: 0.034594] [G loss: -0.033671]\n",
      "epoch6 step51225 [D loss: -0.305628] [G loss: 0.031233]\n",
      "epoch6 step51230 [D loss: -0.549056] [G loss: -0.046491]\n",
      "epoch6 step51235 [D loss: -0.538358] [G loss: 0.157734]\n",
      "epoch6 step51240 [D loss: -0.537932] [G loss: -0.019927]\n",
      "epoch6 step51245 [D loss: -0.277556] [G loss: -0.327287]\n",
      "epoch6 step51250 [D loss: 0.083972] [G loss: -0.312088]\n",
      "epoch6 step51255 [D loss: -0.436891] [G loss: -0.056945]\n",
      "epoch6 step51260 [D loss: 0.270690] [G loss: -0.439137]\n",
      "epoch6 step51265 [D loss: -0.118251] [G loss: -0.382800]\n",
      "epoch6 step51270 [D loss: -0.279855] [G loss: -0.097759]\n",
      "epoch6 step51275 [D loss: 0.425267] [G loss: -0.391373]\n",
      "epoch6 step51280 [D loss: -0.686864] [G loss: -0.215561]\n",
      "epoch6 step51285 [D loss: -0.357580] [G loss: -0.347439]\n",
      "epoch6 step51290 [D loss: -0.305850] [G loss: -0.523073]\n",
      "epoch6 step51295 [D loss: -0.227185] [G loss: -0.299103]\n",
      "epoch6 step51300 [D loss: -0.365628] [G loss: -0.566692]\n",
      "epoch6 step51305 [D loss: -0.214337] [G loss: -0.454840]\n",
      "epoch6 step51310 [D loss: -0.262398] [G loss: -0.450148]\n",
      "epoch6 step51315 [D loss: -0.131339] [G loss: -0.282802]\n",
      "epoch6 step51320 [D loss: -0.779354] [G loss: -0.033223]\n",
      "epoch6 step51325 [D loss: -0.119293] [G loss: 0.018472]\n",
      "epoch6 step51330 [D loss: -0.081332] [G loss: -0.491614]\n",
      "epoch6 step51335 [D loss: -0.213800] [G loss: -0.242384]\n",
      "epoch6 step51340 [D loss: -0.169170] [G loss: -0.375754]\n",
      "epoch6 step51345 [D loss: -0.285588] [G loss: -0.387080]\n",
      "epoch6 step51350 [D loss: -0.356581] [G loss: 0.013598]\n",
      "epoch6 step51355 [D loss: -0.234632] [G loss: -0.286735]\n",
      "epoch6 step51360 [D loss: -0.395599] [G loss: -0.550771]\n",
      "epoch6 step51365 [D loss: 0.365384] [G loss: -0.284762]\n",
      "epoch6 step51370 [D loss: -0.119369] [G loss: -0.592295]\n",
      "epoch6 step51375 [D loss: -0.177082] [G loss: -0.573161]\n",
      "epoch6 step51380 [D loss: -0.088989] [G loss: -0.669434]\n",
      "epoch6 step51385 [D loss: -0.674372] [G loss: -0.326504]\n",
      "epoch6 step51390 [D loss: -0.121705] [G loss: -0.416554]\n",
      "epoch6 step51395 [D loss: -0.382003] [G loss: -0.529452]\n",
      "epoch6 step51400 [D loss: 0.094505] [G loss: -0.462216]\n",
      "epoch6 step51405 [D loss: -0.377740] [G loss: -0.258088]\n",
      "epoch6 step51410 [D loss: 0.351836] [G loss: -0.285959]\n",
      "epoch6 step51415 [D loss: -0.170913] [G loss: -0.331733]\n",
      "epoch6 step51420 [D loss: 0.016149] [G loss: -0.364223]\n",
      "epoch6 step51425 [D loss: -0.313837] [G loss: -0.500819]\n",
      "epoch6 step51430 [D loss: -0.127725] [G loss: -0.365089]\n",
      "epoch6 step51435 [D loss: -0.504165] [G loss: 0.008910]\n",
      "epoch6 step51440 [D loss: -0.133251] [G loss: -0.119122]\n",
      "epoch6 step51445 [D loss: -0.222468] [G loss: 0.192311]\n",
      "epoch6 step51450 [D loss: 0.364990] [G loss: -0.517244]\n",
      "epoch6 step51455 [D loss: -0.636976] [G loss: -0.476513]\n",
      "epoch6 step51460 [D loss: 0.335452] [G loss: -0.301257]\n",
      "epoch6 step51465 [D loss: -0.171484] [G loss: -0.348315]\n",
      "epoch6 step51470 [D loss: 0.337303] [G loss: -0.417483]\n",
      "epoch6 step51475 [D loss: -0.296476] [G loss: -0.093100]\n",
      "epoch6 step51480 [D loss: -0.477997] [G loss: -0.238605]\n",
      "epoch6 step51485 [D loss: -0.214846] [G loss: 0.169245]\n",
      "epoch6 step51490 [D loss: -0.265956] [G loss: -0.283159]\n",
      "epoch6 step51495 [D loss: -0.148099] [G loss: 0.099143]\n",
      "epoch6 step51500 [D loss: -0.112180] [G loss: 0.186593]\n",
      "epoch6 step51505 [D loss: -0.594504] [G loss: 0.094895]\n",
      "epoch6 step51510 [D loss: -0.123099] [G loss: -0.218664]\n",
      "epoch6 step51515 [D loss: -0.449807] [G loss: -0.105042]\n",
      "epoch6 step51520 [D loss: 0.219670] [G loss: -0.338056]\n",
      "epoch6 step51525 [D loss: -0.530515] [G loss: -0.157011]\n",
      "epoch6 step51530 [D loss: 0.057049] [G loss: -0.373284]\n",
      "epoch6 step51535 [D loss: -0.288518] [G loss: -0.305326]\n",
      "epoch6 step51540 [D loss: -0.182490] [G loss: -0.643207]\n",
      "epoch6 step51545 [D loss: 0.040055] [G loss: -0.457738]\n",
      "epoch6 step51550 [D loss: -0.285633] [G loss: -0.299338]\n",
      "epoch6 step51555 [D loss: 0.357795] [G loss: -0.460181]\n",
      "epoch6 step51560 [D loss: -0.451195] [G loss: -0.540172]\n",
      "epoch6 step51565 [D loss: -0.093933] [G loss: -0.166898]\n",
      "epoch6 step51570 [D loss: 0.119309] [G loss: -0.355039]\n",
      "epoch6 step51575 [D loss: -0.106114] [G loss: -0.438525]\n",
      "epoch6 step51580 [D loss: 0.100353] [G loss: -0.354755]\n",
      "epoch6 step51585 [D loss: -0.531775] [G loss: -0.442811]\n",
      "epoch6 step51590 [D loss: -0.089121] [G loss: -0.152918]\n",
      "epoch6 step51595 [D loss: -0.279989] [G loss: -0.025248]\n",
      "epoch6 step51600 [D loss: -0.036414] [G loss: -0.508626]\n",
      "epoch6 step51605 [D loss: 0.190294] [G loss: -0.266745]\n",
      "epoch6 step51610 [D loss: 0.025523] [G loss: -0.497124]\n",
      "epoch6 step51615 [D loss: -0.014858] [G loss: -0.140410]\n",
      "epoch6 step51620 [D loss: -0.429576] [G loss: -0.066227]\n",
      "epoch6 step51625 [D loss: 0.046997] [G loss: -0.300652]\n",
      "epoch6 step51630 [D loss: -0.802248] [G loss: -0.242029]\n",
      "epoch6 step51635 [D loss: -0.189575] [G loss: -0.361941]\n",
      "epoch6 step51640 [D loss: -0.109567] [G loss: -0.488971]\n",
      "epoch6 step51645 [D loss: -0.730843] [G loss: 0.358134]\n",
      "epoch6 step51650 [D loss: -0.062168] [G loss: -0.061713]\n",
      "epoch6 step51655 [D loss: 0.261186] [G loss: -0.018359]\n",
      "epoch6 step51660 [D loss: -0.043132] [G loss: 0.399574]\n",
      "epoch6 step51665 [D loss: -0.508501] [G loss: 0.372949]\n",
      "epoch6 step51670 [D loss: -0.469970] [G loss: 0.241284]\n",
      "epoch6 step51675 [D loss: -0.273709] [G loss: 0.110458]\n",
      "epoch6 step51680 [D loss: -0.654187] [G loss: 0.339727]\n",
      "epoch6 step51685 [D loss: 0.114801] [G loss: 0.229992]\n",
      "epoch6 step51690 [D loss: -0.453114] [G loss: 0.215737]\n",
      "epoch6 step51695 [D loss: 0.120214] [G loss: 0.050178]\n",
      "epoch6 step51700 [D loss: -0.067392] [G loss: 0.051215]\n",
      "epoch6 step51705 [D loss: -0.216076] [G loss: 0.121344]\n",
      "epoch6 step51710 [D loss: 0.224238] [G loss: 0.004761]\n",
      "epoch6 step51715 [D loss: 0.031662] [G loss: 0.142597]\n",
      "epoch6 step51720 [D loss: -0.490689] [G loss: 0.357484]\n",
      "epoch6 step51725 [D loss: -0.105086] [G loss: 0.181921]\n",
      "epoch6 step51730 [D loss: -0.220933] [G loss: 0.491999]\n",
      "epoch6 step51735 [D loss: -1.044992] [G loss: 0.218031]\n",
      "epoch6 step51740 [D loss: -0.151826] [G loss: -0.000707]\n",
      "epoch6 step51745 [D loss: -0.443527] [G loss: -0.198386]\n",
      "epoch6 step51750 [D loss: 0.230097] [G loss: -0.057800]\n",
      "epoch6 step51755 [D loss: -0.401028] [G loss: 0.081795]\n",
      "epoch6 step51760 [D loss: -0.125356] [G loss: 0.037230]\n",
      "epoch6 step51765 [D loss: -0.148455] [G loss: 0.032107]\n",
      "epoch6 step51770 [D loss: -0.045273] [G loss: -0.306824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step51775 [D loss: -0.241821] [G loss: -0.088590]\n",
      "epoch6 step51780 [D loss: -0.211211] [G loss: -0.342310]\n",
      "epoch6 step51785 [D loss: 0.040842] [G loss: -0.262899]\n",
      "epoch6 step51790 [D loss: 0.189845] [G loss: -0.185714]\n",
      "epoch6 step51795 [D loss: 0.580803] [G loss: 0.004557]\n",
      "epoch6 step51800 [D loss: -0.749245] [G loss: -0.347531]\n",
      "epoch6 step51805 [D loss: -0.062125] [G loss: -0.434804]\n",
      "epoch6 step51810 [D loss: -0.304206] [G loss: -0.504514]\n",
      "epoch6 step51815 [D loss: -0.343770] [G loss: -0.412353]\n",
      "epoch6 step51820 [D loss: -0.504768] [G loss: 0.055888]\n",
      "epoch6 step51825 [D loss: -0.398409] [G loss: -0.356692]\n",
      "epoch6 step51830 [D loss: -0.231375] [G loss: -0.010654]\n",
      "epoch6 step51835 [D loss: -0.102203] [G loss: -0.410098]\n",
      "epoch6 step51840 [D loss: 0.103227] [G loss: -0.378025]\n",
      "epoch6 step51845 [D loss: -0.367664] [G loss: 0.074173]\n",
      "epoch6 step51850 [D loss: -0.607466] [G loss: -0.216591]\n",
      "epoch6 step51855 [D loss: 0.037149] [G loss: -0.239753]\n",
      "epoch6 step51860 [D loss: -0.232147] [G loss: -0.161716]\n",
      "epoch6 step51865 [D loss: -0.260033] [G loss: -0.000988]\n",
      "epoch6 step51870 [D loss: -0.124017] [G loss: -0.072118]\n",
      "epoch6 step51875 [D loss: -0.381156] [G loss: -0.053206]\n",
      "epoch6 step51880 [D loss: -0.198973] [G loss: 0.039449]\n",
      "epoch6 step51885 [D loss: -0.345410] [G loss: -0.348709]\n",
      "epoch6 step51890 [D loss: -0.534183] [G loss: -0.446646]\n",
      "epoch6 step51895 [D loss: -0.181073] [G loss: 0.101525]\n",
      "epoch6 step51900 [D loss: -0.222583] [G loss: -0.199153]\n",
      "epoch6 step51905 [D loss: -0.512254] [G loss: 0.021257]\n",
      "epoch6 step51910 [D loss: 0.409424] [G loss: -0.247820]\n",
      "epoch6 step51915 [D loss: 0.051155] [G loss: -0.114422]\n",
      "epoch6 step51920 [D loss: -0.091162] [G loss: -0.194440]\n",
      "epoch6 step51925 [D loss: 0.214824] [G loss: 0.160394]\n",
      "epoch6 step51930 [D loss: -0.067291] [G loss: -0.037289]\n",
      "epoch6 step51935 [D loss: 0.007977] [G loss: -0.035995]\n",
      "epoch6 step51940 [D loss: 0.126790] [G loss: -0.303066]\n",
      "epoch6 step51945 [D loss: -0.216204] [G loss: 0.154828]\n",
      "epoch6 step51950 [D loss: 0.015889] [G loss: -0.288485]\n",
      "epoch6 step51955 [D loss: 0.068683] [G loss: -0.060866]\n",
      "epoch6 step51960 [D loss: -0.100768] [G loss: -0.068668]\n",
      "epoch6 step51965 [D loss: -0.136581] [G loss: -0.015235]\n",
      "epoch6 step51970 [D loss: -0.312705] [G loss: -0.023294]\n",
      "epoch6 step51975 [D loss: -0.580572] [G loss: -0.283581]\n",
      "epoch6 step51980 [D loss: -0.192500] [G loss: -0.242240]\n",
      "epoch6 step51985 [D loss: -0.123911] [G loss: -0.196063]\n",
      "epoch6 step51990 [D loss: -0.081503] [G loss: -0.052301]\n",
      "epoch6 step51995 [D loss: 0.130294] [G loss: -0.067497]\n",
      "epoch6 step52000 [D loss: -0.314104] [G loss: -0.235684]\n",
      "epoch6 step52005 [D loss: -0.278878] [G loss: -0.243045]\n",
      "epoch6 step52010 [D loss: -0.316264] [G loss: -0.283734]\n",
      "epoch6 step52015 [D loss: -0.588976] [G loss: -0.315082]\n",
      "epoch6 step52020 [D loss: 0.227136] [G loss: -0.154378]\n",
      "epoch6 step52025 [D loss: -0.274571] [G loss: -0.291889]\n",
      "epoch6 step52030 [D loss: -0.157619] [G loss: -0.180019]\n",
      "epoch6 step52035 [D loss: -0.078012] [G loss: -0.308680]\n",
      "epoch6 step52040 [D loss: 0.079299] [G loss: -0.260518]\n",
      "epoch6 step52045 [D loss: -0.144308] [G loss: 0.036763]\n",
      "epoch6 step52050 [D loss: -0.349454] [G loss: 0.035884]\n",
      "epoch6 step52055 [D loss: -0.486146] [G loss: -0.105434]\n",
      "epoch6 step52060 [D loss: 0.193942] [G loss: -0.238151]\n",
      "epoch6 step52065 [D loss: 0.024308] [G loss: -0.171260]\n",
      "epoch6 step52070 [D loss: -0.243938] [G loss: -0.171127]\n",
      "epoch6 step52075 [D loss: -0.003130] [G loss: -0.212512]\n",
      "epoch6 step52080 [D loss: 0.259387] [G loss: -0.118236]\n",
      "epoch6 step52085 [D loss: -0.511369] [G loss: -0.192318]\n",
      "epoch6 step52090 [D loss: -0.371579] [G loss: 0.261182]\n",
      "epoch6 step52095 [D loss: -0.023016] [G loss: -0.151389]\n",
      "epoch6 step52100 [D loss: -0.264217] [G loss: -0.040003]\n",
      "epoch6 step52105 [D loss: 0.252426] [G loss: -0.216039]\n",
      "epoch6 step52110 [D loss: -0.069166] [G loss: 0.027416]\n",
      "epoch6 step52115 [D loss: 0.289724] [G loss: 0.063900]\n",
      "epoch6 step52120 [D loss: -0.251192] [G loss: 0.283255]\n",
      "epoch6 step52125 [D loss: -0.093547] [G loss: -0.120947]\n",
      "epoch6 step52130 [D loss: 0.066810] [G loss: 0.076427]\n",
      "epoch6 step52135 [D loss: -0.441779] [G loss: 0.134725]\n",
      "epoch6 step52140 [D loss: -0.329539] [G loss: -0.293002]\n",
      "epoch6 step52145 [D loss: 0.172510] [G loss: -0.161364]\n",
      "epoch6 step52150 [D loss: -0.795261] [G loss: -0.090858]\n",
      "epoch6 step52155 [D loss: -0.388965] [G loss: -0.091666]\n",
      "epoch6 step52160 [D loss: -0.035382] [G loss: -0.316255]\n",
      "epoch6 step52165 [D loss: -0.680462] [G loss: -0.178929]\n",
      "epoch6 step52170 [D loss: -0.003134] [G loss: -0.311248]\n",
      "epoch6 step52175 [D loss: -0.543330] [G loss: -0.036005]\n",
      "epoch6 step52180 [D loss: -0.855188] [G loss: -0.020027]\n",
      "epoch6 step52185 [D loss: -0.704232] [G loss: 0.054790]\n",
      "epoch6 step52190 [D loss: -0.085632] [G loss: -0.333455]\n",
      "epoch6 step52195 [D loss: -0.190944] [G loss: -0.393839]\n",
      "epoch6 step52200 [D loss: -0.400153] [G loss: -0.422372]\n",
      "epoch6 step52205 [D loss: 0.351709] [G loss: -0.518899]\n",
      "epoch6 step52210 [D loss: 0.204070] [G loss: -0.211004]\n",
      "epoch6 step52215 [D loss: -0.347672] [G loss: 0.060350]\n",
      "epoch6 step52220 [D loss: -0.240455] [G loss: 0.017589]\n",
      "epoch6 step52225 [D loss: -0.722780] [G loss: 0.119518]\n",
      "epoch6 step52230 [D loss: -0.016749] [G loss: -0.180847]\n",
      "epoch6 step52235 [D loss: 0.063128] [G loss: 0.041695]\n",
      "epoch6 step52240 [D loss: -0.350320] [G loss: 0.331305]\n",
      "epoch6 step52245 [D loss: -0.278374] [G loss: 0.312090]\n",
      "epoch6 step52250 [D loss: -0.464975] [G loss: 0.117957]\n",
      "epoch6 step52255 [D loss: -0.631456] [G loss: 0.091831]\n",
      "epoch6 step52260 [D loss: -0.052067] [G loss: 0.021253]\n",
      "epoch6 step52265 [D loss: -0.064592] [G loss: 0.270096]\n",
      "epoch6 step52270 [D loss: -0.085304] [G loss: 0.041650]\n",
      "epoch6 step52275 [D loss: -0.366051] [G loss: 0.359904]\n",
      "epoch6 step52280 [D loss: 0.296143] [G loss: 0.369955]\n",
      "epoch6 step52285 [D loss: -0.567363] [G loss: 0.308991]\n",
      "epoch6 step52290 [D loss: 0.110400] [G loss: 0.054952]\n",
      "epoch6 step52295 [D loss: -0.509277] [G loss: 0.486019]\n",
      "epoch6 step52300 [D loss: -0.323345] [G loss: 0.561099]\n",
      "epoch6 step52305 [D loss: -0.475369] [G loss: 0.373735]\n",
      "epoch6 step52310 [D loss: -0.110334] [G loss: 0.407913]\n",
      "epoch6 step52315 [D loss: -0.212396] [G loss: 0.413552]\n",
      "epoch6 step52320 [D loss: -0.050155] [G loss: 0.181640]\n",
      "epoch6 step52325 [D loss: 0.107556] [G loss: 0.455543]\n",
      "epoch6 step52330 [D loss: 0.351754] [G loss: 0.317498]\n",
      "epoch6 step52335 [D loss: -0.115010] [G loss: 0.617739]\n",
      "epoch6 step52340 [D loss: 0.062679] [G loss: 0.079218]\n",
      "epoch6 step52345 [D loss: -0.090888] [G loss: 0.210096]\n",
      "epoch6 step52350 [D loss: 0.065835] [G loss: 0.406083]\n",
      "epoch6 step52355 [D loss: -0.528722] [G loss: 0.236701]\n",
      "epoch6 step52360 [D loss: -0.490699] [G loss: 0.486355]\n",
      "epoch6 step52365 [D loss: 0.394327] [G loss: 0.337500]\n",
      "epoch6 step52370 [D loss: -0.257915] [G loss: 0.598129]\n",
      "epoch6 step52375 [D loss: -0.395613] [G loss: 0.346745]\n",
      "epoch6 step52380 [D loss: -0.608383] [G loss: -0.021861]\n",
      "epoch6 step52385 [D loss: -0.289004] [G loss: -0.128095]\n",
      "epoch6 step52390 [D loss: -0.512507] [G loss: 0.091656]\n",
      "epoch6 step52395 [D loss: -0.228759] [G loss: 0.186581]\n",
      "epoch6 step52400 [D loss: -0.390936] [G loss: -0.129238]\n",
      "epoch6 step52405 [D loss: -0.337781] [G loss: -0.310188]\n",
      "epoch6 step52410 [D loss: -0.332634] [G loss: 0.037481]\n",
      "epoch6 step52415 [D loss: 0.096068] [G loss: -0.340102]\n",
      "epoch6 step52420 [D loss: -0.303037] [G loss: 0.095830]\n",
      "epoch6 step52425 [D loss: 0.130317] [G loss: -0.529151]\n",
      "epoch6 step52430 [D loss: 0.409645] [G loss: -0.127123]\n",
      "epoch6 step52435 [D loss: 0.059367] [G loss: -0.572255]\n",
      "epoch6 step52440 [D loss: -0.078136] [G loss: -0.631044]\n",
      "epoch6 step52445 [D loss: -0.701437] [G loss: -0.022658]\n",
      "epoch6 step52450 [D loss: 0.313405] [G loss: -0.811661]\n",
      "epoch6 step52455 [D loss: 0.231276] [G loss: -0.370219]\n",
      "epoch6 step52460 [D loss: -0.556585] [G loss: -0.340878]\n",
      "epoch6 step52465 [D loss: -0.175007] [G loss: -0.338099]\n",
      "epoch6 step52470 [D loss: -0.295206] [G loss: -0.486628]\n",
      "epoch6 step52475 [D loss: -0.670719] [G loss: -0.482754]\n",
      "epoch6 step52480 [D loss: -0.034186] [G loss: 0.014959]\n",
      "epoch6 step52485 [D loss: -0.278453] [G loss: 0.015649]\n",
      "epoch6 step52490 [D loss: 0.300386] [G loss: -0.453770]\n",
      "epoch6 step52495 [D loss: -0.247531] [G loss: -0.199708]\n",
      "epoch6 step52500 [D loss: -0.437894] [G loss: -0.011699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step52505 [D loss: -0.159792] [G loss: -0.098021]\n",
      "epoch6 step52510 [D loss: 0.074234] [G loss: -0.186996]\n",
      "epoch6 step52515 [D loss: 0.115185] [G loss: 0.006506]\n",
      "epoch6 step52520 [D loss: -0.016691] [G loss: -0.041854]\n",
      "epoch6 step52525 [D loss: -0.103754] [G loss: 0.137727]\n",
      "epoch6 step52530 [D loss: 0.020959] [G loss: 0.208505]\n",
      "epoch6 step52535 [D loss: -0.347900] [G loss: 0.268659]\n",
      "epoch6 step52540 [D loss: -0.021717] [G loss: 0.217956]\n",
      "epoch6 step52545 [D loss: -0.371210] [G loss: 0.187849]\n",
      "epoch6 step52550 [D loss: 0.254448] [G loss: 0.417775]\n",
      "epoch6 step52555 [D loss: -0.664030] [G loss: 0.701608]\n",
      "epoch6 step52560 [D loss: -0.267176] [G loss: 0.236009]\n",
      "epoch6 step52565 [D loss: -0.146424] [G loss: 0.519585]\n",
      "epoch6 step52570 [D loss: -0.405721] [G loss: 0.290412]\n",
      "epoch6 step52575 [D loss: -0.060911] [G loss: 0.780887]\n",
      "epoch6 step52580 [D loss: -0.318657] [G loss: -0.034538]\n",
      "epoch6 step52585 [D loss: -0.323166] [G loss: -0.005375]\n",
      "epoch6 step52590 [D loss: 0.083745] [G loss: 0.343559]\n",
      "epoch6 step52595 [D loss: -0.168949] [G loss: 0.204657]\n",
      "epoch6 step52600 [D loss: -0.102672] [G loss: 0.275217]\n",
      "epoch6 step52605 [D loss: -0.217248] [G loss: -0.070912]\n",
      "epoch6 step52610 [D loss: -0.261488] [G loss: -0.160104]\n",
      "epoch6 step52615 [D loss: -0.124224] [G loss: 0.024662]\n",
      "epoch6 step52620 [D loss: 0.148398] [G loss: 0.228825]\n",
      "epoch6 step52625 [D loss: 0.332054] [G loss: -0.061105]\n",
      "epoch6 step52630 [D loss: 0.077501] [G loss: 0.234442]\n",
      "epoch6 step52635 [D loss: -0.352019] [G loss: 0.282114]\n",
      "epoch6 step52640 [D loss: 0.018835] [G loss: 0.047533]\n",
      "epoch6 step52645 [D loss: -0.054120] [G loss: 0.019243]\n",
      "epoch6 step52650 [D loss: 0.069609] [G loss: -0.116365]\n",
      "epoch6 step52655 [D loss: -0.036565] [G loss: 0.030898]\n",
      "epoch6 step52660 [D loss: -0.356895] [G loss: -0.294106]\n",
      "epoch6 step52665 [D loss: -0.210458] [G loss: -0.129922]\n",
      "epoch6 step52670 [D loss: 0.104139] [G loss: -0.173377]\n",
      "epoch6 step52675 [D loss: -0.316311] [G loss: -0.454137]\n",
      "epoch6 step52680 [D loss: -0.329253] [G loss: -0.139762]\n",
      "epoch6 step52685 [D loss: -0.136724] [G loss: -0.315573]\n",
      "epoch6 step52690 [D loss: -0.322625] [G loss: -0.049726]\n",
      "epoch6 step52695 [D loss: -0.242826] [G loss: -0.362875]\n",
      "epoch6 step52700 [D loss: 0.034362] [G loss: -0.491145]\n",
      "epoch6 step52705 [D loss: 0.556799] [G loss: -0.563055]\n",
      "epoch6 step52710 [D loss: -0.689953] [G loss: -0.430319]\n",
      "epoch6 step52715 [D loss: -0.156374] [G loss: -0.587005]\n",
      "epoch6 step52720 [D loss: -0.710265] [G loss: -0.386745]\n",
      "epoch6 step52725 [D loss: 0.285779] [G loss: -0.175456]\n",
      "epoch6 step52730 [D loss: -0.296092] [G loss: -0.541970]\n",
      "epoch6 step52735 [D loss: -0.112873] [G loss: -0.598703]\n",
      "epoch6 step52740 [D loss: -0.056893] [G loss: -0.570164]\n",
      "epoch6 step52745 [D loss: 0.249063] [G loss: -0.577778]\n",
      "epoch6 step52750 [D loss: -0.136612] [G loss: -0.368839]\n",
      "epoch6 step52755 [D loss: 0.012073] [G loss: -0.568187]\n",
      "epoch6 step52760 [D loss: 0.088674] [G loss: -0.061222]\n",
      "epoch6 step52765 [D loss: -0.250566] [G loss: -0.249154]\n",
      "epoch6 step52770 [D loss: -0.020808] [G loss: -0.388692]\n",
      "epoch6 step52775 [D loss: 0.057078] [G loss: -0.127445]\n",
      "epoch6 step52780 [D loss: -0.110734] [G loss: 0.048033]\n",
      "epoch6 step52785 [D loss: -0.680003] [G loss: -0.050288]\n",
      "epoch6 step52790 [D loss: -0.019893] [G loss: -0.372478]\n",
      "epoch6 step52795 [D loss: -0.279710] [G loss: 0.099999]\n",
      "epoch6 step52800 [D loss: 0.357292] [G loss: 0.371437]\n",
      "epoch6 step52805 [D loss: 0.336921] [G loss: 0.302038]\n",
      "epoch6 step52810 [D loss: -0.743342] [G loss: 0.506605]\n",
      "epoch6 step52815 [D loss: -0.476042] [G loss: 0.277933]\n",
      "epoch6 step52820 [D loss: 0.143457] [G loss: 0.294985]\n",
      "epoch6 step52825 [D loss: 0.182848] [G loss: -0.182869]\n",
      "epoch6 step52830 [D loss: -0.117817] [G loss: 0.117423]\n",
      "epoch6 step52835 [D loss: -0.566734] [G loss: 0.197724]\n",
      "epoch6 step52840 [D loss: 0.071390] [G loss: -0.370560]\n",
      "epoch6 step52845 [D loss: 0.208714] [G loss: -0.002815]\n",
      "epoch6 step52850 [D loss: -0.129863] [G loss: -0.256166]\n",
      "epoch6 step52855 [D loss: -0.515357] [G loss: 0.018744]\n",
      "epoch6 step52860 [D loss: 0.027069] [G loss: -0.154567]\n",
      "epoch6 step52865 [D loss: 0.252144] [G loss: -0.448946]\n",
      "epoch6 step52870 [D loss: -0.484105] [G loss: -0.038392]\n",
      "epoch6 step52875 [D loss: -0.181719] [G loss: 0.045630]\n",
      "epoch6 step52880 [D loss: 0.307599] [G loss: -0.267233]\n",
      "epoch6 step52885 [D loss: 0.134037] [G loss: -0.191438]\n",
      "epoch6 step52890 [D loss: -0.118051] [G loss: -0.191410]\n",
      "epoch6 step52895 [D loss: 0.105152] [G loss: -0.204949]\n",
      "epoch6 step52900 [D loss: -0.512134] [G loss: -0.565770]\n",
      "epoch6 step52905 [D loss: -0.422310] [G loss: -0.259023]\n",
      "epoch6 step52910 [D loss: 0.033673] [G loss: -0.376349]\n",
      "epoch6 step52915 [D loss: -0.504364] [G loss: -0.619725]\n",
      "epoch6 step52920 [D loss: -0.053179] [G loss: -0.126143]\n",
      "epoch6 step52925 [D loss: -0.217136] [G loss: -0.111846]\n",
      "epoch6 step52930 [D loss: -0.251331] [G loss: -0.511457]\n",
      "epoch6 step52935 [D loss: -0.303620] [G loss: -0.256226]\n",
      "epoch6 step52940 [D loss: -0.207518] [G loss: -0.694455]\n",
      "epoch6 step52945 [D loss: -0.717873] [G loss: -0.005295]\n",
      "epoch6 step52950 [D loss: 0.162952] [G loss: -0.127425]\n",
      "epoch6 step52955 [D loss: 0.406965] [G loss: -0.371254]\n",
      "epoch6 step52960 [D loss: -0.566592] [G loss: -0.085540]\n",
      "epoch6 step52965 [D loss: -0.199860] [G loss: -0.440116]\n",
      "epoch6 step52970 [D loss: -0.061203] [G loss: -0.242168]\n",
      "epoch6 step52975 [D loss: -0.521251] [G loss: -0.203594]\n",
      "epoch6 step52980 [D loss: 0.135009] [G loss: -0.447742]\n",
      "epoch6 step52985 [D loss: -0.271446] [G loss: -0.196539]\n",
      "epoch6 step52990 [D loss: 0.172801] [G loss: -0.561120]\n",
      "epoch6 step52995 [D loss: -0.408629] [G loss: -0.253693]\n",
      "epoch6 step53000 [D loss: -0.220173] [G loss: -0.549423]\n",
      "epoch6 step53005 [D loss: -0.274013] [G loss: -0.377679]\n",
      "epoch6 step53010 [D loss: -0.271605] [G loss: -0.472546]\n",
      "epoch6 step53015 [D loss: -0.089060] [G loss: -0.675510]\n",
      "epoch6 step53020 [D loss: 0.470913] [G loss: -0.674039]\n",
      "epoch6 step53025 [D loss: -0.186638] [G loss: -0.377051]\n",
      "epoch6 step53030 [D loss: 0.312402] [G loss: -0.781908]\n",
      "epoch6 step53035 [D loss: -0.170682] [G loss: -0.400327]\n",
      "epoch6 step53040 [D loss: -0.230977] [G loss: -0.429621]\n",
      "epoch6 step53045 [D loss: 0.144556] [G loss: -0.626571]\n",
      "epoch6 step53050 [D loss: 0.397637] [G loss: -0.390475]\n",
      "epoch6 step53055 [D loss: -0.125217] [G loss: -0.379803]\n",
      "epoch6 step53060 [D loss: 0.034795] [G loss: 0.011009]\n",
      "epoch6 step53065 [D loss: -0.408042] [G loss: -0.336123]\n",
      "epoch6 step53070 [D loss: 0.021803] [G loss: -0.025659]\n",
      "epoch6 step53075 [D loss: -0.231856] [G loss: -0.225214]\n",
      "epoch6 step53080 [D loss: -0.045692] [G loss: 0.205897]\n",
      "epoch6 step53085 [D loss: -0.565862] [G loss: -0.143376]\n",
      "epoch6 step53090 [D loss: 0.077451] [G loss: -0.451030]\n",
      "epoch6 step53095 [D loss: 0.021988] [G loss: -0.094968]\n",
      "epoch6 step53100 [D loss: 0.080516] [G loss: -0.381025]\n",
      "epoch6 step53105 [D loss: -0.085119] [G loss: -0.332780]\n",
      "epoch6 step53110 [D loss: 0.130887] [G loss: 0.128547]\n",
      "epoch6 step53115 [D loss: -0.040480] [G loss: 0.482515]\n",
      "epoch6 step53120 [D loss: -0.739577] [G loss: 0.106534]\n",
      "epoch6 step53125 [D loss: 0.319870] [G loss: 0.031985]\n",
      "epoch6 step53130 [D loss: -0.052121] [G loss: 0.161995]\n",
      "epoch6 step53135 [D loss: -0.249110] [G loss: 0.144359]\n",
      "epoch6 step53140 [D loss: -0.605692] [G loss: 0.213401]\n",
      "epoch6 step53145 [D loss: 0.179337] [G loss: -0.038492]\n",
      "epoch6 step53150 [D loss: -0.282594] [G loss: 0.560406]\n",
      "epoch6 step53155 [D loss: 0.113095] [G loss: 0.119198]\n",
      "epoch6 step53160 [D loss: -0.174622] [G loss: 0.333578]\n",
      "epoch6 step53165 [D loss: 0.063377] [G loss: -0.013560]\n",
      "epoch6 step53170 [D loss: -0.305406] [G loss: -0.072419]\n",
      "epoch6 step53175 [D loss: 0.124548] [G loss: 0.198135]\n",
      "epoch6 step53180 [D loss: -0.110602] [G loss: 0.213643]\n",
      "epoch6 step53185 [D loss: -0.234741] [G loss: 0.031644]\n",
      "epoch6 step53190 [D loss: 0.275483] [G loss: 0.226716]\n",
      "epoch6 step53195 [D loss: -0.147237] [G loss: 0.186158]\n",
      "epoch6 step53200 [D loss: -0.103256] [G loss: 0.009048]\n",
      "epoch6 step53205 [D loss: 0.042599] [G loss: 0.291151]\n",
      "epoch6 step53210 [D loss: -0.517462] [G loss: 0.404530]\n",
      "epoch6 step53215 [D loss: -0.557583] [G loss: 0.047090]\n",
      "epoch6 step53220 [D loss: -0.409321] [G loss: -0.104288]\n",
      "epoch6 step53225 [D loss: 0.070589] [G loss: 0.354997]\n",
      "epoch6 step53230 [D loss: -0.152520] [G loss: 0.033960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step53235 [D loss: -0.367113] [G loss: 0.115901]\n",
      "epoch6 step53240 [D loss: 0.066437] [G loss: 0.144819]\n",
      "epoch6 step53245 [D loss: 0.204992] [G loss: -0.086782]\n",
      "epoch6 step53250 [D loss: 0.237090] [G loss: -0.222779]\n",
      "epoch6 step53255 [D loss: -0.150907] [G loss: -0.191344]\n",
      "epoch6 step53260 [D loss: -0.127620] [G loss: -0.107094]\n",
      "epoch6 step53265 [D loss: 0.139560] [G loss: -0.375728]\n",
      "epoch6 step53270 [D loss: -0.254745] [G loss: -0.234177]\n",
      "epoch6 step53275 [D loss: -0.129311] [G loss: -0.410437]\n",
      "epoch6 step53280 [D loss: -0.104690] [G loss: -0.687767]\n",
      "epoch6 step53285 [D loss: 0.302514] [G loss: -0.261321]\n",
      "epoch6 step53290 [D loss: 0.102494] [G loss: -0.572169]\n",
      "epoch6 step53295 [D loss: 0.282297] [G loss: -0.519404]\n",
      "epoch6 step53300 [D loss: -0.330400] [G loss: -0.338257]\n",
      "epoch6 step53305 [D loss: -0.013447] [G loss: -0.479991]\n",
      "epoch6 step53310 [D loss: -0.549497] [G loss: -0.361632]\n",
      "epoch6 step53315 [D loss: -0.237294] [G loss: -0.454892]\n",
      "epoch6 step53320 [D loss: -0.628250] [G loss: -0.265012]\n",
      "epoch6 step53325 [D loss: -0.178484] [G loss: -0.348468]\n",
      "epoch6 step53330 [D loss: -0.190953] [G loss: -0.528107]\n",
      "epoch6 step53335 [D loss: -0.311431] [G loss: -0.257648]\n",
      "epoch6 step53340 [D loss: 0.238795] [G loss: -0.346162]\n",
      "epoch6 step53345 [D loss: -0.274724] [G loss: -0.240344]\n",
      "epoch6 step53350 [D loss: -0.387772] [G loss: -0.522321]\n",
      "epoch6 step53355 [D loss: 0.004895] [G loss: -0.359538]\n",
      "epoch6 step53360 [D loss: -0.434053] [G loss: -0.148137]\n",
      "epoch6 step53365 [D loss: -0.028981] [G loss: -0.072459]\n",
      "epoch6 step53370 [D loss: -0.123475] [G loss: -0.039181]\n",
      "epoch6 step53375 [D loss: -0.341790] [G loss: -0.159701]\n",
      "epoch6 step53380 [D loss: 0.170265] [G loss: -0.299688]\n",
      "epoch6 step53385 [D loss: -0.142680] [G loss: -0.181287]\n",
      "epoch6 step53390 [D loss: -0.142660] [G loss: -0.293131]\n",
      "epoch6 step53395 [D loss: -0.416860] [G loss: 0.029455]\n",
      "epoch6 step53400 [D loss: 0.289892] [G loss: -0.202812]\n",
      "epoch6 step53405 [D loss: -0.360739] [G loss: 0.210748]\n",
      "epoch6 step53410 [D loss: -0.763609] [G loss: 0.342507]\n",
      "epoch6 step53415 [D loss: 0.074817] [G loss: 0.092240]\n",
      "epoch6 step53420 [D loss: -0.127385] [G loss: 0.271587]\n",
      "epoch6 step53425 [D loss: 0.142744] [G loss: 0.193661]\n",
      "epoch6 step53430 [D loss: -0.291350] [G loss: 0.232248]\n",
      "epoch6 step53435 [D loss: 0.025390] [G loss: -0.076581]\n",
      "epoch6 step53440 [D loss: -0.106068] [G loss: 0.303770]\n",
      "epoch6 step53445 [D loss: -0.096814] [G loss: 0.249394]\n",
      "epoch6 step53450 [D loss: -0.245083] [G loss: 0.100718]\n",
      "epoch6 step53455 [D loss: -0.174794] [G loss: 0.302157]\n",
      "epoch6 step53460 [D loss: -0.354814] [G loss: -0.267029]\n",
      "epoch6 step53465 [D loss: -0.131809] [G loss: -0.273339]\n",
      "epoch6 step53470 [D loss: 0.004695] [G loss: 0.167669]\n",
      "epoch6 step53475 [D loss: -0.435573] [G loss: 0.125808]\n",
      "epoch6 step53480 [D loss: -0.259337] [G loss: -0.216765]\n",
      "epoch6 step53485 [D loss: 0.195536] [G loss: -0.089788]\n",
      "epoch6 step53490 [D loss: -0.177597] [G loss: -0.185613]\n",
      "epoch6 step53495 [D loss: 0.031021] [G loss: -0.052411]\n",
      "epoch6 step53500 [D loss: -0.149144] [G loss: 0.108220]\n",
      "epoch6 step53505 [D loss: -0.308153] [G loss: 0.058221]\n",
      "epoch6 step53510 [D loss: -0.054770] [G loss: 0.084329]\n",
      "epoch6 step53515 [D loss: -0.266424] [G loss: 0.234412]\n",
      "epoch6 step53520 [D loss: -0.148788] [G loss: 0.220353]\n",
      "epoch6 step53525 [D loss: -0.701247] [G loss: 0.236605]\n",
      "epoch6 step53530 [D loss: -0.048101] [G loss: -0.238114]\n",
      "epoch6 step53535 [D loss: -0.370216] [G loss: -0.206577]\n",
      "epoch6 step53540 [D loss: -0.259375] [G loss: -0.174363]\n",
      "epoch6 step53545 [D loss: 0.081380] [G loss: -0.109511]\n",
      "epoch6 step53550 [D loss: -0.131334] [G loss: -0.193802]\n",
      "epoch6 step53555 [D loss: -0.136644] [G loss: -0.242726]\n",
      "epoch6 step53560 [D loss: -0.409337] [G loss: 0.081183]\n",
      "epoch6 step53565 [D loss: -0.146129] [G loss: -0.762636]\n",
      "epoch6 step53570 [D loss: 0.122649] [G loss: -0.132881]\n",
      "epoch6 step53575 [D loss: 0.127545] [G loss: -0.406535]\n",
      "epoch6 step53580 [D loss: -0.291392] [G loss: 0.103421]\n",
      "epoch6 step53585 [D loss: -0.262065] [G loss: -0.068145]\n",
      "epoch6 step53590 [D loss: 0.203415] [G loss: -0.556059]\n",
      "epoch6 step53595 [D loss: -0.073132] [G loss: -0.382040]\n",
      "epoch6 step53600 [D loss: -0.167926] [G loss: -0.322788]\n",
      "epoch6 step53605 [D loss: -0.959794] [G loss: -0.700770]\n",
      "epoch6 step53610 [D loss: -0.547219] [G loss: -0.109189]\n",
      "epoch6 step53615 [D loss: -0.095139] [G loss: -0.348290]\n",
      "epoch6 step53620 [D loss: -0.612421] [G loss: -0.483691]\n",
      "epoch6 step53625 [D loss: 0.210140] [G loss: -0.388333]\n",
      "epoch6 step53630 [D loss: -0.428177] [G loss: -0.308993]\n",
      "epoch6 step53635 [D loss: 0.234167] [G loss: -0.526622]\n",
      "epoch6 step53640 [D loss: -0.358831] [G loss: -0.475212]\n",
      "epoch6 step53645 [D loss: -0.594799] [G loss: -0.347751]\n",
      "epoch6 step53650 [D loss: 0.282615] [G loss: -0.439732]\n",
      "epoch6 step53655 [D loss: -0.056830] [G loss: -0.266574]\n",
      "epoch6 step53660 [D loss: -0.270431] [G loss: -0.261241]\n",
      "epoch6 step53665 [D loss: -0.677692] [G loss: -0.000061]\n",
      "epoch6 step53670 [D loss: -0.144652] [G loss: -0.387666]\n",
      "epoch6 step53675 [D loss: -0.382167] [G loss: -0.588764]\n",
      "epoch6 step53680 [D loss: -0.453371] [G loss: -0.460359]\n",
      "epoch6 step53685 [D loss: -0.067960] [G loss: -0.258313]\n",
      "epoch6 step53690 [D loss: -0.140407] [G loss: -0.190929]\n",
      "epoch6 step53695 [D loss: 0.065900] [G loss: -0.022787]\n",
      "epoch6 step53700 [D loss: -0.511456] [G loss: -0.160701]\n",
      "epoch6 step53705 [D loss: 0.020523] [G loss: 0.186007]\n",
      "epoch6 step53710 [D loss: -0.024793] [G loss: 0.199264]\n",
      "epoch6 step53715 [D loss: -0.394760] [G loss: 0.084953]\n",
      "epoch6 step53720 [D loss: -0.144933] [G loss: -0.207630]\n",
      "epoch6 step53725 [D loss: 0.178312] [G loss: -0.291991]\n",
      "epoch6 step53730 [D loss: -0.421411] [G loss: -0.016264]\n",
      "epoch6 step53735 [D loss: -0.039195] [G loss: -0.455515]\n",
      "epoch6 step53740 [D loss: -0.074814] [G loss: -0.105041]\n",
      "epoch6 step53745 [D loss: -0.094115] [G loss: 0.027246]\n",
      "epoch6 step53750 [D loss: -0.168532] [G loss: -0.032517]\n",
      "epoch6 step53755 [D loss: 0.362659] [G loss: -0.090518]\n",
      "epoch6 step53760 [D loss: -0.499746] [G loss: -0.153270]\n",
      "epoch6 step53765 [D loss: -0.206685] [G loss: -0.028003]\n",
      "epoch6 step53770 [D loss: -0.541934] [G loss: -0.207853]\n",
      "epoch6 step53775 [D loss: 0.152324] [G loss: -0.289639]\n",
      "epoch6 step53780 [D loss: -0.303021] [G loss: -0.183390]\n",
      "epoch6 step53785 [D loss: -0.216051] [G loss: -0.058274]\n",
      "epoch6 step53790 [D loss: 0.011433] [G loss: -0.070784]\n",
      "epoch6 step53795 [D loss: -0.031750] [G loss: -0.337639]\n",
      "epoch6 step53800 [D loss: -0.494632] [G loss: -0.202476]\n",
      "epoch6 step53805 [D loss: -0.328723] [G loss: -0.381157]\n",
      "epoch6 step53810 [D loss: -0.380528] [G loss: -0.009847]\n",
      "epoch6 step53815 [D loss: -0.664804] [G loss: 0.113709]\n",
      "epoch6 step53820 [D loss: 0.046893] [G loss: -0.157640]\n",
      "epoch6 step53825 [D loss: 0.143529] [G loss: -0.491743]\n",
      "epoch6 step53830 [D loss: 0.418205] [G loss: -0.734925]\n",
      "epoch6 step53835 [D loss: -0.081276] [G loss: -0.371612]\n",
      "epoch6 step53840 [D loss: -0.445313] [G loss: -0.444717]\n",
      "epoch6 step53845 [D loss: -0.212252] [G loss: -0.320387]\n",
      "epoch6 step53850 [D loss: -0.308300] [G loss: -0.366426]\n",
      "epoch6 step53855 [D loss: -0.476078] [G loss: -0.502167]\n",
      "epoch6 step53860 [D loss: -0.050071] [G loss: -0.455326]\n",
      "epoch6 step53865 [D loss: -0.645037] [G loss: -0.412008]\n",
      "epoch6 step53870 [D loss: -0.507084] [G loss: -0.461932]\n",
      "epoch6 step53875 [D loss: -0.421699] [G loss: -0.794734]\n",
      "epoch6 step53880 [D loss: 0.277901] [G loss: -0.726659]\n",
      "epoch6 step53885 [D loss: -0.073765] [G loss: -0.871346]\n",
      "epoch6 step53890 [D loss: -0.634530] [G loss: -0.429988]\n",
      "epoch6 step53895 [D loss: 0.133003] [G loss: -1.124620]\n",
      "epoch6 step53900 [D loss: -0.145405] [G loss: -0.606688]\n",
      "epoch6 step53905 [D loss: -0.246526] [G loss: -0.880822]\n",
      "epoch6 step53910 [D loss: 0.050573] [G loss: -0.755633]\n",
      "epoch6 step53915 [D loss: 0.339844] [G loss: -0.655111]\n",
      "epoch6 step53920 [D loss: 0.271673] [G loss: -0.512448]\n",
      "epoch6 step53925 [D loss: -0.111635] [G loss: -0.266210]\n",
      "epoch6 step53930 [D loss: -0.437843] [G loss: -0.447219]\n",
      "epoch6 step53935 [D loss: -0.087321] [G loss: -0.695606]\n",
      "epoch6 step53940 [D loss: -0.276908] [G loss: -0.456670]\n",
      "epoch6 step53945 [D loss: -0.112202] [G loss: -0.397388]\n",
      "epoch6 step53950 [D loss: 0.063986] [G loss: -0.565125]\n",
      "epoch6 step53955 [D loss: -0.233968] [G loss: -0.049466]\n",
      "epoch6 step53960 [D loss: -0.142422] [G loss: -0.184998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6 step53965 [D loss: -0.215966] [G loss: -0.478110]\n",
      "epoch6 step53970 [D loss: -0.331831] [G loss: -0.106371]\n",
      "epoch6 step53975 [D loss: -0.397005] [G loss: -0.175412]\n",
      "epoch6 step53980 [D loss: -0.151459] [G loss: -0.204535]\n",
      "epoch6 step53985 [D loss: 0.005885] [G loss: -0.112458]\n",
      "epoch6 step53990 [D loss: -0.107443] [G loss: -0.147929]\n",
      "epoch6 step53995 [D loss: -0.490902] [G loss: 0.336100]\n",
      "epoch6 step54000 [D loss: -0.299913] [G loss: -0.038919]\n",
      "epoch6 step54005 [D loss: -0.286231] [G loss: 0.114229]\n",
      "epoch6 step54010 [D loss: -0.335383] [G loss: -0.083915]\n",
      "epoch6 step54015 [D loss: -0.164377] [G loss: 0.055166]\n",
      "epoch6 step54020 [D loss: -0.206825] [G loss: 0.181154]\n",
      "epoch6 step54025 [D loss: -0.628251] [G loss: 0.066541]\n",
      "epoch6 step54030 [D loss: -0.347188] [G loss: -0.045353]\n",
      "epoch6 step54035 [D loss: -0.483172] [G loss: -0.066660]\n",
      "epoch6 step54040 [D loss: -0.157621] [G loss: 0.273695]\n",
      "epoch6 step54045 [D loss: -0.860815] [G loss: 0.390281]\n",
      "epoch6 step54050 [D loss: -0.126087] [G loss: 0.139819]\n",
      "epoch6 step54055 [D loss: -0.363778] [G loss: 0.756140]\n",
      "epoch6 step54060 [D loss: -0.027003] [G loss: 0.321788]\n",
      "epoch6 step54065 [D loss: -0.442041] [G loss: 0.298106]\n",
      "epoch6 step54070 [D loss: -0.454977] [G loss: 0.136155]\n",
      "epoch6 step54075 [D loss: 0.068659] [G loss: 0.119835]\n",
      "epoch6 step54080 [D loss: -0.237781] [G loss: -0.007450]\n",
      "epoch6 step54085 [D loss: 0.170037] [G loss: 0.268013]\n",
      "epoch6 step54090 [D loss: -0.143663] [G loss: -0.034188]\n",
      "epoch6 step54095 [D loss: -0.385771] [G loss: 0.076088]\n",
      "epoch6 step54100 [D loss: 0.060968] [G loss: 0.274920]\n",
      "epoch6 step54105 [D loss: -0.120036] [G loss: 0.286949]\n",
      "epoch6 step54110 [D loss: -0.382239] [G loss: 0.178785]\n",
      "epoch6 step54115 [D loss: -0.148048] [G loss: 0.032426]\n",
      "epoch6 step54120 [D loss: -0.216829] [G loss: 0.385036]\n",
      "epoch6 step54125 [D loss: -0.059968] [G loss: -0.300606]\n",
      "epoch6 step54130 [D loss: 0.193021] [G loss: 0.253370]\n",
      "epoch6 step54135 [D loss: -0.170312] [G loss: -0.061810]\n",
      "epoch6 step54140 [D loss: -0.161740] [G loss: 0.368854]\n",
      "epoch6 step54145 [D loss: -0.047211] [G loss: 0.105193]\n",
      "epoch6 step54150 [D loss: -0.309735] [G loss: -0.122162]\n",
      "epoch6 step54155 [D loss: -0.122654] [G loss: 0.358966]\n",
      "epoch6 step54160 [D loss: -0.362003] [G loss: 0.127356]\n",
      "epoch6 step54165 [D loss: -0.558942] [G loss: 0.193402]\n",
      "epoch6 step54170 [D loss: -0.251630] [G loss: 0.265631]\n",
      "epoch6 step54175 [D loss: -0.161367] [G loss: -0.009644]\n",
      "epoch6 step54180 [D loss: 0.109640] [G loss: -0.178364]\n",
      "epoch6 step54185 [D loss: -0.047079] [G loss: -0.348406]\n",
      "epoch6 step54190 [D loss: -0.364216] [G loss: 0.072593]\n",
      "epoch6 step54195 [D loss: -0.084280] [G loss: -0.238424]\n",
      "epoch6 step54200 [D loss: -0.073230] [G loss: -0.356044]\n",
      "epoch6 step54205 [D loss: -0.048897] [G loss: -0.113169]\n",
      "epoch6 step54210 [D loss: -0.117640] [G loss: -0.067504]\n",
      "epoch6 step54215 [D loss: 0.162320] [G loss: -0.272095]\n",
      "epoch6 step54220 [D loss: -0.031445] [G loss: 0.083574]\n",
      "epoch6 step54225 [D loss: 0.043971] [G loss: -0.089847]\n",
      "epoch6 step54230 [D loss: -0.124508] [G loss: -0.099417]\n",
      "epoch6 step54235 [D loss: -0.048837] [G loss: -0.420927]\n",
      "epoch6 step54240 [D loss: -0.094473] [G loss: -0.043470]\n",
      "epoch6 step54245 [D loss: -0.266375] [G loss: -0.064242]\n",
      "epoch6 step54250 [D loss: -0.515594] [G loss: -0.198234]\n",
      "epoch6 step54255 [D loss: 0.061129] [G loss: 0.026668]\n",
      "epoch6 step54260 [D loss: 0.015071] [G loss: 0.160864]\n",
      "epoch6 step54265 [D loss: -0.299755] [G loss: 0.363396]\n",
      "epoch6 step54270 [D loss: 0.345648] [G loss: -0.043407]\n",
      "epoch6 step54275 [D loss: -0.219240] [G loss: 0.255388]\n",
      "epoch6 step54280 [D loss: -0.064691] [G loss: -0.225490]\n",
      "epoch6 step54285 [D loss: -0.551749] [G loss: 0.186174]\n",
      "epoch6 step54290 [D loss: 0.072198] [G loss: -0.242515]\n",
      "epoch6 step54295 [D loss: -0.030767] [G loss: -0.140841]\n",
      "epoch6 step54300 [D loss: 0.225492] [G loss: -0.013582]\n",
      "epoch6 step54305 [D loss: -0.122866] [G loss: 0.001765]\n",
      "epoch6 step54310 [D loss: -0.615518] [G loss: 0.058457]\n",
      "epoch6 step54315 [D loss: -0.115727] [G loss: 0.046142]\n",
      "epoch6 step54320 [D loss: -0.271527] [G loss: -0.302036]\n",
      "epoch6 step54325 [D loss: 0.030249] [G loss: -0.106102]\n",
      "epoch6 step54330 [D loss: 0.172314] [G loss: -0.043058]\n",
      "epoch6 step54335 [D loss: 0.171720] [G loss: -0.245708]\n",
      "epoch6 step54340 [D loss: 0.029628] [G loss: -0.113601]\n",
      "epoch6 step54345 [D loss: -0.230831] [G loss: 0.286041]\n",
      "epoch6 step54350 [D loss: 0.216058] [G loss: 0.089087]\n",
      "epoch6 step54355 [D loss: 0.021047] [G loss: 0.390795]\n",
      "epoch6 step54360 [D loss: 0.107535] [G loss: 0.344084]\n",
      "epoch6 step54365 [D loss: -0.317843] [G loss: 0.237627]\n",
      "epoch6 step54370 [D loss: -0.210439] [G loss: 0.433196]\n",
      "epoch6 step54375 [D loss: -0.497409] [G loss: -0.012556]\n",
      "epoch6 step54380 [D loss: -0.116377] [G loss: 0.246519]\n",
      "epoch6 step54385 [D loss: 0.396281] [G loss: 0.047562]\n",
      "epoch6 step54390 [D loss: 0.305314] [G loss: 0.035748]\n",
      "epoch6 step54395 [D loss: -0.314789] [G loss: 0.399847]\n",
      "epoch6 step54400 [D loss: 0.044789] [G loss: 0.048342]\n",
      "epoch6 step54405 [D loss: 0.346947] [G loss: 0.161056]\n",
      "epoch6 step54410 [D loss: 0.078792] [G loss: -0.011487]\n",
      "epoch6 step54415 [D loss: -0.511299] [G loss: 0.452886]\n",
      "epoch6 step54420 [D loss: -0.299260] [G loss: 0.033852]\n",
      "epoch6 step54425 [D loss: -0.364752] [G loss: 0.069327]\n",
      "epoch6 step54430 [D loss: -0.253449] [G loss: 0.246856]\n",
      "epoch6 step54435 [D loss: -0.121745] [G loss: -0.251106]\n",
      "epoch6 step54440 [D loss: -0.180925] [G loss: -0.209678]\n",
      "epoch6 step54445 [D loss: -0.040309] [G loss: -0.329106]\n",
      "epoch6 step54450 [D loss: 0.245976] [G loss: -0.236730]\n",
      "epoch6 step54455 [D loss: -0.120749] [G loss: -0.299297]\n",
      "epoch6 step54460 [D loss: -0.271167] [G loss: -0.431078]\n",
      "epoch6 step54465 [D loss: 0.202080] [G loss: -0.215305]\n",
      "epoch6 step54470 [D loss: -0.268105] [G loss: -0.418134]\n",
      "epoch6 step54475 [D loss: -0.482812] [G loss: -0.382755]\n",
      "epoch6 step54480 [D loss: 0.579047] [G loss: -0.586761]\n",
      "epoch6 step54485 [D loss: -0.385735] [G loss: -0.349704]\n",
      "epoch6 step54490 [D loss: 0.179387] [G loss: -0.899452]\n",
      "epoch6 step54495 [D loss: -0.177604] [G loss: -0.579558]\n",
      "epoch6 step54500 [D loss: -0.561407] [G loss: -0.234797]\n",
      "epoch6 step54505 [D loss: 0.261284] [G loss: -0.967744]\n",
      "epoch6 step54510 [D loss: 0.145157] [G loss: -0.408996]\n",
      "epoch6 step54515 [D loss: -0.190956] [G loss: -0.707043]\n",
      "epoch6 step54520 [D loss: -0.279456] [G loss: -0.435366]\n",
      "epoch6 step54525 [D loss: 0.124027] [G loss: -0.594920]\n",
      "epoch6 step54530 [D loss: -0.316509] [G loss: -0.143327]\n",
      "epoch6 step54535 [D loss: -0.467008] [G loss: 0.295795]\n",
      "epoch6 step54540 [D loss: 0.228342] [G loss: -0.409820]\n",
      "epoch6 step54545 [D loss: -0.194075] [G loss: -0.273276]\n",
      "epoch6 step54550 [D loss: -0.687319] [G loss: -0.177296]\n",
      "epoch6 step54555 [D loss: 0.079704] [G loss: -0.452320]\n",
      "epoch6 step54560 [D loss: -0.651987] [G loss: -0.262544]\n",
      "epoch6 step54565 [D loss: 0.077320] [G loss: -0.171881]\n",
      "epoch6 step54570 [D loss: -0.277160] [G loss: -0.256479]\n",
      "epoch6 step54575 [D loss: -0.069934] [G loss: -0.096483]\n",
      "epoch6 step54580 [D loss: -0.324224] [G loss: 0.244836]\n",
      "epoch6 step54585 [D loss: -0.303517] [G loss: -0.148055]\n",
      "epoch6 step54590 [D loss: 0.189673] [G loss: -0.284995]\n",
      "epoch6 step54595 [D loss: -0.194107] [G loss: 0.123715]\n",
      "epoch6 step54600 [D loss: -0.554080] [G loss: 0.275717]\n",
      "epoch6 step54605 [D loss: -0.451887] [G loss: 0.222636]\n",
      "epoch6 step54610 [D loss: -0.069855] [G loss: -0.024466]\n",
      "epoch6 step54615 [D loss: -0.391758] [G loss: 0.351543]\n",
      "epoch6 step54620 [D loss: -0.168070] [G loss: 0.306075]\n",
      "epoch6 step54625 [D loss: -0.084848] [G loss: 0.041854]\n",
      "epoch6 step54630 [D loss: -0.076378] [G loss: 0.410799]\n",
      "epoch6 step54635 [D loss: 0.001461] [G loss: 0.048912]\n",
      "epoch6 step54640 [D loss: -0.202681] [G loss: 0.066849]\n",
      "epoch6 step54645 [D loss: 0.091483] [G loss: 0.146763]\n",
      "epoch6 step54650 [D loss: -0.226776] [G loss: 0.098600]\n",
      "epoch6 step54655 [D loss: -0.044808] [G loss: 0.083952]\n",
      "epoch6 step54660 [D loss: -0.450445] [G loss: 0.374764]\n",
      "epoch6 step54665 [D loss: -0.415442] [G loss: 0.012570]\n",
      "epoch6 step54670 [D loss: -0.427323] [G loss: 0.420599]\n",
      "epoch7 step54675 [D loss: -0.418901] [G loss: 0.035141]\n",
      "epoch7 step54680 [D loss: 0.351431] [G loss: 0.023689]\n",
      "epoch7 step54685 [D loss: -0.060737] [G loss: 0.468709]\n",
      "epoch7 step54690 [D loss: -0.191823] [G loss: 0.525467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step54695 [D loss: -0.045550] [G loss: 0.132260]\n",
      "epoch7 step54700 [D loss: 0.073926] [G loss: 0.387048]\n",
      "epoch7 step54705 [D loss: -0.660483] [G loss: 0.398366]\n",
      "epoch7 step54710 [D loss: -0.243869] [G loss: 0.223790]\n",
      "epoch7 step54715 [D loss: -0.224088] [G loss: -0.001059]\n",
      "epoch7 step54720 [D loss: 0.134474] [G loss: 0.035177]\n",
      "epoch7 step54725 [D loss: -0.160618] [G loss: 0.195405]\n",
      "epoch7 step54730 [D loss: 0.097177] [G loss: 0.202049]\n",
      "epoch7 step54735 [D loss: -0.517708] [G loss: 0.536273]\n",
      "epoch7 step54740 [D loss: -0.316818] [G loss: 0.028196]\n",
      "epoch7 step54745 [D loss: -0.070900] [G loss: 0.350371]\n",
      "epoch7 step54750 [D loss: 0.135124] [G loss: 0.192813]\n",
      "epoch7 step54755 [D loss: -0.250091] [G loss: 0.370433]\n",
      "epoch7 step54760 [D loss: 0.140490] [G loss: 0.103261]\n",
      "epoch7 step54765 [D loss: -0.284355] [G loss: -0.175435]\n",
      "epoch7 step54770 [D loss: -0.143924] [G loss: -0.361717]\n",
      "epoch7 step54775 [D loss: 0.098180] [G loss: -0.347550]\n",
      "epoch7 step54780 [D loss: -0.148450] [G loss: -0.106337]\n",
      "epoch7 step54785 [D loss: -0.154041] [G loss: -0.158399]\n",
      "epoch7 step54790 [D loss: 0.188360] [G loss: -0.365331]\n",
      "epoch7 step54795 [D loss: 0.325442] [G loss: -0.468496]\n",
      "epoch7 step54800 [D loss: 0.021608] [G loss: -0.376310]\n",
      "epoch7 step54805 [D loss: -0.019855] [G loss: -0.560693]\n",
      "epoch7 step54810 [D loss: -0.168019] [G loss: -0.734080]\n",
      "epoch7 step54815 [D loss: -0.345406] [G loss: -0.816947]\n",
      "epoch7 step54820 [D loss: -0.501372] [G loss: -0.326474]\n",
      "epoch7 step54825 [D loss: 0.376474] [G loss: -0.752169]\n",
      "epoch7 step54830 [D loss: -0.174278] [G loss: -0.683236]\n",
      "epoch7 step54835 [D loss: 0.152102] [G loss: -0.661924]\n",
      "epoch7 step54840 [D loss: 0.022027] [G loss: -0.576780]\n",
      "epoch7 step54845 [D loss: -0.129078] [G loss: -0.517201]\n",
      "epoch7 step54850 [D loss: 0.098285] [G loss: -0.950457]\n",
      "epoch7 step54855 [D loss: -0.216013] [G loss: -0.719667]\n",
      "epoch7 step54860 [D loss: 0.040526] [G loss: -0.393974]\n",
      "epoch7 step54865 [D loss: 0.080409] [G loss: -0.415889]\n",
      "epoch7 step54870 [D loss: -0.292587] [G loss: -0.366018]\n",
      "epoch7 step54875 [D loss: -0.268739] [G loss: -0.535149]\n",
      "epoch7 step54880 [D loss: -0.240649] [G loss: -0.534889]\n",
      "epoch7 step54885 [D loss: 0.093031] [G loss: -0.468695]\n",
      "epoch7 step54890 [D loss: -0.240712] [G loss: -0.414444]\n",
      "epoch7 step54895 [D loss: 0.030375] [G loss: -0.551444]\n",
      "epoch7 step54900 [D loss: -0.332755] [G loss: -0.357969]\n",
      "epoch7 step54905 [D loss: -0.010612] [G loss: -0.491332]\n",
      "epoch7 step54910 [D loss: -0.331154] [G loss: -0.583490]\n",
      "epoch7 step54915 [D loss: -0.158964] [G loss: 0.006379]\n",
      "epoch7 step54920 [D loss: -0.123648] [G loss: -0.129952]\n",
      "epoch7 step54925 [D loss: 0.026461] [G loss: -0.140662]\n",
      "epoch7 step54930 [D loss: -0.118225] [G loss: -0.282851]\n",
      "epoch7 step54935 [D loss: -0.433337] [G loss: -0.303716]\n",
      "epoch7 step54940 [D loss: -0.193056] [G loss: -0.305055]\n",
      "epoch7 step54945 [D loss: -0.008783] [G loss: -0.094701]\n",
      "epoch7 step54950 [D loss: -0.085094] [G loss: 0.008931]\n",
      "epoch7 step54955 [D loss: -0.216428] [G loss: 0.312429]\n",
      "epoch7 step54960 [D loss: -0.112575] [G loss: -0.006407]\n",
      "epoch7 step54965 [D loss: 0.182110] [G loss: -0.154145]\n",
      "epoch7 step54970 [D loss: -0.219202] [G loss: 0.256643]\n",
      "epoch7 step54975 [D loss: -0.335416] [G loss: 0.291579]\n",
      "epoch7 step54980 [D loss: -0.089754] [G loss: 0.249037]\n",
      "epoch7 step54985 [D loss: -0.123803] [G loss: -0.215872]\n",
      "epoch7 step54990 [D loss: -0.544579] [G loss: 0.276221]\n",
      "epoch7 step54995 [D loss: -0.133196] [G loss: 0.225195]\n",
      "epoch7 step55000 [D loss: -0.050137] [G loss: 0.136649]\n",
      "epoch7 step55005 [D loss: -0.243226] [G loss: -0.231185]\n",
      "epoch7 step55010 [D loss: -0.417497] [G loss: 0.018041]\n",
      "epoch7 step55015 [D loss: -0.005409] [G loss: 0.078454]\n",
      "epoch7 step55020 [D loss: -0.118646] [G loss: 0.012314]\n",
      "epoch7 step55025 [D loss: -0.527089] [G loss: 0.108872]\n",
      "epoch7 step55030 [D loss: -0.072700] [G loss: 0.019428]\n",
      "epoch7 step55035 [D loss: 0.276349] [G loss: 0.339995]\n",
      "epoch7 step55040 [D loss: -0.109206] [G loss: 0.172424]\n",
      "epoch7 step55045 [D loss: -0.383381] [G loss: 0.212687]\n",
      "epoch7 step55050 [D loss: -0.384515] [G loss: 0.441797]\n",
      "epoch7 step55055 [D loss: 0.223600] [G loss: 0.342131]\n",
      "epoch7 step55060 [D loss: -0.882304] [G loss: 0.122828]\n",
      "epoch7 step55065 [D loss: 0.066076] [G loss: 0.154441]\n",
      "epoch7 step55070 [D loss: 0.079824] [G loss: 0.404041]\n",
      "epoch7 step55075 [D loss: -0.501967] [G loss: 0.157723]\n",
      "epoch7 step55080 [D loss: -0.199234] [G loss: 0.284540]\n",
      "epoch7 step55085 [D loss: -0.576704] [G loss: 0.296965]\n",
      "epoch7 step55090 [D loss: -0.160489] [G loss: -0.033669]\n",
      "epoch7 step55095 [D loss: -0.203966] [G loss: 0.138477]\n",
      "epoch7 step55100 [D loss: -0.548707] [G loss: 0.282609]\n",
      "epoch7 step55105 [D loss: -0.034456] [G loss: 0.074234]\n",
      "epoch7 step55110 [D loss: -0.365265] [G loss: 0.364465]\n",
      "epoch7 step55115 [D loss: -0.412447] [G loss: 0.381182]\n",
      "epoch7 step55120 [D loss: -0.348882] [G loss: 0.463030]\n",
      "epoch7 step55125 [D loss: -0.470112] [G loss: 0.506412]\n",
      "epoch7 step55130 [D loss: 0.309830] [G loss: 0.184569]\n",
      "epoch7 step55135 [D loss: -0.549478] [G loss: 0.588458]\n",
      "epoch7 step55140 [D loss: -0.265078] [G loss: 0.745047]\n",
      "epoch7 step55145 [D loss: -0.199662] [G loss: 0.361126]\n",
      "epoch7 step55150 [D loss: -0.124537] [G loss: 0.751375]\n",
      "epoch7 step55155 [D loss: 0.168859] [G loss: 0.751917]\n",
      "epoch7 step55160 [D loss: -0.180069] [G loss: 1.190883]\n",
      "epoch7 step55165 [D loss: 0.070409] [G loss: 0.690538]\n",
      "epoch7 step55170 [D loss: -0.021035] [G loss: 1.122732]\n",
      "epoch7 step55175 [D loss: 0.030413] [G loss: 0.813825]\n",
      "epoch7 step55180 [D loss: 0.020304] [G loss: 0.839242]\n",
      "epoch7 step55185 [D loss: -0.505489] [G loss: 1.141539]\n",
      "epoch7 step55190 [D loss: 0.062310] [G loss: 0.798483]\n",
      "epoch7 step55195 [D loss: -0.081387] [G loss: 0.923714]\n",
      "epoch7 step55200 [D loss: -0.373045] [G loss: 1.294859]\n",
      "epoch7 step55205 [D loss: -0.656755] [G loss: 1.631773]\n",
      "epoch7 step55210 [D loss: -0.275012] [G loss: 1.152657]\n",
      "epoch7 step55215 [D loss: -0.266079] [G loss: 1.406848]\n",
      "epoch7 step55220 [D loss: 0.336126] [G loss: 0.896184]\n",
      "epoch7 step55225 [D loss: -0.101888] [G loss: 1.510067]\n",
      "epoch7 step55230 [D loss: -0.096112] [G loss: 0.842931]\n",
      "epoch7 step55235 [D loss: 0.110710] [G loss: 1.051980]\n",
      "epoch7 step55240 [D loss: 0.172633] [G loss: 0.979329]\n",
      "epoch7 step55245 [D loss: -0.393448] [G loss: 0.811312]\n",
      "epoch7 step55250 [D loss: -0.096098] [G loss: 0.921135]\n",
      "epoch7 step55255 [D loss: -0.266310] [G loss: 0.728929]\n",
      "epoch7 step55260 [D loss: -0.298124] [G loss: 0.506301]\n",
      "epoch7 step55265 [D loss: -0.538475] [G loss: 0.502545]\n",
      "epoch7 step55270 [D loss: -0.156430] [G loss: 0.553588]\n",
      "epoch7 step55275 [D loss: -0.413923] [G loss: 0.508426]\n",
      "epoch7 step55280 [D loss: -0.097595] [G loss: 0.540387]\n",
      "epoch7 step55285 [D loss: 0.455718] [G loss: 0.275680]\n",
      "epoch7 step55290 [D loss: -0.112709] [G loss: 0.368280]\n",
      "epoch7 step55295 [D loss: -0.279412] [G loss: 0.591789]\n",
      "epoch7 step55300 [D loss: -0.694417] [G loss: 0.437960]\n",
      "epoch7 step55305 [D loss: -0.256682] [G loss: 0.302478]\n",
      "epoch7 step55310 [D loss: 0.612720] [G loss: 0.191217]\n",
      "epoch7 step55315 [D loss: -0.546393] [G loss: 0.127280]\n",
      "epoch7 step55320 [D loss: 0.101935] [G loss: 0.216582]\n",
      "epoch7 step55325 [D loss: 0.480745] [G loss: 0.201198]\n",
      "epoch7 step55330 [D loss: -0.204784] [G loss: 0.171964]\n",
      "epoch7 step55335 [D loss: -0.358015] [G loss: 0.044218]\n",
      "epoch7 step55340 [D loss: -0.122217] [G loss: 0.102438]\n",
      "epoch7 step55345 [D loss: 0.150017] [G loss: -0.305351]\n",
      "epoch7 step55350 [D loss: -0.382701] [G loss: 0.096358]\n",
      "epoch7 step55355 [D loss: -0.115794] [G loss: 0.291581]\n",
      "epoch7 step55360 [D loss: -0.005896] [G loss: -0.299918]\n",
      "epoch7 step55365 [D loss: -0.383638] [G loss: -0.163872]\n",
      "epoch7 step55370 [D loss: 0.109115] [G loss: -0.041212]\n",
      "epoch7 step55375 [D loss: -0.102695] [G loss: -0.121383]\n",
      "epoch7 step55380 [D loss: 0.198385] [G loss: -0.034794]\n",
      "epoch7 step55385 [D loss: -0.314850] [G loss: -0.034840]\n",
      "epoch7 step55390 [D loss: 0.340622] [G loss: -0.037641]\n",
      "epoch7 step55395 [D loss: -0.289274] [G loss: -0.519795]\n",
      "epoch7 step55400 [D loss: -0.160933] [G loss: -0.086668]\n",
      "epoch7 step55405 [D loss: -0.338103] [G loss: -0.240867]\n",
      "epoch7 step55410 [D loss: -0.791479] [G loss: 0.257669]\n",
      "epoch7 step55415 [D loss: -0.366558] [G loss: 0.107596]\n",
      "epoch7 step55420 [D loss: -0.334938] [G loss: 0.046120]\n",
      "epoch7 step55425 [D loss: -0.250497] [G loss: -0.031411]\n",
      "epoch7 step55430 [D loss: -0.158706] [G loss: 0.357144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step55435 [D loss: -0.315154] [G loss: 0.291059]\n",
      "epoch7 step55440 [D loss: -0.239449] [G loss: 0.301815]\n",
      "epoch7 step55445 [D loss: -0.367944] [G loss: 0.595104]\n",
      "epoch7 step55450 [D loss: -0.093533] [G loss: 0.558298]\n",
      "epoch7 step55455 [D loss: 0.198656] [G loss: 0.380465]\n",
      "epoch7 step55460 [D loss: -0.190815] [G loss: 0.704081]\n",
      "epoch7 step55465 [D loss: -0.120826] [G loss: -0.124176]\n",
      "epoch7 step55470 [D loss: -0.160411] [G loss: 0.174577]\n",
      "epoch7 step55475 [D loss: -0.319875] [G loss: 0.399896]\n",
      "epoch7 step55480 [D loss: -0.255910] [G loss: 0.386915]\n",
      "epoch7 step55485 [D loss: 0.246134] [G loss: 0.206380]\n",
      "epoch7 step55490 [D loss: -0.420157] [G loss: 0.065425]\n",
      "epoch7 step55495 [D loss: -0.063047] [G loss: -0.095076]\n",
      "epoch7 step55500 [D loss: -0.131890] [G loss: 0.168634]\n",
      "epoch7 step55505 [D loss: -0.612806] [G loss: 0.189547]\n",
      "epoch7 step55510 [D loss: -0.207254] [G loss: 0.221333]\n",
      "epoch7 step55515 [D loss: 0.077797] [G loss: 0.131704]\n",
      "epoch7 step55520 [D loss: -0.136611] [G loss: 0.139869]\n",
      "epoch7 step55525 [D loss: -0.387258] [G loss: 0.254590]\n",
      "epoch7 step55530 [D loss: 0.393327] [G loss: 0.014079]\n",
      "epoch7 step55535 [D loss: -0.091592] [G loss: 0.388853]\n",
      "epoch7 step55540 [D loss: -0.306260] [G loss: 0.122171]\n",
      "epoch7 step55545 [D loss: -0.190666] [G loss: 0.025791]\n",
      "epoch7 step55550 [D loss: 0.145073] [G loss: 0.227328]\n",
      "epoch7 step55555 [D loss: 0.062747] [G loss: 0.362037]\n",
      "epoch7 step55560 [D loss: -0.047607] [G loss: -0.033862]\n",
      "epoch7 step55565 [D loss: -0.173181] [G loss: -0.035505]\n",
      "epoch7 step55570 [D loss: -0.464739] [G loss: -0.106497]\n",
      "epoch7 step55575 [D loss: -0.116696] [G loss: 0.304846]\n",
      "epoch7 step55580 [D loss: -0.113077] [G loss: 0.070588]\n",
      "epoch7 step55585 [D loss: 0.217917] [G loss: -0.059103]\n",
      "epoch7 step55590 [D loss: 0.141021] [G loss: -0.098074]\n",
      "epoch7 step55595 [D loss: -0.261814] [G loss: 0.311540]\n",
      "epoch7 step55600 [D loss: -0.088716] [G loss: 0.022616]\n",
      "epoch7 step55605 [D loss: 0.212007] [G loss: -0.031246]\n",
      "epoch7 step55610 [D loss: 0.009411] [G loss: -0.234188]\n",
      "epoch7 step55615 [D loss: -0.295309] [G loss: 0.017204]\n",
      "epoch7 step55620 [D loss: -0.225539] [G loss: -0.076563]\n",
      "epoch7 step55625 [D loss: 0.361739] [G loss: -0.179467]\n",
      "epoch7 step55630 [D loss: -0.540417] [G loss: -0.085924]\n",
      "epoch7 step55635 [D loss: 0.087721] [G loss: -0.086104]\n",
      "epoch7 step55640 [D loss: 0.448101] [G loss: -0.229595]\n",
      "epoch7 step55645 [D loss: 0.223549] [G loss: 0.259311]\n",
      "epoch7 step55650 [D loss: 0.087891] [G loss: -0.129163]\n",
      "epoch7 step55655 [D loss: -0.268490] [G loss: -0.062994]\n",
      "epoch7 step55660 [D loss: 0.004910] [G loss: 0.126600]\n",
      "epoch7 step55665 [D loss: -0.470018] [G loss: -0.665973]\n",
      "epoch7 step55670 [D loss: -0.075812] [G loss: -0.133829]\n",
      "epoch7 step55675 [D loss: -0.041826] [G loss: -0.361222]\n",
      "epoch7 step55680 [D loss: -0.393417] [G loss: 0.014686]\n",
      "epoch7 step55685 [D loss: -0.197434] [G loss: -0.091439]\n",
      "epoch7 step55690 [D loss: 0.166309] [G loss: -0.152497]\n",
      "epoch7 step55695 [D loss: -0.083611] [G loss: -0.193018]\n",
      "epoch7 step55700 [D loss: 0.152454] [G loss: -0.178383]\n",
      "epoch7 step55705 [D loss: 0.138326] [G loss: -0.373469]\n",
      "epoch7 step55710 [D loss: 0.302996] [G loss: -0.136661]\n",
      "epoch7 step55715 [D loss: -0.134042] [G loss: -0.096669]\n",
      "epoch7 step55720 [D loss: -0.220530] [G loss: 0.066268]\n",
      "epoch7 step55725 [D loss: 0.132394] [G loss: -0.299837]\n",
      "epoch7 step55730 [D loss: -0.392207] [G loss: -0.102448]\n",
      "epoch7 step55735 [D loss: -0.439721] [G loss: -0.214192]\n",
      "epoch7 step55740 [D loss: 0.299498] [G loss: -0.345488]\n",
      "epoch7 step55745 [D loss: -0.443210] [G loss: -0.306116]\n",
      "epoch7 step55750 [D loss: 0.395289] [G loss: -0.462090]\n",
      "epoch7 step55755 [D loss: -0.176295] [G loss: -0.541331]\n",
      "epoch7 step55760 [D loss: -0.276153] [G loss: -0.501660]\n",
      "epoch7 step55765 [D loss: -0.376344] [G loss: -0.183694]\n",
      "epoch7 step55770 [D loss: -0.323796] [G loss: -0.072868]\n",
      "epoch7 step55775 [D loss: 0.157812] [G loss: -0.157357]\n",
      "epoch7 step55780 [D loss: -0.040688] [G loss: -0.176274]\n",
      "epoch7 step55785 [D loss: -0.279246] [G loss: -0.077853]\n",
      "epoch7 step55790 [D loss: -0.301931] [G loss: 0.011182]\n",
      "epoch7 step55795 [D loss: -0.071408] [G loss: -0.229959]\n",
      "epoch7 step55800 [D loss: -0.460489] [G loss: 0.172241]\n",
      "epoch7 step55805 [D loss: 0.157242] [G loss: -0.111495]\n",
      "epoch7 step55810 [D loss: -0.252896] [G loss: 0.238081]\n",
      "epoch7 step55815 [D loss: -0.256295] [G loss: 0.144062]\n",
      "epoch7 step55820 [D loss: -0.415178] [G loss: 0.028143]\n",
      "epoch7 step55825 [D loss: 0.028208] [G loss: -0.065881]\n",
      "epoch7 step55830 [D loss: -0.099540] [G loss: 0.125580]\n",
      "epoch7 step55835 [D loss: -0.390877] [G loss: 0.202530]\n",
      "epoch7 step55840 [D loss: -0.036082] [G loss: 0.520738]\n",
      "epoch7 step55845 [D loss: 0.140757] [G loss: -0.105895]\n",
      "epoch7 step55850 [D loss: -0.341941] [G loss: -0.098109]\n",
      "epoch7 step55855 [D loss: -0.021526] [G loss: 0.078978]\n",
      "epoch7 step55860 [D loss: -0.328059] [G loss: 0.052045]\n",
      "epoch7 step55865 [D loss: -0.250734] [G loss: 0.262272]\n",
      "epoch7 step55870 [D loss: 0.006293] [G loss: 0.289499]\n",
      "epoch7 step55875 [D loss: -0.246769] [G loss: 0.486599]\n",
      "epoch7 step55880 [D loss: -0.434488] [G loss: 0.468990]\n",
      "epoch7 step55885 [D loss: -0.330786] [G loss: 0.276637]\n",
      "epoch7 step55890 [D loss: -0.520535] [G loss: 0.298913]\n",
      "epoch7 step55895 [D loss: 0.150446] [G loss: 0.347591]\n",
      "epoch7 step55900 [D loss: -0.258222] [G loss: 0.268893]\n",
      "epoch7 step55905 [D loss: -0.403639] [G loss: 0.193507]\n",
      "epoch7 step55910 [D loss: -0.134728] [G loss: 0.126906]\n",
      "epoch7 step55915 [D loss: -0.358241] [G loss: 0.199189]\n",
      "epoch7 step55920 [D loss: 0.200556] [G loss: 0.215331]\n",
      "epoch7 step55925 [D loss: -0.026772] [G loss: 0.069164]\n",
      "epoch7 step55930 [D loss: 0.205370] [G loss: -0.112837]\n",
      "epoch7 step55935 [D loss: -0.191405] [G loss: 0.073601]\n",
      "epoch7 step55940 [D loss: 0.165224] [G loss: 0.027035]\n",
      "epoch7 step55945 [D loss: -0.137665] [G loss: -0.057542]\n",
      "epoch7 step55950 [D loss: -0.433650] [G loss: -0.165562]\n",
      "epoch7 step55955 [D loss: -0.201044] [G loss: -0.066336]\n",
      "epoch7 step55960 [D loss: -0.332836] [G loss: -0.205679]\n",
      "epoch7 step55965 [D loss: -0.046612] [G loss: -0.184421]\n",
      "epoch7 step55970 [D loss: 0.023681] [G loss: 0.001033]\n",
      "epoch7 step55975 [D loss: 0.002545] [G loss: -0.025828]\n",
      "epoch7 step55980 [D loss: -0.248057] [G loss: -0.329296]\n",
      "epoch7 step55985 [D loss: 0.098503] [G loss: -0.417584]\n",
      "epoch7 step55990 [D loss: -0.270771] [G loss: 0.030249]\n",
      "epoch7 step55995 [D loss: -0.394895] [G loss: -0.118774]\n",
      "epoch7 step56000 [D loss: -0.211299] [G loss: 0.000434]\n",
      "epoch7 step56005 [D loss: -0.249885] [G loss: -0.306273]\n",
      "epoch7 step56010 [D loss: -0.464404] [G loss: 0.180292]\n",
      "epoch7 step56015 [D loss: 0.047328] [G loss: -0.218233]\n",
      "epoch7 step56020 [D loss: -0.012237] [G loss: 0.228991]\n",
      "epoch7 step56025 [D loss: -0.350824] [G loss: 0.070235]\n",
      "epoch7 step56030 [D loss: -0.538900] [G loss: -0.213872]\n",
      "epoch7 step56035 [D loss: -0.250015] [G loss: 0.220157]\n",
      "epoch7 step56040 [D loss: -0.503159] [G loss: 0.193748]\n",
      "epoch7 step56045 [D loss: -0.263454] [G loss: 0.335912]\n",
      "epoch7 step56050 [D loss: -0.272442] [G loss: 0.003993]\n",
      "epoch7 step56055 [D loss: -0.333973] [G loss: 0.264467]\n",
      "epoch7 step56060 [D loss: 0.162008] [G loss: 0.305319]\n",
      "epoch7 step56065 [D loss: 0.028549] [G loss: 0.196947]\n",
      "epoch7 step56070 [D loss: -0.448190] [G loss: 0.210069]\n",
      "epoch7 step56075 [D loss: 0.030922] [G loss: 0.280065]\n",
      "epoch7 step56080 [D loss: -0.248770] [G loss: 0.428040]\n",
      "epoch7 step56085 [D loss: -0.215839] [G loss: 0.350280]\n",
      "epoch7 step56090 [D loss: -0.310530] [G loss: 0.405132]\n",
      "epoch7 step56095 [D loss: 0.538559] [G loss: 0.402909]\n",
      "epoch7 step56100 [D loss: 0.074303] [G loss: 0.300678]\n",
      "epoch7 step56105 [D loss: -0.246500] [G loss: 0.421067]\n",
      "epoch7 step56110 [D loss: -0.488126] [G loss: 0.574764]\n",
      "epoch7 step56115 [D loss: 0.202483] [G loss: 0.001714]\n",
      "epoch7 step56120 [D loss: 0.048054] [G loss: 0.166535]\n",
      "epoch7 step56125 [D loss: 0.233897] [G loss: 0.251650]\n",
      "epoch7 step56130 [D loss: -0.560761] [G loss: 0.495527]\n",
      "epoch7 step56135 [D loss: -0.325035] [G loss: 0.203690]\n",
      "epoch7 step56140 [D loss: -0.199315] [G loss: 0.000917]\n",
      "epoch7 step56145 [D loss: 0.084041] [G loss: 0.242624]\n",
      "epoch7 step56150 [D loss: 0.111809] [G loss: 0.288154]\n",
      "epoch7 step56155 [D loss: 0.256001] [G loss: -0.116857]\n",
      "epoch7 step56160 [D loss: -0.357332] [G loss: 0.327642]\n",
      "epoch7 step56165 [D loss: -0.248295] [G loss: 0.355470]\n",
      "epoch7 step56170 [D loss: -0.329321] [G loss: 0.359979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step56175 [D loss: -0.029778] [G loss: 0.447178]\n",
      "epoch7 step56180 [D loss: -0.417738] [G loss: 0.225886]\n",
      "epoch7 step56185 [D loss: -0.474649] [G loss: 0.364037]\n",
      "epoch7 step56190 [D loss: -0.228568] [G loss: 0.058094]\n",
      "epoch7 step56195 [D loss: 0.140913] [G loss: -0.172285]\n",
      "epoch7 step56200 [D loss: 0.157134] [G loss: 0.045973]\n",
      "epoch7 step56205 [D loss: 0.254809] [G loss: 0.029818]\n",
      "epoch7 step56210 [D loss: 0.295339] [G loss: 0.080631]\n",
      "epoch7 step56215 [D loss: -0.451621] [G loss: 0.178491]\n",
      "epoch7 step56220 [D loss: 0.320752] [G loss: -0.220560]\n",
      "epoch7 step56225 [D loss: -0.100914] [G loss: 0.131026]\n",
      "epoch7 step56230 [D loss: -0.214192] [G loss: -0.231354]\n",
      "epoch7 step56235 [D loss: -0.111776] [G loss: -0.119568]\n",
      "epoch7 step56240 [D loss: -0.031640] [G loss: 0.244960]\n",
      "epoch7 step56245 [D loss: -0.334097] [G loss: 0.013059]\n",
      "epoch7 step56250 [D loss: -0.146182] [G loss: 0.139578]\n",
      "epoch7 step56255 [D loss: -0.498729] [G loss: 0.055952]\n",
      "epoch7 step56260 [D loss: -0.341920] [G loss: 0.549476]\n",
      "epoch7 step56265 [D loss: -0.400321] [G loss: 0.004715]\n",
      "epoch7 step56270 [D loss: -0.208636] [G loss: 0.407545]\n",
      "epoch7 step56275 [D loss: 0.056688] [G loss: -0.065684]\n",
      "epoch7 step56280 [D loss: 0.524798] [G loss: -0.043465]\n",
      "epoch7 step56285 [D loss: -0.366089] [G loss: -0.045775]\n",
      "epoch7 step56290 [D loss: -0.410208] [G loss: 0.031318]\n",
      "epoch7 step56295 [D loss: -0.105687] [G loss: 0.130496]\n",
      "epoch7 step56300 [D loss: -0.283616] [G loss: -0.125531]\n",
      "epoch7 step56305 [D loss: 0.192611] [G loss: 0.008121]\n",
      "epoch7 step56310 [D loss: -0.344333] [G loss: -0.142232]\n",
      "epoch7 step56315 [D loss: -0.209448] [G loss: -0.373134]\n",
      "epoch7 step56320 [D loss: -0.076626] [G loss: -0.260102]\n",
      "epoch7 step56325 [D loss: -0.198408] [G loss: -0.107172]\n",
      "epoch7 step56330 [D loss: -0.065213] [G loss: -0.233687]\n",
      "epoch7 step56335 [D loss: 0.012440] [G loss: -0.124922]\n",
      "epoch7 step56340 [D loss: -0.189189] [G loss: -0.375190]\n",
      "epoch7 step56345 [D loss: 0.060926] [G loss: -0.255884]\n",
      "epoch7 step56350 [D loss: -0.064485] [G loss: -0.123413]\n",
      "epoch7 step56355 [D loss: 0.365966] [G loss: -0.335314]\n",
      "epoch7 step56360 [D loss: 0.074853] [G loss: -0.235757]\n",
      "epoch7 step56365 [D loss: -0.288389] [G loss: -0.507636]\n",
      "epoch7 step56370 [D loss: -0.236699] [G loss: -0.552061]\n",
      "epoch7 step56375 [D loss: -0.130503] [G loss: -0.108117]\n",
      "epoch7 step56380 [D loss: -0.039263] [G loss: -0.231130]\n",
      "epoch7 step56385 [D loss: -0.097985] [G loss: -0.275340]\n",
      "epoch7 step56390 [D loss: -0.327412] [G loss: -0.133628]\n",
      "epoch7 step56395 [D loss: -0.102298] [G loss: -0.211080]\n",
      "epoch7 step56400 [D loss: -0.056029] [G loss: -0.099912]\n",
      "epoch7 step56405 [D loss: -0.208429] [G loss: -0.003741]\n",
      "epoch7 step56410 [D loss: -0.170645] [G loss: -0.155999]\n",
      "epoch7 step56415 [D loss: 0.103158] [G loss: -0.016432]\n",
      "epoch7 step56420 [D loss: -0.337234] [G loss: -0.004366]\n",
      "epoch7 step56425 [D loss: 0.131810] [G loss: 0.000513]\n",
      "epoch7 step56430 [D loss: -0.349215] [G loss: -0.080332]\n",
      "epoch7 step56435 [D loss: -0.028904] [G loss: 0.196867]\n",
      "epoch7 step56440 [D loss: -0.158667] [G loss: 0.029734]\n",
      "epoch7 step56445 [D loss: 0.493619] [G loss: -0.140917]\n",
      "epoch7 step56450 [D loss: 0.091034] [G loss: 0.261375]\n",
      "epoch7 step56455 [D loss: -0.066039] [G loss: 0.200700]\n",
      "epoch7 step56460 [D loss: -0.112775] [G loss: -0.258898]\n",
      "epoch7 step56465 [D loss: -0.410696] [G loss: 0.141667]\n",
      "epoch7 step56470 [D loss: -0.011223] [G loss: -0.010709]\n",
      "epoch7 step56475 [D loss: -0.194372] [G loss: -0.111719]\n",
      "epoch7 step56480 [D loss: -0.820401] [G loss: 0.331161]\n",
      "epoch7 step56485 [D loss: -0.304255] [G loss: -0.191981]\n",
      "epoch7 step56490 [D loss: -0.566417] [G loss: 0.031625]\n",
      "epoch7 step56495 [D loss: -0.398975] [G loss: -0.038700]\n",
      "epoch7 step56500 [D loss: -0.078004] [G loss: -0.101745]\n",
      "epoch7 step56505 [D loss: -0.436571] [G loss: 0.120498]\n",
      "epoch7 step56510 [D loss: -0.228315] [G loss: -0.039241]\n",
      "epoch7 step56515 [D loss: -0.179278] [G loss: -0.262333]\n",
      "epoch7 step56520 [D loss: 0.037034] [G loss: -0.454380]\n",
      "epoch7 step56525 [D loss: 0.083813] [G loss: -0.638628]\n",
      "epoch7 step56530 [D loss: -0.321249] [G loss: -0.512712]\n",
      "epoch7 step56535 [D loss: -0.555184] [G loss: -0.196671]\n",
      "epoch7 step56540 [D loss: -0.291797] [G loss: -0.335606]\n",
      "epoch7 step56545 [D loss: -0.017958] [G loss: 0.014047]\n",
      "epoch7 step56550 [D loss: -0.573772] [G loss: -0.190443]\n",
      "epoch7 step56555 [D loss: 0.217222] [G loss: -0.527812]\n",
      "epoch7 step56560 [D loss: 0.051842] [G loss: -0.766658]\n",
      "epoch7 step56565 [D loss: -0.078389] [G loss: -0.481914]\n",
      "epoch7 step56570 [D loss: -0.385018] [G loss: -0.333147]\n",
      "epoch7 step56575 [D loss: 0.028650] [G loss: -0.702197]\n",
      "epoch7 step56580 [D loss: -0.439519] [G loss: -0.519156]\n",
      "epoch7 step56585 [D loss: -0.225753] [G loss: -0.290830]\n",
      "epoch7 step56590 [D loss: -0.134645] [G loss: -0.601477]\n",
      "epoch7 step56595 [D loss: 0.124301] [G loss: -0.863763]\n",
      "epoch7 step56600 [D loss: -0.353408] [G loss: -0.410443]\n",
      "epoch7 step56605 [D loss: 0.056920] [G loss: -0.367914]\n",
      "epoch7 step56610 [D loss: -0.211059] [G loss: -0.719890]\n",
      "epoch7 step56615 [D loss: -0.479614] [G loss: -0.359308]\n",
      "epoch7 step56620 [D loss: -0.413145] [G loss: -0.321209]\n",
      "epoch7 step56625 [D loss: -0.216462] [G loss: -0.367289]\n",
      "epoch7 step56630 [D loss: -0.216898] [G loss: -0.671479]\n",
      "epoch7 step56635 [D loss: -0.032956] [G loss: -0.231500]\n",
      "epoch7 step56640 [D loss: -0.156866] [G loss: -0.468977]\n",
      "epoch7 step56645 [D loss: -0.561334] [G loss: -0.012974]\n",
      "epoch7 step56650 [D loss: -0.028342] [G loss: -0.411362]\n",
      "epoch7 step56655 [D loss: 0.367622] [G loss: -0.068165]\n",
      "epoch7 step56660 [D loss: -0.210972] [G loss: -0.056330]\n",
      "epoch7 step56665 [D loss: -0.019749] [G loss: -0.199859]\n",
      "epoch7 step56670 [D loss: -0.320381] [G loss: -0.018059]\n",
      "epoch7 step56675 [D loss: -0.338812] [G loss: -0.274627]\n",
      "epoch7 step56680 [D loss: -0.165134] [G loss: -0.236308]\n",
      "epoch7 step56685 [D loss: 0.068806] [G loss: -0.001471]\n",
      "epoch7 step56690 [D loss: -0.361308] [G loss: -0.113569]\n",
      "epoch7 step56695 [D loss: 0.473534] [G loss: -0.212509]\n",
      "epoch7 step56700 [D loss: -0.016771] [G loss: 0.033963]\n",
      "epoch7 step56705 [D loss: -0.101234] [G loss: -0.167327]\n",
      "epoch7 step56710 [D loss: -0.277093] [G loss: -0.138425]\n",
      "epoch7 step56715 [D loss: 0.308853] [G loss: -0.251535]\n",
      "epoch7 step56720 [D loss: -0.567097] [G loss: 0.159013]\n",
      "epoch7 step56725 [D loss: 0.083848] [G loss: -0.323517]\n",
      "epoch7 step56730 [D loss: -0.207726] [G loss: -0.063540]\n",
      "epoch7 step56735 [D loss: -0.145324] [G loss: -0.005396]\n",
      "epoch7 step56740 [D loss: -0.069468] [G loss: 0.024845]\n",
      "epoch7 step56745 [D loss: -0.545096] [G loss: 0.266106]\n",
      "epoch7 step56750 [D loss: -0.293859] [G loss: 0.240862]\n",
      "epoch7 step56755 [D loss: 0.166670] [G loss: -0.088497]\n",
      "epoch7 step56760 [D loss: -0.875374] [G loss: -0.018030]\n",
      "epoch7 step56765 [D loss: -0.557347] [G loss: 0.243924]\n",
      "epoch7 step56770 [D loss: -0.464113] [G loss: 0.442662]\n",
      "epoch7 step56775 [D loss: -0.041036] [G loss: 0.220601]\n",
      "epoch7 step56780 [D loss: -0.309689] [G loss: 0.432196]\n",
      "epoch7 step56785 [D loss: -0.504509] [G loss: 0.087067]\n",
      "epoch7 step56790 [D loss: -0.036971] [G loss: 0.312948]\n",
      "epoch7 step56795 [D loss: -0.276867] [G loss: 0.172920]\n",
      "epoch7 step56800 [D loss: -0.035253] [G loss: -0.000849]\n",
      "epoch7 step56805 [D loss: 0.237537] [G loss: 0.217423]\n",
      "epoch7 step56810 [D loss: -0.158055] [G loss: 0.116367]\n",
      "epoch7 step56815 [D loss: 0.238096] [G loss: -0.070135]\n",
      "epoch7 step56820 [D loss: 0.180564] [G loss: -0.375644]\n",
      "epoch7 step56825 [D loss: -0.256683] [G loss: 0.014340]\n",
      "epoch7 step56830 [D loss: 0.011650] [G loss: 0.053424]\n",
      "epoch7 step56835 [D loss: 0.017057] [G loss: 0.038122]\n",
      "epoch7 step56840 [D loss: -0.341471] [G loss: 0.026575]\n",
      "epoch7 step56845 [D loss: -0.077784] [G loss: -0.158635]\n",
      "epoch7 step56850 [D loss: 0.364722] [G loss: -0.069039]\n",
      "epoch7 step56855 [D loss: -0.153144] [G loss: -0.221530]\n",
      "epoch7 step56860 [D loss: -0.236865] [G loss: -0.321046]\n",
      "epoch7 step56865 [D loss: -0.166936] [G loss: -0.023301]\n",
      "epoch7 step56870 [D loss: 0.457585] [G loss: -0.388909]\n",
      "epoch7 step56875 [D loss: -0.604759] [G loss: 0.036247]\n",
      "epoch7 step56880 [D loss: 0.262346] [G loss: -0.173901]\n",
      "epoch7 step56885 [D loss: -0.397729] [G loss: 0.096043]\n",
      "epoch7 step56890 [D loss: -0.109607] [G loss: -0.086938]\n",
      "epoch7 step56895 [D loss: -0.488564] [G loss: 0.102987]\n",
      "epoch7 step56900 [D loss: -0.201261] [G loss: -0.108605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step56905 [D loss: -0.049113] [G loss: -0.084727]\n",
      "epoch7 step56910 [D loss: -0.335471] [G loss: 0.282292]\n",
      "epoch7 step56915 [D loss: 0.007947] [G loss: -0.226416]\n",
      "epoch7 step56920 [D loss: -0.608994] [G loss: 0.264753]\n",
      "epoch7 step56925 [D loss: -0.400930] [G loss: -0.226720]\n",
      "epoch7 step56930 [D loss: -0.382636] [G loss: -0.396063]\n",
      "epoch7 step56935 [D loss: -0.341425] [G loss: -0.209003]\n",
      "epoch7 step56940 [D loss: -0.215372] [G loss: -0.121386]\n",
      "epoch7 step56945 [D loss: -0.739238] [G loss: -0.067079]\n",
      "epoch7 step56950 [D loss: 0.263323] [G loss: -0.378870]\n",
      "epoch7 step56955 [D loss: 0.094887] [G loss: -0.105952]\n",
      "epoch7 step56960 [D loss: 0.242609] [G loss: -0.267968]\n",
      "epoch7 step56965 [D loss: 0.437557] [G loss: -0.050531]\n",
      "epoch7 step56970 [D loss: -0.684261] [G loss: 0.093453]\n",
      "epoch7 step56975 [D loss: 0.110967] [G loss: 0.048364]\n",
      "epoch7 step56980 [D loss: 0.127261] [G loss: -0.300892]\n",
      "epoch7 step56985 [D loss: -0.369138] [G loss: 0.140083]\n",
      "epoch7 step56990 [D loss: -0.041310] [G loss: -0.060818]\n",
      "epoch7 step56995 [D loss: -0.401250] [G loss: -0.169545]\n",
      "epoch7 step57000 [D loss: -0.115731] [G loss: -0.118206]\n",
      "epoch7 step57005 [D loss: -0.485844] [G loss: -0.142324]\n",
      "epoch7 step57010 [D loss: -0.363497] [G loss: 0.114231]\n",
      "epoch7 step57015 [D loss: -0.378633] [G loss: -0.124708]\n",
      "epoch7 step57020 [D loss: -0.057985] [G loss: -0.078845]\n",
      "epoch7 step57025 [D loss: -0.115174] [G loss: 0.220479]\n",
      "epoch7 step57030 [D loss: -0.358354] [G loss: 0.238991]\n",
      "epoch7 step57035 [D loss: -0.323035] [G loss: 0.433316]\n",
      "epoch7 step57040 [D loss: -0.525770] [G loss: 0.285511]\n",
      "epoch7 step57045 [D loss: -0.225635] [G loss: 0.289543]\n",
      "epoch7 step57050 [D loss: 0.044189] [G loss: 0.263911]\n",
      "epoch7 step57055 [D loss: 0.005814] [G loss: 0.442812]\n",
      "epoch7 step57060 [D loss: 0.142260] [G loss: 0.404026]\n",
      "epoch7 step57065 [D loss: 0.105964] [G loss: 0.531340]\n",
      "epoch7 step57070 [D loss: -0.360664] [G loss: 0.356649]\n",
      "epoch7 step57075 [D loss: -0.309268] [G loss: 0.604770]\n",
      "epoch7 step57080 [D loss: 0.201058] [G loss: 0.215930]\n",
      "epoch7 step57085 [D loss: 0.375516] [G loss: 0.410015]\n",
      "epoch7 step57090 [D loss: -0.539605] [G loss: 0.488817]\n",
      "epoch7 step57095 [D loss: -0.175011] [G loss: 0.008764]\n",
      "epoch7 step57100 [D loss: -0.223357] [G loss: 0.320426]\n",
      "epoch7 step57105 [D loss: -0.190697] [G loss: 0.433531]\n",
      "epoch7 step57110 [D loss: -0.261191] [G loss: 0.268534]\n",
      "epoch7 step57115 [D loss: 0.099920] [G loss: 0.517213]\n",
      "epoch7 step57120 [D loss: 0.030437] [G loss: 0.598705]\n",
      "epoch7 step57125 [D loss: -0.082600] [G loss: 0.171303]\n",
      "epoch7 step57130 [D loss: 0.165026] [G loss: 0.428553]\n",
      "epoch7 step57135 [D loss: -0.150736] [G loss: 0.622692]\n",
      "epoch7 step57140 [D loss: -0.047150] [G loss: 0.457368]\n",
      "epoch7 step57145 [D loss: 0.245372] [G loss: 0.440096]\n",
      "epoch7 step57150 [D loss: 0.088316] [G loss: 0.307256]\n",
      "epoch7 step57155 [D loss: -0.180489] [G loss: 0.459675]\n",
      "epoch7 step57160 [D loss: 0.395301] [G loss: 0.540166]\n",
      "epoch7 step57165 [D loss: 0.014230] [G loss: 0.358619]\n",
      "epoch7 step57170 [D loss: 0.230380] [G loss: 0.169372]\n",
      "epoch7 step57175 [D loss: -0.275181] [G loss: 0.461954]\n",
      "epoch7 step57180 [D loss: -0.555345] [G loss: 0.341533]\n",
      "epoch7 step57185 [D loss: -0.116892] [G loss: 0.340448]\n",
      "epoch7 step57190 [D loss: -0.271816] [G loss: 0.074227]\n",
      "epoch7 step57195 [D loss: -0.166614] [G loss: 0.516719]\n",
      "epoch7 step57200 [D loss: -0.331597] [G loss: 0.213555]\n",
      "epoch7 step57205 [D loss: -0.047019] [G loss: 0.551030]\n",
      "epoch7 step57210 [D loss: 0.121707] [G loss: -0.134923]\n",
      "epoch7 step57215 [D loss: 0.218659] [G loss: 0.067918]\n",
      "epoch7 step57220 [D loss: -0.103333] [G loss: 0.082928]\n",
      "epoch7 step57225 [D loss: -0.090899] [G loss: 0.214900]\n",
      "epoch7 step57230 [D loss: -0.018306] [G loss: 0.304091]\n",
      "epoch7 step57235 [D loss: -0.271463] [G loss: 0.288506]\n",
      "epoch7 step57240 [D loss: -0.624807] [G loss: 0.313603]\n",
      "epoch7 step57245 [D loss: 0.247825] [G loss: -0.085564]\n",
      "epoch7 step57250 [D loss: 0.023841] [G loss: 0.070966]\n",
      "epoch7 step57255 [D loss: -0.062504] [G loss: -0.093306]\n",
      "epoch7 step57260 [D loss: -0.218371] [G loss: -0.107732]\n",
      "epoch7 step57265 [D loss: 0.019090] [G loss: 0.414260]\n",
      "epoch7 step57270 [D loss: 0.040218] [G loss: 0.050891]\n",
      "epoch7 step57275 [D loss: -0.327713] [G loss: -0.150975]\n",
      "epoch7 step57280 [D loss: -0.775939] [G loss: 0.187718]\n",
      "epoch7 step57285 [D loss: -0.329921] [G loss: 0.188128]\n",
      "epoch7 step57290 [D loss: -0.119971] [G loss: 0.044418]\n",
      "epoch7 step57295 [D loss: -0.499930] [G loss: -0.028666]\n",
      "epoch7 step57300 [D loss: -0.385834] [G loss: -0.140331]\n",
      "epoch7 step57305 [D loss: -0.214711] [G loss: 0.504209]\n",
      "epoch7 step57310 [D loss: -0.440721] [G loss: 0.411232]\n",
      "epoch7 step57315 [D loss: -0.445222] [G loss: -0.109438]\n",
      "epoch7 step57320 [D loss: -0.095708] [G loss: -0.161763]\n",
      "epoch7 step57325 [D loss: -0.225416] [G loss: -0.072554]\n",
      "epoch7 step57330 [D loss: -0.240426] [G loss: -0.224288]\n",
      "epoch7 step57335 [D loss: 0.035565] [G loss: 0.067402]\n",
      "epoch7 step57340 [D loss: -0.331216] [G loss: -0.135453]\n",
      "epoch7 step57345 [D loss: -0.279547] [G loss: -0.346956]\n",
      "epoch7 step57350 [D loss: -0.286730] [G loss: -0.308519]\n",
      "epoch7 step57355 [D loss: -0.121948] [G loss: -0.323582]\n",
      "epoch7 step57360 [D loss: -0.153653] [G loss: -0.287359]\n",
      "epoch7 step57365 [D loss: -0.526871] [G loss: -0.427741]\n",
      "epoch7 step57370 [D loss: 0.064598] [G loss: -0.477057]\n",
      "epoch7 step57375 [D loss: -0.238904] [G loss: -0.223446]\n",
      "epoch7 step57380 [D loss: -0.431194] [G loss: -0.449184]\n",
      "epoch7 step57385 [D loss: 0.338747] [G loss: -0.603389]\n",
      "epoch7 step57390 [D loss: -0.190800] [G loss: -0.469188]\n",
      "epoch7 step57395 [D loss: -0.817223] [G loss: -0.264573]\n",
      "epoch7 step57400 [D loss: -0.406136] [G loss: -0.327557]\n",
      "epoch7 step57405 [D loss: 0.163499] [G loss: 0.297830]\n",
      "epoch7 step57410 [D loss: -0.377193] [G loss: -0.350172]\n",
      "epoch7 step57415 [D loss: -0.649371] [G loss: 0.550329]\n",
      "epoch7 step57420 [D loss: 0.267995] [G loss: 0.103836]\n",
      "epoch7 step57425 [D loss: 0.165896] [G loss: 0.161775]\n",
      "epoch7 step57430 [D loss: -0.392371] [G loss: 0.106933]\n",
      "epoch7 step57435 [D loss: -0.109649] [G loss: 0.007890]\n",
      "epoch7 step57440 [D loss: 0.091676] [G loss: -0.140079]\n",
      "epoch7 step57445 [D loss: -0.008842] [G loss: 0.175919]\n",
      "epoch7 step57450 [D loss: 0.139834] [G loss: 0.161119]\n",
      "epoch7 step57455 [D loss: -0.101643] [G loss: 0.079691]\n",
      "epoch7 step57460 [D loss: -0.420611] [G loss: 0.555989]\n",
      "epoch7 step57465 [D loss: -0.910005] [G loss: 0.639082]\n",
      "epoch7 step57470 [D loss: -0.297087] [G loss: 0.373098]\n",
      "epoch7 step57475 [D loss: 0.218822] [G loss: 0.353507]\n",
      "epoch7 step57480 [D loss: 0.034148] [G loss: 0.600811]\n",
      "epoch7 step57485 [D loss: -0.157059] [G loss: 0.594214]\n",
      "epoch7 step57490 [D loss: 0.010489] [G loss: 0.429586]\n",
      "epoch7 step57495 [D loss: 0.093357] [G loss: 0.558287]\n",
      "epoch7 step57500 [D loss: -0.141456] [G loss: 0.605645]\n",
      "epoch7 step57505 [D loss: -0.096511] [G loss: 0.437719]\n",
      "epoch7 step57510 [D loss: -0.122522] [G loss: 0.662133]\n",
      "epoch7 step57515 [D loss: -0.008899] [G loss: 0.612684]\n",
      "epoch7 step57520 [D loss: -0.120418] [G loss: 0.702922]\n",
      "epoch7 step57525 [D loss: 0.087397] [G loss: 0.280107]\n",
      "epoch7 step57530 [D loss: 0.008138] [G loss: 0.511053]\n",
      "epoch7 step57535 [D loss: -0.102205] [G loss: 0.458331]\n",
      "epoch7 step57540 [D loss: -0.016880] [G loss: 0.314857]\n",
      "epoch7 step57545 [D loss: -0.286567] [G loss: 0.794443]\n",
      "epoch7 step57550 [D loss: -0.000687] [G loss: 0.359449]\n",
      "epoch7 step57555 [D loss: -0.459301] [G loss: 0.376842]\n",
      "epoch7 step57560 [D loss: 0.025316] [G loss: 0.150367]\n",
      "epoch7 step57565 [D loss: -0.329577] [G loss: 0.309478]\n",
      "epoch7 step57570 [D loss: 0.247470] [G loss: 0.269978]\n",
      "epoch7 step57575 [D loss: -0.096268] [G loss: 0.299625]\n",
      "epoch7 step57580 [D loss: -0.246482] [G loss: 0.165046]\n",
      "epoch7 step57585 [D loss: 0.081827] [G loss: 0.204496]\n",
      "epoch7 step57590 [D loss: -0.240861] [G loss: 0.450611]\n",
      "epoch7 step57595 [D loss: -0.243729] [G loss: 0.414511]\n",
      "epoch7 step57600 [D loss: 0.258020] [G loss: 0.005928]\n",
      "epoch7 step57605 [D loss: -0.469135] [G loss: -0.173779]\n",
      "epoch7 step57610 [D loss: 0.044098] [G loss: -0.146112]\n",
      "epoch7 step57615 [D loss: -0.406865] [G loss: 0.451396]\n",
      "epoch7 step57620 [D loss: -0.177951] [G loss: 0.073335]\n",
      "epoch7 step57625 [D loss: 0.126964] [G loss: 0.227855]\n",
      "epoch7 step57630 [D loss: -0.366220] [G loss: -0.009817]\n",
      "epoch7 step57635 [D loss: 0.298733] [G loss: 0.298847]\n",
      "epoch7 step57640 [D loss: -0.116069] [G loss: 0.283977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step57645 [D loss: -0.038594] [G loss: 0.064708]\n",
      "epoch7 step57650 [D loss: -0.465069] [G loss: 0.183217]\n",
      "epoch7 step57655 [D loss: -0.076706] [G loss: 0.149365]\n",
      "epoch7 step57660 [D loss: -0.663584] [G loss: 0.179644]\n",
      "epoch7 step57665 [D loss: -0.162148] [G loss: 0.137324]\n",
      "epoch7 step57670 [D loss: -0.257956] [G loss: -0.296374]\n",
      "epoch7 step57675 [D loss: -0.305147] [G loss: 0.412524]\n",
      "epoch7 step57680 [D loss: -0.415096] [G loss: -0.324793]\n",
      "epoch7 step57685 [D loss: -0.167114] [G loss: -0.170837]\n",
      "epoch7 step57690 [D loss: 0.001319] [G loss: -0.276689]\n",
      "epoch7 step57695 [D loss: -0.227791] [G loss: -0.474327]\n",
      "epoch7 step57700 [D loss: 0.331503] [G loss: -0.205400]\n",
      "epoch7 step57705 [D loss: 0.251462] [G loss: -0.158433]\n",
      "epoch7 step57710 [D loss: 0.031832] [G loss: -0.436743]\n",
      "epoch7 step57715 [D loss: 0.151286] [G loss: -0.299496]\n",
      "epoch7 step57720 [D loss: 0.481422] [G loss: -0.063660]\n",
      "epoch7 step57725 [D loss: -0.225622] [G loss: -0.422502]\n",
      "epoch7 step57730 [D loss: -0.192049] [G loss: 0.092654]\n",
      "epoch7 step57735 [D loss: 0.176435] [G loss: -0.669152]\n",
      "epoch7 step57740 [D loss: 0.090034] [G loss: 0.140755]\n",
      "epoch7 step57745 [D loss: -1.035136] [G loss: -0.076914]\n",
      "epoch7 step57750 [D loss: -0.369902] [G loss: -0.270202]\n",
      "epoch7 step57755 [D loss: -0.046598] [G loss: -0.166670]\n",
      "epoch7 step57760 [D loss: -0.120477] [G loss: -0.358679]\n",
      "epoch7 step57765 [D loss: -0.262232] [G loss: -0.462316]\n",
      "epoch7 step57770 [D loss: -0.563716] [G loss: -0.082115]\n",
      "epoch7 step57775 [D loss: -0.111718] [G loss: -0.362157]\n",
      "epoch7 step57780 [D loss: -0.205584] [G loss: -0.078332]\n",
      "epoch7 step57785 [D loss: -0.114906] [G loss: 0.210385]\n",
      "epoch7 step57790 [D loss: -0.071736] [G loss: -0.307144]\n",
      "epoch7 step57795 [D loss: -0.122052] [G loss: -0.017535]\n",
      "epoch7 step57800 [D loss: 0.128826] [G loss: -0.224688]\n",
      "epoch7 step57805 [D loss: -0.003181] [G loss: 0.157206]\n",
      "epoch7 step57810 [D loss: -0.322530] [G loss: -0.222626]\n",
      "epoch7 step57815 [D loss: -0.005973] [G loss: -0.090153]\n",
      "epoch7 step57820 [D loss: 0.070823] [G loss: 0.147082]\n",
      "epoch7 step57825 [D loss: -0.382962] [G loss: 0.068479]\n",
      "epoch7 step57830 [D loss: -0.163587] [G loss: 0.072128]\n",
      "epoch7 step57835 [D loss: 0.018475] [G loss: 0.246572]\n",
      "epoch7 step57840 [D loss: -0.788888] [G loss: 0.230612]\n",
      "epoch7 step57845 [D loss: -0.303021] [G loss: 0.152787]\n",
      "epoch7 step57850 [D loss: -0.557777] [G loss: 0.114899]\n",
      "epoch7 step57855 [D loss: -0.311374] [G loss: 0.080247]\n",
      "epoch7 step57860 [D loss: -0.224498] [G loss: -0.229214]\n",
      "epoch7 step57865 [D loss: -0.225093] [G loss: 0.178987]\n",
      "epoch7 step57870 [D loss: -0.151799] [G loss: 0.233278]\n",
      "epoch7 step57875 [D loss: -0.062387] [G loss: -0.279112]\n",
      "epoch7 step57880 [D loss: -0.085260] [G loss: -0.203837]\n",
      "epoch7 step57885 [D loss: -0.389185] [G loss: 0.191582]\n",
      "epoch7 step57890 [D loss: 0.239093] [G loss: -0.013571]\n",
      "epoch7 step57895 [D loss: -0.176875] [G loss: 0.317314]\n",
      "epoch7 step57900 [D loss: -0.204387] [G loss: -0.317648]\n",
      "epoch7 step57905 [D loss: 0.344165] [G loss: -0.256336]\n",
      "epoch7 step57910 [D loss: 0.036365] [G loss: -0.276400]\n",
      "epoch7 step57915 [D loss: -0.545253] [G loss: 0.035062]\n",
      "epoch7 step57920 [D loss: -0.459346] [G loss: 0.317350]\n",
      "epoch7 step57925 [D loss: -0.592262] [G loss: -0.404212]\n",
      "epoch7 step57930 [D loss: -0.248706] [G loss: 0.000850]\n",
      "epoch7 step57935 [D loss: -0.105049] [G loss: -0.373169]\n",
      "epoch7 step57940 [D loss: -0.351801] [G loss: -0.094776]\n",
      "epoch7 step57945 [D loss: 0.219569] [G loss: -0.440228]\n",
      "epoch7 step57950 [D loss: -0.110510] [G loss: -0.005747]\n",
      "epoch7 step57955 [D loss: -0.652327] [G loss: 0.222727]\n",
      "epoch7 step57960 [D loss: -0.330831] [G loss: 0.008811]\n",
      "epoch7 step57965 [D loss: -0.034245] [G loss: -0.144948]\n",
      "epoch7 step57970 [D loss: 0.155104] [G loss: -0.026315]\n",
      "epoch7 step57975 [D loss: -0.199712] [G loss: -0.408579]\n",
      "epoch7 step57980 [D loss: -0.426368] [G loss: -0.012887]\n",
      "epoch7 step57985 [D loss: -0.409185] [G loss: -0.235953]\n",
      "epoch7 step57990 [D loss: 0.445226] [G loss: -0.180425]\n",
      "epoch7 step57995 [D loss: -0.043599] [G loss: -0.043071]\n",
      "epoch7 step58000 [D loss: 0.304291] [G loss: -0.153951]\n",
      "epoch7 step58005 [D loss: -0.241888] [G loss: -0.116754]\n",
      "epoch7 step58010 [D loss: -0.021832] [G loss: -0.251319]\n",
      "epoch7 step58015 [D loss: -0.120218] [G loss: 0.032332]\n",
      "epoch7 step58020 [D loss: -0.011648] [G loss: -0.168941]\n",
      "epoch7 step58025 [D loss: -0.413451] [G loss: -0.108872]\n",
      "epoch7 step58030 [D loss: 0.184728] [G loss: 0.073909]\n",
      "epoch7 step58035 [D loss: -0.143855] [G loss: 0.374303]\n",
      "epoch7 step58040 [D loss: 0.090689] [G loss: 0.060475]\n",
      "epoch7 step58045 [D loss: -0.546398] [G loss: 0.499327]\n",
      "epoch7 step58050 [D loss: -0.605110] [G loss: 0.482421]\n",
      "epoch7 step58055 [D loss: -0.135793] [G loss: 0.275280]\n",
      "epoch7 step58060 [D loss: -0.613330] [G loss: 0.934310]\n",
      "epoch7 step58065 [D loss: -0.354698] [G loss: -0.027514]\n",
      "epoch7 step58070 [D loss: 0.140080] [G loss: 0.397356]\n",
      "epoch7 step58075 [D loss: -0.221948] [G loss: 0.502506]\n",
      "epoch7 step58080 [D loss: 0.021997] [G loss: 0.521314]\n",
      "epoch7 step58085 [D loss: 0.124067] [G loss: 0.616665]\n",
      "epoch7 step58090 [D loss: 0.078126] [G loss: 0.557584]\n",
      "epoch7 step58095 [D loss: -0.151243] [G loss: 0.252487]\n",
      "epoch7 step58100 [D loss: -0.197970] [G loss: 0.845334]\n",
      "epoch7 step58105 [D loss: 0.205858] [G loss: 0.628922]\n",
      "epoch7 step58110 [D loss: 0.009196] [G loss: 0.461175]\n",
      "epoch7 step58115 [D loss: -0.347718] [G loss: 0.356769]\n",
      "epoch7 step58120 [D loss: -0.220465] [G loss: 0.498055]\n",
      "epoch7 step58125 [D loss: -0.621116] [G loss: 0.597578]\n",
      "epoch7 step58130 [D loss: -0.549275] [G loss: 0.769649]\n",
      "epoch7 step58135 [D loss: -0.119101] [G loss: 0.791185]\n",
      "epoch7 step58140 [D loss: -0.030348] [G loss: 0.501661]\n",
      "epoch7 step58145 [D loss: -0.305635] [G loss: 0.618306]\n",
      "epoch7 step58150 [D loss: -0.590129] [G loss: 0.669686]\n",
      "epoch7 step58155 [D loss: -0.003422] [G loss: 0.804385]\n",
      "epoch7 step58160 [D loss: 0.238611] [G loss: 0.184631]\n",
      "epoch7 step58165 [D loss: -0.533107] [G loss: 0.707172]\n",
      "epoch7 step58170 [D loss: -0.301890] [G loss: 0.525657]\n",
      "epoch7 step58175 [D loss: 0.036945] [G loss: 0.588949]\n",
      "epoch7 step58180 [D loss: 0.139347] [G loss: 0.086263]\n",
      "epoch7 step58185 [D loss: -0.501866] [G loss: 0.137918]\n",
      "epoch7 step58190 [D loss: 0.479218] [G loss: 0.166941]\n",
      "epoch7 step58195 [D loss: -0.164160] [G loss: 0.462967]\n",
      "epoch7 step58200 [D loss: 0.220073] [G loss: 0.102170]\n",
      "epoch7 step58205 [D loss: -0.362447] [G loss: 0.330517]\n",
      "epoch7 step58210 [D loss: -0.000310] [G loss: 0.229057]\n",
      "epoch7 step58215 [D loss: -0.252655] [G loss: -0.182026]\n",
      "epoch7 step58220 [D loss: -0.120882] [G loss: 0.038754]\n",
      "epoch7 step58225 [D loss: 0.165207] [G loss: 0.168627]\n",
      "epoch7 step58230 [D loss: -0.532812] [G loss: -0.295429]\n",
      "epoch7 step58235 [D loss: -0.409065] [G loss: -0.559946]\n",
      "epoch7 step58240 [D loss: -0.361130] [G loss: -0.163680]\n",
      "epoch7 step58245 [D loss: -0.278338] [G loss: -0.197687]\n",
      "epoch7 step58250 [D loss: 0.098469] [G loss: -0.192304]\n",
      "epoch7 step58255 [D loss: -0.066301] [G loss: -0.350681]\n",
      "epoch7 step58260 [D loss: -0.452148] [G loss: -0.230495]\n",
      "epoch7 step58265 [D loss: -0.079824] [G loss: 0.123510]\n",
      "epoch7 step58270 [D loss: -0.170766] [G loss: -0.340485]\n",
      "epoch7 step58275 [D loss: -0.441519] [G loss: -0.429576]\n",
      "epoch7 step58280 [D loss: -0.249197] [G loss: -0.667061]\n",
      "epoch7 step58285 [D loss: 0.082367] [G loss: -0.388217]\n",
      "epoch7 step58290 [D loss: -0.476880] [G loss: -0.426888]\n",
      "epoch7 step58295 [D loss: -0.192933] [G loss: -0.080427]\n",
      "epoch7 step58300 [D loss: -0.561038] [G loss: -0.639981]\n",
      "epoch7 step58305 [D loss: -0.272402] [G loss: -0.333095]\n",
      "epoch7 step58310 [D loss: -0.566107] [G loss: -0.654218]\n",
      "epoch7 step58315 [D loss: -0.407710] [G loss: -0.581752]\n",
      "epoch7 step58320 [D loss: -0.058410] [G loss: -0.279170]\n",
      "epoch7 step58325 [D loss: -0.021849] [G loss: -0.313085]\n",
      "epoch7 step58330 [D loss: -0.544556] [G loss: -0.426474]\n",
      "epoch7 step58335 [D loss: 0.232391] [G loss: -0.526404]\n",
      "epoch7 step58340 [D loss: -0.176369] [G loss: -0.431035]\n",
      "epoch7 step58345 [D loss: -0.780717] [G loss: -0.401120]\n",
      "epoch7 step58350 [D loss: -0.424663] [G loss: -0.231286]\n",
      "epoch7 step58355 [D loss: 0.290556] [G loss: -0.350307]\n",
      "epoch7 step58360 [D loss: 0.131777] [G loss: -0.527724]\n",
      "epoch7 step58365 [D loss: -0.059347] [G loss: -0.569059]\n",
      "epoch7 step58370 [D loss: -0.227856] [G loss: -0.461828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7 step58375 [D loss: 0.012665] [G loss: -0.366902]\n",
      "epoch7 step58380 [D loss: 0.338818] [G loss: -0.619819]\n",
      "epoch7 step58385 [D loss: -0.141539] [G loss: -0.396830]\n",
      "epoch7 step58390 [D loss: 0.328664] [G loss: -0.248385]\n",
      "epoch7 step58395 [D loss: 0.241072] [G loss: 0.062780]\n",
      "epoch7 step58400 [D loss: -0.588533] [G loss: 0.111976]\n",
      "epoch7 step58405 [D loss: -0.221303] [G loss: -0.333249]\n",
      "epoch7 step58410 [D loss: 0.087393] [G loss: 0.062245]\n",
      "epoch7 step58415 [D loss: 0.147882] [G loss: -0.097816]\n",
      "epoch7 step58420 [D loss: 0.354697] [G loss: -0.071849]\n",
      "epoch7 step58425 [D loss: -0.259861] [G loss: 0.111004]\n",
      "epoch7 step58430 [D loss: -0.144928] [G loss: 0.027576]\n",
      "epoch7 step58435 [D loss: -0.329772] [G loss: 0.356504]\n",
      "epoch7 step58440 [D loss: -0.452923] [G loss: 0.206843]\n",
      "epoch7 step58445 [D loss: -0.452924] [G loss: 0.601502]\n",
      "epoch7 step58450 [D loss: -0.132129] [G loss: -0.027818]\n",
      "epoch7 step58455 [D loss: -0.547387] [G loss: 0.385756]\n",
      "epoch7 step58460 [D loss: 0.046321] [G loss: -0.009270]\n",
      "epoch7 step58465 [D loss: 0.747582] [G loss: 0.190424]\n",
      "epoch7 step58470 [D loss: 0.110381] [G loss: 0.093396]\n",
      "epoch7 step58475 [D loss: -0.545104] [G loss: 0.594351]\n",
      "epoch7 step58480 [D loss: 0.198902] [G loss: 0.457035]\n",
      "epoch7 step58485 [D loss: -0.356659] [G loss: 0.079401]\n",
      "epoch7 step58490 [D loss: -0.428426] [G loss: 0.100258]\n",
      "epoch7 step58495 [D loss: 0.126851] [G loss: -0.126139]\n",
      "epoch7 step58500 [D loss: -0.024869] [G loss: 0.212925]\n",
      "epoch7 step58505 [D loss: -0.008257] [G loss: 0.155784]\n",
      "epoch7 step58510 [D loss: -0.015692] [G loss: 0.088042]\n",
      "epoch7 step58515 [D loss: -0.386560] [G loss: 0.032768]\n",
      "epoch7 step58520 [D loss: -0.147485] [G loss: -0.145345]\n",
      "epoch7 step58525 [D loss: 0.198540] [G loss: 0.146553]\n",
      "epoch7 step58530 [D loss: -0.063715] [G loss: -0.047147]\n",
      "epoch7 step58535 [D loss: -0.073119] [G loss: 0.143114]\n",
      "epoch7 step58540 [D loss: 0.211651] [G loss: 0.005408]\n",
      "epoch7 step58545 [D loss: 0.228385] [G loss: -0.051746]\n",
      "epoch7 step58550 [D loss: -0.316247] [G loss: 0.096558]\n",
      "epoch7 step58555 [D loss: -0.191464] [G loss: 0.192600]\n",
      "epoch7 step58560 [D loss: 0.184996] [G loss: -0.129077]\n",
      "epoch7 step58565 [D loss: -0.285092] [G loss: 0.445834]\n",
      "epoch7 step58570 [D loss: -0.580235] [G loss: 0.322604]\n",
      "epoch7 step58575 [D loss: -0.663974] [G loss: -0.232221]\n",
      "epoch7 step58580 [D loss: -0.650075] [G loss: 0.113791]\n",
      "epoch7 step58585 [D loss: -0.104993] [G loss: 0.043648]\n",
      "epoch7 step58590 [D loss: 0.171262] [G loss: 0.265599]\n",
      "epoch7 step58595 [D loss: -0.134281] [G loss: 0.449911]\n",
      "epoch7 step58600 [D loss: -0.021488] [G loss: 0.167828]\n",
      "epoch7 step58605 [D loss: -0.064234] [G loss: 0.273611]\n",
      "epoch7 step58610 [D loss: 0.490852] [G loss: 0.144669]\n",
      "epoch7 step58615 [D loss: -0.228108] [G loss: -0.031260]\n",
      "epoch7 step58620 [D loss: -0.301176] [G loss: 0.125215]\n",
      "epoch7 step58625 [D loss: -0.494815] [G loss: 0.286050]\n",
      "epoch7 step58630 [D loss: -0.063213] [G loss: 0.245930]\n",
      "epoch7 step58635 [D loss: -0.079706] [G loss: 0.042386]\n",
      "epoch7 step58640 [D loss: -0.547054] [G loss: -0.053734]\n",
      "epoch7 step58645 [D loss: 0.215551] [G loss: -0.317080]\n",
      "epoch7 step58650 [D loss: -0.207532] [G loss: 0.122672]\n",
      "epoch7 step58655 [D loss: -0.299369] [G loss: 0.052472]\n",
      "epoch7 step58660 [D loss: 0.391971] [G loss: -0.359445]\n",
      "epoch7 step58665 [D loss: 0.051746] [G loss: 0.177944]\n",
      "epoch7 step58670 [D loss: 0.008174] [G loss: 0.065360]\n",
      "epoch7 step58675 [D loss: 0.066988] [G loss: 0.171045]\n",
      "epoch7 step58680 [D loss: -0.275536] [G loss: 0.130716]\n",
      "epoch7 step58685 [D loss: -0.130879] [G loss: 0.082709]\n",
      "epoch7 step58690 [D loss: -0.101688] [G loss: 0.061704]\n",
      "epoch7 step58695 [D loss: -0.063795] [G loss: -0.045634]\n",
      "epoch7 step58700 [D loss: 0.020619] [G loss: 0.167823]\n",
      "epoch7 step58705 [D loss: -0.420162] [G loss: -0.026333]\n",
      "epoch7 step58710 [D loss: -0.560876] [G loss: -0.020650]\n",
      "epoch7 step58715 [D loss: -0.268146] [G loss: 0.138409]\n",
      "epoch7 step58720 [D loss: -0.064958] [G loss: -0.061246]\n",
      "epoch7 step58725 [D loss: -0.497947] [G loss: 0.445558]\n",
      "epoch7 step58730 [D loss: 0.276574] [G loss: 0.204634]\n",
      "epoch7 step58735 [D loss: 0.042274] [G loss: 0.066357]\n",
      "epoch7 step58740 [D loss: 0.148508] [G loss: -0.326397]\n",
      "epoch7 step58745 [D loss: 0.104712] [G loss: -0.070112]\n",
      "epoch7 step58750 [D loss: 0.130335] [G loss: -0.338214]\n",
      "epoch7 step58755 [D loss: 0.382619] [G loss: -0.521694]\n",
      "epoch7 step58760 [D loss: -0.104274] [G loss: -0.122651]\n",
      "epoch7 step58765 [D loss: -0.158006] [G loss: -0.208201]\n",
      "epoch7 step58770 [D loss: -0.095950] [G loss: -0.409806]\n",
      "epoch7 step58775 [D loss: 0.298534] [G loss: -0.249557]\n",
      "epoch7 step58780 [D loss: -0.355308] [G loss: -0.131722]\n",
      "epoch7 step58785 [D loss: 0.246273] [G loss: -0.169931]\n",
      "epoch7 step58790 [D loss: -0.278472] [G loss: -0.303498]\n",
      "epoch7 step58795 [D loss: -0.197101] [G loss: -0.146890]\n",
      "epoch7 step58800 [D loss: -0.018172] [G loss: -0.139189]\n",
      "epoch7 step58805 [D loss: -0.451354] [G loss: -0.277587]\n",
      "epoch7 step58810 [D loss: -0.149970] [G loss: 0.085729]\n",
      "epoch7 step58815 [D loss: -0.824101] [G loss: -0.111726]\n",
      "epoch7 step58820 [D loss: -0.347460] [G loss: 0.232837]\n",
      "epoch7 step58825 [D loss: -0.040238] [G loss: -0.286241]\n",
      "epoch7 step58830 [D loss: 0.310804] [G loss: -0.269980]\n",
      "epoch7 step58835 [D loss: -0.231172] [G loss: -0.403770]\n",
      "epoch7 step58840 [D loss: -0.176018] [G loss: 0.081334]\n",
      "epoch7 step58845 [D loss: -0.273072] [G loss: -0.643332]\n",
      "epoch7 step58850 [D loss: -0.255295] [G loss: -0.476920]\n",
      "epoch7 step58855 [D loss: -0.104464] [G loss: -0.464157]\n",
      "epoch7 step58860 [D loss: -0.331905] [G loss: -0.481705]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfd3e5ffe61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGANGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-bfd3e5ffe61c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0;31m# Train the critic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     d_loss = self.critic_model.train_on_batch([imgs, noise],\n\u001b[0;32m--> 206\u001b[0;31m                                                               [valid, fake, dummy])\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        # model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                for _ in range(self.n_critic):\n",
    "                    global_step += 1\n",
    "                    imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                    # Sample generator input\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                    # Train the critic\n",
    "                    d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
    "                                                              [valid, fake, dummy])\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Generator\n",
    "                    # ---------------------\n",
    "\n",
    "                g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch%d step%d [D loss: %f] [G loss: %f]\" % (epoch, global_step, d_loss[0], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    self.sample_images(epoch, global_step)\n",
    "\n",
    "    def sample_images(self, epoch, global_step):\n",
    "        r, c = 10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        generated_images = self.generator.predict(noise)\n",
    "\n",
    "        generated_images = np.asarray((generated_images * 127.5 + 127.5).astype(np.uint8))\n",
    "\n",
    "        def vis_square(data, padsize=1, padval=0):\n",
    "            # force the number of filters to be square\n",
    "            n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "            padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n",
    "            data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n",
    "\n",
    "            # tile the filters into an image\n",
    "            data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "            data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "            return data\n",
    "\n",
    "        img = vis_square(generated_images)\n",
    "        if not os.path.isdir('images_wpgan_cifar10'):\n",
    "            os.mkdir('images_wpgan_cifar10')\n",
    "        Image.fromarray(img).save(\n",
    "            \"images_wpgan_cifar10/epoch_%d_step_%d.png\" % (epoch, global_step))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wgan = WGANGP()\n",
    "    wgan.train(epochs=10, batch_size=32, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
